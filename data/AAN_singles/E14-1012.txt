Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 107?115,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsModeling the Use of Graffiti Style Features to Signal Social Relationswithin a Multi-Domain Learning ParadigmMario Piergallini1, A. Seza Do?ru?z2, Phani Gadde1, David Adamson1, Carolyn P. Ros?1,31Language TechnologiesInstituteCarnegie Mellon University5000 Forbes Avenue,Pittsburgh PA, 15213{mpiergal,pgadde,dadamson}@cs.cmu.edu2Tilburg University, TSH,5000 LE Tilburg, TheNetherlands/Language TechnologiesInstitute, Carnegie MellonUniversity, 5000 ForbesAve.,Pittsburgh PA 15213a.s.dogruoz@gmail.com3Human-ComputerInteraction InstituteCarnegie Mellon University5000 Forbes Avenue,Pittsburgh PA, 15213cprose@cs.cmu.eduAbstractIn this paper, we present a series ofexperiments in which we analyze the usage ofgraffiti style features for signaling personalgang identification in a large, online streetgangs forum, with an accuracy as high as 83%at the gang alliance level and 72% for thespecific gang.
We then build on that result inpredicting how members of different gangssignal the relationship between their gangswithin threads where they are interacting withone another, with a predictive accuracy as highas 66% at this thread composition predictiontask.
Our work demonstrates how graffitistyle features signal social identity both interms of personal group affiliation andbetween group alliances and oppositions.When we predict thread composition bymodeling identity and relationshipsimultaneously using a multi-domain learningframework paired with a rich featurerepresentation, we achieve significantly higherpredictive accuracy than state-of-the-artbaselines using one or the other in isolation.1 IntroductionAnalysis of linguistic style in social media hasgrown in popularity over the past decade.Popular prediction problems within this spaceinclude gender classification (Argamon et al.,2003), age classification (Argamon et al., 2007),political affiliation classification (Jiang &Argamon, 2008), and sentiment analysis (Wiebeet al., 2004).
From a sociolinguistic perspective,this work can be thought of as fitting within thearea of machine learning approaches to theanalysis of style (Biber & Conrad, 2009),perhaps as a counterpart to work by variationistsociolinguists in their effort to map out the spaceof language variation and its accompanyingsocial interpretation (Labov, 2010; Eckert &Rickford, 2001).
One aspiration of work insocial media analysis is to contribute to thisliterature, but that requires that our models areinterpretable.
The contribution of this paper is aninvestigation into the ways in which stylisticfeatures behave in the language of participants ofa large online community for street gangmembers.
We present a series of experimentsthat reveal new challenges in modeling stylisticvariation with machine learning approaches.
Aswe will argue, the challenge is achieving highpredictive accuracy without sacrificinginterpretability.Gang language is a type of sociolect that hasso far not been the focus of modeling in the areaof social media analysis.
Nevertheless, we arguethat the gangs forum we have selected as ourdata source provides a strategic source of data forexploring how social context influences stylisticlanguage choices, in part because it is an areawhere the dual goals of predictive accuracy andinterpretability are equally important.
Inparticular, evidence that gang related crime mayaccount for up to 80% of crime in the UnitedStates attests to the importance of understandingthe social practices of this important segment ofsociety (Johnsons, 2009).
Expert testimonyattributing meaning to observed, allegedly gang-related social practices is frequently used asevidence of malice in criminal investigations(Greenlee, 2010).
Frequently, it is police officerswho are given the authority to serve as expertwitnesses on this interpretation because of theirroutine interaction with gang members.107Nevertheless, one must consider their lack offormal training in forensic linguistics (Coulthard& Johnson, 2007) and the extent to which thenature of their interaction with gang membersmay subject them to a variety of cognitive biasesthat may threaten the validity of theirinterpretation (Kahneman, 2011).Gang-related social identities are known to bedisplayed through clothing, tattoos, and languagepractices including speech, writing, and gesture(Valentine, 1995), and even dance (Philips,2009).
Forensic linguists have claimed that theseobserved social practices have been over-interpreted and inaccurately interpreted wherethey have been used as evidence in criminal trialsand that they may have even resulted insentences that are not justified by sufficientevidence (Greenlee, 2010).
Sociolinguisticanalysis of language varieties associated withgangs and other counter-cultural groups attests tothe challenges in reliable interpretation of suchpractices (Bullock, 1996; Lefkowitz, 1989).
Ifwe as a community can understand better howstylistic features behave due to the choicesspeakers make in social contexts, we will be in abetter position to achieve high predictiveaccuracy with models that are neverthelessinterpretable.
And ultimately, our models mayoffer insights into usage patterns of these socialpractices that may then offer a more solidempirical foundation for interpretation and use oflanguage as evidence in criminal trials.In the remainder of the paper we describe ourannotated corpus.
We then motivate thetechnical approach we have taken to modelinglinguistic practices within the gangs forum.Next, we present a series of experimentsevaluating our approach and conclude with adiscussion of remaining challenges.2 The Gangs Forum CorpusThe forum that provides data for our experimentsis an online forum for members of street gangs.The site was founded in November, 2006.
It wasoriginally intended to be an educational resourcecompiling knowledge about the various gangorganizations and the street gang lifestyle.
Overtime, it became a social outlet for gang members.There are still traces of this earlier focus in thatthere are links at the top of each page to websitesdedicated to information about particular gangs.At the time of scraping its contents, it had over amillion posts and over twelve thousand activeusers.
Our work focuses on analysis of stylisticchoices that are influenced by social context, soit is important to consider some details about thesocial context of this forum.
Specifically, wediscuss which gangs are present in the data andhow the gangs are organized into alliances andrivalries.
Users are annotated with their gangidentity at two levels of granularity, and threadsare annotated with labels that indicate whichgang dominates and how the participating gangsrelate to one another.2.1 User-Level AnnotationsAt the fine-grained level, we annotated userswith the gang that they indicated being affiliatedwith,  including Bloods, Crips, Hoovers,Gangster Disciples, other Folk Nation, LatinKings, Vice Lords, Black P. Stones, other PeopleNation, Trinitarios, Norte?os, and Sure?os.There was also an Other category for the smallergangs.
For a coarser grained annotation of gangaffiliation, we also noted the nation, otherwiseknown as gang alliance, each gang wasassociated with.For our experiments, a sociolinguist withsignificant domain expertise annotated the gangidentity of 3384 users.
Information used in ourannotation included the user?s screen name, theirprofile, which included a slot for gang affiliation,and the content of their posts.
We used regularexpressions to find gang names or otheridentifiers occurring within the gang affiliationfield and the screen names and annotated theusers that matched.
If the value extracted for thetwo fields conflicted, we marked them asclaiming multiple gangs.
For users whoseaffiliation could not be identified automatically,we manually checked their profile to see if theiravatar (an image that accompanies their posts) orother fields there contained any explicitinformation.
Otherwise, we skimmed their postsfor explicit statements of gang affiliation.Affiliation was unambiguously identifiedautomatically for 56% of the 3384 users fromtheir affiliation field.
Another 36% wereidentified automatically based on their screenname.
Manual inspection was only necessary in9% of the cases.
Users that remained ambiguous,were clearly fake or joke accounts, or whoclaimed multiple gangs were grouped together inan ?Other?
category, which accounts for 6.2% ofthe total.
Thus, 94% of the users were classifiedinto the 12 specific gangs mentioned above.108At a coarse-grained level, users were alsoassociated with a nation.
The nation categorywas inspired by the well-known gang alliancesknown as the People Nation and Folks Nation,which are city-wide alliances of gangs inChicago.
We labeled the Crips and Hoovers as anation since they are closely allied gangs.Historically, the Hoovers began breaking awayfrom the Crips and are rivals with certain subsetsof Crips, but allies with the majority of otherCrips gangs.
The complex inner structure of theCrips alliance will be discussed in Section 5where we interpret our quantitative results.There are a large number of gangs thatcomprise the People and Folks Nations.
Themajor gangs within the People Nation are theLatin Kings, Vice Lords and Black P. Stones.The Folks Nation is dominated by the GangsterDisciples with other Folks Nation gangs beingsignificantly smaller.
The People Nation, Bloodand Norte?os gangs are in a loose, nationalalliance against the opposing national alliance ofthe Folks Nation, Crips and Sure?os.
Remaininggangs were annotated as other, such as theTrinitarios, that don't fit into this nationalalliance system nor even smaller alliances.2.2 Thread-Level AnnotationsIn addition to person-level annotations of gangand nation, we also annotated 949 threads withdominant gang as well as thread composition, bywhich we mean whether the users whoparticipated on the thread were only from alliedgangs, included opposing gangs, or contained amix of gangs that were neither opposing norallied.
These 949 threads were ones where amajority of the users who posted were in the setof 3384 users annotated with a gang identity.For the dominant gang annotation at thegang level, we consider only participants on thethread for whom there was an annotated gangaffiliation.
If members of a single gang producedthe majority of the posts in the thread, then thatwas annotated as the dominant gang of the thread.If no gang had a majority in the thread, it wasinstead labeled as Mixed.
For dominant gang atthe nation level, the same procedure was used,but instead of looking for which gang accountedfor more of the members, we looked for whichgang alliance accounted for the majority of users.For the thread composition annotation, wetreated the Bloods, People Nation, and Norte?osas allied with each other as the ?Red set?.
Wetreated Crips, Hoovers, Folks Nation, andSure?os as allies with each other as the ?Blueset?.
The Red and Blue sets oppose one another.The Latin Kings and Trinitarios also oppose oneanother.
Thread composition was labeled asAllied, Mixed or Opposing depending on thegangs that appeared in the thread.
As with thedominant gang annotation, only annotated userswere considered.
If all of the posts were by usersof the same gang or allied gangs, the thread waslabeled as Allied.
If there were any posts fromrival gangs, it was labeled as Opposing.Otherwise, it was labeled as Mixed.
If the userswere all labeled with Other as their gang it wasalso labeled as Mixed.3 Modeling Language Practices at theFeature LevelIn this section, we first describe the rich featurerepresentation we developed for this work.Finally, we discuss the motivation for employinga multi-domain learning framework in ourmachine-learning experiments.3.1 Feature Space Design: Graffiti StyleFeaturesWhile computational work modeling gang-related language practices is scant, we can learnlessons from computational work on other typesof sociolects that may motivate a reasonableapproach.
Gender prediction, for example, is aproblem where there have been numerouspublications in the past decade (Corney et al.,2002; Argamon et al., 2003; Schler et al., 2005;Schler, 2006; Yan & Yan, 2006; Zhang et al.,2009).
Because of the complex and subtle waygender influences language choices, it is astrategic example to motivate our work.Gender-based language variation arises frommultiple sources.
Among these, it has been notedthat within a single corpus comprised of samplesof male and female language that the twogenders do not speak or write about the sametopics.
This is problematic because word-basedfeatures such as unigrams and bigrams, whichare very frequently used, are highly likely to pickup on differences in topic (Schler, 2006) andpossibly perspective.
Thus, in cases wherelinguistic style variation is specifically ofinterest, these features do not offer goodgeneralizability (Gianfortoni et al., 2011).Similarly, in our work, members of different109gangs are located in different areas associatedwith different concerns and levels ofsocioeconomic status.
Thus, in working tomodel the stylistic choices of gang forummembers, it is important to consider how toavoid overfitting to content-level distinctions.Typical kinds of features that have been usedin gender prediction apart from unigram featuresinclude part-of-speech (POS) ngrams (Argamonet al., 2003), word-structure features that clusterwords according to endings that indicate part ofspeech (Zhang et al., 2009), features that indicatethe distribution of word lengths within a corpus(Corney et al., 2002), usage of punctuation, andfeatures related to usage of jargon (Schler et al.,2005).
In Internet-based communication,additional features have been investigated suchas usage of internet specific features including?internet speak?
(e.g., lol, wtf, etc.
), emoticons,and URLs (Yan & Yan, 2006).Transformation Origin or meaningb^, c^, h^, p^ ?Bloods up?
Positive towardsBloods, Crips, Hoovers,Pirus, respectivelyb ?
bk, c ?
ckh ?
hk, p ?
pkBlood killer, Crip killerHoover killer, Piru killerck ?
cc, kc Avoid use of ?ck?
since itrepresents Crip killero ?
x, o ?
?
Represents crosshairs,crossing out the ?0?s in aname like Rollin?
60s Cripsb ?
6 Represents the six-pointedstar.
Symbol of Folk Nationand the affiliated Crips.e ?
3 Various.
One is the trinity inTrinitario.s ?
5 Represents the five-pointedstar.
Symbol of PeopleNation and the affiliatedBloods.Table 1: Orthographical substitutions from ganggraffiti symbolismIn order to place ourselves in the best positionto build an interpretable model, our space ofgraffiti style features was designed based on acombination of qualitative observations of thegangs forum data and reading about gangcommunication using web accessible resourcessuch as informational web pages linked to theforum and other resources related to gangcommunication (Adams & Winter, 1997; Garot,2007).
Specifically, in our corpus we observedgang members using what we refer to as graffitistyle features to mark their identity.
Ganggraffiti employs shorthand references to conveyaffiliation or threats (Adams & Winter,1997).
For example, the addition of a <k> after aletter representing a rival gang stands for ?killer.
?So, writing <ck> would represent ?crip killer.?
Asummary of these substitutions can be seen inTable 1.
Unfortunately, only about 25% of theusers among the 12,000 active users employthese features in their posts, which limits theirability to achieve a high accuracy, butnevertheless offers the opportunity to model afrequent social practice observed in the corpus.The graffiti style features were extractedusing a rule-based algorithm that compareswords against a standard dictionary as well asusing some phonotactic constraints on theposition of certain letters.
The dictionary wasconstructed using all of the unique words foundin the AQUAINT corpus (Graff, 2002).
If aword in a post did not match any word from theAQUAINT corpus, we tested it against each ofthe possible transformations in Table 1.Transformations were applied to words usingfinite state transducers.
If some combinationtransformations from that table applied to theobserved word could produce some term fromthe AQUAINT corpus, then we counted thatobserved word as containing the featuresassociated with the applied transformations.The transformations were applied in the orderof least likely to occur in normal text to the mostlikely.
Since ?bk?
only occurs in a handful ofobscure words, for example, almost anyoccurrence of it can be assumed to be asubstitution and the ?k?
can safely be removedbefore the next step.
By contrast, ?cc?
and ?ck?occur in many common words so they must besaved for last to ensure that the final dictionarychecks have any simultaneous substitutionsalready removed.When computing values for the graffiti stylefeatures for a text, the value for each feature wascomputed as the number of words (tokens) thatcontained the feature divided by the total numberof words (tokens) in the document.
We used aset of 13 of these features, chosen on the basis ofhow frequently they occurred and how stronglythey distinguished gangs from one another (forexample, substituting ?$?
for ?s?
was atransformation that was common across gangs in110our qualitative analysis, and thus did not seembeneficial to include).Transformation Freq.
FalsePositiverateFalseNegativerateb^, c^, h^, p^ 15103 0% 0%b ?
bk 26923 1% 0%c ?
ck 16144 25% 8%h ?
hk 10053 1% 0%p ?
pk 5669 3% 0%ck ?
cc, kc 72086 2% 0%o ?
x, o ?
?
13646 15% 5%b ?
6 2470 16% 0%e ?
3 8628 28% 1%s ?
5 13754 6% 0%Table 2: Evaluation of extraction of graffiti stylefeatures over the million post corpusThe feature-extraction approach wasdeveloped iteratively.
After extracting thefeatures over the corpus of 12,000 active users,we created lists of words where the features weredetected, sorted by frequency.
We then manuallyexamined the words to determine where weobserved errors occurring and then made someminor adjustments to the extractors.
Table 2displays a quantitative evaluation of the accuracyof the graffiti style feature extraction.Performance of the style features wasestimated for each style-feature rule.
For eachrule, we compute a false positive and falsenegative rate.
For false positive rate, we beginby retrieving the list of words marked by thefeature extraction rule containing the associatedstyle marking.
From the full set of words thatmatched a style feature rule, we selected the 200most frequently occurring word types.
Wemanually checked that complete set of wordtokens and counted the number of misfires.
Thefalse positive rate was then calculated for eachfeature by dividing the number of tokens thatwere misfires over the total number of tokens inthe set.
In all cases, we ensured that at least 55%of the total word tokens were covered, soadditional words may have been examined.In the case of false negatives, we started withthe set of word types that did not match any wordin the dictionary and also did not trigger the stylefeature rule.
Again we sorted word types in thislist by frequency and selected the top 200 mostfrequent.
We then manually checked for missedinstances where the associated style feature wasused but not detected.
The false negative ratewas then the total number of word tokens withinthis word type set divided by the total number ofword tokens in the complete set of word types.Another type of feature we used referencedthe nicknames gangs used for themselves andother gangs, which we refer to as Names features.The intuition behind this is simple: someone whois a member of the Crips gang will talk about theCrips more often.
The measure is simply howoften a reference to a gang occurs per document.Some of these nicknames we included weregang-specific insults, with the idea that ifsomeone uses insults for Crips often, they arelikely not a Crip.
The last type of reference iswords that refer to gang alliances like the PeopleNation and Folks Nation.
Members of thoseChicago-based gangs frequently refer to theirgang as the ?Almighty [gang name] Nation?.Gang Positive/NeutralMentionsInsultsCrips crip, loc crab, ckrip, ckBloods blood, damu,piru, ubnslob, bklood,pkiru, bk, pkHoovers hoover, groover,crim, hgc, hcgsnoover,hkoover, hkGangsterDisciplesGD, GDN,GangsterDisciplegk, dk, nigkaFolksNationsfolk, folknation,almighty, nationPeopleNationpeople,peoplenation,almighty, nationLatinKingsalkqn, king,queenBlack P.Stonesstone, abpsn,moe, black p.ViceLordsvice, lord, vl,avln, foe, 4chTable 3: Patterns used for gang name features.
For allgangs listed in the table, there are slang terms used aspositive mentions of the gang.
For some gangs thereare also typical insult names.We used regular expressions to captureoccurrences of these words and variations onthem such as the use of the orthographicsubstitutions mentioned previously, plurals,feminine forms, etc.
Additionally, in the Bloodand Hoover features, they sometimes usenumbers to replace the ?o?s representing thestreet that their gang is located on.
So the Bloodsfrom 34th Street, say, might write ?Bl34d?.1113.2 Computational Paradigm: Multi-domain learningThe key to training an interpretable model in ourwork is to pair a rich feature representation witha model that enables accounting for the structureof the social context explicitly.
Recent work inthe area of multi-domain learning offers such anopportunity (Arnold, 2009; Daum?
III, 2007;Finkel & Manning, 2009).
In our work, we treatthe dominant gang of a thread as a domain forthe purpose of detecting thread composition.This decision is based on the observation thatwhile it is a common practice across gangs toexpress their attitudes towards allied andopposing gangs using stylistic features like theGraffiti style features, the particular features thatserve the purpose of showing affiliation oropposition differ by gang.
Thus, it is not thefeatures themselves that carry significance, butrather a combination of who is saying it and howit is being said.As a paradigm for multi-domain learning, weuse Daume?s Frustratingly Easy DomainAdaptation approach (Daum?
III, 2007) asimplemented in LightSIDE (Mayfield & Ros?,2013).
In this work, Daum?
III proposes a verysimple ?easy adapt?
approach, which wasoriginally proposed in the context of adapting toa specific target domain, but easily generalizes tomulti-domain learning.
The key idea is to createdomain-specific versions of the original inputfeatures depending on which domain a data pointbelongs to.
The original features represent adomain-general feature space.
This allows anystandard learner to appropriately optimize theweights of domain-specific and domain-generalfeatures simultaneously.
In our work, this allowsus to model how different gangs signal within-group identification and across-group animosityor alliance using different features.
The resultingmodel will enable us to identify how gangs differin their usage of style features to display socialidentity and social relations.It has been noted in prior work that style isoften expressed in a topic-specific or evendomain-specific way (Gianfortoni et al., 2011).What exacerbates these problems in textprocessing approaches is that texts are typicallyrepresented with features that are at the wronglevel of granularity for what is beingmodeled.
Specifically, for practical reasons, themost common types of features used in textclassification tasks are still unigrams, bigrams,and part-of-speech bigrams, which are highlyprone to over-fitting.
When text is representedwith features that operate at too fine-grained of alevel, features that truly model the target style arenot present within the model.
Thus, the trainedmodels are not able to capture the style itself andinstead capture features that correlate with thatstyle within the data (Gianfortoni et al., 2011).This is particularly problematic in caseswhere the data is not independent and identicallydistributed (IID), and especially where instancesthat belong to different subpopulations within thenon-IID data have different class valuedistributions.
In those cases, the model will tendto give weight to features that indicate thesubpopulation rather than features that model thestyle.
Because of this insight from prior work,we contrast our stylistic features with unigramfeatures and our multi-domain approach with asingle-domain approach wherever appropriate inour experiments presented in Section 4.4 Prediction ExperimentsIn this section we present a series of predictionexperiments using the annotations described inSection 2.
We begin by evaluating our ability toidentify gang affiliation for individual users.Because we will use dominant gang as a domainfeature in our multi-domain learning approach todetect thread composition, we also present anevaluation of our ability to automatically predictdominant gang for a thread.
Finally, we evaluateour ability to predict thread composition.
All ofour experiments use L1 regularized Logisticregression.4.1 Predicting Gang Affiliation per UserThe first set of prediction experiments we ranwas to identify gang affiliation.
For thisexperiment, the full set of posts contributed by auser was concatenated together and used as adocument from which to extract text features.We conducted this experiment using a 10-foldcross-validation over the full set of usersannotated for gang affiliation.
Results contrastingalternative feature spaces at the gang level andnation level are displayed in Table 4.
We beginwith a unigram feature space as the baseline.
Wecontrast this with the Graffiti style featuresdescribed above in Section 3.1.
Because all ofthe Graffiti features are encoded in words aspairs of characters, we contrast the carefullyextracted Graffiti style features with character112bigrams.
Next we test the nickname featuresalso described in Section 3.1.
Finally, we testcombinations of these features.Gang NationUnigrams 70% 81%Character Bigrams 64% 76%Graffiti Features 44% 68%Name Features 63% 78%Name + Graffiti 67% 81%Unigrams + Name 70% 82%Unigrams + CharacterBigrams71% 82%Unigrams + Graffiti 71% 82%Unigrams + Name  +Graffiti72% 83%Unigrams + Name  +Character Bigrams72% 79%Table 4: Results (percent accuracy) for gangaffiliation prediction at the gang and nation level.We note that the unigram space is achallenging feature space to beat, possiblybecause only about 25% of the users employ thestyle features we identified with any regularity.The character bigram space actually significantlyoutperforms the Graffiti features, in part becauseit captures aspects of both the Graffiti features,the name features, and also some other gangspecific jargon.
When we combine the stylisticfeatures with unigrams, we start to see anadvantage over unigrams alone.
The bestcombination is Unigrams, Graffiti style features,and Name features, at 72% accuracy (.65 Kappa)at the gang level and 83% accuracy (.69 Kappa)at the nation level.
Overall the accuracy isreasonable and offers us the opportunity toexpand our analysis of social practices on thegangs forum to a much larger sample in ourfuture work than we present in this first foray.4.2 Predicting Dominant Gang per ThreadIn Section 4.3 we present our multi-domainlearning approach to predicting threadcomposition.
In that work, we use dominantgang on a thread as a domain.
In thoseexperiments, we contrast results with hand-annotated dominant gang and automatically-predicted dominant gang.
In order to compute anautomatically-identified dominant gang for the949 threads used in that experiment, we build amodel for gang affiliation prediction using datafrom the 2689 users who did not participate onany of those threads as training data so there isno overlap in users between train and test.The feature space for that classifier includedunigrams, character bigrams, and the gang namefeatures since this feature space tied for bestperforming at the gang level in Section 4.1 andpresents a slightly lighter weight solution thanUnigrams, graffiti style features, and gang namefeatures.
We applied that trained classifier to theusers who participated on the 949 threads.
Fromthe automatically-predicted gang affiliations, wecomputed a dominant gang using the gang andnation level for each thread using the same rulesthat we applied to the annotated user identitiesfor the annotated dominant gang labels describedin Section 2.2.
We then evaluated ourperformance by comparing the automatically-identified dominant gang with the more carefullyannotated one.
Our automatically identifieddominant gang labels were 73.3% accurate (.63Kappa) at the gang level and 76.6% accurate (.72Kappa) at the nation level.
This experiment ismainly important as preparation for theexperiment presented in Section 4.3.4.3 Predicting Thread CompositionOur final and arguably most important predictionexperiments were for prediction of threadcomposition.
This is where we begin toinvestigate how stylistic choices reflect therelationships between participants in adiscussion.
We conducted this experiment twice,specifically, once with the annotated dominantgang labels (Table 5) and once with theautomatically predicted ones (Table 6).
In bothcases, we evaluate gang and nation as alternativedomain variables.
In both sets of experiments,the multi-domain versions significantlyoutperform the baseline across a variety offeature spaces, and the stylistic features providebenefit above the unigram baseline.
In bothtables the domain and nation variables are hand-annotated.
* indicates the results are significantlybetter than the no domain unigram baseline.Underline indicates best result per column.
Andbold indicates overall best result.The best performing models in both casesused a multi-domain model paired with a stylisticfeature space rather than a unigram space.
Bothmodels performed significantly better than any ofthe unigram models, even the multi-domainversions with annotated domains.
Where gangwas used as the domain variable and Graffitistyle features were the features used forprediction, we found that the high weightfeatures associated with Allied threads were113either positive about gang identity for a varietyof gangs other than their own (like B^ in a Cripsdominated thread) or protective (like CC in aBloods dominated thread).NoDomainDominantGangDominantNationUnigrams 53% 58%* 60%*CharacterBigrams49% 55% 56%GraffitiFeatures53% 54% 61%*NameFeatures54% 63%* 66%*Name +Graffiti54% 61%* 65%*Unigrams+ Name52% 58%* 61%*Unigrams+ Graffiti53% 57% 57%Unigrams+ Name+ Graffiti54% 61%* 65%*Table 5: Results (percent accuracy) for threadcomposition prediction, contrasting a single domainapproach with two multi-domain approaches, onewith dominant gang as the domain variables, and theother with dominant nation as the domain variable.
Inthis case, the domain variables are annotated.NoDomainDominantGangDominantNationUnigrams 53% 57% 57%CharacterBigrams49% 53% 55%GraffitiFeatures53% 65%* 58%*NameFeatures54% 61%* 59%*Name +Graffiti54% 60%* 59%*Unigrams+ Name52% 56% 56%Unigrams+ Graffiti53% 58%* 57%Unigrams+ Name+ Graffiti54% 60%* 59%*Table 6: Results (percent accuracy) for threadcomposition prediction, contrasting a single domainapproach with two multi-domain approaches withpredicted domain variables, one with dominant gangas the domain variables, and the other with dominantnation as the domain variable.Crips-related features were the most frequentwithin this set, perhaps because of the complexsocial structure within the Crips alliance, asdiscussed above.
We saw neither featuresassociated with negative attitudes of the gangtowards others nor other gangs towards them inthese Allied threads, but in opposing threads, wesee both, for example, PK in Crips threads or BKin Bloods threads.
Where unigrams are used asthe feature space, the high weight features arealmost exclusively in the general space ratherthan the domain space, and are generallyassociated with attitude directly rather than gangidentity.
For example, ?lol,?
and ?wtf.
?5 ConclusionsWe have presented a series of experiments inwhich we have analyzed the usage of stylisticfeatures for signaling personal gangidentification and between gang relations in alarge, online street gangs forum.
This first forayinto modeling the language practices of gangmembers is one step towards providing anempirical foundation for interpretation of thesepractices.
In embarking upon such an endeavor,however, we must use caution.
In machine-learning approaches to modeling stylisticvariation, a preference is often given toaccounting for variance over interpretability,with the result that interpretability of models issacrificed in order to achieve a higher predictionaccuracy.
Simple feature encodings such asunigrams are frequently chosen in a (possiblymisguided) attempt to avoid bias.
As we havediscussed above, however, rather than cognizantintroduction of bias informed by prior linguisticwork, unknown bias is frequently introducedbecause of variables we have not accounted forand confounding factors we are not aware of,especially in social data that is rarely IID.
Ourresults suggest that a strategic combination ofrich feature encodings and structured modelingapproach leads to high accuracy andinterpretability.
In our future work, we will useour models to investigate language practices inthe forum at large rather than the subset of usersand threads used in this paper1.1 An appendix with additional analysis and thespecifics of the feature extraction rules can be foundat http://www.cs.cmu.edu/~cprose/Graffiti.html.
Thiswork was funded in part by ARL000665610000034354.114ReferencesAdams, K. & Winter, A.
(1997).
Gang graffiti as adiscourse genre, Journal of Sociolinguistics 1/3.
Pp337-360.Argamon, S., Koppel, M., Fine, J., & Shimoni, A.(2003).
Gender, genre, and writing style in formalwritten texts, Text, 23(3), pp 321-346.Argamon, S., Koppel, M., Pennebaker, J., & Schler, J.(2007).
Mining the blogosphere: age, gender, andthe varieties of self-expression.
First Monday12(9).Arnold, A.
(2009).
Exploiting Domain And TaskRegularities For Robust Named EntityRecognition.
PhD thesis, Carnegie MellonUniversity, 2009.Biber, D. & Conrad, S. (2009).
Register, Genre, andStyle, Cambridge University PressBullock, B.
(1996).
Derivation and Linguistic Inquiry:Les Javnais, The French Review 70(2), pp 180-191.Corney, M., de Vel, O., Anderson, A., Mohay, G.(2002).
Gender-preferential text mining of e-maildiscourse, in the Proceedings of the 18th AnnualComputer Security Applications Conference.Coulthard, M. & Johnson, A.
(2007).
An Introductionto Forensic Linguistics: Language as Evidence,RoutledgeDaum?
III, H. (2007).
Frustratingly Easy DomainAdaptation.
In Proceedings of the 45th AnnualMeeting of the Association of ComputationalLinguistics, pages 256-263.Eckert, P. & Rickford, J.
(2001).
Style andSociolinguistic Variation, Cambridge: Universityof Cambridge Press.Finkel, J.
& Manning, C. (2009).
HierarchicalBayesian Domain Adaptation.
In Proceedings ofHuman Language Technologies: The 2009 AnnualConference of the North American Chapter of theAssociation for Computational Linguistics.Garot, R. (2007).
?Where You From!?
: Gang Identityas Performance, Journal of ContemporaryEthnography, 36, pp 50-84.Gianfortoni, P., Adamson, D. & Ros?, C. P. (2011).Modeling Stylistic Variation in Social Media withStretchy Patterns, in Proceedings of FirstWorkshop on Algorithms and Resources forModeling of Dialects and Language Varieties,Edinburgh, Scottland, UK, pp 49-59.Graff, D. (2002).
The AQUAINT Corpus of EnglishNews Text, Linguistic Data Consortium,PhiladelphiaGreenlee, M. (2010).
Youth and Gangs, in M.Coulthard and A. Johnson (Eds.).
The RoutledgeHandbook of Forensic Linguistics, Routledge.Jiang, M. & Argamon, S. (2008).
Political leaningcategorization by exploring subjectivities inpolitical blogs.
In Proceedings of the 4thInternational Conference on Data Mining, pages647-653.Johnsons, K. (2009).
FBI: Burgeoning gangs behindup to 80% of U.S. Crime, in USA Today, January29, 2009.Kahneman,  D. (2011).
Thinking Fast and Slow,Farrar, Straus, and GirouxKrippendorff, K. (2013).
Content Analysis: AnIntroduction to Its Methodology (Chapter 13),SAGE PublicationsLabov, W. (2010).
Principles of Linguistic Change:Internal Factors (Volume 1), Wiley-Blackwell.Lefkowitz, N. (1989).
Talking Backwards in French,The French Review 63(2), pp 312-322.Mayfield, E. & Ros?, C. P. (2013).
LightSIDE: OpenSource Machine Learning for Text Accessible toNon-Experts, in The Handbook of AutomatedEssay Grading, Routledge Academic Press.http://lightsidelabs.com/research/Philips, S. (2009).
Crip Walk, Villian Dance, PuebloStroll: The Embodiment of Writing in AfricanAmerican Gang Dance, Anthropological Quarterly82(1), pp69-97.Schler, J., Koppel, M., Argamon, S., Pennebaker, J.(2005).
Effects of Age and Gender on Blogging,Proceedings of AAAI Spring Symposium onComputational Approaches for Analyzing Weblogs.Schler, J.
(2006).
Effects of Age and Gender onBlogging.
Artificial Intelligence, 86, 82-84.Wiebe, J., Bruce, R., Martin, M., Wilson, T., & Ball,M.
(2004).
Learning Subjective Language,Computational Linguistics, 30(3).Yan, X., & Yan, L. (2006).
Gender classification ofweblog authors.
AAAI Spring Symposium SeriesComputational Approaches to Analyzing Weblogs(p. 228?230).Zhang, Y., Dang, Y., Chen, H. (2009).
GenderDifference Analysis of Political Web Forums : AnExperiment on International Islamic Women?sForum, Proceedings of the 2009 IEEE internationalconference on Intelligence and securityinformatics, pp 61-64.115
