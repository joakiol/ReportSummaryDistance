A Method of Measuring Term Representativeness- Baseline Method Using Co-occurrence Distribution -Toru Hisamitsu,* Yoshiki Niwa,* and Jun-ichi Tsujii *$ Central Research Laboratory, Hitachi, Ltd.Akanuma 2520, Hatoyama, Saitama 350-0395, Japan{hisamitu, yniwa} @harl.hitachi.co.jpAbstractThis paper introduces a scheme, which we callthe baseline method, to define a measure of termrepresentativeness and measures defined by usingthe scheme.
The representativeness of a term ismeasured by a normalized characteristic valuedefined for a set of all documents that contain theterm.
Normalization is done by comparing theoriginal characteristic value with thecharacteristic value defined for a randomlychosen document set of the same size.
The lattervalue is estimated by a baseline function obtainedby random sampling and logarithmic linearapproximation.
We found that the distancebetween the word distribution in a document setand the word distribution in a whole corpus is aneffective characteristic value to use for thebaseline method.
Measures defined by thebaseline method have several advantagesincluding that they can be used to compare therepresentativeness of two terms with verydifferent frequencies, and that they havewell-defined threshold values of beingrepresentative.
In addition, the baseline functionfor a corpus is robust against differences incorpora; that is, it can be used for normalizationin a different corpus that has a different size or isin a different domain.1 IntroductionMeasuring the representativeness (i.e., theinformativeness or domain specificity) of a term ~ isessential to various tasks in natural languageprocessing (NLP) and information retrieval (IR).
Itis particularly crucial when applied to an IRinterface to help a user find informative terms.
Forinstance, when the number of retrieved ocuments iintractably large, an overview of representativewords in the documents i needed to understand thecontents.
To enable this, an IR system, calledDualNAVI, that has two navigation windows whereone displays a graph of representative words in theretrieved ocuments, was developed (Nishioka et al1997).
This window helps users grasp the contentsof retrieved ocuments, but it also exposes problemsconcerning existing representativeness measures.Figure l shows an example of a graph for thequery '~Y-'~'~(-~ (electronic money), with NihonA term is a word or a word sequence.
{ Graduate School of Science, the University of Tokyo7-3-I Hongo, Bunkyo-ku, Tokyo 113-8654, Japantsujii@is.s.u-tokyo.ac.j pKeizai Sl#mbun (a financial newspaper) 1996 as thecorpus.
Frequently appearing words are displayed inthe upper part of the window, and words are selectedby a tf-idf-like measure (Niwa et al 1997).
Typicalnon-representative words are filtered out by using astop-word list.me n e y .
~ v ~ ~ ~ \ ] ~ - - - - - - ~electronic ---- /tmu,.~ \] ~ .
/ / ' f -~year~ / \  ~L~I2~-- monthread c pherFigure 1A topic word graph when the query isN~-e  ~---(etectronic money).One problem is the difficulty of suppressinguninformative words such as ~V- (year), -- (one),and )\] (month) because classical measures, uch astf-idf are too sensitive to word frequency and noestablished method to automatically construct astop-word list has bcen developed.Another problem is that the difference in therepresentativeness of words is not sufficiently\[In ~j indicated.
In the exarnple above, highlighting " ....(cipher) over less representative words such as ~'U~k_ 5 (read) would be useful.
Most classicalmeasures based on only term frequency anddocument frequency cannot overcome this problem.To define a more elaborate measure, atternptsto incorporate more precise co-occurrenceinformation have been made.
Caraballo et al (1999)tried to define a measure for "specificity" of a nounby using co-occurrence intbrmation of a noun, but itwas not very successful in the sense that themeasure did not particularly outperformed the termfrequency.Hisamitsu et al (1999) developed a measureof the representativeness of a term by usingco-occurrence information and a normalization320technique.
Fhe measure is based on the distancebetween tile word distribution in the documenlscontaining a term and the word distribution ill thewhole corpus.
Their measure overcomes previouslymentioned problems and preliminary experimentsshowed that this measure worked better thanexisting measures in picking outrepresentative/non-representative terms.
Since tilenormalizatio11 technique plays a crucial part ofconstructing tile nleasure, issl_lcs related to thenormalization need more study.In this paper we review Hisamitsu's measureand introduce a generic scheme - which we call thebaseline method for convenience - that can be usedto define wu'ious measures including the above.
Acharacteristic value of all documents containing aterm Y is normalized by using a baseline fimctionthat estimates the characteristic value of a randomlychosen document set of the slune size.
Tilenormalized value is then used to measure tilerepresentativeness of  the term 77.
A measure definedby the baseline.-method has several advantagescompared to classical measures.We compare four measures (two classicalones and two newly defined ones) from w.triousviewpoints, and show the superiority of the measurebased on the normalized distance between two worddistributions.
Another important finding is that thebaseline function is substantially portable, that is,one defined for a corpus can be used for a differentcorpus even it" the two corpora Mvc considerablydifferent sizes or arc in different domains.2.
E,isting measures of representative~kess2.1 OverviewVarious methods for mea:.
;uring the inforlnativcnessor domain specificity of a word have been proposedin the donmins of IR and term extraction in NLP(see the survey paper by Kageura 1996).
Illcharacterizing a term, Kagcura introduced theconcepts of "unithood" and "termhood": unithood is"the degree of strength or stability of syntagnmticcombinations or collocations," and termhood is "tiledegree to which a linguistic unit is related to (ormore straightR)rwardly, represents) domain-specificconcepts."
Kageura's termhood is therefore what wecall representativeness here.Representativeness lneasurcs were firstintroduced in till IR domain for determiningindexing words.
The simplest measure is calculatedfi'om only word frequency within a document, Forexample, tile weight 1 o of word w~ in document d/ isdefined by./~.// r .
.
_ ___  ,~ >Z/< .It-iwherc./ii is tilt: frequency of word wi in document (\]i(Sparck-Jolms 1973, Noreauh ct al.
1977).
Moreelaborate measures for tcrmhood combine wordfrequency within a document and word occurrenceover a whole corpus.
For instance, (/:/4/; the mostcomlnonly used measure, was originally defined itsN IoIcl\[ \[,i = ./;, x log( - - ) ,where iV, and N,,,,~ are, respectively, tile number ofdocuments containing word wg and the total numberof documents (Salton et al 1973).
There are awlriety or" definitions of ?idJl but its basic feature isthat a word appearing more flequently in fewerdocuments i assigned a higher value.
If documentsare categorized beforehand, we can use a moresophisticated measure based on the X-' test of thehypothesis that an occurrence of" the target word isindependent of categories (Nagao et al 1976).Research on automatic term extraction inNLP domains has led to several measures forweighting terms mainly by considering the unithoodof a word sequence.
For instance, mutualinformation (Church ct al.
1990) and thelog-likelihood (Dunning 1993) methods forextracting word bigrams have been widely used.Other measures for calculating the unithood ofn-grains have also been proposed (Frantzi et al1996, Nakagawa et al 1998, Kita et al 1994).2.2 ProblemsExisting measures uffer from at least one of thefollowing problems:(1) Classical measures sucll as t/-idjare so sensitiveto term frequencies that they fail to avoid veryfrequent non-informative words.
(2) Methods using cross-category word distributions(such as the Z-' method) can be applied only ifdocuments in a corpus are categorized.
(3) Most lneasures in NLP domains cannot reatsingle word terms because they use the unithoodstrength of multiple words.The threshold wdue lbr being representative isdcfincd in all ad hoc manner.constructs(4)The scheme that we describe heremeasures that are free of these problems.3.
Baseline method for definingrepresentativeness measures3.1 Basic ideaThis subsection describes the method we developedfor defining a measure of  term representativeness.Our basic idea is smmnarized by tile lhmous quote(Firth 1957) :"You shall k~ow a wo~zt l~y the coml)alT); irIwup.v.
"We interpreted this as the following workinghypolhesis:321For any term T, if the term isrepresentat ive ,  D(T), the seto fa l ldocuments  conta in ing  T, shou ld  havesome character i s t i c  p roper tycompared  to the "average"To apply this hypothesis, we need to specify ameasure to obtain some "property" of a documentset and the concept of "average".
Thus, weconverted this hypothesis into the followingprocedure:Choose a measure  M character i z ingadocumentset .
For termT,  ca lcu la teM(D(T)), the va lue of the measurefor D(T).
Then compare M(D(T)) withB~(#D(T)), where #D(T)is the numberof words  conta ined  in #D(T), and B,~est imates  the va lue  of M(D) when Dis a randomly  chosen document  setof s ize #D(T).Here, M measures the property and BM estinmtes theaverage.
The size of a document set is defined as thenumber of words it contains.We tried two measures as M. One was thenumber of different words (referred to here asDIFFNUM) appearing in a document set.
Teramotoconducted an experiment with a snmll corpus andreported that DIFFNUM was useful for flicking outimportant words (Teramoto et al 1999) under thehypothesis that the number of different wordsco-occurring with a topical (representative) word issnmllcr than that with a generic word.
The othermeasure was the distance between the worddistribution in D(T) and the word distribution in thewhole corpus Do.
The distance between the twodistributions can be measured in various ways, andwe used the log-likelihood ratio as in Hisalnitsu et al1999, and denote this rneasure as LLR.
Figure 2plots (#D, M(D))s when M is DIFFNUM or LLR,where D varies over sets of randomly selecteddocuments of various sizes from the articles inNikkei-Shinbun 1996.For measure M, we define Rep(T, M), therepresentativeness of T, by normalizing M(D(T)) byBM(#D(T)).
The next subsection describes theconstruction of By and the normalization.3.2 Base l ine  funct ion  and  normal i za t ionUsing the case of LLR as an example, thissubsection explains why nornmlization is necessaryand describes the construction of a baselinefunction.Figure 3 superimposes coordinates {(#D(7),LLR(D(T))} s onto the graph of LLR where T varies2 With Teramoto's method, eight paranaeters must be ttmed tonormalize D1FFNUM( D( T) ), but the details of how this wasdone were not disclosed.I00000010000010000I00010010I100 100000 100000000#D: Size of randomly chosen documentsF igure  2Values of DIFFNUM and LLR forrandomly chosen document set.II ~ ,~ ' '  i " " ~ .
.
.
.
over -ytc pner), qi(year), )J (month), i~cJ~-ll~7~(read), -- (one), j -  ~ (do), and ~}: i>~/(economy).Figure 3 shows that, for example, LLR(D(J-~)) issmaller than LLR(D( ~,~ }J5 )), which reflects ourlinguistic intuition that words co-occurring with"economy" are more biased than those with "do".However, LLR(DOI~-',3-)) is smaller than LLR(D(.
?J/-I~6))  and smaller even than LLR(D@O-~)).
Thiscontradicts our linguistic intuition, and is whyvalues of LLR are not dircctly used to compare therepresentativeness of terms.
This phenomenon arisesbecause LLR(D(~) generally increases as #\])(7)increases.
We therefore need to use some form ofnormalization to offset this underlying tendency.We used a baseline function to normalize thevalues.
In this case, Bu,(o) was designed so that itapproximates the curve in Fig.
3.
From thedefinition of the distance, it is obvious that Bu.t~(0) =Bu.R(#Do) = 0.
At the limit when #1)(~--+ o% Bu.R(')becomes a monotonously increasing function.The curve could be approxinmted preciselythrough logarithmic linear approximation near (0, 0).~lb make an approximation, up to 300 documents arerandomly sampled at a time.
(Let each randomlychosen document set be denoted by D. The numberof sampled ocuments are increased from one to 300,repeating each number up to five times.)
Each (#D,LLR(D)) is converted to (log(#D), Iog(LLR(D))).The curve formulated by the (log(#D), log(LLR(D)))values, which is very close to a straight line, isfurther divided into nmltiple parts and is part-wiseapproximated by a linear function.
For instance, inthe interval I = {x \[ 10000 _<x < 15,000},Iog(LLR(D)) could be approximated by 1.103 +1.023 x log(#D) with R e = 0.996.For LLR, we define Rep(T, LLR), therepresentativeness of T by normalizing LLR(D(7))by Bu.R(#D(7)) asfollows:Rep(r, LLR) = 100 x (Iog(LLR(D(T))) _ 1).
"log(Bu, (# D(T)))322For instance, when we used Nihon KeizaiShimbun 1996, The average of I OOx(log(LLR(D))~log(BLue (#D)) - 1), Avr, was -0.00423 and thestandard deviation, cs, was about 0.465 when Dvaries over randomly selected octuncnt sets.
l';veryobserved wflue fell within Avs'4-4er and 99% ot'observed values fell within Avl?3cs.
This hapfmlledin all corpora (7 orpora) we tested.
Theretbrc, wecan de:fine the threshold of being representative as,say, Aw" + 40.umoooo ~:} f ' i (economy)  .
_ _  _ h.. .
J J~n ion lh )!
;~i'~;i/.Jl).~) ( read)  ii., (cipher) \ !!
~ , j ~  !
& (do))~ 1000010001 O0 1000 10000 100000 1000000 10000000 I \[ = {}S#1) and lid (T)Figure 3Baseline and sample word distribution3.3 Treatment of very frequent ermsSo \['ar we have been unable to treat extremelyfrequent terms, such as -~-~ (do).
We thereforeused random sampling to calculalc tile 1@1)(77 LLR)of a very li'cquent lerm T. II' the munbcr ot'documents in D(7) is larger than a threshold wdue N,which was calculated froln the average number ofwords contained in a document, N docnmcnts arcrandomly chosen from D(2) (we used N = 150).
Thissubset is denoted D(T) and Re/)(7; LLR) is delinedby 100 x (log(LLR(D(7))) /log(BL~,Se (#1)(7))) -- 1).This is effcctivc because wc can use awell-approximated part of the baseline curve; it alsoreduccs thc amount of calctflation required.By using Rel)(77 LLR) detSned above, wcobtained Rel)(-'F g), LLR) = -0.573, Rel)(a')&TJ, llk 7~),LLR) = 4.08, and , * .... Re\])(llil-o, LLR) = 6.80, whichreflect our linguistic intuition.3.4 Features of Rep(T, M)Rep(T, M) has the t bllowing advantages by virtue ofits definition:(1) Its definition is mathematically clear.
(2) It can compare high-frequency terms with low-ficqucncy terms.
(3) The threshold value of being representative canbe defined systematically.
(4) It can be applied to n-gram terms for any n.4.
Experiments4.1 Ewfluation of monogramsTaldng topic-word selection for a navigationwindow for IR (see Fig.
1) into account, wecxamined the relation bctwecn the value of Rel)(7,M) and a manual classification of words(monograms) extracted from 158,000 articles(excluding special-styled non-sentential rticles suchas company-personnel-aflhir articles) in the 1996issties of the Nildcei Shinbun.4.1.1 PreparationWe randolnly chose 20,000 words from 86,000words having doculnent ficquencies larger than 2,thcn randomly chose 2,000 of them and classifiedthese into thrce groups: class a (acceptable) wordsuscfill for the navigation window, class d (delete)words not usethl for the navigation window, ,andclass u (uncertain) words whose usefulness in thenavigation window was either neulral or difficult tojudge.
In the classification process, a judge used theDualNA VI system and examined the informativenessof each word as guidance.
Classification into class dwords was done conservatively because theconsequences of removing informative words fromlhc window are more serious than those of allowinguseless words to appear.3hblc I shows part of the chtssification of thc2,000 words.
Words marked "p" arc proper nouns.The difference between propcr nouns in class a andproper nouns in other classes is that the former arcwcllknown.
Most words classified as "d" are verycommon verbs (such as-,J-~(do) and {J~s-~(have)),adverbs, demonstrative pronouns, conjunctions, andnumbers.
It is thereti)rc impossible to define astop-word list by only using parts-of-spccch bccauscahnost all parts-of speech appear in class d words.4.1.2 Measures used in tile experimentsTo evaluate the effectiveness of several lneasures,we compared the ability of each measure to gather(avoid) representative (non-representative) terms.We randomly sorted thc 20,000 words and thencompared the results with the restllts of sorting byother criteria: Rep(., LLR), Rep(., DIFFNUM), (f(tern~ liequency), and tfid.fi The comparison wasdone by nsing the accunmlated number of wordsmarked by a specified class that appeared in the firstN (1 _< N_< 2,000) words.
The definition we used fortj- idf wasNlota\[ .t/- ira= 4771775 ?log N(r 'where T is a term, TF(7) is the term frequency of 7,Nt,,,<,l is the number of total documents, and N(7) isthe number of documents that contain 7:4.1.3 ResultsFigure 4 compares, for all the sorting criteria, tile323accumulated number of words marked "a".
The totalnumber of class a words was 911.
Rep( o, LLR)clearly outperformed the other measures.
AlthoughRep(., DIFFNUM) outperformed .tfand tf-idf up toabout the first 9,000 monograms, it otherwiseunder-performed them.
If we use the threslaold valueof Rep(., LLR), from the first word to the 1,511thword is considered representative.
In this case, therecall and precision of the 1,511 words against allclass a words were 85% and 50%, respectively.When using tf-idf the recall and precision of thefirst 1,511 words against all class a words were 79%and 47%, respectively (note that tJ'-idfdoes not havea clear threshold value, though).Although the degree of out-performance byRep(., LLR) is not seemingly large, this is apromising result because it has been pointed out that,in the related domains of term extraction, existingmeasures hardly outperform even the use offrequency (for example, Daille et al 1994, Caraballoet al 1999) when we use this type of comparisonbased on the accumulated numbers.Figure 5 compares, for all the sorting criteria,the accumulated number of words marked by d (454in total), in this case, fewer the number of words isbetter.
The difference is far clearer in this case:Rep(., LLR) obviously outperformed the othermeasures.
In contrast, tfidJ and frequency barelyoutperformed random sorting.
Rep(., DIFFNUM)outperformed tfand (f-idfuntil about the first 3,000monograms, but under-performed otherwise.Figure 6 compares, for all the sorting criteria,the accumulated number of words marked ap(acceptable proper nouns, 216 in total ).
Comparingthis figure with Fig.
4, we see that theout-performance ofRep(., LLR) is more pronounced.Also, Rep(., DIFFNUM) globally outperformed tfand tf-idf while the performance of( land tf-idfwcrenearly the same or even worse than with randomsorting.IOOO900~00700600500400300100 5000 10000 15000 20000Order?
random ?
Rep(., LLR) a Rep(., DIFFNUM) ~ t f id f  * tfFigure 4Sorting results on class a words350300Z250200.<150100~g /L0 5000 10000 15000 20000Order?
random ~ Rep(., LLR) a Rcp(., DIFFNUM) ~ tt: idf ?
tfFigure 5Sorting results on class d wordsp)a~ 150Z100.<o j~,,--o 5(1{)0 I0000 15000 20000Order?
random ~ Rep(., LLR) z~ Rep(., I)IFFNUM) ~ tl=id\[" ?
tfFigure 6Sorting results on class ap wordsqhble 1Examples of the classified wordschtss a class u class d~" 2 :L ~Y-2"~ 5/ 1..'<-- ~ O'/~s("g) (chilly) )kT'-I'i)J (83,000,000)(amusement park) ~'\['J?J2 (depressed) ~)<?2 (greatly)g)3~)~ (threlerfingletter) ;~'~'1 t (lshigami) p T-l'flJqM-/-: (1, t46)/ '7"4) 'OM- - JP  (fircwall) ~}5',;: (Shigeyuki) p ~J-~<~ (all)"\[~l'~t~', (antique) li~?
;i,'2:t, '??
(misdirected) ~" L L (not... in the least)7" \]- ~ ; / / /  (Atlanta) p ~}J(~A~ (agility)In the experiments, proper nouns generallyhave a high Rep-value, and some have particularlyhigh scores.
Proper nouns having particularly highscores are, for instance, the names ofsumo wrestlersor horses.
This is because they appear in articleswith special formats uch as sports reports.We attribute the difference of the performancebetween Rep(., LLR) and RED(., DIFFNUM) to thequantity of information used.
Obviously informationon the distribution of words in a document is morecomprehensive than that on the number of differentwords.
This encourages us to try other measures ofdocument properties that incorporate ven moreprecise information.3244.2 Picking out fl'equeni non-representativemonogramsWhen we concentrate on the nlost fi-equent erms,Re/)(., DIFFNUM) outperfomlcd Rep(., LLR) in thefollowing sense.
We marked "clearlynon-representative terms" in the 2,000 most frequentmonograms, then counted the number of markedterms that were assigned Rt7)-values maller thanthe threshold value of a specified representativenessu lcasurc .The total number of checked terms was 563,and 409 of them are identified as non-representativeby Rep(', LER).
On the other hand, Rep( ?,DIFFNUM) identified 453 terms asnon--representative.4.3 Rank correlation between measuresWe investigated the rank-correlation of the sortingresults for the 20,000 terms used in the experimentsdescribed in subsection 4.1.
Rank correlation wasmeasured by Spearman's method and Kendall'smethod (see Appendix) using 2,000 terms randomlyselected from the 20,000 terms.
Table 2 shows thecorrelation between Rep(,, LLR) and other measures.It is interesting that the ranking by Rep(., LLR) andthat by Rep(., DIFFNUM) had a very lowcorrelation, even lower than with (f or (fidf Thisindicates that a combination of Rep(., LLR) andRep(,, DIFFNUM) should provide a strongdiscriminative ability in term classification; thispossibility deserves further investigation.Table 2Two types of Rank correlation betweenterm-rankings byRep(., LLR) and other measures.Rep(., DIFFNUM) t/=ic(f tfSpearman -0.00792 0.202 0.198Kenda l l  -0 .0646 0.161 0.1534.4 Portability of baseline functionsWe examined the robustness of thc baselinefimctions; that is, whether a baseline functiondefined from a corpus can be used for normalizationin a different corpus.
This was investigated by usingRe/)(., LLR) with seven different corpora.
Sevenbaseline functions were defined from seven corpora,then were used for normalization for defining Rep(.,LLR) in the corpus used in the experimentsdescribed in subesction 4.1.
The per%rmance of theRe/)(,, LLR)s defined using the difl'erent baselineflmctions was compared in the same way as in thesnbsection 4. l. The seven corpora used to constructbaseline fhnctions were as follows:NK96-ORG: 15,8000 articles used in the experiments in 4.1NK96-50000:50,000 randomly selected articles from Ihe wholecorpus N K96 (206,803 articles of Nikkei-shinhun 1996)N K96-100000: I 0(},000 randomly selected articles fn}m N K96NK96-200000: 2{}0,00(} randomly selcctcd articles fiom NK96NK98-1580{}0:158,0{}(} randomly selecled articles from articles inNikkei-xhinhun 1998N('- 158000:158,{}00 randomly selected abstracts of academic papersI\]'Olll NACSIS corptl:.
; (Kando ct al.
1999)NC-:\LI.
: all abstracts (333,003 abstracts) in the NACSIS coq)us.Statistics on their content words are shown in Table 3.Table 3Corpora and statistics on their content words~ ~ .
NK96-OP, G NK96-soooo NKq6-1ooooo NK96-2ooooofi o | ' Iota l  words  42,555,095 13,49S,244 26 ,934,068 53 .816,407;: ofdillbrent words 210,572 127,852 172.914 233,668~ ~  NK98-158000 NC-158000 NC-A I .
I .# ,af total v,'ords 39,762, 127 30,770,682 64,806,627# of difliarent words 196,261 231,769 350.991Figure 7 compares, for all the baseline functions, theaccumulated number of words marked "a" (seesubsection 4.1).
The pertbrmancc decreased onlyslightly when the baseline defned from NC-ALLwas used.
In other cases, the difl'erences was sosmall that they were almost invisible ill Fig.
7.
Thesame results were obtained when using class dwords and class ap words.tuoo9OO700-j5OO0 2000 40011 (dRRI XOOH I UO(lO 12tRR} 14000 160110 IROOt} 21111{11/Order* random ~ NK96-OR( i  A NK96-5t}000 - NK96-100000c\] NK96-20{}000 * NK98-158{}(1{} + NC-158000 x NC-ALLFigure 7Sorting results on class a wordsWe also examined the rank correlationsbetween the ranking that resulted from eachrepresentativeness measure in the same way asdescribed in subsection 4.2 (see Table 4).
They wereclose to 100% except when combining the Kendall'smethod and NACSIS corpus baselines.Table 4Rank correlation between the measure defined by anNK96-ORG baseline and ones defined by other baselines(%)NK96-  NK96-  NK96-  NK9g-"~C- 1 5800C NC-A I .
I .
500{}0 I.OOOO 2000{}0 158000Spcarmann 0.997 0.997 0.996 0.999 0.912 0.900Kendall 0.970 0.956 0.951 0.979 0.789 0.780These resnhs suggest hat a baseline functionconstructed from a corpus can be used to rank termsin considerably different corpora.
This is particularlyuseful when we are dealing with a corpus silnilar toa known corpus  but  do  not  know the  precise worddistributions in the corpus.
The same tdnd ofrobustness was observed when we used Re/)(",325DIFFNUM).
This baseline thnction robustness i  animportant tbature of  measures defined using thebaseline based.5.
Conclusion and future worksWe have developed a better method -- the baselinemethod -- for defining the representativeness of  aterm.
A characteristic value of all docmnentscontaining a term T, D(T), is normalized by using abaseline function that estimates the characteristicvalue of  a randomly chosen doculnent set of  thesame size as D(?).
The normalized value is used tomeasure the representativeness of  the term T, and ameasure defined by the baseline method offersseveral advantages compared to classical measures:(1) its definition is mathematically simple and clean(2) it can compare high-frequency terms withlow-frequency terms, (3) the threshold value forbeing representative can be defined systcmatically,and (4) it can be applied to n-gram terms for any n.We developed two measures: one based onthe normalized distance between two worddistributions (Rep(., LLR)) and another based onthe number of  different words in a document set(Rep( o, DIFFNUM)).
We compared these measureswith two classical measures from various viewpoints,and confirmed that Rep(,, LLR) was superior.Experiments showed that the newly developedmeasures were particularly eflizctive for discardingfrequent but uninformative terms.
We can expectthat these measures can be used for automatedconstruction of  a stop-word list and improvement ofsimilarity calculation of  documents.An important finding was that the baselinefunction is portable; that is, one defined on a corpuscan be used for laormalization in a diflbrent corpuseven if the two corpora have considerably diftbrentsizes or are in different domains.
Wc can thereforeapply the measures in a practical application whendealing with multiple similar corpora whose worddistribution information is not fully known but wehave the inforlnation on one particular corpus.We plan to apply Rep(., LLR) and Rep(.,DIFFNUM) to several tasks in IR domain, such asthe construction of  a stop-word list for indexing andterm weighting in document-similarity calculation.It will also be interesting to theoreticallyestimate the baseline functions by usingfundalnental parameters such as the total numbcr ofwords in a corpus or the total different number in thecorpus.
The natures of  the baseline functionsdeserve further study.AcknowledgementsThis project is supported in part by the AdvancedSoftware Technology Project under the auspices ofInformation-technology Promotion Agency, Japan(IPA).ReferencesCaraballo, S. A. and Charniak, E. (1999).
Determiningthe specificity of nouns fronl text.
Prec.
of EMNLP'99,pp.
63-70.Church, K. W. and Itanks, P. (1990).
Word AssociationNorms, Mutual hlformation, and Lexicography,Conq)utational Linguistics 6( 1 ), pp.22-29.Daille, B. and Gaussiel; E., and Lange, J.
(1994).
Towardsautomatic extraction of monolingual nd bilingualterminology.
Prec.
of COL1NG'94, pp.
515-521.Dunning, T. (1993).
Accurate Method for the Statistics ofSurprise and Coincidence, Computational Linguistics19(1), pp.61-74.Firth, J.
A synopsis ot' linguistic theory 1930- 1955.
(t 957).Studies in Linguistic Analysix, Philological Society, Oxford.Frantzi, K. T., Ananiadou, S., and Tsujii, J.
(1996).Extracting Terminological Expressions, IPSJ TechnicalReport of SIG NL, NLl12-12, pp.83-88.Hisamitsu, 'I:, Niwa, Y., and "l'sttiii, J.
(1999).
MeasuringRepresentativeness of Terms, Prec.
oflRAL'99, pp.83-90.Kageura, K. and Umino, B.
(1996).
Methods of automatic termrecognition: A review.
Termino logy  3(2), pp.259-289.Kando, N., I:,2uriyanaa, K. and Nozue, T. (1999).
NACSIS testcollection workshop (NTCIR-I), l'roc, of the 22nd Ammalhlternational A CM SIGIR Cot!\['.
on Research andDevelopment i  1R, pp.299-300.Kita, Y., Kate, Y., Otomo, 'E, and Yano, Y.
(1994).Colnparativc Study of Automatic Extraction of CollocationsfiOln Corpora: Mutual nlbrmation vs.
Cost Criteria, Journalof Natural Language Processing, 1( 1 ), 21-33.Nagao, M., Mizutani, M., and lkeda, H. (1976).
An AutomatedMethod of the Extraction of hnportant Words fiom JapaneseScientific l)ocuments, Trans.
oJIPSJ, 17(2), pp.
110-117.Nakagawa, H. and Mori, T. (1998).
Nested Collocation andCompound Noun For Term Extraction, Prec.
c(Computernt '98, pp.64-70Nishioka, S., Niwa, Y., lwayama, M., and Takano, A.
(1997).DualNA VI: An intbrmation retrieval interface.
Prec.
o jWISS'97, pp.43-48.
(in Japanese)Niwa, Y., Nishioka, S., Iwayama, M., and Takano, A.
(1997).
'lbpic graph generalion lbr query navigation: UTse offiequency classes lbr topic extraction.
Prec.
c?fNLPRS'97,pp.95-100.Norcault, q'., McGill, M., and Koll, M. B.
(1977).
APertbrmance Evaluation of Similarity Measure, DocumentTelill Weighting Schemes and Representation in a BooleanEnvironment.
In Oddey, R. N.
(ed.
), Iq \ [brmal ion  RetrievalResemz:h. London: Butterworths, pp.57-76.Salton, G. and Yang, C. S. (1973).
On the Specification of TermValues in Automatic Indexing.
Journal of Documentation29(4), pp.351-372.Sparck-Jones, K. (1973).
Index Term Weighting.
h(/brmationStorage and Retrieval 9(11), pp.616-633.Tcramoto, Y., Miyahara, Y., and Matsumoto, S.(1999).Word weight calculation for document retrieval by analyzingthe distribution of co-occurrence words, Prec.
of the 59thAmmal Meeting of lPS.l, 1P-06.
(in Japanese)AppendixAsusume that items I1 .....
IN are ranked by measures A and B,and that the rank of item/: assigncd by A (B) is RiO" ) (R~(j)),where RA(i ) eRA( j )  (Rl4(i) ?Ri~(j)) if i ~j.
Then, Spearman's rankcorrelation between the two rankings is given ast 6x~j(R4(i)-R"(i))2N(N ~ - 1)and Kendal l ' s  rank correlat ion between the two rank ings  isgiven asI ?
({# {(i, j) I  c~(&.,(i) - R A ( j ) )  = cr(Rz,(i ) - RB(j ) )}-N C2#{(i,./) l cr(R.4(i) - R.I(J)) = -cr(R~(i)  - Re(./))}) ,where c~ (x)=l ifx > 0, clse ifx < 0, c~ (x) = -I.326
