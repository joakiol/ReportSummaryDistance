Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 322?325,Prague, June 2007. c?2007 Association for Computational LinguisticsTKB-UO: Using Sense Clustering for WSDHenry Anaya-Sa?nchez1, Aurora Pons-Porrata1, Rafael Berlanga-Llavori21 Center of Pattern Recognition and Data Mining, Universidad de Oriente, Cuba2 Computer Science, Universitat Jaume I, Spain1 {henry,aurora}@csd.uo.edu.cu2 berlanga@lsi.uji.esAbstractThis paper describes the clustering-basedapproach to Word Sense Disambiguationthat is followed by the TKB-UO system atSemEval-2007.
The underlying disambigua-tion method only uses WordNet as externalresource, and does not use training data.
Re-sults obtained in both Coarse-grained En-glish all-words task (task 7) and Englishfine-grained all-words subtask (task 17) arepresented.1 IntroductionThe TKB-UO system relies on the knowledge-driven approach to Word Sense Disambiguation(WSD) presented in (Anaya-Sa?nchez et al, 2006).Regarding that meaningful senses of words in a tex-tual unit must be coherently related, our proposaluses sense clustering with the aim of determiningcohesive groups of senses that reflect the connectiv-ity of the disambiguating words.The way this proposal uses clustering for disam-biguation purposes is different from those usages re-ported in other works of the WSD area.
For ex-ample, in (Pedersen et al, 2005) textual contextsare clustered in order to represent senses for WordSense Discrimination.
Other works like (Agirre andLo?pez, 2003), cluster fine-grained word senses intocoarse-grained ones for polysemy reduction.
In-stead, our method clusters all possible senses cor-responding to all words in a disambiguating textualunit.
Thus, our system implements a novel cluster-ing approach for the contextual disambiguation ofwords.We use the lexical resource WordNet (version 2.1)as the repository of word senses, and also as theprovider of sense representations.
It is worth men-tioning that our proposal does not require the use oftraining data.2 The disambiguation algorithmOur method starts with a clustering of all possiblesenses of the disambiguating words.
Such a cluster-ing tries to identify cohesive groups of word senses,which are assumed to represent the different mean-ings for the set of disambiguating words.
Then, clus-ters that match the best with the context are selectedvia a filtering process.
If the selected clusters dis-ambiguate all words, the process is stopped and thesenses belonging to the selected clusters are inter-preted as the disambiguating ones.
Otherwise, theclustering and filtering steps are performed again(regarding the remaining senses) until the disam-biguation is achieved.Algorithm 1 shows the general steps of our pro-posal for the disambiguation of a set of words W .
Inthe algorithm, clustering represents the basic clus-tering method, filter is the function that selects theclusters, and T denotes the intended textual contextfrom which words in W are disambiguated (typi-cally, a broader bag of words than W ).
Next subsec-tions describe in detail each component of the wholeprocess.2.1 Sense RepresentationFor clustering purposes, word senses are repre-sented as topic signatures (Lin and Hovy, 2000).Thus, for each word sense s we define a vector322Algorithm 1 Clustering-based approach for the dis-ambiguation of the set of words W in the textualcontext TInput: The finite set of words W and the textualcontext T .Output: The disambiguated word senses.Let S be the set of all senses of words in W , andi = 0;repeati = i + 1G = clustering(S, ?0(i))G?
= filter(G,W, T )S = ?g?G?
{s|s ?
g}until |S| = |W | or ?0(i + 1) = 1return S?t1 : ?1, .
.
.
, tm : ?m?, where each ti is a Word-Net term highly correlated to s with an associationweight ?i.
The set of signature terms for a wordsense includes all its WordNet hyponyms, its di-rectly related terms (including coordinated terms)and their filtered and lemmatized glosses.
To weightsignature terms, the tf -idf statistics is used, con-sidering each word as a collection and its senses asits of documents.
Topic signatures of senses form aVector Space Model similar to those defined in In-formation Retrieval Systems.
In this way, they canbe compared with measures such as cosine, Dice andJaccard (Salton et al, 1975).In (Anaya-Sa?nchez et al, 2006), it is shown thatthis kind of WordNet-based signatures outperformthose Web-based ones developed by the Ixa Re-search Group 1 in the disambiguation of nouns.2.2 Clustering AlgorithmSense clustering is carried out by the Extended StarClustering Algorithm (Gil et al, 2003), which buildsstar-shaped and overlapped clusters.
Each clusterconsists of a star and its satellites, where the star isthe sense with the highest connectivity of the clus-ter, and the satellites are those senses connected withthe star.
The connectivity is defined in terms of the?0-similarity graph, which is obtained using the co-sine similarity measure between topic signatures andthe minimum similarity threshold ?0.
The way this1http://ixa.si.ehu.es/Ixa/clustering algorithm relates word senses resemblesthe manner in which syntactic and discourse relationlinks textual elements.2.3 Filtering ProcessOnce clustering is performed over the senses ofwords in W , a set of sense clusters is obtained.
Assome clusters can be more appropriate to describethe semantics of W than others, they are ranked ac-cording to a measure w.r.t the textual context T .As we represent the context T in the same vectorspace that the topic signatures of senses, the follow-ing function can be used to score a cluster of sensesg regarding T :(|words(g)|,?imin{g?i,Ti}min{?ig?i,?iTi},?
?s?g number(s))where words(g) denotes the set of words havingsenses in g, g?
is the centroid of g (computed asthe barycenter of the cluster), and number(s) is theWordNet number of sense s according to its corre-sponding word.Then, we rank all clusters by using the lexico-graphic order of their scores w.r.t.
the above func-tion.Once the clusters have been ranked, they are or-derly processed to select clusters for covering thewords in W .
A cluster g is selected if it containsat least one sense of an uncovered word and othersenses corresponding to covered words are includedin the current selected clusters.
If g does not con-tain any sense of uncovered words it is discarded.Otherwise, g is inserted into a queue Q.
Finally, ifthe selected clusters do not cover W , clusters in Qadding senses of uncovered words are chosen untilall words are covered.2.4 ?0 Threshold and the Stopping CriterionAs a result of the filtering process, a set of senses forall the words in W is obtained (i.e.
the union of allthe selected clusters).
Each word in W that has onlya sense in such a set is considered disambiguated.
Ifsome word still remains ambiguous, we must refinethe clustering process to get stronger cohesive clus-ters of senses.
In this case, all the remaining sensesmust be clustered again but raising the ?0 threshold.323Notice that this process must be done iteratively un-til either all words are disambiguated or when it isimpossible to raise ?0 again.
Initially, ?0 is definedas:?0(1) = pth(90, sim(S))and at the i-th iteration (i > 1) it is raised to:?0(i) = minp?{90,95,100}{?
= pth(p, sim(S))|?
> ?0(i ?
1)}In these equations, S is the set of current senses,and pth(p, sim(S)) represents the p-th percentilevalue of the pairwise similarities between senses(i.e.
sim(S) = {cos(si, sj)|si, sj ?
S, i 6= j} ?
{1}).2.5 A Disambiguation ExampleIn this subsection we illustrate the use of our pro-posal in the disambiguation of the content wordsappearing in the sentence ?The runner won themarathon?.
In this example, the set of disam-biguating words W includes the nouns runner andmarathon, and the verb win (lemma of the verbalform won).
Also, we consider that the context is thevector T = ?runner : 1, win : 1,marathon : 1?.The rest of words are not considered because theyare meaningless.
As we use WordNet 2.1, weregard that the correct senses for the context arerunner#6, win#1 and marathon#2.Figure 1 graphically depicts the disambiguationprocess carried out by our method.
The boxes inthe figure represent the obtained clusters, which aresorted regarding the ranking function (scores are un-der the boxes).Initially, all word senses are clustered using?0=0.049 (the 90th-percentile of the pairwisesimilarities between the senses).
It can be seenin the figure that the first cluster comprises thesense runner#6 (the star), which is the senserefering to a trained athlete who competes in footraces, and runner#4, which is the other senseof runner related with sports.
Also, it includesthe sense win#1 that concerns to the victory ina race or competition, and marathon#2 thatrefers to a footrace.
It can be easily appreciatedthat this first cluster includes senses that coverthe set of disambiguating words.
Hence, it isselected by the filter and all other clusters areFigure 1: Disambiguation of words in ?The runnerwon the marathon?.discarded.
After this step, S is updated with the set{runner#6, runner#4, win#1,marathon#2}.
2In this point of the process, the senses of S do notdisambiguate W because the noun runner has twosenses in S. Therefore, the sttoping criterion doesnot hold because neither |S| 6= |W | and ?0(2) =0.104 6= 1.
Consequently, a new cluster distributionmust be obtained using the current set S.The boxes in the bottom of Figure 1 representthe new clusters.
In this case, all clusters are sin-gles.
Obviously, the cluster containing the senserunner#4 is discarded because the cluster that in-cludes the sense runner#6 overlaps better with thecontext, and therefore precedes it in the order.Then, the final set of selected senses is S ={runner#6, win#1, marathon#2}, which in-cludes only one sense for each word in W .3 SemEval-2007 ResultsOur system participated in the Coarse-grained En-glish all-words task (task 7) and in the English fine-grained all-words subtask (task 17).
In both cases,the disambiguation process was performed at thesentence level.
Thus, we defined the intended tex-tual context T for a sentence to be the bag of all itslemmatized content words.
However, W was set upin a different manner for each task.We present our results only in terms of the F1measure.
Recall and Precision values are omitted2In the figure, doubly-boxed clusters depict the selected onesby the filter.324Test set F1d001 0.78804d002 0.72559d003 0.69400d004 0.70753d005 0.58551Total 0.70207Table 1: TKB-UO results in Coarse-grained Englishall-words task.Category Instances F1Noun 161 0.367Verb 304 0.303All 465 0.325Table 2: TKB-UO results in English Fine-grainedall-words subtask.because our method achieves a 100% of Coverage.3.1 Coarse-grained English All-words TaskFirstly, it is worth mentioning that we do not usethe coarse-grained inventory provided by the com-petition for this task.
Indeed, our approach can beviewed as a method to build such a coarse-grainedinventory as it clusters tightly related senses.Each W was defined as the set of all tagged wordsbelonging to the sentence under consideration.
Ta-ble 3.1 shows the official results obtained by our sys-tem.As it can be appreciated, the effectiveness of ourmethod was around the 70%, except in the fifthtest document (d005), which is an excerpt of storiesabout Italian painters.3.2 English Fine-grained All-words SubtaskSimilar to previous task, we included into each Wthose tagged words of the disambiguating sentence.However, as the set of tagged words per sentencewas verb-plentiful, with very few nouns, we ex-panded W with the rest of nouns and adjectives ofthe sentence.Table 3.2 summarizes the results (split by wordcategories) obtained in this subtask.
The second col-umn of the table shows the number of disambiguat-ing word occurrences.As we can see, in this subtask only nouns andverbs were required to be disambiguated, and over-all, verbs predominate over nouns.
The poor per-formance obtained by verbs (w.r.t.
nouns) can beexplained by its high polysemy degree and its rela-tively small number of relations in WordNet.4 ConclusionsIn this paper, we have described the TKB-UO sys-tem for WSD at SemEval-2007.
This knowledge-driven system relies on a novel way of using cluster-ing in the WSD area.
Also, it benefits from topic sig-natures built from WordNet, which in combinationwith the clustering algorithm overcomes the sparse-ness of WordNet relations for associating semanti-cally related word senses.
The system participatedin both the Coarse-grained English all-words task(task 7) and the English fine-grained all-words sub-task (task 17).
Since we use sense clustering, we donot use the coarse-grained sense inventory providedby the competition for task 7.
Further work will fo-cus on improving the results of fine-grained WSD.ReferencesEneko Agirre and Oier Lo?pez.
2003.
Clustering wordnetword senses.
Proceedings of the Conference on RecentAdvances on Natural Language Processing, pp.
121?130Henry Anaya-Sa?nchez, Aurora Pons-Porrata, and RafaelBerlanga-Llavori.
2006.
Word sense disambiguationbased on word sense clustering.
Lecture Notes in Arti-ficial Intelligence, 4140:472?481.Reynaldo Gil-Garc?
?a, Jose?
M.
Bad?
?a-Contelles, and Au-rora Pons-Porrata.
2003 Extended Star ClusteringAlgorithm.
Lecture Notes on Computer Sciences,2905:480?487Chin-Yew Lin and Eduard Hovy.
2000.
The AutomatedAcquisition of Topic Signatures for Text Summariza-tion.
Proceedings of the COLING Conference, pp.495?501Ted Pedersen, Amruta Purandare, and Anagha Kulka-rni.
2005.
Name Discrimination by Clustering Sim-ilar Contexts.
Lecture Notes in Computer Science,3406:226?237Gerard Salton, A. Wong, and C.S.
Yang.
1975.
AVector Space Model for Information Retrieval.
Jour-nal of the American Society for Information Science,18(11):613?620325
