Automatic  Semantic Sequence Extractionfrom Unrestricted Non-Tagged TextsShiho Nobesawa and Hi roak i  Saito mad Masakazu  Nakan ish iDept.
of Computer  ScienceKeio University3-14-1 Hiyoshi Kohoku, Yokohama 223-8522, Japan{shiho, hxs, czl}@nak.ies.keio.ac.jpAbst rac tMophological processing, syntactic parsing andother useflfl tools have been proposed in the fieldof natural language processing(NLP).
Manyof those NLP tools take dictionary-based ap-proaches.
Thus these tools are often not veryefficient with texts written in casual wordingsor texts which contain maw domain-specificterms, because of the lack of vocabulary.In this paper we propose a simple methodto obtain domain-specific sequences from unre-stricted texts using statist;ical information only.This method is language-independent.We had experiments oil sequence xtractionon email l;exts in Japanese, and succeeded inextracting significant semantic sequences in thetest corpus.
We tried morphological parsingon the test corpus with ChaSen, a Japanesedictionary-based morphological parser, and ex-amined our system's efficiency in extraction ofsemantic sequences which were not recognizedwith ChaSen.
Our system detected 69.06% ofthe unknown words correctly.1 I n t roduct ionI/eeognition of contained words is an impoftan| preproecssing for syntactic parsing.
Wordrecognition is mostly done based on dictionarylookup, and unknown words often cause parseerrors.
Thus most of the researches have beendone on fixed corpora with special dictionariesfor the domain.Part-of-speech(POS) tags are often used forterm recognition.
This kind of preprocessingis often time-consmning and causes anfi)iguity.Wtmn it conies to the corpus with high rate ofunknown words it is not easy to do a fair parsingwith dictionaries and rules.Obtaining the contained terms and phrasescorrectly can be an efficient preprocessing.
Inthis paper we propose a method to recognizedomain-specific sequences with simple and non-eosty processing, which enables the use of unre-stricted corpora fc)r NLP tools.We concentrate on building a tool for extract-ing nmaningful sequences automatically withless preparation.
Our systcnl only necds a fairsize of non-tagged training corpus of tim tar-get language.
No restriction is required for thetraining corpus.
We do not need any preprocess-ing for the training corpus.We had experiments on email messages inJapanese and our system could recognize 69.06%of the undcfined sequences of the test corpus.2 Japanese  Characters  and TermsTaking a word as a basic semantic unit simplifiesthe conflming tasks of processing real languages.However single words are often not a good unitregarding the meaning of the context, becauseof the polysemy of the words(Fung, 1998).
In-stead a phrase or a term can be taken as smallestsemantic units.Most of the phrase/term extraction systemsare based on recognizing noun phrases, ordomain-specific terms, fi'om large corpora.
Arg-anion et a1.
(1998) proposed a memory-based ap-proach for noun phrase, which was to learnpatterns with several sub-patterns.
Anani-adou(1994) proposed a methodology based onterm recognition using morphological rules.2.1 Term Extract ion in JapaneseJapanese has 11o separator between words.
Onnoun phrase extraction many researches havebeen done in Japanese as well, both stochas-tic and gramlnatical ways.
In stochastic ap-proaches ~z-gram is one of the most fascinat-ing model.
Noun phrase extraction(Nagao ndMori, 1994), word segmentation(Oda and Kita~5791999) and diction extraction are the major is-sues.
There also are many researches on segmen-tation according to the entropy.
Since Japanesehas a great number of characters use of the infor-mation of letters is also a very interesting issue.2.2 Characters in JapaneseUnlike English, Japanese has great mnount ofcharacters for daily use.
Japanese is special notonly for its huge set of characters but its con-taining of three character types.
Hiragana is aset of 71 phonetic haracters, which are mostlyused for flmction words, inflections and adverbs.Katakana is also a set of phonetic characters,each related to a hiragana character.
The useis mainly restricted to the representation f for-eign words.
It's also used to represent pronun-ciations.
Kanji is a set of Chinese-origin char-acters.
There are thousands of kanji characters,and each kanji holds its own meaning.
They  areused to represent content words.
We also usealphabetical characters and Arabic numerals.3 Overv iewThis system takes Japanese sentences as input.It processes sentences one by one, and we obtainsegments of the sentences which are recognizedas meaningful sequences as output.
The flow ofthis system is as follows(Figure 1): Our systemTRAINING EXTRACTIONinput (sentences)cooccur renceinformation- - _4input (a sentence)linking scorecalculationsequence extractionoutput (sequences)Figure 1: The Flow of tim Systemtakes one sentence as an input at one time, andcalculates tile scores between two neighboringletters according to the statistical data drivenfrom the training corpus.
After scoring the sys-tem decides which sequences to extract.3.1 Automatic Sequence ExtractionNobesawa et a1.
(1996; 1999) proposed a systemwhich estimates the likelihood of a string of let-ters be a meaningfifl block in a sentence.
Thismethod oes not need any knowledge of lexicon,and they showed that it was possible to segmentsentences in meaningflfl way only with statisti-cal information between letters.
Tile experimeN;was in Japanese, and they also showed that tilecooccurrence information between Japanese let-ters had enough information for estimating theconnection of letters.We use this point in this paper and had ex-periments on extracting meaningfnl sequences inemail message texts to make up the lack of vo-cabulary of dictionaries.3.2 ScoringOur system introduces the linking score,which indicates the likelihood that two let-ters are neighboring as a (part of) meaningfulstring(Nobesawa et al, 1996).Only with neighboring bigrams it is impossi-ble to distinguish the events 'XY' in 'AXYB'fi'om 'CXYD'.
Thus we introduce d-bigramwhich is a bigram cooccurrence information con-cerning the distance(Tsutsumi et al, 1993).Expression (1) calculates the score betweentwo neighboring letters;UK(i) = E E M~(wj,wi+d;d ) x,q(d) (1)d=l  j-=i--(d--1)where wl as an eveN;, d as the distance betweentwo eveN;s, dmax as the maximum distance usedin the processing (we set drnax -~ 5), and g(d) asthe weight fimction on distance (for this systemg(d) = d-2(Sano et al, 1996), to decrease tile in-fluence of tile d-bigrams when the distance getlonger (Church and Hanks, 1989)).
When cal-culating the linking score between the letters wiand Wi+l, tile d-bigram information of the let-ter pairs around tim target two (such as (wi-l,wi+2; 3)) are added.Expression (2) calculates the mutual informa-tion between two events with d-bigram data;v; d)d) - -  (2)where x, y as events, d for the distance betweentwo events, and P(x) as the probability.3.3 Sequence ExtractionUsing the linking score calculated according totile statistical information, our system searchesfor the sequences to extract (thus we call oursystem LSE(linky sequence xtraction) system).580Figure 2 shows an example graph of the link-ing scores for a sentence.
Each alphabet letteron the x-axis stands for a letter in a sentence.Figure 2: The Score GraphThe linking scores between two neighbor-ing letters are dotted on the graph on they-axis.
Since the linking score gets higherwhen the pair has stronger connection, themountain-shaped lines may get considered asunsegmentable blocks of letters.
The linkingscores of the pairs in longer words/phrases canbe higher with the influence of the statistical in-formation of other letter pairs around them.
Onthe other hand, the linking score between twoletters which are accidentally neighboring etslower, and it makes valley-shaped point on thescore graph.
Our system extracts the mountain-shaped parts of the sentence as the qinky se-quences', which is considered to be nleaningflflaccording to the statistical information.
In ex-ample Figure 2, strings AB, CDEF and HIJKmight be extracted.The height of mountains are not fixed, accord-ing to the likelihood of the letters blocked asa string.
Tiros we need a threshold to decidestrings to extract according to the required sizeand the strength of connection.
With higherthreshold the strings gets shorter, since thehigher linking score means that the neighboringletters can be connected only wlmn they havestronger commotion between them.3.4 I-Iow the System Uses theStatist ical InformationFigure 3 shows the example graph on a sentence"~ i~"~"~2 \[o-gen-ki-de-su-ka-?\]" (: How areyou?
)(Sano, 1997).
Each graph line indicatesthe linking score of the sentence after learningsome thousamts of sentences of the target do~main (for this graph we used a postcard corpusas Lhe target domain, and for the base domainwe took a newspaper corpus).
When the systemhave no information on the postcard domain,the system could indicate that only the pair ofletters "~/z(, (gen-ki)" is connectable (there is amountain-shaped line for this pair).
Obtainingthe information of postcard corpus, the linkingscores of every pair in this sentence gel; bigger,to make higher mountain.
And the shape ofthe mountain also changes to a flat one moun-tain which contains whole sentence from a steel)mountain with deep valleys.t0.005.00o.0~-5.03-t0.00-150~-20.~-3o.ooa N!!
'>,,I'131RIiS HOLD030116014I_~?qlt~/( ,Ah~?Figure 3: Score Graph for "@@23~-~-~-)5~ ?(@@-o-gen-ki-de-su-ka-?
: How are you?
)"4 Exper imentsWe had experiments on extracting semantic se-quences based only on letter cooccm'rencc infor-mation.We tried a dictionary-based Jap~mese mor-phological parser ChaSen vet.
1.51 (\] 9 9 7) oil thetest corpus as well to check sequences whid~ adictionary-based parser can not: recognize.4.1 CorpusWe chose email messages as the corpora for ex-periments of our system.
Email messages aremostly written in colloquialism, especially whenthey are written by younger people to send totheir friends.
In Japanese colloquialism has ca-sual wording which (lifters from literary style.Casual wording contains emphasizing and termsnot in dictionary such as slangs.
In English anemphasized word may he written in capital et;-ters, such as in "it SURE is not true", whichis easily connected to the basic word "sure".We do the same kind of letter type changes inJapanese for emphasizing, however, since the re-lationship between letter types is not the sameas English, it is not easy to connect he empha-sized terms and the basic terms.5814.1.1 T ra in ing  CorpusThe training corpus we used to extract statisti-cal information is a set of email messages entbetween young female friends during 1998 to1999.
This corpus does not cover the one usedas the test corpus.
All the messages were sentto one receiver, and the number of senders is17.
The email corpus contains 351 email mes-sages, which has 7,865 sentences(176,380 letters,i.e.
22.4 letters per sentence on average).We did not include quotations of other emailsin the training corpus to avoid double-countingof same sentences, though email messages oftencontain quotations.4.1.2 Test  CorpusThe test corpus is a set of email messages sentbetween young female friends during 1999.
Thiscorpus is not a part of the training corpus.
Allthe messages were sent to one receiver, and thenumber of senders is 3.
This corpus contains1,118 sentences(24,160 letters, i.e.
21.6 lettersper sentence on average).4.2 P re l iminary  Resu l tsFigure 4 shows the distribution of the linkingscores.
The average of the scores is 0.34.
Thepairs of letters with higher linking scores aretreated as highly 'linkable' pairs, that is, pairswith strong connection according to the statis-tical inforination of the domain (actually of thetraining corpus)..,a .~ .m .,a\]tJ {ImFigure 4: Score Distril)utionPairs of letters with high scores are mainly foundin high-scored sequences (Tahle 1).Table 1 shows a part of the sequences ex-tracted with our system using letter cooccur-rence information.
The threshold of extractionfor Table 1 is 5.0.Table 1: Sequences Extracted Based on LetterCooccurrencesequence memfing frequency(with scores over 5.0)... a ...... 72~: ~ so 52~:~ " ~ but 48/J~ ~ '~ ttmrefore 43/~ ~J~ mail 39(~)  (laugh) 36~Y~'5/b I 29Jc~h~ it 26.... a ...... 25I~ 5~ myself 2025 ~, b a net/Internet 20!
!
a !
!
16I) >/~ link 152~ fl'iend 13casuM wordingb representation change (written in katat~na)These sequences which extracted frequentlyare the ones often use in tile target domain.4.3 Undef ined  Words  w i th  ChaSenSince ChaSen is a dictionary-based system, itoutputs unknown strings of letters as they are,with a tag 'undefined word'.Table 2 shows the number of sequences whichChaSen resulted as "undefined words".
The row'undefined words' indicates the sequences whichwere labeled as 'undefined word' with ChaSen,and the row 'parsing errors' stands for the se-quences which were not undefined words withChaSen but not segmented correctly 1 .
The ex-traction threshold is 0.5.ChaSen had 627 undefined words as its out-put.
Since the test corpus contains 1,118 sen-tences, 56.08% of the sentences had an unde-fined word on average.
As it is impossible to di-vide an undefined sequence into two undefinedwords, when two or more undefined sequencesare neighboring they m'e often connected intoone undefined word s Ttms the real number ofundefined sequences can be more than counted.Table 2 shows that our system on statistical in-formation can be a help to recover 69.06% of theundefined sequences detected by ChaSen.1Since our system is not to put POS tags, we do notcount agging errors with ChaScn (i.e., we do not containtagging errors in the 'parsing errors').2ChaSen cm, divide two neighboring undifined se-quences when the letter types of the sequences differs.582Table 2: Undefined Words with ChaSenundefined words w/LSE  systemfrequency ~/:total suc.
~ part.
b failedover 10 281 230 7 443 - 9 143 100 13 302 56 43 4 91 147 60 44 43total 627 433 68 12669.06% 10.85% 20.10%a sue.
: succeeded to extractb pm't.
: pm'tiMly extractedTable 2 also shows that  this system has bet-ter precision with tile sequences with larger fre-quency.
For the sequences with frequency over10 times (in the test corpus), 81.85% of the se-quences have extracted correctly.
Ignoring se-quences which appeared in the test corpus once,the rate of correct extract ion rose up to 77.71%.Table 3 shows how our system worked withthe sequences whirl1 are found as undefinedwords with ChaSen parsing system.
The  thresh-old for extract ion is 0.5.
Table 3 shows that timTable 3: Categories of undefined Wordsmldefined words w 7 LSE systemcategory #total sue."
part) fidledproper nouns 60 39 17 4new words 70 48 12 l0letter additions 119 89 4 26changes ~ 276 194 28 54term.
marks ~z 58 43 0 15smileys 15 9 6 0et:c. 29 12 1 16toted 627 433 68 126a sue.
: succeeded to extractI, part.
: partially extractedc changes: representation changes't tenn. marks: termination marksbiggest reason for the undefined words are thewob lem of the representation.
As descril)ed inSection 4.3.2, we change the way of descript ionwlmn we want to emphasize the sequence.
Thepronunciat ion extension with adding extra vow-els or extension marks is also for the same rea-son.
Adding these two categories, 356 sequencesout of 627 undefined words(56.78%) are causedin this emphasizing.Terminat ion marks as undefined words con-lain sequences uch as " ...... " and " !
! "
Theterminat ion marks not in dict ionary often indi-cate the impression, sud l  as surprise, hal)piness,considering and so on.New words including proper  nouns are the ac-tual 'undefined words'.
ChaSen had 130 of themas its output ,  that  is 20.73% of the undefinedwords.4.3.1 Let ter  Types  in Undef ined WordsTable 4 shows the types of letters included inthe 'undefined words' with ChaSen.
Tile figuresindicate the numbers of letters.We had 627 undefined words in the test cor-pus with ChaSen (Table 2), which contain 1,493letters totally.
The average length of the unde-fined words is thus 2.38.
70.40% of the letters in%~ble 4: Letter  Types  of Undefined Wordsundefined words w/LSE systemtype variety #total sllc.
a pal't, b failedl~mji I.
19 19 0 0hiragmm 12 200 155 7 38katal~ma 73 1051 712 188 151nmneral 1 1 0 1 0alphabet 23 122 43 72 7symbol 22 100 39 37 24total 1493 968 305 220a sue.
: succeeded to ex~rac~l, part.
: pm-t, ially extractedundefined words were katakana letters(Table 4),which are phonetic and often used for describingnew words.
Katakana letters are also often usedfor emphasiz ing sequences.OI1 the other hand, there was only one lettereach for kanji and numeral  figure.
That  is be-cause each kanji letter and numeral  figure has itsown meaning, and those letters are most ly  foundin the dictionary, even though tlle tags are notsemantical ly correct.
Or, as for kan.\]i letters, itsometimes can be tagged with incorrect segmen-tat ion 3.
Thus undefined words in kanji lettersare not counted as 'undefined words' mostly, andinstead they cause segmentat ion fai lure(Section4.4).4.3.2 Representat ion  ChangesSince Japanese have two phonetic haracter sets,we have several ways to represent one term; inkanii (if thm'e is any for the tin-m), in hiragana,in katakana, or sevm'al d laracter  type mixed.
Itis also possible to use Romanizat ion to representa tern1.a ,,~_ a )  \[ko-no\] (:this)/t!k'~ \[se-l~d\] (:the world)" is incor-rectly segmented as ",~ 0~91~: \[ko-no-yo\](:the pr sent life)/\[kai\](:world)"; "kono yo" is a fixed phrase, and "lmi"is a suffix for a nmm to put the meaning of "the worhtof", e.g.
"~7::gl ~(:the literary world)"583Table 5 shows the numbers of ChaSen errorsaccording to the representation change.
Most ofTable 5: Undefined Words because of Represen-tation Changesundefined words w/LSE  systemsubeategory ~tota l  sue."
part.
b failedterm chmlges 40 33 3 4lmtal~na 137 102 12 23chmlge & katalmala 55 34 10 11etc.
44 25 3 16total 276 194 28 54.
sue.
: succeeded to extractb part.
: partiMly extractedthe dictionaries have only one basic representa-tion for one term as its entry 4.
However, in ca-sual writing we sometimes do not use the basicrepresentation, to emphasize the term, or justto simplify tile writing.4.3.3 Pronunciat ion Extens ionIn JapalmSe language we have many kinds offunction words to put at the end of sentences(or sometimes 'bunsetsu' blocks).
The functionwords for sentence nds are to change the soundof the sentences, to represent friendliness, order-ing, and other emotions.
These function wordsare not basically used in written texts, but incolloquial sentences.In Japanese language we put extra letters torepresent he lengthening of a phone,.
Sincealmost all Japanese phones have vowels, tolengthen a phone for emphasizing we put extravowels or extension marks after tim letter.
TableTaMe 6: Extra Letters output as UndefinedWordsletter ~b ~, -) ~ $~ ~ 'y ~" totala i u e o t t nsue."
39 2 5 32 7 3 1 0 89part.b 0 0 0 0 0 4 0 0 4failed 5 1 4 2 1 7 5 1 26total 44 3 9 34 8 14 6 1 119suc.
: succeeded to extractb part.
: partially extracted.6 shows that 74.79% of the small letters whichresulted as undefined words with ChaSen couldbe salvaged as parts of semantic sequences withour system.4Dictionaries may have phonetic representations forthe entries, not as headings.These small letters in this table are extra let-ters to change the pronunciation; i.e.
they ~remostly not included in the dictionary.
Howeverthey are actually a part of the word, since theycould not be separated from the previous se-quences.4.4 Segmentation Failure with ChaSenTable 7 shows (;he result of the extraction ofsequences which ChaSen made parsing errors.It indicates that our system could recognize70.88% of the sequences which ChaSen madeparsing errors.Table 7: Segmentation Failure with ChaSenundefined words w/LSE systemcategory 7~total SilO.
a part.
b failedA 42 41 1 0B 60 35 10 15C 92 81 5 6D 11 2 5 4E 8 4 3 1F 176 106 37 33G 19 10 5 4H 257 154 73 30I 253 233 6 14J 115 82 19 14torn 941 667 159 11570.88% 16.90% 12.22%A: sequences incl.
alphabetical charactersB: sequences incl.
numeral figuresC: proper nounsD: new words excl.
proper nounsE: fixed locutionsF: sequences with representation changesG: sequences in other character typesII: emph,xsized expressionsI: termination marksJ: parsing errorsa sue.
: succeeded to extractpart.
: partially extractedCategory F is for the sequences which changedtheir representations according to tile terms'pronunciation changes for casual use.
For ex-ample, "~?
\[ya-p-pa\]" is a casual form of "~lTk 9 \[ya-ha-ri\](: as I thought)".
In casual talk-ing using original terln "yahari" sounds a littletoo polite.
Sonm common casual forms are indictionaries, but not all.For the category B, our system failed to ex-tract 25 sequences.
All the sequences in B arewith counting suffixes.
12 sequences out of the58425 couhl not l)e connected wil;h the counting suf-fixes, e.g.
"3 0 H \[3-0-nichi\](: 30 days, or, the30th day)" got over-segmented l)etween zero andthe suffix.
We have a big w~riety of counting suf-fixes in Japanese and since our system is onlyon letter cooccurrence information we couM notavoid tlm over-segmentation.Category C indicates the sequences wlfich arewritten in other character types for emphasizing.The major changes are: (1) to write in hiraganacharacters instead of kan.ji characters, and (2) towrite in katakana characters to emphasize theterm.5 Conclus ionDictionary-based NLP tools often have worseprecision with ~exts written in casual wordingsand texts which contain many domain-specificterms.
'lbrm recognition system available fi)rany corpora as a preprocessing enables the useof NLP tools on many kinds of texts.In this paper we proposed a simple mefllod fi)rterm recognition based on statistical informa-tion.
We had experiments on extracting seman-tically meaningflfl sequences according to thestatistical information drawn fi:om the trainingcorpus~ and our system recognized 69.06% of thesequences whidl were tagged as undefined wordswitll a conventional nmrphologieal parser.Our sysi;em was efl3cient in recognizing differ-ent representations of terms, proper nouns, andother casual wording phrases.
This helps to sal-vage semantically meaningful sequences not indictionaries and this can be an efficient prepro-cessing.6 Future WorkIn this paper we proposed a simt)le term recog-nition method based only on statistical informa-tion.
There may be several ways to combine theextracted sequences with the dictionaries.
Wemay need to put POS tags to the sequences forthe use with other NLP tools.
We ext)ect thatwe can use tagging tools for this.This system we propsed is language-independent.
For example, we Call use thissystem on English to extract English sequenceswhich appeared frequently in the trainingcorpus, such as proper nouns.ReferencesSophia Ammiadou.
1994.
A Methodology for Auto-tactic Term ll,ecoglfit;ion.
Colin9-9~, pages 1034-1038.Shlomo Argmnon, Ido DagmL and Yuwtl Kry-molowski.
1998.
A M(~mory-Based Approachto Learning Shallow Natural Lang~lage, Patterns.Col'ing-ACL'98, pages 67-73, August.Kenneth W. Church and Patrick IIanks.
1989.
WordAssociation Norms, Mutual hfformation, and Lex~icography.
The 27th Annual Conference of th, e As-sociation of Computational Lin quistics.PascMe Fung.
1998.
Extracting Key Terms fl'omChinese and .lapmmse texts.
Th, e InternationalJournal on Computer P~vccssin9 of Oriental Lan-9~zagc, Special Issue on Information Retrieval onOriental Languages.Yuji Matsumoto, Akira Kitauchi, Tatsuo Ya-mashit:a, Yoshital~t tlirano, Osmnu hnaMfi,and Tomo~fld hnanmra.
1997.
Jat)mleseMorpholotical Analysis System ChaSen 1.51Manual.
'2bchnical report, Nara Institute ofS(:ience mid Technology.
http://cactus.aist-nara.a(:.jp/lab/nlt/chasen.litnfl.Makoto Nagao mid Shinsuke Mori.
1994.
A NewMethod of N-gram Statistics for Large, Number ofn m~d Automatic Extraction of Words and Phrasesfi'om Large Text Data of ,lapmlese.
Colin9-95,pages 611-615, August.Shiho Nobesawa, Junya Tsutsumi, Da Jiang Sun, ~\[~)-mohisa State, Kengo Sate, mM Masalmzu Nakan-ishi.
1996.
Segmenting Sentenc(',s into LinkyStrings Using D-bigram St:atistics.
Uolin9-96 ,t)ages 586 591, August;.Shiho Nobesawa, Itiroaki S~fito, and Mas~fl(azuNal(anishi.
1999.
String Extraction Based Onlyon SLatisl;ic Lint~tbilil.y.
IUCI)OL'99, pages 23-28, March.Iliroki Oda and Kenji Kita.
1999.
A Character-Based Japanese Word Segmenter Using a PPM*-B~use(t Language Model.
ICCPOL'99, pages 527-532, Mm'ch.Tomohisa Sane, Junya Tsutsmni, Da Jimlg Sun,Shiho Nobesawa, Kc, ngo Sate, Kumiko Omori,m~d Masal~/zu Nal~mishi.
1996.
An Experimenton Good Usages of D-bigram Statistics in Natu-ral Lmtguage Ev~fluation.
End Annual Meeting ofth, c ANLP (NLP96), pages 185-188.
Written illJapmw, se.r\]Smohisa Sane.
1997.
NaturM Language ProcessingUsing Dynmnie StatisticM Information.
Master'sthesis, Keio University.
\?ritten in Jal)anese.Junya Tsutsumi, Tomoaki Nitta, Notate One, m~dShiho Nobesawa.
1.993.
A Multi-Lingual Transla-tion System Based on A Statistical Model.
JSAI~chnical report, S}G-PPAI-9302-g pages 7 12.Written in Japanese.585
