Workshop on Humans and Computer-assisted Translation, pages 84?92,Gothenburg, Sweden, 26 April 2014.c?2014 Association for Computational LinguisticsOnline Word Alignment for Online Adaptive Machine TranslationM.
Amin FarajianFBK-irst,University of TrentoTrento, Italyfarajian@fbk.euNicola BertoldiFBK-irstTrento, Italybertoldi@fbk.euMarcello FedericoFBK-irstTrento, Italyfederico@fbk.euAbstractA hot task in the Computer AssistedTranslation scenario is the integration ofMachine Translation (MT) systems thatadapt sentence after sentence to the post-edits made by the translators.
A mainrole in the MT online adaptation process isplayed by the information extracted fromsource and post-edited sentences, whichin turn depends on the quality of theword alignment between them.
In fact,this step is particularly crucial when theuser corrects the MT output with wordsfor which the system has no prior infor-mation.
In this paper, we first discussthe application of popular state-of-the-artword aligners to this scenario and revealtheir poor performance in aligning un-known words.
Then, we propose a fastprocedure to refine their outputs and toget more reliable and accurate alignmentsfor unknown words.
We evaluate ourenhanced word-aligner on three languagepairs, namely English-Italian, English-French, and English-Spanish, showing aconsistent improvement in aligning un-known words up to 10% absolute F-measure.1 IntroductionIn the adaptive MT the goal is to let the MT systemtake as soon and as much as possible advantage ofuser feedback, in order to learn from correctionsand to hence avoid repeating the same mistakes infuture sentences.A typical application scenario is the usage bya professional translator of a Computer AssistedTranslation (CAT) tool enhanced with a SMT sys-tem.
For each input sentence, first the translatorreceives one or more translation suggestions fromeither a Translation Memory or a SMT system,then (s)he chooses which suggestion is more use-ful, and finally (s)he creates an approved transla-tion by post-editing.
The pair of input sentenceand post-edit is a valuable feedback to improve thequality of next suggestions.
While the sentencepair is trivially added to the Translation Memory,how to exploit it for improving the SMT system isfar to be a solved problem, but rather is a hot andquite recent topic in the MT community.In online MT adaptation specific issues have tobe addressed, which distinguish it from the morestandard and investigated task of domain adapta-tion.
First of all, the SMT system should adaptvery quickly, because the time between two con-secutive requests are usually short, and very pre-cisely, because the translator is annoyed by cor-recting the same error several time.
Then, a crucialpoint is which and how information is extractedfrom the feedback, and how it is exploited to up-date the SMT system.
Finally, model updating re-lies on a little feedback consisting of just one sen-tence pair.In this work we focus on the word alignmenttask which is the first and most important step inextracting information from the given source andits corresponding post-edit.
In particular, we areinterested in the cases where the given sentencepairs contain new words, for which no prior infor-mation is available.
This is an important and chal-lenging problem in the online scenario, in whichthe user interacts with the system and expects thatit learns from the previous corrections and doesnot repeat the same errors again and again.Unfortunately, state-of-the-art word-alignersshow poor generalization capability and are proneto errors when infrequent or new words occur inthe sentence pair.
Word alignment errors at thisstage could cause the extraction of wrong phrasepairs, i.e.
wrong translation alternatives, whichcan lead in producing wrong translations for those84words, if they appear in the following sentences.Our investigation focuses on how to quicklybuild a highly precise word alignment from asource sentence and its translation.
Moreover, weare interested in improving the word alignment ofunknown terms, i.e.
not present in the trainingdata, because they are one of the most importantsource of errors in model updating.Although we are working in the online MTadaptation framework, our proposal is worthwhileper se; indeed, having an improved and fast wordaligner can be useful for other interesting tasks,like for instance terminology extraction, transla-tion error detection, and pivot translation.In Section 2 we report on some recent ap-proaches aiming at improving word alignment.
InSection 3, we describe three widely used toolk-its, highlight their pros and cons in the onlineMT adaptation scenario, and compare their per-formance in aligning unknown terms.
In Section 4we propose a standalone module which refines theword alignment of unknown words; moreover, wepresent an enhanced faster implementation of thebest performing word aligner, to make it usable inthe online scenario.
In Section 5 we show exper-imental results of this module on three differentlanguages.
Finally, we draw some final commentsin Section 6.2 Related worksHardt et al.
(2010) presented an incremental re-training method which simulates the procedureof learning from post-edited MT outputs (refer-ences), in a real time fashion.
By dividing thelearning task into word alignment and phrase ex-traction tasks, and replacing the standard word-alignment module, which is a variation of EMalgorithm (Och and Ney, 2003), with a greedysearch algorithm, they attempt to find a quick ap-proximation of the word alignments of the newlytranslated sentence.
They also use some heuris-tics to improve the obtained alignments, withoutsupporting it with some proofs or even providingsome experimental results.
Furthermore, the run-ning time of this approach is not discussed, and itis not clear how effective this approach is in onlinescenarios.Blain et al.
(2012) have recently studied theproblem of incremental learning from post-editingdata, with minimum computational complexityand acceptable quality.
They use the MT out-put (hypothesis) as a pivot to find the word align-ments between the source sentence and its corre-sponding reference.
Similarly to (Hardt and Elm-ing, 2010), once the word alignment between thesource and post-edit sentence pair is generated,they use the standard phrase extraction methodto extract the parallel phrase pairs.
This workis based on an implicit assumption that MT out-put is reliable enough to make a bridge betweensource and reference.
However, in the real worldthis is not always true.
The post-editor sometimesmakes a lot of changes in the MT output, or eventranslates the entire sentence from scratch, whichmakes the post-edit very different from the auto-matic translation.
Moreover, in the presence ofnew words in the source sentence, the MT systemeither does not produce any translation for the newword, or directly copies it in the output.
Due tothe above two reasons, there will be missing align-ments between the automatic translation and post-edit, which ultimately results in incomplete pathsfrom source to post-edit.
But, the goal here is toaccurately align the known words, as well as learn-ing the alignments of the new words, which is notfeasible by this approach.In order to improve the quality of the wordalignments McCarley et al.
(2011) proposed atrainable correction model which given a sentencepair and their corresponding automatically pro-duced word alignment, it tries to fix the wrongalignment links.
Similar to the hill-climbing ap-proach used in IBM models 3-5 (Brown et al.,1993), this approach iteratively performs smallmodifications in each step, based on the changesof the previous step.
However, the use of addi-tional sources of knowledge, such as POS tags ofthe words and their neighbours, helps the systemto take more accurate decisions.
But, requiringmanual word alignments for learning the align-ment moves makes this approach only applicablefor a limited number of language pairs for whichmanual aligned gold references are available.Tomeh et al.
(2010) introduced a superviseddiscriminative word alignment model for produc-ing higher quality word alignments, which istrained on a manually aligned training corpus.
Toreduce the search space of the word aligner, theypropose to provide the system with a set of au-tomatic word alignments and consider the unionof these alignments as the possible search space.This transforms the word alignment process into85the alignment refinement task in which given a setof automatic word alignments, the system tries tofind the best word alignment points.
Similar to(McCarley et al., 2011), this approach relies on themanually annotated training corpora which is notavailable for most of the language pairs.3 Word AlignmentWord alignment is the task of finding the corre-spondence among the words of a sentence pair(Figure 1).
From a mathematical point of view,it is a relation among the words, because any wordin a sentence can be mapped into zero, one ormore words of the other, and vice-versa; in otherwords, any kind of link is allowed, namely one-to-one, many-to-one, many-to-many, as well as leav-ing words unaligned.
So called IBM models 1-5(Brown et al., 1993) as well as the HMM-basedalignment models (Vogel et al., 1996), and theirvariations are extensively studied and widely usedfor this task.
They are directional alignment mod-els, because permit only many-to-one links; butoften the alignments in the two opposite directionsare combined in a so-called symmetrized align-ment, which is obtained by intersection, union orother smart combination.Nowadays, word-aligners are mostly employedin an intermediate step of the training procedureof a SMT system; In this step, the training cor-pus is word aligned as a side effect of the es-timation of the alignment models by means ofthe Expectation-Maximization algorithm.
For thistask, they perform sufficiently well, because thetraining data are often very large, and the limitedamount of alignment errors do not have strong im-pact on the estimation of the translation model.Instead, the already trained word-aligners arerarely applied for aligning new sentence pairs.
Inthis task their performance are often not satisfac-tory, due to their poor generalization capability;they are especially prone to errors when infrequentor new words occur in the sentence pair.This is the actual task to be accomplished in theonline adaptive scenario: as soon as a new sourceand post-edited sentence pair is available, it hasto be word aligned quickly and precisely.
In thisscenario, the sentence pair likely does not belongto the training corpus, hence might contain infre-quent or new words, for which the aligner has littleor no prior information.3.1 Evaluation MeasuresA word aligner is usually evaluated in terms ofPrecision, Recall, and F-measure (or shortly F ),which are defined as follows (Fraser and Marcu,2007):Precision =|A?P ||A|, Recall =|A?S||S|F ?measure =1?Precision+1?
?Recallwhere A is the set of automatically computedalignments, and S and P refer to the sure (un-ambiguous) and possible (ambiguous) manualalignments; note that S ?
P .
In this paper, ?
isset to 0.5 for all the experiments, in order to havea balance between Precision and Recall.In this paper we are mainly interested how theword-aligner performs on the unknown words;hence, we define a version of Precision, Recall,and F metrics focused on the oov-alignment only,i.e.
the alignments for which either the source orthe target word is not included in the training cor-pus.
The subscript all identifies the standard met-rics; the subscript oov identifies their oov-basedversions.In Figure 1 we show manual and automaticword alignments between an English-Italian sen-tence pair.
A sure alignment, like are-sono, is rep-resented by a solid line, and a possible alignment,like than-ai, by a dash line.
An oov-alignment,like that linking the unknown English word de-ployable to the Italian word attivabili, is identi-fied by a dotted line.
According to this example,Precision and Recall will be about 0.85 (=11/13)and 0.91 (=10/11), respectively, and the corre-sponding F is hence about 0.88.
Focusing on theoov-alignment only, Precisionoovis 1.00 (=1/1),Recalloovis 0.50 (=1/2), and Foovis 0.67.3.2 Evaluation BenchmarkIn this paper, we compare word-alignment perfor-mance of three word-aligners introduced in Sec-tion 3.3 on three distinct tasks, namely English-Italian, English-French, and English-Spanish; thetraining corpora, common to all word-aligners, aresubset of the JRC-legal corpus1(Steinberger etal., ), of the Europarl corpus V7.0 (Koehn, 2005),and of the Hansard parallel corpus2, respectively.1langtech.jrc.it/JRC-Acquis.html2www.isi.edu/natural-language/download/hansard/index.html86financial assistance mechanisms are less rapidly deployable than conventional budgetary mechanismsi meccanismi diassistenza finanziaria sono attivabili meno rapidamente rispetto ai meccanismi bilancio convenzionalidifinancial assistance mechanisms are less rapidly deployable than conventional budgetary mechanismsi meccanismi diassistenza finanziaria sono attivabili meno rapidamente rispetto ai meccanismi bilancio convenzionalidiFigure 1: Example of manual (above) and automatic (below) word alignments between an English-Italiansentence pair.
Sure and possible alignments are identified by solid and dash lines, respectively, and theoov-alignments by a dotted line.
The OOV words, like deployable (English) and finanziaria (Italian), areprinted in italics.Statistics of the three training corpora are reportedin Table 1.En-It En-Fr En-EsSegments 940K 1.1M 713KTokenssrc19.8M 19.8M 19.8MTokenstrg20.3M 23.3M 20.4MTable 1: Statistics of the training corporafor English-Italian, English-French, and English-Spanish tasks.Three evaluation data sets are also available,which belong to the same domains of the cor-responding training corpora.
The English-Italiantest set was built by two professional translatorsby correcting an automatically produced word-alignment.
The English-French test set is the man-ually aligned parallel corpus introduced in (Ochand Ney, 2000)3.
The English-Spanish test set wasprovided by (Lambert et al., 2005)4.
Statistics ofthe three test sets are reported in Table 2.To have a better understanding of the behaviorof the word aligners on the unknown words, wecreated new test sets with an increasing ratio of theunknown words (oov-rate), for each task.
Startingfrom each of the original test set, we replaced anincreasing portion of randomly chosen words bystrings which do not exist in the training corpus;the oov-noise artificially introduced ranges from3www.cse.unt.edu/?rada/wpt/data/English-French.test.tar.gz4www.computing.dcu.ie/?plambert/data/epps-alignref.htmlEn-It En-Fr En-EsSegments 200 484 500Tokenssrc6,773 7,681 14,652Tokenstrg7,430 8,482 15,516oov-ratesrc0.90 0.27 0.35oov-ratetrg0.84 0.34 0.32#alignment 7,380 19,220 21,442Table 2: Staticts of the test corpora for English-Italian, English-French, and English-Spanishtasks.
oov-ratesrcand oov-ratetrgare the ratio ofthe new words in the source and target side of thetest corpus, respectively.1% to 50%.
For each value of the artificial oov-noise (m = 1, ..., 50), we randomly selected m%words in both the source and target side indepen-dently, and replaced them by artificially createdstrings.
For selecting the words to be replacedby artificially created strings, we do not differenti-ate between the known and unknown words; hencethe actual oov-rate in the test corpus, used in theplots, might be slightly larger.To further make sure that the random selectionof the words does not affect the systems, for eachoov-noise we created 10 different test corpora andreported the averaged results.
One might think ofother approaches for introducing oov-noise, suchas replacing singletons or low-frequency wordswhich have more potential to be unknown, insteadof randomly selection of the words.
But in this pa-per we decided to follow the random selection ofthe words.873.3 State-of-the-art Word AlignersWe consider three widely-used word aligners,namely berkeley, fast-align, and mgiza++.
Weanalyze their performance in aligning an held-outtest corpora; in particular, we compare their capa-bility in handling the unknown words.
For a faircomparison, all aligners are trained on the sametraining corpora described in Section 3.2.berkeley aligner (Liang et al., 2006) applies theco-training approach for training the IBM model1 and HMM.
We trained berkeley aligner using5 iterations of model 1 followed by 5 iterationsof HMM.
When applied to new sentence pairs,the system produces bi-directional symmetrizedalignment.fast-align is a recently developed unsuper-vised word aligner that uses a log-linear re-parametrization of IBM model 2 for training theword alignment models (Dyer et al., 2013).
Weexploited the default configuration with 5 itera-tions for training.
As the system is directional, wetrained two systems (source-to-target and target-to-source).
When applied to new sentence pairs,we first produced the two directional alignments,and then combined them into a symmetrized align-ment by using the grow-diag-final-and heuristic(Och and Ney, 2003).mgiza++ (Gao and Vogel, 2008) and its an-cestors, i.e.
giza, and giza++, implement all theIBM models and HMM based alignment models.mgiza++ is a multithreaded version of giza++,which enables an efficient use of multi-core plat-forms.
We trained the system using the follow-ing configuration for model iterations: 15h53343.mgiza++ also produces directional alignment;hence, we followed the same protocol to create asymmetrize alignment of sentence pairs as we didfor fast-align.Differently from berkeley and fast-align,mgiza++ somehow adapts its models whenapplied to new sentence pairs.
According tothe so-called ?forced alignment?, it essentiallyproceeds with the training procedure on thesenew data starting from pre-trained and pre-loadedmodels, and produces the alignment as a by-product.
In preliminary experiments, we observedthat performing 3 iterations of model 4 is thebest configuration for mgiza++ to align the newsentence pairs.These word aligners are designed to work in of-fline mode; they load the models and align thewhole set of available input data in one shot.
How-ever, in the online scenario where a single sen-tence pair is provided at a time, they need to reloadthe models every time which is very expensive interms of I/O operations.
In this paper we firstwere interested in measuring the quality of theword aligners to select the best one.
Therefore,we mimic the online modality by forcing them toalign one sentence pair at a time.Precision Recall F-measureall oov all oov all oovEnglish-Italianfast-align 82.6 33.3 82.8 19.6 82.7 24.7berkeley 91.9 ?
81.0 ?
86.1 ?mgiza++ 86.2 84.6 89.4 30.8 87.8 45.2English-Frenchfast-align 81.5 47.2 91.8 19.5 86.3 27.6berkeley 87.9 ?
92.9 ?
90.3 ?mgiza++ 89.0 88.2 96.0 17.2 92.4 28.8English-Spanishfast-align 81.5 31.3 71.8 12.7 76.3 18.1berkeley 88.7 ?
71.2 ?
79.0 ?mgiza++ 89.2 95.5 80.6 35.6 84.7 51.9Table 3: Comparison of different widely-usedword aligners in terms of precision, recall, and F-measure on English-Italian, English-French, andEnglish-Spanish language pairs.
Columns all re-port the evaluation performed on all alignments,while columns oov the evaluation performed onthe oov-alignments.The three word aligners were evaluated on thethree tasks introduced in Section 3.2.
Table 3shows their performance on the full set of align-ments (all) and on the subset of oov-alignments(oov) in terms of Precision, Recall, and F-measure.The figures show that all aligners perform well onthe whole test corpus.
mgiza++ is definitely su-perior to fast-align; it also outperforms berkeleyin terms of F-measure, but they are comparable interms of Precision.Unfortunately, the quality of the word align-ments produced for the new words is quite poor forall systems.
mgiza++ outperforms the other align-ers in all the language pairs on oov-alignments,and in particular it achieves a very high preci-sion.
On the contrary, berkeley aligner always failsto detect out-of-vocabulary words; its precision ishence undefined, and consequently its F-measure.To our knowledge of the system, this behavior isexpected because of the joint alignment approachused in berkeley which produces an alignment be-tween two terms if both the directional models8830 4050 6070 80901  2  4  8  16  32F-measureOOV rateEnglish-Italianmgizaberkeleyfast-align  30 4050 6070 80900.5  1  2  4  8  16  32F-measureOOV rateEnglish-Frenchmgizaberkeleyfast-align  30 4050 6070 80900.5  1  2  4  8  16  32F-measureOOV rateEnglish-Spanishmgizaberkeleyfast-align10 15 2025 30 3540 45 501  2  4  8  16  32F-measure-oovOOV rateEnglish-Italianmgizafast-align10 15 2025 30 3540 45 500.5  1  2  4  8  16  32F-measure-oovOOV rateEnglish-Frenchmgizafast-align10 15 2025 30 3540 45 500.5  1  2  4  8  16  32F-measure-oovOOV rateEnglish-Spanishmgizafast-alignFigure 2: Performance in terms of standard F-measure (above) and oov-based F-measure (below) of theword aligners on test sets with increasing oov-rate, for all language pairs.
The oov-based F-measure forberkeley is not reported because it is undefined.agree, and this hardly occurs for unknown words.To further investigate the behavior of the wordaligners on the unknown words, we evaluated theirperformance on the artificially created test sets,described in Section 3.2.
The performance of theword aligners in terms of standard and oov-basedF-measure is shown in Figure 2.
As expected, theoverall F-measure decreases by introducing un-known words.
mgiza++ is more accurate than theother aligners up to oov-rate of 16%.We observe that mgiza++ outperforms the oth-ers in terms of the oov-based F-measure onthe English-Italian and English-Spanish languagepairs up to oov-noise of 32% and 16%, respec-tively.
fast-align instead performs better in theEnglish-French task.
fast-align always show abetter quality when the oov-rate is very high.oov-based F-measure is not reported for berke-ley because this aligner is not able to detect oov-alignments as explained above.4 Enhancement to Word Alignment4.1 Refinement of oov-alignmentsTo address the problem of unaligned new words,we present a novel approach, in which the wordalignments of the source and target segment pairare induced in two-steps.
First, a standard wordaligner is applied; most of the words in the sourceand target sentence pair will be aligned, but mostof the unknown words will not.
It is worth men-tioning that aligning unknown words in this stepdepends on the quality of the employed wordaligner.
Once the alignments are computed andsymmetrized (if required), phrase extraction pro-cedure is applied to extract all valid phrase-pairs.Note that un-aligned words are included in the ex-tracted phrase pairs, if their surrounding words arealigned.It has been shown that inclusion of un-alignedwords in the phrase-pairs, generally, has neg-ative effects on the translation quality and canproduce errors in the translation output (Zhanget al., 2009).
Nevertheless, the overlap amongphrase-pairs, which contain un-aligned unknownwords, can be considered as a valuable sourceof knowledge for inducing the correct alignmentof these words.
To get their alignments fromthe extracted phrase-pairs we follow an approachsimilar to (Espl?a-Gomis et al., 2012) in whichthe word alignment probabilities are determinedby the alignment strength measure.
Given thesource and target segments (S = {s1, .
.
.
, sl}and T = {t1, .
.
.
, sm}), and the set of extractedparallel phrase-pairs (?
), the alignment strengthAi,j(S, T,?)
of the siand tjcan be calculated asfollows:Ai,j(S, T,?)
=?(?,?)?
?cover(i, j, ?, ?)|?|.|?
|cover(i, j, ?, ?)
={1 if si?
?
and tj?
?0 otherwisewhere |?| and |?
| are the source and targetlengths (in words) of the phrase pair (?, ?
).89cover(i, j, ?, ?)
simply spots whether the word-pair (si, tj) is covered by the phrase pair (?, ?
).The alignment strengths are then used to pro-duce the a directional source-to-target word align-ments; siis aligned to tjif Ai,j> 0 and Ai,j?Ai,k, ?k ?
[1, |T |].
One-to-many alignment isallowed in cases that multiple target words haveequal probabilities to be aligned to i-th sourceword (Ai,j= Ai,k).
The directional word align-ments are then symmetrized.The new set of symmetrized alignments can beused in different ways: (i) as a replacement of theinitial word alignments as in (Espl?a-Gomis et al.,2012), or (ii) as additional alignment points to beadded to the initial set.
According to a prelim-inary investigation, we choose the latter option:only a subset of the new word alignments is usedfor updating the initial alignments.
More specifi-cally, we add only the alignments of the new wordswhich are not already aligned.Moreover, our approach differs from that pro-posed by Espl?a-Gomis et al.
(2012) in the proce-dure to collect the original set of phrase pairs fromthe source and target sentence pair.
They rely onthe external sources of information such as onlinemachine translation systems (e.g.
Google Trans-late, and Microsoft Translator).
Communicatingwith external MT systems imposes some delaysto the pipeline, which is not desired for the on-line scenario.
Furthermore, the words that are notknown by the machine translation systems are notcovered by any phrase-pair, hence the refinementmodule is not able to align them.We instead employ the phrase-extract software5provided by the Moses toolkit, which relies on thealignment information of the given sentence pair,and allows the inclusion of un-aligned unknownwords in the extracted phrase pairs; hence, the re-finement module has the potential to find the cor-rect alignment for those words.Note that there is no constraint on the wordalignment and phrase extraction modules used inthe first step, hence, any word aligner and phraseextractor can be used for computing the initialalignments and extracting the parallel phrase pairsfrom the given sentence pairs.
But, since the out-puts of the first aligner make the ground for obtain-ing the alignments of the second level, they needto be highly accurate and precise.5The ?grow-diag-final-and?
heuristic was set for the sym-metrization.4.2 onlineMgiza++The experiments to compare state-of-the-art wordaligners, reported and discussed in Section 3, arecarried out offline.
This is because the aforemen-tioned word aligners are not designed to work on-line, and need to load the models every time re-ceives a new sentence pair.
Loading the models isvery time consuming, and depending on the sizeof the models might take several minutes, whichis not desired for the online scenario.To overcome this problem, we decided to im-plement an online version of mgiza++ whichprovides the best performance as shown in Sec-tion 3.3.
This new version, called onlineM-giza++, works in client-server mode.
It con-sists of two main modules mgizaServer and mgiza-Client.
mgizaServer is responsible for computingthe alignment of the given sentence pairs.
To avoidunnecessary I/O operations, mgizaServer loads allthe required models once at the beginning of thealignment session, and releases them at the end.mgizaClient communicates with the client appli-cations through the standard I/O channel.In our final experiments we observed someunexpected differences between the results ofmgiza++ and onlineMgiza++.
Therefore, we donot present the results of onlineMgiza++ in thispaper.
However, we expect the two systems pro-duce the same results.5 Experimental ResultsIn this section we evaluate the effectiveness ofthe proposed refinement module.
Each consid-ered word aligner was equipped by our refinementmodule, and compared to its corresponding base-line.
Figure 3 shows the oov-based F-measureachieved by the baseline and enhanced word align-ers on all test sets and all tasks.
We observe thatthe refinement module consistently improves theF-measure of all aligners on all language pairs;The improvement for mgiza++ are big (up to10%) for very low oov-rates and decreases whenthe oov-rate increases; the same but smaller be-havior is observed for fast-align.
This is due to thefact that by inserting more oov words into the testsets the systems are able to produce less accuratealignment points, which leads in lower contextualinformation (i.e.
smaller number of overlappingphrase-pairs) for aligning the unknown words.
In-terestingly, the refinement module applied to theberkeley output permits the correct detection of900 10 2030 40 5060 70 801  2  4  8  16  32F-measure-oovOOV rateEnglish-Italianmgiza + enhberkeley + enhfast-align + enhmgizafast-align0 10 2030 40 5060 70 800.5  1  2  4  8  16  32F-measure-oovOOV rateEnglish-Frenchmgiza + enhberkeley + enhfast-align + enhmgizafast-align0 10 2030 40 5060 70 800.5  1  2  4  8  16  32F-measure-oovOOV rateEnglish-Spanishmgiza + enhberkeley + enhfast-align + enhmgizafast-alignFigure 3: Performance in terms of oov-based F-measure of the baseline and enhanced word aligners ontest sets with increasing oov rate, for all language pairs.
The oov-based F-measure for berkeley is notreported because it is undefined.0 0.51 1.521  2  4  8  16  32DeltaF-measureOOV rateEnglish-Italianmgiza + enhberkeley + enhfast-align + enh0 0.51 1.520.5  1  2  4  8  16  32DeltaF-measureOOV rateEnglish-Frenchmgiza + enhberkeley + enhfast-align + enh0 0.51 1.520.5  1  2  4  8  16  32DeltaF-measureOOV rateEnglish-Spanishmgiza + enhberkeley + enhfast-align + enhFigure 4: Difference of performance in terms of standard F-measure of the enhanced word aligners fromtheir corresponding baselines on test sets with increasing OOV rate, for all language pairs.many oov-alignments, which the baseline systemcan not find most of them.Furthermore, Figure 4 reports the F-measuredifferences achieved by the enhanced word-aligners from their corresponding baselines on thefull data sets.
The refinement module slightlybut consistently improves the overall F-measure aswell, especially for high oov-rates.
The highestimprovement is achieved by the enhanced berke-ley aligner, mainly because its baseline performsworse in this condition.6 ConclusionIn this paper we discussed the need of having a fastand reliable online word aligner in the online adap-tive MT scenario that is able to accurately alignthe new words.
The quality of three state-of-the-art word aligners, namely berkeley, mgiza++, andfast-align, were evaluated on this task in terms ofPrecision, Recall, and F-measure.
For this purposewe created a benchmark in which an increasingamount of the words of the test corpus are ran-domly replaced by new words in order to augmentthe oov-rate.
The results show that the quality ofthe aligners on new words is quite low, and sug-gest that new models are required to effectively ad-dress this task.
As a first step, we proposed a fastand language independent procedure for aligningthe unknown words which refines any given au-tomatic word alignment.
The results show thatthe proposed approach significantly increases theword alignment quality of the new words.In future we plan to evaluate our approach in anend-to-end evaluation to measure its effect on thefinal translation.
We also plan to investigate theexploitation of additional features such as linguis-tic and syntactic information in order to furtherimprove the quality of the word alignment mod-els as well as the proposed refinement procedure.However, this requires other policies of introduc-ing new words, rather than just randomly selectingthe words and replacing them by artificial strings.AcknowledgmentsThis work was supported by the MateCat project,which is funded by the EC under the 7thFrame-work Programme.ReferencesF.
Blain, H. Schwenk, and J. Senellart.
2012.
In-cremental adaptation using translation informationand post-editing analysis.
In International Work-shop on Spoken Language Translation, pages 234?241, Hong-Kong (China).Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
The91mathematics of statistical machine translation: Pa-rameter estimation.
Computational Linguistics,19(2):263?312.Chris Dyer, Victor Chahuneau, and Noah A. Smith.2013.
A simple, fast, and effective reparameteriza-tion of ibm model 2.
In Proceedings of the 2013Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 644?648, Atlanta,Georgia, June.
Association for Computational Lin-guistics.Miquel Espl?a-Gomis, Felipe S?anchez-Mart?
?nez, andMikel L. Forcada.
2012.
A simple approach to usebilingual information sources for word alignment.Procesamiento del Lenguaje Natural, (49):93?100.Alexander Fraser and Daniel Marcu.
2007.
Measuringword alignment quality for statistical machine trans-lation.
Comput.
Linguist., 33(3):293?303.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, SETQA-NLP ?08, pages 49?57, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Daniel Hardt and Jakob Elming.
2010.
Incrementalre-training for post-editing smt.
In 9th Conferenceof the Association for Machine Translation in theAmericas (AMTA), Denver, United States.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of theTenth Machine Translation Summit (MT Summit X),pages 79?86, Phuket, Thailand.Patrik Lambert, Adri`a de Gispert, Rafael E. Banchs,and Jos?e B. Mari?no.
2005.
Guidelines for wordalignment evaluation and manual alignment.
Lan-guage Resources and Evaluation, 39(4):267?285.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreent.
In Proceedings of the Human Lan-guage Technology Conference of the NAACL, MainConference, pages 104?111, New York City, USA,June.
Association for Computational Linguistics.J.
Scott McCarley, Abraham Ittycheriah, SalimRoukos, Bing Xiang, and Jian-ming Xu.
2011.
Acorrection model for word alignments.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing, EMNLP ?11, pages 889?898, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Franz Josef Och and Hermann Ney.
2000.
Improvedstatistical alignment models.
In Proceedings of the38th Annual Meeting of the Association of Compu-tational Linguistics (ACL).F.J.
Och and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional Linguistics, 29(1):19?51.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Toma?z Erjavec, Dan Tufis?, andD?aniel Varga.
The jrc-acquis: A multilingualaligned parallel corpus with 20+ languages.
In InProceedings of the 5th International Conference onLanguage Resources and Evaluation (LREC), pages2142?2147, Genoa, Italy.Nadi Tomeh, Alexandre Allauzen, Guillaume Wis-niewski, and Franois Yvon.
2010.
Refining wordalignment with discriminative training.
In Proceed-ings of the ninth Conference of the Association forMachine Translation in the America (AMTA).S.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM-basedword alignment in statistical translation.
In Pro-ceedings of COLING, pages 836?841, Copenhagen,Denmark.Yuqi Zhang, Evgeny Matusov, and Hermann Ney.2009.
Are unaligned words important for machinetranslation?
In Conference of the European As-sociation for Machine Translation, pages 226?233,Barcelona, Spain.92
