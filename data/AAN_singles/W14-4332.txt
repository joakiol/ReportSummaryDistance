Proceedings of the SIGDIAL 2014 Conference, pages 243?250,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsUsing Ellipsis Detection and Word Similarity for Transformation ofSpoken Language into Grammatically Valid SentencesManuel Giulianifortiss GmbHMunich, Germanygiuliani@fortiss.orgThomas Marschallfortiss GmbHMunich, Germanymarschat@in.tum.deAmy IsardUniversity of EdinburghEdinburgh, UKamyi@inf.ed.ac.ukAbstractWhen humans speak they often use gram-matically incorrect sentences, which is aproblem for grammar-based language pro-cessing methods, since they expect in-put that is valid for the grammar.
Wepresent two methods to transform spokenlanguage into grammatically correct sen-tences.
The first is an algorithm for au-tomatic ellipsis detection, which finds el-lipses in spoken sentences and searchesin a combinatory categorial grammar forsuitable words to fill the ellipses.
The sec-ond method is an algorithm that computesthe semantic similarity of two words us-ing WordNet, which we use to find alter-natives to words that are unknown to thegrammar.
In an evaluation, we show thatthe usage of these two methods leads toan increase of 38.64% more parseable sen-tences on a test set of spoken sentencesthat were collected during a human-robotinteraction experiment.1 IntroductionComputer systems that are designed to interactverbally with humans need to be able to recog-nise and understand human speech.
In this pa-per we use as an example the robot bartenderJAMES (Joint Action for Multimodal EmbodiedSocial Systems),1shown in Figure 1.
The robotis able to take drink orders from customers and toserve drinks.
It is equipped with automatic speechrecognition, to understand what the human is say-ing, and it has a grammar, to parse and process thespoken utterances.The JAMES robot grammar was initially veryrestricted, and therefore during grammar devel-opment as well as during the user studies that1http://www.james-project.euFigure 1: The robot bartender of the JAMESproject interacting with a customer.we conducted (Foster et al., 2012; Giuliani et al.,2013; Keizer et al., 2013), we experienced situa-tions in which the robot was not able to processthe spoken input by humans, because they spokesentences with grammatical structures that couldnot be parsed by the grammar, they used wordsthat were not part of the grammar, or they left outwords.
We had for example cases where humansapproached the robot and used a sentence with anellipsis (?I want Coke?, but the grammar expecteda determiner in front of ?Coke?)
or a sentence witha word that was unknown to the grammar (?I needa water?, but ?need?
was not part of the gram-mar?s word list).
In these cases, the robot was un-able to process and to respond to the spoken ut-terance by the human.
Of course, these shortcom-ings can be overcome by extending the grammar,but even with a much more sophisticated grammarthere will always be instances of unexpected lan-guage, and we believe that our approach can bevery useful in extending the coverage of a gram-mar during testing or user studies.Therefore, we present an approach to transformunparseable spoken language into sentences that agiven grammar can parse.
For ellipsis detection,243we present in Section 3.1 a novel algorithm thatsearches for ellipses in a sentence and computescandidate words to fill the ellipsis with words froma grammar.
In Section 3.2, we show how we useWordNet (Miller, 1995) to find replacements forwords that are not in the robot?s grammar.
In Sec-tion 4 we evaluate our approach with a test setof 211 spoken utterances that were recorded ina human-robot interaction (HRI) experiment, andthe grammar for processing used in the same ex-periment.2 Related WorkThe work described in this paper draws on re-search and techniques from three main areas: theautomatic detection of ellipses in sentences, cal-culation of semantic similarity between two wordsusing WordNet, and spoken language processing.This section provides a summary of relevant workin these areas.2.1 Ellipsis DetectionThere is a wide range of research in ellipsis de-tection in written language, where different typesof ellipses are widely defined, such as gapping,stripping or verb phrase ellipsis (Lappin, 1996).For example, an ellipsis occurs when a redundantword is left out of succeeding sentences, such asthe words ?want to have?
in the sentence ?I wantto have a water, and my friend a juice?, which areomitted in the second part of the sentence.The detection of verb phrase ellipses (VPE)is a subfield of ellipsis detection that has re-ceived much attention.
For VPE detection, re-searchers have used machine learning algorithmswhich were trained on grammar-parsed corpora,for example in the works of Hardt (1997), Nielsen(2004a), Nielsen (2004b), and Smith and Rauchas(2006).
Other approaches for ellipsis detectionrely on symbolic processing of sentences, which issimilar to our work.
Haddar and Hamadou (1998)present a method for ellipsis detection in the Ara-bic language, which is based on an augmentedtransition network grammar.
Egg and Erk (2001)present a general approach for ellipsis detectionand resolution that uses a language for partial de-scription of ?-terms called Constraint Languagefor Lambda Structures.2.2 WordNet-based Semantic SimilarityCalculationWordNet is used in many varied natural languageprocessing applications, such as word sense dis-ambiguation, determining the structure of texts,text summarisation and annotation, informationextraction and retrieval, automatic indexing, lexi-cal selection, and the automatic correction of worderrors in text.
In our work, we use WordNetto find similar or synonym words.
In previouswork, researchers have proposed several methodsto generally compute the semantic relatedness oftwo words using WordNet.
Budanitsky and Hirst(2006) review methods to determine semantic re-latedness.
Newer examples for WordNet-basedcalculation of semantic similarity are the worksby Qin et al.
(2009), Cai et al.
(2010), Liu et al.
(2012), and Wagh and Kolhe (2012).2.3 Spoken Language ProcessingOur work addresses the processing of spoken lan-guage, which differs from the processing of writ-ten language in that spoken language is more of-ten elliptical and grammatically incorrect.
Previ-ous work in this area has attempted to address thisissue at different levels of processing.
Issar andWard (1993) presented the CMU speech process-ing system that supports recognition for grammat-ically ill-formed sentences.
Lavie (1996) presentsGLR*, a grammar-based parser for spoken lan-guage, which ignores unparseable words and sen-tence parts and instead looks for the maximal sub-set of an input sentence that is covered by thegrammar.Other researchers in this area have designedgrammar-based approaches for incremental spo-ken language processing: Brick and Scheutz(2007) present RISE, the robotic incremental se-mantic engine.
RISE is able to process syntacticand semantic information incrementally and to in-tegrate this information with perceptual and lin-guistic information.
Kruijff et al.
(2007) presentan approach for incremental processing of situ-ated dialogue in human-robot interaction, whichmaintains parallel interpretations of the current di-alogue that are pruned by making use of the con-text information.
Schlangen and Skantze (2009)describe a ?general, abstract model of incrementaldialogue processing?, where their goal is to pro-vide principles for designing new systems for in-cremental speech processing.2443 ApproachOur goal in this paper is to transform spoken utter-ances which cannot be parsed by our grammar intogrammar-valid sentences.
During this process, wehave to make sure that the changes to the inputsentence do not change its meaning.
In this sec-tion, we show how we implement ellipsis detec-tion and semantic similarity computation in orderto achieve this goal.
We present our ellipsis detec-tion algorithm in Section 3.1.
Section 3.2 explainsour implementation of WordNet-based word simi-larity computation.3.1 Ellipsis Detection AlgorithmWe use the OpenCCG parser (White, 2006), whichis based on Combinatory Categorial Grammar(Kruijff and Baldridge, 2004; Steedman, 2000), toparse the output of our speech recognition system.We use the properties of CCGs to solve a prob-lem that often occurs during parsing of spoken lan-guage.
In our evaluation (Section 4) we use a testset (Section 4.1) of spoken sentences that was col-lected during one of our human-robot interactionstudies (Foster et al., 2012) and the CCG (Sec-tion 4.2) that was used in the same study.
In thetest set, we found that speakers leave out words.For example, one speaker said I want water toorder a drink.
The grammar used in the experi-ment assumed that every noun is specified by anarticle; the grammar was only able to parse thesentence I want a water .
Just to remind you,of course this particular example could have beensolved by rewriting the grammar, but at the timeof running the experiment it was not possible tous to change the grammar.
Furthermore, we arguethat there will always be examples of the abovedescribed situation where experiment participantsuse grammatical structures or words that cannot beprocessed by the used grammar.
Thus, we presentan algorithm that automatically finds ellipses insentences and suggests words from the grammarthat could be used to fill the ellipses.To illustrate our approach, we will use the ex-ample sentence give me a water .
Example (1)shows the words of the example sentence withtheir assigned categories from the used CCG, andExample (2) shows the parsed sentence.
In the ex-amples, we use the category symbols s for sen-tence, n for noun, and np for noun phrase.
In Ex-ample (2) the symbol> denotes the used CCG for-ward application combinator.
(1) CCG lexicon entriesa.
give := s / np / npb.
me := npc.
a := np / nd.
water := n(2) Full parse of an example sentencegive me a waters/np/np np np/n n>np>s/np>sThe algorithm consists of two parts: (i) searchfor ellipses in the sentence and selection of themost relevant ellipsis, and (ii) computation of thecategory for the word that will fill the chosen el-lipsis.
(i) Ellipsis SearchIn order to find the ellipsis in the sentence, our al-gorithm assumes that to the left and to the right ofthe ellipsis, the spoken utterance consists of sen-tence parts that the grammar can parse.
In our ex-ample, these sentence parts would be I want to theleft of the ellipsis and water to the right.
In orderto automatically find the sentence part to the right,we use the following algorithm, which we presentin Listing 1 in a Java-style pseudo code: The al-gorithm uses the method tokenize() to split up thestring that contains the utterance into an array ofsingle words.
It then iterates through the array andbuilds a new sentence of the words in the array,using the method buildString().
This sentence isthen processed by the parser.
If the parser findsa parse for the sentence, the algorithm returns theresult.
Otherwise it cuts off the first word of thesentence and repeats the procedure.
This way, thealgorithm searches for a parseable sentence partfor the given utterance from the left to the right un-til it either finds the right-most parseable sentencepart or there are no more words to parse.
In orderto find the left-most parseable sentence part, weimplemented a method findParseReverse(), whichparses sentence parts from right to left.One has to consider that our method for ellip-sis detection can falsely identify ellipses in cer-tain sentence constellations.
For example, if theword like in the sentence I would like a wateris left out and given to our ellipsis detection al-gorithm, it would falsely find an ellipsis betweenI and would , and another ellipsis between would245Listing 1: Ellipsis detection algorithm.R e s u l t f i n d P a r s e ( S t r i n g u t t e r a n c e ) {words [ ] = t o k e n i z e ( u t t e r a n c e ) ;f o r ( i = 0 ; i < words .
l e n g t h ; i ++) {S t r i n g s e n t e n c e = b u i l d S t r i n g ( words [i ] , words .
l e n g t h ) ;R e s u l t p a r s e = p a r s e ( s e n t e n c e ) ;i f ( p a r s e != nu l l ) {re turn p a r s e ;}}re turn nu l l ;}and a.
The reason for the detection of the firstellipsis is that the categories for I and would can-not be combined together.
would and like have tobe parsed first to an auxiliary verb-verb construct.This construct can then be combined with the pro-noun I.
To overcome this problem, we first com-pute the category for each found ellipsis.
Then wefind a word for the ellipsis with the simplest cate-gory, which is either an atomic category or a func-tional category with fewer functors than the otherfound categories, add it to the original input sen-tence, and parse the output sentence.
If the outputsentence cannot be parsed, we repeat the step withthe next found ellipsis.
(ii) Ellipsis Category ComputationAfter the algorithm has determined the ellipsis inan utterance, it computes the category of the wordthat will fill the ellipsis.
The goal here is to find acategory which the grammar needs to combine thesentence parts to the left and right of the ellipsis.For example, the left part of our example utteranceI want has the category s/np and the right part wa-ter has the category n. Hence, the category for themissing word needs to be np/n, because it takesthe category of the right sentence part as argumentand produces the category np, which is the argu-ment of the category of the left sentence part.Figure 2 shows the processing sequence dia-gram of our algorithm for computing the categoryof an ellipsis.
In the diagram, left and right standfor the categories of the sentence parts that are tothe left and right of the ellipsis.
The predicatessymbolise functions: isEmpty(category) checksif a category is empty, atom(category) checksif a category is atomic, compl(category) checksif a category is complex and has a slash oper-ator that faces toward the ellipsis.
The predi-cate arg(category) returns the argument of a com-s / righttrueisEmpty(left) isEmpty(right)falses \ lefttrueatom(left)atom(right)s / right \ leftcompl(left)compl(right)falsefalsetruetrueatom(left)compl(right)left \ arg(right)falsetrueatom(right)compl(left)arg(left) / righttruefalseFigure 2: Processing sequence of the categorycomputation algorithm.plex category.
Rectangular boxes symbolise stepswhere the algorithm builds the result category forthe missing word.
The algorithm determines thecategory with the following rules:?
if the categories to the left or to the right ofthe ellipsis are empty, the ellipsis category iss/right or s\left, respectively,?
if the categories to the right and to the left ofthe ellipsis are atomic, the ellipsis category iss/right\left,?
if the categories to the right and to the leftof the ellipsis are both complex and have aslash operator facing toward the ellipsis, theellipsis category is s/right\left,?
if the category to the left of the ellipsis isatomic and to the right of the ellipsis is com-plex, the ellipsis category is left\arg(right),?
if the category to the right of the ellipsis isatomic and to the left of the ellipsis is com-plex, the ellipsis category is arg(left)\right.After the computation of the ellipsis category,we use the OpenCCG grammar to select words tofill the ellipsis.
This step is straightforward, be-cause the grammar maintains a separate word listwith corresponding categories.
Here, we benefitfrom the usage of a categorial grammar, as theusage of a top-down grammar formalism wouldhave meant a more complicated computation inthis step.3.2 WordNet-based Word SubstitutionSpoken language is versatile and there are manyways to express one?s intentions by using differ-246ent expressions.
Thus, in grammar-based spo-ken language processing it often happens that sen-tences cannot be parsed because of words thatare not in the grammar.
To overcome this prob-lem, we use WordNet (Miller, 1995) to find se-mantically equivalent replacements for unknownwords.
WordNet arranges words in sets of syn-onyms called synsets which are connected to othersynsets by a variety of relations, which differ foreach word category.
The most relevant relationsfor our work are: for nouns and verbs hyperonyms(e.g., drink is a hyperonym of juice) and hyponyms(e.g., juice is a hyponym of drink), and for adjec-tives we use the similar to relation.Our implementation of word substitution exe-cutes two steps if a word is unknown to the gram-mar: (1) look-up of synonyms for the unknownwords.
The unknown word can be substituted witha semantically similar word directly, if the synsetof the unknown word contains a word, which isknown to the grammar.
(2) Computation of simi-lar words in the WordNet hyperonym/hyponym hi-erarchy.
If the synset of the unknown word doesnot contain a substitution, we compute if one ofthe hyperonyms of the unknown word has a hy-ponym which is known to the grammar.
Here, onehas to be careful not to move too far away fromthe meaning of the unknown word in the Word-Net tree, in order not to change the meaning ofthe originally spoken sentence.
Also, the compu-tation of the similar word should not take too muchtime.
Therefore, in our implementation, we onlysubstitute an unknown word with one of its hyper-onym/hyponym neighbours when the substitutioncandidate is a direct hyponym of the direct hyper-onym of the unknown word.4 EvaluationThe goal of this evaluation is to measure howmany spoken sentences that our grammar cannotparse can be processed after the transformation ofthe sentences with our methods.
In Section 4.1we present the test set of spoken sentences that weused in the evaluation.
In Section 4.2 we give de-tails of the used grammar.
As mentioned above,both, the test set as well as the grammar, weretaken from the human-robot interaction study re-ported by Foster et al.
(2012).
Section 4.3 sum-marises the details of the evaluation procedure.
Fi-nally, we present the evaluation results in Section4.4 and discuss their meaning in Section 4.5.4.1 Test SetAs test set for the evaluation, we used the spo-ken utterances from the participants of the human-robot interaction experiment reported by Foster etal.
(2012).
In the experiment, 31 participants wereasked to order a drink from the robot bartendershown in Figure 1.
The experiment consisted ofthree parts: in the first part, participants had to or-der drinks on their own, in the second and thirdpart, participants were accompanied by a confed-erate in order to have a multi-party interaction withthe robot.
The spoken utterances in the test setwere annotated by hand from video recordings ofthe 93 drink order sequences.
Please refer to (Fos-ter et al., 2012) for a detailed description of theexperiment.Table 1 shows an overview of the test set.
Intotal, it contains 211 unique utterances; the exper-iment participants spoke 531 sentences of whichsome sentences were said repeatedly.
We di-vided the test set into the following speech acts(Searle, 1965): Ordering (?I would like a juiceplease.?
), Question (?What do you have??
), Greet-ing (?Hello there.?
), Polite expression (?Thankyou.?
), Confirmation (?Yes.?
), Other (?I amthirsty.?
).4.2 GrammarThe grammar that we used in this evaluation wasalso used in the robot bartender experiment (Fos-ter et al., 2012).
This grammar is limited in itsscope, because the domain of the experiment?therobot hands out drinks to customers?was limitedas well.
Overall, the lexicon of the grammar con-tains 92 words, which are divided into the follow-ing part of speech classes: 42 verbs, 11 nouns, 10greetings, 6 pronouns, 5 prepositions, 4 adverbs, 4determiners, 3 quantifiers, 3 confirmations, 2 rela-tive pronouns, 1 conjunction, 1 polite expression.4.3 ProcedureFor the evaluation, we implemented a programmethat takes our test set and automatically parseseach sentence with four different settings, whichare also presented in Table 1: (1) parsing withthe grammar only, (2) application of ellipsis de-tection and word filling before parsing, (3) appli-cation of WordNet similarity substitution beforeparsing, (4) application of a combination of bothmethods before parsing.
Please note that for al-ternative (4) the sequence in which the methods247Speech act No.
utt (1) CCG (2) Ell.
det.
(3) WordNet (4) Ell.
+ WordNetOrdering 143 34 16 - 1Question 19 1 - - -Greeting 18 4 1 - -Polite expression 14 1 - - -Confirmation 5 4 - - -Other 12 - - - -Total 211 44 17 - 1Table 1: Overview for test set and evaluation.
Column No.
utt contains the number of test utterancesper speech act.
Column (1) CCG shows the number of utterances that were directly parsed by thegrammar.
Columns (2) Ell.
det., (3) WordNet, and (4) Ell.
+ WordNet show how many utterances wereadditionally parsed using the ellipsis detection , WordNet substitution, and combination of both modules.are applied to a given sentence can make a differ-ence to the parsing result.
In this evaluation, weused both possible sequences: first ellipsis detec-tion followed by WordNet substitution method orvice versa.4.4 ResultsTable 1 shows the result of the evaluation proce-dure.
The grammar parses 44 sentences of the211 test set sentences correctly.
By using the el-lipsis detection algorithm, 17 additional sentencesare parsed.
The usage of the WordNet substitutionalgorithm yields no additionally parsed sentences.The combination of both methods (in this case,first ellipsis detection, then WordNet substitution)leads to the correct parse of one additional sen-tence.
None of the transformed sentences changedits meaning when compared to the original sen-tence.4.5 DiscussionThe evaluation results show that the applicationof our ellipsis detection algorithm leads to an in-crease of successfully parsed sentences of 38.64%.In the class of ordering sentences, which was themost relevant for the human-robot interaction ex-periment from which we used the evaluation testset, the number of successfully parsed sentencesincreases by 47.06%.
Compared to this, the us-age of WordNet substitution alone does not lead toan increase in parseable sentences.
The one casein which the combination of ellipsis detection andWordNet substitution transformed an unparseablesentence into a grammatically valid sentence is in-teresting: here, the experiment participant said ?Ineed Coke.?
to order a drink from the robot.
Thissentence contained the word ?need?, which wasnot in the grammar.
WordNet has the synonym?want?
in the synset for the word ?need?.
How-ever, the sentence ?I want Coke.?
was also notparseable, because the grammar expected an arti-cle in front of every noun.
The ellipsis detectionalgorithm was able to find the missing article in thesentence and filled it with an article ?a?
from thegrammar, leading to a parseable sentence ?I wanta Coke.
?.Although we see an increase in parsed sen-tences, 150 sentences of the test set were not trans-formed by our approach.
Therefore, we made ananalysis for the remaining utterances to find themain causes for this weak performance.
We foundthat the following reasons cause problems for thegrammar (with number of cases in brackets behindeach reason):?
Word missing in grammar (81).
The partic-ipant used a word that was not in the gram-mar.
For example, users ordered drinks bysaying ?One water, please.?
, but the gram-mar did not contain ?one?
as an article.
Thisresult shows that the WordNet similarity sub-stitution has the potential to lead to a largeincrease in parseable sentences.
However asmentioned above, there is a risk of changingthe meaning of a sentence too much when al-lowing the replacement of words which areonly vaguely similar to the unknown word.?
Sentence structure (25).
Some participantssaid sentences that were either grammaticallyincorrect or had a sentence structure that wasnot encoded in the grammar.
For exampleone participant tried to order a juice by saying?Juice for me.?.
Additionally, some partici-pants asked questions (?Do you have coke??
).248For the latter, please note that it was not partof the HRI experiment, from which we usethe test set, that the experiment participantsshould be allowed to ask questions to therobot.?
Unnecessary fill words (22).
Some experi-ment participants used unnecessary fill wordsthat did not add meaning to the sentence, forexample one participant said ?Oh come on, Ionly need water?
to order a drink.?
Sentence not related to domain (22).
Someparticipants said sentences that were contraryto the given experiment instructions.
For ex-ample, some participants asked questions tothe robot (?How old are you??)
and to the ex-perimenter (?Do I need to focus on the cam-era??
), or complained about the robot?s per-formance (?You are not quite responsive rightnow.?).
Clearly, these sentences were out ofthe scope of the grammar.5 ConclusionWe presented two methods for transforming spo-ken language into grammatically correct sen-tences.
The first of these two approaches is anellipsis detection, which automatically detects el-lipses in sentences and looks up words in a gram-mar that can fill the ellipsis.
Our ellipsis de-tection algorithm is based on the properties ofthe combinatory categorial grammar, which as-signs categories to each word in the grammarand thus enables the algorithm to find suitable fillwords by calculating the category of the ellipsis.The second approach for sentence transformationwas a WordNet-based word similarity computa-tion and substitution.
Here, we used the synsets ofWordNet to substitute words that are unknown to agiven grammar with synonyms for these words.
Inan evaluation we showed that the usage of ellip-sis detection leads to an increase of successfullyparsed sentences of up to 47.06% for some speechacts.
The usage of the WordNet similarity substi-tution does not increase the number of parsed sen-tences, although our analysis of the test set showsthat unknown words are the most common reasonthat sentences cannot be parsed.Our approach was specifically implemented tohelp circumventing problems during developmentand usage of grammars for spoken language pro-cessing in human-robot interaction experiments,and the example grammar was a very restrictedone.
However, we believe that our method canalso be helpful with more extensive grammars, andfor developers of dialogue systems in other ar-eas, such as telephone-based information systemsor offline versions of automatic smartphone assis-tants like Apple?s Siri.In the future, we will refine our methodology.In particular, the WordNet similarity substitutionis too rigid in its current form.
Here, we planto loosen some of the constraints that we ap-plied to our algorithm.
We will systematically testhow far away from a word one can look for suit-able substitutes in the WordNet hierarchy, with-out losing the meaning of a sentence.
Further-more, we plan to add a dialogue history to ourapproach, which will provide an additional sourceof information?besides the grammar?to the el-lipsis detection method.
Finally, we plan to workwith stop word lists to filter unnecessary fill wordsfrom the input sentences, since these proved alsoto be a reason for sentences to be unparseable.AcknowledgementsThis research was supported by the EuropeanCommission through the project JAMES (FP7-270435-STREP).ReferencesTimothy Brick and Matthias Scheutz.
2007.
Incre-mental natural language processing for hri.
In Pro-ceedings of the ACM/IEEE International Confer-ence on Human-Robot Interaction, pages 263?270.ACM New York, NY, USA.Alexander Budanitsky and Graeme Hirst.
2006.
Eval-uating wordnet-based measures of lexical semanticrelatedness.
Computational Linguistics, 32(1):13?47.Songmei Cai, Zhao Lu, and Junzhong Gu.
2010.
Aneffective measure of semantic similarity.
In Ad-vances in Wireless Networks and Information Sys-tems, pages 9?17.
Springer.Markus Egg and Katrin Erk.
2001.
A compositionalaccount of vp ellipsis.
Technology, 3:5.Mary Ellen Foster, Andre Gaschler, Manuel Giuliani,Amy Isard, Maria Pateraki, and Ronald P. A. Pet-rick.
2012.
Two people walk into a bar: Dynamicmulti-party social interaction with a robot agent.
InProceedings of the 14th ACM International Confer-ence on Multimodal Interaction (ICMI 2012), Octo-ber.249Manuel Giuliani, Ronald P.A.
Petrick, Mary Ellen Fos-ter, Andre Gaschler, Amy Isard, Maria Pateraki, andMarkos Sigalas.
2013.
Comparing task-based andsocially intelligent behaviour in a robot bartender.
InProceedings of the 15th International Conference onMultimodal Interfaces (ICMI 2013), Sydney, Aus-tralia, December.Kais Haddar and A Ben Hamadou.
1998.
An ellip-sis detection method based on a clause parser forthe arabic language.
In Proceedings of the Interna-tional Florida Artificial Intelligence Research Soci-ety FLAIRS98, pages 270?274.Daniel Hardt.
1997.
An empirical approach to vp el-lipsis.
Computational Linguistics, 23(4):525?541.Sunil Issar and Wayne Ward.
1993.
Cmu?s robust spo-ken language understanding system.
In Proceedingsof the Third European Conference on Speech Com-munication and Technology (Eurospeech 1993).Simon Keizer, Mary Ellen Foster, Oliver Lemon, An-dre Gaschler, and Manuel Giuliani.
2013.
Trainingand evaluation of an MDP model for social multi-user human-robot interaction.
In Proceedings of theSIGDIAL 2013 Conference, pages 223?232, Metz,France, August.Geert-Jan M. Kruijff and Jason Baldridge.
2004.
Gen-eralizing dimensionality in combinatory categorialgrammar.
In Proceedings of the 20th InternationalConference on Computational Linguistics (COLING2004), Geneva, Switzerland, August.Geert-Jan M. Kruijff, Pierre Lison, Trevor Benjamin,Henrik Jacobsson, and Nick Hawes.
2007.
In-cremental, multi-level processing for comprehend-ing situated dialogue in human-robot interaction.
InLuis Seabra Lopes, Tony Belpaeme, and Stephen J.Cowley, editors, Symposium on Language andRobots (LangRo 2007), Aveiro, Portugal, December.Shalom Lappin.
1996.
The interpretation of ellipsis.The Handbook of Contemporary Semantic Theory,397:399.Alon Lavie.
1996.
GLR*: A Robust Grammar-Focused Parser for Spontaneously Spoken Lan-guage.
Ph.D. thesis, Carnegie Mellon University.Hongzhe Liu, Hong Bao, and De Xu.
2012.
Conceptvector for semantic similarity and relatedness basedon wordnet structure.
Journal of Systems and Soft-ware, 85(2):370?381.George A. Miller.
1995.
Wordnet: A lexicaldatabase for english.
Communications of the ACM,38(11):39?41.Leif Arda Nielsen.
2004a.
Verb phrase ellipsis detec-tion using automatically parsed text.
In Proceedingsof the 20th International Conference on Computa-tional Linguistics, page 1093.
Association for Com-putational Linguistics.Leif Arda Nielsen.
2004b.
Verb phrase ellipsis detec-tion using machine learning techniques.
AmsterdamStudies in the Theory and History of Linguistic Sci-ence, page 317.Peng Qin, Zhao Lu, Yu Yan, and Fang Wu.
2009.
Anew measure of word semantic similarity based onwordnet hierarchy and dag theory.
In Proceedingsof the International Conference on Web InformationSystems and Mining2009 (WISM 2009), pages 181?185.
IEEE.David Schlangen and Gabriel Skantze.
2009.
A gen-eral, abstract model of incremental dialogue pro-cessing.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Com-putational Linguistics (EACL-09).John R. Searle.
1965.
What is a speech act?
InRobert J. Stainton, editor, Perspectives in the Phi-losophy of Language: A Concise Anthology, pages253?268.Lindsey Smith and Sarah Rauchas.
2006.
A machine-learning approach for the treatment of vp ellipsis.In Proceedings of the Seventeenth Annual Sympo-sium of the Pattern Recognition Association of SouthAfrica, November.Mark Steedman.
2000.
The Syntactic Process.
MITPress, Cambridge, MA, USA.Kishor Wagh and Satish Kolhe.
2012.
A new approachfor measuring semantic similarity in ontology andits application in information retrieval.
In Multi-disciplinary Trends in Artificial Intelligence, pages122?132.
Springer.Michael White.
2006.
CCG chart realization from dis-junctive inputs.
In Proceedings of the Fourth Inter-national Natural Language Generation Conference,pages 12?19, Sydney, Australia, July.
Associationfor Computational Linguistics.250
