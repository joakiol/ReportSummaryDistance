Proceedings of the 7th Workshop on Statistical Machine Translation, pages 109?113,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsTree Kernels for Machine Translation Quality EstimationChristian Hardmeier and Joakim Nivre and Jo?rg TiedemannUppsala UniversityDepartment of Linguistics and PhilologyBox 635, 751 26 Uppsala, Swedenfirstname.lastname@lingfil.uu.seAbstractThis paper describes Uppsala University?ssubmissions to the Quality Estimation (QE)shared task at WMT 2012.
We present a QEsystem based on Support Vector Machine re-gression, using a number of explicitly definedfeatures extracted from the Machine Transla-tion input, output and models in combinationwith tree kernels over constituency and de-pendency parse trees for the input and outputsentences.
We confirm earlier results suggest-ing that tree kernels can be a useful tool forQE system construction especially in the earlystages of system design.1 IntroductionThe goal of the WMT 2012 Quality Estimation(QE) shared task (Callison-Burch et al, 2012) wasto create automatic systems to judge the qualityof the translations produced by a Statistical Ma-chine Translation (SMT) system given the inputtext, the proposed translations and information aboutthe models used by the SMT system.
The sharedtask organisers provided a training set of 1832 sen-tences drawn from earlier WMT Machine Transla-tion test sets, translated from English to Spanishwith a phrase-based SMT system, along with themodels used and diagnostic output produced by theSMT system as well as manual translation qualityannotations on a 1?5 scale for each sentence.
Ad-ditionally, a set of 17 baseline features was madeavailable to the participants.
Systems were evalu-ated on a test set of 422 sentences annotated in thesame way.Uppsala University submitted two systems to thisshared task.
Our systems were fairly successful andachieved results that were outperformed by only onecompeting group.
They improve over the baselineperformance in two ways, building on and extend-ing earlier work by Hardmeier (2011), on whichthe system description in the following sections ispartly based: On the one hand, we enhance the setof 17 baseline features provided by the organiserswith another 82 explicitly defined features.
On theother hand, we use syntactic tree kernels to extractimplicit features from constituency and dependencyparse trees over the input sentences and the MachineTranslation (MT) output.
The experimental resultsconfirm the findings of our earlier work, showingtree kernels to be a valuable tool for rapid prototyp-ing of QE systems.2 FeaturesOur QE systems used two types of features: Onthe one hand, we used a set of explicit features thatwere extracted from the data before running the Ma-chine Learning (ML) component.
On the other hand,syntactic parse trees of the MT input and outputsentences provided implicit features that were com-puted directly by the ML component using tree ker-nels.2.1 Explicit featuresBoth of the QE systems we submitted to the sharedtask used the complete set of 17 baseline featuresprovided by the workshop organisers.
Additionally,the UU best system also contained all the featurespresented by Hardmeier (2011) with the exception109of a few features specific to the film subtitle genreand inapplicable to the text type of the shared task,as well as a small number of features not includedin that work.
Many of these features were modelledon QE features described by Specia et al (2009).
Inparticular, the following features were included inaddition to the baseline feature set:?
number of words, length ratio (4 features)?
source and target type-token ratios (2 features)?
number of tokens matching particular patterns(3 features each):?
numbers?
opening and closing parentheses?
strong punctuation signs?
weak punctuation signs?
ellipsis signs?
hyphens?
single and double quotes?
apostrophe-s tokens?
short alphabetic tokens (?
3 letters)?
long alphabetic tokens (?
4 letters)?
source and target language model (LM) andlog-LM scores (4 features)?
LM and log-LM scores normalised by sentencelength (4 features)?
number and percentage of out-of-vocabularywords (2 features)?
percentage of source 1-, 2-, 3- and 4-grams oc-curring in the source part of the training corpus(4 features)?
percentage of source 1-, 2-, 3- and 4-grams ineach frequency quartile of the training corpus(16 features)?
a binary feature indicating that the output con-tains more than three times as many alphabetictokens as the input (1 feature)?
percentage of unaligned words and words with1 : 1, 1 : n, n : 1 and m : n alignments (10 fea-tures)?
average number of translations per word, un-weighted and weighted by word frequency andreciprocal word frequency (3 features)?
translation model entropy for the input words,cumulatively per sentence and averaged perword, computed based on the SMT lexicalweight model (2 features).Whenever applicable, features were computed forboth the source and the target language, and addi-tional features were added to represent the squareddifference of the source and target language featurevalues.
All feature values were scaled so that theirvalues ranged between 0 and 1 over the training set.The total number of features of the UU best sys-tem amounted to 99.
It should be noted, however,that there is considerable redundancy in the featureset and that the 82 features of Hardmeier (2011)overlap with the 17 baseline features to some extent.We did not make any attempt to reduce feature over-lap and relied on the learning algorithm for featureselection.2.2 Parse treesBoth the English input text and the Spanish MachineTranslations were annotated with syntactic parsetrees from which to derive implicit features.
In En-glish, we were able to produce both constituency anddependency parses.
In Spanish, we were limited todependency parses because of the better availabilityof parsing models.
English constituency parses wereproduced with the Stanford parser (Klein and Man-ning, 2003) using the model bundled with the parser.For dependency parsing, we used MaltParser (Nivreet al, 2006).
POS tagging was done with HunPOS(Hala?csy et al, 2007) for English and SVMTool(Gime?nez and Ma?rquez, 2004) for Spanish, with themodels provided by the OPUS project (Tiedemann,2009).
As in previous work (Hardmeier, 2011), wetreated the parser as a black box and made no at-tempt to handle the fact that parsing accuracy maybe decreased over malformed SMT output.To be used with tree kernels, the output of the de-pendency parser had to be transformed into a sin-gle tree structure with a unique label per node andunlabelled edges, similar to a constituency parsetree.
We followed Johansson and Moschitti (2010)in using a tree representation which encodes part-of-speech tags, dependency relations and words assequences of child nodes (see fig.
1).110Figure 1: Representation of the dependency tree fragmentfor the words Nicole ?s dadA tree and some of its Subset Tree FragmentsSNNPD NVPV Marybroughta    catNPD Na    catNcatDaVbroughtNMaryNPD NVPVbroughta    catFig.
1.
A syntactic parse tree with its sub-trees (STs).NPD Na   catNPD NNPD NaNPD NNPD NVPVbroughta    catcatNPD NVPVa    catNPD NVPVNcatDaVbroughtNMary?Fig.
2.
A tree with some of its subset trees(SSTs).NPD NVPVbroughta    catNPD NVPVa    catNPD NVPa    catNPD NVPaNPDVPaNPDVPNPNVPNPNNP NPD N DNP?VPFig.
3.
A tree with some of its partial trees(PTs).isWhat offeran plandirect      stock   purchaseFig.
4.
A dependency tree of a question.constraint over the SSTs, we obtain a more general form of substructures that wecall partial trees (PTs).
These can be generated by the application of partialproduction rules of the grammar, consequently [VP [V]] and [VP [NP]] arevalid PTs.
Figure 3 shows that the number of PTs derived from the same tree asbefore is still higher (i.e.
30 PTs).
These different substructure numbers providean intuitive quantification of the different information levels among the tree-based representations.3 Fast Tree Kernel FunctionsThe main idea of tree kernels is to compute the number of common substructuresbetween two trees T1 and T2 without explicitly considering the whole fragmentspace.
We have designed a general function to compute the ST, SST and PTkernels.
Our fast evaluation of the PT kernel is inspired by the efficient evaluationof non-continuous subsequences (described in [13]).
To increase the computationspeed of the above tree kernels, we also apply the pre-selection of node pairswhich have non-null kernel.3.1 The Partial Tree KernelThe evaluation of the common PTs rooted in nodes n1 and n2 requires theselection of the shared child subsets of the two nodes, e.g.
[S [DT JJ N]] and[S [DT N N]] have [S [N]] (2 times) and [S [DT N]] in common.
As the orderof the children is important, we can use subsequence kernels for their generation.More in detail, let F = {f1, f2, .., f|F|} be a tree fragment space of type PTs andlet the indicator function Ii(n) be equal to 1 if the target fi is rooted at node nand 0 otherwise, we define the PT kernel as:A tree and some of its Partial Tree FragmentsFigure 2: Tree fragments extracted by the Subset TreeKernel and by the Partial Tree Kernel.
Illustrations byMoschitti (2006a).3 M chine Learning compon nt3.1 OverviewThe QE shared task asked both for an estimate ofa 1?5 quality score for each segment in the test setand for a ranking of t e sentences according to qual-ity.
We decided to treat score estimation as primaryand address the task as a regression problem.
Forthe ranking task, we simply submitted the rankinginduced by the regression output, breaking ties ran-domly.Our system was based on SVM regression asimplemented by the SVMlight software (Joachims,1999) with tree kernel extensions (Moschitti,2006b).
Predicted scores less than 1 were set to 1and predicted scores greater than 5 were set to 5as this was known to be the range of valid scores.Our learning algorithm had some free hyperparam-eters.
Three of them were optimised by joint gridsearch with 5-fold cross-validation over the trainingset: the SVM training error/margin trade-off (C pa-rameter), one free parameter of the explicit featurekernel and the ratio between explicit feature and treekernels (see below).
All other parameters were leftat their default values.
Before running it over thetest set, the system was retrained on the completetraining set using the parameters found with cross-validation.3.2 Kernels for explicit featuresTo select a good kernel for our explicit features,we initially followed the advice given by Hsu et al(2010), using a Gaussian RBF kernel and optimis-ing the SVM C parameter and the ?
parameter of theRBF with grid search.
While this gave reasonableresults, it turned out that slightly better predictioncould be achieved by using a polynomial kernel, sowe chose to use this kernel for our final submissionand used grid search to tune th degree of the poly-nomial instead.
The improvement over the Gaussiankernel was, however, marginal.3.3 Tree kernelsTo exploit parse tree information in our MachineLearning (ML) component, we used tree kernelfunctions.
Tree kernels (Collins and Duffy, 2001)are kernel functions defined over pairs of tree struc-tures.
They measure the similarity between two treesby counting the number of common substructures.Implicitly, they define an infinite-dimensional fea-ture space whose dimensions correspond to all pos-sible tree fragments.
Features are thus available tocover different kinds of abstract node configurationsthat can occ r in a tree.
The important feature i-mensions are effectively selected by the SVM train-ing algorithm through the selection and weightingof the support vectors.
The intuition behind ouruse of tree kernels is that they may help us iden-tify constructions that are difficult to translate in thesource language, and doubtful syntactic structures inthe output language.
Note that we do not currentlycompare parse trees across languages; tree kernels111Cross-validation Test setFeatures T C d ?
?
MAE RMS ?
?
MAE RMSUU best 99 explicit + TK 0.05 4 2 0.506 0.566 0.550 0.692 0.56 0.62 0.64 0.79(a) 99 explicit + TK 0.03 8 3 0.502 0.564 0.552 0.700 0.56 0.61 0.63 0.78(b) 17 explicit + TK 0.05 4 2 0.462 0.530 0.568 0.714 0.57 0.61 0.65 0.79UU bltk 17 explicit + TK 0.03 8 3 0.466 0.534 0.566 0.712 0.58 0.61 0.64 0.79(c) 99 explicit 0 8 2 0.492 0.560 0.554 0.700 0.56 0.59 0.65 0.80(d) 17 explicit 0 8 2 0.422 0.466 0.598 0.748 0.52 0.55 0.70 0.83(e) TK only ?
4 ?
0.364 0.392 0.632 0.782 0.51 0.51 0.70 0.85T : Tree kernel weight C: Training error/margin trade-off d: Degree of polynomial kernel?
: DeltaAvg score ?
: Spearman rank correlation MAE: Mean Average ErrorRMS: Root Mean Square Error TK: Tree kernelsTable 1: Experimental resultsare applied to trees of the same type in the same lan-guage only.We used two different types of tree kernels for thedifferent types of parse trees (see fig.
2).
The Sub-set Tree Kernel (Collins and Duffy, 2001) consid-ers tree fragments consisting of more than one nodewith the restriction that if one child of a node is in-cluded, then all its siblings must be included as wellso that the underlying production rule is completelyrepresented.
This kind of kernel is well suited forconstituency parse trees and was used for the sourcelanguage constituency parses.
For the dependencytrees, we used the Partial Tree Kernel (Moschitti,2006a) instead.
It extends the Subset Tree Kernel bypermitting also the extraction of tree fragments com-prising only part of the children of any given node.Lifting this restriction makes sense for dependencytrees since a node and its children do not correspondto a grammatical production in a dependency tree inthe same way as they do in a constituency tree (Mos-chitti, 2006a).
It was used for the dependency treesin the source and in the target language.The explicit feature kernel and the three tree ker-nels were combined additively, with a single weightparameter to balance the sum of the tree kernelsagainst the explicit feature kernel.
This coefficientwas optimised together with the other two hyperpa-rameters mentioned above.
It turned out that best re-sults could be obtained with a fairly low weight forthe tree kernels, but in the cross-validation experi-ments adding tree kernels did give an improvementover not having them at all.4 Experimental ResultsResults for some of our experiments are shown intable 1.
The two systems we submitted to the sharedtask are marked with their system identifiers.
A fewother systems are included for comparison and arenumbered (a) to (e) for easier reference.Our system using only the baseline features (d)performs a bit worse than the reference system ofthe shared task organisers.
We use the same learn-ing algorithm, so this seems to indicate that the ker-nel and the hyperparameters they selected workedslightly better than our choices.
Using only treekernels with no explicit features at all (e) creates asystem that works considerably worse under cross-validation, however we note that its performance onthe test set is very close to that of system (d).Adding the 82 additional features of Hardmeier(2011) to the system without tree kernels slightly im-proves the performance both under cross-validationand on the test set (c).
Adding tree kernels has asimilar effect, which is a bit less pronounced forthe cross-validation setting, but quite comparable onthe test set (UU bltk, b).
Finally, combining thefull feature set with tree kernels results in an addi-tional gain under cross-validation, but unfortunatelythe improvement does not carry over to the test set(UU best, a).5 ConclusionsIn sum, the results confirm the findings made in ourearlier work (Hardmeier, 2011).
They show that treekernels can be a valuable tool to boost the initial112performance of a Quality Estimation system withoutspending much effort on feature engineering.
Unfor-tunately, it seems that the gains achieved by tree ker-nels over simple parse trees and by the additional ex-plicit features used in our systems do not necessarilyadd up.
Nevertheless, comparison with other partici-pating systems shows that either of them is sufficientfor state-of-the-art performance.ReferencesChris Callison-Burch, Philipp Koehn, Christof Monz,Matt Post, Radu Soricut, and Lucia Specia.
2012.Findings of the 2012 Workshop on Statistical MachineTranslation.
In Proceedings of the Seventh Workshopon Statistical Machine Translation, Montreal, Canada,June.
Association for Computational Linguistics.Michael Collins and Nigel Duffy.
2001.
Convolutionkernels for natural language.
In Proceedings of NIPS2001, pages 625?632.Jesu?s Gime?nez and Llu?
?s Ma?rquez.
2004.
SVMTool: Ageneral POS tagger generator based on Support Vec-tor Machines.
In Proceedings of the 4th Conferenceon International Language Resources and Evaluation(LREC-2004), Lisbon.Pe?ter Hala?csy, Andra?s Kornai, and Csaba Oravecz.
2007.HunPos ?
an open source trigram tagger.
In Proceed-ings of the 45th Annual Meeting of the Association forComputational Linguistics.
Companion Volume: Pro-ceedings of the Demo and Poster Sessions, pages 209?212, Prague, Czech Republic, June.
Association forComputational Linguistics.Christian Hardmeier.
2011.
Improving machine transla-tion quality prediction with syntactic tree kernels.
InMikel L. Forcada, Heidi Depraetere, and Vincent Van-deghinste, editors, Proceedings of the 15th conferenceof the European Association for Machine Translation(EAMT 2011), pages 233?240, Leuven, Belgium.Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin.2010.
A practical guide to support vector classifica-tion.
Technical report, Department of Computer Sci-ence, National Taiwan University.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In B. Scho?lkopf, C. Burges, andA.
Smola, editors, Advances in Kernel Methods ?
Sup-port Vector Learning.
MIT Press.Richard Johansson and Alessandro Moschitti.
2010.Syntactic and semantic structure for opinion expres-sion detection.
In Proceedings of the Fourteenth Con-ference on Computational Natural Language Learn-ing, pages 67?76, Uppsala, Sweden, July.
Associationfor Computational Linguistics.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stAnnual Meeting of the Association for ComputationalLinguistics, pages 423?430, Sapporo, Japan, July.
As-sociation for Computational Linguistics.Alessandro Moschitti.
2006a.
Efficient convolution ker-nels for dependency and constituent syntactic trees.
InProceedings of the 17th European Conference on Ma-chine Learning, Berlin.Alessandro Moschitti.
2006b.
Making tree kernels prac-tical for natural language learning.
In Proceedings ofthe Eleventh International Conference of the EuropeanAssociation for Computational Linguistics, Trento.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006.MaltParser: A language-independent system for data-driven dependency parsing.
In Proceedings of the 5thConference on International Language Resources andEvaluation (LREC-2006), pages 2216?2219, Genoa.Lucia Specia, Craig Saunders, Marco Turchi, ZhuoranWang, and John Shawe-Taylor.
2009.
Improving theconfidence of Machine Translation quality estimates.In Proceedings of MT Summit XII, Ottawa.Jo?rg Tiedemann.
2009.
News from OPUS ?
a collectionof multilingual parallel corpora with tools and inter-face.
In N. Nicolov, K. Bontcheva, G. Angelova, andR.
Mitkov, editors, Recent Advances in Natural Lan-guage Processing, pages 237?248.
John Benjamins,Amsterdam.113
