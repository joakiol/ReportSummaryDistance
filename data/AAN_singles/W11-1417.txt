Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 136?141,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsPredicting Change in Student Motivation by Measuring Cohesion betweenTutor and StudentArthur WardDepartment of BiomedicalInformaticsUniversity of PittsburghPittsburgh, Pa., 15232akw13@pitt.eduDiane LitmanDepartment of ComputerScience, LRDCUniversity of PittsburghPittsburgh, Pa., 15260litman@cs.pitt.eduMaxine EskenaziLanguage TechnologiesInstituteCarnegie Mellon UniversityPittsburgh, Pa., 15213max@cmu.eduAbstractWe apply a previously reported measure of di-alog cohesion to a corpus of spoken tutoringdialogs in which motivation was measured.We find that cohesion significantly predictschanges in student motivation, as measuredwith a modified MSLQ instrument.
This sug-gests that non-intrusive dialog measures canbe used to measure motivation during tutoring.1 IntroductionMotivation is widely believed to be an important fac-tor in learning, and many studies have found rela-tionships between motivation and educational out-comes.
For example Pintrich and DeGroot (1990)found that students?
motivational state was a signif-icant predictor of classroom performance.
In ad-dition, pedagogically significant behaviors such asdictionary lookup in the REAP (Brown and Eske-nazi, 2004) vocabulary tutor have been shown tobe positively correlated with motivation assessments(DelaRosa and Eskenazi, 2011).
Also, in a separatestudy with the REAP tutor, attempts to manipulatereading motivation by presenting more interestingstories were shown to improve vocabulary learning(Heilman et al, 2010).In addition to influencing learning outcomes, mo-tivational state may also affect which interventionswill be effective during tutoring.
For example, Wardand Litman (2011) have shown that motivation cansignificantly affect which students benefit from a re-flective reading following interactive tutoring with athe Itspoke (Litman and Silliman, 2004) tutor.An accurate way to measure student motivationduring tutoring could therefore be valuable to Intel-ligent Tutoring System (ITS) researchers.
Severalself-report instruments have been developed whichmeasure various aspects of motivation (e.g.
(Pintrichand DeGroot, 1990; McKenna and Kear, 1990)).However, these instruments are too intrusive to beadministered during tutoring, for fear of fatally dis-rupting learning.
We would prefer a non-intrusivemeasure which would allow an ITS to detect whenstudent motivation is decreasing so as to launch amotivational intervention.
Similarly, the ITS shouldbe able to detect when motivation is increasingagain, to determine if the intervention worked.
Asmentioned above, such a measure might also allowan ITS to determine when it would be effective touse certain instructional tactics.In this work we investigate cohesion as a non-intrusive measure of motivation for natural languagedialog based ITS.
As defined more precisely below,our measure of cohesion quantifies lexical and se-mantic similarity between tutor and student dialogutterances.
We hypothesize that this measure of lexi-cal similarity may be related to motivation in part be-cause other measures of dialog similarity have beenshown to be related to task success.
For example,there is evidence that perceived similarity between astudent?s own speech rate and that of a recorded taskrequest increases the student?s feelings of immedi-acy, which are in turn linked to greater compliancewith the request to perform a task (Buller and Aune,1992).
1 In addition, Ward and Litman (2006; 2008)investigated a measure of lexical similarity between1In this experiment, the task was to watch a series of videos.136the tutor and student partners in a tutoring dialogwhich was shown to be correlated with task successin several corpora of tutorial dialogs.Measures of cohesion have also been used in a va-riety of NLP tasks such as measuring text readability(e.g.
(Pitler and Nenkova, 2008)), measuring stylis-tic differences in text (Mccarthy et al, 2006), andfor topic segmentation in tutorial dialog (Olney andCai, 2005).Given the previously mentioned results relatingmotivation to educational task success, these linksbetween task success and cohesion lead us to hy-pothesize a direct correlation between motivationand cohesion when using the Itspoke tutor.We will first briefly describe the Itspoke tutor, andthe corpus of tutoring dialogs used in this study.
Wewill then describe the instrument we used to mea-sure motivation both before and immediately aftertutoring, then we will describe the algorithm usedto measure cohesion in the tutoring dialogs.
Finally,we show results of correlations between the measureof motivation and the measure of cohesion.
We willfind that the change in motivation is significantlycorrelated with dialog cohesion.2 Itspoke System and CorpusItspoke (Intelligent Tutoring SPOKEn dialog sys-tem) is a spoken dialog tutoring system whichteaches qualitative physics.
It provides a spoken di-alog interface to the Why2-Atlas (VanLehn et al,2002) tutor, and has recently been re-implementedusing the TuTalk (Jordan et al, 2007) dialog plat-form.
The Itspoke tutor presents a problem in qual-itative physics, and asks the student an initial ques-tion.
The student answers the question, and the di-alog continues until all points have been covered tothe tutor?s satisfaction.The corpus used in the current work was collectedin a previous study (Ward and Litman, 2011), us-ing novice subjects who had never taken a collegephysics course.
Before tutoring, students were givena motivation survey which will be described in Sec-tion 3.
They then engaged Itspoke in five tutoringdialogs as described above.
Immediately after tu-toring they were given the motivation questionnaireagain, with tenses changed as appropriate.166 subjects were recruited by flyer, by advertise-Speaker UtteranceTutor To see which vehicle?s change in motionis greater, we use the definition of accel-eration.
What is the definition of accel-eration?Student Change in velocity.Tutor Excellent.
Acceleration is defined as theamount velocity changes per unit time.Table 1: Dialog turns, with Token, Stem, and SemanticSimilarity Matches in bold (as discussed in Section 4).ment during an undergraduate psychology course, orfrom the University of Pittsburgh?s psychology sub-ject pool.
Of these, 40 were dismissed after pretestas ?middle third?
knowledge students, following ex-treme groups design (Feldt, 1961).
Extreme groupsdesign was adopted to increase the power of a ?high?vs ?low?
knowledge comparison, which is reportedelsewhere (Ward, 2010).
Another 27 students werenot used for various reasons including incompletedata.
This left a corpus of 99 subjects who each par-ticipated in 5 tutorial dialogs.Table 1 shows an exchange from one of these di-alogs.
The tutor asks a question about the currentproblem, which the student then answers.
The tutorrestates the answer, and (later in the dialog) proceedson to the next point of discussion.3 Motivation MeasureIn this study we measure motivation using a reducedversion of the ?Motivated Strategies for LearningQuestionnaire (MSLQ)?
developed by Pintrich andDeGroot (1990).
This version of the MSLQ is alsobased on work by Roll (2009), who adapted it foruse in an IPL (Invention as Preparation for Learning(Schwartz and Martin, 2004)) tutoring environment.Our motivational survey is shown in Figure 1.Questions one and two address ?self-regulation,?particularly the students?
tendency to manage andcontrol their own effort.
Question one is on a re-versed scale relative to the other questions, so re-sponses to it were inverted.
Question three addresses?self-efficacy,?
the students?
expectation of successon the task.
Questions four and five address ?intrin-sic value,?
the students?
beliefs about the importanceand interest of the task.These dimensions of motivation are theoretically137Please read the following statements and thenclick a number on the scale that best matcheshow true it is of you.
1 means ?not at all trueof me?
whereas 7 means ?very true of me?.1.
I think that when the tutor is talkingI will be thinking of other things andwon?t really listen to what is being said.2.
If I could take as much time as I want,I would spend a lot of time on physicstutoring sessions.3.
I think I am going to find the physics tu-tor activities difficult.4.
I think I will be able to use what I learnin the physics tutor sessions in my otherclasses.5.
I think that what I will learn in thephysics tutor sessions is useful for me toknow.Figure 1: Pre-tutoring Motivational Surveydistinct.
However, except for question three (theself-efficacy question), responses to these questionswere all very significantly correlated with each otherin our survey (p < .01).Table 2 shows values of Cronbach?s Alpha (Cron-bach, 1951) for various subsets of the motivationquestions.
Alpha measures the internal consistencyof responses to a multi-point questionnaire, and is afunction of the number of test items and the corre-lation between them.
Higher values are thought toindicate that the various test items are measuring thesame underlying latent construct.
For this study weomit Question 3, maximizing Alpha at .716.
Thisis just above the commonly accepted (Gliem andGliem, 2003) threshold for reliability in such an in-strument.Questions Alpha1, 2, 3, 4, 5 0.5311, 2, 4, 5 0.7162, 4, 5 0.7034, 5 0.683Table 2: Alpha reliabilityscores for various subsetsof questions.As mentioned above,this instrument was ad-ministered both beforeand (with suitable tensechanges) immediatelyafter tutoring.
We willreport correlations usingmean scores on thepre- and post-tutoringmeasures, as well asfor the change-in-motivation score, calculated aspost-minus-pre.4 Semantic Cohesion MeasureIn this work we measure cohesion between tutor andstudent using the ?semantic cohesion?
measure firstreported by Ward and Litman (2008).
This measurecounts the number of ?cohesive ties?
(Halliday andHasan, 1976) between adjacent tutor and student di-alog turns.
A cohesive tie can be the repetition of anexact word or word stem, or the use of two wordswith similar meanings in adjacent turns.
Stop wordsare excluded, and cohesive ties are counted in boththe student-to-tutor and the tutor-to-student direc-tions.
For example, in the dialog shown in Table 1,the final tutor turn repeats the word ?velocity?
fromthe previous student turn.
This repetition would becounted as an exact cohesive tie.
Similarly, the tu-tor uses the word ?changes?
following the student?suse of ?change.?
This would be counted as a stemrepetition cohesive tie.Finally, the student?s use of ?velocity?
will becounted as a cohesive tie because of its semanticsimilarity to ?acceleration,?
from the preceding turn.The algorithm therefore counts four ties in Table 1.As described more completely in (Ward and Litman,2008), semantic similarity cohesive ties are countedby measuring two words?
proximity in the Word-Net (Miller et al, 1990) hierarchy.
We use a simplepath distance similarity measure, as implemented inNLTK (Loper and Bird, 2002).
This measure countsthe number of edges N in the shortest path betweentwo words in WordNet, and calculates similarity as 1/ (1 + N).
Our implementation of this semantic simi-larity measure allows setting a threshold ?, such thatonly word pairs with stronger-than-threshold simi-larity are counted.
Table 3 shows some semanticsimilarity pairs counted with a threshold of 0.3.motion-contactman-persondecrease-accelerationacceleration-changetravel-flyingTable 3: Example Se-mantic ties: ?
= 0.3We obtain a normal-ized cohesion score foreach dialog by dividingthe tie count by the num-ber of turns in the dialog.We then sum the line nor-malized counts over allthe dialogs for each stu-dent, resulting in a per-student cohesion measure.1385 ResultsWe ran correlations between the change-in-motivation score described in Section 3 and thesemantic similarity measure of cohesion describedin Section 4.
We report results for a semanticsimilarity threshold of .3 for consistency with(Ward and Litman, 2008), however the pattern ofresults is not sensitive to this threshold.
Significantresults were obtained for all thresholds between .2and .5, in .1 increments.
2 In addition, we reportresults for the motivation measure with the thirdquestion removed for consistency with (Ward andLitman, 2011).
However the pattern of results is notsensitive to this exclusion, either.
Significant resultswere also obtained using the entire questionnaire.MotivationMeasure Cor.
pValuepre-Tutoring 0.02 0.86Change 0.21 0.03post-Tutoring 0.19 0.055Table 4: Cohesion - MotivationCorrelations.
N = 99. ?
= 0.3In all cases,the change inmotivation wasfound to besignificantlyand positivelycorrelated withthe cohesive-ness of thetutoring dialog.
More lexical similarity betweentutor and student was predictive of increased studentmotivation.
As shown in the middle row of Table4, the correlation with motivational change, using athreshold of .3 and the reduced motivation measurewas r(97)= .21, p = 0.03.Interestingly, as shown in the top and bottom rowsof Table 4, neither motivation before tutoring r(97)= .02, p=.86, nor after tutoring r(97) = .19, p = .055,was significantly correlated with cohesion, althoughthe post-tutoring measure achieves a strong trend.Pre- and post-tutoring mean motivation levelswere, however, significantly correlated with eachother (R(97) = .69, p < .0001).
Mean motivationlevels also showed a non-significant improvementfrom 4.31 before tutoring to 4.44 after tutoring.6 Discussion and Future WorkWe have brought forward evidence that cohesion intutorial dialog, as measured in this paper, is corre-lated with changes in student motivation.
This sug-2Note from the path distance formula that thresholds be-tween .5 and 1 are impossiblegests that dialog cohesion may be useful as a non-intrusive measure of motivational fluctuations.As discussed in Section 1, other researchers haveinvestigated various types of cohesion, and their re-lationship to things such as task success and learn-ing.
In addition, work has been done investigatingthe role of motivation in learning.
However, we be-lieve ours is the first work relating dialog cohesiondirectly to user motivation.The presence of a correlation between cohesionand motivation leaves open the possibility that moremotivated students are experiencing greater tasksuccess in the tutor, and so generating more cohe-sive dialogs.
3 Note, however, that the very non-significant correlation between pre-dialog motiva-tion and dialog cohesion argues against this pos-sibility.
Instead, it seems that some process isboth creating dialog cohesion and improving studentmotivation.
The lack of significance in the post-dialog/motivation correlation may be due to datasparsity.In future work, we hope to investigate other dia-log features which may be even better predictors ofstudent motivation.
As mentioned in Section 1, webecame interested in dialog similarity metrics partlybecause of their association with task success.
Thesekinds of associations between task success and dia-log have also been shown for dialog entrainment.In this discussion we will use the term ?entrain-ment?
for the phenomenon in which conversationalpartners?
speech features become more similar toeach other at many levels, including word choice,over the course of a dialog.
4 As mentioned above,we use the term ?cohesion?
for overall similarity ofword choice between speakers in a dialog, perhapsresulting from entrainment.Users appear to entrain strongly with dialog sys-tems.
For example, Brennan (1996) has found thatusers are likely to adopt the terms used by a WOZdialog system, and that this tendency is at least asstrong as with human dialog partners.
Similarly, Par-ent and Eskenazi (2010) showed that users of theLet?s Go (Raux et al, 2005) spoken dialog systemquickly entrain to its lexical choices.3We thank an anonymous reviewer for prompting this dis-cussion.4This definition conflates studies of priming, alignment,convergence and accommodation.139As with measures of dialog similarity, dialog en-trainment has been found to be related to satisfac-tion and success in task oriented dialogs.
For ex-ample, Reitter and Moore (2007) found that lexi-cal and syntactic repetition predicted task successin the MapTask corpus.
Similarly, Ward and Lit-man (2007) found that lexical and acoustic-prosodicentrainment are correlated with task success in theItspoke dialog system.
Interestingly, in that workentrainment was more strongly correlated with tasksuccess than a measure of dialog cohesion similarto the one used in the current paper.
This raises thequestion of whether such a measure of dialog en-trainment might also be a better predictor of motiva-tion than the current measure of cohesion.
We hopein future work to further investigate this possibility.Finally, because we are interested in predictingmotivation during tutoring, our dialog metrics maybe improved by making them sensitive to the educa-tional domain.
For example, exploratory work withour tutor has suggested that a measure of cohesionwhich only counts cohesive ties between physicsterms is better correlated with certain measures oflearning than a measure which counts non-physicsterms.
This suggests that measures of cohesionor entrainment which recognize educational domainwords may also improve correlations with motiva-tion.AcknowledgmentsThis work was supported by the ONR (N00014-07-1-0039), by the NSF (0631930 and 0914615), andby the LRDC and ISP at the University of Pittsburgh.ReferencesSusan E. Brennan.
1996.
Lexical entrainment in sponta-neous dialog.
In International Symposium on SpokenDialog, pages 41?44.Jonathan Brown and Maxine Eskenazi.
2004.
Re-trieval of authentic documents for reader-specific lexi-cal practice.
In In Proceedings of InSTIL/ICALL Sym-posium.David Buller and R.Kelly Aune.
1992.
The effects ofspeech rate similarity on compliance: Application ofcommunication accommodation theory.
Western Jour-nal of Communication, 56:37?53.Lee Cronbach.
1951.
Coefficient alpha and the internalstructure of tests.
Psychometrika, 16(3):297?334.Kevin DelaRosa and Maxine Eskenazi.
2011.
Self-assessment of motivation: Explicit and implicit indi-cators of l2 vocabulary learning.
Proceedings 15th In-ternational Conference on Artificial Intelligence Edu-cation (AIED).Leonard Feldt.
1961.
The use of extreme groups totest for the presence of a relationship.
Psychometrika,26(3):307?316.Joesph Gliem and Rosemary Gliem.
2003.
Calculating,interpreting, and reporting cronbach?s alpha reliabilitycoefficient for likert-type scales.
Midwest Research toPractice in Adult, Continuing and Community Educa-tion.M.
A. K. Halliday and Ruqaiya Hasan.
1976.
Cohesionin English.
English Language Series.
Pearson Educa-tion Limited.Michael Heilman, Kevyn Collins-Thompson, JamieCallan, Maxine Eskenazi, Alan Juffs, and Lois Wil-son.
2010.
Personalization of reading passages im-proves vocabulary acquisition.
International Journalof Artificial Intelligence in Education, 20:73?98, Jan-uary.Pamela Jordan, Brian Hall, Michael Ringenberg, Yui Cui,and Carolyn Rose?.
2007.
Tools for authoring a di-alogue agent that participates in learning studies.
InProc.
of Artificial Intelligence in Ed., AIED, pages 43?50.D.
Litman and S. Silliman.
2004.
ITSPOKE: An intelli-gent tutoring spoken dialogue system.
In CompanionProc.
of the Human Language Technology Conf: 4thMeeting of the North American Chap.
of the Assoc.
forComputational Linguistics.Edward Loper and Steven Bird.
2002.
Nltk: The naturallanguage toolkit.
In In Proceedings of the ACL Work-shop on Effective Tools and Methodologies for Teach-ing Natural Language Processing and ComputationalLinguistics.
Philadelphia: Association for Computa-tional Linguistics.Philip M. Mccarthy, Gwyneth A. Lewis, David F. Dufty,and Danielle S. Mcnamara.
2006.
Analyzing writ-ing styles with coh-metrix.
In In Proceedings of theFlorida Artificial Intelligence Research Society Inter-national Conference (FLAIRS.M.C.
McKenna and D.J.
Kear.
1990.
Measuring attitudetoward reading: A new tool for teachers.
The ReadingTeacher, 43(8):626?639.George A. Miller, Richard Beckwith, Christiane Fell-baum, Derek Gross, and Katherine J. Miller.
1990.Introduction to WordNet: An on-line lexical database.International Journal of Lexicography (special issue),3 (4):235?312.Andrew Olney and Zhiqiang Cai.
2005.
An orthonormalbasis for topic segmentation in tutorial dialog.
In Pro-140ceedings of the Human Language Technology Confer-ence and Conference on Empirical Methods in NaturalLanguage Processing (HLT/EMNLP), pages 971?978.Vancouver, October.Gabriel Parent and Maxine Eskenazi.
2010.
Lexical en-trainment of real users in the let?s go spoken dialogsystem.
In Proceedings Interspeech-2010, pages 3018?
3021, Makuhari, Chiba, Japan.Paul Pintrich and Elisabeth DeGroot.
1990.
Motivationaland self-regulated learning components of classroomacademic performance.
Journal of Educational Psy-chology, 82(1):33?40.Emily Pitler and Ani Nenkova.
2008.
Revisiting read-ability: A unified framework for predicting text qual-ity.
In Proceedings of Empirical Methods in NaturalLanguage Processing (EMNLP), pages 186 ?
195.Antoine Raux, Brian Langner, Dan Bohus, Alan WBlack, and Maxine Eskenazi.
2005.
Lets go public!taking a spoken dialog system to the real world.
InProceedings Interspeech-2005, pages 885 ?
888, Lis-bon, Portugal.David Reitter and Johanna D. Moore.
2007.
Predict-ing success in dialogue.
In In Proceedings of the 45thAnnual Meeting of the Association of ComputationalLinguistics (ACL), pages 808 ?
815, Prague, Czech Re-public.Ido Roll.
2009.
Structured Invention Tasks to Pre-pare Students for Future Learning: Means, Mecha-nisms, and Cognitive Processes.
Doctor of philoso-phy, Carnegie Mellon University, 5000 Forbes Ave.Pittsburgh, Pa.Daniel Schwartz and Taylor Martin.
2004.
Inventingto prepare for future learning: The hidden efficiencyof encouraging original student production in statisticsinstruction.
Cognition and Instruction, 22:129 ?
184.K.
VanLehn, P. Jordan, C. Rose, D. Bhembe, M. Boettner,A.
Gaydos, M. Makatchev, U. Pappuswamy, M. Rin-genberg, A. Roque, S. Siler, and Srivastava R. 2002.The architecture of why2-atlas: A coach for qualita-tive physics essay writing.
In Proc.
6th Int.
Conf.
onIntelligent Tutoring Systems, pages 158?167.Arthur Ward and Diane Litman.
2006.
Cohesion andlearning in a tutorial spoken dialog system.
In Pro-ceedings of the 19th International FLAIRS Conference(FLAIRS-19), pages 533?538, May.Arthur Ward and Diane Litman.
2007.
Dialog con-vergence and learning.
In Proceedings 13th Interna-tional Conference on Artificial Intelligence Education(AIED), Los Angeles, Ca.Arthur Ward and Diane Litman.
2008.
Semanticcohesion and learning.
In Proceedings 9th Inter-national Conference on Intelligent Tutoring Systems(ITS), pages 459?469, Ann Arbor, June.Arthur Ward and Diane Litman.
2011.
Adding abstrac-tive reflection to a tutorial dialog system.
Proceedings24th International FLAIRS (Florida Artificial Intelli-gence Research Society) Conference.Arthur Ward.
2010.
Reflection and Learning Robust-ness in a Natural Language Conceptual Physics Tutor-ing System.
Doctor of philosophy, University of Pitts-burgh, Pittsburgh, PA. 15260.141
