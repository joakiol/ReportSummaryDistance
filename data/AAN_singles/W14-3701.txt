Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 1?5,October 29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsNormalized Entity Graph for Computing Local CoherenceMohsen Mesgar and Michael StrubeHeidelberg Institute for Theoretical Studies gGmbHSchloss-Wolfsbrunnenweg 3569118 Heidelberg, Germany(mohsen.mesgar|michael.strube)@h-its.orgAbstractGuinaudeau and Strube (2013) introduce agraph based model to compute local en-tity coherence.
We propose a computa-tionally efficient normalization method forthese graphs and then evaluate it on threetasks: sentence ordering, summary coher-ence rating and readability assessment.
Inall tasks normalization improves the re-sults.1 IntroductionGuinaudeau and Strube (2013) introduce a graphbased model (henceforth called entity graph) tocompute local entity coherence.
Despite being un-supervised, the entity graph performs on par withBarzilay and Lapata?s (2005; 2008) supervised en-tity grid on the tasks of sentence ordering, sum-mary coherence rating and readability assessment.The entity graph also overcomes shortcomings ofthe entity grid with regard to computational com-plexity, data sparsity and domain dependence.The entity graph is a bipartite graph where oneset of nodes represents entities and the other setof nodes represents the sentences of a document.Guinaudeau and Strube (2013) apply a one modeprojection on sentence nodes (Newman, 2010) andthen compute the average out-degree of sentencenodes to determine how coherent a document is.They describe variants of their entity graph whichtake the number of shared entities between sen-tences and their grammatical functions into ac-count thus resulting in weighted bipartite graphsand weighted one mode projections.
Here, wepropose to normalize weights for the entity graph.Normalization allows to include distance betweenmentions of the same entity, which improves theperformance on all three tasks thus confirming re-search in related areas which states that normaliz-ing weights leads to better performance (Zhou etal., 2008; Zweig and Kaufmann, 2011).2 The Entity GraphThe entity graph (Guinaudeau and Strube, 2013),G = (V,E), represents the relations between sen-tences and entities in a text, where node set V con-tains all sentences and entities in a text and E isthe set of all edges between sentences and enti-ties.
Let function w(si, ej) indicate the weight ofan edge which connects sentence siand entity ej.If w(si, ej) = 1, then this edge indicates that thereis a mention of ejin sentence si.
In order to real-ize the insight from Grosz et al.
(1995) that certainsyntactic roles are more important than others, thesyntactic role of ejin sican be mapped to an inte-ger value (Guinaudeau and Strube, 2013):w(si, ej) ={3 if ejis subject in si2 if ejis object in si1 otherwiseFigure 1 illustrates a weighted entity graph forthree sentences.1 32 32 1 131 1 11S1 S2 S3e1 e2 e3 e4 e5 e7e6 e8 e9 e101Figure 1: Weighted entity graphThree types of one-mode projections capturerelations between sentences, PU, PWand PAcc.PUcreates an edge between two sentences if theyshare at least one entity.
PWcaptures the intu-ition that the connection between two sentencesis stronger the more entities they share by meansof weighted edges, where the weights equal thenumber of entities shared by sentences (Newman,2004).
The third type of projection, PAcc, inte-grates syntactic information in the edge weightscalculated by the following formula:Wik=?e?Eikw(e, si) ?
w(e, sk) .1Figure 2 shows the three kinds of one-mode pro-jections used in the entity graph.S1 S2S3S1 S2S3S1 S2S3111294P P PU W AccFigure 2: One-mode projectionsWhile the entity grid (Barzilay and Lapata,2008) uses information about sentences which donot share entities by means of the ?- -?
transition,the entity graph cannot employ this negative in-formation.
Here, we propose a normalization forthe entity graph and its corresponding one-modeprojections which is based on the relative impor-tance of entities and, in turn, the relative impor-tance of sentences.
Including negative informa-tion allows to normalize the importance of entitiesaccording to sentence length (measured in termsof entity mentions), and hence to capture distanceinformation between mentions of the same entity.This brings the entity graph closer to Stoddard?s(1991, p.30) notion of cohesion: ?The relative co-hesiveness of a text depends on the number of co-hesive ties [...] and on the distance between thenodes and their associated cohesive elements.?
Byusing this information, edge weights are set lessarbitrary which leads to the more sound methodand higher performance in all tasks.3 Normalized Entity GraphThe entity graph weighs edges by the number ofentities sentences share (PW) and which syntacticfunctions the entities occupy (PAcc).
Here we nor-malize the weights by the number of entities in asentence.
This takes negative information into ac-count as entities which do not occur in other sen-tences also count.
Hence normalization capturesthe relative importance of entities as well as therelative importance of sentences.We follow Newman (2004) by applying nodedegree normalization.
For PW, we divide theweight of each edge by the degree of the corre-sponding sentence node.
If a sentence containsmany entities, then the amount of informationeach entity contributes is reduced.
Assume ?si?as the number of entities in sentence si.
The im-portance of entity ejfor siisImp(si, ej) =1?si?.132 32 1 131 2 11S1 S2 S3e1 e2 e3 e4 e5 e7e6 e8 e9 e1016 66 88 8 8877 777Figure 3: Normalized entity graphFor PAccwe divide the weight of each edge by thesum of all edges?
weights of a sentence.
This givesthe importance of each entity in a sentence relativeto the sentence?s other entities (see Figure 3).Imp(si, ej) =w(si, ej)?ee?Entitiesw(si, ee).For also normalizing the one-mode projectionwe introduce a virtual node TC capturing thetextual content of all sentences (inspired by thegraph based information retrieval model of Rode(2008)).
The virtual node TC is connected to allsentences (see Figure 4).S1 S2 S3e1 e2 e3 e4 e5 e7e6 e8 e9 e10TCw(s1,TC)w(s2,TC)w(s3,TC)Figure 4: Entity graph with virtual nodeRode (2008) uses the following formula to com-pute weights on the edges between the sentencenodes and TC:w(si, TC) =Score(si|TC)?stScore(st|TC),where the function Score(si|TC) is the numberof entities in siwhich have overlap with TC.
Thisvalue is equal to the degree of each sentence.Since we are interested in local coherence, werestrict TC to pairs of sentences (See Figure 5).Subsequently, instead of w(si, TC), we use thenotation lwsjsi(local weight of sentence siaccord-ing to sentence sj).We define the normalized one-mode projectionas follows:Wsij=?e?Esij{(lwsjsi?Imp(si,e))+(lwsisj?Imp(sj,e))}.2Si Sje1 e2 e3 e4 e5 e7e6RTC=w(si,RTC) =w(sj,RTC)bb blwsisjlw sisjFigure 5: Restricted TC for a pair of sentencesSimilar to Rode (2008), we use the product oflwsjsiand Imp(si, e) to approximate the salienceof entity e in sentence si.
This prevents the modelto get biased by the length of sentences.This method can be applied to graphs withedges weighted according to syntactic role (PAcc).To compute the connection?s strength of a pair ofsentences we follow Yang and Knoke?s (2001) ap-proach: The path length in a weighted graph is thesum of the edge weights in the path.
In our case,each path is defined between a pair of sentencesof the entity graph, so the number of edges of allpaths are equal to two.
Figure 6 shows the nor-malized projections where the weights have beencomputed by the above formula.S1 S2S3S1 S2S3S1 S2S3112P P P84827642356U W AccFigure 6: Normalized projections4 ExperimentsWe compare the normalized entity graph with theentity graph on all tasks, Guinaudeau and Strube(2013) compared their work with the entity grid(Barzilay and Lapata, 2008; Elsner and Charniak,2011): sentence ordering, summary coherence rat-ing and readability assessment.
Following Guin-audeau and Strube (2013) we test statistical sig-nificance with the Student?s t-test and Bonferronicorrection, to check whether the best result (boldvalue in the tables) is significantly different fromthe results of the entity graph and the normalizedentity graph.
Diacritics ** indicate significancelevel 0.01, * indicates significance level 0.05.Acc FRandom 0.496 0.496B&L 0.877 0.877E&C 0.915 0.915Entity graph, G&SPU, Dist 0.830 0.830**PW, Dist 0.871 0.871PAcc, Dist 0.889 0.889Normalized entity graphPU, Dist 0.830 0.830**PW, Dist 0.886 0.886PAcc, Dist 0.909 0.909Table 1: Discrimination, baselines and entitygraph vs. normalized entity graph4.1 Sentence OrderingThis task consists of two subtasks: discrimina-tion and insertion.
In both subtasks we evaluatewhether our model can distinguish between thecorrect order of sentences in a document and anincorrect one.
Experimental setup and data fol-low Guinaudeau and Strube (2013) (61 documentsfrom the English test part of the CoNLL 2012shared task (Pradhan et al., 2012)).For discrimination we use 20 permutations ofeach text.
Table 1 shows the results.
Resultsfor Guinaudeau and Strube (2013), G&S, are re-produced, results for Barzilay and Lapata (2008),B&L, and Elsner and Charniak (2011), E&C, werereproduced by Guinaudeau and Strube (2013).The unweighted graph, PU, does not need nor-malization.
Hence the results for the entity graphand the normalized entity graph are identical.
Nor-malization improves the results for the weightedgraphs PWand PAccwith PAccoutperformingB&L considerably and closely approaching E&L.Sentence insertion is more difficult than dis-crimination.
Following Elsner and Charniak(2011), we use two measures for evaluation: Ac-curacy (Acc.)
and the average proportion of cor-rect insertions per document (Ins.).Acc.
Ins.Random 0.028 0.071E&C 0.068 0.167Entity graph, G&SPU, Dist 0.062** 0.101**PW, Dist 0.075 0.114**PAcc, Dist 0.071 0.102**Normalized entity graphPU, Dist 0.062** 0.101**PW, Dist 0.085 0.154PAcc, Dist 0.077 0.157Table 2: Insertion, baselines and entity graph vs.normalized entity graph3Acc.
FB&L 0.833Entity graph, G&SPU0.800 0.815PW0.613 0.613*PAcc0.700 0.704Normalized entity graphPU0.800 0.815PW0.775 0.775PAcc0.788 0.788Table 3: Summary Coherence Rating, B&L andentity graph vs. normalized entity graphTable 2 shows that the normalized entity graphoutperforms the entity graph for PWand PAcc(again, no difference for PU).
The normalizedentity graph outperforms E&C in Acc.
and ap-proaches it in Ins.
The high value for Ins.
showsthat if the normalized entity graph makes false de-cisions they are closer to the original ordering thanthe mistakes of the entity graph.4.2 Summary Coherence RatingWe follow Barzilay and Lapata (2008) for evalu-ating whether the normalized entity graph can de-cide whether automatic or human summaries aremore coherent (80 pairs of summaries extractedfrom DUC 2003).
Human coherence scores are as-sociated with each pair of summarized documents(Barzilay and Lapata, 2008).Table 3 displays reported results of B&L andreproduced results of the entity graph and our nor-malized entity graph.
Normalizing significantlyimproves the results for PWand PAcc.
PUis stillslightly better than both, but in contrast to the en-tity graph, this difference is not statistically signif-icant.
We believe that better weighting schemesbased on linguistic insights eventually will outper-form PUand B&L (left for future work).
Distanceinformation always degrades the results for thistask (see Guinaudeau and Strube (2013)).4.3 Readability AssessmentReadability assessment aims to distinguish textswhich are difficult to read from texts which areeasier to read.
In experiments, Barzilay and La-pata (2008) assume that articles taken from Ency-clopedia Britannica are more difficult to read (lesscoherent) than the corresponding articles from En-cyclopedia Britannica Elementary, its version forchildren.
We follow them with regard to data (107article pairs), experimental setup and evaluation.Table 4 compares reported results by SchwarmAcc.
FS&O 0.786B&L 0.509B&L + S&O 0.888Entity graph, G&SPU, Dist 0.589 0.589**PW, Dist 0.570 0.570**PAcc, Dist 0.766 0.766**Normalized entity graphPU, Dist 0.589 0.589**PW, Dist 0.897 0.897PAcc, Dist 0.850 0.850Table 4: Readability assessment, baselines and en-tity graph vs. normalized entity graphand Ostendorf (2005), S&O, Barzilay and Lapata(2008), B&L, a combined method, B&L + S&O,reproduced results for the entity graph, G&S, andour normalized entity graph.
Distance informationalways improves the results.Sentences in the Britannica Elementary aresimpler and shorter than in the Encyclopedia Bri-tannica.
The entity graph does not take into ac-count the effect of entities not shared between sen-tences while the normalized entity graph assigns alower weight if there are more of these entities.Hence, Britannica Elementary receives a highercohesion score than Encyclopedia Britannica inour model.
Adding grammatical information, doesnot help, because of the influence of the numberof entities (shared and not shared) outweighs theinfluence of syntactic roles.
The normalized en-tity graph (PW, Dist) does not only outperformthe entity graph (significantly) and B&L but alsoS&O and the combination B&L + S&O.5 ConclusionWe proposed a normalization method for the en-tity graph (Guinaudeau and Strube, 2013).
Wecompared our model to the entity graph andto the entity grid (Barzilay and Lapata, 2008)and showed that normalization improves the re-sults significantly in most tasks.
Future workwill include adding more linguistic information,stronger weighting schemes and application toother readability datasets (Pitler and Nenkova,2008; De Clercq et al., 2014).AcknowledgmentsThis work has been funded by the Klaus TschiraFoundation, Heidelberg, Germany.
The first au-thor has been supported by a Heidelberg Institutefor Theoretical Studies Ph.D. scholarship.4ReferencesRegina Barzilay and Mirella Lapata.
2005.
Model-ing local coherence: An entity-based approach.
InProceedings of the 43rd Annual Meeting of the As-sociation for Computational Linguistics, Ann Arbor,Mich., 25?30 June 2005, pages 141?148.Regina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Compu-tational Linguistics, 34(1):1?34.Orph?ee De Clercq, V?eronique Hoste, Bart Desmet,Philip Van Oosten, Martine De Cock, and LieveMacken.
2014.
Using the crowd for readability pre-diction.
Natural Language Engineering, 20(3):293?325.Micha Elsner and Eugene Charniak.
2011.
Extendingthe entity grid with entity-specific features.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics (Volume 2: ShortPapers), Portland, Oreg., 19?24 June 2011, pages125?129.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1995.
Centering: A framework for model-ing the local coherence of discourse.
ComputationalLinguistics, 21(2):203?225.Camille Guinaudeau and Michael Strube.
2013.Graph-based local coherence modeling.
In Proceed-ings of the 51st Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Pa-pers), Sofia, Bulgaria, 4?9 August 2013, pages 93?103.Mark E.J.
Newman.
2004.
Analysis of weighted net-works.
Physical Review E, 70(5):056131.Mark E.J.
Newman.
2010.
Networks: An Introduction.Oxford University Press, New York, N.Y.Emily Pitler and Ani Nenkova.
2008.
Revisitingreadability: A unified framework for predicting textquality.
In Proceedings of the 2008 Conferenceon Empirical Methods in Natural Language Pro-cessing, Waikiki, Honolulu, Hawaii, 25?27 October2008, pages 186?195.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 Shared Task: Modeling multilingual unre-stricted coreference in OntoNotes.
In Proceedingsof the Shared Task of the 16th Conference on Com-putational Natural Language Learning, Jeju Island,Korea, 12?14 July 2012, pages 1?40.Henning Rode.
2008.
From document to entity re-trieval: Improving precision and performance of fo-cused text search.
Ph.D. thesis, Enschede, June.Sarah E. Schwarm and Mari Ostendorf.
2005.
Readinglevel assessment using support vector machines andstatistical language models.
In Proceedings of the43rd Annual Meeting of the Association for Compu-tational Linguistics, Ann Arbor, Mich., 25?30 June2005, pages 523?530.Sally Stoddard.
1991.
Text and Texture: Patterns ofCohesion.
Ablex, Norwood, N.J.Song Yang and David Knoke.
2001.
Optimal connec-tions: Strength and distance in valued graphs.
Socialnetworks, 23(4):285?295.Tao Zhou, Jie Ren, Mat?u?s Medo, and Yi-Cheng Zhang.2008.
Bipartite network projection and personal rec-ommendation.
Physical Review E, 76(4).
046115.Katharina A. Zweig and Michael Kaufmann.
2011.
Asystematic approach to the one-mode projection ofbipartite graphs.
Social Network Analysis and Min-ing, 1:187?218.5
