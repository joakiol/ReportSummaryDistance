Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93?97,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsAggregating opinions: Explorations into Graphs and Media ContentAnalysisGabriele TatzlSORAInstitute for Social Research & AnalysisVienna, Austriagt@sora.atChristoph WaldhauserSORAInstitute for Social Research & AnalysisVienna, Austriachw@sora.atAbstractUnderstanding, as opposed to reading isvital for the extraction of opinions outof a text.
This is especially true, asan author?s opinion is not always clearlymarked.
Finding the overall opinion ina text can be challenging to both hu-man readers and computers alike.
Me-dia Content Analysis is a popular methodof extracting information out of a text, bymeans of human coders.
We describe thedifficulties humans have and the processthey use to extract opinions and offer aformalization that could help to automateopinion extraction within the Media Con-tent Analysis framework.1 IntroductionWhen humans read, they try to not only decode thewritten language, but also link it with external in-formation.
This gives them access to meaning andopinion of a text, that remain hidden from a meredecoder.
This process of reading can be organizedscientifically within the framework of Media Con-tent Analysis (MCA).
Reading, however, is expen-sive in terms of time and money.
Yet the volumeof textual data that is available for research growsseemingly without bounds.
Automating reading,indeed doing MCA ?
at least to some degree ?
is avery desirable advance for any practitioner in thefield.The purpose of this short positional paper is tointroduce MCA as we use it in our day-to-day livesand discuss challenges and possible solutions forthem, with regards to automation.The remainder of this paper is organized as fol-lows.
First we give a brief introduction to MediaContent Analysis and it?s applications in the socialsciences in general.
We will then focus on opin-ion mining as an important task within the generalMCA framework.
Special emphasis will be put onthe challenges humans (and computers alike) face,when extracting opinions from a document.
As acontribution to the effort of overcoming these ob-stacles, we offer a formalized interpretation of theMCA opinion extraction process in section 4.
Fi-nally, some concluding remarks and suggestionsfor an algorithmic implementation are made.2 Media Content AnalysisMedia Content Analysis from a social science per-spective is driven by research questions (e.g.
Howdoes the perception of migrant groups vary in dif-ferent media?)
and practical questions of privateand public clients (e.g.
In which context do nega-tive opinions about a corporation occur?)
in orderto investigate and evaluate the content of commu-nication.Media Content analysis can be generally de-scribed as ?systematic reading of a body oftexts, images, and symbolic matter?
(Krippendorf,2004).
It ?is applied to a wide variety of printedmatter, such as textbooks, comic strips, speeches,and print advertising?
(Krippendorf, 2004) ormore generally to any cultural artifact1.
Addi-tionally, Content Analysis is defined as an empir-ical method for (I) systematic and inter-subjectiveunderstandable description of textual and formalcharacteristics and (II) for inquiring into social re-ality that consists of inferring features of a non-manifest context from features of a manifest writ-ten text and other meaningful matters (Merten,1995; Krippendorf, 2004; Fru?h, 2007).There is a wide range of methods of research,?(.
.
. )
from simple and extensive clas-sifications of types of content for or-ganizational or descriptive purposes to1MCA is e.g.
also used for comparing representations ofgroups, issues and events to their real-world occurrences.93deeply interpretative enquiries into spe-cific examples of content, designed touncover subtle and hidden potentialmeanings?
(McQuail, 2005).The methodology we use is based upon a broadfoundation of recent and widely approved litera-ture (Riffe et al, 1998; Franzosi, 2008; Kaplan,2004; Merten, 1995; Roberts, 2001; Krippen-dorf, 2004; Neuendorf, 2007; Ro?ssler, 2005; Fru?h,2007; Weerakkody, 2009): The analysis typicallystarts from the formulation of some specific re-search questions, in terms of topics, actors andpatterns of interpretation that need to be investi-gated.
Based on theoretical foundations and oper-ationalisation, categories (theoretically or empir-ically grounded) and indicators are defined.
Allcategories together make up the codebook, whichis the instrument for the manual coding of text.The codebook consists of different characteristicsfor every variable and of instructions for the man-ual coding.
One can compare the codebook to theperhaps more familiar questionnaire used in em-pirical quantitative social science.
In this under-standing, the codebook is little more than ques-tions on the text and some hints on how to answerthem.
For instance, a question might concern astatement?s speaker or subject actor and the wayshe is arguing her opinion: Is the argumentationof SACT in the statement rational?
; possible an-swer codes are 1?the argumentation is consistentand rational, 2?the argumentation is not consis-tent and not well explained, and 3?no valuationpossible.In particular, variables are extracted on differentlevels of the documents: some address the wholedocument (article) and its source, some focus onclaims to be able to answer all the different re-search questions.
A core point in conducting em-pirical research is the demand for validity (exter-nal and internal) and reliability2 (pre-tests).
Thesequality checks have to be done carefully (Krippen-dorf, 2004).The work proceeds with the identification (themanual annotation) of specific variables and indi-cators by turning text into numbers and fill out thecodebook?s answer sheet (data entry mask).
Theturning of text into numbers (coding process) isat the moment a very cumbersome task, as it is2Reliability in Content Analysis is the amount of agree-ment or correspondence among two or more coders (Krip-pendorf, 2004; Neuendorf, 2007).done manually.
Humans, so called coders (usuallytrained junior researchers), have to read each arti-cle and de facto answer questions (the codebook)on the text afterwards.
Last but not least, the finaldata file (cleaned manual codings) is used in statis-tical analysis in order to answer the research ques-tions.
The significance of this methodology liesprecisely in its capacity to describe the mediatedpublic discourse and various forms and aspects ofdiversity (i.e.
diversity of opinions).It should be considered that we conduct neitherdiscourse analysis (e.g.
Hajer and Versteeg, 2005)nor linguistic analysis (e.g.
Livesey, 2001).
Ourapproach is an analysis of mediated public dis-course (see inter alia Gerhards et al, 2007), whichimplies certain methodological differences.
Thismethodology is especially useful for the analy-sis of web media content and can be combinedwith other approaches.
In the LivingKnowledgeproject3, the analysis of the mediated public dis-course is combined with Multimodal Genre Anal-ysis (Baldry and Thibault, 2005).3 Opinion Mining in MCADetermining the degree to which a whole article(entire content) or a statement in a text (part ofcontent) is positive, negative or neutral is not theonly but a very essential reason for conductingMedia Content Analysis.
Applying the kind ofMedia Content Analysis mentioned above, we areable to describe the polarity of an opinion and thedegree of correlation between the polarity of anopinion and the context of the opinion holder.
Anopinion holder could be considered as the speaker(person or organization) of a statement in the text.The human coders are instructed by the codebook(rules for coding) how opinions should be detectedand ranked (five point-scale4).
We are firmly con-vinced that it is not possible to detect opinionsacross different use cases only by means of polarwords or opinion bearing words, because meaningof these words is always dependent on the con-3The research leading to these results has receivedfunding from the European Community?s Seventh Frame-work Programme (FP7/2007-2013) under grant agreementn?231126 Living Knowledge: Living Knowledge ?
Facts,Opinions and Bias in Time.4Rate the opinion according to your interpretation of thearticle: The overall opinion is very positive, if the topic ismentioned with positive attributes and/or if a really positiveoutcome of an event is reported and not criticized and/or ifthe author of the article or more than half of the speakerstalking about a certain topic evaluates it as very positive (1 =very positive).94tent?s context.
If you only have a short view onparts of the text, it can result in narrow incompleteinterpretations.
Besides that, additional informa-tion (which is not in the text) is often requiredto interpret an opinion and to understand the el-ements of social structure.
It must be pointed outthat when human coders read an article, there isa process of automatic inference.
The proverbialconcept of reading vs. understanding captures thisnotion with surprising accuracy.
Correspondingly,sentiment analysis is a rather challenging processfor humans as well as for computers.4 Structuring opinionsIn the following we will try to formalize what usu-ally happens inside a human coder, coding an arti-cle.
A typical research question in this sense mightbe: is the opinion of article X , ?x positive, neu-tral, or negative towards a topic Y 5?
The trickypart lies in the fact, that very few articles state theiropinions expressis verbis.
Rather, articles containa number of statements on diverse facets of the ar-ticle?s topic.
These statements in turn are againcomposed of reported actions or speech of sub-ject actors6 (SACTs).
All these elements can bethought of as nodes in a tree: article being the rootnode containing M statement nodes and N SACTnodes.
Note, that the N SACT nodes need notbe uniformly distributed between theM statementnodes.
Figure 1 displays the tree structure inherentto Media Content Analysis.Each node has a number of attributes, variablesin the codebook terminology, such as the nameof the author or SACT.
Next to these obvious at-tributes there are also latent ones, which are onlyaccessible by analyzing all child nodes and ag-gregating the results (possibly with using exter-nal information).
Opinions of articles are one ex-ample of latent attributes in Media Content Anal-ysis.
The process of aggregating all of a state-ment?s SACTs?
opinions (?mn) into a single state-ment opinion (?m), and further aggregating all ofan article?s statement opinions into a single articleopinion, lies at the hearth of opinion mining withinthe Media Content Analysis framework.
Figure 25Selecting only statements that deal with a certain topic Yis beyond the scope of this paper.
However, automating topicselection is rather feasible by including background knowl-edge on the topic itself.
Background knowledge that is read-ily available at a very early stage of MCA research questionformulation.6A subject actor is the person that effects a claim, e.g.
ifthe claim is a statement, it is the speakerStatementmSACTm1 SACTm2?
??
?g()Figure 2: Aggregating SACTs?
opinions into astatement opinion within the MCA frameworkdepicts the aggregating of SACTs?
opinions into astatement opinion as a subtree.To return to the more formalized notation in-troduced above, ?x = f(g1, g2, .
.
.
, gm), withgk(?m1, ?m2, .
.
.
, ?mn, ).
A description of thesetwo classes of functions is not trivial.
A function(f ) that aggregates statement opinions (gk, them-selves aggregates of their SACTs?
opinions) intoan overall article opinion (?)
requires to take intoaccount not only the opinion attributes of its state-ment arguments, but also their relationships, an as-sessment of their equal presentation and take hintsat the author?s intentions.
This function will typ-ically be a weighted mean of the values for theopinion variable for the contained statements:?
?x =?Mk=1wkgk?Mk=1wkEstimating the weights wk needs to include theaforementioned interstatement relationships andpresentation.
For instance, in the aggregation oftwo mildly negative statements and a very positiveone, do these opinions really cancel out?
Diffi-cult as this may be, aggregating SACTs?
opinionsinto a single statement opinion is even more dif-ficult.
Here, external information () plays a cru-cial role, e.g.
can the three SACTs Bill Gates, Li-nus Torvalds and an unnamed undergraduate com-puter science student be equal contributors to any95StaemnACaTaA1A2ag CaTaA1A2a(CaTaA1A2a) CSgg CSg) CS)g CS(Figure 1: Relationship among levels of a documentgiven statement.
In structure, this class of func-tions is also based on the weighted mean concept.However, in estimating the weights, notions ofspeaker interaction, speaker significance and ef-fectiveness come into play.
Many of these con-cepts cannot be sufficiently included by means ofanalyzing the text.
Further, external informationis required.
This information can be thought ofas an ontology or metadata, giving meaning to theactions and speech of a SACT.
In a manual cod-ing process, this information has been learned bythe human coders through their past experience inreading texts.
This is one of the reasons junior re-searchers, and not e.g.
unskilled laborers, are usedfor this task.
External knowledge, quite often to asubstantial part, is critical in understanding a text.5 ConclusionReading and understanding text is daunting taskfor humans.
It requires years if not decades oftraining and experience to uncover hidden mean-ings and latent opinions.
However, the process ofreading is rather simple.
We formalized this pro-cess by focusing on the example of extracting andaggregating opinions of an article.
By rethinkingreading and understanding opinions as a tree, wewere able to structure the way humans use au-tomatic inference to weight arguments and formopinions.
The aggregating functions are simplethemselves, however, estimating the right argu-ments is tricky.
It requires the inclusion of mas-sive amounts of external knowledge.
In our opin-ion, this knowledge is currently not available inmachine accessible form.
With the ever increas-ing diffusion of semantic web data and ongoingefforts to create substantial ontologies of externalknowledge, the future certainly will show interest-ing developments in this field.In the meantime, thinking opinion extracting astraversing a tree might help to create software thathelps human coders in their work.
Also, largetraining sets of manually coded articles could beused to estimate the weights required to aggregateopinions on higher levels of analysis.
However,achieving acceptable performance across diversetopics and usecases seems unlikely at this time.ReferencesAnthony Baldry and Paul J Thibault.
2005.
Multi-modal Transcription and Text Analysis.
Equinox,London and Oakville.Roberto Franzosi.
2008.
Content analysis, volume 1 ofSage benchmarks in social research methods.
Sage,Los Angeles.Werner Fru?h.
2007.
Inhaltanalyse.
Theorie undPraxis.
UVK, Konstanz, 6. rev.
ed.
edition.Ju?rgen Gerhards, Anke Offerhaus, and Jochen Roose.2007.
The public attrobution of responsibility.
de-veloping an instrument for content analysis.
Ko?lnerZeitschrift fu?r Soziologie und Sozialpsychologie,59:105?125.Marteen Hajer and Wytske Versteeg.
2005.
A decadeof discourse analysis of environmental politics:Achievements, challenges, perspectives.
Journal ofEnvironmental Policy and Planning, 7(3):175?184.David Kaplan, editor.
2004.
The SAGE handbookof quantitative methodology for the social sciences.Sage, Thousand Oaks.96Klaus Krippendorf.
2004.
Content analysis.
An in-troduction to its methodology.
Sage, London, 2. ededition.Sharon M Livesey.
2001.
Eco-identity as discursivestruggle: Royal dutch/shell, brent spar and nigeria.Journal of Business Communication, 38(1):58?91.Denis McQuail.
2005.
McQuail?s Mass Communica-tion Theory.
Sage, London, 5. ed edition.Klaus Merten.
1995.
Inhaltsanalyse.
Einfu?hrungin Theorie, Methode und Praxis.
Westdt.
Verlag,Opladen.Kimberly A Neuendorf.
2007.
The content analysisguidebook.
Sage, Thousand Oaks.Daniel Riffe, Stephen Lacy, and Frederick Fico.
1998.Analyzing media messages: using quantitative con-tent analysis in research.
Erlbaum, Mahwah.C W Roberts.
2001.
Content analysis.
In Smelser andBaltes (Smelser and Baltes, 2001).Patrick Ro?ssler.
2005.
Inhaltsanalyse.
UVK, Kon-stanz.Neil J Smelser and Paul B Baltes, editors.
2001.
Inter-national Encyclopedia of the Social & BehavioralScience.
Elsevier, Amsterdam.Niranjala Weerakkody.
2009.
Research Methodsfor Media and Communication.
Oxford UniversityPress, Oxford.97
