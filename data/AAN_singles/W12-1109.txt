JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 77?90,Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCPEnrichir et raisonner sur des espaces s?mantiques pourl?attribution de mots-cl?sAdil El Ghali1, 2 Daniel Hromada1 Kaoutar El Ghali(1) LUTIN UserLab, 30, avenue Corentin Cariou, 75930 Paris cedex 19(2) IBM CAS France, 9 rue de Verdun, 94253 Gentillyelghali@lutin-userlab.frR?SUM?Cet article pr?sent le syst?me hybride et multi-modulaire d?extraction des mots-cl?s ?
partirde corpus des articles scientifiques.
Il s?agit d?un syst?me multi-modulaire car int?gre en soiles traitements 1) morphosyntaxiques (lemmatization et chunking) 2) s?mantiques (ReflectiveRandom Indexing) ainsi que 3) pragmatiques (mod?lis?s par les r?gles de production).
Onparle aussi d?un syst?me hybride car il ?tait utilis?
-sans modification majeure- pour trouver dessolutions aux toutes les deux pistes du DEFT 2012.
Pour la Piste 1 - o?
une terminologie ?taitfournie - nous obt?nmes le F-score de 0.9488 ; pour la Piste 2 ?
o?
aucune liste des mots cl?scandidates n?
?tait pas fourni au pr?alable ?
le F-score obtenu est 0.5874.ABSTRACTEnriching and reasoning on semantic spaces for keyword extractionThis article presents a multi-modular hybrid system for extraction of keywords from corpus ofscientific articles.
System is multi-modular because it integrates components executing transfor-mations on 1) morphosyntactic level (lemmatization and chunking) 2) semantic level (ReflectedRandom Indexing), as well as upon more 3) ?
pragmatic ?
aspects of processed documents,modeled by production rules.
The system is hybrid because it was able to address both tracks ofDEFT2012 competition ?
a ?reduced search-space?
scenario of Track 1, whose objective was tomap the content of a scientific article upon one among the members of a ?
terminological list ?
;as well as more ?
real-life ?
scenario of Track2 within which no list was associated to documentscontained in the corpus.
In both Tracks, the system hereby presented has obtained the an F-scoreof 0.9488 for the Track1, and 0.5874 for the Track2.MOTS-CL?S : Extraction de mots-cl?s, Espaces s?mantiques, RRI, R?seau bay?sien, R?gles de production,Chunking.KEYWORDS: Keyword extraction, Semantic spaces, RRI, Bayesian Network, Production Rules, Chunking.1 IntroductionL?
?dition 2012 du d?fi fouille de textes (DEFT) a pour th?me l?identification automatique desmots-cl?s indexant le contenu d?articles publi?s dans des revues scientifiques.
Deux pistes ont ?t?propos?es : dans la premi?re (Piste 1) la terminologie des mots-cl?s est fournie, alors que dans ladeuxi?me (Piste 2) l?attribution des mots-cl?s devait se faire sans terminologie.77Pour la r?alisation de cette t?che nous avons d?cid?, dans la continuit?
de ce que nous avionsr?alis?
en 2011 (El Ghali, 2011), de repr?senter le sens des termes et des documents du corpusdans des espaces s?mantiques utilisant la variante Reflective Random Indexing (RRI).
Le choix deRRI une variante de Random Indexing (RI) (Sahlgren, 2006) est motiv?
par les bonnes propri?t?sde cette m?thode, h?rit?es de RI et qui sont largement d?crites dans la litt?rature (Cohen et al,2010a).
Mais une de ces propri?t?s moins connue et comment?e s?est r?v?l?e particuli?rementpertinente pour le probl?me pos?
dans le cadre de cette ?dition du DEFT, ?
savoir l?uniformit?
del?espace s?mantique : en effet, les vecteurs construits par RRI pour repr?senter les documents etles termes du corpus sont ?
comparables ?.Dans la m?thode que nous avons d?velopp?
pour cette ?dition du DEFT, nous avons voulur?pondre ?
deux questions principales :1. quel serait l?apport d?un pr?-traitement linguistique de surface aux espaces s?mantiques ?
eten quoi pourrait-on comparer ces pr?-traitements aux m?thodes de constructions d?espacess?mantiques permettant de capturer des ?l?ments de structure ?2.
peut-on am?liorer les m?thodes de scoring d?velopp?es dans les pr?c?dentes ?ditionsdu DEFT en utilisant les derni?res avanc?es en Intelligence artificielle, notamment leraisonnement ?
base de r?gles et les graphes probabilistes, encodant respectivement desr?gles g?n?rales sur le choix des mots-cl?s et des informations incertaines issues du corpusd?apprentissage ?La premi?re question s?imposait naturellement du fait qu?une grande partie des mots-cl?s qui ont?t?
fournis pour la Piste 1 sont en fait des groupes de mots et que leurs cat?gories morphosyn-taxiques et grammaticales respectait des r?gles assez simples.
Pour pouvoir traiter les mots-cl?scompos?s de plusieurs mots, certaines m?thodes de repr?sentation de textes en espaces s?man-tiques telles que BEAGLE (Jones et Mewhort, 2007), PSI (Cohen et al, 2009), ou encore RRIavec des indexes positionnels (Widdows et Cohen, 2010), permettent d?encoder les informationssur l?ordre des mots.
La deuxi?me question est n?e du fait que l?on disposait d?informations denature diff?rentes qui pouvait aider ?
attribuer correctement des mots-cl?s : sur la s?mantique,sur la distribution des mots-cl?s, sur la structure, sur les revues dont sont issues les articles ...Ces informations pouvaient ?tre difficilement encod?es dans un seul formalisme de d?cision.Nous avons donc d?cid?
de d?finir une proc?dure de d?cision pour l?attribution de mots-cl?squi combine des r?gles symboliques avec des r?seaux bay?siens, avec les R?gles de productionProbabilistes (A?t-Kaci et Bonnard, 2011).Nous avons fait le choix d?aborder les deux pistes du d?fi de cette ann?e de mani?re sensiblementidentique, les m?mes m?thodes ont ?t?
utilis?es pour les deux pistes.
Pour ce faire, nous avonsconstruit une terminologie pour la Piste 2.
Cette terminologie est une liste de mots-cl?s candidats?tablie en utilisant un espace s?mantique et un pr?-traitement linguistique de surface.L?article est organis?
comme suit : nous commen?ons par pr?senter dans la section 2 une analysedu corpus et des informations qui peuvent en ?tre extraite et qui sont utiles pour la t?ched?attribution de mots-cl?s.
Ensuite, dans la section 3, nous rappelons bri?vement le principede fonctionnement de RRI, puis nous d?crivons comment incorporer les informations issuedu pr?-traitement linguistique dans les espaces s?mantiques, mais aussi comment la liste descandidats mots-cl?s pour la Piste 2 est construite.
Dans la section 4 nous pr?sentons le principede fonctionnement de la proc?dure de d?cision pour l?attribution des mots-cl?s.
Enfin, dans lasection 5 nous d?taillons les caract?ristiques de chacune des ex?cutions et discutons les r?sultatsavant de conclure.782 Le Corpus2.1 Statistiques g?n?rales de corpus d?apprentissage2.1.1 Piste 1Pour la Piste 1, il y a 140 documents dans le corpus d?apprentissage.
Les documents proviennentde 4 revues diff?rentes, l?identificateur de la revue ?tant encod?
dans le nom du fichier XMLcontenant l?article.La liste terminologique ?
i.e.
la liste contenant tous les termes uniques choisies comme un motcl?
pour un document dans le corpus - associ?e au corpus d?apprentissage contient Tappr = 666termes uniques.Les nombres des mots-cl?s associ?s sont fournis pour chaque document du corpus d?apprentissageaussi bien que du corpus de test.
En somme, ?iNappri = 754.
En moyenne, chaque article decorpus d?apprentissage a :mean(Nappr) = 5.386 ; median(Nappr) = 5;min(Nappr) = 1;max(Nappr) = 13; sd(Nappr) = 1.344Etant donn?
que ?iNappri > Tappr , il est ?vident qu?il y a des termes qui sont d?finis comme motscl?s pour plusieurs articles.
Le principe de bijection 1 terme ?
1 article n?est pas donc applicable.Plus pr?cis?ment, pour le corpus d?apprentissage, 604 mots cl?s sont associ?s ?
un seul article,46 en sont associ?s ?
deux, 10 ?
trois, quatre mots cl?s (i.e.
?
identit?
?, ?
interpr?tation ?, ?enseignement de la traduction ?, ?
traduction ?)
sont chacun associ?s ?
quatre articles, tandis quele terme ?
humanitaire ?
est d?fini comme mot cl?
pour cinq articles et le terme ?
mondialisation ?pour sept articles.On note aussi que parmi 62 termes qui sont associ?s ?
plus qu?un article, seulement 26 (i.e.41,9%) sont associ?s aux articles appartenants ?
plus qu?une revue.Les analyses fr?quentielles pr?liminaires montrent aussi que dans 141 parmi 740 cas, le mot cl?ne se trouve pas dans le corps ni r?sum?
d?article auquel il est associ?.
En d?autres termes, pourplus que 19% des mots cl?s, la fr?quence de leur occurrence dans l?article est z?ro, c?est doncplus qu?
?vident qu?il faut aller au-del?
des fr?quences ?
brutes ?
si on veut que notre syst?med?extraction des mots cl?s ait la pr?cision > 80% (la Figure 1 montre les fr?quences d?occurrencedes mots-cl?s dans les documents associ?s).L?objectif de la Piste 1 est donc de concevoir le syst?me qui, partant de fichiers de corpusd?apprentissage contenant Dappr ?
Tappr = 140 * 666 = 93240 couplages (document, terme)serait capable ?
d?terminer les couples ayant ?t?
?tablis par les auteurs de leurs documents.2.1.2 Piste 2Le corpus d?apprentissage contient 142 documents.
Contrairement ?
la Piste 1, aucune listeterminologique n?est fournie, l?espace de recherche dans lequel on cherche les candidats cens?d?
?tre les mots cl?s est donc beaucoup plus grande.
Mais les quantit?
des mots cl?s associ?sau diff?rents articles sont pr?sents.
Gr?ce ?
ces quantit?s fournis dans la balise <nombre> desdocuments XML, on sait sans regarder au fichier de r?f?rence que la distribution de ?iNappri = 76379FIGURE 1 ?
Cca 19% (en rouge) des mots cl?s de corpus d?apprentissage ne figurent pas dans lesdocuments auxquels ils sont attribu?sassociations entre mots cl?s et articles dispose de propri?t?s suivantes :mean(Nappr) = 5.411;median(Nappr) = 5;min(Nappr) = 3;max(Nappr) = 13; sd(Nappr) = 1.404.L?analyse de fichier de r?f?rence r?v?le que parmi 681 termes qui couvrent l?ensemble de tousles mots cl?s du corpus d?apprentissage de piste2 , 627 en sont associ?s ?
un seul article, 37 ?deux, 12 ?
trois, deux termes ?
(?
humanitaire ?
et ?
didactique ?)
?
quatre articles, les termes ?identit?
?
et ?
culture ?
?tant associ?
?
cinq articles et le terme ?
traduction ?
?
huit documents.
?tant donn?
que l?information concernant l?appartenance d?un article ?
une revue est pr?sente,on sait aussi que parmi 54 termes associ?s ?
plus qu?un article, seulement 18 (i.e.
33.3%) sontassoci?s ?
plus qu?une revue.L?analyse des fr?quences de mots cl?s dans les articles associ?s donne les r?sultats qui vont dansle m?me sens que ceux de la Piste 1 : dans 145 cas (19%), les mots cl?s n?appara?ssent pas dansl?article auquel ils ?taient associ?s !2.2 Statistiques g?n?rales du corpus de test2.2.1 Piste 1Le corpus de test de la Piste 1 contient Dtest = 94 documents dans .
La liste terminologique ducorpus de test contient 478 termes uniques.
Parmi ces 478 termes-candidats, 435 en sont associ?savec un seul document, 34 aux deux documents diff?rentes, quatre termes sont associ?s auxtrois articles, et quatre termes aux quatre articles, le terme le plus r?ussi comme mot cl?
?tant ?identit?
?
lui-m?me associ?
au six articles.
Parmi les 43 termes associ?s ?
plus d?un article, 20(i.e.
46,5%) sont associ?s aux articles appartenants ?
plus d?une revue.La distribution de la somme du nombre des mots cl?s associ?s aux articles du corpus de test de la80Piste 1 ( ?iNtest i = 537) dispose de propri?t?s suivantes :mean(Ntest) = 5.712;median(Ntest) = 5;min(Ntest) = 1;max(Ntest) = 12; sd(Ntest) = 1.701.2.2.2 Piste 2La distribution de ?iNtest i = 484 mots cl?s attribu?s aux 93 documents contenus dans le corpusde test de la Piste 2 est caract?ris?
par les mesures suivantes :mean(Ntest) = 5.204;median(Ntest) = 5;min(Ntest) = 2;max(Ntest) = 10; sd(Ntest) = 1.323.La consultation des fichiers de r?f?rence obtenus apr?s la fin de la phase competitive de DEFT2012nous permets ?
savoir que parmi 35 termes associ?s ?
plus qu?un article, seulement 10 (i.e.
28,6%)sont associ?s aux articles appartenants ?
plus d?une revue.2.3 Que peut-on apprendre d?autre du corpus ?Un rapide parcours du corpus de d?apprentissage et de la terminologie fournie pour la Piste 1,nous montre qu?au del?
des fr?quences, les mots-cl?
choisis par les auteurs respectent quelquesr?gles :?
les mots-cl?s sont diff?rents entre eux : les auteurs n?utilisent que rarement des mots-cl?s tr?sproches ;?
ils sont assez souvent repris dans l?introduction et la conclusion de l?article ;?
leur cat?gorie morphosyntaxique ou grammaticale est tr?s rarement ?
verbale ?, les mot-cl?sles plus utilis?s sont des noms (communs ou propres), des adjectifs ou des groupes nominaux ;Par ailleurs, comme on pouvait s?y attendre les mots-cl?s sont fortement li?s s?mantiquement audocument, comme le montre la figure 2 :FIGURE 2 ?
Similarit?s document-mots-cl?s (min, max, mean) vs. document-terminologie (mean)813 Espaces s?mantiquesLes mod?les de repr?sentation vectorielle de la s?mantique des mots sont une famille de mod?lesqui repr?sentent la similarit?
s?mantique entre les mots en fonction de l?environnement textueldans lequel ces mots apparaissent.
La distribution de co-occurrence des mots dans le corpus estrassembl?e, analys?e puis transform?e en espace s?mantique dans lequel les mots sont repr?sent?scomme des vecteurs dans un espace vectoriel de grande dimension.
LSA (Landauer et Dumais,1997), HAL (Lund et Burgess, 1996) et RI (Kanerva et al, 2000) en sont quelques exemples.
Cesmod?les sont bas?s sur l?hypoth?se distributionnelle de (Harris, 1968) qui affirme que les motsqui apparaissent dans des contextes similaires ont un sens similaire.
La caract?risation de l?unit?de contexte est une probl?matique commune ?
toutes ces m?thodes, sa d?finition est diff?rentesuivant les mod?les.
Par exemple, LSA construit une matrice mot-document dans laquelle chaquecellule ai j contient la fr?quence d?un mot i dans une unit?
de contexte j. HAL d?finit une fen?treflottante de n mots qui parcourt chaque mot du corpus, puis construit une matrice mot-mot danslaquelle chaque cellule ai j contient la fr?quence ?
laquelle un mot i co-occure avec un mot jdans la fen?tre pr?c?demment d?finie.Diff?rentes m?thodes math?matiques permettant d?extraire la signification des concepts, enr?duisant la dimensionnalit?
de l?espace de co-occurence, sont appliqu?es ?
la distributiondes fr?quences stock?es dans la matrice mot-document ou mot-mot.
Le premier objectif deces traitements math?matiques est d?extraire les ?patrons?
qui rendent compte des variationsde fr?quences et qui permettent d?
?liminer ce qui peut ?tre consid?r?
comme du ?
bruit ?.LSA emploie une m?thode g?n?rale de d?composition lin?aire d?une matrice en composantesind?pendantes : la d?composition de valeur singuli?re (SVD).
Dans HAL la dimension de l?espaceest r?duite en maintenant un nombre restreint de composantes principales de la matrice deco-occurrence.
?
la fin de ce processus de r?duction de dimensionnalit?, la similitude entre deuxmots peut ?tre calcul?e selon diff?rentes m?thodes.
Classiquement, la valeur du cosinus de l?angleentre deux vecteurs correspondant ?
deux mots ou ?
deux groupes de mots est calcul?e afind?approximer leur similarit?
s?mantique.3.1 Reflective Random IndexingLa m?thode de construction d?espace s?mantique utilis?e est Reflective Random Indexing (RRI)(Cohen et al, 2010a), c?est une nouvelle m?thode de construction d?espaces s?mantiques bas?esur la projection al?atoire qui est assez diff?rente des autres m?thodes de construction d?espacess?mantiques.
Ses particularit?s sont (i) qu?elle ne construit pas de matrice de co-occurrenceet (ii) qu?elle ne n?cessite pas, contrairement aux autres mod?les vectoriels de repr?sentations?mantique, des traitements statistiques lourds comme la SVD pour LSA.
RRI est bas?e sur laprojection al?atoire (Vempala, 2004; Bingham et Mannila, 2001), qui permet un meilleur passage?
l?
?chelle pour grand nombre des documents.
La construction d?un espace s?mantique avec RRIse d?roule comme suit :?
Cr?er une matrice A(d ?
n), contenant des vecteurs indexes, o?
d est le nombre de documentsou de contextes et n le nombre de dimensions choisies par l?exp?rimentateur.
Les vecteursindexes sont des vecteurs creux g?n?r?s al?atoirement.?
Cr?er une matrice B(t ?
n), contenant des vecteurs termes, o?
t est le nombre de termesdiff?rents dans le corpus.
Initialiser tous ces vecteurs avec des valeurs nulles pour d?marrer la82construction de l?espace s?mantique.?
Pour tout document du corpus, chaque fois qu?un terme ?
appara?t dans un document ?,accumuler le vecteur index de ?
au vecteur terme de ?.?
la fin du processus, les vecteurs termes qui appara?ssent dans des contextes similaires ontaccumul?
des vecteurs indexes similaire.L?aspect ?
Reflective ?
dans RRI consiste ?
rejouer plusieurs cycles des trois ?tapes de l?algorithmenon plus ?
partir de vecteurs al?atoires mais ?
partir des vecteurs indexes obtenues pourles documents.
Ces cycles permettent de gommer l?aspect al?atoire de l?espace, le syst?meconvergeant g?n?ralement au bout d?un nombre r?duit de cycles.3.1.1 Semantic VectorsPlusieurs impl?mentations libre de RRI sont disponibles, nous utilisons la librairie SemanticVectors 1 (Widdows et Cohen, 2010).
Semantic Vectors pr?sente un certain nombre d?avantagespar rapport aux autres librairies impl?mentant RRI, en particulier, parce qu?il offre, d?une part,une impl?mentation de RRI bas?
sur des indexes positionnels (Cohen et al, 2010a) qui construitl?espace s?mantique non plus en se basant sur les occurrences d?un terme dans un documentmais dans une fen?tre glissante ?
la mani?re de HAL, cette version de RRI permet de captureroutre les informations sur la s?mantiques des termes, des informations structurelles sur leurproximit?.
D?autre part, Semantic Vectors implante un certain nombre de mesures de similarit?entre des groupes de mots, en particulier (i) la ?
disjonction quantique ?
(Cohen et al, 2010b)qui permet de construire un volume correspondant ?
plusieurs termes dans l?espace s?mantiqueet de calculer la distance entre ce volume et d?autres termes ou documents de l?espace ; (ii) ?similarit?
tensorielle ?
qui prend en entr?e une suite ordonn?e de termes et calcule sa similarit?avec d?autres suites ordonn?es, exploitant ainsi les informations d?ordre provenant des indexespositionnels.Semantic Vectors est utilis?
dans nombre d?applications.
Nous l?avons utilis?
dans nos partici-pations au DEFT depuis l?
?dition 2009.
Dans des t?ches proches de celle qui nous occupe, lalibrairie a ?t?
utilis?e pour comparer RRI ?
d?autres m?thodes d?espaces s?mantiques pour larecherche de relations entre termes dans un corpus (Rangan, 2011).3.2 Enrichir les espaces s?mantiques avec des informations linguistiquesDans le probl?me d?attributions de mots-cl?s ?
un texte, les termes utilis?s comme mots-cl?ssont, pour une partie d?entre-eux, des groupes de mots.
La s?mantique associ?e ?
un groupe demots dans espace s?mantiques n?est pas aussi pr?cise que celle associ?
?
un mot : elle comprenddes composantes de ce mots dans d?autres contextes.
Pour pouvoir traiter la s?mantique deces groupes de mots, certaines m?thodes de repr?sentation du sens en espaces s?mantiquestelles que BEAGLE (Jones et Mewhort, 2007), PSI (Cohen et al, 2009), ou encore RRI avec desindexes positionnels (Cohen et al, 2010b; Widdows et Cohen, 2010), permettent d?encoder lesinformations sur l?ordre des mots.
Nous avons voulu tester une autre m?thode bas?e sur uneanalyse linguistique de surface du texte.1.
http://code.google.com/p/semanticvectors/83Le principe de cette m?thode est d?identifier des groupes de mots candidats dans le texte viaune phase de chunking (Abney, 1991) puis de construire des classes d?
?quivalence de chunksqui regroupent une majorit?
de mots identiques (apr?s lemmatisation des mots) et qui sonts?mantiquement proches - en se basant sur la s?mantique, dans un espace s?mantique ?classique?,des mots qu?ils contiennent -.
Le corpus est alors transform?
en rempla?ant tous les chunks d?unem?me classe d?
?quivalence par un repr?sentant de la classe et un nouvel espace s?mantique estconstruit ?
partir de ce nouveau corpus, dans cet espace les repr?sentants des classes de chunkssont consid?r?s comme des mots.Pour les besoins de la Piste 1, le chunker a ?t?
entrain?
pour consid?rer comme chunk tousles mots-cl?s compos?s de la terminologie fournie.
Dans la Piste 2 ce m?me chunker, ainsi quela proc?dure de construction de classes de chunks, sont utilis?s pour construire une liste demots-cl?s candidats.4 Affectation de mots-cl?s comme proc?dure de d?cisionmixte4.1 R?seau Bay?sien pour l?affectation de mots-cl?sEn analysant un corpus d?articles, nous cherchons, dans un premier temps, ?
d?terminer la tailledes diff?rents mots-cl?s rattach?s ?
un article donn?.
Dans un second temps, nous nous effor?onsd?
?tablir les probabilit?s d?appartenance de ces mots-cl?s ?
une liste pr?-?tablie.
Nous disposonspour chaque document du corpus des informations suivantes :?
les longueurs du r?sum?
l et du texte L ;?
la revue R dans laquelle l?article est paru ;?
le nombre de mots-cl?s n et leurs tailles respectives n1, .
.
.
, nn (ie le nombre de mots lescomposant) ;?
les similarit?s avec la totalit?
du lexique des mots-cl?s (d1, .
.
.
, dN ) (N taille de la terminologie) ;?
les mots-cl?s (kw1, .
.
.
, kwn).Il s?agit donc de trouver des relations entre les variables exog?nes (l, L, R, n, d1, .
.
.
, dN ) permet-tant de pr?voir le comportement des variables endog?nes (n1, .
.
.
, nn, kw1, .
.
.
, kwn).
A cette fin,il faut disposer d?un formalisme de mod?lisation des connaissances adapt?.
Les r?seaux bay?-siens (Barber, 2012), ?tant des mod?les graphiques auxquels sont associ?es des repr?sentationsprobabilistes sous-jacentes, apparaissent comme particuli?rement adapt?s ?
notre cas d?
?tude.Un r?seau bay?sien B est un couple (G,?)
o?
G est un graphe acyclique dirig?
dont les noeudsrepr?sentent un ensemble de variables al?atoires X = {X1, .
.
.
, Xn} et ?i = [P(X i/C(X i))] est lamatrice des probabilit?s conditionnelles du n?ud i connaissant l?
?tat de ses parents C(X i).L?int?r?t des r?seaux bay?siens est donc que leurs structures graphique et probabiliste permettentde prendre en charge une repr?sentation modulaire des connaissances, une interpr?tation ?
lafois quantitative et qualitative des donn?es.
En effet, le graphe d?un r?seau bay?sien permet ainside repr?senter sch?matiquement les relations entre les variables du syst?me ?
mod?liser et lesdistributions de probabilit?s, elles, permettent de quantifier ces relations.84Le mod?le que l?on se propose de construire est un r?seau bay?sien ?
variables discr?tes (lenom de la revue R, les mots-cl?s kwi , leur nombre n, leurs tailles ni) et ?
variables continues(longueurs du r?sum?
l, de l?article L et les similarit?
?
la terminologie).
C?est un mod?lemixte, appel?
mod?le conditionnel gaussien, pour lequel la distribution des variables continuesconditionnellement aux variables discr?tes est une gaussienne multivari?e.
Cela implique qu?ilpeut y avoir des arcs partant de noeuds discrets vers des noeuds continus, mais pas l?inversehormis pour le cas o?
les noeuds continus sont observables (ce qui est notre cas).
Notons?galement que le nombre de variables n1, .
.
.
, nn et kw1, .
.
.
, kwn varie selon le nombre de mots-cl?s n ; le nombre de noeuds dans un r?seau bay?sien ?tant fixe, nous nous proposons de posern1, .
.
.
, n25, les tailles des diff?rents mots-cl?s avec ni = 0 si i > n et kw1, .
.
.
, kw25 les diff?rentsmots-cl?s avec kwi = NU LL si i > n.Pour r?sumer nous disposons des variables al?atoires suivantes repr?sent?es par les noeuds dur?seau bay?sien que l?on cherche ?
construire :?
R, le nom de la revue (variable discr?te pouvant prendre 4 valeurs) ;?
l, la longueur du r?sum?
(variable continue) ;?
L, la longueur de l?article (variable continue) ;?
n, le nombre de mots-cl?s (variable discr?te pouvant prendre 25 valeurs) ;?
n1, .
.
.
, n25, la taille des mots-cl?s (variable discr?te pouvant prendre 11 valeurs) ;?
d1, .
.
.
, d1062, les similarit?s ?
l?ensemble des mots-cl?s (variable continue) ;?
kw1, .
.
.
, kw25, les mots-cl?s (variable discr?te pouvant prendre 1062 valeurs).L?observation des distributions des documents entre les diff?rentes revues nous permet d?affirmerque celles-ci sont similaires dans le corpus d?apprentissage et celui de test ; ce qui implique que lebiais qu?introduit cette distribution n?impactera pas les performances du mod?le ?
construire.Les moyennes des longueurs de r?sum?
l et d?article L pr?sentent le m?me ordre de grandeur.Ces moyennes ne sont certes pas similaires dans le corpus d?apprentissage et celui de test, maiselles sont distribu?es de la m?me mani?re, ie que les longueurs de r?sum?
(respectivementd?article) sont ?gales dans le corpus d?apprentissage et dans celui de test au m?me facteur pr?s.Notons ?galement que les longueurs d?article et de r?sum?
ne sont pas distribu?es de la m?memani?re ; cela veut dire qu?en plus de la relation directe ?vidente entre ces deux variables, ilexiste probablement une cause commune aux deux, ce qui se traduit dans la structure du r?seaubay?sien par la pr?sence d?un parent commun.Les distributions des nombres de mots par article (respectivement par r?sum?)
peuvent ?treapproxim?es par des m?langes de gaussiennes.
Ces histogrammes sont similaires pour le corpusentier et pour celui d?apprentissage.
Ce qui nous montre que l?
?chantillon ?tudi?
peut ?treconsid?r?
comme repr?sentatif du probl?me.
Toutefois, la relative disparit?
observ?e entre lecorpus de test et celui d?apprentissage cr?era probablement un probl?me de biais qu?il faudraprendre en compte durant la construction du mod?le.Les histogrammes des nombres de mots par article (respectivement par r?sum?)
repr?sentent pourles diff?rentes revues des distributions diff?rentes.
Ces variables sont donc directement reli?es ?la nature de la revue.
Ces diff?rentes distributions ont des formes quelconques, cependant, nousremarquons que l?on pourra les approximer par un m?lange de gaussiennes ; ce qui nous confortedans le choix d?un mod?le conditionnel gaussien pour repr?senter ces variables dans un r?seaubay?sien.85En observant la monotonie des moyennes des similarit?s ?
la terminologie des mots-cl?s surles diff?rentes parties du corpus, nous remarquons qu?elle pr?sente la m?me allure (et m?mequasiment le m?me trac?)
dans tous les cas (corpus entier, corpus d?apprentissage, revue enparticulier, .
.
.
).
Cela nous permet de supposer que la s?lection de mots-cl?s se fait strictementde la m?me mani?re partout, et donc l?id?e d?en faire un mod?le math?matique est parfaitementcoh?rente.Sur la base de ces diff?rentes observations, prenons un exemple de structure de r?seau bay?sienreliant les variables de notre probl?me.
Par convention, les variables discr?tes sont repr?sent?espar des noeuds carr?s, les variables continues par des noeuds ronds et les variables observablespar des noeuds ombr?s (figure 3).FIGURE 3 ?
Structure du r?seau bay?sien appris sur le corpus4.2 Combiner des d?cisions statistiques avec du raisonnement ?
base der?glesLes r?cents travaux en intelligence artificielle sur la combinaison de m?thodes de d?cisionstatistiques et de raisonnement ?
base de r?gles de production, comme les R?gles de ProductionProbabilistes (PPR) de (A?t-Kaci et Bonnard, 2011), nous offrent un cadre pour mod?liser uneproc?dure de d?cision qui prend en compte ce qui est appris par le r?seau bay?sien d?critci-dessus, et les connaissances symboliques encod?es dans les r?gles sur le choix des mots-cl?sdont nous avons donn?
des exemples en 2.3.86Le principe de fonctionnement du syst?me de d?cision, construit en se basant sur PPR, est decalculer un score pour chacun des mots-cl?s pour un document donn?.
Ce calcul est r?alis?
enutilisant des r?gles pouvant faire appel au r?seau bay?sien.
Par exemple, la r?gle ?les mots-cl?ssont diff?rents entre eux?
peut se traduire par la r?gle production ?si deux mots-cl?s sont prochesalors augmenter le score de celui qui est le plus haute probabilit?
d?
?tre un mot-cl?
du document etr?duire l?autre?
qui s?
?crit :IF similarity(kw1, kw2) > seuil AND bnproba(kw1|doc) > bnproba(kw2|doc)THEN increase-score(kw1, doc) AND decrease-score(kw2, doc)Le syst?me de r?gles que nous avons utilis?
contient une quinzaine de r?gles.
Nous ne pouvonspas les d?tailler ici par manque de place.5 Les ex?cutions soumisesLa table 1 r?sume les ex?cutions soumises par notre ?quipe.
Ses r?sultats sont tr?s satisfaisantspour toutes les approches que nous avons utilis?.
La moyenne de F-score pour la Piste 1 pourl?ensemble des participants ?tant de 0,3575 et pour la Piste 2 de 0,2045.
On notera que lespremi?res ex?cutions pour les deux pistes (1.1 et 2.1) qui sont nos ex?cutions de base donnentdes r?sultats corrects en des temps relativement bas.Run Precision Rappel F-score Temps (en s)1.1 0.4618 0.4618 0.4618 21.2 0.9479 0.9497 0.9483 75901.3 0.7486 0.7486 0.7486 -2.1 0.2438 0.2438 0.2438 262.2 0.3471 0.3471 0.3471 2692.3 0.5879 0.5867 0.5873 12700TABLE 1 ?
R?sultats soumis : performance et temps d?
?xecution5.1 Piste 15.1.1 Run 1.1 ?
baseline : RRI et k-NNDans cette ex?cution qui constitue notre baseline, nous avons construit un espace s?mantiqueRRI avec l?ensemble des documents du corpus (appr + test), un document ?tant constitu?
par laconcat?nation du r?sum?
et du corps de l?article.
Puis pour chaque document d du corpus de test,nous avons retenu comme mots-cl?s les k plus proches voisins du document dans la terminologie,k ?tant le nombre de mots-cl?s pour le document d. Le vecteur pour un mot-cl?
kwi compos?des mots w1, ..., wn ?tant obtenu en sommant les vecteurs des mots qu?il contient.~kwi = ?i ~wi (1)875.1.2 Run 1.2 ?
RRI(chunks), BN et r?glesDans cette ex?cution, qui a obtenu le meilleur r?sultat, nous avons construit un espace s?mantique?enrichi?
comme nous l?avons d?crit dans la section 3.2, mais dans lequel un document ?taitrepr?sent?
par quatre vecteurs, un pour le r?sum?, un pour le corps de l?article et deux vecteurspour le premier et le dernier paragraphe de l?article (que nous avons pris comme approximationde l?introduction et la conclusion) .
Nous avons ensuite appris le r?seau bay?sien d?crit en 4.1en utilisant les distances entres les documents et les mots-cl?s obtenues sur cet espace.
Enfin,nous avons utilis?
la proc?dure de d?cision d?crite en 4.2 pour affecter un score ?
chacun desmots-cl?s, les mots-cl?s retenus sont les k ayant les plus hauts scores (k ?tant le nombre demots-cl?s pour le document).5.1.3 Run 1.3Dans le cadre de ce run, on a combin?
les r?sultats de run 1 et run 2, en donnant une l?g?repr?f?rence aux candidates-termes lesquels sont plus longues que d?autres termes-candidates.
Ona donc combin?, par exemple, les termes-candidates de run1 :Catalogne ; Narotzky ; conflit ; contexte ;district industriel ; femmes ; productiontraductionnelle ; production ?crite ; r?seauavec les termes-candidates de run 2 :Espagne ; Narotzky ; anthropologie ?conomique ; district industriel ; f?minisme ;histoire ; r?seaux de production ; ?conomie politique ; ?conomie r?gionalepour obtenir la liste des candidates de run3 :district industriel ; r?seaux de production ; ?conomie politique ; production traduc-tionnelle ; anthropologie ?conomique ; Narotzky ; ?conomie r?gionale ; production ?crite ;f?minismeLe score du candidat ?tait calcul?
par la formule :score = Fr ?
(l ?
Fa) (2)o?
Fr est la fr?quence relative du terme-candidat dans l?article analys?, Fa est la fr?quenceabsolue du terme-candidat dans tous les articles du corpus et l est le nombre de caract?res duterme-candidat.5.2 Piste 25.2.1 Run 2.1 ?
baseline : RRI et k-NNCette ex?cution est identique ?
la premi?re ex?cution de la Piste 1 5.1.1, la terminologie obtenuepar la m?thode d?crite en 3.2 contient 3000 candidats mots-cl?s.885.2.2 Run 2.2 ?
RRI(PositionalIndex), Tensor Similarity et k-NNDans cette deuxi?me ex?cution, nous avons utilis?
la m?me terminologie que pour 2.1, maisl?espace s?mantique a ?t?
construit en utilisant RRI sur des indexes positionnels.
Le calcul desvecteurs de mots-cl?s utilise l?op?rateur Tensoriel de Semantic Vectors.
Les mots-cl?s retenuspour un document d sont les k plus proches voisins du document d dans la terminologie, k ?tantle nombre de mots-cl?s pour le document d.5.2.3 Run 2.3 ?
RRI(chunks), BN et r?glesCette ex?cution est identique ?
la deuxi?me ex?cution de la Piste 1 d?crite en 5.1.2, la ter-minologie obtenu par la m?thode d?crite en 3.2 ?
laquelle on ajout?
les mots-cl?s du corpusd?apprentissage elle contenaint 3270 candidats mots-cl?s.5.3 DiscussionNous pouvons voir que les ex?cutions 1.2 et 2.3 sont celles qui obtiennent les meilleurs r?sultats,ce qui nous conforte dans nos hypoth?ses de d?part.
Les ex?cutions officielles nous ne permettentpas de comparer les performances des espaces ?enrichis?
par des chunks et des espaces RRI avecindexes positionnels, nous avons effectu?
une ex?cution 2.2bis avec un espace ?enrichi?
et k-NNle F-score obtenu est de 0.4186, le r?sultat est sensiblement meilleur que l?ex?cution 2.2.Rappelons que pour le 1.3, on a combin?
les r?sultats de 1.1 et 1.2 de en donnant plus de poidsaux candidates-termes longues (cette r?gle n?ayant pas ?t?
incluse dans le syst?me de r?glesd?crit en 4.2 ).
Etant donn?
que le F-score obtenu (0.7486) se trouve au mi-chemin entre leF-score de 1.1 et de 1.2, nous ne pouvons pas r?ellement conclure quand ?
la pertinence de cetter?gle.ConslusionDans cet article, nous avons pr?sent?
un syst?me d?attribution de mots-cl?s ?
des articles scien-tifiques, qui se base sur des espaces s?mantiques construit en utilisant RRI.
Puis nous avonsessay?
d?am?liorer les performances du syst?mes par deux moyens : (i) en enrichissant lesespaces s?mantiques par des informations issues d?une analyse linguistique de surface, et (ii)en d?finissant une proc?dure de d?cision bas?e sur une combinaison de r?seaux bay?siens etde syst?mes ?
base de r?gles.
Les r?sultats obtenus montrent que ces deux hypoth?ses se sontr?v?l?es payantes et qu?elles am?liorent sensiblement les r?sultats obtenus par une approche RRIseul (qui obtient d?j?
des r?sultats honorables).89R?f?rencesABNEY, S. (1991).
Principle-Based Parsing, chapitre Parsing By Chunks.
Kluwer AcademicPublishers.A?T-KACI, H. et BONNARD, P. (2011).
Probabilistic production rules.
Rapport technique, IBM.BARBER, D. (2012).
Bayesian Reasoning and Machine Learning.
Cambridge University Press.BINGHAM, E. et MANNILA, H. (2001).
Random projection in dimensionality reduction : Applica-tions to image and text data.
In in Knowledge Discovery and Data Mining, pages 245?250.
ACMPress.COHEN, T., SCHVANEVELDT, R. et RINDLESCH, T. (2009).
Predication-based semantic indexing :Permutations as a means to encode predications in semantic space.
In Proceedings of the AMIAAnnual Symposium, pages 114?118.COHEN, T., SCHVANEVELDT, R. et WIDDOWS, D. (2010a).
Reflective random indexing and indirectinference : A scalable method for the discovery of implicit connections.
Biomed Inform, 43(2):240?256.COHEN, T., WIDDOWS, D., SCHVANEVELDT, R. et RINDLESCH, T. (2010b).
Logical leaps and quantumconnectives : Forging paths through predication space.
In Proceedings of the AAAI Fall 2010symposium on Quantum Informatics for cognitive, social and semantic processes (QI-2010).EL GHALI, A.
(2011).
Exp?rimentations autour des espaces s?mantiques hybrides.
In Actes del?atelier DEFT?2011, Montpellier.HARRIS, Z.
(1968).
Mathematical Structures of Language.
John Wiley and Son, New York.JONES, M. N. et MEWHORT, D. J. K. (2007).
Representing word meaning and order informationin a composite holographic lexicon.
Psychological Review, 114(1):1?37.KANERVA, P., KRISTOFERSON, J. et HOLST, A.
(2000).
Random Indexing of Text Samples forLatent Semantic Analysis.
In GLEITMAN, L. et JOSH, A., ?diteurs : Proceedings of the 22nd AnnualConference of the Cognitive Science Society, Mahwah.
Lawrence Erlbaum Associates.LANDAUER, T. K. et DUMAIS, S. T. (1997).
A Solution to Plato?s Problem : The Latent SemanticAnalysis Theory of Acquisition, Induction and Representation of Knowledge.
PsychologicalReview, 104(2):211?240.LUND, K. et BURGESS, C. (1996).
Producing high-dimensional semantic space from lexicalco-occurence.
Behavior research methods, instruments & computers, 28(2):203?208.RANGAN, V. (2011).
Discovery of related terms in a corpus using reflective random indexing.
InProceedings of Workshop on Setting Standards for Searching Electronically Stored Information InDiscovery Proceedings (DESI-4).SAHLGREN, M. (2006).
The Word-Space Model : Using distributional analysis to represent syn-tagmatic and paradigmatic relations between words in high-dimensional vector spaces.
Th?se dedoctorat, Department of Linguistics Stockholm University.VEMPALA, S. S. (2004).
The Random Projection Method, volume 65 de DIMACS Series in DiscreteMathematics and Theoretical Computer Science.
American Mathematical Society.WIDDOWS, D. et COHEN, T. (2010).
The semantic vectors package : New algorithms and publictools for distributional semantics.
In Proceedings of the Fourth IEEE International Conference onSemantic Computing (IEEE ICSC2010).90
