The Autonomy of Shallow Lexical KnowledgeKathleen DahlgrenIntelligent Text Processing, Inc.1310 Montana Avenue Suite ~01Santa Monica, CA 90403internet: 7~550.1670@compuserve.com213-576-4910AbstractThe question of what is "purely linguistic" is considered in relation to the problemof modularity.
A model is proposed in which parsing has access to world knowledge,and both contribute to the construction of a discourse model.
The lexical semantictheory of naive semantics, which identifies word meanings with naive theories, andits use in computational text interpretation, demonstrate that a shallow, constrainedlayer of knowledge which is linguistic can be identified.1 Introduct ionMy work has involved both the development of a theory of lexical semantic representationand the implementation of a computational text understanding system which uses thislexicon to interpret English text (Dahlgren, 1976, Dahlgren, 1988, Dahlgren, McDowelland Stabler, 1989).
The question posed by the workshop is a theoretical one: is thereany justification for distinguishing between lexical semantics and world knowledge?
Myaffirmative answer is based upon both theory and practice.
Section I addresses the the-oretical issues and makes a claim, and Section II supports the claim with results fromcomputational linguistics.
The experience of developing a wide-coverage natural anguageunderstanding system suggests a methodology for distinguishing between lexical knowl-edge and knowledge in general.2 Theoret ical  Considerat ionsThe first question to consider is where and how the line is drawn between linguisticknowledge and knowledge in general.
Arguments from both psychology and theoreticallinguistics are relevant here.
Cognitive psychologist Fodor (1987) argues that linguisticknowledge is contained in a module which automatically (deterministically) processes thespeech input and produces a logic form without any access to other cognitive components.In this modularity hypothesis, other cognitive components have no access to the interme-diate representations produced in the linguistic module.
Its formal properties are thoughtto he the result of innate features of human intelligence.
It operates in a mandatory waywithout access to "central processes."
It does not "grade off insensibly into inference andappreciation of context" (19877).
One of the chief arguments for the autonomy of the lin-guistic model is the speed with which it must operate.
In contrast, inference is assumedto be open-ended and time-consuming.While many agree that syntax has special formal properties which indicate the exis-tence of a distinct module which operates under the constraints reflected in these formal264properties, its autonomy is controversial.
In particular, Marslen-Wilson and Tyler (1987)have conducted a number of experiments toshow that the production of a discourse modelwhich may require pragmatic knowledge is just as fast as the production of logical form,and that there is influence from the discourse level on syntactic hoice.
The experimentshowing the latter point involved a contrast between adjective and gerund readings of ex-pressions like "visiting relatives".
They had subjects read texts with either an adjectivalor gerund bias to establish a context, as in:Adjectival Bias: If you want a cheap holiday, visiting relatives ...Gerund Bias: If you have a spare bedroom, visiting relatives...They gave subjects a probe of "is" or "are" in these contexts.
Response times for "is"were significantly slower in the gerund bias context, and response times for "are" weresignificantly slower in the adjectival bias case.
Thus there are context effects at theearliest point that can be measured.
Since central processes are already demonstrablyactive during processing of the third word in these ambiguous clauses, Marslen-Wilsonand Tyler argue that the empirical facts are just as consistent with a model which "allowscontinuous or even predictive interactions between levels" as they are with a hypothesisin which an encapsulated module produces all possible readings for a higher-level modulewhich sorts them out using inference.
They suggest a model in which an independentsyntactic processor and an inferencing mechanism contribute inparallel to the constructionof a discourse model.
Where syntax fails to determine an element unambiguously, theinferencing mechanism fills the gap or makes the choice.Let us assume a Marslen-Wilson type model in which pragmatics affects sentenceinterpretation a d disambiguation.
The pragmatics they consider anges from selectionalrestrictions to knowledge that visitors stay in spare bedrooms.
Whether or not thisknowledge is linguistic knowledge is a question for theoretical linguistics.
Is knowledgelinguistic only if it is an element of the machinery required for syntactic processing?Another possibility is that the world knowledge required for interpretation is restrictedin principled, predictable ways.
Such constraints would indicate a level or module respon-sible for providing just the information required for linguistic interpretation.
This couldbe called lexical semantic knowledge, as distinguishable from knowledge in general.
Aseparate issue is whether such knowledge has a form which is different from the cognitivemodels which are the output of linguistic interpretation or from memory.
It is possiblethat lexical semantics could provide the world knowledge necessary for interpretation viaa specialized formal anguage, or via representations which are employed in other typesof inference.
My claim is that there is an identifiable, constrained layer of linguistic se-mantic knowledge, but that its form does not differ from the form of general conceptualknowledge.Evidence for constraints upon the world knowledge used during sentence processingcomes from both psycholinguistic research and my own work in computational linguistcs.The protracted ebate over the existence of semantic primitives resulted in their ultimaterejection and provided evidence that lexical knowledge does not differ from other knowl-edge in form of representation.
Addressing first the question of form, I will sketch thedebate and its outcome.The classical theory of word meaning decomposed words into semantic primitives whichhad the force of truth conditions.
The word water meant "clear, tasteless, liquid".
Asentence such as "That is water" was true only of a substance for which the predicates"clear", "tasteless" and "liquid" were true.
The implication was that word meanings were265required to have the force of scientific theories.
True sentences couldn't be uttered unlessthe speakers had knowledge of the true properties of objects.
This led Putnam (1975)and others to separate the theory of word meaning from the theory of reference.
Therelationship between sentences and states of the world sentences was given by a theory ofreference.
The theory of word meaning became a theory of the knowledge required to becompetent in a language, and this knowledge was of prototypes of objects.Convergent with this development in the philosophy of language, Rosch (1976) andother cognitive psychologists questioned the assumption that conceptual knowledge tookthe form of semantic primitives.
They found that categories have gradient properties,rather than the all-or-none membership redicted by the classical theory.
As a resultof these findings, the assumption that word meanings are decomposable into a smallfixed set of primitives has been rejected (Smith and Medin, 1981).
Where does thatleave lexical semantics?
Fillmore (1985) has proposed that word meanings are framesof default knowledge.
Recent studies in cognitive psychology show that some conceptsinvolve theories of the world (Murphy and Medin, 1985).
Building on these findings,Dahlgren (1988) suggests that word meanings are naive theories of objects and events.The theory of lexical semantics proposed in Dahlgren (1988), naive semantics, takeslexical representations a concepts.
A word names a concept, and also plays a role in adiscourse model which can be subjected to formal reasoning for purposes of determiningthe truth conditions of a discourse.
However, the concept the word names constitutesa naive theory of the objects of reference, so that reasoning with word meanings mustbe non-monotonic.
Furthermore, the naive theory has much more information in it thanwould be included in a representation formed from a stock of semantic primitives.
Thusthe representation of water includes information such as:Water is typically a clear liquid, you find it in rivers, you find it in streams,you drink it, you wash with it.Furthermore, the knowledge places objects in a classification scheme (or ontology)which is intended to correspond to English speakers' conceptions of distinctions uchas real versus abstract, and animate versus inanimate.
The scheme is based upon psy-cholinguistic evidence, the classes required to represent verb selection restrictions, andthe philosophical arguments concerning the distinction between sentients and all otherobjects.
Study of protocols from experiments in the prototype theory reveal patterns ofproperties in naive theories.
For example, artifacts have function, parts and operationfeatures, animals have habitat and behavior features, while roles have function and statusfeatures.
These patterns, called kind types, form constraints upon the feature types whichare evident at nodes in the ontology.Knowledge of verb meanings consists of the implications of events.
Cognitive psy-chological studies show that verbs are not conceived in terms of classes uch as motion,exchange, but rather in terms of the other events urrounding the event the verb denotes(Graesser and Clark, 1985, Trabasso and Sperry, 1985).
The typical causes, consequences,goals, instruments, locations of events are the main components of conceptual knowledgefor verbs.When word meanings are identified with conceptual knowledge, a proliferation of men-tal representational types in the semantic lexicon is predicted.
Color concepts have beenshown to relate directly to the organization of color perception.
Thus this theory predictsthat words naming colors have meanings which include mappings to color perceptors.Words naming foods have meanings which include taste representations, along with some266verbal elements.
Some words are fully represented in terms of other words.
(At this stageof computational linguistics, of course, we are in a position to represent only the verbalelements of word meanings.
)Thus the main assumptions of naive semantics are that words name concepts whichare naive theories of objects and events.
The content of these theories is not limitedto a set of primitive features.
Elements of meaning representations belong to a varietyof sensory types.
There is no difference in form between word meanings and cognitiverepresentations.So far, naive semantics seems most consistent with a model in which there is no dis-tinction between lexical semantics and world knowledge.
This is the view of Hobbs, et al(1986), as well as all of the computational linguistic theories which use frames and scriptsto encode domain knowledge.
In the Hobbs method all of the commonsense knowledgeassociated with a word is encoded.
For example, extremely detailed levels of naive physicsare represented with the expression "wear down".
However, experience with naive seman-tics in the development of a computational text understanding system indicates that anextremely shallow layer of knowledge is sufficient to provide the information for successfuldisambiguation a d anaphor esolution.
A theory which identifies word meanings as justthe knowledge needed for linguistic interpretation flows from this experience.Furthermore, a theory which constrains lexical semantic knowledge to a very shallowlayer would explain the real-time speed with which the discourse model is constructed.Fodor's fear of a universe of fridgeons is groundless.
Interpretation does not involve anendless chain of inferences, but instead employs ashort sequence of predictable inferences.This must be the case because cognitive psychologists have repeatedly demonstrated thatinferences are drawn during discourse interpretation, and we know that many of theseinferences are drawn in real time while hearing the utterance, rather than later.
McKoonand Ratcliff (1990) have conducted a series of experiments o tease out the differencesbetween the effects of discourse context and test questions in recall experiments, and totrace the time course of interpretive inferences.
The experiments separate the variables oftime and degree of familiarity of semantic information.
They have found that well-knowninformation contributes to interpretive inference within 250 ms of reading asentence, whileless-well-known i formation contributes only after 650 ms. One experiment involved thefollowing context sentence:The old man loved his granddaughter and she liked to help him with hisanimals; she volunteered to do the milking whenever she visited the farm.When subjects were asked to recognize the word "cow" as having occurred in the sentence,the effect of the typically highly familiar association between cows and milking was evidentwithin 250 ms.
However, when the association between the context and test word wasnot highly familiar, the effect was not observed.
Given the following sentence,The director and the cameraman were ready to shoot close-ups when suddenlythe actress fell from the 14th story.When subjects were asked to recognize the word "dead," the effect of context was notevident after 250 ms (though it was when subjects were given 650 ms).
This experimentshows that highly typical information with strong association to words is employed uringthe construction ofthe interpretation f a sentence (milking and cows).
Information whichrequires more inferencing is not employed uring the interpretation, but can be calledupon later (falling and death).
McKoon and Ratcliff conclude that "inferences mainly267establish local coherence among immediately available pieces of information and there isonly minimal encoding of other kinds of inferences."
These findings upport atheory whichisolates the highly associated, highly typical knowledge as linguistic semantic knowledge.Part of the explanation for the shallowness of interpretive inference lies in the cooper-ative principles of communication.
If a speaker doesn't believe a hearer shares a piece ofknowledge required for the interpretation, then the speaker will include that informationin the utterance.
Another part of the explanation for shallowness lies in the intuitionthat knowledge of one's language includes knowledge of the naive theories of other speak-ers of the language.
We know the culture-wide theory of certain objects, even when weare experts on those objects and have a completely different personal theory.
An ex-ample would be the word "computer", which is a keyboard, monitor and printer to thenon- technician, and is a central processing unit plus peripherals to the technician.
Thepoint is that technicians either know the naive theory, or they fail to communicate withnon-technicians.Thus my claim is that a shallow layer of commonsense knowledge is sufficient to dis-ambiguate and build a discourse model in real time.
Furthermore, this shallow layer hasa constrained range of feature types, if not of feature values.3 Experience with Naive Semantics in ComputationalText UnderstandingIn computational linguistic research, I have been involved in the development of a systemwhich reads and "understands" text sufficiently to answer questions about what the textsays and to extract data from the text.
The system contains interpretive algorithmswhich disambiguate he text, assign anaphors to antecedents, and connect events withcoherence inferences.
Each of these algorithms draws upon lexical semantic information.In the course of building the algorithms and testing them against corpora in three domains(geography, finance and terrorism), two results have emerged:1.
All of the algorithms use the same knowledge base of lexical information.2.
The algorithms succeed with only a very shallow layer of knowledge.In other words, the highly typical, strongly associated knowledge is the knowledgethat is used to build an interpretation f just what the text says, as McKoon and Ratclifffound, and this is confirmed in the application of a shallow layer of naive semantics todisambiguation a d discourse reasoning tasks.
This layer is sufficient for the followinginterpretive components:?
word sense disambiguation?
relative clause attachment disambiguation?
prepositional phrase attachment disambiguation?
nominal compound isambiguation?
anaphor esolution?
coherence relation assignment268Three of the components (word sense disambiguation, PP attachment and anaphorresolution) have been tested against large corpora of text, and have been found to preferthe correct interpretation i over 95% of the cases.
This statistical result is importantbecause it is always possible to find examples which require more knowledge than isincluded in the naive semantics.
The result shows that shallow layer of knowledge issufficient in all but a few real cases.
Again, the explanation for this sufficiency is that ifthe speaker believes that the hearer lacks an element of a naive theory, and that elementis necessary for interpretation, the speaker is obligated to express it.
Extrapolating to thenaive semantic representations for English, the conceptual information subjects producewhen asked to rapidly volunteer characteristics of objects and implications of events tendsto be shared across a subculture.
If information is not widely shared, speakers tend tostate it explicitly.
The use of naive semantic information containing only the sharedknowledge has resulted in broad success tatistically in the disambiguation a d discoursealgorithms; this would be the expected outcome if we assume that the writers of the testcorpora followed the cooperative principle.The text understanding system Interpretext has been under development for overfive years.
The early system parsed English text, producing one parse per sentence.This parse was then subjected to disambiguation algorithms which reformed the parseto correctly attach prepositional phrases and disambiguate word senses.
(At present weare building a new wide coverage parser which will use naive semantic information todisambiguate structure during the parse, reflecting adherence to a model in which theparser has access to and uses lexical semantics).
The formal semantic omponent ofthe system translates the disambiguated parse into a Discourse Representation Structure(DRS) (Kamp, 1981).
Each new sentence adds new predicates to the DRS.
A discoursereasoning module finds the antecedents of anaphors (Dahlgren, Lord and McDowell, 1990)and assigns coherence relations between discourse vents (Dahlgren, 1989).
The resultingrepresentation is a shallow cognitive model of the text content.
It represents only theinferences which must be drawn in order to ensure that one syntactic structure is selected,that word senses are disambiguated, that the individuals or events which are the sameare given the same reference markers, and that each discourse vent is connected to someother in the discourse.
The cognitive model is translated to first order logic, and thenceto Prolog.
Text retrieval is accomplished with a standard Prolog problem-solver.To illustrate the functioning of Interpretext, consider the following short text and thecognitive model produced by Interpretext (Figure 1).The parser produces a labelled bracketing for the first sentence which has the preposi-tional phrase "with terrorist attacks" attached to the noun phrase dominating "Guatemala".The disambiguation step finds that the prepositional phrase "with terrorist attacks" mod-ifies the verb "charge", rather than the object noun phrase.
In addition, word senses arechosen: the legal sense of "charge" rather than the monetary or physical senses, the socialsense of "treatment" rather than the medical sense, and the social sense of "attack" overthe physical or medical sense.
The formal semantic module translates the disambiguatedparse into a DRS.
The DRS has a set of reference markers, which stand for each of theentities and events or other abstract types which have been introduced into the discourse(el, al, etc., above), and a set of conditions, which stand for the relations and propertiesof these entities asserted by the discourse.
The DRS provides a framework for interpre-tation of discourse semantics, uch as pronoun resolution.
After parsing and semantictranslation of the second sentence, the anaphor esolution module identifies "they" withthe US rather than Guatemala or "attacks".
The coherence relation module assigns the269Guatemala was charged by the US with terrorist attacks.
They cited treatmentof suspected guerrillas.el,us,g,al,a2,e2,a3,rlcharge6(el,us,g)with(el,al)attacks(al)terrorist(al)cite(e2,us,a2)treatment(a2)of(a2,a3)guerrillas(a3)rl before nowel included in rle2 included in rlconstituency(e2,el)Figure 1: Sample DRS produced by Interpretextcoherence relation of "constituency" between the events in the two sentences, so that"citing" is seen as part of "charging".
Temporal equations place the charging and citingwithin the same time interval, rl.
The resulting representation is a cognitive model.
It is acollection of predicates derived from the text itself expressing the properties of the entitiesintroduced in the text, relations between them, and added inferred coherence relationsbetween the segments of the text.
All of the components of this analysis are presentlyprototyped and running in Prolog.
A number of implemented formal semantic treatmentssuch as the handling of plurals, modal contexts, questions, and negation are not shown inthe example.The naive semantics which is needed for the algorithms is limited to certain featuretypes.
In general, ontological knowledge is used everywhere, specially the sentient/non-sentient distinction.
This is because many verbs have selectional restrictions involvingsentients, and verb selectional restrictions are frequently in the disambiguation algorithmsas well as in anaphor resolution.
As for the generic knowledge for verbs, the "cause","goal", "consequence", and "instrument" features are used by all of the algorithms.
Fornouns, the features "function", "rolein", "partof", "haspart", "sex", "tool" and someothers are used by the algorithms, but others, like "exemplar" and "internal trait" arenot.Interpretext contains algorithms for structural and word sense disambiguation whichuse naive semantics.
In this section two algorithms are cited to illustrated the power ofshallow naive semantics in a computational text understanding task.
As explained above,all language understanding occurs in the context of some knowledge.
Within a subculturethere is a body of common knowledge that is shared among participants.
There is arelatively shallow layer of that common knowledge ("lexical semantic knowledge") whichthe hearer/reader mploys in discourse interpretation; this shallow knowledge is accessedas "default values" in the absence of relevant contextual information to the contrary.
Twoprocesses central to discourse interpretation are anaphor resolution and the structural270interpretation ofprepositional phrases.
The following examples illustrate the use of lexicalsemantic knowledge as a default in prepositional phrase disambiguation and anaphorresolution, iSentences with prepositional phrases are well-known for their multiple possibilities forsyntactic interpretation.
Consider:(1) Radio Marti reports that guerrillas are shooting villagers with Chineserifles.The complement clause is syntactically ambiguous.
Plausible interpretations for theprepositional phrase "with Chinese rifles" include:(la) Guerrillas are using rifles to shoot villagers.
(lb) Villagers who have Chinese rifles are being shot by guerrillas.If (1) is the first line of a news story, the most likely interpretation is (la).
People knowthat shooting is typically done with guns, and that guerrillas are probably more likely tohave guns than villagers are.
However, suppose the same clause occurs in another newsstory but in a different immediate linguistic context:(2) Radio Marti reports that Chinese rifles have been given to villagers coop-erating with the government.
In retaliation, guerrillas are shooting villagerswith Chinese rifles.Here the text tells the reader that villagers have rifles.
The immediate salience of thisfact overrides the general knowledge xpectation about who is more likely to have guns,making it more likely that the reader will choose interpretation (lb).
The default inter-pretation favors VP attachment for the prepositional phrase, but the context in (2) favorsNP attachment.
If a speaker/writer suspects that the hearer/reader might have difficultyinterpreting a message, the speaker/writer usually provides clarifying information accord-ing to a principle of cooperation i discourse.
Consequently, where a correct interpretationgoes against he expected efault interpretation, there are usually contextual cues.
In (2),the first sentence "sets the stage" so that the VP attachment default is overridden.These assumptions about lexical semantic knowledge and sentence interpretation arebuilt into the Interpretext system.
The idea that shooting is typically done with guns ispart of the naive semantic knowledge ncoded in the lexical entry for the verb "shoot".A rifle is identified as a gun, and a feature in the entry for "rifle" indicates that a typicaloperation performed with a rifle is shooting.
The knowledge that guerrillas typicallyuse guns is part of the naive semantic knowledge about guerrillas; the lexical entry for"villager" does not mention guns.
The representation of this shallow level of knowledgeis sufficient for the Interpretext system to choose interpretation (la), VP attachment, for(1).
This knowlege would also favor an incorrect VP attachment interpretation for (2),unless the system recognizes that, as a result of having been given rifles, the villagers nowhave them, and a discourse ntity of "villagers having Chinese rifles" is established andavailable for access in the next sentence.In the Interpretext system, the shallow knowledge in the lexical entry for the verb"give" includes the fact that, as a consequence of the event of giving, the Recipienthas the Object--i.e., the villagers have rifles.
Thus, the shallow knowledge about theconsequences of "giving" in one sentence can be used to override the knowledge about riflesand shooting in the next sentence (reasoning of this sort has not yet been implemented271in the Interpretext system, but it is entirely feasible).
It follows from the principle ofcooperation that inferences established from the interpretation of the previous linguisticcontext will be favored by the system if they conflict with default inferences.The principle of cooperation also accounts for contextual information overriding defaultknowledge in anaphora resolution, as in the following examples:(3) The doctor looked up and recognized the nurse.
She smiled.Plausible interpretations of (3) include:(3a) The nurse smiled--i.e., "she" = the nurse.
(3b) The doctor smiled--i.e., "she" = the doctor.Although doctors can be men or women, and nurses can be men or women, the currenttypical default for these roles is to expect doctors to be men and nurses to be women,favoring interpretation (3a).
However, these expectations can be altered by previousdiscourse, as in (4).
(4) Nurse Roger Smith was nervous as he entered Dr. Mary Brown's office.The doctor looked up and recognized the nurse.
She smiled.In (4) the default interpretation (3a) is overridden by the information in the previoussentence.Shallow information encoded in the Interpretext lexical entries makes possible thecorrect default interpretation for (3): the entry for "doctor" includes the information thatdoctors are typically (but not inherently) male, and the entry for "nurse" specifies thatnurses are typically (but not inherently) female.
For discourse (4), the (3a) interpretationneeds to be overridden by identifying the definite noun phrase anaphors "doctor" and"nurse" with their respective antecedents, and by accessing shallow lexical knowledgeabout names indicating that a "Roger" is typically male and a "Mary" is typically female,so that "she" can be only Dr. Mary Brown.
A shallow level of lexical semantic knowledgeprovides enough information to correctly interpret (1) and (3), but in (2) and (4) thisinformation is overridden by inferences from the shallow information in the immediatelypreceding context.Lexical-level shallow knowledge is sufficient for correct interpretation of most instancesof sentence structure and anaphor esolution--the immediate representation f text mean-ing.
It is less likely to be adequate for remote bridging inferences.
In example (5), shallownaive semantics can bridge between "go" to transportation as an instrument of going,and from transportation to "car" because the inherent function of a car is transportation.However, in (6), shallow knowledge would not be sufficient o bridge from "pregnant" to"surprise" to "swallow gum".
(5) Ed decided to go to the movies.
He couldn't find his car keys.
(6) Susan told Ralph that she was pregnant.
He swallowed his gum.4 Conc lus ionA model which permits interaction between a syntactic module, a formal semantic mod-ule and world knowledge is theoretically attractive, and justified in psycholinguistic stud-ies.
World knowledge can be separated into a shallow linguistic layer and knowledge in272general.
The linguistic layer contains just the information required for discourse inter-pretation.
In the naive semantic approach to word meaning, words name concepts, andconcepts are naive theories of objects and events.
Experience building a computationaltext understanding system demonstrates that a constrained, predictable portion of thesenaive theories is sufficient o disambiguate words and structure, and to build a discoursemodel with anaphors resolved and coherence relations assigned.References\[1\]\[2\]\[3\]\[4\]\[5\]\[6\]\[7\]\[8\]\[9\]\[lo\]\[11\]\[12\]\[13\]\[14\]\[15\]K. Dahlgren.
ReJerential Semantics.
PhD thesis, University of California, Los Angeles,1976.K.
Dahlgren.
The cognitive structure of social categories.
Cognitive Science, 9:379-398, 1985.K.
Dahlgren.
Naive Semantics .for Natural Language Understanding.
Kluwer Aca-demic Press, Norwell, Mass, 1988.K.
Dahlgren.
Coherence relation assignment.
In Proceedings ofthe Cognitive ScienceSociety, pages 588-596, 1989.K.
; G. Lord; Dahlgren and J. P. McDowell.
Lexical knowledge for accurate anaphoraresolution.
Manuscript, 1990.K.
; J. P. McDowell; Dahlgren and E. P. Stabler, Jr.
Knowledge representation forcommonsense r asoning with text.
Computational Linguistics, 15:149-170, 1989.C.
J. Fillmore.
Frames and the semantics of understanding.
Quaderni de Semantica,VI.2:222-254, 1985.J.
A. Fodor.
Modules, frames, fridgeons, sleeping dogs, and the music of spheres.
InJ.
L. Garfield, editor, Modularity in Knowledge Representation a d Natural-LanguageUnderstanding.
MIT Press, Cambridge, Mass, 1987.A.
Graesser and L. Clark.
Structure and Procedures o\] Implicit Knowledge.
Ablex,Norwood, N J, 1985.J.
R.; W. Croft; T. Davies; D. Edwards Hobbs and K. Laws.
Commonsense physicsand lexical semantics.
In Proceedings of the ACL, pages 231-240, 1986.H.
Kamp.
A theory of truth and semantic representation.
In J.; T. Janssen; Groe-nendijk and M. Stokhof, editors, Formal Methods in the Study of Language.
Mathe-matiseh Centrum, Amsterdam, 1981.F.
C. Keil.
Concepts, Kinds and Cognitive Development.
MIT Press, Cambridge,Mass, 1989.G.
L. Murphy and D. L. Medin.
The role of theories in conceptual coherence.
Psy-chological Review, 92:289-316, 1985.G.
McKoon and R. Ratcliff.
Dimensions of inference.
Psychology o/Learning andMotivation, 25:313-328, 1990.W.
Marslen-Wilson and L. K. Tyler.
Against modularity.
In J. L. Garfield, editor,Modularity in Knowledge Representation a d Natural-Language Understanding.
MITPress, Cambridge, Mass, 1987.273\[16\] H. Putnam.
The meaning of 'meaning'.
In Mind, Language and Reality.
CambridgeUniversity Press, Cambridge, England, 1975.\[17\] E.; C. B. Mervis; W. D. Gray; D. M. Johnson; Rosch and P. Boyes-Braem.
Basicobjects in natural categories.
Cognitive Psychology, 8:382-439, 1976.\[18\] E. E. Smith and D. L. Medin.
Categories and Concepts.
Harvard University Press,Cambridge, MA, 1981.\[19\] T. 'Prabasso and L. L. Sperry.
Causal relatedness and importance of story events.Journal off Memory and Language, 24.1:595-611, 985.274
