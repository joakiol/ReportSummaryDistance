Referring Expressions as Formulas of Description LogicCarlos ArecesINRIA Nancy Grand EstNancy, Franceareces@loria.frAlexander KollerUniversity of EdinburghEdinburgh, UKa.koller@ed.ac.ukKristina StriegnitzUnion CollegeSchenectady, NY, USstriegnk@union.eduAbstractIn this paper, we propose to reinterpret theproblem of generating referring expressions(GRE) as the problem of computing a formulain a description logic that is only satisfied bythe referent.
This view offers a new unifyingperspective under which existing GRE algo-rithms can be compared.
We also show thatby applying existing algorithms for computingsimulation classes in description logic, we canobtain extremely efficient algorithms for rela-tional referring expressions without any dan-ger of running into infinite regress.1 IntroductionThe generation of referring expressions (GRE) isone of the most active and successful research ar-eas in natural language generation.
Building uponDale and Reiter?s work (Dale, 1989; Dale and Reiter,1995), various researchers have added extensionssuch as reference to sets (Stone, 2000), more expres-sive logical connectives (van Deemter, 2002), andrelational expressions (Dale and Haddock, 1991).Referring expressions (REs) involving relations,in particular, have received increasing attention re-cently; especially in the context of spatial refer-ring expressions in situated generation (e.g.
(Kelle-her and Kruijff, 2006)), where it seems particularlynatural to use expressions such as ?the book on thetable?.
However, the classical algorithm by Dale andHaddock (1991) was recently shown to be unableto generate satisfying REs in practice (Viethen andDale, 2006).
Furthermore, the Dale and Haddock al-gorithm and most of its successors (such as (Kelle-her and Kruijff, 2006)) are vulnerable to the prob-lem of ?infinite regress?, where the algorithm jumpsback and forth between generating descriptions fortwo related individuals infinitely, as in ?the book onthe table which supports a book on the table .
.
.
?.In this paper, we propose to view GRE as theproblem of computing a formula of description logic(DL) that denotes exactly the set of individuals thatwe want to refer to.
This very natural idea has beenmentioned in passing before (Krahmer et al, 2003;Gardent and Striegnitz, 2007); however, we take itone step further by proposing DL as an interlinguafor comparing the REs produced by different ap-proaches to GRE.
In this way, we can organize ex-isting GRE approaches in an expressiveness hierar-chy.
For instance, the classical Dale and Reiter al-gorithms compute purely conjunctive formulas; vanDeemter (2002) extends this language by adding theother propositional connectives, whereas Dale andHaddock (1991) extends it by allowing existentialquantification.Furthermore, the view of GRE as a problem ofcomputing DL formulas with a given extension al-lows us to apply existing algorithms for the lat-ter problem to obtain efficient algorithms for GRE.We present algorithms that compute such formulasfor the description logics EL (which allows onlyconjunction and existential quantification) andALC(which also allows negation).
These algorithms ef-fectively compute REs for all individuals in the do-main at the same time, which allows them to system-atically avoid the infinite regress problem.
The ELalgorithm is capable of generating 67% of the rela-tional REs in the Viethen and Dale (2006) dataset, inabout 15 milliseconds.
The ALC algorithm is evenfaster; it computes relational REs for all 100 indi-viduals in a random model in 140 milliseconds.The paper is structured as follows.
In Section 2,42we will first define description logics.
We will thenshow how to generate REs by computing DL sim-ilarity sets for ALC and EL in Section 3.
In Sec-tion 4, we evaluate our algorithms and discuss ourresults.
Section 5 compares our approach to relatedresearch; in particular, it shows how various promi-nent GRE algorithms fit into the DL framework.Section 6 concludes and points to future work.2 Description logics and similarityIn this paper, we will represent referring expres-sions as formulas of description logic (Baader et al,2003).
In order to make this point, we will now de-fine the two description logics we will be workingwith: ALC and EL.Formulas (or concepts) ?
of ALC are generatedby the following grammar:?,??
::= > | p | ??
| ?
u ??
| ?R.
?where p is in the set of propositional symbols prop,and R is in the set of relational symbols rel.
EL isthe negation-free fragment of ALC.Formulas of both ALC and EL are interpreted inordinary relational first-order modelsM = (?, || ?
||)where ?
is a non-empty set and || ?
|| is an interpreta-tion function such that:||p|| ?
?
for p ?
prop||R|| ?
???
for R ?
rel||?
?|| = ??
||?||||?
u ?
?|| = ||?|| ?
||??||||?R.
?|| = {i | for some i?, (i, i?)
?
||R||and i?
?
||?||}.Every formula of a description logic denotes aset of individuals in the domain; thus we can usesuch formulas to describe sets.
For instance, in themodel in Fig.
1b, the formula flower denotes the set{f1, f2}; the formula floweru?in.hat denotes {f2};and the formula flower u ?
?in.hat denotes {f1}.Different description logics differ in the inventoryof logical connectives they allow: While ALC per-mits negation, EL doesn?t.
There are many otherdescription logics in the literature; some that wewill get back to in Section 5 are CL (EL withoutexistential quantification, i.e., only conjunctions ofatoms); PL (ALC without existential quantification,i.e., propositional logic); and ELU (?)
(EL plus dis-junction and atomic negation).Below, we will use a key notion of formula preser-vation that we call similarity.
For any DL L, wewill say that an individual i is L-similar to i?
in agiven modelM if for any formula ?
?
L such thati ?
||?||, we also have i?
?
||?||.
Equivalently, thereis no L-formula that holds of i but not of i?.
We saythat the L-similarity set of some individual i is theset of all individuals to which i is L-similar.Notice that similarity is not necessarily a symmet-rical relation: For instance, f1 is EL-similar to f2 inFig.
1b, but f2 is not EL-similar to f1 (it satisfies theformula ?in.hat and f1 doesn?t).
However, ALC-similarity is a symmetrical relation because the lan-guage contains negation; and indeed, f1 is notALC-similar to f2 either because it satisfies ??in.hat.
Be-causeALC is more expressive than EL, it is possiblefor some individual a to be EL-similar but notALC-similar to some individual b, but not vice versa.3 Generating referring expressionsNow we apply description logic to GRE.
The coreclaim of this paper is that it is natural and useful toview the GRE problem as the problem of computinga formula of some description logic L whose exten-sion is a given target set A of individuals.L-GRE PROBLEMInput: A modelM and a target set A ?
?.Output: A formula ?
?
L such that ||?|| = A(if such a formula exists).In the examples above, it is because flower u?in.hat denotes exactly {f2} that we can say ?theflower in the hat?
to refer to f2.
This perspective pro-vides a general framework into which many existingGRE approaches fit: Traditional attribute selection(Dale and Reiter, 1995) corresponds to building DLformulas that are conjunctions of atoms; relationalREs as in Dale and Haddock (1991) are formulas ofEL; and so on.
We will further pursue the idea of or-ganizing GRE approaches with respect to the variantof DL they use in Section 5.For the rest of this paper, we assume that we aregenerating a singular RE, i.e., the target set A willbe a singleton.
In this case, we will only be ableto generate a formula that denotes exactly A = {a}(i.e., a RE that uniquely refers to a) if there is no43f1floort2tablet1tableb2c2bowlcupb1bowlc1cupononononinin(a) (b)r1rabbitr2rabbitr3rabbitr4rabbith1hath4hath2hath3hatf1flowerf2flowerb1bathtubinininFigure 1: (a) The Dale and Haddock (1991) scenario; (b)the Stone and Webber (1998) scenario.other individual b to which a is similar; otherwise,any formula that is satisfied by a is also satisfied byb.
Conversely, if we know that a is not similar to anyother individual, then there is a formula that is satis-fied by a and not by anything else; this formula canserve as a unique singular RE.
In other words, wecan reduce the L-GRE problem for a given modelto the problem of computing the L-similarity sets ofthis model.
Notice that this use of similarity sets canbe seen as a generalization of van Deemter?s (2002)?satellite sets?
to relational descriptions.In the rest of this section, we will present algo-rithms that compute the similarity sets of a givenmodel for ALC and EL, together with characteris-tic formulas that denote them.
In the ALC case,we adapt a standard algorithm from the literaturefor computing simulation classes; we will then fur-ther adapt this algorithm for EL.
In effect, both al-gorithms compute REs for all individuals in somemodel at the same time ?
very efficiently and with-out any danger of infinite regress.3.1 Computing similarity setsIt can be shown that for ALC, the similarity setsof a finite model coincide exactly with the simu-lation classes of this model.
Simulation classeshave been studied extensively in the literature (seee.g., Blackburn et al (2001); Kurtonina and de Ri-jke (1998)), and there are several efficient algorithmsfor computing ALC-simulation classes (Hopcroft,1971; Paige and Tarjan, 1987; Dovier et al, 2004).However, these algorithms will only compute thesimulation classes themselves.
Here we extend theHopcroft (1971) algorithm such that it computes,along with each set, also a formula that denotes ex-actly this set.
We can then use these formulas asrepresentations of the referring expressions.The pseudocode for our ALC algorithm is shownas Algorithm 1 (with L = ALC) and Algorithm 2.Given a modelM = (?, || ?
||), the algorithm com-putes a set RE of ALC formulas such that {||?|| |?
?
RE} is the set of ALC-similarity sets ofM.
The algorithm starts with RE = {>} (where||>|| = ?
), and successively refines RE by mak-ing its elements denote smaller and smaller sets.
Itmaintains the invariant that at the start and end of ev-ery iteration, {||?|| | ?
?
RE} is always a partitionof ?.
The algorithm iterates over all propositionaland relational symbols in prop and rel to constructnew formulas until either all formulas in RE denotesingletons (i.e., there is only one individual that sat-isfies them), or no progress has been made in theprevious iteration.
In each iteration, it calls the pro-cedure addALC(?, RE ), which intersects ?
with anyformula ?
?
RE which does not denote a singletonand which is not equivalent to ?
and to ??.
In thiscase, it replaces ?
in RE by ?
u ?
and ?
u ?
?.TheALC algorithm computes theALC-similaritysets of the model in timeO(n3), where n is the num-ber of individuals in the domain.
However, it willfreely introduce negations in the case distinctions,which can make the resulting formula hard to realize(see also Section 4.3).
This is why we also presentan algorithm for the EL-similarity sets; EL corre-sponds to positive relational REs, which are gener-ally much easier to realize.We obtain the EL algorithm by replacing the callto addALC in Algorithm 1 by a call to addEL, whichis defined in Algorithm 3.
As before, the algo-rithm maintains a set RE = {?1, .
.
.
, ?n} of for-mulas (this time of EL) such that ||?1|| ?
.
.
.
?||?n|| = ?, and which it refines iteratively.
However,where the ALC algorithm maintains the invariantthat ||?1||, .
.
.
, ||?n|| is a partition of ?, we weakenthis invariant to the requirement that there are nom ?
2 pairwise different indices 1 ?
i1, .
.
.
, im ?n such that ||?i1 || = ||?i2 || ?
.
.
.?
||?im ||.
We call ?i1subsumed if such a decomposition exists.Because it maintains a weaker invariant, the setRE may contain more formulas at the same time inthe EL algorithm than in the ALC algorithm.
Giventhat ?
has an exponential number of subsets, there isa risk that the EL algorithm might have worst-case44Algorithm 1: Computing the L-similarity setsInput: A modelM = (?, || ?
||)Output: A set RE of formulas such that{||?|| | ?
?
RE} is the set ofL-similarity sets ofM.RE ?
{>}1for p ?
prop do2addL(p,RE )3while exists some ?
?
RE , |||?|||M > 1 do4for ?
?
RE , R ?
rel do5addL(?R.
?,RE )6if made no changes to RE then7exit8exponential runtime (although we are not aware ofsuch worst-case examples).
We leave a more carefulcomplexity analysis for future work.We presented both algorithms as first refining REaccording to propositional symbols, and then by re-lational expressions of increasing depth.
But actu-ally, propositional symbols can be encoded usingnew relational symbols (e.g., we could represent thatf1 is a flower in Fig.
1 as a relation labeled flowerfrom f1 to an additional dummy element d).
In thisway, we don?t need to distinguish between proposi-tions and relations, and any arbitrary preference or-dering of properties can be used.3.2 Some examplesLet?s try our algorithms on some examples.
Wefirst run the EL algorithm on the model shown inFig.
1a, which is taken from Dale and Haddock(1991).
The algorithm starts with RE = {>}.
Inthe first loop, it adds the formulas floor, bowl, cup,and table, and then removes > because it is nowsubsumed.
Not all of these formulas denote single-tons; for instance, ||cup|| contains two individuals.So we iterate over the relations to refine our for-mulas.
After the first iteration over the relations,we have RE = {floor, bowl u ?on.floor, bowl u?on.table, cup, table}.
Notice that bowl has becomesubsumed, but we haven?t distinguished the cupsand tables further.Now we can use the split between the bowls todistinguish the cups in the second iteration.
The re-sult of this is RE = {floor, bowlu?on.floor, bowluAlgorithm 2: addALC(?,RE )for ?
?
RE with |||?||| > 1 do1if ||?
u ?|| 6= ?
and ||?
u ?
?|| 6= ?
then2add ?
u ?
and ?
u ??
to RE ;3remove ?
from RE ;4Algorithm 3: addEL(?, RE )for ?
?
RE with |||?||| > 1 do1if ?
u ?
is not subsumed in RE and2||?
u ?|| 6= ?
and ||?
u ?|| 6= ||?|| thenadd ?
u ?
to RE3remove subsumed formulas from RE4?on.table, cup u ?in.
(bowl u ?on.floor), cup u?in.
(bowl u ?on.table), table}.
At this point, allformulas except table denote singletons, and furtheriterations don?t allow us to refine table; so the al-gorithm terminates.
Each formula with a singletonextension {a} is a unique description of a; for in-stance, cup u ?in.
(bowl u ?on.table) is only satis-fied by c2, so we may refer to c2 as ?the cup in thebowl on the table?.
Notice that the algorithm didn?tfocus on any particular individual; it simultaneouslygenerated REs for all individuals except for the twotables (which are similar to each other).The EL algorithm has a harder time with the ex-ample in Fig.
1b (Stone and Webber, 1998).
Whileit will correctly identify r1 as ?the rabbit in the hat?and f2 as ?the flower in the hat?, it will not be able tocompute a RE for f1 because f1 is EL-similar to f2.Indeed, the algorithm terminates with RE contain-ing both flower and floweru?in.hat.
This is a typicalpattern for asymmetrical cases of similarity in EL: Ifthere are two formulas ?1 and ?2 in the output setwith ||?1|| ?
||?2||, then there is generally some in-dividual b ?
||?2|| ?
||?1|| such that all individuals in||?1|| are similar to b, but not vice versa.
By contrast,theALC algorithm can exploit the greater expressiv-ity of ALC to split flower into the two new formulasfloweru?in.hat and floweru?
?in.hat, generating aunique RE for f1 as well.4 DiscussionWe will now describe two experiments evaluatingthe quality of the EL algorithm?s output and the effi-45Figure 2: A schematic view of the filing cabinets.ciency of both of our algorithms, and we discuss theinterface between our algorithms and realization.4.1 Evaluation: Output qualityTo compare the descriptions generated by our al-gorithm to those humans produce, we use a cor-pus of human-generated referring expressions col-lected and made available by Jette Viethen andRobert Dale.1 They asked human subjects to de-scribe one of 16 filing cabinet drawers.
The draw-ers had different colors and were arranged in afour-by-four grid (see Fig.
2).
The human subjectsused four non-relational properties (the drawer?scolor, its column and row number, and whetherit is in a corner) and five relational properties(above, below, next to, left of, right of).
Of the 118referring expressions obtained in the experiment,only 15 use relations.Viethen and Dale (2006) describe the data inmore detail and present results of evaluating the FullBrevity algorithm, the Incremental Algorithm (bothby Dale and Reiter (1995)), and the Relational Al-gorithm (Dale and Haddock, 1991) on this corpus.The Incremental Algorithm is dependent on a pre-defined ordering in which properties are added tothe description.
Viethen and Dale, therefore, try allpossible orderings and evaluate what percentage ofdescriptions an algorithm can generate with any ofthem.
The Full Brevity and the Relational Algo-rithms choose properties based on their discrimina-tory power and only use the orderings as tie break-ers.
Viethen and Dale found that the IncrementalAlgorithm is capable of generating 98 of the 103non-relational descriptions.
However, the RelationalAlgorithm was unable to generate even a single oneof the human-generated relational descriptions.We replicated Viethen and Dale?s experiment for1http://www.ics.mq.edu.au/?jviethen/drawersthe EL algorithm presented above.
In the non-relational case, our results are the same as theirs forthe Incremental Algorithm: the EL algorithm gener-ates 98 of the 103 non-relational descriptions, usingfour (of the possible) orderings.
This is because thetwo algorithms perform essentially the same compu-tations if there are no relations.When we add relations, our algorithm is able togenerate 10 of the 15 human-produced relationaldescriptions correctly (in addition to the 98 non-relational descriptions).
Fig.
3 gives example out-puts of the EL algorithm for three different order-ings, which together achieve this coverage.
Of thefive human-produced descriptions that the EL algo-rithm cannot generate, three involve references tosets (the two blues ones in horizontal sequence/thetwo yellow drawers), and two contain so much re-dundant information that our algorithm cannot re-produce them: Similarly to the Incremental Algo-rithm, our algorithm allows for some redundancy,but stops once it has found a distinguishing descrip-tion.
It does, however, generate other, simpler de-scriptions for these referents.4.2 Evaluation: EfficiencyBoth the EL and the ALC algorithms took about 15milliseconds to compute distinguishing formulas forall 16 individuals in the Viethen and Dale dataset.2In order to get a more comprehensive pictureof the algorithms?
efficiency, we ran them on ran-dom models with increasing numbers of individu-als.
Each model had random interpretations for tendifferent propositional and four relational symbols;each individual had a 10% chance to be in the exten-sion of each propositional symbol, and each pair ofindividuals had a 10% chance to be related by a re-lational symbol.
The results (averaged over 10 runsfor each model size) are shown in Fig.
4.
The EL al-gorithm takes about 350 ms on average to generaterelational REs for all individuals in the model of size100, i.e., less than 4 ms on average for each individ-ual.
The ALC algorithm is even faster, at about 140ms for the model of size 100.
As far as we know,these are by far the fastest published runtimes for2Runtimes were measured on a MacBook Pro (Intel Core 2Duo, 2.16 GHz) running Java 1.6 beta.
We allowed the JavaVM to warm up, i.e., just-in-time compile all bytecode, beforetaking the measurements.46idhuman-produced descriptionoutput of the EL algorithm2the orange drawer above the blue drawerorangeu ?above.blue / orange u ?above.(?below.
(orange) u blue) / orange u ?next.
(blue) u ?next.
(pink)4the yellow drawer on the top of the pink oneyellow u ?above.pink / yellow u corner u ?above.pink / yellow u corner u ?above.(?next.
(yellow) u pink)5?
the pink drawer in the fourth column below the yellow onepink u ?above.orange / pink u ?below.yellow / pink u ?next.
(yellow) u ?above.(?next.
(yellow) u orange)6the yellow drawer on top of the yellow drawer (2?)
/ ?
the drawer after the two blue ones in horizontal sequenceyellow u ?above.yellow / yellow u ?below.pink / yellow u ?next.
(blue) u ?next.
(pink)7the blue drawer below the orange one / ?
the blue drawer below the orange drawer in the second columnblueu?above.(blue)u?next.(?above.
(orange)ublue) / blueu?below.
(orange) / blueu?next.(blue)u?next.
(yellow)10the blue drawer above the pink drawer (2?
)blueu ?above.
(pink) / blue u ?above.
(pink) u ?below.
(blue) / blue u ?next.
(orange) u ?next.
(yellow)11the yellow drawer next to the orange drawer (2?
)yellow u ?above.orange / yellow u ?below.yellow / yellow u ?next.orange12the orange drawer below the pink drawerorange u ?above.
(pink u corner) / orangeu ?below.pink / orange u ?next.yellow14?
the orange drawer below the two yellow drawers (2?
)orange u ?next.
(pink u corner) u ?next.
(pink) / orange u ?below.yellow / orange u ?next.
(pink u corner)Figure 3: The relational descriptions from Viethen and Dale (2006), annotated with the drawer id and the outputs of theEL algorithm using three different orderings.
Notice that four descriptions occurred twice in the corpus.
Descriptionsthat the EL algorithm cannot generate with any ordering are marked by ?.
Generated descriptions that match oneproduced by humans are in boldface.any relational GRE algorithm in the literature.4.3 Interface to realizationOur GRE algorithms do not guarantee that the for-mula they compute can actually be realized in lan-guage.
For example, none of the formulas our al-gorithms computed in the Viethen and Dale domaincontained an atom that would commonly be realizedas a noun; the property drawer is never used be-cause it applies to all individuals in the domain.
Thisparticular problem could easily be worked aroundin a post-processing step.
However, another prob-lem arises from the massive use of negation in theALC algorithm; it will be hard for any realizer tofind a reasonable way of expressing a formula like??R.
(?Pu?Q) as a smooth noun phrase.
Althoughwe agree with van Deemter (2002) and others thatthe careful use of negation and disjunction can im-prove REs, these connectives must not be overused.Thus we consider the formulas computed by the ELalgorithm ?safer?
with respect to realization.Of course, we share the problem of interfacingGRE and realization with every other approach thatseparates these two modules, i.e., almost the en-tire GRE literature (notable exceptions are, e.g., Ho-racek (1997) and SPUD (Stone and Webber, 1998)).010020030040010 20 30 40 50 60 70 80 90 100EL ALCFigure 4: Average runtimes (in ms) of the two algorithmson random models with different numbers of individuals.In principle, we believe that it is a good idea tohandle sentence planning and realization in a singlemodule; for instance, SPUD can use its awarenessof the syntactic context to generate succinct REs asin ?take the rabbit from the hat?.
We hope that theideas we have explored here for efficient and ex-pressive RE generation can eventually be combinedwith recent efficient algorithms for integrated sen-tence planning and realization, such as in Koller andStone (2007).One problem that arises in our approach is that47both algorithms derive some measure of efficiencyfrom their freedom to build formulas without hav-ing to respect any linguistic constraints.
It seemsstraightforward, for instance, to extend Krahmer etal.
?s (2003) approach such that it only considers sub-graphs that can actually be realized, because their al-gorithm proceeds by a genuine search for uniquelyidentifying subgraphs, and will simply take a differ-ent branch of the search if some subgraph is useless.This would be harder in our case.
Our algorithmsdon?t search in the same way; if we disallow certainrefinements of a partition, we have to allow the al-gorithms to backtrack and thus jeopardize the worst-case polynomial runtime.
Investigating this inter-play between efficiency and linguistic constraints isan interesting avenue for future research.5 A unified perspective on GREViewing GRE as a problem of generating DL for-mulas offers a unified perspective: It is the prob-lem of computing a DL formula with a given exten-sion.
Many existing approaches can be subsumedunder this view; we have summarized this for someof them in Fig.
5, along with the DL fragment theyuse.
We already discussed some of these approachesin Section 3.
Furthermore, the non-relational butnegative and disjunctive descriptions generated byvan Deemter (2002) are simply formulas of PL;and Gardent (2002) generalizes this into generatingformulas of ELU (?
), i.e., EL plus disjunction andatomic negation.
The approach presented here fitswell into this landscape, and it completes the pic-ture by showing how to generate REs inALC, whichcombines all connectives used in any of these previ-ous approaches.Where our approach breaks new ground is in theway these formulas are computed: It successivelyrefines a decomposition of the domain into subsets.In this way, it is reminiscent of the Incremental Al-gorithm, which in fact can be seen as a special caseof the EL algorithm.
However, unlike Dale andHaddock (1991) and its successors, such as Kelle-her and Kruijff (2006), we do not have to take spe-cial precautions to avoid infinite regress.
While Daleand Haddock?s algorithm attempts to generate a REfor a single individual, for successive individuals inthe model, our algorithms consider all individuals inGRE algorithm DL variantDale and Reiter (1995) CLvan Deemter (2002) PLDale and Haddock (1991) ELKelleher and Kruijff (2006) ELGardent (2002) ELU (?
)Figure 5: DL variants used by different GRE algorithms.parallel.
It monotonically refines a partition of themodel and never needs to backtrack, and thereforeis always guaranteed to terminate.Perhaps closest in spirit to our approach is Krah-mer et al?s graph algorithm (2003), which also com-putes REs by extending them successively.
How-ever, their subgraphs go beyond the expressivepower of ALC in that they can distinguish between?the dog that bites a dog?
and ?the dog that bites it-self?.
The price they pay for this increase in expres-sive power is an NP-complete worst-case complex-ity.
Interestingly, Krahmer et al themselves discussthe possibility of seeing their subgraphs as formu-las of hybrid logic which are satisfied at the pointswhere the subgraph can be embedded; and hybridlogics can be seen as very expressive descriptionlogics (Areces and ten Cate, 2006).6 ConclusionIn this paper, we have explored the idea of view-ing the generation of singular REs as the problemof computing a DL formula with a given extension.We have shown how such formulas can be computedefficiently (for ALC and EL) by adapting existingalgorithms from the literature.
The EL algorithmis able to generate 95% of the non-relational and67% of the relational REs from Viethen and Dale(2006).
Both algorithms are extremely efficient (350ms and 140 ms respectively to generate relationalREs for all individuals in a random model with 100individuals); to our knowledge, these are by far thefastest runtimes for relational GRE reported in theliterature.
We have made our implementation avail-able online at http://code.google.com/p/crisp-nlg/wiki/DlGre.Because they compute referring expressions forall individuals in the domain at once, our algorithmswill perform especially strongly in static settings,such as the generation of descriptions for museum48exhibits, in which the individuals and their proper-ties don?t change much.
However, even in more dy-namic settings, our algorithms have a chance to out-perform search algorithms like Dale and Haddock?sin the average case because they can?t get stuck inunproductive branches of the search space.
Never-theless, one interesting question for future researchis how to incrementally update simulation classeswhen the model changes.
Similarly, it would beinteresting to explore how different linguistic con-straints and attribute orderings can be taken into ac-count efficiently, how our algorithms could be in-tegrated with more standard DL T-Box inferences,and how they can be adapted to use inverse relationsor to compute REs for sets.
In exploring these ex-tensions we will be able to draw on a rich body ofliterature that has already considered many variantsof simulation algorithms addressing similar issues.In experimenting with the Viethen and Dale data,we found that there is no single ordering that coversall human-produced descriptions, which seems to bein contrast to Dale and Reiter?s (1995) assumptionthat there is only one ordering for each given do-main.
In fact, it is not even the case that each speakerconsistently uses just one ordering.
An interestingopen research question is thus what factors deter-mine which ordering is used.
Unfortunately, bothin the Viethen and Dale dataset and in the TUNAcorpus (van Deemter et al, 2006), only a minor-ity of referring expressions is relational, maybe be-cause these domains lend themselves very well torow/column style propositional REs.
We are cur-rently collecting REs in a domain in which propo-sitional REs are less preferred.Acknowledgments.
We are grateful to HectorGeffner (who independently suggested to view GRE ascomputation of DL formulas), Kees van Deemter, andEmiel Krahmer for interesting discussions.
We alsothank Jette Viethen and Robert Dale for making theircorpus available, and the reviewers for their comments.ReferencesC.
Areces and B. ten Cate.
2006.
Hybrid logics.
InP.
Blackburn, F. Wolter, and J. van Benthem, editors,Handbook of Modal Logics.
Elsevier.F.
Baader, D. McGuiness, D. Nardi, and P. Patel-Schneider, editors.
2003.
The Description LogicHandbook: Theory, implementation and applications.Cambridge University Press.P.
Blackburn, M. de Rijke, and Y. Venema.
2001.
ModalLogic.
Cambridge University Press.R.
Dale and N. Haddock.
1991.
Generating referringexpressions involving relations.
In Proc.
of the 5thEACL.R.
Dale and E. Reiter.
1995.
Computational interpreta-tions of the Gricean maxims in the generation of refer-ring expressions.
Cognitive Science, 19.R.
Dale.
1989.
Cooking up referring expressions.
InProc.
of the 27th ACL.A.
Dovier, C. Piazza, and A. Policriti.
2004.
An ef-ficient algorithm for computing bisimulation equiva-lence.
Theoretical Computer Science, 311(1?3).C.
Gardent and K. Striegnitz.
2007.
Generating bridg-ing definite descriptions.
In H. Bunt and R. Muskens,editors, Computing Meaning, Vol.
3.
Springer.C.
Gardent.
2002.
Generating minimal definite descrip-tions.
In Proc.
of the 40th ACL.J.
Hopcroft.
1971.
An n log(n) algorithm for minimizingstates in a finite automaton.
In Z. Kohave, editor, The-ory of Machines and computations.
Academic Press.H.
Horacek.
1997.
An algorithm for generating refer-ential descriptions with flexible interfaces.
In Proc.
ofthe 35th ACL.J.
Kelleher and G.-J.
Kruijff.
2006.
Incremental genera-tion of spatial referring expressions in situated dialog.In Proc.
of COLING/ACL.A.
Koller and M. Stone.
2007.
Sentence generation asplanning.
In Proc.
of the 45th ACL.E.
Krahmer, S. van Erk, and A. Verleg.
2003.
Graph-based generation of referring expressions.
Computa-tional Linguistics, 29(1).N.
Kurtonina and M. de Rijke.
1998.
Expressivenessof concept expressions in first-order description logics.Artificial Intelligence, 107.R.
Paige and R. Tarjan.
1987.
Three partition refinementalgorithms.
SIAM Journal on Computing, 16(6).M.
Stone and B. Webber.
1998.
Textual economythrough close coupling of syntax and semantics.
InProc.
of the 9th INLG workshop.M.
Stone.
2000.
On identifying sets.
In Proc.
of the 1stINLG.K.
van Deemter, I. van der Sluis, and A. Gatt.
2006.Building a semantically transparent corpus for the gen-eration of referring expressions.
In Proc.
of the 4thINLG.K.
van Deemter.
2002.
Generating referring expres-sions: Boolean extensions of the incremental algo-rithm.
Computational Linguistics, 28(1):37?52.J.
Viethen and R. Dale.
2006.
Algorithms for generatingreferring expressions: Do they do what people do?
InProc.
of the 4th INLG.49
