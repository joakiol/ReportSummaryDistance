THE COLLECTION AND PREL IMINARY ANALYSIS OFA SPONTANEOUS SPEECH DATABASE*Victor Zue, Nancy Daly, James Glass, David Goodine, Hong Leung,Michael Phillips, Joseph Polifroni, Stephanie Seneff, and Michal SoclofSpoken Language Systems GroupLaboratory for Computer ScienceMassachusetts Institute of TechnologyCambridge, Massachusetts 02139ABSTRACTAs part of our effort in developing a spoken language system for interactive problem solving, we recentlycollected a sizeable amount of speech data.
This database is composed of spontaneous sentences which werecollected uring a simulated human/machine dialogue.
Since a computer log of the spoken dialogue wasmaintained, we were able to ask the subjects to provide read versions of the sentences as well.
This paperdocuments he data collection process, and provides ome preliminary analyses of the collected ata.INTRODUCTIONOne of the first tasks confronting researchers developing a spoken language system is the collection ofdata for analysis, system training, and evaluation.
Since people do not always say grammatically well-formed sentences during a spoken dialogue with a computer, the currently available read speech databasesmay not capture the acoustic and linguistic variabilities found in goal-directed spontaneous speech.
As afirst attempt o create a spontaneous speech database 1, we have recently collected a large amount of datafrom 100 subjects during simulated ialogues with the VOYAGER spoken language system.
The purpose ofthis paper is to document the database construction process, and to provide some preliminary linguistic andacoustic analysis.VOYAGER is a system that knows about he physical environment ofa specific geographical rea as well ascertain objects inside this area, and can provide assistance on how to get from one location to another withinthis area.
It currently focuses on the geographic area of the city of Cambridge, Massachusetts, between MITand Harvard University, and can deal with several distinct concepts including directions, distance and timeof travel between objects, relationships such as "nearest," and simple properties such as phone numbers ortypes of food served.
VOYAQErt also has a limited amount of discourse knowledge which enables it to respondto queries uch as: "How do I get there?"
It can also deal with certain clarification fragments such as: "Thebank in Harvard Square."
A detailed escription of the VOYAGER system can be found elsewhere in theseproceedings \[1\].VOYAGER is made up of three components.
The first component, the SUMMIT speech recognition system\[2\], converts the speech signal into a set of word hypotheses.
The natural anguage component, TINA \[3\],provides a linguistic interpretation f the set of words.
The parse tree generated by TINA is translated into aquery language form, which is used to produce a response.
Currently VOYAGER can generate responses in theform of text, graphics, and synthetic speech.
The back end is an enhanced version of a direction assistanceprogram developed by Jim Davis of MIT's Media Laboratory \[4\].
*This research was supported by DARPA under Contract N00014-89-J-1332, monitored through the Office of Naval Research.lWe loosely use the terra spontaneous speech to mean the speech produced by a person "on the fly" when interacting witha computer for problem solving.126DATABASE CONSTRUCTIONWe believe that data should be collected under conditions that closely reflect the actual capabilities ofthe system.
As a result, we have chosen to have subjects use the system as if they are trying to obtain actualinformation.
The data were recorded in a simulation mode in which the speech recognition component wasexcluded.
This step was taken partly to avoid long processing delays that would disrupt the human-machineinteraction.
Instead, an experimenter in a separate room typed in the utterances spoken by the subject,after removing false starts and hesitations.
Subsequent processing by the natural language and responsegeneration components was done automatically by the computer.Figure 1: A display used during the simulated ata collection process.
The type-in window at the bottomwas hidden from the subject's view to avoid unnecessary distractions.DATA COLLECT IONThe data were collected in an office environment where the ambient noise was approximately 65 dB SPL,measured on the C scale.
A Sennheiser HMD-224 noise-cancelling microphone was used to record the speech.The subject sat in front of a computer console that displayed the geographical rea of interest as shown inFigure 1.
The console was slaved to the experimenter's console in the adjacent room.
The experimenter'styping, shown in the bottom of the display, was hidden from the subject to avoid unnecessary distractions.Two information sheets describing both the knowledge base of VOYAGER and its possible responses wereavailable to the subject.
The subjects referred to these sheets from time to time in order to stay withinVOYAGER's domain of knowledge.During a subject's dialogue, both the input speech and the resulting responses were recorded on audiotape.
The voice input, minus false starts, hesitations, and filled pauses, was typed verbatim to VOYAGER by an127experimenter, and saved automatically in a computer log.
The system response was generated automaticallyfrom this text, which was also recorded into the log.
The system's response typically took a second or twoafter the text had been entered.Whenever a sentence contained words or constructs that were unknown to the natural language compo-nent, the system would explain to the subject why a response could not be generated.
In the event thatthe queries were outside of the knowledge domain and the system responses could not dislodge the subjectfrom that line of questioning, the experimenter could override the system and trigger a canned responseexplaining that the system was currently unable to handle that kind of request.
Another canned responsewas available for the case when the subject produced several queries at once.Each session lasted approximately 30 minutes, and began with a five minute introductory audio tapedescribing the task.
This was followed by a 20 minute dialogue between the subject and VOYAGER.
Followingthe dialogue, the subject was asked to read his or her sentences from the computer log.
The resultingdatabase therefore included both a read and a spontaneous version of the same sentence, modulo false starts,hesitations, and filled pauses in the spontaneous version.Fifty male and fifty female subjects were recruited as subjects from the general vicinity of MIT.
Theyranged in age from 18 to 59.
The only requirement was that they be native speakers of American English withno known speech defects.
For their efforts, each subject was given a gift certificate at a popular ice-creamparlor.
The entire recording was carried out over a nine-day period in late July.
Several of the sessions werealso recorded on video tape to document the data collection process.D IG IT IZAT ION AND TRANSCRIPT IONThe recordings made during the data collection were digitized at 16 kHz, after being band-limited at8 kHz.
Special care was used to ensure that false starts, hesitations, mouth clicks, and breath noise wereincluded as part of the digitized utterance.
In addition, prg-determined conventions were established, andwritten instructions provided, for transcribing these non-speech and partial-word events both orthographi-cally and phonetically.
We started with the notations uggested by Rudnicky \[5\], and made modificationsto suit our needs.To date, the entire database of 9,692 utterances has been digitized and orthographically transcribed,including markers for false starts, partial words, and non-word sounds.
In addition, an aligned phonetictranscription has been obtained for approximately 20% of the data.PREL IMINARY ANALYSISWe have divided the database into three parts according to speakers.
Data from 70 arbitrarily selectedspeakers were designated as the training set.
Of the remaining speakers, two-thirds were designated as thedevelopment set, and the rest as the ~est set.
In each set, there were equal numbers of male and femalespeakers.
In this section, we will report on the results of some preliminary analysis on parts of this database,carried out over the past few weeks.GENERAL STATISTICSFrom the computer log, we were able to automatically generate some preliminary statistics of thedatabase.
Table 1 summarizes some of the relevant statistics for the sum of the training and develop-ment sets.
Note that the number of sentences refers to the spontaneous ones; the total number collected isdouble this amount.As the table reveals, approximately two-thirds of the sentences could be handled by the current versionof VOYAGEa.
The remaining third of the data is evenly divided between sentences with out-of-vocabularywords and sentences for which no parses were generated.
These sentences can be used to extend VOYAGER'S128Speakers 90Total Sentences 4361Avg.
Words per Sentence 8.0Sentences with Action 2854(65%)Sentences with Unknown Words 740 (17%)Sentences with No Parse 727(17%)Sentences with No Action 40(1%)Words Used 601Unknown Words 398Unknown Word Frequency 3%Table 1: General statistics of the spontaneous speech from the training and development sets of the VOYAGERdatabase.capabilities.
Only a very small amount, about 1%, were parsed but not acted upon.
This is a direct resultof our conscious decision to constrain the coverage of the natural anguage component according to thecapabilities of the back-end.The version of VOYAGER used for data collection had a vocabulary of about 300 words which weredetermined primarily from a small set of sentences that we made up.
It is interesting to note that onlyabout 200 of these words were actually used by the subjects.
While the number of unknown words appearsto be large, they actually account for less than 3% of the total number of words when frequency of usage isconsidered.The statistics of this database indicated that an average of slightly less than 50 sentences per subjectwere collected in each 20 minute dialogue.
Thus we believe the database can easily be expanded as thecapabilities of the system grow.ACOUSTIC  ANALYSISSince time-aligned phonetic transcriptions were already available for part of the database, we performedsome comparative acoustic analyses of the spontaneous and read utterances.
These preliminary analyseswere carried out using slightly over 1,750 sentences from 9 male and 9 female training speakers.
While thesedata represent less than 20% of the recorded ata, there were more than 60,000 phonetic events.
As a result,the quantitative differences were found to be statistically significant.
Rather than exhaustively reporting ourfindings, we will make a few observations based on some interesting examples.Figure 2 compares the overall duration of the read and spontaneous tterances.
In this and subsequentfigures, the thin line denotes read speech, whereas the thick line denotes pontaneous speech.
The horizontalbars show the means and standard eviations.
These values, together with the sample size, are also displayedto the right.
The figure suggests that spontaneous utterances are longer than their read counterparts bymore than one-third.
However, there is much more variability in the duration of spontaneous speech, asevidenced by its considerably arger standard eviation.There were nearly 1,000 pauses found in the spontaneous sentences in our dataset, or more than one persentence on the average.
2 In contrast, there were only about 200 pauses found in the read sentences.
AsFigure 3 reveals, the pauses in spontaneous speech are about 2.5 times longer on the average than those inread speech.
Their durations are also much more variable.There are nearly 400 non-speech vocalizations found in this database, including mouth clicks, breath~We make a dist inct ion between pauses, epenthet ic  silences and stop closures.
Only those silence regions that  do not havephonet ic significance are labeled as pauses.129ogci1104o.o.Z-so.o...~--22o.o~1o.o~0 =o ?
oI I1.0  2 .0  8 .0  4 .0  5 .0  6 .0  7 .0I l J l l l l  J i l l  I8.0 g.o  10.08.
?9621.5027887.00002 .42?40 .8197828.0000Ut terancGe LengthFigure 2: Normalized histogram of overall duration for read (in thin lines) and spontaneous (in thick lines)utterances for 9 male and 9 female speakers.t70"0 960 o ?
;--50.040.080.020.010 .0I I I I I I0' ' ' I ' ' ' ' I1.0I I I I2..0O.
3356O.
3952958.0000O.
73,870.0906217.0000DurationFigure 3: Normalized histogram of pause duration for read (in thin lines) and spontaneous (in thick lines)utterances for 9 male and 9 female speakers.130Category Read Speech Spontaneous SpeechTOTAL 103 269Mouth Clicks 60 106Breath Noise 37 117Filled Pauses 0 30Others 6 16Table 2: Number of occurrences of non-speech vocalizations for read and spontaneous speech from 9 maleand 9 female speakers.$0?0coI1.20.0~10.00 0.1 + 0.2I I I I0 .30.0968 0.0519 8802.00000.0894 0.04047842.0000Durat ionFigure 4: Normalized histogram of vowel duration for read (in thin lines) and spontaneous (in thick lines)utterances for 9 male and 9 female speakers.noise (both inhaling and exhaling), and filled pauses uch as "um, "uh," or "ah."
Their distributions areshown in Table 2.
Non-speech vocalizations occur about 2.7 times more often in spontaneous speech than inread speech.
Almost all of the clicks appear at the beginning of sentences for read speech, whereas 25% ofthem occur sentence internally in spontaneous speech.
Similarly, more than 20% of the breath no, ise occurssentence internally, with five times as many in spontaneous speech as in read speech.
All the filled pausesoccur in spontaneous speech, two-thirds of them sentence internally.When we measured the durations of individual phonemes, we found very little difference between thetwo speech styles.
Figure 4, for example, shows that the average vowel durations for read and spontaneousspeech are 89 ms and 95 ms, respectively.
Occasionally, we observed unusually long vowels in the spontaneousspeech.
They almost always correspond to words like "is" or "to," when the subject ries to decide what tosay next.
An example is shown in Figure 5.L INGUIST IC ANALYSISWhen the database was transcribed orthographically, false starts and non-words uch as "ah," "um," orlaughter were explicitly marked in the orthography.
Therefore, it is possible to perform astatistical nalysis of1311.1680:, ........ IUTT-S-APK-32bi ;tiil i tj i ii i i iii iiiiiiiii I......... ,t .
.
.
.
.
.
.1 ., .
.
.
.
.
.
.
.
.
.
.
.
.
~ .~.. .
.
.
.
.
.
.
.
.
.
.
.  '
t ' " "  .
.
.
.
.
.
.
.
.
.  '
.
.
.
.
~" .
.
.
.
.
.
.
.
.
.
.
.
.Wide-Band Spectrogram 3.7816i : : : : : : : : :  : : : : : : :  : :  i. .
.
.
.
: : : :  : : : : : : :  : :I i i i l  i i i~i i i i  i i i i i i1.1680 UTT-S-APK-32 Phonetic Transcr lpt lon 3.7816I (sigh) How old Is Harvard UnlvePsity0.5000 UTT-S-APK-32 Orthographic TPanscrlptlon 3.1084Figure 5: Spectrogram of the sentence, " (How old) is Harvard University?"
showing a lengthened "is".how often such events occurred.
We distinguished between on-words internal to the sentence and non-wordsat the beginning or end of the sentence.
In the training set containing about 3,300 spontaneous sentences,more than 10% of the sentences contained at least one of these effects.
An additional 25% contained mouthclicks or breath noise, which may be a less serious effect.
About half of the non-words appear sentenceinternally.False starts occurred in almost 4% of the spontaneous sentences.
Table 3 categorizes the words followingfalse starts in terms of whether a given word was the same as the intended word, a different word in thesame category, a new linguistic category, or a back up to repeat words already uttered.
An example is givenfor each case.
Over 40% of the time, the talker repeated words after the false start.
In order to recognizesuch sentences correctly, the system would have to detect false starts and back up to an appropriate arliersyntactic boundary.Category % ExampleSame Word 32 Wh(at) what's the street address of Cajun Yankee?Same Category 8 Show me the intersection of Har(vard) Hampshire Street and Cambridge Street.New Category 19 Where is the nearest restaurant to Memori(al) 305 Memorial Drive?Back Up 41 How do I get from the Ma(rriott) from the Marriott to Bel Canto's?Table 3: Breakdown of false starts in training sentences.We have examined the linguistic content of the training sentences and have begun to use them to expandVOYAGER's coverage.
We have found a number of new linguistic patterns that are entirely appropriate forthe domain, as well as a few recurring concepts currently outside of the domain that would be reasonableto add.
An example of the latter is a comparison between two objects, such as "Which is closer to here,MIT or Harvard University?"
In addition, we were surprised at the number of ways people said certain132Your directions were not good.Do you like their ice cream?Does the Baybank serve ice cream?Where is my dog?Does Hampshire and Broadway intersect?How far am I from Central Square to Cajun Yankee?Table 4: Examples of problematic sentences from the database.things.
For instance, for sentences like "What is the phone number of MIT?"
the prepositions, "of," "at,""for," and "to" were all used.
In a similar vein, the "from location" in a sentence requesting distancebetween two objects occurred in five distinct syntactic locations within the sentence.
Users also sometimesspoke ungrammatically, violating both syntactic and semantic onstraints.
In other cases they asked abstractquestions or questions involving judgment calls that would be inappropriate for VOYAGER to handle.
Some ofthese sentences were probably uttered ue to curiosity about how the system would respond.
Some examplesare given in Table 4.SUMMARYThis paper documents our initial effort in developing a spontaneous speech database, and reports somepreliminary analyses of the collected ata.
We found the process of data collection to be relatively straight-forward, and we believe it will be fairly easy to collect more data at a later stage, after VOYAGER's capabilitieshave improved.
In fact, we believe that incremental data collection done this way can be quite effective fordevelopment of spoken language systems.Our preliminary analysis of these data has already indicated some significant differences between spon-taneous and read speech.
We are also beginning to use the database to train and evaluate the VOYAGERsystem, both at the acoustic-phonetic and the linguistic levels.
The results of the preliminary evaluation aredescribed in a companion paper \[6\].AcknowledgmentsWe gratefully acknowledge the assistance of other members of the Spoken Language Systems Group forhelping us with data collection and transcription.
We would also like to thank our subjects, who offeredtheir time and effort for the sake of science and ice cream.References\[1\] Zue, V., Glass, J., Goodine, D., Leung, H., Phillips, M., Polifroni, J., and Seneff, S., "The VOYAGERSpeech Understanding System: A Progress Report," These Proceedings.\[2\] Zue, V., Glass, J., Phillips, M., and Seneff, S., "The MIT SUMMIT Speech Recognition System: AProgress Report," Proceedings of the First DARPA Speech and Natural Language Workshop, pp.
178-189, February, 1989.\[3\] Seneff, S., "TINA: A Probabilistic Syntactic Parser for Speech Understanding Systems," Proceedings ofthe First DARPA Speech and Natural Language Workshop, pp.
168-178, February, 1989.\[4\] Davis, J.R. and Trobaugh, T.F., "Directional Assistance," Technical Report 1, MIT Media LaboratorySpeech Group, December 1987.133\[5\] Rudnicky, A.I.
and Sakamoto, M.H., "Transcription Conventions for Spoken Language Research," CMUSchool of Computer Science Technical Report CMU-CS-89-194, 1989.\[6\] Zue, V., Glass, J., Goodine, D., Leung, It., Phillips, M., Polifroni, J., and Seneff, S., "PreliminaryEvaluation of the VOYAGER Spoken Language System," These Proceedings.134
