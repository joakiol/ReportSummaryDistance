Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1089?1096,Sydney, July 2006. c?2006 Association for Computational LinguisticsHighly constrained unification grammarsDaniel FeinsteinDepartment of Computer ScienceUniversity of Haifa31905 Haifa, Israeldaniel@cs.haifa.ac.ilShuly WintnerDepartment of Computer ScienceUniversity of Haifa31905 Haifa, Israelshuly@cs.haifa.ac.ilAbstractUnification grammars are widely acceptedas an expressive means for describing thestructure of natural languages.
In gen-eral, the recognition problem is undecid-able for unification grammars.
Even withrestricted variants of the formalism, off-line parsable grammars, the problem iscomputationally hard.
We present two nat-ural constraints on unification grammarswhich limit their expressivity.
We firstshow that non-reentrant unification gram-mars generate exactly the class of context-free languages.
We then relax the con-straint and show that one-reentrant unifi-cation grammars generate exactly the classof tree-adjoining languages.
We thus re-late the commonly used and linguisticallymotivated formalism of unification gram-mars to more restricted, computationallytractable classes of languages.1 IntroductionUnification grammars (UG) (Shieber, 1986;Shieber, 1992; Carpenter, 1992) have originatedas an extension of context-free grammars, the ba-sic idea being to augment the context-free ruleswith non context-free annotations (feature struc-tures) in order to express additional information.They can describe phonological, morphological,syntactic and semantic properties of languages si-multaneously and are thus linguistically suitablefor modeling natural languages.
Several formula-tions of unification grammars have been proposed,and they are used extensively by computationallinguists to describe the structure of a variety ofnatural languages.Unification grammars are Turing equivalent:determining whether a given string is generated bya given grammar is as hard as deciding whethera Turing machine halts on the empty input (John-son, 1988).
Therefore, the recognition problem forunification grammars is undecidable in the generalcase.
To ensure its decidability, several constraintson unification grammars, commonly known as theoff-line parsability (OLP) constraints, were sug-gested, such that the recognition problem is decid-able for off-line parsable grammars (Jaeger et al,2005).
The idea behind all the OLP definitions isto rule out grammars which license trees in whichunbounded amount of material is generated with-out expanding the frontier word.
This can happendue to two kinds of rules: -rules (whose bodiesare empty) and unit rules (whose bodies consistof a single element).
However, even for unifica-tion grammars with no such rules the recognitionproblem is NP-hard (Barton et al, 1987).In order for a grammar formalism to make pre-dictions about the structure of natural languageits generative capacity must be constrained.
It isnow generally accepted that Context-free Gram-mars (CFGs) lack the generative power needed forthis purpose (Savitch et al, 1987), due to natu-ral language constructions such as reduplication,multiple agreement and crossed agreement.
Sev-eral linguistic formalisms have been proposed ascapable of modeling these phenomena, includingLinear Indexed Grammars (LIG) (Gazdar, 1988),Head Grammars (Pollard, 1984), Tree Adjoin-ing Grammars (TAG) (Joshi, 2003) and Combina-tory Categorial Grammars (Steedman, 2000).
Ina seminal work, Vijay-Shanker and Weir (1994)prove that all four formalisms are weakly equiv-alent.
They all generate the class of mildlycontext-sensitive languages (MCSL), all members1089of which have recognition algorithms with timecomplexity O(n6) (Vijay-Shanker and Weir, 1993;Satta, 1994).1 As a result of the weak equiva-lence of four independently developed (and lin-guistically motivated) extensions of CFG, the classMCSL is considered to be linguistically meaning-ful, a natural class of languages for characterizingnatural languages.Several authors tried to approximate unifica-tion grammars by means of context-free gram-mars (Rayner et al, 2001; Kiefer and Krieger,2004) and even finite-state grammars (Pereira andWright, 1997; Johnson, 1998), but we are notaware of any work which relates unification gram-mars with the class MCSL.
The main objective ofthis work is to define constraints on UGs whichnaturally limit their generative capacity.
We de-fine two natural and easily testable syntactic con-straints on UGs which ensure that grammars sat-isfying them generate the context-free and themildly context-sensitive languages, respectively.The contribution of this result is twofold:?
From a theoretical point of view, constrainingunification grammars to generate exactly theclass MCSL results in a grammatical formal-ism which is, on one hand, powerful enoughfor linguists to express linguistic generaliza-tions in, and on the other hand cognitively ad-equate, in the sense that its generative capac-ity is constrained;?
Practically, such a constraint can provide ef-ficient recognition algorithms for the limitedclass of unification grammars.We define some preliminary notions in section 2and then show a constrained version of UG whichgenerates the class CFL of context-free languagesin section 3.
Section 4 presents the main result,namely a restricted version of UG and a mappingof its grammars to LIG, establishing the proposi-tion that such grammars generate exactly the classMCSL.
For lack of space, we favor intuitive expla-nation over rigorous proofs; the full details can befound in Feinstein (2004).2 Preliminary notionsA CFG is a four-tuple Gcf = ?VN , Vt,Rcf , S?where Vt is a set of terminals, VN is a set of non-1The term mildly context-sensitive was coined by Joshi(1985), in reference to a less formally defined class of lan-guages.
Strictly speaking, what we call MCSL here is alsoknown as the class of tree-adjoining languages.terminals, including the start symbol S, and Rcfis a set of productions, assumed to be in a nor-mal form where each rule has either (zero or more)non-terminals or a single terminal in its body, andwhere the start symbol never occurs in the righthand side of rules.
The set of all such context-freegrammars is denoted CFGS.In a linear indexed grammar (LIG),2 stringsare derived from nonterminals with an associatedstack denoted A[l1 .
.
.
ln], where A is a nontermi-nal, each li is a stack symbol, and l1 is the topof the stack.
Since stacks can grow to be of un-bounded size during a derivation, some way ofpartially specifying unbounded stacks in LIG pro-ductions is needed.
We use A[l1 .
.
.
ln ?]
to de-note the nonterminal A associated with any stack?
whose top n symbols are l1, l2 .
.
.
, ln.
The setof all nonterminals in VN , associated with stackswhose symbols come from Vs, is denoted VN [V ?s ].Definition 1.
A Linear Indexed Grammar is a fivetuple Gli = ?VN , Vt, Vs,Rli, S?
where Vt, VN andS are as above, Vs is a finite set of indices (stacksymbols) and Rli is a finite set of productions inone of the following two forms:?
fixed stack: Ni[p1 .
.
.
pn] ?
??
unbounded stack: Ni[p1 .
.
.
pn ?]
?
?
orNi[p1 .
.
.
pn ?]
?
?Nj [q1 .
.
.
qm ?
]?where Ni, Nj ?
VN , p1 .
.
.
pn, q1 .
.
.
qm ?
Vs,n,m ?
0 and ?, ?
?
(Vt ?
VN [V ?s ])?.A crucial characteristic of LIG is that only onecopy of the stack can be copied to a single elementin the body of a rule.
If more than one copy wereallowed, the expressive power would grow beyondMCSL.Definition 2.
Given a LIG ?VN , Vt, Vs,Rli, S?,the derivation relation ??li?
is defined as follows:for all ?1,?2 ?
(VN [V ?s ] ?
Vt)?
and ?
?
V ?s ,?
If Ni[p1 .
.
.
pn] ?
?
?
Rli then?1Ni[p1 .
.
.
pn]?2 ?li ?1??2?
If Ni[p1 .
.
.
pn ?]
?
?
?
Rli then?1Ni[p1 .
.
.
pn?
]?2 ?li ?1??2?
If Ni[p1 .
.
.
pn ?]
?
?Nj [q1 .
.
.
qm ?]?
?Rli then ?1Ni[p1 .
.
.
pn?
]?2 ?li?1?Nj [q1 .
.
.
qm?]?
?22The definition is based on Vijay-Shanker and Weir(1994).1090The language generated by Gli is L(Gli) = {w ?V ?t | S[ ]?
?li w}, where ???li?
is the reflexive,transitive closure of ?
?li?.Unification grammars are defined over fea-ture structures (FSs) which are directed, con-nected, rooted, labeled graphs, usually depicted asattribute-value matrices (AVM).
A feature struc-ture A can be characterized by its set of paths,?A, an assignment of atomic values to the ends ofsome paths, ?A(?
), and a reentrancy relation ?!
?relating paths which lead to the same node.
A se-quence of feature structures, where some nodesmay be shared by more than one element, is amulti-rooted structure (MRS).Definition 3.
Unification grammars are definedover a signature consisting of a finite set ATOMSof atoms; a finite set FEATS of features and a fi-nite set WORDS of words.
A unification grammaris a tuple Gu = ?Ru,As,L?
where Ru is a finiteset of rules, each of which is an MRS of lengthn ?
1, L is a lexicon, which associates with ev-ery word w ?
WORDS a finite set of feature struc-tures, L(w), and As is a feature structure, the startsymbol.Definition 4.
A unification grammar ?Ru,As,L?over the signature ?ATOMS, FEATS, WORDS?
isnon-reentrant iff for any rule ru ?
Ru, ru isnon-reentrant.
It is one-reentrant iff for every ruleru ?
Ru, ru includes at most one reentrancy, be-tween the head of the rule and some element ofthe body.
Let UGnr, UG1r be the sets of all non-reentrant and one-reentrant unification grammars,respectively.Informally, a rule is non-reentrant if (on anAVM view) no reentrancy tags occur in it.
Whenthe rule is viewed as a (multi-rooted) graph, it isnon-reentrant if the in-degree of all nodes is atmost 1.
A rule is one-reentrant if (on an AVMview) at most one reentrancy tag occurs in it, ex-actly twice: once in the head of the rule and oncein an element of its body.
When the rule is viewedas a (multi-rooted) graph, it is one-reentrant if thein-degree of all nodes is at most 1, with the excep-tion of one node whose in-degree can be 2, pro-vided that the only two distinct paths that lead tothis node leave from the roots of the head of therule and an element of the body.FSs and MRSs are partially ordered by sub-sumption, denoted ?v?.
The least upper boundwith respect to subsumption is unification, de-noted ?unionsq?.
Unification is partial; when A unionsq B isundefined we say that the unification fails and de-note it as AunionsqB = >.
Unification is lifted to MRSs:given two MRSs ?
and ?, it is possible to unifythe i-th element of ?
with the j-th element of ?.This operation, called unification in context anddenoted (?, i) unionsq (?, j), yields two modified vari-ants of ?
and ?
: (?
?, ??
).In unification grammars, forms are MRSs.
Aform ?A = ?A1, .
.
.
,Ak?
immediately derivesanother form ?B = ?B1, .
.
.
,Bm?
(denoted by?A1?u ?B) iff there exists a rule ru ?
Ru oflength n that licenses the derivation.
The headof ru is matched against some element Ai in ?Ausing unification in context: (?A, i) unionsq (ru, 0) =(?
?A, r?).
If the unification does not fail, ?B is ob-tained by replacing the i-th element of ?
?A with thebody of r?.
The reflexive transitive closure of ?
1?u?is denoted by ?
?
?u?.Definition 5.
The language of a unification gram-mar Gu is L(Gu) = {w1 ?
?
?wn ?
WORDS?
|As ?
?u ?A1, .
.
.
,An?
}, where Ai ?
L(wi) for1 ?
i ?
n.3 Context-free unification grammarsWe define a constraint on unification grammarswhich ensures that grammars satisfying it generatethe class CFL.
The constraint disallows any reen-trancies in the rules of the grammar.
When rulesare non-reentrant, applying a rule implies that anexact copy of the body of the rule is insertedinto the generated (sentential) form, not affectingneighboring elements of the form the rule is ap-plied to.
The only difference between rule appli-cation in UGnr and the analog operation in CFGSis that the former requires unification whereas thelatter only calls for identity check.
This small dif-ference does not affect the generative power of theformalisms, since unification can be pre-compiledin this simple case.The trivial direction is to map a CFG to a non-reentrant unification grammar, since every CFGis, trivially, such a grammar (where terminal andnon-terminal symbols are viewed as atomic fea-ture structures).
For the inverse direction, we de-fine a mapping from UGnr to CFGS.
The non-terminals of the CFG in the image of the mappingare the set of all feature structures defined in thesource UG.Definition 6.
Let ug2cfg : UGnr 7?
CFGSbe a mapping of UGnr to CFGS, such that1091if Gu = ?Ru,As,L?
is over the signature?ATOMS, FEATS, WORDS?
then ug2cfg(Gu) =?VN , Vt,Rcf , Scf ?, where:?
VN = {Ai | A0 ?
A1 .
.
.An ?
Ru, i ?
0} ?
{A | A ?
L(a), a ?
ATOMS} ?
{As}.
VN isthe set of all the feature structures occurringin any of the rules or the lexicon of Gu.?
Scf = As ?
Vt = WORDS?
Rcf consists of the following rules:1.
Let A0 ?
A1 .
.
.An ?
Ru and B ?L(b).
If for some i, 1 ?
i ?
n, AiunionsqB 6=>, then Ai ?
b ?
Rcf2.
If A0 ?
A1 .
.
.An ?
Ru and AsunionsqA0 6=> then Scf ?
A1 .
.
.An ?
Rcf .3.
Let ru1 = A0 ?
A1 .
.
.An and ru2 =B0 ?
B1 .
.
.Bm, where ru1 , ru2 ?
Ru.
Iffor some i, 1 ?
i ?
n, Ai unionsq B0 6= >,then the rule Ai ?
B1 .
.
.Bm ?
RcfThe size of ug2cfg(Gu) is polynomial in thesize of Gu.
By inductions on the lengths of thederivation sequences, we prove the following the-orem:Theorem 1.
If Gu = ?Ru,As,L?
is a non-reentrant unification grammar and Gcf =ug2cfg(Gu), then L(Gcf ) = L(Gu).Corollary 2.
Non-reentrant unification grammarsare weakly equivalent to CFGS.4 Mildly context-sensitive UGIn this section we show that one-reentrant unifica-tion grammars generate exactly the class MCSL.In such grammars each rule can have at mostone reentrancy, reflecting the LIG situation wherestacks can be copied to exactly one daughter ineach rule.4.1 Mapping LIG to UG1rIn order to simulate a given LIG with a unificationgrammar, a dedicated signature is defined basedon the parameters of the LIG.Definition 7.
Given a LIG ?VN , Vt, Vs,Rli, S?, let?
be ?ATOMS, FEATS, WORDS?, where ATOMS =VN ?
Vs ?
{elist}, FEATS = {HEAD, TAIL}, andWORDS = Vt.We use ?
throughout this section as the signa-ture over which UGs are defined.
We use FSs overthe signature ?
to represent and simulate LIG sym-bols.
In particular, FSs will encode lists in the nat-ural way, hence the features HEAD and TAIL.
Forthe sake of brevity, we use standard list notationwhen FSs encode lists.
LIG symbols are mappedto FSs thus:Definition 8.
Let toFs be a mapping of LIG sym-bols to feature structures, such that:1.
If t ?
Vt then toFs(t) = ?t?2.
If N ?
VN and pi ?
Vs, 1 ?
i ?
n, thentoFs(N [p1, .
.
.
, pn]) = ?N, p1, .
.
.
, pn?The mapping toFs is extended to sequences ofsymbols by setting toFs(??)
= toFs(?)toFs(?
).Note that toFs is one to one.When FSs that are images of LIG symbols areconcerned, unification is reduced to identity:Lemma 3.
Let X1, X2 ?
VN [V ?s ] ?
Vt. IftoFs(X1) unionsq toFs(X2) 6= > then toFs(X1) =toFs(X2).When a feature structure which is represented asan unbounded list (a list that is not terminated byelist) is unifiable with an image of a LIG symbol,the former is a prefix of the latter.Lemma 4.
Let C = ?p1, .
.
.
, pn, i ?
be a non-reentrant feature structure, where p1, .
.
.
, pn ?Vs, and letX ?
VN [V ?s ]?Vt.
Then Cunionsq toFs(X) 6=> iff toFs(X) = ?p1, .
.
.
, pn, ?
?, for some ?
?V ?s .To simulate LIGs with UGs we represent eachsymbol in the LIG as a feature structure, encod-ing the stack of LIG non-terminals as lists.
Rulesthat propagate stacks (from mother to daughter)are simulated by means of reentrancy in the UG.Definition 9.
Let lig2ug be a mapping of LIGS toUG1r, such that if Gli = ?VN , Vt, Vs,Rli, S?
andGu = ?Ru,As,L?
= lig2ug(Gli) then Gu is overthe signature ?
(definition 7), As = toFs(S[ ]), forall t ?
Vt, L(t) = {toFs(t)} and Ru is definedby:?
A LIG rule of the form X0 ?
?
is mapped tothe unification rule toFs(X0) ?
toFs(?)?
A LIG rule of the form Ni[p1, .
.
.
, pn ?]
??
Nj [q1, .
.
.
, qm ?]
?
is mapped to theunification rule ?Ni, p1, .
.
.
, pn, 1 ?
?toFs(?)
?Nj , q1, .
.
.
, qm, 1 ?
toFs(?
)Evidently, lig2ug(Gli) ?
UG1r for any LIGGli.1092Theorem 5.
If Gli = ?VN , Vt, Vs,Rli, Sli?
is aLIG and Gu = lig2ug(Gli) then L(Gu) = L(Gli).4.2 Mapping UG1r to LIGWe are now interested in the reverse direction,namely mapping UGs to LIG.
Of course, sinceUGs are more expressive than LIGs, only a sub-set of the former can be correctly simulated by thelatter.
The differences between the two formalismscan be summarized along three dimensions:The basic elements UG manipulates featurestructures, and rules (and forms) are MRSs;whereas LIG manipulates terminals andnon-terminals with stacks of elements, andrules (and forms) are sequences of suchsymbols.Rule application In UG a rule is applied by uni-fication in context of the rule and a sententialform, both of which are MRSs, whereas inLIG, the head of a rule and the selected ele-ment of a sentential form must have the samenon-terminal symbol and consistent stacks.Propagation of information in rules In UG in-formation is shared through reentrancies,whereas In LIG, information is propagated bycopying the stack from the head of the rule toone element of its body.We show that one-reentrant UGs can all be cor-rectly mapped to LIG.
For the rest of this sectionwe fix a signature ?ATOMS, FEATS, WORDS?
overwhich UGs are defined.
Let NRFSS be the set ofall non-reentrant FSs over this signature.One-reentrant UGs induce highly constrained(sentential) forms: in such forms, there are noreentrancies whatsoever, neither between distinctelements nor within a single element.
Hence allthe FSs in forms induced by a one-reentrant UGare non-reentrant.Definition 10.
Let A be a feature structure with noreentrancies.
The height of A, denoted |A|, is thelength of the longest path in A.
This is well-definedsince non-reentrant feature structures are acyclic.Let Gu = ?Ru,As,L?
?
UG1r be a one-reentrantunification grammar.
The maximum height of thegrammar, maxHt(Gu), is the height of the high-est feature structure in the grammar.
This is welldefined since all the feature structures of one-reentrant grammars are non-reentrant.The following lemma indicates an importantproperty of one-reentrant UGs.
Informally, in anyFS that is an element of a sentential form inducedby such grammars, if two paths are long (specif-ically, longer than the maximum height of thegrammar), they must have a long common prefix.Lemma 6.
Let Gu = ?Ru,As,L?
?
UG1r be aone-reentrant unification grammar.
Let A be anelement of a sentential form induced by Gu.
If pi ??Fj?
?pi1, pi ??Fk?
?pi2 ?
?A, where Fj , Fk ?
FEATS,j 6= k and |pi1| ?
|pi2|, then |pi1| ?
maxHt(Gu).Lemma 6 facilitates a view of all the FSs in-duced by such a grammar as (unboundedly long)lists of elements drawn from a finite, predefinedset.
The set consists of all features in FEATSand all the non-reentrant feature structures whoseheight is limited by the maximal height of theunification grammar.
Note that even with one-reentrant UGs, feature structures can be unbound-edly deep.
What lemma 6 establishes is that if afeature structure induced by a one-reentrant uni-fication grammar is deep, then it can be repre-sented as a single ?core?
path which is long, andall the sub-structures which ?hang?
from this coreare depth-bounded.
We use this property to encodesuch feature structures as cords.Definition 11.
Let ?
: NRFSS ?
PATHS 7?
(FEATS ?
NRFSS)?
be a mapping suchthat if A is a non-reentrant FS andpi = ?F1, .
.
.
, Fn?
?
?A, then the cord?
(A, pi) is ?A1, F1, .
.
.
,An, Fn,An+1?, wherefor 1 ?
i ?
n + 1, Ai are non-reentrant FSs suchthat:?
?Ai = {?G?
?
pi | ?F1, .
.
.
, Fi?1, G?
?
pi ?
?A, i ?
n, G 6= Fi} ?
{?}?
?Ai(pi) = ?A(?F1, .
.
.
, Fi?1?
?
pi) (if it is de-fined).We also define last(?
(A, pi)) = An+1.
Theheight of a cord is defined as |?
(A, pi)| =max1?i?n+1(|Ai|).
For each cord ?
(A, pi) we re-fer to A as the base feature structure and to pi asthe base path.
The length of a cord is the lengthof the base path.The function ?
is one to one: given ?
(A, pi),both A and pi are uniquely determined.Lemma 7.
Let Gu be a one-reentrant unificationgrammar and let A be an element of a sententialform induced by Gu.
Then there is a path pi ?
?Asuch that |?
(A, pi)| < maxHt(Gu).1093Lemma 7 implies that every non-reentrant FS(i.e., FSs induced by one-reentrant grammars) canbe represented as a height-limited cord.
This map-ping resolves the first difference between LIG andUG, by providing a representation of the basic el-ements.
We use cords as the stack contents of LIGnon-terminals: cords can be unboundedly long,but so can LIG stacks; the crucial point is thatcords are height limited, implying that they can berepresented using a finite number of elements.We now show how to simulate, in LIG, the uni-fication in context of a rule and a sentential form.The first step is to have exactly one non-terminalsymbol (in addition to the start symbol); when allnon-terminal symbols are identical, only the con-tent of the stack has to be taken into account.
Re-call that in order for a LIG rule to be applicableto a sentential form, the stack of the rule?s headmust be a prefix of the stack of the selected ele-ment in the form.
The only question is whether thetwo stacks are equal (fixed rule head) or not (un-bounded rule head).
Since the contents of stacksare cords, we need a property relating two cords,on one hand, with unifiability of their base featurestructures, on the other.
Lemma 8 establishes sucha property.
Informally, if the base path of one cordis a prefix of the base path of the other cord and allfeature structures along the common path of bothcords are unifiable, then the base feature structuresof both cords are unifiable.
The reverse directionalso holds.Lemma 8.
Let A,B ?
NRFSS be non-reentrantfeature structures and pi1, pi2 ?
PATHS be pathssuch that pi1 ?
?B , pi1 ?pi2 ?
?A, ?
(A, pi1 ?pi2) =?t1, F1, .
.
.
, F|pi1|, t|pi1|+1, F|pi1|+1, .
.
.
, t|pi1?pi2|+1?,?
(B, pi1) = ?s1, F1, .
.
.
, s|pi1|+1?, and?F|pi1|+1?
6?
?s|pi1|+1 .
Then A unionsq B 6= > ifffor all i, 1 ?
i ?
|pi1|+ 1, si unionsq ti 6= >.The length of a cord of an element of a sen-tential form induced by the grammar cannot bebounded, but the length of any cord representationof a rule head is limited by the grammar height.
Bylemma 8, unifiability of two feature structures canbe reduced to a comparison of two cords represent-ing them and only the prefix of the longer cord (aslong as the shorter cord) affects the result.
Sincethe cord representation of any grammar rule?s headis limited by the height of the grammar we alwayschoose it as the shorter cord in the comparison.We now define, for a feature structure C (whichis a head of a rule) and some path pi, the set thatincludes all feature structures that are both unifi-able with C and can be represented as a cord whoseheight is limited by the grammar height and whosebase path is pi.
We call this set the compatibility setof C and pi and use it to define the set of all possi-ble prefixes of cords whose base FSs are unifiablewith C (see definition 13).
Crucially, the compat-ibility set of C is finite for any feature structure Csince the heights and the lengths of the cords arelimited.Definition 12.
Given a non-reentrant featurestructure C, a path pi = ?F1, .
.
.
, Fn?
?
?Cand a natural number h, the compatibility set,?
(C, pi, h), is defined as the set of all feature struc-tures A such that C unionsq A 6= >, pi ?
?A, and|?
(A, pi)| ?
h.The compatibility set is defined for a featurestructure and a given path (when h is taken to bethe grammar height).
We now define two similarsets, FH and UH, for a given FS, independently ofa path.
When rules of a one-reentrant unificationgrammar are mapped to LIG rules (definition 14),FH and UH are used to define heads of fixed andunbounded LIG rules, respectively.
A single unifi-cation rule is mapped to a set of LIG rules, eachwith a different head.
The stack of the head issome member of the sets FH and UH.
Each suchmember is a prefix of the stack of potential ele-ments of sentential forms that the LIG rule can beapplied to.Definition 13.
Let C be a non-reentrant featurestructure and h be a natural number.
Then:FH(C, h) = {?
(A, pi) | pi ?
?C ,A ?
?
(C, pi, h)}UH(C, h) = {?
(A, pi) ?
?F?
| ?
(A, pi) ?
FH(C, h),?C(pi) ?, F ?
FEATS, val(last(?
(C unionsq A, pi)), ?F?)
?
}This accounts for the second difference betweenLIG and one-reentrant UG, namely rule appli-cation.
We now briefly illustrate our account ofthe last difference, propagation of information inrules.
In UG1r information is shared between therule?s head and a single element in its body.
Letru = ?C0, .
.
.
,Cn?
be a reentrant unification rulein which the path ?e, leaving the e-th element ofthe body, is reentrant with the path ?0 leaving thehead.
This rule is mapped to a set of LIG rules,corresponding to the possible rule heads inducedby the compatibility set of C0.
Let r be a memberof this set, and let X0 and Xe be the head and thee-th element of r, respectively.
Reentrancy in ru ismodeled in the LIG rule by copying the stack fromX0 to Xe.
The major complication is the contents1094of this stack, which varies according to the cordrepresentations of C0 and Ce and to the reentrantpaths.Summing up, in a LIG simulating a one-reentrant UG, FSs are represented as stacks ofsymbols.
The set of stack symbols Vs, therefore,is defined as a set of height bounded non-reentrantFSs.
Also, all the features of the UG are stacksymbols.
Vs is finite due to the restriction on FSs(no reentrancies and height-boundedness).
The setof terminals, Vt, is the words of the UG.
Thereare exactly two non-terminal symbols, S (the startsymbol) and N .The set of rules is divided to four.
The startrule only applies once in a derivation, simulatingthe situation in UGs of a rule whose head is unifi-able with the start symbol.
Terminal rules are astraight-forward implementation of the lexicon interms of LIG.
Non-reentrant rules are simulatedin a similar way to how rules of a non-reentrantUG are simulated by CFG (section 3).
The ma-jor difference is the head of the rule, X0, whichis defined as explained above.
One-reentrant rulesare simulated similarly to non-reentrant ones, theonly difference being the selected element of therule body, Xe, which is defined as follows.Definition 14.
Let ug2lig be a mapping of UG1rto LIGS, such that if Gu = ?Ru,As,L?
?
UG1rthen ug2lig(Gu) = ?VN , Vt, Vs,Rli, S?, whereVN = {N,S} (fresh symbols), Vt = WORDS,Vs = FEATS ?
{A | A ?
NRFSS, |A| ?maxHt(Gu)}, and Rli is defined as follows:31.
S[ ] ?
N [?
(As, ?)]2.
For every w ?
WORDS such that L(w) ={C0} and for every pi0 ?
?C0 , the ruleN [?
(C0, pi0)] ?
w is in Rli.3.
If ?C0, .
.
.
,Cn?
?
Ru is a non-reentrantrule, then for every X0 ?
LIGHEAD(C0) therule X0 ?
N [?
(C1, ?)]
.
.
.
N [?
(Cn, ?)]
isin Rli.4.
Let ru = ?C0, .
.
.
,Cn?
?
Ru and (0, ?0)ru!
(e, ?e), where 1 ?
e ?
n. Then for everyX0 ?
LIGHEAD(C0) the ruleX0 ?
N [?
(C1, ?)]
.
.
.
N [?
(Ce?1, ?
)]XeN [?
(Ce+1, ?)]
.
.
.
N [?
(Cn, ?
)]3For a non-reentrant FS C0, we define: LIGHEAD(C0)as {N [?]
| ?
?
FH(C0,maxHt(Gu))} ?
{N [?
?]
| ?
?UH(C0,maxHt(Gu))}is in Rli, where Xe is defined as follows.Let pi0 be the base path of X0 and A bethe base feature structure of X0.
Applyingthe rule ru to A, define (?A?, 0) unionsq (ru, 0) =(?P0?, ?P0, .
.
.
,Pe, .
.
.
,Pn?).
(a) If ?0 is not a prefix of pi0 then Xe =N [?
(Pe, ?e)].
(b) If pi0 = ?0 ?
?, ?
?
PATHS theni.
If X0 = N [?
(A, pi0)] then Xe =N [?
(Pe, ?e ?
?)].ii.
If X0 = N [?
(A, pi0), F ?]
thenXe = N [?
(Pe, ?e ?
?
), F ?
].By inductions on the lengths of the derivationswe prove that the mapping is correct:Theorem 9.
If Gu ?
UG1r, then L(Gu) =L(ug2lig(Gu)).5 ConclusionsThe main contribution of this work is the definitionof two constraints on unification grammars whichdramatically limit their expressivity.
We provethat non-reentrant unification grammars generateexactly the class of context-free languages; andthat one-reentrant unification grammars generateexactly the class of mildly context-sensitive lan-guages.
We thus obtain two linguistically plausi-ble constrained formalisms whose computationalprocessing is tractable.This main result is primarily a formal grammarresult.
However, we maintain that it can be easilyadapted such that its consequences to (practical)computational linguistics are more evident.
Themotivation behind this observation is that reen-trancy only adds to the expressivity of a gram-mar formalism when it is potentially unbounded,i.e., when infinitely many feature structures canbe the possible values at the end of the reentrantpaths.
It is therefore possible to modestly ex-tend the class of unification grammars which canbe shown to generate exactly the class of mildlycontext-sensitive languages, by allowing also alimited form of multiple reentrancies among theelements in a rule (e.g., to handle agreement phe-nomena).
This can be most useful for grammarwriters, and at the same time adds nothing to theexpressivity of the formalism.
We leave the formaldetails of such an extension to future work.This work can also be extended in other direc-tions.
The mapping of one-reentrant UGs to LIGis highly verbose, resulting in LIGs with a huge1095number of rules.
We believe that it should bepossible to optimize the mapping such that muchsmaller grammars are generated.
In particular, weare looking into mappings of one-reentrant UGs toother MCSL formalisms, notably TAG.The two constraints on unification grammars(non-reentrant and one-reentrant) are parallel tothe first two classes of the Weir (1992) hierarchyof languages.
A possible extension of this workcould be a definition of constraints on unificationgrammars that would generate all the classes ofthe hierarchy.
Another direction is an extensionof one-reentrant unification grammars, where thereentrancy does not have to be between the headand one element of the body.
Also of interest aretwo-reentrant unification grammars, possibly withlimited kinds of reentrancies.AcknowledgmentsThis research was supported by The Israel ScienceFoundation (grant no.
136/01).
We are gratefulto Yael Cohen-Sygal, Nissim Francez and JamesRogers for their comments and help.ReferencesG.
Edward Barton, Jr., Robert C. Berwick, andEric Sven Ristad.
1987.
The complexity of LFG.In G. Edward Barton, Jr., Robert C. Berwick, andEric Sven Ristad, editors, Computational Complex-ity and Natural Language, Computational Models ofCognition and Perception, chapter 3, pages 89?102.MIT Press, Cambridge, MA.Bob Carpenter.
1992.
The Logic of Typed FeatureStructures.
Cambridge University Press.Daniel Feinstein.
2004.
Computational investigationof unification grammars.
Master?s thesis, Universityof Haifa.Gerald Gazdar.
1988.
Applicability of indexed gram-mars to natural languages.
In Uwe Reyle and Chris-tian Rohrer, editors, Natural Language Parsing andLinguistic Theories, pages 69?94.
Reidel.Efrat Jaeger, Nissim Francez, and Shuly Wintner.2005.
Unification grammars and off-line parsabil-ity.
Journal of Logic, Language and Information,14(2):199?234.Mark Johnson.
1988.
Attribute-Value Logic and theTheory of Grammar, volume 16 of CSLI LectureNotes.
CSLI, Stanford, California.Mark Johnson.
1998.
Finite-state approximation ofconstraint-based grammars using left-corner gram-mar transforms.
In Proceedings of the 17th inter-national conference on Computational linguistics,pages 619?623.Aravind K. Joshi.
1985.
Tree Adjoining Grammars:How much context Sensitivity is required to providea reasonable structural description.
In D. Dowty,I.
Karttunen, and A. Zwicky, editors, Natural Lan-guage Parsing, pages 206?250.
Cambridge Univer-sity Press, Cambridge, U.K.Aravind K. Joshi.
2003.
Tree-adjoining grammars.
InRuslan Mitkov, editor, The Oxford handbook of com-putational linguistics, chapter 26, pages 483?500.Oxford university Press.Bernd Kiefer and Hans-Ulrich Krieger.
2004.
Acontext-free superset approximation of unification-based grammars.
In Harry Bunt, John Carroll, andGiorgio Satta, editors, New Developments in Pars-ing Technology, pages 229?250.
Kluwer AcademicPublishers.Fernando C. N. Pereira and Rebecca N. Wright.
1997.Finite-state approximation of phrase-structure gram-mars.
In Emmanuel Roche and Yves Schabes, edi-tors, Finite-State Language Processing, Language,Speech and Communication, chapter 5, pages 149?174.
MIT Press, Cambridge, MA.Carl Pollard.
1984.
Generalized phrase structuregrammars, head grammars and natural language.Ph.D.
thesis, Stanford University.Manny Rayner, John Dowding, and Beth Ann Hockey.2001.
A baseline method for compiling typed uni-fication grammars into context free language mod-els.
In Proceedings of EUROSPEECH 2001, Aal-borg, Denmark.Giorgio Satta.
1994.
Tree-adjoining grammar parsingand boolean matrix multiplication.
In Proceedingsof the 20st Annual Meeting of the Association forComputational Linguistics, volume 20.Walter J. Savitch, Emmon Bach, William Marsh, andGila Safran-Naveh, editors.
1987.
The formal com-plexity of natural language, volume 33 of Studies inLinguistics and Philosophy.
D. Reidel, Dordrecht.Stuart M. Shieber.
1986.
An Introduction to Unifica-tion Based Approaches to Grammar.
Number 4 inCSLI Lecture Notes.
CSLI.Stuart M. Shieber.
1992.
Constraint-Based GrammarFormalisms.
MIT Press, Cambridge, Mass.Mark Steedman.
2000.
The Syntactic Process.
Lan-guage, Speech and Communication.
The MIT Press,Cambridge, Mass.K.
Vijay-Shanker and David J. Weir.
1993.
Parsingsome constrained grammar formalisms.
Computa-tional Linguistics, 19(4):591 ?
636.K.
Vijay-Shanker and David J. Weir.
1994.
The equiv-alence of four extensions of context-free grammars.Mathematical systems theory, 27:511?545.David J. Weir.
1992.
A geometric hierarchy beyondcontext-free languages.
Theoretical Computer Sci-ence, 104:235?261.1096
