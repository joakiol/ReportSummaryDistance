Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 77?80,Paris, October 2009. c?2009 Association for Computational LinguisticsTwo stage constraint based hybrid approach to free word order lan-guage dependency parsingAkshar Bharati, Samar Husain, Dipti Misra and Rajeev SangalLanguage Technologies Research Centre, IIIT-Hyderabad, India{samar, dipti, sangal}@mail.iiit.ac.inAbstractThe paper describes the overall design of anew two stage constraint based hybrid ap-proach to dependency parsing.
We definethe  two  stages  and  show  how  differentgrammatical construct are parsed at appro-priate stages.
This division leads to selec-tive identification and resolution of specif-ic dependency relations at the two stages.Furthermore,  we  show  how  the  use  ofhard constraints and soft constraints helpsus  build  an  efficient  and  robust  hybridparser.
Finally,  we  evaluate  the  imple-mented parser on Hindi and compare theresults with that of two data driven depen-dency parsers.1 IntroductionDue to the availability of annotated corpora forvarious  languages  since  the  past  decade,  datadriven parsing has proved to be immensely suc-cessful.
Unlike  English,  however,  most  of  theparsers for morphologically rich free word order(MoR-FWO) languages (such as Czech, Turkish,Hindi, etc.)
have adopted the dependency gram-matical  framework.
It  is  well  known  that  forMoR-FWO  languages,  dependency  frameworkprovides ease of linguistic analysis and is muchbetter  suited to account  for  their  various struc-tures (Shieber, 1975; Mel'Cuk, 1988; Bharati etal., 1995).
The state of the art parsing accuracyfor many MoR-FWO languages is still low com-pared  to  that  of  English.
Parsing  experiments(Nivre et al,  2007; Hall  et  al.,  2007) for  theselanguages have pointed towards various reasonsfor this low performance.
For Hindi1, (a) difficul-ty in extracting relevant linguistic cues, (b) non-projectivity,  (c)  lack  of  explicit  cues,  (d)  longdistance  dependencies,  (e)  complex  linguisticphenomena,  and (f)  less corpus size, have beensuggested (Bharati  et  al.,  2008) for  low perfor-1  Hindi is a verb final language with free word order anda rich case marking system.
It is one of the official lan-guages of India, and is spoken by ~800 million people.mance.
The  approach  proposed  in  this  papershows how one can minimize these adverse ef-fects and argues that a hybrid approach can proveto be a better option to parsing such languages.There have been, in the past, many attempts toparsing using constraint based approaches.
Somerecent  works include (Debusmann et  al.,  2004;Schr?der, 2002; Bharati et al, 1993).The  paper  describes  the  overall  design  of  anew two stage constraint based hybrid approachto dependency parsing.
We define the two stagesand  show how different  grammatical  constructare  parsed  at  appropriate  stages.
This  divisionleads to selective identification and resolution ofspecific  dependency  relations  at  two  differentstages.
Furthermore,  we  show  how  the  use  ofhard  constraints  (H-constraints)  and  soft  con-straints (S-constraints) helps us build an efficientand  robust  hybrid  parser.
Specifically,  H-con-straints  incorporate  the  knowledge  base  of  thelanguage  and  S-constraints  are  weights  corre-sponding  to  various  constraints.
These  weightsare automatically learnt from an annotated tree-bank.
Finally, we evaluate the implemented pars-er on Hindi and compare the results with that oftwo data driven dependency parsers.2 Two Stage ParsingThe parser tries to analyze the given input sen-tence, which has already been POS tagged andchunked2, in 2 stages; it first tries to extract intra-clausal3 dependency  relations.
These  relationsgenerally correspond to the argument structure ofthe verb, noun-noun genitive relation, infinitive-verb relation, infinitive-noun relation, adjective-noun, adverb-verb relations, etc.
In the 2nd stageit  then  tries  to  handle  more  complex  relationssuch as conjuncts, relative clause, etc.
What this2  A chunk is a set of adjacent words which are in depen-dency relation with each other, and are connected to therest of the words by a single incoming arc.
The parsermarks relations between the head of the chunks (inter-chunk relations); this is done to avoid local details andcan be thought as a device for modularity.3  A clause is a group of word such that the group con-tains a single finite verb chunk.77essentially means is  a 2-stage resolution of de-pendencies, where the parser selectively resolvesthe dependencies of various lexical heads at theirappropriate  stage,  for  example  verbs  in  the  1ststage  and  conjuncts  and  inter-verb  relations  inthe 2nd  stage.
The key ideas of the proposed lay-ered  architecture  are:  (1)  There  are  two layersstages, (2) the 1st stage handles intra-clausal rela-tions, and the 2nd stage handles inter-clausal rela-tions, (3) the output of each layer is a linguisti-cally valid partial parse that becomes, if neces-sary, the input to the next layer, and (4) the out-put of the final layer is the desired full parse.By following the above approach we are ableto get 4-fold advantage, (1) Each layer in effectdoes linguistically valid partial parsing, (2) by di-viding  the  labels  into  different  functional  sets(intra-clausal  and  inter-clausal)  we localize  thedependencies  that  need  to  be  identified,  hencethe  problem  of  long  distance  dependencies  isminimizes,  (3)  by  attacking  the  problem  in  amodular way, i.e.
handling only individual claus-es  at  1st stage,  we reduce non-projective  struc-tures  significantly,  and  (4)  the  two stage  con-straint  based approach can easily  capture  com-plex linguistic cues that are difficult to learn viathe data-driven parsers.
We?ll revisit these pointsin Section 5.
The 1st stage output for example 1 isshown in figure 1 (a).Eg.
1: mai   ghar     gayaa   kyomki    mai?I?
?home?
?went?
?because?
?I?bimaar   thaa?sick?
?was?
?I went home because I was sick?Figure 1.
Eg 1 (a): 1st stage output, (b): 2nd stagefinal parseIn figure 1a, the parsed matrix clause subtree?mai ghar gayaa?
and the subordinate clause areattached to _ROOT_.
The subordinating conjunct?kyomki?
is  also seen attached to the _ROOT_._ROOT_ ensures that the parse we get after eachstage is connected and takes all the analyzed 1ststage sub-trees along with unprocessed nodes asits children.
The dependency tree thus obtainedin the 1st stage is partial, but linguistically sound.Later  in  the  2nd stage  the  relationship  betweenvarious clauses are identified.
The 2nd stage parsefor the above sentences is also shown in figure1b.
Note  that  under  normal  conditions  the  2ndstage  does  not  modify  the  parse  sub-trees  ob-tained from the 1st stage, it only establishes therelations between the clauses.3 Hard and Soft ConstraintsBoth 1st and 2nd stage described in the previ-ous  section  use  linguistically  motivated  con-straints.
These  hard  constraints  (H-constraints)reflect that aspect of the grammar that in generalcannot be broken.
H-constraints comprise of lex-ical  and  structural  knowledge  of  the  language.The H-constraints are converted into integer pro-gramming  problem  and  solved  (Bharati  et  al.,1995).
The solution(s) is/are valid parse(s).
Thesoft  constraints (S-constraints) on the other handare learnt as weights from an annotated treebank.They reflect various preferences that a languagehas towards various linguistic phenomena.
Theyare  used to  prioritize  the  parses  and select  thebest parse.
Both H & S constraints reflect the lin-guistic realities of the language and together canbe thought as the grammar of a language.
Figure2 shows the overall design of the proposed parserschematically.3.1 Hard ConstraintsThe  core  language  knowledge  being  currentlyconsidered  that  cannot  be  broken  without  thesentence  being  called  ungrammatical  is  namedH-constraints.
There  can  be  multiple  parseswhich can satisfy these H-constraints.
This indi-cates the  ambiguity in  the  sentence if  only thelimited knowledge base is considered.
Stated an-other  way,  H-constraints  are  insufficient  to  re-strict  multiple analysis of a given sentence andthat  more  knowledge  (semantics,  other  prefer-ences, etc.)
is required to curtain the ambiguities.Moreover, we know that many sentences are syn-tactically ambiguous unless one uses some prag-matic knowledge, etc.
For all such constructionsthere  are  multiple  parses.
As  described  earlier,H-constraints  are  used  during  intra-clausal  (1ststage)  and inter-clausal  (2nd stage)  analysis  (cf.Figure  2).
They  are  used  to  form  a  constraintgraph which is converted into integer program-ming equalities (or inequalities).
These are thensolved to get the final solution graph(s).
Some ofthe H-constraints are: (1)  Structural constraints(ensuring the solution graph to be a tree,78Figure 2.
Overall parser designremoving implausible language specific ungram-matical  structures,  etc.
),  (2)  Lexicon (linguisticdemands  of various heads), and (3)  Other lexi-cal constraints (some language specific  charac-teristics), etc.3.2 Soft ConstraintsThe S-constraints on the other hand are the con-straints which can be broken, and are used in thelanguage as preferences.
These are used duringthe prioritization stage.
Unlike the H-constraintsthat are derived from a knowledge base and areused  to  form  a  constraint  graph,  S-constraintshave  weights  assigned  to  them.
These  weightsare automatically learnt using a manually anno-tated  dependency  treebank.
The  tree  with  themaximum overall score is the best parse.
Somesuch  S-constraints are,  (1)  Order of the argu-ments, (2)  Relative position of arguments w.r.t.the verb, (3) Agreement principle, (4) Alignmentof  prominence scale,  and (5)  Structural  prefer-ences/General  graph properties  (mild  non-pro-jectivity, valency, dominance, etc.
), etc.4 EvaluationMalt Parser (version 0.4) (Nivre et al, 2007), andMST  Parser  (version  0.4b)  (McDonald  et  al.,2005) have been tuned for Hindi by Bharati et al(2008).
Parsers were trained on a subset of a Hin-di Treebank (Begum et al, 2008a).
We use thesame  experimental  setup  (parameters,  features,etc.)
used by them and compare the results of thetwo data driven parsers with that of the proposedconstraint  based  hybrid  parser  (CBP)  on  thesame dataset4 in terms of4 For details on the corpus type, annotation scheme,tagset, etc.
see Begum et al (2008a).unlabeled  attachments  (UA),  label  (L)  and  la-beled  attachment  (LA)  accuracy.
In  Table  1,CBP?
shows the performance of the system whena basic prioritizer is used, while CBP??
shows itfor the best parse that is available in the first 25parses.
CBP  gives  the  accuracy  when  the  1stparse is selected.
We show CBP??
to show that agood parse is available in as few as the first 25parses and that once the prioritizer is further im-proved the overall performance will easily crossCBP?
?.UA LA LCBP 86.1 63 65CBP?
87.69 69.67 72.39CBP?
90.1 75 76.9MST 87.8 70.4 72.3Malt 86.6 68.0 70.6Table 1.
Parser Evaluation5 ObservationsThe initial results show that the proposed parserperforms  better  than  the  state-of-the-art  datadriven Hindi parsers.
There are various reasonswhy we think that the proposed approach is bet-ter  suited  to  parsing  MoR-FWO.
(1)  Complexlinguistic cues can easily be encoded as part ofvarious  constraints.
For  example,  it  has  beenshown by Bharati  et  al.
(2008) that,  for  Hindi,complex  agreement  patterns,  though present  inthe  data,  are  not  being  learnt  by  data  drivenparsers.
Such patterns along with other idiosyn-cratic language properties can be easily incorpo-rated as constraints, (2) Making clauses as basicparsing  unit  drastically  reduces  non-projective79sentences.
Experiments  in  parsing  MoR-FOWhave  shown that  such  non-projective  sentencesimpede parser performances (Bharati et al, 2008;Hall et al, 2007).
Note that there will still remainsome  intra-clausal  non-projective  structures  inthe 1st stage, but they will be short distance de-pendencies, (3) Use of H-constraints and S-con-straints  together  reflect  the  grammar  of  a  lan-guage.
The rules in the form of H-constraints arecomplemented  by  the  weights  of  S-constraintslearnt  from  the  annotated  corpus,  (4)  2  stageparsing lends  itself  seamlessly to  parsing com-plex sentences by modularizing the task of over-all parsing, (5) the problem of label bias (Bharatiet  al.,  2008)  faced  by  the  data  driven  Hindiparsers for some cases does not arise here as con-textually  similar  entities  are  disambiguated  bytapping  in  hard  to  learn  features,  (6)  Use  ofclauses as basic parsing units reduces the searchspace at both the stages, (7) Parsing closely relat-ed languages will become easy.The performance of our parser is affected dueto the following reasons,  (a)  Small lexicon (lin-guistic  demands  of  various  heads):  The  totalnumber of such demand frames which the parsercurrently uses is very low.
There are a total ofaround 300 frames, which have been divided into20  verb  classes  (Begum et  al.,  2008b).
As  thecoverage of this lexicon increases, the efficiencywill automatically increase.
(b)  Unhandled con-structions: The parser still doesn?t handle someconstructions, such as the case when a conjuncttakes another conjunct as its dependent, and (c)Prioritization mistakes: As stated earlier the pri-oritizer being used is basic and is still being im-proved.
The  overall  performance  will  increasewith the improvement of the prioritizer.6 ConclusionIn this paper we proposed a new two stage con-straint  based  hybrid  approach  to  dependencyparsing.
We showed  how  by modularizing  thetask of overall parsing into 2 stages we can over-come many problems faced by data driven pars-ing.
We showed how in the 1st stage only intra-clausal dependencies are handled and later in the2nd stage the inter-clausal dependencies are iden-tified.
We also briefly  described the  use  of  H-constraints  and  S-constraints.
We  argued  thatsuch constraints complement each other in get-ting the best parse and that together they repre-sent the grammar of the language.
We evaluatedour  system  for  Hindi  with  two  data  drivenparsers.
Initial  results  show  that  the  proposedparser performs better than those parsers.
Finally,we argued why the proposed hybrid approach isbetter suited to handle the challenges posed byMoR-FWO and gave few pointers as how we canfurther improve our performance.The proposed parser is still being improved atvarious  fronts.
To  begin  with  a  prioritizationmechanism has to be improved.
We need to en-rich the verb frame lexicon along with handlingsome unhandled constructions.
This will be takenup as immediate future work.ReferencesR.
Begum, S.  Husain, A. Dhwaj, D. Sharma, L. Bai,and  R.  Sangal.
2008a.
Dependency  annotationscheme for Indian languages.
Proc.
of IJCNLP08.R.
Begum, S. Husain, D. Sharma and L. Bai.
2008b.Developing  Verb  Frames  in  Hindi.
Proc.
ofLREC08.A.
Bharati, S. Husain, B. Ambati, S. Jain, D. Sharmaand R. Sangal.
2008.
Two Semantic features makeall  the  difference  in  Parsing  accuracy.
Proc.
ofICON-08.A.
Bharati and R. Sangal.
1993.
Parsing Free WordOrder  Languages  in  the  Paninian  Framework.Proc.
of ACL: 93.A.
Bharati, V. Chaitanya and R. Sangal.
1995.
Natu-ral Language Processing: A Paninian Perspective,Prentice-Hall of India, New Delhi.R.
Debusmann, D. Duchier and G. Kruijff.
2004.
Ex-tensible  dependency grammar: A new methodolo-gy.
Proceedings  of  the  Workshop on  Recent  Ad-vances in Dependency Grammar, pp.
78?85.J.
Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi,M.
Nilsson  and  M.  Saers.
2007.
Single  Malt  orBlended?
A Study in Multilingual Parser Optimiza-tion.
Proc.
of EMNLP-CoNLL shared task 2007.R.
McDonald,  F.  Pereira,  K. Ribarov,  and J.  Hajic.2005.
Non-projective  dependency  parsing  usingspanning tree algorithms.
Proc.
of HLT/EMNLP.I.
A. Mel'Cuk.
1988.
Dependency Syntax: Theory andPractice, State University Press of New York.J.
Nivre, J.
Hall, J. Nilsson, A. Chanev, G. Eryigit, S.K?bler, S. Marinov and E Marsi.
2007.
MaltParser:A language-independent system for data-driven de-pendency parsing.
NLE.S.
M.  Shieber.
1985.
Evidence  against  the  context-freeness  of  natural  language.
In  Linguistics  andPhilosophy, p. 8, 334?343.I.
Schr?der.
2002.
Natural  Language  Parsing  withGraded Constraints.
PhD thesis, Hamburg Univ.80
