Proceedings of the NAACL HLT 2010 Workshop on Speech and Language Processing for Assistive Technologies, pages 10?18,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsAutomatic generation of conversational utterances and narrative forAugmentative and Alternative Communication: a prototype systemMartin Dempster & Norman Alm Ehud ReiterSchool of Computing Computer Science DepartmentUniversity of Dundee University of AberdeenDundee, Scotland, DD1 4HN, UK Aberdeen, Scotland, AB24 3UE, UKm.k.dempster@dundee.ac.uknalm@computing.dundee.ac.uke.reiter@abdn.ac.ukAbstractWe detail the design, development and evalua-tion of Augmentative and Alternative Com-munication (AAC) software which encouragesrapid conversational interaction.
The systemuses Natural Language Generation (NLG)technology to automatically generate conver-sational utterances from a domain knowledgebase modelled from content suggested by asmall AAC user group.
Findings from thiswork are presented along with a discussionabout how NLG might be successfully appliedto conversational AAC systems in the future.1 IntroductionAugmentative and Alternative Communication(AAC) systems assist non-speaking people communi-cate.
Reasons for lack of speech are varied and can becomplex, but they are typically related to some pro-found cognitive and/or motor impairment.Most AAC systems are computer based, utilize syn-thesized speech output and employ a phrase-construction approach to input.
This approach requiresthe user to construct the majority of their utterances liveduring conversation.
Undoubtedly this facilitated com-munication is hugely important to those without naturalspeech.
However, this process is often unacceptablyslow and can lead to problematic and stilted interac-tions, mostly due to the rapid nature of unimpeded face-to-face communication.Previous work has shown that it is possible to holdmutually rewarding conversations using wholly pre-stored material, known as the phrase-storage approach.Utterances are authored ahead of time and can be se-lected and output immediately leading to quicker com-munication rates.
However, this approach suffers fromseveral drawbacks which may have affected its moregeneral adoption.Furthermore, Natural Language Processing (NLP)technology has proven to be a fruitful line of inquirywithin the field.
It has offered a powerful means to im-prove system productivity and usability.
We are current-ly investigating how Natural Language Generation(NLG) might be applied in a useful way within an AACdevice geared towards fast-paced and rewarding socialinteractions.
It is hoped that the linguistic control andautomaticity offered by NLG may go some way towardsaddressing the previous criticisms of pre-stored materialregarding its inflexibility and cost in effort.2 Background2.1 Limitations of current AACHigh-tech AAC systems typically augment commu-nication for non-speaking people by allowing live mes-sage construction through some orthographic means.Completed messages are generally sent to a speech syn-thesis engine for output during communication withothers.
Many people who require AAC have associatedphysical disabilities which reduce the speed achievableusing input methods such as keyboards, pointing devic-es or touch-screens.
The rate achievable using mostcommercial AAC systems is highly dependent on thenature of the user?s disabilities but a generally acceptedfigure is in the region of 2-15 words per minute (Hig-ginbotham, Shane et al 2007), at least an order of mag-nitude slower than most natural speakers.This relatively slow rate of input is a crucial factor insome of the issues that arise in AAC-facilitated commu-nication.
Because of the effort and time required tocreate utterances, the user may not be able to constructmessages quickly enough to take active roles in fast10paced conversations.
As a result users may become pas-sive while also typically using a smaller communicativerepertoire than natural speakers (Light 1988).Narrative, an important type of interpersonal com-munication, is not well handled in most communicationaids (Waller 1992).
Delayed response and slow rate ofaided-communication are correlated with higher inci-dence of breakdown in communication and lesser per-ceptions of the AAC user (Todman and Rzepecka 2003;McCarthy and Light 2005).
This is primarily due toconflict between the relatively long time necessary toformulate an utterance and the fast paced nature of con-versation.These problems are particularly critical in social con-texts.
AAC users typically have small social circles andare dependent on contact with families and carers.
Theyoften lack self-esteem and have negative self-image.
Asa result, developing new relationships and experiencingnew things can be difficult, despite being a major priori-ty in their lives (Datillo, Estrella et al 2007).Some work has suggested that the use of pre-storedconversational material based on conversation modelscould help increase communication rate and conversa-tion quality.
Alm (1988) showed that it is possible tosuccessfully model short ?chat?
conversations involvinggreetings, personal enquiries and small-talk.
Further-more, the TALK system allowed a user to pre-store alarge volume of material on specific topics so thatwhole utterances could be selected and output.
The sys-tem also made heavy use of quick-fire phrases, classesof regularly used utterance which could be accessedquickly, and showed that communication using solelypre-stored material was viable (Todman and Alm 2003).Despite encouraging results and the development of acommercial product, the phrase-storage approach tosocial communication has not gained wide popularity.The reasons for this are complex, but include: the rela-tive inflexibility of pre-stored material; the costs asso-ciated with authoring the material and keeping thematerial up-to-date; and the vastly different nature ofthe approach and different training requirements neces-sary to achieve success.2.2 The role of NLP in AACNLP technology has provided many benefits to AACsystem designers.
Possibly the first technology to beincluded in many commercial systems to date was wordprediction and completion.
There have also been manyresearch prototypes exploring the applicability of moreemerging technologies such as named entity recognitionfrom synthesized speech (Wisenburn and Higginbotham2008), the generation of well-formed utterances fromtelegraphic input (McCoy, Pennington et al 1998) andthe automatic identification of contextual vocabularyfrom the web (Higginbotham, Bisantz et al 2008).Netzer and Elhadad (2006) used NLG to allow the se-mantic authoring of utterances.However, NLG, in the sense of data-to-text (Reiterand Dale 2000), has had limited application within AACthus far, although Reiter et al (2009) showed it is possi-ble to generate stories from sensor data which allow achild using AAC to tell others about their day at school.2.3 System RationaleThis project is exploring the use of NLG to produceconversational utterances in AAC systems designed forsocial interaction.
At the outset it was hoped that usingNLG might address some of the difficulties observed inpre-storage systems.
For instance, the generation com-ponent could theoretically produce a range of utterancesand speech act types automatically from the same un-derlying data and adapt these somewhat to the interac-tional context.
Using NLG would also have the benefitof offering control over the well-formedness of the out-put, an important consideration given the difficultysome AAC users have in achieving literacy (Sandbergand Hjelmquist 1997).
The fact that the system has aninherent awareness of the semantic content of the lin-guistic output, rather than simply being stored as cannedtext, is also a potential benefit.
In other words, NLGmight offer a level of automaticity and flexibility thattraditional pre-storage systems cannot offer, as well aspotentially reducing the level of pre-authoring requiredfrom the user.3 System Development3.1 User-centered methodologyTo try to assess how useful NLG could be in thiscontext we adopted a user-centered approach to the de-sign of the system.
A group of 3 AAC users has beenrecruited, all of whom currently use some form of high-tech AAC.
Literacy amongst the group is varied.
Two ofthe individuals use the alphabetic keyboard-basedLightwriter communication device currently, and havenormal cognitive and visual-perceptive skills.
All of theusers have cerebral palsy and dysarthria, and have beeninvolved in previous software evaluations.Weekly or twice weekly sessions were held witheach user for several months while the software wasbeing produced.
Sessions consisted of various activities:11discussion about the user?s ideas for the software andtechnology; the identification of topics and collation ofinput data to the system; demonstrations of the new fea-tures or changes since the last session; system training;and dry-run test conversations between the investigatorsand the users.3.2 System ArchitectureA growing line of inquiry in the NLG community isthe generation of language from ontologies (Mellish andSun 2005).
An ontology is a logical and hierarchicalmodel of the different concepts and the nature of rela-tionships between concepts in a particular domain.These concepts and relationships can be mapped ontolinguistic constructs to allow for the production of natu-ral language descriptions (Karakatsiotis, Galanis et al2008) of parts of the ontology.In the case of our system, we are trying to modelconversational topics that would be of interest in socialconversation between users of the system and their co-conversationalists.
The current categories of topic weare experimenting with include travelling, listening tomusic, watching films and attending concerts.
Manycategories are based on a simple event model whichdefines the basic characteristics common to all events,such as a time of occurrence (see Fig.1).
We have alsoincluded concepts such as Person and Place which areassociated with events to form a logical model of a par-ticular event type.A separate file is created unique to each user which islinked to the original model.
This is filled with individ-uals consisting of data from the user.
In other words,rather than defining the concept of an event as we didwith the original ontology, here we are creating a de-scription of an actual event and any other details, suchas people or places, associated with it.
We have definedour ontology in OWL, a standard language for the defi-nition of ontologies, and each piece of knowledge iseffectively stored as a RDF Triple consisting of a sub-ject, predicate and object.Figure 1: The abstract event modelThe user?s knowledge base is turned into useful con-versational utterances through a template-driven utter-ance generation system (e.g.
Van Deemter, Krahmer etal.
2005).
A large set of templates has been authored,using the SimpleNLG programming interface, whichturn data from the onotlogy into natural language utter-ances.
The templates are created as concrete syntaxtrees containing unspecified ?slots?
and parameters (SeeFig.2).
These syntax trees map out the syntactic struc-ture of the template), and are linked to a particular classin the ontology so that only appropriate templates areapplied to each individual.
Slots are used to add con-textually relevant clauses to our utterances.
For exam-ple, a template might contain a ?time?
slot, the contentsof which are derived from the time of the event in ques-tion.
For instance, the slot might be filled with ?nextTuesday evening?, ?a month ago?
or ?this morning?depending on the context.
Example parameters includethe tense with which the utterance should be generated,and whether a pronoun or full noun phrase should beused to refer to the subject of the utterance.Figure 2: An example syntax tree with empty slotsIn addition to the language produced from the modeland knowledge base we have included the ability to addcanned text phrases to each individual.This is necessary because there may be things thatyou wish to be able say about a topic which it is notfeasible to model.
Because we have a fairly diverse setof topics it is simply not possible to model all aspects ofthese topics in a reasonable time.
There is effectively atrade-off between complexity of the model and howmaintainable and representative it is.
A more complexmodel will lead to more expressive generated language,but will cost a great deal more to design and maintain.In the case of our system, a ?lowest common denomina-tor?
domain model combined with additional cannedtext has proven to be a relatively straightforward andinexpensive design.12The system has also been designed to learn over timethe sequences of utterances a user selects and suggestnext moves based on past behavior.
The system doesthis by maintaining a directional weighted graph whichrecords sequences of utterances as they are used.
Thegraph works by recording each individual utterance as anode in the graph and creating relationships betweenthese nodes as they occur.
The more often two utter-ances appear in sequence the higher the value given tothe edge between the two corresponding nodes.3.3 Conversation model and interface issuesPerhaps the most challenging aspect of taking thesystem from initial concept to working prototype hasbeen finding the most effective way of interfacing thetechnology.
We have found that due to the complexityof the underlying technology, reaching the stage wheregenerated utterances are both useful and accessible tothe user during conversation has required careful con-sideration and the trialing of several approaches with theuser group.It was envisaged that the generative power of NLGwould be its most powerful benefit.
The system couldrealize the same piece of data as numerous speech acttypes and, within a speech type, in several differentphrasings.
This offered the ability to counteract the in-flexibility and uniformity of pre-stored utterancessomewhat.
However, we have had mixed success inachieving this goal as it has proven difficult to find aneffective way to interface this enhanced choice and va-riety to the user.
If there is a large volume of generatedutterances available to choose from we must provide anefficient means by which the material is presented ororganized so that the desired utterance can be locatedquickly.
If a large choice results in a delayed selectionand thus conversational turn, we may then lose any rateand speed of response benefits which would negate theneed to use pre-stored and generated material at all.To address this problem, we attempted to design aconversational model which controlled the generation ofutterances so that only the utterances deemed most like-ly were presented to the user, thus reducing the cogni-tive load required to search through a large set.
This wasdone using a basic system where the templates weretagged according to where it might be most likely to beused in a conversation on a topic.
For instance, a tem-plate might produce a pre-sequence, an introduction,elaboration or concluding remark, or it may produce ainterrogative.
With the addition of historical sequentialmoves from our directional graph we could begin topresent subsets of utterances to the user according towhere they were in topic development.Another approach trialed was inspired by the Griceanmaxim of quantity.
Each template contains meta-dataabout the information it expresses.
For each generatedutterance selected, we can ?rule out?
further generationof the same information.
This is based on the assump-tion that speakers will generally avoid repetition.
Wehave found that this technique provides a useful way ofsupporting discourse coherence within conversations.Finally, using the logical model of topics we havecreated, it is possible to support and model stepwisetopic progression.
We can suggest, based on the modeland the user knowledge base, other topics linked to theone currently selected.
For example, if we were talkingabout an upcoming holiday to London with a friendcalled Bob we may want to the change topical perspec-tive to related aspects of the trip.
We might want to talkabout London as a place, Bob as a friend, and other tripswe have taken with Bob or to London.
Because theseconcepts are all distinct within the model, they eachhave their own set of associated templates and result insets of candidate utterances with differing perspectives.Navigating to related topics in this manner should bequicker since related topics do not have to be locatedmanually.
Although the users are still being trained inthis approach to topic change, early evaluations arepromising.
It enables a ?one-click?
transition to relatedtopics, allowing the user to elaborate on certain aspectsof a previous topic and respond quickly to questionsfrom their conversational partners.Building on the last two mechanisms, we can alsogenerate bridging phrases which allow for more cohe-sive changes in topic.
This allows for a more eloquenttransition to a new topic and also aids the discourse co-herence.All of these approaches in fact belie, to some degree,the complexity of conversation.
By its very nature, con-versation is unpredictable, and the purpose and meaningof sequential moves are highly dependent on their con-text (Clark 1996).
However, any form of context identi-fication, such as speech recognition (Wisenburn andHigginbotham 2008), is likely to present a major tech-nical challenge in any production AAC system at thecurrent time.
The above are simply at attempt to model,using the NLP/AI techniques available, aspects ofcommunication process, to show the potential benefitswhen using NLG-produced utterances rather than sim-ple canned text utterances.Application of some of the above techniques resultedin a highly fluid interface in which the utterances dis-played changed rapidly according to the conversationmodel.
This presented a major challenge to users learn-ing the system, with all displaying a strong preferencefor a static interface where the same utterances could befound in the same location each time they were desired.13Table 1: An example conversation producedusing the system.
Speaker A is the user and speakerB is an unaided speaker.
The right-hand columnshows the interface selections necessary prior toselecting the utterance from a set of possibilities.The marker G represents a generated utterance, Crepresents canned text.
The remainder are quick-fire utterances.We believe this does not suggest that use of suchconversational models and semantic processing is notfeasible, but simply that in the scope of the currentwork it has not been possible to fully evaluate theirpotential.
Thus we have chosen to generate candidatephrases in a static manner without the predictive as-pects described above.
These changes have allowed forquicker achievement of proficiency and have loweredthe cognitive effort required to navigate the interface.In the latest version of the software, we have de-fined a set of templates for each topic which whenrealized in series produce a coherent narrative.
Theycan still be selected individually by the user for output,so they retain ultimate control of what is said, but theutterances are presented in a natural order.
This meansthat the user can easily make use of the utterances as anarrative or can choose according to the particular sit-uation and context.
Any interrogative templates aredisplayed in a different part of the interface.
We haveset up a two column display so that interrogatives andother statements are clearly delineated.This approach has had very promising results as wehave found that users no longer have to search througha list of suggestions which changes after each conver-sational turn.
They can also use the structured natureof the generated utterances to confidently introduce thedifferent topics in conversation.
We are finding someevidence of increased self-selection at the end of theircurrent turn as the user is easily able to continue theirnarrative automatically without having to worry aboutthe location of their next turn in the interface.
There issome other evidence of this structured application ofNLG to narrative as being a promising area (Reiter,Turner et al 2009).We also believe that the passivity and lack of initia-tion observed in AAC users could be positively ad-dressed if AAC systems can better support a morevaried communicative repertoire and suitable trainingis administered to show users how to confidently usethese different constructs (e.g.
Todman 2000).
Earlytraining sessions with our user group have againproved positive with increased use of the trained fea-tures and interaction styles.UTTERANCE USERSELECTIONA: Hi Robert [GREET]B:      Oh, Hi.
Nice to see you.A: And you.
[GREET]A: How?s it going?
[INTRO]B: Fine.
And you?A: Not too bad.
[INTRO]B: So you been keeping busy?A: Yeah [YES]A: I certainly have!
[YES]A:I was out at a concert on Thursdaynight.
(G)[GIGS][Select ?Mar-tin Taylor?
]B: Great.
Who did you go to see?A:Have you heard of Martin Taylor?
(G)[ARTIST][Select ?Mar-tin Taylor?
]B: No.....I don?t think so.A: He is a Jazz guitarist.
(G) [Select ?Mar-tin Taylor?
]B: Oh, great.
I like jazz music.A: Me too.
[AGREE]B: So how was the concert?A:It was really good.
(G)[GIGS][Select ?Mar-tin Taylor?
]A: John and David came with me.
(G)A: We all enjoyed it.
(C)A: We had a bit of an interesting jour-ney home because it was snowingheavily, but we made it back safe.
(C)B:     Well that?s good news.
Where wasthe concert?A:It was at the Tron Theatre in Glas-gow.
(G)I?ve been to Glasgow a few timeslately.
[G][GIGS][Select ?Mar-tin Taylor?
][Select ?Glas-gow?
]A: Anyway, I best be getting on.
[WRAP UP]A: It was great talking to you.
[WRAP UP]B:      Yes, likewise.B: See you soon.A: OK. Cheerio.
[FINISH]B: Bye143.4 Authoring user contentCurrently we have not managed to produce a tool thatthe user can use to update their knowledge base them-selves.
The ontology editing tool used in the program,Prot?g?, is a free academic software package designedfor knowledge engineers and thus has a high degree ofinternal complexity and takes time to learn.
It is also nota particularly accessible piece of software.We have worked with the users to build up theirknowledge bases over a series of meetings by allowingthem to suggest individuals to add while entering thedetails for them into the system.
The process of definingnew individual is very quick, usually requiring the inputof just a few words and selection of the associated indi-viduals.
However, one of the main criticisms on the partof the users is that for the system to be useful in the longterm, it must be kept up to date, as old material willquickly become less relevant and useful in less frequentsituations.
For this reason it is critical to the success ofany NLG-driven communication system that the datainput is as simple and seamless as possible.We have shown in our system that it is possible to getsome limited data automatically from online sources,rather than having to input it manually.
Many web ser-vices are being made available which enable program-mers to access data from online services in theirapplications.
For instance, both Amazon and YouTubehave their own APIs which allow 3rd party applicationsto request content information from these services.The notion of the semantic web is also related to this.There is a large effort underway to define how we mightstructure and link information on the web in such a waythat more of it can be processed automatically by com-puters and made available in interchangeable formats.Shared data and semantic web technologies such asthese operate on the same premise as our proposedcommunication system in that they map out the basicvocabulary required to describe a domain, and allowpeople describe aspects of the domain in these terms.We have used an API provided by social music web-site Last.fm to show that it is possible to create relevantconversational utterances without any authoring re-quirement whatsoever.
By supplying the users Last.fmusername, we can use a web service supplied by the siteto query the user?s recent activity, for instance the songsthey have listened to, songs rated highly or events whichthey have signed up to attend.
Because the output fromthese services comes as structured XML document wecan simply map it?s schema onto our own vocabularyand feed the appropriate data to our templates to pro-duce utterances.If web services are to be used we must have anequivalent local vocabulary to which we can map thedata returned from any queries we send the service.However, in the case of semantic web sources, for ex-ample the FOAF (friend-of-a-friend) vocabulary (Brick-ley) describing online social networks, the process issimpler as we can simply use the pre-existing vocabu-lary standard ourselves rather than having to developour own.
Despite the semantic web being in its infancy,the notion of shared data is growing in popularity andmany popular websites and organizations are providingaccess to their information in a structured way.One problem with using these types of data acquisi-tion methods for our purposes is that the data is largelygeneric and any personal opinion or evaluative informa-tion personal to the user is limited.
In some cases wemay be able to query the data source for a ratingawarded to a particular piece of content, for instance thestar rating system on YouTube, but it is not clear howexpressive the produced language will be since theprocess is likely to be a simple mapping from the ratingto a suitable adjective.
As in our system, the potentialusefulness of the generated language is likely to be in-creased if it is possible for the user to annotate the top-ics with their own canned text expressions andevaluations.
This will enable the system to express moreof the individual?s personality and opinions.We believe this is an area of great interest for AAC.There is growing evidence of the importance of the in-ternet in the lives of disabled people, particularly its roleas a communication medium for people with communi-cation impairments (Cohen 1999).
By harnessing thelarge volumes of data created when using modern hard-ware and software systems and transforming it into use-ful utterances, we can begin to address one of the maincriticisms of whole utterance approaches to AAC sincethere would be no authoring requirement on the part ofthe users.
This is certainly by no means a simpleprocess and this approach will require further investiga-tion, but as semantic web technologies reach maturityFigure 3 - System interface15and gain wider adoption it should be clearer what thepotential of the technology is.4 Formal Evaluation MethodologyIn our evaluations so far, we have concentrated ontraining the users in its operation, updating conversa-tional material and implementing changes based on theuser feedback.
We have recently begun testing the sys-tem in real conversational encounters and the resultshave been promising.
We have found it is possible tohold pleasing conversations lasting up to 20 minuteswith unfamiliar partners, with the aided communicatorachieving a rate of upwards of 40 wpm.There also seems to be higher incidences of initia-tions on the part of the user, with them making good useof both the scripted NLG material, the quick fire phrasesand their own pre-stored material.
The topic progressionfeature is currently being underused but subjects areresponding well to training sessions on how to incorpo-rate this to reduce their response time and expand ontopics to extend the amount they are able to say.Formal evaluations are now being undertaken.
AnAB multiple-baseline study design is being conducted inwhich each aided communicator has a series of conver-sations with 12 unknown and unaided conversationpartners.
In the A condition, the aided participants usetheir existing AAC system, while in the B conditionthey use our prototype system.
Each conversation willbe limited to approximately 10 minutes, and the ses-sions will be split across a three non-consecutive days toavoid user fatigue.There will be at least 3 conversations in both the Aand B conditions, and the intervention point will be ran-domized across the remaining 6 conversations to allowfor valid inferences to be made despite the small n value(Todman and Dugard 2001).
This also reduces the biasintroduced by any training effects and avoids the needto use a response-guided intervention after baseline per-formance has been established.
The difficulty and ex-pense of recruiting large numbers of subjects in AACstudies is a known problem (Higginbotham 1995) andtherefore any findings from quantitative analysis per-formed cannot be generalized across the AAC popula-tion.
However, we expect to be able to achieve a p valueusing the randomization design of <0.05 so the resultsshould at least be internally robust and give a good indi-cation of whether further investigation is warranted.The conversations will be audio-recorded and ana-lyzed for a number of metrics.
Primarily we are interest-ed in measuring the rate at which people are able tocommunicate using the new system as this seems to beone of the clearest indicators of success when evaluatinga new AAC intervention.
We expect to the effect sizeobserved across the conditions to be large.We are also particularly interested whether it is poss-ible to use automatically generated material while main-taining or enhancing the enjoyment and quality of theencounter for all participants.
It is still unclear howacceptable generated material will be to the user so wewill measure the relative frequency of generated andcanned-text utterances.In previous studies it has also been shown that theuse of a whole-utterance approach can change the dy-namics of communication, such as relative speech actdistribution and number and type of initiation, so we areinterested to see how the availability generated materialmight impact this and what role it might play.
A codingschema based on Wang (2007) will be used to categor-ize the utterances used.We are also asking the aided and unaided conversa-tion partners to complete questionnaires regarding vari-ous subjective ratings of the interactions and, in the caseof the unaided speakers, impressions of the aided com-municator.
The questions will be based on a re-evaluation of those suggested by Todman (2000) andanswers will be requested on a 7-point rating scale.
Pre-vious work has shown that quicker, flowing interactionswith less breakdowns or delays can lead to more re-warding interactions for both participants.
We expect toobserve these effects in our system but it?s as yet un-clear what impact the automatically generated phraseswill have, if any, on perceptions of the user.Although the relatively small number of participantsmeans it is unlikely that we will be able to make robustinferences from this data, we hope that results will beindicative of the naturalness and acceptability of auto-matically generated utterances.5 Discussion & Future PlansOne of the primary reasons that AAC systems featur-ing NLP technology prove useful is that they go someway to leveling the playing field for many users.
Theyhave the potential to support the user in ways whichreduce the effort required to communicate yet may im-prove the quality of the communication.
There are manyNLP technologies, such as NLG, that deserve furtherattention within the field of AAC to determine whatthey can offer.Although our system has shown some encouragingpreliminary results there are still many unansweredquestions with regards to the role NLG can play.
Forexample, it is not clear how appealing NLG utterances16are to use.
Given that the user has not authored the formof the utterances themselves there is an argument thatusing them may feel unnatural.
After the formal evalua-tions we should be able provide analysis indicatingwhether NLG phrases are being used and in which sit-uations they are proving most useful.One of the most challenging aspects of designing thesystem was the HCI challenge of incorporating some ofthese technologies.
While it is obvious to the user thatphrases are being generated automatically, and thatthese phrases are generated when a topic is selected, it isstill important to note that the technologies have beenintentionally kept largely transparent to the user.
Whenusing a communication system, the most importantthing is the ability to say what you want to say, but isnot yet clear whether the technical nature of the soft-ware  may be an alienating factor since the user current-ly has no access to the template construction or domainmodeling aspects of the system.At the current time, the domain modeling and tem-plate construction processes are quite complex and ex-pensive.
Tools are becoming available, from the NLGcommunity, which go some way to addressing the diffi-culty of interfacing these types of technology to non-experts (Bilidas, Theologou et al 2007; Power, Stevenset al 2009) but these are largely unsolved problems.Domain modeling itself is problematic in that onepersons notion of what defines a particular concept isoften different to someone else?s.
For instance, one per-son?s idea of sport might encompass the sporting activi-ties they take part in, while another person?s idea ofsport is that which they follow or watch on the televi-sion.
This has clear implications for the general usabili-ty of the system.
Using semantic web vocabularies mayaddress this somewhat since they are likely to be morespecific to a particular purpose and be more mature andinteroperable than the ?home-brew?
domain models wehave used for the prototype.Using whole-utterance approaches to communicationclearly requires the adoption of a different mindset.
Ra-ther than being able to construct a novel message theuser has to ?make do?
with whatever is available in thesystem.
Despite the advantages observed while usingsuch systems, they have still not become generally pop-ular.
It is likely that any NLG whole utterance systemwould similarly not gain immediate acceptance becauseit is vastly different to other systems and approaches tocommunication available.
To some degree we are ask-ing the user of our NLG system to think in an objectorientated manner since they must understand the un-derlying model and the way the concepts are structuredto make the most of the system.
Again it is not yet clearhow natural this process is and how much training isrequired to become an expert user of such a system.However perhaps the major strength of these types ofsystem is the way in which they help scaffold interac-tion so the AAC user can be much more active in con-versation and use an increased repertoire.
The design ofthe software is such that it encourages the use of typesof phrases often underused by AAC users, for example,initiations, elaborating moves, questions and the differ-ent classes of quick-fire remarks.
One interesting ques-tion is whether the use of NLG might make it easier toencourage the user to use new types of conversationalmove.
Since no full text-authoring is required the userdoes not even have feel confident authoring the utter-ance, it is simply provided and can be used or experi-mented with.
Scaffolding interactions in this way maybe one of the most interesting avenues for NLP and AItechnologies with AAC in the future.The architecture of the prototype, although effective,lacks efficiency and may be difficult to reuse.
A greatdeal of work is being done by NLG researchers investi-gating how NLG architectures might be made moremodular and reusable.
This is an ongoing problem but itseems sensible to consider how a pipeline architecture(Reiter and Dale 2000) might work in practice for thistype of system.At the moment, the system requires a reasonable lev-el of literacy because the interface is mainly text based.However, semiotic systems are preferred because of theliteracy problems observed in many AAC users.
It is notclear how NLG may impact on semiotic message con-struction but systems such as Compansion (McCoy,Pennington et al 1998) show there may useful applica-tions in this area too.6 ConclusionDespite having only been able to perform informalevaluations so far, we believe we have seen some en-couraging signals that NLG may have potential as anaugmentative communication technology to assist ingenerating conversational utterances.
We believe thatthe rapid access to well-formed, contextually generatedmaterial offered in our system could lead to significantbenefits for the AAC user and their interlocutors.There are further exciting possibilities with regards tothe technology, particularly the ability to harvest per-sonal data from the internet and other computer usageso that it can be transformed into useful phrases for in-clusion in communication aids.
We hope to have a rich-er set of data and results in the coming months after thesystem training and formal evaluations have been com-pleted.177 ReferencesAlm, N. A.
(1988).
Towards a Conversation Aid forSeverely Phisically Disabled Non-Speaking People.Applied Computing Department.
Dundee, UniversityOf Dundee.
Doctor Philosophy: 197.Bilidas, D., M. Theologou, et al (2007).
EnrichingOWL Ontologies with Linguistic and User-relatedAnnotations: the ELEON system.
19th IEEE Interna-tional Conference on Tools with Artificial Intelli-gence, IEEE.Brickley, D. (25.2.10).
"FOAF Vocabulary Specifica-tion ", from http://xmlns.com/foaf/0.1/Clark, H. H. (1996).
Using Language, Cambridge Uni-versity Press.Cohen, K. J.
(1999).
Using the Internet to EmpowerAugmented Communicators.
CSUN'99.Datillo, J., G. Estrella, et al (2007).
""I have chosen tolive life abundantly": Perceptions of leisure by adultswho use Augmentative and Alternative Communica-tion."
Augmentative & Alternative Communication24(1): 16-28.Higginbotham, D. J.
(1995).
"Use of nondisabled sub-jects in AAC Research : Confessions of a research in-fidel."
Augmentative and Alternative Communication11(1): 2-5.Higginbotham, D. J., A. M. Bisantz, et al (2008).
"TheEffect of Context Priming and Task Type on Augmen-tative Communication Performance."
Augmentative &Alternative Communication.Higginbotham, D. J., H. Shane, et al (2007).
"Access toAAC: Present, past, and future."
Augmentative & Al-ternative Communication 23(3): 243-257.Karakatsiotis, G., D. Galanis, et al (2008).
Natura-lOWL: Generating Texts from OWL Ontologies inProtege and in Second Life.
18th European Confe-rence on Artificial Intelligence.Light, J.
(1988).
"Interaction Involving Individuals us-ing Augmentative and Alternative CommunicationSystems: State of the Art and Future Directions.
"Augmentative and Alternative Communication 4(2):66-82.McCarthy, J. and J.
Light (2005).
"Attitudes towardsindividuals who use Augmentative and AlternativeCommunication: Research Review."
Augmentativeand Alternative Communication 21(1): 41-55.McCoy, K. F., C. A. Pennington, et al (1998).
"Com-pansion: From research prototype to practical integra-tion."
Natural Language Engineering 4(1): 73-95.Mellish, C. and X.
Sun (2005).
The Semantic Web as aLinguistic Resource: Opportunities for Natural Lan-guage Generation.
International Conference on theory,practical and application of Artificial Intelligence.
M.Bramer, F. Coenen and T. Allen.
Cambridge, UK,Springer: 77.Netzer, Y. and M. Elhadad (2006).
Using Semantic Au-thoring for Blissymbols Communication Boards.HLT-2006.Power, R., R. Stevens, et al (2009).
Editing OWLthrough generated CNL.
Workshop on ControlledNatural Language (CNL'09).
Marettimo Island, Italy.Reiter, E. and R. Dale (2000).
Building Natural Lan-guage Generation Systems.
Cambridge CambridgeUniversity Press.Reiter, E., R. Turner, et al (2009).
Using NLG to helplanguage-impaired users tell stories and participate insocial dialogues.
Proceedings of the 12th EuropeanWorkshop on Natural Language Generation.
Athens,Greece, ACL.Sandberg, A. D. and E. Hjelmquist (1997). "
Languageand literacy in nonvocal children with cerebral palsy.
"Reading and Writing 9(2): 107-133.Todman, J.
(2000).
"Rate and quality of conversationsusing a text-storage AAC system: Single-case trainingstudy."
Augmentative and Alternative Communication16: 164-179.Todman, J. and N. A. Alm (2003).
"Modelling conver-sational pragmatics in communication aids."
Journalof Pragmatics(35): 523-538.Todman, J. and P. Dugard (2001).
Single-case andsmall-n experimental designs: A practical guide torandomisation tests.
Mahwah, NJ, Lawrence ErlbaumAssociates.Todman, J. and H. Rzepecka (2003).
"Effect of pre-utterance pause length on perceptions of communica-tive competence in AAC-aided social conversations.
"Augmentative and Alternative Communication 19(4):222-234.Van Deemter, K., E. Krahmer, et al (2005).
"Plan-basedvs.
Template-based NLG: A false opposition?"
Com-putational Linguistics 31(1).Waller, A.
(1992).
Providing Narratives in an Augmen-tative Communication System.
Applied Computing.Dundee, University Of Dundee.
Doctor of Philoso-phy: 163.Wang, Y.
(2007).
A model of conversational structurefor augmentative and alternative communication(AAC) systems.
University of Dundee, UnpublishedPhD Thesis.
PhD.Wisenburn, B. and D. J. Higginbotham (2008).
"AnAAC Application Using Speaking Partner SpeechRecognition to Automatically Produce ContextuallyRelevant Utterances: Objective Results."
Augmenta-tive and Alternative Communication 24(2): 100-109.18
