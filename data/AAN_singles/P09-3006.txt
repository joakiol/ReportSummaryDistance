Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 45?53,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPSentence Diagram Generation Using Dependency ParsingElijah MayfieldDivision of Science and MathematicsUniversity of Minnesota, Morrismayf0016@morris.umn.eduAbstractDependency parsers show syntactic re-lations between words using a directedgraph, but comparing dependency parsersis difficult because of differences in the-oretical models.
We describe a systemto convert dependency models to a struc-tural grammar used in grammar educa-tion.
Doing so highlights features that arepotentially overlooked in the dependencygraph, as well as exposing potential weak-nesses and limitations in parsing models.Our system performs automated analysisof dependency relations and uses them topopulate a data structure we designed toemulate sentence diagrams.
This is doneby mapping dependency relations betweenwords to the relative positions of thosewords in a sentence diagram.
Using anoriginal metric for judging the accuracy ofsentence diagrams, we achieve precisionof 85%.
Multiple causes for errors are pre-sented as potential areas for improvementin dependency parsers.1 Dependency parsingDependencies are generally considered a strongmetric of accuracy in parse trees, as described in(Lin, 1995).
In a dependency parse, words areconnected to each other through relations, with ahead word (the governor) being modified by a de-pendent word.
By converting parse trees to de-pendency representations before judging accuracy,more detailed syntactic information can be discov-ered.
Recently, however, a number of dependencyparsers have been developed that have very differ-ent theories of a correct model of dependencies.Dependency parsers define syntactic relationsbetween words in a sentence.
This can be doneeither through spanning tree search as in (McDon-ald et al, 2005), which is computationally expen-sive, or through analysis of another modeling sys-tem, such as a phrase structure parse tree, whichcan introduce errors from the long pipeline.
Tothe best of our knowledge, the first use of de-pendency relations as an evaluation tool for parsetrees was in (Lin, 1995), which described a pro-cess for determining heads in phrase structuresand assigning modifiers to those heads appropri-ately.
Because of different ways to describe rela-tions between negations, conjunctions, and othergrammatical structures, it was immediately clearthat comparing different models would be diffi-cult.
Research into this area of evaluation pro-duced several new dependency parsers, each us-ing different theories of what constitutes a cor-rect parse.
In addition, attempts to model multi-ple parse trees in a single dependency relation sys-tem were often stymied by problems such as dif-ferences in tokenization systems.
These problemsare discussed by (Lin, 1998) in greater detail.
Anattempt to reconcile differences between parserswas described in (Marneffe et al, 2006).
In thispaper, a dependency parser (from herein referredto as the Stanford parser) was developed and com-pared to two other systems: MINIPAR, describedin (Lin, 1998), and the Link parser of (Sleator andTemperley, 1993), which uses a radically differ-ent approach but produces a similar, if much morefine-grained, result.Comparing dependency parsers is difficult.
Themain problem is that there is no clear way to com-pare models which mark dependencies differently.For instance, when clauses are linked by a con-junction, the Link parser considers the conjunctionrelated to the subject of a clause, while the Stan-ford parser links the conjunction to the verb of aclause.
In (Marneffe et al, 2006), a simple com-parison was used to alleviate this problem, whichwas based only on the presence of dependencies,without semantic information.
This solution loses45information and is still subject to many problemsin representational differences.
Another problemwith this approach is that they only used ten sen-tences for comparison, randomly selected from theBrown corpus.
This sparse data set is not necessar-ily congruous with the overall accuracy of theseparsers.In this paper, we propose a novel solution tothe difficulty of converting between dependencymodels.
The options that have previously beenpresented for comparing dependency models areeither too specific to be accurate (relying on an-notation schemes that are not adequately parallelfor comparison) or too coarse to be useful (suchas merely checking for the existence of depen-dencies).
By using a model of language whichis not as fine-grained as the models used by de-pendency parsers, but still contains some semanticinformation beyond unlabelled relations, a com-promise can be made.
We show that using lineardiagramming models can do this with acceptableerror rates, and hope that future work can use thisto compare multiple dependency models.Section 2 describes structural grammar, its his-tory, and its usefulness as a representation of syn-tax.
Section 3 describes our algorithm for conver-sion from dependency graphs to a structural rep-resentation.
Section 4 describes the process weused for developing and testing the accuracy ofthis algorithm, and Section 5 discusses our resultsand a variety of features, as well as limitations andweaknesses, that we have found in the dependencyrepresentation of (Marneffe et al, 2006) as a resultof this conversion.2 Introduction to structural grammarStructural grammar is an approach to natural lan-guage based on the understanding that the major-ity of sentences in the English language can bematched to one of ten patterns.
Each of these pat-terns has a set of slots.
Two slots are universalamong these patterns: the subject and the predi-cate.
Three additional slots may also occur: thedirect object, the subject complement, and the ob-ject complement.
A head word fills each of theseslots.
In addition, any word in a sentence may bemodified by an additional word.
Finally, anywherethat a word could be used, a substitution may bemade, allowing the position of a word to be filledby a multiple-word phrase or an entire subclause,with its own pattern and set of slots.To understand these relationships better, a stan-dardized system of sentence diagramming hasbeen developed.
With a relatively small number ofrules, a great deal of information about the func-tion of each word in a sentence can be representedin a compact form, using orientation and other spa-tial clues.
This provides a simpler and intuitivemeans of visualizing relationships between words,especially when compared to the complexity of di-rected dependency graphs.
For the purposes of thispaper, we use the system of diagramming formal-ized in (Kolln and Funk, 2002).2.1 HistoryFirst developed in the early 20th century, structuralgrammar was a response to the prescriptive gram-mar approach of the time.
Structural grammar de-scribes how language actually is used, rather thanprescribing how grammar should be used.
Thisapproach allows an emphasis to be placed on thesystematic and formulaic nature of language.
Akey change involved the shift to general role-baseddescription of the usage of a word, whereas the fo-cus before had been on declaring words to fall intostrict categories (such as the eight parts of speechfound in Latin).Beginning with the work of Chomsky in the1950s on transformational grammar, sentence di-agrams, used in both structural and prescriptiveapproaches, slowly lost favor in educational tech-niques.
This is due to the introduction of trans-formational grammar, based on generative theo-ries and intrinsic rules of natural language struc-ture.
This generative approach is almost uni-versally used in natural language processing, asgenerative rules are well-suited to computationalrepresentation.
Nevertheless, both structural andtransformational grammar are taught at secondaryand undergraduate levels.2.2 Applications of structural grammarStructural grammar still has a number of advan-tages over generative transformational grammar.Because it is designed to emulate the natural usageof language, it is more intuitive for non-experts tounderstand.
It also highlights certain features ofsentences, such as dependency relationships be-tween words and targets of actions.
Many facetsof natural language are difficult to describe usinga parse tree or other generative data structure.
Us-ing structural techniques, many of these aspectsare obvious upon basic analysis.46Figure 1: Diagram of ?The students are scholars.
?and ?The students studied their assignment.
?By developing an algorithm to automaticallyanalyze a sentence using structural grammar, wehope that the advantages of structural analysiscan improve the performance of natural languageparsers.
By assigning roles to words in a sentence,patterns or structures in natural language that can-not be easily gleaned from a data structure aremade obvious, highlighting the limitations of thatstructure.
It is also important to note that whilesentence diagrams are primarily used for English,they can be adapted to any language which usessubjects, verbs, and objects (word order is not im-portant in sentence diagramming).
This researchcan therefore be expanded into multilingual de-pendency parser systems in the future.To test the effectiveness of these approaches, asystem must be developed for structural analysisof sentences and subsequent conversion to a sen-tence diagram.3 Sentence diagram generationalgorithmIn order to generate a sentence diagram, we makeuse of typed dependency graphs from the Stanforddependency parser.
To understand this processrequires understanding both the underlying datastructure representing a sentence diagram, and theconversion from a directed graph to this data struc-ture.3.1 Data structureIn order to algorithmically convert dependencyparses to a structural grammar, we developed anoriginal model to represent features of sentencediagrams.
A sentence is composed of four slots(Subject, Predicate, Object, Complement).
Theseslots are represented1in two sentences shown in1All sentence diagram figures were generated by the al-gorithm described in this paper.
Some diagrams have beenFigure 2: Diagram of ?Running through the woodsis his favorite activity.
?Figure 1 by the words ?students,?
?are,?
?assign-ment,?
and ?scholars?
respectively.
Each slot con-tains three sets (Heads, Expletives, Conjunctions).With the exception of the Heads slot in Subjectand Predicate, all sets may be empty.
These setsare populated by words.
A word is comprised ofthree parts: the string it represents, a set of mod-ifying words, and information about its orienta-tion in a diagram.
Finally, anywhere that a wordmay fill a role, it can be replaced by a phrase orsubclause.
These phrases are represented iden-tically to clauses, but all sets are allowed to beempty.
Phrases and subclauses filling the role ofa word are connected to the slot they are filling bya pedestal, as in Figure 2.3.2 Conversion from dependency graphA typed dependency representation of a sentencecontains a root ?
that is, a dependency relationin which neither the governor nor the dependentword in the relation is dependent in any other re-lation.
We use this relation to determine the predi-cate of a sentence, which is almost always the gov-ernor of the root dependency.
The dependent isadded to the diagram data structure based on itsrelation to the governor.Before analysis of dependency graphs begins,our algorithm takes in a set of dependency rela-tions S and a set of actions (possible objects andmethods to call) A.
This paper describes an algo-rithm that takes in the 55 relations from (Marn-effe et al, 2006) and the actions in Table 1.
Thealgorithm then takes as input a directed graph Grepresenting a sentence, composed of a node rep-edited for spacing and readability concerns.
These changesdo not affect their accuracy.47resenting each word in the sentence.
These nodesare connected by edges in the form reln(gov,dep) representing a relation from S between aword gov and dep.
Our algorithm performs thefollowing steps:1.
Determining root actions: For each relationtype R ?
S, create an ordered list of actionsRoot < R,A > from A to perform if that re-lation is the root relation in the graph.2.
Determining regular actions: For each re-lation type R ?
S, create an ordered list ofactions Reln < R,A > from A to perform ifR is found anywhere other than the root in G.3.
Determining the root: Using the root-finding process described in (Marneffe et al,2006), find the root relation?R(?G,?D) ?
G.4.
Initialize a sentence diagram: Find the setof actions?A from Root <?R,A >and performthose actions.5.
Finding children: Create a set Open and addto it each relation ?
G in which?G or?D fromstep 3 is a governor.6.
Processing children: For each relation?R(?G,?D) in Open,(a) Populate the sentence diagram: Findthe set of actions?A from Reln <?R,A >and perform those actions.
(b) Finding children: Add to Open eachrelation R ?G in which?G or?D is a gov-ernor.This step continues until all relations havebeen found in a breadth-first order.Our system of conversion makes the assumptionthat the governor of a typed dependency will al-ready have been assigned a position in a diagram.This is due to the largely tree-like structure ofdependency graphs generated by the dependencyparser.
Dependencies in most cases ?flow?
down-wards to the root, and in exceptions, such as cy-cles, the governor will have been discovered by thetime it is reached again.
As we are searching forwords breadth-first, we know that the dependentof any relation will have been discovered alreadyso long as this tree-like structure holds.
The num-ber of cases where it does not is small comparedto the overall error rate of the dependency parser,and does not have a large impact on the accuracyof the resulting diagram.3.3 Single-relation analysisA strength of this system for conversion is that in-formation about the overall structure of a sentenceis not necessary for determining the role of eachindividual word as it is added to the diagram.
Aseach word is traversed, it is assigned a role relativeto its parent only.
This means that overall structurewill be discovered naturally by tracing dependen-cies throughout a graph.There is one exception to this rule: when com-paring relationships of type cop (copula, a link-ing verb, usually a variant of ?to be?
), three wordsare involved: the linking verb, the subject, and thesubject complement.
However, instead of a tran-sitive relationship from one word to the next, theparser assigns the subject and subject complementas dependent words of the linking verb.
An exam-ple is the sentence ?The students are scholars?
asin Figure 1.
This sentence contains three relations:det(students, The)nsubj(scholars, students)cop(scholars, are)A special case exists in our algorithm to checkthe governor of a cop relation for another rela-tion (usually nsubj).
This was a necessary ex-ception to make given the frequency of linkingverbs in the English language.
Dependency graphsfrom (Marneffe et al, 2006) are defined as asingly rooted directed acyclic graph with no re-entrancies; however, they sometimes share nodesin the tree, with one word being a dependent ofmultiple relations.
An example of this exists inthe sentence ?I saw the man who loves you.?
Theword ?who?
in this sentence is dependent in tworelations:ref(man, who)rel(loves, who)We here refer to this phenomenon as breakingthe tree structure.
This is notable because it causesa significant problem for our approach.
While thecorrect relation is identified and assigned in mostcases, a duplicated copy of the dependent wordwill appear in the resulting diagram.
This is be-cause the dependent word in each relation is addedto the diagram, even if it has already been added.Modifiers of these words are then assigned to eachcopy, which can result in large areas of duplica-tion.
We decided this duplication was acceptable48Term Definition ExampleInput OutputGOV, DEP, RELN Elements of a relation det(??woods",??the").GOV?
?woods"SBJ, PRD, OBJ,CMPSlots in a clause CLAUSE.PRD HEADS(?
?is"),EXPL(),CONJ()HEADS, EXPL,CONJSets of words in a slot CLAUSE.PRD.HEADS() ?
?is"MODS Set of modifiers of aword?
?activity".MODS (??his",?
?favorite")SEGMENT, CLAUSE Set or clause of word ?
?is".SEGMENT() CLAUSE.PRDNEW[WORD, Slot] New clause constructor NEW(?
?is", PRD) CLAUSE(SBJ(),PRD(?
?is"),OBJ(),CMP())ADD(WORD[,ORIENT]) Word added to modi-fiers??activity".ADD(??his")APP(WORD[,RIGHT?])
Word appended tophrasal head??down".APP(?
?shut",false)SET(ORIENT) Word orientation set ?
?his".SET(DIAGONAL)Periods represent ownership, parentheses represent parameters passed to a method, separated by commas, and brackets repre-sent optional parameters.Orientations include HORIZONTAL, DIAGONAL, VERTICAL, GERUND, BENT, DASHED, and CLAUSE as defined in (Kollnand Funk, 2002) .Table 1: Terms and methods defined in our algorithm.Figure 3: The sentence ?A big crowd turned outfor the parade.?
shown as a dependency graph(top) and a sentence diagram.to maintain the simplicity of single-relation con-version rules, though remedying this problem is anavenue for further research.
For testing purposes,if duplicate copies of a word exist, the correct oneis given preference over the incorrect copy, and thediagram is scored as correct if either copy is cor-rectly located.3.4 An example diagram conversionTo illustrate the conversion process, consider thesentence ?A big crowd turned out for the parade.
?The dependency graph for this, as generated by theStanford dependency parser, is shown in Figure 3.The following relations are found, with the actionstaken by the conversion algorithm described:Root: nsubj(turned, crowd)NEW(GOV, PRD);GOV.CLAUSE.SBJ.ADD(DEP);Finding Children: det(crowd, A),amod(crowd, big), prt(turned, out),prep(turned, for) added to Open.Relation: det(crowd, A)GOV.ADD(DEP,DIAGONAL);Relation: amod(crowd, big)GOV.ADD(DEP,DIAGONAL);Relation: prt(turned, out)GOV.APP(DEP,TRUE);Relation: prep(turned, for)Finding Children: pobj(for, parade)added to Open.GOV.ADD(DEP,DIAGONAL);Relation: pobj(for, parade)Finding Children: det(parade, the)added to Open.GOV.ADD(DEP,HORIZONTAL);Relation: det(parade, the)GOV.ADD(DEP,DIAGONAL);4 Experimental setupIn order to test our conversion algorithm, a largenumber of sentence diagrams were needed in order49to ensure a wide range of structures.
We decided touse an undergraduate-level English grammar text-book that uses diagramming as a teaching toolfor two reasons.
The first is a pragmatic matter:the sentences have already been diagrammed ac-curately for comparison to algorithm output.
Sec-ond, the breadth of examples necessary to allowstudents a thorough understanding of the processis beneficial in assuring the completeness of theconversion system.
Cases that are especially diffi-cult for students are also likely to be stressed withmultiple examples, giving more opportunities todetermine the problem if parsers have similar dif-ficulty.Therefore, (Kolln and Funk, 2002) was selectedto be used as the source of this testing data.
Thistextbook contained 292 sentences, 152 from ex-amples and 140 from solutions to problem sets.50% of the example sentences (76 in total, chosenby selecting every other example) were set asideto use for development.
The remaining 216 sen-tences were used to gauge the accuracy of the con-version algorithm.Our implementation of this algorithm was de-veloped as an extension of the Stanford depen-dency parser.
We developed two metrics of pre-cision to evaluate the accuracy of a diagram.
Thefirst approach, known as the inheritance metric,scored the results of the algorithm based on theparent of each word in the output sentence dia-gram.
Head words were judged on their placementin the correct slot, while modifiers were judgedon whether they modified the correct parent word.The second approach, known as the orientationmetric, judged each word based solely on its ori-entation.
This distinction judges whether a wordwas correctly identified as a primary or modifyingelement of a sentence.These scoring systems have various advantages.By only scoring a word based on its immediateparent, a single mistake in the diagram does notseverely impact the result of the score, even if it isat a high level in the diagram.
Certain mistakes areaffected by one scoring system but not the other;for instance, incorrect prepositional phrase attach-ment will not have an effect on the orientationscore, but will reduce the value of the inheritancescore.
Alternatively, a mistake such as failing tolabel a modifying word as a participial modifierwill reduce the orientation score, but will not re-duce the value of the inheritance score.
Generally,orientation scoring is more forgiving than inheri-tance scoring.5 Results and discussionThe results of testing these accuracy metrics aregiven in Figure 4 and Table 2.
Overall inheritanceprecision was 85% and overall orientation preci-sion was 92%.
Due to the multiple levels of analy-sis (parsing from tree to phrase structure to depen-dency graph to diagram), it is sometimes difficultto assign fault to a specific step of the algorithm.There is clearly some loss of information whenconverting from a dependency graph to a sentencediagram.
For example, fifteen dependency rela-tions are represented as diagonal modifiers in asentence diagram and have identical conversionrules.
Interestingly, these relations are not nec-essarily grouped together in the hierarchy givenin (Marneffe et al, 2006).
This suggests that thesyntactic information represented by these wordsmay not be as critical as previously thought, givenenough semantic information about the words.
Intotal, six sets of multiple dependency relationsmapping to the same conversion rule were found,as shown in Table 3.The vast majority of mistakes that were madecame from one of two sources: an incorrect con-version from a correct dependency parse, or a fail-ure of the dependency parser to correctly identifya relation between words in a sentence.
Both areexamined below.5.1 Incorrect conversion rulesOn occasion, a flaw in a diagram was the result ofan incorrect conversion from a correct interpreta-tion in a dependency parse.
In some cases, thesewere because of simple changes due to inaccura-cies not exposed from development data.
In somecases, this was a result of an overly general rela-tionship, in which one relation correctly describestwo or more possible structural patterns in sen-tences.
This can be improved upon by specializ-ing dependency relation descriptions in future ver-sions of the dependency parser.One frequent failure of the conversion rules isdue to the overly generalized handling of the rootof sentences.
It is assumed that the governingword in the root relation of a dependency graphis the main verb of a sentence.
Our algorithm hasvery general rules for root handling.
Exceptionsto these general cases are possible, especially in50Sentence Length Ori Mean Ori Std.Dev.
Inh Mean Inh Std.Dev.
Count3-6 96.61 7.42 90.34 15.20 567-8 92.37 15.77 86.00 19.34 579-10 92.80 8.18 82.73 17.15 4511-20 89.97 12.54 82.52 15.51 583-20 92.91 11.84 85.51 17.05 216Table 2: Precision of diagramming algorithm on testing data.Relations Ruleabbrev, advmod, amod, dep, det, measure, neg, nn,num, number, poss, predet, prep, quantmod, refGOV.ADD(DEP,DIAGONAL)iobj, parataxis, pobj GOV.ADD(DEP,HORIZONTAL)appos, possessive, prt GOV.APP(DEP,TRUE)aux, tmod GOV.APP(DEP,FALSE)advcl, csubj, pcomp, rcmod GOV.ADD(NEW(DEP,PRD))complm, expl, mark GOV.SEGMENT.EXPL.ADD(DEP)Table 3: Sets of multiple dependency relations which are converted identically.0.00.20.40.60.81.0Orientation by Quartiles0.00.20.40.60.81.0Inheritance by QuartilesFigure 4: Inheritance (top) and Orientation preci-sion results of diagramming algorithm on testingdata.
Results are separated by sentence length intoquartiles.interrogative sentences, e.g.
the root relation ofthe sentence ?What have you been reading??
isdobj(reading, What).
This should be han-dled by treating ?What?
as the object of the clause.This problem can be remedied in the future by cre-ating specialized conversion rules for any given re-lation as a root of a dependency graph.A final issue is the effect of a non-tree struc-ture on the conversion algorithm.
Because rela-tionships are evaluated individually, multiple in-heritance for words can sometimes create dupli-cate copies of a word which are then modified inparallel.
An example of this is shown in Figure 5,which is caused due to the dependency graph forthis sentence containing the following relations:nsubj(is-4, hope-3)xsubj(beg-6, hope-3)xcomp(is-4, beg-6)Because the tree structure is broken, a word(hope) is dependent on two different governingwords.
While the xsubj relation places the phrase?to beg for mercy?
correctly in the diagram, a sec-ond copy is created because of the xcomp depen-dency.
A more thorough analysis approach thatchecks for breaking of the tree structure may beuseful in avoiding this problem in the future.5.2 Exposed weaknesses of dependencyparsersA number of consistent patterns are poorly dia-grammed by this system.
This is usually due to51Figure 5: Duplication in the sentence diagram for?Our only hope is to beg for mercy.
?limitations in the theoretical model of the depen-dency parser.
These differences between the ac-tual structure of the sentence and the structure theparser assigns can lead to a significant differencein semantic value of phrases.
Improving the accu-racy of this model to account for these situations(either through more fine-grained separation of re-lationships or a change in the model) may improvethe quality of meaning extraction from sentences.One major shortcoming of the dependencyparser is how it handles prepositional phrases.As described in (Atterer and Schutze, 2007), thisproblem has traditionally been framed as involv-ing four words (v, n1, p, n2) where v is the head ofa verb phrase, n1 is the head of a noun phrase dom-inated by v, p is the head of a prepositional phrase,and n2 the head of a noun phrase dominated byp.
Two options have generally been given for at-tachment, either to the verb v or the noun n1.
Thisparser struggles to accurately determine which ofthese two possibilities should be used.
However,in the structural model of grammar, there is a thirdoption, treating the prepositional phrase as an ob-ject complement of n1.
This possibility occurs fre-quently in English, such as in the sentence ?Weelected him as our secretary.?
or with idiomatic ex-pressions such as ?out of tune.?
The current depen-dency parser cannot represent this at all.5.3 AmbiguityA final case is when multiple correct structuralanalyses exist for a single sentences.
In somecases, this causes the parser to produce a gramati-cally and semantically correct parse which, due toambiguity, does not match the diagram for com-parison.
An example of this can be seen in Fig-ure 6, in which the dependency parser assigns theFigure 6: Diagram of ?On Saturday night the li-brary was almost deserted.
?predicate role to ?was deserted?
when in fact de-serted is acting as a subject complement.
How-ever, the phrase ?was deserted?
can accurately actas a predicate in that sentence, and produces a se-mantically valid interpretation of the phrase.6 ConclusionWe have demonstrated a promising method forconversion from a dependency graph to a sentencediagram.
However, this approach still has the op-portunity for a great deal of improvement.
Thereare two main courses of action for future work toreap the benefits of this approach: analyzing cur-rent results, and extending this approach to otherparsers for comparison.
First, a more detailedanalysis of current errors should be undertaken todetermine areas for improvement.
There are twobroadly defined categories of error (errors madebefore a dependency graph is given to the algo-rithm for conversion, and errors made during con-version to a diagram).
However, we do not knowwhat percent of mistakes falls into those two cat-egories.
We also do not know what exact gram-matical idiosyncracy caused each of those errors.With further examination of current data, this in-formation can be determined.Second, it must be determined what level ofconversion error is acceptable to begin makingquantitative comparisons of dependency parsers.Once the level of noise introduced by the conver-sion process is lowered to the point that the major-ity of diagram errors are due to mistakes or short-falls in the dependency graph itself, this tool willbe much more useful for evaluation.
Finally, thissystem should be extended to other dependencyparsers so that a comparison can be made betweenmultiple systems.ReferencesMichaela Atterer and Hinrich Schutze.
2007.
Preposi-tional Phrase Attachment without Oracles.
In Com-52putational Linguistics.John Carroll, Guido Minnen, and Ted Briscoe.
1999.Corpus annotation for parser evaluation.
In Pro-ceedings of the EACL workshop on LinguisticallyInterpreted Corpora.Dan Klein and Christopher D. Manning.
2003.
Ac-curate Unlexicalized Parsing.
In Proceedings of the41st Meeting of the Association for ComputationalLinguistics.Martha Kolln and Robert Funk.
2002.
UnderstandingEnglish Grammar, Sixth Edition.
Longman Publish-ers.Dekang Lin.
1995.
A Dependency-based Methodfor Evaluating Broad-Coverage Parsers.
In NaturalLanguage Engineering.Dekang Lin.
1998.
Dependency-based evaluation ofMINIPAR.
In Workshop on the Evaluation of Pars-ing SystemsMarie-Catherine de Marneffe, Bill MacCartney andChristopher D. Manning.
2006.
Generating TypedDependency Parses from Phrase Structure Parses.In International Conference on Language Resourcesand Evaluation.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Haji?c.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedingsof the conference on Human Language Technologyand Empirical Methods in Natural Language Pro-cessing.Daniel D. Sleator and Davy Temperley.
1993.
ParsingEnglish with a link grammar.
In Third InternationalConference on Parsing Technologies.53
