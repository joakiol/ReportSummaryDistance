Proceedings of the 3rd Workshop on the People?s Web Meets NLP, ACL 2012, pages 29?33,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsEAGER: Extending Automatically Gazetteers for Entity RecognitionOmer Gunes, Christian Schallhart, Tim FurcheDepartment of Computer Science,Oxford University, Oxford OX1 3QDfirstname.lastname@cs.ox.ac.ukJens Lehmann, Axel NgongaInstitute of Computer Science,University of Leipzig, 04103 Leipziglastname@informatik.uni-leipzig.deAbstractKey to named entity recognition, the manualgazetteering of entity lists is a costly, error-prone process that often yields results thatare incomplete and suffer from sampling bias.Exploiting current sources of structured in-formation, we propose a novel method forextending minimal seed lists into completegazetteers.
Like previous approaches, wevalue WIKIPEDIA as a huge, well-curated, andrelatively unbiased source of entities.
How-ever, in contrast to previous work, we exploitnot only its content, but also its structure, asexposed in DBPEDIA.
We extend gazetteersthrough Wikipedia categories, carefully limit-ing the impact of noisy categorizations.
Theresulting gazetteers easily outperform previ-ous approaches on named entity recognition.1 IntroductionAutomatically learning gazetteers with minimal su-pervision is a long standing problem in named entityrecognition.We propose EAGER as a novel approach to ex-tending automatically gazetteers for entity recogni-tion, utilizing DBPEDIA (Bizer et al, 2009) ratherthan WIKIPEDIA.
DBPEDIA serves as a much bet-ter foundation than WIKIPEDIA, because all the in-formation used in previous approaches (and muchmore) is already provided as a structured databaseof facts and articles.
The extraction is more robustand complete than ad-hoc methods and maintainedby a large community.
E.g., navigating the categoryhierarchy is much easier and reliable with DBPE-DIA.To summarize, EAGER?s main contributions are(1) A novel gazetteer expansion algorithm that addsnew entities from DBPEDIA.
EAGER adds enti-ties that have several categories in common withthe seed terms, addressing noisy categorizationsthrough a sophisticated category pruning tech-nique.
(2) EAGER also extracts categories from DBPE-DIA abstracts using dependency analysis.
Fi-nally, EAGER extracts plural forms and syn-onyms from redirect information.
(3) For entity recognition, we integrate the gazetteerwith a simple, but effective machine learningclassifier, and experimentally show that the ex-tended gazetteers improve the F1 score between7% and 12% over our baseline approach andoutperform (Zhang and Iria, 2009) on all learnedconcepts (subject, location, temporal).2 Related WorkWe divide the related work in automatic gazetteerpopulation into three groups: (1) Machine learningapproaches (2) Pattern driven approaches Finally,like our own work, (3) knowledge driven approachesKnowledge Driven.
In any case, machine learn-ing and pattern driven approaches extract their termsfrom unstructured sources ?
despite the fact thatlarge, general knowledge bases became availablein the last years.
One of the first knowledge-driven methods (Magnini et al, 2002) employedWORDNET to identify trigger words and candidate29gazetteer terms with its word-class and -instance re-lations.
As WORDNET covers domain specific vo-cabularies only to a limited extent, this approach isalso limited in its general applicability.In (Toral and Mu?oz, 2006), gazetteers are builtfrom the noun phrases in the first sentences ofWIKIPEDIA articles by mapping these phrases toWORDNET and adding further terms found alongthe hypernymy relations.
The approach presentedin (Kazama and Torisawa, 2007; Kazama and Tori-sawa, 2008) relies solely on WIKIPEDIA, produc-ing gazetteers without explicitly named concepts, ar-guing that consistent but anonymous labels are stilluseful.Most closely related to our own work, the authorsof (Zhang and Iria, 2009) build an approach solelyon WIKIPEDIA which does not only exploit the arti-cle text but also analyzes the structural elements ofWIKIPEDIA:3 Automatically Extending Gazetteer Lists3.1 Extraction Algorithm: OverviewAlgorithm 1 shows an outline of the gazetteer ex-pansion algorithm used in EAGER.
To extend an ini-tial seed set S EAGER proceeds, roughly, in threesteps: First, it identifies DBPEDIA articles for seedentities and extracts implicit category and synonyminformation from abstracts and redirect information(Lines 1?11).
Second, it finds additional categoriesfrom the DBPEDIA category hierarchy (Lines 12?20).
Finally, it uses the categories from the first twosteps to extract additional entities (Lines 21?24).
Inthe following, we consider the three steps separately.3.2 Implicit: Abstract and RedirectsBefore EAGER can analyse abstract and redirect in-formation for an article, we need to find the corre-sponding DBPEDIA articles (Lines 1?3) for eachseed entry in S .
There may be one or moresuch entry.
Here, we observe the first advantageof DBPEDIA?s more structured information: DB-PEDIA already contains plain text labels such as?Barack Obama?
and we can directly query (usingthe SPARQL endpoint) all articles with a label equal(or starting with) an entity in our seed set.
This al-lows for more precise article matching and avoidscomplex URL encodings as necessary in previous,Algorithm 1: GazetteerExtension(S )1 foreach seed entity e ?S do2 find article a for e in DBPEDIA;3 Articles(e)?
a;4 G ?
/0; P ?
/0;5 foreach entity e, article a = Articles(e) do6 foreach sentence s ?
a.Abstract do7 Ds?
dependencies in s;8 add all t : nsubj(e, t) ?
Ds to P;9 add all t : nsubj(e, t ?
),conj(t ?, t) ?
Ds to P;10 foreach article a?
?
a.Redirects do11 add all labels of a to G ;12 Cats(e)?
Cats(e)?a.Cats;13 foreach entity e, category c ?
Cats(e) do14 Cats(e)?
Cats(e)?CategoryNeighbors(c,k);15 foreach category c ?
Cats(e) for some e do16 Support(c)?
|{e?
: c ?
Cats(e?
)}|;17 foreach connected component C in Cats do18 Support(C )?
?c?C Support(c);19 MaxCatComp?
C with maximal Support;20 add all categories in MaxCatComp to P;21 foreach category c ?P do22 foreach article a with c ?
a.Cats do23 if |a.Cats\P| ?
?
then24 add all labels of a to G ;WIKIPEDIA-based approaches such as (Kazama andTorisawa, 2007).
As (Zhang and Iria, 2009), we re-ject redirection entries in this step as ambiguous.With the articles identified, we can proceed toextract category information from the abstracts andnew entities from the redirect information.
In thedependency analysis of article abstracts (Lines 6?9), we aim to extract category (or, more generally,hypernym) information from the abstracts of arti-cles on the ssed list.
We perform a standard de-pendency analysis on the sentences of the abstractand return all nouns that stand in nsubj relation toa seed entity or (directly or indirectly) in conj (cor-relative conjunction) relation to a noun that standsin nsubj relation to a seed entity.
This allows usto extract, e.g., both ?general?
and ?statesman?
ascategories from a sentence such as ?Julius Caesarwas a Roman general and statesman?.
This analy-sis is inspired by (Zhang and Iria, 2009), but per-formed on the entire abstract which is clearly dis-30123456Seed ListArticlessubject......Category ACategory BsubjectCategory A?broaderCategory A?
?broaderbroaderCategory B?subject...subjectsubjectsubjectNew Articles65321subjectsubjectUnrelated Cat.Unrelated Cat.123456Gazetteer78910789...Figure 1: EAGER Gazetteer Extension Algorithmtinguished in WIKIPEDIA.
This contrasts to (Zhangand Iria, 2009), where this is applied only to the firstsentence (as WIKIPEDIA does not directly provide aconcept of ?abstract?).
All categories thus obtainedare added to P and will be used in Section 3.4 togenerate additional entities.Finally, we are interested in redirection infor-mation (Lines 10?11) about an article for a seedentity as that provides such with synonyms, pluralforms, different spellings, etc.
Fortunately, DB-PEDIA provides this information directly by meansof the dbpedia-owl:wikiPageRedirects property.The labels of all redirect articles with this propertypointing to a seed entity articles are directly addedto the Gazetteer.3.3 Explicit: Category GraphIn addition to categories from the abstract analy-sis, we also use the category graph of DBPEDIA.It has been previously observed, (Zhang and Iria,2009) and (Strube and Ponzetto, 2006), that the cat-egory graph of poor quality.
DBPEDIA improveslittle on that fact.
However, EAGER uses a sophis-ticated analysis of categories related to seed entitiesthat allows us to prune most of the noise in the cat-egory graph.
Biased towards precision over recall,Section 4 shows that combined with the categoryextraction from abstracts it provides a significantlyextended Gazetteer without introducing substantialnoise.The fundamental contribution of EAGER is a cat-egory pruning based on finding a connected com-ponent in the graph of related categories that is sup-ported by as many different entities from the seed listas possible.
Figure 1 illustrates this further: Fromthe articles for the seed entities, we compute (Line12) the direct categories (via subject edges) and as-sociate them to their seed entities e via Cats(e).
Weextent this set (Lines 13?14) with all categories inthe k-neighbourhood (here, we use k = 3), i.e., con-nected via up to k broader edges traversed in anydirection, again maintaining via Cats(e) which cat-egories are reached from which seed entity e. Inthe resulting graph of all such categories, we iden-tify the connected component with maximum sup-port (Lines 15?19).
The support of a component isthe sum of the support of its categories.
The supportof a category c is the number of seed entities withc ?
Cats(e).
For Figure 1, this yields the categorygraph of the blue and black categories of the figure.The blue categories form the connected componentwith maximum support and are thus retained (inP),the black categories are dropped.3.4 Entities from CategoriesFinally, in Lines 21?24, EAGER completes thegazetteer extension by extracting the labels of allarticles of categories in P if they are sufficientlyunambiguous.
An article is called sufficiently un-ambiguous, if it is categorised only with categoriesfrom P up to a threshold ?
(here, set to 5) of non-P categories.
This avoids adding very general en-tities that tend to have large number of categories inWIKIPEDIA and thus DBPEDIA.
The output of Al-gorithm 3 is the extended gazetteers G .4 EvaluationTo evaluate the impact of EAGER on entity recogni-tion, we performed a large set of experiments (on thearcheology domain).
The experiment domains and31Subject Location TemporalP R F1 P R F1 P R F1Baseline (B) 69.9 54.1 62.0 76.5 46.1 61.3 86.4 75.4 80.9B+ Dependency 73.6 64.7 69.0 73.4 69.4 71.4 86.2 85.2 85.7B+ Category 72.3 64.5 68.5 71.9 70.1 71.0 86.4 85.0 85.8B+ Redirection 71.6 65.8 68.7 71.2 71.7 71.4 86.32 85.46 85.89(Zhang and Iria, 2009) full 69.8 66.5 68.1 68.9 75.0 71.8 82.4 83.4 82.9EAGER full 72.1 66.5 69.3 72.0 74.6 73.3 86.8 86.1 86.5Table 1: EAGER comparisoncorpora are described in Section 4.1.
Finally, Sec-tion 4.2 presents the results of the evaluation, show-ing the contributions of the different parts of EAGERand comparing it with (Zhang and Iria, 2009), whichwe outperform for all entity types, in some cases upto 5% in F1 score.4.1 Evaluation SetupIn this experiment, we consider entity recognition inthe domain of archaeology.As part of this effort, (Jeffrey et al, 2009) iden-tified three types of entities that are most usefulfor archaeological research; Subject(SUB), Tempo-ral Terms(TEM), Location (LOC).In this evaluation, we use the same setup as in(Zhang and Iria, 2009): A corpus of 30 full lengthUK archaeological reports archived by the Arts andHumanities Data Service (AHDS).
The length of thedocuments varies from 4 to 120 pages.
The corpusis inter-annotated by three archaeologists.4.2 ResultFor the evaluation, we perform a 5-fold validationon the above corpus.
The evaluate the performance(in terms of precision, recall and F1 score) for en-tity recognition of the baseline system as well asthe baseline system extended with a gazetteer fea-ture.
For the latter, we consider full EAGER as de-scribed in Section 3 as well as only the entities de-rived from dependency analysis of abstracts, fromthe category graph, and from redirection informa-tion.
Finally, we also include the performance num-bers report in (Zhang and Iria, 2009) for comparison(since we share their evaluation settings).Table 1 show the results of the comparison: EA-GER significantly improves precision and recall overthe baseline system and outperforms(Zhang and Iria,2009) in all cases.
Furthermore, the impact of allthree types of information (dependencies from ab-stract, category, redirection) of EAGER individuallyis quite notable with a slight disadvantage for cate-gory information.
However, in all cases the combi-nation of all three types as proposed in EAGER showsa significant further increase in performance.5 ConclusionAt its heart, EAGER is a novel algorithm for ex-tending sets of entities of a specific type with ad-ditional entities of that type extracted from DBPE-DIA.
It is based on a new strategy for pruning thecategory graph in DBPEDIA (and thus WIKIPEDIA),necessary to address the inherent noise.
Our evalua-tion shows that EAGER can significantly improve theperformance of entity recognition and outperformsexisting systems in all cases.
Unlike previous ap-proaches, our approach makes use of richer contentand structural elements of DBpedia.We believe that EAGER is a strong indicatorthat DBPEDIA provides a much richer, yet easierto use foundation for NLP tasks in general thanWIKIPEDIA.The extensibility and domain adaptability of ourmethods still need further investigation.
We are cur-rently extending the evaluation to several other do-mains, including property descriptions in real estateand classified adds.
We are also investigating moretargeted means of detecting and addressing noise inthe category graph.32ReferencesChristian Bizer, Jens Lehmann, Georgi Kobilarov, S?renAuer, Christian Becker, Richard Cyganiak, and Sebas-tian Hellmann.
2009.
DBpedia ?
A crystallizationpoint for the Web of Data.
Web Semantics: Science,Services and Agents on the World Wide Web, 7(3).Stuart Jeffrey, Julian Richards, Fabio Ciravegna, StewartWaller, Sam Chapman, and Ziqi Zhang.
2009.
TheArchaeotools project: Faceted Classification and Nat-ural Language Processing in an Archaeological Con-text.
Phil.
Trans.
R. Soc.
A, 367(3):2507?2519.Jun?ichi Kazama and Kentaro Torisawa.
2007.
Exploit-ing Wikipedia as External Knowledge for Named En-tity Recognition.
In Proceedings of the 2007 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, EMNLP-CoNLL, pages 698?707.Jun?ichi Kazama and Kentaro Torisawa.
2008.
InducingGazetteers for Named Entity Recognition by Large-Scale Clustering of Dependency Relations.
In Pro-ceedings of the 46th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 407?415.Bernardo Magnini, Matteo Negri, Roberto Prevete, andHristo Tanev.
2002.
A WordNet-based approach toNamed Entities recognition.
In Proceedings of the2002 workshop on Building and using semantic net-works - Volume 11, SEMANET ?02, pages 1?7.M.
Strube and S. P. Ponzetto.
2006.
WikiRelate!
Com-puting Semantic Relatedness Using Wikipedia.
InProceedings of the 21st National Conference on Ar-tificial Intelligence, pages 1419?1424.Antonio Toral and Rafael Mu?oz.
2006.
A Proposalto Automatically Build and Maintain Gazetteers forNamed Entity Recognition by using Wikipedia.
InProceedings of the Workshop on New Text ?
wikisand blogs and other Dynamic text sources, ECAL?06,pages 56?61.Ziqi Zhang and Jos?
Iria.
2009.
A novel approach toautomatic gazetteer generation using Wikipedia.
InProceedings of the 2009 Workshop on The People?sWeb Meets NLP: Collaboratively Constructed Seman-tic Resources, People?s Web ?09, pages 1?9.33
