A Structure-Sharing RepresentationforUnification-Based Grammar FormalismsFernando C .
N .
Pere i raAr t i f i c ia l  In te l l igence  Center ,  SR I  In ternat iona landCenter  fo r  the  S tudy  o f  Language and  In fo rmat ionS tanford  Un ivers i tyAbst ractThis paper describes a structure-sharing method for the rep-resentation of complex phrase types in a parser for PATR-\[I,a unification-based grammar formalism.In parsers for unification-based grammar formalisms,complex phrase types are derived by incremental refinementof rite phrase types defined in grammar rules and lexicalentries.
In a naive implementation, a new phrase type isbuilt by copying older ones and then combining the copiesaccording to the constraints stated in a grammar ule.
Thestructure-sharing method was designed to eliminate mostsuch copying; indeed, practical tests suggest hat the use ofthis technique reduces parsing time by as much as 60%.The present work is inspired by the structure-sharingmethod for theorem proving introduced by Boyer and Mooreand on the variant of it that is used in some Prolog imple-mentations.1 Overv iewIn this paper I describe a method, structure sharing, forthe representation of complex phrase types in 'a parser forPATR-II, a unification-based grammar formalism.In parsers for unification-based grammar formalisms,cfmtplex phrase types are derived by incremental refinementof the phrase types defined in grammar rules anti h, xicalemries.
In a naive implementation, a new phrase t.vpe isbuilt by" copying older ones and then combining the copiesaccording to the constraints tated in a grammar uh,.
Thestructure-sharing method eliminates most such copying byThis research, made possible in part by a gift from the Systems De*velol.~ment Foundation, wa~ also supported by the Defense AdvancedResearch Projects Agency under Contracts N00039*80-C-OG75 andN00039-84-C-0,524 with the Naval Electronic Systems Command.
Theviews and conclusions contained in this document are those of the au-thor and should not be inierpreted as representative ol the officialpolicies, either expressed or implied, of the Defense Advanced Re*s,,arrh Projects Agency, or the United States government.Thanks are due to Stuart Shieber, Lauri Karttunen.
aml Ray Per-rault for their comments on earlier presentations of this materiM.representing updates to objects (phrase types) separatelyfrom the objects themselves.The present work is inspired by the structure-sharingmethod for theorem proving introduced by Boyer and Moore\[11 and on the variant of it that is used in some Prolog im-plementations \[9\].2 Grammars  w i th  Un i f i ca t ionThe data representation discussed in this paper is applicable,with but minor changes, to a variety of grammar formalismsbased on unification, such as definite-clause grammars \[61,functional-unification grammar \[4\], lexical-fimctional gram-mar \[21 and PATR-II \[8i.
For the sake of concreteness, how-ever, our discussion will be in terms of the PATR-II formal-ism.The basic idea of unification-ba.se, I grammar formalisms isvery simple.
As with context-free ~rammars.
granlmar ulesstafe how phrase types con,blue t(, yiehl ol her phr:~se types.\[h,t where:m a context-free grammar allows only a finitenl,mber ,~f predefined atomic phrase types or nonlerminal.~,a unification-based grammar will in general define implicitlyan infinity of phra.se types.A phrase type is defined by a net of constraints.
A gram-mar m,le is a set of ronsl.rnints b,,twe,,u the type .\,~ .
f  aphr:me ;lnd the types .\', .
.
.
.
.
.
\ ' ,  of its ,'on..,iitm,nis.
Thert,h, niay I,, applied It, It,.
analysis ~,f a -,Ir'irlg s,, ;is thec<mc;ih,nalion of rcmslil.m'nls "~1,.....%t if and <rely if thotypes ,,f the .~i arc' rOml);~iible with the lypes .\', ;tml theconstraints in the ruh,.Unification is the operation that determines whether twotypes are compauble by buihling the most general type com-patible with both.if the constramls arc, Cqllationn I)elween at tril-iI,,s (~fphra.se types, ;is is the ,'ase in PAT I I - I I .
i~, ,  ltl ir:l~e l.x t)e-can lie uni lh,d wlH,iI~,~,l,r ih,,y ,Io l iol ;l~-.ii.rli , l i~i inci  ~,;ihie.~I.o I l ie ,~;llll?, al, l .r i l l i lh,.
The  i l l l i l i l ; i l  i l l i i i~, lhcl l  jil.~l Ih~, ~'llii-junct ion  (,sOt I l i l i( l l l)  Of the ro r res lX lad ing  sets of  COll.~trailll~,lsl.Ilere is a sample rule, in a simplified version (if the PATR-137II notation:Xo - -  Xt  X2 : (Xo cat) = $(X, cat) = NP(X, cat) = VP (l)(Xt agr) = (X~ agr)(Xo trans) = (X2 trans)(Xo trans argt) = (Xt trans)This rule may be read as stating that a phrase of type Xocan be the concatenation f a phrase of type Xt and a phraseof type X:, provided that the attribute quations of the ruleare satisfied if the phrases axe substituted for their types.The equations tate that phrases of types X0, Xt, and X:have categories S, NP, and VP, respectively, that types Xtand X~ have the same agreement value, that types Xo andX2 have the same translation, and that the first argumentof X0's translation is the translation of Xt.Formally, the expressions of the form (it..-I,,,) used inattribute quations axe path8 and each I~ is a label.When all the phrase types in a rule axe given constantcat (category} values by the rule, we can use an abbreviatednotation in which the phrase type vaxiables X~ axe replacedby their category values and the category-setting equationsare omitted.
For example, rule (1) may be written asS -* NP  VP : (NP aor) = (VP agr)(5' trana) = (VP teens) (2)(8 trana args) -- (NP  trans)In existing PATR-II implementations, phrase types arenot actually represented by their sets of defining equations.Instead, they are represented by symbolic solutions of theequations in the form of directed acyclic graphs (dacs) witharcs labeled by the attributes used in the equations.
Dagnodes represent the values of attributes and an arc labeledby l goes from node m to node n if and only if, accordingto the equations, the value represented by m has n as thevalue of its t attribute \[~\].A dag node (and by extension a dag) is said to be atomicif it represents a constant value; complex if it has some out-going arcs; and a leaf if is is neither atomic or complex, thatis, if it represents an as yet completely undetermined value.The domain dora(d) of a complex dag d is the set of labelson arcs leaving the top node of d. Given a dag d and a labell E dora(d) we denote by d/I the subdag of d at the end ofthe arc labeled I from the top node of d. By extension, forany path p whose labels are in the domains of the appropri-ate subdags, d/p represents the subdag of d at the end ofpath p from the root of d.For uniformity, lexical entries and grammar rules are alsorepresented by appropriate dags.
For example, the dag forrule (t) is shown in Figure 1.3 The Prob lemIn a chart parser \[31 all the intermediate stages of deriva-tions are encoded in ed0es, representing either incomplete0 2arg I I~transFigure 1: Dag Representation f a Rule(active) or complete (pensive) phra.ses.
For PATR-\[I, eachedge contains adag instance that represents he phrase typeof that edge.
The problem we address here is how to encodemultiple dag instances efficiently.\[n a chart parser for context-free grammars, the solutionis trivial: instances can be represented by the unique inter-hal names (that is, addresses) of their objects because theinformation contained in an instance is exactly the same a.sthat in the original object.\[n a parser for PATR-|I or any other unification-based for-realism, however, distinct instances of an object will in gen-eral specify different values for attributes left unspecified inthe original object.
Clearly, the attribute values pecified forone instance are independent of those for another instanceof the same object.One obvious solution is to build new instances by copy-ing the original object and then updating the copy with thenew attribute values.
This was the solution adopted in thefirst PATR-II parser \[8\].
The high cost of this solution bothin time spent copying and in space required for the copiesthenmelves constitutes the principal justification for employ-ing the method described here.4 Structure Shar ingStructure sharing is based on the observation that an ini-tial object, together with a list of update records, containsthe same information as the object that results from apply-ing the updates to the initial object.
In this way, we cantrade the cost of actually applying the updates (with pos-sible copying to avoid the destruction of the source object)against he cost of having to compute the effects of updateswhen examining the derived object.
This reasoning appliesin particular to dag instances that are the result of addingattribute values to other instances.138As in the variant of Boyer and Moore's method \[1\] usedin Prolog \[9\], I shall represent a dag instance by a molecule(see Figure 2) consisting of1.
\[A pointer to\] the initial dag, the instance's keleton2.
\[A pointer to\] a table of updates of the skeleton, theinstance's environment.Environments may contain two kinds of updates: reroutingsthat replace a dag node with another dag; are bindings thatadd to a node a new outgoing arc pointing to a dag.
Figure3 shows the unification of the dags1, "- \ [a :z ,b :y \ ]z= = \[c. \[d: eliAfter unification, the top node of/2 is rerouted to It and thetop node of \[i gets an arc binding with label c and a valuethat is the subdag \[d : e\] of/2.
As we shall see later, any up-date of a dag represented by a molecule is either an updateof the molecule's keleton or an update of a dag (to whichthe same reasoning applies) appearing in the molecule's en-viroment.
Therefore, the updates in a molecule's environ-ment are always shown in figures tagged by a boxed numberidentifying the affected node in the molecule's skeleton.The choice of which dag is rerouted and which one getsarc bindings is arbitrary.For reasons discussed later, the cost of looking up instancenode updates in Boyer and Moore's environment represen-tation is O(\]dl), where \[d\[ is the length of the derivation (a~equence of resolutions) of the instance.
In the present rep-resentation, however, this cost is only O(Iog \]d\]).
This betterperformance is achieved by particularizing the environmentrepresentation a d by splitting the representational schemeinto two components: a memory organization and a daft rep-re.sentation.A dag representation is & way of mapping the mathemat-ical entity dag onto a memory.
A memory organization is away of putting together a memory that has certain proper-ties with respect o lookup, updating and copying.
One canthink of the memory organization as the hardware and thedag representation as the data structure.5 Memory  organ izat ionIn practice, random-access memory can be accessed and up-dated in constant ime.
However, updates destroy old val-ues, which is obviously unacceptable when dealing with al-ternative updates of the same data structure.
If we want tokeep the old version, we need to copy it first into a sepa-rate part of memory and change the copy instead.
For thenormal kind of memory, copying time is proportional to thesize of the object copied.The present scheme uses another type of memory orga-nization - -  virtual-copy array~ ~ which requires O(logn)time to access or update an array with highest used indexk=2a\[nl = f a:fn = 30 = 132 (base 4)O(a) = 3Figure 4: Virtual-Copy Arrayof n, but in which the old contents are not destroyed by up-dating.
Virtual-copy arrays were developed by David H. D.Warren \[10\] as an implementation of extensible arrays forProlog.Virtual-copy arrays provide a fully general memory ~truc-ture: anything that can be stored in r,'tndom-a,-ces~ mem-ory can be stored in virtual-copy arrays, althoqlgh p,~mtersin machine memory correspond to indexes in a virtual-copyarray.
An updating operation takes a virtual-copy array, anindex, and a new value and returns a new virtual-copy arraywith the new value stored at the given index.
An access op-eration takes an array and an index, and returns the valueat that index.Basically, virtual-copy arrays are 2k-ary trees for somefixed k > 0.
Define the depth d(n) of a tree node nto be 0 for the root and d(p) + I if p is the parent ofn.
Each virtual-copy array a has also a positive depthD(a) > max{d(n) : n is a node of a}.
A tree node at depthD(a) (necessarily a leaf) can be either an array elementor the special marker .L for unassigned elements.
All leafnodes at depths lower than D(a) are also ?, indicating thatno elements have yet been stored in the subarray below thenode.
With this arrangement, he array can store at most2 k?
('l elements, numbered 0 through 2 k?~*l - l, but unusedsdbarrays need not be allocated.By numbering the 2 h daughters of a nonleaf node from 0to 2 k - 1, a path from a's root to an array element (a leaf atdepth D(a)) can be represented by a sequence no.
.
.
no(ab-tin which n, is the number of the branch taken at depth d.This sequence is just the base 2 k representation f the indexn of the array element, with no the most significant digitand no(.}
the least significant (Figure .t).When a virtual-copy array a is updated, one of two thingsmay happen.
If the index for the updated element exceedsthe maximum for the current depth (,a~ in the a\[8\] := ~/up-date in Figure 5), a new root node is created for the updatedarray and the old array becomes the leftmost daughter of thenew root.
Other node,, are also created, as appropriate, toreach the position of the new element.
If, on the other hand,the index for the update is within the range for the current139mo,.~,2~  _ mIskeleton ~ "~ environmentown I ref I refSpot Danielinitial update?-?
I,ef I,.fDaniel SpotFigure 2: MoleculeX unification.
/ ~ ~ < > ~  <-/ \  <>?
-  "_L_ J ?
-  ' :_L_IIIxa y~dFigure 3: Unification of Two Molecules140a{21: = ha: \[O:e, 2:h, 8:glo{81: = g?
?a: \[0:e, 2:f, 8:glI ga: \[0:e, 2:fle fFigure 5: Updating Virtual-Copy Arraysdepth, the path from the root to the element being updatedis copied and the old element is replaced in the new tree bythe new element (as in the a\[21 := h update in Figure 5).This description assumes that the element being updatedhas alroady been set.
If not, the branch to the element mayT,,rminate prematurely in a 2. leaf, in which case new nodesare created to the required depth and attached to the ap-propriate position at the end of the new path from the root.6 Dag representationAny dug representation can be implemented with virtual-copy memory instead of random-access memory.
If that were,lone for the original PATR-II copying implementation, acertain measure of structure sharing would be achieved.The present scheme, however, goes well b~yond that byusing the method of structure sharing introduced in Section4.
As we saw there, an instance object is represented by amolecule, a pair consisting of a skeleton dug {from a ruleor iexical entry) and an update environment.
We shall nowexamine the structure of environments.In a chart parser for PATR-ll, dug instances in the chartfall into two classes.Base in.stances are those associated with edges that arecreated directly from lexical entries or rules.Derived instances occur in edges that result from the com-bination of a left and a right parent edge containing the leftand right parent instances of the derived instance.
The leftancestors of an instance {edge) are its left parent and thatparent's ancestors, and similarly for right ancestors, l willassume, for ease of exposition, that a derived instance isalways a subdag of the unification of its right parent witha subdag of its left parent.
This is the case for most com-mon parsing algorithms, although more general schemes arepossible \[7\].If the original Boyer-Moore scheme were used directly, theenvironment for a derived instance would consist of point-ers to left and right parent instances, as well as a list ofthe updates needed to build the current instance from itsparents.
As noted before, this method requires a worst-caseO(Idl} search to find the updates that result in the currentinstance.The present scheme relies on the fact that in the greatmajority of cases no instance is both the left and the rightancestor of another instance.
\[ shall assume for the momentthat this is always the case.
In Section 9 this restriction willbe removed.It is asimple observation about unification that an updateof a node of an instance \]" is either an update of \[ 's skeletonor of the value (a subdag of another instance) of anotherupdate of L If we iterate this reasoning, it becomes clearthat every update is ultimately an update of the skeleton ofa base instance ancestor of \[.
Since we assumed above thatno instance could occur more than once in it's derivation, wecan therefore conclude that \[ 's environment consists only ofupdates of nodes in the skeletons of its base instance an-cestors.
By numbering the base instances of a derivationconsecutively, we can then represent an environment by anarray of frames, each containing all the updates of the skele-ton of a given base instance.Actually, the environment of an instance \[ will be a branchenvironment containing not only those updates directly rele-vant to \[, but also all those that are relevant o the instanceso f / ' s  particular branch through the parsing search space.In the context of a given branch environment, it is thenpossible to represent a molecule by a pair consisting of askeleton and the index of a frame in the environment.
Inparticular, this representation can be used for all the value~(dags) in updates.More specifically, the frame of a base instance is an arrayof update records indexed by small integers representing thenodes of the instance's skeleton.
An update record is eithera list of arc bindings for distinct arc labels or a reroutingupdate.
An arc binding is a pair consisting of a label anda molecule (the value of the arc binding).
This representsan addition of an arc with that label and that value at th,,given node.
A rerouting update is just a pointer to anothermolecule; it says that the subdag at that node in the updateddug is given by that molecule (rather than by whatever w,xsin the initial skeleton).To see how skeletons and bindings work together to rep-resent a dag, consider the operation of finding the sub(tagd/ ( I t ' " lm)  of dug d. For this purpose, we use a currentskeleton s and a current frame f, given initially by the skele-ton and frame of the molecule representing d. Now assume141that the current skeleton s and current frame ,f correspondto the subdag d' -- d/(ll.., l~-l).
To find d/(l~.., l~) -" ~/l~,we use the following method:I.
If the top node of s has been rerouted in j" to a dag v,dereference ?
by setting s and .f from v and repeatingthis step; otherwise2.
If the top node of s has an arc labeled by l~ with values', the subdag at l~ is given by the moledule (g,\[);otherwise3.
If .f contains an arc binding labeled l~ for the top nodeof s, the subdag at l~ is the value of the bindingIf none of these steps can be applied, (It .-.
l~) is not a pathfrom the root in d.The details of the representation are illustrated by theexample in Figure 6, which shows the passive edges for thechart analysis of the string ab according to the sample gram-S-*AB:  (5" a) = (A)(S b) = (B)(S==)  = (Shy)marA-*a :  (Auv)  = a(3)8-. .
.b:  (Buy)  = bFor the sake of simplicity, only the subdags correspondingto the explicit equations in these rules are shown (ie., thecat dug arcs and the rule arcs 0, 1,... are omitted}.
Inthe figure, the three nonterminal edges (for phrase types S,.4 and B) are labeled by molecules representing the corre-sponding dags.
The skeleton of each of the three moleculescomes from the rule used to build the nonterminal.
Eachmolecule points (via a frame index not shown in the figure)to a frame in the branch environment.
The frames for theA and B edges contain arc bindings for the top nodes ofthe respective skeletons whereas the frame for the S edgereroute nodes 1 and 2 of the S rule skeleton to the A and Bmolecules respectively.7 The Unification AlgorithmI shall now give the u~nification algorithm for two molecules(dags} in the same branch environment.We can treat a complex dug d a8 a partial function fromlabels to dags that maps the label on each arc leaving the topnode of the dag to the dug at the end of that arc.
This allowsus to define the following two operations between dags:d~ \ d2 = {{l ,d}ed~l i~dom{d:}}di <3 d= = {(l,d) Edl  J I Gdorn(d:)}It is clear that dom(dl <~ d~) = dom(d2 <~ dl).We also need the notion of dug dereferencing introducedin the last section.
As a side effect of successive unifications,the top node of a dag may be rerouted to another dag whosetop node will also end up being rerouted.
Dereferencing isthe process of following such chains of rerouting pointers toreach a dug that has not been rerouted.The unification of dags dl and d~ in environment e consistsof the following steps:1.
Dereference dl and d22.
If dl and d: are identical, the unification is immediatelysuccessful3.4.5.6.If dl is a leaf, add to e a rerouting from the top node ofdl to d~; otherwiseIf d2 is a leaf, add to e a rerouting from the top node ofd2 to dl; otherwiseIf dl and d2 are complex dags, for each arc (l, d) E dl <~d= unify the dag d with the dag d' of the correspondingarc (i,d') G d~ <l dl.
Each of those unifications mayadd new bindings to e. If this unification of subdags i.~successful, all the arcs in dl \ d~ are are cab'red in e ~arc bindings for the top node of d: and tinnily the topnode of dl is rerouted to d~.If none of the conditions above applies, the unificationfails.To determine whether a dag node is a leaf or com-plex, both the skeleton and the frame of the correspondingmolecule must be examined.
For a dereferenced molecule.the set of arcs leaving a node is just the union of the skele-ton arcs and the arc bindings for the node.
For this to makesense, the skeleton arcs and arc bindings for any moleculenode must be disjoint.
The interested reader will have nodi~cuhy in proving that this property is preserved by theunification algorithm and therefore all molecules built fromskeletons and empty frames by unification wiU satisfy it.
?8 Mapping dags onto virtual-copymemoryAs we saw above, any dag or set of dags constructed bythe parser is built from just two kinds of material: (I)frames; (21 pieces of the initial skeletons from rules and\[exical entries.
The initial skeletons can be represented triv-ially by host language data structures, as they never change.F~'ames, though, are always being updated.
A new frame isborn with the creation of an instance of a rule or lexicalentry when the rule or entry is used in some parsing step(uses of the same rule or entry in other steps beget their ownframes).
A frame is updated when the instance it belongsto participates in a unification.During parsing, there are in general several possible waysof continuing a derivation.
These correspond to alternativeways of updating a branch environment.
In abstract terms,142\[\] \[\]{7) iFigure 6: Structure-Sharing Charton coming to a choice point in the derivation with n possi-ble continuations, n - 1 copies of the environment are made,giving n environments - - namely, one for each alternative.In fact.
the use of virtual-copy arrays for environments andframes renders this copying unnecessary, so each continu-ation path performs its own updating of its version of theenvironment without interfering with the other paths.
Thus,all unchanged portions of the environment are shared.In fact, derivations as such are not explicit in a ,'hartparser.
Instead, the instance in each edge has its own branch,,nvironment, as described previously.
Therefore.
when twoe,lges are combined, it is necessary to merge their environ-ments.
The cost of this merge operation is at most the samethe worst case cost for unification proper (O(\[d\[ log JdJ)).However, in the very common case in which the ranges offrame indices of the two environments do not overlap, themerge cost is only O(log \[d\[).To summarize, we have sharing at two levels: the Boyer-Moore style dag representation allows derived (lag in-stances to share input data structures (skeletons), and thevirtual-copy array environment representation allows differ-ent branches of the search space to share update records.9 The Renaming ProblemIn the foregoing discussion of the structure-sharing method,\[ assumed that the left and right ancestors of a derived in-stance were disjoint.
In fact, it is easy to show that the con-dition holds whenever the graHtm;tr d. 's  n?
)t ~.llow elllptyderiv(,d edges.In ,',mtrast, it is p,)ssible t,) construct a grammar in whichan empty derived edge with dag D is b. th a left and a rightancestor of another edge with dag E. Clearly, tile two uses(~f D a.s an ancestor of E are mutually independent andthe corresponding updates have to be seqregated.
In ,~therwords, we need two ,'~l)ies of tile instance D. 13v anal,,~'with theorem proving, \[ call Ihi~ lhe renaminq pr~d,h,m.The ('nrreflt sol|,t.i(,n is t,) us,, real ,'(,I)YiV|g t,) turn th,,empty edge into a skelet(>n, which is the|| adde~l t~ the chart.The new skeleton is then used in the norn|al fa.shion to pro-duce multiple instances that are free of mutual interference.10 Imp lementat ionThe representation described here has been used in a PATR-II parser implemented in I)r,~l,)g ".
Two versions of the parserexist - cme using all Ea,-h,y-st.vle algorithn| related to Ear-ley deduction \[7\], the other using a left-,'.rner algorithm.Preliminary tests of the left-corner algorithm with struc-ture sharing on various grammars and input have shownparsing times as much as 60% faster (never less, in fact,than 40% faster) than those achieved by the same parsingalgorithm with structure copying.14,3References\[1\] R. S. Boyer and J S. Moore.
The sharing of structure intheorem-proving program& In Machine Intelligence 7,pages 101-116, John Wiley and Sons, New York, NewYork, 1972.\[21 J. Bresnan and R. Kaplan.
Lexical-functional gram-mar: a formal system for grammatical representation.In J. Bresnan, editor, The Mental Representation ofGrammatical Relations, pages 173-281, MIT Press,Cambridge, Massachusetts, 1982.\[3\] M. Kay.
Algorithm Schemata nd Data Structures inSyntactic Processing.
Technical Report, XEROX PaloAlto Research Center, Palo Alto, California, 1980.
Aversion will appear in the proceedings of the NobelSymposium on Text Processing, Gothenburg, 1980.I4\] M. Kay.
Functional grammar.
In Pro?.
of the FifthAnnual Meeting of the Berkeley Linguistic Society,pages 142-158, Berkeley Linguistic Society, Berkeley,California, February 17-19 1979.\[5\] Fernando C. N. Pereira nd Stuart M. Shieber.
The se-mantics of grammar formalisms een as computer lan-guages.
|n Proe.
of Coling8~, pages 123-129, Asso,-ia-tion for Computational Linguistics, 1984.\[6\] Fernando C. N. Pereira and David H. D. Warren.
Defi-nite clause grammars for language analysis - a survey ofthe formalism and a comparison with augmented transi-tion networks.
Artificial Inteilicence, 13:231-278, 1980.\[7\] Fernando C. N. Pereira and David H. D. Warren.
Pars-ing as deduction.
In Proc.
of the 9lst Annual 3Iectin~of the Association for Computational Linguistics, MIT,Cambridge, Massachusetts, June 15-17 1983.\[8\[ Stuart M. Shieber.
The design of a computer lan-guage for linguistic information.
In Proc.
of Colinf8j,pages 362-366, Association for Computational l,inguis-tics, 1984.\[9\] David H. D. Warren.
Applied Logic - its use and intple.menlalion as proqramming tool.
PhD thesis, Universityof FMinburgh, Scotland, 1977.
Reprinted as T~,,'hnicalNote 290, Artificial Intelligence Center, SRI, Intorna-tional, Menlo Park, California.
{10\] David H. D. Warren, Logarithmic access arrays forProlog.
Unpublished program, 1983.144
