Language model adaptation with MAP estimationand the perceptron algorithmMichiel Bacchiani, Brian Roark and Murat SaraclarAT&T Labs-Research, 180 Park Ave., Florham Park, NJ 07932, USA{michiel,roark,murat}@research.att.comAbstractIn this paper, we contrast two language modeladaptation approaches: MAP estimation andthe perceptron algorithm.
Used in isolation, weshow that MAP estimation outperforms the lat-ter approach, for reasons which argue for com-bining the two approaches.
When combined,the resulting system provides a 0.7 percent ab-solute reduction in word error rate over MAPestimation alone.
In addition, we demonstratethat, in a multi-pass recognition scenario, it isbetter to use the perceptron algorithm on earlypass word lattices, since the improved error rateimproves acoustic model adaptation.1 IntroductionMost common approaches to language model adapta-tion, such as count merging and model interpolation, arespecial cases of maximum a posteriori (MAP) estima-tion (Bacchiani and Roark, 2003).
In essence, these ap-proaches involve beginning from a smoothed languagemodel trained on out-of-domain observations, and adjust-ing the model parameters based on in-domain observa-tions.
The approach ensures convergence, in the limit, tothe maximum likelihood model of the in-domain obser-vations.
The more in-domain observations, the less theout-of-domain model is relied upon.
In this approach, themain idea is to change the out-of-domain model parame-ters to match the in-domain distribution.Another approach to language model adaptation wouldbe to change model parameters to correct the errorsmade by the out-of-domain model on the in-domain datathrough discriminative training.
In such an approach,the baseline recognizer would be used to recognize in-domain utterances, and the parameters of the model ad-justed to minimize recognition errors.
Discriminativetraining has been used for language modeling, using vari-ous estimation techniques (Stolcke and Weintraub, 1998;Roark et al, 2004), but language model adaptation tonovel domains is a particularly attractive scenario for dis-criminative training, for reasons we discuss next.A key requirement for discriminative modeling ap-proaches is training data produced under conditions thatare close to testing conditions.
For example, (Roark et al,2004) showed that excluding an utterance from the lan-guage model training corpus of the baseline model usedto recognize that utterance is essential to getting worderror rate (WER) improvements with the perceptron al-gorithm in the Switchboard domain.
In that paper, 28different language models were built, each omitting oneof 28 sections, for use in generating word lattices for theomitted section.
Without removing the section, no benefitwas had from models built with the perceptron algorithm;with removal, the approach yielded a solid improvement.More time consuming is controlling acoustic model train-ing.
For a task such as Switchboard, on which the abovecitation was evaluated, acoustic model estimation is ex-pensive.
Hence building multiple models, omitting var-ious subsections is a substantial undertaking, especiallywhen discriminative estimation techniques are used.Language model adaptation to a new domain, how-ever, can dramatically simplify the issue of controllingthe baseline model for producing discriminative trainingdata, since the in-domain training data is not used forbuilding the baseline models.
The purpose of this paper isto compare a particular discriminative approach, the per-ceptron algorithm, which has been successfully appliedin the Switchboard domain, with MAP estimation, foradapting a language model to a novel domain.
In addi-tion, since the MAP and perceptron approaches optimizedifferent objectives, we investigate the benefit from com-bination of these approaches within a multi-pass recogni-tion system.The task that we focus upon, adaptation of a generalvoicemail recognition language model to a customer ser-vice domain, has been shown to benefit greatly fromMAP estimation (Bacchiani and Roark, 2003).
It is anattractive test for studying language model adaptation,since the out-of-domain acoustic model is matched tothe new domain, and the domain shift does not raise theOOV rate significantly.
Using 17 hours of in-domainobservations, versus 100 hours of out-of-domain utter-ances, (Bacchiani and Roark, 2003) reported a reductionin WER from 28.0% using the baseline system to 20.3%with the best performing MAP adapted model.
In this pa-per, our best scenario, which uses MAP adaptation andthe perceptron algorithm in combination, achieves an ad-ditional 0.7% reduction, to 19.6% WER.The rest of the paper is structured as follows.
In thenext section, we provide a brief background for bothMAP estimation and the perceptron algorithm.
This isfollowed by an experimental results section, in which wepresent the performance of each approach in isolation, aswell as several ways of combining them.2 Background2.1 MAP language model adaptationTo build an adapted n-gram model, we use a countmerging approach, much as presented in (Bacchiani andRoark, 2003), which is shown to be a special case of max-imum a posteriori (MAP) adaptation.
Let wO be the out-of-domain corpus, and wI be the in-domain sample.
Leth represent an n-gram history of zero or more words.
Letck(hw) denote the raw count of an n-gram hw in wk,for k ?
{O, I}.
Let p?k(hw) denote the standard Katzbackoff model estimate of hw given wk.
We define thecorrected count of an n-gram hw as:c?k(hw) = |wk| p?k(hw) (1)where |wk| denotes the size of the sample wk.
Then:p?
(w | h) =?hc?O(hw) + c?I(hw)?h?w?
c?O(hw?)
+?w?
c?I(hw?
)(2)where ?h is a state dependent parameter that dictates howmuch the out-of-domain prior counts should be reliedupon.
The model is then defined as:p?
(w | h) ={p?
(w | h) if cO(hw) + cI(hw) > 0?p?
(w | h?)
otherwise(3)where ?
is the backoff weight and h?
the backoff historyfor history h.The principal difficulty in MAP adaptation of this sortis determining the mixing parameters ?h in Eq.
2.
Follow-ing (Bacchiani and Roark, 2003), we chose a single mix-ing parameter for each model that we built, i.e.
?h = ?for all states h in the model.2.2 Perceptron algorithmOur discriminative n-gram model training approach usesthe perceptron algorithm, as presented in (Roark et al,2004), which follows the general approach presented in(Collins, 2002).
For brevity, we present the algorithm,not in full generality, but for the specific case of n-grammodel training.The training set consists of N weighted word latticesproduced by the baseline recognizer, and a gold-standardtranscription for each of the N lattices.
Following (Roarket al, 2004), we use the lowest WER hypothesis in thelattice as the gold-standard, rather than the reference tran-scription.
The perceptron model is a linear model with kfeature weights, all of which are initialized to 0.
The al-gorithm is incremental, i.e.
the parameters are updated ateach example utterance in the training set in turn, and theupdated parameters are used for the next utterance.
Af-ter each pass over the training set, the model is evaluatedon a held-out set, and the best performing model on thisheld-out set is the model used for testing.For a given path pi in a weighted word lattice L, letw[pi] be the cost of that path as given by the baseline rec-ognizer.
Let GL be the gold-standard transcription forL.
Let ?
(pi) be the K-dimensional feature vector for pi,which contains the count within the path pi of each fea-ture.
In our case, these are unigram, bigram and trigramfeature counts.
Let ?
?t ?
RK be the K-dimensional fea-ture weight vector of the perceptron model at time t. Theperceptron model feature weights are updated as follows1.
For the example lattice L at time t, find p?it such thatp?it = argminpi?L(w[pi] + ??
(pi) ?
?
?t) (4)where ?
is a scaling constant.2.
For the 0 ?
k ?
K features in the feature weightvector ??t,?
?t+1[k] = ?
?t[k] + ?
(p?it)[k] ?
?
(GL)[k] (5)Note that if p?it = GL, then the features are left un-changed.As shown in (Roark et al, 2004), the perceptron fea-ture weight vector can be encoded in a deterministicweighted finite state automaton (FSA), so that much ofthe feature weight update involves basic FSA operations,making the training relatively efficient in practice.
Assuggested in (Collins, 2002), we use the averaged per-ceptron when applying the model to held-out or test data.After each pass over the training data, the averaged per-ceptron model is output as a weighted FSA, which can beused by intersecting with a lattice output from the base-line system.3 Experimental ResultsWe evaluated the language model adaptation algorithmsby measuring the transcription accuracy of an adaptedvoicemail transcription system on voicemail messages re-ceived at a customer care line of a telecommunicationsnetwork center.
The initial voicemail system, namedScanmail, was trained on general voicemail messagescollected from the mailboxes of people at our researchsite in Florham Park, NJ.
The target domain is also com-posed of voicemail messages, but for a mailbox that re-ceives messages from customer care agents regardingnetwork outages.
In contrast to the general voicemailmessages from the training corpus of the Scanmail sys-tem, the messages from the target domain, named SS-NIFR, will be focused solely on network related prob-lems.
It contains frequent mention of various networkrelated acronyms and trouble ticket numbers, rarely (if atall) found in the training corpus of the Scanmail system.To evaluate the transcription accuracy, we used a multi-pass speech recognition system that employs variousunsupervised speaker and channel normalization tech-niques.
An initial search pass produces word-lattice out-put that is used as the grammar in subsequent searchpasses.
The system is almost identical to the one de-scribed in detail in (Bacchiani, 2001).
The main differ-ences in terms of the acoustic model of the system arethe use of linear discriminant analysis features; use of a100 hour training set as opposed to a 60 hour training set;and the modeling of the speaker gender which in this sys-tem is identical to that described in (Woodland and Hain,1998).
Note that the acoustic model is appropriate for ei-ther domain as the messages are collected on a voicemailsystem of the same type.
This parallels the experimentsin (Lamel et al, 2002), where the focus was on AM adap-tation in the case where the LM was deemed appropriatefor either domain.The language model of the Scanmail system is a Katzbackoff trigram, trained on hand-transcribed messages ofapproximately 100 hours of voicemail (1 million words).The model contains 13460 unigram, 175777 bigram, and495629 trigram probabilities.
The lexicon of the Scan-mail system contains 13460 words and was compiledfrom all the unique words found in the 100 hours of tran-scripts of the Scanmail training set.For every experiment, we report the accuracy of theone-best transcripts obtained at 2 stages of the recog-nition process: after the first pass lattice construction(FP), and after vocal tract length normalization and gen-der modeling (VTLN), Constrained Model-space Adap-tation (CMA), and Maximum Likelihood Linear regres-sion adaptation (MLLR).
Results after FP will be denotedFP; results after VTLN, CMA and MLLR will be denotedMP.For the SSNIFR domain we have available a 1 hourmanually transcribed test set (10819 words) and approx-imately 17 hours of manually transcribed adaptation data(163343 words).
In all experiments, the vocabulary ofthe system is left unchanged.
Generally, for a domainshift this can raise the error rate significantly due to anincrease in the OOV rate.
However, this increase in errorrate is limited in these experiments, because the majorityof the new domain-dependent vocabulary are acronymsSystem FP MPBaseline 32.7 28.0MAP estimation 23.7 20.3Perceptron (FP) 26.8 23.0Perceptron (MP) ?
23.9Table 1: Recognition on the 1 hour SSNIFR test set us-ing systems obtained by supervised LM adaptation on the17 hour adaptation set using the two methods, versus thebaseline out-of-domain system.which are covered by the Scanmail vocabulary throughindividual letters.
The OOV rate of the SSNIFR test set,using the Scanmail vocabulary is 2%.Following (Bacchiani and Roark, 2003), ?h in Eq.
2 isset to 0.2 for all reported MAP estimation trials.
Follow-ing (Roark et al, 2004), ?
in Eq.
4 is also (coincidentally)set to 0.2 for all reported perceptron trials.
For the percep-tron algorithm, approximately 10 percent of the trainingdata is reserved as a held-out set, for deciding when tostop the algorithm.Table 1 shows the results using MAP estimation andthe perceptron algorithm independently.
For the percep-tron algorithm, the baseline Scanmail system was used toproduce the word lattices used in estimating the featureweights.
There are two ways to do this.
One is to use thelattices produced after FP; the other is to use the latticesproduced after MP.These results show two things.
First, MAP estimationon its own is clearly better than the perceptron algorithmon its own.
Since the MAP model is used in the ini-tial search pass that produces the lattices, it can considerall possible hypotheses.
In contrast, the perceptron algo-rithm is limited to the hypotheses available in the latticeproduced with the unadapted model.Second, training the perceptron model on FP latticesand applying that perceptron at each decoding step out-performed training on MP lattices and only applying theperceptron on that decoding step.
This demonstrates thebenefit of better transcripts for the unsupervised adapta-tion steps.The benefit of MAP adaptation that leads to its supe-rior performance in Table 1 suggests a hybrid approach,that uses MAP estimation to ensure that good hypothesesare present in the lattices, and the perceptron algorithmto further reduce the WER.
Within the multi-pass recog-nition approach, several scenarios could be considered toimplement this combination.
We investigate two here.For each scenario, we split the 17 hour adaptation setinto four roughly equi-sized sets.
In a first scenario, weproduced a MAP estimated model on the first 4.25 hoursubset, and produced word lattices on the other three sub-sets, for use with the perceptron algorithm.
Table 2 showsSystem MAP Pct.
FP MPBaseline 0 32.7 28.0MAP estimation 100 23.7 20.3MAP estimation 25 25.6 21.5Perceptron (FP) 25 23.8 20.5Perceptron (MP) 25 ?
20.8Table 2: Recognition on the 1 hour SSNIFR test set usingsystems obtained by supervised LM adaptation on the 17hour adaptation set using the first method of combinationof the two methods, versus the baseline out-of-domainsystem.the results for this training scenario.A second scenario involves making use of all of theadaptation data for both MAP estimation and the percep-tron algorithm.
As a result, it requires a more compli-cated control of the baseline models used for producingthe word lattices for perceptron training.
For each of thefour sub-sections of the adaptation data, we produced abaseline MAP estimated model using the other three sub-sections.
Using these models, we produced training lat-tices for the perceptron algorithm for the entire adaptationdata set.
At test time, we used the MAP estimated modeltrained on the entire adaptation set, as well as the percep-tron model trained on the entire set.
The results for thistraining scenario are shown in table 3.Both of these hybrid training scenarios demonstrate asmall improvement by using the perceptron algorithm onFP lattices rather than MP lattices.
Closely matching thetesting condition for perceptron training is important: ap-plying a perceptron trained on MP lattices to FP latticeshurts performance.
Iterative training did not produce fur-ther improvements: training a perceptron on MP latticesproduced by using both MAP estimation and a perceptrontrained on FP lattices, achieved no improvement over the19.6 percent WER shown above.4 DiscussionThis paper has presented a series of experimental re-sults that compare using MAP estimation for languagemodel domain adaptation to a discriminative modelingapproach for correcting errors produced by an out-of-domain model when applied to the novel domain.
Be-cause the MAP estimation produces a model that is usedduring first pass search, it has an advantage over theperceptron algorithm, which simply re-weights paths al-ready in the word lattice.
In support of this argument, weshowed that, by using a subset of the in-domain adapta-tion data for MAP estimation, and the rest for use in theperceptron algorithm, we achieved results at nearly thesame level as MAP estimation on the entire adaptationset.System MAP Pct.
FP MPBaseline 0 32.7 28.0MAP estimation 100 23.7 20.3Perceptron (FP) 100 22.9 19.6Perceptron (MP) 100 ?
19.9Table 3: Recognition on the 1 hour SSNIFR test set us-ing systems obtained by supervised LM adaptation on the17 hour adaptation set using the second method of com-bination of the two methods, versus the baseline out-of-domain system.With a more complicated training scenario, which usedall of the in-domain adaptation data for both methodsjointly, we were able to improve WER over MAP estima-tion alone by 0.7 percent, for a total improvement overthe baseline of 8.4 percent.Studying the various options for incorporating the per-ceptron algorithm within the multi-pass rescoring frame-work, our results show that there is a benefit from incor-porating the perceptron at an early search pass, as it pro-duces more accurate transcripts for unsupervised adapta-tion.
Furthermore, it is important to closely match testingconditions for perceptron training.ReferencesMichiel Bacchiani and Brian Roark.
2003.
Unsupervisedlanguage model adaptation.
In Proceedings of the In-ternational Conference on Acoustics, Speech, and Sig-nal Processing (ICASSP), pages 224?227.Michiel Bacchiani.
2001.
Automatic transcription ofvoicemail at AT&T.
In Proceedings of the Interna-tional Conference on Acoustics, Speech, and SignalProcessing (ICASSP).Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and experi-ments with perceptron algorithms.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP), pages 1?8.L.
Lamel, J.-L. Gauvain, and G. Adda.
2002.
Unsuper-vised acoustic model training.
In Proceedings of theInternational Conference on Acoustics, Speech, andSignal Processing (ICASSP), pages 877?880.Brian Roark, Murat Saraclar, and Michael Collins.
2004.Corrective language modeling for large vocabularyASR with the perceptron algorithm.
In Proceedingsof the International Conference on Acoustics, Speech,and Signal Processing (ICASSP).A.
Stolcke and M. Weintraub.
1998.
Discriminitive lan-guage modeling.
In Proceedings of the 9th Hub-5Conversational Speech Recog nition Workshop.P.C.
Woodland and T. Hain.
1998.
The September 1998HTK Hub 5E System.
In The Proceedings of the 9thHub-5 Conversational Speech Recognition Workshop.
