EasyEnglish: A Tool for Improving Document QualityArendse  BernthIBM ResearchP.O.
Box 704Yorktown Heights, NY 10598, USAarendse@wat son.
ibm.
coraAbst rac tWe describe the authoring tool, EasyEng-lish, which is part of IBM's internal SGMLediting environment, Information Develop-ment Workbench.
EasyEnglish elps writ-ers produce clearer and simpler English bypointing out ambiguity and complexity aswell as performing some standard grammarchecking.
Where appropriate, EasyEnglishmakes uggestions for rephrasings that maybe substituted directly into the text by us-ing the editor interface.EasyEnglish is based on a full parse byEnglish Slot Grammar; this makes it possi-ble to produce a higher degree of accuracyin error messages as well as handle a largevariety of texts.1 In t roduct ionLike most other big corporations today, IBM is in-terested in cost-effective, yet high-quality informa-tion dissemination.
Every year, many pages of on-line and printed documentation are produced.
Nomatter what part of the world the documentationis written in, it is normally first written in English,and then translated into all the other supported lan-guages.
IBM has developed a number of tools to helpwriters cope with this task of information develop-ment.In this paper, we describe EasyEnglish, a toolthat helps writers produce clearer and simpler Eng-lish by pointing out ambiguity and complexity.Where appropriate, EasyEnglish makes uggestionsfor rephrasings.
The EasyEnglish system can beviewed as a "grammar checker++", in that standardgrammar checking facilities uch as spell-checking,word count (sentence l ngth), and detection of pas-sive constructions are available in addition to thechecks for ambiguity.
Furthermore, facilities foruser-defined controlled vocabulary are available.
To-tally, there are currently about forty checks.EasyEnglish ispart of IBM's internal InformationDevelopment Workbench (IDWB), an SGML-baseddocument creation and document management sys-tem.
ArborText's Adept editor is used with IDWB 1EasyEnglish summarizes the problems encounteredin a given document by giving an overall rating, theClarity Indez (CI).
The CI has to be in a certainrange before the document can be accepted for pub-lication.EasyEnglish combines features from both stan-dard grammar checkers and Controlled Language(CL) compliance checkers with checks for structuralambiguity in a way that we believe is general enoughto be useful for any writer.., not just tec~hnical writ-ers.
It has been claimed that the restrictions foundin CLs mostly reflect the inadequacies of the MTsystems used in conjunction with CLs (Cl~mencin1996; van der Eijk et al 1996; Hayes et al 1996).
Itis certainly the case that preprocessing a documentwith the same parser that is used for source analysisimproves the MT results.
EasyEnglish uses the sameparser as LMT (McCord 1989a, 1989b).
This offersan obvious advantage for MT results.
Other MT sys-tems, including the KANT system (Mitamura ndNyberg 1995; Nyberg and Mitamura 1996), see theadvantage of this.
However, we claim that a docu-ment that has been "EasyEnglished" is also easierto understand for native speakers as well as non-native speakers of English.
A similar point has beenmade for Caterpillar Technical English (Hayes ct al.1996).
We think, however, that our approach ismoregeneral because our use of a broad-coverage, geaeralEnglish grammar 2 allows us to go beyond the con-cept of CL to look for more general types of ambi-guities.I EasyEnglish also works with the XEDIT editor onVM and the EPM editor on OS/2.
An earlier versionof EasyEnglish was written in Prolog; however, the cur-rent version is written in pure ANSI C, and hence thequestion of platform is mainly a matter of supplying anappropriate ditor interface.~English Slot Grammar (McCord 1980, 1990, 1993)1592 Control led Language Checker orGrammar  Checker?The emphasis of a CL compliance checker is onensuring that the input text (document) conformsto the restrictions imposed by the definition of theCL, whereas the emphasis of a standard grammarchecker is on ensuring that the text is not ungram-matical.
Controlled Languages have been inventedto solve the problems associated with readability andtranslatability, with slight regard to ensuring gram-maticality.
In fact, the point has been made that itis up to the writer to ensure that the text is gram-matical (Hayes et al 1996).
Or, in the words of Goy-vaerts (1996): " ... it is still possible to write con-trolled non-English."
A similar point has been madefor GIFAS Rationalized French (Lux and Dauphin1996).However, the more grammatical the text is, theeasier it is to read and translate, so it seems thatthis concept of a CL checker is too narrow.
On theother hand, in many applications it may not be nec-essary for writers to restrict themselves to a verylimited subset of English in order to write easily un-derstandable and translatable documents.
In thissense the concept of a CL checker may be too broad.We have developed a system that we believestrikes a useful balance between CL checking andstandard grammar checking.
It consists in restrict-ing the CL checking to the detection of structural(syntactic) ambiguity, complexity, and violations ofvocabulary constraints.
This view is in line with thedescription of Dokamentationsdea~sch in (Schachtl1996).
Dokumentationsdeutsch is not defined by alist of allowed constructions, but rather by a list offorbidden constructions, allowing most of standardGerman syntax.
In the same way, EasyEnglish al-lows most of standard English syntax.
Also (Luxand Dauphin 1996) point out the importance of thelinguistic coverage being as broad as possible.
Atthe same time, we perform some of the checks thata standard grammar checker would perform.
3The CL checks of EasyEnglish do work betterwhen the text is not too ill-formed grammatically,since ill-formedness reduces the chances of the parsermaking good sense of the input.
Most grammarcheckers eem to have a problem with precision, 4and this evidently stems from the inability of thesystem to make sense of the input.
This is causednot only by too narrow coverage of the parser, butalso by the ill-formed input that a standard gram-3We have conflated the notions of grammar errors andstyle tveaknesses.
For a good discussion of the differences,see (Ravin 1993).4We define precision to be the number of relevant er-ror reports divided by the total number of error reports.In other words, it is a measure of how many irrelevanterror reports the user will be bothered with.
The higherthe precision, the better.mar checker tries to deal with; it is harder to parsenon-standard constructions correctly.
It has beenpointed out time and again (Richardson and Braden-Harder 1993; Wojcik and Holmback 1996; Cl6mencin1996) that user acceptance depends on suitably highprecision.
Of course, the user also wants the checkerto find the problems that need to be corrected, 5but this seems to take much lower precedence (Wo-jcik and Holmback 1996; C16mencin 1996).We have made a small, preliminary study compar-ing the quality of EasyEnglish with that of Gram-matik and the grammar checker in AmiPro.
Forthe study, we used a variety of text types, includingtechnical documents, a manager's speech, and an on-line job advertisement written by a non-native Eng-lish speaker.
The (Precision, Recall) figures were:EasyEnglish (0.81, 0.87), Grammatik (0.51, 0.86),AmiPro (0.50, 0.69).
There is overlap in the kindsof checks made by these three systems, but we at-tempted to evaluate ach system on its own terms,i.e.
on the basis of the collection of checks that it.tries to do.
That is, these figures show how we\[ieach system does what it tries to do, rather thanhow useful what it tries to do is.
(The recall fig-ures for Grammatik and AmiPro may be artificiallyhigh, since we may not have been able to identify allthe problems that these grammar checkers intend toaddress.
)Of course, high precision and recall alone are notenough to ensure the usefulness of an authoring toolsuch as EasyEnglish.
We agree with (Adriaens andMacken 1995; Wojcik and Holmbach 1996) that it isalso necessary to evaluate how well writers can usethe system to arrive at a satisfactory document.
Itis our claim that the types of checks EasyEnglishperforms are vastly more relevant for ensuring highdocument quality than a majority of the checks inthe above-mentioned grammar checkers (e.g.
mostof the lexically-based checks).
It has been claimedthat standard grammar checkers typically check forstylistic issues that are relevant for writers of fic-tion (Goyvaerts 1996).
But, as Goyvaerts (1996)puts it: "Industry does not need Shakespeare orChaucer, industry needs clear, concise communca-rive writing - -  in one word Controlled Language.
"Of course, standard grammar checkers do also tryto supply checks that are relevant for non-fictionalgenres.
However, some of the standard stylistic rec-ommendations are not entirely relevant for technicaldocuments at least.
It is, for example, rather com-mon for a standard grammar checker to discouragerepetition.
For a company that has to pay for doc-ument translation on a per word basis, every repeti-5We will use the term recall to mean the number ofrelevant problems found divided by the number uf allproblems occurring in the text.
Recall thus describeshow good the checker is at identifying the problems.
Thehigher the recall, the better.1 60tion means a savings.3 Reso lu t ion  o f  Ambigu i tyEasyEnglish identifies a number of structurally am-biguous constructions and supplies suggestions forunambiguous rephrasings.
It is then up to the userto decide which interpretation is intended.
Somesystems support automatic substitution; since wedeal with truly ambiguous constructions, we have toinvolve the user in making the choice.
The EasyEng-lish editor interface, however, does allow the userto select an offered rephrasing by mouse-clickingand have the selection substituted automatically.Other systems, e.g.
the Attempto System (Fuchs andSchwitter 1996), present he user with a rephrasingthat illustrates which interpretation the system ar-rived at.
If that interpretation is not the desired one,it is up to the user to construct a rephrasing that willresult in the desired interpretation.
We think it ismore user-friendly to show the user exactly how theconstruction may be ambiguous and let her makeher own choice.In order for the disambiguation rules to workproperly, it is crucial to have a deep analysis of thetext.
This deep analysis is provided by English SlotGrammar (ESG) (McCord 1980, 1990, 1993) in theform of parse trees expressed as a network struc-ture.
The disambiguation rules explore the networkto spot ambiguous and potentially ambiguous con-structions.ESG often provides more than one parse, rankedaccording to a specific numerical ranking system(McCord 1990, 1993).
But, unlike some other sys-tems, e.g.
the Boeing Simplified English Checker(Wojcik and Holmback 1996), which look at a wholeforest of trees, it is only necessary for EasyEnglishto look at the highest-ranked parse.
ESG parsingheuristics often arrive at correct attachments in thehighest-ranked parse.
But even when the attach-ment is off, EasyEnglish can often point out otherattachment possibilities to the writer.
For exam-pie, if a present participial clause is attached to theobject of a verb, there will also be the possibilitythat the participial clause actually should modifythe subject instead.
However, it is not necessaryfor the parse to reflect this, since this can be re-flected in the EasyEnglish rule instead.
A simplisticview of this rule would be: "If a present participialclause modifies the object, suggest wo rephrasings,one that forces the attachment to the subject, andone that forces the attachment to the object".An example taken from an IBM manual: "Differ-ent system users may operate on different objectsusing the same application program.
"This sentence generates the following message:Ambiguous attachment of verb phrase: "us-ing the same application program".Who/what is "using the same applica-tion program", "Different system users" or"different objects" ?I f  "Different system users", a possiblerephrasing would be: "by using the sameapplication program";I f  "different objects", a possible rephrasingwould be: "different objects that use thesame application program".Notice the additional benefit we get from basingthe suggestion on a parse: the correct subject-verbagreement can be inferred for use in the suggestions.Coordination is another source of ambiguity, sincethe scope is not always clear.
One type of ambiguityoccurs when a conjoined noun phrase premodifies anoun, as in this example from an IBM manual:" It is the number defined in the file or result fielddefinition.
"The phrase "file or result field definition" is am-biguous in many ways, as is shown by the outputfrom EasyEnglish:Ambiguity in: "the file or result field defi-nition".
Possible rephrasings:'`the result field definition or the file" or"the file definition or the result field defin-ition" or"the file field definition or the result fielddefinition" or"the definition of the file or of the resultfield" or"the field definition of the file or of theresult"Another type of ambiguity in coordination con-cerns combinations of coordinating conjunctions, asillustrated by the following example: "The cat andthe rat or the mat sat.
"Ambiguous coordination; possible rephras-lags: "Either the cat and the rat or themat"  or"The cat and either the rat or the mat"The above cases illustrate constructions that aredefinitely ambiguous; however, some common prob-lems involve modification that may or may not becorrect, depending on domain knowledge, which wedo not attempt o make use of at present.For example, the implicit subject in a nonfiniteclause premodifying the main clause should be thesame as the subject of the main clause.
It is gener-ally not possible to tell, on the basis of syntax alone,whether the author has adhered to this rule.
But itis possible to alert the user to the potential problem.The following two examples illustrate the problem.The first example, taken from an IBM manual, isokay, whereas the second example, taken from (Led-erer 1989), is not okay.161= After signing on, the user has access to all ob-jects on the system.
"Potentially urrong modification: =signingon".
Okay if subject of "signing on" is "theuser":" As a baboon who grew up wild in the jungle, Irealized that Wiki had special nutritional needs.
"Potentially wrong modification; okay if "I"is "a baboon who grew up mild in thejungle".An earlier version of EasyEnglish, written in Pro-log, included a pronoun resolution module, RAP(Lappin and McCord 1990a,b; Lappin and Leass1994).
This module, originally written for use withLMT, was modified slightly to point out ambiguouspronominal references.
It has not yet been includedin the C version of EasyEnglish, and we give herean example of its use produced by the Prolog ver-sion.
The example is taken from (Lederer 1989):=Guilt, vengeance, and bitterness can be emotion-ally destructive to you and your children.
You mustget rid of them.
"This generates the following message:Ambiguous pronoun reference: '2hem".4 Vocabu lary  Funct ionsEasyEnglish comes with a built-in general Englishdictionary of about 80,000 words.
In addition,EasyEnglish has a flexible system for using dictio-naries as it does its analysis.
Users can specify in auser profile which dictionaries they want to call up.The specification can include any number of termdictionaries, any number of abbreviation dictionar-ies, any number of non-allowed word dictionaries,and any number of controlled vocabulary dictionar-ies.
There are EasyEnglish commands for compilinga user-maintainable format of these different kindsof dictionaries into efficiently useable forms, and forcreating abbreviation dictionaries from terminologydictionaries in maintainance form.The dictionaries upport three different ypes ofvocabulary checks.
The first vocabulary check looksfor restricted words, i.e.
words that the writer ei-ther should never use, or that the writer should onlyuse as certain parts-of-speech.
The user may spec-ify these words in a specific user dictionary alongwith preferred alternatives.
In addition, this cate-gory includes slang words, a list of which is system-supplied.
The second type of vocabulary check iden-tifies acronyms or abbreviations in the text andchecks to see that the first occurrence is properlyspelled out according to the definition supplied inthe user dictionary for" acronyms.
The third checkgives the user the option to specify a controlled vo-cabulary; all words that are not in the controlled-vocabulary file or that are improperly used with re-spect to part-of-speech will be flagged, should theuser decide to turn this check on.
User dictionariesfor restricted words, acronyms, and controlled vo-cabulary have been built for the IDWB for certaindomains.The vocabulary checks rely on two things: theparser and user dictionaries.
It is crucial to be ableto determine the applicable part of speech with ac-curacy.
Take for example the word "beef".
If thisis used as a verb ("they beef a lot"), it should beflagged as slang; on the other hand, if it is used asa noun ("he ate beef"), it should not be flagged.
Afull parse helps decide on this.User dictionaries may be built with the help of theseparate terms module, ETerms, which is run inde-pendently of EasyEnglish.
ETerms identifies candi-dates for new terms by looking for words not found inany of the dictionaries 6 as well as multinoun terms.The output from ETerms is very accurate due tothe use of full ESG parsing.
For each term, the fre-quency is stated, and the user has the choice be-tween having the terms sorted either in frequencyorder or alphabetical order.
The terms file has aformat that is directly usable as a user dictionary;however, to keep terminology consistent and removemisspellings, it is necessary that a terminologist ap-prove the content before actual use.The terms file may also be sent to the IBM trans-lation centers at an early stage.
This speeds up thetask of translation considerably, since their terminol-ogists can decide on the proper translations beforethe translators actually start the translation process.This list is also a good start on an online bilingualdictionary for an MT system.5 Standard  Grammar  Check ingIn addition to spotting ambiguity and providingterminological support, EasyEnglish also performsmore traditional grammar checking.
It is a deli-cate balance to process text that has grammaticalerrors; the parser needs to be able to make reason-ably good sense of the text in order for the checkingcomponent not to overflag problems.
The grammat-ical checks fall into three different categories, whichwe will treat separately: Syntactic problems, lexicalproblems, and punctuation problems.5.1 Syntact ic  problemsThis category is obviously the category most sensi-tive to parsing problems.
However, we have foundthat a number of checks can be implemented success-fully, including, but not limited to, checks for lackof parallelism in coordination and in list elements,passives, double negatives, long sentences, incom-plete sentences, wrong pronoun case, and long nounstrings.6Since these could also be misspellings, they are alsoflagged by EasyEnglish itself.162To illustrate the function of these checks, let uslook at the checks for passives.
When a passiveconstruction is encountered, an active transforma-tion provides the desired suggested rephrasing, pro-vided the logical subject is available.
If the logicalsubject is not available, the passive is pointed out,but no rephrasing is offered.
Some standard gram-mar checkers insist on supplying an active rephrasingeven in this case, and they do that by introducing afake subject 'T',  "they", or "he".
In our view, thisrarely provides a reasonable i phrasing.The following sentence from an IBM manual illus-trates both cases: "The format is defined in the filewhich was not included by the header file.
"This sentence generates two messages for the pas-sives, one without a rephrasing, and one with arephrasing:Passive construction: ~is defined in the filewhich was not included by the header file".Passive construction: "was not includedby the header file".
Possible rephrasing:"which the header file did not include"The parse supplies the information ecessary todecide on the correct word order and tense used inthe rephrasing.In the case of a double passive, there is the ad-ditional problem of ambiguity, as illustrated by thefollowing example from (Lederer 1989): "Two carswere reported stolen by the Groveton police yester-day."
7Ambiguous passive construction.
Is thesubject of "s~olen': '2he Groveton police"fIn contrast o this group of syntactic problems, acheck for subject-verb agreement is much harder toimplement reliably.
This is due to the ambiguity ofpart-of-speech t at is so prevalent in English.
Manyverbs can also be nouns and vice versa.
When therethen is a mistake in subject-verb agreement, it be-comes very hard to produce a reliable parse.
(We areassuming a strictly syntactic approach).
Standardgrammar checkers eem to have even worse prob-lems with this check (on the order of a precision ofless than 10 percent).5.2 Lexical  P rob lemsLexical problems, on the other hand, are not verymuch affected by bad parses and can be spotted witha high degree of reliability.
These include misspelledor unknown words, duplicated words, and the like.5.3 Punctuat ionUsing a full parse, EasyEnglish is able to spot a vari-ety of punctuation errors, including, but not limitedto, missing commas i l l  conjoined clauses and noun7This sentence is actually ambiguous in many ways;here, we shall not address the other ambiguities.phrases, comma splices, missing hyphens, missingpunctuation at the end of a segment, and questionswith a final period instead of a question mark.6 The  Use  o f  Format t ing  TagsEasyEnglish works with SGML, Bookmaster, or IP\[,'formats as well as with plain text.
Dealing withformatting tags is a necessary, but rather complex,task, which is often underestimated (as pointed outby Cl~mencin (1996)).
But the trouble of buildinga good tag-handling system is well-rewarded.
For-matting tags are of great help in the segmentationprocess and may be enlisted for identifying condi-tions such as missing periods (or other sentence de-limiters) and lack of parallelism in lists, both ofwhich are handled by EasyEnglish.
It is also usefulto be able to identify tables and displays, therebyallowing differential treatment of them.
Further-more, it can be helpful for the parser to take thetags into account, especially quote and highlightingtags, which may delimit complete phrases; headertags can influence the parser to prefer noun phraseanalyses over sentence analysis.Another, very important, use of formatting tags ischecking of revised text only.
The so-called reviswntags indicate revisions to earlier versions of the d,,e-ument.
Being able to properly identify revised partsmeans that the user can elect to check only revisedparts.
This is a great time saver, considering theextensive use of previously written documents in atechnical environment (Means and Godden 1996).7 ConclusionOne of our greatest concerns has been to provide asystem that is both useful and acceptable to the user.We have addressed this issue on four fronts: Highprecision, generality of the problem types EasyEng-lish is able to identify, customizability, and user-friendly interfaces.
High precision is attained bythe use of a high-quality, robust, broad coveragegrammar (ESG) that delivers dependably consistentparses with great detail.
Generality is attained byaddressing enerally ambiguous constructions ratherthan restricting ourselves to a specific CL.
This way,the user does not have to learn a CL, either, whichcan be a quite difficult task (Wojcik and Holmback1996; van der Eijk et al 1996; Douglas and Hurst1996; Ooyvaerts 1996).
Customizability is attainedby allowing the user to specify in a user profile whichchecks should be applied, as well as which user dic-tionaries should be used.
User-friendliness i at-tained by integrating EasyEnglish with suitable dit-ing environments in such a way as to make changeseasy, and to keep the EasyEnglish information up-to-date with these changes.
Error statistics are co,-stantly updated as the user corrects mistakes, sothat once a mistake is corrected the user will notbe bothered with it again.163Judging from the feedback from our users, thisapproach seems to have paid off.
Users generally ex-press enthusiasm about using EasyEnglish, and theIBM translation centers have reported that they findthe =EasyEnglished" ocuments easier to deal with.This is informal evidence that our goal of easing thetask of translation has been accomplished; however,we still need to make formal studies to be able toquantify the exact savings.8 AcknowledgementsI would like to thank the following persons for contri-butions to EasyEnglish and to this paper: MichaelMcCord of IBM Research for use of his ESG gram-mar and parser, for contributing ideas to the designand implementation, for extensive work on the lex-icons and lexical utilities, and for commenting onthis paper; Andrew Tanabe of the IBM AS/400 Di-vision for contributing ideas for some of the rules,for coordinating users and user input, for extensivetesting, and for his role in incorporating EasyEng-lish in IDWB; Sue Medeiros of IBM Research forreading and commenting on this paper.Re ferencesG.
Adrisens and L. Macken.
1995.
Technologi-cal Evaluation of a Controlled Language Appli-cation: Precision, Recall, and Convergence Testsfor SECC.
In Proceedings of the 6th InternationalConference on Theoretical and Methodological Is-sues in Machine Translation, pp.
123-141, Leu-yen, Belgium.G.
Cl~mencin.
1996.
Integration of a CL-Checkerin an Operational SGML Authoring Environ-ment.
In Proceedings of The First InternationalWorkshop On Controlled Language Applications,Katholieke Universiteit Leuven, pp.
32-40, Bel-gium.S.
Douglas and M. Hurst.
1996.
Controlled Lan-guage Support for Perkins Approved Clear Eng-lish.
In Proceedings of The First InternationalWorkshop On Controlled Language Applications,Katholieke Universiteit Leuven, pp.
93-105, Bel-gium.N.
E. Fuchs and R. Schwitter.
1996.
Attempto Con-trolled English (ACE).
Proceedings of The FirstInternational Workshop On Controlled LanguageApplications, Katholieke Universiteit Leuven, pp.124-136, Belgium.P.
Goyvaerts.
1996.
Controlled English, Curseor Blessing?
A User's Perspective.
Proceedingsof The First International Workshop On Con-trolled Language Applications, Katholieke Univer-siteit Leuven, pp.
137-142, Belgium.P.
Hayes, S. Maxwell, and L. Schmandt.
1996.Controlled English Advantages for Translated andOriginal English Documents.
Proceedings of TheFirst International Workshop On Controlled Lan-guage Applications, Katholieke Universiteit Leu-yen, pp.
84-92, Belgium.S.
Lappin and H. Leass.
1994.
An Algorithm forPronominal Anaphora Resolution.
ComputationalLinguistics, vol.
20, pp.
535-561.S.
Lappin and M. C. McCord.
1990a.
A SyntacticFilter on Pronominal Anaphora for Slot Gram-mar.
Proceedings of the ~Sth Annual Meeting ofthe ACL, pp.
135-142.S.
Lappin and M. C. McCord.
1990b.
AnaphoraResolution in Slot Grammar.
Computational Lin-guistics, vol.
16, pp.
197-212.R.
Lederer.
1989.
Anguished English, Laurel Books,Dell Publishing.V.
Lux and E. Dauphin.
1996.
Corpus Studies:A Contribution to the Definition of a ControlledLanguage.
Proceedings of The First InternationalWorkshop On Controlled Language Applications,Katholieke Universiteit Leuven, pp.
193-204, Bel-gium.M.
C. McCord.
1980.
Slot Grammars.
Computa-tional Linguistics, vol.
6, pp.
31-43.M.
C. McCord.
1989a.
Design of LMT: A Prolog-based Machine Translation System.
Computa-tional Linguistics, vol.
15, pp.
33-52.M.
C. McCord.
1989b.
LMT.
Proceedings of MTSummit II, pp.
94-99, Deutsche Gesellschaft ffirDokumentation, Frankfurt.M.
C. McCord.
1990.
Slot Grammar: A Sys-tem for Simpler Construction of Practical NaturalLanguage Grammars.
In R. Studer, editor, Nat-ural Language and Logic: International ScientificSymposium, Lecture Notes in Computer Science,Springer Verlsg, Berlin, pp.
118-145.M.
C. McCord.
1993.
Heuristics for Broad-CoverageNatural Language Parsing.
Proceedings of theARPA Human Language Technology Workshop,Morgan-Kaufmann.L.
Means and K. Godden.
1996.
The ControlledAutomotive Service Language (CASL) Project.Proceedings of The First International WorkshopOn Controlled Language Applications, KatholiekeUniversiteit Leuven, pp.
106-114, Belgium.T.
Mitamura and E. H. Nyberg.
1995.
Con-trolled English for Knowledge-Based MT: Expe-rience with the KANT System.
Proceedings ofthe 6th International Conference on Theoreticalan Methodological Issues in Machine Translation,Leuven, Belgium.E.
H. Nyberg and T. Mitamura.
1996.
Con-trolled Language and Knowledge-Based Machine1 64Translation: Principles and Practice.
Proceedingsof The First International Workshop On Con-trolled Language Applications, Katholieke Univer-siteit Leuven, pp.
137-142, Belgium.Y.
Ravin.
1993.
Grammar Errors and Style Weak-nesses in a Text-Critiquing System.
In K. Jensen,G.
Heidorn, and S. Richardson, editors, NaturalLanguage Processing: The PNLP Approach, pp.65-76, Kluwer Academic Publishers, 1993.S.
Richardson and L. Braden-Harder.
1993.
The Ex-perience of Developing a Large-Scale Natural Lan-guage Processing System: Critique.
In K. Jensen,G.
Heidorn, and S. Richardson, editors, NaturalLanguage Processing: The PNLP Approach, pp.77-89, Kluwer Academic Publishers, 1993.S.
Schachtl.
1996.
Requirements for ControlledGerman in Industrial Applications.
Proceedingsof The First International Workshop On Con-trolled Language Applications, Katholieke Univer-siteit Leuven, pp.
143-149, Belgium.P.
van der Eijk, M. de Koning, and G. van derSteen.
1996.
Controlled Language Correction andTranslation.
Proceedings of The First Interna-tional Workshop On Controlled Language Appli-cations, Katholieke Universiteit Leuven, pp.
64-73, Belgium.R.
H. Wojcik and H. Holmback.
1996.
Getting aControlled Language Off the Ground at Boeing.Proceedings of The First International WorkshopOn Controlled Language Applications, KatholiekeUniversiteit Leuven, pp.
22-31, Belgium.165
