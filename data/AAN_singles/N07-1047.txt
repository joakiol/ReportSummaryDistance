Proceedings of NAACL HLT 2007, pages 372?379,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsApplying Many-to-Many Alignments and Hidden Markov Models toLetter-to-Phoneme ConversionSittichai Jiampojamarn, Grzegorz Kondrak and Tarek SherifDepartment of Computing Science,University of Alberta,Edmonton, AB, T6G 2E8, Canada{sj,kondrak,tarek}@cs.ualberta.caAbstractLetter-to-phoneme conversion generallyrequires aligned training data of lettersand phonemes.
Typically, the align-ments are limited to one-to-one align-ments.
We present a novel technique oftraining with many-to-many alignments.A letter chunking bigram prediction man-ages double letters and double phonemesautomatically as opposed to preprocess-ing with fixed lists.
We also applyan HMM method in conjunction witha local classification model to predict aglobal phoneme sequence given a word.The many-to-many alignments result insignificant improvements over the tradi-tional one-to-one approach.
Our systemachieves state-of-the-art performance onseveral languages and data sets.1 IntroductionLetter-to-phoneme (L2P) conversion requires a sys-tem to produce phonemes that correspond to a givenwritten word.
Phonemes are abstract representa-tions of how words should be pronounced in naturalspeech, while letters or graphemes are representa-tions of words in written language.
For example, thephonemes for the word phoenix are [ f i n I k s ].The L2P task is a crucial part of speech synthesissystems, as converting input text (graphemes) intophonemes is the first step in representing sounds.L2P conversion can also help improve performancein spelling correction (Toutanova and Moore, 2001).Unfortunately, proper nouns and unseen words pre-vent a table look-up approach.
It is infeasible to con-struct a lexical database that includes every word inthe written language.
Likewise, orthographic com-plexity of many languages prevents us from usinghand-designed conversion rules.
There are alwaysexceptional rules that need to be added to cover alarge vocabulary set.
Thus, an automatic L2P sys-tem is desirable.Many data-driven techniques have been proposedfor letter-to-phoneme conversion systems, includingpronunciation by analogy (Marchand and Damper,2000), constraint satisfaction (Van Den Bosch andCanisius, 2006), Hidden Markov Model (Taylor,2005), decision trees (Black et al, 1998), andneural networks (Sejnowski and Rosenberg, 1987).The training data usually consists of written wordsand their corresponding phonemes, which are notaligned; there is no explicit information indicatingindividual letter and phoneme relationships.
Theserelationships must be postulated before a predictionmodel can be trained.Previous work has generally assumed one-to-onealignment for simplicity (Daelemans and Bosch,1997; Black et al, 1998; Damper et al, 2005).An expectation maximization (EM) based algo-rithm (Dempster et al, 1977) is applied to train thealigners.
However, there are several problems withthis approach.
Letter strings and phoneme stringsare not typically the same length, so null phonemesand null letters must be introduced to make one-to-one-alignments possible, Furthermore, two lettersfrequently combine to produce a single phoneme372(double letters), and a single letter can sometimesproduce two phonemes (double phonemes).To help address these problems, we propose anautomatic many-to-many aligner and incorporate itinto a generic classification predictor for letter-to-phoneme conversion.
Our many-to-many alignerautomatically discovers double phonemes and dou-ble letters, as opposed to manually preprocessingdata by merging phonemes using fixed lists.
To ourknowledge, applying many-to-many alignments toletter-to-phoneme conversion is novel.Once we have our many-to-many alignments, weuse that data to train a prediction model.
Manyphoneme prediction systems are based on local pre-diction methods, which focus on predicting an indi-vidual phoneme given each letter in a word.
Con-versely, a method like pronunciation by analogy(PbA) (Marchand and Damper, 2000) is considereda global prediction method: predicted phoneme se-quences are considered as a whole.
Recently, VanDen Bosch and Canisius (2006) proposed trigramclass prediction, which incorporates a constraint sat-isfaction method to produce a global prediction forletter-to-phoneme conversion.
Both PbA and tri-gram class prediction show improvement over pre-dicting individual phonemes, confirming that L2Psystems can benefit from incorporating the relation-ship between phonemes in a sequence.In order to capitalize on the information foundin phoneme sequences, we propose to apply anHMM method after a local phoneme prediction pro-cess.
Given a candidate list of two or more possiblephonemes, as produced by the local predictor, theHMM will find the best phoneme sequence.
Usingthis approach, our system demonstrates an improve-ment on several language data sets.The rest of the paper is structured as follows.We describe the letter-phoneme alignment methodsincluding a standard one-to-one alignment methodand our many-to-many approach in Section 2.
Thealignment methods are used to align graphemesand phonemes before the phoneme prediction mod-els can be trained from the training examples.
InSection 3, we present a letter chunk predictionmethod that automatically discovers double lettersin grapheme sequences.
It incorporates our many-to-many alignments with prediction models.
InSection 4, we present our application of an HMMmethod to the local prediction results.
The resultsof experiments on several language data sets are dis-cussed in Section 5.
We conclude and propose futurework in Section 6.2 Letter-phoneme alignment2.1 One-to-one alignmentThere are two main problems with one-to-one align-ments:1.
Double letters: two letters map to one phoneme(e.g.
sh - [ S ], ph - [ f ]).2.
Double phonemes: one letter maps to twophonemes (e.g.
x - [ k s ], u - [ j u ]).First, consider the double letter problem.
In mostcases when the grapheme sequence is longer thanthe phoneme sequence, it is because some letters aresilent.
For example, in the word abode, pronounced[ @ b o d ], the letter e produces a null phoneme (?
).This is well captured by one-to-one aligners.
How-ever, the longer grapheme sequence can also be gen-erated by double letters; for example, in the wordking, pronounced [ k I N ], the letters ng togetherproduce the phoneme [ N ].
In this case, one-to-onealigners using null phonemes will produce an in-correct alignment.
This can cause problems for thephoneme prediction model by training it to producea null phoneme from either of the letters n or g.In the double phoneme case, a new phoneme isintroduced to represent a combination of two (ormore) phonemes.
For example, in the word fumewith phoneme sequence [ f j u m ], the letter u pro-duces both the [ j ] and [ u ] phonemes.
Thereare two possible solutions for constructing a one-to-one alignment in this case.
The first is to cre-ate a new phoneme by merging the phonemes [ j ]and [ u ].
This requires constructing a fixed list ofnew phonemes before beginning the alignment pro-cess.
The second solution is to add a null letter inthe grapheme sequence.
However, the null letter notonly confuses the phoneme prediction model, butalso complicates the the phoneme generation phase.For comparison with our many-to-many ap-proach, we implement a one-to-one aligner based onthe epsilon scattering method (Black et al, 1998).The method applies the EM algorithm to estimate373Algorithm 1: Pseudocode for a many-to-manyexpectation-maximization algorithm.Algorithm:EM-many2manyInput: xT , yV ,maxX,maxYOutput: ?forall mapping operations z do?
(z) := 0foreach sequence pair (xT , yV ) doExpectation-many2many(xT , yV ,maxX,maxY, ?)Maximization-Step(?
)the probability of mapping a letter l to a phonemep, P (l, p).
The initial probability table starts bymapping all possible alignments between letters andphonemes for each word in the training data, in-troducing all possible null phoneme positions.
Forexample, the word/phoneme-sequence pair abode[ @ b o d ] has five possible positions where a nullphoneme can be added to make an alignment.The training process uses the initial probability ta-ble P (l, p) to find the best possible alignments foreach word using the Dynamic Time Warping (DTW)algorithm (Sankoff and Kruskal, 1999).
At each it-eration, the probability table P (l, p) is re-calculatedbased on the best alignments found in that iteration.Finding the best alignments and re-calculating theprobability table continues iteratively until there isno change in the probability table.
The final proba-bility table P (l, p) is used to find one-to-one align-ments given graphemes and phonemes.2.2 Many-to-Many alignmentWe present a many-to-many alignment algorithmthat overcomes the limitations of one-to-one align-ers.
The training of the many-to-many aligner isan extension of the forward-backward training of aone-to-one stochastic transducer presented in (Ris-tad and Yianilos, 1998).
Partial counts are counts ofall possible mappings from letters to phonemes thatare collected in the ?
table, while mapping probabil-ities (initially uniform) are maintained in the ?
table.For each grapheme-/phoneme-sequence pair (x, y),the EM-many2many function (Algorithm 1) calls theExpectation-many2many function (Algorithm 2) tocollect partial counts.
T and V are the lengths of xand y respectively.
The maxX and maxY variablesare the maximum lengths of subsequences used ina single mapping operation for x and y.
(For theAlgorithm 2: Pseudocode for a many-to-manyexpectation algorithm.Algorithm:Expectation-many2manyInput: xT , yV ,maxX,maxY, ?Output: ??
:= Forward-many2many (xT , yV ,maxX,maxY )?
:= Backward-many2many (xT , yV ,maxX,maxY )if (?T,V = 0) thenreturnfor t = 0...T dofor v = 0...V doif (t > 0 ?DELX) thenfor i = 1...maxX st t?
i ?
0 do?
(xtt?i+1, ?
)+ =?t?i,v?(xtt?i+1,?
)?t,v?T,Vif (v > 0 ?DELY ) thenfor j = 1...maxY st v ?
j ?
0 do?
(?, yvv?j+1)+ =?t,v?j?
(?,yvv?j+1)?t,v?T,Vif (v > 0 ?
t > 0) thenfor i = 1...maxX st t?
i ?
0 dofor j = 1...maxY st v ?
j ?
0 do?
(xtt?i+1, yvv?j+1)+ =?t?i,v?j?
(xtt?i+1,yvv?j+1)?t,v?T,Vtask at hand, we set both maxX and maxY to 2.
)The Maximization-step function simply normalizesthe partial counts to create a probability distribution.Normalization can be done over the whole table tocreate a joint distribution or per grapheme to createa conditional distribution.The Forward-many2many function (Algorithm 3)fills in the table ?, with each entry ?
(t, v) being thesum of all paths through the transducer that gen-erate the sequence pair (xt1, yv1).
Analogously, theBackward-many2many function fills in ?, with eachentry ?
(t, v) being the sum of all paths through thetransducer that generate the sequence pair (xTt , yVv ).The constants DELX and DELY indicate whetheror not deletions are allowed on either side.
In oursystem, we allow letter deletions (i.e.
mapping ofletters to null phoneme), but not phoneme deletions.Expectation-many2many first calls the two func-tions to fill the ?
and ?
tables, and then uses theprobabilities to calculate partial counts for everypossible mapping in the sequence pair.
The par-tial count collected at positions t and v in the se-quence pair is the sum of all paths that generate thesequence pair and go through (t, v), divided by thesum of all paths that generate the entire sequencepair (?
(T, V )).Once the probabilities are learned, the Viterbi374Algorithm 3: Pseudocode for a many-to-manyforward algorithm.Algorithm:Forward-many2manyInput: (xT , yV ,maxX,maxY )Output: ?
?0,0 := 1for t = 0...T dofor v = 0...V doif (t > 0 ?
v > 0) then?t,v = 0if (t > 0 ?DELX) thenfor i = 1...maxX st t?
i ?
0 do?t,v+ = ?
(xtt?i+1, ?
)?t?i,vif (v > 0 ?DELY ) thenfor j = 1...maxY st v ?
j ?
0 do?t,v+ = ?
(?, yvv?j+1)?t,v?jif (v > 0 ?
t > 0) thenfor i = 1...maxX st t?
i ?
0 dofor j = 1...maxY st v ?
j ?
0 do?t,v+ = ?
(xtt?i+1, yvv?j+1)?t?i,v?jalgorithm can be used to produce the most likelyalignment as in the following equations.
Back point-ers to maximizing arguments are kept at each step sothe alignment can be reconstructed.?
(0, 0) = 1 (1)?
(t, v) = max1?i?maxX,1?j?maxY8<:?
(xtt?i+1, ?)?t?i,v?
(?, yvv?j+1)?t,v?j?
(xtt?i+1, yvv?j+1)?t?i,v?j(2)Given a set of words and their phonemes, align-ments are made across graphemes and phonemes.For example, the word phoenix, with phonemes [ f in I k s ], is aligned as:ph oe n i x| | | | |f i n I ksThe letters ph are an example of the double let-ter problem (mapping to the single phoneme [ f ]),while the letter x is an example of the doublephoneme problem (mapping to both [ k ] and [ s ]in the phoneme sequence).
These alignments pro-vide more accurate grapheme-to-phoneme relation-ships for a phoneme prediction model.3 Letter chunkingOur new alignment scheme provides more accu-rate alignments, but it is also more complex ?sometimes a prediction model should predict twophonemes for a single letter, while at other timesthe prediction model should make a prediction basedon a pair of letters.
In order to distinguish betweenthese two cases, we propose a method called ?letterchunking?.Once many-to-many alignments are built acrossgraphemes and phonemes, each word contains a setof letter chunks, each consisting of one or two let-ters aligned with phonemes.
Each letter chunk canbe considered as a grapheme unit that contains eitherone or two letters.
In the same way, each phonemechunk can be considered as a phoneme unit consist-ing of one or two phonemes.
Note that the doubleletters and double phonemes are implicitly discov-ered by the alignments of graphemes and phonemes.They are not necessarily consistent over the train-ing data but based on the alignments found in eachword.In the phoneme generation phase, the system hasonly graphemes available to predict phonemes, sothere is no information about letter chunk bound-aries.
We cannot simply merge any two letters thathave appeared as a letter chunk in the training data.For example, although the letter pair sh is usuallypronounced as a single phoneme in English (e.g.gash [ g ae S ]), this is not true universally (e.g.gasholder [ g ae s h o l d @ r ]).
Therefore, we im-plement a letter chunk prediction model to providechunk boundaries given only graphemes.In our system, a bigram letter chunking predic-tion automatically discovers double letters based oninstance-based learning (Aha et al, 1991).
Since themany-to-many alignments are drawn from 1-0, 1-1,1-2, 2-0, and 2-1 relationships, each letter in a wordcan form a chunk with its neighbor or stand aloneas a chunk itself.
We treat the chunk prediction asa binary classification problem.
We generate all thebigrams in a word and determine whether each bi-gram should be a chunk based on its context.
Table 1shows an example of how chunking prediction pro-ceeds for the word longs.
Letters li?2, li?1, li+1, andli+2 are the context of the bigram li; chunk = 1 ifthe letter bigram li is a chunk.
Otherwise, the chunksimply consists of an individual letter.
In the exam-ple, the word is decomposed as l|o|ng|s, which canbe aligned with its pronunciation [ l | 6 | N | z ].
Ifthe model happens to predict consecutive overlap-ping chunks, only the first of the two is accepted.375li?2 li?1 li li+1 li+2 chunklo n g 0l on g s 0l o ng s 1o n gs 0Table 1: An example of letter chunking prediction.4 Phoneme predictionMost of the previously proposed techniques forphoneme prediction require training data to bealigned in one-to-one alignments.
Those modelsapproach the phoneme prediction task as a classi-fication problem: a phoneme is predicted for eachletter independently without using other predictionsfrom the same word.
These local predictions assumeindependence of predictions, even though there areclearly interdependencies between predictions.
Pre-dicting each phoneme in a word without consideringother assignments may not satisfy the main goal offinding a set of phonemes that work together to forma word.A trigram phoneme prediction with constraint sat-isfaction inference (Van Den Bosch and Canisius,2006) was proposed to improve on local predictions.From each letter unit, it predicts a trigram class thathas the target phoneme in the middle surrounded byits neighboring phonemes.
The phoneme sequenceis generated in such a way that it satisfies the tri-gram, bigram and unigram constraints.
The over-lapping predictions improve letter-to-phoneme per-formance mainly by repairing imperfect one-to-onealignments.However, the trigram class prediction tends to bemore complex as it increases the number of tar-get classes.
For English, there are only 58 uni-gram phoneme classes but 13,005 tri-gram phonemeclasses.
The phoneme combinations in the tri-gramclasses are potentially confusing to the predictionmodel because the model has more target classes inits search space while it has access to the same num-ber of local features in the grapheme side.We propose to apply a supervised HMM methodembedded with local classification to find the mostlikely sequence of phonemes given a word.
AnHMM is a statistical model that combines the obser-vation likelihood (probability of phonemes given let-ters) and transition likelihood (probability of currentphoneme given previous phonemes) to predict eachphoneme.
Our approach differs from a basic HiddenMarkov Model for letter-to-phoneme system (Tay-lor, 2005) that formulates grapheme sequences asobservation states and phonemes as hidden states.The basic HMM system for L2P does not providegood performance on the task because it lacks con-text information on the grapheme side.
In fact, apronunciation depends more on graphemes than onthe neighboring phonemes; therefore, the transitionprobability (language model) should affect the pre-diction decisions only when there is more than onepossible phoneme that can be assigned to a letter.Our approach is to use an instance-based learn-ing technique as a local predictor to generate a setof phoneme candidates for each letter chunk, givenits context in a word.
The local predictor producesconfidence values for Each candidate phoneme.
Wenormalize the confidence values into values between0 and 1, and treat them as the emission probabilities,while the transition probabilities are derived directlyfrom the phoneme sequences in the training data.The pronunciation is generated by consideringboth phoneme prediction values and transition prob-abilities.
The optimal phoneme sequence is foundwith the Viterbi search algorithm.
We limit the sizeof the context to n = 3 in order to avoid over-fitting and minimize the complexity of the model.Since the candidate set is from the classifier, thesearch space is limited to a small number of can-didate phonemes (1 to 5 phonemes in most cases).The HMM postprocessing is independent of localpredictions from the classifier.
Instead, it selects thebest phoneme sequence from a set of possible lo-cal predictions by taking advantage of the phonemelanguage model, which is trained on the phonemesequences in the training data.5 EvaluationWe evaluated our approaches on CMUDict, Brulex,and German, Dutch and English Celex cor-pora (Baayen et al, 1996).
The corpora (exceptEnglish Celex) are available as part of the Letter-to-Phoneme Conversion PRONALSYL Challenge1.1The PRONALSYL Challenge: http://www.pascal-network.org/Challenges/PRONALSYL/.376Language Data set Number of wordsEnglish CMUDict 112,102English Celex 65,936Dutch Celex 116,252German Celex 49,421French Brulex 27,473Table 2: Number of words in each data set.For the English Celex data, we removed duplicatewords as well as words shorter than four letters.
Ta-ble 2 shows the number of words and the languageof each corpus.For all of our experiments, our local classifierfor predicting phonemes is the instance-based learn-ing IB1 algorithm (Aha et al, 1991) implementedin the TiMBL package (Daelemans et al, 2004).The HMM technique is applied as post process-ing to the instance-based learning to provide a se-quence prediction.
In addition to comparing one-to-one and many-to-many alignments, we also compareour method to the constraint satisfaction inferencemethod as described in Section 4.
The results arereported in word accuracy rate based on the 10-foldcross validation, with the mean and standard devia-tion values.Table 3 shows word accuracy performance acrossa variety of methods.
We show results comparingthe one-to-one aligner described in Section 2.1 andthe one-to-one aligner provided by the PRONAL-SYL challenge.
The PRONALSYS one-to-onealignments are taken directly from the PRONAL-SYL challenge, whose method is based on an EMalgorithm.
For both alignments, we use instance-based learning as the prediction model.Overall, our one-to-one alignments outperformthe alignments provided by the data sets for all cor-pora.
The main difference between the PRONAL-SYS one-to-one alignment and our one-to-one align-ment is that our aligner does not allow a null letteron the grapheme side.
Consider the word abomina-tion [ @ b 6 m I n e S @ n ]: the first six letters andphonemes are aligned the same way by both align-ers (abomin- [ @ b 6 m I n ]).
However, the twoaligners produce radically different alignments forthe last five letters.
The alignment provided by thePRONALSYS one-to-one alignments is:a t i o n| | | | | | |e S @ nwhile our one-to-one alignment is:a t i o n| | | | |e S @ nClearly, the latter alignment provides more informa-tion on how the graphemes map to the phonemes.Table 3 also shows that impressive improvementsfor all evaluated corpora are achieved by usingmany-to-many alignments rather than one-to-onealignments (1-1 align vs. M-M align).
The signif-icant improvements, ranging from 2.7% to 7.6% inword accuracy, illustrate the importance of havingmore precise alignments.
For example, we can nowobtain the correct alignment for the second part ofthe word abomination:a ti o n| | | |e S @ nInstead of adding a null phoneme in the phonemesequence, the many-to-many aligner maps the letterchunk ti to a single phoneme.The HMM approach is based on the same hy-pothesis as the constraint satisfaction inference(CSInf) (Van Den Bosch and Canisius, 2006).
Theresults in Table 3 (1-1+CSInf vs. 1-1+HMM) showthat the HMM approach consistently improves per-formance over the baseline system (1-1 align), whilethe CSInf degrades performance on the Brulex dataset.
For the CSInf method, most errors are causedby trigram confusion in the prediction phase.The results of our best system, which combinesthe HMM method with the many-to-many align-ments (M-M+HMM), are better than the results re-ported in (Black et al, 1998) on both the CMU-Dict and German Celex data sets.
This is true eventhough Black et al (1998) use explicit lists of letter-phoneme mappings during the alignment process,while our approach is a fully automatic system thatdoes not require any handcrafted list.6 Conclusion and future workWe presented a novel technique of applying many-to-many alignments to the letter-to-phoneme conver-sion problem.
The many-to-many alignments relax377Language Data set PRONALSYS 1-1 align 1-1+CsInf 1-1+HMM M-M align M-M+HMMEnglish CMUDict 58.3?
0.49 60.3?
0.53 62.9?
0.45 62.1?
0.53 65.1?
0.60 65.6?
0.72English Celex ?
74.6?
0.80 77.8?
0.72 78.5?
0.76 82.2?
0.63 83.6?
0.63Dutch Celex 84.3?
0.34 86.6?
0.36 87.5?
0.32 87.6?
0.34 91.1?
0.27 91.4?
0.24German Celex 86.0?
0.40 86.6?
0.54 87.6?
0.47 87.6?
0.59 89.3?
0.53 89.8?
0.59French Brulex 86.3?
0.67 87.0?
0.38 86.5?
0.68 88.2?
0.39 90.6?
0.57 90.9?
0.45Table 3: Word accuracies achieved on data sets based on the 10-fold cross validation.
PRONALSYS: one-to-one alignments provided by the PRONALSYL challenge.
1-1 align: our one-to-one alignment methoddescribed in Section 2.1.
CsInf: Constraint satisfaction inference (Van Den Bosch and Canisius, 2006).M-M align: our many-to-many alignment method.
HMM: our HMM embedded with a local prediction.the constraint assumptions of the traditional one-to-one alignments.
Letter chunking bigram predictionincorporates many-to-many alignments into the con-ventional phoneme prediction models.
Finally, theHMM technique yields global phoneme predictionsbased on language models.Impressive word accuracy improvements areachieved when the many-to-many alignments are ap-plied over the baseline system.
On several languagesand data sets, using the many-to-many alignments,word accuracy improvements ranged from 2.7% to7.6%, as compared to one-to-one alignments.
TheHMM cooperating with the local predictions showsslight improvements when it is applied to the many-to-many alignments.
We illustrated that the HMMtechnique improves the word accuracy more con-sistently than the constraint-based approach.
More-over, the HMM can be easily incorporated into themany-to-many alignment approach.We are investigating the possibility of integrat-ing syllabification information into our system.
Ithas been reported that syllabification can poten-tially improve pronunciation performance in En-glish (Marchand and Damper, 2005).
We planto explore other sequence prediction approaches,such as discriminative training methods (Collins,2004), and sequence tagging with Support VectorMachines (SVM-HMM) (Altun et al, 2003) to in-corporate more features (context information) intothe phoneme generation model.
We are also inter-ested in applying our approach to other related areassuch as morphology and transliteration.AcknowledgementsWe would like to thank Susan Bartlett, Colin Cherry,and other members of the Natural Language Pro-cessing research group at University of Alberta fortheir helpful comments and suggestions.
This re-search was supported by the Natural Sciences andEngineering Research Council of Canada.ReferencesDavid W. Aha, Dennis Kibler, and Marc K. Albert.
1991.Instance-based learning algorithms.
Machine Learn-ing, 6(1):37?66.Yasemin Altun, Ioannis Tsochantaridis, and ThomasHofmann.
2003.
Hidden Markov Support Vector Ma-chines.
In Proceedings of the 20th International Con-ference on Machine Learning (ICML-2003).Harald Baayen, Richard Piepenbrock, and Leon Gulikers.1996.
The CELEX2 lexical database.
LDC96L14.Alan W. Black, Kevin Lenzo, and Vincent Pagel.
1998.Issues in building general letter to sound rules.
In TheThird ESCA Workshop in Speech Synthesis, pages 77?80.Michael Collins.
2004.
Discriminative training meth-ods for Hidden Markov Models: Theory and experi-ments with perceptron algorithms.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-gauge Processing (EMNLP).Walter Daelemans and Antal Van Den Bosch.
1997.Language-independent data-oriented grapheme-to-phoneme conversion.
In Progress in Speech Synthesis,pages 77?89.
Springer, New York.Walter Daelemans, Jakub Zavrel, Ko Van Der Sloot, andAntal Van Den Bosch.
2004.
TiMBL: Tilburg Mem-ory Based Learner, version 5.1, reference guide.
InILK Technical Report Series 04-02.Robert I. Damper, Yannick Marchand, John DS.Marsters, and Alexander I. Bazin.
2005.
Aligningtext and phonemes for speech technology applicationsusing an EM-like algorithm.
International Journal ofSpeech Technology, 8(2):147?160, June.378Arthur Dempster, Nan Laird, and Donald Rubin.
1977.Maximum likelihood from incomplete data via the EMalgorithm.
In Journal of the Royal Statistical Society,pages B:1?38.Yannick Marchand and Robert I. Damper.
2000.
Amultistrategy approach to improving pronunciation byanalogy.
Computational Linguistics, 26(2):195?219,June.Yannick Marchand and Robert I. Damper.
2005.
Cansyllabification improve pronunciation by analogy ofEnglish?
In Natural Language Engineering, pages(1):1?25.Eric Sven Ristad and Peter N. Yianilos.
1998.
Learn-ing string-edit distance.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 20(5):522?532.David Sankoff and Joseph Kruskal, 1999.
Time Warps,String Edits, and Macromolecules, chapter 2, pages55?91.
CSLI Publications.Terrence J. Sejnowski and Charles R. Rosenberg.
1987.Parallel networks that learn to pronounce English text.In Complex Systems, pages 1:145?168.Paul Taylor.
2005.
Hidden Markov Models for graphemeto phoneme conversion.
In Proceedings of the 9thEuropean Conference on Speech Communication andTechnology 2005.Kristina Toutanova and Robert C. Moore.
2001.
Pro-nunciation modeling for improved spelling correction.In ACL ?02: Proceedings of the 40th Annual Meetingon Association for Computational Linguistics, pages144?151, Morristown, NJ, USA.
Association for Com-putational Linguistics.Antal Van Den Bosch and Sander Canisius.
2006.Improved morpho-phonological sequence processingwith constraint satisfaction inference.
Proceedings ofthe Eighth Meeting of the ACL Special Interest Groupin Computational Phonology, SIGPHON ?06, pages41?49, June.379
