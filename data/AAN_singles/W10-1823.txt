Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 157?161,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsA Feature Type Classification for Therapeutic Purposes:a preliminary evaluation with non-expert speakersGianluca E. LebaniUniversity of Trentogianluca.lebani@unitn.itEmanuele PiantaFondazione Bruno Kesslerpianta@fbk.euAbstractWe propose a feature type classificationthought to be used in a therapeutic context.Such a scenario lays behind our need for aeasily usable and cognitively plausible classi-fication.
Nevertheless, our proposal has botha practical and a theoretical outcome, and itsapplications range from computational lin-guistics to psycholinguistics.
An evaluationthrough inter-coder agreement has been per-formed to highlight the strength of our pro-posal and to conceive some improvements forthe future.1 IntroductionMost common therapeutic practices for anomiarehabilitation rely either on the therapist?s intui-tive linguistic knowledge or on different kinds ofresources that have to be consulted manually(Semenza, 1999; Raymer and Gonzalez-Rothi,2002; Springer, 2008).
STaRS.sys (SemanticTask Rehabilitation Support system) is a toolthought for supporting the therapist in the prepa-ration of a semantic task (cfr.
Nickels, 2002).To be effective, such a system must lean on aknowledge base in which every concept is asso-ciated with different kinds of featural descrip-tions.
The notion of feature refers to the linguis-tic descriptions of a property that can be obtainedby asking a subject to describe a concept.
Exam-ples of concept-feature pairings will be repre-sented here as <concept> feature 1  couplessuch as <dog> has a tail or <dog> barks.1Typographical conventions: concepts, categories and fea-tures will be printed in italics courier new font.When reporting a concept-feature pair, the concept will befurther enclosed by <angled brackets>.
Feature typesand classes of types will be both reported in times roman,but while the formers will be written in italics, type classeswill be in SMALL CAPITALS.As a consequence of this scenario, an intuitiveand cognitively plausible classification of thefeature types that can be associated with a con-cept is a vital component of our tool.
In this pa-per, we present a classification that meets suchcriteria, built by moving from an analysis of therelevant proposals available in the literature.We evaluated our classification by asking to agroup of naive Italian speakers to annotate a testset by using our categories.
The resulting agree-ment has been interpreted both as an index ofreliability and as a measure of ease of learningand use by non-expert speakers.
In these prelimi-nary phases we focus on Italian, leaving to futureevaluations whether or how to extend the domainof our tool to other languages.These pages are organized as follows: in Sec-tion 2 we briefly review the relevant works forthe following discussion.
In Section 3 we intro-duce our classification and in the remaining partwe evaluate its reliability and usability.2 Related Works2.1 Feature NormsIn the psychological tradition, a collection of fea-ture norms is typically built by asking to a groupof speakers to generate short phrases (i.e.
fea-tures) to describe a given set of concepts.Even if normative data have been collectedand employed for addressing a wide range ofissues on the nature of the semantic memory, theonly freely available resources are, to our know-ledge, those by Garrard et al(2001), those byMcRae et al(2005), those by Vinson and Vig-liocco (2008), all in English, and the Dutchnorms available in the Leuven database (DeDeyne et al 2008).Moving out of the psychological domain, theonly collection built in the lexicographic tradi-tion is that by Kremer et al(2008), collectedfrom Italian and German speakers1572.2 Related ClassificationsThe proposals that constitute our theoreticalframework have been chosen for their being ei-ther implemented in an extensive semantic re-source, motivated by well specified theoreticalexplanations (on which there is consensus) oreffectively used in a specific therapeutic context.They have originated in research fields as distantas lexicography, theoretical linguistics, ontologybuilding, (clinical) neuropsychology and cogni-tive psychology.
Specifically, the works wemoved from have been:?
a type classification adopted for clinical pur-poses in the CIMeC?s Center for Neurocogni-tive Rehabilitation (personal communication);?
the knowledge-type taxonomy proposed byWu & Barsalou (2009), and the modified ver-sion adopted by Cree & McRae (2003);?
the brain region taxonomy proposed by Cree& McRae (2003);?
the semantic (but not lexical) relations imple-mented in WordNet 3.0 (Fellbaum, 1998) andin EuroWordNet (Alonge et al 1998);?
the classification of part/whole relations byWinston et al(1987);?
the SIMPLE-PAROLE-CLIPS Extended Qua-lia Structures (Ruimy et al 2002).3 STaRS.sys feature types classificationThe properties of our classification follow fromthe practical use scenario of STaRS.sys.
In de-tails, the fact that it?s thought to be used in a the-rapeutic context motivates our need for a classi-fication that has to be: (1) intuitive enough to beeasily used by therapist and (2) robust and (3)cognitively plausible so as to be used for prepar-ing the relevant kinds of therapeutic tasks.Furthermore, being focused on features pro-duced by human speakers, the classification ap-plies to the linguistic description of a property,rather than to the property itself.
Accordingly,then, pairings like the following:<plane> carries stuff<plane> is used for carrying stuffare though as instances of different types (re-spectively, is involved in and is used for).Starting from an analysis of the relevant pro-posals available in the literature, we identified aset of 26 feature types, most of which have beenorganized into the following six classes:TAXONOMIC PROPERTIES: Two types relatedto the belonging of a concept to a category havebeen isolated: the is-a and the coordinate types.PART-OF RELATIONS: We mainly followedWinston et als (1987) taxonomy in distinguish-ing six types describing a relation between aconcept and its part(s): has component, hasmember, has portion, made-of, has phase andhas geographical part.PERCEPTUAL PROPERTIES: Inspired by theCree and McRae?s (2003) brain region taxono-my, we isolated six types of perceivable proper-ties: has size, has shape, has texture, has taste,has smell, has sound, has colour.USAGE PROPERTIES: This class is composedby three types of an object?s use descriptions: isused for, is used by and is used with.LOCATIONAL PROPERTIES: We identifiedthree types describing the typical situation, spaceand time associated to an object.ASSOCIATED EVENTS AND ATTRIBUTES: Thisclass encompasses three kinds of informationthat can be associated to an object: its emotiveproperty (has affective property), one of its per-manent properties (has attribute) and the role itplays in an action or in a process (is involved in).As a matter of fact, each of the other classes is aspecification of one of the two latter types, towhich particular relevance has been accordeddue to their status from a cognitive point of view.Others: Two feature types fall out of thisclassification, and constitute two distinct classeson their own.
These are the has domain type, thatspecifies the semantic field of a concept, and thedummy is associated with, used for classifyingall those features that falls out of any other label.Comparison and final remarks: A quickcomparison between our types and the otherclassifications reveals that, apart from the is usedwith type, we didn?t introduce any new opposi-tion.
Any type of ours, indeed, has a parallel typeor relation in at least one of the other proposals.Such a remark shows what is the third major ad-vantage of our classification, together with itsusability and its cognitive plausibility: its compa-tibility with a wide range of well known theoreti-cal and experimental frameworks, that allows itto serve as a common ground for the interplay oftheories, insights and ideas originated from theabove mentioned research areas.4 EvaluationGiven the aims of our classification, and ofSTaRS.sys in general, we choose to evaluate ourcoding scheme by asking to a group of non ex-perts to label a subset of the non-normalizedKremer et als (2008) norms and measuring the158inter-coder agreement between them (Artsteinand Poesio, 2008), adhering to the Krippen-dorff?s (2004, 2008) recommendations.The choice to recruit only naive subjects hasthe positive consequence of allowing us to drawinferences also on the usability of our proposal.That is, such an evaluation can be additionallyseen as a measure of how easily a minimallytrained user can understand the oppositions iso-lated in our classification.4.1 Experimental SetupParticipants: 5 Italian speakers with a universitydegree were recruited for this evaluation.
Noneof them had any previous experience in lexico-graphy, nor any education in lexical semantics.Materials: 300 concept-feature pairs were se-lected mainly from a non-normalized version ofthe Kremer et als (2008) norms.
We choose thisdataset because (1) it?s a collection of descrip-tions generated by Italian speakers and (2) wewanted to avoid any bias due to a normalizationprocedure, so as to provide our subjects with de-scriptions that were as plausible as possible.The experimental concept-attribute pairs havebeen chosen so to have the more balanced distri-bution of concepts and feature types as possible,by not allowing duplicated pairs.
As for the con-cepts, an uniform distribution of features per cat-egory (30 feature for all the ten categories of theoriginal dataset) and of features per concept (i.e.between 4 and 7) has been easily obtained.The attempt to balance feature types, however,has revealed impracticable, mainly due to thenature of the concepts of the Kremer?s collectionand to the skewness of its type distribution.Therefore, we fixed an arbitrary minimum thre-shold of ten plausible features per type.
Plausiblefeatures have been obtained from a pilot annota-tion experiment performed by one author and anadditional subject.
We further translated 23 con-cept-feature pairs from the McRae (11 cases) andfrom the Leuven (12 cases) datasets for balanc-ing types as much as possible.Still, it has not been possible to find ten fea-tures for the following types: has GeographicalPart, has Phase and has Member (no features atall: this is a consequence of the kind of conceptrepresented the dataset), has Portion (only fourcases, again, this is a consequence of the sourcedataset), has Domain (5) and has Sound (6).
Wenevertheless decided to include these types in theinstructions and the relevant features in the testset.
Our decision has been motivated by the re-sults of the pilot experiment, in which the sub-jects made reference to such types as a secondaryinterpretation in more than ten cases.Procedure: The participants were asked to la-bel every concept-feature pair with the appropri-ate type label, relying primarily on the linguisticform of the feature.
They received a 17-pagesbooklet providing an explanation of the annota-tion goals, a definition and some examples forevery type class and for every type, a decisionflowchart and a reference table.Every participant was asked to read carefullythe instructions, to complete a training set of 30concept-feature pairs and to discuss his/her deci-sions with one of the two authors before startingthe experimental session.
The test set was pre-sented as a unique excel sheet.
On the average,labeling the 300 experimental pairs took 2 hours.4.2 ResultsThe annotations collected from the participantshave been normalized by conflating direct (e.g.is-a) and reverse (e.g.
is the Category of) relationlabels, and the agreement between their choicehas been measured adopting Fleiss?
Kappa.
The?Kappa: annotators?
column of Table 1 reportsthe general and the type-wise kappa scores2 forthe annotations of the participants.Feature Type Kappa:annotatorsKappa:gold/majorityis-a 0.900 0.956coordination 0.788 0.913has component 0.786 0.864has portion 0.558 0.747made of 0.918 0.955has size 0.912 1has shape 0.812 1has texture 0.456 0.793has taste 0.852 1has smell 0.865 1has sound 0.582 0.795has colour 0.958 1is used for 0.831 0.727is used by 0.964 1is used with 0.801 0.939situation located 0.578 0.854space located 0.808 0.898time located 0.910 0.946is involved in 0.406 0.721has attribute 0.460 0.746has affective property 0.448 0.855has domain 0.069 0.277is associated with 0.141 0.415General 0.73 0.866Table 1: Type-wise agreement values2All reported Kappa values are associated with p < 0.001.159Even if there is no consensus on how to interp-ret Kappa values in isolation, and despite the factthat, to our knowledge, this is the first work ofthis kind, we can nevertheless draw interestingconclusions from the pattern in table 1.
The gen-eral Kappa score has a value of 0.73, and theagreement values are above 0.8 for 12 types, notso distant in 2 cases, and well above 0.67 for 9types, 5 of which are our ?residual?
categories,that is, those that are more ?general?
that at leastone of the other types3.Such a contrast between the residual and theother types is even more pronounced in the class-wise analysis, where the only Kappa value belowthe 0.8 threshold is the one obtained for the AS-SOCIATED EVENTS AND ATTRIBUTES class (?
=0.766) 4 .
Furthermore, the distribution of falsepositives in a confusion matrix between the per-formance of the annotators and the ?majority?vote5 shows that part of the low agreement forthe residual types is due to the ?summation?
ofthe disagreement on the other categories.
Ob-viously, part of this variance is due also to thefact that such types have fuzzier boundaries, andso are more difficult to handle.As for the remaining four low agreementtypes, two of them (has affective property, hasdomain) have been signaled by the annotators tobe difficult to handle, while the remaining two(has sound, has portion) have been frequentlyconfused with one of the ASSOCIATED EVENTSAND ATTRIBUTES types and with the has compo-nent type, respectively.
Such results are not verypuzzling for the has domain and has portiontypes, given the technicality of the former and,for the latter, the nature of the described con-cepts.
They do point, however, to a better defini-tion of the remaining two types, the has soundand has affective property ones, in that most dif-ficulties seem to arise from an unclear definitionof their respective scopes.As pointed out by Artstein and Poesio (2008),agreement doesn?t ensure validity.
In trying toevaluate how our annotators ?did it right?, wemeasured the exact Kappa coefficient (Conger,1980) between the majority annotation (i.e.
whatannotators should have done to agree) and theannotation of the same set by one of the two au-3Our residual labels are has Attribute, has Texture, is Asso-ciated with, is Involved in and Situation Located.4The general Fleiss?
Kappa value for the class-wise com-parison is 0.766.5That is, the performance obtained by assigning the labelchosen by the majority of the annotators.thors.
With some approximation, we see this lastperformance as the ?right?
one.Results are reported in the ?Kappa: gold / ma-jority?
column of Table 1.
The general Kappavalue is well above 0.8, and so it is for 15 of the23 types.
Only two types (has domain and is as-sociated with) are below the 0.67 minimal thre-shold.
These data further confirm the difficultiesin handling residual types, but, more importantly,seem to suggest that our ?gold standard?
annota-tor have been able to learn the classification in afairly correct way (at least, it did in a way similaras one of the two authors of this classification).4.3 DiscussionWe interpret the results of our evaluation as ademonstration of the reliability of our codingscheme as well as of the usability of our classifi-cation, at least as the non residual types are con-cerned.
For the future, many improvements aresuggested by our data.
In particular, they showedthe need of the annotators to receive a bettertraining on some relations and distinctions.This points in the direction of both a moredeep training on the types we?ve dubbed as ?re-siduals?, and of a better definition of poorly un-derstood types such as has domain and has affec-tive property and puzzling distinctions such asthe has smell/is Involved in ones.5 Conclusions and Future DirectionsIn this paper we introduced a classification of theinformation types that can be expressed to de-scribe a concrete concept.
Even if we thoughtthis classification mainly for therapeutic purpos-es, its use can be broadened to include a widerange of possible NLP tasks.We evaluated our proposal by asking a groupof naive speakers to annotate a list of concept-feature pairs with the appropriate label.
Even ifour results can?t be interpreted as absolutely pos-itive, we consider them promising, in that (1) theskeleton of the classification seems to have beenvalidated by the performance of our participantsand (2) a great part of the disagreement seems tobe solvable through major care in the trainingphase.
In the near future we are going to test our(improved) coding scheme with annotators fromthe population of the STaRS.sys final users, i.e.therapist with experience in semantic therapy.Finally, further research is needed to assess ifand to what extent the semantic model underly-ing our classification is compatible with those ofexisting lexical and/or semantic resources.160AcknowledgmentsWe are grateful to the annotators who gave usthe data reported in Section 4 and to all theCLICers that commented our classification.
Inparticular, we would like to thank dr. FedericaCavicchio for their statistical advice and GerhardKremer for providing us with a non-normalizedversion of his dataset.ReferenceAntonietta Alonge, Nicoletta Calzolari, Piek Vossen,Laura Bloksma, Irene Castellon, Maria A. Martiand Wim Peters.
1998.
The linguistic design of theEuroWordNet database.
Computer and the Human-ities, 32: 91-115.Ron Artstein and Massimo Poesio.
2008.
Inter-coderagreement for computational linguistics.
Computa-tional Linguistics, 34 (4): 555-596.Anthony J. Conger.
1980.
Integration and generalisa-tion of Kappas for multiple raters.
PsychologicalBulletin, 88: 322-328.George S. Cree and Ken MCrae.
2003.
Analyzing thefactors underlying the structure and computation ofthe meaning of chipmunk, cherry, chisel, cheese,and cello (and many other such concrete nouns).Journal of Experimental Psychology: General, 132(2): 163-201Simon De Deyne, Steven Verheyen, Eef Amel, WolfVanpaemel, Matthew J.
Dry, Wouter Voorspoelsand Gert Storm.
2008.
Exemplar by feature appli-cability matrices and other Dutch normative datafor semantic concepts.
Behavior Research Me-thods, 40 (4): 1030-1048.Christiane Fellbaum.
1998.
WordNet.
An electroniclexical database.
The MIT Press.
Cambridge, MA.Joseph L. Fleiss.
1971.
Measuring nominal scaleagreement among many raters.
Psychological Bul-letin, 76 (5): 378-382.Peter Garrard, Matthew A. Lambon Ralph, John R.Hodges and Karalyn Patterson.
2001.
Prototypi-cality, distinctiveness and intercorrelation: analysesof the semantic attributes of living and nonlivingconcepts.
Cognitive Neuropsychology, 18 (2): 125-174.Gerhard Kremer, Andrea Abel and Marco Baroni.2008.
Cognitively salient relations for multilinguallexicography.
Proceedings of COLING-CogALexWorkshop 2008: 94-101.Klaus Krippendorff.
2004.
Reliability in content anal-ysis: some common misconceptions and recom-mendations.
Human Communication Research, 30(3): 411-433.Klaus Krippendorff.
2008.
Testing the reliability ofcontent analysis data: what is involved and why.
InK.
Krippendorff and M.A.
Bock (eds.).
The Con-tent Analysis Reader.
Sage, Thousand Oaks, CA:350-357.Ken McRae, George S. Cree, Mark S. Seidenberg andChris McNorgan.
2005.
Semantic feature produc-tion norms for a large set of living and nonlivingthings.
Behavior Research Methods, Instruments &Computers, 37 (4): 547-559.Gregory L. Murphy.
2002.
The big book of concepts.The MIT Press, Cambridge, MA.Lyndsey Nickels.2002.
Therapy for naming disorders:revisiting, revising, and reviewing.
Aphasiology,16 (10/11): 935-979Anastasia M. Raymer and Leslie J. Gonzalez-Rothi.2002.
Clinical diagnosis and treatment of namingdisorders.
In A.E.
Hillis (ed.).
Handbook of AdultLanguage Disorders.
Psychology Press: 163-182.Eleanor Rosch and Carolyn B. Mervis.
1975.
Familyresemblances: studies in the internal structure ofcategories.
Cognitive Psychology, 7: 573-605.Nilda Ruimy, Monica Monachini, Raffaella Distante,Elisabetta Guazzini, Stefano Molino, Marisa Uli-vieri, Nicoletta Calzolari and Antonio Zampolli.2002.
Clips, a multi-level Italian computational le-xicon: a glimpse to data.
Proceedings LREC 2002:792-799.Carlo Semenza.
1999.
Lexical-semantic disorders inaphasia.
In G. Denes and L. Pizzamiglio (eds.
).Handbook of clinical and experimental neuropsy-chology.
Psychology Press, Hove: 215-244.Luise Springer.
2008.
Therapeutic approaches inaphasia rehabilitation.
In B. Stemmer and H. Whi-taker (eds.)
Handbook of the Neuroscience of Lan-guage.
Elsevier Science, : 397-406.David P. Vinson and Gabriella Vigliocco.
2008.
Se-mantic feature production norms for a large set ofobjects and events.
Behavior Research Methods, 40(1): 183-190.Morton E. Winston, Roger Chaffin and DouglasHerrman.
1987.
A taxonomy of part-whole rela-tion.
Cognitive Science, 11:417-444.Ling-ling Wu and Lawrence W. Barsalou.
2009.
Per-ceptual Simulation in conceptual combination: evi-dence from property generation.
Acta Psychologi-ca, 132: 173-189.161
