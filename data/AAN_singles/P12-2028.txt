Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 140?144,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsLearning the Latent Semantics of a Concept from its DefinitionWeiwei GuoDepartment of Computer Science,Columbia University,New York, NY, USAweiwei@cs.columbia.eduMona DiabCenter for Computational Learning Systems,Columbia University,New York, NY, USAmdiab@ccls.columbia.eduAbstractIn this paper we study unsupervised wordsense disambiguation (WSD) based on sensedefinition.
We learn low-dimensional latentsemantic vectors of concept definitions to con-struct a more robust sense similarity measurewmfvec.
Experiments on four all-words WSDdata sets show significant improvement overthe baseline WSD systems and LDA basedsimilarity measures, achieving results compa-rable to state of the art WSD systems.1 IntroductionTo date, many unsupervised WSD systems rely ona sense similarity module that returns a similar-ity score given two senses.
Many similarity mea-sures use the taxonomy structure of WordNet [WN](Fellbaum, 1998), which allows only noun-noun andverb-verb pair similarity computation since the otherparts of speech (adjectives and adverbs) do not havea taxonomic representation structure.
For example,the jcn similarity measure (Jiang and Conrath, 1997)computes the sense pair similarity score based on theinformation content of three senses: the two sensesand their least common subsumer in the noun/verbhierarchy.The most popular sense similarity measure is theExtended Lesk [elesk] measure (Banerjee and Peder-sen, 2003).
In elesk, the similarity score is computedbased on the length of overlapping words/phrasesbetween two extended dictionary definitions.
Thedefinitions are extended by definitions of neighborsenses to discover more overlapping words.
How-ever, exact word matching is lossy.
Below are twodefinitions from WN:bank#n#1: a financial institution that accepts depositsand channels the money into lending activitiesstock#n#1: the capital raised by a corporation throughthe issue of shares entitling holders to an ownership in-terest (equity)Despite the high semantic relatedness of the twosenses, the overlapping words in the two definitionsare only a, the, leading to a very low similarity score.Accordingly we are interested in extracting latentsemantics from sense definitions to improve elesk.However, the challenge lies in that sense defini-tions are typically too short/sparse for latent vari-able models to learn accurate semantics, since thesemodels are designed for long documents.
For exam-ple, topic models such as LDA (Blei et al, 2003),can only find the dominant topic based on the ob-served words in a definition (financial topic inbank#n#1 and stock#n#1) without further dis-cernibility.
In this case, many senses will share thesame latent semantics profile, as long as they are inthe same topic/domain.To solve the sparsity issue we use missing wordsas negative evidence of latent semantics, as in (Guoand Diab, 2012).
We define missing words of a sensedefinition as the whole vocabulary in a corpus minusthe observed words in the sense definition.
Sinceobserved words in definitions are too few to revealthe semantics of senses, missing words can be usedto tell the model what the definition is not about.Therefore, we want to find a latent semantics pro-file that is related to observed words in a definition,but also not related to missing words, so that the in-duced latent semantics is unique for the sense.Finally we also show how to use WN neighborsense definitions to construct a nuanced sense simi-larity wmfvec, based on the inferred latent semanticvectors of senses.
We show that wmfvec outperformselesk and LDA based approaches in four All-wordsWSD data sets.
To our best knowledge, wmfvec isthe first sense similarity measure based on latent se-mantics of sense definitions.140financial sport institution Ro Rmv1 1 0 0 20 600v2 0.6 0 0.1 18 300v3 0.2 0.3 0.2 5 100Table 1: Three possible hypotheses of latent vectors forthe definition of bank#n#12 Learning Latent Semantics of Definitions2.1 IntuitionGiven only a few observed words in a definition,there are many hypotheses of latent vectors that arehighly related to the observed words.
Therefore,missing words can be used to prune the hypothesesthat are also highly related to the missing words.Consider the hypotheses of latent vectors in ta-ble 1 for bank#n#1.
Assume there are 3 dimen-sions in our latent model: financial, sport, institu-tion.
We use Rvo to denote the sum of relatednessbetween latent vector v and all observed words; sim-ilarly, Rvm is the sum of relatedness between thevector v and all missing words.
Hypothesis v1 isgiven by topic models, where only the financialdimension is found, and it has the maximum relat-edness to observed words in bank#n#1 definitionRv1o = 20. v2 is the ideal latent vector, since it alsodetects that bank#n#1 is related to institution.
Ithas a slightly smaller Rv2o = 18, but more impor-tantly, its relatedness to missing words, Rv2m = 300,is substantially smaller than Rv1m = 600.However, we cannot simply choose a hypothesiswith the maximum Ro ?Rm value, since v3, whichis clearly not related to bank#n#1 but with a min-imum Rm = 100, will therefore be (erroneously)returned as the answer.
The solution is straightfor-ward: give a smaller weight to missing words, e.g.,so that the algorithm tries to select a hypothesis withmaximum value of Ro ?
0.01 ?
Rm.
We chooseweighted matrix factorization [WMF] (Srebro andJaakkola, 2003) to implement this idea.2.2 Modeling Missing Words by WeightedMatrix FactorizationWe represent the corpus of WN definitions as anM ?N matrix X , where row entries are M uniquewords existing in WN definitions, and columns rep-resent N WN sense ids.
The cell Xij records theTF-IDF value of word wi appearing in definition ofsense sj .In WMF, the original matrix X is factorized intotwo matrices such that X ?
P>Q, where P is aK ?
M matrix, and Q is a K ?
N matrix.
Inthis scenario, the latent semantics of each word wior sense sj is represented as a K-dimension vectorP?,i or Q?,j respectively.
Note that the inner productof P?,i and Q?,j is used to approximate the seman-tic relatedness of word wi and definition of sense sj :Xij ?
P?,i ?Q?,j .In WMF each cell is associated with a weight, somissing words cells (Xij=0) can have a much lesscontribution than observed words.
Assume wm isthe weight for missing words cells.
The latent vec-tors of words P and senses Q are estimated by min-imizing the objective function:1?i?jWij (P?,i ?Q?,j ?Xij)2 + ?||P ||22 + ?||Q||22where Wi,j ={1, if Xij 6= 0wm, if Xij = 0(1)Equation 1 explicitly requires the latent vector ofsense Q?,j to be not related to missing words (P?,i ?Q?,j should be close to 0 for missing words Xij =0).
Also weight wm for missing words is very smallto make sure latent vectors such as v3 in table 1 willnot be chosen.
In experiments we set wm = 0.01.After we run WMF on the definitions corpus, thesimilarity of two senses sj and sk can be computedby the inner product of Q?,j and Q?,k.2.3 A Nuanced Sense Similarity: wmfvecWe can further use the features in WordNet to con-struct a better sense similarity measure.
The mostimportant feature of WN is senses are connected byrelations such as hypernymy, meronymy, similar at-tributes, etc.
We observe that neighbor senses areusually similar, hence they could be a good indica-tor for the latent semantics of the target sense.We use WN neighbors in a way similar to elesk.Note that in elesk each definition is extended by in-cluding definitions of its neighbor senses.
Also, theydo not normalize the length.
In our case, we alsoadopt these two ideas: (1) a sense is represented bythe sum of its original latent vector and its neigh-bors?
latent vectors.
Let N(j) be the set of neigh-bor senses of sense j. then new latent vector is:Qnew?,j = Q?,j +?k?N(j)k Q?,k (2) Inner product (in-stead of cosine similarity) of the two resulting sensevectors is treated as the sense pair similarity.
Werefer to our sense similarity measure as wmfvec.1Due to limited space inference and update rules for P andQ are omitted, but can be found in (Srebro and Jaakkola, 2003)1413 Experiment SettingTask: We choose the fine-grained All-Words SenseDisambiguation task, where systems are required todisambiguate all the content words (noun, adjective,adverb and verb) in documents.
The data sets we useare all-words tasks in SENSEVAL2 [SE2], SENSE-VAL3 [SE3], SEMEVAL-2007 [SE07], and Semcor.We tune the parameters in wmfvec and other base-lines based on SE2, and then directly apply the tunedmodels on other three data sets.Data: The sense inventory is WN3.0 for the fourWSD data sets.
WMF and LDA are built on the cor-pus of sense definitions of two dictionaries: WN andWiktionary [Wik].2 We do not link the senses acrossdictionaries, hence Wik is only used as augmenteddata for WMF to better learn the semantics of words.All data is tokenized, POS tagged (Toutanova et al,2003) and lemmatized, resulting in 341,557 sensedefinitions and 3,563,649 words.WSD Algorithm: To perform WSD we need twocomponents: (1) a sense similarity measure that re-turns a similarity score given two senses; (2) a dis-ambiguation algorithm that determines which sensesto choose as final answers based on the sense pairsimilarity scores.
We choose the Indegree algorithmused in (Sinha and Mihalcea, 2007; Guo and Diab,2010) as our disambiguation algorithm.
It is a graph-based algorithm, where nodes are senses, and edgeweight equals to the sense pair similarity.
The finalanswer is chosen as the sense with maximum inde-gree.
Using the Indegree algorithm allows us to eas-ily replace the sense similarity with wmfvec.
In In-degree, two senses are connected if their words arewithin a local window.
We use the optimal windowsize of 6 tested in (Sinha and Mihalcea, 2007; Guoand Diab, 2010).Baselines: We compare with (1) elesk, the mostwidely used sense similarity.
We use the implemen-tation in (Pedersen et al, 2004).We believe WMF is a better approach to modellatent semantics than LDA, hence the second base-line (2) LDA using Gibbs sampling (Griffiths andSteyvers, 2004).
However, we cannot directly useestimated topic distribution P (z|d) to represent thedefinition since it only has non-zero values on oneor two topics.
Instead, we calculate the latent vec-2http://en.wiktionary.org/Data Model Total Noun Adj Adv VerbSE2 random 40.7 43.9 43.6 58.2 21.6elesk 56.0 63.5 63.9 62.1 30.8ldavec 58.6 68.6 60.2 66.1 33.2wmfvec 60.5 69.7 64.5 67.1 34.9jcn+elesk 60.1 69.3 63.9 62.8 37.1jcn+wmfvec 62.1 70.8 64.5 67.1 39.9SE3 random 33.5 39.9 44.1 - 33.5elesk 52.3 58.5 57.7 - 41.4ldavec 53.5 58.1 60.8 - 43.7wmfvec 55.8 61.5 64.4 - 43.9jcn+elesk 55.4 60.5 57.7 - 47.4jcn+wmfvec 57.4 61.2 64.4 - 48.8SE07 random 25.6 27.4 - - 24.6elesk 42.2 47.2 - - 39.5ldavec 43.7 49.7 - - 40.5wmfvec 45.1 52.2 - - 41.2jcn+elesk 44.5 52.8 - - 40.0jcn+wmfvec 45.5 53.5 - - 41.2Semcor random 35.26 40.13 50.02 58.90 20.08elesk 55.43 61.04 69.30 62.85 43.36ldavec 58.17 63.15 70.08 67.97 46.91wmfvec 59.10 64.64 71.44 67.05 47.52jcn+elesk 61.61 69.61 69.30 62.85 50.72jcn+wmfvec 63.05 70.64 71.45 67.05 51.72Table 2: WSD results per POS (K = 100)tor of a definition by summing up the P (z|w) ofall constituent words weighted by Xij , which givesmuch better WSD results.3 We produce LDA vec-tors [ldavec] in the same setting as wmfvec, whichmeans it is trained on the same corpus, uses WNneighbors, and is tuned on SE2.At last, we compare wmfvec with a mature WSDsystem based on sense similarities, (3) (Sinha andMihalcea, 2007) [jcn+elesk], where they evaluate sixsense similarities, select the best of them and com-bine them into one system.
Specifically, in their im-plementation they use jcn for noun-noun and verb-verb pairs, and elesk for other pairs.
(Sinha and Mi-halcea, 2007) used to be the state-of-the-art systemon SE2 and SE3.4 Experiment ResultsThe disambiguation results (K = 100) are summa-rized in Table 2.
We also present in Table 3 resultsusing other values of dimensions K for wmfvec andldavec.
There are very few words that are not cov-ered due to failure of lemmatization or POS tag mis-matches, thereby F-measure is reported.Based on SE2, wmfvec?s parameters are tuned as?
= 20, wm = 0.01; ldavec?s parameters are tunedas ?
= 0.05, ?
= 0.05.
We run WMF on WN+Wikfor 30 iterations, and LDA for 2000 iterations.
For3It should be noted that this renders LDA a very challengingbaseline to outperform.142LDA, more robust P (w|z) is generated by averag-ing over the last 10 sampling iterations.
We also seta threshold to elesk similarity values, which yieldsbetter performance.
Same as (Sinha and Mihalcea,2007), values of elesk larger than 240 are set to 1,and the rest are mapped to [0,1].elesk vs wmfvec: wmfvec outperforms elesk consis-tently in all POS cases (noun, adjective, adverb andverb) on four datasets by a large margin (2.9% ?4.5% in total case).
Observing the results yieldedper POS, we find a large improvement comes fromnouns.
Same trend has been reported in other distri-butional methods based on word co-occurrence (Caiet al, 2007; Li et al, 2010; Guo and Diab, 2011).More interestingly, wmfvec also improves verbs ac-curacy significantly.ldavec vs wmfvec: ldavec also performs very well,again proving the superiority of latent semanticsover surface words matching.
However, wmfvec alsooutperforms ldavec in every POS case except Sem-cor adverbs (at least +1% in total case).
We observethe trend is consistent in Table 3 where different di-mensions are used for ldavec and wmfvec.
Theseresults show that given the same text data, WMFoutperforms LDA on modeling latent semantics ofsenses by exploiting missing words.jcn+elesk vs jcn+wmfvec: jcn+elesk is a very ma-ture WSD system that takes advantage of the greatperformance of jcn on noun-noun and verb-verbpairs.
Although wmfvec does much better than elesk,using wmfvec solely is sometimes outperformed byjcn+elesk on nouns and verbs.
Therefore to beatjcn+elesk, we replace the elesk in jcn+elesk withwmfvec (hence jcn+wmfvec).
Similar to (Sinha andMihalcea, 2007), we normalize wmfvec similaritysuch that values greater than 400 are set to 1, andthe rest values are mapped to [0,1].
We choose thevalue 400 based on the WSD performance on tun-ing set SE2.
As expected, the resulting jcn+wmfveccan further improve jcn+elesk for all cases.
More-over, jcn+wmfvec produces similar results to state-of-the-art unsupervised systems on SE02, 61.92%F-mearure in (Guo and Diab, 2010) using WN1.7.1,and SE03, 57.4% in (Agirre and Soroa, 2009) us-ing WN1.7.
It shows wmfvec is robust that it notonly performs very well individually, but also canbe easily incorporated with existing evidence as rep-resented using jcn.dim SE2 SE3 SE07 Semcor50 57.4 - 60.5 52.9 - 54.9 43.1 - 44.2 57.90 - 58.9975 57.8 - 60.3 53.5 - 55.2 43.3 - 44.6 58.12 - 59.07100 58.6 - 60.5 53.5 - 55.8 43.7 - 45.1 58.17 - 59.10125 58.2 - 60.2 53.9 - 55.5 43.7 - 45.1 58.26 - 59.19150 58.2 - 59.8 53.6 - 54.6 44.4 - 45.9 58.13 - 59.15Table 3: ldavec and wmfvec (latter) results per # of dimensions4.1 DiscussionWe look closely into WSD results to obtain an in-tuitive feel for what is captured by wmfvec.
For ex-ample, the target word mouse in the context: ... inexperiments with mice that a gene called p53 couldtransform normal cells into cancerous ones... eleskreturns the wrong sense computer device, due to thesparsity of overlapping words between definitionsof animal mouse and the context words.
wmfvecchooses the correct sense animal mouse, by recog-nizing the biology element of animal mouse and re-lated context words gene, cell, cancerous.5 Related WorkSense similarity measures have been the core com-ponent in many unsupervised WSD systems andlexical semantics research/applications.
To date,elesk is the most popular such measure (McCarthyet al, 2004; Mihalcea, 2005; Brody et al, 2006).Sometimes people use jcn to obtain similarity ofnoun-noun and verb-verb pairs (Sinha and Mihalcea,2007; Guo and Diab, 2010).
Our similarity measurewmfvec exploits the same information (sense defini-tions) elesk and ldavec use, and outperforms themsignificantly on four standardized data sets.
To ourbest knowledge, we are the first to construct a sensesimilarity by latent semantics of sense definitions.6 ConclusionsWe construct a sense similarity wmfvec from the la-tent semantics of sense definitions.
Experiment re-sults show wmfvec significantly outperforms previ-ous definition-based similarity measures and LDAvectors on four all-words WSD data sets.AcknowledgmentsThis research was funded by the Office of the Di-rector of National Intelligence (ODNI), IntelligenceAdvanced Research Projects Activity (IARPA),through the U.S. Army Research Lab.
All state-ments of fact, opinion or conclusions containedherein are those of the authors and should not beconstrued as representing the official views or poli-cies of IARPA, the ODNI or the U.S. Government.143ReferencesEneko Agirre and Aitor Soroa.
2009.
Proceedings of per-sonalizing pagerank for word sense disambiguation.In the 12th Conference of the European Chapter of theACL.Satanjeev Banerjee and Ted Pedersen.
2003.
Extendedgloss overlaps as a measure of semantic relatedness.In Proceedings of the 18th International Joint Confer-ence on Artificial Intelligence, pages 805?810.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
Journal of MachineLearning Research, 3.Samuel Brody, Roberto Navigli, and Mirella Lapata.2006.
Ensemble methods for unsupervised wsd.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meetingof the ACL.Jun Fu Cai, Wee Sun Lee, and Yee Whye Teh.
2007.Improving word sense disambiguation using topic fea-tures.
In Proceedings of the 2007 Joint Conference onEmpirical Methods in Natural Language Processingand Computational Natural Language Learning.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences, 101.Weiwei Guo and Mona Diab.
2010.
Combining orthogo-nal monolingual and multilingual sources of evidencefor all words wsd.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics.Weiwei Guo and Mona Diab.
2011.
Semantic topic mod-els: Combining word distributional statistics and dic-tionary definitions.
In Proceedings of the 2011 Con-ference on Empirical Methods in Natural LanguageProcessing.Weiwei Guo and Mona Diab.
2012.
Modeling sentencesin the latent space.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Linguis-tics.Jay J. Jiang and David W. Conrath.
1997.
Finding pre-dominant word senses in untagged text.
In Proceed-ings of International Conference Research on Compu-tational Linguistics.Linlin Li, Benjamin Roth, and Caroline Sporleder.
2010.Topic models for word sense disambiguation andtoken-based idiom detection.
In Proceedings of the48th Annual Meeting of the Association for Computa-tional Linguistics.Diana McCarthy, Rob Koeling, Julie Weeds, and JohnCarroll.
2004.
Finding predominant word senses inuntagged text.
In Proceedings of the 42nd Meeting ofthe Association for Computational Linguistics.Rada Mihalcea.
2005.
Unsupervised large-vocabularyword sense disambiguation with graph-based algo-rithms for sequence data labeling.
In Proceedings ofthe Joint Conference on Human Language Technologyand Empirical Methods in Natural Language Process-ing, pages 411?418.Ted Pedersen, Siddharth Patwardhan, and Jason Miche-lizzi.
2004.
Wordnet::similarity - measuring the re-latedness of concepts.
In Proceedings of Fifth AnnualMeeting of the North American Chapter of the Associ-ation for Computational Linguistics.Ravi Sinha and Rada Mihalcea.
2007.
Unsupervisedgraph-based word sense disambiguation using mea-sures of word semantic similarity.
In Proceedings ofthe IEEE International Conference on Semantic Com-puting, pages 363?369.Nathan Srebro and Tommi Jaakkola.
2003.
Weightedlow-rank approximations.
In Proceedings of the Twen-tieth International Conference on Machine Learning.Kristina Toutanova, Dan Klein, Christopher Manning, ,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of the 2003 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics on Human Language Technology.144
