Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 54?62,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsPredicting Cognitively Salient Modifiersof the Constitutive Parts of ConceptsGerhard Kremer and Marco BaroniCIMeC, University of Trento, Italy(gerhard.kremer|marco.baroni)@unitn.itAbstractWhen subjects describe concepts in termsof their characteristic properties, they oftenproduce composite properties, e. g., rabbitsare said to have long ears, not just ears.
Wepresent a set of simple methods to extractthe modifiers of composite properties (inparticular: parts) from corpora.
We achieveour best performance by combining evi-dence about the association between themodifier and the part both within the con-text of the target concept and independentlyof it.
We show that this performance is rel-atively stable across languages (Italian andGerman) and for production vs. perceptionof properties.1 IntroductionSubject-generated concept descriptions in terms ofproperties of different kinds (category: rabbits aremammals, parts: they have long ears, behaviour:they jump, .
.
. )
are widely used in cognitive sci-ence as proxies to feature-based representations ofconcepts in the mind (Garrard et al, 2001; McRaeet al, 2005; Vinson and Vigliocco, 2008).
Thesefeature norms (as collections of subject-elicitedproperties are called in the relevant literature) areused in simulations of cognitive tasks and experi-mental design.
Moreover, vector spaces that havesubject-generated properties as dimensions havebeen shown to be a good complement or alternativeto traditional semantic models based on corpus col-locates (Andrews et al, 2009; Baroni et al, 2010).Since the concept?property pairs in featurenorms resemble the tuples that relation extractionalgorithms extract from corpora (Hearst, 1992; Pan-tel and Pennacchiotti, 2006), recent research hasattempted to extract feature-norm-like concept de-scriptions from corpora (Almuhareb, 2006; Baroniet al, 2010; Shaoul and Westbury, 2008).
Froma practical point of view, the success of this en-terprise would mean being able to produce muchlarger norms without the need to resort to expensiveand time-consuming elicitation experiments, lead-ing to wider cognitive simulations and possibly bet-ter vector space models of semantics.
From a the-oretical point of view, a corpus-based system thatproduces human-like concept descriptions mightprovide cues of how humans themselves come upwith such descriptions.However, the corpus-based models proposed forthis task up to this point overlook the fact that sub-jects very often produce composite properties: Sub-jects state that rabbits have long ears, not just ears;cars have four wheels; a calf is a baby cow, etc.Composite properties are not multi-word expres-sions in the usual sense.
There is nothing specialor idiomatic about long ears.
It is just that wefind it to be a remarkable fact about rabbits, worthstating in their description, that their ears are long.In the norms described in section 3, around onethird of the part descriptions are composite.
Notethat while our focus is on feature norms, a similarpoint about the importance of composite propertiescould be made for other knowledge repositories ofimportance to computational linguistics, such asWordNet (Fellbaum, 1998) and ConceptNet (Liuand Singh, 2004), approximately 68,000 (36%) ofthe entries and 1,300 (32%) of the part entries beingcomposites, respectively.In this paper, we tackle the problem of gener-ating composite properties from corpus data bysimplifying it in various ways.
First, we focuson part properties only, because they are com-monly encountered in feature norms, and becausethey are are commonly composite (cf.
section 3).Second, we assume that an early step in the pro-cess of property extraction has already generateda list of simple parts, perhaps using an existingwhole?part relation extraction algorithm (Girju etal., 2006).
Finally, we focus on composite parts54with an adjective?noun structure ?
together withnumeral?noun cases, these constitute the near to-tality of composite parts in the norms describedin section 3.
Having thus delimited the scope ofour exploration, we will adopt the following ter-minology: concept for the target nominal concept(rabbit), part for the (nominal) part property (ear)and modifier for the adjective that makes the partcomposite (long).We present simple methods that, given a list ofconcept?part pairs and a POS-tagged and lemma-tised corpus, rank and extract candidate modifiersfor the parts when predicated of the concepts.
Weexploit the co-occurrence patterns of the part withthe modifier both near the concept and in other con-texts (both kinds of co-occurrences turn out to behelpful).
We first test our methods on German fea-ture norms, and then we show that they generalisewell by applying them to similar data in Italian, andto the same set of German concept?part pairs whenevaluated by asking new subjects to rate the topranked modifiers generated by the ranking meth-ods.
This also leads to a more general discussionof differences between modifiers produced by sub-jects in the elicitation experiment and those that arerated acceptable in perception, and the significanceof this for corpus-based property generation.The paper is structured as follows.
After shortlyreviewing some related work in section 2, in sec-tion 3, we describe our feature norms focusing inparticular on composite properties.
In section 4,we describe our methods to harvest modifiers froma corpus and report the extraction experiments,whereas section 5 concludes by discussing direc-tions for further work.2 Related WorkWe are not aware of other attempts to extractconcept-dependent modifiers of properties.
Wereview instead related work in feature norm col-lection and prediction, and mention some rele-vant literature on the extraction of significant co-occurrences from corpora.Feature-based concept description norms havebeen collected in psychology for decades.
Amongthe more recent publicly available norms of thissort, there are those collected by Garrard et al(2001), Vinson and Vigliocco (2008) and McRaeet al (2005).
The latter was the main methodologi-cal inspiration for the bilingual norms we rely on(see section 3 below).
The norms of McRae andcolleagues include descriptions of 541 concreteconcepts corresponding to English nouns.
The 725subjects that rated these concepts had to list theirfeatures on a paper questionnaire.
The producedfeatures were then normalised and classified intocategories such as part and function by the exper-imenters.
The published norms include, amongother kinds of information, the frequency of pro-duction of each feature for a concept by the sub-jects.Almuhareb (2006) was the first to attempt toreproduce subject-generated features with text min-ing techniques.
He computed precision and re-call measures of various pattern-based feature ex-traction methods using Vinson and Vigliocco?snorms for 35 concepts as a gold standard.
Thebest precision was around 16% at about 11% re-call; maximum recall was around 60% with lessthan 2% precision, confirming how difficult thetask is.
Importantly for our purposes, Almuharebremoved the modifier from composite features be-fore running the experiments (1 wheel convertedto wheel), thus eschewing the main characteris-tic of subject-generated concept descriptions thatwe tackle here.
Shaoul and Westbury (2008) andBaroni et al (2010) used corpus-based semanticspace models to predict the top 10 features of 44concepts from the McRae norms.
The best model(Baroni et al?s Strudel) guesses on average 24% ofthe human-produced features, again confirming thedifficulty of the task.
And, again, the test set waspre-processed to remove modifiers of compositefeatures, thus sidestepping the problem we wantto deal with.
It is worth remarking that, by remov-ing modifiers, previous authors are making the taskeasier in terms of feature extraction procedure (be-cause the algorithms only need to look for singlewords), but they also create artificial ?salient?
fea-tures that, once the modifier has been stripped of,are not that salient anymore (what distinguishes amonocycle from a tricycle is that one has 1 wheel,the other 3, not simply having wheels).
It is con-ceivable that a method to assign sensible modifiersto features might actually improve the overall qual-ity of feature extraction algorithms.Following a very long tradition in computationallinguistics (Church and Hanks, 1990), we use co-occurrence statistics for words in certain contextsto hypothesise a meaningful connection betweenthe words.
In this respect, what we propose is notdifferent from common methods to extract and rank55collocations, multi-word expressions or semanti-cally related terms (Evert, 2008).
From a technicalpoint of view, the innovative aspect of our task isthat we do not just look for co-occurrences betweentwo items, but for co-occurrences in the context ofa third element, i. e., we are interested in modifier?part pairs that are related when predicated of acertain concept.
The method we apply to the ex-traction of modifier?part pairs when they co-occurwith the target concept in a large window is similarto the idea of looking for partially untethered con-textual patterns proposed by Garera and Yarowsky(2009), that extract name?pattern?property tupleswhere the pattern and the property must be adja-cent, but the target name is only required to occurin the same sentence.3 Composite Parts in Feature NormsOur empirical starting point are the feature normscollected in parallel from 73 German and 69 Ital-ian subjects by Kremer et al (2008), following amethodology similar to that of McRae et al (2005).The norms pertain to 50 concrete concepts from 10classes such as mammals (e. g., dog), manipulabletools (e. g., comb), etc.
The concept?part pairs inthese norms served on the one hand as input to ouralgorithm ?
on the other hand, its output (the set ofselected modifiers from the corpus) could be evalu-ated against those modifiers that were produced bythe subjects.
Furthermore, the bilingual nature ofthe norms allows us to tune our algorithm on onelanguage (German), and evaluate its performanceon the other (Italian), to assess its cross-lingualgeneralisation capability.To confirm that speakers actually frequently pro-duce properties composed of part and modifier, ob-serve that in the German data (10,010 descriptivephrases in total), of the 1,667 parts produced, 625(more than one third) were composite parts, and404 were composed of an adjective and a noun, thetarget of this research work.
Looking at the distinctparts that were elicited, 92 were always producedwith a modifier, 280 only without modifier, and 122both with and without modifier.
That is, for about43% of the parts at least some speakers used a com-posite expression of adjective and noun.
This highproportion motivates our work and is not surpris-ing, given that, for describing a specific concept,one will tend to come up with whatever makes thisconcept special and distinguishes it from other con-cepts ?
which (considering parts) sometimes is thepart itself (elephant: trunk) and sometimes some-thing special about the shape, colour, size, or otherattributes of the part (elephant: big ears).The data set for modifier extraction and subse-quent method evaluation comprises all the concept?modifier?part triples (e. g., onion: brown peel) pro-duced by at least one subject, taken from the Ger-man and the Italian norms.
The German (Italian)speakers described 41 (30) different concepts byusing at least one out of 80 (45) different parts incombination with one out of 62 (50) different mod-ifiers, totalling to 229 (127) differently combinedtriples.4 ExperimentsThis section describes the approach we explored forranking and extracting modifiers of composite partsand evaluates the performance of 6 different extrac-tion methods in terms of the production norms.Acceptance rate data from a follow-up judgementexperiment complete the evaluation.4.1 Ranked Modifier ListsBased on the idea that the co-occurrence of wordsin a text corpus reflects to some extent how strongthese words are associated in speakers?
minds(Spence and Owens, 1990), our extraction approachworks on the lemmatised and POS-tagged GermanWaCky1 web corpus of about 1.2 billion tokens.Modifier?Part FrequenciesUsing the CQP2 tool, corpus frequencies were col-lected for all co-occurrences of adjectives withthose part nouns that were produced in the exper-iment described above.
A possible gap of up to3 tokens between the pair of adjective and nounallowed to extract also adjectives that are not di-rectly adjacent to the nouns in the corpus (but in asequence of adjectives, for example).
For each partnoun, the 5 most frequent adjective modifiers fromthe ranked modifier?part list were selected underthe assumption that the preferred usage of thesemodifiers with the specific part indicates the mostcommon attributes which that part typically has.1See the WaCky project at http://wacky.sslmit.unibo.it2Corpus Query Processor (part of the IMS Open CorpusWorkbench, see http://cwb.sourceforge.net)56Log-Likelihood Values of FrequenciesAn attempt to improve the performance of the firstmethod is to calculate3 the log-likelihood associ-ation value for each modifier?part pair instead ofkeeping the raw co-occurrence frequency, and se-lect the 5 highest ranked modifiers for each partfrom this list.
Log-likelihood weighting shouldaccount for typical modifiers which have a low fre-quency but do generally not occur often in the cor-pus, and with not many other parts ?
their log-likeli-hood value will be higher, and so will be their rank(e. g., two-sided blade in contrast to long blade).Modifier?Part Frequencies in Concept ContextHowever, both of these methods do not necessarilyyield generally atypical modifiers that are howevertypical of a part when it is attributed to a specificconcept.
For example, birds?
beaks are typicallybrown, orange or yellow, but aiming to extract mod-ifiers for a crow?s beak, black would be one of thedesired modifiers ?
which does not appear at a highfrequency rank as a generic beak modifier.
Themethods described so far did not take the conceptinto account when generating the modifier?partpairs, i. e., for all concepts with a specific part thesame set of modifiers would be extracted.To address this issue, a second frequency ranklist was prepared in the same manner ?
with theonly difference that the part noun had to appearwithin the context of the concept noun.
That way,also modifiers for specific concepts?
parts that devi-ate from the most typical part modifiers appear at ahigh rank.
However, these data are sparser, whichis why we used a wide context of 40 sentences (20sentences before and after the part) within whichthe concept had to occur (i. e., a paragraph-like con-text size in which the topic, presumably, comprisesthe concept).
We refer to ranked lists of modifier?part pairs that do not take the target concept intoaccount as contextless lists, and to lists within thespan of a context as in-context lists.Due to the already mentioned data sparsenessproblem, not all modifiers used for a part noun inthe production norms could be extracted with thelatter method, as some of the obvious modifiers forspecific parts are just not written about.
For these,there is a higher chance that they appear, if at all, inthe contextless rank list.
For example, thin bristlesdoes not appear in the context of broom.
In the in-3Using the UCS toolkit, described at http://www.collocations.de/software.html#UCScontextless concept contextrank freq modifier freq modifier1 507 thick 16 thick2 209 dense 14 white3 204 soft 11 small4 185 black 11 soft5 175 long 9 denseTable 1: Top 5 modifiers from frequency rank listsfor part fur and concept bearcontext list, 33% of the 229 triples extracted fromthe German norms were not found (in the context-less list, only 9% modifier?part pairs are missing).Additionally, particular concepts, parts, or concept?part pairs (within the 40 sentence span) might bemissing from the corpus, as well.
From the Ger-man norms collection, all concepts appeared in thecorpus, but one part (a noun?noun compound), and6 concept?part pairs (rare, colloquial part nouns)were missing.
In the evaluation to follow, all themodifiers pertaining to these missing data from thecorpus will be counted as positives not found bythe algorithm.The example excerpt in table 1 shows modifiersthat were selected for bear and fur, using the twofrequency rank lists described above.
Although inthis example most of the modifiers (thick, dense,soft) are found in both lists, two arguably reason-able modifiers are just in the contextless set (black,long), and one only in the in-context set (white).A disadvantage of selecting modifiers from the in-context rank list is that many modifiers have thesame low frequency, but they should neverthelesshave differing ranks.
In such cases, we assignedranks according to alphabetic order of modifiers.Summed Log-Rescaled FrequenciesNext, to improve performance and profit from bothinformation sources the above methods provide,the in-context and contextless rank lists were com-bined.
In one variant, the scaled frequencies forthe concept?modifier?part triples appearing in bothlists were added.
Scaling was necessary becausethe frequencies in the contextless list are in generalmuch higher than in the in-context list.
Further-more, to account for the fact that at high ranksthe difference in frequency between subsequentranks is much higher than at lower ranks, scalingwas done by using the logarithmic values of the fre-57quencies: For each concept?modifier?part triple, itslogarithmic frequency value was divided by the log-arithmic value of the maximum corpus frequencyof all parts in the corpus (in the contextless list)or of all concept?part pairs co-occurring within 40sentences (in the case of the in-context list).Productwise Combination of FrequenciesAs an alternative back-off approach, the raw fre-quencies were combined productwise into a newlist (for those modifier?part pairs missing in the in-context list, the frequency of the pair in the context-less list was taken alone, instead of multiplying itby zero; i. e., the in-context term was max(freq, 1)).This achieves a sort of ?intersective?
effect, wheremodifiers that are both commonly attributed to thepart and predicated of it in the context of the tar-get concept are boosted up in the list, according tothe intuition that a good modifier should be bothplausible for the part in general, and typical for theconcept at hand.Cosine-Based Re-RankingAn attempt to further improve performance is basedon the idea that parts are described by some spe-cific types of attributes.
For example, a leaf wouldbe characterised by its shape or consistency (e. g.,long, stiff ), whereas for fur rather colour should beconsidered (e. g., white, brown).
If we are able tocluster modifiers for their attribute type and findout which attribute types are in particular importantfor a specific part, those could get a preference inthe rank list and be moved towards the top.
Toapproach this in a simple way, a re-ranking methodis used which is supposed to cluster and choose theright cluster of modifiers implicitly: The modifiersin the (productwise-) combined list were tested fortheir similarity by looking if they co-occur withthe same relative frequency with the same set ofnouns.
In case of high similarity (in this respect)of a modifier to a single other modifier, or if themodifier was similar to a lot of modifiers, it shouldbe re-ranked to a higher position.
In more detail,a vector was created for each modifier, denotingits co-occurrence frequencies with each noun inthe corpus within a window of 4 tokens (on theleft side of the noun).
Random indexing helped toreduce the vector dimensionality from 27,345 to3,000 elements (Sahlgren, 2005).
These vectorsserved for calculating the cosine distances betweenmodifiers.
Then, for each of the top 200 modifiersin the combined frequency rank list (covering 84%of the triples from the German norms), the cosinedistance was calculated to each of the top 100 mod-ifiers in the contextless rank list.
A constant of 1was added to each of the computed cosines, thusobtaining a quantity between 1 and 2.
The originalcombined frequency value was multiplied by thisquantity (thus leaving it unchanged when the orig-inal cosine was 0, increasing it otherwise).
Fromthe re-ranked list resulting from this operation, weselected, again, the top 5 modifiers of each concept?part pair.
For example, suppose that black is amongthe modifiers of a crow?s beak in the combined list.We compute the cosine similarity of black with thetop 100 modifiers of beak (in any context), and,for each of these cosines, we multiply the originalcombined value of black by cosine+1.
Since thecolour is a common attribute of beaks, the presenceof modifiers like yellow and brown, high on the con-textless beak list, helps re-ranking black high in thecrow-specific beak list.
We hope that this methodhelps out concept-specific values (e. g., black forcrow) of attributes that are in general typical of apart (colour for beak).4.2 Performance on Composite Parts Fromthe Production NormsThe feature norms data represented the gold stan-dard for the evaluation of all sets of modifiers cho-sen by each of the described methods for the givenconcept?part pairs.
Note that, even if a modifier?part pair was produced only once in the fea-ture production norms, the corresponding concept?modifier?part triple was included in the gold stan-dard ?
which contains 41 different concepts, 80different parts, and 62 different modifiers, totallingto 229 concept?modifier?part triples.
As in the Ger-man corpus there are 154,935 adjective?part-nounpairs, the random baseline (random guessing) forfinding these 229 pairs is approaching 0 (similarlyfor Italian and the judgement dataset).Figure 1 displays the performance of the meth-ods on German in the form of a recall?precisiongraph.
For each rank (1?5), overall recall and inter-polated precision values are given for all modifier?part pairs up to this rank ?
note that precision at1% recall is overrated as it is based on an arbitraryfraction of rank 1 pairs.
As expected, extractingmodifiers of parts within a concept context (the in-context list) achieves low recall.
In contrast, modi-fiers that were extracted by querying the corpus forparts without considering the concept context have580.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Method Performancerecallprecisionparts in concept context (freq)contextless (freq)combination productwise (freqs)cosine re?ranking (freq product)parts in context (log?likelihood)combination by sum (log rescaled freqs)baseline: averaged random guessingFigure 1: Evaluation on German normsa higher recall.
But this method has a lower preci-sion in general.
The performance for the methodcombining frequencies productwise and for the onethat re-ranks this combined list via cosine-basedsmoothing are substantially better.
Not only the pre-cision is much higher at all recall levels, but alsotheir maximum recall values are higher than thoseof the contextless lists, i. e., it was worth combin-ing the complementing information in the two lists.However, the performance of the cosine-based re-ranked list compared to the productwise-combinedlist is not considerably higher, as we might havehoped.
The remaining two alternative methods per-formed much worse: the one using log-likelihoodvalues as ranking criterion had in general a low pre-cision and a low recall, and the method combiningthe in-context and the contextless rank list by sum-ming up the rescaled logarithmic frequency valuesperforms as bad as the contextless rank list.
Never-theless, note that all methods perform distinctivelywell above the baseline.Qualitatively analysing the data collected withthe described methods did not give definite cluesabout why some performed not as good as expected.As a comprehensible example, the modifier shortfor legs is at rank 5 in the contextless list, but be-cause of the frequent co-occurrence with monkey itrises to rank 2 in the productwise combination ofthese lists, and even to rank 1 in the cosine-basedre-ranked list.
An understandable bad performingexample is the modifier yellow for the eyes of anowl: Although it appears in the in-context list at0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Method Performancerecallprecisionparts in concept context (freq)contextless (freq)combination productwise (freqs)cosine re?ranking (freq product)Figure 2: Evaluation on Italian normsrank 2, it is a quite infrequent modifier for eyesin general (i. e., low in the contextless list), andthus it is not contained in the top 5 modifiers inthe productwise combined rank list.
On the otherhand, it is not perfectly clear to us why, e. g., flat forthe roof of a skyscraper, which is at rank 5 in thecontextless list and at rank 6 in the combined list,is lowered to rank 9 in the cosine-based re-rankedlist (in the in-context list, it does not appear at all).For all methods, collected modifiers include suchof undesired attributes not describing the part, butother, rather situational aspects, e. g., own, left, new,protecting, and famous.
Furthermore, we observedthat some modifiers are reasonable for the respec-tive concept?part pair, but they are counted as falsebecause they did not occur in the production experi-ment (that we took as the evaluation basis), e. g., forthe blade of a sword, not only large is acceptable,but also long and wide, essentially making the sameassertion about the size of the blade.
This issue isaddressed further below by creating a new evalua-tion standard based on plausibility judgements.To evaluate the cross-lingual performance ofthe extraction approach, the Italian norms wereexplored similarly to the German norms for com-posite parts.
The gold standard here comprised127 triples (from combinations of 30 different con-cepts, 45 parts, and 50 different modifiers).
Thesame methods described above were used to ex-tract modifiers from the Italian WaCky web corpus(more than 1.5 billion tokens), with one differenceregarding the query for adjectives near nouns: As59in the Italian language adjectives in a noun phrasecan be used both before and after the noun (withdifferences in their meaning), and given that mostof them were produced after the noun, we collectedall adjectives occurring up to 2 words from the leftof the noun and up to 4 words to the right.Figure 2 shows the performance curves of themethods for the Italian data.
In this evaluation, themethod using log-likelihood values and the methodcombining lists via addition of logarithmic rescaledfrequencies are omitted as their performance wasnot promising at all in the German data, and theyare conceptually similar to the contextless andproductwise-combination approaches, respectively.Like in German, the in-context method yields alow recall, in contrast to the method not consid-ering the presence of concepts in context.
Again,cosine-based re-ranking performs very similarly tothe method using the productwise-combined list.For the performance on the Italian data, their differ-ence from the simple frequency rank lists is not aslarge as it is for the German data, but it is clearlyvisible, especially at higher recall values.Summarising, our comparison of various corpus-based ranking methods to the feature productionnorms, both in German and Italian, suggests thatcomposite parts produced by subjects are bestmined in corpora by making use of both general in-formation about typical modifiers of the parts (thecontextless rank) and more specific informationabout modifiers that co-occur with the part near thetarget concept.
Moreover, it is better to combinethe two information sources productwise, whichsuggests an intersecting effect (the most likely mod-ifiers are both well-attested out of context and seennear the target concept).
For both languages, thereis no strong evidence that re-ranking by cosine sim-ilarity (a method that should favour modifiers thatare values of common attributes of a part) is im-proving on the plain combination method (althoughre-ranking is not hurting, either).By looking at the overall performance, the re-sults are somewhat underwhelming, with precisionaround 20% at around 30% recall for the best mod-els in both languages.
A natural question at thispoint is whether the modifiers ranked at the topby the best methods and treated as false positivesbecause they are not in the norms are neverthelesssensible modifiers for the parts, or whether they aretruly noise.
In order to explore this issue we turnnow to our next experiment.4.3 Performance Evaluation Based onPlausibility JudgementsThe purpose of this judgement experiment was tosee which concept?modifier?part triples the ma-jority of participants would rate as acceptable.
Itallows us to investigate two topics: (i) the compari-son of what people produce and what they perceiveas being a prominent modifier for a concept?partpair (our algorithm might actually provide goodcandidates which were just not produced, as we justsaid) and (ii) a re-evaluation of the cosine-basedre-ranking method (it could be in fact better thanwe thought because we only evaluated what wasproduced, but did not have a definite plausibilityrating of the candidates missing in the norms).The tested set contained the triples yielded byour two best performing methods (productwisecombination and cosine-based re-ranking), whichwere applied to the German feature norms (692triples, comprising 41 concepts and 71 parts).
Fromthis set, a set of triples was chosen randomly foreach of the 46 participants (recruited by e-mailamong acquaintances of the first author).
Thetriples were presented to participants embeddedinto a natural-sounding sentence of the form ?The[part] of a [concept] is [modifier]?.
Each partic-ipant rated 333 sentences, presented on separatelines of a text file (this set of sentences presentedcomprised additional triples which were intendedfor other purposes ?
for the current evaluation, weused a subset of 110 of these from each partici-pant, on the average).
Participants were instructedto read the sentences as general statements abouta concept?s part and mark them by typing a let-ter (?w?
for wonderful and ?d?
for dubious ?
tofacilitate one-handed typing and easy memorisa-tion) at the beginning of the line, if they thought itplausible/unlikely that someone used the sentenceto explain an aspect of the relevant part.
In total,5,525 judgements were collected; each sentence inthe set was judged on the average by 8 persons.The performance evaluation is based on the ac-ceptance rate of the participants: Modifiers ac-cepted by at least 75% of the raters are consid-ered plausible.
Figure 3 shows the recall?precisiongraph for the methods tested on the concept?partpairs from the German norms.
From the 692 triplesjudged, around 13% were accepted by the majorityof speakers.
The precision rate is comparable withthe evaluation on the basis of the modifiers pro-duced by participants (highest recall is 1, of course,600.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0Method Performancerecallprecisioncombination productwise (freqs)cosine re?ranking (freq product)Figure 3: Evaluation on judgements (German)because all modifiers to be judged were exclusivelyfrom the data set selected by our methods).Again, the performance of the cosine-based re-ranking method is similar to the performance of theproductwise-combination method.
For a more ex-act evaluation of the difference between these two,a last test was conducted: Instead of measuring theperformance in the form of counts of modifiers thatwere accepted by the majority of participants, weused the acceptance rates of all modifiers: The ac-ceptance rates of all judged triples were summed upif they contained the same concept?part pair.
Thismeans that each concept?part pair received a scorereflecting the overall acceptance of the set of modi-fiers for that pair (e. g., for bear: fur, all acceptancerates for bear: brown fur, bear: soft fur, .
.
.
weresummed up).
Then, the score of each concept?partpair in the productwise-combined list was com-pared against the score of the same pair for thecosine-based re-ranking method, using a pairwiset-test (this procedure is sound because the modifiersper pair are the same for the two methods).
Thetest showed a significant difference (p = 0.008), butin favour of the productwise-combination method(score means were slightly higher).
That is, cosine-based re-ranking in the current form brings no ad-vantage over the simpler productwise combinationof the frequency lists.Finally, turning to the qualitative comparison ofproduction and perception, there was a relativelysmall overlap of triples (46) contrasting with modi-fiers only produced but not accepted (53), and mod-ifiers accepted but not produced (42).
Intuitively,we would have expected that what was producedwill be also accepted by the majority of people.Possibly, some participants in the judgement ex-periment found a few of the triples produced ques-tionable (goose: long beak) ?
such triples were inour gold standard because we deliberately did notwant to exclude composite parts even if producedby only one speaker ?
whereas participants produc-ing parts for given concepts probably just did notthink of specific parts or modifiers (e. g., aeroplane:small windows and bear: dense fur).
The importantfact regarding this difference is, however, that ourmethod captures both kinds of modifiers.5 DiscussionWe presented several corpus-based methods thatprovide a set of adjective modifiers for each con-crete concept?part pair, to be compared to thosemodifiers that are salient to human subjects.
Thegeneral approach was to generate ranked lists, andselect the 5 candidates at the top of the ranks.The best of our methods works on the simple(productwise-) combination of frequency informa-tion of co-occurring adjective?noun pairs with andwithout considering a wide ?concept context?
inwhich the part noun has to occur.
This method per-formed better than the one based on co-occurrencefrequency not in concept context (generic modi-fiers, not appropriate for every concept) and theone based on co-occurrence frequencies in conceptcontext, only (low recall because of sparse data).We evaluated the methods on feature productionnorms and on plausibility judgements of generatedconcept?modifier?part triples to compare produc-tion and perception of modifiers.
The performancewas similar in precision ?
although the qualitativeanalysis showed that modifiers produced and modi-fiers perceived did not have a large overlap.
Thismeans our algorithm is capable of collecting bothwith the same performance.After tuning the algorithm on German norms, weevaluated its generalisation capability to a differentlanguage (Italian).
Performance was similar.
Lesssatisfying at first glance is the precision value ofjust around 20% at the maximum recall level (how-ever, when compared to the baseline of below 1%precision, this is an essentially better value) ?
aswell as the fact that our implementation of the intu-itive idea to re-rank modifiers that are similar (andshould instantiate the same attribute) did not have61a performance advantage.
This is subject to furtherwork.
Moreover, using a machine-learning method(building a binary classifier) could be tried.
An-other idea was to crawl the web and select concept-specific text passages to build a specialised corpus.Possibly, we could draw then from a richer infor-mation source.
A rough attempt to do this did notseem to yield promising results.So far, we included only adjectives as permis-sible modifiers.
A future extension could be alsoaiming for numerals (e. g., four wheels).
Then, forthe simulation of human-like behaviour we imag-ine as part of the possible future work to enablethe algorithm to decide if a part noun should bepaired with a modifier, at all ?
or if the part itself issufficient to describe a concept (big ears vs. trunk).Regarding the evaluation, a more exact perfor-mance measure would probably be achieved byeither having more participants producing conceptdescriptions and then only selecting those modi-fiers for the gold standard that were produced by amajority ?
or letting participants in a judgement ex-periment also judge modifiers that were produced,to filter out the unlikely ones.A next step in the project will be extractingsalient parts for concepts (which we assumed tohave done already for the purpose of this paper),possibly by integrating the information we alreadycollected by extracting modifiers.
In the end, wewould like to come up with an adaptable methodthat extracts not only parts but also other typesof relations (e. g., category, behaviour, function,etc.
), which have been already addressed in re-lated works, though.
The issue we presented inthis paper, however, is new and, we think, worthexploring.ReferencesAbdulrahman Almuhareb.
2006.
Attributes in LexicalAcquisition.
Phd thesis, University of Essex.Mark Andrews, Gabriella Vigliocco, and David Vin-son.
2009.
Integrating experiential and distribu-tional data to learn semantic representations.
Psy-chological Review, 116(3):463?498.Marco Baroni, Eduard Barbu, Brian Murphy, and Mas-simo Poesio.
2010.
Strudel: A distributional seman-tic model based on properties and types.
CognitiveScience, 34(2):222?254.Kenneth Church and Peter Hanks.
1990.
Word associ-ation norms, mutual information, and lexicography.Computational Linguistics, 16(1):22?29.Stefan Evert.
2008.
Corpora and collocations.
InA.
Lu?deling and M.
Kyto?, editors, Corpus Linguis-tics: An International Handbook, pages 1212?1248.Mouton de Gruyter, Berlin, Germany.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press, Cambridge,MA.Nikesh Garera and David Yarowsky.
2009.
Structural,transitive and latent models for biographic fact ex-traction.
In Proceedings of EACL, pages 300?308,Athens, Greece.Peter Garrard, Matthew Lambon Ralph, John Hodges,and Karalyn Patterson.
2001.
Prototypicality, dis-tinctiveness, and intercorrelation: Analyses of thesemantic attributes of living and nonliving concepts.Cognitive Neuropsychology, 18(2):25?174.Roxana Girju, Adriana Badulescu, and Dan Moldovan.2006.
Automatic discovery of part-whole relations.Computational Linguistics, 32(1):83?135.Marti Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofCOLING, pages 539?545, Nantes, France.Gerhard Kremer, Andrea Abel, and Marco Baroni.2008.
Cognitively salient relations for multilinguallexicography.
In Proceedings of the COGALEXWorkshop at COLING08, pages 94?101.Hugo Liu and Push Singh.
2004.
ConceptNet: A prac-tical commonsense reasoning toolkit.
BT Technol-ogy Journal, pages 211?226.Ken McRae, George Cree, Mark Seidenberg, and ChrisMcNorgan.
2005.
Semantic feature productionnorms for a large set of living and nonliving things.Behavior Research Methods, 37(4):547?559.Patrick Pantel and Marco Pennacchiotti.
2006.Espresso: Leveraging generic patterns for automat-ically harvesting semantic relations.
In Proceed-ings of COLING-ACL, pages 113?120, Sydney, Aus-tralia.Magnus Sahlgren.
2005.
An introduction to randomindexing.
http://www.sics.se/?mange/papers/RI_intro.pdf.Cyrus Shaoul and Chris Westbury.
2008.
Performanceof HAL-like word space models on semantic cluster-ing.
In Proceedings of the ESSLLI Workshop on Dis-tributional Lexical Semantics, pages 42?46, Ham-burg, Germany.Donald Spence and Kimberly Owens.
1990.
Lexicalco-occurrence and association strength.
Journal ofPsycholinguistic Research, 19(5):317?330.David Vinson and Gabriella Vigliocco.
2008.
Seman-tic feature production norms for a large set of objectsand events.
Behavior Research Methods, 40(1):183?190.62
