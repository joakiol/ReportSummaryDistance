ATT ITUDE EMERGENCE - AN EFFECT IVE  INTERPRETAT ION SCHEMEFOR PERSUASIVE  D ISCOURSEI tOR.NG- JYH P. WU and STEVEN L. LYT INENArtificial Intelligence LaboratoryThe University of MichiganAnn Arbor, MI 48109.
U.S.A.ABSTRACTPrevious approaches have used a reasoning mechanismcalled belief percolation to determine the actual speechintent of the speaker (e.g., (Wilks and Bien 1979)).In this paper, a similar mechanism, called attitudeemergence, is proposed as a mechanism for inferring aspeaker's attitude toward the propositions in a persua-sive discourse.
It is sbown that in order to adequatelyinterpret the statements in advertisements, associa-tions of relevant semantic information, through br*dg-lug inferences, are to be percolated up through attitudemodel contexts to enhance and calibrate the interpre-tation of statements.
A system called BUYER is beingimplemented to recognize speech intents through atti-tude emergence in the domain of food advertisementstaken from Reader's Digest.
An example of BUYER'sprocessing is also presented in the paper.Introduct ionOne of the most significant characteristics of persuasivediscourse is that it involves the expression of people'sbeliefs, desires, preferences, etc.
These beliefs, desires,and preferences constitute a model of mental a~titudes(or, an attitude model) which characterizes the mindof the speaker engaging in a persuasiw', discourse.
Anattitude model is important for figuring out what thespeaker means; i.e., his speech iutent.
More specifi-cally, often when the speaker expresses his beliefs, de-sires or preferences in persuasive discourse, he meansto induce a reaction, in the forms of comparable men-tal attitudes, on the part of a hearer.
For example,an expression of the speaker's belief can be intendedto induce such an belief in the hearer.
However, ingeneral, inferring the speech intent through attitudcmodel reasoning is complex.
For instance, in our do-main of persuasive discourse - advertisements - a ma-jor statement may be followed by minor statements, asdemonstrated in the following passage.
(1.1) Nabisco is great.
(1.2) It is nutritious whole wheat,(1.3) low in cholesterol and saturated fat,(1.4} haz plenty of fiber and vitamin.Arranged in this fashion, tbe expression of thespeaker's preference in (1.1) - Nabisco is great comesto be supported by statements (1.2) through (1.4).This makes tile acceptance of (1.1) as the heater'sown much more compelling, intending to induce inthe hearer the same preference xpressed in (1.1).
Al-though tills explanation sounds intuitively simple andcorrect, the question remains: how do statements suchas (1.2) to (1.4), which are oil the surface~ "disjoint"expressions of the speaker's belief, come to have a realpsychological impact on the hearer?
Some sort of rea-soning must have been employed to bridge them with(1.1) and to produce the persuasive ffects.Previously, model-based reasoning has been inves-tigate(\[ for many tasks, such as belief ascription andmetaphor understanding (Ballim et al 1991), logicalreasoning (Dinsmore 1987), and natural anguage un-derstanding in general (Faueonnier 1985).
One previ-ous approach to attitude model reasoning concentratesexactly on issues of inferring speech intents.
As dis-cussed concisely in (Wilks and Bien 1979), the state-ment "Frank is coming tomorrow" can be interpretedin many ways, depending on the context.
For instance,if the hearer believes that the speaker believes thatFrank is hostile to the hearer, and the hearer has uopersonal knowledge about Frank, then this statementmight be interpreted as a threat to the hearer.To account for different possible interpretations ofstatements like these, Wilks el al.
propose an altitudepercolatiou mechanism, in which a statement is pusheddown to the frame of the system's belief to create theattitude context - the system's belief of the speaker'sbelief.
Since in this more specific context, the followingstatements are simultaneously present I : Frank comestomorrow and Frank is hostile to the system.
Thus,tile system can infer that Frank may harm the sys-tem, which in turn, allows the system to interpret heoriginal statement ms a threat to itself.In our domain of advertisement persuasive disconrse~much fewer facts arc privately known compared towhat are mutually known 2.
Therefore, it is argued~If tile system has personM knowledge otherwise aboutFrank, then this may affect the reasoning proces,q.2It is also an essential criteria for "good" advertisementsto adhere to fashionable viewpoints.AC1-ES DE COLING-92, NANTES, 23-28 AOt~r 1992 9 1 1 PROC.
OF COLING-92.
NANTES, Auo.
23-28.
1992that the push dowa operation, which investigates intothe personal knowledge about one another, will be lim-ited.
Instead, in this paper, a more relevant mecha.nism, called attitude emergence, is investigated.
It is amore conlprehensive treatmeTit of attitude lnodels~ nti--lizing mutually known semantic and world knowledgeto convey speech intent, a.s observed in the interpreta-tion of our earlier example.
More specitically, attitudemodels for statements are eonstnmted, aud a~qsimilatedthrough bridging inferences based on mntual knowl-edge.
The semantic association resulting flora assinfi-lation then gets percolated up along attitude model con-texts so that the proper interpretation of speech intentis recognized.
This attitude emergence mechanism isbeing implemented in a system called BUYEI{~, whichunderstands food advertisements taken fl'om lgeader'sDigest.
A corpus of 129 advertis(mmnts has been col-lected.
Part of the ads are used R)r constructing tilesystem, while the rest of them are used to verify thegenerality of BUYI';ll.
's knowledge base.
In this papm,we present an examl)le of 1111Yl,2d, processing one nfthese ads.The  bas ic  f ramework  o f  a t t t i l ;udeemergenceAs observed above, the recognition of speech intent inpersuasive discourse is rather comj)lex.
Various sortsof mutual knowledge ntay be employed in bridging thestatements and bringing out the speech intents.
In (Wnand Lytinen 1991), we proposed a three.step rocedureof attitude mergence:Step 1: Construct tile initial altitude model (or A-model).Step 2: Assimilate the successive statements cnherentlyinto one A-model (if possible) anti recognize thesemantic a.qsociation Imtween tile models.Step 3: Percolate upwards &tOltg A-model context o effectattitude hauge due to the semantic associationrecognized in Step 2.A-models are rceursive structures of infi)rmation withattitude contexts, each layer el Milch consists of anagent and an attitude he holds toward the deeper hwelinformation.
A simple passag;e is analyzed ill (Wu andI,ytinen 1991),(2.1) Peter loves antique cars.
(2.2) His favorite model is tile 1887 I)uryca.Tire evolution f A-.models through this three-step ro-cedure can be summarized as follows: At tile end ofStep l (see Fig.
1), a,m A-model is coastructed con-sisting of an attitude context (Report i;pcak(~r ...),which eml)eds another attitude context ?
(Love Peter ...), which contains ~,.
*l object antique.ea.k's.
Notethat, these linear R)rmula m'c just, short hands ik)r ulod-els.
We take thai, ill implmnentatinn, models are ibr-mula plus indexing ;rod encapsulation, as tile boxes illFig.
I is intended to capture: the indice,~ on agents arecalled S-boxes and on attitude~q A-boxes.l';ach attitude context creates it'~ oegn environnientR)r simulative reasoning (Wilks and llavtley 1990),.FaTV _A?
.
\ [ - -V& -~ .
.
.
.
.
.
.Antique eara \]Figure 1: The initial attitude model after (2.1) h&sbeen processed.. .
.
.
.
.
~ , .
a k - -  .
.
.
.
.
.I.,'igure 2: The attitude model and reasoning when (2.2)is assimilated.which involves only entities with comparable attitude,qtatus.
In turn, simulative reasoning call produce re-suits app\]icable to the attitude context where it takesplace, and may sometimes affect related contexts, e.g.,causing re-Evaluation of the attitude in the embeddingattitude contexts.
Thus, ill Step 2, while statement(2.2) is being assimilated with statement (2.1), somereasoning takes place marked as (A), (B) and tO) inFig.
2.At point (A), an IS-A semantic relation is recog-nized between "antique_cars" and "1887_Duryea" inthe semantic space whicb, ,as depicted as orthogonal toattitude space in Fig.
2, stores attitude-independentsemantic information.
Ill order to trigger emergenceof more attitude related information, the recognitionof the LqoA relation is percolated up along layers ofe~ttit.ude contexts to reach tile (Report Speaker ...) con-text, where (B) and (C) occur.
At points (B) and (C),~'~ta~,emeuts (2.2) and (2.1) are found to be related; inparticular, tile (Report Speaker ...) context of (2.2) iscalibrated to be "evidential" (to (2.1)), wbile, that of(2.1) to be "snl)l)orted" (by (2.2)). "
lhat (B) and (C)occur is due to tile following world knowledge (WKI):,'\~:li s ) IJ()I.INi 1-97, I<IAitii~s, 23 28 Ao()r 1992.
9 I 2 Pltoc.
OF COLING.92, NANTES, AUG. 23-28, 1992(Ru=alng  ~ )(R~lng  =}(84)  ~ p4ar l l t i~d  In AIB lud~= apm~eFigure 3: The two attitude ruodels for the readings of$I.If the speaker provides more detailed informationabout a clMm (Y) in a statement (X)Then Y is "supported" by "evidence" X and becomesmore believableAs demonstrated by (A) - (C), semantic associationemerges from embedded attitude contexts to calibratethe attitude in higher contexts - i.e., how attitudeemergence happens.In this simple example, the attitude emergencemechanism has involved, nonetheless, a large amountof knowledge.
This knowledge is briefly reviewed be-low.
Yet, more sophisticated reasoning is required toprocess real world ads (see below).
First, there isknowledge concerning A-model construction based onthe following mapping rules: (1) Sentence types to A-boxes, e.g,  a declarative sentence type maps into abelief; (2) Attitude verbs to A-boxes, e.g., "loves" intoa preference; (3) Evaluative predicates to A-boxes, e.g.,"favorite" into a preference; (4) Adverbs to A-models,e.g., "certainly" into a belief; (5) Cue phrases to A-models, "it is time that" into a desire (recommenda-tion).Secondly, there is knowledge concerning A-model as-similation and bridging inferences.
For example, inpassage (2), the expression "his favorite model" is re-solved through the following three separate bridginginference steps:1.
That "his" refers to tldngs pertinent to Peter.2.
That "favorite" is an evMuative predicate translated intoa "prefer" attitude box.3.
That cars have models.For step (1), a focusing mechanisnr is required to locatethe S-box - Peter, since a pronominal expression usu-ally (but not always) refers to some object in the focus.For step (2), the A-model helps to guide the resolutionfilrther into the most relevant A-box; in other words,an A-model itself carl serve as a marker to find the mostrelevant A-model earlier in tile discourse.
For step (3),a basic semantic association occurs to recognize pos~sitde semantic relations.
In summary, the resolutionof the expression "his favorite model," and similarlyfor all other expressions, is achieved by bridging in-ferences which synthesize many knowledge sources, in-cluding focusing, A-models themselves, and semanticassociation.A rea l  wor ld  example  f rom BUYER.In this section, a real world advertisement is presentedto demonstrate the application of attitude emergencein processing persuasive discourse.
As discussed above,a simple version of A-model construction and assimila-tion has to be extended to include more general worldknowledge.
The following ad, which BUYER has pro-cessed, demonstrates this.The Folgers ad.SI.
l.s your decaffeinated ~s dark as ours?$2.
Star~ with one teaspoon of both.$3.
Hut just bec&tlse the anmunts are cquaJdoesn'~ t:lean the results w~ll he.$4.
Mount,~t~ Grown ~blgers dark, sparklingCrystals are the dilt~reJtce.S6.
So dark a3~d rich, shouldn't you switch?In tile process of understanding this ad, tim systemhas to tigure out many tbings, for example: ls S1 aquestion or a prompt fur suggesting an action (for tilehearer to perform)?
Is $2, given tile proper interpre-tation of $1, an order or a recommendation; Does $3affect the status of tile attii.ude xpressed in 817 andso on.
In order to answer these questions concerningspeech intcuts, tile attltude model of each statementh~ to go through more involved calibration and en-hancement tban the simple version presented in theprevious section.
First, the reading of statement 5'Iis ambiguous.
It could mean that the speaker wantsthe hearer to inform him as to whetber the bearer'sdecaffeinated is as dark a~s ours.
Or, it can have an-other reading: the speaker wants the hearer to knowwhether the hearer's decaffeinatcd is ms dark as ours.The latter reading is inferred by the following worldknowledge (WK2)~:If  the advertiser already knows everything about hisproducts (which is reasonable to assume),Then a questio~ concerning the product is actuallyall intention to iu.\[orm.The two possible attitude models for the two readingsof $1 are depicted in Fig.
3.
Note that the two vari-ables el and e l '  stand for tile different events speci-fied by (Inform-whether Hearer ...) and (Know-whetherHearer ...), respectively.
The two events are indexed bytheir event types, as demonstrated by the ovals in theboxes in Fig.
3.
Then, when $2 is processed, from itssentence type (imperative), it is inferred that its atti-tude context is compatible witll both readiugs of $1,3For simplicity and readability, we represent BUYER'sknowledge in this and following examples as English-likerules.AcI~:S DE COLING-92, Nntcn~s, 23-28 ^ o\[rr 1992 9 1 3 I)rtoc.
or COLING-92, NANTES, AU~.
23-28, 1992(83) aa a conditional In Attitude Sp~ce\[P1 ); The arrlour~t~ are equal,{Q1 ): Tim resutbs are riot equal.Figure 4: The attitude models of tim conditional $3.i.e., (Want Speaker (P Hearer ...)).
Hence, the semanticassociation begins to emerge when the events e2, speci-fied as "start witb one teaspoon of both," and el or el'(see Fig.
3) are being assimilated.
The coherence rea-soning component of BUYER.
(Wu and Lytinen 1990)is able to recognize the following Enable coherence re-lation:That tile hearer starts with one temspoon of both kindsof coffee can enable that hc knows which coffee is bet-ter.That is, the action e2suggested in $2 is an e~:perirnentto find out something.
The choice between el andel ~ is now clear, due to the following world knowledge(WE3):I f  an agent has a goal to find out something about X,Then he can perform an experiment with X.Since eL' - (Know-whetl)er ttearer ...) -- is acquired asa goal for the hearer according to Reading 2, el' andhence, Reading 2 is determined as the speech intent.Then, when $3 is processed, it logically means:It is )lot the case that Pl implies Q1.where P1 stands for - the amounts are equal; Ql theresults are equal.
The cormnon sense logical reason-ing employed in constructing the attitude model of $3proceeds ms follows: assume P1 is a fact/observation,should we assmne QI or ~ Ql according PFI?
If Q1 isassumed, then it produces: P1 impliesQt, which wonklbe contradictory.
So, the only alternative is to chooseQ1.
The result is then the attitude model shownin Fig.
4.
Following attitude percolation, the attitudemodel of Fig.
4 is pushed down into the one in Fig.
3for t?~eading 2, creating the attitude context of (WantSpeaker (Believe Hearer ...)).
At this point, BUYER isable to reason that Pl - the amounts are equal - is afact, by resolving "the amounts" to "the amounts ofcoffee used in e27' Given that the conditional PF1 hasa satisfying antecedent, he conseqnent ~ QI (or "theresults are not eqnal") is derived as a fact.
Note that,similar to how "tile amounts" is resolved, "the results"would be resolved ms "the results in the experimentswith the two coffees.
"Next, when $4 is processed, by pushing down andresolving "the difference" to "the difference betweenthe resnlts in the experimellt," it is recognized tl~at $4is supl)orting the implicit speech intent made in $3 -.53: The speaker claims that the resultsof Y ar~florent.
,$5: Tile speaker molivates the useS~: t~Ot feooxpepa0kOr~na~ to~eKrl~0~.
~ fcofrFl~ cl~mo0ffeo, dnawing =ppert$4: The apeaker gives evidencesupporting the claim.$1 : The speaker wants the hearerto Know X.Figure 5: The statements of the Folgers ad in view oftheir attitude models.the speaker wants the hearer to believe that tbe resultsof the experiments are not equal.
This is due to thefollowing world knowledge (WK4):I f  the speaker gives the physical cause of a conse-quence statement,Then the consequence statement becomes more be-lievable.Thus, the intended belief that tim results are not equalis further enhanced.
Finally, $5, like 83, is not a literalconditional statement.
It logically means:P~ implies should?
(-, Q2)where P7 is that Folgers is so dark and rich and Q2,switch to Folgers.
However, the intended meaning is,obviously - switch to Folgers.
The derivation hingeson the following "dogma" about "abnormal vs. nor-real states": (1) Unfamiliar external states may be ab-normal; (2) If unknown external states are indeed ab-normal, people query about them using "should X? '
;(3) Abnormal states are to be corrected.
Due to (1) -(3), the intended meaning can be derived, since ~ Q2is abnormal and to be corrected; in addition, Pz is alsoa fact.
Fig.
5 summarizes tim speech intents reasonedby attitude emergence for the Folgers ad:Re la ted  workWork on belief percolation ((Wilks and Bien 1979),(Wilk~ and Bien 1983), (Wilks and Ballim 1987), (Hal-lira et al 1991)) has strongly inspired our work.
flow-ever, n~lost of this work concentrates on one single oper-ation of attitude/belief percolation .- the "push down"operation.
Although this operation is important for in-vestigative reasoning and assimilating attitude models,effects on attitude models themselves due to attitudepercolation are more important for our domain of per-snasive disconrse.
Thus, attitude emergence stands asa more relevant mechanism to reason about persuasivespeech intent.
Moreover, the proposed thretr-step r~cedure for computing attitude emergence proves to bea general framework for recognizing speech intents.The mapping rules proposed in (Hinkelman andAllen 1989), as well as those in (Gerlach and Sprenger1988), are similar to the attitude model constructionrules, while deeper reasoning may underlie some ofAclT.s t)E COL1NG-92, NA/VIq!S, 23-28 AOt';r 1992 9 l 4 I'ROC.
Ol: COLING-92.
NANTES.
AUG. 23-28, 1992their rules, e.g., the interpretation of should?
('~Q~)as Q2, as we have done to ours.
Ill (Hiukelman andAllen 1989), they also proposed plan-recognition tofurther identify the speech intent.
However, we be-lieve that in persuasive discourse, identifying speechintent through A-models can be done more locally us-ing coherence and bridging inferences.
In this sense,our approach is closer to those proposed in (Cohen1987) and (Mann and Thompson 1988), while (Cohen1987) considered only support relations and (Mann andThompson 1988) remained as a descriptive theory, andboth did not consider A-models as essential lot infer-ring speech intent.A-models also arc somewhat similar to model-theoretical approaches to semantics.
While theoriesof the more formal kind -- e.g, Discourse Represen-talional Theory (DRT) (Kamps 1981) -- and of thenrore cognitive - e.g., Mental Spaces (Fauconnier 1985)- emphasize the fundamental issues of reference andpresupposition, attitude mergence s es application ofmodel reasoning to recognize speech intents.
Thesealso demonstrate hat mental attitudes erve as onlyone (though important) way to organize information.There are other ways information should be organized.I,br example, our formulation of conditionals (for $3)is organized not according to attitudes, but principlesstudied in DRT and mental spaces.Conc lus ion  and  fu ture  workIn this paper, a mechanism called attitude mergenceis discussed.
The basic framework of attitude emer-gence, which consists of attitude model construction,assimilation, and effects propagation, was first pro-posed in (Wu and Lytinen 1991) with limited oper-ations.
The mechanism is filrther inrproved aud ex-tended to recognize more indirect speech in persua-sive discourse, by adding other common sense and log-ical reasoning.
The generality of attitude emergenceis demonstrated by a real world ad which BUYER hasproce~ed.
BUYER is the computer implementation fattitude mergence and is implentented asa rule-basedsystem which currently has 348 rules organized in 1Oproblem-solving modules.
These problem-solving mod-ules are organized in a way that rules are both forward-and backward-chained, depending tim deductive andabduetive nature of the rules, respectively, and allowsefficient backtracking.One future work of attitude emergence lies on tilefurther systematization the dynamics of attitudemodels.
Only the force aspect of a statement is presentin the current formulation.
A tidier formulation of at-titude dynamics should include both force and counterforce, reflecting the enforcement and the resistance to-ward an expressed attitude.
For example, in Folgersad, the "counter force" induced by $2 -- the inertia ofthe hearer not to be told what to do - can he over-corned by the (attracting) force expressed in $1 - thespeaker wants the hearer to know something important- and the force due to the common knowledge that theexperiment urged ill $2 can enable the attainment ofsuch knowledge.
Relating statements o psychologicalforces arc steps toward explaining the psychological re-ality of persuasive force and pressure.
Along this line,it is found that the work on "force dynamics" proposedin (Tahny 1988) is highly relevant.
We are currentlylooking into the relation between the two.Re ferencestlallim, A; Wilks, Y.; and Barnden, J.
1991.
Belief ascrip-tion, metaphor, and inteitsional identification.
CognitiveScience 15:133 171.Cohen, R. 1987.
Analyzing the structure of argumentativediscourse.
Computational Liguistlcs 13:11-23.l)insmore, J.
1987.
Mental spaces from a functional per~spective.
Cognitive Science 11:1-12.Fauconnier, G. 1985.
Mental spaces.
The MIT Press,Cambridge, MA.Gerlach, M. and Sprengerp M. 1988.
Semantic interpre-tation of pragmatic clues: Connective, modal verbs, andindirect speech acts.
In Proceddings of the Eleventh Inter.national Conference on Computational Linguistics.
191195.ltinkelman, E. and Allen, J.
1989.
Two constraints onspeech act ambiguity.
In Proceedings of the Twenty See.enth Annual Meeting of the Association for ComputationalLinguistics.
212-219.Kamps, H. 1981.
A theory of truth and semantic repre-sentation.
In Groenendijk, J.; Janssen, T.; and Stokhof,M., editors 1981, Formal methods in the study o\] language.Mathematish Centrum, Amsterdam.
277-322.Mann, W. and Thompson, S. 1988.
Rhetorical structuretheory: qbward a functional theory of text organization.Text 8:243-281.q'almy, L. 1988.
Force dynamics in language and cognition.Cognitive Science 12:49 100.Wilks, Y. and Ballim, A.
1987.
Multiple agents and heuris-tic ascription of belief, ht Proceedings of the Tenth hater-natior~al Joint Conference on Artificial Intelligence.
118-124.Wilks, Y. and Bien, J.
1979.
Speech acts and multipleenvironments.
In Proceedings of the Sith InternationalJoint Conference on Artificial Intelligence.Wilks, Y. and Bien, J.
1983.
Beliefs, points of view andmultiple environments.
Cognitive Sclence 8:120-146.Wilks, Y. and Hartley, A.
1990.
Belief ascription andmodel generative reasoning: joining two paradigms to arobust parser of messages.
In The 1990 DARPA Work-shop.
219-239.Wu, H-J.
and Lytinen, S. 1990.
Coherence reasoning inpersuasive discourse.
In Proceedings o\[ the Twelfth Con-ference of the Cognitive Science Society, Cambridge, Mas-sachusetts.
503-510.Wu, It-J.
and Lytinen, S. 1991.
Attitude and coherencereazoning in persuasive discourse.
In Proceedings of the1991 A A A 1 Spring Symposium on A tyumentation a d Be-lie\], Stanford, California.AL'rF.S DE COLING..92, NANTES, 23-28 ^ot"rr 1992 9 1 5 PROC.
OF COLING-92, NANTES, Aua.
23-28, 1992
