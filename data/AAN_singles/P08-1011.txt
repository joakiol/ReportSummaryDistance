Proceedings of ACL-08: HLT, pages 89?96,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsMeasure Word Generation for English-Chinese SMT SystemsDongdong Zhang1, Mu Li1, Nan Duan2, Chi-Ho Li1, Ming Zhou11Microsoft Research Asia 2Tianjin UniversityBeijing, China Tianjin, China{dozhang,muli,v-naduan,chl,mingzhou}@microsoft.comAbstractMeasure words in Chinese are used to indi-cate the count of nouns.
Conventional sta-tistical machine translation (SMT) systems donot perform well on measure word generationdue to data sparseness and the potential longdistance dependency between measure wordsand their corresponding head words.
In thispaper, we propose a statistical model to gen-erate appropriate measure words of nouns foran English-to-Chinese SMT system.
We mod-el the probability of measure word generationby utilizing lexical and syntactic knowledgefrom both source and target sentences.
Ourmodel works as a post-processing procedureover output of statistical machine translationsystems, and can work with any SMT system.Experimental results show our method canachieve high precision and recall in measureword generation.1 IntroductionIn linguistics, measure words (MW) are words ormorphemes used in combination with numerals ordemonstrative pronouns to indicate the count ofnouns1, which are often referred to as head words(HW).Chinese measure words are grammatical unitsand occur quite often in real text.
According to oursurvey on the measure word distribution in theChinese Penn Treebank and the test datasets distri-buted by Linguistic Data Consortium (LDC) forChinese-to-English machine translation evaluation,the average occurrence is 0.505 and 0.319 measure1 The uncommon cases of verbs are not considered.words per sentence respectively.
Unlike in Chinese,there is no special set of measure words in English.Measure words are usually used for mass nounsand any semantically appropriate nouns can func-tion as the measure words.
For example, in thephrase three bottles of water, the word bottles actsas a measure word.
Countable nouns are almostnever modified by measure words2.
Numerals andindefinite articles are directly followed by counta-ble nouns to denote the quantity of objects.Therefore, in the English-to-Chinese machinetranslation task we need to take additional effortsto generate the missing measure words in Chinese.For example, when translating the English phrasethree books into the Chinese phrases ????
?,where three corresponds to the numeral ???
andbooks corresponds to the noun ??
?, the Chinesemeasure word ???
should be generated betweenthe numeral and the noun.In most statistical machine translation (SMT)models (Och et al, 2004; Koehn et al, 2003;Chiang, 2005), some of measure words can begenerated without modification or additionalprocessing.
For example, in above translation, thephrase translation table may suggest the word threebe translated into ??
?, ???
?, ???
?, etc, andthe word books into ??
?, ???
?, ????
(scroll),etc.
Then the SMT model selects the most likelycombination ?????
as the final translation re-sult.
In this example, a measure word candidate setconsisting of ???
and ???
can be generated bybilingual phrases (or synchronous translation rules),and the best measure word ???
from the measure2 There are some exceptional cases, such as ?100 head of cat-tle?.
But they are very uncommon.89word candidate set can be selected by the SMTdecoder.
However, as we will show below, existingSMT systems do not deal well with the measureword generation in general due to data sparsenessand long distance dependencies between measurewords and their corresponding head words.Due to the limited size of bilingual corpora,many measure words, as well as the collocationsbetween a measure and its head word, cannot bewell covered by the phrase translation table in anSMT system.
Moreover, Chinese measure wordsoften have a long distance dependency to theirhead words which makes language model ineffec-tive in selecting the correct measure words fromthe measure word candidate set.
For example, inFigure 1 the distance between the measure word???
and its head word ????
(undertaking) is 15.In this case, an n-gram language model with n<15cannot capture the MW-HW collocation.
Table 1shows the relative position?s distribution of headwords around measure words in the Chinese PennTreebank, where a negative position indicates thatthe head word is to the left of the measure wordand a positive position indicates that the head wordis to the right of the measure word.
Although lotsof measure words are close to the head words theymodify, more than sixteen percent of measurewords are far away from their corresponding headwords (the absolute distance is more than 5).To overcome the disadvantage of measure wordgeneration in a general SMT system, this paperproposes a dedicated statistical model to generatemeasure words for English-to-Chinese translation.We model the probability of measure word gen-eration by utilizing rich lexical and syntacticknowledge from both source and target sentences.Three steps are involved in our method to generatemeasure words: Identifying the positions to gener-ate measure words, collecting the measure wordcandidate set and selecting the best measure word.Our method is performed as a post-processing pro-cedure of the output of SMT systems.
The advan-tage is that it can be easily integrated into any SMTsystem.
Experimental results show our method cansignificantly improve the quality of measure wordgeneration.
We also compared the performance ofour model based on different contextual informa-tion, and show that both large-scale monolingualdata and parallel bilingual data can be helpful togenerate correct measure words.Position Occurrence Position Occurrence1 39.5% -1 02 15.7% -2 03 4.7% -3 8.7%4 1.4% -4 6.8%5 2.1% -5 4.3%>5 8.8% <-5 8.0%Table 1.
Position distribution of head words2 Our Method2.1 Measure word  generation in ChineseIn Chinese, measure words are obligatory in cer-tain contexts, and the choice of measure wordusually depends on the head word?s semantics (e.g.,shape or material).
The set of Chinese measurewords is a relatively close set and can be classifiedinto two categories based on whether they have acorresponding English translation.
Those not hav-ing an English counterpart need to be generatedduring translation.
For those having English trans-lations, such as ???
(meter), ???
(ton), we justuse the translation produced by the SMT systemitself.
According to our survey, about 70.4% ofmeasure words in the Chinese Penn Treebank needFigure 1.
Example of long distance dependency between MW and its modified HW??/??/?
?/ ?/?
?
?Pudong 's de-velopment andopening up is a century-spanning/?/?
?/for vigorously promoting shanghaiand constructing a modern econom-ic , trade , and financial center  undertaking??/?
?/ ?/ ??
/???
/?
?/ ?/ ?
?/ ?
/?
?/ ?
?/ ?/?.
?90to be explicitly generated during the translationprocess.In Chinese, there are generally stable linguisticcollocations between measure words and their headwords.
Once the head word is determined, the col-located measure word can usually be selected ac-cordingly.
However, there is no easy way to identi-fy head words in target Chinese sentences since formost of the time an SMT output is not a wellformed sentence due to translation errors.
Mistakeof head word identification may cause low qualityof measure word generation.
In addition, some-times the head word itself is not enough to deter-mine the measure word.
For example, in Chinesesentences ????
5???
(there are five peoplein his family) and ????
5????????
(atotal of five people attended the meeting), where???
(people) is the head word collocated with twodifferent measure words ???
and ??
?, we cannotdetermine the measure word just based on the headword ??
?.2.2 FrameworkIn our framework, a statistical model is used togenerate measure words.
The model is applied toSMT system outputs as a post-processing proce-dure.
Given an English source sentence, an SMTdecoder produces a target Chinese translation, inwhich positions for measure word generation areidentified.
Based on contextual information con-tained in both input source sentence and SMT sys-tem?s output translation, a measure word candidateset M is constructed.
Then a measure word selec-tion model is used to select the best one from M.Finally, the selected measure word is inserted intopreviously determined measure word slot in theSMT system?s output, yielding the final translationresult.2.3 Measure word position identificationTo identify where to generate measure words in theSMT outputs, all positions after numerals aremarked at first since measure words often follownumerals.
For other cases in which measure wordsdo not follow numerals (e.g., ???
/?
/???
(many computers), where ???
is a measure wordand ????
(computers) is its head word), we justmine the set of words which can be followed bymeasure words from training corpus.
Most ofwords in the set are pronouns such as ???
(this),???
(that) and ????
(several).
In the SMT out-put, the positions after these words are also identi-fied as candidate positions to generate measurewords.2.4 Candidate measure word generationTo avoid high computation cost, the measure wordcandidate set only consists of those measure wordswhich can form valid MW-HW collocations withtheir head words.
We assume that all the surround-ing words within a certain window size centered onthe given position to generate a measure word arepotential head words, and require that a measureword candidate must collocate with at least one ofthe surrounding words.
Valid MW-HW colloca-tions are mined from the training corpus and a sep-arate lexicon resource.There is a possibility that the real head word isoutside the window of given size.
To address thisproblem, we also use a source window centered onthe position ps, which is aligned to the target meas-ure word position pt.
The link between ps and ptcan be inferred from SMT decoding result.
Thus,the chance of capturing the best measure word in-creases with the aid of words located in the sourcewindow.
For example, given the window size of 10,although the target head word ????
(undertaking)in Figure 1 is located outside the target window, itscorresponding source head word undertaking canbe found in the source window.
Based on thissource head word, the best measure word ???
willbe included into the candidate measure word set.This example shows how bilingual information canenrich the measure word candidate set.Another special word {NULL} is always in-cluded in the measure word candidate set.
{NULL}represents those measure words having a corres-ponding English translation as mentioned in Sec-tion 2.1.
If {NULL} is selected, it means that weneed not generate any measure word at the currentposition.
Thus, no matter what kinds of measurewords they are, we can handle the issue of measureword generation in a unified framework.2.5 Measure word selection modelAfter obtaining the measure word candidate set M,a measure word selection model is employed toselect the best one from M. Given the contextualinformation C in both source window and target91window, we model the measure word selection asfinding the measure word m* with highest post-erior probability given C:??
= argmax????(?|?)
(1)To leverage the collocation knowledge betweenmeasure words and head words, we extend (1) byintroducing a hidden variable h where H representsall candidate head words located within the targetwindow:??
= argmax???
?
?
(?, ?|?)??
?= argmax???
?
?(?|?)?
(?|?, ?)???
(2)In (2), ?(?|?)
is the head word selection proba-bility and is empirically estimated according to theposition distribution of head words in Table 1.?
(?|?, ?)
is the conditional probability of m givenboth h and C. We use maximum entropy model tocompute ?
(?|?, ?):?
(?|?, ?)
= exp(?
??
??(?,?)?
)?
exp(?
??
??(??,?)?
)????
(3)Based on the different features used in the com-putation of ?
(?|?, ?)
, we can train two sub-models ?
a monolingual model (Mo-ME) whichonly uses monolingual (Chinese) features and abilingual model (Bi-ME) which integrates bilingualfeatures.
The advantage of the Mo-ME model isthat it can employ an unlimited monolingual targettraining corpora, while the Bi-ME model leveragesrich features including both the source and targetinformation and may improve the precision.
Com-pared to the Mo-ME model, the Bi-ME model suf-fers from small scale of parallel training data.
Toleverage advantages of both models, we use acombined model Co-ME, by linearly combing themonolingual and bilingual sub-models:??
= argmax??????????
+ (1 ?
?)?????
?where ?
?
[0,1] is a free parameter that can be op-timized on held-out data and it was set to 0.39 inour experiments.2.6 FeaturesThe computation of Formula (3) involves the fea-tures listed in Table 2 where the Mo-ME modelonly employs target features and the Bi-ME modelleverages both target features and source features.For target features, n-gram language modelscore is defined as the sum of log n-gram probabil-ities within the target window after the measureword is filled into the measure word slot.
TheMW-HW collocation feature is defined to be afunction f1 to capture the collocation between ameasure word and a head word.
For features ofsurrounding words, the feature function f2 is de-fined as 1 if a certain word exists at a certain posi-tion, otherwise 0.
For example, f2(?,-2)=1 meansthe second word on the left is ???.
f2(?,3)=1means the third word on the right is ???.
Forpunctuation position feature function f3, the featurevalue is 1 when there is a punctuation followingthe measure word, which indicates the target headword may appear to the left of measure word.
Oth-erwise, it is 0.
In practice, we can also ignore theposition part, i.e., a word appears anywhere withinthe window is viewed as the same feature.Target features Source featuresn-gram language modelscoreMW-HW collocationMW-HW collocation surrounding wordssurrounding words source head wordpunctuation position POS tagsTable 2.
Features used in our modelFor source language side features, MW-HW col-location and surrounding words are used in a simi-lar way as does with target features.
The sourcehead word feature is defined to be a function f4 toindicate whether a word ei is the source head wordin English according to a parse tree of the sourcesentence.
Similar to the definition of lexical fea-tures, we also use a set of features based on POStags of source language.3 Model Training and Application3.1 TrainingWe parsed English and Chinese sentences to gettraining samples for measure word generationmodel.
Based on the source syntax parse tree, foreach measure word, we identified its head word byusing a toolkit from (Chiang and Bikel, 2002)which can heuristically identify head words forsub-trees.
For the bilingual corpus, we also per-form word alignment to get correspondences be-tween source and target words.
Then, the colloca-tion between measure words and head words andtheir surrounding contextual information are ex-tracted to train the measure word selection models.According to word alignment results, we classify92measure words into two classes based on whetherthey have non-null translations.
We map Chinesemeasure words having non-null translations to aunified symbol {NULL} as mentioned in Section2.4, indicating that we need not generate these kindof measure words since they can be translated fromEnglish.In our work, the Berkeley parser (Petrov andKlein, 2007) was employed to extract syntacticknowledge from the training corpus.
We ran GI-ZA++ (Och and Ney, 2000) on the training corpusin both directions with IBM model 4, and then ap-plied the refinement rule described in (Koehn et al,2003) to obtain a many-to-many word alignmentfor each sentence pair.
We used the SRI LanguageModeling Toolkit (Stolcke, 2002) to train a five-gram model with modified Kneser-Ney smoothing(Chen and Goodman, 1998).
The Maximum Entro-py training toolkit from (Zhang, 2006) was em-ployed to train the measure word selection model.3.2 Measure word generationAs mentioned in previous sections, we apply ourmeasure word generation module into SMT outputas a post-processing step.
Given a translation froman SMT system, we first determine the position ptat which to generate a Chinese measure word.
Cen-tered on pt, a surrounding word window with spe-cified size is determined.
From translation align-ments, the corresponding source position ps alignedto pt can be referred.
In the same way, a sourcewindow centered on ps is determined as well.
Then,contextual information within the windows in thesource and the target sentence is extracted and fedto the measure word selection model.
Meanwhile,the candidate set is obtained based on words inboth windows.
Finally, each measure word in thecandidate set is inserted to the position pt, and itsscore is calculated based on the models presentedin Section 2.5.
The measure word with the highestprobability will be chosen.There are two reasons why we perform measureword generation for SMT systems as a post-processing step.
One is that in this way our methodcan be easily applied to any SMT system.
The oth-er is that we can leverage both source and targetinformation during the measure word generationprocess.
We do not integrate our measure wordgeneration module into the SMT decoder sincethere is only little target contextual informationavailable during SMT decoding.
Moreover, as wewill show in experiment section, a pre-processingmethod does not work well when only source in-formation is available.4 Experiments4.1 DataIn the experiments, the language model is a Chi-nese 5-gram language model trained with the Chi-nese part of the LDC parallel corpus and the Xin-hua part of the Chinese Gigaword corpus withabout 27 million words.
We used an SMT systemsimilar to Chiang (2005), in which FBIS corpus isused as the bilingual training data.
The trainingcorpus for Mo-ME model consists of the ChinesePeen Treebank and the Chinese part of the LDCparallel corpus with about 2 million sentences.
TheBi-ME model is trained with FBIS corpus, whosesize is smaller than that used in Mo-ME modeltraining.We extracted both development and test data setfrom years of NIST Chinese-to-English evaluationdata by filtering out sentence pairs not containingmeasure words.
The development set is extractedfrom NIST evaluation data from 2002 to 2004, andthe test set consists of sentence pairs from NISTevaluation data from 2005 to 2006.
There are 759testing cases for measure word generation in ourtest data consisting of 2746 sentence pairs.
We usethe English sentences in the data sets as input tothe SMT decoder, and apply our proposed methodto generate measure words for the output from thedecoder.
Measure words in Chinese sentences ofthe development and test sets are used as refer-ences.
When there are more than one measurewords acceptable at some places, we manuallyaugment the references with multiple acceptablemeasure words.4.2 BaselineOur baseline is the SMT output where measurewords are generated by a Hiero-like SMT decoderas discussed in Section 1.
Due to noises in the Chi-nese translations introduced by the SMT system,we cannot correctly identify all the positions togenerate measure words.
Therefore, besides preci-sion we examine recall in our experiments.4.3 Evaluation over SMT outputTable 3 and Table 4 show the precision and recallof our measure word generation method.
From the93experimental results, the Mo-ME, Bi-ME and Co-ME models all outperform the baseline.
Comparedwith the baseline, the Mo-ME method takes advan-tage of a large size monolingual training corpusand reduces the data sparseness problem.
The ad-vantage of the Bi-ME model is being able to makefull use of rich knowledge from both source andtarget sentences.
Also as shown in Table 3 and Ta-ble 4, the Co-ME model always achieve the bestresults when using the same window size since itleverages the advantage of both the Mo-ME andthe Bi-ME models.Wsize Baseline Mo-ME Bi-ME Co-ME654.82%64.29% 67.15%  67.66%8 64.93% 68.50%  69.00%10 64.72% 69.40% 69.58%12 65.46% 69.40% 69.76%14 65.61% 69.69%  70.03%Table 3.
Precision over SMT outputWsize Baseline Mo-ME Bi-ME Co-ME645.61%51.48% 53.69%  54.09%8 51.98% 54.75%  55.14%10 51.81% 55.44% 55.58%12 52.38% 55.44% 55.72%14 52.50% 55.67%  55.93%Table 4.
Recall over SMT outputWe can see that the Bi-ME model can achievebetter results than the Mo-ME model in both recalland precision metrics although only a small sizedbilingual corpus is used for Bi-ME model training.The reason is that the Mo-ME model cannot cor-rectly handle the cases where head words are lo-cated outside the target window.
However, due toword order differences between English and Chi-nese, when target head words are outside the targetwindow, their corresponding source head wordsmight be within the source window.
The capacityof capturing head words is improved when bothsource and target windows are used, which demon-strates that bilingual knowledge is useful for meas-ure word generation.We compare the results for each model with dif-ferent window sizes.
Larger window size can leadto better results as shown in Table 3 and Table 4since more contextual knowledge is used to modelmeasure word generation.
However, enlarging thewindow size does not bring significant improve-ments, The major reason is that even a small win-dow size is already able to cover most of measureword collocations, as indicated by the position dis-tribution of head words in Table 1.The quality of the SMT output also affects thequality of measure word generation since our me-thod is performed in a post-processing step overthe SMT output.
Although translation errors de-grade the measure word generation accuracy, weachieve about 15% improvement in precision and a10% increase in recall over baseline.
We noticethat the recall is relatively lower.
Part of the reasonis some positions to generate measure words arenot successfully identified due to translation errors.In addition to precision and recall, we also evaluatethe Bleu score (Papineni et al, 2002) changes be-fore and after applying our measure word genera-tion method to the SMT output.
For our test data,we only consider sentences containing measurewords for Bleu score evaluation.
Our measureword generation step leads to a Bleu score im-provement of 0.32 where the window size is set to10, which shows that it can improve the translationquality of an English-to-Chinese SMT system.4.4 Evaluation over reference dataTo isolate the impact of the translation errors inSMT output on the performance of our measureword generation model, we conducted another ex-periment with reference bilingual sentences inwhich measure words in Chinese sentences aremanually removed.
This experiment can show theperformance upper bound of our method withoutinterference from an SMT system.
Table 5 showsthe results.
Compared to the results in Table 3, theprecision improvement in the Mo-ME model islarger than that in the Bi-ME model, which showsthat noisy translation of the SMT system has moreserious influence on the Mo-ME model than theBi-ME model.
This also indicates that source in-formation without noises is helpful for measureword generation.Wsize Mo-ME Bi-ME Co-ME6 71.63% 74.92% 75.72%8 73.80% 75.48% 76.20%10 73.80% 74.76% 75.48%12 73.80% 75.24% 75.96%14 73.56% 75.48% 76.44%Table 5.
Results over reference data944.5 Impacts of featuresIn this section, we examine the contribution ofboth target language based features and sourcelanguage based features in our model.
Table 6 andTable 7 show the precision and recall when usingdifferent features.
The window size is set to 10.
Inthe tables, Lm denotes the n-gram language modelfeature, Tmh denotes the feature of collocation be-tween target head words and the candidate measureword, Smh denotes the feature of collocation be-tween source head words and the candidate meas-ure word, Hs denotes the feature of source headword selection, Punc denotes the feature of targetpunctuation position, Tlex denotes surroundingword features in translation, Slex denotes surround-ing word features in source sentence, and Pos de-notes Part-Of-Speech feature.Feature setting Precision RecallBaseline 54.82% 45.61%Lm 51.11% 41.24%+Tmh 61.43% 49.22%+Punc 62.54% 50.08%+Tlex 64.80% 51.87%Table 6.
Feature contribution in Mo-ME modelFeature setting Precision RecallBaseline 54.82% 45.61%Lm 51.11% 41.24%+Tmh+Smh 64.50% 51.64%+Hs 65.32% 52.26%+Punc 66.29% 53.10%+Pos 66.53% 53.25%+Tlex 67.50% 54.02%+Slex 69.52% 55.54%Table 7.
Feature contribution in Bi-ME modelThe experimental results show that all the fea-tures can bring incremental improvements.
Themethod with only Lm feature performs worse thanthe baseline.
However, with more features inte-grated, our method outperforms the baseline,which indicates each kind of features we selectedis useful for measure word generation.
Accordingto the results, the feature of MW-HW collocationhas much contribution to reducing the selectionerror of measure words given head words.
Thecontribution of Slex feature explains that other sur-rounding words in source sentence are also helpfulsince head word determination in source languagemight be incorrect due to errors in English parsetrees.
Meanwhile, the contribution from Smh, Hsand Slex features demonstrates that bilingualknowledge can play an important role for measureword generation.
Compared with lexicalized fea-tures, we do not get much benefit from the Posfeatures.4.6 Error analysisWe conducted an error analysis on 100 randomlyselected sentences from the test data.
There arefour major kinds of errors as listed in Table 8.Most errors are caused by failures in finding posi-tions to generate measure words.
The main reasonfor this is some hint information used to identifymeasure word positions is missing in the noisyoutput of SMT systems.
Two kinds of errors areintroduced by incomplete head word and MW-HWcollocation coverage, which can be solved by en-larging the size of training corpus.
There are alsohead word selection errors due to incorrect syntaxparsing.Error type Ratiounseen head word  32.14%unseen MW-HW collocation 10.71%missing MW position 39.29%incorrect HW selection 10.71%others 7.14%Table 8.
Error distribution4.7 Comparison with other methodsIn this section we compare our statistical methodswith the pre-processing method and the rule-basedmethods for measure word generation in a transla-tion task.In pre-processing method, only source languageinformation is available.
Given a source sentence,the corresponding syntax parse tree Ts is first con-structed with an English parser.
Then the pre-processing method chooses the source head wordhs based on Ts.
The candidate measure word withthe highest probability collocated with hs is se-lected as the best result, where the measure wordcandidate set corresponding to each head word ismined over a bilingual training corpus in advance.We achieved precision 58.62% and recall 49.25%,which are worse than the results of our post-processing based methods.
The weakness of thepre-processing method is twofold.
One problem isdata sparseness with respect to collocations be-95tween English head words and Chinese measurewords.
The other problem comes from the Englishhead word selection error introduced by usingsource parse trees.We also compared our method with a well-known rule-based machine translation system ?SYSTRAN3.
We translated our test data with SY-STRAN?s English-to-Chinese translation engine.The precision and recall are 63.82% and 51.09%respectively, which are also lower than our method.5 Related WorkMost existing rule-based English-to-Chinese MTsystems have a dedicated module handling meas-ure word generation.
In general a rule-based me-thod uses manually constructed rule patterns topredict measure words.
Like most rule based ap-proaches, this kind of system requires lots of hu-man efforts of experienced linguists and usuallycannot easily be adapted to a new domain.
Themost relevant work based on statistical methods toour research might be statistical technologies em-ployed to model issues such as morphology gener-ation (Minkov et al, 2007).6 Conclusion and Future WorkIn this paper we propose a statistical model formeasure word generation for English-to-ChineseSMT systems, in which contextual knowledgefrom both source and target sentences is involved.Experimental results show that our method not on-ly achieves high precision and recall for generatingmeasure words, but also improves the quality ofEnglish-to-Chinese SMT systems.In the future, we plan to investigate more fea-tures and enlarge coverage to improve the qualityof measure word generation, especially reduce theerrors found in our experiments.AcknowledgementsSpecial thanks to David Chiang, Stephan Stillerand the anonymous reviewers for their feedbackand insightful comments.ReferencesStanley F. Chen and Joshua Goodman.
1998.
An Empir-ical study of smoothing techniques for language3 http://www.systransoft.com/modeling.
Technical Report TR-10-98, Harvard Uni-versity Center for Research in Computing Technolo-gy, 1998.David Chiang and Daniel M. Bikel.
2002.
Recoveringlatent information in treebanks.
Proceedings of COL-ING '02, 2002.David Chiang.
2005.
A hierarchical phrase-based mod-el for statistical machine translation.
In Proceedingsof ACL 2005, pages 263-270.Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedings ofHLT-NAACL 2003, pages 127-133.Einat Minkov, Kristina Toutanova, and Hisami Suzuki.2007.
Generating complex morphology for machinetranslation.
In Proceedings of 45th Annual Meetingof the ACL, pages 128-135.Franz J. Och and Hermann Ney.
2000.
Improved statis-tical alignment models.
In Proceedings of 38th An-nual Meeting of the ACL, pages 440-447.Franz J. Och and Hermann Ney.
2004.
The alignmenttemplate approach to statistical machine translation.Computational Linguistics, 30:417-449.Kishore Papineni, Salim Roukos, ToddWard, and WeiJ-ing Zhu.
2002.
BLEU: a method for automatic evalu-ation of machine translation.
In Proceedings of 40thAnnual Meeting of the ACL, pages 311-318.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of HLT-NAACL, 2007.Andreas Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proceedings of InternationalConference on Spoken Language Processing, volume2, pages 901-904.Le Zhang.
MaxEnt toolkit.
2006. http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html96
