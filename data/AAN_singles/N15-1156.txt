Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1380?1385,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsCASSA: A Context-Aware Synonym Simplification AlgorithmRicardo Baeza-YatesYahoo Labs &Web Research GroupUniversitat Pompeu Fabra,Barcelona, Spainrbaeza@acm.orgLuz RelloHuman-Computer Interaction InstituteCarnegie Mellon UniversityPittsburgh, PA, USAluzrello@acm.orgJulia DembowskiDepartment ofComputational LinguisticsSaarland University, Germanyjuliad@coli.uni-saarland.deAbstractWe present a new context-aware method forlexical simplification that uses two free lan-guage resources and real web frequencies.
Wecompare it with the state-of-the-art method forlexical simplification in Spanish and the es-tablished simplification baseline, that is, themost frequent synonym.
Our method im-proves upon the other methods in the detectionof complex words, in meaning preservation,and in simplicity.
Although we use Spanish,the method can be extended to other languagessince it does not require alignment of parallelcorpora.1 IntroductionSimplified text is crucial for some populations toread effectively, especially for cognitively impairedpeople such as people with autism spectrum disor-der (Evans et al, 2014; Orasan et al, 2013), aphasia(Carroll et al, 1999), dyslexia (Rello et al, 2013a),Down syndrome (Saggion et al, 2015; Saggion etal., 2011), or other intellectual disabilities (Huener-fauth et al, 2009).In fact, the United Nations (1994) proposed a setof standard rules to leverage document accessibilityfor persons with disabilities.
Text simplification at-tempts to solve this problem automatically by reduc-ing the complexity of the lexicon, syntax, or seman-tics while attempting to preserve its meaning and in-formation content (Siddharthan, 2006).
Among allthe types of text simplification this paper focuses onlexical simplification.Lexical simplification methods require languageresources, such as simplified corpora or synonymsdictionaries.
For languages with less resources thanEnglish, e.g.
no Simple Wikipedia (Biran et al,2011; Yatskar et al, 2010) or less representation inWordNet, such as Spanish,1the creation of lexicalsimplification methods is more challenging.Our approach makes use of two free resources,Google Books Ngram Corpus and the SpanishOpenThesaurus, as well as real web frequencies tocreate a lexical simplification system.
Our systemimproves upon the state of the art for lexical simpli-fication in Spanish and the established simplificationbaseline, i.e., the most frequent synonym, in severalaspects: complex word detection, meaning preser-vation, and simplicity.
We also show the coverageof our technique in a collection of books in Spanish,as this is another relevant measure of a simplifica-tion algorithm.
The method is language independentand given that these resources are available in otherlanguages, it could be easily extended to other lan-guages with similar language resources.The rest of the paper is organized as follows.
Thenext section presents related work.
Then in Section 3we present the simplification algorithm while in Sec-tions 4 and 5 we present our experimental evalua-tion.
Finally, in Section 6 we discuss our results, ex-tensions to other languages, and outline future work.1The Spanish part of EuroWordNet contains only 50,526word meanings and 23,370 synsets, in comparison to 187,602meanings and 94,515 synsets in the English WordNet 1.5.
(Vossen, 2004).13802 Related WorkLexical simplification is a kind of text simplificationthat aims at the word level.
It can be performedthrough the substitution of words by simpler syn-onyms, by adding a definition, or by showing sim-pler synonyms.
Most of the approaches aim at thesubstitution of complex words.To find appropriate synonyms, many approachesuse WordNet (Burstein et al, 2007; Carroll et al,1999; Lal and Ruger, 2002).
De Belder et al(2010) apply explicit word sense disambiguationwith a latent words language model.
Devlin and Un-thank (2006) use dictionaries.
Aluisio and Gasperin(2010) use a thesaurus and lexical ontologies.More recently, Biran et al (2011) and Yatskaret al (2010) used Simple English Wikipedia, incombination with the standard English Wikipediafor their lexical simplification algorithms using ma-chine learning.There are also machine translation based ap-proaches (Coster and Kauchak, 2011; Specia, 2010)as well as hybrid approaches (Narayan and Gardent,2014; Siddharthan and Angrosh, 2014) that are alsoable to handle lexical simplification, since the trans-lation model maps words from the non-simplifiedlanguage to words of the simplified language.The closest algorithm to ours is LexSiS (Bott etal., 2012; Saggion et al, 2013), that uses the Span-ish OpenThesaurus and a corpus that contains 6,595words of original and 3,912 words of manually sim-plified news articles.
To the best of our knowledgethis is the first and only lexical simplification algo-rithm for Spanish.
Hence, we use it here as the state-of-the-art in our evaluation.To the best of our knowledge, our approach isnovel in using the Google Books Ngram corpusfor the word context, Open Thesaurus for the syn-onyms, and real web frequencies for disambiguat-ing synonym candidates.
However, Google Ngramhave been previously used to find synonyms, forinstance to expand user queries by including syn-onyms (Baker and Lamping, 2011).3 MethodCASSA (Context-Aware Synonym SimplificationAlgorithm) is a method that generates simpler syn-onyms of a word.
It takes into consideration the con-text and the web frequency of the complex word fordisambiguation.3.1 ResourcesOur method uses the following two resources:?
Spanish OpenThesaurus (version 2): Thethesaurus is freely available2to be usedwith OpenOffice.org.
This thesaurus provides21,378 target words (lemmas) with a total of44,348 different word senses for them.
Thefollowing is a part of the thesaurus entry forfarol, which is ambiguous, as it could mean?lie?, ?lamp?, or the adjective ?flashy?, amongothers.farol- embuste|mentira (?lie?
)- luz|l?ampara|fuego|bombilla(?lamp?
)- ostentoso|jactancioso|farolero(?flashy?)?
Google Books Ngram Corpus for Spanish(2012 edition): The corpus consists of n-gramsand their usage frequency over time,3and isderived from 8,116,746 books, over 6% of allbooks ever published.
The corpus has 854,649volumes and 83,967,471,303 tokens (Lin et al,2012).3.2 Algorithm DescriptionFirst, we modified and enriched the SpanishOpenThesaurus and created our List of Senses.
In-stead of having a target word with different senses,we included the target word in each sense, and wekept a list of unique senses, including for each wordits frequency in the Web using a large search engineindex.
The Spanish OpenThesaurus contains single-word and multi-word expressions.
We only treatedsingle-word units, which represent 98% of the cases,leaving out only 399 multi-word expressions, suchas de esta forma (?in this manner?
).We lemmatized the words because the frequen-cies were all for inflected word forms as they ap-pear in the Web while we were interested in thelemma frequencies for the synonyms, adding all the2http://openthes-es.berlios.de3http://books.google.com/ngrams1381frequencies for each lemma.
We take into accountthe frequency of the words, because previous stud-ies have shown that less frequent words were foundto be more challenging for people with and withoutthe most frequent reading disorder, that is, dyslexia(Rello et al, 2013b).Second, we use the 5-grams in the Google BooksNgram Corpus, where we use the third token of each5-gram as our target words.
The other tokens are thecontext of the target word.
A context is consideredvalid if all words, including the target word, consistonly of lowercase alphabetic characters, to filter forproper names, and is not a stop word, using a stan-dard list of stop words in Spanish.The lemmatized token is included in the list oftarget words only if it appears in our List of Senses.The remaining four tokens are the context, kept ina context list.
We count the frequency of the targetword appearing with that context in the corpus, aswell as the frequency of the same context appearingwith different target words.
See two possible con-texts for noche and fortuna in the examples below:era una noche oscura de (?it was a dark night of?
)de probar fortuna en el (?to try fortune in the?
)Third, we define the complexity of a word usingthe relative frequency of the synonyms within thesame sense in the List of Senses.That is, our definition is tailored to web text.
Forthis we use a parameter k such that if a word is kor more times less frequent than one or more of itssynonyms, is considered a complex word.
We usedk = 10 as the default threshold to get that 27% ofthe words have simpler synonyms.
We later showhow this percentage changes with smaller k.Finally, for each complex word and the contextsit appears in, we select as simpler synonym themost frequent synonym of the sense that appearsmost frequently for the n-gram corresponding to that(word, context) pair.
That is, to disambiguate thesense, our method uses the context where the targetword appears.
If the context is not found, we use themost frequent sense (baseline below).4 Quality Evaluation4.1 Comparison PointsBaseline: replaces a word with its most frequentsynonym (presumed to be the simplest).
This base-Original?El contemplaba en silencio aquella cruz.He was contemplating in silence that cross.Baseline?El ve?
?a en silencio aquella cruz.He was seeing in silence that cross.LexSis?El consideraba en silencio aquella cruz.He was considering in silence that cross.CASSA?El miraba en silencio aquella cruz.He was looking in silence that cross.Figure 1: Example of substitutions performed by thethree algorithms.line has been broadly used in previous lexical sim-plification studies (Burstein et al, 2007; Carroll etal., 1999; Devlin and Unthank, 2006; Lal and Ruger,2002), with the exception of (Bott et al, 2012) thatused word frequency and length.
It is very hard tobeat this baseline for simpler synonyms generation.For instance, in SemEval task for English lexicalsimplification (Specia et al, 2012), only one sys-tem out of nine outperformed the frequency base-line.
For the complexity part we use the same as ournew method.
That is, both algorithms consider thesame words as complex.LexSiS: replaces a word with the output of thestate-of-the-art method for Spanish lexical simplifi-cation (Bott et al, 2012).4.2 Frequency BandsWe divided the selected complex words methodsinto two groups: [LOW], that includes very lowfrequency complex words, and [HIGH], that con-tains high frequency complex words.
The wordfrequency ranges from 40 to 2,000 occurrences inGoogle Books Ngram Corpus for the [LOW] group,and from 2,001 to 1,300,000 for the [HIGH] group.4.3 Evaluation DatasetsMain dataset: From a set of texts of scientific andliterature genres (37,876 words), we randomly se-lected 20 [LOW] and 20 [HIGH] complex wordswithin the sentence they appear, together with theircorresponding candidate for substitution generatedby the Baseline, LexSiS, and ours (a valid sentencemust had at least 2 different substitutions).
We hadin total 120 simplification examples (composed byan original and a simplified sentence).
Figure 11382shows a set of substitutions along with the originalsentence.Similar studies had smaller or slightly larger eval-uation data sets.
In Yatskar et al (2010), 200simplification examples were rated by six annota-tors (three native, three non-native speakers of En-glish), although only the native speakers annotationswere used for the results because they yielded higherinter-annotator agreement.
Biran et al (2011) used130 examples that were judged by three annotators(native English speakers).
In Bott et al (2012), threeannotators (native speakers of Spanish) rated 69 sen-tences each of the Spanish lexical simplification per-formed by LexSiS.Complexity dataset: This dataset was created toevaluate the degree of complexity of the words se-lected by the algorithms.
Using the same texts asbefore we extracted 40 random complex words ac-cording to LexSiS and 40 according to our method(recall that those also are complex for the baseline).4.4 Judgment GuidelinesWe presented the 200 examples in two different on-line tests, one for each evaluation dataset.
The exam-ples were presented in random order to three nativeSpanish speakers, frequent readers and non-authorsof this paper.
For the Main Dataset each annota-tor rated the simplification examples on two scales:Meaning Preservation ?does the transformation pre-serve the original meaning of the sentence (yes/no);and Simplification ?does the transformation result ina simpler sentence (more complex, same complexityor simpler).
For the Complexity Dataset the annota-tors rated the examples on a three point scale (com-plex, neither complex or simple and simple).We used Fleiss Kappa (Fleiss, 1971) to measurethe inter-annotator agreement for multiple raters.We obtained a reasonable agreement: 0.46 for mean-ing preservation, 0.54 for simplicity ratings, and0.41 for complexity.
Hence, we have a moderateagreement (Landis and Koch, 1977), comparablewith agreements in related literature (Biran et al,2011; Bott et al, 2012; Yatskar et al, 2010).4.5 ResultsIn Table 1 we show the results for the Main Dataset,where in the last column we consider only the sim-Type Mean.
(%) Simp.
(%) SimpSyn.
(%)Baseline 49.17 60.00 65.08LexSiS 42.50 35.83 45.83CASSA 74.17 70.83 77.08Table 1: Average percentage scores in meaning preser-vation (Mean.
), simplification (Simp.
), and simplificationamong the synonyms (SimpSyn.
).pler synonym substitutions (21 for Baseline, 16 forLexSiS, and 32 for ours) that preserved their mean-ing (agreement of 2 annotators).
In this case, thesimplicity performance improves for all the meth-ods.
In Table 2 we give the results for the two bandfrequencies for meaning preservation and simplicity.In the dataset our method overlaps in 15.79% withLexSiS candidates and in 65.79% with the baseline.The results of LexSiS are consistent with the onespresented in Bott et al (2012) for the news genre.In that study only for one dataset among three im-proved upon the frequency baseline in some mea-sures (meaning preservation and global simplicity).As it can be observed from the frequency band re-sults and the complexity measure, LexSiS offers bet-ter synonyms for high frequency and not for low fre-quency words.
On the other hand, our method im-proves with low frequency complex words.In the complexity evaluation, the prediction accu-racy for complex words was only 13.33% for Lex-Sis while was more than double, 34.17%, for ours(idem for the baseline as it used the same complex-ity criteria).
The percentages for the complexityare low as the annotators were regular readers andnon-impaired native speakers.
For people with lan-guage difficulties or cognitive disabilities the accu-racy should be higher because people which cogni-tive disabilities are more sensitive to text simplifi-cations, such as people with Down Syndrome (Sag-gion et al, 2015), dyslexia (Rello and Baeza-Yates,2014), or mild intellectual disabilities (Huenerfauthet al, 2009).5 Coverage EvaluationAs not all possible contexts appear in Google BooksNgrams, we created a corpus made of 195 classicliterature books from the 15th century to the 20thcentury of over 100Mb, to check the coverage of our1383Type Freq.
Meaning (%) Simp.
(%)Baseline [HIGH] 40.00 58.33LexSiS [HIGH] 41.67 36.67CASSA [HIGH] 73.33 70.00Baseline [LOW] 58.33 61.67LexSiS [LOW] 43.33 35.00CASSA [LOW] 75.00 71.67Table 2: Average percentage scores by frequency band.Case k = 10 k = 5 k = 2 No kComp.
words 27.16 38.80 54.24 100.00Baseline (abs.)
24.07 35.32 50.14 84.43Baseline (rel.)
88.62 91.03 92.04 84.43Comp.
contexts 27.95 40.03 55.84 100.00CASSA (abs.)
2.67 4.14 6.44 12.14CASSA (rel.)
9.55 10.34 11.53 12.14Table 3: Coverage of the baseline and our method.method.
We included the books that are compulsoryreadings for secondary and high school in Spain.This corpus is composed by 16,495,885 tokens and5,886,366 lexical words (without stop words, propernames and punctuation marks).4The coverage of the Spanish Open Thesaurus inour corpus is 88.34%.5This is the maximum thatany simplification algorithm that uses this resourcecan obtain.
In Table 3 we present the coverage of thebaseline and our method depending on the thresholdk used to decide what a complex word is and hence acomplex content, including the absolute percentagesas well as the relative percentages with respect to thecomplex words or contexts.For smaller k, the coverage of the baseline in-creases significantly being the maximum possible84.43% when all words are considered complex(more than three times the default coverage).
Onthe other hand, our method does not increase muchthe coverage as that is limited by the context cov-erage reaching a maximum of 12.14%, only 27%more than the default case (k = 10).
This maxi-mum, compared with the baseline is a bit more than14% of the cases, implying that our method is equalto the baseline around 85% of the time.4All the book titles used for this corpus are given in the Ap-pendix of Rello (2014).5Note that this only applies to the corpus used in the cover-age, not for the evaluation dataset.Considering the maximum possible coverage ofthe baseline and assuming that all non covered sen-tences contain complex words (most probable case),the simplicity performance of the baseline drops to53.1% while for ours would be 54.2% (that is, a2.1% improvement).
This should improve if any ofthe resources used grow.6 Conclusions and Future WorkOur method improves upon LexSiS and the base-line for all the measures.
As we mentioned earlier,even beating the baseline is very hard and we im-prove upon both other methods by more than 50%in meaning preservation and is 11.8% better than thebaseline, the second best, for simplicity.
Comparedto the results for English of Biran et al (2011) usingWordNet, our method has better simplicity scoresfor low frequency words as well as is in meaningpreservation, although they are not directly compa-rable as different resources are used.Although Open Thesaurus is available in nine lan-guages and Google Books Ngrams in seven, thereare only two languages in both sets: Spanish andGerman.
Hence our method should be easily ex-tended to German.
Other languages are also possiblewith language resources, in particular English.AcknowledgmentsWe thank Diego Saez-Trumper, Eduardo Graells andMiguel Ballesteros for their suggestions in the im-plementation of CASSA.ReferencesS.
M.
Alu?
?sio and C. Gasperin.
2010.
Fosteringdigital inclusion and accessibility: the PorSimplesproject for simplification of Portuguese texts.
In Proc.NAACL HLT ?10 Workshop YIWCALA ?10, pages 46?53, Stroudsburg, PA, USA.S.
D. Baker and J. O. Lamping.
2011.
Identifying a syn-onym with n-gram agreement for a query phrase.
USPatent 7,925,498.O.
Biran, S. Brody, and N. Elhadad.
2011.
Putting itsimply: a context-aware approach to lexical simpli-fication.
In Proc.
ACL?11, pages 496?501, Portland,Oregon, USA.S.
Bott, L. Rello, B. Drndarevic, and H. Saggion.
2012.Can Spanish be simpler?
LexSiS: Lexical simplifica-tion for Spanish.
In Proc.
Coling ?12, Mumbay, India.1384J.
Burstein, J.
Shore, J. Sabatini, Yong-Won Lee, andM.
Ventura.
2007.
The automated text adaptation tool.(demo).
In Proc.
NAACL?07, pages 3?4.J.
Carroll, G. Minnen, D. Pearce, Y. Canning, S. De-vlin, and J. Tait.
1999.
Simplifying text for language-impaired readers.
In Proc.
EACL ?09, pages 269?270.W.
Coster and D. Kauchak.
2011.
Learning to sim-plify sentences using wikipedia.
In Proceedings ofthe Workshop on Monolingual Text-To-Text Genera-tion, pages 1?9.
Association for Computational Lin-guistics.J.
De Belder, K. Deschacht, and Marie-Francine Moens.2010.
Lexical simplification.
In Proceedings ofLTEC 2010: 1st International Conference on Inter-disciplinary Research on Technology, Education andCommunication.S.
Devlin and G. Unthank.
2006.
Helping aphasic peo-ple process online information.
In Proc.
ASSETS ?06,pages 225?226.
ACM.R.
Evans, C. Orasan, and I. Dornescu.
2014.
Anevaluation of syntactic simplification rules for peoplewith autism.
In Proceedings of the 3rd Workshop onPredicting and Improving Text Readability for TargetReader Populations (PITR) at EACL, pages 131?140.J.
L. Fleiss.
1971.
Measuring nominal scale agree-ment among many raters.
Psychological Bulletin,76(5):378?382.M.
Huenerfauth, L. Feng, and N. Elhadad.
2009.
Com-paring evaluation techniques for text readability soft-ware for adults with intellectual disabilities.
In Proc.ASSETS ?09, pages 3?10.
ACM.P.
Lal and S. Ruger.
2002.
Extract-based summarizationwith simplification.
In Proceedings of the ACL 2002Automatic Summarization / DUC 2002 Workshop.J.R.
Landis and G.G.
Koch.
1977.
The measurement ofobserver agreement for categorical data.
Biometrics,pages 159?174.Y.
Lin, J-B.
Michel, A. E. Lieberman, J. Orwant,W.
Brockman, and S. Petrov.
2012.
Syntactic anno-tations for the Google books ngram corpus.
(demo).In Proc.
ACL?12, pages 169?174.S.
Narayan and C. Gardent.
2014.
Hybrid simplifica-tion using deep semantics and machine translation.
InACL?14, pages 435?445.United Nations.
1994.
Standard Rules on the Equaliza-tion of Opportunities for Persons with Disabilities.C.
Orasan, R. Evans, and I. Dornescu, 2013.
TowardsMultilingual Europe 2020: A Romanian Perspective,chapter Text Simplification for People with Autis-tic Spectrum Disorders, pages 287?312.
RomanianAcademy Publishing House, Bucharest.L.
Rello and R. Baeza-Yates.
2014.
Evaluation ofDyswebxia: A reading app designed for people withdyslexia.
In Proc.
W4A ?14, Seoul, Korea.L.
Rello, R. Baeza-Yates, S. Bott, and H. Saggion.
2013a.Simplify or help?
Text simplification strategies forpeople with dyslexia.
In Proc.
W4A ?13, Rio deJaneiro, Brazil.L.
Rello, R. Baeza-Yates, L. Dempere, and H. Sag-gion.
2013b.
Frequent words improve readability andshort words improve understandability for people withdyslexia.
In Proc.
INTERACT ?13, Cape Town, SouthAfrica.L.
Rello.
2014.
DysWebxia.
A Text Accessibility Modelfor People with Dyslexia.
Ph.D. thesis, UniversitatPompeu Fabra.H.
Saggion, E.
G?omez-Mart?
?nez, E. Etayo, A. Anula,and L. Bourg.
2011.
Text Simplification in Simplext:Making Text More Accessible.
Revista de la SociedadEspa?nola para el Procesamiento del Lenguaje Natural(Journal of the Spanish Society for Natural LanguageProcessing), 47.H.
Saggion, S. Bott, and L. Rello.
2013.
Comparingresources for Spanish lexical simplification.
In SLSP2013: Statistical Language and Speech Processing,volume 7978 of Lecture Notes in Computer Science,pages 236?247.H.
Saggion, S.?Stajner, S. Bott, S. Mille, L. Rello, andB.
Drndarevic.
2015.
Making it simplext: Implemen-tation and evaluation of a text simplification system forspanish.
ACM Transactions on Accessible Computing(TACCESS), In Press.A.
Siddharthan and M.A.
Angrosh.
2014.
Hybrid textsimplification using synchronous dependency gram-mars with hand-written and automatically harvestedrules.
In Proceedings of the 14th Conference of the Eu-ropean Chapter of the Association for ComputationalLinguistics (EACL), Gothenburg, Sweden,, pages 722?731.A.
Siddharthan.
2006.
Syntactic simplification and textcohesion.
Research on Language and Computation,4(1):77?109.L.
Specia, S. K. Jauhar, and R. Mihalcea.
2012.Semeval-2012 task 1: English lexical simplification.In Proceedings of the First Joint Conference on Lexi-cal and Computational Semantics, pages 347?355.L.
Specia.
2010.
Translating from Complex to Simpli-fied Sentences.
In PROPOR, pages 30?39.P.
Vossen.
2004.
EuroWordNet: A multilingual databasewith lexical semantic networks.
International Journalof Lexicography, 17(2):161?173.M.
Yatskar, B. Pang, C. Danescu-Niculescu-Mizil, andL.
Lee.
2010.
For the sake of simplicity: Un-supervised extraction of lexical simplifications fromWikipedia.
In Proc.
ACL?10, pages 365?368, Uppsala,Sweden.1385
