The Parallel Grammar ProjectMiriam ButtCent.
for Computational LinguisticsUMISTManchester M60 1QD GBmutt@csli.stanford.eduHelge DyvikDept.
of LinguisticsUniversity of BergenN5007 Bergen NORWAYhelge.dyvik@lili.uib.noTracy Holloway KingPalo Alto Research CenterPalo Alto, CA 94304 USAthking@parc.comHiroshi MasuichiCorporate Research CenterFuji Xerox Co., Ltd.Kanagawa 259-0157, JAPANhiroshi.masuichi@fujixerox.co.jpChristian RohrerIMS Universita?t StuttgartD-70174 Stuttgart GERMANYrohrer@ims.uni-stuttgart.deAbstractWe report on the Parallel Grammar (ParGram)project which uses the XLE parser and grammardevelopment platform for six languages: English,French, German, Japanese, Norwegian, and Urdu.11 IntroductionLarge-scale grammar development platforms are ex-pensive and time consuming to produce.
As such, adesideratum for the platforms is a broad utilizationscope.
A grammar development platform should beable to be used to write grammars for a wide varietyof languages and a broad range of purposes.
In thispaper, we report on the Parallel Grammar (ParGram)project (Butt et al, 1999) which uses the XLE parserand grammar development platform (Maxwell andKaplan, 1993) for six languages: English, French,German, Japanese, Norwegian, and Urdu.
All ofthe grammars use the Lexical-Functional Gram-mar (LFG) formalism which produces c(onstituent)-structures (trees) and f(unctional)-structures (AVMs)as the syntactic analysis.LFG assumes a version of Chomsky?s UniversalGrammar hypothesis, namely that all languages arestructured by similar underlying principles.
WithinLFG, f-structures are meant to encode a languageuniversal level of analysis, allowing for cross-linguistic parallelism at this level of abstraction.
Al-though the construction of c-structures is governed1We would like to thank Emily Bender, Mary Dalrymple,and Ron Kaplan for help with this paper.
In addition, we wouldlike to acknowledge the other grammar writers in the Par-Gram project, both current: Stefanie Dipper, Jean-Philippe Mar-cotte, Tomoko Ohkuma, and Victoria Rose?n; and past: CarolineBrun, Christian Fortmann, Anette Frank, Jonas Kuhn, VeronicaLux, Yukiko Morimoto, Mar?
?a-Eugenia Nin?o, and Fre?de?riqueSegond.by general wellformedness principles, this level ofanalysis encodes language particular differences inlinear word order, surface morphological vs. syntac-tic structures, and constituency.The ParGram project aims to test the LFG formal-ism for its universality and coverage limitations andto see how far parallelism can be maintained acrosslanguages.
Where possible, the analyses producedby the grammars for similar constructions in eachlanguage are parallel.
This has the computationaladvantage that the grammars can be used in simi-lar applications and that machine translation (Frank,1999) can be simplified.The results of the project to date are encouraging.Despite differences between the languages involvedand the aims and backgrounds of the project groups,the ParGram grammars achieve a high level of paral-lelism.
This parallelism applies to the syntactic anal-yses produced, as well as to grammar developmentitself: the sharing of templates and feature decla-rations, the utilization of common techniques, andthe transfer of knowledge and technology from onegrammar to another.
The ability to bundle grammarwriting techniques, such as templates, into transfer-able technology means that new grammars can bebootstrapped in a relatively short amount of time.There are a number of other large-scale gram-mar projects in existence which we mention brieflyhere.
The LS-GRAM project (Schmidt et al, 1996),funded by the EU-Commission under LRE (Lin-guistic Research and Engineering), was concernedwith the development of grammatical resources fornine European languages: Danish, Dutch, English,French, German, Greek, Italian, Portuguese, andSpanish.
The project started in January 1994 andended in July 1996.
Development of grammaticalresources was carried out in the framework of theAdvanced Language Engineering Platform (ALEP).The coverage of the grammars implemented in LS-GRAM was, however, much smaller than the cov-erage of the English (Riezler et al, 2002) or Ger-man grammar in ParGram.
An effort which is closerin spirit to ParGram is the implemention of gram-mar development platforms for HPSG.
In the Verb-mobil project (Wahlster, 2000), HPSG grammars forEnglish, German, and Japanese were developed ontwo platforms: LKB (Copestake, 2002) and PAGE.The PAGE system, developed and maintained in theLanguage Technology Lab of the German NationalResearch Center on Artificial Intelligence DFKIGmbH, is an advanced NLP core engine that facili-tates the development of grammatical and lexical re-sources, building on typed feature logics.
To evalu-ate the HPSG platforms and to compare their mer-its with those of XLE and the ParGram projects, onewould have to organize a special workshop, partic-ularly as the HPSG grammars in Verbmobil werewritten for spoken language, characterized by shortutterances, whereas the LFG grammars were devel-oped for parsing technical manuals and/or newspa-per texts.
There are some indications that the Ger-man and English grammars in ParGram exceed theHPSG grammars in coverage (see (Crysmann et al,2002) on the German HPSG grammar).This paper is organized as follows.
We first pro-vide a history of the project.
Then, we discuss howparallelism is maintained in the project.
Finally, weprovide a summary and discussion.2 Project HistoryThe ParGram project began in 1994 with three lan-guages: English, French, and German.
The gram-mar writers worked closely together to solidify thegrammatical analyses and conventions.
In addition,as XLE was still in development, its abilities grewas the size of the grammars and their needs grew.After the initial stage of the project, more lan-guages were added.
Because Japanese is typolog-ically very different from the initial three Euro-pean languages of the project, it represented a chal-lenging case.
Despite this typological challenge, theJapanese grammar has achieved broad coverage andhigh performance within a year and a half.
TheSouth Asian language Urdu also provides a widelyspoken, typologically distinct language.
Although itis of Indo-European origin, it shares many character-istics with Japanese such as verb-finality, relativelyfree word order, complex predicates, and the abil-ity to drop any argument (rampant pro-drop).
Nor-wegian assumes a typological middle position be-tween German and English, sharing different prop-erties with each of them.
Both the Urdu and the Nor-wegian grammars are still relatively small.Each grammar project has different goals, andeach site employs grammar writers with differentbackgrounds and skills.
The English, German, andJapanese projects have pursued the goal of hav-ing broad coverage, industrial grammars.
The Nor-wegian and Urdu grammars are smaller scale butare experimenting with incorporating different kindsof information into the grammar.
The Norwegiangrammar includes a semantic projection; their anal-yses produce not only c- and f-structures, but alsosemantic structures.
The Urdu grammar has imple-mented a level of argument structure and is test-ing various theoretical linguistic ideas.
However,even when the grammars are used for different pur-poses and have different additional features, theyhave maintained their basic parallelism in analysisand have profited from the shared grammar writingtechniques and technology.Table (1) shows the size of the grammars.
The firstfigure is the number of left-hand side categories inphrase-structure rules which compile into a collec-tion of finite-state machines with the listed numberof states and arcs.
(1)Language Rules States ArcsGerman 444 4883 15870English 310 4935 13268French 132 1116 2674Japanese 50 333 1193Norwegian 46 255 798Urdu 25 106 1693 ParallelismMaintaining parallelism in grammars being devel-oped at different sites on typologically distinct lan-guages by grammar writers from different linguis-tic traditions has proven successful.
At project meet-ings held twice a year, analyses of sample sentencesare compared and any differences are discussed; thegoal is to determine whether the differences are jus-tified or whether the analyses should be changedto maintain parallelism.
In addition, all of the f-structure features and their values are compared; thisnot only ensures that trivial differences in namingconventions do not arise, but also gives an overviewof the constructions each language covers and howthey are analyzed.
All changes are implemented be-fore the next project meeting.
Each meeting also in-volves discussion of constructions whose analysishas not yet been settled on, e.g., the analysis of parti-tives or proper names.
If an analysis is agreed upon,all the grammars implement it; if only a tentativeanalysis is found, one grammar implements it andreports on its success.
For extremely complicated orfundamental issues, e.g., how to represent predicatealternations, subcommittees examine the issue andreport on it at the next meeting.
The discussion ofsuch issues may be reopened at successive meetingsuntil a concensus is reached.Even within a given linguistic formalism, LFG forParGram, there is usually more than one way to an-alyze a construction.
Moreover, the same theoreti-cal analysis may have different possible implemen-tations in XLE.
These solutions often differ in effi-ciency or conceptual simplicity and one of the taskswithin the ParGram project is to make design deci-sions which favor one theoretical analysis and con-comitant implementation over another.3.1 Parallel AnalysesWhenever possible, the ParGram grammars choosethe same analysis and the same technical solutionfor equivalent constructions.
This was done, forexample, with imperatives.
Imperatives are alwaysassigned a null pronominal subject within the f-structure and a feature indicating that they are im-peratives, as in (2).
(2) a.
Jump!
Saute!
(French)Spring!
(German) Tobe!
(Japanese)Hopp!
(Norwegian) kuudoo!
(Urdu)b. PRED jump SUBJSUBJ PRED proSTMT-TYPE impAnother example of this type comes from theanalysis of specifiers.
Specifiers include many dif-ferent types of information and hence can be ana-lyzed in a number of ways.
In the ParGram analysis,the c-structure analysis is left relatively free accord-ing to language particular needs and slightly vary-ing theoretical assumptions.
For instance, the Nor-wegian grammar, unlike the other grammars, im-plements the principles in (Bresnan, 2001) concern-ing the relationship between an X -based c-structureand the f-structure.
This allows Norwegian speci-fiers to be analyzed as functional heads of DPs etc.,whereas they are constituents of NPs in the othergrammars.
However, at the level of f-structure, thisinformation is part of a complex SPEC feature inall the grammars.
Thus parallelism is maintainedat the level of f-structure even across different the-oretical preferences.
An example is shown in (3)for Norwegian and English in which the SPEC con-sists of a QUANT(ifier) and a POSS(essive) (SPECcan also contain information about DETerminers andDEMONstratives).
(3) a. alle mine hester (Norwegian)all my horses?all my horses?b.
PRED horseSPECQUANT PRED allPOSSPRED proPERS 1NUM sgInterrogatives provide an interesting example be-cause they differ significantly in the c-structures ofthe languages, but have the same basic f-structure.This contrast can be seen between the German ex-ample in (4) and the Urdu one in (5).
In German,the interrogative word is in first position with thefinite verb second; English and Norwegian patternlike German.
In Urdu the verb is usually in final po-sition, but the interrogative can appear in a numberof positions, including following the verb (5c).
(4) Was hat John Maria gegeben?
(German)what has John Maria give.PerfP?What did John give to Mary??
(5) a. jon=nee marii=koo kyaa diiyaa?
(Urdu)John=Erg Mary=Dat what gave?What did John give to Mary?b.
jon=nee kyaa marii=koo diiyaa?c.
jon=nee marii=ko diiyaa kyaa?Despite these differences in word order and hence inc-structure, the f-structures are parallel, with the in-terrogative being in a FOCUS-INT and the sentencehaving an interrogative STMT-TYPE, as in (6).
(6) PRED give SUBJ,OBJ,OBLFOCUS-INTPRED proPRON-TYPE intSUBJ PRED JohnOBJ [ ]OBL PRED MarySTMT-TYPE intIn the project grammars, many basic construc-tions are of this type.
However, as we will see inthe next section, there are times when parallelism isnot possible and not desirable.
Even in these cases,though, the grammars which can be parallel are;so, three of the languages might have one analysis,while three have another.3.2 Justified DifferencesParallelism is not maintained at the cost of misrepre-senting the language.
This is reflected by the fact thatthe c-structures are not parallel because word ordervaries widely from language to language, althoughthere are naming conventions for the nodes.
Instead,the bulk of the parallelism is in the f-structure.
How-ever, even in the f-structure, situations arise in whichwhat seems to be the same construction in differentlanguages do not have the same analysis.
An exam-ple of this is predicate adjectives, as in (7).
(7) a.
It is red.b.
Sore wa akai.
(Japanese)it TOP red?It is red.
?In English, the copular verb is considered the syn-tactic head of the clause, with the pronoun being thesubject and the predicate adjective being an XCOMP.However, in Japanese, the adjective is the main pred-icate, with the pronoun being the subject.
As such,these receive the non-parallel analyses seen in (8a)for Japanese and (8b) for English.
(8) a. PRED red SUBJSUBJ PRED prob.
PRED be XCOMP SUBJSUBJ PRED proXCOMPPRED red SUBJSUBJ [ ]Another situation that arises is when a featureor construction is syntactically encoded in one lan-guage, but not another.
In such cases, the informa-tion is only encoded in the languages that need it.The equivalence captured by parallel analyses is not,for example, translational equivalence.
Rather, par-allelism involves equivalence with respect to gram-matical properties, e.g.
construction types.
One con-sequence of this is that a typologically consistentuse of grammatical terms, embodied in the featurenames, is enforced.
For example, even though thereis a tradition for referring to the distinction betweenthe pronouns he and she as a gender distinction inEnglish, this is a different distinction from the onecalled gender in languages like German, French,Urdu, and Norwegian, where gender refers to nom-inal agreement classes.
Parallelism leads to the sit-uation where the feature GEND occurs in German,French, Urdu, and Norwegian, but not in Englishand Japanese.
That is, parallelism does not meanfinding the same features in all languages, but ratherusing the same features in the same way in all lan-guages, to the extent that they are justified there.
AFrench example of grammatical gender is shown in(9); note that determiner, adjective, and participleagreement is dependent on the gender of the noun.The f-structure for the nouns crayon and plume areas in (10) with an overt GEND feature.
(9) a.
Le petit crayon est casse?.
(French)the-M little-M pencil-M is broken-M.?The little pencil is broken.?b.
La petite plume est casse?e.
(French)the-F little-F pen-F is broken-F.?The little pen is broken.?
(10)PRED crayonGEND mascPERS 3PRED plumeGEND femPERS 3F-structures for the equivalent words in English andJapanese will not have a GEND feature.A similar example comes from Japanese dis-course particles.
It is well-known that Japanese hassyntactic encodings for information such as honori-fication.
The verb in the Japanese sentence (11a)encodes information that the subject is respected,while the verb in (11b) shows politeness from thewriter (speaker) to the reader (hearer) of the sen-tence.
The f-structures for the verbs in (11) are as in(12) with RESPECT and POLITE features within theADDRESS feature.
(11) a. sensei ga hon wo oyomininaru.teacher Nom book Acc read-Respect?The teacher read the book.?
(Japanese)b. seito ga hon wo yomimasu.student Nom book Acc read-Polite?The student reads the book.?
(Japanese)(12) a. PRED yomu SUBJ,OBJADDRESS RESPECT +b.
PRED yomu SUBJ,OBJADDRESS POLITE +A final example comes from English progres-sives, as in (13).
In order to distinguish these twoforms, the English grammar uses a PROG featurewithin the tense/aspect system.
(13b) shows the f-structure for (13a.ii).
(13) a. John hit Bill.
i.
He cried.ii.
He was crying.b.
PRED cry SUBJSUBJ PRED proTNS-ASPTENSE pastPROG +However, this distinction is not found in the otherlanguages.
For example, (14a) is used to expressboth (13a.i) and (13a.ii) in German.
(14) a. Er weinte.
(German)he cried?He cried.?b.
PRED weinen SUBJSUBJ PRED proTNS-ASP TENSE pastAs seen in (14b), the German f-structure is left un-derspecified for PROG because there is no syntacticreflex of it.
If such a feature were posited, rampantambiguity would be introduced for all past tenseforms in German.
Instead, the semantics will deter-mine whether such forms are progressive.Thus, there are a number of situations where hav-ing parallel analyses would result in an incorrectanalysis for one of the languages.3.3 One Language Shows the WayAnother type of situation arises when one languageprovides evidence for a certain feature space or typeof analysis that is neither explicitly mirrored norexplicitly contradicted by another language.
In the-oretical linguistics, it is commonly acknowledgedthat what one language codes overtly may be harderto detect for another language.
This situation hasarisen in the ParGram project.
Case features fall un-der this topic.
German, Japanese, and Urdu markNPs with overt case morphology.
In comparison,English, French, and Norwegian make relatively lit-tle use of case except as part of the pronominal sys-tem.
Nevertheless, the f-structure analyses for all thelanguages contain a case feature in the specificationof noun phrases.This ?overspecification?
of information expressesdeeper linguistic generalizations and keeps the f-structural analyses as parallel as possible.
In addi-tion, the features can be put to use for the isolatedphenomena in which they do play a role.
For exam-ple, English does not mark animacy grammaticallyin most situations.
However, providing a ANIM +feature to known animates, such as people?s namesand pronouns, allows the grammar to encode infor-mation that is relevant for interpretation.
Considerthe relative pronoun who in (15).
(15) a. the girl[ANIM +] who[ANIM +] leftb.
the box[ANIM +] who[ANIM +] leftThe relative pronoun has a ANIM + feature that is as-signed to the noun it modifies by the relative clauserules.
As such, a noun modified by a relative clauseheaded by who is interpreted as animate.
In the caseof canonical inanimates, as in (15b), this will resultin a pragmatically odd interpretation, which is en-coded in the f-structure.Teasing apart these different phenomena crosslin-guistically poses a challenge that the ParGram mem-bers are continually engaged in.
As such, we havedeveloped several methods to help maintain paral-lelism.3.4 Mechanics of Maintaining ParallelismThe parallelism among the grammars is maintainedin a number of ways.
Most of the work is done dur-ing two week-long project meetings held each year.Three main activities occur during these meetings:comparison of sample f-structures, comparison offeatures and their values, and discussions of new orproblematic constructions.A month before each meeting, the host sitechooses around fifteen sentences whose analysis isto be compared at the meeting.
These can be a ran-dom selection or be thematic, e.g., all dealing withpredicatives or with interrogatives.
The sentencesare then parsed by each grammar and the output iscompared.
For the more recent grammars, this maymean adding the relevant rules to the grammars, re-sulting in growth of the grammar; for the older gram-mars, this may mean updating a construction that hasnot been examined in many years.
Another approachthat was taken at the beginning of the project was tohave a common corpus of about 1,000 sentences thatall of the grammars were to parse.
For the English,French, and German grammars, this was an alignedtractor manual.
The corpus sentences were used forthe initial f-structure comparisons.
Having a com-mon corpus ensured that the grammars would haveroughly the same coverage.
For example, they allparsed declarative and imperative sentences.
How-ever, the nature of the corpus can leave major gapsin coverage; in this case, the manual contained no in-terrogatives.The XLE platform requires that a grammar de-clare all the features it uses and their possible val-ues.
Part of the Urdu feature table is shown in (16)(the notation has been simplified for expository pur-poses).
As seen in (16) for QUANT, attributes whichtake other attributes as their values must also be de-clared.
An example of such a feature was seen in(3b) for SPEC which takes QUANT and POSS fea-tures, among others, as its values.
(16) PRON-TYPE: pers poss null .PROPER: date location name title .PSEM: locational directional .PTYPE: sem nosem .QUANT: PRED QUANT-TYPEQUANT-FORM .The feature declarations of all of the languages arecompared feature by feature to ensure parallelism.The most obvious use of this is to ensure that thegrammars encode the same features in the same way.For example, at a basic level, one feature declarationmight have specified GEN for gender while the oth-ers had chosen the name GEND; this divergence innaming is regularized.
More interesting cases arisewhen one language uses a feature and another doesnot for analyzing the same phenomena.
When this isnoticed via the feature-table comparison, it is deter-mined why one grammar needs the feature and theother does not, and thus it may be possible to elim-inate the feature in one grammar or to add it to an-other.On a deeper level, the feature comparison is use-ful for conducting a survey of what constructionseach grammar has and how they are implemented.For example, if a language does not have an ADE-GREE (adjective degree) feature, the question willarise as to whether the grammar analyzes compar-ative and superlative adjectives.
If they do not, thenthey should be added and should use the ADEGREEfeature; if they do, then the question arises as to whythey do not have this feature as part of their analysis.Finally, there is the discussion of problematicconstructions.
These may be constructions that al-ready have analyses which had been agreed upon inthe past but which are not working properly now thatmore data has been considered.
More frequently,they are new constructions that one of the grammarsis considering adding.
Possible analyses for the con-struction are discussed and then one of the gram-mars will incorporate the analysis to see whether itworks.
If the analysis works, then the other gram-mars will incorporate the analysis.
Constructionsthat have been discussed in past ParGram meet-ings include predicative adjectives, quantifiers, par-titives, and clefts.
Even if not all of the languageshave the construction in question, as was the casewith clefts, the grammar writers for that languagemay have interesting ideas on how to analyze it.These group discussions have proven particularlyuseful in extending grammar coverage in a parallelfashion.Once a consensus is reached, it is the responsi-bility of each grammar to make sure that its anal-yses match the new standard.
As such, after eachmeeting, the grammar writers will rename features,change analyses, and implement new constructionsinto their grammars.
Most of the basic work has nowbeen accomplished.
However, as the grammars ex-pand coverage, more constructions need to be inte-grated into the grammars, and these constructionstend to be ones for which there is no standard analy-sis in the linguistic literature; so, differences can eas-ily arise in these areas.4 ConclusionThe experiences of the ParGram grammar writershas shown that the parallelism of analysis and imple-mentation in the ParGram project aids further gram-mar development efforts.
Many of the basic deci-sions about analyses and formalism have alreadybeen made in the project.
Thus, the grammar writerfor a new language can use existing technology tobootstrap a grammar for the new language and canparse equivalent constructions in the existing lan-guages to see how to analyze a construction.
Thisallows the grammar writer to focus on more diffi-cult constructions not yet encountered in the existinggrammars.Consider first the Japanese grammar which wasstarted in the beginning of 2001.
At the initial stage,the work of grammar development involved imple-menting the basic constructions already analyzed inthe other grammars.
It was found that the grammarwriting techniques and guidelines to maintain par-allelism shared in the ParGram project could be ef-ficiently applied to the Japanese grammar.
Duringthe next stage, LFG rules needed for grammatical is-sues specific to Japanese have been gradually incor-porated, and at the same time, the biannual ParGrammeetings have helped significantly to keep the gram-mars parallel.
Given this system, in a year and a half,using two grammar writers, the Japanese grammarhas attained coverage of 99% for 500 sentences of acopier manual and 95% for 10,000 sentences of aneCRM (Voice-of-Customer) corpus.Next consider the Norwegian grammar whichjoined the ParGram group in 1999 and also empha-sized slightly different goals from the other groups.Rather than prioritizing large textual coverage fromthe outset, the Norwegian group gave priority to thedevelopment of a core grammar covering all majorconstruction types in a principled way based on theproposals in (Bresnan, 2001) and the inclusion of asemantic projection in addition to the f-structure.
Inaddition, time was spent on improving existing lexi-cal resources ( 80,000 lemmas) and adapting themto the XLE format.
Roughly two man-years has beenspent on the grammar itself.
The ParGram cooper-ation on parallelism has ensured that the derived f-structures are interesting in a multilingual context,and the grammar will now serve as a basis for gram-mar development in other closely related Scandina-vian languages.Thus, the ParGram project has shown that it ispossible to use a single grammar development plat-form and a unified methodology of grammar writingto develop large-scale grammars for typologicallydifferent languages.
The grammars?
analyses show alarge degree of parallelism, despite being developedat different sites.
This is achieved by intensive meet-ings twice a year.
The parallelism can be exploited inapplications using the grammars: the fewer the dif-ferences, the simpler a multilingual application canbe (see (Frank, 1999) on a machine-translation pro-totype using ParGram).ReferencesJoan Bresnan.
2001.
Lexical-Functional Syntax.Blackwell.Miriam Butt, Tracy Holloway King, Mar?
?a-EugeniaNin?o, and Fre?de?rique Segond.
1999.
A GrammarWriter?s Cookbook.
CSLI Publications.Ann Copestake.
2002.
Implementing Typed FeatureStructure Grammars.
CSLI Publications.Berthold Crysmann, Anette Frank, Bernd Keifer, St.Mu?ller, Gu?nter Neumann, Jakub Piskorski, UlrichScha?fer, Melanie Siegel, Hans Uszkoreit, FeiyuXu, Markus Becker, and Hans-Ulrich Krieger.2002.
An integrated architecture for shallow anddeep parsing.
In Proceedings of the Annual Meet-ing of the Association for Computational Linguis-tics, University of Pennsylvania.Anette Frank.
1999.
From parallel grammar devel-opment towards machine translation.
In Proceed-ings of MT Summit VII, pages 134?142.John T. Maxwell, III and Ron Kaplan.
1993.
Theinterface between phrasal and functional con-straints.
Computational Lingusitics, 19:571?589.Stefan Riezler, Tracy Holloway King, Ronald Ka-plan, Dick Crouch, John T. Maxwell, III, andMark Johnson.
2002.
Parsing the wall street jour-nal using a lexical-functional grammar and dis-criminative estimation techniques.
In Proceed-ings of the Annual Meeting of the Association forComputational Linguistics, University of Penn-sylvania.Paul Schmidt, Sibylle Rieder, Axel Theofilidis, andThierry Declerck.
1996.
Lean formalisms, lin-guistic theory, and applications: Grammar devel-opment in alep.
In Proceedings of COLING.Wolfgang Wahlster, editor.
2000.
Verbmobil:Foundations of Speech-to-Speech Translation.Springer.
