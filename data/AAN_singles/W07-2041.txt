Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 195?198,Prague, June 2007. c?2007 Association for Computational LinguisticsIRST-BP: Web People Search Using Name EntitiesOctavian PopescuFBK-irst, Trento (Italy)popescu@itc.itBernardo MagniniFBK-irst, Trento (Italy)magnini@itc.itAbstractIn this paper we describe a person clus-tering system for web pages and reportthe results we have obtained on the testset of the Semeval 2007 Web PersonSearch task.
Deciding which particularperson a name refers to within a textdocument depends mainly on the capac-ity to extract the relevant informationout of texts when it is present.
We con-sider ?relevant?
here to stand primarilyfor two properties: (1) uniqueness and(2) appropriateness.
In order to addressboth (1) and (2) our method gives pri-mary importance to Name Entities(NEs), defined according to the ACEspecifications.
The common nouns notreferring to entities are considered fur-ther as coreference clues only if they arefound within already coreferred docu-ments.1 IntroductionNames are ambiguous items (Artiles, Gonzaloand  Sekine 2007).
As reported on an experimentcarried out on an Italian news corpus (Magniniet al 2006) within a 4 consecutive days from alocal newspaper the perplexity is 56% and 14%for first and last name respectively.
Decidingwhich particular person a name refers to within atext document depends mainly on the capacity toextract the relevant information out of textswhen it is present1.
We consider ?relevant?
hereto stand primarily for two properties: (1)uniqueness and (2) appropriateness.
A feature isunique as long as it appears only with one per-son.
Consider a cluster of web pages that charac-terizes only one person.
Many of the N-grams inthis cluster are unique compared to other cluster.Yet the uniqueness may come simply from thesparseness.
Appropriateness is the property of anN-gram to characterize that person.Uniqueness may be assured by ontologicalproperties (for example, ?There is a uniquepresident of a republic at a definite moment oftime?, ?Alberta University is in Canada).
How-ever, the range of ontological information we areable to handle is quite restricted and we are notable to realize the coreference solely relying onthem.
Uniqueness may be assured by estimatinga very unlike probability of the occurrence ofcertain N-grams for different persons (as, forexample, ?Dekang Lin professor Alberta CanadaGoogle?
).Appropriateness is a difficult issue because oftwo reasons: (a) it is a dynamic feature (b) it ishard to be localized and extracted from text.
Thegreatest help comes from the name of the page,when it happens to be a suggestive name such as?homepage?, ?CV?, ?resume?
or ?about?.
Gene-1It is very difficult to evaluate whether the informa-tion allowing the coreference of two instances of a(same) name is present in a web page or news.
Acrude estimation on our news corpus for the namesoccurring between 6-20 times, which represent 8% ofthe names inventory for the whole collection, is thatin much more than 50% of the news, the relevantinformation is not present.195alogy pages are very useful, to the extent that theinformation could be accurately extracted andthat the same information occurs in some otherpages as well.
However, in general, for plainweb pages, we rely on paragraphs in which asingle person is mentioned and consequently, thesearch space for similarity is also within thistype of paragraphs.Our proposal is to rely on special N-grams forcoreference and it is a variant of agglomerativeclustering based on social net-works(Bagga&Baldwin 1998, Malin 2005) .
Theterms the N-grams contain are crucial.
Supposewe have the same name shared by two differentpersons who happen to also have the same pro-fession, let?s say, ?lawyer?, and who also prac-tice in the same state.
While all three words ?
(name, profession, state) - might be rare wordsfor the whole corpus, their probability computedas chance to be seen in the same document islow, their three-gram fails to cluster correctly thedocuments referring to the two persons2.
Know-ing that the ?lawyer?
is a profession that has dif-ferent specializations, which are likely to befound as determiners, we may address this prob-lem more accurately considering the same three-gram by changing ?lawyer?
with a word morespecific denoting her specialization.The present method for clustering people webpages containing names according addressesboth uniqueness and appropiateness.
We rely ona procedure that firstly identifies the surest casesof coreference and then recursively discover newcases.
It is not necessarily the case that the latestfound coreferences are more doubtful, but ratherthat the evidence required for their coreferenceis harder to achieve.The cluster metrics gives a primary impor-tance to words denoting entities which are de-fined according to ACE definitions: PER, LOC,ORG, GPE.In Section 2 we present in detail the architec-ture of our system and in Section 3 we presentits behavior and the results we obtained on thetest set of Semeval 2007 Web Person Searchtask.
In section 4 we present our conclusions andfuture directions for improvement.2The traditional idf methods used in document clus-tering must be further refined in order to be effectivein person coreference.2 System ArchitectureFirst, the text is split into paragraphs, basedmainly on the html structure of the page.
Wehave a Perl script which decides weather thename of interest is present within a paragraph.
Ifthe test is positive the paragraph is marked as aperson-paragraph, and our initial assumption isthat each person-paragraph refers to a differentperson.The second step is considered the first proce-dure of the feature extraction module.
To eachparagraph person we associate a set of NEs, rarewords and temporal expressions, each of themcounting as independent items.
For all of theseitems which are inside of the same dependencypath we also consider the N-grams made out ofthe respective items preserving the order.
Foreach person-paragraph we compute the list ofabove items and consider them as features forclustering.
This set is called the association set.The first step in making the coreference is themost important one and consists in two opera-tions: (1) the most similar pages are clusteredtogether and (2) for each cluster, we make a listof the pages which most likely do not refer to thesame person.
Starting with this initial estimation,the next steps are repeated till no new corefer-ence is made.For each cluster of pages, a new set of itemsis computed starting from the association sets.Only the ones which are specific to the respec-tive cluster - comparing against all other clustersand against the list of pages not related (see (2)above) ?
are kept in the new association set.These are the features we use further for cluster-ing.
The clustering score of two person-paragraphs is given by summing up the individ-ual score of common features in their associationsets.
The score of a feature is determined basedon its type - (NE, distinctive words, temporalexpressions) - , its length in terms of wordscompounding it, and the number of its occur-rences inside the cluster and inside the wholecorpus, considering only the web pages relativeto that name and the absolute frequency of thewords.
The feature score is finally weighed witha factor which expresses the distance betweenthe name and the respective feature.
An empiri-cal threshold has been chosen.196Each of the above paragraphs representing amodule in our system is explained in one of thenext subsections respectively.2.1 PreprocessingWeb pages contain a lot of information outsidethe raw text.
We wrote Perl scripts for identify-ing the e-mail addresses, phone and fax numbersand extract them if they were in the same para-graph with the name of interest.
It seems that alot can be gained considering the web addresses,the type of page, the links outside the pages andso on.
However, we have not exploited up tonow these extra clues for coreference.
The wholecorpus associated with a name is searched onlyonce.
If the respective items are found in twodifferent pages, these two pages are clustered.In web pages, the visual structure plays animportant role, and many times the graphics de-sign substitutes for linguistics features.
Using anormal html parser, such as lynx, the text maylack its usual grammatical structure which maydrastically decrease the performances of sen-tence splitters, Name Entity Recognizers andparsers.
To alleviate this problem, the text is firsttagged with PoS.
If a paragraph, ?\n?, does nothave a main verb, then it is treated separately.
Ifthe text contains only nouns and determiners andif the paragraph is within a paragraph containingthe name of interest, the phrase ?You are talkingabout?
is added in front of it to make it a normalsentence.The text is split into person-paragraphs, andeach person-paragraph is split into sentences,lemmatized, the NEs are recognized 3  and thetext is parsed using MiniPar (Dekang Lin 1998).We are interested only in dependency paths thatare rooted in NEs ?
the NP which are included inbigger XP, or sister of NPs, or contain time ex-pressions.The person-paragraphs are checked for the in-terest names.
We write rules for recognizing thevalid names.
If a page does not have a validname of interest, it is discarded.
A page is alsodiscarded when a valid name of interest has itsentity type ?ORG?.3We thank to the Textec group at IRST for making itpossible for everyone to pre process the text veryeasily with state of the art performances.2.2 Feature ExtractionThe association set contains a set of features.The features are NEs or part of NEs, because theclosed class words, the very frequent words ?computed on the set of all web pages for all per-sons ?
are deleted from the NEs4.
When we referto the length of a feature we mean the number ofwords it is made of, after deletion.We consider words (phrases) which are notNEs as features but only if they are frequent inalready coreferred person-paragraphs.
That is,initially the coreference is determined solely onNEs.
If there is enough evidence, i.e.
when aword is frequent within the cluster and not pre-sent within other clusters, then the respectiveword (phrase) is taken into account for corefer-ence.Time expressions are relevant indicators forcoreference if they are appropriately linked to aperson.
We consider them always, just like aNE, but when they appear in particular depend-ency trees they have a special value.
If they aredominated by a name of interest and/or by thelemma ?birth?, ?born?
we consider them as asure factor for coreference.For all composed features we also considerthe order preserved combinations of their partsobtaining new features.The association sets increase their cardinalityby coreference.
At each step, the new added fea-tures are checked against the ones from the otherclusters.
The common features are kept in sepa-rate sets.
The coreference is not decided on theirbasis, but these features are used to identify theparagraph persons that do not refer to a particu-lar person, and therefore should not be includedin the same cluster.
We do not explicitly weighdifferently the features (apart of the cases men-tioned above) but they are actually weighed dif-ferently implicitly.
The words within a com-posed feature are repeated, a feature of length nproduces n(n-1) new features, n> 2.
Besides, aswe will see in the next section, the similarityscore uses the length of a feature.4Sometimes, correctly or not,  the SVM base NERwe use includes, especially inside of LOC and GPEname entities, common words.
In order to remain asprecise as possible, we choose not to consider thesewords when we compute the similarity score.1972.3 Similarity MeasureOur similarity score for two person-paragraphsis the sum of the individual scores of the com-mon features which are weighed according tothe maximum of distances between the name ofinterest and the feature.There are three parameters on which we relyfor computing similarity: the length, the numberof occurrences, and the absolute frequency of afeature.
The score considers the cube of the fea-ture length (which means that the one word fea-tures do not score).
We compute the ratio be-tween the number of occurrences within thecluster and the number of occurrences in the webpages relative to that name.
The third parameteris the absolute frequency of the words.
As usu-ally, if the word is a rare word it counts as moreevidence for coreference.
We regard these pa-rameters as independent, in spite of their relativedependency, and we simply multiply them.We define the distance between a feature anda name as a discrete measure.
If the name andthe feature are sisters of the same head then theirdistance is minimum, therefore their importancefor similarity is the highest.
The second lowerdistance value is given within the same sentenceand the distance increases with the number ofsentences.
If there are no other names mentionedin the paragraph, the distance is divided by half.We have established an empirical thresholdwhich initially is very high, as the features arenot checked among the clusters in the first run.After the first run, it is relaxed and the commonand individual sets are computed as we havedescribed in the previous section.3 EvaluationThe system performance on the test set of Seme-val 2007 Web Person Search task is F?=0.5 =0.75, harmonic means of purity, and F=0.2 = 0.80- the inverse purity mean.
The data set has beendivided in three sets: SET1 ACL people, SET2Wikipedia people, and SET3 census people.
Theresults are presented in table 1.
The fact that thesystem is less accurate on SET2 may be due tothe fact that larger person paragraph are consid-ered and therefore more inappropriate similarityare declared.TestSetPurity InversePurityF?=0.5SET1 0,75 0,80 0,77SET2 0,83 0,71 0,77SET3 0,81 0,75 0,784 Conclusion and Further ResearchOur method is greedy and it depends a lot on theaccuracy of coreference as the system propa-gates the errors from step to step.One of the big problems of our system is thepreprocessing step and further improvement isrequired.
That is because we rely on the per-formances of NER and parsers.
We also hopethat by the inclusion of extra textual informationthe html carries, we will have better results.A second direction for us is to exactly under-stand the role of ontological information.
For themoment, we recognized some of the words de-noting professions and we tried to guess theirdeterminators.
We think that having hierarchicalrelationships among LOC, GPE and also forORG may make a difference in results especiallyfor massive corpora.ReferencesArtiles, J., Gonzalo, J. and Sekine, S. (2007).Establishing a benchmark for the Web PeopleSearch Task: The Semeval 2007 WePS Track.In Proceedings of Semeval 2007, Associationfor Computational Linguistics.Bagga A., Baldwin B.,(1998) Entity-Basedcross-document-referencing using vectorspace model, In proceedings of 17th  Interna-tional Conference on Computational Linguis-ticsMagnini B., Pianta E., Popescu O. and SperanzaM.
(2006).
Ontology Population from TextualMentions: Task Definition and Benchmark.Proceedings of the OLP2 workshop on Ontol-ogy Population and Learning, Sidney, Austra-lia,.
Joint with ACL/ColingMalin.
B., (2005): Unsupervised Name Disam-biguation via Network Similarity, In proceed-ings SIAM Conference on Data Mining 2005Zanolli R., Pianta E. (2006) Technical report,ITC IRST198
