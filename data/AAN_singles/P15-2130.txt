Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 794?799,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsMulti-domain Dialog State Tracking using Recurrent Neural NetworksNikola Mrk?si?c1,2, Diarmuid?O S?eaghdha2, Blaise Thomson2, Milica Ga?si?c1Pei-Hao Su1, David Vandyke1, Tsung-Hsien Wen1and Steve Young11Department of Engineering, University of Cambridge, UK2VocalIQ Ltd. , Cambridge, UK{nm480,mg436,phs26,djv27,thw28,sjy}@cam.ac.uk {diarmuid, blaise}@vocaliq.comAbstractDialog state tracking is a key componentof many modern dialog systems, most ofwhich are designed with a single, well-defined domain in mind.
This paper showsthat dialog data drawn from different dia-log domains can be used to train a generalbelief tracking model which can operateacross all of these domains, exhibiting su-perior performance to each of the domain-specific models.
We propose a training pro-cedure which uses out-of-domain data toinitialise belief tracking models for entirelynew domains.
This procedure leads to im-provements in belief tracking performanceregardless of the amount of in-domain dataavailable for training the model.1 IntroductionSpoken dialog systems allow users to interact withcomputer applications through a conversational in-terface.
Modern dialog systems are typically de-signed with a well-defined domain in mind, e.g.,restaurant search, travel reservations or shoppingfor a new laptop.
The goal of building open-domaindialog systems capable of conversing about anytopic remains far off.
In this work, we move to-wards this goal by showing how to build dialogstate tracking models which can operate acrossentirely different domains.
The state tracking com-ponent of a dialog system is responsible for inter-preting the users?
utterances and thus updating thesystem?s belief state: a probability distribution overall possible states of the dialog.
This belief state isused by the system to decide what to do next.Recurrent Neural Networks (RNNs) are wellsuited to dialog state tracking, as their ability to cap-ture contextual information allows them to modeland label complex dynamic sequences (Graves,2012).
In recent shared tasks, approaches based onthese models have shown competitive performance(Henderson et al., 2014d; Henderson et al., 2014c).This approach is particularly well suited to our goalof building open-domain dialog systems, as it doesnot require handcrafted domain-specific resourcesfor semantic interpretation.We propose a method for training multi-domainRNN dialog state tracking models.
Our hierarchicaltraining procedure first uses all the data availableto train a very general belief tracking model.
Thismodel learns the most frequent and general dialogfeatures present across the various domains.
Thegeneral model is then specialised for each domain,learning domain-specific behaviour while retainingthe cross-domain dialog patterns learned during theinitial training stages.
These models show robustperformance across all the domains investigated,typically outperforming trackers trained on target-domain data alone.
The procedure can also be usedto initialise dialog systems for entirely new do-mains.
In the evaluation, we show that such initiali-sation always improves performance, regardless ofthe amount of the in-domain training data available.We believe that this work is the first to address thequestion of multi-domain belief tracking.2 Related WorkTraditional rule-based approaches to understandingin dialog systems (e.g.
Goddeau et al.
(1996)) havebeen superseded by data-driven systems that aremore robust and can provide the probabilistic dia-log state distributions that are needed by POMDP-based dialog managers.
The recent Dialog StateTracking Challenge (DSTC) shared tasks (Williamset al., 2013; Henderson et al., 2014a; Hendersonet al., 2014b) saw a variety of novel approaches,including robust sets of hand-crafted rules (Wangand Lemon, 2013), conditional random fields (Leeand Eskenazi, 2013; Lee, 2013; Ren et al., 2013),maximum entropy models (Williams, 2013) andweb-style ranking (Williams, 2014).794Henderson et al.
(2013; 2014d; 2014c) proposeda belief tracker based on recurrent neural networks.This approach maps directly from the ASR (au-tomatic speech recognition) output to the beliefstate update, avoiding the use of complex semanticdecoders while still attaining state-of-the-art per-formance.
We adopt this RNN framework as thestarting point for the work described here.It is well-known in machine learning that a sys-tem trained on data from one domain may not per-form as well when deployed in a different domain.Researchers have investigated methods for mitigat-ing this problem, with NLP applications in parsing(McClosky et al., 2006; McClosky et al., 2010),sentiment analysis (Blitzer et al., 2007; Glorot etal., 2011) and many other tasks.
There has been asmall amount of previous work on domain adapta-tion for dialog systems.
Tur et al.
(2007) and Mar-golis et al.
(2010) investigated domain adaptationfor dialog act tagging.
Walker et al.
(2007) traineda sentence planner/generator that adapts to differ-ent individuals and domains.
In the third DSTCshared task (Henderson et al., 2014b), participantsdeployed belief trackers trained on a restaurant do-main in an expanded version of the same domain,with a richer output space but essentially the sametopic.
To the best of our knowledge, our work isthe first attempt to build a belief tracker capable ofoperating across disjoint dialog domains.3 Dialog State Tracking using RNNsBelief tracking models capture users?
goals giventheir utterances.
Goals are represented as sets ofconstraints expressed by slot-value mappings suchas [food: chinese] or [wifi: available].
The set ofslots S and the set of values Vsfor each slot makeup the ontology for an application domain.Our starting point is the RNN framework forbelief tracking that was introduced by Hendersonet al.
(2014d; 2014c).
This is a single-hidden-layerrecurrent neural network that outputs a distributionover all goal slot-value pairs for each user utterancein a dialog.
It also maintains a memory vectorthat stores internal information about the dialogcontext.
The input for each user utterance consistsof the ASR hypotheses, the last system action, thecurrent memory vector and the previous belief state.Rather than using a spoken language understanding(SLU) decoder to convert this input into a meaningrepresentation, the system uses the turn input toextract a large number of word n-gram features.These features capture some of the dialog dynamicsbut are not ideal for sharing information acrossdifferent slots and domains.Delexicalised n-gram features overcome thisproblem by replacing all references to slot namesand values with generic symbols.
Lexical n-gramssuch as [want cheap price] and [want Chinesefood] map to the same delexicalised feature, rep-resented by [want tagged-slot-value tagged-slot-name].
Such features facilitate transfer learningbetween slots and allow the system to operate onunseen values or entirely new slots.
As an example,[want available internet] would be delexicalised to[want tagged-slot-value tagged-slot-name] as well,a useful feature even if there is no training dataavailable for the internet slot.
The delexicalisedmodel learns the belief state update correspondingto this feature from its occurrences across the otherslots and domains.
Subsequently, it can apply thelearned behaviour to slots in entirely new domains.The system maintains a separate belief state foreach slot s, represented by the distribution psoverall possible slot values v ?
Vs.
The model inputat turn t, xt, consists of the previous belief statept?1s, the previous memory state mt?1, as well asthe vectors fland fdof lexical and delexicalisedfeatures extracted from the turn input1.
The beliefstate of each slot s is updated for each of its slotvalues v ?
Vs.
The RNN memory layer is updatedas well.
The updates are as follows2:xtv= ftl?
ftd?
mt?1?
pt?1v?
pt?1?gtv= ws1?
?
(Ws0xtv+ bs0)+ bs1ptv=exp(gtv)exp(gt?)
+?v??Vexp(gtv?
)mt= ?(Wsm0xt+Wsm1mt?1)where?
denotes vector concatenation and pt?is theprobability that the user has expressed no constraintup to turn t. Matrices Ws0, Wsm0, Wsm1and thevector ws1are the RNN weights, and b0and b1arethe hidden and output layer RNN bias terms.For training, the model is unrolled across turnsand trained using backpropagation through timeand stochastic gradient descent (Graves, 2012).1Henderson et al.
?s work distinguished between three typesof features: the delexicalised feature sets fsand fvare sub-sumed by our delexicalised feature vector fd, and the turninput f corresponds to our lexical feature vector fl.2The original RNN architecture had a second componentwhich learned mappings from lexical n-grams to specific slotvalues.
In order to move towards domain-independence, wedo not use this part of the network.7954 Hierarchical Model TrainingDelexicalised features allow transfer learning be-tween slots.
We extend this approach to achievetransfer learning between domains: a model trainedto talk about hotels should have some success talk-ing about restaurants, or even laptops.
If we canincorporate features learned from different domainsinto a single model, this model should be able totrack belief state across all of these domains.The training procedure starts by performingshared initialisation: the RNN parameters of allthe slots are tied and all the slot value occurrencesare replaced with a single generic tag.
These slot-agnostic delexicalised dialogs are then used to trainthe parameters of the shared RNN model.Extending shared initialisation to training acrossmultiple domains is straightforward.
We first delex-icalise all slot value occurrences for all slots acrossthe different domains in the training data.
Thiscombined (delexicalised) dataset is then used totrain the multi-domain shared model.The shared RNN model is trained with the pur-pose of extracting a very rich set of lexical anddelexicalised features which capture general dialogdynamics.
While the features are general, the RNNparameters are not, since not all of the featuresare equally relevant for different slots.
For exam-ple, [eat tagged-slot-value food] and [near tagged-slot-value] are clearly features related to food andarea slots respectively.
To ensure that the modellearns the relative importance of different featuresfor each of the slots, we train slot specific mod-els for each slot across all the available domains.To train these slot-specialised models, the sharedRNN?s parameters are replicated for each slot andspecialised further by performing additional runsof stochastic gradient descent using only the slot-specific (delexicalised) training data.5 Dialog domains consideredWe use the experimental setup of the Dialog StateTracking Challenges.
The key metric used to mea-sure the success of belief tracking is goal accuracy,which represents the ability of the system to cor-rectly infer users?
constraints.
We report the jointgoal accuracy, which represents the marginal testaccuracy across all slots in the domain.We evaluate on data from six domains, varyingacross topic and geographical location (Table 1).The Cambridge Restaurants data is the data fromDSTC 2.
The San Francisco Restaurants and Ho-Dataset / Model Domain Train Test SlotsCambridge Rest.
Restaurants 2118 1117 4SF Restaurants Restaurants 1608 176 7Michigan Rest.
Restaurants 845 146 12All Restaurants Restaurants 4398 - 23Tourist Info.
Tourist Info 2039 225 9SF Hotels Hotels Info 1086 120 7R+T+H Model Mixed 7523 - 39Laptops Laptops 900 100 6R+T+H+L Model Mixed 8423 - 45Table 1: datasets used in our experimentstels data was collected during the Parlance project(Ga?si?c et al., 2014).
The Tourist Information do-main is the DSTC 3 dataset: it contains dialogsabout hotels, restaurants, pubs and coffee shops.The Michigan Restaurants and Laptops datasetsare collections of dialogs sourced using AmazonMechanical Turk.
The Laptops domain containsconversations with users instructed to find laptopswith certain characteristics.
This domain is sub-stantially different from the other ones, making itparticularly useful for assessing the quality of themulti-domain models trained.We introduce three combined datasets used totrain increasingly general belief tracking models:1.
All Restaurants model: trained using the com-bined data of all three restaurant domains;2.
R+T+H model: trained on all dialogs relatedto restaurants, hotels, pubs and coffee shops;3.
R+T+H+L model: the most general model,trained using all the available dialog data.6 ResultsAs part of the evaluation, we use the three com-binations of our dialog domains to build increas-ingly general belief tracking models.
The domain-specific models trained using only data from eachof the six dialog domains provide the baseline per-formance for the three general models.6.1 Training General ModelsTraining the shared RNN models is the first step ofthe training procedure.
Table 2 shows the perfor-mance of shared models trained using dialogs fromthe six individual and the three combined domains.The joint accuracies are not comparable betweenthe domains as each of them contains a differentnumber of slots.
The geometric mean of the six ac-curacies is calculated to determine how well thesemodels operate across different dialog domains.796Model / Domain Cam Rest SF Rest Mich Rest Tourist SF Hotels Laptops Geo.
MeanCambridge Restaurants 75.0 26.2 33.1 48.7 5.5 54.1 31.3San Francisco Restaurants 66.8 51.6 31.5 38.2 17.5 47.4 38.8Michigan Restaurants 57.9 22.3 64.2 32.6 10.2 45.4 32.8All Restaurants 75.5 49.6 67.4 48.2 19.8 53.7 48.5Tourist Information 71.7 27.1 31.5 62.9 10.1 55.7 36.0San Francisco Hotels 26.2 28.7 27.1 27.9 57.1 25.3 30.6Rest ?
Tourist ?
Hotels (R+T+H) 76.8 51.2 68.7 65.0 58.8 48.1 60.7Laptops 66.9 26.1 32.0 46.2 4.6 74.7 31.0All Domains (R+T+H+L) 76.8 50.8 64.4 63.6 57.8 76.7 64.3Table 2: Goal accuracy of shared models trained using different dialog domains (ensembles of 12 models)The parameters of the three multi-domain mod-els are not slot or even domain specific.
Nonethe-less, all of them improve over the domain-specificmodel for all but one of their constituent domains.The R+T+H model outperforms the R+T+H+Lmodel across four domains, showing that the useof laptops-related dialogs decreases performanceslightly across other more closely related domains.However, the latter model is much better at balanc-ing its performance across all six domains, achiev-ing the highest geometric mean and still improvingover all but one of the domain-specific models.6.2 Slot-specialising the General ModelsSlot specialising the shared model allows the train-ing procedure to learn the relative importance ofdifferent delexicalised features for each slot in agiven domain.
Table 3 shows the effect of slot-specialising shared models across the six dialogdomains.
Moving down in these tables correspondsto adding more out-of-domain training data andmoving right corresponds to slot-specialising theshared model for each slot in the current domain.Slot-specialisation improved performance in thevast majority of the experiments.
All three slot-specialised general models outperformed the RNNmodel?s performance reported in DSTC 2.6.3 Out of Domain InitialisationThe hierarchical training procedure can exploit theavailable out-of-domain dialogs to initialise im-proved shared models for new dialog domains.In our experiments, we choose one of the do-mains to act as the new domain, and we use a subsetof the remaining ones as out-of-domain data.
Thenumber of in-domain dialogs available for train-ing is increased at each stage of the experimentand used to train and compare the performance oftwo slot-specialised models.
These models slot-specialise from two different shared models.
Oneis trained using in-domain data only, and the otheris trained on all the out-of-domain data as well.The two experiments vary in the degree of sim-ilarity between the in-domain and out-of-domaindialogs.
In the first experiment, Michigan Restau-rants act as the new domain and the remainingR+T+H dialogs are used as out-of-domain data.
Inthe second experiment, Laptops dialogs are the in-domain data and the remaining dialog domains areused to initialise the more general shared model.Figure 1 shows how the performance of thetwo differently initialised models improves as ad-ditional in-domain dialogs are introduced.
In bothexperiments, the use of out-of-domain data helps toModelCambridge Restaurants SF Restaurants Michigan RestaurantsShared Model Slot-specialised Shared Model Slot-specialised Shared Model Slot-specialisedDomain Specific 75.0 75.4 51.6 56.5 64.2 65.6All Restaurants 75.5 77.3 49.6 53.6 67.4 65.9R+T+H 76.8 77.4 51.2 54.6 68.7 65.8R+T+H+L 76.8 77.0 50.8 54.1 64.4 66.9Tourist Information SF Hotels LaptopsShared Model Slot-specialised Shared Model Slot-specialised Shared Model Slot-specialisedDomain Specific 62.9 65.1 57.1 57.4 74.7 78.4R+T+H 65.0 67.1 58.8 60.7 - -R+T+H+L 63.6 65.5 57.8 61.6 76.7 78.9Table 3: Impact of slot specialisation on performance across the six domains (ensembles of 12 models)7970 200 400 600 80050556065In-domain InitialisationOut-of-domain Initialisation0 200 400 600 800406080In-domain InitialisationOut-of-domain InitialisationFigure 1: Joint goal accuracy on Michigan Restaurants (left) and the Laptops domain (right) as a functionof the number of in-domain training dialogs available to the training procedure (ensembles of four models)initialise the model to a much better starting pointwhen the in-domain training data set is small.
Theout-of-domain initialisation consistently improvesperformance: the joint goal accuracy is improvedeven when the entire in-domain dataset becomesavailable to the training procedure.These results are not surprising in the case ofthe system trained to talk about Michigan Restau-rants.
Dialog systems trained to help users findrestaurants or hotels should have no trouble find-ing restaurants in alternative geographies.
In linewith these expectations, the use of a shared modelinitialised using R+T+H dialogs results in a modelwith strong starting performance.
As additionalrestaurants dialogs are revealed to the training pro-cedure, this model shows relatively minor perfor-mance gains over the domain-specific one.The results of the Laptops experiment are evenmore compelling, as the difference in performancebetween the differently initialised models becomeslarger and more consistent.
There are two factors atplay here: exposing the training procedure to sub-stantially different out-of-domain dialogs allowsit to learn delexicalised features not present in thein-domain training data.
These features are appli-cable to the Laptops domain, as evidenced by thevery strong starting performance.
As additionalin-domain dialogs are introduced, the delexicalisedfeatures not present in the out-of-domain data arelearned as well, leading to consistent improvementsin belief tracking performance.In the context of these results, it is clear thatthe out-of-domain training data has the potential tobe even more beneficial to tracking performancethan data from relatively similar domains.
This isespecially the case when the available in-domaintraining datasets are too small to allow the proce-dure to learn appropriate delexicalised features.7 ConclusionWe have shown that it is possible to train general be-lief tracking models capable of talking about manydifferent topics at once.
The most general modelexhibits robust performance across all domains,outperforming most domain-specific models.
Thisshows that training using diverse dialog domainsallows the model to better capture general dialogdynamics applicable to different domains at once.The proposed hierarchical training procedurecan also be used to adapt the general model to newdialog domains, with very small in-domain datasets required for adaptation.
This procedure im-proves tracking performance even when substantialamounts of in-domain data become available.7.1 Further WorkThe suggested domain adaptation procedure re-quires a small collection of annotated in-domaindialogs to adapt the general model to a new domain.In our future work, we intend to focus on initialis-ing good belief tracking models when no annotateddialogs are available for the new dialog domain.ReferencesJohn Blitzer, Mark Dredze, and Fernando Pereira.2007.
Biographies, Bollywood, boom-boxes andblenders: Domain adaptation for sentiment classifi-cation.
In Proceedings of ACL.798Milica Ga?si?c, Dongho Kim, Pirros Tsiakoulis, Cather-ine Breslin, Matthew Henderson, Martin Szummer,Blaise Thomson, and Steve Young.
2014.
Incremen-tal on-line adaptation of POMDP-based dialoguemanagers to extended domains.
In Proceedings ofINTERSPEECH.Xavier Glorot, Antoine Bordes, and Yoshua Bengio.2011.
Domain adaptation for large-scale sentimentclassification: A deep learning approach.
In Pro-ceedings of ICML.D.
Goddeau, H. Meng, J. Polifroni, S. Seneff, andS.
Busayapongchai.
1996.
A form-based dialoguemanager for spoken language applications.
In Pro-ceedings of ICSLP.Alex Graves.
2012.
Supervised Sequence Labellingwith Recurrent Neural Networks.
Springer, Berlin.Matthew Henderson, Blaise Thomson, and SteveYoung.
2013.
Deep neural network approach for theDialog State Tracking Challenge.
In Proceedings ofSIGDIAL.Matthew Henderson, Blaise Thomson, and Jason D.Wiliams.
2014a.
The Second Dialog State TrackingChallenge.
In Proceedings of SIGDIAL.Matthew Henderson, Blaise Thomson, and Jason D.Wiliams.
2014b.
The Third Dialog State TrackingChallenge.
In Proceedings of IEEE SLT.Matthew Henderson, Blaise Thomson, and SteveYoung.
2014c.
Robust dialog state tracking usingdelexicalised recurrent neural networks and unsuper-vised adaptation.
In Proceedings of IEEE SLT.Matthew Henderson, Blaise Thomson, and SteveYoung.
2014d.
Word-based dialog state trackingwith recurrent neural networks.
In Proceedings ofSIGDIAL.Sungjin Lee and Maxine Eskenazi.
2013.
Recipe forbuilding robust spoken dialog state trackers: Dia-log State Tracking Challenge system description.
InProceedings of SIGDIAL.Sungjin Lee.
2013.
Structured discriminative modelfor dialog state tracking.
In Proceedings of SIG-DIAL.Anna Margolis, Karen Livescu, and Mari Ostendorf.2010.
Domain adaptation with unlabeled data fordialog act tagging.
In Proceedings of the ACL Work-shop on Domain Adaptation.David McClosky, Eugene Charniak, and Mark Johnson.2006.
Effective self-training for parsing.
In Pro-ceedings of HLT-NAACL.David McClosky, Eugene Charniak, and Mark Johnson.2010.
Automatic domain adaptation for parsing.
InProceedings of NAACL HLT.Hang Ren, Weiqun Xu, Yan Zhang, and Yonghong Yan.2013.
Dialog state tracking using conditional ran-dom fields.
In Proceedings of SIGDIAL.Gokhan Tur, Umit Guz, and Dilek Hakkani-T?ur.
2007.Model adaptation for dialog act tagging.
In Proceed-ings of IEEE SLT.Marilyn Walker, Amanda Stent, Franc?ois Mairesse, andRashmi Prasad.
2007.
Individual and domain adap-tation in sentence planning for dialogue.
Journal ofArtificial Intelligence Research, 30:413?456.Zhuoran Wang and Oliver Lemon.
2013.
A simpleand generic belief tracking mechanism for the Dia-log State Tracking Challenge: On the believabilityof observed information.
In Proceedings of SIG-DIAL.Jason D. Williams, Antoine Raux, Deepak Ramachan-dran, and Alan W. Black.
2013.
The Dialogue StateTracking Challenge.
In Proceedings of SIGDIAL.Jason D. Williams.
2013.
Multi-domain learning andgeneralization in dialog state tracking.
In Proceed-ings of SIGDIAL.Jason D. Williams.
2014.
Web-style ranking and slucombination for dialog state tracking.
In Proceed-ings of SIGDIAL.799
