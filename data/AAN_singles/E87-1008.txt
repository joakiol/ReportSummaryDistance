AUTOMATED REASONING ABOUT NATURAL LANGUAGE CORRECTNESSWolfgang MenzelZentral inst itut f~r SprachwissenschaftAkademie der Wissenschaften der DDRPrenzlauer Promenade 149-152Berl in,  II00, DDRABSTRACTAutomated Reasoning techniques applied tothe problem of natural language correct-ness allow the design of f lexible trainingaids for the teaching of foreign langua-ges.
The approach involves importantadvantages for both the student and theteacher by detecting possible errors andpointing out their reasons.
Explanationsmay be given on four dist inct levels, thusoffering di f ferent ly instructive errormessages according to the needs of thestudent.I.
THE IDEAThe application of techniques from thedomain of Automated Reasoning to theproblem of natural language correctnessoffers solutions to at least some of thedeficiencies of tradit ional approaches tocomputer assisted language learning.
Bysupplying a special ized inference mecha-nism with knowledge about what is correctwithin fragments of natural languageutterances, a flexible training device canbe designed.
It prompts the studentwith e .g .
randomly generated sentenceframes, where slots have to be fil led in.The system then accomplishes two maintasks:(I) It tries to diagnose possible errorsin the students response in order to buildup an internal model of the currentcapabil it ies of the student in terms ofstr ictly l inguistic categories.
(2) It gives an explanation of the diag-nostic results to guide the student in hissearch for a correct solution.In contrast to other approaches (c.f.Barchan et al 1985, Pulman 1984, Schwind1987) we concentrate our efforts more onthe handling of fragmentory utterances,instead of trying to analyse the correct-ness of complete sentences.
The enormousdiff icult ies connected with the design ofa universal error diagnosis for naturallanguage sentences may only part ial ly beseen as a motivation for this restriction.Other, equally important justif icationscould be mentioned as well:(I) The handl ing of only simple sen-tence fragments seems to be a more naturaland transparent l imitation compared withan ad hoc exclusion of important parts ofthe grammar from the rule system.
Promis-ing the student a universal sentenceacceptor, the real capabil it ies of whichare rather limited, may easi ly be mis-interpreted as a kind of bluff, since theconsequences of such a cut will alwaysremain a mysterious thing to the student.Severe restrictions on the grammaticalknowledge are inevitable at the moment,but probably nobody will ever be able toexplain the language competence of atraining system to a learner of a secondlanguage without total ly confusing him.Hence, minimising the problem of grammati-cal coverage by accepting only fragmentsof sentences, drast ical ly improves theprospects of f inally achieving somethinglike a "water-proof" solution.
Nothingcould be considered to be more harmful ina teaching environment than to blame asystem's failure on the student.
(2) The concentrat ion on small sub-fields of grammar makes the determinationof very precise and detai led diagnost icresults possible.
This, of course, is notso much important if seen only for thepurpose of direct explanation: An explana-tion overloaded with details is likely toirritate the student.
Nevertheless, avery precise diagnosis is a sound basisfor building up a model of the currentcapabil it ies of the student, which advan-tageously may be used to guide the furthercourse of interaction.
(3) The approach allows a stepwiseextension of the degree of sophist icat ionwhile preserving the same basic principleson all levels.
This enables a rathersmooth accomodation to dif ferent per-formance classes of hardware as well as aneasy adaptation to dif ferent paedagogicalobjectives.
Indeed, there are good reasonsto expect the very simple examples (e.g.the insertion of a correct German deter-miner) to be well suited for practical46training purposes.
(4) The focus on selected grammaticalregularities facil itates a systematictraining, which from a didactic viewpointseems to be more promising than just theunspecif ied invitation: "Type in an arbi-trary sentence!"
with the always presentrisk to catch the system out.
Here weprefer to guide the student in a ratherunconstrained way by prompting him withcarefully selected sentence frames orquestions.
To hide the limitations of thedictionary, as usual, the domain contextof a simple exercise environment (a room,a shop, an airport etc.)
is used.In its diagnostic capabil it ies thepresented approach shows a strong analogyto the basic concepts usually appliedwithin a system of Automated Reasoning: ahypothesis is verif ied to be in accordancewith a set of initial facts and a set ofrules, which for our special purpose modelthe correctness conditions of a specifictraining exercise.
The initial facts aregiven as a logical combination of syn-tactic and semantic features describingthe grammatical properties of certain wordforms in the system prompt.
The hypothesisresults from the the student's responsewhere word forms are internally represen-ted by their associated features as well.II.
KNOWLEDGE REPRESENTATIONTo formalize the correctness conditionsof natural language constructs in a lin-guist ical ly adequate manner we adopted twobasic operators from a dependency grammar?
model (Kunze 1975):constraints of the kind:(*** <destination> <condition>)transmitters of the kind:(<source> <destination> <category>)Both of them operate on feature sets.
Aconstraint reduces the feature set of aword form bound to the variable<destination> to its maximum subset whichsatisfies the given <condition>.
Transmit-ters car ry  features belonging to a speci-fic <category> from a <source> to a<destination>, changing the feature set atthe destination according to a predefinedagreement relation.
Typical categories arethe ordinary ones: GENDER, NUMBER, CASE,PERSON etc., but semantic or very languagespecific features (like INFLECTIONALDEGREE for German, cf.
ROdiger 1975) maybe used as well.
Accordingly, by means ofthese operators the conditions for themorpho-syntactic correctness within aCAT=PREPOS I TIONSELECT=DIRECTIONCASEI,PREP-3 ICASECAT=PREPOS ITIONSELECT=LOCATION\ARTICLECAT=POSSESSIVE-PRONOUNDEMONSTRATIVE-PRONOUNCASE INUMBER ~I *NOUN ICASECAT=NOUN GENDERINFLECTIONAL- ~ GREECAT=ADJECT IVEFigure I: Correctness conditions for a special German preposit ional phrase47simple German prepos i t ional  phrase of thetype (PREP DET ADJ NOUN) may be coded asshown in ~igure i.The " nodes in this graph denotevariables, which have to be bound tos ingle word forms.
Accord ing to theirvalue ass ignment  mode two types ofvar iables  may be dist inguished.
Contextvar iab les  belong to the sentence frame andreceive their  value (the feature set of aspec i f ic  word form) a l ready dur ing thesentence generat ion  process.
The value ofa slot variable, however, depends on thestudent's response and is estab l ished by apattern match ing procedure based main ly  onword class information.
The power of thepattern matcher  used determines a lmostcomplete ly  the f lex ib i l i ty  of the system:A rather s imple one, us ing ob l igatory  slotvar iab les  only (hence, rest r ic t ing theslot to a f ixed length) wil l  be suf f ic ientunder certa in c ircumstances.
The addit io-nal use of opt ional  s lot var iables  al lowsthe implementat ion  of more d ivers i f iedexercises.
Somet imes even a s imple parserfor sentence f ragments may be required.The t ransmit ters  obv ious ly  const i tutethe part  of rules wi th in  the knowledgebase.
They can eas i ly  be interpreted asdef in ing logical impl icat ions, semant ica l -ly extended by two ex istent ia l  quant i f iersfor the var iab les  <source> and<destination>.
In a certain sense trans-mit ters  correspond to the well knownConstraints:(***(***(***(***(***(***(*** *ADJ*PREP-4 (CAT PREPOSIT ION))*PREP-4 (SELECT DIRECTION))*PREP-3 (CAT PREPOSIT ION))*PREP-3 (SELECT LOCATION))*NOUN (CAT NOMINAL))*DET (CAT ARTICLEPOSSESS IVE-PRONOUNDEMONSTRATIVE-PRONOUN))(CAT ADJECTIVE))Transmitter:(*PREP-4 *NOUN CASE)(*PREP-3 *NOUN CASE)(*NOUN *DET CASE)(*NOUN *DET NUMBER)(*NOUN *DET GENDER)(*NOUN *ADJ CASE)(*NOUN *ADJ NUMBER)(*NOUN *ADJ GENDER)(*DET *ADJ INFLECTIONAL-DEGREE)f igure 2: Rule set for the example inf igure 1IF .
.
.THEN rules in a typical  expertsystem.The factual  knowledge, on the otherside, consists  of constra ints  (which couldbe thought  of to be t ransmit ters  with anowhere-source,  indicated by "***" in therule set of f igure 2) together  with thefeature combinat ions  in the d ic t ionaryentries.
Only  from the point  of v iew ofexp lanat ion the factual  in format ion has aspecial  status: one cannot  ask for it bymeans of a why-quest ion.III.
ERROR DIAGNOSISCommonly  one tr ies to d i s t ingu ish  thef ield of Automated Reasoning from thedeve lopment  of expert  systems by compar inga mean size of the knowledge base as wellas the length of a typica l  in ferencechain.
Normally, a system of AutomatedReason ing is expected to have a ratherl imited number of rules but the ab i l i ty  tohandle  extremely  long chains whereas thecharacter i s t i cs  of an expert  systeminclude p lenty  of rules but very  shortinferences.
In this respect, a system forforeign language t ra in ing  belongs to athird category, s ince both, the size ofthe knowledge base as well  as the meanlength of an inference path are com-parat ive ly  small.
Unfortunately,  thiss impl ic i ty  doesn ' t  result  in a very s impledes ign for the inference engine as well.D i f f i cu l t ies  ar ise from a pecu l ia r i ty  ofthe language t ra in ing task: On the onehand, facts and rules are g iven to de-scr ibe the c o r r e c t n e s s ofnatural  language constructs.
On the otherhand, exp lanat ions  are required about thed e f i c i e n c i e s of a studentssolution.
P robab ly  the system is neverasked to point  out the reasons why aspec i f ic  inference can be drawn, but it isexpected to expla in the reasons why acorrectness  proof  can n o t beestabl ished.
This, of course, requires aspecial  d iagnos is  procedure  which in thecase of an error in the student's responsesearches for p laus ib le  a l ternat ives  whichmight  have been leading to a correctsolution.The d iagnos is  is carr ied out in twosteps (f igure 3).
Us ing a c lass ica l  non-determin is t i c  forward chain ing a lgor i thmthe f irst step tr ies to show the correct -ness by success ive ly  apply ing constra intsand t ransmit ters  on all the feature setsprev ious ly  bound to variables.
A t ransmit -ter can be applied, if its source doesn ' tappear to be a dest inat ion  in any other48t ransmit ter  wait ing for appl icat ion yet.This implies that cycles of t ransmit tersare not a l lowed with in the knowledge base,a conf igurat ion  which actual ly  doesn' toccur in a natural  language sentence,anyhow.The appl icat ion of a constra int  or at ransmit ter  fails, if it results in anempty feature set at the dest inat ion.Fai lures due to the miss ing of facts inthe knowledge base may indicate an errorin the students response, and all thecategories, var iables and values concernedare stored as fa i lure points to beanalysed in detai l  later.
A sentence framecan be cons idered to be correct lycompleted by the student, if all there levant constra ints  and t ransmit ters  havebeen appl ied successful ly.
If such asolut ion cannot be found (that is, amistake of the student has beenencountered),  the second step resumes theanalysis  by invest igat ing the consequencesof assuming in each case just thecomplementory  feature set at the fa i lurepoint.
By doing this, the d iagnosisp rocedure  in fact tr ies to s imulate theignoring of the corresponding rule by thestudent and aims at f inding out all theresult ing consequences.To de l iver  the informat ion needed bythe second step of the d iagnosis  procedurerequires to extend the capabi l i t ies  of thebasic rout ine for feature set compar isonbeyond the usual un i f i cat ion  operations.In addit ion to the normal intersectionbetween the re levant features at the<source> and the <dest inat ion> theprocedure determines the complement  of thefeature set at the <dest inat ion> (seef igure 4).
To achieve the des i red highresolut ion of the d iagnos is  un i f i cat ion  isalways carr ied out for a s ingle category.All the other features are left unchanged.Given the case of an error in thestudents response the invest igat ion ofboth alternatives,  the intersect ion aswell as the complement  becomes necessary.That is, the d iagnos is  is confronted withan enormous number  of analysis  paths.Strong heur is t ic  cr i ter ia  are needed torestr ict  the size of the search spaceeffectively.
So far, an a lgor i thmcons ider ing only paths with a min imumnumber of fa i lure points has turned out tobe suf f ic ient  in most cases.IV.
EXPLANATION COMPONENTUsually, due to the often numerousmorpho-syntact ic  readings of a word formthe d iagnosis  component  comes out with acouple of poss ib le  error interpretations,all of them can by no means be expla inedto a student wi thout  tota l ly  confus inghim.
Again, heur is t ic  cr i ter ia  are neededto reduce the number of interpretat ions ina sens ib le  way.Step I: CORRECTNESS PROOFHypothes isinit ial factsStep II: INVESTIGATION OF INFERENCEFAILURESHypothes isI i 11/T2" +ILr  gGinit ial factsc=successful  t ransmit ter  appl icat ionfa i lure pointcomplementary  transmitter appl icat ionposs ib le  error explanat ionF igure 3: Two step d iagnos is49\[NOM1CASE : IGENIL Acc\]l unif ied with I\[NOM\]CASE = |DAT| \[ACC\]I results in: 1 CASE LAce\]CASE = \[DAT\](source)(destination)(intersection)(complement)Figure 4: Example for the extended featureset unif icationTo select an appropriate (that is,helpful from the students point of view)error descript ion the diagnostic resultshave to be ordered by an estimatedexplanatory power.
So far, the fol lowingcriteria have been taken intoconsideration:(I) A category preference, whichchooses a certain transmitter function(e.g.
GENDER) as a more probable one.
Thisis a simple but obviously crude andunrel iable criterion.
(2) The distance between the complemen-tary transmitter application and the hypo-thesis, whereby errors "higher up" in asentence structure are preferred.
Forexample, it is more likely that the casegoverned by a preposit ion has been mis-taken than that the agreement within thepreposit ional phrase is violated.
(3) In a multiple error diagnosis acategory common to most of the alterna~rives could be taken for the explanation.Given the very frequent error combination(CASE and GENDER) or (NUMBER and GENDER)missing gender agreement should be areasonable explanation.A good heuristics certainly has toinclude the structure of the dict ionaryentries and the rule set in its investiga-tion of possible alternatives.
If there isindeed a second reading with respect toone of the hypothesised error reasons thenprobably the student overlooked thispossibility.
Here further investigationsare necessary.From a paedagogical point of view itwould be desirable to explain the diagnos-tic results (detected errors and theirpossible reasons) on di f ferent ly instruc-t ive levels, selecting the right oneaccording to previous results or currentdesires of the student.
The fol lowing fourlevels seem to be appropriate and theore-t ical ly motivated:(I) r ight/wrong answer without furtherexplanation(2) explanation on the level of rules(e.g.
"missing gender agreement betweenxxx and yyy")(3 )  explanation on the level of facts(e.g.
"xxx is a feminine noun, hence youshould take a feminine determiner")(4) explanation on the level ofexamples using the inverted dict ionary asa data base to retrieve appropriate wordforms by means of the inferred featuresets.The verbal izat ion of an explanation isdone on the basis of sentence schemata,which have to be defined together with thecorrectness conditions.
On demand, theactual categories, values or examples areinserted and minor surface smoothingoperations are carried out.V.
DIALOG CONTROL & USER MODELLINGBy careful ly investigating a series ofresponses a model of the current capabil i-ties of the student can be build up.
Basedon this model the system autonomously mayvary dif ferent aspects of the dialogbehaviour.
The most simple example is theselection of one of the explanationlevels.
The system switches over to adeeper level of explanation if the studenteither repeatedly fails to find thecorrect solution or signals his inabil ityfor understanding the previous errormessage.
It goes back to a higher level ifconsecutive successes of the studentjustify this.A series of responses may contain hintsabout where the weaknesses of the studentactually lie.
Thus, in addition to thecriteria of section IV another heuristicsfor the selection of diagnost ic results isavailable: Continued repetit ion of one and50the same error type will cause theexplanation to focus on this category.Furthermore, the collected information canbe used to guide the training strategy.Exercise generation may be controlled tojust concentrate on the weak points of thestudent or even to alter the degree ofexercise difficulty.VI.
EXPERIMENTATIONTo study some selected problems (espe-cially the exploitation of heuristic ruleswithin the diagnosis and explanationcomponents) in greater detail, a firstprototype has been implemented.
Currentlythe system includes a random sentencegenerator to supply the system prompts, asimple pattern matcher for obl igatory slotvariables, the two step diagnosisdescribed above and an explanationcomponent up to the level of facts.The training examples studied so farhave mainly been taken from the area ofGerman noun phrase inflection (indeed anintricate subject from the foreigne{spoint of view).
The experiments confirmedthat simple versions of training exercisesmay run already on very cheap type ofhardware (i.e.
8-bit micros).the explanation mostly points out thelocation of the error rather precisely.
(4) A model of the student% capabil i-ties is built up and the teacher issupplied with a statistics in terms ofl inguistic categories even in the case ofvery complex or mixed exercises.
(5) Instead of explicit ly listing them,exercises can be generated automatically,thus achieving a variety which almostexcludes repetition even in the case ofextremely long or repeated trainingsessions.Limitations for the application domainmostly result from the feature basedapproach to knowledge representation.
Itfirst of all predestines the solution forthe training of morpho-syntactic reg-ularities (esp.
agreement relations).
Tohandle problems of e.g.
usage or style ina suff ic iently general manner seems to befar beyond the current possibil ities.REFERENCESVII.
DISCUSSIONThe design of foreign language trainingsystems based on fundamental techniques ofAutomated Reasoning exhibits severalimportant advantages as compared with animmediate implementation of the almosttrivial scheme a Pattern Drill Book isbased upon:(I) Automated Reasoning allows moreflexibility.
Not the one correct solutionis asked for.
The student may chooseh i s solution within the limitations ofthe dict ionary (expressed by the exerciseenvironment).
Dialog situations may easilybe simulated.
Experimentation becomespossible.
(2) In addition to the right/wrongdiagnosis further three levels of explana-tion are available.
A correct solution canbe generated just for the part icular wordsamples chosen by the student.
(3) It becomes possible to includerather complex regularit ies between con-text and slot variables.
Nevertheless,Barchan, J.; Woodmansee, B. and Yazdani,M.
(1985) Computer Assisted Instructionusing a French Grammar Analyser.Research Report 128, Department ofComputer Science, University of Exeter.Kunze, J.
(1975) Abh~ngigkeitsgrammatik.studia grammatica XII, Akademie-Verlag,Berlin.Pulman, S.G. (1984) Limited DomainSystem for Language Teaching.Proceedings Coling 84, Stanford: 84-87.RGdiger, B.
(1975) Flexivische und Wort-bi ldungsanalyse des Deutschen.Linguist ische Studien, Reihe A, Sonder-heft 1975, Berlin.Schwind, C.B.
(1987) Prototyp einesSprachtutorensystems fGr Deutsch alsFremdsprache, KI-Rundbrief 44, Januar1987: 42Wos, L.; Overbeek, R.; Lusk, E. and Boyle,J .
(1984) Automated Reasoning.
PrenticeHall, Englewood Cliffs.51
