Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 587?595, Vancouver, October 2005. c?2005 Association for Computational LinguisticsCombining Multiple Forms of Evidence While FilteringYi Zhang ?Information System and Technology ManagementSchool of EngineeringUniversity of California, Santa CruzSanta Cruz, CA 95064, USAyiz@soe.ucsc.eduJamie CallanLanguage Technologies InstituteSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213, USAcallan@cs.cmu.eduAbstractThis paper studies how to go beyond relevanceand enable a filtering system to learn more in-teresting and detailed data driven user modelsfrom multiple forms of evidence.
We carry outa user study using a real time web based per-sonal news filtering system, and collect exten-sive multiple forms of evidence, including ex-plicit and implicit user feedback.
We explorethe graphical modeling approach to combinethese forms of evidence.
To test whether the ap-proach can help us understand the domain bet-ter, we use graph structure learning algorithmto derive the causal relationships between dif-ferent forms of evidence.
To test whether theapproach can help the system improve the per-formance, we use the graphical inference algo-rithms to predict whether a user likes a docu-ment based on multiple forms of evidence.
Theresults show that combining multiple formsof evidence using graphical models can helpus better understand the filtering problem, im-prove filtering system performance, and handlevarious data missing situations naturally.1 IntroductionAn adaptive personal information filtering system is anautonomous agent that delivers information to the user ina dynamic environment over a period of time.
A com-mon filtering approach is adapting existing text classi-fication/retrieval algorithms to classify incoming docu-ments as either relevant or non relevant using user pro-files learned from explicit user feedback on documentsthe user has seen.
However, there are other importantcriteria for the user besides relevance, such as readabil-ity (Collins-Thompson and Callan, 2004), novelty (Har-man, 2003), and authority (Kleinberg, 1998).
Besides,much information about the user and the document canbe collected by a filtering system.
These suggest a way toimprove the current filtering system: going beyond rele-vance and using multiple forms of evidence.
?This research was done while at the Language Technolo-gies Institute, Carnegie Mellon University.Unfortunately, there is no standard evaluation data setfor this research, and there is not much work on findinga good theory to combine various forms of evidence.
Tosolve the first problem, we designed a user study and col-lect thousands of cases with multiple forms of evidence,including the content of a document, explicit and im-plicit user feedback, such as a user?s mouse usage, keyboard usage, document length, novelty, relevance, read-ability, authority, user profile characteristics, news sourceinformation, and whether a user likes a document or not.Solving the second problem is very challenging.
A goodmodel should have the representation power to combinemultiple forms of evidence; it should be able to help usunderstand the relationships between various forms of ev-idence; it should use the evidence to improve filteringsystem performance; and it should handle various prob-lems like missing data in an operational environment ro-bustly.On the other hand, researchers have identified threemajor advantages of graphical modeling approach: 1) itprovides inference tools to naturally handle situations ofmissing data entry because of the conditional dependen-cies encoded in the graph structure; 2) it can learn causalrelationships in the domain, thus help us to understandthe problem and to predict the consequences of interven-tion; and 3) it can easily combine prior knowledge (suchas partial information about the causal relationship) withdata in this framework.
This approach has been appliedto model computer software users (Horvitz et al, 1998),car drivers (Pynadath and Wellman, 1995), and students(Conati et al, 1997).
Motivated by the prior work, wechoose to use graphical models as our solution.
To under-stand relationships between various forms of evidence,we use the causal graph structure learning algorithms (ad-vantage 2), together with some prior knowledge of thedomain (advantage 3), to derive the causal relationshipsbetween different user feedback, actions and user con-text.
To improve the existing filtering system, especiallyin the situation of missing data, we use statistical infer-ence tools to predict how a user will like a document,using information available in different missing evidencesituations (advantage 1).
We also try linear regression asan alternative approach.The following sections describe our efforts towards587Figure 1: The user study system structure.
The structuredinformation, such as user feedback and crawler statistics,are kept in the database.
The content of each web pagecrawled is saved in the news repository.collecting data and customizing the graphical modelingapproach to combine multiple forms of evidence for fil-tering.
We begin with a description of the user study inSection 2, followed by some preliminary data analysison the data collected in Section 3.
Section 4 explorescausal structure learning algorithm to understand the re-lationships between various forms of evidence from thedata and Section 5 explores how to improve the systemperformance using multiple forms of evidence.
Section6 discusses related work and how this work differs fromexisting work, and Section 7 concludes.2 User StudyNo existing filtering database contains the level of detailthat we needed for our study, so we developed a webbased news story filtering system to collect an evalua-tion data set (Figure 1).
This system constantly gathersand recommends information to the users.
The systemincludes a crawler with 8000 candidate RSS news feeds(Pilgrim, 2002) to crawl every day.
The Lemur indexerindexes the crawled document stream incrementally, andan adaptive filtering system recommends documents tothe users using a modified logistic regression algorithm(Zhang, 2004).
Users read and evaluate what the systemhas delivered to them.
An example of the web interfaceafter user login is in Figure 2.More than 20 paid subjects from 19 different programsat Carnegie Mellon University, who are otherwise not af-filiated with our research, participated in the study for 4weeks.
We expected to collect enough data for evalua-tion over this period of time.
The subjects were requiredto read the news for about 1 hour per day and provideexplicit feedback for each page they visited.
1 28 users1In the last week of the study, some subjects read 2 hoursper day.
They are encouraged but not required to do so.Figure 2: Web interface after a user logged in.Figure 3: Evaluation user interface.
The interface for userto give their explicit feedback of the current news story.tried this system.
However, only 21 users are official paidsubjects, among which one worked only for 2 weeks and20 worked for about 4 weeks.2.1 Data collectedWe have collected 7881 feedback entries from all 28users, among which 7839 were from the 21 official par-ticipants.
Each entry contains several different forms ofevidence for a news story a user clicked.2 Our intentionto collect the evidence is not to be exhaustive, but repre-sentative.
The evidence can be roughly classified into thefollowing five categories listed in Tables 1 to 5.3Explicit user feedback After finishing reading a newsstory, a user clicks a button on the toolbar of thebrowser to bring up an evaluation interface shown inFigure 3.
Through this interface, the user providedthe explicit feedback to tell the hidden propertiesabout current story, including the topics the newsbelongs to (classes), how the user likes this news2Each entry is for a <document, user class, time> tuple.3The forms of evidence are listed in the first column and wewill get the the other columns later in Section 3.588(user likes), how relevant the news is related to theclass(es) (relevant), how novel the news is (novel),whether the news matches the readability level ofthe user (readable), and whether the news is au-thoritative (authoritative).
user likes, relevantand novel are recorded as integers ranging from 1(least) to 5 (most).
readable and authoritative arerecorded as 0 or 1.
A user has the option to providepartial instead of all explicit feedback.
A user cancreate new classes, and choose multiple classes forone documents.User actions The browser adapted from (Claypool et al,2001) recorded some user actions, such as mouse ac-tivities, scroll bar activities, and keyboard activities(Table 2).
TimeOnPage is the number of seconds theuser spent on a page, and EventOnScroll is the num-ber of clicks on the scroll bars.
When the mouseis out of the browser window or when the browserwindow is not focused, the browser does not captureany activities.
More details about the actions are in(Le and Waseda, 2000).Topic information Each participant filled out an exitquestionnaire and answered several topic/class4 spe-cific questions for each of his/her most popular 10topics and other topics with more than 20 evalu-ated documents each (Table 3).
The questions in-clude how familiar the user is with the topic be-fore the study (topic familiar before), how the userlikes this topic (topic like), and how confident theuser is with respect to the answers he/she provided(topic confidence).
We include this informationas evidence, because they may be collected whena topic is created and used by filtering systems.Whether collecting them in exit questionnaire af-fects the answers needs further investigation.News Source Information For each news source (RSSfeed), we collected the number of web pages thatlink to it (RSS link), the number of pages that link tothe server that provided it (host link), and the speedof the server that hosts it.Content based evidence Three pieces of evidence arecollected to represent the content of each document:the relevance score, the readability score and thenumber of words in the document (doc len) (Table5).
To estimate the relevance score of a document,the system processes all the documents a user putinto a class ordered by the feedback time and adap-tively learns a topic specific relevance model usingthe relevance feedback the user provided.
The rel-evance score of a documents is estimated using a4?topic?
and ?class?
are used interchangeably in the paper.Table 1: Basic descriptive statistics about explicit feed-backs.Variable Mean variance corr missuser likes 3.5 1.2 1 0.05relevant 3.5 1.3 0.73 0.005novel 3.6 1.33 0.70 0.008authoritative 0.88 0.32 0.50 0.065readable 0.90 0.30 0.54 0.012modified logistic regression model learned from allfeedback before it (Zhang, 2004).
To estimate thereadability score of document, the system processesall the documents in all users?
classes ordered by thefeedback time and adaptively learns a user indepen-dent readability model using a logistic regression al-gorithm.3 Preliminary data analysisThe means and variances of all variables are in Tables 1 to5.
These basic descriptive statistics are very diverse.
Thevalues of some evidence may be missing; only the useractions and news source information were always col-lected.
Out of the 7991 entries, only 4522 (57%) entriescontain no missing value.
The missing rate of each formof evidence is also reported in the tables.
There are sev-eral reasons for missing data.
For example, the explicitfeedback is missing because users didn?t always followinstructions, the relevance score is missing for the firststory in a class, and the topic familiar before valuesfor many topics are missing because we only collectedthe topic specific answers for larger topics.
We expectmissing data to be common in operational environments.The correlation coefficient between each evidence andthe explicit feedback user likes is also listed (corr).The high correlation coefficients between user likes andother forms of explicit feedback are not very interest-ing because we can only get explicit feedback after auser reads the document.
The correlation coefficient be-tween relevance score and user likes is 0.37, the highestamong all forms of evidence that the system can get be-fore delivering a document.
This is not surprising sincemost filtering systems only consider relevance and userelevance score to make decisions.The correlation coefficients between user likes andthe topic information (Table 3) are relatively high.This suggests collecting topic familiar before ortopic like in a real filtering system, since they are in-formative and collecting them requires less user effort (auser only needs to provide information on the class levelinstead of document level).
Section 5 will show how touse it with other forms of evidence in a filtering system.The correlation coefficients between the news source in-589Table 2: Basic descriptive statistics about user actions.The unit for time is second.Variable Mean variance corrTimeOnPage 7.2?
104 1.3?
105 0.14EventOnScroll 1 3.6 0.1ClickOnWindow 0.93 2.5 0.05TimeOnMouse 2?
103 5.8?
103 0.02MSecForDownArrow 211 882 0.08NumOfDownArrow 1.1 4.7 0.09MSecForUpArrow 29 240 0.03NumOfUpArrow 0.10 0.8 0.04NumOfPageUp 0.12 0.9 ' 0NumOfPageDown 0.14 1 ' 0MSecForPageUp 22 202 ' 0MSecForPageDown 28 251 ' 0Table 3: Basic descriptive statistics about topics.
Eachvariable ranges from 1 to 7.variable Mean variance corr misstopic familiar before 3.6 1.9 0.30 0.27topic like 4.9 2.0 0.30 0.27topic confidence 4.7 2.0 0.34 0.27Table 4: Basic descriptive statistics about news sources.variable Mean variance corrRSS link 90.35 4.89 0.14host link 4.41?
104 7.5?
107 0.08RSS SPEED 3.92?
105 3.7?
109 -0.08Table 5: Basic descriptive statistics about documents.The length of the document does not include HTML tags.variable mean variance corr missdoc length 837 1.2?
103 0.04 0.05relevant score 0.49 0.42 0.37 0.18readability score 0.52 0.16 0.25 0.11formation and user likes are weaker (Table 4).
The cor-relation coefficient between user likes and each user ac-tion (Table 2) is even lower (Table 1).
Some actions, suchas TimeOnPage, are more correlated with user likesthan other refined actions, such as NumOfPageDown.This finding agrees with (Claypool et al, 2001).4 Understanding the domain using causalstructure learningCorrelation analysis in Section 3 has helped us to getsome initial idea about the data collected.
However, inorder to better understand the underlying truth of the do-main, we need to go beyond correlation and uncover thecausal relationships between different variables.To do that, we first specify N nodes, one for each formof evidence to be included in the model.
Then PC algo-rithm is used (Spirtes et al, 2000) to search the causalrelationships between multiple forms of evidence fromthe data collected.
To make the search space smaller,some prior domain knowledge, such as forbidden edges,required edges or temporal tiers, can be introduced be-fore searching.
In our experiments, we manually spec-ified some prior knowledge based on the first authors?experience and intuition as the following 5-tier tempo-ral tier: 5 1) Topic info = (familiar topic before),RSS info =(RSS link, host link), document length(doc len); 2) hidden criteria, such as relevant, novel,authoritative, and readable; 3) system generatedscores, such as relevance score and readability score; 4)user likes; 5) user actions, such as seconds spent on apage (TimeOnPage) or the number of clicks on the ?
key(NumOfDownArrow).
This informs the learning algo-rithm that?
from a higher level to lower level is prohib-ited.It is very encouraging to see that the structure learnedautomatically looks reasonable (Figure 4).
Accord-ing to the graph, novel, relevant, authoritative,readabilty of a document and whether a user isfamiliar with the topic before using the system(familar topic before) are direct causes of the user?spreference for a document (user likes) .
How fa-miliar with this topic a user is before participatingthe study (topic familiar before) and the number ofweb links to the news source (RSS link) directly af-fect the user?s relevant and authoritative feedbackand readability score.
Relevant, authoritative,familiar topic before and host link influence a user?sactions, such as the EventOnScroll.Comparing Tables 2 to 5 with Figure 4, one may askwhy some variables are correlated with user likes al-though there is no direct links between them and userlikes.
For example, why the correlation between rele-vance score and user likes is 0.39, while there is no di-rect link between them.
Does Figure 4 contradict Ta-ble 5?
The answer is ?no?.
In fact the indirect causalrelationship between them tells us why relevance scoreand user likes are correlated: relevance score and userlikes have a common cause relevant.
Most of the re-fined actions, such as the number of pressing page up key(NumOfPageUp), are far away from user likes.
Thisimplies that these refined actions are not very informativeif we want to use the learned model to predict whethera user likes a document or not.
This finding agree with(Claypool et al, 2001) and Table 2.The node authoritative is directly linked toreadability score and host link.
The link betweenhost link and authoritative confirms the existing ap-proaches that use the web link structure to estimate the5Other priors are also possible.590Figure 4: User independent causal graphical structurelearned using PC algorithm.
X ?
Y means X is a di-rect cause of Y. X ?Y means the algorithm cannot tell ifX causes Y or if Y causes X. X ??
Y means the algo-rithm found some problem, which may happen due to alatent common cause of X and Y, a chance pattern in thesample, or other violations of assumptions.Figure 5: Structure of GM complete.Figure 6: Structure of GM causal.authority of a page (Kleinberg, 1998).
The links betweenreadability score, readable and authoritative are veryinteresting.
They suggest the difficulty to understand apage may make the user feel it is not authoritative.
Fur-ther investigation shows that although the percentage ofun-authoritative news is less than 15% in general, amongthe 187 news stories some users identified as ?difficult?using class labels, 73% were also rated as not authorita-tive.
Besides some successful web page authority algo-rithms that only use hyper links, the estimation of author-ity may be further improved using the content of a page.There are links among relevant, novel, readable andauthoritative.
Although the algorithm failed to tell thecausal direction between some pairs of variables, it sug-gests that the four variables influence each other.
Thismay be an inherent property of the document; or becausea user is likely to rate one aspect of the document higherthan he/she should if the other aspects are good.One may ask why the structure in Figure 4 containsno link between readable and readability score, sinceintuitively it should exist.
To answer this question, oneneeds to understand that the causal relationships learnedautomatically are what the algorithm ?believes?
based onthe evidence of the data, the assumptions it makes, andthe prior constraints we engineered.
They may have er-rors, because the data is noisy, or the assumptions andthe prior constraints may be wrong.
For example, the PCalgorithm do statistical test about the independence re-lationships among variables using the data and the finalresults are subject to the error of the statistical test.
ThePC algorithm assumes no hidden variables, however be-sides relevant, novel, authoritative, and readable, otherhidden variables, such as whether a document is up-to-date, interesting, misleading, etc.
(Schamber and Bate-man, 1996), may exist and influence a user?s preferencefor a document.
Thus it is not surprising that some of thecausal relationships, such as the link between readableand readability score, are missed in the final graph be-cause of the limitation of the learning algorithms.
Themodel learned only sheds some light on the relationshipsbetween the variables instead of uncovering the wholetruth.
It only serves as a starting point for us.
To furtherunderstand the domain, we may want to break down somevariables in the current graph further and relate them toeither the user or document properties.
In general, causaldiscovery is inherently difficult and far from solved.5 Improving system performance usinginference algorithmsA primary task of a filtering system is to predict userpreference (user likes) for a document so that the sys-tem can decide whether to deliver it to the user.
Totell whether combining multiple forms of evidence using591graphical models can improve system performance, weevaluate the proposed solution on the task of predictinguser likes while filtering.To predict user likes, the system needs to learn agraphical model: the combination of a graph structureand a set of local conditional probability functions or po-tential functions.
Doing inference over the causal struc-ture learned in the previous section is difficult because ofthe circles and a mixture of directed and undirected linkson the graph.
So, we tried the following directed acyclicgraphical models.GM complete, an almost complete Bayesian network:In this graph, we order the nodes from top to bot-tom, and the parents of a node are all the nodesabove it, such as in Figure 5.
For this structure, theorder of the nodes is not very important when usingGaussian distributions.GM causal, a graphical model inspired by causal models:We manually modify the causal structure in Figure4 to make it a directed acyclic graph as in Figure 6.In the graphs, RSS info=(RSS link, host link) and Topicinfo=topic familiar before, topic like) are 2 dimensionalvectors representing the information about the newssource and the topic in Table 4 and Table 3. actions =(TimeOnPage, ...) is a 12 dimensional vector repre-senting the user actions in Table 1. user likes is thetarget variable the system wants to predict.Before learning the parameters of the model, we needto choose a specific conditional form for the probabilityfunction associated with each node.
We chose Gaussiandistributions.
If the parents of node X are Y, P (X|Y ) =N(m + W ?
Y,?
), where N(?,?)
is a gaussian distri-bution with mean ?
and covariance ?.
This is a com-monly used distribution for continuous valued nodes.
Itassumes the joint distribution of these variables is mul-tivariate Gaussian, which may be wrong.
Nevertheless,because of the mathematical convenience, the existenceof efficient learning and inference algorithms for Gaus-sian networks, and the availability of modeling tools, wechose this distribution.
Using the BNT Toolbox (Mur-phy, 2001), the maximum likelihood estimations of theparameters (m,W,?)
were learned using EM algorithmand junction tree inference engine(Cowell et al, 1999)over the graphical models, with whatever informationwas available on the first 2/3 of the data.An alternative approach to combine multiple forms ofevidence is linear regression.
We tried two special meth-ods to solve the missing evidence problem while usinglinear regression: 1) building a model that does not usethe evidence that is missing for each missing situation(LR different); or 2)mean substitution: replacing eachmissing value for an evidence with the average of theFigure 7: Comparison of the prediction power of differ-ent models using 7952 cases for evaluation.
The verticalaxis is the correlation coefficient between the predictedvalue of user likes using the model and the true explicitfeedback provided by the users.
The order of differentforms of evidence is set manually, based on how easy itis to collect each evidence.observed evidence (LR mean).
For K different formsof evidence, the system may need to handle 2K differ-ent evidence missing situations.
A large number of linearregression models need to be learned if we use the firstapproach, considering K is higher than 15 in some of ourexperiments.
Building 215 models is almost impossiblefor us, so a heuristic approach, which is discussed later,was used to make the experiments possible.Not all 7991 cases collected in the user study wereused in the experiments.
We conducted two sets of ex-periments.
For the first set of experiments, we use 7952cases for which user likes is not missing.
For the otherset of runs, we use only cases without missing value.
Inthis task, the value of each variable is continuous and nor-malized to variance one.
Each model is learned using allinformation available on the first 2/3 of the cases, andtested on the remaining 1/3 of the cases.
The correlationcoefficient between the predicted value of user likes andthe true explicit user likes feedback provided by theusers is used as the evaluation measure.
Our baseline isusing relevance score alone, which has a correlation co-efficient of 0.367 with 95% confidence interval 0.33-0.40on the last 1/3 of the 7952 cases.5.1 Experimental results and discussionsFigure 7 shows the effectiveness of different modelsat different testing conditions as indicated by the hor-izontal axis.
From left to right, additional sourcesof evidence are given when testing.
At the very leftof the figure (x=RSS info), a model predicts the592value of user likes only given the value of RSS infoat testing time.
?+explicit?
means the explicit feed-back (except user likes) about the current document isgiven besides the value of actions, relevance score,readability score, RSS info, and TopicInfo.
Thegraphical models and LR mean model were trained withall evidence/features, and the learned models are inde-pendent of the testing condition.
LR different modelswere only trained with features that are also provided attesting time, so there is one model per testing condition.6The results show that GM complete performs sim-ilarly to LR different.
This is not surprising.
Theo-retically, if there is no missing entries in training data,GM complete?s estimation of the conditional distribu-tion of P (user likes|available evidence) would be thesame as that of LR different on a testing case with miss-ing evidence.Comparing the correlation coefficients under dif-ferent testing conditions when using LR different orGM complete, we can see that as more forms of ev-idence are available, the performance improves.
Ifonly the news source information of a document(RSS info) is given, all models perform poorly.
Thereadability score improves the system performance sig-nificantly.
This is nice and interesting, because the evi-dence is user independent and can be estimated efficientlyfor each document.
The performance keeps improvingas topic info and relevance score were added.
Tocollect them, we needs user feedback on previous doc-uments.
The performance improvement is not very ob-vious with actions added.
This means that given otherevidence (RSS info, topic info, relevance score andreadability score), the system won?t improve its predic-tion of the document much by observing these actions.However, this is only true when we use a model learnedfor all users and other forms of evidence are available.
Itdoes not mean the actions are useless if we learn userspecific model, or if other forms of evidence (such asrelevance score) are not available.
All models performvery good with explicit feedback added.
However, this isa ?cheating?
condition of less interest to us.The performances of LR mean and GM causaldo not increase monotonically as more forms of ev-idence are added.
They perform much worse thanLR different and GM complete.
Why does a structurethat looks more causally reasonable not perform well6However, for a specific testing condition, the training dataand testing data contain cases where some evidence that is sup-posed to be available is missing.
These cases in training datawere ignored and not used to learn a LR different model.However, ignoring such kind of cases in testing data makescomparison of different runs difficult.
So we used mean sub-stitution approach to fill the required missing features in testingdata while using LR different.Model Cond.
corr RLow RUpLR mean +R 0.2783 0.2426 0.3132LR different +R 0.4372 0.4058 0.4677GM complete +R 0.4247 0.3928 0.4555GM causal +R 0.3078 0.2728 0.342LR mean +A 0.2646 0.2286 0.2998LR different +A 0.4375 0.406 0.4679GM complete +A 0.4315 0.3999 0.4622GM causal +A 0.3086 0.2736 0.3428Table 6: A comparison of different models on all data un-der the +relevance score (+R) and +action (+A) con-ditions.
Corr is the correlation coefficient between thepredicted value of user likes using the model and thetrue explicit feedback provided by the users.
RLO andRUP are the lower and upper bounds for a 95% confi-dence interval for each coefficient.as the simple GM complete?
We may answer thisquestion better by comparing the underlying assumptionsof these algorithms.
GM complete only assumes thejoint distribution of all variables is multivariate Gaus-sian.
GM causal makes much stronger independenceassumptions by removing some links between variables.As mentioned before, the causal relationships learned au-tomatically are not perfect, which may cause the poorperformance of GM causal.
LR mean also suffersfrom the strong conditional independent assumptions.Table 6 reports the performance together with theconfidence intervals of all the models under the+relevance score and +actions conditions.
Underboth conditions, GM complete and LR different arestatistically significantly better than the baseline 0.367.LR mean and GM causal are significantly worse.
Itmeans using multiple forms of evidence may hurt somemodels and benefit others.
Further analysis about the+actions runs shows that LR mean gave explicit feed-back too much weight and overlooked other less strongevidence.
At testing time, it did not handle the problem ofmissing explicit feedback well and thus performed poorly.Although GM complete also gave very high weights toexplicit feedback, it could infer the missing values basedon other available evidence at testing time, thus per-formed better than LR mean.
LR different didn?t con-sider explicit feedback for training, thus it didn?t over-look other forms of evidence and suffer from the problemless.
LR mean may work reasonably if explicit vari-ables are not included, however the large difference onhow informative each evidence is will still hurt the per-formance of LR mean to some extent when some strongevidence is missing.
For GM complete approach, a sin-gle model is needed to handle various evidence missingsituations.
If we use LR different approach, several mod-els are needed.
As we mentioned before, there are 2K593Model Cond.
Corr RLow RUpLR mean +R 0.13 0.08 0.18LR different +R 0.41 0.37 0.45GM complete +R 0.41 0.37 0.45GM causal +R 0.41 0.375 0.45LR mean +A 0.11 0.061 0.16LR different +A 0.42 0.38 0.46GM complete +A 0.42 0.38 0.46GM causal +A 0.38 0.33 0.42Table 7: The performance on 4522 no missing value casesunder the +relevance score (+R) and +action (+A)conditions.different evidence missing combinations, and 2K linearregression models are needed in order to handle all thesesituations using LR different approach.
LR different maybe preferred if K is small, while graphical modeling us-ing GM complete may be a better approach to handledifferent data missing situations if K is big.So far, all results are based on 7952 cases wheresome evidence may be missing.
We also comparedthe models under different testing conditions using the4522 cases that do not have any missing value (Table7).
GM causal performs significantly better than be-fore.
We need to be very careful with the structures whileusing the graphical modeling approach, since a structurethat looks more reasonable may work poorly on the in-ference task.
However, we couldn?t not draw any con-clusion on whether GM complete is better in general,because the answer may be different with different con-ditional probability distributions, different data sets, or abetter structure learning algorithm.6 Related WorkThere has been some research on news filtering usingtime-coded implicit feedback (Lang, 1995; Morita andShinoda, 1994).
We noticed that an independent workuses a different graphical modeling approach, depen-dency network, to understand the relationships betweenimplicit measures and explicit satisfaction while userwere conducting their web searches and viewing results,and then uses decision tree to predict user satisfactionwith results (Fox et al, 2005).
Our work differs fromthe previous work in the goal of the task, the range of ev-idence considered, the modeling approach we took, andthe findings reached.There has been a lot of related research on using im-plicit feedback (Kelly and Teevan, 2003).
The useractions we collected are based on (Claypool et al,2001).
There is much work about how to handle miss-ing data.
(Schafer and Graham, 2002) discussed severalapproaches such as case deletion, mean substitution, andrecommended maximum likelihood (ML) and Bayesianmultiple imputation (MI).
LR mean uses mean substitu-tion, LR different uses case deletion, and graphical mod-els follow the ML approach.There has been some research on criteria beyond topicrelevance (Carbonell and Goldstein, 1998) (Zhang et al,2002) (Collins-Thompson and Callan, 2004) (Kleinberg,1998).
(Schamber and Bateman, 1996) identified crite-ria underlying users?
relevance judgements and exploredhow users employed the criteria in making evaluationsby asking users to interpret and sort criteria independentof document manually.
In the literature, the word ?rele-vant?
is used ambiguously, either as a narrow definitionof ?related to the matter at hand (aboutness)?
or a broaderdefinition of ?having the ability to satisfy the needs of theuser?.
When it is used by the second definition, such asin (Schamber and Bateman, 1996), researchers are usu-ally studying what we refer to as user likes.
In this paper,we use ?relevant?
as is defined in the first definition anduse the phrase ?user likes?
for the second definition.
De-spite the vocabulary difference, our work is motivated bythe early research.
The major contributions of our workin this area are: 1) we model the user likes and other cri-teria as hidden variables; 2) we quantify the importanceof various criteria based on probabilistic reasoning; and3) we have explored the new methodology for combiningthese criteria with implicit and explicit user feedback.7 CONCLUSIONWe have explored how to combine multiple forms of evi-dence using the graphical modeling approach.
This workis significant because it addresses some long-standing is-sues in the adaptive information filtering community: theintegration of a wider range of user-specific and user-independent evidence, and handling situations like miss-ing data that occur in operational environments.We have analyzed the user study data using graphicalmodels, as well as linear regression algorithms.
The ex-perimental results show that the graphical modeling ap-proach can help us to understand the causal relationshipsbetween multiple forms of evidence in the domain andexplain the real world scenario better.
It can also helpthe filtering system to predict user preference more accu-rately with multiple forms of evidence compared to usinga relevance model only.As more forms of evidence are added, missing data is acommon problem because of system glitches or becauseusers will not behave as desired.
A real system needs tohandle missing data by either ignoring it or by estimat-ing it based on what is known.
The graphical modelingapproach addresses this problem naturally.
LR differenthandles the problem by building many different models tobe used at different data missing conditions.
LR differentand GM complete perform similarly.
When the types594of evidence is few, LR different probably is preferablebecause of the simplicity.
However, as more forms ofevidence are added, a more powerful model, such asGM complete, may be preferred because of the com-putation and space efficiency.We only collected data for documents users clicked.Further investigation is needed to look at data not clicked,which is a critical step to see whether the improvement onprediction accuracy of user preference will help the sys-tem serve the user better in a real system.
This is the firststep towards using graphical models to combine multipleforms of evidence while filtering.
The proposed solution,especially the data analyzing methodology used in thispaper, can also be used in other IR tasks besides filtering,such as context-based retrieval.8 AcknowledgmentsWe thank Jaime Carbonell, Tom Minka, Stephen Robert-son, Yiming Yang, Wei Xu, Peter Spirtes, Diane Kelley,Paul Ogilvie, Kevyn Collins-Thompson, Luo Si, JoemonJose for valuable discussions about the work described inthis paper.This research was funded in part by a fellowship fromIBM and a grant from National Science Foundation.
Anyopinions, findings, conclusions or recommendations ex-pressed in this paper are the authors?, and do not neces-sarily reflect those of the sponsors.ReferencesJaime Carbonell and Jade Goldstein.
1998.
The use ofMMR, diversity-based reranking for reordering docu-ments and producing summaries.
In Proceedings ofthe 21st annual international ACM SIGIR conference.Mark Claypool, Phong Le, Makoto Wased, and DavidBrown.
2001.
Implicit interest indicators.
In Intel-ligent User Interfaces.K.
Collins-Thompson and J. Callan.
2004.
A languagemodeling approach to predicting reading difficulty.
InProceedings of the HLT/NAACL 2004 Conference.C.
Conati, A. S. Gertner, K. VanLehn, and M. J.Druzdzel.
1997.
On-line student modeling forcoached problem solving using Bayesian networks.
InProceedings of the Sixth International Conference onUser Modeling, pages 231?242.Robert G. Cowell, A. Philip Dawid, Steffen L. Lauritzen,and David J. Spiegelhalter.
1999.
Probabilistic Net-works and Expert Systems.
Springer.Steve Fox, Kuldeep Karnawat, Mark Mydland, SusanDumais, and Thomas White.
2005.
Evaluating im-plicit measures to improve web search.
In ACM Trans.Information Systems, volume 23.Donna Harman.
2003.
Overview of the TREC 2002 nov-elty track.
In The Eleventh Text REtrieval Conference(TREC-11).
NIST 500-251.E.
Horvitz, J. Breese, D. Heckerman, D. Hovel, andK.
Rommelse.
1998.
The Lumiere project: Bayesianuser modeling for inferring the goals and needs of soft-ware users.
In Proceedings of the Fourteenth Confer-ence on Uncertainty in Artificial Intelligence, July.Diane Kelly and Jaime Teevan.
2003.
Implicit feedbackfor inferring user preference: a bibliography.
SIGIRForum, 37(2):18?28.J.
Kleinberg.
1998.
Authoritative sources in a hyper-linked environment.
In Proc.
9th ACM-SIAM Sympo-sium on Discrete Algorithms.Ken Lang.
1995.
Newsweeder: Learning to filter news.In Proceedings of the Twelfth International Conferenceon Machine Learning.Phong Le and Makoto Waseda.
2000.
A curious browser:Implicit ratings.
http://www.cs.wpi.edu/ clay-pool/mqp/iii/.Masahiro Morita and Yoichi Shinoda.
1994.
Informa-tion filtering based on user behavior analysis and bestmatch text retrieval.
In Proceedings of the 17th ACMSIGIR conference.Kevyn Murphy.
2001.
The Bayes net toolbox for matlab.In Computing Science and Statistics.Mark Pilgrim.
2002.
What is RSS.http://www.xml.com/pub/a/2002/12/18/dive-into-xml.html.D.V.
Pynadath and W.P.
Wellman.
1995.
Accounting forcontext in plan recognition, with application to trafficmonitoring.
In Proceedings of the Eleventh Confer-ence on Uncertainty in Artificial Intelligence.Joseph L. Schafer and John W. Graham.
2002.
Missingdata: Our view of the state of art.
In PsychologicalMethods, volume 7, No 2.Linda Schamber and Judy Bateman.
1996.
User crite-ria in relevance evaluation: Toward development of ameasurement scale.
In ASIS 1996 Annual ConferenceProceedings, October.Perter Spirtes, Clark Glymour, and Richard Scheines.2000.
Causation, Prediction, and Search.
The MITPress.Yi Zhang, Jamie Callan, and Tom Minka.
2002.
Noveltyand redundancy detection in adaptive filtering.
In Pro-ceedings of the 25th Annual International ACM SIGIRConference.Yi Zhang.
2004.
Using Bayesian priors to combine clas-sifiers for adaptive filtering.
In Proceedings of the 27thAnnual International ACM SIGIR Conference.595
