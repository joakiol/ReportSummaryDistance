THE CORRECTION OF  ILL -FORMED INPUT US ING H ISTORY-BASEDEXPECTAT ION WITH APPL ICAT IONS TO SPEECH UNDERSTANDINGPamela K. FinkSouthwest Research Institute6220 Culebra RoadSan Antonio, TX 78284Alan W. BiermannDepartment of Computer ScienceDuke UniversityDurham, NC 27706A method for error correction of ill-formed input is described that acquires dialogue patterns intypical usage and uses these patterns to predict new inputs.
Error correction is done by strongly biasingparsing toward expected meanings unless clear evidence from the input shows the current sentence isnot expected.
A dialogue acquisition and tracking algorithm is presented along with a description of itsimplementation i  a voice interactive system.
A series of tests are described that show the power ofthe error correction methodology when stereotypic dialogue occurs.This material is based upon work supported by TheNational Science Foundation under Grant number MCS7904120 and Grant number MCS 8113491 and by theAir Force Office of Scientific Research, Air ForceSystems Command, USAF, under Grant 81-0221.1 INTRODUCTIONIn an environment where stereotypic discourse commonlyoccurs, the repetitiveness and predictability of the inter-actions may enable a machine to effectively anticipatesome inputs.
For a speech understanding system, suchanticipation can greatly enhance the processor's capabili-ties for error correction so that proper action will takeplace despite inaccuracies at the voice recognition phase.This paper is concerned with the automatic onstructionof a model of user behaviors in typical interactions andthe use of such a model in the correction of misrecogni-tion errors.It is assumed that a user approaches the machine in atypical application with a problem to be solved.
He orshe inputs a series of sentences requesting action orinformation that will lead to a solution and then leaveswhen the task is complete.
In the early examples of suchan interaction, the machine will have little or no expecta-tion and will be dependent on its basic capabilities forunderstanding and carrying out commands.
However, ifrepetitive behaviors occur, the processor will effectivelyuse them to anticipate inputs and correct errors.
This willenable the user to speak less precisely and more quicklywhile still achieving reliable performance.Such repetitive behaviors may occur within a singledialogue where a user may utter sentences with similarmeanings again and again (as in "Is there a plane onThursday?
What time does it leave?
Is there one onFriday?
When does it leave?").
They may also occurwhen a given dialogue resembles earlier ones.
Theexpectation system will thus continuously monitor inputs,looking for repetition.
If no repetitious behavior occurs,the natural language processor is allowed to proceedwithout intervention in handling a dialogue.
However, ifrepetitiveness i detected, the expectation system willsupply the processor with anticipated behaviors whichcan be used to help remove uncertainties in sentencerecognition when they occur.In the following sections, an overview of the history-based expectation system is given.
Then a representationfor user behaviors is described, followed by an algorithmfor creating and tracking such models along with a meth-Copyright1986 bythe Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted provided thatthe copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
To copyotherwise, or to republish, requires a fee and/or specific permission.0362-613X/86/010013-36503.00Computational Linguistics, Volume 12, Number 1, January-March 1986 13Pamela K. Fink and Alan W. Biermann The Correction of IH-Formed Inputod for using them in error correction.
Finally, an imple-mentation of this methodology is described in the domainof speech recognition and results from a series of testsinvestigating the system's performance in various situ-ations are presented.2 AN OVERVIEW OF THE HISTORY-BASEDEXPECTATION SYSTEMThe general goal of the history-based expectation systemis to merge a series of dialogues, each of which consistsof a sequence of sentences, into a more general dialoguethat reflects the patterns that exist between and withinthe separate dialogues.
Thus, the expectation systemmust:- save incoming dialogues,- f ind  patterns between and within these dialogues sothat they can be merged into a more general dialoguewhich becomes a formula for a more general situation,and- use this information to help predict what will be said bya user in a given situation.This ability to predict what might be said by a user canhelp error correct what is input to the natural anguagesystem through errorful means, such as a voice recogniz-er.
We will call this ability expectation.
Figure 1 showsan overview of the structure of the history-based expec-tation system.
Expectation is acquired at two levels, thesentence level and the dialogue level.
A special parser,called the expectation parser, is used to analyze at thesentence level.
The expected ialogue is a data structureused to store the history-based expectation that isacquired using an expectation acquisition algorithm.
Thisconstitutes the dialogue level.As each sentence is entered into the system, such asthrough a speech recognition device, it is parsed and ameaning representation is produced and saved by anexpectation acquisition algorithm in the expectationmodule (see 1 in Figure 1).
The parse is also output foruse in the next step in the system's processing of thesentence.
This process builds a sequence of sentencemeanings, which are then incorporated into an expecteddialogue (see 2 in Figure 1).
After an expected ialogueis partially or completely built, the expectation moduleattempts to determine where the user is in a givendialogue using information from the expected ialogueand the current parsed sentence (see 1 and 3 in Figure1).
If it succeeds, it creates and transmits (see 4 inFigure 1) an expected sentence set to the expectationparser.
The expectation parser will then use this infor-mation to improve its ability to recognize the next incom-ing sentence.m mI EXPECTAT ION II MODULE I#r IiWORDSEQUENCE=> I EXPECTAT ION INETWORK I PARSER IL .___  JFigure 1.
Overview of the history-basedexpectation system.14 Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input3 A REPRESENTATION FOR USER BEHAVIORSSuppose a user inputs the following sequence:Sentence LabelDisplay my mail summary for today.
S 1Show me this letter.
(with touch input) $2(the letter appears on the screen)Remove this letter.
$3Display the letter from JA.
$4(letter appears on the screen)Delete it.
$5Log off.
$6We denote the meaning of each sentence Si with thenotation M(Si).
The exact form of M(Si) need not bediscussed at this point; it could be a conceptual depend-ence graph (Schank and Abelson 1977), a deep parse ofSi, or some other representation.
A user behavior isrepresented by a network, or directed graph, of suchmeanings.
At the beginning of a task, the state of theinteraction is represented by the start state of the graph.The immediate successors of this state are the typicalopening meaning structures for this user, and succeedingstates represent, historically, paths that have beenfollowed by this user.It is important hat if two sentences, Si and Sj, haveapproximately the same meaning this should be clear inthe representations M(Si) and M(Sj).
Our algorithm,described below, merges two meanings M(Si) and M(Sj)into a single node in the behavior epresentation if they- are sufficiently similar, and- appear in similar contexts.Thus, in the above example it would appear that M(S3)and M(S5) play similar roles and could be represented byone structure: after a letter is read, one might expect osee it deleted.Often, two commands will be similar except for theinstantiation of certain constituents.
This is the case insentences $2 and $4, which request the display of,respectively, the message indicated by a touch and theletter from JA.
Again, it is desired to represent suchsimilar meanings in a behavior graph with a single node ifthey appear in similar environments.
Thus, a routine willbe needed to find a generalization of two such sentencesthat can represent their common meaning.
In the exam-ple, the generalization of $2 and $4 might be "display(LETTER)" where "(LETTER)" is a noun group referringto a letter.In tracking a dialogue, we may arrive at a node in thebehavior graph with meaning M1.
This means acommand is expected with meaning M2 that is eitheridentical to, or a special case of, M1.
If such an M2 isinput at this time, we will say that M1 predicts M2 anddefine the predicate:Predicts(M1, M2) = true if and only if meaning M1is identical or similar to M2.It is quite possible, as with M(S2) and M(S4) above, thata common generalization can be found for two sentencesthat appear in similar contexts.
Then one will be able tomerge them into a single node in the behavior graph.Thus, it is necessary to have a predicate to check whetherthese conditions hold and a function to find the desiredgeneralization.
The following two routines do this:Mergeable(M1, M2) = true if and only if an M canbe found such that Predicts(M, M1) andPredicts(M, M2).Merge(M1, M2) yields a meaning M that is identi-cal to, or a generalization of, M1 and M2.A user behavior is represented as a network ofsentence meanings with transitions from one meaning toanother that indicate traversals observed in actualdialogues and their frequencies.
For example, the abovesix-sentence sequence could be represented as shown inFigure 2.
Each node i has a meaning Mi and a count Ci,which gives the number of times in observed dialoguesthis node has been visited.
The integer on each transitiongives the number of times it has been traversed inobserved ialogues.
'(r 2STARTM(Sl)M(S2),M(S#)M(SS),M(S5)M(S6\]Figure 2.
Modelling the user's behavior.More formally, a behavior graph B will consist of a setof nodes named 0, 1, 2, 3 .
.
.
.
.
bsize-1.
Each node i willhave its associated Mi and Ci and the first node will havea special meaning M0 = 'start'.
The transitions will berepresented as triples (i, j, k) where the traversal is fromnode i to node k and has been observed j times.
Theexample six-command sequence would be represented byComputational Linguistics, Volume 12, Number 1, January-March 1986 15Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Inputthe nodes 0 through 4 with Mi's and Ci's as shown andwith the triples{(0,1,1) (1,1,2) (2,2,3) (3,1,2) (3,1,4)}.Notice that the observed probability of crossing transi-tion (i, j, k) is j /Ci,  a fact that is used by the expectationparser.4 THE EXPECTATION MODEL BUILDING ANDTRACKING ALGORITHMIt is desired to have an algorithm to monitor thediscourse, collect the history of inputs, and invoke expec-tation when any kind of repetition occurs.
Such an algo-rithm is described below.
To do so, however, someadditional notation is needed:current = an integer giving the state number in B corre-sponding to the most recently recognized sentence.bsize = the total number of states in B.E(i) = {k I J > 0 ( i , j , k )  is in B}, the set of successorstates to state i, also called the expected sentence setof i.P(S, E(current)) = The result of the expectation parserwith input S and E(current), where S is the currentinput sentence which may have errors, and E(current)is a set of expected meanings in B, the successors ofnode current.
The result or output of the parse ofsentence S is its meaning M(S).The behavior graph B begins with one state numbered"0" and with M0 = start, C(0) = 0.
Thus, the size ofthe graph is bsize = 1 and the most recently recognizedsentence is assumed to be this start state, current = 0.Suppose that the first sentence in the above sampledialogue is read:S1 = "Display my mail summary for today.
"Then the processor will begin with no expectation sinceE(0) is currently the empty set, and findM(S1) = P(S1, {}).This will result in the creation of a second state in B withthe following statements:Create a NEW NODE:Put(current, 1, bsize) into B;(a transition to the new state is created)C(current) := C(current) + 1; (state O's count is incremented)current := bsize; (the new state is now the current state)M(current) := M(S); (the new state's meaning is recorded)C(current) := 0; (this state has not yet been visited and exited)bsize : = bsize + 1; (the size of graph B is incremented)Thus, the first two states shown in Figure 2 will existwith the single transition (0, 1, 1).
Sentence $2 and $3result in similar processing, the addition of states 2 and 3,and the creation of transitions (1, 1, 2) and (2, 1, 3) asshown in Figure 3.0STARTM(SI)M(S2)M(SS)Figure 3.
Constructing the behavior graph.The input sentence will yield a different action,however, if its meaning M(S) is determined to be merge-able with the meaning of an existing node Mk on thegraph.
While the details of mergeability have not yetbeen discussed, let us assume for the current examplethat M(S4) is mergeable with M(S2).
Then a new mean-ing will appear in the graph that is a generalization ofthese two, Merge(M(S2), M(S4)), and a graph transitionwill be built to this new meaning.
Transfer to the exist-ing meaning Mk would proceed as follows:C(current) := C(current) + 1;Mk := Merge(Mk, M(S));Put(current, 1, k) into B;current := k;Figure 4 shows the updated graph.
At this point, current= 2, and the expectation set, E(2), is non-empty for thefirst time.
So, now we compute P(S5, {M3}), meaningthat $5 is read with the expectation that its meaning willbe "remove this one".
Given this expectation, the parserwill prefer any transitions down paths that lead to someparaphrase of this sentence and, unless the system clearlyrecognizes that something else has been said, a sentencemeaning "remove this one" should be recognized.
If it is,then current will be advanced to this expected node.
Ingeneral, there may be several expected sentence mean-ings, and the processor will select the one most similar tothe incoming utterance unless that sentence is clearly notany member of the expected set.16 Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input'6,\], I It lSTARTM(SI)M(S2).H(S4)M(SS)Figure 4.
Merging M(S2) and M(S4).Thus, if a successor k to the current state predicts theincoming sentence, we track that successor.
Trackingthe expected meaning Mk would proceed as follows:C(current) := C(current) + 1;Mk := Merge(Mk, M(S));Increment r in (current, r, k);current := k;Figure 5 shows the result.ISTARTIM(SI )M(S2).H(S4)M(S3),H(S5)Figure 5.
Merging M(S3) and M(S5).The final sentence $6 in the dialogue will cause thecreation of a termination state and complete the graph ofFigure 2.
The behavior graph creation and trackihg algo-rithm is thus the collection of the above code segments:if no behavior graph B exists thenbeginbsize : = 1;M0 := start;CO := 0;end;elseload B;current := 0;repeatbeginread input sentence S;M(S) := P(S, "Mk I k in E(current)");if Predicts(Mk, M(S)) where k in E(current) thenbeginC(current) := C(current) + 1;Mk := Merge(Mk, M(S));Increment r in (current, r, k);current := k;end;elseif Mergeable("Mk I k = 1 and/or 2 and/or ...bsize-l", M(S)) thenbeginC(current) := C(current) + 1;Mk := Merge("Mk I k = 1 and/or 2and/or ... bsize-l", M(S));Put(current, 1, k) into B;current := k;end;elsecreate aNEW NODE;end;until M(S) is a dialogue termination.This code creates a finite state model of the dialoguebased on equivalence or similarity classes defined by thefunctions Predicts, Mergeable, and Merge.
As will bediscussed in the next section, similarity classes are basednot only on the similarity of the sentences themselves,but also on the environment in which they occur.
Thus,there is only one state for each such similarity class in thefinite state model created.When the user enters the system again, this algorithmcan be reinvoked using the existing B graph.
If the nextdialogue is very similar to a previous one, then the expec-tation dialogue will powerfully support error correction.If the next dialogue has little resemblance to previousones, then no expectation will be available, and the userwill be dependent on basic processor recognition capabil-ities.This section has given an overview of the approach tohistory-based expectation processing.
The details of themethod are dependent on how the functions P, Predicts,Mergeable, and Merge are implemented.
The followingsections describe our implementation, which was used toinvestigate the viability of this approach and the perform-ance it can achieve.Computational Linguistics, Volume 12, Number 1, January-March 1986 17Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input5 AN IMPLEMENTATION 5.1 THE EXPECTATION PARSERThe usefulness of the methodology described above wastested in the implementation of a connected speechunderstanding system.
An off-the-shelf speech recogni-tion device, a Nippon Electric Corporation DP-200, wasadded to an existing natural anguage processing system,the Natural Language Computer (NLC) (Ballard 1979,Biermann and Ballard 1980).
The expectation systemprovided the intermediate processing between the error-ful output of the speech recognizer and the deep seman-tics of NLC.
The resulting speech understanding systemis called the Voice Natural Language Computer withExpectation (VNLCE, Fink 1983).
\[The current systemshould be distinguished from an earlier voice system(VNLC, Biermann et al 1985), which had no expectationand which handled discrete speech where a 300 millisec-ond pause must follow each word.\]It should be emphasized, of course, that the centralissue here is the study of expectation mechanisms and thedetails of the design decisions could have been made inrather different ways.
Thus one could have implementedexpectation error correction with a typed input system orwith a speech input system that integrates voice signalprocessing with higher level functions in a way not possi-ble with a commercial recognizer.
This implementationshows only one way in which the functions P, Predicts,Mergeable, and Merge can be constructed to achieveexpectation capabilities.
The conclusion of this paper isthat in this particular situation substantial errorcorrection is achieved, and thus one may suspect thatsimilar results can be achieved in other applications.The implementation, as in the overview of the generalsystem presented in section 2, consists of two majorparts, an expectation parser and an expectation module,and their respective data structures.
The expectationparser embodies the function P, while the major func-tions of the expectation module are Predicts, Mergeable,and Merge.
An expected sentence set, E(current), alongwith the most recent input sentence S, are inputs to theexpectation parser P. The expectation parser P usesthese two inputs to determine the meaning M(S) of theinput sentence S. Thus, M(S) is a deep parse of S. Thefunction Predicts determines if one of the sentences inE(current) predicts M(S).
If so, then 1~(S) is mergedwith this sentence meaning and dialogue tracking isbegun from that point.
Otherwise the function Mergea-ble determines how "similar" M(S) is to any othersentences in the expected ialogue.
In this implementa-tion, the function Mergeable is actually much morecautious about determining whether or not a set ofsentences should be merged.
For the implementation, ifMergeable determines that certain nodes in the expecteddialogue are mergeable with M(S), then it adds thesuccessors of these nodes to E, creating an expandedexpected sentence set.
Then, if the next sentence input ispredicted by one or more of these sentences, they aremerged through the action of Predicts and Merge.The purpose of the expectation parser in this implemen-tation of a speech understanding system is to take inputfrom the scanner and the expectation module, and usethis information to determine what was said by the user.Thus, during the parsing process, the expectation parsermust reconcile the sequence of words input from thescanner with the expected sentence set from the expecta-tion module, or determine that the scanner input is notlike anything that was expected and, thus, ignoreexpectation.
In this way, the expectation parser parsesfrom two inputs.
It is constantly trying to maintain anequilibrium between the input from the scanner and theinput from the expectation module.
This balancing iskept in line by a set of rating factors that are used duringthe parsing procedure to help guide the search for areasonable sentence structure.
These rating factors, attimes, will be referred to as probabilities in the followingdiscussion.
However, in reality, the ratings are one thou-sand times the values of the logarithms of numbersbetween 0 and 1.
Thus, the ratings span the values -999to 0, where 0 is equivalent to a probability of one.
Theseratings are computed this way because they remain inte-gral and still fairly accurately represent the correctvalues.
Also, they can simply be added and subtractedrather than multiplied and divided in the hundreds ofcalculations required for a single sentence parse.The expectation parser uses an ATN-like represen-tation for its grammar (Woods 1970).
Its strategy istop-down.
The types of sentences accepted are essential-ly those accepted by the original NLC grammar, imper-ative sentences with nested noun groups andconjunctions (Ballard 1979).
An attempt has been madeto build as deep a parse as possible so that sentences withthe same meaning result in identical parses.
Sentenceshave the same "meaning" if they "result in identical tasksbeing performed.
The various sentence structures thatWe have have the same meaning we call paraphrases.studied the following types of paraphrasing:1) WORD<=>WORD'entry' <=> 'number'2) ADJ NOUN <=> NOUN QUALIFIER'positive ntries' < = > 'entries which are positive'3) NOUN NUMBER <=> DET ORDINAL NOUN'row 2' <=> 'the second row'4) CLASSIFIER NOUN < = > NOUN of/in CLASSIFIER'the row 1 entries' <=> 'the entries in row 1'5) EQUIVALENT SETS'row 1' <=> 'entries in row 1'6) QUANTIFIERS'all (of) (the)entries' <=> 'the entries'7) CONJUNCTION OF NOUNS'double rows one and two' <=> 'double row oneand row two'18 Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input8) DEFAULT CONTEXT'the rows' <=> 'the rows in matrix 1'9) NAMES'column 1' <=> 'testA'10) PRONOUNS'it' < = > 'row 1'11) ORDINAL NOUN <=> NOUN X in COLUMN or ROWYNOUN NUMBER < = > NOUN X in COLUMN or ROWY'sixth entry' <=> 'entry 2 in column 3''entry 6' < = > 'entry 3 in row 2'12) NUMBER <=> ENTRY X'9.75' <=> 'entry 3'13) WORD <=> {WORDS}'double' < = > 'multiply by two'14) CONJUNCTION OF VERBS'double row two and zero matrix one.
'<= > 'double row two.
zero matrix one.
'It is obvious from this list that there are varying levels ofparaphrasing.
Some arise at the vocabulary level(number 1), some at the syntactic level (numbers 2, 3, 4,5, 6, and 7), some at the semantic level (numbers 8, 9,and 10), some at the current world level (numbers 11and 12), and some at a combination of levels (numbers13 and 14).
Some are domain dependent, especially atthe vocabulary level such as entry < = > number.
Othersare not, such as ADJ NOUN <=> NOUN QUALIFIER.Those that only require knowledge of the vocabulary orof the grammar are implemented in the current history-based expectation system.
This means that paraphrasesone through seven are handled currently as part of theparsing process itself.
The last seven may be dealt withat some future date.
However, they are somewhat morecomplicated because they require temporal-type know-ledge such as the current referent of a pronoun or thecurrent size of a matrix.
The lexical and grammaticalparaphrases, on the other hand, will always have thesame meaning, regardless of the current state of theworld.
By handling the seven lexical and syntactic para-phrases, a stored parse can aid in recognizing manysentences with the same "meaning" but different surfacestructures.To simplify representation of the parser output wehave developed a special notation to indicate the deepparse of a sentence.
For example, the parse of thesentences:Double the positive row 1 entries.Double the positive entries in row 1.Double the row 1 entries which are positive.Double the entries in row 1 which are positive.is notated as:Double (entries (positive) (rl))The mechanism for using the expectation i formationduring parsing is built into the ATN-like network.
Theparser eceives from the scanner a sequence of word slots.These word slots are defined by the speech recognitionsystem based on the sequence of words it recognized.Thus, there could be missing or extra word slots due toerrors made during speech recognition.
To each wordslot the scanner adds other possible words based on whatwords the system tends to confuse.
The scanner alsorates the possibilities for each word slot by the samescale discussed previously.
During parsing, the parsercreates a template that represents the parse of thesentence input.
This template contains slots that repre-sent the parts of a sentence such as verb, adjective, andheadnoun.
At each point in the parse of a sentence,when the expectation parser is trying to determine whatthe role of the current word slot is in the sentence, fivedifferent attempts are made to use the current word slotas needed to fill the template slot at the current point inthe grammar network.
These are:?
ADV (advance): Find a word in the current word slotfrom the scanner output that will fit the needs at thisnode in the grammar.
If such_ a word cannot be found,try choice 2.?
EXPADV (expectation advance): Look at the parse ofthe current expected sentence to see if the templateslot that the parser is currently trying to fill is filled inthe expected sentence.
If so, copy the value in thetemplate slot from the expected sentence to the currentparse, ignoring the word slot from the scanner.
Other-wise, try choice 3.?
SKIPWORD: Skip the current word slot from the scan-ner output, filling the corresponding parser templateslot, when appropriate, with a NIL value to indicatethat a word has been skipped and that it was assumedto have the function associated with the template slot.If the parse fails later on, and the parser backs up tothis point, try choice 4.?
EXTRAWS (extra word slot): Assume that the wordslot from the scanner is an extra one due to an error inrecognition.
Skip this word slot and again try choice 1.If failure occurs, try choice 2.
Finally, if failure againoccurs, try choice 5.?
LOSTWS (lost word slot): Assume that the neededword slot from the scanner is lost due to an error inrecognition.
Without advancing to the next scannerword slot, try step 2 again.
If this fails, then fill theparser template slot, when appropriate, with a NILvalue to indicate that a word has been lost and that itwas assumed to have the function associated with thattemplate slot.
Remain at the current scanner word slotso that it can again be evaluated for a different func-tion.An example piece of the parser network is shown inFigure 6.
The five kinds of error correction were handcoded into each network so that the special character-Computational Linguistics, Volume 12, Number 1, January-March 1986 19Pamela K. Fink and Alan W. Biermann The Correction of HI-Formed Inputformatted routine FILLADJ:425742674272427945564286455152144885475047564762476950365043STARTADVCHEK PART ADJFILLSLOT ADJECTIVE QUOTEEXPCOMP ADJRETEXPADVEXPCHEK ADJECTIVECOPYSLOT ADJECTIVECOPYWORD ADJECTIVEgoto 45 56goto 4556SKIPWORD LOG7I FILLSLOT ADJECTIVE NILCOPYWORD QUOTE NILgoto 4556EXTRAWS LOG7goto 4267goto 4551LOSTWS LOG7goto 5214goto 4762Figure 6.
An example parse net.istics of each grammatical structure could be accountedfor individually.
Thus in some cases, certain errorcorrection alternatives were checked immediately whilein others it was wiser to determine whether normal proc-essing would fail at deeper levels before attempting thosesame corrections.
The network represents a tree struc-ture which is searched by the expectation parser.Succession in the network is represented by the parent-child relationship, which is indicated in Figure 6 byindentation.
Thus, the node containing the commandADV is the parent of the node containing the commandCHEK PART ADJ, and so is succeeded by it.
Should acommand fail, the parser backs up to the parent node ofthe node that has just failed.
Thus, if a check for anadjective in CHEK PART ADJ fails, control will back upto the node containing ADV.
Choice is represented bythe sibling relationship which is indicated in Figure 6 bythe vertical lines connecting nodes.
Thus, ADV,EXPADV, SKIPWORD, EXTRAWS, and LOSTWS are allsiblings in the tree network and are choices that theparser can make when parsing a sentence.
Note that, inthis case, these five choices represent he five possibleattempts that are made in trying to parse a word slot thatwere discussed above.
A choice is made by picking thesiblings in the order in which they appear in the network.Thus, when the CHEK PART ADJ fails and control backsup to ADV, the expectation parser will back up to theSTART node and then take the second choice, EXPADV,and attempt to proceed own that chain of commands.The scoring mechanism within the parser serves to aidin the evaluation of the alternative paths during the parseprocess and the pruning of improbable choices.
A typicalspoken input to the system is"add row one to row two"and the speech recognition machine will often returnsuch errorful output as"and row * to row".The asterisk indicates that the device guesses the exist-ence of a word but has failed to identify it.The parser must be able to extract the user's originalintent and its operation is guided by rating factors whichevaluate the quality of the path through the parser, theword selection, the level of agreement with expectation,and the self consistency (or compatibility) of thesentence.
These individual ratings work as follows:1) The Transition ValueEvery time the parser moves over a SKIPWORD,EXTRAWS, or LOSTWS command a charge is madeto the value of the transition.
Normally, a transitiondoes not cost anything, but each SKIPWORD,EXTRAWS, and LOSTWS executed results in a lower-ing of the transition's value.
This charge is made forthe rest of the parse unless the SKIPWORD,EXTRAWS, or LOSTWS is backed over.
This chargecan be seen in the sample grammar net appearing inFigure 6 after the words SKIPWORD, EXTRAWS, andLOSTWS.
The charge in this example for each of thethree commands i 1000*log\[0.7\] = -35 .2) The Word ValueWe define the synophones of a given vocabularyword to be the words a user might speak that couldpossibly be recognized as that word.
Because of thenature of the dynamic programming algorithm in theNEC machine, it yields only one guess at each wordslot.
So it is necessary for our software to providethe set of synophones for each guessed word.
This,in effect, simulates the situation where the speechrecognition device provides a larger number of possi-ble matches.
Thus, in the case of the above recog-nizer outpu t, the following synophones would beproduced to represent the sequence of possiblewords spoken:word slot word rating0 and lO00*log\[1.O\] -- 0add lO00*log\[0.8\] = -221 row 1000*log\[1.0\] = 0rows 1000.1og\[0.8\] = -222 * 1000*log\[ 1.0\] -- 03 to 1000*log\[ 1.0\] = 0two 1000*log\[1.0\] = 0into 1000.1og\[0.8\] -- -2220 Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K.  F ink  and  A lan  W.  Biermann The Correction of Ill-Formed Input4 row 1000*log\[1.0\] = 0rows 1000*log\[0.8\] = -225 1000*log!l.0!
= 0Each alternative word is given a rating.
The wordsselected by the recognizer are given maximumratings and alternatives are given lower values.
Iftwo words have the same pronunciation as with toand two, they are given the same values.3) The Expectation ValueThis value is based on whether or not there is anexpected sentence, how well the current parse ismatching the current expected sentence from theexpected sentence set, and how much the currentparse is using this expected sentence.
Whenever aslot is filled by the parser, it is compared with thecorresponding slot in the expected sentence.
If theydo not match, the expectation value decreases, other-wise the expectation value remains the same.4) The Compatibility ValueThis value differs from the other three in that it issimply true or false.
Verb-operand, noungroup-noungroup, and expectation are checks made duringthe parse.
If compatibility fails, then the expectationparser backs up, otherwise it continues forward.Each of these components has a value assessed at eachword slot in the incoming sentence as well as one for theentire sentence.
The word slot values are assumed tohave a top rating until the parser reaches that word slot.Thus, the parser is always examining a best case situationbased on what it has already done.
For example, allword slot transition values are assumed, initially, to havethe value 1000*log\[i\] = 0.
The transition value at aword slot is only lowered if it is necessary for the parserto execute a SKIPWORD, EXTRAWS, or LOSTWScommand in parsing that word slot.
The charge made isaccOrding to the value indicated at the particularcommand in the grammar network.
The average of thecurrent values of all word slot transition values createsthe sentence transition rating for the parse so far.
Theword slot and sentence values for the expectation andword values are computed similarly.
The compatibilityvalue differs, however, since it does not have degrees ofratings but rather indicates acceptability or lack thereof.Thus, it is not included in the formula for determining arating for the parse.
Rather, if it fails, then parsing auto-matically backs up.
If it succeeds, then parsing continuesforward.The values of the transition, word, and expectationcomponents are used to determine two sentence parseratings.
At each word slot, the values of the three factorsare averaged together to produce a general word slotparse rating.
Also, the sentence values for the threecomponents are averaged together to obtain a generalsentence parse rating.
Thus, we have the followingequations that define the various rating values, where n isthe number of word slots in the sentence:1) The Transition Valueword slot transition value:ws transition\[x\] = value of SKIPWORD, EXTRA.WS, orLOSTWS at word slot xsentence transition value:transition confidence = E ws transition\[i\]/n- -  i=0 - -2) The Word Valueword slot word value:ws word\[x\] = value of the word chosen from thescanner input for word slot xsentence word value:word confidence= E ws word\[i\]/n- -  i=0 - -3) The Expectation Valueword slot expectation value:ws expectation\[x\] = match of word slot x in currentparse with slot x in the expected sentencesentence xpectation value:expectation confidence = E ws expectation\[i\]/ni=04) The Parse Valuesword slot parse value:word slot factor\[x\] = (ws transition\[x\] +ws word\[x\]+ ws expectation\[x\])/3sentence parse value:sentence factor = (transition confidence +word confidence + expectation confidence)/3The transition confidence, word confidence andexpectation confidence provide an average overallvalue for the ws transition, ws word, andws expectation ratings, respectively.
These averagevalues provide a best case rating at any point during theparse because they assume perfect ratings for all wordslots not yet parsed.
The overall parse values,words lo t fac tor  and sentence factor, are calculatedsimply from the average of the other three rating values.This is done so that each factor has equivalent power incontrolling the parse.
If it is desirable to allow one factorto have more control over the parse than the other two,then this can be accomplished by manipulating the partic-ular minimum rating values discussed below.
In order tocontrol the expectation parsing, search is cut-off if ratingvalues fall below certain levels.
Currently, these levelsare:1.
Minimum word slot transition value ( -52)Minimum sentence transition value ( -12)2.
Mimmum word slot word value ( -150)Minimum sentence word value ( -60)3.
Minimum word slot expectation value ( -23)Mimmum sentence xpectation value ( -7 )4.
Minimum word slot parse value ( -190)Minimum sentence parse value ( -65)If any one of the rating factors drops below its corre-sponding minimum value, the current search path is cut-off and a different route through the grammar nets isattempted.
In this way, there is a control over the extentof the search.
By setting all the minimum ratings toComputational Linguistics, Volume 12, Number 1, January-March 1986 21Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input-999,  for example, all possibilities in the grammar arechecked.
On the other hand, setting all the minimumratings to 0 results in the expectation parser behaving likea normal parser since this essentially turns off the use ofthe SKIPWORD, EXTRAWS, and LOSTWS commands, theuse of synophones, and expectation.In theory, the parsing algorithm is admissible.
That is,it is capable of finding the best possible parse.
The vari-ous rating factors can initially be set high and graduallylowered until a parse is found.
This parse would have thehighest rating possible.
However, this is impractical inpractice due to the amount of time required to repeatedlysearch a growing space.
Thus, minimum rating values areset and the search is conducted once.
In this way, thefirst parse found is the "best" parse in the sense that it isthe first one found whose rating was higher than theminimum pre-set value.5.2 ROUTINES OF THE EXPECTATION MODULEThe task of the expectation module is to acquire a gener-al dialogue from a series of dialogues poken by a user.The dialogues essentially contain examples of how to goabout solving a particular kind of problem.
In acquiringthese dialogues and merging them into one generalizeddialogue, the expectation system learns how to solve thisparticular kind of problem through examples.
In a sense,by building this generalized dialogue the expectationsystem is creating a procedure that can solve a particularsubset of problems.
This is a future goal of the project.However, the current application is for the generalizeddialogue to be used as an aid in the voice recognitionprocess by offering predictions about what might be saidnext.The types of problems that can be learned by theexisting history-based expectation system include linearalgebra applications uch as matrix multiplication, simul-taneous linear equations, and Gaussian elimination.Non-linear algebra problems that require matrix-typerepresentations can also be learned, such as gradebookmaintenance and invoice manipulation.
Though theimplemented system is limited to matrix-oriented prob-lems, the theoretical system is capable of learning a widerange of problem types.
The only requirement on theproblem or situation is that it can be entered into theexpectation system in the form of examples.
Thus, forexample, it can acquire a "script" such as the one forgoing to a restaurant as defined in Schank and Abelson(1977).The expectation module takes two inputs and produc-es two outputs.
The inputs are?
the user behavior graph discussed earlier, called theexpected ialogue D, and?
the meaning of the most recently input sentence, M(S).Its outputs are a new expected dialogue D modifiedaccording to the latest input sentence M(S) and anexpected sentence set E. These outputs are producedbased upon the inputs and the functions Predicts, Merge-able, and Merge.The role of the predicate Predicts can be best under-stood by recalling the function of the parser P. P usesthe set of expected sentences E(current) to try to errorcorrect the incoming sentence S. P may do this bydiscovering that some Mk in E(current) is quite similar toM(S).
If P does select such an Mk and uses it to helpparse S, then Predicts (Mk, M(S)) is true.
Otherwise,Predicts (Mk, M(S)) is false.
Thus the function ofPredicts is to select he Mk which the parser used in pars-ing S. If the parser did not use expectation, then Predictsalways is false.If the incoming sentence was not predicted by existingtransitions in D, perhaps it can be found to be similar tosome node Mk in D and a new transition could be addedto that node.
The routine Mergeable has the job of find-ing one or more such Mk's into which the currentsentence meaning M(S) can be merged.
The question ofsimilarity of two sentences i determined by the meaningsof the sentences themselves and the "environment" inwhich they occur in the dialogue.
Sentence "meanings"are based on the sentence deep parses produced by theexpectation parser, while a sentence "environment" isbased on the meanings of the sentences preceding andfollowing it in the expected ialogue.Similarity is based on the notion of "distance".Currently two sentences are considered similar in mean-ing if their parses differ in only one slot in the noungroup template.
This means that their noun groupdistance cannot be greater than one to be consideredsimilar.
For example, the following two sentences aresimilar:M("double the first row") = double (r l )M("double row 2") = double (r2)The environment of one sentence matches that of another ifthe sentence meanings preceding the two sentences beingcompared are identical and/or  the sentence meaningsfollowing them are identical.
Clearly, these definitionsare quite arbitrary and many other strategies could betried.
However, for the purposes of this study, they werequite satisfactory.Based on the question of how well the environmentand the sentence itself matches previously seen environ-ments and sentences, five different matches are possiblebetween the current incoming sentence and the elementsof the expected ialogue:1) The sentence matches a sentence meaning in theexpected ialogue exactly, but there is no match oftheir environments.2) The sentence matches a sentence meaning in theexpected ialogue similarly, but there is no match oftheir environments.3) The sentence matches a sentence meaning in theexpected sentence set exactly, which implies thattheir environments also match.22 Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input4) The sentence matches a sentence meaning in theexpected sentence set similarly, which implies thattheir environments also match.5) There is no match between the sentence and anysentence meaning in the expected ialogue.In cases 1, 2, and 5, the sentence is determined to be newand unique to the expected ialogue.
Therefore, Mk andM(S) are not mergeable.
In such cases, M(S) is added asa new entry in the expected ialogue D. In the other twocases, numbers 3 and 4, the incoming sentence is deter-mined to be the same as or similar to one already seenpreviously in an exact or similar situation.
Thus, Mk ismergeable with M(S).
In case 3 the sentence is automat-ically merged with the one that it matches exactly in theexpected sentence set.
In case 4, the sentence is mergedwith the one that it matches similarly in the expectedsentence set only after it has passed an argument creationalgorithm test to be discussed below.
Otherwise it is alsoconsidered new and unique and added to the expecteddialogue as in cases 1, 2, and 5.
The actual argumentcreation occurs in the function Merge.The notion of creating an argument is associated withthe problem of when to merge a set of similar sentencesin an expected ialogue into one sentence with a specialflag in the slot where the sentences differ.
This is deter-mined by the function Mergeable.
As an example, at acertain point in a dialogue, one may have an expectedsentence set E(i) such as the following:double (rl) .33double (r2) .33double (r3) .33The numbers indicate the probability levels, derived fromj/Ci,  as discussed at the end of section 3.In such a situation, the user's intentions may bereflected more correctly by the following expectedsentence set:double (rARG) 1.0which signifies that any row may be referred to.
Howev-er, though this simplified expected sentence set may be agood generalization of the pattern observed, it hasramifications for error correction.
Specifically, it will beunable to fill in a row number should that value be miss-ing in the incoming sentence.
The first option also has itsdrawbacks.
In this case, should the row number be miss-ing in the sentence, the expectation parser will errorcorrect the sentence to the most probable value, or thefirst one in the set if the probabilities are equal, here thevalue one for row 1.
Thus, both options are imperfect interms of the error correction capabilities that they canprovide.
The comparison that must be made to deter-mine which option is better in a given situation is howoften the first will error correct incorrectly as opposed tohow much error correcting power we will lose by usingthe second.
How it is done is beyond the scope of thispaper but is explained in detail in Fink (1983).The Merge function takes two inputs, M1 and M2,which have been determined by the Mergeable functionto be similar in some way by considering their respectiveenvironments and meanings.
Based upon how similar thetwo meanings are, Merge creates a meaning M that is ageneralization of M1 and M2, sometimes employing anargument.
Thus, there are only two possible kinds ofmatches at this point between an input sentence and amember of the expected sentence set, an exact match ora similar match.
In the case of an exact match M = M1= M2 and M replaces Mi  in the expected ialogue.
Inthe case of a similar match, the meanings only differ byone slot in the noun group of their deep parse represen-tation, so a generalization of that slot to "ARG"  is made,meaning an argument is created.
The function appears asfollows:Merge (M1, M2)beginfor each slot x in M1 and M2 doif x(M1) != x(M2) thenx(M) := ARG;elsex(M) := x(M1);end;Thus, if the sentences "Double ( r l ) "  and "Double (r2)"are inputs to Merge, the output would be "Double(rARG)".6 EXPERIMENTAL RESULTSAn experiment was run using VNLCE to test the errorcorrection capabilities in different situations.
These situ-ations were simulated by making the test subjectsperform certain tasks on the system that resulted indifferent dialogue structures, or schemas.
The four testsmade on VNLCE in this experiment are considered to berepresentative of the possible schemas that can beproduced by different dialogues in different situations.All possible dialogue schemas actually produce a contin-uum of patterns from totally-ordered to totally-unord-ered.
The tests described below are simply points on thiscontinuum.I) Totally-Ordered SchemaThis type of schema occurs whenever the system hasat most two sentences at a time in its expectedsentence set and one of these always has a probabili-ty rating over 80%.II) Partially-Ordered SchemaIn this case, there is a general order to the sentencesbeing spoken, but there is not usually just one highlyprobable sentence in the expected sentence set at atime, but several with varying degrees of probability.III) Totally-Unordered SchemaThis occurs when there is no over-all order to thesentences being spoken.
Essentially any sentence inComputational Linguistics, Volume 12, Number 1, January-March 1986 23Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Inputthe expectation dialogue has a probability of beingspoken next.IV) Totally-Ordered Schema with ArgumentsThis test is an example of a totally-ordered schema,but the system does not know exactly what will besaid all the time because one or more of the expectedsentences contain an argument.Each of the four tests was run on three different testsubjects to acquire data concerning how fast a userspeaks, what types of errors are produced by the voicerecognizer, and how well the expectation system acquiresand uses the expected ialogue to help error correct theinput.To begin the experiment session, the subject trainedthe voice recognizer, a NEC DP-200, on a specific vocab-ulary of 49 different words in connected speech mode.The DP-200 can handle only 150 word slots in connectedspeech mode, so 49 allowed for some repetitive training.The subject was then given a brief tutorial that leadhim/her through a few features of the VNLCE systemand gave him/her some practice in talking to the NECdevice.
This training session usually took a total of about45 minutes.
The subject was then given one or more ofthe test sheets representing the problems to be solved.The number was based on the amount of time that thesubject was willing to donate to the effort.Each test dialogue had a similar over-all structure inthat it required a certain amount of repetition, thus creat-ing a loop structure in the expected ialogue.
In all tests,except test II, the subject was provided with the specificsequence of sentences to be spoken.
This guaranteedthat the desired level of repetition was actually achieved.How much repetition there was in each dialoguedepended on the expected dialogue schema beingimitated.
In test I, which was done to demonstrate atotally-ordered schema, the test subject had to repeat anidentical sequence of six sentences nine times in a rowexcept for the seventh time when four new sentenceswere inserted into the loop.
A sample schema can beseen in Figure 7.
In test II, the user had much more free-dom, since its purpose was to demonstrate a partially-ordered schema.
Here the subject had to solve six sets ofsimultaneous linear equations with two equations andtwo unknowns and he/she spoke whatever sentences thatseemed appropriate.
A sample schema is shown inFigure 8.
Notice that in one case an argument wascreated.
The third test was done to show how well errorcorrection works when the dialogue seems random, creat-ing a totally-unordered schema.
To create such an envi-ronment, the user was asked to repeat four sentences inrandom order eight times.
An example xpected ialogueschema that resulted from this test is shown in Figure 9.In the last test, test IV, the subject was asked to repeat asequence of four sentences ix times, each time throughchanging the value of the row number spoken.
Thisdemonstrates the argument creation facility in a totally-ordered dialogue schema.
The expected ialogue gener-ated from this test appears in Figure 10.Each test has associated with it three charts indicatingthe results.
The first graph represents the averagesentence rror and correction rates, the second shows theaverage word error and correction rates, while the thirdillustrates the average rate-of-speech in words-per-sec-ond spoken by the subject while doing the experiment.The charts indicating the average rror and correctionrates of the four tests reflect the loop structure of thedialogues.
Each chart is a series of bar graphs, each bargraph representing the average rror and correction ratesover the sentences poken by the subjects in a particularloop of the dialogue.
The highest point on each of thesebars represents the raw error rate of the voice recognizer.The different markings within the bars themselves repre-sent the percentage of the errors that were corrected by aparticular facility of the expectation system.
The hori-zontal design associated with "loosening" indicates thepercentage of the errors that were corrected by the use ofthe flexible parsing techniques, such features as the syno-phones and the parser commands SKIPWORD,EXTRAWS, and LOSTWS.
The vertical design associatedwith expectation indicates the percentage of the errorsthat were corrected by use of the expected sentence setalone.
The blank area indicates the percentage of theerrors that were corrected by using both of the abovefacilities.
Finally, the dot design shows the percentage ofthe errors that were not corrected.
Thus, for example, inthe top chart in Figure 11, the eighth loop of the dialoguehad an 85% sentence rror rate from the voice recogniz-er.
Of those errors, 6% were corrected using the facili-ties associated with loosening the search, while 25%were corrected by using only expectation.
Another 63%were corrected using features from both categories.
Only6% could not be corrected.Test I, using a totany-ordered dialogue schema, wasdone to show how well the expectation system can errorcorrect errorful input when it can predict exactly whatwill be said next.
As can be seen from the graphs inFigure 11, as the ability to predict what will be said nextincreases, so does the ability to error correct.
In loopseven of the dialogue, we deliberately had each user addfour extra sentences between the fourth and fifthsentences of the loop.
This was done to show that theexpectation system had not become a complete automa-ton, but that it was still capable of dealing with unex-pected input.
However, as can be seen from these graphs(Figure 11), the expectation system's error correctingpower decreases in that particular loop of the dialoguesince there is no expectation at certain points to help it.Test II, creating a partially-ordered dialogue schema,was done to show how the expectation acquisition algo-rithm dealt with dialogues containing some pattern and tosee how well error correction could work when expecta-tion was not perfect.
The results are shown in Figure 12.24 Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input(c reate  (2) (3 i )- ~ (~ead (rl))(d'ivide ,pos ,),c3;)(do.io (~o,.~,.?
?
(.~,;)(.~d ,,~, (,,.
()(mul t ip ly  (c3)  (e6)- I 1 ')@obt~.ot ,.i, ,~2;)(r2)  ( la rgest  o) ' )Figure 7.
Expected ialogue schema for Test I.Computational Linguistics, Volume 12, Number 1, January-March 1986 25Pamela K.Fink and Alan W. Biermann The Correction f Ill-Formed Input(mul t ip ly ( r1 )  (e l (1 ' ; )  r u l t ip ly ( r2 )  ( -_~ ubt ract  (rl) ( z~~ iv  ide ((d iv ide( r2 )  (e l ( r2 ) )~ ~ubtzaet ( r l )  ( r2 )ubt rac t  ( r l )  (r~ero(r2) (eARfi)) ~dd (z l )  ( r2 )(r2) (rl))4~div ide  (rl) (el))(.,)26Figure 8.
Expected ialogue schema for Test II.Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input~STAR~(...d ,.1;)1,1~ d iv ide  ( r l )  ( la rgestdd (x2)  (x l~ 'u l t ip ly  (negat ive  ?
( r2 ) )  (e l )~Figure 9.
Expected ialogue schema for Test III.Computational Linguistics, Volume 12, Number 1, January-March 1986 27Pamela K.Fink and Alan W. Biermann The Correction fIll-Formed InputSTART)'~ Cr  ead(  rARG i ),L 6Cread  (x'ARG~Cdouble (e2 (rARG)i~subt rac t  (e2 (~ARG)) (negat ive  e )~28Figure 10.
Expected ialogue schema for Test IV.Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of lll-Formed InputSENTeNCE-ERROR-RATE100% -LEGEND:9o~ \] ~ ~ ~lii,'""!
70% t :L .
.
.
.
'?"
i !111iil\]! '
- '  4O% 30% -o, _ ~  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~..-.
'.~~ ~% Er rors  Cor rec ted  by~:  loosen ing~:  expectat ion\ [ -7 :  bothcor rec ted1 2 3 4 5 6 7 8 9 10LOOP NUMBER IN DIALOGUEWORD-ERROR-RATE100% /90% /80% /70% /60% /50% /40% /30% /20% /10% -0%1 2 3 4 5 a 7 8 9 10LOOP NUMBER IN DIALOGUEFigure 11.
Error and correction rates for Test I.Computational Linguistics, Volume 12, Number 1, January-March 1986 29Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed InputSENTENCE-ERROR-RATE100% -90% -80% -LEGEND:  % Er rorsr - - l :Corrected  byloosen ingexpectat ionbothnot  cor rec ted70% -60% -50% -40% -30% -20% -10% -0%1 2 3 4LOOP NU.
n  ?5MBER IN6 7DIALOGUE8 9 10WORD-ERROR-  RATE100% -90% -80% -70% -60% -50% -40% -30% -20% -10% -0%1 2 3 4 5 6 7LOOP NUMBER IN D IALOGUE8 9 1030Figure 12.
Error and correction rates for Test II.Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed InputSEN TEN CE-  ERROR-  RATE100% -90% -80% -LEGEND : % E: rors70% -60% -50% -40% -30% -20% -10% -0%N1 2 3 4LOOP NUMBER I5!t\i;!
Ii.I6N  D IALOGUECor rected  byl o o s e n i n gexpectat ionbothnot  cor rec ted~" i " " - "7 8 9 10WORD-ERROR-RATE100% -90% -80% -7 0% -60% -50% -40% -30% -20%10%0%1 2 3 4 5 6 7 8LOOP NUMBER IN  DIALOGUE9 10Figure 13.
Error and correction rates for Test III.Computational Linguistics, Volume 12, Number 1, January-March 1986 31Pamela K. Fink and Alan W. Biermann The Correction of lll-Formed InputSEN TEN CE-  ERROR-  RATE100% -90% -80% -70% -60% -50% -40% -30% -20% -10% -0%J1 2LEGEND:  % Er rors  Cor rected  by~ :  l o o s e n i n g~ :  expectat ionEZ\ ] :  both~ :  not  cor rec ted3LOOPUiliiI !llllL:Z.4 5 6 7NUMBER IN  D IALOGUE8 9 10WORD-  ERROR-  RATE100% -90% -80% -70% -60% -50% -40% -30% -20% -O~ _ _ _1 2 3 4 5 6 7LOOP NUMBER IN  D IALOGUE8 9 1032Figure 14.
Error and correction rates for Test IV.Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Input# OF WORDS/SECOND4 -I3 -I2 -I1 -I0TEST I - T o t a l l y - O r d e r e d  S c h ~ / /1 2 3# OF WORDS/SECOND4 -I3 -I2 -I1 -04 5 6 7 8 9LOOP NUMBER IN DIALOGUETEST I I  - Par t ia l l y -Ordered  Schema101 2 3 4 $ 6 7 8 9LOOP NUMBER IN DIALOGUE# OF WORDS/SECOND4 -I3 -I2 -I1 -I0TEST I I I -  Tota l ly -Unoxdered  Schema101 2 3 4 5 6 7 8 9LOOP NUMBER IN DIALOGUE10# OF WORDS/SECOND4 -I3 -I2 -I1 -I0TEST IV - Tota l ly -Ordered  Schema v i th  Arguments1 2 3 4 5 6 7 8 9LOOP NUMBER IN DIALOGUE10Figure 15.
Speech rate in the four dialogue schema tests.Computational Linguistics, Volume 12, Number 1, January-March 1986 33Pamela K. Fink and Alan W. Biermann The Correction of m-Formed InputTest III demonstrates the error correction capabilitiesof the system when expectation only knows that one of agroup of sentences will be said next.
It produces a total-ly-unordered dialogue schema.
The results of thesystems error correction capabilities in such a situationappear in Figure 13.Test IV uses a totally-ordered dialogue schema, butwith a variation from test I.
Each sentence sooner orlater contains an argument so that the system does notknow everything about the sentence that will be saidnext.
The data given in Figure 14 shows the errorcorrection rates for this dialogue.
It clearly shows howerror correction failures increase until after the third loopwhen argument creation begins so that the system nolonger error corrects incorrectly.Figure 15 shows the graphs of the average speech rateof the speakers for each of the four tests.
Like the othereight graphs, these graphs reflect the loop structure ofthe dialogues.
As can be seen, the speakers tended toincrease their speech rate as they talked to the system.This behavior was hoped for because as the speech rateincreased, so did the error rate of the speech recognizer,thus placing more of a burden on the error correctingabilities of the expectation system.
Note that, in all eightgraphs in Figures 11 through 14, the word and sentenceerror rates from the voice recognizer generally increasedwith the progress through the dialogue.
This is due to theincreased rate of speech.
However, the actual failure rateof VNLCE did not increase by the same amount.
Theseextra errors were corrected by the expectation system.Figure 16 gives a summary of the average error andcorrection rates for each test and over all.7 RELATED LITERATUREA number of speech understanding systems have beendeveloped uring the past fifteen years (Barnett et al1980, Dixon and Martin 1979, Erman et al 1980, Hatonand Pierrel 1976, Lea 1980, Lowerre and Reddy 1980,Medress 1980, Reddy 1976, Walker 1978, and Wolf andWoods 1980).
Most of these efforts concentrated on theinteraction between low level information sources from aspeech recognizer and a natural language processor todiscover the meaning of an input sentence.
While someof these systems did exhibit expectation capabilities atthe sentence level, none acquired dialogues of the kinddescribed here for the sake of dialogue level expectationand error correction.
A detailed escription of the kindsof expectation mechanisms appearing in these systemsappears in Fink (1983).The problem of handling ill-formed input has beenstudied by Carbonell and Hayes (1983), Granger (1983),Jensen et al (1983), Kwasny and Sondheimer (1981),Riesbeek and Schank (1976), Thompson (1980), Weis-chedel and Black (1980), and Weischedel and Sondheim-er (1983).
A wide variety of techniques have beendeveloped for addressing problems at the word, phrase,sentence, and in some cases, dialogue level.
However,these methodologies have not used historical informationat the dialogue level as described here.
In most cases, thegoal of these systems is to characterize the ill-formedinput into classes of errors and to correct on that basis.The work described here makes no attempt to classify theerrors, but treats them as random events that occur atany point in a sentence.
Thus, an error in this work hasno pattern but occurs probabilistically.
A verb is just aslikely to be mis-recognized or not recognized as is anoun, adjective, determiner, etc.Test  I Tes t  I I  Tes t  I I I  Tes t  IV  Over -a l lword-er ror - ra te  18 .78  11.75  11 .25  12 .17  13 .49cor rectedword-er ror - ra tesentence-er ror - ra te.59  1 .50  1 .50  4 .17  1 .9461 .22  40 .83  52 .25  56.33  52.66cor rectedsentence-er ror - ra te3.22  6 .00  5 .38  16 ,00  7 .65average  speak ing  ra te  2 .27  2 .95  1 .85  1 .97  2 .26Figure 16.
Average word and sentence rror rate in percent,average speaking rate in words-spoken-per-minute.34 Computational Linguistics, Volume 12, Number 1, January-March 1986Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed InputThe acquisition of dialogue as implemented in VNLCEis reminiscent of the program synthesis methodologydeveloped by Biermann and Krishnaswamy (1976)where program flowcharts were constructed from tracesof their behaviors.
However, the "flowcharts" in thecurrent project are probabilistic in nature and the prob-lems associated with matching incoming sentences toexisting nodes has not been previously addressed.Another dialogue acquisition system has been developedby Ho (1984).
However, that system has different goals:to enable the user to consciously design a dialogue toembody a particular human-machine interaction.
Theacquisition system described here is aimed at dealing withill-formed input and is completely automatic and invisibleto the user.
It self activates to bias recognition towardhistorically observed patterns but is not otherwiseobservable.The VNLCE processor may be considered to be alearning system of the tradition described, for example, inMichalski et al (1984).
The current system learns finitestate flowcharts whereas typical learning systems usuallyacquire coefficient values as in Minsky and Papert(1969), assertional statements as in Michalski (1980), orsemantic nets as in Winston (1975).
That is, the currentsystem learns procedures rather than data structures.There is some literature on procedure acquisition such asthe LISP synthesis work described in Biermann et al(1984) and the PROLOG synthesis method of Shapiro(1982).
However, the latter methodologies have notbeen applied to dialogue acquisition.8 CONCLUSIONS AND AREAS FOR FUTURE RESEARCHWe have shown that the ability to use expectation i  theform of knowledge about the dialogue being spoken, aswith humans, is a tremendous aid to speech recognitionby computer.
Since expectation, in this research, hasbeen based on repetition of patterns, the expectationsystem's ability to correct varies, of course, with therepetitiveness of the dialogue itself.
We have attempted,in sections 5 and 6, to justify this decision by demon-strating how the expectation system can acquire commonprogramming constructs uch as loops and arguments.
Itis our belief that repetitious patterns occur in everydaylife, and that the expectation system is capable of dealingwith such patterns, resulting in a generalized situationsimilar to a Schankian script.
Finally, we have tested theexpectation system's correction power in some represen-tative situations, as discussed in section 6.
It has beendemonstrated that the expectation system has the capa-bilities of reducing a large sentence rror rate to nearlyzero in many situations.
At the word level, error rates tothe expectation system climbed as high as 47 % in certainuser dialogues when the user was speaking fast.
At thesame time, the error rate leaving the expectation systemremained fairly low at between zero and fifteen percent.On the average, the system was able to lower a sentenceerror rate of 53% to 8%, and a word error rate of13.5% to 2%.
The use of expectation, along with anability to ignore or add words to the input stream of theparser, is all that is needed to achieve this errorcorrection rate on randomly erroneous input.The parser design, with the five choices at each wordslot, has the potential to run into problems with the expo-nential growth of the search and to result in unacceptablylong parse times.
However, when the rating scheme isused intelligently, it not only aids in finding the bestparse of a word sequence, but it also helps to lower thesearch time necessary by pruning unreasonable searchchoices.
The average parse time for a sentence, from thetests discussed above, was 5.1 seconds while the averagetotal processing time for a sentence was 10.5 seconds.This was on a highly loaded PDP 11/70 under the UNIX 1operating system.
In the event that a particular wordsequence leads the parser down a garden path, a time-out facility has been implemented that causes the parserto fail after one minute of real-time.
However, out of atotal of 629 sentences spoken in the above four tests, thisfeature was needed only 19 times.The research reported on here was divided into twoparts, the theory and the implementation.
Most of thetheory developed was implemented in the VNLCEsystem.
This theory has been aimed at error correctionof random errors using expectation based on historicalinformation.
However, there are many possible exten-sions that could be examined in the future and added tothe implementation if the investigation indicates that itwould create a yet more usable system.
These includethe following:?
use of low level knowledge from the speech recognitionphase,?
use of high level knowledge about the domain in partic-ular and the dialogue task in general,?
a "continue" facility and an "auto-loop" facility asdescribed by Biermann and Krishnaswamy (1976),?
a "conditioning" facility as described by Fink et al(1985),?
implementation f new types of paraphrasing,?
checking a larger environment in the expectationacquisition algorithm when deciding if an incomingsentence is the same or similar to one already seen, and?
examining inter-speaker dialogue patterns.All but two of these areas for expansion are aimed atmoving the expectation system from one that findspatterns in a user's dialogues and acquires historicalknowledge about them to one that can acquire trueprocedures.
The first two areas for expansion have noth-ing to do with creating a true procedure acquisitionmodule but would be highly desirable from the point ofview of the speech recognition application.
Featuresthree and four would simply make the system easier touse and would require little theoretical investigation.
Thefinal three would require research efforts.In conclusion, we have designed a system that is capa-ble of correcting ill-formed input and implemented theComputational Linguistics, Volume 12, Number 1, January-March 1986 35Pamela K. Fink and Alan W. Biermann The Correction of Ill-Formed Inputdesign in the area of speech recognition.
The systemperforms error-correction through a mechanism also usedby humans in the same situation, that of expectation.
Wehave shown that the expectation algorithm is generalenough to handle almost any dialogue structure.
It ispossible to predict approximately what kind of errorcorrection to expect from the system based on thedialogue structure and the word error rate.
We have alsoshown that the theory on which the implemented expec-tation system is based is capable of acquiring and gener-alizing real-world, script-like situations.
This researchcan serve as a starting point for further esearch into thefield of computer expectation, procedure acquisition, andlearning.REFERENCESBallard, B.
1979 Semantic Processing for a Natural LanguageProgramming System.
Ph.D. Dissertation Report CS-1979-8, DukeUniversity, Durham, North Carolina.Barnett, J.; Berstein, M.; Gillman, R.; and Kameny, I.
1980 The SDCSpeech Understanding System.
In Lea 1980: 272-293.Biermann, A. and Ballard, B.
1980 Toward Natural Language Compu-tation.
AJCL 6(2): 71-86.Biermann, A.; Guiho, G.; and Kodratoff, Y., Eds.
1984 AutomaticProgram Construction Techniques.
Macmillan Publishing Co., NewYork, New York.Biermann, A. and Krishnaswamy, R. 1976 Construction of Programsfrom Example Computations.
IEEE Transactions on Software Engi-neering SE-2(3): 141-153.Biermann, A.; Rodman, R.; Rubin, D.; and Heidlage, J.
1985.
NaturalLanguage with Discrete Speech as a Mode for Human-to-MachineCommunication.
Comm.
of ACM 28(6).Carbonell, J. and Hayes, P. 1983 Recovery Strategies for ParsingExtragrammatical L nguage.
AJCL 9(3-4): 123-146.Dixon, N. and Martin, T., Eds.
1979 Automatic Speech and SpeakerRecognition.
IEEE Press, New York, New York.Erman, L.; Hayes-Roth, F; Lesser, V.; and Reddy, D. 1980 The Hear-say-II Speech Understanding System: Integrating Knowledge toResolve Uncertainty.
Computing Surveys, 12(2).Fink, P. 1983 The Acquisition and Use of Dialogue Expectation inSpeech Recognition, Dissertation, Department of ComputerScience, Duke University.Fink, P.; Sigmon, A.; and Biermann, A.
1985 Computer Control ViaLimited Natural Language.
IEEE Trans SMC SMC-14(1): 54-68.Granger, R. 1983 The NOMAD System: Expectation-BasedDetection and Correction of Errors during Understanding ofSyntactically Ill-Formed Text.
AJCL 9(3-4): 188-196.Haton, J. and Pierrel, J.
1976 Organization and Operation of aConnected Speech Understanding System at Lexical, Syntactic andSemantic Levels.
1976 IEEE International Conference on Acous-tics, Speech and Signal Processing, Philadelphia, Pennsylvania:430-433.Ho, T.-P. 1984 The Dialogue Designing Dialogue System, Disserta-tion, Computer Science Department, California Institute of Tech-nology.Jensen, K.; Heidorn, G.; Miller, L.; and Ravin, Y.
1983 Parse Fittingand Prose Fixing: Getting a Hold on Ill-Formedness.
AJCL 9(3-4):147-160.Kwasny, S. and Sondheimer, N. 1981 Relaxation Techniques for Pars-ing Grammatically Ill-Formed Input in Natural Language Under-standing Systems.
AJCL 7(2): 99-108.Lea, W., Ed.
1980 Trends in Speech Recognition.
Prentice-Hall, NewJersey.Lowerre, B. and Reddy, R. 1980 The Harpy Speech UnderstandingSystem.
In Lea 1980: 340-360.Medress, M. 1980 The Sperry Univac System for Continuous SpeechRecognition.
In Lea 1980.Michalski, R. 1980 Pattern Recognition as Rule-Guided InductiveInference.
IEEE Trans.
Pattern Analysis and Machine Intelligence.Michalski, R.; Carbonell, J.; and Mitchell, T. 1984 Machine Learning.Springer Verlag, New York.Minsky, M. and Papert, S. 1969 Perceptrons.
MIT Press, Cambridge,Massachusetts.Reddy, D. 1976 Speech Recognition by Machine: A Review.Proceedings of the IEEE 64(4): 501-531.Riesbeck, C. and Schank, R. 1976 Comprehension by Computer:Expectation-Based Analysis of Sentences in Context.
Tech.
Rep.78, Computer Science Department, Yale University, New Haven,Connecticut.Schank, R. and Abelson, R. 1977 Scripts, Plans, Goals, and Under-standing.
Lawrence Erlbaum Associates, Hillsdale, New Jersey.Shapiro, E. 1982 Algorithmic Program Debugging.
MIT Press,Cambridge, Massachusetts.Thompson, B.
1980 Linguistic Analysis of Natural Language Commu-nication with Computers.
Proceedings of the Eighth InternationalConference on Computational Linguistics, Tokyo, Japan: 190-201.Walker, D., Ed.
1978 Understahding Spoken Language.
Elsevier North-Holland, New York, New York.Weischedel, R. and Black, J.
1980 Responding Intelligently to Unpars-able Inputs.
AJCL 6(2): 97-109.Weisehedel, R. and Sondheimer, N. 1983 Meta-Rules as a Basis forProcessing Ill-Formed Input.
AJCL 9(3-4): 161-177.Winston, P. 1975 Learning Structural Descriptions from Examples.
InWinston, P., Ed., Psychology of Computer Vision.
McGraw-Hill, NewYork, New York.Wolf, J. and Woods, W. 1980 The HWIM Speech UnderstandingSystem.
In Lea 1980: 316-339.Woods, W. 1970 Transition Network Grammars for NaturalLanguage Analysis.
Comm.
of the ACM 13(10): 591-606.NOTE1.
UNIX is a trademark of AT&T Bell Laboratories.36 Computational Linguistics, Volume 12, Number 1, January-March 1986
