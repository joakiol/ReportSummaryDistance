B. V. SUKI-IOTINDECIPHERING METHODS AS A MEANS OF LINGUISTICRESEARCHMethods of linguistic deciphering may be regarded as a set of pro-cedures aimed at the recognition of linguistic objects in a text whoselanguage is not known to the investigator.They combine many advantages of the formal approach to language.Assuming that each deciphering procedure may serve as a definitionof the respective linguistic object we may view the set of such proceduresas a certain linguistic theory which has the following properties:1) A great degree of generalization, because its definitions houldbe valid both for the known and unknown languages.2) Formality, because naturally enough, the deciphering pro-cedures should be presented in the shape of algorithms.3) Constructivity, i.e.
the possibility of identifying a certain lin-guistic object with the help of a deciphering procedure within a rea-sonable (finite) time interval.To identify a linguistic object a deciphering algorithm makes useof a set of its features.
Those features are sufficient for a non-constructivedefinition of the object under investigation and to a very great extentdetermine the kind of the recognition algorithm.It seems obvious that a linguistic object cannot be defined by meansof binary features alone.
A definition based on binary features willbe either too specific and valid only for a chosen language, or too abstractand insufficient for identifying the object in a given text.The following scheme seems to be better founded:(1) Binary features are used to determine the general type of cer-tain linguistic objects.
The objects belonging to that type form the setof admissible solutions of a deciphering problem.
(2) An objective function which estimates the quality of eachsolution is introduced on the set of admissible solutions.
The values ofthe objective function are calculated with the help of the investigatedtext.
They reflect the individuality of the given language.14210 B.V .
$UKHOTINA maximum or a minimum of the objective function should cor,-respond to the linguistic object which is to be defined.
(3) It follows that a recognition procedure should be an optimi-zation algorithm which finds "the best" admissible solution - fromthe point of view of the objective function.Thus, the set of admissible solutions, the objective function and theoptimization algorithm constitute the definition of a linguistic objectwhich may be used for the purposes of deciphering.
A definition ofthis kind will be further eferred to as a deciphering algorithm, or simply,an algorithm.There is a natural hierarchy of deciphering algorithms.
An algorithmB is senior to an algorithm A if the former makes use of the informationprovided by the latter.
If A and B work alternatively, each time im-proving the output, then the seniority isdetermined by the first iteration.Consequently, taking into account he fact that the set of essentiallydifferent deciphering algorithms hould be finite, it appears that theremust exist "zero " algorithms which use no information producedby any other deciphering algorithm.Zero algorithms hould be different due to the fact that the phy-sical substances of different languages may be different oo.
Thus thezero algorithm for the analysis of the written form of languages shouldbe able to discriminate between a dark spot and a light one and to findthe set of alphabetic symbols of the language.
A similar algorithmadjusted to the analysis of audible speech should produce an alphabet ofphonemes, exploiting its capacity to discern certain minimal differenciesof sonation.
The plurality of zero algorithms may be reduced by con-verting signals of different nature into a set of curves.
As is well knownsuch algorithms are the goal of pattern recognition theory.Senior algorithms hould be used for the analysis of grammar; thehighest level corresponds to the problems of semantics and translation.Many algorithms of different levels display great similarity andsometimes even identity, their only difference consisting in the linguisticmaterial which serves as the input.Thus the algorithms that classify letters according to their pro-nunciation may closely resemble the algorithms that classify morphe-mes according to their grammatical role; the algorithms that findthe boundaries between sentences may be similar to those that findboundaries between words and so on.The following types may be pointed out:1) Algorithms of classification, which divide the set of investi-DECIPHERING METHODS AS A MEANS OF LINGUISTICS RESEARCH 211gated objects into several subsets.
For instance, the letters are classi-fied into vowels and consonants, morphemes - into auxiliary and rootmorphemes, words - into parts of speech.2) Algorithms of aggregation which form larger units fromsmaller ones.
For instance, they put together letters into morphemesor syllables, morphemes into words and words into sentences.3) Algorithms of connection, which find Out some rdation ofpartial ordering.
A typical example is provided by different algorithmsof discovering the dependency graph of a sentence.4) Algorithms of mapping the dements of an unknown languageinto the dements of a known one.
Algorithms of this type shouldsolve problems of translation and discover the kinship of languages.The most simple classification algorithm is that which classify let-ters into vowels and consonants:In effect this algorithm is valid for any string composed of objectsof two different classes and characterized by the fact that objects of thesame class co-occur rather rarely whereas objects of different classesco-occur rdatively more often.The set of admissible solutions in this case is a set of divisions of thelist of objects into two subsets; the quality Q of a division D = { K1,Ks } is evaluated by the following formula:Q- - -2  .~ f (e,, ej).i 1Here f (e~, ei) denotes the frequency of co-occurrence of objectse,, e s from classes/('1 and Ks respectively.
The maximum of Q correspondsto the optimal classification.
An appropriate optimization procedurereduces the amount o f  divisions that should be evaluated to a reason-able number.
This algorithm has been thoroughly tested in a numberof computer experiments and in every case yielded almost entirelycorrect results.The most important algorithm of aggregation is the morphemeidentification algorithm.
Apart from identifying morphemes this al-1 See \]3.
B. CyXOTHH, YIpo6aeMH cTpyTypnofi anHrB~ICTn~, 1962.
Lateron appeared the works of V. V. SEVORO~Kn~, Ik.
C~Lo and A. TlmTmxo~.Since the pioneering work of Z. I-tam~s, From phoneme to morpheme, in~ Language 2,XXXI (1955), pp.
190-222, attempts for solving this problem were made by N. D.ANDaE~V, A. Y.
~a_rv~vI~.
The author's first paper on this problem appeared in 1963(Hpo6AeM~ cTpyHTypHofi ArlI-IrBHCTrII~H).212 B.V. $UKHOTINgorithm discovers an IC graph which shows the way in which morphe-mes are combined into words.
The algorithm is valid even for textswhich have no special devices for marking the boundaries betweenwords and may be used in order to fred those boundaries.An admissible solution in this case is a series of divisions D1 .... , D~of the text, each class of D~ being included in a certain class of D~+1.Morphemes form the classes of the smallest division D1, the classesof the biggest division D~ corresponding to words.The objective function is set up by ascribing to each class K~ ofD i a certain number p(K~) which shows the strength of mutual pre-diction of the components of Kit and by adding up all p(K~i):Q= .~v 2; p(Ko,).i yp (K~) is the product of Sty,, (Ki~) (internal stability) and SG (Ki~) (exter-nal stability).Sti~ (Kij) is the mean conditional probability1 (f(l~) f(r.)where the string K~j of the length L is divided into the left part l~ andthe right part r~ (l~r~ = Kq) in all possible ways; f(l~), f(r~), f(K~) de-noting the frequencies of the respective strings.SG(Ki~) is equal to zero if there is a string K such that K~ c Kand f(K~)=f(K), and equal to 1 in other cases.This algorithm was tested in a number of manual experiments.A large computer experiment is going on at the present ime.It is only statistically that the immediate neighbourhood of thewords in a text reflects their semantic onnections.
The understandingof the text is greatly facilitated by the discovery of those connections,a procedure carried out by the connection algorithms.Representative of these is the algorithm of finding the dependencygraph of a sentence.
For this purpose the words of the language shouldbe classified into parts of speech so that we may consider a word vto be included in a class Kv.
The conditional probability p(KJK,) ofoccurrence o f  Kv near Kwis calculated with the help of the text.The set of admissible solutions in the set of all possible dependencytrees which may be ascribed to a given sentence.
The conditional pro-babilities provide the weights for the arcs of the tree.
The quality ofDECIPHERING METHODS AS A MEANS OF LINGUISTIC RESEARCH 213a tree is the sum (or the mean) of the weights of all arcs.
The optimaltree presumably has the maximum quality.
Some algorithms of thistype has recendy been tested in computer experiments and yieldedgood results.One such experiment which employed 19 syntactic classes wascarried out for a R.ussian text of about 10000 words.
It has establishedabout 80 % correct connections.
Here are some typical examples:+ I II +1 +OaHamau nrpa:tr~ B r~apr~iAdv.
Verb.
Prep.
Acc.
Sub.y r~0Haoraap~efiua H pyMoBaPrep.
Gen. Sub.
Gen. Sub.Ylpo,me B paccenHnOCTn cnnezn nepen nycTl, IMn CBOI4MH npntopaMr~Nora.
S. Pr.
Loc.
Sub.
Verb.
Pr.
Ins.
Ad.
Ins.
Ad.
Ins.
Sub.Applying the optimization algorithm to the alphabet of syntacticclasses, we get the "representating graph " which shows the typicalconnections, recognized by the given algorithm.
For the algorithmmentioned above such representating graph 'looks as follows:\[ Adverb \[~ l  No,,.
s,,bs,: H Nora.
~,',j.
1~'~ co4,,,aio.
:.\[ a,.,,,,d.
\] \[ I,,.
s,b,t.
\] Ice,,.
S,bst.
\ [ .
\[ Lo~.
s,b,t.Algorithms of this kind may be used for the purposes of machinetranslation, in which case a greater amount of the input informationis needed.214 ~.
V. SUKHOTINA typical example of an algorithm which obtains mapping M-----= { E~ ~ El } (E~ being some elements of the unknown language,E" - the respective lements of the known one) is furnished by thealgorithm which discovers the pronunciation of letters.It is based on the hypothesis that letters of two different languageswhich have similar pronunciation possess imilar combinatory powerin their respective languages as well.The combinatory power of letter li may be described by the vec-tor of conditional probabilities { p(lJlj) } which characterizes the oc-currences of I i in the neighbourhood of I r In the same way, vector(p(1JIj) } characterizes the combinatory power of 1'.The quality of a mapping may be estimated by the formula:Q(M)----- .~ d(lol" ).iHere d denotes the distance (e.g.
Euclidean) between vectors (p(l  dl~) ) and { p(l'/l~) }.
All pairs l, ~ l~ l i ~ l~ belong to mapping M, sothat d may be calculated by the formula:d(l,, l;) ?-~,(p(l,/l~) p(l,/lyl)YThe minimum of Q corresponds to the optimal mapping.
Somealgorithms of this type have been tested with good results.
It is obviousthat a similar algorithm will be able to compile a bilingual dictionarywith the entries in the unknown language, although the latter problemis, naturally, far more difficult.
