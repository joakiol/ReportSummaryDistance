Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 37?42,Sydney, July 2006. c?2006 Association for Computational LinguisticsInvestigations on Event-Based SummarizationMingli WuDepartment of ComputingThe Hong Kong Polytechnic UniversityKowloon, Hong Kongcsmlwu@comp.polyu.edu.hkAbstractWe investigate independent and relevantevent-based extractive mutli-documentsummarization approaches.
In this paper,events are defined as event terms and as-sociated event elements.
With independ-ent approach, we identify important con-tents by frequency of events.
With rele-vant approach, we identify importantcontents by PageRank algorithm on theevent map constructed from documents.Experimental results are encouraging.1 IntroductionWith the growing of online information, it is in-efficient for a computer user to browse a greatnumber of individual news documents.
Auto-matic summarization is a powerful way to over-come such difficulty.
However, the research lit-erature demonstrates that machine summariesneed to be improved further.The previous research on text summarizationcan date back to (Luhn 1958) and (Edmundson1969).
In the following periods, some researchersfocus on extraction-based summarization, as it iseffective and simple.
Others try to generate ab-stractions, but these works are highly domain-dependent or just preliminary investigations.
Re-cently, query-based summarization has receivedmuch attention.
However, it is highly related toinformation retrieval, another research subject.
Inthis paper, we focus on generic summarization.News reports are crucial to our daily life.
In thispaper, we focus on effective summarization ap-proaches for news reports.Extractive summarization is widely investi-gated in the past.
It extracts part of document(s)based on some weighting scheme, in which dif-ferent features are exploited, such as position indocument, term frequency, and key phrases.
Re-cent extraction approaches may also employ ma-chine learning approaches to decide which sen-tences or phrases should be extracted.
Theyachieve preliminary success in different applica-tion and wait to be improved further.Previous extractive approaches identify theimportant content mainly based on terms.
Bag ofwords is not a good representation to specify anevent.
There are multiple possible explanationsfor the same collection of words.
A predefinedtemplate is a better choice to represent the event.However it is domain-dependent and need mucheffort to create and fill it.
This tension motivatesus to seek a balance between effective imple-mentation and deep understanding.According to related works (Filatovia andHatzivassiloglou, 2004) (Vanderwende et al,2004), we assume that event may be a naturalunit to convey meanings of documents.
In thispaper, event is defined as the collection of eventterms and associated event elements in clauselevel.
Event terms express the meaning of actionsthemselves, such as ?incorporate?.
In addition toverbs, action nouns can also express meaning ofactions and should be regarded as event terms.For example, ?incorporation?
is action noun.Event elements include named entities, such asperson name, organization name, location, time.These named entities are tagged with GATE(Cunningham et al, 2002).
Based on our eventdefinition, independent and relevant event-basedapproaches are investigated in this research.
Ex-periments show that both of them achieve en-couraging results.The related works are discussed in Section 2.Independent event-based summarization ap-proach is described in Section 3.
Relevant event-based summarization approach is described inSection 4.
Section 5 presents the experiments and37evaluations.
Then the strength and limitation ofour approaches are discussed in Section 6.
Fi-nally, we conclude the work in Section 7.2 Related WorkTerm-based extractive summarization can dateback to (Luhn, 1958) and (Edmundson, 1969).This approach is simple but rather applicable.
Itrepresents the content of documents mainly bybag of words.
Luhn (1958) establishes a set of?significant?
words, whose frequency is betweena higher bound and a lower bound.
Edmundson(1969) collects common words, cue words, ti-tle/heading words from documents.
Weightscores of sentences are computed based ontype/frequency of terms.
Sentences with higherscores will be included in summaries.
Later re-searchers adopt tf*idf score to discriminatewords (Brandow et al, 1995) (Radev et al,2004).
Other surface features are also exploitedto extract important sentence, such as position ofsentence and length of sentence (Teufel andMoens, 1999) (Radev et al, 2004).
To make theextraction model suitable for documents in dif-ferent domains, recently machine learning ap-proaches are widely employed (Kupiec et al,1995) (Conroy and Schlesinger, 2004).To represent deep meaning of documents,other researchers have investigated differentstructures.
Barzilay and Elhadad (1997) segmentthe original text and construct lexical chains.They employ strong chains to represent impor-tant parts of documents.
Marcu (1997) describesa rhetorical parsing approach which takes unre-stricted text as input and derives the rhetoricalstructure tree.
They express documents withstructure trees.
Dejong (1978) adopts predefinedtemplates to express documents.
For each topic,the user predefines frames of expected informa-tion types, together with recognition criteria.However, these approaches just achieve moder-ate results.Recently, event receives attention to representdocuments.
Filatovia and Hatzivassiloglou(2004) define event as action (verbs/actionnouns) and named entities.
After identifying ac-tions and event entities, they adopt frequencyweighting scheme to identify important sentence.Vanderwende et al (2004) represent event bydependency triples.
After analysis of triples theyconnect nodes (words or phrases) by way of se-mantic relationships.
Yoshioka and Haraguchi(2004) adopt a similar approach to build a map,but they regard sentence as the nodes of the map.After construction of a map representation fordocuments, Vanderwende et al (2004), and Yo-shioka and Haraguchi (2004) all employ PageR-ank algorithm to select the important sentences.Although these approaches employ event repre-sentation and PageRank algorithm, it should benoted that our event representation is differentwith theirs.
Our event representation is based onnamed entities and event terms, without help ofdependency parsing.
These previous event-basedapproaches achieved promising results.3 Independent Event-based Summari-zationBased on our observation, we assume that eventsin the documents may have different importance.Important event terms will be repeated and al-ways occur with more event elements, becausereporters hope to state them clearly.
At the sametime, people may omit time or location of an im-portant event after they describe the event previ-ously.
Therefore in our research, event terms oc-curs in different circumstances will be assigneddifferent weights.
Event terms occur betweentwo event elements should be more importantthan event terms occurring just beside one eventelements.
Event terms co-occurring with partici-pants may be more important than event termsjust beside time or location.The approach on independent event-basedsummarization involves following steps.1.
Given a cluster of documents, analyzeeach sentence one at a time.
Ignore sen-tences that do not contain any event ele-ment.2.
Tag the event terms in the sentence, whichis between two event elements or near anevent element with the distance limitation.For example, [Event Element A, EvenTerm, Event Element B], [Event Term,Event Element A], [Event Element A,Event Term]3.
Assign different weights to different eventterms, according to contexts of eventterms.
Different weight configurations aredescribed in Section 5.2.
Contexts refer tonumber of event elements beside eventterms and types of these event elements.4.
Get the average tf*idf score as the weightof every event term or event element.
Thealgorithm is similar with Centroid.385.
Sum up the weights of event terms andevent elements in a sentence.6.
Select the top sentences with highestweights, according to the length of sum-mary.4 Relevant Event-based SummarizationIndependent event-based approaches do not ex-ploit relevance between events.
However, wethink that it may be useful to identify importantevents.
After a document is represented byevents, relevant events are linked together.
Wemade the assumption that important events maybe mentioned often and events associated to im-portant events may be important also.
PageRankis a suitable algorithm to identify the importanceof events from a map, according to the previousassumption.
In the following sections, we willdiscuss how to represent documents by eventsand how to identify important event with PageR-ank algorithm.4.1 Document RepresentationWe employ an event map to represent content ofa document cluster, which is about a certaintopic.
In an event map, nodes are event terms orevent elements, and edges represent associationor modification between two nodes.
Since thesentence is a natural unit to express meanings,we assume that all event terms in a sentence areall relevant and should be linked together.
Thelinks between every two nodes are undirectional.In an ideal case, event elements should belinked to the associated event terms.
At the sametime, an event element may modify another ele-ment.
For example, one element is a head nounand another one is the modifier.
An event term(e.g., verb variants) may modify an event ele-ment or event term of another event.
In this case,a full parser should be employed to get associa-tions or modifications between different nodes inthe map.
Because the performance of currentparsing technology is not perfect, an effectiveapproach is to simulate the parse tree to avoidintroducing errors of a parser.
The simplifica-tions are described as follows.
Only event ele-ments are attached with corresponding eventterms.
An event term will not be attached to anevent element of another event.
Also, an eventelement will not be attached to another eventelement.
Heuristics are used to attach event ele-ments with corresponding event terms.Given a sentence ?Andrew had become littlemore than a strong rainstorm early yesterday,moving across Mississippi state and heading forthe north-eastern US?, the event map is shown inFig.
1.
After each sentence is represented by amap, there will be multiple maps for a cluster ofdocuments.
If nodes from different maps arelexical match, they may denote same thing andshould be linked.
For example, if named entity?Andrew?
occurred in Sentence A, B and C, thenthe three occurrences OA, OB and OC will belinked as OA?OB, OB?OC, OC?OA.
By thisway, maps for sentences can be linked based onsame concepts.Figure 1.
Document representation with eventmap4.2 Importance Identification by PageRankGiven a whole map for a cluster of documents,the next step is to identify focus of these docu-ments.
Based on our assumption about importantcontent in the previous section, PageRank algo-rithm (Page et al, 1998) is employed to fulfillthis task.
PageRank assumes that if a node isconnected with more other nodes, it may be morelikely to represent a salient concept.
The nodesrelevant to the significant nodes are closer to thesalient concept than those not.
The algorithmassigns the significance score to each node ac-cording to the number of nodes linking to it aswell as the significance of the nodes.
In PageR-ank algorithm, we use two directional links in-stead for every unidirectional link in Figure 1.The equation to calculate the importance (in-dicated by PR) of a certain node A is shown asfollows:))()(...)()()()(()1()(2211ttBCBPRBCBPRBCBPRddAPR ++++?=Where B1, B2,?, Bt are all nodes which link tothe node A.
C(Bi) is the number of outgoing linksfrom the node Bi.
The weight score of each nodecan be gotten by this equation recursively.
d isthe factor used to avoid the limitation of loop inthe map structure.
As the literature (Page et al,1998) suggested, d is set as 0.85.
The signifi-cance of each sentence to be included in the39summary is then derived from the significance ofthe event terms and event elements it contains.5 Evaluation5.1 Dataset and Evaluation MetricsDUC 2001 dataset is employed to evaluate oursummarization approaches.
It contains 30 clus-ters and a total of 308 documents.
The number ofdocuments in each cluster is between 3 and 20.These documents are from some English newsagencies, such as Wall Street Journal.
The con-tents of each cluster are about some specifictopic, such as the hurricane in Florida.
For eachcluster, there are 3 different model summaries,which are provided manually.
These modelsummaries are created by NIST assessors for theDUC task of generic summarization.
Manualsummaries with 50 words, 100 words, 200 wordsand 400 words are provided.Since manual evaluation is time-consumingand may be subjective, the typical evaluationpackage, ROUGE (Lin and Hovy, 2003), is em-ployed to test the quality of summaries.
ROUGEcompares the machine-generated summaries withmanually provided summaries, based on uni-gram overlap, bigram overlap, and overlap withlong distance.
It is a recall-based measure andrequires that the length of the summaries be lim-ited to allow meaningful comparison.
ROUGE isnot a comprehensive evaluation method and in-tends to provide a rough description about theperformance of machine generated summary.5.2 Experimental ConfigurationIn the following experiments for independentevent-based summarization, we investigate theeffectiveness of the approach.
In addition, weattempt to test the importance of contextual in-formation in scoring event terms.
The number ofassociated event terms and the type of eventterms are considered to set the weights of eventterms.
The weights parameters in the followingexperiments are chosen according to empiricalestimations.Experiment 1: Weight of any entity is 1.Weight of any verb/action noun, which is be-tween two entities or just beside one entity, is 1.Experiment 2: Weight of any entity is 1.Weight of any verb/action noun, which is be-tween two entities, is 3.
Weight of anyverb/action noun, which is just beside one entity,is 1.Experiment 3: Weight of any entity is 1.Weight of any verb/action noun, which is be-tween two entities and the first entity is person ororganization, is 5.
Weight of any verb/actionnoun, which is between two entities and the firstentity is not person and not organization, is 3.Weight of any verb/action noun, which is justafter a person or organization, is 2.
Weight ofany verb/action noun, which is just before oneentity, is 1.
Weight of any verb/action noun,which is just after one entity and the entity is notperson and not organization, is 1.In the following experiments, we investigatethe effectiveness of our approaches on under dif-ferent length limitation of summary.
Based onthe algorithm of experiment 3, we design ex-periment to generate summaries with length 50words, 100 words, 200 words, 400 words.
Theyare named Experiment 4, Experiment 5, Ex-periment 3 and Experiment 6.In other experiments for relevant event-basedsummarization, we investigate the function ofrelevance between events.
The configurations aredescribed as follows.Experiment 7: Event terms and event ele-ments are identified as we discussed in Section 3.In this experiment, event elements just includenamed entities.
Occurrences of event terms orevent elements are linked with by exact matches.Finally, the PageRank is employed to select im-portant events and then important sentences.Experiment 8: For reference, we select one ofthe four model summaries as the final summaryfor each cluster of documents.
ROUGE is em-ployed to evaluate the performance of thesemanual summaries.5.3 Experimental ResultsThe experiment results on independent event-based summarization are shown in table 1.
Theresults for relevant event-based summarizationare shown in table 3.Exp.
1 Exp.
2 Exp.
3Rouge-1 0.315 0.322 0.323Rouge-2 0.049 0.055 0.055Rouge-L 0.299 0.305 0.306Table 1.
Results on independent event-basedsummarization (summary with length of 200words)From table 1, we can see that results of Ex-periment 2 are better than those of Experiment 1.It proves our assumption that importance ofevent terms is different when these event termsoccur with different number of event elements.Results of Experiment 3 are not significant betterthan those of Experiment 2, so it seems that the40assumption that importance of event terms is notvery different when these event terms occur withdifferent types of event elements.
Another possi-ble explanation is that after adjustment of theweight for event terms, the difference betweenthe results of Experiment 2 and Experiment 3may be extended.\Table 2.
Results on independent event-basedsummarization (summary with different length)Four experiments of table 2 show that per-formance of our event based summarization aregetting better, when the length of summaries isexpanded.
One reason is that event based ap-proach prefers sentences with more event termsand more event elements, so the preferredlengths of sentences are longer.
While in a shortsummary, people always condense sentencesfrom original documents, and use some newwords to substitute original concepts in docu-ments.
Then the Rouge score, which evaluatesrecall aspect, is not good in our event-based ap-proach.
In contrast, if the summaries are longer,people will adopt detail event descriptions inoriginal documents, and so our performance isimproved.Exp.
7 Exp.
8Rouge-1 0.325 0.595Rouge-2 0.060 0.394Rouge-L 0.305 0.586Table 3.
Results on relevant event-basedsummarization and a reference experiment(summary with length of 200 words)In table 3, we found the Rouge-score of rele-vant event-based summarization (Experiment 7)is better than independent approach (Experiment1).
In Experiment 1, we do not discriminate theweight of event element and event terms.
In Ex-periment 7, we also did not discriminate theweight of event element and event terms.
It isfair to compare Experiment 7 with Experiment 1and it?s unfair to compare Experiment 7 withExperiment 3.
It looks like the relevance betweennodes (event terms or event elements) can help toimprove the performance.
However, performanceof both dependent and independent event-basedsummarization need to be improved further,compared with human performance in Experi-ment 8.6 DiscussionAs discussed in Section 2, event-based ap-proaches are also employed in previous works.We evaluate our work in this context.
As event-based approaches in this paper are similar withthat of Filatovia and Hatzivassiloglou (2004), andthe evaluation data set is the same one, the re-sults are compared with theirs.
Exp.
4 Exp.
5 Exp.
3 Exp.
6Rouge-1 0.197 0.249 0.323 0.382Rouge-2 0.021 0.031 0.055 0.081Rouge-L 0.176 0.231 0.306 0.367Fi t-gure 2.
Results reported in (Filatovia and Hazivassiloglou 2004)Figure 3.
Results of relevant event-based ap-proachFilatovia and Hatzivassiloglou (2004) reportthe ROUGE scores according to each cluster ofDUC 2001 data collection in Figure 2.
In thisfigure, the bold line represents their event-basedapproach and the light line refers to tf*idf ap-proach.
It can be seen that the event-based ap-proach performs better.
The evaluation of therelevant event-based approach presented this pa-per is shown in Figure 3.
The proposed approachachieves significant improvement on mostdocument clusters.
The reason seems that therelevance between events is exploited.Centroid is a successful term-based summari-zation approach.
For caparison, we employMEAD (Radev et.al., 2004) to generate Cen-troid-based summaries.
Results show that Cen-troid is better than our relevant event-based ap-proach.
After comparing the summaries given bythe two approaches, we found some limitation ofour approach.41Event-based approach does not work well ondocuments with rare events.
We plan to dis-criminate the type of documents and apply event-based approach on suitable documents.
Our rele-vant event-based approach is instance-based andtoo sensitive to number of instances of entities.Concepts seem better to represent meanings ofevents, as they are really things we care about.
Inthe future, the event map will be build based onconcepts and relationships between them.
Exter-nal knowledge may be exploited to refine thisconcept map.7 ConclusionIn this study, we investigated generic summari-zation.
An event-based scheme was employed torepresent document and identify important con-tent.
The independent event-based approachidentified important content according to eventfrequency.
We also investigated the differentimportance of event terms in different context.Experiment showed that this idea achieved prom-ising results.
Then we explored summarizationunder different length limitation.
We found thatour independent event-based approaches actedwell with longer summaries.In the relevant event-based approach, eventswere linked together by same or similar eventterms and event elements.
Experiments showedthat the relevance between events can improvethe performance of summarization.
Comparedwith close related work, we achieved encourag-ing improvement.ReferencesRegina Barzilay, and Michael Elhadad.
1997.
Usinglexical chains for text summarization.
In Proceed-ings of the ACL?97/EACL?97 Workshop on Intel-ligent Scalable Text Summarization, 10-17.Ronald Brandow, Karl Mitze, and Lisa F. Rau.
1995.Automatic condensation of electronic publicationsby sentence selection.
Information Processing andManagement 31(5):675-686.John M. Conroy and Judith D. Schlesinger.
2004.Left-brain/right-brain multi-document summariza-tion.
Available at http://duc.nist.gov/pubs.htmlHamish Cunningham, Diana Maynard, KalinaBontcheva, Valentin Tablan.
2002.
GATE: aframework and graphical development environ-ment for robust NLP tools and applications.
InProceedings of the 40th Annual Meeting of the As-sociation for computational Linguistics (ACL?02).Gerald Francis DeJong.
1978.
Fast skimming of newsstories: the FRUMP system.
Ph.D. thesis, YaleUniversity.H.P.
Edmundson.
1969.
New methods in automaticextracting.
Journal of the Association for comput-ing machinery, 16(2):264-285.Elena Filatova and Vasileios Hatzivassiloglou.
Event-based extractive summarization.
2004.
In Proceed-ings of the ACL-04 Workshop, 104-111.Julian Kupiec, Jan Pedersen and Francine Chen.
1995.A trainable document summarizer.
In Proceedingsof the 18th ACM-SIGIR conference, 68-73.Chin-Yew Lin and Eduard Hovy.
2003.
AutomaticEvaluation of Summaries Using N-gram Co-occurrence Statistics.
In Proceedings of HLT-NAACL, Edmonton, Canada, May.H.P.
Luhn.
1958.
The automatic creation of literatureabstracts.
IBM Journal of Research and Develop-ment 2:159-165.Daniel Marcu.
1997.
The rhetorical parsing of naturallanguage texts.
In Proceedings of the 35th AnnualMeeting of the Association for computational Lin-guistics (ACL?97), 96-103.Dragomir R. Radev, Timothy Allison, Sasha Blair-Goldensohn, John Blitzer, Arda Celebi, StankoDimitrov, Elliott Drabek, Ali Hakim, Wai Lam,Danyu Liu, Jahna Otterbacher, Hong Qi, HoracioSaggion, Simone Teufel, Michael Topper, AdamWinkel, Zhu Zhang.
2004.
MEAD - a platform formultidocument multilingual text summarization.LREC 2004.Simone Teufel and Marc Moens.
1999.
Argumenta-tive classification of extracted sentences as a firststep towards flexible abstracting.
Advances inAutomatic Text Summarization, Inderjeet Maniand Mark T. Maybury (editors), 137-154.
Cam-bridge, Massachusetts: MIT Press.Larry Page, Sergey Brin, et al 1998.
The PageRankCitation Ranking: Bring Order to the Web.
Techni-cal Report, Stanford University, 1998.Lucy Vanderwende, Michele Banko, and ArulMenezes.
2004.
Event-centric summary generation.Available at http://duc.nist.gov/pubs.htmlMasaharu Yoshioka and Makoto Haraguchi.
2004.Multiple news articles summarization based onevent reference information.
In Working Notes ofthe Fourth NTCIR Workshop Meeting, NationalInstitute of Informatics, 2004.42
