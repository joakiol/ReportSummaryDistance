Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 675?684,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsExploiting Multiple Treebanks for Parsing with Quasi-synchronousGrammarsZhenghua Li, Ting Liu?, Wanxiang CheResearch Center for Social Computing and Information RetrievalSchool of Computer Science and TechnologyHarbin Institute of Technology, China{lzh,tliu,car}@ir.hit.edu.cnAbstractWe present a simple and effective frameworkfor exploiting multiple monolingual treebankswith different annotation guidelines for pars-ing.
Several types of transformation patterns(TP) are designed to capture the systematic an-notation inconsistencies among different tree-banks.
Based on such TPs, we design quasi-synchronous grammar features to augment thebaseline parsing models.
Our approach cansignificantly advance the state-of-the-art pars-ing accuracy on two widely used target tree-banks (Penn Chinese Treebank 5.1 and 6.0)using the Chinese Dependency Treebank asthe source treebank.
The improvements arerespectively 1.37% and 1.10% with automaticpart-of-speech tags.
Moreover, an indirectcomparison indicates that our approach alsooutperforms previous work based on treebankconversion.1 IntroductionThe scale of available labeled data significantly af-fects the performance of statistical data-driven mod-els.
As a structural classification problem that ismore challenging than binary classification and se-quence labeling problems, syntactic parsing is moreprone to suffer from the data sparseness problem.However, the heavy cost of treebanking typicallylimits one single treebank in both scale and genre.At present, learning from one single treebank seemsinadequate for further boosting parsing accuracy.1?Correspondence author: tliu@ir.hit.edu.cn1Incorporating an increased number of global features, suchas third-order features in graph-based parsers, slightly affectsparsing accuracy (Koo and Collins, 2010; Li et al, 2011).Treebanks # of Words GrammarCTB5 0.51 million Phrase structureCTB6 0.78 million Phrase structureCDT 1.11 million Dependency structureSinica 0.36 million Phrase structureTCT about 1 million Phrase structureTable 1: Several publicly available Chinese treebanks.Therefore, studies have recently resorted to other re-sources for the enhancement of parsing models, suchas large-scale unlabeled data (Koo et al, 2008; Chenet al, 2009; Bansal and Klein, 2011; Zhou et al,2011), and bilingual texts or cross-lingual treebanks(Burkett and Klein, 2008; Huang et al, 2009; Bur-kett et al, 2010; Chen et al, 2010).The existence of multiple monolingual treebanksopens another door for this issue.
For example, ta-ble 1 lists a few publicly available Chinese treebanksthat are motivated by different linguistic theories orapplications.
In the current paper, we utilize thefirst three treebanks, i.e., the Chinese Penn Tree-bank 5.1 (CTB5) and 6.0 (CTB6) (Xue et al, 2005),and the Chinese Dependency Treebank (CDT) (Liuet al, 2006).
The Sinica treebank (Chen et al, 2003)and the Tsinghua Chinese Treebank (TCT) (Qiang,2004) can be similarly exploited with our proposedapproach, which we leave as future work.Despite the divergence of annotation philosophy,these treebanks contain rich human knowledge onthe Chinese syntax, thereby having a great deal ofcommon ground.
Therefore, exploiting multipletreebanks is very attractive for boosting parsing ac-curacy.
Figure 1 gives an example with different an-675?
?1 ?
?2 ?3 ?
?4VV NN CC NNpromote trade and industryv n c nOBJNMODNMODVOB COOLADw0ROOTROOTFigure 1: Example with annotations from CTB5 (upper)and CDT (under).notations from CTB5 and CDT.2 This example illus-trates that the two treebanks annotate coordinationconstructions differently.
In CTB5, the last noun isthe head, whereas the first noun is the head in CDT.One natural idea for multiple treebank exploita-tion is treebank conversion.
First, the annotationsin the source treebank are converted into the styleof the target treebank.
Then, both the convertedtreebank and the target treebank are combined.
Fi-nally, the combined treebank are used to train abetter parser.
However, the inconsistencies amongdifferent treebanks are normally nontrivial, whichmakes rule-based conversion infeasible.
For exam-ple, a number of inconsistencies between CTB5 andCDT are lexicon-sensitive, that is, they adopt dif-ferent annotations for some particular lexicons (orword senses).
Niu et al (2009) use sophisticatedstrategies to reduce the noises of the converted tree-bank after automatic treebank conversion.The present paper proposes a simple and effectiveframework for this problem.
The proposed frame-work avoids directly addressing the difficult anno-tation transformation problem, but focuses on mod-eling the annotation inconsistencies using transfor-mation patterns (TP).
The TPs are used to composequasi-synchronous grammar (QG) features, suchthat the knowledge of the source treebank can in-spire the target parser to build better trees.
We con-duct extensive experiments using CDT as the sourcetreebank to enhance two target treebanks (CTB5 andCTB6).
Results show that our approach can signifi-cantly boost state-of-the-art parsing accuracy.
More-over, an indirect comparison indicates that our ap-2CTB5 is converted to dependency structures following thestandard practice of dependency parsing (Zhang and Clark,2008b).
Notably, converting a phrase-structure tree into itsdependency-structure counterpart is straightforward and can beperformed by applying heuristic head-finding rules.proach also outperforms the treebank conversion ap-proach of Niu et al (2009).2 Related WorkThe present work is primarily inspired by Jiang etal.
(2009) and Smith and Eisner (2009).
Jiang et al(2009) improve the performance of word segmen-tation and part-of-speech (POS) tagging on CTB5using another large-scale corpus of different annota-tion standards (People?s Daily).
Their framework issimilar to ours.
However, handling syntactic anno-tation inconsistencies is significantly more challeng-ing in our case of parsing.
Smith and Eisner (2009)propose effective QG features for parser adaptationand projection.
The first part of their work is closelyconnected with our work, but with a few impor-tant differences.
First, they conduct simulated ex-periments on one treebank by manually creating afew trivial annotation inconsistencies based on twoheuristic rules.
They then focus on better adapting aparser to a new annotation style with few sentencesof the target style.
In contrast, we experiment withtwo real large-scale treebanks, and boost the state-of-the-art parsing accuracy using QG features.
Sec-ond, we explore much richer QG features to fullyexploit the knowledge of the source treebank.
Thesefeatures are tailored to the dependency parsing prob-lem.
In summary, the present work makes substan-tial progress in modeling structural annotation in-consistencies with QG features for parsing.Previous work on treebank conversion primar-ily focuses on converting one grammar formalismof a treebank into another and then conducting astudy on the converted treebank (Collins et al, 1999;Xia et al, 2008).
The work by Niu et al (2009)is, to our knowledge, the only study to date thatcombines the converted treebank with the existingtarget treebank.
They automatically convert thedependency-structure CDT into the phrase-structurestyle of CTB5 using a statistical constituency parsertrained on CTB5.
Their experiments show thatthe combined treebank can significantly improvethe performance of constituency parsers.
However,their method requires several sophisticated strate-gies, such as corpus weighting and score interpo-lation, to reduce the influence of conversion errors.Instead of using the noisy converted treebank as ad-ditional training data, our approach allows the QG-676enhanced parsing models to softly learn the system-atic inconsistencies based on QG features, makingour approach simpler and more robust.Our approach is also intuitively related to stackedlearning (SL), a machine learning framework thathas recently been applied to dependency parsingto integrate two main-stream parsing models, i.e.,graph-based and transition-based models (Nivre andMcDonald, 2008; Martins et al, 2008).
However,the SL framework trains two parsers on the sametreebank and therefore does not need to consider theproblem of annotation inconsistencies.3 Dependency ParsingGiven an input sentence x = w0w1...wn and its POStag sequence t = t0t1...tn, the goal of dependencyparsing is to build a dependency tree as depicted inFigure 1, denoted by d = {(h,m, l) : 0 ?
h ?n, 0 < m ?
n, l ?
L}, where (h,m, l) indicates andirected arc from the head word (also called father)wh to the modifier (also called child or dependent)wm with a dependency label l, and L is the label set.We omit the label l because we focus on unlabeleddependency parsing in the present paper.
The artifi-cial node w0, which always points to the root of thesentence, is used to simplify the formalizations.In the current research, we adopt the graph-basedparsing models for their state-of-the-art performancein a variety of languages.3 Graph-based modelsview the problem as finding the highest scoring treefrom a directed graph.
To guarantee the efficiency ofthe decoding algorithms, the score of a dependencytree is factored into the scores of some small parts(subtrees).Scorebs(x, t,d) = wbs ?
fbs(x, t,d)=?p?dwpart ?
fpart(x, t, p)where p is a scoring part which contains one or moredependencies of d, and fbs(.)
denotes the basic pars-ing features, as opposed to the QG features.
Figure2 lists the scoring parts used in our work, where g,h, m, and s, are word indices.We implement three parsing models of varyingstrengths in capturing features to better understandthe effect of the proposed QG features.3Our approach can equally be applied to transition-basedparsing models (Yamada and Matsumoto, 2003; Nivre, 2003)with minor modifications.dependency sibling grandparenthmhmshmgFigure 2: Scoring parts used in our graph-based parsingmodels.?
The first-order model (O1) only incorporatesdependency parts (McDonald et al, 2005), andrequires O(n3) parsing time.?
The second-order model using only siblingparts (O2sib) includes both dependency andsibling parts (McDonald and Pereira, 2006),and needs O(n3) parsing time.?
The second-order model (O2) uses all thescoring parts in Figure 2 (Koo and Collins,2010).
The time complexity of the decodingalgorithm is O(n4).4For the O2 model, the score function is rewritten as:Scorebs(x, t,d) =?
{(h,m)}?dwdep ?
fdep(x, t, h,m)+?
{(h,s),(h,m)}?dwsib ?
fsib(x, t, h, s,m)+?
{(g,h),(h,m)}?dwgrd ?
fgrd(x, t, g, h,m)where fdep(.
), fsib(.)
and fgrd(.)
correspond to thefeatures for the three kinds of scoring parts.
Weadopt the standard features following Li et al(2011).
For the O1 and O2sib models, the aboveformula is modified by deactivating the extra parts.4 Dependency Parsing with QG FeaturesSmith and Eisner (2006) propose the QG for ma-chine translation (MT) problems, allowing greatersyntactic divergences between the two languages.Given a source sentence x?
and its syntactic treed?, a QG defines a monolingual grammar that gen-erates translations of x?, which can be denoted byp(x,d,a|x?,d?
), where x and d refer to a translationand its parse, and a is a cross-language alignment.Under a QG, any portion of d can be aligned to any4We use the coarse-to-fine strategy to prune the searchspace, which largely accelerates the decoding procedure (Kooand Collins, 2010).677hmhmmhConsistent: 55.4% Reverse: 8.6%Sibling: 10.0%Grand: 11.7% Reverse-grand: 1.4%( ', , )dep d h m?
?
( ', , , )grd d g h m?
?
( ', , , )sib d h s m?
?imhihm28.2%imhhmshms6.7%imhshsim6.4%imsh4.9%smh4.4%msh4.2%hmghmg30.1% 6.5%hmg6.2%hmig6.1%imhgmhg5.4% 5.3%ihgmSyntactic Structures of the Corresponding Source SideTarget SideFigure 4: Most frequent transformation patterns (TPs) when using CDT as the source treebank and CTB5 as thetarget.
A TP comprises two syntactic structures, one in the source side and the other in the target side, and denotesthe process by which the left-side subtree is transformed into the right-side structure.
Functions ?dep(.
), ?sib(.
), and?grd(.)
return the specific TP type for a candidate scoring part according to the source tree d?.Source ParserParserSTarget ParserParserTTrainTrainParseTargetTreebankT={(xj, dj)}jSource TreebankS={(xi, di)}iParsedTreebankTS={(xj, djS)}jTarget Treebank withSource AnnotationsT+S={(xj, djS, dj)}jOutFigure 3: Framework of our approach.portion of d?, and the construction of d can be in-spired by arbitrary substructures of d?.
To date, QGshave been successfully applied to various tasks, suchas word alignment (Smith and Eisner, 2006), ma-chine translation (Gimpel and Smith, 2011), ques-tion answering (Wang et al, 2007), and sentencesimplification (Woodsend and Lapata, 2011).In the present work, we utilize the idea of the QGfor the exploitation of multiple monolingual tree-banks.
The key idea is to let the parse tree of onestyle inspire the parsing process of another style.Different from a MT process, our problem consid-ers one single sentence (x = x?
), and the alignmenta is trivial.
Figure 3 shows the framework of ourapproach.
First, we train a statistical parser on thesource treebank, which is called the source parser.The source parser is then used to parse the whole tar-get treebank.
At this point, the target treebank con-tains two sets of annotations, one conforming to thesource style, and the other conforming to the targetstyle.
During both the training and test phases, thetarget parser are inspired by the source annotations,and the score of a target dependency tree becomesScore(x, t,d?,d) =Scorebs(x, t,d)+Scoreqg(x, t,d?,d)The first part corresponds to the baseline model,whereas the second part is affected by the source treed?
and can be rewritten asScoreqg(x, t,d?,d) = wqg ?
fqg(x, t,d?,d)where fqg(.)
denotes the QG features.
We expect theQG features to encourage or penalize certain scor-ing parts in the target side according to the sourcetree d?.
Taking Figure 1 as an example, supposethat the upper structure is the target.
The targetparser can raise the score of the candidate depen-dence ?and?
?
?industry?, because the depen-678dency also appears in the source structure, and ev-idence in the training data shows that both annota-tion styles handle conjunctions in the same manner.Similarly, the parser may add weight to ?trade?
?
?industry?, considering that the reverse arc is inthe source structure.
Therefore, the QG-enhancedmodel must learn the systematic consistencies andinconsistencies from the training data.To model such consistency or inconsistency sys-tematicness, we propose the use of TPs for encodingthe structural correspondence between the sourceand target styles.
Figure 4 presents the three kindsof TPs used in our model, which correspond to thethree scoring parts of our parsing models.Dependency TPs shown in the first row considerhow one dependency in the target side is trans-formed in the source annotations.
We only considerthe five cases shown in the figure.
The percentagesin the lower boxes refer to the proportion of thecorresponding pattern, which are counted from thetraining data of the target treebank with source anno-tations T+S .
We can see that the noisy source struc-tures and the gold-standard target structures have55.4% common dependencies.
If the source struc-ture does not belong to any of the listed five cases,?dep(d?, h,m) returns ?else?
(12.9%).
We couldconsider more complex structures, such as h beingthe grand grand father of m, but statistics show thatmore complex transformations become very scarcein the training data.For the reason that dependency TPs can onlymodel how one dependency in the target structure istransformed, we consider more complex transforma-tions for the other two kinds of scoring parts of thetarget parser, i.e., the sibling and grand TPs shownin the bottom two rows.
We only use high-frequencyTPs of a proportion larger than 1.0%, aggregate oth-ers as ?else?, which leaves us with 21 sibling TPsand 22 grand TPs.Based on these TPs, we propose the QG fea-tures for enhancing the baseline parsing models,which are shown in Table 2.
The type of theTP is conjoined with the related words and POStags, such that the QG-enhanced parsing models canmake more elaborate decisions based on the context.Then, the score contributed by the QG features canbe redefined asScoreqg(x, t,d?,d) =?
{(h,m)}?dwqg-dep ?
fqg-dep(x, t,d?, h,m)+?
{(h,s),(h,m)}?dwqg-sib ?
fqg-sib(x, t,d?, h, s,m)+?
{(g,h),(h,m)}?dwqg-grd ?
fqg-grd(x, t,d?, g, h,m)which resembles the baseline model and can be nat-urally handled by the decoding algorithms.5 Experiments and AnalysisWe use the CDT as the source treebank (Liu etal., 2006).
CDT consists of 60,000 sentences fromthe People?s Daily in 1990s.
For the target tree-bank, we use two widely used versions of Penn Chi-nese Treebank, i.e., CTB5 and CTB6, which con-sist of Xinhua newswire, Hong Kong news and ar-ticles from Sinarama news magazine (Xue et al,2005).
To facilitate comparison with previous re-sults, we follow Zhang and Clark (2008b) for datasplit and constituency-to-dependency conversion ofCTB5.
CTB6 is used as the Chinese data set in theCoNLL 2009 shared task (Hajic?
et al, 2009).
There-fore, we adopt the same setting.CDT and CTB5/6 adopt different POS tag sets,and converting from one tag set to another is difficult(Niu et al, 2009).5 To overcome this problem, weuse the People?s Daily corpus (PD),6 a large-scalecorpus annotated with word segmentation and POStags, to train a statistical POS tagger.
The taggerproduces a universal layer of POS tags for both thesource and target treebanks.
Based on the commontags, the source parser projects the source annota-tions into the target treebanks.
PD comprises ap-proximately 300 thousand sentences of with approx-imately 7 million words from the first half of 1998of People?s Daily.Table 3 summarizes the data sets used in thepresent work.
CTB5X is the same with CTB5 butfollows the data split of Niu et al (2009).
We useCTB5X to compare our approach with their treebankconversion method (see Table 9).5The word segmentation standards of the two treebanks alsoslightly differs, which are not considered in this work.6http://icl.pku.edu.cn/icl_groups/corpustagging.asp679fqg-dep(x, t,d?, h,m) fqg-sib(x, t,d?, h, s,m) fqg-grd(x, t,d?, g, h,m)?dir(h,m) ?
dist(h,m) ?dir(h,m) ?dir(h,m) ?
dir(g, h)?dep(d?, h,m) ?
th ?
tm ?sib(d?, h, s,m) ?
th ?
ts ?
tm ?grd(d?, g, h,m) ?
tg ?
th ?
tm?dep(d?, h,m) ?
wh ?
tm ?sib(d?, h, s,m) ?
wh ?
ts ?
tm ?grd(d?, g, h,m) ?
wg ?
th ?
tm?dep(d?, h,m) ?
th ?
wm ?sib(d?, h, s,m) ?
th ?
ws ?
tm ?grd(d?, g, h,m) ?
tg ?
wh ?
tm?dep(d?, h,m) ?
wh ?
wm ?sib(d?, h, s,m) ?
th ?
ts ?
wm ?grd(d?, g, h,m) ?
tg ?
th ?
wm?sib(d?, h, s,m) ?
ts ?
tm ?grd(d?, g, h,m) ?
tg ?
tmTable 2: QG features used to enhance the baseline parsing models.
dir(h,m) denotes the direction of the dependency(h,m), whereas dist(h,m) is the distance |h ?m|.
?dir(h,m) ?
dist(h,m) indicates that the features listed in thecorresponding column are also conjoined with dir(h,m) ?
dist(h,m) to form new features.Corpus Train Dev TestPD 281,311 5,000 10,000CDT 55,500 1,500 3,000CTB5 16,091 803 1,910CTB5X 18,104 352 348CTB6 22,277 1,762 2,556Table 3: Data used in this work (in sentence number).We adopt unlabeled attachment score (UAS) asthe primary evaluation metric.
We also use Root ac-curacy (RA) and complete match rate (CM) to givemore insights.
All metrics exclude punctuation.
Weadopt Dan Bikel?s randomized parsing evaluationcomparator for significance test (Noreen, 1989).7For all models used in current work (POS taggingand parsing), we adopt averaged perceptron to trainthe feature weights (Collins, 2002).
We train eachmodel for 10 iterations and select the parameters thatperform best on the development set.5.1 PreliminariesThis subsection describes how we project the sourceannotations into the target treebanks.
First, we traina statistical POS tagger on the training set of PD,which we name TaggerPD .8 The tagging accuracyon the test set of PD is 98.30%.We then use TaggerPD to produce POS tags forall the treebanks (CDT, CTB5, and CTB6).Based on the common POS tags, we train asecond-order source parser (O2) on CDT, denotedby ParserCDT .
The UAS on CDT-test is 84.45%.We then use ParserCDT to parse CTB5 and CTB6.7http://www.cis.upenn.edu/[normal-wave?
]dbikel/software.html8We adopt the Chinese-oriented POS tagging features pro-posed in Zhang and Clark (2008a).Models without QG with QGO2 86.13 86.44 (+0.31, p = 0.06)O2sib 85.63 86.17 (+0.54, p = 0.003)O1 83.16 84.40 (+1.24, p < 10?5)Li11 86.18 ?Z&N11 86.00 ?Table 4: Parsing accuracy (UAS) comparison on CTB5-test with gold-standard POS tags.
Li11 refers to thesecond-order graph-based model of Li et al (2011),whereas Z&N11 is the feature-rich transition-basedmodel of Zhang and Nivre (2011).At this point, both CTB5 and CTB6 contain depen-dency structures conforming to the style of CDT.5.2 CTB5 as the Target TreebankTable 4 shows the results when the gold-standardPOS tags of CTB5 are adopted by the parsing mod-els.
We aim to analyze the efficacy of QG featuresunder the ideal scenario wherein the parsing mod-els suffer from no error propagation of POS tag-ging.
We determine that our baseline O2 modelachieves comparable accuracy with the state-of-the-art parsers.
We also find that QG features canboost the parsing accuracy by a large margin whenthe baseline parser is weak (O1).
The improve-ment shrinks for stronger baselines (O2sib and O2).This phenomenon is understandable.
When gold-standard POS tags are available, the baseline fea-tures are very reliable and the QG features becomesless helpful for more complex models.
The p-valuesin parentheses present the statistical significance ofthe improvements.We then turn to the more realistic scenariowherein the gold-standard POS tags of the targettreebank are unavailable.
We train a POS tagger onthe training set of CTB5 to produce the automatic680Models without QG with QGO2 79.67 81.04 (+1.37)O2sib 79.25 80.45 (+1.20)O1 76.73 79.04 (+2.31)Li11 joint 80.79 ?Li11 pipeline 79.29 ?Table 5: Parsing accuracy (UAS) comparison on CTB5-test with automatic POS tags.
The improvements shownin parentheses are all statistically significant (p < 10?5).Setting UAS CM RAfbs(.)
79.67 26.81 73.82fqg(.)
79.15 26.34 74.71fbs(.)
+ fqg(.)
81.04 29.63 77.17fbs(.)
+ fqg-dep(.)
80.82 28.80 76.28fbs(.)
+ fqg-sib(.)
80.86 28.48 76.18fbs(.)
+ fqg-grd(.)
80.88 28.90 76.34Table 6: Feature ablation for Parser-O2 on CTB5-testwith automatic POS tags.POS tags for the development and test sets of CTB5.The tagging accuracy is 93.88% on the test set.
Theautomatic POS tags of the training set are producedusing 10-fold cross-validation.9Table 5 shows the results.
We find that QG fea-tures result in a surprisingly large improvement overthe O1 baseline and can also boost the state-of-the-art parsing accuracy by a large margin.
Li etal.
(2011) show that a joint POS tagging and de-pendency parsing model can significantly improveparsing accuracy over a pipeline model.
Our QG-enhanced parser outperforms their best joint modelby 0.25%.
Moreover, the QG features can be used toenhance a joint model and achieve higher accuracy,which we leave as future work.5.3 Analysis Using Parser-O2 with AUTO-POSWe then try to gain more insights into the effect ofthe QG features through detailed analysis.
We se-lect the state-of-the-art O2 parser and focus on therealistic scenario with automatic POS tags.Table 6 compares the efficacy of different featuresets.
The first major row analyzes the efficacy of9We could use the POS tags produced by TaggerPD in Sec-tion 5.1, which however would make it difficult to compare ourresults with previous ones.
Moreover, inferior results may begained due to the differences between CTB5 and PD in wordsegmentation standards and text sources.the basic features fbs(.)
and the QG features fqg(.
).When using the few QG features in Table 2, the ac-curacy is very close to that when using the basicfeatures.
Moreover, using both features generatesa large improvement.
The second major row com-pares the efficacy of the three kinds of QG featurescorresponding to the three types of scoring parts.
Wecan see that the three feature sets are similarly effec-tive and yield comparable accuracies.
Combiningthese features generate an additional improvementof approximately 0.2%.
These results again demon-strate that all the proposed QG features are effective.Figure 5 describes how the performance varieswhen the scale of CTB5 and CDT changes.
Inthe left subfigure, the parsers are trained on partof the CTB5-train, and ?16?
indicates the use ofall the training instances.
Meanwhile, the sourceparser ParserCDT is trained on the whole CDT-train.
We can see that QG features render largerimprovement when the target treebank is of smallerscale, which is quite reasonable.
More importantly,the curves indicate that a QG-enhanced parsertrained on a target treebank of 16,000 sentencesmay achieve comparable accuracy with a base-line parser trained on a treebank that is doublethe size (32,000), which is very encouraging.In the right subfigure, the target treebank istrained on the whole CTB5-train, whereas the sourceparser is trained on part of the CDT-train, and ?55.5?indicates the use of all.
The curve clearly demon-strates that the QG features are more helpful whenthe source treebank gets larger, which can be ex-plained as follows.
A larger source treebank canteach a source parser of higher accuracy; then, thebetter source parser can parse the target treebankmore reliably; and finally, the target parser can betterlearn the annotation divergences based on QG fea-tures.
These results demonstrate the effectivenessand stability of our approach.Table 7 presents the detailed effect of the QG fea-tures on different dependency patterns.
A pattern?VV ?
NN?
refers to a right-directed dependencywith the head tagged as ?VV?
and the modifiertagged as ?NN?.
whereas ???
means left-directed.The ?w/o QG?
column shows the number of the cor-responding dependency pattern that appears in thegold-standard trees but misses in the results of thebaseline parser, whereas the signed figures in the?+QG?
column are the changes made by the QG-6817172737475767778798081821 2 4 8 16Training Set Size of CTB5w/o QGwith QG79.479.679.88080.280.480.680.88181.20 3 6 12 24 55.5Training Set Size of CDTwith QGFigure 5: Parsing accuracy (UAS) comparison on CTB5-test when the scale of CDT and CTB5 varies (thousandsin sentence number).Dependency w/o QG +QG DescriptionsNN?
NN 858 -78 noun modifier or coordinating nounsVV?
VV 777 -41 object clause or coordinating verbsVV?
VV 570 -38 subject clauseVV?
NN 509 -79 verb and its objectw0 ?
VV 357 -57 verb as sentence rootVV?
NN 328 -32 attributive clauseP?
VV 278 -37 preposition phrase attachmentVV?
DEC 233 -33 attributive clause and auxiliary DEP?
NN 175 -35 preposition and its objectTable 7: Detailed effect of QG features on different de-pendency patterns.enhanced parser.
We only list the patterns with anabsolute change larger than 30.
We find that the QGfeatures can significantly help a variety of depen-dency patterns (i.e., reducing the missing number).5.4 CTB6 as the Target TreebankWe use CTB6 as the target treebank to further verifythe efficacy of our approach.
Compared with CTB5,CTB6 is of larger scale and is converted into de-pendency structures according to finer-grained head-finding rules (Hajic?
et al, 2009).
We directly adoptthe same transformation patterns and features tunedon CTB5.
Table 8 shows results.
The improvementsare similar to those on CTB5, demonstrating that ourapproach is effective and robust.
We list the top threesystems of the CoNLL 2009 shared task in Table 8,showing that our approach also advances the state-of-the-art parsing accuracy on this data set.1010We reproduce their UASs using the data releasedby the organizer: http://ufal.mff.cuni.cz/conll2009-st/results/results.php.
The parsing accuracies of the top systems may beunderestimated since the accuracy of the provided POS tags inCoNLL 2009 is only 92.38% on the test set, while the POS tag-ger used in our experiments reaches 94.08%.Models without QG with QGO2 83.23 84.33 (+1.10)O2sib 82.87 84.11 (+1.37)O1 80.29 82.76 (+2.47)Bohnet (2009) 82.68 ?Che et al (2009) 82.11 ?Gesmundo et al (2009) 81.70 ?Table 8: Parsing accuracy (UAS) comparison on CTB6-test with automatic POS tags.
The improvements shownin parentheses are all statistically significant (p < 10?5).Models baseline with another treebankOurs 84.16 86.67 (+2.51)GP (Niu et al, 2009) 82.42 84.06 (+1.64)Table 9: Parsing accuracy (UAS) comparison on the testset of CTB5X.
Niu et al (2009) use the maximum en-tropy inspired generative parser (GP) of Charniak (2000)as their constituent parser.5.5 Comparison with Treebank ConversionAs discussed in Section 2, Niu et al (2009) automat-ically convert the dependency-structure CDT to thephrase-structure annotation style of CTB5X and usethe converted treebank as additional labeled data.We convert their phrase-structure results on CTB5X-test into dependency structures using the same head-finding rules.
To compare with their results, werun our baseline and QG-enhanced O2 parsers onCTB5X.
Table 9 presents the results.11 The indirectcomparison indicates that our approach can achievelarger improvement than their treebank conversionbased method.6 ConclusionsThe current paper proposes a simple and effectiveframework for exploiting multiple large-scale tree-banks of different annotation styles.
We designrich TPs to model the annotation inconsistencies andconsequently propose QG features based on theseTPs.
Extensive experiments show that our approachcan effectively utilize the syntactic knowledge fromanother treebank and significantly improve the state-of-the-art parsing accuracy.11We thank the authors for sharing their results.
Niu et al(2009) also use the reranker (RP) of Charniak and Johnson(2005) as a stronger baseline, but the results are missing.
Theyfind a less improvement on F score with RP than with GP (0.9%vs.
1.1%).
We refer to their Table 5 and 6 for details.682AcknowledgmentsThis work was supported by National NaturalScience Foundation of China (NSFC) via grant61133012, the National ?863?
Major Projects viagrant 2011AA01A207, and the National ?863?Leading Technology Research Project via grant2012AA011102.ReferencesMohit Bansal and Dan Klein.
2011.
Web-scale fea-tures for full-scale parsing.
In Proceedings of the49th Annual Meeting of the Association for Compu-tational Linguistics: Human Language Technologies,pages 693?702, Portland, Oregon, USA, June.
Associ-ation for Computational Linguistics.Bernd Bohnet.
2009.
Efficient parsing of syntacticand semantic dependency structures.
In Proceedingsof the Thirteenth Conference on Computational Natu-ral Language Learning (CoNLL 2009): Shared Task,pages 67?72, Boulder, Colorado, June.
Association forComputational Linguistics.David Burkett and Dan Klein.
2008.
Two languages arebetter than one (for syntactic parsing).
In Proceedingsof the 2008 Conference on Empirical Methods in Nat-ural Language Processing, pages 877?886, Honolulu,Hawaii, October.
Association for Computational Lin-guistics.David Burkett, Slav Petrov, John Blitzer, and Dan Klein.2010.
Learning better monolingual models with unan-notated bilingual text.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, CoNLL ?10, pages 46?54, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In Proceedings of ACL-05, pages 173?180.Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In ANLP?00, pages 132?139.Wanxiang Che, Zhenghua Li, Yongqiang Li, YuhangGuo, Bing Qin, and Ting Liu.
2009.
Multilingualdependency-based syntactic and semantic parsing.
InProceedings of CoNLL 2009: Shared Task, pages 49?54.Keh-Jiann Chen, Chi-Ching Luo, Ming-Chung Chang,Feng-Yi Chen, Chao-Jan Chen, Chu-Ren Huang, andZhao-Ming Gao, 2003.
Sinica treebank: Design crite-ria,representational issues and implementation, chap-ter 13, pages 231?248.
Kluwer Academic Publishers.Wenliang Chen, Jun?ichi Kazama, Kiyotaka Uchimoto,and Kentaro Torisawa.
2009.
Improving depen-dency parsing with subtrees from auto-parsed data.In Proceedings of the 2009 Conference on Empiri-cal Methods in Natural Language Processing, pages570?579, Singapore, August.
Association for Compu-tational Linguistics.Wenliang Chen, Jun?ichi Kazama, and Kentaro Torisawa.2010.
Bitext dependency parsing with bilingual sub-tree constraints.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, pages 21?29, Uppsala, Sweden, July.
Associationfor Computational Linguistics.Micheal Collins, Lance Ramshaw, Jan Hajic, andChristoph Tillmann.
1999.
A statistical parser forczech.
In ACL 1999, pages 505?512.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and experi-ments with perceptron algorithms.
In Proceedings ofEMNLP 2002.Andrea Gesmundo, James Henderson, Paola Merlo, andIvan Titov.
2009.
A latent variable model of syn-chronous syntactic-semantic parsing for multiple lan-guages.
In Proceedings of CoNLL 2009: Shared Task,pages 37?42.Kevin Gimpel and Noah A. Smith.
2011.
Quasi-synchronous phrase dependency grammars for ma-chine translation.
In Proceedings of the 2011 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 474?485, Edinburgh, Scotland, UK.,July.
Association for Computational Linguistics.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan ?Ste?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic dependen-cies in multiple languages.
In Proceedings of CoNLL2009.Liang Huang, Wenbin Jiang, and Qun Liu.
2009.Bilingually-constrained (monolingual) shift-reduceparsing.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing,pages 1222?1231, Singapore, August.
Association forComputational Linguistics.Wenbin Jiang, Liang Huang, and Qun Liu.
2009.
Au-tomatic adaptation of annotation standards: Chineseword segmentation and pos tagging ?
a case study.
InProceedings of the Joint Conference of the 47th An-nual Meeting of the ACL and the 4th InternationalJoint Conference on Natural Language Processing ofthe AFNLP, pages 522?530, Suntec, Singapore, Au-gust.
Association for Computational Linguistics.Terry Koo and Michael Collins.
2010.
Efficient third-order dependency parsers.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, pages 1?11, Uppsala, Sweden, July.
Asso-ciation for Computational Linguistics.683Terry Koo, Xavier Carreras, and Michael Collins.
2008.Simple semi-supervised dependency parsing.
In Pro-ceedings of ACL-08: HLT, pages 595?603, Columbus,Ohio, June.
Association for Computational Linguis-tics.Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-liang Chen, and Haizhou Li.
2011.
Joint modelsfor chinese pos tagging and dependency parsing.
InEMNLP 2011, pages 1180?1191.Ting Liu, Jinshan Ma, and Sheng Li.
2006.
Buildinga dependency treebank for improving Chinese parser.In Journal of Chinese Language and Computing, vol-ume 16, pages 207?224.Andr?
F. T. Martins, Dipanjan Das, Noah A. Smith, andEric P. Xing.
2008.
Stacking dependency parsers.
InEMNLP?08, pages 157?166.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing al-gorithms.
In Proceedings of EACL 2006.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of ACL 2005, pages 91?98.Zheng-Yu Niu, Haifeng Wang, and Hua Wu.
2009.
Ex-ploiting heterogeneous treebanks for parsing.
In Pro-ceedings of the Joint Conference of the 47th AnnualMeeting of the ACL and the 4th International JointConference on Natural Language Processing of theAFNLP, pages 46?54, Suntec, Singapore, August.
As-sociation for Computational Linguistics.Joakim Nivre and Ryan McDonald.
2008.
Integratinggraph-based and transition-based dependency parsers.In Proceedings of ACL 2008, pages 950?958.Joakim Nivre.
2003.
An efficient algorithm for pro-jective dependency parsing.
In Proceedings of the8th International Workshop on Parsing Technologies(IWPT), pages 149?160.Eric W. Noreen.
1989.
Computer-intensive methods fortesting hypotheses: An introduction.
John Wiley &Sons, Inc., New York.
Book (ISBN 0471611360 ).Zhou Qiang.
2004.
Annotation scheme for chinese tree-bank.
Journal of Chinese Information Processing,18(4):1?8.David Smith and Jason Eisner.
2006.
Quasi-synchronousgrammars: Alignment by soft projection of syntac-tic dependencies.
In Proceedings on the Workshopon Statistical Machine Translation, pages 23?30, NewYork City, June.
Association for Computational Lin-guistics.David A. Smith and Jason Eisner.
2009.
Parser adapta-tion and projection with quasi-synchronous grammarfeatures.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing,pages 822?831, Singapore, August.
Association forComputational Linguistics.Mengqiu Wang, Noah A. Smith, and Teruko Mita-mura.
2007.
What is the Jeopardy model?
a quasi-synchronous grammar for QA.
In Proceedings of the2007 Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL), pages 22?32,Prague, Czech Republic, June.
Association for Com-putational Linguistics.Kristian Woodsend and Mirella Lapata.
2011.
Learningto simplify sentences with quasi-synchronous gram-mar and integer programming.
In Proceedings ofthe 2011 Conference on Empirical Methods in Natu-ral Language Processing, pages 409?420, Edinburgh,Scotland, UK., July.
Association for ComputationalLinguistics.Fei Xia, Rajesh Bhatt, Owen Rambow, Martha Palmer,and Dipti Misra.
Sharma.
2008.
Towards a multi-representational treebank.
In In Proceedings of the 7thInternational Workshop on Treebanks and LinguisticTheories.Nianwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese Treebank: Phrasestructure annotation of a large corpus.
In Natural Lan-guage Engineering, volume 11, pages 207?238.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statisticaldependency analysis with support vector machines.
InProceedings of IWPT 2003, pages 195?206.Yue Zhang and Stephen Clark.
2008a.
Joint word seg-mentation and POS tagging using a single perceptron.In Proceedings of ACL-08: HLT, pages 888?896.Yue Zhang and Stephen Clark.
2008b.
A tale of twoparsers: Investigating and combining graph-based andtransition-based dependency parsing.
In Proceedingsof the 2008 Conference on Empirical Methods in Nat-ural Language Processing, pages 562?571, Honolulu,Hawaii, October.
Association for Computational Lin-guistics.Yue Zhang and Joakim Nivre.
2011.
Transition-baseddependency parsing with rich non-local features.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies, pages 188?193, Portland, Ore-gon, USA, June.
Association for Computational Lin-guistics.Guangyou Zhou, Jun Zhao, Kang Liu, and Li Cai.
2011.Exploiting web-derived selectional preference to im-prove statistical dependency parsing.
In Proceedingsof the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies, pages 1556?1565, Portland, Oregon, USA,June.
Association for Computational Linguistics.684
