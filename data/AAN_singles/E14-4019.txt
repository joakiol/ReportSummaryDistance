Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 95?99,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsChinese Native Language IdentificationShervin MalmasiCentre for Language TechnologyMacquarie UniversitySydney, NSW, Australiashervin.malmasi@mq.edu.auMark DrasCentre for Language TechnologyMacquarie UniversitySydney, NSW, Australiamark.dras@mq.edu.auAbstractWe present the first application of Na-tive Language Identification (NLI) to non-English data.
Motivated by theories of lan-guage transfer, NLI is the task of iden-tifying a writer?s native language (L1)based on their writings in a second lan-guage (the L2).
An NLI system was ap-plied to Chinese learner texts using topic-independent syntactic models to assesstheir accuracy.
We find that models usingpart-of-speech tags, context-free grammarproduction rules and function words arehighly effective, achieving a maximum ac-curacy of 71% .
Interestingly, we also findthat when applied to equivalent Englishdata, the model performance is almostidentical.
This finding suggests a sys-tematic pattern of cross-linguistic transfermay exist, where the degree of transfer isindependent of the L1 and L2.1 IntroductionNative Language Identification (NLI) is the task ofidentifying an author?s native language (L1) basedon their writings in a second language (the L2).NLI works by identifying language use patternsthat are common to groups of speakers that sharethe same native language.
This process is under-pinned by the presupposition that an author?s L1will dispose them towards particular language pro-duction patterns in their L2, as influenced by theirmother tongue.
This relates to Cross-LinguisticInfluence (CLI), a key topic in the field of SecondLanguage Acquisition (SLA) that analyzes trans-fer effects from the L1 on later learned languages(Ortega, 2009).While NLI has applications in security, most re-search has a strong linguistic motivation relating tolanguage teaching and learning.
Rising numbersof language learners have led to an increasing needfor language learning resources, which has in turnfuelled much of the language acquisition researchof the past decade.
In this context, by identify-ing L1-specific language usage and error patterns,NLI can be used to better understand SLA and de-velop teaching methods, instructions and learnerfeedback that is specific to their mother tongue.However, all of the NLI research to date has fo-cused exclusively on English L2 data.
To this endthere is a need to apply NLI to other languages,not only to gauge their applicability but also to aidin teaching research for other emerging languages.Interest in learning Chinese is rapidly growing,leading to increased research in Teaching Chineseas a Second Language (TCSL) and the develop-ment of related resources such as learner corpora(Chen et al., 2010).
The application of these toolsand scientific methods like NLI can greatly assistresearchers in creating effective teaching practicesand is an area of active research.The aim of this research is to evaluate the cross-language applicability of NLI techniques by ap-plying them to Chinese learner texts, evaluatingtheir efficacy and comparing the results with theirEnglish equivalents.To the best of our knowledge this is the firstreported application of NLI to non-English dataand we believe this is an important step in gain-ing deeper insights about the technique.2 Related WorkNLI is a fairly recent, but rapidly growing area ofresearch.
While some research was conducted inthe early 2000s, the most significant work has onlyappeared in the last few years (Wong and Dras,2009; Wong and Dras, 2011; Swanson and Char-niak, 2012; Tetreault et al., 2012; Bykh and Meur-ers, 2012).Most studies approach NLI as a multi-class su-pervised classification task.
In this experimentaldesign, the L1 metadata are used as class labels95and the individual writings are used as training andtesting data.
Using lexical and syntactic featuresof increasing sophistication, researchers have ob-tained good results under this paradigm.
While adetailed exposition of NLI has been omitted heredue to space constraints, a concise review can befound in Bykh and Meurers (2012).2.1 NLI 2013 Shared TaskThis increased interest brought unprecedentedlevel of research focus and momentum, resultingin the first NLI shared task being held in 2013.1The shared task aimed to facilitate the comparisonof results by providing a large NLI-specific datasetand evaluation procedure, to enable direct compar-ison of results achieved through different methods.Overall, the event was considered a success, draw-ing 29 entrants and experts from not only Compu-tational Linguistics, but also SLA.
The best teamsachieved accuracies of greater than 80% on this11-class classification task.
A detailed summaryof the results is presented in Tetreault et al.
(2013).3 DataGrowing interest has led to the recent develop-ment of the Chinese Learner Corpus (Wang et al.,2012), the first large-scale corpus of learner textscomprised of essays written by university stu-dents.
Learners from 59 countries are representedand proficiency levels have been sampled repre-sentatively across beginners, intermediate and ad-vanced learners.
However, texts by native speak-ers of other Asian countries are disproportionatelyrepresented, likely due to geographical proximity.For this work we extracted 3.75 million tokensof text from the CLC in the form of individualsentences.2Following the methodology of Brookeand Hirst (2011), we combine the sentences fromthe same L1 to form texts of 600 tokens on aver-age, creating a set of documents suitable for NLI3.We choose the top 11 languages, shown in Ta-ble 1, to use in our experiments.
This is due totwo considerations.
First, while many L1s are rep-resented in the corpus, most have relatively fewtexts.
Choosing the top 11 classes allows us to1Organised by the Educational Testing Service and co-located with the eighth instalment of the Building Ed-ucational Applications Workshop at NAACL/HLT 2013.sites.google.com/site/nlisharedtask2013/2Full texts are not made available, only individual sen-tences with the relevant metadata (proficiency/nationality).3Pending permission from the CLC corpus authors, wewill attempt to release the Chinese NLI dataset publicly.Language Size Language SizeFilipino FIL 415 Indonesian IND 402Thai THA 400 Laotian LAO 366Burmese MYA 349 Korean?KOR 330Khmer KHM 294 Vietnamese VIE 267Japanese?JAP 180 Spanish?SPA 112Mongolian MON 101Table 1: Our data, broken down by language andthe number of texts in each class.
Languages over-lapping with the TOEFL11 corpus marked with?.balance having a large number of classes, and alsomaximizes the amount of data used.
Secondly, thisis the same number of classes used in the NLI 2013shared task, enabling us to draw cross-languagecomparisons with the shared task results.4 Experimental SetupWe also follow the supervised classification ap-proach described in ?2.
We devise and run exper-iments using several models that capture differenttypes of linguistic information.
For each model,features are extracted from the texts and a clas-sifier is trained to predict the L1 labels using thefeatures.
As our data is not topic-balanced, weavoid using topic-dependent lexical features suchas character or word n-grams.Each experiment is run with two feature repre-sentations: binary (presence/absence of a feature)and normalized frequencies, where feature valuesare normalized to text length using the l2-norm.4.1 ParserThe Stanford CoreNLP4suite of NLP tools andthe provided Chinese models are used to tokenize,PoS tag and parse the unsegmented corpus texts.4.2 ClassifierWe use Support Vector Machines for classifica-tion.
Specifically, we use the LIBLINEAR SVMpackage (Fan et al., 2008) as it is well-suited totext classification tasks with large numbers of fea-tures and texts.
We use the L2-regularized L2-losssupport vector classification (dual) solver.4.3 EvaluationThe same evaluation metrics and standards used inthe NLI2013 Shared Task are used: we report clas-sification accuracy under 10-fold cross-validation.We also use the same number of classes as theshared task to facilitate comparative analyses.4http://nlp.stanford.edu/software/corenlp.shtml96Feature Accuracy (%)Binary FrequencyRandom Baseline 9.09 9.09PoS unigrams 20.12 35.32Part-of-Speech bigrams 32.83 54.24Part-of-Speech trigrams 47.24 55.60Function Words 43.93 51.91Production Rules 36.14 49.80All features 61.75 70.61Table 2: Chinese Native Language Identificationaccuracy (%) for all of our models.5 Experiments and Results5.1 Part-of-Speech tag n-gramsOur first experiment assesses the utility of thesyntactic information captured by part-of-speech(PoS) tags for Chinese NLI.
The PoS tags for eachtext are predicted and n-grams of size 1?3 are ex-tracted from the tags.
These n-grams capture (verylocal) syntactic patterns of language use and areused as classification features.The results for these three features, and ourother models are shown in Table 2.
The trigramfrequencies give the best accuracy of 55.60%, sug-gesting that there exist group-specific patterns ofChinese word order and category choice whichprovide a highly discriminative cue about the L1.5.2 Function WordsAs opposed to content words, function words aretopic-independent grammatical words that indi-cate the relations between other words.
Theyinclude determiners, conjunctions and auxiliaryverbs.
Distributions of English function wordshave been found to be useful in studies of author-ship attribution and NLI.
Unlike PoS tags, thismodel analyzes the author?s specific word choices.We compiled a list of 449 Chinese functionwords5to be used as features in this model.
Asshown in Table 2, the function word frequencyfeatures provide the best accuracy of 51.91%,significantly higher than the random baseline.This again suggests the presence of L1-specificgrammatical and lexical choice patterns that canhelp distinguish the L1, potentially due to cross-linguistic transfer.
Such lexical transfer effects5The function word list was compiled from Chinese lan-guage teaching resources.
The complete list can be accessedat http://comp.mq.edu.au/?madras/research/data/chinese-fw.txtROOTIPPU?VPVPIPVPVV??QPCLPM?CD?VE?PPNPNPNN??DPDT?
?P?NPPN?IP ?
NP VP PU VP ?
PP VPNP ?
DP NP PP ?
P NPFigure 1: A constituent parse tree for a sentencefrom the corpus along with some of the context-free grammar production rules extracted from it.have been previously noted by researchers andlinguists (Odlin, 1989).
These effects are medi-ated not only by cognates and similarities in wordforms, but also word semantics and meanings.5.3 Context-free Grammar Production RulesIn the next experiment we investigate the differ-ences in the distribution of the context-free gram-mar production rules used by the learners.
To dothis, constituent parses for all sentences are ob-tained and the production rules, excluding lexical-izations, are extracted.
Figure 1 shows a sampletree and rules.
These context-free phrase structurerules capture the overall structure of grammaticalconstructions and are used as classification fea-tures in this experiment.As seen in Table 2, the model achieves an accu-racy of 49.80%.
This supports the hypothesis thatthe syntactic substructures contain characteristicconstructions specific to L1 groups and that thesesyntactic cues strongly signal the writer?s L1.5.4 Combining All FeaturesFinally, we assess the redundancy of the informa-tion captured by our models by combining themall into one vector space to create a single clas-sifier.
From Table 2 we see that for each featurerepresentation, the combined feature results arehigher than the single best feature, with a max-97imum accuracy of 70.61%.
This demonstratesthat for at least some of the features, the informa-tion they capture is orthogonal and complemen-tary, and combining them can improve results.6 DiscussionA key finding here is that NLI models can be suc-cessfully applied to non-English data.
This is animportant step for furthering NLI research as thefield is still relatively young and many fundamen-tal questions have yet to be answered.All of the tested models are effective, and theyappear to be complementary as combining themimproves overall accuracy.
We also note the differ-ence in the efficacy of the feature representationsand see a clear preference for frequency-based fea-ture values.
Others have found that binary featuresare the most effective for English NLI (Brooke andHirst, 2012), but our results indicate frequency in-formation is more informative in this task.
Thecombination of both feature types has also beenreported to be effective (Malmasi et al., 2013).To see how these models perform across lan-guages, we also compare the results against theTOEFL11 corpus used in the NLI2013 sharedtask.
We perform the same experiments on thatdataset using the English CoreNLP models, PennTreebank PoS tagset and a set of 400 English func-tion words.
Figure 2 shows the results side by side.Remarkably, we see that the model resultsclosely mirror each other across corpora.
This is ahighly interesting finding from our study that mer-its further investigation.
There is a systematic pat-tern occurring across data from learners of com-pletely different L1-L2 pairs.
This suggests thatmanifestations of CLI via surface phenomena oc-cur at the same levels and patternings regardlessof the L2.
Cross-language studies can help re-searchers in linguistics and cognitive science tobetter understand the SLA process and languagetransfer effects.
They can enhance our understand-ing of how language is processed in the brain inways that are not possible by just studying mono-linguals or single L1-L2 pairs, thereby providingus with important insights that increase our knowl-edge and understanding of the human languagefaculty.One limitation of this work is the lack of sim-ilar amounts of training data for each language.However, many of the early and influential NLIstudies (e.g.
Koppel et al.
(2005), Tsur and Rap-poport (2007)) were performed under similar cir-PoS-1 PoS-2 PoS-3FW PR0204060Accuracy(%)Chinese EnglishFigure 2: Comparing feature performance on theChinese Learner Corpus and English TOEFL11corpora.
PoS-1/2/3: PoS uni/bi/trigrams, FW:Function Words, PR: Production Rulescumstances.
This issue was noted at the time, butdid not deter researchers as corpora with similarissues were used for many years.
Non-EnglishNLI is also at a similar state where the extant cor-pora are not optimal for the task, but no other al-ternatives exist for conducting this research.Finally, there are also a number of way to fur-ther develop this work.
Firstly, the experimentalscope could be expanded to use even more lin-guistically sophisticated features such as depen-dency parses.
Model accuracy could potentiallybe improved by using the metadata to developproficiency-segregated models.
Classifier ensem-bles could also help in increasing the accuracy.7 ConclusionIn this work we have presented the first applicationof NLI to non-English data.
Using the ChineseLearner Corpus, we compare models based onPoS tags, function words and context-free gram-mar production rules and find that they all yieldhigh classification accuracies.Comparing the models against an equivalentEnglish learner corpus we find that the accura-cies are almost identical across both L2s, suggest-ing a systematic pattern of cross-linguistic transferwhere the degree of transfer is independent of theL1 and L2.
Further research with other L2 learnercorpora is needed to investigate this phenomena.AcknowledgmentsWe wish to thank Associate Professor MaolinWang for providing access to the CLC corpus, andZhendong Zhao for his assistance.
We also thankthe reviewers for their constructive feedback.98ReferencesJulian Brooke and Graeme Hirst.
2011.
Na-tive language detection with ?cheap?
learner cor-pora.
In Conference of Learner Corpus Research(LCR2011), Louvain-la-Neuve, Belgium.
Pressesuniversitaires de Louvain.Julian Brooke and Graeme Hirst.
2012.
Robust, Lex-icalized Native Language Identification.
In Pro-ceedings of COLING 2012, pages 391?408, Mum-bai, India, December.
The COLING 2012 Organiz-ing Committee.Serhiy Bykh and Detmar Meurers.
2012.
Native Lan-guage Identification using Recurring n-grams ?
In-vestigating Abstraction and Domain Dependence.In Proceedings of COLING 2012, pages 425?440,Mumbai, India, December.
The COLING 2012 Or-ganizing Committee.Jianguo Chen, Chuang Wang, and Jinfa Cai.
2010.Teaching and learning Chinese: Issues and perspec-tives.
IAP.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.Moshe Koppel, Jonathan Schler, and Kfir Zigdon.2005.
Automatically determining an anonymous au-thor?s native language.
In Intelligence and SecurityInformatics, volume 3495 of LNCS, pages 209?217.Springer-Verlag.Shervin Malmasi, Sze-Meng Jojo Wong, and MarkDras.
2013.
Nli shared task 2013: Mq submission.In Proceedings of the Eighth Workshop on Innova-tive Use of NLP for Building Educational Applica-tions, pages 124?133, Atlanta, Georgia, June.
Asso-ciation for Computational Linguistics.Terence Odlin.
1989.
Language Transfer: Cross-linguistic Influence in Language Learning.
Cam-bridge University Press, Cambridge, UK.Lourdes Ortega.
2009.
Understanding Second Lan-guage Acquisition.
Hodder Education, Oxford, UK.Benjamin Swanson and Eugene Charniak.
2012.Native Language Detection with Tree SubstitutionGrammars.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguis-tics (Volume 2: Short Papers), pages 193?197, JejuIsland, Korea, July.
Association for ComputationalLinguistics.Joel Tetreault, Daniel Blanchard, Aoife Cahill, andMartin Chodorow.
2012.
Native tongues, lost andfound: Resources and empirical evaluations in na-tive language identification.
In Proceedings of COL-ING 2012, pages 2585?2602, Mumbai, India, De-cember.
The COLING 2012 Organizing Committee.Joel Tetreault, Daniel Blanchard, and Aoife Cahill.2013.
A report on the first native language identi-fication shared task.
In Proceedings of the EighthWorkshop on Innovative Use of NLP for Build-ing Educational Applications, pages 48?57, Atlanta,Georgia, June.
Association for Computational Lin-guistics.Oren Tsur and Ari Rappoport.
2007.
Using classifierfeatures for studying the effect of native languageon the choice of written second language words.
InProc.
Workshop on Cognitive Aspects of Computat.Language Acquisition, pages 9?16.Maolin Wang, Qi Gong, Jie Kuang, and Ziyu Xiong.2012.
The development of a chinese learner corpus.In Speech Database and Assessments (Oriental CO-COSDA), 2012 International Conference on, pages1?6.
IEEE.Sze-Meng Jojo Wong and Mark Dras.
2009.
Con-trastive Analysis and Native Language Identifica-tion.
In Proceedings of the Australasian LanguageTechnology Association Workshop 2009, pages 53?61, Sydney, Australia, December.Sze-Meng Jojo Wong and Mark Dras.
2011.
Exploit-ing Parse Structures for Native Language Identifi-cation.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Process-ing, pages 1600?1610, Edinburgh, Scotland, UK.,July.
Association for Computational Linguistics.99
