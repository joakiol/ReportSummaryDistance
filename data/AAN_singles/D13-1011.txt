Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 102?112,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsLearning to Freestyle: Hip Hop Challenge-Response Induction viaTransduction Rule SegmentationDekai Wu Karteek Addanki Markus Saers Meriem BeloucifHuman Language Technology CenterDepartment of Computer ScienceHKUST, Clear Water Bay, Hong Kong{dekai|vskaddanki|masaers|mbeloucif}@cs.ust.hkAbstractWe present a novel model, Freestyle, thatlearns to improvise rhyming and fluent re-sponses upon being challenged with a line ofhip hop lyrics, by combining both bottom-up token based rule induction and top-downrule segmentation strategies to learn a stochas-tic transduction grammar that simultaneouslylearns both phrasing and rhyming associations.In this attack on the woefully under-explorednatural language genre of music lyrics, weexploit a strictly unsupervised transductiongrammar induction approach.
Our task is par-ticularly ambitious in that no use of any a pri-ori linguistic or phonetic information is al-lowed, even though the domain of hip hoplyrics is particularly noisy and unstructured.We evaluate the performance of the learnedmodel against a model learned only usingthe more conventional bottom-up token basedrule induction, and demonstrate the superi-ority of our combined token based and rulesegmentation induction method toward gen-erating higher quality improvised responses,measured on fluency and rhyming criteria asjudged by human evaluators.
To highlightsome of the inherent challenges in adaptingother algorithms to this novel task, we alsocompare the quality of the responses generatedby our model to those generated by an out-of-the-box phrase based SMT system.
We tacklethe challenge of selecting appropriate trainingdata for our task via a dedicated rhyme schemedetection module, which is also acquired viaunsupervised learning and report improvedquality of the generated responses.
Finally,we report results with Maghrebi French hiphop lyrics indicating that our model performssurprisingly well with no special adaptation toother languages.1 IntroductionThe genre of lyrics in music has been severely under-studied from the perspective of computational lin-guistics despite being a form of language that hasperhaps had the most impact across almost all humancultures.
With the motivation of spurring further re-search in this genre, we apply stochastic transduc-tion grammar induction algorithms to address someof the modeling issues in song lyrics.
An ideal start-ing point for this investigation is hip hop, a genrethat emphasizes rapping, spoken or chanted rhyminglyrics against strong beats or simple melodies.
Hiphop lyrics, in contrast to poetry and other genres ofmusic, present a significant number of challenges forlearning as it lacks well-defined structure in terms ofrhyme scheme, meter, or overall meaning making itan interesting genre to bring to light some of the lessstudied modeling issues.The domain of hip hop lyrics is particularly un-structured when compared to classical poetry, a do-main on which statistical methods have been appliedin the past.
Hip hop lyrics are unstructured in thesense that a very high degree of variation is permit-ted in the meter of the lyrics, and large amounts ofcolloquial vocabulary and slang from the subcultureare employed.
The variance in the permitted me-ter makes it hard to make any assumptions aboutthe stress patterns of verses in order to identify therhyming words used when generating output.
Thebroad range of unorthodox vocabulary used in hiphop make it difficult to use off-the-shelf NLP toolsfor doing phonological and/or morphological analy-sis.
These problems are further exacerbated by dif-ferences in intonation of the same word and lack ofrobust transcription (Liberman, 2010).102We argue that stochastic transduction grammars,1given their success in the area of machine transla-tion and efficient unsupervised learning algorithms,are ideal for capturing the structural relationship be-tween lyrics.
Hence, our Freestyle system mod-els the problem of improvising a rhyming responsegiven any hip hop lyric challenge as transducinga challenge line into a rhyming response.
Weuse a stochastic transduction grammar induced ina completely unsupervised fashion using a combi-nation of token based rule induction and segment-ing (Saers et al 2013) as the underlying model tofully-automatically learn a challenge-response sys-tem and compare its performance against a simplertoken based transduction grammar model.
Both ourmodels are completely unsupervised and use no priorphonetic or linguistic knowledge whatsoever despitethe highly unstructured and noisy domain.We believe that the challenge-response systembased on an interpolated combination of token basedrule induction and rule segmenting transductiongrammars will generate more fluent and rhyming re-sponses compared to one based on token based trans-duction grammars models.
This is based on the ob-servation that token based transduction grammarssuffer from a lack of fluency; a consequence of thedegree of expressivity they permit.
Therefore, as aprincipal part of our investigation we compare thequality of responses generated using a combinationof token based rule induction and top-down rule seg-menting transduction grammars to those generatedby pure token based transduction grammars.We also hypothesize that in order to generate flu-ent and rhyming responses, it is not sufficient to trainthe transduction grammars on all adjacent lines of ahip hop verse.
Therefore, we propose a data selec-tion scheme using a rhyme scheme detector acquiredthrough unsupervised learning to generate the train-ing data for the challenge-response systems.
Therhyme scheme detector segments each verse of a hiphop song into stanzas and identifies the lines in eachstanza that rhyme with each other which are thenadded as training instances.
We demonstrate the su-periority of our training data selection method bycomparing the quality of the responses generated bythe models trained on data selected with and without1Also known in SMT as ?synchronous grammars?.using the rhyme scheme detector.Unlike conventional spoken and written language,disfluencies and backing vocals2 occur very fre-quently in the domain of hip hop lyrics which af-fect the performance of NLP models designed forprocessing well-formed sentences.
We propose twostrategies to mitigate the effect of disfluencies on ourmodel performance and compare their efficacy usinghuman evaluations.
Finally, in order to illustrate thechallenges faced by other NLP algorithms, we con-trast the performance of our model against a conven-tional, widely used phrase-based SMT model.A brief terminological note: ?stanza?
and ?verse?are frequently confused and sometimes conflated.Worse yet, their usage for song lyrics is often con-tradictory to that for poetry.
To avoid ambiguitywe consistently follow these technical definitions forsegments in decreasing size of granularity:verse a large unit of a song?s lyrics.
A song typi-cally contains several verses interspersed withchoruses.
In the present work, we do not differ-entiate choruses from verses.
In song lyrics, averse is most commonly represented as a sepa-rate paragraph.stanza a segment within a verse which has a me-ter and rhyme scheme.
Stanzas often consist of2, 3, or 4 lines, but stanzas of more lines arealso common.
Particularly in hip hop, a singleverse often contains many stanzas with differ-ent rhyme schemes and meters.line a segment within a stanza consisting of a singleline.
In poetry, strictly speaking this would becalled a ?verse?, which however conflicts withthe conventional use of ?verse?
in song lyrics.In Section 2, we discuss some of the previouswork that applies statistical NLP methods to lessconventional domains and problems.
We describeour experimental conditions in Section 3.
We com-pare the performance of token and segment basedtransduction grammar models in Section 4.
We com-pare our data selection schemes and disfluency han-dling strategies in Sections 5 and 6.
Finally, in2Particularly the repetitive chants, exclamations, and inter-jections in hip hop ?hype man?
style backing vocals.103Section 7 we describe some preliminary results ob-tained using our approach on improvising hip hopresponses in French and conclude in Section 8.2 Related workAlthough a few attempts have been made to applystatistical NLP learning methods to unconventionaldomains, Freestyle is among the first to tackle thegenre of hip hop lyrics (Addanki and Wu, 2013; Wuet al 2013a,b).
Our preliminary work suggested theneed for further research to identify models that cap-ture the correct generalizations to be able to gener-ate fluent and rhyming responses.
As a step towardsthis direction, we contrast the performance of inter-polated bottom-up token based rule induction andtop-down segmenting transduction grammar modelsand token based transduction grammar models.
Webriefly describe some of the past work in statisticalNLP on unconventional domains below.Most of the past work either uses some form ofprior linguistic knowledge or enforces harsher con-straints such as set number of words in a line, or a setmeter which are warranted by more structured do-mains such as poetry.
However, in hip hop lyrics itis hard to make any linguistic or structural assump-tions.
For example, words such as sho, flo, hollawhich frequently appear in the lyrics are not part ofany standard lexicon and hip hop does not require aset number of syllables in a line, unlike poems.
Also,surprising and unlikely rhymes in hip hop are fre-quently achieved via intonation and assonance, mak-ing it hard to apply prior phonological constraints.A phrase based SMT systemwas trained to ?trans-late?
the first line of a Chinese couplet or duilianinto the second by Jiang and Zhou (2008).
The mostsuitable next line was selected by applying linguisticconstraints to the n best output of the SMT system.However in contrast to Chinese couplets, which ad-here to strict rules requiring, for example, an identi-cal number of characters in each line and one-to-onecorrespondence in their metrical length, the domainof hip hop lyrics is far more unstructured and thereexists no clear constraint that would ensure fluentand rhyming responses to hip hop challenge lyrics.Barbieri et al(2012) use controlled Markov pro-cesses to semi-automatically generate lyrics that sat-isfy the structural constraints of rhyme and meter.Tamil lyrics were automatically generated given amelody using conditional random fields by A. et al(2009).
The lyrics were represented as a sequenceof labels using the KNM system where K, N and Mrepresented the long vowels, short vowels and con-sonants respectively.Genzel et al(2010) used SMT in conjunctionwith stress patterns and rhymes found in a pronun-ciation dictionary to produce translations of poems.Although many constraints were applied in translat-ing full verses of poems, it was challenging to sat-isfy all the constraints.
Stress patterns were assignedto words given the meter of a line in Shakespeare?ssonnets by Greene et al(2010), which were thencombined with a language model to generate poems.Sonderegger (2011) attempted to infer the pronun-ciation of words in old English by identifying therhyming patterns using graph theory.
However, theirheuristic of clustering words with similar IPA end-ings resulted in large clusters of false positives suchas bloom and numb.
A language-independent gener-ative model for stanzas in poetry was proposed byReddy and Knight (2011) via which they could dis-cover rhyme schemes in French and English poetry.3 Experimental conditionsBefore introducing our Freestyle models, we firstdetail our experimental assumptions and the evalua-tion scheme under which the responses generated bydifferent models are compared against one another.We describe our training data as well as a phrase-based SMT (PBSMT) contrastive baseline.
We alsodefine the evaluation scheme used to compare the re-sponses of different systems on criteria of fluencyand rhyming.3.1 Training dataWe used freely available user generated hip hoplyrics on the Internet to provide training data for ourexperiments.
We collected approximately 52,000English hip hop song lyrics amounting to approxi-mately 800Mb of raw HTML content.
The data wascleaned by stripping HTML tags, metadata and nor-malized for special characters and case differences.The processed corpus contained 22 million tokenswith 260,000 verses and 2.7 million lines of hip hoplyrics.
As human evaluation using expert hip hop104listeners is expensive, a small subset of 85 lines waschosen as the test set to provide challenges for com-paring the quality of responses generated by differentsystems.3.2 Evaluation schemeThe performance of various Freestyle versionswas evaluated on the task of generating a improvisedfluent and rhyming response given a single line of ahip hop verse as a challenge.
The output of all thesystems on the test set was given to three indepen-dent frequent hip hop listeners for manual evalua-tion.
They were asked to evaluate the system out-puts according to fluency and the degree of rhyming.They were free to choose the tune to make the lyricsrhyme as the beats of the song were not used in thetraining data.
Each evaluator was asked to score theresponse of each system on the criterion of fluencyand rhyming as being good, acceptable or bad.3.3 Phrase-based SMT baselineIn order to evaluate the performance of an out-of-the-box phrase-based SMT (PBSMT) system towardthis novel task of generating rhyming and fluent re-sponses, a standard Moses baseline (Koehn et al2007) was also trained in order to compare its per-formance with our transduction grammar inductionmodel.
A 4-gram language model which was trainedon the entire training corpus using SRILM (Stolcke,2002) was used to generate responses in conjunctionwith the phrase-based translation model.
As no au-tomatic quality evaluation metrics exist for hip hopresponses analogous to BLEU for SMT, the modelweights cannot be tuned in conventional ways suchasMERT (Och, 2003).
Instead, a slightly higher thantypical language model weight was empirically cho-sen using a small development set to produce fluentoutputs.4 Interpolated segmenting model vs. tokenbased modelWe compare the performance of transduction gram-mars induced via interpolated token based and rulesegmenting (ISTG) versus token based transductiongrammars (TG) on the task of generating a rhymingand fluent response to hip hop challenges.
We usethe framework of stochastic transduction grammars,specifically bracketing ITGs (inversion transductiongrammars) (Wu, 1997), as our translation model for?transducing?
any given challenge into a rhymingand fluent response.
Our choice is motivated bythe significant amount of empirical evidence for therepresentational capacity of transduction grammarsacross a spectrum of natural language tasks such astextual entailment (Wu, 2006), mining parallel sen-tences (Wu and Fung, 2005) and machine translation(Zens and Ney, 2003).
Further, existence of effi-cient learning algorithms (Saers et al 2012; Saersand Wu, 2011) that make no language specific as-sumptions, make inversion transduction grammars asuitable framework for our modeling needs.
Exam-ples of lexical transduction rules can be seen in Ta-bles 3 and 5.
In addition, the grammar also includesstructural transduction rules for the straight caseA?
[A A] and also the inverted case A?
<A A>.4.1 Token based vs. segmental ITGsThe degenerate case of ITGs are token based ITGswherein each translation rule contains at most onetoken in input and output languages.
Efficient induc-tion algorithmswith polynomial run time exist for to-ken based ITGs and the expressivity they permit hasbeen empirically determined to capture most of theword alignments that occur across natural languages.The parameters of the token based ITGs can be es-timated using expectation maximization through anefficient dynamic programming algorithm in con-junction with beam pruning (Saers and Wu, 2011).In contrast to token based ITGs, each rule in a seg-mental ITG grammar can contain more than one to-ken in both input and output languages.
In machinetranslation applications, segmental models producetranslations that are more fluent as they can capturelexical knowledge at a phrasal level.
However, onlya handful of purely unsupervised algorithms existfor learning segmental ITGs under matched trainingand testing assumptions.
Most other approaches inSMT use a variety of ad hoc heuristics for extractingsegments from token alignments, justified purely byshort term improvements in automatic MT evalua-tion metrics such as BLEU (Papineni et al 2002)which cannot be transferred to our current task.
In-stead, we use a completely unsupervised learning al-gorithm for segmental ITGs that stays strictly withinthe transduction grammar optimization frameworkfor both training and testing as proposed in Saers105et al(2013).Saers et al(2013) induce a phrasal inversiontransduction grammar via interpolating the bottom-up rule chunking approach proposed in Saers et al(2012) with a top-down rule segmenting approachdriven by a minimum description length objectivefunction (Solomonoff, 1959; Rissanen, 1983) thattrades off the maximum likelihood against modelsize.
Saers et al(2013) report improvements inBLEU score (Papineni et al 2002) on their transla-tion task.
In our current approach instead of using abottom-up rule chunking approach we use a simplertoken based grammar instead.
Given two grammars(Ga and Gb) and an interpolation parameter ?
theprobability function of the interpolated grammar isgiven by:pa+b (r) = ?pa (r) + (1?
?
)pb (r)for all rules r in the union of the two rule sets, andwhere pa+b is the rule probability function of thecombined grammar and pa and pb are the rule prob-ability functions of Ga and Gb respectively.
Thepseudocode for the top-down rule segmenting algo-rithm is shown in 1.
The algorithm uses the methodscollect_biaffixes, eval_dl, sort_by_delta andmake_segmentations.
These methods collect all thebiaffixes in an ITG, evaluate the difference in de-scription length, sort candidates by these differences,and commit to a given set of candidates, respectively.The suitable interpolation parameter is chosen em-pirically based on the responses generated on a smalldevelopment set.We compare the performance of inducing a tokenbased ITG versus inducing a segmental ITG using in-terpolated bottom-up token based rule induction andtop-down rule segmentation.
To highlight some ofthe inherent challenges in adapting other algorithmsto this novel task, we also compare the quality of theresponses generated by our model to those generatedby an off-the-shelf phrase based SMT system.4.2 Decoding heuristicsWe use our in-house ITG decoder implemented ac-cording to the algorithm mentioned in Wu (1996)for the generating responses to challenges by decod-ing with the trained transduction grammars.
The de-coder uses a CKY-style parsing algorithm (Cocke,Algorithm 1 Iterative rule segmenting learningdriven by minimum description length.1: ?
?
The ITG being induced2: repeat3: ?sum ?
04: bs?
collect_biaffixes(?
)5: b?
?
[]6: for all b ?
bs do7: ?
?
eval_dl(b,?
)8: if ?
< 0 then9: b?
?
[b?, ?b, ??
]10: sort_by_delta(b?
)11: for all ?b, ??
?
b?
do12: ??
?
eval_dl(b,?
)13: if ??
< 0 then14: ??
make_segmentations(b,?
)15: ?sum ?
?sum + ?
?16: until ?sum ?
017: return ?1969) with cube pruning (Chiang, 2007).
The de-coder builds an efficient hypergraph structure whichis then scored using the induced grammar.
Thetrained transduction grammar model was decodedusing the 4-gram language model and the modelweights determined as described in 3.3.In our decoding algorithm, we restrict the reorder-ing to only be monotonic as we want to produce out-put that follows the same rhyming order of the chal-lenge.
Interleaved rhyming order is harder to evalu-ate without the larger context of the song and we donot address that problem in our current model.
Wealso penalize singleton rules to produce responses ofsimilar length as successive lines in a stanza are typ-ically of similar length.
Finally, we add a penalty toreflexive translation rules that map the same surfaceform to itself such as A ?
yo/yo.
We obtain theserules with a high probability due to the presence ofsentence pairs where both the input and output areidentical strings as many stanzas in our data containrepeated chorus lines.4.3 Results: Rule segmentation improvesresponsesResults in Table 1 indicate that the ISTG outperformsthe TG model towards the task of generating fluentand rhyming responses.
On the criterion of fluency,106Table 1: Percentage of ?good and ?acceptable (i.e., either good or acceptable) responses on fluency and rhymingcriteria.
PBSMT, TG and ISTG models trained using corpus generated from all adjacent lines in a verse.
PBSMT+RS,TG+RS, ISTG+RS are models trained on rhyme scheme based corpus selection strategy.
Disfluency correction strategywas used in all cases.model fluency (?good) fluency (?acceptable) rhyming (?good) rhyming (?acceptable)PBSMT 3.14% 4.70% 1.57% 4.31%TG 21.18% 54.51% 23.53% 39.21%ISTG 26.27% 57.64% 27.45% 48.23%PBSMT+RS 30.59% 43.53% 1.96% 9.02%TG+RS 34.12% 60.39% 20.00% 42.74%ISTG+RS 30.98% 61.18% 30.98% 53.72%Table 2: Transduction rules learned by ISTG model.transduction grammar rule log prob.A?
long/wrong -11.6747A?
rhyme/time -11.6604A?
felt bad/couldn't see what i really had -11.3196A?
matter what you say/leaving anyway -11.8792A?
arhythamatic/this rhythm is sick -12.3492the ISTGmodel produces a significantly higher frac-tion of sentences rated good (26.27% vs. 21.18%)and ?acceptable (57.64% vs. 54.51%).
Higher frac-tion of responses generated by the ISTG model arerated as good (27.45% vs. 23.53%) and ?acceptable(57.64% vs. 54.51%) compared to the TG model.Both TG and ISTG model perform significantly bet-ter than the PBSMT baseline.
Upon inspecting thelearned rules, we noticed that the ISTG models cap-ture rhyming correspondences both at the token andsegmental levels.
Table 2 shows some examplesof the transduction rules learned by ISTG grammartrained using rhyme scheme detection.5 Data selection via rhyme schemedetection vs. adjacent linesWe now compare two data selection approachesfor generating the training data for transductiongrammar induction via a rhyme scheme detectionmodule and choosing all adjacent lines in a verse.We also briefly describe the training of the rhymescheme detection module and determine the efficacyof our data selection scheme by training the ISTGmodel, TG model and the PBSMT baseline on train-ing data generated with and without employing therhyme scheme detection module.
As the rule seg-menting approach was intended to improve the flu-ency as opposed to the rhyming nature of the re-sponses, we only train the rule segmenting modelon the randomly chosen subset of all adjacent linesin the verse.
Further, adding adjacent lines as thetraining data to the segmenting model maintains thecontext of the responses generated thereby produc-ing higher quality responses.
The segmental trans-duction grammar model was combined with the to-ken based transduction grammar model trained ondata selected with and without using rhyme schemedetection model.5.1 Rhyme scheme detectionAlthough our approach adapts a transduction gram-mar induction model toward the problem of generat-ing fluent and rhyming hip hop responses, it wouldbe undesirable to train the model directly on all thesuccessive lines of the verses?as done by Jiang andZhou (2008)?due to variance in hip hop rhymingpatterns.
For example, adding successive lines of astanza which follows ABAB rhyme scheme as train-ing instances to the transduction grammar causes in-correct rhyme correspondences to be learned.
Thefact that a verse (which is usually represented asa separate paragraph) may contain multiple stanzasof varying length and rhyme schemes worsens thisproblem.
Adding all possible pairs of lines in a verseas training examples not only introduces a lot ofnoise but also explodes the size of the training datadue to the large size of the verse.We employ a rhyme scheme detection model (Ad-danki and Wu, 2013) in order to select training in-stances that are likely to rhyme.
Lines belonging to107the same stanza and marked as rhyming accordingto the rhyme scheme detection model are added tothe training corpus.
We believe that this data selec-tion scheme will improve the rhyming associationslearned during the transduction grammar inductionthereby biasing the model towards producing fluentand rhyming output.The rhyme scheme detection model proposes aHMM based generative model for a verse of hip hoplyrics similar to Reddy and Knight (2011).
However,owing to the lack of well-defined verse structure inhip hop, a number of hidden states corresponding tostanzas of varying length are used to automaticallyobtain a soft-segmentation of the verse.
Each statein the HMM corresponds to a stanza with a particu-lar rhyme scheme such asAA,ABAB,AAAAwhilethe emissions correspond to the final words in thestanza.
We restrict the maximum length of a stanzato be four to maintain a tractable number of statesand further only use states to represent stanzas whoserhyme schemes could not be partitioned into smallerschemes without losing a rhyme correspondence.The parameters of the HMM are estimated usingthe EM algorithm (Devijer, 1985) using the corpusgenerated by taking the final word of each line in thehip hop lyrics.
The lines from each stanza that rhymewith each other according to the Viterbi parse usingthe trained model are added as training instances fortransduction grammar induction.
As the source andtarget languages are identical, each selected pair gen-erates two training instances: a challenge-responseand a response-challenge pair.The training data for the rhyme scheme detectorwas obtained by extracting the end-of-line tokensfrom each verse.
However, upon data inspection wenoticed that shorter lines in hip hop stanzas are typi-cally joined with a comma and represented as a sin-gle line of text and hence all the tokens before thecommas were also added to the training corpus.
Weobtained a corpus containing 4.2 million tokens cor-responding to potential rhyming candidates compris-ing of around 153,000 unique token types.We evaluated the performance of our rhymescheme detector on the task of correctly labeling agiven verse with rhyme schemes.
As our model iscompletely unsupervised, we chose a random sam-ple of 75 verses from our training data as our test set.Two native English speakers who were frequent hiphop listeners were asked to partition the verse intostanzas and assign them with a gold standard rhymescheme.
Precision and recall were aggregated for theViterbi parse of each verse against this gold standardand f-score was calculated.
The rhyme scheme de-tection module employed in our data selection ob-tained a precision of 35.81% and a recall of 57.25%,giving an f-score of 44.06%.5.2 Training data selection via rhyme schemedetectionWe obtained around 600,000 training instances uponextracting a training corpus using rhyme scheme de-tection module as described in Section 5.1.
Weadded those lines that were adjacent and labeled asrhyming by the rhyme scheme detector as training in-stances resulting in a training corpus of size 200,000.5.3 Training data selection via adjacent linesConsidering all adjacent lines in a verse resulted ina corpus with over 5 million training instances.
Inorder to ensure fair comparison of models trainedon data selected using rhyme scheme detection, werandomly chose 200,000 training instances from thegenerated corpus.
The training corpus thus gener-ated shared around 15% of training instances withthe corpus generated through our proposed data se-lection scheme.5.4 Results: Rhyme scheme detection helpsResults in Table 1 indicate that using the rhymescheme detector for training data selection helpsproduce significantly more fluent responses com-pared to using adjacent lines.
A possible explana-tion for this could be that adding all adjacent lines astraining instances introduces a lot of noise into themodel which hurts the fluency of the responses gen-erated.
Also, the cumulative fraction of sentencesthat were labeled good or ?acceptable on the crite-rion of rhyming is larger when rhyme scheme detec-tion was used to generate the training data (althoughthe TG model trained on the corpus generated us-ing adjacent lines produces a higher percentage ofrhyming responses that were rated good).
Given thesignificantly higher rate of response fluency whenusing rhyme scheme detection, we argue that usingrhyme scheme detector for data selection is benefi-cial.108Table 3: English hip hop challenge-response examples.challenge man i die to see em all thun i just don't caretg+rs in the sky and me the in polla and the you theretg and the ride the me the and white the i the airpbsmt+rs man i live to see em all i just don't carechallenge did a twelve year bid in the streets and held it downtg+rs to the girls here kid the and to the thought the nowtg to the p's here did the a the i was the thepbsmt+rs did a year in the streets and it downchallenge oh i believe in yesterdaytg+rs can you see the daytg now you see the waypbsmt+rs oh i believe in tomorrowchallenge what would i dotg+rs just me and youtg and you and youpbsmt+rs what would you dochallenge cause you ain't going home till the early morntg+rs and the you this alone i i gotta ontg and i you my on the a home wepbsmt+rs cause you and your friends aint nothing butIt is also interesting to note from Table 1 thatISTG+RS performs better than TG+RS indicatingthat transduction grammar induced via interpolatingtoken based grammar and rule segmenting producesbetter responses than token based transduction gram-mar on both data selection schemes.
Although theaverage fraction of responses rated good on fluencyare slightly lower for ISTG+RS compared to TG+RS(34.12% vs. 30.98%), the fraction of responses rated?acceptable are higher (61.18% vs. 57.64%).
It isimportant to note that the fraction of sentences ratedgood and ?acceptable on rhyming are much largerfor ISTG+RS model.
Although the fluency of theresponses generated by PBSMT+RS drastically im-proves compared to PBSMT it still lags behind theTG+RS and ISTG+RS models on both fluency andrhyming.
The results in Table 1 confirm our hypoth-esis that off-the-shelf SMT systems are not guaran-teed to be effective on our novel task.5.5 Challenge-response examplesTable 3 shows some of the challenges and the cor-responding responses of PBSMT+RS, TG+RS andTG model.
While PBSMT+RS and TG+RS mod-els generate responses reflecting a high degree offluency, the output of the TG contains a lot of ar-ticles.
It is interesting to note that TG+RS producesresponses comparable to PBSMT+RS despite beinga token based transduction grammar.
However, PB-SMT tends to produce responses that are too simi-lar to the challenge.
Moreover, TG models produceresponses that indeed rhyme better (shown in bold-face).
In fact, TG tries to rhymewords not only at theend but also in middle of the lines, as our transduc-tion grammar model captures structural associationsmore effectively than the phrase-based model.6 Disfluency handling via disfluencycorrection and filteringIn this section, we compare the effect of two dis-fluency mitigating strategies on the quality of the re-sponses generated by the PBSMT baseline and tokenbased transduction grammar model with and withoutusing rhyme scheme detection.6.1 Correction vs. filteringError analysis of our initial runs showed a dis-turbingly high proportion of responses generated byour system that contained disfluencies with succes-sive repetitions of words such as the and I.
Upon in-spection of data we noticed that the training lyricsactually did contain such disfluencies and backingvocal lines, amounting to 10% of our training data.We therefore compared two alternative strategies totackle this problem.
The first strategy involved fil-tering out all lines from our training corpus whichcontained such disfluencies.
In the second strategy,we implemented a disfluency detection and correc-tion algorithm (for example, the the the, which fre-quently occurred in the training corpus, was cor-rected to simply the).
The PBSMT baseline and theTG model were trained on both the filtered and cor-rected versions of the training corpus and the qualityof the responses were compared.6.2 Results: Disfluency correction helpsThe results in Table 4 indicate that the disfluencycorrection strategy outperforms the filtering strategyfor both TG and TG+RS models.
For the modelTG+RS, disfluency correction generated 34.12%good responses in terms of fluency, while the filter-ing strategy produced only 28.63% good responses.Similarly for the model TG, disfluency correctionproduced 21.8% of responses with good fluency andthe filtering strategy produced only 17.25%.
Dis-fluency correction strategy produces higher fractionof responses with ?acceptable fluency compared tothe filtering strategy for both TG and TG+RS mod-els.
This result is not surprising, as harshly pruning109Table 4: Effect of the disfluency correction strategies on fluency of the responses generated for the TG inductionmodels vs PBSMT baselines using both rhyme scheme detection and adjacent lines as the corpus selection method.model+disfluency strat.
fluency (good) fluency (?acceptable) rhyming (good) rhyming (?acceptable)PBSMT+filtering 4.3% 13.72% 3.53% 7.06%PBSMT+correction 3.14% 4.70% 1.57% 4.31%PBSMT+RS+filtering 31.76% 43.91% 12.15% 21.17%PBSMT+RS+correction 30.59% 43.53% 1.96% 9.02%TG+filtering 17.25% 46.27% 18.04% 33.33%TG+correction 21.18% 54.51% 23.53% 39.21%TG+RS+filtering 28.63% 56.86% 14.90% 34.51%TG+RS+correction 34.12% 60.39% 20.00% 42.74%the training corpus causes useful word associationinformation necessary for rhyming to be lost.
Sur-prisingly, for both PBSMT and PBSMT+RSmodels,the disfluency correction has a negative effect on thefluency level of the response but still falls behind TGand TG+RS models.
As disfluency correction yieldsmore fluent responses for TG and TG+RS models,the results for ISTG and ISTG+RS models in Table1 were obtained using disfluency correction strategy.7 Maghrebi French hip hopWe have begun to apply Freestyle to rap in lan-guages other than English, taking advantage ofthe language independence and linguistics-light ap-proach of our unsupervised transduction grammarinduction methods.
With no special adaption ourtransduction grammar based model performs sur-prisingly well, even with significantly smaller train-ing data size and noisier data.
These results acrossdifferent languages are encouraging as they can beused to discover truly language independence as-sumptions.
We briefly describe our initial experi-ments on Maghrebi French hip hop lyrics below.7.1 DatasetWe collected freely available French hip hop lyricsof approximately 1300 songs.
About 85% of thesongs were by Maghrebi French artists of Alge-rian, Moroccan, or Tunisian cultural backgrounds,while the remaining were by artists from the restof Francophonie.
As the large majority of songsare in Maghrebi French, the lyrics are sometimesinterspersed with romanized Arabic such as ?De latravers?e du d?sert au bon couscous de Y?ma?
(Y?mameansMy mother).
Some songs also contain Berberphrases, for instance ?a yemmi ino, a thizizwith?
(which means my son, a bee).
Furthermore, somesongs also contained English phrases in the style ofgangster rap such as ?T'es game over, game over... Leson de Chicken wings?.
As mentioned earlier, it iscomplexity like this which dissuaded us from mak-ing language specific assumptions in our model.We extracted the end-of-line words and obtaineda corpus containing 120,000 tokens correspondingto potential rhyming candidates with around 29,000unique token types which was used as the trainingdata for the rhyme scheme detector module.
For thetransduction grammar induction, the training datacontained about 47,000 sentence pairs selected us-ing rhyme scheme detection.7.2 ResultsAfter human evaluation by native French speak-ers and frequent hip hop listeners, our transductiongrammar based model generates about 9.2% and14.5% of the responses that are rated good by thehuman evaluators on the criterion of fluency andrhyming respectively.
About 30.2% and 38% ofthe responses are rated as ?acceptable.
These num-bers are encouraging given the noisy lyrics andmuchsmaller amount of training data.
Some examples ofthe challenge-response pairs and learned transduc-tion rules in French are shown in Tables 5 and 6.From Table 5, we can see that responses gener-ated by the system rhyme with the challenges.
Thefirst response is fluent and not only perfectly rhymeswith the challenge but also semantically valid.
In thesecond example, the model realizes a less commonAABA rhyme scheme through the response.
The re-110Table 5: French hip hop challenge-response examples.challenge Si je me tromperesponse faut que je racontechallenge Un jour je suis un livreresponse et ce que je de vivrechallenge Pacha mama ils ne voient pas ta souffranceresponse Combat ni leur de voulait de la d?cadencechallenge la palestine n'etait pas une terre sans peuple.response le darfour d'autre de la guerre on estchallenge Une banlieue qui meutresponse les yeux etTable 6: Transduction rules for Maghrebi French hip hop.transduction grammar rule log prob.A?
terre/la guerre -9.4837A?
haine/peine -9.77056A?
mal/pays natal -10.6877A?
je frissonne/mi corazon -11.0931A?
gratteurs/rappeurs -11.7306sponse in the third example, exhibits strong rhymingwith the challenge and both the challenge and theresponse contain words like souffrance, combat andd?cadence which are related.
Similarly in the fourthexample, the challenge and response also contain se-mantically related tokens which also rhyme.
Theseexamples illustrate that our transduction grammarformalism coupled with our rhyme scheme detectionmodule does capture the necessary correspondencesbetween lines of hip hop lyrics without assuming anylanguage specific resources.8 ConclusionWe presented a new machine learning approach forimprovising hip hop responses to challenge lyricsby inducing stochastic transduction grammars, anddemonstrated that inducing the transduction rules byinterpolating bottom-up token based rule inductionand rule segmentation strategies outperforms a tokenbased baseline.
We compared the performance ofour Freestylemodel against a widely used off-the-shelf phrase-based SMT model, showing that PB-SMT falls short in tackling the noisy and highly un-structured domain of hip hop lyrics.
We showed thatthe quality of responses improves when the trainingdata for the transduction grammar induction is se-lected using a rhyme scheme detector.
Several do-main related oddities such as disfluencies and back-ing vocals have been identified and some strategiesfor alleviating their effects have been compared.
Wealso reported results on Maghrebi French hip hoplyrics which indicate that our model works surpris-ingly well with no special adaptation for languagesother than English.
In the future, we plan to inves-tigate alternative training data selection techniques,disfluency handling strategies, search heuristics, andnovel transduction grammar induction models.AcknowledgementsThis material is based upon work supported in part bythe Hong Kong Research Grants Council (RGC) researchgrants GRF620811, GRF621008, GRF612806; by theDefense Advanced Research Projects Agency (DARPA)under BOLT contract no.
HR0011-12-C-0016, and GALEcontract nos.
HR0011-06-C-0022 and HR0011-06-C-0023; and by the European Union under the FP7 grantagreement no.
287658.
Any opinions, findings and con-clusions or recommendations expressed in this materialare those of the authors and do not necessarily reflect theviews of the RGC, EU, or DARPA.ReferencesAnanth Ramakrishnan A., Sankar Kuppan, andLalitha Devi Sobha.
?Automatic generation ofTamil lyrics for melodies.?
Workshop on Computa-tional Approaches to Linguistic Creativity (CALC-09).2009.Karteek Addanki and DekaiWu.
?Unsupervised rhymescheme identification in hip hop lyrics using hiddenMarkov models.?
1st International Conference on Sta-tistical Language and Speech Processing (SLSP 2013).2013.Gabriele Barbieri, Fran?ois Pachet, Pierre Roy, andMirko Degli Esposti.
?Markov constraints for gen-erating lyrics with style.?
20th European Conferenceon Artificial Intelligence, (ECAI 2012).
2012.David Chiang.
?Hierarchical phrase-based translation.
?Computational Linguistics, 33(2), 2007.John Cocke.
Programming languages and their compil-ers: Preliminary notes.
Courant Institute ofMathemat-ical Sciences, New York University, 1969.P.A.
Devijer.
?Baum?s forward-backward algorithm re-visited.?
Pattern Recognition Letters, 3(6), 1985.D.
Genzel, J. Uszkoreit, and F. Och.
?Poetic statisti-cal machine translation: rhyme and meter.?
2010 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP 2010).
Association for Computa-tional Linguistics, 2010.E.
Greene, T. Bodrumlu, and K. Knight.
?Auto-matic analysis of rhythmic poetry with applications111to generation and translation.?
2010 Conference onEmpirical Methods in Natural Language Processing(EMNLP 2010).
Association for Computational Lin-guistics, 2010.Long Jiang and Ming Zhou.
?Generating Chinesecouplets using a statistical MT approach.?
22nd In-ternational Conference on Computational Linguistics(COLING 2008).
2008.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, and Evan Herbst.
?Moses:Open source toolkit for statistical machine translation.
?Interactive Poster and Demonstration Sessions of the45th Annual Meeting of the Association for Computa-tional Linguistics (ACL 2007).
June 2007.MarkLiberman.
?Rap scholarship, rapmeter, and the an-thology of mondegreens.?
http://languagelog.ldc.upenn.edu/nll/?p=2824, December 2010.
Accessed:2013-06-30.Franz Josef Och.
?Minimum error rate training in sta-tistical machine translation.?
41st Annual Meeting ofthe Association for Computational Linguistics (ACL-2003).
July 2003.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
?BLEU: a method for automatic evalu-ation of machine translation.?
40th Annual Meeting ofthe Association for Computational Linguistics (ACL-02).
July 2002.S.
Reddy and K. Knight.
?Unsupervised discovery ofrhyme schemes.?
49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies (ACL HLT 2011), vol.
2.
Association forComputational Linguistics, 2011.Jorma Rissanen.
?A universal prior for integers and es-timation by minimum description length.?
The Annalsof Statistics, 11(2), June 1983.Markus Saers, KarteekAddanki, andDekaiWu.
?Fromfinite-state to inversion transductions: Toward un-supervised bilingual grammar induction.?
24th In-ternational Conference on Computational Linguistics(COLING 2012).
December 2012.Markus Saers, Karteek Addanki, and Dekai Wu.
?Combining top-down and bottom-up search for un-supervised induction of transduction grammars.?
Sev-enth Workshop on Syntax, Semantics and Structure inStatistical Translation (SSST-7).
June 2013.Markus Saers and Dekai Wu.
?Reestimation of reifiedrules in semiring parsing and biparsing.?
Fifth Work-shop on Syntax, Semantics and Structure in StatisticalTranslation (SSST-5).
Association for ComputationalLinguistics, June 2011.Ray J. Solomonoff.
?A new method for discov-ering the grammars of phrase structure languages.
?International Federation for Information ProcessingCongress (IFIP).
1959.M.
Sonderegger.
?Applications of graph theory to anEnglish rhyming corpus.?
Computer Speech & Lan-guage, 25(3), 2011.Andreas Stolcke.
?SRILM ?
an extensible languagemodeling toolkit.?
7th International Conference onSpoken Language Processing (ICSLP2002 - INTER-SPEECH 2002).
September 2002.Dekai Wu.
?A polynomial-time algorithm for statisti-cal machine translation.?
34th Annual Meeting of theAssociation for Computational Linguistics (ACL96).1996.DekaiWu.
?Stochastic inversion transduction grammarsand bilingual parsing of parallel corpora.?
Computa-tional Linguistics, 23(3), 1997.Dekai Wu.
?Textual entailment recognition using inver-sion transduction grammars.?
Joaquin Qui?onero-Candela, Ido Dagan, Bernardo Magnini, and Flo-rence d?Alch?
Buc (eds.
),Machine Learning Chal-lenges, Evaluating Predictive Uncertainty, Visual Ob-ject Classification and Recognizing Textual Entail-ment, First PASCAL Machine Learning ChallengesWorkshop (MLCW 2005), vol.
3944 of Lecture Notesin Computer Science.
Springer, 2006.Dekai Wu, Karteek Addanki, and Markus Saers.
?FREESTYLE: A challenge-response system for hiphop lyrics via unsupervised induction of stochastictransduction grammars.?
14th Annual Conference ofthe International Speech Communication Association(Interspeech 2013).
2013a.Dekai Wu, Karteek Addanki, and Markus Saers.
?Modeling hip hop challenge-response lyrics as ma-chine translation.?
14th Machine Translation Summit(MT Summit XIV).
2013b.Dekai Wu and Pascale Fung.
?Inversion transduc-tion grammar constraints for mining parallel sentencesfrom quasi-comparable corpora.?
Second Interna-tional Joint Conference on Natural Language Process-ing (IJCNLP 2005).
Springer, 2005.Richard Zens and HermannNey.
?A comparative studyon reordering constraints in statistical machine trans-lation.?
41st Annual Meeting of the Association forComputational Linguistics (ACL-2003).
Associationfor Computational Linguistics, 2003.112
