Probabil ist ic Coreference in InformationAndrew Keh lerSRI International333 Ravenswood AvenueMenlo Park, CA 94025kehler@ai.sri.comExtract ionAbst ractCertain applications require that the out-put of an information extraction system beprobabilistic, so that a downstream sys-tem can reliably .fuse the output with pos-sibly contradictory information from othersources.
In this paper we consider theproblem of assigning a probability distri-bution to alternative sets of coreference r -lationships among entity descriptions.
Wepresent the results of initial experimentswith several approaches to estimating suchdistributions in an application using SRI'sFASTUS information extraction system.1 I n t roduct ionNatural language information extraction (IE) sys-tems take texts containing natural anguage as inputand produce database templates populated with in-formation that is relevant to a particular application.These records may be fed as input to a downstreamsystem for which the IE system is only one of sev-eral sources of information.
In such a scenario, thedownstream system must .fuse the incoming informa-tion from each of its sources, requiring the resolutionof conflicts.
To accomplish this, the fusion systemmust know the reliability of the information receivedfrom each source; in this way unreliable informationfrom one source can be disregarded in favor of highlyreliable information from another.Figure 1 exhibits this scenario with a typical IEsystem such as SRI's FASTUS system (Hobbs et al,1996).
The IE system has two components.
The firstcomponent consists of a series of phases that recog-nize domain-relevant patterns in the text and createtemplates representing event and entity descriptionsfrom them.
The second component merges tem-plates created from different phrases in the text thatoverlap in reference.
The resulting set of templatesconstitutes a formal description of the state of af-fairs as described in the text with respect to theapplication specification, which is then fed to thedownstream system.As part of determining this state of affairs, theIE system must create templates describing the rel-evant entities that are reported on.
This requiresdetermining when two or more templates describethe same entity, as templates created from corefer-ring phrases need to be merged.
We have performedan informal study of FASTUS's processing of a setof texts which indicates that the merging phase iswhere most of the ambiguities (as well as most ofthe errors) lie.
However, most IE systems, includingFASTUS, have pursued a deterministic strategy formerging and report only a single possible state ofaffairs.
This limitation makes it difficult for a down-stream system to fuse the information with possiblycontradictory information from other sources, as noinformation about the IE system's certainty of theresults is passed along, nor is information about pos-sible alternative states of affairs and their associatedlevels of certainty.In this paper, we consider the problem of assign-ing a probability distribution to alternative sets ofcoreference r lationships among entity descriptions.We present he results of initial experiments withseveral approaches to estimating such distributionsin an application using FASTUS.2 Overv iew o f  the  Prob lemLet us consider an example text of the sort that weencounter in our application: 11The texts in our application are messages consistingof free text, possibly interspersed with formatted tablesor charts which themselves may contain atural languagefragments that require analysis.
While this example isshorter than most texts in our corpus, the relevant freetext portions of the messages are typically no longer thana few paragraphs.
The style displayed in this example isfairly typical, although in some cases the sentence struc-163NL TextINFORMATIONSOURCEI INFORMATION EXTRACTIONPATTERN \] ~\[ TEMPLATE\]RECOGNITION\[-'--"\] MERGING \[INFORMATION ~SOURCEDOWNSTREAMPROCESSINGFigure 1: A Scenario Employing an Information Extraction SystemSub j: Kinston Military Rail DepotA rail depot was found 100 km southwestof the capitol of Raleigh, consisting of ex-tensive admin and support areas (similarto the ammunition depot in Fairview), twomaterial storage areas, extensive transship-ment facilities (some of which are underconstruction immediately east of the de-pot), and several training areas.We focus on the four mentions of depots in thetext, which are highlighted with italics.
The pat-tern matching phases of FASTUS produce templatessimilar to those shown in Figure 2.FACILITY DEPOTNUMBER 1LOCATION KINSTONTYPE RAILFACILITY DEPOT -NUMBER 1TYPE RAILTemplate A Template BFACILITY DEPOTNUMBER 1LOCATION FAIRVIEWTYPE AMMUNITIONFACILITY 1DEPOT \]NUMBERTemplate C Template DFigure 2: Templates Representing Depots Men-tionedWe will refer to a set of templates that have po-tential coreference relationships among them as ature is more telegraphic.coreference set, 2 and possible partitions of corefer-ential templates in the set as coreference configura-tions.
In the coreference set containing templatesA, B, C, and D, system knowledge xternal to theprobabilistic model indicates that the type Ammuni-tion in template C is not compatible with the typeRail in A and B; therefore these are taken a pri-ori to be non-coreferential.
Given these incompati-bilities, seven possible coreference configurations re-main.
Template names grouped within parenthesesare taken to be mutually coreferring; we will refer tosuch a grouping as a cell of the coreference configu-ration.1.
(A B D) (C) 5.
(B D) (A) (C)2.
(A B) (C D) 6.
(C D) (A) (S)3.
(hB)  (C) (D) 7.
(A) (S) (C) (D)4.
(A D) (B) (C)The first of these configurations expresses the correctcoreference r lationships for the example.Given a coreference s t of templates, possibly cou-pled with a list of template pairs known a priori notto corefer, the task is to assign a probability distri-bution over the possible coreference configurationsfor that set.Relat ionship to Past  Work While there havebeen previous investigations ofempirical approachesto coreference, these have generally centered on thetask of assigning correct referents for anaphor/c ex-pressions (Connolly, Burger, and Day, 1994; Aoneand Bennett, 1995; Lappin and Leass, 1994; Dagan2Templates A, B, C, and D constitute the only coref-erence set in this example, since none of the other NPs(e.g., the various "areas" mentioned) are compatiblewith any of the others.
In general, however, a text cangive rise to any number of distinct coreference s ts, eachof which will be assigned its own probability distribution.164and Itai, 1990; Dagan et al, 1995; Kennedy andBoguraev, 1996a; Kennedy and Boguraev, 1996b).The current ask deviates from that problem in sev-eral respects.
First, in our task, all coreference r -lationships among templates are modeled regardlessof the "referentiality" of the phrases that led to theircreation.
For instance, indefinites will sometimescorefer with a previously described entity; a typ-ical case is illustrated by the coreference betweenthe indefinite "a rail depot" and the depot intro-duced in the subject line in the example passage.Also, entities described with bare plurals are com-monly found to be coreferential with other entities,in addition to cases in which they have their morestandard generic meanings.
On the other hand, def-inite noun phrases are often not referential to itemsevoked in the text (e.g., "the ammunition depot inFairview").
Determining when such expressions arediscourse-anaphoric is part of the task; this informa-tion is generally not known to the system a priori.Second, the results of this task will be evaluatedby the probability assigned to the correct state ofaffairs with respect o an entire coreference s t, andnot by the number of correct antecedents assignedto anaphoric expressions.
Modeling at the level ofcoreference sets ensures that the probabilities areconsistent when considering the global state of af-fairs being described in the text.
Furthermore, therole of probabilities for this application goes beyondselecting the correct coreference r lationships - theprobability assigned to an alternative will be cen-tral in determining how the downstream system willweigh it against information from other sources dur-ing data fusion.
A system that assigns a probabilityof 0.9 to correct answers is more successful than onethat assigns a probability of 0.6 to them.The Limitations of  IE  Sys tems The propertiesof typical IE systems uch as FASTUS also make thistask challenging.
For one, successful modeling ofcoreference r lationships i hampered by the crude-ness of the representations used.
The templates thatare created are fairly shallow and may be incom-plete.
A reliance on detailed information about thecontext can prove detrimental if such informationis often missed by the system.
Also, FASTUS alsodoes not build up complex representations for thesyntax and semantics of sentences, placing limits onthe extent o which such information can be utilizedin determining coreference.
Lastly, there are the in-accuracies that result from processing real text.
Thepattern matching phases of FASTUS may intermit-tently misanalyze phrases that serve as antecedentsfor subsequent referring expressions.
Therefore, forexample, with respect to an identified coreferenceset, it may be correct o place a referential pronounin its own cell (implying that it does not corefer withanything), simply because system error caused itsantecedent ot to be included in the set.Out l ine  o f  the Approach The number of coref-erence configurations over which a distribution is tobe assigned epends on the number of templates inthe coreference s t, and the set of a priori constraintsagainst coreference between some of its members.
Asthere are many scenarios that will never be encoun-tered in a corpus of training data of any reasonablesize, it would be hopeless to attempt o estimate aconditional distribution for each possibility directly.To make matters worse, training data comes at acost, as keys have to be coded by hand.
One of thegoals of this effort is to allow the ability to train upprobabilities in new domains quickly, which requiresan approach that is successful with a limited amountof training data.However, it would be reasonable to expect thatwe have enough data to estimate distributions forcoreference sets with only two members.
This sug-gests a two-step approach.
First, we develop a gen-eral model of coreference b tween any two templates,and apply it to pairwise combinations of templatesin a given coreference s t without regard to the othertemplates in the set.
We then utilize a method forcombining the resulting probabilities to form a dis-tribution over all the possible coreference configura-tions.
We describe our method for modeling prob-abilities between pairs of templates in the next sec-tion, and describe two methods for deriving a dis-tribution over the coreference configurations in Sec-tion 4.
We report on an evaluation and comparisonof the approaches in Section 5.3 Training A Model for Pairs ofTemplatesOur first task is to derive a model for determiningthe probability that two templates corefer, condi-tioned on various characteristics of the context.
Forthis we employ an approach to maximum entropymodeling described by Berger et al (1996).Max imum Ent ropy  Mode l ing  Suppose we wishto model some random process, such as that whichdetermines coreference between two templates gen-erated by an IE system, based on various character-istics of the context hat influence this process, suchas the content of the templates themselves, the formof the natural anguage xpressions from which thetemplates were created, and the distance between165those expressions in the text.
We refer to the col-lection of such characteristics for a given example asits context x, and the value denoting the output ofthe process as y.
We can define a set of binary fea-tures that relate a possible value of a characteristicof x with a possible outcome y, i.e., whether the twotemplates corefer (y = 1) or not (y = 0).
For exam-ple, a feature fl(x, y) pairing the characteristic of Sand T having identical slot values with the outcomethat they corefer would be defined as follows.Binary  Feature  f l(x,Y):fl(x,y) = {1 if S and T have identicalslot values and S and T corefer0 otherwiseFrom these features we can define constraints onthe probabilistic model that is learned, in which weassume that the expected value of the feature withrespect o the distribution of the training data (Pd)holds with respect o the general model (Pro).Constra ints :pal(X, y)f(x, y) = ~ pd(x)pm (ylx)f(X, y)X,y X,yGiven that we have chosen a set of such constraintsto impose on our model, we wish to identify thatmodel which has the maximum entropy - this isthe model that assumes the least information be-yond those constraints.
Berger et al (1996) showthat this model is a member of an exponential familywith one parameter for each constraint, specificallya model of the form1 ~ I~ (x,~)p(yl ) = E 'in whichz(x) = eZ,YThe parameters A1, ..., An are Lagrange multipliersthat impose the constraints corresponding to thechosen features f l ,  ..-,fn- The term Z(x) normal-izes the probabilities by summing over all possibleoutcomes y. Berger et al (1996) demonstrate thatthe optimal values for the Ai's can be obtained bymaximizing the likelihood of the training data withrespect o the model, which can be performed usingtheir improved iterative scaling algorithm.In practice, we will not want to incorporate con-straints for all of the features that we might define,but only those that are most relevant and informa-tive.
Therefore, we use a procedure for selectingwhich of our pool of features hould be made active.At each iteration, the algorithm approximates thegain in the model's predictiveness that would resultfrom imposing the constraints corresponding to eachof the existing inactive features, and selects the onewith the highest anticipated payoff.
Upon makingthis feature active, the Ai's for all active features are(re)trained so that the constraints are all met simul-taneously.
The feature selection process is iterateduntil the approximate gain for all the remaining in-active features is negligible.Character is t ics  of  Context  for TemplateCoreference We now need a set of possible char-acteristics of context on which the algorithm couldchoose to conditionalize in deriving the probabilis-tic model.
For our initial experiments, we uti-lized a set of easily computable, but fairly crude,characteristics.
3 These characteristics fall into threecategories.
In what follows, we take S and T to bearbitrary templates where the natural language x-pression from which T was created appears later inthe text than the expression from which S was cre-ated.The first category relates to the contents of thetemplates themselves.
We model the relationshipbetween S and T as one of the following: S and Thave identical slot values, S is properly subsumed byT, S properly subsumes T, or S and T are otherwiseconsistent.
For instance, in our example in Section 2,template A is properly subsumed by template B, andA, B, and C are all properly subsumed by D, sincein each case the latter template is more general thanthe former.
We also have a binary characteristic forS and T having at least two (non-nil) slot valuesin common.
Finally, we have a characteristic formodeling when the values of the NAME slot of atemplate are both multi-worded and identical; thisis a crude heuristic for identifying matching uniqueidentifiers.The second category of characteristics relates tothe form of reference used in the expression fromwhich T was created, specifically whether it was de-3One could imagine a variety of more detailed andinformative characteristics of context than those usedhere.
However, in performing these experiments, we areinterested in how far we can get with a fairly simplestrategy that will port relatively easily to new domains,rather than relying heavily on information that is specificto our current domain.
A fairly coarse-grained set ofcharacteristics also allows us to restrict ourselves to arelatively small set of training data; likewise we will notwant to encode a large set of data for each new domain.166Template S Template T ProbabilityA B 0.671A D 0.505B D 0.752C D 0.504Table 1: Pairwise Probabilities for Example Coref-erence Setscribed with an indefinite phrase, a definite phrase(including pronouns), or neither of these (e.g., abare, non-pronominal noun phrase).
In the case ofdefinite expressions, we also consider the recommen-dations of a distinct coreference module within FAS-TUS.
We have a characteristic representing whetherthe potential antecedent is the preferred antecedent, 4a non-preferred, but possible antecedent, or not onthe list of possible antecedents.
5The final category of characteristics relates to thedistance in the text between the expressions fromwhich S and T were created, which we categorizeas being in one of five equivalence classes: veryclose, close, mid-distance, far away, and very faraway.
These distances are measured crudely (i.e.,by character length) so as not to be dependent onthe accuracy of methods for identifying more com-plex boundaries (e.g., clause, sentence, and discoursesegment boundaries).The results of training the maximum entropymodels are discussed in Section 5.
To illustrate theapproaches described in the next section, we will usethe probabilities for the templates from the examplepassage in Section 2, shown in Table 1, which wereproduced from the parameters induced from one ofthe training sets.4 In fe r r ing  a Mode l  fo r  Core ferenceSetsWe now have a method for obtaining a model thatassigns probabilities to the pairs of templates (hence-forth, "pairwise probabilities") in a coreference setthat can possibly corefer.
If there are only two tem-plates in the coreference s t, then we have the distri-4preferred reference is a transitive relation, that is,template S is treated as a preferred referent of templateT if there is a chain of preferred referents linking them,e.g., if there is a template R that is the preferred referentof T and template S is the preferred referent of R.5Although we do not model information about thesurface positions of the expressions from which S and Twere created within their respective sentences, the coref-erence module does take such information into accountin determining likely antecedents of definite xpressions.bution we seek.
However, if there are more than twotemplates, we must utilize the pairwise probabili-ties to derive a distribution over the members of theset of coreference configurations.
In the followingsections, we describe two approaches to recoveringsuch a distribution, followed by a description of twobaseline metrics.
An evaluation of these approachesis then given in Section 5.4.1 An Evidential Reasoning ApproachThe first approach we describe uses the pairwiseprobabilities as sources of evidence that inform thechoice of model for the coreference s ts.
The list ofcoreference configurations for our example passageare repeated below; we will refer to these configura-tions by their corresponding numbers.1.
(A B D) (C) 5.
(B D) (A) (C)2.
(A B) (C D) 6.
(C D) (A) (B)3.
(AB)  (C) (D) 7.
(A) (S) (C) (D)4.
(A D) (B) (C)We recast a probability that two templates S andT corefer as a mass distribution over two members ofthe power set of coreference configurations, namelythe set containing exactly those configurations inwhich S and T occupy the same cell, and the setcontaining those in which they do not.
For instance,the probability that A and B corefer was determinedto be 0.671; mapping this to corresponding sets ofcoreference configurations results in the mass distri-bution mAB in whichmAB({Configs 1, 2, 3}) = 0.671andmAB({Configs 4, 5, 6, 7}) = 0.329This mass distribution can be seen as representingthe beliefs of an observer who only has access totemplates A and B, and who is therefore ignorantabout their relationship to C and D. We can viewthe other pairwise probabilities for the coreferenceset in the same manner.In the best of all worlds, we might identify a modelthat is consistent with the mass distributions pro-vided by all the pairwise probabilities.
However,such a model may not, and often will not, exist.This is the case for the pairwise probabilities in ourexample, which can be seen most easily by consider-ing only templates A, C, and D. The probability ofA and D coreferring is 0.505 and of C and D corefer-ring is 0.504.
Because we know that A and C can-not corefer, the coreference configurations in whichA and D corefer and the configurations in which C167and D corefer are mutually exclusive.
Therefore,there would have to be a distribution that assigns0.505 of probability mass to a set of configurationsthat is mutually exclusive from a set that is assigned0.504 of probability mass.
Obviously, this cannot bedone with a set of probabilities that add up to 1.This inconsistency arises from the manner inwhich the pairwise probabilities are estimated.
Theprobability of coreference between templates itu-ated similarly to A and D may be 0.505 with re-spect to all contexts in the training data, howeverit is almost certainly not this high with respect othe subset of cases in which a template similar to Cis similarly situated.
The same reasoning applies tothe probability of C and D coreferring in light of theexistence of A.
Unfortunately, the existence of tem-plates other than the pair being modeled is the typeof conditional information for which we have littlehope of accounting in a general and statistically sig-nificant manner.Therefore, we may be left with a series of massdistributions defined over sets of coreference configu-rations that are in inherent conflict.
Instead of view-ing these distributions as constraints on the under-lying probabilistic model, we view them as sourcesof evidence.
The question is then how to take thesesources into account, given that they may be par-tially contradictory.
Dempster's Rule of Combina-tion (Dempster, 1968) provides a mechanism for do-ing this.
Dempster's rule combines two mass distri-butions m 1 and m 2 to form a third distribution m 3that represents he consensus of the original two dis-tributions; the new mass distribution in effect leanstoward the areas of agreement between the origi-nal distributions and away from points of conflict.Dempster's rule is defined as follows:1 E ml(Ai)m2(Aj) m3(Ak) - -  1 - -AinAj--Akin which~= E ml(Ai)m2(Aj)AiNAj----OThe Al in our case are members of the power set ofpossible coreference configurations.
In our exampleabove, mAB ass igns  probability mass to two suchAm, the set containing configurations 1, 2, and 3,and the set containing configurations 4, 5, 6, and 7.The value a is called the conflict between the massdistributions being combined; it provides a measureof the degree of disagreement between them.
When= 0, the original distributions are compatible;when ,?
= 1, they are in complete conflict and theresult is undefined.
When 0 < ,~ < 1, some conflictbetween the distributions exists; Dempster's rule hasthe effect of focusing on the agreement between thedistributions by eliminating the conflicting portionsand normalizing what remains.We can therefore use Dempster's Rule to resolvethe conflict between the pairwise probability distri-butions to generate a distribution over the coref-erence configurations.
Because we have pairwiseprobabilities for each possibly coreferring pair in thecoreference s t, it turns out that the Dempster solu-tion is more easily stated and computed here thanin the general case.
The solution is identical to theone that results when the probabilities of all the rele-vant pairwise relations (indicating either coreferenceor not) are multiplied, normalized by the amount ofprobability mass assigned to coreference configura-tions that are impossible because coreference is tran-sitive.
For instance, the probability for the corefer-ence configuration ((A B) (C)) is initially computedto be 6p(A =c B) * p(A ?c C) * p(B Pc C)However, using this method, impossible combina-tions (e.g., A =c B, B =c C, A?c  C) will also re-ceive positive probability mass.
If we normalize theprobabilities of possible combinations by distribut-ing the sum of the probability assigned to all im-possible combinations, the result is the same as thatgotten by iteratively combining the pairwise distri-butions using Dempster's Rule.The resulting distribution for our example is:1.
(A B D) (C) = .3832.
(A B) (C D) = .1843.
(A B) (C) (D) = .1234.
(A D) (B) (C) -- .0625.
(B D) (A) (C) = .1256.
(C D) (A) (B) = .0617.
(A) (B) (C) (D) = .061In motivating our approach, we noted that we can-not expect o have the amount of training data nec-essary to directly estimate distributions for all thepossible scenarios with which we may be confronted.Limiting ourselves to modeling probabilities betweenpairs of templates, however, leads to inconsistenciesbecause of the failure to take into account he crucialinformation provided by the existence of other com-patible templates.
Dempster's Rule can be seen as avery coarse-grained approach to conditioning on con-text in this regard.
The contributions of the pairwisemodels are conditioned not on the existence of other~We use the notation =c to indicate coreference.168templates in context, but by virtue of the existenceof conflicting models derived from those templates.For instance; the pairwise probability of coreferencebetween C and D was originally 0.504, which mightbe reasonable if those were the only two templatesgenerated from the text.
7 However, the probabilitythat C and D corefer in the final distribution is only0.245, the sum of the probabilities of the two parti-tions in which C and D occupy the same cell.
Thisadjustment results from the existence of templates Aand B: the fact that template D has a high probabil-ity of coreferring with each, combined with the factthat template C is incompatible with each, reducesthe likelihood that C and D corefer.
Therefore, thepreferences for particular coreferential dependenciescan change when considering the larger picture ofpossible coreference s ts.In practice, coreference sets that are significantlylarger than the one we have considered here can leadto an explosive number of possible coreference con-figurations.
We have implemented simple methodsfor pruning very low probability configurations dur-ing processing and for smoothing the resulting distri-bution.
The latter step is accomplished, when nec-essary, by eliminating certain low-probability config-urations at the end of processing.
The probabilitymass from these configurations i distributed uni-formly over all the possible configurations that havebeen eliminated.
While this is unlikely to be thebest strategy for smoothing from the standpoint ofprobabilistic modeling, we are constrained by thenumber of alternatives we can report to the down-stream system.
Smoothing in this way allows us toreport only the coreference configurations with non-negligible probability, along with a single probabilitythat is assigned uniformly to the remainder of thepossible configurations.4.2 A Mode l  Based  on  Merg ing  Dec is ionsThe second approach we consider models the like-lihood of correctness of decisions that a templatemerger such as the one used in FASTUS would makein processing a text.
To illustrate, consider the casein our example in which the probability of the coref-erence configuration ((A B D) (C)) is determined.The merger would make the following decisions inderiving such a configuration, in which the notation"B&A" represents the template that results from7Actually this number is lower than it would havebeen, because template B was identified as the preferredantecedent for template D instead of template C. If Cand D were the only two templates generated, then Cwould have been identified as the preferred antecedent,thus raising the probability.templates A and B having previously been merged.1.
B =c A?
~ yes2.
C =c B&A?
~ no3.
D=cC?~no4.
D =c B&A?
~ yesWe therefore model the probability of this coref-erence configuration as the product of each of thecorresponding pairwise probabilities.
Since we can-not model coreference involving objects that have re-sulted from previous (hypothetical) merges - the ap-propriate feature values for distance and form of re-ferring expression would become unclear - we makethe following approximation:p(X =o Yl~...&Y.)
~ p(x  =o y.
)in which Yn is the most recently created template inYt, ..., Yn.Using the probabilities from Table 1, s the prob-ability assigned to ((A B D) (C)) would thereforebep(B =c A) * p(C 7to B) * p(D ~tc C) * p(D ~-c B) =0.671 * 1 * (1 - 0.504) * 0.752 = 0.250Note that unlike the evidential approach, the proba-bility of the pair D and A coreferring does not comeinto play, given that coreference between D and Band between B and A has been factored in.This approach yields a probabilistic model asgiven, that is, the probabilities um to 1 withoutnormalization.
However, in certain circumstancesthe approximation above will generate probabilitymass for an impossible case, specifically when it isknown a priori that X is incompatible with one ofthe templates Y1,..., Y,~-i.
For instance, if templatesB and C in our example had been compatible (withA and C remaining incompatible), then the approxi-mation above would assign positive probability massto the coreference configuration ((A B C) (D)), be-cause the zero probability of A coreferring with Cwould not come into play.
Therefore we modify theabove approximation to apply only if X and each ofY1, ..., Yn-1 are compatible; otherwise, the probabil-ity mass assigned is used for normalization.
One cansee that this can only improve the pure form of themodel.Using the pairwise probabilities from Table 1, theresults of the model as applied to the example are:SWe use these probabilities for ease of comparison.In reality, the pairwise probabilities for this model weretrained with an adapted set of training data as ex-plained below, and so these numbers axe in actuality abit different.1691.
(A B D) (C) = .2502.
(A B) (C D) = .3383.
(A B) (C) (D)= .0834.
(h D) (S) (C) = .0205.
(B D) (A ) (C)= .1236.
(C D) (A) (S) = .1667.
(A) (S) (C) (D) = .0204.3 Two Bases of ComparisonWe compared the two learned models with two base-line models.
First, as an absolute baseline, we com-pared the model with the uniform distribution, thatis, the distribution that assigns equal probability toeach alternative.
We then sought a more challeng-ing, yet straightforward baseline.
We defined a sim-ple, "greedy" approach to merging similar to theone used in FASTUS, in which merging of newly-created templates i attempted iteratively throughthe prior discourse, starting with the most recentlyproduced object.
Any unifications that succeed areperformed.
For instance, in the above example, thegreedy method produces the configuration ((A B)(C D)), because A is compatible with B, C is notcompatible with either, and D is compatible with C(with which merging would be attempted before theearlier-evoked templates B and A).
Alternatively, incases in which all of the templates in a coreferenceset are pairwise compatible, the greedy method willproduce the configuration i  which they are all coref-erential.We then calculated how often this approachyielded the correct results in each training set.
Wedistinguished between three values: the percentageof correctness for coreference sets of cardinality 2(call this P2), the percentage for coreference s ts ofcardinality 3 (call this P3), and the percentage forcoreference sets of cardinality 4 or more (call thisP>3).
The greedy model was defined such that theresult of the greedy merging strategy is assigned theappropriate probability Pk, with the remainder ofthe probability mass 1 -p}  distributed uniformlyamong the remaining possible alternatives.
(No al-ternatives were included that were a priori knownto be impossible due to incompatibilities.
)For instance, in the first training set we describebelow, p2--.571, p3=.652, and p>3=.344 (the per-centage for the whole training corpus was p=.555).If there are 4 templates, and 10 coreference con-figurations are possible, then the answer derivedby the greedy strategy would receive probability.344, and the remaining 9 alternatives would re-ceive probability 1-.3449 = .0729.
In the secondtraining set we describe below, p2--.646, p3=.600,and p>3--.345 (the percentage for the whole train-ing corpus was p=.549), and in the third training set,p2--.628, p3=.600, and p>3=.280 (the percentage forthe whole training corpus was p=.523).5 Exper iments5.1 Training the Max imum EntropyModelsFor reasons described below, we trained separatepairwise probability models for each of the two ap-proaches.
We ran FASTUS over our developmentcorpus, 72 texts of which produced coreference data.The texts gave rise to 132 coreference s ts, and pro-duced characteristics of context for 647 potentialcoreference r lationships between pairs of templates.We created akey by analyzing the texts and enteringthe correct coreference r lationships.We created three splits of training and test data.In the first split, the training set contained 60 mes-sages, giving rise to 110 coreference s ts, and the testset contained 12 messages, giving rise to 22 corefer-ence sets.
In the second split, the training set con-tained 57 messages, giving rise to 102 coreferencesets, and the test set contained 15 messages, givingrise to 30 coreference sets.
The third test set wascreated by combining the first and second test sets.The training set contained 47 messages, giving riseto 88 coreference s ts, and the test set contained 25messages (the first two test sets overlapped by twomessages), which gave rise to 44 coreference s ts.For training the maximum entropy model, onlythe sets of characteristics of context for pairwisecoreference are relevant; he number of such sets dif-fered between the two approaches as discussed be-low.
The evaluations were performed on the test setswith respect o the final distribution generated forthe coreference s ts, with the result being measuredin terms of the average cross-entropy between themodel and the test data.Data  for the Evidential  Model  The evidentialmodel utilizes the pairwise probabilities between allpairs of templates in a coreference s t. Therefore, weused all such pairs in each training set to train themaximum entropy model.
In the first training set,the 110 coreference s ts gave rise to characteristicsof context for 578 pairs of templates; in the second,the 102 coreference s ts gave rise to characteristicsfor 581 pairs of templates.
In the third training set,the 88 coreference s ts gave rise to characteristics for525 pairs of templates.The maximum entropy algorithm selected similarsets of features to model in each case.
9 Among the9The following features represent the referenced char-170systems of ,ki values learned, negative values werelearned for the features in which template S prop-erly subsumes template T and in which S and T areotherwise consistent.
These two features model thecases in which template T contains information otcontained in template S, reflecting the fact that ex-pressions referring to the same entity usually do notbecome more specific as the discourse proceeds.
Apositive value was learned for the feature modelingcases in which templates S and T had at least twoidentical non-nil slot values, as well as for the featuremodeling an exact match of complex name values.As one might expect, a negative value was learnedfor the case in which template T was created from anindefinite expression.
A positive value was learnedfor the case in which template T was created from adefinite expression and S was (perhaps transitively)the preferred referent according to the coreferencemodule.
Interestingly, no value was learned for tem-plate S being a possible but non-preferred referent,but a small positive value was learned for it not be-ing on the list at all - presumably this covers casesin which the coreference module fails to identify anexisting referent.
All the distance features except forclose and mid-distance r ceived negative hi values,suggesting that coreference between close and mid-distance templates was more likely than coreferencebetween templates that were very close, far away,and very far away.The cross-entropy of the learned model as appliedto the training data in each case was about 0.80.Given that the cross-entropy of the uniform distri-bution and the data is 1 (as there are only two pos-sible values for the random variable, i.e., S and Tare coreferent or not), this relatively small reduc-tion suggests that the problem has some amount ofdifficulty, which is consistent with the notable lackof clear signals of coreference characteristic of thetexts in our domain.Data  for the  Merg ing  Decis ion Mode l  Unlikethe evidential model, the merging decision modeldoes not always utilize all of the palrwise probabili-ties between pairs in a coreference s t. For instance,in determining the probability of a coreference con-figuration ((A B C)), it does not consider the prob-ability assigned to the pair A and C except o checkthat they are compatible.
Therefore, the trainingset for the maximum entropy algorithm was pareddown to only contain those pairs that the mergerwould have considered in deriving the correct coref-erence configurations.
The resulting data had thesame coreference sets as the training data for theacteristic of context paired with the result of coreference.evidential approach, but consisted of characteristicsof context for 415 template pairs in the first train-ing set, 405 pairs in the second training set, and 370pairs in the third training set.
The features electedwere similar to those in the training of the evidentialmodel.The cross-entropies of the learned maximum en-tropy models and the training data were notablybetter than those for the evidential model, at about0.70 in each case.
This improvement is not partic-ularly surprising.
In the evidential case, the factthat all pairs of templates are considered results ina certain amount of "washing out" of the data, dueto redundancy in coreference r lationships.
For in-stance, coreference between two templates that arefar away might be unlikely if there are no corefer-ring expressions between them, but quite likely ifthere are.
When just considering the pairwise fea-ture sets, these two cases are not distinguished, sothe resulting probability will be mixed.
However, inthe merging decision case, pairs that are far awaywill not be in the data set if there are coreferringexpressions between them, and thus the probabilityfor coreference at long distances will be diminished.The result is a "cleaner" set of data in which clearerdistinctions may be found, as evidenced by the lowercross-entropy achieved.5.2 Eva luat ion  Resu l t sThe cross-entropies of the various approaches as ap-plied to the three sets of test data are shown in Ta-ble 2.
The number within parentheses indicates thenumber of times that the coreference set with thehighest probability was the correct one.
As hoped,both the evidential and merging decision approachesoutperformed the uniform and greedy approacheswith respect o cross-entropyJ ?Interestingly, and perhaps surprisingly, the evi-dential approach outperformed the merging decisionmodel, even though in many respects the latter ismore natural and elegant.
While considering fea-ture sets for all pairs may wash out the trainingdata for the pairwise probability model somewhat,the evidence provided by all pairs appears to morethan make up for the difference.
Given that a goalof these experiments i to see how well the strate-gies would perform with a fairly crude, easily com-putable, and portable set of characteristics of con-1?The merging decision approach did not do any betterthan the greedy approach in terms of raw accuracy, andin fact did somewhat worse in the third test.
Again, how-ever, the reduction in cross-entropy is important, as thestatistics produced by the system will be integrated withother probabilistic factors in the downstream system.171\[I Test Set 1 Test Set2 Test Sets land2Uniform I 2.12 (--) 1.76 (--) 2.01 (--)Greedy 1.50 (15) I 1.30 (20) 1.41 (30)Merging Decision 1.32 (15) 1.13 (20) 1.27 (27)Evidential 1.10 (17) 0.89 (21) 1.00 (35)Table 2: Initial Evaluation Cross-Entropiestext, we are encouraged by the results of these ex-periments, especially considering the limited amountof training data that was available.Nonetheless, additional data is necessary to con-firm the results of these initial evaluations.
Althoughthe consistency of the results between the first twotraining/test divisions may suggest that the amountof training data is sufficient for the rather coarselygrained feature set used, the size of the test setsare potentially of concern, which motivated our in-clusion of the third training/test division.
Despitethe reduction in training data and corresponding in-crease in test data, the results of this experimentappear to consistent with the first two.There are a variety of characteristics of contextthat one might add to improve the models.
Forinstance, one could add a characteristic indicatingwhen a template is created from a phrase in a sub-ject line or table, as many cases of coreference withsubsequent indefinite phrases occur in this circum-stance.
Other types of information about text type,text structure, and more finely grained distinctionswith respect to referential types (e.g., modeling pro-nouns differently than other definite NPs) would alllikely further improve the model, although for someof these additional training data would be requiredand more domain and genre dependence may result.While this work was motivated by a need to passprobabilistic output to a downstream data fusionsystem, these methods can be applied system inter-nally also, to supplant existing algorithms for merg-ing in IE settings that do not allow for probabilisticoutput.
In this scenario, the system simply performsthe template merging dictated by the most proba-ble coreference onfiguration for a given coreferenceset.
However, as noted earlier, the texts in our appli-cation are relatively short, and therefore the coref-erence sets are usually of manageable size.
Signif-icantly larger coreference sets can lead to an enor-mous number of possible coreference onfigurations.Therefore, to address this task in applications withmuch longer texts, mechanisms beyond those thatwere necessary here will be required for intelligentlypruning the search space and subsequently smooth-ing the distributions.6 Conc lus ionsCertain applications require that the output of an in-formation extraction system be probabilistic, so thata downstream system can reliably \]use the outputwith possibly contradictory information from othersources.
In this paper we considered the problemof assigning a probability distribution to alterna-tive sets of coreference r lationships among entitydescriptions.
We presented the encouraging resultsof initial experiments with several approaches toes-timating such distributions in an application usingSRI's FASTUS information extraction system.
Wewould expect further gains from encoding additionaltraining data and modeling more informative char-acteristics of context.AcknowledgmentsThe author thanks John Bear, Joshua Goodman,and two anonymous reviewers for helpful commentsand criticisms, and the SRI Message Handler projectteam for their contributions to the system in whichthis work is embedded.
This work was supported bythe Defense Advanced Research Projects Agency un-der contract number 4099SCL001 (E-Systems Inc.,prime contractor).Re ferencesAone, Chinatsu and Scott William Bennett.
1995.Evaluating automated and manual acquisition ofanaphora resolution strategies.
In Proceedings ofthe 33rd Annual Meeting of the Association forComputational Linguistics (ACL-95), pages 122-129, Cambridge, MA, June.Berger, Adam, Stephen A. Della Pietra, and Vin-cent J. Della Pietra.
1996.
A maximum entropyapproach to natural language processing.
Compu-tational Linguistics, 22(1):39-71.Connolly, Dennis, John D. Burger, and David S.Day.
1994.
A machine learning approach to172anaphoric reference.
In Proceedings of the Inter-national Conference on New Methods in LanguageProcessing (NeMLaP).Dagan, Ido and Alon Itai.
1990.
Automatic acquisi-tion of constraints for the resolution of anaphorareferences and syntactic ambiguities.
In Proceed-ings of the 13th International Conference on Com-putational Linguistics (COLING-90), pages 330-332.Dagan, Ido, John Justenson, Shalom Lappin, Her-bert Leass, and Amnon Ribak.
1995.
Syntax andlexical statistics in anaphora resolution.
AppliedArtificial Intelligence, 9(6):633-644, Nov/Dec.Dempster, Arthur P. 1968.
A generalization ofBayesian inference.
Journal of the Royal Statis-tical Society, 30:205-247.Hobbs, Jerry R., Douglas E. Appelt, John Bear,David Israel, Megumi Kameyama, Mark Stickel,and Mabry Tyson.
1996.
FASTUS: A cascadedfinite-state transducer for extracting informationfrom natural-language text.
In Finite State De-vices for Natural Language Processing.
MIT Press,Cambridge, MA.Kennedy, Christopher and Branimir Boguraev.1996a.
Anaphora for everyone: Pronominalanaphora resolution without a parser.
In Pro-ceedings of the 16th International Conference onComputational Linguistics (COLING-96).Kennedy, Christopher and Branimir Boguraev.1996b.
Anaphora in a wider context: Track-ing discourse referents.
In Proceedings of the12th European Conference on Artificial Intelli-gence (ECAI-96).Lappin, Shalom and Herbert Leass.
1994.
An algo-rithm for pronominal anaphora resolution.
Com-putational Linguistics, 20(4):535-561.173
