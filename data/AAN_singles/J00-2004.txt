Models of Translational Equivalenceamong WordsI.
Dan  Me lamed*West GroupParallel texts (bitexts) have properties that distinguish them from other kinds of parallel data.First, most words translate to only one other word.
Second, bitext correspondence is typicallyonly partial--many words in each text have no clear equivalent in the other text.
This articlepresents methods for biasing statistical translation models to reflect hese properties.
Evalua-tion with respect to independent human judgments has confirmed that translation models biasedin this fashion are significantly more accurate than a baseline knowledge-free model.
This arti-cle also shows how a statistical translation model can take advantage of preexisting knowledgethat might be available about particular language pairs.
Even the simplest kinds of language-specific knowledge, such as the distinction between content words and function words, areshown to reliably boost ranslation model performance on some tasks.
Statistical models thatreflect knowledge about he model domain combine the best of both the rationalist and empiricistparadigms.1.
IntroductionThe idea of a computer system for translating from one language to another is almostas old as the idea of computer systems.
Warren Weaver wrote about mechanical trans-lation as early as 1949.
More recently, Brown et al (1988) suggested that it may bepossible to construct machine translation systems automatically.
Instead of codifyingthe human translation process from introspection, Brown and his colleagues proposedmachine learning techniques to induce models of the process from examples of its in-put and output.
The proposal generated much excitement, because it held the promiseof automating a task that forty years of research ave proven very labor-intensive anderror-prone.
Yet very few other researchers have taken up the cause, partly becauseBrown et al's (1988) approach was quite a departure from the paradigm in vogue atthe time.Formally, Brown et al (1988) built statistical models of translational equivalence(or translation models 1, for short).
In the context of computational linguistics, trans-lational equivalence is a relation that holds between two expressions with the samemeaning, where the two expressions are in different languages.
Empirical estimationof statistical translation models is typically based on parallel texts or bitexts--pairsof texts that are translations of each other.
As with all statistical models, the besttranslation models are those whose parameters correspond best with the sources ofvariance in the data.
Probabilistic translation models whose parameters reflect univer-sal properties of translational equivalence and/or  existing knowledge about particular* D1-66F, 610 Opperman Drive, Eagan, MN 55123.
E-marl: dan.melamed@westgroup.com1 The term translation model, which is standard in the literature, refers to a mathematical re ationshipbetween two data sets.
In this context, he term implies nothing about he process of translationbetween atural languages, automated orotherwise.
@ 2000 Association for Computational LinguisticsComputational Linguistics Volume 26, Number 2languages and language pairs benefit from the best of both the empiricist and ratio-nalist traditions.This article presents three such models, along with methods for efficiently esti-mating their parameters.
Each new method is designed to account for an additionaluniversal property of translational equivalence in bitexts:...Most word tokens translate to only one word token.
I approximate thistendency with a one-to-one assumption.Most text segments are not translated word-for-word.
I build an explicitnoise model.Different linguistic objects have statistically different behavior intranslation.
I show a way to condition translation models on differentword classes to help account for the variety.Quantitative valuation with respect to independent human judgments has shownthat each of these three estimation biases significantly improves translation model ac-curacy over a baseline knowledge-free model.
However, these biases will not producethe best possible translation models by themselves.
Anyone attempting to build an op-timal translation model should infuse it with all available knowledge sources, includ-ing syntactic, dictionary, and cognate information.
My goal here is only to demonstratethe value of some previously unused kinds of information that are always available fortranslation modeling, and to show how these information sources can be integratedwith others.A review of some previously published translation models follows an introductionto translation model taxonomy.
The core of the article is a presentation of the modelestimation biases described above.
The last section reports the results of experimentsdesigned to evaluate these innovations.Throughout this article, I shall use CA?
?/~GT4A/~C letters to denote entire textcorpora and other sets of sets, CAPITAL letters to denote collections, including se-quences and bags, and italics for scalar variables.
I shall also distinguish betweentypes and tokens by using bold font for the former and plain font for the latter.2.
Translation Model DecompositionThere are two kinds of applications of translation models: those where word orderplays a crucial role and those where it doesn't.
Empirically estimated models of trans-lational equivalence among word types can play a central role in both kinds of appli-cations.Applications where word order is not essential include?
cross-language information retrieval (e.g., McCarley 1999),?
multilingual document filtering (e.g., Oard 1997),?
computer-assisted language learning (e.g., Nerbonne t al.
1997),?
certain machine-assisted translation tools (e.g., Macklovitch 1994;Melamed 1996a),?
concordancing for bilingual exicography (e.g., Catizone, Russell, andWarwick 1989; Gale and Church 1991),222Melamed Models of Translational Equivalence?
corpus linguistics (e.g., Svartvik 1992),?
"crummy" machine translation (e.g., Church and Hovy 1992; Resnik1997).For these applications, empirically estimated models have a number of advantagesover handcrafted models such as on-line versions of bilingual dictionaries.
Two ofthe advantages are the possibility of better coverage and the possibility of frequentupdates by nonexpert users to keep up with rapidly evolving vocabularies.A third advantage is that statistical models can provide more accurate informationabout he relative importance of different translations.
Such information is crucial forapplications such as cross-language information retrieval (CLIR).
In the vector spaceapproach to CLIR, the query vector Q' is in a different language (a different vectorspace) from the document vectors D. A word-to-word translation model T can map QIinto a vector Q in the vector space of D. In order for the mapping to be accurate, T mustbe able to encode many levels of relative importance among the possible translationsof each element of QI.
A typical bilingual dictionary says only what the possibletranslations are, which is equivalent to positing a uniform translational distribution.The performance of cross-language information retrieval with a uniform T is likely tobe limited in the same way as the performance of conventional information retrievalwithout erm-frequency information, i.e., where the system knows which terms occurin which documents, but not how often (Buckley 1993).Applications where word order is crucial include speech transcription for trans-lation (Brousseau et al 1995), bootstrapping of OCR systems for new languages (PhilipResnik and Tapas Kanungo, personal communication), interactive translation(Foster, Isabelle, and Plamondon 1996), and fully automatic high-quality machinetranslation (e.g., A1-Onaizan et al 1999).
In such applications, a word-to-word trans-lation model can serve as an independent module in a more complex sequence-to-sequence translation model.
2The independence of such a module is desirable for tworeasons, one practical and one philosophical.
The practical reason is illustrated inthis article: Order-independent translation models can be accurately estimated moreefficiently in isolation.
The philosophical reason is that words are an important epis-temological category in our naive mental representations of language.
We have manyintuitions (and even some testable theories) about what words are and how they be-have.
We can bring these intuitions to bear on our translation models without beingdistracted by other facets of language, such as phrase structure.
For example, thetranslation models presented in the last two chapters of Melamed (to appear) cap-ture the intuitions that words can have multiple senses and that spaces in text do notnecessarily delimit words.The independence of a word-to-word translation module in a sequence-to-sequencetranslation model can be effected by a two-stage decomposition.
The first stage is basedon the observation that every sequence L is just an ordered bag, and that the bag Bcan be modeled independently of its order O.
For example, the sequence (abc I consistsof the bag {c,a, b} and the ordering relation {(b,2), (a, 1), (c,3)}.
If we represent eachsequence L as a pair (B, O), thenPr(L) - Pr(B,O) (1)-- Pr(B)-Pr(OIB ).
(2)2 "Sentence-to-sentence" might be a more transparent term than "sequence-to-sequence," but all themodels that I'm aware of apply equally well to sequences of words that are not sentences.223Computational Linguistics Volume 26, Number 2Now, let L1 and L2 be two sequences and let A be a one-to-one mapping betweenthe elements of L1 and the elements of L2.
Borrowing a term from the operationsresearch literature, I shall refer to such mappings as assignments.
3 Let .4 be the set ofall possible assignments between L1 and L2.
Using assignments, we can decomposeconditional and joint probabilities over sequences:Pr(LIIL2) = ~ Pr(L1,A\[L2) (3)AG.4Pr(L,,L2) = ~ Pr(L1, A, L2) (4)ACAwherePr(L,,A\]L2) - Pr(B1,01,AIL2) (5)= Pr(B1,AIL2) ?
Pr(OI\[B1, A, L2) (6)Pr(L1,A, L2) ~ Pr(B,, O1, A,  B2, 02) (7)= Pr(B1, A, B2).
Pr(O1, O2IB1,A, B2) (8)Summing bag pair probabilities over all possible assignments, we obtain a bag-to-bagt rans la t ion  mode l :Pr(B1, B2) = ~ Pr(B,, A, B2) (9)AEAThe second stage of decomposition takes us from bags of words to the wordsthat they contain.
The following bag pair generation process illustrates how a word-to-word translation model can be embedded in a bag-to-bag translation model forlanguages ?1 and ?2:.2.3.Generate a bag size /.4 1 is also the assignment size.Generate l language-independent concepts C1,..., C1.From each concept Ci, 1 < i < I, generate a pair of word sequences (ffi, rTi)from ?~ x ?~, according to the distribution trans(G ~), to lexicalize theconcept in the two languages.
5 Some concepts are not lexicalized in somelanguages, so one of ffi and rTi may be empty.A pair of bags containing m and n nonempty word sequences can be generated by aprocess where l is anywhere between 1 and m + n.For notational convenience, the elements of the two bags can be labeled so thatB1 - {u~,...,t~} and B 2 ~ {V~ .
.
.
.
.
~} ,  where some of the 1/'s and "?
's may beempty.
The elements of an assignment, hen, are pairs of bag element labels: A --{(h,jl) .
.
.
.
.
(h, jl)}, where each i ranges over  {IJ 1 .
.
.
.
.
11l}, eachj ranges over {v~ .
.
.
.
.
x~},3 Assignments are different from Brown, Della Pietra, Della Pietra, and Mercer's (1993) alignments inthat assignments can range over pairs of arbitrary labels, not necessarily sequence position indexes.Also, unlike alignments, assignments must be one-to-one.4 The exact nature of the bag size distribution is immaterial for the present purposes.5 Since they are put into bags, ffi and r7 i could just as well be bags instead of sequences.
I make themsequences only to be consistent with more sophisticated models that account for noncompositionalcompounds (e.g.
Melamed, to appear, Chapter 8).224Melamed Models of Translational Equivalenceeach i is distinct, and each j is distinct.
The label pairs in a given assignment can begenerated in any order, so there are I!
ways to generate an assignment of size I.
6 Itfollows that the probability of generating a pair of bags (B1, B2) with a particularassignment A of size l isPr(B1,A, B2\]I,C, trans) : Pr(1).
I!
n E Pr(C)trans('fi'vilC)"(i,j) ff A CCC(lO)The above equation holds regardless of how we represent concepts.
There aremany plausible representations, such as pairs of trees from synchronous tree adjoininggrammars (Abeill6 et al 1990; Shieber 1994; Candito 1998), lexical conceptual struc-tures (Dorr 1992) and WordNet synsets (Fellbaum 1998; Vossen 1998).
Of course, for arepresentation to be used, a method must exist for estimating its distribution in data.A useful representation will reduce the entropy of the trans distribution, which is con-ditioned on the concept distribution as shown in Equation 10.
This topic is beyond thescope of this article, however.
I mention it only to show how the models presentedhere may be used as building blocks for models that are more psycholinguisticallysophisticated.To make the translation model estimation methods presented here as general aspossible, I shall assume a totally uninformative concept representation--the rans dis-tribution itself.
In other words, I shall assume that each different pair of word sequencetypes is deterministically generated from a different concept, so that trans(.1i,~i\]C) iszero for all concepts except one.
Now, a bag-to-bag translation model can be fullyspecified by the distributions of l and trans.Pr(B1,A, B2\]I, trans) = Pr(l).
I!
H trans(~,~j)(i,j) CA(11)The probability distribution trans (.1, ~) is a word-to-word translation model.
Unlikethe models proposed by Brown et al (1993b), this model is symmetric, because bothword bags are generated together from a joint probability distribution.
Brown and hiscolleagues' models, reviewed in Section 4.3, generate one half of the bitext given theother hal l  so they are represented by conditional probability distributions.
A sequence-to-sequence translation model can be obtained from a word-to-word translation modelby combining Equation 11 with order information as in Equation 8.3.
The One-to-One AssumptionThe most general word-to-word translation model trans(.1, ~), where ,i and ??
rangeover sequences in ?1 and ?2, has an infinite number of parameters.
This model canbe constrained in various ways to make it more practical.
The models presented inthis article are based on the one-to-one assumption: Each word is translated to atmost one other word.
In these models, .1 and ??
may consist of at most one word each.As before, one of the two sequences (but not both) may be empty.
I shall describeempty sequences as consisting of a special NULL word, so that each word sequencewill contain exactly one word and can be treated as a scalar.
Henceforth, I shall write uand v instead of 11 and ~?.
Under the one-to-one assumption, a pair of bags containing m6 The number of permutations is smaller when either bag contains two or more identical elements, butthis detail will not affect he estimation algorithms presented here.225Computational Linguistics Volume 26, Number 2and n nonempty words can be generated by a process where the bag size I is anywherebetween max(m, n) and m + n.The one-to-one assumption is not as restrictive as it may appear: The explanatorypower of a model based on this assumption may be raised to an arbitrary level byextending Western notions of what words are to include words that contain spaces(e.g., in English) or several characters (e.g., in Chinese).
For example, I have shownelsewhere how to estimate word-to-word translation models where a word can be anoncompositional compound consisting of several space-delimited tokens (Melamed,to appear).
For the purposes of this article, however, words are the tokens generatedby my tokenizers and stemmers for the languages in question.
Therefore, the modelsin this article are only a first approximation to the vast complexities of translationalequivalence between atural languages.
They are intended mainly as stepping stonestowards better models.4.
Previous Work4.1 Models of Co-occurrenceMost methods for estimating translation models from bitexts tart with the followingintuition: Words that are translations of each other are more likely to appear in cor-responding bitext regions than other pairs of words.
Following this intuition, mostauthors begin by counting the number of times that word types in one half of thebitext co-occur with word types in the other half.
Different co-occurrence countingmethods tem from different models of co-occurrence.A model of co-occurrence is a Boolean predicate, which indicates whether a givenpair of word tokens co-occur in corresponding regions of the bitext space.
Differentmodels of co-occurrence are possible, depending on the kind of bitext map that is avail-able, the language-specific information that is available, and the assumptions madeabout he nature of translational equivalence.
All the translation models reviewed andintroduced in this article can be based on any of the co-occurrence models describedby Melamed (1998a).
For expository purposes, however, I shall assume a boundary-based model of co-occurrence throughout this article.
A boundary-based model ofco-occurrence assumes that both halves of the bitext have been segmented into s seg-ments, so that segment Ui in one half of the bitext and segment Vi in the other halfare mutual translations, 1 < i < s.Under the boundary-based model of co-occurrence, there are several ways to com-pute co-occurrence counts cooc(u, v) between word types u and v. In the models ofBrown, Della Pietra, Della Pietra, and Mercer (1993), reviewed in Section 4.3,sCOOC(R, V) = ~ ei(u) .j~(V), (12)i=1where ei and j5 are the unigram frequencies of u and v, respectively, in each alignedtext segment i.
For most translation models, this method produces uboptimal results,however, when ei(u) > 1 and )~(v) > 1.
I argue elsewhere (Melamed 1998a) thatcooc(u, v) = ~ min\[ei(u),j~(v)\] (13)i=1is preferable, and this is the method used for the models introduced in Section 5.226Melamed Models of Translational EquivalenceHeIIFigure 1nods his headI "hoche la tetenods and hoche often co-occur, as do nods and head.
The direct association between ods andhoche, and the direct association between ods and head give rise to an indirect associationbetween hoche and head.4.2 Nonprobabilistic Translation LexiconsMany researchers have proposed greedy algorithms for estimating nonprobabilisticword-to-word translation models, also known as translation lexicons (e.g., Catizone,Russell, and Warwick 1989; Gale and Church 1991; Fung 1995; Kumano and Hirakawa1994; Melamed 1995; Wu and Xia 1994).
Most of these algorithms can be summarizedas follows:1.
Choose a similarity function S between word types in ?1 and word typesin ?2.2.
Compute association scores S(u,v) for a set of word type pairs(U, V) C (?1 X ?2) that occur in training data.3.
Sort the word pairs in descending order of their association scores.4.
Discard all word pairs for which S(u, v) is less than a chosen threshold.The remaining word pairs become the entries in the translation lexicon.The various proposals differ mainly in their choice of similarity function.
Almost allthe similarity functions in the literature are based on a model of co-occurrence withsome linguistically motivated filtering (see Fung \[1995\] for a notable xception).Given a reasonable similarity function, the greedy algorithm works remarkablywell, considering how simple it is.
However, the association scores in Step 2 are typ-ically computed independently of each other.
The problem with this independenceassumption is illustrated in Figure 1.
The two word sequences represent correspond-ing regions of an English/French bitext.
If nods and hoche co-occur much more oftenthan expected by chance, then any reasonable similarity metric will deem them likelyto be mutual translations.
Nods and hoche are indeed mutual translations, o their ten-dency to co-occur is called a direct association.
Now, suppose that nods and head oftenco-occur in English.
Then hoche and head will also co-occur more often than expectedby chance.
The dashed arrow between hoche and head in Figure i represents an indirectassociation, since the association between hoche and head arises only by virtue of theassociation between each of them and nods.
Models of translational equivalence thatare ignorant of indirect associations have "a tendency.. ,  tobe confused by collocates"(Dagan, Church, and Gale 1993,5).Paradoxically, the irregularities (noise) in text and in translation mitigate the prob-lem.
If noise in the data reduces the strength of a direct association, then the samenoise will reduce the strengths of any indirect associations that are based on this direct227Computational Linguistics Volume 26, Number 2Table 1Variables used to describe translation models.
(U, V) = the two halves of the bitext(U, V) = a pair of aligned text segments in (/d, V)e(u) = the unigram frequency of u in Uf(v) = the unigram frequency of v in Vcooc(u, v) = the number of times that u and v co-occurtrans(vlu ) = the probability that a token of u will be translated as a token of vassociation.
On the other hand, noise can reduce the strength of an indirect associa-tion without affecting any direct associations.
Therefore, direct associations are usuallystronger than indirect associations.
If all the entries in a translation lexicon are sortedby their association scores, the direct associations will be very dense near the top ofthe list, and sparser towards the bottom.Gale and Church (1991) have shown that entries at the very top of the list canbe over 98% correct.
Their algorithm gleaned lexicon entries for about 61% of theword tokens in a sample of 800 English sentences.
To obtain 98% precision, theiralgorithm selected only entries for which it had high confidence that the associationscore was high.
These would be the word pairs that co-occur most frequently.
Arandom sample of 800 sentences from the same corpus showed that 61% of the wordtokens, where the tokens are of the most frequent types, represent 4.5% of all the wordtypes.A similar strategy was employed by Wu and Xia (1994) and by Fung (1995).Fung skimmed off the top 23.8% of the noun-noun entries in her lexicon to achieve aprecision of 71.6%.
Wu and Xia have reported automatic acquisition of 6,517 lexiconentries from a 3.3-million-word corpus, with a precision of 86%.
The first 3.3 millionword tokens in an English corpus from a similar genre contained 33,490 different wordtypes, suggesting a recall of roughly 19%.
Note, however, that Wu and Xia chose toweight their precision estimates by the probabilities attached to each entry:For example, if the translation set for English word detect has thetwo correct Chinese candidates with 0.533 probability and with 0.277probability, and the incorrect ranslation with 0.190 probability, thenwe count this as 0.810 correct ranslations and 0.190 incorrect ransla-tions.
(Wu and Xia 1994, 211)This is a reasonable valuation method, but it is not comparable to methods thatsimply count each lexicon entry as either right or wrong (e.g., Daille, Gaussier, andLang6 1994; Melamed 1996b).
A weighted precision estimate pays more attention toentries that are more frequent and hence easier to estimate.
Therefore, weighted pre-cision estimates are generally higher than unweighted ones.4.3 Reestimated Sequence-to-Sequence Translation ModelsMost probabilistic translation model reestimation algorithms published to date arevariations on the theme proposed by Brown et al (1993b).
These models involve con-ditional probabilities, but they can be compared to symmetric models if the latter arenormalized by the appropriate marginal distribution.
I shall review these models usingthe notation in Table 1.228Melamed Models of Translational Equivalence4.3.1 Models Using Only Co-occurrence Information.
Brown and his colleagues em-ploy the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977)to estimate the parameters of their Model 1.
On iteration i, the EM algorithm reesti-mates the model parameters transi(v\]u) based on their estimates from iteration i -  1.In Model 1, the relationship between the new parameter estimates and the old ones istransi_l(VlU ) ?
e(u) -f(v) transi(vlu) = z ~_, (u,v)e(u,v) ~u,eutransi-l(VlU')(14)where z is a normalizing factor.
7It is instructive to consider the form of Equation 14 when all the translation prob-abilities trans(v\[u) for a particular u are initialized to the same constant p, as Brownet al (1993b, 273) actually do:transl(v\]u) : z E p.e(u) .
f(v) (15)(u,v)c(u,v) p. \]U\[: z E e(u) .
f(v) (16)(u,v)e(u,v) pU\]The initial translation probability transl(v\]u) is set proportional to the co-occurrencecount of u and v and inversely proportional to the length of each segment U in whichu occurs.
The intuition behind the numerator is central to most bitext-based translationmodels: The more often two words co-occur, the more likely they are to be mutualtranslations.
The intuition behind the denominator is that the co-occurrence count ofu and v should be discounted to the degree that v also co-occurs with other words inthe same segment pair.Now consider how Equation 16 would behave if all the text segments on eachside were of the same length, s so that each token of v co-occurs with exactly c words(where c is constant):transl(vlu ) : z E e(u) .
f (v)  (17)c (u,v) c (u,v)z ~ e(u) .
f(v) (18)c(u,v) e(u,v)The normalizing coefficient z is constant over all words.
The only difference betweenEquations 16 and 18 is that the former discounts co-occurrences proportionally to thesegment lengths.
When information about segment lengths is not available, the onlyinformation available to initialize Model 1 is the co-occurrence counts.
This propertymakes Model 1 an appropriate baseline for comparison to more sophisticated modelsthat use other information sources, both in the work of Brown and his colleagues andin the work described here.7 This expression is obtained by substituting Brown, Della Pietra, Della Pietra, and Mercer's (1993)Equation 17 into their Equation 14.8 Or, equivalently, if the notion of segments were dispensed with altogether, as under the distance-basedmodel of co-occurrence (Melarned 1998a).229Computational Linguistics Volume 26, Number 24.3.2 Word Order Correlation Biases.
In any bitext, the positions of words relative tothe true bitext map correlate with the positions of their translations.
The correlation isstronger for language pairs with more similar word order.
Brown et al (1988) intro-duced the idea that this correlation can be encoded in translation model parameters.Dagan, Church, and Gale (1993) expanded on this idea by replacing Brown et al's(1988) word alignment parameters, which were based on absolute word positions inaligned segments, with a much smaller set of relative offset parameters.
The muchsmaller number of parameters allowed Dagan, Church, and Gale's model to be effec-tively trained on much smaller bitexts.
Vogel, Ney, and Tillmann (1996) have shownhow some additional assumptions can turn this model into a hidden Markov model,enabling even more efficient parameter estimation.It cannot be overemphasized that the word order correlation bias is just knowledgeabout the problem domain, which can be used to guide the search for the optimummodel parameters.
Translational equivalence can be empirically modeled for any pairof languages, but some models and model biases work better for some language pairsthan for others.
The word order correlation bias is most useful when it has highpredictive power, i.e., when the distribution of alignments or offsets has low entropy.The entropy of this distribution is indeed relatively low for the language pair that bothBrown and his colleagues and Dagan, Church, and Gale were working with--Frenchand English have very similar word order.
A word order correlation bias, as well asthe phrase structure biases in Brown et al's (1993b) Models 4 and 5, would be lessbeneficial with noisier training bitexts or for language pairs with less similar wordorder.
Nevertheless, one should use all available information sources, if one wants tobuild the best possible translation model.
Section 5.3 suggests a way to add the wordorder correlation bias to the models presented in this article.4.4 Reestimated Bag-to-Bag Translation ModelsAt about the same time that I developed the models in this article, Hiemstra (1996)independently developed his own bag-to-bag model of translational equivalence.
Hismodel is also based on a one-to-one assumption, but it differs from my models in thatit allows empty words in only one of the two bags, the one representing the shortersentence.
Thus, Hiemstra's model is similar to the first model in Section 5, but it hasa little less explanatory power.
Hiemstra's approach also differs from mine in his useof the Iterative Proportional Fitting Procedure (IPFP) (Deming and Stephan 1940) forparameter estimation.The IPFP is quite sensitive to initial conditions, so Hiemstra investigated a num-ber of initialization options.
Choosing the most advantageous, Hiemstra has publishedparts of the translational distributions ofcertain words, induced using both his methodand Brown et al's (1993b) Model 1 from the same training bitext.
Subjective compar-ison of these examples uggests that Hiemstra's method is more accurate.
Hiemstra(1998) has also evaluated the recall and precision of his method and of Model 1 on asmall hand-constructed setof link tokens in a particular bitext.
Model 1 fared worse,on average.5.
Parameter EstimationThis section describes my methods for estimating the parameters ofa symmetric word-to-word translation model from a bitext.
For most applications, we are interested inestimating the probability trans(u,v) of jointly generating the pair of words (u,v).Unfortunately, these parameters cannot be directly inferred from a training bitext,because we don't know which words in one half of the bitext were generated together230Melamed Models of Translational Equivalencewith which words in the other half.
The observable features of the bitext are only theco-occurrence counts cooc(u, v) (see Section 4.1).Methods for estimating translation parameters from co-occurrence ounts typicallyinvolve l ink counts links(u, v), which represent hypotheses about the number of timesthat u and v were generated together, for each u and v in the bitext.
A l ink token isan ordered pair of word tokens, one from each half of the bitext.
A l ink type is anordered pair of word types.
The link counts links(u, v) range over link types.
We canalways estimate trans(u, v) by normalizing link counts so that Y\]~u,v trans(u, v) = 1:trans(u, v) = links(u, v)Y~-u,,v, links(u', v') (19)For estimation purposes, it is convenient to also employ a separate set of non-probabilistic parameters score(u, v), which represent the chances that u and v can everbe mutual translations, i.e., that there exists some context where tokens u and v aregenerated from the same concept.
The relationship between score(u, v) and trans(u, v)can be more or less direct, depending on the model and its estimation method.
Eachof the models presented below uses a different score formulation.All my methods for estimating the translation parameters trans(u,v) share thefollowing general outline:.....Initialize the score parameters to a first approximation, based only on theco-occurrence counts.Approximate the expected link counts links(u, v), as a function of thescore parameters and the co-occurrence counts.Estimate trans(u, v), by normalizing the link counts as in Equation 19.
Ifless than .0001 of the trans(u, v) distribution changed from the previousiteration, then stop.Reestimate the parameters score(u, v), as a function of the link countsand the co-occurrence counts.Repeat from Step 2.Under certain conditions, a parameter estimation process of this sort is an instance ofthe expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977).
Asexplained below, meeting these conditions is computationally too expensive for mymodels.
9 Therefore, I employ some approximations, which lack the EM algorithm'sconvergence guarantee.The maximum likelihood approach to estimating the unknown parameters i tofind the set of parameters ~) that maximize the probability of the training bitext (U, V).~) = arg rn~x Pr(U, VIO ) (20)The probability of the bitext is a sum over the distribution ~4 of possible assignments:Pr(U, Vie) = ~ Pr(U,A, Vie).
(21)AE.,49 For example, the expectation i  Step 2 would need to be computed exactly, rather than merelyapproximated.231Computational Linguistics Volume 26, Number 2The munber of possible assignments grows exponentially with the size of alignedtext segments in the bitext.
Due to the parameter interdependencies introduced bythe one-to-one assumption, we are unlikely to find a method for decomposing theassignments into parameters that can be estimated independently of each other as inBrown et al \[1993b, Equation 26\]).
Barring such a decomposition method, the MLEapproach is infeasible.
This is why we must make do with approximations to the EMalgorithm.In this situation, Brown et al (1993b, 293) recommend "evaluating the expectationsusing only a single, probable alignment."
The single most probable assignment Ama~is the maximum a posteriori (MAP) assignment:Amax = ar~maxPr(U,A, VIO ) (22) -- AE~4= ar~maxPr(l) ?
l!
I I  trans(ui, vj) (23)-- AE,,4 (i,j) cA= argmaxl?g \[ Pr(1)'l!
I I -  AG,4 (i,j)EAtrans(ui'vJ)\] (24)= argmax {log\[Pr(l) ?
1!\] + v  AC~4 (i,j) ~EA logtrans(ui, vj)} (25)To simplify things further, let us assume that Pr(l) ?
I!
is constant, so thatAmax = argmax ~ logtrans(ui, vj).
(26)AE~4 (i,j) cAIf we represent the bitext as a bipartite graph and weight the edges by log trans(u, v),then the right-hand side of Equation 26 is an instance of the weighted maximummatching problem and Ama~ is its solution.
For a bipartite graph G = (V1 U V2, E),with v = IV1 U V21 and e = IEI, the lowest currently known upper bound on thecomputational complexity of this problem is O(ve + v 2 log v) (Ahuja, Magnati, andOrlin 1993, 500).
Although this upper bound is polynomial, it is still too expensivefor typical bitexts.
1?
Subsection 5.1.2 describes a greedy approximation to the MAPapproximation.5.1 Method A: The Competitive Linking Algorithm5.1.1 Step 1: Initialization.
Almost every translation model estimation algorithm ex-ploits the well-known correlation between translation probabilities and co-occurrencecounts.
Many algorithms also normalize the co-occurrence ounts cooc(u,v) by themarginal frequencies of u and v. However, these quantities account for only the threeshaded cells in Table 2.
The statistical interdependence between two word types canbe estimated more robustly by considering the whole table.
For example, Gale andChurch (1991, 154) suggest hat "~b 2, a X2-1ike statistic, seems to be a particularlygood choice because it makes good use of the off-diagonal cells" in the contingencytable.10 At  least  for my cur rent  very  ineff ic ient imp lementat ion .232Melamed Models of Translational EquivalenceTable 2A co-occurrence ontingency table.u -~u Totalv cooc( u,v)~v cooc(u,~v) cooc(-~u,-~v) cooc(.,~v)Total cooc(-,u,.)
II cooc(.,.
)In informal experiments described elsewhere (Melamed 1995), I found that theG 2 statistic suggested by Dunning (1993) slightly outperforms ?2.
Let the cells of thecontingency table be named as follows:Now,Ilul ulv a b~v c dB(a\[a + b, pl)B(c\[c + d, p2) (27)G2(u,v) = -2log B(al a + b,p)B(c\[c + d,p)where B(kln, p) = (nk)pk(1--p)n--k are binomial probabilities.
The statistic uses maximumlikelihood estimates for the probability parameters: Pl = ~'a p2 = 74-d'c P -  a+b+c+a'a+cG 2 is easy to compute because the binomial coefficients in the numerator and in thedenominator cancel each other out.
All my methods initialize the parameters score(u, v)to G2(u,v), except hat any pairing with NULL is initialized to an infinitesimal value.I have also found it useful to smooth the co-occurrence ounts, e.g., using the SimpleGood-Turing smoothing method (Gale and Sampson 1995), before computing G2.5.1.2 Step 2: Estimation of Link Counts.
To further reduce the complexity of esti-mating link counts, I employ the competitive linking algorithm, which is a greedyapproximation to the MAP approximation:1.
Sort all the score(u, v) from highest o lowest.2.
For each score(u, v), in order:(a)(b)If u (resp., v) is NULL, consider all tokens of v (resp., u) in thebitext linked to NULL.
Otherwise, link all co-occurring tokenpairs (u, v) in the bitext.The one-to-one assumption implies that linked words cannot belinked again.
Therefore, remove all linked word tokens fromtheir respective halves of the bitext.The competitive linking algorithm can be viewed as a heuristic search for the mostlikely assignment in the space of all possible assignments.
The heuristic is that themost likely assignments contain links that are individually the most likely.
The searchproceeds by a process of elimination.
In the first search iteration, all the assignmentsthat do not contain the most likely link are discarded.
In the second iteration, allthe assignments hat do not contain the second most likely link are discarded, and233Computational Linguistics Volume 26, Number 2so on until only one assignment remains, u The algorithm greedily selects the mostlikely links first, and then selects less likely links only if they don't conflict withprevious elections.
The probability of a link being rejected increases with the numberof links that are selected before it, and thus decreases with the link's score.
In thisproblem domain, the competitive linking algorithm usually finds one of the mostlikely assignments, asI will show in Section 6.
Under an appropriate hashing scheme,the expected running time of the competitive linking algorithm is linear in the size ofthe input bitext.The competitive linking algorithm and its one-to-one assumption are potent weap-ons against he ever-present sparse data problem.
They enable accurate stimationof translational distributions even for words that occur only once, as long as thesurrounding words are more frequent.
In most translation models, link scores arecorrelated with co-occurrence frequency.
So, links between tokens u and v for whichscore(u, v) is highest are the ones for which there is the most evidence, and thus also theones that are easiest to predict correctly.
Winner-take-all link assignment methods, uchas the competitive linking algorithm, can prevent links based on indirect associations(see Section 4.2), thereby leveraging their accuracy on the more confident links toraise the accuracy of the less confident links.
For example, suppose that ul and u2co-occur with vl and v2 in the training data, and the model estimates score(u1, vl) --.05, score (ul, v2) = .02, and score(u2, v2) = .01.
According to the one-to-one assumption,(Ul, v2) is an indirect association and the correct ranslation of v2 is u2.
To the extent hatthe one-to-one assumption is valid, it reduces the probability of spurious links for therarer words.
The more incorrect candidate translations can be eliminated for a givenrare word, the more likely the correct ranslation is to be found.
So, the probability ofa correct match for a rare word is proportional to the fraction of words around it thatcan be linked with higher confidence.
This fraction is largely determined by two bitextproperties: the distribution of word frequencies, and the distribution of co-occurrencecounts.
Melamed (to appear) explores these properties in greater depth.5.1.3 Step 3: Reestimation of the Model Parameters.
Method A reestimates the scoreparameters a the logarithm of the trans parameters.
The competitive linking algorithmonly cares about he relative magnitudes ofthe various core(u, v).
However, Equation 26is a sum rather than a product, so I scale the trans parameters logarithmically, to beconsistent with its probabilistic interpretation:scoreA(u, v) = log trans(u, v) (28)5.2 Method B: Improved Estimation Using an Explicit Noise ModelYarowsky (1993, 271) has shown that "for several definitions of sense and collocation,an ambiguous word has only one sense in a given collocation with a probability of90-99%."
In other words, a single contextual c ue can be a highly reliable indicator ofa word's sense.
One of the definitions of "sense" studied by Yarowsky was a wordtoken's translation i the other half of a bitext.
For example, the English word sentencemay be considered to have two senses, corresponding to its French translations peine(judicial sentence) and phrase (grammatical sentence).
If a token of sentence occurs inthe vicinity of a word like jury or prison, then it is far more likely to be translatedas peine than as phrase.
"In the vicinity of" is one kind of collocation.
Co-occurrence11 The competitive linking algorithm can be generalized to stop searching before the number of possibleassignments i  reduced to one, at which point the link counts can be computed as probabilisticallyweighted averages over the remaining assignments.
I use this method to resolve ties.234Melamed Models of Translational Equivalence700 I I J P I I I I I600500 GI.---~ 400O~300EC200100cooc(u ,v )  = 8cooc(u,v) = 9 /cooc(u,v) = 12 /cooc(u,v) = 16PI I I I I I I I I0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9links(u,v) / cooc(u, v)Figure 2The ratio links(u, v)/cooc(u, v), for several values of cooc(u, v).in bitext space is another kind of collocation.
If each word's translation is treated asa sense tag (Resnik and Yarowsky 1997), then "translational" collocations have theunique property that the collocate and the word sense are one and the same!Method B exploits this property under the hypothesis that "one sense per collo-cation" holds for translational collocations.
This hypothesis implies that if u and vare possible mutual translations, and a token u co-occurs with a token v in the bitext,then with very high probability the pair (u, v) was generated from the same conceptand should be linked.
To test this hypothesis, I ran one iteration of Method A on300,000 aligned sentence pairs from the Canadian Hansards bitext.
I then plotted thelinks(u,v) ratio ~ for several values of cooc(u, v) in Figure 2.
The curves show that the ratiolinks(u,v) cooc(u,v) tends to be either very high or very low.
This bimodality is not an artifactof the competitive linking process, because in the first iteration, linking decisions arebased only on the initial similarity metric.Information about how often words co-occur without being linked can be used tolinks(u,v) bias the estimation of translation model parameters.
The smaller the ratio cooc(u,v), themore likely it is that u and v are not mutual translations, and that links posited betweentokens of u and v are noise.
The bias can be implemented via auxiliary parametersthat model the curve illustrated in Figure 2.
The competitive linking algorithm createsall the links of a given type independently of each other.
12 So, the distribution ofthe number links(u, v) of links connecting word types u and v can be modeled by abinomial distribution with parameters cooc(u, v) and p(u, v).
p(u, v) is the probability12 Except for the case when mult iple tokens of the same word type occur near each other, which I herebysweep under  the carpet.235Computational Linguistics Volume 26, Number 2Table 3Variables used to describe Method B.links (u, v)B(kIn, p).~+TKN= the number of times that u and v are hypothesized toco-occur as mutual translations= probability of k being generated from a binomial distributionwith parameters n and p= probability of a link given mutual translations= probability of a link given not mutual translations= probability of a link= probability of mutual translations= total number of links in the bitext= total number of co-occurrences in the bitextthat u and v will be linked when they co-occur.
There is never enough data to robustlyestimate ach p parameter  separately.
Instead, I shall model  all the p's with just twoparameters.
For u and v that are mutual  translations, p(u, v) will average to a relativelyhigh probability, which I will call ~+.
for u and v that are not mutual  translations,p(u, v) will average to a relatively low probability, which I will call ),-.
~+ and ,k-links(u,v) correspond to the two peaks of the distribution cooc(u,v), which is il lustrated in Figure 2.The two parameters can also be interpreted as the rates of true and false positives.
Ifthe translation in the bitext is consistent and the translation model  is accurate, then~+ will be close to one and ,~- will be close to zero.To find the most likely values of the auxil iary parameters ,k+ and )~-, I adopt thestandard method of max imum likelihood estimation, and find the values that maxi-mize the probabil ity of the link frequency distributions, under the usual independenceassumptions:Pr(linkslm?del) = H Pr(links(u, v)Icooc(u, v), ~+, k-) (29)tlIVTable 3 summarizes the variables involved in this auxil iary estimation process.The factors on the right-hand side of Equation 29 can be written explicitly withthe help of a mixture coefficient.
Let ~- be the probabil ity that an arbitrary co-occurringpair of word types are mutual  translations.
Let B(kln, p) denote the probabil ity that klinks are observed out of n co-occurrences, where k has a binomial distribution withparameters n and p. Then the probabil ity that word types u and v will be linkedlinks(u, v) times out of cooc(u, v) co-occurrences is a mixture of two binomials:Pr(links(u, v)Icooc(u, v), ,k +, )~-) = TB(links(u, v)Icooc(u, v), )~+)+ (1 - ~-)B(links(u,v)lcooc(u,v ),A-).
(30)One more variable allows us to express -r in terms of A + and ~-:  Let )~ be theprobabil ity that an arbitrary co-occuring pair of word tokens will be linked, regardlessof whether they are mutual  translations.
Since ~- is constant over all word types, italso represents the probabil ity that an arbitrary co-occurring pair of word tokens aremutual  translations.
Therefore,= ~-~+ + (1 - T))~-.
(31)), can also be estimated empirically.
Let K be the total number  of links in the bitext236Melamed Models of Translational Equivalence._.~ -1.2 -E._=-1.4~D "G?E -1.6c~-1.8 0 e%oo JGoo ooo2 _o.
_0.75 0.8 0.85 0.9 0.95 0.01 0.008 ~--Figure 3Pr(linkslmodel), asgiven in Equation 29, has only one global maximum in the region ofinterest, where 1 > ),+ > ,~ > ,~- > 0.and let N be the total number of word token pair co-occurrences:K = Z links(u, v), (32)u,vN = ~ cooc(u, v).
(33)U,VBy definition,A = K/N.
(34)Equating the right-hand sides of Equations 31 and 34 and rearranging the terms, weget:K/N-  A- (35)Since r is now a function of )~+ and )~-, only the latter two variables represent degreesof freedom in the model.In the preceding equations, either u or v can be NULL.
However, the numberof times that a word co-occurs with NULL is not an observable feature of bitexts.To make sense of co-occurrences with NULL ,  we can view co-occurrences a potentiallinks and cooc(u, v) as the maximum number of times that tokens of u and v mightbe linked.
From this point of view, cooc(u, NULL) should be set to the unigram fre-quency of u, since each token of u represents one potential link to NULL.
Similarly forcooc( NULL, V).
These co-occurrence counts should be summed together with all theothers in Equation 33.The probability function expressed by Equations 29 and 30 may have many localmaxima.
In practice, these local maxima are like pebbles on a mountain, invisible atlow resolution.
I computed Equation 29 over various combinations of A + and A- afterone iteration of Method A over 300,000 aligned sentence pairs from the CanadianHansard bitext.
Figure 3 illustrates that the region of interest in the parameter space,where 1 > A + > )~ > )~- > 0, has only one dominant global maximum.
This globalmaximum can be found by standard hill-climbing methods, as long as the step size islarge enough to avoid getting stuck on the pebbles.237Computational Linguistics Volume 26, Number 2Given estimates for A + and A-, we can compute B(links(u,v)\[cooc(u,v), A +) andB(links(u, v)\[cooc(u, v), A-) for each occurring combination of links and cooc values.These are the probabilities that links (u, v) links were generated out of cooc(u, v) possiblelinks by a process that generates correct links and by a process that generates incorrectlinks, respectively.
The ratio of these probabilities i the likelihood ratio in favor of thetypes u and v being possible mutual translations, for all u and v:B(links(u, v)\[cooc(u, v), A +)scoreB(u, v) = log B(links(u, v)Icooc(u, v), A-)" (36)Method B differs from Method A only in its redefinition of the score function inEquation 36.
The auxiliary parameters A + and A- and the noise model that theyrepresent can be employed the same way in translation models that are not based onthe one-to-one assumption.5.3 Method C: Improved Estimation Using Preexisting Word ClassesIn Method B, the estimation of the auxiliary parameters A + and A- depends only onthe overall distribution of co-occurrence ounts and link frequencies.
All word pairsthat co-occur the same number of times and are linked the same number of times areassigned the same score.
More accurate models can be induced by taking into accountvarious features of the linked tokens.
For example, frequent words are translated lessconsistently than rare words (Catizone, Russell, and Warwick 1989).
To account forthese differences, we can estimate separate values of A + and A- for different ranges ofcooc(u, v).
Similarly, the auxiliary parameters can be conditioned on the linked partsof speech.
A kind of word order correlation bias can be effected by conditioning theauxiliary parameters on the relative positions of linked word tokens in their respectivetexts.
Just as easily, we can model ink types that coincide with entries in an on-linebilingual dictionary separately from those that do not (cf.
Brown et al 1993).
Whenthe auxiliary parameters are conditioned on different link classes, their optimizationis carried out separately for each class:B (links (u, v)\[cooc(u, v), A +)scorec(u, vlZ = class(u, v)) = log B(links(u, v)\[cooc(u, v), A z)" (37)Section 6.1.1 describes the link classes used in the experiments below.6.
Evaluation6.1 Evaluation at the Token LevelThis section compares translation model estimation methods A, B, and C to each otherand to Brown et al's (1993b) Model 1.
To reiterate, Model 1 is based on co-occurrenceinformation only; Method A is based on the one-to-one assumption; Method B adds the"one sense per collocation" hypothesis to Method A; Method C conditions the auxiliaryparameters of Method B on various word classes.
Whereas Methods A and B andModel 1 were fully specified in Section 4.3.1 and Section 5, the latter section describeda variety of features on which Method C might classify links.
For the purposes ofthe experiments described in this article, Method C employed the simple classificationin Table 4 for both languages in the bitext.
All classification was performed by tablelookup; no context-aware part-of-speech tagger was used.
In particular, words thatwere ambiguous between open classes and closed classes were always deemed to be inthe closed class.
The only language-specific knowledge involved in this classification238Melamed Models of Translational EquivalenceTable 4Word classes used by Method C for the experiments described in this article.Link classes were constructed by taking the cross-product of the word classes.Class Code DescriptionEOSEOPSCMSYMNUCFEnd-Of-Sentence punctuationEnd-Of-Phrase punctuation, such as commas and colonsSubordinate Clause Markers, such as " and (Symbols, such as ~ and *the NULL word, in a class by itselfContent words: nouns, adjectives, adverbs, non-auxiliary verbsall other words, i.e., function wordsmethod is the list of function words in class F. Certainly, more sophisticated wordclassification methods could produce better models, but even the simple classificationin Table 4 should suffice to demonstrate the method's potential.6.1.1 Experiment 1.
Until now, translation models have been evaluated either sub-jectively (e.g.
White and O'Connell 1993) or using relative metrics, such as perplex-ity with respect o other models (Brown et al 1993b).
Objective and more accuratetests can be carried out using a "gold standard."
I hired bilingual annotators to linkroughly 16,000 corresponding words between on-line versions of the Bible in Frenchand English.
This bitext was selected to facilitate widespread use and standardiza-tion (see Melamed \[1998c\] for details).
The entire Bible bitext comprised 29,614 versepairs, of which 250 verse pairs were hand-linked using a specially developed anno-tation tool.
The annotation style guide (Melamed 1998b) was based on the intuitionsof the annotators, o it was not biased towards any particular translation model.
Theannotation was replicated five times by seven different annotators.Each of the four methods was used to estimate a word-to-word translation modelfrom the 29,614 verse pairs in the Bible bitext.
All methods were deemed to haveconverged when less than .0001 of the translational probability distribution changedfrom one iteration to the next.
The links assigned by each of methods A, B, and C in thelast iteration were normalized into joint probability distributions using Equation 19.
Ishall refer to these joint distributions as Model A, Model B, and Model C, respectively.Each of the joint probability distributions was further normalized into two conditionalprobability distributions, one in each direction.
Since Model 1 is inherently directional,its conditional probability distributions were estimated separately in each direction,instead of being derived from a joint distribution.The four models' predictions were compared to the gold standard annotations.Each model guessed one translation (either stochastically or deterministically, depend-ing on the task) for each word on one side of the gold standard bitext.
Therefore,precision = recall here, and I shall refer to the results simply as "percent correct."
Theaccuracy of each model was averaged over the two directions of translation: English toFrench and French to English.
The five-fold replication of annotations in the test dataenabled computation of the statistical significance of the differences in model accuracy.The statistical significance of all results in this section was measured at the c~ -- .05level, using the Wilcoxon signed ranks test.
Although the models were evaluated onpart of the same bitext on which they were trained, the evaluations were with respectto the translational equivalence relation hidden in this bitext, not with respect o anyof the bitext's visible features.
Such testing on training data is standard practice for239Computational Linguistics Volume 26, Number 2unsupervised learning algorithms, where the objective is to compare several methods.Of course, performance would degrade on previously unseen data.In addition to the different translation models, there were two other independentvariables in the experiment: method of translation and whether function words wereincluded.
Some applications, uch as query translation for CLIR, don't care about func-tion words.
To get a sense of the relative ffectiveness of the different translation modelestimation methods when function words are taken out of the equation, I removedfrom the gold standard all link tokens where one or both of the linked words wereclosed-class words.
Then, I removed all closed-class words (including nonalphabeticsymbols) from the models and renormalized the conditional probabilities.The method of translation was either single-best or whole distribution.
Single-best translation is the kind that somebody might use to get the gist of a foreign-language document.
The input to the task was one side of the gold standard bitext.The output was the model's ingle best guess about the translation of each word inthe input, together with the input word.
In other words, each model produced linktokens consisting of input words and their translations.
For some applications, it isinsufficient to guess only the single most likely translation of each word in the input.The model is expected to output the whole distribution of possible translations foreach input word.
This distribution is then combined with other distributions that arerelevant to the application.
For example, for cross-language information retrieval, thetranslational distribution can be combined with the distribution of term frequencies.For statistical machine translation, the translational distribution can be decoded witha source language model (Brown et al 1988; A1-Onaizan et al 1999).
To predict howthe different models might perform in such applications, the whole distribution taskwas to generate a whole set of links from each input word, weighted according tothe probability assigned by the model to each of the input word's translations.
Eachmodel was tested on this task with and without function words.The mean results are plotted in Figures 4 and 5 with 95% confidence intervals.All four graphs in these figures are on the same scale to facilitate comparison.
Onboth tasks involving the entire vocabulary, each of the biases presented in this articleimproves the efficiency of modeling the available training data.
When closed-classwords were ignored, Model 1 performed better than Method A, because open-classwords are more likely to violate the one-to-one assumption.
However, the explicit noisemodel in Methods B and C boosted their scores ignificantly higher than Model 1 andMethod A.
Method B was better than Method C at choosing the single best open-classlinks, and the situation was reversed for the whole distribution of open-class links.However, the differences in performance between these two methods were tiny onthe open-class tasks, because they left only two classes for Method C to distinguish:content words and NULLS.
Most of the scores on the whole distribution task were lowerthan their counterparts on the single-best translation task, because it is more difficultfor any statistical method to correctly model the less common translations.
The "best"translations are usually the most common.6.1.2 Experiment 2.
To study how the benefits of the various biases vary with trainingcorpus size, I evaluated Models A, B, C, and 1 on the whole distribution translationtask, after training them on three different-size subsets of the Bible bitext.
The firstsubset consisted of only the 250 verse pairs in the gold standard.
The second subsetincluded these 250 plus another andom sample of 2,250 for a total of 2,500, an orderof magnitude larger than the first subset.
The third subset contained all 29,614 versepairs in the Bible bitext, roughly an order of magnitude larger than the second subset.All models were compared to the five gold standard annotations, and the scores were240Melamed Models of Translational Equivalence(a)0.5Oo?-o(1)Q.0.450.40.350.30.250.20.15................................................. t .. ...................................................} I t IModel 1 Model A Model B Model C(b)0.50.450.4'-" 0.35 O ?..)E?
0.3(3.0.250.2ii t0.15 ' ' ' 'Model 1 Model A Model B Model CFigure 4Comparison of model performance on single-best translation task.
(a) All links; (b) open-classlinks only.241Computational Linguistics Volume 26, Number 2(a)0.5(b)0.450.4"6'- 0.35 OoE~ 0.30.250.20.150.5.......................................... i ...................tI I I IModel 1 Model A Model B Model C0.450.4*5"- 0.35 OoE0.3 o0.250.20.15 ' ' ' 'Model 1 Model A Model B Model CFigure 5Comparison of model performance on whole distribution task.
(a) All links; (b) open-classlinks only.242Melamed Models of Translational EquivalenceoOoc-oo)f3..0.40.350.30.250.20 .150.10.050................ / / / /Mode l  C ,Mode l  B .
.
.
.
.
.
.
.
.Mode l  A ..... ?
.....?
Mode l  1 ......... ~ .........250 2500number  of t ra in ing verse  pairs  (on log scale)Figure 6Effects of training set size on model accuracy on the whole distribution task.29614averaged over the two directions of translation, as before.
Again, because the totalprobability assigned to all translations for each source word was one, precision =recall = percent correct on this task.
The mean scores over the five gold standardannotations are graphed in Figure 6, where the right edge of the figure corresponds tothe means of Figure 5(a).
The figure supports the hypothesis n Melamed (to appear,Chapter 7) that the biases presented in this article are even more valuable when thetraining data are more sparse.
The one-to-one assumption is useful, even though itforces us to use a greedy approximation to maximum likelihood.
In relative terms,the advantage of the one-to-one assumption is much more pronounced on smallertraining sets.
For example, Model A is 102% more accurate than Model I when trainedon only 250 verse pairs.
The explicit noise model buys a considerable gain in accuracyacross all sizes of training data, as do the link classes of Model C. In concert, whentrained and tested only on the gold standard test set, the three biases outperformedModel 1 by up to 125%.
This difference is even more significant given the absoluteperformance ceiling of 82% established by the interannotator agreement rates on thegold standard.6.2 Evaluation at the Type LevelAn important application of statistical translation models is to help lexicographerscompile bilingual dictionaries.
Dictionaries are written to answer the question, "Whatare the possible translations of X?"
This is a question about link types, rather thanabout link tokens.Evaluation by link type is a thorny issue.
Human judges often disagree about thedegree to which context should play a role in judgments of translational equivalence.For example, the Harper-Collins French Dictionary (Cousin et al 1990) gives the followingFrench translations for English appoint: nommer, engager, fixer, d~signer.
Likewise, most243Computational Linguistics Volume 26, Number 210000010000Q)o 1000C~oC o 100oo~ 100~ 3 / 3Figure 72/21/1.1 I I0 30000 60000entry numberC_90000Distribution of link type scores.
The long plateaus correspond to the most commonli,k~(u,v).
1/1,2/2, and 3/3.
combinations of cooc ) ?lay judges would not consider instituer a correct French translation of appoint.
In actualtranslations, however, when the object of the verb is commission, task force, panel, etc.,English appoint is usually translated into French as instituer.
To account for this kind ofcontext-dependent translational equivalence, link types must be evaluated with respectto the bitext whence they were induced.I performed a post hoc evaluation of the link types produced by an earlier versionof Method B (Melamed 1996b).
The bitext used for this evaluation was the same alignedHansards bitext used by Gale and Church (1991), except hat I used only 300,000aligned segment pairs to save time.
The bitext was automatically pretokenized todelimit punctuation, English possessive pronouns, and French elisions.
Morphologicalvariants in both halves of the bitext were stemmed to a canonical form.The link types assigned by the converged model were sorted by the scores inEquation 36.
Figure 7 shows the distribution of these scores on a log scale.
The logscale helps to illustrate the plateaus in the curve.
The longest plateau represents heset of word pairs that were linked once out of one co-occurrence (1/1) in the bitext.All these word pairs were equally likely to be correct.
The second-longest plateauresulted from word pairs that were linked twice out of two co-occurrences (2/2) andthe third longest plateau is from word pairs that were linked three times out of threeco-occurrences (3/3).
As usual, the entries with higher scores were more likely to becorrect.
By discarding entries with lower scores, coverage could be traded for accuracy.This trade-off was measured at three points, representing cutoffs at the end of each ofthe three longest plateaus.The traditional method of measuring coverage requires knowledge of the correctlink types, which is impossible to determine without a gold standard.
An approximatecoverage measure can be based on the number of different words in the corpus.
For244Melamed Models of Translational EquivalenceTable 5Lexicon coverage at three different minimum score thresholds.
The bitextcontained 41,028 different English words and 36,314 different Frenchwords, for a total of 77,342.Total English FrenchCutoff Minimum Lexicon Words WordsPlateau Score Entries Represented % Represented %3/3 28 32,274 14,299 35 13,409 372/2 18 43,075 18,533 45 1Z133 471/1 9 88,633 36,371 89 33,017 91lexicons extracted from corpora, perfect coverage implies at least one entry containingeach word in the corpus.
One-sided variants, which consider only source words, havealso been used (Gale and Church 1991).
Table 5 shows both the marginal (one-sided)and the combined coverage at each of the three cutoff points.
It also shows the absolutenumber of (non-NULL) entries in each of the three lexicons.
Of course, the size ofautomatically induced lexicons depends on the size of the training bitext.
Table 5shows that, given a sufficiently large bitext, the method can automatically constructtranslation lexicons with as many entries as published bilingual dictionaries.The next task was to measure accuracy.
It would have taken too long to evaluateevery lexicon entry manually.
Instead, I took five random samples (with replacement)of 100 entries each from each of the three lexicons.
Each of the samples was first com-pared to a translation lexicon extracted from a machine-readable ilingual dictionary(Cousin et al 1991).
All the entries in the sample that appeared in the dictionary wereassumed to be correct.
I checked the remaining entries in all the samples by hand.
Toaccount for context-dependent translational equivalence, I evaluated the accuracy ofthe translation lexicons in the context of the bitext whence they were extracted, usinga simple bilingual concordancer.
A lexicon entry (u,v) was considered correct if u andv ever appeared as direct translations of each other in an aligned segment pair.
Thatis, a link type was considered correct if any of its tokens were correct.Direct translations come in different flavors.
Most entries that I checked by handwere of the plain vanilla variety that you might find in a bilingual dictionary (entrytype V).
However, a significant munber of words translated into a different part ofspeech (entry type P).
For instance, in the entry (protection, prot6g6), the English wordis a noun but the French word is an adjective.
This entry appeared because to haveprotection is often translated as ~tre prot~g~ ('to be protected') in the bitext.
The entrywill never occur in a bilingual dictionary, but users of translation lexicons, be theyhuman or machine, will want to know that translations often happen this way.The evaluation of translation models at the word type level is complicated by thepossibility of phrasal translations, such as imm~diatement ~-~ right away.
All the methodsbeing evaluated here produce models of translational equivalence between individualwords only.
How can we decide whether asingle-word translation "matches" a phrasaltranslation?
The answer lies in the observation that corpus-based lexicography usuallyinvolves alexicographer.
Bilingual lexicographers can work with bilingual concordanc-ing software that can point them to instances of any link type induced from a bitextand display these instances sorted by their contexts (e.g.
Simard, Foster, and Perrault1993).
Given an incomplete link type, the lexicographer can usually reconstruct thecomplete link type from the contexts in the concordance.
For example, if the modelproposes an equivalence between immddiatement and right, a bilingual concordance245Computational Linguistics Volume 26, Number 2Table 6Distribution of different ypes of correct lexicon entries at varying levels ofcoverage (mean + standard eviation).Cutoff Coverage % Type V % Type P % Type I Total % Accuracy3/3 36% 89 4- 2.2 3.4 :E 0.5 7.6 + 3.2 99,2 4- 0.82/2 46% 81 4- 3.0 8.0 ::E 2.1 9.8 + 1.8 99.0 4- 1.41/1 90% 82 + 2.5 4.4 + 0.5 6.0 + 1.9 92.8 + 1.1can show the lexicographer that the model  was really trying to capture the equiva-lence between imm#diatement and right away or between imm#diatement and right now.I counted incomplete ntries in a third category (entry type I).
Whether links in thiscategory should be considered correct depends on the application.Table 6 shows the distribution of correct lexicon entries among the types V, P and I.Figure 8 graphs the accuracy of the method against coverage, with 95% confidenceintervals.
The upper  curve represents accuracy when incomplete links are consideredcorrect, and the lower when they are considered incorrect.
On the former metric, themethod can generate translation lexicons with accuracy and coverage both exceeding90%, as well as dictionary-size translation lexicons that are over 99% correct.7.
ConclusionThere are many ways to model  translational equivalence and many ways to estimatetranslation models.
"The mathematics of statistical machine translation" proposed byBrown et al (1993b) are just one kind of mathematics for one kind of statistical trans-1009896>,o 94o 9290888684(99.2%) 0%)rrlct~ ( 9 2 .
8 % )(91.6%) t"-..incomplete : in-correct ........... t(86.8%)- -  I I I36 46 90% coverageFigure 8Translation lexicon accuracy with 95% confidence intervals at varying levels of coverage.246Melamed Models of Translational Equivalencelation.
In this article, I have proposed and evaluated new kinds of translation modelbiases, alternative parameter estimation strategies, and techniques for exploiting pre-existing knowledge that may be available about particular languages and languagepairs.
On a variety of evaluation metrics, each infusion of knowledge about the prob-lem domain resulted in better translation models.Each innovation presented here opens the way for more research.
Model biases canbe mixed and matched with each other, with previously published biases like the wordorder correlation bias, and with other biases yet to be invented.
The competitive linkingalgorithm can be generalized in various ways.
New kinds of preexisting knowledgecan be exploited to improve accuracy for particular language pairs or even just forparticular bitexts.
It is difficult to say where the greatest advances will come from.
Yet,one thing is clear from our current vantage point: Research on empirical methods formodeling translational equivalence has not run out of steam, as some have claimed,but has only just begun.AcknowledgmentsMuch of this research was performed at theDepartment of Computer and InformationScience at the University of Pennsylvania,where it was supported by an equipmentgrant from Sun MicroSystems Laboratoriesand by ARPA Contract#N66001-94C-6043.
Many thanks to myformer colleagues at UPenn and to theanonymous reviewers for their insightfulsuggestions for improvement.ReferencesAbeillG Anne, Yves Schabes, and AravindK.
Joshi.
1990.
Using lexicalized treeadjoining rammars for machinetranslation.
In Proceedings ofthe 13thInternational Conference on ComputationalLinguistics.
Helsinki, Finland.Ahuja, Ravindra K., Thomas L. Magnati,and James B. Orlin.
1993.
Network Flows:Theory, Algorithms, and Applications.Prentice Hall, Englewood Cliffs, NJ.A1-Onaizan, Yaser, Jan Curin, Michael Jahr,Kevin Knight, John Lafferty, I. DanMelamed, Franz J. Och, David Purdy,Noah A. Smith, and David Yarowsky.1999.
Statistical machine translation.
CLSPTechnical Report.
Baltimore, MD.Available at www.clsp.jhu.edu/ws99/projects/mt/final_report/mt-final-report.psBrousseau, Julie, Caroline Drouin, GeorgeFoster, Pierre Isabelle, Roland Kuhn, YvesNormandin, and Pierre Plamondon.
1995.French speech recognition i  an automaticdictation system for translators: TheTransTalk project.
In Proceedings ofEuroSpeech'95, pages 193-196, Madrid,Spain.Brown, Peter F., John Cocke, Stephen A.Della Pietra, Vincent J. Della Pietra,Fredrick Jelinek, Robert L. Mercer, andPaul Roossin.
1988.
A statistical approachto language translation.
In Proceedings ofthe 12th International Conference onComputational Linguistics, pages 71-76,Budapest, Hungary.Brown, Peter F., Stephen A. Della Pietra,Vincent J. Della Pietra, Meredith J.Goldsmith, Jan Hajic, Robert L. Mercerand Surya Mohanty.
1993a.
Butdictionaries are data too.
In Proceedings ofthe ARPA HLT Workshop, ages 202-205,Princeton, NJ.Brown, Peter F., Stephen A. Della Pietra,Vincent J. Della Pietra, and Robert L.Mercer.
1993b.
The mathematics ofstatistical machine translation: Parameterestimation.
Computational Linguistics19(2):263-311.Buckley, Chris.
1993.
The importance ofproper weighting methods.
In Proceedingsof the DARPA Workshop on Human LanguageTechnology, pages 349-352, Princeton, NJ.Candito, Marie?H~l~ne.
1998.
Buildingparallel LTAG for French and Italian.
InCOLING-ACL "98:36 Annual Meeting of theAssociation for Computational Linguistics and17th International Conference onComputational Linguistics, pages 211-217,Montreal, Canada.Catizone, Roberta, Graham Russell, andSusan Warwick.
1989.
Derivingtranslation data from bilingual texts.
InProceedings ofthe First International LexicalAcquisition Workshop.
Detroit, MI.Church, Kenneth W., and Eduard H. Hovy.1993.
Good applications for crummymachine translation.
Machine Translation 8.Cousin, Pierre-Henri, Lorna Sinclair,Jean-Francois Allain, and Catherine E.Love.
1990.
The Harper Collins FrenchDictionary.
Harper Collins Publishers,247Computational Linguistics Volume 26, Number 2New York, NY.Cousin, Pierre-Henri, Lorna Sinclair,Jean-Francois Allain, and Catherine E.Love.
1991.
The Collins Paperback FrenchDictionary.
Harper Collins Publishers,Glasgow.Dagan, Ido, Kenneth W. Church, andWilliam A. Gale.
1993.
Robust wordalignment for machine aided translation.In Proceedings ofthe Workshop on Very LargeCorpora: Academic and IndustrialPerspectives, pages 1-8, Columbus, OH.Daille, B~atrice, l~ric Gaussier, andJean-Marc Lang4.
1994.
Towardsautomatic extraction of monolingual andbilingual terminology.
Proceedings ofthe15th International Conference onComputational Linguistics, pages 515-521,Kyoto, Japan.Deming, W. Edwards, and Frederick F.Stephan.
1940.
On a least squaresadjustment of a sampled frequency tablewhen the expected marginal totals areknown.
The Annals of MathematicalStatistics, 11:42~444.Dempster, Arthur P., N. M. Laird, andDonald B. Rubin.
1977.
Maximumlikelihood from incomplete data via theEM algorithm.
Journal of the RoyalStatistical Society, 39(B):1-38.Dorr, Bonnie J.
1992.
The use of lexicalsemantics in interlingual machinetranslation.
Machine Translation,7(3):135-193.Dunning, Ted.
1993.
Accurate methods forthe statistics of surprise and coincidence.Computational Linguistics 19(1):61-74.Fellbaum, Christiane, editor.
1998.
WordNet:An Electronic Lexical Database.
MIT Press.Foster, George, Pierre Isabelle, and PierrePlamondon.
1996.
Word completion: Afirst step toward target-text mediatedIMT.
In Proceedings ofthe 16th InternationalConference on Computational Linguistics,pages 394-399, Copenhagen, Denmark.Fung, Pascale.
1995.
A pattern matchingmethod for finding noun and propernoun translations from noisy parallelcorpora.
In Proceedings ofthe 33rd AnnualMeeting, pages 236-243, Boston, MA.Association for ComputationalLinguistics.Gale, William A., and Kenneth W. Church.1991.
Identifying word correspondencesin parallel texts.
Proceedings ofthe DARPASNL Workshop, pages 152-157, Asilomar,CA.Gale, William A., and Geoff Sampson.
1995.Good-Turing frequency estimationwithout tears.
Journal of QuantitativeLinguistics, 2:217-237.
Swets & ZeitlingerPublishers, Sassenheim, The Netherlands.Hiemstra, Djoerd.
1996.
Using StatisticalMethods to Create a Bilingual Dictionary.Masters thesis, University of Twente, TheNetherlands.Hiemstra, Djoerd.
1998.
Multilingualdomain modeling in twenty-one:Automatic reation of a bi-directionaltranslation lexicon from a parallel corpus.In Proceedings ofthe Eighth meeting ofComputational Linguistics in the Netherlands(CLIN), pages 41-58.Kumano, Akira, and Hideki Hirakawa.
1994.Building an MT dictionary from paralleltexts based on linguistic and statisticalinformation.
In Proceedings ofthe 15thInternational Conference on ComputationalLinguistics, pages 76-81, Kyoto, Japan.McCarley, J. Scott.
1999.
Should we translatethe documents or the queries incross-language information retrieval?
InProceedings ofthe 37th Annual Meeting,pages 208-214, College Park, MD.Association for ComputationalLinguistics.Macklovitch, Elliott.
1994.
Using bi-textualalignment for translation validation: TheTransCheck system.
In Proceedings ofthe1st Conference ofthe Association for MachineTranslation in the Americas, pages 157-168.Columbia, MD.Melamed, I. Dan.
1995.
Automaticevaluation and uniform filter cascades forinducing N-best translation lexicons.
InProceedings ofthe Third Workshop on VeryLarge Corpora, pages 184-198, Cambridge,MA.Melamed, I. Dan.
1996a.
Automaticdetection of omissions in translations.
InProceedings ofthe 16th InternationalConference on Computational Linguistics,pages 764-769, Copenhagen, Denmark.Melamed, I. Dan.
1996b.
Automaticconstruction of clean broad-coveragetranslation lexicons.
In Proceedings ofthe2nd Conference ofthe Association for MachineTranslation in the Americas, pages 125-134,Montreal, Canada.Melamed, I. Dan.
1998a.
Models ofco-occurrence.
Institute for Research inCognitive Science Technical Report#98-05.
University of Pennsylvania,Philadelphia, PA.Melamed, I. Dan.
1998b.
Annotation styleguide for the blinker project.
Institute forResearch in Cognitive Science TechnicalReport #98-06.
University ofPennsylvania, Philadelphia, PA.Melamed, I. Dan.
1998c.
Manual annotationof translational equivalence: The blinkerproject.
Institute for Research in Cognitive248Melamed Models of Translational EquivalenceScience Technical Report #98-07.University of Pennsylvania, Philadelphia,PA.Melamed, I. Dan.
To appear.
EmpiricalMethods for Exploiting Parallel Texts, MITPress.Nerbonne, John, Lauri Karttunen, ElenaPaskaleva, Gabor Proszeky, and TiitRoosmaa.
1997.
Reading more intoforeign languages.
In Proceedings ofthe 5thACL Conference on Applied Natural LanguageProcessing, pages 135-138, Washington,DC.Oard, Douglas W. 1997.
Adaptive filteringof multilingual document streams.
InProceedings ofthe 5th RIAO Conference onComputer-Assisted Information Retrieval,pages 233-253, Montreal, Canada.Resnik, Philip.
1997.
Evaluating multilingualgisting of Web pages.
In Proceedings oftheAAAI Symposium on Natural LanguageProcessing for the World Wide Web.
Stanford,CA.Resnik, Philip, and David Yarowsky.
1997.A perspective on word sensedisambiguation methods and theirevaluation.
In Proceedings ofthe SIGLEXWorkshop on Tagging Text with LexicalSemantics, pages 79-86, Washington, DC.Shieber, Stuart.
1994.
Restricting theweak-generative capacity of synchronoustree-adjoining grammars.
ComputationalIntelligence, 10(4):371-385.Simard, Michel, George F. Foster, andFrancois Perrault.
1993.
TransSearch: Abilingual concordance tool.
Centred'innovation en technologies del'information, Laval, Canada.Svartvik, Jan. 1992.
Directions in CorpusLinguistics.
Mouton de Gruyter, Berlin.Vogel, Stephan, Hermann Ney, andChristoph Tillmann.
1996.
HMM-basedword alignment in statistical translation.In Proceedings ofthe 16th InternationalConference on Computational Linguistics.Copenhagen, Denmark.Piek, Vossen, editor.
1998.
Eurowordnet: AMultilingual Database with Lexical SemanticNetworks.
Kluwer Academic Publishers.White, John S., and Theresa A. O'Connell.1993.
Evaluation of machine translation.In Proceedings ofthe ARPA HLT Workshop,pages 206-210, Princeton, NJ.Wu, Dekai, and Xuanyin Xia.
1994.
Learningan English-Chinese l xicon from aparallel corpus.
In Proceedings ofthe FirstConference ofthe Association for MachineTranslation i  the Americas, pages 206-213,Columbia, MD.Yarowsky, David.
1993.
One sense percollocation.
In Proceedings ofthe DARPAWorkshop on Human Language Technology,pages 266-271, Princeton, NJ.249
