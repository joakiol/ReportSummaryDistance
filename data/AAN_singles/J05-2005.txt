Representing Discourse Coherence:A Corpus-Based StudyFlorian Wolf?University of CambridgeEdward Gibson?
?Massachusetts Institute of TechnologyThis article aims to present a set of discourse structure relations that are easy to code and todevelop criteria for an appropriate data structure for representing these relations.
Discoursestructure here refers to informational relations that hold between sentences in a discourse.
Theset of discourse relations introduced here is based on Hobbs (1985).We present a method for annotating discourse coherence structures that we used to manuallyannotate a database of 135 texts from the Wall Street Journal and the AP Newswire.
All textswere independently annotated by two annotators.
Kappa values of greater than 0.8 indicatedgood interannotator agreement.We furthermore present evidence that trees are not a descriptively adequate data structure forrepresenting discourse structure: In coherence structures of naturally occurring texts, we foundmany different kinds of crossed dependencies, as well as many nodes with multiple parents.
Theclaims are supported by statistical results from our hand-annotated database of 135 texts.1.
IntroductionAn important component of natural language discourse understanding and productionis having a representation of discourse structure.
A coherently structured discourse hereis assumed to be a collection of sentences that are in some relation to each other.
Thisarticle aims to present a set of discourse structure relations that are easy to code and todevelop criteria for an appropriate data structure for representing these relations.There have been two kinds of approaches to defining and representing discoursestructure and coherence relations.
These approaches differ with respect to what kindsof discourse structure they are intended to represent.
Some accounts aim to representthe intentional-level structure of a discourse; in these accounts, coherence relationsreflect how the role played by one discourse segment with respect to the interlocu-tors?
intentions relates to the role played by another segment (e.g., Grosz and Sidner1986).
Other accounts aim to represent the informational structure of a discourse; inthese accounts, coherence relations reflect how the meaning conveyed by one discoursesegment relates to the meaning conveyed by another discourse segment (e.g., Hobbs1985; Marcu 2000; Webber et al 1999).
Furthermore, accounts of discourse structurevary greatly with respect to how many discourse relations they assume, ranging from 2(Grosz and Sidner 1986) to over 400 different coherence relations (reported in Hovy and?
Computer Laboratory and Genetics Department, Cambridge, CB3 0FD, U.K.E-mail: Florian.Wolf@cl.cam.ac.uk??
Department of Brain and Cognitive Sciences, Cambridge, MA 02139.
E-mail: egibson@mit.edu.Submission received: 15th June 2004; Revised submission received: 5th September 2004; Accepted forpublication: 23rd October 2004?
2005 Association for Computational LinguisticsComputational Linguistics Volume 31, Number 2Maier [1995]).
However, Hovy and Maier (1995) argue that, at least for informational-level accounts, taxonomies with more relations represent subtypes of taxonomies withfewer relations.
This means that different informational-level-based taxonomies can becompatible with each other; they differ with respect to how detailed or fine-grained amanner they represent informational structures of texts.
Going beyond the question ofhow different informational-level accounts can be compatible with each other, Moserand Moore (1996) discuss the compatibility of rhetorical structure theory (RST) (Mannand Thompson 1988) with the theory of Grosz and Sidner (1986).
However, note thatMoser and Moore (1996) focus on the question of how compatible the claims are thatMann and Thompson (1988) and Grosz and Sidner (1986) make about intentional-leveldiscourse structure.In this article, we aim to develop an easy-to-code representation of informationalrelations that hold between sentences or other nonoverlapping segments in a dis-course monologue.
We describe an account with a small number of relations in orderto achieve more generalizable representations of discourse structures; however, thenumber is not so small that informational structures that we are interested in areobscured.
The goal of the research presented is not to encode intentional relations intexts.
We consider annotating intentional relations too difficult to implement in practiceat this time.
Note that we do not claim that intentional-level structure of discourse isnot relevant to a full account of discourse coherence; it just is not the focus of thisarticle.The next section describes in detail the set of coherence relations we use, which aremostly based on Hobbs (1985).
We try to make as few a priori theoretical assumptionsabout representational data structures as possible.
These assumptions are outlined inthe next section.
Importantly, however, we do not assume a tree data structure torepresent discourse coherence structures.
In fact, a major result of this article is thattrees do not seem adequate to represent discourse structures.This article is organized as follows.
Section 2 describes the procedure we used tocollect a database of 135 texts annotated with coherence relations.
Section 3 describesin detail the descriptional inadequacy of tree structures for representing discoursecoherence, and Section 4 provides statistical evidence from our database that supportsthis claim.
Section 5 offers some concluding remarks.2.
Collecting a Database of Texts Annotated with Coherence RelationsThis section describes (1) how we defined discourse segments, (2) which coherencerelations we used to connect discourse segments, and (3) how the annotation procedureworked.2.1 Discourse SegmentsThere is agreement that discourse segments should be nonoverlapping spans of text.However, there is disagreement in the literature about how to define discourse segments(cf.
the discussion in Marcu [2000]).
Whereas some argue that discourse segmentsshould be prosodic units (Hirschberg and Nakatani 1996), others argue for intentionalunits (Grosz and Sidner 1986), phrasal units (Lascarides and Asher 1993; Longacre 1983;Webber et al 1999), or sentences (Hobbs 1985).For our database, we mostly adopted a clause-unit-based definition of discoursesegments.
We chose this method of segmenting discourse because it was easy to use.250Wolf and Gibson Representing Discourse CoherenceTable 1Contentful conjunctions used to illustrate coherence relations.Cause?effect because; and soViolated expectation although; but; whileCondition if .
.
.
(then); as long as; whileSimilarity and; (and) similarlyContrast by contrast; butTemporal sequence (and) then; first, second, .
.
.
; before; after; whileAttribution according to .
.
.
; .
.
.
said; claim that .
.
.
; maintain that .
.
.
; stated that .
.
.Example for example; for instanceElaboration also; furthermore; in addition; note (furthermore) that; (for, in, on, against,with, .
.
. )
which; who; (for, in, on, against, with, .
.
. )
whomGeneralization in generalHowever, we also assumed that contentful coordinating and subordinating conjunc-tions (cf.
Table 1) can delimit discourse segments.Note that we did not classify and as delimiting discourse segments if it was usedto conjoin nouns in a conjoined noun phrase, like dairy plants and dealers in example (1)(from wsj 0306; Wall Street Journal 1989 corpus [Harman and Liberman 1993]) or if itwas used to conjoin verbs in a conjoined verb phrase, like snowed and rained in example(2) (constructed):(1) Milk sold to the nation?s dairy plants and dealers averaged $14.50 for eachhundred pounds.
(2) It snowed and rained all day long.We classified periods, semicolons, and commas as delimiting discourse segments.
How-ever, in cases like example (3) (constructed), in which they conjoin a complex nounphrase, commas were not classified as delimiting discourse segments.
(3) John bought bananas, apples, and strawberries.We furthermore treated attributions (John said that .
.
.)
as discourse segments.
This wasempirically motivated.
The texts used here were taken from news corpora, and there,attributions can be important carriers of coherence structures.
For instance, consider acase in which some source A and some source B both comment on some event X. Itshould be possible to distinguish between a situation in which source A and source Bmake basically the same statement about event X and a situation in which source A andsource B make contrasting comments about event X.
Note, however, that we treatedcases like example (4) (constructed) as one discourse segment and not as two separateones ( .
.
.
cited and transaction costs .
.
.).
We separated attributions only if the attributedmaterial was a complementizer phrase, a sentence, or a group of sentences.
This is notthe case in example (4): The attributed material is a complex NP (transaction costs fromits 1988 recapitalization).
(4) The restaurant operator cited transaction costs from its 1988 recapitalization.251Computational Linguistics Volume 31, Number 22.2 Discourse Segment GroupingsAdjacent discourse segments could, in our approach, be grouped together.
For example,discourse segments were grouped if they all stated something that could be attributedto the same source (cf.
section 2.3 for a definition of attribution coherence relations).Furthermore, discourse segments were grouped if they were topically related.
Forexample, if a text discussed inventions in information technology, there could be groupsof a few discourse segments each talking about inventions by specific companies.
Theremight also be subgroups, consisting of several discourse segments each, talking aboutspecific inventions at specific companies.
Thus, marking groups could determine apartially hierarchical structure for the text.Other examples of discourse segment groupings included cases in which severaldiscourse segments described an event or a group of events that all occurred beforeanother event or another group of events described by another (group of) discoursesegments.
In those cases, what was described by a group of discourse segments was ina temporal sequence relation with what was described by another (group of) discoursesegments (cf.
section 2.3 for a definition of temporal-sequence coherence relations).
Notefurthermore that in cases in which one topic required one grouping and a followingtopic required a grouping that was different from the first grouping, both groupingswere annotated.Unlike approaches such as the TextTiling algorithm (Hearst 1997), ours allowedpartially overlapping groups of discourse segments.
The idea behind this option wasto allow groupings of discourse segments in which a transition discourse segmentbelonged to the previous as well as the following group.
However, the option was notused by the annotators (i.e., in our database of 135 hand-annotated texts, there were noinstances of partially overlapping discourse segment groups).2.3 Coherence RelationsAs pointed out in section 1, we aim to develop a representation of informationalrelations between discourse segments.
Note one difference between schema-basedapproaches (McKeown 1985) and coherence relations as we used them: Whereasschemas are instantiated from information contained in a knowledge base, coherencerelations as we used them do not make (direct) reference to a knowledge base.There are a number of different informational coherence relations, dating back, intheir basic definitions, to Hume, Plato, and Aristotle (cf.
Hobbs 1985; Hobbs et al 1993;Kehler 2002).
The coherence relations we used are mostly based on Hobbs (1985); belowwe describe each coherence relation we used and note any differences between ours andHobbs?s (1985) set of coherence relations (cf.
Table 2 for an overview of how our set ofcoherence relations relates to the set of coherence relations in Hobbs [1985]).The kinds of coherence relations we used include cause?effect relations, as inexample (5) (constructed), in which discourse segment 1 states the cause for the effectthat is stated in discourse segment 2:(5) Cause?effect1.
There was bad weather at the airport2.
and so our flight got delayed.Our cause?effect relation subsumed the cause as well as the explanation relation inHobbs (1985).
A cause relation holds if a discourse segment stating a cause occurs252Wolf and Gibson Representing Discourse Coherencebefore a discourse segment stating an effect; an explanation relation holds if a discoursesegment stating an effect occurs before a discourse segment stating a cause.
We encodedthis difference by adding a direction to the cause?effect relation.
In a graph, this can berepresented by a directed arc going from cause to effect.Another kind of causal relation is condition.
Hobbs (1985) does not distinguish con-dition relations from either cause or explanation relations.
However, we felt that it mightbe important to distinguish between a causal relation describing an actual causal event(cause?effect, cf.
above), on the one hand, and a causal relation describing a possiblecausal event (condition, cf.
below), on the other hand.
In example (6) (constructed),discourse segment 2 states an event that will take place if the event described bydiscourse segment 1 also takes place:(6) Condition1.
If the new software works,2.
everyone should be happy.In a third type of causal relation, the violated expectation relation (also violatedexpectation in Hobbs [1985]), a causal relation between two discourse segments thatnormally would be present is absent.
In example (7) (constructed), discourse segment 1normally would be a cause for everyone?s being happy; this expectation is violated bywhat is stated by discourse segment 2:(7) Violated expectation1.
The new software worked great,2.
but nobody was happy.Other possible coherence relations include similarity (parallel in Hobbs [1985]) orcontrast (also contrast in Hobbs [1985]) relations, in which similarities or contrasts aredetermined between corresponding sets of entities or events, such as between discoursesegments 1 and 2 in example (8) (constructed) and discourse segments 1 and 2 inexample (9) (constructed), respectively:(8) Similarity1.
The first flight to Frankfurt this morning was delayed.2.
The second flight arrived late as well.
(9) Contrast1.
The first flight to Frankfurt this morning was delayed.2.
The second flight arrived on time.Discourse segments might also elaborate (also elaboration in Hobbs [1985]) on othersentences, as in example (10) (constructed), in which discourse segment 2 elaborateson discourse segment 1:(10) Elaboration1.
A probe to Mars was launched from the Ukraine this week.2.
The European-built ?Mars Express?
is scheduled to reach Mars bylate December.Discourse segments can provide examples for what is stated by another discoursesegment.
In example (11) (constructed), discourse segment 2 states an example253Computational Linguistics Volume 31, Number 2(exemplification in Hobbs [1985]) for what is stated in discourse segment 1:(11) Example1.
There have been many previous missions to Mars.2.
A famous example is the Pathfinder mission.Hobbs (1985) also includes an evaluation relation, as in example (12) (from Hobbs[1985]), in which discourse segment 2 states an evaluation of what is stated in discoursesegment 1.
We decided to call such relations elaborations, since we found it too difficultin practice to reliably distinguish elaborations from evaluations (according to our annota-tion scheme, in example (12), what is stated in discourse segment 2 elaborates on whatis stated in discourse segment 1):(12) Elaboration (labeled as evaluation in Hobbs [1985])1.
(A story.)2.
It was funny at the time.Unlike Hobbs (1985), we did not have a separate background relation as in exam-ple (13) (modified from Hobbs [1985]), in which what is stated in discourse segment1 provides the background for what is stated in discourse segment 2.
As with theevaluation relation, we found the background relation too difficult to reliably distinguishfrom elaboration relations (according to our annotation scheme, in example (13), what isstated in discourse segment 1 elaborates on what is stated in discourse segment 2):(13) Elaboration (labeled as background in Hobbs [1985])1.
T is the pointer to the root of a binary tree.2.
Initialize T.In a generalization relation, as in example (14) (constructed), one discourse seg-ment (here discourse segment 2) states a generalization for what is stated by anotherdiscourse segment (here discourse segment 1):(14) Generalization1.
Two missions to Mars in 1999 failed.2.
There are many missions to Mars that have failed.Furthermore, discourse segments can be in an attribution relation, as in example(15) (constructed), in which discourse segment 1 states the source of what is statedin discourse segment 2 (cf.
[Bergler 1991] for a more detailed semantic analysis ofattribution relations):(15) Attribution1.
John said that2.
the weather would be nice tomorrow.Hobbs (1985) does not include an attribution relation.
However, we decided to includeattribution as a relation because, as pointed out in section 2.1, the texts we annotatedare taken from news corpora.
There, attributions can be important carriers of coherencestructures.254Wolf and Gibson Representing Discourse CoherenceIn a temporal sequence relation, as in example (16) (constructed), one discoursesegment (here discourse segment 1) states an event that takes place before another eventstated by the other discourse segment (here discourse segment 2):(16) Temporal Sequence1.
First, John went grocery shopping.2.
Then he disappeared in a liquor store.In contrast to cause?effect relations, there is no causal relation between the eventsdescribed by the two discourse segments.
The temporal sequence relation is equivalent tothe occasion relation in Hobbs (1985).The same relation, illustrated by example (17) (constructed), is an epiphenomenonof assuming contiguous distinct elements of text (Hobbs [1985] does not include a samerelation).
A same relation holds if a subject NP is separated from its predicate by anintervening discourse segment.
For instance, in example (17), discourse segment 1 is thesubject NP of a predicate in discourse segment 3, and so there is a same relation betweendiscourse segments 1 and 3; discourse segment 1 is the first and discourse segment 3is the second segment of what is actually one single discourse segment, separated bythe intervening discourse segment 2, which is in an attribution relation with discoursesegment 1 (and therefore also with discourse segment 3, since discourse segments 1 and3 are actually one single discourse segment):(17) Same1.
The economy,2.
according to some analysts,3.
is expected to improve by early next year.Table 2 provides an overview of how our set of coherence relations relates to the setof coherence relations in Hobbs (1985).We distinguish between asymmetrical or directed relations, on the one hand, andsymmetrical or undirected relations, on the other hand (Mann and Thompson 1988;Marcu 2000).
Cause?effect, condition, violated expectation, elaboration, example, generaliza-tion, attribution, and temporal sequence are asymmetrical or directed relations, whereassimilarity, contrast, and same are symmetrical or undirected relations.
In asymmetrical ordirected relations, the directions of relations are as follows: Cause?effect: from the discourse segment stating the cause to the discoursesegment stating the effect Condition: from the discourse segment stating the condition to thediscourse segment stating the consequence Violated expectation: from the discourse segment stating the cause to thediscourse segment describing the absent effect Elaboration: from the elaborating discourse segment to the elaborateddiscourse segment Example: from the discourse segment stating the example to the discoursesegment stating the exemplified Generalization: from the discourse segment stating the special case to thediscourse segment stating the general case255Computational Linguistics Volume 31, Number 2Table 2Correspondence between the set of coherence relations in Hobbs (1985) and our set of coherencerelations.Hobbs (1985) Our annotation schemeOccasion Temporal sequenceCause Cause?effect: cause stated first, then effect;directionality indicated by directed arcs in acoherence graphExplanation Cause?effect: effect stated first, then cause;directionality indicated by directed arcs in acoherence graph?
ConditionEvaluation ElaborationBackground ElaborationExemplification: example stated first, then Examplegeneral case; directionality indicated bydirected arcs in a coherence graphExemplification: general case stated first, then Generalizationexample; directionality indicated bydirected arcs in a coherence graphElaboration ElaborationParallel SimilarityContrast ContrastViolated expectation Violated expectation?
Attribution?
Same Attribution: from the discourse segment stating the source to the attributedstatement Temporal sequence: from the discourse segment stating the event thathappened first to the discourse segment stating the event that happenedsecondThis definition of directionality is related to Mann and Thompson?s (1988) notionof nucleus and satellite nodes (where the nodes can represent [groups of] discoursesegments): For asymmetrical or directed relations, the directionality is from satelliteto nucleus node; by contrast, symmetrical or undirected relations hold between twonucleus nodes.Note also that in our annotation project, we decided to annotate a coherence relationeither if there was a coherence relation between the complete content of two discoursesegments, or if there was a relation between parts of the content of two discoursesegments.
Consider the following example (from ap890104-0003; AP Newswire corpus;[Harman and Liberman 1993]):(18) 1. a[ Difficulties have arisen ] b[ in enacting the accord for theindependence of Namibia ]2. for which SWAPO has fought many years,For this example we would annotate an elaboration relation from discourse segment 2 todiscourse segment 1 (discourse segment 2 provides additional details about the accord256Wolf and Gibson Representing Discourse Coherencementioned in discourse segment 1), although the relation actually only holds betweendiscourse segment 2 and the second part of discourse segment 1, indicated by brackets.Although it is beyond the scope of the current project, future research shouldinvestigate annotations with discourse segmentations that allow annotating rela-tions only between parts of discourse segments that are responsible for a coherencerelation.
For example, consider example (19) (from ap890104-0003; AP Newswirecorpus [Harman and Liberman 1993]), in which brackets indicate how more-fine-grained discourse segments might be marked:(19) 1. a[ for which ] b[ SWAPO ] c[ has fought many years, ]2. referring to the acronym of the South-West African PeoplesOrganization nationalist movement.In our current project, we annotated an elaboration relation from discourse segment 2 todiscourse segment 1 (discourse segment 2 provides additional details, the full name,for SWAPO, which is mentioned in discourse segment 1).
A future, more detailed,annotation of coherence relations could then annotate this elaboration relation to holdonly between discourse segment 2 and the word SWAPO in discourse segment 1.2.4 Coding ProcedureTo code the coherence relations of a text, we used a procedure consisting of three steps.In the first step, a text was segmented into discourse segments (cf.
section 2.1).In the second step, adjacent discourse segments that were topically related weregrouped together.
The criteria for this step are described in section 2.2.In the third step, coherence relations (cf.
section 2.3) were determined betweendiscourse segments and groups of discourse segments.
Each previously unconnected(group of) discourse segment(s) was tested to see whether it connected to any of the(groups of) discourse segments that had already been connected to the already existingrepresentation of discourse structure.In order to help determine the coherence relation between (groups of) discoursesegments, the annotators judged which, if any, of the contentful coordinating conjunc-tions in Table 1 resulted, when used, in the most acceptable passage (cf.
Hobbs 1985;Kehler 2002).
If using a contentful conjunction to connect (groups of) discourse seg-ments resulted in an acceptable passage, this was used as evidence that the coherencerelation corresponding to the mentally inserted contentful conjunction held betweenthe (groups of) discourse segments under consideration.
This mental exercise was doneonly if there was not already a contentful coordinating conjunction that disambiguatedthe coherence relation.The following list (which was also used by the annotators to guide them in theirtask) shows in more detail how the annotations were carried out:1.
Segment the text into discourse segments:(a) Insert segment boundaries at every period that marks a sentenceboundary (i.e., not at periods such as those in Mrs. or Dr.).
(b) Insert segment boundaries at every semicolon and colon that marksa sentence or clause boundary.
(c) Insert segment boundaries at every comma that marks a sentenceor clause boundary; do not insert segment boundaries at commasthat conjoin complex noun or verb phrases.257Computational Linguistics Volume 31, Number 2(d) Insert segment boundaries at every quotation mark, if there is notalready a segment boundary based on steps (a)?(c).
(e) Insert segment boundaries at the contentful coordinatingconjunctions listed in Table 1, if there is not already a segmentboundary based on steps (a)?(d).
For and, do not insert a segmentboundary if it is used to conjoin verbs or nouns in a conjoined verbor noun phrase.2.
Generate groupings of related discourse segments:(a) Group contiguous discourse segments that are enclosed by pairs ofquotation marks.
(b) Group contiguous discourse segments that are attributed to thesame source.
(c) Group contiguous discourse segments that belong to the samesentence (marked by periods, commas, semicolons, orcolons).
(d) Group contiguous discourse segments that are topically centeredon the same entities or events.3.
Determine coherence relations between discourse segments and groups ofdiscourse segments.
For each previously unconnected (group of) discoursesegment(s), test whether it connects to any of the (groups of) discoursesegments that have already been connected to the already existingrepresentation of discourse structure.
Use the following steps for eachdecision:(a) Use pairs of quotation marks as a signal for attribution.
(b) For pairs of (groups of) discourse segments that are alreadyconnected with one of the contentful coordinating conjunctionsfrom Table 1, choose the coherence relation that corresponds to thecoordinating conjunction.
(c) For pairs of (groups of) discourse segments that are not connectedwith one of the contentful coordinating conjunctions fromTable 1:i. Mentally connect the (groups of) discourse segments withone of the coordinating conjunctions from Table 1and judge whether the resultant passage soundsacceptable.ii.
If the passage sounds acceptable, choose the coherencerelation that corresponds to the coordinating conjunctionselected in step (c.i).iii.
If the passage does not sound acceptable, repeat step (c.i)until an acceptable coordinating conjunction is found.iv.
If the passage does not sound acceptable with any of thecoordinating conjunctions from Table 1, assume that the(groups of) discourse segments under consideration are notrelated by a coherence relation.
(d) Iterative procedure for steps (a) and (b):i.
Start with any of the unambiguous coordinatingconjunctions from Table 1 (because, although, if .
.
.
then, .
.
.said, for example).258Wolf and Gibson Representing Discourse CoherenceTable 3Statistics for texts in our database.Number of words Number of discourse segmentsMean 545 61Minimum 161 6Maximum 1,409 143Median 529 60ii.
If none of the unambiguous coordinating conjunctions resultsin an acceptable passage, use the more ambiguouscoordinating conjunctions (and, but, while, also, etc.).
(e) Important distinctions for steps (2) and (3) (this is based onpractical issues that came up during the annotation project):i.
Example versus elaboration: An example relation sets up anadditional entity or event (the example), whereas anelaboration relation provides more details about an alreadyintroduced entity or event (the one on which one elaborates).ii.
Cause?effect versus temporal sequence: Both cause?effect andtemporal sequence describe a temporal order of events (incause?effect, the cause has to precede the effect).
However,only cause?effect relations have a causal relation betweenwhat is stated by the (groups of) discourse segments underconsideration.
Thus, if there is a causal relation between the(groups of) discourse segments under consideration, assumecause?effect rather than temporal sequence (cf.
Lascarides andAsher 1993).2.5 AnnotatorsThe annotators for the database were MIT undergraduate students who worked in ourlab as research students.
For training, the annotators received a manual that describedthe background of the project, discourse segmentation, coherence relations and how torecognize them, and how to use the annotation tools that we developed in our lab (Wolfet al 2003).
The first author of this article provided training for the annotators.
Trainingconsisted of explaining the background of the project and the annotation method andof annotating example texts (these texts are not included in our database).
Training took8?10 hours in total, distributed over five days of a week.
After completing the training,annotators worked independently.2.6 Statistics on Annotated DatabaseIn order to evaluate hypotheses about appropriate data structures for representingcoherence structures, we have collected a database of 135 texts from the Wall StreetJournal 1987?1989 (30 texts) and the AP Newswire 1989 (105 texts) (both from Harmanand Liberman [1993]) in which the relations between discourse segments have beenlabeled with the coherence relations described above.
Table 3 shows statistics for thisdatabase.259Computational Linguistics Volume 31, Number 2Steps 2 (discourse segment grouping) and 3 (coherence relation annotation) ofthe coding procedure described in section 2.4 were performed independently by twoannotators.
For step 1 (discourse segmentation), a pilot study on 10 texts showedthat agreement on this step, as determined by number of common segments/(number ofcommon segments + number of differing segments), was never below 90%.
Therefore, all 135texts were segmented by two annotators together, resulting in segmentations that bothannotators could agree on.In order to determine interannotator agreement for step 2 of the coding procedurefor the database of annotated texts, we calculated kappa statistics (Carletta 1996).
Weused the following procedure to construct a confusion matrix: First, all groups markedby either annotator were extracted.
Annotator 1 had marked 2,616 groups, and an-notator 2 had marked 3,021 groups in the whole database.
The groups marked bythe annotators consisted of 536 different discourse segment group types (for example,groups that included the first two discourse segments of each text were marked 31 timesby both annotators; groups that included the first three discourse segments of each textwere marked 6 times by both annotators).
Therefore, the confusion matrix had 536 rowsand columns.
For all annotations of the 135 texts, the agreement was 0.8449, per chanceagreement was 0.0161, and kappa was 0.8424.
Annotator agreement did not differ as afunction of text length, arc length, or kind of coherence relation (all ?2 values < 1).We also calculated kappa statistics to determine interannotator agreement for step 3of the coding procedure.1 For all annotations of the 135 texts, the agreement was 0.8761,per chance agreement was 0.2466, and kappa was 0.8355.
Annotator agreement did notdiffer as a function of text length (?2 = 1.27, p < 0.75), arc length (?2 < 1), or kind ofcoherence relation (?2 < 1).
Table 4 shows the confusion matrix for the database of135 annotated texts that was used to compute the kappa statistics.
The table shows,for example, that much of the interannotator disagreement seems to have been drivenby disagreement over how to annotate elaboration relations (in the whole database,annotator 1 marked 260 elaboration relations where annotator 2 marked no relation;annotator 2 marked 467 elaboration relations where annotator 1 marked no relation).The only other comparable discourse annotation project that we are currently awareof is that of Carlson, Marcu, and Okurowski (2002).2 Since they use trees and split theannotation process into different substeps than those in our procedure, their annotatoragreement figures are not directly comparable to ours.
Furthermore, note that Carlsonand her colleagues do not report annotator agreement figures for their database as awhole, but for different subsets of four to seven documents that were each annotatedby different pairs of annotators.
For discourse segmentation, they report kappa valuesranging from 0.951 to 1.00; for annotation of discourse tree spans, their kappa valuesranged from 0.778 to 0.929; for annotation of coherence relation nuclearity (whether anode in a discourse tree is a nucleus or a satellite, cf.
section 2.3 for the definition ofthese terms), kappa values ranged from 0.695 to 0.882; for assigning types of coherencerelations, they reported kappa values ranging from 0.624 to 0.823.1 Note that interannotator agreement for step 3 was influenced by interannotator agreement for step 2.
Forexample, one annotator might mark a group of discourse segments 2 and 3, whereas the secondannotator might not mark that group of discourse segments.
If the first annotator then marks, forexample, a cause?effect coherence relation between discourse segment 4 and the group of discoursesegments 2 and 3, whereas the second annotator marks a cause?effect coherence relation betweendiscourse segment 4 and discourse segment 3, this would count as a disagreement.
Thus, our measure ofinterannotator agreement for step 3 is conservative.2 Note that Miltsakaki et al (2004) report results on annotating connectives but not on annotating wholediscourse structures.260Wolf and Gibson Representing Discourse CoherenceTable4Confusionmatrixofannotationsforthedatabaseof135annotatedtexts.contr=contrast;expv=violatedexpectation;ce=cause?effect;none=nocoherencerelation;gen=generalization;cond=condition;examp=example;ts=temporalsequence;attr=attribution;elab=elaboration;sim=similarity.Annotator2Annotator1contrexpvcenonegencondexamptsattrelabsamesimSumPercentagecontr38311034000200004304.47expv411307000000001241.29ce0044614000005004654.83none662442002271664671647157.43gen0001210000100230.24cond000201270101001311.36examp0011800219003002412.51ts112700021401002262.35attr000500001,3870001,39214.47elab0017260030303,913104,19743.63same002500010053015395.60sim7034300060031,0741,13611.81Sum461149513396211322462431,3934,3915351,139Percentage4.791.555.304.120.201.372.562.5314.5045.605.5611.80261Computational Linguistics Volume 31, Number 23.
Data Structures for Representing Coherence RelationsIn order to represent the coherence relations between discourse segments in a text, mostaccounts of discourse coherence assume tree structures (Britton 1994; Carlson, Marcu,and Okurowski 2002; Corston-Oliver 1998; Longacre 1983; Grosz and Sidner 1986; Mannand Thompson 1988; Marcu 2000; Polanyi and Scha 1984; Polanyi 1996; Polanyi et al2004; van Dijk and Kintsch 1983; Walker 1998); some accounts do not allow crosseddependencies but appear to allow nodes with multiple parents (Lascarides and Asher1991).3 Other accounts assume less constrained graphs that allow crossed dependenciesas well as nodes with multiple parents (e.g., Bergler 1991; Birnbaum 1982; Danlos 2004;Hobbs 1985; McKeown 1985; Reichman 1985; Zukerman and McConachy 1995; fordialogue structure, Penstein Rose et al 1995).Some proponents of tree structures assume that trees are easier to formalize and toderive than less constrained graphs (Marcu 2000; Webber et al 2003).
We demonstratethat in fact many coherence structures in naturally occurring texts cannot be adequatelyrepresented by trees.
Therefore we argue for less constrained graphs in which nodesrepresent discourse segments and labeled directed arcs represent the coherence rela-tions that hold between these discourse segments as an appropriate data structure forrepresenting coherence.Some proponents of more general graphs argue that trees cannot account for a fulldiscourse structure that represents informational, intentional, and attentional discourserelations.
For example, Moore and Pollack (1992) point out that rhetorical structuretheory (Mann and Thompson 1988) has both informational and intentional coherencerelations but then forces annotators to decide on only one coherence relation betweenany two discourse segments.
Moore and Pollack argue that often there is an informa-tional as well as an intentional coherence relation between two discourse segments,which then presents a problem for RST, since only one of the relations can be annotated.Instead, Moore and Pollack propose allowing more than one coherence relation betweentwo discourse segments, which violates the tree constraint of not having nodes withmultiple parents.Reichman (1985) argues that tree-based story grammars are not sufficient to accountfor discourse structure.
Instead, she argues that in order to account for the intentionalstructure of discourse, more general data structures are needed.
We argue that the sameis true for the informational structure of discourse.Moore and Pollack (1992), Moser and Moore (1996), and Reichman (1985) arguethat trees are insufficient for representing informational, intentional, and attentionaldiscourse structure.
Note, however, that the focus of our work is on informationalcoherence relations, not on intentional relations.
That does not mean that we think thatattentional or intentional structure should not be part of a full account of discoursestructure.
Rather, we would like to argue that whereas the above accounts argue againsttrees for representing informational, intentional, and attentional discourse structuretogether, we argue that trees are not even descriptively adequate to describe just in-formational discourse structure by itself.3 Although Lascarides and Asher (1991) do not explicitly disallow crossed dependencies, they argue thatwhen a discourse structure is being constructed, the right frontier of an already existing discoursestructure is the only possible attachment point for a new incoming discourse segment (cf.
also Polanyi1996; Polanyi and Scha 1984; Webber et al 1999).
This constraint on building discourse structureseffectively disallows crossed dependencies.262Wolf and Gibson Representing Discourse CoherenceSome accounts of informational discourse structure do not assume tree structures(e.g., Bergler [1991] and Hobbs [1985] for monologue and Penstein Rose et al [1995]for dialogue structure).
However, none of these accounts provides systematic empir-ical support for using more general graphs rather than trees.
Providing a systematicempirical study of whether trees are descriptively adequate for representing discoursecoherence is the goal of this article.There are also accounts of informational discourse structure that argue for treesas a ?backbone?
for discourse structure but allow certain violations of tree constraints(crossed dependencies or nodes with multiple parents).
Examples of such accountsinclude Webber et al (1999) and Knott (1996).
Similarly to our approach, Webberet al (1999) investigated informational coherence relations.
The kinds of coherencerelations they used are basically the same as those that we used (cf.
also Hobbs 1985).However, they argue for a tree structure as a backbone for discourse structure buthave also addressed violations of tree structure constraints.
In order to accommodateviolations of tree structure constraints (in particular, crossed dependencies), Webberet al (1999) argue for a distinction between ?structural?
discourse relations, on theone hand, and ?nonstructural?
or ?anaphoric?
discourse relations on the other hand.Structural discourse relations are represented within a lexicalized tree-adjoining gram-mar framework, and the resultant structural discourse structure is represented by atree.
However, more recently, Webber et al (2003) have argued that structural discoursestructure should allow nodes with multiple parents, but no crossed dependencies.
It isunclear, however, why Webber et al (2003) allow one kind of tree constraint violation(nodes with multiple parents) but not another (crossed dependencies).Note that there seems to be a problem with the definition of ?structural?
versus?nonstructural?
discourse structure in Webber et al (1999): According to Webber et al(1999), nonstructural discourse relations are licensed by anaphoric relations and canbe involved in crossed dependencies.
However, Webber et al (1999) also argue thatone criterion for nonstructural coherence relations is that they can cross (non)structuralcoherence relations.
Since this definition of ?nonstructural?
appears to be circular, itis necessary to find an independent way to validate the difference between structuraland nonstructural coherence relations.
Knott (1996) might provide a way to empiricallyformalize the claims in Webber et al (1999), or at least claims that seem to be verysimilar to those in Webber et al (1999): Based on the observation that he cannot identifycharacteristic cue phrases for elaboration relations (e.g., because would be a characteristiccue phrase for cause?effect), Knott argues that elaboration relations are more permissivethan other types of coherence relations (e.g., cause?effect, similarity, contrast).
As a conse-quence, Knott argues, elaboration relations would be better described in terms of focusstructures (cf.
Grosz and Sidner 1986), which Knott argues are less constrained, than interms of rhetorical relations (cf.
Hobbs 1985; Mann and Thompson 1988), which Knottargues are more constrained.
This hypothesis makes testable empirical claims: Elabora-tion relations should in some way pattern differently from other coherence relations.
Wecome back to this issue in sections 4.1 and 4.2.In this article we present evidence against trees as a data structure for representingdiscourse coherence.
Note, though, that the evidence does not support the claim thatdiscourse structures are completely arbitrary.
The goal of our research program is to firstdetermine which constraints on discourse structure are empirically viable.
To us, thework we present here seems to be the crucial first step in avoiding arbitrary constraintson inferences for building discourse structures.
In other words, the point we wishto make here is that although there might be other constraints on possible discourseannotations that will have to be identified in future research, tree structure constraints263Computational Linguistics Volume 31, Number 2do not seem to be the right kinds of constraints.
This appears to be a crucial differencebetween approaches like Knott?s (1996), Marcu?s (2000), or Webber et al?s (2003), onthe one hand, and our approach, on the other hand.
The goal of the former approachesseems to be to first specify a set of constraints on possible discourse annotations andthen to annotate texts with these constraints in mind.The following two sections illustrate problems with trees as a representation ofdiscourse coherence structures.
Section 3.1 shows that the discourse structures of nat-urally occurring texts contain crossed dependencies, which cannot be represented intrees.
Another problem for trees, in addition to crossed dependencies, is that manynodes in coherence graphs of naturally occurring texts have multiple parents.
This isshown in section 3.2.
Because of these problems for trees, we argue for a representationsuch as chain graphs (cf.
Frydenberg 1989; Lauritzen and Wermuth 1989), in whichdirected arcs represent asymmetrical or directed coherence relations and undirected arcsrepresent symmetrical or undirected coherence relations (this is equivalent to arguingfor directed graphs with cycles).
For all the examples in sections 3.1 and 3.2, chain-graph-based analyses are given.
RST analyses are given only for those examples thatare also annotated by Carlson, Marcu, and Okurowski (2002) (in those cases, the RSTanalyses are those provided by Carlson, Marcu, and Okurowski).3.1 Crossed DependenciesConsider the text passage in example (20) (modified from SAT practice materials):(20) 1.
Schools tried to teach students history of science.2.
At the same time they tried to teach them how to think logically andinductively.3.
Some success has been reached in the first of these aims.4.
However, none at all has been reached in the second.Figure 1 shows the coherence graph for example (20).
Note that the arrowheads of thearcs represent directionality for asymmetrical relations (elaboration) and bidirectionalityfor symmetrical relations (similarity, contrast).The coherence structure for example (20) can be derived as follows: Contrast relation between discourse segments 1 and 2: Discourse segments1 and 2 describe teaching different things to students. Contrast relation between discourse segments 3 and 4: Discourse segments3 and 4 describe varying degrees of success (some vs. none). Elaboration relation between discourse segments 3 and 1: Discoursesegment 3 provides more details (the degree of success) about the teachingdescribed in discourse segment 1.Figure 1Coherence graph for example (20).
contr = contrast; elab = elaboration.264Wolf and Gibson Representing Discourse Coherence Elaboration relation between discourse segments 4 and 2: Discoursesegment 4 provides more details (the degree of success) about the teachingdescribed in discourse segment 2.In the resultant coherence structure for (20), there is a crossed dependency between{3, 1} and {4, 2}.In order to be able to represent a structure like the one for (20) in a tree withoutviolating validity assumptions about tree structures (Diestel 2000), one might consideraugmenting a tree either with feature propagation (Shieber 1986) or with a coindex-ation mechanism (Chomsky 1973).
There is a problem, however, with both featurepropagation and coindexation mechanisms: Both the tree structure itself and the fea-tures and coindexations as well represent the same kind of information (coherencerelations).
It is unclear how a dividing line could be drawn between tree structuresand their augmentation.
That is, it is unclear how one could decide which part of atext coherence structure should be represented by the tree structure and which partshould be represented by the augmentation.
Other areas of linguistics have faced thisissue as well.
Researchers investigating data structures for representing intrasententialstructure, for instance, generally fall into two groups.
One group tries to formulateprinciples that allow representation of some aspects of structure in the tree itselfand other aspects in some augmentation formalism (e.g., Chomsky 1973; Marcuset al 1994).
Another group argues that it is more parsimonious to assume a unifieddependency-based representation that drops the tree constraints of allowing no crosseddependencies (e.g., Brants et al 2002; Skut et al 1997; Ko?nig and Lezius 2000).
Ourapproach falls into the latter group.
As we point out, there does not seem to be a well-defined set of constraints on crossed dependencies in discourse structures.
Without suchconstraints, it does not seem viable to represent discourse structures as augmented treestructures.An important question is how many different kinds of crossed dependencies occurin naturally occurring discourse.
If there are only a very limited number of differentstructures with crossed dependencies in natural texts, one could make specialprovisions to account for these structures and otherwise assume tree structures.Example (20), for instance, has a listlike structure.
It is possible that listlike examplesare exceptional in natural texts.
However, there are many other naturally occurringnonlistlike structures that contain crossed dependencies.
As an example of a nonlistlikestructure with a crossed dependency (between {4, 2} and {3, 1?2}), consider example(21) (constructed):(21) 1.
Susan wanted to buy some tomatoes2.
and she also tried to find some basil3.
because her recipe asked for these ingredients.4.
The basil would probably be quite expensive at this time of the year.The coherence structure for (21), shown in Figure 2, can be derived as follows: Similarity relation between 1 and 2: 1 and 2 both describe shopping forgrocery items. Cause?effect relation between 3 and 1?2: 3 describes the cause for theshopping described by 1 and 2.265Computational Linguistics Volume 31, Number 2Figure 2Coherence graph for example (21).
sim = similarity; ce = cause?effect; elab = elaboration. Elaboration relation between 4 and 2: 4 provides details about the basilin 2.Example (22), (from ap890109-0012; AP Newswire 1989 corpus [Harman andLiberman 1993]) has a similar structure:(22) 1.
The flight Sunday took off from Heathrow Airport at 7:52pm2.
and its engine caught fire 10 minutes later,3.
the Department of Transport said.4.
The pilot told the control tower he had the engine fire undercontrol.The coherence structure for example (22) can be derived as follows: Temporal sequence relation between 1 and 2: 1 describes the takeoff thathappens before the engine fire described by 2 occurs. Attribution relation between 3 and 1?2: 3 mentions the source of what issaid in 1?2. Elaboration relation between 4 and 2: 4 provides more detail about theengine fire in 2.The resulting coherence structure, shown in Figure 3, contains a crossed dependencybetween {4, 2} and {3, 1?2}.Consider example (23) (from wsj 0655; Wall Street Journal 1989 corpus [Harmanand Liberman 1993]):(23) 1.
1a[ Mr. Baker?s assistant for inter-American affairs, ] 1b[ BernardAronson, ]2. while maintaining3.
that the Sandinistas had also broken the cease-fire,4.
acknowledged:5.
?It?s never very clear who starts what.
?Figure 3Coherence graph for example (22).
ts = temporal sequence; attr = attribution; elab = elaboration.266Wolf and Gibson Representing Discourse CoherenceFigure 4Coherence graph for example (23).
expv = violated expectation; elab = elaboration; attr = attribution.Figure 5Coherence graph for example (23) with discourse segment 1 split into two segments.
expv =violated expectation; elab = elaboration; attr = attribution.Figure 6Tree-based RST annotation for example (23) from Carlson, Marcu, and Okurowski (2002).
Brokenlines represent the start of asymmetric coherence relations; continuous lines represent the end ofasymmetric coherence relations; symmetric coherence relations have two continuous lines(cf.
section 2.3).
attr = attribution; elab = elaboration.The annotations based on our annotation scheme with the discourse segmentationbased on the segmentation guidelines in Carlson, Marcu, and Okurowski (2002) arepresented in Figure 4, and those with the discourse segmentation based on oursegmentation guidelines from section 2.1 are presented in Figure 5.
Figure 6 showsa tree-based RST annotation for example (23) from Carlson, Marcu, and Okurowski(2002).
The only difference between our approach and that of Carlson, Marcu, andOkurowski with respect to how example (23) is segmented is that Carlson and hercolleagues assume discourse segment 1 to be one single segment.
By contrast, basedon our segmentation guidelines, discourse segment 1 would be segmented into twosegments (because of the comma that does not separate a complex NP or VP), 1a and1b, as indicated by the brackets in example (24):44 Based on our segmentation guidelines, the complementizer that in discourse segment 3 would be part ofdiscourse segment 2 instead (cf.
(15)).
However, since this would not make a difference in terms of theresulting discourse structure, we do not provide alternative analyses with that as part of discoursesegment 2 instead of discourse segment 3.267Computational Linguistics Volume 31, Number 2(24) 1a[ Mr. Baker?s assistant for inter-American affairs, ] 1b[ Bernard Aronson, ]The coherence structure for example (23) can be derived as follows: If discourse segment 1 is segmented into 1a and 1b (following ourdiscourse segmentation guidelines), elaboration relation between 1a and1b: 1b provides additional detail (a name) about what is stated in 1a(Mr. Baker?s assistant). Same relation between 1 (or 1a) and 4: The subject NP in 1 (Mr. Baker?sassistant) is separated from its predicate in 4 (acknowledged) byintervening discoure segments 2 and 3 (and 1b in our discoursesegmentation). Attribution relation between 2 and 3: 2 states the source (the elidedMr.
Baker) of what is stated in 3. Elaboration relation between the group of discourse segments 2 and 3 anddiscourse segment 1 (or the group of discourse segments 1a and 1b in ourdiscourse segmentation): 2 and 3 state additional detail (a statement abouta political process) about what is stated in 1 (or 1a and 1b) (Mr. Baker?sassistant). Attribution relation between 4 (and by virtue of the same relation, also1 or 1a) and 5: 4 states the source (Mr. Baker?s assistant) of what is statedin 5. Violated expectation relation between the group of discourse segments 2and 3 and the group of discourse segments 4 and 5: Although Mr. Baker?sassistant acknowledges cease-fire violations by one side (discoursesegments 2 and 3), he acknowledges that it is in fact difficult to clearlyblame one side for cease-fire violations (discourse segments4 and 5).The resulting coherence structure, shown in Figure 5 (discourse segmentation fromCarlson, Marcu, and Okurowski [2002]) and Figure 6 (our discourse segmentation),contains a crossed dependency: The same relation between discourse segment 1 and dis-course segment 4 crosses the violated expectation relation between the group of discoursesegments 2 and 3 and the group of discourse segments 4 and 5.Figure 6 represents a tree-based RST annotation for example (23) from Carlson,Marcu, and Okurowski (2002); in Figure 6, dashed lines represent the start of asym-metric coherence relations and continuous lines mark the end of asymmetric coherencerelations; symmetric coherence relations have two continuous lines (cf.
section 2.3 forthe distinction between symmetric and asymmetric coherence relations and for thedirections of asymmetric coherence relations).
Carlson, Marcu, and Okurowski (2002)do not provide descriptions of how they derived tree-based RST structures for theirexamples that are used in this article.
Therefore, instead of discussing how the tree-based RST structures were derived, we show comparisons of the RST structure andour chain-graph-based structure; the comparison for (23) is provided in Table 5.
Notein particular that the RST structure for example (23) does not represent the violatedexpectation relation between 2?3 and 4?5; that relation could not be annotated withoutviolating the tree constraint of not allowing crossed dependencies.268Wolf and Gibson Representing Discourse CoherenceTable 5Comparison for example (23) of tree-based RST structure from Carlson, Marcu, and Okurowski(2002) and our chain-graph-based structure.Tree-based RST structure Our chain-graph-based structure(1a and 1b are one discourse segment) Elaboration between 1a and 1bSame between 1?2 and 4 Same between 1 (or 1a) and 4Attribution between 1 and 2 Attribution between 1 and 2Elaboration between 2?3 and 1 Elaboration between 2?3 and 1 (or 1a and 1b)Attribution between 1?4 and 5 Attribution between 4 and 5(no relation) Violated expectation between 2?3 and 4?5Figure 7Coherence graph for example (25).
cond = condition; attr = attribution; elab = elaboration.3.2 Nodes with Multiple ParentsIn addition to including crossed dependencies, many coherence structures of naturaltexts include nodes with multiple parents.
Such nodes cannot be represented in treestructures.
Consider example (25) (from ap890103 = 0014; AP Newswire 1989 corpus[Harman and Liberman 1993]).
(25) 1.
?Sure I?ll be polite,?2.
promised one BMW driver3.
who gave his name only as Rudolf.4.
?As long as the trucks and the timid stay out of the left lane.
?The coherence structure for example (25) can be derived as follows: Attribution relation between 2 and 1 and 2 and 4: 2 states the source ofwhat is stated in 1 and 4, respectively. Elaboration relation between 3 and 2: 3 provides additional detail (thename) about the BMW driver in 2. Condition relation between 4 and 1: 4 states the BMW driver?s condition forbeing polite, stated in 1.5 This condition relation is also indicated by thephrase ?as long as.
?In the resultant coherence structure for example (25), node 1 has two parents?oneattribution and one condition ingoing arc (cf.
Figure 7).5 A cultural reference: In Germany, when driving on a highway, it is only lawful to pass on the left side.Thus, Rudolf is essentially saying that he will be polite as long as the trucks and the timid do not keephim from passing other cars.269Computational Linguistics Volume 31, Number 2Figure 8Coherence graph for example (26).
Additional coherence relation used (from Carlson, Marcu,and Okurowski [2002]): evaluation-s = the situation presented in the satellite assesses thesituation presented in the nucleus (evaluation-s would be elaboration in our annotation scheme).attr = attribution; cond = condition.Figure 9Coherence graph for example (26) with discourse segments 1 and 2 merged into one singlediscourse segment.
Additional coherence relation used (from Carlson, Marcu, and Okurowski[2002]): evaluation-s = the situation presented in the satellite assesses the situation presented inthe nucleus (evaluation-s would be elaboration in our annotation scheme).
attr = attribution;cond = condition.As another example of a discourse structure that contains nodes with multipleparents, consider the structure of example (26) (from wsj 0655; Wall Street Journal 1989corpus [Harman and Liberman 1993]):(26) (they in 4 and 6 = Contra supporters; this is clear from the whole textwsj 0655)1.
?The administration should now state2.
that3.
if the February election is voided by the Sandinistas4.
they should call for military aid,?5.
said former Assistant Secretary of State Elliott Abrams.6.
?In these circumstances, I think they?d win.
?Our annotations are shown in Figures 8 (discourse segmentation from Carlson, Marcu,and Okurowski [2002]) and 9 (our discourse segmentation); Carlson et al?s (2002) tree-based RST annotation is shown in Figure 10.
The only difference between our annotationand that of Carlson, Marcu, and Okurowski is that we do not assume two separatediscourse segments for 1 and 2; 1 and 2 are one discourse segment in our annotation(represented by the node 1+2 in Figure 9).
Note also that in discourse segment 3 ofexample (23) ?that?
is not in a separate discourse segment; it is unclear why in example(26), ?that?
is in a separate discourse segment (discourse segment 2) and not part ofdiscourse segment 3.
The discourse structure for example (26) can be derived as follows:1.
According to our discourse segmentation guidelines (cf.
section 2.1), 1 and2 should be one single discourse segment: Therefore either same relationbetween 1 and 2 (cf.
Figure 8), or merge 1 and 2 into one single discoursesegment, 1+2 (cf.
Figure 9).270Wolf and Gibson Representing Discourse CoherenceFigure 10Tree-based RST annotation for example (26) from Carlson, Marcu, and Okurowski (2002).
Brokenlines represent the start of asymmetric coherence relations; continuous lines represent the end ofasymmetric coherence relations; symmetric coherence relations have two continuous lines (cf.section 2.3).
Additional coherence relation used (from Carlson, Marcu, and Okurowski [2002]):evaluation-s = the situation presented in the satellite assesses the situation presented in thenucleus (evaluation-s would be elaboration in our annotation scheme).
attr = attribution;cond = condition.2.
Attribution relation between 1 or 1+2 and 3?4: 1 or 1+2 state the source (theadministration) of what is stated in 3?4.3.
Condition relation between 3 and 4: 3 states the condition for what is statedin 4 (the condition relation is also signaled by the cue phrase if in 3).4.
Attribution relation between 5 and 1?4: 5 states the source of what is statedin 1?4.5.
Attribution relation between 5 and 6: 5 states the source of what is stated in 6.6.
Evaluation-s6 relation between 6 and 3?4: 3?4 state what is evaluated by6?the Contra supporters should call for military aid, and if the Februaryelection is voided (group of discourse segments 3?4), the Contrasupporters might win (discourse segment 6).
Note that in our annotationscheme, the evaluation-s relation would be an elaboration relation (6provides additional detail about 3?4: Elliott Abrams?s opinion on theContras?
chances of winning).In the resultant coherence structure for example (26), node 3?4 has multiple parents oringoing arcs: one attribution ingoing arc and one evaluation-s ingoing arc (cf.
Figures 8and 9).Table 6 presents a comparison of the RST annotation and our chain-graph-basedannotation for (26).
Note in particular that the attribution relation between 5 and 6 cannotbe represented in the RST tree structure.
Note furthermore that the RST tree contains anevaluation-s relation between 6 and 1?5.
However, this evaluation-s relation seems to holdrather between 6 and 3?4: What is being evaluated is a chance for the Contras to win6 The relation evaluation-s is part of the annotation scheme in Carlson, Marcu, and Okurowski (2002) butnot part of our annotation scheme.
In an evaluation-s relation, the situation presented in the satelliteassesses the situation presented in the nucleus (Carlson, Marcu, and Okurowski 2002).
An evaluation-srelation would be an elaboration relation in our annotation scheme.271Computational Linguistics Volume 31, Number 2Table 6Comparison for (26) of tree-based RST structure (from Carlson, Marcu, and Okurowski (2002)and our chain-graph-based structure.Tree-based RST structure Our chain-graph-based structureSame between 2 and 3?4 Same between 1 and 2, or merging of 1 and 2 to 1+2Attribution between 1 and 2?4 Attribution between 1 or 1+2 and 3?4Condition between 3 and 4 Condition between 3 and 4Attribution between 5 and 1?4 Attribution between 5 and 1?4(no relation) Attribution between 5 and 6Evaluation-s between 6 and 1?5 Evaluation-s between 6 and 3?4a military conflict under certain circumstances.
But a coherence relation between 6 and3?4 could not have been annotated in a tree structure.4.
StatisticsWe performed a number of statistical analyses on our annotated database to test ourhypotheses.
Each set of statistics was calculated for both annotators separately.
How-ever, since the statistics for both annotators were never different from each other (asconfirmed by significant R2s > 0.9 or by ?2s > 1), we report only the statistics for oneannotator in the following sections.An important question is how frequent the phenomena discussed in the previoussections are.
The more frequent they are, the more urgent the need for a data structurethat can adequately represent them.
The following sections report statistical results oncrossed dependencies (section 4.1) and nodes with multiple parents (section 4.2).4.1 Crossed DependenciesThe following sections report counts on crossed dependencies in the annotated databaseof 135 texts (cf.
section 1).
Section 4.1.1 reports results on the frequency of crosseddependencies, section 4.1.2 reports results concerning the question of what types ofcoherence relations tend to be involved in crossed dependencies, and section 4.1.3reports results on the arc lengths of coherence relations involved in crossed depen-dencies.
Section 4.1.4 provides a short summary of the statistical results on crosseddependencies.4.1.1 Frequency of Crossed Dependencies.
In order to track the frequency of crosseddependencies for the coherence structure graph of each text, we counted the minimumnumber of arcs that would have to be deleted in order to eliminate crossed dependen-cies in the coherence structure.
Figure 11 illustrates this process.
The example graphdepicted in the figure contains the following crossed dependencies: {1, 3} crosses with{2, 4}, {3, 5} with {2, 4}, and {5, 7} with {6, 8}.
By deleting {2, 4}, two crosseddependencies can be eliminated: the crossing of {1, 3} with {2, 4} and the crossing of{3, 5} with {2, 4}.
By deleting either {5, 7} or {6, 8} the remaining crossed dependencybetween {5, 7} and {6, 8} can be eliminated.
Therefore two edges would have to bedeleted from the graph in Figure 11 in order to make it free of crossed dependencies.272Wolf and Gibson Representing Discourse CoherenceFigure 11Example graph with crossed dependencies.Figure 12Correlation between number of arcs and number of crossed dependencies.Table 7Percentages of arcs to be deleted in order to eliminate crossed dependencies in the database texts.Mean 12.5Minimum 0Maximum 44.4Median 10.9Table 7 shows the results of the counts.
On average for the 135 annotated texts,12.5% of arcs in a coherence graph have to be deleted in order to make the graph freeof crossed dependencies.
Seven texts out of the 135 had no crossed dependencies.
Themean number of arcs for the coherence graphs of these texts was 36.9 (minimum: 8,maximum: 69, median: 35).
The mean number of arcs for the other 128 coherence graphs(those with crossed dependencies) was 125.7 (minimum: 20, maximum: 293, median:115.5).
Thus, the graphs with no crossed dependencies had significantly fewer arcsthan the graphs that had crossed dependencies (?2(1) = 15,330.35 (Yates?s correctionfor continuity applied), p < 10?6).
This is a likely explanation for why these seven textshad no crossed dependencies.More generally, linear regressions show a correlation between the number of arcs ina coherence graph and the number of crossed dependencies.
The more arcs a graph has,the higher the number of crossed dependencies (R2 = 0.39, p < 10?4; cf.
Figure 12).
Thesame linear correlation holds between text length and number of crossed dependencies:The longer a text, the more crossed dependencies are in its coherence structure graph(for text length in discourse segments: R2 = .29, p < 10?4; for text length in words:R2 = .24, p < 10?4).4.1.2 Types of Coherence Relations Involved in Crossed Dependencies.
In additionto the question of how frequent crossed dependencies are, another question is whether273Computational Linguistics Volume 31, Number 2Table 8Percentages of arcs to be deleted in order to eliminate crossed dependencies.Coherence relation Percentage of coherence Percentage of overall Factorrelations participating in coherence relations (= overall/crossedcrossed dependencies dependencies)Same 1.13 17.21 15.23Condition 0.05 0.28 5.59Attribution 1.93 6.31 3.27Temporal sequence 0.94 1.56 1.66Generalization 0.24 0.34 1.40Contrast 5.84 7.93 1.36Cause?effect 1.13 1.53 1.35Violated expectation 0.61 0.82 1.40Elaboration 50.52 37.97 0.71Example 4.43 3.15 1.34Similarity 33.18 22.91 0.69there are certain types of coherence relations that participate more or less frequently incrossed dependencies than other types of coherence relations.
For an arc to participatein a crossed dependency, it must be in the set of arcs that would have to be deleted froma coherence graph in order to make that graph free of crossed dependencies (cf.
theprocedure outlined in section 4.1.1).
In other words, the question is whether the fre-quency distribution over types of coherence relations is different for arcs participatingin crossed dependencies compared to the overall frequency distribution over types ofcoherence relations in the whole database.Figure 13 shows that the overall distribution over types of coherence relationsparticipating in crossed dependencies is not different from the distribution over types ofcoherence relations overall.
This is confirmed by the results of a linear regression, whichshow a significant correlation between the two distributions of percentages (R2 = 0.84,p < .0001).
Note that the overall distribution includes only arcs with length greater thanone, since arcs of length one cannot participate in crossed dependencies.However, there are some differences for individual coherence relations.
Some typesof coherence relations occur considerably less frequently in crossed dependencies thanoverall in the database.
Table 8 shows the data from Figure 13 ranked by the factorof ?percentage of overall coherence relations?
by ?percentage of coherence relationsparticipating in crossed dependencies.?
The proportion of same relations, for instance, is15.23 times greater, and the percentage of condition relations is 5.59 times greater, overallin the database than in crossed dependencies.
We do not yet understand the reason forthese differences and plan to address this question in future research.Another way of testing whether certain coherence relations contribute more thanothers to crossed dependencies is to remove coherence relations of a certain type fromthe database and then count the remaining number of crossed dependencies.
For exam-ple, it is possible that the number of crossed dependencies is reduced once all elaborationrelations are removed from the database.
Table 9 shows that by removing all elaborationrelations from the database of 135 annotated texts, the percentage of coherence relationsinvolved in crossed dependencies is reduced from 12.5% to 4.96% of the remainingcoherence relations.
That percentage is reduced even further, to 0.84%, by removing allelaboration and similarity relations from the database.
These numbers seem to be partialsupport for Knott?s (1996) hypothesis: Knott argued that elaboration relations are less274Wolf and Gibson Representing Discourse CoherenceFigure13Distributionsovertypesofcoherencerelations.Foreachcondition(?overallstatistics?and?crossed-dependenciesstatistics?
),thesumoverallcoherencerelationsis100;eachbarineachconditionrepresentsafractionofthetotalof100inthatcondition.They-axisusesalog 10scale.attr=attribution;ce=cause?effect;cond=condition;contr=contrast;elab=elaboration;examp=example;expv=Violatedexpectation;gen=generalization;sim=similarity;ts=temporalsequence.275Computational Linguistics Volume 31, Number 2Table 9Effect of removing different types of coherence relations on the percentage of coherence relationsinvolved in crossed dependencies.Remaining percentage of coherence relationsinvolved in crossed dependenciesCoherence relation removed Mean Min Max MedianSame 13.08 0 44.44 11.39Condition 12.63 0 45.28 10.89Attribution 13.44 0 44.86 11.36Temporal sequence 12.53 0 44.44 10.87Generalization 12.53 0 44.44 10.84Contrast 11.88 0 46.15 9.86Cause?effect 12.67 0 49.47 11.03Violated expectation 12.51 0 44.44 10.87Elaboration 4.96 0 47.47 1.23Example 12.08 0 44.44 9.89Similarity 7.32 0 24.56 7.04Elaboration and similarity 0.84 0 10.68 0.00constrained than other types of coherence relations (cf.
the discussion of Knott [1996] insection 3).However, there is a possible alternative hypothesis to Knott?s (1996).
In particular,elaboration relations are very frequent (37.97% of all coherence relations; cf.
Table 8).
Itis possible that removing elaboration relations from the database reduces the number ofcrossed dependencies only because a large number of coherence relations are removedwhen elaborations are removed.
In other words, an alternative hypothesis to that ofKnott (1996) is that the lower number of crossed dependencies is just due to less-dense coherence graphs (i.e., the less dense coherence graphs are, the lower the chancefor crossed dependencies).
We tested this hypothesis by correlating the percentage ofcoherence relations removed with the percentage of crossed dependencies that remainafter removing a certain type of coherence relation.7 Figure 14 shows that the higherthe percentage of removed coherence relations, the lower the percentage of coherencerelations becomes that are involved in crossed dependencies.
This correlation is con-firmed by a linear regression (R2 = 0.7697, p < .0005; after removing the elaboration datapoint: R2 = 0.4504, p < .05; these linear regressions do not include the data point elabora-tion + similarity).
Thus, although removing certain types of coherence relations reducesthe number of crossed dependencies, it results in a very impoverished representation ofcoherence structure (i.e., after removing all elaboration and all similarity relations, only39.12% of all coherence relations would still be represented [cf.
Table 8]; the figure is52.13% based on the distribution over coherence relations including those with absolutearc length one [cf.
Table 11]).With respect to Knott?s (1996) hypothesis, note that leaving out elaboration relationsstill leaves the proportion of remaining crossed dependencies at 4.96% (cf.
Table 9).7 Note that the percentages of removed coherence relations do not include coherence relations of absolutearc length one, since removing those coherence relations cannot have any influence on the number ofcrossed dependencies (coherence relations of absolute arc length one cannot be involved in crosseddependencies).
Thus, the percentages of coherence relations removed in Figure 14 are from the thirdcolumn of Table 8.276Wolf and Gibson Representing Discourse CoherenceFigure 14Correlation between removed percentage of overall coherence relations and remainingpercentage of crossed dependencies.
Note that the data point for elaboration + similarity is notincluded in the figure.
R2 = 0.7699, p < .0005.In order to further reduce the proportion of remaining crossed dependencies, it isnecessary to remove similarity relations in addition to removing elaboration relations(cf.
Table 9).
This is a pattern of results that is not predicted by any literature that weare aware of (including Knott [1996], among others, although he predicts these resultspartially).
We believe this issue should be addressed in future research.4.1.3 Arc Lengths of Coherence Relations Involved in Crossed Dependencies.
An-other question is how great the distance typically is between discourse segments thatparticipate in crossed dependencies, or how great the arc length is for coherencerelations that participate in crossed dependencies.8 It is possible, for instance, thatcrossed dependencies primarily involve long-distance arcs and that more local crosseddependencies are disfavored.
However, Figure 15 shows that the distribution over arclengths is practically identical for the overall database and for coherence relations par-ticipating in crossed dependencies (linear regression: R2 = 0.937, p < 10?4), suggestinga strong locality bias for coherence relations overall as well as for those participatingin crossed dependencies.9 The arc lengths are normalized in order to take into accountthe varying length of texts.
Normalized arc length is calculated by dividing the absolutelength of an arc by the maximum length that that arc could have, given its position inits text.
For example, if there is a coherence relation between discourse segment 1 anddiscourse segment 4 in a text, the raw distance between them would be three.
If thesediscourse segments are part of a text that has five discourse segments total (i.e., 1 to 5),8 The distance between two discourse segments is not measured in terms of how many coherence links onehas to follow from any discourse segment x to any discourse segment y to which discourse segment x isrelated via a coherence relation.
Instead, distance is measured in terms of the number of interveningdiscourse segments.
Thus, distance between nodes reflects linear distance between two discoursesegments in a text.
For example, the distance between a discourse segment 1 and a discourse segment 4would be three.9 The arc length distribution for the database overall does not include arcs of (absolute) length one, sincesuch arcs cannot participate in crossed dependencies.277Computational Linguistics Volume 31, Number 2Figure 15Comparison of normalized arc length distributions.
For each condition (?overall statistics?
and?crossed-dependencies statistics?
), the sum over all coherence relations is 100; each bar in eachcondition represents a fraction of the total of 100 in that condition.the normalized distance would be 3/4 = 0.75 (because four would be the maximumpossible length of an arc that originates in discourse segment 1 or 4, given that the texthas five discourse segments in total).4.1.4 Summary of Crossed-Dependencies Statistics.
Taken together, the statistical re-sults on crossed dependencies suggest that crossed dependencies are too frequent tobe ignored by accounts of coherence.
Furthermore, the results suggest that any type ofcoherence relation can participate in a crossed dependency.
However, there are somecases in which knowing the type of coherence relation that an arc represents can beinformative as to how likely that arc is to participate in a crossed dependency.
Thestatistical results reported here also suggest that crossed dependencies occur primarilylocally, as evidenced by the distribution over lengths of arcs participating in crosseddependencies.4.2 Nodes with Multiple ParentsSection 3.2 provided examples of coherence structure graphs that contain nodes withmultiple parents.
In addition to crossed dependencies, nodes with multiple parents areanother reason why trees are inadequate for representing natural language coherencestructures.
The following sections report statistical results from our database on nodeswith multiple parents.
As in the previous section on crossed dependencies, we reportresults on the frequency of nodes with multiple parents (section 4.2.1), the types ofcoherence relations ingoing to nodes with multiple parents (section 4.2.2), and the arclength of coherence relations ingoing to nodes with multiple parents (section 4.2.3).Table 10In-degree of nodes in the overall database.Mean 1.60Minimum 1Maximum 12Median 1278Wolf and Gibson Representing Discourse CoherenceFigure 16Correlation between number of arcs and number of nodes with multiple parents.Section 4.2.4 provides a short summary of the statistical results on nodes with multipleparents.4.2.1 Frequency of Nodes with Multiple Parents.
We determined the frequency ofnodes with multiple parents by counting the number of nodes with in-degree greaterthan one.
We assume nodes with in-degree greater than one in a graph to be the equiv-alent of nodes with multiple parents in a tree.
The results of our count indicated that41.22% of all nodes in the database have an in-degree greater than one.
In addition tocounting the number of nodes with in-degree greater than one, we determined the meanin-degree of the nodes in our database.
Table 10 shows that the mean in-degree (= meannumber of parents) of all nodes in the investigated database of 135 texts is 1.6.
As for co-herence relations involved in crossed dependencies (cf.
section 4.1.1), a linear regressionshowed a significant correlation between the number of arcs in a coherence graph andthe number of nodes with multiple parents (cf.
Figure 16; R2 = 0.7258, p < 10?4; for textlength in discourse segments: R2 = .6999, p < 10?4; for text length in words: R2 = .6022,p < 10?4).
The proportion of nodes with in-degree greater than one and the mean in-degree of the nodes in our database suggest that even if a mechanism could be derivedfor representing crossed dependencies in (augmented) tree graphs, nodes with multipleparents present another significant problem for trees representing coherence structures.4.2.2 Types of Coherence Relations Ingoing to Nodes with Multiple Parents.
Aswith crossed dependencies, an important question is whether there are certain typesof coherence relations that are more or less frequently ingoing to nodes with mul-tiple parents than other types of coherence relations.
In other words, the questionis whether the frequency distribution over types of coherence relations is differentfor arcs ingoing to nodes with multiple parents compared to the overall frequencydistribution over types of coherence relations in the whole database.
Figure 17 showsthat the overall distribution over types of coherence relations ingoing to nodes withmultiple parents is not different from the distribution over types of coherence rela-tions overall.10 This is confirmed by the results of a linear regression, which show10 Note that, unlike in section 4.1.2, the distribution over coherence relations for all coherence relationsincludes arcs with length one, since there was in this case no reason to exclude them.279Computational Linguistics Volume 31, Number 2Table 11Proportion of coherence relations.Coherence relation Percentage of Percentage of Factor (= overall/coherence relations overall coherence ingoing to nodes withingoing to nodes with relations multiple parents)multiple parentsAttribution 7.38 12.68 1.72Cause?effect 2.63 4.19 1.59Temporal sequence 1.38 2.11 1.53Condition 0.83 1.21 1.46Violated expectation 0.90 1.13 1.26Generalization 0.17 0.21 1.22Contrast 6.72 7.62 1.13Same 10.72 9.74 0.91Similarity 20.22 20.79 1.03Elaboration 45.83 38.13 0.83Example 3.20 2.19 0.68a significant correlation between the two distributions of percentages (R2 = 0.967,p < 10?4).Unlike for crossed dependencies (cf.
Table 8), there are no big differences for indi-vidual coherence relations.
Table 11 shows the data from Figure 17, ranked by the factorof ?percentage of overall coherence relations?
by ?percentage of coherence relationsingoing to nodes with multiple parents.
?As for crossed dependencies, we also tested whether removing certain kinds ofcoherence relations reduced the mean in-degree (number of parents) and/or the per-centage of nodes with in-degree greater than one (more than one parent).
Table 12 showsthat removing all elaboration relations from the database reduces the mean in-degreeof nodes from 1.60 to 1.238 and the percentage of nodes with in-degree greater thanone from 41.22% to 20.29%.
Removing all elaboration as well as all similarity relationsreduces these numbers further to 1.142 and 11.24%, respectively.
As Table 12 also shows,removing other types of coherence relations does not lead to as great a reduction in themean in-degree and the percentage of nodes with in-degree greater than one.However, as with crossed dependencies (cf.
section 4.1.2), we also tested whetherthe reduction in nodes with multiple parents could simply be due to removing moreand more coherence relations (i.e., the less dense a graph is, the smaller the chancethat there are nodes with multiple parents).
We correlated the percentage of coherencerelations removed with the mean in-degree of the nodes after removing different typesof coherence relations.11 Figure 18 shows that the higher the percentage of removedcoherence relations, the lower the mean in-degree of the nodes in the database becomes.This correlation is confirmed by the results of a linear regression (R2 = 0.9455, p < 10?4;after removing the elaboration data point: R2 = 0.8310, p < .0005; note that these linearregressions do not include the data point elaboration + similarity).
We also correlated11 Note that in the correlations in this section, the proportions of removed coherence relations includecoherence relations of absolute arc length one, because removing these coherence relations also has aneffect on the mean in-degree of nodes and the proportion of nodes with in-degree greater than one.
Thus,the proportions of coherence relations removed in Figure 18 and in Figure 19 are from the third column ofTable 11.280Wolf and Gibson Representing Discourse CoherenceFigure17Distributionsovertypesofcoherencerelations.Foreachcondition(?overallstatistics?and?ingoingtonodeswithmultipleparents?
),thesumoverallcoherencerelationsis100;eachbarineachconditionrepresentsafractionofthetotalof100inthatcondition.They-axisusesalog 10scale.attr=attribution;ce=cause?effect;cond=condition;contr=contrast;elab=elaboration;examp=example;expv=Violatedexpectation;gen=generalization;sim=similarity;ts=temporalsequence.281Computational Linguistics Volume 31, Number 2Table 12Effect of removing different types of coherence relations on the mean in-degree of nodes and onthe percentage of nodes with in-degree greater than 1.Coherence relation removed In-degree of nodes Percentage of nodes within-degree > 1Mean Min Max MedianSame 1.519 1 12 1 35.85Condition 1.599 1 12 1 41.01Attribution 1.604 1 12 1 41.18Temporal sequence 1.599 1 12 1 41.12Generalization 1.600 1 12 1 41.16Contrast 1.569 1 12 1 39.45Cause?effect 1.599 1 12 1 41.14Violated expectation 1.598 1 12 1 40.96Elaboration 1.238 1 11 1 20.29Example 1.574 1 11 1 40.37Similarity 1.544 1 12 1 36.25Elaboration and similarity 1.142 1 11 1 11.24Figure 18Correlation between percentage of removed coherence relations and mean in-degree ofremaining nodes.
Note that the data point for elaboration + similarity is not included in the figure.R2 = 0.9455, p < 10?4.the percentage of coherence relations removed with the percentage of nodes with in-degree greater than one after removing different types of coherence relations.
Figure 19shows that the higher the percentage of removed coherence relations, the lower thepercentage of nodes with in-degree greater than one.
This correlation is also confirmedby the results of a linear regression (R2 = 0.9574, p < 10?4; after removing the elaborationdata point: R2 = 0.8146, p < .0005; note that these correlations do not include the datapoint elaboration + similarity).Thus, although removing certain types of coherence relations (the same ones asfor crossed dependencies, i.e., elaboration and similarity; cf.
section 4.1.2) can reduce themean in-degree of nodes and the proportion of nodes with in-degree greater than one,the result is a very impoverished coherence structure.
For example, after removing both282Wolf and Gibson Representing Discourse CoherenceFigure 19Correlation between percentage of removed coherence relations and percentage of nodes within-degree > 1.
Note that the data point for elaboration + similarity is not included in the figure.R2 = 0.9574, p < 10?4.elaboration and similarity relations, only 52.13% of all coherence relations would still berepresented (cf.
Table 11).
Furthermore, note that this pattern of results is not predictedby any literature we are aware of, including Knott (1996), although he predicts theresults partially (he predicts that removing elaboration relations but not that removingelaboration as well as similarity relations is necessary in order to remove basically allnodes with multiple parents; cf.
the discussion in the last paragraph of section 4.1.2).This issue will have to be investigated in future research.4.2.3 Arc Lengths of Coherence Relations Ingoing to Nodes with Multiple Parents.As for crossed dependencies, we also compared arc lengths.
Here, we compared thelength of arcs that are ingoing to nodes with multiple parents to the overall distributionof arc lengths.
Again, we compared normalized arc lengths (see section 4.1.3 for thenormalization procedure).
By contrast to the comparison for crossed dependencies,we included in this comparison arcs of (absolute) length one, because such arcs canbe ingoing to nodes with either single or multiple parents.
Figure 20 shows that thedistribution over arc lengths is practically identical for the overall database and forarcs ingoing to nodes with multiple parents (linear regression: R2 = 0.993, p < 10?4),suggesting a strong locality bias for coherence relations overall as well as for thoseparticipating in crossed dependencies.4.2.4 Summary of Statistical Results on Nodes with Multiple Parents.
In sum, thestatistical results on nodes with multiple parents suggest that they are a frequent phe-nomenon and that they are not limited to certain kinds of coherence relations.
However,as with crossed dependencies, removing certain kinds of coherence relations (elaborationand similarity) can reduce the mean in-degree of nodes and the proportion of nodeswith in-degree greater than one.
But also as with crossed dependencies, our data atpresent do not distinguish whether this reduction in nodes with multiple parents isdue to a property of the coherence relations removed (elaboration and similarity) orwhether it is just that removing more and more coherence relations simply reducesthe chance for nodes to have multiple parents.
We plan to address this question infuture research.
In addition to the results on frequency of nodes with multiple parents283Computational Linguistics Volume 31, Number 2Figure 20Comparison of normalized arc length distributions.
For each condition (?overall statistics?
and?arcs ingoing to nodes with multiple parents?
), the sum over all coherence relations is 100; eachbar in each condition represents a fraction of the total of 100 in that condition.and types of coherence relations ingoing to nodes with multiple parents, the statisticalresults reported here suggest that ingoing arcs to nodes with multiple parents areprimarily local.5.
ConclusionThe goals of this article have been to present a set of coherence relations that are easyto code and to illustrate the inadequacy of trees as a data structure for representingdiscourse coherence structures.
We have developed a coding scheme with high interan-notator reliability and used that scheme to annotate 135 texts with coherence relations.An investigation of these annotations has shown that discourse structures of naturallyoccurring texts contain various kinds of crossed dependencies as well as nodes withmultiple parents.
Neither phenomenon can be represented using trees.
This implies thatexisting databases of coherence structures that use trees are not descriptively adequate.Our statistical results suggest that crossed dependencies and nodes with multipleparents are not restricted phenomena that could be ignored or accommodated with afew exception rules.
Furthermore, even if one could find a way of augmenting treestructures to account for crossed dependencies and nodes with multiple parents, therewould have to be a mechanism for unifying the tree structure with the augmentationfeatures.
Thus, in terms of derivational complexity, trees would just shift the burdenfrom having to derive a less constrained data structure to having to derive a unificationof trees and features or coindexation.Because trees are neither a descriptively adequate data structure for representingcoherence structures nor easier to derive, we argue for less constrained graphs as a datastructure for representing coherence structures.
In particular, we argue for a representa-tion such as chain graphs (cf.
final paragraph of section 3).
Such less constrained graphswould have the advantage of being able to adequately represent coherence structures inone single data structure (cf.
Brants et al 2002; Skut et al 1997; Ko?nig and Lezius 2000).284Wolf and Gibson Representing Discourse CoherenceFurthermore, they are at least not harder to derive than (augmented) tree structures.The greater descriptive adequacy might in fact make them easier to derive.
However,this is still an open issue and will have to be addressed in future research.In section 2.3 we briefly illustrated the possibility of more-fine-grained discoursesegmentation than in the current project.
Although such a detailed annotation of co-herence relations was beyond the scope of the current project, future research shouldaddress this issue.
More-fine-grained discourse segmentation could then also facilitateintegration of discourse-level with sentence-level structural descriptions.Another issue that should be addressed in future research is empirically viableconstraints on inferences for building discourse structures.
As pointed out in section 3,even though we have argued against trees as a data structure for representing discoursestructures, that does not necessarily mean that discourse structures can be completelyarbitrary.
Future research should investigate questions such as whether there are struc-tural constraints on coherence graphs (e.g., as proposed by Danlos [2004]) or whetherthere are systematic structural differences between the coherence graphs of texts thatbelong to different genres (e.g., as proposed by Bergler [1991]).ReferencesBergler, Sabine.
1991.
The semantics ofcollocational patterns for reporting verbs.In Proceedings of the Fifth Conference of theEuropean Chapter of the Association forComputational Linguistics, Berlin,Germany.Birnbaum, Lawrence.
1982.
Argumentmolecules: A functional representation ofargument structures.
In Proceedings of theThird National Conference on ArtificialIntelligence (AAAI-82), Pittsburgh, PA,pages 63?65.Brants, Sabine, Sabine Dipper, Silvia Hansen,Wolfgang Lezius, and George Smith.
2002.The tiger treebank.
In Proceedings of theWorkshop on Treebanks and LinguisticTheories, Sozopol, Bulgaria.Britton, Bruce K. 1994.
Understandingexpository text.
In Morton AnnGernsbacher, editor, Handbook ofPsycholinguistics.
Academic Press,Madison, WI, pages 641?674.Carletta, Jean.
1996.
Assessing agreement onclassification tasks: The kappa statistic.Computational Linguistics, 22(2):249?254.Carlson, Lynn, Daniel Marcu, and Mary E.Okurowski.
2002.
RST discourse treebank.Corpus number LDC 2002T07, LinguisticData Consortium, Philadelphia.Chomsky, Noam, 1973.
Conditions ontransformations.
In S. Anderson andP.
Kiparsky, editors, A Festschrift for MorrisHalle.
Holt, Rinehart and Winston, NewYork, pages 232?286.Corston-Oliver, Simon.
1998.
Computingrepresentations of the structure of writtendiscourse.
Technical Report MSR-TR-98-15,Microsoft Research, Redmond, WA.Danlos, Laurence.
2004.
Discoursedependency structures as dags.In SigDIAL2004, Cambridge, MA.Diestel, Reinhard.
2000.
Graph Theory.Springer Verlag, New York.Frydenberg, Morten.
1989.
The chain graphMarkov property.
Scandinavian Journal ofStatistics, 17:333?353.Grosz, Barbara J. and Candace L. Sidner.1986.
Attention, intentions, and thestructure of discourse.
ComputationalLinguistics, 12(3):175?204.Harman, Donna and Mark Liberman.
1993.Tipster complete.
Corpus numberLDC93T3A, Linguistic Data Consortium,Philadelphia.Hearst, Marti.
1997.
Texttiling: Segmentingtext into multi-paragraph subtopicpassages.
Computational Linguistics,23(1):33?64.Hirschberg, Julia and Christine H. Nakatani.1996.
A prosodic analysis of discoursesegments in direction-giving monologues.In Proceedings of the 34th Annual Meetingof the Association for ComputationalLinguistics, pages 286?293, Santa Cruz, CA.Hobbs, Jerry R. 1985.
On the coherenceand structure of discourse.
TechnicalReport 85-37, Center for the Study ofLanguage and Information (CSLI),Stanford, CA.Hobbs, Jerry R., Martin E. Stickel, Douglas E.Appelt, and Paul Martin.
1993.Interpretation as abduction.
ArtificialIntelligence, 63:69?142.Hovy, Eduard and Elisabeth Maier.
1995.Parsimonious or profligate: How manyand which discourse relations?
Technicalreport, University of Southern California.285Computational Linguistics Volume 31, Number 2Kehler, Andrew.
2002.
Coherence, Reference,and the Theory of Grammar.
StanfordUniversity Press, Stanford, CA.Knott, Alistair.
1996.
A Data-DrivenMethodology for Motivating a Set of CoherenceRelations.
Ph.D. thesis, University ofEdinburgh.Ko?nig, Esther and Wolfgang Lezius.
2000.A description language for syntacticallyannotated corpora.
In Proceedings of theComputational Linguistics Conference(COLING), pages 1056?1060, Saarbru?cken,Germany.Lascarides, Alex and Nicholas Asher.
1991.Discourse relations and defeasibleknowledge.
In Proceedings of the 29thAnnual Meeting of the Association forComputational Linguistics, pages 55?63,Berkeley, CA.Lascarides, Alex and Nicholas Asher.
1993.Temporal interpretation, discourserelations and common sense entailment.Linguistics and Philosophy, 16(5):437?493.Lauritzen, Steffen and Nanny Wermuth.1989.
Graphical models for associationsbetween variables, some of which arequalitative and some quantitative.
Annalsof Statistics, 17:31?57.Longacre, Robert E. 1983.
The Grammar ofDiscourse.
Plenum, New York.Mann, William C. and Sandra A. Thompson.1988.
Rhetorical structure theory: Toward afunctional theory of text organization.
Text,8(3):243?281.Marcu, Daniel.
2000.
The Theory and Practiceof Discourse Parsing and Summarization.MIT Press, Cambridge, MA.Marcus, Mitchell, Grace Kim, Mary AnnMarcinkiewicz, Robert MacIntyre, AnnBies, Mark Ferguson, Karen Katz, andBritta Schasberger.
1994.
The PennTreebank: Annotating predicate argumentstructure.
In Proceedings of the ARPAHuman Language Technology Workshop,Plainsboro, NJ.
San Francisco, CA.
MorganKaufmann.McKeown, Kathleen R. 1985.
Text Generation:Using Discourse Strategies and FocusConstraints to Generate Natural LanguageText.
Cambridge University Press,Cambridge.Miltsakaki, Eleni, Rashmi Prasad, Aravind K.Joshi, and Bonnie L. Webber.
2004.
ThePenn discourse treebank.
In Proceedings ofthe Language and Resources and EvaluationConference, Lisbon.Moore, Johanna D. and Martha E. Pollack.1992.
A problem for rst: The need formulti-level discourse analysis.Computational Linguistics, 18(4):537?544.Moser, Megan and Johanna D. Moore.
1996.Toward a synthesis of two accounts ofdiscourse structure.
ComputationalLinguistics, 22(3):409?419.Penstein Rose, Carolyn, Barbara Di Eugenio,Lori S. Levin, and Carol Van Ess-Dykema.1995.
Discourse processing of dialogueswith multiple threads.
In Proceedings ofthe 33rd Annual Meeting of the Associationfor Computational Linguistics, Cambridge,MA.Polanyi, Livia.
1996.
The linguistic structureof discourse.
Technical Report 96-118,Center for the Study of Language andInformation (CSLI), Stanford, CA.Polanyi, Livia, Chris Culy, Martin van denBerg, Gian Lorenzo Thione, and DavidAhn.
2004.
A rule based approach todiscourse parsing.
In SigDIAL 2004,Cambridge, MA.Polanyi, Livia and Remko Scha.
1984.
Asyntactic approach to discourse semantics.In Proceedings of the 10th InternationalConference on Computational Linguistics,Stanford, CA.Reichman, Rachel.
1985.
Getting Computers toTalk Like You and Me.
MIT Press,Cambridge, MA.Shieber, Stuart M. 1986.
An introduction tounification-based approaches to grammar.Lecture Notes 4, Center for the Study ofLanguage and Information (CSLI),Stanford, CA.Skut, Wojciech, Brigitte Krenn, ThorstenBrants, and Hans Uszkoreit.
1997.
Anannotation scheme for free word orderlanguages.
In Proceedings of the FifthConference on Applied Natural LanguageProcessing (ANLP-97), Washington,DC.van Dijk, Teun A. and Walter Kintsch.
1983.Strategies of Discourse Comprehension.Academic Press, New York.Walker, Marilyn A.
1998.
Centering,anaphora resolution, and discoursestructure.
In E. Prince, A. K. Joshi, andM.
A. Walker, editors, Centering Theory inDiscourse.
Oxford University Press,Oxford, pages 401?435.Webber, Bonnie L., Alistair Knott, MatthewStone, and Aravind K. Joshi.
1999.Discourse relations: A structural andpresuppositional account using lexicalizedtag.
In Proceedings of the 37th AnnualMeeting of the Association for ComputationalLinguistics (ACL-99), College Park, MD,pages 41?48.286Wolf and Gibson Representing Discourse CoherenceWebber, Bonnie L., Matthew Stone,Aravind K. Joshi, and Alistair Knott.2003.
Anaphora and discoursestructure.
Computational Linguistics,29(4):545?587.Wolf, Florian, Edward Gibson, Amy Fisher,and Meredith Knight.
2003.
A procedurefor collecting a database of texts annotatedwith coherence relations.
Technical report,Massachusetts Institute of Technology,Cambridge, MA.Zukerman, Ingrid and Richard McConachy.1995.
Generating discourse across severaluser modules: Maximizing belief whileavoiding boredom and overload.
InProceedings of the International JointConference on Artificial Intelligence(IJCAI-95), pages 1251?1257, Montreal.287
