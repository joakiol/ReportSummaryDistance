Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 24?33,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsDetecting Code-Switching in a Multilingual Alpine Heritage CorpusMartin Volk and Simon ClematideUniversity of ZurichInstitute of Computational Linguisticsvolk|siclemat@cl.uzh.chAbstractThis paper describes experiments in de-tecting and annotating code-switching ina large multilingual diachronic corpus ofSwiss Alpine texts.
The texts are in En-glish, French, German, Italian, Romanshand Swiss German.
Because of the mul-tilingual authors (mountaineers, scientists)and the assumed multilingual readers, thetexts contain numerous code-switchingelements.
When building and annotatingthe corpus, we faced issues of languageidentification on the sentence and sub-sentential level.
We present our strategyfor language identification and for the an-notation of foreign language fragmentswithin sentences.
We report 78% precisionon detecting a subset of code-switcheswith correct language labels and 92% un-labeled precision.1 IntroductionIn the Text+Berg project we have digitized theyearbooks of the Swiss Alpine Club (SAC) fromits first edition in 1864 until today.
They containarticles about mountain expeditions, the flora andfauna of the Alpes and other mountain regions,glacier and climate observations, geology and his-tory papers, book reviews, accident and securityreports, as well as the protocols of the annualclub gatherings.
The texts are in the four officiallanguages of Switzerland French, German, Italianand Romansh1plus a few in English and SwissGerman dialects.Because of the multilinguality of the authorsand readers, many articles are mixed-languagetexts with inter-sentential and intra-sentential1.
Romansh is the 4th official language in Switzerland.
Itis spoken by around 25,000 people in the mountainous South-Eastern canton of Graub?unden.code-switching.
This poses a challenge for auto-matically processing the texts.
When we applyPart-of-Speech (PoS) tagging, named entity recog-nition or parsing, our systems need to know thelanguage that they are dealing with.
Therefore wehad used a language identifier from the start of theproject to mark the language of each sentence.
Wereport on our experiences with sentence-based lan-guage identification in section 3.
Figure 1 showsan example of a French text with an English ap-pendix title plus an English quote from this book.Lately we discovered that our corpus alsocontains many intra-sentential code-switches.
Forexample, we find sentences like... und ich finde esvery nice and de-lightfuleinen Vortrag halten zu d?urfen.
(Die Alpen, 1925) (EN : ... and I find itvery nice and delightful to be allowed togive a talk.
)where the German sentence contains an Englishphrase in quotation marks.
Obviously, a GermanPoS tagger will produce nonsense tags for the En-glish phrase as the words will be unknown to it.PoS taggers are good at tagging single unknownwords based on the surrounding context, but mosttaggers fail miserably when a sequence of twoor more words is unknown.
The upper half of fi-gure 2 shows the PoS tagger output for the aboveexample.
The words very, nice, delightful are sen-selessly tagged as proper names (NE), only and istagged as foreign word (FM).Our goal is to detect all intra-sentential code-switches and to annotate them as exemplified inthe lower half of figure 2.
They shall be framedwith the TEI-conformant tag <foreign> whichalso shall specify the language of the foreign lan-guage segment.
All tokens in the segment shall betagged as foreign words (e.g.
FM in the GermanSTTS tag set, ET in the French Le Monde tag set(Abeill?e et al., 2003)), and each lemma shall get24the special symbol @fn@ to set it apart from lem-mas of the surrounding sentence.
In this paper wereport on our experiments towards this goal andsuggest an algorithm for detecting code-switching.We adopt a wide definition of code-switching.We are interested in detecting all instances wherea text is in a dominant language and containswords, phrases and sentences in another language.Though our definition is broad, it is clearly morerestricted than others, as e.g.
the definition byKracht and Klein (2014) which includes specialpurpose codes like bank account numbers or shoesizes.In this paper we will give an overview of thelanguage mix in the yearbooks of the Swiss Al-pine Club over the 150 years, and we will illus-trate how we identified inter-sentential and intra-sentential code-switching.
We will give a quanti-tative overview of the number of code-switchingcandidates that we automatically located.2 The Text+Berg CorpusThe Text+Berg corpus comprises the annual pu-blications of the Swiss Alpine Club (SAC) fromits first edition in 1864 until 2013.
From the startuntil 1923 the official yearbook was called ?Jahr-buch des Schweizer Alpen-Club?
(EN : yearbookof the Swiss Alpine Club), and it typically consis-ted of 500 to 700 pages.
The articles of these first60 years were mostly in German (with 86% ofthe words), but some also in French (13% of thewords) and few in Italian and Romansh (Volk etal., 2010).Interestingly, the German articles containedpassages in French and sometimes other languages(e.g.
English, Swiss German, Latin) without trans-lations, and vice versa.
Obviously, the article au-thors and yearbook editors assumed that the rea-ders of the yearbook were polyglott at least in En-glish, French, German and Latin during that time.In fact, the members of the SAC in the 19th cen-tury came from an academic elite.
Mountain ex-ploration was a past-time of the rich and educated.Still, during that same time the French-speakingsections of the Swiss Alpine Club published theirown yearbook in parallel to the official yearbookand called it ?Echo des Alpes?.
It started shortlyafter the official yearbook in the late 1860s andcontinued until 1923.
Each ?Echo des Alpes?
year-book contained between 300 to 600 pages addingup to a total of 22,582 pages with 7.4 million to-kens, almost all in French with rare quotes in Ger-man.As of 1925 the official SAC yearbook and the?Echo des Alpes?
were merged into a new publi-cation called ?Die Alpen.
Les Alpes.
Le Alpi?
(inGerman, French, Italian) which has been publi-shed ever since.
Over the years it sometimes ap-peared as quarterly and sometimes as monthly ma-gazine.
Today it appears 12 times per year in ma-gazine format.
For the sake of simplicity we conti-nue to call each annual volume a yearbook.The merger in 1925 resulted in a higher per-centage of French texts in the new yearbook.
Forexample, the 1925 yearbook had around 143,000words in German and 112,000 in French (56% to44%).
The ratio varied somewhat but was still at64% to 36% in 1956.From 1957 onwards, the SAC has published pa-rallel (i.e.
translated) French and German versionsof the yearbooks.
At the start of this new era onlyhalf of the articles were translated, the rest wasprinted in the original language in identical ver-sions in the two language copies.Over the next decade the number of translationsincreased and as of 1983 the yearbooks were com-pletely translated between German and French.Few Italian articles were still published verbatimin both the French and German yearbooks.
As of2012 the SAC has launched an Italian languageversion of its monthly magazine so that now it pro-duces French, German and Italian parallel texts.In its latest release the Text+Berg corpus (com-prising the SAC yearbooks, the ALPEN maga-zine and the Echo des Alpes) contains around45.8 million tokens (after tokenization).
Frenchand German account for around 22 million tokenseach, Italian accounts for 0.8 million tokens.
Theremainder goes to English, Latin, Romansh andSwiss German.
The corpus is freely available forresearch purposes upon request.3 Language Identification in theText+Berg CorpusWe compiled the Text+Berg corpus by scanningall SAC yearbooks from 1864 until 2000 (around100,000+ pages).
Afterwards we employed com-mercial OCR software to convert the scan imagesinto electronic text.
We developed and appliedtechniques to automatically reduce the number ofOCR errors (Volk et al., 2011).We obtained the yearbooks from 2001 to25FIGURE 1 ?
Example of an English title and an English quote in a French text (Die Alpen, 1955)FIGURE 2 ?
Example of an annotated German sentence with English segment, before and after code-switch detection (Die Alpen, 1925)262009 as PDF documents which we automaticallyconverted to text.
The subsequent yearbooks from2010 until 2013 we received as XML files fromthe SAC.We have turned the whole corpus into a uniformXML format.
For this, the OCR output texts aswell as the texts converted from PDF and XMLare structured and annotated by automatically mar-king article boundaries, by tokenization, languageidentification, Part-of-Speech tagging and lemma-tization.
Our processing pipeline also includes to-ponym recognition and geo-coding of mountains,glaciers, cabins, valleys, lakes and towns.
Further-more we recognize and co-reference person names(Ebling et al., 2011), and we annotate temporalexpressions (date, time, duration and set) with avariant of HeidelTime (Rettich, 2013).
Finally weanalyze the parallel parts of our corpus and pro-vide sentence alignment information that is com-puted via BLEUalign (Sennrich and Volk, 2011).In order to process our texts with language-specific tools (e.g.
PoS tagging and person namerecognition) we employed automatic languageidentification on the sentence level.
We usedLingua-Ident2(developed by Michael Piotrowski)to determine for each sentence in our corpus whe-ther it is in English, French, German, Italian or Ro-mansh.
Lingua-Ident is a statistical language iden-tifier based on letter n-gram frequencies.
For longsentences it reliably distinguishes between the lan-guages.
Unfortunately it often misclassifies shortsentences.
Therefore we decided to use it only forsentences with more than 40 characters.
Shortersentences are assigned the language of the article.This can be problematic for mixed language ar-ticles.
An alternative strategy would be to assignthe language of the previous sentence to short sen-tences.For sentences that Lingua-Ident judges as Ger-man we run a second classifier that distinguishesbetween Standard German and Swiss German dia-lect text.
Since there are no writing rules for SwissGerman dialects, they come in a variety of spel-lings.
We have compiled a list of typical SwissGerman words (e.g.
Swiss-German : chli, chlii,chlini, chline = German : klein, kleine = English :small) that are not used in Standard German in or-der to identify Swiss German sentences.32.
http ://search.cpan.org/dist/Lingua-Ident/3.
We are aware that the Text+Berg corpus contains alsooccasional sentences (or sentence fragments) in other Ger-man dialects (e.g.
Austrian German, Bavarian German) andBased on the language tag of each sentencewe are able to investigate coarse-grained code-switching.
Whenever the language of a sentencedeviates from the language of the article, we have acandidate for code-switching.
For example, in theyearbook 1867 we find a German text (describingthe activities of the club) with a French quote :Der Berichterstatter bemerkt dar?uber :?On peut remarquer `a cette occasionqu?il est rare que par un effort de l?es-prit on puisse mettre du brouillard enbouteille, et .
.
.
?
Die etwas ?altere Sek-tion Diablerets, deren Steuer Herr Au-gust Bernus mit kundiger Hand .
.
.Most code-switching occurs with direct speech,quotes and book titles.
The communicative goal isobviously to make the text more authentic.4 Related Work on Detection ofCode-SwitchingMost previous work on automatically detectingcode-switching focused on the switches betweentwo known languages (whereas we have to dealwith a mix of 6 languages).Solorio and Liu (2008) worked on real-timeprediction of code-switching points in Spanish-English conversations.
This means that the judge-ment whether the current word is in a different lan-guage than the language of the matrix clause canonly be based on the previous words.
They use thePoS tag and its probability plus the lemma as pro-vided by both the Spanish and the English Tree-Tagger as well as the position of the word in theBeginning-Inside-Outside scheme as features formaking the decision.
In order to keep the numberof experiments manageable they restricted theirhistory to one or two preceding words.
As an inter-esting experiment they generated code-switchingsentences Spanish-English based on their differentpredictors and asked human judges to rate the na-turalness of the resulting sentences.
This helpedthem to identify the most useful code-switchingpredictor.Vu et al.
(2013) and Adel et al.
(2013) consi-der English-Mandarin code-switching in speechrecognition.
They investigate recurrent neural net-work language models and factored language mo-dels to the task in an attempt to integrate syntac-tic features.
For the experiments they use SEAME,in old German spellings.
Since these varieties are rare in thecorpus, we do not deal with them explicitly.27the South East Asia Mandarin-English speech cor-pus compiled from Singaporean and Malaysianspeakers.
It consists of spontaneous interviewsand conversations.
The transcriptions were clea-ned and each word was manually tagged as En-glish, Mandarin or other.
The data consists of anintensive mix of the two languages with the ave-rage duration of both English and Mandarin seg-ments to be less than a second ( !).
In order to as-sign PoS tags to this mixed language corpus, theauthors applied two monolingual taggers and com-bined the results.Huang and Yates (2014) also work on the de-tection of English-Chinese code-switching but noton speech but rather on web forum texts produ-ced by Chinese speakers living in the US.
Theyuse statistical word alignment and a Chinese lan-guage model to substitute English words in Chi-nese sentences with suitable Chinese words.
Pre-paring the data in this way significantly improvedMachine Translation quality.
Their approach is li-mited to two known languages and to very shortcode-switching phrases (typically only one word).Tim Baldwin and his group (Hughes et al.,2006) have surveyed the approaches to languageidentification at the time.
They found a number ofmissing issues, such as language identification forminority languages, open class language identifi-cation (in contrast to identification within a fixedset of languages), sparse training data, varyingencodings, and multilingual documents.
Subse-quently they (Lui and Baldwin, 2011) introduced asystem for language identification of 97 languagestrained on a mixture of corpora from differentdomains.
They claim that their system Langid isparticularly well suited for classifying short inputstrings (as in Twitter messages).
We therefore tes-ted Langid in our experiments for code-switchingdetection.5 Exploratory Experiments with theSAC Yearbook 1925In order to assess the performance of Langidfor the detection of code-switching we performedan exploratory experiment with the SAC yearbook1925.
We extracted all word sequences betweenpairs of quotation marks where at least one tokenhad been assigned the ?unknown?
lemma by ourPoS tagger.
The ?unknown?
lemma indicates thatthis word sequence may come from a different lan-guage.The word sequence had to be at least 4 cha-racters long, thus skipping single letters and ab-breviations.
In this way we obtained 333 wordsequences that are potential candidates for intra-sentential code-switching.
We then ran these wordsequences through the Langid language identifica-tion system with the restriction that we expect theword sequences only to be either English, French,German, Italian or Latin (Romansh and Swiss Ger-man are not included in Langid).
For a given stringLangid delivers the most likely language togetherwith a confidence score.We then compared the language predicted bythe Langid system with the (automatically) com-puted language of the complete sentence.
In 189out of the 333 sentences the Langid output pre-dicted a code-switch.
We then manually graded allLangid judgements and found that 225 languagejudgements (67.5%) were correct.
But only 89 ofthe 189 predicted code-switches came with thecorrect language.
40 of the 100 incorrect judge-ments were actually code-switches but with a dif-ferent language.
The remaining ones should havebeen classified with the same language as the sur-rounding sentence and are thus no examples ofcode-switching.A closer inspection of the results revealed thatthe book contained not only code-switches in theexpected 5 languages, but also into Romansh (6),Spanish (4) and Swiss-German (13).
Obviously allof these were incorrectly classified.
Most (8) ofthe Swiss-German word sequences were classifiedas German which could count as half correct, butthe others were misclassified as English (amongthem a variant of the popular Swiss German fare-well phrase uf Wiederluege spelled as uf?s Wieder-luege).The Langid system has a tendency to classifyword sequences as English.
Many of the short, in-correctly classified word sequences were judgedas English.
It turns out that Langid judges even theempty string as English with a score of 9.06.
The-refore all judgements with this score are dubious.We found that 56 short word sequences were clas-sified as English with this score, out of which 35were erroneously judged as English.
Only stringswith a length of 15 and more characters that areclassified as English should be trusted.
All othersneed to be discarded.In general, if precision is the most important as-pect, then Langid should only be used for strings28SAC yearbooks candidates predicted code-sw correct wrong lang no code-sw1868 to 1878 388 121 88 33 131926 to 1935 792 335 266 69 23Total 1180 456 354 102 36TABLE 1 ?
Recognition of code-switches in the Text+Berg corpuswith 20 or more characters.
In our test set only 4strings that were longer than 20 characters wereincorrectly classified within the selected languageset.
Among the errors was the famous Latin phraseconditio sine qua non (length : 21 characters inclu-ding blanks) which Langid incorrectly classifiedas Italian.Another reason for the considerable number ofmisclassifications can be repeated occurrences ofa word sequence.
Our error count is a token-basedcount and thus prone to misclassified recurringphrases.
In our experiment, Langid misclassifiedthe French book name Echo des Alpes as Italian.Unfortunately this name occurs 18 times in ourtest set and thus accounts for 18 errors.
We suspectthat an -o at the end of a word is a strong indicatorfor Italian.
In a short string like Echo des Alpes (14characters), this can make the difference.Another interesting observation is that hyphensspeak for German.
Our test set contains the hy-phenated French string vesse-de-neige which Lan-gid misclassifies as German with a clear marginover French.
When the same string is analyzedwithout hyphens, then Langid correctly computesa preference for French over German.
A similarobservation comes from the Swiss German phraseuf?s Wiederluege being classified as English whenspelled with the apostrophe (which is less frequentin German than in English).
Without the apos-trophe Langid would count the string as German.With short strings like this, special symbols have avisible impact on the language identification.We also observed that Langid is sensitive toall-caps capitalization.
For example, AUS DEMLEBEN DER GEBIRGSMUNDARTEN (EN : TheLives of Mountain Dialects) is misclassified as En-glish (with the default score) while Aus dem Le-ben der Gebirgsmundarten is correctly classifiedas German.Overall, we found that code-switching withinthe same article rarely targets different languages.For example, if the article is in German andcontains code-switches into English, then it hardlyever contains code-switches into other languages.In analogy to the one-sense-per-discourse hypo-thesis we might call this the one-code-switch-language-per-discourse hypothesis.6 Detecting Intra-sententialCode-SwitchingBased on exploratory studies and observationswe decided on the following algorithm for detec-ting and annotating intra-sentential foreign lan-guage segments in the Text+Berg corpus.
Wesearch for sub-sentential token sequences (possi-bly of length 1) that are framed by a pair of quota-tion marks and that contain at least one ?unknown?lemma.
There must be at least two tokens outsideof the quotation marks in the same sentence.
Asa compromise we restrict our detection to stringslonger than 15 characters so that we get relati-vely reliable language judgements by Langid.
Thestrings may consist of one token that is longer than15 characters (e.g.
Matterhornhochtourist) or a se-quence of tokens whose sum of characters inclu-ding blanks is more than 15.
We feed these can-didate strings to Langid for language identifica-tion and compare the output language with the lan-guage attribute of the surrounding sentence.
If thelanguages are different, then we regard the tokensequence as code-switch and mark it accordinglyin XML as shown in figure 2.In order to determine the precision of this al-gorithm, we checked 10 yearbooks from 1868 to1878 (there was no yearbook in 1870) and from1926 to 1935.
The results are in table 1.
Fromthe 1180 code-switch candidates that we compu-ted based on the above restrictions, Langid predic-ted 456 code-switches (39%).
This means that in39% of the cases Langid predicted a language thatwas different from the language of the surroundingsentence.We manually evaluated all 456 predicted code-switches and found that 354 of them (78%) werecorrectly classified and labeled.
These segmentswere indeed in a different language than the sur-rounding sentence and their language was cor-rectly determined.
For example, the French seg-29SAC yearbooks> 15 characterswithout unknowns?
15 charactersall sample : TN/FN all sample : TN/FP1868 to 1878 322 20/1 404 15/81926 to 1935 1944 78/1 1136 54/23Total 2266 (2%) 98/2 1540 (31%) 69/31TABLE 2 ?
Estimation of the loss of recall due to the filtering approach based on a random sample of 100quotations for each filtering category (TN : true negatives, FN : false negatives)ment in the following German sentence is cor-rectly detected and classified :Anschliessend f?uhrte Ambros dasselbeBergsteigertriodans des circonstancestr`es d?efavorablesauf den Monte Rosa... (Die Alpen, 1935) (EN : After-wards Ambros led the same 3 mountai-neersunder very unfavorable condi-tionsonto Monte Rosa.
)Out of the 102 segments whose languagewas wrongly classified, only 36 were no code-switches.
For example, the Latin segment cumgrano salis africani is indeed a code-switch ina German sentence although Langid incorrectlyclassifies it as English.
In fact, our evaluation sho-wed that Langid is ?reluctant?
to classify strings asLatin.
Latin strings are often misclassified as En-glish or Italian.Overall this means that only 8% of the predictedcode-switches are no code-switches.
Therefore wecan safely add the module for code-switch detec-tion into our processing and annotation pipeline.In order to estimate the recall of our quota-tion filtering approach we manually evaluated asample of the quotations that our algorithm exclu-ded.
Table 2 presents the numbers for the two timeperiods for two cases : first for sequences that arelonger than 15 characters and contain only knownlemmas, second for sequences that are shorter than16 characters and contain at least one ?unknown?lemma.
For both cases we checked 100 instances.The evaluation for the quotations with morethan 15 characters but with all known lemmas (no?unknown?
lemma) shows only 2 false negatives.Therefore, we can conclude safely that most of thecode-switches with more than 15 characters wereincluded in our candidate set.Table 2 also shows that there were 1540 quota-tions with 15 or less characters.
The manual ins-pection of 100 randomly selected quotations re-vealed that 31 indeed include foreign material.Some of these quotations are geographic names,e.g.
the valley Bergell (EN/IT : Val Bregaglia),where it is difficult to decide whether this shouldbe regarded as a code-switch.
For this evaluation,we sticked to the principle that a foreign geogra-phic name in quotation marks counts as a code-switch.
The number of missed code-switches ishigh (31%).
However, due to the limited preci-sion of Langid (and other character-based lan-guage identifiers) for short character sequences,we still consider our length threshold appropriate.A different approach to language identification isneeded to reliably classify these short quotes.7 DiscussionThe correctly marked code-switches in our testperiods can be split by language of the matrix sen-tence and the language of the sub-sentential seg-ment (= the code-switch segment).
Table 3 givesan overview of the types of code-switches for thetwo periods under investigation.
We see clearlythat code-switches from German to English wererare in the 19th century (8 out of 89 = 9%) but be-came much more popular in the 1920s and 1930s(61 out of 265 = 23%).
This came at the cost ofFrench which lost ground from 54% (48 out of 89)to 40% (106 out of 265).One can only compare the code-switch num-bers from German with the corresponding num-bers from French after normalizing the numbersin relation to the overall amount of text in Ger-man and French.
During the first period (1868 to1878) we count roughly 200,000 tokens in Frenchand 1.4 million tokens in German, whereas in thesecond period (1926 to 1935) we have around 1million tokens in French and again 1.4 milliontokens in German.
For the first period we find87 code-switches (triggered by quotation marks)in the 1.4 million German tokens compared to189 code-switches in the second period.
The num-30sentlangsegmlang1868 to18781926 to1935de en 8 61de fr 48 106de it 24 19de la 7 3fr de 2 35fr en - 20fr it - 11fr la - 2it de - 3it en - 2it fr - 3Total 89 265TABLE 3 ?
Correctly detected code-switches in theText+Berg corpussentlangsegmlang1868 to18781926 to1935de en 13 23de fr 9 5de it 8 12de la 2 1fr de - 7fr en 1 10fr it - 8fr la - 1it en - 2Total 33 69TABLE 4 ?
Incorrectly labeled code-switches inthe Text+Berg corpusber of code-switches have clearly increased.
ForFrench we observe the same trend with 2 code-switches in 200?000 words in the first period com-pared to 68 code-switches in the 1 million tokensin the second period.There is also a striking difference betweenFrench and German with many more code-switches in German than in French.
For instance,for German we find 135 code-switches per 1 mil-lion tokens in the second period vs. 68 code-switches per 1 million tokens for French.One surprising finding were the code-switchesinto Latin.
We had not noticed them before, sinceour corpus does not contain longer passages of La-tin text.
But this study shows that code-switchescorrectsegm Langid predictionlang en it fr la de Totalla 15 12 3 1 31de 7 5 5 1 18fr 7 3 10it 6 6es 3 1 2 6rm 1 2 3ru 1 1id 1 1Total 40 22 10 3 1 76TABLE 5 ?
Confusion matrix for incorrectly labe-led code-switches in the periods 1868 to 1878 and1926 to 1935into Latin persisted into the 1920s (3 out of Ger-man and 2 out of French).On the negative side (cf.
table 4), misclassi-fying segments as English is the most frequentcause for a wrong language assignment in bothperiods.
Table 5 shows the confusion matrix whichcontrasts the manually determined segment lan-guage with the incorrect language predicted byLangid.
This confirms that Langid has a tendencyto classify short text segments as English.
Butthere are also a number of errors for Latin beingmistaken for Italian, and German being mistakenfor Italian or French.As a general remark, it should be noted that ann-gram-based language identifier has advantagesover a lexicon-based language identifier in the faceof OCR errors.
In the yearbook 1926 we observedthe rare case of a whole English sentence havingbeen contracted to one token Ilovetobemothered.Still, our code-switch detector recognizes this asan English string.48 ConclusionsWe have described our efforts in language iden-tification in a multilingual corpus of Alpine texts.As part of corpus annotation we have identifiedthe language of each corpus sentence amongst En-glish, French, Standard German, Swiss German,4.
The complete sentence is : Un long Anglais, avec le-quel, dans le hall familial, je m?essaie `a ?echanger laborieu-sement quelques impressions `a ce sujet, me dit :I love to bemothered.31Italian and Romansh.
Furthermore we have de-veloped an algorithm to identify intra-sententialcode-switching by analyzing sentence parts inquotation marks that contain ?unknown?
lemmas.We have shown that token sequences thatamount to 15 or more characters can be judged bya state-of-the-art language identifier and will resultin 78% correctly labeled code-switches.
Another14% are code-switches but with a language dif-ferent from the auto-assigned language.
Only 8%are not code-switches at all.There are many ways to continue and extendthis research.
We have not included language iden-tification for Swiss German nor for Romansh inthe intra-sentential code-switch experiments re-ported in this paper.
We will train language modelsfor these two languages and add them to Langidto check the impact on the recognition accuracy.Since code-switches into Romansh are rare, andsince Romansh can easily be confused with Ita-lian, it is questionable whether the addition of thislanguage model will have a positive influence.We have used the ?general-purpose?
languageidentifier Langid in these experiments.
It will beinteresting to investigate language identifiers thatare optimized for short text fragments as discus-sed by Vatanen et al.
(2010).
Given the relati-vely high number of short quotations (31%) thatcontain code-switches, recall could improve consi-derably.In this paper we have focused solely on code-switching candidates that are triggered by pairs ofquotation marks.
In order to increase the recall wewill certainly enlarge the set of triggers to other in-dicators such as parentheses or commas.
We havebriefly looked at parentheses as trigger symbolsand found them clearly less productive than quo-tation marks.
To also find code-switches that haveno overt marker remains the ultimate goal.Finally, we will exploit the parallel parts of ourcorpus.
If a sentence in German contains a Frenchsegment, then it is likely that this French segmentoccurs verbatim in the parallel French sentence.Based on sentence and word alignment we willsearch for identical phrases in both language ver-sions.
We hope that this will lead to high accuracycode-switch data that we can use as training mate-rial for machine learning experiments.AcknowledgmentsWe would like to thank Michi Amsler andDon Tuggener for useful comments on literatureand tools for language identification and code-switching, as well as Patricia Scheurer for com-ments and suggestions on the language use inthe SAC corpus.
This research was supportedby the Swiss National Science Foundation undergrant CRSII2 147653/1 through the project ?MO-DERN : Modelling discourse entities and relationsfor coherent machine translation?.ReferencesAnne Abeill?e, Lionel Cl?ement, and Francois Tousse-nel.
2003.
Building a Treebank for French.
In AnneAbeill?e, editor, Building and Using Parsed Corpora,volume 20 of Text, Speech and Language Tech-nology, chapter 10, pages 165?187.
Kluwer, Dor-drecht.Heike Adel, Ngoc Thang Vu, and Tanja Schultz.
2013.Combination of recurrent neural networks and fac-tored language models for code-switching languagemodeling.
In Proceedings of the 51st Annual Mee-ting of the Association for Computational Linguis-tics (ACL), Sofia.Sarah Ebling, Rico Sennrich, David Klaper, and MartinVolk.
2011.
Digging for names in the mountains :Combined person name recognition and referenceresolution for German alpine texts.
In Proceedingsof The 5th Language & Technology Conference :Human Language Technologies as a Challenge forComputer Science and Linguistics, Poznan.Fei Huang and Alexander Yates.
2014.
Improvingword alignment using linguistic code switching data.In Proceedings of the 14th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics, pages 1?9, G?oteborg.Baden Hughes, Timothy Baldwin, Steven Bird, JeremyNicholson, and Andrew Mackinlay.
2006.
Reconsi-dering language identification for written languageresources.
In Proceedings of LREC 2006, pages485?488, Genoa.Marcus Kracht and Udo Klein.
2014.
The grammarof code switching.
Journal of Logic, Language andInformation, 23(3) :313?329.Marco Lui and Timothy Baldwin.
2011.
Cross-domain feature selection for language identification.In Proceedings of 5th International Joint Conferenceon Natural Language Processing, pages 553?561,Chiang Mai, Thailand.
Asian Federation of NaturalLanguage Processing.Katrin Rettich.
2013.
Automatische Annotationvon deutschen und franz?osischen temporalen Aus-dr?ucken im Text+Berg-Korpus.
Master thesis, Uni-versit?at Z?urich, Institut f?ur Computerlinguistik.Rico Sennrich and Martin Volk.
2011.
Itera-tive, MT-based sentence alignment of parallel texts.32In Proceedings of The 18th International NordicConference of Computational Linguistics (Noda-lida), Riga.Thamar Solorio and Yang Liu.
2008.
Learning to pre-dict code-switching points.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 973?981, Honolulu.
Asso-ciation for Computational Linguistics.Tommi Vatanen, Jaakko J. V?ayrynen, and Sami Vir-pioja.
2010.
Language identification of short textsegments with n-gram models.
In Proceedings ofLREC, pages 3423?3430, Malta.Martin Volk, Noah Bubenhofer, Adrian Althaus, MayaBangerter, Lenz Furrer, and Beni Ruef.
2010.
Chal-lenges in building a multilingual alpine heritage cor-pus.
In Proceedings of LREC, Valletta, Malta.Martin Volk, Lenz Furrer, and Rico Sennrich.
2011.Strategies for reducing and correcting OCR errors.In C. Sporleder, A. van den Bosch, and K. Zerva-nou, editors, Language Technology for Cultural He-ritage : Selected Papers from the LaTeCH Work-shop Series, Theory and Applications of NaturalLanguage Processing, pages 3?22.
Springer-Verlag,Berlin.Ngoc Thang Vu, Heike Adel, and Tanja Schultz.2013.
An investigation of code-switching atti-tude dependent language modeling.
In StatisticalLanguage and Speech Processing, pages 297?308.Springer.33
