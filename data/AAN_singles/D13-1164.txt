Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1574?1583,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsA Convex Alternative to IBM Model 2Andrei SimionColumbia UniversityIEOR DepartmentNew York, NY, 10027aas2148@columbia.eduMichael CollinsColumbia UniversityComputer ScienceNew York, NY, 10027mc3354@columbia.eduClifford SteinColumbia UniversityIEOR DepartmentNew York, NY, 10027cs2035@columbia.eduAbstractThe IBM translation models have been hugelyinfluential in statistical machine translation;they are the basis of the alignment modelsused in modern translation systems.
Exclud-ing IBM Model 1, the IBM translation mod-els, and practically all variants proposed in theliterature, have relied on the optimization oflikelihood functions or similar functions thatare non-convex, and hence have multiple lo-cal optima.
In this paper we introduce a con-vex relaxation of IBM Model 2, and describean optimization algorithm for the relaxationbased on a subgradient method combinedwith exponentiated-gradient updates.
Our ap-proach gives the same level of alignment ac-curacy as IBM Model 2.1 IntroductionThe IBM translation models (Brown et al 1993)have been tremendously important in statistical ma-chine translation (SMT).
The IBM models were thefirst generation of SMT systems; in recent work,they play a central role in deriving alignments usedwithin many modern SMT approaches, for exam-ple phrase-based translation models (Koehn, 2008)and syntax-based translation systems (e.g., (Chi-ang, 2005; Marcu et al 2006)).
Since the origi-nal IBM paper, there has been a large amount of re-search exploring the original IBM models and mod-ern variants (e.g., (Moore, 2004; Liang et al 2006;Toutanova and Galley, 2011; Riley and Gildea,2012; Vogel et al 1996)).Excluding IBM Model 1, the IBM translationmodels, and practically all variants proposed in theliterature, have relied on the optimization of like-lihood functions or similar functions that are non-convex.
Unfortunately, non-convex objective func-tions have multiple local optima, and finding aglobal optimum of a non-convex function is typi-cally a computationally intractible problem.
Typi-cally, an EM algorithm is used, which often runs ina reasonable amount of time, but with no guaranteesof finding a global optima (or for that matter, even anear-optimal solution).In this paper we make the following contributions:?
We introduce a convex relaxation of IBMModel 2.
At a very high level, the relaxationis derived by replacing the product t(fj |ei) ?d(i|j) with a relaxation that is commonly usedin the linear programming literature (e.g., see(Bertsimas, 1997; Bertsimas and Tsitsiklis,1997; Martins et al 2010)).
(Here t(f |e) arethe translation parameters of the model, andd(i|j) are the distortion parameters; the prod-uct is non-linear, effectively introducing non-convexity into the problem.)?
We describe an optimization algorithm forthe relaxed objective, based on a combina-tion of stochastic subgradient methods with theexponentiated-gradient (EG) algorithm (Kivi-nen and Warmuth, 1997; Beck and Teboulle,2003).?
We describe experiments with the method onstandard alignment datasets, showing that theEG algorithm converges in only a few passesover the data, and that our method achieves ac-curacies that are very similar to those of IBMModel 2.Framing the unsupervised learning of alignmentmodels as a convex optimization problem, withguaranteed convergence to a global optimum, hasseveral clear advantages.
First, the method is eas-ier to analyze, as the objective function is beingtruly maximized.
Second, there is no need for ini-tialization heuristics with the approach, given thatthe method will always converge to a global op-timum.
Finally, we expect that our convexity-based approach may facilitate the further develop-ment of more convex models.
There has been a rich1574interplay between convex and non-convex meth-ods in machine learning: as one example considerthe literature on classification problems, with earlywork on the perceptron (linear/convex), then workon neural networks with back-propagation (non-linear/non-convex), then the introduction of supportvector machines (non-linear/convex), and finally re-cent work on deep belief networks (non-linear/non-convex).
In view of these developments, the lackof convex methods in translation alignment modelshas been noticeable, and we hope that our work willopen up new directions and lead to further progressin this area.Notation.
Throughout this paper, for any integerN , we use [N ] to denote {1 .
.
.
N} and [N ]0 to de-note {0 .
.
.
N}.2 Related Work(Brown et al 1993) introduced IBM Models 1through 5, and optimization methods for these mod-els based on the EM algorithm.
While the modelswere originally introduced for full translation, theyare now mainly used to derive alignments which arethen used by phrase-based and other modern SMTsystems.
Since the original IBM models were in-troduced, many variants have been introduced in theliterature.
(Vogel et al 1996) introduced a model,sometimes referred to as IBM 2.5, which uses a pa-rameterization that is similar to a hidden Markovmodel, and which allows the value of each alignmentvariable to be conditioned on a previous alignmentvariable.
(Liang et al 2006) describe a method thatexplicitly incorporates agreement preferences dur-ing training.
(Och and Ney, 2003) give a systematiccomparison of several alignment models in the liter-ature.
(Moore, 2004) gives a detailed study of IBMModel 1, showing various steps that can be used toimprove its performance.
(Ganchev et al 2010)describes a method based on posterior regulariza-tion that incorporates additional constraints withinthe EM algorithm for estimation of IBM models.All of these approaches are unsupervised, in thatthey do not require labeled alignment data; howeverseveral authors have considered supervised models(e.g., see (Lacoste-Julien et al 2006; Taskar et al2005; Haghighi et al 2009)).
The focus of the cur-rent paper is on unsupervised learning; the unsuper-vised variants described above all make use of non-convex objective functions during training, with theusual problems with multiple local maxima.3 The IBM Model 1 and Model 2Optimization ProblemsIn this section we give a brief review of IBM Models1 and 2, and the optimization problems arising fromthese models.
The standard approach for optimiza-tion within these models is the EM algorithm.Throughout this section, and the remainder of thepaper, we assume that our set of training examplesis (e(k), f (k)) for k = 1 .
.
.
n, where e(k) is the k?thEnglish sentence and f (k) is the k?th French sen-tence.
Following standard convention, we assumethe task is to translate from French (the ?source?language) into English (the ?target?
language).
Weuse E to denote the English vocabulary (set of pos-sible English words), and F to denote the Frenchvocabulary.
The k?th English sentence is a sequenceof words e(k)1 .
.
.
e(k)lkwhere lk is the length of thek?th English sentence, and each e(k)i ?
E; similarlythe k?th French sentence is a sequence f (k)1 .
.
.
f(k)mkwhere each f (k)j ?
F .
We define e(k)0 for k = 1 .
.
.
nto be a special NULL word (note that E contains theNULL word).
Finally, we define L = maxnk=1 lkand M = maxnk=1mk.For each English word e ?
E, we will assumethat D(e) is a dictionary specifying the set of possi-ble French words that can be translations of e. Theset D(e) is a subset of F .
In practice, D(e) can bederived in various ways; in our experiments we sim-ply define D(e) to include all French words f suchthat e and f are seen in a translation pair.Given these definitions, the IBM model 2 opti-mization problem is given in Figure 1.
The parame-ters in this problem are t(f |e) and d(i|j).
The t(f |e)parameters are translation parameters specifying theprobability of English word e being translated asFrench word f .
The distortion parameters d(i|j)specify the probability of the j?th French word in asentence being aligned to the i?th English word.
Weuse a variant of IBM Model 2 where the distortionvariables are shared across all sentence lengths (sim-ilar variants have been used in (Liang et al 2006)and (Koehn, 2008)).
The objective function is then1575Input: DefineE, F , L,M , (e(k), f (k), lk,mk) fork = 1 .
.
.
n, D(e) for e ?
E as in Section 3.Parameters:?
A parameter t(f |e) for each e ?
E, f ?
D(e).?
A parameter d(i|j) for each i ?
[L]0, j ?
[M ].Constraints:?e ?
E, f ?
D(e), t(f |e) ?
0 (1)?e ?
E,?f?D(e)t(f |e) = 1 (2)?i ?
[L]0, j ?
[M ], d(i|j) ?
0 (3)?j ?
[M ],?i?
[L]0d(i|j) = 1 (4)Objective: Maximize1nn?k=1mk?j=1loglk?i=0t(f (k)j |e(k)i )d(i|j) (5)with respect to the t(f |e) and d(i|j) parameters.Figure 1: The IBM Model 2 Optimization Problem.the log-likelihood of the training data (see Eq.
5):1nn?k=1mk?j=1log p(f (k)j |e(k)) ,wherep(f (k)j |e(k)) =lk?i=0t(f (k)j |e(k)i )d(i|j) .Crucially, while the constraints in the IBM Model2 optimization problem are linear, the objectivefunction in Eq.
5 is non-convex.
Therefore, opti-mization methods for IBM Model 2, in particularthe EM algorithm, are typically only guaranteed toreach a local maximum of the objective function.For completeness, Figure 2 shows the optimiza-tion problem for IBM Model 1.
In IBM Model 1the distortion parameters d(i|j) are all fixed to bethe uniform distribution (i.e., 1/(L + 1)).
The ob-jective function for IBM Model 1 is actually convex,so the EM algorithm will converge to a global max-imum.
However IBM Model 1 is much weaker thanmodel 2, and typically gives far worse performance.Input: DefineE, F , L,M , (e(k), f (k), lk,mk) fork = 1 .
.
.
n, D(e) for e ?
E as in Section 3.Parameters:?
A parameter t(f |e) for each e ?
E, f ?
D(e).Constraints:?e ?
E, f ?
D(e), t(f |e) ?
0 (6)?e ?
E,?f?D(e)t(f |e) = 1 (7)Objective: Maximize1nn?k=1mk?j=1loglk?i=0t(f (k)j |e(k)i )(L+ 1)(8)with respect to the t(f |e) parameters.Figure 2: The IBM Model 1 Optimization Problem.A common heuristic is to initialize the t(f |e) param-eters in EM optimization of IBM Model 2 using theoutput from IBM Model 1.
The intuition behind thisheuristic is that the IBM Model 1 values for t(f |e)will be a reasonable starting point, and the EM al-gorithm will climb to a ?good?
local optimum.
Weare not aware of any guarantees for this initializationheuristic, however.4 A Convex Relaxation of IBM Model 2We now introduce a convex optimization problem,the I2CR (IBM 2 Convex Relaxation) problem.As its name suggests, this optimization problem isclosely related to IBM Model 2, but is convex.
Be-cause of this it will be relatively easy to derive an op-timization algorithm that is guaranteed to convergeto a global optimum.
Our experiments show thatthe relaxation gives very similar performance to theoriginal IBM 2 optimization problem, as describedin the previous section.We first describe an optimization problem,I2CR-1, that illustrates the basic idea behind theconvex relaxation.
We then describe a refined re-laxation, I2CR-2, that introduces a couple of modi-fications, and which performs well in experiments.1576Input: DefineE, F , L,M , (e(k), f (k), lk,mk) fork = 1 .
.
.
n, D(e) for e ?
E as in Section 3.Parameters:?
A parameter t(f |e) for each e ?
E, f ?
D(e).?
A parameter d(i|j) for each i ?
[L]0, j ?
[M ].
?A parameter q(i, j, k) for each k ?
[n], i ?
[lk]0,j ?
[mk].Constraints:?e ?
E, f ?
D(e), t(f |e) ?
0 (9)?e ?
E,?f?D(e)t(f |e) = 1 (10)?i ?
[L]0, j ?
[M ], d(i|j) ?
0 (11)?j ?
[M ],?i?
[L]0d(i|j) = 1 (12)?i, j, k, q(i, j, k) ?
0 (13)?i, j, k, q(i, j, k) ?
d(i|j) (14)?i, j, k, q(i, j, k) ?
t(f (k)j |e(k)i ) (15)Objective: Maximize1nn?k=1mk?j=1loglk?i=0q(i, j, k) (16)with respect to the q(i, j, k), t(f |e) and d(i|j) pa-rameters.Figure 3: The I2CR-1 (IBM 2 Convex Relaxation) Prob-lem, version 1.4.1 The I2CR-1 ProblemThe I2CR-1 problem is shown in Figure 3.
A firstkey idea is to introduce a new variable q(i, j, k) foreach k ?
[n], i ?
[lk]0, j ?
[mk]: that is, a newvariable for each triple (i, j, k) specifying a sen-tence pair, and a specific English and French posi-tion in that sentence.
Each q variable must satisfythe constraints in Eqs.
13-15, repeated here for con-venience:?i, j, k, q(i, j, k) ?
0 ,?i, j, k, q(i, j, k) ?
d(i|j) ,?i, j, k, q(i, j, k) ?
t(f (k)j |e(k)i ) .The objective function is1nn?k=1mk?j=1loglk?i=0q(i, j, k)which is similar to the objective function in Figure 1,but where t(f (k)j |e(k)i )?d(i|j) has been replaced byq(i, j, k).
The intuition behind the new problem is asfollows.
If, instead of the constraints in Eqs.
13-15,we had the constraintq(i, j, k) = t(f (k)j |e(k)i )?
d(i|j) , (17)then the I2CR-1 problem would clearly be identi-cal to the IBM Model 2 optimization problem.
Wehave used a standard relaxation of the non-linearconstraint x = y ?
z where x, y, z are all variablesin the range [0, 1], namelyx ?
y ,x ?
z ,x ?
y + z ?
1 .These inequalites are a relaxation in the sense thatany (x, y, z) triple that satisfies x = y ?
z also sat-isfies these constraints.
Applying this relaxation toEq.
17 givesq(i, j, k) ?
t(f (k)j |e(k)i ) ,q(i, j, k) ?
d(i|j) ,q(i, j, k) ?
t(f (k)j |e(k)i ) + d(i|j)?
1 .
(18)The final thing to note is that the constraint inEq.
18 can be omitted in the I2CR-1 problem.
Thisis because the task is to maximize the objectivewith respect to the q variables and the objectiveis strictly increasing as the q values increase?thuslower bounds on their values are redundant in theI2CR-1 problem.It is easily verified that the constraints in theI2CR-1 problem are linear, and that the objectivefunction is convex.
In Section 5 of this paper wedescribe an optimization method for the problem.Note that because the objective function is beingmaximized, and the objective increases monotoni-cally as the q values increase, at the global optimum11More precisely, at any global optimum: the objective func-tion may not be strictly convex, in which case there will be mul-tiple global optima.1577Input: Same as in I2CR-1 (Figure 4).Parameters: Same as in I2CR-1 (Figure 4).Constraints: Same as in I2CR-1 (Figure 4).Objective: Maximize12nn?k=1mk?j=1log?lk?i=0q(i, j, k)+12nn?k=1mk?j=1log?lk?i=0t(f (k)j |e(k)i )(L+ 1)with respect to the q(i, j, k), t(f |e) and d(i|j) pa-rameters.Figure 4: The I2CR-2 (IBM 2 Convex Relaxation) Prob-lem, version 2.
The problem is identical to the I2CR-1problem, but it also includes a term in the objective func-tion that is identical to the IBM Model 1 objective.
Wedefine log?
(z) = log(z + ?)
where ?
is a small positiveconstant.we haveq(i, j, k) = min{t(f (k)j |e(k)i ), d(i|j)} ,where min{x, y} returns the minimum of the twovalues x and y.
Thus, we could actually eliminatethe q variables and write an optimization problemthat is identical to the IBM Model 2 optimizationproblem, but with the objective function1nn?k=1mk?j=1loglk?i=0min{t(f (k)j |e(k)i ), d(i|j)} .It will turn out that both views of the I2CR-1problem?with and without the q variables?arehelpful, so we have included both in this paper.4.2 The I2CR-2 ProblemFigure 4 shows the refined optimization problem,which we call I2CR-2.
The problem incorporatestwo modifications.
First, we modify the objectivefunction to be12nn?k=1mk?j=1log?lk?i=0q(i, j, k)+12nn?k=1mk?j=1log?lk?i=0t(f (k)j |e(k)i )(L+ 1).Thus the objective function includes a second termthat is identical to the objective function for IBMModel 1 (see Figure 2).
In preliminary experimentswith the I2CR-1 optimization problem, we foundthat the I2CR-1 objective was not sufficiently depen-dent on the t parameters: intuitively, if the d param-eters achieve the min on many training examples,the values for the t variables become unimportant.The addition of the IBM Model 1 objective fixed thisproblem by introducing a term that depends on the tvalues alone.Second, we replace log by log?, where log?
(z) =log(z + ?
), and ?
is a small positive constant (inour experiments we used ?
= 0.001).
Under thisdefinition the derivatives of log?
are upper-boundedby 1/?, in contrast to log, where the derivativescan diverge to infinity.
The optimization methodswe use are gradient-based methods (or more pre-cisely, subgradient-based methods), and we havefound them to be considerably more stable when thevalues for gradients do not diverge to infinity.The modified objective remains convex.5 A Stochastic Exponentiated-GradientAlgorithm for OptimizationWe now describe an algorithm for optimizing theI2CR-2 problem in Figure 4.
The algorithm isclosely related to stochastic gradient ascent, but withtwo modifications:?
First, because the t(f |e) and d(i|j) parame-ters have simplex constraints (see Figure 1),we use exponentiated gradient (EG) updates.EG algorithms are gradient-based methods thatmaintain simplex constraints; see for exam-ple: (Kivinen and Warmuth, 1997; Beck andTeboulle, 2003; Collins et al 2008).?
Second, the objective function in the I2CR-2 problem is convex, but is not differentiable(the gradient may not exist at all points).
Forthis reason we use subgradients in the place ofgradients.
In spite of the non-differentiabilityof the objective function, subgradient meth-ods still have strong convergence guaranteeswhen combined with EG updates (e.g., the con-vergence proofs in (Beck and Teboulle, 2003)1578go through with minor modifications; see also(Bertsekas, 1999)).To derive the updates, recall that we are maximiz-ing the following objective function:h(t, d)=12|T |?k?Tmk?j=1log?lk?i=0min{t(f (k)j |e(k)i ), d(i|j)}+12|T |?k?Tmk?j=1log?lk?i=0t(f (k)j |e(k)i )(L+ 1).
(19)Here we use T to denote the set {1 .
.
.
n}; we willsee shortly why this notation is convenient.
We uset and d to refer to the full set of t and d parametersrespectively; h(t, d) is the function to be maximized.Recall that log?
(z) = log(z + ?)
where ?
is a smallpositive parameter.Given a concave function f(x) where x ?
Rd, asubgradient of f(x) at x is any vector g(x) ?
Rdsuch that for any y ?
Rd,f(y) ?
f(x) + g(x) ?
(y ?
x) ,where u?v is the inner product between vectors u andv.
Subgradients are similar to gradients for differ-entiable concave functions, in that gradients satisfythe above property.
Subgradients can be used in theplace of gradients in many optimization algorithms(see for example (Bertsekas, 1999)).The subgradients for the objective function inEq.
19 take a simple form.
First, defineR(j, k) = ?+lk?i=0t(f (k)j |e(k)i ) ,Q(j, k) = ?+lk?i=0min{t(f (k)j |e(k)i ), d(i|j)} ,andI(i, j, k) ={1 if t(f (k)j |e(k)i ) ?
d(i|j)0 otherwise .Then the subgradients2 are?t(f |e) =12|T |?i,j,k:f(k)j =fe(k)i =e(1R(j, k)+I(i, j, k)Q(j, k))2We set ?t(f |e) and ?d(i|j) as the subgradients for theobjective function in Eq.
19 with respect to t(f |e) and d(i|j)respectively.and?d(i|j) =12|T |?k:i?lk,j?mk1?
I(i, j, k)Q(j, k).Exponentiated-gradient updates then take the fol-lowing form:t(f |e)?t(f |e)?
exp{?
?
?t(f |e)}?f t(f |e)?
exp{?
?
?t(f |e)}(20)andd(i|j)?d(i|j)?
exp{?
?
?d(i|j)}?i d(i|j)?
exp{?
?
?d(i|j)}, (21)where ?
> 0 is a constant step size in the algorithm.Note that the EG updates make use of subgradients,but maintain the simplex constraints on the t and dvariables.The method just described is a batch gradientmethod, where the entire training set T = {1 .
.
.
n}is used to derive the subgradients before the updatesin Eqs.
20 and 21 are made.
Many results in ma-chine learning and NLP have shown that stochasticgradient methods, where a subset of the training ex-amples is used before each gradient-based update,can converge much more quickly than batch gradi-ent methods.
In our notation, this simply involvesreplacing T by some subset T ?
of the training exam-ples in the above definitions, where |T ?| is typicallymuch smaller than |T |.Figure 5 shows our final algorithm, a stochasticversion of the exponentiated-gradient method.
Themethod takes S passes over the data.
For each pass,it randomly partitions the training set into mini-batches T1 .
.
.
TK of size B, where B is an integerspecifying the size of each mini-batch (in our exper-iments we used B = 125 or B = 250).
The al-gorithm then performs EG updates using each mini-batch T1 .
.
.
TK in turn.
As can be seen in Table 3,our experiments show that the algorithm makes verysignificant progress in the first pass over the data,and takes very few iterations to converge to a goodsolution even though we initialized with uniform pa-rameter values.6 ExperimentsIn this section we describe experiments using theI2CR-2 optimization problem combined with the15791: Input: Define E, F , L, M , (e(k), f (k), lk,mk)for k = 1 .
.
.
n, D(e) for e ?
E as in Section 3.An integer B specifying the batch size.
An inte-ger S specifying the number of passes over thedata.
A step size ?
> 0.
A parameter ?
> 0used in the definition of log?
.2: Parameters:?A parameter t(f |e) for each e ?
E, f ?
D(e).
?A parameter d(i|j) for each i ?
[L]0, j ?
[M ].3: Definitions:R(j, k) = ?+lk?i=0t(f (k)j |e(k)i )Q(j, k) = ?+lk?i=0min{t(f (k)j |e(k)i ), d(i|j)}4: Initialization:?
?e ?
E, f ?
D(e), t(f |e) = 1/|D(e)|?
?j ?
[M ], i ?
[L]0, d(i|j) = 1/(L+ 1)5: Algorithm:6: for all s = 1 to S do7: Randomly partition [n] into subsets T1 .
.
.
TK ofsize B where K = n/B.8: for all b = 1 to K do9: ?e ?
E, f ?
D(e), ?
(e, f) = 010: ?j ?
[M ], i ?
[L]0, ?
(i, j) = 011: for all k ?
Tb do12: for all j = 1 to mk do13: for all i = 0 to lk do14: ?
(e(k)i , f(k)j ) += 1/(2R(j, k))15: if t(f (k)j |e(k)i ) ?
d(i|j) then16: ?
(e(k)i , f(k)j ) += 1/(2Q(j, k))17: else18: ?
(i, j) += 1/(2Q(j, k))19: ?e, f, t(f |e) = t(f |e) exp (?
?
?
(e, f)/B)20: ?i, j, d(i|j) = d(i|j) exp (?
?
?
(i, j)/B)21: Renormalize t and d parameters to satisfy?f t(f |e) = 1 and?i d(i|j) = 1.22: Output: t and d parameters.Figure 5: The stochastic exponentiated-gradient algo-rithm for optimization of I2CR-2.stochastic EG algorithm for parameter estimation.We first describe the data sets we use, and then de-scribe experiments with the method, comparing ourapproach to results from IBM Model 2.
We com-pare the various algorithms in terms of their accu-racy in recovering alignments, using metrics such asF-measure and AER.6.1 Data SetsWe use data from the bilingual word alignmentworkshop held at HLT-NAACL 2003 (Michalceaand Pederson, 2003).
As a first dataset, we use theCanadian Hansards bilingual corpus, with 247,878English-French sentence pairs as training data, 37sentences of development data, and 447 sentencesof test data (note that we use a randomly chosensubset of the original training set of 1.1 million sen-tences, similar to the setting used in (Moore, 2004)).The development and test data have been manuallyaligned at the word level, annotating alignments be-tween source and target words in the corpus as ei-ther ?sure?
(S) or ?possible?
(P ) alignments, as de-scribed in (Och and Ney, 2003).As a second data set, we used the Romanian-English data from the HLT-NAACL 2003 workshop.This consisted of a training set of 48,706 Romanian-English sentence-pairs, a development set of 17 sen-tence pairs, and a test set of 248 sentence pairs.6.2 MethodologyFor each of the models?IBM Model 1, IBM Model2, and I2CR-2?we follow convention in applyingthe following methodology: first, we estimate thet and d parameters using models in both source-target and target-source directions; second, we findthe most likely alignment for each development ortest data sentence in each direction; third, we takethe intersection of the two alignments as the finaloutput from the model.For the EG algorithm we use a batch size B =250 and step size ?
= 0.5 on the Hansards data, andB = 125 and ?
= 0.5 for the Romanian-Englishdata.We report the performance of the models in termsof Precision, Recall, AER, and F-Measure as definedby (Och and Ney, 2003).
If A is the set of align-ments produced by an algorithm, S is the set of surealignments as annotated in test data, and P is theset of possible alignments, then these quantities aredefined asRecall =|A ?
S||S|,1580Precision =|A ?
S||A|,AER = 1?|A ?
S|+ |A ?
P ||A|+ |S|,F-Measure =1.5Recall +.5Precision.Note that we report results in both AER andF-measure; however there is evidence (Fraser andMarcu, 2004) that F-measure is better correlatedwith translation quality when the alignments areused in a full system.In training IBM Model 1 we follow (Moore,2004) in running EM for 15 iterations.
In trainingIBM Model 2 we first train IBM Model 1 for 15iterations to initialize the t parameters, then trainIBM Model 2 for a further 10 iterations.
For theEG algorithm, we use 10 iterations over the trainingdata for the Hansards data, and 15 iterations on theRomanian-English data (on the latter dataset resultson the trial data showed that the method took slightlylonger to converge).
We report F-measure and AERresults for each of the iterations under the IBMModel 2 and I2CR-2 models.
See Table 1 for the re-sults on the Hansards data, and Table 2 for the resultson the English-Romanian dataset.
It can be seen thatboth I2CR-2 and IBM Model 2 converge to a fairlystable result after 2-3 iterations.
The two modelsgive very similar levels of performance, for exampleafter 10 iterations on the Hansard data IBM Model2 gives 14.22 AER and 0.7516 F-Measure versus14.60 AER and 0.7506 F-Measure for I2CR-2.On the right, Table 3 shows the values of the ob-jective function at each iteration when using the EGalgorithm to optimize the I2CR-2 objective.
Themethod makes a large amount of progress on the firstiteration and then continues to improve.
Finally, wenote that the memory requirements for I2CR-2 andIBM2 are about the same, but that the time for oneiteration of I2CR-2 on the Hansards data is approxi-mately one hour, while the time for one iteration ofIBM2 was approximately 10 minutes.7 Conclusions and Future WorkWe have introduced the first convex model for un-supervised learning of alignments in statistical ma-chine translation with performance comparable toIteration IBM2 I2CR-2 IBM2 I2CR-2AER AER F-Measure F-MeasureTest Set Statistics1 0.1491 0.1556 0.7530 0.73692 0.1477 0.1489 0.7519 0.74563 0.1451 0.1476 0.7527 0.74674 0.1426 0.1488 0.7536 0.74495 0.1422 0.1495 0.7535 0.74726 0.1431 0.1476 0.7511 0.74787 0.1434 0.1506 0.7506 0.74568 0.1437 0.1495 0.7501 0.74709 0.1434 0.1494 0.7501 0.746810 0.1422 0.1460 0.7516 0.7506Development Set Statistics1 0.1871 0.1971 0.6823 .66762 0.1896 0.1760 0.6758 .68273 0.1964 0.1860 0.6648 .67394 0.1912 0.1835 0.6713 .67755 0.1884 0.1813 0.6740 .067736 0.1836 0.1851 0.6767 0.68117 0.1831 0.1806 0.6749 0.67658 0.1842 0.1843 0.6739 0.67759 0.1864 0.1928 0.6694 0.664010 0.1845 0.1829 0.6703 .6721Table 1: Results on the Hansards data for IBM Model 2and the I2CR-2 method.Iteration IBM2 I2CR-2 IBM2 I2CR-2AER AER F-Measure F-MeasureTest Set Statistics1 0.4041 0.5354 0.5959 0.46462 0.4010 0.4764 0.5990 0.52563 0.4020 0.4543 0.5980 0.54574 0.4012 0.4384 0.5988 0.56175 0.4003 0.4277 0.5997 0.57236 0.3990 0.4266 0.6010 0.58347 0.4000 0.4162 0.6000 0.58388 0.4023 0.4114 0.5977 0.58869 0.4022 0.4081 0.5978 0.591910 0.4027 0.4043 0.5973 0.595711 0.4031 0.4040 0.5969 0.596012 0.4042 0.4027 0.5958 0.597313 0.4043 0.4021 0.5957 0.597914 0.4062 0.4007 0.5938 0.599315 0.4057 0.4014 0.5943 0.5986Development Set Statistics1 0.4074 0.5841 0.5926 0.41592 0.3911 0.4938 0.6089 0.50623 0.3888 0.4673 0.6112 0.53274 0.3904 0.4596 0.6096 0.54045 0.3881 0.4463 0.6119 0.55376 0.3904 0.4306 0.6096 0.56947 0.3936 0.4175 0.6094 0.58268 0.3897 0.4060 0.6103 0.59409 0.3961 0.4014 0.6039 0.598610 0.3970 0.4072 0.6030 0.592811 0.4018 0.3956 0.5982 0.604412 0.4035 0.3931 0.5965 0.606913 0.4035 0.3862 0.5965 0.613814 0.4014 0.3908 0.5986 0.609215 0.4063 0.3858 0.5937 0.6142Table 2: Results on the English-Romanian data for IBMModel 2 and the I2CR-2 method.1581Iteration EF Objective FE Objective0 -99.6053 -79.55661 -32.4528 -27.49252 -31.1641 -26.2623 -30.6311 -25.70934 -30.3367 -25.37145 -30.1428 -25.14566 -30.0000 -24.9927 -29.8736 -24.86058 -29.8093 -24.75519 -29.7326 -24.68410 -29.6771 -24.6099Table 3: Objective values for the EG algorithm opti-mization of I2CR-2 at each iteration.
?EF Objective?corresponds to training a model with t(e|f) parameters,?FE Objective?
corresponds to the reverse direction, witht(f |e) parameters.
Iteration 0 corresponds to the objec-tive value under the initial, uniform parameter values.the commonly-used IBM Model 2.
We believethat introducing convexity without sacrificing per-formance will open the door to further improve-ments in this area.
Future work will consider ways tospeed up our algorithm and extensions of the methodto more complex alignment models.AcknowledgmentsMichael Collins is partly supported by NSF grantIIS-1161814.
Cliff Stein is partly supported by NSFgrant CCF-0915681.
The authors thank Sasha Rushfor his help with implementation questions.
Wealso thank the anonymous reviewers for many use-ful comments; we hope to pursue the comments wewere not able to address in a followup paper.ReferencesPeter L. Bartlett, Ben Taskar, Michael Collins and DavidMcallester.
2004.
Exponentiated Gradient Algorithmsfor Large-Margin Structured Classification.
In Pro-ceedings of NIPS.Amir Beck and Marc Teboulle.
2003.
Mirror Descent andNonlinear Projected Subgradient Methods for ConvexOptimization.
Operations Research Letters, 31:167-175.Dimitris Bertsimas and John N. Tsitsiklis.
1997.
Intro-duction to Linear Programming.
Athena Scientific.Dimitris Bertsimas.
2005.
Optimization Over Integers.Dynamic Ideas.Dimitri P. Bertsekas.
1999.
Nonlinear Optimization.Athena Press.Steven Boyd and Lieven Vandenberghe.
2004.
ConvexOptimization.
Cambridge University Press.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert.
L. Mercer.
1993.
The Mathematicsof Statistical Machine Translation: Parameter Estima-tion.
Computational Linguistics, 19:263-311.David Chiang.
2005.
A Hierarchical Phrase-Based Modelfor Statistical Machine Translation.
In Proceedings ofthe ACL.Michael Collins, Amir Globerson, Terry Koo, XavierCarreras and Peter L. Bartlett.
2008.
ExponentiatedGradient Algorithms for Conditional Random Fieldsand Max-Margin Markov Networks.
Journal MachineLearning, 9(Aug): 1775-1822.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum Likelihood From Incomplete Data via theEM Algorithm.
Journal of the royal statistical society,series B, 39(1):1-38.Alexander Fraser and Daniel Marcu.
2007.
Measur-ing Word Alignment Quality for Statistical Ma-chine Translation.
Journal Computational Linguistics,33(3): 293-303.Kuzman Ganchev, Joao V. Graca, Jennifer Gillenwater,Ben Taskar.
2010.
Posterior Regularization for Struc-tured Latent Variable Models.
Journal of MachineLearning, 11(July): 2001-2049.Joao V. Graca, Kuzman Ganchev and Ben Taskar.
2007.Expectation Maximization and Posterior Constraints.In Proceedings of NIPS.Aria Haghighi, John Blitzer, John DeNero and Dan Klein.2009.
Better Word Alignments with Supervised ITGModels.
In Proceedings of the ACL.Darcey Riley and Daniel Gildea.
2012.
Improving theIBM Alignment Models Using Variational Bayes.
InProceedings of the ACL.Yuhong Guo and Dale Schuurmans.
2007.
Convex Relax-ations of Latent Variable Training.
In NIPS.Simon Lacoste-Julien, Ben Taskar, Dan Klein, andMichael Jordan.
2008.
Word Alignment via QuadraticAssignment.
In Proceedings of the HLT-NAACL.Phillip Koehn.
2008.
Statistical Machine Translation.Cambridge University Press.Kivinen, J., Warmuth, M. 1997.
Exponentiated GradientVersus Gradient Descent for Linear Predictors.
Infor-mation and Computation, 132, 1-63.Percy Liang, Ben Taskar and Dan Klein.
2006.
Alignmentby Agreement.
In Proceedings of NAACL.Daniel Marcu, Wei Wang, Abdessamad Echihabi,and Kevin Knight.
2006.
SPMT: Statistical Ma-chine Translation with Syntactified Target LanguagePhrases.
In Proceedings of the EMNLP.1582Andre F. T. Martins, Noah A. Smith and Eric P. Xing.2010.
Turbo Parsers: Dependency Parsing by Ap-proximate Variational Inference.
In Proceedings of theEMNLP.Rada Michalcea and Ted Pederson.
2003.
An Evalua-tion Exercise in Word Alignment.
HLT-NAACL 2003:Workshop in building and using Parallel Texts: DataDriven Machine Translation and Beyond.Robert C. Moore.
2004.
Improving IBM Word-Alignment Model 1.
In Proceedings of the ACL.Stephan Vogel, Hermann Ney and Christoph Tillman.1996.
HMM-Based Word Alignment in StatisticalTranslation.
In Proceedings of COLING.Franz Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational-Linguistics, 29(1): 19-52.Libin Shen, Jinxi Xu and Ralph Weischedel.
2008.
ANew String-to-Dependency Machine Translation Al-gorithm with a Target Dependency Language Model.In Proceedings of the ACL-HLT.Ben Taskar, Simon Lacoste-Julien and Dan Klein.
2005.A Discriminative Matching Approach to Word Align-ment.
In Proceedings of the EMNLP.Kristina Toutanova and Michel Galley.
2011.
Why Ini-tialization Matters for IBM Model 1: Multiple Optimaand Non-Strict Convexity.
In Proceedings of the ACL.Kenji Yamada and Kevin Knight.
2001.
A Syntax-BasedStatistical Translation Model.
In Proceedings of theACL.Kenji Yamada and Kevin Knight.
2002.
A Decoder forSyntax-Based Statistical Machine Translation.
In Pro-ceedings of the ACL.Ashish Vaswani, Liang Huang and David Chiang.
2012.Smaller Alignment Models for Better Translations:Unsupervised Word Alignment with the L0-norm.
InProceedings of the ACL.1583
