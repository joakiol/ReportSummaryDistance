Proceedings of NAACL HLT 2007, Companion Volume, pages 157?160,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsAre Some Speech Recognition ErrorsEasier to Detect than Others?Yongmei ShiDepartment of Computer Scienceand Electrical EngineeringUniversity of Maryland, Baltimore CountyBaltimore, MD 21250yshi1@umbc.eduLina ZhouDepartment of Information SystemsUniversity of Maryland, Baltimore CountyBaltimore, MD 21250zhoul@umbc.eduAbstractThis study investigates whether somespeech recognition (SR) errors are eas-ier to detect and what patterns can beidentified from those errors.
Specifically,SR errors were examined from both non-linguistic and linguistic perspectives.
Theanalyses of non-linguistic properties re-vealed that high error ratios and consecu-tive errors lowered the ease of error detec-tion.
The analyses of linguistic propertiesshowed that ease of error detection was as-sociated with changing parts-of-speech ofreference words in SR errors.
Addition-ally, syntactic relations themselves and thechange of syntactic relations had impacton the ease of error detection.1 IntroductionSpeech recognition (SR) errors remain as one of themain impediment factors to the wide adoption ofspeech technology, especially for continuous large-vocabulary SR applications.
As a result, loweringword error rate is the focus of SR research whichcan benefit from analyzing SR errors.
SR errorshave been examined from various perspectives: lin-guistic regularity of errors (McKoskey and Boley,2000), the relationships between linguistic factorsand SR performance (Greenberg and Chang, 2000),and the associations of prosodic features with SR er-rors (Hirschberg et al, 2004).
However, little is un-derstood about patterns of errors with regard to easeof detection.Analyzing SR errors can be helpful to error detec-tion.
Skantze and Edlund (2004) conducted a userstudy to evaluate the effects of various features onerror detection.
Our study is different in that it in-vestigates the relationships between the characteris-tics of SR errors and their ease of detection throughan empirical user study.
Given two SR systems withthe same word error rates, the output of one systemcould be more useful if its errors are easier to detectthan the other.
Accordingly, SR and its error de-tection research could focus on addressing difficulterrors by developing automatic solutions or by pro-viding decision support to manual error detection.2 ExperimentA laboratory experiment was carried out to evaluatehumans?
performance in SR error detection.2.1 Experimental DataSpeech transcripts were extracted from a dictationcorpus on daily correspondence in office environ-ment generated using IBM ViaVoice under high-quality condition (Zhou et al, 2006).Eight paragraphs were randomly selected fromthe transcripts of two task scenarios based on twocriteria: recognition accuracy and paragraph length(measured by # of words).
Specifically, the over-all recognition accuracy (84%) and the length of amedium-sized paragraph (90 words) of the corpuswere used as references.The selected paragraphs consist of 36 sentences.Sentence lengths range from 9 to 38 words, with anaverage of 20.
For error detection, SR output in-stead of references is a better base for computing157error rates because SR output but not reference tran-scripts are accessible during error detection.
Thismay result in fewer number of deletion errors be-cause when one SR error maps to several referencewords, it is counted as one substitution error.
Basedon this method, there are totally 140 errors in theselected data: 104 substitution, 31 insertion, and 5deletion errors.
The error ratio, defined as the ratioof the number of errors to the number of words inoutput sentence, ranges from 4.76% to 61.54%.2.2 Task and ProcedureParticipants were required to read error annotationschema and sample transcripts prior to the exper-iment, and could attend the experiment only af-ter they passed the test on their knowledge of theschema and SR output.Each participant was asked to detect errors in alleight paragraphs.
All sentences in the same para-graphs were presented all at once.
The paragraphswere presented with different methods, includingthree with no additional information, three with al-ternative hypotheses, and two with both dictationscenario and alternative hypotheses.
The sequenceof paragraphs and their presentation methods wererandomized for each participant.Ten participants from a mid-sized university inthe U.S. completed the study.
They were all nativespeakers and none of them was professional editor.3 Analysis and DiscussionIn this section, we analyze the relationship betweencharacteristics of SR errors and ease of error detec-tion.
We characterize errors with non-linguistic andlinguistic properties and further break down the lat-ter into parts-of-speech and syntactic relations.3.1 Ease of Error DetectionThe ease of detecting an error was defined as thenumber of participants who successfully detectedthe error.
When computing the ease of error detec-tion, we merged all the data by ignoring the presen-tation methods.
The decision was made because arepeated measure ANOVA of recall failed to yielda significant effect of presentation methods (p =n.s.).
The recall was selected because it measuresthe percentage of actual errors being detected andthe focal interest of this study was actual errors.
Theaverage recalls of error detection of three presenta-tion methods were very close, ranging from 72% to75%.The ease values fell between 0 and 10, with 0 be-ing the least ease when all participants missed the er-ror and 10 being the most ease when everyone foundthe error.
To improve the power of statistical analy-ses, errors were separated into 3 groups using equal-height binning based on their ease values, namely 1for low, 2 for medium, and 3 for high (see Table 1).The overall average ease value was 2.15.Level of Ease Ease Values # of ErrorsLow (1) 0-5 39Medium (2) 6-8 41High (3) 9-10 60Table 1: Grouping of ease values3.2 Non-linguistic Error PropertiesThree non-linguistic error properties, including errorratio, word error type, and error sequence (in isola-tion or next to other errors) were selected to examinetheir relationships with ease of error detection.Two-tailed correlation analyses of error ratio andease of detection showed that the Pearson correla-tion coefficient was -0.477 (p < 0.01), which sug-gests that it is easier to detect errors in sentenceswith lower error ratios.One way ANOVA failed to yield a significant ef-fect of error type on ease of detection (p = n.s.
).Nonetheless, mean comparisons showed that inser-tion errors were less easy to detect (mean = 2.03)than deletion errors (mean = 2.20) and substitutionerrors (mean = 2.18).
Users may have difficulty injudging extra words.Among the 140 errors, about half of them (i.e., 71)were next to some other errors.
One way ANOVArevealed a significant effect of error sequence onease of detection, p < 0.05.
Specifically, isolatederrors (mean = 2.33) are easier to detect than con-secutive errors (mean = 1.97).3.3 Part-Of-Speech(POS)SR output and reference transcripts were analyzedusing Brill?s part-of-speech tagger (Brill, 1995).
Toalleviate data sparsity problem, we adopted second-158level tags such as NN and VB.
The POSes of SRerrors as well as POS change patterns between ref-erence words and SR errors were analyzed.Table 2 reports the average eases of detection fordifference POSes on all the errors, substitution er-rors only, and insertion errors only.
Deletion errorswere not included because they did not appear in SRoutput.
Only those POSes with frequency of at least10 in all the errors were selected.POS All Substitution InsertionNN 2.03 2.00 2.25VB 2.30 2.41 1.67CC 2.21 2.38 1.83IN 2.22 2.27 2.00DT 1.80 2.25 1.50Table 2: Ease of detection for different POSesIt was easier to detect verbs that were misplacedthan verbs that were inserted mistakenly (p < 0.1in one-tailed results).
This is because an additionalverb may change syntactic and semantic structuresof entire sentence.
Similar patterns held for both CCand DT (p < 0.1 in one-tailed results).
The lessease in detecting DT and CC when they were in-serted than replaced is due in part to the fact thatthey play significant syntactic roles in constructinga grammatical sentence.
Further, ease of detectingDT was lower than the average ease of all errors(p < 0.1 in one-tailed results).Only substitution errors were applicable in POSchange analysis.
POS change was set to ?Y?
whenthe POSes of an SR error and its corresponding ref-erence word were different, and ?N?
when otherwise.This resulted in 69 Ys and 35 Ns.
One way ANOVAresults yielded a significant effect of POS changeon ease of detection (p < 0.05).
Specifically, itwas easier to detect errors that had different POSes(mean = 2.32) from their references than those thatshared the same POSes (mean = 1.91).
This ispartly due to the requirements of semantic and evendiscourse information in detecting errors from thesame POSes.3.4 Syntactic RelationsBoth SR output and reference transcripts wereparsed using minipar (Lin, 1998), a principle-basedparser that can generate a dependency parse tree foreach sentence.
The dependency relations betweenSR errors and other words in the same sentence wereextracted as the syntactic relations of SR errors.
Thesame kinds of relations were also extracted for cor-responding reference words.Three types of properties of syntactic relationswere analyzed, including the number of syntacticrelations, syntactic relation change, and errors?
pat-terns of syntactic relations.Table 3 reports descriptive statistics of ease ofdetection for SR errors with varying numbers ofsyntactic relations.
The average number of syntac-tic relations for all errors was 1.64.
Analysis re-sults showed that it was easier to detect errors withno syntactic relations than those with one relation(p < 0.05).
The analysis of correlation between thenumber of syntactic relations and the ease of detec-tion yielded a very small Pearson correlation coef-ficient (p = n.s.).
They suggest that errors that donot fit into a sentence are easy to detect.
However,increasing the number of syntactic relations does notlower the ease of detection.# of Syntactic Mean Std FrequencyRelations Deviation0 2.40 0.695 351 1.98 0.883 512 2.21 0.918 193 2.00 0.791 17> 3 2.22 0.808 18Table 3: Ease of detection for numbers of relationsSame as POS change, only substitution errorswere considered in syntactic relation change anal-ysis, and the values of the syntactic changes wereset similarly.
By dividing the syntactic relations intohead and modifier according to whether the wordsserved as heads in the relations, we also derived syn-tactic changes for head and modifier relations, re-spectively.Two-way ANOVA analyses of head and modifiersyntactic relation changes yielded a significant in-teraction effect (p < 0.05).
A post-hoc analysisrevealed that, when the modifier syntactic relationswere the same, it was easier to detect errors that didnot cause the change of head syntactic relations than159those causing such changes (p < 0.05).Table 4 reports descriptive statistics of ease of de-tection in terms of syntactic relations of SR errorsthat occurred at least 5 times.
Two relations werepresented in the ?Syntactic Relations?
column.
Thefirst one is the relation in which errors played thehead role, and the second one is the relation that er-rors served as a modifier.
?None?
indicates no suchrelations exist.Syntactic Mean Std FrequencyRelations Deviationnone none 2.40 0.695 35none subj 2.70 0.675 10none det 1.78 0.833 9none punc 2.00 0.926 8none nn 2.00 1.000 7none pcomp-n 2.33 1.033 6mod pcomp-n 1.20 0.447 5none obj 1.80 0.837 5Table 4: Ease of detection for syntactic relationsIt is shown in Table 4 that it is easier to detect ifan error is the subject of a verb (subj).
A typical ex-ample is the ?summary?
in sentence ?summary willhave to make my travel arrangement ... ?.
All theparticipants successfully detected ?summary?
as anerror.
In contrast, ?mod pcomp-n?
was difficult todetect.
Manual scrutinizing of the data showed thatsuch errors were nouns that both have some otherwords/phrases as modifier (mod) and are nominalcomplements of a preposition (pcomp-n).
For exam-ple, for ?transaction?
in sentence ?I?m particularlyinterested in signal transaction in ...
?, 80% partic-ipants failed to detect the error.
It requires domainknowledge to determine the error.4 Conclusion and Future WorkThis study revealed that both high error ratio andconsecutive errors increased the difficulty of errordetection, which highlights the importance of SRperformance.
In addition, it was easier to detectSR errors when they had different POSes from cor-responding reference words.
Further, SR errorslacking syntactic relations were easy to detect, andchanges in syntactic relations of reference words inSR errors had impact on the ease of error detection.The extracted patterns could advance SR and auto-matic error detection research by accounting for theease of error detection.
They could also guide thedevelopment of support systems for manual SR er-ror correction.This study brings up many interesting issues forfuture study.
We plan to replicate the study with au-tomatic error detection experiment.
Additional ex-periments would be conducted on a larger data set toextract more robust patterns.AcknowledgementThis work was supported by the National ScienceFoundation (NSF) under Grant 0328391.
Any opin-ions, findings and conclusions or recommendationsexpressed in this material are those of the authorsand do not necessarily reflect the views of NSF.ReferencesEric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: A casestudy in part of speech tagging.
Computational Lin-guistics, 21(4):543?565.Steven Greenberg and Shuangyu Chang.
2000.
Linguis-tic dissection of switchboard-corpus automatic speechrecognition systems.
In Proceedings of the ISCAWorkshop on Automatic Speech Recognition: Chal-lenges for the New Millennium.Julia Hirschberg, Diane Litman, and Marc Swerts.
2004.Prosodic and other cues to speech recognition failures.Speech Communication, 43:155?175.Dekang Lin.
1998.
Dependency-based evaluation ofminipar.
In Proceedings of the Workshop on the Eval-uation of Parsing Systems.David McKoskey and Daniel Boley.
2000.
Error analysisof automatic speech recognition using principal direc-tion divisive partitioning.
In Proceedings of ECML,pages 263?270.Gabriel Skantze and Jens Edlund.
2004.
Early error de-tection on word level.
In Proceedings of Robustness.Lina Zhou, Yongmei Shi, Dongsong Zhang, and An-drew Sears.
2006.
Discovering cues to error detec-tion in speech recogntion output: A user-centered ap-proach.
Journal of Management of Information Sys-tems, 22(4):237?270.160
