In: Proceedings of CoNLL-2000 and LLL-2000, pages 167-175, Lisbon, Portugal, 2000.Extracting a Domain-Specif ic Ontology from a Corporate IntranetJ S rg -Uwe K ie tz  and Raphae l  Vo lzSwiss Life, Corporate Center, IT Research ~z Development, Zfirich, Switzerlanduwe.
kietz@swisslife, ch, ed.
raphael@leahpar, deAlexander  MaedcheAIFB, Univ.
Karlsruhe, D-76128 Karlsruhe, Germanymaedche@aifb,  un i -kar l s ruhe ,  deAbst rac tThis paper describes our actual and ongoingwork in supporting semi-automatic ontology ac-quisition from a corporate intranet of an in-surance company.
A comprehensive architec-ture and a system for semi-automatic ontologyacquisition supports processing semi-structuredinformation (e.g.
contained in dictionaries)and natural language documents and includ-ing existing core ontologies (e.g.
GermaNet,WordNet).
We present a method for acquir-ing a application-tailored domain ontology fromgiven heterogeneous intranet sources.1 In t roduct ion1.1 Need for focused  access  toknowledgeThe amount of information available to corpo-rate employees has grown drastically with theuse of intranets.
Unfortunally this growth ofavailable information has made the access touseful or needed information ot much easier asthe access is usually based on keyword searchingor even browsing.
The focused access to knowl-edge resources like intranet documents plays avital role in knowledge management and sup-ports in general the shifting towards a SemanticWeb.Keyword searching results in a lot of irrele-vant information as a term can have differentmeanings in distinct contents, e.g.
"Ziirich" asthe name of a town and as the name of an in-surance company.
Presently it is quite difficultto provide this information to the search engine,e.g.
exclude all the information about the town"Ziirich" without losing information about theinsurance company "Ziirich'.The project On-To Knowledge builds anontology-based tool environment to performknowledge management dealing with large num-bers of heterogeneous, distributed and semi-structured ocuments as found within large in-tranets and the World-Wide Web (Fensel et al,2000).
In this project ontologies play a keyrole by providing a common understanding ofthe domain.
Semantically annotated documentsare accessed using the vocabulary provided bya domain-specific ontology.Providing the user with an access methodbased on ontological terms instead of keywordshas several advantages.
First, the abstractiongiven by the ontology provides that the userdoes not have to deal with document-specificrepresentations.
Second, by this abstraction ro-bustness towards changes in content and formatof the accessed ocuments i gained.1.2 Semi -automat ic  vs .
manua lonto logy const ruct ionThe required omain-specific ontologies for On-To-Knowledge are built manually.
Ontolo-gies are usually built using tools like OntoEdit(Staab and Maedche, 2000) or Protege (Grossoet al, 1999).
Using such tools has simplified on-tology construction.
However, the wide-spreadusage of ontologies is still hindered by the time-consuming and expensive manual constructiontask.Within On-To-Knowledge our work evalu-ates semi-automatic ontology construction fromtexts as an alternative approach to ontology en-gineering.
Based on the assumption that mostconcepts and conceptual structures of the do-main as well the company terminology are de-scribed in documents, applying knowledge ac-quisition from text for ontology design seemsto be promising.
Therefore a number of pro-posals have been made to facilitate ontolog-ical engineering through automatic discovery167from domain data, domain-specific natural an-guage texts in particular (cf.
(Byrd and Ravin,1999; Faure and Nedellec, 1999; Hahn andSchnattinger, 1998; Morin, 1999; Resnik, 1993;Wiemer-Hastings et al, 1998)).The extraction of ontologies from text canhave additional benefits for On-To-.Knowledgeas the required semantic annotation of docu-ments could be provided as a side effect of theextraction process.1.3 The approachOur approach is based on different heteroge-neous sources: First, a generic core ontol-ogy is used as a top level structure for thedomain-specific goal ontology.
Second, domain-specific concepts are acquired using a dictio-nary that contains important corporate termsdescribed in natural anguage.
Third, we use adomain-specific and a general corpus of texts toremove concepts that were domain-unspecific.This task is accomplished using the heuristicthat domain-specific concepts are more frequentin the domain-specific corpus.
Eventually welearned relations between concepts by analyz-ing the aforementioned intranet documents.
Weused a multi-strategy approach in learning tolevel the specific advantages and drawbacks ofdifferent learning methods.
Several methodswere applied with the possibility to combinetheir results.1.4 OrganizationSection 2 describes the overall architecture ofthe system and explains our notion of ontolo-gies.
Section 3 discusses the methodology ap-plied to acquire a domain-specific ontology.
Sec-tion 4 highlights the applied learning mecha-nisms.
Section 5 demonstrates some prelimi-nary results.
Eventually Section 6 points outfurther directions for our work and acknowl-edges other contributors to the work.2 Arch i tec tureA general architecture for the approach of semi-automatic ontology learning from natural an-guage has been described in (Maedche andStaab, 2000b).Our not ion of ontologies is closely asso-ciated to the notion in OIL (Horrocks et al,2000).
From the expressive power it is equiva-lent to the CLASSIC-A?Af (Borgida and Patel-Schneider, 1994) description logic.
By that itcombines three important aspects provided byDescription Logics (providing formal semanticsand efficient reasoning support), frame-basedsystems and web standards.
XML is used asa serial syntax definition language, describingknowledge in terms of concepts and role restric-tions (i.e.
all- and cardinality-restrictions as inthe DL ,A?.M).
Also, relations can be intro-duced as an independent entity whose domainand range concepts can be restricted.The system comprises of components fortext management,information extraction, ontol-ogy learning, ontology storage, ontology visual-isation and manual ontology engineering.The text  management& processing com-ponent  supports efficient handling and pro-cessing of input sources.
Multiple sourcesare supported like semi-structured information,natural language documents and existing on-tologies.The  in format ion  ext ract ion  is provided bythe system SMES (Saaxbriicken Message Ex-traction System), a shallow text processor forGerman (cf.
(Neumann et al, 2000; Neumannet al, 1997)).
It performs syntactic analysison natural anguage documents.
SMES includesshallow parsing mechanisms and processes textat different layers: The first step tokenizes textand recognizes basic compound structures likenumbers and dates.
Next, the morphologicalstructure of words is analyzed using a word stemlexicon containing 700.000 word stems.
Phrasalstructures are created in the third step usingfinal state transducers that combine the mor-phological information.
On top of these phrasalstructures a dependency-based parser parser isapplied.
The results of each step axe annotatedin XML-tagged text and can be used indepen-dently.Ontology learning operates on the ex-tracted information and is used for three tasks.One task is the acquisition of new structures,the second task is the evaluation of given struc-tures.
Eventually this evaluation is used forpruning of domain-unspecific concepts.
Severalmethods were implemented.Pat tern -based  approaches The imple-mented heuristic methods are based on regularexpressions, as the output of the information ex-168semi-structured information,eg domain-specific dictionariesnatural languagetextsSelect cor(XML tagged) text&selected algorithmsLexical DBFigure 1: Architecture of the Ontology Learning Approachtraction component is regular.
Patterns can beused to acquire taxonomic as well as conceptualrelations.
Also a very simple heuristic is usedto acquire concepts from dictionaries, whereasdictionary entries are considered concepts.Stat ist ical  approaches We implementedseveral statistical methods.
One methodretrieves concept frequencies from text (cf.
(Salton, 1988)) and is used for the aforemen-tioned pruning of concepts.
A second methodis used to acquire conceptual relations based onfrequent couplings of concepts.Combin ing results is enabled by the im-plementation of a common result structure forall learning methods.
The complex task ofontology engineering is fitted better as it ispossible to combine the results from differentlearning methods.
(Michalski and Kaufmann,1998) describe that multi-strategy learning ar-chitectures upport balancing between advan-tages and disadvantages of different learningmethods.Ontology Engineer ing In our approach ofsemi-automatic ontology acquisition extensivesupport for ontology engineering is necessary.Manual ontology modeling & visualization isprovided by the system OntoEdit 1.
It allows toedit and to browse existing as well as discoveredontological structures.The acquired ontologies are stored in a re-lational database.
To maximize portabilityonly ANSI-SQL statements are used in the sys-tem.
All data structures can be serialized intofiles, different formats like our internal XML-representation OXML, Frame-Logic (Kifer etal., 1995), RDF-Schema (W3C, 1999) and OIL(Horrocks et.al., 2000) are supported.
An F-Logic inference ngine described in further de-tail in (Decker, 1998) can be accessed from On-1A comprehensive description of the ontology engi-neering system OntoEdit and the underlying methodol-ogy is given in (Staab and Maedche, 2000)169toEdit.3 Methodo logyParallel to the architecture we developed an on-tology acquisition methodology that emphasizesthe semi-automatic manner of ontology con-struction.
Figure 2 depicts the cyclic acquisitionprocess.The cycle starts with the selection of a genericcore ontology (cf.
subsection 4.1).
Any largegeneric ontology (like CyC or Dahlgren's ontol-ogy), lexical-semantic nets (like WordNet, Ger-manet or EuroWordNet) or domain-related on-tologies (like TOVE) could start the process.After choosing the base ontology the user mustidentify the domain-specific texts that ought tobe used for the extraction of domain-specific en-titles.The next step is acquire domain-specific con-cept from the selected texts since the base ontol-ogy is domain-unspecific.
The taxonomic em-bedding of all newly acquired concepts mustalso be established.These steps enrichedthe ontology with domain-specific concepts, butstill many domain-unspecific concepts remain.The given ontology must be focused to the do-main.
Therefore all unspecific oncepts must beremoved from the ontology.
Now the conceptualstructure of the target ontology is established.But what about conceptual relations ?
In ad-dition to the relations provided by the base on-tology that survived the focusing step (as theirdomain/range-concepts still exist) new concep-tual relations are induced in the next step byapplying multiple learning methods to the se-lected texts.The resulting domain-specific ontology can befurther refined and improved by repeating theacquisition cycle.
This approach acknowledgesthe evolving nature of domain-specific ontolo-gies that have adopt to changes in their domainor their application such as described in (Erd-mann et al, 2000).4 Acqu is i t ion  Process4.1 Base OntologyGermaNet  We decided to choose a lexical-semantic net for the German language, calledGermaNet (cf.
(Hamp and Feldweg, 1997))as our base ontology.
GermaNet is the Ger-man counterpart to the well known WordNet.Presently it builds a lexical semantic networkfor 16.000 German words, where three differenttypes of word classes are distinguished: nouns,verbs and adjectives.
Words are grouped intosets of synonyms so called synsets.
As in Word-Net two kinds of relations are recognized: Lex-ical relations that hold between words (likeantonym) and semantic relations that hold be-tween synsets (like meronym).Conversion to our  onto logy pr imit iveSynsets are regarded as concepts.
Synsets areconverted to concepts if they have at least onehypernym or hyponym relation.
Some semanticrelations between synsets are converted to con-ceptual relations, as some semantic relations donot have the property of being inherited to sub-concepts if they hold between superconcepts 2.The taxonomy is established using the hy-ponym relations.
If a synset (transitively)points to itself through its hyponym relations,the hyponym relation that causes the cycle isignored.
Unfortunally there were several cycleswithin the verb classes 3.Every word in a synset is analyzed by the in-formation extraction component to acquire itsstem.
The stem is assigned to the correspond-ing concept o get a link to the analyzed texts.This link must be unique for each stem, thusa l:n relation between a concept and stems isestablished.Sometimes the same stem is acquired fromdifferent synsets.
The disambiguation can notbe done without using the context of the word.As we do not have any relations to do the dis-ambiguation yet, we introduce a new conceptthat gets the ambiguous stem and make all con-flicting synsets ubconcepts of the newly intro-duced concepts.
The newly introduced conceptis embedded into the taxonomy as a sub con-cept of the deepest common super concept ofall conflicting synsets.
The disambiguation willbe enabled using the relations between conceptsidentified in the user query.2This is one of the essential differences to ontologies,where relations must hold for all subconcepts3The only correct interpretation f a cycle is to regardthe synsets contained as synonyms, but this would bemodelled in a different manner (one synset), thereforewe consider cycles as bugs (and not existent in the finalversion of GermaNet)170natural languagetextssemi-structured information,e,g.
domain-specific dictionariesFigure 2: Semi-Automatic Ontology Acquisition Process4.2 Acquis it ion of concepts4.2.1 Get t ing  conceptsAs already mentioned we used a dictionary ofcorporate terms to acquire domain specific on-cepts.
Figure 3 shows an example.A.D.T.Automat ic  Debit  TransferElectronic service arising from a debit autho-rization of the Yellow Account holder for a re-cipient o debit bills that fall due direct fromthe account.Cf.
also direct debit system.Figure 3: An example ntryThis dictionary is multi-lingual to providethat all employees use common translations ofdomain terms.
We converted the headwords ofall German entries to concepts.
Some entriesshare descriptions, as shown in the example.Those entries are joined and the headwords areregarded as synonyms.
Some entries show ref-erences to other entries (e.g.
"direct debit sys-tem'" is referenced by "A.D.T.'")
we convertedthese links to conceptual relations.Again, every headword is analyzed by the in-formation extraction component (SMES) to ac-quire the word stem.
This stem is assigned tothe newly created concept, if not already exis-tent in the ontology.
If this stem exists, we needto do find out whether or not the dictionary en-try describes the same concept as contained inthe ontology.4.2.2 Resolving conflictsWe apply several heuristics to solve this prob-lem automatically.
Table 1 shows the appliedheuristics.
In general dictionary entries are con-sidered domain-specific and thus more impor-tant than existing concepts.
The algorithm usesthe information included within the dictionaryentry and its description to find out whether theentry denotes the existing concept or induces anew concept.First, the algorithm checks whether theconflicting dictionary head word denotes anacronym (e.g.
ALE is an acronym for unem-ployment benefits in German.
Unfortunally thestem reference contained in the ontology pointsto the concept ale, which is a sub concept of al-coholic beverage), in this case the stem referenceis reassigned to the dictionary concept.171Propery AutomaticresolutionWord is acronym Remove stem reference-in ontologyDictionary entry has Do not import the en-no description try and keep concept inontologyDictionary entry and Do not import the en-ontology entry have a try and keep concept incommon super concept ontologyelse ask the user to resolvethe conflictTable 1: Dictionary: Resolution for stem con-flictsIf this doesn't help, the algorithm checkswhether further information is contained in thedictionary description by trying to find thesuper concept using the taxonomy acquisitionmethod explained in the next section.
If thefound super concept is also a super concept ofthe concept in the ontology, the dictionary entryand the concept in the ontology are consideredequal.If no descriptions are contained in the dictio-nary entry and the entry is not an acronym ,the concept in the ontology is kept.
Last butnot least, if no heuristics could be applied, theuser is asked to resolve the conflict.4.2.3 Getting the taxonomyWe used a pattern matching method to acquirethe taxonomic embedding for the newly createdconcepts.
The entires are aligned into the tax-onomy using their descriptions.
Based on theextracted syntactic information, several heuris-tic patterns for extracting taxonomic relationsare applied.
This works quite well, as the infor-mation extraction component supplies regularoutput.
(Hearst, 1992) motivated the acquisition ofhyponyms by applying pattern matching totext.
This approach was also applied in (Morin,1999).
Our patterns acquire stem referencesfrom the given texts using backward referencesinside the defined patterns.
The stem referencesare used to get the concept contained in the on-tology.
Patterns can also reference the dictio-nary headwords, figure 4 depicts a very success-ful pattern.Since regular expressions are not easy to readPattern1.
lexicon entry :: (NP1, NP2, NPi, and / orNP~)2. for all NPi, 1 <= i <= n hypernym(NPi, lex-icon entry)Result hypernym("electronic service","A.D.T."
)Figure 4: Pattern Definitionand much testing is required until expressionswork, a pattern definition workbench was im-plemented to be able to document, categorizeand test the defined patterns.4.3 Removal  of conceptsWe motivated the removal of generic conceptsin section 3.
In order to prune domainun-specific oncepts, concept frequencies are deter-mined from the selected omain-specific docu-ments (see (Salton, 1988)).
Concept frequenciesare also determined from a second corpus thatcontains generic documents (as found in refer-ence corpora like CELEX).
We used the publiclyavailable archive of a well-known German ews-paper (http://http://www.taz.de/) as genericcorpus.All concept frequencies are propagated to su-per concepts, by summing the frequencies ofsubconcepts.
The frequencies of both corpora arecompared.
All existing concepts that are morefrequent within the domain-specific corpus re-main in the ontology.
Additionally a minimumconcept frequency can be defined.
All remainingconcepts must satisfy this minimum frequency.Eventually the user can specify that conceptsacquired from the dictionary (as well as theirsuper concepts) must remain in the ontology.4.4 Acquisit ion of ConceptualRelations4.4.1 Statistical approachThis approach is founded on the idea that fre-quent couplings of concepts in sentences can beregarded as relevant relations between concepts.We adopted an algorithm based on associationrules (see (Skrikant and Agrawal, 1995)) to findfrequent correlations between concepts.
Lin-guistically processed texts as input, where cou-pling of concepts within sentences axe retrieved,are processed by our algorithm.
Consult (Volz,2000a; Maedche and Staab, 2000a) for a de-172tailed description of this approach.Two measures denote the statistical data de-rived by the algorithm: Support measures thequota of a specific coupling within the totalnumber of couplings.
Confidence denotes thepart of all couplings supporting both domainand range concepts within the number of cou-plings that support the same domain concept.The retrieved measures are propagated to superconcepts using the background knowledge pro-vided by the taxonomy.
This strategy is used toemphasize the couplings in higher levels of thetaxonomy.For instance, the linguistic processing mayfind that the word "policy" frequently co-occurswith each of the words "policy owner" and "in-surance salesman".
From this statistical lin-guistic data our approach derives correlationsat the conceptual level, viz.
between the con-cept Policy and the concepts, PolicyOwner andInsuranceSalesman.
The discovery algorithmdetermines support and confidence measures forthe relationships between these three pairs, aswell as for relationships at higher levels of ab-straction, such as between Policy and Person.In a final step, the algorithm determines thelevel of abstraction most suited to describethe conceptual relationships by pruning appear-ingly less adequate ones.
Here, the relation be-tween Policy and Person may be proposed forinclusion in the ontology.Results are presented to the user, if the mea-sures of a coupling satisfy specific minimum val-ues provided by the user.
Also, the input struc-tures can be restricted to a set of certain con-cepts (whereas at least one element of every cou-pling must be in the given set) to be able to doa more focused way of relation acquisition.We have to stress that this method can onlybe used to retrieve suggestions that are pre-sented to the user.
Manual abour is still neededto select and name the relations.
To simplifyuser access results are conveniently displayed inthe common result structure.
The correctnesstowards the inheritance property of the taxon-omy is automatically determined.4.4.2 Pat tern  based approachWe extended the pattern based approach men-tioned above towards the acquisition of named,non-taxonomic conceptual relations from text.We have defined some patterns on top of theinformation extracted by phrase-level process-ing of documents.
The name of a relation canbe assigned using the aforementioned backwardreferences within a pattern.
In contrast o thepatterns defined to acquire taxonomic relationsno dictionary headwords can be assigned.5 Resul tsWe can only present partial results at the mo-ment, as our work is still ongoing.
We con-verted only one part of speech class of the Ger-maNet lexical-semantic net.
Our version con-tained 18509 synsets for the noun class.
18056synsets have been converted, as all synsets thatwere not embedded in the taxonomy (by havingneither super nor sub concepts) were skipped.3565 new super concepts were introduced due toour disambiguation strategy.
Therefore 21621concepts were created.The acquisition of concepts using the dictio-nary led to 1054 new concepts.
62 of the con-cepts in the dictionary were already included inthe ontology.
Only 518 concepts remain afterthe acquisition of the taxonomic embedding.The learning method finds 679 is-a relations,but 161 is-a relations were determined to bewrong by empiric user evaluation.
Thus 76,29percent of all discovered relations were regardedcorrect by the user.
Notably 49,14 percent of alldictionary entries could be imported automati-cMly.The evaluation of the acquisition of relations,as well as the pruning step is not yet done.
Re-sults regarding the acquisition of relations usingour statistical approach in a different domain(tourism) have been presented in (Maedche andStaab, 2000a).
Using a minimum support valueof 0.04 and a minimum confidence of 0.01 bestresults were reached.
98 relations were discov-ered using an ontology that contained 284 con-cepts and 88 conceptual relations.
11% of thediscovered relations were already modeled be-fore, thus 13% of the hand-modelled relationswere discovered by the learning algorithm.6 Conc lus ions  & Fur ther  WorkIn this paper we have described our recent andongoing work in semi-automatic ontology acqui-sition from a corporate intranet.
Based on ourcomprehensive architecture a new approach forsupporting the overall process of engineering on-173tologies from text is described.
It is mainlybased on a given core ontology, which is ex-tended with domain specific concepts.
The re-sulting ontology is pruned and restricted to aspecific application using a corpus-based mech-anism for ontology pruning.
On top of the on-tology two approaches upporting the difficulttask of determining non-taxonomic conceptualrelationships are applied.In the future much work remains to be done.First, several techniques for evaluating the ac-quired ontology have to be developed.
In ourscenario we will apply ontology cross compar-ison techniques uch as described in (Maedcheand Staab, 2000a).
Additionally, applying theontology on top of the intranet documents (e.g.a information retrieval scenario, a semantic doc-ument annotation scenario such as describedin (Erdmann et al, 2000)) will allow us anapplication-specific evaluation of the ontologyusing standard measures uch as precision andrecall.
Second, our approach for multi-strategylearning is still in an early stage.
We; will haveto elaborate how the results of different learn-ing algorithms will have to be assessed and com-bined in the multi-strategy learning set.
Never-theless, an approach combing different resourceson which different echniques are applied, seemspromising for supporting the complex task ofontology learning from text.Acknowledgements :  This work has been par-tially found by the European Union and theSwiss Government under the contract-no "BBWNr.99.0174" as part of the European commis-sion Research Project "IST-1999-10132" (On-to-Knowledge).
We thank the DFKI:, languagetechnology group, in particular Gfinter Neu-mann, who generously supported us in usingtheir SMES system.ReferencesA.
Borgida and P. Patel-Schneider.
1994.
A seman-tics and complete algorithm for subsumption ithe CLASSIC description logic.
Journal of Arti-ficial Intelligence Research, 1:277-308.Roy J. Byrd and Yael Ravin.
1999.
Identifying andextracting relations from text.
In NLDB'99 --4th International Conference on Applications ofNatural Language to Information Systems.S.
Decker.
1998.
On domain-specific declara-tive knowledge representation a d database lan-guages.
In Proc.
of the 5th Knowledge Repre-sentation meets Databases Workshop (KRDB98),pages 9.1-9.7.M.
Erdmann, A. Maedche, H.-P. Schnurr, and Stef-fen Staab.
2000.
From manual to semi-automaticsemantic annotation: About ontology-based textannotation tools.
In P. Buitelaar ~4 K. Hasida(eds).
Proceedings of the COLING 2000 Workshopon Semantic Annotation and Intelligent Content,Luxembourg, August.David Faure and Claire Nedellec.
1999.
Knowledgeacquisition of predicate-argument structures fromtechnical texts using machine learning.
In Proc.
ofCurrent Developments in Knowledge Acquisition,EKAW-99.D.
Fensel, F. van Harmelen, H. Akkermans,M.
Klein, J. Broekstra, C. Fluyt, J. van derMeer, H.-P. Schnurr, R. Studer, J. Davies,J.
Hughes, U. Krohn, R. Engels, B. Bremdahl,F.
Ygge, U. Reimer, and I. Horrocks.
2000.
On-toknowledge: Ontology-based tools for knowledgemanagement.
In Proceedings of the eBusinessand e Work 2000 Conference (EMMSEC 2000),Madrid, Spain, To appear October.E.
Grosso, H. Eriksson, R. W. Fergerson, S. W.Tu, and M. M. Musen.
1999.
Knowledge mod-eling at the millennium - -  the design and evolu-tion of Protege-2000.
In Proc.
the 12th Interna-tional Workshop on Knowledge Acquisition, Mod-eling and Mangement (KAW'99), Banff, Canada,October 1999.Udo Hahn and Klemens Schnattinger.
1998.
To-wards text knowledge ngineering.
In AAAI  '98- Proceedings of the 15th National Conference onArtificial Intelligence.
Madison, Wisconsin, July26-30, 1998, pages 129-144, Cambridge/MenloPark.
MIT Press/AAAI Press.B.
Hamp and H. Feldweg.
1997.
Germanet - alexical-semantic net for german.
In Proceedingsof ACL workshop Automatic Information Extrac-tion and Building of Lexical Semantic Resourcesfor NLP Applications, Madrid.M.A.
Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedingsof the 14th International Conference on Compu-tational Linguistics.
Nantes, France.I.
Horrocks, D. Fensel, J. Broekstra, S. Decker,M.
Erdmann, C. Goble, F. van Harmelen,M.
Klein, S. Staab, and R. Studer.
2000.
Theontology inference layer oil, on-to-knowledge eu-ist-10132 project deliverable no.
otk-dl.
Techni-cal report, Free University Amsterdam, Divisionof Mathematics and Computer Science, Amster-dam, NL.I.
Horrocks et.al.
2000.
The ontology inter-change language oil: The grease between on-tologies.
Technical report, Dep.
of ComputerScience, Univ.
of Manchester, UK/ Vrije Uni-174versiteit Amsterdam, NL/ AIdministrator, Ned-erland B.V./ AIFB, Univ.
of Karlsruhe, DE.http://www.cs.vu.nl/-dieter/oil/.M.
Kifer, G. Lausen, and J. Wu.
1995.
Logical foun-dations of object-oriented and frame-based lan-guages.
Journal of the A CM, 42.A.
Maedche and S. Staab.
2000a.
Discovering con-ceptual relations from text.
In Proceedings ofECAI-2000.
IOS Press, Amsterdam.A.
Maedche and S. Staab.
2000b.
Semi-automaticengineering of ontologies from text.
In Proceed-ings of the 12th Internal Conference on Softwareand Knowledge Engineering.
Chicago, USA.
KSI.R.
Michalski and K. Kaufmann.
1998.
Data min-ing and knowledge discovery: A review of issuesand multistrategy approach.
In Machine Learn-ing and Data Mining Methods and Applications.John Wiley, England.E.
Morin.
1999.
Automatic acquisition of seman-tic relations between terms from technical cor-pora.
In Proc.
of the Fifth International Congresson Terminology and Knowledge Engineering -TKE'99.G.
Neumann, R. Backofen, J. Baur, M. Becker, andC.
Braun.
1997.
An information extraction coresystem for real world german text processing.
InANLP'97 --  Proceedings of the Conference onApplied Natural Language Processing, pages 208-215, Washington, USA.G.
Neumann, C. Braun, and J. Piskorski.
2000.
Adivide-and-conquer st ategy for shallow parsing ofgerman free texts.
In Proceedings of ANLP-2000,Seattle, Washington.P.
Resnik.
1993.
Selection and Information: AClass-based Approach to Lexical Relationships.Ph.D.
thesis, University of Pennsylania.G.
Salton.
1988.
Automatic Text Processing.Addison-Wesley.R.
Skrikant and R. Agrawal.
1995.
Mining gener-alized association rules.
In Proceedings of VLDB1995, pages 407-419.S.
Staab and A. Maedche.
2000.
Ontology engineer-ing beyond the modeling of concepts and rela-tions.
In Proceedings of the ECAI'2000 Workshopon Application of Ontologies and Problem-SolvingMethods.Raphael Volz.
2000a.
Discovering conceptual rela-tions from text.
Studienarbeit, University of Karl-sruhe (TH), Karlsruhe- Germany.
in German.Raphael Volz.
2000b.
From texts to ontologies us-ing machine learning and lexical-semantic net-works \[working title\].
Diploma thesis, Universityof Karlsruhe (TH), Karlsruhe- Germany.
in Ger-man.W3C.
1999.
Rdf schema specification.http://www.w3.org/TR/PR-rdf-schema/.P.
Wiemer-Hastings, A. Graesser, and K. Wiemer-Hastings.
1998.
Inferring the meaning of verbsfrom context.
In Proceedings of the Twentieth An-nual Conference of the Cognitive Science Society.175
