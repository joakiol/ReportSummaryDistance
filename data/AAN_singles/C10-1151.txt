Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1344?1352,Beijing, August 2010Heterogeneous Parsing via Collaborative DecodingMuhua Zhu Jingbo Zhu Tong XiaoNatural Language Processing Lab.Northeastern Universityzhumuhua@gmail.com{zhujingbo, xiaotong}@mail.neu.edu.cnAbstractThere often exist multiple corpora for thesame natural language processing (NLP)tasks.
However, such corpora are gen-erally used independently due to distinc-tions in annotation standards.
For the pur-pose of full use of readily available hu-man annotations, it is significant to simul-taneously utilize multiple corpora of dif-ferent annotation standards.
In this pa-per, we focus on the challenge of con-stituent syntactic parsing with treebanksof different annotations and propose a col-laborative decoding (or co-decoding) ap-proach to improve parsing accuracy byleveraging bracket structure consensus be-tween multiple parsing decoders trainedon individual treebanks.
Experimental re-sults show the effectiveness of the pro-posed approach, which outperforms state-of-the-art baselines, especially on longsentences.1 IntroductionRecent years have seen extensive applications ofmachine learning methods to natural languageprocessing problems.
Typically, increase in thescale of training data boosts the performance ofmachine learning methods, which in turn en-hances the quality of learning-based NLP systems(Banko and Brill, 2001).
However, annotatingdata by human is expensive in time and labor.
Forthis reason, human-annotated corpora are consid-ered as the most valuable resource for NLP.In practice, there often exist more than one cor-pus for the same NLP tasks.
For example, forconstituent syntactic parsing (Collins, 1999; Char-niak, 2000; Petrov et al, 2006) in Chinese, in ad-dition to the most popular treebank Chinese Tree-bank (CTB) (Xue et al, 2002), there are alsoother treebanks such as Tsinghua Chinese Tree-bank (TCT) (Zhou, 1996).
For the purpose offull use of readily available human annotationsfor the same tasks, it is significant if such cor-pora can be used jointly.
At first sight, a di-rect combination of multiple corpora is a way tothis end.
However, corpora created for the sameNLP tasks are generally built by different orga-nizations.
Thus such corpora often follow dif-ferent annotation standards and/or even differentlinguistic theories.
We take CTB and TCT asa case study.
Although both CTB and TCT areChomskian-style treebanks, they have annotationdivergences in at least two dimensions: a) CTBand TCT have dramatically different tag sets, in-cluding parts-of-speech and grammar labels, andthe tags cannot be mapped one to one; b) CTBand TCT have distinct hierarchical structures.
Forexample, the words ???
(Chinese) ??
(tradi-tional) ??
(culture)?
are grouped as a flat nounphrase according to the CTB standard (right sidein Fig.
1), but in TCT, the last two words are in-stead grouped together beforehand (left side inFig.
1).
The differences cause such treebanksof different annotations to be generally used in-dependently.
This paper is dedicated to solvingthe problem of how to use jointly multiple dis-parate treebanks for constituent syntactic parsing.Hereafter, treebanks of different annotations are1344called heterogeneous treebanks, and correspond-ingly, the problem of syntactic parsing with het-erogeneous treebanks is referred to as heteroge-neous parsing.Previous work on heterogeneous parsing is of-ten based on treebank transformation (or treebankconversion) (Wang et al, 1994; Niu et al, 2009).The basic idea is to transform annotations of onetreebank (source treebank) to fit the standard ofanother treebank (target treebank).
Due to diver-gences of treebank annotations, such transforma-tion is generally achieved in an indirect way byselecting transformation results from the output ofa parser trained on the target treebank.
A com-mon property of all the work mentioned above isthat transformation accuracy is heavily dependenton the performance of parsers trained on the tar-get treebank.
Sometimes transformation accuracyis not so satisfactory that techniques like instancepruning are needed in order to refine transforma-tion results (Niu et al, 2009).We claim there exists another way, interestingbut less studied for heterogeneous parsing.
Thebasic idea is that, although there are annotationdivergences between heterogenous treebanks, ac-tually we can also find consensus in annotationsof bracket structures.
Thus we would like to trainparsers on individual heterogeneous treebanks andguide the parsers to gain output with consensus inbracket structures as much as possible when theyare parsing the same sentences.To realize this idea, we propose a generic col-laborative decoding (or co-decoding) frameworkwhere decoders trained on heterogeneous tree-banks can exchange consensus information be-tween each other during the decoding phase.
The-oretically the framework is able to incorporate alarge number of treebanks and various functionsthat formalize consensus statistics.Our contributions can be summarized: 1) wepropose a co-decoding approach to directly uti-lizing heterogeneous treebanks; 2) we propose anovel function to measure parsing consensus be-tween multiple decoders.
We also conduct ex-periments on two Chinese treebanks: CTB andTCT.
The results show that our approach achievespromising improvements over baseline systemswhich make no use of consensus information.npnS??npa??n??NPNR??NN??NN????????
(Chinese) (traditional) (culture)Figure 1: Example tree fragments with TCT (left)and CTB (right) annotations2 Collaborative Decoding-basedHeterogeneous Parsing2.1 MotivationThis section describes the motivation to useco-decoding for heterogeneous parsing.
We firstuse the example in Fig.
1 to illustrate what con-sensus information exists between heterogenoustreebanks and why such information might helpto improve parsing accuracy.
This figure containstwo partial parse trees corresponding to thewords ???
(Chinese) ??
(traditional) ??
(culture)?, annotated according to the TCT (leftside) and CTB (right side) standards respectively.Despite the distinctions in tag sets and bracketstructures, these parse trees actually have partialagreements in bracket structures.
That is, not allbracket structures in the parse trees are different.Specifically put, although the internal structuresof the parse trees are different, both CTB andTCT agree to take ???
??
???
as a nounphrase.
Motivated by this observation, we wouldlike to guide parsers that are trained on CTB andTCT respectively to verify their output interac-tively by using consensus information implicitlycontained in these treebanks.
Better performanceis expected when such information is considered.A feasible framework to make use of consensusinformation is n-best combination (Hendersonand Brill, 1999; Sagae and Lavie, 2006; Zhang etal., 2009; Fossum and Knight, 2009).
In contrast1345to previous work on n-best combination wheremultiple parsers, say, Collins parser (Collins,1999) and Berkeley parser (Petrov et al, 2006)are trained on the same training data, n-bestcombination for heterogeneous parsing is insteadallowed to use either a single parser or multipleparsers which are trained on heterogeneoustreebanks.
Consensus information can be incor-porated during the combination of the output(n-best list of full parse trees following distinctannotation standards) of individual parsers.
How-ever, despite the success of n-best combinationmethods, they suffer from the limited scope ofn-best list.
Taking this into account, we preferto apply the co-decoding approach such thatconsensus information is expected to affect theentire procedure of searching hypothesis space.2.2 System OverviewThe idea of co-decoding is recently extensivelystudied in the literature of SMT (Li et al, 2009;Liu et al, 2009).
As the name shows, co-decodingrequires multiple decoders be combined and pro-ceed collaboratively.
As with n-best combination,there are at least two ways to build multiple de-coders: we can either use multiple parsers trainedon the same training data (use of diversity of mod-els), or use a single parser on different trainingdata (use of diversity of datasets) 1.
Both wayscan build multiple decoders which are to be inte-grated into co-decoding.
For the latter case, onemethod to get diverse training data is to use dif-ferent portions of the same training set.
In thisstudy we extend the case to an extreme situationwhere heterogeneous treebanks are used to buildmultiple decoders.Fig.
2 represents a basic flow chart of heteroge-neous parsing via co-decoding.
Note that here wediscuss the case of co-decoding with only two de-coders, but the framework is generic enough to in-tegrate more than two decoders.
For convenienceof reference, we call a decoder without incorpo-rating consensus information as baseline decoder1To make terminologies clear, we use parser as its regularsense, including training models (ex.
Collins model 2) andparsing algorithms (ex.
the CKY algorithm used in Collinsparser), and we use decoder to represent parsing algorithmswith specified parameter valuestreebank1 treebank2decoder1 decoder2co-decodingtest dataFigure 2: Basic flow chart of co-decodingand correspondingly refer to a decoder augmentedwith consensus information as member decoder.So the basic steps of co-decoding for heteroge-neous parsing is to first build baseline decoders onheterogeneous treebanks and then use the baselinedecoders to parse sentences with consensus infor-mation exchanged between each other.To complete co-decoding for heterogeneousparsing, three key components should be consid-ered in the system:?
Co-decoding model.
A co-decoder con-sists of multiple member decoders which arebaseline decoders augmented with consen-sus information.
Co-decoding model de-fines how baseline decoders and consensusinformation are correlated to get member de-coders.?
Decoder coordination.
Decoders in the co-decoding model cannot proceed indepen-dently but should have interactions betweeneach other in order to exchange consensus in-formation.
A decoder coordination strategydecides on when, where, and how the inter-actions happen.?
Consensus-based score function.
Consensus-based score functions formalize consensusinformation between member decoders.
Tak-ing time complexity into consideration, con-sensus statistics should be able to be com-puted efficiently.1346In the following subsections, we first presentthe generic co-decoding model and then describein detail how member decoders collaborate.
Fi-nally we introduce a novel consensus-based scorefunction which is used to quantify consensus in-formation exchanged between member decoders.2.3 Generic Co-decoding ModelThe generic co-decoding model described here isalso used in (Li et al, 2009) for co-decoding ofmachine translators.
For a given sentence S, aparsing algorithm (decoder) seeks a parse tree T ?which is optimal in the sense that it maximizessome score function F (T ), as shown in Eq.
1.T ?
= argmaxTs.t.S=yield(T )F (T ) (1)where Ts.t.S = yield(T ) represents the set ofparse trees that yield the input sentence S. Forbaseline decoders, the score function F (T ) isgenerally just the inside probability P (T ) 2 ofa tree T , defined as the product of probabili-ties of grammar rules appearing in parse tree T :?r?R(T ) P (r).
In the co-decoding framework,F (T ) is extended so as to integrate consensus-based score functions which measure consensusinformation between member decoders, as shownin Eq.
2.Fm(T ) = Pm(T ) +n?k,k 6=m?k(Hk(S), T ) (2)We use dk to denote the kth decoder and useHk(S) to denote corresponding parsing hypoth-esis space of decoder dk.
Moreover, Pm(T ) isreferred to as baseline score given by baselinedecoders and ?k(Hk(S), T ) is consensus scorebetween decoders dm and dk, which is definedas a linear combination of consensus-based scorefunctions, as shown in Eq.
3.?k(Hk(S), T ) =?l?k,lfk,l(Hk(S), T ) (3)where fk,l(Hk(S), T ) represents a consensus-based score function between T and Hk(S),and ?k,l is the corresponding weight.
Index l2Actually, the joint probability P(S,T) of sentence S andparse tree T is used, but we can prove that P (S, T ) = P (T ).ranges over all consensus-based score functionsin Eq.
3.
Theoretically we can define a varietyof consensus-based score functions.For the simplest case where there are only twomember decoders and one consensus-based scorefunction, Eq.
2 and Eq.
3 can be combined andsimplified into the equationFi(T ) = Pi(T ) + ?1?if(H1?i(S), T ) (4)where index i is set to the value of either 1 or 0.This simplified version is used in the experimentsof this study.2.4 Decoder CoordinationThis subsection discusses the problem of decodercoordination.
Note that although Eq.
2 is definedat sentence level, the co-decoding model actu-ally should be applied to the parsing procedureof any subsequence (word span) of sentence S.So it is natural to render member decoders col-laborate when they are processing the same wordspans.
To this end, we would like to adopt best-first CKY-style parsing algorithms as baseline de-coders, since CKY-style decoders have the prop-erty that they process word spans in the ascend-ing order of span sizes.
Moreover, the hypothe-ses 3 spanning the same range of words are read-ily stacked together in a chart cell before CKY-style decoders move on to process other spans.Thus, member decoders can process the sameword spans collaboratively from small ones to bigones until they finally complete parsing the entiresentence.A second issue in Eq.
2 is that consensus-based score functions are dependent on hypoth-esis space Hk(S).
Unfortunately, the whole hy-pothesis space is not available most of the time.To address this issue, one practical method is toapproximate Hk(S) with a n-best hypothesis list.For best-first CKY parsing, we actually retain allunpruned partial hypotheses over the same spanas the approximation.
Hereafter, the approxima-tion is denoted as H?k(S)Finally, we notice in Eq.
2 that consensus score3In the literature of syntactic parsing, especially in chartparsing, hypotheses is often called edges.
This paper willcontinue to use the terminology hypothesis when no ambigu-ity exists.1347?k(Hk(S), T ) and Hk(S) form a circular depen-dency: searching for Hk(S) requires both base-line score and consensus score; on the other hand,calculating consensus score needs Hk(S) (its ap-proximation in practice) to be known beforehand.Li et al (2009) solves this dilemma with a boot-strapping method.
It starts with seedy n-best listsgenerated by baseline decoders and then alter-nates between calculating consensus scores andupdating n-best hypothesis lists.
Such bootstrap-ping method is a natural choice to break down thecircular dependency, but multi-pass re-decodingmight dramatically reduce decoding efficiency.Actually, Li et al (2009) restricts the iterationnumber to two in their experiments.
In this paper,we instead use an alternative to the bootstrappingmethod.
The process is described as follows.1.
In traditional best-first CKY-style parsing al-gorithms, hypotheses over the same wordspans are grouped according to some crite-rion of hypothesis equivalence 4.
Amongequivalent hypotheses, only a single optimalhypothesis is retained.
In this paper, we in-stead keep top k of equivalent hypotheses ina data structure called best-first cache.2.
Use hypotheses in best-first caches to ap-proximate Hk(S), and calculate consensusscore ?k(Hk(S), T ) between decoders.3.
Use baseline score and consensus score to lo-cally rerank hypotheses in best-first caches.Then remove hypotheses in caches except thetop one hypothesis.In this study, we choose the best-first CKY-styleparsing algorithm used in Collins parser (Collins,1999).
Algorithm 1 extends this algorithm for co-decoding.
The first two steps initialize baselinedecoders and assign appropriate POS tags to sen-tence St.
Since baseline decoders are built on het-erogeneous treebanks, POS taggers correspond-ing to each baseline decoder are demanded, unlessgold POS tags are provided.
The third step is thecore of the co-decoding algorithm.
Here the com-plete procedure invokes baseline decoders to com-4the simplest criterion of equivalence is whether hypothe-ses have the same grammar labels.Algorithm 1 CKY-style Co-decodingArgument: dk{the set of baseline decoders}St{a sentence to be parsed}BeginSteps:1. assign POS tags to sentence St2.
initialize baseline decoders dk3.
for span from 2 to sentence length dofor start from 1 to (sentence length-span+1) doend := (start + span - 1)for each base decoder dk docomplete(dk , start, end)do co-decoding(start, end)EndSubroutine:complete(dk, start, end): base decoder dk generateshypotheses over the span (begin.end), and fills in best-first caches.co-decoding(start, end): calculate consensus scoreand rerank hypotheses in best-first caches.
The top 1 ischosen to be the best-first hypothesis.plete parsing on the span [start, end] and gener-ates H?k(s).
The co-decoding procedure calculatesconsensus score and locally reranks hypotheses inbest-first caches.2.5 Consensus-based Score FunctionThere are at least two feasible ways to mea-sure consensus between constituency parse trees.By viewing parse trees from diverse perspectives,we can either use functions on bracket structuresof parse trees, as in (Wang et al, 1994), oruse functions on head-dependent relations by firsttransforming constituency trees into dependencytrees, as in (Niu et al, 2009).
Although the co-decoding model is generic enough to integrate var-ious consensus-based score functions in a uniformway, this paper only uses a bracket structure-basedfunction.As mentioned above, the function proposed in(Wang et al, 1994) is based on bracket struc-tures.
Unfortunately, that function is not appli-cable in the situation of this paper.
The reason isthat, the function in (Wang et al, 1994) is de-fined to work on two parse trees, but this paperinstead needs a function on a tree T and a set oftrees (the approximation H?k(S)).
To this end, wefirst introduce the concept of constituent set (CS)of a parse tree.
Conceptually, CS of a parse tree isa set of word spans corresponding to all the sub-134864152 3[1,3],[2,3],[1,1][1,1][2,3],[2,2],[3,3][1,1][2,2][3,3]Figure 3: Constituent set of a synthetic parse treetrees of the tree, as illustrated in Fig.
3.
For exam-ple, the constituent set of the tree rooted at node6 has three elements: [1, 1], [1, 3], and [1, 2].
ForH?k(S), the constituent set is defined as the unionof constituent sets of all elements it contains.CS(H?k(S)) =?T?H?k(S)CS(T )In practice, we need to cut off elements inCS(H?k(S)) in order to retain most confidentword spans.With the concept of constituent set, aconsensus-based score function on T and H?k(S)can be defined as follows.f(H?k(S), T ) =?c?CS(T ) I(c, CS(H?k(S)))|CS(T )| (5)where I(c, CS(H?k(S))) is an indicator functionwhich returns one if c ?
CS(T ) is compatiblewith all the elements in CS(H?k(S)), zero oth-erwise.
Two spans, [a, b] and [i, j] are said tobe compatible if they satisfy one of the followingconditions: 1) i > b; 2) a > j; 3) a ?
i ?
b andj ?
b; 4) i ?
a ?
j and b ?
j.
Fig 4 uses twoexample to illustrate the concept of compatibility.3 Experiments3.1 Data and Performance MetricThe most recent version of the CTB corpus, CTB6.0 and the CIPS ParsEval data are used as hetero-geneous treebanks in the experiments.
Followingthe split utilized in (Huang et al, 2007), we di-vided the dataset into blocks of 10 files.
For eachw1 w2 w3 w4 w1 w2 w3 w4Figure 4: left) two spans conflict; right) two spansare compatibleblock, the first file was added to the CTB develop-ment data, the second file was added to the CTBtesting data, and the remaining 8 files were addedto the CTB training data.
For the sake of parsingefficiency, we randomly sampled 1,000 sentencesof no more than 40 words from the CTB test set.CTB-Partitions Train Dev Test#Sentences 22,724 2,855 1,000#Words 627,833 78,653 25,100Ave-Length 30.1 30.0 20.3TCT-Partitions Train Dev Test#Sentences 32,771 N/A 1,000#Words 354,767 N/A 10,400Ave-Length 10.6 N/A 10.4Table 1: Basic statistics on the CTB and TCT dataCIPS-ParsEval data is publicly available for thefirst Chinese syntactic parsing competition, CIPS-ParsEval 2009.
Compared to CTB, sentences inCIPS-ParsEval data are much shorter in length.We removed sentences which have words lessthan three.
CIPS-ParsEval test set has 7,995 sen-tences after sentence pruning.
As with the CTBtest set, we randomly sampled 1,000 sentencesfor evaluating co-decoding performance.
SinceCIPS-ParsEval data is actually a portion of theTCT corpus, for convenience of reference, we willrefer to CIPS-ParsEval data as TCT in the follow-ing sections.
Table 1 contains statistics on CTBand TCT.The two training sets are used individually tobuild baseline decoders.
With regard to the testsets, each sentence in the test sets should havetwo kinds of POS tags, according to the CTB andTCT standards respectively.
To this end, we ap-plied a HMM-based method for POS annotationtransformation (Zhu and Zhu, 2009).
During thePOS transformation, the divergences of word seg-mentation are omitted.For all experiments, bracketing F1 is used asthe performance metric, provided by EVALB 5.5http://nlp.cs.nyu.edu/evalb13493.2 Baseline DecodersAs already mentioned above, we apply Collinsparser in this paper.
Specifically speaking, twoCKY-style baseline decoders to participate co-decoding are built on CTB and TCT respectivelywith Collins model two.
For the CTB-based de-coder, we use the CTB training data with slightmodifications: we replaced POS tags of punctua-tions with specific punctuation symbols.To get the TCT-based decoder, we made follow-ing modifications.
Firstly, TCT is available withmanually annotated head indices for all the con-stituents in parse trees.
For example, a grammarlabel, say, np-1, means that the constituent is anoun phrase with the second child being its headchild.
In order to relax context independence as-sumptions made in PCFG, we appended head in-dices to grammar labels to get new labels, for ex-ample np1.
Secondly, since Collins parser is alexicalized parser, head rules specific to the TCTcorpus were manually created, which are used to-gether with readily available head indices.
Suchadaptation is also used in (Chen et al, 2009);3.3 Parsing ResultsWe conduct experiments on both CTB and TCTtest sets.
Two parameters need to be set: the cut-off threshold for constructing constituent set ofH?k(S) and the weight ?
6 of consensus score inEq.
4.
We tuned the parameters on the CTB de-velopment set and finally set them to 5 and 20respectively in the experiments.
Table 2 presentsbracketing F1 scores of baseline systems and theco-decoding approach.
Here, the row of baselinerepresents the performance of individual baselinedecoders, and the comparison of baseline and co-decoding on a test set, say CTB, demonstrateshow much boosting the other side, say TCT, cansupply.
For the co-decoding approach, the sizeof best-first cache is set to 5 which achieves thebest result among the cache sizes we have experi-mented.As the results show, co-decoding achievespromising improvements over baseline systemson both test sets.
Interestingly, we see that theimprovement on the TCT test set is larger than6We use the same ?
for both member decoders.Test Set CTB TCTBaseline 79.82 81.02Co-decoding 80.33 81.77Table 2: Baseline and Co-decoding on the CTBand TCT test setsthat on the CTB test set.
In general, a relativelystrong decoder can improve co-decoding perfor-mance more than a relatively weak decoder does.At the first sight, the TCT-based decoder seems tohave better performance than the CTB-based de-coder.
But if taking sentence length into consid-eration, we can find that the TCT-based decoderis actually relatively weak.
Table 3 shows theperformance of the CTB-based decoder on shortsentences.3.4 AnalysisFig.
5 shows the bracketing F1 on the CTB test setat different settings of the best-first cache size C .F1 scores reach the peak before C increases to 6.As a result, we set C to 5 in all our experiments.7979.58080.5810  1  2  3  4  5  6bracketingF1size of best-first cacheCTBFigure 5: Bracketing F1 with varying best-firstcache sizeTo evaluate the effect of sentence length on co-decoding, Table 3 presents F1 scores on portionsof the CTB test set, partitioned according to sen-tence length.
From the results we can see thatco-decoding performs better on long sentences.One possible reason is that member decoders havemore consensus on big spans.
Taking this obser-vation into consideration, one enhancement to theco-decoding approach is to enable co-decodingonly on long sentences.
This way, parsing ef-1350Partitions [0,10] (10,20] (20,30] (30,40]# Sentence 276 254 266 204Ave-Length 6.07 15.64 25.43 35.20Baseline 92.83 84.34 78.98 76.69Co-decoding 92.84 84.36 79.43 77.65Table 3: Effect of sentence length on co-decodingperformanceficiency of co-decoding can be improved.
It isworth emphasizing that co-decoding is still help-ful for parsers whose performance on short sen-tences is not satisfactory, as shown in Table 2.Another interesting analysis is to check howmany parsing results are affected by co-decoding,compared to baseline decoders.
Table 4 showsthe statistics.Test Set # All # Improved # DecreasedCTB 1000 225 109TCT 1000 263 92Table 4: Statistics on sentences of test dataAs the table shows, although overall accuracy isincreased, we find that on some sentences, co-decoding instead worsens parsing accuracy.
Inorder to get insights on error sources, we manu-ally analyzed 20 sentences on which co-decodingachieves negative results.
We find a large por-tion (14 of 20) of sentences are short sentences(of words less than 20).
Actually, due to high ac-curacy of the CTB-based decoder on short sen-tences, co-decoding is indifferent when this de-coder is processing short sentences.
And we alsofind that some errors are derived from differencesin annotation standards.
Fortunately, the diver-gence of annotations mainly exists in relativelysmall spans.
So one solution to the problem is toenable co-decoding on relatively big spans.
Thesewill be done in our future work.4 Related Work4.1 System CombinationIn the literature of syntactic parsing, n-best com-bination methods include parse selection, con-stituent recombination, production recombina-tion, and n-best reranking.
Henderson and Brill(1999) performs parse selection by maximizingthe expected precision of selected parse with re-spect to the set of parses to be combined.
Sagaeand Lavie (2006) proposes to recombine con-stituents from the output of individual parsers.More recently, Fossum and Knight (2009) studiesa combination method at production level.
Zhanget al (2009) reranks n-best list of one parser withscores derived from another parser.Compared to n-best combination, co-decoding(Li et al, 2009; Liu et al, 2009) combines sys-tems during decoding phase.
Theoretically, sys-tem combination during decoding phase helps de-coders to select better approximation to hypothe-sis space, since pruning is practically unavoidable.To the best of our knowledge, co-decoding meth-ods have not been applied to syntactic parsing.4.2 Treebank TransformationThe focus of this study is heterogeneous parsing.Previous work on this challenge is generally basedon treebank transformation.
Wang et al (1994)describes a method for transformation betweenconstituency treebanks.
The basic idea is to traina parser on a target treebank and generate a n-bestlist for each sentence in source treebank(s).
Then,a matching metric which is a function on the num-ber of the same word spans between two trees isdefined to select a best parse from each n-best list.Niu et al (2009) applies a closely similar frame-work as with (Wang et al, 1994) to transform adependency treebank to a constituency one.5 ConclusionsThis paper proposed a co-decoding approach tothe challenge of heterogeneous parsing.
Com-pared to previous work on this challenge, co-decoding is able to directly utilize heterogeneoustreebanks by incorporating consensus informationbetween partial output of individual parsers dur-ing the decoding phase.
Experiments demonstratethe effectiveness of the co-decoding approach, es-pecially the effectiveness on long sentences.AcknowledgmentsThis work was supported in part by the NationalScience Foundation of China (60873091).
Wewould like to thank our anonymous reviewers fortheir comments.1351ReferencesBanko, Michele and Eric Brill.
2001.
Scaling tovery very large corpora for natural language dis-ambiguation.
In Proc.
of ACL 2001, pages 26-33.Chen, Xiao, Changning Huang, Mu Li, and ChunyuKit.
2009.
Better Parser Combination.
TechniqueReport of CIPS-ParsEval 2009.Collins, Michael.
1999.
Head-driven statistical mod-els for natural language parsing.
Ph.D. thesis, Uni-versity of Pennsylvania.Charniak, Eugene.
2000.
A maximum-entropy-inspired parser.
In Proc.
of NAACL 2000, pages132-139.Fossum, Victoria and Kevin Knight.
2009.
Combin-ing constituent parsers.
In Proc.
of NAACL 2009,pages 253-256.Henderson, John and Eric Brill.
1999.
Exploiting di-versity in natural language processing.
In Proc.
ofSIGDAT-EMNLP 1999, pages 187-194.Huang, Zhongqiang, Mary P. Harper, and Wen Wang.2007.
Mandarin part-of-speech tagging and dis-criminative reranking.
In Proc.
of EMNLP-CoNLL2007, pages 1093-1102.Li, Mu, Nan Duan, Dongdong Zhang, Chi-Ho Li, andMing Zhou.
2009.
Collaborative decoding: par-tial hypothesis re-ranking using trnaslationconsen-sus between decoders.
In Proc.
of ACL 2009, pages585-592.Liu, Yang, Haitao Mi, Yang Feng, and Qun Liu.
2009.Joint Decoding with Multiple Translation Models.In Proc.
of ACL 2009, pages 576-584.Niu, Zheng-Yu, Haifeng Wang, Hua Wu.
2009.
Ex-ploiting heterogeneous treebanks for parsing.
InProc.
of ACL 2009, pages 46-54.Petrov, Slav, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and in-terpretable tree annotation.
In Proc.
of COLING-ACL 2006, pages 433-440.Sage, Kenji and Alon Lavie.
2006.
Parser combina-tion by reparsing.
In Proc.
of NAACL 2006, pages129-132.Xue, Nianwen, Fu dong Chiou, and Martha Palmer.2002.
Building a large-scale Annotated Chinesecorpus.
In Proc.
of COLING 2002, pages 1-8.Wang, Jong-Nae, Jing-Shin Chang, and Keh-Yih Su.1994.
An automatic treebank conversion algorithmfor corpus sharing.
In Proc.
of ACL 1994, pages248-254.Zhang, Hui, Min Zhang, Chew Lim Tan, and HaizhouLi.
2009.
K-best combination of syntactic parsers.In Proc.
of EMNLP 2009, pages 1552-1560.Zhou, Qiang.
1996.
Phrase bracketing and annotatingon Chinese language corpus.
(in Chinese) Ph.D.thesis, Beijing University.Zhu, Muhua and Jingbo Zhu.
2009.
Label Corre-spondence Learning for Part-of-Speech AnnotationTransformation.
In Proc.
of CIKM 2009, pages1461-1464.1352
