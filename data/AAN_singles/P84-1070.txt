A D ISCOVERY PROCEDUREFOR CERTAIN  PHONOLOGICAL  RULESMark JohnsonLinguistics, UCSD.ABSTRACTAcquisition of phonological systems can be insightfullystudied in terms of discovery procedures.
This paper describesa discovery procedure, implemented in Lisp, capable of deter-mining a set of ordered phonological rules, which may be inopaque contexts~ from a set of surface forms arranged in para-digms.1.
INTRODUCTIONFor generative grammarians,  uch as Chomsky (1965), aprimary problem of linguistics is to explain how the languagelearner can acquire the grammar of his or her language on thebasis of the limited evidence available to him or her.
Chomskyintroduced the idealization of instantaneous acquisition, which1 adopt here, in order to model the language acquisition deviceas a function from primary linguistic data to possible gram-mars, rather than as a process.Assuming that the set of possible human languages issmall, rather than large, appears to make acquisition easier,since there are fewer possible grammars  to choose from, andless data should be required to choose between them.
Accord-ingly, generative linguists are interested in delimiting the classof possible human languages.
This is done by looking for pro-perties common to all human languages, or universals.Together, these universals form universal grammar, a set ofprinciples that all human languages obey.
Assuming thatuniversal grammar  is innate, the language learner can use it torestrict the number of possible grammars he or she must  con-sider when learning a language.As part of universal grammar,  the language learner issupposed to innately possess an evaluation metric, which isused to "decide" between two grammars when both are con-sistent with other principles of universal grammar and theavailable language data.2.
D ISCOVERY PROCEDURESThis approach deals with acquisition without reference toa specific discovery procedure, and so in some sense the resultsof such research are general~ in that in principle they apply toall discovery procedures.
Still, I think that there is some util-ity in considering the problem of acquisition in terms of actualdiscovery procedures.Firstly, we can identify the parts of a grammar that areunderspeeified with respect to the available data.
Parts  of agrammar  or a rule are strongly data determined if they arefixed or uniquely determined by the data, given the require-ment that  overall grammar be empirically correct.By contrast,  a part of a grammar  or of a rule is weakly datadetermined if there is a large class of grammar  or rule partsthat are all consistent with the available data.
For example, ifthere are two possible analyses that equally well account forthe available data, then the choice of which of these analysesshould be incorporated in the final g rammar  is weakly datadetermined.
Strong or weak data determination is therefore aproperty of the grammar formalism and the data combined,and independent of the choice of discovery procedure.Secondly, a discovery procedure may partition a phono-logical system in an interesting way.
For instance, in thediscovery procedure described here tile evaluation metric is notcalled apon to compare one grammar with another, but ratherto make smaller, more local, comparisons.
This leads to a fac-toring of the evaluation metric that may prove useful for itsfurther investigation.Thirdly, focussing on discovery procedures forces us toidentify what the surface indications of the various construc-tions in the grammar  are.
Of course, this does not mean oneshould look for a one-to-one correspondence between individualgrammar  construct ions and the surface data; but rather com-plexes of grammar constructions that interact to yield particu-lar patterns on the surface.
One is then investigating the logi-cal implications of the existence of a particular construct ions inthe data.Following from the last point, 1 think a discovery pro-cedure should have a deductive rather than enumerative struc-ture.
In particular, procedures that work essentially byenumerat ing all possible (sub)grammars and seeing which oneswork are not only in general very inefficient, but.
also not.
veryinsightful.
These discovery by enumerat ion procedures implygive us a list of all rule systems that  are empirically adequateas a result, but they give us no idea as to what properties ofthese systems were crucial in their being empirically adequate.This is because the structure imposed on the problem by asimple recursive enumerat ion procedure is in general notrelated to the intrinsic structure of the rule discovery problem.3.
A PHONOLOGICAL  RULE  D ISCOVERY PRO-CEDUREBelow and in Appendix A I outline a discovery pro-cedure: which I have fully implemented in Franz Lisp on aVAX 11/750 computer,  for a restricted class of phonologicalrules, namely rules of the type shown in (1).
(1)  ~ ~ b / cRule (1) means that any segment a that appears in con-text C in  the input to the rule appears asa  bin the rule's out-put.
Context  C is a feature matrix, and to say that a appearsin context C means that C is a subse!
of the fvature malrix344formed by the segments around a 1.
A phonological systemconsists of an ordered 2 set of such rules, where the rules areconsidered to apply in a cascaded fashion, that.
is, the outputof one rule is the input to the next..The problem the discovery procedure must  solve is, givensome data, to determine the set of rules.
As an idealization, Iassume that the input to the discovery procedure is a set ofsurface paradigms, a two dimensional array of words with allwords in the same row possessing the same stem and all wordsin the same column the same affix.
Moreover, l assume theroot and suffix morphemes are already identified, ahhough Iadmit this task may be non-trivial.4.
DETERMIN ING THE CONTEXT THAT CONDI -T IONS AN ALTERNATIONConsider the simplest phonological system: one in whichonly one phonological rule is operative.
In this system thealternating segements a and b can be determined by inspec-tion, since a and b will be the only alternating segments in thedata (although there will be a systematic ambiguity as towhich is a and which is b).
Thus  a and b are strongly datadetermined.Given a and b. we can write a set of equations that therule context C that conditions this alternation must obey.Our rule rnust apply in all contexts C b where a b appears thatalternates with an a, since by hypothesis b was produced bythis rule.
We can represent this by equation (2).
(2) ~7\]Cb, C matches C bThe second condition that our rule must  obey is that itdoesn't apply in any context.
C a where an a appears.
If it did,of course, we would expect a b, not an a, in this position onthe surface.
We can write this condition by equation (3).
(3) ~?C,, C does not match 6',These two equations define the rule context C. Note thatin general these equations do not yield a unique value for C;depending apon the data tbere may be no C that simultane-ously satisfies (2) and (3).
or there may be several different Cthat simultaneously satisfies (2) and (3).
We cannot appealfurther to the data to decide which C to use, since they all areequally consistent with the data.Let us call the set of C that s imultaneously satisfies (2)and (3) S o Then S c is strongly data determined; in fact,there is an efficient algorithm for comput ing S c from the C,sand Cbs that  does not involve enumerat ing and testing all ima-ginable C (the algorithm is described in Appendix A).However, if S c contains more than one 6', the choice ofwhich C from Sc to actually use as the rule's context is weakly1 What  is crucial for what follows is that saying context Cmatches a portion of a word W is equivalent o saying that Cis a subset of W. Since both rule contexts and words can bewritten as sets of features, 1 use "contexts" to refer both torule contexts and to words.z I make this assumption as a first approximation.
Infact, in real phonological systems phonological rules may beunordered with respect o each other.data determined.
Moreover.
the choice of v, hich ( ' f rom Sc louse does not affect any other decisions that the discovery pro-cedure has to make - that is.
nothing else in the completegrammar  must change if we decide to use one C instead ofanother.Plausibly, the evaluation metric and universal principlesdecide which C to use in this situation.
For example, if thealternation involves nasafization of a vowel, something thatusually only occurs in the context, of a nasal, and one of thecontexts in S c involves the feature nasal but the other C in S cdo not, a reasonable requirement is that the discovery pro-cedure should select the context involving the feature nasal asthe appropriate context Cfor  the rule.Another possibility is that .qc'S containing more than one,member indicates to the discovery procedure that it simply hastoo little data to determine the grammar,  and it defers makinga decision on which C to use until it has the relevant data.The decision as to which of these possibilities is correct is isnot unimportant ,  and may have interesting empirical conse-quences regarding language acquisition.McCarthy (1981) gives some data on a related issue.Spanish does not tolerate word initial sC clusters, a fact.
whichmight be accounted for in two ways; either with a rule thatinserts e before word initial sC clusters, or by a constraint onwell-formed underlying structures (a redundancy rule) barringword initial sC.
McCarthy reports that  either constraint isadequate to account for Spanish morphopbonemics,  and thereis no particular language internal evidence to prefer one overthe other.The two accounts make differing predictions regardingthe treatrnent of loan words.
The e insertion rule predicts thatloan words beginning with sC should receive an initial e (asthey do: esnob, esmoking, esprey), while the well-formednessconstraint makes no such prediction.McCar thy 's  evidence from Spanish therefore suggests thatthe human acquisition procedure can adopt one potentialanalysis and rejects an other without empirical evidence to dis-tinguish between them.
ltowever, in the Spanish case, the twopotential analyses differ as to which components of the gram-mar they involve (active phonological processes versus lexicalredundancy rules) which affects the overall structure of theadopted grammar  to a much greater degree than the choice ofone C from S c over another.5.
RULE ORDERINGIn the last section 1 showed that  a single phonologicalrule can be determined from the surface data.
In practice,very few, if any, phonological systems involve only one rule.Systems involving more than one rule show complexity thatsingle rule systems do not.
In particular, a rules may beordered in such a fashion that  one rule affects segments thatare part of the context that  condit ions the operation ofanother rule.
If a rule's context is visible on the surface (ie.has not been destroyed by the operation of another rule) it issaid to be transparent, while if a rule's context is no longervisible on the surface it is opaque.
On the face of it, opaquecontexts could pose problems for discovery procedures.345()r<h,rillg (,i r,lh,~ h~u- b<'(q+ a topic ~,ul>,,l+jlilial re.~e~-~r\[h it+?h..<,h,g',.
Xl'.
mai,, ,d,i,.cli'..c, i. thi- ~,,rti.. is t(, shov.
thate?trirlsically ordered ruh,s i,, prilu'iph' pose t~o prohlem for adiscover) prl,tt'durl'.
('~l'n if later ruh's obscure Ihe ('ontext ofearlier ones.
I don't make any elaitn that Ihe procedurepresented here is optinlal - in fact I can think of at least twoways to make it perform its job more effil'ienlly.
The outputof this (lisc<~very procedure is the set of all possible orderedruh.
s3stelllS z aud their correspondiHg u lderhing forms thatcan pr(,duee the given surface fort,is.As before.
I ass,lnle thal the data is in the form of sets ofparadigms.
I also assunu, that for e~er) ruh, ctlanging an a toa b. an aheri ,ai ion hetween a and b appears in the data: thus++e know hy listing the alternations in ttw data just what thepossihle as and bs of the ruh' are 4.Frorn the assumpxion thai ruh,s are ex tins\[(ally orderedil folh,ws lhat one of the ruh's must have appli(,(t last: that is.there is a urJique "most surfaev" rule.
The ('ontext or this ruh.+~ill ne<essariLy I,r t ransl)aret,  (visible in the surface hJrms), asthere is ill) later rule to nlake its context  opaque.Of coHrse, till' (liscover.
', procedure has no a priori way oftellhJg +~hit'h alt(.rnati.n (.,rresponds In the nlost surfacy rule.ThlLy> although tilt, identh) of till' segnlelitS involved in tileniosl suffal", rule ilia)" he strictly data delerlnined, at thisstall, Ihls inftlrnlali i ln i.
"; Ill)| availahle to the discovery pro-('edure.SO at this point, tile discovery pr(lcedure proposed heresystematical ly investigates all of the surface ahernations: fi)reach alternation it makes the hypothesis that h, is the theal ternat ion (if lilt, nlost sllrfa(') rub'.
('herks that a context Callbe fouud thai conditions this alternation (this lnust he so ifthe hypothesis is correct) using the sirigle rule algorithmpresented earlier, and then investigates if it, is possible to con-strut(  an empirically correct set of rules based on thishylitlt.hesis.Given thai we have found a potential IlIIIOSI surfacy"ruh,, all of the surface alternates are replaced by the putativeunderlying segment to fornl a set of intermediate forms, inwhi<'h the rule just discovered has been undone.
We can undothis rule berause we previously identified tile alternating seg-nlents, ull),.rtantly, undoing this rule means that all otherThus  if the n rules in the systetn are unoi'dered, thisprocedure returns n!
solutions corresponding to the n ways ofordering these rules.The reason why the class of phonological rules con-sidered in this paper was restricted to those mapping segmentsinto segments was so that all alternations could be identifiedby simply comparing surface forms segment by segment.
Thusin this discovery procedure the algorithm for identifying possi-ble alternates can be of a particularly simple form.
If we arewilling It) complicate the rnachinery that deterlnines the possi-bh' ahernat ions in some data.
we can relax the restrictionprohibiting epe+nt, hesis and deletion rules, and the requirementthat all alternations are visible on tile surface.
That  is, if theapproach here is correct, the problem of identifying which seg-ments alternate is a different problem to discovering the( (U l l | '~t  llllll t l~hdll l l~ll~, lh l  ~ ,flit I hill ll,il,ruh.s whl)se cot, texts had been made opaque in the surfacedala b.v the operation of the most surfacy rule will now bet ransparen t.The hypothesis tester proceeds to look for another alter-nation, this tilne in the intermediate forms, rather than in thesurface fi)rms, and so on until all alternations have beenaccounted for.If at an.
',' stage the hypothesis tester fails to find a rule I,odr'scribe the alternation it is currently working with, that is,the single-rule algorithm determines thai no rule context existsthat can capture this alternation, the hypothesis tester dis-cards ttte current hypothesis, and tries auother.The hypothesis tester is responsible for proposing dif-ferent rule order\[ass, which are tested by applying the rules inreverse to arrive at progressively more renloved representa-lions, with the single-ruh' algorithm being applied at each stepto deterlnine if a rule exists that relates one level of intermedi-ate representation with the next.
We ran regard thehyp(itilesis tester as systematical ly searching through tile spaceof different rule orderings, seeking rub' orderings that success-fully accounts for the ohserved data.q'tJe output of this procedure is therefore a list of all pos-sible rule orderings.
As \] tnentioned before, I think that tileetlumeratlve approacit adopted here is basically flawed.
Soalthougit this procedure is relatively efficient, in situationswhere rule ordering is strictly data determined (that is, whereonly one nile ordering is consistent with the data),  in situa-tions where the rules are tmordered (any rule ordering will do),the procedure will generate all possible n!
orderings of the nrules.This was most striking while working with some Japanesedata.
with 6 dislincl alternations, 4 of which were unorderedwith respect to each other.
The discovery procedure, aspresented above, required approximately 1 hour of CPU timeto completely analyse this data: it.
found <l different underlyingforms and 512 different rule s.vstems that generate theJapanese data, differing primarily in tile ordering of the rules.This demonstrates that a discovery procedure that simplyenumerates all possible rule ordering is failing to capture someinlportant insight regarding rule ordering, since unorderedrules are much more difficult for this type of procedure to han-dle, yet, unordered rules are the most comtnon situation innatural langnage phonology.This problem may be traced back to the assumptionmade above that a phonological system consists of an orderedset of rules.
The Japanese example shows that in many realphonological systems, the ordering of particular rules is simplynot strongly data determined.
What we need is some way ofpartit ioning different, rule orderings into equivalence classes, aswas done with this the different rule contexts in the single rulealgorithm, and then compute with these equivalence classesrather than individual rule systems; that is.
seek to localize theweak data determinacy.Looking at the problem in another way, we asked thediscovery procedure to find all sets of ordered rules that gen-erate the surface data, which it did.
However, it seems thatthis simply was not rigllt question, since the answer to thisquestion, a set of 512 different systems, is virtually346uninterpretable by human beings.
Part of the problem is lhatphonologists in general have not yet agreed what exactly theprinciples of rule ordering are s .Still, the present discovery procedure, whatever its defi-ciencies, does demonstrate that rule ordering in phonologydoes not pose any principled insurmountable problems fordiscovery procedures (although the procedure presented here iscertainly practically lacking in certain situations), even if alater rule is allowed to disturb the context of an earlier rule, sothat the rule's context is no longer "surface true".
None theless, it is an empirical question as to whether phonology is bestdescribed in terms of ordered interacting rules~ all that l haveshown is that such systems are not in principle unlearnable.6.
CONCLUSIONIn this paper I have presented the details of a discoveryprocedure that can determine a limited class of phonologicalrules with arbitrary rule ordering.
The procedure has theinteresting property that it can be separated into two separatephases, the first, phase being superificial data analysis, that is,collecting the sets C, and C b of equations (2) and (3), and thesecond phase being the application of the procedure proper,which need never reference the data directly, but can do all ofits calculations using C, and Cb ~.
This property is interestingbecause it is likely that 6", and C a have limiting values, as thenumber of forms in the surface data increases.
That is,presumably the language only has a fixed number of alterna-tions, and each of these only occurs in some fixed contexts,and as soon as we have enough data to see all of these con-texts we will have determined C, and C b. and extra data willnot.
make these sets larger.
Thus the computational complex-ity of the second phase of the discovery procedure is more orless independent, of the size the lexicon, making the entire pro-cedure require linear time with respect to the size of the data.i think this is a desirable result, since there is something coun-terintuitive to a situation in which the difficulty of discoveringa grammar increases rapidly with the size of the lexicon.7.
APPENDIX  A: DETERMIN ING A RULE'S CON-TEXTIn this appendix !
describe an algorithm for calculatingthe set of rule contexts S c = { C } that satisify equations (2)and (3) repeated below in set notation as (4) and (5).
Recallthat C b are the contexts in which the alternation did takeplace, and C a are the contexts in which the alternations didnot take place.
We want to find (the set, of) contexts that.simultaneously match all the Cb, while not matching any C..(4) V C~, C C_ C bIn this paper 1 adopted strict ordering of all rules be-cause it is one of the more stringent rule ordering hypothesesavailable.e In fact, the sets C a and C b as defined above do not con-tain quite enough information alone.
We must also indicatewhich segments in these contexts alternate, and what they al-ternate to.
This may form the basis of a very different ruleorder discovery procedure.
(5) Vc,.
c ; c,We can manipulat.e these into computationally moretractable forms.
Starting with (4), we havec~, c c c~ (= (4))VCb, \ / fE  C , f~  C b~/e  c, fc  A CbCC I"3 CbPut C, = f"l Cb- Then CC 6"i.Now consider equation (5).~'c , , c~ c,Vc , ,~  i~ ( c -  c.)But since C~ C 1, if f~  ( C-  C0).
thenfE  ( C 1 - C , )  N C. Then~/c.,q_ /~ ( c , -  c , ) , /~ cThis last equation says thal ever), context thai fulfills theconditions above contains at least one feature that distin-guishes it from each C0, and that this feature must be in theintersection of all the C b.
If for any C,.
C\] - C e=O (the nullset of features), then there are no contexts C that simultane-ously match all the C b and none of the C,, implying that norule exists that accounts for the observed ah.ernation.We can construct the set S c using this last formula byfirst, calculating C1, the intersection of all the Cb, and then foreach C,, calculating C I : ( C I - C?
), a member of whichmust be in every 6'.
The idea is to keep a set of the minimalC needed to account for the C, so far; if C conl.ains a memberof C!
we don't need to modify it; if C does not contain amember of C I then we have to add a member of C I to it inorder for it to satisfy the equations above.
The algorithmbelow acomplishes this.set C 1 : \["I Cbset S c = {~}foreach C.set%= c , -  c.if%-Oreturn "No rule contezts"foreach C in S ci f cn  el=-0remove C f rom S cfo reaeh/ in  6'/add  CU { /}t?S  creturn S cwhere the subroutine "add" adds a set to S c only if it orits subset is not already present.After this algorithm has applied, S c will contain all theminimal different C that satisfy equations (4) and (5) above.347
