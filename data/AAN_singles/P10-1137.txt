Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1346?1356,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsMultilingual Pseudo-Relevance Feedback: Performance Study ofAssisting LanguagesManoj K. Chinnakotla Karthik Raman Pushpak BhattacharyyaDepartment of Computer Science and EngineeringIndian Institute of Technology, Bombay,Mumbai, India{manoj,karthikr,pb}@cse.iitb.ac.inAbstractIn a previous work of ours Chinnakotlaet al (2010) we introduced a novelframework for Pseudo-Relevance Feed-back (PRF) called MultiPRF.
Given aquery in one language called Source, weused English as the Assisting Language toimprove the performance of PRF for thesource language.
MulitiPRF showed re-markable improvement over plain ModelBased Feedback (MBF) uniformly for 4languages, viz., French, German, Hungar-ian and Finnish with English as the as-sisting language.
This fact inspired usto study the effect of any source-assistantpair on MultiPRF performance from outof a set of languages with widely differ-ent characteristics, viz., Dutch, English,Finnish, French, German and Spanish.Carrying this further, we looked into theeffect of using two assisting languages to-gether on PRF.The present paper is a report of these in-vestigations, their results and conclusionsdrawn therefrom.
While performance im-provement on MultiPRF is observed what-ever the assisting language and whateverthe source, observations are mixed whentwo assisting languages are used simul-taneously.
Interestingly, the performanceimprovement is more pronounced whenthe source and assisting languages areclosely related, e.g., French and Spanish.1 IntroductionThe central problem of Information Retrieval (IR)is to satisfy the user?s information need, which istypically expressed through a short (typically 2-3words) and often ambiguous query.
The problemof matching the user?s query to the documents isrendered difficult by natural language phenomenalike morphological variations, polysemy and syn-onymy.
Relevance Feedback (RF) tries to over-come these problems by eliciting user feedbackon the relevance of documents obtained from theinitial ranking and then uses it to automaticallyrefine the query.
Since user input is hard to ob-tain, Pseudo-Relevance Feedback (PRF) (Buckleyet al, 1994; Xu and Croft, 2000; Mitra et al, 1998)is used as an alternative, wherein RF is performedby assuming the top k documents from the initialretrieval as being relevant to the query.
Based onthe above assumption, the terms in the feedbackdocument set are analyzed to choose the most dis-tinguishing set of terms that characterize the feed-back documents and as a result the relevance ofa document.
Query refinement is done by addingthe terms obtained through PRF, along with theirweights, to the actual query.Although PRF has been shown to improve re-trieval, it suffers from the following drawbacks:(a) the type of term associations obtained for queryexpansion is restricted to co-occurrence based re-lationships in the feedback documents, and thusother types of term associations such as lexical andsemantic relations (morphological variants, syn-onyms) are not explicitly captured, and (b) due tothe inherent assumption in PRF, i.e., relevance oftop k documents, performance is sensitive to thatof the initial retrieval algorithm and as a result isnot robust.Multilingual Pseudo-Relevance Feedback(MultiPRF) (Chinnakotla et al, 2010) is a novelframework for PRF to overcome both the abovelimitations of PRF.
It does so by taking the help ofa different language called the assisting language.In MultiPRF, given a query in source languageL1, the query is automatically translated intothe assisting language L2 and PRF performedin the assisting language.
The resultant termsare translated back into L1 using a probabilisticbi-lingual dictionary.
The translated feedback1346model, is then combined with the original feed-back model of L1 to obtain the final model whichis used to re-rank the corpus.
MulitiPRF showedremarkable improvement on standard CLEFcollections over plain Model Based Feedback(MBF) uniformly for 4 languages, viz., French,German, Hungarian and Finnish with English asthe assisting language.
This fact inspired us tostudy the effect of any source-assistant pair onPRF performance from out of a set of languageswith widely different characteristics, viz., Dutch,English, Finnish, French, German and Spanish.Carrying this further, we looked into the effect ofusing two assisting languages together on PRF.The present paper is a report of these in-vestigations, their results and conclusions drawntherefrom.
While performance improvement onPRF is observed whatever the assisting languageand whatever the source, observations are mixedwhen two assisting languages are used simulta-neously.
Interestingly, the performance improve-ment is more pronounced when the source and as-sisting languages are closely related, e.g., Frenchand Spanish.The paper is organized as follows: Section 2,discusses the related work.
Section 3, explains theLanguage Modeling (LM) based PRF approach.Section 4, describes the MultiPRF approach.
Sec-tion 5 discusses the experimental set up.
Section 6presents the results, and studies the effect of vary-ing the assisting language and incorporates mul-tiple assisting languages.
Finally, Section 7 con-cludes the paper by summarizing and outlining fu-ture work.2 Related WorkPRF has been successfully applied in various IRframeworks like vector space models, probabilis-tic IR and language modeling (Buckley et al,1994; Jones et al, 2000; Lavrenko and Croft,2001; Zhai and Lafferty, 2001).
Several ap-proaches have been proposed to improve the per-formance and robustness of PRF.
Some of the rep-resentative techniques are (i) Refining the feed-back document set (Mitra et al, 1998; Sakai etal., 2005), (ii) Refining the terms obtained throughPRF by selecting good expansion terms (Cao etal., 2008) and (iii) Using selective query expan-sion (Amati et al, 2004; Cronen-Townsend et al,2004) and (iv) Varying the importance of docu-ments in the feedback set (Tao and Zhai, 2006).Another direction of work, often reported in theTREC Robust Track, is to use a large external col-lection like Wikipedia or the Web as a source ofexpansion terms (Xu et al, 2009; Voorhees, 2006).The intuition behind the above approach is thatif the query does not have many relevant docu-ments in the collection then any improvements inthe modeling of PRF is bound to perform poorlydue to query drift.Several approaches have been proposed forincluding different types of lexically and se-mantically related terms during query expansion.Voorhees (1994) use Wordnet for query expan-sion and report negative results.
Recently, randomwalk models (Lafferty and Zhai, 2001; Collins-Thompson and Callan, 2005) have been used tolearn a rich set of term level associations by com-bining evidence from various kinds of informationsources like WordNet, Web etc.
Metzler and Croft(2007) propose a feature based approach called la-tent concept expansion to model term dependen-cies.All the above mentioned approaches use the re-sources available within the language to improvethe performance of PRF.
However, we make use ofa second language to improve the performance ofPRF.
Our proposed approach is especially attrac-tive in the case of resource-constrained languageswhere the original retrieval is bad due to poor cov-erage of the collection and/or inherent complexityof query processing (for example term conflation)in those languages.Jourlin et al (1999) use parallel blind relevancefeedback, i.e.
they use blind relevance feedback ona larger, more reliable parallel corpus, to improveretrieval performance on imperfect transcriptionsof speech.
Another related idea is by Xu et al(2002), where a statistical thesaurus is learned us-ing the probabilistic bilingual dictionaries of Ara-bic to English and English to Arabic.
Meij etal.
(2009) tries to expand a query in a differ-ent language using language models for domain-specific retrieval, but in a very different setting.Since our method uses a corpus in the assistinglanguage from a similar time period, it can belikened to the work by Talvensaari et al (2007)who used comparable corpora for Cross-LingualInformation Retrieval (CLIR).
Other work pertain-ing to document alignment in comparable corpora,such as Braschler and Scha?uble (1998), Lavrenkoet al (2002), also share certain common themeswith our approach.
Recent work by Gao et al1347(2008) uses English to improve the performanceover a subset of Chinese queries whose transla-tions in English are unambiguous.
They use inter-document similarities across languages to improvethe ranking performance.
However, cross lan-guage document similarity measurement is in it-self known to be an hard problem and the scale oftheir experimentation is quite small.3 PRF in the LM FrameworkThe Language Modeling (LM) Framework allowsPRF to be modelled in a principled manner.
In theLM approach, documents and queries are modeledusing multinomial distribution over words calleddocument language model P (w|D) and query lan-guage model P (w|?Q) respectively.
For a givenquery, the document language models are rankedbased on their proximity to the query languagemodel, measured using KL-Divergence.KL(?Q||D) =XwP (w|?Q) ?
logP (w|?Q)P (w|D)Since the query length is short, it is difficult to es-timate ?Q accurately using the query alone.
InPRF, the top k documents obtained through the ini-tial ranking algorithm are assumed to be relevantand used as feedback for improving the estima-tion of ?Q.
The feedback documents contain bothrelevant and noisy terms from which the feedbacklanguage model is inferred based on a GenerativeMixture Model (Zhai and Lafferty, 2001).Let DF = {d1, d2, .
.
.
, dk} be the top k docu-ments retrieved using the initial ranking algorithm.Zhai and Lafferty (Zhai and Lafferty, 2001) modelthe feedback document setDF as a mixture of twodistributions: (a) the feedback language model and(b) the collection model P (w|C).
The feedbacklanguage model is inferred using the EM Algo-rithm (Dempster et al, 1977), which iterativelyaccumulates probability mass on the most distin-guishing terms, i.e.
terms which are more fre-quent in the feedback document set than in theentire collection.
To maintain query focus the fi-nal converged feedback model, ?F is interpolatedwith the initial query model ?Q to obtain the finalquery model ?Final.
?Final = (1?
?)
?
?Q + ?
?
?F?Final is used to re-rank the corpus using theKL-Divergence ranking function to obtain the fi-nal ranked list of documents.
Henceforth, we referInitial Retrieval Algorithm(LM Based Query Likelihood)Initial Retrieval Algorithm(LM Based Query Likelihood)Top ?k?
Results Top ?k?
ResultsPRF(Model Based Feedback)PRF(Model Based Feedback)L1 Index L2  IndexFinal Ranked List Of Documents in L1FeedbackModel Interpolation Relevance ModelTranslationKL-Divergence Ranking FunctionFeedback Model ?L2Feedback Model ?L1Query in L1 Translated Query to L2ProbabilisticDictionaryL2?
L1TranslatedFeedback ModelQuery Model ?QFigure 1: Schematic of the Multilingual PRF ApproachSymbol Description?Q Query Language Model?FL1 Feedback Language Model obtained from PRF in L1?FL2 Feedback Language Model obtained from PRF in L2?TransL1 Feedback Model Translated from L2 to L1t(f |e) Probabilistic Bi-Lingual Dictionary from L2 to L1?, ?
Interpolation coefficients coefficients used in MultiPRFTable 2: Glossary of Symbols used in explaining MultiPRFto the above technique as Model Based Feedback(MBF).4 Multilingual PRF (MultiPRF)The schematic of the MultiPRF approach is shownin Figure 1.
Given a query Q in the source lan-guage L1, we automatically translate the queryinto the assisting language L2.
We then rank thedocuments in the L2 collection using the querylikelihood ranking function (John Lafferty andChengxiang Zhai, 2003).
Using the top k doc-uments, we estimate the feedback model usingMBF as described in the previous section.
Simi-larly, we also estimate a feedback model using theoriginal query and the top k documents retrievedfrom the initial ranking in L1.
Let the resultantfeedback models be ?FL2 and ?FL1 respectively.The feedback model estimated in the assisting lan-guage ?FL2 is translated back into language L1using a probabilistic bi-lingual dictionary t(f |e)from L2 ?
L1 as follows:P (f |?TransL1 ) =X?
e in L2t(f |e) ?
P (e|?FL2 ) (1)The probabilistic bi-lingual dictionary t(f |e) is1348Language CLEF Collection Identifier DescriptionNo.
ofDocumentsNo.
of UniqueTermsCLEF Topics(No.
of Topics)EnglishEN-00+01+02 LA Times 94 113005 174669 -EN-03+05+06 LA Times 94, Glasgow Herald 95 169477 234083 -EN-02+03 LA Times 94, Glasgow Herald 95 169477 234083 91-200 (67)FrenchFR-00 Le Monde 94 44013 127065 1-40 (29)FR-01+02 Le Monde 94, French SDA 94  87191 159809 41-140 (88)FR-02+03 Le Monde 94, French SDA 94-95 129806 182214 91-200 (67)FR-03+05 Le Monde 94, French SDA 94-95 129806 182214 141-200,251-300 (99)FR-06 Le Monde 94-95, French SDA 94-95 177452 231429 301-350 (48)GermanDE-00 Frankfurter Rundschau 94, Der Spiegel 94-95 153694 791093 1-40 (33)DE-01+02 Frankfurter Rundschau 94, Der Spiegel 94-95, German SDA 94 225371 782304 41-140 (85)DE-02+03 Frankfurter Rundschau 94, Der Spiegel 94-95, German SDA 94-95 294809 867072 91-200 (67)DE-03 Frankfurter Rundschau 94, Der Spiegel 94-95, German SDA 94-95 294809 867072 141-200 (51)Finnish FI-02+03+04 Aamulehti 94-95 55344 531160 91-250 (119) FI-02+03 Aamulehti 94-95 55344 531160 91-200 (67)Dutch NL-02+03 NRC Handelsblad 94-95, Algemeen Dagblad 94-95 190604 575582 91-200 (67)Spanish ES-02+03 EFE 94, EFE 95 454045 340250 91-200 (67)Table 1: Details of the CLEF Datasets used for Evaluating the MultiPRF approach.
The number shown in brackets of the finalcolumn CLEF Topics indicate the actual number of topics used during evaluation.Source Term Top Aligned Terms in TargetFrench Englishame?ricain american, us, united, state, americanation nation, un, united, state, countryet?ude study, research, assess, investigate, surveyGerman Englishflugzeug aircraft, plane, aeroplane, air, flightspiele play, game, stake, role, playerverha?ltnis relationship, relate, balance, proportionTable 3: Top Translation Alternatives for some sample wordsin Probabilistic Bi-Lingual Dictionarylearned from a parallel sentence-aligned corporain L1?L2 based on word level alignments.
Tiede-mann (Tiedemann, 2001) has shown that the trans-lation alternatives found using word alignmentscould be used to infer various morphological andsemantic relations between terms.
In Table 3,we show the top translation alternatives for somesample words.
For example, the French wordame?ricain (american) brings different variants ofthe translation like american, america, us, united,state, america which are lexically and semanti-cally related.
Hence, the probabilistic bi-lingualdictionary acts as a rich source of morphologicallyand semantically related feedback terms.
Thus,during this step, of translating the feedback modelas given in Equation 1, the translation model addsrelated terms in L1 which have their source as theterm from feedback model ?FL2 .
The final Multi-PRF model is obtained by interpolating the abovetranslated feedback model with the original querymodel and the feedback model of language L1 asgiven below:?MultiL1 = (1?
?
?
?)
?
?Q + ?
?
?FL1+ ?
?
?TransL1 (2)Since we want to retain the query focus duringback translation the feedback model in L2 is inter-polated with the translated query before transla-tion of the L2 feedback model.
The parameters ?and ?
control the relative importance of the orig-inal query model, feedback model of L1 and thetranslated feedback model obtained from L1 andare tuned based on the choice of L1 and L2.5 Experimental SetupWe evaluate the performance of our system us-ing the standard CLEF evaluation data in six lan-guages, widely varying in their familial relation-ships - Dutch, German, English, French, Span-ish and Finnish using more than 600 topics.
Thedetails of the collections and their correspondingtopics used for MultiPRF are given in Table 1.Note that, in each experiment, we choose assist-ing collections such that the topics in the sourcelanguage are covered in the assisting collection soas to get meaningful feedback terms.
In all the top-ics, we only use the title field.
We ignore the top-ics which have no relevant documents as the trueperformance on those topics cannot be evaluated.We demonstrate the performance of MultiPRFapproach with French, German and Finnish assource languages and Dutch, English and Span-ish as the assisting language.
We later vary theassisting language, for each source language andstudy the effects.
We use the Terrier IR platform(Ounis et al, 2005) for indexing the documents.We perform standard tokenization, stop word re-moval and stemming.
We use the Porter Stemmerfor English and the stemmers available through theSnowball package for other languages.
Other thanthese, we do not perform any language-specificprocessing on the languages.
In case of French,1349Collection Assist.
Lang P@5 P@10 M AP GMAPM BF MultiPRF % Impr.
MBF MultiPRF % Impr.
MBF MultiPRF % Impr.
MBF MultiPRF % Impr.FR - 00 EN 0.4690 0.5241 11.76?0.4000 0.4000 0.00 0.4220 0.4393 4.10 0.2961 0.3413 15.27ES 0.5034 7.35 ?
0.4103 2.59 0.4418 4.69 0.3382 14.22NL 0.5034 7.35 0.4103 2.59 0.4451 5.47 0.3445 16.34FR - 01+02 EN 0.4636 0.4818 3.92 0.4068 0.4386 7.82?0.4342 0.4535 4.43?0.2395 0.2721 13.61ES 0.4977 7.35 ?
0.4363 7.26 ?
0.4416 1.70 0.2349 -1.92NL 0.4818 3.92 0.4409 8.38 ?
0.4375 0.76 0.2534 5.80FR - 03+05 EN 0.4545 0.4768 4.89?0.4040 0.4202 4?0.3529 0.3694 4.67?0.1324 0.1411 6.57ES 0.4727 4.00 0.4080 1.00 0.3582 1.50 0.1325 0.07NL 0.4525 -0.44 0.4010 -0.75 0.3513 0.45 0.1319 -0.38FR - 06 EN 0.4917 0.5083 3.39 0.4625 0.4729 2.25 0.3837 0.4104 6.97 0.2174 0.2810 29.25ES 0.5083 3.39 0.4687 1.35 0.3918 2.12 0.2617 20.38NL 0.5083 3.39 0.4646 0.45 0.3864 0.71 0.2266 4.23DE- 00 EN 0.2303 0.3212 39.47?0.2394 0.2939 22.78?0.2158 0.2273 5.31 0.0023 0.0191 730.43ES 0.3212 39.47 ?
0.2818 17.71 ?
0.2376 10.09 0.0123 434.78NL 0.3151 36.82 ?
0.2818 17.71 ?
0.2331 8.00 0.0122 430.43DE- 01+02 EN 0.5341 0.6000 12.34?0.4864 0.5318 9.35?0.4229 0.4576 8.2?0.1765 0.2721 9.19ES 0.5682 6.39 ?
0.5091 4.67 ?
0.4459 5.43 0.2309 30.82NL 0.5773 8.09 ?
0.5114 5.15 ?
0.4498 6.35 ?
0.2355 33.43DE- 03 EN 0.5098 0.5412 6.15 0.4784 0.4980 4.10 0.4274 0.4355 1.91 0.1243 0.1771 42.48ES 0.5647 10.77 ?
0.4980 4.10 0.4568 6.89 ?
0.1645 32.34NL 0.5529 8.45 ?
0.4941 3.27 0.4347 1.72 0.1490 19.87FI- 02+03+04 EN 0.3782 0.4034 6.67?0.3059 0.3319 8.52?0.3966 0.4246 7.06?0.1344 0.2272 69.05ES 0.3879 2.58 0.3267 6.81 0.3881 -2.15 0.1755 30.58NL 0.3948 4.40 0.3301 7.92 0.4077 2.79 0.1839 36.83Table 4: Results comparing the performance of MultiPRF over baseline MBF on CLEF collections with English (EN), Spanish(ES) and Dutch (NL) as assisting languages.
Results marked as ?
indicate that the improvement was found to be statisticallysignificant over the baseline at 90% confidence level (?
= 0.01) when tested using a paired two-tailed t-test.since some function words like l?, d?
etc., occur asprefixes to a word, we strip them off during index-ing and query processing, since it significantly im-proves the baseline performance.
We use standardevaluation measures like MAP, P@5 and P@10for evaluation.
Additionally, for assessing robust-ness, we use the Geometric Mean Average Preci-sion (GMAP) metric (Robertson, 2006) which isalso used in the TREC Robust Track (Voorhees,2006).
The probabilistic bi-lingual dictionary usedin MultiPRF was learnt automatically by runningGIZA++: a word alignment tool (Och and Ney,2003) on a parallel sentence aligned corpora.
Forall the above language pairs we used the EuroparlCorpus (Philipp, 2005).
We use Google Trans-late as the query translation system as it has beenshown to perform well for the task (Wu et al,2008).
We use the MBF approach explained inSection 3 as a baseline for comparison.
We usetwo-stage Dirichlet smoothing with the optimalparameters tuned based on the collection (Zhai andLafferty, 2004).
We tune the parameters of MBF,specifically ?
and ?, and choose the values whichgive the optimal performance on a given collec-tion.
We uniformly choose the top ten documentsfor feedback.
Table 4 gives the overall results.6 Results and DiscussionIn Table 4, we see the performance of the Multi-PRF approach for three assisting languages, andhow it compares with the baseline MBF meth-ods.
We find MultiPRF to consistently outperformthe baseline value on all metrics, namely MAP(where significant improvements range from 4.4%to 7.1%); P@5 (significant improvements rangefrom 4.9% to 39.5% and P@10 (where MultiPRFhas significant gains varying from 4% to 22.8%).Additionally we also find MultiPRF to be more ro-bust than the baseline, as indicated by the GMAPscore, where improvements vary from 4.2% to730%.
Furthermore we notice these trends holdacross different assisting languages, with Span-ish and Dutch outperforming English as the as-sisting language on some of the French and Ger-man collections.
On performing a more detailedstudy of the results we identify the main reasonfor improvements in our approach is the ability toobtain good feedback terms in the assisting lan-guage coupled with the introduction of lexicallyand semantically related terms during the back-translation step.In Table 5, we see some examples, which illus-trates the feedback terms brought by the MultiPRFmethod.
As can be seen by these example, thegains achieved by MultiPRF are primarily due toone of three reasons: (a) Good Feedback in As-sisting Language: If the feedback model in theassisting language contains good terms, then theback-translation process will introduce the corre-sponding feedback terms in the source language,thus leading to improved performance.
As anexample of this phenomena, consider the FrenchQuery ?Maladie de Creutzfeldt-Jakob?.
In thiscase the original feedback model also performs1350TOPIC NOASSISTLANG.SOURCE LANGUAGEQUERYTRANSLATEDQUERYQUERYMEANINGM BFM APM P RFM APM BF - Top Representative Terms(With Meaning) Excl.
QueryTermsMultiPRF - Top RepresentativeTerms (With Meaning) Excl.
QueryTermsGERMAN '01:TOPIC 61 EN?lkatastrophe inSibirien Oil Spill in SiberiaSiberian OilCatastrophe 0.618 0.812exxon , million,  ol (oil), tonn,russisch (russian), olp (oil),moskau (moscow), usolverschmutz (oil pollution), ol,russisch, erdol (petroleum), russland(russia), olunfall(oil spill), olpGERMAN '02:TOPIC 105 ES Bronchialasthma El asma bronquialBronchialAsthma 0.062 0.636chronisch (chronic), pet, athlet(athlete), ekrank (ill), gesund(healthy),  tuberkulos(tuberculosis), patient, reis (rice),personasthma, allergi, krankheit (disease),allerg (allergenic), chronisch,hauterkrank (illness of skin), arzt(doctor), erkrank (ill)FRENCH '02:TOPIC 107 NL Ing?nierie g?n?tiqueGenetischeManipulatieGeneticEngineering 0.145 0.357d?velopp (developed), ?volu(evolved), product, produit(product), mol?culair (molecular)genetic, gen, engineering, d?velopp,productFRENCH '06:TOPIC 256 ENMaladie deCreutzfeldt -Jakob Creutzfeldt -JakobCreutzfeldt -Jakob Disease 0.507 0.688malad (illness), produit (product),animal (animal), hormon(hormone)malad, humain (human), bovin(bovine), enc?phalopath (sufferingfrom encephalitis), scientif, recherch(research)GERMAN '03:TOPIC 157 ENSiegerinnen vonWimbledonChampions ofWimbledonWimbledonLady Winners 0.074 0.146telefonbuch (phone book), sieg(victory), titelseit (front page),telekom (telecommunication),grafgross (large), verfecht (champion),sampra (sampras), 6, champion,steffi, verteidigt (defendending),martina, jovotna , navratilovaGERMAN '01:TOPIC 91 ES AI in LateinamerikaLa gripe aviar enAm?rica LatinaAI in LatinAmerica 0.456 0.098international, amnesty,strassenkind (street child),kolumbi (Columbian), land, brasili(Brazil), menschenrecht (humanrights), polizei (police)karib (Caribbean), land, brasili,schuld (blame), amerika, kalt (cold),welt (world), forschung (research)GERMAN '03:TOPIC 196 ENFusion japanischerBankenFusion of JapanesebanksMerger ofJapanese Banks 0.572 0.264daiwa, tokyo, filial (branch),zusammenschluss (merger)kernfusion (nuclear fusion),zentralbank (central bank), daiwa,weltbank (world bank),investitionsbank (investment bank)FRENCH '03:TOPIC 152 NL Les droits de l'enfantDe rechten van hetkind Child Rights 0.479 0.284convent (convention), franc,international, onun (unitednations), r?serv (reserve)per (father), convent, franc, jurid(legal), homm (man), cour (court),biologTable 5: Qualitative comparison of feedback terms given by MultiPRF and MBF on representative queries where positive andnegative results were observed in French and German collections.quite strongly with a MAP score of 0.507.
Al-though there is no significant topic drift in thiscase, there are not many relevant terms apart fromthe query terms.
However the same query per-forms very well in English with all the documentsin the feedback set of the English corpus being rel-evant, thus resulting in informative feedback termssuch as {bovin, scientif, recherch}.
(b) FindingSynonyms/Morphological Variations: Another sit-uation in which MultiPRF leads to large improve-ments is when it finds semantically/lexically re-lated terms to the query terms which the origi-nal feedback model was unable to.
For example,consider the French query ?Inge?nierie g?n?tique?.While the feedback model was unable to findany of the synonyms of the query terms, due totheir lack of co-occurence with the query terms,the MultiPRF model was able to get these terms,which are introduced primarily during the back-translation process.
Thus terms like {genetic, gen,engineering}, which are synonyms of the querywords, are found thus resulting in improved per-formance.
(c) Combination of Above Factors:Sometimes a combination of the above two factorscauses improvements in the performance as in theGerman query ?O?lkatastrophein Sibirien?.
Forthis query, MultiPRF finds good feedback termssuch as {russisch, russland} while also obtainingsemantically related terms such as {olverschmutz,erdol, olunfall}.Although all of the previously described exam-ples had good quality translations of the queryin the assisting language, as mentioned in (Chin-nakotla et al, 2010), the MultiPRF approach isrobust to suboptimal translation quality as well.To see how MultiPRF leads to improvements evenwith errors in query translation consider the Ger-man Query ?Siegerinnen von Wimbledon?.
Whenthis is translated to English, the term ?Lady?
isdropped, this causes only ?Wimbledon Champi-ons?
to remain.
As can be observed, this causesterms like sampras to come up in the MultiPRFmodel.
However, while the MultiPRF model hassome terms pertaining to Men?s Winners of Wim-bledon as well, the original feedback model suf-fers from severe topic drift, with irrelevant termssuch as {telefonbuch, telekom} also amongst thetop terms.
Thus we notice that despite the er-ror in query translation MultiPRF still manages tocorrect the drift of the original feedback model,while also introducing relevant terms such as{verfecht, steffi, martina, novotna, navratilova}as well.
Thus as shown in (Chinnakotla et al,2010), having a better query translation systemcan only lead to better performance.
We alsoperform a detailed error analysis and found threemain reasons for MultiPRF failing: (i) Inaccura-cies in query translation (including the presence ofout-of-vocabulary terms).
This is seen in the Ger-man Query AI in Lateinamerika, which wronglytranslates to Avian Flu in Latin America in Span-ish thus affecting performance.
(ii) Poor retrievalin Assisting Language.
Consider the French queryLes droits de l?enfant, for which due to topic driftin English, MultiPRF performance reduces.
(iii)In a few rare cases inaccuracy in the back transla-1351(a) Source:French (FR-01+02) Assist:Spanish (b) Source:German (DE-01+02) Assist:Dutch(c) Source:Finnish (FI-02+03+04) Assist:EnglishFigure 2: Results showing the sensitivity of MultiPRF performance to parameters ?
and ?
for French, German and Finnish.tion affects performance as well.6.1 Parameter Sensitivity AnalysisThe MultiPRF parameters ?
and ?
in Equation2 control the relative importance assigned to theoriginal feedback model in source language L1,the translated feedback model obtained from as-sisting language L2 and the original query terms.We varied the ?
and ?
parameters for French, Ger-man and Finnish collections with English, Dutchand Spanish as assisting languages and studied itseffect on MAP of MultiPRF.
The results are shownin Figure 2.
The results show that, in all the threecollections, the optimal value of the parametersalmost remains the same and lies in the range of0.4-0.48.
Due to the above reason, we arbitrarilychoose the parameters in the above range and donot use any technique to learn these parameters.6.2 Effect of Assisting Language ChoiceIn this section, we discuss the effect of varyingthe assisting language.
Besides, we also studythe inter and intra familial behaviour of source-assisting language pairs.
In order to ensure thatthe results are comparable across languages, weindexed the collections from the years 2002, 2003and use common topics from the topic range 91-200 that have relevant documents across all the sixlanguages.
The number of such common topicswere 67.
For each source language, we use theother languages as assisting collections and studythe performance of MultiPRF.
Since query trans-lation quality varies across language pairs, we an-alyze the behaviour of MultiPRF in the followingtwo scenarios: (a) Using ideal query translation(b) Using Google Translate for query translation.In ideal query translation setup, in order to elim-inate its effect, we skip the query translation stepand use the corresponding original topics for eachtarget language instead.
The results for both theabove scenarios are given in Tables 6 and 7.From the results, we firstly observe that besidesEnglish, other languages such as French, Spanish,German and Dutch act as good assisting languagesand help in improving performance over mono-lingual MBF.
We also observe that the best as-sisting language varies with the source language.However, the crucial factors of the assisting lan-guage which influence the performance of Multi-PRF are: (a) Monolingual PRF Performance: Themain motivation for using a different language wasto get good feedback terms, especially in case ofqueries which fail in the source language.
Hence,an assisting language in which the monolingualfeedback performance itself is poor, is unlikelyto give any performance gains.
This observationis evident in case of Finnish, which has the low-est Monolingual MBF performance.
The resultsshow that Finnish is the least helpful of assist-ing languages, with performance similar to thoseof the baselines.
We also observe that the threebest performing assistant languages, i.e.
English,French and Spanish, have the highest monolingualperformances as well, thus further validating theclaim.
One possible reason for this is the relative1352SourceLang.Assisting Language SourceLang.MBF English German Dutch Spanish French FinnishEnglishMAP-0.4464 ( -0.7%) 0.4471 (-0.5%) 0.4566 (+1.6%) 0.4563 (+1.5%) 0.4545 (+1.1%) 0.4495P@5 0.4925 ( -0.6%) 0.5045 (+1.8%) 0.5164 (+4.2%) 0.5075 (+2.4%) 0.5194 (+4.8%) 0.4955P@10 0.4343 (+0.4%) 0.4373 (+1.0%) 0.4537 (+4.8%) 0.4343 (+0.4%) 0.4373 (+1.0%) 0.4328GermanMAP 0.4229 (+4.9%)-0.4346 (+7.8%) 0.4314 (+7.0%) 0.411 (+1.9%) 0.3863 ( -4.2%) 0.4033P@5 0.5851 (+14%) 0.5851 (+14%) 0.5791 (+12.8%) 0.594 (+15.7%) 0.5522 (+7.6%) 0.5134P@10 0.5284 (+11.3%) 0.5209 (+9.8%) 0.5179 (+9.1%) 0.5149 (+8.5%) 0.5075 (+6.9%) 0.4746DutchMAP 0.4317 (+4%) 0.4453 (+7.2%)-0.4275 (+2.9%) 0.4241 (+2.1%) 0.3971 ( -4.4%) 0.4153P@5 0.5642 (+11.8%) 0.5731 (+13.6%) 0.5343 (+5.9%) 0.5582 (+10.6%) 0.5045 (0%) 0.5045P @10 0.5075 (+9%) 0.4925 (+5.8%) 0.4896 (+5.1%) 0.5015 (+7.7%) 0.4806 (+3.2%) 0.4657Spanish MAP 0.4667 ( -2.9%) 0.4749 ( -1.2%) 0.4744 (-1.3%)-0.4609 ( -4.1%)0.4311 ( -10.3%) 0.4805P@5 0.62 ( -2.9%) 0.6418 (+0.5%) 0.6299 (-1.4%) 0.6269 ( -1.6%) 0.6149 ( -3.7%) 0.6388P@10 0.5625 ( -1.8%) 0.5806 (+1.3%) 0.5851 (+2.1%) 0.5627 ( -1.8%) 0.5478 ( -4.4%) 0.5731FrenchMAP 0.4658 (+6.9%) 0.4526 (+3.9%) 0.4374 (+0.4%) 0.4634 (+6.4%)-0.4451 (+2.2%) 0.4356P@5 0.4925 (+3.1%) 0.4806  (+0.6%) 0.4567 (-4.4%) 0.4925 (+3.1%) 0.4836 (+1.3%) 0.4776P@10 0.4358 (+3.9%) 0.4239 (+1%) 0.4224 (+0.7%) 0.4388 (+4.6%) 0.4209 (+0.4%) 0.4194FinnishMAP 0.3411 ( -4.7%) 0.3796 (+6.1%) 0.3722 (+4%) 0.369 (+3.1%) 0.3553 ( -0.7%)-0.3578P@5 0.394 (+3.1%) 0.403 (+5.5%) 0.406 (+6.3%) 0.4119 (+7.8%) 0.397 (+3.9%) 0.3821P@10 0.3463 (+11.5%) 0.3582 (+15.4%) 0.3478 (+12%) 0.3448 (+11%) 0.3433 (+10.6%) 0.3105Table 6: Results showing the performance of MultiPRF with different source and assisting languages using Google Translatefor query translation step.
The intra-familial affinity could be observed from the elements close to the diagonal.ease of processing in these languages.
(b) FamilialSimilarity Between Languages: We observe thatthe performance of MultiPRF is good if the as-sisting language is from the same language fam-ily.
Birch et al (2008) show that the languagefamily is a strong predictor of machine transla-tion performance.
Hence, the query translationand back translation quality improves if the sourceand assisting languages belong to the same family.For example, in the Germanic family, the source-assisting language pairs German-English, Dutch-English, Dutch-German and German-Dutch showgood performance.
Similarly, in Romance family,the performance of French-Spanish confirms thisbehaviour.
In some cases, we observe that Multi-PRF scores decent improvements even when theassisting language does not belong to the samelanguage family as witnessed in French-Englishand English-French.
This is primarily due to theirstrong monolingual MBF performance.6.3 Effect of Language Family on BackTranslation PerformanceAs already mentioned, the performance of Multi-PRF is good if the source and assisting languagesbelong to the same family.
In this section, we ver-ify the above intuition by studying the impact oflanguage family on back translation performance.The experiment designed is as follows: Given aquery in source language L1, the ideal translationin assisting language L2 is used to compute thequery model in L2 using only the query terms.Then, without performing PRF the query modelSourceLang.Assisting LanguageM BF MPRFFR ES DE NL EN FIFrench - 0.3686 0.3113 0.3366 0.4338 0.3011 0.4342 0.4535Spanish 0.3647 - 0.3440 0.3476 0.3954 0.3036 0.5000 0.4892German 0.2729 0.2736 - 0.2951 0.2107 0.2266 0.4229 0.4576Dutch 0.2663 0.2836 0.2902 - 0.2757 0.2372 0.3968 0.3989Table 8: Effect of Language Family on Back TranslationPerformance measured through MultiPRF MAP.
100 Topicsfrom years 2001 and 2002 were used for all languages.is directly back translated from L2 into L1 andfinally documents are re-ranked using this trans-lated feedback model.
Since the automatic querytranslation and PRF steps have been eliminated,the only factor which influences the MultiPRF per-formance is the back-translation step.
This meansthat the source-assisting language pairs for whichthe back-translation is good will score a higherperformance.
The results of the above experimentis shown in Table 8.
For each source language,the best performing assisting languages have beenhighlighted.The results show that the performance ofclosely related languages like French-Spanish andGerman-Dutch is more when compared to othersource-assistant language pairs.
This shows thatin case of closely related languages, the back-translation step succeeds in adding good termswhich are relevant like morphological variants,synonyms and other semantically related terms.Hence, familial closeness of the assisting languagehelps in boosting the MultiPRF performance.
Anexception to this trend is English as assisting lan-1353SourceLang.Assisting Language SourceLang.MBF English German Dutch Spanish French FinnishEnglishMAP-0.4513 (+0.4%) 0.4475 ( -0.4%) 0.4695 (+4.5%) 0.4665 (+3.8%) 0.4416 ( -1.7%) 0.4495P @5 0.5104 (+3.0%) 0.5104 (+3.0%) 0.5343 (+7.8%) 0.5403 (+9.0%) 0.4806 ( -3.0%) 0.4955P@10 0.4373 (+1.0%) 0.4358 (+0.7%) 0.4597 (+6.2%) 0.4582 (+5.9%) 0.4164 ( -3.8%) 0.4328GermanMAP 0.4427 (+9.8%)-0.4306 (+6.8%) 0.4404 (+9.2%) 0.4104 (+1.8%) 0.3993 ( -1.0%) 0.4033P@5 0.606 (+18%) 0.5672 (+10.5%) 0.594 (+15.7%) 0.5761 (+12.2%) 0.5552 (+8.1%) 0.5134P @10 0.5373 (+13.2%) 0.503 (+6.0%) 0.5299 (+11.7%) 0.494 (+4.1%) 0.5 (+5.4%) 0.4746DutchMAP 0.4361 (+5.0%) 0.4344 (+4.6%)-0.4227 (+1.8%) 0.4304 (+3.6%) 0.4134 ( -0.5%) 0.4153P@5 0.5761 (+14.2%) 0.5552 (+10%) 0.5403 (+7.1%) 0.5463 (+8.3%) 0.5433 (+7.7%) 0.5045P @10 0.5254 (+12.8%) 0.497 (+6.7%) 0.4776 (+2.6%) 0.5134 (+10.2%) 0.4925 (+5.8%) 0.4657SpanishMAP 0.4665 ( -2.9%) 0.4773 ( -0.7%) 0.4733 ( -1.5%)-0.4839 (+0.7%) 0.4412 ( -8.2%) 0.4805P@5 0.6507 (+1.8%) 0.6448 (+0.9%) 0.6507 (+1.8%) 0.6478 (+1.4%) 0.597 ( -6.5%) 0.6388P@10 0.5791 (+1.0%) 0.5791 (+1.0%) 0.5761 (+0.5%) 0.5866 (+2.4%) 0.5567 ( -2.9%) 0.5731FrenchMAP 0.4591 (+5.4%) 0.4514 (+3.6%) 0.4409 (+1.2%) 0.4712 (+8.2%)-0.4354 (0%) 0.4356P@5 0.4925 (+3.1%) 0.4776 (0%) 0.4776 (0%) 0.4995 (+4.6%) 0.4955 (+3.8%) 0.4776P @10 0.4463 (+6.4%) 0.4313 (+2.8%) 0.4373 (+4.3%) 0.4448 (+6.1%) 0.4209 (+0.3%) 0.4194FinnishMAP 0.3733 (+4.3%) 0.3559 ( -0.5%) 0.3676 (+2.7%) 0.3594 (+0.4%) 0.371 (+3.7%)-0.3578P@5 0.4149 (+8.6%) 0.385 (+0.7%) 0.388 (+1.6%) 0.388 (+1.6%) 0.3911 (+2.4%) 0.3821P@10 0.3567 (+14.9%) 0.31 ( -0.2%) 0.3253 (+4.8%) 0.32 (+3.1%) 0.3239 (+4.3%) 0.3105Table 7: Results showing the performance of MultiPRF without using automatic query translation i.e.
by using correspondingoriginal queries in assisting collection.
The results show the potential of MultiPRF by establishing a performance upper bound.guage which shows good performance across bothfamilies.6.4 Multiple Assisting LanguagesSo far, we have only considered a single assist-ing language.
However, a natural extension tothe method which comes to mind, is using mul-tiple assisting languages.
In other words, com-bining the evidence from all the feedback mod-els of more than one assisting language, to get afeedback model which is better than that obtainedusing a single assisting language.
To check howthis simple extension works, we performed exper-iments using a pair of assisting languages.
In theseexperiments for a given source language (fromamongst the 6 previously mentioned languages)we tried using all pairs of assisting languages (foreach source language, we have 10 pairs possible).To obtain the final model, we simply interpolate allthe feedback models with the initial query model,in a similar manner as done in MultiPRF.
The re-sults for these experiments are given in Table 9.As we see, out of the 60 possible combinationsof source language and assisting language pairs,we obtain improvements of greater than 3% in 16cases.
Here the improvements are with respect tothe best model amongst the two MultiPRF mod-els corresponding to each of the two assisting lan-guages, with the same source language.
Thus weobserve that a simple linear interpolation of mod-els is not the best way of combining evidence frommultiple assisting languages.
We also observe thanwhen German or Spanish are used as one of thetwo assisting languages, they are most likely toSourceLanguageAssisting Language Pairs withImprovement > 3%English FR-DE (4.5%),  FR -ES (4.8%), DE-NL (+3.1%)French EN-DE (4.1%), DE -ES (3.4%), NL-FI (4.8 %)German NoneSpanish NoneDutchEN-DE (3.9%), DE -FR (4.1%), FR -ES (3.8%), DE-ES(3.9%)FinnishEN-ES (3.2%), FR -DE (4.6%), FR -ES (6.4%),DE-ES (11.2%), DE -NL (4.4%), ES -NL (5.9%)Total - 16EN ?
3 Pairs; FR ?
6 Pairs; DE ?
10 Pairs;ES - 8 Pairs; NL ?
4 Pairs; FI ?
1 PairTable 9: Summary of MultiPRF Results with Two AssistingLanguages.
The improvements described above are with re-spect to maximum MultiPRF MAP obtained using either L1or L2 alone as assisting language.lead to improvements.
A more detailed study ofthis observation needs to be done to explain this.7 Conclusion and Future WorkWe studied the effect of different source-assistantpairs and multiple assisting languages on the per-formance of MultiPRF.
Experiments across a widerange of language pairs with varied degree of fa-milial relationships show that MultiPRF improvesperformance in most cases with the performanceimprovement being more pronounced when thesource and assisting languages are closely related.We also notice that the results are mixed when twoassisting languages are used simultaneously.
Aspart of future work, we plan to vary the modelinterpolation parameters dynamically to improvethe performance in case of multiple assisting lan-guages.AcknowledgementsThe first author was supported by a fellowshipaward from Infosys Technologies Ltd., India.
Wewould like to thank Mr. Vishal Vachhani for hishelp in running the experiments.1354ReferencesGiambattista Amati, Claudio Carpineto, and Giovanni Ro-mano.
2004.
Query Difficulty, Robustness, and Selec-tive Application of Query Expansion.
In ECIR ?04, pages127?137.Alexandra Birch, Miles Osborne and Philipp Koehn.
2008.Predicting Success in Machine Translation.
In EMNLP?08, pages 745-754, ACL.Martin Braschler and Carol Peters.
2004.
Cross-LanguageEvaluation Forum: Objectives, Results, Achievements.Inf.
Retr., 7(1-2):7?31.Martin Braschler and Peter Scha?uble.
1998.
Multilingual In-formation Retrieval based on Document Alignment Tech-niques.
In ECDL ?98, pages 183?197, Springer-Verlag.Chris Buckley, Gerald Salton, James Allan, and Amit Sing-hal.
1994.
Automatic Query Expansion using SMART :TREC 3.
In TREC-3, pages 69?80.Guihong Cao, Jian-Yun Nie, Jianfeng Gao, and StephenRobertson.
2008.
Selecting Good Expansion Terms forPseudo-Relevance Feedback.
In SIGIR ?08, pages 243?250.
ACM.Manoj K. Chinnakotla, Karthik Raman, and Pushpak Bhat-tacharyya.
2010.
Multilingual PRF: English Lends aHelping Hand.
In SIGIR ?10, ACM.Kevyn Collins-Thompson and Jamie Callan.
2005.
QueryExpansion Using Random Walk Models.
In CIKM ?05,pages 704?711.
ACM.Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft.2004.
A Framework for Selective Query Expansion.
InCIKM ?04, pages 236?237.
ACM.Ido Dagan, Alon Itai, and Ulrike Schwall.
1991.
Two Lan-guages Are More Informative Than One.
In ACL ?91,pages 130?137.
ACL.A.
Dempster, N. Laird, and D. Rubin.
1977.
Maximum Like-lihood from Incomplete Data via the EM Algorithm.
Jour-nal of the Royal Statistical Society, 39:1?38.T.
Susan Dumais, A. Todd Letsche, L. Michael Littman, andK.
Thomas Landauer.
1997.
Automatic Cross-LanguageRetrieval Using Latent Semantic Indexing.
In AAAI ?97,pages 18?24.Wei Gao, John Blitzer, and Ming Zhou.
2008.
Using EnglishInformation in Non-English Web Search.
In iNEWS ?08,pages 17?24.
ACM.David Hawking, Paul Thistlewaite, and Donna Harman.1999.
Scaling Up the TREC Collection.
Inf.
Retr., 1(1-2):115?137.Hieu Hoang, Alexandra Birch, Chris Callison-burch, RichardZens, Rwth Aachen, Alexandra Constantin, Marcello Fed-erico, Nicola Bertoldi, Chris Dyer, Brooke Cowan, WadeShen, Christine Moran, and Ondej Bojar.
2007.
Moses:Open Source Toolkit for Statistical Machine Translation.In ACL ?07, pages 177?180.P.
Jourlin, S. E. Johnson, K. Spa?rck Jones and P. C. Wood-land.
1999.
Improving Retrieval on Imperfect SpeechTranscriptions (Poster Abstract).
In SIGIR ?99, pages283?284.
ACM.John Lafferty and Chengxiang Zhai.
2003.
Probabilistic Rel-evance Models Based on Document and Query Genera-tion.
Language Modeling for Information Retrieval, pages1?10.
Kluwer International Series on IR.K.
Sparck Jones, S. Walker, and S. E. Robertson.
2000.
AProbabilistic Model of Information Retrieval: Develop-ment and Comparative Experiments.
Inf.
Process.
Man-age., 36(6):779?808.John Lafferty and Chengxiang Zhai.
2001.
Document Lan-guage Models, Query Models, and Risk Minimization forInformation Retrieval.
In SIGIR ?01, pages 111?119.ACM.Victor Lavrenko and W. Bruce Croft.
2001.
Relevance BasedLanguage Models.
In SIGIR ?01, pages 120?127.
ACM.Victor Lavrenko, Martin Choquette, and W. Bruce Croft.2002.
Cross-Lingual Relevance Models.
In SIGIR ?02,pages 175?182, ACM.Edgar Meij, Dolf Trieschnigg, Maarten Rijke de, and WesselKraaij.
2009.
Conceptual Language Models for Domain-specific Retrieval.
Information Processing & Manage-ment, 2009.Donald Metzler and W. Bruce Croft.
2007.
Latent ConceptExpansion Using Markov Random Fields.
In SIGIR ?07,pages 311?318.
ACM.Mandar Mitra, Amit Singhal, and Chris Buckley.
1998.
Im-proving Automatic Query Expansion.
In SIGIR ?98, pages206?214.
ACM.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical Alignment Models.Computational Linguistics, 29(1):19?51.I.
Ounis, G. Amati, Plachouras V., B.
He, C. Macdonald, andJohnson.
2005.
Terrier Information Retrieval Platform.In ECIR ?05, volume 3408 of Lecture Notes in ComputerScience, pages 517?519.
Springer.Koehn Philipp.
2005.
Europarl: A Parallel Corpus for Statis-tical Machine Translation.
In MT Summit ?05.Stephen Robertson.
2006.
On GMAP: and Other Transfor-mations.
In CIKM ?06, pages 78?83.
ACM.Tetsuya Sakai, Toshihiko Manabe, and Makoto Koyama.2005.
Flexible Pseudo-Relevance Feedback Via SelectiveSampling.
ACM TALIP, 4(2):111?135.Tao Tao and ChengXiang Zhai.
2006.
Regularized Esti-mation of Mixture Models for Robust Pseudo-RelevanceFeedback.
In SIGIR ?06, pages 162?169.
ACM.Tuomas Talvensaari, Jorma Laurikkala, Kalervo Ja?rvelin,Martti Juhola, and Heikki Keskustalo.
2007.
Creating andExploiting a Comparable Corpus in Cross-language Infor-mation Retrieval.
ACM Trans.
Inf.
Syst., 25(1):4, 2007.Jrg Tiedemann.
2001.
The Use of Parallel Corpora in Mono-lingual Lexicography - How word alignment can identifymorphological and semantic relations.
In COMPLEX ?01,pages 143?151.Ellen M. Voorhees.
1994.
Query Expansion Using Lexical-Semantic Relations.
In SIGIR ?94, pages 61?69.
Springer-Verlag.1355Ellen Voorhees.
2006.
Overview of the TREC 2005 RobustRetrieval Track.
In TREC 2005, Gaithersburg, MD.
NIST.Dan Wu, Daqing He, Heng Ji, and Ralph Grishman.
2008.A Study of Using an Out-of-Box Commercial MT Systemfor Query Translation in CLIR.
In iNEWS ?08, pages 71?76.
ACM.Jinxi Xu and W. Bruce Croft.
2000.
Improving the Effective-ness of Information Retrieval with Local Context Analy-sis.
ACM Trans.
Inf.
Syst., 18(1):79?112.Jinxi Xu, Alexander Fraser, and Ralph Weischedel.
2002.Empirical Studies in Strategies for Arabic Retrieval.
InSIGIR ?02, pages 269?274.
ACM.Yang Xu, Gareth J.F.
Jones, and Bin Wang.
2009.Query Dependent Pseudo-Relevance Feedback Based onWikipedia.
In SIGIR ?09, pages 59?66.
ACM.Chengxiang Zhai and John Lafferty.
2001.
Model-basedFeedback in the Language Modeling approach to Infor-mation Retrieval.
In CIKM ?01, pages 403?410.
ACM.Chengxiang Zhai and John Lafferty.
2004.
A Study ofSmoothing Methods for Language Models applied to In-formation Retrieval.
ACM Transactions on InformationSystems, 22(2):179?214.1356
