Proceedings of the ACL 2014 Student Research Workshop, pages 86?93,Baltimore, Maryland USA, June 22-27 2014. c?2014 Association for Computational LinguisticsImproving Text Normalization via Unsupervised Model andDiscriminative RerankingChen Li and Yang LiuThe University of Texas at DallasComputer Science Departmentchenli,yangl@hlt.utdallas.eduAbstractVarious models have been developed fornormalizing informal text.
In this paper,we propose two methods to improve nor-malization performance.
First is an unsu-pervised approach that automatically iden-tifies pairs of a non-standard token andproper word from a large unlabeled cor-pus.
We use semantic similarity based oncontinuous word vector representation, to-gether with other surface similarity mea-surement.
Second we propose a rerankingstrategy to combine the results from differ-ent systems.
This allows us to incorporateinformation that is hard to model in indi-vidual systems as well as consider multi-ple systems to generate a final rank for atest case.
Both word- and sentence-leveloptimization schemes are explored in thisstudy.
We evaluate our approach on datasets used in prior studies, and demonstratethat our proposed methods perform betterthan the state-of-the-art systems.1 IntroductionThere has been a lot of research efforts recentlyon analysis of social media text (e.g., from Twit-ter and Facebook) (Ritter et al., 2011; Owoputi etal., 2013; Liu et al., 2012b).
One challenge inprocessing social media text is how to deal withthe frequently occurring non-standard words, suchas bday (meaning birthday), snd (meaning sound)and gl (meaning girl) .
Normalizing informal text(changing non-standard words to standard ones)will ease subsequent language processing mod-ules.Text normalization has been an important topicfor the text-to-speech field.
See (Sproat et al.,2001) for a good report of this problem.
Recently,much research on normalization has been donefor social text domain, which has many abbrevi-ations or non-standard tokens.
A simple approachfor normalization would be applying traditionalspell checking model, which is usually based onedit distance (Damerau, 1964; Levenshtein, 1966).However, this model can not well handle the non-standard words in social media text due to the largevariation in generating them.Another line of work in normalization adoptsa noisy channel model.
For a non-standard to-ken A, this method finds the most possible stan-dard word ?S based on the Bayes rule: ?S =argmaxP (S|A) = argmaxP (A|S) ?
P (S).Different methods have been used to computeP (A|S).
Pennell and Liu (2010) used a CRF se-quence modeling approach for deletion-based ab-breviations.
Liu et al.
(2011) further extended thiswork by considering more types of non-standardwords without explicit pre-categorization for non-standard tokens.In addition, the noisy channel model has alsobeen utilized on the sentence level.
Choudhury etal.
(2007) used a hidden Markov model to sim-ulate SMS message generation, considering thenon-standard tokens in the input sentence as emis-sion states in HMM and labeling results as pos-sible candidates.
Cook and Stevenson (2009) ex-tended work by adding several more subsystemsin this error model according to the most commonnon-standard token?s formation process.Machine translation (MT) is another commonlychosen method for text normalization.
It is alsoused on both the token and the sentence level.
Awet al.
(2006) treated SMS as another language, andused MT methods to translate this ?foreign lan-guage?
to regular English.
Contractor et al.
(2010)used an MT model as well but the focus of theirwork is to utilize an unsupervised method to cleannoisy text.
Pennell and Liu (2011) firstly intro-duced an MT method at the token level whichtranslates an unnormalized token to a possible cor-86rect word.Recently, a new line of work surges relying onthe analysis of huge amount of twitter data, of-ten in an unsupervised fashion.
By using con-text information from a large corpus, Han et al.
(2012) generated possible variant and normaliza-tion pairs, and constructed a dictionary of lexicalvariants of known words, which are further rankedby string similarity.
This dictionary can facilitatelexical normalization via simple string substitu-tion.
Hassan and Menezes (2013) proposed an ap-proach based on the random walk algorithm on acontextual similarity bipartite graph, constructedfrom n-gram sequences on a large unlabeled textcorpus.
Yang and Eisenstein (2013) presented aunified unsupervised statistical model for text nor-malization.2 Previous Normalization Methods Usedin RerankingIn this work we adopt several normalization meth-ods developed in previous studies.
The followingbriefly describes these previous approaches.
Nextsection will introduce our proposed methods usingunsupervised learning and discriminative rerank-ing for system combination.2.1 Character-block level MTPennell and Liu (2011) proposed to use acharacter-level MT model for text normalization.The idea is similar to traditional translation,except that the translation unit is characters,not words.
Formally, for a non-standard wordA = a1a2...an, the MT method finds themost likely standard word S = s1s2...sm(aiand siare the characters in the words): S =argmaxP (S|A) = argmaxP (A|S)P (S) =argmaxP (a1a2...an|s1s2...sm)P (s1s2...sm)where P (a1a2...an|s1s2...sm) is from a character-level translation model, and P (s1s2...sm) is froma character-level language model.
(Li and Liu,2012a) modified this approach to perform thetranslation at the character-block level in orderto generate better alignment between characters(analogous to the word vs. phrase based alignmentin traditional MT).
This system generates oneranked list of word candidates.2.2 Character-level Two-step MTLi and Liu (2012b) extended the character-levelMT model by incorporating the pronunciation in-formation.
They first translate non-standard wordsto possible pronunciations, which are then trans-lated to standard words in the second step.
Thismethod has been shown to yield high coverage(high accuracy in its n-best hypotheses).
There aretwo candidate lists generated by this two-step MTmethod.
The first one is based on the pronuncia-tion list produced in the first step (some phoneticsequences directly correspond to standard words).The second list is generated from the second trans-lation step.2.3 Character-Block level Sequence LabelingPennell and Liu (2010) used sequence labelingmodel (CRF) for normalizing deletion-based ab-breviation at the character-level.
The model labelsevery character in a standard word as ?Y?
or ?N?to represent whether it appears or not in a possibleabbreviation token.
The features used for the clas-sification task represent the character?s position,pronunciation and context information.
Using thesequence labeling model, a standard word cangenerate many possible non-standard words.
A re-verse look-up table is used to store the correspond-ing possible standard words for the non-standardwords for reverse lookup during testing.
Liu et al.
(2011) extended the above model to handle othertypes of non-standard words.
(Li and Liu, 2012a)used character-blocks (same ones as that in thecharacter-block MT method above) as the units inthis sequence labeling framework.
There is onelist of word candidates from this method.2.4 Spell CheckerThe forth normalization subsystem is the JazzySpell Checker1, which is based on edit distanceand integrates a phonetic matching algorithm aswell.
This provides one list of hypotheses.3 Proposed MethodAll the above models except the Spell Checker aresupervised methods that need labeled data con-sisting of pairs of non-standard words and properwords.
In this paper we propose an unsupervisedmethod to create the lookup table of the non-standard words and their corresponding properwords offline.
We further propose to use differ-ent discriminative reranking approaches to com-bine multiple individual systems.1http://jazzy.sourceforge.net873.1 Unsupervised Corpus-based Similarityfor NormalizationPrevious work has shown that unlabeled text canbe used to induce unsupervised word clustersthat can improve performance of many supervisedNLP tasks (Koo et al., 2008; Turian et al., 2010;Ta?ckstro?m et al., 2012).
We investigate using alarge unlabeled Twitter corpus to automaticallyidentify pairs of non-standard words and their cor-responding standard words.We use the Edinburgh Twitter corpus (Petro-vic et al., 2010), and a dictionary obtainedfrom http://ciba.iciba.com/ to identify all the in-vocabulary and out-of-vocabulary (OOV) words inthe corpus.
The task is then to automatically findthe corresponding OOV words (if any) for eachdictionary word, and the likelihood of each pair.The key question is how to compute this likelihoodor similarity.We propose to use an unsupervised methodbased on the large corpus to induce dense real-valued low-dimension word embedding and thenuse the inner product as a measure of semanticsimilarity.
We use the continuous bag-of-wordsmodel that is similar to the feedforward neuralnetwork language model to compute vector rep-resentations of words.
This model was first in-troduced by (Mikolov et al., 2013).
We use thetool word2vec2 to implement this model.
Twoconstraints are used in order to eliminate unlikelyword pairs: (I) OOV words need to begin with thesame letter as the dictionary standard word; (II)OOV words can only consist of English letter anddigits.In addition to considering the above semanticsimilarity, for the normalization task, we use otherinformation including the surface character levelsimilarity based on longest common sequence be-tween the two tokens, and the frequency of the to-ken.
The final score between a dictionary word wand an OOV word t is:sim(w, t) =longest common string(w, t)length(t)?
log(TermFreq(t))?
inner product(vec(w), vec(t))?longest common seq(w, t)length(t)(1)The first and second term share the same propertyof visual prime value used in (Liu et al., 2012a).2https://code.google.com/p/word2vec/The third term is the vector-based semantic simi-larity of the two words, calculated by our proposedmodel.
The last term is the length of longest com-mon sequence between the two words divided bythe length of the OOV word.Using this method, we can identify all the pos-sible OOV words for each dictionary word basedon an unlabeled large corpus.
Each pair has asimilarity score.
Then a reverse lookup table iscreated to store the corresponding possible stan-dard words for each non-standard word, which isused during testing.
This framework is similar tothe sequence labeling method described in Sec-tion 2.3 in the sense of creating the mapping ta-ble between the OOV and dictionary words.
How-ever, the difference is that this is an unsupervisedmethod whereas the sequence labeling uses super-vised learning to generate possible candidates.3.2 Reranking for System Combination3.2.1 Word Level RerankingEach of the above systems has its own strength andweakness.
The MT model and the sequence la-beling models have better precision, the two-stepMT model has a broader coverage of candidates,and the spell checker has a high confidence forsimple non-standard words.
Therefore combiningthese systems is expected to yield better overallresults.
We propose to use a supervised maximumentropy reranking model to combine our proposedunsupervised method with those described in Sec-tion 2 (4 systems that have 5 candidate lists).
Thefeatures we used in the normalization rerankingmodel are shown in Table 1.
This maxent rerank-ing method has shown success in many previouswork such as (Charniak and Johnson, 2005; Ji etal., 2006).Features:1.Boolean value to indicate whether a candidate is on thelist of each system.
There are 6 lists and thus 6 such fea-tures.2.A concatenation of the 6 boolean features above.3.The position of this candidate in each candidate list.
Ifthis candidate is not on a list, the value of this feature is -1for that list.4.The unigram language model probability of the candi-date.5.Boolean value to indicate whether the first character ofthe candidate and non-standard word is the same.6.Boolean value to indicate whether the last character ofthe candidate and non-standard word is the same.Table 1: Features for Reranking.The first three features are related to the indi-88vidual systems, and the last three features com-pare the candidate with the non-standard word.
Itis computationally expensive to include informa-tion represented in the last three features in the in-dividual systems since they need to consider morecandidates in the normalization step; whereas inreranking, only a small set of word candidatesare evaluated, thus it is more feasible to use suchglobal features in the reranking model.
We alsotried some other lexical features such as the lengthdifference of the non-standard word and the can-didate, whether non-standard word contains num-bers, etc.
But they did not obtain performancegain.
Another advantage of the reranker is that wecan use information about multiple systems, suchas the first three features.3.2.2 Sentence Level Reranking andDecodingIn the above reranking method, we only use infor-mation about the individual words.
When contex-tual words are available (in sentences or Tweets),we can use that information.
If a sentence con-taining OOV words is given during testing, wecan perform standard sentence level Viterbi decod-ing to combine information from the normaliza-tion candidates and language model scores.Furthermore, if sentences are available duringtraining (not just isolated word pairs as used in allthe previous supervised individual systems and theMaxent reranking above), we can also use contex-tual information for training the reranker.
This canbe achieved in two different ways.
First, we addthe Language Model score from context words asfeatures in the reranker.
In this work, in addition tothe features in Table 1, we add a trigram probabil-ity to represent the context information.
For everycandidate of a non-standard word, we use trigramprobability from the language model.
The trigramconsists of this candidate, and the previous and thefollowing token of the non-standard word.
If theprevious/following word is also a non-standard to-ken, then we calculate the trigram using all of theircandidates and then take the average.
After addingthe additional LM probability feature, the sameMaxent reranking method as above is used, whichoptimizes the word level accuracy.The second method is to change the training ob-jective and perform the optimization at the sen-tence level.
The feature set can be the same as theword level reranker, or with the additional contex-tual LM score features.
To train the model (featureweights), we perform sentence level Viterbi de-coding on the training set to find the best hypoth-esis for each non-standard word.
If the hypothe-sis is incorrect, we update the feature weight us-ing structured perceptron strategy (Collins, 2002).We will explore these different feature and train-ing configurations for reranking in the followingexperiments.4 Experiments4.1 Experimental SetupThe following data sets are used in our experi-ments.
We use Data 1 and Data 2 as test data, andData 3 as training data for all the supervised mod-els.?
Data 1: 558 pairs of non-standard tokens andstandard words collected from 549 tweets in2010 by (Han and Baldwin, 2011).?
Data 2: 3,962 pairs of non-standard tokensand standard words collected from 6,160tweets between 2009 and 2010 by (Liu et al.,2011).?
Data 3: 2,333 unique pairs of non-standardtokens and standard words, collected from2,577 Twitter messages (selected from theEdinburgh Twitter corpus) used in (Pennelland Liu, 2011).
We made some changes onthis data, removing the pairs that have morethan one proper words, and sentences thatonly contain such pairs.3?
Data 4: About 10 million twitter messagesselected from the the Edinburgh Twitter cor-pus mentioned above, consisting of 3 millionunique tokens.
This data is used by the un-supervised method to create the mapping ta-ble, and also for building the word-based lan-guage model needed in sentence level nor-malization.The dictionary we used is obtained fromhttp://ciba.iciba.com/, which includes 75,262 En-glish word entries and their corresponding pho-netic symbols (IPA symbols).
This is used in var-ious modules in the normalization systems.
Thenumber of the final standard words used to createthe look-up table is 10,105 because we only usethe words that have the same number of character-block segments and phones.
These 10,105 words3http://www.hlt.utdallas.edu/?chenli/normalization89cover 90.77% and 93.74% standard words in Dataset 1 and Data set 2 respectively.
For the non-standard words created in the CRF model, theycover 80.47% and 86.47% non-standard words inData set1 and Data set 2.
This coverage using thenon-standard words identified by the new unsuper-vised model is 91.99% and 92.32% for the twodata sets, higher than that by the CRF model.During experiments, we use CRF++ toolkit 4for our sequence labeling model, SRILM toolkit(Stolcke, 2002) to build all the language models,Giza++ (Och and Ney, 2003) for automatic wordalignment, and Moses (Koehn et al., 2007) fortranslation decoding in three MT systems.4.2 Isolated Word NormalizationExperimentsTable 2 shows the isolated word normalization re-sults on the two test data sets for various systems.The performance metrics include the accuracy forthe top-1 candidate and other top-N candidates.Coverage means how many test cases correct an-swers can be obtained in the final list regardlessof its positions.
The top part presents the resultson Data Set 1 and the bottom shows the results onData Set 2.
We can see that our proposed unsu-pervised corpus similarity model achieves bettertop-1 accuracy than the other individual systemsdescribed in Section 2.
Its top-n coverage is notalways the best ?
the 2-step MT method has advan-tages in its coverage.
The results in the table alsoshow that reranking improves system performanceover any of the used individual systems, which isexpected.
After reranking, on Data set 1, our sys-tem yields better performance than previously re-ported ones.
On Data set 2, it has better top-1 ac-curacy than (Liu et al., 2012a), but slightly worsetop-N coverage.
However, the method in (Liu etal., 2012a) has higher computational cost becauseof the calculation of the prime visual values foreach non-standard word on the fly during testing.In addition, they also used more training data thanours.4.3 Sentence Level Normalization ResultsWe have already seen that after reranking we ob-tain better word-level normalization performance,for both top-1 and other top-N candidates.
Onefollow-up question is whether this improved per-formance carries over to sentence level normaliza-4http://crfpp.googlecode.com/System Accuracy %Top1 Top3 Top10 Top20 CoverData 1MT 61.81 73.53 78.50 79.57 80.00MT21 39.61 52.93 63.59 65.36 65.72MT22 53.64 68.56 77.44 80.46 88.10SL 53.29 61.99 69.09 71.92 75.85SC 50.27 56.31 56.84 57.02 57.02UCS 61.81 69.98 74.60 76.55 82.17Rerank 77.14 86.96 93.04 94.82 95.90Sys1 75.69 n/a n/a n/a n/aSys2 73 81.9 86.7 89.2 94.2Data 2MT 55.02 63.3 66.99 67.77 68.00MT21 35.64 47.65 54.67 56.01 56.4MT22 49.02 62.49 70.99 74.86 80.07SL 46.52 55.05 61.21 62.97 66.21SC 51.16 55.48 55.88 55.88 55.88UCS 57.29 65.75 70.55 72.64 80.84Rerank 74.44 84.57 90.25 92.37 93.5Sys1 69.81 82.51 92.24 93.79 95.71Sys2 62.6 75.1 84 87.5 90.7Sys3 73.04 n/a n/a n/a n/aTable 2: MT: Character-block Level MT;MT21&MT22: First&Second step in Character-level Two-step MT; SL: Sequence Labeling sys-tem; SC: Spell Checker; UCS: Unsupervised Cor-pus Similarity Model; Sys1 is from (Liu et al.,2012a); Sys2 is from (Li and Liu, 2012a); Sys3is from (Yang and Eisenstein, 2013).tion when context information is used via the in-corporation of a language model.
Since detectingwhich tokens need normalization in the first placeis a hard task itself in social media text and is anopen question currently, similar to some previouswork, we assume that we already know the non-standard words that need to be normalized for agiven sentence.
Then the sentence-level normal-ization task is just to find which candidate fromthe n-best lists for each of those already ?detected?non-standard words is the best one.
We use thetweets in the Data set 1 described above becauseData set 2 only has token pairs but not sentences.Table 3 shows the sentence level normaliza-tion results using different reranking configura-tions with respect to the features used in thereranker and the training process.
Regarding fea-tures, reranker 1 and 3 use the features described90in Section 3.2.1, i.e., features based on the wordsonly, without the additional trigram LM probabil-ity feature; reranker 2 and 4 use the additional LMprobability feature.
About training, reranker 1 and2 use the Maxent reranking that is trained and op-timized for the word level; reranker 3 and 4 usestructure perceptron training at the sentence level.Note that all of the systems perform Viterbi decod-ing during testing to determine the final top onecandidate for each non-standard word in the sen-tence.
The scores from the reranked normalizationoutput and the LM probabilities are combined indecoding.
From the results, we can see that addingcontextual information (LM probabilities) as fea-tures in the reranker is useful.
When this featureis not used, using sentence-level training objec-tive benefits (reranker 3 outperforms 1); however,when this feature is used, performing sentence-level training via structure perceptron is not useful(reranker 2 outperforms 4), partly because the con-textual information is incorporated in the featuresalready and using it in sentence-level decoding fortraining is redundant and does not bring additionalgain.
Finally compared to the previously reportresults, our system performs the best.System Acc % System Acc %Reranker1 84.30 Reranker2 86.91Reranker3 85.03 Reranker4 85.37Sys1 84.13 Sys2 82.23Table 3: Sentence level normalization results onData Set 1 using different reranking setups.
Sys1is from (Liu et al., 2012a); Sys2 is from (Yang andEisenstein, 2013).
Acc % is the top one accuracy.4.4 Impact of Unsupervised CorpusSimilarity ModelOur last question is regarding unsupervised modelimportance in the reranking system and contribu-tions of its different similarity measure compo-nents.
We conduct the following two experiments:First, we removed the new model and just use theother remaining models in reranking (five candi-date lists).
Second, we kept this new model butchanged the corpus similarity measure (removedthe third item in Eq(1) that represents the seman-tic similarity).
This way we can evaluate the im-pact of the semantic similarity measure based onthe continuous word vector representation.Table 4 shows the word level and sentence re-sults on Data set 1 and 2 using these differentsetups.
Because of space limit, we only presentthe top one accuracy.
The other top-n resultshave similar patterns.
Sentence level normaliza-tion uses the Reranker 2 described above.
We cansee that there is a degradation in both of the newsetups, suggesting that the unsupervised methoditself is beneficial, and in particular the word vec-tor based semantic similarity component is crucialto the system performance.System Word Level Sent LevelData1 Data2 Data1system-A 73.75 70.33 84.51system-B 74.77 70.83 86.22system-C 77.14 74.44 86.91Table 4: Word level and Sentence level normaliza-tion results (top-1 accuracy in %) after rerankingon Data Set 1 and 2.
System-A is without usingthe unsupervised model, system-B is without itssemantic similarity measure, and system-C is ourproposed system.5 ConclusionsIn this paper, we proposed a novel normalizationsystem by using unsupervised methods in a largecorpus to identify non-standard words and theircorresponding proper words.
We further combineit with several previously developed normalizationsystems by a reranking strategy.
In addition, weexplored different sentence level reranking meth-ods to evaluate the impact of context information.Our experiments show that the reranking systemnot only significantly improves the word level nor-malization accuracy, but also helps the sentencelevel decoding.
In the future work, we plan to ex-plore more useful features and also leverage pair-wise and link reranking strategy.AcknowledgmentsWe thank the NSF for travel and conference sup-port for this paper.
The work is also partially sup-ported by DARPA Contract No.
FA8750-13-2-0041.
Any opinions, findings, and conclusions orrecommendations expressed are those of the au-thor and do not necessarily reflect the views of thefunding agencies.91ReferencesAiti Aw, Min Zhang, Juan Xiao, Jian Su, and Jian Su.2006.
A phrase-based statistical model for sms textnormalization.
In Processing of COLING/ACL.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminativereranking.
In Proceedings of the 43rd ACL.Monojit Choudhury, Rahul Saraf, Vijit Jain, AnimeshMukherjee, Sudeshna Sarkar, and Anupam Basu.2007.
Investigation and modeling of the structureof texting language.
IJDAR.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and exper-iments with perceptron algorithms.
In Proceedingsof EMNLP.Danish Contractor, Tanveer A. Faruquie, L. VenkataSubramaniam, and L. Venkata Subramaniam.
2010.Unsupervised cleansing of noisy text.
In Proceed-ings of COLING.Paul Cook and Suzanne Stevenson.
2009.
An unsu-pervised model for text message normalization.
InProceedings of NAACL.Fred J Damerau.
1964.
A technique for computer de-tection and correction of spelling errors.
Communi-cations of the ACM, 7(3):171?176.Bo Han and Timothy Baldwin.
2011.
Lexical normali-sation of short text messages: Makn sens a #twitter.In Proceeding of 49th ACL.Bo Han, Paul Cook, and Timothy Baldwin.
2012.
Au-tomatically constructing a normalisation dictionaryfor microblogs.
In Proceedings of the 2012 EMNLP.Hany Hassan and Arul Menezes.
2013.
Social textnormalization using contextual graph random walks.In Proceedings of ACL.Heng Ji, Cynthia Rudin, and Ralph Grishman.
2006.Re-ranking algorithms for name tagging.
In Pro-ceedings of the Workshop on Computationally HardProblems and Joint Inference in Speech and Lan-guage Processing.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, Evan Herbst, and Evan Herbst.
2007.Moses: Open source toolkit for statistical machinetranslation.
In Proceedings of ACL.Terry Koo, Xavier Carreras, and Michael Collins.2008.
Simple semi-supervised dependency parsing.In Proceedings of ACL.Vladimir I Levenshtein.
1966.
Binary codes capableof correcting deletions, insertions and reversals.
InSoviet physics doklady, volume 10, page 707.Chen Li and Yang Liu.
2012a.
Improving text nor-malization using character-blocks based models andsystem combination.
In Proceedings of COLING2012.Chen Li and Yang Liu.
2012b.
Normalization of textmessages using character- and phone-based machinetranslation approaches.
In Proceedings of 13th In-terspeech.Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu.2011.
Insertion, deletion, or substitution?
: normal-izing text messages without pre-categorization norsupervision.
In Proceedings of the 49th ACL: shortpapers.Fei Liu, Fuliang Weng, and Xiao Jiang.
2012a.
Abroad-coverage normalization system for social me-dia language.
In Proceedings of the 50th ACL.Xiaohua Liu, Ming Zhou, Xiangyang Zhou,Zhongyang Fu, and Furu Wei.
2012b.
Jointinference of named entity recognition and normal-ization for tweets.
In Proceedings of ACL.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013.
Efficient estimation of word represen-tations in vector space.
Proceedings of Workshop atICLR.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Olutobi Owoputi, Brendan O?Connor, Chris Dyer,Kevin Gimpel, Nathan Schneider, and Noah A.Smith.
2013.
Improved part-of-speech tagging foronline conversational text with word clusters.
InProceedings of NAACL.Deana Pennell and Yang Liu.
2010.
Normalization oftext messages for text-to-speech.
In ICASSP.Deana Pennell and Yang Liu.
2011.
A character-levelmachine translation approach for normalization ofsms abbreviations.
In Proceedings of 5th IJCNLP.Sasa Petrovic, Miles Osborne, and Victor Lavrenko.2010.
The edinburgh twitter corpus.
In Proceedingsof NAACL.Alan Ritter, Sam Clark, Oren Etzioni, et al.
2011.Named entity recognition in tweets: an experimentalstudy.
In Proceedings of EMNLP.Richard Sproat, Alan W. Black, Stanley F. Chen,Shankar Kumar, Mari Ostendorf, and ChristopherRichards.
2001.
Normalization of non-standardwords.
Computer Speech & Language, 15(3):287?333.Andreas Stolcke.
2002.
SRILM-an extensible lan-guage modeling toolkit.
In Proceedings of Interna-tional Conference on Spoken Language Processing.92Oscar Ta?ckstro?m, Ryan McDonald, and Jakob Uszko-reit.
2012.
Cross-lingual word clusters for directtransfer of linguistic structure.
In Proceedings ofNAACL.Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.2010.
Word representations: A simple and generalmethod for semi-supervised learning.
In Proceed-ings of ACL.Yi Yang and Jacob Eisenstein.
2013.
A log-linearmodel for unsupervised text normalization.
In Pro-ceedings of EMNLP.93
