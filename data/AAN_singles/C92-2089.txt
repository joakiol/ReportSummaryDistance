A FEATURE-BASED MODEL FOR LEX ICAL  DATABASESJEAN VI~RONIS, NANCY IDEGroupe Reprdsentation etTraitement des Connaissances,Centre National de la Recherche Scientifique,31, Chemin Joseph Aiguier, 13402 Marseille Cedex 09, FranceDepartment of Computer Science, Vassar CollegePoughkeepsie, New York 12601, U.S.A.e-mail : veron is@vassar .edu ,  ideOvassar .eduAbstract  -- To date, no fully suitable data model forlexical databases has been proposed.
As lexicaldatabases have prolifcrated inmultiple formats, there hasbeen growing concern over the reusability of lexicalresources.
In this paper, we propose a model based onfeature structures which overcomes most of theproblems inherent in classical database models, anti inparticular enables accessing, manipulating or merginginformation structured in multiple ways.
Because oftheir widespread use in file representation f linguisticinformation, the applicability of feature structures tolexical databases seems natural, although to our knowl-edge this has not yet been implemented.
The nse offeature structures in lexical databases also opens up thepossibility of compatibility with computational lexicons.1.
INTRODUCTIONThere exists a substantial body of researchdemonstrating that machine readablc dictiotmries are arich source of ready-made lexical and semanticinformation which can be used in natural anguageprocessing (for exantple, Amslcr, 1980; Calzolari, 1984;Markowitz, Ahlswede, and Evens, 1986; Byrd et al,1987; Nakamura nd Nagao, 1988; V6ronis and Ide,1990; Klavans, Chodorow, and Wachohler, 1990;Wilks et al, 1990).
Much of this research involves thecreation of lexieal databases from original dictionarydata, in order to facilitate retrieval and analysis.However, lexical data is much more complex than thekind of data (suppliers and parts, employees' records,etc.)
that has provided the impetus for most databaseresearch.
Therefore, classical data models (e.g.,relational) do not apply well to lexical data, and, as aresult, current lexical databases xist in a wide varicty of(often ad hoc) formats.
To date, no fully suitablc datamodel for lexical databases has beeu proposed.As lexical databases have proliferated in multipleformats, there has been growing concern over thereusability of lexical resources.
The interchange audintegration of data, as well as the development ofcommon software, is increasingly important to avoidduplication of eflort and enable the development oflarge-scale databases of linguistic information (which isthe concern of projects such as ACQUILEX,GENELEX, EDR, etc.
).In this paper, we provide a data model that is suitedto lexical databases.
A strong requirement for such adata model is that it must make lexical informationcompatible despite its variability in structure across thedictionaries from which it is derived.
We show that amodel based on feature structures overcomes most of theproblems inherent in classical database models, and, inparticular, enables accessing, manipulating or merginginformation structured in multiple ways.
The feature-based model also allows retaining the particular organi-zation of a given dictionary while at the same time ma-king it invisible to certain retrieval oporations.
Becauseof their widespread use in the representation f linguisticinformation, the applicability of feature structures tolexical databases secms natural, although to oar kuowl-edge this has not yet been implemented.
The use offeaturc structures in lexical databases also opens up thepossibility of compatibility with computalional lexicons.2.
PREVIOUS MODELSThe classical relational model has been proposed torepresent dictionaries (Nakamura nd Nagao, 1988).However, as Neff, Byrd, and Rizk, 1988, point out, therelational model cannot capture the obvious hierarchy inmost dictionary entries.
For example, the entry forabandon in Fig.
1 has two main sub-parts, one for itsverb senses and one for its noun sense, and the twosenses of the verb labeled "1" in Fig.
1 are in fact twosub-senses of the first sense given in tile entry.
Thesetwo sub-senses are more closely related to each otherthan to senses 2, 3, and 4, but file tahular format ofrelational models obscures this fact.Neff, Byrd, and Rizk describe a lexical database(the IBM LDB) based on an unnormalized (also NonFirst Normal Form or NF 2) relational data model, inwhich attribute values may be nested relations with theirown internal structure (see Abiteboul and Bidoit, 1984;Roth et al, 1988).
Fig.
2 shows the LDOCE entry forabandon represented in a NF 2 model.
The outermosttable consists of a rclation between a headword andsome number of homographs.
In turn, a homographconsists of a part of speech, a grammar code, and somenumber of senses, etc.
Obviously, this model bettercaptures the hierarchical structure of information i  thedictionary and enables the tactoring of attributes.Although NF 2 models clearly improve on othermodels for representing dictionary information, anumber of problems, outlined in the following sub-sections, still remain.Acids DE COLING-92, NANTES, 23-28 AoL'r 1992 5 8 8 PROC.
OF COLING-92, NAN'rEs, AUG. 23-28, 1992a.ban.don I / ,~'bamdon/v \[TIt 1 to leave completelyand for ever; desert: The sailors abandoned theburning ship.
2 to leave (a relation or friend) in athoughtless or cruel way: lie abandoned his wife andwent away with all their money.
3 to give up, esp.without finishing: The search was abandoned whennight came, even though the child had not beenfound.
4 (to) to give (oneself) up completely to afeeling, desire, etc.
: lie abandoned him*elf to grief Iabandoned behaviour.
-- ~ment n IU\].abandon 2 n \[U\] the state when one's feelings andactions are uncontrolled; freedom from control: 7'hepeople were so excited that they jumped and shoutedwith abandon / in gay abandon.Fig.
1.
Definition of 'abandon' from LDOCE2.1 Recursive nestingSome dictionaries take the grouping and nesting ofsenses several levels deep in order to distinguish finerand finer grains of meaning.
The Haebette ZyzomysCD-ROM dictionary, for instance, distinguishes up tofive levels in an entry (Fig.
3).va lour  \[valceR\] n. f. A.
1. l .
Ce par quoi une~a rsonne est digne d'estime, ensemble des qualit6s quirecommandent.
(V. m6rite).
Avoir conscience de savaleur.
C'est un heroine de grande valour.
2.
Vx.Vaillance, bravoure (sp~ial., au combat).
"La valourn'anend pas le hombre des anndes" (Corneille).
OValour militaire (croix de la): d6coration frangaise...i'i, 1.
Ce en quoi une chose est dignc d'int6r6t.
Lossouvenirs attaches h cot objet font pour toni sa valeur.2.
Caract~re de ce qui est reconnu digne d'int6r6t...B\] L 1.
Caract~re mesurable d'un objet, en tam qu'ilest susceptible d'6tre 6chang6, d6sir6, vendu, etc.
(V.prix).
Faire estimer la valour d'un objet d'art...Fig.
3.
Part of the definition of 'valour' in ZyzomysNF2 models explicitly prohibit recursive mbeddingof relations.
Therefore, the only way to represent herecursive nesting of senses is through the proliferationof attributes uch as sENS< I,ZV~I.1, SENSE L~WL2, etc.
mrepresent the different levels.
This in turn demands thatqueries take into account all the possible positions wherea given sub-attribute (e.g., usage) could appear.
Forexample, mulitple queries are required to retrieve allnouns which have an archaic (Vx = vieux) sense.
Sincearty sense at any level could have this attribute value, itis necessary to query each level.2.2 ExceptionsExceptional cases are characteristic of lexical data.
Forinstance, sense 3 of the word "conjure" in the OALD hasa pronunciation different from the other senses in theentry, and the entry "heave" in the CED shows thatinflected forms may apply to individual senses--in thiscase, the past tense and past participle is "heaved" for allbut the nautical senses, for which it is "hove" (Fig.
4).con.jure \[k^nd3o(r)/vt,  i I \[VP2A,15A\] do clevertricks which appear magical... 2 \[VP15B1 ~ up, causeto appear as if from nothing... 3/kan'dsUa(r) /  \[VP17\](formal) appeal solemnly to_.
\[OALD\]heave (hi:v) vb.
heaves, heaving, heaved or (chieflynautical) hove .
.
.
.
5.
(pa.~t tense and past participlehove) Nautical.
a. to move or cause to move in aspecified way ._ ICED\]Fig.
4.
Exceptions in dictionary entriesAllowing the same attribute at different levels, indifferent nested relations (for example, al lowing apronunciation attribute at both the homograph and senselevels) would require a mechanism to "override" anattribute value at an inner level of  nesting.
NF 2 modelsdo not provide any such mechanism and, in fact, do notallow the same attribute to appear at different levels.
Ifany attribute can appear in any nested relation, the modelbecomes ill-defined since the very notion of hierarchyupon which it relies is undermined.
Therefore, the onlyHWabandorlI{OMOGRAPHpc GC SENSEDN BC DEF' 1 N \] T 1 ON EXAMP I,EDF SPv T1 1 .
.
.
.
H .
.
.
.
T to leave  complete ly  The sa i lo rs  abandoned theand for ever  burn ing  sh ip  .................................................................. _a e._s.?
r.t. ... .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.2 - -D-H  .
.
.
.
H to leave  (a re la t ion  He abandoned his w i fe  andor f r iend)  in a thought:- went away with  al l  the i r......................... ~_tt?_L_o__r___c__r__u__c_'.l___w__a_.z .... ........
~.
?_\[te..Z .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.3 .
.
.
.
It .
.
.
.
T tO g ive  up, esp.
The search  was  abandonedwithout: f in i sh ing  when n ight  came, even  thoughthe ch i ld  had  not been  found- ~-'-- "-- \]--"-" h-'-" - ~-#-~ {-6"" ~" i re  -- ~\]{ \[{6-~ e- i?
\]" L-6 ........ -i ~-- ~ ~ ~a'~}\] ~-n-~ - -fiTA-AZ Y ~-- ~-6- ........complete \ ]y  to  a fee l ing ,  g r ie fdes i re ,  etc, abandoned behav iour-',V~"0---'-'6"~-:--'-'-'~s-'-'ss'~h'~"s'CWJ~"~?e'~-'o-~  ......... '~"fi~-" "~e o-r~7~\[ - -~  r'~" - s'6" -~,'~c Y \ [~ ....fee l ings  and ac t ions  are that  they  jumped and shouteduncont ro l led  w i th  abandon~in gay  abandon ...................................... ~...f reedom f rom cont ro lFig.
2.
NF 2 representation of the entry 'abandon'ACRES DE COLING-92, NAMES, 23-28 AO~" 1992 5 8 9 PRO(:.
OF COLING-92, NANTES, AUO.
23-28, 1992way exceptions could be handled in an NF 2 modelwould be by re-defining the template so that attributessuch as pronunciation, i flected forms, etymology, etc.,are associated with senses rather than homographs.However, this would disable the factoring of thisinformation, which applies to the entire entry in the vastmajority of cases.2.3 Var iab le  factor ingDictionaries obviously differ considerably in theirphysical ayout.
For example, in one dictionary, allsenses of a given orthographic form with the sameetymology will be grouped in a single entry, regardlessof part of speech; whereas in another, different entriesfor the same orthographic form are given if the part ofspeech is different.
The CED, for instance, has only oneentry for abandon, including both the noun and verbforms, but the LDOCE gives two entries for abandon,one for each part of speech.
As a result of thesedifferences, the IBM LDB template for the LDOCEplaces the part of speech attribute at the homographlevel, whereas in the CED template, part of speech mustbe given at the level of sense (or "sense group" if somenew attribute were defined to group senses with thesame part of speech within an entry).
This means thatthe query for part of speech in the LDOCE is completelydifferent from that for the CED.
Further, it means thatthe merging or comparison of information from differentdictionaries demands complete (and possibly complex)de-structuring and re-strncturing of the data.
This makesdata sharing and interchange, aswell as the developmentof general software for the manipulation of lexical data,difficult.However, differences in dictionary layout aremainly differences in structural organization, whereasthe fundamental elements of lexieal information seem tobe constant.
In the example above, for instance, thebasic information (orthography, pronuncation, part ofspeech, etc.)
is the same in both the CED and LDOCE,even if its organization is different.The only way to have directly compatible databasesfor different dictionaries in the NF 2 model, even if oneassumes that attributes for the same kind of information(e.g., orthography) can have the same name acrossdatabases, is to have a common template across all ofthem.
However, the fixed factoring of attributes in NF 2models prohibits the creation of a common template,because the template for a given database mirrors theparticular factoring of a single dictionary.
Therefore, amore flexible model is needed that would retain theparticular factoring of a given dictionary, and at the sametime render that factoring transparent to certain databaseoperations.3.
A FEATURE-BASED MODELWe introduce a model for dictionary data based onfeature structures.
We demonstrate the mapping betweenthe information found in dictionaries and the feature-based model, and show how the various characteristicsof lexical data, such as recursive nesting of elements,(variable) factoring of information, and exceptions canbe handled using well-developed feature structuremechanisms.Fig.
5 shows how feature structures can be used torepresent simple dictionary entries.
We will considerfeature structures as typed (as defined, for instance, byPollard and Sag, 1987), that is, not all features canappear anywhere, but instead, they must follow aschema that specifies which features are allowable(although not necessarily present), and where.
Theschema lso specifies the domain of values, atomic orcomplex, allowed for each of these features.
Forexample, entries are described by the type ENTRY, inwhich the features allowed are form, gram, usage, def,etc.
The domain of values for form is feature structuresof type FORM, which consists of feature structureswhose legal features include orth, hyph, and pron.
Eachof these features has, in turn, an atomic value of typeSTRING, etc.I eom.peti.tor/kam'peUto(r)/ n person who competes I\[OALDI Iform: hyph: com.peti.torproD: k@m'petIt@ (r)I g .... Epos: ~ ?Ldef: Ere?t: person who compete %Fig.
5.
Representation of a simple sense3.1 Value disjunction and var iantsThe use of value disjunction (Karttunen, 1984) enablesthe represention of variants, common in dictionaryentries, as shown in Fig.
6.
We have added an extensionwhich allows the specification of either a set (noted {Xl,... xn\]) or a list (noted (xl .
.
.
.
Xn)) of possible values.This enables retaining the order of values, which is inmany cases important in dictionaries.
For example, theorthographic form given first is most likely file mostcommon or preferred form.
Other information, such asgrammatical codes, may not be ordered.biryani or biriani (,blrl'o:nl) n. Any of a variety of \]Indian dishes... \[CED\] II .
.
.
.
Forth: (b i ryani ,  b i r ian i ) l -  ~kpron ,biri'A:nl J |ef: Itext Any of .
.
.
.
iety qlof Indian dishes...JJFig.
6.
Value disjunctionIn many cases, sets or lists of alternatives are notsingle values but instead groups of features.
This iscommon in dictionaries; for instance, Fig.
7 shows atypical example where the alternatives are groupsconsisting of orthography and pronunciation.ACRES DE COLING-92, NAW~s, 23-28 AOtJT 1992 5 9 0 PROC.
OF COLING-92, NANTES, AUO.
23-28, 1992mackle ('mmk'l) or macule ('nnekju:l) n, Priming.
adouble or blurred impression caused by shiftingpaper or type.
\[CED\]Id orm : orth: mackle I orth: mactl\] e LIt ....... 'm&kju: l\]J usago: L dora: Prirltinf~ ef: \[ text;: a double or blurted.,.Fig.
7.
Value disjunction of non-atomic values3.2 Genera l  d i s junct ion  and  fac tor ingGeneral disjunction (Kay, 1985) provides a means tospecify alternative sub-parts of a feature structure.Again, we have extended rite mechanism to enable thespeci f icat ion of  both sets and lists of  sub-parts.Therefore, feature structures can be described as beingof  the form \[~1 .
.
.
.
~,1, where each q~i is a feature-value pair f :  V, a set of  feature structures { V!
.
.
.
.
Vp},or a list of  feature structures (VI .
.
.
.
Vp).General  d is junct ion a l lows common parts ofcomponents to be tactored.
Without any disjunction,two different representations for the entry for hospitallerfrom the CED are required.
The use of value disjunctionenables localizing the problem and thus eliminates omeof the redundancy, but only general disjunction (Fig.
8)captures the obvious factoring and represents the entrycleanly and without redumlancy.hospitaller or U.S. hospitaler ('h0tspltolo) n. a person,esp.
a member of certain religious orders... ICED\] \]fotra:f\[pton: 'hQsplt@\] @ \]\[orth: hospita \[ Ier\]\] Igram: \ [pos: nldef: Ire?L: a person...\]Fig.
8.
General disjunctionGeneral disjunction provides a means to representmultiple senses, since they can be seen as alternatives(Fig.
9).
1Sense nesting is also easily represented using thismechanism.
Fig.
10 shows the representat ion forabandon given previously.
At the outermost level of  thefeature structure, there is a disjunction between the twodifferent parts of  speech (which appear in two separateentries in the LDOCE), The dis junction enables thefac tor ing  of  o r thography ,  p ronunc ia t ion ,  andlNote that in our examples, "\]\]" signals the beginning of acomment which is not part of the feature structure.
We have notincluded the sense number as a feature in our examples becausesense numbers can be automatically generated.hyphenat ion over both homographs.
Within the firstcomponent of the disjunction, the different senses forthe verb comprise an embedded list of disjunets.- -  \] Fd isproof  (dls'pru:f) n. 1. facts that disprove\[ something.
2. the act of disproving.
\[CED\]ll orm ~orth: disproof I !\] I L pron: dls'pKu: fJ r~m fpo~: n\] I \['~11 .
.
.
.
.
1I I ~dei: \ [ text :  facts that dinprove..\]Fig.
9.
Representation of multiple sensesAn important characteristic of  this model is thatthere is ne different ype of feature structure for entries,homographs,  or senses.
This captures what appears tobe n fundamental property of  lexical data, that is, thattile different levels (entries, homographs,  senses) arcassociated with rite same kinds of information, Previousmodels have treated these different levels as differentobjects, associated wtih different kinds of information,which obscures die more fundamental structure of  theinfornmtion.Note that we restrict the lorm of feature structuresin our model to a hierarchical normal form.
That is, inany feature structure F = \[?1 .
.
.
.
~,J, only one ?i, letus say 0 ,  = {I//1 .
.
.
.
~p\ ] ,  is a d is junct ion.
Thisrestriction is applied recursively to embedded featurestructures.
This scheme enables representing a featurestructure as a tree in which factored information\[0l .
.
.
.
~n-ll at a given level is associated with a node,and branches from that node correspond to the disjuncts~1 .
.
.
.
gp.
lnformatiou associated with a node appliesto the whole sub-tree rooted at timt node.
For example,the tree in Fig.
11 represents the feature structure forabandon given in Fig.
10.
The representat ion ofinformation as a tree of feature structares, where eachnode represeuts a level of hierarchy in the dictionary,ref lects structure and factor ing of  informat ion indictionaries and captures the fm~damental similarityamong levels cited above.3.3 Dis junct ive normal  to rn ,  and equivalenceIt is possible to define an unfactor operator tomult iply out the terms of  alternatives in a generaldisjunction (Fig.
12), assuming that no feature appearsat both a higher level and inside a disjunct.
2By applying the unfactor operator ecursively, it ispossible to eliminate all disjunctions except at the toplevel.
The resulting (extremely redundant) structure iscalled the disjunctive normal form (DNF).
We say thattwo feature structures are DNF-equivalent if they have2Value disjunction is not affected by the unfactor pre.cels.Ilowever, a value disjunction \[f: {a, b}\] can be converted to ageneral disjunction \[{If: al, If: bl } l, and subsequently un factored.ACRES DE COLING-92, NANTES, 23-28 AOtn' 1992 5 9 l I'ROC.
OF COLING-92, NANTES, AUG. 23-28.
1992form:\[ orth: abandon\[ hyph: a.ban ,do~|  pron: @"b&ndOn J'~homograph 1gram: pos: vgramc: T1~/sense  i\[ boxc : .... tI ....ef: ~\[ text: to leave completely and for ever \]L\[te?t: deser t \ ]~x:  \[text: The sailors abandoned the burning ship//sense 2\[ \]i ~""  j~e la ted : \ [o r th :  abandonment\]//homograph 2.... \[::::c; I 1 W ?
: \ [C17_ : : : ;  .
.
.
.ldef: \[text: the state when one's feelings and actionsI ex: \[text: The people were so excited that they jumped..k~Fig 10.
R~re~ntation of ~e ~ abandon in LDOCEa.ban .don l lpron:hyph: @"b&ndOn J~//homograph i / /homograph 2gramc: gramc: U Jr em \[=ode --bone: .
.
.
.
T .
.
.
.
.l de f : \ [ t thest  .... ..... \ ]1/ /  .
.
.
.
.
1 LX:  \[ .
.
.
.
.
The people,  Eem:  f scod .
.
.
.
.
.
--\] .
.
.
.
.
.
.
.
.L boxc: .... H .... T _ I  \]~f:  r \ [  t .
.
.
.
to  1 .
.
.
.
.
.
.
1~1L\[  text :  d .... t \ ]  JIx: \[ text: The sailors,..\]lFig.
11.
Hierarchical Normal Formthe same DNF.
The fact that the same DNF may havetwo or more equivalent factorings enables therepresentation f different factorings in dictionaries,while retaining a means to recognize their equivalence.Fig.
13a shows the factoring for inflected forms ofalumnus in the CED; the same information could havebeen factored as it appears in Fig.
13b.
Note that wehave used sets and notlists in Fig.
13.
Strictly speaking,the corresponding future structures with lists would nothave the same DNFs.
However, since it is trivial toconvert lists into sets, it is easy to define a strongerversion of DNF-equivalence that disregards order.L1E :aJJFig, 12.
UnfactoringWe can also define a factor operator to apply to agroup of disjuncts, in order to factor out commoninformation.
Information can be unfactored and re-factored in a different format without loss ofinformation, thus enabling various presentations of theAClT.S DE COLING-92, NANTEs, 23-28 ho\[;r 1992 $ 9 2 PROC.
OF COLING-92, NANTES, AUG. 23-28.
1992same information, which may, in turn, correspond todifferent printed renderings or "views" of the data.I alumnus (a'l^nmas) or (fern.)
alumna (Cl^nmO) n .
,pl.
-ni (-nail or -nae (-hi:) ... \[CEDIorth: alumnuIlL\[ ...... @"l^mn@~J I lorth: alumnaform: b L Pr?n: 8"i mn@-J\]JI numb: p\]r qend: masc \ ] \ ] I  | otth: alumniL pron: @"l^mnaI\[ ~ lorth: alumnaepron: @"i ^ rank(a)alumnus (o'l^mnas), pl.
-hi (-hal), or (fern.)
air\[ c0' pl.-?,o (-o :)lumnar numb: singI I |orth: alumnu':I{ Lpron: @ "i r^,m@ 5II \[:<: \[ hpron: 0"\] ^ mnaforal:orth: alumnapron: @"\] ^ ran@orth: alumnaepror\]: @"I ^ mDi(b)Fig.
13.
Two different factorings of the same information3.4 Part ia l  factor ingThe type of factoring described above does not handlethe example in Fig.
14, where only a part of thegrammatical information is factored (0os and subc, butnot gcode).
We call allow a given feature to appear atboth the factored level and inside the disjunct, as long asthe two values for that feature are compatible.
In thatcase, unfactoring involves taking the unification of thefactored information "and the information i  rite disjmtet.ea,reen/k~'ri:n/ vt,vi 1 \[VP6A\] turn (a ship) on oneside for cleaning, repairing, etc.
2 \[VP6A, 2A\] (causeto) tilt, lean over to one side.
\[OALD\]-'f \[ .... \] orth: careenhyph: ca.
reenpron: k@'ri:n.... \]stlbc i (tr, JntrI ~am: ~gc:ode: VP6A-J def: \[text: ttlrn (a ship)...\]///sens~ 2\[gcode : (VP6A, VP2AI\]\[teXt : (cause < Ld?f: tol t~ l t .
.
.
\ ]Fig.
14.
Partial factoring3,5 Exceptions and overr id ingWe saw ill the previous section that compatibleinformation can appear at various levels in a disjunction.Exceptions in dictionaries will be handled by allowingincompatible information to appear at different levels.When this is the case, nnfactoring will be defined toretain only the information at the imlermost level.
In thisway, a value specified at rite outer level is overridden bya value specified for the same feature at an intter level.For example, Fig.
15 shows the factored entry forconjure, in which the pronunciation specified at theoutermost level applies to all senses except sense 3,where it is overriden.
.=conjure/'k^nd3o(r)/ vt, vi 1 \[VP2A,15AI do clever\[ tricks which appear magical... 2 \[VPISB\] ~ up, cau~to appear as if from nothing... 3/kon'd5Oa(r)/ \[VP17\]I (formal) appeal solemnly to... \[OALD\]"kVndZ@ (r)oft.
h: conjuzeform; hyph: con.
jurepron :gta,l: \[ pos: v \]~;tlbc: (tr, intr)qdef: \[te~t: do clever tzicks...\]gram: gcode : VPIbB\]related; orth : conjure up\]gram: \[gcode : VP II\]def: Lte?t : appt~al solemnly...Fig.
15.
Overriding of valuesAcrEs DE COLING-92, NANTES, 23-28 AO0r 1992 5 9 3 lh{oc, OF COL1NG-92, NANTES, AUG. 23-28, 19923.6 ImplementationFeature-based systems developed so far are designed forparsing natural language and are not intended to be usedas general DBMSs.
Therefore, they typically do notprovide even standard atabase operations.
They arcfurthermore usually restricted to handle only a fewhundred grammar rules, and so even the largest systemsare incapable of dealing with the "large amounts of datatbat wotdd be required for a dictionary.In Ide, Le Maitre, V6rouis (forthcoming), wedescribe an object-oriented implementation whichprovides the required expressiveness and flexibility.
Weshow how the feature-based model can be implementedin an object-oriented DBMS, and demonstrate thatleature structures map readily to an object-oriented datamodel.
However, our work suggests that thedevelopment of a featttrc-based DBMS, including built-in mechnisms for dis junct ion,  uni f icat ion,generalization, etc., is desirable.
Such feature-basedDBMSs could have applications far beyond therepresentation f lexical dam.4.
CONCLUSIONIn this paper we show that previously applied dammodels are inadequate for lexical databases.
Inparticular, we show that relational data models,including normalized models which allow the nesting ofattributes, cannot capture the structural properties oflexical information.
We propose an alternative f ature-based model for lexical databases, which departs frompreviously proposed models in significant ways.
Inparticular, it allows for a lull representation f sensenesting and defines an inheritance mechanism thatenables the elimination of redundant information.
"\['hemodel provides a flexibility which seems able to handlethe varying structures of different monolingualdictionaries.Acknowledgments -- The present research has beenpartially funded by the GRECO-PRC CommunicationHonune-Machine of the French Ministery of Researchand Technology, U.S.-French NSF/CNRS grant IN'I'-9016554 for collaborative research, and U.S. NSF RUIgrant IRI-9108363.
The authors would like toacknowledge the contribution of discnssioos with JacquesLe Maitre to the ideas in this paper.REFERENCESABITEBOUL, S., BIDOIT, N. (1984) Ncm first no'anal formrelations to represent hierarchicaUy organized ata.Proc.
ACM SIGAC77SIGMOD Symposium onPrinciples of Database Systentw Waterloo, Ontario;191-200.AMSLER, R. A.
(1980) The structure of the Merriam-Webster Pocket Dictionary.
Ph.
D. Dissertation, D.Texas at Austin.BYRD, R. J., CALZOLARI, N., CIIODOROW, M. S.,KLAVANS, J. L., NEI;F, M. S., RIZK, O.
(1987) Toolsand methods for computational inguistics.Computational Linguistics, 13(3/4): 219-240.CALZOLARI, N. (19841 Detecting patterns in a lexical database.
Proc.
lOth International Conference onComputational Linguistics, COLING'84; Stanford,California; 170-173.IDE, N., LE MAITRE, J., Vf~,RONIS, J.
(forthcoming)Outline of a model for lexical databases.
InformationProcessing and Management.KAR'I~fUNF, N, L. (1984) Features and values.
Proc.
lOthInternational Conference on ComputationalLinguistics, COLING'84; Stanford, California; 28-33;1984.KAY, M. (1985) Parsing in functional unificationgrammar.
In: Dowty, D.R., Karttunen, L., andZwicky, A.M., editors.
Natural Language Parsing;Cambridge: Cambridge University Press.KLAVANS, J., CIIODOROW, M., WACIIOLDER, N. (19901From dictionary to knowledge base via taxonomy.Proc.
6th Annual Conference of the UW Centre forthe New Oxford English Dictionary; Waterloo,Ontario; 110-132,1,F, CLUSE, C., RICIIARD, P., (19891.
The 02 databaseprogramming language.
Proc.
15th VLDBConference; Amsterdam; 1989.MARKOWlTZ, J., AI1LSWEDE, T., EVENS, M. (19861Semantically significant patterns in dictionarydefinitions.
Proc.
24rd Annual Conference of theAssociation for Computational Linguistics; NewYork; 112-119.NAKAMURA, J., NAGAO, M. (1988) Extraction ofsemantic information from an ordinary Englishdictionary and its evaluation.
Proc.
12thInternational Conference on ComputationalLinguistics, COLING'88; Budapest, Hungary; 459-464.NEFF, M. S., BYRD, R. J., RIZK, O.
A.
(19881 Creatingand querying lexical databases.
Proc.
Association forComputational Linguistics Second AppliedConference on Natural Language Processing;Austin, Texas; 84-92.
})OLLARD, C., SAG, 1.
A.
(1987).
Information-basedSyntax and Semantics.
CSLI Lecture Notes Series;Chicago: University of Chicago Press.ROTII, M. A., KORTII, H. F., SILBERSCIIA'VZ, A.
(19881.Extended algebra nd calculus for nested relationaldatabases.
ACM Tran.~actions on Database Systems.13(4):389-417.VERONIS,  J., IDE, N., M. (1990) Word SenseDisambiguation with Very Large Neural NetworksExtracted frmn Machine Readable Dictionaries.Proc.
13th International Conference onComputational Linguistics, COLING'90: Helsinki,Finland; 2:389-394.WILKS, Y., FASS D., GUO, C., MACDONALD, J., PLATE, T.,SLATOR.
B.
(19901 Providing Machine TractableDictionary Tools.
Machine Translation; 5, 99-154.AcIy~ DE COL1NG-92, NAN'IlkS, 23-28 AO~r 1992 5 9 4 Paoc.
OF COLING-92, NANTES, AUG. 23-28, 1992
