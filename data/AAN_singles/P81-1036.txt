Chart Parsing and Rule Schemata in PSGHenry ThompsonDept.
of Artificial Intelligence, Univ.
of Edinburgh,Hope Park Square, Meadow Lane, Edinburgh, EH8 9NWINTRODUCTIONMCHART is a flexible, modular chart parsing framework Ihave been developing (in Lisp) at Edinburgh, whoseinitial design characteristics were largely determinedby pedagogical needs.PSG is a gr---n-tical theory developed by Gerald Gazdarat Sussex, in collaboration with others in both the USand Britain, most notably Ivan Sag, Geoff Pull,--, andEwan Klein.
It is a notationally rich context freephrase structure grumm~r, incorporating meta-rules andrule schemata to capture generalisations.
(Gazdar198Oa, 1980b, 1981; Gazdar & Sag 1980; Gazdar, Sag,Pullum & Klein to appear)In this paper I want to describe how I have used MCHARTin beginning to construct a parser for gr-mm-rs express-ed in PSG, and how aspects of the chart parsing approachin general and MCHART in particular have made it easy toacco~mmodate two significant aspects of PSG: ruleschemata involving variables over categories; andcompound category symbols ("slash" categories).
To dothis I will briefly introduce the basic ideas of chartparsing; describe the salient aspects of MEHART; givean overview of PSG; and finally present the interest-ing aspects of the parser I am building for PSG usingMCHART.
Limitations of space, time, and will mean thatall of these sections will be brief and sketchy - Ihope to produce a much expanded version at a later date.I.
Chart ParsingThe chart parsing idea was originally conceived of byMartin Kay, and subsequently developed and refined byhim and Rot Kaplan (Kay 1973, 1977, 1980; Kaplan 1972,1973a, 19735).
The basic idea builds on the deviceknown as a well formed substring table, and transformsit from a passive repository of achieved results intoan active parsing agent.
A well formed substringtable can be considered as a directed graph, with eachedge representing a node in the analysis of a string.Before any parsing has occurred, all the nodes are(pre)terminal, as in Figure I.Figure I. Kim saw the child with he lass$N V O N P D NNon-terminal nodes discovered in the course of parsing,by whatever method, are recorded in the WFST by theaddition of edges to the graph.
For example inFigure 2 we see the edges which might have been addedin a parsing of the sentence given in Figure I.Figure 2.SThe advantage of the WFST comes out if we suppose thegr~--.=r involved reeognises the structural ambiguityof this sentence.
If the parsing continued in orderto produce the other structure, with the PP attachedat the VP level, considerable effort would be savedby the WFST.
The subject NP and the PP itself wouldnot need to be reparsed, as they are already in thegraph.What the chart adds to the WFST is the idea of activeedges.
Where the inactive edges of the WFST (and thechart) represent complete constituents, active edgesrepresent incomvlete constituents.
Where inactiveedges indicate the presence of such and such aconstituent, with such and such sub-structure,extending from here to ~here, active edges indicate astage in the search for a constituent.As such they record the category of the constituentunder construction, its sub-structure as found so far,and some specification of how it may be extended and/or completed.The fund~umental principle of chart parsing, from whichall else follows, is keyed by the meeting ofactive with inactive edges:The Fundamental Rule********************Whenever an active edge A and an inactive edge I meetfor the first time, if I satisfies A's conditions forextension, then build a* new edge as follows:lts left end is the left end of AIts right end is the right end of IIts category is the category of AIts contents are a function (dependent on thegrammatical formalism employed) of the contentsof A and the category and contents of IIt is inactive or active depending on whetherthis extension completes A or notNote that neither A nor I is modified by the abvveprocess - a completely new edge is constructed,independent of either of =hem.
In the case of A,this may seem surprising and wasteful of space, butin fact it is crucial to properly dealing withstructural ambiguity.
It guarantees that all parseswill be found, independent of the order in whichoperations are performed.
Whenever further inactiveedges are added at this point the continued presenceof A, together with the fundamental rule, insuresthat alternative extensions of A will be pursued asappropriate.A short example should make the workings of thisprinciple clear.
For the sake of simplicity, thegrammar I will use in this and subsequent examples isan unadorned set of context free phrase structure rules,and the structures produced are simple constituentstructure trees.
Nonetheless as should be clear fromwhat follows, the chart is equally useful for a widerange of grammutical formalisms, including phrasestructure rules with features and ATNs.
*In fact depending on formalism more than one new edgemay be built - see below.167Figures 3a-3d show the parsing of "the man" by the rule"::P -> D N".
In these figures, inactive edges arelight lines below the row of verteces.Active edges are heavy lines above the row.
Figure 3asimply shows the two inactive edges for the string withform-class information.Figure be.Figure 3b shows the addition of an empty active edge atthe left hand end.
We will discuss where it comes fromin the next section.
Its addition to the chart invokesthe fundamental rule, with this edge being A and theedge for "the" being I.Figure 3b.NP:D N\[\]O\[tho\] N\[man\]The notation here for the active edges is the categorysought, in this case NP, followed by a colon, followedby a list of the categories needed for extension/completion, in this case D followed by N, followed by abracketed list of sub-constituents, in this case empty.Since the first symbol of the extension specificationof A matches the category of I, an new edge is createdby the fundamental rule, as shown in Figure 3c.Figure 3c.NP IThis edge represents a partially completed NP, stillneeding an N to complete, with a partial structure, ltsaddition co the chart invokes the fundamental ruleagain, this time with it as A and the "man" edge as I.Once again the extension condition is meet, and a newedge is constructed.
This one is inactive however, asnothing more is required to complete it.Figure 3d.NP:D N\[\]NP:N\[D.\]NP\['D N\]The fundamental rule is invoked for the last time, backat the left hand end, because the empty NP edge (active)now meets the complete NP edge (inactive) for the firsttime, but nothing comes of this as D does not match NP,and so the process comes to a halt with the chart asshown in Figure 3d.The question of where the active edges come from isseparate from the basic book-keeping of the fundamentalprinciple.
Different rule invocation strategies suchas top-down, bottom-up, or left corner are reflected indifferent conditions for the introduction of empty activeedges, different conditions for the introduction ofempty active edges.
For instance for a top-downinvocation strategy, the following rule could be used:Top-down Strategy RuleWhenever an active edge is added to the chart, if thef i rs t  symbol it needs to extend itself is a non-terminal, add an empty active edge at its right handend for each rule in the gra-s~=r which expands theneeded symbol.With th i s  ru le  and the fundamental  ru le  in  operat ion ,s imply adding empty ac t ive  edges for  a l l  ru les  expandingthe d i s t ingu ished  symbol to the le f t  hand end of thechar t  w i l l  provoke the parse .
Success fu l  parses  arere f lec ted  in inact ive  edges of the cor rec t  ca tegoryspanning the ent i re  char t ,  once there  i s  no moreac t iv i ty  provoked by one or the o ther  of the ru les .Bottom-up invocat ion  i s  equa l ly  s t ra ight - fo rward :Bottom-up St ra tegy  RuleWhenever an inactive edge is added to the chart, forall the rules in the grammar whose expansion beginswith the this edge's category, add an empty activeedge at its left hand end.Note that  wh i le  th i s  ru le  i s  keyed o f f  inact ive  edgesthe top-down ru le  was t r iggered  by ac t ive  edges be ingadded.
Bottom-up says "Who needs what jus t  got bu i l tin  order  to get  s ta r ted" ,  wh i le  top-down says "Who canhelp bu i ld  what I need to car ry  on".
Bottom-up i ss l ight ly  s imp ler ,  as no add i t iona l  ac t ion  i s  needed tocommence the parse  beyond s imply  const ruct ing  thein i t ia l  char t  - the tex ica l ly  insp i red  inact ive  edgesthemselves get  th ings  moving.A%s~ note that  i f  the grammars to be parsed are  le f t -recursive, then both of these rules need redundancychecks of the form "and no such empty active edge isalready in place" added to them.The question of search strategy is independent of thechoice of rule invocation strategy.
Whether the parseproceeds depth-first, breadth-first, or in some othermanner is determined by the order in which edges areadded to the chart, and the order in which active-inactive pairs are considered under the fundamental rule.A single action, such as the adding of an edge to thechart, may provoke multiple operations: a number ofedge pairs to be processed by the fund=-,~ntal rule, and/or a number of new edges to be added as a result of somerule invocation strategy.
Last in first out processingof such multiple operations will give approximatelydepth-first behaviour, while first in first out will8ire approximately breadth-first.
More complex strat-egies, including semantically guided search, requiremore complicated queuing heuristics.The question of what gr~-~-tical formalism is employed isagain largely independent of the questions of rule in-vocation and search strategy.
St comes into play intwo different ways.
When the fundamental rule isinvoked, it is the details of the particular gr=~-,ticalformalism in use which determines the interpretation ofthe conditions for extension carried in the active edge.The result may be no new edges, if the conditions arenot met; one new edge, if they are; or indeed more thanone, if the inactive edge allows extension in more than168one way.
This might be the case in an ATN style ofgrammar, where the active edge specifies its conditionsfor extension by way of reference to a particular statein the network, which may have more than one out-goingarc which can be satisfied by the inactive edgeconcerned.
The other point at which gra~naticalformalism is involved is in rule invocation.
Once astrategy is chosen, it still remains each time it isinvoked to respond to the resulting queries, e.g.
"Whoneeds what just got built in order to get started", inthe case of a simple bottom-up strategy.
Such aresponse clearly depends on the details of the gra--~t-ical formalism being employed.Underlying all this flexibility, and making it possible,is the fundamental rule, which ensures that no matterwhat formalism, search strategy, and rule invocationstrategy* are used, every parse will eventually befound, and found only once.II.
MCHARTIn the construction of MCHART, I was principly motivatedby a desire to preserve what I see as the principalvirtues of the chart parsing approach, namely thesimplicity and power of its fundamental principle, andthe clear separation it makes between issues ofgrammatical formalism, search strategy, and ruleinvocation strategy.
This led to a carefullymodularised program, whose structure reflects thatseparation.
Where a choice has had to be made betweenclarity and efficiency, clarity has been preferred.This was done both in recognition of the system'sexpected role in teaching, and in the hopes that it canbe easily adopted as the basis for many diverse investi-gations, with as few efficiency-motivated hidden biasesas possible.The core of the system is quite small.
It defines thedata structures for edges and verteces, and organisesthe construction of the initial char~ and the printingof results.
Three distinct interfaces are providedwhich the user manipulates to create the particularparser he wants: A signal table for determining ruleinvocation strategy; a functional interface fordetermining gr=-s, atical formalism; and a multi-levelagenda for determining search strategy.The core system raises a signal whenever somethinghappens to which a rule invocation strategy might besensitive, namely the beginning and end of parsing,and the adding of active or inactive edges to the chart.To implement a particular strategy, the user  specifiesresponse to some or all of these.
For example abottom-up strategy would respond to the signal Adding~nactiveEdge, but ignore the others; while a top-downstrategy would need to respond to both AddingActiveEdgeand StartParse.There is also a signal for each new active-inactivepair, to which the user may specify a response.
Row-ever the system provides a default, which involves theafore-mentioned functional interface.
To takeadvantage of this, the user must define two functions.The first, called ToExtend, when given an active edgeand an inactive edge, must return a set of 'rules' whichmight be used to extend the one over the o~her.
Takentogether, an active edge, an inactive edge, and such arule are called a configuration.
The other functionr.he user must define, called RunConfig, cakes a config-uration as argument and is responsible for implementingthe fundamental principle, by building a new edge ifthe rule applies.
For use here and in responses tosignals, the system provides the function NewEdge, bywhich new edges may be handed over for addition to thechart.
*Defective invocation strategies, which never invoke aneeded rule, or invoke it more than once at the sameplace, can of course vitiate this guarantee.The system is embedded within a multi-level agendamechanism.
The adding of edges to the chart, therunning of configurations, the raising of signals areall controllable by this mechan ism.
The user  mayspecify what priority level each such action is to bequeued at, and may also specify what ordering regime isto be applied to each queue.
LIFO and FIFO areprovided as default options by the system.
Anythingmore complicated must be functionally specified by theuser.More detailed specifications would be out of place inthis context, but I hope enough has been said to give agood idea of how I have gone about implementing thechart in a clean and modular way.
Hardcopy and/ormachine-readable versions of the source code and a fewillustrative examples of use are available a tcost  fromme to those who are interested.
The system is writtenin ELISP, a local superset of Rutgers Lisp which isvery close to Interlisp.
A strenuous effort has beenmade to produce a relatively dialect neutral, transparen~implementation, end as the core system is only a fewpages long, translation to other versions of Lispshould not be difficult.III.
PSGInto the vacuum left by the degeneration into self-referential sterility of transformational-generativegrau~ar have sprung a host of non-transformationalgr*--,-tical theories.
PSG, as developed by GeraldGazdar and colleagues, is one of the most attractiveof these.
It combines a simplicity and elegance offormal apparatus with a demonstrably broad and arguablyinsightful coverage of English 8r---~tical phenomena(Gazdar 198Oa, 198Ob, forthcoming; Gazdar & Sag 1980;Gazdar, Pullum & Sag 1980; Gazdar, Klein, Pullum &Sag forthcoming).
It starts with context-free phrasestructure rules, with a two bar X-bar category system,under a node admissability interpretation.
Fouradditional notational devices increase the expressivepower of the formalism without changing its formalpower - features, meta-rules, rule schemata, andcumpound categories.The addition of feature marking from a finite set tothe category labels gives a large but finite inventoryof node labels.
Meta-rules are pattern-based rewriterules which provide for the convenient expression of aclass of syntactic regularities e.g.
passive andsubject-auxilliary inversion.
They can be interpretedas inductive c lauses  in the definition of the grammar,saying effectively "For every rule in the grammar ofsuch and such a form, add another of such and such aform".
Provided it does not generate infinite sets ofrules, such a device does not change the formal powerof the system.Rule schemata are another notational convenience, whichuse variables over categories (and features) to expresscompactly a large (but finite) family of rules.
Forinstance, the rule {S -> NP\[PN x\] VP\[FN x\]}*~ where PNis the person-number feature and x is a variable, is acompact expression of the requirement that subject andverb(-phrase) agree in person-number, and {x -> x andx} might be a simplified rule for handling conjunction.The final device in the system is a compounding of thecategory system, designed to capture facts aboutunbounded dependencies.This device augments the gr-,,~-r with a set of derivedcategories of the form x/y, for all categories x and yin the unaugmented graIEnar, together with a set ofderived rules for expanding these 'slash' categories.Such a category can be interpreted as 'an x with a y**Here and subsequently I use old-style category labelsas notational equivalents of their X-bar versions.169missing from it'.
The expansions for such a categoryare all the expansions for x, with the '/y' applied toevery element on the right hand sides thereof.
Thusif {A -~ B C} & {A -> D}, then {A/C -> B/C C}, {A/C ->B C/C}, and {A/C -> D/C}.
In addition x/x alwaysexpands, inter alia, to null.
Given this addition tothe gr=-,-=r, we can write rules like {NP ->  NP.
~hatS/NP} for relative clauses.
If we combine this devicewith variables over categories, we can write (over-simplified) rules like {S -> x S/x} for topicalization,and (x -> whatever x S/x} for free relatives.
Thisapproach to unbounded dependencies combines nicely w i ththe rule schema given above for conjunction to accountfor the so-called 'across the board' deletion facts.This would claim that e.g.
'the man that Kim saw andRobin gave the book to' is OK because what is conjoinedis two S/NPs, while e.g.
'the man that Kim saw andRobin gave the book to Leslie' is not OK because what isconjoined is an S/NP and an S, for which there is norule.It is of course impossible to give a satisfactorys,,m-~ry of an entire formalism in such a short space,but I hope a sufficient impression will have beenconveyed by the foregoing to make what follows intell-igible.
The interested reader is referred to thereferences given above for a full description of PSG?
by its author(s).IV.
Parsing PSG using MCHAETWhat with rule schemata and mete-rules, a relativelysmall amount of linguistic work within the PSG frame-work can lead to a large number of rules.
Mechanicalassistance is clearly needed to help the linguistmanage his gr~,~r ,  and to tell him what he's got atany given point.
Al~hough I am not convinced there isany theoretical significance to the difference informal complexity and power between context freegr=,--~rs and transbrmational gr=-~.=rs, the methodologic-al significance is clear and uncontestable.
Computa-tional tools for manipulating context free gr=mm-rs arereadily available and relatively well understood.
Onbeing introduced to PSG, and being impressed by itspotential, it therefore seemed to me altogetherappropriate to put the resources of computationallinguistics at the service of the theoretical linguist.A Parser, and eventually a directed generator, for PSGwould be of obvious use to the linguists workingwithin its framework.Thus my goal in building a parser for PSG is to servethe linguist - ~o provide a tool which allows theexpression and manipulation of the gr~mm~r in termsdetermined by the linguist for linguistic reasons.The goal is not an analogue or "functionally equivalent"system, but one which actually takes the linguists'rules and uses them to parse (and eventually generate).MCHART has proved to be an exceptionally effectivebasis for the construction of such a system.
Itsgenerality and flexibility have allowed me to implementthe basic formal devices of PSG in a non ad-hoc way,which I hope will allow me to meet my goal of providinga system for linguists to use in' their day to day work,without requiring them ~o be wizard prograemers first.Of the four sspects of PSG discussed above, it is ruleschemata and slash categories which are of mostinterest.
I intend to handle mete-rules by simplyclosing the gr=mm=r under the meta-rules ahead of time.Feature checking is also straight-forward, and in whatfollows I will ignore features in the interests ofsimplicity of exposition.Let us first consider rule schemata.
How are we todeal with a rule with a variable over categories?
Ifwe are following a ~op down rule invocation strategy,serious inefficiencies will result, whether the variableis on the left or right hand sides.
A rule with avariable on the left hand side will be invoked by everyactive edge which needs a non-terminal to extend itself,and a variable on the right hand side of a rule willinvoke every rule in the gr=---ar~ Fortunately, thingsare much better under a bottom up strategy.
I hadalready determined to use a bottom up approach, becausevarious characteristics of PSG strongly suggested that,with careful indexing of rules, this would mitigatesomewhat the effect of having a very large number ofrules.
*Suppose that every rule schema begins with** at leastone non-variable element, off which it which it canbe indexed.Then at some point an active edge will be added to thechart, needing a variable category to be extended.
Ifwhenever the fundamental rule is applied to this edgeand an inactive edge, this variable is instantiaEedthroughout the rule as the category of that inactiveedge, then the right thing will happen.
The exactlocus of implementation is the aforementioned functionToEx~end.
To implement rule schemaEa, instead ofsimply extracting the rule from the active edge andreturning it, it must first check to see if the righthand side of the rule begins with a variable.
If so,it returns a copy of the rule, with the variablereplaced by the category of the inactive edge throughout.In a bottom up context, ~his approach together with thefundamental rule means that all and only the plausiblevalues for the variable will be tried.
The followingexample should make this clear.Suppose we have a rule schema for english conjunctionas follows: {x -> both x and x}#, and noun phraserules including {NP -> Det N}, {NP -> Propn}, {Den ->NP 's}, where we assume that the possessive will getan edge of its own.
Then this is a sketch of how"both K im's  and Rob in ' s  hats" would be parsed as anNP.
Figure 4a shows a part of the chart, with thelexical edges, as well as three active edges.F iaure  ~a.
*A very  h igh proportion of PSG rules contain at l eas tone (pre)terminal.
The chart will support bi-directional processing, so running bottom up all suchrules can be indexed off a preterminal, whether i t  isfirst on the right hand side or not.
For example arule like {NT -> NT pt NT} could be indexed off p~, firstlooking leftwards to find the first NT, then rightwardsfor ~he other.
Preliminary results suggest that thisapproach will eliminate a great deal of wasted effort.
**In fact given the hi-directional approach, as long asa non-variable is contained anywhere in the rule we arealright.
If we assume that the root nature of ~opical-isation is reflected by the prese~in  the schema givenabove of some beginning of sentence marker, ~hen thisstipulation is true of all schemata proposed to date.#This rule is undoubtedly wrong.
I am using it hereand subsequently to have a rule which is indexed by itsfirst element.
The hi-directional approach obviatesthe necessity for this, but it would obscure the pointI am trying to make to have to explain this in detail.170Edge 1 is completely empty, and was inserted because theconjunction rule was triggered bottom up off the word"both".
Edge 2 follows from edge 1 by the fundamentalrule.
It is the crucial edge for what fo~lows, for~he next thing it needs is a variable.
Thus when itis added to the chart, and ToExtend is called on it andthe Fropn edge, the rule returned is effectively{Fropn:Fropn and Propn \[both\]}, which is the result ofsubstituting Propn for x throughout the rule in edge 2.This instantiated rule is immediately satisfied, leadingto the addition of edge 3.
No further progress willoccur on this path, however, as edge 3 needs "and" to beextended.,~o, \ /~/.ur~J ) 5 (,r.c.iFigure ~b.Figure 4B shows what happens when at some later pointbottom up processing adds edge 4, since a Propn constit-utes an NP.
Once again the fundamental rule will beinvoked, and ToExtend will be called on edge 2 and thisnew NP edge.
The resulting instantiated rule is{NP:NP and NP \[both\]}, which is immediately satisfied,resulting in edge 5.
But this path is also futile, asagain an "and" is required.oe-'W/rk~'~ 1Figure 4c.Finally Figure 4c shows what happens when further bottomup invocation causes edge 6 to be built - a determinercomposed of an NP and a possessive 's.
Again thefundamental rule will call ToExtend, this time on edge 2and this new Det edge.
The resulting instantiated ruleis {Det:Det and Det \[both\]}, which is immediatelysatisfied, resulting in edge 7.
From this point it isclear sailing.
The "and" will he consumed, and then"Robin's"  as a determ/ner, with the end result being aninactive edge for a compound determiner spanning "bothK im's  and Robin 's", which will in turn be incorporatedinto the con~plete NP.The way in which the fundamental rule, bottom up invoca-tion, and the generalised ToExtend interact to implementvariables over categories is elegant and effective.Very little effort is wasted, in the example edges 3 and5, but these might in fact be needed if the clause con-tinued in other ways.
The particular value of thisimplementation is that it is not restricted to one part-icular rule schema.
With this facility added, thegrazmaar writer is free to add schemata to his gra"m~r,and the system will accommodate them without any addition-al effort.Slash categories are another matter.
We could justtreat them in the same way we do meta-rules.
Thiswould mean augmenting the grammar with all the rulesformable under the principles described in the precedingsection on PSG.
Although this would probably work(there are some issues of ordering with respect toordinary meta-rules which are not altogether clear to me),it would lead to considerable inefficiency given ourbottom up assu~tion.
The parsing of as simple asentence as "Kim met Robin" would involve the uselessinvocation of many slash category expanding rules, and antanber of useless constituents would actually be found,including two S/NPs, and a VP/NP.
What we would liketo do is invoke these rules top down.
After all, ifthere is a slash category in a parse, there must be a"linking" rule, such as the relative clause rule mention-ed above, which expands a non slash category in terms ofinter alia a slash category.
Once again we can assumethat bottom up processing will eventually invoke thislinking rule, and carry it forward until what is neededis the slash category.
At this point we simply run topdown on the slash category.
MCHAKT allows us toimplement this mixed initiative approach quite easily.In addition to responding to the AddinglnactiveEdgesignal to implement the bottom up rule, we also fieldthe AddingActiveEdge signal and act if and only if whatis needed is a slash category.
If it is we add activeedges for just those rules generated by the slashingprocess for the particular slash category which isneeded.
In the particular case where what is needed isx/x for some category x, an e~ty  inactive edge isbuilt as well.
For instance in parsing the NP "thesong that Kim sang", once the relative dause rule getsto the point of needing an S/NP, various edges will bebuilt, including one expanding S/NP as NP followed byVP/NP.
This will consume "Ki~' as NP, and then belooking for VP/NP.
This will in turn be handled topdown, with an edge added looking for VP/NP as V followedby NP/NP among others.
"sang" is the V, and NP/NPprovokes top down action for the last time, this timesimply building an e~ty  inactive edge (aka trace).The nice thing about this approach is that it is simplyadditive.
We take the system as it was, and withoutmodifying anything already in place, simply add thisextra capacity by responding to a previously ignoredsignal.Alas things aren't quite that simple.
Our implementa-tions of rule schemata and slash categories each workfine independently.
Unfortunately they do not combineeffectively.
NPs like "the song that both Robin wroteand Kim sang" will not be parsed.
This is unfortunateindeed, as it was just to account for coordination factswith  respect  to  s lashed categor ies  that  these  dev iceswere incorporated into PSG in the form they have.The basic problem is that in our implementation of ruleschemata, we made crucial use of the fact that everythingran bottom up, while in our implementation of slashcategories we introduced some things which ran top down.The most straight-forward solution to the problem lies inthe conditions for the top down invocation of rulesexpanding slash categories.
We need to respond notjust to overt slash categories, but also to variables.After all, somebody looking for x m/ght be looking fory/z, and so the slash category mechanism should respondto active edges needing variable categories a8 well asto those needing explicit slash categories.
In thatcase all possible slash category expanding rules mustbe invoked.
This is not wonderful, but it's not as badas it might at first appear.
Most variables in ruleschemata are constrained to range over a limited set ofcategories.
There are also constraints on what slashcategories are actually possible.
Thus relatively fewschemata will actually invoke the full range of slashcategory rules, and the number of such  rules will not betoo great either.
Although some effort will certainlyhe wasted, it will still be much less than would havebeen by the brute force method of simply including the171slash category rules in ~he Era,--~ar directly.One might hope to use the left context to further con-strain the expansion of variables to slash categories,but orderin E problems, as well as the fact that thelinking rule may be arbitrarily far from the schema,as in e.g.
"the son E that Rim wrote Leslie arrangedRobin conducted and I sanE" limit the effectiveness ofsuch an appro&ch.I trust this little exercise has illustrated well boththe benefits and the drawbacks of a mixed initiativeinvocation strategy.
It allows you to tailor theinvocation of groups of rules in appropriate ways, butit does not guarantee that the result will not eitherunder -parse ,  as in  th i s  case ,  or indeed over -parse .The so lu t ion  in  th i s  case i s  a p r inc ip led  one, stemmingas i t  does from an ana lys i s  of the mismatch of assumpt-ions between the bottom up and top down par ts  of thesystem.V.
ConclusionSo far I have been encouraged by the ease with which Ihave been able to implement the various PSG deviceswithin the MCHART framework.
Each such device hasrequired a separate implementation, but taken togetherthe result is fully general.
Unless the PSG frame-work itself changes, no further progr=-ming is required.The linguist may now freely add, modify or remove rules,meta-rules, and schemata, and the system's behaviourwill faithfully reflect these changes without furtherado.
And if details of the fra~aework do change, theeffort involved to track them will be manageable, owin Eto the modularity of the MCHAET implementation.
Ifeel strongly that the use of a flexible and generalbase such as MCHART for the system, as opposed tocustom building a PSG parser from scratch, has beenvery much worth while.
The fact that the resultingsystem wears its structure on its sleeve, as it were,i s  eas i l y  exp la ined  and (I hope) unders tood ,  and eas i lyadapted,  more than o f f se ts  the poss ib le  loss  ofefficiency i nvo lved .The reinvention of the wheel is a sin whose denuncia-tions in this field are exceeded in number only by itsinstances.
I am certainly no l ees  guilty than mostin ~his regard.
None the less I venture to hope thatfor many aspects of parsing, a certain amount of thework simply need not be redone any more.
The basicconcept ua~ framework of the chart parsing approachseems to me ideally suited as the startin E point formuch of the discussion that goes on in the field.
Awider recognition of this, and the wide adoption of, ifnot a particular program such as MCHART, which is toomuch to expect, then at least of the basic chartparsing approach, would improve co,~unications in thefield tremendously, if nothing else.
The directcomparison of results, the effective evaluation ofclaims about efficiency, degrees of (near) determinism,e t~ would be so ,-,ch easier.
The chart also providesto my mind a very useful tool in teaching, allowing asit does the exemplification of so many of the crucialissues within the same framework.Try it, you might like it.In the same polemical vein, I would also encourage morecooperation on projects of this sort between theoreticaland computational linguists.
Our  technology can be ofconsiderable assisiance in the enterprise of grammardevelopment and evaluation.
There are plenty of othernon-transformational frameworks besides PSG which coulduse support similar to that which I am trying toprovide.
The benefit is not just to the linguist -?
ith a little luck in a few years I should have thebroadest coverage parser the world has yet seen, becauseall these l%nguists will ~ave been usiq8 my system toexten~ t~&pir ~r=-,-=r.
Whether I will actually be ableto make any use of the result is adm/ttedly less thanclear, but after all, getting there is half the fun.VI.
ReferencesGazdar, G.J.M.
(1980a) A cross-categorial semantics forcoordination.
Linguistics & Philosophy 3, 407-409.
(1980b) Unbounded dependencies and co-ordinate structure.
To appear in Linguistic In~uir~ ii.
(1981) Phrase Structure Gr=mm-r. Toappear in P. Jacobson and G.K. Pullum (eds.)
The natureof s~ntactic representation., G.K.
Pull,--, & I.
Sag (1980) A PhraseStructure Gr~=r  of the English Auxiliar 7 System.
Toappear in F. Heny (ed.)
Proceedings of the FourthGronin~en Round Table., G.K. Pullum, I.
Sag, & E.H. Klein (toappear)  English Gray,tar.Kaplan, R.M.
(1972) Augmented transition networks aspsychological models of sentence comprehension.Artificial Intelli6ence 3, 77-1OO.
(1973a) A General Syntactic Processor.In Rustin (ed.)
Natural Language Processing.
Algorith-mics Press, N.Y.(1973b) A multi-processin E approach tonatural language.
In Proceedings of the firstNational Computer Conference.
AFIPS Press, Montvale,N.J.Kay, M. (1973) The MIND System.
In Eustin (ed.
)Natural Language Processing.
Algorithmics Press, N.Y.- -  (1977) Morphological and syntactic analysis.In A. Zampolli (ed.)
S~rntactic Structures Processing.North Holland.
(1980) A lgor i thm Schemata nd Data S t ruc turesin  Syntact i c  P rocess ing .
To appear in  the proceed ingsof the Nobel Symposium on Text P rocess in  E 1980.
AlsoCSL-80-12, Xerox PAEC, Palo A l to ,  CA.
