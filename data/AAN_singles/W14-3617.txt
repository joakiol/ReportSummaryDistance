Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 132?136,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsAutomatic Correction of Arabic Text: a Cascaded ApproachHamdy Mubarak, Kareem DarwishQatar Computing Research InstituteQatar Foundation{hmubarak,kdarwish}@qf.org.qaAbstractThis paper describes the error correction model thatwe used for the Automatic Correction of Arabic Textshared task.
We employed two correction mod-els, namely a character-level model and a case-specific model, and two punctuation recovery mod-els, namely a simple statistical model and a CRFmodel.
Our results on the development set suggestthat using a cascaded correction model yields thebest results.1 IntroductionIn This paper, we describe our system for auto-matic Arabic error correction shared task (QALB-2014 Shared Task on Automatic Correction of Ara-bic) as part of the Arabic NLP workshop (Mohitet al., 2014).
Our system is composed of two mainsteps.
The first involves correcting word level er-rors, and the second pertains to performing punctu-ation recovery.
For word level correction, we usedtwo approaches, namely: 1) a statistical characterlevel transformation model that is aided by a lan-guage model (LM) to handle letter insertions, dele-tions, and substitutions and word merges; and 2) acase-specific system that is aided by a LM to han-dle specific error types such as dialectal word sub-stitutions and word splits.
For punctuation recovery,we used two approaches, namely a simple statisticalword-based system, and a conditional random fields(CRF) sequence labeler (Lafferty et al., 2001) thatattempts to recover punctuation based on POS andword sequences.
We performed all experiments onthe QALB dataset (Zaghouani et al., 2014).2 Word Error CorrectionIn this section we describe two approaches for wordcorrection.
The first approach involves using a char-acter level model, and the second handles specificcorrection cases.2.1 Character-level Correction ModelFor the character level model, we treated correctionas a Transliteration Mining (TM) task.
In TM, asequence in a source alphabet is used to find themost similar sequence in a lexicon that is writtenin a target alphabet.
TM has been fairly well stud-ied with multiple evaluation campaigns such as theNamed Entities Workshop (NEWS) (Zhang et al.,2011; Zhang et al., 2012).
In our work, we adopteda TM system to find corrections appearing in a largeArabic corpus.
The system involved learning char-acter (or character-sequence) level mappings be-tween erroneous words and their correct counter-parts.
Given the character mappings between theerroneous and correct words, we used a generativemodel that attempts to generate all possible map-pings of a source word while restricting the out-put to words in the target language (El-Kahki etal., 2011; Noeman and Madkour, 2010).
Specifi-cally, we used the baseline system of El-Kahky etal.
(2011).
To train character-level mappings, weextracted all the parallel word-pairs in the original(uncorrected) and corrected versions in the trainingset.
If a word in the original version of the trainingset was actually correct, the word would be mappedto itself.
We then aligned the parallel word pairs atcharacter level using GIZA++ (Och and Ney, 2003),and symmetrized the alignments using grow-diag-132final-and heuristic (Koehn et al., 2007).
In all, wealigned a little over one million word pairs.
As in thebaseline of El-Kahki et al.
(2011), given a possiblymisspelled word worg, we produced all its possiblesegmentations along with their associated mappingsthat we learned during alignment.
Valid target se-quences were retained and sorted by the product ofthe constituent mapping probabilities.
The top n (wepicked n = 10) candidates, wtrg1..nwith the highestprobability were generated.
Using Bayes rule, wecomputed:argmaxwtrgi?1..np(wtrgi|worg) = p(worg|wtrgi)p(wtrgi)(1)where p(worg|wtrgi) is the posterior probability ofmapping, which is computed as the product of themappings required to generate worgfrom wtrgi,and p(wtrgi) is the prior probability of the word.Then we used a trigram LM to pick the most likelycandidate in context.
We used a linear combinationof the the character-level transformation probabilityand the LM probability using the following formula:score = ?log(ProbLM) + (1?
?
)log(Probchar)We built the lexicon from a set of 234,638 Aljazeeraarticles1that span 10 years and all of ArabicWikipedia.
We also built a trigram languagemodel on the same corpus.
The combined corpuscontains 576 million tokens including 1.6 millionunique ones.
Spelling mistakes in Aljazeera arti-cles (Mubarak et al., 2010) and Wikipedia wereinfrequent.We varied the value of ?
between 0 and 1 with in-crements of 0.1 and found that the values 0.6 and 0.7yielded the best results.
This indicates that LM prob-ability is more important than character-mappingprobability.2.2 Case-specific CorrectionIn this method we attempted to address specifictypes of errors that are potentially difficult for thecharacter-based model to handle.
Some of these er-rors include dialectal words and words that were er-roneously split.
Before applying any correction, weconsulted a bigram LM that was trained the afore-mentioned set of Aljazeera articles.
The following1http://www.aljazeera.netcases are handled (in order):?
Switching from English punctuations to Arabicones, namely changing: ???
?
???
and ?,??
?,?.?
Handling common dialectal words and commonword-level mistakes.
An example dialectal word is???
@ (Ally)2(meaning ?this?
or ?that?)
which couldbe mapped to ?Y ?
@ (Al?y) , ??
?
@ (Alty) or?KY ?
@(Al?yn).
An example of a common mistake is ZA?@???
@ (An$A?
Allh) (meaning ?God willing?)
which iscorrected to ?
?
?
@ Z A??
@(>n $A?
Allh).
The sen-tence is scored with and without the word replace-ment, and the replacement is done if it yields higherLM probability.
?Handling errors pertaining to the different formsof alef, alef maqsoura and ya, and ta marboutaand ha (Nizar Habash, 2010).
We reimplementedthe baseline system in (Moussa et al., 2012) wherewords are normalized and the different possible de-normalized forms are scored in context using theLM.
We also added the following cases, namely at-tempting to replace:?'
(&) with ??'
(&w) or ?K'(}w); and?'
(}) with Z?(y?)
or vice versa (ex:??Q?
(mr&s)?
???Q?
(mr&ws)).?
Handling merges and splits.
Often words areconcatenated erroneously.
Thus, we attempted tosplit all words that were at least 5 letters long af-ter letters that don?t change their shapes when theyare connected to the letters following them, namelydifferent alef forms, X (d),X (*), P (r),P (z), ?
(w),?
(p), and ?
(Y) (ex: AJK.PAK(yArbnA)?
AJK.P AK(yArbnA)).
If the bigram was observed in the LM andthe LM score was higher (in context) than when theywere concatenated, then the word was split.
Con-versely, some words were split in the middle.
Weattempted to merge every two words in sequence.If the LM score was higher (in context) after themerge, then the two words would be merged (ex:2Buckwalter transiteration133H@ PA?JK @ (AntSAr At)?H@PA?JK @ (AntSArAt)).?
Removing repeated letters.
Often people repeatletters, particularly long vowels, for emphasis as in@ @ @QJJJk@ (>xyyyyrAAA) (meaning ?at last?).
Wecorrected for elongation in a manner similar to thatof Darwish et al.
(Darwish et al., 2012).
When along vowel are repeated, we replaced it with a eitherthe vowel (ex.
@Qg@) (>xyrA) or the vowel with onerepetition (ex.
@QJk@) (>xyyrA) and scored usingthe LM.
If a repeated alef appeared in the beginningof the word, we attempted to replace it with alef lam(ex.?PA?
k@@ (AAHDArp) ??PA?
m?
'@ (AlHDArp)(meaning ?civilization?)).
A trailing alef-hamza-alef sequence was replaced by alef-hamza (ex.
@ Z A???(smA?A)?
ZA???(smA?)
(meaning ?sky?)).?
Correcting out-of-vocabulary words.
For wordsthat were not observed in the LM, we attempted thefollowing corrections: 1) replacing phonetically orvisually confusable letters, namely?
(D) and?
(Z), X (d) andX (*), andX (*) andP; (z) (ex: ?.A?
(ZAbT) ?
?.A?
(DAbT)) 2) removing the lettersH.
(b) and X (d) that are added to verbs in presenttense in some dialects (ex: I.J?JK.(byktb)?
I.J?K(yktb)); 3) replacing the letters h (H) and ?
(h),which are added in some dialects to indicate futuretense, with ?
(s) (ex: H.Q??Jk (Hy$rb)?
H.Q??J?
(sy$rb)); and 4) replacing a leading ?A?
(hAl) witheither ?
@ @Y ?
(h*A Al) or ?
@ ?Y ?
(h*h Al) (ex.H.AJ??A?
(hAlktAb)?
H.AJ??
@ @Y?
(h*A AlktAb))and the leading ?A?
(EAl) with ?@???
(ElY Al) (ex.
?PBA ?
(EAl>rD) ??PB@???
(ElY Al>rD)).After replacement, the LM was always consulted.2.3 Correction ResultsTable 1 reports on the results of performing both cor-rection methods on the development set.
Also, sinceMethod F-measureCharacter-level 0.574Case-specific 0.587Character-level?
Case-specific 0.615Case-specific?
Character-level 0.603Table 1: The correction results using the character-levelmodel, case-specific correction, or their cascades.the case-specific corrections handle cases that werenot handled by the character-level model, we at-tempted to cascade both methods together.
It seemsthat when applying the character-level model firstfollowed by the case-specific correction yielded thebest results.3 Punctuation RecoveryIn this section, we describe two methods for punc-tuation recovery.
The first is a simple word-basedmodel and the other is a CRF based model.3.1 Simple Statistical ModelIn this approach, we identified words that were pre-ceded or followed by punctuations in the trainingset.
If a word was preceded or followed by a par-ticular punctuation mark more than 40% of the time,then we automatically placed the punctuation beforeor after the word in the dev set.
Also, if a sentencedid not have a period at the end of it, we added aperiod.3.2 CRF ModelIn this approach we trained a CRF sequence labelingto attempt to recover punctuation.
CRF combinesstate and transition level features making it a pos-sibly better choice than an HMM or a simple clas-sifier.
We used the CRF++ implementation3of thesequence labeler.
We trained the labeler on the train-ing part of the QALB dataset.
We used the followingfeatures:Word features: the current word, the previous andnext words, and the two previous and two nextwords.Part-of-speech (POS) tags: the POS of the current3http://crfpp.googlecode.com/svn/trunk/doc/index.html134Method Precision Recall F-measureStat model 0.306 0.153 0.204CRF model 0.373 0.141 0.204Table 2: The punctuation recovery results using the sim-ple statistical model and the CRF model.Method F-measureStat model (before correction) 0.593Stat model (after correction) 0.614CRF model (before correction) 0.607CRF model (after correction) 0.615Table 3: Cascaded correction (Character-level ?
Case-specific) combined with punctuation recovery.word and the POS of the two previous and two fol-lowing words.3.3 Punctuation Recovery ResultsTable 2 reports on the results of using the two differ-ent methods for punctuation recovery.
Note that noother correction is applied.4 Combining Correction with PunctuationRecoveryGiven that cascading both correction models yieldedthe best results, we attempted to combine the cas-caded correction model with the two punctuation re-covery methods.
We tried to put punctuation recov-ery before and after correction.
Table 3 summarizesthe results.
As the results suggest, combining cor-rection with punctuation recovery had a negative ef-fect on overall F-measure.
This requires further in-vestigation.5 Official Shared Task Experiments andResultsFor the official submissions to the shared task, wesubmitted 3 runs as follows:1.
QCRI-1: character-level correction, then case-based correction.2.
QCRI-2: case-based correction, then statisticalpunctuation recovery3.
QCRI-3: exactly like 2, but preceded also bystatistical punctuation recoveryRun Precision Recall F-measureQCRI-1 0.717 0.5686 0.6343QCRI-2 0.6286 0.6032 0.6157QCRI-3 0.6066 0.5928 0.5996Table 4: Official Results.Table 4 reports on the officially submitted resultsagainst the test set.
It seems that our attempts to addpunctuation recovery worsened results.6 ConclusionIn this paper, we presented automatic approachesfor correcting Arabic text and punctuation recovery.Our results on the development set shows that usinga cascaded approach that involves a character-levelmodel and another model that handles specific errorsyields the best results.
Incorporating punctuation re-covery did not improve correction.ReferencesKareem Darwish, Walid Magdy, and Ahmed Mourad.2012.
Language processing for arabic microblog re-trieval.
Proceedings of the 21st ACM internationalconference on Information and knowledge manage-ment.
ACM, 2012.Ali El-Kahky, Kareem Darwish, Ahmed Saad Aldein,Mohamed Abd El-Wahab, Ahmed Hefny, and WaleedAmmar.
2001.
Improved transliteration mining usinggraph reinforcement.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing, pp.
1384-1393, 2011.Nizar Habash.
2010.
Introduction to Arabic natural lan-guage processing.
Synthesis Lectures on Human Lan-guage Technologies 3.1 (2010): 1-187Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, Evan Herbst, Moses: Open Source Toolkitfor Statistical Machine Translation, Annual Meeting ofthe Association for Computational Linguistics (ACL),demonstration session, Prague, Czech Republic, June2007.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data, In Proc.
of ICML,pp.282-289, 2001.Behrang Mohit, Alla Rozovskaya, Nizar Habash, WajdiZaghouani, and Ossama Obeid, 2014.
The First QALB135Shared Task on Automatic Text Correction for Arabic.In Proceedings of EMNLP workshop on Arabic Natu-ral Language Processing.
Doha, Qatar.Mohammed Moussa, Mohamed Waleed Fakhr, and Ka-reem Darwish.
2012.
Statistical denormalization forArabic Text.
In Empirical Methods in Natural Lan-guage Processing, pp.
228.
2012.Hamdy Mubarak, Ahmed Metwali, Mostafa Ramadan.2010.
Spelling Mistakes in Arabic Newspapers.
ArabicLanguage and Scientific Researches conference, Fac-ulty of Arts, Ain Shams University, Cairo, EgyptSara Noeman and Amgad Madkour.
2010.
Language In-dependent Transliteration Mining System Using FiniteState Automata Framework.
ACL NEWS workshop2010.Franz J. Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, Vol.
1(29), 2003.Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-sama Obeid, Nadi Tomeh, Alla Rozovskaya, NouraFarra, Sarah Alkuhlani, and Kemal Oflazer.
2014.Large Scale Arabic Error Annotation: Guidelines andFramework.
In Proceedings of the Ninth InternationalConference on Language Resources and Evaluation(LREC14), Reykjavik, Iceland.Min Zhang, A Kumaran, Haizhou Li.
2011.
Whitepaperof NEWS 2012 Shared Task on Machine Translitera-tion.
IJCNLP-2011 NEWS workshop.Min Zhang, Haizhou Li, Ming Liu, A Kumaran.
2012.Whitepaper of NEWS 2012 Shared Task on MachineTransliteration.
ACL-2012 NEWS workshop.136
