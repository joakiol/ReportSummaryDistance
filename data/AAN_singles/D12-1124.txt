Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1357?1367, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsWord Salad: Relating Food Prices and DescriptionsVictor Chahuneau Kevin GimpelLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USA{vchahune,kgimpel}@cs.cmu.eduBryan R. RoutledgeTepper School of BusinessCarnegie Mellon UniversityPittsburgh, PA 15213, USAroutledge@cmu.eduLily ScherlisPhillips AcademyAndover, MA 01810, USAlily.scherlis@gmail.comNoah A. SmithLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USAnasmith@cs.cmu.eduAbstractWe investigate the use of language in foodwriting, specifically on restaurant menus andin customer reviews.
Our approach is to buildpredictive models of concrete external vari-ables, such as restaurant menu prices.
Wemake use of a dataset of menus and customerreviews for thousands of restaurants in severalU.S.
cities.
By focusing on prediction tasksand doing our analysis at scale, our method-ology allows quantitative, objective measure-ments of the words and phrases used to de-scribe food in restaurants.
We also exploreinteractions in language use between menuprices and sentiment as expressed in user re-views.1 IntroductionWhat words might a menu writer use to justify thehigh price of a steak?
How does describing an itemas chargrilled vs. charbroiled affect its price?
Whena customer writes an unfavorable review of a restau-rant, how is her word choice affected by the restau-rant?s prices?
In this paper, we explore questionslike these that relate restaurant menus, prices, andcustomer sentiment.
Our goal is to understand howlanguage is used in the food domain, and we di-rect our investigation using external variables suchas restaurant menu prices.We build on a thread of NLP research that seekslinguistic understanding by predicting real-worldquantities from text data.
Recent examples includeprediction of stock volatility (Kogan et al 2009)and movie revenues (Joshi et al 2010).
There, pre-diction tasks were used for quantitative evaluationand objective model comparison, while analysis oflearned models gave insight about the social processbehind the data.We echo this pattern here as we turn our atten-tion to language use on restaurant menus and in userrestaurant reviews.
We use data from a large cor-pus of restaurant menus and reviews crawled fromthe web and formulate several prediction tasks.
Inaddition to predicting menu prices, we also considerpredicting sentiment along with price.The relationship between language and senti-ment is an active area of investigation (Pang andLee, 2008).
Much of this research has focused oncustomer-written reviews of goods and services, andperspectives have been gained on how sentiment isexpressed in this type of informal text.
In additionto sentiment, however, other variables are reflectedin a reviewer?s choice of words, such as the price ofthe item under consideration.
In this paper, we takea step toward joint modeling of multiple variablesin review text, exploring connections between priceand sentiment in restaurant reviews.Hence this paper contributes an exploratory data1357analysis of language used to describe food (by itspurveyors and by its consumers).
While our primarygoal is to understand the language used in our cor-pus, our findings bear relevance to economics andhospitality research as well.
This paper is a step onthe way to the eventual goal of using linguistic anal-ysis to understand social phenomena like sales andconsumption.2 Related WorkThere are several areas of related work scatteredthroughout linguistics, NLP, hospitality research,and economics.Freedman and Jurafsky (2011) studied the use oflanguage in food advertising, specifically the wordson potato chip bags.
They argued that, due tothe ubiquity of food writing across cultures, eth-nic groups, and social classes, studying the use oflanguage for describing food can provide perspec-tive on how different socioeconomic groups self-identify using language and how they are linguisti-cally targeted.
In particular, they showed that priceaffects how ?authenticity?
is realized in marketinglanguage, a point we return to in ?5.
This is an ex-ample of how price can affect how an underlyingvariable is expressed in language.
Among other ex-plorations in this paper, we consider how price inter-acts with expression of sentiment in user reviews ofrestaurants.As mentioned above, our work is related to re-search in predicting real-world quantities using textdata (Koppel and Shtrimberg, 2006; Ghose et al2007; Lerman et al 2008; Kogan et al 2009; Joshiet al 2010; Eisenstein et al 2010; Eisenstein etal., 2011; Yogatama et al 2011).
Like much ofthis prior work, we aim to learn how language isused in a specific context while building models thatachieve competitive performance on a quantitativeprediction task.Along these lines, there is recent interest in ex-ploring the relationship between product sales anduser-generated text, particularly online product re-views.
For example, Ghose and Ipeirotis (2011)studied the sales impact of particular properties ofreview text, such as readability, the presence ofspelling errors, and the balance between subjectiveand objective statements.
Archak et al(2011) had asimilar goal but decomposed user reviews into partsdescribing particular aspects of the product beingreviewed (Hu and Liu, 2004).
Our paper differsfrom price modeling based on product reviews inseveral ways.
We consider a large set of weakly-related products instead of a homogeneous selectionof a few products, and the reviews in our dataset arenot product-centered but rather describe the overallexperience of visiting a restaurant.
Consequently,menu items are not always mentioned in reviews andrarely appear with their exact names.
This makes itdifficult to directly use review features in a pricingmodel for individual menu items.Menu planning and pricing has been studied formany years by the culinary and hospitality researchcommunity (Kasavana and Smith, 1982; Kelly et al1994), often including recommendations for writingmenu item descriptions (Miller and Pavesic, 1996;McVety et al 2008).
Their guidelines frequentlyinclude example menus from successful restaurants,but typically do not use large corpora of menus orautomated analysis, as we do here.
Other workfocused more specifically on particular aspects ofthe language used on menus, such as the study byZwicky and Zwicky (1980), who made linguistic ob-servations through manual analysis of a corpus of200 menus.Relatedly, Wansink et al(2001; 2005) showedthat the way that menu items are described af-fects customers?
perceptions and purchasing behav-ior.
When menu items are described evocatively,customers choose them more often and report highersatisfaction with quality and value, as compared towhen they are given the same items described withconventional names.
Wansink et aldid not use acorpus, but rather conducted a small-scale experi-ment in a working cafeteria with customers and col-lected surveys to analyze consumer reaction.
Whileour goals are related, our experimental approach isdifferent, as we use automated analysis of thousandsof restaurant menus and rely on a set of one mil-lion reviews as a surrogate for observing customerbehavior.Finally, the connection between products andprices is also a central issue in economics.
How-ever, the stunning heterogeneity in products makesempirical work challenging.
For example, there areover 50,000 menu items in New York that include1358City # Restaurants # Menu Items # Reviewstrain dev.
test train dev.
test train dev.
testBoston 930 107 113 63,422 8,426 8,409 80,309 10,976 11,511Chicago 804 98 100 51,480 6,633 6,939 73,251 9,582 10,965Los Angeles 624 80 68 17,980 2,938 1,592 75,455 13,227 5,716New York 3,965 473 499 365,518 42,315 45,728 326,801 35,529 37,795Philadelphia 1,015 129 117 83,818 11,777 9,295 52,275 7,347 5,790San Francisco 1,908 255 234 103,954 12,871 12,510 499,984 59,378 67,010Washington, D.C. 773 110 121 47,188 5,957 7,224 71,179 11,852 14,129Total 10,019 1,252 1,252 733,360 90,917 91,697 1,179,254 147,891 152,916Table 1: Dataset statistics.the word chicken.
What is the price of chicken?
Thisis an important practical and daunting matter whenmeasuring inflation (e.g., Consumer Price Index ismeasured with a precisely-defined basket of goods).Price dispersion across goods and the variation ofthe goods is an important area of industrial organi-zation economic theory.
For example, economistsare interested in models of search, add-on pricing,and obfuscation (Baye et al 2006; Ellison, 2005).3 DataWe crawled Allmenus.com (www.allmenus.com) to gather menus for restaurants in sevenU.S.
cities: Boston, Chicago, Los Angeles, NewYork, Philadelphia, San Francisco, and Washing-ton, D.C. Each menu includes a list of item nameswith optional text descriptions and prices.
Most All-menus restaurant pages contain a link to the cor-responding page on Yelp (www.yelp.com) withmetadata and user reviews for the restaurant, whichwe also collected.The metadata consist of many fields for eachrestaurant, which can be divided into three cate-gories: location (city, neighborhood, transit stop),services available (take-out, delivery, wifi, parking,etc.
), and ambience (good for groups, noise level,attire, etc.).
Also, the category of food and a pricerange ($ to $$$$, indicating the price of a typicalmeal at the restaurant) are indicated.
The user re-views include a star rating on a scale of 1 to 5.The distribution of prices of individual menuitems is highly skewed, with a mean of $9.22 buta median of $6.95.
On average, a restaurant has73 items on its menu with a median price of $8.69and 119 Yelp reviews with a median rating of 3.55???????
?0100k200k300k400k500kstar rating???????
??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?01k2k3k4k5k$$$$$$price range????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?????????????????????????
?01k2k3k4k5k$$$$$$price range????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????
?????????????????????????
?01k2k3k4k5k$$$$$price range?
????????????????????????????
? ???????????????????????????????????????????????????????????????????????????????????????????????????????????????????
???????
? ???????
?Figure 1: Frequency distributions of restaurant priceranges (left) and review ratings (right).stars.
The star rating and price range distributionsare shown in Figure 1.The set of restau ts was randomly split intothree parts (80% for training, 10% for development,10% for evaluation), independently for each city.The sizes of the splits and the full set of datasetstatistics are provided in Table 1.4 Predictive TasksWe consider several prediction tasks using thedataset just described.
These include predictingindividual menu item prices (?5), predicting theprice range for each restaurant (?6), and finallyjointly predicting median price and sentiment foreach restaurant (?7).
To do this, we use two typesof models: linear regression (?5 and ?6) and logis-tic regression (?7), both with `1 regularization whensparsity is desirable.
We tune the regularization co-efficient by choosing the value that minimizes de-velopment set loss (mean squared error and log loss,respectively).For evaluation, we use mean absolute error(MAE) and mean relative error (MRE).
Given adataset ?xi, yi?Ni=1 with inputs xi and outputs yi, and1359denoting predicted outputs by y?i, these are definedas follows:MAE =1NN?i=1|yi ?
y?i|MRE =1NN?i=1???
?yi ?
y?iyi???
?In practice, since we model log-prices but eval-uate on real prices, the final prediction is often anon-linear transformation of the output of the linearclassifier of weight vector w, which we denote by:y?i = f(w>xi).We also frequently report the total number of fea-tures available in the training set for each model (nf)as well as the number of non-zero feature weightsfollowing learning (nnz).5 Menu Item Price PredictionWe first consider the problem of predicting the priceof each item on a menu.
In this case, every in-stance xi corresponds to a single item in the menuparametrized by the features detailed below and yi isthe item?s price.
In this section, our models alwaysuse the logarithm of the price1 as output values andtherefore: y?i = ew>xi .Baselines We evaluate several baselines whichmake independent predictions for each distinct itemname.
The first two predict the mean or the me-dian of the prices in the training set for a givenitem name, and use the overall price mean or me-dian when a name is missing in the training set.
Thethird baseline is an `1-regularized linear regressionmodel trained with a single binary feature for eachitem name in the training data.
These baselines areshown as the first three rows in Table 2.We note that there is a wide variation of menuitem names in the dataset, with more than 400,000distinct names.
Although we address this issue laterby introducing local text features, we also performedsimple normalization of the item names for all ofthe baselines described above.
To do this normal-ization, we first compiled a stop word list based onthe most frequent words in the item names.2 We1The price distribution is more symmetric in the log domain.2This list can be found in the supplementary material.removed stop words and then ordered the words ineach item name lexicographically, in order to col-lapse together items such as coffee black and blackcoffee.
This normalization reduced the unique itemname count by 40%, strengthening the baselines.5.1 FeaturesWe use `1-regularized linear regression for feature-rich models.
We now introduce several sets of fea-tures that we add to the normalized item names:3I.
METADATA: Binary features for each restaurantmetadata field mentioned above, excluding pricerange.
A separate binary feature is included foreach unique ?field, value?
tuple.II.
MENUNAMES: n-grams in menu item names.We used binary features for unique unigrams, bi-grams, and trigrams.
Here, stop words were re-tained as they can be informative (e.g., with andlarge correlate with price).III.
MENUDESC: n-grams in menu item descrip-tions, as in MENUNAMES.Review Features In addition to these features, weconsider leveraging the large amount of text presentin user reviews to improve predictions.
We at-tempted to find mentions of menu items in the re-views and to include features extracted from the sur-rounding words in the model.
Perfect item mentionsbeing relatively rare, we consider inexact matchesweighted by a coefficient measuring the degree ofresemblance: we used the Dice similarity betweenthe set of words in the sentence and in the item name.We then extracted n-gram features from this sen-tence, and tried several ways to use them for priceprediction.Given a review sentence, one option is to add thecorresponding features to every item matching thissentence, with a value equal to the similarity coeffi-cient.
Another option is to select the best matchingitem and use the same real-valued features but onlyfor this single item.
Binary feature values can beused instead of the real-valued similarity coefficient.We also experimented with the use of part-of-speechtags in order to restrict our features to adjective andadverb n-grams instead of the full vocabulary.
All of3The normalized item names are present as binary featuresin all of our regression models1360MAE MRE nf nnzPredict mean 3.70 43.32 n/a n/aPredict median 3.67 43.93 n/a n/aRegression 3.66 45.64 267,945 240,139METADATA 3.55 43.11 268,450 258,828P?R 3.47 43.11 267,946 205,176MENUNAMES 3.23 38.33 896,631 230,840+ MENUDESC 3.19 36.23 1,981,787 151,785+ P?R 3.08 34.51 1,981,788 140,954+ METADATA 3.08 34.97 1,982,363 148,774+ MENTIONS 3.06 34.37 4,959,488 458,462Table 2: Results for menu item price prediction.
MAE =mean absolute error ($), MRE = mean relative error (%),nf = total number of features, nnz = number of featureswith non-zero weight.these attempts yielded negative or only slightly pos-itive results, of which we include only one examplein our experiments: the MENTIONS feature set con-sists of n-grams for the best matching item with theDice coefficient as the feature value.We also tried to incorporate the reviews by usingthem in aggregate via predictions from a separatemodel; we found this approach to work better thanthe methods described above which all use featuresfrom the reviews directly in the regression model.
Inparticular, we use the review features in a separatemodel that we will describe below (?6) to predictthe price range of each restaurant.
The model usesunigrams, bigrams, and trigrams extracted from thereviews.
We use the estimated price range (which wedenote P?R) as a single additional real-valued featurefor individual item price prediction.5.2 ResultsOur results are shown in Table 2.
We achieve a fi-nal reduction of 50 cents in MAE and nearly 10%in MRE compared with the baselines.
Using menuname features (MENUNAMES) brings the bulk ofthe improvement, though menu description features(MENUDESC) and the remaining features also leadto small gains.
Interestingly, as the MENUDESC andP?R features are added to the model, the regulariza-tion favors more general features by selecting fewerand fewer non-zero weights.While METADATA features improve over thebaselines when used alone, they do not lead to im-proved performance over the MENU* + P?R features,suggesting that the text features may be able to sub-stitute for the information in the metadata, at leastfor prediction of individual item prices.The MENTIONS features resulted in a small im-provement in MAE and MRE, but at the cost of ex-panding the model size significantly.
A look at thelearned feature weights reveals that most of the se-lected features seem more coincidental than generic(rachel?s, highly negative) when not totally unintu-itive (those suicide, highest positive).
This suggeststhat our method of extracting features from men-tions is being hampered by noise.
We suspect thatthese features could be more effective with a bettermethod of linking menu items to mentions in reviewtext.5.3 AnalysisWe also inspected the feature weights of our learnedmodels.
By comparing the weights of related fea-tures, we can see the relative differences in termsof contribution to menu item prices.
Table 3 showsexample feature weights, manually arranged intoseveral categories (taken from the model with ME-NUNAMES + MENUDESC + P?R + METADATA).Table 3(a) shows selected features for the ?am-bience?
field in the Yelp restaurant metadata andpane (b) lists some unigrams related to cookingmethods.
Pane (c) shows feature weights for n-grams often used to market menu items; we seelarger weights for words targeting those who want toeat organically- or locally-grown food (farmhouse,heirloom, wild, and hormone), compared to thoselooking for comfort food (old time favorite, tradi-tional, real, and fashioned).
This is related to ob-servations made by Freedman and Jurafsky (2011)that cheaper food is marketed by appealing to tra-dition and historicity, with more expensive food de-scribed in terms of naturalness, quality of ingredi-ents, and the preparation process (e.g., hand picked,wild caught, etc.).
Relatedly, in pane (e) we seethat real mashed potatoes are expected to be cheaperthan those described as creamy or smooth.Pane (d) shows feature weights for trigrams con-taining units of chicken; we can see an ordering interms of size (bits < cubes < strips < cuts) as wellas the price increase associated with the use of theword morsels in place of less refined units.
We alsosee a difference between pieces and pcs, with thelatter being frequently used to refer to entire cuts of1361(a) METADATA: (c) MENUDESC:ambience descriptorsdive-y -0.015 old time favorite -0.112intimate -0.013 fashioned -0.034trendy -0.012 line caught -0.028casual -0.005 all natural -0.028romantic -0.004 traditional -0.009classy -7e-6 natural 3e-4touristy 0.058 classic 0.002upscale 0.099 free range 0.004(b) MENUDESC: real 0.004cooking fresh 0.006panfried -0.094 homemade 0.010chargrilled -0.029 authentic 0.012cooked -0.012 organic 0.020boiled -0.006 specialty 0.025fried -0.005 special 0.033steamed 0.011 locally 0.037charbroiled 0.015 natural grass fed 0.038grilled 0.022 artisanal 0.064simmered 0.025 raised 0.066roasted 0.034 heirloom 0.083sauteed 0.034 wild 0.084broiled 0.053 hormone 0.085seared 0.066 farmed 0.099braised 0.068 hand picked 0.101stirfried 0.071 wild caught 0.116flamebroiled 0.106 farmhouse 0.133(d) MENUDESC: (e) MENUDESC:= ?of chicken?
= ?potatoes?slices -0.102 real mashed -0.028bits -0.032 mashed -0.005cubes -0.030 creamy mashed -5e-9pieces -0.024 smashed 0.018strips -0.001 smooth mashed 0.129chunks 0.015 (f) MENUDESC:morsels 0.025 = ?potato?pcs 0.040 mash -0.022cuts 0.042 mashed -0.019(g) MENUDESC: ?crisp?
vs. ?crispy?crisp -0.022 crispy bacon 0.008crispy -0.011 crisp bacon 0.033(h) MENUDESC: ?roast?
vs. ?roasted?roasted 0.034 roasted potatoes 0.026roast 0.040 roast potatoes 0.110roasted chicken -0.041 roasted salmon 0.091roast chicken -0.012 roast salmon 0.151roast pork -0.038 roasted tomato 0.010roasted pork 0.055 roast tomato 0.026Table 3: Selected features from model for menu itemprice prediction.
See text for details.chicken (e.g., wings, thighs, etc.)
and the formermore often used as a synonym for chunks.Panes (f), (g), and (h) reveal price differences dueto slight variations in word form.
We find that, eventhough crispy has a higher weight than crisp, crispbacon is more expensive than crispy bacon.
We alsofind that food items prefixed with roast lead to moreexpensive prices than the similar roasted, except inthe case of pork, though here the different forms maybe evoking two different preparation styles.Also of note is the slight difference betweenthe nonstandard mash potato and mashed potato.We observed lower weights with other nonstandardspellings, notably portobella having lower weightthan each of the more common spellings portabella,portobello, and portabello.6 Restaurant Price Range PredictionIn addition to predicting the prices of individualmenu items, we also considered the task of predict-ing the price range listed for each restaurant on itsYelp page.
The values for this field are integers from1 to 4 and indicate the price of a typical meal fromthe restaurant.For this task, we again train an `1-regularizedlinear regression model with integral price rangesas the true output values yi.
Each input xi corre-sponds to the feature vector for an entire restaurant.For evaluation, we round the predicted values to thenearest integer: y?i = ROUND(w>xi) and report thecorresponding mean absolute error and accuracy.We compared this simple approach with an or-dinal regression model (McCullagh, 1980) trainedwith the same `1 regularizer and noted very little im-provement (77.32% vs. 77.15% accuracy for META-DATA).
Therefore, we only report in this section re-sults for the linear regression model.In addition to the feature sets used for individ-ual menu item price prediction, we used features onreviews (REVIEWS).
Specifically, we used binaryfeatures for unigrams, bigrams, and trigrams in thefull set of reviews for each restaurant.
A stopwordlist was derived from the training data.4 Bigramsand trigrams were filtered if they ended with stop-words.
Additionally, features occurring fewer thanthree times in the training set were discarded.4This list is included in the supplementary material.1362Features MAE Acc.
nf nnzPredict mode 0.5421 48.22 n/a n/aMENU* 0.3875 66.29 1,910,622 995METADATA 0.2372 77.15 591 219REVIEWS 0.2172 79.76 3,027,470 1,567+METADATA 0.2111 80.36 3,027,943 1,376Table 4: Results for restaurant price range prediction.MAE = mean absolute error, Acc = classification accu-racy (%), nf = total number of features, nnz = number offeatures with non-zero weight.6.1 ResultsOur results for price range prediction are shownin Table 4.
Predicting the most frequent pricerange gave us an accuracy of 48.22%.
Performanceimprovements were obtained by separately addingmenu (MENU*), metadata (METADATA), and re-view features (REVIEWS).
Unlike individual itemprice prediction, the reviews were more helpful thanthe menu features for predicting overall price range.This is not surprising, since reviewers will often gen-erally discuss price in their reviews.
We combinedmetadata and review features to get our best accu-racy, exceeding 80%.We also wanted to perform an analysis of senti-ment in the review text.
To do this, we trained a lo-gistic regression model predicting polarity for eachreview; we used the REVIEWS feature set, but thistime considering each review as a single training in-stance.
The polarity of a review was determined bywhether or not its star rating was greater than theaverage rating across all reviews in the dataset (3.7stars).
We achieved an accuracy of 87% on the testdata.
We omit full details of these models becausethe polarity prediction task for user reviews is well-known in the sentiment analysis community and ourmodel is not an innovation over prior work (Pangand Lee, 2008).
However, our purpose in trainingthe model was to use the learned weights for under-standing the text in the reviews.6.2 Interpreting ReviewsGiven learned models for predicting a restaurant?sprice range from its set of reviews as well as polar-ity for each review, we can turn the process aroundand use the feature weights to analyze the reviewtext.
Restricting our attention to reviews of 50?60words, Table 5 shows sample reviews from our testset that lead to various predictions of price range andsentiment.5This technique can also be useful when trying todetermine the ?true?
star rating for a review (if pro-vided star ratings are noisy), or to show the mostpositive and most negative reviews for a productwithin a particular star rating.
The 5-point scaleis merely a coarse approximation to the reviewer?smental state; using fitted models can provide addi-tional clues to decode the reviewer?s sentiment.We can also do a more fine-grained analysis ofreview text by noting the contribution to the pricerange prediction of each position in the text stream.This is straightforward because our features are sim-ply n-grams of the review text.
In Figure 2, we showthe influence of each word in a review sentence onthe predicted polarity (brown) and price range (yel-low).
The height of a bar at a given position is pro-portional to the sum of the feature weights for everyunigram, bigram, and trigram containing the tokenat that position (there are at most 6 active n-gramsat a position).The first example shows the smooth shift in ex-pressed sentiment from the beginning of the sen-tence to the end.
The second sentence is a difficultexample for sentiment analysis, since there are sev-eral positive words and phrases early but the senti-ment is chiefly expressed in the final clause.
Ourmodel noted the steady positive sentiment early inthe sentence but identified the crucial negation dueto strong negative weight on bigrams fresh but, leftme, and me yearning.
In both examples, the yellowbars show that price estimates are reflected mainlythrough isolated mentions of offerings and ameni-ties (drinks, atmosphere, security, good service).7 Joint Prediction of Price and SentimentAlthough we observe no interesting correlation (r =0.06) between median star rating and median itemprice in our dataset, this does not imply that senti-5To choose the 9 reviews in the table, we took the reviewsfrom our test set in the desired length range and computed pre-dicted sentiment and price range for each; then we scaled thepredicted price range so that its range matched that of predictedsentiment, and maximized various linear combinations of thetwo.
This accounts for the four corners.
The others were foundby maximizing a linear combination of one (possibly negated)prediction minus the absolute value of the other.1363?
cheap expensive??
?i love me a cheap vietnamese sandwich .mmm , pate .
this place has the best ones i?ve had in the city , and i conveniently livea few blocks away .
the ladies behind thecounter are always courteous and fast , andwho can beat a $ 3 sandwich ?!
crazy assdeli .this place is tiny !
the pork buns are so tenderand flavorful .
i dream about these things .manila clams were awesome , not the biggestclam fan either , but i loved it .
mmm 7 spicechips .
i ca n?t wait to go back !amazing service and desserts .
nice winelist and urban decor .
i went with a girl-friend and we split an entree , appetizer anddessert and they happily brought us separateportions which were just the right size .
thebread is awesome , too .
definitely a bit of asplurge , but worth it in moderation .great place to get fast food that tastes good .paneer and chicken are both good .
i wouldprefer to go thursday thru saturday night .thats when they have their good shift work-ing .
also it stays open late until 4 am onweekends .
really enjoyable !had some solid thai here for lunch last week.
ordered the special of the day , a chickencurry .
quick service and nice interior .
onlyissue was , had a bit of a stomach ache after-wards ?
prefer their sister restaurant , citizenthai and the monkey , in north beach .weekday evening was quiet , not every ta-ble was filled .
our waiter was amicable andfriendly , which is always a plus .
the co-conut bread pudding was ok and very sweet.
it ?s definitely a dessert plate that can beshared with a glass of wine .
?for some reason my friend wanted me togo here with him .
it was a decent standardgreasy slice of pizza .
it was n?t bad by anymeans , but it was nothing special at all .on the plus side , cheap and fast .
so insummary : cheap , fast , greasy , average .ugh !
the salt !
all 5 dishes we ordered wereso unbearably salty , i ?d rather just have themsg .
greasy , oily , salty - there is muchbetter chinese food to be had in sf than here .i was very disappointed and wo n?t be back .downhill alert ... had a decent lunch atdragon well this week marred by prettyspotty service .
our waiter just did n?t haveit together , forgetting to bring bowls for oursplit soup , our beverages , etc.
.
food wasgood but pretty pricey for what we got .Table 5: Reviews from the test set deemed by our model to have particular values of sentiment and price.this place gets 5 stars for food , drinks , and atmosphere ... and negative stars for the jar-headed douche bag `` security guards ''thisplacegets5starsforfood,drinks, andatmosphere... andnegative starsfor the jar-headeddouchebag``securityguards''this place gets 5 stars for food , drinks , and atmosphere ... and negative stars for the jar-headed douche bag `` security guards ''great dark , sexy atmosphere .
good service .
nice variety of tasty cocktails .
sushi tasted good , food was fresh but nothing left me yearning to returngreatdark,sexyatmosphere.goodservice.nicevariety oftastycocktails .sushitastedgood,foodwasfreshbutnothingleftmeyearningtoreturngreat dark , sexy atmosphere .
good service .
nice variety of tasty cocktails .
sushi tasted good , food was fresh but nothing left me yearning to returnFigure 2: Local (position-level) sentiment (brown) and price (yellow) estimates for two sentences in the test corpus.ment and price are independent of each other.6 Wetry to capture this interaction by modeling at thesame time review polarity and item price: we con-sider the task of jointly predicting aggregate senti-ment and price for a restaurant.For every restaurant in our dataset, we computeits median item price p?
and its median star ratingr?.
The average of these two values for the entiredataset ($8.69 and 3.55 stars) split the plane (p?, r?
)in four sections: we assign each restaurant to one ofthese quadrants which we denote ?
, ?
?, ?
and?
?.
This allows us to train a 4-class logistic regres-6Price and sentiment are both endogenous outcomes reflect-ing the characteristics of the restaurant.
E.g., ?better?
restau-rants can charge higher prices.sion model using the REVIEWS feature set for eachrestaurant.
We achieve an accuracy of 65% on thetest data, but we are mainly interested in interpret-ing the estimated feature weights.7.1 AnalysisTo visualize the top feature weights learned by themodel, we have to map the four weight vectorslearned by the model back to the underlying two-dimensional sentiment/price space.
Therefore, wecompute the following values:w$ = (w??
+ w?
)?
(w??
+ w?
)wF = (w??
+ w??)?
(w?
+ w?
)1364We then select for display the features which are thefurthest from the origin (maxw2$ + w2F) and rep-resent the selected n-grams as points in the senti-ment/price space to obtain Figure 3.We notice that the spread of the sentiment valuesis larger, which suggests that reviews give strongerclues about consumer experience than about the costof a typical meal.
However, obvious price-relatedadjectives (inexpensive vs. expensive) appear in thislimited selection, as well as certain phrases indicat-ing both sentiment and price (overpriced vs. veryreasonable).
Other examples of note: gem is used instrongly-positive reviews of cheap restaurants; forexpensive restaurants, reviewers use highly recom-mended or amazing.
Also, phrases like no flavor andmanager appear in negative reviews of more expen-sive restaurants, while dirty appears more often innegative reviews of cheaper restaurants.8 ConclusionWe have explored linguistic relationships betweenfood prices and customer sentiment through quan-titative analysis of a large corpus of menus and re-views.
We have also proposed visualization tech-niques to better understand what our models havelearned and to see how they can be applied to newdata.
More broadly, this paper is an example of us-ing extrinsic variables to drive model-building forlinguistic data, and future work might explore richerextrinsic variables toward a goal of task-driven no-tions of semantics.AcknowledgmentsWe thank Julie Baron, Ric Crabbe, David Garvett, LauraGimpel, Chenxi Jiao, Elaine Lee, members of the ARKresearch group, and the anonymous reviewers for helpfulcomments that improved this paper.
This research wassupported in part by the NSF through CAREER grant IIS-1054319 and Sandia National Laboratories (fellowship toK.
Gimpel).ReferencesN.
Archak, A. Ghose, and P. G. Ipeirotis.
2011.
Deriv-ing the pricing power of product features by miningconsumer reviews.
Management Science, 57(8).M.
R. Baye, J. Morgan, and P. Scholten.
2006.
Eco-nomics and information systems; handbooks in infor-mation systems.
In T. Hendershott, editor, Judgementunder Uncertainty: Heuristics and Biases.
Elsevier,Amsterdam.J.
Eisenstein, B. O?Connor, N. A. Smith, and E. P. Xing.2010.
A latent variable model for geographic lexicalvariation.
In Proc.
of EMNLP.J.
Eisenstein, N. A. Smith, and E. P. Xing.
2011.
Discov-ering sociolinguistic associations with structured spar-sity.
In Proc.
of ACL.G.
Ellison.
2005.
A model of add-on pricing.
QuarterlyJournal of Economics, 120(2):585?637, May.J.
Freedman and D. Jurafsky.
2011.
Authenticity inAmerica: Class distinctions in potato chip advertising.Gastronomica, 11(4):46?54.A.
Ghose and P. G. Ipeirotis.
2011.
Estimating the help-fulness and economic impact of product reviews: Min-ing text and reviewer characteristics.
IEEE Transac-tions on Knowledge and Data Engineering, 23(10).A.
Ghose, P. G. Ipeirotis, and A. Sundararajan.
2007.Opinion mining using econometrics: A case study onreputation systems.
In Proc.
of ACL.M.
Hu and B. Liu.
2004.
Mining opinion features incustomer reviews.
In Proc.
of AAAI.M.
Joshi, D. Das, K. Gimpel, and N. A. Smith.
2010.Movie reviews and revenues: An experiment in textregression.
In Proc.
of NAACL.M.
L. Kasavana and D. I. Smith.
1982.
Menu Engineer-ing: A Practical Guide to Menu Analysis.
HospitalityPublications.T.
J. Kelly, N. M. Kiefer, and K. Burdett.
1994.
Ademand-based approach to menu pricing.
Cornell Ho-tel and Restaurant Administrative Quarterly, 35(1).S.
Kogan, D. Levin, B. R. Routledge, J. Sagi, and N. A.Smith.
2009.
Predicting risk from financial reportswith regression.
In Proc.
of NAACL.M.
Koppel and I. Shtrimberg.
2006.
Good news or badnews?
let the market decide.
Computing Attitude andAffect in Text: Theory and Applications.K.
Lerman, A. Gilder, M. Dredze, and F. Pereira.
2008.Reading the markets: Forecasting public opinion ofpolitical candidates by news analysis.
In Proc.
ofCOLING.P.
McCullagh.
1980.
Regression models for ordinaldata.
Journal of the royal statistical society.
Series B(Methodological), pages 109?142.P.
J. McVety, B. J. Ware, and C. L. Ware.
2008.
Funda-mentals of Menu Planning.
John Wiley & Sons.J.
E. Miller and D. V. Pavesic.
1996.
Menu: Pricing &Strategy.
Hospitality, Travel, and Tourism Series.
JohnWiley & Sons.B.
Pang and L. Lee.
2008.
Opinion mining and senti-ment analysis.
Foundations and Trends in InformationRetrieval, 2(1-2):1?135.1365pastaamazinglove this placeca n'twaitincrediblegreatfoodcalamariflavorlessawesometastelesseveryonesuper friendlyhandsdownn't waithighlyno flavorhighly recommendbarworstterriblecountergemawfuldisgustingoverpricedinexpensiveworsenot worthmediocrehorriblerudericeedibledirtyexpensiveveryreasonablefriendly staffappetizerfantasticgo-toshould havedefinitely be backwastelocationtwo starsnever gogrosswinehighly recommendedhighly recommendedmanagercalamarievryoneno flavorbarexpensiveappetizerfantasticshould havewastelocationtwo starsnever gogrosswinemanageramazinglove this placeca n'twaitincrediblegreatfoodawesomesuper friendlyhandsdownn't waithighlyhighly recommendveryreasonablefriendly staffgo-todefinitely be backpositivecheap expensivenegativeFigure 3: Top 50 features from joint prediction of price and sentiment.
The black circle is the origin.
See text fordetails on how the coordinates for each feature were computed.
Insets show enlargements of dense areas of the graph.1366B.
Wansink, J. E. Painter, and K. van Ittersum.
2001.Descriptive menu labels?
effect on sales.
Cornell Ho-tel and Restaurant Administrative Quarterly, 42(6).B.
Wansink, K. van Ittersum, and J. E. Painter.
2005.How descriptive food names bias sensory perceptionsin restaurants.
Food Quality and Preference, 16(5).D.
Yogatama, M. Heilman, B. O?Connor, C. Dyer, B. R.Routledge, and N. A. Smith.
2011.
Predicting a sci-entific community?s response to an article.
In Proc.
ofEMNLP.A.
D. Zwicky and A. M. Zwicky.
1980.
America?s na-tional dish: The style of restaurant menus.
AmericanSpeech, 55(2):83?92.1367
