Proceedings of the ACL Student Research Workshop, pages 115?120,Ann Arbor, Michigan, June 2005. c?2005 Association for Computational LinguisticsLearning Information Structure in The Prague TreebankOana PostolacheDepartment of Computational LinguisticsUniversity of Saarland, Saarbru?cken, Germanyoana@coli.uni-sb.deAbstractThis paper investigates the automaticidentification of aspects of InformationStructure (IS) in texts.
The experimentsuse the Prague Dependency Treebankwhich is annotated with IS following thePraguian approach of Topic Focus Artic-ulation.
We automatically detect t(opic)and f(ocus), using node attributes fromthe treebank as basic features and derivedfeatures inspired by the annotation guide-lines.
We show the performance of C4.5,Bagging, and Ripper classifiers on sev-eral classes of instances such as nouns andpronouns, only nouns, only pronouns.
Abaseline system assigning always f(ocus)has an F-score of 42.5%.
Our best systemobtains 82.04%.1 IntroductionInformation Structure (IS) is a partitioning of thecontent of a sentence according to its relation tothe discourse context.
There are numerous the-oretical approaches describing IS and its seman-tics (Halliday, 1967; Sgall, 1967; Vallduv?
?, 1990;Steedman, 2000) and the terminology used is di-verse (see (Kruijff-Korbayova?
& Steedman, 2003)for an overview).
However, all theories considerat least one of the following two distinctions: (i)a topic/focus1 distinction that divides the linguis-tic meaning of the sentence into parts that link thecontent to the context, and others that advance thediscourse, i.e.
add or modify information; and (ii)?
We use the Praguian terminology for this distinction.a background/kontrast 2 distinction between parts ofthe utterance which contribute to distinguishing itsactual content from alternatives the context makesavailable.
Existing theories, however, state theirprinciples using carefully selected illustrative exam-ples.
Because of this, they fail to adequately explainwhat possibly different linguistic dimensions coop-erate to realize IS and how they do it.In this paper we report the results of an experi-ment aimed to automatically identify aspects of IS.This effort is part of a larger investigation aimed toget a more realistic view on the realization of IS innaturally occurring texts.For such an investigation, the existence of a cor-pus annotated with some kind of ?informativity sta-tus?
is of great importance.
Fully manual annotationof such a corpus is tedious and time-consuming.
Ourplan is to initially annotate a small amount of dataand then to build models to automatically detect ISin order to apply bootstrapping techniques to createa larger corpus.This paper describes the results of a pilot study;its aim is to check if the idea of learning IS worksby trying it on an already existing corpus.
Forour experiments, we have used the Prague Depen-dency Treebank (PDT) (Hajic?, 1998), as it is theonly corpus annotated with IS (following the theoryof Topic-Focus Articulation).
We trained three dif-ferent classifiers, C4.5, Bagging and Ripper, usingbasic features from the treebank and derived fea-tures inspired by the annotation guidelines.
We haveevaluated the performance of the classifiers against abaseline that simulates the preprocessing procedurethat preceded the manual annotation of PDT, and?
The notion ?kontrast?
with a ?k?
has been introduced in (Vall-duv??
and Vilkuna, 1998) to replace what Steedman calls ?fo-cus?, and to avoid confusion with other definitions of focus.115against a rule-based system which we implementedfollowing the annotation instructions.The organization of the paper is as follows.
Sec-tion 2 describes the Prague Dependency Treebank,Section 3 presents the Praguian approach of Topic-Focus Articulation, from two perspectives: of thetheoretical definition and of the annotation guide-lines that have been followed to annotate the PDT.Section 4 presents the experimental setting, evalua-tion metric and results.
The paper closes with con-clusions and issues for future research (Section 5).2 Prague Dependency TreebankThe Prague Dependency Treebank (PDT) consistsof newspaper articles from the Czech National Cor-pus ( ?Cermaa?k, 1997) and includes three layers ofannotation.
The morphological layer gives a fullmorphemic analysis in which 13 categories aremarked for all sentence tokens (including punctu-ation marks).
The analytical layer, on which the?surface?
syntax (Hajic?, 1998) is annotated, containsanalytical tree structures, in which every token fromthe surface shape of the sentence has a correspond-ing node labeled with main syntactic functions likeSUBJ, PRED, OBJ, ADV.
The tectogrammaticallayer renders the deep (underlying) structure of thesentence (Sgall et al, 1986; Hajic?ova?
et al, 1998).Tectogrammatical tree structures (TGTSs) containnodes corresponding only to the autosemantic wordsof the sentence (e.g., no preposition nodes) and todeletions on the surface level; the condition of pro-jectivity is obeyed, i.e.
no crossing edges are al-lowed; each node of the tree is assigned a functorsuch as ACTOR, PATIENT, ADDRESSEE, ORIGIN,EFFECT, the list of which is very rich; elementarycoreference links are indicated, in the case of pro-nouns.3 Topic Focus Articulation (TFA)The tectogrammatical level of the PDT was moti-vated by the more and more obvious need of largecorpora that treat not only the morphological andsyntactic structure of the sentence but also seman-tic and discourse-related phenomena.
Thus, TGTSshave been enriched with features displaying the in-formation structure of the sentence which is a meansof showing its contextual potential.3.1 TheoryIn the Praguian approach to IS, the content of thesentence is divided in two parts: the Topic is ?whatthe sentence is about?
and the Focus represents theinformation asserted about the Topic.
A prototypicaldeclarative sentence asserts that its Focus holds (ordoes not hold) about its Topic: Focus(Topic) or not-Focus(Topic).The TFA definition uses the distinction betweenContext-Bound (CB) and Non-Bound (NB) parts ofthe sentence.
To distinguish which items are CB andwhich are NB, the question test is applied, (i.e., thequestion for which a given sentence is the appropri-ate answer is considered).
In this framework, weakand zero pronouns and those items in the answerwhich reproduce expressions present (or associatedto those present) in the question are CB.
Other itemsare NB.In example (1), (b) is the sentence under investi-gation, in which CB and NB items are marked, (a)is the context in which the sentence is uttered, and(c) is the question for which the given sentence is anappropriate answer:(1) (a) Tom and Mary both came to John?s party.
(b) JohnCBinvitedCBonlyNBherNB.
(c) Whom did John invite?The following rules determine which lexical items(CB or NB) belong to the Topic or to the Focus(Hajic?ova?
et al, 1998; Hajic?ova?
and Sgall, 2001):1.
The main verb and any of its direct dependentsbelong to the Focus if they are NB;2.
Every item that does not depend directly on themain verb and is subordinated to an element ofFocus belongs to Focus (where ?subordinatedto?
is defined as the irreflexive transitive clo-sure of ?depend on?);3.
If the main verb and all its dependents are CB,then those dependents kiof the verb whichhave subordinated items lmthat are NB arecalled ?proxi foci?
; the items lmtogether withall items subordinated to them belong to Focus,where i,m > 1;4.
Every item not belonging to Focus according to1 ?
3 belongs to Topic.1163.2 Annotation guidelinesWithin PDT, the TFA attribute has been annotatedfor all nodes (including the restored ones) at the tec-togrammatical level.
Instructions for the assignmentof TFA attribute have been specified in (Bura?n?ova?et al, 2000) and are summarized in Table 1.
Theseinstructions are based on the surface word order, theposition of the sentence stress (intonation center ?IC3) and the canonical order of the dependents.The TFA attribute has 3 values: t, for non-contrastive CB items; f, for NB items; and c, forcontrastive CB items.
In this paper, we do notdistinguish between contrastive and non-contrastiveitems, considering both of them as being just t. Inthe PDT annotation, the values t (from topic) and f(from focus) have been chosen to be used because,in the most cases, in prototypical sentences, t itemsbelong to the Topic and f items to the Focus.Before the manual annotation, the corpus hasbeen preprocessed to mark all nodes with the TFAattribute of f, as it is the more common value.
Thenthe annotators changed the value according to theguidelines in Table 1.4 Automatic extraction of TFAIn this section we consider the automatic identifi-cation of t and f using machine learning techniquestrained on the annotated data.The data set consists of 1053 files (970,920words) from the pre-released version of PDT 2.0.4We restrict our experiments by considering onlynoun- and pronoun-nodes.
The total number of in-stances (nouns and pronouns) in the data is 297,220out of which 254,242 (86.54%) are nouns and39,978 (13.46%) are pronouns.
The t/f distributionof these instances is 172,523 f (58.05%) and 124,697t (41.95%).We experimented with three different classifiers,C4.5, Bagging and Ripper, because they are basedon different machine learning techniques (decisiontrees, bagging, rules induction) and we wanted to seewhich of them performs better on this task.
We used?
In the PDT the intonation center is not annotated.
However,the annotators were instructed to use their opinion where theIC is when they utter the sentence.?
We are grateful to our colleagues at the Charles Universityin Prague for providing us the experimental data before thePDT 2.0 official release.Weka implementations of these classifiers (Wittenand Frank, 2000).4.1 FeaturesThe experiments use two types of features: (1) basicfeatures of the nodes taken directly from the tree-bank (node attributes), and (2) derived features in-spired by the annotation guidelines.The basic features are the following (the first 4 areboolean, and 5 and 6 are nominal):1. is-noun: true, if the node is a noun;2. is-root: true, if the node is the root of the tree;3. is-coref-pronoun: true, if the node is a coref-erential pronoun;4. is-noncoref-pronoun: true, if the node isa non-coreferential pronoun (in Czech, manypronouns are used in idiomatic expressions inwhich they do not have an coreferential func-tion, e.g., sve?ho c?asu, lit.
?in its (reflexive)time?, ?some time ago?);5.
SUBPOS: detailed part of speech which differ-entiates between types of pronouns: personal,demonstrative, relative, etc.;6.
functor: type of dependency relations: MOD,MANN, ATT, OTHER.The derived features are computed using the de-pendency information from the tectogrammaticallevel of the treebank and the surface order of thewords corresponding to the nodes5.
Also, we haveused lists of forms of Czech pronouns that are usedas weak pronouns, indexical expressions, pronounswith general meaning, or strong pronouns.
All thederived features have boolean values:7. is-rightmost-dependent-of-the-verb;8. is-rightside-dependent-of-the-verb;9. is-leftside-dependent;10. is-embedded-attribute: true, if the node?s par-ent is not the root;11. has-repeated-lemma: true, in case of nouns,when another node with the same lemma ap-pears in the previous 10 sentences.12.
is-in-canonical-order;13. is-weak-pronoun;14. is-indexical-expression;15. is-pronoun-with-general-meaning;16. is-strong-pronoun-with-no-prep;?
On the tectogramatical level in the PDT, the order of thenodes has been changed during the annotation process of theTFA attribute, so that all t items precede all f items.
Our fea-tures use the surface order of the words corresponding to thenodes.1171.
The bearer of the IC (typically, the rightmost child of the verb) f2.
If IC is not on the rightmost child, everything after IC t3.
A left-side child of the verb (unless it carries IC) t4.
The verb and the right children of the verb before the f-node (cf.
1) that are canonically ordered f5.
Embedded attributes (unless repeated or restored) f6.
Restored nodes t7.
Indexical expressions (ja?
I, ty you, te?d now, tady here), weak pronouns, pronominal expressionswith a general meaning (ne?kdo somebody, jednou once) (unless they carry IC)t8.
Strong forms of pronouns not preceded by preposition (unless they carry IC) tTable 1: Annotation guidelines; IC = Intonation Center4.2 Evaluation frameworkIn order to perform the evaluation, we randomly se-lected 101,054 instances (1/3 of the data) from allthe instances, which represents our test set; the re-maining 2/3 of the data we used as a training set.The same test set is used by all three classifiers.
Inour experiments we have not tweaked the featuresand thus we have not set aside a development set.In the test set 87% of the instances are nouns and13% are pronouns.
The t/f distribution in the test setis as follows: 58% of the instances are t, and 42%instances are f.We have built models using decision trees (C4.5),bagging and rule-induction (Ripper) machine learn-ing techniques to predict the Information Structure.We have also implemented a deterministic, rule-based system that assigns t or f according to the an-notation guidelines presented in Table 1.
The rule-based system does not have access to what intona-tion center (IC) is.The baseline simulates the preprocessing proce-dure used before the manual annotation of TFA at-tribute in the PDT, i.e., assigns always the class thathas the most instances.Our machine learning models are comparedagainst the baseline and the rule-based system.
As ametric we have used the Weighted Averaged F-scorewhich is computed as follows:%_f*F-score_f+%_t*F-score_tThe reason why we have chosen this metric (insteadof Correctly Classified, for example) is that it gives amore realistic evaluation of the system, consideringalso the distribution of t and f items 6.?
Consider, for example, the case in which the test set consistsof 70% f items and 30% t items.
The Baseline system would4.3 ResultsThe results of the experiment using all instances(nouns and pronouns) are shown in Table 2 in thesecond column.
C4.5 and Bagging achieve the bestperformance improving on the results of the rule-based system by 6.99%.The top of the decision tree generated by C4.5 inthe training phase looks like this:is-coref-pronoun = true| is-leftside-dependent = true| | SUBPOS = ...is-coref-pronoun = false| is-leftside-dependent = true| | is-in-canonical-order = trueThe overall tree has 129 leaves out of 161 nodes.In order to achieve a better understanding of thedifficulty of the task for nouns and pronouns, weconsidered evaluations on the following classes ofinstances:?
only nouns;?
nouns that are direct dependents of the verb(verb children);?
nouns that are not direct dependents of the verb(non-verb children);?
only pronouns;?
coreferential pronouns;?
non-coreferential pronouns.We also wanted to investigate if the three classifiersperform differently with respect to different classesof instances (in which case we could have a gen-eral system, that uses more classifiers, and for cer-tain classes of instances we would ?trust?
a certainclassifier, according to its performance on the devel-opment data).have as much as 70% correctly classified instances, just be-cause the t/f distribution is as such.
The Weighted AveragedF-score would be in this case 57.64% which is a more ade-quate value that reflects better the poorness of such a system.118only nouns only pronounsSystems nouns & verb non-verb non-pronouns allchildren children all coref corefBaseline 42.50 51.43 41.90 73.08 81.35 96.94 58.79Rule-based 76.68 75.59 79.09 69.06 82.23 95.51 62.44C4.5 82.04 79.98 80.38 73.87 93.77 97.25 68.60Bagging 82.04 79.97 80.37 73.86 93.71 97.34 68.36Ripper 81.78 79.88 80.31 73.86 93.55 97.35 68.36Table 2: Overall results: Weighted Averaged F-score as percentageTable 2, in columns three and onwards, shows theresults on different classes of instances.
The test setfor each class of instances represents 1/3 randomlyextracted instances from all instances in the data be-longing to that class, in the same fashion as for theoverall split.The baseline is higher for some classes, yet theclassifiers perform always better, even than the rule-based system, which for non-verb children performsworse than the baseline.
However, the difference be-tween the three classifiers is very small, and only inone case (for the coreferential pronouns) C4.5 is out-performed by Ripper.To improve the results even more, there are twopossibilities: either providing more training data, orconsidering more features.
To investigate the effectof the size of the training data we have computedthe learning curves for the three classifiers.
Figure 1shows the C4.5 learning curve for the overall experi-ment on nouns and pronouns; the learning curves forthe other two classifiers are similar, and not includedin the figure.Figure 1: Learning curve for the C4.5 classifierThe curve is interesting, showing that after only 1%of the training set (1961 instances) C4.5 can alreadyperform well, and adding more training data im-proves the F-score only slightly.
To ensure the initial1% aren?t over-representative of the kind of IS phe-nomena, we experimented with different 1% partsof the training set, and the results were similar.
Wealso did a 10-fold cross validation experiment on thetraining set, which resulted in a Weighted AveragedF-score of 82.12% for C4.5.The slight improvement achieved by providingmore data indicates that improvements are likely tocome from using more features.Table 3 shows the contribution of the two types offeatures (basic and derived) for the experiment withall instances (nouns and pronouns).
For comparisonwe have displayed again the baseline and the rule-based system F-score.XXXXXXXXXXXSystemFeatures Basic Derived AllC4.5 62.82 77.51 82.04Bagging 62.83 77.50 81.99Ripper 62.48 77.28 81.78Rule-based 76.68Baseline 42.50Table 3: Contribution of different features.
F-scoregiven as a percentage.The results show that the model trained only withbasic features performs much better than the base-line, yet it is not as good as the rule-based system.However, removing the basic features completelyand keeping only the derived features considerablylowers the score (by more than 4%).
This indicatesthat adding more basic features (which are easy toobtain from the treebank) could actually improve theresults.119The derived features, however, have the biggest im-pact on the performance of the classifiers.
Yet,adding more sophisticated features that would helpin this task (e.g., coreferentiality for nouns) is diffi-cult because they cannot be computed reliably.5 ConclusionsIn this paper we investigated the problem of learn-ing aspects of Information Structure from annotateddata.
We presented results from a study trying toverify whether Information Structure can be learnedusing mostly syntactic features.
We used the PragueDependency Treebank which is annotated with ISfollowing the Praguian theory of Topic Focus Artic-ulation.
The results show that we can reliably iden-tify t(opic) and f(ocus) with over 82% Weighted Av-eraged F-score while the baseline is at 42%.Issues for further research include, on the onehand, a deeper investigation of the Topic-Focus Ar-ticulation in the Prague Dependency Treebank, byimproving the feature set, considering also the dis-tinction between contrastive and non-contrastive titems and, most importantly, by investigating howwe can use the t/f annotation in PDT (and respec-tively our results) in order to detect the Topic/Focuspartitioning of the whole sentence.On the other hand, we want to benefit from theexperience with the Czech data in order to createan English corpus annotated with Information Struc-ture.
We want to exploit a parallel English-Czechcorpus available as part of the PDT, in order to ex-tract correlations between different linguistic dimen-sions and Topic/Focus in the Czech data and investi-gate how they can be transferred to the English ver-sion of the corpus.ReferencesEva Bura?nova?, Eva Hajic?ova?
& Petr Sgall.
2000.
Tag-ging of very large corpora: Topic-Focus Articulation.Proceedings of the 18th International Conference onComputational Linguistics, COLING 2000, 139-144.Frantis?ek ?Cerma?k.
1997.
Czech National Corpus: ACase in Many Contexts.
International Journal of Cor-pus Linguistics, 2(2):181-197.Jan Hajic?.
1998.
Building a syntactically annotatedcorpus: The Prague Dependency Treebank.
Issuesof valency and Meaning.
Studies in Honor of JarmilaPanevova?, ed.
by E. Hajic?ova?.
Karolinum, Prague.Eva Hajic?ova?, Barbara Partee & Petr Sgall.
1998.
Topic-focus articulation, tripartite structures, and semanticcontent.
Studies in Linguistics and Philosiphy, 71Dordrecht: Kluwer.Eva Hajic?ova?
& Petr Sgall.
2001.
Topic-focus andsalience.
Proceedings of the 39th Annual Meeting ofthe Association for Computational Linguistics, ACL2001, 268-273.
Toulose, France.M.
Halliday.
1967.
Notes on transitivity and theme inEnglish, Part II.
Journal of Linguistic, 3:199-244.Ivana Kruijff-Korbayova?
and Mark Steedman.
2003.Discourse and Information Structure.
Journalof Logic, Language and Information 12:249-259.Kluwer, Amsterdam.Petr Sgall.
1967.
Functional sentence perspective in agenerative description.
Prague Studies in Mathemati-cal Linguistics, 2:203-225.Petr Sgall, Eva Hajic?ova?
& Jarmila Panevova?.
1986.
TheMeaning of the Sentence in Its Semantic and Prag-matic Aspects.
Reidel, Dordrecht.Mark Steedman.
2000.
Information Structure andthe syntax-phonology interface.
Linguistic Inquiry,34:649-689.Enrich Vallduv??.
1990.
The information component.Ph.D Thesis, University of Pennsylvania.Enric Vallduv??
& Maria Vilkuna.
1998.
On rheme andkontrast.
Syntax and Semantics, Vol.
29: The Limitsof Syntax, ed.
by P. Culicover and L. McNally.
Aca-demic Press, San Diego.Ian H. Witten & Eibe Frank.
2000.
Practical MachineLearning Tools and Techniques with Java Implemen-tations.
Morgan Kaufmann, San Francisco.120
