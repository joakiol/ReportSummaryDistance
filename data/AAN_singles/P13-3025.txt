Proceedings of the ACL Student Research Workshop, pages 172?179,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDeepfix: Statistical Post-editing of Statistical Machine Translation UsingDeep Syntactic AnalysisRudolf Rosa and David Marec?ek and Ales?
TamchynaCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostranske?
na?me?st??
25, Prague{rosa,marecek,tamchyna}@ufal.mff.cuni.czAbstractDeepfix is a statistical post-editing sys-tem for improving the quality of statis-tical machine translation outputs.
It at-tempts to correct errors in verb-noun va-lency using deep syntactic analysis and asimple probabilistic model of valency.
Onthe English-to-Czech translation pair, weshow that statistical post-editing of statis-tical machine translation leads to an im-provement of the translation quality whenhelped by deep linguistic knowledge.1 IntroductionStatistical machine translation (SMT) is the cur-rent state-of-the-art approach to machine transla-tion ?
see e.g.
Callison-Burch et al(2011).
How-ever, its outputs are still typically significantlyworse than human translations, containing vari-ous types of errors (Bojar, 2011b), both in lexicalchoices and in grammar.As shown by many researchers, e.g.
Bojar(2011a), incorporating deep linguistic knowledgedirectly into a translation system is often hard todo, and seldom leads to an improvement of trans-lation output quality.
It has been shown that it isoften easier to correct the machine translation out-puts in a second-stage post-processing, which isusually referred to as automatic post-editing.Several types of errors can be fixed by employ-ing rule-based post-editing (Rosa et al 2012b),which can be seen as being orthogonal to the sta-tistical methods employed in SMT and thus cancapture different linguistic phenomena easily.But there are still other errors that cannot be cor-rected with hand-written rules, as there exist manylinguistic phenomena that can never be fully de-scribed manually ?
they need to be handled statis-tically by automatically analyzing large-scale textcorpora.
However, to the best of our knowledge,English Czechgo to the doctor j?
?t k doktorovi dative casego to the centre j?
?t do centra genitive casego to a concert j?
?t na koncert accusative casego for a drink j?
?t na drink accusative casego up the hill j?
?t na kopec accusative caseTable 1: Examples of valency of the verb ?to go?and ?j??t?.
For Czech, the morphological cases ofthe nouns are also indicated.Source: The government spends on the middleschools.Moses: Vla?da utra?c??
str?edn??
s?koly.Meaning: The government destroys the middleschools.Reference: Vla?da utra?c??
za str?edn??
s?koly.Meaning: The government spends on the middleschools.Table 2: Example of a valency error in output ofMoses SMT system.there is very little successful research in statisticalpost-editing (SPE) of SMT (see Section 2).In our paper, we describe a statistical approachto correcting one particular type of English-to-Czech SMT errors ?
errors in the verb-noun va-lency.
The term valency stands for the way inwhich verbs and their arguments are used together,usually together with prepositions and morpholog-ical cases, and is described in Section 4.
Severalexamples of the valency of the English verb ?to go?and the corresponding Czech verb ?j??t?
are shownin Table 1.We conducted our experiments using a state-of-the-art SMT system Moses (Koehn et al 2007).An example of Moses making a valency error istranslating the sentence ?The government spendson the middle schools.
?, adapted from our devel-opment data set.
As shown in Table 2, Mosestranslates the sentence incorrectly, making an er-ror in the valency of the ?utra?cet ?
s?kola?
(?spend ?school?)
pair.
The missing preposition changes themeaning dramatically, as the verb ?utra?cet?
is pol-172ysemous and can mean ?to spend (esp.
money)?
aswell as ?to kill, to destroy (esp.
animals)?.Our approach is to use deep linguistic analysisto automatically determine the structure of eachsentence, and to detect and correct valency errorsusing a simple statistical valency model.
We de-scribe our approach in detail in Section 5.We evaluate and discuss our experiments inSection 6.
We then conclude the paper and pro-pose areas to be researched in future in Section 7.2 Related WorkThe first reported results of automatic post-editingof machine translation outputs are (Simard et al2007) where the authors successfully performedstatistical post-editing (SPE) of rule-based ma-chine translation outputs.
To perform the post-editing, they used a phrase-based SMT system in amonolingual setting, trained on the outputs of therule-based system as the source and the human-provided reference translations as the target, toachieve massive translation quality improvements.The authors also compared the performance of thepost-edited rule-based system to directly using theSMT system in a bilingual setting, and reportedthat the SMT system alone performed worse thanthe post-edited rule-based system.
They then triedto post-edit the bilingual SMT system with anothermonolingual instance of the same SMT system,but concluded that no improvement in quality wasobserved.The first known positive results in SPE of SMTare reported by Oflazer and El-Kahlout (2007)on English to Turkish machine translation.
Theauthors followed a similar approach to Simardet al(2007), training an SMT system to post-edit its own output.
They use two iterations ofpost-editing to get an improvement of 0.47 BLEUpoints (Papineni et al 2002).
The authors useda rather small training set and do not discuss thescalability of their approach.To the best of our knowledge, the best results re-ported so far for SPE of SMT are by Be?chara et al(2011) on French-to-English translation.
The au-thors start by using a similar approach to Oflazerand El-Kahlout (2007), getting a statistically sig-nificant improvement of 0.65 BLEU points.
Theythen further improve the performance of theirsystem by adding information from the sourceside into the post-editing system by concatenat-ing some of the translated words with their sourceDirection Baseline SPE Context SPEen?cs 10.85?0.47 10.70?0.44 10.73?0.49cs?en 17.20?0.53 17.11?0.52 17.18?0.54Table 3: Results of SPE approach of Be?chara et al(2011) evaluated on English-Czech SMT.words, eventually reaching an improvement of2.29 BLEU points.
However, similarly to Oflazerand El-Kahlout (2007), the training data used arevery small, and it is not clear how their methodscales on larger training data.In our previous work (Rosa et al 2012b), weexplored a related but substantially different areaof rule-based post-editing of SMT.
The resultingsystem, Depfix, manages to significantly improvethe quality of several SMT systems outputs, usinga set of hand-written rules that detect and correctgrammatical errors, such as agreement violations.Depfix can be easily combined with Deepfix,1 asit is able to correct different types of errors.3 Evaluation of Existing SPEApproachesFirst, we evaluated the utility of the approach ofBe?chara et al(2011) for the English-Czech lan-guage pair.
We used 1 million sentence pairs fromCzEng 1.0 (Bojar et al 2012b), a large English-Czech parallel corpus.
Identically to the paper, wesplit the training data into 10 parts, trained 10 sys-tems (each on nine tenths of the data) and usedthem to translate the remaining part.
The secondstep was then trained on the concatenation of thesetranslations and the target side of CzEng.
We alsoimplemented the contextual variant of SPE wherewords in the intermediate language are annotatedwith corresponding source words if the alignmentstrength is greater than a given threshold.
We lim-ited ourselves to the threshold value 0.8, for whichthe best results are reported in the paper.
We tunedall systems on the dataset of WMT11 (Callison-Burch et al 2011) and evaluated on the WMT12dataset (Callison-Burch et al 2012).Table 3 summarizes our results.
The reportedconfidence intervals were estimated using boot-strap resampling (Koehn, 2004).
SPE did not leadto any improvements of BLEU in our experiments.In fact, SPE even slightly decreased the score (but1Depfix (Rosa et al 2012b) performs rule-based post-editing on shallow-syntax dependency trees, while Deepfix(described in this paper) is a statistical post-editing systemoperating on deep-syntax dependency trees.173the difference is statistically insignificant in allcases).We conclude that this method does not improveEnglish-Czech translation, possibly because ourtraining data is too large for this method to bringany benefit.
We therefore proceed with a morecomplex approach which relies on deep linguisticknowledge.4 Deep Dependency Syntax, Formemes,and Valency4.1 Tectogrammatical dependency treesTectogrammatical trees are deep syntactic depen-dency trees based on the Functional GenerativeDescription (Sgall et al 1986).
Each node ina tectogrammatical tree corresponds to a contentword, such as a noun, a full verb or an adjec-tive; the node consists of the lemma of the con-tent word and several other attributes.
Functionalwords, such as prepositions or auxiliary verbs, arenot directly present in the tectogrammatical tree,but are represented by attributes of the respectivecontent nodes.
See Figure 1 for an example of twotectogrammatical trees (for simplicity, most of theattributes are not shown).In our work, we only use one of themany attributes of tectogrammatical nodes, calledformeme (Dus?ek et al 2012).
A formeme is astring representation of selected morpho-syntacticfeatures of the content word and selected auxiliarywords that belong to the content word, devised tobe used as a simple and efficient representation ofthe node.A noun formeme, which we are most interestedin, consists of three parts (examples taken fromFigure 1):1.
The syntactic part-of-speech ?
n for nouns.2.
The preposition if the noun has one (emptyotherwise), as in n:on+X or n:za+4.3.
A form specifier.?
In English, it typically marks the subjector object, as in n:subj.
In case of anoun accompanied by a preposition, thethird part is always X, as in n:on+X.?
In Czech, it denotes the morphologi-cal case of the noun, represented byits number (from 1 to 7 as there areseven cases in Czech), as in n:1 andn:za+4.t-treezone=engovernment n:subjspend v:finmiddle adj:attrschool n:on+Xt-treezone=csvl?da n:1utr?cet v:finst?edn?
adj:attr?kola n:za+4Figure 1: Tectogrammatical trees for the sentence?The government spends on the middle schools.?
?
?Vla?da utra?c??
za str?edn??
s?koly.?
; only lemmas andformemes of the nodes are shown.Adjectives and nouns can also have theadj:attr and n:attr formemes, respectively,meaning that the node is in morphological agree-ment with its parent.
This is especially importantin Czech, where this means that the word bears thesame morphological case as its parent node.4.2 ValencyThe notion of valency (Tesnie`re and Fourquet,1959) is semantic, but it is closely linked to syn-tax.
In the theory of valency, each verb has oneor more valency frames.
Each valency frame de-scribes a meaning of the verb, together with argu-ments (usually nouns) that the verb must or canhave, and each of the arguments has one or severalfixed forms in which it must appear.
These formscan typically be specified by prepositions and mor-phological cases to be used with the noun, and thuscan be easily expressed by formemes.For example, the verb ?to go?, shown in Ta-ble 1, has a valency frame that can be expressedas n:subj go n:to+X, meaning that the sub-ject goes to some place.The valency frames of the verbs ?spend?and ?utra?cet?
in Figure 1 can be written asn:subj spend n:on+X and n:1 utra?cetn:za+4; the subject (in Czech this is a noun innominative case) spends on an object (in Czech,the preposition ?za?
plus a noun in accusativecase).In our work, we have extended our scope alsoto noun-noun valency, i.e.
the parent node can beeither a verb or a noun, while the arguments are al-ways nouns.
Practice has proven this extension tobe useful, although the majority of the corrections174performed are still of the verb-noun valency type.Still, we keep the traditional notion of verb-nounvalency throughout the text, especially to be ableto always refer to the parent as ?the verb?
and tothe child as ?the noun?.5 Our Approach5.1 Valency modelsTo be able to detect and correct valency errors, wecreated statistical models of verb-noun valency.We model the conditional probability of the nounargument formeme based on several features of theverb-noun pair.
We decided to use the followingtwo models:P (fn|lv, fEN ) (1)P (fn|lv, ln, fEN ) (2)where:?
fn is the formeme of the Czech noun argu-ment, which is being modelled?
lv is the lemma of the Czech parent verb?
ln is the lemma of the Czech noun argument?
fEN is the formeme of the English nounaligned to the Czech noun argumentThe input is first processed by the model (1),which performs more general fixes, in situationswhere the (lv, fEN ) pair rather unambiguously de-fines the valency frame required.Then model (2) is applied, correcting some er-rors of the model (1), in cases where the nounargument requires a different valency frame thanis usual for the (lv, fEN ) pair, and making somemore fixes in cases where the correct valencyframe required for the (lv, fEN ) pair was too am-biguous to make a correction according to model(1), but the decision can be made once informationabout ln is added.We computed the models on the full training setof CzEng 1.0 (Bojar et al 2012b) (roughly 15 mil-lion sentences), and smoothed the estimated prob-abilities with add-one smoothing.5.2 DeepfixWe introduce a new statistical post-editing system,Deepfix, whose input is a pair of an English sen-tence and its Czech machine translation, and theoutput is the Czech sentence with verb-noun va-lency errors corrected.The Deepfix pipeline consists of several steps:1. the sentences are tokenized, tagged and lem-matized (a lemma and a morphological tag isassigned to each word)2. corresponding English and Czech words arealigned based on their lemmas3.
deep-syntax dependency parse trees of thesentences are built, the nodes in the trees arelabelled with formemes4.
improbable noun formemes are replaced withcorrect formemes according to the valencymodel5.
the words are regenerated according to thenew formemes6.
the regenerating continues recursively to chil-dren of regenerated nodes if they are inmorphological agreement with their parents(which is typical for adjectives)To decide whether the formeme of the noun isincorrect, we query the valency model for all pos-sible formemes and their probabilities.
If an alter-native formeme probability exceeds a fixed thresh-old, we assume that the original formeme is incor-rect, and we use the alternative formeme instead.For our example sentence, ?The governmentspends on the middle schools.?
?
?Vla?da utra?c??
zastr?edn??
s?koly.
?, we query the model (2) and get thefollowing probabilities:?
P(n:4 | utra?cet, s?kola, n:on+X) = 0.07(the original formeme)?
P(n:za+4 | utra?cet, s?kola, n:on+X) = 0.89(the most probable formeme)The threshold for this change type is 0.86, isexceeded by the n:za+4 formeme and thus thechange is performed: ?s?koly?
is replaced by ?zas?koly?.5.3 Tuning the ThresholdsWe set the thresholds differently for different typesof changes.
The values of the thresholds that weused are listed in Table 4 and were estimated man-ually.
We distinguish changes where only themorphological case of the noun is changed fromchanges to the preposition.
There are three possi-ble types of a change to a preposition: switchingone preposition to another, adding a new preposi-tion, and removing an existing preposition.
The175Correction type Thresholds for models(1) (2)Changing the noun case only 0.55 0.78Changing the preposition 0.90 0.84Adding a new preposition ?
0.86Removing the preposition ?
?Table 4: Deepfix thresholdschange to the preposition can also involve chang-ing the morphological case of the noun, as eachpreposition typically requires a certain morpho-logical case.For some combinations of a change type and amodel, as in case of the preposition removing, wenever perform a fix because we observed that itnearly never improves the translation.
E.g., if averb-noun pair can be correct both with and with-out a preposition, the preposition-less variant isusually much more frequent than the prepositionalvariant (and thus is assigned a much higher prob-ability by the model).
However, the prepositionoften bears a meaning that is lost by removing it?
in Czech, which is a relatively free-word-orderlanguage, the semantic roles of verb argumentsare typically distinguished by prepositions, as op-posed to English, where they can be determinedby their relative position to the verb.5.4 ImplementationThe whole Deepfix pipeline is implemented inTreex, a modular NLP framework (Popel andZ?abokrtsky?, 2010) written in Perl, which provideswrappers for many state-of-the-art NLP tools.
Forthe analysis of the English sentence, we use theMorc?e tagger (Spoustova?
et al 2007) and theMST parser (McDonald et al 2005).
The Czechsentence is analyzed by the Featurama tagger2 andthe RUR parser (Rosa et al 2012a) ?
a parseradapted to parsing of SMT outputs.
The wordalignment is created by GIZA++ (Och and Ney,2003); the intersection symmetrization is used.6 Evaluation6.1 Automatic EvaluationWe evaluated our method on three datasets:WMT10 (2489 parallel sentences), WMT11 (3003parallel sentences), and WMT12 (3003 parallelsentences) by Callison-Burch et al(2010; 2011;2012).
For evaluation, we used outputs of astate-of-the-art SMT system, Moses (Koehn et al2http://featurama.sourceforge.net/2007), tuned for English-to-Czech translation (Bo-jar et al 2012a).
We used the WMT10 datasetand its Moses translation as our development datato tune the thresholds.
In Table 5, we report theachieved BLEU scores (Papineni et al 2002),NIST scores (Doddington, 2002), and PER (Till-mann et al 1997).The improvements in automatic scores are lowbut consistently positive, which suggests thatDeepfix does improve the translation quality.However, the changes performed by Deepfix areso small that automatic evaluation is unable to re-liably assess whether they are positive or negative?
it can only be taken as an indication.6.2 Manual EvaluationTo reliably assess the performance of Deepfix,we performed manual evaluation on the WMT12dataset translated by the Moses system.The dataset was evenly split into 4 parts andeach of the parts was evaluated by one of two an-notators (denoted ?A?
and ?B?).
For each sentencethat was modified by Deepfix, the annotator de-cided whether the Deepfix correction had a posi-tive (?improvement?)
or negative (?degradation?
)effect on the translation quality, or concluded thatthis cannot be decided (?indefinite?)
?
either be-cause both of the sentences are correct variants, orbecause both are incorrect.3The results in Table 6 prove that the overall ef-fect of Deepfix is positive: it modifies about 20%of the sentence translations (569 out of 3003 sen-tences), improving over a half of them while lead-ing to a degradation in only a quarter of the cases.We measured the inter-annotator agreement on100 sentences which were annotated by both an-notators.
For 60 sentence pairs, both of the anno-tators were able to select which sentence is better,i.e.
none of the annotators used the ?indefinite?marker.
The inter-annotator agreement on these60 sentence pairs was 97%.43The evaluation was done in a blind way, i.e.
the annota-tors did not know which sentence is before Deepfix and whichis after Deepfix.
They were also provided with the source En-glish sentences and the reference human translations.4If all 100 sentence pairs are taken into account, requiringthat the annotators also agree on the ?indefinite?
marker, theinter-annotator agreement is only 65%.
This suggests thatdeciding whether the translation quality differs significantlyis much harder than deciding which translation is of a higherquality.176Dataset BLEU score (higher is better) NIST score (higher is better) PER (lower is better)Baseline Deepfix Difference Baseline Deepfix Difference Baseline Deepfix DifferenceWMT10* 15.66 15.74 +0.08 5.442 5.470 +0.028 58.44% 58.26% -0.18WMT11 16.39 16.42 +0.03 5.726 5.737 +0.011 57.17% 57.09% -0.08WMT12 13.81 13.85 +0.04 5.263 5.283 +0.020 60.04% 59.91% -0.13Table 5: Automatic evaluation of Deepfix on outputs of the Moses system on WMT10, WMT11 andWMT12 datasets.
*Please note that WMT10 was used as the development dataset.Part Annotator Changed sentences Improvement Degradation Indefinite1 A 126 57 (45%) 35 (28%) 34 (27%)2 B 112 62 (55%) 29 (26%) 21 (19%)3 A 150 88 (59%) 29 (19%) 33 (22%)4 B 181 114 (63%) 42 (23%) 25 (14%)Total 569 321 (56%) 135 (24%) 113 (20%)Table 6: Manual evaluation of Deepfix on outputs of Moses Translate system on WMT12 dataset.6.3 DiscussionWhen a formeme change was performed, it wasusually either positive or at least not harmful (sub-stituting one correct variant for another correctvariant).However, we also observed a substantialamount of cases where the change of the formemewas incorrect.
Manual inspection of a sample ofthese cases showed that there can be several rea-sons for a formeme change to be incorrect:?
incorrect analysis of the Czech sentence?
incorrect analysis of the English sentence?
the original formeme is a correct but very rarevariantThe most frequent issue is the first one.
This isto be expected, as the Czech sentence is often er-roneous, whereas the NLP tools that we used aretrained on correct sentences; in many cases, it isnot even clear what a correct analysis of an incor-rect sentence should be.7 Conclusion and Future WorkOn the English-Czech pair, we have shown thatstatistical post-editing of statistical machine trans-lation outputs is possible, even when translatingfrom a morphologically poor to a morphologi-cally rich language, if it is grounded by deep lin-guistic knowledge.
With our tool, Deepfix, wehave achieved improvements on outputs of twostate-of-the-art SMT systems by correcting verb-noun valency errors, using two simple probabilis-tic valency models computed on large-scale data.The improvements have been confirmed by man-ual evaluation.We encountered many cases where the per-formance of Deepfix was hindered by errors ofthe underlying tools, especially the taggers, theparsers and the aligner.
Because the use of theRUR parser (Rosa et al 2012a), which is partiallyadapted to SMT outputs parsing, lead to a reduc-tion of the number of parser errors, we find the ap-proach of adapting the tools for this specific kindof data to be promising.We believe that our method can be adaptedto other language pairs, provided that there is apipeline that can analyze at least the target lan-guage up to deep syntactic trees.
Because we onlyuse a small subset of information that a tectogram-matical tree provides, it is sufficient to use onlysimplified tectogrammatical trees.
These could becreated by a small set of rules from shallow-syntaxdependency trees, which can be obtained for manylanguages using already existing parsers.AcknowledgmentsThis research has been supported by the 7th FPproject of the EC No.
257528 and the project7E11042 of the Ministry of Education, Youth andSports of the Czech Republic.Data and some tools used as a prerequisitefor the research described herein have been pro-vided by the LINDAT/CLARIN Large Infrastruc-tural project, No.
LM2010013 of the Ministry ofEducation, Youth and Sports of the Czech Repub-lic.We would like to thank two anonymous review-ers for many useful comments on the manuscriptof this paper.177ReferencesHanna Be?chara, Yanjun Ma, and Josef van Genabith.2011.
Statistical post-editing for a statistical MTsystem.
MT Summit XIII, pages 308?315.Ondr?ej Bojar, Bushra Jawaid, and Amir Kamran.2012a.
Probes in a taxonomy of factored phrase-based models.
In Proceedings of the Seventh Work-shop on Statistical Machine Translation, pages 253?260, Montre?al, Canada.
Association for Computa-tional Linguistics.Ondr?ej Bojar, Zdene?k Z?abokrtsky?, Ondr?ej Dus?ek, Pe-tra Galus?c?a?kova?, Martin Majlis?, David Marec?ek, Jir???Mars??
?k, Michal Nova?k, Martin Popel, and Ales?
Tam-chyna.
2012b.
The joy of parallelism with CzEng1.0.
In Proceedings of the 8th International Confer-ence on Language Resources and Evaluation (LREC2012), pages 3921?3928, I?stanbul, Turkey.
Euro-pean Language Resources Association.Ondr?ej Bojar.
2011a.
Rich morphology and whatcan we expect from hybrid approaches to MT.
In-vited talk at International Workshop on Using Lin-guistic Information for Hybrid Machine Translation(LIHMT-2011), November.Ondr?ej Bojar.
2011b.
Analyzing error types inEnglish-Czech machine translation.
Prague Bulletinof Mathematical Linguistics, 95:63?76, March.Chris Callison-Burch, Philipp Koehn, Christof Monz,Kay Peterson, Mark Przybocki, and Omar Zaidan.2010.
Findings of the 2010 joint workshop on sta-tistical machine translation and metrics for machinetranslation.
In Proceedings of the Joint Fifth Work-shop on Statistical Machine Translation and Metric-sMATR, pages 17?53, Uppsala, Sweden, July.
Asso-ciation for Computational Linguistics.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Omar Zaidan.
2011.
Findings of the 2011workshop on statistical machine translation.
In Pro-ceedings of the Sixth Workshop on Statistical Ma-chine Translation, pages 22?64, Edinburgh, Scot-land, July.
Association for Computational Linguis-tics.Chris Callison-Burch, Philipp Koehn, Christof Monz,Matt Post, Radu Soricut, and Lucia Specia.
2012.Findings of the 2012 workshop on statistical ma-chine translation.
In Proceedings of the SeventhWorkshop on Statistical Machine Translation, pages10?51, Montre?al, Canada, June.
Association forComputational Linguistics.George Doddington.
2002.
Automatic evaluationof machine translation quality using n-gram co-occurrence statistics.
In Proceedings of the secondinternational conference on Human Language Tech-nology Research, pages 138?145.
Morgan Kauf-mann Publishers Inc.Ondr?ej Dus?ek, Zdene?k Z?abokrtsky?, Martin Popel, Mar-tin Majlis?, Michal Nova?k, and David Marec?ek.2012.
Formemes in English-Czech deep syntac-tic MT.
In Proceedings of the Seventh Workshopon Statistical Machine Translation, pages 267?274,Montre?al, Canada.
Association for ComputationalLinguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InACL 2007, Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguis-tics Companion Volume Proceedings of the Demoand Poster Sessions, pages 177?180, Prague, CzechRepublic, June.
Association for Computational Lin-guistics.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proc.
of EMNLP,Barcelona, Spain.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005.
Online large-margin training ofdependency parsers.
In Proceedings of the 43rdAnnual Meeting on Association for ComputationalLinguistics, pages 91?98.
Association for Computa-tional Linguistics.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Kemal Oflazer and Ilknur Durgar El-Kahlout.
2007.Exploring different representational units inEnglish-to-Turkish statistical machine translation.In Proceedings of the Second Workshop on Statisti-cal Machine Translation, pages 25?32.
Associationfor Computational Linguistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In ACL 2002,Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, pages 311?318, Philadelphia, Pennsylvania.Martin Popel and Zdene?k Z?abokrtsky?.
2010.
Tec-toMT: modular NLP framework.
In Proceedings ofthe 7th international conference on Advances in nat-ural language processing, IceTAL?10, pages 293?304, Berlin, Heidelberg.
Springer-Verlag.Rudolf Rosa, Ondr?ej Dus?ek, David Marec?ek, and Mar-tin Popel.
2012a.
Using parallel features in pars-ing of machine-translated sentences for correction ofgrammatical errors.
In Proceedings of Sixth Work-shop on Syntax, Semantics and Structure in Statis-tical Translation (SSST-6), ACL, pages 39?48, Jeju,Korea.
ACL.Rudolf Rosa, David Marec?ek, and Ondr?ej Dus?ek.2012b.
DEPFIX: A system for automatic correctionof Czech MT outputs.
In Proceedings of the Sev-enth Workshop on Statistical Machine Translation,178pages 362?368, Montre?al, Canada.
Association forComputational Linguistics.Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?.
1986.The meaning of the sentence in its semantic andpragmatic aspects.
Springer.Michel Simard, Cyril Goutte, and Pierre Isabelle.2007.
Statistical phrase-based post-editing.
In Hu-man Language Technologies 2007: The Conferenceof the North American Chapter of the Associationfor Computational Linguistics; Proceedings of theMain Conference, pages 508?515, Rochester, NewYork, April.
Association for Computational Linguis-tics.Drahom?
?ra Spoustova?, Jan Hajic?, Jan Votrubec, PavelKrbec, and Pavel Kve?ton?.
2007.
The best oftwo worlds: Cooperation of statistical and rule-based taggers for Czech.
In Proceedings of theWorkshop on Balto-Slavonic Natural Language Pro-cessing 2007, pages 67?74, Praha, Czechia.
Uni-verzita Karlova v Praze, Association for Computa-tional Linguistics.Lucien Tesnie`re and Jean Fourquet.
1959.
Ele?ments desyntaxe structurale.
E?ditions Klincksieck, Paris.Christoph Tillmann, Stephan Vogel, Hermann Ney,Alex Zubiaga, and Hassan Sawaf.
1997.
Ac-celerated dp based search for statistical translation.In European Conf.
on Speech Communication andTechnology, pages 2667?2670.179
