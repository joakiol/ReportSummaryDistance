Proceedings of the First Workshop on Metaphor in NLP, pages 58?66,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsAutomatic Extraction of Linguistic Metaphor with LDA Topic ModelingIlana Heintz*, Ryan Gabbard*, Mahesh Srinivasan+, *, David Barner+, Donald S. Black*,Marjorie Freedman*, Ralph Weischedel** Raytheon BBN Technologies10 Moulton St,Cambridge MA 02139{iheintz, rgabbard,mfreedman, dblack,rweischedel}@bbn.com+University of California, San Diego5336 McGill Hall,9500 Gilman DriveLa Jolla, CA 92093-0109barner@ucsd.edu,mahesh.srinivasan@gmail.comAbstractWe aim to investigate cross-cultural patternsof thought through cross-linguistic investiga-tion of the use of metaphor.
As a first step,we produce a system for locating instances ofmetaphor in English and Spanish text.
In con-trast to previous work which relies on re-sources like syntactic parsing and WordNet,our system is based on LDA topic modeling,enabling its application even to low-resourcelanguages, and requires no labeled data.
Weachieve an F-score of 59% for English.1 IntroductionPatterns in the use of metaphors can provide agreat deal of insight into a culture.
Cultural differ-ences expressed linguistically as metaphor can playa role in matters as complex and important as dip-lomatic relations.
For instance, Thornborrow(1993) discusses the different metaphors that areused in the context of security in French and Brit-ish coverage of two major post-cold-war summitmeetings.
Example metaphors such as ?the corner-stone of the new security structure,?
?structures fordefence and security cooperation,?
and ?the emerg-ing shape of Europe,?
exemplify the English use ofthe source concept structure in describing the tar-get concept of security.
In contrast, the metaphors?des r?gles de s?curit?
nouvelles (new rules of se-curity)?, ?une r?vision fondamentale des disposi-tions de s?curit?
(a fundamental revision ofsecurity provisions)?, and ?un syst?me de s?curit?europ?en (a system of European security)?
exem-plify the French use of the more abstract sourceconcept system to describe the same target concept.As Thornborrow notes, the implied British concep-tion of security as ?concrete, fixed, and immobile?contrasts deeply with the French conception of se-curity as ?a system as a series of processes.
?Our ultimate goal is to use metaphor to furtherour knowledge of how different cultures under-stand complex topics.
Our immediate goal in thispaper is to create an automated system to find in-stances of metaphor in English and Spanish text.Most existing work on metaphor identification(Fass, 1991; Martin, 1994; Peters and Peters, 2000;Mason, 2004; Birke and Sarkar, 2006; Gegigan etal., 2006; Krishnakumaran and Zhu, 2007; Shutovaet  al., 2010; Shutova et al 2012)1 has reliedon some or all of handwritten rules, syntactic pars-ing, and semantic databases like WordNet (Fell-baum, 1998) and FrameNet (Baker et al 1998).This limits the approaches to languages with richlinguistic resources.
As our ultimate goal is broad,cross-linguistic application of our system, we can-not rely on resources which would be unavailablein resource-poor languages.
Instead, we applyLDA topic modeling (Blei et al 2003b) whichrequires only an adequate amount of raw text in thetarget language.
This work is similar to Bethard etal.
(2009), in which an SVM model is trained withLDA-based features to recognize metaphoricaltext.
There the work is framed as a classificationtask, and supervised methods are used to labelmetaphorical and literal text.
Here, the task is oneof recognition, and we use heuristic-based, unsu-1 See Shutova (2010) for a survey of existing approaches58pervised methods to identify the presence of meta-phor in unlabeled text.
We hope to eliminate theneed for labeled data which, as discussed inBethard et al(2009) and elsewhere, is very diffi-cult to produce for metaphor recognition.2 TerminologyWe will refer to a particular instance of metaphori-cal language in text as a linguistic metaphor.Each such metaphor talks about a target conceptin terms of a source concept.
For example, in?Dems, like rats, will attack when cornered?
thesource concept is animals and the target concept ispoliticians2, or at a higher level, governance.
Theabstract mapping between a source concept and atarget concept will be referred to as a conceptualmetaphor which is grounded by a collection oflinguistic metaphors.In this work, we restrict our attention to a singletarget concept, governance.
Our definition of gov-ernance is broad, including views of the governedand those who govern, institutions of government,laws, and political discourse.
We used a large col-lection (see Table 1) of potential source concepts.Beginning with the source concepts of primarymetaphors, which are hypothesized to be univer-sal (Grady, 1998), we expanded our set to includesource concepts commonly found in the scientificliterature about metaphor, as well as those foundby human annotators manually collecting instancesof governance-related metaphors.Animals Fishing PlantsBaseball Flight RaceBody Football ReligionBotany Gambling SickBoundary Grasp SizeChess Health SoundColor Height SportsCombustion Light TasteCooking Liquid TemperatureCourtship Machine TextureCut Maritime TheaterDirectional force Money Time of dayDogs Motion ToxicityDrug use Mythology VehicleElectricity Natural disasters WarEnergy source Nuclear WeaponryEntry Odor Weather2 ?Dems?'
refers to the Democratic Party, an American politi-cal partyFamily Pathways WeightFarming Physical structure Wild westFight PlanningTable 1: English Source Concepts3 High-level system overviewFigure 1: System OverviewOur main hypothesis is that metaphors are likely tobe found in sentences that exhibit evidence of botha source and a target concept.
The core idea of oursystem is to use LDA topics as proxies for seman-tic concepts which may serve as the source or tar-get for a metaphor.
For a given language, we buildan LDA model from Wikipedia and then align itstopics to potential source and target concepts,which are defined by small human-created lists ofseed words.At runtime, the system first does LDA infer-ence on our input corpus to get topic probabilitiesfor each document and sentence.
The system thenselects those sentences linked by LDA to both asource-aligned topic and a target-aligned topic.3For example, a sentence containing ?
?virtud so-3 This is a distant, automatic relative of the ?directed-search?technique of Martin (1994).59cial para construir la democracia?
?4 will be se-lected because LDA strongly associates it withboth the topic [elecciones, ministro, sucesor, ?
]5,aligned to the target concept governance, and thetopic [edificio, arquitectura, torre,?]
6, aligned tothe source concept physical structure.Next, the system identifies the words in eachselected sentence that are strongly associated witheach concept.
In the sentence above, it marks vir-tud and democracia as target-associated and con-struir as source-associated.Next it applies two filters.
First, we exclude anysentence with too few words that are not LDAstopwords, because the model's predictions may bevery inaccurate in these cases.
Second, if the topicassociated with the source model for a sentence isalso a top-ranked topic for the document as awhole, the sentence is excluded.
The reason forthis is that if the source concept is present through-out the document, it is probably being used literal-ly (see Figure 2).Finally, it uses previously-computed infor-mation to determine a final score.
All linguisticmetaphors scoring above a certain threshold arereturned.
By varying this threshold, the user canvary the precision-recall tradeoff as needed.
A dia-gram of the system can be found in Figure 1.Figure 2: Even though the last sentence is relevant to thesource concept pathways and the target concept govern-ance, it will be correctly rejected because pathways-aligned topics are present throughout the document.4 Implementation Details: TrainingOur runtime system requires as input an LDAmodel, a list of seed words for each concept, andan alignment between concepts and LDA topics.4.1 LDA Topic ModelThe topics defined by LDA topic modeling serveas stand-ins for the more abstractly-defined sourceand target concepts underlying the metaphors.
Theinput to training our LDA model is the full text of4 social virtue to build democracy5 elections, minister, successor6 building, architecture, towerWikipedia articles in the target language.
Wikipe-dia is available in numerous languages and servesas a corpus of general knowledge, providing uswith topics corresponding to a broad range of con-cepts.
Our LDA model is trained using MALLET(McCallum, 2002) for 1000 iterations with 100topics, optimizing hyperparameters every 10 itera-tions after a 100 iteration burn-in period.
The 500most common tokens in the training corpus wereused as stopwords.
The result of LDA is 100 top-ics, where each topic is a probability distributionover the training corpus vocabulary.
Representa-tive words for example English topics are shown inFigure 3.Figure 3: Sample LDA topics with representative terms4.2 Concept Seed Word ListsFor each concept  , we have a label and a small setof seed words representing that concept, referred toas     .
These lists were created by hand in Eng-lish and then translated into Spanish by nativespeakers.
The translation was not intended to beexact; we instructed the annotators to create thelists in a way that was appropriate for their lan-guage and culture.
For instance, the football topicfor English describes American football, but inSpanish, the same topic describes soccer.4.3 Concept-Topic AlignmentThe final input to our system is an alignment be-tween concepts and topics, with every topic beingmapped to at most one concept.
In addition to theseed lists and LDA model, this alignment processtakes a score threshold        and a maximumnumber of alignments per source and target con-cept   and  .The alignment algorithm is as follows.
Wealign each topic   to the concept   with the maxi-mum score       , which measures the conceptterms?
summed probability in the LDA topic:.
We remove all align-ments where                .
Finally, for eachconcept, only the   highest scoring alignmentsare kept, where   may be different for source andOur county has many roads in bad shape.Thousands of our bridges are structurallydeficient.
Congress needs to pass a newhighway bill.theater stage musical miss actreesstheory philosophy pp study scientificknowledgenfl bowl yards coach players card yardgovernor republican senate election congress60target.
We refer to the aligned topics for a conceptas     .Label Seed ListWordsAligned TopicsVehicle vehicle,wheels, gas,bus0.035: engine, car,model0.29: railway,trains, train0.022: energy,gas, linearAnimals animal, beast,cattle0.066: animals,animal, speciesCourtship courtship, ro-mance, courtNoneGovernance aristocrat, bi-partisan, citi-zen, duke0.25: Election,elected, parliament0.22: Governor,republican, Senate0.14: sir, lord,henry0.13: kingdom,emperor, empire0.12: rights, legal,lawsTable 2: Sample concepts, manually-created seed lists,and aligned topicsA last condition on the topic-concept alignmentis the assignment of topics to trump concepts.
Ouronly trump concept in this study is war.
If an LDAtopic is aligned with both the war concept and thegovernance concept, it is removed from alignmentwith the governance concept.
We do this becausewar is so tightly associated with governments thatthe alignment algorithm invariably aligns it to thegovernance topic.
However, war is also a veryimportant source concept for governance meta-phors; our choice is to suffer on recall by missingsome governance-relevant sentences, but increaserecall on metaphors for which the source concept iswar.
Sample topic-concept alignments are showninTable 2.
By inspecting the resulting alignmentsby hand, we chose the following parameter valuesfor both languages:       =0.01,  =3,  =5.The process of defining concepts is simple andfast and the alignment method is inexpensive.Therefore, while we have not captured all possiblesource concepts in our initial list, expanding thislist is not difficult.
We can define new source con-cepts iteratively as we analyze metaphors that ourextraction system misses, and we can add targetconcepts as our interests broaden.5 Implementation Details: RuntimeThe system receives as input a corpus of docu-ments, their LDA decodings, the LDA decodingsof each sentence treated as a separate document,and the topic-concept alignments.
Each four-tupleis processed independently, where   isthe language,   is the source concept,   is the tar-get concept, and   is the sentence.Determining Concept Relevance: Recall ourbasic intuition that a sentence relevant both to anLDA topic in      (termed source-relevant) andone in      (termed target-relevant) is potentiallymetaphorical.
The system judges a sentence   tobe  -relevant if the probability of  -aligned topicsin that sentence is above a threshold:, where        is an ad-justable parameter tuned by hand.
is 0.06 inEnglish and 0.05 in Spanish.
is 0.1 in bothlanguages.
On the source side, the system removesall topics in      from        and renormalizesbefore determining relevance in order to avoid pe-nalizing sentences for having very strong evidenceof relevance to governance in addition to providingevidence of relevance to a source concept.
Forreference below, let                    (ameasure of how strongly the sentence is associatedwith its topics) and let(the most proba-ble  -aligned topic in the sentence).If   is not both source- and target-relevant, thesystem stops and the sentence is not selected.Finding Concept-Associated Words: The systemnext creates sets    of the words in   associatedwith the concept  .
Let                   .Then let{                   , whereis a hand tuned parameter set to 0.1 for bothlanguages.
That is, any word whose probability inthe topic is higher than a theshold is included as aconcept-associated word in that sentence.
Letand vice-versa.
Note that wordswhich could potentially be associated with eitherconcept are associated with neither.
For referencebelow, let                      (the moststrongly concept-associated words in the sentence)61and                    (the combinedstrength of those associations).If   lacks words strongly associated with thesource and target concepts (that is,    or    isempty), the system stops and the sentence is notselected.Filters: The system applies two filters.
First,must have at least four words which are not LDAstopwords; otherwise, the LDA predictions whichdrive the system's concept-relevance judgementstend to be unreliable.
Second, the most likelysource topic       must not be one of the top 10topics for the document as a whole, for reasonsdescribed above.
If either of these requirementsfail, the system stops and the sentence is not se-lected.Final Scoring: Finally, the system determinesif(  (     )  (     )            )where        is a hand-tuned threshold set to -10.0for English and -13.0 for Spanish.
This takes intoaccount the strength of association between topicsand the sentence, between the annotated words andthe topics, and between the topics and their alignedconcepts.
Any sentence passing this threshold isselected as a linguistic metaphor.6 Example OutputWe provide examples of both true and false posi-tives extracted by our system.
The annotations ofsource and target-associated words in each sen-tence are those defined as    and    above.
Thesource concept animals is used for all examples.1.
ModeratesT we all hear are an endangeredSspeciesS, Sen. Richard2.
DemsT like ratsS sometimes attack when cor-nered3.
ObamaT 's world historical political ambitionscrossbredS with his4.
At least DemocraticT representativesT aresnakeheadS fish5.
Another whopperS from Cleveland, GOPTlawyer backs him up6.
Previous post: Illinois GOPT lawmakerT ar-rested in animalS feed bag related incident7.
Next post: National Enquirer catfightingMichelle ObamaT has clawsS out for that niceAnn Romney8.
Sen. Lisa MurkowskiT R AK independentfrom Alaska - thank you silly Repubs, teaSparty her out haExamples 1 through 4 are correct metaphors ex-tracted by our system.
In each, some words relatedto the target concept governance are described us-ing terms related to the source concept animals.Example 1 best represents the desired output of oursystem, such that it contains a governance- andanimals-relevant metaphor and the terms associat-ed with the metaphor are properly annotated.
Someissues do arise in these true positive examples.
Ex-ample 2, while often termed a simile, is counted asa metaphor for our purposes.
In example 3, thesource term is correctly annotated, but the targetterms should be political ambitions rather thanObama.
It is unclear why the term snakehead butnot the term fish in example 4 is associated withthe source concept.Examples 5 through 8 represent system errors.In example 5, the fact that the word whopper oc-curs frequently to describe a large animal (espe-cially a fish) causes the sentence to be mistakenlyidentified as relevant to the source concept animal.The source term animal in example 6 is clearlyrelevant to the source concept, but it is being usedliterally.
The document-level source concept fil-tering does not entirely eliminate this error class.While example 7 contains a metaphor and hassome relationship to American politics, it would becounted as an error in our evaluations because themetaphor itself is not related to governance.
In ex-ample 8, we have two errors.
First, tea is stronglypresent in the topic aligned to the animal concept,causing the sentence to be incorrectly marked assource-relevant.
Second, because our topic modeloperates at the level of individual words, it wasunable to recognize that tea here is part of thefixed, governance-related phrase tea party.
77 Evaluation7.1 Collecting Evaluation DataWe collected a domain-specific corpus in eachlanguage.
We curated a set of news websites andgovernance-relevant blogs in English and Spanishand then collected data from these websites overthe course of several months.
For each language,we ran our system over this corpus (all steps in7 an American political movement62Section 5), produced a set of linguistic metaphorsfor each topic-aligned source concept (the targetconcept was always governance), and ranked themby the final score (Section 4.4).
Below, we willrefer to the set of all linguistic metaphors sharingthe same source and target concept as a conceptualmetaphor.7.2 Simple EvaluationFor this evaluation, we selected the top five exam-ples for each conceptual metaphor.
If the samesentence was selected by multiple conceptual met-aphors, it was kept for only the highest scoringone.
We then added enough of the highest-rankedunselected metaphors to create a full set of 300.We then added random sentences from the corpusthat were not selected as metaphorical by the sys-tem to bring the total to 600.
Our Spanish annota-tors were unavailable at the time this evaluationtook place, so we are only able to report results forEnglish in this case.For each of these instances, two annotatorswere asked the question, ?Is there a metaphorabout governance in this example??
These annota-tors had previous experience in identifying meta-phors for this study, both by searching manually inonline texts and evaluating previous versions ofour system.
Over time we have given them feed-back on what does and does not constitute a meta-phor.
In this case, the annotators were givenneither the system's concept-word association an-notations nor the source concept associated withthe instance.
In one way, the evaluation was gen-erous, because any metaphor in the extracted sen-tence would benefit precision even if it was not themetaphor found by our system.
On the other hand,the same is true for the random sentences; whilethe system will only extract metaphors with sourceconcepts in our list, the annotators had no suchrestriction.
This causes the recall score to suffer.The annotation task was difficult, with a  -score of0.48.
The resulting scores are given in Table 3.The examples given in Section 5 illustrate the errorclasses found among the false positives identifiedby the human annotators.
There are many caseswhere the source-concept associated terms are usedliterally rather than metaphorically, and many cas-es where the system-found metaphor is not aboutgovernance.
Some text processing issues, such asa bug in our sentence breaking script, as well as thenoisy nature of blog and blog comment input,caused some of the examples to be difficult to in-terpret or evaluate.Annotator Precision ?Recall?
F Kappa126543676066500.48Mean 54 64 59Table 3: Simple English Evaluation7.3 Stricter EvaluationCommon Experimental SetupWe did a second evaluation of both English andSpanish using a different paradigm.
For each lan-guage, we selected the 250 highest-ranked linguis-tic metaphor instances in the corpus.
Subjects onAmazon Mechanical Turk were shown instanceswith the system-predicted concept-associatedwords highlighted and asked if the highlightedwords were being used metaphorically (optionswere yes and no).
Each subject was randomlyasked about roughly a quarter of the data.We paid the subjects $10 per hour.
We addedcatch trial sentences which asked the subject tosimply answer yes or no as a way of excludingthose not actually reading the sentences.
Subjectsanswering these questions incorrectly were exclud-ed (17 in English, 25 in Spanish).We defined the metaphoricity of an instance tobe the fraction of subjects who answered yes forthat instance.
We define the metaphoricity of aconceptual metaphor as the average metaphoricityof its groundings among the instances in this eval-uation set.63English ResultsWe restricted our subjects to those claiming tobe native English speakers who had IP addresseswithin the U.S. and had 115 participants.
The ex-amples were grouped into 66 conceptual meta-phors.
The mean metaphoricity of instances was0.41 (standard deviation=0.33).
The mean meta-phoricity of the conceptual metaphors (Figure 4),was 0.39 (SD=0.26).
Although there was widevariance in metaphoricity across conceptual meta-phors, it appears likely that most of the conceptualmetaphors discovered by the system are correct:65% of the conceptual metaphors had metaphorici-ty greater than 0.25, and 73% greater than 0.2.Given that many metaphors are conventional anddifficult to detect in natural language (Lakoff andJohnson, 1980), it is possible that even in cases inwhich only a minority of subjects detected a meta-phor, a metaphor nonetheless existsSpanish ResultsWe restricted our subjects to those claiming to benative speakers of Mexican Spanish with IP ad-dresses in the US (57) or Mexico (29).
The in-stances were grouped into 52 conceptual meta-phors.
The mean metaphoricity of instances was0.33 (SD=0.23) and for conceptual metaphors(Figure 4), 0.31 (SD=0.16).
60% of conceptualmetaphors had metaphoricity greater than 0.25, and73% greater than 0.2.
That performance was onlyslightly lower than English is a positive indicationof our method?s cross-linguistic potential.8 Discussion and Future WorkWe observed a number of problems with our ap-proach which provide avenues for future research.8.1 Topics as Proxies of Primary MetaphorConceptsMany of the metaphors missed by our system wereinstances of primary metaphor, especially thoseinvolving movement and spatial position.
OurLDA approach is poorly suited to these because thesource concepts are not well-characterized by wordco-occurrence: words describing movement andspatial position do not have a strong tendency toco-occur with other such words, at least in Wik-ipedia.
Augmenting our system with a separateFigure 4: Metaphoricity of Conceptual Metaphors for English (top) and Spanish (bottom)64approach to primary metaphor would boost its per-formance significantly.8.2 Topics as Proxies of Non-Primary Meta-phor ConceptsWe found that most of our potential source con-cepts did not correspond to any LDA topic.
How-ever, many of these, such as wild west, have fairlystrong word co-occurrence patterns, so they plau-sibly could be found by a different topic modelingalgorithm.
There are two promising approacheshere which could potentially be combined.
Thefirst is to use a hierarchical LDA algorithm (Blei etal, 2003b) to allow concepts to align to topics withvarying degrees of granularity, from the very gen-eral (e.g.
war) to the very specific (e.g.
wild west).The second is to use constrained LDA approaches(Andrzejewski and Zhu, 2009; Hu et al 2010) toattempt to force at least one topic to correspond toeach of our seed concept lists.A different approach would leave behind seedlists entirely.
In our current approach, only aboutone third of the topics modeled by LDA are suc-cessfully aligned with a source concept from ourhand-made list.
However, some non-aligned LDAtopics have properties similar to those that werechosen to represent source concepts.
For instance,the topic whose highest ranked terms are [institute,professor, engineering, degree] is comprised of aset of semantically coherent and concrete terms,and could be assigned a reasonably accurate labelsuch as higher education.
If we were to chooseLDA topics based on the terms?
coherence andconcreteness (and perhaps other relevant, measura-ble properties), then assign a label using a methodsuch as that in Mei et al(2007), we would be ableto leverage more of the concepts in the LDA mod-el.
This would increase the recall of our system,and also reduce some of the confusion associatedwith incorrect labeling of concepts in linguistic andconceptual metaphors.
Applying Labeled LDA, asin Ramage et al(2009), would be a similar ap-proach.8.3 Confusion of Literal and MetaphoricalUsage of Source ConceptsAnother major problem was the confusion betweenliteral and metaphorical usage of source terms.This is partly addressed by our document topicsfilter, but more sophisticated use of document con-text for this purpose would be helpful.
A similarfilter based on contexts across the test corpusmight be useful.8.4 Fixed ExpressionsSome of our errors were due to frequent fixedphrases which included a word strongly associatedwith a source topic, like Tea Party.
Minimum de-scription length (MDL) phrase-finding or similartechniques could be used to filter these out.
Initialexperiments performed after the evaluations dis-cussed above show promise in this regard.
Usingthe MDL algorithm (Rissanen, 1978), we devel-oped a list of likely multi-word expressions in theWikipedia corpus.
We then concatenated thesephrases in the Wikipedia corpus before LDA mod-eling and in the test corpus before metaphor pre-diction.
Though we did not have time to formallyevaluate the results, a subjective analysis showedfewer of these fixed phrases appearing as indica-tors of metaphor (as words in    or   ).8.5 Difficulty of AnnotationA different method of presentation of metaphors tothe subjects, for instance with annotations markingwhere in the sentence we believed metaphor toexist or with a suggestion of the source concept,may have improved agreement and perhaps thesystem?s evaluation score.8.6 SummaryWe have presented a technique for linguistic andconceptual metaphor discovery that is cross-linguistically applicable and requires minimal lin-guistic resources.
Our approach of looking foroverlapping semantic concepts allows us to findmetaphors of any syntactic structure.
The frame-work of our metaphor discovery technique is flexi-ble in its ability to incorporate a wide variety ofsource and target concepts.
The only linguistic re-sources the system requires are a corpus of gen-eral-knowledge text adequate for topic modelingand a small set of seed word lists.
We could im-prove our system by applying new research in au-tomatic topic modeling, by creating new filters andscoring mechanisms to discriminate between literaland figurative word usages, and by creating train-ing data to allow us to automatically set certainsystem parameters.65AcknowledgementsSupported by the Intelligence Advanced Research Pro-jects Activity (IARPA) via Department of Defense USArmy Research Laboratory contract number W911NF-12-C0-0023.
The U.S. Government is authorized toreproduce and distribute reprints for Governmental pur-poses notwithstanding any copyright annotation there-on.
Disclaimer: The views and conclusions containedherein are those of the authors and should not be inter-preted as necessarily representing the official policies orendorsements, either expressed or implied, of IARPA,DoD/ARL, or the U.S.
Government.
?ReferencesDavid Andrzejewski and Xiaojin Zhu.
2009.
Latent Di-richlet Allocation with Topic-in-Set Knowledge.
InProceedings of NAACL Workshop on Semi-Supervised Learning for NLP.Collin Baker, Charles Fillmore, and John Lowe.
1998.The Berkeley FrameNet project.
In Proceedings ofCOLING-ACL.Stephen Bethard, Vicky Tzuyin Lai and James H. Mar-tin.
2009.
Topic Model Analysis of Metaphor Fre-quency for Psycholinguistic Stimuli.
.
In Proc.
OfNAACL-HLT Workshop on Computational Ap-proaches to Linguistic Creativity.Julia Birke and Anoop Sarkar.
2006.
A Clustering Ap-proach for the Nearly Unsupervised Recognition ofNonliteral Language.
In Proceedings of EACL.David Blei, Thomas Griffiths, Michael Jordan, andJoshua Tenenbaum.
2003a.
Hierarchical topic modelsand the nested Chinese restaurant process.
In Pro-ceedings of NIPS.David Blei, Andrew Ng, and Michael Jordan.
2003b.Latent Dirichlet Allocation.
Journal of MachineLearning Research, 2003(3):993?1022.Dan Fass.
1991. met*: A Method for DiscriminatingMetonymy and Metaphor by Computer.
Computa-tional Linguistics, 17(1):49?90.Christine Fellbaum.
1998.
WordNet: An Electronic Lex-ical Database.
MIT Press, Cambridge, MA.Matt Gegigan, John Bryant, Srini Narayanan, andBranimir Ciric.
2006.
Catching Metaphors.
In Pro-ceedings of the 3rd Workshop on Scalable NaturalLanguage Understanding.Joseph E. Grady.
1998.
Foundations of meaning: Prima-ry metaphors and primary scenes.
UMI.Yuenin Hu, Jordan Boyd-Graber, and Brianna Satinoff.2010.
Interactive Topic Modeling.
In Proceedings ofACL.Saisuresh Krishnakumaran and Xiaojin Zhu.
2007.Hunting Elusive Metaphors Using Lexical Re-sources.
In Proceedings of the Workshop on Compu-tational Approaches to Figurative Language.George Lakoff and Mark Johnson.
1980.
Metaphors WeLive By.
University of Chicago.James H. Martin.
1994.
MetaBank: A knowledge-baseof metaphoric language convention.
ComputationalIntelligence, 10(2):134?149.Zachary Mason.
2004.
CorMet: A Computational, Cor-pus-Based Conventional Metaphor Extraction Sys-tem.
Computational Linguistics, 30(1):23?44.Andrew Kachites McCallum.
2002.
MALLET: A Ma-chine Learning for Language Toolkit.http://mallet.cs.umass.edu.Qiaozhu Mei, Xuehua Shen, and Chengxiang Zhai.Automatic Labeling of Multinomial Topic Models.In Proceedings of KDD ?07.
2007.Wim Peters and Ivonne Peters.
2000.
Lexicalised Sys-tematic Polysemy in WordNet.
In Proceedings ofLREC.Daniel Ramage, David Hall, Ramesh Nallapati andChristopher D. Manning.
2009.
Labeled LDA: A su-pervised topic model for credit attribution in multi-labeled corpora.
In Proceedings of EMNLP.Jorma Rissanen.
Modeling by shortest data description.Automatica 14:465-471.Ekaterina Shutova, Lin Sun, and Anna Korhonen.
2010.Metaphor Identification Using Noun and Verb Clus-tering.
In Proceedings of COLING.Ekaterina Shutova, Simone Teufel, and Anna Korhonen.2012.
Statistical Metaphor Processing.
Computation-al Linguistics.
Uncorrected proof.Ekaterina Shutova.
2010.
Models of metaphor in NLP.In Proceedings of ACL.Joanna Thornborrow.
1993.
Metaphors of security: acomparison of representation in defence discourse inpost-cold-war France and Britain.
Discource & Soci-ety, 4(1):99?11966
