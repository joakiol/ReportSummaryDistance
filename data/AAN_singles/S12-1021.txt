First Joint Conference on Lexical and Computational Semantics (*SEM), pages 132?141,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsAn Unsupervised Ranking Model for Noun-Noun CompositionalityKarl Moritz Hermann, Phil Blunsom, and Stephen PulmanDepartment of Computer ScienceUniversity of OxfordWolfson Building, Parks RoadOxford OX1 3QD, UK{karl.moritz.hermann,phil.blunsom,stephen.pulman}@cs.ox.ac.ukAbstractWe propose an unsupervised system thatlearns continuous degrees of lexicality fornoun-noun compounds, beating a strong base-line on several tasks.
We demonstrate that thedistributional representations of compoundsand their parts can be used to learn a fine-grained representation of semantic contribu-tion.
Finally, we argue such a representationcaptures compositionality better than the cur-rent status-quo which treats compositionalityas a binary classification problem.1 IntroductionA Multiword Expressions (MWE) can be defined asa sequence of words whose meaning cannot nec-essarily be derived from the meaning of the wordsmaking up that sequence, for example:Rat Race ?
self-defeating or pointless pursuit1MWEs are considered a ?key problem for the de-velopment of large-scale, linguistically sound nat-ural language processing technology?
(Sag et al,2002).
The challenge posed by MWEs is three-fold, consisting of MWE identification, classifica-tion and interpretation.
Following the identificationof a MWE, it needs to be established whether theexpression should be treated as lexical (idiomatic)or as compositional.
The final step, learning the se-mantics of the MWE, strongly depends on this deci-sion.1Definition taken from Wikipedia, and clearly not recover-able if one only knows the meaning of the words ?rat?
and ?race?.The problem posed by MWEs is considered hard,but at the same time it is highly relevant and inter-esting.
MWEs occur frequently in language and in-terpreting them correctly would directly improve re-sults in a number of tasks in NLP such as translationand parsing (Korkontzelos and Manandhar, 2010).By extension this makes deciding the lexicality ofMWEs an important challenge for various fields in-cluding machine translation, question answering andinformation retrieval.
In this paper we discuss com-positionality with respect to noun-noun compounds.Most Computational Linguistics literature treatscompositionality as a binary problem, classifyingcompounds as either lexical or compositional.
Weshow that this approach is too simplistic and arguefor the real-valued treatment of compositionality.We propose two unsupervised models that learncompositionality rankings for compounds, placingthem on a scale between lexical and compositionalextremes.
We develop a fine-grained representa-tion of compositionality using a novel generative ap-proach that models context as generated by com-pound constituents.
This representation differenti-ates between the semantic contribution of both com-pound constituents as well as the compound itself.Comparing it with existing work in the field, wedemonstrate the competitiveness of our approach.We evaluate on an existing corpus of noun com-pounds with ranked compositionality data, as wellas on a large corpus with a binary annotation for lex-ical and compositional compounds.
We analyse theimpact of data sparsity and propose an interpolationapproximation which significantly reduces the effectof sparsity on model performance.1322 Related WorkInterpreting MWEs is a difficult task as ?compoundnouns can be freely constructed?
(Spa?rck Jones,1985), and are thus able to proliferate infinitely.
Atthe same time, semantic composition can take manydifferent forms, making uniform interpretation ofcompounds impossible (Zanzotto et al, 2010).Most current work on MWEs focuses on inter-preting compounds and sidesteps the task of deter-mining whether a compound is compositional in thefirst place (Butnariu et al, 2010; Kim and Baldwin,2008).
Such methods, aimed at learning the seman-tics of compounds, can roughly be divided into twomajor strands of research.One group relies on data intensive methods to ex-tract semantics vectors from large corpora (Baroniand Zamparelli, 2010; Zanzotto et al, 2010; Gies-brecht, 2009).
The focus of these approaches is todevelop methods for composing the vectors of un-igrams into a semantic vector representing a com-pound.
Some of the work in this area touches on theissue of lexicality, as models learning distributionalrepresentations of MWEs ideally would first estab-lish whether a given MWE is compositional or not(Mitchell and Lapata, 2010).The other group are knowledge intensive ap-proaches collecting linguistic features (Kim andBaldwin, 2005; Korkontzelos and Manandhar,2009).
Tratz and Hovy (2010), for instance, traina classifier for noun compound interpretation on alarge set of WORDNET and Thesaurus features.Combined approaches include Kim and Baldwin(2008), who interpret noun compounds by extrapo-lating their semantics from observations where thetwo nouns forming a compound are in an intransi-tive relationship.
For example extracting the phrase?the family owns a car?
from the training data wouldhelp learn that the compound ?family car?
describesa POSSESSOR-OWNED/POSSESSED relationship.Some of these supervised classifiers include lexi-cality as a classification option, considering it jointlywith the actual compound interpretation.Next to the work on MWE interpretation there hasbeen some work focused on determining lexicalityin its own right (Reddy et al, 2011; Bu et al, 2010;Kim and Baldwin, 2007).One possibility is to exploit special properties oflexical MWEs such as high statistical associationof their constituents (Pedersen, 2011) or syntacticrigidity (Fazly et al, 2009; McCarthy et al, 2007).However, these approaches are limited in their ap-plicability to compound nouns (Reddy et al, 2011).Another method is to compare the semantics ofa compound and its constituents to decide com-positionality.
The approaches used to determinethose semantics can again be divided into knowl-edge intensive and data-driven methods.
Dependingon the chosen representation of semantics these ap-proaches can either be used for supervised classifiersor together with a distance metric comparing vectorspace representations of semantics.
In a binary set-ting, a threshold would then be applied to the resultof that distance function (Korkontzelos and Man-andhar, 2009).
In a real-valued setting the distancemetric itself can be used as a measure for compo-sitionality (Reddy et al, 2011).
Related to the vec-tor space based models, some research focuses onimproving the distance metrics used to compare in-duced semantics (Bu et al, 2010).3 MethodologyEnglish noun-noun compounds are majority left-branching (Lauer, 1995), with a head (the secondelement), modified by an attributive noun (first el-ement).
For example:Ground Floor ?
The floor of a building at or near-est ground level.2In this paper, we will use the terms attributive noun(AN) and head noun (HN) to refer to the first andsecond noun in a noun compound.3.1 Real-Valued RepresentationLexicality of MWEs is frequently treated as a bi-nary property (Tratz and Hovy, 2010; O?
Se?aghdha,2007).
We argue that lexicality should instead betreated as a graded property, as most compound se-mantics exhibit a mixture of compositional and lexi-cal influences.
For example, ?cocktail dress?
derivesa large part of its semantics from ?dress?, but thecompound also contributes an idiosyncratic elementto its meaning.2Definition from http://www.thefreedictionary.com133We define lexicality as the degree to which id-iosyncrasy contributes to a compound?s semantics.Inversely phrased, the compositionality of a com-pound can be defined as the degree to which its senseis related to the senses of its constituents.3This graded representation follows Spa?rck Jones(1985), who argued that ?it is not possible to main-tain a principled distinction between lexicalised andnon-lexicalised compounds?.
Some recent workalso supports this view (Reddy et al, 2011; Bu etal., 2010; Baldwin, 2006).
From a practical per-spective, a real-valued representation of composi-tionality should help improve interpretation of com-pounds.
This is especially true when factoring in therespective semantic contributions of its parts.3.2 Context GenerationAccording to the distributional hypothesis, the se-mantics of a lexical item can be expressed by itscontext.
We apply this hypothesis to the problem ofnoun compound compositionality by using a genera-tive model on compound context.
Our model allowscontext to be generated by the compound itself or byeither one of its constituents.
By learning which el-ement of the compound generates which part of itscontext we effectively determine the semantic con-tribution of each element.
This in turn gives us afine-grained, graded representation of a compound?slexicality.4 Corpora for Evaluation4.1 Ranked Corpus ?
REDDYAs we want to evaluate our models?
ability to learnlexicality as a real-valued property, we require anannotated data set of noun compounds ranked bylexicality.
To the best of our knowledge the onlysuch data set was developed by Reddy et al (2011).This data set contains 90 distinct noun compoundswith real-valued gold standard scores ranking from0 (lexical) to 5 (compositional).
The compoundsare nearly linearly distributed across the [0;5] range,with inter annotator agreement (Spearman?s ?)
of3For example, the meaning of ?gravy train?
has hardly anyrelation to either ?gravy?
or ?train?.
Its semantics are thus highlydependent on the compound in its own right.
On the other endof the spectrum, ?climate change?
is significantly related to both?climate?
and ?change?, contributing little inherent semantics toits overall meaning.0.522.
We refer to this data set and evaluation asREDDY throughout this paper.4.2 Binary Corpora ?
TRATZWe also apply our models to a second, binary classi-fication task.
Tratz and Hovy (2010) compiled a dataset for noun compound interpretation, which classi-fies noun compounds based on their internal struc-ture.
We use this corpus to extract lexical and com-positional noun compounds.After some pre-processing4 the data set contains18,858 compositional and 118 lexical noun com-pounds.
We believe this to more accurately representthe real world distribution of lexical and composi-tional noun compounds: Tratz and Hovy (2010) ex-tracted noun compounds from several large corporaincluding the Wall Street Journal section of the PennTreebank, thus obtaining a reasonable approxima-tion of real world occurrence.
Other collections ofnoun compounds (O?
Se?aghdha, 2007) feature sim-ilar proportions of lexical and compositional nouncompounds.The large bias towards compositional noun com-pounds does not support the status-quo of treatingcompositionality as a binary property.
As discussedearlier, we assume that most compounds have acompositional as well as a lexical element.
Whilethe compositional aspect may be larger for mostcompounds this alone does not suffice as a reasonto disregard the lexical element contained in thesecompounds.In order to evaluate our system on the TRATZdata, we use receiving operator characteristic (ROC)curves.
ROC analysis enables us to evaluate a rank-ing model without setting an artificial threshold forthe compositionality/lexicality decision.5 Baseline ApproachWe develop a set of advanced baselines related tothe semi-supervised models presented by Reddy etal.
(2011).
We define the context K of a noun com-pound as all words in all sentences the compoundappears in.
From this we calculate distributionalrepresentations of a compound (c = ?a, h?)
and itsconstituent elements a, h. We refer to these repre-sentations as ~c for the compound and ~a, ~h for the4We removed trigrams from the data set.134Name ?
r ?ADD w.Sac + (1?
w).Shc .323 .567MULT Sac.Shc .379 .551MIN min(Sac, Shc) .343 .550MAX max(Sac, Shc) .299 .505COMB w1.Sac+w2.Shc+w3.Sac.Shc .366 .556Table 1: Results of COSLEX with different operators onthe REDDY data set, reporting Pearson?s r and Spear-man?s ?
correlations.
Weights for operators ADD (w =0.3) and COMB (w = ?0.3, 0.1, 0.6?)
are manually opti-mised.
Values range from -1 (negative correlation) to +1(perfect correlation) with 0 describing random data.attributive and head noun, respectively.
We can cal-culate the cosine similarity based lexicality score(COSLEX) by combining the cosine similarity of thecompound?s distribution with each of its two con-stituents (Reddy et al, 2011).Sac = sim(~a,~c)Shc = sim(~h,~c)COSLEX(c) = Sac ?
ShcWe evaluate a number of alternative operators ?
forcombining Sac and Shc.
Results for this baselineon the REDDY corpus are in Table 1,5 with weightswi on the combination operators manually optimisedfor Spearman?s ?
on that data set.
In effect thisrenders this baseline into a supervised approach, sowe would expect it to perform very well.
We usethe best performing operators (ADD with w = 0.3,MULT) as baselines for this paper.6 Generative ModelsWe exploit the distributional hypothesis to modelthe semantic contribution of the different elementsof a noun compound.
For this, we require a sys-tem that treats a noun compound as a vector of threesemantics-bearing units: the compound itself, itshead and its attributive noun.
This system shouldthen model the relationship between the context ofthe compound and these three units, deciding whichof them is responsible for each context element.5Reddy et al (2011) report higher figures on our baselinemodels.
The differences are attributed to differences in trainingdata and parametrization.6.1 3-way Compound MixtureWe model a corpus D of tuples d = {c, k1, ..., kn}.Each tuple d contains a noun compound c = ?a, h?and its context words K = (k1, ..., kn).
We use vo-cabularies Vc for noun compounds, Va for attributivenouns, Vh for head nouns and Vk for context.We condition our generative model on the nouncompounds.
Given an observation d of a compoundc, we generate each context word in two steps.
First,we choose one of the compounds three elements6 togenerate the next context word.
Second, we gener-ate a new context word conditioned on that element.Formally, the context is generated as follows.We draw three multinomial parameters ?c, ?aand ?h from Dirichlet distributions with parameters?c, ?a and ?h.
?c represents the distribution overcontext words Vk given compound c. ?a and ?hare distributions over Vk given attributive noun a andhead noun h, respectively.
These three distributionsform the mixture components of our model.A fourth multinomial parameter ?z , drawn froma Dirichlet distribution with parameter ?z , controlsthe distribution over the mixture components.
?z isspecific to each compound c, so multiple observa-tions of the same compound share this parameter.For each context word we draw a mixture compo-nent zc,i ?
{c?, a?, h?}
from the multinomial distribu-tion with parameter ?z .
zc,i determines which dis-tribution the context word itself will be drawn from.Finally, we draw the context word:?i: ki | ?
{zc,i} ?
Multi(?
{zc,i})Thus, for each observation of a compound noun wehave a vector zc = ?z1, ..., zn?
detailing how itscontext words were created either by the compounditself or by one of its constituents.
To determine lex-icality, we are interested in learning the multinomialparameter ?z , which describes to what extent thecompound and its constituents contribute to the gen-eration of the context (i.e.
semantics).
We can ap-proximate ?z from the vector zc.We define the lexicality score Lex(c) for a com-pound as the percentage of context words created by6The compound itself, its attributive noun and its head noun135Figure 1: Plate diagram illustrating the MULT-CMPDmodel with context words ki drawn from a mixture modelwith three components controlled by zi.the compound and not one of its constituents:Lex(c) = p(z=c?|?a, h?
), (1)where c = ?a, h?Figure 1 shows a plate diagram of this model, whichwe will refer to as MULT-CMPD.One hypothesis encoded in model MULT-CMPDis that deciding which part of a compound (the com-pound itself, the head or the attributive noun) gen-erates context is a single decision.
An alternativerepresentation could treat this as a two-step process,which we encode in a second model BIN-CMPD.The intuition behind the BIN-CMPD model is thatthere are two distinct decisions.
First, whether acompound is compositional or not.
Second, whether(in the compositional case) its semantics stem fromits head or attributive nounWhere MULT-CMPD uses a three component mix-ture to determine which multinomial distribution touse, BIN-CMPD uses two cascaded binary mixtures(see Figure 2).
The BIN-CMPD model first chooseswhether to treat a compound as compositional orlexical.
If the compound is determined as composi-tional, a second binary mixture determines whetherto generate a context word using the attributive (?a)or head multinomial (?h).
For the lexical case, themodel remains unchanged.Figure 2: Schematic description of compositional-ity/lexicality decision for models MULT-CMPD and BIN-CMPD.Model r ?COSLEX (ADD) .323 .567COSLEX (MULT) .379 .551MULT-CMPD .141 .435BIN-CMPD .168 .410Table 2: Results on the REDDY data set, reporting Pear-son?s r and Spearman?s ?
correlations.
Values range from-1 (negative correlation) to +1 (perfect correlation).6.1.1 Inference and SamplingWe use Gibbs sampling to learn the vectors z foreach instance d, integrating out the parameters ?x.We train our models on the British National Corpus(BNC), extracting all noun-noun compounds from aparsed version of the corpus.In order to speed up convergence of the sampler,we use simulated annealing over the first 20 iter-ations (Kirkpatrick et al, 1983), helping the ran-domly initialised model reach a mode faster.
We re-port results using marginal distributions after a fur-ther 130 iterations, excluding the counts of the an-nealing stage.6.1.2 EvaluationWe evaluate our two models on the REDDY dataset by comparing its scores for lexicality (Lex(c))with the annotated gold standard.
The aim of thisevaluation is to determine how accurately the mod-els can capture gradual distinctions in lexicality.
TheROC analysis on the TRATZ data set furthermore in-forms us how precise the models are at distinguish-ing lexical from compositional compounds.Results of the REDDY evaluation are in Table 2.We use Spearman?s ?
to measure the monotonic cor-relation of our data to the gold standard.
Pearson?s radditionally captures the linear relationship betweenthe data, taking into account the relative differencesin Lex(c) scores among noun compounds.136Figure 3: ROC analysis of models MULT-CMPD andBIN-CMPD versus the best COSLEX baseline (ADD) onthe TRATZ data setWhile both models, BIN-CMPD and MULT-CMPD, clearly learn a correlation with lexical-ity rankings, they underperform the strong, semi-supervised COSLEX baselines described earlier inthis paper.
The second evaluation, on the binaryTRATZ data set shows a different picture (see Fig-ure 3).
The best COSLEX baseline (ADD withw = 0.2) fails to outperform random choice on thistask.
Both generative models clearly beat COSLEXon this task, with MULT-CMPD in particular per-forming very well for low sensitivity.There is no clear distinction in performance be-tween the two generative approaches.
Further anal-ysis might help us to separate the two more clearly,and we will continue using both models throughoutthis paper.It is important to note the different performance ofthe generative models vs. the cosine similarity ap-proach on two tasks.
The REDDY data set has anearly linear distribution of compositionality scores,while the TRATZ data set is overwhelmingly com-positional, which more closely represents the realworld distribution of compounds.
The poor perfor-mance of the cosine similarity approach (COSLEX)on the TRATZ evaluation suggests the limitationsof this approach when applied to more realistic datasuch as this data set.
An additional explanation forthe semi-supervised baseline?s poorer result is thatthe effect of parameter tuning decreases on largerdata.Investigating the errors made by the modelsMULT-CMPD and BIN-CMPD gives rise to a numberof possible explanations for their performance.
Themost promising lead is related to data sparsity, withmany of the evaluated noun-noun compounds onlyappearing once or twice in the corpus.
This makes itharder for our generative approach to learn sensiblecontext distributions for these instances.We will next investigate how to reduce the effectsencountered by sparsity.6.2 InterpolationWorking on problems related to non-unigram data,sparsity is a frequently encountered problem.
As al-ready explored in the previous section, this is alsothe case for our generative models of lexicality.It would be possible to use an even larger trainingcorpus, but there are limitations as to what extentthis is possible.
The BNC, containing 100 millionwords, is already one of the largest corpora regu-larly used in Computational Linguistics.
However,adding more data in an unsupervised sense is un-likely to significantly improve results (Brants et al,2007).Alternatively, it would be possible to add spe-cific training data that included the noun compoundsfrom the evaluation data sets.
This would, how-ever, compromise the unsupervised nature of our ap-proach, and it thus not an option either.In this paper, we will instead focus on extenuat-ing the effects of data sparsity through other unsu-pervised means.
For this purpose we investigate in-terpolating on a larger set of noun compounds.Kim and Baldwin (2007) observed that seman-tic similarity of verb-particle compounds correlateswith their lexicality.
We extend this observation fornoun compounds, hypothesising that the lexicalityof similar words will be similar.
We combine thiswith the assumption that noun compounds sharing aconstituent are likely to be semantically similar (Ko-rkontzelos and Manandhar, 2009).Using this idea, we can approximate the lexical-ity of a given compound with the lexicality scores ofall compounds sharing either of its constituents.
Sofar we have calculated the lexicality of a given com-pound using the formula Lex(c) in Equation 1.
Theformula Clex(c) in Equation 2 averages the lexical-ity scores of a compound with those of its related137Function and Model r ?COSLEX (ADD) .323 .567COSLEX (MULT) .379 .551Lex(c)MULT-CMPD .141 .435BIN-CMPD .168 .410Clex(c)MULT-CMPD .357 .596BIN-CMPD .400 .592Ilex(c)MULT-CMPD .422 .621BIN-CMPD .538 .623Table 3: Results on the REDDY data set, reportingPearson?s r and Spearman?s ?
correlations, comparingIlex(c) and Clec(c) interpolations with Lex(c).compounds.
As p(z=1|?a, h?)
directly influencesboth p(z=1|?a, ??)
and p(z=1|?
?, h?
), we can alsoconsider dropping it from the approximation such asin Equation 3.
This approach trades some specificityin favour of reducing sparsity, as we observe moreinstances of such related compounds than of a par-ticular noun compound itself only.Lex(c) ?
Clex(c) (2)Clex(c) =p(z=1|?a, ??)
+ p(z=1|?
?, h?)
+ p(z=1|?a, h?
)3,where c = ?a, h?Lex(c) ?
Ilex(c) (3)Ilex(c) =p(z=1|?a, ??)
+ p(z=1|?
?, h?
)2,where c = ?a, h?Both formulations enable us to better deal withsparse data as decisions are made based on a widerrange of observations.
At the same time, we avoid aloss of specificity as the models and scores are stillhighly dependent on the individual noun compound.We avoid introducing additional degrees of free-dom by using uniform weights only.
However, itwould be simple to turn this approach into a semi-supervised model by tuning the weights for the dif-ferent probabilities involved in calculating Clex(c)and Lex(c).
That approach would be comparable tothe operators used on our COSLEX baselines.Results on the REDDY data set using Clex(c)and Ilex(c) are in Table 3.
Figure 4 shows the im-pact of these approximations on the Tratz data forthe BIN-CMPD model.
These interpolations suggeststrong improvements in performance.
It should es-pecially be noted that Ilex(c) consistently outper-forms Clex(c), which indicates the strength of theFigure 4: ROC analysis of model BIN-CMPD on theTRATZ data set, comparing Ilex(c) and Clec(c) inter-polations with Lex(c).related-compound probabilities over the individualcompound probabilities.These results confirm our suspicion that sparsitywas a major factor affecting our models?
perfor-mance.
Furthermore, they strengthen our hypothe-sis about the relatedness of semantic similarity andlexicality and demonstrate a sensible approach forexploiting this relationship.7 AnalysisWe use this section for qualitative evaluation, com-plementing the quantitative evaluation in the previ-ous sections.
The purpose of the qualitative evalu-ation is to better understand exactly what it is ourmodels are learning.Table 5 lists the compounds that model BIN-CMPD considers the most lexical and the most com-positional.
The list of compounds with the high lex-icality scores is dominated by proper nouns such ascountries, companies and persons.
This is in linewith expectation as compounds of proper nouns arefully lexical.
Removing proper nouns (also in Table5), we get a slightly more ambiguous list.
For exam-ple, ?study design?
is not considered a lexical com-pound, but rather a highly institutionalized, com-positional MWE (Sag et al, 2002).
Using Lex(c)?study design?
is ranked as such, so this appears tobe a case where interpolation has a negative impact.In this paper we argued for a finer grained analysisof compositionality, taking into account the differ-138Context of ?flea market?
generated byflea market flea marketcanal, wall, incline,campsitestall, Paris, sale,Saturday, week,Sunday, quarter,damage, changebarter, souvenir,launderette,Lamine, Canet,Kouyate, PlageContext of ?night owl?
generated bynight owl night owlcourt, fee, guest,early, day, Baden,membership, life,gamewaive, player,Halikarnas, bar,bird, unbooked,ViennaadventurousContext of ?memory lane?
generated bymemory lane memory lanetake, story, about,tell, real, glimpse,Britain, reminis-cencevillage, protection,drive, catwalk,plantwar, justify, bill,Campbell, rude-boysContext of ?melting pot?
generated bymelting pot melting potforest, racial,caribbean, plan,programme, real-ity, arrangementin, into, put, polit-ical, community,prepareethnic, greatest,drawing, liaise,pan-european,mythTable 4: Overview over context words generated by model BIN-CMPD.
We list a selection of words predominatelygenerated by each of the mixture components of the given noun-noun compound.Most Compositionallabour union, tax authority, health council,market counterparty, employment policyMost Lexicalstudy design, family motto, wood shaving,avoidance behaviour, smash hitMost Lexical (including Proper Nouns)Vo Quy, Bonito Oliva, Mamur Zapt, EvanderHolyfield, Saudi ArabiaTable 5: Top lexical and compositional nouns for theBIN-CMPD model using Ilex(c)ent impact of both constituents.
We tried to achievethis by modelling a compound?s context as gener-ated from its various semantic constituents.
Table 4highlights the impact of this method for a numberof noun compounds, showing which context wordswere predominately generated by each constituent.Due to the nature of the context used, some ofthe links are semantically not obvious (e.g.
the rela-tionship between owls and Vienna).
In some casesthe semantic contribution of the parts is more clearlyseparated, such as the contributions of ?memory?
and?lane?
to the semantics of ?memory lane?.
In sum-mary, these examples clearly suggest that our mod-els learn to associate context with compound ele-ments and that this association is an informed one.8 ConclusionWe proposed a novel approach for learning lexicalityscores for noun compounds and empirically demon-strated the feasiblity of this approach.
Using a gen-erative model we were able to beat a strong, semi-supervised baseline with an unsupervised model.We discussed the issue of data sparsity in depthand proposed several approaches for overcomingthis problem.
Focusing on unsupervised approaches,we demonstrated how interpolation can be used totackle sparsity.
The two interpolation methods thatwe implemented helped us to strongly improve over-all model performance.
Our empirical evaluation ofinterpolation metricsClex(c) and Ilex(c) also givescredence to the hypothesis that lexicality is related tosemantic similarity.On the theoretical side, we offered further supportto the real-valued treatment of lexicality.Further work will include using larger trainingcorpora.
While the BNC is a popular corpus in Com-putational Linguistics, it proved to be too small tolearn sensible representations for a number of com-pounds encountered in the test data.
Using largercorpora will also allow us to further study and re-duce the sparsity issues encountered.To study the relationship between constituent andcompound compositionality in greater depth, wewill also investigate alternative approaches for in-terpolation.
Similarity measures that consider thesemantic relevance of individual context elementsshould also be considered as a next step.Another obvious source of future work is to ap-ply our approach to general collocations beyond thespecial case of noun compounds only.AcknowledgmentsThe authors would like to acknowledge the use ofthe Oxford Supercomputing Centre (OSC) in carry-ing out this work.139ReferencesTimothy Baldwin.
2006.
Compositionality and mul-tiword expressions: Six of one, half a dozen of theother?
In Proceedings of the Workshop on MultiwordExpressions: Identifying and Exploiting UnderlyingProperties, page 1, Sydney, Australia.
Association forComputational Linguistics.Marco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: representingadjective-noun constructions in semantic space.
InProceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, EMNLP?10, pages 1183?1193, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.Och, and Jeffrey Dean.
2007.
Large Language Mod-els in Machine Translation.
In Proceedings of the2007 Joint Conference on Empirical Methods in Nat-ural Language Processing and Computational Natu-ral Language Learning (EMNLP-CoNLL), pages 858?867.Fan Bu, Xiaoyan Zhu, and Ming Li.
2010.
Measuringthe non-compositionality of multiword expressions.
InProceedings of the 23rd International Conference onComputational Linguistics, COLING ?10, pages 116?124, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Cristina Butnariu, Su Nam Kim, Preslav Nakov, Diar-muid O?.
Se?aghdha, Stan Szpakowicz, and Tony Veale.2010.
Semeval-2010 task 9: The interpretation ofnoun compounds using paraphrasing verbs and prepo-sitions.
In Proceedings of the 5th International Work-shop on Semantic Evaluation, SemEval ?10, pages 39?44, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Afsaneh Fazly, Paul Cook, and Suzanne Stevenson.2009.
Unsupervised type and token identificationof idiomatic expressions.
Computational Linguistics,35(1):61?103.Eugenie Giesbrecht.
2009.
In search of semantic com-positionality in vector spaces.
In Proceedings of the17th International Conference on Conceptual Struc-tures: Conceptual Structures: Leveraging SemanticTechnologies, ICCS ?09, pages 173?184, Berlin, Hei-delberg.
Springer-Verlag.Su Nam Kim and Timothy Baldwin.
2005.
Automaticinterpretation of noun compounds using wordnet simi-larity.
In In Proceedings of the 2nd International JointConference on Natural Language Processing, Jeju Is-land, South Korea, 1113, pages 945?956.Su Nam Kim and Timothy Baldwin.
2007.
Detect-ing compositionality of English verb-particle construc-tions using semantic similarity.
In Proceedings of the7th Meeting of the Pacific Association for Computa-tional Linguistics, PACLING ?07, pages 40?48.Su Nam Kim and Timothy Baldwin.
2008.
An unsu-pervised approach to interpreting noun compounds.
InNatural Language Processing and Knowledge Engi-neering, 2008.
NLP-KE ?08.
International Conferenceon, pages 1?7.S.
Kirkpatrick, C. D. Gelatt, and M. P. Vecchi.
1983.Optimization by simulated annealing.
Science,220(4598):671?680.Ioannis Korkontzelos and Suresh Manandhar.
2009.
De-tecting compositionality in multi-word expressions.In Proceedings of the ACL-IJCNLP 2009 ConferenceShort Papers, ACLShort ?09, pages 65?68, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Ioannis Korkontzelos and Suresh Manandhar.
2010.
Canrecognising multiword expressions improve shallowparsing?
In Human Language Technologies: The2010 Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,HLT ?10, pages 636?644, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Mark Lauer.
1995.
Corpus statistics meet the noun com-pound: some empirical results.
In Proceedings ofthe 33rd annual meeting on Association for Compu-tational Linguistics, ACL ?95, pages 47?54, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Diana McCarthy, Sriram Venkatapathy, and AravindJoshi.
2007.
Detecting compositionality of verb-object combinations using selectional preferences.
InProceedings of the 2007 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), pages 369?379, Prague, Czech Republic.
As-sociation for Computational Linguistics.Jeff Mitchell and Mirella Lapata.
2010.
Composition indistributional models of semantics.
Cognitive Science,34(8):1388?1429.Diarmuid O?
Se?aghdha.
2007.
Annotating and learningcompound noun semantics.
In Proceedings of the 45thAnnual Meeting of the ACL: Student Research Work-shop, ACL ?07, pages 73?78, Stroudsburg, PA, USA.Association for Computational Linguistics.Ted Pedersen.
2011.
Identifying collocations to mea-sure compositionality: shared task system description.In Proceedings of the Workshop on Distributional Se-mantics and Compositionality, DiSCo ?11, pages 33?37, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Siva Reddy, Diana McCarthy, and Suresh Manandhar.2011.
An empirical study on compositionality in com-140pound nouns.
In Proceedings of The 5th Interna-tional Joint Conference on Natural Language Process-ing 2011 (IJCNLP 2011), Chiang Mai, Thailand.Ivan A.
Sag, Timothy Baldwin, Francis Bond, AnnCopestake, and Dan Flickinger.
2002.
Multiword ex-pressions: A pain in the neck for NLP.
In In Proc.of the 3rd International Conference on Intelligent TextProcessing and Computational Linguistics (CICLing-2002, pages 1?15.Karen Spa?rck Jones.
1985.
Compound noun interpre-tation problems.
In Frank Fallside and William A.Woods, editors, Computer speech processing, pages363?381.
Prentice Hall International (UK) Ltd., Hert-fordshire, UK, UK.Stephen Tratz and Eduard Hovy.
2010.
A taxonomy,dataset, and classifier for automatic noun compoundinterpretation.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, ACL ?10, pages 678?687, Stroudsburg, PA, USA.Association for Computational Linguistics.Fabio Massimo Zanzotto, Ioannis Korkontzelos,Francesca Fallucchi, and Suresh Manandhar.
2010.Estimating linear models for compositional dis-tributional semantics.
In Proceedings of the 23rdInternational Conference on Computational Linguis-tics, COLING ?10, pages 1263?1271, Stroudsburg,PA, USA.
Association for Computational Linguistics.141
