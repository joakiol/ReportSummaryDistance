Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 450?454,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsReordering Modeling using Weighted Alignment MatricesWang Ling, Tiago Lu?
?s, Joa?o Grac?a, Lu?
?sa Coheur and Isabel TrancosoL2F Spoken Systems LabINESC-ID Lisboa{wang.ling,tiago.luis,joao.graca}@inesc-id.pt{luisa.coheur,isabel.trancoso}@inesc-id.ptAbstractIn most statistical machine translation sys-tems, the phrase/rule extraction algorithm usesalignments in the 1-best form, which mightcontain spurious alignment points.
The usageof weighted alignment matrices that encode allpossible alignments has been shown to gener-ate better phrase tables for phrase-based sys-tems.
We propose two algorithms to generatethe well known MSD reordering model usingweighted alignment matrices.
Experiments onthe IWSLT 2010 evaluation datasets for twolanguage pairs with different alignment algo-rithms show that our methods produce moreaccurate reordering models, as can be shownby an increase over the regular MSD modelsof 0.4 BLEU points in the BTEC French toEnglish test set, and of 1.5 BLEU points in theDIALOG Chinese to English test set.1 IntroductionThe translation quality of statistical phrase-basedsystems (Koehn et al, 2003) is heavily dependenton the quality of the translation and reordering mod-els generated during the phrase extraction algo-rithm (Ling et al, 2010).
The basic phrase extrac-tion algorithm uses word alignment information toconstraint the possible phrases that can be extracted.It has been shown that better alignment quality gen-erally leads to better results (Ganchev et al, 2008).However the relationship between the word align-ment quality and the results is not straightforward,and it was shown in (Vilar et al, 2006) that betteralignments in terms of F-measure do not always leadto better translation quality.The fact that spurious word alignments might oc-cur leads to the use of alternative representations forword alignments that allow multiple alignment hy-potheses, rather than the 1-best alignment (Venu-gopal et al, 2009; Mi et al, 2008; ChristopherDyer et al, 2008).
While using n-best alignmentsyields improvements over using the 1-best align-ment, these methods are computationally expen-sive.
More recently, the method described in (Liuet al, 2009) produces improvements over the meth-ods above, while reducing the computational costby using weighted alignment matrices to representthe alignment distribution over each parallel sen-tence.
However, their results were limited by thefact that they had no method for extracting a reorder-ing model from these matrices, and used a simpledistance-based model.In this paper, we propose two methods for gener-ating the MSD (Mono Swap Discontinuous) reorder-ing model from the weighted alignment matrices.First, we test a simple approach by using the 1-bestalignment to generate the reordering model, whileusing the alignment matrix to produce the translationmodel.
This reordering model is a simple adaptationof the MSD model to read from alignment matrices.Secondly, we develop two algorithms to infer the re-ordering model from the weighted alignment matrixprobabilities.
The first one uses the alignment infor-mation within phrase pairs, while the second usescontextual information of the phrase pairs.This paper is organized as follows: Section 2 de-scribes the MSD model; Section 3 presents our twoalgorithms; in Section 4 we report the results fromthe experiments conducted using these algorithms,450and comment on the results; we conclude in Sec-tion 5.2 MSD modelsMoses (Koehn et al, 2007) allows many config-urations for the reordering model to be used.
Inthis work, we will only refer to the default config-uration (msd-bidirectional-fe), which uses the MSDmodel, and calculates the reordering orientation forthe previous and the next word, for each phrase pair.Other possible configurations are simpler than thedefault one.
For instance, the monotonicity modelonly considers monotone and non-monotone orien-tation types, whereas the MSD model also considersthe monotone orientation type, but distinguishes thenon-monotone orientation type between swap anddiscontinuous.
The approach presented in this workcan be adapted to the other configurations.In the MSD model, during the phrase extraction,given a source sentence S and a target sentence T ,the alignment set A, where aji is an alignment from ito j, the phrase pair with words in positions betweeni and j in S, Sji , and n and m in T , Tmn , can beclassified with one of three orientations with respectto the previous word:?
The orientation is monotonous if only the pre-vious word in the source is aligned with the pre-vious word in the target, or, more formally, ifan?1i?1 ?
A ?
an?1j+1 /?
A.?
The orientation is swap, if only the next wordin the source is aligned with the previous wordin the target, or more formally, if an?1j+1 ?
A ?an?1i?1 /?
A.?
The orientation is discontinuous if neither ofthe above are true, which means, (an?1i?1 ?A ?
an?1j+1 ?
A) ?
(an?1i?1 /?
A ?
an?1j+1 /?
A).The orientations with respect to the next word aregiven analogously.
The reordering model is gener-ated by grouping the phrase pairs that are equal, andcalculating the probabilities of the grouped phrasepair being associated each orientation type and di-rection, based on the orientations for each directionthat are extracted.
Formally, the probability of thephrase pair p having a monotonous orientation isprevword(s)source phrasetarget phraseprevword(t)nextword(s)source phrasetarget phraseprevword(t)a) b)c)source phrasetarget phraseprevword(t)d)nextword(s)source phrasetarget phraseprevword(t)prevword(s)Figure 1: Enumeration of possible reordering cases withrespect to the previous word.
Case a) is classified asmonotonous, case b) is classified as swap and cases c)and d) are classified as discontinuous.given by:P (p,mono) = C(mono)C(mono)+C(swap)+C(disc) (1)Where C(o) is the number of times a phrase is ex-tracted with the orientation o in that group of phrasepairs.
Moses also provides many options for thisstage, such as types of smoothing.
We use the de-fault smoothing configuration which adds the fixedvalue of 0.5 to all C(o).3 Weighted MSD ModelWhen using a weighted alignment matrix, ratherthan working with alignments points, we use theprobability of each word in the source aligning witheach word in the target.
Thus, the regular MSDmodel cannot be directly applied here.One obvious solution to solve this problem is toproduce a 1-best alignment set alng with the align-ment matrix, and use the 1-best alignment to gen-erate the reordering model, while using the align-ment matrix to produce the translation model.
How-ever, this method would not be taking advantage ofthe weighted alignment matrix.
The following sub-sections describe two algorithms that are proposedto make use of the alignment probabilities.3.1 Score-basedEach phrase pair that is extracted using the algorithmdescribed in (Liu et al, 2009) is given a score basedon its alignments.
This score is higher if the align-ment points in the phrase pair have high probabili-ties, and if the alignment is consistent.
Thus, if an451extracted phrase pair has better quality, its orienta-tion should have more weight than phrase pairs withworse quality.
We implement this by changing theC(o) function in equation 1 from being the numberof the phrase pairs with the orientation o, to the sumof the scores of those phrases.
We also need to nor-malize the scores for each group, due to the fixedsmoothing that is applied, since if the sum of thescores is much lower (e.g.
0.1) than the smoothingfactor (0.5), the latter will overshadow the weightof the phrase pairs.
The normalization is done bysetting the phrase pair with the highest value of thesum of all MSD probabilities to 1, and readjustingother phrase pairs accordingly.
Thus, a group of 3phrase pairs that have the MSD probability sums of0.1, 0.05 and 0.1, are all set to 1, 0.5 and 1.3.2 Context-basedWe propose an alternative algorithm to calculatethe reordering orientations for each phrase pair.Rather than classifying each phrase pair with eithermonotonous (M ), swap (S) or discontinuous (D),we calculate the probability for each orientation, anduse these as weighted counts when creating the re-ordering model.
Thus, for the previous word, givena weighted alignment matrix W , the phrase pair be-tween the indexes i and j in S, Sji , and n and m inT , Tmn , the probability values for each orientationare given by:?
Pc(M) = Wn?1i?1 ?
(1?Wn?1j+1 )?
Pc(S) = Wn?1j+1 ?
(1?Wn?1i?1 )?
Pc(D) = Wn?1i?1 ?Wn?1j+1+ (1?Wn?1i?1 )?
(1?Wn?1j+1 )These formulas derive from the adaptation of con-ditions of each orientation presented in 2.
In theregular MSD model, the previous orientation for aphrase pair is monotonous if the previous word inthe source phrase is aligned with the previous wordin the target phrase and not aligned with the nextword.
Thus, the probability of a phrase pair to have amonotonous orientation Pc(M) is given by the prob-ability of the previous word in the source phrasebeing aligned with the previous word in the targetphrase Wn?1i?1 , and the probability of the previousword in the source to not be aligned with the nextword in the target (1 ?
Wn?1j+1 ).
Also, the sum ofthe probabilities of all orientations (Pc(M), Pc(S),Pc(D)) for a given phrase pair can be trivially shownto be 1.
The probabilities for the next word aregiven analogously.
Following equation 1, the func-tion C(o) is changed to be the sum of all Pc(o), fromthe grouped phrase pairs.4 Experiments4.1 CorpusOur experiments were performed over two datasets,the BTEC and the DIALOG parallel corpora fromthe latest IWSLT evaluation 2010 (Paul et al, 2010).BTEC is a multilingual speech corpus that containssentences related to tourism, such as the ones foundin phrasebooks.
DIALOG is a collection of human-mediated cross-lingual dialogs in travel situations.The experiments performed with the BTEC cor-pus used only the French-English subset, while theones perfomed with the DIALOG corpus used theChinese-English subset.
The training corpora con-tains about 19K sentences and 30K sentences, re-spectively.
The development corpus for the BTECtask was the CSTAR03 test set composed by 506sentences, and the test set was the IWSLT04 test setcomposed by 500 sentences and 16 references.
Asfor the DIALOG task, the development set was theIWSLT09 devset composed by 200 sentences, andthe test set was the CSTAR03 test set with 506 sen-tences and 16 references.4.2 SetupWe use weighted alignment matrices based on Hid-den Markov Models (HMMs), which are producedby the the PostCAT toolkit1, based on the poste-rior regularization framework (V. Grac?a et al, 2010).The extraction algorithm using weighted alignmentmatrices employs the same method described in (Liuet al, 2009), and the phrase pruning threshold wasset to 0.1.
For the reordering model, we use thedistance-based reordering, and compare the resultswith the MSD model using the 1-best alignment.Then, we apply our two methods based on align-ment matrices.
Finally, we combine our two meth-ods above by adapting the function C(o), to be the1http://www.seas.upenn.edu/ strctlrn/CAT/CAT.html452sum of all Pc(o), weighted by the scores of the re-spective phrase pairs.
The optimization of the trans-lation model weights was done using MERT, andeach experiment was run 5 times, and the final scoreis calculated as the average of the 5 runs, in order tostabilize the results.
Finally, the results were eval-uated using BLEU-4, METEOR, TER and TERp.The BLEU-4 and METEOR scores were computedusing 16 references.
The TER and TERp were com-puted using a single reference.4.3 Reordering model comparisonTables 1 and 2 show the scores using the differ-ent reordering models.
Consistent improvements inthe BLEU scores may be observed when changingfrom the MSD model to the models generated us-ing alignment matrices.
The results were consis-tently better using our models in the DIALOG task,since the English-Chinese language pair is more de-pendent on the reordering model.
This is evidentif we look at the difference in the scores betweenthe distance-based and the MSD models.
Further-more, in this task, we observe an improvement on allscores from the MSD model to our weighted MSDmodels, which suggests that the usage of alignmentmatrices helps predict the reordering probabilitiesmore accurately.We can also see that the context based reorderingmodel performs better than the score based modelin the BTEC task, which does not perform sig-nificantly better than the regular MSD model inthis task.
Furthermore, combining the score basedmethod with the context based method does not leadto any improvements.
We believe this is because thealignment probabilities are much more accurate inthe English-French language pair, and phrase pairscores remain consistent throughout the extraction,making the score based approach and the regularMSD model behave similarly.
On the other hand,in the DIALOG task, score based model has bet-ter performance than the regular MSD model, andthe combination of both methods yields a significantimprovement over each method alone.Table 3 shows a case where the context basedmodel is more accurate than the regular MSD model.The alignment is obviously faulty, since the word?two?
is aligned with both ?deux?, although itshould only be aligned with the first occurrence.BTEC BLEU METEOR TERp TERDistance-based 61.84 65.38 27.60 22.40MSD 62.02 65.93 27.40 22.80score MSD 62.15 66.18 27.30 22.20context MSD 62.42 66.29 27.00 22.00combined MSD 62.42 66.14 27.10 22.20Table 1: Results for the BTEC task.DIALOG BLEU METEOR TERp TERDistance-based 36.29 45.15 49.00 41.20MSD 39.56 46.85 47.20 39.60score MSD 40.2 47.16 46.52 38.80context MSD 40.14 47.14 45.88 39.00combined MSD 41.03 47.69 46.20 38.20Table 2: Results for the DIALOG task.Furthermore, the word ?twin?
should be alignedwith ?a` deux lit?, but it is aligned with ?cham-bres?.
If we use the 1-best alignment to computethe reordering type of the sentence pair ?Je voudraisre?server deux?
/ ?I?d like to reserve two?, the re-ordering type for the following orientation wouldbe monotonous, since the next word ?chambres?is falsely aligned with ?twin?.
However, it shouldclearly be discontinuous, since the right alignmentfor ?twin?
is ?a` deux lit?.
This problem is less seri-ous when we use the weighted MSD model, sincethe orientation probability mass would be dividedbetween monotonous and discontinuous since theprobability weighted matrix for the wrong alignmentis 0.5.
On the BTEC task, some of the other scoresare lower than the MSD model, and we suspect thatthis stems from the fact that our tuning process onlyattempts to maximize the BLEU score.5 ConclusionsIn this paper we addressed the limitations of theMSD reordering models extracted from the 1-bestalignments, and presented two algorithms to ex-tract these models from weighted alignment matri-ces.
Experiments show that our models perform bet-ter than the distance-based model and the regularMSD model.
The method based on scores showed agood performance for the Chinese-English languagepair, but the performance for the English-French pairwas similar to the MSD model.
On the other hand,the method based on context improves the results on453Alignment Je voudraisre?serverdeuxchambresa` deuxlits.I 1?d 0.7like 0.7toreserve 1two 1 0.5twin 0.5 0.5rooms 1.
1Table 3: Weighted alignment matrix for a training sen-tence pair from BTEC, with spurious alignment proba-bilities.
Alignment points with 0 probabilities are leftempty.both pairs.
Finally, on the Chinese-English test, bycombining both methods we can achieve a BLEUimprovement of approximately 1.5%.
The code usedin this work is currently integrated with the Geppettotoolkit2 , and it will be made available in the nextversion for public use.6 AcknowledgementsThis work was partially supported by FCT (INESC-ID multiannual funding) through the PIDDAC Pro-gram funds, and also through projects CMU-PT/HuMach/0039/2008 and CMU-PT/0005/2007.The PhD thesis of Tiago Lu?
?s is supported byFCT grant SFRH/BD/62151/2009.
The PhD the-sis of Wang Ling is supported by FCT grantSFRH/BD/51157/2010.
The authors also wish tothank the anonymous reviewers for many helpfulcomments.ReferencesChristopher Dyer, Smaranda Muresan, and Philip Resnik.2008.
Generalizing Word Lattice Translation.
Tech-nical Report LAMP-TR-149, University of Maryland,College Park, February.Kuzman Ganchev, Joa?o V. Grac?a, and Ben Taskar.
2008.Better alignments = better translations?
In Proceed-ings of ACL-08: HLT, pages 986?993, Columbus,Ohio, June.
Association for Computational Linguis-tics.2http://code.google.com/p/geppetto/Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics on Human Language Technology - Volume 1,NAACL ?03, pages 48?54, Morristown, NJ, USA.
As-sociation for Computational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-burch, Richard Zens, Rwth Aachen, Alexan-dra Constantin, Marcello Federico, Nicola Bertoldi,Chris Dyer, Brooke Cowan, Wade Shen, ChristineMoran, and Ondrej Bojar.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the 45th Annual Meeting of the Association forComputational Linguistics Companion Volume Pro-ceedings of the Demo and Poster Sessions, pages 177?180, Prague, Czech Republic, June.
Association forComputational Linguistics.Wang Ling, Tiago Lu?
?s, Joao Grac?a, Lu?
?sa Coheur, andIsabel Trancoso.
2010.
Towards a general and ex-tensible phrase-extraction algorithm.
In IWSLT ?10:International Workshop on Spoken Language Transla-tion, pages 313?320, Paris, France.Yang Liu, Tian Xia, Xinyan Xiao, and Qun Liu.
2009.Weighted alignment matrices for statistical machinetranslation.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing:Volume 2 - Volume 2, EMNLP ?09, pages 1017?1026,Morristown, NJ, USA.
Association for ComputationalLinguistics.Haitao Mi, Liang Huang, and Qun Liu.
2008.
Forest-based translation.
In Proceedings of ACL-08: HLT,pages 192?199, Columbus, Ohio, June.
Associationfor Computational Linguistics.Michael Paul, Marcello Federico, and Sebastian Stu?ker.2010.
Overview of the iwslt 2010 evaluation cam-paign.
In IWSLT ?10: International Workshop on Spo-ken Language Translation, pages 3?27.Joa?o V. Grac?a, Kuzman Ganchev, and Ben Taskar.
2010.Learning Tractable Word Alignment Models withComplex Constraints.
Comput.
Linguist., 36:481?504.Ashish Venugopal, Andreas Zollmann, Noah A. Smith,and Stephan Vogel.
2009.
Wider pipelines: N-bestalignments and parses in MT training.David Vilar, Maja Popovic, and Hermann Ney.
2006.Aer: Do we need to ?improve?
our alignments?
InInternational Workshop on Spoken Language Transla-tion (IWSLT), pages 205?212.454
