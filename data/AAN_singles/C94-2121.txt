Word Sense i)ismnl}iguati<)n a d Text Set mentationBas(q on I,c?ical (+ohcslOll( )KUMUI{A Manabu,  I IONI )A  TakeoSchool of \[nforma,tion Science,Japan Advanced Inst i tute of Science a.nd Technology('l'al.sunokuchi, lshikawa 923-12 Japan)c-nmil: { oku,honda}?~jaist.ac.ji~Abst rac tIn this paper, we describe ihow word sense am=biguity can be resolw'.d with the aid of lexical eo-hesion.
By checking \]exical coheshm between thecurrent word and lexical chains in the order ofthe salience, in tandem with getmration of lexica\]chains~ we realize incretnental word sense d isambiguation based on contextual infl)rmation thatlexical chains,reveah Next;, we <le~<:ribe how setmen< boundaries of a text can be determined withthe aid of lexical cohesion.
Wc can measure theplausibility of each point in the text as a segmentboundary by computing a degree of agreement ofthe start and end points of lexical chaihs.1 In t roduct ionA text is not a mere set of unrelated sentences.Rather, sentences in a text are about the samething and connected to each other\[l()\].
Cohesionand cohere'nee are said to contribute to such con-nection of the sentences.
While coherence is asemantic relationship and needs computationallyexpensive processing for identification, cohesionis a surface relationship among words iu a textand more accessible than coherence.
Cohesionis roughly classitled into reference t, co'r@tnction,and lezical coh, esion 2.Except conjmwtion that explicitly indicates l;herelationship between sentences, l;he other two<:lasses are considered to t>e similar in that the re-lationship hetweer~ sentences i in<licated by twosemantically same(or elated) words.
But lexical1Reference by pronouns and ellipsis in Halliday andHasan's classification\[3\] are included here.2Reference by flfll NPs, substitution mtd lcxical cohe-.sion in Ilalllday and Hasan's classillcation a.re includedhere.cohesion is far easier to idenlAfy than reference be-cause  1)oth words in lexical cohesion relation ap-pear  in a text while one word in reference relationis a pr<mom, or elided and has less information toinfer the other word in the relation automatically.Based on this observation, we use lexical cohe-sion as a linguistic device for discourse analysis.We call a sequence of words which are in lexiealcohesion relation with each other a Icxical chainlike \[10\].
l,exical chains tend to indicate portionsof a text; that form a semantic uttit.
And so vari.-ous lexical chains tend to appear in a text corre.spou(ling to the change of the topic.
Therefore,I.
lexical chains provide a local context to aidin the resolution of word sense ambiguity;2. lexical <'hains provide a <'lue for the determi-nation of segnlent boundaries of the text\[10\].\]n this paper, we first describe how word senseambiguity can t)e resolved with the aid of lexicalcohesion.
During the process of generating lex-i<'al chains incrementally, they are recorded in aregister in the order of the salience.
The salie'nccof lexical chains is based on their recency andlength.
Since the more salient lexical chain represents the nearby local context, by checking lexi:ca\[ cohesion between the current word and lexiealchains in the order of tile salience, in tandem withgeneratiou of lexical chains, we realize incremen.tal word sense disambiguation based on contex-tual information that lexical chains reveal.Next;, we describe how segment boundaries ofa text can be determined with the aid of lexicalcohesion.
Since the start and end points of lexicalchains it, the text tend to indicate the start andend points of the segment, we can measure theplausibility o\[' each point in the text as a segmentboundary by computing a degree of agreement ofthe sta.rt and end points of lexical chains.755Morris and Itirst\[10\] pointed out the abovetwo importance of lexical cohesion for discourseanalysis and presented a way of computinglexical chains by using Roger's InternationalThesaurus\[15\].
IIowever, in spite of their mentionto the importance, they did not present he wayof word sense disambiguation based on lexical co-hesion and they only showed the correspondencesbetween lexical chains and segment boundaries bytheir intuitive analysis.McRoy's work\[8\] can be considered as the onethat uses the information of lexical cohesion forword sense disambiguation, but her method doesnot; take into account the necessity to arrangelexical chains dynamically.
Moreover, her wordsense disambignation method based on lexical co-hesion is not evaluated fully.In section two we outline what lexical cohe-sion is.
In section three we explain the way ofincremental generation of  lexical chains in tan-dem with word sense disambiguation a d describethe result of the evaluation of our disambiguationmethod.
In section four we explain the measureof the plausibility of segment boundaries and de-scribe the result of the evaluation of our measure.2 Lex ica l  Cohes ionConsider the following example, which is theEnglish translation of the fragment of one ofJapanese texts that we use for the experimentlater.In the universe that continues expancbing, a number of stars have appearedaml disappeared again and again.
Andabout ten billion years after tile birthof the universe, in the same way asthe other stars, a primitive galaxy wasformed with the primitive sun as thecenter.Words {nniverse, star, universe, star, galaxy,sun} seem to be semantically same or related toeach other and they are included in the same cat-egory in Roget's International Thesaurus.
LikeMorris and tIirst, we compute such sequences ofrelated words(lexical chains) by using a thesaurusas the knowledge base to take into account notonly the repetition of the same word but the useof superordinates, subordinates, and synonyms.We.
use a Japanese thesaurus 'Bnnrui-goihyo'\[1\].
Bunrui-goihyo has a similar organi-zation to Roger's: it consists of 798 categoriesand has a hierarchical structure above this level.For each word, a list of category numbers whichcorresponds to its multiple word senses is given.We count a sequence of words which are includedin the same category as a lexical chain.
It mightbe (:lear that this task is computationally trivial.Note that we regard only a sequence of words inthe same category as a lexical chain, rather thanusing the complete Morris and Hirst's frameworkwith five types of thesaural relations.The word sense of a word can be determinedin its context.
For example, in the context{universe, star, universe, star, galaxy, sun}, theword 'earth' has a 'planet' sense, not a 'ground'one.
As clear from this example, lexical chains('an be used as a contextual aid to resolve wordsense ambiguity\[10\].
In the generation processof lexical chains, by choosing the lexical chainthat the current word is added to, its word senseis determined.
Thus, we regard word sense dis-ambiguation as selecting the most likely categorynumber of the thesaurus, as similar to \[16\].l';arlier we proposed incremental disambigua-tion method that uses intrasentential informa-tion, such as selectional restrictions and caseframes\[l 2\].
In the next section, we describe incre-mental disambiguation method that uses lexicalchains as intersentential(contextual) information.3 Generat ion  of  Lex ica l  Cha insIn the last section, we showed that lexical chainscarl play a role of local context, t\]owever, multi-ple lexical chains might cooccur in portions of atext and they might vary in their plausibility aslocal context.
For this reason, for lexical chainsto function truly as local context, it is necessaryto arrange them in the order of the salience thatindicates the degree of tile plausibility.
We basethe salience on the following two factors: the re-cency and the length.
The more recently updatedchains are considered to be the more activatedcontext in the neighborhood and are given moresalience.
The longer chains are considered to bemore about the topic in the neighborhood andare given more salience.By checking lexical cohesion between the cu>rent word and lexical chains in the order of thesalience, the lexical chain that is selected to addthe current word determines its word sense andplays a role of local context.Based on this idea, incremental generation of756lexical chains realizes incremental word sense dis-ambiguation using contextual information thatlexical chains reveal.
During the generationof lexical chains, their salience is also incrementally updated.
We think incrementaldisambiguation\[9\] is a better strategy, becausea combinatorial explosion of the number of total ambiguities rnight occur if ambiguity in notresolved as early as possible during the analytical process.
Moreover, incremental word sensedisarnbiguation is indist)ensable during the gemeration of lexical chains if lexical chains are usedfor incremental nalysis, because tile word senseambiguity might cause many undesirable l xicalchains and they might degrade the performance,of the analysis(in this case, the disambignationitself).3.1 The A lgor i thmFirst of all, a &~pauese text is automatically seg--mented into a sequence of words 1)y the morpho-logical analysis\[l 1\].
Ih-om tile result of the |nor-phological analysis, candidate words are selectedto inch.lde in lexical chains.
We consider onlynouns, verbs, and adjectives, with sonte exceplions such as nouns in adverbial use and verbs inpostpositional use.Next lexical chains are formed.
Lexical cohe-sion among candidate words inside a sentence isfirst; checked by using the thesaurus.
Ilere theword sense of the current w/)rd might be deter-mined.
This preference for lexica.1 cohesion insidea sentence over the intersentential one retlects ourobservation that the former nfight be tighter.After the analysis htside a sentence, i:audidatewords are tried to be added to one of the lexi-eal chains that are recorded in the register in theorder of the above salience.
The ih'st chain thatthe current word has tile lexica\] cohesion relationis selected.
The salience of the selected lexicalchain gets higher and then the arrangement inthe register is updated.Here not ()lily the word sense amt)iguity of thecurrent word is resolved but the word sense of theamt)iguous words in the selected \]exica\[ chain caualso be determined.
Because the lexical chain getshigher salience, other word senses of the mnhiguous words in the lexic~d chain whi/-h correspondto other lexical chains can he rejected.
Therefore,, lcxica\] chains can be used riot only a.s priorcontext but, also later context for word seuse dis-ambiguation.If a candidate word can not be added to theexisting lexical chain, new lexieal chains for eachword sense are recorded in the register.As clear fl'om tile algorithm, rather than thetruly incremental method where the register oflexical chains is updated word by word in a sen-tenee, we adopt the incremental method whereupdates are performed at the end of each sentencebecause we regard intrasentential nformation asmore iml)ortant.The process of word sense disambiguation us-ing lexical chains is illustrated in Figure 1.
Themost salient lexical chain is located at the top inthe register.
In the initial state the word W1 re--utains aml)iguous.
When tile current unambigu-ous word W2 is added, tile chain b is selected(topleft).
The chain b t)ecomes the most salient(top-right).
Ilere the word sense ambiguity of the wordW\[ in the chain b is resolved(bottom-left).
If theword to be added is ambiguous(W3), tile wordsense corresponding to the more salient \]exiealchaln(1D21) in seh;eted(l)ottom-right).3.2 The  Ewf luat ionWc apply Lhe algodthn~ to five texts.
Tal)le lshows the system's performance.The 'correctness' of the disambiguation isjudge, d by one of the authors.
The system's per-formance is con|tinted as the quotient of the number of correctly disambiguated words by the numher of ambiguous words miuus the nmnber ofwrongly segmented words(morphological attalysisergo rs) 3,Words that relnaill ambiguous are those that(1o llOt \['orin any lexical chains with other words.F, xcept t)y the errors in the ntorphologieal naly-sis, most of the errors in the disambiguation arecaused by being dragged into the wrong context.The average performance is 63.4 %.
We thinkthe system's l?erformam:e is promising for the fol-lowing reasous:I. l,exical cohesion is not the only knowledgesour('e lbr word sense disatnbiguation and\[)roves to be usefill at least as a source sup-plernentary to our earlier framework thatused cane frmnes\[12\].2.
In fact, higher performance is reported in\[16\], thai; uses bro~der context acquired byat ,  I lie accuramy ot' the inorphological analysis will be im-l)r(wed by adding new word entries or the like.757{W2, \[ID2\]) /~'(~,p ~n b wlDmq~.hain c WI\[ID,2!
(mind ))))~ ist of a/~oiguous wordsk (Wl,{ID11,II\]121) (...,\[...,...\]) ........min b W2\[ID2\] W1\[ID11\] )ain a D<chain c )~a ind  )).,::i .4!:!
:i: x:i:!$>"f::+-.i:i::.:.....
(,,,*,, b w~I,o2j w?~eino )....
!:!:i:?
::, ~-----~ (Wl,\[ID11,ID12\]) (...,\[...,.,.\]) ........(W3, \[ID3\]., ID32 \] )//rain a ,,, )c~in cl ))~J.st of mrbiguous words ~zst of ambiguous words(...\[:..,..,\]) ........ ) ) ~,~ (.
:.\[...,...1) ........Figure 1: The process of word sense disambiguationnumber ofcandidatewordsnumber ofambiguouswordstext number ofsentencesNo.1 41 481 166No.2 26 197 71.No.3 24 212 57No.4 38 433 123No.5 24 163 82number ofwords thatremainambiguous13121911number ofcorrectlydisambiguatedwords12632347142system'sperformance(%)87.551.664.260.153.8Table 1: The performance for the disambigm~tion758training on large corl)ora , but.
our methodcan attain such tolerab\[e l vel of performancewithout any training.However, our salience of lexical chains is, ofcourse, rather naive and must be refined by us-ing other kinds of inibrmation, such as JapanesetopicM marker 'wa'.chainss tar t~end( i - 24)( 4 - 13)(14 - is)( 8 - 9)(14 - 18)texti 21234567890123456789012344 Text  Segmentat ion  by  Lex i -ca l  Cha insThe second importance of lexic~d chains is thatthey provide a clue for the deternfination of seg-ment boundaries.
(Jertain spans of sentences ina text form selnantic units and are usually calledsegments.
It is crucial to identify the segmentboundaries as a first step to construct the struc-ture of a text\[2\].4.1 The  Measure  for Segnmnt  t ioun<l -a r iesWhen a portion of a text forms a semantic unit,there is a tendency for related words to be used.Therefore, if lexical chains can be found, theywill ten(t to indicate the segment boundaries ofthe text.
When a l.exical chain ends, there is atendency for a segment o end.
\[f a, llew chainbegins, this might be an indication thai; a newsegment has begun\[l 0\].
Taking into account iffscorrespondence of \[exieal chain boundaries to seg-ment boundaries, we measure the plausibilit;y eleach point; in the text; as ~ segment hotmdary: tbreach point between sentences n an(l 'n k I (whereit ranges fl'om 1 to the m|nlt)er el' sentences in thetext minus 1), compute the stun of the numl)erof lexical chains that en(l at the sentence ?z andthe number of lexical chains that begin at thesentence n + 1.
We call this naive measure of adegree of agreement of the start and end points oflexicM chains w(n ,n  + l) boundary strength like\[14\].
The points ill the text are selected in theorder of boundary strength as candidates of seg-ment boundaries.Consider for example the live lexieal chains inthe imaginary text that consists of 24 sentences inFigure 2.
In this text, the boundary strength canbe computed as follows: w(a,4)  = 1,, .
,(7,s) -1,w(9,10) ~- 1,w(13,14) -- 3,. .
.
.Figure 2: l,exieal chains in the text4.2 The  Evahmt ionWe, try to segnient the texts ill section 3.2and apply the above measure to the lexicalchains that were tbluned.
We pick out threetexts(No.3,4,5), which are fi:om the exam questions of the Japanese language, that ask us to par-tiglon the texts into a given number of segments.The system's performmwe is judged by the com.p~rison with segment boundaries marked as anattaehe(l model answer.
Two more texts(No.6,7)\['rom the questions are also tried to be segtnented.Here we do not t:M~e into account he intbrmation of paragraph lmundaries, uch as the indenration, at all in the following rea,sons:?
\ ]{cea l l se  OllF texts  aFe h 'o in  the exam questions, nla, ny  ()f them have no I\]Tta, rks  of para-graph I)oundaries;?
ill?
case of ,laps.nose, it is pointed out thatparagraph and segment boundaries do notalways coincide with each other\[l 3\].Table 2 shows the t)crformanee in case wherethe system generates the given number of segmentbotm(laries 4 in the order el" the strength.
FromTable 2, we can compute the system's marks asan exanlinee in tim Lest that consists of these fivequesLiolm.
Tal-)le 3 shows the performance in casewhere segment boundm:ies are generated own tohalf of the maximum strength.
'l'he metrics thatwe.
use for the ewduation are as follows: Recall isthe quotient of' the in|tuber of correctly identifiedboundaries by the total mmlber of correct boundaries.
Precision is the quotient of the nmnber of(:orre(:t\[y identifie(l I)ounda, ries by the tnllnl)er ofgenerated boundaries.We think the poor result for the text No.5might be caused by the difficulty of tile text~The number of boundaries to be given is the mtmberof segments given in the question minus 1.759textNo.3No.4No.5No.6No.7given number ofboundariesnumber ofcorrect boundaries1 16 31 043 1Table 2: The performance for the segmenta-t ion(l)textI _ _No.3No.4No.5No.6No.7number ofgeneratedboundariesnumber ofcorrectboundaries3 110 37 35 1rec.
prec.I1 0.3 H0.--T-~0~-% o 1o.7---~ o.4~\]_ 0.aK 0.20 ATable 3: The performance for the segmenta-tion(2)itself because it is written by one of themost difficult writers in Japan, KOBAYASH\[Hideo.
Table 2 shows that our system gets8 (1+3+3+1) /15(1+6+1+4F3)= 5  % in thetest.
From Table 3, the average recall and pre-cision rates are 0.52 and 0.25 respectively.
Ofcourse these results are unsatisfactory, but wethink this measure for segment boundaries ispromising and useful as a preliminary one.Since lexical chains are considered to be dif-ferent in their degree of contribution to segmentboundaries, we arc now refining the measure bytaking into account heir importance.
We basethe importance of lexical chains on the followingtwo factors:1.
The lexical chains that include more wordswith topical marker 'wa' get more impor-tance.2.
The longer lexical chains tend to represent asemantic unit and get more importance.The start and end points of the more impor-tant lexical chains can get the more boundarystrength.
This refinement of the measure is inthe process and yields a certain extent of improve-ment of the system's performance.Moreover, this ewduation method is not nec-essarily adequate since partitioning into a largernumber of smaller segments might be possibleand be necessary for the given texts.
And so wewill have to consider the evaluation method thatthe agreement with hmnan subjects is tested infuture.
Ilowever, since human subjects do not al-ways agree with each other on segmentation\[6, 4,14\], our evaluation method using the texts in thequestions with model answers is considered to bea good simplification.Several other methods to text segmentationhave been proposed.
Kozima\[7\] and Youmans\[17\]proposed statistical measures(they are namedLCP and VMP respectively), which indicate theplausibility of text points as a segment bound-ary.
Their hills or valleys tend to indicate seg-ment boundaries.
However, they only showed thecorrelation between their measures and segmentboundaries by their intuil, ive analysis of few sam-ple texts, and so we cannot compare our system'sand their performance precisely.ltearst\[5\] independently proposes a similarmeasure for text segmentation a d evaluates theperformance o\[ her method with precision and re-call rates.
However, her segmentation methoddepends heavily on the information of paragraphboundaries and always partitions a text at thepoints of paragraph boundaries.5 Conc lus ionWe showed that lexical cohesion can be used as aknowledge source for word sense disambiguationand text segrnentatinn.
We think our method ispromising, although only partially successful re-sults can be obtained in the experiments so far.Here we reported some preliminary positive re-sults and made some suggestions for how to im-prove the method in future.
The improvement ofthe method is now under way.In addition, because computation of lexicalchains depends completely on the thesaurus used,we think the comparison among the results bydifferent hesauri would be insightful and are nowplanning.
\[t it also necessary to incorporate othertextual information, such as clue words, whichcan be computationally accessible to improve theperformance.760References\[1\] Bunrui-Goihyo.
Shuei Shuppan., :1964. inJapanese.\[2\] B.J.
Grosz and C.L.
Sidner.
Attention,intentions, and the structure of discourse.Coraputationol Li~iguistics, 12(3):175 204,1986.\[3\] It.
A. K. ftalliday and R. Hassan.
Cohesionin English.
Longman, 1976.\[4\] M.A.
ltearst.
Texttiling: A quantitative ap-proach to discourse segmentation.
Techni-cal Report 93/24, University of California,Berkeley, 1993.\[5\] M.A.
Hearst.
Multi-paragraph segmentwtion of expository texts.
Technical Report94/790, Uniw~rsity of California, Berkeley,1994:.\[6\] J. ttirschberg and B.
C, rosz.
lnt:onational fea-tures of local and global discourse structure.In Proc.
of the Darpa Workshop on Speechand Natu~vd Language, pages ,141- 446, 1992.\[7\] H. Kozima.
Text segmentation based on sim-ilarity between words.
In Proc.
of the 31stA nn.lLal Meeting of the Association for Com-putational Linguistics, pages 286 288, 1993.\[8\] S.W.
Mcll~oy.
Using multiple knowledgesources for word sense discrimination.
Com-putational Linguistics , 18(1):1 30, 1992.\[9\] C.S.
Mellish.
Computer Interpretation ofNatural Language Descriptions.
Ellis Hor--wood, 1985.\[10\] J. Morris and G. tlirst.
Lexical cohesioncomputed by thesaural relations as an indi-cator of the structure of text.
ComputationalLinguistics, 17(1.
):21-48, 1991.\[11\] Nagao Lab., Kyoto University.
,\]apancscMorphological Analysis System ,\]UMANManual Version l.O, 1993. in ,lapanese.\[12\] M. Okumura and H. Tanaka.
Towards in-cremental disambiguation with a general-ized discrimination etwork.
In Proc.
of the8th National Conference on Arti\]icial Intel-ligence, pages 990 995, 1990.\[13\] T. Ookuma.
Gengo tan'i toshite no bun~shou.
Nihongo gaku, 11(4):20-25, 1992. inJapanese.\[14\] R.J. Passonneau.
Intention-based segmenta.-tion: Human reliability and correlation withlinguistic cues.
In Proc.
of the 31st An-nual Meeting of the Association for Compu-tational Linguistics, pages 148-155, 1993.\[15\] P. I{oget.
Roget's International Thesaurus,Fourth Edition.
Harper and Row PublishersInc., 1977.\[16\] D. Yarowsky.
Word-sense disambiguationusing statistical models of roget's categoriestrained on large corpora.
In Proc.
of the ldth.\['ntcrnational Co~@re~nce on ComputationalLinguistics, pages 454--460, 1992.\[17\] G. Youmans.
A new tool for discourse anal-ysis: The vocabulary-management profile.Language , 67:763--789, 1991.7(/1
