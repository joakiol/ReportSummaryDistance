Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 24?28,Baltimore, Maryland USA, June 26-27 2014. c?2014 Association for Computational LinguisticsAutomated Disease Normalization with Low Rank ApproximationsRobert Leaman Zhiyong LuNational Center for Biotechnology InformationNational Library of Medicine{robert.leaman, zhiyong.lu}@nih.govAbstractWhile machine learning methods fornamed entity recognition (mention-leveldetection) have become common, ma-chine learning methods have rarely beenapplied to normalization (concept-levelidentification).
Recent research intro-duced a machine learning method fornormalization based on pairwise learningto rank.
This method, DNorm, uses a lin-ear model to score the similarity betweenmentions and concept names, and hasseveral desirable properties, includinglearning term variation directly fromtraining data.
In this manuscript we em-ploy a dimensionality reduction tech-nique based on low-rank matrix approx-imation, similar to latent semantic index-ing.
We compare the performance of thelow rank method to previous work, usingdisease name normalization in the NCBIDisease Corpus as the test case, anddemonstrate increased performance asthe matrix rank increases.
We furtherdemonstrate a significant reduction in thenumber of parameters to be learned anddiscuss the implications of this result inthe context of algorithm scalability.1 IntroductionThe data necessary to answer a wide variety ofbiomedical research questions is locked away innarrative text.
Automating the location (namedentity recognition) and identification (normaliza-tion) of key biomedical entities (Do?an et al.,2009; N?v?ol et al., 2011) such as diseases, pro-teins and chemicals in narrative text may reducecuration costs, enable significantly increasedscale and ultimately accelerate biomedical dis-covery (Wei et al., 2012a).Named entity recognition (NER) techniqueshave typically focused on machine learningmethods such as conditional random fields(CRFs), which have provided high performancewhen coupled with a rich feature approach.
Theutility of NER for biomedical end users is lim-ited, however, since many applications requireeach mention to be normalized, that is, identifiedwithin a specified controlled vocabulary.The normalization task has been highlighted inthe BioCreative challenges (Hirschman et al.,2005; Lu et al., 2011; Morgan et al., 2008),where a variety of methods have been exploredfor normalizing gene names, including stringmatching, pattern matching, and heuristic rules.Similar methods have been applied to diseasenames (Do?an & Lu, 2012b; Kang et al., 2012;N?v?ol et al., 2009) and species names (Gerneret al., 2010; Wei et al., 2012b), and the MetaMapprogram is used to locate and identify conceptsfrom the UMLS MetaThesaurus (Aronson, 2001;Bodenreider, 2004).Machine learning methods for NER have pro-vided high performance, enhanced system adapt-ability to new entity types, and abstracted manydetails of specific rule patterns.
While machinelearning methods for normalization have beenexplored (Tsuruoka et al., 2007; Wermter et al.,2009), these are far less common.
This is partial-ly due to the lack of appropriate training data,and also partially due to the need for a general-izable supporting framework.Normalization is frequently decomposed intothe sub-tasks of candidate generation and disam-biguation (Lu et al., 2011; Morgan et al., 2008).During candidate generation, the set of conceptnames is constrained to a set of possible matchesusing the text of the mention.
The primary diffi-culty addressed in candidate generation is termvariation: the need to identify terms which aresemantically similar but textually distinct (e.g.?nephropathy?
and ?kidney disease?).
The dis-ambiguation step then differentiates between thedifferent candidates to remove false positives,typically using the context of the mention and thearticle metadata.24Recently, Leaman et al.
(2013a) developed analgorithm (DNorm) that directly addresses theterm variation problem with machine learning,and used diseases ?
an important biomedical en-tity ?
as the first case study.
The algorithm learnsa similarity function between mentions and con-cept names directly from training data using amethod based on pairwise learning to rank.
Themethod was shown to provide high performanceon the NCBI Disease Corpus (Do?an et al., 2014;Do?an & Lu, 2012a), and was also applied toclinical notes in the ShARe / CLEF eHealth task(Suominen et al., 2013), where it achieved thehighest normalization performance out of 17 in-ternational teams (Leaman et al., 2013b).
Thenormalization step does not consider context, andtherefore must be combined with a disambigua-tion method for tasks where disambiguation isimportant.
However, this method provides highperformance when paired with a conditional ran-dom field system for NER, making the combina-tion a step towards fully adaptable mentionrecognition and normalization systems.This manuscript adapts DNorm to use a di-mensionality reduction technique based on lowrank matrix approximation.
This may provideseveral benefits.
First, it may increase the scala-bility of the method, since the number of pa-rameters used by the original technique is pro-portional to the square of the number of uniquetokens.
Second, reducing the number of parame-ters may, in turn, improve the stability of themethod and improve its generalization due to theinduction of a latent ?concept space,?
similar tolatent semantic indexing (Bai et al., 2010).
Final-ly, while the rich feature approach typically usedwith conditional random fields allows it to par-tially compensate for out-of-vocabulary effects,DNorm ignores unknown tokens.
This reducesthe ability of the model to generalize, due to thezipfian distribution of text (Manning & Sch?tze,1999), and is especially problematic in textwhich contains many misspellings, such as con-sumer text.
Using a richer feature space withDNorm would not be feasible, however, unlessthe parameter scalability problem is resolved.In this article we expand the DNorm methodin a pilot study on feasibility of using low rankapproximation methods for disease name nor-malization.
To make this work comparable to theprevious work on DNorm, we again employedthe NCBI Disease Corpus (Do?an et al., 2014).This corpus contains nearly 800 abstracts, splitinto training, development, and test sets, as de-scribed in Table 1.
Each disease mention is anno-tated for span and concept, using the MEDICvocabulary (Davis et al., 2012), which combinesMeSH?
(Coletti & Bleich, 2001) and OMIM?
(Amberger et al., 2011).
The average number ofconcepts for each name in the vocabulary is 5.72.Disease names exhibit relatively low ambiguity,with an average number of concepts per name of1.01.Subset Abstracts Mentions ConceptsTraining 593 5145 670Development 100 787 176Test 100 960 203Table 1.
Descriptive statistics for the NCBI DiseaseCorpus.2 MethodsDNorm uses the BANNER NER system(Leaman & Gonzalez, 2008) to locate diseasementions, and then employs a ranking method tonormalize each mention found to the diseaseconcepts in the lexicon (Leaman et al., 2013a).Briefly, we define   to be the set of tokens fromboth the disease mentions in the training data andthe concept names in the lexicon.
We stem eachtoken in both disease mentions and conceptnames (Porter, 1980), and then convert each toTF-IDF vectors of dimensionality | |, where thedocument frequency for each token is taken to bethe number of names in the lexicon containing it(Manning et al., 2008).
All vectors are normal-ized to unit length.
We define a similarity scorebetween mention vector   and name vector  ,(   ), and each mention is normalized byiterating through all concept names and returningthe disease concept corresponding to the onewith the highest score.In previous work,      (   )      ,where  is a weight matrix and each entryrepresents the correlation between token    ap-pearing in a mention and token    appearing in aconcept name from the lexicon.
In this work,however, we set  to be a low-rank approxima-tion of the form       , where   andare both   | |  matrices,   being the rank(number of linearly independent rows), and| | (Bai et al., 2010).For efficiency, the low-rank scoring functioncan be rewritten and evaluated as      (   )(  ) (  )     , allowing the respectiveand    vectors to be calculated once and thenreused.
This view provides an intuitive explana-tion of the purpose of the  and   matrices: to25convert the sparse, high-dimensional mentionand concept name vectors (  and  ) into dense,low dimensional vectors (as    and   ).
Underthis interpretation, we found that performanceimproved if each    and    vector was renor-malized to unit length.This model retains many useful properties ofthe original model, such as the ability to repre-sent both positive and negative correlations be-tween tokens, to represent both synonymy andpolysemy, and to allow the token distributionsbetween the mentions and the names to be differ-ent.
The new model also adds one important ad-ditional property: the number of parameters islinear in the number of unique tokens, potentiallyenabling greater scalability.2.1 Model TrainingGiven any pair of disease names where one (  )is for   , the correct disease concept fortion , and the other,   , is for   , an incorrectconcept , we would like to update the weight ma-trix   so that            .
FollowingLeaman et al.
(2013a), we  iterate through each?
?
tuple, selecting   and   as the namefor    and   , respectively, with the highest sim-ilarity score to , using stochastic gradient de-scent to make updates to .
With a dense weightmatrix  , the update rule is: if, then   is updated as( (  )   (  ) ) , where   is the learningrate, a parameter controlling the size of thechange to W. Under the low-rank approximation,the update rules are: if             ,then   is updated as       (     )  ,and   is updated as        (     ) ,noting that the updates are applied simultaneous-ly (Bai et al., 2010).
Overfitting is avoided usinga holdout set, using the average of the ranks ofthe correct concept as the performance measure-ment, as in previous work.We initialize   using values chosen randomlyfrom a normal distribution with mean 0 andstandard deviation 1.
We found it useful to ini-tialize   as   , since this causes the representa-tion for disease mentions and disease names toinitially be the same.We employed an adaptive learning rate usingthe schedule, where   is the itera-tion,    is the initial learning rate, and   is thediscount (Finkel et al., 2008).
We used an initiallearning rate of.
This is much lowerthan reported by Leaman et al.
(2013a), since wefound that higher values caused the training tofound that higher values caused the training todiverge.
We used a discount parameter of    ,so that the learning rate is equal to one half theinitial rate after five iterations.3 ResultsOur results were evaluated at the abstract level,allowing comparison to the previous work onDNorm (Leaman et al., 2013a).
This evaluationconsiders the set of disease concepts found in theabstract, and ignores the exact location(s) whereeach concept was found.
A true positive consistsof the system returning a disease concept anno-tated within the NCBI Disease Corpus, and thenumber of false negatives and false positives aredefined similarly.
We calculated the precision,recall and F-measure as follows:We list the micro-averaged results in Table 2.Rank Precision Recall F-measure50 0.648 0.671 0.659100 0.673 0.685 0.679250 0.697 0.697 0.697500 0.702 0.700 0.701(Full) 0.828 0.819 0.809Table 2.
Performance measurements for eachmodel on the NCBI Disease Test set.
Full corre-sponds with the full-rank matrix used in previouswork.4 DiscussionThere are two primary trends to note.
First, theperformance of the low rank models is about10%-15% lower than the full rank model.
Sec-ond, there is a clear trend towards higher preci-sion and recall as the rank of the matrix increas-es.
This trend is reinforced in Figure 1, whichshows the learning curve for all models.
Thesedescribe the performance on the holdout set aftereach iteration through the training data, and aremeasured using the average rank of the correctconcept in the holdout set, which is dominatedby a small number of difficult cases.Using the low rank approximation, the numberof parameters is equal to     | |.
Since   isfixed and independent of | |, the number of pa-rameters is now linear in the number of tokens,effectively solving the parameter scalabilityproblem.
Table 3 lists the number of parametersfor each of the models used in this study.26Figure 1.
Learning curves showing holdout per-formance at each iteration through the trainingdata.Rank Parameters50 1.8?106100 3.7?106250 9.1?106500 1.8?107(Full) 3.3?108Table 3.
Number of model parameters for eachvariant, showing the low rank methods using 1 to2 orders of magnitude fewer parameters.There are two trade-offs for this improvementin scalability.
First, there is a substantial perfor-mance reduction, though this might be mitigatedsomewhat in the future by using a richer featureset ?
a possibility enabled by the use of the lowrank approximation.
Second, training and infer-ence times are significantly increased; trainingthe largest low-rank model (     ) requiredapproximately 9 days, though the full-rank mod-el trains in under an hour.The view that the   and   matrices convert theTF-IDF vectors to a lower dimensional spacesuggests that the function of   and   is to pro-vide word embeddings or word representations ?a vector space where each word vector encodesits relationships with other words.
This furthersuggests that one way to provide higher perfor-mance may be to take advantage of unsupervisedpre-training (Erhan et al., 2010).
Instead of ini-tializing   and   randomly, they could be initial-ized using a set of word embeddings trained on alarge amount of biomedical text, such as withneural network language models (Collobert &Weston, 2008; Mikolov et al., 2013).5 ConclusionWe performed a pilot study to determine whethera low rank approximation may increase thescalability of normalization using pairwise learn-ing to rank.
We showed that the reduction in thenumber of parameters is substantial: it is nowlinear to the number of tokens, rather than pro-portional to the square of the number of tokens.We further observed that the precision and recallincrease as the rank of the matrices is increased.We believe that further performance increasesmay be possible through the use of a richer fea-ture set, unsupervised pre-training, or other di-mensionality reduction techniques including fea-ture selection or L1 regularization (Tibshirani,1996).
We also intend to apply the method toadditional entity types, using recently releasedcorpora such as CRAFT (Bada et al., 2012).AcknowledgmentsThe authors would like to thank the anonymousreviewers for their helpful suggestions.
This re-search was supported by the NIH Intramural Re-search Program, National Library of Medicine.ReferencesAmberger, J., Bocchini, C., & Hamosh, A.
(2011).
Anew face and new challenges for OnlineMendelian Inheritance in Man (OMIM(R)).
HumMutat, 32(5), 564-567.Aronson, A. R. (2001).
Effective mapping ofbiomedical text to the UMLS Metathesaurus: theMetaMap program.
In  Proceedings of the AMIASymposium, 17-21.Bada, M., Eckert, M., Evans, D., Garcia, K., Shipley,K., Sitnikov, D., et al.
(2012).
Concept annotationin the CRAFT corpus.
BMC Bioinformatics, 13,161.Bai, B., Weston, J., Grangier, D., Collobert, R.,Sadamasa, K., Qi, Y. J., et al.
(2010).
Learning torank with (a lot of) word features.
Inform.Retrieval, 13(3), 291-314.Bodenreider, O.
(2004).
The Unified MedicalLanguage System (UMLS): integrating biomedicalterminology.
Nucleic Acids Res, 32, D267-270.Coletti, M. H., & Bleich, H. L. (2001).
Medicalsubject headings used to search the biomedicalliterature.
J Am Med Inform Assoc, 8(4), 317-323.Collobert, R., & Weston, J.
(2008).
A unifiedarchitecture for natural language processing:deep neural networks with multitask learning.
InProceedings of the ICML, 160-167.Davis, A. P., Wiegers, T. C., Rosenstein, M. C., &Mattingly, C. J.
(2012).
MEDIC: a practicaldisease vocabulary used at the Comparative20304050607080901000 5 10AveragerankIteration50100250500Full27Toxicogenomics Database.
Database, 2012,bar065.Do?an, R. I., Leaman, R., & Lu, Z.
(2014).
NCBIdisease corpus: A resource for disease namerecognition and concept normalization.
J BiomedInform, 47, 1-10.Do?an, R. I., & Lu, Z.
(2012a).
An improved corpusof disease mentions in PubMed citations.
InProceedings of the ACL 2012 Workshop onBioNLP, 91-99.Do?an, R. I., & Lu, Z.
(2012b).
An Inference Methodfor Disease Name Normalization.
In  Proceedingsof the AAAI 2012 Fall Symposium on InformationRetrieval and Knowledge Discovery inBiomedical Text, 8-13.Do?an, R. I., Murray, G. C., N?v?ol, A., & Lu, Z.(2009).
Understanding PubMed user searchbehavior through log analysis.
Database (Oxford),2009, bap018.Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., & Bengio, S. (2010).
Why doesunsupervised pre-training help deep learning?
J.Machine Learning Res., 11, 625-660.Finkel, J. R., Kleenman, A., & Manning, C. D.(2008).
Efficient, Feature-based, ConditionalRandom Field Parsing.
In  Proceedings of the 46thAnnual Meeting of the ACL, 959-967.Gerner, M., Nenadic, G., & Bergman, C. M. (2010).LINNAEUS: a species name identification systemfor biomedical literature.
BMC Bioinformatics, 11,85.Hirschman, L., Colosimo, M., Morgan, A., & Yeh, A.(2005).
Overview of BioCreAtIvE task 1B:normalized gene lists.
BMC Bioinformatics, 6Suppl 1, S11.Kang, N., Singh, B., Afzal, Z., van Mulligen, E. M.,& Kors, J.
A.
(2012).
Using rule-based naturallanguage processing to improve diseasenormalization in biomedical text.
J.
Am.
Med.Inform.
Assoc., 20, 876-881.Leaman, R., Do?an, R. I., & Lu, Z.
(2013a).
DNorm:Disease name normalization with pairwiselearning-to-rank.
Bioinformatics, 29(22), 2909-2917.Leaman, R., & Gonzalez, G. (2008).
BANNER: anexecutable survey of advances in biomedicalnamed entity recognition.
Pac.
Symp.
Biocomput.,652-663.Leaman, R., Khare, R., & Lu, Z.
(2013b).
NCBI at2013 ShARe/CLEF eHealth Shared Task:Disorder Normalization in Clinical Notes withDNorm.
In Working Notes of the Conference andLabs of the Evaluation Forum Valencia, Spain.Lu, Z., Kao, H. Y., Wei, C. H., Huang, M., Liu, J.,Kuo, C. J., et al.
(2011).
The gene normalizationtask in BioCreative III.
BMC Bioinformatics, 12Suppl 8, S2.Manning, C., & Sch?tze, H. (1999).
Foundations ofStatistical Natural Language Processing:Massachusetts Institute of Technology.Manning, C. D., Raghavan, P., & Sch?tze, H. (2008).Introduction to Information Retrieval: CambridgeUniversity Press.Mikolov, T., Yih, W.-t., & Zweig, G. (2013).Linguistic Regularities in Continuous Space WordRepresentations.
In  Proceedings of the 2013Conference of the NAACL-HLT, 746-751.Morgan, A.
A., Lu, Z., Wang, X., Cohen, A. M.,Fluck, J., Ruch, P., et al.
(2008).
Overview ofBioCreative II gene normalization.
Genome Biol.,9 Suppl 2, S3.N?v?ol, A., Do?an, R. I., & Lu, Z.
(2011).
Semi-automatic semantic annotation of PubMed queries:a study on quality, efficiency, satisfaction.
JBiomed Inform, 44(2), 310-318.N?v?ol, A., Kim, W., Wilbur, W. J., & Lu, Z.
(2009).Exploring two biomedical text genres for diseaserecognition.
In  Proceedings of the ACL 2009BioNLP Workshop, 144-152.Porter, M. F. (1980).
An algorithm for suffixstripping.
Program, 14, 130-137.Suominen, H., Salanter?, S., Velupillai, S., Chapman,W., Savova, G., Elhadad, N., et al.
(2013).Overview of the ShARe/CLEF eHealth EvaluationLab 2013.
In P. Forner, H. M?ller, R. Paredes, P.Rosso & B. Stein (Eds.
), Information AccessEvaluation.
Multilinguality, Multimodality, andVisualization (Vol.
8138, pp.
212-231): SpringerBerlin Heidelberg.Tibshirani, R. (1996).
Regression shrinkage andselection via the Lasso.
Journal of the RoyalStatistical Society Series B-Methodological, 58(1),267-288.Tsuruoka, Y., McNaught, J., Tsujii, J., & Ananiadou,S.
(2007).
Learning string similarity measures forgene/protein name dictionary look-up usinglogistic regression.
Bioinformatics, 23(20), 2768-2774.Wei, C. H., Harris, B. R., Li, D., Berardini, T. Z.,Huala, E., Kao, H. Y., et al.
(2012a).
Acceleratingliterature curation with text-mining tools: a casestudy of using PubTator to curate genes inPubMed abstracts.
Database (Oxford), 2012,bas041.Wei, C. H., Kao, H. Y., & Lu, Z.
(2012b).
SR4GN: aspecies recognition software tool for genenormalization.
PLoS One, 7(6), e38460.Wermter, J., Tomanek, K., & Hahn, U.
(2009).
High-performance gene name normalization with GeNo.Bioinformatics, 25(6), 815-821.28
