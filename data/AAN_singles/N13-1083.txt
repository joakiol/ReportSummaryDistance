Proceedings of NAACL-HLT 2013, pages 703?708,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsA Cross-language Study on Automatic Speech Disfluency DetectionWen WangSRI InternationalMenlo Park, CAwwang@speech.sri.comAndreas StolckeMicrosoft ResearchMountain View, CAanstolck@microsoft.comJiahong Yuan, Mark LibermanUniversity of PennsylvaniaPhiladelphia, PAjiahong.yuan@gmail.commarkyliberman@gmail.comAbstractWe investigate two systems for automatic dis-fluency detection on English and Mandarinconversational speech data.
The first systemcombines various lexical and prosodic fea-tures in a Conditional Random Field model fordetecting edit disfluencies.
The second systemcombines acoustic and language model scoresfor detecting filled pauses through constrainedspeech recognition.
We compare the contri-butions of different knowledge sources to de-tection performance between these two lan-guages.1 IntroductionSpeech disfluencies are common phenomena inspontaneous speech.
They consist of spoken wordsand phrases that represent self-correction, hesitation,and floor-grabbing behaviors, but do not add seman-tic information; removing them yields the intended,fluent utterance.
The presence of disfluencies inconversational speech data can cause problems forboth downstream processing (parsing and other nat-ural language processing tasks) and human readabil-ity of speech transcripts.
There has been much re-search effort on automatic disfluency detection inrecent years (Shriberg and Stolcke, 1997; Snoveret al 2004; Liu et al 2006; Lin and Lee, 2009;Schuler et al 2010; Georgila et al 2010; Zwartsand Johnson, 2011), particularly from the DARPAEARS (Effective, Affordable, Reusable Speech-to-Text) MDE (MetaData Extraction) (DARPA Infor-mation Processing Technology Office, 2003) pro-gram, which focused on the automatic transcriptionof sizable amounts of speech data and renderingsuch transcripts in readable form, for both conversa-tional telephone speech (CTS) and broadcast news(BN).However, the EARS MDE effort was focused onEnglish only, and there hasn?t been much researchon the effectiveness of similar automatic disfluencydetection approaches for multiple languages.
Thispaper presents three main innovations.
First, weextend the EARS MDE-style disfluency detectionapproach combining lexical and prosodic featuresusing a Conditional Random Field (CRF) model,which was employed for detecting disfluency on En-glish conversational speech data (Liu et al 2005),to Mandarin conversational speech, as presented inSection 2.
Second, we implement an automaticfilled pause detection approach through constrainedspeech recognition, as presented in Section 3.
Third,for both disfluency detection systems, we compareside-by-side contributions of different knowledgesources to detection performance for two languages,English and Mandarin, as presented in Section 4.Conclusions appear in Section 5.2 EARS MDE Style Automatic DisfluencyDetectionWe focus on two types of disfluencies, Fillers andEdit disfluencies, following the EARS MDE disflu-ency types modeled in (Liu et al 2006).
Fillers in-clude filled pauses (FP), discourse markers (DM),and explicit editing terms (ET).
FPs are words usedby the speakers as floor holders to maintain con-trol of a conversation.
They can also indicate hes-itations of the speaker.
In this work, English FPs703comprise uh and um, based on English CTS cor-pora.
For Mandarin, Zhao and Jurafsky found thatMandarin speakers intensively used both demonstra-tives zhege (literally ?this?)
and nage (literally ?that?
)and uh/mm as FPs based on a large speech corpus ofMandarin telephone conversation (Zhao and Juraf-sky, 2005).
We study the same set of Chinese FPs inthis study.
DMs are words or phrases related to thestructure of the discourse and help taking or keepinga turn, or serving as acknowledgment, for example,I mean, you know.
An explicit ET is an editing termin an edit disfluency that is not an FP or a DM.
Forexample, we have two action items  sorry three ac-tion items from the meeting, where sorry is an ex-plicit ET.Edit disfluencies involve syntactically relevantcontent that is either repeated, revised, or aban-doned.
The basic pattern for edit disfluencies hasthe form (reparandum)  <editing term> correc-tion.
The reparandum is the portion of the utterancethat is corrected or abandoned entirely (in the caseof restarts).
An interruption point (IP), marked with??
in the pattern, is the point at which the speakerbreaks off the original utterance and then repeats,revises, or restarts the utterance.
The editing termis optional and consists of one or more filler words.The correction is the portion of the utterance thatcorrects the original reparandum.
Revisions denotethe cases when a speaker modifies the original utter-ance with a similar syntactic structure, e.g., we havetwo action items  sorry three action items from themeeting.
Restarts denote the cases when a speakerabandons an utterance or a constituent and restartsall over again, e.g., He  I like this idea.We used a CRF model to combine lexical features,shallow syntactic features, and prosodic features forjoint detection of edit words and IP words.
A CRFdefines a global log-linear distribution of the state(or label) sequence E conditioned on an observationsequence, in our case including the word sequenceW and the features F , and optimized globally overthe entire sequence considering the context event in-formation for making decisions at each point.
Weused the Mallet package (McCallum, 2002) to im-plement the CRF model.
We used a first-order modelthat includes only two sequential events in the fea-ture set.
The CRF model is trained to maximizethe conditional log-likelihood of a given trainingset P (EjW; F ).
During testing, the most likely se-quence E is found using the Viterbi algorithm.
Toavoid over-fitting, a zero-mean Gaussian prior (Mc-Callum and Li, 2003) was applied to the parame-ters, where the variance of the prior was optimizedon the development test set.
Each word is associ-ated with a class label, representing whether it isan edit word or not.
We included IP in the targetclasses and used five states, as outside edit (O), be-gin edit with an IP (B-E+IP), begin edit (B-E), in-side edit with an IP (I-E+IP), and inside edit (I-E) (Liu et al 2006).
State transitions are also thesame as in (Liu et al 2006).
We built a HiddenMarkov Model (HMM) based part-of-speech (POS)taggers for English conversational speech and Man-darin broadcast conversation data.
After employingthe co-training approach described in (Wang et al2007), we achieved 94% POS tagging accuracy forboth data sets.
The features for CRF modeling in-clude: n-grams from words and automatically gen-erated POS tags, speaker turns, whether there is arepeated word sequence ending at a word bound-ary, whether a word is a fragment, whether thereis a predefined filler phrase after the word bound-ary, and the prosody model posterior probabilitiesfrom a decision tree model (Shriberg and Stolcke,1997) and discretized by cumulative binning (Liu etal., 2006).
The prosodic features were computedfor each interword boundary from words and pho-netic alignments of the manual transcriptions.
Weextracted the same set of prosodic features for En-glish and Mandarin data, based on duration, funda-mental frequency (f0), energy, and pause informa-tion, and nonprosodic information such as speakergender and speaker change, for training and apply-ing the decision-tree-based prosody model (Liu etal., 2006).We implemented a rule-based system for fillerword detection.
We defined a list of possible Chi-nese and English filler words, including filled pausesand discourse markers.
The rules also explore POStags assigned by our Chinese and English POS tag-gers.7043 Constrained Speech Recognition forFilled Pause DetectionWe also propose an alternative approach for auto-matic detection of FPs given speech transcripts thatomit FPs but are otherwise accurate.
This approachis motivated by situations where only an edited,?cleaned-up?
transcript is available, but where anaccurate verbatim transcript is to be recovered au-tomatically.
We treat this task as a constrainedspeech recognition problem, and investigate how ef-fectively it is solved by a state-of-the-art large vo-cabulary continuous speech recognition (LVCSR)system.
Hence, this approach can be considered ascombining LVCSR acoustic model (AM) and lan-guage model (LM) knowledge sources in a searchframework for FP detection.
Compared to the FPdetection component in the disfluency detection sys-tems described in Section 2, this alternative ap-proach explores different knowledge sources.
Inparticular, the AMs explore different front-end fea-tures compared to the lexical and prosodic featuresexplored in those disfluency detection systems pre-sented in Section 2.
Details of the front-end featuresare illustrated below.We evaluated this approach on both English andMandarin conversational speech.
For detecting FPsin English conversational speech, we used a mod-ified and simplified form of the recognition sys-tem developed for the 2004 NIST Rich Transcrip-tion Conversational Telephone Speech (CTS) eval-uations, described in (Stolcke et al 2006).
Thefirst pass of the recognizer uses a within-wordMFCC+MLP model (i.e, trained on Mel-frequencycepstral coefficient (MFCC) features augmentedwith Multi-Layer Perceptron (MLP) based phone-posterior features), while the second pass uses across-word model trained on Perceptual Linear Pre-diction (PLP) features adapted (by speaker) to theoutput of the first pass.
For purposes of FP detec-tion, the recognition is constrained to a word lat-tice formed by the manually transcribed non-FP ref-erence words, with optional FP words inserted be-tween any two words and at the beginning and endof each utterance.
Both first and second pass de-coding was constrained by the optional-FP lattices.In the second pass, HTK lattices were generatedwith bigram LM probabilities and rescored with a4-gram LM.
The consensus decoding output fromthe rescored lattices was used for scoring FP detec-tion.
The system thus evaluates the posterior prob-ability of an FP at every word boundary using bothacoustic model (AM) and language model (LM) ev-idence.
The acoustic model for the English recog-nition system was trained on about 2300 hours ofCTS data.
The language models (which models FPlike any other word) are bigram and 4-gram statisti-cal word n-gram LMs estimated from the same dataplus additional non-CTS data and web data.For detecting FPs in Mandarin broadcast con-versation speech, we used a modified form ofthe recognition system developed for the 2008DARPA GALE (Global Autonomous Language Ex-ploitation) Speech-to-Text evaluation, described in(Lei et al 2009).
The system conducted a con-strained decoding on the optional-FP lattices, usinga speaker-independent within-word triphone MPE-trained MFCC+pitch+MLP model and a prunedtrigram LM.
For the Mandarin ASR system, theMFCC+MLP front-end features were augmentedwith 3-dimension smoothed pitch features (Lei et al2006).
HTK lattices were generated with probabil-ities from the pruned trigram LM and rescored bythe full trigram LM.
The consensus decoding outputfrom the rescored lattices was used for scoring FPdetection.
The AMs for this system were trained on1642 hours of Mandarin broadcast news and conver-sation speech data and the LMs were trained on 1.4billion words comprising a variety of resources.
De-tails of training data and system development wereillustrated in (Lei et al 2009).This procedure is similar to forced aligning theword lattices to the audio data (Finke and Waibel,1997).
Both Finke et als approach (Finke andWaibel, 1997) and our approach built a lattice fromeach transcription sentence (in our approach, op-tional filled pauses are inserted between any twowords and at the beginning and end of each utter-ance).
Then Finke et alforce-aligned the latticewith utterance; whereas, we used multi-pass con-strained decoding with within-word and cross-wordmodels, MLLR adaptation of the acoustic models,and rescoring with a higher-order n-gram LM, so theperformance will be better than just flexible align-ment to the lattices.
Note that when constructingthe word lattices with optional FP words, for En-705glish, the optional FP words are a choice betweenuh and um.
For Mandarin, the optional FP wordsare a choice between uh, mm, zhege, and nage.
Weassigned equal weights to FP words.4 Experimental ResultsScoring of EARS MDE-style automatic disfluencydetection output is done using the NIST tools 1,computing the error rate as the average number ofmisclassified words per reference event word.
ForEnglish, the training and evaluation data were fromthe 40 hours CTS data in the NIST RT-04F MDEtraining data including speech, their transcriptionsand disfluency annotations by LDC.
We randomlyheld out two 3-hour subsets from this training dataset for evaluation and parameter tuning respectively,and used the remaining data for training.
Notethat for Mandarin, there is no LDC released Man-darin MDE training data.
We adapted the EnglishMDE annotation guidelines for Mandarin and man-ually annotated the manual transcripts of 92 Man-darin broadcast conversation (BC) shows releasedby LDC under the DARPA GALE program, for editdisfluencies and filler words.
We randomly held outtwo 3-hour subsets from the 92 shows for evalu-ation and parameter tuning respectively, and man-ually corrected disfluency annotation errors on theevaluation set.Table 1 shows the results in NIST error rate (%)for edit word, IP, and filler word detection.
We ob-serve that adding POS features improves edit word,edit IP, and filler word detection for both languages,and adding a prosody model produced further im-provement (note that filler word detection systemsdid not employ prosodic features).
The gains fromcombining the word, POS, and prosody model overthe word n-gram baseline are statistically significantfor both languages (confidence level p < 0:05 usingmatched pair test).
Also, adding the prosody modelover word+POS yielded a larger relative gain in editword+IP detection performance for Mandarin thanfor English data.
A preliminary study of these re-sults has shown that the prosody model contributesdifferently for different types of disfluencies for En-glish and Mandarin conversational speech and wewill continue this study in future work.
We also plan1www.itl.nist.gov/iad/mig/tests/rt/2004-fall/index.htmlto investigate the prosodic features considering thespecial characteristics of edited disfluencies in Man-darin studied in (Lin and Lee, 2009).Table 1: NIST error rate (%) for edit word, IP, and fillerword detection on the English and Mandarin test set,using word n-gram features, POS n-gram features, andprosody model.Feature NIST Error Rate (%)Edit Word Edit IP Filler WordEnglishWord 53.0 38.7 31.2+POS 52.6 38.2 29.8++Prosody 52.3 38.0 29.8MandarinWord 58.5 42.8 33.4+POS 57.7 42.1 32.9++Prosody 56.9 41.5 32.9For evaluating constrained speech recognition forFP detection, the English test set of conversationalspeech data and word transcripts is derived fromthe CTS subset of the NIST 2002 Rich Transcrip-tion evaluation.
The waveforms were segmented ac-cording to utterance boundaries given by the human-generated transcripts, resulting in 6554 utterancesegments with a total duration of 6.8 hours.
We thenexcluded turns that have fewer than five tokens orhave two or more FPs in a row (such as ?uh um?
and?uh, uh?
), resulting in 3359 segments.
This yieldsthe test set from which we computed English FP de-tection scores.
The transcripts of this test set con-tain 54511 non-FP words and 1394 FPs, transcribedas either uh or um.
When evaluating FP detectionperformance, these two orthographical forms weremapped to a single token type, so recognizing oneform as the other is not penalized.
The Mandarintest set is the DARPA GALE 2008 Mandarin speech-to-text development test set of 1 hour duration.
Thetranscripts of this test set contain 9820 non-FP wordsand 370 FP words, transcribed as uh, mm, zhege,and nage.
We collapsed them to a single token typefor FP scoring.
We evaluated FP detection perfor-mance in terms of both false alarm (incorrect detec-tion) and miss (failed detection) rates, shown in Ta-ble 2.
We observed that adding pronunciation scoresdidn?t change the Pfaand Pmiss.
On the English706test set, adding LM scores degraded Pmissbut im-proved Pfa.
However, on the Mandarin test set, in-creasing LM weight improved both Pmissand Pfa,suggesting that for the Mandarin LVCSR system inthis study, the LM could provide complementary in-formation to the AM to discriminate FP and non-FPwords.Table 2: Probabilities of false alarms (FAs) and misses inFP detection on the English and Mandarin test set w.r.t.acoustic model weight wa, language model weight wg,and pronunciation score weight wp.fwa; wg; wpg FAs (%) Misses (%)Englishf1,0,8g 1.76 3.23f1,8,8g 1.18 4.73Mandarinf1,0,8g 1.19 19.68f1,8,8g 0.76 16.765 ConclusionIn conclusion, we have presented two automatic dis-fluency detection systems, one combining variouslexical and prosodic features, and the other com-bining LVCSR acoustic and language model knowl-edge sources.
We observed significant improve-ments in combining lexical and prosodic featuresover just employing word n-gram features, for bothlanguages.
When combining AM and LM knowl-edge sources for FP detection in constrained speechrecognition, we found increasing LM weight im-proved both false alarm and miss rates for Mandarinbut degraded the miss rate for English.AcknowledgmentsThe authors thank all the anonymous reviewers ofthis paper for valuable suggestions.
This work issupported in part by NSF grant IIS-0964556.ReferencesDARPA Information Processing Technology Office.2003.
Effective,affordable, reusable speech-to-text(EARS).
http://www.darpa.mil/ipto/programs/ears.Michael Finke and Alex Waibel.
1997.
Flexible tran-scription alignment.
In IEEE Workshop on SpeechRecognition and Understanding, pages 34?40.K.
Georgila, N. Wang, and J. Gratch.
2010.
Cross-domain speech disfluency detection.
In Proceedingsof SIGDIAL, pages 237?240, Tokyo.X.
Lei, M. Siu, M.Y.
Hwang, M. Ostendorf, and T. Lee.2006.
Improved tone modeling for Mandarin broad-cast news speech recognition.
In Proceedings of Inter-speech.X.
Lei, W. Wu, W. Wang, A. Mandal, and A. Stolcke.2009.
Development of the 2008 SRI Mandarin speech-to-text system for broadcast news and conversation.
InProceedings of Interspeech, Brighton, UK.C.
K. Lin and L. S. Lee.
2009.
Improved featuresand models for detecting edit disfluencies in transcrib-ing spontaneous mandarin speech.
IEEE Transac-tions on Audio, Speech, and Language Processing,17(7):1263?1278, September.Yang Liu, Elizabeth Shriberg, Andreas Stolcke, and MaryHarper.
2005.
Comparing HMM, maximum entropy,and conditional random fields for disfluency detec-tion.
In Proc.
Interspeech, pages 3313?3316, Lisbon,September.Yang Liu, Elizabeth Shriberg, Andreas Stolcke, DustinHillard, Mari Ostendorf, and Mary Harper.
2006.Enriching speech recognition with automatic detec-tion of sentence boundaries and disfluencies.
IEEETransactions on Audio, Speech, and Language Pro-cessing, 14(5):1526?1540, September.
Special Issueon Progress in Rich Transcription.A.
McCallum and W. Li.
2003.
Early results for namedentity recognition with conditional random fields.
InProceedings of the CoNLL.Andrew McCallum.
2002.
Mallet: A machine learningfor language toolkit.
http://mallet.cs.umass.edu.W.
Schuler, S. AbdelRahman, T. Miller, and L. Schwartz.2010.
Broad-coverage incremental parsing usinghuman-like memory constraints.
Computational Lin-guistics, 36(1).E.
Shriberg and A. Stolcke.
1997.
A prosody-onlydecision-tree model for disfluency detection.
In Pro-ceedings of Eurospeech, pages 2383?2386.M.
Snover, B. Dorr, and R. Schwartz.
2004.
A lexically-driven algorithm for disfluency detection.
In Su-san Dumais, Daniel Marcu, and Salim Roukos, edi-tors, Proc.
HLT-NAACL, Boston, May.
Association forComputational Linguistics.Andreas Stolcke, Barry Chen, Horacio Franco, VenkataRamana Rao Gadde, Martin Graciarena, Mei-YuhHwang, Katrin Kirchhoff, Arindam Mandal, NelsonMorgan, Xin Lin, Tim Ng, Mari Ostendorf, KemalSo?nmez, Anand Venkataraman, Dimitra Vergyri, WenWang, Jing Zheng, and Qifeng Zhu.
2006.
Recent in-novations in speech-to-text transcription at SRI-ICSI-UW.
IEEE Trans.
Audio, Speech, and Lang.
Pro-707cess., 14(5):1729?1744, September.
Special Issue onProgress in Rich Transcription.W.
Wang, Z. Huang, and M. P. Harper.
2007.
Semi-supervised learning for part-of-speech tagging of Man-darin transcribed speech.
In Proceedings of ICASSP,pages 137?140.Y.
Zhao and D. Jurafsky.
2005.
A preliminary study ofmandarin filled pause.
In Proceedings of DISS, pages179?182, Aix-en-Provence.S.
Zwarts and M. Johnson.
2011.
The impact of lan-guage models and loss functions on repair disfluencydetection.
In Proceedings of ACL/HLT, pages 703?711, Portland.708
