Proceedings of the 43rd Annual Meeting of the ACL, pages 467?474,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsAlignment Model Adaptation for Domain-Specific Word AlignmentWU Hua, WANG Haifeng, LIU ZhanyiToshiba (China) Research and Development Center5/F., Tower W2, Oriental PlazaNo.1, East Chang An Ave., Dong Cheng DistrictBeijing, 100738, China{wuhua, wanghaifeng, liuzhanyi}@rdc.toshiba.com.cnAbstractThis paper proposes an alignmentadaptation approach to improvedomain-specific (in-domain) wordalignment.
The basic idea of alignmentadaptation is to use out-of-domain corpusto improve in-domain word alignmentresults.
In this paper, we first train twostatistical word alignment models with thelarge-scale out-of-domain corpus and thesmall-scale in-domain corpus respectively,and then interpolate these two models toimprove the domain-specific wordalignment.
Experimental results show thatour approach improves domain-specificword alignment in terms of both precisionand recall, achieving a relative error ratereduction of 6.56% as compared with thestate-of-the-art technologies.1 IntroductionWord alignment was first proposed as anintermediate result of statistical machinetranslation (Brown et al, 1993).
In recent years,many researchers have employed statistical models(Wu, 1997; Och and Ney, 2003; Cherry and Lin,2003) or association measures  (Smadja et al,1996; Ahrenberg et al, 1998; Tufis and Barbu,2002) to build alignment links.
In order to achievesatisfactory results, all of these methods require alarge-scale bilingual corpus for training.
When thelarge-scale bilingual corpus is not available, someresearchers use existing dictionaries to improveword alignment (Ker and Chang, 1997).
However,only a few studies (Wu and Wang, 2004) directlyaddress the problem of domain-specific wordalignment when neither the large-scaledomain-specific bilingual corpus nor thedomain-specific translation dictionary is available.In this paper, we address the problem of wordalignment in a specific domain, in which only asmall-scale corpus is available.
In thedomain-specific (in-domain) corpus, there are twokinds of words: general words, which alsofrequently occur in the out-of-domain corpus, anddomain-specific words, which only occur in thespecific domain.
Thus, we can use theout-of-domain bilingual corpus to improve thealignment for general words and use the in-domainbilingual corpus for domain-specific words.
Weimplement this by using alignment modeladaptation.Although the adaptation technology is widelyused for other tasks such as language modeling(Iyer et al, 1997), only a few studies, to the best ofour knowledge, directly address word alignmentadaptation.
Wu and Wang (2004) adapted thealignment results obtained with the out-of-domaincorpus to the results obtained with the in-domaincorpus.
This method first trained two models andtwo translation dictionaries with the in-domaincorpus and the out-of-domain corpus, respectively.Then these two models were applied to thein-domain corpus to get different results.
Thetrained translation dictionaries were used to selectalignment links from these different results.
Thus,this method performed adaptation through resultcombination.
The experimental results showed asignificant error rate reduction as compared withthe method directly combining the two corpora astraining data.In this paper, we improve domain-specific wordalignment through statistical alignment modeladaptation instead of result adaptation.
Our methodincludes the following steps: (1) two wordalignment models are trained using a small-scalein-domain bilingual corpus and a large-scale467out-of-domain bilingual corpus, respectively.
(2) Anew alignment model is built by interpolating thetwo trained models.
(3) A translation dictionary isalso built by interpolating the two dictionaries thatare trained from the two training corpora.
(4) Thenew alignment model and the translation dictionaryare employed to improve domain-specific wordalignment results.
Experimental results show thatour approach improves domain-specific wordalignment in terms of both precision and recall,achieving a relative error rate reduction of 6.56%as compared with the state-of-the-art technologies.The remainder of the paper is organized asfollows.
Section 2 introduces the statistical wordalignment model.
Section 3 describes ouralignment model adaptation method.
Section 4describes the method used to build the translationdictionary.
Section 5 describes the modeladaptation algorithm.
Section 6 presents theevaluation results.
The last section concludes ourapproach.2 Statistical Word AlignmentAccording to the IBM models (Brown et al, 1993),the statistical word alignment model can begenerally represented as in Equation (1).
?=')|,'()|,(),|(aapapapefefef  (1)In this paper, we use a simplified IBM model 4(Al-Onaizan et al, 1999), which is shown inEquation (2).
This simplified version does not takeword classes into account as described in (Brownet al, 1993).
))))(()](([))()](([()|( )|()|,Pr()|,(0,110,111112000),(00??????=>?===????+??=???????????
?==majjmajjmjajliiimjjjajjpjdahjcjdahjeftenppmap??????????
eef(2)ml,  are the lengths of the target sentence and thesource sentence respectively.j  is the position index of the source word.ja  is the position of the target word aligned tothe jth source word.i?
is the fertility of .
ie1p  is the fertility probability for e , and.0110 =+ pp)jaj|et(f  is the word translation probability.
)|( ii en ?
is the fertility probability.
)(1 jacjd ??
is the distortion probability for thehead of each cept1.
))((1 jpjd ?>  is the distortion probability for theremaining words of the cept.
}:{min)( kkaikih == is the head of cept i.
}:{max)( kjjkaakjp ==<i?
is the first word before  with non-zerofertility.
If ,; else .ie0?
}i0|}0:{| '' ' ><<> iii i?00 'i <<?
0=i?
:max{ ' 'i ii >= ?
?ij jijiac ??
?== ][  is the center of cept i.During the training process, IBM model 3 isfirst trained, and then the parameters in model 3are employed to train model 4.
During the testingprocess, the trained model 3 is also used to get aninitial alignment result, and then the trained model4 is employed to improve this alignment result.
Forconvenience, we describe model 3 in Equation (3).The main difference between model 3 and model 4lies in the calculation of distortion probability.??????===?????????????
?==majjmjajliiliiimjjmlajdeftenppmap0:11112000),(),,|()|(!
)|()|,Pr()|,(00?????????
?eef(3)1 A cept is defined as the set of target words connected to a source word(Brown et al, 1993).468However, both model 3 and model 4 do nottake the multiword cept into account.
Onlyone-to-one and many-to-one word alignments areconsidered.
Thus, some multi-word units in thedomain-specific corpus cannot be correctly aligned.In order to deal with this problem, we performword alignment in two directions (source to target,and target to source) as described in (Och and Ney,2000).
The GIZA++ toolkit2 is used to performstatistical word alignment.We use  and  to represent thebi-directional alignment sets, which are shown inEquation (4) and (5).
For alignment in both sets,we use j for source words and i for target words.
Ifa target word in position i is connected to sourcewords in positions  and , then .We call an element in the alignment set analignment link.1SG 2SG2j1j },{ 21 jjAi =}}0 ,|{|),{(1 ?=== jjii aiajAiASG  (4)}}0  ,|{|),{(2 ?=== jjjj aaiiAAjSG (5)3 Word Alignment Model AdaptationIn this paper, we first train two models using theout-of-domain training data and the in-domaintraining data, and then build a new alignmentmodel through linear interpolation of the twotrained models.
In other words, we make use of theout-of-domain training data and the in-domaintraining data by interpolating the trained alignmentmodels.
One method to perform model adaptationis to directly interpolate the alignment models asshown in Equation (6).
),|()1(),|(),|( efapefapefap OI ?
?+?= ??
(6)),|( efapI  and  are the alignmentmodel trained using the in-domain corpus and theout-of-domain corpus, respectively.
),|( efapO?
is aninterpolation weight.
It can be a constant or afunction of  and .
f eHowever, in both model 3 and model 4, thereare mainly three kinds of parameters: translationprobability, fertility probability and distortionprobability.
These three kinds of parameters havetheir own interpretation in these two models.
Inorder to obtain fine-grained interpolation models,we separate the alignment model interpolation intothree parts: translation probability interpolation,fertility probability interpolation and distortionprobability interpolation.
For these probabilities,we use different interpolation methods to calculatethe interpolation weights.
After interpolation, wereplace the corresponding parameters in equation(2) and (3) with the interpolated probabilities to getnew alignment models.2 It is located at http://www.fjoch.com/GIZA++.html.In the following subsections, we will performlinear interpolation for word alignment in thesource to target direction.
For the word alignmentin the target to source direction, we use the sameinterpolation method.3.1 Translation Probability InterpolationThe word translation probability  isvery important in translation models.
The sameword may have different distributions in thein-domain corpus and the out-of-domain corpus.Thus, the interpolation weight for the translationprobability is taken as a variant.
The interpolationmodel for  is described in Equation (7).
)|(jaj eft)|(jaj eft)|())(1()|()()|(jjjjjajOatajIatajefteefteeft??+?=??
(7)The interpolation weight  in (7) is afunction of .
It is calculated as shown inEquation (8).
)(jat e?jae??
???????
?+= )()()()(jjjjaOaIaIat epepepe  (8))(jaI ep  and  are the relativefrequencies of  in the in-domain corpus and inthe out-of-domain corpus, respectively.
)(jaO epjae?
is anadaptation coefficient, such that 0??
.Equation (8) indicates that if a word occursmore frequently in a specific domain than in thegeneral domain, it can usually be considered as adomain-specific word (Pe?as et al, 2001).
Forexample, if  is much larger than ,the word  is a domain-specific word and theinterpolation weight approaches to 1.
In this case,we trust more on the translation probabilityobtained from the in-domain corpus than thatobtained from the out-of-domain corpus.
)(jaI epja)(jaO epe4693.23.34Fertility Probability InterpolationThe fertility probability describes thedistribution of the number of words that  isaligned to.
The interpolation model is shown in (9).
)|( ii en ?ie)|()1()|()|( iiOniiInii enenen ?????
?
?+?= (9)Where,  is a constant.
This constant is obtainedusing a manually annotated held-out data set.
Infact, we can also set the interpolation weight to bea function of the word .
From the wordalignment results on the held-out set, we concludethat these two weighting schemes do not performquite differently.n?ieDistortion Probability InterpolationThe distortion probability describes the distributionof alignment positions.
We separate it into twoparts: one is the distortion probability in model 3,and the other is the distortion probability in model4.
The interpolation model for the distortionprobability in model 3 is shown in (10).
Since thedistortion probability is irrelevant with any specificsource or target words, we take  as a constant.This constant is obtained using the held-out set.d?),,|()1(),,|(),,|(mlajdmlajdmlajdjOdjIdj??+?=??
(10)For the distortion probability in model 4, weuse the same interpolation method and take theinterpolation weight as a constant.Translation Dictionary AcquisitionWe use the translation dictionary trained from thetraining data to further improve the alignmentresults.
When we train the bi-directional statisticalword alignment models with the training data, weget two word alignment results for the training data.By taking the intersection of the two wordalignment results, we build a new alignment set.The alignment links in this intersection set areextended by iteratively adding word alignmentlinks into it as described in (Och and Ney, 2000).Based on the extended alignment links, we build atranslation dictionary.
In order to filter the noisecaused by the error alignment links, we only retainthose translation pairs whose log-likelihood ratioscores (Dunning, 1993) are above a threshold.Based on the alignment results on theout-of-domain corpus, we build a translationdictionary  filtered with a threshold .
Basedon the alignment results on a small-scalein-domain corpus, we build another translationdictionary  filtered with a threshold .1D2D1?2?After obtaining the two dictionaries, wecombine two dictionaries through linearlyinterpolating the translation probabilities in the twodictionaries, which is shown in (11).
The symbols fand e represent a single word or a phrase in thesource and target languages.
This differs from thetranslation probability in Equation (7), where thesetwo symbols only represent single words.
)|())(1()|()()|( efpeefpeefp OI ?
?+?= ??
(11)The interpolation weight is also a function of e. Itis calculated as shown in (12)3.)()()()(epepepeOII+=?
(12))(epI  and  represent the relativefrequencies of e  in the in-domain corpus andout-of-domain corpus, respectively.
)(epO56 EvaluationAdaptation AlgorithmThe adaptation algorithms include two parts: atraining algorithm and a testing algorithm.
Thetraining algorithm is shown in Figure 1.After getting the two adaptation models and thetranslation dictionary, we apply them to thein-domain corpus to perform word alignment.
Herewe call it testing algorithm.
The detailed algorithmis shown in Figure 2.
For each sentence pair, thereare two different word alignment results, fromwhich the final alignment links are selectedaccording to their translation probabilities in thedictionary D. The selection order is similar to thatin the competitive linking algorithm (Melamed,1997).
The difference is that we allow many-to-oneand one-to-many alignments.We compare our method with four other methods.The first method is descried in (Wu and Wang,2004).
We call it ?Result Adaptation (ResAdapt)?.3 We also tried an adaptation coefficient to calculate theinterpolation weight as in (8).
However, the alignment resultsare not improved by using this coefficient for the dictionary.470Input: In-domain training dataOut-of-domain training data(1) Train two alignment models(source to target) and  (target tosource) using the in-domain corpus.stIMtsIM(2) Train the other two alignment modelsand  using the out-of-domaincorpus.stOMtsOM(3) Build an adaptation model stM  based onand , and build the otheradaptation modelstIMstOMtsM  based onand  using the interpolation methodsdescribed in section 3.tsIMtsOM(4) Train a dictionary  using thealignment results on the in-domaintraining data.1D(5) Train another dictionary  using thealignment results on the out-of-domaintraining data.2D(6) Build an adaptation dictionary D  basedon  and  using the interpolationmethod described in section 4.1D 2DOutput: Alignment models stM  and tsMTranslation dictionary DFigure 1.
Training AlgorithmInput: Alignment models stM  and tsM ,translation dictionary D , and testingdata(1) Apply the adaptation model stM andtsM  to the testing data to get twodifferent alignment results.
(2) Select the alignment links with highertranslation probability in the translationdictionary D .Output: Alignment results on the testing dataFigure 2.
Testing AlgorithmThe second method ?Gen+Spec?
directly combinesthe out-of-domain corpus and the in-domain corpusas training data.
The third method ?Gen?
only usesthe out-of-domain corpus as training data.
Thefourth method ?Spec?
only uses the in-domaincorpus as training data.
For each of the last threemethods, we first train bi-directional alignmentmodels using the training data.
Then we build atranslation dictionary based on the alignmentresults on the training data and filter it usinglog-likelihood ratio as described in section 4.6.16.2Training and Testing DataIn this paper, we take English-Chinese wordalignment as a case study.
We use a sentence-aligned out-of-domain English-Chinese bilingualcorpus, which includes 320,000 bilingual sentencepairs.
The average length of the English sentencesis 13.6 words while the average length of theChinese sentences is 14.2 words.We also use a sentence-aligned in-domainEnglish-Chinese bilingual corpus (operationmanuals for diagnostic ultrasound systems), whichincludes 5,862 bilingual sentence pairs.
Theaverage length of the English sentences is 12.8words while the average length of the Chinesesentences is 11.8 words.
From this domain-specificcorpus, we randomly select 416 pairs as testingdata.
We also select 400 pairs to be manuallyannotated as held-out set (development set) toadjust parameters.
The remained 5,046 pairs areused as domain-specific training data.The Chinese sentences in both the training setand the testing set are automatically segmentedinto words.
In order to exclude the effect of thesegmentation errors on our alignment results, thesegmentation errors in our testing set arepost-corrected.
The alignments in the testing setare manually annotated, which includes 3,166alignment links.
Among them, 504 alignment linksinclude multiword units.Evaluation MetricsWe use the same evaluation metrics as described in(Wu and Wang, 2004).
If we use  to representthe set of alignment links identified by theproposed methods and  to denote the referencealignment set, the methods to calculate theprecision, recall, f-measure, and alignment errorrate (AER) are shown in Equation (13), (14), (15),and (16).
It can be seen that the higher thef-measure is, the lower the alignment error rate is.Thus, we will only show precision, recall and AERscores in the evaluation results.GSCS|S||SS|GCG ?=precision(13)471|S||SS|CCG ?=recall(14)||||||2CGCGSSSSfmeasure +?
?=  (15)fmeasureSSSSAERCGCG ?=+??
?= 1||||||21 (16)6.3 Evaluation ResultsWe use the held-out set described in section 6.1 toset the interpolation weights.
The coefficient ?
inEquation (8) is set to 0.8, the interpolation weightin Equation (9) is set to 0.1, the interpolationweight  in model 3 in Equation (10) is set to0.1, and the interpolation weight  in model 4 isset to 1.
In addition, log-likelihood ratio scorethresholds are set to  and .
Withthese parameters, we get the lowest alignment errorrate on the held-out set.n?d?d?301 =?
252 =?Using these parameters, we build twoadaptation models and a translation dictionary onthe training data, which are applied to the testingset.
The evaluation results on our testing set areshown in Table 1.
From the results, it can be seenthat our approach performs the best among all ofthe methods, achieving the lowest alignment errorrate.
Compared with the method ?ResAdapt?, ourmethod achieves a higher precision without loss ofrecall, resulting in an error rate reduction of 6.56%.Compared with the method ?Gen+Spec?, ourmethod gets a higher recall, resulting in an errorrate reduction of 17.43%.
This indicates that ourmodel adaptation method is very effective toalleviate the data-sparseness problem ofdomain-specific word alignment.Method Precision Recall AEROurs 0.8490 0.7599 0.1980ResAdapt 0.8198 0.7587 0.2119Gen+Spec 0.8456 0.6905 0.2398Gen 0.8589 0.6576 0.2551Spec 0.8386 0.6731 0.2532Table 1.
Word Alignment Adaptation ResultsThe method that only uses the large-scaleout-of-domain corpus as training data does notproduce good result.
The alignment error rate isalmost the same as that of the method only usingthe in-domain corpus.
In order to further analyzethe result, we classify the alignment links into twoclasses: single word alignment links (SWA) andmultiword alignment links (MWA).
Single wordalignment links only include one-to-onealignments.
The multiword alignment links includethose links in which there are multiword units inthe source language or/and the target language.The results are shown in Table 2.
From the results,it can be seen that the method ?Spec?
producesbetter results for multiword alignment while themethod ?Gen?
produces better results for singleword alignment.
This indicates that the multiwordalignment links mainly include the domain-specificwords.
Among the 504 multiword alignment links,about 60% of the links include domain-specificwords.
In Table 2, we also present the results ofour method.
Our method achieves the lowest errorrate results on both single word alignment andmultiword alignment.Method Precision Recall AEROurs (SWA) 0.8703 0.8621 0.1338Ours (MWA) 0.5635 0.2202 0.6833Gen (SWA) 0.8816 0.7694 0.1783Gen (MWA) 0.3366 0.0675 0.8876Spec (SWA) 0.8710 0.7633 0.1864Spec (MWA) 0.4760 0.1964 0.7219Table 2.
Single Word and Multiword AlignmentResultsIn order to further compare our method with themethod described in (Wu and Wang, 2004).
We doanother experiment using almost the same-scalein-domain training corpus as described in (Wu andWang, 2004).
From the in-domain training corpus,we randomly select about 500 sentence pairs tobuild the smaller training set.
The testing data isthe same as shown in section 6.1.
The evaluationresults are shown in Table 3.Method Precision Recall AEROurs 0.8424 0.7378 0.2134ResAdapt 0.8027 0.7262 0.2375Gen+Spec 0.8041 0.6857 0.2598Table 3.
Alignment Adaptation Results Using aSmaller In-Domain CorpusCompared with the method ?Gen+Spec?, ourmethod achieves an error rate reduction of 17.86%472while the method ?ResAdapt?
described in (Wuand Wang, 2004) only achieves an error ratereduction of 8.59%.
Compared with the method?ResAdapt?, our method achieves an error ratereduction of 10.15%.This result is different from that in (Wu andWang, 2004), where their method achieved anerror rate reduction of 21.96% as compared withthe method ?Gen+Spec?.
The main reason is thatthe in-domain training corpus and testing corpus inthis paper are different from those in (Wu andWang, 2004).
The training data and the testing datadescribed in (Wu and Wang, 2004) are from asingle manual.
The data in our corpus are fromseveral manuals describing how to use thediagnostic ultrasound systems.In addition to the above evaluations, we alsoevaluate our model adaptation method using the"refined" combination in Och and Ney (2000)instead of the translation dictionary.
Using the"refined" method to select the alignments producedby our model adaptation method (AER: 0.2371)still yields better result than directly combiningout-of-domain and in-domain corpora as trainingdata of the "refined" method (AER: 0.2290).6.4 The Effect of In-Domain CorpusIn general, it is difficult to obtain large-scalein-domain bilingual corpus.
For some domains,only a very small-scale bilingual sentence pairs areavailable.
Thus, in order to analyze the effect of thesize of in-domain corpus, we randomly selectsentence pairs from the in-domain training corpusto generate five training sets.
The numbers ofsentence pairs in these five sets are 1,010, 2,020,3,030, 4,040 and 5,046.
For each training set, weuse model 4 in section 2 to train an in-domainmodel.
The out-of-domain corpus for theadaptation experiments and the testing set are thesame as described in section 6.1.# SentencePairs Precision Recall AER1010 0.8385 0.7394 0.21422020 0.8388 0.7514 0.20733030 0.8474 0.7558 0.20104040 0.8482 0.7555 0.20085046 0.8490 0.7599 0.1980Table 4.
Alignment Adaptation Results UsingIn-Domain Corpora of Different Sizes# SentencePairs Precision Recall AER1010 0.8737 0.6642 0.24532020 0.8502 0.6804 0.24423030 0.8473 0.6874 0.24104040 0.8430 0.6917 0.24015046 0.8456 0.6905 0.2398Table 5.
Alignment Results Directly CombiningOut-of-Domain and In-Domain CorporaThe results are shown in Table 4 and Table 5.Table 4 describes the alignment adaptation resultsusing in-domain corpora of different sizes.
Table 5describes the alignment results by directlycombining the out-of-domain corpus and thein-domain corpus of different sizes.
From theresults, it can be seen that the larger the size ofin-domain corpus is, the smaller the alignmenterror rate is.
However, when the number of thesentence pairs increase from 3030 to 5046, theerror rate reduction in Table 4 is very small.
This isbecause the contents in the specific domain arehighly replicated.
This also shows that increasingthe domain-specific corpus does not obtain greatimprovement on the word alignment results.Comparing the results in Table 4 and Table 5, wefind out that our adaptation method reduces thealignment error rate on all of the in-domaincorpora of different sizes.6.5 The Effect of Out-of-Domain CorpusIn order to further analyze the effect of theout-of-domain corpus on the adaptation results, werandomly select sentence pairs from theout-of-domain corpus to generate five sets.
Thenumbers of sentence pairs in these five sets are65,000, 130,000, 195,000, 260,000, and 320,000(the entire out-of-domain corpus).
In the adaptationexperiments, we use the entire in-domain corpus(5046 sentence pairs).
The adaptation results areshown in Table 6.From the results in Table 6, it can be seen thatthe larger the size of out-of-domain corpus is, thesmaller the alignment error rate is.
However, whenthe number of the sentence pairs is more than130,000, the error rate reduction is very small.
Thisindicates that we do not need a very large bilingualout-of-domain corpus to improve domain-specificword alignment results.473# SentencePairs (k) Precision Recall AER65 0.8441 0.7284 0.2180130 0.8479 0.7413 0.2090195 0.8454 0.7461 0.2073260 0.8426 0.7508 0.2059320 0.8490 0.7599 0.1980Table 6.
Adaptation Alignment Results UsingOut-of-Domain Corpora of Different Sizes7 ConclusionThis paper proposes an approach to improvedomain-specific word alignment through alignmentmodel adaptation.
Our approach first trains twoalignment models with a large-scale out-of-domaincorpus and a small-scale domain-specific corpus.Second, we build a new adaptation model bylinearly interpolating these two models.
Third, weapply the new model to the domain-specific corpusand improve the word alignment results.
Inaddition, with the training data, an interpolatedtranslation dictionary is built to select the wordalignment links from different alignment results.Experimental results indicate that our approachachieves a precision of 84.90% and a recall of75.99% for word alignment in a specific domain.Our method achieves a relative error rate reductionof 17.43% as compared with the method directlycombining the out-of-domain corpus and thein-domain corpus as training data.
It alsoachieves a relative error rate reduction of 6.56% ascompared with the previous work in (Wu andWang, 2004).
In addition, when we train the modelwith a smaller-scale in-domain corpus as describedin (Wu and Wang, 2004), our method achieves anerror rate reduction of 10.15% as compared withthe method in (Wu and Wang, 2004).We also use in-domain corpora andout-of-domain corpora of different sizes to performadaptation experiments.
The experimental resultsshow that our model adaptation method improvesalignment results on in-domain corpora of differentsizes.
The experimental results also show thateven a not very large out-of-domain corpus canhelp to improve the domain-specific wordalignment through alignment model adaptation.ReferencesL.
Ahrenberg, M. Merkel, M. Andersson.
1998.
ASimple Hybrid Aligner for Generating LexicalCorrespondences in Parallel Tests.
In Proc.
ofACL/COLING-1998, pp.
29-35.Y.
Al-Onaizan, J. Curin, M. Jahr, K. Knight, J. Lafferty,D.
Melamed, F. J. Och, D. Purdy, N. A. Smith, D.Yarowsky.
1999.
Statistical Machine TranslationFinal Report.
Johns Hopkins University Workshop.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, R.Mercer.
1993.
The Mathematics of StatisticalMachine Translation: Parameter Estimation.Computational Linguistics, 19(2): 263-311.C.
Cherry and D. Lin.
2003.
A Probability Model toImprove Word Alignment.
In Proc.
of ACL-2003, pp.88-95.T.
Dunning.
1993.
Accurate Methods for the Statistics ofSurprise and Coincidence.
Computational Linguistics,19(1): 61-74.R.
Iyer,  M. Ostendorf,  H. Gish.
1997.
UsingOut-of-Domain Data to Improve In-DomainLanguage Models.
IEEE Signal Processing Letters,221-223.S.
J. Ker and J. S. Chang.
1997.
A Class-basedApproach to Word Alignment.
ComputationalLinguistics, 23(2): 313-343.I.
D. Melamed.
1997.
A Word-to-Word Model ofTranslational Equivalence.
In Proc.
of ACL 1997, pp.490-497.F.
J. Och and H. Ney.
2000.
Improved StatisticalAlignment Models.
In Proc.
of ACL-2000, pp.440-447.A.
Pe?as, F. Verdejo, J. Gonzalo.
2001.
Corpus-basedTerminology Extraction Applied to InformationAccess.
In Proc.
of the Corpus Linguistics 2001, vol.13.F.
Smadja, K. R. McKeown, V. Hatzivassiloglou.
1996.Translating Collocations for Bilingual Lexicons: aStatistical Approach.
Computational Linguistics,22(1): 1-38.D.
Tufis and A. M. Barbu.
2002.
Lexical TokenAlignment: Experiments, Results and Application.
InProc.
of LREC-2002, pp.
458-465.D.
Wu.
1997.
Stochastic Inversion TransductionGrammars and Bilingual Parsing of ParallelCorpora.
Computational Linguistics, 23(3): 377-403.H.
Wu and H. Wang.
2004.
Improving Domain-SpecificWord Alignment with a General Bilingual Corpus.
InR.
E. Frederking and K. B. Taylor (Eds.
), MachineTranslation: From Real Users to Research: 6thconference of AMTA-2004, pp.
262-271.474
