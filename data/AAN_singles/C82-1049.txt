COLING 82, J. Horeck~ (ed.
)North-Holland Publishing Company?
Academia, 1982A MESSAGE-PASSING CONTROL STRUCTURE FOR TEXT UNDERSTANDINGBrian Phillips and James A. HendlerTexas Instruments Inc.Dallas, Texas, USAThis paper describes an object-oriented, message-passingsystem for natural language text understanding.
Theapplication domain is the texts of Texas Instruments'patent descriptions.
The object-oriented environmentpermits syntactic analysis modules to communicate withdomain knowledge modules to resolve ambiguities as theyarise.1.0 INTRODUCTIONAs syntactic and conceptual coverage increase to meet the requirements ofpractical language understanding systems the computational effort to search thelarger knowledge spaces tends to grow exponentially in current systems.Clearly , this search problem is one of (many) problems that have to be resolved.One solution is to eliminate many of the alternatives as they are encountered.We are investigating a control structure that allows syntactic and semanticknowledge sources mutual access to allow early selection of appropriatealternatives.We wish to include in our system the multiple facets of linguistic structure andto maintain their descriptive autonomy, accordingly other suggestions that havebeen made to constrai~ searching (e.g., Hendrix (1977), Schank (1975)) do notsatisfy this design criterion.
We also want the system to simultaneously builda conceptual representation of the text and to be able to feed semanticpredictions to syntax.
In the Rus system (Bobrow (1978)) the semantic omponentcritiques the constructs of syntax but does not generate predictions.2.0 OBJECTS AND MESSAGE-PASSINGWe have adopted a pseudo-parallel, object-oriented approach to writing oursystem (Hewitt (1976)).
Objects encapsulate data and their operations.
Actionson data can only be performed by sending messages to appropriate objects.
Arequest for action may require that the object enlist the aid of other objects,which i t  does by further message-passing.
Any object can communicate with anyother object (though objects can receive messages they cannot process).Further, an object need not get a reply to a message.
Objects have memory andcan retain their state between activations.
This flow of control among objectsis more general than stack-oriented activation of subprograms.307 /I308 B. PHILLIPS af, d J.A.
HENDLERI n te r l i sp ,  Simula, Smalltalk, and Lisp Machine Lisp (Weinreb & Moon (1981)) havefeatures that encompass the object not ior .
Our system is being implementedusing the " f lavor"  system in Lisp Machine Lisp.3.0 THE APPLICATIONWe are using working abstracts of descriptions of Texas Instruments' issuedpatents.
These are written in a restr icted style by by the attorneys and thetopics are l imited to so l id -state  micro-electronic devices.
Thus we are able touse natura l ly  occurring data without immediately confronting the problems ofincomplete syntactic and conceptual coverage that would be encountered in manyother domains.
An example is:A modulator comprising two transistors each having co l lector ,  emitterand base electrodes, means for applying a direct  voltage across saidemitter electrodes, a center-tapped source of a l ternat ing signalsconnected between said base electrodes, said co l lector  electrodesbeing connected together and to the center tap of said source.
A loadimpedance connected between said co l lector  electrodes and said emitterelectrode of one of said t rans istors ,  and a var iable res istorconnected between the base electrode and the emitter electrode of saidone transistor .The interact ion of embedding and conjunction gives a high degree of syntacticambiguity to the texts.
The texts can also be ungrammatical, whence the desireto be building the conceptual representation in para l le l  with the syntacticanalysis in order that some meaning w i l l  be extracted from the text  even whenthe syntactic analysis is not completed.The goal of the project is to bui ld a conceptual representation for the text ,then add re t r ieva l  capabi l i t ies  that w i l l  be more f lex ib le  than a word-matchingscheme.4.0 THE SYSTEMThe objects of our system correspond to the organizing pr inciples of thecomponents.
In syntax we have constituency objects that can take grammar ulesand t ry  to match them against input.
In semantics we have taxonomy objects,case-frame objects, causal-chain objects, meta objects (that handle a form oflambda-abstraction), etc.Small & Rieger (1981) also have an object viewpoint of language analysis.However, in the i r  scheme each word is an object, motivated by the i r  view that"human knowledge about language is organized pr imar i ly  as knowledge about wordsrather than as knowledge about rules" (p .
l ) .
Our system is organized aroundrules.Objects in d i f ferent  components do not necessarily have the same vocabulary: insyntax there are words and phrase structure and semantics has concepts andre lat ions ;  accordingly there is a t rans lat ion object through which messagespass.A CONTROL STRUCTURE FOR TEXT UNDERSTANDING 309Kornfeld (1979) has given an example of a (pseudo-)parallel communication systemthat passes information between objects to reduce the respective search spaces;he terms the phenomenon .
"combinatorial I__MMplosion".
The interaction betweensyntax and semantics allows the the conceptual representation of sentencefragments to be built in parallel with the syntactic analysis.
Semanticpredictions arm fed back to syntax to try to achieve the combinatorialimplosion.4.1 The SyntaxThe formalism we are using is "local grammar" (Saenz (1980), Ross (1981)) whichconsists of a context-free phrase structure grammar with augmentations.
Theaugmentations are blocking and percolation rules.
For example, the auxiliaryrule in our system isverb-group = > aux verb-group structure ruleaspect (1) = affix (2) blocking ruleaffix (0) = affix (1) percolation ruleFigure I: The auxiliary ruleThe structure segments are numbered left  to right, starting at 0 for theleft-hand-side of the rule.
The values of the features "aspect" and "affix" areestablished in the dictionary for terminal items and percolated up the analysistree for higher level phrases.The parsing algorithm is a modified left-corner routine (Griffiths & Petrick(1965)).
The modifications are to use the object environment to produce allparses in parallel and to merge common subparses.#CONSTITUENT 22731061#, an object of flavor CONSTITUENT,has instance variable values:CATEGORY: VERB-GROUPGOALS-LIST: ((VERB-GROUP .
#CONSTITUENT 22731051#))PART-PARSE: ((1.
BEING ((AUX (AFFIX PROGRESSIVE)(ASPECT PASSIVE)))))RULE-TAIL: ((VERB-GROUP))AUGMENTATIONS: ((EQUAL (ASPECT 1.)
(AFFIX 2.
))(PERCOLATE AFFIX (AFFIX 1.
)))SEGMENT-COUNTER: 2.INPUT-WORD: BEINGFigure 2: A syntactic constituent objectFigure 2 gives an example of the state variables of a constituent object that isusing the auxiliary rule.of Figure 1.
"Category" is the left-hand-side of thestructure rule, "part-parse" is the fragment of the right-hand-side so far .matched, and "rule-tai l" is the remaining part of the structure rule.
"Augmentations" are the percolation and blocking rules.
The "goals-list" givesother constituent objects that are awaiting completion of this constituent(there may be several because of merged paths).
The word "being" has just beenprocessed as the f i rs t  segment of the part-parse and the segment counter nowI310 B. PHILLIPS and J.A.
HENDLERpoints to the second position.
The object has processes for (a) advancing theanalysis with a new input word, (b) for advaacing the analysis when a subparsehas been completed (the parse can only be immediately advanced when the nextelement of the rule-tai l  is a terminal symbol; otherwise i t  has to createanother object to process a rule expanding the non-terminal category), and (c)for merging with another path.4.2 The Knowledge BaseGeneral knowledge of the domain is represented in a semantic network (Phillips(1978)).
The conceptual analyses wil l  be instantiations of general knowledgewith novelty introduced from the texts.Semantic nets are usually seen as data (e.g., Qill ian (1968), Brachman (1978))with various routines for performing operations such as taxonomy searches,finding paths from node to node, and binding variables in the network.
Eachnode of our network is an object having associated processes dependent on thetypes of links i t  has to other nodes.MODUL2TORMODULATIONMETA > \[3 CONNECTORS/ ~  / ~ COMPONENTS " / ..POWER I ~ TRANSISTOR7\ .AC SOURCE DC SOURCEFigure 3: A fragment of a semantic netThus in Figure 3, which shows part of our semantic network, links indicate theother nodes to which a node can send a message, as opposed to a physicalpointer.
A node is actually implemented as a "mix" of objects for the kinds oflinks i t  has;  thus as new links are added so are new processes.
A node neednot know anything about the internal format of data in other nodes to getA CONTROL STRUCTURE FOR TEXT UNDERSTANDING 311information from them.
Further, when a message is sent to a node, the senderneed not know whether this is a "simple" or "complex" message: a simple messagecan be answered by the qode i t se l f ,  a complex message requires the node to sendmessages to other nodes.
Thus a "part-whole" message to establish whether adirect-voltage source can be part of a modulator or part of a transistor,  wi l lalso use intervening taxonomy, decomposition (meta) links (Figure 3) withoutthis being specified in the original query.
A node receiving this message would "pass a similar message to its neighbouring nodes i f  i t  cannot i t se l f  respond.4.3 Flow Of ControlProcessing of text is in i t ia ted from a task specific knowledge object, in thiscase a "patent knowledge expert" that has an expectation of f inding a patent.I t  passes a message to the translator that sees i f  i t  has any data that wi l lmatch this expectation.
Since no part of the text has been examined by syntax,nothing can be found.
A start message is sent to syntax.The translator object should pass predictions to syntax but this does not, ingeneral, seem possible as the real izations of a concept include all  possibledescriptive references.
Thus the translator maintains its l i s t  of predictionsand, when syntactic constituents are received, matches their  translationsagainst the predictions.
A match causes a message to be sent to the source ofthe prediction, which can extend the conceptual representation and producefurther predictions.When no matches are found, the translator seeks a knowledge structure thatcorresponds to the syntactic structure.
This occurs, for example, when thesyntactic objects are confronted with the attachment of the "means for applying.
.
. "
phrase in the example given above: is the correct analysis "modulatorcomprising .
.
.
means .
.
. "
or "transistors each having .
.
.
means .
.
.
"?
A paththrough the network of Figure 3 shows that a modulator can have a direct voltagesource but no such path exists for transistors.
The appropriate instantiationof the network is created and the unacceptable syntactic path is eliminated fromfurther consideration.Processing is complete when the text has been consumed and all  the concepts fromthe text are connected to the topic of patent, though ungrammaticality may causean ear l ier  end.5.0 CONCLUSIONOur understanding of language and cognitive processes is growing and novelprogramming languages are developing.
With this knowledge and these tools, weare getting closer to viable natural language systems in l imited domains.There are other developments that wi l l  contribute to building natural languagesystems, namely the decreasing cost and increasing power of hardware.
Alsoadvances in computer-aided esign give promise of cost-effective special purposemachines with hardware routines for processes now implemented in software(Fahlman (1979)).
More power wi l l  certainly aid in constructing languageunderstanding systems.
But the power wi l l  be wasted i f  i t  is used to attack aproblem that can be resolved by some other approach, say by constructing anobject-oriented system as presented above.312 B. PHILLIPS and J.A.
HENDLER6.0 REFERENCES\[1\] Bobrow, R.J., The RUS System, Report 3878, Bolt Beranek & Newman Inc.,Cambridge, MA.
(July 1978).\[2\] Brachman, R.J, A structRral paradigm for representing knowledge, Report3605, Bolt, Beranek, & Newman Inc., Cambridge, MA.
(May 1978).\[3\] Fahlman, S.E., NETL: A System for Representing and Using Real WorldKnowledge (MIT Press, Cambridge, MA, 1979).\[4\] Griffiths, T.V., & Petrick, S.R, On the relative efficiencies ofcontext-free grammar recognizers, Comm.
ACM 5 (1965) 289-300.\[5\] Hendrix, G.G., Human engineering for applied natural language processing,in Proceedings of the 5th International Joint Conference on Art i f ic ialIntelligence (Cambridge, 1977).\[6\] Hewitt, C., Viewing control structures as patterns of passing messages, AIMemo 410, MIT AI Laboratory, Cambridge, MA.
(December 1976).\[ 7\] Kornfeld, W.A., Using parallel processing for problem solving, AI Memo 561,MIT AI Laboratory, Cambridge, MA.
(December 1979).\[8\] Phillips, B., A model for knowledge and its application discourse analysis.American Journal of Computational Linguistics, Microfiche 82 (1978).\[9\] Quillian, M.R., Semantic memory, in Minsky, M.
(ed.
), Semantic InformationProcessing (MIT Press, Cambridge, HA, 1968).\[10\] Ross, K.M., Parsing English Phrase Structures, Ph.D. Thesis, Dept.
ofLinguistics, University of Massachusetts (September 1981).\[11\] Saenz, R.M., Local Grammar, Unpublished paper, Dept.
of Linguistics,University of Massachusetts (February 1980).\[12\] Schank, R.C., Conceptual Information Processing (American Elsevier, NewYork, 1975).\[13\] Small, S.L., & Rieger, C., Parsing and Comprehending with Word Experts,Technical Report I039, Art i f ic ial  Intelligence Group, University ofMaryland (April 1981).\[ 14\] Weinreb, D., & Moon, D., Lisp Machine Manual (MIT AI Laboratory, Cambridge,MA, 1981).
