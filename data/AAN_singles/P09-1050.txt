Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 441?449,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPAutomatic Set Instance Extraction using the WebRichard C. WangLanguage Technologies InstituteCarnegie Mellon Universityrcwang@cs.cmu.eduWilliam W. CohenMachine Learning DepartmentCarnegie Mellon Universitywcohen@cs.cmu.eduAbstractAn important and well-studied problem isthe production of semantic lexicons froma large corpus.
In this paper, we presenta system named ASIA (Automatic Set In-stance Acquirer), which takes in the nameof a semantic class as input (e.g., ?carmakers?)
and automatically outputs its in-stances (e.g., ?ford?, ?nissan?, ?toyota?
).ASIA is based on recent advances in web-based set expansion - the problem of find-ing all instances of a set given a smallnumber of ?seed?
instances.
This ap-proach effectively exploits web resourcesand can be easily adapted to differentlanguages.
In brief, we use language-dependent hyponym patterns to find anoisy set of initial seeds, and then use astate-of-the-art language-independent setexpansion system to expand these seeds.The proposed approach matches or outper-forms prior systems on several English-language benchmarks.
It also shows ex-cellent performance on three dozen addi-tional benchmark problems from English,Chinese and Japanese, thus demonstratinglanguage-independence.1 IntroductionAn important and well-studied problem is the pro-duction of semantic lexicons for classes of in-terest; that is, the generation of all instances ofa set (e.g., ?apple?, ?orange?, ?banana?)
givena name of that set (e.g., ?fruits?).
This task isoften addressed by linguistically analyzing verylarge collections of text (Hearst, 1992; Kozarevaet al, 2008; Etzioni et al, 2005; Pantel andRavichandran, 2004; Pasca, 2004), often usinghand-constructed or machine-learned shallow lin-guistic patterns to detect hyponym instances.
A hy-ponym is a word or phrase whose semantic rangeFigure 1: Examples of SEAL?s input and output.English entities are reality TV shows, Chinese en-tities are popular Taiwanese foods, and Japaneseentities are famous cartoon characters.is included within that of another word.
For exam-ple, x is a hyponym of y if x is a (kind of) y. Theopposite of hyponym is hypernym.In this paper, we evaluate a novel approach tothis problem, embodied in a system called ASIA1(Automatic Set Instance Acquirer).
ASIA takes asemantic class name as input (e.g., ?car makers?
)and automatically outputs instances (e.g., ?ford?,?nissan?, ?toyota?).
Unlike prior methods, ASIAmakes heavy use of tools for web-based set ex-pansion.
Set expansion is the task of finding allinstances of a set given a small number of exam-ple (seed) instances.
ASIA uses SEAL (Wang andCohen, 2007), a language-independent web-basedsystem that performed extremely well on a largenumber of benchmark sets ?
given three correctseeds, SEAL obtained average MAP scores in thehigh 90?s for 36 benchmark problems, including adozen test problems each for English, Chinese andJapanese.
SEAL works well in part because it canefficiently find and process many semi-structuredweb documents containing instances of the set be-ing expanded.
Figure 1 shows some examples ofSEAL?s input and output.SEAL has been recently extended to be robustto errors in its initial set of seeds (Wang et al,1http://rcwang.com/asia4412008), and to use bootstrapping to iteratively im-prove its performance (Wang and Cohen, 2008).These extensions allow ASIA to extract instancesof sets from the Web, as follows.
First, given asemantic class name (e.g., ?fruits?
), ASIA uses asmall set of language-dependent hyponym patterns(e.g., ?fruits such as ?)
to find a large but noisyset of seed instances.
Second, ASIA uses the ex-tended version of SEAL to expand the noisy set ofseeds.ASIA?s approach is motivated by the conjecturethat for many natural classes, the amount of infor-mation available in semi-structured documents onthe Web is much larger than the amount of infor-mation available in free-text documents; hence, itis natural to attempt to augment search for set in-stances in free-text with semi-structured documentanalysis.
We show that ASIA performs extremelywell experimentally.
On the 36 benchmarks usedin (Wang and Cohen, 2007), which are relativelysmall closed sets (e.g., countries, constellations,NBA teams), ASIA has excellent performancefor both recall and precision.
On four additionalEnglish-language benchmark problems (US states,countries, singers, and common fish), we com-pare to recent work by Kozareva, Riloff, and Hovy(Kozareva et al, 2008), and show comparable orbetter performance on each of these benchmarks;this is notable because ASIA requires less infor-mation than the work of Kozareva et al(their sys-tem requires a concept name and a seed).
We alsocompare ASIA on twelve additional benchmarksto the extended Wordnet 2.1 produced by Snowet al(Snow et al, 2006), and show that for thesetwelve sets, ASIA produces more than five timesas many set instances with much higher precision(98% versus 70%).Another advantage of ASIA?s approach is that itis nearly language-independent: since the underly-ing set-expansion tools are language-independent,all that is needed to support a new target languageis a new set of hyponym patterns for that lan-guage.
In this paper, we present experimental re-sults for Chinese and Japanese, as well as English,to demonstrate this language-independence.We present related work in Section 2, and ex-plain our proposed approach for ASIA in Sec-tion 3.
Section 4 presents the details of our ex-periments, as well as the experimental results.
Acomparison of results are illustrated in Section 5,and the paper concludes in Section 6.2 Related WorkThere has been a significant amount of researchdone in the area of semantic class learning (akalexical acquisition, lexicon induction, hyponymextraction, or open-domain information extrac-tion).
However, to the best of our knowledge, thereis not a system that can perform set instance ex-traction in multiple languages given only the nameof the set.Hearst (Hearst, 1992) presented an approachthat utilizes hyponym patterns for extracting can-didate instances given the name of a semantic set.The approach presented in Section 3.1 is based onthis work, except that we extended it to two otherlanguages: Chinese and Japanese.Pantel et al(Pantel and Ravichandran, 2004)presented an algorithm for automatically inducingnames for semantic classes and for finding theirinstances by using ?concept signatures?
(statisticson co-occuring instances).
Pasca (Pasca, 2004)presented a method for acquiring named entities inarbitrary categories using lexico-syntactic extrac-tion patterns.
Etzioni et al(Etzioni et al, 2005)presented the KnowItAll system that also utilizeshyponym patterns to extract class instances fromthe Web.
All the systems mentioned rely on eithera English part-of-speech tagger, a parser, or both,and hence are language-dependent.Kozareva et al(Kozareva et al, 2008) illustratedan approach that uses a single hyponym patterncombined with graph structures to learn semanticclass from the Web.
Section 5.1 shows that ourapproach is competitive experimentally; however,their system requires more information, as it usesthe name of the semantic set and a seed instance.Pasca (Pas?ca, 2007b; Pas?ca, 2007a) illustrateda set expansion approach that extracts instancesfrom Web search queries given a set of input seedinstances.
This approach is similar in flavor toSEAL but, addresses a different task from that ad-dressed here: for ASIA the user provides no seeds,but instead provides the name of the set being ex-panded.
We compare to Pasca?s system in Sec-tion 5.2.Snow et al(Snow et al, 2006) use known hyper-nym/hyponym pairs to generate training data for amachine-learning system, which then learns manylexico-syntactic patterns.
The patterns learned arebased on English-language dependency parsing.We compare to Snow et als results in Section 5.3.4423 Proposed ApproachASIA is composed of three main components: theNoisy Instance Provider, the Noisy Instance Ex-pander, and the Bootstrapper.
Given a semanticclass name, the Provider extracts a initial set ofnoisy candidate instances using hand-coded pat-terns, and ranks the instances by using a sim-ple ranking model.
The Expander expands andranks the instances using evidence from semi-structured web documents, such that irrelevantones are ranked lower in the list.
The Bootstrap-per enhances the quality and completeness of theranked list by using an unsupervised iterative tech-nique.
Note that the Expander and Bootstrap-per rely on SEAL to accomplish their goals.
Inthis section, we first describe the Noisy InstanceProvider, then we briefly introduce SEAL, fol-lowed by the Noisy Instance Expander, and finally,the Bootstrapper.3.1 Noisy Instance ProviderNoisy Instance Provider extracts candidate in-stances from free text (i.e., web snippets) us-ing the methods presented in Hearst?s early work(Hearst, 1992).
Hearst exploited several patternsfor identifying hyponymy relation (e.g., such au-thor as Shakespeare) that many current state-of-the-art systems (Kozareva et al, 2008; Pantel andRavichandran, 2004; Etzioni et al, 2005; Pasca,2004) are using.
However, unlike all of those sys-tems, ASIA does not use any NLP tool (e.g., parts-of-speech tagger, parser) or rely on capitalizationfor extracting candidates (since we wanted ASIAto be as language-independent as possible).
Thisleads to sets of instances that are noisy; however,we will show that set expansion and re-ranking canimprove the initial sets dramatically.
Below, wewill refer to the initial set of noisy instances ex-tracted by the Provider as the initial set.In more detail, the Provider first constructs afew queries of hyponym phrase by using a se-mantic class name and a set of pre-defined hy-ponym patterns.
For every query, the Provider re-trieves a hundred snippets from Yahoo!, and splitseach snippet into multiple excerpts (a snippet of-ten contains multiple continuous excerpts from itsweb page).
For each excerpt, the Provider extractsall chunks of characters that would then be usedas candidate instances.
Here, we define a chunkas a sequence of characters bounded by punctua-tion marks or the beginning and end of an excerpt.Figure 2: Hyponym patterns in English, Chinese,and Japanese.
In each pattern, <C> is a place-holder for the semantic class name and <I> is aplaceholder for its instances.Lastly, the Provider ranks each candidate instancex based on its weight assigned by the simple rank-ing model presented below:weight(x) =sf (x,S)|S|?ef (x,E)|E|?wcf (x,E)|C|where S is the set of snippets, E is the set of ex-cerpts, and C is the set of chunks.
sf (x,S) isthe snippet frequency of x (i.e., the number ofsnippets containing x) and ef (x,E) is the excerptfrequency of x.
Furthermore, wcf (x,E) is theweighted chunk frequency of x, which is definedas follows:wcf (x,E) =?e?E?x?e1dist(x, e) + 1where dist(x, e) is the number of characters be-tween x and the hyponym phrase in excerpt e.This model weights every occurrence of x basedon the assumption that chunks closer to a hyponymphrase are usually more important than those fur-ther away.
It also heavily rewards frequency, asour assumption is that the most common instanceswill be more useful as seeds for SEAL.Figure 2 shows the hyponym patterns we usefor English, Chinese, and Japanese.
There are twotypes of hyponym patterns: The first type are theones that require the class name C to precede itsinstance I (e.g., C such as I), and the second typeare the opposite ones (e.g., I and other C).
Inorder to reduce irrelevant chunks, when excerptswere extracted, the Provider drops all characterspreceding the hyponym phrase in excerpts thatcontain the first type, and also drops all charac-ters following the hyponym phrase in excerpts thatcontain the second type.
For some semantic classnames (e.g., ?cmu buildings?
), there are no web443documents containing any of the hyponym-phrasequeries that were constructed using the name.
Inthis case, the Provider turns to a back-off strategywhich simply treats the semantic class name as thehyponym phrase and extracts/ranks all chunks co-occurring with the class name in the excerpts.3.2 Set Expander - SEALIn this paper, we rely on a set expansion systemnamed SEAL (Wang and Cohen, 2007), whichstands for Set Expander for Any Language.
Thesystem accepts as input a few seeds of some targetset S (e.g., ?fruits?)
and automatically finds otherprobable instances (e.g., ?apple?, ?banana?)
of Sin web documents.
As its name implies, SEALis independent of document languages: both thewritten (e.g., English) and the markup language(e.g., HTML).
SEAL is a research system thathas shown good performance in published results(Wang and Cohen, 2007; Wang et al, 2008; Wangand Cohen, 2008).
Figure 1 shows some examplesof SEAL?s input and output.In more detail, SEAL contains three major com-ponents: the Fetcher, Extractor, and Ranker.
TheFetcher is responsible for fetching web docu-ments, and the URLs of the documents come fromtop results retrieved from the search engine us-ing the concatenation of all seeds as the query.This ensures that every fetched web page containsall seeds.
The Extractor automatically constructs?wrappers?
(i.e.
page-specific extraction rules) foreach page that contains the seeds.
Every wrap-per comprises two character strings that specifythe left and right contexts necessary for extract-ing candidate instances.
These contextual stringsare maximally-long contexts that bracket at leastone occurrence of every seed string on a page.
Allother candidate instances bracketed by these con-textual strings derived from a particular page areextracted from the same page.After the candidates are extracted, the Rankerconstructs a graph that models all the relationsbetween documents, wrappers, and candidate in-stances.
Figure 3 shows an example graph whereeach node di represents a document, wi a wrapper,and mi a candidate instance.
The Ranker performsRandom Walk with Restart (Tong et al, 2006) onthis graph (where the initial ?restart?
set is theset of seeds) until all node weights converge, andthen ranks nodes by their final score; thus nodesare weighted higher if they are connected to manyFigure 3: An example graph constructed bySEAL.
Every edge from node x to y actually hasan inverse relation edge from node y to x that isnot shown here (e.g., m1 is extracted by w1).seed nodes by many short, low fan-out paths.
Thefinal expanded set contains all candidate instancenodes, ranked by their weights in the graph.3.3 Noisy Instance ExpanderWang (Wang et al, 2008) illustrated that it is feasi-ble to perform set expansion on noisy input seeds.The paper showed that the noisy output of anyQuestion Answering system for list questions canbe improved by using a noise-resistant version ofSEAL (An example of a list question is ?Whowere the husbands of Heddy Lamar??).
Since theinitial set of candidate instances obtained usingHearst?s method are noisy, the Expander expandsthem by performing multiple iterations of set ex-pansion using the noise-resistant SEAL.For every iteration, the Expander performs setexpansion on a static collection of web pages.
Thiscollection is pre-fetched by querying Google andYahoo!
using the input class name and words suchas ?list?, ?names?, ?famous?, and ?common?
fordiscovering web pages that might contain lists ofthe input class.
In the first iteration, the Expanderexpands instances with scores of at least k in theinitial set.
In every upcoming iteration, it expandsinstances obtained in the last iteration that havescores of at least k and that also exist in the ini-tial set.
We have determined k to be 0.4 based onour development set2.
This process repeats untilthe set of seeds for ith iteration is identical to thatof (i?
1)th iteration.There are several differences between the origi-nal SEAL and the noise-resistant SEAL.
The mostimportant difference is the Extractor.
In the origi-2A collection of closed-set lists such as planets, Nobelprizes, and continents in English, Chinese and Japanese444nal SEAL, the Extractor requires the longest com-mon contexts to bracket at least one instance of ev-ery seed per web page.
However, when seeds arenoisy, such common contexts usually do not ex-ist.
The Extractor in noise-resistant SEAL solvesthis problem by requiring the contexts to bracketat least one instance of a minimum of two seeds,rather than every seed.
This is implemented usinga trie-based method described briefly in the origi-nal SEAL paper (Wang and Cohen, 2007).
In thispaper, the Expander utilizes a slightly-modifiedversion of the Extractor, which requires the con-texts to bracket as many seed instances as possible.This idea is based on the assumption that irrelevantinstances usually do not have common contexts;whereas relevant ones do.3.4 BootstrapperBootstrapping (Etzioni et al, 2005; Kozareva,2006; Nadeau et al, 2006) is an unsupervised iter-ative process in which a system continuously con-sumes its own outputs to improve its own perfor-mance.
Wang (Wang and Cohen, 2008) showedthat it is feasible to bootstrap the results of set ex-pansion to improve the quality of a list.
The pa-per introduces an iterative version of SEAL callediSEAL, which expands a list in multiple iterations.In each iteration, iSEAL expands a few candi-dates extracted in previous iterations and aggre-gates statistics.
The Bootstrapper utilizes iSEALto further improve the quality of the list returnedby the Expander.In every iteration, the Bootstrapper retrieves 25web pages by using the concatenation of threeseeds as query to each of Google and Yahoo!.In the first iteration, the Bootstrapper expandsrandomly-selected instances returned by the Ex-pander that exist in the initial set.
In every upcom-ing iteration, the Bootstrapper expands randomly-selected unsupervised instances obtained in thelast iteration that also exist in the initial set.
Thisprocess terminates when all possible seed com-binations have been consumed or five iterations3have been reached, whichever comes first.
No-tice that from iteration to iteration, statistics areaggregated by growing the graph described in Sec-tion 3.2.
We perform Random Walk with Restart(Tong et al, 2006) on this graph to determine thefinal ranking of the extracted instances.3To keep the overall runtime minimal.4 Experiments4.1 DatasetsWe evaluated our approach using the evaluationset presented in (Wang and Cohen, 2007), whichcontains 36 manually constructed lists acrossthree different languages: English, Chinese, andJapanese (12 lists per language).
Each list containsall instances of a particular semantic class in a cer-tain language, and each instance contains a set ofsynonyms (e.g., USA, America).
There are a totalof 2515 instances, with an average of 70 instancesper semantic class.
Figure 4 shows the datasetsand their corresponding semantic class names thatwe use in our experiments.4.2 Evaluation MetricSince the output of ASIA is a ranked list of ex-tracted instances, we choose mean average pre-cision (MAP) as our evaluation metric.
MAP iscommonly used in the field of Information Re-trieval for evaluating ranked lists because it is sen-sitive to the entire ranking and it contains both re-call and precision-oriented aspects.
The MAP formultiple ranked lists is simply the mean value ofaverage precisions calculated separately for eachranked list.
We define the average precision of asingle ranked list as:AvgPrec(L) =|L|?r=1Prec(r)?
isFresh(r)Total # of Correct Instanceswhere L is a ranked list of extracted instances, ris the rank ranging from 1 to |L|, Prec(r) is theprecision at rank r. isFresh(r) is a binary functionfor ensuring that, if a list contains multiple syn-onyms of the same instance, we do not evaluatethat instance more than once.
More specifically,the function returns 1 if a) the synonym at r is cor-rect, and b) it is the highest-ranked synonym of itsinstance in the list; it returns 0 otherwise.4.3 Experimental ResultsFor each semantic class in our dataset, theProvider first produces a noisy list of candidate in-stances, using its corresponding class name shownin Figure 4.
This list is then expanded by the Ex-pander and further improved by the Bootstrapper.We present our experimental results in Table 1.As illustrated, although the Provider performsbadly, the Expander substantially improves the445Figure 4: The 36 datasets and their semantic class names used as inputs to ASIA in our experiments.English Dataset NP Chinese Dataset NP Japanese Dataset NPNP NP +NE NP NP +NE NP NP +NE# NP +BS +NE +BS # NP +BS +NE +BS # NP +BS +NE +BS1.
0.22 0.83 0.82 0.87 13.
0.09 0.75 0.80 0.80 25.
0.20 0.63 0.71 0.762.
0.31 1.00 1.00 1.00 14.
0.08 0.99 0.80 0.89 26.
0.20 0.40 0.90 0.963.
0.54 0.99 0.99 0.98 15.
0.29 0.66 0.84 0.91 27.
0.16 0.96 0.97 0.964.
0.48 1.00 1.00 1.00 *16.
0.09 0.00 0.93 0.93 *28.
0.01 0.00 0.80 0.875.
0.54 1.00 1.00 1.00 17.
0.21 0.00 1.00 1.00 29.
0.09 0.00 0.95 0.956.
0.64 0.98 1.00 1.00 *18.
0.00 0.00 0.19 0.23 *30.
0.02 0.00 0.73 0.737.
0.32 0.82 0.98 0.97 19.
0.11 0.90 0.68 0.89 31.
0.20 0.49 0.83 0.898.
0.41 1.00 1.00 1.00 20.
0.18 0.00 0.94 0.97 32.
0.09 0.00 0.88 0.889.
0.81 1.00 1.00 1.00 21.
0.64 1.00 1.00 1.00 33.
0.07 0.00 0.95 1.00*10.
0.00 0.00 0.00 0.00 22.
0.08 0.00 0.67 0.80 34.
0.04 0.32 0.98 0.9711.
0.11 0.62 0.51 0.76 23.
0.47 1.00 1.00 1.00 35.
0.15 1.00 1.00 1.0012.
0.01 0.00 0.30 0.30 24.
0.60 1.00 1.00 1.00 36.
0.20 0.90 1.00 1.00Avg.
0.37 0.77 0.80 0.82 Avg.
0.24 0.52 0.82 0.87 Avg.
0.12 0.39 0.89 0.91Table 1: Performance of set instance extraction for each dataset measured in MAP.
NP is the NoisyInstance Provider, NE is the Noisy Instance Expander, and BS is the Bootstrapper.quality of the initial list, and the Bootstrapper thenenhances it further more.
On average, the Ex-pander improves the performance of the Providerfrom 37% to 80% for English, 24% to 82% forChinese, and 12% to 89% for Japanese.
The Boot-strapper then further improves the performance ofthe Expander to 82%, 87% and 91% respectively.In addition, the results illustrate that the Bootstrap-per is also effective even without the Expander; itdirectly improves the performance of the Providerfrom 37% to 77% for English, 24% to 52% forChinese, and 12% to 39% for Japanese.The simple back-off strategy seems to be effec-tive as well.
There are five datasets (marked with *in Table 1) of which their hyponym phrases returnzero web documents.
For those datasets, ASIA au-tomatically uses the back-off strategy described inSection 3.1.
Considering only those five datasets,the Expander, on average, improves the perfor-mance of the Provider from 2% to 53% and theBootstrapper then improves it to 55%.5 Comparison to Prior WorkWe compare ASIA?s performance to the resultsof three previously published work.
We use thebest-configured ASIA (NP+NE+BS) for all com-parisons, and we present the comparison results inthis section.5.1 (Kozareva et al, 2008)Table 2 shows a comparison of our extraction per-formance to that of Kozareva (Kozareva et al,2008).
They report results on four tasks: USstates, countries, singers, and common fish.
Weevaluated our results manually.
The results in-dicate that ASIA outperforms theirs for all fourdatasets that they reported.
Note that the inputto their system is a semantic class name plus oneseed instance; whereas, the input to ASIA is onlythe class name.
In terms of system runtime, foreach semantic class, Kozareva et alreported thattheir extraction process usually finished overnight;however, ASIA usually finished within a minute.446N Kozareva ASIA N Kozareva ASIAUS States Countries25 1.00 1.00 50 1.00 1.0050 1.00 1.00 100 1.00 1.0064 0.78 0.78 150 1.00 1.00200 0.90 0.93300 0.61 0.67323 0.57 0.62Singers Common Fish10 1.00 1.00 10 1.00 1.0025 1.00 1.00 25 1.00 1.0050 0.97 1.00 50 1.00 1.0075 0.96 1.00 75 0.93 1.00100 0.96 1.00 100 0.84 1.00150 0.95 0.97 116 0.80 1.00180 0.91 0.96Table 2: Set instance extraction performance com-pared to Kozareva et al We report our precisionfor all semantic classes and at the same ranks re-ported in their work.5.2 (Pas?ca, 2007b)We compare ASIA to Pasca (Pas?ca, 2007b) andpresent comparison results in Table 3.
There areten semantic classes in his evaluation dataset, andthe input to his system for each class is a set ofseed entities rather than a class name.
We evaluateevery instance manually for each class.
The resultsshow that, on average, ASIA performs better.However, we should emphasize that for thethree classes: movie, person, and video game,ASIA did not initially converge to the correct in-stance list given the most natural concept name.Given ?movies?, ASIA returns as instances stringslike ?comedy?, ?action?, ?drama?, and other kindsof movies.
Given ?video games?, it returns ?PSP?,?Xbox?, ?Wii?, etc.
Given ?people?, it returns?musicians?, ?artists?, ?politicians?, etc.
We ad-dressed this problem by simply re-running ASIAwith a more specific class name (i.e., the first onereturned); however, the result suggests that futurework is needed to support automatic constructionof hypernym hierarchy using semi-structured webdocuments.5.3 (Snow et al, 2006)Snow (Snow et al, 2006) has extended the Word-Net 2.1 by adding thousands of entries (synsets)at a relatively high precision.
They have madeseveral versions of extended WordNet available4.For comparison purposes, we selected the version(+30K) that achieved the best F-score in their ex-periments.4http://ai.stanford.edu/?rion/swn/Precision @Target Class System 25 50 100 150 250Cities Pasca 1.00 0.96 0.88 0.84 0.75ASIA 1.00 1.00 0.97 0.98 0.96Countries Pasca 1.00 0.98 0.95 0.82 0.60ASIA 1.00 1.00 1.00 1.00 0.79Drugs Pasca 1.00 1.00 0.96 0.92 0.75ASIA 1.00 1.00 1.00 1.00 0.98Food Pasca 0.88 0.86 0.82 0.78 0.62ASIA 1.00 1.00 0.93 0.95 0.90Locations Pasca 1.00 1.00 1.00 1.00 1.00ASIA 1.00 1.00 1.00 1.00 1.00Newspapers Pasca 0.96 0.98 0.93 0.86 0.54ASIA 1.00 1.00 0.98 0.99 0.85Universities Pasca 1.00 1.00 1.00 1.00 0.99ASIA 1.00 1.00 1.00 1.00 1.00Movies Pasca 0.92 0.90 0.88 0.84 0.79Comedy Movies ASIA 1.00 1.00 1.00 1.00 1.00People Pasca 1.00 1.00 1.00 1.00 1.00Jazz Musicians ASIA 1.00 1.00 1.00 0.94 0.88Video Games Pasca 1.00 1.00 0.99 0.98 0.98PSP Games ASIA 1.00 1.00 1.00 0.99 0.97Pasca 0.98 0.97 0.94 0.90 0.80Average ASIA 1.00 1.00 0.99 0.98 0.93Table 3: Set instance extraction performance com-pared to Pasca.
We report our precision for all se-mantic classes and at the same ranks reported inhis work.For the experimental comparison, we focusedon leaf semantic classes from the extended Word-Net that have many hypernyms, so that a mean-ingful comparison could be made: specifically, weselected nouns that have at least three hypernyms,such that the hypernyms are the leaf nodes in thehypernym hierarchy of WordNet.
Of these, 210were extended by Snow.
Preliminary experimentsshowed that (as in the experiments with Pasca?sclasses above) ASIA did not always converge tothe intended meaning; to avoid this problem, weinstituted a second filter, and discarded ASIA?s re-sults if the intersection of hypernyms from ASIAand WordNet constituted less than 50% of thosein WordNet.
About 50 of the 210 nouns passedthis filter.
Finally, we manually evaluated preci-sion and recall of a randomly selected set of twelveof these 50 nouns.We present the results in Table 4.
We used afixed cut-off score5 of 0.3 to truncate the rankedlist produced by ASIA, so that we can computeprecision.
Since only a few of these twelve nounsare closed sets, we cannot generally compute re-call; instead, we define relative recall to be theratio of correct instances to the union of correctinstances from both systems.
As shown in the re-sults, ASIA has much higher precision, and muchhigher relative recall.
When we evaluated Snow?sextended WordNet, we assumed all instances that5Determined from our development set.447Snow?s Wordnet (+30k) Relative ASIA RelativeClass Name # Right # Wrong Prec.
Recall # Right # Wrong Prec.
RecallFilm Directors 4 4 0.50 0.01 457 0 1.00 1.00Manias 11 0 1.00 0.09 120 0 1.00 1.00Canadian Provinces 10 82 0.11 1.00 10 3 0.77 1.00Signs of the Zodiac 12 10 0.55 1.00 12 0 1.00 1.00Roman Emperors 44 4 0.92 0.47 90 0 1.00 0.96Academic Departments 20 0 1.00 0.67 27 0 1.00 0.90Choreographers 23 10 0.70 0.14 156 0 1.00 0.94Elected Officials 5 102 0.05 0.31 12 0 1.00 0.75Double Stars 11 1 0.92 0.46 20 0 1.00 0.83South American Countries 12 1 0.92 1.00 12 0 1.00 1.00Prizefighters 16 4 0.80 0.23 63 1 0.98 0.89Newspapers 20 0 1.00 0.23 71 0 1.00 0.81Average 15.7 18.2 0.70 0.47 87.5 0.3 0.98 0.92Table 4: Set instance extraction performance compared to Snow et alFigure 5: Examples of ASIA?s input and out-put.
Input class for Chinese is ?holidays?
and forJapanese is ?dramas?.were in the original WordNet are correct.
Thethree incorrect instances of Canadian provincesfrom ASIA are actually the three Canadian terri-tories.6 ConclusionsIn this paper, we have shown that ASIA, a SEAL-based system, extracts set instances with high pre-cision and recall in multiple languages given onlythe set name.
It obtains a high MAP score (87%)averaged over 36 benchmark problems in threelanguages (Chinese, Japanese, and English).
Fig-ure 5 shows some real examples of ASIA?s in-put and output in those three languages.
ASIA?sapproach is based on web-based set expansionusing semi-structured documents, and is moti-vated by the conjecture that for many naturalclasses, the amount of information available insemi-structured documents on the Web is muchlarger than the amount of information availablein free-text documents.
This conjecture is givensome support by our experiments: for instance,ASIA finds 457 instances of the set ?film direc-tor?
with perfect precision, whereas Snow et alsstate-of-the-art methods for extraction from freetext extract only four correct instances, with only50% precision.ASIA?s approach is also quite language-independent.
By adding a few simple hyponympatterns, we can easily extend the system to sup-port other languages.
We have also shown thatHearst?s method works not only for English, butalso for other languages such as Chinese andJapanese.
We note that the ability to constructsemantic lexicons in diverse languages has obvi-ous applications in machine translation.
We havealso illustrated that ASIA outperforms three otherEnglish systems (Kozareva et al, 2008; Pas?ca,2007b; Snow et al, 2006), even though many ofthese use more input than just a semantic classname.
In addition, ASIA is also quite efficient,requiring only a few minutes of computation andcouple hundreds of web pages per problem.In the future, we plan to investigate the pos-sibility of constructing hypernym hierarchy auto-matically using semi-structured documents.
Wealso plan to explore whether lexicons can be con-structed using only the back-off method for hy-ponym extraction, to make ASIA completely lan-guage independent.
We also wish to explorewhether performance can be improved by simul-taneously finding class instances in multiple lan-guages (e.g., Chinese and English) while learningtranslations between the extracted instances.7 AcknowledgmentsThis work was supported by the Google ResearchAwards program.448ReferencesOren Etzioni, Michael J. Cafarella, Doug Downey,Ana-Maria Popescu, Tal Shaked, Stephen Soder-land, Daniel S. Weld, and Alexander Yates.
2005.Unsupervised named-entity extraction from theweb: An experimental study.
Artif.
Intell.,165(1):91?134.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In In Proceedingsof the 14th International Conference on Computa-tional Linguistics, pages 539?545.Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.2008.
Semantic class learning from the web withhyponym pattern linkage graphs.
In Proceedings ofACL-08: HLT, pages 1048?1056, Columbus, Ohio,June.
Association for Computational Linguistics.Zornitsa Kozareva.
2006.
Bootstrapping named entityrecognition with automatically generated gazetteerlists.
In EACL.
The Association for Computer Lin-guistics.David Nadeau, Peter D. Turney, and Stan Matwin.2006.
Unsupervised named-entity recognition:Generating gazetteers and resolving ambiguity.
InLuc Lamontagne and Mario Marchand, editors,Canadian Conference on AI, volume 4013 of Lec-ture Notes in Computer Science, pages 266?277.Springer.Marius Pas?ca.
2007a.
Organizing and searching theworld wide web of facts ?
step two: harnessing thewisdom of the crowds.
In WWW ?07: Proceedingsof the 16th international conference on World WideWeb, pages 101?110, New York, NY, USA.
ACM.Marius Pas?ca.
2007b.
Weakly-supervised discoveryof named entities using web search queries.
InCIKM ?07: Proceedings of the sixteenth ACM con-ference on Conference on information and knowl-edge management, pages 683?690, New York, NY,USA.
ACM.Patrick Pantel and Deepak Ravichandran.
2004.Automatically labeling semantic classes.
InDaniel Marcu Susan Dumais and Salim Roukos, ed-itors, HLT-NAACL 2004: Main Proceedings, pages321?328, Boston, Massachusetts, USA, May 2 -May 7.
Association for Computational Linguistics.Marius Pasca.
2004.
Acquisition of categorized namedentities for web search.
In CIKM ?04: Proceed-ings of the thirteenth ACM international conferenceon Information and knowledge management, pages137?145, New York, NY, USA.
ACM.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2006.Semantic taxonomy induction from heterogenousevidence.
In ACL ?06: Proceedings of the 21st Inter-national Conference on Computational Linguisticsand the 44th annual meeting of the ACL, pages 801?808, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan.2006.
Fast random walk with restart and its appli-cations.
In ICDM, pages 613?622.
IEEE ComputerSociety.Richard C. Wang and William W. Cohen.
2007.Language-independent set expansion of named enti-ties using the web.
In ICDM, pages 342?350.
IEEEComputer Society.Richard C. Wang and William W. Cohen.
2008.
Iter-ative set expansion of named entities using the web.In ICDM, pages 1091?1096.
IEEE Computer Soci-ety.Richard C. Wang, Nico Schlaefer, William W. Co-hen, and Eric Nyberg.
2008.
Automatic set ex-pansion for list question answering.
In Proceedingsof the 2008 Conference on Empirical Methods inNatural Language Processing, pages 947?954, Hon-olulu, Hawaii, October.
Association for Computa-tional Linguistics.449
