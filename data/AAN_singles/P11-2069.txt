Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 395?400,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsMonolingual Alignment by Edit Rate Computationon Sentential Paraphrase PairsHouda Bouamor Aure?lien MaxLIMSI-CNRSUniv.
Paris SudOrsay, France{firstname.lastname}@limsi.frAnne VilnatAbstractIn this paper, we present a novel way of tack-ling the monolingual alignment problem onpairs of sentential paraphrases by means ofedit rate computation.
In order to inform theedit rate, information in the form of subsenten-tial paraphrases is provided by a range of tech-niques built for different purposes.
We showthat the tunable TER-PLUS metric from Ma-chine Translation evaluation can achieve goodperformance on this task and that it can effec-tively exploit information coming from com-plementary sources.1 IntroductionThe acquisition of subsentential paraphrases has at-tracted a lot of attention recently (Madnani and Dorr,2010).
Techniques are usually developed for extract-ing paraphrase candidates from specific types of cor-pora, including monolingual parallel corpora (Barzi-lay and McKeown, 2001), monolingual comparablecorpora (Dele?ger and Zweigenbaum, 2009), bilin-gual parallel corpora (Bannard and Callison-Burch,2005), and edit histories of multi-authored text (Maxand Wisniewski, 2010).
These approaches face twomain issues, which correspond to the typical mea-sures of precision, or how appropriate the extractedparaphrases are, and of recall, or how many of theparaphrases present in a given corpus can be foundeffectively.
To start with, both measures are oftenhard to compute in practice, as 1) the definition ofwhat makes an acceptable paraphrase pair is stilla research question, and 2) it is often impracticalto extract a complete set of acceptable paraphrasesfrom most resources.
Second, as regards the pre-cision of paraphrase acquisition techniques in par-ticular, it is notable that most works on paraphraseacquisition are not based on direct observation oflarger paraphrase pairs.
Even monolingual corporaobtained by pairing very closely related texts such asnews headlines on the same topic and from the sametime frame (Dolan et al, 2004) often contain unre-lated segments that should not be aligned to form asubsentential paraphrase pair.
Using bilingual cor-pora to acquire paraphrases indirectly by pivotingthrough other languages is faced, in particular, withthe issue of phrase polysemy, both in the source andin the pivot languages.It has previously been noted that highly parallelmonolingual corpora, typically obtained via mul-tiple translation into the same language, consti-tute the most appropriate type of corpus for ex-tracting high quality paraphrases, in spite of theirrareness (Barzilay and McKeown, 2001; Cohn etal., 2008; Bouamor et al, 2010).
We build on thisclaim here to propose an original approach for thetask of subsentential alignment based on the compu-tation of a minimum edit rate between two sententialparaphrases.
More precisely, we concentrate on thealignment of atomic paraphrase pairs (Cohn et al,2008), where the words from both paraphrases arealigned as a whole to the words of the other para-phrase, as opposed to composite paraphrase pairsobtained by joining together adjacent paraphrasepairs or possibly adding unaligned words.
Figure 1provides examples of atomic paraphrase pairs de-rived from a word alignment between two Englishsentential paraphrases.395Chinawillcontinue continue?carry onimplementingthefinancial financial openingup?open financialopeninguppolicyChinawillcarryon openfinancialpolicyFigure 1: Reference alignments for a pair of Englishsentential paraphrases and their associated list of atomicparaphrase pairs extracted from them.
Note that identitypairs (e.g.
China ?
China) will never be considered inthis work and will not be taken into account for evalua-tion.The remainder of this paper is organized as fol-lows.
We first briefly describe in section 2 how weapply edit rate computation to the task of atomicparaphrase alignment, and we explain in section 3how we can inform such a technique with paraphrasecandidates extracted by additional techniques.
Wepresent our experiments and discuss their results insection 4 and conclude in section 5.2 Edit rate for paraphrase alignmentTER-PLUS (Translation Edit Rate Plus) (Snover etal., 2010) is a score designed for evaluation of Ma-chine Translation (MT) output.
Its typical use takesa system hypothesis to compute an optimal set ofword edits that can transform it into some existingreference translation.
Edit types include exact wordmatching, word insertion and deletion, block move-ment of contiguous words (computed as an approx-imation), as well as variants substitution throughstemming, synonym or paraphrase matching.
Eachedit type is parameterized by at least one weightwhich can be optimized using e.g.
hill climbing.TER-PLUS is therefore a tunable metric.
We willhenceforth design as TERMT the TER metric (basi-cally, without variants matching) optimized for cor-relation with human judgment of accuracy in MTevaluation, which is to date one of the most usedmetrics for this task.While this metric was not designed explicitely forthe acquisition of word alignments, it produces as aby-product of its approximate search a list of align-ments involving either individual words or phrases,potentially fitting with the previous definition ofatomic paraphrase pairs.
When applying it on aMT system hypothesis and a reference translation,it computes how much effort would be needed toobtain the reference from the hypothesis, possiblyindependently of the appropriateness of the align-ments produced.
However, if we consider insteada pair of sentential paraphrases, it can be used toreveal what subsentential units can be aligned.
Ofcourse, this relies on information that will often gobeyond simple exact word matching.
This is wherethe capability of exploiting paraphrase matching cancome into play: TER-PLUS can exploit a table ofparaphrase pairs, and defines the cost of a phrasesubstitution as ?a function of the probability of theparaphrase and the number of edits needed to alignthe two phrases without the use of phrase substitu-tions?.
Intuitively, the more parallel two sententialparaphrases are, the more atomic paraphrase pairswill be reliably found, and the easier it will be forTER-PLUS to correctly identify the remaining pairs.But in the general case, and considering less appar-ently parallel sentence pairs, its work can be facil-itated by the incorporation of candidate paraphrasepairs in its paraphrase table.
We consider this possi-ble type of hybridation in the next section.3 Informing edit rate computation withother techniquesIn this article, we use three baseline techniquesfor paraphrase pair acquisition, which we will onlybriefly introduce (see (Bouamor et al, 2010) formore details).
As explained previously, we want toevaluate whether and how their candidate paraphrasepairs can be used to improve paraphrase acquisitionon sentential paraphrases using TER-PLUS.
We se-lected these three techniques for the complementar-ity of types of information that they use: statisticalword alignment without a priori linguistic knowl-edge, symbolic expression of linguistic variation ex-ploiting a priori linguistic knowledge, and syntacticsimilarity.396Statistical Word Alignment The GIZA++tool (Och and Ney, 2004) computes statistical wordalignment models of increasing complexity fromparallel corpora.
While originally developped in thebilingual context of Machine Translation, nothingprevents building such models on monolingualcorpora.
However, in order to build reliable modelsit is necessary to use enough training materialincluding minimal redundancy of words.
To thisend, we will be using monolingual corpora madeup of multiply-translated sentences, allowing us toprovide GIZA++ with all possible sentence pairsto improve the quality of its word alignments (notethat following common practice we used symetrizedalignments from the alignments in both directions).This constitutes an advantage for this technique thatthe following techniques working on each sentencepair independently do not have.Symbolic expression of linguistic variation TheFASTR tool (Jacquemin, 1999) was designed to spotterm variants in large corpora.
Variants are de-scribed through metarules expressing how the mor-phosyntactic structure of a term variant can be de-rived from a given term by means of regular ex-pressions on word categories.
Paradigmatic varia-tion can also be expressed by defining constraintsbetween words to force them to belong to the samemorphological or semantic family, both constraintsrelying on preexisting repertoires available for En-glish and French.
To compute candidate paraphrasepairs using FASTR, we first consider all the phrasesfrom the first sentence and search for variants in theother sentence, do the reverse process and take theintersection of the two sets.Syntactic similarity The algorithm introducedby Pang et al (2003) takes two sentences as in-put and merges them by top-down syntactic fusionguided by compatible syntactic substructure.
Alexical blocking mechanism prevents sentence con-stituents from fusionning when there is evidence ofthe presence of a word in another constituent of oneof the sentence.
We use the Berkeley Probabilisticparser (Petrov and Klein, 2007) to obtain syntac-tic trees for English and its Bonsai adaptation forFrench (Candito et al, 2010).
Because this processis highly sensitive to syntactic parse errors, we usek-best parses (with k = 3 in our experiments) andretain the most compact fusion from any pair of can-didate parses.4 Experiments and discussionWe used the methodology described by Cohn et al(2008) for constructing evaluation corpora and as-sessing the performance of various techniques on thetask of paraphrase acquisition.
In a nutshell, pairs ofsentential paraphrases are hand-aligned and define aset of reference atomic paraphrase pairs at the levelof words or blocks or words, denoted as Ratom, andalso a set of reference composite paraphrase pairsobtained by joining adjacent atomic paraphrase pairs(up to a given length), denoted as R. Techniquesoutput word alignments from which atomic candi-date paraphrase pairs, denoted as Hatom, as well ascomposite paraphrase pairs, denoted as H, can beextracted.
The usual measures of precision, recalland f-measure can then be defined in the followingway:p =|Hatom ?R||Hatom|r =|H ?
Ratom||Ratom|f1 =2prp + rTo evaluate our individual techniques and theiruse by the tunable TER-PLUS technique (hence-forth TERP), we measured results on two differentcorpora in French and English.
In each case, a held-out development corpus of 150 paraphrase pairs wasused for tuning the TERP hybrid systems towardsprecision (?
p), recall (?
r), or F-measure (?f1).1 All techniques were evaluated on the same testset consisting of 375 paraphrase pairs.
For English,we used the MTC corpus described in (Cohn et al,2008), which consists of multiply-translated Chi-nese sentences into English, with an average lexicaloverlap2 of 65.91% (all tokens) and 63.95% (contentwords only).
We used as our reference set both thealignments marked as ?Sure?
and ?Possible?.
ForFrench, we used the CESTA corpus of news articles3obtained by translating into French from various lan-guages with an average lexical overlap of 79.63%(all tokens) and 78.19% (content words only).
These1Hill climbing was used for tuning as in (Snover et al,2010), with uniform weights and 100 random restarts.2We compute the percentage of lexical overlap be-tween the vocabularies of two sentences S1 and S2 as :|S1 ?
S2|/min(|S1|, |S2|)3http://www.elda.org/article125.html397Individual techniques Hybrid systems (TERPpara+X)Giza++ Fastr Pang TMT TERPpara +G +F +P +G + F + PG F P ?
p ?
r ?
f1 ?
p ?
r ?
f1 ?
p ?
r ?
f1 ?
p ?
r ?
f1 ?
p ?
r ?
f1French Frenchp 28.99 52.48 62.50 25.66 31.35 30.26 31.43 41.99 30.55 41.14 36.74 29.65 34.84 54.49 20.94 33.89 42.27 27.06 42.80r 45.98 8.59 8.65 41.15 44.22 44.60 44.10 35.88 45.67 35.25 40.96 43.85 44.41 13.61 40.40 40.46 31.36 44.10 31.61f1 35.56 14.77 15.20 25.66 36.69 36.05 36.70 38.70 36.61 37.97 38.74 35.38 39.05 21.78 27.58 36.88 36.01 33.54 36.37English Englishp 18.28 33.02 36.66 20.41 31.19 19.14 19.35 26.89 19.85 21.25 41.57 20.81 22.51 31.32 18.02 18.92 29.45 16.81 29.42r 14.63 5.41 2.23 17.37 2.31 19.38 19.69 11.92 18.47 17.10 6.94 21.02 20.28 3.41 18.94 16.44 13.57 19.30 16.35f1 16.25 9.30 4.21 18.77 4.31 19.26 19.52 16.52 19.14 18.95 11.91 20.92 21.33 6.15 18.47 17.59 18.58 17.96 21.02Figure 2: Results on the test set on French and English for the individual techniques and TERP hybrid systems.Column headers of the form ??
c?
indicate that TERP was tuned on criterion c.figures reveal that the French corpus tends to containmore literal translations, possibly due to the originallanguages of the sentences, which are closer to thetarget language than Chinese is to English.
We usedthe YAWAT (Germann, 2008) interactive alignmenttool and measure inter-annotator agreement over asubset and found it to be similar to the value reportedby Cohn et al (2008) for English.Results for all individual techniques in the twolanguages are given on Figure 2.
We first note thatall techniques fared better on the French corpus thanon the English corpus.
This can certainly be ex-plained by the fact that the former results from moreliteral translations, which are consequently easier toword-align.TERMT (i.e.
TER tuned for Machine Transla-tion evaluation) performs significantly worse on allmetrics for both languages than our tuned TERP ex-periments, revealing that the two tasks have differ-ent objectives.
The two linguistically-aware tech-niques, FASTR and PANG, have a very strong pre-cision on the more parallel French corpus, and alsoon the English corpus to a lesser extent, but fail toachieve a high recall (note, in particular, that theydo not attempt to report preferentially atomic para-phrase pairs).
GIZA++ and TERPpara perform inthe same range, with acceptable precision and re-call, TERPpara performing overall better, with e.g.
a1.14 advantage on f-measure on French and 3.27 onEnglish.
Recall that TERP works independently oneach paraphrase pair, while GIZA++ makes use ofartificial repetitions of paraphrases of the same sen-tence.Figure 3 gives an indication of how well eachtechnique performs depending on the difficulty ofthe task, which we estimate here as the value(1?
TER(para1, para2)), whose low values cor-respond to sentences which are costly to trans-form into the other using TER.
Not surprisingly,TERPpara and GIZA++, and PANG to a lesser ex-tent, perform better on ?more parallel?
sententialparaphrase pairs.
Conversely, FASTR is not affectedby the degree of parallelism between sentences, andmanages to extract synonyms and more generallyterm variants, at any level of difficulty.We have further tested 4 hybrid configurationsby providing TERPpara with the output of the otherindividual techniques and of their union, the lattersimply obtained by taking paraphrase pairs outputby at least one of these techniques.
On French,where individual techniques achieve good perfor-mance, any hybridation improves the F-measureover both TERPpara and the technique used, the bestperformance, using FASTR, corresponding to an im-provement of respectively +2.35 and +24.28 overTERPpara and FASTR.
Taking the union of all tech-niques does not yield additional gains: this mightbe explained by the fact that incorrect predictionsare proportionnally more present and consequentlyhave a greater impact when combining techniqueswithout weighting them, possibly at the level of each398<0.1 <0.2 <0.3 <0.4 <0.5 <0.6 <0.7 <0.8 <0.90102030405060708090100 TERpParaF1Giza++FastrPangDifficulty (1-TER)F-measure<0.1 <0.2 <0.3 <0.4 <0.5 <0.6 <0.7 <0.8 <0.90102030405060708090100 TERpParaF1Giza++FastrPangDifficulty (1-TER)F-measure(a) French (b) EnglishFigure 3: F-measure values for our 4 individual techniques on French and English depending on the complexity ofparaphrase pairs measured with the (1-TER) formula.
Note that each value corresponds to the average of F-measurevalues for test examples falling in a given difficulty range, and that all ranges do not necessarily contain the samenumber of examples.prediction.4 Successful hybridation on English seemharder to obtain, which may be partly attributed tothe poor quality of the individual techniques relativeto TERPpara.
We however note anew an improve-ment over TERPpara of +1.81 when using FASTR.This confirms that some types of linguistic equiva-lences cannot be captured using edit rate computa-tion alone, even on this type of corpus.5 Conclusion and future workIn this article, we have described the use of edit ratecomputation for paraphrase alignment at the sub-sentential level from sentential paraphrases and thepossibility of informing this search with paraphrasecandidates coming from other techniques.
Our ex-periments have shown that in some circumstancessome techniques have a good complementarity andmanage to improve results significantly.
We arecurrently studying hard-to-align subsentential para-phrases from the type of corpora we used in order toget a better understanding of the types of knowledgerequired to improve automatic acquisition of theseunits.4Indeed, measuring the precision on the union yields a poorperformance of 23.96, but with the highest achievable value of50.56 for recall.
Similarly, the maximum value for precisionwith a good recall can be obtained by taking the intersection ofthe results of TERPpara and GIZA++, which yields a value of60.39.Our future work also includes the acquisition ofparaphrase patterns (e.g.
(Zhao et al, 2008)) to gen-eralize the acquired equivalence units to more con-texts, which could be both used in applications andto attempt improving further paraphrase acquisitiontechniques.
Integrating the use of patterns within anedit rate computation technique will however raisenew difficulties.We are finally also in the process of conductinga careful study of the characteristics of the para-phrase pairs that each technique can extract withhigh confidence, so that we can improve our hybri-dation experiments by considering confidence val-ues at the paraphrase level using Machine Learning.This way, we may be able to use an edit rate com-putation algorithm such as TER-PLUS as a moreefficient system combiner for paraphrase extractionmethods than what was proposed here.
A poten-tial application of this would be an alternative pro-posal to the paraphrase evaluation metric PARAMET-RIC (Callison-Burch et al, 2008), where individualtechniques, outputing word alignments or not, couldbe evaluated from the ability of the informated editrate technique to use correct equivalence units.AcknowledgmentsThis work was partly funded by a grant from LIMSI.The authors wish to thank the anonymous reviewersfor their useful comments and suggestions.399ReferencesColin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with Bilingual Parallel Corpora.
In Proceed-ings of ACL, Ann Arbor, USA.Regina Barzilay and Kathleen R. McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Pro-ceedings of ACL, Toulouse, France.Houda Bouamor, Aure?lien Max, and Anne Vilnat.
2010.Comparison of Paraphrase Acquisition Techniques onSentential Paraphrases.
In Proceedings of IceTAL, Re-jkavik, Iceland.Chris Callison-Burch, Trevor Cohn, and Mirella Lapata.2008.
Parametric: An automatic evaluation metric forparaphrasing.
In Proceedings of COLING, Manch-ester, UK.Marie Candito, Beno?
?t Crabbe?, and Pascal Denis.
2010.Statistical French dependency parsing: treebank con-version and first results.
In Proceedings of LREC, Val-letta, Malta.Trevor Cohn, Chris Callison-Burch, and Mirella Lapata.2008.
Constructing corpora for the development andevaluation of paraphrase systems.
Computational Lin-guistics, 34(4).Louise Dele?ger and Pierre Zweigenbaum.
2009.
Extract-ing lay paraphrases of specialized expressions frommonolingual comparable medical corpora.
In Pro-ceedings of the 2nd Workshop on Building and UsingComparable Corpora: from Parallel to Non-parallelCorpora, Singapore.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.
Un-supervised construction of large paraphrase corpora:Exploiting massively parallel news sources.
In Pro-ceedings of Coling 2004, pages 350?356, Geneva,Switzerland.Ulrich Germann.
2008.
Yawat : Yet Another WordAlignment Tool.
In Proceedings of the ACL-08: HLTDemo Session, Columbus, USA.Christian Jacquemin.
1999.
Syntagmatic and paradig-matic representations of term variation.
In Proceed-ings of ACL, pages 341?348, College Park, USA.Nitin Madnani and Bonnie J. Dorr.
2010.
GeneratingPhrasal and Sentential Paraphrases: A Survey of Data-Driven Methods .
Computational Linguistics, 36(3).Aure?lien Max and Guillaume Wisniewski.
2010.
Min-ing Naturally-occurring Corrections and Paraphrasesfrom Wikipedia?s Revision History.
In Proceedings ofLREC, Valletta, Malta.Franz Josef Och and Herman Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4).Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignement of multiple translations: Ex-tracting paraphrases and generating new sentences.
InProceedings of NAACL-HLT, Edmonton, Canada.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of NAACL-HLT, Rochester, USA.Matthew Snover, Nitin Madnani, Bonnie J. Dorr, andRichard Schwartz.
2010.
TER-Plus: paraphrase, se-mantic, and alignment enhancements to TranslationEdit Rate.
Machine Translation, 23(2-3).Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2008.
Pivot Approach for Extracting Paraphrase Pat-terns from Bilingual Corpora.
In Proceedings of ACL-HLT, Columbus, USA.400
