Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 123?128,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsSemEval-2010 Task 17: All-words Word Sense Disambiguationon a Specific DomainEneko AgirreIXA NLP groupUBCDonostia, Basque Countrye.agirre@ehu.esOier Lopez de LacalleIXA NLP groupUBCDonostia, Basque Countryoier.lopezdelacalle@ehu.esChristiane FellbaumDepartment of Computer SciencePrinceton UniversityPrinceton, USAfellbaum@princeton.eduAndrea MarchettiIITCNRPisa, Italyandrea.marchetti@iit.cnr.itAntonio ToralILCCNRPisa, Italyantonio.toral@ilc.cnr.itPiek VossenFaculteit der LetterenVrije Universiteit AmsterdamAmsterdam, Netherlandsp.vossen@let.vu.nlAbstractDomain portability and adaptation of NLPcomponents and Word Sense Disambiguationsystems present new challenges.
The diffi-culties found by supervised systems to adaptmight change the way we assess the strengthsand weaknesses of supervised and knowledge-based WSD systems.
Unfortunately, all ex-isting evaluation datasets for specific domainsare lexical-sample corpora.
With this paperwe want to motivate the creation of an all-words test dataset for WSD on the environ-ment domain in several languages, and presentthe overall design of this SemEval task.1 IntroductionWord Sense Disambiguation (WSD) competitionshave focused on general domain texts, as attestedin the last Senseval and Semeval competitions (Kil-garriff, 2001; Mihalcea et al, 2004; Pradhan et al,2007).
Specific domains pose fresh challenges toWSD systems: the context in which the senses occurmight change, distributions and predominant sensesvary, some words tend to occur in fewer senses inspecific domains, and new senses and terms mightbe involved.
Both supervised and knowledge-basedsystems are affected by these issues: while the firstsuffer from different context and sense priors, thelater suffer from lack of coverage of domain-relatedwords and information.Domain adaptation of supervised techniques is ahot issue in Natural Language Processing, includ-ing Word Sense Disambiguation.
Supervised WordSense Disambiguation systems trained on generalcorpora are known to perform worse when appliedto specific domains (Escudero et al, 2000; Mart?
?nezand Agirre, 2000), and domain adaptation tech-niques have been proposed as a solution to this prob-lem with mixed results.Current research on applying WSD to specific do-mains has been evaluated on three available lexical-sample datasets (Ng and Lee, 1996; Weeber et al,2001; Koeling et al, 2005).
This kind of datasetcontains hand-labeled examples for a handful of se-lected target words.
As the systems are evaluated ona few words, the actual performance of the systemsover complete texts can not be measured.
Differ-ences in behavior of WSD systems when applied tolexical-sample and all-words datasets have been ob-served on previous Senseval and Semeval competi-tions (Kilgarriff, 2001; Mihalcea et al, 2004; Prad-han et al, 2007): supervised systems attain resultson the high 80?s and beat the most frequent base-line by a large margin for lexical-sample datasets,but results on the all-words datasets were much moremodest, on the low 70?s, and a few points above themost frequent baseline.Thus, the behaviour of WSD systems on domain-specific texts is largely unknown.
While some wordscould be supposed to behave in similar ways, andthus be amenable to be properly treated by a generic123WSD algorithm, other words have senses closelylinked to the domain, and might be disambiguatedusing purpose-built domain adaptation strategies (cf.Section 4).
While it seems that domain-specificWSD might be a tougher problem than genericWSD, it might well be that domain-related wordsare easier to disambiguate.The main goal of this task is to provide a mul-tilingual testbed to evaluate WSD systems whenfaced with full-texts from a specific domain, that ofenvironment-related texts.
The paper is structuredas follows.
The next section presents current lexi-cal sample datasets for domain-specific WSD.
Sec-tion 3 presents some possible settings for domainadaptation.
Section 4 reviews the state-of-the art indomain-specific WSD.
Section 5 presents the designof our task, and finally, Section 6 draws some con-clusions.2 Specific domain datasets availableWe will briefly present the three existing datasetsfor domain-related studies in WSD, which are alllexical-sample.The most commonly used dataset is the DefenseScience Organization (DSO) corpus (Ng and Lee,1996), which comprises sentences from two differ-ent corpora.
The first is the Wall Street Journal(WSJ), which belongs to the financial domain, andthe second is the Brown Corpus (BC) which is a bal-anced corpora of English usage.
191 polysemouswords (nouns and verbs) of high frequency in WSJand BC were selected and a total of 192,800 occur-rences of these words were tagged with WordNet 1.5senses, more than 1,000 instances per word in aver-age.
The examples from BC comprise 78,080 oc-currences of word senses, and examples from WSJconsist on 114,794 occurrences.
In domain adapta-tion experiments, the Brown Corpus examples playthe role of general corpora, and the examples fromthe WSJ play the role of domain-specific examples.Koeling et al (2005) present a corpus were theexamples are drawn from the balanced BNC cor-pus (Leech, 1992) and the SPORTS and FINANCESsections of the newswire Reuters corpus (Rose et al,2002), comprising around 300 examples (roughly100 from each of those corpora) for each of the 41nouns.
The nouns were selected because they weresalient in either the SPORTS or FINANCES domains,or because they had senses linked to those domains.The occurrences were hand-tagged with the sensesfrom WordNet version 1.7.1 (Fellbaum, 1998).
Indomain adaptation experiments the BNC examplesplay the role of general corpora, and the FINANCESand SPORTS examples the role of two specific do-main corpora.Finally, a dataset for biomedicine was developedby Weeber et al (2001), and has been used asa benchmark by many independent groups.
TheUMLS Metathesaurus was used to provide a set ofpossible meanings for terms in biomedical text.
50ambiguous terms which occur frequently in MED-LINE were chosen for inclusion in the test set.
100instances of each term were selected from citationsadded to the MEDLINE database in 1998 and man-ually disambiguated by 11 annotators.
Twelve termswere flagged as ?problematic?
due to substantial dis-agreement between the annotators.
In addition to themeanings defined in UMLS, annotators had the op-tion of assigning a special tag (?none?)
when noneof the UMLS meanings seemed appropriate.Although these three corpora are useful for WSDresearch, it is difficult to infer which would be theperformance of a WSD system on full texts.
Thecorpus of Koeling et al, for instance, only includeswords which where salient for the target domains,but the behavior of WSD systems on other wordscannot be explored.
We would also like to note thatwhile the biomedicine corpus tackles scholarly textof a very specific domain, the WSJ part of the DSOincludes texts from a financially oriented newspaper,but also includes news of general interest which haveno strict relation to the finance domain.3 Possible settings for domain adaptationWhen performing supervised WSD on specific do-mains the first setting is to train on a general domaindata set and to test on the specific domain (sourcesetting).
If performance would be optimal, thiswould be the ideal solution, as it would show that ageneric WSD system is robust enough to tackle textsfrom new domains, and domain adaptation wouldnot be necessary.The second setting (target setting) would be totrain the WSD systems only using examples from124the target domain.
If this would be the optimal set-ting, it would show that there is no cost-effectivemethod for domain adaptation.
WSD systems wouldneed fresh examples every time they were deployedin new domains, and examples from general do-mains could be discarded.In the third setting, the WSD system is trainedwith examples coming from both the general domainand the specific domain.
Good results in this settingwould show that supervised domain adaptation isworking, and that generic WSD systems can be sup-plemented with hand-tagged examples from the tar-get domain.There is an additional setting, where a genericWSD system is supplemented with untagged exam-ples from the domain.
Good results in this settingwould show that semi-supervised domain adapta-tion works, and that generic WSD systems can besupplemented with untagged examples from the tar-get domain in order to improve their results.Most of current all-words generic supervisedWSD systems take SemCor (Miller et al, 1993) astheir source corpus, i.e.
they are trained on SemCorexamples and then applied to new examples.
Sem-Cor is the largest publicly available annotated cor-pus.
It?s mainly a subset of the Brown Corpus, plusthe novel The Red Badge of Courage.
The Browncorpus is balanced, yet not from the general domain,as it comprises 500 documents drawn from differ-ent domains, each approximately 2000 words long.Although the Brown corpus is balanced, SemCor isnot, as the documents were not chosen at random.4 State-of-the-art in WSD for specificdomainsInitial work on domain adaptation for WSD sys-tems showed that WSD systems were not able toobtain better results on the source or adaptation set-tings compared to the target settings (Escudero etal., 2000), showing that a generic WSD system (i.e.based on hand-annotated examples from a genericcorpus) would not be useful when moved to new do-mains.Escudero et al (2000) tested the supervised adap-tation scenario on the DSO corpus, which had exam-ples from the Brown Corpus and Wall Street Journalcorpus.
They found that the source corpus did nothelp when tagging the target corpus, showing thattagged corpora from each domain would suffice, andconcluding that hand tagging a large general corpuswould not guarantee robust broad-coverage WSD.Agirre and Mart?
?nez (2000) used the same DSO cor-pus and showed that training on the subset of thesource corpus that is topically related to the targetcorpus does allow for domain adaptation, obtainingbetter results than training on the target data alone.In (Agirre and Lopez de Lacalle, 2008), the au-thors also show that state-of-the-art WSD systemsare not able to adapt to the domains in the contextof the Koeling et al (2005) dataset.
While WSDsystems trained on the target domain obtained 85.1and 87.0 of precision on the sports and finances do-mains, respectively, the same systems trained on theBNC corpus (considered as a general domain cor-pus) obtained 53.9 and 62.9 of precision on sportsand finances, respectively.
Training on both sourceand target was inferior that using the target examplesalone.Supervised adaptationSupervised adaptation for other NLP tasks has beenwidely reported.
For instance, (Daume?
III, 2007)shows that a simple feature augmentation methodfor SVM is able to effectively use both labeled tar-get and source data to provide the best domain-adaptation results in a number of NLP tasks.
Hismethod improves or equals over previously exploredmore sophisticated methods (Daume?
III and Marcu,2006; Chelba and Acero, 2004).
In contrast, (Agirreand Lopez de Lacalle, 2009) reimplemented thismethod and showed that the improvement on WSDin the (Koeling et al, 2005) data was marginal.Better results have been obtained using purpose-built adaptation methods.
Chan and Ng (2007) per-formed supervised domain adaptation on a manu-ally selected subset of 21 nouns from the DSO cor-pus.
They used active learning, count-merging, andpredominant sense estimation in order to save tar-get annotation effort.
They showed that adding just30% of the target data to the source examples thesame precision as the full combination of target andsource data could be achieved.
They also showedthat using the source corpus significantly improvedresults when only 10%-30% of the target corpuswas used for training.
In followup work (Zhong et125Projections for 2100 suggest that temperature in Europe will have risen by between 2 to 6.3 C above 1990levels.
The sea level is projected to rise, and a greater frequency and intensity of extreme weather events areexpected.
Even if emissions of greenhouse gases stop today, these changes would continue for many decadesand in the case of sea level for centuries.
This is due to the historical build up of the gases in the atmosphereand time lags in the response of climatic and oceanic systems to changes in the atmospheric concentrationof the gases.Figure 1: Sample text from the environment domain.al., 2008), the feature augmentation approach wascombined with active learning and tested on theOntoNotes corpus, on a large domain-adaptation ex-periment.
They significantly reduced the effort ofhand-tagging, but only obtained positive domain-adaptation results for smaller fractions of the targetcorpus.In (Agirre and Lopez de Lacalle, 2009) the au-thors report successful adaptation on the (Koelinget al, 2005) dataset on supervised setting.
Theirmethod is based on the use of unlabeled data, re-ducing the feature space with SVD, and combina-tion of features using an ensemble of kernel meth-ods.
They report 22% error reduction when usingboth source and target data compared to a classifiertrained on target the target data alone, even when thefull dataset is used.Semi-supervised adaptationThere are less works on semi-supervised domainadaptation in NLP tasks, and fewer in WSD task.Blitzer et al (2006) used Structural CorrespondenceLearning and unlabeled data to adapt a Part-of-Speech tagger.
They carefully select so-called pivotfeatures to learn linear predictors, perform SVD onthe weights learned by the predictor, and thus learncorrespondences among features in both source andtarget domains.
Agirre and Lopez de Lacalle (2008)show that methods based on SVD with unlabeleddata and combination of distinct feature spaces pro-duce positive semi-supervised domain adaptation re-sults for WSD.Unsupervised adaptationIn this context, we take unsupervised to meanKnowledge-Based methods which do not requirehand-tagged corpora.
The predominant sense acqui-sition method was succesfully applied to specific do-mains in (Koeling et al, 2005).
The methos has twosteps: In the first, a corpus of untagged text from thetarget domain is used to construct a thesaurus of sim-ilar words.
In the second, each target word is disam-biguated using pairwise WordNet-based similaritymeasures, taking as pairs the target word and each ofthe most related words according to the thesaurus upto a certain threshold.
This method aims to obtain,for each target word, the sense which is the mostpredominant for the target corpus.
When a generalcorpus is used, the most predominant sense in gen-eral is obtained, and when a domain-specific corpusis used, the most predominant sense for that corpusis obtained (Koeling et al, 2005).
The main motiva-tion of the authors is that the most frequent sense is avery powerful baseline, but it is one which requireshand-tagging text, while their method yields simi-lar information automatically.
The results show thatthey are able to obtain good results.
In related work,(Agirre et al, 2009) report improved results usingthe same strategy but applying a graph-based WSDmethod, and highlight the domain-adaptation poten-tial of unsupervised knowledge-based WSD systemscompared to supervised WSD.5 Design of the WSD-domain taskThis task was designed in the context of Ky-oto (Piek Vossen and VanGent, 2008)1, an Asian-European project that develops a community plat-form for modeling knowledge and finding factsacross languages and cultures.
The platform op-erates as a Wiki system with an ontological sup-port that social communities can use to agree on themeaning of terms in specific domains of their inter-est.
Kyoto will focus on the environmental domainbecause it poses interesting challenges for informa-tion sharing, but the techniques and platforms willbe independent of the application domain.
Kyoto1http://www.kyoto-project.eu/126will make use of semantic technologies based onontologies and WSD in order to extract and repre-sent relevant information for the domain, and is thusinterested on measuring the performance of WSDtechniques on this domain.The WSD-domain task will comprise comparableall-words test corpora on the environment domain.Texts from the European Center for Nature Con-servation2 and Worldwide Wildlife Forum3 will beused in order to build domain specific test corpora.We will select documents that are written for a gen-eral but interested public and that involve specificterms from the domain.
The document content willbe comparable across languages.
Figure 1 shows anexample in English related to global warming.The data will be available in a number of lan-guages: English, Dutch, Italian and Chinese.
Thesense inventories will be based on wordnets of therespective languages, which will be updated to in-clude new vocabulary and senses.
The test data willcomprise three documents of around 2000 wordseach for each language.
The annotation procedurewill involve double-blind annotation plus adjudica-tion, and inter-tagger agreement data will be pro-vided.
The formats and scoring software will fol-low those of Senseval-34 and SemEval-20075 En-glish all-words tasks.There will not be training data available, but par-ticipants are free to use existing hand-tagged cor-pora and lexical resources (e.g.
SemCor and pre-vious Senseval and SemEval data).
We plan to makeavailable a corpus of documents from the same do-main as the selected documents, as well as wordnetsupdated to include the terms and senses in the se-lected documents.6 ConclusionsDomain portability and adaptation of NLP com-ponents and Word Sense Disambiguation systemspresent new challenges.
The difficulties found bysupervised systems to adapt might change the waywe assess the strengths and weaknesses of super-vised and knowledge-based WSD systems.
Unfor-tunately, all existing evaluation datasets for specific2http://www.ecnc.org3http://www.wwf.org4http://www.senseval.org/senseval35http://nlp.cs.swarthmore.edu/semeval/domains are lexical-sample corpora.
With this paperwe have motivated the creation of an all-words testdataset for WSD on the environment domain in sev-eral languages, and presented the overall design ofthis SemEval task.Further details can be obtained from the Semeval-20106 website, our task website7, and in our distri-bution list87 AcknowledgmentsThe organization of the task is partially fundedby the European Commission (KYOTO FP7 ICT-2007-211423) and the Spanish Research Depart-ment (KNOW TIN2006-15049-C03-01).ReferencesEneko Agirre and Oier Lopez de Lacalle.
2008.
On ro-bustness and domain adaptation using SVD for wordsense disambiguation.
In Proceedings of the 22nd In-ternational Conference on Computational Linguistics(Coling 2008), pages 17?24, Manchester, UK, August.Coling 2008 Organizing Committee.Eneko Agirre and Oier Lopez de Lacalle.
2009.
Super-vised domain adaptation for wsd.
In Proceedings ofthe 12th Conference of the European Chapter of theAssociation for Computational Linguistics (EACL-09).E.
Agirre, O. Lopez de Lacalle, and A. Soroa.
2009.Knowledge-based WSD and specific domains: Per-forming over supervised WSD.
In Proceedings of IJ-CAI, Pasadena, USA.John Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In Proceedings of the 2006 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 120?128, Sydney, Australia, July.
As-sociation for Computational Linguistics.Yee Seng Chan and Hwee Tou Ng.
2007.
Domain adap-tation with active learning for word sense disambigua-tion.
In Proceedings of the 45th Annual Meeting ofthe Association of Computational Linguistics, pages49?56, Prague, Czech Republic, June.
Association forComputational Linguistics.Ciprian Chelba and Alex Acero.
2004.
Adaptation ofmaximum entropy classifier: Little data can help alot.
In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing (EMNLP),Barcelona, Spain.6http://semeval2.fbk.eu/7http://xmlgroup.iit.cnr.it/SemEval2010/8http://groups.google.com/groups/wsd-domain127Hal Daume?
III and Daniel Marcu.
2006.
Domain adap-tation for statistical classifiers.
Journal of ArtificialIntelligence Research, 26:101?126.Hal Daume?
III.
2007.
Frustratingly easy domain adapta-tion.
In Proceedings of the 45th Annual Meeting ofthe Association of Computational Linguistics, pages256?263, Prague, Czech Republic, June.
Associationfor Computational Linguistics.Gerard Escudero, Lluiz Ma?rquez, and German Rigau.2000.
An Empirical Study of the Domain Dependenceof Supervised Word Sense Disambiguation Systems.Proceedings of the joint SIGDAT Conference on Em-pirical Methods in Natural Language Processing andVery Large Corpora, EMNLP/VLC.C.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
MIT Press.A.
Kilgarriff.
2001.
English Lexical Sample Task De-scription.
In Proceedings of the Second InternationalWorkshop on evaluating Word Sense DisambiguationSystems, Toulouse, France.R.
Koeling, D. McCarthy, and J. Carroll.
2005.
Domain-specific sense distributions and predominant senseacquisition.
In Proceedings of the Human Lan-guage Technology Conference and Conference onEmpirical Methods in Natural Language Processing.HLT/EMNLP, pages 419?426, Ann Arbor, Michigan.G.
Leech.
1992.
100 million words of English:the British National Corpus.
Language Research,28(1):1?13.David Mart?
?nez and Eneko Agirre.
2000.
One Sense perCollocation and Genre/Topic Variations.
Conferenceon Empirical Method in Natural Language.R.
Mihalcea, T. Chklovski, and Adam Killgariff.
2004.The Senseval-3 English lexical sample task.
In Pro-ceedings of the 3rd ACL workshop on the Evaluationof Systems for the Semantic Analysis of Text (SENSE-VAL), Barcelona, Spain.G.A.
Miller, C. Leacock, R. Tengi, and R.Bunker.
1993.A Semantic Concordance.
In Proceedings of theARPA Human Language Technology Workshop.
Dis-tributed as Human Language Technology by San Ma-teo, CA: Morgan Kaufmann Publishers., pages 303?308, Princeton, NJ.Hwee Tou Ng and Hian Beng Lee.
1996.
Integrat-ing multiple knowledge sources to disambiguate wordsense: An exemplar-based approach.
In Proceedingsof the 34th Annual Meeting of the Association forComputationla Linguistics (ACL), pages 40?47.Nicoletta Calzolari Christiane Fellbaum Shu-kai HsiehChu-Ren Huang Hitoshi Isahara Kyoko Kanzaki An-drea Marchetti Monica Monachini Federico NeriRemo Raffaelli German Rigau Maurizio TesconPiek Vossen, Eneko Agirre and Joop VanGent.
2008.Kyoto: a system for mining, structuring and distribut-ing knowledge across languages and cultures.
InEuropean Language Resources Association (ELRA),editor, Proceedings of the Sixth International Lan-guage Resources and Evaluation (LREC?08), Mar-rakech, Morocco, may.Sameer Pradhan, Edward Loper, Dmitriy Dligach, andMartha Palmer.
2007.
Semeval-2007 task-17: Englishlexical sample, srl and all words.
In Proceedings ofthe Fourth International Workshop on Semantic Eval-uations (SemEval-2007), pages 87?92, Prague, CzechRepublic.Tony G. Rose, Mark Stevenson, and Miles Whitehead.2002.
The Reuters Corpus Volumen 1: from Yes-terday?s News to Tomorrow?s Language Resources.In Proceedings of the Third International Conferenceon Language Resources and Evaluation (LREC-2002),pages 827?832, Las Palmas, Canary Islands.Marc Weeber, James G. Mork, and Alan R. Aronson.2001.
Developing a test collection for biomedicalword sense disambiguation.
In Proceedings of theAMAI Symposium, pages 746?750, Washington, DC.Zhi Zhong, Hwee Tou Ng, and Yee Seng Chan.
2008.Word sense disambiguation using OntoNotes: An em-pirical study.
In Proceedings of the 2008 Conferenceon Empirical Methods in Natural Language Process-ing, pages 1002?1010, Honolulu, Hawaii, October.Association for Computational Linguistics.128
