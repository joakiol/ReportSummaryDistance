Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 20?21,Vancouver, October 2005.DialogueView: an Annotation Tool for DialogueFan Yang and Peter A. HeemanCenter for Spoken Langauge UnderstandingOGI School of Science & EngineeringOregon Health & Science University20000 NW Walker Rd., Beaverton OR, U.S.A. 97006{fly, heeman}@cslu.ogi.edu1 IntroductionThere is growing interest in collecting and annotating cor-pora of language use.
Annotated corpora are useful forformulating and verifying theories of language interac-tion, and for building statistical models to allow a com-puter to naturally interact with people.A lot of annotation tools have been built or are be-ing built.
CSLU Toolkit (Sutton et al, 1998) and Emu(Cassidy and Harrington, 2001) are built for words tran-scription or speech events (such as accent); DAT is builtfor coding dialogue acts using the DAMSL scheme (Coreand Allen, 1997); Nb is built for annotating hierarchicaldiscourse structure (Flammia, 1998); annotation toolkits,such as Mate (McKelvie et al, 2001), AGTK (Bird et al,2001), and Nite (Carletta et al, 2003), are built for usersto create their own tools.
In this demo, we will present anovel tool, DialogueView, for annotating speech repairs,utterance boundaries, utterance tags, and hierarchical dis-course structure altogether.The annotation tool, DialogueView, consists of threeviews: WordView, UtteranceView, and BlockView.These three views present different abstractions of a di-alogue, which helps users better understand what is hap-pening in the dialogue.
WordView shows the words time-aligned with the audio signal.
UtteranceView shows thedialogue as a sequence of utterances.
It abstracts awayfrom the exact timing of the words and can even skipwords, based on WordView annotations, that do not im-pact the progression of the dialogue.
BlockView showsthe dialogue as a hierarchy of discourse blocks, and ab-stracts away from the exact utterances that were said.
An-notations are done at the view that is most appropriate forwhat is being annotated.
The tool allows users to eas-ily navigate among the three views and it automaticallyupdates all views when changes are made in one view.DialogueView makes use of multiple views to presentdifferent abstractions of a dialogue to users.
Abstractionhelps users focus on what is important for different an-notation tasks.
For example, for annotating speech re-pairs, utterance boundaries, and overlapping and aban-doned utterances, WordView provides the exact timinginformation.
For coding speech act tags and hierarchi-cal discourse structure, UtteranceView shows a broadercontext and hides such low-level details.In this presentation, we will show how DialogueViewhelps users annotate speech repairs, utterance boundaries,utterance tags, and hierarchical discourse blocks.
Re-searchers studying dialogue might want to use this toolfor annotating these aspects of their own dialogues.
Wewill also show how the idea of abstraction in Dialogue-View helps users understand and annotate a dialogue.
Al-though DialogueView focuses on spoken dialogue, wefeel that abstraction can be used in annotating mono-logues, multi-party, and multi-modal interaction, withany type of annotations, such as syntactic structure, se-mantics and co-reference.
Researchers might want toadopt the use of abstraction in their own annotation tools.2 WordViewThe first view is WordView, which takes as input two au-dio files (one for each speaker), the words said by eachspeaker and the start and stop times of each word (inXML format), and shows the words time-aligned with theaudio signal.
This view is ideal for seeing the exact tim-ing of speech, especially overlapping speech.
Users canannotate speech repairs, utterance boundaries, and utter-ance tags in WordView.WordView gives users the ability to select a region ofthe dialogue and to play it.
Users can play each speakerchannel individually or both combined.
Furthermore, Di-alogueView allows users to aurally verify their speech re-pair annotations.
WordView supports playing a regionof speech but with the annotated reparanda and editingterms skipped over.
We have found this useful in decid-ing whether a speech repair is correctly annotated.
If onehas annotated the repair correctly, the edited speech willsound fairly natural.3 UtteranceViewThe annotations in WordView are utilized in building thenext view, UtteranceView.
This view shows the utter-ances of two speakers as if it were a script for a movie.To derive a single ordering of the utterances of the two20speakers, we use the start time of each utterance as anno-tated in WordView.
We refer to this process as linearizingthe dialogue (Heeman and Allen, 1995).
The order of theutterances should show how the speakers are sequentiallyadding to the dialogue, and is our motivation for defin-ing utterances as being small enough so that they are notaffected by subsequent speech of the other speaker.Users can annotate utterance tags in UtteranceView be-sides WordView.
WordView is more suitable for tags thatdepend on the exact timing of the words, or a very lo-cal context, such as whether an utterance is abandonedor incomplete, or whether there is overlap speech.
Utter-anceView is more suitable for tags that relate the utter-ance to other utterances in the dialogue, such as whetheran utterance is an answer, a statement, a question, or anacknowledgment.
Whether an annotation tag can be usedin WordView or UtteranceView (or both) is specified inthe configuration file.
Which view a tag is used in doesnot affect how it is stored in the annotation files (also inXML format).In UtteranceView, users can annotate hierarchicalgroupings of utterances.
We call each grouping a block,and blocks can have other blocks embedded inside ofthem.
Each block is associated with a summary, whichusers need to fill in.
Blocks can be closed; when a block isclosed, it is replaced by its summary, which is displayedas if it were said by the speaker who initiated the block.Just as utterances can be tagged, so can discourse blocks.The block tags scheme is also specified in the configura-tion file.UtteranceView supports two types of playback.
Thefirst playback simply plays both channels mixed, which isexactly what is recorded.
The second playback is slightlydifferent.
It takes the linearization into account and dy-namically builds an audio file in which each utterancein turn is concatenated together, and a 0.5 second pauseis inserted between each utterance.
This gives the useran idealized rendition of the utterances, with overlappingspeech separated.
By comparing these two types of play-backs, users can aurally check if their linearization of thedialogue is correct.Users can use the configuration file to customize Utter-anceView.
Typically, UtteranceView gives users a cleandisplay of what is going on in a dialogue.
This cleandisplay removes reparanda and editing terms in speechrepairs, and it also removes abandoned speech, whichhas no contributions to the conversation.1 UtteranceViewalso supports adding texts or symbols to an utterancebased on the tags, such as adding ???
after a question,?...?
after an incomplete utterance, and ?+?
at both thebeginning and end of an overlapping utterance to signalthe overlap.
(c.f.
Childes scheme (MacWhinney, 2000)).1Note that these clean processes are optional.
Users canspecify them in the configuration file.4 BlockViewIn addition to WordView and UtteranceView, we are ex-perimenting with a third view, which we call BlockView.This view shows the hierarchical structure of the dis-course by displaying the summary and intention (DSP)for each block, indented appropriately.
BlockView givesa very concise view of the dialogue.
It is also convenientfor navigating in the dialogue.
By highlighting a line andthen pressing Sync, the user can see the correspondingpart of the dialogue in UtteranceView and WordView.5 AvailabilityDialogueView is written in Incr Tcl/Tk.
We also use thesnack package for audio support; hence DialogueViewsupports audio file formats of WAV, MP3, AU, and oth-ers (see http://www.speech.kth.se/snack/ for the completelist).
DialogueView has been tested on Microsoft Win-dows (2000 and XP) and Redhat Enterprise Linux.DialogueView is freely available for research andeducational use.
Users should first install a stan-dard distribution of Tcl/Tk, such as ActiveTcl fromhttp://www.tcl.tk, and then download DialogueView fromhttp://www.cslu.ogi.edu/DialogueView.
The distributionalso includes some examples of annotated dialogues.ReferencesSteven Bird et al 2001.
Annotation tools based on the anno-tation graph API.
In Proceedings of ACL/EACL 2001 Work-shop on Sharing Tools and Resources for Research and Edu-cation.Jean Carletta et al 2003.
The NITE XML toolkit: flexible an-notation for multi-modal language data.
Behavior ResearchMethods, Instruments, and Computers, April.
Special Issueon Measuring Behavior.Steve Cassidy and Jonathan Harrington.
2001.
Multi-level an-notation in the Emu speech database management system.Speech Communication, 33:61?77.Mark G. Core and James F. Allen.
1997.
Coding dialogues withthe DAMSL annotation scheme.
In Proceedings of AAAI Fall1997 Symposium.Giovanni Flammia.
1998.
Discourse Segmentation Of Spo-ken Dialogue: An Empirical Approach.
Ph.D. thesis, Mas-sachusetts Institute of Technology.Peter A. Heeman and James Allen.
1995.
Dialogue transcrip-tion tools.
Trains Technical Note 94-1, URCS, March.Brian MacWhinney.
2000.
The CHILDES Project: Tools forAnalyzing Talk.
Mahwah, NJ:Lawrence Erlbaum Associates,third edition.D.
McKelvie, et al 2001.
The MATE Workbench - An anno-tation tool for XML coded speech corpora.
Speech Commu-nication, 33(1-2):97?112.
Special issue, ?speech Annotationand Corpus Tools?.Stephen Sutton et al.
1998.
Universal speech tools: The CSLUtoolkit.
In Proceedings of 5th ICSLP, Australia.21
