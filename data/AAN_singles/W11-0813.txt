Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pages 83?91,Portland, Oregon, USA, 23 June 2011. c?2011 Association for Computational LinguisticsAn N-gram frequency database reference to handle MWE extraction in NLPapplicationsPatrick WatrinCentre for Natural Language ProcessingInstitut Langage et CommunicationUCLouvainpatrick.watrin@uclouvain.beThomas Fran?oisAspirant F.N.R.S.Centre for Natural Language ProcessingInstitut Langage et CommunicationUCLouvainthomas.francois@uclouvain.beAbstractThe identification and extraction of MultiwordExpressions (MWEs) currently deliver satis-factory results.
However, the integration ofthese results into a wider application remainsan issue.
This is mainly due to the fact thatthe association measures (AMs) used to detectMWEs require a critical amount of data andthat the MWE dictionaries cannot account forall the lexical and syntactic variations inherentin MWEs.
In this study, we use an alterna-tive technique to overcome these limitations.
Itconsists in defining an n-gram frequency data-base that can be used to compute AMs on-the-fly, allowing the extraction procedure to effi-ciently process all the MWEs in a text, even ifthey have not been previously observed.1 IntroductionMultiword Expressions (MWEs) are commonlydefined as ?recurrent combinations of words thatco-occur more often than expected by chance andthat correspond to arbitrary word usages?
(Smadja,1993, 143).
Their importance in the field of natu-ral language processing (NLP) is undeniable.
Al-though composed of several words, these sequencesare nonetheless considered as simple units with re-gard to part-of-speech at the lexical as well as syn-tactic levels.
Their identification is therefore essen-tial to the efficiency of applications such as parsing(Nivre and Nilsson, 2004), machine translation (Renet al, 2009), information extraction, or informationretrieval (Vechtomova, 2005).
In these systems, theprinciple of syntactic or semantic/informational unitis particularly important.Although the identification and extraction ofMWEs now deliver satisfactory results (Evert andKrenn, 2001; Pearce, 2002), their integration intoa broader applicative context remains problematic(Sag et al, 2001).
The explanations for this situationare twofold.1.
The most effective extraction methods resortto statistical association measures based on thefrequency of lexical structures.
They, therefore,require a critical amount of data and cannotfunction properly from a simple phrase or evenfrom a short text.2.
Since the syntactic and lexical variability ofMWEs may be high, lexical resources learnedfrom a corpus cannot take it into account.
Thecoverage of these resources is indeed too limi-ted when applied to a new text.To address these two limitations, this article des-cribes how an n-gram frequency database can beused to compute association measures (AMs) effi-ciently, even for small texts.
The specificity of thisnew technique is that AMs are computed on-the-fly,freeing it from the coverage limitation that afflictsmore simple techniques based on a dictionary.We start off focussing on our extraction method,and more particularly on the process via which acandidate structure is statistically validated (Section2).
This presentation principally aims to identifythe precise needs of a frequency database reference,both in terms of the interrogation process and in thetype of information to be kept in the database.
Then,we will address various issues of storage and queryperformance raised by the design of the frequency83database (Section 3).
Finally, Section 4 reports theresults of our experiments and Section 5 concludesand open up future perspectives.2 Extraction processOur extraction procedure is comparable to thosedeveloped by Smadja (1993) and Daille (1995).They use a linguistic filter upstream of the statisti-cal estimation.
Unlike purely statistical techniques,this solution provides less coverage but greater ac-curacy.
It also allows us to assign a unique morpho-syntactic category to each extracted unit (as well asa description of its internal structure), which facili-tates its integration into a more complex procedure.Concretely, we first tagged the texts to clear anylexical ambiguities 1.
We then identified all MWEcandidates in the tagged text with the help of a li-brary of transducers 2 (or syntactic patterns).
Finally,the list of candidates was submitted to the statisticalvalidation module which assigns an AM to each ofthese.2.1 Linguistic filtersIn this study, we consider four basic types ofnominal structures 3 : adjective-noun (AN), noun-adjective (NA), noun-preposition-noun (N prepN),and noun-noun (NN), which are likely to undergothree types of variations : modification (mainly ad-verbial insertion and / or adjectival), coordination,and juxtaposition (e.g.
N prepN prepN, N prepNN,etc).
This enables us to identify a wide variety ofsequences that are labelled by XML tags which spe-cify :?
the lexical heads of the various components ;?
the adjectival and prepositional dependencies ;?
any possible coordination.This information can be exploited later to carry outthe syntactic decomposition of the extracted struc-tures and also to limit the statistical validation to thecontent words of each structure.1.
The tagging is done with the TreeTagger (Schmid, 1994).2.
To apply our transducers to the tagged text, we use Unitex(Paumier, 2003).
The output of the process is a file containingonly the recognized sequences.3.
As we work in the field of indexation, we limit our ex-traction to nominal terms.2.2 Statistical validationAssociation measures are conventionally usedto automatically determine whether an extractedphrase is an MWE or not.
They are mathematicalfunctions that aim to capture the degree of cohesionor association between the constituents.
The mostfrequently used measures are the log-likelihood ratio(Dunning, 1993), the mutual information (Churchand Hanks, 1990) or the ?2 (Church and Gale, 1991),although up to 82 measures have been considered byPecina and Schlesinger (2006).
In this paper, we didnot aim to compare AMs, but simply to select someeffective ones in order to evaluate the relevance of areference for MWE extraction.However, association measures present two mainshortcomings that were troublesome for us : they aredesigned for bigrams, although longer MWEs arequite frequent in any corpus 4, and they require thedefinition of a threshold above which an extractedphrase is considered as an MWE.
The first aspect isvery limiting when dealing with real data where lon-ger units are common.
The second may be dealt withsome experimental process to obtain the optimal va-lue for a given dataset, but is prone to generalizationproblems.
In the next two sections, we present thestrategies we have used to overcome these two limi-tations.2.2.1 Beyond bigramsA common way to go beyond the bigram limita-tion is to compute the AMs at the bigram level andthen use the results as input for the computation ofhigher order AMs (Seretan et al, 2003).
However,our preliminary experimentations have yielded un-satisfactory results for this technique when it is ap-plied to all words and not to heads only.
This is pro-bably a side effect of high frequency bigrams suchas preposition-determiner (prep det) in French.Another strategy explored by Silva andLopes (1999) is the fair dispersion point normaliza-tion.
For a given n-gram, which has n?1 dispersionpoints that define n ?
1 "pseudo-bigrams", theycompute the arithmetic mean of the probabilities ofthe various combinations rather than attempting topick up the right point.
This technique enables the4.
In our test corpus (see Section 4), 2044 MWEs out of3714 are longer than the bigrams.84authors to generalize various conventional measuresbeyond the bigram level.
Among these, we selectedthe fair log-likelihood ratio as the second AM forour experiments (see Equation 1), given that theclassic log-likelihood ratio has been found to beone of the best measures (Dunning, 1993; Evert andKrenn, 2001).LogLik f (w1 ?
?
?wn) = 2?
logL(p f 1,k f 1,n f 1)+ logL(p f 2,k f 2,n f 2)?
logL(p f ,k f 1,n f 1)?
logL(p f ,k f 2,n f 2) (1)wherek f 1 = f (w1 ?
?
?wn) n f 1 = Avyk f 2 = Avx?
k f 1 n f 2 = N ?n f 1Avx = 1n?1i=n?1?i=1f (w1 ?
?
?wi)Avy = 1n?1i=n?i=2f (wi ?
?
?wn)p f = k f 1+k f 2N p f 1 = k f 1n f 1 p f 2 = k f 2n f 2and N is the number of n-grams in the corpus.Silva and Lopes (1999) also suggested an AM oftheir own : the Symmetrical Conditional Probabi-lity, which corresponds to P(w1|w2)P(w2|w1) for abigram.
They defined the fair dispersion point nor-malization to extend it to larger n-grams, as shownin Equation 2.SCPf ([w1 ?
?
?wn]) =p(w1 ?
?
?wn)2Avp(2)where w1 ?
?
?wn is the n-gram considered and Avp isdefined as follows :Avp = 1n?1i=n?1?i=1p(w1 ?
?
?wi)?
p(wi+1 ?
?
?wn) (3)Finally, we considered a last AM : the Mutual Ex-pectation (Dias et al, 1999) (see Equation 4).
Itsspecificity lies in its ability to take into account non-contiguous MWEs such as ?to take __ decision?
or?a __ number of?, which can also be realized usingthe heads (see above).ME(w1 ?
?
?wn) =f (w1 ?
?
?wn)?
p(w1 ?
?
?wn)FPE(4)where FPE is defined as follows :FPE = 1n[p(w2 ?
?
?wn)+n?i=2p(w1 ?
?
?
w?i ?
?
?wn)] (5)It should be noted that the expression w1 ?
?
?
w?i ?
?
?wn,where the ?
indicates an omitted term, represents allthe n (n-1)-grams the candidate MWE comprises.FPE is then able to estimate the ?glue?
betweenall the constituents separated by a gap, but this ne-vertheless requires a more complex string matchingprocess.To summarize, we have selected the three follo-wing association measures for n-grams : the fair log-likelihood ratio, SCPf , and ME.
Their efficiency isfurther discussed in Section 4.2.2.2 Selection of MWEsThe second problem that arises when one wants tolocate all the MWEs in a given text is the classifica-tion criterion.
For the log-likelihood ratio, which fol-lows a chi-square distribution once it is transformedas ?2?
log?, a first solution is to base the decisionon the p-value.
However, significance tests becomehighly unreliable for large corpora, since the highfrequencies produce high scores for the chi-squareand all phenomena then appear significant (Kilgar-riff, 2005).A second technique commonly used in the MWEliterature is to select a threshold for the AM abovewhich an analyzed phrase is considered as an MWE.Again, this threshold depends on the size of the cor-pus used and cannot be fixed once and for all fora specific AM.
It must be obtained empirically foreach application of an MWE extractor to a new textor to a new domain.
In order not to resort to a thres-hold, (Silva et al, 1999) suggested the LocalMax al-gorithm that selects MWEs whose AMs are higherthan those of their neighborhood.
In other words, agiven unit is classified as an MWE if g(w1 ?
?
?wn),the associative function, is a local maximum.In our case, since the notion of reference impliesa large corpus and high frequencies, we rejectedthe first of these three approaches.
We experimen-ted with the second and third and show in Section 5how the use of a reference could partially solve thethreshold issues.853 Reference BuildingThe integration of MWEs in an NLP system isusually done via a dictionary.
MWEs are then re-garded as a sequence of simple words separated byspaces (Sag et al, 2001).
As a result, their lexicaland syntactic structure is fixed and cannot be usedto take into account variation at this level.Several methods have been proposed to overcomethis limitation.
Nerima et al (2006) and Sag etal.
(2001) associate each MWE with a feature struc-ture specifying the nature of units and the type offixedness.
This approach requires a manual valida-tion of the features when inserting them into thedictionary.
Watrin (2007) considers a simpler tech-nique that consists in identifying, for each type ofstructure, all the possible insertion points and spe-cifying the lexical and syntactic nature of possiblemodifiers.
In this case, each MWE takes the form ofa regular expression formalizing all possible varia-tions from the canonical form.Both solutions enable to consider more MWEsbut fail to express all possible variations.
For ins-tance, phenomena such as coordination or juxta-position do not seem to be taken into account bythe authors mentioned above including Nerima etal.
(2006).
Moreover, they limit lexical variations toa finite set of canonical structures that have been en-countered and are therefore unable to recognize newcandidates.The notion of reference which we define in thisarticle aims to overcome these two limitations.
Ra-ther than providing a list of MWEs that are pre-computed on a corpus, we suggest storing the in-formation needed to calculate various AMs withina database.
Hence, we no longer restrict MWEs toa finite set of lexical entries but allow the on-the-flycomputation of AMs for any MWE candidate, wha-tever the size of the input text.3.1 Implementation detailsFrom a computational point of view, this idea in-volves the compression of a large number of lexi-cal structures of order N as well as their absolutefrequency.
Moreover, the calculation of the variousAMs considered in this study also requires the fre-quencies of all structures of order n, strictly lowerthan N (0 < n < N).
The second type of informa-tion can however be inferred from the frequency ofthe structures of order N, provided the storage andquestioning system is efficient enough for real-timeapplications.
The need for efficiency also applies toqueries related to the ME measure or the LocalMaxalgorithm that partly involve the use of wildcards.This type of search tool can be efficiently im-plemented with a PATRICIA tree (Morrison, 1968).This data structure enables the compression of n-grams that share a common prefix and of the nodesthat have only one child.
The latter compression iseven more effective as most of the n-grams have aunique suffix (Sekine, 2008).
Beyond the compres-sion that this structure allows, it also guarantees avery fast access to data insofar as a query is a simpletree traversal that can be done in constant time.In order to further optimize the final data struc-ture, we store the vocabulary in a table and associatean integer as a unique identifier for every word.
Inthis way, we avoid the word repetition (whose sizein memory far exceeds that of an integer) in the tree.Moreover, this technique also enables to speed upthe query mechanism, since the keys are smaller.We derived two different implementations of thisstructure.
The first stores the data directly in me-mory.
While it enables easy access to data, the num-ber of n-grams that can be stored is limited by thecapacity of the RAM.
Therefore, in order to take ahuge number of n-grams into account, we also im-plemented a ?disk?
version of the tree.Finally, in order to treat wildcard queries nee-ded by the ME and the LocalMax, we enhanced ourstructure with a set of indexes to improve access toeach word, whatever its depth within the tree.
Ob-viously, this mechanism might not be robust enoughfor a system multiplying the number of wildcards,but it is perfectly suited to the needs of an MWEsextraction process.3.2 References usedOnce the computational aspects of reference buil-ding have been dealt with, a corpus from which topopulate the database needs to be selected.
This as-pect raises two issues : the size and the nature of thecorpus used.
Dunning (1993) has demonstrated thatthe size of the corpus from which MWEs are extrac-ted matters.
On the other hand, common characteris-tics of a corpus, such as its register, the contempora-86Reference # 5-Grams # Nodes500 K 500,648 600,5361000 K 1,001,080 1,183,3465000 K 5,004,987 5,588,793Google 1,117,140,444 62,159,203TABLE 1: Number of 5-grams and nodes in the referencesusedneity of its language or the nature of the topics co-vered, may impact the performances of a referencewhen used on a text with different characteristics.Given these issues, four corpora were selected (cf.Table 1).
The first three are made up of articles pu-blished in the Belgian daily newspaper Le Soir in2009, with 500K, 1000K and 5000K words respec-tively.
They share many characteristics with our testcorpus.
The last corpus is made up of the largestamount of n-grams publicly available for French :the Google 5-grams 5 (Michel et al, 2011).
Its sizereaches 1T words 6, and its coverage in terms of to-pic and register is supposedly wider than corpora ofnewspaper articles only.
In a sense, the Google re-ference may be viewed as an attempt to a universalreference.4 EvaluationMost evaluations of MWE extraction systems arebased on human judgments and restrict the valida-tion process to the n-best candidates.
Inevitably par-tial, this method is unable to estimate performancein terms of recall.
To overcome these limitations,we use the evaluation method described by Evertand Krenn (2001).
They propose an automatic me-thod that consists in computing both recall and pre-cision using various n-best samples.
It involves theformation of a golden standard (i.e.
a list of MWEsmanually identified in a corpus) and a sorted list ofMWEs extracted automatically by applying AM onthe same corpus.
The recall and precision rates aretherefore calculated by comparing the n-best (wheren increases from 0 till n in steps of x) to the golden5.
For the purposes of comparison, we also limited the sizeof the n-grams indexed in Le Soir to 5 words.6.
In order to model a contemporary language, we only keptthe frequencies observed in texts written between 2000 and2008.standard list 7.4.1 The test corpusIn this study, we use the corpus described in La-porte et al (2006).
It is a French corpus in which allMWEs have been manually annotated.
It consists oftwo sub-corpora :?
the transcription, in a written style, of the Oc-tober 3rd and 4th, 2006 meetings of the FrenchNational Assembly (FNA), and?
the complete text of Jules Verne?s novel"Around the World in 80 Days", published in1873 (JV).These two sub-corpora respectively contain 98,969and 69,877 words for a total of 3,951 and 1,103MWEs 8.
We limit our evaluation to the FNA cor-pus in order to keep data consistent both in termsof register and time.
We assume that these two va-riables have a direct impact on the use of MWEs, ahypothesis that seems to be confirmed by the rate ofMWEs in both sub-corpora.4.2 Extractor ParametersBefore evaluating the performance of each of theabove mentioned references, we first assessed the in-fluence of the various parameters involved in the ex-traction process and which affect the performanceof the AMs.
These parameters are the LocalMax,the smoothing technique, the lemmatization of theMWE constituents (LEMMA) 9 and the head-drivenvalidation (HDV) 10.
To select the optimal parame-ters for our extractor, we established an additionalreference (1000K words from Le Soir).7.
We build these lists from MWE types to avoid introdu-cing a bias in the evaluation process.
Well-recognised high fre-quency MWEs might indeed gloss over poorly recognised low-frequency MWEs.8.
These occurrences correspond to 1,384 MWE types forthe FNA corpus and 521 for the JV corpus.9.
The lemmatization of the MWE constituents is based onthe assumption that the inflexion of the lemmas implies a dis-persal of the frequency mass (the overall frequency of a lemmais split between its inflected forms) that may affect the behaviorof the AMs.10.
The HDV aims to focus on the lexical heads of the MWEcandidates.
Therefore, function words (prepositions, conjunc-tions, etc.)
are ignored and replaced by wildcards in the queriessent to the reference in order to keep the distance information.For instance, from the sequence ministre de l?agriculture (Mi-nister for Agriculture), we derive the form ministre * * agricul-ture.8710203040506070800  10  20  30  40  50  60  70  80  90  100Precision(%)MWE (%)Measures -- PrecisionFair Log-LikelihoodMutual ExpectationSymmetric Conditional Probability01020304050600  10  20  30  40  50  60  70  80  90  100Recall (%)MWE (%)Measures -- RecallFair Log-LikelihoodMutual ExpectationSymmetric Conditional ProbabilityFIGURE 1: Evaluation of AMsThe first step of this selection procedure was todefine a baseline.
For this purpose, we comparedthe precision and recall rates of our three AMs (seeFigure 1) and kept only the best, namely the log-likelihood ratio, for the rest of our experiments.While the ME provides better precision for the topfive percent of the extracted units, the log-likelihoodratio appears more reliable in that it maintains itsefficiency over time (for recall as well as precision).The SCP, for its part, displays more stable results butdoes not reach sufficient precision.On the basis of this baseline, we then separatelycompared the contribution of each of the four para-meters.
Results are reported in Figure 2 and detailedin the following subsections.4.2.1 The LocalMaxFigure 2 shows that the LocalMax significantlyimproves the precision of the extraction.
It emergesas the most relevant parameter at this level.
Howe-102030405060700  10  20  30  40  50  60  70  80  90  100Precision(%)MWE (%)Parameters -- PrecisionLemmatizationAdd Text SmoothingLocalMaxHeadBaseline01020304050600  10  20  30  40  50  60  70  80  90  100Recall (%)MWE (%)Parameters -- RecallLemmatizationAdd Text SmoothingLocalMaxHeadBaselineFIGURE 2: Evaluation of the parametersver, unlike other parameters, its application directlyaffects the recall that falls below our baseline.
Thismay not be a problem for certain applications.
In ourcase, we aim to index and classify documents.
The-refore, while we can accommodate a lower preci-sion, we cannot entirely neglect the recall.
We thusabandoned this parameter which, moreover, indubi-tably increases the processing time in that it requiresthe use of approximate matching (see Section 3.1).4.2.2 The Add-text smoothingSmoothing is another aspect worthy of considera-tion.
No matter how large the reference used is, itwill never constitute more than a subset of the lan-guage.
Therefore, it is necessary to find a solutionto estimate the frequency of unobserved n-grams.For the baseline, we used a simple "add-one?
(orLaplace) smoothing (Manning and Sch?tze, 1999)which presents a severe flaw when the size of the n-grams to smooth increases : the normalization pro-88cess discounts too much probability mass from ob-served events.We therefore compare this simple method withanother one we consider more ?natural?
: the ?add-text?
smoothing that adds the text to process to thereference.
We view this method as more natural tothe extent that it simulates a standard MWE extrac-tion process.
In this case, the reference complementsthe frequency universe of the input corpus as if it for-med a homogeneous whole.
Figure 2 demonstrates aclear superiority of the second smoothing procedureover the first one which was therefore discarded.4.2.3 Lemmatization and HDVThe lemmatization and HDV follow a similarcurve with regard to precision, although HDV is bet-ter for recall.
Nonetheless, this difference only ap-pears when precision falls below 35%.
This doesnot seem sufficient to reject the lemmatization pro-cess whose computation time is significantly lowerthan for the HDV.
We therefore limit the use of thislast parameter to the reference built from Googlewhose n-grams cannot be lemmatized due to lack ofcontext.
114.3 Evaluation of the referencesThe estimation of the parameters allowed us to es-tablish a specific evaluation framework.
Two sets ofparameters were defined depending on whether theyapply to Google (ATS + HDV) or to the referencesbuilt from Le Soir (ATS + LEMMA).
From a prac-tical standpoint, we limited the MWE extraction tonominal units of size inferior to five in order to meetthe characteristics of our test corpus (the annotationsof which are limited to nominal sequences), on theone hand, and to allow comparability of results onthe other hand (the n-grams from Google do not ex-ceed the order 5).Initially, we considered the extraction of MWEsin the whole evaluation corpus.
Results displayed inFigure 3 provide an advantage over the use of a refe-rence with respect to the extraction carried out on thetest corpus only.
In addition, we see a clear improve-ment in performance with respect to that obtainablewith a dictionary of MWEs.
1211.
References constructed on the basis of the newspaper LeSoir have been reindexed from a lemmatized text.12.
The MWE dictionary used in this experiment was ini-010203040506070800  10  20  30  40  50  60  70  80  90  100Precision(%)MWE (%)References -- Precision500K Words1000K Words5000K WordsGoogle (1T Words)Text Only (3K)External Dictionary01020304050600  10  20  30  40  50  60  70  80  90  100Recall (%)MWE (%)References -- Recall500K Words1000K Words5000K WordsGoogle (1T Words)Text Only (3K)External DictionaryFIGURE 3: Evaluation on the 100K CorpusIn a second step, we wanted to test the efficiencyof our references in the more adverse context of ashort text.
We randomly selected 3K words of ourtest corpus to simulate a short text while maintai-ning a sufficient number of MWEs (i.e.
151 nominalMWEs).
Results shown in Figure 4 further confirmour first experience and validate our concept of a re-ference in a real application context.Beyond validating the use of a frequency base,these results also confirm the general idea that thesize of the corpus used for the reference matters.
Thedifferences between the references of 500K, 1000Kand 5000K words showed a continuous improve-ment both in precision and recall.
The results obtai-ned with the Google reference are more surprising,since they do not meet that growing trend.
Howe-ver, given the number of errors that those n-gramscontain (mainly due to the OCR-ization and tokeni-tially derived from the corpus of 5000K words used to build thecorresponding reference.8901020304050607080901000  10  20  30  40  50  60  70  80  90  100Precision(%)MWE (%)References (3K) -- Precision500K Words1000K Words5000K WordsGoogle (1T Words)Text Only (3K)External Dictionary01020304050600  10  20  30  40  50  60  70  80  90  100Recall (%)MWE (%)References (3K) -- Recall500K Words1000K Words5000K WordsGoogle (1T Words)Text Only (3K)External DictionaryFIGURE 4: Evaluation on the 3K Corpuszation processes), the result remains satisfactory.
Iteven confirms to some extent the importance of sizein the sense that preprocessing errors are being miti-gated by the global mass of the frequencies.5 Conclusion and perspectivesIn this paper, we presented an MWE extractionsystem based on the use of frequency references.
Wehave shown that its use enables MWE extraction onshort texts with performances that are at least com-parable to those achieved by standard solutions andfar superior to solutions based on the use of MWEdictionaries.Moreover, as this system has been integrated wi-thin an indexing engine, various issues were rai-sed, some of which constitute avenues for future re-search.
First, since our indexer aims at the identifi-cation of entities and terms specific to a given spe-cialty area, the question of data representativenessis of particular importance.
It is not clear to whatMWE 500 K 1000 K 5000 K Googlem?megroupe0.73 1.44 3.85 1,746.03nouveauxinstruments3.81 3.3 49.83 2,793.65lettres denoblesse33.99 52.43 232.51 27,202.17TABLE 2: Examples of MWEs candidates whose log-likelihood ratio is not significant on a small corpus andbecomes extremely significant on a large corpus.
Theyare compared to the score of an actual MWE.extent a given reference can be applied to varioustypes of texts.
We only noticed that the Google refe-rence, whose features were less similar to the testcorpus, nevertheless yielded satisfactory results incomparison with our other references that better fit-ted the test corpus features.In addition, our results show that the threshold is-sue remains relevant.
Although the LocalMax seemsto allow better discrimination of the MWE candi-dates, it is not selective enough to keep only the ac-tual MWEs.
On the other hand, as the size of thereferences increases, some results of the AMs basedon the log-likelihood ratio reach high values that canno longer be interpreted by a chi-square significancetest (see Table 2).We believe that our references offer an interes-ting perspective to face this problem.
The stability oftheir frequencies makes it possible to define a thre-shold corresponding to a specific percentage of pre-cision and recall (set according to the needs of a gi-ven application).
Therefore, as long as the size ofthe analyzed texts remains limited ?
which can becontrolled ?, the efficiency of this threshold shouldremain constant.
Further experimentations on thisaspect are however required to determine to whatextent this assumption stands true as the size of theanalyzed texts grows.ReferencesK.W.
Church and W.A.
Gale.
1991.
Concordances forparallel text.
In Proceedings of the Seventh AnnualConference of the UW Centre for the New OED andText Research, pages 40?62.K.W.
Church and P. Hanks.
1990.
Word associationnorms, mutual information, and lexicography.
Com-putational linguistics, 16(1) :22?29.90J.
da Silva and G.P.
Lopes.
1999.
A local maxima me-thod and a fair dispersion normalization for extractingmulti-word units from corpora.
In Sixth Meeting onMathematics of Language.B.
Daille.
1995.
Combined approach for terminologyextraction : lexical statistics and linguistic filtering.Technical report, Lancaster University.G.
Dias, S.
Guillor?, and J.G.P.
Lopes.
1999.
Languageindependent automatic acquisition of rigid multiwordunits from unrestricted text corpora.
Proceedings ofthe 6th Conference on the Traitement Automatique desLangues Naturelles (TALN1999), pages 333?339.T.
Dunning.
1993.
Accurate methods for the statistics ofsurprise and coincidence.
Computational linguistics,19(1) :61?74.S.
Evert and B. Krenn.
2001.
Methods for the qualitativeevaluation of lexical association measures.
In Procee-dings of the 39th Annual Meeting on Association forComputational Linguistics, pages 188?195.A.
Kilgarriff.
2005.
Language is never ever ever random.Corpus linguistics and linguistic theory, 1(2) :263?276.E.
Laporte, T. Nakamura, and S. Voyatzi.
2006.
A frenchcorpus annotated for multiword expressions with ad-verbial function.
In Proceedings of the Language Re-sources and Evaluation Conference (LREC) : Linguis-tic Annotation Workshop, pages 48?51.C.D.
Manning and H. Sch?tze, editors.
1999.
Founda-tions of Statistical Natural Language Processing.
MITPress.J.B.
Michel, Y.K.
Shen, A.P.
Aiden, A. Veres, M.K.
Gray,The Google Books Team, J.P. Pickett, D. Hoiberg,D.
Clancy, P. Norvig, J. Orwant, S. Pinker, M.A.
No-wak, and E.L. Aiden.
2011.
Quantitative analysisof culture using millions of digitized books.
Science,331(6014) :176?182.D.R.
Morrison.
1968.
PATRICIA?practical algorithmto retrieve information coded in alphanumeric.
Jour-nal of the ACM, 15(4) :514?534.L.
Nerima, V. Seretan, and E. Wehrli.
2006.
Le pro-bl?me des collocations en TAL.
Nouveaux cahiers delinguistique fran?aise, 27 :95?115.J.
Nivre and J. Nilsson.
2004.
Multiword units in syn-tactic parsing.
In Proceedings of LREC-04 Workshopon Methodologies & Evaluation of Multiword Units inReal-world Applications, pages 37?46.S.
Paumier.
2003.
De la reconnaissance de formes lin-guistiques ?
l?analyse syntaxique.
Ph.D. thesis, Uni-versit?
de Marne-la-Vall?e.D.
Pearce.
2002.
A comparative evaluation of colloca-tion extraction techniques.
In Proc.
of the 3rd Inter-national Conference on Language Resources and Eva-luation (LREC 2002), pages 1530?1536.P.
Pecina and P. Schlesinger.
2006.
Combining associa-tion measures for collocation extraction.
In Procee-dings of the 21th International Conference on Com-putational Linguistics and 44th Annual Meeting ofthe Association for Computational Linguistics (CO-LING/ACL 2006), pages 651?658.Z.
Ren, Y. L, J. Cao, Q. Liu, and Y. Huang.
2009.
Im-proving statistical machine translation using domainbilingual multiword expressions.
In Proceedings ofthe Workshop on Multiword Expressions : Identifica-tion, Interpretation, Disambiguation and Applications,pages 47?54.I.
Sag, T. Baldwin, F. Bond, A. Copestake, and D. Fli-ckinger.
2001.
Multiword expressions : A pain in theneck for NLP.
In In Proc.
of the 3rd InternationalConference on Intelligent Text Processing and Com-putational Linguistics (CICLing-2002), pages 1?15.H.
Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In Proceedings of InternationalConference on New Methods in Language Processing,volume 12.
Manchester, UK.S.
Sekine.
2008.
A linguistic knowledge discovery tool :Very large ngram database search with arbitrary wild-cards.
In COLING : Companion volume : Demonstra-tions, pages 181?184.V.
Seretan, L. Nerima, and E. Wehrli.
2003.
Extrac-tion of Multi-Word Collocations Using Syntactic Bi-gram Composition.
In Proceedings of the 4th In-ternational Conference on Recent Advances in NLP(RANLP2003), pages 424?431.J.
da Silva, G. Dias, S.
Guillor?, and J. Pereira Lopes.1999.
Using localmaxs algorithm for the extractionof contiguous and non-contiguous multiword lexicalunits.
Progress in Artificial Intelligence, pages 849?849.F.
Smadja.
1993.
Retrieving collocations from text :Xtract.
Computational Linguistics, 19 :143?177.O.
Vechtomova.
2005.
The role of multi-word unitsin interactive information retrieval.
In D.E.
Losadaand J.M.
Fern?ndez-Luna, editors, ECIR 2005, LNCS3408, pages 403?420.
Springer-Verlag, Berlin.P.
Watrin.
2007.
Collocations et traitement automatiquedes langues.
In Actes du 26e Colloque internationalsur le lexique et la grammaire, pages 1530?1536.91
