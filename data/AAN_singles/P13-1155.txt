Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1577?1586,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsSocial Text Normalization using Contextual Graph Random WalksHany HassanMicrosoft ResearchRedmond, WAhanyh@microsoft.comArul MenezesMicrosoft ResearchRedmond, WAarulm@microsoft.comAbstractWe introduce a social media text normal-ization system that can be deployed as apreprocessing step for Machine Transla-tion and various NLP applications to han-dle social media text.
The proposed sys-tem is based on unsupervised learning ofthe normalization equivalences from unla-beled text.
The proposed approach usesRandom Walks on a contextual similaritybipartite graph constructed from n-gramsequences on large unlabeled text corpus.We show that the proposed approach has avery high precision of (92.43) and a rea-sonable recall of (56.4).
When used asa preprocessing step for a state-of-the-artmachine translation system, the translationquality on social media text improved by6%.
The proposed approach is domain andlanguage independent and can be deployedas a preprocessing step for any NLP appli-cation to handle social media text.1 IntroductionSocial Media text is usually very noisy and con-tains a lot of typos, ad-hoc abbreviations, pho-netic substitutions, customized abbreviations andslang language.
The social media text is evolvingwith new entities, words and expressions.
Naturallanguage processing and understanding systemssuch as Machine Translation, Information Extrac-tion and Text-to-Speech are usually trained andoptimized for clean data; therefore such systemswould face a challenging problem with social me-dia text.Various social media genres developed distinctcharacteristics.
For example, SMS developed anature of shortening messages to avoid multiplekeystrokes.
On the other hand, Facebook and in-stant messaging developed another genre wheremore emotional expressions and different abbre-viations are very common.
Somewhere in be-tween, Twitter?s statuses come with some brevitysimilar to SMS along with the social aspect ofFacebook.
On the same time, various social me-dia genres share many characteristics and typostyles.
For example, repeating letters or punctu-ation for emphasizing and emotional expressionsuch as ?
?goooood morniiing??.
Using phoneticspelling in a generalized way or to reflect a lo-cal accent; such as ?
?wuz up bro??
(what is upbrother).
Eliminating vowels such as ?
?cm to cmy luv??.
Substituting numbers for letters such as??4get??
(forget) , ??2morrow??
(tomorrow), and??b4??
(before).
Substituting phonetically sim-ilar letters such as ??phone??
(fon).
Slang ab-breviations which usually abbreviates multi-wordexpression such as ??LMS??
(like my status) ,??idk??
(i do not know), ??rofl??
(rolling on floorlaughing).While social media genres share many charac-teristics, they have significant differences as well.It is crucial to have a solution for text normaliza-tion that can adapt to such variations automati-cally.
We propose a text normalization approachusing an unsupervised method to induce normal-ization equivalences from noisy data which canadapt to any genre of social media.In this paper, we focus on providing a solu-tion for social media text normalization as a pre-processing step for NLP applications.
However,this is a challenging problem for several reasons.First, it is not straightforward to define the Out-of-Vocabulary (OOV) words.
Traditionally, an OOVword is defined as a word that does not exist inthe vocabulary of a given system.
However, thisdefinition is not adequate for the social media textwhich has a very dynamic nature.
Many wordsand named entities that do not exist in a given vo-cabulary should not be considered for normaliza-tion.
Second, same OOV word may have many1577appropriate normalization depending on the con-text and on the domain.
Third, text normalizationas a preprocessing step should have very high pre-cision; in other words, it should provide conser-vative and confident normalization and not over-correct.
Moreover, the text normalization shouldhave high recall, as well, to have a good impact onthe NLP applications.In this paper, we introduce a social media textnormalization system which addresses the chal-lenges mentioned above.
The proposed system isbased on constructing a lattice from possible nor-malization candidates and finding the best normal-ization sequence according to an n-gram languagemodel using a Viterbi decoder.
We propose anunsupervised approach to learn the normalizationcandidates from unlabeled text data.
The proposedapproach uses RandomWalks on a contextual sim-ilarity graph constructed form n-gram sequenceson large unlabeled text corpus.
The proposed ap-proach is very scalable, accurate and adaptive toany domain and language.
We evaluate the ap-proach on the normalization task as well as ma-chine translation task.The rest of this paper is organized as follows:Section(2) discusses the related work, Section(3)introduces the text normalization system and thebaseline candidate generators, Section(4) intro-duces the proposed graph-based lexicon inductionapproach, Section(5) discusses the experimentsand output analysis, and finally Section(6) con-cludes and discusses future work.2 Related WorkEarly work handled the text normalization prob-lem as a noisy channel model where the normal-ized words go through a noisy channel to producethe noisy text.
(Brill and Moore, 2000) introducedan approach for modeling the spelling errors asa noisy channel model based on string to stringedits.
Using this model gives significant perfor-mance improvements compared to previously pro-posed models.
(Toutanova and Moore, 2002) im-proved the string to string edits model by mod-eling pronunciation similarities between words.
(Choudhury et al, 2007) introduced a supervisedHMM channel model for text normalization whichhas been expanded by (Cook and Stevenson, 2009)to introduce unsupervised noisy channel modelusing probabilistic models for common abbrevi-ation and various spelling errors types.
Someresearchers used Statistical Machine Translationapproach for text normalization; formalizing theproblem as a translation from the noisy forms tothe normalized forms.
(Aw et al, 2006) proposedan approach for normalizing Short Messaging Ser-vice (SMS) texts by translating it into normal-ized forms using Phrase-based SMT techniques oncharacter level.
The main drawback of these ap-proaches is that the noisy channel model cannotaccurately represent the errors types without con-textual information.More recent approaches tried to handle the textnormalization problem using normalization lexi-cons which map the noisy form of the word to anormalized form.
For example, (Han et al, 2011)proposed an approach using a classifier to identifythe noisy words candidate for normalization; thenusing some rules to generate lexical variants and asmall normalization lexicon.
(Gouws et al, 2011)proposed an approach using an impoverished nor-malization lexicon based on string and distribu-tional similarity along with a dictionary lookupapproach to detect noisy words.
More recently,(Han et al, 2012) introduced a similar approachby generating a normalization lexicon based ondistributional similarity and string similarity.
Thisapproach uses pairwise similarity where any twowords that share the same context are consideredas normalization equivalences.
The pairwise ap-proach has a number of limitations.
First, it doesnot take into account the relative frequencies ofthe normalization equivalences that might sharedifferent contexts.
Therefore, the selection of thenormalization equivalences is performed on pair-wise basis only and is not optimized over thewhole data.
Secondly, the normalization equiva-lences must appear in the exact same context tobe considered as a normalization candidate.
Theselimitations affect the accuracy and the coverage ofthe produced lexicon.Our approach also adopts a lexicon based ap-proach for text normalization, we construct a lat-tice from possible normalization candidates andfind the best normalization sequence accordingto an n-gram language model using a Viterbi de-coder.
The normalization lexicon is acquired fromunlabeled data using random walks on a contex-tual similarity graph constructed form n-gram se-quences on large unlabeled text corpus.
Our ap-proach has some similarities with (Han et al,2012) since both approaches utilize a normaliza-1578tion lexicon acquired form unlabeled data usingdistributional and string similarities.
However, ourapproach is significantly different since we acquirethe lexicon using random walks on a contextualsimilarity graph which has a number of advantagesover the pairwise similarity approach used in (Hanet al, 2012).
Namely, the acquired normalizationequivalence are optimized globally over the wholedata, the rare equivalences are not considered asgood candidates unless there is a strong statisticalevidence across the data, and finally the normal-ization equivalences may not share the same con-text.
Those are clear advantages over the pairwisesimilarity approach and result in a lexicon withhigher accuracy as well as wider coverage.
Thoseadvantages will be clearer when we describe theproposed approach in details and during evalua-tion and comparison to the pairwise approach.3 Text Normalization SystemIn this paper, we handle text normalization as alattice scoring approach, where the translation isperformed from noisy text as the source side tothe normalized text as the target side.
Unlike con-ventional MT systems, the translation table is notlearned from parallel aligned data; instead it ismodeled by the graph-based approach of lexicongeneration as we will describe later.
We constructa lattice from possible normalization candidatesand find the best normalization sequence accord-ing to an n-gram language model using a Viterbidecoder.In this paper, we restrict the normalization lexi-con to one-to-one word mappings, we do not con-sider multi words mapping for the lexicon induc-tion.
To identify OOV candidates for normaliza-tion; we restrict proposing normalization candi-dates to the words that we have in our inducednormalization lexicon only.
This way, the systemwould provide more confident and conservativenormalization.
We move the problem of identi-fying OOV words to training time; at training timewe use soft criteria to identify OOV words.3.1 Baseline Normalization CandidatesGenerationWe experimented with two normalization candi-date generators as baseline systems.
The first is adictionary based spelling correction similar to As-pell1.
In this experiment we used the spell checker1http://aspell.net/to generate all possible candidates for OOV wordsand then applied the Viterbi decoder on the con-structed lattice to score the best correction candi-dates using a language model.Our second candidates generator is based ona trie approximate string matching with K errorssimilar to the approach proposed in (Chang et al,2010), where K errors can be caused by substi-tution, insertion, or deletion operations.
In ourimplementation, we customized the errors opera-tions to accommodate the nature of the social me-dia text.
Such as lengthening, letter substitution,letter-number substitution and phonetic substitu-tion.
This approach overcomes the main problemof the dictionary-based approach which is provid-ing inappropriate normalization candidates to theerrors styles in the social media text.As we will show in the experiments inSection(5), dictionary-based normalization meth-ods proved to be inadequate for social media do-main normalization for many reasons.
First, theyprovide generic corrections which are inappropri-ate for social media text.
Second, they usually pro-vide corrections with the minimal edit distance forany word or named entity regardless of the natureof the words.
Finally, the previous approaches donot take into account the dynamics of the socialmedia text where new terms can be introduced ona daily basis.4 Normalization Lexicons usingGraph-based Random Walks4.1 Bipartite Graph RepresentationThe main motivation of this approach is thatnormalization equivalences share similar context;which we call contextual similarity.
For instance,assume 5-gram sequences of words, two wordsmay be normalization equivalences if their n-gramcontext shares the same two words on the left andthe same two words on the right.
In other words,they are sharing a wild card pattern such as (word1 word 2 * word 4 word 5).This contextual similarity can be represented asa bipartite graph with the first partite representingthe words and the second partite representing then-gram contexts that may be shared by words.
Aword node can be either normalized word or noisyword.
Identifying if a word is normalized or noisy(candidate for normalization) is crucial since thisdecision limits the candidate noisy words to benormalized.
We adopted a soft criteria for iden-1579C2making4makin2 mking1tkin1C3 23C1 taking1takin21C4 145Figure 1: Bipartite Graph Representation, leftnodes represent contexts, gray right nodes repre-sent the noisy words and white right nodes rep-resent the normalized words.
Edge weight is theco-occurrence count of a word and its context.tifying noisy words.
A vocabulary is constructedfrom a large clean corpus.
Any word that does notappear in this vocabulary more than a predefinedthreshold (i.e.
10 times) is considered as a can-didate for normalization (noisy word).
Figure(1)shows a sample of the bipartite graphG(W,C,E),where noisy words are shown as gray nodes.Algorithm 4.1: CONSTRUCTBIPARTITE(text)comment: Construct Bipartite Graphoutput (G(W,C,E))comment: Extract all n-gram sequencesNgrams?
EXTRACTNGRAMS(TextCorpus)for each n ?
Ngramsdo????????????????????????
?comment: Check for center wordif ISNOISY(CenterWord)W ?
ADDSOURCENODE(CenterWord)elseW ?
ADDABSORBINGNODE(CenterWord)comment: add the context patternC ?
ADD(Context)comment: edge weightE ?
ADD(Context,Word, count)The bipartite graph, G(W,C,E), is composedof W which includes all nodes representing nor-malized words and noisy words, C which includesall nodes representing shared context, and finallyE which represents the edges of the graph con-necting word nodes and context nodes.
The weighton the edge is simply the number of occurrencesof a given word in a context.
While construct-ing the graph, we identify if a node represents anoisy word (N) (called source node) or a normal-ized word (M) (called absorbing node).
The bi-partite graph is constructed using the procedure inAlgorithm(4.1).4.2 Lexicon generation using Random WalksOur proposed approach uses Markov RandomWalks on the bipartite graph in Figure(1) as de-fined in (Norris, 1997).
The main objective is toidentify pairs of noisy and normalized words thatcan be considered as normalization equivalences.In principal, this is similar to using random walksfor semi-supervised label propagation which hasbeen introduced in (Szummer and Jaakkola, 2002)and then used in many other applications.
Forexample, (Hughes and Ramage, 2007) used ran-dom walks on Wordnet graph to measure lexicalsemantic relatedness between words.
(Das andPetrov, 2011) used graph-based label propagationfor cross-lingual knowledge transfers to inducePOS tags between two languages.
(Minkov andCohen, 2012) introduced a path constrained graphwalk algorithm given a small number of labeledexamples to assess nodes relatedness in the graph.In this paper, we apply the label propagation ap-proach to the text normalization problem.Consider a random walk on the bipartite graphG(W,C,E) starting at a noisy word (sourcenode) and ending at a normalized word (absorb-ing node).
The walker starts from any sourcenode Ni belonging to the noisy words then moveto any other connected node Mj with probabilityPij .
The transition between each pair of nodesis defined by a transition probability Pij whichrepresents the normalized probability of the co-occurrence counts of the word and the correspond-ing context.
Though the counts are symmetric, theprobability is not symmetric.
This is due to theprobability normalization which is done accordingto the nodes connectivity.
Therefore, the transitionprobability between any two nodes i, j is definedas:Pij = Wij/?
?kWik (1)For any non-connected pair of nodes, Pij =0.
Itis worth noting that due to the bipartite graph rep-resentation; any word node, either noisy (source)or normalized (absorbing), is only connected tocontext nodes and not directly connected to anyother word node.1580The algorithm repeats independent randomwalks for K times where the walks traverse thegraph randomly according to the transition prob-ability distribution in Eqn(1); each walk startsfrom the source noisy node and ends at an absorb-ing normalized node, or consumes the maximumnumber of steps without hitting an absorbing node.For any random walk the number of steps takento traverse between any two nodes is called thehitting time (Norris, 1997).
Therefore, the hit-ting time between a noisy and a normalized pairof nodes (n,m) with a walk r is hr(n,m).
Wedefine the cost between the two nodes as the aver-age hitting time H(n,m) of all walks that connectthose two nodes:H(n,m) =?
?rhr(n,m)/R (2)Consider the bipartite graph in Figure(1), as-sume a random walk starting at the source noderepresenting the noisy word ?tkin?
then moves tothe context node C1 then to the absorbing noderepresenting the normalized word ?taking?.
Thisrandom walk will associate ?tkin?
with ?taking?with a walk of two steps (hits).
Another randomwalk that can connect the two words is [?tkin??
C4?
?takin??
C1?
?taking?
], which has4 steps (hits).
In this case, the cost of this pairof nodes is the average number of hits connectingthem which is 3.It is worth noting that the random walks areselected according to the transition probability inEqn(1); therefore, the more probable paths will bepicked more frequently.
The same pair of nodescan be connected with many walks of various steps(hits), and the same noisy word can be connectedto many other normalized words.We define the contextual similarity probabil-ity of a normalization equivalence pair n,m asL(n,m).
Which is the relative frequency of theaverage hitting of those two nodes, H(n,m), andall other normalized nodes linked to that noisyword.
Thus L(n,m), is calculated as:L(n,m) = H(n,m)/?iH(n,mi) (3)Furthermore, we add another similarity cost be-tween a noisy word and a normalized word basedon the lexical similarity cost, SimCost(n,m),which we will describe in the next section.
Thefinal cost associated with a pair is:Cost(n,m) = ?1L(n,m) + ?2SimCost(n,m) (4)Algorithm 4.2: INDUCELEXICON(G)output (Lexicon)INIT((Lexicon))for each n ?W ?
G(W,C,E)do??????????????????????????????????????
?comment: for noisy nodes onlyif ISNOISY(n)????????????????
?INIT(Rn)comment: do K random walksfor i?
0 to KdoRn?
RANDOMWALK(n)comment: Calculate Avg.
hits and normalizeLn?
NORMALIZE(Rn)comment: Calculate Lexical Sim CostLn?
SIMCOST(Ln)Ln?
PRUNE(Ln)Lexicon?
ADD(Ln)We used uniform interpolation, both ?1 and ?2equals 1.
The final Lexicon is constructed usingthose entries and if needed we prune the list to taketop N according to the cost above.
The algorithmis outlined in 4.2.4.3 Lexical Similarity CostWe use a similarity function proposed in (Con-tractor et al, 2010) which is based on LongestCommon Subsequence Ratio (LCSR) (Melamed,1999).
This cost function is defined as the ratioof LCSR and Edit distance between two strings asfollows:SimCost(n,m) = LCSR(n,m)/ED(n,m) (5)LCSR(n,m) = LCS(n,m)/MaxLenght(n,m) (6)We have modified the Edit Distance calculationED(n,m) to be more adequate for social media text.The edit distance is calculated between the conso-nant skeleton of the two words; by removing allvowels, we used Editex edit distance as proposedin (Zobel and Philip, 1996), repetition is reducedto a single letter before calculating the edit dis-tance, and numbers in the middle of words are sub-stituted by their equivalent letters.5 Experiments5.1 Training and Evaluation DataWe collected large amount of social media data togenerate the normalization lexicon using the ran-1581dom walk approach.
The data consists of 73 mil-lion Twitter statuses.
All tweets were collectedfrom March/April 2012 using the Twitter Stream-ing APIs2.
We augmented this data with 50 mil-lion sentences of clean data from English LDC Gi-gaword corpus 3.
We combined both data, noisyand clean, together to induce the normalizationdictionary from them.
While the Gigaword cleandata was used to train the language model to scorethe normalized lattice.We constructed a test set of 1000 sentences ofsocial media which had been corrected by a na-tive human annotator, the main guidelines were tonormalize noisy words to its corresponding cleanwords in a consistent way according to the evi-dences in the context.
We will refer to this testset as SM-Test.
Furthermore, we developed a testset for evaluating the effect of the normalizationsystem when used as a preprocessing step for Ma-chine translation.
The machine translation test setis composed of 500 sentences of social media En-glish text translated to normalized Spanish text bya bi-lingual translator.5.2 Evaluating Normalization LexiconGenerationWe extracted 5-gram sequences from the com-bined noisy and clean data; then we limited thespace of noisy 5-gram sequences to those whichcontain only one noisy word as the center wordand all other words, representing the context, arenot noisy.
As we mentioned before, we identifywhether the word is noisy or not by looking upa vocabulary list constructed from clean data.
Inthese experiments, the vocabulary is constructedfrom the Language Model data (50M sentences ofthe English Gigaword corpus).
Any word that ap-pears less than 10 times in this vocabulary is con-sidered noisy and candidate for normalization dur-ing the lexicon induction process.
It is worth not-ing that our notion of noisy word does not mean itis an OOV that has to be corrected; instead it in-dicates that it is candidate for correction but maybe opted not to be normalized if there is no con-fident normalization for it.
This helps to maintainthe approach as a high precision text normaliza-tion system which is highly preferable as an NLPpreprocessing step.We constructed a lattice using normalization2https://dev.twitter.com/docs/streaming-apis3http://www.ldc.upenn.edu/Catalog/LDC2011T07candidates and score the best Viterbi path with 5-gram language model.
We experimented with twocandidate generators as baseline systems, namelythe dictionary-based spelling correction and thetrie approximate match with K errors; where K=3.For both candidate generators the cost function fora given candidate is calculated using the lexicalsimilarity cost in Eqn(5).
We compared those ap-proaches with our newly proposed unsupervisednormalization lexicon induction; for this case thecost for a candidate is the combined cost of thecontextual similarity probability and the lexicalsimilarity cost as defined in Eqn(4).
We examinethe effect of data size and the steps of the randomwalks on the accuracy and the coverage of the in-duced dictionary.We constructed the bipartite graph with the n-gram sequences as described in Algorithm 4.1.Then the Random Walks Algorithm in 4.2 is ap-plied with 100 walks.
The total number of wordnodes is about 7M nodes and the total numberof context nodes is about 480M nodes.
We usedMapReduce framework to implement the pro-posed technique to handle such large graph.
Weexperimented with the maximum number of ran-dom walk steps of 2, 4 and 6; and with differentportions of the data as well.
Finally, we prunedthe lexicon to keep the top 5 candidates per noisyword.Table(1) shows the resulting lexicons from dif-ferent experiments.Lexicon Lexicon Data StepsLex1 123K 20M 4Lex2 281K 73 M 2Lex3 327K 73M 4Lex4 363K 73M 6Table 1: Generated Lexicons, steps are the Ran-dom Walks maximum steps.As shown in Table(1), we experimented withdifferent data sizes and steps of the random walks.The more data we have the larger the lexicon weget.
Also larger steps increase the induced lexi-con size.
A random walk step size of 2 means thatthe noisy/normalized pair shares the same context;while a step size of 4 or more means that they maynot share the same context.
Next, we will exam-ine the effect of lexicon size on the normalizationtask.15825.3 Text Normalization EvaluationWe experimented different candidate generatorsand compared it to the unsupervised lexicon ap-proach.
Table(2) shows the precision and recall ona the SM-Test set.System Candidates Precision Recall F-MeasureBase1 Dict 33.9 15.1 20.98Base2 Trie 26.64 27.65 27.13RW1 Lex1 88.76 59.23 71.06RW2 Lex2 90.66 54.06 67.73RW3 Lex3 92.43 56.4 70.05RW4 Lex4 90.87 60.73 72.8Table 2: Text Normalization with different lexi-consIn Table(2), the first baseline is using a dictio-nary based spell checker; which gets low precisionand very low recall.
Similarly the trie approximatestring match is doing a similar job with better re-call though the precision is worst.
Both of thebaseline approaches are inadequate for social me-dia text since both will try to correct any word thatis similar to a word in the dictionary.
The Trie ap-proximate match is doing better job on the recallsince the approximate match is based on phoneticand lexical similarities.On the other hand, the induced normalizationlexicon approach is doing much better even witha small amount of data as we can see with sys-tem RW1 which uses Lex1 generated from 20Msentences and has 123K lexicon entry.
Increas-ing the amount of training data does impact theperformance positively especially the recall.
Onthe other hand, increasing the number of steps hasa good impact on the recall as well; but with aconsiderable impact on the precision.
It is clearthat increasing the amount of data and keeping thesteps limit at ??4??
gives better precision and cov-erage as well.
This is a preferred setting since themain objective of this approach is to have betterprecision to serve as a reliable preprocessing stepfor Machine Translation and other NLP applica-tions.5.4 Comparison with Pairwise SimilarityWe present experimental results to compare ourproposed approach with (Han et al, 2012) whichused pairwise contextual similarity to induce anormalization lexicon of 40K entries, we will referto this lexicon as HB-Dict.
We compare the per-formance of HB-Dict and our induced dictionary(system RW3).
We evaluate both system on SM-Test test set and on (Han et al, 2012) test set of548 sentences which we call here HB-Test.System Precision Recall F-MeasureSM-TestHB-Dict 71.90 26.30 38.51RW3 92.43 56.4 70.05HB-TestHB-Dict 70.0 17.9 26.3RW3 85.37 56.4 69.93Table 3: Text Normalization ResultsAs shown in Table(3), RW3 system signifi-cantly outperforms HB-Dict system with the lex-icon from (Han et al, 2012) on both test sets forboth precision and recall.
The contextual graphrandom walks approach helps in providing highprecision lexicon since the sampling nature of theapproach helps in filtering out unreliable normal-ization equivalences.
The random walks will tra-verse more frequent paths; which would lead tomore probable normalization equivalence.
On theother hand, the proposed approach provides highrecall as well which is hard to achieve with higherprecision.
Since the proposed approach deploysrandom walks to sample paths that can traversemany steps, this relaxes the constraints that thenormalization equivalences have to share the samecontext.
Instead a noisy word may share a con-text with another noisy word which in turn sharesa context with a clean equivalent normalizationword.
Therefore, we end up with a lexicon thathave much higher recall than the pairwise simi-larity approach since it explores equivalences be-yond the pairwise relation.
Moreover, the randomwalk sampling emphasis the more frequent pathsand hence provides high precision lexicon.5.5 Output AnalysisTable(4) shows some examples of the induced nor-malization equivalences, the first part shows goodexamples where vowels are restored and phoneticsimilar words are matched.
Remarkably the cor-rection ??viewablity??
to ??visibility??
is interest-ing since the system picked the more frequentform.
Moreover, the lexicon contains some entrieswith foreign language words normalized to its En-glish translation.
On the other hand, the lexiconhas some bad normalization such as ??unrecycled??
which should be normalized to ?
?non recycled?
?but since the system is limited to one word cor-rection it did not get it.
Another interesting badnormalization is ??tutting??
which is new type of1583dancing and should not be corrected to ??tweet-ing?
?.Noisy Clean Remarkstnght tonight Vowels restoreddarlin darling g restoredurung orange phonetic similarityviewablity visibility good correctionunrecycled recycled negation ignoredtutting tweeting tutting is dancing typeTable 4: Lexicon SamplesTable 5 lists a number of examples and theirnormalization using both Baseline1 and RW3.
Atthe first example, RW3 got the correct normaliza-tion as ?interesting?
which apparently is not theone with the shortest edit distance, though it isthe most frequent candidate at the generated lex-icon.
The baseline system did not get it right; itgot a wrong normalization with shorter edit dis-tance.
Example(2) shows the same effect by get-ting ?cuz?
normalized to ?because?.
At Exam-ple(3), both the baseline and RW3 did not getthe correct normalization of ?yur?
to ?you are?which is currently a limitation in our system sincewe only allow one-to-one word mapping in thegenerated lexicons not one-to-many or many-to-many.
At Example(4), RW3 did not normalize?dure?
to ?sure?
; however the baseline normal-ized it by mistake to ?dare?.
This shows a char-acteristic of the proposed approach; it is very con-servative in proposing normalization which is de-sirable as a preprocessing step for NLP applica-tions.
This limitation can be marginalized by pro-viding more data for generating the lexicon.
Fi-nally, Example 4 shows also that the system nor-malize ?gr8?which is mainly due to having a flex-ible similarity cost during the normalization lexi-con construction.1.
Source: Mad abt dt so mch intestingBaseline1: Mad at do so much ingestingRW3: Mad about that so much interesting2.
Source: i?l do cuz ma parnts r ma lyfBaseline1: I?ll do cut ma parents r ma lifeRW3: I?ll do because my parents are my life3.
Source: yur cuuuuuteBaseline1: yur cuuuuuteRW3: your cute4.
Source: I?m dure u will get a gr8 scoreBaseline1: I?m dare you will get a gr8 scoreRW3: I?m dure you will get a great scoreTable 5: Normalization Examples5.6 Machine Translation Task EvaluationThe final evaluation of the text normalization sys-tem is an extrinsic evaluation where we evaluatethe effect of the text normalization task on a so-cial media text translating from English to Span-ish using a large scale translation system trainedon general domain data.
The system is trainedon English-Spanish parallel data from WMT 2012evaluation 4.
The data consists of about 5M paral-lel sentences on news, europal and UN data.
Thesystem is a state of the art phrase based systemsimilar to Moses (Hoang et al, 2007).
We usedThe BLEU score (Papineni et al, 2002) to evaluatethe translation accuracy with and without the nor-malization.
Table(6) shows the translation evalua-tion with different systems.
The translation withnormalization was improved by about 6% from29.02 to 30.87 using RW3 as a preprocessing step.System BLEU ImpreovemnetNo Normalization 29.02 0%Baseline1 29.13 0.37%HB-Dict 29.76 3.69%RW3 30.87 6.37%Table 6: Translation Results6 Conclusion and Future WorkWe introduced a social media text normalizationsystem that can be deployed as a preprocessorfor MT and various NLP applications to han-dle social media text.
The proposed approach isvery scalable, adaptive to any domain and lan-guage.
We show that the proposed unsupervisedapproach provides a normalization system withvery high precision and a reasonable recall.
Wecompared the system with conventional correctionapproaches and with recent previous work; and weshowed that it highly outperforms other systems.Finally, we have used the system as a preprocess-ing step for a machine translation system whichimproved the translation quality by 6%.As an extension to this work, we will extend theapproach to handle many-to-many normalizationpairs; also we plan to apply the approach to morelanguages.
Furthermore, the approach can be eas-ily extended to handle similar problems such as ac-cent restoration and generic entity normalization.4http://www.statmt.or/wmt121584AcknowledgmentsWe would like to thank Lee Schwartz and WillLewis for their help in constructing the test setsand in the error analysis.
We would also like tothank the anonymous reviewers for their helpfuland constructive comments.ReferencesAiTi Aw, Min Zhang, Juan Xiao, and Jian Su.
2006.A phrase-based statistical model for SMS text nor-malization.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for Computa-tional Linguistics, pages 3340, Sydney, Australia.Eric Brill and Robert C. Moore.
2000.
An improved er-ror model for noisy channel spelling correction, InACL 2000: Proceedings of the 38th Annual Meetingon Association for Computational Linguistics, En-glewood Cliffs, NJ, USA.Ye-In Chang and Jiun-Rung Chen and Min-Tze Hsu2010.
A hash trie filter method for approximatestring matching in genomic databases Applied In-telligence, 33:1, pages 21:38, Springer US.Monojit Choudhury, Rahul Saraf, Vijit Jain, AnimeshMukherjee, Sudeshna Sarkar, and Anupam Basu2007.
Investigation and modeling of the structure oftexting language.
International Journal of DocumentAnalysis and Recognition, vol.
10, pp.
157:174.Danish Contractor and Tanveer Faruquie and VenkataSubramaniam 2010.
Unsupervised cleansing ofnoisy text.
In COLING ?10 Proceedings of the 23rdInternational Conference on Computational Linguis-tics, pages 189:196.Paul Cook and Suzanne Stevenson.
2009.
An unsu-pervised model for text message normalization.. InCALC 09: Proceedings of the Workshop on Compu-tational Approaches to Linguistic Creativity, pages71:78, Boulder, USA.Dipanjan Das and Slav Petrov 2011 Unsuper-vised part-of-speech tagging with bilingual graph-based projections Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages600:609, Portland, OregonStephan Gouws, Dirk Hovy, and Donald Metzler.2011.
Unsupervised mining of lexical variants fromnoisy text.
In Proceedings of the First workshop onUnsupervised Learning in NLP, pages 82:90, Edin-burgh, Scotland.Bo Han and Timothy Baldwin.
2011.
Lexical normal-isation of short text messages: Makn sens a twit-ter.
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics:Human Language Technologies (ACL-HLT 2011),pages 368:378, Portland, Oregon, USA.Bo Han and Paul Cook and Timothy Baldwin 2012.Automatically Constructing a Normalisation Dic-tionary for Microblogs.
Proceedings of the 2012Joint Conference on Empirical Methods in Natu-ral Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL 2012), pages421:432, Jeju Island, Korea.Hieu Hoang and Alexandra Birch and Chris Callison-burch and Richard Zens and Rwth Aachen andAlexandra Constantin and Marcello Federico andNicola Bertoldi and Chris Dyer and Brooke CowanandWade Shen and Christine Moran and Ondrej Bo-jar 2007.
Moses: Open source toolkit for statisticalmachine translation.Thad Hughes and Daniel Ramage 2007.
Lexical se-mantic relatedness with random graph walks Pro-ceedings of Conference on Empirical Methods inNatural Language Processing EMNLP, pp.
581589,PragueFei Liu and Fuliang Weng and Bingqing Wang andYang Liu 2011.
Insertion, Deletion, or Substi-tution?
Normalizing Text Messages without Pre-categorization nor Supervision Proceedings of the49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 19:24, Portland, OregonDan Melamed 1999.
Bitext Maps and Alignment viaPattern Recognition.
In Computational Linguistics,25, pages 107:130.Einat Minkov and William Cohen Graph BasedSimilarity Measures for Synonym Extraction fromParsed Text In Proceedings of the TextGraphs work-shop 2012J.
Norris 1997.
Markov Chains.
Cambridge Univer-sity Press.Kishore Papineni and Salim Roukos and Todd Wardand Wei-jing Zhu 2002.
BLEU: a Method for Au-tomatic Evaluation of Machine Translation.
in Pro-ceedings of ACL-2002: 40th Annual meeting of theAssociation for Computational Linguistics.
, pages311:318.Richard Sproat, Alan W. Black, Stanley Chen, ShankarKumar, Mari Ostendorf, and Christopher Richards.Normalization of non-standard words.
2001.Xu Sun and Jianfeng Gao and Daniel Micol and ChrisQuirk 2010.
Learning Phrase-Based Spelling ErrorModels from Clickthrough Data.
Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 266:274, Sweeden.Martin Szummer and Tommi 2002.
Partially labeledclassification with markov random walks.
In Ad-vances in Neural Information Processing Systems,pages 945:952.1585Kristina Toutanova and Robert C. Moore.
Pronunci-ation modeling for improved spelling correction..2002.
In Proceedings of the 40th Annual Meetingon Association for Computational Linguistics, ACL, pages 144151, Philadelphia, USA.Justin Zobel and Philip Dart 1996.
Phonetic stringmatching: Lessons from information retrieval.
inProceedings of the Eighteenth ACM SIGIR Inter-national Conference on Research and Developmentin Information Retrieval, pages 166:173, Zurich,Switzerland.1586
