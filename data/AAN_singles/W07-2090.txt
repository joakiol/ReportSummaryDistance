Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 406?409,Prague, June 2007. c?2007 Association for Computational LinguisticsUNT-Yahoo: SuperSenseLearner: Combining SenseLearner withSuperSense and other Coarse Semantic FeaturesRada Mihalcea and Andras CsomaiUniversity of North Texasrada@cs.unt.edu,csomaia@unt.eduMassimiliano CiaramitaYahoo!
Research Barcelonamassi@yahoo-inc.comAbstractWe describe the SUPERSENSELEARNERsystem that participated in the English all-words disambiguation task.
The system re-lies on automatically-learned semantic mod-els using collocational features coupled withfeatures extracted from the annotations ofcoarse-grained semantic categories gener-ated by an HMM tagger.1 IntroductionThe task of word sense disambiguation consists ofassigning the most appropriate meaning to a poly-semous word within a given context.
Applicationssuch as machine translation, knowledge acquisition,common sense reasoning, and others, require knowl-edge about word meanings, and word sense disam-biguation is considered essential for all these tasks.Most of the efforts in solving this problemwere concentrated so far toward targeted supervisedlearning, where each sense tagged occurrence of aparticular word is transformed into a feature vector,which is then used in an automatic learning process.The applicability of such supervised algorithms ishowever limited only to those few words for whichsense tagged data is available, and their accuracyis strongly connected to the amount of labeled dataavailable at hand.Instead, methods that address all words in unre-stricted text have received significantly less atten-tion.
While the performance of such methods is usu-ally exceeded by their supervised lexical-sample al-ternatives, they have however the advantage of pro-viding larger coverage.In this paper, we describe SUPERSENSE-LEARNER ?
a system for solving the semantic am-biguity of all words in unrestricted text.
SUPER-SENSELEARNER brings together under one systemthe features previously used in the SENSELEARNER(Mihalcea and Csomai, 2005) and the SUPERSENSE(Ciaramita and Altun, 2006) all-words word sensedisambiguation systems.
The system is using a rel-atively small pre-existing sense-annotated data setfor training purposes, and it learns global semanticmodels for general word categories.2 Learning for All-Words Word SenseDisambiguationOur goal is to use as little annotated data as possi-ble, and at the same time make the algorithm gen-eral enough to be able to disambiguate as manycontent words as possible in a text, and efficientenough so that large amounts of text can be anno-tated in real time.
SUPERSENSELEARNER is at-tempting to learn general semantic models for var-ious word categories, starting with a relatively smallsense-annotated corpus.
We base our experimentson SemCor (Miller et al, 1993), a balanced, se-mantically annotated dataset, with all content wordsmanually tagged by trained lexicographers.The input to the disambiguation algorithm con-sists of raw text.
The output is a text with wordmeaning annotations for all open-class words.The algorithm starts with a preprocessing stage,where the text is tokenized and annotated with part-406of-speech tags; collocations are identified using asliding window approach, where a collocation is de-fined as a sequence of words that forms a compoundconcept defined in WordNet (Miller, 1995).Next, a semantic model is learned for all pre-defined word categories, where a word category isdefined as a group of words that share some com-mon syntactic or semantic properties.
Word cate-gories can be of various granularities.
For instance,a model can be defined and trained to handle all thenouns in the test corpus.
Similarly, using the samemechanism, a finer-grained model can be defined tohandle all the verbs for which at least one of themeanings is of type e.g., ?<move>?.
Finally, smallcoverage models that address one word at a time, forexample a model for the adjective ?small,?
can bealso defined within the same framework.
Once de-fined and trained, the models are used to annotate theambiguous words in the test corpus with their corre-sponding meaning.
Sections 3 and 4 below providedetails on the features implemented by the variousmodels.Note that the semantic models are applicable onlyto: (1) words that are covered by the word categorydefined in the models; and (2) words that appearedat least once in the training corpus.
The words thatare not covered by these models (typically about 10-15% of the words in the test corpus) are assigned themost frequent sense in WordNet.3 SenseLearner Semantic ModelsDifferent semantic models can be defined andtrained for the disambiguation of different word cat-egories.
Although more general than models thatare built individually for each word in a test corpus(Decadt et al, 2004), the applicability of the seman-tic models built as part of SENSELEARNER is stilllimited to those words previously seen in the train-ing corpus, and therefore their overall coverage isnot 100%.Starting with an annotated corpus consisting ofall the annotated files in SemCor, augmented withthe SENSEVAL-2 and SENSEVAL-3 all-words datasets, a separate training data set is built for eachmodel.
There are seven models provided with thecurrent SENSELEARNER distribution, implementingthe following features:3.1 Noun ModelsmodelNN1: A contextual model that relies on thefirst noun, verb, or adjective before the target noun,and their corresponding part-of-speech tags.modelNNColl: A collocation model that imple-ments collocation-like features based on the firstword to the left and the first word to the right of thetarget noun.3.2 Verb ModelsmodelVB1 A contextual model that relies on thefirst word before and the first word after the targetverb, and their part-of-speech tags.modelVBColl A collocation model that implementscollocation-like features based on the first word tothe left and the first word to the right of the targetverb.3.3 Adjective ModelsmodelJJ1 A contextual model that relies on the firstnoun after the target adjective.modelJJ2 A contextual model that relies on the firstword before and the first word after the target adjec-tive, and their part-of-speech tags.modelJJColl A collocation model that implementscollocation-like features using the first word to theleft and the first word to the right of the target adjec-tive.Based on previous performance in theSENSEVAL-2 and SENSEVAL-3 evaluations,we selected the noun and verb collocational modelsfor inclusion in the SUPERSENSELEARNER systemparticipating in the SEMEVAL all-words task.4 SuperSenses and other Coarse-GrainedSemantic FeaturesA great deal of work has focused in recent yearson shallow semantic annotation tasks such as namedentity recognition and semantic role labeling.
In theformer task, systems analyze text to detect mentionsof instances of coarse-grained semantic categoriessuch as ?person?, ?organization?
and ?location?.
Itseems natural to ask if this type of shallow seman-tic information can be leveraged to improve lexicaldisambiguation.
Particularly, since the best perform-ing taggers typically implement sequential decodingschemes, e.g., Viterbi decoding, which have linear407complexity and can be performed quite efficiently.In practice thus, this type of pre-processing resem-bles POS-tagging and could provide the WSD sys-tem with useful additional evidence.4.1 TagsetsWe use three different tagsets.
The first is the set ofWordNet supersenses (Ciaramita and Altun, 2006):a mapping of WordNet?s synsets to 45 broad lexi-cographers categories, 26 for nouns, 15 for verbs,3 for adjectives and 1 for adverbs.
The secondtagset is based on the ACE 2007 English data forentity mention detection (EMD) (ACE, 2007).
Thistagset defines seven entity types: Facility, Geo-Political Entity, Location, Organization, Person, Ve-hicle, Weapon; further subdivided in 44 subtypes.The third tagset is derived from the BBN EntityCorpus (BBN, 2005) which complements the WallStreet Journal Penn Treebank with annotations of alarge set of entities: 12 named entity types (Person,Facility, Organization, GPE, Location, Nationality,Product, Event, Work of Art, Law, Language, andContact-Info), nine nominal entity types (Person,Facility, Organization, GPE, Product, Plant, Animal,Substance, Disease and Game), and seven numerictypes (Date, Time, Percent, Money, Quantity, Ordi-nal and Cardinal).
Several of these types are furtherdivided into subtypes, for a total of 105 classes.14.2 TaggersWe annotate the training and evaluation data usingthree sequential taggers, one for each tagset.
Thetagger is a Hidden Markov Model trained with theperceptron algorithm introduced in (Collins, 2002),which applies Viterbi decoding and is regularizedusing averaging.
Label to label dependencies arelimited to the previous tag (first order HMM).
Weuse a generic feature set for NER based on words,lemmas, POS tags, and word shape features, in addi-tion we use as a feature of each token the supersenseof a first (super)sense baseline.
A detailed descrip-tion of the features used and the tagger can be foundin (Ciaramita and Altun, 2006).
The supersense tag-ger is trained on the Brown sections one and two ofSemCor.
The BBN tagger is trained on sections 2-21 of the BBN corpus.
The ACE tagger is trained1BBN Corpus documentation.on the 599 ACE 2007 training files.
The accuracyof the tagger is, approximately, 78% F-score for su-persenses and ACE, and 87% F-score for the BBNcorpus.4.3 FeaturesThe taggers disregard the lemmatization of the eval-uation data.
In practice, this means that multiwordlemmas such as ?take off?, are split into their ba-sic components.
In fact, the goal of the tagger isto guess the elements of the instances of semanticcategories by means of the usual BIO encoding.
Inother words, the tagger predicts a labeled bracket-ing of the tokens in each sentence.
As an exam-ple, the supersense tagger annotates the tokens in thephrase ?substance abuse?
as ?substanceB?noun.act?and ?abuseI?noun.act?, although the gold standardsegmentation of the data does not identify the phraseas one lemma.
We use the labels generated in thisway as features of each token to disambiguate.5 Feature CombinationFor the final system we create a combined feature setfor each target word, consisting of the lemma, thepart of speech, the collocational SENSELEARNERfeatures, and the three coarse grained semantic tagsof the target word.
Note that the semantic fea-tures are represented as lemma TAG to avoid over-generalization.In the training stage, a feature vector is con-structed for each sense-annotated word covered bya semantic model.
The features are model-specific,and feature vectors are added to the training setpertaining to the corresponding model.
The labelof each such feature vector consists of the targetword and the corresponding sense, represented asword#sense.
Table 1 shows the number of featurevectors constructed in this learning stage for eachsemantic model.
To annotate new text, similar vec-tors are created for all the content-words in the rawtext.
Similar to the training stage, feature vectorsare created and stored separately for each semanticmodel.Next, word sense predictions are made for all thetest examples, with a separate learning process runfor each semantic model.
For learning, we are usingthe Timbl memory based learning algorithm (Daele-408Training RESULTSmode size Precision Recallnoun 89052 0.658 0.228verb 48936 0.539 0.353all 137988 0.583 0.583Table 1: Precision and recall for the SUPERSENSE-LEARNER semantic models.Training RESULTSmode size Precision Recallnoun 89052 0.666 0.233verb 48936 0.554 0.360all 137988 0.593 0.593Table 2: Precision and recall for the SUPERSENSE-LEARNER semantic models - without U labels.mans et al, 2001), which was previously found use-ful for the task of word sense disambiguation (Hosteet al, 2002; Mihalcea, 2002).Following the learning stage, each vector in thetest data set is labeled with a predicted word andsense.
If the word predicted by the learning algo-rithm coincides with the target word in the test fea-ture vector, then the predicted sense is used to an-notate the test instance.
Otherwise, if the predictedword is different from the target word, no annota-tion is produced, and the word is left for annotationin a later stage (e.g., using the most frequent senseback-off method).6 ResultsThe SUPERSENSELEARNER system participated inthe SEMEVAL all-words word sense disambigua-tion task.
Table 1 shows the results obtained foreach part-of-speech (nouns and verbs), as well asthe overall results.
We have also ran a separateevaluation excluding the U (unknown) tag, whichis shown in Table 2.
SUPERSENSELEARNER wasranked the third among the fourteen participatingsystems, proving the validity of the approach.AcknowledgmentsWe would like to thank Mihai Surdeanu for provid-ing a pre-processed version of the ACE data.References2007.
Automatic content extraction workshop.http://www.nist.gov/speech/tests/ace/ace07/index.htm.2005.
BBN pronoun coreference and entity type cor-pus.
Linguistic Data Consortium (LDC) catalog num-ber LDC2005T33.M.
Ciaramita and Y. Altun.
2006.
Broad-coverage sensedisambiguation and information extraction with a su-persense sequence tagger.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing.M.
Collins.
2002.
Discriminative training methods forhidden markov models: Theory and experiments withperceptron algorithms.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP), Philadelphia, July.
Association forComputational Linguistics.W.
Daelemans, J. Zavrel, K. van der Sloot, and A. van denBosch.
2001.
Timbl: Tilburg memory based learner,version 4.0, reference guide.
Technical report, Univer-sity of Antwerp.B.
Decadt, V. Hoste, W. Daelemans, and A.
Van denBosch.
2004.
Gambl, genetic algorithm optimizationof memory-based wsd.
In Senseval-3: Third Interna-tional Workshop on the Evaluation of Systems for theSemantic Analysis of Text, Barcelona, Spain, July.V.
Hoste, W. Daelemans, I. Hendrickx, and A. van denBosch.
2002.
Evaluating the results of a memory-based word-expert approach to unrestricted word sensedisambiguation.
In Proceedings of the ACL Workshopon ?Word Sense Disambiguatuion: Recent Successesand Future Directions?, Philadelphia, July.R.
Mihalcea and A. Csomai.
2005.
Senselearner: Wordsense disambiguation for all words in unrestricted text.In Proceedings of the 43nd Annual Meeting of the As-sociation for Computational Linguistics, Ann Arbor,MI.R.
Mihalcea.
2002.
Instance based learning with auto-matic feature selection applied to Word Sense Disam-biguation.
In Proceedings of the 19th InternationalConference on Computational Linguistics (COLING2002), Taipei, Taiwan, August.G.
Miller, C. Leacock, T. Randee, and R. Bunker.
1993.A semantic concordance.
In Proceedings of the 3rdDARPA Workshop on Human Language Technology,Plainsboro, New Jersey.G.
Miller.
1995.
Wordnet: A lexical database.
Commu-nication of the ACM, 38(11):39?41.409
