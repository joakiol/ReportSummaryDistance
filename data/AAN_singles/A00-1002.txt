Machine Translation of Very Close LanguagesJan HAJI(~Computer Science Dept.Johns Hopkins University3400 N. Charles St., Baltimore,MD 21218, USAhajic@cs.jhu.eduJan HRICKTI MFF UKMalostransk6 nfim.25Praha 1, Czech Republic, 11800hric@barbora.m ff.cuni.czVladislav KUBONOFAL MFF UKMalostransk6 mim.25Praha 1, Czech Republic, 11800vk@ufal.mff.cuni.czAbstractUsing examples of the transfer-based MTsystem between Czech and RussianRUSLAN and the word-for-word MT systemwith morphological disambiguation betweenCzech and Slovak (~ESILKO we argue thatfor really close languages it is possible toobtain better translation quality by means ofsimpler methods.
The problem of translationto a group of typologically similar languagesusing a pivot language is also discussed here.IntroductionAlthough the field of machine translation has avery long history, the number of really successfulsystems is not very impressive.
Most of the fundsinvested into the development of various MTsystems have been wasted and have notstimulated a development of techniques whichwould allow to translate at least technical textsfrom a certain limited domain.
There were, ofcourse, exceptions, which demonstrated thatunder certain conditions it is possible to developa system which will save money and effortsinvested into human translation.
The main reasonwhy the field of MT has not met the expectationsof sci-fi literature, but also the expectations ofscientific community, is the complexity of thetask itself.
A successful automatic translationsystem requires an application of techniques fromseveral areas of computational inguistics(morphology, syntax, semantics, discourseanalysis etc.)
as a necessary, but not a sufficientcondition.
The general opinion is that it is easierto create an MT system for a pair of relatedlanguages.
In our contribution we would like todemonstrate hat this assumption holds only forreally very closely related languages.1.
Czech-to-Russian MT system RUSLAN1.1 HistoryThe first attempt o verify the hypothesis thatrelated languages are easier to translate started inmid 80s at Charles University in Prague.
Theproject was called RUSLAN and aimed at thetranslation of documentation i the domain ofoperating systems for mainframe computers.
Itwas developed in cooperation with the ResearchInstitute of Mathematical Machines in Prague.
Atthat time in former COMECON countries it wasobligatory to translate any kind of documentationto such systems into Russian.
The work on theCzech-to-Russian MT system RUSLAN (cf.
Oliva(1989)) started in 1985.
It was terminated in 1990(with COMECON gone) for the lack of funding.1.2 System descriptionThe system was rule-based, implemented inColmerauer's Q-systems.
It contained a full-fledged morphological and syntactic analysis ofCzech, a transfer and a syntactic andmorphological generation of Russian.
There wasalmost no transfer at the beginning of the projectdue to the assumption that both languages aresimilar to the extent that does not require anytransfer phase at all.
This assumption turned to bewrong and several phenomena were covered bythe transfer in the later stage of the project (forexample the translation of the Czech verb "b~"\[to be\] into one of the three possible Russianequivalents: empty form, the form "byt6" in future7tense and the verb "javljat6sja"; or the translationof verbal negation).At the time when the work was terminated in1990, the system had a main translationdictionary of about 8000 words, accompanied byso called transducing dictionary covering another2000 words.
The transducing dictionary wasbased on the original idea described in Kirschner(1987).
It aimed at the exploitation of the factthat technical terms are based (in a majority ofEuropean languages) on Greek or Latin stems,adopted according to the particular derivationalrules of the given languages.
This fact allows forthe "translation" of technical terms by means of adirect transcription of productive ndings and aslight (regular) adjustment of the spelling of thestem.
For example, the English wordslocalization and discrimination can betranscribed into Czech as "lokalizace" and"diskriminace" with a productive nding -ationbeing transcribed to -ace.
It was generallyassumed that for the pair Czech/Russian thetransducing dictionary would be able to profitfrom a substantially greater number of productiverules.
This hypothesis proved to be wrong, too(see B6mov~, Kubofi (1990)).
The set ofproductive ndings for both pairs (English/Czech,as developed for an earlier MT system fromEnglish to Czech, and Czech/Russian) was verysimilar.The evaluation of results of RUSLAN showedthat roughly 40% of input sentences weretranslated correctly, about 40% with minor errorscorrectable by a human post-editor and about20% of the input required substantial editing orre-translation.
There were two main factors thatcaused a deterioration of the translation.
The firstfactor was the incompleteness of the maindictionary of the system.
Even though the systemcontained a set of so-called fail-soft rules, whosetask was to handle such situations, an unknownword typically caused a failure of the module ofsyntactic analysis, because the dictionary entriescontained - besides the translation equivalentsand morphological information - very importantsyntactic information.The second factor was the module of syntacticanalysis of Czech.
There were several reasons ofparsing failures.
Apart from the common inabilityof most rule-based formal grammars to cover aparticular natural anguage to the finest detail ofits syntax there were other problems.
One of  themwas the existence of non-projective constructions,which are quite common in Czech even inrelatively short sentences.
Even though theyaccount only for 1.7?/'o f syntactic dependencies,every third Czech sentence contains at least one,and in a news corpus, we discovered as much as15 non-projective dependencies; see also Haji6 etal.
(1998).
An example of a non-projectiveconstruction is "Soubor se nepodafilo otev~it."\[lit.
: File Refl.
was_not._possible to_open.
- It wasnot possible to open the file\].
The formalism usedfor the implementation (Q-systems) was not meantto handle non-projective constructions.
Anothersource of trouble was the use of so-calledsemantic features.
These features were based onlexical semantics of individual words.
Their maintask was to support a semantically plausibleanalysis and to block the implausible ones.
Itturned out that the question of implausiblecombinations of  semantic features is also morecomplex than it was supposed to be.
The practicaloutcome of the use of semantic features was ahigher atio of parsing failures - semantic featuresoften blocked a plausible analysis.
For example,human lexicographers a signed the verb 'to run' asemantic feature stating that only a noun withsemantic features of a human or other living beingmay be assigned the role of subject of this verb.The input text was however full of sentences with'programs' or 'systems' running etc.
It was ofcourse very easy to correct he semantic feature inthe dictionary, but the problem was that therewere far too many corrections required.On the other hand, the fact that both languagesallow a high degree of word-order freedomaccounted for a certain simplification of  thetranslation process.
The grammar elied on thefact that there are only minor word-orderdifferences between Czech and Russian.1.3 Lessons learned  f rom RUSLANWe have learned several lessons regarding the MTof closely related languages:?
The transfer-based approach provides asimilar quality of translation both for closelyrelated and typologically different languages?
Two main bottlenecks of full-fledgedtransfer-based systems are:8- complexity of the syntactic dictionary- relative unreliability of the syntacticanalysis of the source languageEven a relatively simple component(transducing dictionary) was equally complexfor English-to-Czech and Czech-to-RussiantranslationLimited text domains do not exist in real life,it is necessary to work with a high coveragedictionary at least for the source language.2.
Translation and localization2.1 A pivot languageLocalization of products and their documentationis a great problem for any company, which wantsto strengthen its position on foreign languagemarket, especially for companies producingvarious kinds of  software.
The amounts of textsbeing localized are huge and the localizationcosts are huge as well.It is quite clear that the localization from onesource language to several target languages,which are typologically similar, but differentfrom the source language, is a waste of moneyand effort.
It is of course much easier to translatetexts from Czech to Polish or from Russian toBulgarian than from English or German to any ofthese languages.
There are several reasons, whylocalization and translation is not beingperformed through some pivot language,representing a certain group of closely relatedlanguages.
Apart from political reasons thetranslation through a pivot language has severaldrawbacks.
The most important one is theproblem of the loss of translation quality.
Eachtranslation may to a certain extent shift themeaning of the translated text and thus eachsubsequent translation provides results more andmore different from the original.
The secondmost important reason is the lack of translatorsfrom the pivot to the target language, while this isusually no problem for the translation from thesource directly to the target language.2.2 Translation memory is the keyThe main goal of this paper is to suggest how toovercome these obstacles by means of acombination of an MT system with commercialMAHT (Machine-aided human translation)systems.
We have chosen the TRADOSTranslator's Workbench as a representativesystem of a class of these products, which can becharacterized as an example-based translationtools.
IBM's Translation Manager and otherproducts also belong to this class.
Such systemsuses so-called translation memory, which containspairs of previously translated sentences from asource to a target language.
When a humantranslator starts translating a new sentence, thesystem tries to match the source with sentencesalready stored in the translation memory.
If it issuccessful, it suggests the translation and thehuman translator decides whether to use it, tomodify it or to reject it.The segmentation f a translation memory is a keyfeature for our system.
The translation memorymay be exported into a text file and thus allowseasy manipulation with its content.
Let us supposethat we have at our disposal two translationmemories - one human made for the source/pivotlanguage pair and the other created by an MTsystem for the pivot/target language pair.
Thesubstitution of segments of a pivot language bythe segments of a target language is then only aroutine procedure.
The human translatortranslating from the source language to the targetlanguage then gets a translation memory for therequired pair (source/target).
The system ofpenalties applied in TRADOS Translator'sWorkbench (or a similar system) guarantees that ifthere is already a human-made translation present,then it gets higher priority than the translationobtained as a result of the automatic MT.
Thissystem solves both problems mentioned above -the human translators from the pivot to the targetlanguage are not needed at all and the machine-made translation memory serves only as aresource supporting the direct human translationfrom the source to the target language.3.
Mach ine  t rans lat ion of  (very) closelyrelated Slavic languagesIn the group of Slavic languages, there are moreclosely related languages than Czech and Russian.Apart from the pair of Serbian and Croatianlanguages, which are almost identical and were9considered one language just a few years ago, themost closely related languages in this group areCzech and Slovak.This fact has led us to an experiment withautomatic translation between Czech and Slovak.It was clear that application of a similar methodto that one used in the system RUSLAN wouldlead to similar results.
Due to the closeness ofboth languages we have decided to apply asimpler method.
Our new system, (~ESILKO,aims at a maximal exploitation of the similarityof both languages.
The system uses the method ofdirect word-for-word translation, justified by thesimilarity of syntactic constructions of bothlanguages.Although the system is currently being tested ontexts from the domain of documentation tocorporate information systems, it is not limited toany specific domain.
Its primary task is, however,to provide support for translation and localizationof various technical texts.3.1 System (~ESiLKOThe greatest problem of the word-for-wordtranslation approach (for languages with verysimilar syntax and word order, but differentmorphological system) is the problem ofmorphological ambiguity of individual wordforms.
The type of ambiguity is slightly differentin languages with a rich inflection (majority ofSlavic languages) and in languages which do nothave such a wide variety of forms derived from asingle lemma.
For example, in Czech there areonly rare cases of part-of-speech ambiguities ( t~t\[to stay/the state\], zena \[woman/chasing\] or tri\[three/rub(imperative)\]), much more frequent isthe ambiguity of gender, number and case (forexample, the form of the adjective jam\[ \[spring\]is 27-times ambiguous).
The main problem is thateven though several Slavic languages have thesame property as Czech, the ambiguity is notpreserved.
It is distributed in a different mannerand the "form-for-form" translation is notapplicable.Without he analysis of at least nominal groups itis often very difficult to solve this problem,because for example the actual morphemiccategories of adjectives are in Czechdistinguishable only on the basis of gender,number and case agreement between an adjectiveand its governing noun.
An alternative way to thesolution of this problem was the application of astochastically based morphological disambiguator(morphological tagger) for Czech whose successrate is close to 92?/'0.
Our system therefore consistsof the following modules:1.
Import of the input from so-called 'empty'translation memory2.
Morphological analysis of Czech3.
Morphological disambiguation4.
Domain-related bilingual glossaries (incl.single- and multiword terminology)5.
General bilingual dictionary6.
Morphological synthesis of Slovak7.
Export of the output o the original translationmemoryLetus now look in a more detail at the individualmodules of the system:ad 1.
The input text is extracted out of atranslation memory previously exported into anASCII file.
The exported translation memory (ofTRADOS) has a SGML-Iike notation with arelatively simple structure (cf.
the followingexample):Example 1.
- A sample of the exported translationmemory<RTF Preamble>...</RTF Preamble><TrU><CrD>23051999<CrU>VK<Seg L=CS_01>Pomoci v~kazu ad-hoc m65eterychle a jednoduge vytv~i~et regerge.<Seg L=SK_01 >n/a</TrU>Our system uses only the segments marked by<Seg L=CS_01>, which contain one sourcelanguage sentence ach, and <Seg L=SK_01>,which is empty and which will later contain thesame sentence translated into the target languageby CESiLKO.ad 2.
The morphological analysis of Czech isbased on the morphological dictionary developedby Jan Haji6 and Hana Skoumalov~i in 1988-99(for latest description, see Haji~ (1998)).
Thedictionary contains over 700 000 dictionaryentries and its typical coverage varies between1099% (novels) to 95% (technical texts).
Themorphological analysis uses the system ofpositional tags with 15 positions (eachmorphological .category, such as Part-of-speech,Number, Gender, Case, etc.
has a fixed, single-symbol place in the tag).Example 2 - tags assigned to the word-form"pomoci" (help/by means of)pomoci:NFP2 .... .
.
A .... \]NFS7 ...... A ....
I R--2 .
.
.
.
.
.
.
.
.
.
.where :N - noun; R - prepositionF - feminine genderS - singular, P - plural7, 2 - case (7 - instrumental, 2 - genitive)A - affirmative (non negative)ad 3.
The module of morphologicaldisambiguation is a key to the success of  thetranslation.
It gets an average number of 3.58tags per token (word form in text) as an input.The tagging system is purely statistical, and ituses a log-linear model of probability distribution- see Haji~, Hladkfi (1998).
The learning is basedon a manually tagged corpus of Czech texts(mostly from the general newspaper domain).The system learns contextual rules (features)automatically and also automatically determinesfeature weights.
The average accuracy of taggingis between 91 and 93% and remains the sameeven for technical texts (if we disregard theunknown names and foreign-language t rms thatare not ambiguous anyway).The lemmatization immediately follows tagging;it chooses the first lemma with a possible tagcorresponding to the tag selected.
Despite thissimple lemmatization method, and also thanks tothe fact that Czech words are rarely ambiguous intheir Part-of-speech, it works with an accuracyexceeding 98%.ad 4.
The domain-related bilingual glossariescontain pairs of individual words and pairs ofmultiple-word terms.
The glossaries areorganized into a hierarchy specified by the user;typically, the glossaries for the most specificdomain are applied first.
There is one generalmatching rule for all levels of glossaries - thelongest match wins.The multiple-word terms are sequences of lemmas(not word forms).
This structure has severaladvantages, among others it allows to minimizethe size of the dictionary and also, due to thesimplicity of the structure, it allows modificationsof the glossaries by the linguistically naive user.The necessary morphological information isintroduced into the domain-related glossary in anoff-line preprocessing stage, which does notrequire user intervention.
This makes a bigdifference when compared to the RUSLANCzech-to-Russian MT system, when eachmultiword dictionary entry cost about 30 minutesof linguistic expert's time on average.ad 5.
The main bilingual dictionary contains datanecessary for the translation of  both lemmas andtags.
The translation of tags (from the Czech intothe Slovak morphological system) is necessary,because due to the morphological differences bothsystems use close, but slightly different tagsets.Currently the system handles the 1:1 translation oftags (and 2:2, 3:3, etc.).
Different ratio oftranslation is very rare between Czech and Siovak,but nevertheless an advanced system of dictionaryitems is under construction (for the translation 1:2,2:1 etc.).
It is quite interesting that the lexicallyhomonymous words often preserve theirhomonymy even after the translation, so nospecial treatment of homonyms is deemednecessary.ad 6.
The morphological synthesis of Slovak isbased on a monolingual dictionary of SIovak,developed by J.Hric (1991-99), covering morethan \]00,000 dictionary entries.
The coverage ofthe dictionary is not as high as of  the Czech one,but it is still growing.
It aims at a similar coverageof Slovak as we enjoy for Czech.ad 7.
The export of  the output of the system(~ESILKO into the translation memory (ofTRADOS Translator's Workbench) amountsmainly to cleaning of all irrelevant SGMLmarkers.
The whole resulting Slovak sentence isinserted into the appropriate location in theoriginal translation memory file.
The followingexample also shows that the marker <CrU>contains an information that the target languagesentence was created by an MT system.11Example 3.
-A  sample of the translation memorycontaining the results of MT<RTF Preamble>...</RTF Preamble><TrU><CRD>23051999<CrU>MT!<Seg L=CS_01>Pomoci v~kazu ad-hoc mfi~eterychle a jednodu~e vytv~i~et re,erie.<Seg L=SK_01>Pomoci v~kazov ad-hoc m6~eter~chio a jednoducho vytvhrat' re,erie.</TrU>3.2 Evaluation of resultsThe problem how to evaluate results of automatictranslation is very difficult.
For the evaluation ofour system we have exploited the closeconnection between our system and theTRADOS Translator's Workbench.
The methodis simple - the human translator eceives thetranslation memory created by our system andtranslates the text using this memory.
Thetranslator is free to make any changes to the textproposed by the translation memory.
The targettext created by a human translator is thencompared with the text created by the mechanicalapplication of translation memory to the sourcetext.
TRADOS then evaluates the percentage ofmatching in the same manner as it normallyevaluates the percentage of matching of sourcetext with sentences in translation memory.
Oursystem achieved about 90% match (as defined bythe TRADOS match module) with the results ofhuman translation, based on a relatively large(more than 10,000 words) test sample.4.
ConclusionsThe accuracy of the translation achieved by oursystem justifies the hypothesis that word-for-word translation might be a solution for MT ofreally closely related languages.
The remainingproblems to be solved are problems with the one-to many or many-to-many translation, where thelack of information in glossaries and dictionariessometimes causes an unnecessary translationerror.The success of the system CESILKO hasencouraged the investigation of the possibility touse the same method for other pairs of Slaviclanguages, namely for Czech-to-Polish translation.Although these languages are not so similar asCzech and Slovak, we hope that an addition of asimple partial noun phrase parsing might provideresults with the quality comparable to the full-fledged syntactic analysis based system RUSLAN(this is of course true also for the Czechoto-Slovaktranslation).
The first results of Czech-to Polishtranslation are quite encouraging in this respect,even though we could not perform as rigoroustesting as we did for Slovak.AcknowledgementsThis project was supported by the grant GAt~R405/96/K214 and partially by the grant GA(~R201/99/0236 and project of the Ministry ofEducation No.
VS96151.ReferencesB6movfi, Alevtina and Kubofi, Vladislav (1990).
Czech-to-Russian Transducing Dictionary; In: Proceedingsof the Xlllth COLING conference, Helsinki 1990Haji~, Jan (1998).
Building and Using a SyntactiallyAnnotated Coprus: The Prague DependencyTreebank.
In: Festschrifi for Jarmila Panevov~i,Karolinum Press, Charles Universitz, Prague.
pp.106---132.Haji~, Jan and Barbora Hladk~t (1998).
TaggingInflective Languages.
Prediction of MorphologicalCategories for a Rich, Structured Tagset.
ACL-Coling'98, Montreal, Canada, August 1998, pp.
483-490.Haji~, Jan; Brill, Eric; Collins, Michael; Hladk~tBarbora; Jones, Douglas; Kuo, Cynthia; Ramshaw,Lance; Schwartz, Oren; Tillman, Christoph; andZeman, Daniel: Core Natural Language ProcessingTechnology Applicable to Multiple Languages.
TheWorkshop'98 Final Report.
CLSP JHU.
Also at:http:llwww.clsp.jhu.edulws981projectslnlplreport.Kirschner, Zden~k (1987).
APAC3-2: An English-to-Czech Machine Translation System; ExpliziteBeschreibung der Sprache und automatischeTextbearbeitung XII1, MFF UK PragueOliva, Karel (1989).
A Parser for Czech Implementedin Systems Q; Explizite Beschreibung der Spracheund automatische Textbearbeitung XVI, MFF UKPrague12
