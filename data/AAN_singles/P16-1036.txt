Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 378?387,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsTogether We Stand: Siamese Networks for Similar Question RetrievalArpita Das1Harish Yenala1Manoj Chinnakotla2,1Manish Shrivastava11IIIT Hyderabad, Hyderabad, India{arpita.das,harish.yenala}@research.iiit.ac.inm.shrivastava@iiit.ac.in2Microsoft, Hyderabad, Indiamanojc@microsoft.comAbstractCommunity Question Answering (cQA)services like Yahoo!
Answers1, BaiduZhidao2, Quora3, StackOverflow4etc.provide a platform for interaction withexperts and help users to obtain preciseand accurate answers to their questions.The time lag between the user posting aquestion and receiving its answer couldbe reduced by retrieving similar historicquestions from the cQA archives.
Themain challenge in this task is the ?lexico-syntactic?
gap between the current and theprevious questions.
In this paper, we pro-pose a novel approach called ?SiameseConvolutional Neural Network for cQA(SCQA)?
to find the semantic similaritybetween the current and the archived ques-tions.
SCQA consist of twin convolu-tional neural networks with shared param-eters and a contrastive loss function join-ing them.SCQA learns the similarity metric forquestion-question pairs by leveraging thequestion-answer pairs available in cQA fo-rum archives.
The model projects semanti-cally similar question pairs nearer to eachother and dissimilar question pairs far-ther away from each other in the seman-tic space.
Experiments on large scale real-life ?Yahoo!
Answers?
dataset reveals thatSCQA outperforms current state-of-the-art approaches based on translation mod-els, topic models and deep neural network1https://answers.yahoo.com/2http://zhidao.baidu.com/3http://www.quora.com/4http://stackoverflow.com/based models which use non-shared pa-rameters.1 IntroductionThe cQA forums have emerged as popular andeffective means of information exchange on theWeb.
Users post queries in these forums and re-ceive precise and compact answers in stead of alist of documents.
Unlike in Web search, opinionbased queries are also answered here by expertsand users based on their personal experiences.
Thequestion and answers are also enhanced with richmetadata like categories, subcategories, user ex-pert level, user votes to answers etc.One of the serious concerns in cQA is?question-starvation?
(Li and King, 2010) wherea question does not get immediate answer fromany user.
When this happens, the question maytake several hours and sometimes days to get sat-isfactory answers or may not get answered at all.This delay in response may be avoided by re-trieving semantically related questions from thecQA archives.
If a similar question is found inthe database of previous questions, then the corre-sponding best answer can be provided without anydelay.
However, the major challenge associatedwith retrieval of similar questions is the lexico-syntactic gap between them.
Two questions maymean the same thing but they may differ lexicallyand syntactically.
For example the queries ?Whyare yawns contagious??
and ?Why do we yawnwhen we see somebody else yawning??
conveythe same meaning but differ drastically from eachother in terms of words and syntax.Several techniques have been proposed in theliterature for similar question retrieval and theycould be broadly classified as follows:1.
Classic Term Weighting Based Ap-proaches: Classical IR based retrieval378models like BM25 (Robertson et al, 1994)and Language modeling for InformationRetrieval (LMIR) (Zhai and Lafferty, 2004)score the similarity based on the weightsof the matching text terms between thequestions.2.
Translation Models: Learning wordor phrase level translation models fromquestion-answer pairs in parallel corpora ofsame language (Jeon et al, 2005; Xue etal., 2008; Zhou et al, 2011).
The similarityfunction between questions is then defined asthe probability of translating a given questioninto another.3.
Topic Models: Learning topic models fromquestion-answer pairs (Ji et al, 2012; Caiet al, 2011; Zhang et al, 2014).
Here, thesimilarity between questions, is defined inthe latent topic space discovered by the topicmodel.4.
Deep Learning Based Approaches: DeepLearning based models like (Zhou et al,2016),(Qiu and Huang, 2015), (Das et al,2016) use variants of neural network archi-tectures to model question-question pair sim-ilarity.Retrieving semantically similar questions can bethought of as a classification problem with largenumber of categories.
Here, each category con-tains a set of related questions and the numberof questions per category is small.
It is possiblethat given a test question, we find that there are noquestions semantically related to it in the archives,it will belong to a entirely new unseen category.Thus, only a subset of the categories is known dur-ing the time of training.
The intuitive approach tosolve this kind of problem would to learn a simi-larity metric between the question to be classifiedand the archive of previous questions.
Siamesenetworks have shown promising results in suchdistance based learning methods (Bromley et al,1993; Chopra et al, 2005).
These networks pos-sess the capability of learning the similarity metricfrom the available data, without requiring specificinformation about the categories.In this paper, we propose a novel unified modelcalled Siamese Convolutional Neural Network forcQA.
SCQA architecture contain deep convolu-tional neural networks as twin networks with acontrastive energy function at the top.
These twinnetworks share the weights with each other (pa-rameter sharing).
The energy function used is suit-able for discriminative training for Energy-Basedmodels (LeCun and Huang, 2005).
SCQA learnsthe shared model parameters and the similaritymetric by minimizing the energy function connect-ing the twin networks.
Parameter sharing guar-antees that question and its relevant answer arenearer to each other in the semantic space whilethe question and any answer irrelevant to it arefar away from each other.
For example, the rep-resentations of ?President of USA?
and ?BarackObama?
should be nearer to each other than thoseof ?President of USA?
and ?Tom Cruise livesin USA?.
The learnt similarity metric is used toretrieve semantically similar questions from thearchives given a new posted question.Similar question pairs are required to trainSCQA which is usually hard to obtain in largenumbers.
Hence, SCQA overcomes this limita-tion by leveraging Question-Answer pairs (Q,A)from the cQA archives.
This also has additionaladvantages such as:?
The knowledge and expertise of the answer-ers and askers usually differ in a cQA fo-rum.
The askers, who are novices or non-experts, usually use less technical terminol-ogy whereas the answerers, who are typicallyexperts, are more likely to use terms whichare technically appropriate in the given realmof knowledge.
Due to this, a model whichlearns from Question-Answer (Q,A) train-ing data has the advantage of learning map-pings from non-technical and simple termsto technical terms used by experts such asshortsight => myopia etc.
This advan-tage will be lost if we learn from (Q,Q) pairswhere both the questions are posed by non-experts only.?
Experts usually include additional topics thatare correlated to the question topic which theoriginal askers may not even be aware of.For example, for the question ?how can Iovercome short sight?
?, an expert may givean answer containing the concepts ?lasersurgery?, ?contact lens?, ?LASIK surgery?etc.
Due to this, the concept short sight getsassociated with these expanded concepts aswell.
Since, the askers are non-experts, such379rich concept associations are hard to learnfrom (Q,Q) training archives even if theyare available in large scale.
Thus, leveraging(Q,A) training data leads to learning richerconcept/term associations in SCQA.In summary, the following are our main contri-butions in this paper:?
We propose a novel model SCQA basedon Siamese Convolutional Neural Networkwhich use shared parameters to learn the sim-ilarity metric between question-answer pairsin a cQA dataset.?
In SCQA, we overcome the non-availabilityof training data in the form of question-question pairs by leveraging existingquestion-answer pairs from the cQA archiveswhich also helps in improving the effective-ness of the model.?
We reduce the computational complexity bydirectly using character-level representationsof question-answer pairs in stead of us-ing sentence modeling based representationswhich also helps in handling spelling errorsand out-of-vocabulary (OOV) words in docu-ments.The rest of the paper is organized as follows.
Sec-tion 2 presents the previous approaches to conquerthe problem.
Section 3 describes the architectureof SCQA.
Sections 4 and 5 explain the trainingand testing phase of SCQA respectively.
Section6 introduces a variant of SCQA by adding tex-tual similarity to it.
Section 7 describes the experi-mental set-up, details of the evaluation dataset andevaluation metrics.
In Section 8, quantitative andqualitative results are presented.
Finally, Section9 concludes the paper.2 Related WorkThe classical retrieval models BM25 (Robertsonet al, 1994), LMIR (Zhai and Lafferty, 2004) donot help much to capture semantic relatedness be-cause they mainly consider textual similarity be-tween queries.
Researchers have used translationbased models to solve the problem of question re-trieval.
Jeon et al (2005) leveraged the similar-ity between the archived answers to estimate thetranslation probabilities.
Xue et al (2008) en-hanced the performance of word based translationmodel by combining query likelihood languagemodel to it.
Zhou et al (2011) used phrase basedtranslation model where they considered questionanswer pairs as parallel corpus.
However, Zhanget al (2014) stated that questions and answerscannot be considered parallel because they are het-erogeneous in lexical level and in terms of user be-haviors.
To overcome these vulnerabilities topicmodeling was introduced by (Ji et al, 2012; Caiet al, 2011; Zhang et al, 2014).
The approachassumes that questions and answers share somecommon latent topics.
These techniques matchquestions not only on a term level but also on atopic level.Zhou et al (2015) used a fisher kernel to modelthe fixed size representation of the variable lengthquestions.
The model enhances the embeddingof the questions with the metadata ?category?
in-volved with them.
Zhang et al (2016) learntrepresentations of words and question categoriessimultaneously and incorporated the learnt repre-sentations into traditional language models.Following the recent trends, deep learning isalso employed to solve this problem.
Qiu et al(2015) introduced convolutional neural tensor net-work (CNTN), which combines sentence model-ing and semantic matching.
CNTN transforms theword tokens into vectors by a lookup layer, thenencode the questions and answers to fixed-lengthvectors with convolutional and pooling layers, andfinally model their interactions with a tensor layer.Das et al (2016) used deep structured topic mod-eling that combined topic model and paired con-volutional networks to retrieve related questions.Zhou et al (2016) used a deep neural network(DNN) to map the question answer pairs to a com-mon semantic space and calculated the relevanceof each answer given the query using cosine simi-larity between their vectors in that semantic space.Finally they fed the learnt semantic vectors into alearning to rank (LTR) framework to learn the rel-ative importance of each feature.On a different line of research, severalTextual-based Question Answering (QA) systems(Qanda5, QANUS6, QSQA7etc.)
are developedthat retrieve answers from the Web and other tex-tual sources.
Similarly, structured QA systems5http://www.openchannelfoundation.org/projects/Qanda/6http://www.qanus.com/7http://www.dzonesoftware.com/products/open-source-question-answer-software/380F(Q)Convolutional NeuralNetworkF(A)Convolutional NeuralNetworkW|| F(Q) - F(A)  ||SQ AF(Q) F(A)Figure 1: Architecture of Siamese network.
(Aqualog8, NLBean9etc.)
obtain answers fromstructured information sources with predefined on-tologies.
QALL-ME Framework (Ferrandez et al,2011) is a reusable multilingual QA architecturebuilt using structured data modeled by an ontol-ogy.
The reusable architecture of the system maybe utilized later to incorporate multilingual ques-tion retrieval in SCQA.2.1 Siamese Neural NetworkSiamese Neural Networks (shown in Figure 1)were introduced by Bromley et al (1993) tosolve the problem of signature verification.
Later,Chopra et al (2005) used the architecture withdiscriminative loss function for face verification.Recently these networks are used extensively toenhance the quality of visual search (Liu et al,2008; Ding et al, 2008).Let, F (X) be the family of functions with set ofparameters W .
F (X) is assumed to be differen-tiable with respect to W .
Siamese network seeksa value of the parameter W such that the symmet-ric similarity metric is small if X1and X2belongto the same category, and large if they belong todifferent categories.
The scalar energy functionS(Q,A) that measures the semantic relatednessbetween question answer pair (Q,A) can be de-fined as:S(Q,A) = ?F (Q)?
F (A)?
(1)In SCQA question and relevant answer pairs arefed to train the network.
The loss function is min-imized so that S(Q,A) is small if the answer A isrelevant to the question Q and large otherwise.8http://technologies.kmi.open.ac.uk/aqualog/9http://www.markwatson.com/opensource/Figure 2: Architecture of SCQA.
The network consists of repe-ating convolution, max pooling and ReLU layers and a fully co-nnected layer.
Also the weights W1to W5are shared betweenthe sub-networks.3 Architecture of SCQAAs shown in Figure 2, SCQA consists of apair of deep convolutional neural networks (CNN)with convolution, max pooling and rectified lin-ear (ReLU) layers and a fully connected layer atthe top.
CNN gives a non linear projection of thequestion and answer term vectors in the seman-tic space.
The semantic vectors yielded are con-nected to a layer that measures distance or simi-larity between them.
The contrastive loss functioncombines the distance measure and the label.
Thegradient of the loss function with respect to theweights and biases shared by the sub-networks,is computed using back-propagation.
StochasticGradient Descent method is used to update the pa-rameters of the sub-networks.3.1 Inputs to SCQAThe size of training data used is in millions, thusrepresenting every word with one hot vector wouldbe practically infeasible.
Word hashing introducedby Mcnamee et al (2004) involves letter n-gramto reduce the dimensionality of term vectors.
For aword, say, ?table?
represented as (#table#) where# is used as delimiter, letter 3-grams would be #ta,tab, abl, ble, le#.
Thus word hashing is charac-ter level representation of documents which takescare of OOV words and words with minor spellingerrors.
It represents a query using a lower di-mensional vector with dimension equal to num-ber of unique letter trigrams in the training dataset(48,536 in our case).The input to the twin networks of SCQA areword hashed term vectors of the question and381answer pair and a label.
The label indicateswhether the sample should be placed nearer or far-ther in the semantic space.
For positive samples(which are expected to be nearer in the semanticspace), twin networks are fed with word hashedvectors of question and relevant answers whichare marked as ?best-answer?
or ?most voted an-swers?
in the cQA dataset of Yahoo!
Answers(question-relevant answer pair).
For negative sam-ples (which are expected to be far away from eachother in the semantic space), twin networks are fedwith word hashed vectors of question and answerof any other random question from the dataset(question-irrelevant answer pair).3.2 ConvolutionEach question-answer pair is word hashed into (qi-ai) such that qi?Rntand ai?Rntwhere ntis thetotal number of unique letter trigrams in the train-ing data.
Convolution layer is applied on the wordhashed question answer vectors by convolving afilter with weights c ?
Rhxwwhere h is the filterheight and w is the filter width.
A filter consistingof a layer of weights is applied to a small patch ofword hashed vector to get a single unit as output.The filter is slided across the length of vector suchthat the resulting connectivity looks like a series ofoverlapping receptive fields which output of widthw.3.3 Max PoolingMax pooling performs a kind of non-linear down-sampling.
It splits the filter outputs into small non-overlapping grids (larger grids result to greater thesignal reduction), and take the maximum value ineach grid as the value in the output of reduced size.Max pooling layer is applied on top of the outputgiven by convolutional network to extract the cru-cial local features to form a fixed-length featurevector.3.4 ReLUNon-linear function Rectified linear unit (ReLU)is applied element-wise to the output of max pool-ing layer.
ReLU is defined as f(x) = max(0, x).ReLU is preferred because it simplifies backprop-agation, makes learning faster and also avoids sat-uration.3.5 Fully Connected layerThe terminal layer of the convolutional neural sub-networks is a fully connected layer.
It converts theoutput of the last ReLU layer into a fixed-lengthsemantic vector s ?
Rnsof the input to the sub-network.
We have empirically set the value of nsto 128 in SCQA.4 TrainingWe train SCQA for a question while looking forsemantic similarity with the answers relevant to it.SCQA is different from the other deep learningcounterparts due to its property of parameter shar-ing.
Training the network with a shared set of pa-rameters not only reduces number of parameters(thus, save lot of computations) but also ensuresconsistency of the representation of questions andanswers in semantic space.
The shared parametersof the network are learnt with the aim to minimizethe semantic distance between the question and therelevant answers and maximize the semantic dis-tance between the question and the irrelevant an-swers.Given an input {qi, ai} where qiand aiare theithquestion answer pair, and a label yiwith yi?
{1,-1}, the loss function is defined as:loss(qi, ai) ={1?
cos(qi, ai), if y = 1;max(0, cos(qi, ai)?m), if y = ?1;where m is the margin which decides by howmuch distance dissimilar pairs should be movedaway from each other.
It generally varies be-tween 0 to 1.
The loss function is minimized suchthat question answer pairs with label 1 (question-relevant answer pair) are projected nearer to eachother and that with label -1 (question-irrelevant an-swer pair) are projected far away from each otherin the semantic space.
The model is trained byminimizing the overall loss function in a batch.The objective is to minimize :L(?)
=?
(qi,ai)?C?C?loss(qi, ai) (2)where C contains batch of question-relevantanswer pairs and C?contain batch of question-irrelevant answer pairs.
The parameters shared bythe convolutional sub-networks are updated usingStochastic Gradient escent (SGD).5 TestingWhile testing, we need to retrieve similar ques-tions given a query.
During testing we make pairsof all the questions with the query and feed them382to SCQA.
The term vectors of the question pairsare word hashed and fed to the twin sub-networks.The trained shared weights of the SCQA projectsthe question vector in the semantic space.
Thesimilarity between the pairs is calculated usingthe similarity metric learnt during the training.Thus SCQA outputs a value of distance measure(score) for each pair of questions.
The thresholdis dynamically set to the average similarity scoreacross questions and we output only those whichhave a similarity greater than the average similar-ity score.6 Siamese Neural Network with TextualSimilaritySCQA is trained using question-relevant an-swer pairs as positive samples and question-irrelevant answer pairs as negative samples.
Itpoorly models the basic text similarity becausein the (Q,A) training pairs, the answerers of-ten do not repeat the question words while pro-viding the answer.
For example: for the ques-tion ?Who is the President of the US?
?, theanswerer would just provide ?Barrack Obama?.Due to this, although the model learns thatpresident the US => Barrack Obama, thesimilarity for president => president wouldn?tbe much and hence needs to be augmented throughBM25 or some such similarity function.Though SCQA can strongly model semanticrelations between documents, it needs boosting inthe area of textual similarity.
The sense of wordbased similarity is infused to SCQA by usingBM25 ranking algorithm.
Lucene10is used to cal-culate the BM25 scores for question pairs.
Thescore from similarity metric of SCQA is com-bined with the BM25 score.
A new similarityscore is calculated by the weighted combinationof the SCQA and BM25 score as:score = ?
?
SCQAscore+ (1?
?)
?BM25score(3)where ?
control the weights given to SCQAand BM25 models.
It range from 0 to 1.
SCQAwith this improved similarity metric is calledSiamese Convolutional Neural Network for cQAwith Textual Similartity (T-SCQA).
Figure 4 de-picts the testing phase of T-SCQA.
This model willgive better performance in datasets with good mixof questions that are lexically and semantically10https://lucene.apache.org/Hyperparameter ValueBatch Size 100Depth of CNN 3Learning rate 0.01Momentum 0.05Kernel width of Convolution 10Kernel width of MaxPooling 100Length of semantic vector 128Table 1: Hyperparameters of SCQA.similar.
The value of ?
can be tuned accordingto the nature of dataset.7 ExperimentsWe collected Yahoo!
Answers dataset fromYahoo!
Labs Webscope11.
Each question inthe dataset contains title, description, best an-swer, most voted answers and meta-data likecategories, sub categories etc.
For trainingdataset, we randomly selected 2 million dataand extracted question-relevant answer pairs andquestion-irrelevant answer pairs from them to trainSCQA.
Similarly, our validation dataset contains400,000 question answer pairs.
The hyperparam-eters of the network are tuned on the validationdataset.
The values of the hyperparameters forwhich we obtained the best results is shown in Ta-ble 1.We used the annotated survey dataset of 1018questions released by Zhang et al (2014) as testsetfor all the models.
On this gold data, we evaluatedthe performance of the models with three eval-uation criteria: Mean Average Precision (MAP),Mean Reciprocal Rank (MRR) and Precision at K(P@K).Each question and answer was pre-processedby lower-casing, stemming, stopword and specialcharacter removal.7.1 Parameter SharingIn order to find out whether parameter sharinghelps in the present task we build two modelsnamed Deep Structured Neural Network for Com-munity Question Answering(DSQA) and DeepStructured Neural Network for Community Ques-tion Answering with Textual Similarity T-DSQA.DSQA and T-DSQA have the same architectureas SCQA and T-SCQA with the exception that in11http://webscope.sandbox.yahoo.com/catalog.php?datatype=l3830.70.750.80.850.90.9510 20 30 40 50 60 70 80ValueofEvaluationMetricEpoch NumberMAPMRRP@1Figure 3: Variation of evaluation metrics with the epochs.the former models weights are not shared by theconvolutional sub-networks.
The weightage ?
forcontrolling corresponding scores of SCQA andBM25 for the model T-SCQA was tuned on thevalidation set.8 ResultsWe did a comparative study of the results of theprevious methods with respect to SCQA and T-SCQA.
The baseline performance is shown byquery likelihood language model (LM).
For thetranslation based methods translation(word),translation+LM and translation(phrase) weimplemented the papers by Jeon et al (2005),Xue et al (2008), Zhou et al (2011) respec-tively.
The first paper deals with word based trans-lation, the second enhanced the first by adding lan-guage model to it and the last paper implementsphrase based translation method to bridge lexi-cal gap.
As seen from Table 2, the translationbased methods outperforms the baseline signifi-cantly.
The models are trained using GIZA++12tool with the question and best answer pair as theparallel corpus.
For the topic based Q-A topicmodel and Q-A topic model(s), we implementedthe models QATM -PR (Question-Answer TopicModel) Ji et al(2012) and TBLMSQATM?V(Su-pervised Question-Answer Topic Model with uservotes as supervision) Zhang et al (2014) respec-tively.
Again it is visible from the Table 2 thattopic based approaches show slight improvementover translation based methods but they show sig-nificant improvement over baseline.
The mod-12http://www.statmt.org/moses/giza/GIZA++.htmlMethod MAP MRR P@1LMIR 0.762 0.844 0.717translation(word) 0.786 0.870 0.807translation+LM 0.787 0.869 0.804translation(phrase) 0.789 0.875 0.817Q-A topic model 0.787 0.879 0.810Q-A topic model(s) 0.800 0.888 0.820DSQA 0.755 0.921 0.751T-DSQA 0.801 0.932 0.822SCQA 0.811 0.895 0.830T-SCQA 0.852?0.934?0.849?Table 2: Results on Yahoo!
Answers dataset.
The best re-sults are obtained by T-SCQA (bold faced).
The differencebetween the results marked(*) and other methods are statisti-cally significant with p <0.001.els DSQA and T-DSQA were built using convo-lutional neural sub-networks joined by a distancemeasure at the top.
There is no sharing of parame-ters involved between the sub-networks of thesemodels.
It is clear from the comparison of re-sults between T-DSQA and T-SCQA that param-eter sharing definitely helps in the task of similarquestion retrieval in cQA forums.
T-SCQA outper-forms all the previous approaches significantly.8.1 Quantitative AnalysisSCQA and T-SCQA learns the semantic relation-ship between the question and their best and mostvoted answers.
It is observed that by varying theweights of SCQA andBM25 scores, the value ofMAP changes significantly (Figure 5).
The weightis tuned in the validation dataset.
We trained ourmodel for several epochs and observed how theresults varied with the epochs.
We found thatthe evaluation metrics changed with increasingthe number of epochs but became saturated afterepoch 60.
The comparison of evaluation metricswith epochs can be visualised in Figure 3.The comparisons SCQA and T-SCQA with thepreviously proposed models is shown in Table 2.For baseline we considered the traditional lan-guage model LMIR.
The results in the table areconsistent with the literature which says transla-tion based models outperform the baseline meth-ods and topic based approaches outperform thetranslational methods.
Also, it is observed thatdeep learning based solution with parameter shar-ing is more helpful for this task than without pa-rameter sharing.
Note, that the results of previousmodels stated in Table 2 differ from the original384Distance MetricWqririjqTextual matching+BM25 ScoreConvolution Max pooling ReLU Fully Connected LayerConvolution Max pooling ReLU Fully Connected LayerFinal ScoreSCQA ScoreFigure 4: Testing phase of T-SCQA.
Here the qiis the ithquery and rijis the jthquestion retrieved by qi.
The twin CNNnetworks share the parameters (W) with each other.
The connecting distance metric layer outputs the SCQA score and thetextual matching module outputs the BM25 score.
The weighted combination of these scores give the final score.
rijis statedsimilar to the query qiif the final score of the pair exceeds an appropriate threshold.Figure 5: The variation of MAP with ?.papers since we tried to re-implement those mod-els with our training data (to the best of our capa-bility).
Though we use the test data released byZhang et al (2014) we do not report their resultsin Table 2 due to the difference in training dataused to train the models.In the test dataset released by Zhang et al(2014), there are fair amount of questions that pos-sess similarity in the word level hence T-SCQAperformed better than SCQA for this dataset.
T-SCQA gives the best performance in all evaluationmeasures.
The results of T-SCQA in Table 2 usesthe trained model at epoch 60 with the value of ?as 0.8.8.2 Qualitative AnalysisIn Table 3 few examples are shown to depict howresults of T-SCQA reflect strong semantic infor-mation when compared to other baseline methods.For Q1 we compare performance of LMIR and T-SCQA.
LMIR outputs the question by consider-ing word based similarity.
It focuses on match-ing the words ?how?, ?become?, ?naturally?
etc,hence it outputs ?How can I be naturally funny?
?which is irrelevant to the query.
On the other hand,T ?SCQA retrieves the questions that are seman-tically relevant to the query.
For Q2 we comparethe performance of T-SCQA with phrase basedtranslation model (Zhou et al, 2011).
The out-puts of translation(phrase) model shows that thetranslation of ?nursery?
and ?pre-school?
to ?day-care?, ?going to university?
to ?qualifications?
arehighly probable.
The questions retrieved are se-mantically related, however asking craft ideas forpre-school kids for the event of mother?s day is ir-relevant in this context.
The results of our modelsolely focuses on the qualifications, degrees andskills one needs to work in a nursery.
For Q3 wecompare the performance of T-SCQA with super-vised topic model (Zhang et al, 2014).
The ques-tions retrieved by both the models revolve aroundthe topic ?effect of smoking on children?.
Whilethe topic model retrieve questions which deal withsmoking by mother and its effect on child, T-SCQA retrieve questions which deals not only withthe affects of a mother smoking but also the effectof passive smoking on the child.
For Q4 we com-385Query CommentQ1: How can I become naturally happy?LMIR 1.How can I be naturally happy?
LMIR performs2.How can I become naturally funny?
word based1.Are some of us naturally born happy or do we learn how to matching usingT-SCQA become happy?
?how?,?become?,2.How can I become prettier and feel happier with myself?
?naturally?
etc.Q2: Do you need to go to university to work in a nursery or pre-school?
For translationtranslation 1.What degree do you need to work in a nursery?
(phrase)(phrase) 2.
I work at a daycare with pre-school kids(3-5).
Any ideas on university->degreecrafts for mother?s day?
nursery->daycare1.Will my B.A hons in childhood studies put me in as an are highly probableunqualified nursery nurse?
translations but craftT-SCQA 2.What skills are needed to work in a nursery, or learned from ideas for daycareworking in a nursery?
is irrelevant.Q3: Does smoking affect an unborn child?
Both modelsQ-A topic 1.How do smoking cigarettes and drinking affect an unborn retrieve questionsmodel(s) child?
on topic ?effect of2.How badly will smoking affect an unborn child?
smoking on children?1.How does cigarette smoking and alcohol consumption by but T-SCQA couldmothers affect unborn child?
retrieve based onT-SCQA 2.Does smoking by a father affect the unborn child?
If there passive smokingis no passive smoking, then is it still harmful?
through father.Q4: How do I put a video on YouTube?
T-DSQA could not1.How can I download video from YouTube and put them decipher ?put?.T-DSQA on my Ipod?
It relates ?put?
to2.I really want to put videos from YouTube to my Ipod..how?
download and1.How do I post a video on YouTube?
transfer of videosT-SCQA 2.How can I make a channel on YouTube and upload videos while T-SCQA relateson it?
plz help me... it to uploading videos.Table 3: This table compares the qualitative performance of T-SCQA with LMIR, phrase based translation model transla-tion(phrase), supervised topic model Q-A topic model(s) and deep semantic model without parameter sharing T-DSQA.
Forqueries Q1-4 T-SCQA show better performance than the previous models .pare the performance of T-SCQA with T-DSQA.
T-DSQA retrieves the questions that are related todownloading and transferring YouTube videos toother devices.
Thus, T-DSQA cannot clearly clar-ify the meaning of ?put?
in Q4.
However, the re-trieved questions of T-SCQA are more aligned to-wards the ways to record videos and upload themin YouTube.
The questions retrieved by T-SCQAare semantically more relevant to the query Q4.9 ConclusionsIn this paper, we proposed SCQA for similarquestion retrieval which tries to bridge the lexico-syntactic gap between the question posed by theuser and the archived questions.
SCQA employstwin convolutional neural networks with sharedparameters to learn the semantic similarity be-tween the question and answer pairs.
Interpo-lating BM25 scores into the model T-SCQA re-sults in improved matching performance for bothtextual and semantic matching.
Experiments onlarge scale real-life ?Yahoo!
Answers?
dataset re-vealed that T-SCQA outperforms current state-of-the-art approaches based on translation models,topic models and deep neural network based mod-els which use non-shared parameters.As part of future work, we would like to en-hance SCQA with the meta-data information likecategories, user votes, ratings, user reputation ofthe questions and answer pairs.
Also, we wouldlike to experiment with other deep neural archi-tectures such as Recurrent Neural Networks, LongShort Term Memory Networks, etc.
to form thesub-networks.386ReferencesJane Bromley, James W Bentz, L?eon Bottou, Is-abelle Guyon, Yann LeCun, Cliff Moore, EduardS?ackinger, and Roopak Shah.
1993.
Signature ver-ification using a siamese time delay neural network.IJPRAI.Li Cai, Guangyou Zhou, Kang Liu, and Jun Zhao.2011.
Learning the latent topics for question re-trieval in community QA.
IJCNLP.Sumit Chopra, Raia Hadsell, and Yann LeCun.
2005.Learning a similarity metric discriminatively, withapplication to face verification.
CVPR.Arpita Das, Manish Shrivastava, and Manoj Chin-nakotla.
2016.
Mirror on the wall: Finding sim-ilar questions with deep structured topic modeling.Springer.Shilin Ding, Gao Cong, Chin-Yew Lin, and XiaoyanZhu.
2008.
Using conditional random fields to ex-tract contexts and answers of questions from onlineforums.
ACL.Oscar Ferrandez, Christian Spurk, Milen Kouylekov,Iustin Dornescu, Sergio Ferrandez, Matteo Negri,Ruben Izquierdo, David Tomas, Constantin Orasan,Guenter Neumann, et al 2011.
The qall-me frame-work: A specifiable-domain multilingual questionanswering architecture.
Web semantics.Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee.
2005.Finding similar questions in large question and an-swer archives.
CIKM.Zongcheng Ji, Fei Xu, Bin Wang, and Ben He.
2012.Question-answer topic model for question retrievalin community question answering.
CIKM.Yann LeCun and Fu Jie Huang.
2005.
Loss functionsfor discriminative training of energy-based models.AISTATS.Baichuan Li and Irwin King.
2010.
Routing questionsto appropriate answerers in community question an-swering services.
CIKM.Yuanjie Liu, Shasha Li, Yunbo Cao, Chin-Yew Lin,Dingyi Han, and Yong Yu.
2008.
Understand-ing and summarizing answers in community-basedquestion answering services.
ICCL.Paul Mcnamee and James Mayfield.
2004.
Charac-ter n-gram tokenization for european language textretrieval.
Information retrieval.Xipeng Qiu and Xuanjing Huang.
2015.
Con-volutional neural tensor network architecture forcommunity-based question answering.
IJCAI.Stephen E Robertson, Steve Walker, Susan Jones,Micheline Hancock-Beaulieu, Mike Gatford, et al1994.
Okapi at trec-3.
NIST Special Publication.Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft.
2008.Retrieval models for question and answer archives.SIGIR.Chengxiang Zhai and John Lafferty.
2004.
A study ofsmoothing methods for language models applied toinformation retrieval.
ACM Trans.
Inf.
Syst.Kai Zhang, Wei Wu, Haocheng Wu, Zhoujun Li, andMing Zhou.
2014.
Question retrieval with highquality answers in community question answering.CIKM.Kai Zhang, Wei Wu, Fang Wang, Ming Zhou, andZhoujun Li.
2016.
Learning distributed represen-tations of data in community question answering forquestion retrieval.
ICWSDM.Guangyou Zhou, Li Cai, Jun Zhao, and Kang Liu.2011.
Phrase-based translation model for questionretrieval in community question answer archives.ACL:HLT.Guangyou Zhou, Tingting He, Jun Zhao, and Po Hu.2015.
Learning continuous word embedding withmetadata for question retrieval in community ques-tion answering.
ACL.Guangyou Zhou, Yin Zhou, Tingting He, and Wen-sheng Wu.
2016.
Learning semantic representa-tion with neural networks for community questionanswering retrieval.
Knowledge-Based Systems.387
