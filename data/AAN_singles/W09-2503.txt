Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 18?26,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPSub-sentential Paraphrasing by Contextual Pivot TranslationAure?lien MaxLIMSI-CNRSUniversite?
Paris-Sud 11Orsay, Franceaurelien.max@limsi.frAbstractThe ability to generate or to recognizeparaphrases is key to the vast majority ofNLP applications.
As correctly exploit-ing context during translation has beenshown to be successful, using context in-formation for paraphrasing could also leadto improved performance.
In this arti-cle, we adopt the pivot approach basedon parallel multilingual corpora proposedby (Bannard and Callison-Burch, 2005),which finds short paraphrases by findingappropriate pivot phrases in one or severalauxiliary languages and back-translatingthese pivot phrases into the original lan-guage.
We show how context can be ex-ploited both when attempting to find pivotphrases, and when looking for the mostappropriate paraphrase in the original sub-sentential ?envelope?.
This framework al-lows the use of paraphrasing units rangingfrom words to large sub-sentential frag-ments for which context information fromthe sentence can be successfully exploited.We report experiments on a text revisiontask, and show that in these experimentsour contextual sub-sentential paraphrasingsystem outperforms a strong baseline sys-tem.1 IntroductionThe ability to generate or to recognize paraphrasesis key to the vast majority of NLP applications.Most current research efforts on paraphrase gener-ation attempt to push the limits of their respectivemethods and resources without recourse to deepmeaning interpretation, an admitedly long-termresearch objective.
A step towards meaning-awareparaphrasing can be done by appropriate use of thecontext in which a paraphrasing occurrence oc-curs.
At the lowest level, deciding automaticallywhen a word can be substituted with a synonym isa complex issue (Connor and Roth, 2007).
Whenattempting paraphrasing on a higher level, such asarbitrary phrases or full sentences (Barzilay andLee, 2003; Pang et al, 2003; Quirk et al, 2004;Bannard and Callison-Burch, 2005; Zhao et al,2008a), a first issue concerns the acquisition of el-ementary units, which in the general case do notexist in predefined dictionaries.
Some paraphras-ing strategy must then follow, which may considerthe context of a substitution to guide the selectionof appropriate units (Callison-Burch, 2008; Max,2008).
An important limitation to this family ofworks is the scarcity of corpora that can be used asreliable supervised training data.
Indeed, strictlyparallel sentence pairs, for instance, are not nat-urally produced in human activities.1 As a con-sequence, works on paraphrasing have recourse tocostly human evaluation procedures, and an objec-tive of automatic evaluation metrics is to rely onas little gold standard data as possible (Callison-Burch et al, 2008).A text revision task is an application of para-phrase generation where context may be used inan effective way.
When a local change is made toa text, it occurs within a textual ?envelope?
withinwhich a paraphrase should fit.
In particular, if theoriginal sentence was grammatical, the substitutedsentence should remain grammatical and conveyessentially the same meaning.2 The manner inwhich such a context can be exploited dependsof course on the type of automatic paraphrasingtechnique used.
In this article, we adopt the pivot1Recent works such as (Nelken and Yamangil, 2008)have proposed mining the revision histories of collabora-tive authoring resources like Wikipedia, offering interestingprospects in paraphrasing and rewriting studies.2We posit here that the revision activity does not involveimportant semantic changes, as opposed to the rewriting ac-tivity.
In future work, we will attempt to consider cases ofparaphrasing involving meaning changes corresponding totextual entailment phenomena.18approach based on parallel multilingual corporaproposed by (Bannard and Callison-Burch, 2005),which finds short paraphrases by finding appropri-ate pivot phrases in one or several auxiliary lan-guages and back-translating these pivot phrasesinto the original language.
We show how con-text can be exploited both when attempting to findpivot phrases, and when looking for the most ap-propriate paraphrase in the original sub-sententialenvelope.
This framework allows the use of para-phrasing units ranging from words to large sub-sentential fragments for which context informa-tion from the sentence can be successfully ex-ploited.This article is organized as follows.
In section 2,we briefly review related work in paraphrasing andcontext-aware Machine Translation.
We describethe main characteristics of our approach to sub-sentential paraphrasing in section 3.
We then de-scribe an evaluation protocol for evaluating ourproposal and report the results of a human evalua-tion in section 4.
We finally conclude and presentour future work in section 5.2 Related workDifferent sources have been considered for para-phrase acquisition techniques.
(Pang et al, 2003),for example, apply syntactic fusion to multipletranslations of individual sentences.
(Barzilay andLee, 2003; Dolan et al, 2004) acquire short para-phrases from comparable corpora, while (Bha-gat and Ravichandran, 2008) considered the is-sue of acquiring short paraphrase patterns fromhuge amounts of comparable corpora.
(Bannardand Callison-Burch, 2005) introduced a pivot ap-proach to acquire short paraphrases from multi-lingual parallel corpora, a resource much morereadily available than their monolingual counter-part.
(Zhao et al, 2008b) acquire paraphrase pat-terns from bilingual corpora and report the vari-ous types obtained.3 (Callison-Burch, 2008) im-proves the pivot paraphrase acquisition techniqueby using syntactic constraints at the level of con-stituents during phrase extraction.
This works alsouses syntactic constraints during phrase substitu-tion, resulting in improvements in both grammat-3The types of their paraphrase patterns are the follow-ing (numbers in parentheses indicate frequency in theirdatabase): phrase replacements (267); trivial changes (79);structural paraphrases (71); phrase reorderings (56); and ad-dition of deletion of information that are claimed to not altermeaning (27).icality and meaning preservation in a large-scaleexperiment on English.
(Max, 2008) explored theuse of syntactic dependency preservation duringphrase substitution on French.This family of works considered the acquisi-tion of short paraphrases and their use in localparaphrasing of known units.
Several works havetackled full sentence paraphrasing as a monolin-gual translation task relying on Statistical Ma-chine Translation (SMT).
For instance, (Quirk etal., 2004) used a phrase-based SMT decoder thatuses local paraphrases acquired from compara-ble corpora to produce monotone sentential para-phrases.
(Zhao et al, 2008a) acquired monolin-gual biphrases from various sources and used themwith a phrase-based SMT decoder, and (Madnaniet al, 2007) combined rules of their hierarchicaldecoders by pivot to obtain a monolingual gram-mar.
These works were not motivated by the gen-eration of high-quality paraphrases that could, forexample, be reused in documents.
The lack ofstructural information, the local nature of the para-phrasing performed and the fact that the context ofthe original sentences was not taken into accountin the phrase-based approaches make it difficult tocontrol meaning preservation during paraphrasing.Context has been shown to play a crucial rolein Machine Translation, where in particular properWord Sense Disambiguation (WSD) is required inmany cases.
A variety of works have integratedcontext with some success into phrase-based andhierarchical decoders.
For example, (Carpuat andWu, 2007) disambiguate phrases using a state-of-the-art WSD classifier, and (Stroppa et al, 2007)use a global memory-based classifier to find ap-propriate phrase translations in context.
Contextis often defined as local linguistic features suchas surrounding words and their part-of-speech, butsome works have experimented with more syntac-tic features (e.g.
(Gimpel and Smith, 2008; Maxet al, 2008; Haque et al, 2009)).Using an intermediate pivot language withbilingual translation in which a given languagepair is low-resourced has led to improvementsin translation performance (Wu and Wang, 2007;Bertoldi et al, 2008), but to our knowledge this ap-proach has not been applied to full sentence para-phrasing.
Several reasons may explain this, in par-ticular the relative low quality of current MT ap-proaches on full sentence translation, and the diffi-culties in controlling what is paraphrased and how.193 Contextual pivot SMT forsub-sentential paraphrasingAlthough many works have addressed the issue oflocal paraphrase acquisition, effective use of suchparaphrases for paraphrase generation has only beachieved at the level of text units correspondingto short contiguous phrases.
Recent works haveproposed approaches to exploit context in orderto correctly replace a text fragment with a para-phrase, but they are limited to known text unitsand therefore suffer from a scarcity of data.4In this work, we address the case of sub-sentential paraphrase generation, an intermediatecase between local paraphrasing using text unitsfor which paraphrases are available and full sen-tence paraphrasing.
Data sparcity is addressed byusing a pivot translation mechanism, which canproduce back-translations for text fragments forwhich paraphrases cannot be acquired beforehandby some paraphrase acquisition technique.
Sub-sentential paraphrasing by pivot allows the ex-ploitation of context during both source-to-pivottranslation, where the source context is avail-able, and during pivot-to-source back-translation,where the target context is known.
The successof this approach is then directly dependent on theavailability of high quality MT engines and ontheir ability to exploit these source and target con-texts.3.1 Paraphrasing by pivot translationWhereas attempts at using two translation sys-tems in pivot have met with some success for low-resourced language pairs, it is unlikely that cur-rent SMT systems can be successfully called insuccession to obtain high-quality sentential para-phrases.5 Several works have shown that mono-lingual biphrases obtained by multilingual pivotscan be used by decoders, but although gains canfor example be obtained by using sentential para-phrases as alternative reference corpora for opti-mizing SMT systems (Madnani et al, 2007), re-sulting paraphrases seem to be of too low quality4Current approaches based on paraphrase patterns areonly a partial solution to this issue, as the variables used arelimited to simple types.5In particular, back-translation can introduce lexical er-rors due to incorrect word sense disambiguation and there-fore severely hamper understanding, as illustrated by the in-famous MT textbook example of the sentence The spirit iswilling but the flesh is weak being translated into Russian andback-translated into English as The vodka is good, but themeat is rotten.for most other possible application contexts.
Inthis work, we propose to use a pivot approach froma source language to a pivot language and back tothe source language, but for sub-sentential frag-ments.
In this way, the source context in whichthey occur can be exploited for both translatinginto the pivot language and for back-translatinginto the original language.
This is illustrated onFigure 1.Step (1) performs a N-best decoding (a singleexample is shown here) in which a segmentationof the source sentence is forced to ensure thata given fragment (mettre en danger la richessee?cologique in the example) is translated indepen-dently of its surrounding context.6 Only trans-lations which respect this segmentation are kept,yielding a variety of pivot sentences.
We aremostly interested in the pivot translation of ourparaphrased fragment, but its prefix and suffixpivot context can be exploited by contextual SMTto guide pivot-to-source translation, although thelower quality of automatically generated sentencesmight not help as much as before.Step (2) produces from each obtained N-besthypothesis a new N-best list of hypotheses, thistime in the source language.
The decoder is oncemore asked to use a given segmentation, and is fur-ther given imposed translations for the pivot pre-fix and suffix, as shown by the arrows going di-rectly from the sentence at the top to the sentenceat the bottom of Figure 1.
Step (2) can be fol-lowed by a reranking procedure on the obtainedN-best list of hypotheses, whose individual scorecan be obtained by combining the scores of thetwo translation hypotheses that led to it.
As op-posed to the pivot approach for phrases of (Ban-nard and Callison-Burch, 2005), it is not possi-ble to sum over all possible pivots for a givenpair ?original sentence, paraphrased sentence?, asthe search space would make this computation im-practical.
We can instead look for the paraphrasethat maximizes the product of the probabilities ofthe two translation steps according to the scoresproduced by the decoders used.A further step can eliminate paraphrases by ap-plying heuristics designed to define sought or un-desirable properties for paraphrases, although this6It is in fact incorrect to say that translation of the vari-ous fragments would take place independently of each other,as various models such as a source context models or targetlanguage models will use information from surrounding frag-ments.20Figure 1: Example of sub-sentential paraphrasing by contextual pivot translationcould be directly integrated in the reranking step.For example, we may not be interested by identityparaphrases, or by paraphrases including or beingincluded in the original fragment, or we may pre-fer paraphrases in which a given word has beenreplaced, etc.3.2 Source context for pivot SMTUsing the context of a phrase is necessary to trans-late it correctly, most notably when several wordsenses corresponding to distinct translations areinvolved.
The following examples show a case ofa polysemous English word, which can be trans-lated into three distinct French words and back-translated into various English fragments:?
Follow the instructions outlined below tosave that file.
?
sauvegarder ce fichier ?write the file on disk?
Quitting smoking is a sure-fire way to savesome money.
?
e?conomiser de l?argent ?have some money on your bank account?
Brown?s gamble may save the banks but theeconomy cannot wait.
?
sauver les banques?
salvage the banksOur approach for source context aware SMT,based on that of (Stroppa et al, 2007), is illus-trated by the system architecture on Figure 2.
Amemory-based classification approach was cho-sen as it allows for efficient training with largeexample sets, can handle any number of outputclasses and produces results that can be directlyused to estimate the required conditional probabil-ities.
We add context-informed features to the log-linear framework of our SMT system based on theconditional probability of a target phrase eigivena source phrase fiand its context, C(fi):hm(fi, C(fi), ei) = logP (ei|fi, C(fi))Figure 2: Architecture of our contextual phrase-based SMT system21Memory-based classification performs implicitsmoothing, which addresses in part the problemof data sparcity, which worsen with the inclu-sion of context features and makes direct estima-tion of those probabilities problematic.
Given afixed-length vector, ?fi, C(fi)?, a set of weightedclass labels corresponding to target phrases isreturned by the classifier, which give access toP (ei|fi, C(fi)) after normalization.Because each source phrase potentially occursin a unique context, they must be given a uniqueentry in the phrase table.
To this end, we addeda preprocessor component whose role is to dy-namically build a modified source file containingunique tokens and to produce a modified trans-lation table containing those tokens.
Phrase ex-traction uses both phrase alignment results andlinguistic analysis of the source corpus to pro-duce standard biphrases and biphrases with con-textual information.
The latter are used to train thememory-based classifier.
The source file under-goes the same linguistic analysis whose output isthen aligned to unique tokens (e.g.
president@45),and each possible phrase which is also present inthe standard translation table is classified using itscontext information.
The output is used to create aset of entries in the contextual translation tables, inwhich a new score corresponding to our context-based feature are added.Most existing context-aware SMT approachesrely on context features from the immediate con-text of a source phrase.
In this work, we initiallyrestricted ourselves to a limited set of features: upto two lemmas to the left and to the right of a seg-ment and their part-of-speech.73.3 Target context for pivot SMTWhen decoding from the pivot hypothesis, weforce our decoder to use provided sentence pre-fix and suffix corresponding to the ?envelope?
ofthe original fragment.
Target context will thus betaken into account by the decoder.Furthermore, based on the hypothesis that aparaphrase for an unmodified envelope should pre-serve the syntactic dependencies between the para-phrased fragment and its envelope (inter-fragmentdependencies), we optionaly add a ?hard?
rerank-ing step where we filter the N-best list of hypothe-7We will integrate richer syntactic context as in (Gimpeland Smith, 2008; Max et al, 2008) in our short-term futurework, as we expect it to be particularly useful for our para-phrasing task.ses to keep only those which preserve these depen-dencies.
Note however that for a dependency to bemarked as preserved, we only need to find its labeland its target word in the envelope (governor or de-pendent), as the word in the paraphrased fragmentmight have changed.
This of course has practicalimplications on the nature of the paraphrases thatcan be produced.In part due to various deficiencies of phrasealignments discussed in (Callison-Burch, 2008),we further apply heuristics to filter out some un-desirable paraphrase candidates.
Our current setof heuristics includes:?
no reordering should have taken place be-tween the original source phrase and its con-text8;?
considering the set of full word lemmas forthe original fragment and the paraphrasedfragment, at least one lemma should not be-long to both sets9;?
neither the original fragment nor its para-phrase must be included into the other (onlytaking full words into account).4 ExperimentsWe have conducted experiments motivated by atext revision task that we report in this sectionby describing our baseline and context-aware sub-sentential paraphrasing systems and the results ofa small-scale manual evaluation.4.1 Data and systemsWe built two-way French-English SMT sys-tems using 188,115 lines of the Europarl cor-pus (Koehn, 2005) of parliamentary debates withmoses (Koehn et al, 2007) 10.
Our corpus wasanalyzed by the XIP robust parser (A?
?t-Mokhtaret al, 2002) and its output tokenization was used.We built standard systems, as well as a contextualsystem for French?English as described in sec-tion 3.2 using an additional contextual score ob-8Reordering is allowed in the paraphrased fragment.9As a consequence, minimal paraphrases may differ byonly one full word.
This can however be used advantageouslywhen the sought type of paraphrasing aims at ?normalizing?a text fragment and when the most appropriate rewording isvery similar to an original text fragment.10We used revision 2234 available on the moses SVN web-site: http://mosesdecoder.sourceforge.net/svn.php.
In particular, it allows the use of XML annota-tions to guide the translation of particular fragments.22Baseline fr?en 30.56Contextual fr?en 31.17Baseline en?fr 32.10Table 1: BLEU scores for the translation systemsused by our paraphrasing systemtained through memory-based classification per-formed with the TiMBL package (Daelemans etal., 2007).
Standard MERT was used to optimizemodel weights.
BLEU scores for the three systemsare reported on Table 1.
The contextual systemobtains a slightly higher score than the baselinesystem, which can participate to some extent to abetter exploitation of context for paraphrasing.11Two paraphrasing systems we built: Sbasis abaseline system which uses standard phrase tablesand post-filtering heuritics, but does not includereranking based on syntactic dependencies.
Scontis a contextual system which uses the contex-tual French?English translation system, rerank-ing based on syntactic dependencies and post-filtering heuristics.We used 1000-best lists of hypotheses for thesource-to-pivot translation, and restricted our-selves to much smaller 10-best lists for pivot-to-source translation (integrating early more con-straints directly into decoding could help in ob-taining better and smaller N-best lists).124.2 Evaluation protocolA native speaker was asked to study a held-out testfile of Europarl data in French and to identify atmost one fragment per sentence that would be agood candidate for revision and for which the an-notator could think of reasonable paraphrases thatdid not involve changes to the envelope.
Candidatefragments were accepted if they were not found inthe French?English translation table.
This stepresulted in a corpus of 151 sentences with as manytest fragments, with sizes ranging from 2 to 12words, an average size of 5.38 words and a me-dian size of 4 words.Two native speakers, including the previous an-notator, were asked to evaluate all paraphrasedsentences on grammaticality and meaning.
Con-trary to previous works, we decided to use a11The unexpected worse performance of the fr?en systemmay be explained by issues related to tokenization after anal-ysis by the parser.12In our future work, we intend to investigate the possibleuse of lattices rather than N-best lists.smaller evaluation scale with only 3 values, asusing more values tend to result in low inter-annotator agreement:?
2: indicates that the paraphrase is perfect oralmost perfect;?
1: indicates that the paraphrase could becomegrammatical with one minor change, or thatits meaning is almost clear;?
0: indicates that more than one minor changeis required to make the paraphrase grammat-ical or understandable.4.3 Results and discussionWe ran both systems and took their one-best hy-pothesis for evaluation.
Table 2 shows the resultsof a contrastive evaluation of the results obtained.For the 143 sentences for which paraphrases couldbe produced, we obtained 72 results common toboth systems, and 71 which were specific to eachsystem.
The fact that for half of the cases the twosystems produced the same paraphrases revealsthat either context did not play an important rolein these cases, and/or that the search space wasrather limited due to the presence of rare words inthe original fragment.
Systems Scontand Sbasarecompared based on the number of cases were onewas found to be better or worse than the other forthe 71 cases where they proposed different para-phrases, either by the two judges (denoted by the< and > signs) or by one of the two judges whilethe other found the two systems to be of compara-ble performance (denoted by the ?
and ?
signs).As can be seen from the table, there is a clear pref-erence for our Scontsystem, with a 31:37 ratio ofcases where it is preferred for grammar, and 33:49for meaning.Table 3 shows absolute results for the same runof evaluation.
First, it can be noted that both sys-tems perform at a reasonable level, both for shortand long text fragments.
Several reasons may ex-plain this: first, sentences to paraphrase are fromthe same domain as the training corpora for ourSMT systems, which is a positive bias towardsthe paraphrasing systems.
Also, the post-filteringheuristics and the fact that both systems couldbenefit from the knowledge of the target enve-lope during pivot-to-source back-translation cer-tainly helped in filtering out incorrect paraphrases.These results confirm the trend observed on con-trastive results that our Scontsystem is the best23Scont< SbasScont?
SbasScont?
SbasScont> Sbas?
TotalGrammar 3 3 10 21 34 71Meaning 3 13 13 20 22 71Table 2: Contrastive results.
The notation Scont< Sbasstands for cases in which Scontis found to beworse than Sbasby both judges; Scont?
Sbasfor cases where Scontwas found to be worse by one judgewhile the other found the two systems equivalent; similarly for other cases.
???
stands for cases wherejudges disagreed.count Grammar Meaning System- + ?
- + ?
- + ?Sbasand Scont72 0 69 3 1 67 4 0 66 6Sbasonly 71 13 46 12 18 41 12 9 39 23Scontonly 71 5 63 3 8 56 7 4 55 12Sbas: 2 ?
size ?
5 81 6 69 6 10 63 8 4 61 16Scont: 2 ?
size ?
5 81 2 78 1 6 72 3 2 71 8Sbas: 6 ?
size ?
12 62 7 46 9 9 45 8 5 44 13Scont: 6 ?
size ?
12 62 4 54 4 3 51 8 2 50 10Table 3: Absolute results for manual evaluation.
?+?
indicates that both judges agree on a positivejudgement (score 1 or 2), ?-?
that both judges agree on a negative judgment (score 0), and ???
that judgesdisagreed.
?System?
judgments include judgments for both Grammar and Meaning.performer for that task and that test set.
It ishowever noteworthy that results were significantlybetter when they were produced by both systems,which may correspond to the easiest cases with re-spect to the training data and/or the task but alsosuggests the application of consensus techniquesas done in MT system output combination.Table 4 shows paraphrasing examples producedby Scont.
As can be noted from positive exam-ples (a-c), the obtained paraphrases are mostly ofthe same syntactic types as the original phrases,which may be due to the proximity between themain language and the pivot language, as well asto the constraint on syntactic dependency preser-vation.
Example (a) shows a case of what maybe seen as some sort of normalization, as the con-cept of ?confidence of people?
(w.r.t.
the Englishpivot language) may be more frequently expressedas la confiance des citoyens (citizens) than as laconfiance des gens (people) in the reference cor-pus.
Example (b), although showing a correctparaphrasing, contains an agreement error whichis a result of the use of the gender neutral Englishpivot and the fact that the language model used bythe pivot-to-source SMT system was not able tochoose the correct agreement.
Example (c) illus-trates a case of correct paraphrasing involving re-ordering strongly influenced by the reordering re-quired by the pivot language.
The incorrect para-phrase of example (d) mainly results from the in-ability of the source-to-pivot SMT system to cor-rectly translate the selected fragment; in particular,the syntactic structure was not correctly translated,and the noun palier (stage) was incorrectly trans-lated as the verb heal and back-translated as theverb traiter (heal, cure).
Lastly, example (e) con-tains an error in word sense disambiguation be-tween the pivot noun act and the noun loi (law)13,as well as the incorrect deletion of the adverb tre`sfermement (firmly) during source-to-pivot transla-tion.Several conclusions can be drawn from theseresults and observations.
First, it is not surpris-ing that the performance of the SMT systems usedhas an important impact on the results.
This canbe mitigated in several ways: by attempting para-phrasing on in-domain sentences; by using an ap-propriate pivot language with respect to the natureof the text fragment to paraphrase; by using one orseveral pivot languages (as proposed by (Bannardand Callison-Burch, 2005) for phrase paraphras-ing) and consensus on the obtained paraphrases.13This example might call for better lexical checking be-tween original and paraphrased sentences, as well as exploit-ing context-aware SMT on the lower quality input of pivot-to-source translation.24(a) En tant que parti de gauche, nous avons du?, avec beaucoup de peine, nous rendre compte que les institutions ne sontpas des jeux de construction montables, transformables et de?montables a` souhait, mais qu?elles ont leur propre histoireet doivent be?ne?ficier de la confiance des gens qui les soutiennent.As the left, we have had, with a great deal of trouble, we see that the institutions are not games montables construction,transformables de?montables and to wish, but they have their own history and must enjoy the confidence of peoplewho support them.?
doivent avoir la confiance des citoyens(b) Monsieur le pre?sident, je suis inquie`te au sujet de l?attitude qui risque de se de?velopper au sein de l?UE concernant laliberte?
des e?changes.Mr President, I am concerned about the attitude which might develop within the EU on free trade.?
je suis pre?occupe?
par(c) Ces accords constituent un cadre contractuel entie`rement nouveau pour les pays de la re?gion.These agreements constitute an entirely new contractual framework for the countries of the region.?
un tout nouveau cadre contractuel(d) Aujourd?hui, le durcissement paralle`le des inde?pendantistes albanais et des autorite?s serbes fait franchir a` la crise unnouveau palier tre`s inquie?tant dans la monte?e des tensions.Today, the inflexibility parallel with the Albanian independent and the Serbian authorities to overcome the crisis is anew heal very worrying in the rise of tension.?
(*) de surmonter la crise est une nouvelle traiter tre`s pre?occupant(e) La commission condamne tre`s fermement cet acte et prend note de la de?cision de constituer un comite?
spe?cial au seinde la fiscalia general de la nacio?n afin d?enque?ter sur cet assassinat.The Commission condemn this act and takes note of the decision to set up a special committee fiscalia within thegeneral de la nacin in order to investigate this murder.?
(*) condamne cette loiTable 4: Examples of sub-sentential paraphrasings produced by our Scontsystem.Another remark is that our systems could be im-proved as regards their ability to exploit sourcecontext.145 Conclusion and future workIn this article, we have presented an approach toobtain sub-sentential paraphrases by using pivotSMT systems.
Although our results showed thatwe were able to build a strong baseline on our testset, they also showed that integrating context bothwhen translating from source-to-pivot and whenback-translating from pivot-to-source can lead toimproved performance.
Our approach has the dis-tinctive feature that it targets text fragments thatcan be larger than phrases traditionally capturedby statistical techniques, while not targeting fullsentences for which it would be harder to exploitcontext successfully.
More generally, it addressesthe case of the paraphrasing of text units for whichno paraphrases are directly available.We have identified several issues in our exper-iments that will constitute our future work.
Weintend to experiment with several pivot languagesand to make them compete to obtain the N-bestlists, as done in some approaches to multisourcetranslation (Och and Ney, 2001) and/or to use aconsensus technique to select the best paraphrase.14It should be noted, however, that the reported experi-ments used relatively small amounts of training data as inmost comparable works on context-aware Machine Transla-tion.As regards our context-aware SMT systems, weplan to exploit more complex syntactic knowledgeand to learn correspondances for inter-fragmentdependencies so as to make our rescoring basedon syntactic dependencies more flexible.
We arecurrently working on extracting revision instancesfrom Wikipedia?s revision history, which will pro-vide us with a corpus of genuine revision occur-rences as well as with an out-domain test corpuswith reference paraphrases.
Lastly, we want to in-vestigate the use of our approach for two types ofapplications: text normalization, in which a textis revised to select approved phraseology and ter-minology, through the use of a carefully chosentraining corpus for our pivot-to-source SMT sys-tem ; and interactive translation output revision forcases with or without a source text for professionaltranslators or monolingual users.AcknowledgmentsThis work was funded by a grant from LIMSI.ReferencesSalah A?
?t-Mokhtar, Jean-Pierre Chanod, and ClaudeRoux.
2002.
Robustness beyond shallowness: in-cremental deep parsing.
Natural Language Engi-neering, 8(3):121?144.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Pro-ceedings of ACL, Ann Arbor, USA.25Regina Barzilay and Lillian Lee.
2003.
Learn-ing to paraphrase: an unsupervised approach us-ing multiple-sequence alignment.
In Proceedings ofNAACL/HLT, Edmonton, Canada.Nicola Bertoldi, Madalina Barbaiani, Marcello Fed-erico, and Roldano Cattoni.
2008.
Phrase-basedstatistical machine translation with pivot languages.In Proceeding of IWSLT, pages 143?149, Hawaii,USA.Rahul Bhagat and Deepak Ravichandran.
2008.
Largescale acquisition of paraphrases for learning surfacepatterns.
In Proceedings of ACL: HLT, Columbus,USA.Chris Callison-Burch, Trevor Cohn, and Mirella Lap-ata.
2008.
Parametric: An automatic evaluationmetric for paraphrasing.
In Proceedings of COL-ING, Manchester, UK.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
In Pro-ceedings of EMNLP, Hawai, USA.Marine Carpuat and Dekai Wu.
2007.
Context-dependent phrasal translation lexicons for statisti-cal machine translation.
In Proceedings of MachineTranslation Summit XI, Copenhagen, Denmark.Michael Connor and Dan Roth.
2007.
Context sensi-tive paraphrasing with a single unsupervised classi-fier.
In Proceedings of ECML, Warsaw, Poland.Walter Daelemans, Jakub Zavrel, Ko van der Sloot,and Antal van den Bosch.
2007.
TiMBL: TilburgMemory Based Learner, version 6.1, ReferenceGuide.
Technical report, ILK 07-xx.
Available fromhttp://ilk.uvt.nl/downloads/pub/papers/ilk0703.pdf.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: Exploiting massively parallel news sources.In Proceedings of Coling 2004, pages 350?356,Geneva, Switzerland.Kevin Gimpel and Noah A. Smith.
2008.
Rich source-side context for statistical machine translation.
InProceedings of WMT at ACL, Columbus, USA.Rejwanul Haque, Sudip Kumar Naskar, Yanjun Ma,and Andy Way.
2009.
Using supertags as sourcelanguage context in smt.
In Proceedings of EAMT,Barcelona, Spain.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of ACL, demo session, Prague, CzechRepublic.Philipp Koehn.
2005.
Europarl: A parallel corpusfor statistical machine translation.
In Proceedingsof MT Summit, Phuket, Thailand.Nitin Madnani, Necip Fazil Ayan, Philip Resnik, andBonnie J. Dorr.
2007.
Paraphrases for parametertuning in statistical machine translation.
In Proceed-ings of Workshop on Machine Translation at ACL,Prague, Czech Republic.Aure?lien Max, Rafik Makhloufi, and Philippe Langlais.2008.
Explorations in using grammatical dependen-cies for contextual phrase translation disambigua-tion.
In Proceedings of EAMT, Hamburg, Germany.Aure?lien Max.
2008.
Local rephrasing suggestions forsupporting the work of writers.
In Proceedings ofGoTAL, Gothenburg, Sweden.Rani Nelken and Elif Yamangil.
2008.
Miningwikipedia?s article revision history for training com-putational linguistics algorithms.
In Proceedings ofthe AAAI Workshop on Wikipedia and Artificial In-telligence: An Evolving Synergy, Chicago, USA.Franz Josef Och and Hermann Ney.
2001.
Statisti-cal multi-source translation.
In Proceedings of MTSummit, Santiago de Compostela, Spain.Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignment of multiple translations:Extracting paraphrases and generating new sen-tences.
In Proceedings of NAACL/HLT, Edmonton,Canada.Chris Quirk, Chris Brockett, and William B. Dolan.2004.
Monolingual machine translation for para-phrase generation.
In Proceedings of EMNLP,Barcelona, Spain.Nicolas Stroppa, Antal van den Bosch, and Andy Way.2007.
Exploiting source similarity for smt usingcontext-informed features.
In Proceedings of TMI,Skvde, Sweden.Hua Wu and Haifeng Wang.
2007.
Pivot languageapproach for phrase-based statistical machine trans-lation.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics,Prague, Czech Republic.Shiqi Zhao, Cheng Niu, Ming Zhou, and Sheng Li.2008a.
Combining multiple resources to improvesmt-based paraphrasing model.
In Proceedings ofACL-HLT, Columbus, USA.Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.2008b.
Pivot approach for extracting paraphrasepatterns from bilingual corpora.
In Proceedings ofACL-HLT, Columbus, USA.26
