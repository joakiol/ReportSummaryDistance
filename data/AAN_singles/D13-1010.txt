Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 91?101,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsMeasuring Ideological Proportions in Political SpeechesYanchuan Sim?
Brice D. L.
Acree?
?Language Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USA{ysim,nasmith}@cs.cmu.eduJustin H. Gross?
Noah A.
Smith?
?Department of Political ScienceUniversity of North Carolina at Chapel HillChapel Hill, NC 27599, USA{brice.acree,jhgross}@unc.eduAbstractWe seek to measure political candidates?
ideo-logical positioning from their speeches.
To ac-complish this, we infer ideological cues froma corpus of political writings annotated withknown ideologies.
We then represent thespeeches of U.S. Presidential candidates as se-quences of cues and lags (filler distinguishedonly by its length in words).
We apply adomain-informed Bayesian HMM to infer theproportions of ideologies each candidate usesin each campaign.
The results are validatedagainst a set of preregistered, domain expert-authored hypotheses.1 IntroductionThe artful use of language is central to politics, andthe language of politicians has attracted consider-able interest among scholars of political commu-nication and rhetoric (Charteris-Black, 2005; Hart,2009; Deirmeier et al 2012; Hart et al 2013)and computational linguistics (Thomas et al 2006;Fader et al 2007; Gerrish and Blei, 2011, in-ter alia).
In American politics, candidates for of-fice give speeches and write books and manifestosexpounding their ideas.
Every political season,however, there are accusations of candidates ?flip-flopping?
on issues, with opinion shows, late-nightcomedies, and talk radio hosts replaying clips ofcandidates contradicting earlier statements.
Pres-idential candidate Mitt Romney?s own aide infa-mously proclaimed in 2012: ?I think you hit a resetbutton for the fall campaign [i.e., the general elec-tion].
Everything changes.
It?s almost like an Etch-a-Sketch.
You can kind of shake it up and we startall over again.
?A more general observation, often stated but notyet, to our knowledge, tested empirically, is thatsuccessful primary candidates ?move to the cen-ter?
before a general election.
The expectation fol-lows directly from long-standing and widely influen-tial theories of political competition that are collec-tively referred to in their simplest form as the ?me-dian voter theorem?
(Hotelling, 1929; Black, 1948;Downs, 1957).
Thus it is to be expected that whena set of voters that are more ideologically concen-trated are replaced by a set who are more widelydispersed across the ideological spectrum, as occursin the transition between the United States primaryand general elections, that candidates will presentthemselves as more moderate in an effort to captureenough votes to win.Do political candidates in fact stray ideologicallyat opportune moments?
More specifically, can wemeasure candidates?
ideological positions from theirprose at different times?
Following much workon classifying the political ideology expressed by apiece of text (Laver et al 2003; Monroe and Maeda,2004; Hillard et al 2008), we start from the as-sumption that a candidate?s choice of words andphrases reflects a deliberate attempt to signal com-mon cause with a target audience, and as a broaderstrategy, to respond to political competitors.
Ourcentral hypothesis is that, despite candidates?
in-tentional vagueness, differences in position?amongcandidates or over time?can be automatically de-tected and described as proportions of ideologies ex-pressed in a speech.In this work, we operationalize ideologies in anovel empirical way, exploiting political writingspublished in explicitly ideological books and mag-azines (?2).1 The corpus then serves as evidence for1We consider general positions in terms of broad ideolog-ical groups that are widely discussed in current political dis-course (e.g., ?Far Right,?
?Religious Right,?
?Libertarian,?
?91BACKGROUNDLEFT RIGHTCENTERPROGRESSIVERELIGIOUS LEFTFAR LEFTRELIGIOUS RIGHTCENTER-LEFTFAR RIGHTCENTER-RIGHTLIBERTARIANPOPULISTFigure 1: Ideology tree showing the labels for the ide-ological corpus in ?2.1 (excluding BACKGROUND) andcorresponding to states in the HMM (?3.3).a probabilistic model that allows us to automaticallyinfer compact, human-interpretable lexicons of cuesstrongly associated with each ideology.These lexicons are used, in turn, to create a low-dimensional representation of political speeches: aspeech is a sequence of cues interspersed with lags.Lags correspond to the lengths of sequences of non-cue words, which are treated as irrelevant to the in-ference problem at hand.
In other words, a speech isrepresented as a series alternating between cues sig-naling ideological positions and uninteresting filler.Our main contribution is a probabilistic techniquefor inferring proportions of ideologies expressed bya candidate (?3).
The inputs to the model are thecue-lag representation of a speech and a domain-specific topology relating ideologies to each other.The topology tree (shown in Figure 1) encodingthe closeness of different ideologies and, by exten-sion, the odds of transitioning between them within aspeech.
Bayesian inference is used to manage uncer-tainty about the associations between cues and ide-ologies, probabilities of traversing each of the tree?sedges, and other parameters.We demonstrate the usefulness of the measure-ment model by showing that it accurately recov-ers pre-registered beliefs regarding narratives widelyaccepted?but not yet tested empirically?about the2008 and 2012 U.S. Presidential elections (?4).2 First Stage: Cue ExtractionWe first present a data-driven technique for automat-ically constructing ?cue lexicons?
from texts labeledwith ideologies by domain experts.etc.).
Analysis of positions on specific issues is left for futurework.Total tokens 32,835,190Total types 138,235Avg.
tokens per book 77,628Avg.
tokens per mag.
issue 31,713Breakdown by ideology: Documents TokensLEFT 0 0FAR LEFT 112 3,334,601CENTER-LEFT 196 7,396,264PROGRESSIVE LEFT 138 7,257,723RELIGIOUS LEFT 7 487,844CENTER 5 429,480RIGHT 97 3,282,744FAR RIGHT 211 7,392,163LIBERTARIAN RIGHT 88 1,703,343CENTER-RIGHT 9 702,444POPULIST RIGHT 5 407,054RELIGIOUS RIGHT 6 441,530Table 1: Ideology corpus statistics.
Note that some docu-ments are not labeled with finer-grained ideologies.2.1 Ideological CorpusWe start with a collection of contemporary politicalwritings whose authors are perceived as represen-tative of one particular ideology.
Our corpus con-sists of two types of documents: books and maga-zines.
Books are usually written by a single author,while each magazine consists of regularly publishedissues with collections of articles written by severalauthors.
A political science domain expert who isa co-author of this work manually labeled each ele-ment in a collection of 112 books and 10 magazinetitles2 with one of three coarse ideologies: LEFT,RIGHT, or CENTER.
Documents that were labeledLEFT and RIGHT were further broken down intomore fine-grained ideologies, shown in Fig.
1.3 Ta-ble 1 summarizes key details about the ideologicalcorpus.In addition to ideology labels, individual chapterswithin the books were manually tagged with topicsthat the chapter was about.
For instance, in BarackObama?s book The Audacity of Hope, his chapter2There are 765 magazine issues, which are published bi-weekly to quarterly, depending on the magazine.
All of a mag-azine?s issues are labeled with the same ideology.3We cannot claim that these texts are ?pure?
examples ofthe ideologies they are labeled with (i.e., they may contain partsthat do not match the label).
By finding relatively few termsstrongly associated with texts sharing a label, our model shouldbe somewhat robust to impurities, focusing on those terms thatare indicative of whatever drew the expert to identify them as(mostly) sharing an ideology.92titled ?Faith?
is labeled as RELIGIOUS.
Not allchapters have clearly defined topics, and as such,these chapters are simply labeled MISC.
Maga-zines are not labeled with topics because each issueof a magazine generally touches on multiple top-ics.
There are a total of 61 topics; the full list canbe found in the supplementary materials, along witha table summarizing key details about the corpus,which contains 32.8 million tokens.2.2 Cue Discovery ModelWe use the ideological corpus to infer ideologicalcues: terms that are strongly associated with an ide-ology.
Because our ideologies are organized hierar-chically, we required a technique that can accountfor multiple effects within a single text.
We furtherrequire that the sets of cue terms be small, so thatthey can be inspected by domain experts.
We there-fore turn to the sparse additive generative (SAGE)models introduced by Eisenstein et al(2011).Like other probabilistic language models, SAGEassigns probability to a text as if it were a bag ofterms.
It differs from most language models in pa-rameterizing the distribution using a generalized lin-ear model, so that different effects on the log-oddsof terms are additive.
In our case, we define theprobability of a term w conditioned on attributes ofthe text in which it occurs.
These attributes includeboth the ideology and its coarsened version (e.g., aFAR RIGHT book also has the attribute RIGHT).For simplicity, let A(d) denote the set of attributesof document d and A =?dA(d).
The parametricform of the distribution is given, for term w in doc-ument d, by:p(w | A(d);?)
=exp(?0w +?a?A(d) ?aw)Z(A(d),?
)Each of the ?
weights can be a positive or negativevalue influencing the probability of the word, condi-tioned on various properties of the document.
Whenwe stack an attribute a?s weights into a vector acrossall words, we get an ?a vector, understood as an ef-fect on the term distribution.
(We use ?
to refer tothe collection of all of these vectors.)
The effects inour model, described in terms of attributes, are:?
?0, the background (log) frequencies of words,fixed to the empirical frequencies in the corpus.Hence the other effects can be understood as de-viations from this background distribution.?
?ic , the coarse ideology effect, which takes differ-ent values for LEFT, RIGHT, and CENTER.?
?if , the fine ideology effect, which takes differentvalues for the fine-grained ideologies correspond-ing to the leaves in Fig.
1.?
?t, the topic effect, taking different values foreach of the 61 manually assigned topics.
We fur-ther include one effect for each magazine series(of which there are 10) to account for each maga-zine?s idiosyncrasies (topical or otherwise).?
?d, a document-specific effect, which captures id-iosyncratic usage within a single document.Note that the effects above are not mutually exclu-sive, although some effects never appear togetherdue to constraints imposed by their semantics (e.g.,no book is labeled both LEFT and RIGHT).When estimating the parameters of the model (the?
vectors), we impose a sparsity-inducing `1 priorthat forces many weights to zero.
The objective is:max?
?d?w?dlog p(w | A(d);?)??a?A?a?
?a?1This objective function is convex but requires spe-cial treatment due to non-differentiability when anyelements are zero; we use the OWL-QN algorithmto solve it (Andrew and Gao, 2007).
To reduce thecomplexity of the hyperparameter space (the possi-ble values of all ?a) and to encourage similar levelsof sparsity across the different effect vectors, we let,for each ideology attribute a,?a = ?
?
|V(a)| /maxa?
?A |V(a?
)|where V(a) is the set of term types appearing inthe data with attribute a (i.e., its vocabulary) , and?
is a hyperparameter we can adjust to control theamount of sparsity in the SAGE vectors.
For thenon-ideology effects, we fix ?a = 10 (not tuned).2.3 Bigram and Trigram LexiconsAfter estimating parameters, we are left with sparse?a for each attribute.
We are only interested, how-ever, in the ideological attributes I ?
A.
For anideological attribute i ?
I, we take the terms withpositive elements of this vector to be the cues forideology i; call this set L(i) and let L =?i?IL(i).93Because political texts use a fair amount of multi-word jargon, we initially represented each documentas a bag of unigrams, bigrams, and trigrams, ignor-ing the fact that these ?overlap?
with each other.4While this would be inappropriate in language mod-eling and is inconsistent with our model?s indepen-dence assumptions among words, it is sensible sinceour goal is to identify cues that are statistically asso-ciated with attributes like ideologies.Preliminary trials revealed that unigrams tend todominate in such a model, since their frequencycounts are so much higher.
Further, domain ex-perts found them harder to interpret out of contextcompared to bigrams and trigrams.
We therefore in-cluded only bigrams and trigrams as terms in our cuediscovery model.2.4 ValidationThe term selection method we have described canbe understood as a form of feature selection thatreasons globally about the data and tries to con-trol for some effects that are not of interest (topicor document idiosyncrasies).
We compared theapproach to two classic, simple methods for fea-ture selection: ranking based on pointwise mu-tual information (PMI) and weighted average PMI(WAPMI) (Schneider, 2005; Cover and Thomas,2012).
Selected features were used to classify theideologies of held-out documents from our cor-pus.5 We evaluated these feature selection methodswithin na?
?ve Bayes classification in a 5-fold cross-validation setup.
We vary ?
for the SAGE modeland compare the results to equal-sized sets of termsselected by PMI and WAPMI.
We consider SAGEwith and without topic effects.Figure 2 visualizes accuracy against the num-ber of features for each method.
Bigrams andtrigrams consistently outperform unigrams (McNe-mar?s, p < 0.05).
Otherwise, there are no sig-nificant differences in performance except WAPMI4Generative models that produce the same evidence morethan once are sometimes called ?deficient,?
but model defi-ciency does not necessarily imply that the model is ineffective.Some of the IBM models for statistical machine translation pro-vide a classic example (Brown et al 1993).5The text was tokenized and stopwords removed.
Punctu-ation, numbers, and web addresses were normalized.
Tokensappearing less than 20 times in training data, or in fewer than 5documents were removed.26 27 28 29 210 211 212 213 214 ?0.50.550.60.650.7PMIWAPMI SAGESAGE w/ topicsFigure 2: Plot of average classification accuracy for5-fold cross validation against the number of features.Dashed lines refer to using only unigram features, whilesolid lines refer to using bigram and trigram features.with bigrams/trigrams at its highest point.
SAGEwith topics is slightly (but not significantly) bet-ter than without.
We conclude that SAGE is acompetitive choice for cue discovery, noting that aprincipled way of controlling for topical and doc-ument effects?offered by SAGE but not the othermethods?may be even more relevant to our taskthan classification accuracy.2.5 Cue LexiconWe ran SAGE on the the full ideological book cor-pus, including topic effects, and setting ?
= 30, ob-tained a set of |L| = 8, 483 cue terms.
The supple-mentary materials include top cue terms associatedwith various ideologies and a heatmap of similaritiesamong SAGE vectors.We conducted a small, relatively informal studyin which seven subjects (including four scholars ofAmerican politics) were asked to match brief de-scriptions of the classes, including prominent proto-typical individuals exemplifying each, to cue terms.About 70% of ideologies were correctly matchedby experts, with relatively few confusions betweenLEFT and RIGHT.
More details are given in sup-plementary materials.3 Second Stage: Cue-Lag IdeologicalProportionsThe main contribution of this paper is a techniquefor measuring ideology proportions in the prose ofpolitical candidates.
We adopt a Bayesian approachthat manages our uncertainty about the cue lexi-94con L, the tendencies of political speakers to ?flip-flop?
among ideological types, and the relative ?dis-tances?
among different ideologies.
The representa-tion of a candidate?s ideology as a mixture amongdiscrete, hierarchically related categories can be dis-tinguished from continuous representations (?scal-ing?
or ?spatial?
models) often used in political sci-ence, especially to infer positions from Congres-sional roll-call voting patterns (Poole and Rosen-thal, 1985; Poole and Rosenthal, 2000; Clintonet al 2004).
Moreover, the ability to draw in-ferences about individual policy-makers?
ideologiesfrom their votes on proposed legislation is severelylimited by institutional constraints on the types oflegislation that is actually subject to recorded votes.3.1 Political Speeches CorpusWe gathered transcribed speeches given by candi-dates of the two main parties (Democrats and Re-publicans) during the 2008 and 2012 Presidentialelection seasons.
Each election season is comprisedof two stages: (i) the primary elections, where can-didates seek the support of their respective parties tobe nominated as the party?s Presidential candidate,and (ii) the general elections where the parties?
cho-sen candidates travel across the states to garner sup-port from all citizens.
Each candidate?s speeches arepartitioned into epochs for each election; e.g., thosethat occur before the candidate has secured enoughpledged delegates to win the party nomination are?from the primary.?
Table 2 presents a breakdownof the candidates and speeches in our corpus.3.2 Cue-Lag RepresentationOur measurement model only considers ideologicalcues; other terms are treated as filler.
We thereforetransform each speech into a cue-lag representation.The representation is a sequence of alternatingcues (elements from the ideological lexicon L) andinteger ?lags?
(counts of non-cue terms falling be-tween two cues).
This will allow us to capture the in-tuition that a candidate may use longer lags betweenevocations of different ideologies, while nearby cuesare likely to be from similar ideologies.To map a speech into the cue-lag representation,we simply match all elements of L in the speech andreplace sequences of other words by their lengths.When a trigram cue strictly includes a bigram cue,Party Pri?08 Gen?08 Pri?12 Gen?12Democrats?
167 - - -Republicans?
50 - 49 -Obama (D) 78 81 - 99McCain (R) 9 159 - -Romney (R) 8 ?
(13) 19 19?Democrats in our corpus are: Joe Biden, Hillary Clinton, JohnEdwards, and Bill Richardson in 2008 and Barack Obama inboth 2008 and 2012.?Republicans in our corpus are: Rudy Giuliani, Mike Huck-abee, John McCain, and Fred Thompson in 2008, MichelleBachmann, Herman Cain, Newt Gingrich, Jon Huntsman, RickPerry, and Rick Santorum in 2012, and Ron Paul and Mitt Rom-ney in both 2008 and 2012.?For Romney, we have 13 speeches which he gave in the period2008-2011 (between his withdrawal from the 2008 electionsand before the commencement of the 2012 elections).
Whilethese speeches are not technically part of the regular Presiden-tial election campaign, they can be seen as his preparation to-wards the 2012 elections, which is particularly interesting asRomney has been accused of having inconsistent viewpoints.Table 2: Breakdown of number of speeches in our polit-ical speech corpus by epoch.
On average, 2,998 tokens,and 95 cue terms are found in each speech document.we take only the trigram.
When two cues partiallyoverlap, we treat them as consecutive cue terms andset the lag to 0.
Figure 3 shows an example of ourcue-lag representation.3.3 CLIP: An Ideology HMMThe model we use to infer ideologies, cue-lag ide-ological proportions (CLIP), is a hidden Markovmodel.
Each state corresponds to an ideology(Fig.
1) or BACKGROUND.
The emission from a stateconsists of (i) a cue from L and (ii) a lag value.
Thehigh-level generative story for a single speech withT cue-lag pairs is as follows:1.
Parameters are drawn from conjugate priors(details in ?3.3.3).2.
Let the initial state be the BACKGROUNDstate.3.
For t ?
{1, 2, .
.
.
, T}:6(a) Transition to state St based on thetransition distribution, discussed in ?3.3.1.This transition is conditioned on the previ-ous state St?1 and the lag at timestep t?1,denoted by Lt?1.6The length of the sequence is assumed to be exogenous, sothat no stop state needs to be defined.95Original sentence Just compare this President?s record with Ronald Reagan?s first term.
President Reagan also facedan economic crisis.
In fact, in 1982, the unemployment rate peaked at nearly 11 percent.
But in thetwo years that followed, he delivered a true recovery economic growth and job creation were threetimes higher than in the Obama Economy.Cue-lag representation .
.
.6??
ronald reagan2??
presid reagan3??
econom crisi5??
unemploy rate17??
econom growth1?
?job creation9??
.
.
.Figure 3: Example of the cue-lag representation.
(b) Emit cue term Wt from the lexicon Land lag Lt based on the emission distribu-tion, discussed in ?3.3.2.We turn next to the transitions and emissions.3.3.1 Ideology Topology and TransitionParameterizationCLIP assumes that each cue term uttered by apolitician is generated from a hidden state corre-sponding to an ideology.
The ideologies are orga-nized into a tree based on their hierarchical relation-ships; see Fig.
1.
In this study, the tree is fixed ac-cording to our domain knowledge of current Ameri-can politics; in future work it might be enriched withgreater detail or its structure learned automatically.The ideology tree is used in defining the transitiondistribution in the HMM, but not to directly definethe topology of the HMM.
Importantly, each statemay transition to any other state, but the transitiondistribution is defined using the graph, so that ide-ologies that are closer to each other will tend to bemore likely to transition to each other.
To transitionbetween two states si and sj , a walk must be takenin the tree from vertex si to vertex sj .
We emphasizethat the walk corresponds to a single transition?the speaker does not emit anything from the statespassed through along the path.A simplified version of our transition distribution,for exposition, is given as follows:ptree(sj | si; ?,?)=(??u,v??Path(si,sj)(1?
?u)?u,v)?sjPath(si, sj) refers to the sequence of edges in thetree along the unique path from si to sj .
Each ofthese edges ?u, v?
must be traversed, and the prob-ability of doing so, conditioned on having alreadyreached u, is (1?
?u)?i.e., not stopping in u?times?u,v?i.e., selecting vertex v from among those thatshare an edge with u.
Eventually, sj is reached, andthe walk ends, incurring probability ?sj .In order to capture the intuition that a longer lagafter a cue term should increase the entropy over thenext ideology state, we introduce a restart probabil-ity, which is conditioned on the length of the mostrecent lag, `.
The probability of restarting the walkfrom the BACKGROUND state is a noisy-OR modelwith parameter ?.
This gives the transition distribu-tion:p(sj | si, `; ?,?, ?)
= (1?
?
)`+1ptree(sj | si; ?,?
)+ (1?
(1?
?
)`+1)ptree(sj | sBACKGROUND ; ?,?
)Note that, if ?
= 1, there is no Markovian depen-dency between states (i.e., there is always a restart),so CLIP reverts to a mixture model.This approach allows us to parameterize the fullset of |I|2 transitions with O(|I|) parameters.7 Sincethe graph is a tree and the walks are not allowedto backtrack, the only ambiguity in the transitionis due to the restart probability; this distinguishesCLIP from other algorithms based on random walks(Brin and Page, 1998; Mihalcea, 2005; Toutanova etal., 2004; Collins-Thompson and Callan, 2005).3.3.2 Emission ParameterizationRecall that, at time step t, CLIP emits a cue fromthe lexicon L and an integer-valued lag.
For eachstate s, we let the probability of emitting cue wbe denoted by ?s,w; ?s is a multinomial distribu-tion over the entire lexicon L. This allows our ap-proach to handle ambiguous cues that can associatewith more than one ideology, and also to associate acue with a different ideology than our cue discoverymethod proposed, if the signal from the data is suffi-ciently strong.
We assume each lag to be generatedby a Poisson distribution with global parameter ?.7More precisely, there are |I| edges (since there are |I| + 1vertices including BACKGROUND), each with a ?-parameter ineach direction.
For a vertex with degree d, however, there areonly d?1 degrees of freedom, so that there are 2|I|?
(|I|+1) =|I|?1 degrees of freedom for ?.
There are |I| ?-parameters anda single ?, for a total of 2|I| degrees of freedom.963.3.3 Inference and LearningAbove we described CLIP?s transitions and emis-sions.
Because our interest is in measuringproportions?and, as we will see, in comparingthose proportions across speakers and campaignperiods?we require a way to allow variation in pa-rameters across different conditions.
Specifically,we seek to measure differences in time spent in eachideology state.
This can be captured by allowingeach speaker to have a different ?
and ?
in each stageof the campaign.
On the other hand, we expect that aspeaker draws from his ideological lexicon similarlyacross different epochs?there is a single ?
sharedbetween different epochs.In order to manage uncertainty about the param-eters of CLIP, to incorporate prior beliefs based onour ideology-specific cue lexicons {L(i)}i, and toallow sharing of statistical strength across condi-tions, we adopt a Bayesian approach to inference.This will allow principled exploration of the poste-rior distribution over the proportions of interest.We place a symmetric Dirichlet prior on the treewalk probabilities ?
; its parameter is ?.
For thecue emission distribution associated with ideologyi, ?si , we use an informed Dirichlet prior with twodifferent values, ?cue for cues in L(i), and a smaller?def for those in L \ L(i).8Learning proceeds by collapsed Gibbs samplingfor the hidden states and slice sampling (with vaguepriors) for the hyperparameters (?, ?, ?, and ?).
De-tails of the sampler are given in the supplementarymaterials.
At each Gibbs step, we resample the ide-ology state and restart indicator variable for everycue term in every speech.We ran our Gibbs sampler for 75,000 iterations,discarding the first 25,000 iterations for burn-in, andcollected samples at every 10 iterations.
Further, weperform the slice sampling step at every 5,000 itera-tions.
For each candidate, we collected 5,000 poste-rior samples which we use to infer his/her ideologi-cal proportions.In order to determine the amount of time a candi-date spends in each ideology, we denote the unit oftime in terms of half the lag before and after each cue8This implies that a term can, in the posterior distribution,be associated with an ideology i of whose L(i) it was not amember.
In fact, this occurred frequently in our runs of themodel.term, i.e., when a candidate draws a cue term fromideology i during timestep t, we say that he spends12(Lt?1 + Lt) amount of time in ideology i. Aver-aging over all the samples returned by our samplerand normalizing it by the length of the documents ineach epoch, we obtain a candidate?s expected ideo-logical proportions within the epoch.4 Pre-registered HypothesesThe traditional way to evaluate a text analysis modelin NLP is, of course, to evaluate its output againstgold-standard judgements by humans.
In the caseof recent political speeches, however, we are doubt-ful that such judgments can be made objectively ata fine-grained level.
While we are confident aboutgross categorization of books and magazines in ourideological corpus (?2.1), many of which are overtlymarked by their ideological assocations, we believethat human estimates of ideological proportions, oreven association of particular tokens with ideologiesthey may evoke, may be overly clouded by the vari-ation in annotator ideology and domain expertise.We therefore adopt a different method for evalua-tion.
Before running our model, we identified a setof hypotheses, which we pre-registered as expec-tations.
These are categorized into groups based ontheir strength and relevance to judging the validity ofthe model.
Strong hypotheses are those that consti-tute the lowest bar for face validity; if violated, theysuggest a flaw in the model.
Moderate hypothesesare those that match the intuition of domain expertsconducting the research, or extant theory.
Violationssuggest more examination is required, and may raisethe possibility that further testing might be pursuedto demonstrate the hypothesis is false.
Our 13 prin-cipal hypotheses are enumerated in Table 3.5 EvaluationWe compare the posterior proportions inferred byCLIP with several baselines:?
HMM: rather than ?3.3.1, a fully connected, tra-ditional transition matrix is used.?
MIX: a mixture model; at each timestep, we al-ways restart (?
= 1).
This eliminates Marko-vian dependencies between ideologies at nearbytimesteps, but still uses the ideology tree in defin-ing the probabilities of each state through ?.97Hypotheses CLIP HMM MIX NORESSanity checks (strong):S1.
Republican primary candidates should tend to draw more from RIGHT thanfrom LEFT.
*12/12 10/13 13/13 12/13S2.
Democratic primary candidates should tend to draw more from LEFT thanfrom RIGHT.4/5 5/5 5/5 5/5S3.
In general elections, Democrats should draw more from the LEFT than theRepublicans and vice versa for the RIGHT.4/4 4/4 3/4 0/4S total 20/21 19/22 21/22 17/22Primary hypotheses (strong):P1.
Romney, McCain and other Republicans should almost never draw from FARLEFT, and extremely rarely from PROGRESSIVE.29/32 *21/31 27/32 29/32P2.
Romney should draw more heavily from the RIGHT than Obama in both stagesof the 2012 campaign.2/2 2/2 1/2 1/2Primary hypotheses (moderate):P3.
Romney should draw more heavily on words from the LIBERTARIAN,POPULIST, RELIGIOUS RIGHT, and FAR RIGHT in the primary com-pared to the general election.
In the general election, Romney should drawmore heavily on CENTER, CENTER-RIGHT and LEFT vocabularies.2/2 2/2 0/2 2/2P4.
Obama should draw more heavily on words from the PROGRESSIVE in the2008 primary than in the 2008 general election.0/1 0/1 0/1 1/1P5.
In the 2008 general election, Obama should draw more heavily on theCENTER, CENTER-LEFT, and RIGHT vocabularies than in the 2008 primary.1/1 1/1 1/1 1/1P6.
In the 2012 general election, Obama should sample more from the LEFT thanfrom the RIGHT, and should sample more from the LEFT vocabularies thanRomney.2/2 2/2 0/2 0/2P7.
McCain should draw more heavily from the FAR RIGHT, POPULIST, andLIBERTARIAN in the 2008 primary than in the 2008 general election.0/1 1/1 1/1 1/1P8.
In the general 2008, McCain should draw more heavily from the CENTER,CENTER-RIGHT, and LEFT vocabularies than in the 2008 primary.1/1 1/1 1/1 1/1P9.
McCain should draw more heavily from the RIGHT than Obama in both stagesof the campaign.2/2 2/2 2/2 1/2P10.Obama and other Democrats should very rarely draw from FAR RIGHT.
6/7 5/7 7/7 4/7P total 45/51 37/50 40/51 41/51Table 3: Pre-registered hypotheses used to validate the measurement model; number of statements evaluated correctlyby different models.
*Some differences were not significant at p = 0.05 and are not included in the results.?
NORES, where we never restart (?
= 0).
Thisstrengthens the Markovian dependencies.In MIX, there are no temporal effects between cueterms, although the structure of our ideology treeencourages the speaker to draw from coarse-grainedideologies over fine-grained ideologies.
On the otherhand, the strong Markovian dependency betweenstates in NORES would encourage the model to staylocal within the ideology tree.
In our experiments,we will see how that the ideology tree and the ran-dom treatment of restarting both contribute to ourmodel?s inferences.Table 3 presents a summary of which hypothe-ses the models?
inferences are in accordance with.CLIP is not consistently outperformed by any of thecompeting baselines.Sanity checks (S1?3) CLIP correctly identifiessixteen LEFT/RIGHT alignments of primary candi-dates (S1, S2), but is unable to determine one can-didate?s orientation; it finds Jon Huntsman to spendroughly equal proportions of speech-time drawingon LEFT and RIGHT cue terms.
Interestingly,Huntsman, who had served as U.S.
Ambassador toChina under Obama, was considered the one mod-erate in the 2012 Republican field.
MIX correctlyidentifies all thirteen Republicans, while NORESplaces McCain from the 2008 primaries as mostlyLEFT-leaning and HMM misses three of thirteen,including Perry and Gingrich, who might be deeply98disturbed to find that they are misclassified as LEFT-leaning.
As for the Democratic primary candidates(S2), CLIP?s one questionable finding is that JohnEdwards spoke slightly more from the RIGHT thanthe LEFT.
For the general elections (S3), CLIP andHMM correctly identify the relative amount of timespent in LEFT/RIGHT between Obama and his Re-publican competitors.
NORES had the most trou-ble, missing all four.
CLIP finds Obama spend-ing slightly more time on the RIGHT than on theLEFT in the 2008 general elections but nevertheless,Obama is still found to spend more time engaging inLEFT-speak than McCain.Name interference When we looked at the cueterms actually used in the speeches, we found onesystematic issue: the inclusion of candidates?
namesas cue terms.
Terms mentioning John McCain areassociated with the RIGHT, so that Obama?s men-tions of his opponent are taken as evidence forrightward positioning; in total, mentions of McCaincontributed 4% absolute to Obama?s RIGHT ide-ological proportion.
Similarly, barack obama andpresid obama are LEFT cues (though senat obamais a RIGHT cue).
In future work, we believe filteringcandidate names in the first stage will be beneficial.Strong hypotheses P1 and P2 CLIP and the vari-ants making use of the ideology tree were in agree-ment on most of the strong primary hypotheses.Most of these involved our expectation that theRepublican candidates would rarely draw on FARLEFT and PROGRESSIVE LEFT.
Our qualitativehypotheses were not specific about how to quantify?rare?
or ?almost never.?
We chose to find a resultinconsistent with a P1 hypothesis any time a Repub-lican had proportions greater than 5% for either ide-ology.
The notable deviations for CLIP were FredThompson (13% from the PROGRESSIVE LEFTduring the 2008 primary) and Mitt Romney (12%from the PROGRESSIVE LEFT between the 2008and 2012 elections, 13% from the FAR LEFT dur-ing the 2012 general election).
This model did noworse than other variants here and much better thanone: HMM had 10 inconsistencies out of 32 oppor-tunities, suggesting the importance of the ideologytree.McCainPrimaries 2008 General 2008Far LeftReligious (L)Center-LeftCenter-RightLibertarian (R)Religious (R)Progressive (L)LeftCenterRightPopulist (R)Far RightRomneyPrimaries 2008 2008-2011 Primaries 2012 General 2012Far LeftReligious (L)CenterCenter-RightLibertarian (R)Religious (R)Progressive (L)LeftCenter-LeftRightPopulist (R)Far RightObamaPrimaries 2008 General 2008 General 2012Far LeftReligious (L)LeftCenter-LeftCenter-RightLibertarian (R)Populist (R)Religious (R)Progressive (L)CenterRightFar RightFigure 4: Proportion of time spent in each ideology byMcCain, Romney, and Obama during the 2008 and 2012Presidential election seasons.?Etch-a-Sketch?
hypotheses Hypotheses P3, P4,P5, P7, and P8 are all concerned with differencesbetween the primary and general elections: success-ful primary candidates are expected to ?move to thecenter.?
A visualization of CLIP?s proportions forMcCain, Romney, and Obama is shown in Figure 4,with their speeches grouped together by differentepochs.
The model is in agreement with most ofthese hypotheses.
It did not confirm P4?Obamaappears to CLIP to be more PROGRESSIVE in the2008 general election than in the primary, though thedifference is small (3%) and may be within the mar-gin of error.
Likewise, in P7, the difference betweenMcCain drawing from FAR RIGHT, POPULISTand LIBERTARIAN between the 2008 primary andgeneral elections is only 2% and highly uncertain,with a 95% credible interval of 44?50% during theprimary (vs. 47?50% in the general election).Fine-grained ideologies Fine-grained ideologiesare expected to account for smaller proportions, sothat making predictions about them is quite difficult.This is especially true for primary elections, where abroader palette of ideologies is expected to be drawnfrom, but we have fewer speeches from each candi-99date.
CLIP?s inconsistency with P10, for example,comes from assigning 5.4% of Obama?s 2008 pri-mary cues to FAR RIGHT.CLIP?s inferences on the corpus of politicalspeeches can be browsed at http://www.ark.cs.cmu.edu/CLIP.
We emphasize that CLIPand its variants are intended to quantify the ideo-logical content candidates express in speeches, notnecessarily their beliefs (which may not be perfectlyreflected in their words), or even how they are de-scribed by pundits and analysts (who draw on farmore information than is expressed in speeches).CLIP?s deviations from the hypotheses are sug-gestive of potential improvements to cue extraction(?2), but also of incorrect hypotheses.
We expectfuture research to explore a richer set of linguisticcues and attributes beyond ideology (e.g., topics andframing on various issues).
We plan to use CLIPas a text analysis method to support substantive in-quiry in political science, such as following trendsin expressed ideology over time.6 Related WorkAs early as the 1960s, there has been research onmodeling ideological beliefs using automated sys-tems (Abelson and Carroll, 1965; Carbonell, 1978;Sack, 1994).
These early works model ideology at asophisticated level, involving the actors, actions andgoals; they require manually constructed knowledgebases.
Poole and Rosenthal (1985) used congres-sional roll call data to demonstrate the ideologicaldivide in Congress, and provided a methodology formeasuring ideological positions.
Gerrish and Blei(2011; 2012) augmented the methodology with textfrom congressional bills using probabilistic modelsto uncover lawmakers?
positions on specific polit-ical issues, putting them on a left-right spectrum,while Thomas et al(2006) made use of floor de-bate speeches to predict votes.
Likewise, taking ad-vantage of the proliferation of text today, numer-ous techniques have been developed to identify top-ics and perspectives in the media (Gentzkow andShapiro, 2005; Lin et al 2008; Fortuna et al 2009;Gentzkow and Shapiro, 2010); determine the polit-ical leanings of a document or author (Laver et al2003; Efron, 2004; Mullen and Malouf, 2006; Faderet al 2007); or recognize stances in debates (So-masundaran and Wiebe, 2009; Anand et al 2011).Going beyong lexical indicators, Greene and Resnik(2009) investigated syntactic features to identify per-spectives or implicit sentiment.7 ConclusionsWe introduced CLIP, a domain-informed, Bayesianmodel of ideological proportions in political lan-guage.
We showed how ideological cues could bediscovered from a lightly labeled corpus of ideolog-ical writings, then incorporated into CLIP.
The re-sulting inferences are largely consistent with a setof preregistered hypotheses about candidates in the2008 and 2012 Presidential elections.AcknowledgmentsFor thoughtful feedback on this research, the authorsthank: several anonymous reviewers, Amber Boydstun,Philip Resnik, members of the ARK group at CMU, andparticipants in Princeton University?s Political Methodol-ogy Colloquium and PolMeth XXX hosted by The Uni-versity of Virginia.
This work was supported in part by anA?STAR fellowship to Y. Sim, NSF grants IIS-1211201and IIS-1211277, and Google?s support of the Reading isBelieving project at CMU.ReferencesRobert P. Abelson and J. Douglas Carroll.
1965.
Com-puter simulation of individual belief systems.
Ameri-can Behavioral Scientist, 8(9):24?30.Pranav Anand, Marilyn Walker, Rob Abbott, Jean E. FoxTree, Robeson Bowmani, and Michael Minor.
2011.Cats rule and dogs drool!
: Classifying stance in onlinedebate.
In Proceedings of the Second Workshop onComputational Approaches to Subjectivity and Senti-ment Analysis.Galen Andrew and Jianfeng Gao.
2007.
Scalable train-ing of l1-regularized log-linear models.
In Proceed-ings of ICML.Duncan Black.
1948.
On the rationale of group decision-making.
The Journal of Political Economy, 56(1):23?34.Sergey Brin and Lawrence Page.
1998.
The anatomy of alarge-scale hypertextual web search engine.
ComputerNetworks and ISDN Systems, 30(1):107?117.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Computational Linguistics, 19(2):263?311.100Jaime G. Carbonell.
1978.
Politics: Automated ideolog-ical reasoning.
Cognitive Science, 2(1):27?51.Jonathan Charteris-Black.
2005.
Politicians andRhetoric: The Persuasive Power of Metaphor.Palgrave-MacMillan.Joshua Clinton, Simon Jackman, and Douglas Rivers.2004.
The statistical analysis of roll call data.
Ameri-can Political Science Review, 98(2):355?370.Kevyn Collins-Thompson and Jamie Callan.
2005.Query expansion using random walk models.
In Pro-ceedings of CIKM.Thomas M. Cover and Joy A. Thomas.
2012.
Elementsof Information Theory.
Wiley-Interscience.Daniel Deirmeier, Jean-Francois Godbout, Bei Yu, andStefan Kaufmann.
2012.
Language and ideologyin congress.
British Journal of Political Science,42(1):31?55.Anthony Downs.
1957.
An Economic Theory of Democ-racy.
Harper, New York.Miles Efron.
2004.
Cultural orientation: Classifyingsubjective documents by cociation analysis.
In AAAIFall Symposium on Style and Meaning in Language,Art, and Music.Jacob Eisenstein, Amr Ahmed, and Eric P Xing.
2011.Sparse additive generative models of text.
In Proceed-ings of ICML.Anthony Fader, Dragomir R. Radev, Michael H. Crespin,Burt L. Monroe, Kevin M. Quinn, and Michael Co-laresi.
2007.
MavenRank: Identifying influentialmembers of the US senate using lexical centrality.
InProceedings of EMNLP-CoNLL.Blaz Fortuna, Carolina Galleguillos, and Nello Cristian-ini.
2009.
Detecting the bias in media with statisticallearning methods.
In Ashok N. Srivastava and MehranSahami, editors, Text Mining: Classification, Cluster-ing, and Applications, chapter 2, pages 27?50.
Chap-man & Hall/CRC.Matthew Gentzkow and Jesse Shapiro.
2005.
Media biasand reputation.
Technical report, National Bureau ofEconomic Research.Matthew Gentzkow and Jesse M. Shapiro.
2010.
Whatdrives media slant?
evidence from u.s. daily newspa-pers.
Econometrica, 78(1):35?71.Sean M. Gerrish and David M. Blei.
2011.
Predict-ing legislative roll calls from text.
In Proceedings ofICML.Sean M. Gerrish and David M. Blei.
2012.
How theyvote: Issue-adjusted models of legislative behavior.
InAdvances in NIPS 25.Stephan Greene and Philip Resnik.
2009.
More thanwords: syntactic packaging and implicit sentiment.
InProceedings of NAACL.Roderick P. Hart, Jay P. Childers, and Colene J. Lind.2013.
Political Tone: How Leaders Talk and Why.University of Chicago Press.Roderick P. Hart.
2009.
Campaign talk: Why electionsare good for us.
Princeton University Press.Dustin Hillard, Stephen Purpura, and John Wilker-son.
2008.
Computer-assisted topic classification formixed-methods social science research.
Journal of In-formation Technology & Politics, 4(4):31?46.Harold Hotelling.
1929.
Stability in competition.
TheEconomic Journal, 39(153):41?57.Michael Laver, Kenneth Benoit, and John Garry.
2003.Extracting policy positions from political texts usingwords as data.
The American Political Science Review,97(2):311?331.Wei-Hao Lin, Eric Xing, and Alexander Hauptmann.2008.
A joint topic and perspective model for ideo-logical discourse.
In Proceedings of ECML-PKDD.Rada Mihalcea.
2005.
Unsupervised large-vocabularyword sense disambiguation with graph-based algo-rithms for sequence data labeling.
In Proceedings ofEMNLP.Burt L. Monroe and Ko Maeda.
2004.
Talk?s cheap:Text-based estimation of rhetorical ideal-points.
Pre-sented at the Annual Meeting of the Society for Politi-cal Methodology.Tony Mullen and Robert Malouf.
2006.
A preliminaryinvestigation into sentiment analysis of informal polit-ical discourse.
In AAAI Symposium on ComputationalApproaches to Analysing Weblogs.Keith T. Poole and Howard Rosenthal.
1985.
A spatialmodel for legislative roll call analysis.
American Jour-nal of Political Science, 29(2):357?384.Keith T. Poole and Howard Rosenthal.
2000.
Congress:A Political-Economic History of Roll Call Voting.
Ox-ford University Press.Warren Sack.
1994.
Actor-role analysis: ideology, pointof view, and the news.
Master?s thesis, MassachusettsInstitute of Technology, Cambridge, MA.Karl-Michael Schneider.
2005.
Weighted average point-wise mutual information for feature selection in textcategorization.
In Proceedings of PKDD.Swapna Somasundaran and Janyce Wiebe.
2009.
Rec-ognizing stances in online debates.
In Proceedings ofACL.Matt Thomas, Bo Pang, and Lillian Lee.
2006.
Get outthe vote: determining support or opposition from con-gressional floor-debate transcripts.
In Proceedings ofEMNLP.Kristina Toutanova, Christopher D. Manning, and An-drew Y. Ng.
2004.
Learning random walk models forinducing word dependency distributions.
In Proceed-ings of ICML.101
