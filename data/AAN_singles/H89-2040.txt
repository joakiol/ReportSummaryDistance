Continuous Speech Recognition from Phonetic TranscriptionS.
E. LevinsonA LjoljeSpeech Research DepartmentAT&T Bell LaboratoriesMurray Hill, NJ 07974Previous research by the authors has been directed toward phonetic transcription offluent speech.
We have applied our techniques to speech recognition on the DARPAResource Management Task.
In order to perform speech recognition, however, thephonetic transcription must be interpreted as a sequence of words.
A centralcomponent of this process is lexical access for which a novel method is proposed.The new technique treats lexical access as simply a string-to-string editing problem.That is, we seek the grammatically correct sequence of words whose phonetic spelling,as given in a dictionary, is closest, in a well defined sense, to the computed phonetictranscription of an actual utterance.
The distance between two phonetic units is takenas the Euclidean distance between the means of their respective spectral and durationaldensities.
This measure is called the rhobar metric and is known to have manyinteresting properties.
This measure is especially appealing here since the neededdensities are already present in the hidden Markov model on which the phonetictranscriptions are based.
We extend this metric heuristically to the case of insertionsand deletions by using the distance between the inserted or deleted unit and silence.The string-to-string editing operation is then easily performed by a two-level dynamicprogramming algorithm in which the inner level performs lexical access and the outerlevel does the parsing.The method has been applied to the DARPA continuous peech recognition task usingthe strict task grammar.
The acoustic/phonetic model was derived from 3969 sentencesrecorded from 109 speakers.
Model parameters were obtained from sample statisticscomputed on the basis of phonetic segmentation performed by a segmental k-meansalgorithm.Rather than attempt o measure phonetic accuracy, we have synthesized the speechfrom the phonetic transcription augmented by computed uration and pitch.
The resultis remarkably intelligible, especially when considering that it is equivalent to a 120BPS coder.
Audio tapes of the synthesized speech are available from the authors.
Wealso tested our system on the October 1989 DARPA Test Data.
Although the bestspeaker (speaker #1) achieved an 82% word accuracy rate, The overall word accuracyon the 10 speakers was 57.2% comprising 27.3% substitutions, 12.9% insertions, 2.7%deletions and 70.2% correct classifications.
The high error rate is the result ofcatastrophic failure of the recognizer in which occasional sentences are entirelymisrecognized.
We do not yet understand the cause of this failure mode.Although these results are disappointing, the high quality of the phonetic transcriptionand the simplicity of the architecture are an incentive to continue the research.292
