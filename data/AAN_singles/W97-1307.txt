Recognizing Referential Links:An Information Extraction PerspectiveMegumi KameyamaArtificial Intelligence CenterSRI International333 Ravenswood Ave., Menlo Park, CA 94025, U.S.A.megumi@ai, sri.
tomAbstractWe present an efficient and robust reference reso-lution algorithm in an end-to-end state-of-the-artinformation extraction system, which must workwith a considerably impoverished syntactic analy-sis of the input sentences.
Considering this disad-vantage, the basic setup to collect, filter, then orderby salience does remarkably well with third-personpronouns, but needs more semantic and discourseinformation to improve the treatments ofother ex-pression types.IntroductionAnaphora resolution is a component technology ofan overall discourse understanding system.
Thispaper focuses on reference resolution in an infor-mation extraction system, which performs a par-tial and selective 'understanding' of unrestricteddiscourses.Reference Resolution in IEAn information extraction (IE) system automat-ically extracts certain predefined target informa-tion from real-world online texts or speech tran-scripts.
The target information, typically of theform "who did what to whom where when," is ex-tracted from natural language sentences orformat-ted tables, and fills parts of predefined templatedata structures with slot values.
Partially filledtemplate data objects about the same entities, en-tity relationships, and events are then merged tocreate a network of related data objects.
Thesetemplate data objects depicting instances of thetarget information are the raw output of IE, readyfor a wide range of applications such as database 46updating and summary generation.
1In this IE context, reference resolution takes theform of merging partial data objects about thesame entities, entity relationships, and events de-scribed at different discourse positions.
Mergingin IE is very difficult, accounting for a significantportion of IE errors in the final output.
This pa-per focuses on the referential relationships amongentities rather than the more complex problem ofevent merging.An IE system recognizes particular target infor-mation instances, ignoring anything deemed irrel-evant.
Reference resolution within IE, however,cannot operate only on those parts that describetarget information because anaphoric expressionswithin target linguistic patterns may have an-tecedents outside of the target, and those that oc-cur in an apparently irrelevant pattern may ac-tually resolve to target entities.
For this reason,reference resolution in the IE system needs ac-cess to all of the text rather than some selectiveparts.
Furthermore, it is reasonable to assume thata largely domain-independent method of referenceresolution can be developed, which need not betailored anew each time a new target is defined.In this paper, I discuss one such entity refer-ence resolution algorithm for a general geo-politicalbusiness domain developed for SRI's FASTUS TMsystem (Hobbs et al, 1996), one of the leading IEsystems, which can also be seen as a representativeof today's IE technology.IThe IE technology has undergone a rapid developmentin the 1990s driven by the series of Message Understand-ing Conferences (MUCs) in the U.S. government-sponsoredTIPSTER program (http ://www.
t ips ter ,  org).The Input  to Reference Resolut ionMultiple top-scoring sites working on IE have con-verged on the use of finite-state linguistic patternsapplied in stages of smaller to larger units.
Thisfinite-state transduction approach to IE, first intro-duced in SRI's FASTUS, has proven effective forreal-world texts because full parsing is far too am-biguous, slow, and brittle against real-world sen-tences.
This means that we cannot assume correctand full syntactic structures in the input to ref-erence resolution in a typical IE system.
The in-put is a set of (often overlapping or discontiguous)finite-state approximations of sentence parts.
Wemust approximate fine-grained theoretical propos-als about referential dependencies, and adapt themto the context of sparse and incomplete syntacticinput.The  input to reference resolution in the the-oretical literature is assumed to be fully parsedsentences, often with syntactic attributes uch asgrammatical functions and thematic roles on theconstituents (Webber, 1978; Sidner, 1979; Hobbs,1978; Grosz, Joshi, and Weinstein, 1995).
In im-plemented reference resolution systems, for pro-noun resolution in particular, there seems to bea trade-off between the completeness of syntac-tic input and the robustness with real-world sen-tences.
In short, more robust and partial parsinggives us wider coverage, but less syntactic infor-mation also leads to less accuyate reference reso-lution.
For instance, Lappin and Leass (1994) re-port an 86% accuracy for a resolution algorithmfor third-person pronouns using fully parsed sen-tences as input.
Kennedy and Boguraev (1996)then report a 75% accuracy for an algorithm thatapproximates Lappin and Leass's with more robustand coarse-grained syntactic input.
After describ-ing the algorithm in the next section, I will brieflycompare the present approach with these pronounresolution approaches.AlgorithmThis algorithm was first implemented for theMUC-6 FASTUS system (Appelt et al, 1995), andproduced one of the top scores (a recall of 59%and precision of 72%) in the MUC-6 CoreferenceTask, which evaluated systems' ability to recog- 47nize coreference among noun phrases (Sundheim,1995).
Note that only identity of reference wasevaluated there.
2The three main factors in this algorithm are (a)accessible text regions, (b) semantic onsistency,and (c) dynamic syntactic preference.
The algo-rithm is invoked for each sentence after the earlierfinite-state transduction phases have determinedthe best sequence(s) of nominal and verbal expres-sions.
Crucially, each nominal expression is associ-ated with a set of template data objects that recordvarious linguistic and textual attributes of the re-ferring expressions contained in it.
These data ob-jects are similar to discourse referents in discoursesemantics (Karttunen, 1976; Kamp, 1981; Heim,1982; Kamp and Reyle, 1993), in that anaphoricexpressions uch as she are also associated withcorresponding anaphoric entities.
A pleonastic ithas no associated entities.
Quantificational nomi-nals such as each company are associated with en-tity objects because they are 'anaphoric' to groupentities accessible in the context.
In this setup, theeffect of reference resolution is merging of multipleentity objects.
Here is the algorithm.1.
INPUT: Template entities with the followingtextual, syntactic, and semantic features:(a) determiner type (e.g., DEF, INDEF, PRON)(b) grammatical or numerical number (e.g., SG,PL, 3)(c) head string (e.g., automaker)(d) the head string sort in a sort hierarchy (e.g.,aut omaker-+ company-+organizat ion)(e) modifier strings (e.g., newly founded, with thepilots)(f) text span (the start and end byte positions)(g) sentence and paragraph positions 3(h) text region type (e.g., HEADLINE, TEXT)2Other referential relationships such as subset and part-whole did not reach sufficiently reliable interannotatoragreements.
Only identity of reference had a sufficientlyhigh agreement rate (about 85%) between two humanannotators.ZHigher text structure properties such as subsections andsections hould also be considered if there are any.
Exactaccessibility computation using complex hierarchical textstructures i a future topic of study.2.
FOR EACH potentially anaphoric entity objectin the current sentence, in the left-to-right order,DO(1) COLLECT antecedent entity objects from theaccessible text region.?
For an entity in a HEADLINE text region,the entire TEXT is accessible because theheadline summarizes the text.?
For an entity in a TEXT region, everythingpreceding its text span is accessible (except forthe HEADLINE).
Intrasentential cataphorais allowed only for first-person pronouns.?
In addition, a locality assumption onanaphora sets a (soft) window of search foreach referring expression type--the entirepreceding text for proper names, narrower fordefinite noun phrases, even narrower for pro-nouns, and only the current sentence for re-flexives.
In the MUC-6 system, the windowsize was arbitrarily set to ten sentences fordefinites and three sentences for pronouns,ignoring paragraph boundariesl and no an-tecedents beyond the limit were considered.This clearly left ample room for refinement.
4(2) FILTER with semantic consistency betweenthe anaphoric entity E1 and the potential an-tecedent entity E2.?
Number Consistency: El's number must beconsistent with E2's number--for example,twelve is consistent with PLURAL, but notwith SINGULAR.
As a special case, pluralpronouns (they, we) can take singular organi-zation antecedents.?
Sort Consistency: El's sort must ei-ther EQUAL or SUBSUME E2's sort.This reflects a monotonicity assumption onanaphora--for example, since company sub-sumes automaker, the company can take aChicago-based automaker as an antecedent,but it is too risky to allow the automakerto take a Chicago-based company as anantecedent.
On the other hand, since4For example, in a more recent FASTUS system, para-graphs are also considered in sett ing the limit, and at  mostone candidate beyond the l imit is proposed when no candi-dates are found within the limit.
48automaker and a i r l ine  are neither the samesort nor in a subsumption relation, an au-tomaker and the airline cannot corefer.
(Thesystem's ort hierarchy is still sparse and in-complete.)?
Modifier Consistency: El 's modifiers mustbe consistent with E2's modifiers--for ex-ample, French and British are inconsistent,but French and multinational are consistent.
(The system doesn't have enough knowledgeto do this well.
)(3) ORDER by dynamic syntactic preference.
Thefollowing ordering approximates the relativesalience of entities.
The basic underlyinghypothesis is that intrasentential candidatesare more salient than intersentential candi-dates as proposed, for example, in Hobbs(1978) and Kameyama (in press), and thatfine-grained syntax-based salience fades withtime.
Since fine-grained syntax with gram-matical functions is unavailable, the syntacticprominence of subjects and left-dislocation isapproximated by the left-right linear ordering.i.
the preceding part of the same sentence inthe left -r ight orderii.
the immediately preceding sentence in theleft -r ight orderiii.
other preceding sentences within the 'limit'(see above) in the r ight- left  order3.
OUTPUT: After each anaphoric entity has foundan ordered set of potential antecedent entities,there are destructive (indefeasible) and nonde-structive (defeasible) options.
(a) Destructive Option: MERGE the anaphoricentity into the preferred antecedent entity .
(b) Nondestructive Option: RECORD the an-tecedent entity list in the anaphoric entity toallow reordering (i.e., preference revisions) byevent merging or overall model selection.The MUC-6 system took the destructive op-tion.
The nondestructive option has been im-plemented in a more recent system.These basic steps of "COLLECT, FILTER, andORDER by salience" are analogous to Lappin andLeass's (1994) pronoun resolution algorithm, buteach step in FASTUS relies on considerably poorersyntactic input.
The present algorithm thus pro-vides an interesting case of what happens withextremely poor syntactic input, even poorer thanin Kennedy and Boguraev's (1996) system.
Thiscomparison will be discussed later.Name Al ias  Recogn i t ionIn addition to the above general algorithm, aspecial-purpose alias recognition algorithm is in-voked for coreference r solution of proper names.
51.
INPUT: The input English text is in mixedcases.
An earlier transduction phase has rec-ognized unknown names as well as specific-type names for persons, locat ions,  ororganizat ions  using name-internal patternmatching and known name lists.2.
FOR EACH new sentence, FOR EACH unknownname, IF it is an alias or acronym of an-other name already recognized in the given text,MERGE the two--an alias is a selective sub-string of the full name (e.g., Colonial for Colo-nial Bee)~, and acronym is a selective sequenceof initial characters in the full name (e.g., GMfor General Motors).Overa l l  Per fo rmanceThe MUC-6 FASTUS reference resolution algo-rithm handled only coreference (i.e., identity of ref-erence) of proper names, definites, and pronouns.These are the 'core' anaphoric expression typeswhose dependencies tend to be constrained by sur-face textual factors such as locality.
The MUC-6Coreference Task evaluation included coreferenceof bare nominals, possessed nominals, and indefi-nites as well, which the system did not handle be-cause we didn't have a reliable algorithm for thesemostly 'accidental' coreferences that seemed to re-quire deeper inferences.
Nevertheless, the systemscored a recall of 59% and precision of 72% in theblind evaluation of thirty newspaper articles.5 In addition, a specific-type name may be converted intoanother type in certain linguistic ontexts.
For instance, ina subsidiary of Mrs. Field, Mrs. Field is converted from aperson name into a company name.49Expression Type Number ofOccurrencesDefinites ' 61Pronouns 39Proper Names 32Reflexives 1TOTAL 133CorrectlyResolved28(46%)24(62%)22(69%)1(100%)75(56%)Table 1: Core Discourse Anaphors in Five ArticlesGrammaticalPerson3rd person3rd personthatlst /2nd personreflexiveIntra/Inter-SAntecedentintra-Sinter-Sinter-Sinter-Sintra-SNumber ofOccurrences276151CorrectlyResolved21(78%)2(33%)0(0%)1(20%)1(100%)Table 2: Pronouns in Five ArticlesTable 1 shows the system's performance in re-solving the core discourse anaphors in five ran-domely selected articles from the development set.Only five articles were examined here because theprocess was highly time-consuming.
The perfor-mance for each expression type varies widely fromarticle to article because of unexpected features ofthe articles.
For instance, one of the five articles isa letter to the editor with a text structure drasti-cally different from news reports.
On average, wesee that the resolution accuracy (i.e., recall) wasthe highest for proper names (69%), followed bypronouns (62%) and definites (46%).
There werenot enough instances of reflexives to compare.Table 2 shows the system's performance for pro-nouns broken down by two parameters, gram-matical person and inter- vs. intrasententialantecedent.
The system did quite well (78%)with third-person pronouns with intrasententialantecedents, the largest class of such pronouns.Part of the pronoun resolution performance hereenables a preliminary comparison with the resultsreported in (1) Lappin and Leass (1994) and (2)Kennedy and Boguraev (1996).
For the third-person pronouns and reflexives, the performancewas (1) 86% of 560 cases in five computer manu-als and (2) 75% of 306 cases in twenty-seven Webpage texts.
The present FASTUS system correctlyresolved 71% of 34 cases in five newspaper arti-cles.
This progressive decline in performance cor-responds to the progressive decline in the amountof syntactic information in the input to referenceresolution.
To summarize the latter decline, Lap--pin and Leass (1994) had the following componentsin their algorithm.1.
INPUT: fully parsed sentences with grammati-cal roles and head-argument and head-adjunctrelations2.
Intrasentential syntactic filter based on syntacticnoncoreference3.
Morphological filter based on person, number,and gender features4.
Pleonastic pronoun recognition5.
Intrasentential binding for reflexives and recip-rocals6.
Salience computation based on grammaticalrole, grammatical parallelism, frequency of men-tion, proximity, and sentence recency7.
Global salience computation for noun phrases(NPs) in equivalence classes (with seven saliencefactors)8.
Decision procedure for choosing among equallypreferred candidate antecedentsKennedy and Boguraev (1996) approximated theabove components with a poorer syntactic input,which is an output of a part-of-speech tagger withgrammatical function information, plus NPs recog-nized by finite-state patterns and NPs' adjunct andsubordination contexts recognized by heuristics.With this input, grammatical functions and prece-dence relations were used to approximate 2 and5.
Finite-state patterns approximated 4.
Threeadditional salience factors were used in 7, and apreference for intraclausal antecedents was addedin 6; 3 and 8 were the same.The present algorithm works with an even poorersyntactic input, as summarized here.1.
INPUT: a set of finite-state approximations ofsentence parts, which can be overlapping or dis-contiguous, with no grammatical function, sub-ordination, or adjunct information..3.4..50No disjoint reference filter is used.Morphological filter is used.Pleonastic pronouns are recognized with finite-state patterns.Reflexives imply limit the search to the currentsentence, with no attempt at recognizing coar-guments.
No reciprocals are treated.. Salience is approximated by computation basedon linear order and recency.
No grammaticalparallelism is recognized.. Equivalence classes correspond to merged entityobjects whose 'current' positions are always themost recent mentions.8.
Candidates are deterministically ordered, so nodecision procedure is needed.Given how little syntactic information is used inFASTUS reference resolution, the 71% accuracy inpronoun resolution is perhaps unexpectedly high.This perhaps shows that linear ordering and re-cency are major indicators of salience, especiallybecause grammatical functions correspond to con-stituent ordering in English.
The lack of disjointreference filter is not the most frequent source oferrors, and a coarse-grained treatment of reflexivesdoes not hurt very much, mainly because of the in-frequency of reflexives.An Example  Ana lys i sIn the IE context, the task of entity reference res-olution is to recognize referential links among par-tially described entities within and across docu-ments, which goes beyond third-person pronounsand identity of reference.
The expression types tobe handled include bare nominals, possessed nomi-nals, and indefinites, whose referential links tend tobe more 'accidental' than textually signaled, andthe referential links to be recognized include sub-set, membership, and part-whole.Consider one of the five articles evaluated, theone with the most number and variety of referentiallinks, for which FASTUS's performance was thepoorest.
Even for the 'core' anaphoric expressionsof 20 definites, 14 pronouns, and 7 names limitedExpression Type Number ofOccurrencesDefinitesPronounsBare NominalsProper NamesPossessed NominalsIndefinitesTOTAL251412763CorrectlyResolved10(40%)10(71%)3(25%)2(29%)0(0%)0(0%)25(37%)Table 3: Referential Links in the Exampleto coreference, for which the code was prepared,the recall was only 51%.Figure 1 shows this article annotated with ref-erential indices.
The same index indicates corefer-ence.
Index subscripts (such as 4a) indicate subset,part, or membership of another expression (e.g.,indexed 4).
The index number ordering, 1,...,N,has no significance.
Each sentence in the TEXTregion is numbered with paragraph and sentencenumbers, so, for instance, 2-1 is the first sentencein the second paragraph.Note that not all of these referential links needbe recognized for each particular IE application.However, since reference resolution must considerall of the text for any particular application for thereason mentioned above, it is reasonable to assumethat an ideal domain-independent reference resolu-tion component should be able to recognize all ofthese.
Is this a realistic goal, especially in an IEcontext?
This question is left open for now.Er ror  AnalysisTable 3 shows the system's performance in recog-nizing the referential links in this article, groupedby referring expression types.
These exclude theinitial mention of each referential chain.
Notablesources of errors and necessary extensions are sum-marized for each expression type here.P ronouns :  Of the four pronoun resolution errors,one is due to a parse error (American in 7-1 wasincorrectly parsed as a person entity, to whichshe in 8-1 was resolved), that in 6-2 is a discoursedeixis (Webber, 1988), beyond the scope of thecurrent approach, and two errors (it in 3-1 andits in 7-1) were due to the left-right ordering ofintrasentential candidates.
Recognition of par- 51allelism among clause conjuncts and a stricterlocality preference for possessive pronouns mayhelp here.Def in i tes:  Of the fifteen incorrect resolutions ofdefinites, five have nonidentity referential rela-tionships, and hence were not handled.
Thesenonidentity cases must be handled to avoid er-roneous identity-only resolutions.
Two errorswere due to the failure to distinguish betweengeneric and specific events.
Token-referring def-inites (the union in 8-2 and the company in 9-1)were incorrectly resolved to recently mentionedtypes.
Three errors were due to the failure torecognize synonyms between, for example, call(3-2) vs. request (3-1) and campaign (9-1) vs.strategy (9-1).
Other error sources are a failurein recognizing an appositive pattern (9-1), theleft-right ordering of the candidates in the pre-vious sentence (9-2), and three 'bugs'.P roper  Names:  Name alias recognition was un-usually poor (2 out of 7) because American wasparsed as a person-denoting noun.
The lower-case print in Patt gibbs also made it difficult tolink it with Ms. Gibbs.
Such parse errors andinput anomalies hurt performance.Bare  Nomina ls :  Since bare nominaJs were notexplicitly resolved, the only correct resolutions(3 out of 12) were due to recognition of ap-positive patterns.
How can the other cases betreated?
We need to understand the discoursesemantics of bare nominMs better before devel-oping an effective algorithm.Possessed Nomina ls :  A systematic treatment ofpossessed nominals is a necessary extension.
Thebasic algorithm will look like this--resolve thepossessor entity A of the possessed nominalASs B, then if there is already an entity of typeB associated with A mentioned anywhere in thepreceding text, then this is the referent of B. Pos-sessed nominal resolution also requires a 'syn-onymy' computation to resolve, for example, itsbattle (9-1) to its corporate campaign (7-1).
Italso needs 'inferences' that rely on multiple suc-cessful resolutions.
For instance, her membersin 8-1 must first resolve her to Ms. Gibbs, whoHEADLINE: Amer ican  Air l ines1 Calls for Mediat ion15 In Its1 Union4 Talks2DOCUMENT DATE: 02/09/87SOURCE: WALL STREET JOURNAL1-1 Amr corp.'s Amer ican  Air l ines1 unit said it1 has called for federa l  mediat ion15 in itsl  cont ract  talks2 with unions4representing its1 pilots10 and f l ight at tendants17.2-1 A spokesman for the  company l  said Amer ican l  officials "felt talks2 had reached a point where mediat ion15 would behelpful.
"2-2 Negot iat ions2a with the  pilots16 have been going on for 11 months; talks2b with f l ight  a t tendants lv  began six monthsago.3-1 The  pres ident5 of the  Assoc ia t ion  o f  Pro fess iona l  F l ight  At tendants4a ,  which represents Amer ican l ' s  more  than10,000 f l ight a t tendants l~,  called the  requests  for mediat ion l~ "premature" and characterized its as a bargainingtactic that could lead to a lockout.3-2 Pat t  gibbss,  p res idents  of the  associat ion4a,  said talks2b with the  company1 seemed to be progressing well and thecalls for mediat ion15 came as a surprise.4-1 The major outstanding issue in the  negot iat ions2b with the  f l ight at tendants17 is a two-tier wage scale, in which recentemployees' alaries increase on a different scale than the salaries of employees who have worked at amer ican1 for a longertime.4-2 The  union4a wants to narrow the differences between the new scale and the old one.5-1 The  company1 declined to comment on the  negotiat lons2b or the outstanding issues.5-2 Representatives for the  5 ,400-member  A l l ied  P i lo ts  Associat ion4b didn't return phone calls.6-1 Under the Federal Railway Labor Act, \[if the  mediator l s~ fails to bring the  two sides~ together and the  two sidesTdon't agree to binding arbitration, a 30-day cooling-off period follows\]0.6-2 After that6,  the  unionTa can strike or the  companyT~ can lock the  unlon~a out.7-1 Ms.  Gibbs5 said that in response to the  company l ' s  move, hers union4a will be "escalating" its4~ "corporate campaign"against Amer ican1 over the next couple of months.7-2 In a corporate  campaign10, a union9 tries to get a companys 's  financiers, investors, directors and other financialpartners to pressure the  companys  to meet union9 demands.8--1 A corporate  campaign~0, she5 said, appeals to her5 members l~ because "it10 is a nice, clean way to take a job action,and our4~ women17 are hired to be nice.
"8-2 the  union4a has decided not to strike, she5 said.9-1 The  union4~ has hired a number  o f  pro fess iona l  consultants14 in its4~ battle18 with the  company1,  including RayRogers14,~ of Corporate Campaign Inc., the  New York labor  consultant14a who developed the  strategy12 at Geo.A.
Hormel  ~ Co. ls 's  Austin, Minn., meatpacking plant last year.9-2 That  campaign12, which included a strike, faltered when the  company13 hired new workers and the InternationalMeatpacking Union wrested control of the local union from Rogers14a' supporters.F igure  1: Example  Ar t i c le  Annotated  w i th  Referent ia l  L inks52is president of the association, and this 'associa-tion' is the Association of Professional Flight At-tendants.
After it is understood as 'the membersof the Association of Professional Flight Atten-dants,' the coreference with the flight attendantscan be inferred.
Similarly for our women in 8-1.Indefinites: Some indefinites are 'coreferential' togeneric types, for example, a corporate campaign(7-2, 8-1).
Given the difficulty in distinguishingbetween generic and specific event descriptions,it is unclear whether it will ever be treated in asystematic way.Conclus ionsIn an operational end-to-end iscourse understand-ing system, a reference resolution component mustwork with input data containing parse errors, lex-icon gaps, and mistakes made by earlier referenceresolution.
In a state-of-the-art IE system suchas SRI's FASTUS, reference resolution must workwith considerably impoverished syntactic analysisof the input sentences.
The present reference res-olution approach within an IE system is robustand efficient, and performs pronoun resolution toan almost comparable level with a high-accuracyalgorithm in the literature.
Desirable extensionsinclude nonidentity referential relationships, treat-ments of bare nominals, possessed nominals, andindefinites, type-token distinctions, and recogni-tion of synonyms.
Another future direction is toturn this component into a corpus-based statisti-cal approach using the relevant factors identifiedin the rule-based approach.
The need for a largetagged corpus may be difficult to satisfy, however.AcknowledgmentThis work was in part supported by U.S. govern-ment cont rac ts~ _ - - -  _" __:3ReferencesAppelt, Douglas, Jerry Hobbs, John Bear, David Israel,Megumi Kameyama, Andy Kehler, David Martin, KarenMyers, and Mabry Tyson.
1995.
SRI International FAS-TUS system: MUC-6 test results and analysis.
In Pro-ceedings of the 6th Message Understanding Conference,pages 237-248.
DARPA.53Grosz, Barbara, Aravind Joshi, and Scott Weinstein.
1995.Centering: A framework for modelling the local coherenceof discourse.
Computational Linguistics, 21(2):203-226.Heim, Irene.
1982.
The Semantics off Definite and IndefiniteNoun Phrases.
Ph.D. thesis, University of Massachusettsat Amherst.Hobbs, Jerry.
1978.
Resolving pronoun references.
Lin-gua, 44:311-338.
Also in B. Grosz, K. Sparck-Jones, andB.
Webber, eds., Readings in Natural Language Process-ing, Morgan Kaufmann, Los Altos, CA, 1986, 339-352.Hobbs, Jerry R., Douglas E. Appelt, John Bear, DavidIsrael, Megumi Kameyama, Mark Stickel, and MabryTyson.
1996.
FASTUS: A cascaded finite-state trans-ducer for extracting information from natural-languagetext.
In E. Roche and Y. Schabes, editors, Finite StateDevices \]for Natural Language Processing.
MIT Press,Cambridge,Massachusetts.Kameyama, Megumi.
in press.
Intrasentential centering: Acase study.
In Marilyn Walker, Aravind Joshi, and EllenPrince, editors, Centering in Discourse.
Oxford Univer-sity Press.Kamp, Hans.
1981.
A theory of truth and semantic repre-sentation.
In J. Groenendijk, T. Janssen, and M. Stokhof,editors, Formal Methods in the Study of Language.
Math-ematical Center, Amsterdam, pages 277-322.Kamp, Hans and Uwe Reyle.
1993.
From Discourse toLogic.
Kluwer, Dordrecht.Karttunen, Lauri.
1976.
Discourse referents.
In James D.McCawley, editor, Syntax and Semantics: Notes \]from theLinguistic Underground, volume 7.
Academic Press, NewYork, pages 363-386.Kennedy, Christopher and Branimir Boguraev.
1996.Anaphora for everyone: Pronominal anaphora resolu-tion without a parser.
In Proceedings off the 16thInternational Con\]ference on Computational Linguistics(COLING-'96}.
Association for Computational Linguis-tics.Lappin, Shalom and Herbert Leass.
1994.
An algorithm forpronominal anaphora resolution.
Computational Linguis-tics, 20(4):535-562.Sidner, Candace.
1979.
Towards a computational theoryof definite anaphora comprehension in English discourse.Technical Report 537, MIT Artificial Intelligence Labo-ratory, Cambridge, MA, June.Sundheim, Beth.
1995.
Overview of results of the MUC-6 evaluation.
In Proceedings of the 6th Message Under-standing Conference, pages 13-32.
DARPA.Webber, Bonnie.
1988.
Discourse deixis: Reference todiscourse segments.
In Proceedings of the 26th AnnualMeeting off the Association \]for Computational Linguis-tics, pages 113-122.
Association for Computational Lin-guistics, June.Webber, Bonnie Lynn.
1978.
A Formal Approach to Dis-course Anaphora.
Ph.D. thesis, Harvard University.
