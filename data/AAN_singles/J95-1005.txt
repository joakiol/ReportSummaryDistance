Squibs and DiscussionsDependency Unification Grammar forPROLOGFriedrich Steimann*Universit~t KarlsruheChristoph Brzoska*Universit/it Karlsruhe1.
IntroductionThe programming language PROLOG has proved to be an excellent ool for imple-menting natural language processing systems.
Its built-in resolution and unificationmechanisms are well suited to both accept and generate sentences of artificial and nat-ural languages.
Although supporting many different linguistic formalisms, its straight-forwardness and elegance have perhaps best been demonstrated with definite clausegrammars (DCGs) (Pereira and Warren 1980), an extension to PROLOG's syntax al-lowing direct implementation of rules of context-free grammars as Horn clauses.While context-free grammars and DCGs--strongly related to the huge linguisticfield of constituency or phrase structure grammars and their descendants--have be-come very popular among logic programmers, dependency grammars (DGs) have longremained a widely unnoticed linguistic alternative.
DG is based on the observationthat each word of a sentence has individual slots to be filled by others, its so-calleddependents.
Which dependents a particular word takes depends not only on its func-tion within the sentence, but also on its meaning--like other contemporary linguisticframeworks, DG integrates both syntactic and semantic aspects of natural anguage.DG was first formalized by Tesni6re (1959) and later, among others, by Gaifman(1965) and Hays (1964).
The formalization presented in this paper is based on Hellwig'sDependency Unification Grammar (DUG) (Hellwig 1986).
We merely add a frameworkfor automatic translation of DUG rules to Horn clauses that makes DUGs as easy toimplement as classic DCGs.2.
Dependency  Grammar as Context-Free GrammarWhereas context-free grammars differentiate between terminals (coding the words ofa language) and non-terminals (representing the constituents hat are to be expanded),the symbols of a DG uniformly serve both purposes: like terminals they must be partof the sentence to be accepted (or generated), and like non-terminals, they call for ad-ditional constituents of the sentence.
Despite this significant difference, DG can be de-fined in terms of context-free grammar, making the twofold role of its symbols explicit:Definit ionA context-free grammar G = (T, N, P, S) where--terminals and non-terminals are related by a one-to-one mappingf :  T --, N\{S} and* Institut ffir Logik, Komplexit~it und Deduktionssysteme, Universit~it Karlsruhe, Germany.
E-maih{steimann,brzoska } @ira.uka.de(~) 1995 Association for Computational LinguisticsComputational Linguistics Volume 21, Number 1each production in P is either of the forms ~//1 .-.
Y/rnor of the formn --* n l .
.
.
f - l (n) .
.
.nm,where n, nl , .
.
.
,  nm are elements of N\{S} and s = Sis a dependency grammar.Accordingly, if atomic symbols are replaced by first-order terms, the following toyDG can be implemented in PROLOG using the DCG rule format:s --> n(_, verb(_)).n(give, verb(N)) -->n(_, noun(N)),\[n(give, verb(N))\],n(_, noun(_)),n(_, noun(_)).n(sleep, verb(N)) -->n(_, noun(N)),\[n(sleep, verb(N))\].n( 'Peter ' ,  noun(N)) -->\ [n ( 'Peter ' ,  noun(N))\].n(CMark ', noun(N)) -->\[n(:Mark', noun(N))\].n(book, noun(N)) -->n(_, det),\[n(book, noun(N))\].n(a, det) -->\[n(a, det)\] .The terms n(., .)
provide space for feature structures commonly employed to capturesyntactic and semantic properties of words (Shieber 1986; Knight 1989).
They serveonly as an example here; other structures, including that used by Hellwig (1986), canalso be employed.Prior to parsing, each sentence must be converted to a string of terms holdingthe features derived through lexical analysis.
This preprocessing step also resolveslexical ambiguities by representing words with alternative meanings through differentsymbols.
Parsing the sentences "Peter gives Mark a book" and "Mark sleeps" with the96Friedrich Steimann and Christoph Brzoska Dependency Unification Grammar for PROLOGabove DCG produces the following dependency trees:sIgivesPeter Mark bookPeter gives Mark a booksIsleepsJMarkIMark sleeps3.
Direct Transformation of DUG Rules to Horn ClausesAlthough implementing DUG as DCG works acceptably, it makes no use of the rules'regular form: note how, when parsing the sentence "Mark sleeps," the parser callsseveral rules before it realizes that the rule for give must fail (because the sentencedoes not contain give), even though the head already indicates that give is required forthe rule to succeed.
If, however, the word partially specified as n(_, verb(_)) in the bodyof the start rule is accepted before the next rule is selected, an intelligent parser canexploit the fact that the sentence's verb is sleep and immediately call the appropriaterule.
We therefore suggest an alternative syntax and translation scheme that producesa more efficient DUG parser.In our DUG syntax, the head of a rule is separated from its body (holding thedependents of the word in the head) by the binary infix operator :>.
The start rules :> n(_, verb(_)).is translated to the Horn clauses(_G1, _G2) "-accept(n(_G3, verb(_G4)), _G1, _G5),n(_G3, verb(_G4), _G5, _G2).where the arguments appended to each predicate hold input and output sentence,respectively, and where an accept predicate is inserted before each literal of the rulebody.
1Accordingly,n(sleep, verb(N)) :> n(_, noun(N)).becomesn(sleep, verb(N), _GI, _G2) :-accept(n(_G3, noun(N)), _GI, _G4),n(_G3, noun(N), _G4, _G2).Note that the head literal of the sleep rule need not be repeated in the body becausethe respective word is removed from the input sentence before the rule is called (inthis case in the start rule).
The fact that a word has no dependent is coded byn(well, adverb) :> \[\].1 The implementation of accept(...) can be found in the appendix.97Computational Linguistics Volume 21, Number 1and translated ton(well, adverb, _G1, _GI).Like other contemporary grammar formalisms, DUG comes with syntactic extensionsthat code optionality and references.3.10ptionalityMany dependents are optional.
Rather than providing an alternative rule for everypossible combination of dependents, it is more convenient to declare a dependentoptional, meaning that a sentence is correct independent of its presence.
For example,n(sleep, verb(N)) :> n(_, noun(N)), ?
n(_, adverb).where ?
precedes the optional dependent, is implemented asn(sleep, verb(N), _GI, _G2) "-accept(n(_G3, noun(N)), _GI, _G4), n(_G3, noun(N), _G4, _G5),((accept(n(_G6, adverb)), _G5, _GT), n(_G6, adverb, _GT, _G2))_GS=_a2).accepting "Mark sleeps" as well as "Mark sleeps well.
"3.2 ReferencingReferences account for the fact that many words are similar in terms of the dependentsthey take.
In order not to repeat he same set of rules over and over again, a referenceoperator ~ (read 'goes like') is introduced that causes branching to the rule of ananalogous word, as inn(yawn, verb(N)) :> ==> n(sleep, verb(N)).In this case, the word sleep being referred to is not a dependent of yawn, the PROLOGtranslationn(yawn, verb(N), _GI, _G2) :- n(sleep, verb(N), _GI, _G2).therefore branches to the rule for sleep without accepting the word sleep.As a side effect, references introduce quasi non-terminals to DUG.
For example,by factoring out common dependency patterns, it is possible to generalize the rulesfor transitive verbs and allow for exceptions to the rule at the same time:standard dependents of transitive verbs in active voicetransverb(N, active) :>word(_, noun(N)), ~ subjectword(_, noun(_)).
~ objectstandard dependents of transitive verbs in passive voicetransverb(N, passive) :>word(_, noun(N)), ~ subject?
word(by, preposition).
~ optional agentstandard transitive verbword(like, verb(N, Voice)) :>==> transverb(N, Voice).98Friedrich Steimann and Christoph Brzoska Dependency Unification Grammar for PROLOGtransitive verb with additionalword(give, verb(N, Voice)) :>==> transverb(N, Voice),word(_, noun(_)).indirect object4.
A Word about Word OrderFollowing Hellwig's DUG formalism, our PROLOG implementation does not codeword order directly in the rules.
Other DG formalisms, such as the one proposed byGaifman (1965) and Hays (1964), mark the position of the head among its depen-dents by a special symbol in the body.
The DUG parser can be adapted to follow thisconvention by accepting the symbol self in the rule body as inn(sleep, noun(N)) :> n(_, noun(N)), self.and by modifying both the preprocessor and the accept predicate so that the inputsentence is split at the position of the dependent accepted and left and right remaindersare passed to the next rules separately.
However, many natural anguages leave wordorder rather unconstrained, and its adequate handling is not a problem specific to DGs(see, for example, Pereira 1981, and Covington 1990).5.
Notes on PerformanceThe presented DUG formalism with free word order has successfully been employedto parse Latin sentences.
Tracing showed that backtracking was considerably reducedas compared with an equivalent phrase structure grammar, although no good upperbound for complexity could be found (Steimann 1991).
Although the pure DG for-malism proved to be particularly practical for integration of idioms and exceptions,its lack of constituent symbols, i.e., non-terminals, would have lead to a grammarof enormous ize and made it difficult to integrate special Latin constructs uch asaccusative cum infinitive or ablative absolute.However, as shown above, DUG is a hybrid grammar: although dependency rulesare the backbone of the formalism, it allows the introduction of quasi non-terminalsthat are integrated into the grammar via references.
If desired, phrase structure rulescan thus easily be combined with ordinary dependency rules.The size of a grammar can be further reduced by introduction of order-sortedfeature types (Ait-Kaci and Nasr 1986) supporting variable numbers of labeled argu-ments and subtyping.
Using feature types instead of constructor terms for represent-ing the words of a language increases readability and enables abstraction of rules aswell as implementation f semantic type hierarchies supporting selectional restrictions(Steimann 1991).ReferencesAit-Kaci, H., and Nasr, R. (1986).
"LOGIN:A logic programming language withbuilt-in inheritance."
The Journal of LogicProgramming 3:185-215.Covington, M. A.
(1990).
"Parsingdiscontinuous constituents in dependencygrammar."
Computational Linguistics16(4):234-236.Gaifman, H. (1965).
"Dependency s stemsand phrase-structure systems.
"Information and Control 8:304-337.Hays, D. G. (1964).
"Dependency theory: Aformalism and some observations.
"Language 40(4):511-525.Hellwig, P. (1986).
"Dependency unificationgrammar."
In Proceedings, llth InternationalConference on Computational Linguistics(COLING 1986).
University of Bonn,Bonn.
195-198.99Computational Linguistics Volume 21, Number 1Knight, K. (1989).
"Unification: Amultidisciplinary survey."
ACMComputing Surveys 21(1):105-113.Pereira, E (1981).
"Extrapositiongrammars."
American Journal ofComputational Linguistics 7(4):243-255.Pereira, E, and Warren, D. H. D.
(1980).
"Definite clause grammars for languageanalysis--a survey of the formalism and acomparison with augmented transitionnetworks."
Artificial Intelligence13:231-278.Shieber, S. M. (1986).
"An introduction tounification-based approaches togrammar."
CLSI Lecture Notes, No.
4,Stanford University, Stanford, California.Steimann, E (1991).
"Ordnungssortiertefeature-Logik undDependenzgrammatiken n derComputerlinguistik."
DiplomarbeitUniversit~it Karlsruhe, Fakult~it fiirInformatik, Karlsruhe, Germany.Tesni6re, L. (1959).
Elements de syntaxestructurale.
Paris: Librairie Klincksiek.100Friedrich Steimann and Christoph Brzoska Dependency Unification Grammar for PROLOGAppendix AThe DUG PreprocessorThe following PROLOG source code implements a simple preprocessor that convertssource files containing DUG rules into target files consisting of Horn clauses only.Automatic reation of the parse tree has also been implemented.
However, it is omittedhere for clarity.Note that every call to a start rule must be extended by two list arguments: theinput and the output sentence (the latter usually being the empty list \[\]).operator directives (priorities must be adapted):- op(1200, xfx, ~:>').
:- op(600, fx, c?,).
:- op(500, fx, '==>').dug(Source, Target) "-see(Source),tell(Target),convert,seen,told.convert :-read(DUGClause),(DUGClause = end_of_fileconvert(DUGClause, PClause),displayq(PClause), write(:.
'), nl,convert).DUG ruleconvert((Headln :> Bodyln), (HeadOut :- BodyOut)) :-!, HeadIn =.. \[PredlArgs\],append(Args, \[In, Out\], Expanded),HeadOut =.. \[PredlExpanded\],convert(BodyIn, BodyOut, In, Out).otherconvert(Clause, Clause).% conjunctionconvert((AIn, Bin), (AOut, BOut), In, Out) :-!, convert(AIn, AOut, In, Intermediate),convert(Bin, BOut, Intermediate, Out).Z optionconvert(?
Aln, ((AOut); In = Out), In, Out) "-!, convert(AIn, AOut, In, Out).Z referenceconvert (==> AIn, AOut, In, Out) :-101Computational Linguistics Volume 21, Number 1!, AIn =.. \[PredlArgs\],append(Args, \[In, Out\], Expanded),AOut =.. \[PredlExpanded\].no dependentsconvert(\[\], true, In, In) "- !.dependent (introduces call to 'accept')convert(AIn, (accept(AIn, In, Intermediate), AOut), In, Out) :-AIn =.. \[PredIArgs\],append(Args, \[Intermediate, Out\], Expanded),AOut =.. \[PredIExpanded\].The accept predicate that must be included in every program containingDUGrulescan be implemented asfollows:accept(Element, \[ElementlString\], String).accept(Element, \[OtherlStringln\], \[OtherlStringOut\]) "-accept(Element, StringIn, StringOut).102
