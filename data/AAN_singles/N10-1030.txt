Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 246?249,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsImproving Semantic Role Labeling with Word SenseWanxiang Che, Ting Liu and Yongqiang LiResearch Center for Information RetrievalMOE-Microsoft Key Laboratory of Natural Language Processing and SpeechSchool of Computer Science and TechnologyHarbin Institute of Technology, China, 150001{car, tliu, yqli}@ir.hit.edu.cnAbstractSemantic role labeling (SRL) not only needslexical and syntactic information, but alsoneeds word sense information.
However, be-cause of the lack of corpus annotated withboth word senses and semantic roles, there isfew research on using word sense for SRL.The release of OntoNotes provides an oppor-tunity for us to study how to use word sensefor SRL.
In this paper, we present some novelword sense features for SRL and find that theycan improve the performance significantly.1 IntroductionSemantic role labeling (SRL) is a kind of shallowsentence-level semantic analysis and is becoming ahot task in natural language processing.
SRL aims atidentifying the relations between the predicates in asentence and their associated arguments.
At present,the main stream researches are focusing on featureengineering or combination of multiple results.Word senses are important information for rec-ognizing semantic roles.
For example, if we know?cat?
is an ?agent?
of the predicate ?eat?
in asentence, we can guess that ?dog?
can also bean ?agent?
of ?eat?.
Word sense has been suc-cessfully used in many natural language process-ing tasks, such as machine translation (Chan et al,2007; Carpuat and Wu, 2007).
CoNLL 2008 sharedtask (Surdeanu et al, 2008) first introduced the pred-icate classification task, which can be regarded asthe predicate sense disambiguation.
Meza-Ruiz andRiedel (2009) has shown that the predicate sense canimprove the final SRL performance.
However, thereis few discussion about the concrete influence of allword senses, i.e.
the words besides predicates.
Themajor reason is lacking the corpus, which is both an-notated with all word senses and semantic roles.The release of OntoNotes corpus provides an op-portunity for us to verify whether all word sensescan help SRL.
OntoNotes is a large corpus annotatedwith constituency trees (based on Penn Treebank),predicate argument structures (based on Penn Prop-Bank) and word senses.
It has been used in somenatural language processing tasks, such as joint pars-ing and named entity recognition (Finkel and Man-ning, 2009) and word sense disambiguation (Zhonget al, 2008).In this paper, we regard the word sense informa-tion as additional SRL features.
We compare threecategories of word sense features (subtree-word re-lated sense, predicate sense, and sense path) and findthat the subtree-word related sense feature is ineffec-tive, however, the predicate sense and the sense pathfeatures can improve the SRL performance signifi-cantly.2 Data PreparationIn our experiments, we use the OntoNotes Release2.01 corpus (Hovy et al, 2006).
The OntoNotesproject leaders describe it as ?a large, multilingualrichly-annotated corpus constructed at 90% inter-nanotator agreement.?
The corpus has been an-notated with multiple levels of annotation, includ-ing constituency trees, predicate argument struc-ture, word senses, co-reference, and named entities.For this work, we focus on the constituency trees,word senses, and predicate argument structures.
Thecorpus has English and Chinese portions, and wejust use the English portion, which has been splitinto seven sections: ABC, CNN, MNB, NBC, PRI,VOA, and WSJ.
These sections represent a mix ofspeech and newswire data.Because we used SRL system based on depen-dence syntactic trees, we convert the constituency1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2008T04246trees into dependence trees with an Constituent-to-Dependency Conversion Tool2.
In addition, we alsoconvert the OntoNotes sense of each polysemantinto WordNet sense using sense inventory file pro-vided by OntoNotes 2.0.
For an OntoNotes sensewith more than one WordNet sense, we simply usethe foremost (more popular) one.3 Semantic Role Labeling SystemOur baseline is a state-of-the-art SRL system basedon dependency syntactic tree (Che et al, 2009).
Amaximum entropy (Berger et al, 1996) classifier isused to predict the probabilities of a word in thesentence to be each semantic role.
A virtual role?NULL?
(presenting none of roles is assigned) isadded to the roles set, so it does not need seman-tic role identification stage anymore.
For a predi-cate, two classifiers (one for noun predicates, andthe other for verb predicates) predict probabilities ofeach word in a sentence to be each semantic role (in-cluding virtual role ?NULL?).
The features used inthis stage are listed in Table 1.Feature DescriptionFirstwordLemma The lemma of the first word in asubtreeHeadwordLemma The lemma of the head word ina subtreeHeadwordPOS The POS of the head word in asubtreeLastwordLemma The lemma of the last word in asubtreePOSPath The POS path from a word to apredicatePathLength The length of a pathPosition The relative position of a wordwith a predicatePredicateLemma The lemma of a predicateRelationPath The dependency relation pathfrom a word to a predicateTable 1: Features that are used in SRL.4 Word Sense for Semantic Role LabelingFrom Table 1, we can see that there are lots of lemmaor POS related features.
However, the lemma fea-ture is very sparse and may result in data sparseness2http://nlp.cs.lth.se/software/treebank converter/problem.
As for the POS, it represents the syntacticinformation, but is not enough to distinguish differ-ent semantic roles.
Therefore, we need a kind of newfeature, which is general than the lemma and specialthan the POS.The word sense just satisfies the requirement.Thus, we will add some new features related withword sense for SRL.
Generally, the original featurescan be classified into three categories:1.
Subtree-word related: FirstwordLemma, Last-wordLemma, HeadwordLemma, and Head-wordPOS2.
Predicate related: PredicateLemma3.
Word and predicate related: POSPath, Rela-tionPath, PathLenght, and PositionCorrespondingly, we add three categories of wordsense features by replacing Lemma or POS intoSense, i.e.1.
Subtree-word related sense: FirstwordSense,LastwordSense, and HeadwordSense2.
Predicate related sense: PredicateSense3.
Word and predicate related sense: SensePathThree strategies are designed to adopt thesesenses:1.
Lemma+Sense: It is the original wordsense representation in OntoNotes, such as?dog.n.1?.
In fact, This is a specialization ofthe lemma.2.
Hypernym(n): It is the hypernym of a wordsense, e.g.
the hypernym of ?dog.n.1?
is ?ca-nine.n.1?.
The n means the level of the hy-pernym.
With the increasing of n, the sensebecomes more and more general.
In theory,however, this strategy may result in inconsis-tent sense, e.g.
word ?dog?
and ?canine?
havedifferent hypernyms.
The same problem occurswith Basic Concepts method (Izquierdo et al,2007).3.
Root Hyper(n): In order to extract more con-sistent sense, we use the hypernym of a wordsense counting from the root of a sense tree,e.g.
the root hypernym of ?dog.n.1?
is ?en-tity.n.1?.
The n means the level of the root hy-pernym.
With the increasing of n, the sense247becomes more and more special.
Thus, word?dog?
and ?canine?
have the same Root Hyper:?entity?, ?physical entity?, and ?object?
with n= 1, 2, and 3 respectively.5 ExperimentsWe will do our experiments on seven of theOntoNotes English datasets described in Section 2.For each dataset, we aimed for roughly a 60% train/ 20% development / 20% test split.
See Table 2for the detailed statistics.
In order to examine theinfluence of word senses in isolation, we use the hu-man annotated POS, parse trees, and word sensesprovided by OntoNotes.
The lemma of each word isextracted using WordNet tool.Training Developing TestingABC 669 163 138(0001-0040) (0041-0054) (0057-0069)CNN 1,691 964 1,146(0001-0234) (0235-0331) (0333-0437)MNB 381 130 125(0001-0015) (0016-0020) (0021-0025)NBC 351 129 86(0001-0025) (0026-0032) (0033-0039)PRI 1,205 384 387(0001-0067) (0068-0090) (0091-0112)VOA 1,238 325 331(0001-0159) (0160-0212) (0213-0264)WSJ 8,592 2,552 3,432(0020-1446) (1447-1705) (1730-2454)All 14,127 4,647 5,645Table 2: Training, developing and testing set sizes for theseven datasets in sentences.
The file ranges (in parenthe-sis) refer to the numbers within the names of the originalOntoNotes files.The baseline SRL system without sense informa-tion is trained with all the training corpus as de-scribed in Section 3.
Its performance on the devel-opment data is F1 = 85.48%.Table 3 shows the performance (F1) comparisonon the development data among different sense ex-tracting strategies with different feature categories.The numbers are the parameter n used in Hypernymand Root Hyper strategies.From Table 3, we can find that:1.
Both of the predicate sense feature and thesense path feature can improve the performance.
ForSubtree-word Predicate Senserelated sense sense pathLemma+Sense 85.34% 86.16% 85.69%1 85.41% 86.12% 85.74%Hypernym(n) 2 85.48% 86.10% 85.74%3 85.38% 86.10% 85.69%1 85.35% 86.07% 85.96%Root Hyper(n) 2 85.45% 86.13% 85.86%3 85.46% 86.05% 85.91%Table 3: The performance comparison on the devel-opment data among different sense extracting strategieswith different feature categories.the predicate sense feature, we arrive at the sameconclusion with Meza-Ruiz and Riedel (2009).
Asfor the sense path feature, it is more special than thePOS, therefore, it can enhance the precision.2.
The subtree-word related sense is almost use-less.
The reason is that the original lemma and POSfeatures have been able to describe the subtree-wordrelated information.
This kind of sense features isjust reduplicate.3.
For different sense feature categories(columns), the performance is not very seriously af-fected by different sense extracting strategies (rows).That is to say, once the sense of a word is disam-biguated, the sense expressing form is not importantfor SRL.In order to further improve the performance,we add the predicate sense and the sense pathfeatures simultaneously.
Here, we select theLemma+Sense strategy for the predicate sense andthe Root Hyper(1) strategy for the sense path.
Thefinal performance achieves F1 = 86.44%, which isabout 1% higher than the baseline (F1 = 85.48%).Finally, we compare the baseline (without sense)result with the word sense result on the test data.
Inorder to see the contribution of correct word senses,we introduce a simple sense determining strategy,which use the first (the most popular)WordNet sensefor each word.
The final detailed comparison resultsare listed in Table 4.Averagely, both of the methods with the first senseand the correct sense can perform better than thebaseline.
However, the improvement of the methodwith the first sense is not significant (?2-test3 with3http://graphpad.com/quickcalcs/chisquared1.cfm248Precision Recall F1w/o sense 86.25 83.01 84.60ABC first sense 84.91 81.71 83.28word sense 87.13 83.40 85.22w/o sense 86.67 79.97 83.19CNN first sense 86.94 80.73 83.72word sense 87.75 80.64 84.05w/o sense 85.29 81.69 83.45MNB first sense 85.04 81.85 83.41word sense 86.96 82.47 84.66w/o sense 84.49 76.42 80.26NBC first sense 84.53 76.63 80.38word sense 86.20 77.44 81.58w/o sense 86.48 82.29 84.34PRI first sense 86.82 83.10 84.92word sense 87.45 83.14 85.24w/o sense 89.87 86.65 88.23VOA first sense 90.01 86.60 88.27word sense 91.35 87.10 89.18w/o sense 88.38 82.93 85.57WSJ first sense 88.72 83.29 85.92word sense 89.25 84.00 86.54w/o sense 87.85 82.46 85.07Avg first sense 88.11 82.85 85.40word sense 88.84 83.37 86.02Table 4: The testing performance comparison amongthe baseline without (w/o) sense information, the methodwith the first sense, and the method with the correct wordsense.?
< 0.01).
Especially, for some sections, such asABC and MNB, it is harmful to the performance.
Incontrast, the correct word sense can improve the per-formance significantly (?2-test with ?
< 0.01)andconsistently.
These can further prove that the wordsense can enhance the semantic role labeling.6 ConclusionThis is the first effort to adopt the word sensefeatures into semantic role labeling.
Experimentsshow that the subtree-word related sense featuresare ineffective, but the predicate sense and the sensepath features can improve the performance signifi-cantly.
In the future, we will use an automatic wordsense disambiguation (WSD) system to obtain wordsenses and study the function of WSD for SRL.AcknowledgmentsThis work was supported by National NaturalScience Foundation of China (NSFC) via grant60803093, 60975055, the ?863?
National High-Tech Research and Development of China via grant2008AA01Z144, and Natural Scientific ResearchInnovation Foundation in Harbin Institute of Tech-nology (HIT.NSRIF.2009069).ReferencesAdam L. Berger, Stephen A. Della Pietra, and VincentJ.
Della Pietra.
1996.
A maximum entropy approachto natural language processing.
Computational Lin-guistics, 22.Marine Carpuat and Dekai Wu.
2007.
Improving statisti-cal machine translation using word sense disambigua-tion.
In Proceedings of EMNLP/CoNLL-2007, pages61?72, Prague, Czech Republic, June.Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007.Word sense disambiguation improves statistical ma-chine translation.
In Proceedings of ACL-2007, pages33?40, Prague, Czech Republic, June.Wanxiang Che, Zhenghua Li, Yongqiang Li, YuhangGuo, Bing Qin, and Ting Liu.
2009.
Multilingualdependency-based syntactic and semantic parsing.
InProceedings of CoNLL-2009, pages 49?54, Boulder,Colorado, June.Jenny Rose Finkel and Christopher D. Manning.
2009.Joint parsing and named entity recognition.
In Pro-ceedings of NAACL/HLT-2009, pages 326?334, Boul-der, Colorado, June.Eduard Hovy, Mitchell Marcus, Martha Palmer, LanceRamshaw, and Ralph Weischedel.
2006.
Ontonotes:The 90% solution.
In Proceedings of NAACL/HLT-2006, pages 57?60, New York City, USA, June.Rube?n Izquierdo, Armando Sua?rez, and German Rigau.2007.
Exploring the automatic selection of basic levelconcepts.
In Proceedings of RANLP-2007.Ivan Meza-Ruiz and Sebastian Riedel.
2009.
Jointlyidentifying predicates, arguments and senses usingmarkov logic.
In Proceedings of NAACL/HLT-2009,pages 155?163, Boulder, Colorado, June.Mihai Surdeanu, Richard Johansson, Adam Meyers,Llu?
?s Ma`rquez, and Joakim Nivre.
2008.
The conll2008 shared task on joint parsing of syntactic and se-mantic dependencies.
In Proceedings of CoNLL-2008,pages 159?177, Manchester, England, August.Zhi Zhong, Hwee Tou Ng, and Yee Seng Chan.
2008.Word sense disambiguation using OntoNotes: An em-pirical study.
In Proceedings of EMNLP-2008, pages1002?1010, Honolulu, Hawaii, October.249
