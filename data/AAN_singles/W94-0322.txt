Generating Indirect Answers to Yes-No QuestionsNancy  GreenDepartment of Computer ScienceUniversity of DelawareNewark, DE  19716, USAInternet: i green@udel.eduSandra Carber ryDepartment of Computer ScienceUniversity of DelawareVisitor: Inst.
for Research in Cognitive ScienceUniversity of PennsylvaniaInternet: carberry@udel.eduAbst rac tAn indirect answer to!
a Yes-No question conversation-ally implicates the speaker's evaluation of the truth ofthe questioned proposition.
We present he approachto generation used in our implemented system for gen-erating and interpret~ing indirect answers to Yes-Noquestions in English.
Generation of a discourse plan isperformed in two phases: content planning and planpruning.
During content planning, stimulus conditionsare used to trigger speaker goals to include appropriateextra information wit h the direct answer.
Plan prun-ing determines what parts of this full response do notneed to be stated explicitly - resulting in, in appropri-ate discourse contexts, the generation of an indirectanswer.1.
In t roduct ionJImagine a discourse context for (1) in which R's use iof just (ld) is intended to convey a No, i.e., that Ris not going shopping tonight.
(By convention, squarebrackets indicate that the enclosed text was not ex-plicitly stated.)
The part of R's response consisting of(ld) - (le) is what we 'call an indirect answer to a Yes-No question, and if (lc) had been uttered, (lc) wouldhave been called a direct answer.l.a.
O: I need a ride to the mall.b.
Are you going shopping tonight?c.
R: \[no\]d. My car's not running.e.
The timing belt is broken.According to one study of spoken English \[Ste84\],13 percent of responses to Yes-No questions were in-direct answers.
Thus, the ability to interpret indirectanswers is required for robust dialogue systems.
Fur-thermore, there are good reasons for generating indi-rect answers in a dialogue system.
First, a direct yesor no alone may be misleading if extra information isneeded to qualify the answer.
Second, an indirect an-swer may contribute to a more efficient dialogue.
Forexample, in addition to providing the requested infor-mation, it may anticipate a follow-up question fromQ, or it may allow R to respond immediately with-out asking for clarification of the question.
That is,the increased efficiency is more the result of avoid-ing the follow-up question or clarification subdialoguethan the result of omitting the direct answer.
Third,an indirect answer may be preferable for politenessconsiderations, asin (1).We have developed a computational model for theinterpretation and generation of indirect answers toYes-No questions in English.
More precisely, by a Yes-No question we mean one or more utterances used asa request by Q (the questioner) that R (the respon-der) convey R's evaluation of the truth of a proposi-tion p. An indirect answer implicitly conveys via oneor more utterances R's evaluation of the truth of thequestioned proposition p, i.e.
that p is true, that p isfalse, that there is some truth to p, that p may be true,or that p may be false.
Our model presupposes thatQ's question has been understood by P~ as intendedby Q, that Q's request was appropriate, and that Qand I:t are engaged in a cooperative goal-directed di-alogue.
Both the interpretation and generation com-ponents have been implemented in Common Lisp on aSun SPARCstation.A language user's pragmatic knowledge of how lan-guage is used to answer Yes-No questions in Englishcan be used to constrain the problem of generatingand interpreting indirect answers.
This knowledge isencoded in our model as a set of domain-independentdiscourse plan operators and a set of coherence rules,described in section 2.1 Our system is reversible in thatthe same pragmatic knowledge is used by the genera-tion and interpretation modules.
Generation is mod-eled as discourse plan construction and interpretationas discourse plan inference.
The output of generationis a discourse plan which can be realized by a tacti-cal generation component \[McK85\], and the output ofinterpretation is the speaker's inferred iscourse plan.We found that while the above pragmatic knowledge issufficient for interpretation, it is not sufficient for the1 Our main sources of data were previous tudies \[Hir85,Ste84\], transcripts of naturally occurring two-person-dia-logue lAme92\], and constructed examples.1897th International Generation Workshop * Kennebunkport, Maine ?
June 21-24, 1994problem of content-planning during generation.
Thispaper describes our approach to generation, includingour solution to this problem.Generation of a discourse plan, described in sec-tion 4, is performed in two phases: content planningand plan pruning.
During content planning, stimulusconditions, described in section 3, are used to triggernew speaker goals to include appropriate xtra infor-mation with the direct answer.
Plan pruning deter-mines what parts of this full response do not need tobe stated explicitly.
In appropriate discourse contexts,a plan for an indirect answer is generated.
In othercontexts, i.e.
those in which the direct answer mustbe given explicitly, a plan for a direct answer with ap-propriate extra information is generated.
Note that,according to the study mentioned earlier \[Ste84\], 85percent of direct answers are accompanied by such in-formation.
Thus, it is important o model this typeof response as well.
Section 5 discusses other factorsin generating indirect answers, and section 6 surveysrelated work.2.
P ragmat ic  KnowledgeA language user's knowledge of how to answer a Yes-No question appropriately can be described by a setof discourse plan operators representing full answers.A full answer consists of a direct answer (which wecall the nucleus) and, possibly, extra relevant informa-tion (satellites).
An indirect answer can be modeledas the result of R's providing one or more satelliteswithout expressing the nucleus explicitly.
Due to co-herence constraints holding between ucleus and satel-lite, Q may infer R's discourse plan by inferring whichcoherence relation between an indirect answer and acandidate direct answer is plausible.
The coherencerelations are similar to the subject-matter relations ofRhetorical Structure Theory (RST) \[MT87\].
~The discourse plan operators used to generate andinterpret R's response in (1) are given in Figures 1and 2.
Figure 1 depicts the top-level operator for con-structing a No answer.
To explain our notation, sand h are constants denoting speaker (R) and hearer(Q), respectively.
Symbols prefixed with "?"
denotepropositional variables.
The variable in the headerof Answer-no will be instantiated with the questionedproposition, e.g.
in (1) that R is going shopping.
Ap-plicability conditions are necessary conditions for ap-propriate use of the operator.
For example, for a Noanswer to be appropriate, R must believe that thequestioned proposition p is false.
Also, an answer isnot appropriate unless s and h share the expectation2The terms nucleus and satellite have been borrowedfrom RST.
Note that according to RST, a property of thenucleus is that its removal results in incoherence.
However,in our model, a direct answer may be removed withoutcausing incoherence, provided that it is inferrable from therest of the response.
(Answer-no s h ?p):Applicability conditions:(discourse-expectation (informif s h ?p))(believe s (not ?p))Nucleus:( in form s h (not  ?p))Satellites:(Use-otherwise s h (not ?p))(Use-obstacle s h (not ?p))(Use-contrast s h (not ?p))Primary goals:(BMB h s (not ?p))Figure 1: Discourse plan operator for No answer(Use-obstacle s h ?p):; ;  s tells h of an obstacle explaining;;  the failure ?pExistential variable: ?qStimulus conditions:(explanation-indicated s h ?p ?q)(excuse-indicated s h ?p ?q)Applicability conditions:(believe s (cr-obstacle ?q ?p))(Plausible (cr-obstacle ?q ?p))Nucleus:(inform s h ?q)Satellites:(Use-elaboration s h ?q)(Use-obstacle s h ?q)(Use-cause s h ?q)Primary goals:(BMB h s (cr-obstacle ?q ?p))Figure 2: Discourse plan operator for Obstaclethat s will provide s's evaluation of the truth of p,which is denoted as (discourse-expectation (i formif sh p)).
Primary goals describe the intended effects ofthe operator.
We use (BMB h s p) to denote that h be-lieves it to be mutually believed with s that p \[CM81 \].In general, the nucleus and satellites of a discourseplan operator describe primitive or non-primitive com-municative acts.
Our plan formalism allows zero, one,or more occurrences of a satellite in a full answer.
Theexpected (but not required) order of nucleus and satel-lites is the order they are listed in an operator.
(informs h p) denotes the primitive act of s informing h thatp.
The satellites in Figure 1 refer to non-primitiveacts, described by discourse plan operators which wehave defined (one for each coherence relation used ina full answer).
For example, Use-obstacle, a satelliteof Answer-no, is defined in Figure 2.To explain the additional notation in Figure 2,(cr-obstacle q p) denotes that the coherence relation1907th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994Operator:Answer-yesAnswer-noAnswer-hedgedAnswer-maybeAnswer-maybe-notSatellites:Use-condition~Use-elaborationUse-causeUse-otherwise~se-obstacleUse-contrastUse-contrastUse-resultUse-usuallyUse-possible-causeUse-resultUse-usuallyUse-possible-obstacleTable 1: Satellites of top-level operatorscr-obstacle holds between q and p.S Thus, the first ap-plicability condition can be glossed as requiring that sbelieve that the coherence relation holds.
In the sec-ond applicability condition, (Plausible (cr-obstacle qp)) denotes that_, given what s believes to be mutuallybelieved with h, the coherence relation (cr-obstacle qp) is plausible.
In our model, this sort of condition isevaluated using a set of coherence rules based on therelation definitions of RST.In summary, we provide our system with a set ofdiscourse plan operators representing shared domain-independent knowledge of the informational contentof a full answer.
(Operators whose names begin withAnswer are top-level Operators.)
Table 1 shows thesatellites of each top-level discourse plan operator.
Inaddition, we provide a set of coherence rules definingthe plausibility of the Coherence relations generated bythe satellite discourse plan operators.
43.
Stimulus ConditionsApplicability conditions prevent inappropriate use of adiscourse plan operator.
However, they do not modela speaker's motivation for choosing to provide extrainformation.
A full answer might provide too muchinformation if every satellite whose applicability con-ditions held were included in the full answer.
On theother hand, at the time when he is asked a question, Rmay not have the primary goals of a potential satelliteoperator.
Thus, a goal-driven approach to selectingsatellites would provide insufficient information.
Toovercome these limitations, we have incorporated stim-ulus conditions into the discourse plan operators in our3Although this is not one of the original relations ofRST, it is similar to other causal relations defined in RST.4In addition to RST Subject-matter relations, we haveidentified the following coherence relations in our corpus:cr-obstacle, cr-possible-cause, cr-possible-obstacle, and cr-usually.model.
Playing a key role in content determination,stimulus conditions describe conditions motivating aspeaker to include a satellite during plan construction.They can be thought of as triggers which give rise tonew speaker goals.
In order for a satellite to be in-cluded, all of its applicability conditions and at leastone of its stimulus conditions must be true.
Whilestimulus conditions may be derivative of deeper prin-ciples of cooperativity \[Gri75a\] or politeness \[BL78\],they provide a level of precompiled knowledge whichreduces the amount of reasoning required for contentdetermination.Our methodology for identifying stimulus condi-tions was to survey linguistic studies (described be-low), as well as to analyze the possible motivationof the speaker in the examples in our corpus.
Ac-cording to StenstrSm \[Ste84\], the typical motivationfor providing extra information is to answer an im-plicit wh-question.
Other reasons cited are to providean explanation justifying a negative answer, to qual-ify the answer, or "social reasons".
Levinson \[Lev83\]claims that the presence of an explanation is a struc-tural characteristic of dispreferred responses, such asrefusals and unexpected answers.
Brown and Levin-son \[BL78\] show how various uses of language are mo-tivated by politeness.
For example, use of conversa-tional implicature is one strategy for a speaker to avoiddoing a face-threatening act, s and as we discuss in sec-tion 6, an indirect answer conversationally implicatesthe direct answer.
Hirschberg \[Hir85\] claims that anindirect scalar response, rather than a Yes or No an-swer, is necessary in certain cases to avoid misleadingthe hearer.In the rest of this section, we describe ach of thestimulus conditions used in our system.
For each stim-ulus condition, we give one or more axioms definingsufficient conditions for it.
Axioms are encoded asHorn clauses, where symbols prefixed with "?"
arevariables, all variables are implicitly universally quan-tified, and the antecedent conditions are implicitlyconjoined.
The head, i.e.
the consequent, of an axiomis a stimulus condition appearing in one or more of ourdiscourse plan operators.
Table 2 summarizes whichstimulus conditions appear in which operators.
For ex-ample, the stimulus condition (explanation-indicated sh ?p ?q) occurs in the discourse plan operator shownin Figure 2.
Keep in mind that additional constraintson .
?p and ?q arise from the applicability conditions ofthe operator containing the stimulus condition.3.1 Def in i t ionsExp lanat ion - ind icatedThis stimulus condition appears in all of the oper-SThey claim that another strategy is to give the directanswer last, i.e.
in our terminology, to give the satellite(s)before the nucleus.1917th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994Operator:Use-causeUse-conditionUse-contrastUse-elaborationUse-obstacleUse-otherwiseUse-possible-causeUse-possible-obstacleUse-resultUse-usuallyStimulus conditions:Explanation-indicatedClarify-condition-indicatedAppeasement-indicatedAnswer-ref-indicatedClarify-extent-indicatedSubstitute-indicatedAnswer-ref-indicatedClarify-concept-indicatedExplanation-indicatedExcuse-indicatedExplanation-indicatedExcuse-indicatedExplanation-indicatedExPlanation-indicatedExcuse-indicatedExplanation-indicatedExplanation-indicatedTable 2: Stimulus conditions of discourse plan opera-torsators for providing causal explanations.
For examplein (2), 6 which indirectly conveys a No, R gives an ex-planation of why R won't get a car.2.a.
q: actually you'll probably get a carwon't you as soon as you get thereb.
R: can't driveNote that this stimulus condition may contribute togreater dialogue efficiency by anticipating a follow-uprequest for an explanation.
Formally, the condition isdefined by the following axiom.
((explanation-indicated s h ?p ?q)<-(wbel s (wbel h (not ?p)))(unless (wbel s (accepts-authority h s))))This may be glossed as, s is motivated to give h anexplanation q for p, if s suspects that h suspects thatp is not true, unless it is the case that s has reasonto believe that h will accept p on s's authority.
(wbelagent p), which we usually gloss as agent suspects thatp, denotes that agent has some confidence in the beliefthat p. Note tha, t R may acquire the suspicion that Qdoubts that p is true by means of syntactic lues fromthe Yes-No question, e.g.
the form of the question in(2@Excuse- ind icatedAlthough this stimulus condition appears in someof the same causal operators as Explanation-indicated,~Stenstr6m's (110)it represents a different kind of motivation.
A Yes-Noquestion may be interpreted as a prerequest \[Lev83\]for a request, i.e.
as an utterance used as a preface toanother equest.
7 Prerequests are often used to checkwhether a related request is likely to succeed, or toavoid having to make the other request directly.
Thus,a negative answer to a Yes-No question used as a pre-request may be interpreted as a refusal.
To soften therefusal, the speaker may give an explanation of thenegative answer, as illustrated in (1).
Formally, thecondition is defined by the following axiom.
((excuse-indicated s h (not ?p) ?q)<-(~bel s (prerequest h s (informif s h ?p))))This may be glossed as, s is motivated to give h anexcuse q for (not p), if s suspects that h's request,(informif s h p), is a prerequest.
Techniques for inter-preting indirect speech acts \[PA80, Hin89\] can be usedto determine whether the antecedent holds.Answer - re f - ind icatedThis condition appears in Use-Elaboration, illus-trated by (3), s and in Use-Contrast, illustrated by(4) .93 .a .
Q:b.c.
E:d.Did you have a hotel in mind?\[What hotel did you have in mind?\]\[yes\]There's a Holiday Inn right nearwhere I'm working.4.a.
Q: You're on that?b.
\[Who's on that?\]c. R: no no nod.
Dave is.In (3), R has interpreted the question in (a) as a pre-request for the wh-question shown in (b).
Thus, (d)not only answers the question in (a) but also the an-ticipated wh-question in (b).
Similarly in (4), R mayinterpret the question in (a) as a prerequest for thewh-question in (b), and so gives (d) to provide an an-swer to both (a) and (b).
Formally, the condition isdefined by the following axiom.
((Answer-re:f-indicated s h ?p ?q)<-(wbel s (want h (knowref h ?t ?q)))This may be glossed as, s is motivated to provide hwith q, if s suspects that h wants to know the referentTin analyses of discourse based on speech act theory,e.g.
\[PA80\], a question such as (lb) might be described asan indirect request.
However, since it may be respondedto appropriately by a Yes or No, it is included in the classof Yes-No questions addressed in our model.SAmerican Express tape 19StenstrSm's (102).
Note that a No answer may beconversationally implicated by use of (4d) alone.1927th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994of a term t in q.
As in Excuse-indicated, techniquesfor interpreting indirect speech acts can be used todetermine if the antecedent holds.Subst i tu te - ind icatedThis condition appears in Use-contrast, illustratedby (5).S.a.Q: Do you have Verdi's Otello or Aida?b.R: \[no\]c.  We have R igo le t to .Although Q may not have intended to use (5a) as aprerequest for the qu#stion What Verdi operas do youhave.C, R suspects that the answer to this wh-questionmight be helpful to Q.
Formally, the condition is de-fined by the following axiom.
((Substitute-indicated s h ?p ?q)<-(wbel s (need h (knowref h ?t ?q))))This may be glossed as, s is motivated to provide hwith q, if s suspects that it would be helpful for h toknow the referent of a term t in q.
The antecedentwould hold wl~enever obstacle detection techniques\[AP80\] determine that h's not knowing the referentof t is an obstacle to an inferred plan of h's.
How-ever, note that not all helpful responses, in the sensedescribed in lAPS0\], can be used as indirect answers.For example, even if the clerk (R) at the music storebelieves that Q's not knowing the closing time couldbe an obstacle to Q's buying a recording, tl/e response(6), given instead of (5c), would not convey (55) sinceit cannot be coherently related to (55).6.
R: We close at 5:30 tonight.Clar i fy -concept - ind icatedThis stimulus condition appearsUse-elaboration, as illustrated by (7)3 0in7.
Q: Do you have a pet?R: We have a turtle.In (7), R was motivated to elaborate on the type ofpet they have, since turtles are not prototypical pets.Formally, the condition is defined by the following ax-iom.
((Clarify-concept-indicated s h ?p ?q)<-(concept ?p ?c)(has-atypical-insgance ?q ?c))This may be glossed as, s is motivated to clarify pto h with q, if p has a concept c, and q provides anatypical instance of c. Stereotypical knowledge is usedto evaluate the second antecedent.1?
Hirschberg's (177).C la r i fy -cond i t ion - ind icatedThis stimulus condition appears in the operatorUse-condition, as illustrated by (8).
118.a.
Q: Um let me can I make the reservationand change it by tomorrowb.
R: \[yes\]c. if it's still available.In (8), a truthful Yes answer depends on the truth of(c).
Formally, the stimulus condition is defined by thefollowing axioms.
((Clarify-condition-indicated s h ?p ?q)<-(ignorant s ?q))((Clarify-condition-indicated s h ?p ?q)<-(wbel s (not ?q)))These may be glossed as, s is motivated to clarify acondition q for p to h 1) if s doesn't know if q holds,or 2) if s suspects that q does not hold.C la r i fy -extent - ind icatedThis stimulus condition appears in Use-contrast,as illustrated by (9).
129.a.
Q: Have you gotten the letters yet?b.
R: I've gotten the letter from X.On the strict interpretation of (9a), Q is askingwhether R has gotten allof the letters, but on a looserinterpretation, Q is asking if R has gotten any of theletters.
Then, if R has gotten some but not all ofthe letters, a Yes would be untruthful.
However, ifQ is speaking loosely, then a No might lead Q to er-roneously conclude that R has not gotten any of theletters.
R's answer circumvents this problem, by con-veying the extent to which the questioned proposition(on the strict interpretation) is true.
Formally, thecondition is defined by the following axioms.
((clarify-extent-indicated s h(some-truth ?p) ?q)<-(wbel s (ignorant h ?q))(believe s (highest-true-exp ?q ?p)))((clarify-extent-indicated s h (not ?p) ?q)<-(wbel s (ignorant h ?q))(believe s (highest-true-exp ?q ?p)))These may be glossed as, s is motivated to clarify to hthe extent q to which p is true, or the alternative q top which is true, if s suspects that h does not know if qn American Express tape 10aba2 Hirschberg's (59)1937th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994holds, and s believes that q is the highest expression al-ternative to p that does hold.
According to I-Iirschberg\[Hir85\] (following Gazdar), sentences Pi and pj (rep-resenting the propositional content of two utterances)are expression alternatives if they are the same exceptfor having comparable components ei and e j, respec-tively.
Further, Hirschberg claims that in a particulardiscourse context, there may be a partial ordering ofvalues which the discourse participants mutually be-lieve to be salient, and that the ranking of ei and ejin this ordering can be used to describe the ranking ofpi and pj.
In the above example, (9b) is a realizationof the highest rue expression alternative to the ques-tioned proposition, p, i.e.
the proposition that R hasgotten all the letters, isAppeasement - ind icatedThis stimulus condition appears in Use-contrast,as illustrated by (10).
1410.a.
Q: Did you manage to read that sectionI gave you?b.
R: I've read the first couple of pages.In (10), R conveys that there is some (though notmuch) truth to the questioned proposition in an effortto soften his answer.
Note that more than one stim-ulus condition may motivate R to include the samesatellite.
E.g., in (10), R may have been motivatedalso by clarify-eztent-indicated, which was describedabove.
However, it is possible to provide a context for(9) where appeasement-indicated holds but not clarify-extent-indicated, or a context where the converse istrue.
Formally, the condition is defined by the follow-ing axiom.
((appeasement-indicated s h (not ?p) ?q)<-(wbel s (undesirable h (not ?p)))(wbel s (desirable h ?q)))((appeasement-indicated s h(some-truth ?p) ?q)<-(wbel s (undesirable h (not ?p)))(wbel s (desirable h ?q)))This may be glossed as, s is motivated to appease hwith q for p not holding or only being partly true, if ssuspects that (not p) is undesirable to h but that q isdesirable to h. The antecedents o this rule would beevaluated using heuristic rules and stereotypical ndspecific knowledge about h's desires.
For example, two13Recall that additional constraints on p and q arise fromthe applicability conditions of operators containing thisstimulus condition, namely Use-contrastin this case.
Thus,another constraint is that it is plausible that cr-contrastholds.
Note that cr-contrast also is defined in terms ofsuch an ordering.a4 Hirchberg's (56)heuristics of rational agency that might lead to beliefsabout h's desires are 1) if an agent wants you to per-form an action A, then your failure to perform A maybe undesirable to the agent, and 2) if an agent wantsyou to do A, then it is desirable to the agent hat youperform a part of A.4.
Generation AlgorithmThe inputs to generation in our model consist of 1) aset of discourse plan operators augmented with stim-ulus conditions, 2) a set of coherence rules, 3) R'sbeliefs, and 4) the discourse xpectation that R willprovide R's evaluation of the truth of the questionedproposition p. The output of the generation algorithmis a discourse plan which can be realized by a tacticalgeneration component \[McK85\].
We assume that whenanswer generation begins, the speaker's only goal is tosatisfy the above discourse xpectation35Our answer generation algorithm has two phases.In the first phase, content planning, the generator cre-ates a discourse plan for a full answer, i.e., a directanswer and extra appropriate information, e.g.
(lc)given explicitly, followed by (ld) : (le).
In the secondphase, plan pruning, the generator determines whichpropositions of the planned full answer do not need tobe explicitly stated.
For example, given an appropri-ate model of R's beliefs, our system generates a planfor asserting only the proposition conveyed in (le) asan answer to (la) - (lb)36 Note that an advantage ofour approach is that, even when it is not possible toomit the direct answer, a full answer is generated.4.1 Content planningContent planning is performed by top-down expansionof an answer discourse plan operator.
The process be-gins by instantiating each of the operators with thequestioned proposition until one is found such that itsapplicability conditions hold.
Next, this (top-level)answer operator is expanded.
A discourse plan op-erator is expanded by deciding which of its satellitesto include in the full answer and expanding each ofthem (recursively).
A satellite (e.g.
Use-obstacle inFigure 2) is selected if, for some instantiation of itsexistential variable, all of the applicability conditionsand at least one of the stimulus conditions of the in-stantiated operator hold.Note that testing of applicability conditions andstimulus conditions (including searching for an appro-aSThe plan that is output by our algorithm specifies anordering of discourse acts based upon the ordering of co-herence relations pecified in the discourse plan operators.However, to model a speaker who has more than the aboveinitial goal, reordering may be required.16The tactical component must choose an appropriatereferring expression to refer to R's car's timing belt, de-pending on whether (ld) is omitted.1947th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994priate instantiation of the existential variable) is han-dled by a theorem prover.
Our model of R's beliefs,represented asa set of Horn clauses, includes 1) generalworld knowledge presumably shared with Q, 2) knowl-edge about the preceding discourse, and 3) R's beliefs(including "weaker be~liefs" encoded using the wbel op-erator) about Q's beliefs.
Much of the shared worldknowledge needed to evaluate our coherence rules con-sists of knowledge from domain plan operators.4.2 P lan  prun ingThe output of the ~ontent planning phase, an ex-panded iscourse plan representing a full answer, is theinput to the plan pruning phase of generation.
The ex-panded plan is represented as a tree of discourse acts.The goal of this phase is to make the response moreconcise, 17 i.e., to determine which of the planned actscan be omitted while lstill allowing Q to infer the fulldiscourse plan.
To do this, the generator considerseach of the acts in the frontier of the tree from rightto left.
(This ensures that a satellite is considered be-fore its related nucleus.)
The generator creates a trialplan consisting of the original plan minus the nodespruned so far and minus the current node.
Then, us-ing the interpretation imodule, the generator simulatesQ's interpretation of a response containing the infor-mation that would be given explicitly according to thetrial plan.
If Q couldlinfer the full plan (as the mostpreferred interpretation), then the current node can bepruned.
Otherwise, itlis left in the plan and the nextnode is considered.For example, consider Figure 3 as we illustrate thepossible ffect of pruni;ng on a full discourse plan.
Theleaf nodes, representing discourse acts, are numbered 1- 8.
Arcs labelled N and S lead to a nucleus or satellite,respectively.
Node 8 corresponds to the direct answer.Plan pruning would process the nodes in order from 1to 8.
The maximal set :of nodes which could be prunedin Figure 3 is the set containing 2, 3, 4, 7, and 8.
Thatis, nodes 2 - 4 might be inferrable from 1, node 7 from5 or 6, and node 8 from 4 or 7.
In the event hat it isdetermined that no node can be pruned, the full planwould be output.
Not:e that our interpretation algo-rithm (described in \[GC94\]) performs asubprocess, hy-pothesis generation, to recognize missing propositionsother than the direct answer, i.e.
the propositions atnodes 2, 3, 4, and 7.4.3 ExampleThis section gives an ~example of how the discourseplan shown in Figure 4 would be generated, corre-sponding to the answer shown in (11), where only(l ld) is explicitly stated.lrConciseness is not the only possible motive for omittingthe direct answer.
As mentioned in section 3, an indirectanswer may be used to avoid performing a face-threateningact.7 6 5 4 - -32 1Figure 3: Example of full discourse plan before prun-ing11.a.
Q: You went to the party, didn't you7b.
R: \[no\]c. \[The baby sitter could not sit.\]d. The baby sitter was sick.In phase one, the generator creates a discourse plan fora full answer.
First, it must decide which top-level dis-course plan operator to expand.
Each of the top-leveloperators would be instantiated with the questionedproposition, (occur (go-party s) past).
The top-leveloperators would be instantiated and tested until onewas found whose applicability conditions held, namely,Answer-no.
Next, the generator must decide which ofthe satellites of Answer-no to include.
So, it wouldsearch for all propositions q such that, when the exis-tential variable ?q of a satellite is instantiated with q,then all of the satellite's applicability conditions andat least one of its stimulus conditions hold.
In thisexample, the proposition (not (in-state (can-sit sitter)past)) would be found to satisfy the applicability con-ditions and the explanation-indicated stimulus condi-tion of Use.obstacle.
(Note that this proposition mightbe chosen because the model of R's beliefs includes adomain plan operator for going to a party, with a pre-condition that the agent's itter can baby sit.
)Next, this instantiation of Use-obstacle must beexpanded, i.e., the generator must decide which of thesatellites of Use-obstacle to include.
By a proceduresimilar to that described above, it would decide toinclude (another) Use-obstacle, where the existentialvariable is instantiated with the proposition (in-state(sick sitter) past).
(Note that this proposition mightbe chosen because the model of R,'s beliefs includes theshared belief that being sick typically renders a sitterunfit to perform his or her duties.)
The stimulus con-dition explanation-indicated might be the motivationfor including this satellite.
(For example, suppose itis shared knowledge that R's baby sitter is rarely un-available.)
If further attempts to expand the plan wereunsuccessful, then the full plan would contain the dis-course acts shown in Figure 4.
(The acts in the planare labelled (b) - (d) corresponding to the part of (11)they represent.)
Note that if this plan were output1957th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994(Answer-no s h (occur (go-party s) pas t ) ) :Nucleus:b.
(inform s h (not (occur (go-party s)past)))Satellites:(Use-obstacle s h(not (occur (go-party s) past)))Nucleus:(inform s h(not (in-state (can-sit sitter)past ) ) )Sate l l i tes :(Use-obstacle s h(not ( in -s ta te  (can-s i t  s i t te r )pas t ) ) )Nucleus:(inform s h (in-state (sick sitter)past))C.d.Figure 4: Discourse plan for (11)without undergoing plan-pruning, it would be realizedas a direct answer (l lb), and extra information (l lc)-(lld).In phase two, plan-pruning, the generator's over-all goal is to make the answer as concise as possible.Therefore, it would consider the primitive acts speci-fied in the full plan in the order (d), (c), (b).
Since(d) is not inferrable from any other act, it would beautomatically retained in the plan.
Next, a trial planwith (c) pruned from it would be considered.
Interpre-tation of the response consisting of (b) and (d) is sim-ulated.
Since the full plan could be inferred, (c) wouldbe pruned.
Next, another trial plan would be consid-ered, where, in addition to (c), (b) has been pruned.Since the full plan could be inferred from the result-ing trial response consisting of just (d), (b) would bepruned too.
Thus, the output of phase two would bethe plan shown in Figure 4 with (b) and (c) markedas pruned.5.
Other  fac tors  in  generat ionThe primary focus of our research as been on 1) useof pragmatic knowledge which is common to both theinterpretation and generation of indirect answers, i.e.the so-called reversible knowledge, and 2) identifyingstimulus conditions.
In this section, we give a briefdescription of some other factors in generating indirectanswers.First, note that we made the simplifying assump-tion that R's only initial goal is to answer the ques-tion (accurately, efficiently, and politely).
However, itis possible for R to construct an indirect answer whichsatisfies multiple initial goals of R. For example, Rmight have decided to give the answer in (12c) notonly as an explanation, but also as background for R'srequest in (12d).12.a.
q: Are you going to the lecture?b.
R: \[no\]c. I have to get my brakes fixed.d.
Can you recommend a garage nearc ampus ?Second, stylistic goals may affect the generationof indirect answers.
In addition to affecting syntacticand lexical aspects of discourse \[Hovg0, MG91, DH93\],stylistic goals may affect which and how much infor-mation is given.
For example, elaboration can be usedto make an answer more lively, as shown in (13).13,a.
Q: Do you have a car?b.
R: \[yes\]c. I bought a British-racing-greenAustin-Healey 3000 last week.Also, extra information that entails the direct answer(e.g.
repetitions and generalizations) may be given foremphasis.
Further, a stylistic goal of terseness mayoverride the stimulus conditions we have provided forindirect answers.
For example, depending upon thedegree of Q's interest in R's affairs, the indirect answerin (14c) - (14f) may provide Q with more than Q caresto know.14.a.
Q: Are you going to the movies tonight?b.
R: \[no\]c. I can't afford to.d.
I spent $900 on my car last week.e.
It needed a new transmission.f.
The car is 15 years old.Third, certain syntactic forms for expressing Yes-No questions require more than just yes~no t  makeclear whether R is confirming or disconfirming that aproposition p holds \[Ste84\].
For example, is (15) showsthe use of amplification (i.e.
supplying an auxiliaryverb) in answer to a negative-polarity, positive-biasquestion.I5.a.
Q: Didn't Ann get the letter?b.
R: Yes she did.c.
R: No she didn't.
(A question is said to have positive or negative polaritydepending on the presence or absence of negation, re-spectively.
Bias describes the questioner's presumedbelief in the truth of the questioned proposition.
)In answer to (16a), a negative-polarity, negative-biasquestion, 19 R provides an indirect answer, giving theextent to which the proposition that R has been up-18(15) and (16) are Stenstrbm's (105) and (111),respectively.19Although it is expressed as a declarative sentence,Stenstr6m classifies (16a) as a request for confirmation,which we treat as a type of Yes-No question.1967th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994stairs is true, in order to avoid the same type of con-fusion.16.a.
Q: I don't think you've been upstairsyet.b.
R: Um only just to the ioo.6.
Re la ted  researchOur work differs from most previous work in cooper-ative response generation in that, in our model, theinformation given in an indirect answer conversation-ally implicates \[Gri75a\] the direct answer.
I-Iirschberg\[Hir85\], who provided general rules for identifyingwhen a scalar conversational implicature is licensed,claimed that speakers may give indirect responses toYes-No questions in order to block potential incor-rect scalar implicatures of a simple Yes or No.
Sheimplemented a system which determines whether theYes/No 2?
licenses any unwanted scalar implicatures,and if so, proposes alternative scalar responses whichdo not.
This type of response is similar, in our model,to a speaker's use of Use-contrast motivated by clarify-extent-indicated, as illustrated in (9).
(As noted ear-lier, our coherence rules for the relation cr-contrastas well as our axioms for clarify-extent-indicated makeuse of the notion of a salient partial ordering whichwas elucidated by Hirsehberg.)
However, Hirschberg'smodel does not account for quite a variety of typesof indirect answers which can be generated using theother operators in our model, nor for other motives forusing Use-contrast.Rhetorical or coherence relations \[Gri75b, Hal76,MT87\] have been used in several text-generation sys-tems to aid in ordering parts of a text (e.g.\[Hov88\])as well as in content-planning (e.g.
\[McK85, MP93\]).The discourse plan operators based on coherence rela-tions in our model (i.e.
the operators used as satellitesof top-level operators)play a similar role in content-planning of an indirect answer.
When coherence re-lations are used for content-planning, it is necessaryto constrain the information which thereby may beselected.
McKeown \[McK85\] uses discourse focus con-straints.
In \[Moo89\], plan selection heuristics are usedthat maximize the heater's presumed familiarity withthe concepts in the text, prefer general-purpose to lessgeneral operators, and minimize verbosity.
Maybury's\[May92\] system uses "desirable" preconditions, pre-conditions that are not inecessary preconditions, topri-oritize alternative operators.
In contrast o the above,by the use of stimulus conditions, our model is able totrigger new, opportunistic speaker goals.Moore and Pollack \[MP92\] show the need to dis-tinguish the intentional and informational structureof discourse, where the latter is characterized by the2?Hirschberg did not addresss other possible types of di-rect answers, represented by the Answer-Hedged, Answer-Maybe, and Answer-Maybe-Not perators in our model.sort of relations classified as subject-matter relationsin RST.
Note that in our interpretation component\[GC94\], informational relations (i.e.
plausible co-herence relations holding between indirect answersand candidate direct answers) are used to infer thespeaker's goal to convey a particular answer.
Mooreand Paris \[MP93\] argue that it is necessary for gen-eration systems to represent not only the speaker'stop-level intentional goal, but also the intentional sub-goals that a speaker hoped to achieve by use of arhetorical relation so that, if a subgoal is not achieved,then an alternative rhetorical means can be tried.
Inour model, the operators used as satellites of top-levelanswer discourse plan operators are based on RST'ssubject-matter relations.
The primary goals of theseoperators are similar to the effect fields of the cor-responding RST relation definitions.
As Moore andParis argue, goals based on these relation definitionsare rhetorical goals, not intentional goals.
However,in our model, it is possible to determine the inten-tional subgoals by checking which stimulus conditionsmotivated the speaker to include a particular satelliteoperator.
For example, if explanation-indicated moti-vates R to include a Use-cause satellite, then one canview R as having the implicit intentional goal of givingan explanation.
Thus, our model provides the infor-mation necessary to recover from the possible failureof (all or part of) an indirect answer.Finally, our use of simulated interpretation duringplan pruning has some similarity to previous work.
InHoracek's approach to generating concise xplanations\[I-Ior91\], a set of propositions representing the full ex-planation i s pruned by eliminating propositions whichcan be derived from the remaining ones by contextualrules.
Jameson and Wahlster \[JW82\] use an antici-pation feedback loop algorithm to generate llipticalutterances.7.
ConclusionAn indirect answer to a Yes-No question conversation-ally implicates the speaker's evaluation of the truthof a questioned proposition.
The generation of indi-rect answers is important if a dialogue system is to re-spond efficiently, accurately, and politely.
This paperhas presented the approach to generation used in ourimplemented system for generating and interpretingindirect answers to Yes-No questions in English.
Oursis the first system to generate a wide range of types ofindirect answers (as well as full answers).
The systemis reversible in that the same pragmatic knowledge isused in generation and interpretation.
Generation isperformed in two phases: content planning and planpruning.
During content planning, stimulus conditionsare used to trigger speaker goals to include appropriateextra information with the direct answer.
Plan prun-ing determines what parts of this full response do notneed to be stated explicitly - resulting in, in appropri-ate discourse contexts, the generation of an indirect1977th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994answer.Re ferences\[AP80\] James F. Allen and C. Raymond Perrault.
An-alyzing intention in utterances.
Artificial In-telligence, 15:143-178, 1980.\[Ame92\] American Express tapes.
Transcripts of au-diotape conversations made at SRI Interna-tional, Menlo Park, California.
Prepared byJacqueline Kowto under the direction of PattiPrice.\[BL78\] Penelope Brown and Stephen Levinson.
Uni-versals in language usage: Politeness phe-nomena.
In Esther N. Goody, editor, Ques-tions and politeness: Strategies in social in-teraction, pages 56-289.
Cambridge UniversityPress, Cambridge, 1978.\[CM81\] H. Clark and C. Marshall.
Definite refer-ence and mutual knowledge.
In A. K. Joshi,B.
Webber, and I.
Sag, editors, Elements ofdiscourse understanding.
Cambridge Univer-sity Press, Cambridge, 1981.Chrysanne DiMarco and Graeme Hirst.
Acomputational theory of goal-directed stylein syntax.
Computational Linguistics, 19(3),1993.Nancy Green and Sandra Carberry.
A hybridreasoning model for indirect answers.
To ap-pear in Proceedings of the 32nd Annual Meet-ing of the Association for Computational Lin-guistics, 1994.\[Gri75a\] H. Paul Grice.
Logic and conversation.
InP.
Cole and J. L. Morgan, editors, Syntax andSemantics lII: Speech Acts, pages 41-58, NewYork, 1975.
Academic Press.\[Gri75b\] J. E. Grimes.
The Thread of Discourse.
Mou-ton, The Hague, 1975.\[Hal76\] M. Halliday.
Cohesion in English.
Longman,London, 1976.\[Hin89\] Elizabeth Ann Hinkelman.
Linguistic andPragmatic Constraints on Utterance Interpre-tation.
PhD thesis, University of Rochester,1989.\[Hir85\] Julia Bell Hirschberg.
A Theory of Scalar Im-plicature.
PhD thesis, University of Pennsyl-vania, 1985.\[Hor91\] Helmut Horacek.
Exploiting conversationalimplicature for generating concise explana-tions.
In Proceedings.
European Associationfor Computational Linguistics, 1991.\[Hov88\] Eduard H. Hovy.
Planning coherent multisen-tential text.
In Proceedings of the 26th AnnualMeeting of the Association for ComputationalLinguistics, pages 163-169, 1988.\[DH93\]\[GC94\]\[Hov90\] Eduard H. Hovy.
Pragmatics and naturallanguage generation.
Artificial Intelligence,43:153-197, 1990.\[JW82\] Anthony Jameson and Wolfgang Wahlster.User modelling in anaphora generation: ellip-sis and definite description.
In Proceedings ofthe European Conference on Artificial Intelli-gence, 1982.\[Lev83\] S. Levinson.
Pragmatics.
Cambridge Univer-sity Press, Cambridge, 1983.\[May92\] Mark T Maybury.
Communicative acts forexplanation generation.
International Journalof Man-Machine Studies, 37:135-172, 1992.\[MeK85\] Kathleen R. McKeown.
Text Generation.Cambridge University Press, 1985.r\[MG91\] Marzena Makuta-Giluk.
A computationalrhetoric for syntactic aspects of text.
TechnicalReport CS-91-56, Master's thesis, Departmentof Computer Science, University of Waterloo,Waterloo, Ontario, Canada, December 1991.\[Moo89\] Johanna D. Moore.
A Reactive Approach toExplanation in Expert and Advice-Giving Sys-tems.
PhD thesis, University of California atLos Angeles, 1989.\[MP92\] Johanna D. Moore and Martha E. Pollack.A problem for rst: The need for multi-leveldiscourse analysis.
Computational Linguistics,18(4):537-544, December 1992.\[MP93\] Johanna D. Moore and Cecile Paris.
Plan-ning text for advisory dialogues: Capturing in-tentional and rhetorical information.
Compu-tational Linguistics, 19(4):651-694, December1993.\[MT87\] W. C. Mann and S. A. Thompson.
Rhetoricalstructure theory: Toward a functional theoryof text organization.
Text, 8(3):167-182, 1987.\[PA80\] R. Perrault and J. Allen.
A plan-based analy-sis of indirect speech acts.
American Journalof Computational Linguistics, 6(3-4):167-182,1980.\[Ste84\] Anna-Brita StenstrSm.
Questions and re-sponses in english conversation.
In ClaesSchaar and Jan Svartvik, editors, Lund Studiesin English 68.
CWK Gleerup, MaimS, Sweden,1984.198
