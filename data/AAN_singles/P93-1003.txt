AN ALGORITHM FOR F INDINGNOUN PHRASE CORRESPONDENCESIN  B IL INGUAL CORPORAJ u l ian  Kup iecXerox Palo Alto Research Center3333 Coyote Hill Road, Palo Alto, CAkupiec@parc.xerox.com94304Abst rac tThe paper describes an algorithm that employsEnglish and French text taggers to associate nounphrases in an aligned bilingual corpus.
The tag-gets provide part-of-speech categories which areused by finite-state recognizers to extract simplenoun phrases for both languages.
Noun phrasesare then mapped to each other using an iterativere-estimation algorithm that bears similarities tothe Baum-Welch algorithm which is used for train-ing the taggers.
The algorithm provides an alter-native to other approaches for finding word cor-respondences, with the advantage that linguisticstructure is incorporated.
Improvements o thebasic algorithm are described, which enable con-text to be accounted for when constructing thenoun phrase mappings.INTRODUCTIONAreas of investigation using bilingual corpora haveincluded the following:?
Automatic sentence alignment \[Kay andRSscheisen, 1988, Brown eL al., 1991a, Galeand Church, 1991b\].?
Word-sense disambiguation \[Dagan el al.,1991, Brown et ai., 1991b, Church and Gale,1991\].?
Extracting word correspondences \[Gale andChurch, 1991a\].?
Finding bilingual collocations \[Smadja, 1992\].?
Estimating parameters for statistically-basedmachine translation \[Brown et al, 1992\].The work described here makes use of thealigned Canadian Hansards \[Gale and Church,1991b\] to obtain noun phrase correspondences be-tween the English and French text.The term "correspondence" is used here to sig-nify a mapping between words in two aligned sen-tences.
Consider an English sentence Ei and aFrench sentence Fi which are assumed to be ap-proximate translations of each other.
The sub-script i denotes the i'th alignment of sentences inboth languages.
A word sequence in E/ is definedhere as the correspondence of another sequence inFi if the words of one sequence are considered torepresent the words in the other.Single word correspondences have been investi-gated \[Gale and Church, 1991a\] using a statisticoperating on contingency tables.
An algorithm forproducing collocational correspondences has alsobeen described \[Smadja, 1992\].
The algorithm in-volves several steps.
English collocations are firstextracted from the English side of the corpus.
In-stances of the English collocation are found andthe mutual information is calculated between theinstances and various single word candidates inaligned French sentences.
The highest rankingcandidates are then extended by another word andthe procedure is repeated until a correspondingFrench collocation having the highest mutual in-formation is found.An alternative approach is described here,which employs imple iterative re-estimation.
Itis used to make correspondences between simplenoun phrases that have been isolated in corre-sponding sentences of each language using finite-state recognizers.
The algorithm is applicable forfinding single or multiple word correspondencesand can accommodate additional kinds of phrases.In contrast to the other methods that have beenmentioned, the algorithm can be extended in astraightforward way to enable correct correspon-dences to be made in circumstances where numer-ous low frequency phrases are involved.
This isimportant consideration because in large text cor-pora roughly a third of the word types only occuronce.Several applications for bilingual correspon-dence information have been suggested.
They canbe used in bilingual concordances, for automat-ically constructing bilingual exicons, and proba-bilistically quantified correspondences may be use-ful for statistical translation methods.COMPONENTSFigure 1 illustrates how the corpus is analyzed.The words in sentences are first tagged with their17corresponding part-of-speech categories.
Eachtagger contains a hidden Markov model (HMM),which is trained using samples of raw text fromthe Hansards for each language.
The taggers arerobust and operate with a low error rate \[Ku-piec, 1992\].
Simple noun phrases (excluding pro-nouns and digits) are then extracted from the sen-tences by finite-state recognizers that are specifiedby regular expressions defined in terms of part-of-speech categories.
Simple noun phrases are iden-tified because they are most reliably recognized;it is also assumed that they can be identified un-ambiguously.
The only embedding that is allowedis by prepositional phrases involving "of" in En-glish and "de" in French, as noun phrases involv-ing them can be identified with relatively low error(revisions to this restriction are considered later).Noun phrases are placed in an index to associatea unique identifier with each one.A noun phrase is defined by its word sequence,excluding any leading determiners.
Singular andplural forms of common nouns are thus distinctand assigned ifferent positions in the index.
Foreach sentence corresponding to an alignment, heindex positions of all noun phrases in the sentenceare recorded in a separate data structure, provid-ing a compact representation f the corpus.So far it has been assumed (for the sake of sim-plicity) that there is always a one-to-one mappingbetween English and French sentences.
In prac-tice, if an alignment program produces blocks ofseveral sentences in one or both languages, thiscan be accommodated by treating the block in-stead as a single bigger "compound sentence" inwhich noun phrases have a higher number of pos-sible correspondences.THE MAPP ING ALGORITHMSome terminology is necessary to describe the al-gorithm concisely.
Let there be L total alignmentsin the corpus; then Ei is the English sentence foralignment i.
Let the function ?
(Ei) be the num-ber of noun phrases identified in the sentence.
Ifthere are k of them, k = ?
(Ei), and they canbe referenced by j = 1...k. Considering the j ' thnoun phrase in sentence Ei, the function I~(Ei, j)produces an identifier for the phrase, which is theposition of the phrase in the English index.
If thisphrase is at position s, then I~(Ei,j) = s.In turn, the French sentence Fi will contain?
(Fi) noun phrases and given the p'th one, its po-sition in the French index will be given by/~(Fi, p).It will also be assumed that there are a total ofVE and Vr phrases in the English and French in-dexes respectively.
Finally, the indicator functionI 0 has the value unity if its argument is true, andzero otherwise.Assuming these definitions, the algorithm isI English sentence E i1I English Tagger II English NP Recognizer II  n0.sh'o ex II Bilingual Corpus I rth alignmentI French FTntence IFrench Tagger II French I NP RecognizerI Frenchlndex IFigure 1: Component Layoutstated in Figure 2.
The equations assume a direc-tionality: finding French "target" correspondencesfor English "source" phrases.
The algorithm is re-versible, by swapping E with F.The model for correspondence is that a sourcenoun phrase in Ei is responsible for producing thevarious different arget noun phrases in Fi withcorrespondingly different probabilities.
Two quan-tities are calculated; Cr(s, t) and Pr(s, t).
Compu-tation proceeds by evaluating Equation (1), Equa-tion (2) and then iteratively applying Equations(3) and (2); r increasing with each successive iter-ation.
The argument s refers to the English nounphrase nps(s) having position s in the Englishindex, and the argument  refers to the Frenchnoun phrase npF(t) at position t in the Frenchindex.
Equation (1) assumes that each Englishnoun phrase in Ei is initially equally likely to cor-respond to each French noun phrase in Fi.
All cor-respondences are thus equally weighted, reflectinga state of ignorance.
Weights are summed overthe corpus, so noun phrases that co-occur in sev-eral sentences will have larger sums.
The weightsC0(s, t) can be interpreted as the mean number oftimes that npF(t) corresponds to  apE(s) given thecorpus and the initial assumption of equiprobablecorrespondences.These weights can be used to form a new esti-mate of the probability that npF(t) corresponds tonpE(s), by considering the mean number of timesnpF(t) corresponds to apE(s) as a fraction of thetotal mean number of correspondences forapE(s),as in Equation (2).
The procedure is then iter-ated using Equations (3), and (2) to obtain suc-cessively refined, convergent estimates of the prob-18Co( ,t) ==cr( ,t) =r>OVE>s>IVv>t>lL ?
(E~) ?
(F0 1E E E I(tt(Ei' J) = s)l(tt(Fi' k) = t) ?
(F,)i=1 j= l  k=lCr-l(S,t)vF Eq=l Cr-l(s, q)L ?
(E0 ?
(F0E E E I(#(Ei,j) = s)I(tt(Fi,k) = t)Pr_l(s,t)i= I  j= l  k= l(1)(2)(3)Figure 2: The Algorithmability that ripE(t) corresponds to ripE(s).
Theprobability of correspondences can be used as amethod of ranking them (occurrence counts canbe taken into account as an indication of the re-liability of a correspondence).
Although Figure 2defines the coefficients simply, the algorithm is notimplemented literally from it.
The algorithm em-ploys a compact representation of the correspon-dences for efficient operation.
An arbitrarily largecorpus can be accommodated bysegmenting it ap-propriately.The algorithm described here is an instance ofa general approach to statistical estimation, rep-resented by the EM algorithm \[Dempster et al,1977\].
In contrast o reservations that have beenexpressed \[Gale and Church, 1991a\] about us-ing the EM algorithm to provide word correspon-dences, there have been no indications that pro-hibitive amounts of memory might be required, orthat the approach lacks robustness.
Unlike theother methods that have been mentioned, the ap-proach has the capability to accommodate morecontext o improve performance.RESULTSA sample of the aligned corpus comprising 2,600alignments was used for testing the algorithm (notall of the alignments contained sentences).
4,900distinct English noun phrases and 5,100 distinctFrench noun phrases were extracted from the sam-ple.When forming correspondences involving longsentences with many clauses, it was observed thatthe position at which a noun phrase occurred in Elwas very roughly proportional to the correspond-ing noun phrase in Fi.
In such cases it was notnecessary to form correspondences with all nounphrases in Fi for each noun phrase in Ei.
Instead,the location of a phrase in Ei was mapped lin-early to a position in Fi and correspondences wereformed for noun phrases occurring in a windowaround that position.
This resulted in a total of34,000 correspondences.
The mappings are stablewithin a few (2-4) iterations.In discussing results, a selection of examples willbe presented that demonstrates the strengths andweaknesses of the algorithm.
To give an indicationof noun phrase frequency counts in the sample, thehighest ranking correspondences are shown in Ta-ble 1.
The figures in columns (1) and (3) indicatethe number of instances of the noun phrase to theirright.185 Mr. Speaker 187 M. Le PrSsident128 Government 141 gouvernement60 Prime Minister 65 Premier Ministre63 Hon.
Member 66 d6put667 House 68 ChambreTable 1: Common correspondencesTo give an informal impression of overall per-formance, the hundred highest ranking correspon-dences were inspected and of these, ninety werecompletely correct.
Less frequently occurringnoun phrases are also of interest for purposes ofevaluation; some of these are shown in Table 2.32 Atlantic CanadaOpportunitiesAgency5 DREE1 late spring1 whole issueof free trade23 Agence de promotion6conomique duCanada atlantique4 MEER1 fin du printemps1 questiondu libre-~changeTable 2: Other correspondencesThe table also illustrates an unembedded En-glish noun phrase having multiple prepositional19phrases in its French correspondent.
Organiza-tional acronyms (which may be not be available ingeneral-purpose dictionaries) are also extracted, asthe taggers are robust.
Even when a noun phraseonly occurs once, a correct correspondence an befound if there are only single noun phrases in eachsentence of the alignment.
This is demonstratedin the last row of Table 2, which is the result ofthe following alignment:Ei: "The whole issue of free trade has been men-tioned.
"Fi: "On a mentionn~ la question du libre-~change.
"Table 3 shows some incorrect correspondencesproduced by the algorithm (in the table, "usine"means "factory").11 r ?
tho obtraining I 01 asia0 I1 mix of on-the-job 6 usineTable 3The sentences that are responsible for these cor-respondences illustrate some of the problems asso-ciated with the correspondence model:Ei: "They use what is known as the dual systemin which there is a mix of on-the-job and off-the-job training.
"Fi: "Ils ont recours ?
une formation mixte, partieen usine et partie hors usine.
"The first problem is that the conjunctive modifiersin the English sentence cannot be accommodatedby the noun phrase recognizer.
The tagger alsoassigned "on-the-job" as a noun when adjectivaluse would be preferred.
If verb correspondenceswere included, there is a mismatch between thethree that exist in the English sentence and thesingle one in the French.
If the English were toreflect the French for the correspondence modelto be appropriate, the noun phrases would per-haps be "part in the factory" and "part out ofthe factory".
Considered as a translation, thisis lame.
The majority of errors that occur arenot the result of incorrect agging or noun phraserecognition, but are the result of the approximatenature of the correspondence model.
The corre-spondences in Table 4 are likewise flawed (in thetable, "souris" means "mouse" and "tigre de pa-pier" means "paper tiger"):1 toothless tiger 1 souris1 toothless tiger 1 tigre de papier1 roaring rabbit 1 souris1 roaring rabbit 1 tigre de papierTable 4These correspondences are the result of the fol-lowing sentences:Ei: "It is a roaring rabbit, a toothless tiger.
"Fi: "C' est un tigre de papier, un souris qui rugit.
"In the case of the alliterative English phrase "roar-ing rabbit", the (presumably) rhetorical aspect ispreserved as a rhyme in "souris qui rugit"; the re-sult being that "rabbit" corresponds to "souris"(mouse).
Here again, even if the best correspon-dence were made the result would be wrong be-cause of the relatively sophisticated considerationsinvolved in the translation.EXTENSIONSAs regards future possibilities, the algorithm lendsitself to a range of improvements and applications,which are outlined next.F ind ing  Word  Cor respondences :  The algo-rithm finds corresponding noun phrases but pro-vides no information about word-level correspon-dences within them.
One possibility is simply toeliminate the tagger and noun phrase recognizer(treating all words as individual phrases of lengthunity and having a larger number of correspon-dences).
Alternatively, the following strategy canbe adopted, which involves fewer total correspon-dences.
First, the algorithm is used to build nounphrase correspondences, then the phrase pairs thatare produced are themselves treated as a bilingualnoun phrase corpus.
The algorithm is then em-ployed again on this corpus, treating all words asindividual phrases.
This results in a set of sin-gle word correspondences for the internal words innoun phrases.Reduc ing  Ambigu i ty :  The basic algorithmassumes that noun phrases can be uniquely identi-fied in both languages, which is only true for sim-ple noun phrases.
The problem of prepositionalphrase attachment is exemplified by the followingcorresp on den ces:16 Secretary 20 secrdtaire d' Etatof State16 Secretary 19 Affaires extdrieuresof State16 External Affairs 19 Affaires extdrieures16 External Affairs 20 secrdtaire d' EtatTable 5The correct English and French noun phrasesare "Secretary of State for External Affairs" and"secr~taire d' Etat aux Affaires ext~rieures".
Ifprepositional phrases involving "for" and "~" werealso permitted, these phrases would be correctly20identified; however many other adverbial preposi-tional phrases would also be incorrectly attachedto noun phrases.If all embedded prepositional phrases were per-mitted by the noun phrase recognizer, the algo-rithm could be used to reduce the degree of ambi-guity between alternatives.
Consider a sequencenp~ppe of an unembedded English noun phrasenpe followed by a prepositional phrase PPe, andlikewise a corresponding French sequence nplpp I.Possible interpretations of this are:1.
The prepositional phrase attaches to the nounphrase in both languages.2.
The prepositional phrase attaches to the nounphrase in one language and does not in theother.3.
The prepositional phrase does not attach tothe noun phrase in either language.If the prepositional phrases attach to the nounphrases in both languages, they are likely to berepeated in most instances of the noun phrase; itis less likely that the same prepositional phrasewill be used adverbially with each instance of thenoun phrase.
This provides a heuristic methodfor reducing ambiguity in noun phrases that oc-cur several times.
The only modifications requiredto the algorithm are that the additional possiblenoun phrases and correspondences between themmust be included.
Given thresholds on the num-ber of occurrences and the probability of the cor-respondence, the most likely correspondence anbe predicted.Including Context:  In the algorithm, cor-respondences between source and target nounphrases are considered irrespectively ofother cor-respondences in an alignment.
This does not makethe best use of the information available, and canbe improved upon.
For example, consider the fol-lowing alignment:El: "The Bill was introduced just beforeChristmas.
"Fi: "Le projet de lot a ~t~ present~ juste avant lecong~ des F~tes.
"Here it is assumed that there are many instancesof the correspondence "Bill" and "projet de lot",but only one instance of "Christmas" and "cong~des F~tes".
This suggests that "Bill" correspondsto "projet de lot" with a high probability andthat "Christmas" likewise corresponds strongly to"cong~ des F~tes".
However, the model will assertthat "Christmas" corresponds to "projet de lot"and to "cong~ des F~tes" with equal probability,no matter how likely the correspondence b tween"Bill" and "projet de lot".The model can be refined to reflect this situ-ation by considering the joint probability that atarget npr(t) corresponds to a source ripE(s) andall the other possible correspondences in the align-ment are produced.
This situation is very similarto that involved in training HMM text taggers,where joint probabilities are computed that a par-ticular word corresponds to a particular part-of-speech, and the rest of the words in the sentenceare also generated (e.g.
\[Cutting et al, 1992\]).CONCLUSIONThe algorithm described in this paper provides apractical means for obtaining correspondences be-tween noun phrases in a bilingual corpus.
Lin-guistic structure isused in the form of noun phraserecognizers to select phrases for a stochastic modelwhich serves as a means of minimizing errors dueto the approximations inherent in the correspon-dence model.
The algorithm is robust, and exten-sible in several ways.Re ferences\[Brown et al, 1991a\] P. F. Brown, J. C. Lai, andR.
L. Mercer.
Aligning sentences in parallel cor-pora.
In Proceedings of the 29th Annual Meetingof the Association of Computational Linguis-tics, pages 169-176, Berkeley, CA., June 1991.\[Brown et al, 1991b\] P. F. Brown, S. A. DellaPietra, V. J. Della Pietra, and R. L. Mer-cer.
Word sense disambiguation using statisti-cal methods.
In Proceedings of the 29th AnnualMeeting of the Association of ComputationalLinguistics, pages 264-270, Berkeley, CA., June1991.\[Brown et al, 1992\] P. F. Brown, S. A. DellaPietra, V. J. Della Pietra, J. D. Lafferty, andR.
L. Mercer.
Analysis, statistical transfer, andsynthesis n machine translation.
In Proceedingsof the Fourth International Conference on The-oretical and Methodological Issues in MachineTranslation, pages 83-100, Montreal, Canada.,June 1992.\[Church and Gale, 1991\] K. W. Church andW.
A. Gale.
Concordances for parallel text.
InProceedings of the Seventh Annual Conferenceof the UW Center for the New OED and TextResearch, pages 40-62, September 1991.\[Cutting et at., 1992\] D. Cutting, J. Kupiec,J.
Pedersen, and P. Sibun.
A practical part-of-speech tagger.
In Proceedings of the ThirdConference on Applied Natural Language Pro-cessing, Trento, Italy, April 1992.
ACL.\[Dagan et al, 1991\] I. Dagan, A. Itai, andU.
Schwall.
Two languages are more informa-tive than one.
In Proceedings of the 29th AnnualMeeting of the Association of Computational21Linguistics, pages 130-137, Berkeley, CA., June1991.\[Dempster t ai., 1977\]A.P.
Dempster, N.M. Laird, and D.B.
Rubin.Maximum likelihood from incomplete data viathe EM algorithm.
Journal of the Royal Statis-tical Society, B39:1-38, 1977.\[Gale and Church, 1991a\] W. A. Gale and K. W.Church.
Identifying word correspondences inparallel texts.
In Proceedings of the FourthDARPA Speech and Natural Language Work-shop, pages 152-157, Pacific Grove, CA., Febru-ary 1991.
Morgan Kaufmann.\[Gale and Church, 1991b\] W. A. Gale and K. W.Church.
A program for aligning sentences inbilingual corpora.
In Proceedings of the 29thAnnual Meeting of the Association of Compu-tational Linguistics, pages 177-184, Berkeley,CA., June 1991.\[Kay and RSscheisen, 1988\]M. Kay and M. RSscheisen.
Text-translationalignment.
Technical Report P90-00143, XeroxPalo Alto Research Center, 3333 Coyote HillRd., Palo Alto, CA 94304, June 1988.\[Kupiec, 1992\] J. M. Kupiec.
Robust part-of-speech tagging using a hidden markov model.Computer Speech and Language, 6:225-242,1992.\[Smadja, 1992\] F. Smadja.
How to compile abilingual collocational lexicon automatically.
InC. Weir, editor, Proceedings of the AAAI-92 Workshop on Statistically-Based NLP Tech-niques, San Jose, CA, July 1992.22
