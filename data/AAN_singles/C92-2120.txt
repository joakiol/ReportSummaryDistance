CONSTRUCTION OFCORPUS-BASED SYNTACTIC  RULES FORACCURATE SPEECH RECOGNIT IONJUNKO HOSAKA TOSHIYUKI TAKEZAWAATR In terpret ing  Te lephony Research Laborator iesH ikar ida i  2-2, Seika-cho, Soraku-gunKyoto  619-02, Japanhosaka@at  r - la .at  r.co.jptakezawaQat  r- la.~t r.co.j pAbst rac tThis paper describes the syntactic rules which areapplied in the Japanese speech recognition module ofa speech-to-speech translation system.
Japanese isconsidered to be a free word/phrase order language.Since syntactic rules are applied as constraints to re-duce the search space in speech recognition, apply-ing rules which take into account all possible phraseorders can have almost the same effect as using noconstraints.
Instead, we take into consideration therecognition weaknesses of certain syntactic ategoriesand treat them precisely, so that a miuimal num-ber of rules can work most effectively.
In this paperwe first examine which syntactic ategories are eas-ily misrecognized.
Second, we consult our dialoguecorpus, in order to provide the rules with great gen-erality.
Based ou both stndies, we refine the rules.
Fi-nally, we verify the validity of the refinement throughspeech recognition experiments.1 In t roduct ionWe are developing the SpokenLanguage Tl~ANSlation system (SL-TRANS)\[1\], inwhich both speech recognition processing and naturallanguage processing arc integrated.
Currently we arestudying automatic speech translation from Japaneseinto English in the domain of dialogues with the reception service of an international conference office.In this framework we are constructing syntactic rulesfor recognition of Japanese speech.In speech recognition, the most significant concernis raising the recognition accuracy.
For that pur-pose, applying linguistic information turns out to bepromising.
Various approaches have been taken, suchas using stochastic models\[2\], syntactic rules\[3\], se-mantic information\[4\] and discourse plans\[5\].
Amongstochastic models, the bigram and trigram succeededin achieving a high recognition accuracy in languagesthat have a strong tendency toward a standard wordorder, such as English.
On the contrary, Japanesebelongs to free word order languages\[6\].
For sucha language, semantic information is more adequatea.s a constraint.
However, building semantic on-straints for a large vocabulary needs a tremendousamount of data.
Currently, our data consist ofdialogues between the conference registration officeand prospective conference participants with approx-imately 199,000 words in telephone conversations andapproximately 72,000 words in keyboard conversa-tions.
But our data are still not sufficient o buildappropriate semantic onstraints for sentences with700 distinct words.
Processing a discourse plan re-quires excessive calculation and the study of discourseitself must be further developed to be applicable tospeech recognition.
On the other hand, syntax hasbeen studied in more detail and makes increasing thevocabulary easier.As we are working on spoken language, we try to re-flect real language usage.
For this purpose, astochas-tic approach beyond trigrams, namely stochastic sen-tence parsing\[7\], seems most promising.
Ideally, syn-tactic rules should be generated automatically froma large dialogue corpus and probabilities should alsobe automatically assigned to each node.
But to doso, we need underlying rules.
Moreover, coping withphoneme perplexity, which is crucial to speech recog-nition, with rules created frmn a dialogue corpus, re-quires additional research\[8\].In this paper we propose taking into account ileweaknesses of the speech recogniton system in theearliest stage, namely when we construct underlyingsyntactic rules.
First, we examined the speech recog-nition results to determine which Syntactic ategoriestend to be recognized erroneously.
Second, we uti-lized our dialogue corpus\[9\] to support he refinementof rules concerning those categories.
As examples, wediscuss formal nouns 1 and conjunctive postposi~ions 2.Finally, we carried out a speech recognition experi-ment with the refined rules to verify the validity ofour approach.1 Formal noun~ : keishiki-meishi in Japanese.Conjunctive postpositions : setsuzoku-joshi in Japanese.AcrEs DE COLING-92, NAr~TES, 23-28 AOt'~q" 1992 8 0 6 PROC.
OF COLING-92, NANTES, AUG. 23-28, 19922 Issues in HMM-LR SpeechRecognit ionin the Japanese speech recognition module of our ex-perimental system the combination of generalized I,Rparsing and fIidden Markov Model (IIMM) is realized~s IIMM-LR \[10\].
The system predicts phonetnes byusing an LR parsing table and drives IIMM phonemeverifiers to detect/verify them without any interven-ing structure, such as a phoneme lattice.The speech recognition unit is a Japanese bun-selsu, which roughly corresponds to a phrase and isthe next largest unit after the word.
The ending ofthe bunselsu (phrase) is usually marked by a breathpoint.
This justities its treatment as a distinct unit.A Japanese phrase consists of one independent word(e.g.
noun, adverb, verb) and zero, one or more thanone dependent words (e.g.
postposition, auxiliaryverb).
The nmnber of words in a phreLse ranges from1 to 14, and the mean number is about 3, accordingto our dialogue corpus.We will clarify the weaknesses of HMM-Llt speechrecognition both in phrases and in sentences.2.1 Phrase Recognition ErrorsWe examined which syntactic ategories tmtd to beerroneously recognized, when using IIMM-LR pltraaespeech recognition.
For this purl)ose , we appliedsyntactic rules containing no constraints on wordsequences s. This me,ms tllat any word can followany word.Examples (1) and (2) show the resnlts of IIMM-LHJapanese speech recognition "l. The nttered phonemestrings are enclosed in I I.
(i) Isochirawal (this, that)> I : sochira-wa2 : sochira-wa-hu3 : sochira-ha-wa4 : sochira-hu-wa-hu5 : sochira-wa-hu-hu(2) laringatougozaimasul (thank you)............................................i : ari~nga-to-wa-eN-hu-su-su-su2 : ari-nga-to-wa-eN-hu--su-su3 : ari-nga-to-wa-eN-hu~su-su-u4: ari-nga-to-wa-eN-su-suS : ari-nga-to-wa-eN-hu-,~u-su-su-a3Japttnese verbs, adjectives, etc.
itl-e always inllected whettllsed.
In syntactic lades colit~llillg 11o word sequence con-straints, hfllected verbs, inflected adjectives, ctc.
m-c consid-ered to be words,4The nlaxhna\[ mnount of whole beam width, the globalbeam width, is set for 16 attd the xne~ximal beam width ofeach brmach, the local beam width, 10.In the examples, the symbols >, -, ng and N havespecial meaning:A correctly recognized plmme is nmrked with >.?
A word boundary is marked with -.A nasalized /g / i s  transcribed ng.
* A syllabic nasal is transcribed N.In (1), after recognizing the tirst word, the sys-tem selected subsequent words solely to produce aphoneme string similar to the original utterance.
(2) is an example of phrase recognition which failed.In this example tou was erroneously recognized as to.Suhsequently, no fllrther correet words were selected.Examples (1) and (2) both show that IIMM-LRtends to select words consisting of extremely fewphonemes when it fails in word recognition.
Toavoid this problem, precise rules should be writ-ten fin' sequences of words with small nnmbers ofphonemes.
In Japmmse, postpositions(e.g, ga, o, nit,wh-pronouiis(e.g, itsu, nani, claret\[Ill, numerals(e.g.ichi, hi, san) and certain nouns(e.g, kata, mono) par-ticularly tit this description.2 .2 Sentence  i l .ecogn i t ion  Er rorsTo exanfine the error tendency of sentence speechrecognition we applied a two-step method\[12\].
First,we applied phra~e rules to the ItMM-LR speechrecognition s. Second, we applied phrase-ba-sed sen-tence rules tt, the phrase candidates as a post-filter,in order to obtain sentence candidates, while filter-ins out unacceptable candidates.
We experimentedwith the 353 phrases making up 1:/7 sentences.
Therecognition rate ff)r the top candidates wins 68.3 % byexact string tnatching, and for the top 5 candidates95.5 %.Based on the top 5 phr~me candidates, we con-dncted a ;;entente xperiment, ht this experimentwe applied loosely constrained sentence rules.
Withthese rules, altproxinnttely 80 % of all the pos-sibh', combinations of phrase candidates were re-.cepted.
Following are examples which did not exactlymatch the uttered sentences a .
Notice that misrecog-nized words consist of a relatively small number ofphonelues j  gig }ve have seen iil sect ion 2.1.
(3) lka ingi~ni  moubhiko-mi-tai-no-desu-nga \[(rl ~ould like go !egister forthe conference.
)as: kaingi-ni moushJko~mi-tai-N-desu-nga3b: kaingi.-ni moushiko-mi-gai-no-desu-ka(4) Ikochira-wa kaingizimukyoku-desul5'fhe global beam width is set fin" 100 and tile local beamwidth 10.~Since the phr~e candidates *tlv obtaiued by the I1MM-LItspeech recognitiolt, word botmdatie~ m'e Mready marked by -.AcrEs DE COLINGo92.
NANTES.
23-28 ^ ot'n 1992 8 0 7 I'r~oc.
OF COLINGO2, NANTES.
AUG. 23-28.
1992(This is  the conference o f f i ce .
).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.4a: kata-wa kaingizimukyoku-desu.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(5) \[doumo ar ingat -ou-goza ima-sh i - ta l(Thank you very much.).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.5a: go-o a r ingat -ou-goza ima-sh i - ta5b: go-me ar ingat -ou-goza ima-sh i - ta5c: mono ar ingat -ou-goza ima-sh i - ta.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(6) \[gozyuusho-to onamae-o nengai-shi-masu\[(Can I have your name and address?).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.6a: gozyuusho-to namae-oonengai-.sh?-masu-shiThough the phoneme string in 3a is different fromthe uttered phoneme string, the difference betweenno and N in meaning is minor, and has no effect ontranslation with the current echnique.
While (3) isaffirmative, 3b is interrogative, which is indicated bythe sentence final postposition ka.
This cannot betreated with sentence rules.
To haudle this problem,we need dialogue management.The uttered phrase kochira-~a in (4), meaning"this," was recognized erroneously as kat.a-wa in 4a,meaning "person."
The word kata belongs to theformal noun group, a kind of noun which should bemodified by a verbal phrase \[13\].
Sentence 4a is ac-ceptable, if modified by a verbal phrase, as in 4a':4a': midori-no seihukn-o kiteiru kata-wakaigizimukyoku-desu(The person who is wearing a green uniform is\[with\] the conference office.
)This is also true of the phrase mono in 5c meaning"thing," which was erroneously recognized instead ofdoumo meaning "very much":5c': kouka-na mono aringat-ou-gozaima-shi-ta(Thank you for the expensive thing.
)In sentence candidates 5a and 5b, the numeral go,meaning "five," is used.
These sentences may seemstrange at first glance, but in a situation such as play-ing cards, these sentences are quite natural.
If some-one plays a 5 when you need one, you would say:"Thanks for the five."
Similarly, when you need a 3and a 5, and someone plays a 3 and after that some-one else plays a 5, you would say: "Thanks for thefive, too.
"In the sentence candidate 6a, the conjunetive-poslposilion (conj-pp) shi is used sentence finally.
Inprinciple, aconj~pp combines two sentences, function-ing like a conjunction, such as "while" and "though,"and is used in the middle of a sentence.Erroneous entence recognition such as in the caseof 3a-b cannot be treated by sentence rules.
There-fore, we are trying to cope with erroneous recognition,as seen in sentence candidates 4a, 5a-c and 6a, withsentence rules.3 Dealing with Speech Recog-nition Er rorsWe are going to deal with sentences containing tilefollowing phrases:?
Phrases with formal nouns?
Phrases with numerals?
Phrases with conj-pps used in the sentence finalpositionIn order to decide how to cope with the aboveproblems, we used our dialogue corpus.
Currentlywe have 177 keyboard conversations consisting of ap-proximately 72,000 words and 181 telephone conver-sations consisting of approxilnately 199,000 words 7.We regard keyboard conversations as representingwritten Japanese and telephone conversations a rep-resenting spoken Japanese.
When retrieving the dia-logue corpus, we always compare written and spokenJapanese, in order to clarify the features of the latter.We examined the actuM usage of formal nouns as wellas that of eonj-pps.3 .1  Formal  NounsWe examined the behavior of formal nouns, such askoto and mono.
Formal nouns are considered to bea kind of noun which lacks the content usually foundin common nouns such as "sky" or "apple."
Theyfunction similarly to relative pronouns and thereforeare used with a verbal modifier\[13\], as in examples 7and 8:7 : kinou ilia koto~wa torikeshitai.
(I would like to take back what  I said yesterday.
)8 : nedan-ga takai mono-ga shitsu-ga ii wakede-wanai.
(It is not always true that an expensive thing hasgood quality.
)In examples 7 and S, the formal nouns, kolo andmono, are modified by kinou ilia (yesterday said) andnedan-ga takai (price expensive), respectively.
Butit is also true that these nouns behave like commonnouns and can be used without any verbal modifier,as in examples 9 and 10:9 : sore-wa koto desu ne.7The dialogue corpus is ?.rowing constantly.
When we re-trieved formM nouns, we had 113 keyboard conversations and96 telephone conversations.ACTES DE COLING-92, NANa~2S, 23-28 AOUT 1992 8 0 8 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992(It is a grave matter.
)10 : mono-wa ta.shika-da.
(This stuff is trustworthy.
)Considering the examples 7-10, we coukl define twokinds of usage for formal nouns.
This distinction isapplicable to sentence analysis, but is meaninglessfrom the standpoint of applying syntactic rules msconstraints.3.1.1 Formal  Nouns in the CorpusIll our dialogue corpus, koto, mono, hou and kata aretile most frequently used formal nouns.
Table 1 showshow often tile formal nouns are used with a verbalmodifier.
We have also rctrieved formal nouns usedin the sentence initial position, w~ in example 10.Table 1: Formal NouusKeyboard \] Te lepho~With Verb.
Mod.Without Verb.
Mod.Sent.
InitialTotal214 30,~72 po I ~Table 1 indicates that tile coverage reaches 63 % inwritten Japanese, when we allow only formal nounspreceded by a verbal modifier in the syntactic rules.llowever, the coverage remains at 40 %, which is lessthan half, in the spoken Japanese we are dealing with.We have further examined those sentences in whichfortnal nouns are not modified by verbals.
Most ofthem are modified by phrases consisting of a noun andpostposition o, which approximately corresponds to"of."
Further, some are modified by phrases cousist~ing of a verb tbllowed by postpositions to and no.Others are moditled by words which cars be used ex-clusively ,as nominal modifiers uch as donna (whatkind of) and sono (that).
We found only one exam-pie in the keyboard conversation i which a fortnalnoun is not modified at all:11 : osorakn kyouju-ni koto-no shidm-o tsutaerukoto-ga ii-to omoim~su.
(it might be good if you tell the professor how thetiring is going.
)In our diMogue corpus we found 2,491 phrases containing the formal nouns kolo, mono, hou and kala.Out of 2,491 examples, there is only one which is notmodified at all.
If we define formal lsouns ,~s thosewhich are always modilied in some manner, i.e.
evenif we do not allow formal nouns to be used alone, thecoverage still exceeds 99 %.
Since the occurrence rateof formal nmms without ally moditier is very low, wecan treat the usage of formal nouns (as in examples9-11) as semi-frozen expressions.3.2 Conjunctive PostpositionsJapanese pc,stpositions such m~ 9 a, o and hi, whichfunction a.s case markers, are usually attached tonominals.
Different from this kind of postposition,conj-pps uch a~s ga, te and ba are used after verbMs.Conj-pps combine two clauses, fimctiouing similarlyto conjunctions such as "because" and "whilc," andare thus often used in the middle of a sentence, as inexample 12.
But they cars also be used in the sen-tence final position, as ill exmnple 13.12: kaigi-ni mousikomi-tai-no-desu-ga,DttTmousikomiyousi-o ookurikudasai.AKK\]\]ecanse I would like to apply for the conference,plee, se send me a registration form.13: kaigi-ni mousikomi-tui-uo-desu-ga.DA\]'1 would like to apply for the conference, ...Example 13 sounds vague, if uttered in isolation.There should follow some additional words to expressthe complete meaning.
Sentences finishing with aeonj-pp leave the interpretation to tile hearer.
And,in general, the hearer can correctly interpret the sen-tence from the context.
Understanding conj-pps,therefore, plays an important role in treating spokenJapanese.3.2.1 Sentence Final Conj-pps in the CorpusIn the dialogue corpus the following conj-pps are used:ga (beeanse, while), node and udc (because), teaud~ (and), k.r~ 0 .
.
.
.
.
.
.
.
.
fret), k'~,'~.,l .
.... k~,'edo,kedo and kedomo (though, but), shi (and, and then),.
.
.
.
.
.
.
de (because), tara (if), to (if, when), ba (if) andnagara (while).Table 2 shows conj-pps used sentence finally.According to Table 2, the conj-pp ga is the onemost used in keyboard conversations.
While the us-age of conj-pps in keyboard conversations is heavilyconcentrated on ga with all occurrence rate of 85%,it is more balanced m telephone conversations.
Inaddition to ga (38%), kcredomo (30%) and conj-ppswhich carry a similar meaning such as kercdo, kedoand kedomo are frequently used.
In telephone conver-sations, node (13%) is also frequently nsed.
Treatingonly the six conj-pps in sentence final position, thecoverage reaches 91% for Sl)oken Japanese.
l)itt~ren~tiatmg conj-pps which can Ire used in sentence finalposition i?om those which can be used only in themiddle of a sentence is also supported by the speechrecognition results\[14\].
The conj-pps shi and cha areespecially subject to erroneous recognition.Acrgs DF.
COLING-92, NAbrLT.S, 23-28 Ao?rr 1992 8 0 9 PROC.
OF COLING-92, NANTES, AUo.
23-28, 1992Table 2: Sentence Final Conj-pps\[_ Keyboard Te lephoneConj-pp \ ]F requency \ ]  % Frequency\ ]  %9a 197node 11nde 0le 8de 0kara 6keredomo 5keredo 1kedo 1kedomo 0shi 2monode llara 01o 0ba 0nagara 085 274 385 96 130 5 13 23 30 1 03 14 22 212 30o 18 -2T0 12 29 37 51 l0 10 0 00 5 10 2 00 2 00 1 03 .3  Syntact i c  Ru les  fo r  Speech  Recog-n i t ionBased on the corpus retrieval we decided to deal withformal nouns and conj-pps as described below.
AIMwe decided to treat numerals only in a restricted en--vironment,  because they are significant noise factorsin speech rccognitionS:?
Phrases with formal nouns nmst be modified.?
Phrases with numerals can be used only illcertain environments.
Numerals are allowedin addresses, telephone numbers, dates aimprices.
Japanese nnlYlera\]s consist of all ex-tremely small number of phonemes, e.g.
ichi,hi, san (1, 2, 3) and are therefore specially easyto misrecognize 9.
"\['bus, they should be stronglyconstrained.
The domain we have chosen is lim-ited to dialogues between all international con-ferenee receptkmist and prospcctive part ic ipantsand we are going to deal only with tile antic-ipated usage in the domain.
Another condi-tion, sue\]l as playing cards, will be treated whenspeech recognition is further improved.?
We classify conj-pps into two groups: conj-ppswhich call be used in the sentence final positionas well as in the milldlc of a sentence, and conj-pps which can be used only ill the nfiddle of aseutence.We refined the loosely constrained syntactic rulesintroduced ill section 2.2. ill the new version of thesentence rules, formal nouns, numerals and eonjq)psare more precisely treated.
Ill the following, we explain the rules for formal nouns and conj-llpS.SSee Figure 2.9Nmnbers greater than ten e.re in principle the combinationof basic numbers.
'File format for syutactic rules is as follows:(<CATI> <--> (<CAT2> <CAT3>))Nonterufinals are surrounded by <>10.
The aboverule indicates that CATI consists of CAT2 and CAT3.To make tile distinction between phrase categorieswhich are terminals ill phrase-based sentence rulesand those which are not, we will write tile former allin lower-case.Ill the process of sentence construction, phrasescontaining a formal noun np-formal are treated msfotlowsn :(<M-NN> <--> (<NN>))(<M-NN> <--> (<MOD-N> <NN-FORM>))(<M-NN> <-~> (<MOD-N> <H-NN>))(<NN> <~--> (<np>))(<NN-FORM> <--> (<np-formal>))'\]?\]le above rules say that noun phrases M-NN call,m principle, be modified by some modifier MOD-K Intile case of a common noun NN, tile phrase can belnodified but need not be.
But in the case of a formalnoun IqN-FOKK file phrase must be modified.Phrases with a conj-pp which is exclusively used intile middle of a sentence vaux-s ,  those with a eonj-pp which is used both ill the middle of a sentenceand in tile sentence final vaux-s+~, and verb phraseswithout any eonj-pps vaux, are treated as follows:(<SS> <--> (<NVS>))(<NVS> <--> (<VS>))(<VS> <--> (<VC>))(<VS> <--> (<ADVPH> <VS>))<ADVPH> <--> (<ADV-s>))(<ADV-s> <--> (<ADVI>))(<ADV-s> <--> (<ADVI> <ADV-s>))<ADVP}I> <--> (<ADV-c>))(<ADV~c> <--> (<VADVS>))(<VADVS> <--> (<VADV>))(<VADVS> <--> (<ADV-s> <VADVS>))(<VADV> <--> (<vaux-s>) )(<VADV> <--> (<vaux-s+f>) )(<VC> <--> (<vaux>))(<VC> <--> (<vaux-s+f>) )A sentence SS does uot always need a noun phrase.A sentence SS can consist of only one verb phrase VC,or call be preceded by adverbial pfir,~ses ADVPH.
A sen-tence SS can end either with a verb phrase withouta conj-pps vaux or with a verb phrase with a cer-tain kind of conj-pps vaux-s+:f .
An adverbial phraseADVPH can consist of only adverbs ADVI and Call alsoconsist of verbal phrases VADVS.
The verbal pbrasesl?For tenninMs we have a different notation.
Terminals inphrase rules ta'e phoneme sU'ings, whose trm~scriptlon is de-fined by the HMM-LR phoneme model.11 For the sake of explanation, the rifles m'e simplified.Acr~ DE COLING-92, NAhqES.
23-28 AOt~q' 1992 8 1 0 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992VADVS call contain ally conj-pps, which means bothvaux-s  and vanx-s+~.Compared with tile first version, which accepts all- g 9 0 1 - / ~ / ~ A ~ ~proximately 80 % of the sentence candidates coilsist- ~"ing of all the possible combinations of plmLse candi-dates, tile refined version only accepts approximately ~ 80 , .tile phrase rules and l)hrase-based sentence rules.
~ 70Table 3: Size and Perplexity of Syntactic Rules60f ~ ~- -o  NowGrammnr\[ Pi .
.
.
.
.
\])~ule8 I Seutencc t~.tde~ | \] J  ReSent .
.
.
.
F\[nl~ll(3oll\[-ppm?
- )~ No Forme~l Noun Trentlng\[ lqo.
of l\[uies 1,973 471 50 i .
.
.
.
.
NoE l  .
.
.
.
.
.
.
.N o, of Terminals 744 133 / ~'1Perplexity :k57/Phoneme 99.7/l'hrm~e404 Validity of l~ule tLefinements ~00 5 10We tested the improvement in two ways: speechrecognition accuracy 'and the acceptance rate\[12\].rio estimate the latter we checked how many sen-tence candidates were f ltered out by applying phrmse-based sentence rules as a post-filter.
We verifiedthe rule refinements through coral)arisen of resultsgained by five different rule sets: tile refined ver-sion of sentence rules which contain all three relinements (Neu Grammar); the refined versiou withoutconj-pp treatment (No Sentence F ina l  Conj-pp),without formal noun treatment (No Formal ~ounTreat ing) ,  and without mnneral trcatmcnt (NoNume~'al Tz'eat?ng); and rules which allow all combi-nations of phr~qe candidates (No (;rmmn~n:).
For thef rst  four of these rule sets wc determined ranks basedon the probabilities of phoneme strings predicted bysyntactic rules.
But in the No Grmamar case we deter-mined tile rank solely based on phoneme probability.We exl)erimented with the same 353 phrases whichmake up 137 sentences as irl section 2.2.
The phraserecognition rate for the top 5 candidates was again95.5% by exact string matching.4 .1  Speech  Recogn i t ion  AccuracyWe conducted speech recognition experiments.
Fig-ure 1 shows the constraint effectiveness of the phrmse-based sentence rules given the five conditions ex-amined.
These live conditions arc'.
compared ill tilegraph, based on their abilities to correctly recognizethe spoken sentences among tile top ranked 20 can.didates.While the sentence recognition rate tbr the top can-didates remains 37.2 % when probability is the onlyfactor in determining tile candidates, the recognitionrate rises to 70.1% when tile refined syntactic rulesare applied as constraints.
Differentiating eonj-pps ishighly effective.
Without this treatment, tile recog-nition rate renaains 48.2%.
Formal noun and lnunera\]treatments are not as effective.
Figure 1 indicates15 20No.
of Gllndidelte=Figure 1 : Comparison of l~cognltion I{tttesthat tile elt~ct according to each syntactic onstraintis especially distinct up to rank 5, and that the recog-nition rates saturate when we take into account Sell-tenee candidates up to rank 10.4 .2  Acceptance  RateWe also verified the validity of sentence rules throughtile acceptance rate.
We examined how many sentence candidat~es were filtered ont.
Table 4 shows thefrequencies of sentences consisting of different nun>bets of phrases in our test corpus:Table 4: Phrase Number and Frequency\ [Phrase  Number 2 8Freq y .
.
.
.
.
.
~ \ ] ~ ~Figure 2 shows tile acceptance rates when applyingfour different syntactic rules.
Wlmn applying ruleswhich allow all combinations of phrase candidates,the accel)tance rate remains 100 %.
't'hc effect of constraints i especially clear lot sen-tences with a small number of I)hra~s.
In sentenceswitil one phrase, the asceptance rate for the revisedversion is 41%, and for the wu'sion without conj-ppconstraints 70%.
In cOral)arisen with Figure 1, treat-ing nmuerals contributes toward filtering out sentencecandidates rather than raising speech recognition ac-curacy.
Independent of the constraint strength, tilemort?
phrases there are ill ~.
sentence, tile ntore effetelively tile rules work.
'l)hc wdue for a sentence with8 phrases is unreliable, as we have only one example.Acn!s DE COLING-92, NAbrn!s, 23-28 ,',.o(n" 1992 8 i 1 PRec.
of COLING-92, NANTI!S, AUG. 23-28.
19928O?c 7oo-$60o~e- -o  New GrammarA .-... ?
No  8entente  F ina l  Con j -pp?
.
?
.
.
.
.
x< No  Formal  Noun Treat ing?
., o - - *  No  Numera lTreat ing"A""  "..I, I I I I I I I I1 2 3 4 5 s 7 8 9Number  o f  Phrases  In One SontenceFigure 2: Acceptance Rate5 Conc lus ionWe have described phrase-based syntactic rules whichare used as constraints in the Japanese speech recog-nition module of our experimental speech-to-speechtranslation system.
For constructing rules we tookinto account he error tendency in speech recognition.We treated precisely those syntactic ategories whichtend to be recognized erroneously.
To increase theefficacy of each rule, the rule construction is stronglymotivated by our dialogue corpus.
By applying therefined phrase-based syntactic rules, the speech recog-nition rate for the top candidates improved from 37.2% to 70.1% and for the top 5 candidates from 73.7% to 83.9 %.The implementation f syntactic rules bascd on ourdialogue corpus is continuing in order to increase cov-erage.
Currently we are studying postposition dele-tion in nominal phrases, which is one of the featuresof spoken Japanese.
When adding rules and enlarg-ing vocabulary, we cammt avoid decreasing speechrecognition accuracy, but our further experimentsshowed that careful rule construction filtered out un-acceptable sentence candidates much more effectively.Though we believe that our dialogue corpus for the,current domain provides enough expressions of spo-ken Japanese, we are going to apply the same methodto other domains to establish the generality of therules.AcknowledgementsThe authors wish to thank Dr.A.Kurematsu, President ofATR Interpreting Telephony Research Labs for his contin-ued support, Mr.T.Morimoto for discussion of the variousstages of this work, Mr.K.hmue for his help in databaseretrieval and Dr.S.Luperfoy and Dr.L.Fals for reading anearlier draft.References\[1\] Morimoto, T., Shikano, K., Iida, H., Kurem~.tsu,A.
(1990): "Integra.tion of Speech Recognition andLanguage Processing in Spoken Language Trans-lation System(SL-TRANS)," Proc.
of ICSLP-90,pp.921-924.\[2\] Lee, K.-F. ~nd Hon, H.-W.(1988): "Large-Vocabulary Speaker-Independent Continuous SpeechRecognition Using HMM," Proc.
of ICASSP-88,pp.123-1'26.\[3\] Ney, H.(1987): "Dynamic Programming SpeechRecognition Using a Context-Free Grammar," Proc.of ICASSP-87, pp.69-72.\[4\] Matsunaga, S., Sagayama, S., Homma, S. and Furui,S.
(1990): "A Continuous Speech Recognition SystemBased on a Two-Level Grammar Approach," Proc.
ofICASSP-90, pp.589-592.\[5\] Yamao'ka, T. and 1ida, H.(1990): "A Method to Pre-dict the Next Utterance Using a Four-layered PlanRecognition Model," Proc.
of ECAI-90, pp.726-731.\[6\] Kuno, S. (1973): The Structure of the Japanese Lan-guage, The MIT Press, Cambridge, Massachusettsand London.\[7\] Fujisaki, T. (1984): "A Stochastic Approach to Sen-tence Parsing," Proc.
of COLING-84, pp.16-19.\[8\] Ferretti, M., Maltese, G., Scarci, S. (1990): "Mea-suring Information Provided by Language Model andAcoustic Model in Probabilistic Speech Recognition:Theory and Experimental Results," Speech Commu-nication 9, pp.531-539.\[9\] Ehara, T., Ogura, K., Morimoto, T. (1990): "ATRDialogue Database," Proc.
of ICSLP-90, pp.
1093-1096.\[10\] Kita, K., Kawabata, T., Salto, H. (1989): "HMMContinuous Speech Recogniton Using Predictive LRParsing," Proc.
of ICASSP-89, pp.703~706.\[11\] Hosaka, J., Ogura, K., Kogure, K. (1990): "WordSequence Constraints for Japanese Speech Recogni-tion," Proc.
of ECA1-90, pp.
363-365.\[12\] Takezawa, T., Kita, K., Hosaka, J., Morinmto,T.
(1991):"Linguistic Constraints for ContinuousSpeech Recognition in Goal-Directed Dialogue,"Proc.
of ICASSP 91, pp.801-804.Ogawa, Y., Hayashi, H., et al (1982, 1988): NihongoKyouiku Jiten, Talshuukan, Tokyo, (In Japanese).Hosaka, J., Takezawa, T., Ehara, T. (1991): "Uti-lizing Empirical Data for Postposition Classificationtoward Spoken Japanese Speech Recognition," Proc.of ESCA-91, pp.
573-576.\[13\]ACRES DE COLING-92, NANTES, 23-28 Aotrr 1992 8 1 2 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992
