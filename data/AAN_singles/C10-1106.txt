Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 940?948,Beijing, August 2010Fast, Greedy Model Minimization for Unsupervised TaggingSujith Ravi and Ashish Vaswani and Kevin Knight and David ChiangUniversity of Southern CaliforniaInformation Sciences Institute{sravi,avaswani,knight,chiang}@isi.eduAbstractModel minimization has been shown towork well for the task of unsupervisedpart-of-speech tagging with a dictionary.In (Ravi and Knight, 2009), the authors in-voke an integer programming (IP) solverto do model minimization.
However,solving this problem exactly using aninteger programming formulation is in-tractable for practical purposes.
We pro-pose a novel two-stage greedy approxima-tion scheme to replace the IP.
Our methodruns fast, while yielding highly accuratetagging results.
We also compare ourmethod against standard EM training, andshow that we consistently obtain bettertagging accuracies on test data of varyingsizes for English and Italian.1 IntroductionThe task of unsupervised part-of-speech (POS)tagging with a dictionary as formulated by Meri-aldo (1994) is: given a raw word sequence and adictionary of legal POS tags for each word type,tag each word token in the text.
A common ap-proach to modeling such sequence labeling prob-lems is to build a bigram Hidden Markov Model(HMM) parameterized by tag-bigram transitionprobabilities P (ti|ti?1) and word-tag emissionprobabilities P (wi|ti).
Given a word sequence wand a tag sequence t, of length N , the joint prob-ability P (w, t) is given by:P (w, t) =N?i=1P (wi|ti) ?
P (ti|ti?1) (1)We can train this model using the ExpectationMaximization (EM) algorithm (Dempster and Ru-bin, 1977) which learns P (wi|ti) and P (ti|ti?1)that maximize the likelihood of the observed data.Once the parameters are learnt, we can find thebest tagging using the Viterbi algorithm.t?
= arg maxtP (w, t) (2)Ravi and Knight (2009) attack the Merialdotask in two stages.
In the first stage, they searchfor a minimized transition model (i.e., the small-est set of tag bigrams) that can explain the datausing an integer programming (IP) formulation.In the second stage, they build a smaller HMMby restricting the transition parameters to onlythose tag bigrams selected in the minimizationstep.
They employ the EM algorithm to train thismodel, which prunes away some of the emissionparameters.
Next, they use the pruned emissionmodel along with the original transition model(which uses the full set of tag bigrams) and re-train using EM.
This alternating EM training pro-cedure is repeated until the number of tag bigramsin the Viterbi tagging output does not change be-tween subsequent iterations.
The final Viterbi tag-ging output from their method achieves state-of-the-art accuracy for this task.
However, their mini-mization step involves solving an integer program,which can be very slow, especially when scal-ing to large-scale data and more complex taggingproblems which use bigger tagsets.
In this pa-per, we present a novel method that optimizes thesame objective function using a fast greedy modelselection strategy.
Our contributions are summa-rized below:940?
We present an efficient two-phase greedy-selection method for solving the minimiza-tion objective from Ravi and Knight (2009),which runs much faster than their IP.?
Our method easily scales to large datasizes (and big tagsets), unlike the previ-ous minimization-based approaches and weshow runtime comparisons for different datasizes.?
We achieve very high tagging accuraciescomparable to state-of-the-art results for un-supervised POS tagging for English.?
Unlike previous approaches, we also showresults obtained when testing on the entirePenn Treebank data (973k word tokens) inaddition to the standard 24k test data used forthis task.
We also show the effectiveness ofthis approach for Italian POS tagging.2 Previous workThere has been much work on the unsupervisedpart-of-speech tagging problem.
Goldwater andGriffiths (2007) also learn small models employ-ing a fully Bayesian approach with sparse pri-ors.
They report 86.8% tagging accuracy withmanual hyperparameter selection.
Smith and Eis-ner (2005) design a contrastive estimation tech-nique which yields a higher accuracy of 88.6%.Goldberg et al (2008) use linguistic knowledge toinitialize the the parameters of the HMM modelprior to EM training.
They achieve 91.4% ac-curacy.
Ravi and Knight (2009) use a MinimumDescription Length (MDL) method and achievethe best results on this task thus far (91.6% wordtoken accuracy, 91.8% with random restarts forEM).
Our work follows a similar approach using amodel minimization component and alternate EMtraining.Recently, the integer programming frameworkhas been widely adopted by researchers to solveother NLP tasks besides POS tagging such as se-mantic role labeling (Punyakanok et al, 2004),sentence compression (Clarke and Lapata, 2008),decipherment (Ravi and Knight, 2008) and depen-dency parsing (Martins et al, 2009).3 Model minimization formulated as aPath ProblemThe complexity of the model minimization stepin (Ravi and Knight, 2009) and its proposed ap-proximate solution can be best understood if weformulate it as a path problem in a graph.Let w = w0, w1, .
.
.
, wN , wN+1 be a word se-quence where w1, .
.
.
, wN are the input word to-kens and {w0, wN+1} are the start/end tokens.Let T = {T1, .
.
.
, TK}?
{T0, TK+1} be the fixedset of all possible tags.
T0 and TK+1 are specialtags that we add for convenience.
These would bethe start and end tags that one typically adds tothe HMM lattice.
The tag dictionary D containsentries of the form (wi, Tj) for all the possibletags Tj that word token wi can have.
We add en-tries (w0, T0) and (wK+1, TK+1) to D. Given thisinput, we now create a directed graph G(V,E).Let C0, C1 .
.
.
, CK+1 be columns of nodes in G,where column Ci corresponds to word token wi.For all i = 0, .
.
.
, N+1 and j = 0, .
.
.
,K+1, weadd node Ci,j in column Ci if (wi, Tj) ?
D. Now,?i = 0, .
.
.
, N , we create directed edges from ev-ery node in Ci to every node in Ci+1.
Each ofthese edges e = (Ci,j , Ci+1,k) is given the label(Tj , Tk) which corresponds to a tag bigram.
Thiscreates our directed graph.
Let l(e) be the tag bi-gram label of edges e ?
E. For every path P fromC0,0 to CN+1,K+1, we say that P uses an edge la-bel or tag bigram (Tj , Tk) if there exists an edgee in P such that l(e) = (Tj , Tk).
We can nowformulate the the optimization problem as: Findthe smallest set S of tag bigrams such that thereexists at least one path from C0,0 to CN+1,K+1 us-ing only the tag bigrams in S. Let us call this theMinimal Tag Bigram Path (MinTagPath) problem.Figure 1 shows an example graph where theinput word sequence is w1, .
.
.
, w4 and T ={T1, .
.
.
, T3} is the input tagset.
We add thestart/end word tokens {w0, w5} and correspond-ing tags {T0, T4}.
The edges in the graph are in-stantiated according to the word/tag dictionary Dprovided as input.
The node and edge labels arealso illustrated in the graph.
Our goal is to find apath from C0,0 to C5,4 using the smallest set of tagbigrams.941T0T1T2T3T4w0w1w2w3w4w5T0,T1T0,T3T1,T2T1,T2T2,T1T2,T2T3,T2T3,T4T2,T4T2,T3T2,T2T1,T3C0,0C1,1C1,3C2,2C3,1C3,2 C4,2C4,3C5,4word sequence:POS tagsInitial graph: G (V, E)Figure 1: Graph instantiation for the MinTagPath problem.4 Problem complexityHaving defined the problem, we now show thatit can be solved in polynomial time even thoughthe number of paths from C0,0 to CN+1,K+1 isexponential in N , the input size.
This relies on theassumption that the tagset T is fixed in advance,which is the case for most tagging tasks.1 Let Bbe the set of all the tag bigram labels in the graph,B = {l(e), ?e ?
E}.
Now, the size of B wouldbe at most K2 + 2K where every word could betagged with every possible tag.
For m = 1 .
.
.
|B|,let Bm be the set of subsets of B each of whichhave size m. Algorithm 1 optimally solves theMinTagPath problem.Algorithm 1 basically enumerates all the possi-ble subsets of B, from the smallest to the largest,and checks if there is a path.
It exits the first time apath is found and therefore finds the smallest pos-sible set si of size m such that a path exists thatuses only the tag bigrams in si.
This implies thecorrectness of the algorithm.
To check for path ex-istence, we could either throw away all the edgesfrom E not having a label in si, and then executea Breadth-First-Search (BFS) or we could traverse1If K, the size of the tagset, is a variable as well, then wesuspect the problem is NP-hard.Algorithm 1 Brute Force solution to MinTagPathfor m = 1 to |B| dofor si ?
Bm doUse Breadth First Search (BFS) to checkif ?
path P from C0,0 to CN+1,K+1 usingonly the tag bigrams in si.if P exists thenreturn si,mend ifend forend foronly the edges with labels in si during BFS.
Therunning time of Algorithm 1 is easy to calculate.Since, in the worst case we go over all the sub-sets of size m = 1, .
.
.
, |B| of B, the number ofiterations we can perform is at most 2|B|, the sizeof the powerset P of B.
In each iteration, we doa BFS through the lattice, which has O(N) timecomplexity2 since the lattice size is linear in Nand BFS is linear in the lattice size.
Hence the run-ning time is?
2|B| ?O(N) = O(N).
Even thoughthis shows that MinTagPath can be solved in poly-nomial time, the time complexity is prohibitivelylarge.
For the Penn Treebank, K = 45 and the2Including throwing away edges or not.942worst case running time would be ?
1013.55 ?
N .Clearly, for all practical purposes, this approach isintractable.5 Greedy Model MinimizationWe do not know of an efficient, exact algorithmto solve the MinTagPath problem.
Therefore, wepresent a simple and fast two-stage greedy ap-proximation scheme.
Notice that an optimal pathP (or any path) covers all the input words i.e., ev-ery word token wi has one of its possible taggingsin P .
Exploiting this property, in the first phase,we set our goal to cover all the word tokens usingthe least possible number of tag bigrams.
This canbe cast as a set cover problem (Garey and John-son, 1979) and we use the set cover greedy ap-proximation algorithm in this stage.
The outputtag bigrams from this phase might still not allowany path from C0,0 to CN+1,K+1.
So we carry outa second phase, where we greedily add a few tagbigrams until a path is created.5.1 Phase 1: Greedy Set CoverIn this phase, our goal is to cover all the word to-kens using the least number of tag bigrams.
Thecovering problem is exactly that of set cover.
LetU = {w0, .
.
.
, wN +1} be the set of elements thatneeds to be covered (in this case, the word tokens).For each tag bigram (Ti, Tj) ?
B, we define itscorresponding covering set STi,Tj as follows:STi,Tj = {wn : ((wn, Ti) ?
D?
(Cn,i, Cn+1,j) ?
E?
l(Cn,i, Cn+1,j) = (Ti, Tj))?
((wn, Tj) ?
D?
(Cn?1,i, Cn,j) ?
E?
l(Cn?1,i, Cn,j) = (Ti, Tj))}Let the set of covering sets be X .
We assigna cost of 1 to each covering set in X .
The goalis to select a set CHOSEN ?
X such that?STi,Tj?CHOSEN= U , minimizing the total costof CHOSEN .
This corresponds to covering allthe words with the least possible number of tagbigrams.
We now use the greedy approximationalgorithm for set cover to solve this problem.
Thepseudo code is shown in Algorithm 2.Algorithm 2 Set Cover : Phase 1DefinitionsDefine CAND : Set of candidate covering setsin the current iterationDefine Urem : Number of elements in U re-maining to be coveredDefine ESTi,Tj : Current effective cost of a setDefine Itr : Iteration numberInitializationsLET CAND = XLET CHOSEN = ?LET Urem = ULET Itr = 0LET ESTi,Tj = 1|STi,Tj | , ?
STi,Tj ?
CANDwhile Urem 6= ?
doItr ?
Itr + 1Define S?Itr = argminSTi,Tj?CANDESTi,TjCHOSEN = CHOSEN?S?ItrRemove S?Itr from CANDRemove all the current elements in S?Itr fromUremRemove all the current elements in S?Itr fromevery STi,Tj ?
CANDUpdate effective costs, ?
STi,Tj ?
CAND,ESTi,Tj =1|STi,Tj |end whilereturn CHOSENFor the graph shown in Figure 1, here are a fewpossible covering sets STi,Tj and their initial ef-fective costs ESTi,Tj .?
ST0,T1 = {w0, w1}, EST0,T1 = 1/2?
ST1,T2 = {w1, w2, w3, w4}, EST1,T2 = 1/4?
ST2,T2 = {w2, w3, w4}, EST2,T2 = 1/3In every iteration Itr of Algorithm 2, we pick aset S?Itr that is most cost effective.
The elementsthat S?Itr covers are then removed from all the re-maining candidate sets and Urem and the effec-tiveness of the candidate sets is recalculated forthe next iteration.
The algorithm stops when allelements of U i.e., all the word tokens are cov-ered.
Let, BCHOSEN = {(Ti, Tj) : STi,Tj ?943CHOSEN}, be the set of tag bigrams that havebeen chosen by set cover.
Now, we check, usingBFS, if there exists a path from C0,0 to CN+1,K+1using only the tag bigrams in BCHOSEN .
If not,then we have to add tag bigrams to BCHOSEN toenable a path.
To accomplish this, we carry out thesecond phase of this scheme with another greedystrategy (described in the next section).For the example graph in Figure 1,one possible solution BCHOSEN ={(T0, T1), (T1, T2), (T2, T4)}.5.2 Phase 2: Greedy Path CompletionWe define a graph GCHOSEN (V ?, E?)
?G(V,E) that contains the edges e ?
E suchl(e) ?
BCHOSEN .Let BCAND = B \ BCHOSEN , be the currentset of candidate tag bigrams that can be added tothe final solution which would create a path.
Wewould like to know how many holes a particulartag bigram (Ti, Tj) can fill.
We define a hole as anedge e such that e ?
G \ GCHOSEN and thereexists e?, e??
?
GCHOSEN such that tail(e?)
=head(e) ?
tail(e) = head(e??
).Figure 2 illustrates the graph GCHOSEN usingtag bigrams from the example solution to Phase 1(Section 5.1).
The dotted edge (C2,2, C3,1) rep-resents a hole, which has to be filled in the cur-rent phase in order to complete a path from C0,0to C5,4.In Algorithm 3, we define the effectiveness of acandidate tag bigram H(Ti, Tj) to be the numberof holes it covers.
In every iteration, we pick themost effective tag bigram, fill the holes and recal-culate the effectiveness of the remaining candidatetag bigrams.Algorithm 3 returns BFINAL, the final set ofchosen tag bigrams.
It terminates when a path hasbeen found.5.3 Fitting the ModelOnce the greedy algorithm terminates and returnsa minimized grammar of tag bigrams, we followthe approach of Ravi and Knight (2009) and fitthe minimized model to the data using the alter-nating EM strategy.
The alternating EM iterationsare terminated when the change in the size of theobserved grammar (i.e., the number of unique tagAlgorithm 3 Greedy Path Complete : Phase 2Define BFINAL : Final set of tag bigrams se-lected by the two-phase greedy approachLET BFINAL = BCHOSENLET H(Ti, Tj) = |{e}| such that l(e) =(Ti, Tj) and e is a hole, ?
(Ti, Tj) ?
BCANDwhile @ path P from C0,0 to CN+1,K+1 usingonly (Ti, Tj) ?
BCHOSEN doDefine (T?i, T?j) = argmax(Ti,Tj)?BCANDH(Ti, Tj)BFINAL = BFINAL?
(T?i, T?j)Remove (T?i, T?j) from BCANDGCHOSEN = GCHOSEN?
{e} such thatl(e) = (Ti, Tj)?
(Ti, Tj) ?
BCAND, Recalculate H(Ti, Tj)end whilereturn BFINALbigrams in the tagging output) is ?
5%.
We referto our entire approach using greedy minimizationfollowed by EM training as MIN-GREEDY.6 Experiments and Results6.1 English POS TaggingData: We use a standard test set (consisting of24,115 word tokens from the Penn Treebank) forthe POS tagging task (described in Section 1).
Thetagset consists of 45 distinct tag labels and thedictionary contains 57,388 word/tag pairs derivedfrom the entire Penn Treebank.
Per-token ambi-guity for the test data is about 1.5 tags/token.
Inaddition to the standard 24k dataset, we also trainand test on larger data sets of 48k, 96k, 193k, andthe entire Penn Treebank (973k).Methods: We perform comparative evaluationsfor POS tagging using three different methods:1.
EM: Training a bigram HMM model usingEM algorithm.2.
IP: Minimizing grammar size using inte-ger programming, followed by EM training(Ravi and Knight, 2009).3.
MIN-GREEDY: Minimizing grammar sizeusing the Greedy method described in Sec-944T0T1T2T3T4w0w1w2w3w4w5T0,T1T1,T2T1,T2T2,T1T2,T4C0,0C1,1C1,3C2,2C3,1C3,2 C4,2C4,3C5,4word sequence:POS tagsT0,T1T1,T2T2,T4Tag bigrams chosen after Phase 1(BCHOSEN)Hole in graph: Edge e = (C2,2, C3,1)Graph after Phase 1: GCHOSEN(V?, E?
)Figure 2: Graph constructed with tag bigrams chosen in Phase 1 of the MIN-GREEDY method.tion 5, followed by EM training.Results: Figure 3 shows the tagging perfor-mance (word token accuracy %) achieved by thethree methods on the standard test (24k tokens) aswell as Penn Treebank test (PTB = 973k tokens).On the 24k test data, the MIN-GREEDY methodachieves a high tagging accuracy comparable tothe previous best from the IP method.
However,the IP method does not scale well which makesit infeasible to run this method in a much largerdata setting (the entire Penn Treebank).
MIN-GREEDY on the other hand, faces no such prob-lem and in fact it achieves high tagging accuracieson all four datasets, consistently beating EM bysignificant margins.
When tagging all the 973kword tokens in the Penn Treebank data, it pro-duces an accuracy of 87.1% which is much betterthan EM (82.3%) run on the same data.Ravi and Knight (2009) mention that it is pos-sible to interrupt the IP solver and obtain a sub-optimal solution faster.
However, the IP solver didnot return any solution when provided the sameamount of time as taken by MIN-GREEDY forany of the data settings.
Also, our algorithmswere implemented in Python while the IP methodemploys the best available commercial softwarepackage (CPLEX) for solving integer programs.Figure 4 compares the running time efficiencyfor the IP method versus MIN-GREEDY methodTest set Efficiency(average running time in secs.
)IP MIN-GREEDY24k test 93.0 34.348k test 111.7 64.396k test 397.8 93.3193k test 2347.0 331.0PTB (973k) test ?
1485.0Figure 4: Comparison of MIN-GREEDY versusMIN-GREEDY approach in terms of efficiency(average running time in seconds) for differentdata sizes.
All the experiments were run on a sin-gle machine with a 64-bit, 2.4 GHz AMD Opteron850 processor.as we scale to larger datasets.
Since the IP solvershows variations in running times for differentdatasets of the same size, we show the averagerunning times for both methods (for each row inthe figure, we run a particular method on threedifferent datasets with similar sizes and averagethe running times).
The figure shows that thegreedy approach can scale comfortably to largedata sizes, and a complete run on the entire PennTreebank data finishes in just 1485 seconds.
Incontrast, the IP method does not scale well?onaverage, it takes 93 seconds to finish on the 24ktest (versus 34 seconds for MIN-GREEDY) andon the larger PTB test data, the IP solver runs for945Method Tagging accuracy (%)when training & testing on:24k 48k 96k 193k PTB (973k)EM 81.7 81.4 82.8 82.0 82.3IP 91.6 89.3 89.5 91.6 ?MIN-GREEDY 91.6 88.9 89.4 89.1 87.1Figure 3: Comparison of tagging accuracies on test data of varying sizes for the task of unsupervisedEnglish POS tagging with a dictionary using a 45-tagset.
(?
IP method does not scale to large data).4006008001000120014001600Observedgrammarsize(#oftagbigrams)infinaltaggingoutputSize of test data (# of word tokens)24k 48k 96k 193k PTB (973k)EMIPGreedyFigure 5: Comparison of observed grammar size(# of tag bigram types) in the final tagging outputfrom EM, IP and MIN-GREEDY.more than 3 hours without returning a solution.It is interesting to see that for the 24k dataset,the greedy strategy finds a grammar set (contain-ing only 478 tag bigrams).
We observe that MIN-GREEDY produces 452 tag bigrams in the firstminimization step (phase 1), and phase 2 adds an-other 26 entries, yielding a total of 478 tag bi-grams in the final minimized grammar set.
Thatis almost as good as the optimal solution (459tag bigrams from IP) for the same problem.
ButMIN-GREEDY clearly has an advantage since itruns much faster than IP (as shown in Figure 4).Figure 5 shows a plot with the size of the ob-served grammar (i.e., number of tag bigram typesin the final tagging output) versus the size of thetest data for EM, IP and MIN-GREEDY methods.The figure shows that unlike EM, the other twoapproaches reduce the grammar size considerablyand we observe the same trend even when scalingTest set Average Speedup Optimality Ratio24k test 2.7 0.9648k test 1.7 0.9896k test 4.3 0.98193k test 7.1 0.93Figure 6: Average speedup versus Optimality ra-tio computed for the model minimization step(when using MIN-GREEDY over IP) on differentdatasets.to larger data.
Minimizing the grammar size helpsremove many spurious tag combinations from thegrammar set, thereby yielding huge improvementsin tagging accuracy over the EM method (Fig-ure 3).
We observe that for the 193k dataset, thefinal observed grammar size is greater for IP thanMIN-GREEDY.
This is because the alternatingEM steps following the model minimization stepadd more tag bigrams to the grammar.We compute the optimality ratio of the MIN-GREEDY approach with respect to the grammarsize as follows:Optimality ratio = Size of IP grammarSize of MIN-GREEDY grammarA value of 1 for this ratio implies that the solu-tion found by MIN-GREEDY algorithm is exact.Figure 6 compares the optimality ratio versus av-erage speedup (in terms of running time) achievedin the minimization step for the two approaches.The figure illustrates that our solution is nearly op-timal for all data settings with significant speedup.The MIN-GREEDY algorithm presented herecan also be applied to scenarios where the dictio-nary is incomplete (i.e., entries for all word typesare not present in the dictionary) and rare words946Method Tagging accuracy (%) Number of unique tag bigrams in final tagging outputEM 83.4 1195IP 88.0 875MIN-GREEDY 88.0 880Figure 7: Results for unsupervised Italian POS tagging with a dictionary using a set of 90 tags.take on all tag labels.
In such cases, we can fol-low a similar approach as Ravi and Knight (2009)to assign tag possibilities to every unknown wordusing information from the known word/tag pairspresent in the dictionary.
Once the completed dic-tionary is available, we can use the procedure de-scribed in Section 5 to minimize the size of thegrammar, followed by EM training.6.2 Italian POS TaggingWe also compare the three approaches for ItalianPOS tagging and show results.Data: We use the Italian CCG-TUT corpus (Boset al, 2009), which contains 1837 sentences.
Ithas three sections: newspaper texts, civil codetexts and European law texts from the JRC-AcquisMultilingual Parallel Corpus.
For our experi-ments, we use the POS-tagged data from theCCG-TUT corpus, which uses a set of 90 tags.We created a tag dictionary consisting of 8,733word/tag pairs derived from the entire corpus(42,100 word tokens).
We then created a test setconsisting of 926 sentences (21,878 word tokens)from the original corpus.
The per-token ambiguityfor the test data is about 1.6 tags/token.Results: Figure 7 shows the results on ItalianPOS tagging.
We observe that MIN-GREEDYachieves significant improvements in tagging ac-curacy over the EM method and comparable to IPmethod.
This also shows that the idea of modelminimization is a general-purpose technique forsuch applications and provides good tagging ac-curacies on other languages as well.7 ConclusionWe present a fast and efficient two-stage greedyminimization approach that can replace the inte-ger programming step in (Ravi and Knight, 2009).The greedy approach finds close-to-optimal solu-tions for the minimization problem.
Our algo-rithm runs much faster and achieves accuraciesclose to state-of-the-art.
We also evaluate ourmethod on test sets of varying sizes and show thatour approach outperforms standard EM by a sig-nificant margin.
For future work, we would liketo incorporate some linguistic constraints withinthe greedy method.
For example, we can assignhigher costs to unlikely tag combinations (such as?SYM SYM?, etc.
).Our greedy method can also be used for solvingother unsupervised tasks where model minimiza-tion using integer programming has proven suc-cessful, such as word alignment (Bodrumlu et al,2009).AcknowledgmentsThe authors would like to thank Shang-Hua Tengand Anup Rao for their helpful comments andalso the anonymous reviewers.
This work wasjointly supported by NSF grant IIS-0904684,DARPA contract HR0011-06-C-0022 under sub-contract to BBN Technologies and DARPA con-tract HR0011-09-1-0028.ReferencesBodrumlu, T., K. Knight, and S. Ravi.
2009.
A newobjective function for word alignment.
In Proceed-ings of the NAACL/HLT Workshop on Integer Pro-gramming for Natural Language Processing.Bos, J., C. Bosco, and A. Mazzei.
2009.
Converting adependency treebank to a categorial grammar tree-bank for Italian.
In Proceedings of the Eighth In-ternational Workshop on Treebanks and LinguisticTheories (TLT8).Clarke, J. and M. Lapata.
2008.
Global inference forsentence compression: An integer linear program-ming approach.
Journal of Artificial IntelligenceResearch (JAIR), 31(4):399?429.Dempster, A.P., N.M. Laird and D.B.
Rubin.
1977.Maximum likelihood from incomplete data via the947EM algorithm.
Journal of the Royal Statistical So-ciety, 39(1):1?38.Garey, M. R. and D. S. Johnson.
1979.
Computersand Intractability: A Guide to the Theory of NP-Completeness.
John Wiley & Sons.Goldberg, Y., M. Adler, and M. Elhadad.
2008.EM can find pretty good HMM POS-taggers (whengiven a good start).
In Proceedings of the 46thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies(ACL/HLT).Goldwater, Sharon and Thomas L. Griffiths.
2007.A fully Bayesian approach to unsupervised part-of-speech tagging.
In Proceedings of the 45th AnnualMeeting of the Association for Computational Lin-guistics (ACL).Martins, A., N. A. Smith, and E. P. Xing.
2009.
Con-cise integer linear programming formulations fordependency parsing.
In Proceedings of the JointConference of the 47th Annual Meeting of the As-sociation for Computational Linguistics (ACL) andthe 4th International Joint Conference on NaturalLanguage Processing of the AFNLP.Merialdo, B.
1994.
Tagging English text with aprobabilistic model.
Computational Linguistics,20(2):155?171.Punyakanok, V., D. Roth, W. Yih, and D. Zimak.2004.
Semantic role labeling via integer linear pro-gramming inference.
In Proceedings of the Inter-national Conference on Computational Linguistics(COLING).Ravi, S. and K. Knight.
2008.
Attacking decipher-ment problems optimally with low-order n-grammodels.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP).Ravi, S. and K. Knight.
2009.
Minimized modelsfor unsupervised part-of-speech tagging.
In Pro-ceedings of the Joint Conference of the 47th An-nual Meeting of the Association for ComputationalLinguistics (ACL) and the 4th International JointConference on Natural Language Processing of theAFNLP.Smith, N. and J. Eisner.
2005.
Contrastive estima-tion: Training log-linear models on unlabeled data.In Proceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics (ACL).948
