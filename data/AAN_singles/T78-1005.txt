Taxonomic Latt ice Structures for S i tuat ion RecognitionWil l iam A. WoodsBolt Beranek and Newman Inc.50 Moulton StreetCambridge, MA 02138I.
The Role of a Knowledge Network for anIntel l igent MachineThe kinds of intel l igent computerassistants that we would like to be ableto construct are very much likeintel l igent organisms in their own right.Imagine for a moment an intel l igentorganism trying to get alng in the world(find enough food, stay out of trouble,satisfy basic needs, etc.).
The mostvaluable service played by an internalknowledge base for such an organism is torepeatedly answer quest ions like "what'sgoing on out there?
", "can it harm me?
","how can I avoid/p lacate it?
", "Is it goodto eat?
", "Is there any special thing Ishould do about it?
", etc.
To supportthis kind of activity, a substantial  partof the knowledge base must be organized asa recognit ion device for c lass i fy ing andidenti fying s ituat ions in the world.
Themajor purpose of this s i tuat ionrecognit ion is to locate internalprocedures which are appl icable(appropriate, permitted, mandatory,  etc.
)to the current situation.In construct ing an intel l igentcomputer assistant, the roles of knowledgeare very similar.
The basic goals of foodgett ing and danger avoidance are replacedby goals of doing what the user wants andavoiding things that the machine has beeninstructed to avoid.
However, thefundamental problem of analyzing as i tuat ion (one establ ished eitherl inguist ica l ly  or physica l ly  or by somecombinat ion of the two) in order todetermine whether it is one for whichthere are procedures to be executed, orone which was to be avoided (or one whichmight lead to one that is to be avoided),etc.
is basical ly the same.
For example,one might want to instruct such a systemto remind the user in advance of anyupcoming scheduled meetings,  to inform himif he tries to assign a resource that hasalready been committed, to always printout messages in reverse chronologicalorder (when requested),  to assume that"the first" refers to the first day of theupcoming month in a future schedul ingcontext and the first day of the currentmonth in a past context, etc.The pr incipal  role of the knowledgenetwork for such a system is essent ia l lyto serve as a "coat rack" upon which tohang various pieces of advice for thesystem to execute.
Thus the notion ofprocedural  attachment becomes not just anef f ic iency technique, but the main purposefor the existence of the network.
Thisdoes not necessar i ly  imply, however, thatthe procedures involved consist  oflow-level machine code.
They may instead,and probably usual ly will, be high levelspeci f icat ions of things to be done orgoals to be achieved.
The pr incipalstructure that organizes all of theseprocedures is a conceptual  taxonomy ofs i tuat ions about which the machine knowssomething.TO support the above uses ofknowledge, an important character ist icrequired of an ef f ic ient  knowledgerepresentat ion seems to be a mechanism ofinheritance that will permit informationto be stored in its most general form andyet stil l  be tr iggered by any morespecif ic s i tuat ion or instance to which itapplies.
Moreover,  the nodes in thenetwork (or at least a major class ofnodes) should be interpretable ass i tuat ion descr ipt ions.
One of the mostfundamental  kinds of information to bestored in the knowledge base will be rulesof the form "if <situat ion descr ipt ion> issat isf ied then do <action descr ipt ion>",or "if <situat ion descr ipt ion> then expect<situat ion descr ipt ion>".
Situat iondescr ipt ions are in generalcharacter izat ions of classes of s i tuat ionsthat the machine could be in.
They arenot complete descr ipt ions of world states,but only partial  descr ipt ions that applyto classes of world states.
(The machineshould never be assumed or required tohave a complete descr ipt ion of a worldstate if it is to deal with the realworld.)
A situation in this part ial  senseis def ined by the results of certainmeasurements,  computat ions,  or recognit ionprocedures  applied to the system's input.Examples  of s i tuat ions might be "You havea goal to achieve which is an example ofs i tuat ion Y", "You are perceiv ing anobject of class Z", "The user has askedyou to perform a task of type W", etc.33More specif ic s i tuat ions might be:"trying to schedule a meet ing for threepeople, two of which have busy schedules","about to print a message from a user tohimself",  "about to refer to a date in arecent previous year in a context whereprec is ion but conciseness is required".The major references to thisconceptual  taxonomy by the intel l igentmachine wil l  be attempts to identify andact ivate those s i tuat ion descr ipt ions thatapply to its current s i tuat ion or somehypothes ized s i tuat ion in order toconsider any advice that may be storedthere.
Note that "consider ing advice oftype X" is itself an example of as ituat ion, so that this process can easi lybecome recursive and potent ia l lyunmanageable without appropr iate care.Conceptual ly,  one might  think of theprocess of act ivat ing all of thedescr ipt ions that are sat isf ied by thecurrent  s i tuat ion as one of taking adescr ipt ion of the current s i tuat ion andmatching it against descr ipt ions stored inthe system.
However, there are in generalmany d i f ferent  ways in which the currents i tuat ion might be described, and it isnot clear how one should construct  such adescr ipt ion.Moreover,  until  it is so recognized,a s i tuat ion consists of a co l lect ion ofunrelated events and condit ions.
Theprocess of recogniz ing the elementscurrent ly  being perceived as an instanceof a s i tuat ion about which someinformation is known consists ofd iscover ing that those elements can beinterpreted as f i l l ing roles in as i tuat ion descr ipt ion known to the system.In fact, the process of creat ing adescr ipt ion of the current s i tuat ion isvery much like the process of pars ing asentence, and inherent ly uses theknowledge structure of the system like aparser uses a grammar in order toconstruct  the appropr iate descr ipt ion.Consequent ly,  by the time a descr ipt ion ofthe s i tuat ion has been constructed,  it hasalready been ef fect ive ly  matched againstthe descr ipt ions in the knowledge base.2.
Parsing SituationsAs suggested above, the process ofrecogniz ing that a current s i tuat ion is aninstance of an internal s i tuat iondescr ipt ion is similar to the process ofparsing a sentence, a lthough cons iderablymore di f f icu l t  due to a more open endedset of possib le re lat ionships among the"const i tuents" of a situation.
That is,whereas the pr incipal  re lat ionship betweenconst i tuents in sentences is merelyadjacency in the input string, there lat ionships among const i tuents of as i tuat ion may be arbi t rary (e.g.
eventspreceding one another in time, people,places, or physical  objects in var iousspatial re lat ionships with each other,objects in physical  or legal possess ion ofpeople, people in re lat ionships ofauthor i ty  to other people, etc.)
However,the basic character is t ic  of parsers,  thatthe objects recognized are character izedas structured objects assembled out ofrecognizable parts according to knownrules of assembly, is shared by this taskof s i tuat ion recognit ion.Note that it is not suf f ic ient  merelyto character ize a s i tuat ion as a member ofone of a f inite number of known classes.That is, where it is not suf f ic ient  for aparser to simply say that its input is anexample of a declarat ive sentence (onewants to be able to ask what the subjectis, what the verb is, whether the sentencehas past, present or future tense, etc.
),in a similar way it is insuff ic ient  tomerely  say that an input s i tuat ion is anexample of someone doing something.
Onemust generate a detai led descr ipt ion ofwho is doing what to whom, etc.It is also not suf f ic ient  tocharacter ize  a s i tuat ion as a singleinstance of an exist ing concept withvalues f i l led in for empty slots.
Ingeneral ,  a s i tuat ion descr ipt ion must be acomposite structured object, var ioussubparts of which wil l  be instances ofother concepts assembled together in waysthat are formal ly permitted,  in much thesame way that the descr ipt ion of asentence is put together from instances ofnoun phrases, clauses, and prepos i t ionalphrases.
The specif ic  instance bui lt  upmust  keep track of which const i tuents  ofthe specif ic  s i tuat ion fill which roles ofthe concepts being recognized.
Moreover,it cannot do so by simply f i l l ing in theslots of those general  concepts,  since ageneral  concept may have mult ip leinstant iat ions in many situat ions.Rather, new structures represent inginstances of those concepts must beconstructed and pair ings of const i tuentroles from the concept and role f i l lersfrom the current s i tuat ion must  beassociated with each new instance.3.
~he Process of Situation RecognitionThe process of s i tuat ion recognit ionconsists of detect ing that a set ofpart ic ipants  of certain kinds stand insome specif ied re lat ionship to each other.In general,  when some set of part ic ipantsis present at the sensory interface of thesystem (immediate input plus past memory),the task of determining whether there issome s i tuat ion descr ipt ion in memory thatwil l  account for the re lat ionships  ofthose inputs is not trivial.
If the totalnumber of s i tuat ion descr ipt ions in thesystem is suf f ic ient ly  small, all of themcan be indiv idual ly  tested against theinput to see if any are satisf ied.
If the34number of such descr ipt ions issuf f ic ient ly  large, however, this is notfeasible.Al ternat ively,  if there is somepart icular part ic ipant  that by virtue ofits type strongly suggests what s i tuat iondescr ipt ions it might part ic ipate in, thenan index from this part ic ipant  mightselect a more manageable set of s i tuat iondescr ipt ions to test.
Even in this case,however, the number of s i tuat ions in whichthe const i tuent could part ic ipate maystill be too large to test eff ic ient ly.In the most di f f icult  s ituation, no singlepart ic ipant in the input is suf f ic ient lysuggest ive by itself to constra in the setof possible patterns to a reasonablenumber.
However, it may stil l  be that thecoincidence of several const i tuents andre lat ionships may suff ice, providing thatthe coincidence can be detected.
It isthis problem of coincidence detect ion thatI bel ieve to be crucial to solving thegeneral  s i tuat ion recognit ion problem.As an example, consider the fol lowingfragment of a protocol  of a commandergiving commands to an intel l igent d isplaysystem:Cdr : Show me a display of theeastern Mediterranean.\[computer produces display\]Cdr: Focus in more on Israel andJordan.\[computer does so\]Cdr: Not that much; I want to beable to see Port Said and theIsland of Cyprus.In the first clause of the third commandof this discourse, (i.e.
"not that much"),there is no single word that is stronglysuggest ive of the interpretat ion of thesentence.
Moreover, there is nothingexpl ic i t  to suggest the re lat ionship ofthis clause to the one that fol lows thesemicolon.
The latter, if interpreted inisolation, would merely be a request for adisplay, or perhaps a succession of twodisplays, while in the context given, itis a request to modify a previous display.There are two methods that I bel ievemay be suff ic ient,  either indiv idual ly  orin combination, to model coincidencedetection.
One is the use of factoredknow!ed@e structures that merge commonparts of a l ternat ive hypotheses.
Theother involves the use of a markablec lass i f icat ion structure in which theind iv idua l "  recognit{on pred icatestr iggered by the ongoing discourse willleave traces of their having fired, sothat coincidences of such traces can beef f ic ient ly  detected.
I have beeninvest igat ing a structure which I call a"taxonomic latt ice", that combines somefeatures of both methods.3;1 Factored Knowledge StructuresGiven a knowledge-based system withlarge numbers of s i tuat ion-act ion rules,where it is infeasible to find the rulesthat match a given s i tuat ion bysystemat ica l ly  consider ing each rule, oneneeds to have some way of reducing thecomputat ional  load.
As ment ioned before,one approach is to index the rulesaccording to some sal ient feature thatwil l  be easi ly  detectable in the inputs ituat ion and can then be used to find amuch more l imited set of rules to apply.This has been done in many systems,including the LUNAR system for naturallanguage quest ion answering \[Woods, 1973,1977\].
In that system, rules forinterpret ing the meanings of sentenceswere indexed according to the verb of thesentence and rules for interpret ing nounphrases were indexed by the head noun.Although this approach reduces the numberof rules that need to be considered, ithas several l imitat ions still.
The f irstis that there may be some values of theindex key for which there are stil l  alarge number of rules to consider.
In thecase of the LUNAR system, for example, theverb "be" had a large number of rules toaccount for d i f ferent senses of the word.Another is that there can be certainconstruct ions for which there is no singleeasi ly  detected feature that is stronglyconstraining as to possible meaning.
Inthis case, there is no useful index keythat can be used to select a suf f ic ient lyconstrained set of rules to try.Another l imitat ion of this indexingapproach as the range of language becomesmore fluent is that in certain el l ipt icalsentences, the constra in ing key may beel l ipsed, and although one can have therules indexed by other keys as well, theremaining ones may not suf f ic ient lyconstrain the set of rules that need to beconsidered.
Finally, even when the set ofrules has been constrained to a re lat ive lysmall set, there is f requent ly  a good dealof sharing of common tests among di f ferentrules, and consider ing each ruleindependent ly  results in repeating thesetests separately for each rule.One approach to solving all of theabove problems is to use what I have beencal l ing a "factored knowledge structure"for the recognit ion process.
In such astructure, the common parts of d i f ferentrules are merged so that the process oftest ing them is done only once.
With suchstructures, one can ef fect ively test allof the rules in a very large set, and doso eff ic ient ly,  but never consider anysingle rule individual ly.
At each pointin a factored knowledge structure, a testis made and some information gained aboutthe input.
The result of this testdetermines the next test to be made.
Aseach test is made and addit ionalinformation accumulated, the set of35possible rules that could be sat isf ied bythe input, given the values of the testsso far made, is gradual ly  narrowed untileventual ly  only rules that actual ly matchthe input remain.
Until the end of thisdecis ion structure is reached, however,none of these rules is actual ly  consideredexpl ic it ly.
This pr inciple of factoringtogether common parts of d i f ferentpatterns to faci l i tate shared processingis the basic technique that makes ATNgrammars \[Woods, 1970\] more ef f ic ient  insome sense than ordinary phrase structuregrammars.
It has also been used by thelexical retr ieval component of the BBNspeech understanding system \[Woods et al,1976; Wolf and Woods, 1977\] and accountsfor the ef f ic iency of the finite stategrammar approach of the CMU Harpy system\[Lowerre, 1976\].
A recent innovative useof this pr inc ip le appears in Rieger's"tr igger trees" for organiz ing spontaneouscomputat ions \[Rieger, 1977\].Whether factored together or not, thetask of accessing rules is not a simpleone.
One problem is that rules don'tmatch the input letter- for - letter :  rather,they have var iables in them with var iousrestr ict ions on what they can match.
Forexample a rule might  say that whenever anaccess is made to a c lass i f ied file, thena record of the person making the requestshould be made.
The descr ipt ion,  "anaccess to a c lass i f ied file" needs to bematched against the user's request (orsome subpart of it) and in that match, thedescr ipt ion  "a c lass i f ied file" will bematched against some specif ic file name.In this kind of s i tuat ion, there is nonatural  ordering of the rules, analogousto the alphabet ical  ordering of words,that will help in f inding the rules thatare sat isf ied by the given situation.
Noris a structure as simple as the d ict ionarytree above adequate for this case.Another problem is that a givens i tuat ion may be matched by several ruless imultaneously  with di f fer ing degrees ofgeneral i ty.
For example, there may be arule that says "whenever access is made toa top secret file (more specif ic thanclassi f ied),  then check the need-to-knowstatus of the user for that informationand block access if not satisf ied".
Inthe case of a request to a top secretfile, both of the above rules must befound, while in the case of an ordinaryc lass i f ied file, only the first should.The actual input, however,  will notexpl ic i t ly  ment ion either "top-secret" or"c lassi f ied",  but will mere ly  be some filename that has many attr ibutes andpropert ies,  among which the attr ibute"classif ied" is not part icu lar ly  salient.3.2 Markable C lass i f i cat ion StructuresAnother technique that holds promisefor s i tuat ion recognit ion is the use of amarkable c lass i f icat ion structure in whichcoinc idences of re lat ive ly  non-sal ientevents can be detected.
The keystone ofthis approach is a technique that Qui l l ianproposed for model ing certain aspects ofhuman associat ive memory \[Quil l ian, 1966,1968\].
Qui l l ian's  technique of "semanticintersect ion" consisted of propagat ingtraces of "act ivation" through a semanticnetwork structure so that connect ion pathsrelat ing arbitrary concepts could bedetected.
For example, his system wasable to connect concepts such as "plant"and "nourishment" by d iscover ing the"chain" equivalent  to "plants drawnour ishment  from the soil".
If theappropr iate information were in thenetwork, this technique would also findchains of indirect connect ions such as"Plants can be food for people" and"People draw nour ishment from food."
Themethod was capable of f inding paths ofarbitrary length.The problem of f inding connect ionsbetween concepts in a knowledge network isl ike the problem of f inding a path througha maze from a source node to some goalnode.
At the lowest level, it requires atrial and error search in a space that canbe large and potent ia l ly  combinator ic .That is, if one element of the input couldbe connected to k d i f ferent  concepts,  eachof which would in turn be connected to kothers, and so on, until  f inal ly  a conceptthat connected to the goal was discovered,then the space in which one would have tosearch to find a path of length n wouldcontain k n paths.
However,  if one startedfrom both ends (assuming a branchingfactor of k also in the reversedirect ion),  one could find all the pathsof l~Dgth n/2 from either end in only2.kn/z .If one then had an ef f ic ient  way todetermine whether any of the paths fromthe source node connected with any of thepaths from the goal node, such a searchfrom both ends would have a cons iderablesavings.
This can be done quitee f f ic ient ly  if the a lgor i thm is capable ofputt ing marks in the structure of the mazeitself (or some structure isomorphic toit), so that it can tell when reaching agiven node whether a path from the sourceor the goal has already reached that node.However, without such abi l i ty to mark thenodes of the maze, the process of testingwhether a given path from the source canhook up with a path from the goal wouldinvolve a search through all the pathsfrom the goal individual ly,  and a searchdown each such path to see if the node atthe end of the source path occurredanywhere on that path.
If this werenecessary,  then all of the advantage ofsearching from both ends would be lost.36The use of the graph structure itself tohold marks is thus cr it ical  to gainingadvantage from this algorithm.Essential ly,  the nodes of the graph serveas rendezvous points where paths that arecompatible can meet each other.
Thecoincidence of a path from the sourcemeeting a path from the goal at some nodeguarantees the d iscovery of a completepath without any path requir ing more thana simple test at the corresponding node inthe graph as each link is added to thepath.What is needed for s ituat ionrecognit ion in a genera l izat ion ofQui l l ian's  semantic intersect ion techniquein which the source and goal nodes arereplaced by a potent ia l ly  large number ofconcept nodes, some of which arest imulated by immediate input, and some ofwhich are remembering recent act ivat ion inthe past.
Moreover, what is s igni f icantis not just simple paths between twonodes, but the conf luence of marks frommult ip le  sources in predeterminedpatterns.
Moreover, unlike Qui l l ian, whoconsidered all connect ions ident ical ly insearching for paths, we will considermarker passing strategies in which markscan be passed select ively along certainlinks.
Recently, Fahlman \[1977\] haspresented some interest ing formal machinespeci f icat ions of Qui l l ian-type spreadingact ivat ion processes which have thischaracter ist ic .4.
The Structure of ConceptsIn bui lding up internal descr ipt ionsof situations, one needs to make use ofconcepts of objects, substances, times,places, events, condit ions,  predicates,functions, individuals, etc.
Each suchinternal concept wil l  itself have astructure and can be represented as aconf igurat ion of attr ibutes or parts,sat isfying certain restr ict ions andstanding in specif ied re lat ionships toeach other.
Brachman \[1978\] has developeda set of ep is temolog ica l ly  expl ic i tconventions for represent ing such conceptsin a "Structured Inheritance Network", inwhich interre lat ionships of various partsof concepts to each other and to moregeneral and more specif ic concepts areexpl ic i t ly  represented.
The essentialcharacter ist ic  of these networks is theirabi l i ty to represent descr ipt ions ofstructured objects of var ious degrees ofgenera l i ty  with expl ic i t  representat ion ofthe inheritance re lat ionships betweencorresponding const i tuents of thosestructures.
A concept node in Brachman'sformulat ion consists of a set of dattrs (agenera l izat ion of the notions ofattr ibute, part, const ituent,  feature,etc.)
and a set of structuralre lat ionships among them.
Some of thesedattrs are represented direct ly  at a givennode, and others are inherited indirect lyfrom other nodes in the network to whichthey are related.Let us assume that each concept thatthe system understands is represented as anode in one of these structuredinheritance networks.
The network, as awhole, then serves as a conceptualtaxonomy of all possible "entit ies" thatthe system can perceive or understand.Each node in this taxonomy can be thoughtof as a micro schema for the recognit ionof instances of that concept.
Each has aset of dattrs with individual restr ict ionsand a set of structural  condit ions thatrelate the dattrs to one another.
Theserestr ict ions and structural  condit ions maythemselves be defined in terms of otherconcepts defined by other micro schemata,and so on until a level of pr imit ive lydefined, direct ly perceivable concepts isreached.Each concept in the taxonomy can bethought of as having a level ofabstractness def ined as the maximum depthof nesting of its const i tuent  structure.Instances of pr imit ive ly  def ined conceptshave level 0, conste l lat ions of thoseconcepts have level i, a concept havinglevel 1 and lower concepts as dattrs haslevel 2,, and so on.
If a taxonomycontained only level 0 and level 1concepts, then the s i tuat ion recognit ionproblem would be great ly simpli f ied, sinceone never needs to recognize port ions ofthe input as ent it ies that part ic ipate asconst i tuents of larger entit ies.
Thegeneral problem, however, requires us todo exact ly that.
More seriously, thegeneral case requires us to recognize aconcept some of whose dattrs may haverestr ict ions def ined in terms of theconcept itself.
This is true, forexample, for the concept of noun phrase ina taxonomy of syntact ic construct ions.Such recursively def ined concepts have nomaximum level of abstractness,  althoughany given instance will only involve af inite number of levels of recursion.This potential  for recursive def in i t ionmust be kept in mind when formulat ingalgor ithms for s i tuat ion recognit ion.5.
The Need for Inher i tance StructuresAS a result of having di f ferentlevels of abstract ion in one's taxonomy,an input s ituat ion will often sat isfyseveral situation, descr ipt ionss imultaneously,  no one of which willaccount for all of the input nor supplantthe relevance of the others.
For example,adding a ship to a d isplay iss imultaneously an example of changing ad isplay and of d isplaying a ship.
Advicefor both act ivit ies must be considered.Moreover,  a single descr ipt ion may haveseveral d i f ferent instant iat ions in thecurrent situation, with s i tuat iondescr ipt ions becoming arbi t rar i ly  complex37by the addit ion of var ious qual i f iers,  bythe conjunct ion and d is junct ion ofdescr ipt ions,  etc.
For example, one mightwant to store advice associated with thes i tuat ion \[wanting to d isplay a large shipat a locat ion on the screen that is withinone unit distance from either the top,bottom, or side of the screen when thescale of the d isp lay is greater than1:1000\].
Finally, s i tuat ion descr ipt ionsmay subsume other descr ipt ions at lowerlevels of detail ,  and advice from both maybe relevant and may either supplement orcontradict  each other.
For example,d isp laying an aircraft  carrier is aspecial case of d isplaying a ship, andthere may be specif ic  advice associatedwith d isplaying carr iers as well as moregeneral  advice for d isplaying any ship.Thus, convent ions wil l  be required todetermine which advice takes precedenceover the other if conf l icts arise.The organizat ion of large numbers ofsuch s i tuat ion descr ipt ions of varyingdegrees of genera l i ty  so that alldescr ipt ions more general  or more specif icthan a given one can ef f ic ient ly  be foundis one thing we require of an intel l igentcomputer assistant.
In order to bui ld andmainta in  such a structure, it is importantto store each rule at the appropr iatelevel of general i ty,  relying on amechanism whereby more specif ic s i tuat ionsautomat ica l ly  inherit  information frommore general  ones.
That is, when onewants to create a s i tuat ion descr ipt ionthat is more specif ic than a given one insome dimension, one does not want to haveto copy all of the attr ibutes of thegeneral  situation, but only those that arechanged.
Aside from conserving memorystorage, avoiding such copying alsofac i l i tates updating and mainta in ing theconsistency of the data base by avoidingthe creat ion of dupl icate copies ofinformation that then may need to beindependent ly  modif ied and couldacc identa l ly  be modif ied inconsistent ly.For example, one may want to storeadvice about d isplaying geographicalfeatures, about d isp laying such featuresthat cover an area, about d isplayingbodies of water, about d isplaying lakes,etc.
Thus, information about f inding thearea covered by a feature would be storedat the level of deal ing with sucharea-cover ing features, information aboutdisplaying water in a certain color wouldbe stored at the level of d isp layingbodies of  water, and information abouthaving inlets and outlets would be storedat the level of lakes.
In any specif ics i tuat ion that the system finds itself,many such concepts at d i f ferent  levels ofgenera l i ty  wil l  be satisf ied, and theadvice associated with all of them becomesappl icable.
That is, any more specif icconcept, including that of the currents ituation, inherits a great deal ofinformation that is expl ic i t ly  stored athigher levels in the taxonomy.In the case of the s i tuat iondescr ipt ions that we are deal ing with,even the speci f icat ion of what dattrs ag iven concept possesses is stored at themost general  level and inherited by morespecif ic concepts.
Thus, for example, thedescr ipt ions of attr ibute dattrs for colorand weight are stored for a generalconcept of physical  object.
These dattrsare then inherited by any more specif icconcepts of physical  objects, such asplanes, ships, desks, and penci ls.6.
~e  Taxonomic  Latt iceI bel ieve that a general  solut ion tothe s i tuat ion recognit ion problem can beobtained by the use of a c lass i f i cat ionstructure in which traces of individuale lements of complex concepts can intersectto faci l i tate the d iscovery  ofco inc idences and connect ions that may notbe strongly inferable from constra in ingexpectat ions.
The structure that Ipropose to use is a vers ion of Brachman'sstructured inheritance networks, in whichdescr ipt ions of all potent ia l ly  relevants i tuat ions are stored with expl ic i tindicat ions of general  subsumption of ones i tuat ion by another, and expl ic i tindicat ions of the inheritance of dattrsand of advice by one concept from another.This structure, which I have cal led ataxonomic latt ice, is character ized by amult~t6de of s i tuat ion descr ipt ions atd i f ferent  levels of general i ty.We say that a s i tuat ion descr ipt ionSl subsumes a descr ipt ion $2 if anys i tuat ion sat isfying $2 wil l  also satisfySI.
In this case, S1 is a more generaldescr ipt ion than $2, and is placed higherin the taxonomy.
For example, \[displayinga port ion of country\] is a more specif ics i tuat ion than \[displaying a geographicalarea\], which is in turn more speci f ic  than\[displaying a d isp layable entity\].
All ofthese are subsumed by a general  concept\[purposive activity\] ,  which in turn ismore specif ic  than \[activity\].
Moreover,a given descr ipt ion can subsume manyincomparable descr ipt ions and can itselfbe subsumed by many incomparabledescr ipt ions.
For example, an instance of\[displaying a geographical  area\] is alsoan instance of \[accessing a geographicalarea\], \[displaying information\] ,  and\[using the display\[,  and may poss ib ly  alsobe an instance of \[responding to a usercommand\].The space of possib le s i tuat iondescr ipt ions forms a latt ice under therelat ion of subsumption.
At the top ofthe latt ice is a single, most generals i tuat ion we will call T, which is alwayssat isf ied and can be thought of as thed is junct ion of all poss ib le  s ituat ions.Anything that is universal ly  true can bestored here.
Conversely,  at the bottom ofthe latt ice is a s i tuat ion that is never38satisf ied, which we call NIL.
It can bethought of as the conjunct ion of allpossible (including inconsistent)situations.
Assert ions of negativeexistence can be stored here.At the "middle" level of the latt iceare a set of pr imit ive percept ib lepredicates -- descr ipt ions whose truth inthe world are d i rect ly  measurable by the"sense organs" of the system.
All c lassesabove this level are constructed by someform of genera l izat ion operation, and allc lasses below are formed by some form ofspecial izat ion.
At some pointsuf f ic ient ly  low in the lattice, one canbegin to form inconsistent descr ipt ions bythe conjunct ion of incompatible concepts,the imposit ion of impossible restr ict ions,etc.
There is nothing to prevent suchconcepts from being formed; indeed, it isnecessary in order for the organism tocontemplate, store, and remember theirinconsistency.There are a number of specif icrelat ionships that can cause one s i tuat iondescr ipt ion to subsume another.
A givensituat ion descr ipt ion can be made moregeneral  by relaxing a condit ion on adattr, by el iminat ing the requirement fora dattr, by relaxing the constraints ofits structural descr ipt ion,  or byexpl ic i t ly  dis jo ining it (or'ing it) withanother descript ion.
A given descr ipt ioncan be made more specif ic by t ighteningthe condit ions on a dattr, by adding adattr, by t ightening the constraints ofits structural descr ipt ion,  or byexpl ic i t ly  conjoining (and'ing) it withanother descript ion.
These operat ionsapplied to any finite set of s i tuat iondescr ipt ions induce a latt ice structure ofpossible s i tuat ion descr ipt ions that canbe formed by combinat ions of the elementsof the initial set.
We refer to thisstructure as the virtual latt ice inducedby a given set of s i tuat ion descr ipt ions.Note that only a f inite port ion of thislatt ice need be stored with expl ic i tconnect ions from more specif ic to moregeneral concepts.
By processing thisexpl ic i t  lattice, one can test any givendescr ipt ion for membership in the virtuallatt ice and assimi late any new situat iondescr ipt ion into the expl ic i t  latt ice inthe appropriate place corresponding to itsposit ion in the virtual lattice.In operation, any s i tuat iondescr ipt ion about which information isexpl ic i t ly  stored will be entered into theexpl ic i t  lattice.
Any s i tuat ion that themachine can understand is in some sensealready in the virtual latt ice and needsonly be "looked up" in it.
One task wehave set for ourselves to developef f ic ient  a lgor i thms to tell whether agiven situation can be understood in termsof the concepts of the latt ice and if so,to construct its corresponding descr ipt ionand expl ic i t ly  record its relat ions toother concepts in the expl ic i t  lattice.7.
An ExampleAs an example of the s i tuat ionrecognit ion process using markerpropagat ion in a taxonomic lattice, let usconsider a simple case of interpret ing theintent of a simple English sentence.
Theexample chosen is not complex enough torequire all of the machinery  discussed,but is presented here to i l lustrate themechanism.
The major features of thes i tuat ion recognit ion mechanism onlybecome crit ical in interpret ing commandsthat require several sentences to bui ldup, or which depend on the current contextin complex ways, but such s ituat ions ared i f f icu l t  to i l lustrate.For our example, suppose that thesystem contained a concept for requests todisplay a geographical  region, and theuser's input request were "Show me theeastern end of the Mediterranean."
Theconcept \[request\] contains dattrs for therequestor, the requestee, a descr ipt ion ofthe state that the requestor desires, aform of request (demand, order, pol i terequest, expression of preference, etc.
),and perhaps others.
Requests can takemany forms.
Assume that we have stored inthe system a rule that s@ys "Any sentenceof the form: 'show me NP' is a request todisplay that NP."
This rule could bestored in the latt ice as a piece of adviceassociated with the concept "A sentence ofthe form: 'show me NP'," in such a waythat when a sentence of the indicated formwas found, an instance of a d isp layrequest would be created.
At that point,this result ing display request would beplaced in the latt ice in such a way thatall more general concepts of which it isan instance would be activated, and inpart icular ,  the concept of a request todisplay a geographical  region would beactivated.The pars ing of the original sentencecan either be done by an ATN grammar, orby a version of the taxonomic latt iceitself (one that character izes a taxonomyof sentence types).
Let us assume herethat it is done by an ATN grammar that isc losely coupled to a taxonomic lattice,with the ATN represent ing the syntact icinformation about sentence form and thetaxonomic latt ice represent ing generalsemantic information.
As the ATN grammarpicks up const i tuents of the sentence, itreaches states where it makes hypothesesabout the syntact ic roles that thoseconst i tuents play in the sentence (e.g.
"this is the subject", "this is the verb",etc.).
Such hypotheses are then enteredinto the lattice, where they begin toact ivate the recognit ion condit ions ofconcepts in the network.
For example, inthe taxonomic latt ice there is a conceptof an imperative sentence whose subject isthe system, whose verb is "show", whoseindirect object is the user and whosedirect object is a d isplayable object.39As the parsing proceeds, the ATN willmake assert ions about the sentence it isbui ld ing up, and it wil l  not only bebui ld ing up syntactic representat ions ofconst i tuents of the sentence, but willalso be bui ld ing up representat ions ofpossib le meanings of those const i tuents.In part icular,  it wil l be bui ld ing up al ist of those concepts in the latt ice ofwhich the current const i tuent  may be arestr ict ion or instance and a l ist of thedattr -value pair ings that have been foundso far.
If a parse path succeeds (i.e.reaches a POP arc), then a node in thetaxonomic latt ice corresponding to thathypothesis  will be found or constructed.This node will have l inks to more generaland more specif ic  concepts, and will haveits const i tuents l inked to appropr iatedattrs of those concepts.
At the pointwhen this concept node isfound/constructed,  a process of act ivat ionspreading wil l  be launched in the latt iceto find any advice that may be inheritedby that concept.
This process will alsoleave "footprints" in the latt ice thatwil l  faci l i tate the detect ion of conceptsof which the current one may itself be adattr (or part of a structural  condit ion).In the example above, when the parserhas parsed the init ial port ion of thesentence "show me", it has bui l t  up in itsinternal registers the informationcorresponding to the hypothes is  that thesentence is an imperative, with subject"you" and indirect object "me".
Moreover,it knows that (in input sentences) "you"refers to the system itself, whi le "me"refers to the speaker.
It also knows thatthe main verb is the verb "show".
Let ussuppose that at this point, the parserdecides to act ivate the correspondingtaxonomic latt ice nodes for the concepts\[the system\], \[the user\], and \[the verbshow\] (possibly with pointers to thesyntact ic hypothesis  being constructedand/or the labels SUBJECT, OBJECT, VERB,respect ively) .
Ignoring for now whateverinformation or advice may be foundassociated with these concepts or theirgenera l izat ions,  the footpr ints that theyleave in the network will intersect at anode \[display request\] which has dattrsfor requestor, requestee, form of request,and requested thing.
They also intersectat other concepts such as \[ imperativesentence\],  \[active sentence\],  \[action\],and a more specif ic kind of d isplayrequest \[region display request\],  whoserequested thing is a geographical  region.This latter concept was created andinserted into the latt ice precisely tohold advice about how to d isp laygeographical  regions, and to serve as amonitor for the occurrence of suchsituations.
Fig.
1 is a fragment of ataxonomic latt ice showing the concepts ofinterest.
(For detai ls  of the notation,see Brachman \[1978\], Woods and Brachman\[1978\].
)When the final noun phrase has beenparsed and given an interpretat ion,  thefootpr ints that its act ivat ion leaves inthe network will awaken the \[regiondisplay request\] node, which will then beful ly satisf ied, and the parser willcreate a corresponding instance node, withappropr iate bindings for its dattrs.
Inprocess ing the noun phrase, the parserwil l  discover the adject ive "eastern" andthe noun "Mediterranean" and wil l  act ivatethe corresponding nodes in the taxonomiclatt ice.
The concept \[east\] is aninstance of \[direction\],  which, amongother things, is the restr ict ion for adattr of a concept \ [d irect ional lydetermined subregion\] that def ines themeaning of such concepts as "north easternIdaho".
Another dattr of this sameconcept has the restr ict ion \[geographicalregion\],  which is on the superc chain fromMediterranean.
Hence, footpr ints from"eastern" and "Mediterranean" wil lintersect at the concept \ [d irect ional lydetermined subregion\],  causing an instanceof that concept to be constructed as apossib le meaning of the noun phrase.
The\ [direct ional ly determined subregion\]concept itself has a superc connect ion to\[geographical  region\], which happens to bethe restr ict ion for the "requested thing"dattr of the concept \[region d isp layrequest\] which has a l ready received marksfor its other dattrs.
Thus, theintersect ion of footpr ints from thevar ious const i tuents of the sentence atthis concept node has served to selectthis node out of all the other nodes inthe network.
Since the more generalconcept \[display request\] is on a supercchain from \[region d isp lay request\],  itwil l  also be activated, and advice fromboth places wil l  be considered.8.
Conc lus ionIn s i tuat ion recognit ion,  the nodesof a taxonomic latt ice structure serve asrendezvous points where footpr ints fromvar ious const i tuent  elements of a conceptcan meet.
This fac i l i tates the detect ionof co inc idences of related events, whichin many cases wil l  not be suggest ive inisolation.
The implementat ion of thekinds of operat ions descr ibed aboveinvolves a system of marker passingconvent ions for propagat ing the various"footprints" around the network, detect ingcoinc idences,  creat ing instance nodes, andpropagat ing further markers whenco inc idences are found.
A major port ionof our current  research involves thed iscovery  of ef fect ive convent ions forsuch marker passing operat ions.
Otherissues include working out convent ions forhow far markers  should propagate(amounting to decis ions as to where torendezvous),  deciding how much informationa mark carr ies with it and to what extentmarks are inherited, developing ways toal low a node to remember part ial40intersections of marks in such a way thatit can incrementally extend them asadditional marks accumulate, identifyingimplications of the marker passingstrategies on representationalconventions, etc.9.
ReferencesBrachman, R.J. (1978)"A Structural Paradigm for RepresentingKnowledge," Technical Report No.
3605,Bolt Beranek and Newman Inc., Cambridge,MA.Fahlman, S.E.
(1977)"A System for Representing and Using 'Real-World Knowledge," Ph.D. dissertation,Dept.
of Electrical Engineering andComputer Science, M.I.T.Lowerre, B.T.
(1976)"The HARPY Speech Recognition System,"Technical Report, Department of ComputerScience, Carnegie-Mellon university,Pittsburgh, Pa.Quillian, M.R.
(1966)"Semantic Memory,"No.
AFCRL-66-189, Bolt Beranek andInc., Cambridge, Ma.ReportNewmanQuillian, M.R.
(1968)"Semantic Memory," in Semantic InformationProcessinq (M. Minsky, ed.).
Cambridge,Ma:M.I.T.
Press., pp.
27-70.Rieger, C. (1977)"Spontaneous Computation in CognitiveModels," Cognitive Science I, No.
3,pp.
315-354.Wolf, J.J. and W.A.
Woods (1977)"The HWIM Speech Understanding System,"Conference Record, IEEE InternationalConference o n_n Acoustics, Spe@ch L an ~Signal Processing, Har?ford, Conn., May.Woods, W.A (1970)"Transition Network Grammars for NaturalLanguage Analysis," CACM, Vol.
13, No.
10,October (reprints available).Woods, W.A.
(1973)"Progress in Natural LanguageUnderstanding: An Application to LunarGeology," AFIPS Conference Proceedinq,Vol.
42, 1973 National Computer Conferenceand Exposition (reprints available).Woods, W.A., M. Bates, G. Brown, B. Bruce,C.
Cook, J. Klovstad, J. Makhoul,B.
Nash-Webber, R. Schwartz, J. Wolf,V.
Zue (1976)Speech Understanding Systems - FinalReport, 30 October 1974 to 29 October1976, BBN Report No.
3438, Vols.
I-V, BoltBeranek and Newman Inc., Cambridge, Ma.Woods, W.A.
(1977)"Semantics and Quantification in NaturalLanguage Question Answering," to appear inAdvances in Computers, Vol.
17, New York:Academic Press.
(Also Report No.
3687,Bolt Beranek and Newman Inc., 1977).Woods, W.A.
and R.J. Brachman (1978)"Research in Natural LanguageUnderstanding" - Quarterly TechnicalProgress Report No.
1 (BBN ReportNo.
3742), Bolt Beranek and Newman Inc.,Cambridge, MAFig.
141
