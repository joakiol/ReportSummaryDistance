Continuous Speech Recognition UsingSegmental Neural NetsS.
Austin'l', J. Makhoult, R. Schwartzi', and G. ZavaliagkostBBN Systems and Technologies, Cambridge, MA 02138,Northeastern U iversity, Boston, MA 02115ABSTRACTWe present he concept of a "Segmental NeuralNet" (SNN) for phonetic modeling in continuousspeech recognition.
The SNN takes as input allthe frames of a phonetic segment and gives asoutput an estimate of the probability of each ofthe phonemes, given the input segment.
By tak-ing into account all the frames of a phonetic seg-ment simultaneously, the SNN overcomes the well-known conditional-independence limitation of hid-den Markov models (HMM).
However, the prob-lem of automatic segmentation with neural nets isa formidable computing task compared to HMMs.Therefore, to take advantage of the training anddecoding speed of HMMs, we have developed anovel hybrid SNN/HMM system that combines theadvantages ofboth types of approaches.
In this hy-brid system, use is made of the N-best paradigmto generate likely phonetic segmentations, whichare then scored by the SNN.
The HMM and SNNscores are then combined to optimize performance.In this manner, the recognition accuracy is guaran-teed to be no worse than the HMM system alone.1 IntroductionThe current state of the art in continuous peechrecognition (CSR) is based on the use of HMMsto model phonemes in context.
Two main rea-sons for the popularity of HMMs is their high per-formance, in terms of recognition accuracy, andtheir computational efficiency (after initial signalprocessing, real-time recognition is possible on aSun 4 \[1\]).
However, the limitations of HMMsin modeling the speech signal have been knownfor some time.
Two such limitations are (a) theconditional-independence assumption, which pre-vents a HMM from taking full advantage of thecorrelation that exists among the frames of a pho-netic segment, and (b) the awkwardness with whichsegmental features (such as duration) can be incor-porated into HMM systems.
We have developedthe concept of Segmental Neural Nets (SNN) toovercome the two HMM limitations just mentionedfor phonetic modeling in speech.
However, neu-ral nets are known to require a large amount ofcomputation, especially for training.
Also, there isno known efficient search technique for finding thebest scoring segmentation with neural nets in con-tinuous speech.
Therefore, we have developed ahybrid SNN/HMM system that is designed to takefull advantage of the good properties of both meth-ods: the phonetic modeling properties of SNNs andthe good computational properties of HMMs.
Thetwo methods are integrated through a novel use ofthe N-best paradigm developed in conjunction withthe BYBLOS system at BBN.2 Segmental Neural Net Struc-tureThere have been several recent approaches to theuse of neural nets in CSR.
The SNN differs fxomthese approaches in that it attempts to recognizeeach phoneme by using all the frames in a phoneticsegment simultaneously toperform the recognition.In fact, we define a SNN as a neural network thattakes the frames of a phonetic segment as inputand produces as output an estimate of the probabil-ity of a phoneme given the input segment.
But theSNN requires the availability of some form of pho-netic segmentation f the speech.
To consider allpossible segmentations of the input speech wouldbe computationally prohibitive.
We describe in thenext section how we use the HMM to obtain likelycandidate segmentations.
Here, we shall assumethat a phonetic segmentation has been made avail-able.249phonetic segment !Figure 1: The Segmental Neural Network modelsamples the frames in a segment and produces asingle segment score.The structure of a typical SNN is shown in Fig-ure 1.
The input to the net is a fixed number offrames of speech features (5 frames in our system).The features in each 10-ms frame currently include14 mel-warped cepstral coefficients, cepstral dif-ferences in time, power, and power difference.
Butthe actual number of such frames in a phonetic seg-ment is variable.
Therefore, we convert he vari-able number of frames in each segment to a fixednumber of frames (in this case, five frames).
Inthis way, the SNN is able to deal effectively withvariable-length segments incontinuous speech.
Therequisite time warping is performed by a quasi-linear sampling of the feature vectors comprisingthe segment.
For example, in a 17-frame phoneticsegment, we would use frames 1, 5, 9, 13, and17, as input to the SNN.
In a 3-frame segment, hefive frames used are 1, 1, 2, 3, 3, with a repeti-tion of the first and third frames.
In this sampling,we are using a result from stochastic segment mod-els (SSM) in which it was found that sampling ofnaturally-occurring frames gives better esults thanstrict linear interpolation \[5\].Far from discarding duration information, whichis implied in the warping to fixed length, the du-ration of the original segments can be handed tothe neural net as just another feature that can beweighted according to its significance for recogni-tion.Therefore, by looking at a whole phonetic seg-ment at once, we are able to take advantage of thecorrelation that exists among frames of a phoneticsegment, and by making explicit use of duration asanother feature, we are able to fully utilize dura-tion information, thus ameliorating both limitationsof HMMs.
These properties of the SNN are alsoshared by the SSM, which was originally developedat BBN \[5\].
The main difference between the twois in how the probability of a segment is computed.In the SSM, an explicit multi-dimensional proba-bility model has to be used (usually Gaussian) withmany simplifying assumptions, o as to reduce thelarge amount of computation for training and recog-nition that would be needed in a model that has acomplete covariance matrix.
In contrast, the SNNhas been shown to be capable of implicitly generat-ing an estimate of the posterior probability withoutthe need for an explicit model\[2, 3\].
In this way,we believe that the neural net will use as muchcorrelation among frames as is needed to enhanceperformance.In our initial experiments, we are using a singleSNN with 53 outputs, each representing one of thephonemes in our system.
The SNN outputs aretrained with a 1 for the correct phoneme and a 0for all the others.3 Integration of Algorithms Us-ing the N.Best ParadigmIn continuous peech recognition, many systemsproduce as output a single transcription that bestmatches the input speech, given some grammar.Because of imperfections in the recognition, theoutput may not be the correct sentence that wasuttered and anything using this output (such as anatural language part of a speech understandingsystem) will be in error.
One way to avoid thisis to use a search that produces not only the singlebest-matching sentence but also the N-best match-ing sentences \[6\], where N is taken to be largeenough to include the correct sentence most of thetime (N is usually anywhere between 20 and 100in our system, depending on the perplexity of thetask; a higher N is needed for higher perplexity).The list of N sentences i  ordered by overall score inmatching the input utterance.
For integration withnatural language, we send the list of N sentences tothe natural anguage component, which processes250the sentences in the order given and chooses thefirst sentence that can be understood by the system.In the hybrid SNN/HMM system, we use thisN-best paradigm differently.
A spoken utteranceis processed by the HMM recognizer to produce alist of the N best-scoring sentence hypotheses.
Thelength of this list is chosen to be long enough toinclude the correct answer almost always.
There-after the recognition task is reduced to selectingthe best hypothesis from the N-best list.
As men-tioned above, this list is usually between 20 and100, which means that the search space of possibleword theories is reduced from a huge number (fora 1000 word vocabulary, even a two word utter-ante has a million possible word hypotheses) to arelatively very small number.
This means that eachof the N hypotheses can be examined and scoredusing algorithms which would have been computa-tionally impossible with a combinatorially large setof hypotheses.
In addition, it is possible to generateseveral types of scoring for each hypothesis.
Thisnot only provides avery effective way of comparingthe effectiveness of different speech models (e.g.,SNN versus HMM), but it also provides an easyway to combine several radically different models.The most obvious way in which the SNN coulduse the N-best list would be to derive a SNN scorefor each hypothesis in the N-best list and then re-order this list on the basis of these scores.
The pro-posed answer would be the hypothesis with the bestSNN score.
However, it is possible to generate sev-eral scores for each hypothesis, uch as SNN score,HMM score, g r~mar  score, and the hypothesizednumber of words.
We can then generate a compos-ite score by, for example, taking a linear combina-tion of the individual scores.
It is also possible tochoose the weights for this linear combination byautomatically searching for the combination whichminimizes a measure of the rank of the correct hy-potheses over a training corpus \[4\].4 Hybrid SNN/HMM System Us-ing N-BestAs mentioned above, recognition in the hybridSNN/HMM system is performed by using the SNNscores together with HMM and other scores to re-order the N-best list of likely hypotheses for theutterance.
The process is shown schematically inFigure 2.
A constrained HMM recognition is per-formed for each of the N-best hypotheses in turn.This provides both the HMM version of the acous-tic score and the segmentation f the utterance forspeechv~ N-bent listHMM reecoring ~eegm?ntntionland ~ renScN?NringI '""" IHMM scores .~ SNN e?oresand reorder listFigure 2: Schematic diagram of the N-best rescor-ing system using the SNN score.each of the N hypotheses.
Of course, only one ofthese hypotheses can be correct, but this is not aproblem since a bad segmentation for the incorrecthypothesis will lead to a correspondingly poor SNNscore.
This means that the incorrect hypothesis willnot only be penalized because of a bad acousticmatch, but it will also be penalized because of amalformed segmentation.The SNN uses the segmentation a d phonetic se-quence produced by the HMM under each hypoth-esis to construct feature vectors from each segmentin the same way as in the Waining procedure.
Theneural net produces a score between 0 and 1 foreach segment, which gives an estimate of the prob-ability that the segment actually corresponds to thehypothesized phoneme.
The logarithm of all thesesegment scores are computed and added together toproduce a SNN score for the particular hypothesis.For each hypothesis, a total score is then com-puted by taking a linear combination of the SNNscore, HMM score, and other scores computedsolely from the text of the hypothesis (e.g., gram-mar score, number of words).
The weights for thelinear combination are found by training on a de-velopment corpus that is different from the trainingcorpus used to train both the HMM and SNN.
Adifferent corpus is used since the acoustic scores251generated from training data will be unrealisticallyoptimistic.It is important to note that, because of the useof weighting to optimize peformance in this hy-brid system, overall recognition accuracy can neverbe worse than with the HMM system alone.
Howmuch better the hybrid system will be depends onhow well the SNN performs and how different arethe errors made by the HMM and SNN systemsalone.5 ResultsIn our initial experiments, we used a version ofthe BYBLOS HMM system with non-crossword,context-dependent triphones, to compute the N-bestsentence hypotheses.
N was set to 20 in our experi-ments.
We used a single context-independent SNNwith 53 outputs.
The neural net had only a sin-gle layer.
The training and test data were obtainedfrom the DARPA Resource Management speaker-dependent corpus, which consisted of data from 12male and female speakers.
In order to provide arealistic framework for the recognition, a statisticalclass grammar with perplexity 100 was used.Under these conditions, the HMM system alonegave a word error rate of 9.1%, the SNN systemalone gave a word error rate of 20.3%, and thehybrid SNN/HMM system gave a word error rateof 8.5%.
The small reduction in error rate in thehybrid system over the HMM system is quite rea-sonable, considering the relatively large error rateof the SNN system alone.
The poor performanceof the SNN system was expected because the SNNwas really primitive, both in terms of structure andthe fact that it was context-independent.
We expectthat, as we enhance the structure of the SNN andmake it context dependent, the performance of theSNN will improve and so will that of the hybridsystem.6 Conclusions and Further WorkThe ultimate purpose of investigating new speechrecognition algorithms is to improve on the per-forrnance of existing algorithms.
Our hybridSNN/HMM system has the advantage that its per-formance cannot be inferior to that of the corre-sponding HMM system alone.
The neural networkin this initial version of the SNN is a very simplemodel.
It uses a one-layer neural net modellingcontext-independent phonemes.
Even so, it pro-duces a slight increase in accuracy over the context-dependent HMMs.
Future developments of theSNN system will include the modelling of context-dependent phoneme segments, will use more soph-icsticated neural networks, and will add additionalfeatures in order to model phoneme segments moreclosely.AcknowledgmentsThe authors would like to thank Amro EI-Jaroudi ofthe University of Pittsburgh for his help in runningsome of the experiments.
This work was sponsoredby DARPA.References\[1\] Austin, S., Peterson, P., Placeway, P.,Schwartz, R., Vandegrift, J., "Towards aReal-Time Spoken Language System UsingCommercial Hardware," Proceedings of theDARPA Speech and Natural Language Work-shop, Hidden Valley, PA, June 1990.\[2\] EI-Jaroudi, A. and Makhoul, J., "A New ErrorCriterion for Posterior Probability Estimationwith Neural Nets," International Joint Con-ference on Neural Networks, San Diego, CA,June 1990, Vol III, pp.
185-192.\[3\] Gish, H., "A Probabilistic Approach to theUnderstanding and Training of Neural Net-work Classifiers," ICASSP-90, April 1990,Albuquerque, NM, pp.
1361-1368.\[4\] Ostendorf, M., Kannan, A., Austin, S., Kim-ball, O., Schwartz, R., Rohlicek, J.R., "In-tegration of Diverse Recognition Methodolo-gies Through Reevaluation of N-Best Sen-tence Hypotheses," Proceedings of the DARPASpeech and Natural Language Workshop, Pa-cific Grove, CA, February 1991.\[5\] Ostendorf, M. and Roukos S., "A StochasticSegment Model for Phoneme-based Continu-ous Speech Recognition," IEEE Trans.
Acous-tic Speech and Signal Processing, Vol.
ASSP-37(12), pp.
1857-1869, December 1989.\[6\] Schwartz, R. and Y.L.
Chow (1990) "The N-Best Algorithm: An Efficient and Exact Pro-cedure for Finding the N Most Likely Sen-tence Hypotheses," ICASSP-90, April 1990,Albuquerque, NM, pp.
81-84.
Also in Pro-ceedings of the DARPA Speech and NaturalLanguage Workshop, Cape Cod, MA, Oct.1989.252
