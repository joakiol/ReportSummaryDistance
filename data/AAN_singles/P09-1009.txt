Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 73?81,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPUnsupervised Multilingual Grammar InductionBenjamin Snyder, Tahira Naseem, and Regina BarzilayComputer Science and Artificial Intelligence LaboratoryMassachusetts Institute of Technology{bsnyder, tahira, regina}@csail.mit.eduAbstractWe investigate the task of unsupervisedconstituency parsing from bilingual par-allel corpora.
Our goal is to use bilin-gual cues to learn improved parsing mod-els for each language and to evaluate thesemodels on held-out monolingual test data.We formulate a generative Bayesian modelwhich seeks to explain the observed par-allel data through a combination of bilin-gual and monolingual parameters.
To thisend, we adapt a formalism known as un-ordered tree alignment to our probabilisticsetting.
Using this formalism, our modelloosely binds parallel trees while allow-ing language-specific syntactic structure.We perform inference under this model us-ing Markov Chain Monte Carlo and dy-namic programming.
Applying this modelto three parallel corpora (Korean-English,Urdu-English, and Chinese-English) wefind substantial performance gains overthe CCM model, a strong monolingualbaseline.
On average, across a variety oftesting scenarios, our model achieves an8.8 absolute gain in F-measure.
11 IntroductionIn this paper we investigate the task of unsuper-vised constituency parsing when bilingual paral-lel text is available.
Our goal is to improve pars-ing performance on monolingual test data for eachlanguage by using unsupervised bilingual cues attraining time.
Multilingual learning has been suc-cessful for other linguistic induction tasks such aslexicon acquisition, morphological segmentation,and part-of-speech tagging (Genzel, 2005; Snyderand Barzilay, 2008; Snyder et al, 2008; Snyder1Code and the outputs of our experiments are available athttp://groups.csail.mit.edu/rbg/code/multiling induction.et al, 2009).
We focus here on the unsupervisedinduction of unlabeled constituency brackets.
Thistask has been extensively studied in a monolingualsetting and has proven to be difficult (Charniakand Carroll, 1992; Klein and Manning, 2002).The key premise of our approach is that am-biguous syntactic structures in one language maycorrespond to less uncertain structures in the otherlanguage.
For instance, the English sentence Isaw [the student [from MIT]] exhibits the classicproblem of PP-attachment ambiguity.
However,its Urdu translation, literally glossed as I [[MIT of ]student] saw, uses a genitive phrase that may onlybe attached to the adjacent noun phrase.
Know-ing the correspondence between these sentencesshould help us resolve the English ambiguity.One of the main challenges of unsupervisedmultilingual learning is to exploit cross-lingualpatterns discovered in data, while still allowinga wide range of language-specific idiosyncrasies.To this end, we adapt a formalism known as un-ordered tree alignment (Jiang et al, 1995) toa probabilistic setting.
Under this formalism,any two trees can be embedded in an alignmenttree.
This alignment tree allows arbitrary partsof the two trees to diverge in structure, permittinglanguage-specific grammatical structure to be pre-served.
Additionally, a computational advantageof this formalism is that the marginalized probabil-ity over all possible alignments for any two treescan be efficiently computed with a dynamic pro-gram in linear time.We formulate a generative Bayesian modelwhich seeks to explain the observed parallel datathrough a combination of bilingual and mono-lingual parameters.
Our model views each pairof sentences as having been generated as fol-lows: First an alignment tree is drawn.
Eachnode in this alignment tree contains either a soli-tary monolingual constituent or a pair of coupledbilingual constituents.
For each solitary mono-73lingual constituent, a sequence of part-of-speechtags is drawn from a language-specific distribu-tion.
For each pair of coupled bilingual con-stituents, a pair of part-of-speech sequences aredrawn jointly from a cross-lingual distribution.Word-level alignments are then drawn based onthe tree alignment.
Finally, parallel sentences areassembled from these generated part-of-speech se-quences and word-level alignments.To perform inference under this model, we usea Metropolis-Hastings within-Gibbs sampler.
Wesample pairs of trees and then compute marginal-ized probabilities over all possible alignments us-ing dynamic programming.We test the effectiveness of our bilingual gram-mar induction model on three corpora of paralleltext: English-Korean, English-Urdu and English-Chinese.
The model is trained using bilingualdata with automatically induced word-level align-ments, but is tested on purely monolingual datafor each language.
In all cases, our model out-performs a state-of-the-art baseline: the Con-stituent Context Model (CCM) (Klein and Man-ning, 2002), sometimes by substantial margins.On average, over all the testing scenarios that westudied, our model achieves an absolute increasein F-measure of 8.8 points, and a 19% reductionin error relative to a theoretical upper bound.2 Related WorkThe unsupervised grammar induction task hasbeen studied extensively, mostly in a monolin-gual setting (Charniak and Carroll, 1992; Stolckeand Omohundro, 1994; Klein and Manning, 2002;Seginer, 2007).
While PCFGs perform poorly onthis task, the CCM model (Klein and Manning,2002) has achieved large gains in performance andis among the state-of-the-art probabilistic modelsfor unsupervised constituency parsing.
We there-fore use CCM as our basic model of monolingualsyntax.While there has been some previous work onbilingual CFG parsing, it has mainly focused onimproving MT systems rather than monolingualparsing accuracy.
Research in this direction waspioneered by (Wu, 1997), who developed Inver-sion Transduction Grammars to capture cross-lingual grammar variations such as phrase re-orderings.
More general formalisms for the samepurpose were later developed (Wu and Wong,1998; Chiang, 2005; Melamed, 2003; Eisner,2003; Zhang and Gildea, 2005; Blunsom et al,2008).
We know of only one study which eval-uates these bilingual grammar formalisms on thetask of grammar induction itself (Smith and Smith,2004).
Both our model and even the monolingualCCM baseline yield far higher performance on thesame Korean-English corpus.Our approach is closer to the unsupervisedbilingual parsing model developed by Kuhn(2004), which aims to improve monolingual per-formance.
Assuming that trees induced over paral-lel sentences have to exhibit certain structural reg-ularities, Kuhn manually specifies a set of rulesfor determining when parsing decisions in the twolanguages are inconsistent with GIZA++ word-level alignments.
By incorporating these con-straints into the EM algorithm he was able to im-prove performance over a monolingual unsuper-vised PCFG.
Still, the performance falls short ofstate-of-the-art monolingual models such as theCCM.More recently, there has been a body of workattempting to improve parsing performance by ex-ploiting syntactically annotated parallel data.
Inone strand of this work, annotations are assumedonly in a resource-rich language and are projectedonto a resource-poor language using the paralleldata (Hwa et al, 2005; Xi and Hwa, 2005).
Inanother strand of work, syntactic annotations areassumed on both sides of the parallel data, and amodel is trained to exploit the parallel data at testtime as well (Smith and Smith, 2004; Burkett andKlein, 2008).
In contrast to this work, our goalis to explore the benefits of multilingual grammarinduction in a fully unsupervised setting.We finally note a recent paper which uses pa-rameter tying to improve unsupervised depen-dency parse induction (Cohen and Smith, 2009).While the primary performance gains occur whentying related parameters within a language, someadditional benefit is observed through bilingual ty-ing, even in the absence of a parallel corpus.3 ModelWe propose an unsupervised Bayesian model forlearning bilingual syntactic structure using paral-lel corpora.
Our key premise is that difficult-to-learn syntactic structures of one language may cor-respond to simpler or less uncertain structures inthe other language.
We treat the part-of-speechtag sequences of parallel sentences, as well as their74(i) (ii) (iii)Figure 1: A pair of trees (i) and two possible alignment trees.
In (ii), no empty spaces are inserted, butthe order of one of the original tree?s siblings has been reversed.
In (iii), only two pairs of nodes havebeen aligned (indicated by arrows) and many empty spaces inserted.word-level alignments, as observed data.
We ob-tain these word-level alignments using GIZA++(Och and Ney, 2003).Our model seeks to explain this observed datathrough a generative process whereby two alignedparse trees are produced jointly.
Though theyare aligned, arbitrary parts of the two trees arepermitted to diverge, accommodating language-specific grammatical structure.
In effect, ourmodel loosely binds the two trees: node-to-nodealignments need only be used where repeatedbilingual patterns can be discovered in the data.3.1 Tree AlignmentsWe achieve this loose binding of trees by adaptingunordered tree alignment (Jiang et al, 1995) to aprobabilistic setting.
Under this formalism, anytwo trees can be aligned using an alignment tree.The alignment tree embeds the original two treeswithin it: each node is labeled by a pair (x, y),(?, y), or (x, ?)
where x is a node from the firsttree, y is a node from the second tree, and ?
is anempty space.
The individual structure of each treemust be preserved under the embedding with theexception of sibling order (to allow variations inphrase and word order).The flexibility of this formalism can be demon-strated by two extreme cases: (1) an alignment be-tween two trees may actually align none of theirindividual nodes, instead inserting an empty space?
for each of the original two trees?
nodes.
(2)if the original trees are isomorphic to one an-other, the alignment may match their nodes ex-actly, without inserting any empty spaces.
SeeFigure 1 for an example.3.2 Model overviewAs our basic model of syntactic structure, weadopt the Constituent-Context Model (CCM) ofKlein and Manning (2002).
Under this model,the part-of-speech sequence of each span in a sen-tence is generated either as a constituent yield?
if it is dominated by a node in the tree ?or otherwise as a distituent yield.
For example,in the bracketed sentence [John/NNP [climbed/VB[the/DT tree/NN]]], the sequence VB DT NN is gen-erated as a constituent yield, since it constitutes acomplete bracket in the tree.
On the other hand,the sequence VB DT is generated as a distituent,since it does not.
Besides these yields, the con-texts (two surrounding POS tags) of constituentsand distituents are generated as well.
In this exam-ple, the context of the constituent VB DT NN wouldbe (NNP, #), while the context of the distituent VBDT would be (NNP, NN).
The CCM model em-ploys separate multinomial distributions over con-stituents, distituents, constituent contexts, and dis-tituent contexts.
While this model is deficient ?each observed subsequence of part-of-speech tagsis generated many times over ?
its performanceis far higher than that of unsupervised PCFGs.Under our bilingual model, each pair of sen-tences is assumed to have been generated jointly inthe following way: First, an unlabeled alignmenttree is drawn uniformly from the set of all suchtrees.
This alignment tree specifies the structureof each of the two individual trees, as well as thepairs of nodes which are aligned and those whichare not aligned (i.e.
paired with a ?
).For each pair of aligned nodes, a correspond-ing pair of constituents and contexts are jointlydrawn from a bilingual distribution.
For unalignednodes (i.e.
nodes paired with a ?
in the alignment75tree), a single constituent and context are drawn,from language-specific distributions.
Distituentsand their contexts are also drawn from language-specific distributions.
Finally, word-level align-ments are drawn based on the structure of thealignment tree.In the next two sections, we describe our modelin more formal detail by specifying the parame-ters and generative process by which sentences areformed.3.3 ParametersOur model employs a number of multinomial dis-tributions:?
piCi : over constituent yields of language i,?
piDi : over distituent yields of language i,?
?Ci : over constituent contexts of language i,?
?Di : over distituent contexts of language i,?
?
: over pairs of constituent yields, one fromthe first language and the other from the sec-ond language,?
Gzpair : over a finite set of integer val-ues {?m, .
.
.
,?2,?1, 0, 1, 2, .
.
.
,m}, mea-suring the Giza-score of aligned tree nodepairs (see below),?
Gznode : over a finite set of integer values{?m, .
.
.
,?2,?1, 0}, measuring the Giza-score of unaligned tree nodes (see below).The first four distributions correspond exactly tothe parameters of the CCM model.
Parameter ?
isa ?coupling parameter?
which measures the com-patibility of tree-aligned constituent yield pairs.The final two parameters measure the compatibil-ity of syntactic alignments with the observed lexi-cal GIZA++ alignments.
Intuitively, aligned nodesshould have a high density of word-level align-ments between them, and unaligned nodes shouldhave few lexical alignments.More formally, consider a tree-aligned nodepair (n1, n2) with corresponding yields (y1, y2).We call a word-level alignment good if it alignsa word in y1 with a word in y2.
We call a word-level alignment bad if it aligns a word in y1 witha word outside y2, or vice versa.
The Giza-score for (n1, n2) is the number of good wordalignments minus the number of bad word align-ments.
For example, suppose the constituent mylong name is node-aligned to its Urdu translationmera lamba naam.
If only the word-pairs my/meraand name/naam are aligned, then the Giza-scorefor this node-alignment would be 2.
If however,the English word long were (incorrectly) alignedunder GIZA++ to some Urdu word outside the cor-responding constituent, then the score would dropto 1.
This score could even be negative if the num-ber of bad alignments exceeds those that are good.DistributionGzpair provides a probability for thesescores (up to some fixed absolute value).For an unaligned node n with correspondingyield y, only bad GIZA++ alignments are possible,thus the Giza-score for these nodes will always bezero or negative.
Distribution Gznode provides aprobability for these scores (down to some fixedvalue).
We want our model to find tree alignmentssuch that both aligned node pairs and unalignednodes have high Giza-score.3.4 Generative ProcessNow we describe the stochastic process wherebythe observed parallel sentences and their word-level alignments are generated, according to ourmodel.As the first step in the Bayesian generative pro-cess, all the multinomial parameters listed in theprevious section are drawn from their conjugatepriors ?
Dirichlet distributions of appropriate di-mension.
Then, each pair of word-aligned parallelsentences is generated through the following pro-cess:1.
A pair of binary trees T1 and T2 along withan alignment tree A are drawn according toP (T1, T2, A).
A is an alignment tree for T1and T2 if it can be obtained by the follow-ing steps: First insert blank nodes (labeled by?)
into T1 and T2.
Then permute the orderof sibling nodes such that the two resultingtrees T ?1 and T?2 are identical in structure.
Fi-nally, overlay T ?1 and T?2 to obtain A.
We ad-ditionally require that A contain no extrane-ous nodes ?
that is no nodes with two blanklabels (?, ?).
See Figure 1 for an example.We define the distribution P (T1, T2, A) to beuniform over all pairs of binary trees and theiralignments.2.
For each node in A of the form (n1, ?)
(i.e.nodes in T1 left unaligned by A), draw(i) a constituent yield according to piC1 ,76(ii) a constituent context according to ?C1 ,(iii) a Giza-score according to Gznode.3.
For each node in A of the form (?, n2) (i.e.nodes in T2 left unaligned by A), draw(i) a constituent yield according to piC2 ,(ii) a constituent context according to ?C2 ,(iii) a Giza-score according to Gznode.4.
For each node in A of the form (n1, n2) (i.e.tree-aligned node pairs), draw(i) a pair of constituent yields (y1, y2) ac-cording to:?C1 (y1) ?
?C2 (y2) ?
?
(y1, y2)Z(1)which is a product of experts combiningthe language specific context-yield dis-tributions as well as the coupling distri-bution ?
with normalization constant Z,(ii) a pair of contexts according to the ap-propriate language-specific parameters,(iii) a Giza-score according to Gzpair.5.
For each span in Ti not dominated by a node(for each language i ?
{1, 2}), draw a dis-tituent yield according to piDi and a distituentcontext according to ?Di .6.
Draw actual word-level alignments consis-tent with the Giza-scores, according to a uni-form distribution.In the next section we turn to the problem ofinference under this model when only the part-of-speech tag sequences of parallel sentences andtheir word-level alignments are observed.3.5 InferenceGiven a corpus of paired part-of-speech tag se-quences (s1, s2) and their GIZA++ alignmentsg, we would ideally like to predict the set oftree pairs (T1,T2) which have highest proba-bility when conditioned on the observed data:P(T1,T2?
?s1, s2,g).
We could rewrite this byexplicitly integrating over the yield, context, cou-pling, Giza-score parameters as well as the align-ment trees.
However, since maximizing this in-tegral directly would be intractable, we resort tostandard Markov chain sampling techniques.
Weuse Gibbs sampling (Hastings, 1970) to draw treesfor each sentence conditioned on those drawn forall other sentences.
The samples form a Markovchain which is guaranteed to converge to the truejoint distribution over all sentences.In the monolingual setting, there is a well-known tree sampling algorithm (Johnson et al,2007).
This algorithm proceeds in top-down fash-ion by sampling individual split points using themarginal probabilities of all possible subtrees.These marginals can be efficiently pre-computedand form the ?inside?
table of the famous Inside-Outside algorithm.
However, in our setting, treescome in pairs, and their joint probability cruciallydepends on their alignment.For the ith parallel sentence, we wish to jointlysample the pair of trees (T1, T2)i together withtheir alignment Ai.
To do so directly would in-volve simultaneously marginalizing over all pos-sible subtrees as well as all possible alignmentsbetween such subtrees when sampling upper-levelsplit points.
We know of no obvious algorithmfor computing this marginal.
We instead first sam-ple the pair of trees (T1, T2)i from a simpler pro-posal distributionQ.
Our proposal distribution as-sumes that no nodes of the two trees are alignedand therefore allows us to use the recursive top-down sampling algorithm mentioned above.
Aftera new tree pair T ?
= (T ?1 , T?2 )i is drawn from Q,we accept the pair with the following probability:min{1,P (T ?|T?i,A?i) Q(T |T?i,A?i)P (T |T?i,A?i) Q(T ?|T?i,A?i)}where T is the previously sampled tree-pair forsentence i, P is the true model probability, andQ is the probability under the proposal distribu-tion.
This use of a tractable proposal distributionand acceptance ratio is known as the Metropolis-Hastings algorithm and it preserves the conver-gence guarantee of the Gibbs sampler (Hastings,1970).
To compute the terms P (T ?|T?i,A?i)and P (T |T?i,A?i) in the acceptance ratio above,we need to marginalize over all possible align-ments between tree pairs.Fortunately, for any given pair of trees T1 andT2 this marginalization can be computed usinga dynamic program in time O(|T1||T2|).
Herewe provide a very brief sketch.
For every pairof nodes n1 ?
T1, n2 ?
T2, a table stores themarginal probability of the subtrees rooted at n1and n2, respectively.
A dynamic program buildsthis table from the bottom up: For each node pairn1, n2, we sum the probabilities of all local align-ment configurations, each multiplied by the appro-77priate marginals already computed in the table forlower-level node pairs.
This algorithm is an adap-tation of the dynamic program presented in (Jianget al, 1995) for finding minimum cost alignmenttrees (Fig.
5 of that publication).Once a pair of trees (T1, T2) has been sam-pled, we can proceed to sample an alignment treeA|T1, T2.2 We sample individual alignment deci-sions from the top down, at each step using thealignment marginals for the remaining subtrees(already computed using the afore-mentioned dy-namic program).
Once the triple (T1, T2, A) hasbeen sampled, we move on to the next parallel sen-tence.We avoid directly sampling parameter val-ues, instead using the marginalized closed formsfor multinomials with Dirichlet conjugate-priorsusing counts and hyperparameter pseudo-counts(Gelman et al, 2004).
Note that in the case ofyield pairs produced according to Distribution 1(in step 4 of the generative process) conjugacy istechnically broken, since the yield pairs are nolonger produced by a single multinomial distribu-tion.
Nevertheless, we count the produced yieldsas if they had been generated separately by eachof the distributions involved in the numerator ofDistribution 1.4 Experimental setupWe test our model on three corpora of bilin-gual parallel sentences: English-Korean, English-Urdu, and English-Chinese.
Though the model istrained using parallel data, during testing it has ac-cess only to monolingual data.
This set-up ensuresthat we are testing our model?s ability to learn bet-ter parameters at training time, rather than its abil-ity to exploit parallel data at test time.
Following(Klein and Manning, 2002), we restrict our modelto binary trees, though we note that the alignmenttrees do not follow this restriction.Data The Penn Korean Treebank (Han et al,2002) consists of 5,083 Korean sentences trans-lated into English for the purposes of languagetraining in a military setting.
Both the Koreanand English sentences are annotated with syntactictrees.
We use the first 4,000 sentences for trainingand the last 1,083 sentences for testing.
We notethat in the Korean data, a separate tag is given for2Sampling the alignment tree is important, as it providesus with counts of aligned constituents for the coupling pa-rameter.each morpheme.
We simply concatenate all themorpheme tags given for each word and treat theconcatenation as a single tag.
This procedure re-sults in 199 different tags.
The English-Urdu par-allel corpus3 consists of 4,325 sentences from thefirst three sections of the Penn Treebank and theirUrdu translations annotated at the part-of-speechlevel.
The Urdu side of this corpus does not pro-vide tree annotations so here we can test parse ac-curacy only on English.
We use the remainingsections of the Penn Treebank for English test-ing.
The English-Chinese treebank (Bies et al,2007) consists of 3,850 Chinese newswire sen-tences translated into English.
Both the Englishand Chinese sentences are annotated with parsetrees.
We use the first 4/5 for training and the final1/5 for testing.During preprocessing of the corpora we removeall punctuation marks and special symbols, fol-lowing the setup in previous grammar inductionwork (Klein and Manning, 2002).
To obtain lex-ical alignments between the parallel sentences weemploy GIZA++ (Och and Ney, 2003).
We use in-tersection alignments, which are one-to-one align-ments produced by taking the intersection of one-to-many alignments in each direction.
These one-to-one intersection alignments tend to have higherprecision.We initialize the trees by making uniform splitdecisions recursively from the top down for sen-tences in both languages.
Then for each pair ofparallel sentences we randomly sample an initialalignment tree for the two sampled trees.Baseline We implement a Bayesian version ofthe CCM as a baseline.
This model uses the sameinference procedure as our bilingual model (Gibbssampling).
In fact, our model reduces to thisBayesian CCM when it is assumed that no nodesbetween the two parallel trees are ever alignedand when word-level alignments are ignored.
Wealso reimplemented the original EM version ofCCM and found virtually no difference in perfor-mance when using EM or Gibbs sampling.
In bothcases our implementation achieves F-measure inthe range of 69-70% on WSJ10, broadly in linewith the performance reported by Klein and Man-ning (2002).Hyperparameters Klein (2005) reports usingsmoothing pseudo-counts of 2 for constituent3http://www.crulp.org78Figure 2: The F-measure of the CCM baseline (dotted line) and bilingual model (solid line) plotted onthe y-axis, as the maximum sentence length in the test set is increased (x-axis).
Results are averaged overall training scenarios given in Table 1.yields and contexts and 8 for distituent yields andcontexts.
In our Bayesian model, these similarsmoothing counts occur as the parameters of theDirichlet priors.
For Korean we found that thebaseline performed well using these values.
How-ever, on our English and Chinese data, we foundthat somewhat higher smoothing values workedbest, so we utilized values of 20 and 80 for con-stituent and distituent smoothing counts, respec-tively.Our model additionally requires hyperparam-eter values for ?
(the coupling distribution foraligned yields), Gzpair and Gznode (the distribu-tions over Giza-scores for aligned nodes and un-aligned nodes, respectively).
For ?
we used asymmetric Dirichlet prior with parameter 1.
ForGzpair and Gznode, in order to create a strong biastowards high Giza-scores, we used non-symmetricDirichlet priors.
In both cases, we capped the ab-solute value of the scores at 3, to prevent countsparsity.
In the case of Gzpair we gave pseudo-counts of 1,000 for negative values and zero, andpseudo-counts of 1,000,000 for positive scores.For Gznode we gave a pseudo-count of 1,000,000for a score of zero, and 1,000 for all nega-tive scores.
This very strong prior bias encodesour intuition that syntactic alignments which re-spect lexical alignments should be preferred.
Ourmethod is not sensitive to these exact values andany reasonably strong bias gave similar results.In all our experiments, we consider the hyper-parameters fixed and observed values.Testing and evaluation As mentioned above,we test our model only on monolingual data,where the parallel sentences are not provided tothe model.
To predict the bracketings of thesemonolingual test sentences, we take the smoothedcounts accumulated in the final round of samplingover the training data and perform a maximumlikelihood estimate of the monolingual CCM pa-rameters.
These parameters are then used to pro-duce the highest probability bracketing of the testset.To evaluate both our model as well as the base-line, we use (unlabeled) bracket precision, re-call, and F-measure (Klein and Manning, 2002).Following previous work, we include the whole-sentence brackets but ignore single-word brack-ets.
We perform experiments on different subsetsof training and testing data based on the sentence-length.
In particular we experimented with sen-tence length limits of 10, 20, and 30 for both thetraining and testing sets.
We also report the upperbound on F-measure for binary trees.
We averagethe results over 10 separate sampling runs.5 ResultsTable 1 reports the full results of our experiments.In all testing scenarios the bilingual model out-performs its monolingual counterpart in terms ofboth precision and recall.
On average, the bilin-gual model gains 10.2 percentage points in preci-sion, 7.7 in recall, and 8.8 in F-measure.
The gapbetween monolingual performance and the binarytree upper bound is reduced by over 19%.The extent of the gain varies across pairings.For instance, the smallest improvement is ob-served for English when trained with Urdu.
TheKorean-English pairing results in substantial im-provements for Korean and quite large improve-ments for English, for which the absolute gainreaches 28 points in F-measure.
In the case of Chi-nese and English, the gains for English are fairlyminimal whereas those for Chinese are quite sub-79Max Sent.
Length Monolingual Bilingual Upper BoundTest Train Precision Recall F1 Precision Recall F1 F1ENwithKR 1010 52.74 39.53 45.19 57.76 43.30 49.50 85.620 41.87 31.38 35.87 61.66 46.22 52.83 85.630 33.43 25.06 28.65 64.41 48.28 55.19 85.62020 35.12 25.12 29.29 56.96 40.74 47.50 83.330 26.26 18.78 21.90 60.07 42.96 50.09 83.330 30 23.95 16.81 19.76 58.01 40.73 47.86 82.4KRwithEN 1010 71.07 62.55 66.54 75.63 66.56 70.81 93.620 71.35 62.79 66.80 77.61 68.30 72.66 93.630 71.37 62.81 66.82 77.87 68.53 72.91 93.62020 64.28 54.73 59.12 70.44 59.98 64.79 91.930 64.29 54.75 59.14 70.81 60.30 65.13 91.930 30 63.63 54.17 58.52 70.11 59.70 64.49 91.9ENwithCH 1010 50.09 34.18 40.63 37.46 25.56 30.39 81.020 58.86 40.17 47.75 50.24 34.29 40.76 81.030 64.81 44.22 52.57 68.24 46.57 55.36 81.02020 41.90 30.52 35.31 38.64 28.15 32.57 84.330 52.83 38.49 44.53 58.50 42.62 49.31 84.330 30 46.35 33.67 39.00 51.40 37.33 43.25 84.1CHwithEN 1010 39.87 27.71 32.69 40.62 28.23 33.31 81.920 43.44 30.19 35.62 47.54 33.03 38.98 81.930 43.63 30.32 35.77 54.09 37.59 44.36 81.92020 29.80 23.46 26.25 36.93 29.07 32.53 88.030 30.05 23.65 26.47 43.99 34.63 38.75 88.030 30 24.46 19.41 21.64 39.61 31.43 35.05 88.4ENwithUR 1010 57.98 45.68 51.10 73.43 57.85 64.71 88.120 70.57 55.60 62.20 80.24 63.22 70.72 88.130 75.39 59.40 66.45 79.04 62.28 69.67 88.12020 57.78 43.86 49.87 67.26 51.06 58.05 86.330 63.12 47.91 54.47 64.45 48.92 55.62 86.330 30 57.36 43.02 49.17 57.97 43.48 49.69 85.7Table 1: Unlabeled precision, recall and F-measure for the monolingual baseline and the bilingual modelon several test sets.
We report results for different combinations of maximum sentence length in both thetraining and test sets.
The right most column, in all cases, contains the maximum F-measure achievableusing binary trees.
The best performance for each test-length is highlighted in bold.stantial.
This asymmetry should not be surprising,as Chinese on its own seems to be quite a bit moredifficult to parse than English.We also investigated the impact of sentencelength for both the training and testing sets.
Forour model, adding sentences of greater length tothe training set leads to increases in parse accu-racy for short sentences.
For the baseline, how-ever, adding this additional training data degradesperformance in the case of English paired with Ko-rean.
Figure 2 summarizes the performance ofour model for different sentence lengths on sev-eral of the test-sets.
As shown in the figure, thelargest improvements tend to occur at longer sen-tence lengths.6 ConclusionWe have presented a probabilistic model for bilin-gual grammar induction which uses raw paralleltext to learn tree pairs and their alignments.
Ourformalism loosely binds the two trees, using bilin-gual patterns when possible, but allowing substan-tial language-specific variation.
We tested ourmodel on three test sets and showed substantialimprovement over a state-of-the-art monolingualbaseline.44The authors acknowledge the support of the NSF (CA-REER grant IIS-0448168, grant IIS-0835445, and grant IIS-0835652).
Thanks to Amir Globerson and members of theMIT NLP group for their helpful suggestions.
Any opinions,findings, or conclusions are those of the authors, and do notnecessarily reflect the views of the funding organizations80ReferencesAnn Bies, Martha Palmer, Justin Mott, and ColinWarner.
2007.
English Chinese translation treebankv 1.0.
LDC2007T02.Phil Blunsom, Trevor Cohn, and Miles Osborne.
2008.Bayesian synchronous grammar induction.
In Pro-ceedings of NIPS.David Burkett and Dan Klein.
2008.
Two languagesare better than one (for syntactic parsing).
In Pro-ceedings of EMNLP, pages 877?886.Eugene Charniak and Glen Carroll.
1992.
Two exper-iments on learning probabilistic dependency gram-mars from corpora.
In Proceedings of the AAAIWorkshop on Statistically-Based NLP Techniques,pages 1?13.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the ACL, pages 263?270.Shay B. Cohen and Noah A. Smith.
2009.
Shared lo-gistic normal distributions for soft parameter tyingin unsupervised grammar induction.
In Proceedingsof the NAACL/HLT.Jason Eisner.
2003.
Learning non-isomorphic treemappings for machine translation.
In The Compan-ion Volume to the Proceedings of the ACL, pages205?208.Andrew Gelman, John B. Carlin, Hal S. Stern, andDonald B. Rubin.
2004.
Bayesian data analysis.Chapman and Hall/CRC.Dmitriy Genzel.
2005.
Inducing a multilingual dictio-nary from a parallel multitext in related languages.In Proceedings of EMNLP/HLT, pages 875?882.C.
Han, N.R.
Han, E.S.
Ko, H. Yi, and M. Palmer.2002.
Penn Korean Treebank: Development andevaluation.
In Proc.
Pacific Asian Conf.
Languageand Comp.W.
K. Hastings.
1970.
Monte carlo sampling meth-ods using Markov chains and their applications.Biometrika, 57:97?109.R.
Hwa, P. Resnik, A. Weinberg, C. Cabezas, andO.
Kolak.
2005.
Bootstrapping parsers via syntacticprojection across parallel texts.
Journal of NaturalLanguage Engineering, 11(3):311?325.T.
Jiang, L. Wang, and K. Zhang.
1995.
Alignment oftrees ?
an alternative to tree edit.
Theoretical Com-puter Science, 143(1):137?148.M.
Johnson, T. Griffiths, and S. Goldwater.
2007.Bayesian inference for PCFGs via Markov chainMonte Carlo.
In Proceedings of the NAACL/HLT,pages 139?146.Dan Klein and Christopher D. Manning.
2002.
Agenerative constituent-context model for improvedgrammar induction.
In Proceedings of the ACL,pages 128?135.D.
Klein.
2005.
The Unsupervised Learning of Natu-ral Language Structure.
Ph.D. thesis, Stanford Uni-versity.Jonas Kuhn.
2004.
Experiments in parallel-text basedgrammar induction.
In Proceedings of the ACL,pages 470?477.I.
Dan Melamed.
2003.
Multitext grammarsand synchronous parsers.
In Proceedings of theNAACL/HLT, pages 79?86.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Yoav Seginer.
2007.
Fast unsupervised incrementalparsing.
In Proceedings of the ACL, pages 384?391.David A. Smith and Noah A. Smith.
2004.
Bilingualparsing with factored estimation: Using English toparse Korean.
In Proceeding of EMNLP, pages 49?56.Benjamin Snyder and Regina Barzilay.
2008.
Un-supervised multilingual learning for morphologicalsegmentation.
In Proceedings of the ACL/HLT,pages 737?745.Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,and Regina Barzilay.
2008.
Unsupervised multi-lingual learning for POS tagging.
In Proceedings ofEMNLP, pages 1041?1050.Benjamin Snyder, Tahira Naseem, Jacob Eisenstein,and Regina Barzilay.
2009.
Adding more languagesimproves unsupervised multilingual part-of-speechtagging: A Bayesian non-parametric approach.
InProceedings of the NAACL/HLT.Andreas Stolcke and Stephen M. Omohundro.
1994.Inducing probabilistic grammars by Bayesian modelmerging.
In Proceedings of ICGI, pages 106?118.Dekai Wu and Hongsing Wong.
1998.
Machinetranslation with a stochastic grammatical channel.In Proceedings of the ACL/COLING, pages 1408?1415.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):377?403.Chenhai Xi and Rebecca Hwa.
2005.
A backoffmodel for bootstrapping resources for non-englishlanguages.
In Proceedings of EMNLP, pages 851 ?858.Hao Zhang and Daniel Gildea.
2005.
Stochastic lex-icalized inversion transduction grammar for align-ment.
In Proceedings of the ACL, pages 475?482.81
