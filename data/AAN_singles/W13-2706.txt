Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 43?48,Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational LinguisticsMorphological annotation of Old and Middle Hungarian corporaAttila Nova?k1,2 Gyo?rgy Orosz2 No?ra Wenszky21Research Institute for Linguistics, Hungarian Academy of SciencesBenczu?r u.
33., Budapest, Hungary2MTA-PPKE Natural Language Research GroupFaculty of Information Technology, Pa?zma?ny Pe?ter Catholic UniversityPra?ter u.
50/a, Budapest, Hungary{novak.attila,oroszgy}@itk.ppke.hu, wenszkynora@gmail.comAbstractIn our paper, we present a computationalmorphology for Old and Middle Hungar-ian used in two research projects that aimat creating morphologically annotated cor-pora of Old and Middle Hungarian.
In ad-dition, we present the web-based disam-biguation tool used in the semi-automaticdisambiguation of the annotations and thestructured corpus query tool that has aunique but very useful feature of makingcorrections to the annotation in the queryresults possible.1 IntroductionOne of the aims of two parallel OTKA projects ofthe Research Institute for Linguistics of the Hun-garian Academy of Sciences1 is to create mor-phologically analyzed and searchable corpora oftexts from the Old Hungarian and Middle Hungar-ian period.
In the course of the projects, the Hu-mor Hungarian morphological analyzer (Nova?k,2003; Pro?sze?ky and Nova?k, 2005) was extendedto be capable of analyzing words containing mor-phological constructions, suffix allomorphs, suf-fix morphemes, paradigms or stems that were usedin Old and Middle Hungarian but no longer existin present-day Hungarian.
In the sections below,we describe how the morphological analyzer wasadapted to the task, the problems we encounteredand how they were solved.
We also present theautomatic and the manual disambiguation systemused for the morphosyntactic annotation of textsand the corpus manager with the help of whichthe annotated corpora can be searched and main-tained.1Hungarian historical generative syntax [OTKANK78074], and Morphologically analysed corpus of Old andMiddle Hungarian texts representative of informal languageuse [OTKA 81189]2 PreprocessingThe overwhelming majority of extant texts fromthe Old Hungarian period are codices, mainly con-taining texts translated from Latin.
The texts se-lected for the Corpus of Informal Language Use,however, are much closer to spoken language:minutes taken at court trials, such as witch tri-als, and letters sent by noblemen and serfs.
Inthe case of the latter corpus, metadata belonging tothe texts are also of primary importance, as thesemake the corpus fit for historical-sociolinguisticresearch.2.1 DigitizationAll the texts selected for our corpora were orig-inally hand-written.
However, the basis for thedigitized version was always a printed edition ofthe texts published earlier.
The printed texts werescanned and converted to a character stream us-ing OCR.
This was not a trivial task, especiallyin the case of Old Hungarian texts, owing to theextensive use of unusual characters and diacrit-ics.
In the lack of an orthographic norm, eachtext applied a different set of characters; moreover,the printed publications used different fonts.
Thusthe only way to get acceptable results was to re-train the OCR program2 for each text from scratchsince the out-of-the-box Hungarian language andglyph models of the software did not fit any of ourtexts.
Subsequently, all the automatically recog-nized documents had to be manually checked andcorrected, but even so, this workflow proved to bemuch faster than attempting to type in the texts.2.2 NormalizationThe next step of preprocessing was normalization,i.e.
making the texts uniform regarding their or-thography and phonology.
Normalization, which2We used FineReader, which makes full customization ofglyph models possible, including the total exclusion of out-of-the-box models.43was done manually, in our case meant modern-ization to present-day orthography.
Note that thisalso implies differences in tokenization into indi-vidual words between the original and the normal-ized version.
During this process, which also in-cluded segmentation of the texts into clauses, cer-tain phonological dialectal variations were neu-tralized.Morphological variation, however, was left un-touched: no extinct morphemes were replaced bytheir present day counterparts.
We also retainedextinct allomorphs unless the variation was purelyphonological.
In the case of potential irresolvableambiguity, the ambiguity was preserved as well,even if it was due to the vagueness of the orthog-raphy of the era.An example of this is the non-consistent mark-ing of vowel length.
The definite and indefinite3rd person singular imperfect of the frequentlyused word mond ?say?
was monda?
?
monda re-spectively, but accents are often missing from thetexts.
Furthermore, in many texts in the corpus,these two forms were used with a clearly differ-ent distribution from their present day counterpartsmondta?mondott.
Therefore, in many cases, nei-ther the orthography, nor the usage was consistentenough to decide unambiguously how a certain ap-pearance of monda should be annotated concern-ing definiteness.Another example of inherent ambiguity is a di-alectal variant of possessive marking, which isvery frequent in these corpora and often neutral-izes singular and plural possessed forms.
For ex-ample, cselekedetinek could both mean ?of his/herdeed?
or ?of his/her deeds?, which in many casescannot be disambiguated based on the contexteven for human annotators.
Such ambiguous caseswere annotated as inherently ambiguous regardingnumber/definiteness etc.2.3 Jakab?s databasesSome of the Old Hungarian codices (Jo?kai (Jakab,2002), Guary (Jakab and Kiss, 1994), Apor (Jakaband Kiss, 1997), and Festetics (Jakab and Kiss,2001)) were not digitized using the OCR tech-nique described above, as these were available inthe form of historical linguistic databases, createdby Jakab La?szlo?
and his colleagues between 1978and 2002.
However, the re-creation of the origi-nal texts out of these lexical databases was a dif-ficult task.
The first problem was that, in thedatabases, the locus of word token occurrencesonly identified codex page, column and line num-ber, but there was no information concerning theorder of words within a line.
The databases alsocontain morphological analyses, but they were en-coded in a hard-to-read numerical format, whichoccasionally was incorrect and often incomplete.Furthermore, the categorization was in many re-spects incompatible with our system.
However, fi-nally we managed to re-create the original texts.First the order of words was manually restoredand incomplete and erroneous analyses were fixed.Missing lemmas were added to the lexicon of theadapted computational morphology, and the nor-malized version of the texts was generated usingthe morphology as a word form generator.
Finally,the normalized texts were reanalyzed to get analy-ses compatible with the annotation scheme appliedto the other texts in the corpora.3 The morphological analyzerThe digitized and normalized texts have been an-alyzed with an extended version of the Humoranalyzer for Hungarian.
The lexicon of lemmasand the affix inventory of the program have beenaugmented with items that have disappeared fromthe language but are present in the historical cor-pora.
Just the affix inventory had to be supple-mented with 50 new affixes (not counting their al-lomorphs).Certain affixes have not disappeared, but theirproductivity has diminished compared to the OldHungarian era.
Although words with these mor-phemes are still present in the language, they aregenerally lexicalized items, often with a changedmeaning.
An example of such a suffix is ?At,which used to be a fully productive nomen actio-nis suffix.
Today, this function belongs to the suf-fix ?A?s.
The (now lexicalized) words, however,that end in ?At mark the (tangible) result of an ac-tion (i.e.
nomen acti) in present-day standard Hun-garian, as in falazat ?wall?
vs. falaza?s ?building awall?.One factor that made adaptation of the morpho-logical model difficult was that there are no reli-able accounts on the changes of paradigms.
Dataconcerning which affix allomorphs could be at-tached to which stem allomorphs had to be ex-tracted from the texts themselves.
Certain mor-phological constructions that had already disap-peared by the end of the Old Hungarian era were44rather rare (such as some participle forms) and of-ten some items in these rare subparadigms have al-ternative analyses.
This made the formal descrip-tion of these paradigms rather difficult.However, the most time consuming task was theenlargement of the stem inventory.
Beside the ad-dition of a number of new lemmas, the entries ofseveral items already listed in the lexicon of thepresent-day analyzer had to be modified for ourpurposes.
The causes were various: some rootsnow belong to another part of speech, or in someconstructions they had to be analyzed differentlyfrom their present analysis.Furthermore, the number of pronouns was con-siderably higher in the examined period thantoday.
The description of their extensive andrather irregular paradigms was really challengingas some forms were underrepresented in the cor-pora.Some enhancements of the morphological an-alyzer made during the corpus annotation projectswere also applicable to the morphological descrip-tion of standard modern Hungarian.
One suchmodification was a new annotation scheme ap-plied to time adverbials that are lexicalized suf-fixed (or unsuffixed) forms of nouns, like reggel?morning/in the morning?
or nappal ?daytime/indaytime?, quite a few of which can be modified byadjectives when used adverbially, such as fe?nyesnappal ?in broad daylight?.
This latter fact shedslight on a double nature of these words that couldbe captured in an annotation of these forms as spe-cially suffixed forms of nouns instead of atomicadverbs, an analysis that is compatible with X-bartheory (Jackendoff, 1977).4 DisambiguationWith the exception of already analyzed sources(i.e.
the ones recovered from the Jakab databases),the morphological annotation had to be disam-biguated.
The ambiguity rate of the output ofthe extended morphological analyzer on historicaltexts is higher than that for the standard Humoranalyzer for present-day corpora (2.21 vs. 1.923analyses/word with an identical (high) granularityof analyses).
This is due to several factors: (i) thehistorical analyzer is less strict, (ii) there are sev-eral formally identical members of the enlargedverbal paradigms including massively ambiguoussubparadigms like that of the passive and the fac-3measured on newswire texttitive,4 (iii) a lot of inherent ambiguities describedabove.The workflow for disambiguation of mor-phosyntactic annotation was a semi-automaticprocess: an automatically pre-disambiguated ver-sion of each text was checked and corrected manu-ally.
For a very short time, we considered using theJakab databases as a training corpus, but recover-ing them required so much development and man-ual labor and the analyses in them lacked so muchdistinction we wanted to make that we opted forcreating the training data completely from scratchinstead.4.1 The manual disambiguation interfaceTo support the process of manual checking andthe initial manual disambiguation of the trainingcorpus a web-based interface was created usingJavaScript and Ajax where disambiguation andnormalization errors can be corrected very effec-tively.
The system presents the document to theuser using an interlinear annotation format that iseasy and natural to read.
An alternative analysiscan be chosen from a pop-up menu containing alist of analyses applicable to the word that appearswhen the mouse cursor is placed over the problem-atic word.
Note that the list only contains gram-matically relevant tags and lemmas for the wordreturned by the morphological analyzer.
This isvery important, since, due to the agglutinating na-ture of Hungarian, there are thousands of possibletags (see Figure 1).Figure 1: The web-based disambiguation interfaceThe original and the normalized word forms aswell as the analyses can also be edited by clickingthem, and an immediate reanalysis by the morpho-logical analyzer running on the web server can beinitiated by double clicking the word.
We use Ajaxtechnology to update only the part of the page be-longing to the given token, so the update is imme-diate.
Afterwards, a new analysis can be selectedfrom the updated pop-up menu.4This ambiguity is absent from modern standard Hungar-ian because the passive is not used any more.45As there is an inherent difference between theoriginal and normalized tokenization, and be-cause, even after thorough proofreading of the nor-malized version, there may remain tokenizationerrors in the texts, it is important that tokens andclauses can also be split and joined using the dis-ambiguation interface.The automatic annotation system was created ina way that makes it possible that details of theannotation scheme be modified in the course ofwork.
One such modification was e.g.
the changeto the annotation of time adverbs mentioned inSection 3 above.
The modified annotation canbe applied to texts analyzed and disambiguatedprior to the modification relatively easily.
Thisis achieved by the fact that, in the course of re-analysis, the program chooses the analysis mostsimilar to the previously selected analysis (basedon a letter trigram similarity measure).
Neverthe-less, the system highlights all tokens the reanaly-sis of which resulted in a change of annotation, sothat these spots can be easily checked manually.For changes in the annotation scheme where thesimple similarity-based heuristic could not be ex-pected to yield an appropriate result (e.g.
whenwe decided to use a more detailed analysis of de-rived verb forms as before), a more sophisticatedmethod was devised to update the annotations: oldanalyses were replaced using automatically gener-ated regular expressions.4.2 Automatic disambiguationWhile the first few documents were disambiguatedcompletely manually using the web-based tool,we soon started to train and use a tagger for pre-disambiguation applying the tagger incrementally,trained on an increasing number of disambiguatedand checked text.
First the HMM-based trigramtagger HunPos (Hala?csy et al 2007) was used.HunPos is not capable of lemmatization, but weused a straightforward method to get a full anal-ysis: we applied reanalysis to the text annotatedonly by the tags assigned by HunPos using theautomatic similarity-based ranking of the analy-ses.
This approach yielded quite good results, butone problem with it was that the similarity-basedranking always prefers shorter lemmas, which wasnot appropriate for handling the case of a fre-quent lemma ambiguity for verbs with one of thelemma candidates ending in an ?ik suffix and theother lacking a suffix (such as dolgozik ?work?
vs.(fel)dolgoz ?process?).
Always selecting the ?ik-less variant is not a good bet in the case of manyfrequent words in this ambiguity class.Recently, we replaced HunPos with anotherHMM-based trigram tagger, PurePos (Orosz andNova?k, 2012), that has many nice extra features.
Itcan process morphologically analyzed ambiguousinput and/or use an integrated analyzer constrain-ing possible analyses to those proposed by the an-alyzer or read from the input.
This boosts the pre-cision of the tagger dramatically in the case of lan-guages like Hungarian and small training corpora.The fact that PurePos can be fed analyzed inputmakes it easy to combine with constraint-basedtools that can further improve the accuracy of thetagging by handling long distance agreement phe-nomena not covered by the trigram model or sim-ply removing impossible tag sequences from thesearch space of the tool.PurePos can perform lemmatization, even forwords unknown to the morphological analyzer(and not annotated on the input) learning a suffix-based lemmatization model from the training cor-pus along with a similar suffix-based tag guessingmodel, thus it assigns a full morphological anal-ysis to each token.
It is also capable of generat-ing an n-best list of annotations for the input sen-tence when using beam search instead of the de-fault Viterbi decoding algorithm.4.3 Disambiguation performanceWe performed an evaluation of the accuracy ofPurePos on an 84000-word manually checkedpart of the historical corpus using five-fold cross-validation with a training corpus of about 67000words and a test corpus of about 17000 words ineach round.
The ratio of words unknown to theMA in this corpus is rather low: 0.32%.The average accuracy of tagging, lemmatiza-tion and full annotation for different versions ofthe tagger are shown in Table 1.
In addition totoken accuracy, we also present sentence accu-racy values in the table.
Note that, in contrast tothe usual way of evaluating taggers, these valueswere calculated excluding the always unambigu-ous punctuation tokens from the evaluation.
Thebaseline tagger uses no morphological informationat all.
Its current lemmatization implementationuses suffix guessing in all cases (even for wordsseen in the training corpus) and selects the mostfrequent lemma, which is obviously not an ideal46solution.The disambiguator using morphology performssignificantly better.
Its clause-level accuracy is81.50%, which means that only every fifth clausecontains a tagging error.
The tag set we used inthe corpus differentiates constructions which arenot generally differentiated at the tag level in Hun-garian corpora, e.g.
deictic pronouns (ebben ?inthis?)
vs. deictic pre-determiners (ebben a ha?zban?in this house?).
Many of these can only be dis-ambiguated using long-distance dependencies, i.e.information often not available to the trigram tag-ger.
Combination of the tagger with a constraint-based tool (see e.g.
Hulden and Francom (2012))would presumably improve accuracy significantly.In the rightmost column, we listed a theoreti-cal upper limit of the performance of the currenttrigram tagger implementation using 5-best outputand an ideal oracle that can select the best annota-tion.baseline morph 5-best+otoken Tag 90.17% 96.44% 98.97%Lem.
91.52% 98.19% 99.11%Full 87.29% 95.90% 98.53%clause Tag 62.48% 83.81% 93.99%Full 54.68% 81.50% 91.47%Table 1: Disambiguation performance of the tag-ger5 Searching the corpusThe web-based tool we created as a corpus queryinterface does not only make it possible to searchfor different grammatical constructions in thetexts, but it is also an effective correction tool.
Er-rors discovered in the annotation or the text ap-pearing in the ?results?
box can immediately becorrected and the corrected text and annotationis recorded in the database.
Naturally, this latterfunctionality of the corpus manager is only avail-able to expert users having the necessary privi-leges.A fast and effective way of correcting errors inthe annotation is to search for presumably incor-rect structures and to correct the truly problematicones at once.
The corrected corpus can be ex-ported after this procedure and the tagger can beretrained on it.The database used for the corpus manager isbased on the Emdros corpus manager (Petersen,2004).
In addition to queries formulated usingMQL, the query language of Emdros, either typedin at the query box or assembled using controlsof the query interface, advanced users can usea custom-made corpus-specific query language(MEQL), which makes a much more compact for-mulation of queries possible than MQL.
It is e.g.extremely simple to locate a specific locus in thecorpus: one simply needs to type in the sequenceof words one is looking for.
Queries formulatedin MEQL are automatically converted to MQLqueries by the query processor.The search engine makes it possible to searchinside sentences, clauses, or texts containinggrammatical constructions and/or tagged withmetadata matching the criteria specified in thequery.
Units longer than a sentence can also besearched for.
The context displayed by default foreach hit is the enclosing sentence with focus wordshighlighted.
Clauses may be non-continuous:this is often the case for embedded subordinateclauses, but the corpus also contains many injectedparenthetical coordinate clauses and many exam-ples where the topic of a subordinate clause pre-cedes its main clause with the net effect of thesubordinate clause being interrupted by the mainclause.
The query example in Figure 2 shows asentence containing several clauses with gaps: theclauses enclosed in angle brackets are wedged be-tween the topic and comment part of the clauseswhich they interrupt.
Emdros is capable of repre-senting these interrupted clauses as single linguis-tic objects with the interrupting clause not beingconsidered part of the interrupted one.6 ConclusionIn our paper, we described the most importantsteps of the creation of a morphological annota-tion framework for the analysis of Old and Mid-dle Hungarian extant texts consisting of a mor-phological analyzer, an automatic disambiguationtool and an intuitive web-based manual disam-biguation tool.
Certain problems arising duringthis process were discussed together with their so-lution.
We also presented our corpus manager,which serves both as a structured corpus query tooland as a correction tool.The morphological analyzer is used for the an-notation of the constantly growing Old and Mid-dle Hungarian corpora.
Part of these corpora arealready searchable by the public.
The Old Hun-47Figure 2: The query interfacegarian Corpus is available at http://rmk.nytud.hu,while the analyzed part of the Historical Corpusof Informal Language Use can be searched athttp://tmk.nytud.hu.AcknowledgmentsResearch reported in this paper was supported bythe research project grants OTKA NK78074 andOTKA 81189.
In addition, we gratefully acknowl-edge support by the grants TA?MOP-4.2.1./B-11/2/KMR-2011-002 and TA?MOP-4.2.2./B-10/1-2010-0014.
We would also like to thank anony-mous reviewers of the paper for their helpful com-ments and suggestions.ReferencesPe?ter Hala?csy, Andra?s Kornai, and Csaba Oravecz.2007.
HunPos: an open source trigram tagger.
InProceedings of the 45th Annual Meeting of the ACLon Interactive Poster and Demonstration Sessions,ACL ?07, pages 209?212, Stroudsburg, PA, USA.Association for Computational Linguistics.Mans Hulden and Jerid Francom.
2012.
Boost-ing statistical tagger accuracy with simple rule-based grammars.
In Nicoletta Calzolari (Confer-ence Chair), Khalid Choukri, Thierry Declerck,Mehmet Ug?ur Dog?an, Bente Maegaard, Joseph Mar-iani, Jan Odijk, and Stelios Piperidis, editors, Pro-ceedings of the Eighth International Conference onLanguage Resources and Evaluation (LREC?12), Is-tanbul, Turkey.
European Language Resources As-sociation (ELRA).Ray Jackendoff.
1977.
X-bar-Syntax: A Study ofPhrase Structure.
Linguistic Inquiry Monograph 2.MIT Press, Cambridge, MA.La?szlo?
Jakab and Antal Kiss.
1994.
A Guary?-ko?dexa?be?ce?rendes adatta?ra.
Sza?m?
?to?ge?pes nyelvto?rte?netiadatta?r.
Debreceni Egyetem, Debrecen.La?szlo?
Jakab and Antal Kiss.
1997.
Az Apor-ko?dexa?be?ce?rendes adatta?ra.
Sza?m?
?to?ge?pes nyelvto?rte?netiadatta?r.
Debreceni Egyetem, Debrecen.La?szlo?
Jakab and Antal Kiss.
2001.
A Festetics-ko?dexa?be?ce?rendes adatta?ra.
Sza?m?
?to?ge?pes nyelvto?rte?netiadatta?r.
Debreceni Egyetem, Debrecen.La?szlo?
Jakab.
2002.
A Jo?kai-ko?dex mint nyelviemle?k: szo?ta?rszeru?
feldolgoza?sban.
Sza?m?
?to?ge?pesNyelvto?rte?neti Adatta?r.
Debreceni Egyetem, Debre-cen.Attila Nova?k.
2003.
Milyen a jo?
Humor?
[Whatis good Humor like?].
In I. Magyar Sza?m?
?to?ge?pesNyelve?szeti Konferencia, pages 138?144, Szeged.SZTE.Gyo?rgy Orosz and Attila Nova?k.
2012.
PurePos ?
anopen source morphological disambiguator.
In Pro-ceedings of the 9th International Workshop on Nat-ural Language Processing and Cognitive Science.,Wroclaw, Poland.Ulrik Petersen.
2004.
Emdros ?
a text database en-gine for analyzed or annotated text.
In In: Proceed-ings of COLING 2004.
(2004) 1190?1193.Ga?bor Pro?sze?ky and Bala?zs Kis.
1999.
A unification-based approach to morpho-syntactic parsing of ag-glutinative and other (highly) inflectional languages.In Proceedings of the 37th annual meeting of theAssociation for Computational Linguistics on Com-putational Linguistics, ACL ?99, pages 261?268,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Ga?bor Pro?sze?ky and Attila Nova?k.
2005.
Compu-tational Morphologies for Small Uralic Languages.In Inquiries into Words, Constraints and Contexts.,pages 150?157, Stanford, California.48
