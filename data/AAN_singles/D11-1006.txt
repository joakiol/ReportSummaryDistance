Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62?72,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsMulti-Source Transfer of Delexicalized Dependency ParsersRyan McDonaldGoogleNew York, NYryanmcd@google.comSlav PetrovGoogleNew York, NYslav@google.comKeith HallGoogleZu?richkbhall@google.comAbstractWe present a simple method for transferringdependency parsers from source languageswith labeled training data to target languageswithout labeled training data.
We first demon-strate that delexicalized parsers can be di-rectly transferred between languages, produc-ing significantly higher accuracies than unsu-pervised parsers.
We then use a constraintdriven learning algorithm where constraintsare drawn from parallel corpora to project thefinal parser.
Unlike previous work on project-ing syntactic resources, we show that simplemethods for introducing multiple source lan-guages can significantly improve the overallquality of the resulting parsers.
The projectedparsers from our system result in state-of-the-art performance when compared to previouslystudied unsupervised and projected parsingsystems across eight different languages.1 IntroductionStatistical parsing has been one of the most active ar-eas of research in the computational linguistics com-munity since the construction of the Penn Treebank(Marcus et al, 1993).
This includes work on phrase-structure parsing (Collins, 1997; Charniak, 2000;Petrov et al, 2006), dependency parsing (McDonaldet al, 2005; Nivre et al, 2006) as well as a num-ber of other formalisms (Clark and Curran, 2004;Wang and Harper, 2004; Shen and Joshi, 2008).As underlying modeling techniques have improved,these parsers have begun to converge to high lev-els of accuracy for English newswire text.
Subse-quently, researchers have begun to look at both port-ing these parsers to new domains (Gildea, 2001; Mc-Closky et al, 2006; Petrov et al, 2010) and con-structing parsers for new languages (Collins et al,1999; Buchholz and Marsi, 2006; Nivre et al, 2007).One major obstacle in building statistical parsersfor new languages is that they often lack the manu-ally annotated resources available for English.
Thisobservation has led to a vast amount of researchon unsupervised grammar induction (Carroll andCharniak, 1992; Klein and Manning, 2004; Smithand Eisner, 2005; Cohen and Smith, 2009; Berg-Kirkpatrick and Klein, 2010; Naseem et al, 2010;Spitkovsky et al, 2010; Blunsom and Cohn, 2010).Grammar induction systems have seen large ad-vances in quality, but parsing accuracies still signif-icantly lag behind those of supervised systems.
Fur-thermore, they are often trained and evaluated underidealized conditions, e.g., only on short sentencesor assuming the existence of gold-standard part-of-speech (POS) tags.1 The reason for these assump-tions is clear.
Unsupervised grammar induction isdifficult given the complexity of the analysis space.These assumptions help to give the model traction.The study of unsupervised grammar induction hasmany merits.
Most notably, it increases our under-standing of how computers (and possibly humans)learn in the absence of any explicit feedback.
How-ever, the gold POS tag assumption weakens any con-clusions that can be drawn, as part-of-speech arealso a form of syntactic analysis, only shallower.Furthermore, from a practical standpoint, it is rarelythe case that we are completely devoid of resourcesfor most languages.
This point has been made by1A notable exception is the work of Seginer (2007).62studies that transfer parsers to new languages byprojecting syntax across word alignments extractedfrom parallel corpora (Hwa et al, 2005; Ganchev etal., 2009; Smith and Eisner, 2009).
Although again,most of these studies also assume the existence ofPOS tags.In this work we present a method for creating de-pendency parsers for languages for which no labeledtraining data is available.
First, we train a sourceside English parser that, crucially, is delexicalized sothat its predictions rely soley on the part-of-speechtags of the input sentence, in the same vein as Ze-man and Resnik (2008).
We empirically show thatdirectly transferring delexicalized models (i.e.
pars-ing a foreign language POS sequence with an En-glish parser) already outperforms state-of-the-art un-supervised parsers by a significant margin.
This re-sult holds in the presence of both gold POS tags aswell as automatic tags projected from English.
Thisemphasizes that even for languages with no syntac-tic resources ?
or possibly even parallel data ?
sim-ple transfer methods can already be more powerfulthan grammar induction systems.Next, we use this delexicalized English parser toseed a perceptron learner for the target language.The model is trained to update towards parses thatare in high agreement with a source side Englishparse based on constraints drawn from alignments inthe parallel data.
We use the augmented-loss learn-ing procedure (Hall et al, 2011) which is closelyrelated to constraint driven learning (Chang et al,2007; Chang et al, 2010).
The resulting parser con-sistently improves on the directly transferred delex-icalized parser, reducing relative errors by 8% onaverage, and as much as 18% on some languages.Finally, we show that by transferring parsers frommultiple source languages we can further reduce er-rors by 16% over the directly transferred Englishbaseline.
This is consistent with previous work onmultilingual part-of-speech (Snyder et al, 2009) andgrammar (Berg-Kirkpatrick and Klein, 2010; Cohenand Smith, 2009) induction, that shows that addinglanguages leads to improvements.We present a comprehensive set of experimentson eight Indo-European languages for which a sig-nificant amount of parallel data exists.
We makeno language specific enhancements in our experi-ments.
We report results for sentences of all lengths,?????????????????????????????????????????????????????????????
?Figure 1: An example (unlabeled) dependency tree.as well as with gold and automatically inducedpart-of-speech tags.
We also report results on sen-tences of length 10 or less with gold part-of-speechtags to compare with previous work.
Our resultsconsistently outperform the previous state-of-the-artacross all languages and training configurations.2 PreliminariesIn this paper we focus on transferring dependencyparsers between languages.
A dependency parsertakes a tokenized input sentence (optionally part-of-speech tagged) and produces a connected tree wheredirected arcs represent a syntactic head-modifier re-lationship.
An example of such a tree is given inFigure 1.
Dependency tree arcs are often labeledwith the role of the syntactic relationship, e.g., is tohearing might be labeled as SUBJECT.
However, wefocus on unlabeled parsing in order to reduce prob-lems that arise due to different treebank annotationschemes.
Of course, even for unlabeled dependen-cies, significant variations in the annotation schemesremain.
For example, in the Danish treebank deter-miners govern adjectives and nouns in noun phrases,while in most other treebanks the noun is the head ofthe noun phrase.
Unlike previous work (Zeman andResnik, 2008; Smith and Eisner, 2009), we do notapply any transformations to the treebanks, whichmakes our results easier to reproduce, but systemat-ically underestimates accuracy.2.1 Data SetsThe treebank data in our experiments are from theCoNLL shared-tasks on dependency parsing (Buch-holz and Marsi, 2006; Nivre et al, 2007).
We useEnglish (en) only as a source language throughoutthe paper.
Additionally, we use the following eightlanguages as both source and target languages: Dan-ish (da), Dutch (nl), German (de), Greek (el), Italian(it), Portuguese (pt), Spanish (es) and Swedish (sv).For languages that were included in both the 2006and 2007 tasks, we used the treebank from the lat-63ter.
We focused on this subset of languages becausethey are Indo-European and a significant amount ofparallel data exists for each language.
By present-ing results on eight languages our study is alreadymore comprehensive than most previous work in thisarea.
However, the restriction to Indo-European lan-guages does make the results less conclusive whenone wishes to transfer a parser from English to Chi-nese, for example.
To account for this, we reportadditional results in the discussion for non-Indo-European languages.
For all data sets we used thepredefined training and testing splits.Our approach relies on a consistent set of part-of-speech tags across languages and treebanks.
Forthis we used the universal tagset from Petrov etal.
(2011), which includes: NOUN (nouns), VERB(verbs), ADJ (adjectives), ADV (adverbs), PRON(pronouns), DET (determiners), ADP (prepositionsor postpositions), NUM (numerals), CONJ (conjunc-tions), PRT (particles), PUNC (punctuation marks)and X (a catch-all tag).
Similar tagsets are used byother studies on grammar induction and projection(Naseem et al, 2010; Zeman and Resnik, 2008).
Forall our experiments we replaced the language spe-cific part-of-speech tags in the treebanks with theseuniversal tags.Like all treebank projection studies we require acorpus of parallel text for each pair of languages westudy.
For this we used the Europarl corpus version5 (Koehn, 2005).
The corpus was preprocessed instandard ways and word aligned by running six it-erations of IBM Model 1 (Brown et al, 1993), fol-lowed by six iterations of the HMM model (Vogel etal., 1996) in both directions.
We then intersect wordalignments to generate one-to-one alignments.2.2 Parsing ModelAll of our parsing models are based on thetransition-based dependency parsing paradigm(Nivre, 2008).
Specifically, all models use anarc-eager transition strategy and are trained usingthe averaged perceptron algorithm as in Zhang andClark (2008) with a beam size of 8.
The featuresused by all models are: the part-of-speech tags ofthe first four words on the buffer and of the top twowords on the stack; the word identities of the firsttwo words on the buffer and of the top word on thestack; the word identity of the syntactic head ofthe top word on the stack (if available).
All featureconjunctions are included.
For treebanks withnon-projective trees we use the pseudo-projectiveparsing technique to transform the treebank intoprojective structures (Nivre and Nilsson, 2005).We focus on using this parsing system for tworeasons.
First, the parser is near state-of-the-art onEnglish parsing benchmarks and second, and moreimportantly, the parser is extremely fast to train andrun, making it easy to run a large number of exper-iments.
Preliminary experiments using a differentdependency parser ?
MSTParser (McDonald et al,2005) ?
resulted in similar empirical observations.2.3 EvaluationAll systems are evaluated using unlabeled attach-ment score (UAS), which is the percentage of words(ignoring punctuation tokens) in a corpus that mod-ify the correct head (Buchholz and Marsi, 2006).Furthermore, we evaluate with both gold-standardpart-of-speech tags, as well as predicted part-of-speech tags from the projected part-of-speech taggerof Das and Petrov (2011).2 This tagger relies only onlabeled training data for English, and achieves accu-racies around 85% on the languages that we con-sider.
We evaluate in the former setting to compareto previous studies that make this assumption.
Weevaluate in the latter setting to measure performancein a more realistic scenario ?
when no target lan-guage resources are available.3 Transferring from EnglishTo simplify discussion, we first focus on the mostcommon instantiation of parser transfer in the liter-ature: transferring from English to other languages.In the next section we expand our system to allowfor the inclusion of multiple source languages.3.1 Direct TransferWe start with the observation that discriminativelytrained dependency parsers rely heavily on part-of-speech tagging features.
For example, when train-ing and testing a parser on our English data, a parserwith all features obtains an UAS of 89.3%3 whereas2Available at http://code.google.com/p/pos-projection/3The best system at CoNLL 2007 achieved 90.1% and useda richer part-of-speech tagset (Nivre et al, 2007).64a delexicalized parser ?
a parser that only has non-lexical features ?
obtains an UAS of 82.5%.
Thekey observation is that part-of-speech tags contain asignificant amount of information for unlabeled de-pendency parsing.This observation combined with our universalpart-of-speech tagset, leads to the idea of directtransfer, i.e., directly parsing the target languagewith the source language parser without relying onparallel corpora.
This idea has been previously ex-plored by Zeman and Resnik (2008) and recently byS?gaard (2011).
Because we use a mapping of thetreebank specific part-of-speech tags to a commontagset, the performance of a such a system is easy tomeasure ?
simply parse the target language data setwith a delexicalized parser trained on the source lan-guage data.
We conducted two experiments.
In thefirst, we assumed that the test set for each target lan-guage had gold part-of-speech tags, and in the sec-ond we used predicted part-of-speech tags from theprojection tagger of Das and Petrov (2011), whichalso uses English as the source language.UAS for all sentence lengths without punctuationare given in Table 1.
We report results for both theEnglish direct transfer parser (en-dir.)
as well as abaseline unsupervised grammar induction system ?the dependency model with valence (DMV) of Kleinand Manning (2004), as obtained by the implemen-tation of Ganchev et al (2010).
We trained on sen-tences of length 10 or less and evaluated on all sen-tences from the test set.4 For DMV, we reversed thedirection of all dependencies if this led to higher per-formance.
From this table we can see that directtransfer is a very strong baseline and is over 20%absolute better than the DMV model for both goldand predicted POS tags.
Table 4, which we will dis-cuss in more detail later, further shows that the directtransfer parser also significantly outperforms state-of-the-art unsupervised grammar induction models,but in a more limited setting of sentences of lengthless than 10.Direct transfer works for a couple of reasons.First, part-of-speech tags contain a significantamount of information for parsing unlabeled depen-dencies.
Second, this information can be transferred,4Training on all sentences results in slightly lower accura-cies on average.to some degree, across languages and treebank stan-dards.
This is because, at least for Indo-Europeanlanguages, there is some regularity in how syntaxis expressed, e.g., primarily SVO, prepositional, etc.Even though there are some differences with respectto relative location of certain word classes, stronghead-modifier POS tag preferences can still help re-solve these, especially when no other viable alter-natives are available.
Consider for example an arti-ficial sentence with a tag sequence: ?VERB NOUNADJ DET PUNC?.
The English parser still predictsthat the NOUN and PUNC modify the VERB and theADJ and DET modify the NOUN, even though in theEnglish data such noun phrases are unlikely.53.2 Projected TransferUnlike most language transfer systems for parsers,the direct transfer approach does not rely on project-ing syntax across aligned parallel corpora (modulothe fact that non-gold tags come from a system thatuses parallel corpora).
In this section we describea simple mechanism for projecting from the directtransfer system using large amounts of parallel datain a similar vein to Hwa et al (2005), Ganchev etal.
(2009), Smith and Eisner (2009) inter alia.
Thealgorithm is based on the work of Hall et al (2011)for training extrinsic parser objective functions andborrows heavily from ideas in learning with weaksupervision including work on learning with con-straints (Chang et al, 2007) and posterior regular-ization (Ganchev et al, 2010).
In our case, theweak signals come from aligned source and targetsentences, and the agreement in their correspondingparses, which is similar to posterior regularizationor the bilingual view of Smith and Smith (2004) andBurkett et al (2010).The algorithm is given in Figure 2.
It starts bylabeling a set of target language sentences with aparser, which in our case is the direct transfer parserfrom the previous section (line 1).
Next, it usesthese parsed target sentences to ?seed?
a new parserby training a parameter vector using the predictedparses as a gold standard via standard perceptronupdates for J rounds (lines 3-6).
This generates aparser that emulates the direct transfer parser, but5This requires a transition-based parser with a beam greaterthan 1 to allow for ambiguity to be resolved at later stages.65Notation:x: input sentencey: dependency treea: alignmentw: parameter vector?
(x, y): feature vectorDP : dependency parser, i.e., DP : x?
yInput:X = {xi}ni=1: target language sentencesP = {(xsi , xti, ai)}mi=1: aligned source-target sentencesDPdelex: delexicalized source parserDPlex: lexicalized source parserAlgorithm:1.
Let X ?
= {(xi, yi)}ni=1 where yi = DPdelex(xi)2. w = 0seed-stage 3. for j : 1 .
.
.
J4.
for xi : x1 .
.
.
xn5.
Let y = argmaxy w ?
?
(xi, y)6. w = w + ?
(xt, yi)?
?
(xi, y)projection-stage 7. for (xsi , xti, ai) : (xs1, xt1, a1) .
.
.
(xsm, xsm, am)8.
Let ys = DPlex(xsi )9.
Let Yt = {y1i , .
.
.
, yki }, where:yki = argmaxy/?
{y1i ,...,yk?1i } w ?
?
(xti, y)10.
Let yt = argmaxyt?Yt ALIGN(ys, yt, ai)11. w = w + ?
(xi, yt)?
?
(xi, y1i )return DP ?
such that DP ?
(x) = argmaxy w ?
?
(x, y)Figure 2: Perceptron-based learning algorithm for train-ing a parser by seeding the model with a direct transferparser and projecting constraints across parallel corpora.has now been lexicalized and is working in the spaceof target language sentences.
Next, the algorithm it-erates over the sentences in the parallel corpus.
Itparses the English sentence with an English parser(line 8, again a lexicalized parser).
It then uses thecurrent target language parameter vector to createa k-best parse list for the target sentence (line 9).From this list, it selects the parse whose dependen-cies align most closely with the English parse via thepre-specified alignment (line 10, also see below forthe definition of the ALIGN function).
It then usesthis selected parse as a proxy to the gold standardparse to update the parameters (line 11).The intuition is simple.
The parser starts withnon-random accuracies by emulating the directtransfer model and slowly tries to induce better pa-rameters by selecting parses from its k-best listthat are considered ?good?
by some external met-ric.
The algorithm then updates towards that out-put.
In this case ?goodness?
is determined throughthe pre-specified sentence alignment and how wellthe target language parse aligns with the Englishparse.
As a result, the model will, ideally, convergeto a state where it predicts target parses that align asclosely as possible with the corresponding Englishparses.
However, since we seed the learner with thedirect transfer parser, we bias the parameters to se-lect parses that both align well and also have highscores under the direct transfer model.
This helpsto not only constrain the search space at the startof learning, but also helps to bias dependencies be-tween words that are not part of the alignment.So far we have not defined the ALIGN functionthat is used to score potential parses.
Let a ={(s(1), t(1)), .
.
.
, (s(n), t(n))} be an alignment wheres(i) is a word in the source sentence xs (not nec-essarily the ith word) and t(i) is similarly a wordin the target sentence xt (again, not necessarily theith word).
The notation (s(i), t(i)) ?
a indicatestwo words are the ith aligned pair in a.
We definethe ALIGN function to encode the Direct Correspon-dence Assumption (DCA) from Hwa et al (2005):ALIGN(ys, yt, a)=?
(s(i),t(i))?a(s(j),t(j))?aSCORE(ys, yt, (s(i), s(j)), (t(i), t(j)))SCORE(ys, yt, (s(i), s(j)), (t(i), t(j)))=??????
?+1 if (s(i), s(j)) ?
ys and (t(i), t(j)) ?
yt?1 if (s(i), s(j)) ?
ys and (t(i), t(j)) /?
yt?1 if (s(i), s(j)) /?
ys and (t(i), t(j)) ?
yt0 otherwiseThe notation (i, j) ?
y indicates that a dependencyfrom head i to modifier j is in tree y.
The ALIGNfunction rewards aligned head-modifier pairs andpenalizes unaligned pairs when a possible alignmentexists.
For all other cases it is agnostic, i.e., whenone or both of the modifier or head are not aligned.Figure 3 shows an example of aligned English-Greek sentences, the English parse and a potentialGreek parse.
In this case the ALIGN function re-turns a value of 2.
This is because there are threealigned dependencies: took?book, book?the and66?????????????????????????????????????????????????????????????????????????
?Figure 3: A Greek and English sentence pair.
Wordalignments are shown as dashed lines, dependency arcsas solid lines.from?John.
These add 3 to the score.
There isone incorrectly aligned dependency: the preposi-tion mistakenly modifies the noun on the Greek side.This subtracts 1.
Finally, there are two dependenciesthat do not align: the subject on the English sideand a determiner to a proper noun on the Greek side.These do not effect the result.The learning algorithm in Figure 2 is an instanceof augmented-loss training (Hall et al, 2011) whichis closely related to the constraint driven learning al-gorithms of Chang et al (2007).
In that work, ex-ternal constraints on output structures are used tohelp guide the learner to good parameter regions.In our model, we use constraints drawn from paral-lel data exactly in the same manner.
Since posteriorregularization is closely related to constraint drivenlearning, this makes our algorithm also similar to theparser projection approach of Ganchev et al (2009).There are a couple of differences.
First, we bias ourmodel towards the direct transfer model, which isalready quite powerful.
Second, our alignment con-straints are used to select parses from a k-best list,whereas in posterior regularization they are used assoft constraints on full model expectations duringtraining.
The latter is beneficial as the use of k-bestlists does not limit the class of parsers to those whoseparameters and search space decompose neatly withthe DCA loss function.
An empirical comparison toGanchev et al (2009) is given in Section 5.Results are given in Table 1 under the column en-proj.
For all experiments we train the seed-stageperceptron for 5 iterations (J = 5) and we use onehundred times as much parallel data as seed stagenon-parallel data (m = 100n).
The seed-stage non-parallel data is the training portion of each treebank,stripped of all dependency annotations.
After train-ing the projected parser we average the parametersgold-POS pred-POSDMV en-dir.
en-proj.
DMV en-dir.
en-proj.da 33.4 45.9 48.2 18.4 44.0 45.5de 18.0 47.2 50.9 30.3 44.7 47.4el 39.9 63.9 66.8 21.2 63.0 65.2es 28.5 53.3 55.8 19.9 50.2 52.4it 43.1 57.7 60.8 37.7 53.7 56.3nl 38.5 60.8 67.8 19.9 62.1 66.5pt 20.1 69.2 71.3 21.0 66.2 67.7sv 44.0 58.3 61.3 33.8 56.5 59.7avg 33.2 57.0 60.4 25.3 55.0 57.6Table 1: UAS for the unsupervised DMV model (DMV),a delexicalized English direct transfer parser (en-dir.
)and a English projected parser (en-proj.).
Measured onall sentence lengths for both gold and predicted part-of-speech tags as input.of the model (Collins, 2002).
The parsers evaluatedusing predicted part-of-speech tags use the predictedtags at both training and testing time and are thusfree of any target language specific resources.When compared with the direct transfer model(en-dir.
in Table 1), we can see that there is an im-provement for every single language, reducing rela-tive error by 8% on average (57.0% to 60.4%) andup to 18% for Dutch (60.8 to 67.8%).
One couldwonder whether the true power of the projectionmodel comes from the re-lexicalization step ?
lines3-6 of the algorithm.
However, if just this step is run,then the average UAS only increases from 57.0%to 57.4%, showing that most of the improvementcomes from the projection stage.
Note that the re-sults in Table 1 indicate that parsers using predictedpart-of-speech tags are only slightly worse than theparsers using gold tags (about 2-3% absolute), show-ing that these methods are robust to tagging errors.4 Multi-Source TransferThe previous section focused on transferring an En-glish parser to a new target language.
However,there are over 20 treebanks available for a varietyof language groups including Indo-European, Altaic(including Japanese), Semitic, and Sino-Tibetan.Many of these are even in standardized formats(Buchholz and Marsi, 2006; Nivre et al, 2007).
Paststudies have shown that for both part-of-speech tag-ging and grammar induction, learning with multiplecomparable languages leads to improvements (Co-hen and Smith, 2009; Snyder et al, 2009; Berg-Kirkpatrick and Klein, 2010).
In this section we ex-67Source Training Languageda de el en es it nl pt svTargetTestLanguageda 79.2 45.2 44.0 45.9 45.0 48.6 46.1 48.1 47.8de 34.3 83.9 53.2 47.2 45.8 53.4 55.8 55.5 46.2el 33.3 52.5 77.5 63.9 41.6 59.3 57.3 58.6 47.5en 34.4 37.9 45.7 82.5 28.5 38.6 43.7 42.3 43.7es 38.1 49.4 57.3 53.3 79.7 68.4 51.2 66.7 41.4it 44.8 56.7 66.8 57.7 64.7 79.3 57.6 69.1 50.9nl 38.7 43.7 62.1 60.8 40.9 50.4 73.6 58.5 44.2pt 42.5 52.0 66.6 69.2 68.5 74.7 67.1 84.6 52.1sv 44.5 57.0 57.8 58.3 46.3 53.4 54.5 66.8 84.8Table 2: UAS for all source-target language pairs.
Each column represents which source language was used to train adelexicalized parser and each row represents which target language test data was used.
Bold numbers are when sourceequals target and underlined numbers are the single best UAS for a target language.
Results are for all sentence lengthswithout punctuation.amine whether this is also true for parser transfer.Table 2 shows the matrix of source-target lan-guage UAS for all nine languages we consider (theoriginal eight target languages plus English).
Wecan see that there is a wide range from 33.3% to74.7%.
There is also a wide range of values depend-ing on the source training data and/or target testingdata, e.g., Portuguese as a source tends to parse tar-get languages much better than Danish, and is alsomore amenable as a target testing language.
Someof these variations are expected, e.g., the Romancelanguages (Spanish, Italian and Portuguese) tend totransfer well to one another.
However, some areunexpected, e.g., Greek being the best source lan-guage for Dutch, as well as German being one of theworst.
This is almost certainly due to different an-notation schemes across treebanks.
Overall, Table 2does indicate that there are possible gains in accu-racy through the inclusion of additional languages.In order to take advantage of treebanks in multi-ple languages, our multi-source system simply con-catenates the training data from all non-target lan-guages.
In other words, the multi-source directtransfer parser for Danish will be trained by firstconcatenating the training corpora of the remain-ing eight languages, training a delexicalized parseron this data and then directly using this parser toanalyze the Danish test data.
For the multi-sourceprojected parser, the procedure is identical to thatin Section 3.2 except that we use the multi-sourcedirect transfer model to seed the algorithm insteadof the English-only direct transfer model.
For theseexperiments we still only use English-target paralleldata because that is the format of the readily avail-able data in the Europarl corpus.Table 3 presents four sets of results.
The first(best-source) is the direct transfer results for the ora-cle single-best source language per target language.The second (avg-source) is the mean UAS over allsource languages per target language.
The third(multi-dir.)
is the multi-source direct transfer sys-tem.
The fourth and final result set (multi-proj.
)is the multi-source projected system.
The resultingparsers are typically much more accurate than theEnglish direct transfer system (Table 1).
On aver-age, the multi-source direct transfer system reduceserrors by 10% relative over the English-only directtransfer system.
These improvements are not consis-tent.
For Greek and Dutch we see significant lossesrelative to the English-only system.
An inspection ofTable 2 shows that for these two languages Englishis a particularly good source training language.For the multi-source projected system the resultsare mixed.
Some languages see basically no changerelative the multi-source direct transfer model, whilesome languages see modest to significant increases.But again, there is an overall trend to better mod-els.
In particular, starting with an English-only di-rect transfer parser with 57.0% UAS on average,by adding parallel corpora and multiple source lan-guages we finish with parser having 63.8% UASon average, which is a relative reduction in errorof roughly 16% and more than doubles the perfor-mance of a DMV model (Table 1).Interestingly, the multi-source systems provide,on average, accuracies near that of the single-bestsource language and significantly better than the av-erage source UAS.
Thus, even this simple method of68best-source avg-source gold-POS pred-POSsource gold-POS gold-POS multi-dir.
multi-proj.
multi-dir.
multi-proj.da it 48.6 46.3 48.9 49.5 46.2 47.5de nl 55.8 48.9 56.7 56.6 51.7 52.0el en 63.9 51.7 60.1 65.1 58.5 63.0es it 68.4 53.2 64.2 64.5 55.6 56.5it pt 69.1 58.5 64.1 65.0 56.8 58.9nl el 62.1 49.9 55.8 65.7 54.3 64.4pt it 74.8 61.6 74.0 75.6 67.7 70.3sv pt 66.8 54.8 65.3 68.0 58.3 62.1avg 63.7 51.6 61.1 63.8 56.1 59.3Table 3: UAS for multi-source direct (multi-dir.)
and projected (multi-proj.)
transfer systems.
best-source is the bestsource model from the languages in Table 2 (excluding the target language).
avg-source is the mean UAS over thesource models for the target (excluding target language).multi-source transfer already provides strong perfor-mance gains.
We expect that more principled tech-niques will lead to further improvements.
For exam-ple, recent work by S?gaard (2011) explores data setsub-sampling methods.
Unlike our work, S?gaardfound that simply concatenating all the data led todegradation in performance.
Cohen et al (2011) ex-plores the idea learning language specific mixturecoefficients for models trained independently on thetarget language treebanks.
However, their resultsshow that this method often did not significantly out-perform uniform mixing.5 ComparisonComparing unsupervised and parser projection sys-tems is difficult as many publications use non-overlapping sets of languages or different evaluationcriteria.
We compare to the following three systemsthat do not augment the treebanks and report resultsfor some of the languages that we considered:?
USR: The weakly supervised system ofNaseem et al (2010), in which manually de-fined universal syntactic rules (USR) are usedto constrain a probabilistic Bayesian model.
Inaddition to their original results, we also reportresults using the same part-of-speech tagset asthe systems described in this paper (USR?
).This is useful for two reasons.
First, it makesthe comparison more direct.
Second, we cangenerate USR results for all eight languagesand not just for the languages that they report.?
PGI: The phylogenetic grammar induction(PGI) model of Berg-Kirkpatrick and Klein(2010), in which the parameters of completelyunsupervised DMV models for multiple lan-guages are coupled via a phylogenetic prior.?
PR: The posterior regularization (PR) approachof Ganchev et al (2009), in which a supervisedEnglish parser is used to generate constraintsthat are projected using a parallel corpus andused to regularize a target language parser.
Wereport results without treebank specific rules.Table 4 gives results comparing the models pre-sented in this work to those three systems.
For thiscomparison we use sentences of length 10 or lessafter punctuation has been removed in order to beconsistent with reported results.
The overall trendscarry over from the full treebank setting to this re-duced sentence length setup: the projected mod-els outperform the direct transfer models and multi-source transfer gives higher accuracy than transfer-ring only from English.
Most previous work has as-sumed gold part-of-speech tags, but as the code forUSR is publicly available we were able to train itusing the same projected part-of-speech tags usedin our models.
These results are also given in Ta-ble 4 under USR?.
Again, we can see that the multi-source systems (both direct and projected) signifi-cantly outperform the unsupervised models.It is not surprising that a parser transferred fromannotated resources does significantly better thanunsupervised systems since it has much more in-formation from which to learn.
The PR system ofGanchev et al (2009) is similar to ours as it alsoprojects syntax across parallel corpora.
For Span-ish we can see that the multi-source direct trans-fer parser is better (75.1% versus 70.6%), and thisis also true for the multi-source projected parser69??
gold-POS ??
?
pred-POS?en-dir.
en-proj.
multi-dir.
multi-proj.
USR?
USR PGI PR multi-dir.
multi-proj.
USR?da 53.2 57.4 58.4 58.8 55.1 51.9 41.6 54.9 54.6 41.7de 65.9 67.0 74.9 72.0 60.0 63.7 63.4 55.1el 73.9 73.9 73.5 78.7 60.3 65.2 74.3 53.4es 58.0 62.3 75.1 73.2 68.3 67.2 58.4 70.6 59.1 56.8 43.3it 65.5 69.9 75.5 75.5 47.9 65.5 70.2 41.4nl 67.6 72.2 58.8 70.7 44.0 45.1 56.3 67.2 38.8pt 77.9 80.6 81.1 86.2 70.9 71.5 63.0 74.0 79.2 66.4sv 70.4 71.3 76.0 77.6 52.6 58.3 72.0 73.9 59.4avg 66.6 69.4 71.7 74.1 57.4 63.9 67.5 49.9Table 4: UAS on sentences of length 10 or less without punctuation, comparing the systems presented in this workto three representative systems from related work.
en-dir./en-proj.
are the direct/projected English parsers and multi-dir./multi-proj.
are the multi-source direct/projected parsers.
Section 5 contains a description of the baseline systems.(73.2%).
Ganchev et al also report results forBulgarian.
We trained a multi-source direct trans-fer parser for Bulgarian which obtained a score of72.8% versus 67.8% for the PR system.
If we onlyuse English as a source language, as in Ganchev etal., the English direct transfer model achieves 66.1%on Bulgarian and 69.3% on Spanish versus 67.8%and 70.6% for PR.
In this setting the English pro-jected model gets 72.0% on Spanish.
Thus, underidentical conditions the direct transfer model obtainsaccuracies comparable to PR.6Another projection based system is that of Smithand Eisner (2009), who report results for German(68.5%) and Spanish (64.8%) on sentences of length15 and less inclusive of punctuation.
Smith and Eis-ner use custom splits of the data and modify a sub-set of the dependencies.
The multi-source projectedparser obtains 71.9% for German and 67.8% forSpanish on this setup.7 If we cherry-pick the sourcelanguage the results can improve, e.g., for Spanishwe can obtain 71.7% and 70.8% by directly transfer-ring parsers form Italian or Portuguese respectively.6 DiscussionOne fundamental point the above experiments il-lustrate is that even for languages for which noresources exist, simple methods for transferringparsers work remarkably well.
In particular, if6Note that the last set of results was obtained by using thesame English training data as Ganchev et al Using the CoNLL2007 English data set for training, the English direct transfermodel is 63.2% for Bulgarian and 58.0% for Spanish versus67.8% and 70.6% for PR, highlighting the large impact that dif-ference treebank annotation standards can have.7Data sets and evaluation criteria obtained via communica-tions with David Smith and Jason Eisner.one can transfer part-of-speech tags, then a largepart of transferring unlabeled dependencies has beensolved.
This observation should lead to a new base-line in unsupervised and projected grammar induc-tion ?
the UAS of a delexicalized English parser.Of course, our experiments focus strictly on Indo-European languages.
Preliminary experiments forArabic (ar), Chinese (zh), and Japanese (ja) suggestsimilar direct transfer methods are applicable.
Forexample, on the CoNLL test sets, a DMV modelobtains UAS of 28.7/41.8/34.6% for ar/zh/ja re-spectively, whereas an English direct transfer parserobtains 32.1/53.8/32.2% and a multi-source directtransfer parser obtains 39.9/41.7/43.3%.
In thissetting only Indo-European languages are used assource data.
Thus, even across language groups di-rect transfer is a reasonable baseline.
However, thisis not necessary as treebanks are available for a num-ber of language groups, e.g., Indo-European, Altaic,Semitic, and Sino-Tibetan.The second fundamental observation is that whenavailable, multiple sources should be used.
Eventhrough naive multi-source methods (concatenatingdata), it is possible to build a system that has compa-rable accuracy to the single-best source for all lan-guages.
This advantage does not come simply fromhaving more data.
In fact, if we randomly sam-pled from the multi-source data until the training setsize was equivalent to the size of the English data,then the results still hold (and in fact go up slightlyfor some languages).
This suggests that even bet-ter transfer models can be produced by separatelyweighting each of the sources depending on the tar-get language ?
either weighting by hand, if we knowthe language group of the target language, or auto-70matically, if we do not.
As previously mentioned,the latter has been explored in both S?gaard (2011)and Cohen et al (2011).7 ConclusionsWe presented a simple, yet effective approachfor projecting parsers from languages with labeledtraining data to languages without any labeled train-ing data.
Central to our approach is the idea ofdelexicalizing the models, which combined with astandardized part-of-speech tagset alows us to di-rectly transfer models between languages.
We thenuse a constraint driven learning algorithm to adaptthe transferred parsers to the respective target lan-guage, obtaining an additional 16% error reduc-tion on average in a multi-source setting.
Our finalparsers achieve state-of-the-art accuracies on eightIndo-European languages, significantly outperform-ing previous unsupervised and projected systems.Acknowledgements: We would like to thank Kuz-man Ganchev, Valentin Spitkovsky and DipanjanDas for numerous discussions on this topic and com-ments on earlier drafts of this paper.
We wouldalso like to thank Shay Cohen, Dipanjan Das, NoahSmith and Anders S?gaard for sharing early draftsof their recent related work.ReferencesT.
Berg-Kirkpatrick and D. Klein.
2010.
Phylogeneticgrammar induction.
In Proc.
of ACL.P.
Blunsom and T. Cohn.
2010.
Unsupervised inductionof tree substitution grammars for dependency parsing.Proc.
of EMNLP.P.
F. Brown, V. J. Della Pietra, S. A. Della Pietra, andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: parameter estimation.
Computa-tional Linguistics, 19.S.
Buchholz and E. Marsi.
2006.
CoNLL-X sharedtask on multilingual dependency parsing.
In Proc.
ofCoNLL.D.
Burkett, S. Petrov, J. Blitzer, and D. Klein.
2010.Learning better monolingual models with unannotatedbilingual text.
In Proc.
of CoNLL.G.
Carroll and E. Charniak.
1992.
Two experiments onlearning probabilistic dependency grammars from cor-pora.
In Proc.
of the Working Notes of the WorkshopStatistically-Based NLP Techniques.M.W.
Chang, L. Ratinov, and D. Roth.
2007.
Guidingsemi-supervision with constraint-driven learning.
InProc.
of ACL.M.
Chang, D. Goldwasser, D. Roth, and V. Srikumar.2010.
Structured output learning with indirect super-vision.
In Proc.
of ICML.E.
Charniak.
2000.
A maximum-entropy-inspired parser.In Proc.
of NAACL.S.
Clark and J. R. Curran.
2004.
Parsing the WSJ usingCCG and log-linear models.
In Proc.
of ACL.S.B.
Cohen and N.A.
Smith.
2009.
Shared logistic nor-mal distributions for soft parameter tying in unsuper-vised grammar induction.
In Proc.
of NAACL.S.B.
Cohen, D. Das, and N.A.
Smith.
2011.
Unsuper-vised structure prediction with non-parallel multilin-gual guidance.
In Proc.
of EMNLP.M.
Collins, J.
Hajic?, L. Ramshaw, and C. Tillmann.
1999.A statistical parser for Czech.
In Proc.
of ACL.M.
Collins.
1997.
Three generative, lexicalised modelsfor statistical parsing.
In Proc.
of ACL.M.
Collins.
2002.
Discriminative training methods forhidden markov models: Theory and experiments withperceptron algorithms.
In Proc.
of ACL.D.
Das and S. Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projections.In Proc.
of ACL-HLT.K.
Ganchev, J. Gillenwater, and B. Taskar.
2009.
De-pendency grammar induction via bitext projection con-straints.
In Proc.
of ACL-IJCNLP.K.
Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.2010.
Posterior regularization for structured latentvariable models.
Journal of Machine Learning Re-search.D.
Gildea.
2001.
Corpus variation and parser perfor-mance.
In Proc of EMNLP.K.
Hall, R. McDonald, J. Katz-Brown, and M. Ringgaard.2011.
Training dependency parsers by jointly optimiz-ing multiple objectives.
In Proc.
of EMNLP.R.
Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Ko-lak.
2005.
Bootstrapping parsers via syntactic projec-tion across parallel texts.
Natural Language Engineer-ing, 11(03):311?325.D.
Klein and C. D. Manning.
2004.
Corpus-based induc-tion of syntactic structure: models of dependency andconstituency.
In Proc.
of ACL.P.
Koehn.
2005.
Europarl: A parallel corpus for statisti-cal machine translation.
In MT Summit.M.
P. Marcus, Mary Ann Marcinkiewicz, and BeatriceSantorini.
1993.
Building a large annotated corpus ofEnglish: the Penn treebank.
Computational Linguis-tics, 19.D.
McClosky, E. Charniak, and M. Johnson.
2006.Reranking and self-training for parser adaptation.
InProc.
of ACL.71R.
McDonald, K. Crammer, and F. Pereira.
2005.
Onlinelarge-margin training of dependency parsers.
In Proc.of ACL.T.
Naseem, H. Chen, R. Barzilay, and M. Johnson.
2010.Using universal linguistic knowledge to guide gram-mar induction.
In Proc.
of EMNLP.J.
Nivre and J. Nilsson.
2005.
Pseudo-projective depen-dency parsing.
In Proc.
of ACL.J.
Nivre, J.
Hall, and J. Nilsson.
2006.
Maltparser: Adata-driven parser-generator for dependency parsing.In Proc.
of LREC.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nils-son, S. Riedel, and D. Yuret.
2007.
The CoNLL2007 shared task on dependency parsing.
In Proc.
ofEMNLP-CoNLL.J.
Nivre.
2008.
Algorithms for deterministic incremen-tal dependency parsing.
Computational Linguistics,34(4):513?553.S.
Petrov, L. Barrett, R. Thibaux, and D. Klein.
2006.Learning accurate, compact, and interpretable tree an-notation.
In Proc.
of ACL.S.
Petrov, P. Chang, M. Ringgaard, and H. Alshawi.2010.
Uptraining for accurate deterministic questionparsing.
In EMNLP ?10.S.
Petrov, D. Das, and R. McDonald.
2011.
A universalpart-of-speech tagset.
In ArXiv:1104.2086.Y.
Seginer.
2007.
Fast unsupervised incremental parsing.In Proc.
of ACL.L.
Shen and A.K.
Joshi.
2008.
Ltag dependency parsingwith bidirectional incremental construction.
In Proc.of EMNLP.N.A.
Smith and J. Eisner.
2005.
Contrastive estimation:Training log-linear models on unlabeled data.
In Proc.of ACL.D.A.
Smith and J. Eisner.
2009.
Parser adaptation andprojection with quasi-synchronous grammar features.In Proc.
of EMNLP.D.A.
Smith and N.A.
Smith.
2004.
Bilingual parsingwith factored estimation: Using english to parse ko-rean.
In Proc.
of EMNLP.B.
Snyder, T. Naseem, J. Eisenstein, and R. Barzilay.2009.
Adding more languages improves unsupervisedmultilingual part-of-speech tagging: A Bayesian non-parametric approach.
In Proc.
of NAACL.A.
S?gaard.
2011.
Data point selection for cross-language adaptation of dependency parsers.
In Proc.ACL.V.I.
Spitkovsky, H. Alshawi, and D. Jurafsky.
2010.From baby steps to leapfrog: How ?less is more?
in un-supervised dependency parsing.
In Proc.
of NAACL-HLT.S.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM-basedword alignment in statistical translation.
In Proc.
ofCOLING.W.
Wang and M. P. Harper.
2004.
A statistical con-straint dependency grammar (CDG) parser.
In Proc.
ofthe Workshop on Incremental Parsing: Bringing Engi-neering and Cognition Together.D.
Zeman and P. Resnik.
2008.
Cross-language parseradaptation between related languages.
In NLP for LessPrivileged Languages.Y.
Zhang and S. Clark.
2008.
A Tale of TwoParsers: Investigating and Combining Graph-basedand Transition-based Dependency Parsing.
In Proc.of EMNLP.72
