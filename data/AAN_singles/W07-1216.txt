Proceedings of the 5th Workshop on Important Unresolved Matters, pages 120?127,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsFips, a ?Deep?
Linguistic Multilingual ParserEric WehrliLATL-Dept.
of LinguisticsUniversity of GenevaEric.Wehrli@lettres.unige.chAbstractThe development of robust ?deep?
linguis-tic parsers is known to be a difficult task.Few such systems can claim to satisfy theneeds of large-scale NLP applications interms of robustness, efficiency, granular-ity or precision.
Adapting such systemsto more than one language makes the taskeven more challenging.This paper describes some of the proper-ties of Fips, a multilingual parsing sys-tem that has been for a number of years(and still is) under development at LATL.Based on Chomsky?s generative grammarfor its grammatical aspects, and on object-oriented (OO) sofware engineering tech-niques for its implementation, Fips is de-signed to efficiently parse the four Swiss?national?
languages (German, French,Italian and English) to which we alsoadded Spanish and (more recently) Greek.1 IntroductionThis papers describes the Fips project, whichaims at developing a robust, multilingual ?deep?linguistic parsing system efficient enough for awide-range of NLP applications.
The systemis currently available for six languages (English,French, German, Italian, Spanish and Greek), andhas been extensively used for terminology extrac-tion (Seretan & Wehrli, 2006), as well as for ter-minology assistance and translation (Wehrli, 2004,2006).This paper is organized as follows.
The nextsection gives an overview of the Fips parser, de-scribing some of its linguistic properties and itsmain processes.
In section 3, we present theobject-oriented design adopted for the project.Section 4 discusses some cases of cross-linguisticsyntactic variation.
Finally, section 5 providessome details about the results and presents an eval-uation of the parser for the six languages.2 The Fips parserFips is a robust ?deep?
linguistic parser which as-signs to an input sentence an enriched S-structuretype of representation, along with a predicate-argument representation.
Fips can also be usedas a tagger, outputing for each word of a givensentence a POS-tag and optionally the grammat-ical function (associated to the first word of a con-stituent), the base form (citation form) of the word,and whether a word is part of an expression or acollocation.As an illustation, figure 1 shows the enrichedstructure representation and figure 2 the POS-tagsreturned by Fips for sentence (1).
Notation is ex-plained below.
(1) The record she broke was very old.
[TP[DPthe [NPrecordi [ CP [ DP e]i [ TP [ DPshe ] broke [DPe]i ] ] ] ] was [FP [AP [Adv very] old ] ] ]Figure 1: Enriched S-Structure representation forsentence (1)The linguistic assumptions used in this projectcorrespond roughly to a free-adaptation of Chom-sky?s generative linguistics, borrowing conceptsfrom the Minimalist model (Chomsky, 1995,2004), from the Simpler Syntax model (Culicover& Jackendoff, 2005), as well as from LexicalFunctional Grammar (Bresnan, 1982, 2001).120word tag expressionthe DET-SINrecord NOM-SIN break-recordshe PRO-PER-SIN-FEMbroke VER-PAS-3-SIN break-recordwas VER-PAS-3-SINvery ADVold ADJFigure 2: POS-tag output for sentence (1)Roughly, the grammar is lexicalist, exploiting arich lexicon which specifies, among others,?
the selectional properties of functional ele-ments such as prepositions, auxiliaries, deter-miners, etc.
For instance, the English auxil-iary have selects a [+past participle] verbalprojection.
Similarly, in German, werden se-lects an infinitival verbal complement;?
arguments selected by predicative heads(nouns, verbs, adjectives);?
other syntactic or semantic features whichmight be relevant for syntactic processingsuch as [+pronominal] feature associated tocertain verbs in French, Italian, German, etc.,types and subtypes of adverbs, control prop-erties of verbs selecting infinitival comple-ments, and so on.As shown in figure 1 above, the fundamentalstructures built by Fips all follow the same pat-tern, that is : LeftSubconstituents Head RightSub-constituents, which can be abbreviated as L X R,where L stands for the (possibly empty) list ofleft subconstituents, X for the (possibly empty)head of the phrase and R for the (possibly empty)list of right subconstituents.
The possible val-ues for X are the usual lexical categories Adverb,Adjective, Noun, Determiner, Verb, Preposition,Complementizer, Interjection.
To this list we addthe functional category Tense, which is the headof a sentence (TP), as well as Functional, used torepresent predicative objects headed either by anadjective, an adverb, a noun or a preposition.Compared to current mainstream Chomskyanrepresentations, Fips constituent structures are rel-atively flat and make a rather parsimonious use offunctional projections.
They do, however, containempty categories, either to represent empty sub-jects, for instance in infinitival complements, rep-resented as sentences with a (usually lexically un-realized) subject.
Empty categories are also usedto represent ?traces?
of extraposed constituents, asin wh-constructions, where a chain of coindexedconstituents is computed, headed by the extra-posed element and footed by its ?trace?, an emptyconstituent in argument or adjunct position.
Anexample of such chain is given in figure 1, wherethe noun record is first coindexed with the (lex-ically unrealized) relative pronoun in the speci-fier position of the CP constituent, which is itselfrelated to the empty constituent [DPe]i in thecanonical direct object position of the verb formbroke.Although quite complex, the computation ofsuch chains brings many benefits in terms of qual-ity and accuracy of the analysis.
One clear exam-ple is provided by the identification of collocation,as exemplified in example (1) with the collocationbreak-record.
In that sentence, the two terms ofthe collocation do not occur in the expected orderand do not even occur in the same clause, sincerecord is the subject of the main clause, whilebroke is in the relative clause.
However, as thestructure give in fig.
1 shows, the presence of the?trace?
of record in the direct object position ofthe verb form broke makes the identification of thecollocation rather simple, and fig.
2 confirms thatFips has indeed recognized the collocation.The grammar itself consists of both rules andprocesses.
Rules specify the attachment of con-stituents, thus determining, at least for the mainpart, the constituent structure associated to a sen-tence.
The grammatical processes, which roughlycorrespond to some of the earlier transformationrules of Generative Grammar, are primarily re-sponsible for tasks such as:?
filling up the argument table associated withpredicative elements (mostly verbs);?
chain formation, ie.
establishing a link be-tween an extraposed element, such as a wh-element and an empty category in an argu-ment or adjunct canonical position;?
modifications of the argument structure ofpredicates (adding, deleting, modifying argu-ments), as is necessary to account for passiveor Romance causative constructions;?
coordination or enumeration structures.121In all such cases, the claim is that a proceduralaccount is simpler than a rule-based description,leading furthermore to a more efficient implemen-tation.3 Object-oriented designThe computational model adopted for the Fipsproject relies on object-oriented (OO) concepts(see, for instance, Mo?ssenbo?ck, 1995).
An ab-stract model is assumed both for objects andfor their associated procedures (usually called?methods?
in OO-jargon) ?
roughly correspond-ing to the ?universal?
linguistic level ?
from whichlanguage-specific objects and procedures are de-rived.
In other words, linguistic objects are definedas abstract data types, whose implementation canvary from language to language.
Such variationis handled by the type extension feature providedby OO-models when the variation concerns datastructures or by the procedure redefinition featurewhen variation concerns a process.Fips relies on three main objects:?
lexical units (LexicalItem), which correspondto the ?words?
of a language, as they appearin the lexical database;?
syntactic projections (Projection), which arethe syntactic constituents;?
items (Item), which correspond to an analysis(partial or complete) ?
since the parser uses aparallel strategy, many items are maintainedthroughout the parsing process.The main procedures (methods) associated tothose objects are Project, Merge and Move, cor-responding to the operation of projection, combi-nation and movement, respectively.
The followingsubsections will briefly discuss them in turn.3.1 ProjectThe projection mechanism creates a syntacticconstituent (an object of type Projection in ourmodel), either on the basis of a lexical object, or onthe basis of another syntactic constituent.
For in-stance, any lexical item, as computed and retrievedfrom the lexical database by the lexical analysis isprojected into a syntactic constituent, with the lex-ical item as its head.
Thus, given lex, a lexicalitem, lex.Project(p) creates a syntactic projectionp headed by lex, as in example (2):(2)a. chat ??
[NPchat ]b. eine ??
[DPeine ]c. with ??
[PPwith ]A more powerful variant of the projectionmechanism, called metaprojection, can createricher syntactic constituents based either on spe-cific lexical items or on other syntactic projec-tions.
For instance, we consider pronouns to benominal-type lexical elements which project to aDP level.
Similarly, verbs are taken as sentenceheads, and will therefore give rise to richer syn-tactic constituents, as illustrated in the followingexamples:(3)a. pronouns[DP[NPtoi ] ]b. mangeras (?will-eat?
)[TPmangerasi [ VP ei ] ]c. reads[TP[VPreads ] ]d. regnet (?rains?
)[CPregneti [ TP [ VP ei ] ] ]Notice that the position of the tensed verb is dif-ferent in the the structures given in (3b,c,d).
Weassume that tensed verbs in French (and more gen-erally in Romance) ?move?
to the head of TP, asshown in (3b), while such movement does not oc-cur in English (3c).
An even more drastic exampleof metaprojection occurs in German, where we as-sume that a whole clause structure is projected onthe basis of a tensed verb (in matrix clause), as il-lustrated in (3d).3.2 MergeMerge is the fundamental combination mechanismin our parsing model.
Each time the parser readsa word, it is first transformed into a syntacticconstituent, a projection, as we have just seen.The projection, in turn, must now be combined(merged) with (partial or complete) constituentsin its immediate left context.
Two scenarios areconsidered, corresponding to left attachment andto right attachment.
Left attachment occurs whenthe projection in the left context of the new pro-jection can be attached as a left subconstituent ofthe new projection.
Right attachment correspondsto the situation where the new projection can beattached as a right subconstituent of the projectionin its left context.
In fact, to be more accurate, the122incoming projection can attach as a subconstituentnot just of the projection in its left context, but toany active node of it, as illustrated in Figure 3 be-low:Merge must be validated either by lexical prop-erties such as selectional features or by generalproperties (adverbs, adjuncts, parentheticals canrelatively freely modify projections).TP         ......theLeft context: Active node stack :Constituent to be attached :boyeatenhasabigice?creamNPAPDPVPDPNP         Figure 3: Active node stack3.3 MoveAlthough the general architecture of surface struc-tures results from the combination of projectionand merge operations, an additional mechanismis necessary to satisfy well-formedness conditionssuch as thematic assignment.
As mentioned ear-lier, such a mechanism reveals quite useful for thecollocation identification process (cf.
fig.
2).
Thismechanism handles extraposed elements and linkthem to empty constituents in canonical positions,thereby creating a chain between the base (canoni-cal) position and the surface (extraposed) positionof the moved constituent.
To take another simpleexample, let us consider the interrogative sentencegiven in (4a) and the (slightly simplified) associ-ated structure in (4b):(4)a. who did you invite ?b.
[ CP [ DP who]i didj [ TP [ DP you ] ej [ VPinvite [DPe]i ] ] ]The chain mechanism functions as follows: asthe parser encounters a wh-word in an extraposedposition, it stores it in a stack associated with itsgoverning category (typically the CP projectionwhich dominates it).
As the parse proceeds, thestack is transferred along the right edge of thestructure, provided it does violate island condi-tions (cf.
Ross, 1967).
Whenever a predicative el-ement is added to the structure, an attempt is madeto complete the chain, ie.
to interpret the projec-tion on top of the stack with respect to the predi-cate.
If successful, an empty category coindexedwith the extraposed projection is inserted into thestructure and the projection is removed from thestack.
At the end of the parse, items containingunresolved chains are heavily penalized.3.4 A parsing exampleTo illustrate the parsing procedure and the inter-action of the 3 mechanisms described above, con-sider the following simple sentence in French.(5)a.
Paul mange une pomme.
?Paul eats an apple?b.
[TP[DP[NPPaul ] ] mangei [VP e i [DP une[NPpomme ] ] ] ]Step 1 the parser reads ?Paul?
and metaprojects aDP structure [DP[NPPaul ] ].Step 2 the parser reads ?manges?
and metapro-jects a TP-VP structure [TPmangei [ VP ei ]].
A merge operation is possible with the pre-ceding DP structure, which yields [TP[DP[NPPaul ] ] mangei [ VP ei ] ].Step 3 the parser reads the determiner ?une?
andcreates a DP structure [DPune ].
A merge op-eration is possible with the left-adjacent TPconstituent, with DP attached as right con-stituent of the internal VP node [TP[DP[NPPaul ] ] mangei [ VP ei [ DP une ] ] ].Step 4 the parser reads the noun ?pomme?, cre-ates an NP structure [NPpomme ], and attachit (merge operation) as a right constituent ofthe DP structure in the TP structure, whichyields the complete structure (5b).3.5 The grammarMerge operations are constrained by variousmostly language-specific conditions which can bedescribed by means of rules.
Those rules arestated in a pseudo formalism which attempts to beboth intuitive for linguists and relatively straight-forward to code.
The conditions associated to therules take the form of boolean functions, as de-scribed in the examples (6) for left attachments123and in the examples (7) for right attachments,where a and b refer, respectively, to the first andto the second constituent of a merge operation.(6)a.
AP + NPa.HasFeat(prenominal)a.AgreeWith(b, {gender, number})b. DP + NPa.HasSelectionFeat( nCompl)a.AgreeWith(b,{gender, number, case})Rule 6a specifies that an adjective projectionstructure (an AP constituent) can (left-)merge witha noun projection structure (an NP constituent) un-der the two conditions (i) that the first constituent(the adjective) bears the feature prenominaland (ii) that both constituents agree in number andgender.
This rule, which is part of our Frenchgrammar, will allow for petit animal (?small ani-mal?
), but not pre?historique animal (?prehistoricalanimal?
), since the adjective pre?historique doesnot bear the feature [+prenominal], nor pe-tit animaux (?small animals?
), since petit is singu-lar while animaux is plural and hence both do notagree in number.Rule (6b) is taken from our German grammar.
Itstates that a common noun can be (right-)attachedto a determiner phrase, under the conditions (i)that the head of the DP bears the selectional fea-ture [+Ncomplement] (ie.
the determiner se-lects a noun), and (ii) the determiner and the nounagree in gender, number and case.3.6 Procedural grammarOne of the original features of the Fips parser is itsprocedural approach to several grammatical prop-erties.
In addition to the chain mechanism de-scribed in the previous section, the procedural ap-proach also concerns the treatment of passive andother restructuring constructions, as well as coor-dination.
The next two paragraphs briefly sketchour treatment of passive and coordination con-structions.3.6.1 passivesAlong with many linguists or various persua-sions, we assume that the fundamental propertyof passives is the elimination (or demotion) of thesubject argument of a predicate.
Based on thatassumption, our treatment is essentially a case ofargument-structure modification: demotion of thesubject argument to an optional ?by-phrase?
ar-gument, promotion of the direct object argumentto the subject argument slot.
In our implemen-tation, the treatment of passives takes the formof a grammar rule specifying the attachment of a[+past participle] verbal projection as complementof the passive auxiliary.
This attachment triggersthe restructuring process described above1.3.6.2 coordinationCoordinate structures constitute a well-knownproblem for both theoretical and computationallinguistics.
For the latter, coordination is prob-lematic because it is a major source of non-determinism.
Given the fact that such structuresare extremely common in both speech and writ-ing, it is therefore mandatory for NLP systems tohandle them efficiently.
Our treatment of coordi-nation is based on the following assumptions:?
Coordination can affect any pair of like con-stituents;?
coordinate structures do not strictly obey theX schema.
They have the following structure:[XP[ ConjP XP Conj XP ] ], where X takesits value in the set of lexical categories aug-mented by T and F (see section 2 above), andCONJ is a coordination conjunction (eg.
and,or, but, etc.
).The coordination procedure is triggered by thepresence of a conjunction.
All the nodes on theright edge of the constituent in its immediate leftcontext are considered potential candidates for thecoordination structure.
A metaprojection createsa coordinate projection, in which the node on theright edge is the left subconstituent of the conjunc-tion.
The set of such projections is quickly filteredout by further incoming material.To illustrate our treatment of coordinate struc-tures, in particular the type of structure we assume(slightly simplified in the (8) sentences) as well asthe potential ambiguity of coordination, considerthe following simple English examples.(7)a.
the old men and womenb.
[DP[ConjP [ DP the [ NP [ AP old ] men ] ]and ] [DP[NPwomen ] ] ]c. [DPthe [NP[APold ] [ConjP [NP men ] and[NPwomen ] ] ] ]1The same restructuring process applies to particial struc-tures, as in John left the room, followed by his dog.124d.
[DPthe [NP[ ConjP [ NP [ A old ] men ] ]and ] [NPwomen ] ](8)a. John believes Bill and Mary will be to blame.b.
John believes [TP[DPBill and Mary ] willbe to blame ]c. [TPJohn believes Bill ] and [TPMary willbe to blame ]4 Examples of cross-linguistic variationIn the Fips system, language variation occurs notonly at the level of the grammar, as expected, butalso at the level of the associated procedures.
Con-sider for example, the case of the argument check-ing procedure.
Whereas a preverbal DP can be in-terpreted as the subject of a verb if it agrees withit (number, person) in languages such as Frenchor English (as well as other so-called ?configu-rational languages?
), the same criteria would nothold for case-marked languages, such as Germanor Modern Greek.
In those languages, subjectscan essentially occur anywhere in the sentence butmust be marked [+nominative] and of courseagree with the verb (number, person)2.
Relativelysimilar at an abstract level, the argument check-ing procedure must be ?tuned?
for each individuallanguage.Our second example of cross-linguistic varia-tion concerns clitic pronouns.
The relevant datastructures (objects) and interpretation procedures(methods) to handle clitics are defined at an ab-stract level.
Specific languages (ie.
Spanish, Ital-ian, French, Greek, etc.)
inherit those objectsand methods, which they can further specialize ac-cording to language-specific properties and con-straints.
The general mechanism to handle cliticscomprises two distinct steps: attachment and in-terpretation3 .
As a clitic is read (as an independentword or as an orthographically attached affix), it isattached to the head of the verb form which fol-lows it (proclitic) or which precedes it (enclitic).Since this verbal head is not necessarily the onewith respect to which the clitic pronoun can be in-terpreted (it might be an auxiliary, for instance),2We assume that German (and Modern Greek) are so-called scrambling languages with an unmarked basic wordorder (cf.
Haider and Rosengren, 1998, Hinterho?lzl, 2006).3From now on, the discussion will only focus on Romanceclitics.a temporary data structure is used to store cliticsuntil the parser has identified the main predicateof the sentence4 .
Only then can the interpretationprocess start.
All the clitics in the temporary datastructure must be interpreted either as argument oras adjunct of the verb5.
The examples below il-lustrate our analysis of clitics, applied to Italian(9), French (10) and Spanish (11).
The Italian andFrench examples display proclitics (pre-verbal cl-itics), while the Spanish example is a case of encl-itics (post-verbal clitics).
Notice also that in Ital-ian and Spanish we have clitic clusters (two cliticsconcatenated in one orthographical word), and inthe Spanish example, the cluster is itself concate-nated to the verb.
In all three examples, the cliticpronouns have be properly analyzed, ie.
inter-preted as arguments of the verb.
This is expressedin the resulting structures by the chains connect-ing a pronoun and an empty category in postverbalposition.
As in the wh-chains discussed earlier, allthe elements are coindexed.(9)a.
Glielo ho dato.
(?I have given it to him?)b.
[TP[DPe ] glii-loj ho [VP dato [PP ei ] [DPej ] ] ](10)a. Paul le lui a donne?.
(?Paul has given it tohim?)b.
[TP[DPPaul ] lei luij a [ VP donne?
[ DP ei ][PPej ] ] ](11)a. Da?mmelo.
(?Give it to me?)b.
[TP[DPe ] dai-mej-lok [ VP ei [ PP ej ] [ DPek ] ] ]Although very similar in their fundamental be-havior, clitics across Romance languages are nev-ertheless too different to be handled by exactlythe same mechanism.
Furthermore, even if suchmechanism could be implemented, chances arethat it would prove insufficient or inadequate insome ways to handle an additional Romance lan-guage such as Romanian or Portuguese.
Our ap-proach, based on a general abstract mechanism,which can be specialized to suit the specific prop-erties of each language seems therefore more ap-propriate.4This temporary structure is also used to check the well-formedness of clitic sequences.5For the sake of simplicity, we will leave aside a few morecomplex cases, such as French clitic ?en?
corresponding tocomplements of the direct object of the main verb (Paul enconna?
?t la raison ?Paul knows the reason of it?)
or so-called?long-distance?
clitics in Italian or Spanish restructurationconstructions.1255 Results and evaluationTo date, the Fips multilingual parser has been de-veloped for 6 languages (English, French, Ger-man, Italian, Spanish and Greek).
Other lan-guages have been very partially treated, such asRomanian, Russian, Polish and Romansch Sursil-van.A significant effort has been made at the lexicallevel, qualitatively and quantitatively.
The table infigure 4 below shows the curren approximate sizeof each lexicon.language lexemes words collocationsanglais 54?000 90?000 5?000franc?ais 37?000 227?000 12?500allemand 39?000 410?000 2?000italien 31?000 220?000 2?500espagnol 22?500 260?000 320grec 12?000 90?000 225Figure 4: Number of entries in the lexical databaseAt the grammar level, the coverage of the Eng-lish and French grammar is quite satisfactory, Ital-ian, Spanish and especially German still need im-provements, while the Greek grammar is very par-tial.Fips attempts to produce complete analyzesfor input sentences.
Since the parsing strategyis (pseudo-)parallel, many analyzes are producedand ranked according to preferences such as localvs.
non-local attachments, argument vs. adjunctinterpretation, presence vs. absence of a collo-cation, etc.
When a complete analysis fails, theparser outputs a sequence of partial analyzes cov-ering the whole sentence.A comparative evaluation has been conductedto show how the various implementations of Fipscompare with respect to a near identical cor-pus, the European Parliament corpus (cf.
Koehn,2005).
We parsed approximately 1 million wordsin each of the six languages.
The table given infigure 5 show the results:The first line in table 5 show the size of each filein terms of symbols (word, punctuation, format-ting symbol, etc.
), approximately 1 million sym-bols for each file.
The second line gives the num-ber of unknown words, not counting words start-ing with an uppercase letter which are assumedto be proper nouns (given the fact that in Ger-man common nouns are capitalized, we did notleave aside capitalized unknown words for thatlanguage).
The third line indicates the numberof sentences approximately 40?000 for each file,slightly more for the German file.
We can seethat the average length of a sentence is roughly20 to 25 symbols (slightly more for French).
Thefourth line shows the percentage of sentences forwhich Fips returned a complete analysis.
The bestscore is obtained with English (71.95%), closelyfollowed by French (70.01%).
Greek is clearlybehind with only about 31%, largely due to thefact that its grammar as well as its lexicon havereceived much less attention so far.
We can ob-serve a quite clear (and unsurprising) correlationbetween rich lexical coverage (English, French)and high number of complete analyzes.Finally the last line shows the speed of theparser in terms of number of words per second.The mean speed of Fips is between 130 and 180word/second.
FipsGreek is somewhat faster, pre-sumably because its grammar is less developedthan the grammar of the other languages at thispoint.
It came up as a surprise to see that FipsEn-glish was clearly slower.
The reason has probablyto do with the high number of lexical ambiguitiesof the type N/V (e.g.
lead, study, balance, need)which are likely to significantly increase the num-ber of parallel (partial) analyzes.6 Concluding remarksAlthough the research described in this paper isby no means completed, it has already achievedseveral important goals.
First of all, it has shownthat ?deep linguistic parsing?
should not neces-sarily be equated with ?inefficient parsing?.
Al-though clearly slower than shallow parsers, Fips isfast enough for such demanding tasks as transla-tion or terminology extraction.At the software level, the adopted design makesit possible to ?plug?
an additional language with-out any change or any recompilation of the sys-tem.
It is sufficient to add the language-specificmodules and lexical databases to have a fully func-tional parser for that language.
Arguably themodel has so far not been tested with languagesbelonging to widely distinct language types.
Infact, it has only been applied to (a small set) of Eu-ropean languages.
Future work will address thatissue, and we are planning to extend our work to-wards Asian and Semitic languages.126language German English Spanish French Greek Italiannumber of symbols 1082117 1046431 1041466 1144345 1045778 998871unknown words 13569 879 6825 853 26529 3099number of sentences 45880 40348 40576 38653 39812 37726% of complete analyzes 48.04% 71.95% 56.87% 70.01% 30.99% 58.74%speed (word/second) 138 82 127 133 243 182Figure 5: Comparative evaluation of the parsersAcknowledgementThanks to Luka Nerima, Christopher Laenzlinger,Gabriele Musillo and Antonio Leoni de Leo?n forvarious suggestions and comments on earlier ver-sions of this paper.
The research described herehas been supported in part by a grant from theSwiss national science foundation (no 101412-103999).7 ReferencesBresnan, J.
(e?d.
), 1982.
The Mental Representa-tion of Grammatical Relations, Cambridge,Mass., MIT Press.Bresnan, J., 2001.
Lexical Functional Syntax, Ox-ford, Blackwell.Chomsky, N. 1995.
The Minimalist Program,Cambridge, Mass., MIT Press.Chomsky, N. 2004.
?Beyond Explanatory Ade-quacy?, in A. Belletti (ed.)
The Cartographyof Syntactic Structures, Oxford, Oxford Uni-versity Press.Culicover, P. et R. Jackendoff, 2005.
Simpler Syn-tax, Oxford, Oxford University Press.Haider, H. and I. Rosengren 1998.
?Scrambling?Sprache und Pragmatik 49, Lund University.Hinterho?lzl, R. 2006.
Scrambling, RemnantMovement and Restructuring in West Ger-manic, Oxford, Oxford University Press.Koehn, Ph., 2005.
?Europarl: A Parallel Cor-pus for Statistical Machine Translation, MTSummit.Mo?ssenbo?ck, H. 1995.
Object-Oriented Program-ming in Oberon-2, New York, Springer.Ross, .R.
1967.
Constraints on Variables in Syn-tax, Ph.D. dissertation, MIT.Seretan, V. et E. Wehrli, 2006.
?Accurate colloca-tion extraction using a multilingual parser?
inProceedings of the 21st International Confer-ence on Computational Linguistics and 44thAnnual Meeting of the Association for Com-putational Linguistics (COLING/ACL 2006),Sydney, 952-960.Wehrli, E. 2004.
?Traduction, traduction de mots,traduction de phrases?, in B. Bel et I.
Marlien(eds.
), Proceedings of TALN XI, Fes, 483-491.Wehrli, E. 2006.
?TwicPen : Hand-held Scan-ner and Translation Software for non-NativeReaders?, in Proceedings of the 21st Interna-tional Conference on Computational Linguis-tics and 44th Annual Meeting of the Asso-ciation for Computational Linguistics (COL-ING/ACL 2006), Sydney.127
