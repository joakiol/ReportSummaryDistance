Proceedings of the ACL 2007 Demo and Poster Sessions, pages 209?212,Prague, June 2007. c?2007 Association for Computational LinguisticsHunPos ?
an open source trigram taggerPe?ter Hala?csyBudapest U. of TechnologyMOKK Media ResearchH-1111 Budapest, Stoczek u 2peter@halacsy.comAndra?s KornaiMetaCarta Inc.350 Massachusetts Ave.Cambridge MA 02139andras@kornai.comCsaba OraveczHungarian Academy of SciencesInstitute of LinguisticsH-1068 Budapest, Benczur u.
33.oravecz@nytud.huAbstractIn the world of non-proprietary NLP soft-ware the standard, and perhaps the best,HMM-based POS tagger is TnT (Brants,2000).
We argue here that some of the crit-icism aimed at HMM performance on lan-guages with rich morphology should moreproperly be directed at TnT?s peculiar li-cense, free but not open source, since it isthose details of the implementation whichare hidden from the user that hold the keyfor improved POS tagging across a widervariety of languages.
We present HunPos1,a free and open source (LGPL-licensed) al-ternative, which can be tuned by the user tofully utilize the potential of HMM architec-tures, offering performance comparable tomore complex models, but preserving theease and speed of the training and taggingprocess.0 IntroductionEven without a formal survey it is clear thatTnT (Brants, 2000) is used widely in researchlabs throughout the world: Google Scholar showsover 400 citations.
For research purposes TnT isfreely available, but only in executable form (closedsource).
Its greatest advantage is its speed, impor-tant both for a fast tuning cycle and when dealingwith large corpora, especially when the POS tag-ger is but one component in a larger information re-trieval, information extraction, or question answer-1http://mokk.bme.hu/resources/hunpos/ing system.
Though taggers based on dependencynetworks (Toutanova et al, 2003), SVM (Gime?nezand Ma`rquez, 2003), MaxEnt (Ratnaparkhi, 1996),CRF (Smith et al, 2005), and other methods mayreach slightly better results, their train/test cycle isorders of magnitude longer.A ubiquitous problem in HMM tagging originatesfrom the standard way of calculating lexical prob-abilities by means of a lexicon generated duringtraining.
In highly inflecting languages considerablymore unseen words will be present in the test datathan in more isolating languages, which largely ac-counts for the drop in the performance of n-gramtaggers when moving away from English.
To mit-igate the effect one needs a morphological dictio-nary (Hajic?
et al, 2001) or a morphological analyzer(Hakkani-Tu?r et al, 2000), but if the implementationsource is closed there is no handy way to incorporatemorphological knowledge in the tagger.The paper is structured as follows.
In Section 1we present our own system, HunPos, while in Sec-tion 2 we describe some of the implementation de-tails of TnT that we believe influence the perfor-mance of a HMM based tagging system.
We eval-uate the system and compare it to TnT on a varietyof tasks in Section 3.
We don?t necessarily considerHunPos to be significantly better than TnT, but weargue that we could reach better results, and so couldothers coming after us, because the system is opento explore all kinds of fine-tuning strategies.
Someconcluding remarks close the paper in Section 4.2091 Main features of HunPosHunPos has been implemented in OCaml, a high-level language which supports a succinct, well-maintainable coding style.
OCaml has a high-performance native-code compiler (Doligez et al,2004) that can produce a C library with the speedof a C/C++ implementation.On the whole HunPos is a straightforward trigramsystem estimating the probabilitiesargmaxt1...tTP (tT+1|tT )T?i=1P (ti|ti?1, ti?2)P (wi|ti?1, ti)for a given sequence of words w1 .
.
.
wT (the addi-tional tags t?1, t0, and tT+1 are for sentence bound-ary markers).
Notice that unlike traditional HMMmodels, we estimate emission/lexicon probabilitiesbased on the current tag and the previous tag as well.As we shall see in the next Section, using tag bi-grams to condition the emissions can lead to as muchas 10% reduction in the error rate.
(In fact, HunPoscan handle a context window of any size, but on thelimited training sets available to us increasing thisparameter beyond 2 gives no further improvement.
)As for contextualized lexical probabilities, our ex-tension is very similar to Banko and Moore (2004)who use P (wi|ti?1, ti, ti+1) lexical probabilitiesand found, on the Penn Treebank, that ?incorporat-ing more context into an HMM when estimating lex-ical probabilities improved accuracy from 95.87% to96.59%?.
One difficulty with their approach, notedby Banko and Moore (2004), is the treatment of un-seen words: their method requires a full dictionarythat lists what tags are possible for each word.
Tobe sure, for isolating languages such information isgenerally available from machine readable dictio-naries which are often large enough to make the outof vocabulary problem negligible.
But in our situ-ation this amounts to idealized morphological ana-lyzers (MA) that have their stem list extended so asto have no OOV on the test set.The strong side of TnT is its suffix guessing algo-rithm that is triggered by unseen words.
From thetraining set TnT builds a trie from the endings ofwords appearing less than n times in the corpus, andmemorizes the tag distribution for each suffix.2 A2The parameter n cannot be externally set ?
it is docu-mented as 10 but we believe it to be higher.clear advantage of this approach is the probabilis-tic weighting of each label, however, under defaultsettings the algorithm proposes a lot more possibletags than a morphological analyzer would.
To facil-itate the use of MA, HunPos has hooks to work witha morphological analyzer (lexicon), which mightstill leave some OOV items.
As we shall see inSection 3, the key issue is that for unseen wordsthe HMM search space may be narrowed down tothe alternatives proposed by this module, which notonly speeds up search but also very significantlyimproves precision.
That is, for unseen words theMA will generate the possible labels, to which theweights are assigned by the suffix guessing algo-rithm.2 Inside TnTHere we describe, following the lead of (Jurish,2003), some non-trivial features of TnT sometimesonly hinted at in the user guide, but clearly evidentfrom its behavior on real and experimentally ad-justed corpora.
For the most part, these features areclever hacks, and it is unfortunate that neither Brants(2000) nor the standard HMM textbooks mentionthem, especially as they often yield more signifi-cant error reduction than the move from HMM toother architectures.
Naturally, these features are alsoavailable in HunPos.2.1 CardinalsFor the following regular expressions TnT learns thetag distribution of the training corpus separately togive more reliable estimates for open class items likenumbers unseen during training:?[0-9]+$?[0-9]+\.$?[0-9.,:-]+[0-9]+$?
[0-9]+[a-zA-Z]{1,3}$(The regexps are only inferred ?
we haven?t at-tempted to trace the execution.)
After this, at testtime, if the word is not found in the lexicon (nu-merals are added to the lexicon like all other items)TnT checks whether the unseen word matches someof the regexps, and uses the distribution learned forthis regexp to guess the tag.2102.2 Upper- and lowercaseThe case of individual words may carry relevant in-formation for tagging, so it is well worth preservingthe uppercase feature for items seen as such in train-ing.
For unseen words TnT builds two suffix tries:if the word begins with uppercase one trie is used,for lowercase words the other trie is applied.
Theundocumented trick is to try to lookup the word insentence initial position from the training lexicon inits lowercase variant, which contributes noticeablyto the better performance of the system.3 EvaluationEnglish For the English evaluation we used theWSJ data from Penn Treebank II.
We extracted sen-tences from the parse trees.
We split data into train-ing and test set in the standard way (Table 1).Set Sect?ns Sent.
Tokens UnseenTrain 0-18 38,219 912,344 0Test 22-24 5,462 129,654 2.81%Table 1: Data set splits used for EnglishAs Table 2 shows HunPos achieves performancecomparable to TnT for English.
The increase in theemission order clearly improves this performance.seen unseen overallTnT 96.77% 85.91% 96.46%HunPos 1 96.76% 86.90% 96.49%HunPos 2 96.88% 86.13% 96.58%Table 2: WSJ tagging accuracy, HunPos with firstand second order emission/lexicon probabilitiesIf we follow Banko and Moore (2004) and con-struct a full (no OOV) morphological lexicon fromthe tagged version of the test corpus, we obtain96.95% precision where theirs was 96.59%.
Forwords seen, precision improves by an entirely neg-ligible 0.01%, but for unseen words it improves by10%, from 86.13% to 98.82%.
This surprising resultarises from the fact that there are a plenty of unam-biguous tokens (especially the proper names that areusually unseen) in the test corpus.What this shows is not just that morphology mat-ters (this is actually not that visible for English), butthat the difference between systems can only be ap-preciated once the small (and scantily documented)tricks are factored out.
The reason why Banko andMoore (2004) get less than HunPos is not becausetheir system is inherently worse, but rather becauseit lacks the engineering hacks built into TnT andHunPos.Hungarian We evaluated the different modelsby tenfold cross-validation on the Szeged Corpus(Csendes et al, 2004), with the relevant data in pre-sented Table 3.Set Sent.
Tokens Unseens OOVTrain 63,075 1,044,914 0 N.ATest 7,008 116,101 9.59% 5.64%Table 3: Data set splits used for Hungarian.Note that the proportion of unseen words, nearly10%, is more than three times higher than in En-glish.
Most of these words were covered by the mor-phological analyzer (Tro?n et al, 2006) but still 28%of unseen words were only guessed.
However, thisis just 2.86% of the whole corpus, in the magnitudesimilar to English.morph lex order seen unseen overallno1 98.34% 88.96% 97.27%2 98.58% 87.97% 97.40%yes 1 98.32% 96.01% 98.03%2 98.56% 95.96% 98.24%Table 4: Tagging accuracy for Hungarian of HunPoswith and without morphological lexicon and withfirst and second order emission/lexicon probabili-ties.On the same corpus TnT had 97.42% and Hala?csyet al (2006) reached 98.17% with a MaxEnt tag-ger that used the TnT output as a feature.
HunPosgets as good performance in one minute as this Max-Ent model which took three hours to go through thetrain/test cycle.4 Concluding remarksThough there can be little doubt that the ruling sys-tem of bakeoffs actively encourages a degree of one-upmanship, our paper and our software are not of-fered in a competitive spirit.
As we said at the out-211set, we don?t necessarily believe HunPos to be in anyway better than TnT, and certainly the main ideashave been pioneered by DeRose (1988), Church(1988), and others long before this generation ofHMM work.
But to improve the results beyond whata basic HMM can achieve one needs to tune the sys-tem, and progress can only be made if the experi-ments are end to end replicable.There is no doubt many other systems could betweaked further and improve on our results ?
whatmatters is that anybody could now also tweak Hun-Pos without any restriction to improve the state ofthe art.
Such tweaking can bring surprising results,e.g.
the conclusion, strongly supported by the resultspresented here, that HMM tagging is actually quitecompetitive with, and orders of magnitude fasterthan, the current generation of learning algorithmsincluding SVM and MaxEnt.
No matter how goodTnT was to begin with, the closed source has hin-dered its progress to the point that inherently clum-sier, but better tweakable algorithms could overtakeHMMs, a situation that HunPos has now hopefullychanged at least for languages with more complexmorphologies.AcknowledgementWe thank Thorsten Brants for TnT, and Gyo?rgyGyepesi for constant help and encouragement.ReferencesMichele Banko and Robert C. Moore.
2004.
Part ofspeech tagging in context.
In COLING ?04: Proceed-ings of the 20th international conference on Compu-tational Linguistics, page 556, Morristown, NJ, USA.Association for Computational Linguistics.Thorsten Brants.
2000.
TnT ?
a statistical part-of-speechtagger.
In Proceedings of the Sixth Applied NaturalLanguage Processing Conference (ANLP-2000), Seat-tle, WA.Kenneth Ward Church.
1988.
A stochastic parts programand noun phrase parser for unrestricted text.
In Pro-ceedings of the second conference on Applied naturallanguage processing, pages 136?143, Morristown, NJ,USA.
Association for Computational Linguistics.Do?ra Csendes, Ja?no?s Csirik, and Tibor Gyimo?thy.
2004.The Szeged Corpus: A POS tagged and syntacti-cally annotated Hungarian natural language corpus.In Karel Pala Petr Sojka, Ivan Kopecek, editor, Text,Speech and Dialogue: 7th International Conference,TSD, pages 41?47.Steven J. DeRose.
1988.
Grammatical category disam-biguation by statistical optimization.
ComputationalLinguistics, 14:31?39.Damien Doligez, Jacques Garrigue, Didier Re?my, andJe?ro?me Vouillon, 2004.
The Objective Caml system.Institut National de Recherche en Informatique et enAutomatique.Jesu?s Gime?nez and Llu?
?s Ma`rquez.
2003.
Fast and accu-rate part-of-speech tagging: The svm approach revis-ited.
In Proceedings of RANLP, pages 153?163.Jan Hajic?, Pavel Krbec, Karel Oliva, Pavel Kve?ton?, andVladim?
?r Petkevic?.
2001.
Serial combination of rulesand statistics: A case study in Czech tagging.
InProceedings of the 39th Association of ComputationalLinguistics Conference, pages 260?267, Toulouse,France.Dilek Z. Hakkani-Tu?r, Kemal Oflazer, and Go?khan Tu?r.2000.
Statistical morphological disambiguation foragglutinative languages.
In Proceedings of the 18thconference on Computational linguistics, pages 285?291, Saarbru?cken, Germany.Pe?ter Hala?csy, Andra?s Kornai, Csaba Oravecz, ViktorTro?n, and Da?niel Varga.
2006.
Using a morphologicalanalyzer in high precision POS tagging of Hungarian.In Proceedings of LREC 2006, pages 2245?2248.Bryan Jurish.
2003.
A hybrid approach to part-of-speechtagging.
Technical report, Berlin-BrandenburgischeAkademie der Wissenschaften.Adwait Ratnaparkhi.
1996.
A maximum entropy modelfor part-of-speech tagging.
In Karel Pala Petr Sojka,Ivan Kopecek, editor, Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing, pages 133?142, University of Pennsylvania.Noah A. Smith, David A. Smith, and Roy W. Tromble.2005.
Context-based morphological disambiguationwith random fields.
In Proceedings of the Conferenceon Human Language Technology and Empirical Meth-ods in Natural Language Processing, Vancouver.Kristina Toutanova, Dan Klein, Christopher Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of HLT-NAACL, pages 252?259.Viktor Tro?n, Pe?ter Hala?csy, Pe?ter Rebrus, Andra?s Rung,Pe?ter Vajda, and Eszter Simon.
2006.
Morphdb.hu:Hungarian lexical database and morphological gram-mar.
In Proceedings of LREC 2006, pages 1670?1673.212
