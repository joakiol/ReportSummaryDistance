Proceedings of the 2nd Workshop on Building Educational Applications Using NLP,pages 37?44, Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Using Syntactic Information to Identify PlagiarismO?zlem Uzuner, Boris Katz, and Thade NahnsenMassachusetts Institute of TechnologyComputer Science and Articial Intelligence LaboratoryCambridge, MA 02139ozlem,boris,tnahnsen@csail.mit.eduAbstractUsing keyword overlaps to identify pla-giarism can result in many false negativesand positives: substitution of synonymsfor each other reduces the similarity be-tween works, making it difficult to rec-ognize plagiarism; overlap in ambiguouskeywords can falsely inflate the similar-ity of works that are in fact different incontent.
Plagiarism detection based onverbatim similarity of works can be ren-dered ineffective when works are para-phrased even in superficial and immate-rial ways.
Considering linguistic informa-tion related to creative aspects of writingcan improve identification of plagiarismby adding a crucial dimension to evalu-ation of similarity: documents that sharelinguistic elements in addition to contentare more likely to be copied from eachother.
In this paper, we present a set oflow-level syntactic structures that capturecreative aspects of writing and show thatinformation about linguistic similaritiesof works improves recognition of plagia-rism (over tfidf-weighted keywords alone)when combined with similarity measure-ments based on tfidf-weighted keywords.1 IntroductionTo plagiarize is ?to steal and pass off (the ideasor words of another) as one?s own; [to] use (an-other?s production) without crediting the source; [or]to commit literary theft [by] presenting as new andoriginal an idea or product derived from an exist-ing source?.1 Plagiarism is frequently encounteredin academic settings.
According to turnitin.com, a2001 survey of 4500 high school students revealedthat ?15% [of students] had submitted a paper ob-tained in large part from a term paper mill or web-site?.
Increased rate of plagiarism hurts quality ofeducation received by students; facilitating recog-nition of plagiarism can help teachers control thisdamage.To facilitate recognition of plagiarism, in the re-cent years many commercial and academic prod-ucts have been developed.
Most of these approachesidentify verbatim plagiarism2 and can fail whenworks are paraphrased.
To recognize plagiarismin paraphrased works, we need to capture similar-ities that go beyond keywords and verbatim over-laps.
Two works that exhibit similarity both in theirconceptual content (as indicated by keywords) andin their expression of this content should be consid-ered more similar than two works that are similaronly in content.
In this context, content refers tothe story or the information; expression refers to thelinguistic choices of authors used in presenting thecontent, i.e., creative elements of writing, such aswhether authors tend toward passive or active voice,whether they prefer complex sentences with embed-ded clauses or simple sentences with independentclauses, as well as combinations of such choices.Linguistic information can be a source of powerfor measuring similarity between works based on1www.webster.com2www.turnitin.com37their expression of content.
In this paper, we use lin-guistic information related to the creative aspects ofwriting to improve recognition of paraphrased doc-uments as a first step towards plagiarism detection.To identify a set of features that relate to the linguis-tic choices of authors, we rely on different syntacticexpressions of the same content.
After identifyingthe relevant features (which we call syntactic ele-ments of expression), we rely on patterns in the useof these features to recognize paraphrases of works.In the absence of real-life plagiarism data, in thispaper, we use a corpus of parallel translations ofnovels as surrogate for plagiarism data.
Transla-tions of titles, i.e., original works, into English bydifferent people provide us with books that are para-phrases of the same content.
We use these para-phrases to automatically identify:1.
Titles even when they are paraphrased, and2.
Pairs of book chapters that are paraphrases ofeach other.Our first experiment shows that syntactic elementsof expression outperform all baselines in recogniz-ing titles even when they are paraphrased, provid-ing a way of recognizing copies of works based onthe similarities in their expression of content.
Oursecond experiment shows that similarity measure-ments based on the combination of tfidf-weightedkeywords and syntactic elements of expression out-perform the weighted keywords in recognizing pairsof book chapters that are paraphrases of each other.2 Related WorkWe define expression as ?the linguistic choices ofauthors in presenting a particular content?
(Uzuner,2005; Uzuner and Katz, 2005).
Linguistic similaritybetween works has been studied in the text classifi-cation literature for identifying the style of an author.However, it is important to differentiate expressionfrom style.
Style refers to the linguistic elementsthat, independently of content, persist over the worksof an author and has been widely studied in author-ship attribution.
Expression involves the linguisticelements that relate to how an author phrases par-ticular content and can be used to identify potentialcopyright infringement or plagiarism.
Similaritiesin the expression of similar content in two differ-ent works signal potential copying.
We hypothesizethat syntax plays a role in capturing expression ofcontent.
Our approach to recognizing paraphrasedworks is based on phrase structure of sentences ingeneral, and structure of verb phrases in particular.Most approaches to similarity detection use com-putationally cheap but linguistically less informedfeatures (Peng and Hengartner, 2002; Sichel, 1974;Williams, 1975) such as keywords, function words,word lengths, and sentence lengths; approaches thatinclude deeper linguistic information, such as syn-tactic information, usually incur significant compu-tational costs (Uzuner et al, 2004).
Our approachidentifies useful linguistic information without in-curring the computational cost of full text pars-ing; it uses context-free grammars to perform high-level syntactic analysis of part-of-speech taggedtext (Brill, 1992).
It turns out that such a level ofanalysis is sufficient to capture syntactic informa-tion related to creative aspects of writing; this inturn helps improve recognition of paraphrased doc-uments.
The results presented here show that ex-traction of useful linguistic information for text clas-sification purposes does not have to be computa-tionally prohibitively expensive, and that despite thetradeoff between the accuracy of features and com-putational efficiency, we can extract linguistically-informed features without full parsing.3 Identifying Creative Aspects of WritingIn this paper, we first identify linguistic elementsof expression and then study patterns in the use ofthese elements to recognize a work even when it isparaphrased.
Translated literary works provide ex-amples of linguistic elements that differ in expres-sion but convey similar content.
These works pro-vide insight into the linguistic elements that captureexpression.
For example, consider the following se-mantically equivalent excerpts from three differenttranslations of Madame Bovary by Gustave Flaubert.Excerpt 1: ?Now Emma would often take it intoher head to write him during the day.
Through herwindow she would signal to Justin, and he wouldwhip off his apron and fly to la huchette.
And whenRodolphe arrived in response to her summons, itwas to hear that she was miserable, that her husbandwas odious, that her life was a torment.?
(Trans-lated by Unknown1.
)38Excerpt 2: ?Often, even in the middle of the day,Emma suddenly wrote to him, then from the win-dow made a sign to Justin, who, taking his apronoff, quickly ran to la huchette.
Rodolphe wouldcome; she had sent for him to tell him that she wasbored, that her husband was odious, her life fright-ful.?
(Translated by Aveling.
)Excerpt 3: ?Often, in the middle of the day, Emmawould take up a pen and write to him.
Then shewould beckon across to Justin, who would off withhis apron in an instant and fly away with the letterto la huchette.
And Rodolphe would come.
Shewanted to tell him that life was a burden to her, thatshe could not endure her husband and that thingswere unbearable.?
(Translated by Unknown2.
)Inspired by syntactic differences displayed insuch parallel translations, we identified a novel setof syntactic features that relate to how people con-vey content.3.1 Syntactic Elements of ExpressionWe hypothesize that given particular content, au-thors choose from a set of semantically equivalentsyntactic constructs to express this content.
To para-phrase a work without changing content, peopletry to interchange semantically equivalent syntacticconstructs; patterns in the use of various syntacticconstructs can be sufficient to indicate copying.Our observations of the particular expressivechoices of authors in a corpus of parallel translationsled us to define syntactic elements of expression interms of sentence-initial and -final phrase structures,semantic classes and argument structures of verbphrases, and syntactic classes of verb phrases.3.1.1 Sentence-initial and -final phrasestructuresThe order of phrases in a sentence can shift theemphasis of a sentence, can attract attention to par-ticular pieces of information and can be used as anexpressive tool.1 (a) Martha can finally put some money in the bank.
(b) Martha can put some money in the bank, finally.
(c) Finally, Martha can put some money in the bank.2 (a) Martha put some money in the bank on Friday.
(b) On Friday, Martha put some money in the bank.
(c) Some money is what Martha put in the bank on Fri-day.
(d) In the bank is where Martha put some money onFriday.The result of such expressive changes affect thedistributions of various phrase types in sentence-initial and -final positions; studying these distribu-tions can help us capture some elements of expres-sion.
Despite its inability to detect the structuralchanges that do not affect the sentence-initial and-final phrase types, this approach captures some ofthe phrase-level expressive differences between se-mantically equivalent content; it also captures dif-ferent sentential structures, including question con-structs, imperatives, and coordinating and subordi-nating conjuncts.3.1.2 Semantic Classes of VerbsLevin (1993) observed that verbs that exhibit sim-ilar syntactic behavior are also related semantically.Based on this observation, she sorted 3024 verbsinto 49 high-level semantic classes.
Verbs of ?send-ing and carrying?, such as convey, deliver,move, roll, bring, carry, shuttle, andwire, for example, are collected under this seman-tic class and can be further broken down into fivesemantically coherent lower-level classes which in-clude ?drive verbs?, ?carry verbs?, ?bring and takeverbs?, ?slide verbs?, and ?send verbs?.
Each ofthese lower-level classes represents a group of verbsthat have similarities both in semantics and in syn-tactic behavior, i.e., they can grammatically un-dergo similar syntactic alternations.
For example,?send verbs?
can be seen in the following alterna-tions (Levin, 1993):1.
Base Form?
Nora sent the book to Peter.?
NP + V + NP + PP.2.
Dative Alternation?
Nora sent Peter the book.?
NP + V + NP + NP.Semantics of verbs in general, and Levin?s verbclasses in particular, have previously been used forevaluating content and genre similarity (Hatzivas-siloglou et al, 1999).
In addition, similar seman-tic classes of verbs were used in natural languageprocessing applications: START was the first nat-ural language question answering system to usesuch verb classes (Katz and Levin, 1988).
We use39Levin?s semantic verb classes to describe the ex-pression of an author in a particular work.
We as-sume that semantically similar verbs are often usedin semantically similar syntactic alternations; wedescribe part of an author?s expression in a par-ticular work in terms of the semantic classes ofverbs she uses and the particular argument struc-tures, e.g., NP + V + NP + PP, she prefers for them.As many verbs belong to multiple semantic classes,to capture the dominant semantic verb classes ineach document we credit all semantic classes of allobserved verbs.
We extract the argument structuresfrom part of speech tagged text, using context-freegrammars (Uzuner, 2005).3.1.3 Syntactic Classes of VerbsLevin?s verb classes include exclusively ?non-embedding verbs?, i.e., verbs that do not takeclausal arguments, and need to be supplemented byclasses of ?embedding verbs?
that do take such argu-ments.
Alexander and Kunz (1964) identified syn-tactic classes of embedding verbs, collected a com-prehensive set of verbs for each class, and describedthe identified verb classes with formulae written interms of phrasal and clausal elements, such as verbphrase heads (Vh), participial phrases (Partcp.
), in-finitive phrases (Inf.
), indicative clauses (IS), andsubjunctives (Subjunct.).
We used 29 of the morefrequent embedding verb classes and identified theirdistributions in different works.
Examples of theseverb classes are shown in Table 1.
Further examplescan be found in (Uzuner, 2005; Uzuner and Katz,2005).Syntactic Formula ExampleNP + Vh + NP + from The belt kept him from dying.+ Partcp.NP + Vh + that + IS He admitted that he was guilty.NP + Vh + that I request that she go alone.+ Subjunct.NP + Vh + to + Inf.
My father wanted to travel.NP + Vh + wh + IS He asked if they were alone.NP + pass.
+ Partcp.
He was seen stealing.Table 1: Sample syntactic formulae and examples ofembedding verb classes.We study the syntax of embedding verbs by iden-tifying their syntactic class and the structure oftheir observed embedded arguments.
After identi-fying syntactic and semantic characteristics of verbphrases, we combine these features to create fur-ther elements of expression, e.g., syntactic classesof embedding verbs and the classes of semantic non-embedding verbs they co-occur with.4 EvaluationWe tested sentence-initial and -final phrase struc-tures, semantic and syntactic classes of verbs, andstructure of verb arguments, i.e., syntactic elementsof expression, in paraphrase recognition and in pla-giarism detection in two ways:?
Recognizing titles even when they are para-phrased, and?
Recognizing pairs of book chapters that areparaphrases of each other.For our experiments, we split books into chapters,extracted all relevant features from each chapter, andnormalized them by the length of the chapter.4.1 Recognizing TitlesFrequently, people paraphrase parts of rather thancomplete works.
For example, they may paraphrasechapters or paragraphs from a work rather than thewhole work.
We tested the effectiveness of ourfeatures on recognizing paraphrased components ofworks by focusing on chapter-level excerpts (smallercomponents than chapters have very sparse vectorsgiven our sentence-level features and will be thefoci of future research) and using boosted decisiontrees (Witten and Frank, 2000).Our goal was to recognize chapters from the ti-tles in our corpus even when some titles were para-phrased into multiple books; in this context, titlesare original works and paraphrased books are trans-lations of these titles.
For this, we assumed the ex-istence of one legitimate book from each title.
Weused this book to train a model that captured the syn-tactic elements of expression used in this title.
Weused the remaining paraphrases of the title (i.e., theremaining books paraphrasing the title) as the testset?these paraphrases are considered to be plagia-rized copies and should be identified as such giventhe model for the title.404.1.1 DataReal life plagiarism data is difficult to obtain.However, English translations of foreign titles ex-ist and can be obtained relatively easily.
Titles thathave been translated on different occasions by dif-ferent translators and that have multiple translationsprovide us with examples of books that paraphrasethe same content and serve as our surrogate for pla-giarism data.To evaluate syntactic elements of expression onrecognizing paraphrased chapters from titles, wecompared the performance of these features withtfidf-weighted keywords on a 45-way classifica-tion task.
The corpus used for this experimentincluded 49 books from 45 titles.
Of the 45 ti-tles, 3 were paraphrased into a total of 7 books(3 books paraphrased the title Madame Bovary, 2books paraphrased 20000 Leagues, and 2 booksparaphrased The Kreutzer Sonata).
The remainingtitles included works from J. Austen (1775-1817),C. Dickens (1812-1870), F. Dostoyevski (1821-1881), A. Doyle (1859-1887), G. Eliot (1819-1880), G. Flaubert (1821-1880), T. Hardy (1840-1928), V. Hugo (1802-1885), W. Irving (1789-1859), J. London (1876-1916), W. M. Thack-eray (1811-1863), L. Tolstoy (1828-1910), I. Tur-genev (1818-1883), M. Twain (1835-1910), andJ.
Verne (1828-1905).4.1.2 Baseline FeaturesThe task described in this section focuses on rec-ognizing paraphrases of works based on the waythey are written.
Given the focus of authorship attri-bution literature on ?the way people write?, to eval-uate the syntactic elements of expression on recog-nizing paraphrased chapters of a work, we comparedthese features against features frequently used in au-thorship attribution as well as features used in con-tent recognition.Tfidf-weighted Keywords: Keywords, i.e., con-tent words, are frequently used in content-based textclassification and constitute one of our baselines.Function Words: In studies of authorship at-tribution, many researchers have taken advantageof the differences in the way authors use functionwords (Mosteller and Wallace, 1963; Peng and Hen-gartner, 2002).
In our studies, we used a set of 506function words (Uzuner, 2005).Distributions of Word Lengths and SentenceLengths: Distributions of word lengths and sen-tence lengths have been used in the literature forauthorship attribution (Mendenhall, 1887; Williams,1975; Holmes, 1994).
We include these featuresin our sets of baselines along with informationabout means and standard deviations of sentencelengths (Holmes, 1994).Baseline Linguistic Features: Sets of surface,syntactic, and semantic features have been found tobe useful for authorship attribution and have beenadopted here as baseline features.
These featuresincluded: the number of words and the number ofsentences in the document; type?token ratio; aver-age and standard deviation of the lengths of words(in characters) and of the lengths of sentences (inwords) in the document; frequencies of declara-tive sentences, interrogatives, imperatives, and frag-mental sentences; frequencies of active voice sen-tences, be-passives and get-passives; frequencies of?s-genitives, of-genitives and of phrases that lackgenitives; frequency of overt negations, e.g., ?not?,?no?, etc.
; and frequency of uncertainty markers,e.g., ?could?, ?possibly?, etc.4.1.3 ExperimentTo recognize chapters from the titles in our corpuseven when some titles were paraphrased into mul-tiple books, we randomly selected 40?50 chaptersfrom each title.
We used 60% of the selected chap-ters from each title for training and the remaining40% for testing.
For paraphrased titles, we selectedtraining chapters from one of the paraphrases andtesting chapters from the remaining paraphrases.
Werepeated this experiment three times; at each round,a different paraphrase was chosen for training andthe rest were used for testing.Our results show that, on average, syntactic ele-ments of expression accurately recognized compo-nents of titles 73% of the time and significantly out-performed all baselines3 (see middle column in Ta-ble 2).43The tfidf-weighted keywords used in this experiment do notinclude proper nouns.
These words are unique to each title andcan be easily replaced without changing content or expressionin order to trick a plagiarism detection system that would relyon proper nouns.4For the corpora used in this paper, a difference of 4% ormore is statistically significant with ?
= 0.05.41Feature Set Avg.
Avg.accuracy accuracy(complete (para-corpus) phrases)onlySyntactic elements of expression 73% 95%Function words 53% 34%Tfidf-weighted keywords 47% 38%Baseline linguistic 40% 67%Dist.
of word length 18% 54%Dist.
of sentence length 12% 17%Table 2: Classification results (on the test set) forrecognizing titles in the corpus even when some ti-tles are paraphrased (middle column) and classifi-cation results only on the paraphrased titles (rightcolumn).
In either case, random chance would rec-ognize a paraphrased title 2% of the time.The right column in Table 2 shows that the syntac-tic elements of expression accurately recognized onaverage 95% of the chapters taken from paraphrasedtitles.
This finding implies that some of our elementsof expression are common to books that are derivedfrom the same title.
This commonality could be dueto the similarity of their content or due to the under-lying expression of the original author.4.2 Recognizing Pairs of ParaphrasedChaptersExperiments in Section 4.1 show that we can usesyntactic elements of expression to recognize titlesand their components based on the way they arewritten even when some works are paraphrased.
Inthis section, our goal is to identify pairs of chaptersthat paraphrase the same content, i.e., chapter 1 oftranslation 1 of Madame Bovary and chapter 1 oftranslation 2 of Madame Bovary.
For this evalua-tion, we used a similar approach to that presented byNahnsen et al (2005).4.2.1 DataOur data for this experiment included 47 chap-ters from each of two translations of 20000 Leaguesunder the Sea (Verne), 35 chapters from each of 3translations of Madame Bovary (Flaubert), 28 chap-ters from each of two translations of The KreutzerSonata (Tolstoy), and 365 chapters from each of 2translations of War and Peace (Tolstoy).
Pairingup the chapters from these titles provided us withmore than 1,000,000 chapter pairs, of which approx-imately 1080 were paraphrases of each other.54.2.2 ExperimentFor experiments on finding pairwise matches, weused similarity of vectors of tfidf-weighted key-words;6 and the multiplicative combination of thesimilarity of vectors of tfidf-weighed keywords ofworks with the similarity of vectors of syntactic ele-ments of expression of these works.
We used cosineto evaluate the similarity of the vectors of works.
Weomitted the remaining baseline features from thisexperiment?they are features that are common tomajority of the chapters from each book, they donot relate to the task of finding pairs of chapters thatcould be paraphrases of each other.We ranked all chapter pairs in the corpus basedon their similarity.
From this ranked list, we iden-tified the top n most similar pairs and predicted thatthey are paraphrases of each other.
We evaluated ourmethods with precision, recall, and f-measure.7Figure 1: Precision.Figures 1, 2, and 3 show that syntactic elementsof expression improve the performance of tfidf-weighted keywords in recognizing pairs of para-phrased chapters significantly in terms of precision,recall, and f-measure for all n; in all of these figures,the blue line marked syn tdf represents the per-formance of tfidf-weighted keywords enhanced with5Note that this number double-counts the paraphrased pairs;however, this fact is immaterial for our discussion.6In this experiment, proper nouns are included in theweighted keywords.7The ground truth marks only the same chapter from twodifferent translations of the same title as similar, i.e., chapter xof translation 1 of Madame Bovary and chapter y of translation2 of Madame Bovary are similar only when x = y.42Figure 2: Recall.syntactic elements of expression.
More specifically,the peak f-measure for tfidf-weighted keywords isapproximately 0.77 without contribution from syn-tactic elements of expression.
Adding informationabout similarity of syntactic features to cosine sim-ilarity of tfidf-weighted keywords boosts peak f-measure value to approximately 0.82.8 Althoughthe f-measure of both representations degrade whenn > 1100, this degradation is an artifact of the eval-uation metric: the corpus includes only 1080 similarpairs, at n > 1100, recall is very close to 1, andtherefore increasing n hurts overall performance.Figure 3: F-measure.5 ConclusionPlagiarism is a problem at all levels of education.Increased availability of digital versions of worksmakes it easier to plagiarize others?
work and thelarge volumes of information available on the webmakes it difficult to identify cases of plagiarism.8The difference is statistically significant at ?
= 0.05.To identify plagiarism even when works are para-phrased, we propose studying the use of particularsyntactic constructs as well as keywords in docu-ments.This paper shows that syntactic information canhelp recognize works based on the way they arewritten.
Syntactic elements of expression that fo-cus on the changes in the phrase structure of workshelp identify paraphrased components of a title.
Thesame features help improve identification of pairsof chapters that are paraphrases of each other, de-spite the content these chapters share with the restof the chapters taken from the same title.
The re-sults presented in this paper are based on experi-ments that use translated novels as surrogate for pla-giarism data.
Our future work will extend our studyto real life plagiarism data.6 AcknowledgementsThe authors would like to thank Sue Felshin for herinsightful comments.
This work is supported in partby the Advanced Research and Development Activ-ity as part of the AQUAINT research program.ReferencesD.
Alexander and W. J. Kunz.
1964.
Some classes ofverbs in English.
In Linguistics Research Project.
In-diana University, June.E.
Brill.
1992.
A simple rule-based part of speech tag-ger.
In Proceedings of the 3rd Conference on AppliedNatural Language Processing.V.
Hatzivassiloglou, J. Klavans, and E. Eskin.
1999.
De-tecting similarity by applying learning over indicators.In Proceedings of the 37th Annual Meeting of the ACL.D.
I. Holmes.
1994.
Authorship attribution.
Computersand the Humanities, 28.B.
Katz and B. Levin.
1988.
Exploiting lexical reg-ularities in designing natural language systems.
InProceedings of the 12th Int?l Conference on Compu-tational Linguistics (COLING ?88).B.
Levin.
1993.
English Verb Classes and Alternations.A Preliminary Investigation.
University of ChicagoPress.T.
C. Mendenhall.
1887.
Characteristic curves of com-position.
Science, 11.43F.
Mosteller and D. L. Wallace.
1963.
Inference in an au-thorship problem.
Journal of the American StatisticalAssociation, 58(302).T.
Nahnsen, O?.
Uzuner, and B. Katz.
2005.
Lexicalchains and sliding locality windows in content-basedtext similarity detection.
CSAIL Memo, AIM-2005-017.R.
D. Peng and H. Hengartner.
2002.
Quantitative analy-sis of literary styles.
The American Statistician, 56(3).H.
S. Sichel.
1974.
On a distribution representingsentence-length in written prose.
Journal of the RoyalStatistical Society (A), 137.O?.
Uzuner and B. Katz.
2005.
Capturing expression us-ing linguistic information.
In Proceedings of the 20thNational Conference on Artificial Intelligence (AAAI-05).O?.
Uzuner, R. Davis, and B. Katz.
2004.
Using em-pirical methods for evaluating expression and contentsimilarity.
In Proceedings of the 37th Hawaiian Inter-national Conference on System Sciences (HICSS-37).IEEE Computer Society.O?.
Uzuner.
2005.
Identifying Expression FingerprintsUsing Linguistic Information.
Ph.D. thesis, Mas-sachusetts Institute of Technology.C.
B. Williams.
1975.
Mendenhall?s studies of word-length distribution in the works of Shakespeare andBacon.
Biometrika, 62(1).I.
H. Witten and E. Frank.
2000.
Data Mining: PracticalMachine Learning Tools with Java Implementations.Morgan Kaufmann, San Francisco.44
