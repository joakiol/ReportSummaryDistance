Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 859?866, Vancouver, October 2005. c?2005 Association for Computational LinguisticsCross-linguistic Projection of Role-Semantic InformationSebastian Pad?Computational LinguisticsSaarland UniversitySaarbr?cken, Germanypado@coli.uni-sb.deMirella LapataSchool of InformaticsUniversity of EdinburghEdinburgh, UKmlap@inf.ed.ac.ukAbstractThis paper considers the problem of auto-matically inducing role-semantic annota-tions in the FrameNet paradigm for newlanguages.
We introduce a general frame-work for semantic projection which ex-ploits parallel texts, is relatively inexpen-sive and can potentially reduce the amountof effort involved in creating semantic re-sources.
We propose projection modelsthat exploit lexical and syntactic informa-tion.
Experimental results on an English-German parallel corpus demonstrate theadvantages of this approach.1 IntroductionShallow semantic parsing, the task of automaticallyidentifying the semantic roles conveyed by senten-tial constituents, has recently attracted much atten-tion, partly because of its increasing importance forpotential applications.
For instance, information ex-traction (Surdeanu et al, 2003), question answer-ing (Narayanan and Harabagiu, 2004) and machinetranslation (Boas, 2002) could stand to benefit frombroad coverage semantic processing.The FrameNet project (Fillmore et al, 2003)has played a central role in this endeavour byproviding a large lexical resource based on se-mantic roles.
In FrameNet, meaning is representedby frames, schematic representations of situations.Semantic roles are frame-specific, and are calledframe elements.
The database associates frames withlemmas (verbs, nouns, adjectives) that can evokethem (called frame-evoking elements or FEEs), liststhe possible syntactic realisations of their seman-tic roles, and provides annotated examples from theBritish National Corpus (Burnard, 1995).
The avail-ability of rich annotations for the surface realisationof semantic roles has triggered interest in semanticparsing and enabled the development of data-drivenmodels (e.g., Gildea and Jurafsky, 2002).Frame: DEPARTINGTHEME The officer left the house.The plane leaves at seven.His departure was delayed.SOURCE We departed from New York.He retreated from his opponent.The woman left the house.FrameElementsFEEs abandon.v, desert.v, depart.v, departure.n,emerge.v, emigrate.v, emigration.n, escape.v,escape.n, leave.v, quit.v, retreat.v, retreat.n,split.v, withdraw.v, withdrawal.nTable 1: Example of FrameNet frameTable 1 illustrates an example from the FrameNetdatabase, the DEPARTING frame.
It has two roles, aTHEME which is the moving object and a SOURCEexpressing the initial position of the THEME.
Theframe elements are realised by different syntactic ex-pressions.
For instance, the THEME is typically anNP, whereas the SOURCE is often expressed by aprepositional phrase (see the expressions in boldfacein Table 1).
The DEPARTING frame can be evokedby abandon, desert, depart, and several other verbsas well as nouns (see the list of FEEs in Table 1).Although recent advances in semantic parsing1have greatly benefited from the availability of theEnglish FrameNet, unfortunately such resources arelargely absent for other languages.
The EnglishFrameNet (Version 1.1) contains 513 frames cov-ering 7,125 lexical items and has been under de-velopment for approximately six years.
AlthoughFrameNets are currently under construction for Ger-man, Spanish, and Japanese, these resources are stillin their infancy and of limited value for modellingpurposes.
Methods for acquiring FrameNets fromcorpora automatically would greatly reduce the hu-man effort involved and facilitate their developmentfor new languages.In this paper, we propose a method which em-ploys parallel corpora for acquiring frame elements1Approaches to modelling semantic parsing are too numer-ous to list; see Carreras and M?rquez (2005) for an overview.859and their syntactic realisations (see the upper half ofTable 1) for new languages.
Our method leveragesthe existing English FrameNet to overcome the re-source shortage in other languages by exploiting thetranslational and structural equivalences present inaligned data.
The idea underlying our approach canbe summarised as follows: (1) given a pair of sen-tences E (English) and L (new language) that aretranslations of each other, annotate E with seman-tic roles; and then (2) project these roles onto L. Inthis manner, we induce semantic structure on the Lside of the parallel text, which can then serve as datafor training a statistical semantic parser for L that isindependent of the parallel corpus.We first assess if the main assumption of semanticprojection is warranted (Section 3), namely whetherframes and semantic roles exhibit a high degree ofparallelism across languages.
Then we propose twobroad classes of projection models that utilise lexi-cal and syntactic information (Section 4), and showexperimentally that roles can be projected from En-glish onto German with high accuracy (Section 5).We conclude the paper by discussing the implica-tions of our results and future work (Section 6).2 Related workA number of recent studies exploit parallel cor-pora for cross-linguistic knowledge induction.
Inthis paradigm, annotations for resource-rich lan-guages like English are projected onto another lan-guage through aligned parallel texts.
Yarowsky etal.
(2001) propose several projection algorithms forderiving monolingual tools (ranging from part-of-speech taggers, to chunkers and morphological anal-ysers) without additional annotation cost.
Hwa etal.
(2002) assess the degree of syntactic parallelismin dependency relations between English and Chi-nese.
Their results show that, although assuming di-rect correspondence is often too restrictive, syntacticprojection yields good enough annotations to traina dependency parser.
Smith and Smith (2004) ex-plore syntactic projection further by proposing anEnglish-Korean bilingual parser integrated with aword translation model.Previous work has primarily focused on the pro-jection of morphological and grammatico-syntacticinformation.
Inducing semantic resources from lowdensity languages still poses a significant challengeto data-driven methods.
The challenge is recognisedby Fung and Chen (2004) who construct a ChineseFrameNet by mapping English FrameNet entries toconcepts listed in HowNet2, an on-line ontology forChinese, however without exploiting parallel texts.The present work extends previous approaches onannotation projection by inducing FrameNet seman-tic roles from parallel corpora.
Analogously to Hwaet al (2002), we investigate whether there are indeedsemantic correspondences between two languages,since there is little hope for projecting meaningfulannotations in nonparallel semantic structures.
Sim-ilarly to Fung and Chen (2004) we automatically in-duce semantic role annotations for a target language.In contrast to them, we resort to parallel corpora as asource of semantic equivalence.
Thus, we avoid theneed for a target concept dictionary in addition to theEnglish FrameNet.
We propose a general frameworkfor semantic projection that can incorporate differentknowledge sources.
To our knowledge, the frame-work and its application to semantic role projectionare novel.3 Creation of a Gold Standard CorpusSample Selection.
To evaluate the output of ourprojection algorithms, we created a gold standardcorpus of English-German sentence pairs with man-ual FrameNet frame and role annotations.
The sen-tences were sampled from Europarl (Koehn, 2002),a corpus of professionally translated proceedings ofthe European Parliament.
Europarl is available in11 languages with up to 20 million words per lan-guage aligned at the document and sentence level.Recall that frame projection is only meaningful ifthe same frame is appropriate for both sentences ina projection pair.
This constrains sample selectionfor two reasons: first, FrameNet is as yet incom-plete with respect to its coverage.
So, a randomlyselected sentence pair may evoke novel frames ornovel senses of already existing frames (e.g., the?greeting?
sense of hail which is currently not listedin FrameNet).
Second, due to translational variance,there is no a priori guarantee that words which aremutual translations evoke the same frame.
For ex-ample, the English verb finish is often translatedin German by the adverb abschlie?end, which ar-guably cannot have a role set identical to finish.
Re-lying solely on the English FrameNet database forsampling would yield many sentence pairs whichare either inappropriate for the present study (be-cause they do not evoke the same frames) or simplyproblematic for annotation since they are outside the2See http://www.keenage.com/zhiwang/e_zhiwang.html.860present coverage of the database.For the above reasons, our sample selection pro-cedure was informed by two existing resources,the English FrameNet and SALSA, a FrameNet-compatible database for German currently under de-velopment (Erk et al, 2003).
We first used the pub-licly available GIZA++ (Och and Ney, 2003) soft-ware to induce English-German word alignments.Next, we gathered all German-English sentencesin the corpus that had at least one pair of alignedwords (we,wg), which were listed in FrameNet andSALSA, respectively, and had at least one framein common.
These sentences exemplify 83 frametypes, 696 lemma pairs, and 265 unique English and178 unique German lemmas.
Sentence pairs weregrouped into three bands according to their framefrequency (High, Medium, Low).
We randomly se-lected 380 pairs from each band.
The total sampleconsisted of ,140 sentence pairs.This procedure produces a realistic corpus samplefor the role projection task; similar samples can bedrawn for new language pairs using either existingbilingual dictionaries (Fung and Chen, 2004) or au-tomatically constructed semantic lexicons (Pad?
andLapata, 2005).Annotation.
Two annotators, with native-levelproficiency in German and English, manually la-belled the parallel corpus with semantic information.Their task was to identify the frame for a given pred-icate in a sentence, and assign the correspondingroles.
They were provided with detailed guidelinesthat explained the task using multiple examples.During annotation, they had access to parsed ver-sions of the sentences in question (see Section 5 fordetails), and to the English FrameNet and SALSA.The annotation proceeded in three phases: a train-ing phase (40 sentences), a calibration phase (100sentences), and a production mode phase (1000 sen-tences).
In the calibration phase, sentences weredoubly annotated to assess inter-annotator agree-ment.
In production mode, sentences were split intotwo distinct sets, each of which was annotated by asingle coder.
We ensured that no annotator saw bothparts of any sentence pair to guarantee independentannotation of the bilingual data.
Each coder anno-tated approximately the same amount of data in En-glish and German.Table 2 shows the results of our inter-annotatoragreement study.
In addition to the widely usedKappa statistic, we computed a number of differentagreement measures: the ratio of frames commonMeasure English German AllFrame Match 0.90 0.87 0.88Role Match 0.95 0.95 0.95Span Match 0.85 0.83 0.84Kappa 0.86 0.90 0.87Table 2: Monolingual inter-annotation agreement onthe calibration setMeasure Precision Recall F-scoreFrame Match 0.72 0.72 0.72Role Match 0.91 0.92 0.91Table 3: Cross-lingual semantic parallelism betweenEnglish and Germanbetween two sentences (Frame Match), the ratio ofcommon roles (Role Match), and the ratio of roleswith identical spans (Span Match).
As can be seen,annotators tend to agree in frame assignment; dis-agreements are mainly due to fuzzy distinctions be-tween frames (e.g., between AWARENESS and CER-TAINTY).
As can be seen from Table 2, annotatorsagree in what roles to assign (Role Match is 0.95 forboth English and German); agreeing on their exactspans is a harder problem.Semantic Parallelism.
Since we obtained par-allel FrameNet annotations for English and German,we were able to investigate the degree of semanticparallelism between the two languages.
More specif-ically, we treated the German annotation as goldstandard against which we compared the English an-notations.
To facilitate comparisons with the outputof our automatic projection methods (see Section 4),we measured parallelism using precision and recall.Frames and frame roles were counted as matching ifthey were annotated in a sentence, regardless of theirspans.
The results are shown in Table 3.The cross-lingual data exhibit more than twice theamount of frame differences than monolingual data(compare Tables 2 and 3).
This indicates that framedisambiguation methods must be employed in auto-matic role projection to ensure that two aligned to-kens evoke the same frame.
However, frame disam-biguation is outside the scope of the present paper.On the positive side, role agreement is rela-tively high (0.91 F-score).
This indicates that incases where frames match across languages, seman-tic roles could be accurately transferred (providedthat these languages diverge little in their argumentstructure).
This observation offers support for the861projection approach put forward in this paper.
Note,however, that a practical projection system could at-tain this level of performance only if it could employan oracle to recover annotators?
decisions about thespan of roles.
We can obtain a more realistic upperbound for an automatic system from the monolin-gual Role Span agreement figure (F-score 0.84).
Thelatter represents a ceiling for the agreement we canexpect from sentences annotated by different anno-tators.4 Projection of Semantic InformationIn this section, we formalise the semantic projectiontask and give the details of our modelling approach.All models discussed here project semantic annota-tions from a source language to a target language.As explained earlier, our present study is only con-cerned with the projection of roles between match-ing frames.4.1 Problem FormulationWe assume that we are provided with source and tar-get sentences represented as sets of entities es ?
Esand et ?
Et .
These entities can be words, con-stituents, phrases, or other groupings.
In addition,we are given the semantic annotation of the sourcesentences from which we can directly read off thesource semantic role assignment as : R?
2Es , whereR is the set of semantic roles.
The goal of the pro-jection is to specify the target semantic role assign-ments at : R?
2Et , which are unknown.3Clearly, effecting the projection requires estab-lishing some form of match between the source andtarget entities.
We therefore formalise projection asa function which maps the source role assignmentand a set of matches M ?
Es?Et onto a new targetrole assignment:pro j : (As?M)?
(R?
2Et ) (1)By way of currying, we can state the new target roleassignment as a function which directly computes aset of target entities, given the source role assign-ment, a set of entity matches, and a role:at : (As?M?R)?
2Et (2)According to this formalisation, the crucial part ofsemantic projection is to identify a correct and ex-haustive set of entity matches.
Obviously, this raises3Without loss of generality, we limit ourselves to one frameper sentence, as does FrameNet.r ?
R Semantic rolets ?
Ts, tt ?
Tt Source, target tokensal ?
Al : Ts ?
2Tt Word alignmentas ?
As : R?
2Ts Source role assignmentat : (As?Al?R)?
2Tt Projected target role as-signmentTable 4: Notation and signature summary for word-based projectionthe question of what linguistic information is appro-priate for establishingM.
Unfortunately, any attemptto compute a match based on categorical data de-rived from linguistic analyses (e.g., parts of speech,phrase types or grammatical relations), needs to em-pirically derive cross-linguistic similarities betweencategories, a task which must be repeated for everynew language pair, and requires additional data.Rather than postulating an ad hoc similarity func-tion, we use word alignments to derive informa-tion about semantic roles in the target language.
Ourfirst model family (Section 4.2) relies exclusivelyon this knowledge source.
Although potentially use-ful as a proxy for semantic equivalence, automati-cally induced alignments are often noisy, thus lead-ing to errors in annotation projection (Yarowsky etal., 2001).
For example, function words commonlydiverge across languages and are systematically mis-aligned; furthermore, alignments are restricted tosingle words rather than word combinations.
Thisobservation motivates a second model family with abias towards linguistically meaningful entities (Sec-tion 4.3).
Such entities can be constituents derivedfrom the output of a parser or non-recursive syntac-tic structures (i.e., chunks).In this paper we compare simple word align-ment models against more resource intensive modelsthat utilise constituent-based information and exam-ine whether syntactic knowledge significantly con-tributes to semantic projection.4.2 Word-based Projection ModelThe first model family uses source and target wordtokens as entities for projection.
In this framework,projection models can be defined by deriving the setof matches M directly from word alignments.
Theresulting signatures are shown in Table 4.Our first projection model assigns to each roler with source span s(r) the set of all target tokenswhich are aligned to a token in the source span:aw(as,al,r) =[ts?as(r)al(ts) (3)862John and Mary leftJohann und Maria gingenDepartingDepartingFigure 1:Word alignment-based semantic projectionof Role THEME (shadowed), Frame DEPARTINGThe main shortcoming of this model is that it cannotcapture an important linguistic property of semanticroles, namely that they almost always cover contigu-ous stretches of text.
We can repair non-contiguousprojections by applying a ?convex complementing?heuristic to the output of (3), which fills all holesin a sequence of tokens, without explicit recourse tosyntactic information.
We define the convex comple-menting heuristic as:acw(as,al,r) = {tt | min(i(at1))?
i(tt)?max(i(at1))}(4)where i returns the index of a token t.The two models just described are illustrated inFigure 1.
The frame DEPARTING is introduced byleft and gingen in English and German, respectively.For simplicity, we only show the edges correspond-ing to the THEME role.
In English, the THEME is re-alised by the words John and Mary.
The dotted linesshow the available word alignments.
The projectionof the THEME role according to (3) consists onlyof the tokens {Johann, Maria} (shown by the plainblack lines); the convex complementing heuristic inmodel (4) adds the token und, resulting in the (cor-rect) convex set {Johann, und, Maria}.4.3 Constituent-based Projection ModelOur second model family attempts to make up forerrors in the word alignment by projecting from andto constituents.
In this study, our constituents are ob-tained from full parse trees (see Section 5 for de-tails).
Models which use non-recursive structures arealso possible; however, we leave this to future work.The main difference from word-based projectionmodels is the introduction of constituent informationas an intermediate level; we thus construct a con-stituent alignment for which only a subset of wordalignments has to be accurate.
The appropriate sig-natures and notation for constituent-based projectionare summarised in Table 5.In order to keep the model as flexible as pos-sible, and to explore the influence of different de-sign decisions, we model constituent-based projec-tion as two independently parameterisable subtasks:first we compute a real-valued similarity functionbetween source and target constituents; then, we em-ploy the similarity function to align relevant con-stituents and project the role information.Similarity functions.
In principle, any functionwhich matches the signature in Table 5 could beused.
In practice, the use of linguistic knowledgeruns into the problem of defining similarity betweencategory-based representations discussed above.
Forthis reason, we limit ourselves to two simple similar-ity functions based on word overlap: Given sourceand target constituents cs and ct , we define the wordoverlap ow of cs with ct as the proportion of tokenswithin ct aligned to tokens within cs.
Let yield(c)denote the set of tokens in the yield of a constituentc, then:ow(cs,ct) =|(Sts?yield(cs) al(ts))?
yield(ct)||yield(ct)|(5)Since the asymmetry of this overlap measure leadsto high overlap scores for small target constituents,we define word overlap similarity, as the product oftwo constituents?
mutual overlap:sim(cs,ct) = o(cs,ct) ?o(ct ,cs) (6)Simple word-based overlap has one undesired char-acteristic: larger constituents tend to be less similarbecause of missing alignments (e.g., between func-tion words).
Since content words are arguably moreimportant for the role projection task, we define asecond overlap measure, content word overlap owc,which takes only nouns, verbs and adjectives intoaccount.
Let yieldc(c) denote the set of tokens in theyield of c that are content words, then:owc(cs,ct) =|(Sts?yieldc(cs) al(ts))?
yieldc(ct)||yieldc(ct)|(7)Constituent alignment.
Considerable latitudeis available in interpreting a similarity function toderive a constituent alignment.
Due to space limita-tions, we demonstrate two basic models.Our first forward constituent alignment model(a f c), aligns source constituents that form the span863r ?
R Semantic rolecs ?Cs,ct ?Ct Source and target con-stituentsyield :C ?
T Yield of a constituentyieldc :C ?
T Content word yield of aconstituental ?
Al : Ts ?
2Tt Word alignmentas ?
As : R?
2Cs Source role assignmentsim :Cs?Ct ?
R+ Constituent similarityat : As?Sim?R?
2Ct Projected target role as-signmentTable 5: Notation and signature summary forconstituent-based projectionof a role to a single target constituent.
We computethe similarity of a target constituent ct to a set ofsource constituents cs ?
as(r) by taking the productsimilarity for each source and target constituent pair:a f c(as,sim,r) = argmaxct?Ct?cs?as(r)sim(cs,ct) (8)This projection model forces the target role assign-ment to be a function, i.e., it makes the somewhatsimplifying assumption that each role correspondsto a single target constituent.Our second backward constituent alignmentmodel (abc) proceeds in the opposite direction: it it-erates over target constituents and attempts to de-termine their most similar source constituent foreach ct .
If the aligned source constituent is labelledwith a role, it is projected onto ct :abc(as,sim,r) = {ct |(argmaxcs?Cssim(cs,ct)) ?
as(r)}(9)In general, abc allows for more flexible role pro-jection: it will sometimes decide not to project arole at all (if the source constituents are dissimilarto any target constituents), or it can assign a roleto more than one target constituent; however, thismeans that there is less control over what is pro-jected, and wrong alignments can lead to wrong re-sults more easily.Finally, if no word alignments are found forcomplete source or target constituents, the maxi-mal similarity rating in abc or ab f will be zero.This is often the case for semantically weak single-word constituents such as demonstrative pronouns(e.g., [That] is right./ [Das] ist richtig.).
When weobserve this phenomenon, we heuristically skip un-aligned constituents (zero skipping).Figure 2 contrasts the two constituent-based pro-jection models using the frame QUESTIONING asHe asked all of themEr fragte alle von ihnenNP3PP2NP1NP4PP5NP6QuestioningQuestioningNP1 PP2 NP3NP4 0.33 0.5 1PP5 0.67 1 0.5NP6 0.33 0 0Figure 2: Constituent-based semantic projection ofrole ADDRESSEE (shadowed), frame QUESTION-ING.
Below: Constituent similarity matrix.an example.
Again, we only show one role, AD-DRESSEE, indicated by the shadowed box in Fig-ure 2.
Note that the object NP in German was mis-parsed as an NP and a PP, a relatively frequent er-ror.
The difference between the two decision proce-dures can be explained straightforwardly by look-ing at the table below the graph, which shows thesimilarity matrix for the constituents according toequation (6).
In this table, the source constituents(indices 1?3) correspond to columns, and the tar-get constituents (indices 4?6) to rows.
The align-ment model in (8) iterates over labelled source con-stituents (here only NP1) and chooses the row withthe highest value as the target constituent for a can-didate role.
In our case, this is the PP5 (cell in bold-face).
In contrast, model (9) iterates over all targetconstituents (i.e., rows) and checks if the most sim-ilar source constituent bears a role label.
Since NP1is the most similar constituent for NP6 (underlinedcell), (9) assigns the QUESTIONING role to NP6.5 ExperimentsEvaluation Framework.
We implemented themodels described in the previous section and usedthem to project semantic information from En-glish onto German.
For the constituent-based mod-els, constituent information was obtained from theoutput of Collins?
parser (1997) for English andDubey?s parser (2004) for German.
Words were864Model Precision Recall F-scorew 0.41 0.40 0.41cw 0.46 0.45 0.46Upper bound 0.85 0.84 0.84Table 6: Results for word-based projection modelsaligned using the default setting4 of GIZA++ (Ochand Ney, 2003), a publicly available implementa-tion of the IBM models and HMM word alignmentmodels.
We evaluated the projected roles against the?gold standard?
roles obtained from the manual an-notation (see Section 3).
We also compared our re-sults to the upper bound given by the inter-annotatoragreement on the calibration data set.Results.
Table 6 shows our results for the word-based projection models.
The simplest word-basedmodel (aw), obtains an F-score of 0.41.
This is agood result considering that the model does not ex-ploit any linguistic information (e.g., parts of speechor syntactic structure).
It also supports our hypothe-sis that word alignments are useful for the role pro-jection task.
The convex complementing heuristic(acw) delivers an F-score increase of five points overthe ?words only?
model, simply by making up forholes in the word alignment.We evaluated eight instantiations of theconstituent-based projection models; the results areshown in Table 7.
The best model (in boldface) usesforward constituent alignment, content word-basedoverlap similarity, and zero skipping.
We observethat backward constituent alignment-based models(1?4) perform similarly to word-based projectionmodels (the F-score ranges between 0.40 and 0.45).However, they obtain considerably higher precision(albeit lower recall) than the word-based models.This may be an advantage if the projected datais destined for training target-language semanticparsers.
This precision/recall pattern appears to bea direct result of abc, which only projects a rolefrom cs to ct if cs ?wins?
against all other sourceconstituents, thus resulting in reliable, but overlycautious projections, which cannot not be furtherimproved by zero skipping.The forward constituent alignment models (5?8)show consistently higher performance than word-based models and models 1?4, indicating that thestronger assumptions made by forward alignment4The training scheme involved five iterations of Model 1,five iterations of the HMM model, five iterations of Model 3,and five iterations of Model 4.Model al o 0-skip Precision Recall F-score1 bc w no 0.70 0.33 0.452 bc w yes 0.70 0.33 0.453 bc wc no 0.65 0.32 0.424 bc wc yes 0.65 0.32 0.425 f c w no 0.61 0.60 0.606 f c w yes 0.66 0.60 0.637 f c wc no 0.62 0.60 0.618 fc wc yes 0.70 0.60 0.65Upper bound 0.85 0.84 0.84Table 7: Results for constituent-based projectionmodels (al: constituent alignment model; o: overlapmeasure; 0-skip: zero skipping)are justified in the data.
In addition, we also findthat we can increase precision by concentrating onreliable alignments.
This is achieved by using thezero skipping heuristic (compare the odd vs. even-numbered models in Table 7) and by computingoverlap on content words (compare Models 6 vs. 8,and 5 vs. 7).We used the ?2 test to examine whether the dif-ferences observed between the two classes of mod-els are statistically significant.
The best constituent-based model significantly outperforms the bestword-based model both in terms of precision(?2 = 114.47, p < 0.001) and recall (?2 = 400.40,p < 0.001).
Both projection models perform signifi-cantly worse than humans (p < 0.001).Discussion.
Our results confirm that constituentinformation is important for the semantic projectiontask.
Our best model adopts a conservative strat-egy which enforces a one-to-one correspondence be-tween roles and target constituents.
This strategyleads to high precision, however recall lags behind(see Model 8 in Table 7).
Manual inspection of theprojection output revealed that an important sourceof missing roles are word alignments gaps.
Suchgaps are not only due to noisy alignments, but alsoreflect genuine structural differences between trans-lated sentences.
Consider the following (simplified)example for the STATEMENT frame (introduced bysay) and its semantic role STATEMENT (introducedby we):(10) WeWirclaimbehauptenXXandundwe?saysagenYYThe word alignment correctly aligns the Germanpronoun wir with the first English we and leaves865the second occurrence unaligned.
Since there is nocorresponding German word for the second we, pro-jection of the SPEAKER role fails.
In future work,this problem could be handled with explicit identi-fication of empty categories (see Dienes and Dubey,2003).6 ConclusionsIn this paper, we argue that parallel corpora showpromise in relieving the lexical acquisition bottle-neck for low density languages.
We proposed se-mantic projection as a means of obtaining FrameNetannotations automatically without additional humaneffort.
We examined semantic parallelism, a prereq-uisite for accurate projection, and showed that se-mantic roles can be successfully projected for pred-icate pairs with matching frame assignments.
Sim-ilarly to previous work (Hwa et al, 2002), we findthat some mileage can be gained by assuming di-rect correspondence between two languages.
How-ever, linguistic knowledge is key in obtaining mean-ingful projections.
Our experiments show that theuse of constituent information yields substantial im-provements over relying on word alignment alone.Nevertheless, the word-based models offer a goodstarting point for low-density languages for whichparsers are not available.
Their output could be fur-ther post-processed manually or automatically usingbootstrapping techniques (Riloff and Jones, 1999).We have presented a general, flexible frameworkfor semantic projection which can be easily appliedto other languages.
An important direction for fu-ture work lies in the assessment of more shallowsyntactic information (i.e., chunks) which can be ob-tained more easily for new languages, and generallyin the integration of more linguistic knowledge toguide projection.
Finally, we will incorporate intoour projection approach automatic semantic role an-notations for the source language and investigate thepotential of the projected annotations for training se-mantic parsers for the target language.Acknowledgements.
The authors acknowledgethe support of DFG (Pad?
; grant PI-154/9-2) andEPSRC (Lapata; grant GR/T04540/01).
Thanks toB.
Kouchnir and P. Kreischer for their annotation.ReferencesH.
C. Boas.
2002.
Bilingual framenet dictionaries formachine translation.
In Proceedings of LREC 2002,1364?1371, Las Palmas, Canary Islands.L.
Burnard, 1995.
The Users Reference Guide for theBritish National Corpus.
British National CorpusConsortium, Oxford University Computing Service,1995.X.
Carreras, L. M?rquez, eds.
2005.
Proceedings of theCoNLL shared task: Semantic role labelling, 2005.M.
Collins.
1997.
Three generative, lexicalised modelsfor statistical parsing.
In Proceedings of ACL/EACL1997, 16?23, Madrid, Spain.P.
Dienes, A. Dubey.
2003.
Antecedent recovery: Exper-iments with a trace tagger.
In Proceedings of EMNLP2003, 33?40, Sapporo, Japan.A.
Dubey.
2004.
Statistical parsing for German: Mod-elling syntactic properties and annotation differences.Ph.D.
thesis, Saarland University.K.
Erk, A. Kowalski, S.
Pad?, M. Pinkal.
2003.
Towardsa resource for lexical semantics: A large German cor-pus with extensive semantic annotation.
In Proceed-ings of ACL 2003, 537?544, Sapporo, Japan.C.
J. Fillmore, C. R. Johnson, M. R. Petruck.
2003.Background to FrameNet.
International Journal ofLexicography, 16:235?250.P.
Fung, B. Chen.
2004.
BiFrameNet: Bilingual framesemantics resources construction by cross-lingual in-duction.
In Proceedings of COLING 2004, 931?935,Geneva, Switzerland.D.
Gildea, D. Jurafsky.
2002.
Automatic labeling of se-mantic roles.
Computational Linguistics, 28(3):245?288.R.
Hwa, P. Resnik, A. Weinberg, O. Kolak.
2002.
Eval-uation translational correspondance using annotationprojection.
In Proceedings of ACL 2002, 392?399,Philadelphia, PA.P.
Koehn.
2002.
Europarl: A multilingual corpus forevaluation of machine translation.
Draft.S.
Narayanan, S. Harabagiu.
2004.
Question answeringbased on semantic structures.
In Proceedings of COL-ING 2004, 693?701, Geneva, Switzerland.F.
J. Och, H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?52.S.
Pad?, M. Lapata.
2005.
Cross-lingual bootstrappingfor semantic lexicons.
In Proceedings of AAAI 2005,Pittsburgh, PA.E.
Riloff, R. Jones.
1999.
Learning dictionaries for in-formation extraction by multi-level bootstrapping.
InProceedings of AAAI 1999, Orlando, FL.D.
A. Smith, N. A. Smith.
2004.
Bilingual parsing withfactored estimation: Using English to parse Korean.In Proceedings of EMNLP 2004, 49?56, Barcelona,Spain.M.
Surdeanu, S. Harabagiu, J. Williams, P. Aarseth.2003.
Using predicate-argument structures for infor-mation extraction.
In Proceedings of ACL 2003, 8?15,Sapporo, Japan.D.
Yarowsky, G. Ngai, R. Wicentowski.
2001.
Inducingmultilingual text analysis tools via robust projectionacross aligned corpora.
In Proceedings of HLT 2001,161?168.866
