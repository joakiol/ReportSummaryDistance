Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 74?83,Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational LinguisticsTowards Creating Precision Grammars from Interlinear Glossed Text:Inferring Large-Scale Typological PropertiesEmily M. Bender Michael Wayne Goodman Joshua Crowgey Fei XiaDepartment of LinguisticsUniversity of WashingtonSeattle WA 98195-4340{ebender,goodmami,jcrowgey,fxia}@uw.eduAbstractWe propose to bring together two kinds oflinguistic resources?interlinear glossedtext (IGT) and a language-independentprecision grammar resource?to automat-ically create precision grammars in thecontext of language documentation.
Thispaper takes the first steps in that directionby extracting major-constituent word or-der and case system properties from IGTfor a diverse sample of languages.1 IntroductionHale et al(1992) predicted that more than 90%of the world?s approximately 7,000 languages willbecome extinct by the year 2100.
This is a crisisnot only for the field of linguistics?on track tolose the majority of its primary data?but also acrisis for the social sciences more broadly as lan-guages are a key piece of cultural heritage.
Thefield of linguistics has responded with increasedefforts to document endangered languages.
Lan-guage documentation not only captures key lin-guistic data (both primary data and analyticalfacts) but also supports language revitalization ef-forts.
It must include both primary data collec-tion (as in Abney and Bird?s (2010) universal cor-pus) and analytical work elucidating the linguisticstructures of each language.
As such, the outputsof documentary linguistics are dictionaries, de-scriptive (prose) grammars as well as transcribedand translated texts (Woodbury, 2003).Traditionally, these outputs were printed ar-tifacts, but the field of documentary linguisticshas increasingly realized the benefits of producingdigital artifacts as well (Nordhoff and Poggeman,2012).
Bender et al(2012a) argue that the docu-mentary value of electronic descriptive grammarscan be significantly enhanced by pairing them withimplemented (machine-readable) precision gram-mars and grammar-derived treebanks.
However,the creation of such precision grammars is timeconsuming, and the cost of developing them mustbe brought down if they are to be effectively inte-grated into language documentation projects.In this work, we are interested in leveragingexisting linguistic resources of two distinct typesin order to facilitate the development of precisiongrammars for language documentation.
The firsttype of linguistic resource is collections of inter-linear glossed text (IGT), a typical format for dis-playing linguistic examples.
A sample of IGTfrom Shona is shown in (1).
(1) Ndakangandi-aka-ngaSBJ.1SG-RP-AUXndakatengandi-aka-teng-aSBJ.1SG-RP-buy-FVmucheromu-cheroCL3-fruit?I had bought fruit.?
[sna] (Toews, 2009:34)The annotations in IGT result from deep linguisticanalysis and represent much effort on the part offield linguists.
These rich annotations include thesegmentation of the source line into morphemes,the glossing of those individual morphemes, andthe translation into a language of broader commu-nication.
The IGT format was developed to com-pactly display this information to other linguists.Here, we propose to repurpose such data in the au-tomatic development of further resources.The second resource we will be working withis the LinGO Grammar Matrix (Bender et al2002; 2010), an open source repository of imple-mented linguistic analyses.
The Grammar Matrixpairs a core grammar, shared across all grammarsit creates, with a series of libraries of analysesof cross-linguistically variable phenomena.
Usersaccess the system through a web-based question-naire which elicits linguistic descriptions of lan-guages and then outputs working HPSG (Pol-lard and Sag, 1994) grammar fragments compat-ible with DELPH-IN (www.delph-in.net) toolsbased on those descriptions.
For present purposes,this system can be viewed as a function whichmaps simple descriptions of languages to preci-74sion grammar fragments.
These fragments are rel-atively modest, yet they relate linguistic strings tosemantic representations (and vice versa) and areready to be built out to broad coverage.Thus we ask whether the information encodedby documentary linguists in IGT can be lever-aged to answer the Grammar Matrix?s question-naire and create a precision grammar fragmentautomatically.
The information required by theGrammar Matrix questionnaire concerns five dif-ferent aspects of linguistic systems: (i) constituentordering (including the presence/absence of con-stituent types), (ii) morphosyntactic systems, (iii)morphosyntactic features, (iv) lexical types andtheir instances and (v) morphological rules.
In thisinitial work, we target examples of types (i) and(ii): the major constituent word order and the gen-eral type of case system in a language.
The Gram-mar Matrix and other related work are describedin further in ?2.
In ?3 we present our test data andexperimental set-up.
?
?4?5 describe our method-ology and results for the two tasks, respectively,with further discussion and outlook in ?
?6?7.2 Background and Related Work2.1 The Grammar MatrixThe Grammar Matrix produces precision gram-mars on the basis of description of languagesthat include both high-level typological informa-tion and more specific detail.
Among the for-mer are aspects (i)?
(iii) listed in ?1.
The thirdof these (morphosyntactic features) concerns thetype and range of grammaticized information thata language marks in its morphology and/or syn-tax.
This includes person/number systems (e.g.,is there an inclusive/exclusive distinction in non-singular first person forms?
), the range of aspec-tual distinctions a language marks, and the rangeof cases (if any) in a language, inter alia.
The an-swers to these questions in turn cause the systemto provide relevant features that the user can ref-erence in providing the more specific informationelicited by the questionnaire ((iv) and (v) above),viz., the definition of both lexical types (e.g., firstperson dual exclusive pronouns) and morphologi-cal rules (e.g., nominative case marking on nouns).The information input by the user to the Gram-mar Matrix questionnaire is stored in a file calleda ?choices file?.
The choices file is used both inthe dynamic definition of the html pages (so thatthe features available for lexical definitions de-pend on earlier choices) and as the input to the cus-tomization script that actually produces the gram-mar fragments to spec.
The customization sys-tem distinguishes between choices files which arecomplete and consistent (and can be used to cre-ate working grammar fragments) and those whichdo not yet have answers to required questions orgive answers which are inconsistent according tothe underlying grammatical theory.
The ultimategoal of the present project is to be able to automat-ically create complete and consistent choices fileson the basis of IGT, and in fact to create completeand consistent choices files which take maximaladvantage of the analyses stored in the GrammarMatrix customization system, answering not onlythe minimal set of questions required but in fact allwhich are relevant and possible to answer based onthe information in the IGT.Creating such complete and consistent choicesfiles is a long-term project, with different ap-proches required for the different types of ques-tions outlined in ?1.
Bender et al(2012b) takesome initial steps towards answering the questionswhich define lexical rules.
We envision answeringthe questions regarding morphosyntactic featuresthrough an analysis of the grams that appear on thegloss line, with reference to the GOLD ontology(Farrar and Langendoen, 2003).
The implementa-tion of such systems in such a way that they arerobust to potentially noisy data will undoubtedlybe non-trivial.
The contribution of this paper isthe development of systems to handle one exampleeach of the questions of types (i) and (ii), namelydetecting major constituent word order and the un-derlying case system.
For the first, we build di-rectly on the work of Lewis and Xia (2008) (see?2.2).
Our experiment can be viewed as an at-tempt to reproduce their results in the context ofthe specific view of word order possibilities devel-oped in the Grammar Matrix.
The second question(that of case systems) is in some ways more sub-tle, requiring not only analysis of IGT instances inisolation and aggregation of the results, but alsoidentification of particular kinds of IGT instancesand comparison across them.2.2 RiPLesThe RiPLes project has two intertwined goals.The first goal is to create a framework that allowsthe rapid development of resources for resource-poor languages (RPLs), which is accomplished by75Figure 1: Welsh IGT with alignment and projectedsyntactic structurebootstrapping NLP tools with initial seeds createdby projecting syntactic information from resource-rich languages to RPLs through IGT.
Projectingsyntactic structures has two steps.
First, the wordsin the language line and the translation line arealigned via the gloss line.
Second, the transla-tion line is parsed by a parser for the resource-richlanguage and the parse tree is then projected tothe language line using word alignment and someheuristics as illustrated in Figure 1 (adapted fromXia and Lewis (2009)).1 Previous work has ap-plied these projected trees to enhance the perfor-mance of statistical parsers (Georgi et al 2012).Though the projected trees are noisy, they containenough information for those tasks.The second goal of RiPLes is to use the au-tomatically created resources to perform cross-lingual study on a large number of languagesto discover linguistic knowledge.
For instance,Lewis and Xia (2008) showed that IGT data en-riched with the projected syntactic structure couldbe used to determine the word order property of alanguage with a high accuracy (see ?4).
Naseemet al(2012) use this type of information (in theircase, drawn from the WALS database (Haspel-math et al 2008)) to improve multilingual depen-dency parsing.
Here, we build on this aspect ofRiPLes and begin to extend it towards the widerrange of linguistic phenomena and more detailedclassification within phenomena required by theGrammar Matrix questionnaire.2.3 Other Related WorkOur work is also situated with respect to attemptsto automatically characterize typological proper-1The details of the algorithm and experimental resultswere reported in (Xia and Lewis, 2007).ties of languages, including Daume?
III and Camp-bell?s (2007) Bayesian approach to discovering ty-pological implications and Georgi et als (2010)work on predicting (unknown) typological proper-ties by clustering languages based on known prop-erties.
Both projects use the typological databaseWALS (Haspelmath et al 2008), which has in-formation about 192 different typological proper-ties and about 2,678 different languages (thoughthe matrix is very sparse).
This approach is com-plementary to ours, and it remains an interestingquestion whether our results could be improvedby bringing in information about other typologicalproperties of the language (either extracted fromthe IGT or looked up in a typological database).Another strand of related work concerns the col-lection and curation of IGT, including the ODINproject (Lewis, 2006; Xia and Lewis, 2008),which harvests IGT from linguistics publicationsavailable over the web and TypeCraft (Beermannand Mihaylov, 2009), which facilitates the collab-orative development of IGT annotations.
TerraL-ing/SSWL2 (Syntactic Structures of the World?sLanguages) has begun a database which combinesboth typological properties and IGT illustratingthose properties, contributed by linguists.Finally, Beerman and Hellan (2011) representsanother approach to inducing grammars from IGT,by bringing the hand-built linguistic knowledgesources closer together: On the one hand, theircross-linguistic grammar resource (TypeGram) in-cludes a mechanism for mapping from stringsspecifying verb valence and valence-altering lex-ical rules to sets of grammar constraints.
Onthe other hand, their IGT authoring environment(TypeCraft) provides support for annotating exam-ples with those strings.
The approach advocatedhere attempts to bridge the gap between IGT andgrammar specification algorithmically, instead.3 Development and Test DataOur long-term goal is to produce working gram-mar fragments from IGT produced in documen-tary linguistics projects.
However, in order toevaluate the performance of approaches to answer-ing the high-level questions in the Grammar Ma-trix questionnaire, we need both IGT and gold-standard answers for a reasonably-sized sample oflanguages.
We have constructed development andtest data for this purpose on the basis of work done2http://sswl.railsplayground.net/, accessed 4/25/1376Sets of languages DEV1 (n=10) DEV2 (n=10) TEST (n=11)Range of testsuite sizes 16?359 11?229 48?216Median testsuite size 91 87 76Language families Indo-European (4), Niger- Indo-European (3), Indo-European (2), Afro-Asiatic,Congo (2), Afro-Asiatic, Dravidian (2), Algic, Austro-Asiatic, Austronesian,Japanese, Nadahup, Creole, Niger-Congo, Arauan, Carib, Karvelian,Sino-Tibetan Quechuan, Salishan N. Caucasian, Tai-Kadai, IsolateTable 1: Language families and testsuites sizes (in number of grammatical examples)by students in a class that uses the Grammar Ma-trix (Bender, 2007).
In this class, students workwith descriptive resources for languages they aretypically not familiar with to create testsuites (cu-rated collections of grammatical and ungrammat-ical examples) and Grammar Matrix choices files.Later on in the class, the students extend the gram-mar fragments output by the customization systemto handle a broader fragment of the language.
Ac-cordingly, the testsuites cover phenomena whichgo beyond the customization system.Testsuites for grammars, especially in theirearly stages of development, require examples thatare simple (isolating the phenomena illustrated bythe examples to the extent possible), built out ofa small vocabulary, and include both grammati-cal and ungrammatical examples (Lehmann et al1996).
The examples included in descriptive re-sources often don?t fit these requirements exactly.As a result, the data we are working with includeexamples invented by the students on the basis ofthe descriptive statements in their resources.3In total, we have testsuites and associatedchoices files for 31 languages, spanning 17 lan-guage families (plus one creole and one languageisolate).
The most well-represented family isIndo-European, with nine languages.
We used 20languages, in two dev sets, for algorithm develop-ment (including manual error analysis), and saved11 languages as a held-out test set to verify thegeneralizability of our approach.
Table 1 lists thelanguage families and the range of testsuite sizesfor each of these sets of languages.4 Inferring Word OrderLewis and Xia (2008) show how IGT from ODIN(Lewis, 2006) can be used to determine, with highaccuracy, the word order properties of a language.They identify 14 typological parameters related toword order for which WALS (Haspelmath et al2008) or other typological resources provide in-3Such examples are flagged in the testsuites?
meta-data.formation.
The parameter most closely relevant tothe present work is Order of Words in a Sentence(Dryer, 2011).
For this parameter, Lewis and Xiatested their method in 97 languages and found thattheir system had 99% accuracy provided the IGTcollections had at least 40 instances per language.The Grammar Matrix?s word order questionsdiffer somewhat from the typological classifi-cation that Lewis and Xia (2008) were using.Answering the Grammar Matrix questionnaireamounts to more than making a descriptive state-ment about a language.
The Grammar Matrix cus-tomization system translates collections of suchdescriptive statements into working grammar frag-ments.
In the case of word order, this most di-rectly effects the number and nature of phrasestructure rules included in the output grammar, butcan also interact with other aspects of the gram-mar (e.g., the treatment of argument optionality).More broadly, specifying the word order systemof a grammar determines both grammaticality (ac-cepting some strings, ruling out others) and, forthe fixed word orders at least, aspects of the map-ping of syntactic to semantic arguments.Lewis and Xia (2008), like Dryer (2011), gavethe six fixed orders of S, O and V plus ?no dom-inant order?.
In contrast, the Grammar Matrixdistinguishes Free (pragmatically constrained), V-final, V-initial, and V2 orders, in addition to thesix fixed orders.
It is important to note that therelationship between the word order type of a lan-guage and the actual orders attested in sentencescan be somewhat indirect.
For a fixed word orderlanguage, we would expect the order declared asits type to be the most common in running text,but not the only type available.
English, for exam-ple, is an SVO language, but several constructionsallow for other orders, including subject-auxiliaryinversion, so-called topicalization, and others:(2) Did Kim leave?
(3) The book, Kim forgot.In a language with more word order flexibility ingeneral, there may still be a preferred word order77which is the most common due to pragmatic orother constraints.
Users of the Grammar Matrixare advised to choose one of the fixed word ordersif the deviations from that order can generally beaccounted for by specific syntactic constructions,and a freer word order otherwise.The relationship between the correct word or-der choice for the Grammar Matrix customizationsystem and the distribution of actual token wordorders in our development and test data is affectedby another factor, related to Lewis and Xia?s ?IGTbias?
which we dub ?testsuite bias?.
The collec-tions of IGT we are using were constructed as test-suites for grammar engineering projects and thuscomprise examples selected or constructed to il-lustrate specific grammatical properties in a test-ing regime where one example is enough to repre-sent each sentence type of interest.
Therefore, theydo not represent a natural distribution of word or-der types.
For example, the testsuite authors mayshow the full range of possible word orders in theword order section of the testsuite and then defaultto one particular choice for other portions (thoseillustrating e.g., case systems or negation).4.1 MethodologyOur first stpes mirror the RiPLes approach, pars-ing parse the English translation of each sentenceand projecting the parsed structure onto the sourcelanguage line.
Functional tags, such as SBJ andOBJ, are added to the NP nodes on the Englishside based on our knowledge of English word or-der and then carried over to the source languageside during the projection of parse trees.
The treesare then searched for any of ten patterns: SOV,SVO, OSV, OVS, VSO, VOS, SV, VS, OV, andVO.
The six ternary patterns match when both ver-bal arguments are present in the same clause.
Thefour binary patterns are for intransitive sentencesor those with dropped arguments.
These ten pat-terns make up the observed word orders.Given our relatively limited data set (each lan-guage is one data point), we present an initialapproach to determining underlying word orderbased on heuristics informed by general linguis-tic knowledge.
We compare the distribution of ob-served word orders to distributions we expect tosee for canonical examples of underlying word or-ders.
We accomplish this by first deconstructingthe ternary observed-word-orders into binary pat-terns (the four above plus SO and OS).
This givesus three axes: one for the tendency to exhibit VSor SV order, another for VO or OV order, and an-other for OS or SO order.
By counting the ob-served word orders in the IGT examples, we canplace the language in this three-dimensional space.Figure 4.1 depicts this space with the positions ofcanonical word orders.4 The canonical word orderpositions are those found under homogeneous ob-servations.
For example, the canonical position forSOV order is when 100% of the sentences exhibitSO, OV, and SV orders; and the canonical positionfor Free word order is when each observed orderoccurs with equal frequency to its opposite order(on the same axis; e.g.
VO and OV).
We select theunderlying word order by finding which canoni-cal word order position has the shortest Euclideandistance to the observed word order position.When a language is selected as Free word or-der, we employ a secondary heuristic to decide ifit is actually V2 word order.
The V2 order cannotbe easily recognized only with the binary word or-ders, so it is not given a unique point in the three-dimensional space.
Rather, we try to recognize itby comparing the ternary orders.
A Free-order lan-guage is reclassified as V2 if SVO and OVS occurmore frequently than SOV and OSV.5OVSSOVV-finalVSOVOSVSVV-initialVOSOSSOSVOVSOVOFree/V2Figure 2: Three axes of basic word order and thepositions of canonical word orders.4.2 ResultsTable 2 shows the results we obtained for our devand test sets.
For comparison, we use a most-4Of the eight vertices of this cube, six represent canoni-cal word orders the other two impossible combinations: Thevertex for (SV, VO, OS) (e.g.)
has S both before and after O.5The VOS and VSO patterns are excluded from this com-parison, since they can go either way?there may be un-aligned constituents (i.e.
not a S, O, or V) before the verbwhich are ignored by our system.78frequent-type baseline, selecting SOV for all lan-guages, based on Dryer?s (2011) survey.
We gethigh accuracy for DEV1, low accuracy for DEV2,and moderate accuracy for TEST, but all are sig-nificantly higher than the baseline.Dataset Inferred WO BaselineDEV1 0.900 0.200DEV2 0.500 0.100TEST 0.727 0.091Table 2: Accuracy of word-order inferenceHand analysis of the errors in the dev setsshow that some languages fall victim to the test-suite bias, such as Russian, Quechua, and Tamil.All of these languages have Free word order, butour system infers SVO for Russian and SOV forQuechua and Tamil, because the authors of thetestsuites used one order significantly more thanthe others.
Similarly, the Free word order lan-guage Nishnaabemwin is inferred as V2 becausethere are more SVO and OVS patterns given thanothers.
We also see errors due to misalignmentfrom RiPLes?
syntactic projection.
The VSO lan-guage Welsh is inferred as SVO because the near-ubiquitous sentence-initial auxiliary doesn?t alignto the main verb of the English translation.5 Inferring Case SystemsCase refers to linguistic phenomena in which theform of a noun phrase (NP) varies depending onthe function of the NP in a sentence (Blake, 2001).The Grammar Matrix?s case library (Drellishak,2009) focuses on case marking of core argumentsof verbs.
Specifying a grammar for case involvesboth choosing the high-level case system to bemodeled as well as associating verb types withcase frames and defining the lexical items or lex-ical rules which mark the case on the NPs.
Here,we focus on the high-level case system questionas it is logically prior, and in some ways more in-teresting than the lexical details: Answering thisquestion requires identifying case frames of verbsin particular examples and then comparing acrossthose examples, as described below.The high-level case system of a language con-cerns the alignment of case marking between tran-sitive and intransitive clauses.
The three ele-ments in question are the subjects of intransi-tives (dubbed S), the subjects (or agent-like ar-guments) of transitives (dubbed A) and the ob-jects (or patient-like arguments) of intransitivesCase Case grams presentsystem NOM ?
ACC ERG ?
ABSnonenom-acc Xerg-abs Xsplit-erg X X(conditioned on V)Table 3: GRAM case system assignment rules(O).
Among languages which make use of case,the most common alignment type is a nominative-accusative system (Comrie 2011a,b).
In thistype, S takes the same kind of marking as A.6The Grammar Matrix case library provides nineoptions, including none, nominative-accusative,ergative-absolutive (S marked like O), tripartite (S,A and O all distinct) and several more intricatetypes.
For example, in a language with one typeof split case system the alignment is nominative-accusative in non-past tense clauses, but ergative-absolutive in past tense ones.As with major constituent word order, the con-straints implementing a case system in a grammarserve to model both grammaticality and the map-ping between syntactic and semantic arguments.Here too, the distribution of tokens may be some-thing other than a pure expression of the casealignment type.
Sources of noise in the distri-bution include: argument optionality (e.g., tran-sitives with one or more covert arguments), ar-gument frames other than simple intransitives ortransitives, and quirky case (verbs that use a non-standard case frame for their arguments, such asthe German verb helfen which selects a dative ar-gument, though the language?s general system isnominative-accusative (Drellishak, 2009)).5.1 MethodologyWe explore two possible methodologies for infer-ring case systems, one relatively na?
?ve and onemore elaborate, and compare them to a most-frequent-type baseline.
Method 1, called GRAM,considers only the gloss line of the IGT and as-sumes that it complies with the Leipzig GlossingRules (Bickel et al 2008).
These rules not onlyprescribe formatting aspects of IGT but also pro-vide a set of licensed ?grams?, or tags for grammat-ical properties that appear in the gloss line.
GRAMscans for the grams associated with case, and as-signs case systems according to Table 3.This methodology is simple to implement and6English?s residual case system is of this type.79expected to work well given Leipzig-compliantIGT.
However, since it does not model the func-tion of case, it is dependent on the IGT authors?choice of gram symbols, and may be confused byeither alternative case names (e.g., SBJ and OBJ fornominative and accusative or LOC for ergative inlanguages where it is homophonous with the loca-tive case) or by other grams which collide with thecase name-space (such as NOM for nominalizer).It also only handles four of the nine case systems(albeit the most frequent ones).Method 2, called SAO, is more theoreticallymotivated, builds on the RiPLes approach usedin inferring word order, and is designed to berobust to idiosyncratic glossing conventions.
Inthis methodology, we first identify the S, A andO arguments by projecting the information fromthe parse of the English translation (includingthe function tags) to the source sentence (and itsglosses).
We discard all items which do not appearto be simple transitive or intransitive clauses withall arguments overt, and then collect all grams foreach argument type (from all words within in theNP, including head nouns as well as determinersand adjectives).
While there are many grammati-cal features that can be marked on NPs (such asnumber, definiteness, honorifics, etc.
), the onlyones that should correlate strongly with grammat-ical function are case-marking grams.
Further-more, in any given NP, while case may be multi-ply marked, we only expect one type of case gramto appear.
We thus assume that the most frequentgram for each argument type is a case marker (ifthere are any) and assign the case system accord-ing to the following rules, where Sg, Og and Ag de-note the most frequent grams associated with theseargument positions, respectively:?
Nominative-accusative: Sg=Ag, Sg 6=Og?
Ergative-absolutive: Sg=Og, Sg 6=Ag?
No case: Sg=Ag=Og, or Sg 6=Ag 6=Og and Sg,Ag, Og also present on each of the other ar-gument types?
Tripartite: Sg 6=Ag 6=Og, and Sg, Ag, Og (vir-tually) absent from the other argument types?
Split-S: Sg 6=Ag 6=Og, and Ag and Og are bothpresent in the list for the S argument typeHere, we?re using Split-S to stand in for bothSplit-S and Fluid-S.
These are both systems wheresome S arguments are marked like A, and somelike O.
In Split-S, which is taken depends on theverb.
In Fluid-S, it depends on the interpretation ofthe verb.
These could be distinguished by lookingfor intransitive verbs that appear more than once inthe data and checking whether their S argumentsall have consistently A or O marking.This system is agnostic as to the spelling of thecase grams.
By relying on more analysis of theIGT than GRAM, it also introduces new kinds ofbrittleness.
Recognizing the difference betweengrams being present and (virtually) absent makesthe system susceptible to noise.5.2 ResultsTable 4 shows the results for the inference of case-marking systems.
Currently GRAM performs best,but both methods generally perform better thanthe baseline.
The better performance of GRAMis expected, given the small size and generallyLeipzig-compliant glossing of our data sets.
Infuture work, we plan to incorporate data fromODIN, which is likely less consistently annotatedbut more voluminous, and we expect SAO to bemore robust than GRAM to this kind of data.Dataset GRAM SAO BaselineDEV1 0.900 0.700 0.400DEV2 0.900 0.500 0.500TEST 0.545 0.545 0.455Table 4: Accuracy of case-marking inferenceWe find that GRAM is sometimes able to do wellwhen RiPLes gives alignment errors.
For exam-ple, Old Japanese is a NOM-ACC language, but thecase-marking grams (associated to postpositions)are not aligned to the NP arguments, so SAO is notable to judge their distribution.
On the other hand,SAO prevails when non-standard grams are used,such as the NOM-ACC language Hupdeh, which isannotated with SUBJ and OBJ grams.
This comple-mentarity suggests scope for system combination,which we leave to future work.6 Discussion and Future WorkOur initial results are promising, but also showremaining room for improvement.
Error analysissuggests two main directions to pursue:Overcoming testsuite bias In both the word or-der and case system tasks, we see the effect oftestsuite bias on our system results.
The testsuitesfor freer word order languages can be artificiallydominated by a particular word order that the test-suite author found convenient.
Further, the re-stricted vocabulary used in testsuites, combined80with a general preference for animates as subjects,leads to stems and certain grams potentially beingmisidentified as case markers.We believe that these aspects of testsuite biasare not typical of our true target input data, viz.,the larger collections of IGT created by fieldprojects.
On the other hand, there may be other as-pects of testsuites which are simplifying the prob-lem and to which our current methods are over-fitted.
To address these issues, we intend to lookto larger datasets in future work, both IGT collec-tions from field projects and IGT from ODIN.
Forthe field projects, we will need to construct choicesfiles.
For ODIN, we can search for data from thelanguages we already have choices files for.As we move from testsuites to test corpora(e.g., narratives collected in documentary linguis-tics projects), we expect to find different distribu-tions of word order types.
Our current methodol-ogy for extracting word order is based on idealizedlocations in our word order space for each strictword order type.
Working with naturally occurringcorpora it should be possible to gain a more em-pirically based understanding of the relationshipbetween underlying word order and sentence typedistributions.
It will be particularly interesting tosee how stable these relationships are across lan-guages with the same underlying word order typebut from different language families and/or withdifferences in other typological characteristics.Better handling of unaligned words The othermain source of error is words that remain un-aligned in the projected syntactic structure andthus only loosely incorporated into the syntaxtrees.
This includes items like case marking adpo-sitions in Japanese, which are unaligned becausethere is no corresponding word in English, andauxiliaries in Welsh, which are unaligned whenthe English translation doesn?t happen to use anauxiliary.
In the former case, our SAO methodfor case system extraction doesn?t include the casegrams in the set of grams for each NP.
In the latter,the word order inference system is unable to pickup on the VSO order represented as Aux+S+[VP].Simply fixing the attachment of the auxiliaries willnot be enough in this case, as the word order infer-ence algorithm will need to be extended to han-dle auxiliaries, but fixing the alignment is the firststep.
Alignment problems are also the main reasonour initial attempts to extract information aboutthe order of determiners and nouns haven?t yetbeen able to beat the most-frequent-type baseline.Better handling of these unaligned words isa non-trivial task, and will require bringing insources of knowledge other than the structure ofthe English translation.
The information we haveto leverage in this regard comes mainly from thegloss line and from general linguistic/typologicalknowledge which can be added to the algorithm.That is, there are types of grams which are canon-ically associated with verbal projections and typesof grams canonically associated with nominal pro-jections.
When these grams occur on unalignedelements, we can hypothesize that the elementsare auxiliaries and case-marking adpositions re-spectively.
Further typological considerations willmotivate heuristics for modifying tree structuresbased on these classifications.Other directions for future work include extend-ing this methodology to other aspects of grammat-ical description, including additional high-levelsystems (e.g., argument optionality), discoveringthe range of morphosyntactic features active in alanguage, and describing and populating lexicaltypes (e.g., common nouns with a particular gen-der).
Once we are able to answer enough of thequestionnaire that the customization system is ableto output a grammar, interesting options for de-tailed evaluation will become available.
In par-ticular, we will be able to parse the IGT (includ-ing held-out examples) with the resulting gram-mar, and then compare the resulting semantic rep-resentations to those produced by parsing the En-glish translations with tools that produce compara-ble semantic representations for English (using theEnglish Resource Grammar (Flickinger, 2000)).7 Conclusions and Future WorkIn this paper we have presented an approach tocombining two types of linguistic resources?IGT,as produced by documentary linguists and a cross-linguistic grammar resource supporting preci-sion parsing and generation?to create language-specific resources which can help enrich languagedocumentation and support language revitaliza-tion efforts.
In addition to presenting the broad vi-sion of the project, we have reported initial resultsin two case studies as a proof-of-concept.
Thoughthere is still a ways to go, we find these initial re-sults a promising indication of the approach?s abil-ity to assist in the preservation of the key type ofcultural heritage that is linguistic systems.81AcknowledgmentsWe are grateful to the students in Ling 567 at theUniversity of Washington who created the test-suites and choices files used as development andtest data in this work and to the three anonymousreviewers for helpful comments and discussion.This material is based upon work supportedby the National Science Foundation under GrantNo.
BCS-1160274.
Any opinions, findings, andconclusions or recommendations expressed in thismaterial are those of the author(s) and do not nec-essarily reflect the views of the National ScienceFoundation.ReferencesSteven Abney and Steven Bird.
2010.
The humanlanguage project: building a universal corpus of theworld?s languages.
In Proceedings of the 48th An-nual Meeting of the Association for ComputationalLinguistics, ACL ?10, pages 88?97, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Dorothee Beerman and Lars Hellan.
2011.
Induc-ing grammar from IGT.
In Proceedings of the 5thLanguage and Technology Conference: Human Lan-guage Technologies as a Challenge for ComputerScience and Linguistics (LTC 2011).Dorothee Beermann and Pavel Mihaylov.
2009.
Type-Craft: Linguistic data and knowledge sharing, openaccess and linguistic methodology.
Paper presentedat the Workshop on Small Tools in Cross-linguisticResearch, University of Utrecht.
The Netherlands.Emily M. Bender, Dan Flickinger, and Stephan Oepen.2002.
The grammar matrix: An open-source starter-kit for the rapid development of cross-linguisticallyconsistent broad-coverage precision grammars.
InJohn Carroll, Nelleke Oostdijk, and Richard Sut-cliffe, editors, Proceedings of the Workshop onGrammar Engineering and Evaluation at the 19thInternational Conference on Computational Lin-guistics, pages 8?14, Taipei, Taiwan.Emily M. Bender, Scott Drellishak, Antske Fokkens,Laurie Poulson, and Safiyyah Saleem.
2010.
Gram-mar customization.
Research on Language & Com-putation, pages 1?50.
10.1007/s11168-010-9070-1.Emily M. Bender, Sumukh Ghodke, Timothy Baldwin,and Rebecca Dridan.
2012a.
From database to tree-bank: Enhancing hypertext grammars with grammarengineering and treebank search.
In Sebastian Nord-hoff and Karl-Ludwig G. Poggeman, editors, Elec-tronic Grammaticography, pages 179?206.
Univer-sity of Hawaii Press, Honolulu.Emily M. Bender, David Wax, and Michael WayneGoodman.
2012b.
From IGT to precision grammar:French verbal morphology.
In LSA Annual MeetingExtended Abstracts 2012.Emily M. Bender.
2007.
Combining research andpedagogy in the development of a crosslinguisticgrammar resource.
In Tracy Holloway King andEmily M. Bender, editors, Proceedings of the GEAF2007 Workshop, Stanford, CA.
CSLI Publications.Balthasar Bickel, Bernard Comrie, and Martin Haspel-math.
2008.
The Leipzig glossing rules: Con-ventions for interlinear morpheme-by-morphemeglosses.
Max Planck Institute for Evolutionary An-thropology and Department of Linguistics, Univer-sity of Leipzig.Barry J. Blake.
2001.
Case.
Cambridge UniversityPress, Cambridge, second edition.Bernard Comrie.
2011a.
Alignment of case marking offull noun phrases.
In Matthew S. Dryer and MartinHaspelmath, editors, The World Atlas of LanguageStructures Online.
Max Planck Digital Library, Mu-nich.Bernard Comrie.
2011b.
Alignment of case marking ofpronouns.
In Matthew S. Dryer and Martin Haspel-math, editors, The World Atlas of Language Struc-tures Online.
Max Planck Digital Library, Munich.Hal Daume?
III and Lyle Campbell.
2007.
A Bayesianmodel for discovering typological implications.
InProceedings of the 45th Annual Meeting of the As-sociation of Computational Linguistics, pages 65?72, Prague, Czech Republic, June.
Association forComputational Linguistics.Scott Drellishak.
2009.
Widespread But Not Uni-versal: Improving the Typological Coverage of theGrammar Matrix.
Ph.D. thesis, University of Wash-ington.Matthew S. Dryer.
2011.
Order of subject, object andverb.
In Matthew S. Dryer and Martin Haspelmath,editors, The World Atlas of Language Structures On-line.
Max Planck Digital Library, Munich.Scott Farrar and Terry Langendoen.
2003.
A linguisticontology for the semantic web.
Glot International,7:97?100.Dan Flickinger.
2000.
On building a more efficientgrammar by exploiting types.
Natural LanguageEngineering, 6 (1) (Special Issue on Efficient Pro-cessing with HPSG):15 ?
28.Ryan Georgi, Fei Xia, and William Lewis.
2010.Comparing language similarity across genetic andtypologically-based groupings.
In Proceedings ofthe 23rd International Conference on Computa-tional Linguistics (Coling 2010), pages 385?393,Beijing, China, August.
Coling 2010 OrganizingCommittee.82Ryan Georgi, Fei Xia, and William Lewis.
2012.
Im-proving dependency parsing with interlinear glossedtext and syntactic projection.
In Proceedings ofCOLING 2012: Posters, pages 371?380, Mumbai,India, December.Ken Hale, Michael Krauss, Lucille J. Wata-homigie, Akira Y. Yamamoto, Colette Craig,LaVerne Masayesva Jeanne, and Nora C. England.1992.
Endangered languages.
Language, 68(1):pp.1?42.Martin Haspelmath, Matthew S. Dryer, David Gil, andBernard Comrie, editors.
2008.
The World Atlasof Language Structures Online.
Max Planck DigitalLibrary, Munich.
http://wals.info.Sabine Lehmann, Stephan Oepen, Sylvie Regnier-Prost, Klaus Netter, Veronika Lux, Judith Klein,Kirsten Falkedal, Frederik Fouvry, Dominique Esti-val, Eva Dauphin, Herve` Compagnion, Judith Baur,Lorna Balkan, and Doug Arnold.
1996.
TSNLP:Test suites for natural language processing.
In Pro-ceedings of the 16th conference on Computationallinguistics - Volume 2, COLING ?96, pages 711?716, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.William D. Lewis and Fei Xia.
2008.
Automati-cally identifying computationally relevant typolog-ical features.
In Proceedings of the Third Interna-tional Joint Conference on Natural Language Pro-cessing, pages 685?690, Hyderabad, India.William D. Lewis.
2006.
ODIN: A model for adaptingand enriching legacy infrastructure.
In Proceedingsof the e-Humanities Workshop, Held in cooperationwith e-Science, Amsterdam.Tahira Naseem, Regina Barzilay, and Amir Globerson.2012.
Selective sharing for multilingual dependencyparsing.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguis-tics (Volume 1: Long Papers), pages 629?637, JejuIsland, Korea, July.
Association for ComputationalLinguistics.Sebastian Nordhoff and Karl-Ludwig G. Poggeman,editors.
2012.
Electronic Grammaticography.
Uni-versity of Hawaii Press, Honolulu.Carl Pollard and Ivan A.
Sag.
1994.
Head-DrivenPhrase Structure Grammar.
Studies in Contempo-rary Linguistics.
The University of Chicago Pressand CSLI Publications, Chicago, IL and Stanford,CA.Carmela Toews.
2009.
The expression of tense and as-pect in Shona.
Selected Proceedings of the 39th An-nual Converence on African Linguistics, pages 32?41.Tony Woodbury.
2003.
Defining documentary lin-guistics.
Language documentation and description,1(1):35.Fei Xia and William D. Lewis.
2007.
Multilin-gual structural projection across interlinear text.In Proc.
of the Conference on Human LanguageTechnologies (HLT/NAACL 2007), pages 452?459,Rochester, New York.Fei Xia and William D. Lewis.
2008.
Repurposingtheoretical linguistic data for tool development andsearch.
In Proceedings of the Third InternationalJoint Conference on Natural Language Processing,pages 529?536, Hyderabad, India.Fei Xia and William Lewis.
2009.
Applying NLPtechnologies to the collection and enrichment of lan-guage data on the web to aid linguistic research.
InProceedings of the EACL 2009 Workshop on Lan-guage Technology and Resources for Cultural Her-itage, Social Sciences, Humanities, and Education(LaTeCH ?
SHELT&R 2009), pages 51?59, Athens,Greece, March.
Association for Computational Lin-guistics.83
