Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 127?137,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsImproving Translation via Targeted ParaphrasingPhilip ResnikLinguistics and UMIACSUniversity of Marylandresnik@umd.eduOlivia BuzekLinguistics and Computer ScienceUniversity of Marylandolivia.buzek@gmail.comChang HuComputer ScienceUniversity of Marylandchanghu@cs.umd.eduYakov KronrodLinguistics and UMIACSUniversity of Marylandyakov@umd.eduAlex QuinnComputer ScienceUniversity of Marylandaq@cs.umd.eduBenjamin B. BedersonComputer Science and UMIACSUniversity of Marylandbederson@cs.umd.eduAbstractTargeted paraphrasing is a new approach to theproblem of obtaining cost-effective, reasonablequality translation that makes use of simple andinexpensive human computations by monolin-gual speakers in combination with machinetranslation.
The key insight behind the processis that it is possible to spot likely translationerrors with only monolingual knowledge of thetarget language, and it is possible to generate al-ternative ways to say the same thing (i.e.
para-phrases) with only monolingual knowledgeof the source language.
Evaluations demon-strate that this approach can yield substantialimprovements in translation quality.1 IntroductionFor most of the world?s languages, the availability oftranslation is limited to two possibilities: high qual-ity at high cost, via professional translators, and lowquality at low cost, via machine translation (MT).
Thespectrum between these two extremes is very poorlypopulated, and at any point on the spectrum the readyavailability of translation is limited to only a smallfraction of the world?s languages.
There is, of course,a long history of technological assistance to transla-tors, improving cost effectiveness using translationmemory (Laurian, 1984; Bowker and Barlow, 2004)or other interactive tools to assist translators (Estebanet al, 2004; Khadivi et al, 2006).
And there is arecent and rapidly growing interest in crowdsourc-ing with non-professional translators, which can beremarkably effective (Munro, 2010).
However, allthese alternatives face a central availability bottle-neck: they require the participation of humans withbilingual expertise.In this paper, we report on a new exploration ofthe middle ground, taking advantage of a virtuallyunutilized resource: speakers of the source and tar-get language who are effectively monolingual, i.e.who each only know one of the two languages rel-evant for the translation task.
The solution we areproposing has the potential to provide a more costeffective approach to translation in scenarios wheremachine translation would be considered acceptableto use, if only it were generally of high enough qual-ity.
This would clearly exclude tasks like transla-tion of medical reports, business contracts, or literaryworks, where the validation of a qualified bilingualtranslator is absolutely necessary.
However, it doesinclude a great many real-world scenarios, such asfollowing news reports in another country, reading in-ternational comments about a product, or generatinga decent first draft translation of a Wikipedia pagefor Wikipedia editors to improve.The use of monolingual participants in a human-machine translation process is not entirely new.Callison-Burch et al (2004) pioneered the explo-ration of monolingual post-editing within the MTcommunity, an approach extended more recently toprovide richer information to the user by Albrecht etal.
(2009) and Koehn (2009).
There have also been atleast two independently developed human-machinetranslation frameworks that employ an iterative pro-tocol involving monolinguals on both the source andtarget side.
Morita and Ishida (2009) describe a sys-tem in which target and source language speakersperform editing of MT output to improve fluencyand adequacy, respectively; they utilize source-sideparaphrasing at a course grain level, although their ap-proach is limited to requests to paraphrase the entiresentence when the translation cannot be understood.127Bederson et al (2010) describe a similar protocol inwhich cross-language communication is enhanced bymetalinguistic communication in the user interface.Shahaf and Horvitz (2010) use machine translationas a specific instance of a general game-based frame-work for combining a range of machine and humancapabilities.We call the technique used here targeted para-phrasing.
In a nutshell, target-language monolin-guals identify parts of an initial machine translationthat don?t appear to be right, and source-languagemonolinguals provide the MT system with alterna-tive phrasings that might lead to better translations;these are then passed through MT again and the bestscoring hypothesis is selected as the final translation.This technique can be viewed as compatible withthe richer protocol- and game-based approaches, butit is considerably simpler; in Sections 2 through 4we describe the method and present evaluation re-sults on Chinese-English translation.
Unlike otherapproaches, the technique also offers clear opportu-nities to replace human participation with machinecomponents if the latter are up to the task; we discussthis in Section 5 before wrapping up in Section 6with conclusions and directions for future work.2 Targeted ParaphrasingThe starting point for our approach is an observa-tion: the source sentence provided as input to an MTsystem is just one of many ways in which the mean-ing could have been expressed, and for any givenMT system, some forms of expression are easier totranslate than others.
The same basic observationhas been applied quite fruitfully over the past severalyears to deal with statistical MT challenges involv-ing segmentation, morphological analysis, and morerecently, source language word order (Dyer, 2007;Dyer et al, 2008; Dyer and Resnik, 2010).
Here weapply it to the surface expression of meaning.For example, consider the following real exampleof translation from English to French by an automaticMT system:?
Source: Polls indicate Brown, a state senator,and Coakley, Massachusetts?
Attorney General,are locked in a virtual tie to fill the late Sen. TedKennedy?s Senate seat.?
System: Les sondages indiquent Brown,un se?nateur d?e?tat, et Coakley,Massachusetts?
Procureur ge?ne?ral, sont en-ferme?s dans une cravate virtuel a` remplir leregrette?
se?nateur Ted Kennedy?s sie`ge au Se?nat.A French speaker can look at this automatic transla-tion and see immediately that the underlined partsare wrong, even without knowing the intended sourcemeaning.
We can identify the spans in the source En-glish sentence that are responsible for these badlytranslated French spans, and change them to alterna-tive expressions with the same meaning (e.g.
chang-ing Massachusetts?
Attorney General to the AttorneyGeneral of Massachusetts); if we do so and then usethe same MT system again, we obtain a translationthat is still imperfect (e.g.
cravate means necktie),but is more acceptable:?
System: Les sondages indiquent que Brown, unse?nateur d?e?tat, et Coakley, le procureur ge?ne?raldu Massachusetts, sont enferme?s dans une cra-vate virtuel pourvoir le sie?ge au Se?nat de Sen.Ted Kennedy, qui est de?ce?de?
re?cemment.Operationally, then, translation with targeted para-phrasing includes the following steps.Initial machine translation.
For this paper, weuse the Google Translate Research API, which,among other advantages, provides word-level align-ments between the source text and its output.
Inprinciple, however, any automatic translation systemcan be used in this role, potentially at some costto quality, by performing post hoc target-to-sourcealignment.Identification of mistranslated spans.
This stepidentifies parts of the source sentence that lead toungrammatical, nonsensical, or apparently incorrecttranslations on the target side.
In the experimentsof Sections 3 and 4, this step is performed by hav-ing monolingual target speakers identify likely errorspans on the target side, as in the French exampleabove, and projecting those spans back to the sourcespans that generated them using word alignmentsas the bridge (Hwa et al, 2005; Yarowsky et al,2001).
In Section 5, we describe a heuristic but effec-tive method for performing this fully automatically.Du et al (2010), in this proceedings, explore the128use of source paraphrases without targeting appar-ent mistranslations, using lattice translation (Dyeret al, 2008) to efficiently represent and decode theresulting very large space of paraphrase alternatives.Source paraphrase generation.
This step gener-ates alternative expressions for the source spans iden-tified in the previous step.
In this paper, it is per-formed by monolingual source speakers who performthe paraphrase task: the speaker is given a sentencewith a phrase span marked, and is asked to replace themarked text with a different way of saying the samething, so that the resulting sentence still makes senseand means the same thing as the original sentence.To illustrate in English, someone seeing John andMary took a European vacation this summer mightsupply the paraphrase Mary went on a European, ver-ifying that the resulting John and Mary went on aEuropean vacation this summer preserves the origi-nal meaning.
This step can also be fully automated(Max, 2009) by taking advantage of bilingual phrase-table pivoting (Bannard and Callison-Burch, 2005);see Max (2010), in these proceedings, for a relatedapproach in which the paraphrases of a source phraseare used to refine the estimated probability distribu-tion over its possible target phrases.Generating sentential source paraphrases.
Foreach sentence, there may be multiple paraphrasedspans.
These are multiplied out to provide full-sentence paraphrases.
For example, if two non-overlapping source spans are each paraphrased inthree ways, we generate 9 sentential source para-phrases, each of which represents an alternative wayof expressing the original sentence.Machine translation of alternative sentences.The alternative source sentences, produced via para-phrase, are sent through the same MT system, anda single-best translation hypothesis is selected, e.g.on the basis of the translation system?s model score.In principle, one could also combine the alternativesinto a lattice representation and decode to find thebest path using lattice translation (Dyer et al, 2008);cf.
Du et al (2010).
One could also present trans-lation alternatives to a target speaker for selection,similarly to Callison-Burch et al (2004).Notice that with the exception of the initial trans-lation, each remaining step in this pipeline can in-volve either human participation or fully automaticprocessing.
The targeted paraphrasing frameworktherefore defines a rich set of intermediate points onthe spectrum between fully automatic and fully hu-man translation, of which we explore only a few inthis paper.3 Pilot StudyIn order to assess the potential of our approach,we conducted a small pilot study, using elevensentences in simplified Chinese selected fromthe article on ?Water?
in Chinese Wikipedia(http://zh.wikipedia.org/zh-cn/%E6%B0%B4).
Thisarticle was chosen because its topic is well knownin both English-speaking and Chinese-speaking pop-ulations.
The first five sentences were taken fromthe first paragraph of the article.
The other six sen-tences were taken from a randomly-chosen paragraphin the article.
As a preprocessing step, we removedany parenthetical items from the input sentences, e.g.?(H20)?.
The shortest sentence in this set has 12 Chi-nese characters, the longest has 54.1Human participation in this task was accomplishedusing Amazon Mechanical Turk, an online market-place that enables human performance of small ?hu-man intelligence tasks?
(HITs) in return for micropay-ments.
For each sentence, after we translated it au-tomatically (using Google Translate), three English-speaking Mechanical Turk workers (?Turkers?)
onthe target side performed identification of mistrans-lated spans.
Each span identified was projected backto its corresponding source span, and three Chinese-speaking Turkers were asked to provide paraphrasesof each source span.
These tasks were easy to per-form (no more than around 30 seconds to completeon average) and inexpensive (less than $1 for theentire pilot study).2 The Chinese source span para-phrases were then used to construct full-sentenceparaphrases, which were retranslated, once again byGoogle Translate, to produce the output of the tar-geted paraphrasing translation process.1Note that this page is not a translation of the correspondingEnglish Wikipedia page or vice versa.2The four English-speaking Turkers were recruited throughthe normal Mechanical Turk mechanism.
The three Chinese-speaking Turkers were recruited offline by the authors in order toquickly obtain results, although they participated as full-fledgedTurkers.129The initial translation outputs from Google Trans-late (GT) and the results of the targeted paraphrasingtranslation process (TP) were evaluated accordingto widely used critera of fluency and adequacy.
Flu-ency ratings were obtained on a 5-point scale fromthree native English speakers without knowledge ofChinese.
Translation adequacy ratings were obtainedfrom three native Chinese speakers who are also flu-ent in English; they assessed adequacy of Englishsentences by comparing the communicated meaningto the Chinese source sentences.Fluency was rated on the following scale:1.
Unintelligible: nothing or almost nothing of the sen-tence is comprehensible.2.
Barely intelligible: only a part of the sentence (lessthan 50%) is understandable.3.
Fairly intelligible: the major part of the sentencepasses.4.
Intelligible: all the content of the sentence is com-prehensible, but there are errors of style and/or ofspelling, or certain words are missing.5.
Very intelligible: all the content of the sentence iscomprehensible.
There are no mistakes.Adequacy was rated on the following scale:1.
None of the meaning expressed in the reference sen-tence is expressed in the sentence.2.
Little of the reference sentence meaning is expressedin the sentence.3.
Much of the reference sentence meaning is expressedin the sentence.4.
Most of the reference sentence meaning is expressedin the sentence.5.
All meaning expressed in the reference sentence ap-pears in the sentence.For each GT output, we averaged across the ratingsof the alternative TP to produce average TP fluencyand adequacy scores.
The average GT output rat-ings, measuring the pure machine translation base-line, were 2.36 for fluency and 2.91 for adequacy.Averaging across the TP outputs, these rose to 3.32and 3.49, respectively.One could argue that a more sensible evaluationis not to average across alternative TP outputs, butrather to simulate the behavior of a target-languagespeaker who simply chooses the one translationamong the alternatives that seems most fluent.
Ifwe select the most fluent TP output for each sourcesentence according to the English-speakers?
averagefluency ratings, we obtain average test set ratings of3.58 for fluency and 3.73 for adequacy.
Those arerespective gains of 0.82 and 1.21 over the baselineinitial MT output, each on a 5-point scale.Figure 1 shows a selection of outputs: we presentthe two cases where the most fluent TP alternativeshows the greatest gain in average fluency rating (bestgain +2.67); two cases near the median gain in av-erage fluency (median +1); and the worst two caseswith respect to effect on average fluency rating (worst-0.33).
The table accurately conveys a qualitative im-pression corresponding to the quantitative results: theoverall quality of translations appears to be improvedby our process consistently, despite the absence ofany bilingual input in the improvements.4 Chinese-English EvaluationAs a followup to our pilot study, we conducted anevaluation using Chinese-English test data taken fromthe NIST MT?08 machine translation evaluation, inorder to obtain fully automatic translation evaluationscores.
We report on results for 49 sentences of the1,357 in this data set.
These underwent the sametargeted paraphrasing process as in the pilot study,with the addition of a basic step to filter out cheaters:we disregarded as invalid any responses consistingpurely of ASCII characters (signifying a non-Chineseresponse) or responses that were identical to the orig-inal source text.Target English speakers identified 115 potentialmistranslation spans, or 2.3 spans per sentence, thatyielded at least one source paraphrase on the sourceChinese side.
Chinese speakers provided 138 validparaphrases.
The entire cost for the human tasks inthis experiment was $5.06, or a bit under $0.11 persentence on average.3Table 1 reports on the results, evaluating in stan-dard fashion using BLEU with the four EnglishMT?08 references for each Chinese sentence.
Sincethe targeted paraphrasing translation process (TP)produces multiple hypotheses ?
one automatic trans-lation output per sentential paraphrases ?
we se-lected the single best output for each sentence by3Invalid paraphrase responses were rejected, i.e.
zero-cost.130Condition Fluency Adequacy SentenceGT 1.33 2.33 Water play life evolve into important to use.TP 4.00 4.33 Water in the evolution of life played an important role.GT 1.33 2.67 Human civilization from the source of the majority of large riversin the domain.TP 3.33 4.67 Most of the origin of human civilization in river basin.GT 2.33 3.00 In human daily life, the water in drinking, cleaning, washing andother side to make use of an indispensable.TP 3.67 3.33 In human daily life, water for drinking, cleaning, washing and otheressential role.GT 2.00 2.33 Eastern and Western ancient Pak prime material view of both thewater regarded as a kind of basic groups into the elements, water isthe Chinese ancient five rows of a; the West ancient four elementsthat also have water.TP 3.00 3.33 East and West in ancient concept of simple substances regarded wa-ter as a basic component elements.
Among them, the five elementsof water is one of ancient China; Western ancient four elementsthat also have water.GT 4.00 4.00 Early cities will generally be in the water side of the establishment,in order to solve irrigation, drinking and sewage problems.TP 4.67 4.33 Early cities are generally built near the water to solve the irrigation,drinking and sewage problems.GT 3.0 3.33 Human very early on began to produce a water awareness.TP 2.67 3.00 Man long ago began to understand the water produced.Figure 1: Original Google Translate output (GT) for the pilot study in Section 3, together with translations produced bythe targeted paraphrase translation process (TP), selected to show a range from strong to weak improvements in fluency.131Condition BLEUGT (baseline) 28.33GT n-best oracle 28.47TP one-best 30.01TP oracle 30.79Human upper bound 49.41Table 1: Results on a 49-sentence subset of the NISTMT?08 Chinese-English test setselecting the highest scoring English translation, ac-cording to the translation score delivered with eachoutput by the Google Translate Research API.
(Theoriginal translation was, of course, included amongthe candidates for selection.)
This yielded an im-provement of 1.68 BLEU points on the 49-sentencetest set (TP one-best).One could argue that this result is simply a result ofhaving more hypotheses to choose from, not a resultof the targeted paraphrasing process itself.
In orderto rule out this possibility, we generated (n+ 1)-bestGoogle translations, setting n for each sentence tomatch the number of alternative translations gener-ated via targeted paraphrasing.
We then chose thebest translation for each sentence, among the (n+1)-best Google hypotheses, via oracle selection, usingthe TERp metric (Snover et al, 2009) to evaluateeach hypothesis against the reference translations.4The resulting BLEU score for the full set showednegligible improvement (GT n-best oracle).We did a similar oracle-best calculation usingTERp for targeted paraphrasing (TP oracle).
Theresult shows a potential gain of 2.46 BLEU pointsover the baseline, if the best scoring alternative fromthe targeted paraphrasing process were always cho-sen.In addition to aggregate scoring using BLEU, wealso looked at oracle results on a per-sentence ba-sis using TERp (since BLEU more appropriate touse at the document level, not the sentence level).Identifying the best sentential paraphrase alternativeusing TERp as an oracle, we find that the TERpscore would improve for 32 of the 49 test sentences,4An ?oracle?
telling us which variant is best is not availablein the real world, of course, but in situations like this one, oraclestudies are often used to establish the magnitude of the potentialgain (Och et al, 2004).65.3%.
For those 32 sentences, the average gain is8.36 TERp points.5 A fairer measure is the averageobtained when scoring zero gain for the 17 sentenceswhere no improvement was obtained; taking theseinto account, i.e.
assuming an oracle who chooses theoriginal translation if none of the paraphrase-basedalternatives are better, the average improvement overthe entire set of 49 sentences is 5.46 TERp points.Although we have obtained results on only a smallsubset of the full NIST MT?08 test set, our automaticevaluation confirms the qualitative impressions inFigure 1 and the subjective ratings results obtainedin our pilot study in Section 3.
The TP oracle resultsestablish that by taking advantage of monolingualhuman speakers, it is possible to obtain quite sub-stantial gains in translation quality.
The TP one-bestresults demonstrate that the majority of that oraclegain is obtained in automatic hypothesis selection,simply by selecting the paraphrase-based alternativetranslation with the highest translation score.The last line in Table 1 shows a human upperbound computed using the reference translations viacross validation; that is, for each of the four referencetranslations, we evaluate it as a hypothesized transla-tion using the other three references as ground truth;these four scores were then averaged.
The value ofthis upper bound is quite consistent with the boundcomputed similarly by Callison-Burch (2009).5 English-Chinese EvaluationAs we noted in Section 2, the targeted paraphrasingtranslation process defines a set of human-machinecombinations that do not require bilingual expertise.The previous section described human identificationof mistranslated spans on the target side, human gen-eration of paraphrases for problematic sub-sententialspans on the source side, and both automatic hypothe-sis selection and human selection (via fluency ratings,in Section 3).In this section, we take a step toward more au-tomated processing, replacing human identificationof mistranslated spans with an a fully automaticmethod.6 The idea behind our automatic error iden-tification is straightforward: if the source sentence5?Gains?
refer to a lower score: since TERp is an errormeasure, lower is better.6This section contains material we originally reported inBuzek et al (2010).132GT: WTO chief negotiator on behalf of the United States to propose substantial reduction ofagricultural subsidies, Kai Fa countries substantially reduce industrial products import tariffs to Dapo??
Doha Round of negotiations deadlock.TP: World Trade Organization negotiator suggested the United States today, a substantial reductionof agricultural subsidies, developing countries substantially reduce industrial products??
Importtariffs, in order to break the deadlock in the Doha Round of trade negotiations.REF: the main delegates at the world trade organization talks today suggested that the us make majorcuts in its agricultural subsidies and that developing countries significantly reduce import duties onindustrial products in order to break the deadlock in the doha round of trade talks .GT: Emergency session of the Palestinian prime minister Salam Fayyad state will set a new Govern-mentTP: Emergency session of the Palestinian Prime Minister Salam Fayyad will set the new governmentREF: state of emergency period ends ; palestinian prime minister fayyad to form new governmentGT: Indian territory from south to north, one week before the start after another wet season, theprovincial residents hold long drought every rain in the mood to meet the heavy rain, but did notexpect rain came unexpectedly fierce, a rain disaster, roads become rivers, low-lying areas housing tomake Mo in the water, transport almost paralyzed, Zhi Jin statistics about You nearly 500 people dueto floods were killed.TP: Indian territory from south to north, one week before the start have entered into the rainy season,provincial residents hold long drought to hope rain in the mood to meet the heavy rain, but did notfeed rain came unexpectedly fierce, a rain disaster, roads change the river, low-lying areas housingdo not water, traffic almost to a standstill, since statistics are nearly 500 people due to floods killed.REF: the whole of india , from south to north , started to progressively enter the monsoon season aweek ago .
the residents of each state all greeted the heavy rains as relief at the end of a long drought, but didn?t expect that the rain would come with unexpected violence , a real deluge .
highways havebecome rivers ; houses in low-lying areas have been surbmerged in the water ; the transport system isnearly paralyzed .
to date , figures show that nearly 500 people have unfortunately lost their lives tothe floods .GT: But the Taliban said in the meantime, the other a German hostages kidnapped in very poorhealth, began to fall into a coma and lost consciousness.TP: But the Taliban said in the meantime, another German hostages kidnapped a very weak bodyfell into a coma and began to lose consciousness.REF: but at the same time the taliban said that another german hostage who had been kidnappedwas in extremely poor health , and had started to become comatose and to lose consciousness .GT: Taliban spokesman Ahmadi told AFP in an unknown location telephone interview, said: We,through tribal elders, representatives of direct contact with South Korea.TP: Taliban spokesman Ahmadi told AFP in an unknown location telephone interview, said: We arethrough tribal elders, directly with the South Korean leadership, businessREF: taliban spokesperson ahmadi said in a telephone interview by afp at an undisclosed location :we have established direct contact with the south korean delegation through tribal elders .Figure 2: Random sample of 5 items from study in Section 4: original Google translation (GT), results of targetedparaphrasing translation process (TP), and a human reference translation.133is translated to the target and then back-translated, acomparison of the result with the original is likely toidentify places where the translation process encoun-tered difficulty.7 Briefly, we automatically translatesource F to target E, then back-translate to produce F?in the source language.
We compare F and F?
usingTERp ?
which, in addition to its use as an evaluationmetric, is a form of string-edit distance that identifiesvarious categories of differences between two sen-tences.
When at least two consecutive edits are found,we flag their smallest containing syntactic constituentas a potential source of translation difficulty.8In more detail, we posit that if an area of backtrans-lation F?
has many edits relative to original sentenceF, then that area probably comes from parts of thetarget translation that did not represent the desiredmeaning in F very well.
We only consider consec-utive edits in certain of the TERp edit categories,specifically, deletions (D), insertions (I), and shifts(S); the two remaining categories, matches (M) andparaphrases (P), indicate that the words are identicalor that the original meaning was preserved.
Further-more, we assume that while a single D, S, or I editmight be fairly meaningless, a string of at least two ofthose types of edits is likely to represent a substantiveproblem in the translation.In order to identify reasonably meaningful para-phrase units based on potential errors, we rely on asource language constituency parser.
Using the parse,we find the smallest constituent of the sentence con-taining all of the tokens in a particular error string.
Attimes, these constituents can be quite large, even theentire sentence.
To weed out these cases, we restrictconstituent length to no more than 7 tokens.For example, givenF The most recent probe to visit Jupiter was thePluto-bound New Horizons spacecraft in late Febru-ary 2007.E La investigacio?n ma?s reciente fue la visita de Ju?pitera Pluto?n de la envolvente sonda New Horizons afines de febrero de 2007.7Exactly the same insight is behind the ?source-side pseudo-referencebased feature?
employed by Soricut and Echihabi(2010) in their system for predicting the trustworthiness of trans-lations.8It is possible that the difficulty so identified involves back-translation only, not translation in the original direction.
If thatis the case, then more paraphrasing will be done than necessary,but the quality of the TP process?s output should not suffer.F?
The latest research visit Jupiter was the Pluto-boundNew Horizons spacecraft in late February 2007.spans in the the bolded phrase in F would be iden-tified, based on the TERp alignment and smallestcontaining constituent as shown in Figure 3.In order to evaluate this approach, we again useNIST MT08 data, this time going in the English-to-Chinese direction since we are assuming sourcelanguage resources not currently available for Chi-nese.9 We used English reference 0 as the sourcesentence, and the original Chinese sentence as thetarget.10The data set comprises 1,357 sentence pairs.
Us-ing the above described algorithm to automaticallyidentify possible problem areas in the translation,with the Google Translate API providing both thetranslation and back-translation, we generated 1,780potential error spans in 1,006 of the sentences, and,continuing the targeted paraphrasing process, we ob-tained up to three source paraphrases per span, forthe problemantic spans in 1,000 of those sentences.
(For six sentences, no paraphrases weres suggestedfor any of the problematic spans.)
These yieldedfull-sentence paraphrase alternatives for the 1,000sentences, which we again evaluated via an oraclestudy.For this study we used the TER metric (Snoveret al, 2006) rather than TERp.
Comparing with theGT output, we find that TP yields a better-translatedparaphrase sentence is available in 313 of the 1000cases, or 31.3%, and for those 313 cases, TER for theoracle-best paraphrase alternative improves on theTER for the original sentence by 12.16 TER points.Also taking into account the cases where there isno improvement over the baseline, the average TERscore improves by 3.8 points.
The cost for humantasks in this study ?
just paraphrases, since identi-fying problematic spans was done automatically ?was $117.48, or a bit under $0.12 per sentence.9The Stanford parser (Klein and Manning, 2002), whichwe use to identify source syntactic constituents, exists for bothEnglish and Chinese, but TERp uses English resources such asWordNet in order to capture acceptable variants of expressionfor the same meaning.
Matt Snover (personal communication) isworking on extension of TERp to other languages.10We chose reference 0 because on inspection these referencesseemed most reflective of native English grammar and usage.134NP PPNPFigure 3: TERp alignment of a source sentence and its back-translation in order to identify a problematic source span.6 Conclusions and Future WorkIn this paper we have focused on a relatively less-explored space on the spectrum between high qualityand low cost translation: sharing the burden of thetranslation task among a fully automatic system andmonolingual human participants, without requiringhuman bilingual expertise.
The monolingual par-ticipants in this framework perform straightforwardtasks: they identify parts of sentences in their lan-guage that seem to have errors, they provide sub-sentential paraphrases in context, and they judge thefluency of sentences they are presented with (or, in avariant still to be explored, they simply select whichtarget sentence they like the best).
Unlike other pro-posals for exploiting monolingual speakers in human-machine collaborative translation, the human stepshere are amenable to automation, and in additionto evaluating a mostly-human variant of our targetedparaphrasing translation framework, we also assesseda version in which the identification of mistranslatedspans (to be paraphrased) is done automatically.Our experimentation yielded a consistent patternof results, supporting the conclusion that targetedparaphrasing can lead to significant improvementsin translation, via several different measures.
First,a very small pilot study for Chinese-English trans-lation in Wikipedia provided preliminary validationthat translation fluency and accuracy can be improvedquite significantly for a set of fairly chosen test sen-tences, according to human ratings.
Second, a smallexperiment in Chinese-English translation using stan-dard NIST test sentences suggested the potential fordramatic gains using the BLEU and TERp scores,with oracle improvements of 2.46 points and 5.46points, respectively.
In addition, a non-oracle experi-ment, selecting the best hypothesis according to theMT system?s model score, yielded a gain of nearly 1.7BLEU points.
And third, in a large scale evaluationof the approach using English-Chinese translationof 1,000 sentences, this time automating the step ofidentifying potentially mistranslated parts of sourcesentences, the oracle results demonstrated that a gainof nearly 4 TER points is available.These initial studies leave considerable room forfuture work.
One important step will be to better char-acterize the relationship between cost and quality inquantitative terms: how much does it cost to obtain135how much quality improvement, and how does thatcompare with typical professional translation costs of$0.25 per word?
This question is closely connectedwith the dynamics of crowdsourcing platforms suchas Mechanical Turk ?
the cost per sentence in theseexperiments works out to be around $0.12, but trans-lation on a large scale will involve a complicatedecosystem of workers and cheaters, tasks and motiva-tions and incentives (Quinn and Bederson, 2009).
Arelated crowdsourcing issue requiring further studyis the availability of monolingual human participantsfor a range of language pairs, in order to validatethe argument that drawing on monolingual humanparticipation will significantly reduce the severity ofthe availability bottleneck.
And, of course, in theupper bound in Table 1 makes quite clear the cru-cial value added by bilingual translators, when theyare available; we hope to explore whether the tar-geted paraphrasing translation pipeline can improvethe productivity of post-editing by bilinguals, mak-ing it easier to move toward the upper bound in acost-effective way.Another set of issues concerns the underlying trans-lation technology.
A reviewer correctly notes that thevalue of the approach taken here is likely to varydepending upon the quality of the underlying trans-lation system, and the approach may break down atthe extrema, when the baseline translation is eitheralready very good or completely awful.
We choseto use Google Translate for its wide availability andthe fact that it represents a state of the art baseline tobeat; however, in future work we plan to substituteour own statistical MT systems, which will permit usto experiment across a range of translation model andlanguage model LM training set sizes, and thereforeto vary quality while keeping other system detailsconstant.
More directly connected to research in ma-chine translation, this framework provides a varietyof opportunities for improving fully automatic sta-tistical MT systems.
We plan to implement a fullyautomatic targeted paraphrasing translation pipeline,using the automated methods discussed when intro-ducing the pipeline in Section 2, including transla-tion of targeted paraphrase lattices (cf.
(Max, 2010;Du et al, 2010)).
Finally, we intend to explore theapplication of our approach in scenarios involvingless-common languages, by using a more commonlanguage as a pivot or bridge (Habash and Hu, 2009).AcknowledgmentsThis work has been supported in part by the NationalScience Foundation under awards BCS0941455 andIIS0838801.
The authors would like to thank threeanonymous reviewers for their helpful comments,and Chris Callison-Burch and Chris Dyer for theirhelpful comments and discussion.ReferencesJoshua S. Albrecht, Rebecca Hwa, and G. Elisabeta Marai.2009.
Correcting automatic translations through collab-orations between mt and monolingual target-languageusers.
In EACL ?09: Proceedings of the 12th Confer-ence of the European Chapter of the Association forComputational Linguistics, pages 60?68, Morristown,NJ, USA.
Association for Computational Linguistics.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In ACL ?05:Proceedings of the 43rd Annual Meeting on Associ-ation for Computational Linguistics, pages 597?604,Morristown, NJ, USA.
Association for ComputationalLinguistics.Benjamin B. Bederson, Chang Hu, and Philip Resnik.2010.
Translation by iterative collaboration betweenmonolingual users.
In Graphics Interface (GI) confer-ence.Lynne Bowker and Michael Barlow.
2004.
Bilingualconcordancers and translation memories: a comparativeevaluation.
In LRTWRT ?04: Proceedings of the SecondInternational Workshop on Language Resources forTranslation Work, Research and Training, pages 70?79,Morristown, NJ, USA.
Association for ComputationalLinguistics.Olivia Buzek, Philip Resnik, and Ben Bederson.
2010.
Er-ror driven paraphrase annotation using mechanical turk.In Proceedings of the NAACL HLT 2010 Workshop onCreating Speech and Language Data with Amazon?sMechanical Turk, pages 217?221, Los Angeles, June.Association for Computational Linguistics.Chris Callison-Burch, Colin Bannard, , and JoshSchroeder.
2004.
Improving statistical translationthrough editing.
In Workshop of the European Associa-tion for Machine Translation.Chris Callison-Burch.
2009.
Fast, cheap, and creative:Evaluating translation quality using Amazon?s Mechan-ical Turk.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing,pages 286?295, Singapore, August.
Association forComputational Linguistics.Jinhua Du, Jie Jiang, and Andy Way.
2010.
Facilitatingtranslation using source language paraphrase lattices.136In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, Cambridge,MA, October.
Association for Computational Linguis-tics.Chris Dyer and Philip Resnik.
2010.
Forest translation.In NAACL?10.C.
Dyer, S. Muresan, and P. Resnik.
2008.
Generalizingword lattice translation.
In Proceedings of HLT-ACL,Columbus, OH.C.
Dyer.
2007.
Noisier channel translation: translationfrom morphologically complex languages.
In Proceed-ings of the Second Workshop on Statistical MachineTranslation, Prague, June.Jose?
Esteban, Jose?
Lorenzo, Antonio S. Valderra?banos,and Guy Lapalme.
2004.
Transtype2 - an innovativecomputer-assisted translation system.
In The Compan-ion Volume to the Proceedings of 42st Annual Meetingof the Association for Computational Linguistics, pages94?97, Barcelona, Spain, jul.
Association for Computa-tional Linguistics.
TT2.Nizar Habash and Jun Hu.
2009.
Improving arabic-chinese statistical machine translation using englishas pivot language.
In StatMT ?09: Proceedings of theFourth Workshop on Statistical Machine Translation,pages 173?181, Morristown, NJ, USA.
Association forComputational Linguistics.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Nat.
Lang.
Eng., 11(3):311?325.Shahram Khadivi, Richard Zens, and Hermann Ney.
2006.Integration of speech to computer-assisted translationusing finite-state automata.
In Proceedings of the COL-ING/ACL on Main conference poster sessions, pages467?474, Morristown, NJ, USA.
Association for Com-putational Linguistics.Dan Klein and Christopher D. Manning.
2002.
Fastexact inference with a factored model for natural lan-guage parsing.
In Suzanna Becker, Sebastian Thrun,and Klaus Obermayer, editors, Advances in NeuralInformation Processing Systems 15 - Neural Informa-tion Processing Systems, NIPS 2002, pages 3?10.
MITPress.Philipp Koehn.
2009.
A web-based interactive computeraided translation tool.
In Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 17?20,Suntec, Singapore, August.
Association for Computa-tional Linguistics.Anne-Marie Laurian.
1984.
Machine translation : Whattype of post-editing on what type of documents forwhat type of users.
In 10th International Conference onComputational Linguistics and 22nd Annual Meetingof the Association for Computational Linguistics.Aure?lien Max.
2009.
Sub-sentencial paraphrasing by con-textual pivot translation.
In Proceedings of the 2009Workshop on Applied Textual Inference, pages 18?26,Suntec, Singapore, August.
Association for Computa-tional Linguistics.Aure?lien Max.
2010.
Example-based paraphrasing forimproved phrase-based statistical machine translation.In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, Cambridge,MA, October.
Association for Computational Linguis-tics.Daisuke Morita and Toru Ishida.
2009.
Designing pro-tocols for collaborative translation.
In PRIMA ?09:Proceedings of the 12th International Conference onPrinciples of Practice in Multi-Agent Systems, pages17?32, Berlin, Heidelberg.
Springer-Verlag.Robert Munro.
2010.
Haiti emergency response: thepower of crowdsourcing and SMS.
Relief 2.0 in Haiti,Stanford, CA.Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,Anoop Sarkar, Kenji Yamada, Alexander Fraser,Shankar Kumar, Libin Shen, David Smith, KatherineEng, Viren Jain, Zhen Jin, and Dragomir R. Radev.2004.
A smorgasbord of features for statistical ma-chine translation.
In HLT-NAACL, pages 161?168.Alex Quinn and Benjamin B. Bederson.
2009.
A tax-onomy of distributed human computation.
TechnicalReport HCIL-2009-23, University of Maryland, Octo-ber.D.
Shahaf and E. Horvitz.
2010.
Generalized task marketsfor human and machine computation.
In AAAI 2010,July.Matthew Snover, Bonnie Dorr, Richard Schwartz, LinneaMicciulla, and John Makhoul.
2006.
A study of trans-lation edit rate with targeted human annotation.
In InProceedings of Association for Machine Translation inthe Americas, pages 223?231.Matt Snover, Nitin Madnani, Bonnie Dorr, and RichardSchwartz.
2009.
TER-Plus: Paraphrases, Semantic,and Alignment Enhancements to Translation Edit Rate.Machine Translation.Radu Soricut and Abdessamad Echihabi.
2010.
Trustrank:Inducing trust in automatic translations via ranking.
InProceedings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics, pages 612?621,Uppsala, Sweden, July.
Association for ComputationalLinguistics.David Yarowsky, Grace Ngai, and Richard Wicentowski.2001.
Inducing multilingual text analysis tools via ro-bust projection across aligned corpora.
In HLT ?01:Proceedings of the first international conference onHuman language technology research, pages 1?8, Mor-ristown, NJ, USA.
Association for Computational Lin-guistics.137
