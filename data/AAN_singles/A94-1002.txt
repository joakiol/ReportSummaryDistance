Pract i ca l  I ssues  in Automat ic  Documentat ion  Generat ionKathleen McKeown450 Computer Science BuildingColumbia UniversityNew York, NY 10027kathy@ca, columbia, oduKaren KukichBell Communication ResearchMorristown, NJ 07960-6438kukich@bellcore, comJames Shaw450 Computer Science BuildingColumbia UniversityNew York, NY  10027shaw@cs, columbia, eduAbstractPLANDoc ,  a system under joint devel-opment by Columbia and Bellcore, docu-ments the activity of planning engineersas they study telephone routes.
It takesas input a trace of the engineer's inter-action with a network planning tool andproduces 1-2 page summary.
In this pa-per, we describe the user needs analysis weperformed and how it influenced the devel-opment of PLANDoc .
In particular, weshow how it pinpointed the need for a sub-language specification, allowing us to iden-tify input messages and to characterize thedifferent sentence paraphrases for realiz-ing them.
We focus on the systematic useof conjunction i  combination with para-phrase that we developed for PLANDoc,which allows for the generation of sum-maries that are both concise-avoiding rep-etition of similar information, and fluent-avoiding repetition of similar phrasing.1 Motivat ionIn a collaborative effort between academics and in-dustry, we have embarked on a project that uses textgeneration research in service of an industrial appli-cation.
Bellcore and Columbia are jointly developinga system, PLANDoc ,  that will document the ac-tivity of planning engineers as they study telephoneroutes I.
Telephone planning engineers currently usea software tool, the Bellcore LEIS2-PLAN system,that helps them derive 20-year capacity expansionplans based on growth forecasts and economic con-straints.
PLANDoc  takes as input a trace of the en-gineer's interaction with LEIS-PLAN and producesIPLANDoc  is being developed collaboratively byKaren Kukich and Neal Morgan of Bellcore and KathyMcKeown, James Shaw, Jacques Robin, and Jong Limof Columbia University.~LEIS is a registered trademark of Bell Communica-tions Research, Piscataway, NJ.a 1-2 page summary.
The PLANDoc prototype iscurrently being tested by development teams andwill move into use by regional planners ometimethis Fall.The role of documentation has gained increasingimportance as businesses attempt to achieve higherlevels of productivity, often with fewer employees.In such environments, work must be carefully doc-umented, both to make previous business decisionsreadily available to current employees, and to pro-vide management with information needed to autho-rize major expenditures, in the willlon dollar range.Network planning managers need justification forwhy a proposed plan is best and whether alterna-tives were investigated.
Until recently this informa-tion was provided orally, if at all, due to time con-straints.
But internal auditors and public regulatorshave increased the demand for formal documenta-tion.
Indeed, lawsuits have made the lack of docu-mentation extremely costly.
In a recent settlement,Pacific Bell promised to provide increased documen-tation in lieu of an 80 million dollar rebate to ratepayers.
PLANDoc  documentation also promises tobe useful in training new planning engineers; it pro-vides a record of how experienced planning engineersarrive at their decisions, information which is notcurrently available.Because telephone network planning is currentlydone with an automated software system that pro-duces a trace, albeit cryptic, of the actions of boththe system and the user, development of an au-tomated documentation system is quite practical;input to a report generator is automatically pro-duced and readily available.
Our approach makesuse of existing text generation tools; we adopted theFUF/SURGE package(FUF5; Elhadad 93), devel-oped and widely used at Columbia (Robin 93; McK-eown et al 90; McKeown & Feiner 90; Elhadad93; Paris 87; Wolz 92), which handles the genera-tion of individual sentences.
Given the PLAN traceand the FUF/SURGE sentence generation tools, de-velopment of PLANDoc  requires bridging the gapbetween the two.
The main research problems in-clude:7?
organizing the content of the report, i.e.,content planning,?
mapping facts in the trace to sen-tence structures and choosing appropri-ate words, i.e., lexicalization.To handle these appropriately, we performed auser needs analysis to gather details about the kindsof reports that users would find helpful.
Our analysisrevealed two overriding practical considerations forthe design and implementation f the PLANDocautomatic documentation generator:?
the need for user-centered design, and?
the need for a bounded sublanguage.The first of these was motivated by the fact thatthe system would eventually be used in a live pro-duction setting.
The second was mandated by theneed for a concise, but fluent report.
The analysisshowed that reports must avoid repeating similar in-formation which occurs across input facts, while atthe same time avoiding repeating exact phrasing.In this paper, we show how PLANDoc uses asystematic ombination of conjunction and para-phrasing power to achieve these goals.
Further, weshow how we bounded their different combinationsto avoid a combinatoric explosion of possible phras-ings, while still maintaining fluency and concisenessin the generated reports.
The systematic use ofconjunction and ellipsis to achieve conciseness, com-bined with paraphrasing power, is a unique featureof the PLANDoc system.In the following sections, we first describe the userneeds analysis, then turn to a description of the sub-language and the constrained use of conjunction andparaphrasing.
We close with a discussion of our cur-rent directions.2 User -Centered  Des ignUser-needs analysis is a common practice in the de-velopment of computer-human interface systems andother end-user software.
Particularly in developing alarge scale, practical system, the needs of the usermust be studied if the resulting system is to be ac-cepted and effectively used by the users.
In this sec-tion, we describe the user-needs analysis and systemdevelopment methodology that we are using in ourongoing development of PLANDoc .Our analysis combined two complementary ap-proaches.
First, we interviewed a variety of differentgroups of people involved in the telephone networkplanning task.
Our goal was to identify potentialusers of PLANDoc and to solicit their views onhow such a system could be most helpful.
Second,we collected a set of manually-written narratives toinform the development of the generator, providinginsights on report form and content, vocabulary andsentence structure.
In this section we describe howuser interviews and corpus analysis haped the de-sign of the documentation generator.
But first weprovide some brief background information on theproblem domain.2.1 P rob lem Sett ingVoice and data service is carried to telephone cus-tomers through a complex network of routes con-sisting of copper or fiber cables supplemented byadditional equipment such as Digital Loop Carrier(DLC) systems and fiber multiplexors.
It is the tele-phone network planning engineer's job is to derivea capacity expansion (relief) plan specifying when,where, and how much new copper, fiber, multiplex-ing and other equipment to install in a route to avoidfacilities exhaustion.
This activity is an integral partof telephone operations.
New installations are costly,but at the same time facilities exhaustion can lead toa disruption in telephone service.
Currently, about1,000 planning engineers in 8 regional and indepen-dent telephone companies produce a total of about15,000 route studies per year.The engineer uses PLAN to compute an optimum,cost-effective base relief plan needed to meet forecastdemand over the next twenty years.
The base plan,however, may not always be realizable or desirabledue to political, economical, practical and other fac-tors known to the engineer but not to the computer.The engineer uses PLAN's Interactive RefinementModule that allows 'what-if' modeling to explore theeffects of various changes to the base plan.
For ex-ample, an engineer might explore requesting a DLCactivation for a given site, or changing a fiber acti-vation time.
After comparing the effects of differentrefinement scenarios, the engineer ultimately decideson a realizable relief plan to recommend to manage-ment for project authorization.Overall interaction with PLAN thus includes anautomatically generated base plan, a sequence of re-finements to explore the effects of different changesto the base, and a final proposed plan which may in-dude elements of the base plan along with a selectedset of refinements.2.2 Interv iewsWith the help of Bencore Planning and Engineeringstaff 3 we formulated an initial proposal for PLAN-Doc and drafted preliminary target narratives.
Wethen conducted a series of interviews with plan-ning engineers, managers, auditors and PLAN sup-port staff from several regional telephone compa-nies in their home offices and at two PLAN train-ing courses 4.
The work experience of the engineerswe interviewed ranged from beginner to expert.
Our3Many thanks to M. Horwath, D. Imhoff and L.Tenet.4 Some of the helpful regional Planning and Engineer-ing personnel included P. MeNeill, J. Brunet, P. King,D.
Kelly, I. MeNeill, T. Smith, C. Lowe, and G. Giles,goal was to determine how engineers actually usedthe PLAN system, whether they would find an au-tomated ocumentation facility to be helpful, and,if so, what the form and content of the narrativesshould be.We learned that novice planners often run 'bozo'refinements just to develop a feel for the process,while experienced planners sometimes run refine-ments they know will be suboptimal just for therecord, i.e., for the benefit of managers, auditorsand regulators who might ask "did you try such andsuch?".
More critical to the need for documenta-tion, we also learned that experienced planners keephandwritten notes on paper, listing their refinementsand why they tried them; they asked for a way toenter their notes on-line to keep track of their reason-ing.
Inexperienced planners asked to see narrativeswritten by experienced planners in order to learnfrom them; unfortunately few such narratives exist.Finally, all planners welcomed the idea of havingthe computer generate narratives that they couldinclude in their documentation packages, especiallyif they could add to the narratives themselves.These findings haped the content of PLANDocnarratives and the design of the system.
Specifically,they indicated that planners may not want all re-finements that they tried to appear in the narrative.For example, novice planners do not want to includetheir 'bozo' refinements, while experienced plannersdo want to include the suboptimal refinements heyran to show that their final refinements were supe-rior.
Thus, PLANDoc includes a facility that letsthe planner select a subset of refinements o be in-cluded in the final narrative.
Planners made it clearthat they use knowledge not included in PLAN tomake their decisions (e.g., corporate strategies) andthey wanted a way to record that knowledge on-line,while they were working.
This gave rise to PLAN-Doc's facility to prompt for manually-written gi-neer's notes at crucial points.
We instituted only twouser-visible changes to PLAN's original, successfulinterface, one to prompt for engineering notes andanother to allow the engineer to request a narrativeand select a subset of refinements o be included.Both options are presented using familiar PLAN in-terface commands and screen formats.
Reports aregenerated off-line.2.3 Corpus AnalysisWe also arranged for an experienced retired planningengineer, Jim Phillips, who is also a PLAN expert, towrite a corpus of target narratives based on PLANruns of actual routes.
Based on the findings from ourinterviews and on the target narratives, we arrivedall from Pacific Bell, R. Riggs, D. Spiegel, S. Sweat,L.
Doane, R. Tufts, and R. Ott, all from SouthwesternBell, S. Wasalinko from NYNEX, and C. Lazette fromAmeritech.PART 1 Route Input Data Summary (Tabular)PART 2 Narrative (Text)?
Base Plan Summary?
Refinements Summary with Engineer'sNotes?
Proposed Plan SummaryFigure 1: PLANDoc Report Formatat the report format shown in Figure 1.
It consistsof two parts, a tabular summary of route input dataand a narrative that integrates machine-generatedtext with the engineer's manually-entered notes.Our corpus of target narratives provided informa-tion on what should be included in the report andits overall structure.
Thus, it directly influenced e-velopment of both the Lexicalizer and Content Plan-ner modules of PLANDoo.
An analysis of PLAN'smenu of refinement actions and the sentences in thetarget narratives allowed us to specify a set of 31different possible message types for refinement sen-tences including, for example, fiber extensions toCSAs (Carrier Serving Areas), or DLC (Digital LoopCarrier) equipment activations or denials for CSAs.We then systematically categorized the sentencesin our corpus to reveal all the different phrasings foreach message type.
This categorization showed thatthere was tremendous variety in the possible sen-tences for each message type with respect to sentencestructure and lexical choice.
Indeed, our first imple-mentation of PLANDoc's sentence generator 5, re-suited in more than 150 paraphrases for some mes-sage classes.The target narratives also informed the designof PLANDoo's Content Planner.
Our analysis re-vealed that choosing a specific paraphrase for usein a summary depends on what has already beenmentioned (i.e., the choice is based on previous dis-course).
Furthermore, the narratives provided ex-amples of how multiple messages were frequentlycombined to form complex compound sentences.
Inorder to avoid a combinatorial explosion from com-bining many different sentences forms, we needed tospecify a bounded sublanguage for PLAN's domainthat ensured the sentence variety needed to main-tain discourse coherence and fluency while enablingthe construction of complex sentences.
Before dis-cussing this problem, we provide an actual sampleof some PLANDoc output in Figure 2.2.4 Sample PLANDoc  OutputAt present, the tabular Input Summary generator 6and the textual Refinements Summary generator ofthe PLANDoc system are fully implemented.
Fig-5written in FUF by J. Lira6written in C by N. Morgan9RUNID: REG1Run-ID REG1 started at the BASE plan.
This saved re-finement activated DLC for CSAs 3122, 3130, 3134, 3208and 3420 in the third quarter of 1994.
It demanded thatPLAN use DLC system IDLC272 for all placements inCSA 3122.
The 20 year PWE was $2110.1K, a $198.6Ksavings over the BASE plan and the 5 year IFC was$1064.0K, a $64.5K penalty over the BASE plan.Engineer's note:These CSA's are beyond 28 kf and need range extendersto provide service on copper.
Moving them to 1994 willnegate a job adding a reg bay to the office.RUNID: 3234-2This saved refinement included all DLC changes in Run-ID REG1E.
It requested the activation of DLC for CSA3234 in the second quarter of 1994 and for CSA 3233 inthe fourth quarter of 1994.
DLC systems DLC96SS andDLC96M2 were used for all placements in CSAs 3233and 3234.
For this refinement, he 20 year route PWEwas $1925.3K, a $383.4K savings over the BASE planand the 5 year IFC was $833.9K, a $165.6K savings overthe BASE plan.Engineer's note:I didn't need to demand the activation of these systemsin the refinement as they were activated at this time inthe BASE plan.
The 'idlc272' was demanded because ofthe high demand.
The non-integrated systems in CSA3234 because it is a business area.?
.
.Figure 2: PLANDoc Refinements Summaryure 2 is an abbreviated sample of a RefinementsSummary generated by PLANDoc .
The incorpo-rated Engineering Notes were entered manually bythe Planning Engineer at run time and automati-cally integrated into the narrative by PLANDoc .3 Sublanguage SpecificationIn this section we first provide a brief overview ofPLANDoc's architecture and functioning.
We thenillustrate the large number of possible sentence com-binations, describe the sublanguage specification so-lution and PLANDoc's paraphrasing and conjunc-tion capabilities.3.1 PLANDoc System Overv iewPLANDoc 's  architecture, which is shown in Fig-ure 3, draws on our previous text generation andreport generation work (McKeown 85; Kukich 83).The PLANDoc  system consists of five sequen-tial modules: a Message Generator, an Ontologizer,a Content Planner, a Lexicalizer, and a SurfaceGenerator.
Since PLAN itself is implemented in Cand PLANDoc 's  text generation modules are im-plemented in Lisp, a Message Generator module ~serves as an interface between PLAN and PLAN-Doc.
Input to the Message Generator comes from~written in C by N. MorganRUNID re81DLC 5/7/93 act yesCSU 3122 idlc272 idlc272SAT 3122 3 1994 3 1994SAT 330 3 1994 3 1994SAT 3134 3 1994 3 1994SAT 3208 3 1994 3 1994SAT 3420 3 1994 3 1994END.
2110.1 1064.0Figure 4: A portion of tracking file((cat message)(admtn ((PLANDoc-message-name RDA)(track-tag SAT)(seq-num 3)(runid r-regl)(prev-runid BASE)(status act)(saved yes)))(class refinement)(tel-type DLC)(action activation)(equipment-type all-dlc)(csa-site 3122)(date ((year 1994) (quarter 3))))Figure 5: Output oftheMessage GeneratorPLAN tracking files which record the user's actionsduring a planning session.
Figure 4 is a portion ofa tracking file; it corresponds to the paragraph la-beled RUNID REG1 in the sample PLANDoc  nar-rative above.
Shown below it (Figure 5) is a Lisprepresentation, ie., a message in attribute-value for-mat, for one refinement action in the tracking fileproduced by the Message Generator.
Output mes-sages are first passed to an Ontologizer s. The com-plete set of enriched messages is then passed to aContent Planner 9 whose job is to determine whichinformation in the messages hould appear in thevarious paragraphs and to organize the overall nar-rative.
This involves combining individual messagesto produce the input for complex sentences, choosingcue words and determining paraphrasing forms thatmaintain focus and ensure coherence.
The output ofthe Content Planner is a 'condensed' set of complexmessages, each still in hierarchical attribute-valueformat.We are using the FUF/SURGE package (FUF5;Elhadad 93; Kay 79; Halliday 85) for the Lexical-izer and Surface Generator modules of PLANDoc .We used FUF to write a lexicalization 8rammazfor PLAN's sublanguage.
The task of the Lexical-SThe Ontologizer simply enriches each message withsemantic knowledge from PLAN's domain of discourse.9written in Lisp by J. Robin and J. Shaw10PLAN(c)MessageGenerator(c)Ontologizer Content I J Surface PLANDoc Planner Lexicalizer Generator Narrative(FUF) (Lisp) (FUF) 1 1 (SURGE) ~ (text)Figure 3: PLANDoc  System Arch i tec tureizer module 1?
is twofold: 1) to map the attributesof the messages into systemic/semantic case roles,such as agent, beneficiary, process, circumstance,etc., and 2) to select content words to express thevalues of the attributes, all the while maintainingconstraints imposed by the Content Planner.
Fi-nally, the FUF/SURGE Surface Generator takesthe lexicalized messages, maps case roles into syn-tactic roles, builds the constituent structure of thesentence, fills in function words such as pronouns,prepositions, conjunctions, etc., ensures agreement,and ultimately realizes the structure as a linear sur-face sentence.8.2 Combinatorial  ExplosionTwo of the most salient characteristics of the textin our corpus are the great degree of paraphrasingfound and the frequent use of conjunction and ellip-sis.
Both characteristics arise from the fact that thedomain of discourse is limited to 31 message types,but user interactions include many variations andcombinations of those message types.
Paraphrasingis used to avoid repetition and to maintain focus;conjunction and ellipsis are used to combine mes-sages with similar attributes to form concise sum-mary sentences.
While the number of paraphrasecombinations actually occurring in the target narra-tives was small, the different combinations the usermight invoke was beyond our control and potentiallyquite large.The scope of naturally occurring paraphrasing isillustrated by the sentences derived for one mes-sage class in terms of their mapping of semantic at-tributes to lexical roles n (such as agent, beneficiary,location, etc.)
and syntactic roles (such as subject,direct object, object of preposition, etc.)
It is the jobof the PLANDoc lexicalizer to chose lexical roles forsemantic attributes; the SURGE surface generatorthen maps lexical roles into syntactic roles.The main semantic attributes of the fiber-service-extension message are:(class refinement)(tel-type fiber)1?written in FUF by J. Shaw with input from J. Lim.J.
Robin, M. Elhadad, D. Radev and D. Horowitz11Lexical roles are often referred to as semantic rolesof a sentence, where sentence semantic roles are distinctfrom domain semantic attributes.
We use "lexical roles"to avoid confusion.
(action service-extension)(extension-type T-l)(from-fiber-hub 2113)(to-csa 211S)Some of the paraphrases derived from our corpus forthis message are:1.
"This refinement extended T-1 service fromfiber hub 2113 to CSA 2115."2.
"This refinement demanded that PLAN extendT-1 service from fiber hub 2113 to CSA 2115."3.
"This refinement called for PLAN to extend T-1 service from fiber hub 2113 to CSA 2115."4.
"This refinement requested a T-1 service xten-sion from fiber hub 2113 to CSA 2115."5.
"This refinement called for a T-1 service xten-sion from fiber hub 2113 to CSA 2115."6.
"This refinement served CSA 2115 by T-1 ex-tension from fiber hub 2113."7.
"This refinement demanded that PLAN serveCSA 2115 by T-1 extension from fiber hub2113."8.
"This refinement called for PLAN to serve CSA2115 by T-1 extension from fiber hub 2113."9.
"This refinement demanded service to CSA2115 by T-1 extension from fiber hub 2113."10.
"This refinement called for service to CSA 2115by T-1 extension from fiber hub 2113.
"Note that the lexical and syntactic roles filled bythe semantic attributes in the message vary acrossparaphrases.
For example, although the semanticattribute to-csa is most often realized in the lexi-cal role location which gets mapped to the syntac-tic role object of preposition (e.g., 1, 2, 3), in someparaphrases (e.g., 6, 7, 8) it appears in the lexicalrole beneficiary which gets mapped to the syntacticrole direct object.
More dramatically, two main lex-ical variants occur for the semantic attribute action,namely the head verbs 'extend' and 'serve'.
These inturn give rise to a variety of syntactic onstructions,e.g., simple sentences, nominalizations of the headverbs in participial clauses, infinitive clauses, etc.Since passive is sometimes needed to maintain focusor coherence within a paragraph(McKeown 85), thenumber of possible paraphrases doubles.When paraphrasing is combined with conjunction,the problems compound.
Complex messages arisebecause it is often necessary to combine multiple111) "This refinement activated DLC for CSAs 2111,2112, 2113, 2114, 2115 and 2116 in 1996 QI.
"2) "This refinement activated DLC for CSA 2111 in1995 Q3, for CSAs 2112 and 2113 in 1995 Q4, andfor CSAs 2114, 2115 and 2116 in 1996 QI.
"3) "It requested the placement of a 48-fiber cable fromthe CO to section 1103 and the placement of 24-fiber cables from section 1201 to section 1301 andfrom section 2201 to section 2301 in the secondquarter of 1995.
"Figure 6: Conjunction Examplesmessages with some common and other distinct at-tributes into a single message in order to avoid re-peating similar information.
For example, if a useractivates six CSA sites for DLC in one refinementscenario, those six messages, with four common at-tributes and one distinct attribute, csa-slte, can beexpressed succinctly using conjunction and ellipsis(example 1 Figure 6).
Messages with two distinctattributes can also be easily conjoined dependingon where in the sentence they occur (example 2).A group of messages with more than two distinctattributes results in a complex compound sentence(example 3).Each of PLANDoc 's  31 message types has fiveor more semantic features; six of those 31 messagetypes are stand-alone messages; all of the remain-ing 25 messages can be combined to form compoundmessages with at least one distinct feature, half ofthose with at least two distinct features, and a fewwith three or four distinct features.
Recall that therewere at least ten active and ten passive sentenceforms for the fiber-service-extension message, whichis typical of most of the 31 message types.
Giventhe number of possible message combinations multi-plied by the number of possible paraphrases for eachmessage, the need to limit the paraphrasing powerof the PLANDoc  generator should be clear.3.3 Sublanguage SolutionSince many of the naturally occurring paraphrasesinvolved minor variations in syntax or substitutionof synonyms that formed valid collocations in somecontexts but awkward phrases in others, we choseto constrain PLANDoc 's  paraphrasing power to thefollowing four active sentence forms for most of the31 message types and their four corresponding pas-sive forms:1. simple sentence: "This refinement <verb-ed><object-np>."2.
nomlnalization: "This refinement requested the<action-nominalization> of <object-np>."3.
participial: "This refinement demanded thatPLAN <verb> <object-np>."4.
infinitive: "This refinement called for PLAN to<verb> <object-np>.
"So, for example, the active and passive nominaliza-tion forms of the fiber-activation message are:?
"This refinement requested the activation of fiberfor CSA 2115 in 1996 QI."?
"The activation of fiber for CSA 2115 in 1996 Q1was requested.
"Recall that the job of the PLANDoc Lexicalizer isto manage the mapping of semantic attributes tolexical roles for all possible combinations of com-mon and distinct attributes in compound and com-plex messages.
Constraining the sublanguage to atmost eight paraphrases greatly reduces the complex-ity of that mapping.
It also eliminates the need tospecify a complex set of collocation constraints forsynonym substitutions.
At the same time, eight po-tential paraphrases provide enough flexibility for theLexicalizer to make choices that maintain focus andcoherence and that avoid repetition.
Similar sublan-guage specifications related to the use of names, pro-nouns and deictic expressions for subsequent refer-ences, modifier constructions for noun phrases (e.g.,"This saved DLC refinement .. .
'),  and discourse cuewords (e.g., "also, finally", etc.
), provide the samemanageabil ity and flexibility benefits.3.4 Con junct ion  and  Paraphras ingDetermining when conjunction is to be used andwhat type of paraphrasing is required are both han-dled by the Content Planner.
The Content Planneris given as input a list of messages which form the fullcontent of the report.
Its task is to use knowledgeof the overall semantic ontent to determine how toorder messages and where to form sentence bound-aries.
While it could generate a separate sentence foreach input message, a common solution in many lan-guage generators, this would result in a verbose andrepetitive report.
In order to avoid repeating simi-lar information, PLANDoc uses conjunction, group-ing together semantically related attributes, to con-trol how messages are ordered in the report and toform sentence boundaries.
Note that this approachto content planning, relying on opportunistic group-ing of information based on how it can be realized inconcise linguistic form, is quite different from othersystems which tend to use either rhetorical (McKe-own 85; Moore & Paris; Hovy 91; Wahlster et al 89)or domain dependent(Paris 87; R~mbow & Korelsky92) strategies to order information.To do this, the Content Planner first groups to-gether related messages and tries to find those withthe maximum number of common attributes.
Itgroups these by common action and within this, bycommon date.
When all but one or two attributesare common, ellipsis can be used for every commonattribute, resulting in a concise form that uses a list-like structure for one or two roles of the sentence.To generate this form, the Content Planner buildsa message where one semantic role has as its value121.
"This refinement used a cutover strategy ofALL for CSAs 1111, 1112 and 1113, of MINfor CSAs 2221 and 2222 and of GROWTHfor CSA 3331."2.
*"A cutover strategy of ALL was used forCSAs 1111, 1112 and 1113, of MIN for CSAs2221 and 2222 and of GROWTH for CSA3331.
"Figure 7: Paraphrasing and Conjunctiona list and the Lexicalizer selects conjunction for thelexical role.
Examples 1 and 2 in Figure 6 illustratethese cases.However, the more messages that are grouped to-gether, the greater the number of potentially distinctattributes.
PLANDoc  groups such long compoundmessages into several separate sentences, where eachsentence has a different common partition.
It thencombines these compound sentences together into asingle conjunction.
Example 3, Figure 6, illustratesthis case.
To generate these complex forms, theContent Planner indicates for each message whichattributes are common and which are distinct.
Itthen indicates which common attributes hould begapped; depending on the attribute and its position,sometimes only the first reference is ungapped, whilein other cases all but the last is gapped.
SURGEgenerates the full sentence for each message, but sup-presses the gapped constituents when linearizing thesyntactic tree representing the sentence.
While thisapproach is less efficient, it is highly general sinceit can handle any combination of attributes withoutspecifically anticipating it.Conjunction and ellipsis cannot be generatedblindly, however.
When conjunction is used forcertain paraphrases, ambiguity and/or invalid sen-tences can result.
The examples in Figure 7 showhow conjunction using one paraphrase form (activewith verb "use") is appropriate for conjunction withtwo distinct attributes (cutover strategy and CSAsite), but a passive paraphrase for the same in-put produces an infelicitous result.
This is becauseone distinct attribute occurs to the left of the verb("ALL" in the first clause) and the other (CSA site)to the right of the verb.
Unless no ellipsis at all isused (in which case there is no point in using con-junction), it is impossible to generate a reasonablesentence.
Thus, while we have implemented a gen-eral algorithm, there are still cases that are excep-tions to our approach.
By limiting paraphrasing wehave also limited the number of these cases to a man-ageable amount.4 Re la ted  WorkOther natural language text generation systemsdesigned to summarize quantitative data include:13ANA (Kukich 83), SEMTEX (Roesner87), LFS(Iordanskaja et al 92), GOSSIP  (Iordanskaja etal.
91), STREAK (Robin 93), and FoG (Bourbeauet al 90).
All were influenced by early work on sub-language definition (Kittredge et al 83).
ANA, astock market report generator, achieves a high de-gree of fluency for complex sentences by relying ona phrasal lexicon; SEMTEX and LFS each gen-erate bilingual summaries of labor force statistics,French/English by the former, German/English bythe latter; GOSSIP  generates paragraph-length re-ports describing operating system usage using a se-mantic net formalism; STREAK generates basket-ball summaries, packing as much information into asingle sentence as possible, using complex sentencestructures uch as multiple modifiers of a noun orverb, conjunction and ellipsis; FoG generates ma-rine weather forecasts from meteorological data andremains to date the only generator in everyday in-dustrial use.
However, none of these systems makeextensive use of conjunction and paraphrasing in asystematic way.5 Future  workPLANDoc will move into actual use in Fall 1994.At this point, we will be able to fully evaluate howwell its output meets user needs.
Furthermore, weplan to augment he system so that it can producesummaries of both the base plan and the proposedplan.
Of these, the proposed plan summary presentssomewhat more of a challenge.
It should be about aparagraph in length but succinctly summarize therecommendations made by the planning engineer.Thus, the system must work within tighter spaceconstraints to include all information.
A secondproblem for this summary is that it must includeinformation from multiple sources.
The proposedplan will include elements of the base plan as wellas a subset of the refinements the engineer carriedout.
PLANDoc  must determine how to integratethese different pieces of information, with emphasison the resulting plan and less information on howit was derived.
While we can use some of the sametechniques currently used to make the refinementssummary both more concise and more fluent (i.e.,the combined use of conjunction and paraphrase),more research will be required in discourse planningand selection of textual focus.6 Conc lus ionPLANDoc demonstrates how text generation toolsdeveloped in a research environment are readyfor commercial use.
A fully implemented system,PLANDoc generates 1-2 page summaries of interac-tions between planning engineers and a developedsoftware tool.
In this paper, we have shown howPLANDoc uses a systematic ombination of con-junction and paraphrase to avoid repetition bothof information and of phrasing.
The ability to sys-tematically combine and group together related sen-tences in a wide variety of ways is a unique featureof our automated ocumentation system.
Finally,through a user needs analysis we identified and im-plemented features to improve usability of the result-ing system.
In particular, by allowing engineers toadd their own refinements notes and to modify sys-tem generated text, PLANDoc can also be viewedas an aid to documentation that will help engineersmore quickly create needed justification of why in-creased expenditures are necessary.ReferencesHourbeau, L. and Caxcagno, D. and Goldber8, E.and Kittredge, R. and A. Polguere.
1990.
Bilin-gual generation of weather forecastes in an oper-ations environment.
In Proceedings of the 13thInternational Conference on Computational Lin-guistics, COLING.Dale, R. 1992.
Generating Referring Ezpressions.ACL-MIT Press Series in Natural Language Pro-cessing, Cambridge, Ma.Elhadad, Michael 1991.
FUF: The universal unifier- user manual, version 5.0.
Tech Report CUCS-038-91, Columbia University.Elhadad, Michael 1993.
Using argumentation tocontrol lexical choice: a unification-based imple-mentation.
Ph.D. thesis, Computer Science De-partment, Columbia University.Halliday, M.A.K.
1985.
An introduction to func-tional grammar.
Edward Arnold, London.Hovy, Edward 1991.
Approaches to the planning ofcoherent ext.
In Paris, C. and Swartout, W. andMann.
W.C. (editors), Natural Language Genera-tion in Artificial Intelligence and ComputationalLinguistics, Kluwer Academic Publishers.Iordanskaja, L., R. Kittredge and A. Polguere1991.
Lexical Selection and Prarphrase in aMeaning-TextGeneration Model.
In Paris, C.and Swartout, W. and Mann.
W.C. (editors),Natural Language Generation in Artificial Intel-ligence and Computational Linguistics, KluwerAcademic Publishers, pp.
293-312.Iordanskaja, L., M. Kim, R. Kittredge, B. Lavoieand A. Polguere 1992.
Generation of ExtendedBiligual Statistical Reports.
In Proceedings ofCOLING-94, COLING, pp.
1019-1023.Kay, Martin 1979.
Functional Grammar In Pro-ceedings of the 5th Annual Meeting of the BerkeleyLinguistic Society.Kittredge, Richard and John Lehrberger 1983.
Sub.languages: Studies of Language in Restricted Se-mantic Domains, Walter DeGruyter, New York.Kukich, Kaxen 1983.
The design of a knowledge-based text generator.
In Proceedings of the ~lstConference of the Association for ComputationalLinguistics, Massachusetts Institute of Technol-ogy, Cambridge, Mass., pp 145-150.McKeown, K.R.
1985.
Using Discourse Strate-gies and Focus Constraints to Generate Natu-ral Language Tezt, newblock Studies in NaturalLanguage Processing series, Cambridge Univer-sity Press.McKeown, K., Elhadad, M., Fukumoto, Y., Lim, J.,Lombardi, C., Robin, J., and Smadja, F. 1990.Text generation in COMET In Dale, R. andMellish, C.S.
and Zock, M. (editors), CurrentResearch in Natural Language Generation.
Aca-demic Press.McKeown, K.R., and Feiner, S. 1990.
InteractiveMultimedia Explanation for Equipment Mainte-nance and Repair.
In Proceedings of the DARPASpeech and Natural Language Workshop, DARPA,Hidden Valley, Pa.Moore, J.D.
and C.L.
Paris 1989.
Planning Text forAdvisory Dialogues.
In Proceedings of the ?7thAnnual Meeting of the Association for Computa-tional Linguistics, Association for ComputationalLinguistics, Vancouver, B.C., pp.
203-11.Paris, C.L.
1987.
The Use of Explicit User Modelsin Text Generation: Tailoring to a User's Level ofExpertise.
Columbia University.Rainbow, O. and Korelsky, T. 1992.
Applied TextGeneration.
In Proceedings of the $rd Conferenceon Applied Natural Language Processing.
As-sociation for Computational Linguistics, Ttento,Italy, pp.
40-47.Robin, Jacques 1993.
A Revision-Based GenerationArchitecture for Reporting Facts in their Histor-ical Context.
In Horacek, H. and Zock, M. (edi-tors), New Concepts in Natural Language Genera-tion: Planning, Realization and Systems.
FrancesPinter, London and New York.Roesner, D. 1987.
SEMTEX: A Text Generatorfor German.
In Geraxd Kempen (editor), NaturalLanguage Generation: New Results in ArtificialIntellligence, Psychology and Linguistics.
Marti-nus Ninjhoff Publishers, pp.
133-148.Wahlster, W., Andre, E., Hecking, M., and T. Rist1989.
WIP: Knowledge-based Presentation of In-formation.
German Research Center for ArtificialIntelligence, Saarbruecken, FRG.Wolz, Ursula 1992.
Extending User Expertise in In-teractive Environments Department of ComputerScience, Columbia University.14
