Text Genre Detection Using Common Word FrequenciesE.
STAMATATOS, N. FAKOTAKIS, and G. KOKKINAKISDept.
of Electrical and Computer EngineeringUniversity of PatrasPatras, Greece, 26500stamatatos@wcl.ee.upatras.grAbstractIn this paper we present a method fordetecting the text genre quickly and easilyfollowing an approach originally proposedin authorship attribution studies which usesas style markers the frequencies ofoccurrence of the most frequent words in atraining corpus (Burrows, 1992).
In contrastto this approach we use the frequencies ofoccurrence of the most frequent words of theentire written language.
Using as testingground a part of the Wall Street Journalcorpus, we show that the most frequentwords of the British National Corpus,representing the most frequent words of thewritten English language, are more reliablediscriminators oftext genre in comparison tothe most frequent words of the trainingcorpus.
Moreover, the fi'equencies ofoccurrence of the most common punctuationmarks play an important role in terms ofaccurate text categorization aswell as whendealing with training data of limited size.IntroductionThe development of text databases via theInternet has given impetus to research incomputational linguistics towards the automatichandling of this information.
In particular, theenormous amount of texts coming fromheterogeneous sources revealed the need forrobust ext classification tools which are able tobe easily ported to other domains and naturallanguages and be employed with minimalcomputational cost.Apart from the propositional content &the text,stylistic aspects can also be used asclassificatory means.
Biber studied the stylisticdifferences between written and spokenlanguage (Biber, 1988) as well as the variationof registers in a cross-linguistic omparison(Biber, 1995) and presented a model forinterpreting the functions of various linguisticfeatures.
Unfortunately, his model can not beeasily realized using existing natural anguageprocessing tools.
On the other hand, somecomputational models for detectingautomatically the text genre have recently beenavailable (Karlgren and Cutting, 1994; Kessleret al, 1997).
Kessler gives an excellentsummarization f the potential applications of atext genre detector.
In particular, part-of-speechtagging, parsing accuracy and word-sensedisambiguation could be considerably enhancedby taking genre into account since certaingrammatical constructions or word senses areclosely related to specific genres.
Moreover, ininformation retrieval the search results could besorted according to the genre as well.Towards the automatic detection of text genre,various types of style markers (i.e., countablelinguistic features) have been proposed so far.Karlgren and Cutting (1994) use a combinationof structural markers (e.g., noun count), lexicalmarkers (e.g., "it" count), and token-levelmarkers (e.g., words per sentence average,type/token ratio, etc.).
Kessler et al (1997)avoid structural markers since they requiretagged or parsed text and replace them withcharacter-level markers (e.g., punctuation markcounts) and derivative markers, i.e., ratios andvariation measures derived from measures oflexical and character-level markers.Furthermore, some interesting stylometricapproaches have been followed in authorshipattribution studies.
Specifically, variousfunctions that attempt to represent thevocabulary richness have been proposed(Honore 1979; Sichel, 1975).
The combination808of the best vocabulary richness functions in alnultivariate model can then be used tbrcapturing the characteristics of a stylisticcategory (llohnes, 1992).
However, recentstudies have shown that the m~tjority of theseliinctions depend heavily on text-length(Tweedie and Baaycn, 1998).
Additionally,Stamatatos el al.
(1999) attempted to takeadvantage ot' ah'eady existing text processingtools by proposing the analysis-level markerstaking into account the methodology of theparticular tool that has been used to analyze thetext.
This approach requires the availability erarobust text processing tool and the time and/orconaputational cost for the calculation of thestyle markers is proportional to thecorresponding cost of the analysis of the text bythis tool.Last but not least, a stylometric approachproposed by Burrows (1987; 1992) uses as stylemarkers the li'equeneies of occurrence of themost frequent words (typically the 50 mostfi'equent words) as regards a training corpus.1"his method requires mininml computationalcost and has achieved remarkable results for awide variety of authors.
Moreover, it is domainand language independent since it does notrequire the mauual selection of the words thatbest distinguish the categories (i.e., fnnctionwords), ltowever, in order to achieve betterresults Burrows took into account someadditional restrictions, namely:?
Expansion of the contracted forms.
Forexalnple, "l'na" counts as "1" and "am".?
Separation of common homographic tbrms.For exalnple, the word "to" has the infinitiveand the prepositional form.?
Exception of proper names fi'om the list ofthe most frequent words.?
Text-sampling so that only the narrativeparts of the text contribute to thecompilation of the list of the most frequentwords.
Note that a 'narrative' part is simplydefined as 'non-dialogue'.From a computational point of view, theserestrictions (except he first one) complicate theprocedure of extracting the 1nest frequent wordsof the training corpus.
Thus, the secondrestriction requires a part-of-speech tagger, thethird has to be performed via a named-entityrecognizer, and the last requires the developmentof a robust text sampling tool able to detect henarrative parts of any text.In this paper we present a variation of tiffsapproach.
Instead of extracting the most fi'equentword list of the training corpus, we use as stylemarkers the fi'equencies of occurrence of themost fi'equent words of the entire writtenlanguage.
For English, the most frequent wordsof the written language component of the Brilisq7National Co,7ms are considered.
We show thatour approach performs better than the Burrows'original method without aking into account anyof the above restrictions.
Moreover, we showthat the frequencies of occurrence of the mostfi'equent punctuation marks contain very usefulstylistic information that can enhance theperformance ofan automatic text genre detector.The paper is organized as follows.
The nextsection describes both the corpora nsed in tiffsstudy and the procedure of extracting the mostli'equent word lists.
Section 2 includes the textgenre detection experiments while section 3contains experiments dealing with the role ofpunctuation marks.
Finally, in the last sectionsome conclusions are drawn and future workdirections are given.1 Testing Ground1.1 CorporaAs regards the English language, in the previouswork on text genre detection (Karlgren andCutting, 1994; Kessler et al, 1997) the Browncorpus was used as testing ground.
It comprisesapproximately 500 samples divided into 15categories (e.g., press editorial, press reportage,learned, etc.)
that can be considered as genres.However, this corpus was not built exclusivelytbr text genre detection purposes.
Therefore, thetexts inchlded in the same category are notalways stylistically homogeneous.
Kessler el al.,(1997) underlined this fact and attempted toavoid the problem by eliminating texts that didnot fall nneqnivocally into one of theircategories.
Moreover, some of the categories ofthe Brown corpus are either too general (e.g.,general fiction) or unlikely to be considered inthe fi'anaework of a practical application (e.g.,belles lettres, religion, etc.).
Taking all these into809I.
the2.
of3.
and4.
a5.
in6.
to7.
is8.
was9.
it10.
for1 I. with12.
he13.
be14.
on15.
i16.
that17.
by18.
at19.
you20.
's21.
are22.
not23.
his24.
this25.
from26.
but27.
had28.
which29.
she30.
they31.
or32.
an33.
were34.
we35.
their36.
been37.
has38.
have39.
will40.
would41.
her42.
n't43.
there44.
can45.
all46.
as47.
if48.
who49.
what50.
saidTable 1: The 50 most frequent words of the BNC.account we decided to use the Wall &reetJournal (WSJ) corpus as testing ground for ourapproach.
The texts comprising this corpuscover the majority of the press genres.
Althoughthere is no manual categorization of the WSJdocuments according to their genre, there areheadlines that sometimes help in predicting thecorresponding text genre.
The selection of thetexts included in the presented corpus wasperformed automatically by reading the headlinetag (<HL>) of each doculnent.
A typicalheadline tag ofa WSJ document is as follows:<HL> Market ing  & Media:@ RJR Nabisco Hires@ Adv iser  to Study@ Sale of ESPN Stake@ By Michael  J. McCarthy@ Staff  Reporter  of The Wal l  StreetJournal  </HL>Thus, we constructed a genre-corpus of fourcategories, namely: Editorials, Letters to theEditor, Reportage, and Spot news takingdocuments from the WSJ corpus of the year1989.
The documents containing the string"REVIEW & OUTLOOK (Ed i to r ia l )  :"intheir headline tag were classified as editorialswhile the documents containing the string"Let te rs  to the  Ed i to r :  '" wereconsidered as letters to the editor.
Thedocuments containing either the string"What ' s  News  -" or "Who 's  News: "were considered as spot news.
Finally, all thedocuments containing one of the followingstrings in their headline:" In ternat iona l  : ", "Market ing  &Med ia : " ,  "Po l i t i cs  & Po l i cy : " ,  or"Wor ld  Markets  : " without inchlding a linestarting with the string "@ By " wereconsidered as reportage.
The latter assures thatno signed article is considered as reportage.
Forexample, the document of the above examplewas not included ill any of the tour genrecategories.1.2 Most  F requent  WordsIn order to extract he most fi'equent words ofthe acquired corpora we used equally-sized textsamples (approximately 640k) from eachcategory providing a genre-corpus of 2560k forthe four categories.
The genre-corpus wasdivided into 160 text samples of 16k (i.e.,approximately 2,000 words) each, including 40text samples from each genre.
Hall' of the textsamples from each category were used astraining corpus and the rest as test corpus.For the extraction of the most frequent words ofthe entire English language we used the BritishNational Corpus (BNC).
This corpus consists of100M tokens covering both written and spokenlanguage.In this study we used the unlemmatized wordfrequency list of the written languagecomponent of the BNC I which comprisesroughly 89.7M tokens.
Since the homographicforms are separated, we added the frequencies ofthe words with more than one forms (e.g.
"to")in order to attain a representative ordered list ofthe most frequent words of the entire writtenlanguage.
The resulted ordered word list of the50 most frequent words is given in table 1.The comparison of the most frequent word listof the genre-corpus with the one acquired by theBNC is given in figure 1.
The common words(i.e., those included in both lists) constituteI Available at: http://www.itri.brighton.ac.uk/-Adam.Kilgarriff/bnc-rcadmc.html810apt)l'oximately 75% of tile most frequent wordsof BNC.. .
.
.
.
.
.
BNC - -  Ge,ne-corpusEEO1008060402001~?.
?e l ".
.
.
.
.  "
~  .
.
.
.
.
.
.
.
.
.
.
.
.
i .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
q .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7 .
.
.
.
.
.
.
.
.0 20 40 60 80 100Most frequent woriR of BNCFigure 1: Comparison of the most fi'equentword lists.2 Text  Genre  l )etect ionIn order to detect automatically tile text genrewe used discriminant analy.vis, a well-knownclassification technique of lnultivariate statisticsthat has been used in previous work in text genredetection (Biber, 1993; Karlgrcn and Cutting,1994).
This methodology takes somemultivariate vectors precategorized intonaturally occurring groups (i.e., training data)and extracts a set of discriminant./imctions thatdistinguish the groups.
The mathenlaticalobjective of discHminant analysis is to weightand linearly combine tile discriminatingvariables (i.e., style markers) in some way sothat the groups are tbrced to be as statisticallydistinct as possible (Eisenbeis & Avery, 1972).Then, discrinfinant analysis can be used lbrpredicting tile group membership of previouslyunseen cases (i.e., test data).in the present case, tile multivariate vectors aretile fi'equencies of occurrence of tile mostfi'equent words of the BNC lbr each text sampleand the naturally occurring groups are the fourtext genres.
We applied discriminant analysis totile training genre-corpus using 5 to 75 mostfiequent words of BNC with a step of 5 words.Tile classification models were, then, cross-validated by applying them to the correspondingtest corpus.
The same procedure was followedusing as style markers tile fi'equencies ofoccurrence of the most fi'equent words of thetraining corpus (according to the originalmethod of l~urrows).
Comparative results interms of classification error rate are given infigure 2.
As can been seen, tile best perlbrnlanceachieved by our approach is 2.5% error rate(2/80) based oil the 30 most frequent words ofthe BNC while the best performance of theBurrows' approach is 6.25% error rate (5180)based on the 55 most fi'equent words of thetraining corpus.- -  words taken from BNC.
.
.
.
.
.
.
words taken li'om training corpus4035302520151050x0 20 40 60 80Most frequent ~r~RFigure 2: Comparative classification restllts fortext genre detection.It is worih noting that tile performance of theclassification model is not improved using morewords beyond a certain threshold (in ourapproach 30 words).
This is due to tlle trainingdata overfitting.
Figure 3 shows the trainingcorpus in tile space of the first two discriminantfunctions based on the 10, 30, and 70 mostfrequent words of tile BNC.It is obvious that 10 words are not enough tbrthe sufficient discrimination of the genrecategories.
Oil tile other hand, using tile 70 mostfrequent words the discriminant functions arebiased to the training data.Furthermore, the genres Edilorial and Letters lolhe editor could be grouped into a higher levelgenre since they share common stylistic features.Similarly, tile genres Reportage and Spol newscould be grouped as well.
Note that tilepresented model managed to capture this811?
editorial10 most fi'cquent wordsA letter 0 reportage + spot news30 nms t ti'equent words 70 most ti'equenl wordsS+ ~ 0 & AA6 ~ Y++,+> {+, = ?
++++"~ I+4, + ,,, "" +' +m " 0++..= + o+,++++r+ +, , .+ + .
,~  ,~+-4 i o IP~ .- t, ~xl i "= A-6 I -2-- discriminant I (75%)  --> - discriminant 1 (68%)  -->3t,+.lo -0 E "r.I6 I4p+.+.
!I I  "+~2i II ~ 0-3 -2 -1 0--discrhnlnant 1 (71%)  -->Figure 3: The training corpus in the space of the two first discriminant functionsfor different word lists.
The numbers inside parentheses indicate thepercentage ofvariation explained by the corresponding function.information since in all the cases shown infigure 3 the first discriminant function (axis x),which accounts for the greatest part of the totalvariation, distinguishes between these high levelgenres.
Then, the second discriminant function(axis y) attempts to discriminate each of the highlevel genres into genres of more specific level.3 Punctuat ion  Mark  F requenc iesIn addition to the most fi'equent words, thepunctuation marks play an important role fordiscriminating reliably text genres.
In fact, thereare cases where the frequency of occurrence of acertain punctuation mark could be used alone forpredicting a certain text genre.
For example, aninterview is usually characterized by anuncommonly high frequency of question marks.In order to enhance the performance of thepmlt~mtasnifidetiowenm~mllm viQto account thefrequencies of occurrence of the eight mostfrequent punctuation marks, namely: period,comma, colon, semicolon, quotes, parenthesis,question mark and hyphen.
Thus, we applieddiscriminant analysis to the training genre-corpus taking into account he frequencies ofoccurrence of the above punctuation marks plus5 to 75 most frequent words of BNC with a stepof 5 words.
Thcross-validated by applying them to thecorresponding test corpus.. .
.
.
.
.
.
word frequencies only- -  word and punctuation mark fi'equencies353O252 20l ,mg +5~- 105\\0 20 40 60 80Most frequent wordsF igure  4: Classification results taking intoaccount the punctuation marks.The results are given in figure 4 together withthe performance of the model using wordfrequencies only (from figure 2) for purposes ofcomparison.
The error rate is now considerablylower and very reliable classification accuracyresults (>97%) can be achieved based on arelatively small set of style markers (i.e., thefrequencies of occurrence of the eight812punctuation marks t)lus 15 to 35 most fiequentwords).. .
.
.
.
.
.
word fi'cquencies only- -word  and pullctuation mark fi'equencies30~.
2520,- 15t~10\0 .
.
.
.
.
.
.
.
.
.
l .
.
.
.
.
.
.
.
.
r i ig 10 12 14 16 18 20 22Training thin (in icxt samples Iler genre)Figure 5: l~2rror rate vs. training data size.The role of the punctuation marks in achievingreliable classification restilts can be furtherillustrated by examining the relation betweenclassification accuracy and training data size.Towards this end, we applied discriminantanalysis to different raining corpora consistingof 10 to 20 text samples from each genre takinginto account he frequencies of occurrence of the30 most flequent words of the BNC.
Thisprocedure was followed once again taking intoaccount he eight additional style markers of thepunctuation marks (i.e., totally 38 stylemarkers).
The comparative results are given infigure 5.
As can been seen, the perlbrmance ofthe model taking into account only wordfrequencies is affected dramatically by thedecrease of the training data.
On the other hand,the performance of the model taking intoaccount both word and punctuation markfrequencies remains satisfactory (i.e., error rate< 7%) using 13 to 20 text san\]ples from eachgenre.Conc lus ionIn this paper we presented a methodology fordetecting automatically the text genre ofunrestricted text.
We followed the main idea of astylometric approach originally proposed forattributing authorship, which uses as stylemarkers the fi'equencies of occurrence of themost fi'equent words of a certain training corpus.I n  order to improve the accuracy of this modelvarious additional restrictions have beenproposed (see the introduction), which in generalcomplicate the computational processing ot' thetexts.Instead of taking into account such restrictions,we considered the fi'equencies of occurrence ofthe most fi'equent words of the entire writtenlanguage.
It has been shown that they are morereliable stylistic discriminators as regards thecombination of classification accuracy and thenumber of the required common words that haveto be taken into account.
Note that when dealingwith multivariate models, the reduction of therequired parameters i a vein crucial factor forattaining reliable results and mininfizing thecomputational cost.As testing ground in this study we used a part ofthe WSJ corpus classified into four low-levelgenres that can be grouped into two higher-levelgenres.
The automated classification modelbased on discriminant analysis applied to thefrequencies of occurrence of the most frequentwords of the BNC, that represent he mostfrequent words of the entire written Englishlanguage, managed to capture the stylistichomogeneity in both levels.Moreover, it has been shown that thefi'equencies of occurrence of the most fi'equentpunctuation marks can considerably enhance thepeM'ormance of the proposed model and increasethe reliability of the classification resultsespecially when training data of limited size areavailable.The proposed approach lneets the current rendsin natural anguage processing since:?
it is able to deal with unrestricted text,?
it requires minimal computational cost,?
it is not based on specifc characteristics of acertain domain/language.On the other hand, any of the additionalrestrictions mentioned in the introduction, andespecially the separation of the commonhomographic forlns, can still be considered.
Thecombination of this approach with style markersdealing with syntactic annotation seems to be abetter solution for a general-purpose automatedtext genre detector.
Another useful direction is813the development of a text-sampling tool able todetect different genres within the samedocument.ReferencesBiber, D. (1993).
Using Register-Diversified Corporafor General Language Studies.
ComputationalLinguistics, 19(2), pp.
2 \[ 9-242.Biber, D. (1988).
Variation Across Speech andWriting.
Cambridge University Press.Biber, D. (I 995).
Dimensions of Register Variation:A Cross-linguistic Coml)arison.
CambridgeUniversity l'ress.Burrows, J.
(1987).
Word-patterns and Story-shapes:The Statistical Analysis of Narrative Style.
Litera Wand Linguistic Computing, 2(2), pp.
61-70.Burrows, J.
(1992).
Not Unless You Ask Nicely: TheInte,'pretativc Nexus Between Analysis andInfornaation.
Literaly and Linguistic Computing,7(2), pp.
91-109.Eisenbeis, R., and R. Avery (1972).
DiscriminantAnalysis and Classification Procedures: Theo Wand Applications.
Lexington, Mass.
: D.C. Healthand Co.Hohncs, D. (1992).
A Stylometric Analysis ofMormon Scripture and Related Texts.
Journal ofthe Royal Statistical SocieO~ Series A, 155(1), pp.91-120.Honore, A.
(1979).
Some Simple Measures ofRichness of Vocabulary.
Association Jbr Literawand Linguistic Computing Bulletin, 7(2), pp.
172-177.Karlgren, J., and D. Cutting (1994).
Recognizing textGenres with Simple Metrics Using DiscriminantAnalysis.
In Proc.
of lhe 15 '1' InternationalConference on Computational Linguistics(COLING '94).Kessler, B., G. Nunberg, and H. Schutze (1997).Automatic Detection of Text Genre.
In Proc.
of35 a' Annual Meeting oJ" the Association forComputational Linguistics (ACL/EACL'97), pp.32-38.Sichel, H. (1975).
On a Distribution Law for WordFrequencies.
Journal oJ" the American StatisticalAssociaton, 70, pp.
542-547.Stamatatos, E., N. Fakotakis, and G. Kokkinakis(1999).
Automatic Anthorship Attribution.
InProc.
of the 9" Confi o\[" the European Chapter oJ"the Association Jbr Computational Linguistics(EACL '99), pp.
158-164.Twcedie, F. and Baayen, R. (1998).
How Variablemay a Constant be?
Measures of Lexical Richnessin Perspective.
Computers and the Humanities,32(5), pp.323-352.814
