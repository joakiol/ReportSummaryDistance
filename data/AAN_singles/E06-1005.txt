Computing Consensus Translation from Multiple Machine TranslationSystems Using Enhanced Hypotheses AlignmentEvgeny Matusov, Nicola Ueffing, Hermann NeyLehrstuhl fu?r Informatik VI - Computer Science DepartmentRWTH Aachen University, Aachen, Germany.
{matusov,ueffing,ney}@informatik.rwth-aachen.deAbstractThis paper describes a novel method forcomputing a consensus translation fromthe outputs of multiple machine trans-lation (MT) systems.
The outputs arecombined and a possibly new transla-tion hypothesis can be generated.
Simi-larly to the well-established ROVER ap-proach of (Fiscus, 1997) for combiningspeech recognition hypotheses, the con-sensus translation is computed by votingon a confusion network.
To create the con-fusion network, we produce pairwise wordalignments of the original machine trans-lation hypotheses with an enhanced sta-tistical alignment algorithm that explicitlymodels word reordering.
The context of awhole document of translations rather thana single sentence is taken into account toproduce the alignment.The proposed alignment and voting ap-proach was evaluated on several machinetranslation tasks, including a large vocab-ulary task.
The method was also tested inthe framework of multi-source and speechtranslation.
On all tasks and conditions,we achieved significant improvements intranslation quality, increasing e. g. theBLEU score by as much as 15% relative.1 IntroductionIn this work we describe a novel technique forcomputing a consensus translation from the out-puts of multiple machine translation systems.Combining outputs from different systemswas shown to be quite successful in automaticspeech recognition (ASR).
Voting schemes likethe ROVER approach of (Fiscus, 1997) use editdistance alignment and time information to cre-ate confusion networks from the output of severalASR systems.Some research on multi-engine machine trans-lation has also been performed in recent years.The most straightforward approaches simply se-lect, for each sentence, one of the provided hy-potheses.
The selection is made based on thescores of translation, language, and other mod-els (Nomoto, 2004; Paul et al, 2005).
Otherapproaches combine lattices or N -best lists fromseveral different MT systems (Frederking andNirenburg, 1994).
To be successful, such ap-proaches require compatible lattices and compa-rable scores of the (word) hypotheses in the lat-tices.
However, the scores of most statistical ma-chine translation (SMT) systems are not normal-ized and therefore not directly comparable.
Forsome other MT systems (e.g.
knowledge-basedsystems), the lattices and/or scores of hypothesesmay not be even available.
(Bangalore et al, 2001) used the edit distancealignment extended to multiple sequences to con-struct a confusion network from several transla-tion hypotheses.
This algorithm produces mono-tone alignments only (i. e. allows insertion, dele-tion, and substitution of words); it is not able toalign translation hypotheses with significantly dif-ferent word order.
(Jayaraman and Lavie, 2005)try to overcome this problem.
They introduce amethod that allows non-monotone alignments ofwords in different translation hypotheses for thesame sentence.
However, this approach uses manyheuristics and is based on the alignment that is per-formed to calculate a specific MT error measure;the performance improvements are reported onlyin terms of this measure.33Here, we propose an alignment procedure thatexplicitly models reordering of words in the hy-potheses.
In contrast to existing approaches, thecontext of the whole document rather than a sin-gle sentence is considered in this iterative, unsu-pervised procedure, yielding a more reliable align-ment.Based on the alignment, we construct a con-fusion network from the (possibly reordered)translation hypotheses, similarly to the approachof (Bangalore et al, 2001).
Using global systemprobabilities and other statistical models, the vot-ing procedure selects the best consensus hypoth-esis from the confusion network.
This consen-sus translation may be different from the originaltranslations.This paper is organized as follows.
In Section 2,we will describe the computation of consensustranslations with our approach.
In particular, wewill present details of the enhanced alignment andreordering procedure.
A large set of experimentalresults on several machine translation tasks is pre-sented in Section 3, which is followed by a sum-mary.2 Description of the AlgorithmThe proposed approach takes advantage of mul-tiple translations for a whole test corpus to com-pute a consensus translation for each sentence inthis corpus.
Given a single source sentence in thetest corpus, we combine M translation hypothe-ses E1, .
.
.
, EM from M MT engines.
We firstchoose one of the hypotheses Em as the primaryone.
We consider this primary hypothesis to havethe ?correct?
word order.
We then align and re-order the other, secondary hypotheses En(n =1, ..., M ;n 6= m) to match this word order.
Sinceeach hypothesis may have an acceptable word or-der, we let every hypothesis play the role of theprimary translation once, and thus align all pairsof hypotheses (En, Em); n 6= m.In the following subsections, we will explainthe word alignment procedure, the reordering ap-proach, and the construction of confusion net-works.2.1 Statistical AlignmentThe word alignment is performed in analogy to thetraining procedure in SMT.
The difference is thatthe two sentences that have to be aligned are in thesame language.
We consider the conditional prob-ability Pr(En|Em) of the event that, given Em,another hypothesis En is generated from the Em.Then, the alignment between the two hypothesesis introduced as a hidden variable:Pr(En|Em) =?APr(En,A|Em)This probability is then decomposed into the align-ment probability Pr(A|Em) and the lexicon prob-ability Pr(En|A, Em):Pr(En,A|Em) = Pr(A|Em) ?
Pr(En|A, Em)As in statistical machine translation, we makemodelling assumptions.
We use the IBM Model 1(Brown et al, 1993) (uniform distribution) and theHidden Markov Model (HMM, first-order depen-dency, (Vogel et al, 1996)) to estimate the align-ment model.
The lexicon probability of a sentencepair is modelled as a product of single-word basedprobabilities of the aligned words.The training corpus for alignment is createdfrom a test corpus of N sentences (usually a fewhundred) translated by all of the involved MT en-gines.
However, the effective size of the trainingcorpus is larger than N , since all pairs of differenthypotheses have to be aligned.
Thus, the effectivesize of the training corpus is M ?
(M ?1) ?N .
Thesingle-word based lexicon probabilities p(en|em)are initialized with normalized lexicon counts col-lected over the sentence pairs (En, Em) on thiscorpus.
Since all of the hypotheses are in the samelanguage, we count co-occurring equal words, i. e.if en is the same word as em.
In addition, we adda fraction of a count for words with identical pre-fixes.
The initialization could be furthermore im-proved by using word classes, part-of-speech tags,or a list of synonyms.The model parameters are trained iteratively inan unsupervised manner with the EM algorithmusing the GIZA++ toolkit (Och and Ney, 2003).The training is performed in the directions En ?Em and Em ?
En.
The updated lexicon tablesfrom the two directions are interpolated after eachiteration.The final alignments are determined using costmatrices defined by the state occupation probabil-ities of the trained HMM (Matusov et al, 2004).The alignments are used for reordering each sec-ondary translation En and for computing the con-fusion network.34Figure 1: Example of creating a confusion network frommonotone one-to-one word alignments (denotedwith symbol |).
The words of the primary hypothesis are printed in bold.
The symbol $ denotes a nullalignment or an ?-arc in the corresponding part of the confusion network.1.
would you like coffee or teaoriginal 2. would you have tea or coffeehypotheses 3. would you like your coffee or4.
I have some coffee tea would you likealignment would|would you|you have|like coffee|coffee or|or tea|teaand would|would you|you like|like your|$ coffee|coffee or|or $|teareordering I|$ would|would you|you like|like have|$ some|$ coffee|coffee $|or tea|tea$ would you like $ $ coffee or teaconfusion $ would you have $ $ coffee or teanetwork $ would you like your $ coffee or $I would you like have some coffee $ tea2.2 Word ReorderingThe alignment between En and the primary hy-pothesis Em used for reordering is computed as afunction of words in the secondary translation Enwith minimal costs, with an additional constraintthat identical words in En can not be all aligned tothe same word in Em.
This constraint is necessaryto avoid that reordered hypotheses with e. g. multi-ple consecutive articles ?the?
would be produced iffewer articles were used in the primary hypothesis.The new word order for En is obtained throughsorting the words in En by the indices of the wordsin Em to which they are aligned.
Two words inEn which are aligned to the same word in Em arekept in the original order.
After reordering eachsecondary hypothesis En, we determine M ?
1monotone one-to-one alignments between Em andEn, n = 1, .
.
.
,M ; n 6= m. In case of many-to-one connections of words in En to a single word inEm, we only keep the connection with the lowestalignment costs.
The one-to-one alignments areconvenient for constructing a confusion networkin the next step of the algorithm.2.3 Building Confusion NetworksGiven the M?1 monotone one-to-one alignments,the transformation to a confusion network as de-scribed by (Bangalore et al, 2001) is straightfor-ward.
It is explained by the example in Figure 1.Here, the original 4 hypotheses are shown, fol-lowed by the alignment of the reordered secondaryhypotheses 2-4 with the primary hypothesis 1.
Thealignment is shown with the | symbol, and thewords of the primary hypothesis are to the rightof this symbol.
The symbol $ denotes a null align-ment or an ?-arc in the corresponding part of theconfusion network, which is shown at the bottomof the figure.Note that the word ?have?
in translation 2 isaligned to the word ?like?
in translation 1.
Thisalignment is acceptable considering the two trans-lations alone.
However, given the presence of theword ?have?
in translation 4, this is not the bestalignment.
Yet the problems of this type can inpart be solved by the proposed approach, since ev-ery translation once plays the role of the primarytranslation.
For each sentence, we obtain a total ofM confusion networks and unite them in a singlelattice.
The consensus translation can be chosenamong different alignment and reordering paths inthis lattice.The ?voting?
on the union of confusion net-works is straightforward and analogous to theROVER system.
We sum up the probabilities ofthe arcs which are labeled with the same wordand have the same start and the same end state.These probabilities are the global probabilities as-signed to the different MT systems.
They are man-ually adjusted based on the performance of the in-volvedMT systems on a held-out development set.In general, a better consensus translation can beproduced if the words hypothesized by a better-performing system get a higher probability.
Ad-ditional scores like word confidence measures canbe used to score the arcs in the lattice.2.4 Extracting Consensus TranslationIn the final step, the consensus translation is ex-tracted as the best path from the union of confu-35Table 1: Corpus statistics of the test corpora.BTEC IWSLT04 BTEC CSTAR03 EPPS TC-STARChinese Japanese English Italian English Spanish EnglishSentences 500 506 1 073Running Words 3 681 4 131 3 092 3 176 2 942 2 889 18 896 18 289Distinct Words 893 979 1 125 1 134 1 028 942 3 302 3 742sion networks.
Note that the extracted consensustranslation can be different from the original Mtranslations.
Alternatively, the N -best hypothe-ses can be extracted for rescoring by additionalmodels.
We performed experiments with both ap-proaches.Since M confusion networks are used, the lat-tice may contain two best paths with the sameprobability, the same words, but different wordorder.
We extended the algorithm to favor morewell-formed word sequences.
We assign a higherprobability to each arc of the primary (unre-ordered) translation in each of the M confusionnetworks.
Experimentally, this extension im-proved translation fluency on some tasks.3 Experimental Results3.1 Corpus StatisticsThe alignment and voting algorithm was evaluatedon both small and large vocabulary tasks.
Initialexperiments were performed on the IWSLT 2004Chinese-English and Japanese-English tasks (Ak-iba et al, 2004).
The data for these tasks comefrom the Basic Travel Expression corpus (BTEC),consisting of tourism-related sentences.
We com-bined the outputs of several MT systems that hadofficially been submitted to the IWSLT 2004 eval-uation.
Each system had used 20K sentence pairs(180K running words) from the BTEC corpus fortraining.Experiments with translations of automaticallyrecognized speech were performed on the BTECItalian-English task (Federico, 2003).
Here, theinvolved MT systems had used about 60K sen-tence pairs (420K running words) for training.Finally, we also computed consensus translationfrom some of the submissions to the TC-STAR2005 evaluation campaign (TC-STAR, 2005).
TheTC-STAR participants had submitted translationsof manually transcribed speeches from the Euro-pean Parliament Plenary Sessions (EPPS).
In ourexperiments, we used the translations from Span-Table 2: Improved translation results for the con-sensus translation computed from 5 translationoutputs on the Chinese-English IWSLT04 task.BTEC WER PER BLEUChinese-English [%] [%] [%]worst single system ?04 58.3 46.6 34.6best single system?
?04 54.6 42.6 40.3consensus of 5 systemsfrom 2004 47.8 38.0 46.2system (*) in 2005 50.3 40.5 45.1ish to English.
The MT engines for this task hadbeen trained on 1.2M sentence pairs (32M runningwords).Table 1 gives an overview of the test corpora,on which the enhanced hypotheses alignment wascomputed, and for which the consensus transla-tions were determined.
The official IWSLT04test corpus was used for the IWSLT 04 tasks; theCSTAR03 test corpus was used for the speechtranslation task.
The March 2005 test corpus ofthe TC-STAR evaluation (verbatim condition) wasused for the EPPS task.
In Table 1, the number ofrunning words in English is the average number ofrunning words in the hypotheses, from which theconsensus translation was computed; the vocabu-lary of English is the merged vocabulary of thesehypotheses.
For the BTEC IWSLT04 corpus, thestatistics for English is given for the experimentsdescribed in Sections 3.3 and 3.5, respectively.3.2 Evaluation CriteriaWell-established objective evaluation measureslike the word error rate (WER), position-independent word error rate (PER), and the BLEUscore (Papineni et al, 2002) were used to assessthe translation quality.
All measures were com-puted with respect to multiple reference transla-tions.
The evaluation (as well as the alignmenttraining) was case-insensitive, without consider-ing the punctuation marks.363.3 Chinese-English TranslationDifferent applications of the proposed combina-tion method have been evaluated.
First, we fo-cused on combining different MT systems whichhave the same source and target language.
Theinitial experiments were performed on the BTECChinese-English task.
We combined translationsproduced by 5 different MT systems.
Table 2shows the performance of the best and the worst ofthese systems in terms of the BLEU score.
The re-sults for the consensus translation show a dramaticimprovement in translation quality.
The word er-ror rate is reduced e. g. from 54.6 to 47.8%.
Theresearch group which had submitted the best trans-lation in 2004 translated the same test set a yearlater with an improved system.
We comparedthe consensus translation with this new translation(last line of Table 2).
It can be observed that theconsensus translation based on the MT systemsdeveloped in 2004 is still superior to this 2005 sin-gle system translation in terms of all error mea-sures.We also checked how many sentences in theconsensus translation of the test corpus are differ-ent from the 5 original translations.
185 out of 500sentences (37%) had new translations.
Computingthe error measures on these sentences only, we ob-served significant improvements in WER and PERand a small improvement in BLEU with respectto the original translations.
Thus, the quality ofpreviously unseen consensus translations as gen-erated from the original translations is acceptable.In this experiment, the global system proba-bilities for scoring the confusion networks weretuned manually on a development set.
The distri-bution was 0.35, 0.25, 0.2, 0.1, 0.1, with 0.35 forthe words of the best single system and 0.1 for thewords of the worst single system.
We observedthat the consensus translation did not change sig-nificantly with small perturbations of these val-ues.
However, the relation between the proba-bilities is very important for good performance.No improvement can be achieved with a uniformprobability distribution ?
it is necessary to penal-ize translations of low quality.3.4 Spanish-English TranslationThe improvements in translation quality arealso significant on the TC-STAR EPPS Spanish-English task.
Here, we combined four differentsystems which performed best in the TC-STARTable 3: Improved translation results for the con-sensus translation computed from 4 translationoutputs on the Spanish-English TC-STAR task.EPPS WER PER BLEUSpanish-English [%] [%] [%]worst single system 49.1 38.2 39.6best single system 41.0 30.2 47.7consensus of 4 systems 39.1 29.1 49.3+ rescoring 38.8 29.0 50.72005 evaluation, see Table 3.
Compared to thebest performing single system, the consensus hy-pothesis reduces the WER from 41.0 to 39.1%.This result is further improved by rescoring theN -best lists derived from the confusion networks(N=1000).
For rescoring, a word penalty fea-ture, the IBM Model 1, and a 4-gram target lan-guage model were included.
The linear interpola-tion weights of these models and the score fromthe confusion network were optimized on a sep-arate development set with respect to word errorrate.Table 4 gives examples of improved translationquality by using the consensus translation as de-rived from the rescored N -best lists.3.5 Multi-source TranslationIn the IWSLT 2004 evaluation, the English ref-erence translations for the Chinese-English andJapanese-English test corpora were the same, ex-cept for a permutation of the sentences.
Thus, wecould combine MT systems which have differentsource and the same target language, performingmulti-source machine translation (described e. g.by (Och and Ney, 2001)).
We combined twoJapanese-English and two Chinese-English sys-tems.
The best performing system was a Japanese-English system with a BLEU score of 44.7%, seeTable 5.
By computing the consensus translation,we improved this score to 49.6%, and also signifi-cantly reduced the error rates.To investigate the potential of the proposed ap-proach, we generated the N -best lists (N = 1000)of consensus translations.
Then, for each sentence,we selected the hypothesis in the N -best list withthe lowest word error rate with respect to the mul-tiple reference translations for the sentence.
Wethen evaluated the quality of these ?oracle?
trans-lations with all error measures.
In a contrastiveexperiment, for each sentence we simply selected37Table 4: Examples of improved translation quality with the consensus translations on the Spanish-EnglishTC-STAR EPPS task (case-insensitive output).best system I also authorised to committees to certain reportsconsensus I also authorised to certain committees to draw up reportsreference I have also authorised certain committees to prepare reportsbest system human rights which therefore has fought the european unionconsensus human rights which the european union has foughtreference human rights for which the european union has fought so hardbest system we of the following the agendaconsensus moving on to the next point on the agendareference we go on to the next point of the agendaTable 5: Multi-source translation: improvementsin translation quality when computing consen-sus translation using the output of two Chinese-English and two Japanese-English systems on theIWSLT04 task.BTEC Chinese-English WER PER BLEU+ Japanese-English [%] [%] [%]worst single system 58.0 41.8 39.5best single system 51.3 38.6 44.7consensus of 4 systems 44.9 33.9 49.6Table 6: Consensus-based combination vs. se-lection: potential for improvement (multi-sourcetranslation, selection/combination of 4 translationoutputs).BTEC Chinese-English WER PER BLEU+ Japanese-English [%] [%] [%]best single system 51.3 38.6 44.7oracle selection 33.3 29.3 59.2oracle consensus(1000-best list) 27.0 22.8 64.2the translation with the lowest WER from the orig-inal 4 MT system outputs.
Table 6 shows that thepotential for improvement is significantly largerfor the consensus-based combination of transla-tion outputs than for simple selection of the besttranslation1.
In our future work, we plan to im-prove the scoring of hypotheses in the confusionnetworks to explore this large potential.3.6 Speech TranslationSome state-of-the-art speech translation systemscan translate either the first best recognition hy-1Similar ?oracle?
results were observed on other tasks.potheses or the word lattices of an ASR system.
Ithas been previously shown that word lattice inputgenerally improves translation quality.
In practice,however, the translation system may choose, forsome sentences, the paths in the lattice with manyrecognition errors and thus produce inferior trans-lations.
These translations can be improved if wecompute a consensus translation from the outputof at least two different speech translation systems.From each system, we take the translation of thesingle best ASR output, and the translation of theASR word lattice.Two different statistical MT systems capable oftranslating ASR word lattices have been comparedby (Matusov and Ney, 2005).
Both systems pro-duced translations of better quality on the BTECItalian-English speech translation task when usinglattices instead of single best ASR output.
Weobtained the output of each of the two systemsunder each of these translation scenarios on theCSTAR03 test corpus.
The first-best recognitionword error rate on this corpus is 22.3%.
The objec-tive error measures for the 4 translation hypothe-ses are given in Table 7.
We then computed a con-sensus translation of the 4 outputs with the pro-posed method.
The better performing word latticetranslations were given higher system probabili-ties.
With the consensus hypothesis, the word er-ror rate went down from 29.5 to 28.5%.
Thus, thenegative effect of recognition errors on the trans-lation quality was further reduced.4 ConclusionsIn this work, we proposed a novel, theoreticallywell-founded procedure for computing a possi-bly new consensus translation from the outputs ofmultiple MT systems.
In summary, the main con-38Table 7: Improvements in translation quality onthe BTEC Italian-English task through comput-ing consensus translations from the output of twospeech translation systems with different types ofsource language input.system input WER PER BLEU[%] [%] [%]2 correct text 23.3 19.3 65.61 a) single best 32.8 28.6 53.9b) lattice 30.7 26.7 55.92 c) single best 31.6 27.5 54.7d) lattice 29.5 26.1 58.2consensus a-d 28.5 25.0 58.9tributions of this work compared to previous ap-proaches are as follows:?
The words of the original translation hy-potheses are aligned in order to create a con-fusion network.
The alignment procedure ex-plicitly models word reordering.?
A test corpus of translations generated byeach of the systems is used for the unsuper-vised statistical alignment training.
Thus, thedecision on how to align two translations ofa sentence takes the whole document contextinto account.?
Large and significant gains in translationquality were obtained on various translationtasks and conditions.?
A significant improvement of translationquality was achieved in a multi-source trans-lation scenario.
Here, we combined theoutput of MT systems which have differentsource and the same target language.?
The proposed method can be effectively ap-plied in speech translation in order to copewith the negative impact of speech recogni-tion errors on translation accuracy.An important feature of a real-life application ofthe proposed alignment technique is that the lex-icon and alignment probabilities can be updatedwith each translated sentence and/or text.
Thus,the correspondence between words in different hy-potheses and, consequently, the consensus transla-tion can be improved overtime.5 AcknowledgementThis paper is based upon work supported bythe Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-06-C-0023.
This work was also in part funded by theEuropean Union under the integrated project TC-STAR ?
Technology and Corpora for Speech toSpeech Translation (IST-2002-FP6-506738).ReferencesY.
Akiba, M. Federico, N. Kando, H. Nakaiwa,M.
Paul, and J. Tsujii.
2004.
Overview of theIWSLT04 Evaluation Campaign.
Int.
Workshopon Spoken Language Translation, pp.
1?12, Kyoto,Japan.S.
Bangalore, G. Bordel, G. Riccardi.
2001.
Comput-ing Consensus Translation from Multiple MachineTranslation Systems.
IEEE Workshop on AutomaticSpeech Recognition and Understanding, Madonnadi Campiglio, Italy.P.
Brown, S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The Mathematics of Statisti-cal Machine Translation.
Computational Linguis-tics, vol.
19(2):263?311.J.
G. Fiscus.
1997.
A Post-Processing System to YieldReduced Word Error Rates: Recognizer Output Vot-ing Error Reduction (ROVER).
IEEE Workshop onAutomatic Speech Recognition and Understanding.S.
Jayaraman and A. Lavie.
2005.
Multi-Engline Ma-chine Translation Guided by Explicit Word Match-ing.
10th Conference of the European Associationfor Machine Translation, pp.
143-152, Budapest,Hungary.M.
Federico 2003.
Evaluation Frameworks for SpeechTranslation Technologies.
Proc.
of Eurospeech,pp.
377-380, Geneva, Switzerland.R.
Frederking and S. Nirenburg.
1994.
Three Headsare Better Than One.
Fourth Conference on AppliedNatural Language Processing, Stuttgart, Germany.E.
Matusov, R. Zens, and H. Ney.
2004.
SymmetricWord Alignments for Statistical Machine Transla-tion.
20th Int.
Conf.
on Computational Linguistics,pp.
219?225, Geneva, Switzerland.E.
Matusov and H. Ney.
2005.
Phrase-based Trans-lation of Speech Recognizer Word Lattices UsingLoglinear Model Combination.
IEEE Workshop onAutomatic Speech Recognition and Understanding,pp.
110-115, San Juan, Puerto-Rico.T.
Nomoto.
2004.
Multi-Engine Machine Transla-tion with Voted Language Model.
42nd Confer-ence of the Association for Computational Linguis-tics (ACL), pp.
494-501, Barcelona, Spain.39F.
J. Och and H. Ney.
2001.
Statistical Multi-SourceTranslation.
MT Summit VIII, pp.
253-258, Santi-ago de Compostela, Spain.F.
J. Och and H. Ney.
2003.
A Systematic Comparisonof Various Statistical Alignment Models.
Computa-tional Linguistics, 29(1):19?51.K.
Papineni, S. Roukos, T. Ward, and W.-J.
Zhu.
2002.BLEU: a Method for Automatic Evaluation of Ma-chine Translation.
Annual Meeting of the ACL, pp.311?318, Philadelphia, PA, USA.M.
Paul, T. Doi, Y. Hwang, K. Imamura, H. Okuma,and E. Sumita.
2005.
Nobody is Perfect: ATR?sHybrid Approach to Spoken Language Translation.International Workshop on Spoken Language Trans-lation, pp.
55-62, Pittsburgh, PA, USA.TC-STAR Spoken Language Translation Progress Re-port.
2005. http://www.tc-star.org/documents/deliverable/Deliv D5 Total 21May05.pdfS.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM-basedWord Alignment in Statistical Translation.
16th Int.Conf.
on Computational Linguistics, pp.
836?841,Copenhagen, Denmark.40
