Towards a Dynamic Theory of Belief-Sharing in CooperativeDialoguesHisashi  Komatsu  Nor ih i ro  Ogata  Ak i ra  Ish ikawaThe  To in  Corporat ion  Un ivers i ty  of Tsukuba  Soph ia  Un ivers i ty1 IntroductionIn this paper, we propose a dynamic theory of belief-sharing which dens with certain processes of formingand revising shared beliefs during cooperative dia-logues.Since Clark & MarshNl(1981) the problem of de-termination of the referents of referring expressionshas been discussed in relation to mutual knowl-edge.
In natural language processing, there haw~also been several studies treating this problem ofreferent-determination in terms of mutuN knowledge(Perrault &: Cohen, 1981; Joshi, 1982; Nadathur &Joshi, 1983; Appelt, 1985).
In this paper, we con-ceive referent-determination as a process of belicf-sllaring in dialogues, and propose a formal theoryof dialogue in which referent-determination can becharacterized as part of belief-sharing processes.
Weuse Discourse Representation Theory (DRT) to modelthe characteristics of referents in discourse (Kamp,1981, 1990; Asher, 1993), and propose a model ofdynamic maintenance of the mutual beliefs of tileparticipants in diNogues based on Clause Mainte-nance System (CMS) (Doyle, 1979; Levesquc, 1989;Poole, 1988; Reggia, 1983; de Kleer, 1986; Rciter &de Kleer, 1987).
By this nmdel, we characterize therelationships between a diMogue process and its suc-cessfulness, which is mainly illustrated by examplesof referent-determination but can be applied to anytype of belief-sharing.2 Dynamic MaintenanceShared Beliefsof2.1 DRSHowever cooperative, real-world ialogues are fraughtwith hedges, understatements, or even white lies,which would necessitate introducing a distinction be-tween what is literally conveyed by an utterance, andits real intent on the part of both speaker and hearer.In this study, however, we restrict ourselves to thosecases without such complications, and assume thatan utterance reflects the speaker's intent in a straightmanner, and is taken as such by the hearer.
The con-tent of an utterance is represented in tile followingstyle:(1) K: a ,b ,x ,y ,z  ....Bel(a, K)~cl( b, IO.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.A(~:), B(v),  C(~), ...We call K discourse representation structure(DRS),  {a, b, x ,y , z  .... } K's domain (UK), the el-ements of UI< discourse referents, tile boxed areabelow tile unbroken line K's condition part (CA-),and CK's elements conditions.
K is represented as(UK,CK}.
The broken line divides CK into theself-referentiN part SRP  (above the line), and thedialogue database DB(K)  (below the line).
A con-dillon is the result of an n(_> 0) times applicationof Bel(ct,.)
to a first-order formula p.
Bel(c~,.)
iscalled a belief operator, where c~ designates the ut-terer.
Given ?
as a condition, Bel(ce, ?)
reads "thepartMpant a believes ?."
n is called the rank of?
with regard to its embedding within belief opera-tors.
Conditions of rank O are called bare formulas,while those with a rank greater than 0 belief formu-las.
K represents the shared beliefs formed througha dialogue between the two participants a and b. Theconditions in SRP  indicate a recursive mbedding ofself-referentiN belief sturueture with regard to eo,n-mon knowledge, and are assumed throughout the dia-logue.
By contrast, DB(K)  is empty when a dialoguestarts off.
Thus, at the outset of a dialogue, the DRSKo = ({a, b}, {Bel(a, Ko), Bel(b, K0)}).
As an utter-ante is made, new discourse entities may be intro-duced, making it necessary to add new conditions toDB(K)  and sometimes to retract or negate part ofthe conditions in DB(K) .
With the progress of thedialogue, the DRS changes front K0 ~ K1 ~ ... =~Kn =:~ ...Since only cooperative dialogues are considered,the goal is to arrive at a DRS in which no contra-dictory beliefs arc held by the participants.
But thisgoN is not Mways achieved.
We Nso assume that atcertain points of a dialogue, the participants can holdcontradictory beliefs, and that tile same pariticipant1164Call hold contradictory beliefs at dill?rent points of adialogue, whereas the s;Hne particip~mt cannot holdcontradictory beliefs ?tt any partic:ular point.In what follows, we just indicate DB(K)  unlessotherwise noted.2.2 How shared  be l ie ig  a re  reg is te redAn utterance made by ~ 1)~rticipmlt in a. diMogueis transformed into a condition(s) and registered inDB(K) ,  folh)wing the constrMnts tetted beh)w.First, discourse referents m'e taken to be epistemo-logical entities without counterparts in snrfacc sen-ten('es, but introduced into the DRS by the partic-ipants of ~ diMogue, and of which prot)erties corre-sponding to surface linguistic expressions are l)redi-cared.
Thus, an utterance(2) a: Sato is a studentis not anMyzed ~s(3) student(Snto)but as(4) Sato(x), student(x)with the discourse referent a" introdu(:ed into U~?
1)ya, and the predicates corresponding to expressions inthe utterauce.Second, an utterance is registered not in the formof a bare formula., but in the fl)rm of a 1)elief orlnulaindicating the t)elief agent.
(4), tbr example, is regis-tered as(5) .Bcl(a, Sato(x) , Bel(a, student(x))because at (2), b has not agreed with or opl)osed a'sutterance.
Note theft (5) is nevertheless ;t shared be-lief t~t this point.
Suppose (6) is uttered folh)wingupon (2):(6) b: Yes, he is.This utterance is interpreted as(7) Bet(b, Sato(x)), BelCh, stu.dent(x))and so registered in DB(K) .
At this t,oint, both (5)and (7) are shared beliefs, which me,ms (4) is a beliefshared by a and b.
This transition is tbrumlated asthe axiom of shared belief:(8) The axiom of shared beliefWhet, DUCK) cont~ns P,q(,*,v), ,~nd 13~l(b, v),DB(K ' )  obtained from DB(K)  1)y the substitu-tion of p for them is equivahmt to DB(K) .DB(K)  can bc derived fl'om DB(K ' )  without usingthis axiom, since K tt~us the self-referential part SRP.But the converse does not hold.
The ttxiom of sharedbelief Mlows the rank of shared beliefs to be zero,while the conditions in general are initially registeredwith a rtmk higher than zero.Third, there is involved a step of identification inthe transition front b's utterance of (6) to the condi-tion (7).
Just as the discourse referent x was intro-duced by a's utterance of (2), b introduces a (listinctdiscourse referent y, in terms of which(9) BelCh, S.to(y)), Bed(b, student(y))is registered in DB(K) .
We ~uSSulne that a and b~gree to tiu', identity of x and y ~Lt this point.To sum up, in dialogue (2), (6), DB(K)  is com-posed of (5) ahme when (2) is uttered, hut is extendedby the utterance of (6) as follows:0()) wt(,,,:,: = y),B,~t(~,.~ = v),Bed(a, Sato( x ) ), Bel( a, Sato(y) ,~l(b,  s,,to(,) ), ~l (b ,  S~to(v) ,Bel(a, student(:r) ), Bet(a, student(y)),Bel( b, student(a,)), BelCh, student(y)).By applying the axioin of shared belief, mid x =: y,we obta.in(11) Sat@c), student(x)By contr~st,(12) l.a: Sato isastudent .2.b: No, he is an otfice clerk now.can only h~vc its DB(K)  reduced to(13) Sato(:,:),lJel(a, ,st~dcm.t(x)), Bel(h,oJlice_cle, rk(x)).3 D iachron ic  ana lys i s  o f  d ia -logueIn this section, we consider the changes DRS 's  un-dergo in the course, of ~t dialogue.
In (2), (6) in theprevious section, we saw a case where a DRS withnothing but shm'ed beliefs is successfiflly obtMned inone inning, so to speak, without incurring any con-flict.
We will look at the other three kinds of cases inwhich conflicts are treated in particular ways whichtMlnit of formMization in terms of CMS.3.1 Di rect  so lu t ion  o f  conf l i c t sConsider the following dialogue.
(1.4) 1.
I~: Sato is ~t good guy.2.
b: By no means, he is a liar.3.
a: No kidding.Just after (14.2) is uttered, DB(K)  looks as follows:(1~) w~t(.,:,; : :, j),Vel(b,.
= y),B a(c,, s~,to(.
)), u~t(c~, st, to(v)),Uet(*,, S.to(.~-)), ~et(b, Sato(v )),.~t(,,,,oo(t0,,)),.c~l(t,,/i(,.
(v)).1165The utterance of (14.3) is considered as the conse-quence of an inference such as this:(16) 1. x = y2.
Sato(x)3.
Bet(a, good(x))4.
Bel(b, liar(x))is derived from (15), (16.3-4) do not bring about aninconsistency since they are belief formulas with dif-ferent propositions inside.
But obviously, a has drawnan inconsistency by taking off the belief operators,and carrying out the following inference.
(17) 1. x=y2.
liar(y)3. liar(x) 1, 24.
Vx(l iar(x)-*-,good(x))5.
-good(x) 3, 46. good(x)7.
\[\] 5,6Suppose (14) is continued as follows:(18) a: I meain the Sato in tile linguistics department.b: ()it, I thougtit you were talking about the Satoin the AI department.
The one you mean is in-deed a good guy.
(19) a: He does sometimes.
But you can't dislike him.b: I guess not.In this case, in order to avoid the conflict, one tracesits causes, and retracts the weakest one (16.1) for(18), and (17.4) fro' (19), or replaces it by its negation.As a result, (18), for examle, is associated with(20) Bel(a,-~x = y),B~l(a, Sato(x)),Bel(a, Sato(y)),Bel(b,-,x = y),nd(~,Sato(x)),~el(~,Sato(y)),Bel(a, LiD(x)),  Bel(a, AiD(y)),Bd(a, Vx(li~,'(x) - ,  ~good(x))),Bel(b, LiD(x)) , Bel(b, AiD(y)),Bcl(~, Vx(liar(x) -* ~qood(x))),B~l( ~, good(x)), ~el(~, liar(y)),Bel(b, good(x)), Bcl(b, liar(y)).All Bel's can be taken off in (20), resulting in(21) ~x = y, Sato(x), Sato(y),LiD(x), AiD(y), Vx(liar(x) -* ~good(x) ),9ood(x),liar(y),which is shared by a and b.3.2  Ind i rec t  so lu t ion  o f  conf l i c tsConsider the following dialogue.
(22) 1.a: Today's meeting is held at 203, isn't it?2.b: No, I heard it is at the small conferenceroo ln ,3.b: Who toht you that'?4.a: Sat() told me yesterday.5.b: That's strange.
I'll call the office.6.b: They say it was changed fl'om 203 to thesmall coifference room today.7.a: I see.The inference of (22) is formalized as follows:(23) 1.
Sato2.
Sato ~ 2033.
2034. office5.
office-* s.e.r6.
s.c.r 4, 57. s.c.r -* -~2038.
-1203 6, 79.
\[\] 3~8In this case, the conflict between (22.1) and (22.2)1, 2cannot be solved between themselves.
(22.3) to (22.6)reflects the process of deciding which is to be pre-ferred by tracing the source of each condition.
Thatis~ when one cannot choose between two conflictingconditions Pl and p2 on their own account, one re-places Pl and p2 by ql, ql --* Pl and q2, q~ '~ P2~respectively, and decide which of ql, q2 is to be pre-ferred so that one can avoid the conflict by retractingthe weaker condition in favor of the stronger.3 .3  Conf l i c ts  end ing  in  a d rawConsider the following case.
(24) 1.a: That's Muranishi over there.2.b: No, it's Hokuto.3.a: Really?This case is formalized ~s follows:(25) 1. x = y2.
Hokuto(y)3.
Hokuto(x) 1, 24.
Muranishi(x)5.
Vx(Muranish.
i (x)-*- ,Hokuto(x))6.
-~Hokuto(x) 4, 57.
\[\] 3,6As (24.3) indicates, there is no retractable belief inDB(K) ,  which caused the diMog to end in a break-down.3 .4  Formal i za t ion  o f  d iachron ic  ana ly -s isThe processes of belief revision illustrated in 3.1through 3.3 can be h)rmalized as in (27).
First, wedefine some terms:7166(26) i) I,et c~ be one of the partieilmnts a and b in adialogue, and/3 the other.ii) Given p in DB(K) ,  substitute Bel((e,p) andBel(fl,p) for it.
When Bel((e,p) is replaced byBel((e, "~p), it is called p's self-denial by (r. WhenBel(c~,p) is simply retracted, it is called p's self-withdraw,'d by (e.iii) When Bel((~,p), Bel(/J,p), and p are sub-stituted for by ~p, it is called p's strong-denial.When they are simply retracted, it is (:ailed p'sstrong-withdrawM.iv) Let E be a set of Horn-clauses, PI(E)the set of its prime implieants.
When ~p{-~p~, ..., ~p,,} for any qV-~p~ V...V~p,~ e P I (E) ,q is subordinate, ~o p.(27) Whenever a new condition is added to DB(K)in response to a dialogue ntove, the participant(e starts her CMS, calculates a way of resolvingany contlict, and revises DB(K)  dymunically:1) a) When a condition is explicitly registered inDB(K) ,  strip off its belief operator (if any), addit to CMS as an atomic formula.b) Add implicitly assumed conditionals uch asVx(Muranishi(x) --~ ~Hokuto(x)) to CMS asan atomic formula.c) Add the implicit inference ruh!s in the (lial()gueto CMS ~s a conditional formula.
(E.g., the in-ference rule a, b/c eorresl)onds to the conditionalformula c ~- a, b.
)2) Let E be tit(!
set of CMS-cbmses obtained in1).
Change E into P I (E )  (the set of its primeimI)licants).a) If P I (E)  V El, then the dialogue suc(:eeds.
Ei-ther terminate it, or go on to another.h) If P I (E )  F D, mdess there is a retractabh~ ordeniable assumption 1> in E, go to c).
If dmreis, try to make either p's strong-denial or strong-withdrawal.
If it fails, go to c).
If successful, forall q such that q is subordinate to p, m~d(e q'sself-withdrawal, and call the result E ~.A) If P I (E ' )  V D, then the dialogue suceeds.
Ei-ther terminate it, or go on to another.B)If PI(E') ~- ~, then S := E' all(L gO to b).e) If every assulnption p in E is well justi-fied, the dialogue fails.
If any p has nego-tiable justifications q,,..., q,, replace p by p ~-ql,...,%;ql,...,qn altd call the result E'.
SetE :-- El, and go to b).4 Synchron ic  ana lys i s  o f  d ia-logueNext, according to Ogata(1993), we consider a clas-sification which characterizes the degree of beliefsharing for the t)articipmtts at a l)articular point ofthe conversation, and the eorre(:tness of the sharedbeliefs.
(28) 1) The beliei~ are all shared by the participants:see (2), (~) above.
DB(K) ,:o,,tai,s ~o eo,di-lions l)re, tixed with Bcl.
Since the set of belie, fsof either partMpant is .considered to be consis-tent, I'I(E) V \[\] fi)r tile CMS corresponding tothe DRS.2) There remain some conditions prefixed withBe.l in DB(K) ,  but PI(E) y \[\] for the CMS cor-resl)on(ling to the DRS.
A typical c~use, is when/~'s ~ussertions prol)erly inchtde (~'s t)eliefs andabout the rest of ~'s assertions (~ has not beenable to decide in one way or another.3) There remain some (:onditions prefixed withBeI in DB(K) ,  and PI(E) I- E~.
This is a caseof breakdown ,'~s een in (25).We call titese three ('~uses, respectively, 1) obser-w~tionally susscessful, 2) observ~Ltionally consis-tent, and 3) obserw~tionally unsuccessful.Take the ease of (2), (6) again.
Tit(, dMogue was suc-cessfiflly terminated because the Sato a had in mindand the Sato b had in mind were both students.
Butsuppose a's Sato was a student in the linguistics de-1)artm(mt, and b's Sato in the AI department, (.hat is,they were different persons.
Or suppose a and b hadthe same Sato in rain(|, but that he was no longer astudent ;~t the time.
These two eases are obscrwttion-ally suc(:essfifl, hut the partMpants end a 1) with thewrong beliefs.
In order to meet this gat) ~ we introducea standard of correctness that might be eml)odied byGod's viewpoint, the reality, or the conventions ofthe language community to which the 1)articipantsbelong.
We call this standard the facts.
The cate-gories in (28) are further broken down relative to thefacts as in (29):Detine K '  as the result of adding the Nets to timDB(K)  of a DRS K, and extending UI?
accordiugly.Let PI(E I) be the set of prime implicants fi)r the CMScorresponding to DB(K/).
The facts are a set of bareformub~s.
Then (28) is subclassifled as follows:(29) 1) ol)servationally su(:c, essfuia) m(~') V u,b) m(s ' )  ~- u.2) observationally consistenta) m(E ' )  V El,1,) m(s ' )  ~ u.3) obserwttionally unsuccessfulPI(E I) F ~.We cM1 la) strongly successful, 2a) strongly consis-tent, and the rest (the cases where PI(N ~) F n)strongly unsuccessful.
A comparison of (28) and (29)suggests the folh)wing implications whose conversesdo not hold:(3(I) a) strongly successfltl ~ observationally success-tiff1)) obserwt.tionally m~suc('.essful -~ strongly un-su(:cessfulc) strongly consistent -~ observationally consis-tent11674.1 Character i za t ion  of  express ionsreferring to individualsWe consider the problem of how the concepts of suc-cess introduced in the previous ection might be ap-plied to the dialogues identifying the denotation ofindividual terms, especially proper nouns.
(31) a: That's Sato over there.b: Yes, it is.DB(K)  for (31) is(32) a) x = y,b) Sato(x), Sato(y).If a and b believe there is only one Sato in this situ-ation, (32b) becomes(33) Bel(a, tx.Bel(a, Sato(x)) = x),~el(b,,x.Bcl(~, Sato( x ) ) = ~ ),Bel(a, tx.Bcl(b, Sato(x)) = y),~el(b, ,~.Bel(b, Sato(x) ) = y),which gives rise to(34) tx.Bel(a, Sato(x)) = x,,x.Bel(b, Sato(x)) = y.From this, we obtain by (32a)(35) ,x.Bel(a, Sato(x) )  = ,x.~el(~, Sato(x)) .If (31) is a case of strong success in which "Sato"correctly refers to the unique Sato, DB(K  t) contains(36) x = z, tx.Sato(x) = z.From (323), (34), and (36), we ca,, derive(37) tx.Sato(x)=tx.Bel(a, Sato(x)) = ,x.Bel(b, Sato(x)).In general, of an atomic formula T(x), we calltx.Bel(a, T(x)) a's intended referent, tx.Bel(b,T(x))b's intended referent, and tx.T(x) the semanite refer-ent.
Thus, a strongly successful dialogue with regardto an identification of an individual referent is a casewhere a's intended referent, b's intended referent, andthe semantic referent all coincide.However, if in (31) the individual referred to is Ki-noshita rather than Sato, DB(K  t) will contain(38) ~(z = x),,x.Sato(x) = z.If a and b have different Sato's in mind, DB(K  ~) willcontain(39) tx.Sato(x) = t, ~(~ = x).In either case, the result is strongly unsuccessflfl:(40) -~(tx.Sato(x) = tx.BeI(a, Sato(x) ),-~(tx.Sato(x) = tx.BeI(b, Sato(x))).A case of being observationally unsuccessful such as(24) will be(41) -~(tx.Bel(a, Sato(x)) = tx.Bel(b, Sato(x))).By indicating a's intended referent, b's intended refer-ent, and the semantic referent by Ta, Tb, and Tcom,respectively, we can summarize what has been dis-cussed above as follows:(42) strongly successful: Tcom = Ta = Tb,observationally successful: Ta = Tb,strongly unsuccessfld: Tcom ?
Ta,Tcom ~ Tb,observationally unsuccessful: Ta ~ Tb.5 Conc lus ionIn this paper, we proposed a system which combinesDRS with CMS, and an Mgorithm for the dynamic re-vision of shared beliefs in cooperative dialogues.
Fur-ther, the degree of success in dialogues was formal-ized.Still, the following problems remain to be solved:1) The treatment of background knowledge must bemade precise.
E.g., 'Sato ~ 203' in (23), or'Vx(Muranishi(x) -~ "~Hokuto(x))' in (25) is im-plicitely introduced into the inference without ex-planation of its origin.2) The translation procedure of an utterance into thecondition of DRS must be formalized.3) It's necessary to give a semantic foundation to oursystenl.4) hnplelnentation f a system which simulates ourdialogue mechanism.References\[1\] Appelt, D. (1985).
"Planning English referringexpressions".
Artificial Intelligence, 26, 1-33.\[2\] AsheL N. (1993).
Reference to Abstract Objectsin Discourse, Dordrecht: Kluwcr.\[3\] Clark, H. & Marshall, C. R. (1981).
"Definitereference and mutual knowledge".
In Joshi etal.
Ed., Elements of Discourse Understanding,Cambridge University Press.\[4\] Kleer, J. de (1986).
"An assumption-basedTMS'.
Artificial Intelligence, 28, 127-162.\[5\] Doyle, J.
(1979).
"A truth mMntenanee system".Artificial Intelligence, 1.2, 231-272.\[6\] G?rdenfors, P. (1988).
Knowledge influx: model-ing the dynamics of epistemie states, Cambridge:The MIT Press.\[7\] Joshi, Aravind K. (1982), " MutuaJ Beliefs inQuestion-Answer Systems".
In Smith, N. V. Ed.,Mutual Knowledge, pp.
181-197, London: Aca-demic Press.1168\[8\] Kamp, H. (:\[981).
"h Theory of truih and semzm-tic representation".
In Groenendijk et al Ed.,t;'ormal Methods in the Study of Langua.gc., pp.277-322, Amster&ml: Mathemal;isch CentrumTracts.\[9\] Kaml), H. (1990).
"Prolegon~ena to st StructuralAe(:ount of Belief and Other Attitudes".
In An-derson, C. A.
& ()wens, J.
l','d., Propositional At-titudes: The Role of Content in Logic , Language,and Mind, pp.
27-9(), Stanford: CSLI.\[10\] I,evesque, II.
J.
(1989).
"A k,mwiedgeqevel ac-count of abduction".
1.1CA1-89, 1061-1068.\[11\] Nadathur & aoshi (1983).
"MutuM belief in con-versational systems: their role in referring ex-pressions".
IJCAI-83, 603-6o5, Karlsruhe.\[12\] Ogata, N. (1993).
"Koymnei, Shiji, .lohe) Kyoyii"("Proper Names, Reference, and inform~tion-Sharing").
S@tto-uea Bunsho no tameno Ni-hongo Shori no Kenkyii (Study of Japanesel'.r'ocessing for Software Documents), 12, 257-310, Tokyo: hfformation-Technology PromotionAgency (IPA).\[13\] Perrault, C. 1/,.
& Cohen, P. 1{.
(1981).
"It's foryour own good: a note on illtLCellrsLte reference".In aoshi et al Ed., \],lie.merits of Discourse Un-derstanding, Cainbridge University Press.\[14\] Poole, D. (1988).
"A methodology for using adefault ai,d abdu(:tive reasoning system."
Tech-nical report.
Dept.
of Computer Science.
Univ.of Waterloo, W;Lterloo.\[15\] Reggbt, 3.
(198a).
"Diagnostic expert systemsln~sed on a set-covering model".
InternationalJournal of Man Machi'ne 3tudies, 19(5), 437-460.\[16\] Reiter, R. & Kh, er, J. de (1987).
"FomMationsof s~sSUml)tiolM)ased truth tlls'dnteltan(:e systenls:preliminary report", ddAg87, 18a-188, Seattle,WA.1169
