Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 351?355,Dublin, Ireland, August 23-24, 2014.iTac: Aspect Based Sentiment Analysis usingSentiment Trees and DictionariesFritjof Bornebusch1, Glaucia Cancino1, Melanie Diepenbeck1, Rolf Drechsler1,2,Smith Djomkam1, Alvine Nzeungang Fanseu1, Maryam Jalali1, Marc Michael1, Jamal Mohsen1,Max Nitze1, Christina Plump1, Mathias Soeken1,2, Fred Tchambo1, Toni1, Henning Ziegler11Faculty of Mathematics and Computer Science, University of Bremen, Germany2Cyber-Physical Systems, DFKI GmbH, Bremen, Germanyitac@cs.uni-bremen.deAbstractThis paper describes our approach for thefourth task of the SemEval 2014 challenge:Aspect Based Sentiment Analysis.
Our sys-tem is designed to solve all four subtasks:(i) identifying aspect terms, (ii) determin-ing the polarity of an aspect term, (iii) de-tecting aspect categories, and (iv) determin-ing the polarity of a predefined aspect cate-gory.
Our system is based on the Stanfordsentiment tree.1 IntroductionOnline reviewing, rating, and recommendationhave become quite popular nowadays.
Basedon online reviews and rating, people may decidewhether to buy a certain product or visit a certainplace (restaurant, shop, etc.).
Due to the increasingnumber of reviews, an automatic system is neededthat can evaluate these reviews as positive, negative,or neutral.In this paper, we propose a system for the fourthtask of the SemEval 2014 challenge (Aspect BasedSentiment Analysis).
The target is to identify as-pects of given target entities and to determine thesentiment that is expressed towards each aspect interms of a polarity.
The problem has been dividedinto four different subtasks: (i) extracting aspectsfrom a given sentence, (ii) determining the polarityof each aspect, (iii) matching suitable aspect cat-egories and (iv) identifying the polarity of thesecategories.2 Related WorkThere are several different approaches to performsentiment analysis on a given sentence.
Refer-ences Turney (2002) and Pang et al.
(2002) startedThis work is licenced under a Creative Commons Attribu-tion 4.0 International License.
Page numbers and proceed-ings footer are added by the organizers.
License details:http://creativecommons.org/licenses/by/4.0/to classify a given sentence to be either positive ornegative.
Dave et al.
(2003) continued to includethe neutral semantic orientation to his work.
Theseapproaches perform sentiment analysis on a wholesentence and use phrases such as adjectives andadverbs to get a polarity.
They collect all thesephrases and determine their polarity (e.g.
positive,neutral, or negative).
Hence, it differs from ourwork that performs sentiment analysis based oneach aspect term.Another approach by Snyder and Barzilay (2007)tries to perform aspect based sentiment analysis,which performs sentiment analysis for various as-pects for a given restaurant.
Our work differs fromtheir approach and is more closely related to Huand Liu (2004).
Individual parts of the sentenceare classified separately since different parts canexpress different polarities.
But the authors onlyconsider product features instead of aspect terms.Aspect terms can be product features but they canalso include conditions such as ambience that in-fluences an opinion which have not been addressedin Hu and Liu (2004).3 PreliminariesOur system is based on Natural Language Process-ing (NLP) libraries such as the Stanford CoreNLP.1The system is heavily based on the Stanford senti-ment tree.3.1 Stanford sentiment treeThe sentiment treebank introduced by Socher et al.
(2013) was developed at the University of Stanfordto predict the sentiment of movie reviews.
It con-tains approximately 12,000 sentiment annotatedparse trees of movie reviews.
The sentiment pre-diction can determine five sentiment classes (verynegative, negative, neutral, positive, very positive)using a recursive neural tensor network trained on1http://nlp.stanford.edu/software/corenlp.shtml351Table 1: Removed word categories with examples.Category Exampleperson husband, wife, mother, boyfriendtime date, year, month, Monday-Sundaylocation NYC, Manhattan, street, Avenuemisstagged everything, something, none, some, anythe sentiment treebank.
We aggregate the senti-ment classes into three classes (negative, neutral,positive).4 ImplementationOur system is divided into four subsystems that aredescribed separately in the following section.
Al-though described separately, some subtasks dependon each other (e.g.
Aspect Category Extraction andAspect Category Polarity).4.1 Aspect term extractionThe aim of this subtask is to find aspect terms thatare discussed in a given sentence.
Our approachfollows an idea presented by Hu and Liu (2004).A word in a given sentence is considered to bean aspect term if it satisfies the following threeconditions.C1.1 It is tagged as a noun (tagged with NN, NNS,NNP, or NNPS).C1.2 It is one of the 20% most common nouns ofall given sentences.C1.3 It does not belong to a forbidden word cate-gory (listed in Table 1).Following this extraction, adjacent aspect terms arecombined to multi-word aspect terms.Example 1 ?My wife bought it and was veryhappy, especially with the hard drives and batterylife.?
The result of the rule application is shown inTable 2.
When multi-word aspect terms are consid-ered, battery and life are combined to a single term.The row indicated by terms shows the extractedaspect terms of the sentence.
In the last row goldterms are compared to actual aspect terms givenby the training data.The results of our system are shown in Table 3.These results could be improved by using typeddependencies.
The use of the adjectival modi-fier (amod) and the noun compound modifier (nn)relations can help to improve finding multi-wordaspect terms.Table 2: Rule-satisfication for example.Rule Resultfound nouns wife drives battery lifefrequent noun?
X X X Xnon-forbidden?
x X X Xterms drives battery lifegold terms hard drives battery lifeTable 3: Results for term extraction.Domain Precision Recall F-measureLaptop 0.23 0.25 0.24Restaurant 0.37 0.40 0.384.2 Aspect term polarityAfter extracting the aspect term from the sentencethe next task is to predict its polarity.
For this taskwe are using the Stanford sentiment tree.The sentiment tree is designed to predict the sen-timent of a whole sentence.
Because the sentimenttree contains polarities for every node of the parsetree it is reasonable to use it for aspect sentimentprediction.Our algorithm examines the sentiment tree nodesto predict the polarity of an aspect.
The followingoutlines the basic steps for aspect sentiment predic-tion.
?00 0?0?0 00Thekeyboard (1)istooslik.
?neutral (2)neutral (3)negative (4)Figure 1: Example of the sentiment tree algorithmfor the sentence ?The keyboard is too slik.?.1.
Create the sentiment tree for the sentence andfetch the node of the aspect term stem.2.
Traverse the tree from that node up to the root.The first non-neutral polarity on the path fromthe node to the root node is chosen.3.
If the algorithm reaches the root node withoutfinding a non-neutral polarity, the aspect termis predicted as neutral.352Table 4: Results for term polarity.Domain Prec.
Rec.
F-measure AccuracyLaptop 0.52- negative 0.31 0.79 0.45- neutral 0.33 0.09 0.15- positive 0.79 0.65 0.72Restaurant 0.62- negative 0.35 0.78 0.48- neutral 0.25 0.05 0.08- positive 0.83 0.75 0.79Example 2 Figure 1 illustrates the algorithm forthe sentence ?The keyboard is too slik.?.
The aspectterm keyboard is underlined.
The algorithm startsat the keyboard node (denoted with 1) and examinesthe parent node (2).
Since the parent node has aneutral polarity, the root node needs to be examined(3).
Due to the negative polarity of the root node,the aspect term keyboard is negative (4).The results of the algorithm with the test dataset are shown in Table 4.
We got quite good resultsfor negative and positive aspect terms.
But thereare problems to predict neutral aspect terms, dueto the fact that the sentiment tree rarely predictsneutral polarities.
Overall our accuracy is nearly10 percent points above the ABSA baselines.4.3 Aspect category detectionThis section describes the approach for the thirdsubtask that identifies aspect categories discussedin a given sentence, using a predefined set of aspectcategories, such as food, service, ambience, price,and anecdotes/miscellaneous as a neutral category.Our approach is twofold, depending on whether thesentence contains aspect terms or not.Sentences with aspect terms.
We illustrate ourapproach with the following example sentence.Example 3 Consider the sentence ?Even thoughit is good seafood, the prices are too high.?
withthe predefined aspects terms seafood and price.1.
If the aspect term is a category, it can be di-rectly assigned as a category.
In this examplethe category price is present and will be as-signed.2.
Dishes are very challenging to detect as anaspect term.
For that problem we added a listof dishes scraped from Wikipedia to detectthem.
If a noun is not part of the list we searchDuckDuckGo2for the description of that noun2https://duckduckgo.comTable 5: Result for category extraction.Domain Precision Recall F-measureRestaurant 0.63 0.52 0.59and check whether it is a dish.
If it is a dish,then the category food is assigned.3.
For unassigned aspect terms, the similaritybetween aspect terms and all categories willbe calculated.
For this purpose, RiTa.WordNetsimilarity has been used.
If the path length issmaller than 0.4 (with the help of the trainingdata we experimentally determined the bestcomparison value) the aspect term is assignedto the category.
In our example seafood issimilar to food and therefore the category isfood.4.
If no aspect category could be found, the cate-gory is anecdotes/miscellaneous.Sentences without aspect term.
The third stepfrom the previous approach is executed for allnouns in the sentence.
But the threshold is de-creased to 0.19 to reduce the number of recognizedcategories.
If no similarity falls below the thresh-old, the category is anecdotes/miscellaneous.The results of the third subtask are presented inTable 5.
Although the presented results are mod-erately good, there exist some issues worth to beconsidered here: Using WordNet (Miller, 1995), itis only possible to find the similarity between twoconcepts and not a group of concepts.
For exampleJapanese Tapas with food would not work.
Fur-thermore, WordNet only recognizes the similaritybetween words of the same part of speech, it meansmany possible relations between verbs and nouns,and also adjectives and nouns are missing.
Also,we were not able to calculate the similarity betweena term and the default category.4.4 Category polarityThis section describes the last subtask which aimsto find the polarity of an aspect category for a givensentence.
For the given aspect category whichcan be food, service, ambience, price, or anec-dotes/miscellaneous, the task is to find its polarity.This subtask is applied only for the topic restau-rant.
The second and third subtask must have beensolved since their evaluations are required to clas-sify which aspect term belongs to which aspectcategory.
In the third subtask all aspect terms are353grouped in categories and in the second one theaspect terms are set with their polarities, which weuse to calculate how many times a specific polarityis chosen under the same aspect category.
Then wecan assign a polarity to a specific aspect category.In order to find the polarities of an aspect categorywe carefully analyzed the training data and defineda set of rules to find all possible cases.
We willdiscuss these rules in the following.R4.1 If the aspect term polarities of the samecategory are equal, then their polarity is tagged asthe category polarity.Example 4 ?Prices are higher to dine in and theirchicken tikka marsala is quite good.?
The found as-pect terms in this sentence are Prices which is neg-ative and chicken tikka marsala which is positive.Both aspect terms belong to different categories.The category food (chicken tikka marsala) is posi-tive and the category price (Prices) is negative.R4.2 If one of the aspects of a specified categoryis neutral, it has no influence on the polarity ofa category, as long as at least one other polarityexists.
The polarities of all other aspect terms willdetermine the polarity of a specific category.Example 5 ?Our server checked on us maybetwice during the entire meal.?
In this sentencethe following aspect terms are found: server asnegative and meal as neutral.
Both aspect terms be-long to the same category service, so the categoryservice has the value negative.R4.3 If the aspect term polarities under a samecategory are both positive and negative, then thecategory polarity is tagged as conflict.Example 6 As an example consider the sentence:?The sweet lassi was excellent as was the lamb chet-tinad and the garlic naan but the rasamalai wasforgettable.?
Here four aspect terms were found:sweet lassi, lamb chettinad, and garlic naan withpositive polarities but rasamalai has a negative po-larity.
This results in a conflict polarity for thecategory food.R4.4 If the found category was annotated as anec-dotes/miscellaneous but no aspect term was foundin the second subtask, then we use the sentimenttree.
It generates a specific polarity for the entiresentence which we define as the category?s polarity.Example 7 The sentence: ?A guaranteed delight!
?has no aspect term.
Using the sentiment tree theTable 6: Results for category polarity.Domain Prec.
Rec.
F-measure AccuracyRestaurant 0.63- conflict 0.08 0.10 0.09- negative 0.45 0.73 0.56- neutral 0.24 0.17 0.20- positive 0.86 0.70 0.77polarity for the category anecdotes/miscellaneousis positive.We applied our approach on the training data.The results are shown in Table 6.
We achieved anF-measure of 0.85 for the positive polarity.
Ouraccuracy is 0.56 which is not a good achievementin comparison to other submissions in this subtask.The possible reason for this result could be thatthe first subtask also did not reach good accuracymeasures.5 Conclusion & future worksThis paper describes our system to solve the indi-vidual subtasks by using the Stanford CoreNLP,RiTa.WordNet (Guerini et al., 2013) and a fooddatabase developed by ourselves.
These librariesoffer methods to classify sentences and determinethe polarities.Through the usage of the library based methods,it is not possible to take effect to the result.
Atthis point other libraries such as NLTK3could helpto increase it.
They offer the possibility to trainseveral classifiers with own data.
But the classifierare not domain independent, because they need tobe trained with sentences that belong to a specificdomain, e.g.
laptop or restaurant, in order to getthe right polarity.Our approach is more domain independent, be-cause we do not need any domain to calculate theright polarities.
That?s why we can use our tool toprocess sentences of any domain, without furtherchanging the algorithms.In the future, we expect progress towards thefollowing directions.
First, we want to improve theidentification of aspect terms which consist of morethan two consecutive nouns.
Second, we want toidentify aspect terms which are not available as apart of the sentence.
Finally, improvements to de-termine polarity of sentences with unclear context(i.e.
the absence of adjectives).3http://www.nltk.org/354ReferencesKushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: Opinion extractionand semantic classification of product reviews.
InWWW, pages 519?528.Marco Guerini, Lorenzo Gatti, and Marco Turchi.2013.
Sentiment analysis: How to derive prior polar-ities from SentiWordNet.
In EMNLP, pages 1259?1269.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In KDD, pages 168?177.George A. Miller.
1995.
WordNet: A lexical databasefor english.
Commun.
ACM, 38(11):39?41.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
sentiment classification usingmachine learning techniques.
In EMNLP, pages 79?86.Benjamin Snyder and Regina Barzilay.
2007.
Multipleaspect ranking using the Good Grief algorithm.
InHLT-NAACL, pages 300?307.Richard Socher, Alex Perelygin, Jean Y. Wu, JasonChuang, Christopher D. Manning, Andrew Y. Ng,and Christopher Potts.
2013.
Recursive deep mod-els for semantic compositionality over a SentimentTreebank.
In EMNLP, pages 1631?1642.Peter D. Turney.
2002.
Thumbs up or thumbs down?
:Semantic orientation applied to unsupervised classi-fication of reviews.
In ACL, pages 417?424.355
