A Comparative Study for Query Translation usingLinear Combination and Confidence MeasureYoussef KadriLaboratoire RALI, DIROUniversit?
de Montr?alCP 6128, Montr?al, Canada, H3C3J7kadriyou@iro.umontreal.caJian-Yun NieLaboratoire RALI, DIROUniversit?
de Montr?alCP 6128, Montr?al, Canada, H3C3J7nie@iro.umontreal.caAbstractIn Cross Language Information Retrieval(CLIR), query terms can be translated tothe document language using BilingualDictionaries (BDs) or Statistical Transla-tion Models (STMs).
Combining differenttranslation resources can also be used toimprove the performance.
Unfortunately,the most studies on combining multiple re-sources use simple methods such as linearcombination.
In this paper, we drew up acomparative study between linear combina-tion and confidence measures to combinemultiple translation resources for the pur-pose of CLIR.
We show that the linearcombination method is unable to combinecorrectly different types of resources suchas BDs and STMs.
While the confidencemeasure method is able to re-weight thetranslation candidate more radically than inlinear combination.
It reconsiders eachtranslation candidate proposed by differentresources with respect to additional fea-tures.
We tested the two methods on differ-ent test CLIR collections and the resultsshow that the confidence measure outper-forms the linear combination method.1 IntroductionCross Language Information Retrieval (CLIR) triesto determine documents written in a language froma query written in another language.
Query transla-tion is widely considered as the key problem in thistask (Oard, 1998).
In previous researches, variousapproaches have been proposed for query transla-tion: using a bilingual dictionary, using an off-the-shelf machine translation system or using a parallelcorpus.
It is also found that when multiple transla-tion resources are used, the translation quality canbe improved, comparing to using only one transla-tion resource (Xu, 2005).
Indeed, every translationtool or resource has its own limitations.
For exam-ple, a bilingual dictionary can suggest commontranslations, but they remain ambiguous ?
transla-tions for different senses of the source word aremixed up.
Machine translation systems usuallyemploy sophisticated methods to determine thebest translation sentence, for example, syntacticanalysis and some semantic analysis.
However, itusually output only one translation for a sourceword, while it is usually preferred that a sourcequery word be translated by multiple words in or-der to produce a desired query expansion effect.
Inaddition, the only word choice made by a machinetranslation system can be wrong.
Finally, parallelcorpora contain useful information about wordtranslation in particular areas.
One can use such acorpus to train a statistical translation model,which can then be used to translate a query.
Thisapproach has the advantage that few manual inter-ventions are required to produce the statisticaltranslation model.
In addition, each source wordcan be translated by several related target wordsand the latter being weighted.
However, among theproposed translation words, there may be irrelevantones.Therefore, one can take advantage of severaltranslation resources and tools in order to producebetter query translations.
The key problem is theway to combine the resources.A common method used in previous studies is toassign a weight to each resource.
Then all thetranslation candidates are weighted and then com-bined linearly (Nie, 2000).
However, this kind ofcombination assigns a single confidence score to181all the translations from the same translation re-source.
In reality, a translation resource does notcover all the words with equal confidence.
Forsome words, its translations can be accurate, whilefor some others, they are inappropriate.
By using alinear combination, the relative order among thetranslation candidates is not changed.
In practice, atranslation with a low score can turn out to be abetter translation when other information becomesavailable.For example, the English word ?nutritional?
istranslated into French by a statistical translationmodel trained on a set of parallel texts as follows:{nutritive 0.32 (nutritious), alimentaire 0.21 (food)}.We observe that the most common translationword ?alimentaire?
only takes the second placewith lower probability than ?nutritive?.
If thesetranslations are combined linearly with anotherresource (say a BD), it is unlikely that the correcttranslation word ?alimentaire?
gain larger weightthan ?nutritive?.This example shows that we have to reconsiderthe relative weights of the translation candidateswhen another translation resource is available.
Thepurpose of this reconsideration is to determine howreasonable a translation candidate is given all theinformation now available.
In so doing, the initialranking of translation candidates can be changed.As a matter of fact using the method of confidencemeasures that we propose in this paper, we are ableto reorder the translation candidates as follows:{alimentaire 0.38, nutritive 0.23, valeur 0.11 (value)}.The weight of the correct translation ?alimen-taire?
is considerably increased.In this paper, we will propose to use a newmethod based on confidence measure to re-weightthe translation candidates.
In the re-weighting, theoriginal weight according to each translation re-source is only considered as one factor.
The finalweight is determined by combining all the avail-able factors.
In our implementation, the factors arecombined in neural networks, which produce a fi-nal confidence measure for each of the translationcandidates.
This final weight is not a simple linearcombination of the original weights, but a re-calculation according to all the information avail-able, which is not when each translation resource isestimated separately.The advantages of this approach are twofold.
Onone hand, the confidence measure allows us to ad-just the original weights of the translations and toselect the best translation terms according to all theinformation.
On the other hand, the confidencemeasures also provide us with a new weighting forthe translation candidates that are comparableacross different translation resources.
Indeed, whenwe try to combine a statistical translation modelwith a bilingual dictionary, we had to assign aweight to a candidate from the bilingual dictionary.This weight is not directly compatible with theprobability assigned in the former.In the remaining sections of this paper, we willfirst describe the principle of confidence measurein section 2.
In section 3, we will compare twomethods to combine different translation resources:linear combination and confidence measure.
Sec-tion 4 provides a description on how the parame-ters are tuned.
Section 5 outlines the different stepsfor computing confidence measures.
Finally, wepresent the results of our experiments on both Eng-lish-French and English-Arabic CLIR.
Our ex-periments will show that the method using confi-dence measure significantly outperforms the tradi-tional approach using linear combination.2 Confidence measureConfidence measure is often used to re-rank or re-weight some outputs produced by separate means.For example, in speech recognition and under-standing (Hazen et  al., 2002), one tries to re-rankthe result of speech recognition according to addi-tional information using confidence measure.
Gan-drabur et al (2003) used confidence measures in atranslation prediction task.
The goal is to re-rankthe translation candidates according to additionalinformation.
Confidence measure is defined as theprobability of correctness of a candidate.
In thecase of translation, given a candidate translation tEfor a source word tF, the confidence measure is),,|( FttcorrectP EF , where F is a set of other fea-tures of the translation context (e.g.
the POS-tag ofthe word, the previous translations words, etc.).
Inboth applications, significant gains have been ob-served when using a confidence estimation layerwithin the translation models.The problem of query translation is similar togeneral translation described in (Gandrabur et al2003).
We are presented with several translationresources, each being built separately.
Our goalnow is to use all of them together.
As we discussedearlier, we want to take advantage of the additionalinformation (other translation resources as well as182additional linguistic analysis on the query) in orderto re-weight each of the translation candidates.In previous studies, neural networks have beencommonly used to produce confidence measures.The inputs to the neural networks are translationcandidates from different resources, their originalweights and various other properties of them (e.g.POS-tag, probability in a language model, etc.
).The output of the neural networks is a confidencemeasure assigned to a translation candidate from atranslation resource.
This confidence measure isused to re-rank the whole set of candidates from allthe resources.In this study, we will use the same approach tocombine different translation resources and to pro-duce confidence measures.The neural networks need to be trained on a setof training data.
Such data are available in bothspeech recognition and machine translation.
How-ever, in the case of CLIR, the goal of query transla-tion is not strictly equivalent to machine transla-tion.
Indeed, in query translation, we are not lim-ited to the correct literal translations.
Not literaltranslation words that are strongly related to thequery are also highly useful.
These latter relatedwords can produce a desired query expansion ef-fect in IR.Given this situation, we can no longer use a par-allel corpus as our training data as in the case ofmachine translation.
Modifications are necessary.We will describe the modified way we use to cre-ate the training data in section 4.
The informativefeatures we use will be described n section 5.2.3 General CLIR ProblemAssume a query QE written in a source language Eand a document DF written in a target language F,we would like to determine a score of relevance ofDF to QE.
However, as they are not directly compa-rable, a form of translation is needed.
Let us de-scribe the model that we will use to determine itsscore.Various theoretical models have been developedfor IR, including vector space model, Booleanmodel and probabilistic model.
Recently, languagemodeling is widely used in IR, and it has beenshow to produce very good experimental results.
Inaddition, language modeling also provides a solidtheoretical framework for integrating more aspectsin IR such as query translation.
Therefore, we willuse it as our basic framework in this study.In language modeling framework, the relevancescore of the document DF to the query QE is deter-mined as the negative KL-divergence between thequery?s language model and the document?s lan-guage model (Zhai, 2001a).
It is defined as fol-lows:?
?FtFFEFFE DtpQtpDQR )|(log)|(),(             (1)To avoid the problem of attributing zero prob-ability to query terms not occurring in documentDF, smoothing techniques are used to estimatep(tF|DF).
One can use the Jelinek-Mercer smooth-ing technique which is a method of interpolatingbetween the document and collection languagemodels (Zhai, 2001b).
The smoothed p(tF|DF) iscalculated as follows:)|()|()1()|( FFMLFFMLFF CtpDtpDtp ??
+?=         (2)where||),()|(FFFFFML DDttfDtp = and||),()|(FFFFFML CCttfCtp =are the maximum likelihood estimates of a uni-gram language model based on respectively thegiven document DF and the collection of docu-ments CF.
?
is a parameter that controls the influ-ence of each model.In CLIR, the term )|( EF Qtp in equation (1) rep-resenting the query model can be estimated as fol-lows: ??
==EE qEEEEFqEEFEF QqpQqtpQqtpQtp )|(),|()|,()|(?
?EqEEMLEF Qqpqtp )|()|(             (3)where )|( EEML Qqp  is the maximum likelihoodestimation:||),()|(EEEEEML QQqtfQqp = and )|( EF qtp isthe translation model.
Putting (3) in (1), we obtainthe general CLIR score formula: ??
?F EtFFqEEMLEFFE DtpQqpqtpDQR )|(log)|()|(),(  (4)In our work, we do not change the documentmodel )|( FF Dtp  from monolingual IR.
Our focuswill be put on the estimation of the translationmodel )|( EF qtp - the translation probability from asource query term qE to a target word tF, in particu-lar, when several translation resources are avail-able.Let us now describe two different ways to com-bine different translation resources for the estima-tion of )|( EF qtp : by linear combination and by con-fidence measure.1834 Linear CombinationThe first intuitive method to combine differenttranslation resources is by a linear combination.This means that the final translation model is esti-mated as follows:?=iEFiiqEF qtpzqtp E )|()|( ?
(5)where ?i is the parameter assigned to the transla-tion resource i andEqz is a normalization factor sothat 1)|( =?FtEF qtp .
)|( EFi qtp is the probabilityof translating the source word qE to the target wordtF  by the resource i.In order to determine the appropriate parameterfor each translation resource, we use the EM algo-rithm to find values which maximize the log-likelihood LL of a set C of training data accordingto the combined model, i.e.
:)()|(log),()(),(||1 1||1iijkCeffjnkeik epeftefpCLL ?
?
???
= = == ?
(6)Where (f, e)?C is a pair of parallel sentences;||),(#),(Cefefp = is the prior probability of the pair ofsentences (f, e) in the corpus C, |f| is the length ofthe target sentence f and |e| is the length of thesource sentence e. ?k is the coefficient related toresource k that we want to optimize and n is thenumber of resources.
tk(fj|ei) is the probability oftranslating the source word ei with the target wordfj with each resource.
p(ei) is the prior probabilityof the source word ei in the corpus C. Note that thevalidation data set C on which we optimize theparameters must be different from the one used totrain our baseline models.The training corpora are as follows: For English-Arabic, we use the Arabic-English parallel newscorpus1.
This corpus consists of around 83 K pairsof aligned sentences.
For English-French, we use abitext extracted from two parallel corpora: TheHansard 2  corpus and the Web corpus (Kadri,2004).
It consists of around 60 K pairs of alignedsentences.1 http://www.ldc.upenn.edu/Arabic-English Parallel News Part 1 (LDC2004T18)2 LDC provides a version of this corpus:http://www.ldc.upenn.edu/.The component models for English-ArabicCLIR are: a STM built on a set of parallel Webpages (Kadri, 2004), another STM built on theEnglish-Arabic United Nations corpus (Fraser,2002), Ajeeb3 bilingual dictionary and Almisbar4bilingual dictionary.
For English-French CLIR, weuse three component models: a STM built on Han-sard corpus, another STM built on parallel Webpages and the Freedict5 bilingual dictionary.5 Using Confidence MeasuresThe question considered in confidence measure is:Given a translation candidate, is it correct and howconfident are we on its correctness?Confidence measure aims to answer this ques-tion.
Given a translation candidate tF for a sourceterm qE and a set F of other features, confidencemeasure corresponds to ),,|1( FqtCp EFi = .
We canuse this measure as an estimate of )|( EF qtp , i.e.
: ?
==iEFiqEF FqtCpzqtp E ),,|1()|(        (7)where F is the set of features that we use.
We willsee several features to help determine the confi-dence measure of a translation candidate, for ex-ample, the translation probability, the reversetranslation probability, language model features,and so on.
We will describe these features in moredetail in section 5.2.In general, we can consider confidence measureas P(C=1|X), given X?
the source word, a transla-tion and a set of features.
We use a Multi LayerPerceptron (MLP) to estimate the probability ofcorrectness P(C=1|X) of a translation.
Neural net-works have the ability to use input data of differentnatures and they are well-suited for classificationtasks.Our training data can be viewed as a set of pairs(X,C), where X is a vector of features relative to atranslation6 used as the input of the network, and Cis the desired output (the correctness of the transla-tion 0/1).
The MLP implements a non-linear map-ping of the input features by combining layers oflinear transformation and non-linear transfer func-tion.
Formally, the MLP implements a discriminantfunction for an input X of the form:3 http://www.ajeeb.com/4 http://www.almisbar.com/5 http://www.freedict.com/6 By translation, we mean the pair of source word and itstranslation.184))(();( XWhVoXg ??=?
(8)where ?
={W,V}, W is a matrix of weights be-tween input and hidden layers and V is a vector ofweights between hidden and output layers; h is anactivation function for the hidden units which non-linearly transforms the linear combination of in-puts XW ?
; o is also a non-linear activation func-tion but for the output unit, that transforms theMLP output to the probability estimate P(C=1|X).Under these conditions, our MLP was trained tominimize an objective function of error rate (Sec-tion 4.1).In our experiments, we used a batch gradient de-scent optimizer.
During the test stage, the confi-dence of a translation X is estimated with theabove discriminant function g(X; ?
); where ?
is theset of weights optimized during the learning stage.These parameters are expected to correlate with thetrue probability of correctness P(C=1|X).5.1 The objective function to minimizeA natural metric for evaluating probability esti-mates is the negative log-likelihood (or cross en-tropy CE) assigned to the test corpus by the modelnormalized by the number of examples in the testcorpus (Blatz et al, 2003).
This metric evaluatesthe probabilities of correctness.
It measures thecross entropy between the empirical distribution onthe two classes (correct/incorrect) and the confi-dence model distribution across all the examplesX(i) in the corpus.
Cross entropy is defined as fol-lows:?
?=iiin XCPCE )|(log)()(1                     (9)where C(i) is 1 if the translation X(i) is correct, 0otherwise.
To remove dependence on the priorprobability of correctness, Normalized Cross En-tropy (NCE) is used:bb CECECENCE )( ?=                              (10)The baseline CEb is a model that assigns fixedprobabilities of correctness based on the empiricalclass frequencies:)/log()/()/log()/( 1100 nnnnnnnnCEb ?
?=         (11)where n0 and n1 are the numbers of correct and in-correct translations among n test cases.5.2 FeaturesThe MLP tends to capture the relationship betweenthe correctness of the translation and the features,and its performance depends on the selection ofinformative features.We selected intuitively seven classes of featureshypothesized to be informative for the correctnessof a translation.Translation model index: an index represent-ing the resource of translation that produced thetranslation candidate.Translation probabilities: the probability oftranslating a source word with a target word.
Theseprobabilities are estimated with IBM model 1(Brown et al, 1993) on parallel corpora.
For trans-lations from bilingual dictionaries, as no probabil-ity is provided, we carry out the following processto assign a probability to each translation pair (e, f)in a bilingual dictionary: We trained a statisticaltranslation model on a parallel corpus.
Then foreach translation pair (e,f) of the bilingual diction-ary, we looked up the resulting translation modeland extracted the probability assigned by thistranslation model to the translation pair in ques-tion.
Finally, the probability is normalized by theLaplace smoothing method:?=++= niiSTMSTMBDefpefpefp11)|(1)|()|((12)Where n is the number of translations proposed bythe bilingual dictionary to the word e.Translation ranking: This class of features in-cludes two features: The rank of the translationprovided by each resource and the probability dif-ference between the translation and the highestprobability translation.Reverse translation information: This in-cludes the probability of translation of a targetword to a source word.
Other features measure therank of source word in the list of translations of thetarget word and if the source word holds in the besttranslations of the target word.Translation ?Voting?
: This feature aims toknow whether the translation is voted by more thanone resource.
The more a same translation is votedthe more likely it may be correct.Source sentence-related features: One featuremeasures the frequency of the source word in thesource sentence.
Another feature measures thenumber of source words in the source sentence thathave a translation relation with the translation inquestion.185Language model features: We use the uni-gram, the bigram and the trigram language modelsfor source and target words on the training data.5.3 Training for confidence measuresThe corpus used for training confidence is thesame as the corpus for tuning parameters for thelinear combination.
It is a set of aligned sentences.Source sentences are translated to the target lan-guage word by word using baseline models.
Wetranslated each source word with the most prob-able7 translations for the translation models and thebest five translations provided by the bilingual dic-tionaries.
Translations are then compared to thereference sentence to build a labeled corpus: atranslation of a source word is considered to becorrect if it occurs in the reference sentence.
Theword order is ignored, but the number of occur-rences is taken into account.
This metric fits wellour context of IR: IR models are based on ?bag ofwords?
principle and the order of words is not con-sidered.We test with various numbers of hidden units(from 5 to 100).
We used the NCE metric to com-pare the performance of different architectures.The MLP with 50 hidden units gave the best per-formance.To test the performance of individual features,we experimented with each class of features alone.The best features are the translation ?voting?, lan-guage model features and the translation probabili-ties.
The translation ?voting?
is very informativebecause it presents the translation probability at-tributed by each resource to the translation in ques-tion.
The translation ranking, the reverse transla-tion information, the translation model index andthe source sentence-related features provide somemarginally useful information.6 CLIR experimentsThe experiments are designed to test whether theconfidence measure approach is effective for querytranslation, and how it compares with the tradi-tional linear combination.
We will conduct twoseries of experiments, one for English-FrenchCLIR and another for English-Arabic CLIR.7 The translations with the probability p(f|e)?0.16.1 Experimental setupEnglish-French CLIR: We use English queriesto retrieve French documents.
In our experiments,we use two document collections: one from TREC8and another from CLEF9 (SDA).
Both collectionscontain newspaper articles.
TREC collection con-tains 141 656 documents and CLEF collection44 013 documents.
We use 4 query sets: 3 fromTREC (TREC6 (25 queries), TREC7 (28 queries),TREC8 (28 queries)) and one from CLEF (40 que-ries).English-Arabic CLIR: For these experiments,we use English queries to retrieve Arabic docu-ments.
The test corpus is the Arabic TREC collec-tion which contains 383 872 documents.
For top-ics, we use two sets: TREC2001 (25 queries) andTREC2002 (50 queries).Documents and queries are stemmed and stop-words are removed.
The Porter stemming is usedto stem English queries and French documents.Arabic documents are stemmed using linguistic-based stemming method (Kadri, 2006).
The queryterms are translated with the baseline models (Sec-tion 4).
The resulting translations are then submit-ted to the information retrieval process.
We testedwith different ways to assign weights to translationcandidates: translations from each resource, linearcombination and confidence measures.When using each resource separately, we attrib-ute the IBM 1 translation probabilities to our trans-lations.
For each query term, we take only transla-tions with the probability p(f|e)?0.1 when usingtranslation models and the five best translationswhen using bilingual dictionaries.6.2 Linear combination (LC)The tuned parameters assigned to each transla-tion resource are as follows:English-Arabic CLR:STM-Web: 0.29, STM-UN: 0.34,Ajeeb BD: 0.14, Almisbar BD: 0.22.English-French CLR:STM-Web: 0.3588, STM-Hansard: 0.6408,Freedict BD: 0.0003.These weights produced the best log-likelihoodof the training data.8 http://trec.nist.gov/9 http://www.clef-campaign.org/186For CLIR, the above combinations are used tocombine translation candidates from different re-sources.
The tables below show the CLIR effec-tiveness (mean average precision - MAP) of indi-vidual models and the linear combination.TranslationModelTREC2001TREC2002MergedTREC2001/2002Monolingual IR (0.33) (0.28) (0.31)STM-Web 0.14 (42%) 0.04 (17%) 0.07 (25%)STM-UN 0.11 (33%) 0.09 (34%) 0.10 (33%)Ajeeb BD 0.27 (81%) 0.19 (70%) 0.22 (70%)Almisbar BD 0.17 (51%) 0.16 (58%) 0.16 (54%)Linear Comb.
0.24 (72%) 0.20 (71%) 0.21 (67%)Table1.
English-Arabic CLIR performance (MAP)with individual models and linear combinationTrans.
Model TREC6 TREC7 TREC8 CLEFMonolingual IR 0.39 0.34 0.44 0.40STM-Web 0.22 (56%) 0.17 (50%) 0.22 (50%) 0.29 (72%)STM-Hansard 0.25 (64%) 0.24 (70%) 0.33 (75%) 0.30 (75%)Freedict BD 0.17 (43%) 0.11 (32%) 0.13 (29%) 0.14 (35%)Linear Comb.
0.26 (66%) 0.26 (76%) 0.36 (81%) 0.30 (75%)Table2.
English-French CLIR performance (MAP) withindividual models and linear combinationWe observe that the performance is quite differ-ent from one model to another.
The low score re-corded by the STMs for English-Arabic CLIRcompared to the score of STMs for English-FrenchCLIR is possibly due to the small data set on whichthe English-Arabic STMs are trained.
A set of2816 English-Arabic pairs of documents is notenough to build a reasonable STM.
For English-Arabic CLIR, BDs present better performance thanSTMs because they cover almost all query termsand they provide multiple good translations to eachquery term.
When combining all the resources, theperformance is supposed to be better because wewould like to take advantage of each of the models.However, we see that the combined model per-forms even worse than one of the models - AjeebBD for English-Arabic CLIR.
This shows that thelinear combination is not necessarily a good way tocombine different translation resources.An example of English queries is shown in Ta-ble 3: ?What measures are being taken to developtourism in Cairo??.
The Arabic translation pro-vided by TREC to the word ?measures?
is:?????????.
We see clearly that translations with dif-ferent resources are different.
Some resources pro-pose inappropriate translations such as ???????
or???????.
Even if two resources suggest the sametranslations, the weights are different.
For thisquery, the linear combination produces betterquery translation terms than every resource takenalone: The most probable translations are selectedfrom the combined list.
However, this method isunable to attribute an appropriate weight to the besttranslation ?????????
; it is selected but ranked atthird position with a weak weight.Trans.
model Translation(s) of word ?measures?Ajeeb BD 0.05 ?????
(measure), 0.05 ????
(caliber), ???
?0.05 (measurement), 0.05 ?????
(measure-ment), 0.05 ?????
(standard), 0.05 ?????
(standard), 0.05 ?????
(balance)Almisbar BD 0.05 ???????
(procedures), 0.03 ???
,0.03 ?????
(measurement), 0.03 ?????
(amount)STM-UN 0.69 ??????
(measures)STM-Web 0.09 ??????
?Linear Comb, ????
,0.029 ???????
,0.037 ?????
,0.61 ??????0.020Table3.
Translation examples6.3 CLIR with Confidence Measures (CM)In these experiments, we use confidence meas-ures as weights for translations.
According to theseconfidence measures, we select the translationswith the best confidences for each query term.
Thefollowing tables show the results:Collection TREC 2001 TREC 2002 TREC01-02MAP of LC 0.2426 0.2032 0.2163MAP of CM 0.2775(14.35%) 0.2052 (1%) 0.2290 (5.87 %)Table4.
Comparison of English-Arabic CLIR betweenlinear combination and confidence measuresCollection TREC6 TREC7 TREC8 CLEFMAP of LC 0.2692 0.2630 0.3605 0.3071MAP of CM 0.2988(10.99%)0.2699(2.62%)0.3761(4.32%)0.3230(5.17 %)Table5.
Comparison of English-French CLIR be-tween linear combination and confidence measuresIn terms of MAP, we see clearly that the resultsusing confidence measures are better than thoseobtained with the linear combination.
The two-tailed t-test shows that the improvement broughtby confidence measure over linear combination isstatistically significant at the level P<0.05.
Thisimprovement in CLIR performance is attributed tothe ability of confidence measure to re-weight eachtranslation candidate.
The final sets of translations(and their probabilities) are more reasonable thanin linear combination.
The tables below show someexamples where we get a large improvement inaverage precision when using confidence measuresto combine resources.
The first example is theTREC 2001 query ?What measures are being takento develop tourism in Cairo??.
The translation ofthe query term ?measures?
to Arabic using the two187methods is presented in table 6.
The second exam-ple is the TREC6 query ?Acupuncture?.
Table 7presents the translation of this query term is toFrench using the two techniques:Trans.Model Translation(s) of term ?measures?Linear Comb.
????
,0.029 ???????
,0.037 ?????
,0.61 ??????0.020Conf.
meas.
0.06 ????
,0.10 ???
,0.51 ???????Table6.
Translation examples to ArabicTrans.model Translation(s) of term ?Acupuncture?Linear Comb.
Acupuncture 0.13 (acupuncture), sevrage0.13 (severing), hypnose 0.13 (hypnosis)Conf.
meas.
Acupuncture 0.21, sevrage 0.17, hypnose0.14Table7.
Translation examples to FrenchIn the example of table 6, confidence measurehas been able to redeem the best translation?????????
and rescore it with a stronger weight thanthe other incorrect or inappropriate ones.
The sameeffect is observed in the example of table 7.
Confi-dence measure has been able to increase the correcttranslation ?acupuncture?
to a higher level than theother incorrect ones.
These examples show the po-tential advantage of confidence measure over lin-ear combination: The confidence measure does notblindly trust all the translations from different re-sources.
It tests their validity on new validationdata.
Thus, the translation candidates are rescoredand filtered according to a more reliable weight.7 ConclusionMultiple translation resources are believed to con-tribute in improving the quality of query transla-tion.
However, in most previous studies, only lin-ear combination has been used.
In this study, wepropose a new method based on confidence meas-ure to combine different translation resources.
Theconfidence measure estimates the probability ofcorrectness of a translation, given a set of featuresavailable.
The measure is used to weight the trans-lation candidates in a unified manner.
It is also ex-pected that the new measure is more reasonablethan the original measures because of the use ofadditional features.
Our experiments on both Eng-lish-Arabic and English-French CLIR have shownthat confidence measure is a better way to combinetranslation resources than linear combination.
Thisshows that confidence measure is a promising ap-proach to combine non homogenous resources andcan be further improved on several aspects.
Forexample, we can optimize this technique by identi-fying other informative features.
Other techniquesfor computing confidence estimates can also beused in order to improve the performance of CLIR.ReferencesJ.
Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C.Goutte, A. Kulesza, A. Sanchis and N. Ueffing.
2003.Confidence estimation for machine translation.Technical Report, CLSP/JHU 2003 Summer Work-shop, Baltimore MD.P.
F. Brown, S. A. Pietra, V. J. Pietra and R. L. Mercer.1993.
The mathematics of statistical machine transla-tion: Parameter estimation.
Computational Linguis-tics, 19(2):263?311.A.
Fraser, J. Xu and R. Weischedel.
2002.
TREC2002 Cross-lingual Retrieval at BBN.
TREC11conference.S.
Gandrabur and G. Foster.
2003.
Confidence Estima-tion for Text Prediction.
Proceedings of the CoNLL2003 Conference, Edmonton.T.
J. Hazen, T. Burianek, J. Polifroni and S. Seneff.2002.
Recognition confidence scoring for use inspeech understanding systems.
Computer Speech andLanguage, 16:49-67.Y.
Kadri and J. Y. Nie.
2004.
Query translation forEnglish-Arabic cross language information retrieval.Proceedings of the TALN conference.Y.
Kadri and J. Y. Nie.
2006.
Effective stemming forArabic information retrieval.
The challenge of Ara-bic for NLP/MT Conference.
The British ComputerSociety.
London, UK.J.
Y. Nie, M. Simard and G Foster.
2000.
Multilingualinformation retrieval based on parallel texts from theWeb.
In LNCS 2069, C. Peters editor,CLEF2000:188-201, Lisbon.D.
W. Oard and A. Diekema.
1998.
Cross-LanguageInformation Retrieval.
In M. Williams (ed.
), Annualreview of Information science, 1998:223-256.J.
Xu and R. Weischedel.
2005.
Empirical studies on theimpact of lexical resources on CLIR performance.
In-formation processing & management, 41(3):475-487.C.
Zhai and J. Lafferty.
2001a.
Model-based feedback inthe language modeling approach to information re-trieval.
CIKM 2001 Conference.C.
Zhai and J. Lafferty.
2001b.
A study of smoothingmethods for language models applied to ad hoc in-formation retrieval.
Proceedings of the ACM-SIGIR.188
