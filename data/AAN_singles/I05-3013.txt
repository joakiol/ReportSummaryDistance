NIL Is Not Nothing: Recognition of ChineseNetwork Informal Language ExpressionsAbstractInformal language is actively used in net-work-mediated communication, e.g.
chatroom, BBS, email and text message.
We referthe anomalous terms used in such context asnetwork informal language (NIL) expres-sions.
For example, ??(ou3)?
is used to re-place ??
(wo3)?
in Chinese ICQ.
Withoutunconventional resource, knowledge andtechniques, the existing natural languageprocessing approaches exhibit less effective-ness in dealing with NIL text.
We propose tostudy NIL expressions with a NIL corpus andinvestigate techniques in processing NIL ex-pressions.
Two methods for Chinese NIL ex-pression recognition are designed in NILERsystem.
The experimental results show thatpattern matching method produces higherprecision and support vector machinesmethod higher F-1 measure.
These results areencouraging and justify our future researcheffort in NIL processing.1 IntroductionThe rapid global proliferation of Internet applica-tions has been showing no deceleration since thenew millennium.
For example, in commerce moreand more physical customer services/call centersare replaced by Internet solutions, e.g.
via MSN,ICQ, etc.
Network informal language (NIL) is ac-tively used in these applications.
Following thistrend, we forecast that NIL would become a keylanguage for human communication via network.Today NIL expressions are ubiquitous.
Theyappear, for example, in chat rooms, BBS, email,text message, etc.
There is growing importance inunderstanding NIL expressions from both technol-ogy and humanity research points of view.
Forinstance, comprehension of customer-operator dia-logues in the aforesaid commercial applicationwould facilitate effective Customer RelationshipManagement (CRM).Recently, sociologists showed many interests instudying impact of network-mediated communica-tion on language evolution from psychological andcognitive perspectives (Danet, 2002; McElhearn,2000; Nishimura, 2003).
Researchers claim thatlanguages have never been changing as fast as to-day since inception of the Internet; and the lan-guage for Internet communication, i.e.
NIL, getsmore concise and effective than formal language.Processing NIL text requires unconventionallinguistic knowledge and techniques.
Unfortu-nately, developed to handle formal language text,the existing natural language processing (NLP)approaches exhibit less effectiveness in dealingwith NIL text.
For example, we use ICTCLAS(Zhang et al, 2003) tool to process sentence ??????????
(Is he going to attenda meeting?)?.
The word segmentation result is??|?|?|?|?|??|?|??.
In this sentence , ????
(xi4 ba1 xi4)?
is a NIL expressionwhich means ?is he ?.??
in this case.
It can beconcluded that without identifying the expression,further Chinese text processing techniques are notable to produce reasonable result.This problem leads to our recent research in?NIL is Not Nothing?
project, which aims to pro-duce techniques for NIL processing, thus  availsunderstanding of change patterns and behaviors inlanguage (particularly in Internet language) evolu-tion.
The latter could make us more adaptive to thedynamic language environment in the cyber world.Recently some linguistic works have been car-ried out on NIL for English.
A shared dictionaryYunqing Xia,  Kam-Fai Wong,  Wei GaoDepartment of Systems Engineering and Engineering ManagementThe Chinese University of Hong Kong, Shatin, Hong Kong{yqxia, kfwong, wgao}@se.cuhk.edu.hk95has been compiled and made available online.
Itcontains 308 English NIL expressions includingEnglish abbreviations, acronyms and emoticons.Similar efforts for Chinese are rare.
This is be-cause Chinese language has not been widely usedon the Internet until ten years ago.
Moreover, Chi-nese NIL expression involves processing of Chi-nese Pinyin and dialects, which results in highercomplexity in Chinese NIL processing.In ?NIL is Not Nothing?
project, we develop acomprehensive Chinese NIL dictionary.
This is adifficult task because resource of NIL text is ratherrestricted.
We download a collection of BBS textfrom an Internet BBS system and construct a NILcorpus by annotating NIL expressions in this col-lection by hand.
An empirical study is conductedon the NIL expressions with the NIL corpus and aknowledge mining tool is designed to construct theNIL dictionary and generate statistical NIL fea-tures automatically.
With these knowledge andresources, the NIL processing system, i.e.
NILER,is developed to extract NIL expressions from NILtext by employing state-of-the-art information ex-traction techniques.The remaining sections of this paper are organ-ized as follow.
In Section 2, we observe formationof NIL expressions.
In Section 3 we present therelated works.
In Section 4, we describe NIL cor-pus and the knowledge engineering component inNIL dictionary construction and NIL features gen-eration.
In Section 5 we present the methods forNIL expression recognition.
We outline the ex-periments, discussions and error analysis in Sec-tion 6, and finally Section 7 concludes the paper.2 The Ways NIL Expressions Are Typi-cally FormedNIL expressions were first introduced for expedit-ing writing or computer input, especially for onlinechat where the input speed is crucial to prompt andeffective communication.
For example, it is ratherannoying to input full Chinese sentences in text-based chatting environment, e.g.
over the mobilephone.
Thus abbreviations and acronyms are thencreated by forming words in capital with the firstletters of a series of either English words or Chi-nese Pinyin.Chinese Pinyin is a popular approach to Chi-nese character input.
Some Pinyin input methodsincorporate lexical intelligence to support word orphrase input.
This improves input rate greatly.However, Pinyin input is not error free.
Firstly,options are usually prompted to user and selectionerrors result in homophone, e.g.
???(ban1zu2)?
and ???
(ban1 zhu3)?.
Secondly,input with incorrect Pinyin or dialect produceswrong Chinese words with similar pronunciation,e.g.
???
(xi1 fan4)?
and ???
(xi3 hua-n1)?.
Nonetheless, prompt communication spareslittle time to user to correct such a mistake.
Thesame mistake in text is constantly repeated, and thewrong word thus becomes accepted by the chatcommunity.
This, in fact, is one common way thata new Chinese NIL expression is created.We collect a large number of ?sentences?
(strictly speaking, not all of them are sentences)from a Chinese BBS system and identify NIL ex-pressions by hand.
An empirical study on NIL ex-pressions in this collection shows that NILexpressions can be classified into four classes asfollow based on their origins.1) Abbreviation (A).
Many Chinese NIL expres-sions are derived from abbreviation of Chi-nese Pinyin.
For example, ?PF?
equals to ???
(pei4 fu2)?
which means ?admire?.2) Foreign expression (F).
Popular Informal ex-pressions from foreign languages such asEnglish are adopted, e.g.
?ASAP?
is used for?as soon as possible?.3) Homophone (H).
A NIL expression is some-times generated by borrowing a word withsimilar sound (i.e.
similar Pinyin).
For exam-ple ???
?
equals ???
?
which means?like?.
????
and ????
hold homophonyin a Chinese dialect.4) Transliteration (T) is a transcription from onealphabet to another and a letter-for-letter orsound-for-letter spelling is applied to repre-sent a word in another language.
For exam-ple, ???
(bai4 bai4)?
is transliterationof ?bye-bye?.A thorough observation, in turn, reveals that,based on the ways NIL expressions are formedand/or their part of speech (POS) attributes, weobserve a NIL expression usually takes one of theforms presented in Table 1 and Table 2.The above empirical study is essential to NILlexicography and feature definition.963 Related WorksNIL expression recognition, in particular, can beconsidered as a subtask of information extraction(IE).
Named entity recognition (NER) happens tohold similar objective with NIL expression recog-nition, i.e.
to extract meaningful text segmentsfrom unstructured text according to certain pre-defined criteria.NER is a key technology for NLP applicationssuch as IE and question & answering.
It typicallyaims to recognize names for person, organization,location, and expressions of number, time and cur-rency.
The objective is achieved by employingeither handcrafted knowledge or supervised learn-ing techniques.
The latter is currently dominatingin NER amongst which the most popular methodsare decision tree (Sekine et al, 1998; Pailouras etal., 2000), Hidden Markov Model (Zhang et al,2003; Zhao, 2004), maximum entropy (Chieu andNg, 2002; Bender et al, 2003), and support vectormachines (Isozaki and Kazawa, 2002; Takeuchiand Collier, 2002; Mayfield, 2003).From the linguistic perspective, NIL expres-sions are rather different from named entities innature.
Firstly, named entity is typically noun ornoun phrase (NP), but NIL expression can be anykind, e.g.
number ?94?
in NIL represents ???
?which is a verb meaning ?exactly be?.
Secondly,named entities often have well-defined meaningsin text and are tractable from a standard dictionary;but NIL expressions are either unknown to the dic-tionary or ambiguous.
For example, ????
ap-pears in conventional dictionary with the meaningof Chinese porridge, but in NIL text it represents ????
which surprisingly represents ?like?.
Theissue that concerns us is that these expressions like????
may also appear in NIL text with theirformal meaning.
This leads to ambiguity andmakes it more difficult in NIL processing.Another notable work is the project of ?Nor-malization of Non-standard Words?
(Sproat et al,2001) which aims to detect and normalize the?Non-Standard Words (NSW)?
such as digit se-quence; capital word or letter sequence; mixedcase word; abbreviation; Roman numeral; URLand e-mail address.
In our work, we consider mosttypes of the NSW in English except URL andemail address.
Moreover, we consider ChineseNIL expressions that contain same characters asthe normal words.
For example, ???
?
and????
both appear in common dictionaries, butthey carry anomalous meanings in NIL text.
Am-biguity arises and basically brings NIL expressionsrecognition beyond the scope of NSW detection.According to the above observations, we pro-pose to employ the existing IE techniques to han-dle NIL expressions.
Our goal is to develop a NILexpression recognition system to facilitate net-work-mediated communication.
For this purpose,we first construct the required NIL knowledge re-sources, namely, a NIL dictionary and n-gram sta-tistical features.Table 2: NIL expression forms based on POS attribute.POSAttribute# of NILExpressions ExamplesNumber 1 ?W?
represents ??
(wan4)?and means ?ten thousand?.Pronoun 9 ???
represents ???
and means ?I?.Noun 29?LG?
represents ???(lao3gong1)?
and means ?hus-band?.Adjective 250 ?FB?
represents ???(fu3bai4)?
and means ?corrupt?.Verb 34???
(cong1 bai2)?
repre-sents ???
(chong3 bai4)?and means ?adore?.Adverb 10 ??(fen3)?
represents ??(hen3)?
and means ?very?.Exclamation  9??(nie0)?
represents ??(ne0)?
and equals a descrip-tive exclamation.Phrase 309 ?AFK?
represents ?Away From Keyboard?.Table 1: NIL expression forms based on word formation.WordFormation# of NILExpressions ExamplesChineseWord orPhrase33 ????
represents ????
and means ?like?.Sequence ofEnglishCapitals341 ?PF?
represents ????
and means ?admire?.Number 8?94(jiu3 si4)?
represents???
(jiu4 shi4)?
andmeans ?exactly be?.Mixture ofthe AboveForms30?8?
(ba1 cuo4)?
repre-sents ???
(bu3 cuo4)?and means ?not bad?.Emoticons 239 ?:-(?
represents a sad emotion.974 Knowledge EngineeringRecognition of NIL expressions relies on uncon-ventional linguistic knowledge such as NIL dic-tionary and NIL features.
We construct a NILcorpus and develop a knowledge engineeringcomponent to obtain these knowledge by running aknowledge mining tool on the NIL corpus.
Theknowledge mining tool is a text processing pro-gram that extracts NIL expressions and their at-tributes and contextual information, i.e.
n-grams,from the NIL corpus.
Workflow for this compo-nent is presented in Figure 1.4.1  NIL CorpusThe NIL corpus is a collection of network informalsentences which provides training data for NILdictionary and statistical NIL features.
The NILcorpus is constructed by annotating a collection ofNIL text manually.Obtaining real chat text is difficult because ofthe privacy restriction.
Fortunately, we find BBStext within ????
(da4 zui3 qu1)?
zone inYESKY system (http://bbs.yesky.com/bbs/) re-flects remarkable colloquial characteristics andcontains a vast amount of NIL expressions.
Wedownload BBS text posted from December 2004and February 2005 in this zone.
Sentences withNIL expressions are selected by human annotators,and NIL expressions are manually identified andannotated with their attributes.
We finally col-lected 22,432 sentences including 451,193 wordsand 22,648 NIL expressions.The NIL expressions are marked up withSGML.
The typical example, i.e.
???????????
in Section 1, is annotated as follows.where NILEX is the SGML tag to label a NIL ex-pression, which entails NIL linguistic attributesincluding class, normal, pinyin, segments, pos, andposseg (see Section 4.2).
H is a value of class (seeSection 2).
Value VERB demotes verb, ADJ adjec-tive, NUM number and AUX auxiliary.4.2  NIL DictionaryThe NIL dictionary is a structured databank thatcontains NIL expression entries.
Each entity inturn entails nine attributes described as follow.1.
ID: an unique identification number for theNIL expression, e.g.
915800;2. string: string of the NIL expression, e.g.
?????;3.
class: class of the NIL expression (see Sec-tion 2), e.g.
?H?
for homophony;4. pinyin: Chinese Pinyin for the NIL expres-sion, e.g.
?xi4 ba1 xi4?;5.
normal: corresponding normal text for theNIL expression, e.g.
?????;6.
segments: word segments of the NIL expres-sion, e.g.
??|?|??;7.
pos: POS tag associated with the expression,e.g.
?VERB?
denoting a verb;8. posseg: a POS tag list for the word seg-ments, e.g.
?VERB|AUX|VERB?;9.
frequency: number of occurrences of theNIL expression.We run the knowledge mining tool to extract allannotated NIL expressions together with their at-tributes from the NIL corpus.
The NIL expressionsare then each assigned an ID number and insertedinto an indexed data file, i.e.
the NIL dictionary.Current NIL dictionary contains 651 NIL entries.4.3  NIL Feature SetThe NIL features are required by support vectormachines method in NIL expression recognition.We define two types of statistical features for NILexpressions, i.e.
Chinese word n-grams and POStag n-grams.
Bigger n leads to more contextual?<NILEX string=?????
class=?H?
normal=?????
pinyin=?xi4 ba1 xi4?
segments=??|?|??pos=?VERB?
posseg=?ADJ|NUM|ADJ?>???</NILEX>????
?Figure 1: Workflow for NIL knowledge engineeringcomponent.
NILE refers to NIL expression, which isidentified and annotated by human annotator.NILEAnnotationOriginal TextCollectionNIL CorpusNILDictionaryNILFeaturesExtractA SentenceKnowledge Mining ToolWord Segmentation & POS Tagging(ICTCLAS)98information, but results in higher computationalcomplexity.
To compromise, we generate n-gramswith n = 1, 2, 3, 4.
For example,   ???/???
?is a bi-gram for ?????
in terms of word seg-mentation, and its POS tag bi-gram is?PRONOUN/ VERB?.We run the knowledge mining tool on the NILcorpus to produce all n-grams for Chinese wordsand their POS tags in which NIL expression ap-pears.
8379 features were generated including7416 word-based n-grams and 963 POS tag-basedn-grams.
These statistical NIL features are linkedto the corresponding NIL dictionary entries bytheir global NIL expression IDs.Besides, we consider some morphological fea-tures including being/containing a number, someEnglish capitals or Chinese characters.
These fea-tures can be extracted by parsing string of the NILexpressions.5 NILER System5.1  ArchitectureWe develop NILER system to recognize NIL ex-pressions in NIL text and convert them to normallanguage text.
The latter functionality is discussedin other literatures.
Architecture of NILER systemis presented in Figure 2.The input chat text is first segmented and POStagged with ICTCLAS tool.
Because ICTCLAS isnot able to identify NIL expressions, some expres-sions are broken into several segments.
NIL ex-pression recognizer processes the segments andPOS tags and identifies the NIL expressions.5.2  NIL Expression RecognizerWe implement two methods in NIL expressionrecognition, i.e.
pattern matching and support vec-tor machines.5.2.1  Method I: Pattern MatchingPattern matching (PM) is a traditional method ininformation extraction systems.
It uses a hand-crafted rule set and dictionary for this purpose.Because it?s simple, fast and independent of cor-pus, this method is widely used in IE tasks.By applying NIL dictionary, candidates of NILexpressions are first extracted from the input textwith longest matching.
As ambiguity occurs con-stantly, 24 patterns are produced and employed todisambiguate.
We first extract those word and POStag n-grams from the NIL corpus and create pat-terns by generalizing them manually.
An illustra-tive pattern is presented as follows.?
]_[)_(8]_[ ?!
!
!
anyvunitvnotanyvwhere anyv _  and unitv _  are variables denotingany word and any unit word respectively;  )(xnotis the negation operator.
The illustrative patterndetermines ?8?
to be a NIL expression if it is suc-ceeded by a unit word.
With this pattern, ?8?within sentence ?????
 ????
(He hasbeen working for eight hours.)?
is not recognizedas a NIL expression.5.2.2  Method II: Support Vector MachinesSupport vector machines (SVM) method produceshigh performance in many classification tasks(Joachims, 1998; Kudo and Matsumoto, 2001).
AsSVM can handle large numbers of features effi-ciently, we employ SVM classification method toNIL expression recognition.Suppose we have a set of training data for atwo-class classification problem {(x1,y1), (x2,y2),?,(xN, yN)}, where ),...2,1( NiRx Di  ?
is a fea-ture vector of the i-th order sample in the trainingset and }1,1{ ?iy  is the label for the sample.The goal of SVM is to find a decision function thataccurately predicts y for unseen x.
A non-linearSVM classifier gives a decision function))(()( xgsignxf   for an input vector x, where?liii bzxKxg1),()( YThe szi  are so-called support vectors, andrepresents the training samples.
iY  and b  are pa-rameters for SVM motel.
l is number of trainingsamples.
),( zxK  is a kernel function that implic-NILDictionaryNILFeaturesChat TextNIL ExpressionListNIL ExpressionRecognizerWord SegmentationWord POS Tagging(ICTCLAS)Figure 2: Architecture of NILER system.99itly maps vector x into a higher dimensional space.A typical kernel is defined as dot products, i.e.
)(),( zxkzxK x .Based on the training process, the SVM algo-rithm constructs the support vectors and parame-ters.
When text is input for classification, it is firstconverted into feature vector x.
The SVM methodthen classifies the vector x by determining sign ofg(x), in which 1)(  xf  means that word x is posi-tive and otherwise if 1)(  xf .
The SVM algo-rithm was later extended in SVMmulticlass to predictmultivariate outputs (Joachims, 1998).In NIL expression recognition, we considerNIL corpus as training set and the annotated NILexpressions as samples.
NIL expression recogni-tion is achieved with the five-class SVM classifi-cation task, in which four classes are those definedin Section 2 and reflected by class attribute withinNIL annotation scheme.
The fifth class isNOCLASS, which means the input text is not anyNIL expression class.6 Experiments6.1  Experiment DescriptionWe conduct experiments to evaluate the two meth-ods in performing the task of NIL expression rec-ognition.
In training phase we use NIL corpus toconstruct NIL dictionary and pattern set for PMmethod, and generate statistical NIL features, sup-port vectors and parameters for SVM methods.
Toobserve how performance is influenced by the vol-ume of training data, we create five NIL corpora,i.e.
C#1~C#5, with five numbers of NIL sentences,i.e.
10,000, 13,000, 16,000, 19,000 and 22,432, byrandomly selecting sentence from NIL corpus de-scribed in Section 4.1.To generate test set, we download 5,690 sen-tences from YESKY system which cover BBS textin March 2005.
We identify and annotate NIL ex-pressions within these sentences manually andconsider the annotation results as gold standard.We first train the system with the five corporato produce five versions of NIL dictionary, patternset, statistical NIL feature set and SVM model.
Wethen run the two methods with each version of theabove knowledge over the test set to produce rec-ognition results automatically.
We compare theseresults against the gold stand and present experi-mental results with criteria including precision,recall and F1-measure.6.2  Experimental ResultsWe present experimental results of the two meth-ods on the five corpora in Table 3.Table 3: Experimental results for the two methods on the fivecorpora.
PRE denotes precision, REC denotes recall, and F1denotes F1-Measure.PM SVM CorpusPRE REC F1 PRE REC F1C#1 0.742 0.547 0.630 0.683 0.703 0.693C#2 0.815 0.634 0.713 0.761 0.768 0.764C#3 0.873 0.709 0.783 0.812 0.824 0.818C#4 0.904 0.759 0.825 0.847 0.851 0.849C#5 0.915 0.793 0.850 0.867 0.875 0.8716.3  Discussion I: The Two MethodsTo compare performance of the two methods, wepresent the experimental results with smoothedcurves for precision, recall and F1-Mesure in Fig-ure 3, Figure 4 and Figure 5 respectively.0.650.70.750.80.850.90.950 1 2 3 4 5 6Pattern MatchingSVMFigure 3: Smoothed precision curves over the five corpora.0.50.550.60.650.70.750.80.850.90 1 2 3 4 5 6Pattern MatchingSVMFigure 4: Smoothed recall curves over the five corpora.Figure 3 reveals that PM method produceshigher precision, i.e.
91.5%, and SVM produceshigher recall, i.e.
79.3%, and higher F1-Measure,i.e.
87.1%, with corpus C#5.
It can be inferred thatPM method is self-restrained.
In other words, if aNIL expression is identified with this method, it isvery likely that the decision is right.
However, theweakness is that more NIL expressions are ne-glected.
On the other hand, SVM method outper-100forms PM method regarding overall capability, i.e.F1-Measure, according to Figure 5.0.60.650.70.750.80.850.90 1 2 3 4 5 6Pattern MatchingSVMFigure 5: Smoothed F1-Measure curves over the five corpora.We argue that each method holds strength andweakness.
Different methods should be adopted tocater to different application demands.
For exam-ple, in CRM text processing, we might favor preci-sion.
So PM method may be the better choice.
Onthe other hand, to perform the task of chat roomsecurity monitoring, recall is more important.
ThenSVM method becomes the better option.
We claimthat there exists an optimized approach whichcombines the two methods and yields higher preci-sion and better robustness at the same time.6.4  Discussion II: How Volume Influences Per-formanceTo observe how training corpus influences per-formance in the two methods regarding volume,we present experimental results with smoothedquality curves for the two method in Figure 6 andFigure 7 respectively.0.50.550.60.650.70.750.80.850.90.950 1 2 3 4 5 6PRERECF1Figure 6: Smoothed quality curves for PM method over thefive corpora.0.650.70.750.80.850.90 1 2 3 4 5 6PRERECF1Figure 7: Smoothed quality curves for SVM methodover the five corpora.The smoothed quality curves in Figure 6 andFigure 7 reveal the tendency that bigger volume oftraining data leads to better processing quality.Meanwhile, the improvement tends to decreasealong with increasing of volume.
It thus predictsthat there exists a corpus with a certain volumethat produces the best quality according to the ten-dency.
Although current corpus is not big enoughto prove the optimal volume, the tendency re-vealed by the curves is obvious.6.5  Error AnalysisWe present two examples to analyze errors occurwithin our experiments.Err.1 Ambiguous NIL ExpressionExample 1:[Sentence]: ???
8??
[Meaning]:  I still don?t understand.
[NIL expression found(Y/N)?
]: Y[Normal language text]: ?????
?Error in Example 1 is caused by failure in iden-tifying ?
?
?
(mi3 bai2)?.
Because ?
?(mi3)?
succeeds ?8(ba1)?
in the word seg-ments, i.e.
??|??|8|?|?
?, and it can be used asa unit word, PM method therefore refuses to iden-tify ?8(ba)?
as a NIL expression according to thepattern described in Section 5.2.1.
In fact, ???
?is an unseen NIL expression.
SVM method suc-cessfully recognizes ???
?
to be ???
(mi3you3)?, thus recognizes ?8?.
In our experiments56 errors in PM method suffer the same failure,while SVM method identifies 48 of them.
Thisdemonstrates that PM method is self-restrainedand SVM method is relatively scalable in process-ing NIL text.Err.2 Unseen NIL expressionExample 2:[Sentence]: ???
4U??
[Meaning]: Just came back from 4U.
[NIL expression found (Y/N)?]
: NActually, there is no NIL expression in example2.
But because of a same 1-gram with ?4D?, i.e.
?4?, SVM outputs ?4U?
as a NIL expression.
Infact, it is the name for a mobile dealer.
There are78 same errors in SVM method in our experi-ments, which reveals that SVM method is some-times over-predicting.
In other words, some NILexpressions are recognized with SVM method bymistake, which results in lower precision.1017 Conclusions and Future WorksNetwork informal language processing is a newNLP research application, which seeks to recog-nize and normalize NIL expressions automaticallyin a robust and adaptive manner.
This research iscrucial to improve capability of NLP techniques indealing with NIL text.
With empirical study onChinese network informal text and NIL expres-sions, we propose two NIL expression recognitionmethods, i.e.
pattern matching and support vectormachines.
The experimental results show that PMmethod produces higher precision, i.e.
91.5%, andSVM method higher F-1 measure, i.e.
87.1%.These results are encouraging and justify our fu-ture research effort in NIL processing.Research presented in this paper is preliminarybut significant.
We address future works as follow.Firstly, NIL corpus constructed in our work is fun-damental.
Not only will difficulty in seeking fortext resource be overcome, but a large quantity ofmanpower will be allocated to this laborious andsignificant work.
Secondly, new NIL expressionswill appear constantly with booming of network-mediated communication.
A powerful NIL expres-sion recognizer will be designed to improve adap-tivity of the recognition methods and handle theunseen NIL expressions effectively.
Finally, westate that research in this paper targets in special atNIL expressions in China mainland.
Due to cul-tural/geographical variance, NIL expressions inHong Kong and Taiwan could be different.
Furtherresearch will be conducted to adapt our methods toother NIL communities.ReferencesBender, O., Och, F. J. and Ney, H. 2003.
Maximum En-tropy Models for Named Entity Recognition,CoNLL-2003,  pp.
148-151.Chieu, H. L. and Ng, H. T. 2002.
Named Entity Recog-nition: A Maximum Entropy Approach Using GlobalInformation.
COLING-02, pp.
190-196.Danet, B.
2002.
The Language of Email, European Un-ion Summer School, University of Rome.Isozaki, H. and Kazawa, H. 2002.
Efficient SupportVector Classifiers for Named Entity Recognition,COLING-02, pp.
390-396..Joachims, T. 1998.
Text categorization with SupportVector Machines: Learning with many relevant fea-tures.
ECML?98, pp.
137-142.Kudo, T. and Matsumoto, Y.
2001.
Chunking with Sup-port Vector Machines.
NAACL 2001, pp.192-199.Mayfield, J.
2003.
Paul McNamee; Christine Piatko,Named Entity Recognition using Hundreds of Thou-sands of Features, CoNLL-2003, pp.
184-187.McElhearn, K. 2000.
Writing Conversation - An Analy-sis of Speech Events in E-mail Mailing Lists,http://www.mcelhearn.com/cmc.html, Revue Fran-?aise de Linguistique Appliqu?e, volume V-1.Nishimura, Y.
2003.
Linguistic Innovations and Inter-actional Features of Casual Online Communicationin Japanese, JCMC 9 (1).Pailouras, G., Karkaletsis, V. and Spyropoulos, C. D.2000.
Learning Decision Trees for Named-EntityRecognition and Classification.
Workshop on Ma-chine Learning for Information Extraction,ECAI(2000).Sekine, S., Grishman, R. and Shinnou, H. 1998.
A Deci-sion Tree Method for Finding and Classifying Namesin Japanese Texts, WVLC 98.Snitt, E. N. 2000.
The Use of Language on the Internet,http://www.eng.umu.se/vw2000/Emma/lin-guistics1.htm.Sproat, R., Black, A.,  Chen, S., Kumar, S., Ostendorf,M.
and Richards, M. 2001.
Normalization of Non-standard Words.
Computer Speech and Languages,15(3):287- 333.Takeuchi, K. and Collier, N. 2002.
Use of Support Vec-tor Machines in Extended Named Entity Recognition.CoNLL-2002, pp.
119-125.Zhang, Z., Yu, H., Xiong, D. and Liu, Q.
2003.
HMM-based Chinese Lexical Analyzer ICTCLAS.
In the 2ndSIGHAN workshop affiliated with ACL?03, pp.
184-187.Zhao, S. 2004.
Named Entity Recognition in BiomedicalTexts Using an HMM model, COLING-04 workshopon Natural Language Processing in Biomedicine andits Applications.102
