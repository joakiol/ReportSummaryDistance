Proceedings of NAACL-HLT 2013, pages 1010?1019,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsBroadly Improving User Classification viaCommunication-Based Name and Location Clustering on TwitterShane Bergsma, Mark Dredze, Benjamin Van Durme, Theresa Wilson, David YarowskyDepartment of Computer Science and Human Language Technology Center of ExcellenceJohns Hopkins UniversityBaltimore, MD 21218, USAshane.a.bergsma@gmail.com, mdredze@cs.jhu.edu, vandurme@cs.jhu.edu, taw@jhu.edu, yarowsky@cs.jhu.eduAbstractHidden properties of social media users, suchas their ethnicity, gender, and location, are of-ten reflected in their observed attributes, suchas their first and last names.
Furthermore,users who communicate with each other of-ten have similar hidden properties.
We pro-pose an algorithm that exploits these insightsto cluster the observed attributes of hundredsof millions of Twitter users.
Attributes suchas user names are grouped together if userswith those names communicate with othersimilar users.
We separately cluster millionsof unique first names, last names, and user-provided locations.
The efficacy of these clus-ters is then evaluated on a diverse set of clas-sification tasks that predict hidden users prop-erties such as ethnicity, geographic location,gender, language, and race, using only pro-file names and locations when appropriate.Our readily-replicable approach and publicly-released clusters are shown to be remarkablyeffective and versatile, substantially outper-forming state-of-the-art approaches and hu-man accuracy on each of the tasks studied.1 IntroductionThere is growing interest in automatically classify-ing users in social media by various hidden prop-erties, such as their gender, location, and language(e.g.
Rao et al(2010), Cheng et al(2010), Bergsmaet al(2012)).
Predicting these and other proper-ties for users can enable better advertising and per-sonalization, as well as a finer-grained analysis ofuser opinions (O?Connor et al 2010), health (Pauland Dredze, 2011), and sociolinguistic phenomena(Eisenstein et al 2011).
Classifiers for user prop-erties often rely on information from a user?s socialnetwork (Jernigan and Mistree, 2009; Sadilek et al2012) or the textual content they generate (Pennac-chiotti and Popescu, 2011; Burger et al 2011).Here, we propose and evaluate classifiers that bet-ter exploit the attributes that users explicitly providein their user profiles, such as names (e.g., first nameslike Mary, last names like Smith) and locations (e.g.,Brasil).
Such attributes have previously been used as?profile features?
in supervised user classifiers (Pen-nacchiotti and Popescu, 2011; Burger et al 2011;Bergsma et al 2012).
There are several motivationsfor exploiting these data.
Often the only informa-tion available for a user is a name or location (e.g.for a new user account).
Profiles also provide anorthogonal or complementary source of informationto a user?s social network and textual content; gainsbased on profiles alone should therefore add to gainsbased on other data.
The decisions of profile-basedclassifiers could also be used to bootstrap trainingdata for other classifiers that use complementary fea-tures.Prior work has encoded profile attributes via lex-ical or character-based features (e.g.
Pennacchiottiand Popescu (2011), Burger et al(2011), Bergsmaet al(2012)).
Unfortunately, due to the long-taileddistribution of user attributes, a profile-based classi-fier will encounter many examples at test time thatwere not observed during training.
For example,suppose a user wassim hassan gives their location astanger.
If the attribute tokens wassim, hassan, andtanger do not occur in training (nor indicative sub-1010strings), then a classifier can only guess at the user?sethnicity and location.
In social media, the preva-lence of fake names and large variations in spelling,slang, and language make matters worse.Our innovation is to enhance attribute-based clas-sifiers with new data, derived from the communica-tions of Twitter users with those attributes.
Userswith the name tokens wassim and hassan often talkto users with Arab names like abdul and hussein.Users listing their location as tanger often talk tousers from morocco.
Since users who communicateoften share properties such as ethnicity and location(?8), the user wassim hassan might be an Arab whouses the French spelling of the city Tangier.Our challenge is to encode these data in a formreadily usable by a classifier.
Our approach is torepresent each unique profile attribute (e.g.
tangeror hassan) as a vector that encodes the communi-cation pattern of users with that attribute (e.g.
howoften they talk to users from morocco, etc.
); we thencluster the vectors to discover latent groupings ofsimilar attributes.
Based on transitive (third party)connections, tanger and tangier can appear in thesame cluster, even if no two users from these loca-tions talk directly.
To use the clusters in an attribute-based classifier, we add new features that indicatethe cluster memberships of the attributes.
Clusteringthus lets us convert a high-dimensional space of allattribute pairs to a low-dimensional space of clustermemberships.
This makes it easier to share our data,yields fewer parameters for learning, and creates at-tribute groups that are interpretable to humans.We cluster names and locations in a very largecorpus of 168 million Twitter users (?2) and use adistributed clustering algorithm to separately clus-ter millions of first names, last names, and user-provided locations (?3).
We evaluate the use of ourcluster data as a novel feature in supervised classi-fiers, and compare our result to standard classifiersusing character and token-level features (?4).
Thecluster data enables significantly improved perfor-mance in predicting the gender, location, and lan-guage of social media users, exceeding both ex-isting state-of-the-art machine and human perfor-mance (?6).
Our cluster data can likewise im-prove performance in other domains, on both es-tablished and new NLP tasks as further evaluatedin this paper (?6).
We also propose a way toFirst names: maria, david, ana, daniel, michael, john,alex, jessica, carlos, jose, chris, sarah, laura, juanLast names: silva, santos, smith, garcia, oliveira, ro-driguez, jones, williams, johnson, brown, gonzalezLocations: brasil, indonesia, philippines, london,jakarta, s?o paulo, rio de janeiro, venezuela, brazilTable 1: Most frequent profile attributes for our collectionof 168 million Twitter users, in descending orderenhance a geolocation system by using commu-nication patterns, and show strong improvementsover a hand-engineered baseline (?7).
We shareour clusters with the community to use with othertasks.
The clusters, and other experimental data, areavailable for download from www.clsp.jhu.edu/~sbergsma/TwitterClusters/.2 Attribute Associations on TwitterData and Processing Our raw Twitter data com-prises the union of 2.2 billion tweets from 05/2009to 10/2010 (O?Connor et al 2010), 1.8 billiontweets collected from 07/2011 to 08/2012, and 80million tweets collected from followers of 10 thou-sand location and language-specific Twitter feeds.We implemented each stage of processing usingMapReduce (Dean and Ghemawat, 2008).
The totalcomputation (from extracting profiles to clusteringattributes) was 1300 days of wall-clock CPU time.Attribute Extraction Tweets provide the nameand self-reported location of the tweeter.
We find126M unique users with these attributes in our data.When tweets mention other users via an @user con-struction, Twitter also includes the profile name ofthe mentioned user; we obtain a further 42M usersfrom these cases.
We then normalize the extractedattributes by converting to lower-case, deleting sym-bols, numbers, and punctuation, and removing com-mon honorifics and suffixes like mr/mrs and jr/sr.Common prefixes like van and de la are joined tothe last-name token.1 This processing yields 8.3M1www.clsp.jhu.edu/~sbergsma/TwitterClusters/also provides our scripts for normalizing attributes.
The scriptscan be used to ensure consistency/compatibility betweenarbitrary datasets and our shared cluster data.
Note we use nospecial processing for the companies, organizations, and spam-mers among our users, nor for names arising from differentconventions (e.g.
1-word names, reversed first/last names).1011henrik: fredrik 5.87, henrik 5.82, anders 5.73, johan5.69, andreas 5.59, martin 5.54, magnus 5.41courtney: taylor 8.03, ashley 7.92, courtney 7.92,emily 7.91, lauren 7.82, katie 7.72, brittany 7.69ilya: sergey 5.85, alexey 5.62, alexander 5.59, dmitry5.51, ?????????
5.46, anton 5.44, andrey 5.40Table 2: Top associates and PMIs for three first names.unique locations, 7.4M unique last names, and 5.5Munique first names.
These three sets provide the tar-get attributes that we cluster in ?3.
Table 1 showsthe most frequent names in each of these three sets.User-User Links We extract each user mention asan undirected communication link between the usertweeting and the mentioned user (including self-mentions but not retweets).
We consider each user-user link as a single event; we count it once no mat-ter how often two specific users interact.
We extract436M user-user links in total.Attribute-Attribute Pairs We use our profile datato map each user-user link to an attribute-attributepair; we separately count each pair of first names,last names, and locations.
For example, the first-name pair (henrik, fredrik) occurs 181 times.
Ratherthan using the raw count, we calculate the associa-tion between attributes a1 and a2 via their pointwisemutual information (PMI), following prior work indistributional clustering (Lin and Wu, 2009):PMI(a1, a2) = logP(a1, a2)P(a1)P(a2)PMI essentially normalizes the co-occurrence bywhat we would expect if the attributes were indepen-dently distributed.
We smooth the PMI by adding acount of 0.5 to all co-occurrence events.The most highly-associated name attributes re-flect similarities in ethnicity and gender (Table 2).The most highly-ranked associates for locations areoften nicknames and alternate/misspellings of thoselocations.
For example, the locations charm city,bmore, balto, westbaltimore, b a l t i m o r e, bal-timoreee, and balitmore each have the U.S. city ofbaltimore as their highest-PMI associate.
We showhow this can be used to help geolocate users (?7).3 Attribute ClusteringRepresentation We first represent each target at-tribute as a feature vector, where each feature corre-sponds to another attribute of the same type as thetarget and each value gives the PMI between this at-tribute and the target (as in Table 2).2 To help clusterthe long-tail of infrequent attributes, we also includeorthographic features.
For first and last names, wehave binary features for the last 2 characters in thestring.
For locations, we have binary features for(a) any ideographic characters in the string and (b)each token (with diacritics removed) in the string.We normalize the feature vectors to unit length.Distributed K-Means Clustering Our approachto clustering follows Lin and Wu (2009) who used k-means to cluster tens of millions of phrases.
We alsouse cosine similarity to compute the closest centroid(i.e., we use the spherical k-means clustering algo-rithm (Dhillon and Modha, 2001)).
We keep trackof the average cosine similarity between each vectorand its nearest centroid; this average is guaranteedto increase at each iteration.Like Lin and Wu (2009), we parallelize the al-gorithm using MapReduce.
Each mapper finds thenearest centroids for a portion of the vectors, whilealso computing the partial sums of the vectors as-signed to each centroid.
The mappers emit the cen-troid IDs as keys and the partial sums as values.The Reducer aggregates the partial sums from eachpartition and re-normalizes each sum vector to unitlength to obtain the new centroids.
We also use aninverted index at each iteration that, for each inputfeature, lists which centroids each feature belongsto.
Using this index greatly speeds up the centroidsimilarity computations.Clustering Details We cluster with nine separateconfigurations: over first names, last names, and lo-cations, and each with 50, 200, and 1000 clustercentroids (denoted C50, C200, and C1000).
Since k-2We decided to restrict the features for a target to be at-tributes of the same type (e.g., we did not use last name as-sociations for a first name target) because each attribute typeconveys distinct information.
For example, first names conveygender and age more than last names.
By separately cluster-ing representations using first names, last names, and locations,each clustering can capture its own distinct latent-class associa-tions.1012Cluster 463 (Serbian): pavlovic?, jovanovic, jo-vanovic?, stankovic?, srbija, markovic?, petrovic?,radovic, nenad, milenkovic, nikolic, sekulic, todor-ovic, stojanovic, petrovic, aleksic, ilic, markovicCluster 544 (Black South African): ngcobo, nkosi,dlamini, ndlovu, mkhize, mtshali, sithole, mathebula,mthembu, khumalo, ngwenya, shabangu, nxumalo,buthelezi, radebe, mabena, zwane, mbatha, sibiyaCluster 449 (Turkish): s?ahin, ?elik, ?zt?rk, ko?, ?ak?r,karatas?, aktas?, g?ng?r, ?zkan, balc?, g?m?s?, akkaya,gen?, sar?, y?ksel, g?nes?, yig?it, yal?
?n, orhan, sag?lam,g?ler, demirci, k??
?k, yavuz, bayrak, ?zcan, altunCluster 656 (Indonesian): utari, oktaviana, apriani,mustika, septiana, febrianti, kurniawati, indriani, nur-janah, septian, cahya, anggara, yuliani, purnamasari,sukma, wijayanti, pramesti, ningrum, yanti, wulansariTable 3: Example C1000 last-name clustersCluster 56 [sim=0.497]: gregg, bryn, bret, stewart,lyndsay, howie, elyse, jacqui, becki, rhett, meaghan,kirstie, russ, jaclyn, zak, katey, seamus, brennan,fraser, kristie, stu, jaimie, kerri, heath, carley, griffinCluster 104 [sim=0.442]: stephon, devonte, deion,demarcus, janae, tyree, jarvis, donte, dewayne, javon,destinee, tray, janay, tyrell, jamar, iesha, chyna,jaylen, darion, lamont, marquise, domonique, alexusCluster 132 [sim=0.292]: moustafa, omnya, menna-tallah, ?C?
@, shorouk, ragab, ??
?, radwa, moemen,mohab, hazem, yehia, ?
KQ k, Z @Q??
@, mennah, ?Q??
?,abdelrahman, ????
?, H. 	Qk, Q?AK, nermeen, hebatallah...Table 4: C200 soft clustering for first name yasmeenmeans is not guaranteed to reach a global optimum,we use ten different random initializations for eachconfiguration, and select the one with the highest av-erage similarity after 20 iterations.
We run this onefor an additional 30 iterations and take the output asour final set of centroids for that configuration.The resulting clusters provide data that could helpclassify hidden properties of social media users.
Forexample, Table 3 shows that last names often clus-ter by ethnicity, even at the sub-national level (e.g.Zulu tribe surnames nkosi, dlamini, mathebula, etc.
).Note the Serbian names include two entries that arenot last names: srbija, the Serbian word for Serbia,and nenad, a common Serbian first name.Soft Clustering Rather than assigning each at-tribute to its single highest-similarity cluster, we canassign each vector to its N most similar clusters.These soft-cluster assignments often reflect differentsocial groups where a name or location is used.
Forexample, the name yasmeen is similar to both com-mon American names (Cluster 56), African Ameri-can names (Cluster 104), and Arabic names (Clus-ter 132) (Table 4).
As another example, the C1000assignments for the location trujillo comprise sep-arate clusters containing towns and cities in Peru,Venezuela, Colombia, etc., reflecting the variousplaces in the Latin world with this name.
In general,the soft cluster assignment is a low-dimensional rep-resentation of each of our attributes.
Although it canbe interpretable to humans, it need not be in order tobe useful to a classifier.4 Classification with Cluster FeaturesOur motivating problem is to classify users for hid-den properties such as their gender, location, race,ethnicity, and language.
We adopt a discriminativesolution.
We encode the relevant data for each in-stance in a feature vector and train a (linear) supportvector machine classifier (Cortes and Vapnik, 1995).SVMs represent the state-of-the-art on many NLPclassification tasks, but other classifiers could alsobe used.
For multi-class classification, we use a one-versus-all strategy, a competitive approach on mostmulti-class problems (Rifkin and Klautau, 2004).The input to our system is one or more observeduser attributes (e.g.
name and location fields froma user profile).
We now describe how features arecreated from these attributes in both state-of-the-artsystems and via our new cluster data.Token Features (Tok) are binary features that in-dicate the presence of a specific attribute (e.g., first-name=bob).
Burger et al(2011) and Bergsma et al(2012) used Tok features to encode user profile fea-tures.
For multi-token fields (e.g.
location), our Tokfeatures also indicate the specific position of eachtoken (e.g., loc1=s?o, loc2=paulo, locN=brasil).Character N-gram Features (Ngm) give thecount of all character n-grams of length 1-to-4 in theinput.
Ngm features have been used in user classifi-cation (Burger et al 2011) and represent the state-1013of-the-art in detecting name ethnicity (Bhargava andKondrak, 2010).
We add special begin/end charac-ters to the attributes to mark the prefix and suffix po-sitions.
We also use a smoothed log-count; we foundthis to be most effective in preliminary work.Cluster Features (Clus) indicate the soft-clustermemberships of the attributes.
We have features forthe top-2, 5, and 20 most similar clusters in the C50,C200, and C1000 clusterings, respectively.
Like Linand Wu (2009), we ?side-step the matter of choos-ing the optimal value k in k-means?
by using fea-tures from clusterings at different granularities.
Ourfeature dimensions correspond to cluster IDs; fea-ture values give the similarity to the cluster centroid.Other strategies (e.g.
hard clustering, binary fea-tures) were less effective in preliminary work.5 Classification Experiments5.1 MethodologyOur main objective is to assess the value of us-ing cluster features (Clus).
We add these featuresto classifiers using Tok+Ngm features, which repre-sents the current state-of-the-art.
We compare thesefeature settings on both Twitter tasks (?5.2) andtasks not related to social-media (?5.3).
For eachtask, we randomly divide the gold standard data into50% train, 25% development and 25% test, unlessotherwise noted.
As noted above, the gold-standarddatasets for all of our experiments are available fordownload.
We train our SVM classifiers using theLIBLINEAR package (Fan et al 2008).
We optimizethe classifier?s regularization parameter on develop-ment data, and report our final results on the held-out test examples.
We report accuracy: the propor-tion of test examples classified correctly.
For com-parison, we report the accuracy of a majority-classbaseline on each task (Base).Classifying hidden properties of social mediausers is challenging (Table 5).
Pennacchiotti andPopescu (2011) even conclude that ?profile fields donot contain enough good-quality information to bedirectly used for user classification.?
To provide in-sight into the difficulty of the tasks, we had two hu-mans annotate 120 examples from each of the testsets, and we average their results to give a ?Human?performance number.
The two humans are experts inCountry: 53 possible countriesUnited States courtland dante cali babyUnited States tinas twin on the courtBrazil thamires gomez macap?
apDenmark marte clason NONELang.
ID: 9 confusable languagesBulgarian valentina getova NONERussian borisenko yana edinburghBulgarian NONE blagoevgradUkrainian andriy kupyna ternopilFarsi kambiz barahouei NONEUrdu musadiq sanwal jammuEthnicity: 13 European ethnicitiesGerman dennis hustadtDutch bernhard hofstedeFrench david costeSwedish mattias bjarsmyrPortuguese helder costaRace: black or whiteblack kerry swainblack darrell foskeywhite ty j laroccablack james n joneswhite sean p farrellTable 5: Examples of class (left) and input (names, loca-tions) for some of our evaluation tasks.this domain and have very wide knowledge of globalnames and locations.5.2 Twitter ApplicationsCountry A number of recent papers have consid-ered the task of predicting the geolocation of users,using both user content (Cheng et al 2010; Eisen-stein et al 2010; Hecht et al 2011; Wing andBaldridge, 2011; Roller et al 2012) and social net-work (Backstrom et al 2010; Sadilek et al 2012).Here, we first predict user location at the level ofthe user?s location country.
To our knowledge, weare the first to exploit user locations and names forthis prediction.
For this task, we obtain gold datafrom the portion of Twitter users who have GPS en-abled (geocoded tweets).
We were able to obtain avery large number of gold instances for this task, soselected only 10K for testing, 10K for development,and retained the remaining 782K for training.Language ID Identifying the language of usersis an important prerequisite for building language-specific social media resources (Tromp and Pech-1014enizkiy, 2011; Carter et al 2013).
Bergsma et al(2012) recently released a corpus of tweets markedfor one of nine languages grouped into three confus-able character sets: Arabic, Farsi, and Urdu tweetswritten in Arabic characters; Hindi, Nepali, andMarathi written in Devanagari, and Russian, Bulgar-ian, and Ukrainian written in Cyrillic.
The tweetswere marked for language by native speakers viaAmazon Mechanical Turk.
We again discard thetweet content and extract each user?s first name, lastname, and user location as our input data, while tak-ing the annotated language as the class label.Gender We predict whether a Twitter user is maleor female using data from Burger et al(2011).
Thisdata was created by linking Twitter users to struc-tured profile pages on other websites where usersmust select their gender.
Unlike prior systems usingthis data (Burger et al 2011; Van Durme, 2012), wemake the predictions using only user names.5.3 Other ApplicationsOrigin Knowing the origin of a name can improveits automatic pronunciation (Llitjos and Black,2001) and transliteration (Bhargava and Kondrak,2010).
We evaluate our cluster data on name-originprediction using a corpus of names marked as ei-ther Indian or non-Indian by Bhargava and Kondrak(2010).
Since names in this corpus are not markedfor entity type, we include separate cluster featuresfrom both our first and last name clusters.Ethnicity We also evaluate on name-origin datafrom Konstantopoulos (2007).
This data derivesfrom lists of football players on European nationalteams; it marks each name (with diacritics removed)as arising from one of 13 European languages.
Fol-lowing prior work, we test in two settings: (1) usinglast names only, and (2) using first and last names.Race We also evaluate our ability to identify eth-nic groups at a sub-national level.
To obtain datafor this task, we mined the publicly-available arrestrecords on mugshots.com for the U.S. state of NewJersey (a small but diverse and densely-populatedarea).
Over 99% of users were listed as either blackor white, and we structure the task as a binary clas-sification problem between these two classes.
Wepredict the race of each person based purely on theirname; this contrasts with prior work in social mediawhich looked at identifying African Americans onthe basis of their Twitter content (Eisenstein et al2011; Pennacchiotti and Popescu, 2011).6 Classification ResultsTable 6 gives the results on each task.
The system in-corporating our novel Clus features consistently im-proves over the Ngm+Tok system; all differences be-tween All and Ngm+Tok are significant (McNemar?s,p<0.01).
The relative reduction in error from addingClus features ranges between 7% and 51%.
The Allsystem including Clus features also exceeds humanperformance on all studied tasks.On Country, the U.S. is the majority class, oc-curring in 42.5% of cases.3 It is impressive thatAll so significantly exceeds Tok+Ngm (86.7% vs.84.8%); with 782K training examples, we did notexpect such room for improvement.
Both names andlocations play an important role: All achieves 66%using names alone and 70% with only location.
Onthe subset of data where all three attributes are non-empty, the full system achieves 93% accuracy.Both feature classes are likewise important forLang.
ID; All achieves 67% with only first+lastnames, 72% with just locations, but 83% with both.Our smallest improvement is on Gender.
Thistask is easier (with higher human/system accuracy)and has plenty of training data (more data per classthan any other task); there is thus less room to im-prove.
Looking at the feature weights, the strongest-weighted female cluster apparently captures a sub-community of Justin Bieber fans (showing loyaltywith ?first names?
jbieber, belieb, biebz, beliebing,jbiebs, etc.).
Just because a first name like madisonhas a high similarity to this cluster does not implygirls named Madison are Justin Bieber fans; it sim-ply means that Madisons have similar names to thefriends of Justin Bieber fans (who tend to be girls).Also, note that while the majority of the 34K users inour training data are assigned this cluster somewherein their soft clustering, only 6 would be assigned this3We tried other baselines: e.g., we predict countries if theyare substrings of the location (otherwise predicting U.S.); andwe predict countries if they often occur as a string followingthe given location in our profile data (e.g., we predict Spain forMadrid since Madrid, Spain is common).
Variations on theseapproaches consistently performed between 48% and 56%.1015Task InputNum.
Num.Base Human Tok Ngm ClusTok+All ?Train Class NgmCountry first+last+loc 781920 53 42.5 71.7 83.0 84.5 80.2 84.8 86.7 12.5Lang.
ID first+last+loc 2492 9 27.0 74.2 74.6 80.6 71.1 80.4 82.7 11.7Gender first+last 33805 2 52.4 88.3 85.3 88.6 79.5 89.5 90.2 6.7Origin entity name 500 2 52.4 80.4 - 75.6 81.2 75.6 88.0 50.8Ethnicity last 6026 13 20.8 47.9 - 54.6 48.5 54.6 62.4 17.2Ethnicity first+last 7457 13 21.2 53.3 67.6 77.5 73.6 78.4 81.3 13.4Race first+last 7977 2 54.7 71.4 80.4 81.6 84.6 82.4 84.6 12.5Table 6: Task details and accuracy (%) for attribute-based classification tasks.
?
= relative error reduction (%) of All(Tok+Ngm+Clus) over Ngm+Tok.
All always exceeds both Tok+Ngm and the human performance.cluster in a hard clustering.
This clearly illustratesthe value of the soft clustering representation.Note the All system performed between 83% and90% on each Twitter task.
This level of performancestrongly refutes the prevailing notion that Twitterprofile information is useless in general (Pennac-chiotti and Popescu, 2011) and especially for geolo-cation (Cheng et al 2010; Hecht et al 2011).We now move to applications beyond social me-dia.
Bhargava and Kondrak (2010) have the currentstate-of-the-art on Origin and Ethnicity based on anSVM using character-n-gram features; we reimple-mented this as Ngm.
We obtain a huge improvementover their work using Clus, especially on Originwhere we reduce error by >50%.4 This improve-ment can partly be attributed to the small amount oftraining data; with fewer parameters to learn, Cluslearns more from limited data than Ngm.
We like-wise see large improvements over the state-of-the-art on Ethnicity, on both last name and full namesettings.Finally, Clus features also significantly improveaccuracy on the new Race task.
Our cluster data cantherefore help to classify names into sub-nationalgroups, and could potentially be used to infer otherinteresting communities such as castes in India andreligious divisions in many countries.In general, the relative value of our cluster modelsvaries with the amount of training data; we see hugegains on the smaller Origin data but smaller gainson the large Gender set.
Figure 1 shows how per-formance of Clus and Ngm varies with training dataon Race.
Again, Clus is especially helpful with less4Note Tok is not used here because the input is a single tokenand training and test splits have distinct instances.60657075808510  100  1000  10000AccuracyNumber of training examplesClusNgmFigure 1: Learning curve on Race: Clus perform as wellwith 30 training examples as Ngm features do with 1000.data; thousands of training examples are needed forNgm to rival the performance of Clus using only ahandful.
Since labeled data is generally expensiveto obtain or in short supply, our method for exploit-ing unlabeled Twitter data can both save money andimprove top-end performance.7 Geolocation by AssociationThere is a tradition in computational linguistics ofgrouping words both by the similarity of their con-text vectors (Hindle, 1990; Pereira et al 1993; Lin,1998) and directly by their statistical association intext (Church and Hanks, 1990; Brown et al 1992).While the previous sections explored clusters builtby vector similarity, we now explore a direct appli-cation of our attribute association data (?2).We wish to use this data to improve an existingTwitter geolocation system based on user profile lo-cations.
The system operates as follows: 1) normal-1016ize user-provided locations using a set of regular ex-pressions (e.g.
remove extra spacing, punctuation);2) look up the normalized location in an alias list;3) if found, map the alias to a unique string (targetlocation), corresponding to a structured location ob-ject that includes geo-coordinates.The alias list we are currently using is based onextensive work in hand-writing aliases for the mostpopular Twitter locations.
For example, the currentaliases for Nashville, Tennessee include nashville,nashville tn, music city, etc.
Our objective is to im-prove on this human-designed list by automaticallygenerating aliases using our association data.Aliases by Association For each target, we pro-pose new aliases from the target?s top-PMI asso-ciates (?2).
To become an alias, the PMI betweenthe alias and target must be above a threshold,the alias must occur more than a fixed number oftimes in our profile data, the alias must be withinthe top-N1 associates of the target, and the targetmust be within the top-N2 associates of the alias.We merge our automatic aliases with the manually-written aliases.
The new aliases for Nashville, Ten-nessee include east nashville, nashville tenn, musiccity usa, nashvegas, cashville tn, etc.Experiments To evaluate the geolocation system,we use tweets from users with GPS enabled (?5.2).For each tweet, we resolve the location using thesystem and compare to the gold coordinates.
Thesystem can skip a location if it does not match thealias list; more than half of the locations are skipped,which is consistent with prior work (Hecht et al2011).
We evaluate the alias lists using two mea-sures: (1) its coverage: the percentage of locations itresolves, and (2) its precision: of the ones resolved,the percentage that are correct.
We define a correctresolution to be one where the resolved coordinatesare within 50 miles of the gold coordinates.We use 56K gold tweets to tune the parameters ofour automatic alias-generator, trading off coverageand precision.
We tune such that the system usingthese aliases obtains the highest possible coverage,while being at least as precise as the baseline system.We then evaluate both the baseline set of aliases andour new set on 56K held-out examples.Results On held-out test data, the geolocation sys-tem using baseline aliases has a coverage of 38.7%and a precision of 59.5%.
Meanwhile, the systemusing the new aliases has a coverage of 44.6% anda precision of 59.4%.
With virtually the same pre-cision, the new aliases are thus able to resolve 15%more users.
This provides an immediate benefit toour existing Twitter research efforts.Note that our alias lists can be viewed as clus-ters of locations.
In ongoing work, we are exploringtechniques based on discriminative learning to inferalias lists using not only Clus information but alsoNgm and Tok features as in the previous sections.8 Related WorkIn both real-world and online social networks, ?peo-ple socialize with people who are like them in termsof gender, sexual orientation, age, race, education,and religion?
(Jernigan and Mistree, 2009).
So-cial media research has exploited this for two mainpurposes: (1) to predict friendships based on userproperties, and (2) to predict user properties basedon friendships.
Friendship prediction systems (e.g.Facebook?s friend suggestion tool) use features suchas whether both people are computer science ma-jors (Taskar et al 2003) or whether both are at thesame location (Crandall et al 2010; Sadilek et al2012).
The inverse problem has been explored in theprediction of a user?s location given the location oftheir peers (Backstrom et al 2010; Cho et al 2011;Sadilek et al 2012).
Jernigan and Mistree (2009)predict a user?s sexuality based on the sexuality oftheir Facebook friends, while Garera and Yarowsky(2009) predict a user?s gender partly based on thegender of their conversational partner.
Jha and El-hadad (2010) predict the cancer stage of users ofan online cancer discussion board; they derive com-plementary information for prediction from both thetext a user generates and the cancer stage of the peo-ple that a user interacts with.The idea of clustering data in order to provide fea-tures for supervised systems has been successfullyexplored in a range of NLP tasks, including named-entity-recognition (Miller et al 2004; Lin and Wu,2009; Ratinov and Roth, 2009), syntactic chunking(Turian et al 2010), and dependency parsing (Kooet al 2008; T?ckstr?m et al 2012).
In each case,1017the clusters are derived from the distribution of thewords or phrases in text, not from their communica-tion pattern.
It would be interesting to see whetherprior distributional clusters can be combined withour communication-based clusters to achieve evenbetter performance.
Indeed, there is evidence thatfeatures derived from text can improve the predic-tion of name ethnicity (Pervouchine et al 2010).There has been an explosion of work in recentyears in predicting user properties in social net-works.
Aside from the work mentioned above thatanalyzes a user?s social network, a large amountof work has focused on inferring user propertiesbased on the content they generate (e.g.
Burgerand Henderson (2006), Schler et al(2006), Raoet al(2010), Mukherjee and Liu (2010), Pennac-chiotti and Popescu (2011), Burger et al(2011), VanDurme (2012)).9 Conclusion and Future WorkWe presented a highly effective and readily repli-cable algorithm for generating language resourcesfrom Twitter communication patterns.
We clustereduser attributes based on both the communication ofusers with those attributes as well as substring sim-ilarity.
Systems using our clusters significantly out-perform state-of-the-art algorithms on each of thetasks investigated, and exceed human performanceon each task as well.
The power and versatility ofour clusters is exemplified by the fact we reduce er-ror by a larger margin on each of the non-Twittertasks than on any Twitter task itself.Twitter provides a remarkably large sample andeffectively a partial census of much of the world?spopulation, with associated metadata, descriptivecontent and sentiment information.
Our ability toaccurately assign numerous often unspecified prop-erties such as race, gender, language and ethnicity tosuch a large user sample substantially increases thesociological insights and correlations one can derivefrom such data.ReferencesLars Backstrom, Eric Sun, and Cameron Marlow.
2010.Find me if you can: improving geographical predic-tion with social and spatial proximity.
In Proc.
WWW,pages 61?70.Shane Bergsma, Paul McNamee, Mossaab Bagdouri,Clayton Fink, and Theresa Wilson.
2012.
Languageidentification for creating language-specific Twittercollections.
In Proceedings of the Second Workshopon Language in Social Media, pages 65?74.Aditya Bhargava and Grzegorz Kondrak.
2010.
Lan-guage identification of names with SVMs.
In Proc.HLT-NAACL, pages 693?696.Peter F. Brown, Vincent J. Della Pietra, Peter V. de Souza,Jennifer C. Lai, and Robert L. Mercer.
1992.
Class-based n-gram models of natural language.
Computa-tional Linguistics, 18(4):467?479.John D. Burger and John C. Henderson.
2006.
An ex-ploration of observable features related to blogger age.In Proc.
AAAI Spring Symposium: Computational Ap-proaches to Analyzing Weblogs, pages 15?20.John D. Burger, John Henderson, George Kim, and GuidoZarrella.
2011.
Discriminating gender on Twitter.
InProc.
EMNLP, pages 1301?1309.Simon Carter, Wouter Weerkamp, and Manos Tsagkias.2013.
Microblog Language Identification: Overcom-ing the Limitations of Short, Unedited and IdiomaticText.
Language Resources and Evaluation Journal.
(forthcoming).Zhiyuan Cheng, James Caverlee, and Kyumin Lee.
2010.You are where you tweet: a content-based approachto geo-locating Twitter users.
In Proc.
CIKM, pages759?768.Eunjoon Cho, Seth A. Myers, and Jure Leskovec.
2011.Friendship and mobility: user movement in location-based social networks.
In Proc.
KDD, pages 1082?1090.Kenneth W. Church and Patrick Hanks.
1990.
Word as-sociation norms, mutual information, and lexicogra-phy.
Computational Linguistics, 16(1):22?29.Corinna Cortes and Vladimir Vapnik.
1995.
Support-vector networks.
Mach.
Learn., 20(3):273?297.David J. Crandall, Lars Backstrom, Dan Cosley, Sid-dharth Suri, Daniel Huttenlocher, and Jon Kleinberg.2010.
Inferring social ties from geographic coinci-dences.
Proceedings of the National Academy of Sci-ences, 107(52):22436?22441.Jeffrey Dean and Sanjay Ghemawat.
2008.
MapReduce:simplified data processing on large clusters.
Commun.ACM, 51(1):107?113.Inderjit S. Dhillon and Dharmendra S. Modha.
2001.Concept decompositions for large sparse text data us-ing clustering.
Mach.
Learn., 42(1-2):143?175.Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,and Eric P. Xing.
2010.
A latent variable model forgeographic lexical variation.
In Proc.
EMNLP, pages1277?1287.1018Jacob Eisenstein, Noah A. Smith, and Eric P. Xing.
2011.Discovering sociolinguistic associations with struc-tured sparsity.
In Proc.
ACL, pages 1365?1374.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A li-brary for large linear classification.
J. Mach.
Learn.Res., 9:1871?1874.Nikesh Garera and David Yarowsky.
2009.
Modeling la-tent biographic attributes in conversational genres.
InProc.
ACL-IJCNLP, pages 710?718.Brent Hecht, Lichan Hong, Bongwon Suh, and Ed H. Chi.2011.
Tweets from Justin Bieber?s heart: the dynamicsof the location field in user profiles.
In Proc.
CHI,pages 237?246.Donald Hindle.
1990.
Noun classification frompredicate-argument structures.
In Proc.
ACL, pages268?275.Carter Jernigan and Behram F. T. Mistree.
2009.
Gaydar:Facebook friendships expose sexual orientation.
FirstMonday, 14(10).
[Online].Mukund Jha and Noemie Elhadad.
2010.
Cancer stageprediction based on patient online discourse.
In Proc.2010 Workshop on Biomedical Natural Language Pro-cessing, pages 64?71.Stasinos Konstantopoulos.
2007.
What?s in a name?
InProc.
Computational Phonology Workshop, RANLP.Terry Koo, Xavier Carreras, and Michael Collins.
2008.Simple semi-supervised dependency parsing.
In Proc.ACL-08: HLT, pages 595?603.Dekang Lin and Xiaoyun Wu.
2009.
Phrase clusteringfor discriminative learning.
In Proc.
ACL-IJCNLP,pages 1030?
?1038.Dekang Lin.
1998.
Automatic retrieval and clustering ofsimilar words.
In Proc.
Coling-ACL, pages 768?774.Ariadna Font Llitjos and Alan W. Black.
2001.
Knowl-edge of language origin improves pronunciation accu-racy of proper names.
In Proceedings of EuroSpeech-01, pages 1919?1922.Scott Miller, Jethran Guinness, and Alex Zamanian.2004.
Name tagging with word clusters and discrimi-native training.
In Proc.
HLT-NAACL, pages 337?342.Arjun Mukherjee and Bing Liu.
2010.
Improving genderclassification of blog authors.
In Proc.
EMNLP, pages207?217.Brendan O?Connor, Ramnath Balasubramanyan,Bryan R. Routledge, and Noah A. Smith.
2010.From tweets to polls: Linking text sentiment to publicopinion time series.
In Proc.
ICWSM, pages 122?129.Michael Paul and Mark Dredze.
2011.
You are what youtweet: Analyzing Twitter for public health.
In Proc.ICWSM, pages 265?272.Marco Pennacchiotti and Ana-Maria Popescu.
2011.
Amachine learning approach to Twitter user classifica-tion.
In Proc.
ICWSM, pages 281?288.Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993.Distributional clustering of English words.
In Proc.ACL, pages 183?190.Vladimir Pervouchine, Min Zhang, Ming Liu, andHaizhou Li.
2010.
Improving name origin recogni-tion with context features and unlabelled data.
In Col-ing 2010: Posters, pages 972?978.Delip Rao, David Yarowsky, Abhishek Shreevats, andManaswi Gupta.
2010.
Classifying latent user at-tributes in Twitter.
In Proc.
International Workshop onSearch and Mining User-Generated Contents, pages37?44.Lev Ratinov and Dan Roth.
2009.
Design challenges andmisconceptions in named entity recognition.
In Proc.CoNLL, pages 147?155.Ryan Rifkin and Aldebaro Klautau.
2004.
In defense ofone-vs-all classification.
J. Mach.
Learn.
Res., 5:101?141.Stephen Roller, Michael Speriosu, Sarat Rallapalli, Ben-jamin Wing, and Jason Baldridge.
2012.
Supervisedtext-based geolocation using language models on anadaptive grid.
In Proc.
EMNLP-CoNLL, pages 1500?1510.Adam Sadilek, Henry Kautz, and Jeffrey P. Bigham.2012.
Finding your friends and following them towhere you are.
In Proc.
WSDM, pages 723?732.Jonathan Schler, Moshe Koppel, Shlomo Argamon, andJames W. Pennebaker.
2006.
Effects of age andgender on blogging.
In Proc.
AAAI Spring Sympo-sium: Computational Approaches to Analyzing We-blogs, pages 199?205.Oscar T?ckstr?m, Ryan McDonald, and Jakob Uszkoreit.2012.
Cross-lingual word clusters for direct transferof linguistic structure.
In Proc.
NAACL-HLT, pages477?487.Ben Taskar, Ming-Fai Wong, Pieter Abbeel, and DaphneKoller.
2003.
Link prediction in relational data.
InProc.
NIPS, volume 15.Erik Tromp and Mykola Pechenizkiy.
2011.
Graph-based n-gram language identication on short texts.
InProc.
20th Machine Learning conference of Belgiumand The Netherlands, pages 27?34.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: A simple and general methodfor semi-supervised learning.
In Proc.
ACL, pages384?394.Benjamin Van Durme.
2012.
Streaming analysis of dis-course participants.
In Proc.
EMNLP-CoNLL, pages48?58.Benjamin Wing and Jason Baldridge.
2011.
Simple su-pervised document geolocation with geodesic grids.In Proc.
ACL, pages 955?964.1019
