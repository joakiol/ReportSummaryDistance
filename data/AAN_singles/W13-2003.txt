Proceedings of the BioNLP Shared Task 2013 Workshop, pages 16?25,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsTEES 2.1: Automated Annotation Scheme Learning in the BioNLP 2013Shared TaskJari Bjo?rne and Tapio SalakoskiDepartment of Information Technology, University of TurkuTurku Centre for Computer Science (TUCS)Joukahaisenkatu 3-5, 20520 Turku, Finlandfirstname.lastname@utu.fiAbstractWe participate in the BioNLP 2013 SharedTask with Turku Event Extraction System(TEES) version 2.1.
TEES is a supportvector machine (SVM) based text miningsystem for the extraction of events and re-lations from natural language texts.
In ver-sion 2.1 we introduce an automated an-notation scheme learning system, whichderives task-specific event rules and con-straints from the training data, and usesthese to automatically adapt the systemfor new corpora with no additional pro-gramming required.
TEES 2.1 is shown tohave good generalizability and good per-formance across the BioNLP 2013 taskcorpora, achieving first place in four outof eight tasks.1 IntroductionBiomedical event extraction concerns the detec-tion of statements of biological relations from sci-entific texts.
Events are a formalism for accu-rately annotating the content of any natural lan-guage sentence.
They are characterized by typed,directed arguments, annotated trigger words andthe ability to nest other events as arguments, lead-ing to flexible, complex structures.
Compared tothe more straightforward approach of binary rela-tion extraction, the aim of event extraction is toutilize the added complexity to more accuratelydepict the content of natural language statementsand to produce more detailed text mining results.The BioNLP Shared Task is the primary forumfor international evaluation of different event ex-traction technologies.
Organized for the first timein 2009, it has since been held in 2011 and now in2013 (Kim et al 2009; Kim et al 2011).
Startingfrom the single GENIA corpus on NF-kB, it hassince been extended to varied domain tasks, suchas epigenetics and bacteria-host interactions.
Thetheme of the 2013 task is ?knowledge base con-struction?, defining several domain tasks relevantfor different aspects of this overall goal.The Turku Event Extraction System (TEES)1is a generalized biomedical text mining tool, de-veloped at University of Turku and characterizedby the use of a unified graph representation anda stepwise machine learning approach based onsupport vector machines (SVM).
TEES has partic-ipated in all BioNLP Shared Tasks, achieving firstplace in 2009, first place in four out of eight tasksin 2011 and now in 2013 again first place in fourout of eight tasks (Bjo?rne et al 2011; Bjo?rne etal., 2012).
It has been available as an open sourceproject since 2009, and has also been used by otherresearch groups (Jamieson et al 2012; Neves etal., 2013).The BioNLP Shared Tasks have recorded theprogress of various event extraction approaches.Where TEES 1.0 achieved an F-score of 51.95%in 2009, in 2011 the best performing system byteam FAUST on the extended, but similar GENIAtask achieved an F-score of 56.0% (Riedel et al2011).
Interesting approaches have been demon-strated also in the interim of the Shared Tasks, forexample with the EventMine system of Miwa etal.
(2010) achieving an F-score of 56.00% on the2009 GENIA corpus, and with the extremely com-putationally efficient system of Bui et al(2012)based on automatically learning extraction rulesfrom event templates.
The GENIA task of 2013has been considerably extended and the scope ofthe corpus is different, so a direct comparison withthe earlier GENIA tasks is not possible.In the BioNLP 2013 Shared Task the goal of theTEES project is to continue the generalization ofevent extraction techniques introduced in 2011 byfully automating task-specific adaptation via auto-1http://jbjorne.github.com/TEES/16mated learning of event annotation rules.
As anopen source project TEES should also be easilyapplicable by any team interested in this task, soTEES 2.1 analyses were provided for all interestedparticipants during the system development phaseof the competition.2 Methods2.1 Turku Event Extraction System 2.1TEES is a machine-learning based tool for extract-ing text-bound graphs from natural language arti-cles.
It represents both binary relations and eventswith a unified graph format where named entitiesand triggers are nodes and relations and event ar-guments are edges.
This representation is com-monly stored in the ?interaction XML?
format, anextensible XML representation applicable to var-ious corpora (Bjo?rne et al 2012; Pyysalo et al2008; Segura-Bedmar et al 2013).TEES approaches event extraction as a classi-fication task, breaking the complex graph genera-tion task into smaller steps that can be performedwith multiclass classification.
The SVMmulticlasssupport vector machine2 (Tsochantaridis et al2005) with a linear kernel is used as the classifierin all machine learning steps.To start with the BioNLP Shared Task, TEESconversion tools are used to convert the sharedtask format (txt/a1/a2) corpora into the interac-tion XML format.
Equivalence annotations are re-solved into independent events in the process.Figure 1 shows an overview of the TEES eventextraction process.
In real-world applications, ex-ternal programs are used to split sentences, de-tect protein/gene named entities and parse text,but in the BioNLP Shared Tasks these analysesare provided by the organizers.
As in previousShared Tasks, we used the tokenisations and theMcCCJ parses converted into the collapsed CC-processed Stanford dependency scheme (Stene-torp et al 2013; McClosky, 2010).With the preprocessing done, TEES uses threeprimary processing steps to detect events.
First,event trigger words are detected by classifyingeach non-named entity token into one of the trig-ger classes or as a negative.
Then, for each(optionally directed) pair of named entity andtrigger nodes a relation/argument edge candidate2http://svmlight.joachims.org/svm_multiclass.htmlRegulationNN NN VB NN CC .conj_and><nn dobj><nsubj NNProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .Cause>Cause><ThemeunmergingDCEedge detectiontrigger detectionBAdobj>parsingProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .<Theme Cause> Cause>ProteinSTAT3 Phosphorylationphosphorylation Regulationinvolve ProteinVav and ProteinRac-1 .ProteinSTAT3 phosphorylation involve ProteinVav and ProteinRac-1 .STAT3 phosphorylation involve Vav and Rac-1 .Ser(727) mayNNappos> <auxVBSer(727) maySer(727) maySer(727) maySer(727) mayEntity<ParentEntityEntity<Theme<Theme<ThemeRegulationProteinSTAT3 Phosphorylationphosphorylation involve ProteinVav and ProteinRac-1 .Cause>Cause><Themespeculation and negation detectionFSer(727) mayEntity<Theme<ThemeRegulationSpecSpec<Site<Parent <Site<Parent <SiteFigure 1: TEES event extraction process.
Prepro-cessing steps A?C are achieved in the shared taskwith data provided by organizers.
Event extractionsteps D?F are all performed as consecutive, inde-pendent SVM classification steps.
(Adapted fromBjo?rne et.
al (2012).
)is generated and classified into one of the rela-tion/argument classes or as a negative.
Finally, foreach event trigger node, for each valid set of out-going argument edges an unmerging example isgenerated and classified as a true event or not, sep-arating overlapping events into structurally validones.
For tasks where events can have modifiers, afinal modifier detection step can be performed.
Tobetter fit the trigger detection step into the overalltask, a recall adjustment parameter is experimen-tally determined to increase the amount of triggersgenerated before edges are detected.
The featurerepresentations and basic approach of the systemare largely unchanged from the 2011 entry, and fora more detailed overview we refer to Bjo?rne et.
al(2012).The main change in TEES 2.1, described in thispaper, is the automated annotation scheme learn-ing system, which enables the optimal use of thesystem on any interaction XML format corpus.This preprocessing step results in an annotationscheme definition which is used throughout themachine learning steps and the impact of whichis described in detail in the following sections.172.2 Automated Annotation Scheme LearningIn previous versions of TEES, task specific rulesneeded to be defined in code.
The most impor-tant of these were the event annotation schemes ofeach task, which define the type and number of ar-guments that are valid for each event type.
Thislimited straightforward application of TEES onlyto corpora that were part of the shared tasks.
InTEES 2.1, the event scheme rules and constraintsare learned automatically.
All event types and ar-gument combinations seen in the known trainingdata are considered valid for the current task.
Theresult of this analysis for the GE (GENIA) task isshown in Table 1.The automatically generated annotation schemeanalysis lists all entities, events, relations andmodifiers detected in the corpus.
Entities are sim-ply a type of node and relations can be directed orundirected but are always defined as a single edgeconnecting two nodes.
Events consist of a triggernode whose type is equal to the type of the eventitself and a set of arguments, for which are definedalso valid argument counts.The interaction XML graph format representsboth event arguments and binary relations as edgeelements.
To distinguish these annotations, a pre-requisite for automated detection of valid eventstructures, elements that are part of events are la-beled as such in the TEES 2.1 interaction XMLgraph.
Those node and argument types that arenot annotated also for the test set become the pre-diction targets, and the rest of the annotation canbe used as known data to help in predicting them.The annotation scheme analysis is stored in theTEES model file/directory, is available at runtimevia a class interface and is used in the machinelearning steps to enforce task-specific constraints.The availability of the learned annotation schemeimpacts mostly the edge and unmerging detectors.2.3 TEES 2.1 Edge DetectionThe primary task specific specialization requiredin TEES 2.0 was the set of rules defining validnode combinations for edges.
TEES detects edges(relations or arguments) by defining one edge can-didate for each directed (or undirected) pair ofnodes.
While the system could be used withouttask-specific specialization to generate edge candi-dates for all pairs, due to the potentially large num-ber of nodes in event-containing sentences thisapproach led to an inflated amount of negativesand reduced SVM performance.
In the BioNLPShared Task, e.g.
the common Protein entities canonly ever have incoming edges, so even such asimple limitation could considerably reduce theamount of edge candidates, but these task-specificrules had to be written into the Python-code.
Withthe automatically learned annotation scheme, theedge detector checks for each node pair whether itconstitutes a valid edge candidate as learned fromthe training data, automating and generalizing thistask-specific optimization.2.4 TEES 2.1 UnmergingThe TEES module most affected by the learnedannotation scheme is the unmerging detector,which takes the merged event graph (where over-lapping events share the same trigger node) andattempts to define which node/argument combina-tions constitute valid events (See Figure 1 E).
Oneexample is generated for each potential event, andnodes and edges are duplicated as needed for thoseclassified as positives.
In TEES 2.0, only the GE(GENIA), EPI (Epigenetics and Post-translationalModifications) and ID (Infectious Diseases) tasksfrom 2009 and 2011 were supported, with validargument combinations defined in the code.
InTEES 2.1 invalid argument combinations, as de-termined by the learned annotation scheme, areautomatically removed before classification.
Evenif an event is structurally valid, it may of coursenot be a correct event, but reducing the number ofnegatives by removing invalid ones is an impor-tant optimization step also in the case of unmerg-ing classification.2.5 Unified site-argument representationRepresenting the BioNLP Shared Task site-arguments in the interaction XML format has beenproblematic.
The sites are arguments of argu-ments, linking a separate site-entity to a primaryargument.
In the graph format all arguments areedges, and while technically all edges could bedefined as having a central node to which site-arguments could connect, this would result ina multi-step edge detection system, where site-argument edges could only be predicted after pri-mary argument edges are predicted.
To avoid thissituation, in TEES 2.0 site arguments were definedas edges connecting the site entity either to theprotein node (See Figure 2 A) or to the triggernode (See Figure 2 B).
The second case was themost straightforward, and we assume closest to the18ProteinSTAT3PhosphorylationphosphorylationA: TEES 2.0 main representationSer(727)Entity<Site<ThemeB: TEES 2.0 EPI representationProteinSTAT3PhosphorylationphosphorylationSer(727)Entity<Site<ThemeProteinSTAT3PhosphorylationphosphorylationSer(727)Entity<Site<ThemeC: TEES 2.1 Unified representation<SiteParentFigure 2: A unified representation (C) is intro-duced for site-arguments, replacing the differ-ent TEES 2.0 representations and enabling site-arguments to be processed as any other event ar-guments.syntactic structure, as demonstrated by the goodperformance on the 2011 EPI task (Bjo?rne et al2012).
However, in tasks where events can havemultiple primary arguments, the approach shownin Fig.
2 B becomes problematic, as a primary/siteargument pair cannot be determined unambigu-ously.
In the approach shown in Fig.
2 A, the con-nection between the event and the site argument isindirect, meaning that the TEES 2.1 automated an-notation scheme learning system cannot determinevalid site argument constraints for events.In TEES 2.1 this problem is solved with a uni-fied approach where regardless of task, the sitearguments are comparable to primary argumentedges in all aspects, enabling consistent eventanalysis and simplifying site argument processing(See Figure 2 C).
Additional SiteParent edges aredefined to connect the entity and the protein it be-longs to.
In ambiguous cases, these are used toconnect the right site to the right primary argumentwhen converting to the final Shared Task format.2.6 Validating final predictionsThe current implementation of the automated an-notation scheme learning system in TEES 2.1has a shortcoming occasionally resulting in in-valid event structures being produced.
Consideran event with multiple optional arguments, such asCell differentiation from the CG task with 0?1 At-Loc arguments and 0?1 Theme arguments.
Whileit can be possible that such an event can exist with-out any arguments at all, it is often the case thatat least one of the optional arguments must bepresent.
This is not detected by the current system,and would require the addition of learning rules forsuch groups of mandatory arguments.The result of this and other small limitations inconforming to task rules is the occasional invalidpredicted event.
The Shared Task test set evalua-tion servers will not accept any invalid events, sothese errors had to be resolved in some way.
Asthis problem was detected at a late stage in theshared task, there was no more time to fix the un-derlying causes.
However, these errors could noteither be fixed by looking at the test set and cor-recting the events preventing the acceptance of thesubmission, as that would result in de facto man-ual annotation of the test set and an informationleak.
Therefore, we never looked at the documenttriggering the error, and used the following, con-sistent approach to resolve the invalid events.
Ifthe server would both report an invalid argumentand a missing argument for the same event, theinvalid argument was first replaced with the miss-ing one.
This was only the case with the GRNtask.
If the server would only report an invalidargument, we first removed the argument, and ifthis did not resolve the conflict, we removed theentire event.
Following this, all events recursivelypointing to removed invalid events were also re-moved.
This approach could be implemented witha system processing the validation tools?
output,but the better approach which we aim to pursue isto fix the limitations of the automated annotationscheme learning system, thus producing a tool us-able on any corpora.
In practice only a few invalidevents were produced for each task where they oc-curred, so the impact on performance is likely tobe negligible.2.7 Public datasetTEES 2.0, published in summer 2012 was a po-tentially useful tool for the BioNLP 2013 SharedTask, but at the same time required specific codeextensions to be adapted for the task, leading to asituation where the program was available, but wasnot likely to be of practical value with new cor-pora.
To resolve this problem the automated anno-tation scheme learning system was developed, tak-ing the generalization approaches developed forthe 2011 task and making them automatically ap-plicable for new corpora.
As using TEES can still19be difficult for people not familiar with the system,and as re-training the program is quite time con-suming, we also published our event predictionsfor the 2013 task during the system developmentperiod, for other teams to make use of.
Develop-ment set analyses were made available on Febru-ary 26th, and test set analyses during the test pe-riod on April 13th.
With only a few downloads,the data did not enjoy wide popularity, and dueto the complexity of the tasks utilizing the data inother systems could very well have been too timeconsuming.
TEES was also used to produce publicanalyses for the DDIExtraction 2013 Shared Task,where the data was used more, maybe due to eas-ier integration into a binary relation extraction task(Segura-Bedmar et al 2013; Bjo?rne et al 2013).3 Tasks and ResultsTEES 2.1 could be applied as is to almost all the2013 tasks with no task specific development re-quired.
Only subtask 1 of the Bacteria Biotopestask, concerning the assignment of ontology con-cepts, falls outside the scope of the current sys-tem.
TEES 2.1 was the system to participatein most tasks, with good general performance,demonstrating the utility of abstracting away task-specific details.
Official results for each task areshown in Table 2 and system performance relativeto other entries in Figure 3.Task # R P F SERGE 2/10 46.17 56.32 50.74CG 1/6 48.76 64.17 55.41PC 2/2 47.15 55.78 51.10GRO 1/1 15.22 36.58 21.50GRN 3/5 33 78 46 0.86BBT1 0/4BBT2 1/4 28 82 42BBT3 1/2 12 18 14Table 2: Official test set results for the BioNLP2013 tasks.
Performance is shown in (R)ecall,(P)recision and (F)-score, and also SER for theGRN task.
BB task 1 falls outside the scope ofTEES 2.1.
Rank is indicated by #.3.1 GENIA (GE)The GENIA task is the central task of the BioNLPShared Task series, having been organized in allthree Shared Tasks.
It has also enjoyed the largestnumber of contributions and as such could beGE CG PC GRO GRN BBT2 BBT3 BBT1Task020406080100F-score / SER *100Figure 3: Performance of the systems participat-ing in the BioNLP?13 Shared Task.
Our resultsare marked with black dots.
Please note that theperformance metric for tasks GRN and BBT1 isSER*100, where a smaller score is better.viewed as the primary task for testing differentevent extraction approaches.
In 2013 the GE-NIA task annotation has been considerably ex-tended and the coreference annotation that in 2011formed its own supporting task is integrated in themain GENIA corpus (Kim et al 2013a).The GENIA task is a good example for demon-strating the usefulness of automatically learningthe event annotation scheme.
The task uses 11different event types, pairwise binary coreferencerelations and modality annotation for both specu-lation and negation.
Previous versions of TEESwould have encoded all of this information in theprogram, but with TEES 2.1 the annotation rulesare detected automatically and stored in a sep-arate datafile external to the program.
Table 1shows the automatically learned event scheme.
Itshould however be noted that while the learnedscheme accurately describes the known annota-tion, it may not exactly correspond to the corpusannotation rules.
For example, the Binding event,when learned from the data, can have one or twoTheme arguments, when in the official rules it sim-ply has one or more Theme arguments.In some GENIA Coreference relations (45 outof 338 in train and devel data) at least one of theendpoints is an event trigger.
While such rela-tions could indeed be linked to event trigger nodes,TEES makes no distinction between triggers andevents and would link them to the event annotationwhen converting back to the Shared Task format,20so we chose to skip them.TEES 2.1 achieved a performance of 50.74%,placing second in the GENIA task.
The first placewas reached by team EVEX (Hakala et al 2013),with a system that utilizes the publicly availableTEES 2.1 program.
This result further highlightsthe value of open sourcing scientific code and un-derlines the importance of incorporating existingsolutions into future systems.3.2 Cancer Genetics (CG)The CG task is a domain-specific event extrac-tion task targeting the recovery of information re-lated to cancer (Pyysalo et al 2013; Pyysalo etal., 2012).
It is characterized by a large numberof entity and event types.
Despite a heterogeneousannotation scheme, TEES 2.1 achieved a perfor-mance of 55.41% F-score, placing first in this task.On some event categories TEES achieved a per-formance notably higher than usual for it in eventextraction tasks, such as the 77.20% F-score forthe Anatomy-group events.
The impact of morecommon, and as such more easily detected classeson the micro-averaged F-score is certainly impor-tant, but it is interesting to speculate that maybethe very detailed annotation scheme led to a morefocused and thus more consistent annotation, mak-ing machine learning easier on this task.3.3 Pathway Curation (PC)The PC task aims to produce events suitable forpathway curation (Ohta et al 2013).
Its extrac-tion targets are based on existing pathway modelsand ontologies such as the Systems Biology On-tology (SBO).
The dataset has only a few entitytypes, but similar to the CG task, a large numberof event types.
With 51.10% F-score TEES 2.1placed second, behind team NaCTeM by 1.74 per-centage points (Miwa and Ananiadou, 2013).
Onthe CG task team NaCTeM placed second, 3.32percentage points lower than TEES 2.1.
Even withthe only two participants in the PC task havingvery close performance, compared to the resultsof the same teams on the CG task, we speculatethe PC and CG tasks are of similar complexity.3.4 Gene Regulation Ontology (GRO)The GRO task concerns the automatic annota-tion of documents with Gene Regulation Ontol-ogy (GRO) concepts (Kim et al 2013b).
The an-notation is very detailed, with 145 entity and 81event types.
This results in a large number of smallclasses which are independent in SVM classifica-tion and thus hard to learn.
TEES did not detectmost of the small classes, and generally, the largerthe class, the higher the performance.
It is possiblethat classification performance might be improvedby merging some of the smaller classes and disam-biguating the predictions with a rule-based step,similar to the TEES approach in the EPI 2011 task.Overall performance was at 21.50% F-score butas TEES 2.1 was the only system in this task, notmany conclusions can be drawn from it.
However,the system was also exactly the same as appliedin the other tasks.
With decent performance onsome of the larger classes, we speculate that witha larger training corpus, and with a system adaptedfor the GRO task, performance comparable to theGE, CG and PC tasks could be reached.3.5 Gene Regulation Network (GRN)GRN is a task where event extraction is utilized asan optional, intermediate step in the constructionof a large regulation network (Bossy et al 2013a).The annotation consists of 11 entity types, 12 bi-nary relation types and a single Action event type.The predicted events can be automatically con-verted to the regulation network, or the networkcan be produced by other means.
In either case,the final evaluation is performed on the network,using the Slot Error Rate (SER) metric (Makhoulet al 1999), where lower is better and a value ofless than one is expected for decent predictions.TEES 2.1 produced the event format submis-sion, and with conversion to the regulation net-work achieved an SER of 0.86, placing in the mid-dle of the five teams, all of which had an SER ofless than one.
A downloadable evaluator programwas provided early enough in the development pe-riod to be integrated in TEES 2.1, allowing directoptimization against the official task metrics.
AsSER was a metric not used before with TEES, therelaxed F-score was instead chosen as the opti-mization target, with the assumption that it wouldprovide a predictable result also on the hidden testset.
In training it was also observed that the param-eters for the optimal relaxed F-score also producedthe optimal SER result.3.6 Bacteria Biotopes (BB)Along with the GENIA task, the BB task is theonly task to continue from earlier BioNLP SharedTasks.
The BB task concerns the detection ofstatements about bacteria habitats and relevant en-21vironmental properties and is divided into threesubtasks (Bossy et al 2013b).In task 1 the goal is to detect boundaries of bac-teria habitat entities and for each entity, assign oneor more terms from 1700 concepts in the Onto-Biotope ontology.
While the TEES entity detectorcould be used to detect the entities, assigning thetypes falls outside the scope of the system, and isnot directly approachable as the sort of classifica-tion task used in TEES.
Therefore, BB task 1 wasthe only task for which TEES 2.1 was not applied.BB tasks 2 and 3 are a direct continuation ofthe 2011 BB task, with the goal being extractionof relations between bacteria entities and habitatand geographical places entities.
Only three entityand two relation types are used in the annotation.In task 2 all entities are provided and only rela-tions are detected, in task 3 also the entities mustbe predicted.
The BB task was the only 2013 taskin which we used (limited) task specific resources,as TEES 2.0 resources developed for the 2011 BBtask were directly applicable to the 2013 tasks.
Adictionary of bacteria name tokens, derived fromthe List of Prokaryotic names with Standing inNomenclature3 (Euze?by, 1997) was used to im-prove entity detection performance.
Unlike the2011 task, WordNet features were not used.TEES 2.1 achieved F-scores of 42% and 14%for tasks 2 and 3 respectively, reaching first placein both tasks.
The low overall performance is how-ever indicative of the complexity of these tasks.4 ConclusionsWe applied TEES version 2.1 to the BioNLP 2013Shared Task.
An automated annotation schemelearning system was built to speed up developmentand enable application of the system to novel eventcorpora.
The system could be used as is in al-most all BioNLP 2013 tasks, achieving good over-all performance, including several first places.The GRO task highlighted the limitations of apurely classification based approach in situationswith very many small classes, in a sense the sameissue as with the ontology concept application inBB task 1.
Despite these minor limitations, thebasic stepwise SVM based approach of TEES con-tinues to demonstrate good generalization abilityand high performance.We made our system public during the task de-velopment phase and provided precalculated anal-3http://www.bacterio.cict.fr/yses to all participants.
While we consider it un-fortunate that these analyses did not enjoy greaterpopularity, we are also looking forward to the var-ied approaches and methods developed by the par-ticipating teams.
However, the encouraging re-sults of the GENIA task, not to mention earlierpositive reports on system combination (Kano etal., 2011; Riedel et al 2011) indicate that there isuntapped potential in merging together the strongpoints of various systems.TEES 2.1 had very good performance on manytasks, but it must be considered that as an es-tablished system it was already capable of do-ing much of the basic processing that many otherteams had to develop for their approaches.
Inparticular, previous BioNLP Shared Tasks haveshown that the TEES internal micro-averagededge-detection F-score provides a very good ap-proximation of the official metrics of most tasks.It is unfortunate that official evaluator programswere only available in some tasks, and often onlyat the end of the development period, potentiallyleading to a situation where different teams wereoptimizing for different goals.
In our opinion itis of paramount importance that in shared tasksnot only the official evaluation metric is knownwell ahead of time, but a downloadable evalua-tor program is provided, as the complexity of thetasks means that independent implementations ofthe evaluation metric are error prone and an un-necessary burden on the participating teams.As with previous versions of TEES, the 2.1 ver-sion is publicly available both as a downloadableprogram and as a full, open source code repository.We intend to continue developing TEES, and willhopefully in the near future improve the automatedannotation learning system to overcome its cur-rent limitations.
We find the results of the BioNLP2013 Shared Task encouraging, but as with previ-ous iterations, note that there is still a long wayto go for truly reliable text mining.
We thinkmore novel approaches, better machine learningsystems and careful utilization of the research sofar will likely lead the field of biomedical eventextraction forward.AcknowledgmentsWe thank CSC ?
IT Center for Science Ltd,Espoo, Finland for providing computational re-sources.22Type Name ArgumentsENTITY AnaphoraENTITY EntityENTITY ProteinEVENT Binding Site[0,1](Entity) / Theme[1,2](Protein)EVENT Gene expression Theme[1,1](Protein)EVENT Localization Theme[1,1](Protein) / ToLoc[0,1](Entity)EVENT Negative regulation Cause[0,1](Acetylation, Binding, Gene expression, Negative regulation, Phospho-rylation, Positive regulation, Protein, Protein catabolism, Regulation, Ubiquitina-tion) / Site[0,1](Entity) / Theme[1,1](Binding, Gene expression, Localization, Neg-ative regulation, Phosphorylation, Positive regulation, Protein, Protein catabolism,Regulation, Transcription, Ubiquitination)EVENT Phosphorylation Cause[0,1](Protein) / Site[0,1](Entity) / Theme[1,1](Protein)EVENT Positive regulation Cause[0,1](Acetylation, Binding, Gene expression, Negative regulation, Phospho-rylation, Positive regulation, Protein, Protein catabolism, Regulation, Ubiquitina-tion) / Site[0,1](Entity) / Theme[1,1](Binding, Deacetylation, Gene expression, Lo-calization, Negative regulation, Phosphorylation, Positive regulation, Protein, Pro-tein catabolism, Protein modification, Regulation, Transcription, Ubiquitination)EVENT Protein catabolism Theme[1,1](Protein)EVENT Protein modification Theme[1,1](Protein)EVENT Regulation Cause[0,1](Binding, Gene expression, Localization, Negative regulation, Phos-phorylation, Positive regulation, Protein, Protein modification, Regulation) /Site[0,1](Entity) / Theme[1,1](Binding, Gene expression, Localization, Nega-tive regulation, Phosphorylation, Positive regulation, Protein, Protein catabolism,Protein modification, Regulation, Transcription)EVENT Transcription Theme[1,1](Protein)EVENT Ubiquitination Cause[0,1](Protein) / Theme[1,1](Protein)RELATION Coreference, directed Subject(Anaphora) / Object(Anaphora, Entity, Protein)RELATION SiteParent, directed Arg1(Entity) / Arg2(Protein)MODIFIER negation Binding, Gene expression, Localization, Negative regulation, Phosphorylation,Positive regulation, Protein catabolism, Regulation, TranscriptionMODIFIER speculation Binding, Gene expression, Localization, Negative regulation, Phosphorylation,Positive regulation, Protein catabolism, Regulation, Transcription, UbiquitinationTARGET ENTITY Acetylation, Anaphora, Binding, Deacetylation, Entity, Gene expression,Localization, Negative regulation, Phosphorylation, Positive regulation, Pro-tein catabolism, Protein modification, Regulation, Transcription, UbiquitinationTARGET INTERACTION Cause, Coreference, Site, SiteParent, Theme, ToLocTable 1: Automatically learned GENIA 2013 task event annotation scheme.
The entities are the nodesof the graph.
Targets define the types of nodes and edges to be automatically extracted.
Events andrelations are defined by their type and arguments.
Relations are optionally directed, and always have twoarguments, with specific valid target node types.
Events can have multiple arguments, and in additionto valid target node types, the minimum and maximum amount of each argument per event are defined.Modifiers are binary attributes defined by their type and the types of nodes they can be defined for.23ReferencesJari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2011.
Ex-tracting Contextualized Complex Biological Eventswith Rich Graph-Based Feature Sets.
Computa-tional Intelligence, Special issue on Extracting Bio-molecular Events from Literature.
Accepted in2009.Jari Bjo?rne, Filip Ginter, and Tapio Salakoski.
2012.University of Turku in the BioNLP?11 Shared Task.BMC Bioinformatics, 13(Suppl 11):S4.Jari Bjo?rne, Suwisa Kaewphan, and Tapio Salakoski.2013.
UTurku: Drug Named Entity Detection andDrug-drug Interaction Extraction Using SVM Clas-sification and Domain Knowledge.
In Proceedingsof the 7th International Workshop on Semantic Eval-uation (SemEval 2013).Robert Bossy, Philippe Bessir`es, and Claire Ne?dellec.2013a.
BioNLP shared task 2013 - an overview ofthe genic regulation network task.
In Proceedingsof BioNLP Shared Task 2013 Workshop, Sofia, Bul-garia, August.
Association for Computational Lin-guistics.Robert Bossy, Wiktoria Golik, Zorana Ratkovic,Philippe Bessir`es, and Claire Ne?dellec.
2013b.BioNLP shared task 2013 - an overview of the bac-teria biotope task.
In Proceedings of BioNLP SharedTask 2013 Workshop, Sofia, Bulgaria, August.
Asso-ciation for Computational Linguistics.Quoc-Chinh Bui and Peter M.A.
Sloot.
2012.
A robustapproach to extract biomedical events from litera-ture.
Bioinformatics, 28(20):2654?2661, October.Jean Paul Marie Euze?by.
1997.
List of BacterialNames with Standing in Nomenclature: a FolderAvailable on the Internet.
Int J Syst Bacteriol,47(2):590?592.Kai Hakala, Sofie Van Landeghem, Tapio Salakoski,Yves Van de Peer, and Filip Ginter.
2013.
EVEXin ST?13: Application of a large-scale text miningresource to event extraction and network construc-tion.
In Proceedings of BioNLP Shared Task 2013Workshop, Sofia, Bulgaria, August.
Association forComputational Linguistics.Daniel G. Jamieson, Martin Gerner, Farzaneh Sarafraz,Goran Nenadic, and David L. Robertson.
2012.Towards semi-automated curation: using text min-ing to recreate the hiv-1, human protein interactiondatabase.
Database, 2012.Yoshinobu Kano, Jari Bjo?rne, Filip Ginter, TapioSalakoski, Ekaterina Buyko, Udo Hahn, K Bre-tonnel Cohen, Karin Verspoor, Christophe Roeder,Lawrence Hunter, Halil Kilicoglu, Sabine Bergler,Sofie Van Landeghem, Thomas Van Parys, YvesVan de Peer, Makoto Miwa, Sophia Ananiadou,Mariana Neves, Alberto Pascual-Montano, Arzu-can Ozgur, Dragomir Radev, Sebastian Riedel,Rune Saetre, Hong-Woo Chun, Jin-Dong Kim,Sampo Pyysalo, Tomoko Ohta, and Jun?ichi Tsujii.2011.
U-compare bio-event meta-service: compati-ble bionlp event extraction services.
BMC Bioinfor-matics, 12(1):481.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overviewof BioNLP?09 Shared Task on Event Extraction.
InProceedings of the BioNLP 2009 Workshop Com-panion Volume for Shared Task, pages 1?9, Boulder,Colorado.
ACL.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, and Jun?ichi Tsujii.
2011.
Overview ofBioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Associationfor Computational Linguistics.Jin-Dong Kim, Yue Wang, and Yamamoto Yasunori.2013a.
The genia event extraction shared task,2013 edition - overview.
In Proceedings of BioNLPShared Task 2013 Workshop, Sofia, Bulgaria, Au-gust.
Association for Computational Linguistics.Jung-Jae Kim, Xu Han, Vivian Lee, and DietrichRebholz-Schuhmann.
2013b.
GRO task: Populat-ing the gene regulation ontology with events and re-lations.
In Proceedings of BioNLP Shared Task 2013Workshop, Sofia, Bulgaria, August.
Association forComputational Linguistics.John Makhoul, Francis Kubala, Richard Schwartz, andRalph Weischedel.
1999.
Performance measures forinformation extraction.
In Proceedings of DARPABroadcast News Workshop, pages 249?252.David McClosky.
2010.
Any domain parsing: auto-matic domain adaptation for natural language pars-ing.
Ph.D. thesis, Department of Computer Science,Brown University.Makoto Miwa and Sophia Ananiadou.
2013.
NaCTeMEventMine for BioNLP 2013 CG and PC tasks.
InProceedings of BioNLP Shared Task 2013 Work-shop, Sofia, Bulgaria, August.
Association for Com-putational Linguistics.Makoto Miwa, Sampo Pyysalo, Tadayoshi Hara, andJun?ichi Tsujii.
2010.
A comparative study ofsyntactic parsers for event extraction.
In Proceed-ings of the 2010 Workshop on Biomedical NaturalLanguage Processing, BioNLP ?10, pages 37?45,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Mariana Neves, Alexander Damaschun, NancyMah, Fritz Lekschas, Stefanie Seltmann, HaraldStachelscheid, Jean-Fred Fontaine, Andreas Kurtz,and Ulf Leser.
2013.
Preliminary evaluation ofthe cellfinder literature curation pipeline for geneexpression in kidney cells and anatomical parts.Database, 2013.24Tomoko Ohta, Sampo Pyysalo, Rafal Rak, AndrewRowley, Hong-Woo Chun, Sung-Jae Jung, Sung-PilChoi, and Sophia Ananiadou.
2013.
Overview ofthe pathway curation (PC) task of bioNLP sharedtask 2013.
In Proceedings of BioNLP Shared Task2013 Workshop, Sofia, Bulgaria, August.
Associa-tion for Computational Linguistics.Sampo Pyysalo, Antti Airola, Juho Heimonen, JariBjo?rne, Filip Ginter, and Tapio Salakoski.
2008.Comparative analysis of five protein-protein interac-tion corpora.
BMC Bioinformatics, 9(Suppl 3):S6.Sampo Pyysalo, Tomoko Ohta, Makoto Miwa, Han-Cheol Cho, Jun?ichi Tsujii, and Sophia Ananiadou.2012.
Event extraction across multiple levels of bi-ological organization.
Bioinformatics, 28(18):i575?i581.Sampo Pyysalo, Tomoko Ohta, and Sophia Ananiadou.2013.
Overview of the cancer genetics (CG) taskof bioNLP shared task 2013.
In Proceedings ofBioNLP Shared Task 2013 Workshop, Sofia, Bul-garia, August.
Association for Computational Lin-guistics.Sebastian Riedel, David McClosky, Mihai Surdeanu,Andrew McCallum, and Christopher D. Manning.2011.
Model combination for event extraction inbionlp 2011.
In Proceedings of the BioNLP SharedTask 2011 Workshop, BioNLP Shared Task ?11,pages 51?55, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Isabel Segura-Bedmar, Paloma Mart?
?nez, and MariaHerrero-Zazo.
2013.
SemEval-2013 Task 9: Ex-traction of Drug-Drug Interactions from BiomedicalTexts.
In Proceedings of the 7th International Work-shop on Semantic Evaluation (SemEval 2013).Pontus Stenetorp, Wiktoria Golik, Thierry Hamon,Donald C. Comeau, Rezarta Islamaj Dogan, HaibinLiu, and W. John Wilbur.
2013.
BioNLP sharedtask 2013: Supporting resources.
In Proceedingsof BioNLP Shared Task 2013 Workshop, Sofia, Bul-garia, August.
Association for Computational Lin-guistics.Ioannis Tsochantaridis, Thorsten Joachims, ThomasHofmann, and Yasemin Altun.
2005.
Large marginmethods for structured and interdependent outputvariables.
Journal of Machine Learning Research(JMLR), 6(Sep):1453?1484.25
