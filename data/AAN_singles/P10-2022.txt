Proceedings of the ACL 2010 Conference Short Papers, pages 120?125,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsEvent-based Hyperspace Analogue to Language for Query ExpansionTingxu YanTianjin UniversityTianjin, Chinasunriser2008@gmail.comTamsin MaxwellUniversity of EdinburghEdinburgh, United Kingdomt.maxwell@ed.ac.ukDawei SongRobert Gordon UniversityAberdeen, United Kingdomd.song@rgu.ac.ukYuexian HouTianjin UniversityTianjin, Chinayxhou@tju.edu.cnPeng ZhangRobert Gordon UniversityAberdeen, United Kingdom.p.zhang1@rgu.ac.ukAbstractBag-of-words approaches to informationretrieval (IR) are effective but assume in-dependence between words.
The Hy-perspace Analogue to Language (HAL)is a cognitively motivated and validatedsemantic space model that captures sta-tistical dependencies between words byconsidering their co-occurrences in a sur-rounding window of text.
HAL has beensuccessfully applied to query expansion inIR, but has several limitations, includinghigh processing cost and use of distribu-tional statistics that do not exploit syn-tax.
In this paper, we pursue two methodsfor incorporating syntactic-semantic infor-mation from textual ?events?
into HAL.We build the HAL space directly fromevents to investigate whether processingcosts can be reduced through more carefuldefinition of word co-occurrence, and im-prove the quality of the pseudo-relevancefeedback by applying event informationas a constraint during HAL construction.Both methods significantly improve per-formance results in comparison with orig-inal HAL, and interpolation of HAL andrelevance model expansion outperformseither method alone.1 IntroductionDespite its intuitive appeal, the incorporation oflinguistic and semantic word dependencies in IRhas not been shown to significantly improve overa bigram language modeling approach (Song andCroft, 1999) that encodes word dependencies as-sumed from mere syntactic adjacency.
Both thedependence language model for IR (Gao et al,2004), which incorporates linguistic relations be-tween non-adjacent words while limiting the gen-eration of meaningless phrases, and the MarkovRandom Field (MRF) model, which captures shortand long range term dependencies (Metzler andCroft, 2005; Metzler and Croft, 2007), con-sistently outperform a unigram language mod-elling approach but are closely approximated bya bigram language model that uses no linguis-tic knowledge.
Improving retrieval performancethrough application of semantic and syntactic in-formation beyond proximity and co-occurrencefeatures is a difficult task but remains a tantalisingprospect.Our approach is like that of Gao et al (2004)in that it considers semantic-syntactically deter-mined relationships between words at the sentencelevel, but allows words to have more than onerole, such as predicate and argument for differ-ent events, while link grammar (Sleator and Tem-perley, 1991) dictates that a word can only sat-isfy one connector in a disjunctive set.
Comparedto the MRF model, our approach is unsupervisedwhere MRFs require the training of parameters us-ing relevance judgments that are often unavailablein practical conditions.Other work incorporating syntactic and linguis-tic information into IR includes early research by(Smeaton, O?Donnell and Kelledy, 1995), whoemployed tree structured analytics (TSAs) resem-bling dependency trees, the use of syntax to de-tect paraphrases for question answering (QA) (Linand Pantel, 2001), and semantic role labelling inQA (Shen and Lapata, 2007).Independent from IR, Pado and Lapata (2007)proposed a general framework for the construc-tion of a semantic space endowed with syntactic120information.
This was represented by an undi-rected graph, where nodes stood for words, de-pendency edges stood for syntactical relations, andsequences of dependency edges formed paths thatwere weighted for each target word.
Our work isin line with Pado and Lapata (2007) in construct-ing a semantic space with syntactic information,but builds our space from events, states and attri-butions as defined linguistically by Bach (1986).We call these simply events, and extract them auto-matically from predicate-argument structures anda dependency parse.
We will use this space to per-form query expansion in IR, a task that aims to findadditional words related to original query terms,such that an expanded query including these wordsbetter expresses the information need.
To ourknowledge, the notion of events has not been ap-plied to query expansion before.This paper will outline the original HAL al-gorithm which serves as our baseline, and theevent extraction process.
We then propose twomethods to arm HAL with event information: di-rect construction of HAL from events (eHAL-1),and treating events as constraints on HAL con-struction from the corpus (eHAL-2).
Evaluationwill compare results using original HAL, eHAL-1 and eHAL-2 with a widely used unigram lan-guage model (LM) for IR and a state of the artquery expansion method, namely the RelevanceModel (RM) (Lavrenko and Croft, 2001).
We alsoexplore whether a complementary effect can beachieved by combining HAL-based dependencymodelling with the unigram-based RM.2 HAL ConstructionSemantic space models aim to capture the mean-ings of words using co-occurrence informationin a text corpus.
Two examples are the Hyper-space Analogue to Language (HAL) (Lund andBurgess, 1996), in which a word is representedby a vector of other words co-occurring with itin a sliding window, and Latent Semantic Anal-ysis (LSA) (Deerwester, Dumais, Furnas, Lan-dauer and Harshman, 1990; Landauer, Foltz andLaham, 1998), in which a word is expressed asa vector of documents (or any other syntacti-cal units such as sentences) containing the word.In these semantic spaces, vector-based represen-tations facilitate measurement of similarities be-tween words.
Semantic space models have beenvalidated through various studies and demonstratecompatibility with human information processing.Recently, they have also been applied in IR, suchas LSA for latent semantic indexing, and HAL forquery expansion.
For the purpose of this paper, wefocus on HAL, which encodes word co-occurrenceinformation explicitly and thus can be applied toquery expansion in a straightforward way.HAL is premised on context surrounding a wordproviding important information about its mean-ing (Harris, 1968).
To be specific, an L-sizesliding window moves across a large text corpusword-by-word.
Any two words in the same win-dow are treated as co-occurring with each otherwith a weight that is inversely proportional to theirseparation distance in the text.
By accumulatingco-occurrence information over a corpus, a word-by-word matrix is constructed, a simple illustra-tion of which is given in Table 1.
A single word isrepresented by a row vector and a column vectorthat capture the information before and after theword, respectively.
In some applications, direc-tion sensitivity is ignored to obtain a single vectorrepresentation of a word by adding correspondingrow and column vectors (Bai et al, 2005).w1 w2 w3 w4 w5 w6w1w2 5w3 4 5w4 3 4 5w5 2 3 4 5w6 2 3 4 5Table 1: A HAL space for the text ?w1 w2 w3 w4w5 w6?
using a 5-word sliding window (L = 5).HAL has been successfully applied to query ex-pansion and can be incorporated into this task di-rectly (Bai et al, 2005) or indirectly, as with theInformation Flow method based on HAL (Bruzaand Song, 2002).
However, to date it has usedonly statistical information from co-occurrencepatterns.
We extend HAL to incorporate syntactic-semantic information.3 Event ExtractionPrior to event extraction, predicates, arguments,part of speech (POS) information and syntac-tic dependencies are annotated using the best-performing joint syntactic-semantic parser fromthe CoNNL 2008 Shared Task (Johansson and121Nugues, 2008), trained on PropBank and Nom-Bank data.
The event extraction algorithm theninstantiates the template REL [modREL] Arg0[modArg0] ...ArgN [modArgN], where REL is thepredicate relation (or root verb if no predicatesare identified), and Arg0...ArgN are its arguments.Modifiers (mod) are identified by tracing frompredicate and argument heads along the depen-dency tree.
All predicates are associated with atleast one event unless both Arg0 and Arg1 are notidentified, or the only argument is not a noun.The algorithm checks for modifiers based onPOS tag1, tracing up and down the dependencytree, skipping over prepositions, coordinating con-junctions and words indicating apportionment,such as ?sample (of)?.
However, to constrain out-put the search is limited to a depth of one (withthe exception of skipping).
For example, giventhe phrase ?apples from the store nearby?
and anargument head apples, the first dependent, store,will be extracted but not nearby, which is the de-pendent of store.
This can be detrimental whenencountering compound nouns but does focus oncore information.
For verbs, modal dependents arenot included in output.Available paths up and down the dependencytree are followed until all branches are exhausted,given the rules outlined above.
Tracing can re-sult in multiple extracted events for one predicateand predicates may also appear as arguments ina different event, or be part of argument phrases.For this reason, events are constrained to coveronly detail appearing above subsequent predicatesin the tree, which simplifies the event structure.For example, the sentence ?Baghdad already hasthe facilities to continue producing massive quan-tities of its own biological and chemical weapons?results in the event output: (1) has Baghdad al-ready facilities continue producing; (2) continuequantities producing massive; (3) producing quan-tities massive weapons biological; (4) quantitiesweapons biological massive.4 HAL With Events4.1 eHAL-1: Construction From EventsSince events are extracted from documents, theyform a reduced text corpus from which HAL can1To be specific, the modifiers include negation, as well asadverbs or particles for verbal heads, adjectives and nominalmodifiers for nominal heads, and verbal or nominal depen-dents of modifiers, provided modifiers are not also identifiedas arguments elsewhere in the event.be built in a similar manner to the original HAL.We ignore the parameter of window length (L)and treat every event as a single window of lengthequal to the number of words in the event.
Everypair of words in an event is considered to be co-occurrent with each other.
The weight assigned tothe association between each pair is simply set toone.
With this scheme, all the events are traversedand the event-based HAL is constructed.The advantage of this method is that it sub-stantially reduces the processing time during HALconstruction because only events are involved andthere is no need to calculate weights per occur-rence.
Additional processing time is incurred insemantic role labelling (SRL) during event iden-tification.
However, the naive approach to extrac-tion might be simulated with a combination of lesscostly chunking and dependency parsing, giventhat the word ordering information available withSRL is not utilised.eHAL-1 combines syntactical and statistical in-formation, but has a potential drawback in thatonly events are used during construction so someinformation existing in the co-occurrence patternsof the original text may be lost.
This motivates thesecond method.4.2 eHAL-2: Event-Based FilteringThis method attempts to include more statisticalinformation in eHAL construction.
The key ideais to decide whether a text segment in a corpusshould be used for the HAL construction, basedon how much event information it covers.
Given acorpus of text and the events extracted from it, theeHAL-2 method runs as follows:1.
Select the events of length M or more anddiscard the others for efficiency;2.
Set an ?inclusion criterion?, which decides ifa text segment, defined as a word sequencewithin an L-size sliding window, contains anevent.
For example, if 80% of the words in anevent are contained in a text segment, it couldbe considered to ?include?
the event;3.
Move across the whole corpus word-by-wordwith an L-size sliding window.
For each win-dow, complete Steps 4-7;4.
For the current L-size text segment, checkwhether it includes an event according to the?inclusion criterion?
(Step 2);1225.
If an event is included in the current textsegment, check the following segments fora consecutive sequence of segments that alsoinclude this event.
If the current segment in-cludes more than one event, find the longestsequence of related text segments.
An illus-tration is given in Figure 1 in which darknodes stand for the words in a specific eventand an 80% inclusion criterion is used.TextSegment KSegment K+1Segment K+2Segment K+3Figure 1: Consecutive segments for an event6.
Extract the full span of consecutive segmentsjust identified and go to the next available textsegment.
Repeat Step 3;7.
When the scanning is done, construct HALusing the original HAL method over all ex-tracted sequences.With the guidance of event information, the pro-cedure above keeps only those segments of textthat include at least one event and discards the rest.It makes use of more statistical co-occurrence in-formation than eHAL-1 by applying weights thatare proportional to word separation distance.
Italso alleviates the identified drawback of eHAL-1by using the full text surrounding events.
A trade-off is that not all the events are included by theselected text segments, and thus some syntacticalinformation may be lost.
In addition, the paramet-ric complexity and computational complexity arealso higher than eHAL-1.5 EvaluationWe empirically test whether our event-basedHALs perform better than the original HAL, andstandard LM and RM, using three TREC2 col-lections: AP89 with Topics 1-50 (title field),AP8889 with Topics 101-150 (title field) andWSJ9092 with Topics 201-250 (description field).All the collections are stemmed, and stop wordsare removed, prior to retrieval using the LemurToolkit Version 4.113.
Initial retrieval is iden-tical for all models evaluated: KL-divergence2TREC stands for the Text REtrieval Conference seriesrun by NIST.
Please refer to http://trec.nist.gov/ for details.3Available at http://www.lemurproject.org/based LM smoothed using Dirichlet prior with ?set to 1000 as appropriate for TREC style titlequeries (Lavrenko, 2004).
The top 50 returneddocuments form the basis for all pseudo-relevancefeedback, with other parameters tuned separatelyfor the RM and HAL methods.For each dataset, the number of feedback termsfor each method is selected optimally among 20,40, 60, 804 and the interpolation and smoothingcoefficient is set to be optimal in [0,1] with in-terval 0.1.
For RM, we choose the first relevancemodel in Lavrenko and Croft (2001) with the doc-ument model smoothing parameter optimally setat 0.8.
The number of feedback terms is fixed at60 (for AP89 and WSJ9092) and 80 (for AP8889),and interpolation between the query and relevancemodels is set at 0.7 (for WSJ9092) and 0.9 (forAP89 and AP8889).
The HAL-based query ex-pansion methods add the top 80 expansion termsto the query with interpolation coefficient 0.9 forWSJ9092 and 1 (that is, no interpolation) for AP89and AP8889.
The other HAL-based parametersare set as follows: shortest event length M = 5,for eHAL-2 the ?inclusion criterion?
is 75% ofwords in an event, and for HAL and eHAL-2, win-dow size L = 8.
Top expansion terms are selectedaccording to the formula:PHAL(tj | ?
t) = HAL(tj | ?
q)?tiHAL(ti| ?
q)where HAL(tj |?q) is the weight of tj in the com-bined HAL vector ?q (Bruza and Song, 2002)of original query terms.
Mean Average Precision(MAP) is the performance indicator, and t-test (atthe level of 0.05) is performed to measure the sta-tistical significance of results.Table 2 lists the experimental results5.
It canbe observed that all the three HAL-based queryexpansion methods improve performance over theLM and both eHALs achieve better performancethan original HAL, indicating that the incorpora-tion of event information is beneficial.
In addition,eHAL-2 leads to better performance than eHAL-1, suggesting that use of linguistic information asa constraint on statistical processing, rather thanthe focus of extraction, is a more effective strat-egy.
The results are still short of those achieved4For RM, feedback terms were also tested on larger num-bers up to 1000 but only comparable result was observed.5In Table 2, brackets show percent improvement ofeHALs / RM over HAL / eHAL-2 respectively and * and #indicate the corresponding statistical significance.123Method AP89 AP8889 WSJ9092LM 0.2015 0.2290 0.2242HAL 0.2299 0.2738 0.2346eHAL-1 0.2364 0.2829 0.2409(+2.83%) (+3.32%*) (+2.69%)eHAL-2 0.2427 0.2850 0.2460(+5.57%*) (+4.09%*) (+4.86%*)RM 0.2611 0.3178 0.2676(+7.58%#) (+11.5%#) (+8.78%#)Table 2: Performance (MAP) comparison of queryexpansion using different HALswith RM, but the gap is significantly reduced byincorporating event information here, suggestingthis is a promising line of work.
In addition, asshown in (Bai et al, 2005), the Information Flowmethod built upon the original HAL largely out-performed RM.
We expect that eHAL would pro-vide an even better basis for Information Flow, butthis possibility is yet to be explored.As is known, RM is a pure unigram model whileHAL methods are dependency-based.
They cap-ture different information, hence it is natural toconsider if their strengths might complement eachother in a combined model.
For this purpose, wedesign the following two schemes:1.
Apply RM to the feedback documents (orig-inal RM), the events extracted from thesedocuments (eRM-1), and the text segmentsaround each event (eRM-2), where the threesources are the same as used to produce HAL,eHAL-1 and eHAL-2 respectively;2.
Interpolate the expanded query model byRM with the ones generated by each HAL,represented by HAL+RM, eHAL-1+RM andeHAL-2+RM.
The interpolation coefficient isagain selected to achieve the optimal MAP.The MAP comparison between the original RMand these new models are demonstrated in Ta-ble 36.
From the first three lines (Scheme 1), wecan observe that in most cases the performancegenerally deteriorates when RM is directly runover the events and the text segments.
The eventinformation is more effective to express the infor-mation about the term dependencies while the un-igram RM ignores this information and only takes6For rows in Table 3, brackets show percent differencefrom original RM.Method AP89 AP8889 WSJ9092RM 0.2611 0.3178 0.2676eRM-1 0.2554 0.3150 0.2555(-2.18%) (-0.88%) (-4.52%)eRM-2 0.2605 0.3167 0.2626(-0.23%) (-0.35%) (-1.87%)HAL 0.2640 0.3186 0.2727+RM (+1.11%) (+0.25%) (+1.19%)eHAL-1 0.2600 0.3210 0.2734+RM (-0.42%) (+1.01%) (+2.17%)eHAL-2 0.2636 0.3191 0.2735+RM (+0.96%) (+0.41%) (+2.20%)Table 3: Performance (MAP) comparison of queryexpansion using the combination of RM and termdependenciesthe occurrence frequencies of individual wordsinto account, which is not well-captured by theevents.
In contrast, the performance of Scheme 2is more promising.
The three methods outperformthe original RM in most cases, but the improve-ment is not significant and it is also observed thatthere is little difference shown between RM withHAL and eHALs.
The phenomenon implies moreeffective methods may be invented to complementthe unigram models with the syntactical and sta-tistical dependency information.6 ConclusionsThe application of original HAL to query expan-sion attempted to incorporate statistical word as-sociation information, but did not take into ac-count the syntactical dependencies and had ahigh processing cost.
By utilising syntactic-semantic knowledge from event modelling ofpseudo-relevance feedback documents prior tocomputing the HAL space, we showed that pro-cessing costs might be reduced through more care-ful selection of word co-occurrences and that per-formance may be enhanced by effectively improv-ing the quality of pseudo-relevance feedback doc-uments.
Both methods improved over originalHAL query expansion.
In addition, interpolationof HAL and RM expansion improved results overthose achieved by either method alone.AcknowledgmentsThis research is funded in part by the UK?s Engi-neering and Physical Sciences Research Council,grant number: EP/F014708/2.124ReferencesBach E. The Algebra of Events.
1986.
Linguistics andPhilosophy, 9(1): pp.
5?16.Bai J. and Song D. and Bruza P. and Nie J.-Y.
and CaoG.
Query Expansion using Term Relationships inLanguage Models for Information Retrieval 2005.In: Proceedings of the 14th International ACM Con-ference on Information and Knowledge Manage-ment, pp.
688?695.Bruza P. and Song D. Inferring Query Models by Com-puting Information Flow.
2002.
In: Proceedings ofthe 11th International ACM Conference on Informa-tion and Knowledge Management, pp.
206?269.Deerwester S., Dumais S., Furnas G., Landauer T. andHarshman R. Indexing by latent semantic analysis.1990.
Journal of the American Sociaty for Informa-tion Science, 41(6): pp.
391?407.Gao J. and Nie J. and Wu G. and Cao G. DependenceLanguage Model for Information Retrieval.
2004.In: Proceedings of the 27th Annual InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval, pp.
170?177.Harris Z.
1968.
Mathematical Structures of Lan-guage.. Wiley, New York.Johansson R. and Nugues P. Dependency-basedSyntactic-semantic Analysis with PropBank andNomBank.
2008.
In: CoNLL ?08: Proceedings ofthe Twelfth Conference on Computational NaturalLanguage Learning, pp.
183?187.Landauer T., Foltz P. and Laham D. Introduction to La-tent Semantic Analysis.
1998.
Discourse Processes,25: pp.
259?284.Lavrenko V. 2004.
A Generative Theory of Relevance,PhD thesis, University of Massachusetts, Amherst.Lavrenko V. and Croft W. B. Relevance Based Lan-guage Models.
2001.
In: SIGIR ?01: Proceedingsof the 24th Annual International ACM SIGIR Con-ference on Research and Development in Informa-tion Retrieval, pp.
120?127, New York, NY, USA,2001.
ACM.Lin D. and Pantel P. DIRT - Discovery of InferenceRules from Text.
2001.
In: KDD ?01: Proceedingsof the Seventh ACM SIGKDD International Confer-ence on Knowledge Discovery and Data Mining, pp.323?328, New York, NY, USA.Lund K. and Burgess C. Producing High-dimensionalSemantic Spaces from Lexical Co-occurrence.1996.
Behavior Research Methods, Instruments &Computers, 28: pp.
203?208.
Prentice-Hall, Engle-wood Cliffs, NJ.Metzler D. and Bruce W. B.
A Markov Random FieldModel for Term Dependencies 2005.
In: SIGIR ?05:Proceedings of the 28th annual international ACMSIGIR conference on Research and development ininformation retrieval, pp.
472?479, New York, NY,USA.
ACM.Metzler D. and Bruce W. B.
Latent Concept Expan-sion using Markov Random Fields 2007.
In: SIGIR?07: Proceedings of the 30th Annual InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval, pp.
311?318, ACM,New York, NY, USA.Pado S. and Lapata M. Dependency-Based Construc-tion of Semantic Space Models.
2007.
Computa-tional Linguistics, 33: pp.
161?199.Shen D. and Lapata M. Using Semantic Roles to Im-prove Question Answering.
2007.
In: Proceedingsof the 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pp.
12?21.Sleator D. D. and Temperley D. Parsing English witha Link Grammar 1991.
Technical Report CMU-CS-91-196, Department of Computer Science, CarnegieMellon University.Smeaton A. F., O?Donnell R. and Kelledy F. IndexingStructures Derived from Syntax in TREC-3: SystemDescription.
1995.
In: The Third Text REtrievalConference (TREC-3), pp.
55?67.Song F. and Croft W. B.
A General Language Modelfor Information Retrieval.
1999.
In: CIKM ?99:Proceedings of the Eighth International Confer-ence on Information and Knowledge Management,pp.
316?321, New York, NY, USA, ACM.125
