Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1660?1668,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsEvaluating a City Exploration Dialogue System CombiningQuestion-Answering and Pedestrian NavigationSrinivasan Janarthanam1, Oliver Lemon1, Phil Bartie2, Tiphaine Dalmas2,Anna Dickinson2, Xingkun Liu1, William Mackaness2, and Bonnie Webber21 The Interaction Lab, Heriot-Watt University2 Edinburgh Universitysc445@hw.ac.ukAbstractWe present a city navigation and touristinformation mobile dialogue app with in-tegrated question-answering (QA) and ge-ographic information system (GIS) mod-ules that helps pedestrian users to nav-igate in and learn about urban environ-ments.
In contrast to existing mobile appswhich treat these problems independently,our Android app addresses the prob-lem of navigation and touristic question-answering in an integrated fashion usinga shared dialogue context.
We evaluatedour system in comparison with SamsungS-Voice (which interfaces to Google nav-igation and Google search) with 17 usersand found that users judged our system tobe significantly more interesting to inter-act with and learn from.
They also ratedour system above Google search (with theSamsung S-Voice interface) for tourist in-formation tasks.1 IntroductionWe present a mobile dialogue system (an Androidapp) called Spacebook that addresses the problemof pedestrian navigation and tourist information inurban environments.
There has been little priorwork that addresses these two problems - naviga-tion and tourist information provision - in an inte-grated way.
By navigation, we refer to the prob-lem of finding appropriate destinations to go toand the task of wayfinding to reach them and bytourist information provision we refer to the prob-lem of meeting the informational needs of a userabout entities such as museums, statues and fa-mous personalities.
A dialogue system such as thiscould serve as a personal tour guide to pedestriantourists as they walk around unknown cities.
Withthe proliferation of smartphones, there has been anumber of mobile apps developed to address theseproblems.
However these apps have the followingproblems: first, they demand the user?s visual at-tention because they predominantly present infor-mation on a mobile screen.
This can be dangerousin urban environments, as well as being distract-ing.
Second, these apps address the problems ofnavigation and tourist information independentlyand therefore do not have a shared interaction con-text.
This means that users cannot switch betweeninformation and navigation tasks in a natural andfluid manner.User1: Take me to the National Museum.System2: The National Museum is about 300m away..System3: At the KFC, turn left on to South BridgeSystem4 : Near you is the statue of David Hume.User2: Who is David Hume.System5: David Hume was a Scottish philosopher....User3: Tell me more about David Hume.System6: He was one of the most important figures in..System7: You should be able to see the museum ...User4: Tell me more about the museum.System8: The National Museum of Scotland is a....Table 1: An example interaction with the evalu-ated systemIn contrast to many existing mobile apps,Spacebook has a speech-only interface and ad-dresses both problems in an integrated way.
Weconjecture that with a speech-only interface, userscan immerse themselves in exploring the city,and that because of the shared context they canswitch between navigation and tourist informationtasks more easily.
Using the navigational context,Spacebook pushes point-of-interest informationwhich can then initiate tourist information tasksusing the QA module.
Table 1 presents an exampleinteraction with our system showing the integrateduse of navigation and question-answering capabil-1660ities.
Utterances System4-8 show the system?s ca-pability to push information about nearby points-of-interest (PoI) during a navigation task and an-swer followup questions using the QA system (inutterances User2 and User3).
The final 3 utter-ances show a natural switch between navigation toan entity and QA about that entity.We investigate whether our system using a com-bination of geographical information system (GIS)and natural language processing (NLP) technolo-gies would be a better companion to pedestriancity explorers than the current state-of-the-art mo-bile apps.
We hypothesize that, (1) users will findour speech-only interface to navigation efficient asit allows them to navigate without having to re-peatedly look at a map and (2), that users willfind a dialogue interface which integrates touris-tic question-answering and navigation within ashared context to be useful for finding informationabout entities in the urban environment.
We firstpresent some related work in section 2.
We de-scribe the architecture of the system in section 3.We then present our experimental design, resultsand analysis in sections 5, 6 and 7.2 Related workMobile apps such as Siri, Google Maps Naviga-tion, Sygic, etc.
address the problem of naviga-tion while apps like Triposo, Guidepal, Wikihood,etc.
address the problem of tourist information bypresenting the user with descriptive informationabout various points of interest (PoI) in the city.While some exploratory apps present snippets ofinformation about a precompiled list of PoIs, otherapps dynamically generate a list of PoIs arrangedbased on their proximity to the users.
Users canalso obtain specific information about PoIs usingSearch apps.
Also, since these navigation and ex-ploratory/search apps do not address both prob-lems in an integrated way, users need to switchbetween them and therefore lose interaction con-text.While most apps address these two problemsindependently, some like Google Now, GoogleField Trip, etc, mix navigation with exploration.But such apps present information primarily vi-sually on the screen for the user to read.
Someof these are available for download at the GooglePlay Android app store1.
Several dialogue andnatural language systems have addressed the issue1https://play.google.com/storeof pedestrian navigation (Malaka and Zipf, 2000;Raubal and Winter, 2002; Dale et al, 2003; Bar-tie and Mackaness, 2006; Shroder et al, 2011;Dethlefs and Cuaya?huitl, 2011).
There has alsobeen recent interest in shared tasks for generat-ing navigation instructions in indoor and urban en-vironments (Byron et al, 2007; Janarthanam andLemon, 2011).
Some dialogue systems deal withpresenting information concerning points of inter-est (Ko et al, 2005; Kashioka et al, 2011) and in-teractive question answering (Webb and Webber,2009).In contrast, Spacebook has the objective ofkeeping the user?s cognitive load low and prevent-ing users from being distracted (perhaps danger-ously so) from walking in the city (Kray et al,2003).
Also, it allows users to interleave the twosub-tasks seamlessly and can keep entities dis-cussed in both tasks in shared context (as shownin Table 1).3 ArchitectureThe architecture of the Spacebook system isshown in figure 1.
Our architecture brings to-gether Spoken Dialogue Systems (SDS), Geo-graphic Information Systems (GIS) and Question-Answering (QA) technologies (Janarthanam et al,2012).
Its essentially a spoken dialogue system(SDS) consisting of an automatic speech recog-niser (ASR), a semantic parser, an InteractionManager, an utterance generator and a text-to-speech synthesizer (TTS).
The GIS modules inthis architecture are the City Model, the VisibilityEngine, and the Pedestrian tracker.
Users commu-nicate with the system using a smartphone-basedclient app (an Android app) that sends users?
po-sition, pace rate, and spoken utterances to the sys-tem, and delivers synthesised system utterances tothe user.Figure 1: System Architecture16613.1 Dialogue interfaceThe dialogue interface consists of a speech recog-nition module, an utterance parser, an interactionmanager, an utterance generator and a speech syn-thesizer.
The Nuance 9 speech recogniser witha domain specific language model was used forspeech recognition.
The recognised speech is cur-rently parsed using a rule-based parser into dia-logue acts and semantic content.The Interaction Manager (IM) is the centralcomponent of this architecture, which providesthe user with navigational instructions, pushes PoIinformation and manages QA questions.
It re-ceives the user?s input in the form of a dialogueact (DA), the user?s location (latitude and longi-tude) and pace rate.
Based on these inputs and thedialogue context, it responds with system outputdialogue act, based on a dialogue policy.
The IMinitiates the conversation with a calibration phasewhere the user?s initial location and orientation areobtained.
The user can then initiate tasks that in-terest him/her.
These tasks include searching foran entity (e.g.
a museum or a restaurant), request-ing navigation instructions to a destination, ask-ing questions about the entities in the City Model,and so on.
When the user is mobile, the IM iden-tifies points of interest2 on the route proximal tothe user.
We call this ?PoI push?.
The user is en-couraged to ask for more information if he/she isinterested.
The system also answers adhoc ques-tions from the user (e.g.
?Who is David Hume?
?,?What is the Old College?
?, etc) (see section 3.4).Navigation instructions are given in-situ by ob-serving user?s position continuously, in relationto the next node (street junction) on the currentplanned route, and they are given priority if in con-flict with a PoI push at the same time.
Navigationinstructions use landmarks near route nodes when-ever possible (e.g.
?When you reach ClydesdaleBank , keep walking forward?).
The IM also in-forms when users pass by recognisable landmarks,just to reassure them that they are on track (e.g.
?You will pass by Tesco on the right?).
In additionto navigation instructions, the IM also answersusers?
questions concerning the route, his/her lo-cation, and location of and distance to the variousentities.
Finally, the IM uses the city model?s Vis-ibility Engine (VE) to determine whether the des-tination is visible to the user (see section 3.3).2Using high scoring ones when there are many, based ontourist popularity ratings in the City Model.The shared spatial and dialogue context em-ploys a feature-based representation which is up-dated every 1 second (for location), and after everydialogue turn.
Spatial context such as the user?scoordinates, street names, PoIs and landmarksproximal to the user, etc are used by PoI push-ing and navigation.
The dialogue context main-tains the history of landmarks and PoIs pushed,latest entities mentioned, etc to resolve anaphoricreferences in navigation and QA requests, and todeliver coherent dialogue responses.
The IM re-solves anaphoric references by keeping a recordof entities mentioned in the dialogue context.
Italso engages in clarification sub-dialogues whenthe speech recognition confidence scores are low.The IM stores the name and type information foreach entity (such as landmark, building, etc) men-tioned in navigation instructions and PoI pushes.Subsequent references to these entities using ex-pressions such as ?the museum?, ?the cafe?
etcare resolved by searching for the latest entity ofthe given type.
Pronouns are resolved to the lastmentioned entity.The IM also switches between navigation, PoIpush, and QA tasks in an intelligent manner byusing the shared context to prioritise its utterancesfrom these different tasks.
The utterance genera-tor is a Natural Language Generation module thattranslates the system DA into surface text which isconverted into speech using the Cereproc Text-to-Speech Synthesizer using a Scottish female voice.The only changes made were minor adjustmentsto the pronunciation of certain place names.3.2 Pedestrian trackerUrban environments can be challenging with lim-ited sky views, and hence limited line of sightto satellites, in deep urban corridors.
There istherefore significant uncertainty about the user?strue location reported by GNSS sensors on smart-phones (Zandbergen and Barbeau, 2011).
Thismodule improves on the reported user positionby combining smartphone sensor data (e.g.
ac-celerometer) with map matching techniques, todetermine the most likely location of the pedes-trian (Bartie and Mackaness, 2012).3.3 City ModelThe City Model is a spatial database containinginformation about thousands of entities in the cityof Edinburgh (Bartie and Mackaness, 2013).
Thisdata has been collected from a variety of exist-1662ing resources such as Ordnance Survey, Open-StreetMap, Google Places, and the Gazetteer forScotland.
It includes the location, use class, name,street address, and where relevant other propertiessuch as build date and tourist ratings.
The modelalso includes a pedestrian network (streets, pave-ments, tracks, steps, open spaces) which is usedby an embedded route planner to calculate min-imal cost routes, such as the shortest path.
Thecity model also consists of a Visibility Enginethat identifies the entities that are in the user?svista space (Montello, 1993).
To do this it ac-cesses a digital surface model, sourced from Li-DAR, which is a 2.5D representation of the cityincluding buildings, vegetation, and land surfaceelevation.
The Visibility Engine uses this datasetto offer a number of services, such as determiningthe line of sight from the observer to nominatedpoints (e.g.
which junctions are visible), and de-termining which entities within the city model arevisible.
Using these services, the IM determines ifthe destination is visible or not.3.4 Question-Answering serverThe QA server currently answers a range of def-inition and biographical questions such as, ?Tellme more about the Scottish Parliament?, ?Whowas David Hume?
?, ?What is haggis?
?, and re-quests to resume (eg.
?Tell me more?).
QAis also capable of recognizing out of scope re-quests, that is, either navigation-related questionsthat can be answered by computations from theCity Model and dealt with elsewhere in the sys-tem (?How far away is the Scottish Parliament?
?,?How do I get there??
), or exploration queriesthat cannot be handled yet (?When is the can-non gun fired from the castle??).
Question clas-sification is entirely machine learning-based usingthe SMO algorithm (Keerthi et al, 1999) trainedover 2013 annotated utterances.
Once the questionhas been typed, QA proceeds to focus detectionalso using machine learning techniques (Mikhail-sian et al, 2009).
Detected foci include possi-bly anaphoric expressions (?Who was he?
?, ?Tellme more about the castle?).
These expressionsare resolved against the dialogue history and ge-ographical context.
QA then proceeds to a tex-tual search on texts from the Gazetteer of Scotland(Gittings, 2012) and Wikipedia, and definitionsfrom WordNet glosses.
The task is similar to TACKBP 2013 Entity Linking Track and named en-tity disambiguation (Cucerzan, 2007).
Candidateanswers are reranked using a trained confidencescore with the top candidate used as the final an-swer.
These are usually long, descriptive answersand are provided as a flow of sentence chunks thatthe user can interrupt (see table 2).
The InteractionManager queries the QA model and pushes infor-mation when a salient PoI is in the vicinity of theuser.
?Edinburgh?s most famous and historic thoroughfare,which has formed the heart of the Old Town sincemediaeval times.
The Royal Mile includes Castlehill,the Lawnmarket, the Canongate and the Abbey Strand,but, is officially known simply as the High Street.
?Table 2: QA output: query on ?Royal Mile?3.5 Mobile clientThe mobile client app, installed on an Androidsmartphone (Samsung Galaxy S3), connects theuser to the dialogue system using a 3G data con-nection.
The client senses the user?s location us-ing positioning technology using GNSS satellites(GPS and GLONASS) which is sent to the dia-logue system at the rate of one update every twoseconds.
It also sends pace rate of the user fromthe accelerometer sensor.
In parallel, the clientalso places a phone call using which the user com-municates with the dialogue system.4 Baseline systemThe baseline system chosen for evaluation wasSamsung S-Voice, a state-of-the-art commercialsmartphone speech interface.
S-Voice is a Sam-sung Android mobile phone app that allows a userto use the functionalities of device using a speechinterface.
For example, the user can say ?CallJohn?
and it will dial John from the user?s con-tacts.
It launches the Google Navigation app whenusers request directions and it activates GoogleSearch for open ended touristic information ques-tions.
The Navigation app is capable of providinginstructions in-situ using speech.
We used the S-Voice system for comparison because it providedan integrated state-of-the-art interface to use botha navigation app and also an information-seekingapp using the same speech interface.
Users wereencouraged to use these apps using speech butwere allowed to use the GUI interface when us-ing speech wasn?t working (e.g.
misrecognition oflocal names).
Users obtained the same kind of in-1663formation (i.e.
navigation directions, descriptionsabout entities such as people, places, etc) from thebaseline system as they would from our system.However, our system interacted with the user us-ing the speech modality only.5 Experimental designSpacebook and the baseline were evaluated in thesummer of 2012.
We evaluated both systems with17 subjects in the streets of Edinburgh.
Therewere 11 young subjects (between 20 and 26 years,mean=22 ?
2) and 6 older subjects (between 50and 71 years, mean=61 ?
11).
They were mostlynative English speakers (88%).
59% of the userswere regular smartphone users and their meanoverall time spent in the city was 76 months.
Thetest subjects had no previous experience with theproposed system.
They were recruited via emailadverts and mail shots.
Subjects were given a tasksheet with 8 tasks in two legs (4 tasks per leg).These tasks included both navigation and touristinformation tasks (see table 3).
Subjects used oursystem for one of the legs and the baseline systemfor the other and the order was balanced.
Each legtook up to 30 mins to finish and the total durationincluding questionnaires was about 1.5 hours.
Fig-ure 2 shows the route taken by the subjects.
Theroute is about 1.3 miles long.
Subjects were fol-lowed by the evaluator who made notes on theirbehaviour (e.g.
subject looks confused, subjectlooks at or manipulates the phone, subject looksaround, etc).Subjects filled in a demographic questionnaireprior to the experiment.
After each leg, they filledin a system questionnaire (see appendix) ratingtheir experience.
After the end of the experi-ment, they filled out a comparative questionnaireand were debriefed.
They were optionally askedto elaborate on their questionnaire ratings.
Userswere paid ?20 after the experiment was over.6 ResultsSubjects were asked to identify tasks that theythought were successfully completed.
The per-ceived task success rates of the two systems werecompared for each task using the Chi square test.The results show that there is no statistically sig-nificant difference between the two systems interms of perceived task success although the base-line system had a better task completion rate intasks 1-3, 5 and 6.
Our system performed better inFigure 2: Task routetourist information tasks (4, 7) (see table 4).Task Our system Baseline pT1 (N) 77.7 100 0.5058T2 (TI) 88.8 100 0.9516T3 (N) 100 100 NAT4 (TI) 100 87.5 0.9516T5 (N+TI) 62.5 100 0.1654T6 (N+TI) 87.5 100 0.9516T7 (TI) 100 55.5 0.2926T8 (N) 75.0 88.8 0.9105Table 4: % Perceived Task success - task wisecomparison (N - navigation task, TI - Tourist In-formation task)The system questionnaires that were filled outby users after each leg were analysed.
Theseconsisted of questions concerning each system tobe rated on a six point Likert scale (1-StronglyDisagree, 2-Disagree, 3-Somewhat Disagree, 4-Somewhat Agree, 5-Agree, 6-Strongly Agree).The responses were paired and tested using aWilcoxon Sign Rank test.
Median and Mode foreach system and significance in differences areshown in table 5.
Results show that althoughour system is not performing significantly betterthan the baseline system (SQ1-SQ10 except SQ7),users seem to find it more understanding (SQ7)and more interesting to interact with (SQ11) thanthe baseline.
We grouped the subjects by agegroup and tested their responses.
We found thatthe young subjects (age group 20-26), also felt that1664Leg 1(Task 1) Ask the system to guide you to the Red Fort restaurant.
(Task 2) You?ve heard that Mary Queen of Scots lived in Edinburgh.
Find out about her.
(Task 3) Walk to the university gym.
(Task 4) Near the gym there is an ancient wall with a sign saying ?Flodden Wall?.
Find out what that is.Leg 2(Task 5) Try to find John Knox House and learn about the man.
(Task 6) Ask the system to guide you to the Old College.
What can you learn about this building?
(Task 7) Try to find out more about famous Edinburgh people and places, for example, David Hume,John Napier, and Ian Rankin.
Try to find information about people and places that you are personallyinterested in or that are related to what you see around you.
(Task 8) Ask the system to guide you back to the Informatics Forum.Table 3: Tasks for the userthey learned something new about the city using it(SQ12) (p < 0.05) while the elderly (age group50-71) didn?t.
We also found statistically signifi-cant differences in smartphone users rating for oursystem on their learning compared to the baseline(SQ12).Subjects were also asked to choose between thetwo systems given a number of requirements suchas ease of use, use for navigation, tourist infor-mation, etc.
There was an option to rank the sys-tems equally (i.e.
a tie).
They were presented withthe same requirements as the system questionnairewith one additional question - ?Overall which sys-tem do you prefer??
(CQ0).
Users?
choice of sys-tem based on a variety of requirements is shownin table 6.
Users?
choice counts were tested us-ing Chi-square test.
Significant differences werefound in users?
choice of system for navigationand tourist information requirements.
Users pre-ferred the baseline system for navigation (CQ2)and our system for touristic information (CQ3) onthe city.
Although there was a clear choice of sys-tems based on the two tasks, there was no signifi-cant preference of one system over the other over-all (CQ0).
They chose our system as the most in-teresting system to interact with (CQ11) and thatit was more informative than the baseline (CQ12).Figure 3 shows the relative frequency betweenuser choices on comparative questions.7 AnalysisUsers found it somewhat difficult to navigate usingSpacebook (see comments in table 7).
Althoughthe perceived task success shows that our systemwas able to get the users to their destination andthere was no significant difference between thetwo systems based on their questionnaire responseon navigation, they pointed out a number of issuesand suggested a number of modifications.
ManyFigure 3: Responses to comparative questionsusers noted that a visual map and the directionalarrow in the baseline system was helpful for nav-igation.
In addition, they noted that our system?snavigation instructions were sometimes not satis-factory.
They observed that there weren?t enoughinstructions coming from the system at street junc-tions.
They needed more confirmatory utterances(that they are walking in the right direction) (5users) and quicker recovery and notification whenwalking the wrong way (5 users).
They observedthat the use of street names was confusing some-times.
Some users also wanted a route summarybefore the navigation instructions are given.The problem with Spacebook?s navigation pol-icy was that it did not, for example, direct theuser via easily visible landmarks (e.g.
?Head to-wards the Castle?
), and relies too much on streetnames.
Also, due to the latency in receiving GPSinformation, the IM sometimes did not present in-structions soon enough during evaluation.
Some-times it received erroneous GPS information andtherefore got the user?s orientation wrong.
Theseproblems will be addressed in the future version.Some users did find navigation instructions use-ful because of the use of proximal landmarks such1665Question B Mode B Median S Mode S Median pSQ1 - Ease of use 4 4 5 4 0.8207SQ2 - Navigation 4 4 5 4 0.9039SQ3 - Tourist Information 2 3 4 4 0.07323SQ4 - Easy to understand 5 5 5 5 0.7201SQ5 - Useful messages 5 4 5 4 1SQ6 - Response time 5 5 2 2 0.2283SQ7 - Understanding 3 3 5 4 0.02546SQ8 - Repetitive 2 3 2 3 0.3205SQ9 - Aware of user environment 5 5 4 4 0.9745SQ10 - Cues for guidance 5 5 5 5 0.1371SQ11 - Interesting to interact with 5 4 5 5 0.01799SQ12 - Learned something new 5 4 5 5 0.08942Table 5: System questionnaire responses (B=Baseline, S=our system)Task Baseline Our system Tie p-Preferred Preferred valueCQ0 23.52 35.29 41.17 0.66CQ1 35.29 29.41 35.29 0.9429CQ2 64.70 0 35.29 0.004CQ3 17.64 64.70 17.64 0.0232CQ4 35.29 29.41 23.52 0.8187CQ5 23.52 52.94 23.52 0.2298CQ6 23.52 29.41 35.29 0.8187CQ7 17.64 47.05 35.29 0.327CQ8 29.41 23.52 47.05 0.4655CQ9 29.41 52.94 17.64 0.1926CQ10 47.05 29.41 23.52 0.4655CQ11 5.88 76.47 17.64 0.0006CQ12 0 70.58 29.41 0.005Table 6: User?s choice on comparative questions(CQ are the same questions as SQ but requestinga ranking of the 2 systems)as KFC, Tesco, etc.
(popular chain stores).
Someusers also suggested that our system should havea map and that routes taken should be plotted onthem for reference.
Based on the ratings and ob-servations made by the users, we conclude that ourfirst hypothesis that Spacebook would be more ef-ficient for navigation than the baseline because ofits speech-only interface was inconclusive.
We be-lieve so because users?
poor ratings for Spacebookmay be due to the current choice of dialogue pol-icy for navigation.
It may be possible to reassurethe user with a better dialogue policy with just thespeech interface.
However, this needs further in-vestigation.Users found the information-search task inter-esting and informative when they used Spacebook(see sample user comments in table 8).
Theyalso found push information on nearby PoIs un-expected and interesting as they would not havefound them otherwise.
Many users believed thatthis could be an interesting feature that could helptourists.
They also found that asking questions andfinding answers was much easier with Spacebookcompared to the baseline system, where some-times users needed to type search keywords in.Another user observation was that they did nothave to stop to listen to information presentedby our system (as it was in speech) and couldcarry on walking.
However, with the baseline sys-tem, they had to stop to read information off thescreen.
Although users in general liked the QAfeature, many complained that Spacebook spoketoo quickly when it was presenting answers.
Someusers felt that the system might lose context of thenavigation task if presented with a PoI question.In contrast, some others noted Spacebook?s abilityto interleave the two tasks and found it to be anadvantage.Users?
enthusiasm for our system was observedwhen (apart from the points of interest that werein the experimental task list) they also asked spon-taneous questions about James Watt, the TalbotRice gallery, the Scottish Parliament and Edin-burgh Castle.
Some of the PoIs that the systempushed information about were the Royal Collegeof Surgeons, the Flodden Wall, the Museum ofChildhood, and the Scottish Storytelling Centre.Our system answered a mean of 2.5 out of 6.55questions asked by users in leg 1 and 4.88 out of8.5 questions in leg 2.
Please note that an utter-ance is sent to QA if it is not parsed by the parserand therefore some utterances may not be legit-mate questions themselves.
Users were pushed amean of 2.88 and 6.37 PoIs during legs 1 and 2.There were a total of 17 ?tell me more?
requestsrequesting the system to present more information(mean=1.35 ?
1.57).Evaluators who followed the subjects noted thatthe subjects felt difficulty using the baseline sys-tem as they sometimes struggled to see the screen16661.
?It?s useful when it says ?Keep walking?
but it should say it more often.?2.
?
[Your system] not having a map, it was sometimes difficult to check how aware it was of my environment.?3.
?
[Google] seemed to be easier to follow as you have a map as well to help.?4.
?It told me I had the bank and Kentucky Fried Chicken so I crossed the road because I knew it?d be somewhere overbeside them.
I thought ?OK, great.
I?m going the right way.?
but then it didn?t say anything else.
I like those kind ofdirections because when it said to go down Nicolson Street I was looking around trying to find a street sign.?5.
?The system keeps saying ?when we come to a junction, I will tell you where to go?, but I passed junctions and itdidn?t say anything.
It should say ?when you need to change direction, I will tell you.??6.
?I had to stop most of the times for the system to be aware of my position.
If walking very slowly, its awareness ofboth landmarks and streets is excellent.
?Table 7: Sample user comments on the navigation task1.
?Google doesn?t *offer* any information.
I would have to know what to ask for...?2.
?Since many information is given without being asked for (by your system), one can discover new places andlandmarks even if he lives in the city.
Great feature!!?3.
?I didn?t feel confident to ask [your system] a question and still feel it would remember my directions?4.
?Google could only do one thing at a time, you couldn?t find directions for a place whilst learning more.?5.
?If she talked a little bit slower [I would use the system for touristic purposes].
She just throws masses of informationreally, really quickly.
?Table 8: Sample user comments on the tourist information taskin bright sunlight.
They sometimes had difficultyidentifying which way to go based on the routeplotted on the map.
In comparison, subjects didnot have to look at the screen when they usedour system.
Based on the ratings and observa-tions made by the users about our system?s touristinformation features such as answering questionsand pushing PoI information, we have support forour second hypothesis: that users find a dialogueinterface which integrates question-answering andnavigation within a shared context to be useful forfinding information about entities in the urban en-vironment.8 Future plansWe plan to extend Spacebook?s capabilities to ad-dress other challenges in pedestrian navigation andtourist information.
Many studies have shownthat visible landmarks provide better cues for nav-igation than street names (Ashweeni and Steed,2006; Hiley et al, 2008).
We will use visiblelandmarks identified using the visibility engine tomake navigation instructions more effective, andwe plan to include entities in dialogue and visualcontext as candidates for PoI push, and to imple-ment an adaptive strategy that will estimate userinterests and push information that is of interestto them.
We are also taking advantage of user?slocal knowledge of the city to present navigationinstructions only for the part of the route that theuser does not have any knowledge of.
These fea-tures, we believe, will make users?
experience ofthe interface more pleasant, useful and informa-tive.9 ConclusionWe presented a mobile dialogue app called Space-book to support pedestrian users in navigationand tourist information gathering in urban envi-ronments.
The system is a speech-only interfaceand addresses navigation and tourist informationin an integrated way, using a shared dialogue con-text.
For example, using the navigational context,Spacebook can push point-of-interest informationwhich can then initiate touristic exploration tasksusing the QA module.We evaluated the system against a state-of-the-art baseline (Samsung S-Voice with Google Navi-gation and Search) with a group of 17 users in thestreets of Edinburgh.
We found that users foundSpacebook interesting to interact with, and thatit was their system of choice for touristic infor-mation exploration tasks.
These results were sta-tistically significant.
Based on observations anduser ratings, we conclude that our speech-onlysystem was less preferred for navigation and morepreferred for tourist information tasks due to fea-tures such as PoI pushing and the integrated QAmodule, when compared to the baseline system.Younger users, who used Spacebook, even felt thatthey learned new facts about the city.AcknowledgmentsThe research leading to these results was funded by the Eu-ropean Commission?s Framework 7 programme under grant1667agreement no.
270019 (SPACEBOOK project).ReferencesK.
B. Ashweeni and A. Steed.
2006.
A naturalwayfinding exploiting photos in pedestrian naviga-tion systems.
In Proceedings of the 8th conferenceon Human-computer interaction with mobile devicesand services.P.
Bartie and W. Mackaness.
2006.
Developmentof a speech-based augmented reality system to sup-port exploration of cityscape.
Transactions in GIS,10:63?86.P.
Bartie and W. Mackaness.
2012.
D3.4 PedestrianPosition Tracker.
Technical report, The SPACE-BOOK Project (FP7/2011-2014 grant agreement no.270019).P.
Bartie and W. Mackaness.
2013.
D3.1.2 The Space-Book City Model.
Technical report, The SPACE-BOOK Project (FP7/2011-2014 grant agreement no.270019).D.
Byron, A. Koller, J. Oberlander, L. Stoia, andK.
Striegnitz.
2007.
Generating Instructions in Vir-tual Environments (GIVE): A challenge and evalua-tion testbed for NLG.
In Proceedings of the Work-shop on Shared Tasks and Comparative Evaluationin Natural Language Generation.S.
Cucerzan.
2007.
Large-scale named entity disam-biguation based on Wikipedia data.
In Proceedingsof EMNLP-CoNLL.R.
Dale, S. Geldof, and J. Prost.
2003.
CORAL : UsingNatural Language Generation for Navigational As-sistance.
In Proceedings of ACSC2003, Australia.Nina Dethlefs and Heriberto Cuaya?huitl.
2011.
Hierar-chical Reinforcement Learning and Hidden MarkovModels for Task-Oriented Natural Language Gener-ation.
In Proc.
of ACL.B.
Gittings.
2012.
The Gazetteer for Scotland -http://www.scottish-places.info.H.
Hiley, R. Vedantham, G. Cuellar, A. Liuy,N.
Gelfand, R. Grzeszczuk, and G. Borriello.
2008.Landmark-based pedestrian navigation from collec-tions of geotagged photos.
In Proceedings of the7th Int.
Conf.
on Mobile and Ubiquitous Multimedia(MUM).S.
Janarthanam and O.
Lemon.
2011.
The GRUVEChallenge: Generating Routes under Uncertainty inVirtual Environments.
In Proceedings of ENLG.S.
Janarthanam, O.
Lemon, X. Liu, P. Bartie, W. Mack-aness, T. Dalmas, and J. Goetze.
2012.
Integrat-ing location, visibility, and Question-Answering ina spoken dialogue system for Pedestrian City Explo-ration.
In Proc.
of SIGDIAL 2012, S. Korea.H.
Kashioka, T. Misu, E. Mizukami, Y. Shiga,K.
Kayama, C. Hori, and H. Kawai.
2011.
Multi-modal Dialog System for Kyoto Sightseeing Guide.In Asia-Pacific Signal and Information ProcessingAssociation Annual Summit and Conference.S.S.
Keerthi, S. K. Shevade, C. Bhattacharyya, andK.
R. K. Murthy.
1999.
Improvements to Platt?sSMO Algorithm for SVM Classifier Design.
NeuralComputation, 3:637?649.J.
Ko, F. Murase, T. Mitamura, E. Nyberg, M. Tateishi,I.
Akahori, and N. Hataoka.
2005.
CAMMIA: AContext-Aware Spoken Dialog System for MobileEnvironments.
In IEEE ASRU Workshop.C.
Kray, K. Laakso, C. Elting, and V. Coors.
2003.Presenting Route Instructions on Mobile Devices.In Proceedings of IUI 03, Florida.R.
Malaka and A. Zipf.
2000.
Deep Map - challengingIT research in the framework of a tourist informationsystem.
In Information and Communication Tech-nologies in Tourism 2000, pages 15?27.
Springer.A.
Mikhailsian, T. Dalmas, and R. Pinchuk.
2009.Learning foci for question answering over topicmaps.
In Proceedings of ACL 2009.D.
Montello.
1993.
Scale and multiple psychologiesof space.
In A. U. Frank and I. Campari, editors,Spatial information theory: A theoretical basis forGIS.M.
Raubal and S. Winter.
2002.
Enriching wayfindinginstructions with local landmarks.
In Second Inter-national Conference GIScience.
Springer, USA.C.J.
Shroder, W. Mackaness, and B. Gittings.
2011.Giving the Right Route Directions: The Require-ments for Pedestrian Navigation Systems.
Transac-tions in GIS, pages 419?438.N.
Webb and B. Webber.
2009.
Special Issue on Inter-active Question Answering: Introduction.
NaturalLanguage Engineering, 15(1):1?8.P.
A. Zandbergen and S. J. Barbeau.
2011.
Posi-tional Accuracy of Assisted GPS Data from High-Sensitivity GPS-enabled Mobile Phones.
Journal ofNavigation, 64(3):381?399.1668
