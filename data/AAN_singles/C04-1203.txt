A Natural Language Processing Infrastructure for TurkishA.
C. Cem SAYDepartment of Computer Engineering,Bogazi?i University,Bebek,stanbulsay@boun.edu.tr?zlem ?ETNOLUFaculty of Engineering and Natural Sciences,Sabanc?
University,Tuzla,stanbulozlemc@sabanciuniv.edueniz DEMRDepartment of Computer Engineering,Bogazi?i UniversityBebek,stanbulsdemir@cse.yeditepe.edu.trFatih ??NDepartment of Computer Engineering,Bogazi?i UniversityBebek,stanbulfatih_ogun@yahoo.comAbstractWe built an open-source software platform in-tended to serve as a common infrastructure thatcan be of use in the development of new applica-tions involving the processing of Turkish.
Theplatform incorporates a lexicon, a morphologicalanalyzer/generator, and a DCG parser/generatorthat translates Turkish sentences to predicatelogic formulas, and a knowledge base frame-work.
Several developers have already utilizedthe platform for a variety of applications, includ-ing conversation programs and an artificial per-sonal assistant, tools for automatic analysis ofrhyme and meter in Turkish folk poems, a proto-type sentence-level translator between Albanian,Turkish, and English, natural language interfacesfor generating SQL queries and JAVA code, aswell as a text tagger used for collecting statisticsabout Turkish morpheme order for a speech rec-ognition algorithm.
The results indicate theadaptability of the infrastructure to differentkinds of applications and how it facilitates im-provements and modifications.IntroductionThe obvious potential of natural language processingtechnology for economic, social and cultural pro-gress can be realized more comprehensively if NLPtechniques applicable to a wider selection of the lan-guages of the world are developed.
Before the full-scale treatment of a new language can start, a con-siderable amount of effort has to be invested tocomputerize the lexical, morphological and syntacticspecifics of that language, which would be requiredby any nontrivial application.We built an open-source software platform in-tended to serve as a common infrastructure that canbe of use in the development of new applicationsinvolving the processing of Turkish.
The platform,named TOY (?etinolu 2001), is essentially a bigset of predicates in the logic programming languageProlog.
The choice of Prolog, which was designedspecifically with computational linguistics applica-tions in mind, as the implementation language forour software has natural consequences for theknowledge representation setup to be used by otherprograms built on our platform.
Prolog is based onfirst-order predicate calculus, it allows knowledgeitems to be represented in terms of logic-style factsand rules, and a built-in theorem prover drives theexecution of Prolog queries.The TOY program?s internal organization intosource files reflects the three different levels (seeFigure 1) on which text-based NLP applications canbe based.
In terms of that figure, processing at a?deeper?
level necessitates all components of ?shal-lower?
levels.In this paper, we describe this infrastructure andhow it was adapted to a variety of applications.
Sec-tion 2 gives a brief overview of the infrastructure.Section 3 presents the applications based on it.1 InfrastructureThe TOY platform is formed of a lexicon that con-tains most of the Turkish morphemes (either root orsuffix), a Turkish morphological analyzer/generator,a DCG parser/generator for Turkish, and a semanticprocessor which interfaces the aforementioned sub-units with the underlying knowledge base forknowledge addition and extraction.Figure 1.
TOY?s Internal Organization.1.1    LexiconA complete lexicon is supposed to contain entriesfor all morphemes (meaningful units that make upwords) for the language in question.
There are twokinds of morphemes: roots and affixes.
In Turkish,all affixes follow the root, that is, they are suffixes.Our lexicon contains entries for over 29000 rootsand 157 suffixes.
A single morpheme may havemore than one entry, corresponding to its differentallomorphs.
A morpheme definition example for theword ??ocuk?
(?child?)
is shown in Figure 2.Figure 2.
Morpheme Definition.The semantic representation slot gives a descrip-tion of the contribution of the morpheme to themeaning of full-size sentences in which it appears:Since the meanings of sentences are represented bypredicate logic formulas in our setup, roots contrib-ute ?partial?
versions of such formulas, with ?holes?to be filled by the contributions of the other words ofthe sentence.
For instance, the semantic representa-tion entry of the noun ??ocuk?
is ?ocuk(_).
In thesentence ?Ali ?ocuktur?
(?Ali is a child?
), the valueof the missing argument is supplied by the name Ali,resulting in the formula ?ocuk('Ali') for the overallsentence.For noun entries, the commonsense knowledgeslot contains a pointer to the location of the thingdescribed by this noun in the taxonomy tree (seeFigure 4) used by the program.
(The entry for?
?ocuk?, for instance, indicates that it can bereached by descending from the root along the ?con-crete entity?-?animate-?human being?
arcs.)
Forverbs, this slot contains a set of restrictions on thevarious argument slots of the verb.
As an example,the agent of the verb ?ye-?
(?eat?)
is restricted to bea living thing, and its theme is restricted to be asolid.1.2    Morphological Analyzer/ GeneratorIn the infrastructure, possible legal orderings ofTurkish morphemes are represented by a large finitestate diagram, a small part of which can be seen inFigure 3.
The morphological component of the plat-form is a finite state transducer that makes use of thelexicon for traversing the arcs of the diagram(adopted, with changes, from Kemal Oflazer?s workon Turkish morphology (Oflazer 1993)) to associatea character string with the list of meaning contribu-tions of its morphemes.
This traversal is complicatedby the vowel harmony constraint of Turkish mor-phology.
This rule means that, when adding a suffixto a word, the allomorph to be added is a function ofthe last vowel of the word to be extended.
For in-stance, the plural suffix has the two allomorphs ?-ler?
and ?-lar?.
The Turkish word for ?children?
is?
?ocuklar?, while ?olives?
is ?zeytinler?, since?back vowels?
like ?a?
and ?u?
require a back vowelin the suffix, whereas ?front vowels?
like ?e?
and ?i?require a front vowel there.
The program keeps trackof the vowels during the transduction to enforcethese constraints.
Words of foreign origin which vio-late vowel harmony are flagged appropriately in thelexicon.Figure 3.
A Subgraph of the Morphological FSTEmployed by TOY.Like most Prolog predicates the morphologicalcomponent is reversible, that is, the same piece ofcode can be used both to analyze a given word toobtain its underlying constituents, and to generate aword when given a list of such constituents.
Anotherbuilt-in feature of Prolog makes it very easy for theprogram to compute all results associated with a par-ticular input when more than one legal output ispossible, as in the case of the analysis of themorphologically ambiguous word ?yedi?, where ourmorphological parser produces, through backtrack-ing, two alternative analyses: the third-person/singular past tense inflection of the verb ?ye-?
(?eat?
), and the Turkish number word for ?seven?.1.3    DCG Parser/GeneratorWe encoded a subset of the syntax rules of Turkishin Prolog?s DCG notation.
The DCG formalism al-lows the computation of the meaning formula of aconstituent to be performed in parallel with its syn-tactic parsing; each DCG rule is written to indicatehow the partial meanings of the elements on itsright-hand side fit together to produce the semanticexpression for the constituent on the left-hand side.Certain language constructs correspond naturallyto the notion of quantification in predicate calculus.For instance, the sentence ?Bir ?ocuk zeytin yedi.?
(?A child ate (an/some) olive(s)?)
can be representedby the logical formula?X?Y( ?ocuk(X) ?
zeytin(Y)  ?
ye(Event, X,Y, Loca-tion, Time, Goal, Source, Instrument, defi-nite_past, none, positive) ).In the Prolog program, existentially quantifiedexpressions like this one have the formsome(X,Restrictor,Scope), where X is the quantifiedvariable, and Restrictor and Scope are the two sidesof the conjunction (Covington, 1994)some(X,?ocuk(X),some(Y,zeytin(Y),ye(EventMarker,X,Y,Location,Time,Goal,Source,Instrument,definite_past,none,positive)))The successful DCG parsing of a sentence also re-sults in a field being instantiated to a symbol repre-senting the sentence?s mood.
Possible values for themood field are ?statement,?
?yes_no_question,?
and?wh_question.
?This component of the program is also designedto be reversible, that is, it can produce the corre-sponding sentence when given a logical formula, butyet another peculiarity of the language complicatesthe solution: Turkish word order is (almost) free,which basically means that the sentence constituentscan be shuffled around without changing the mean-ing.
Therefore, a single semantic formula usuallycorresponds to several different sentences, evenwithout taking synonymity of words into account.Our software has the capability of producing multi-ple alternative sentences as output in such cases.1.4    Anaphora ResolverIn general, the full-scale processing of all but verysimple sentences necessitates information that is notpresent in the sentence itself, the most obvious ex-amples being question sentences.
This additionalinformation is either pre-encoded in the knowledgebase as part of a big store of commonsense knowl-edge, or, when the agent is involved in a dialogue ora story understanding task, it is gleaned from theother sentences in the input.One example where the computation of the mean-ing of a declarative sentence requires access toknowledge obtained from previous sentences is theprocess of anaphora resolution.
Resolving an ana-phor is the job of finding out which discoursemarker (unique internal name) to use for the entityreferred to by this phrase in the knowledge base.There is no ?correct?
algorithm for this task becauseof the inherent ambiguity of natural language (Lenat1995).
Our resolver selects a discourse marker for ananaphoric reference making use of the taxonomytree (see Figure 4), semantic type information in itsdictionary, pointers to the locations in this tree, andthe positions of the original referents in their sen-tences.Our resolver treats only definite clauses as ana-phors and resolves direct anaphors.
Gelbukh andSidorov (1999) propose ways of solving indirectanaphors.Figure 4.
TOY?s Taxonomy Tree.An anaphor and its antecedent can be related ifsemantic type of the anaphor contains the semantictype of the antecedent or vice versa or their typesintersect.
Resolution of indirect anaphors will beadded to TOY?s anaphora resolver in the future.
Thistaxonomy tree will also be used for this purpose.1.5    Knowledge Base InterfaceThis module translates predicate logic formulas cre-ated by the DCG parser to Prolog facts and rules.
Asan example, the sentence ?Ali ?ocuktur?
(?Ali is achild?)
is eventually translated to the Prolog fact?ocuk('Ali'), whose form enables it to take part inautomatic proofs involving this knowledge itemwhen necessary.
In general, nouns and adjectives arerepresented as single-argument predicates standingfor the invoked property.Verbs other than ?to be?
have a considerablymore complicated representation.
The Prologequivalent of the sentence ?Ali gitti?
(?Ali left?)
isFigure 5.
Prolog Representation Example.Of course, from the point of view of the com-puter, (or, for that matter, of anybody who cannotspeak Turkish,) a formula like ?ocuk('Ali') is just asopaque as ?Ali ?ocuktur?.
When we look up astrange word in the dictionary, we comprehend itsmeaning by mentally linking it in appropriate waysto the words appearing in its description.
If a suffi-ciently large subgraph of this network of conceptsthat exists in our minds is replicated in the computer,it would be able to give the same response to an in-put sentence as a human utilizing the same network.For instance, the Prolog rule?ocuk(X):- insan(X), k???k(X).
(where ?insan?
means ?human?
and ?k???k?
means?small?
in Turkish) relates these three concepts in away similar to the picture in most people?s minds.The translation of a Turkish sentence to the corre-sponding predicate logic formula by the DCG rulesis just an intermediate step in the processing of thatsentence.
?Understanding?
a sentence necessitates acomputation involving both this formula and thecurrent contents of the knowledge base, possiblyresulting in a change to the knowledge base, and thegeneration of an appropriate response.Skolemization is used in the automatic transfor-mation of the logical formulas of declarative sen-tences to actual Prolog code by means of replacingall the existentially quantified variables by specialexpressions called Skolem functions.
The purpose ofthis operation is to assign a discourse marker toevery entity which is mentioned but not named inthe sentence.
These markers are the atomic symbolsused by the computer to model the world being de-scribed and referred to during the conversation, andkeeping track of them is an essential part of the dia-logue processing task.For wh-question sentences, the DCG parser cre-ates formulas in the form of Prolog predicates.
Forinstance, the sentence ?Kim zeytin yedi??
(?Who ate(an/some) olive(s)??)
is translated to the formulawhich(X,insan(X),some(Y,zeytin(Y),ye(Event,X,Y,Loc, Time,Goal,Source, Instrument,definite_past, none, positive))whose form matches the already available logic pro-gram which(Item,Property1Item,Property2Item).
Seethe next section for a discussion of these ?question-word?
routines.2       Applications Based on TOYIn this section, we will present some applicationsthat were developed using the TOY infrastructure.Each subsection will briefly explain the application,the TOY components used, and the modificationsdone on the infrastructure.2.1    Conversational agent ?
TOYagentSmith (1994) classifies dialogue styles that can beadopted by the computer during human-computerinteraction into four modes, depending on the degreeof control that the computer has on the dialogue:Directive, suggestive, declarative, and passive.TOYagent?s original approach mostly suits the pas-sive mode, where the user has complete control, andthe computer passively acknowledges user state-ments, and provides information only as a responseto direct user requests.TOYagent (Demir 2003) enables users to makeon-line additions to the lexicon without the need toknow Prolog.
When faced with a word that it is un-able to parse morphologically, TOYagent engages ina (mostly menu-driven) subdialogue with the user toidentify the root, category, and morphophonemicproperties of the word, and adds the appropriate en-tries to the lexicon.
The meanings of these newwords can be incorporated to the system by the logicprogram synthesis facility, which enables the user toprovide natural language descriptions for new predi-cates in terms of existing predicates.
These descrip-tions are automatically converted to Prolog clausesand added to the knowledge base of the program forfuture use.The original dialogue algorithm embedded inTOYagent can be summarized as follows:1.
Read a sentence (this may cause a ?word learn-ing?
subdialogue if one or more words in the sen-tence cannot be parsed by the morphologicalanalyzer)2.
Analyze the sentence using the DCG parser, re-solving anaphors if necessary.
If the syntacticparse is unsuccessful, report this to the user andGOTO 1.3.
If the mood is ?statement?, then the user is mak-ing a declarative statement; use the built-in theo-rem prover to try to prove the logical formulacorresponding to the sentence.
There are two pos-sibilities: (In the following, all the ?canned?
re-sponses are in Turkish, of course.)a.
If the formula can be proven using the cur-rent contents of the knowledge base, the informa-tion contained in the sentence is already there;respond with ?Thanks, I know that?b.
If Prolog fails to prove the formula with itscurrent knowledge, then negate the formula andtry to prove this negation.
There are two possibili-ties:i.
If this new formula can be proven using thecurrent contents of the knowledge base, the infor-mation contained in the sentence is contradictorywith what we already know; respond with ?I donot think so?ii.
If Prolog fails to prove this new formulawith its current knowledge, create the necessarydiscourse and event markers and assert the Prologclauses representing the input sentence to theknowledge base, responding with ?Thanks for theinformation?4.
If the mood is ?yes_no_question?, the user hasasked a yes-no question; use the built-in the proverto try to prove the sentence?s logical formula.There are two possibilities:a.
If the formula can be proven using the currentcontents of the knowledge base, respond with?Yes?b.
If Prolog fails to prove the formula with itscurrent knowledge, then negate the formula andtry to prove this negation.
There are two possibili-ties:i.
If this new formula can be proven using thecurrent contents of the knowledge base, respondwith ?No?ii.
If Prolog fails to prove this new formulawith its current knowledge, respond with ?I do notknow.?5.
If the mood is ?wh_question?, the user has askeda wh-question; use the built-in theorem prover onthe sentence?s logical formula.
The associatedprogram of each question word scans the knowl-edge base and produces the relevant answer.
Theanswer can be printed out directly, or, if required,in the form of a grammatical sentence generatedby a procedure that first prepares a new logicalformula from the produced knowledge items andthen uses the syntax and morphology componentsto form the statement corresponding to this for-mula.
GOTO 1.The following conversation fragments, in whichuser entries are shown in boldface, illustrate severalaspects of TOYagent.
(The English translations arenot part of TOYagent?s input-output, and have beenadded ?manually.?
)As an example to ?online?
learning of lexical en-tries, we deleted the word ?ana?
(?mother?)
from thelexicon, and carried out the following dialogue withthe program:Her ana g?zeldir.
(Every mother is beautiful)?ana?
kelimesini bilmiyorum.
(I do not know theword ?ana?
)Kelimenin k?k?
nedir?
(What is the stem of thisword?
)1: a2: an3: anaHangisi: 3.
(Please enter: 3.)?ana?
kelimesinin tipi nedir?
(What is the type ofthe word ?ana??
)1: Cins isim (1: Common noun)2: S?fat        (2: Adjective)3: ?zel isim(3: Proper noun)Hangisi: 3.
(Please enter: 3)S?zl?e eklendi.
(It has been added to the lexicon)?ana?
ne demek?
Anlat?r m?s?n?
(Could you ex-plain the word ?ana??
)?ocuu olan bir bayan anad?r.
(A female who has achild is a mother)Teekk?rler, ?rendim.
(Thanks for the information)Since the unknown word could have appeared inan inflected form in the input sentence, TOYagentfirst asks about the actual stem.
A Prolog rule corre-sponding to the relevant universally quantified logicformula is prepared and asserted for each of theuser?s sentences read in this dialogue.
The last line isthe program?s response to the original input sen-tence.Aye bir anad?r.
(Aye is a mother)Teekk?rler, ?rendim.
(Thanks for the information)Aye g?zel midir?
(Is Aye beautiful?)Evet.
(Yes)Neden?
(Why?
)Her ana g?zeldir.
(Every mother is beautiful)Aye anad?r.
(Aye is a mother)The affirmative answer requires stepping throughthe implication translated to Prolog during the proc-essing of the original user entry.
The question?why??
is answered by translating the Prolog formu-las used for the previous answer back to sentenceform.Definite noun phrases are treated as anaphors:Canan k??
?k bir ?ocuk.
(Canan is a small child)Teekk?rler, ?rendim.
(Thanks for the information)?ocuk kahvalt?da zeytin yedi.
(The child ate olivesfor breakfast)Teekk?rler, ?rendim.
(Thanks for the information)Kim zeytin yedi?
(Who ate olives?
)Canan zeytin yedi.
(Canan ate olives)Ka?
kii kahvalt?da zeytin yedi?
(How many peopleate olives for breakfast?
)Bir kii kahvalt?da zeytin yedi.
(One person ate ol-ives for breakfast)The definite noun phrase in the second user entry(?the child?)
is matched to the most recently men-tioned child.
As mentioned earlier, question wordshave small Prolog programs corresponding to them.The answer extracted from the knowledge base ispresented in the form of a grammatically correctsentence.
(The fact that every child is also a personis one of the commonsense items that have beenpreencoded in the knowledge base.
)A rudimentary capability of commonsense rea-soning about time is implemented: The ?time?
ar-gument in verb predicates has a substructure withslots for the beginning and ending points of the in-terval corresponding to the event.
(In the presentversion, only a small subset of the verbal lexiconentries have their time subslots manually encodedfor this purpose.)
Hours are used as the unit interval.Kemal k??
?k bir ?ocuk.
B?t?n k??
?k ?ocuklar 10saat uyurlar.
(Kemal is a small child.
All small chil-dren sleep for 10 hours)Teekk?rler, ?rendim.
(Thanks for the information)Kemal saat 23?te uyudu.
(Kemal fell asleep at 23hours)Teekk?rler, ?rendim.
(Thanks for the information)Kemal ne zaman uyudu?
(When did Kemal fallasleep?
)Kemal yirmi?
?te uyudu.
(Kemal fell asleep at twentythree)Kemal ne zaman uyand??
(When did Kemal wakeup?
)Kemal dokuzda uyand?.
(Kemal woke up at nine)Note that the program is able to do the ?modulo24?
calculation required for producing the appropri-ate answer.To find pronominal references in the absence ofgender information, the semantic network is utilized.In the following excerpt, the pronoun ?o?(?he/she/it?)
is correctly deduced to correspond to??ay?
(?tea?
), since the network does not allow?Kemal?, a human name, to be the agent of the word?bit-?
(?to be consumed entirely?
), which can haveonly inanimate material at that role.Kemal kahvalt?da ne i?ti?
(What did Kemal drink forbreakfast?)Bilmiyorum.
(I do not know)Kemal ?ay i?ti ise o bitmitir.
(If Kemal drank tea,(he/she/it) must have been consumed entirely)Teekk?rler, ?rendim.
(Thanks for the information)Kemal ?ay i?ti.
(Kemal drank tea)Teekk?rler, ?rendim.
(Thanks for the information)?ay bitmi midir?
(Has the tea been consumed en-tirely?
)Evet (Yes)The latest release of TOYagent (??n 2003) isable to manage conversations with multiple agents,can adapt different ?attitudes?
about whether to be-lieve what a user says depending on the user?s pro-file, and has the capability of detecting and pointingout inconsistencies among the statements made bydifferent users.
This version also supports an op-tional ?inquisitive?
dialogue mode, where the com-puter questions the user about the values of currentlyempty slots in the verb predicates corresponding toprevious user statements.2.2     Turkish Natural Language InterfaceFor SQL Queries (NALAN-TS)NALAN-TS (Maden, Demir and ?zcan 2003) is aTurkish natural language query interface for SQLdatabases, formed of a syntactic parser, semanticanalyzer, meaning extractor, SQL constructor andexecuter.
It is a dictionary based application and in-cludes Turkish and database dictionaries.Figure 6.
NALAN-TS Flow Diagram.The shaded modules in Figure 6 were taken com-pletely from the TOY infrastructure, except for afew modifications like the addition of new Turkishsyntax rules and a different format for the semanticrepresentation of the words in the dictionary.
TOY?sknowledge base interface is taken as the basis byNALAN-TS.2.3   Turkish Speaking Assistant -TUSATUSA (eker, 2003) is a natural language interfacefor an online personal calendar.
The morphologicalanalyzer/generator of TOY was taken as a basis inthis project with modifications made for utilizing.2.4   Generating Java Class Skeleton Using aNatural Language Interface- TUJATUJA (?zcan, eker and Karadeniz 2004) is a natu-ral language interface for generating Java sourcecode and creating an object-oriented semantic net-work.
This program uses TOY?s morphological ana-lyzer/generator as the starting point.2.5     Other ApplicationsBallhysa (2000) used TOY to produce a prototypicalsentence-level translator between Albanian, English,and Turkish.
(To our knowledge, this is the firstNLP work ever done on Albanian) Dutaac?
(2002)used the morphological component to tag a Turkishcorpus of nearly ten million words to collect statis-tics and compared the performance of an N-grammodel of speech recognition based on morphemeswith those based on words or syllables.
Tekeli(2002) made use of the word-level components tobuild an ?ELIZA-like?
(Covington 1994) dialogueprogram which caricaturizes Fatih Terim, a famoussoccer coach and an idiosyncratic Turkish speaker.The program?s ?bag of tricks?
includes coming upwith rhyming responses to user sentences.
Bilsel(2000) developed a ?poem expert?
for analyzingTurkish folk poems for their rhyme and meter prop-erties, a demanding task which is part of the high-school curriculum in Turkey.ConclusionOur work on TOY is continuing on many fronts: TheDCG component is currently being extended tocover both a bigger subset of Turkish syntax, andsome types of agrammatical sentences.
We hope thatTOY will be useful in the development of manyother applications in the near future.ReferencesCan Tekeli 2002.
TERIM_SON.
B.S.
Thesis, Departmentof Computer Engineering, Bogazici University.Douglas Lenat 1995.
CYC: A Large-Scale Investment inKnowledge Infrastructure.
In ?Comm.
ACM, 38/11?,pages 33-38.Eda Bilsel 2000.
Poem Analyzer, B.S.
Thesis, Departmentof Computer Engineering, Bogazici University.Elton Ballhysa 2000.
Albanian-Turkish-English Transla-tor.
B.S.
Thesis, Department of Computer Engineering,Bogazici University.Ender ?zcan, adi E. eker and Zeynep.
I. Karadeniz2004.
Generating Java Class Skeleton Using A NaturalLanguage Interface.
In ?First International Workshopon Natural Language Understanding and Cognitive Sci-ence-NLUCS?.Fatih ??n 2003.
Design and Implementation of an Im-proved Conversational Agent Infrastructure for Turk-ish.
M.S.
Thesis, Department of Computer Engineering,Bogazici University.Helin Dutaac?
2002.
Statistical Language Models forLarge Vocabulary Turkish Speech Recognition.
M.S.Thesis, Department of Computer Engineering, BogaziciUniversity.Ibrahim Maden, eniz Demir and Ender ?zcan 2003.Turkish Natural Language Interface for GeneratingSQL Queries.
In ?TBD 20.
Ulusal Biliim Kurultayi?.Kemal Oflazer 1993.
Two-Level Description of TurkishMorphology.
In ?Proc.
Second Turkish Symposium onArtificial Intelligence and Neural Networks?, BogaziciUniversity Press, pages 86-93, Istanbul.Michael A .Covington 1994.
Natural Language Process-ing for Prolog Programmers.
Prentice Hall, EnglewoodCliffs, NJ.
?zlem ?etinolu 2001.
A Prolog Based Natural Lan-guage Processing Infrastructure for Turkish.
M.S.
The-sis, Department of Computer Engineering, BogaziciUniversity.Ronnie W. Smith 1994.
Spoken Variable Initiative Dia-log: An Adaptable Natural-Language Interface.
In?IEEE Expert: Intelligent Systems and Their Applica-tions 9/1?,pages 45-50.adi E. eker 2003.
Design and Implementation of aPersonal Calendar with a Natural Language Interfacein Turkish.
M.S.
Thesis, Department of Computer En-gineering, Yeditepe University.eniz Demir 2003.
Improved Treatment of Word Meaningin a Turkish Conversational Agent.
M.S.
Thesis, De-partment of Computer Engineering, Bogazici Univer-sity.
