A Robust Cross-Style Bilingual Sentences Alignment ModelTz-Liang Kueng Keh-Yih SuBehavior Design Corporation2F, No.5, Industry E. Rd.
IV,Science-Based Industrial Park,Hsinchu, Taiwan 30077, R.O.C.
{cavs, kysu}@bdc.com.twAbstractMost current sentence alignment approaches adoptsentence length and cognate as the alignment features;and they are mostly trained and tested in the docu-ments with the same style.
Since the length distribu-tion, alignment-type distribution (used by length-basedapproaches) and cognate frequency vary significantlyacross texts with different styles, the length-based ap-proaches fail to achieve similar performance when testedin corpora of different styles.
The experiments show thatthe performance in F -measure could drop from 98.2%to 85.6% when a length-based approach is trained by atechnical manual and then tested on a general magazine.Since a large percentage of content words in the sourcetext would be translated into the corresponding trans-lation duals to preserve the meaning in the target text,transfer lexicons are usually regarded as more reliablecues for aligning sentences when the alignment task isperformed by human.
To enhance the robustness, arobust statistical model based on both transfer lexiconsand sentence lengths are proposed in this paper.
Af-ter integrating the transfer lexicons into the model, a60% F -measure error reduction (from 14.4% to 5.8%) isobserved.1 IntroductionSince the bilingual corpus is a valuable resource fortraining statistical language models [Dagon, 91; Suet al, 95; Su and Chang, 99] and sentence align-ment is the first step for most such tasks, manyalignment approaches have been proposed in theliterature [Brown, 91; Gale and Church, 93; Wu,94; Vogel et al, 96; Och and Ney, 2000].
Most ofthose reported approaches use the sentence lengthas the main feature to perform the alignment task.For example, Brown et al (91) used the featureof number-of-words for alignment, and [Gale andChurch,93] claimed that better performance can beachieved (5.8% error rate for English-French cor-pus) if the number-of-characters is adopted instead.As cognates are reliable cues for language pairs de-rived from the same family, Church (93) also at-tacked this problem by considering cognates addi-tionally.
Because most of those reported work areperformed on those Indo-European language-pairs,for testing the performance on non-Indo-Europeanlanguages, Wu (94) had tried both length and cog-nate features on the Hong Kong Hansard English-Chinese corpus, and 7.9% error rate has been re-ported.
Besides, sentence alignment can also beindirectly achieved via more complicated word cor-responding models [Brown et al, 93; Vogel et al,96; Och and Ney, 2000].
Since those word corre-sponding models, which also achieve similar per-formance, are more complicated and run relativelyslow, they seems to be over-killed for the task ofaligning sentences and will not be discussed in thispaper.Although length-based approaches above men-tioned are simple and can achieve good perfor-mance, they are usually trained and tested inthe text with the same style.
Therefore, theyare style-dependent approaches.
Since performingsupervised-training for each style is not feasible inmany applications, it would be interesting to knowwhether those length-based approaches can stillachieve the similar performance if they are tested inthe text with different styles other than the train-ing corpora.
An experiment was thus conductedto train the parameters with a machinery technicalmanual; the performance is then tested on a generalmagazine (for introducing Taiwan to foreign visi-tors).
It shows that the testing set performance ofthe length-based model (with cognates considered)would drop from 98.2% (tested in the same tech-nical domain) to 85.6% (tested in the new generalmagazine) in F -measure.
After investigating thoseerrors, it has been found that the length distribu-tion and alignment-type distribution (used by thoselength-based approaches) vary significantly acrossthe texts of different styles (as would be shown inTables 5.2 and 5.3), and the cognate-frequency1drops greatly from the technical manual to a gen-eral magazine in non-Indo-European languages (aswould be shown in Table 5.3).On the other hand, sentence length is seldomused by a human to align bilingual sentences.
Theyusually do not align bilingual sentences by countingthe number of characters (or words) in the sentencepairs.
Instead, since a large percentage of contentwords in the source text would be translated intotheir translation-duals to preserve the meaning inthe target text, transfer-lexicons are usually usedfor aligning sentences when the alignment task isperformed by human.
To enhance the robustnessacross different styles, transfer-lexicons are thus in-tegrated into the traditional sentence-length basedmodel in the proposed robust statistical model de-scribed below.
After integrating transfer-lexiconsinto the model, a 60% F -measure error reduction(from 14.4% to 5.8%) has been observed, which cor-responds to improving the cross-style performancefrom 85.6% to 94.2% in F -measure.The details of the proposed robust model, the as-sociated features extracted from the bilingual cor-pora, and the probabilistic scoring function will begiven in Section 2.
In Section 3, we briefly men-tion some implementation issues.
The associatedperformance evaluation is given in Section 4, andSection 5 would address error analysis and discussesthe limitation of the proposed statistical model.
Fi-nally, the concluding remarks are given in Section6.1Here ?Cognate?
mainly refers to those English propernouns (such as those company names of IBM, HP; or thetechnical terms such as IEEE-1394, etc.)
that appear in theChinese text.
As they are most likely to be directly copiedfrom the English sentence into the corresponding Chineseone, they are reliable cues.2 Statistical Sentence Alignment ModelSince an English-Chinese bilingual corpus will beadopted in our experiments, we will denote thesource text with m sentences as ESm1 , and itscorresponding target text, with n sentences, asCSn1 .
Let Mi = {typei,1, ?
?
?
, typei,Ni} denotethe i-th possible alignment-candidate, consisting ofNi Alignment-Passages of typei,j , j = 1, ?
?
?
, Ni;where typei,j is the matching type (e.g., 1?1, 0?1,1?0, etc.)
of the j-th Alignment-Passage in the i-thalignment-candidate, and Ni denotes the number ofthe total Alignment-Passages in the i-th alignment-candidate.
Then the statistical alignment model isto find the Bayesian estimate M?
among all pos-sible alignment candidates, shown in the followingequationM?
= argmaxMiP (Mi|ESm1 , CSn1 ).
(2.1)According to the Bayesian rule, the maximizationproblem in (2.1) is equivalent to solving the follow-ing maximization equationM?
= argmaxMiP (ESm1 , CSn1 |Mi)P (Mi)= argmaxMi{P (Aligned-Pairi,Nii,1|typei,Nii,1)P (typei,Nii,1)}= argmaxMiNi?j=1{P (Aligned-Pairi,j |Aligned-Pairi,j?1i,1, typei,ji,1) ?P (typei,j |typei,j?1i,1)}, (2.2)where Aligned-Pairi,j , j = 1, ?
?
?
, Ni, denotesthe j-th aligned English-Chinese bilingual sentencegroups pair in the i-th alignment candidate.Assume thatP (Aligned-Pairi,j |Aligned-Pairi,j?1i,1 , typei,ji,1)?
P (Aligned-Pairi,j |typei,j), (2.3)and different typei,j in the i-th alignment can-didate are statistically independent2, then theabove maximization problem can be approached bysearching forM?
?
argmaxMiNi?j=1{P (Aligned-Pairi,j |typei,j)P (typei,j)},(2.4)where M?
denotes the desired candidate.2A more reasonable one should be the first-order Markovmodel (i.e., Type-Bigram model); however, it will signifi-cantly increase the searching time and thus is not adoptedin this paper.2.1 Baseline ModelTo make the above model feasible, Aligned-Pairi,jshould be first transformed into an appropriatefeature space.
The baseline model will use boththe length of sentence [Brown et al, 91; Gale andChurch, 93] and English cognates [Wu, 94], and isshown as follows:argmaxMiNi?j=1f(?c, ?w|typei,j)P (?cognate)P (typei,j),(2.5)where ?c and ?w denote the normalized differencesof characters and words as explained in the follow-ing; ?c is defined to be (ltc ?
clsc)/?lscs2c , wherelsc and ltc are the character numbers of the alignedbilingual portions of source text and target text,respectively, under consideration; c denotes theproportional constant for target-character-countand s2c denotes the corresponding target-character-count variance per source-character.
Similarly, ?wis defined to be (ltw ?
wlsw)/?lsws2w, where lswand ltw are the word numbers of the aligned bilin-gual portions of source text and target text, re-spectively; w denotes the proportional constantfor target-word-count and s2w denotes the corre-sponding target-word-count variance per source-word.
Also, the random variables ?c and ?w areassumed to have bivariate normal distribution andeach possesses a standard normal distribution withmean 0 and variance 1.
Furthermore, ?cognate de-notes (?Number of English cognates found in thegiven Chinese sentences??
?Number of correspond-ing English cognates found in the given Englishsentences?
), and is Poisson3 distributed indepen-dent of its associated matching-type; also assumethat ?cognate is independent of other features (i.e.,character-count and word-count).2.2 Proposed Transfer Lexicon ModelSince transfer-lexicons are usually regarded asmore reliable cues for aligning sentences when thealignment task is performed by human, the abovebaseline model is further enhanced by adding3Since almost all those English cognates found in thegiven Chinese sentences can be found in the correspondingEnglish sentences, ?cognate had better to be modeled as aPoisson distribution for a rare event (rather than Normaldistribution as some papers did).those associated transfer lexicons to it.
Thosetranslated Chinese words, which are derived fromeach English word (contained in given Englishsentences) by looking up some kinds of dictionar-ies, can be viewed as transfer-lexicons becausethey are very likely to appear in the translatedChinese sentence.
However, as the distributionof various possible translations (for each Englishlexicon) found in our bilingual corpus is far morediversified4 compared with those transfer-lexiconsobtained from the dictionary, only a small num-ber of transfer-lexicons can be matched if theexact-match is specified.
Therefore, each Chinese-Lexicon obtained from the dictionary is firstaugmented with its associated Chinese characters,and then the augmented transfer-lexicons set arematched with the target Chinese sentence(s).
Oncean element of the augmented transfer-lexicons setis matched in the target Chinese sentence, it iscounted as being matched.
So we compute theNormalized-Transfer-Lexicon-Matching-Measure,?Transfer?Lexicons which denotes [(?Number ofaugmented transfer-lexicons matched??
?Numberof augmented transfer-lexicons unmatched?
)/?Total Number of augmented transfer-lexiconssets?
], and add it to the original model as anotheradditional feature.Assume follows normal distribution and the asso-ciated parameters are estimated from the trainingset, Equation (2.5) is then replaced byargmaxMiNi?j=1{f1(?c, ?w|typei,j)P (?cognate)?f2(?Transfer?Lexicons)?P (typei,j)}.
(2.6)3 ImplementationThe best bilingual sentence alignment in thoseabove models can be found by utilizing a dynamicprogramming algorithm, which is similar to the dy-namic time warping algorithm used in speech recog-nition [Rabiner and Juang, 93].
Currently, the4For example, the English word ?number?
are found to betranslated into ?
?K?, ?
K?, ?
?K?, ??
K?, ??
?K?, ??
}?, ?
?
?
etc., for a specific sense in the given corpus; however,the transfer entries listed in the dictionary are ??K?
and ??}?
only.Case I (Length-Type Error)(E1) Compared to this, modern people have relatively better nutrition and mature faster, working women marry later, and therehas been a great decrease in frequency of births, so that the number of periods in a lifetime correspondingly increases, soit is not strange that the number of people afflicted with endometriosis increases greatly.
(C1) ??
?, ?HA??
? ?o, <?v?
?wu, ?>?byu?
?, ??2~%V??b?$?
?, ??q??P66??6.?
?J7(E2) The problem is not confined to women.
(E3) ?Sperm activity also noticeably decreases in men over forty,?
says Taipei Medical College urologist Chang Han-sheng.
(C2) .?u?4,?4?
?uJ(, ???6}p???
'? C????+3L??
;zCase II (Length&Lexicon-Type Error)(E1) Second, the United States as well as Japan have provided lucrative export markets for countries in this region.
(E2) The U.S. was particularly generous in the postwar years, keeping its markets open to products from Asia and giving nascentindustries in the region a chance to catch up.
(C1) w?, D(?1??r?[??=??
?, U=????hE???
}?Figure 1: An illustration of length&lexical type errormaximum number of either source sentences or tar-get sentences allowed in each alignment unit is setto be ?4?
(i.e., we will not consider those matching-types of ?5?
1?, ?5?
2?, ?1?
5?, etc).Let {s1, ?
?
?
, sm} and {t1, ?
?
?
, tn} be the paral-lel bilingual source and target sentences, and letS(m,n) be the maximum accumulated score be-tween {s1, ?
?
?
, sm} and {t1, ?
?
?
, tn} under the bestalignment path.
Then S(m,n) can be evaluatedrecursively with the initial condition of S(0, 0) = 0in the following way:S(m,n) = max0?h,k?4S(m?
h, n?
k) + score(h, k), (3.1)where score(h, k) denotes the local scoring func-tion to evaluate the local passage of matching type?h?
k?.4 Performance EvaluationIn the experiments, a training set consisting of7, 331 pairs of bilingual sentences, and a testingset with 1, 514 pairs of bilingual sentences are ex-tracted from the Caterpillar User Manual whichis mainly about machinery.
The cross-style test-ing set contains 274 pairs of bilingual sentencesselected from the Sinorama Magazine, which is ageneral magazine (for introducing Taiwan to for-eign visitors) with its topics covering law, politics,education, technology, science, etc.
Figure 1 is anillustration of bilingual Sinorama Magazine texts.For comparing the performance of alignment,both precision rate (p) and recall rate (r), definedas follows, are measured; however, only their asso-ciated F -measure5 is reported for saving space.p =[Number of correct alignment-passages in system output][Total number of all alignment-passages generated from system output],(4.1)r =[Number of correct alignment-passages in system output][Total number of all alignment-passages contained in benchmark corpus].
(4.2)A Sequential-Forward-Selection (SFS) proce-dure [Devijver, 82], based on the perfor-mance measured from the Caterpillar User Man-ual, is then adopted to rank different fea-tures.
Among them, the Chinese transfer lexi-con feature (abbreviated as CTL in the table),which only adopts Normalized-Transfer-Lexicon-Matching-Measure and matching-type priori distri-bution (i.e., P (typei,j)), is first selected, then CLfeature (which adopts character-length), WL fea-ture (using word-length) and EC feature (using En-glish cognate) follow in sequence, as reported inTable 4.1.The selection sequence verifies our previous sup-position that the transfer-lexicon is a more reli-able feature and contributes most to the aligningtask.
Table 4.1 clearly shows that the proposedrobust model achieves a 60% F -measure error re-duction (from 14.4% to 5.8%) compared with thebaseline model (i.e., improving the cross-style per-formance from 85.6% to 94.2% in F -measure).
The5Which is defined as 2prp+r .Training Set Testing Set I Testing Set II[Caterpillar User Manual] [Caterpillar User Manual] [Sinorama Manazine]Baseline Model 98.91 98.21 85.56CTL 98.26 97.51 97.51CTL+CL 99.32 98.19 89.61CTL+CL+WL 99.61 98.83 94.07CTL+CL+WL+EC 99.75 99.11 94.16Table 4.1: Performance (F -measure %) of each model and SFSresult also indicates that the length-related featuresare still useful, even though they are relatively un-reliable.5 Error AnalysisIn order to understand more about the behaviorof the various features, we classify all errors whichoccurs in aligning Sinorama Magazine in Table 5.1;the error dominated by the prior distribution ofmatching type is called matching-type error, theerror dominated by length feature is called length-type error, and the error caused from both lengthfeatures and lexical-related features (either one isnot dominant) is called length&lexicon-type error6.From Table 5.1, it is found that the matching-type errors dominate in the baseline model.
Toinvestigate the matching-type error, the prior dis-tributions of matching-types under training set[Caterpillar User Manual] and testing set II [Sino-rama Magazine] are given in Table 5.2.
The com-parison clearly shows that the matching-type distri-bution varies significantly across different domains,and that explains why the baseline model (whichonly considers length-based features and matching-type distribution) fails to achieve the similar perfor-mance in the cross-style test.
However, as the ?1-1?matching-type always dominates in both texts, thematching-type distribution still provide useful in-formation for aligning sentences when it is jointlyconsidered with the lexical-related feature.
Forthose Length-Type errors generated from the base-line model in Table 5.1, different statistical char-acteristics across different styles are listed in Table6In our experiment, we do not find any error dominatedby lexical-related feature.5.3.
It also clearly shows that the associated statis-tical characteristics of those length-based featuresvary significantly across different styles.
Further-more, although English-cognates are reliable cuesfor aligning bi-lingual sentences and occurs quite afew times in the technical manual (such as companynames: IBM, HP, etc., and some special technicalterms such as ?RS-232?, etc), they almost never oc-cur in a general magazine such as the one that wetest.
Therefore, they provide no help for aligningcorpus in such domains.Table 5.1 also shows that errors distribute differ-ently in the proposed robust model.
The length-type, instead of matching-type, now dominates er-rors, which implies that the mismatching effectresulting from different distributions of matchingtypes has been diluted by the transfer-lexicon fea-ture.
Furthermore, the score of erroneous lexicon-type assignment never dominates any error foundin the proposed robust model, which verifies oursupposition that transfer-lexicons are more reliablecues for aligning sentences.To further investigate those remaining errorsgenerated from the proposed robust model, twoerror examples are given in Figure 1.
The firstcase shows an example of ?Length-Type Error?,in which the short sentence (E2) is erroneouslymerged with the long sentence (E1) and results inan erroneous alignment [E1, E2 : C1] and [E3 :C2].
(The correct alignment should be [E1 : C1]and [E2, E3 : C2].)
Generally speaking, if a shortsource sentence is enclosed by two long source sen-tences in both sides, and they are jointly trans-lated into two long target sentences, then it is errorprone compared with other cases.
The main rea-son is that this short source sentence would containonly a few words and thus its associated transfer-Proposed Robust Model Baseline ModeError Type Percentage (%) Error Type Percentage (%)Matching-Type Error 21.9 Matching-Type Error 81.2Length-Type Error 62.5 Length-Type Error 14.9Length&Lexicon-Type Error 15.6 Length&Lexicon-Type Error 3.9Table 5.1: Error Classification while aligning Sinorama Magazine1-0 0-1 1-1 1-2 2-1 2-2 1-3 3-1 1-4 4-1 4-2Caterpillar 0.1% 0.25% 93.58% 2.31% 3.4% 0.05% 0.11% 0.08% 0.06% 0 0Sinorama 0.28% 0 65.54% 1.69% 24.86% 0.28% 0 5.08% 0 1.98% 0.28%Table 5.2: Comparison of prior distributionsCognate Length Features (?c, ?w) ?cognate ?Transfer?LexiconOccurrence Rate7 c s2c w s2w r ?
?
?2Caterpillar 36.4% 0.65 0.87 3.45 6.09 -0.02 0.06 -0.72 0.21Sinorama 1.1% 0.59 1.79 2.76 7.80 -0.46 0.25 -0.60 0.02Table 5.3: List of all associated parameterslexicons are not sufficient enough to override thewrong preference given by the length-based feature(which would assign similar score to both merge-directions).The second case shows an example of?Length&Lexicon-Type Error?, in which thesource sentence (E1) is erroneously deleted andresults in an erroneous alignment [E1: Delete] and[E2 : C1].
(The correct alignment should be [E1,E2 : C1].)
The main reason is that the meaning ofsentence (E1) is similar to that of (E2) but statedin different words, and the translator has mergedthe redundant information in his/her translation.Therefore, the length-feature prefers to delete thefirst source sentence.
On the other hand, sincemost of those associated transfer-lexicons in thesource sentence E1 cannot be found in the corre-sponding target sentence C1, the Transfer-Lexiconfeature also prefers to delete the first sourcesentence E1.
It seems that this kind of errorswould require further knowledge from languageunderstanding to solve them, and is beyond thescope of this paper.7The occurrence rate is defined as ?Number of sentencesthat contained congates?/?Total number of sentences?6 ConclusionsAlthough those length-based approaches are sim-ple and can achieve good performance when theyare trained and tested in the corpora of thesame style, the performance drops significantlywhen they are tested in different styles otherthan that of the training corpora.
(For in-stance, the F -measure error increases from 1.8%to 14.4% in our experiment.)
The main reasonis that the statistical characteristics of those fea-tures adopted by the length-based approaches (suchas length-distribution, alignment-type-distributionand cognate-frequency) vary significantly from onestyle to another style.Since human align sentences mainly by examin-ing the similarity between different meanings con-veyed by the given bilingual sentences pair, not bycounting the number of characters in sentences, thetransfer-lexicon is expected to be the more reliablecue than the sentence length.
A robust statisticalsentences alignment model, which integrates the as-sociated transfer-lexicons into the original length-based model, is thus proposed in this paper.
Greatimprovement has been observed in our experiment,which reduces the F -measure error generated fromthe length-based model from 14.4% to 5.8%, whenthe proposed approach is tested in the cross-stylecase.Last, length-features, cognate-feature andtransfer-lexicon-feature are implicitly assumed tocontribute equally in aligning sentences in thispaper; however this assumption is not usuallyheld because different features might have variousdynamic ranges for their scores and thus contributedifferently to discrimination power.
To overcomethis problem, various features would be weighteddifferently in the future.AcknowledgementWe would like to thank both Prof. Hsin-Hsi Chenand Prof. Kuang-Hwa Chen for their kindly pro-viding us the aligned bi-lingual Sinorama Magazinefor conducting the above experiment.
The appre-ciation is also extended to our Translation ServiceCenter for providing the bilingual Caterpillar UserManual for this study.References1.
[Brown et al, 91] Peter F. Brown, Jennifer C. Lai,and Robert L. Mercer, (1991).
?Aligning Sentencesin Parallel Corpora?, Proceedings of the 29th An-nual Meeting of the Association for ComputationalLinguistics, pp.
169-176, 18-21 June 1991, UCBerkeley, California, USA.2.
[Brown et al, 93] Peter F. Brown, Stephen A. DellaPietra, Vincent J. Della Pietra and Robert L. Mer-cer, (1993).
?The Mathematics of Statistical Ma-chine Translation: Parameter Estimation?, Com-putational Linguistics 19: 263-311.3.
[Chen, 93] Stanley F. Chen, (1993).
?Aligning Sen-tences in Bilingual Corpora Using Lexical Infor-mation?, Proceedings of the 31th Annual Meetingof the Association for Computational Linguistics,pp.
9-16, 22-26 June 1993, Ohio State University,Columbus, Ohio, USA.4.
[Church, 93] Kenneth W. Church, (1993).
?Char align: A Program for Aligning ParallelTexts at the Character Level?, Proceedings of the31th Annual Meeting of the Association for Com-putational Linguistics, pp.1-8, 22-26 June 1993,Ohio State University, Columbus, Ohio, USA.5.
[Dagon et al, 91] Ido Dagon, Alon Itai and UlrikeSchwall, (1991).
?Two Language Are More Infor-mative Than One?, Proceedings of the 29th AnnualMeeting of the Association for Computational Lin-guistics, pp.
130-137, 18-21 June 1991, UC Berke-ley, California, USA.6.
[Devijver 82] Pierre A. Devijver and Josef Kittler,(1982).
Pattern Recognition: A Statistical Ap-proach, Prentice-Hall Inc., N.J., USA, 1982.7.
[Gale and Church, 93] William A. Gale and Ken-neth W. Church, (1991).
?A Program for AligningSentences in Bilingual Corpora?, ComputationalLinguistics 19:75-102.8.
[Och and Ney, 2000] Franz Josef Och and HermannNey, (2000).
?A Comparison of Alignment Modelsfor Statistical Machine Translation?, Proceedingsof the 38th Annual Meeting of the Association forComputational Linguistics, pp.
1086-1090, 1-8 Oc-tober 2000, Hong Kong.9.
[Rabiner and Juang, 93] Lawrence Rabiner andB.H.
Juang, (1993).
Fundamentals of SpeechRecognition, Prentice-Hall Inc., N.J., USA, 1993.10.
[Su et al, 95] K. Y. Su, J. S. Chang and UnaHsu, (1995).
?A Corpus-Based Statistics-OrientedTwo-Way Design?, Proceedings of TMI-95, Vol.
II,pp.
334-353, Centre for Computational Linguistics,Katholieke Universiteit Leuven, Leuven, Leuven,Belgium, July 5-7, 1995.11.
[Su and Chang, 99] K. Y. Su and J. S. Chang,(1999).
?A Customizable, Self-Learnable Param-eterized MT System: Text Generation?, Proceed-ings of MT SUMMIT VII, pp.
182-188, Singapore.
(Invited Talk)12.
[Vogel et al, 96] Stephan Vogel, Hermann Neyand Christoph Tillmann, (1996).
?HMM-BasedWord Alignment in Statistical Translation?, Pro-ceedings of the 34th Annual Meeting of the Associ-ation for Computational Linguistics, pp.
836-841,24-27 June 1996, UC Santa Cruz, California, USA.13.
[Wu, 94] Dekai Wu, (1994).
?Aligning a ParallelEnglish-Chinese Corpus Statistically with LexicalCriteria?, Proceedings of the 32th Annual Meetingof the Association for Computational Linguistics,pp.
80-87, 27-30 June 1994, New Mexico StateUniversity, Las Cruces, New Mexico, USA.
