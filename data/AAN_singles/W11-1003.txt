Proceedings of SSST-5, Fifth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 21?30,ACL HLT 2011, Portland, Oregon, USA, June 2011. c?2011 Association for Computational LinguisticsSemantic Mapping Using Automatic Word Alignment and Semantic RoleLabelingShumin WuDepartment of Computer ScienceUniversity of Colorado at Bouldershumin.wu@colorado.eduMartha PalmerDepartment of LinguisticsUniverisity of Colorado at Bouldermartha.palmer@colorado.eduAbstractTo facilitate the application of semantics instatistical machine translation, we proposea broad-coverage predicate-argument struc-ture mapping technique using automated re-sources.
Our approach utilizes automaticsyntactic and semantic parsers to gener-ate Chinese-English predicate-argument struc-tures.
The system produced a many-to-manyargument mapping for all PropBank argu-ment types by computing argument similaritybased on automatic word alignment, achieving80.5% F-score on numbered argument map-ping and 64.6% F-score on all arguments.
Bymeasuring predicate-argument structure sim-ilarity based on the argument mapping, andformulating the predicate-argument structuremapping problem as a linear-assignment prob-lem, the system achieved 84.9% F-score us-ing automatic SRL, only 3.7% F-score lowerthan using gold standard SRL.
The map-ping output covered 49.6% of the annotatedChinese predicates (which contains predicate-adjectives that often have no parallel annota-tions in English) and 80.7% of annotated En-glish predicates, suggesting its potential as avaluable resource for improving word align-ment and reranking MT output.1 IntroductionAs the demand for semantically consistent machinetranslation rises (Wu and Fung, 2009a), the needfor a comprehensive semantic mapping tool has be-come more apparent.
With the current architectureof machine translation decoders, few ways of in-corporating semantics in MT output include usingword sense disambiguation to select the correct tar-get translation (Carpuat and Wu, 2007) and reorder-ing/reranking MT output based on semantic con-sistencies (Wu and Fung, 2009b) (Carpuat et al,2010).
While a comprehensive semantic mappingtool can supplement or improve the results of suchtechniques, there are many other exciting ideas wecan explore: with automatic SRL, we can improvecoverage (and possibly accuracy) of Chinese seman-tic class generation (Wu et al, 2010) by running thesystem on a large, unannotated parallel corpus.
Us-ing predicate-argument mappings as constraints, itmay be possibly to improve SRL output by perform-ing joint inference of SRL in source and target lan-guages simultaneously, much like what Burkett andKlein (2008) was able to achieve with syntactic pars-ing.As the foundation of many machine translationdecoders (DeNeefe and Knight, 2009), word align-ment has continuously played an important role inmachine translation.
There have been several at-tempts to improve word alignment, most of whichhave focused on tree-to-tree alignments of syntac-tic structures (Zhang et al, 2007; Marec?ek, 2009a).Our hypothesis is that the predicate-argument struc-ture alignments can abstract away from languagespecific syntactic variation and provide a more ro-bust, semantically coherent alignment across sen-tences.We begin by running GIZA++ (Och and Ney,2003), one of the most popular alignment tools, toobtain automatic word alignments between parallelEnglish/Chinese corpora.
To achieve a broader cov-erage of semantic mappings than just those anno-21tated in parallel PropBank-ed corpora, we attemptto map automatically generated predicate-argumentstructures.
For each Chinese and English verb pred-icate pairs within a parallel sentence, we exam-ine the quality of both the predicate and argumentalignment (using GIZA++ word alignment output)and devise a many-to-many argument mapping tech-nique.
From that, we pose predicate-argument map-ping as a linear assignment problem (optimizing thetotal similarity of the mapping) and solve it withthe Kuhn-Munkres method (Kuhn, 1955).
Withthis approach, we were able to incur only a smallpredicate-argument F-score degradation over usingmanual PropBank annotation.
The output also pro-vides much more fine-grained argument mappingthat can be used for downstream MT applications.2 Related workOur basic approach to semantic mapping is similarto the idea of semantic similarity based on triangu-lation between parallel corpora outlined in Resnik(2004) and Madnani et al (2008a; 2008b), but isimplemented here quite differently.
It is most sim-ilar in execution to the work of (Marec?ek, 2009b),which improves word alignment by aligning tec-togrammatical trees in a parallel English/Czech cor-pus.
The Czech corpus is first lemmatized becauseof the rich morphology, and then the word alignmentis ?symmetrized?.
However, this approach does notexplicitly make use of the predicate-argument struc-ture to confirm the alignments or to suggest newones.Pado?
and Lapata (2005; 2006) used word align-ment and syntax based argument similarity toproject English FrameNet semantic roles to German.The approach relied on annotated semantic roles onthe source side only, precluding joint inferenece ofthe projection using reference or automatic targetside semantic roles.Fung et al (2007) demonstrated that there ispoor semantic parallelism between Chinese-Englishbilingual sentences.
Their technique for im-proving Chinese-English predicate-argument map-ping (ARGChinese,i 7?
ARGEnglish,j) consists ofmatching predicates with a bilingual lexicon, com-puting cosine-similarity (based on lexical transla-tion) of arguments and tuning on an unannotatedparallel corpus.
The system differs from ours inthat it only provided one-to-one mapping of num-bered arguments and may not be able to detectpredicate mapping with no lexical relations that arenevertheless semantically related.
Later, Wu andFung (2009b) used parallel semantic roles to im-prove MT system outputs.
Given the outputs fromMoses (Koehn et al, 2007), a machine translationdecoder, they reordered the outputs based on the bestpredicate-argument mapping.
The resulting systemshowed a 0.5 point BLEU score improvement eventhough the BLEU metric often discounts improve-ment in semantic consistency of MT output.Choi et al (2009) (and later Wu et al (2010))showed how to enhance Chinese-English verb align-ments by exploring predicate-argument structurealignment using parallel PropBanks.
The result-ing system showed improvement over pure GIZA++alignment.
Those two systems differs from oursin that they operated on gold standard parses andsemantic roles.
The systems also did not pro-vide explicit argument mapping between the alignedpredicate-argument structures.3 ResourcesTo perform automatic semantic mapping, we needan annotated corpus to evaluate the results.
In addi-tion, we also need a word aligner, a syntactic parser,and a semantic role labeler (as well as annotated andunannotated corpora to train each system).3.1 CorpusWe used the portion of the Penn Chinese TreeBankwith word alignment annotation as the basis for eval-uating semantic mapping.
The word-aligned por-tion, containing around 2000 parallel sentences, isexclusive to Xinhua News (and covers around 50%of the Xinhua corpus in the Chinese TreeBank).
Wethen merged the word alignment annotation with theTreeBank and PropBank annotation of Ontonotes4.0 (Hovy et al, 2006), which includes a wide ar-ray of data sources like broadcast news, news wire,magazine, web text, etc.
A small percentage of the2000 sentences were discarded because of tokeniza-tion differences.
We dubbed the resulting 1939 par-allel sentences as the triple-gold Xinhua corpus.223.2 Word AlignmentWe chose GIZA++ (Och and Ney, 2003) as our wordalignment tool primarily because of its popularity,though there are other alternatives like Lacoste-Julien et al (2006).3.3 Phrase Structure ParsingWe chose the Berkeley Parser (Petrov and Klein,2007) for phrase structure parsing since it has beentested on both English and Chinese corpora and canbe easily retrained.3.4 Semantic Role LabelingFor semantic role labeling (SRL), we built our ownsystem using a fairly standard approach: SRL isposed as a multi-class classification problem requir-ing the identification of argument candidates foreach predicate and their argument types.
Typi-cally, argument identification and argument label-ing are performed in two separate stages because oftime/resource constraints during training/labeling.For our system, we chose LIBLINEAR (Fan et al,2008), a library for large linear classification prob-lems, as the classifier.
This alleviated the need toseparate the identification and labeling stages: argu-ment identification is trained simply by incorporat-ing the ?NOT-ARG?
label into the training data.Most the of the features used by the classifier arestandard features found in many SRL systems; theseinclude:Predicate predicate lemma and its POS tagVoice indicates the voice of the predicate.
For En-glish, we used the six heuristics detailed byIgo (2007), which detects both ordinary andreduced passive constructions.
For Chinese,we simply detected the presence of passive in-dicator words (those with SB, LB POS tags)amongst the siblings of the predicate.Phrase type phrase type of the constituentSubcategorization phrase structure rule expandingthe predicate parentHead word the head word and its POS tag of theconstituentParent head word whether the head word of theparent is the same as the head word of the con-stituentPosition whether the constituent is before or afterthe predicatePath the syntactic tree path from the predicate tothe constituent (as well as various path general-ization methods)First word first word and its POS tag of the con-stituentLast word last word and its POS tag of the con-stituentSyntactic frame the siblings of the constituentConstituent distance the number of potential con-stituents with the same phrase type between thepredicate and the constituentWe also created many bigrams (and a few trigrams)of the above features.By default, LIBLINEAR uses the one-vs-all ap-proach for multi-class classification.
This does notalways perform well for some easily confusableclass labels.
Also, as noted by Xue (2004), cer-tain features are strong discriminators for argumentidentification but not for argument labeling, whilethe reverse is true for others.
Under such condi-tions, mixing arguments and non-arguments withinthe same class may produce sub-optimal results for abinary classifier.
To address these issues, we built apairwise multi-class classifier (using simple major-ity voting) on top of LIBLINEAR.The resulting English SRL system, evaluatedusing the CoNLL 2005 methodology, achieved a77.3% F-score on the WSJ corpus, comparable tothe leading system (Surdeanu and Turmo, 2005) us-ing a single parser output.
The Chinese SRL system,on the other hand, achieved 74.4% F-score on thetriple-gold Xinhua corpus (similar but not directlycomparable to Wu et al (2006) and Xue (2008)because of differences in TreeBank/PropBank revi-sions as well as differences in test set).4 Predicate-arguments mapping4.1 Argument mappingTo produce a good predicate-argument mapping, weneeded to consider 2 things: whether good argumentmapping can be produced based on argument typeonly, and whether each argument only maps to oneargument in the target language.234.1.1 Predicate-dependent argument mappingTheoretically, PropBank numbered arguments aresupposed to be consistent across predicates: ARG0typically denotes the agent of the predicate andARG1 the theme.
While this consistency may holdtrue for predicates in the same language, as Fung etal.
(2007) noted, this is not a reliable indicator whenmapping predicate-arguments between Chinese andEnglish.
For example, when comparing the Prop-Bank frames of the English verb arrive and the syn-onymous Chinese verb?
?, we see ARG1 (entity inmotion) for arrive.01 is equivalent to ARG0 (agent)of ?
?.01 while ARG4 (end point, destination) isequivalent to ARG1 (destiny).4.1.2 Many-to-many argument mappingJust as there are shortcomings in assuming pred-icate independent argument mappings, assumingone-to-one argument mapping may also be overlyrestrictive.
For example, in the following Chinesesentence:?
??
??
????
???
?
?big passage construction invigorated big southwest?s material flowthe predicate??
(invigorate) has 2 arguments:?
ARG0: ?
??
??
(big passage construc-tion)?
ARG1: ?
?????
(big southwest?s ma-terial flow)In the parallel English sentence:Construction of the main passage has activated theflow of materials in the great southwestactivate has 3 arguments:?
ARG0: construction of the main passage?
ARG1: the flow of materials?
ARGM-LOC: in the great southwestIn these parallel sentences, ARG1 of??
should bemapped to both ARG1 and ARGM-LOC of activate.While the English translation of?
?, invigorate,is not a direct synonym of activate, they at least havesome distant relationship as indicated by sharingthe inherited hypernym make in the WordNet (Fell-baum, 1998) database.
The same cannot be said forall predicate-pairs.
For example, in the followingparallel sentence fragments:??
??
?
?on the street people flow like the tidethe Chinese predicate-argument structure for?
(like) is:?
ARG0: ??
(flow of guests)?
ARG1: ?
(tide)?
ARGM-LOC:??
(on the street)while the English predicate-argument structure forflow is:?
ARG1: people?
ARGM-LOC: on the street?
ARGM-MNR: like the tideSemantically, the predicate-argument pairs areequivalent.
The argument mapping, however, ismore complex:?
?.ARG0??
flow.ARG1, flow.V?
?.V,?.ARG1??
flow.ARGM-MNR?
?.ARGM-LOC??
flow.ARGM-LOCTable 1 details the argument mapping for thetriple-gold Xinhua data.
The mapping distributionfor ARG0 and ARG1 is relatively deterministic (andsimilar to ones found by Fung et al (2007)).
Map-pings involving ARG2-5 and modifier arguments,on the other hand, are much more varied.
Typically,when there is a many-to-many argument mapping,it?s constrained to a one-to-two or two-to-one map-ping.
Much more rarely is there a case of a two-to-two or even more complex mapping.4.2 Word alignment based argument mappingTo achieve optimal mappings between parallelpredicate-argument structure, we would like to max-imize the number of words in the mapped argumentset (over the entire set of arguments) while minimiz-ing the number of unaligned words in the mappedargument set.Let ac,i and ac,j denote arguments in Chinese andEnglish respectively, AI as a set of arguments, Wc,ias words in argument ac,i, and mape(ai) = We,ias the word alignment function that takes the sourceargument and produces a set of words in the target24arg type A0 A1 A2 A3 A4 ADV BNF DIR DIS EXT LOC MNR PRP TMP TPC VA0 1610 79 25 0 0 28 1 0 0 0 8 5 1 11 1 9A1 432 2665 128 11 0 83 9 12 0 0 29 12 5 21 3 142A2 43 310 140 8 3 55 6 9 0 2 20 10 1 4 1 67A3 2 14 21 7 0 2 4 2 0 0 1 2 1 0 1 4A4 1 37 9 3 6 0 0 0 0 0 1 0 1 0 0 4ADV 33 36 9 6 0 307 2 5 6 0 44 121 6 11 2 19CAU 1 0 0 0 0 1 0 0 0 0 0 0 16 0 0 1DIR 1 13 3 2 0 1 0 3 0 0 3 0 0 0 0 20DIS 2 0 0 0 0 69 0 0 40 0 2 1 3 3 0 0EXT 0 4 0 0 0 26 0 0 0 0 0 0 0 0 0 2LOC 23 65 13 1 0 3 1 0 0 0 162 0 0 5 0 4MNR 9 9 5 0 0 260 0 0 0 1 3 34 0 0 0 25MOD 1 0 0 0 0 159 0 0 0 0 0 0 0 0 0 84NEG 0 0 0 0 0 24 0 0 0 0 0 0 0 0 0 5PNC 3 23 11 4 0 1 6 1 0 0 1 2 35 2 0 8PRD 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 1TMP 14 21 2 0 0 235 0 3 0 1 8 16 0 647 0 6V 25 28 22 1 0 211 1 0 1 0 2 12 0 0 0 3278Table 1: Chinese argument type (column) to English argument type (row) mapping on triple-gold Xinhua corpuslanguage sentence.
We define precision as the frac-tion of aligned target words in the mapped argumentset:Pc,I =|(?i?Imape(ac,i)) ?
(?j?JWe,j)||?i?Imape(ac,i)|(1)and recall as the fraction of source words in themapped argument set:Rc,I =?i?I |Wc,i|?
?i |Wc,i|(2)We then choose Ac,I that optimizes the F1-score ofPc and Rc:Ac,I = argmaxI2 ?
Pc,I ?Rc,IPc,I +Rc,I= Fc,I (3)Finally, to constrain both source and target argumentset, we optimize:Ac,I , Ae,J = argmaxI,J2 ?
Fc,I ?
Fe,JFc,I + Fe,J= FIJ (4)To measure similarity between a single pair ofsource, target arguments, we define:Pij =|mape(ac,i) ?Wj ||mape(ac,i)|, Rij =|mapc(ae,j) ?Wi||mapc(ae,j)|(5)To generate the set of argument mapping pairs, wesimply choose all pairs of ac,i, ae,j ?
Ac,I , Ae,Jwhere Fij ?
 ( > 0).Directly optimizing equation 4 requires exhaus-tive search of all argument set combinations betweenthe source and target, which is NP-complete.
Whilethe typical number of arguments for each predicateis relatively small, this is nevertheless inefficient.We performed the following greedy-based approx-imation with quadratic complexity:1.
Compute the best (based on F-score of equa-tion 5) pair of source-target argument mappingsfor each source argument (target argument maybe reused)2.
Select the remaining argument pair with thehighest F-score3.
Insert the pair in Ac,I , Ae,J if it increases FIJ ,else discard4.
repeat until all argument pairs are exhausted5.
repeat 1-4 reversing the source and target direc-tion6.
merge the output of the 2 directionsMuch like GIZA++ word alignment where the out-put of each direction produces only one-to-manymappings, merging the output of the two directionsproduces many-to-many mappings.254.3 One-to-one predicate-argument mappingTo find the best predicate-argument mapping be-tween Chinese and English parallel sentences, weassume each predicate in a Chinese or English sen-tence can only map to one predicate in the targetsentence.
As noted by Wu et al (2010), this as-sumption is mostly valid for the Xinhua news cor-pus, though occasionally, a predicate from one sen-tence may align more naturally to two predicates inthe target sentence.
This typically occurs with verbconjunctions.
For example the Chinese phrase ???
???
(sightseeing and tour) is often translatedto the single English verb ?travel?.
As noted by Xueand Palmer (2009), the Chinese PropBank annotatespredicative adjectives, which tend not to have anequivalent in the English PropBank.
Additionally,some verbs in one language are nominalized in theother.
This results in a good portion of Chinese orEnglish predicates in parallel sentences not havingan equivalent in the other language.With the one-to-one mapping constraint, we op-timize the mapping by maximizing the sum of theF1-scores (as defined by equation 4) of the predi-cates and arguments in the mapping.
Let PC and PEdenote the sets of predicates in Chinese and Englishrespectively, with G(PC , PE) = {g : PC 7?
PE} asthe set of possible mappings between the two predi-cate sets, then the optimal mapping is:g?
= argmaxg?G?i,j?gFCi,Ej (6)To turn this into a classic linear assignment problem,we define Cost(PCi , PEj ) = 1 ?
FCi,Ej , and (6)becomes:g?
= argming?G?i,j?gCost(PC,i, PE,j) (7)(7) can be solved in polynomial time with the Kuhn-Munkres algorithm (Kuhn (1955)).5 Experimental setup5.1 Reference predicate-argument mappingTo generate reference predicate-argument map-pings, we ran the mapping system described in sec-tion 4.2 with a cutoff threshold of FCi,Ej < 0.65(i.e., alignments with F-score below 0.65 are dis-carded).
We reviewed a small random sample of theoutput and found it to have both high precision andrecall, with only occasional discrepancies caused bypossible word alignment errors.
If one-to-one argu-ment mapping is imposed, the reference predicate-argument mapping will lose 8.2% of the alignments.For mappings using automatic word alignment, wechose a cutoff threshold of FCi,Ej < 0.15.
This caneasily be tuned for higher precision or recall basedon application needs.5.2 Parser, SRL, GIZA++We trained the Berkeley parser and our SRL sys-tem on Ontonotes 4.0, excluding the triple-gold Xin-hua sections as well as the non-English or Chinesesourced portion of the corpus.
GIZA++ was trainedon 400K parallel Chinese-English sentences fromvarious sources with the default parameters.
Forthe word mapping functions mape(ac), mapc(ae)in equation 5, instead of taking the word align-ment intersection of the source-target and target-source directions as Pado?
and Lapata (2006), weused the two alignment outputs seperately (using theChinese-English output when projecting Chinese ar-gument to English words, and vice versa).
On av-erage (from the 400K corpus), an English sentencecontains 28.5% more tokens than the parallel Chi-nese sentence (even greater at 36.2% for the Xinhuaportion).
Taking either the intersection or union willsignificantly affect recall or precision of the align-ment.6 Results6.1 Semantic role labelingWe first provide some results of the SRL system onthe triple-gold Xinhua corpus in table 2.
Unlike theconventional wisdom which expects English SRLto outperform Chinese SRL, when running on theChinese-sourced Xinhua parallel corpus, our SRLactually performed better on Chinese than English(74.4% vs 71.8% F-score).
The Berkeley parseroutput also seemed to be of higher quality on Chi-nese; the system was able to pick out better con-stituent candidates in Chinese than English, as ev-idenced by the higher recall for oracle SRL (92.6%vs 91.1%).
Comparing the quality of the output byargument type, we found the only argument typewhere the Chinese SRL system performed signifi-26language type P R F1ChineseCoNLL 77.9% 71.1% 74.4%oracle 100% 92.6% 96.1%word match 84.8% 74.6% 79.4%EnglishCoNLL 75.6% 68.4% 71.8%oracle 100% 91.1% 95.2%word match 82.7% 69.4% 75.5%Table 2: SRL results on triple-gold Xinhua corpus.
?argmatch?
is the standard CoNLL 2005 evaluation metric,?oracle?
is the oracle SRL based on automatic parser out-put, and ?word match?
is scoring based on length of ar-gument overlap with the referencecantly worse is ARG0 (almost 10% F-score lower).This is likely caused by dropped pronouns in Chi-nese sentences (Yang and Xue, 2010), making itharder for both the syntactic and semantic parsersto identify the correct subject.We also report the SRL result scored at word levelinstead of at argument level (79.4% F-score for Chi-nese and 75.5% for English).
The CoNLL 2005shared task scoring (Surdeanu and Turmo, 2005)discounts arguments that are not a perfect word spanmatch, even if the system output is semanticallyclose to the reference argument.
While this is im-portant in some applications of SRL, for other ap-plications like improving word alignment with SRL,improving recall on approximate arguments may bea better trade-off than having high precision on per-fectly matched arguments.
We noticed that whileoverall improvement in SRL improves both wordlevel and argument level performance, for other-wisely identical systems, we can slightly favor wordlevel performance (up to 1-3% F-score) by includ-ing positive training samples that are not a perfectargument match.6.2 Predicate-argument mappingTable 3 details the results of Chinese-Englishpredicate-argument mapping.
Using automatic SRLand word alignment, the system achieved an 84.9%F-score, only 3.7% F-score less than using gold stan-dard SRL annotation.
When looking at only ar-guments, however, the differences are larger: au-tomatic SRL based output produced an 80.5% F-score for core arguments.
While this compares fa-vorably to Fung et al (2007)?s 72.5% (albeit withEvaluation gold P R F1predicate- yes 88.7% 88.5% 88.6%argument no 84.6% 85.3% 84.9%A0-5 labelyes 97.8% 96.2% 97.0%no 87.0% 74.9% 80.5%A0-5 span no 67.9% 57.9% 62.5%all arg labelyes 84.0% 79.3% 81.6%no 70.3% 59.8% 64.6%all arg span no 61.6% 52.2% 56.5%Table 3: Predicate-argument mapping resultsdifferent sections of the corpus), it?s 16.5% F-scorelower than gold SRL based output.
When includingall arguments, automatic SRL based output achieved64.6% while the gold SRL based output achieved81.6%.
This indicates that the mapping result forall arguments is limited by errors in word alignment.We also report the results of automatic SRL on bothproducing the correct argument mappings and wordspans (62.5% for core arguments and 56.5% for allarguments).
This may be relevant for applicationssuch as joint inference between word alignment andSRL.We also experimented with discriminative(reweighing) word alignment based on part-of-speech tags of the words to improve the mappingsystem but were not able to achieve better results.This may be due to the top few POS types account-ing for most of the words in a language, therefore itdid not prove to be a strong discriminator.6.3 Mapping coverageTable 4 provides predicate and word coverage de-tails of the predicate-argument mapping, anotherpotentially relevant statistic for applications ofpredicate-argument mapping.
High coverage ofpredicates and words in the mappings may providemore relevant constraints to help reorder MT outputor rerank word alignment.
We expect labeling En-glish nominalized predicate-arguments will help in-crease both predicate and word coverage in the map-ping output.In order to build a comprehensive probabilitymodel of Chinese-English predicate-argument map-ping, we applied the mapping technique on an unan-notated 400K parallel sentence corpus.
Automatic27output type language coveragetriple-goldpredicate Chinese 50.0%predicate English 81.3%word Chinese 66.0%word English 64.2%automaticpredicate Chinese 49.6%predicate English 80.7%word Chinese 57.4%word English 55.4%Table 4: Predicate-argument mapping coverage.
Predi-cate coverage denotes the number of mapped predicatesover all predicates in the corpus, word coverage denotesthe number of words in the mapped predicate-argumentsover all words in the corpuslanguagePropBank appeared appearedverb framesets in corpus in mappingChinese 16122 8591 7109English 5473 3689 3121Table 5: Frameset coverage on the 400K parallel sentencecorpusSRL found 1.6 million Chinese predicate instancesand 1.3 million English predicate instances.
Themapping system found around 700K predicate-pairs(with FC,E < 0.3).
Table 5 shows the number ofunique verbs in the corpus and contained in the map-ping results within the Chinese and English Prop-Bank verb framesets.
The corpus also included someverbs that do not appear in PropBank framesets.7 Conclusion and future workWe proposed a broad-coverage predicate-argumentmapping system using automatically generated wordalignment and semantic role labeling.
We alsoprovided a competitive Chinese and English SRLsystem using a LIBLINEAR classifier and pair-wise multi-class classification approach.
By explor-ing predicate-argument structure, the mapping sys-tem is able to generate mappings between seman-tically similar predicate-argument structures con-taining non-synonymous predicates, achieving an84.9% F-score, only 3.7% lower than the F-scoreof gold-standard SRL based mappings.
Utilizingword alignment information, the system was ableto provide detailed many-to-many argument map-pings (occurs in 8.2% of the reference mappings)for core arguments and modifier arguments, achiev-ing an 80.5% F-score for core arguments and 64.6%F-score for all arguments.While our experiment with discriminative wordalignment based on POS tags did not show improve-ment, there are other word grouping/weighing met-rics like n-gram based clustering, verb classification,term frequency, that may be more appropriate for se-mantic mapping.
With the advent of a predicate-argument annotation resource for nominalization,Ontonotes 5, we plan to update our SRL systemto produce nominalized predicate-arguments.
Thiswould potentially increase the predicate-argumentmapping coverage in the corpus as well as increasingthe accuracy of mapping (by reducing the number ofunmappable predicate-arguments), making the map-ping more useful for downstream applications.We are also experimenting with a probabilis-tic approach to predicate-argument mapping to im-prove the robustness of mapping against word align-ment errors.
Using the output of the current sys-tem on a large corpus, we can establish mod-els for p(prede|predc), p(arge|predc, prede, argc)and refine them through iterations of expectation-maximization.
If this approach shows promise, thenext step would be to explore integrating the map-ping model directly into GIZA++ for joint inferenceof word alignment and predicate-argument mapping.Other statistical translation specific applications wewould like to explore include extensions of MT out-put reordering (Wu and Fung, 2009b) and rerank-ing using predicate-argument mapping, as well aspredicate-argument projection onto the target lan-guage as an evaluation metric for MT output.AcknowledgementWe gratefully acknowledge the support of theNational Science Foundation Grants CISE- CRI-0551615, and a grant from the Defense AdvancedResearch Projects Agency (DARPA/IPTO) underthe GALE program, DARPA/CMO Contract No.HR0011-06-C-0022, subcontract from BBN, Inc.Any opinions, findings, and conclusions or recom-mendations expressed in this material are those ofthe authors and do not necessarily reflect the viewsof the National Science Foundation.28ReferencesDavid Burkett and Dan Klein.
2008.
Two languages arebetter than one (for syntactic parsing).
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?08, pages 877?886,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Marine Carpuat and Dekai Wu.
2007.
Improving sta-tistical machine translation using word sense disam-biguation.
In The 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Compu-tational Natural Language Learning (EMNLP-CoNLL2007), pages 61?72.Marine Carpuat, Yuval Marton, and Nizar Habash.
2010.Improving arabic-to-english statistical machine trans-lation by reordering post-verbal subjects for align-ment.
In Proceedings of the ACL 2010 ConferenceShort Papers, ACLShort ?10, pages 178?183.Jinho D. Choi, Martha Palmer, and Nianwen Xue.
2009.Using parallel propbanks to enhance word-alignments.In Proceedings of ACL-IJCNLP workshop on Linguis-tic Annotation (LAW?09), pages 121?124.Steve DeNeefe and Kevin Knight.
2009.
Synchronoustree adjoining machine translation.
In Proceedings ofthe 2009 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP?09), volume 2, pages727?736.R.-E.
Fan, K.-W. Chang, C.-J.
Hsieh, X.-R. Wang, andC.-J.
Lin.
2008.
Liblinear: A library for large linearclassification.
Journal of Machine Learning Research,9:1871?1874.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press.Pascale Fung, Zhaojun Wu, Yongsheng Yang, and DekaiWu.
2007.
Learning bilingual semantic frames: Shal-low semantic parsing vs. semantic role projection.
In11th Conference on Theoretical and MethodologicalIssues in Machine Translation, pages 75?84.Eduard Hovy, Mitchell Marcus, Martha Palmer, LanceRamshaw, and Ralph Weischedel.
2006.
Ontonotes:The 90 In Proceedings of HLT-NAACL 2006, pages57?60.Sean Paul Igo.
2007.
Identifying reduced passive voiceconstructions in shallow parsing environments.
Mas-ter?s thesis, University of Utah.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the Annual Meeting of the Association for Com-putational Linguistics (ACL?07), demonstration ses-sion, pages 177?180.Harold W. Kuhn.
1955.
The hungarian method for theassignment problem.
Naval Research Logistics Quar-terly, 2:83?97.Simon Lacoste-Julien, Ben Taskar, Dan Klein, andMichael I. Jordan.
2006.
Word alignment viaquadratic assignment.
In Proceedings of the mainconference on Human Language Technology Confer-ence of the North American Chapter of the Associa-tion of Computational Linguistics, HLT-NAACL ?06,pages 112?119, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Nitin Madnani, Philip Resnik, Bonnie Dorr, and RichardSchwartz.
2008a.
Applying automatically generatedsemantic knowledge: A case study in machine trans-lation.
In NSF Symposium on Semantic KnowledgeDiscovery, Organization and Use.Nitin Madnani, Philip Resnik, Bonnie Dorr, and RichardSchwartz.
2008b.
Are multiple reference translationsnecessary?
investigating the value of paraphrased ref-erence translations in parameter optimization.
In Pro-ceedings of the 8th Conference of the Association forMachine Translation in the Americas (AMTA?08).David Marec?ek.
2009a.
Improving word alignment us-ing alignment of deep structures.
In Proceedings ofthe 12th International Conference on Text, Speech andDialogue, pages 56?63.David Marec?ek.
2009b.
Using tectogrammatical align-ment in phrase-based machine translation.
In Proceed-ings of WDS 2009 Contributed Papers, pages 22?27.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Sebastian Pado?
and Mirella Lapata.
2005.
Cross-linguistic projection of role-semantic information.
InProceedings of the conference on Human LanguageTechnology and Empirical Methods in Natural Lan-guage Processing, HLT ?05, pages 859?866, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Sebastian Pado?
and Mirella Lapata.
2006.
Optimalconstituent alignment with edge covers for semanticprojection.
In Proceedings of the 21st InternationalConference on Computational Linguistics and the 44thannual meeting of the Association for ComputationalLinguistics, ACL-44, pages 1161?1168, Stroudsburg,PA, USA.
Association for Computational Linguistics.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In In HLT-NAACL ?07.Philip Resnik.
2004.
Exploiting hidden meanings: Usingbilingual text for monolingual annotation.
In Alexan-der Gelbukh, editor, Lecture Notes in Computer Sci-ence 2945: Computational Linguistics and IntelligentText Processing, pages 283?299.
Springer.29Mihai Surdeanu and Jordi Turmo.
2005.
Semantic rolelabeling using complete syntactic analysis.
In Pro-ceedings of CoNLL-2005 shared task, pages 221?224.Dekai Wu and Pascale Fung.
2009a.
Can semanticrole labeling improve smt?
In Proceedings of the13th Annual Conference of the EAMT, pages 218?225,Barcelona, Spain.Dekai Wu and Pascale Fung.
2009b.
Semantic roles forsmt: A hybrid two-pass model.
In Proceedings of theNorth American Chapter of the Association for Com-putational Linguistics - Human Language Technolo-gies (NAACL-HLT?09), pages 13?16.Zhaojun Wu, Yongsheng Yang, and Pascale Fung.2006.
C-assert: Chinese shallow semantic parser.http://hlt030.cse.ust.hk/research/c-assert/.Shumin Wu, Jinho D. Choi, and Martha Palmer.
2010.Detecting cross-lingual semantic similarity using par-allel propbanks.
In Proceedings of the 9th Confer-ence of the Association for Machine Translation in theAmericas.Nianwen Xue and Martha Palmer.
2009.
Adding se-mantic roles to the chinese treebank.
Nat.
Lang.
Eng.,15(1):143?172.Nianwen Xue.
2004.
Calibrating features for semanticrole labeling.
In Proceedings of EMNLP 2004, pages88?94.Nianwen Xue.
2008.
Labeling chinese predicateswith semantic roles.
Computational Linguistics,34(2):225?255.Yaqin Yang and Nianwen Xue.
2010.
Chasing the ghost:recovering empty categories in the chinese treebank.In Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters, COLING ?10,pages 1382?1390, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Min Zhang, Hongfei Jiang, Ai Ti Aw, Jun Sun, Sheng Li,and Chew Lim Tan.
2007.
A tree-to-tree alignment-based model for statistical machine translation.
In Ma-chine Translation Summit XI.30
