UNL/USL : MUC-3 TEST RESULTS AND ANALYSI SJitender S .
DeogunDepartment of Computer Science & Engineerin gUniversity of Nebraska - LincolnLincoln, NE 68588-0115deogun @ferg;vax.
unl .
edu(402)-472-503 3Vijay V. RaghavanCenter for Advanced Computer Studie sUniversity of Southwestern LouisianaLafayette, LA 70504-4330raghavan@cacs .usl.edu(318)-231-660 3RESULTSThis report describes the results from the required run in addition to the five optional runs for theMuc-3 task.
One purpose of the optional runs is to investigate the precision-recall tradeoff.
Two ofthe optional runs (options 1 and 4) were also submitted to Nose, making up a total of three officialruns .The experiments are conducted using three different training sets selected from the corpus of1300 messages for which the key-templates have been manually generated during the first phas eof the Muc-3 project .
The Training Set 1 (200 messages) and the Training Set 2 (300 messages)contain an almost equal number of relevant and non-relevant messages where a message is terme drelevant if it generates at least one template .
The Training Set 1 is a proper subset of Training Se t2 .
The Training Set 3 (306 messages) contains only those messages that are relevant and generat eone and only one template .
The occurrence distribution of the various incident types for the threetraining sets are presented in Table 1 .
The *ed rows indicate which of the incident types have enoughoccurrences in the training set to be learnable.
Similarly, not all fills associated with other slots ar elearnable .In any run, only two of the three training sets are used .
One of these two training sets is usedto develop a rule vector (termed as the optimal_query) that can identify a message as being relevantto the Muc-3 task.
The other training set is used to develop concept rule vectors that can identifywhich among the various possible slot fills are actually applicable' to a message .
Since our systemmainly deals with slots for which fills come from a predefined set of fills (i.e .
these are identifiedwith concepts to be learned), the number of concept rule vectors that pertain to each slot is not to omany .The activation value for a slot fill with respect to a test message is computed as the dot productof the concept rule vector and the message representation (as a vector) .
For the required and someof the optional runs (options 2, 4, and 5), the system decides that a slot fill applies if its activatio nvalue with respect to the rule vector forte slot fill is greater than a dynamically generated threshol dT1 .
This threshold for a given slot fill is based on the percentage of messages in the training set towhich the set fill is applicable and the histogram depicting the distribution of the activation value s1 "applicable" means relevance of fill to a message120Incident Training Training TrainingType Set 1 Set 2 Set 3ARSON 10 11 5ARSON THREAT 0 1 0MURDER 59 79 13 8DEATH THREAT 9 12 8BOMBING 42 63 7 1BOMB THREAT 0 1 1KIDNAPPING 15 17 2 5KIDNAPPING THREAT 0 0 0HIJACKING 0 0 0HIJACKING THREAT 0 0 0ROBBERY 4 8 8ROBBERY THREAT 0 0 0ATTACK 23 43 44ATTEMPTED ARSON 0 0 0ATTEMPTED MURDER 1 5 7ATTEMPTED BOMBING 9 12 8ATTEMPTED KIDNAPPING 0 0 0ATTEMPTED HIJACKING 0 0 0ATTEMPTED ROBBERY 0 0 0Total relevant 124 172 806Total nonrelevant 78 128 0incident types for which concept rule vectors are generated bythe learning module .Table 1 : Frequency of incident types in training setsTes tRunOptima lQuery"Set-list typ efills or Concepts"'Threshold CommentRequire dOption 1Option 2Option 3Option 4Option 5Training Set 1Training Set 1Training Set 2Training Set 2Training Set 2Training Set 2Training Set 2Training Set 2Training Set 1Training Set 1Training Set 3Training Set 3Ti0Ti0TiTi No phrase sOptimal query needs non-relevant messages in the training set .When non-relevant messages are present in the training set for concepts ,they are treated as negative examples for every concept .Table 2 : Different parameter settingsin the test set of messages for this slot fill .
A second option is to use a zero threshold implying thatthe slot fill is applicable if the activation value of the corresponding rule vector with respect to th emessage representation is positive .The training sets and the threshold setting used for official and optional test runs are presente din Table 2 .
The number of templates generated are compared in Table 3 and detailed results interms of precision, recall, and overgeneration for Option 4 are presented in Table 4 .
Since oursystem placed an emphasis on set list type slot fills, our system's performance, with respect to setfills only, for the various test runs, is summarized in Table 5 .
The results for Options 2, 3, and 5 ,shown in Tables 3 and 5, are scored at our site rather than by official scorers .
Consequently, thesefigures are not completely consistent with those of the other options .
In our assessment, the recaland precision values of our scoring are lower in Table 3 than what they would have been if score dby the official scorers .
In contrast, the same options in Table 5 are somewhat inflated compared t owhat the official scoring would have yielded .
With this disparity in mind, the following observationsare made on results from different runs :Required Run (Official-1) The official run generated a large number of templates .
This runresulted in a moderate recall and moderate precision .Option 1 (Official-2) The run for option 1 does not generate many templates .
This option use sa stricter or higher threshold for concepts compared to the Official-1 run .
Therefore, thi smethod achieves a low recall with a reasonable level of precision .
This option sacrifices recalto improve precision considerably .Option 2 This option, when compared to the required run, evaluates the impact of swapping the*12 1Template sTest Possible Actual Correct Incorrect Spurious Missing Recall Precision Overgeneratio nRequired 108 143 62 0 81 46 57 43 5 7Option 1 104 63 37 0 26 67 36 59 4 1Option 2 105 125 44 0 81 61 42 35 6 5Option 3 103 53 26 0 27 77 25 49 5 1Option 4 107 108 56 0 52 51 52 52 48Option 5 108 133 54 0 79 54 50 41 59Table 3 : Results from different tests for Template-id slo tSlot Recall Precision Overgeneratio nTemplate-Id 52 52 48Incident-Type 50 95 0Category 38 58 20Org-Perps 25 18 76Perp-Confidence 4 10 54Phys-Target-Types 1 50 0Human-Target-Types 7 43 4Incident-Location 25 26 55Phys-Effects 11 33 1 7Human-Effects 4 28 28Matched only 27 41 45Matched/Missing 15 41 45All Templates 15 23 89Set Fills Only 18 57 20Table 4 : Detailed results for Option 4Summary aetillsTest Possible Actual Correct Incorrect Spurious Missing Recall Precision OvergenerationRequired 570 223 67 38 73 420 16 40 3 3Option 1 547 61 35 3 9 495 8 89 1 5Option 2 557 172 107 5 40 425 20 64 2 5Option 3 544 48 37 0 8 504 7 77 1 7Option 4 568 179 80 20 35 424 18 57 2 0Option 5 571 208 139 4 41 404 25 68 20Table 5 : Results from different tests based on SET FILLS ONLY row12 2two training sets used for optimaLquery versus the other concepts.
The effects on recall andprecision are insignificant .Option 3 Option 3 used the same training sets as option 2 but the threshold was set to default .This led to a sharp drop in the total number of templates resulting in a much smaller valu efor recall .
But as in option 1, there is significant improvement in precision .
Comparing option2 to option 3 serves the same purpose as comparing option 1 to the required run .Option 4 (Official-3) This option used the Training Set 3 to develop the rule vectors for slo tfills .
When compared to option 2, this provides an assessment of the effectiveness of replacingTraining Set 1 by Training Set 3 for learning rule vectors for various possible slot fills .
Thisoption results in a large number of templates compared to the other options .
The use ofTraining Set 3 makes the examples in the training set relatively cleaner.
The method retainsthe level of recall roughly at the same level as the Official-1 run and option 2 while improvin gprecision .Option 5 Option 5 is meant to test the effect of the use of phrases on the development of rule vector .The results from this test are similar to those from option 4 .
Since we have obtained othe rresults (not reported) where the use of phrases is helpful, we feel that the results concerningphrases is not yet conclusive.EXPLANATION OF TEST SETTING SIn each experiment, two different training sets are employed .
A new (test) message is processe dagainst the optimaLquery computed from the first training set .
The message is processed withrespect to the rule vectors corresponding to all the possible slot fills, as computed from the secon dtraining set .
A message is deemed relevant to Muc-database either if it is sufficiently similar t othe optimaLquery or, based on the concepts that are applicable and the rules in the rulebase, th einference engine evaluates the root concept to be true .
Since the second training set is used to develo prule vectors for different slot fills, it is desirable that the training set messages contain incidence o fall the slot fills .
If there are no examples corresponding to a slot fill, the system is unable to develo pa rule vector for that fill and consequently, cannot recognize the occurrence of that slot fill in anew message .
The way in which training sets are used enables us to test the effects of not only th esize of the training set, but also the quality in terms of training messages being non-ambiguous an dnoise-free .The second variable in the optional testing - the threshold activation value - is used to selec tor ignore a slot fill.
The system compares the representation of each message with respect to therule vectors and computes an activation value for the corresponding slot fill .
The default activatio nvalue is taken to be C., that is, a slot fill is deemed applicable if the activation value of its rule vecto rwith respect to the message is positive .
A precision-recall tradeoff can be achieved by changing th evalue of the threshold activation value .
If this threshold is lowered, a concept becomes applicable t omore messages resulting in an improvement in recall at the cost of precision .EFFORTThe team for the Muc-3 project consisted of two professors, three graduate research assistants, an dfour part-time programmers .
The following graduate students made significant contributions to thi sproject: V. K. Elayavalli and Y. Zhang of usL, and S. K. Bhatia of UNL .
The bulk of the effort wasspent on the process for phrase extraction, followed by selection of training set, developing inferenc eengine for the rulebase and the template filler .
The learning and use of scoring program also took aconsiderable amount of time .123LIMITING FACTOR SThe biggest limiting factor was time .
Our estimation of the time and manpower for the project wasalso affected, in part, by a lack of participation in MUC-1 and MUC-2 .
The project often competed ,usually unsuccessfully, for the time of graduate students because of their classes and examinations .A lot of effort was spent on the extraction and the use of phrases .
However, this effort did notprovide much contribution as the phrase information was not exploited to its limits .
Towards theend, we succeeded in developing interesting techniques for phrase extraction and usage but coul dnot realize the benefits due to time constraints .
In retrospect, we feel that we should have spentmore time on template filler module than on indexing module .TRAININ GThe quality and size of training sets have tremendous effect on the performance of the system .
Alimitation of hardware affected the size of training set that could be selected .
A large training setrequired larger main memory and computer time for different modules in the project than could b eafforded by the limited computing resources at the two campuses .
Again, the computing resource shad to be shared with instructional and other research users which had an adverse effect on th eresources for the project .
Limited hardware resources were responsible for our search for a goodtraining set .
In this project, we were limited to use at most 300 messages in the training set du eto memory and time constraints .
Our initial approach was to manually select some messages t odevelop the training set .
Later, we developed the training set through a program by selecting onl ythose messages that addressed exactly one incident type.Ideally, the training set should contain enough messages such that all possible set fills are suffi-ciently represented .
If the training set does not contain any message addressing a certain slot fill,the system is incapable of recognizing that slot fill .
We also developed a module which could b eused to select a training set by computing the representational similarity of messages in the test setto those in the development set .
Unfortunately, the module was not tested well enough to be usedfor the MuC-3 official testing .DOMAIN INDEPENDENCENearly all of the system can be used independent of the domain of application .
The system auto-matically learns the rule vectors corresponding to different slot fills and uses these rule vectors t oidentify the slot fills in new messages .
The only domain dependent part of the system is the rulebase that is used to decide the relevance of a message depending on whether certain concepts ar eapplicable to the message in a desired combination .CONCLUSIO NMuC-3 provided us with a unique opportunity to test our ideas on conceptual classification of doc-uments in the area of message understanding .
Our approach is based on the recognition of messagecontents rather than actually understanding the messages .
The recognition of certain patterns in amessage allows the system to conclude whether certain subjects are addressed in a message .
Thesystem is, however, highly sensitive to the selection of a good training set .In the context of a MUC-like task, the system is capable of recognizing the presence or absenc eof different concepts that correspond to fills drawn from a set of values .
Specifically, our system canefficiently identify the domain of a message and which among certain salient concepts are addressed .For example, in the case of Option 4 run, the recall and precision associated with the optimal_quer yvector is respectively 0 .78 and 0 .88 (i .e .
if the question is whether at least one template shoul dbe generated) .
The performance, in terms of precision, is also impressive in certain slots such a s124INCIDENT TYPE(S) and effects on PHYSICAL OR HUMAN TARGETS .
Furthermore, the concept rul evectors are found to be successful in identifying relevant paragraphs within messages .
In manyapplication environments, such capabilities may be adequate.
Furthermore, our system may be usedas a front-end to a comprehensive message understanding system .The system has only a limited ability to identify fills that are of string type appearing in th emessages .
Phrase extraction, combined with the locality of information, was particularly useful i nfilling certain slots that require string fills.
The process to extract and use phrase information canbe exploited to a greater extent than has been done in the present system .The system can be improved by the following enhancements.
From a domain independent view-point, the system can benefit from a more robust procedure for training set selection.
Moreover, theprocess to extract and use phrase information can be exploited to a greater extent .
For improvingthe performance in the current domain, the template filler module can be modified by taking int oaccount the information regarding dependencies between different slot fills .
In general, much moreeffort is needed in designing the template filler module .125PART III : SYSTEM DESCRIPTIONSThe papers in this section, which were prepared by each of the fifteen site sthat completed the MUC-3 evaluation, describe the systems that were tested .
Th epapers are intended not only to outline each system's architecture but also t oprovide the reader with an understanding of the effectiveness of the technique sthat were used to handle the particular phenomena found in the MUC-3 corpus .
Tomake the discussion of these techniques concrete, most of the sites make specifi creference to some of the phenomena found in message TST1-MUC3-0099 from th edry-run test set and discuss their system's handling of those phenomena .
The fulltext and answer key templates for that message are found in appendix H of th eproceedings .The sites were asked to include the following pieces of information in this paper :* Background : how/for what the system was developed, an dhow much time was spent on the system before MUC-3* Explanation of the modules of the syste m* Explanation of flow of control (interleaved/sequential/ .
.
.
)*Explanation (without system-specific jargon) of processing stages :Identification of relevant texts and paragraph sLexical look-up (example of output and lexicon )- Syntactic analysis (example of output and grammar)Semantic analysis (example of output and semantic rules )-Reference resolutionTemplate fil l* Sample filled-in template, with an explanation of interestingthings :things system got righ tthings system got wrong
