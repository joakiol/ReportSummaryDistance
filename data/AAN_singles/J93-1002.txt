Generalized Probabilistic LR Parsing ofNatural Language (Corpora) withUnification-Based GrammarsTed Briscoe*University of CambridgeJohn Carroll*University of CambridgeWe describe work toward the construction ofa very wide-coverage probabilistic parsing system fornatural anguage (NL), based on LR parsing techniques.
The system is intended to rank the largenumber of syntactic analyses produced by NL grammars according to the frequency of occurrenceof the individual rules deployed in each analysis.
We discuss a fully automatic procedure forconstructing an LR parse table from a unification-based grammar formalism, and consider thesuitability of alternative LALR(1) parse table construction methods for large grammars.
Theparse table is used as the basis for two parsers; a user-driven interactive system that providesa computationally tractable and labor-efficient method of supervised training of the statisticalinformation required to drive the probabilistic parser.
The latter is constructed by associatingprobabilities with the LR parse table directly.
This technique is superior to parsers based onprobabilistic lexical tagging or probabilistic ontext-free grammar because it allows for a morecontext-dependent probabilistic language model, as well as use of a more linguistically adequategrammar formalism.
We compare the performance of an optimized variant of Tomita's (1987)generalized LR parsing algorithm to an (efficiently indexed and optimized) chart parser.
Wereport promising results of a pilot study training on 150 noun definitions from the LongmanDictionary of Contemporary English (LDOCE) and retesting on these plus a further 55definitions.
Finally, we discuss limitations of the current system and possible xtensions to dealwith lexical (syntactic and semantic)frequency of occurrence.1.
Wide-Coverage Parsing of Natural LanguageThe task of syntactically analyzing substantial corpora of naturally occurring text andtranscribed speech as become a focus of recent work.
Analyzed corpora would be ofgreat benefit in the gathering of statistical data regarding language use, for example totrain speech recognition devices, in more general linguistic research, and as a first steptoward robust wide-coverage s mantic interpretation.
The Alvey Natural LanguageTools (ANLT) system is a wide-coverage lexical, morphological, and syntactic analysissystem for English (Briscoe t al.
1987).
Previous work has demonstrated that the ANLTsystem is, in principle, able to assign the correct parse to a high proportion of Englishnoun phrases drawn from a variety of corpora.
The goal of the work reported hereis to develop a practical parser capable of returning probabilistically highly rankedanalyses (from the usually large number of syntactically egitimate possibilities) formaterial drawn from a specific corpus on the basis of minimal (supervised) trainingand manual modification.
* University of Cambridge, Computer Laboratory, Pembroke Street, Cambridge, CB2 3QG, UK.
(Tel.+44-223-334600), (ejb/ jac @cl.cam.ac.uk).
(~) 1993 Association for Computational LinguisticsComputational Linguistics Volume 19, Number 1The first issue to consider is what the analysis will be used for and what constraintsthis places on its form.
The corpus analysis literature contains a variety of proposals,ranging from part-of-speech tagging to assignment ofa unique, sophisticated syntacticanalysis.
Our eventual goal is to recover a semantically and pragmatically appropriatesyntactic analysis capable of supporting semantic interpretation.
Two stringent require-ments follow immediately: firstly, the analyses assigned must determinately representthe syntactic relations that hold between all constituents in the input; secondly, theymust be drawn from an a priori defined, well-formed set of possible syntactic analyses(such as the set defined by a generative grammar).
Otherwise, semantic interpretationof the resultant analyses cannot be guaranteed tobe (structurally) unambiguous, andthe semantic operations defined (over syntactic onfigurations) cannot be guaranteedto match and yield an interpretation.
These requirements immediately suggest that ap-proaches that recover only lexical tags (e.g.
de Rose 1988) or a syntactic analysis thatis the 'closest fit' to some previously defined set of possible analyses (e.g.
Sampson,Haigh, and Atwell 1989), are inadequate (taken alone).
"Pioneering approaches to corpus analysis proceeded on the assumption that com-putationally tractable generative grammars of sufficiently general coverage could notbe developed (see, for example, papers in Garside, Leech, and Sampson 1987).
How-ever, the development of wide-coverage declarative and computationally tractablegrammars makes this assumption questionable.
For example, the ANLT word andsentence grammar (Grover et al 1989; Carroll and Grover 1989) consists of an Englishlexicon of approximately 40,000 lexemes and a 'compiled' fixed-arity term unificationgrammar containing around 700 phrase structure rules.
Taylor, Grover, and Briscoe(1989) demonstrate hat an earlier version of this grammar was capable of assigningthe correct analysis to 96.8% of a corpus of 10,000 noun phrases extracted (withoutregard for their internal form) from a variety of corpora.
However, although Taylor,Grover, and Briscoe show that the ANLT grammar has very wide coverage, they ab-stract away from issues of lexical idiosyncrasy by formimg equivalence classes of nounphrases and parsing a single token of each class, and they do not address the issuesof 1) tuning a grammar to a particular corpus or sublanguage 2) selecting the correctanalysis from the set licensed by the grammar and 3) providing reliable analyses ofinput outside the coverage of the grammar.
Firstly, it is clear that vocabulary, idiom,and conventionalized constructions u ed in, say, legal language and dictionary defini-tions, will differ both in terms of the range and frequency of words and constructionsdeployed.
Secondly, Church and Patil (1982) demonstrate hat for a realistic grammarparsing realistic input, the set of possible analyses licensed by the grammar can bein the thousands.
Finally, it is extremely unlikely that any generative grammar willever be capable of correctly analyzing all naturally occurring input, even when tunedfor a particular corpus or sublanguage (if only because of the synchronic idealizationimplicit in the assumption that the set of grammatical sentences of a language is wellformed.
)In this paper, we describe our approach to the first and second problems andmake some preliminary remarks concerning the third (far harder) problem.
Our ap-proach to grammar tuning is based on a semi-automatic parsing phase during whichadditions to the grammar are made manually and statistical information concerningthe frequency of use of grammar rules is acquired.
Using this statistical informationand modified grammar, a breadth-first probabilistic parser is constructed.
The latteris capable of ranking the possible parses identified by the grammar in a useful (andefficient) manner.
However, (unseen) sentences whose correct analysis is outside thecoverage of the grammar ren,.~in a problem.
The feasibility and usefulness of our ap-proach has been investigated in a preliminary way by analyzing a ~small corpus of26Ted Briscoe and John Carroll Generalized Probabilistic LR Parsingnoun definitions drawn from the Longman Dictionary of Contemporary English (LDOCE)(Procter 1978).
This corpus was chosen because the vocabulary employed is restricted(to approximately 2,000 morphemes), average definition length is about 10 words (witha maximum of around 30), and each definition is independent, allowing us to ignorephenomena such as ellipsis.
In addition, the language of definitions represents a rec-ognizable sublanguage, allowing us to explore the task of tuning a general purposegrammar.
The results reported below suggest hat probabilistic information concern-ing the frequency of occurrence of syntactic rules correlates in a useful (though notabsolute) way with the semantically and pragmatically most plausible analysis.In Section 2, we briefly review extant work on probabilistic approaches to cor-pus analysis and parsing and argue the need for a more refined probabilistic modelto distinguish distinct derivations.
Section 3 discusses work on LR parsing of natu-ral language and presents our technique for automatic onstruction of LR parsers forunification-based grammars.
Section 4 presents the method and results for construct-ing a LALR(1) parse table for the ANLT grammar and discusses these in the light ofboth computational complexity and other empirical results concerning parse table sizeand construction time.
Section 5 motivates our interactive and incremental approachto semi-automatic production of a disambiguated training corpus and describes thevariant of the LR parser used for this task.
Section 6 describes our implementation ofa breadth-first LR parser and compares its performance mpirically to a highly op-timized chart parser for the same grammar, suggesting that (optimized) LR parsingis more efficient in practice for the ANLT grammar despite exponential worst casecomplexity results.
Section 7 explains the technique we employ for deriving a proba-bilistic version of the LR parse table from the training corpus, and demonstrates thatthis leads to a more refined and parse-context-dependent probabilistic model capa-ble of distinguishing derivations that in a probabilistic ontext-free model would beequally probable.
Section 8 describes and presents the results of our first experimentparsing LDOCE noun definitions, and Section 9 draws some preliminary conclusionsand outlines ways in which the work described should be modified and extended.2.
Probabilistic Approaches to ParsingIn the field of speech recognition, statistical techniques based on hidden Markov mod-eling are well established (see e.g.
Holmes 1988:129f for an introduction).
The two mainalgorithms utilized are the Viterbi (1967) algorithm and the Baum-Welch algorithm(Baum 1972).
These algorithms provide polynomial solutions to the tasks of findingthe most probable derivation for a given input and a stochastic regular grammar, andof performing iterative re-estimation of the parameters of a (hidden) stochastic regu-lar grammar by considering all possible derivations over a corpus of inputs, respec-tively.
Baker (1982) demonstrates that Baum-Welch re-estimation can be extended tocontext-free grammars (CFGs) in Chomsky Normal Form (CNF).
Fujisaki et al (1989)demonstrate hat the Viterbi algorithm can be used in conjunction with the CYK pars-ing algorithm and a CFG in CNF to efficiently select the most probable derivationof a given input.
Kupiec (1991) extends Baum-Welch re-estimation to arbitrary (non-CNF) CFGs.
Baum-Welch re-estimation can be used with restricted or unrestrictedgrammars/models in the sense that some of the parameters corresponding topossibleproductions over a given (non-)terminal category set/set of states can be given aninitial probability of zero.
Unrestricted grammars/models quickly become impracti-cal because the number of parameters requiring estimation becomes large and thesealgorithms are polynomial in the length of the input and number of free parameters.27Computational Linguistics Volume 19, Number 1Typically, in applications ofMarkov modeling in speech recognition, the derivationused to analyze a given input is not of interest; rather what is sought is the best(most likely) model of the input.
In any application of these or similar techniquesto parsing, though, the derivation selected is of prime interest.
Baum (1972) provesthat Baum-Welch re-estimation will converge to a local optimum in the sense that theinitial probabilities will be modified to increase the likelihood of the corpus giventhe grammar and 'stabilize' within some threshold after a number of iterations overthe training corpus.
However, there is no guarantee that the global optimum will befound, and the a priori initial probabilities chosen are critical for convergence on usefulprobabilities (e.g.
Lari and Young 1990).
The main application of these techniques towritten input has been in the robust, lexical tagging of corpora with part-of-speechlabels (e.g.
Garside, Leech, and Sampson 1987; de Rose 1988; Meteer, Schwartz, andWeischedel 1991; Cutting et al 1992).Fujisaki et al (1989) describe a corpus analysis experiment using a probabilisticCNF CFG containing 7550 rules on a corpus of 4206 sentences (with an average sen-tence length of approximately 11words).
The unsupervised training process involvedautomatically assigning probabilities to each CF rule on the basis of their frequencyof occurrence in all possible analyses of each sentence of the corpus.
These probabil-ities were iteratively re-estimated using a variant of the Baum-Welch algorithm, andthe Viterbi algorithm was used in conjunction with the CYK parsing algorithm to effi-ciently select he most probable analysis after training.
Thus the model was restricted inthat many of the possible parameters (rules) defined over the (non-)terminal categoryset were initially set to zero and training was used only to estimate new probabilitiesfor a set of predefined rules.
Fujisaki et al suggest hat the stable probabilities willmodel semantic and pragmatic onstraints in the corpus, but this will only be so ifthese correlate with the frequency of rules in correct analyses, and also if the 'noise'in the training data created by the incorrect parses is effectively factored out.
Whetherthis is so will depend on the number of 'false positive' examples with only incorrectanalyses, the degree of heterogeneity in the training corpus, and so forth.
Fujisaki etal.
report some results based on testing the parser on the corpus used for training.In 72 out of 84 sentences examined, the most probable analysis was also the correctanalysis.
Of the remainder, 6 were false positives and did not receive a correct parse,while the other 6 did but it was not the most probable.
A success rate (per sentence)of 85% is apparently impressive, but it is difficult to evaluate properly in the absenceof full details concerning the nature of the corpus.
For example, if the corpus con-tains many simple and similar constructions, unsupervised training is more likely toconverge quickly on a useful set of probabilities.Sharman, Jelinek, and Mercer (1990) conducted a similar experiment with a gram-mar in ID/LP format (Gazdar et al 1985; Sharman 1989).
ID/LP grammars separate thetwo types of information encoded in CF rules--immediate dominance and immediateprecedence--into two rule types that together define a CFG.
This allows probabilitiesconcerning dominance, associated with ID rules, to be factored out from those con-cerning precedence, associated with LP rules.
In this experiment, a supervised trainingregime was employed.
A grammar containing 100 terminals and 16 nonterminals andinitial probabilities based on the frequency of ID and LP relations was extracted froma manually parsed corpus of about one million words of text.
The resulting probabilis-tic ID/LP grammar was used to parse 42 sentences of 30 words or less drawn fromthe same corpus.
In addition, lexical syntactic probabilities were integrated with theprobability of the ID/LP relations to rank parses.
Eighteen of the parses were identicalto the original manual analyses, while a further 19 were 'similar,' yielding a successrate of 88%.
What is noticeable about this experiment is that the results are no better28Ted Briscoe and John Carroll Generalized Probabilistic LR Parsingthan Fujisaki et al's unsupervised training experiment discussed above, despite theuse of supervised training and a more sophisticated grammatical model.
It is likelythat these differences derive from the corpus material used for training and testing,and that the results reported by Fujisaki et al will not be achieved with all corpora.Pereira and Schabes (1992) report an experiment using Baum-Welch re-estimationto infer a grammar and associated rule probabilities from a category set containing15 nonterminals and 48 terminals, corresponding to the Penn Treebank lexical tagset(Santorini 1990).
The training data was 770 sentences, represented as tag sequences,drawn from the treebank.
They trained the system in an unsupervised mode and alsoin a 'semi-supervised' mode, in which the manually parsed version of the corpus wasused to constrain the set of analyses used during re-estimation.
In supervised traininganalyses were accepted if they produced bracketings consistent but not necessarilyidentical with those assigned manually.
They demonstrate that in supervised mode,training not only converges faster but also results in a grammar in which the mostprobable analysis is compatible with the manually assigned analysis of further testsentences drawn from the tree bank in a much greater percentage of cases--78% asopposed to 35%.
This result indicates very clearly the importance of supervised train-ing, particularly in a context where the grammar itself is being inferred in addition tothe probability of individual rules.In our work, we are concerned to utilize the existing wide-coverage ANLT gram-mar; therefore, we have concentrated initially on exploring how an adequate proba-bilistic model can be derived for a unification-based grammar and trained in a super-vised mode to effectively select useful analyses from the large space of syntacticallylegitimate possibilities.
There are several inherent problems with probabilistic CFG(including ID/LP)-based systems.
Firstly, although CFG is an adequate model of themajority of constructions occurring in natural language (Gazdar and Mellish 1989),it is clear that wide-coverage CFGs will need to be very large indeed, and this willlead to difficulties of (manual) development of consistent grammars and, possibly, tocomputational intractability at parse time (particularly during the already computa-tionally expensive training phase).
Secondly, associating probabilities with CF rulesmeans that information about the probability of a rule applying at a particular pointin a parse derivation is lost.
This leads to complications distinguishing the probabilityof different derivations when the same rule can be applied several times in more thanone way.
Grammar 1 below is an example of a probabilistic CFG, in which each pro-duction is associated with a probability and the probabilities of all rules expanding agiven nonterminal category sum to one.Grammar 1i) s' -~ S (i.O)2) S -~ NP VP (I.0)3) VP -~ Vt NP (.4)4) VP -+ Vi (.6)5) NP -~ ProNP (.4)6) NP -+ Det N (.3)7) NP -~ NP PP (.3)8) N --+ N N ( .3 )9) PP --+ P NP (1 .0 )~o) N -+ N?
(.7)29Computational Linguistics Volume 19, Number 1a)sNP VPDet N Vt  NPI IN@ ProNPb)d) e)NN NN Nc)NN NN N0NP NPNP pp NP pp NPP NP NP PP ProNPNP PP P NPFigure 1Probabilistic context-free d rivations.VPvt  NPDet NIThe probability of a particular parse is the product of the probabilities of eachrule used in the derivation.
Thus the probability of parse a) in Figure 1 is 0.0336.
Theprobability of parse b) or c) must be identical though (0.09), because the same rule isapplied twice in each case.
Similarly, the probability of d) and e) is also identical (0.09)for essentially the same reason.
However, these rules are natural treatments of nouncompounding and prepositional phrase (PP) attachment in English, and the differentderivations correlate with different interpretations.
For example, b) would be an ap-propriate analysis for toy coffee grinder, while c) would be appropriate for cat food tin,and each of d) and e) yields one of the two possible interpretations of the man in thepark with the telescope.
We want to keep these structural configurations probabilisticallydistinct in case there are structurally conditioned ifferences in their frequency of oc-currence; as would be predicted, for example, by the theory of parsing strategies (e.g.Frazier 1988).
Fujisaki et al (1989) propose a rather inelegant solution for the nouncompound case, which involves creating 5582 instances of 4 morphosyntactically iden-tical rules for classes of word forms with distinct bracketing behavior in noun-nouncompounds.
However, we would like to avoid enlarging the grammar and eventuallyto integrate probabilistic lexical information with probabilistic structural informationin a more modular fashion.Probabilistic CFGs also will not model the context dependence of rule use; forexample, an NP is more likely to be expanded as a pronoun in subject position thanelsewhere (e.g.
Magerman and Marcus 1991), but only one global probability canbe associated with the relevant CF production.
Thus the probabilistic CFG modelpredicts (incorrectly) that a) and f) will have the same probability of occurrence.
Theseconsiderations suggest that we need a technique that allows use of a more adequategrammatical formalism than CFG and a more context-dependent probabilistic model.Our approach is to use the LR parsing technique as a natural way to obtain a finite-state representation f a non-finite-state grammar incorporating information aboutparse context.
In the following sections, we introduce the LR parser and in Section 830Ted Briscoe and John Carroll Generalized Probabilistic LR Parsingwe demonstrate that LR parse tables do provide an appropriate amount of contextualinformation to solve the problems described above.3.
LR Parsing in a Unification-Based Grammar FrameworkThe heart of the LR parsing technique is the parse table construction algorithm, whichis the most complex and computationally expensive aspect of LR parsing.
Much ofthe attraction of the technique stems from the fact that the real work takes place in aprecompilation phase and the run time behavior of the resulting parser is relativelysimple and directed.
An LR parser finds the 'rightmost derivation in reverse,' for agiven string and CF grammar.
The precompilation process results in a parser controlmechanism that enables the parser to identify the 'handle,' or appropriate substringin the input to reduce, and the appropriate rule of the grammar with which to per-form the reduction.
The control information is standardly encoded as a parse tablewith rows representing parse states, and columns terminal and nonterminal symbolsof the grammar.
This representation defines a finite-state automaton.
Figure 2 givesthe LALR(1) parse table for Grammar 1.
(LALR(1) is the most commonly used variantof LR since it usually provides the best trade-off between directed rule invocation andparse table size.)
If the grammar is in the appropriate LR class (a stronger restric-tion than being an unambiguous CFG), the automaton will be deterministic; however,some algorithms for parse table construction are also able to build nondeterministicautomata containing action conflicts for ambiguous CFGs.
Parse table construction isdiscussed further in Section 4.Act ionsS ta te  $ Det  N@ P ProNP V i  V t. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.0 s3  s2.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 r l. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.2 r5  r5  r5  r5.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.3 s4.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.4 r l0  r l0  r10  r l0  r l0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.5 r6  s4 r6  r6  r6.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.6 r8  rS /s4  r8  r8  r8.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.7 s8  s13  s l l. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.8 s3  s2.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.9 r9  rg /s8  r9  r9.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i0  r7  r7  r7  r7.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i i  s3  s2.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.12 r3  s8.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.13 r4.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.14 r2.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.15 accFigure 2LALR(1) parse table for Grammar 1.GotosState  N NP  PP  S S' VP.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.0 7 1 15. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.2. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.3 5. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.4. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.5 6. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.6 6. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.7 I0  14. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.8 9. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.9 i0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i 0. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i i  12. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.12 i0.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.13. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.14. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1531Computational Linguistics Volume 19, Number 13.1 Creating LR Parse Tables from Unification GrammarsTomita (1987) describes a system for nondeterministic LR parsing of context-free gram-mars consisting of atomic categories, in which each CF production may be augmentedwith a set of tests (which perform similar types of operations to those available ina unification grammar).
At parse time, whenever a sequence of constituents i aboutto be reduced into a higher-level constituent using a production, the augmentationassociated with the production is invoked to check syntactic or semantic onstraintssuch as agreement, pass attribute values between constituents, and construct a rep-resentation of the higher-level constituent.
(This is the standard approach to parsingwith attribute grammars).
The parser is driven by an LR parse table; however, thetable is constructed solely from the CF portion of the grammar, and so none of theextra information embodied in the augmentations i  taken into account during itsconstruction.
Thus the predictive power of the parser to select the appropriate rulegiven a specific parse history is limited to the CF portion of the grammar, which mustbe defined manually by the grammar writer.
This requirement places a greater loadon the grammar writer and is inconsistent with most recent unification-based gram-mar formalisms, which represent grammatical categories entirely as feature bundles(e.g.
Gazdar et al 1985; Pollard and Sag 1987; Zeevat, Calder, and Klein 1987).
Inaddition, it violates the principle that grammatical formalisms hould be declarativeand defined independently of parsing procedure, since different definitions of the CFportion of the grammar will, at least, effect the efficiency of the resulting parser andmight, in principle, lead to nontermination on certain inputs in a manner similar tothat described by Shieber (1985).In what follows, we will assume that the unification-based grammars we are con-sidering are represented in the ANLT object grammar formalism (Briscoe et al 1987).This formalism is a notational variant of Definite Clause Grammar (e.g.
Pereira andWarren 1980), in which rules consist of a mother category and one or more daughtercategories, defining possible phrase structure configurations.
Categories consist of setsof feature name-value pairs, with the possibility of variable values, which may bebound within a rule, and of category-valued features.
Categories are combined usingfixed-arity term unification (Prolog-style).
The results and techniques we report be-low should generalize to many other unification-based formalisms.
An example of apossible ANLT object grammar ule is:IN -, V +, BAR 2, PER x, PLU y, VFORM z\] --+\[N +, V -, BAR 2, PER x, PLU y, CASE Nom\]\[N -, V +, BAR i, PER x, PLU y, VFORM z\]This rule provides a (simple) analysis of the structure of English clauses, correspondingto S --* NP VP, using a feature system based loosely on that of GPSG (Gazdar et al1985).
In Tomita's LR  parsing framework, each such rule must be manually convertedinto a rule of the following form in which some subpart of each category has beenreplaced by an atomic symbol.Vb\[BAR 2, PER x, PLU y, VFOKM z\] -~Nn\[BAR 2, PER x, PLU y, CASE Nom\]Vb\[BAR I, PER x, PLU y, VFORM z\]However, it is not obvious which features should be so replaced--why not includeBAR and CASE?
It will be difficult for the grammar writer to make such substitutionsin a consistent way, and still more difficult to make them in an optimal way  for thepurposes of LR  parsing, since both steps involve consideration and comparison of allthe categories mentioned in each rule of the grammar.32Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingConstructing the LR parse table directly and automatically from a unificationgrammar would avoid these drawbacks.
In this case, the LR parse table would bebased on complex categories, with unification of complex categories taking the placeof equality of atomic ones in the standard LR parse table construction algorithm (Os-borne 1990; Nakazawa 1991).
However, this approach is computationally prohibitivelyexpensive: Osborne (1990:26) reports that his implementation (i HP Common Lispon a Hewlett Packard 9000/350) takes almost 24 hours to construct the LR(0) statesfor a unification grammar of just 75 productions.3.2 Constructing a CF Backbone from a Unif ication GrammarOur approach, described below, not only extracts unification information from complexcategories, but is computationally tractable for realistic sized grammars and also safefrom inconsistency.
We start with a unification grammar and automatically constructa CF 'backbone' of rules containing categories with atomic names and an associated'residue' of feature name-value pairs.
Each backbone grammar rule is generally in di-rect one-to-one correspondence with a single unification grammar rule.
The LR parsetable is then constructed from the CF backbone grammar.
The parser is driven by thistable, but in addition when reducing a sequence of constituents he parser performsthe unifications pecified in the relevant unification grammar rule to form the cate-gory representing the higher-level constituent, and the derivation fails if one of theunifications fails.
Our parser is thus similar to Tomita's (1987), except hat it performsunifications rather than invoking CF rule augmentations; however, the main differencebetween our approach and Tomita's is the way in which the CF grammar that drivesthe parser comes into being.Even though a unification grammar will be, at best, equivalent to a very large(and at worst, if features are employed in recursive or cyclic ways, possibly infinite)set of atomic-category CF productions, in practice we have obtained LR parsers thatperform well from backbone grammars containing only about 30% more productionsthan the original unification grammar.
The construction method ensures that for anygiven grammar the CF backbone captures at least as much information as the optimalCFG that contains the same number of rules as the unification grammar.
Thus theconstruction method guarantees that the resulting LR parser will terminate and willbe as predictive as the source grammar in principle allows.Building the backbone grammar is a two-stage process:.
Compute the largest maximally specific set (in terms of subsumption) ofdisjoint categories covering the whole grammar and assign to eachcategory a distinct atomic category name.
That is:initialize disjoint-set to be empty;for each category C in grammarlet disjoint-merge be the categories in disjoint-setwhich unify with C;if disjoint-merge is emptythen add C to disjoint-set;else replace all elements of disjoint-merge in disjoint-setwith the single most specific category which subsumes Cand all categories in disjoint-merge;assign a distinct name to each category in disjoint-set.33Computational Linguistics Volume 19, Number 1IN -, V +, BAR 2, PER x, PLU y, VFORM z\] -->\[N +, V -, BAR 2, PER x, PLU y, CASE Nom\]\[N -, V +, BAR i, PER x, PLU y, VFOKM z\]IN +, V -, BAR 2, PER x, PLU y, CASE c\] -->\[SUBCAT DET\]\[N +, V -, BAR I, PER x, PLU y, CASE c\]\[N -, V +, BAR I, PER x, PLU y, VFORM z\] -->\[N -, V +, BAR O, PER x, PLU y, VFORM z, SUBCAT INTRANS\]IN -, V +, BAR i, PER x, PLU y, VFORM z\] -->\[N -, V +, BAR O, PER x, PLU y, VFOKM z, SUBCAT TRANS\]\[N +, V -, BAR 2, PER x, PLU y, CASE Acc\]Figure 3ANLT object grammar rules.
{S-l:NP-2:VP-3:DET-4:NI-5:V-6:V-7:\[N -, V +, BAR 2, PER x, PLU y, VFORM z\]\[N +, V -, BAR 2, PER x, PLU y, CASE c\]IN -, V +, BAR i, PER x, PLU y, VFORM z\]\[SUBCAT DET\]IN +, V -, BAR i, PER x, PLU y, CASE c\]\[N -, V +, BAK O, PER x, PLU y, VFOKM z, SUBCAT INTRANS\]\[N -, V +, BAR O, PEK x, PLU y, VFOR/~ z, SUBCAT TKANS\]}Figure 4Categories in disjoint-set.S-1 - -> NP-2 VP-3NP-2 - -> DET-4 N$-5VP-3 - -> V-6VP-3 - -> V-7 NP-2Figure 5Backbone grammar corresponding to object grammar.. For each unification grammar  ule, create a backbone grammar  ulecontaining atomic categories, each atomic category being the nameassigned to the category in the disjoint category set that unifies with thecorresponding category in the unification grammar  ule:for each rule K of form C1 -~ C2 ... Cn in unification grammaradd a rule B of form B1 -~ B2 ... Bn to backbone grammarwhere Bi is the name assigned to the (single) category indisjoint-set which unifies with Ci, for i=l, n.For example, for the rules in Figure 3 (corresponding loosely to S ---* NP VP, NP -~Vi and VP --* Vt NP), step 1 would create the disjoint-set shown in Figure 4.
(Notethat the value for CASE on the NP categories in the grammar  has 'collapsed' down to a34Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingN2e i ther  kinN2 -OR N2 -OR+or  lee N2-ORor  sandyFigure 6Backbone parse tree for either kim or lee or sandy using rule N2 --> N2 \[C0NJ EITHER\],N2 \[CONJ OR\] +.variable, but that the two V categories remain distinct).
Figure 5 shows the backbonerules that would be built in step 2.Algorithms for creating LR parse tables assume that the terminal vocabulary ofthe grammar is distinct from the nonterminal one, so the procedure described abovewill not deal properly with a unification grammar ule whose mother category isassumed elsewhere in the grammar to be a lexical category.
The modification wemake is to automatically associate two different atomic categories, one terminal andone nonterminal, with such categories, and to augment the backbone grammar witha unary rule expanding the nonterminal category to the terminal.Two other aspects of the ANLT grammar formalism require further minor elabora-tions to the basic algorithm: firstly, a rule may introduce a gap by including the featurespecification \[NULL +\] on the gapped aughter--for each such daughter an extra ruleis added to the backbone grammar expanding the gap category to the null string;secondly, the formalism allows Kleene star and plus operators (Gazdar et al 1985)--in the ANLT grammar these operators are utilized in rules for coordination.
A rulecontaining Kleene star daughters i treated as two rules: one omitting the daughtersconcerned and one with the daughters being Kleene plus.
A new nonterminal cate-gory is created for each distinct Kleene plus category, and two extra rules are added tothe backbone grammar to form a right-branching binary tree structure for it; a parsercan easily be modified to flatten this out during processing into the intended flat se-quence of categories.
Figure 6 gives an example of what such a backbone tree lookslike.
Grammars written in other, more low-level unification grammar formalisms, uchas PATR-I1 (Shieber 1984), commonly employ treatments of the type just described todeal with phenomena such as gapping, coordination, and compounding.
However,this method both allows the grammar writer to continue to use the full facilities of theANLT formalism and allows the algorithmic derivation of an appropriate backbonegrammar to support LR parsing.The major task of the backbone grammar is to encode sufficient information (inthe atomic categoried CF rules) from the unification grammar to constrain the appli-cation of the latter's rules at parse time.
The nearly one-to-one mapping of unificationgrammar rules to backbone grammar rules described above works quite well for theANLT grammar, with only a couple of exceptions that create spurious hift-reduce con-flicts during parsing, resulting in an unacceptable degradation i performance.
The35Computational Linguistics Volume 19, Number 1phenomena concerned are coordination and unbounded ependency onstructions.In the ANLT grammar three very general rules are used to form nominal, adjec-tival, and prepositional phrases following a conjunction; the categories in these ruleslead to otherwise disjoint categories for conjuncts being merged, giving rise to a set ofoverly general backbone grammar rules.
For example, the rule in the ANLT grammarfor forming a noun phrase conjunct introduced by a conjunction isN2\[CONJ @con\] --> \[SUBCAT @con, C0NJN +\], H2.The variable value for the C0NJ feature in the mother means that all N2 categoriesspecified for this feature (e.g.
N2 \[C0NJ EITHER\], N2 \[C0NJ NULL\] ) are generalized tothesame category.
This results in the backbone rules, when parsing either kim or lee helps,being unable, after forming a N2 \[C0NJ EITHER\] for either kim, to discriminate betweenthe alternatives ofpreparing to iterate this constituent (as in the phrase kim, lee, or sandyhelps where kim would be N2 \[C0NJ NULL\]), or shifting the next word or to start a newconstituent.
We solve this problem by declaring C0NJ to be a feature that may not havea variable value in an element of the disjoint category set.
This directs the system toexpand out each unification grammar rule that has a category containing this featurewith a variable value into a number of rules fully specified for the feature, and tocreate backbone rules for each of these.
There are eight possible values for C0NJ in thegrammar, so the general rule for forming a nominal conjunct given above, for example,ends up being represented by a set of eight specialized backbone grammar rules.In the grammar, unbounded ependency constructions (UBCs) are analyzed bypropagating the preposed constituent through the parse tree as the value of the SLASHfeature, to link it with the 'gap' that appears in the constituent's normal position.
Allnonlexical major categories contain the feature, rules in the grammar propagating itbetween mother and a single daughter; other daughters are marked \[SLASH \[NOSLASH+\] \] indicating that the daughter is not 'gapped."
Backbone grammar constructionwould normally lose the information in the unification grammar about where gapsare allowed to occur, significantly degrading the performance of a parser.
To carrythe information over into the backbone we declare that wherever SLASH occurs with avariable value, the value should be expanded out into two values: \[NOSLASH +\], anda notional value unifying with anything except \[NOSLASH +\].
We have also experi-mented with a smaller grammar employing 'gap threading' (e.g.
Pereira and Shieber1987), an alternative treatment of UBCs.
We were able to use the same techniques forexpanding out and inference on the values of the (in this case atomic) features usedfor threading the gaps to produce a backbone grammar (and parse table) that had thesame constraining power with respect o gaps as the original grammar.To date, we have not attempted to compute CF backbones for grammars writtenin formalisms with minimal phrase structure components and (almost) completelygeneral categories, uch as HPSG (Pollard and Sag 1987) and UCG (Zeevat, Calder,and Klein 1987); more extensive inference on patterns of possible unification withinnested categories and appropriate xpanding-out of the categories concerned wouldbe necessary for an LR parser to work effectively.
This and other areas of complexityin unification-based formalisms need further investigation before we can claim to havedeveloped a system capable of producing a useful LR parse table for any unification-based grammar.
In particular, declaring certain category-valued features o that theycannot ake variable values may lead to nontermination in the backbone constructionfor some grammars.
However, it should be possible to restrict he set of features thatare considered in category-valued features in an analogous way to Shieber's (1985)restrictors for Earley's (1970) algorithm, so that a parse table can still be constructed.36Ted Briscoe and John Carroll Generalized Probabilistic LR Parsing4.
Building LR Parse Tables for Large NL GrammarsThe backbone grammar generated from the ANLT grammar is large: it contains al-most 500 distinct categories and more than 1600 productions.
When we constructthe LALR(1) parse table, we therefore require an algorithm with practical time andspace requirements.
In the LR parsing literature there are essentially two approachesto constructing LALR(1) parse tables.
One approach is graph-based (DeRemer andPennello 1982), transforming the parse table construction problem to a set of well-known directed graph problems, which in turn are solvable by efficient algorithms.Unfortunately this approach does not work for grammars that are not LR(k) for anyk (DeRemer and Pennello 1982:633), for example, ambiguous grammars.
We thereforebroadly follow the alternative approach of Aho, Sethi, and Ullman (1986), but with anumber of optimizations:...Constructing the LR(0) sets of items: we compute LR(0) states containingonly kernel items (the item IS' --> S\], where S' is the start symbol,and all items that have a symbol to the left of the dot), since nonkernelitems can be cached in a table and retrieved only if needed.
Being able topartition the items in this way is especially useful with the ANLTgrammar, since the mean number of kernel items in each LR(0) set isabout 9, whereas the mean number of nonkernel items per state is morethan 400.Computing the LALR(1) lookaheads for each item: the conventionalapproach is to compute the LR(1) closure of each kernel item in order todetermine the lookaheads that are generated spontaneously and those thatpropagate from other items.
However, in an initial implementation wefound that the LR(1) closure operation as described by Aho et al wastoo expensive to be practicable for the number and size of LR(0) stateswe deal with, even with schemes for caching the closures of nonkernelitems once they had been computed.
Instead, we have moved to analgorithm devised by Kristensen and Madsen (1981), which avoidsperforming the LR(1) closure operation.
The crucial advantage of thisalgorithm is the ability, at any stage in the computation, to tell whetherthe calculation of the lookahead set for a particular item has beencompleted, is underway, or has not yet started.
This means that evenpartially computed lookahead sets can be cached (with the computationyet to be done explicitly marked), and that items whose lookahead setsare found to subsume those of others are able to just copy the resultsfrom the subsumed sets.Constructing the parse table: the LALR(1) parse table is derivedstraightforwardly from the lookahead sets, although to keep the size ofthe parse table within reasonable bounds we chose appropriate datastructures to represent the goto entries and shift and reduce actions.
Forthe ANLT backbone grammar there are approximately 150,000 gotoentries (nonterminal--state pairs), 440,000 shift actions (terminal--statepairs), and 670,000 reduce actions (terminal--rule-number pairs);however, of the goto entries only 2,600 are distinct and of the shiftactions only 1,100 are distinct; most states contain just reduce or justshift actions, and in any one state very few different rules are involved37Computational Linguistics Volume 19, Number 1in reduce actions.
1The majority of states contain just reduce or just shiftactions, and in any one state very few different rules are involved inreduce actions.
Taking advantage of the characteristics of thisdistribution, in each state we represent (in Common Lisp)(a) a set of goto entries as a list of (nonterminal--state) consessorted into a canonical order, list elements and tails of listsshared where possible between states,(b) a set of shift actions as a list containing a single (large) integer(the list shared when possible between states), where if the stateshifts to state s on lookahead t, the element indexed by t in anauxiliary array will contain s together with a number n, and bitn in the binary representation f the integer will be 1,(c) a set of reduce actions as, for each rule involved, a cons whosesecond element is the rule number and whose first is a bit-vector(shared when possible between states) whose nth bit is 1 if thereduce should occur with the nth terminal as lookahead,(d) an accept action as a cons with the first element being thelookahead symbol.For the grammars we have investigated, this representation achieves a similarorder of space saving to the comb vector representation suggested by Aho, Sethi, andUllman (1986:244ff) for unambiguous grammars (see Klein and Martin \[1989\] for asurvey of representation techniques).
The parse table for the ANLT grammar occupiesapproximately 360 Kbytes of memory, and so represents each action (shift, reduce, orgoto) in an average of less than 2.3 bits.
In contrast to conventional techniques, though,we maintain a faithful representation f the parse table, not replacing error entries withmore convenient nonerror ones in order to save extra space.
Our parsers are thus ableto detect failures as soon as theoretically possible, an important efficiency feature whenparsing nondeterministically with ambiguous grammars, and a time-saving featurewhen parsing interactively with them (see next section).Table 1 compares the size of the LALR(1) parse table for the ANLT grammarwith others reported in the literature.
From these figures, the ANLT grammar is morethan twice the size of Tomita's (combined morphological and syntactic) grammar forJapanese (Tomita 1987:45).
The grammar itself is about one order of magnitude biggerthan that of a typical programming language, but the LALR(1) parse table, in termsof number of actions, is two orders of magnitude bigger.
Although Tomita (1984:357)anticipates LR parsing techniques being applied to large NL grammars written informalisms uch as GPSG, the sizes of parse tables for such grammars grow morerapidly than he predicts.
However, for large real-world NL grammars uch as theANLT, the table size is still quite manageable despite Johnson's (1989) worst-casecomplexity result of the number of LR(0) states being exponential on grammar size(leading to a parser with exponentially bad time performance).
We have, therefore,not found it necessary to use Schabes' (1991a) LR-like tables (with number of statesguaranteed to be polynomial even in the worst case).1 of the 3,710 states, 2,200 contain at least 1 action conflict, with a median of 34 conflicts per state.
Thereare a total of 230,000 shift-reduce onflicts and 220,000 reduce-reduce conflicts, fairly uniformlydistributed across the terminal lookahead symbols.
In half of the latter conflicts, the rules involvedhave an identical number of daughters.
One implication of this finding is that an approach to conflictresolution such as that of Shieber (1983) where reduce-reduce conflicts are resolved in favor of thelonger eduction may not suffice to select aunique analysis for realistic NL grammars.38Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingTable 1Sizes of grammar and LALR(1) parse tables.Grammar Number of CFG Number of Number of Total numberrules/categories LR(0) states kernel items of actionsPascal 2 158 / 124 275 ?
2883Modula-23 227 / 194 373 420 3238Tomita, Japanese 800 / ?
?
?
?ANLT (689 PS rules) 1641 / 496 3710 34836 1258451Table 2Timings for LALR(1) parse table construction (in seconds of CPU time ona Sparc-Server 390 running Sun Common Lisp).Grammar Backbone LR(0) state lookahead parse tablecomputation construction computation constructionANLT 150 710 4200 780As might be expected, and Table 2 illustrates, parse table construction for largegrammars i  CPU-intensive.
As a rough guide, Grosch (1990) quotes LALR(1) tableconstruction for a grammar for Modula-2 taking from about 5 to 50 seconds, so scalingup two orders of magnitude, our timings for the ANLT grammar fall in the expectedregion.5.
Interactive Incremental Deterministic Parsing5.1 Constructing a Disambiguated Training CorpusThe major problem with attempting to employ a disambiguated training corpus is tofind a way of constructing this corpus in an error-free and resource-efficient fashion.Even manual assignment of lexical categories i slow, labor-intensive, and error-prone.The greater complexity of constructing a complete parse makes the totally manual ap-proach very unattractive, if not impractical, Sampson (1987:83) reports that it took 2person-years to produce the 'LOB tree bank' of 50,000 words.
Furthermore, in thatproject, no attempt was made to ensure that the analyses were well formed with re-spect o a generative grammar.
Attempting to manually construct analyses consistentwith a grammar of any size and sophistication would place an enormous additionalload on the analyst.
Leech and Garside (1991) discuss the problems that arise in manualparsing of corpora concerning accuracy and consistency of analyses across time andanalyst, the labor-intensive nature of producing detailed analyses, and so forth.
Theyadvocate an approach in which simple 'skeleton' parses are produced by hand frompreviously tagged material, with checking for consistency between analysts.
Theseskeleton analyses can then be augmented automatically with further information im-plicit in the lexical tags.
While this approach may well be the best that can be achieved2 Figures given by Klein and Martin (1989).3 Grammar from Spector (1983) with optionality expanded out; statistics taken from a parse tableconstructed bythe second author.39Computational Linguistics Volume 19, Number 1with fully manual techniques, it is still unsatisfactory in several respects.
Firstly, theanalyses are crude, while we would like to automatically parse with a grammar capa-ble of assigning sophisticated semantically interpretable ones; but it is not clear howto train an existing grammar with such unrelated analyses.
Secondly, the quality ofany grammar obtained automatically from the parsed corpus is likely to be poor be-cause of the lack of any rigorous checks on the form of the skeleton parses.
Such agrammar might, in principle, be trained from the parsed corpus, but there are stilllikely to be small mismatches between the actual analysis assigned manually and anyassigned automatically.
For these reasons, we decided to attempt to produce a trainingcorpus using the grammar that we wished ultimately to train.
As long as the methodemployed ensured that any analysis assigned was a member of the set defined by thegrammar, these problems during training should not arise.Following our experience of constructing a substantial lexicon for the ANLT gram-mar from unreliable and indeterminate data (Carroll and Grover 1989), we decidedto construct the disambiguated training corpus semi-automatically, restricting manualinteraction to selection between alternatives defined by the ANLT grammar.
One obvi-ous technique would be to generate all possible parses with a conventional parser andto have the analyst select he correct parse from the set returned (or reject them all).However, this approach places a great load on the analyst, who will routinely need toexamine large numbers of parses for given sentences.
In addition, computation of allpossible analyses is likely to be expensive and, in the limit, intractable.Briscoe (1987) demonstrates that the structure of the search space in parse deriva-tions makes a left-to-right, incremental mode of parse selection most efficient.
Forexample, in noun compounds analyzed using a recursive binary-branching rule (N--* N N) the number of analyses correlates with the Catalan series (Church and Patil,1982), 4 so a 3-word compound has 2 analyses, 4 has 5, 5 has 14, 9 has 1430, and soforth.
However, Briscoe (1987:154f) shows that with a simple bounded context parser(with one word lookahead) set up to request help whenever a parse indeterminacyarises, it is possible to select any of the 14 analyses of a 5-word compound with amaximum of 5 interactions and any of the 1430 analyses of a 9-word compound witharound 13 interactions.
In general, resolution of the first indeterminacy in the inputwill rule out approximately half the potential analyses, resolution of the next, halfof the remaining ones, and so on.
For 'worst case' CF ambiguities (with O(n 3) com-plexity) this approach to parse selection appears empirically to involve numbers ofinteractions that increase at little more than linear rate with respect o the length ofthe input.
It is possible to exploit this insight in two ways.
One method would be tocompute all possible analyses represented as a (packed) parse forest and ask the userto select between competing subanalyses that have been incorporated into a success-ful analysis of the input.
In this way, only genuine global syntactic ambiguities wouldneed to be considered by the user.
However, the disadvantage of this approach is thatit relies on a prior (and perhaps CPU-intensive) on-line computation of the full set ofanalyses.
The second method involves incremental interaction with the parser duringthe parse to guide it through the search space of possibilities.
This has the advantageof being guaranteed to be computationally tractable but the potential disadvantageof requiring the user to resolve many local syntactic ambiguities that will not be4 The nth Catalan number is given byCn=(2n) 1n n+l"40Ted Briscoe and John Carroll Generalized Probabilistic LR Parsingincorporated into a successful analysis.
Nevertheless, using LR techniques this prob-lem can be minimized and, because we do not wish to develop a system that mustbe able to compute all possible analyses (at some stage) in order to return the mostplausible one, we have chosen the latter incremental method.5.2 The Interactive LR Parsing SystemThe interactive incremental parsing system that we implemented asks the user for adecision at each choice point during the parse.
However, to be usable in practice, sucha system must avoid, as far as possible, presenting the user with spurious choicesthat could be ruled out either by using more of the left context or by looking atwords yet to be parsed.
Our approach goes some way to addressing these points,since the parser is as predictive as the backbone grammar and LR technique allow,and the LALR(1) parse table allows one word lookahead to resolve some ambiguities(although, of course, the resolution of a local ambiguity may potentially involve anunlimited amount of lookahead; e.g.
Briscoe 1987:125ff).
In fact, LR parsing is the mosteffectively predictive parsing technique for which an automatic compilation procedureis known, but this is somewhat undermined by our use of features, which will blocksome derivations so that the valid prefix property will no longer hold (e.g.
Schabes1991b).
Extensions to the LR technique, for example those using LR-regular grammars(Culic and Cohen 1973; Bermudez 1991), might be used to further cut down on inter-actions; however, computation of the parse tables to drive such extended LR parsersmay prove intractable for large NL grammars (Hektoen 1991).An LR parser faces an indeterminacy when it enters a state in which there is morethan one possible action, given the current lookahead.
In a particular state there cannotbe more than one shift or accept action, but there can be several reduce actions, eachspecifying a reduction with a different rule.
When parsing, each shift or reduce choicemust lead to a different final structure, and so the indeterminacy represents a point ofsyntactic ambiguity (although it may not correspond to a genuinely global syntacticambiguity in the input, on account of the limited amount of lookahead).In the ANLT grammar and lexicon, lexical ambiguity is at least as pervasive asstructural mbiguity.
A naive implementation f an interactive LR parser would ask theuser the correct category for each ambiguous word as it was shifted; many open-classwords are assigned upwards of twenty lexical categories by the ANLT lexicon withcomparatively fine distinctions between them, so this strategy would be completelyimpracticable.
To avoid asking the user about lexical ambiguity, we use the techniqueof preterminal delaying (Shieber 1983), in which the assignment ofan atomic preterminalcategory to a lexical item is not made until the choice is forced by the use of a particularproduction i  a later reduce action.
After shifting an ambiguous lexical item, the parserenters a state corresponding to the union of states that would be entered on shiftingthe individual lexical categories.
(Each union of states will in practice be small, sinceit being otherwise would imply that the current context was completely failing toconstrain the following input).
Since, in general, several unification grammar categoriesfor a single word may be subsumed by a single atomic preterminal category, we extendShieber's technique so that it deals with a grammar containing complex categories byassociating a set of alternative analyses with each state (not just one), and letting thechoice between them be forced by later reduce actions, just as with atomic preterminalcategories.In order not to overload the user with spurious choices concerning local ambi-guities, the parser does not request help immediately after it reaches a parse actionconflict.
Instead the parser pursues each option in a limited breadth-first fashion andonly requests help with analysis paths that remain active.
In our current system this41Computational Linguistics Volume 19, Number 1Table 3Amount of user interaction parsing the act of putting an end tosomething with the ANLT grammar using different amounts ofaction conflict lookahead.action conflict number oflookahead choicesmean number of optionsin each choicenone 6 2.31 choice 5 2.22 choices 3 2.03 choices 2 2.04 choices 1 2.0type of lookahead is limited to up to four indeterminacies ahead.
Such checking ischeap in terms of machine resources and very effective in cutting down both thenumber of choice points the user is forced to consider and also the average num-ber of options in each one.
Table 3 shows the reduction in user interaction achievedby increasing the amount of lookahead in our system.
Computation of the backbonegrammar generates extra rules (as previously described to deal with lexical categoriesused as rule mothers and daughters specified to be repeatable an indefinite number oftimes) that do not correspond irectly to single unification grammar rules.
At choicepoints, reductions involving these rules are not presented to the user; instead thesystem applies the reductions automatically, proceeding until the next shift action orchoice point is reached, including these options in those presented to the user.The final set of measures taken to reduce the amount of interaction required withthe user is to ask if the phrase being parsed contains one or more gaps or instances ofcoordination before presenting choices involving either of these phenomena, blockingconsideration of rules on the basis of the presence of particular feature-value pairs.Figure 7 shows the system parsing a phrase with a four-choice lookahead.
The result-ing parse tree is displayed with category aliases substituted for the actual complexcategories.The requests for manual selection of the analysis path are displayed to the ana-lyst in as terse a manner as possible, and require knowledge of the ANLT grammarand lexicon to be resolved effectively.
Figure 8 summarizes the amount of interactionrequired in the experiment reported below for parsing a set of 150 LDOCE noun def-initions with the ANLT grammar.
To date, the largest number of interactions we haveobserved for a single phrase is 55 for the (30-word) LDOCE definition for youth hostel:a hostel for usu young people walking around country areas on holiday forwhich they pay small amounts of money to the youth hostels association or theinternational yha.Achieving the correct analysis interactively took the first author about 40 minutes(including the addition of two lexical entries).
Definitions of this length will oftenhave many hundreds or even thousands of parses; computing just the parse forestfor this definition takes of the order of two hours of CPU time (on a DEC 3100 Unixworkstation).
Since in a more general corpus of written material the average sentencelength is likely to be 30--40 words, this example illustrates clearly the problems withany approach based on post hoc on-line selection of the correct parse.
However, using42Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingParse>> the act of putting an end to somethingAre there any gaps in this phrase?
nAmbiguity in state 27/193 with (of putting an end tosomething $) remaining in buffer.
Analysis so far is the, act.I: Shift word 'of' onto stack.2: Reduce end I analyses with rule NI/N (giving category NI-9).Which choice (i - 2 / abort / finish)?
22384 msec CPU2700 unifications, 2025 failures, i parse(N2 the(N2 (NI act(P2 (PI of(VP (V putting) (N2 an (N2 (NI end)))(P2 (PI to (N2 something)))))))))Figure 7An interactive parse.20-Number ofdef'mitionsi0-I I i i0 l0 20 30 40Number of interactionsFigure 8Numbers of definitions requiring particular amounts of interaction.I'1I5043Computational Linguistics Volume 19, Number 1the incremental pproach to semi-automatic parsing we have been able to demonstratethat the correct analysis is among this set.
Furthermore, a probabilistic parser such asthe one described later may well be able to compute this analysis in a tractable fashionby extracting it from the parse forest.
(To date, the largest example for which we havebeen able to compute all analyses had approximately 2500).The parse histories resulting from semi-automatic parsing are automatically storedand can be used to derive the probabilistic information that will guide the parser aftertraining.
We return to a discussion of the manner in which this information is utilizedin Section 7.6.
Non-Deterministic LR Parsing with Unification GrammarsAs well as building an interactive parsing system incorporating the ANLT grammar(described above), we have implemented a breadth-first, nondeterministic LR parserfor unification grammars.
This parser is integrated with the Grammar DevelopmentEnvironment (GDE; Carroll et al 1988) in the ANLT system, and provided as analternative parser for use with stable grammars for batch parsing of large bodies oftext.
The existing chart parser, although slower, has been retained since it is moresuited to grammar development, because of the speed with which modifications tothe grammar can be compiled and its better debugging facilities (Boguraev et al 1988).Our nondeterministic LR parser is based on Kipps' (1989) reformulation of Tomi-ta's (1987) parsing algorithm and uses a graph-structured stack in the same way.
Ourparser is driven by the LALR(1) state table computed from the backbone grammar,but in addition on each reduction the parser performs the unifications appropriate tothe unification grammar version of the backbone rule involved.
The analysis beingpursued fails if one of the unifications fails.
The parser performs ub-analysis sharing(where if two or more trees have a common sub-analysis, that sub-analysis i repre-sented only once), and local ambiguity packing (in which sub-analyses that have thesame top node and cover the same input have their top nodes merged, being treatedby higher level structures as a single sub-analysis).
However, we generalize the tech-nique of atomic category packing described by Tomita, driven by atomic categorynames, to complex feature-based categories following Alshawi (1992): the packing ofsub-analyses i  driven by the subsumption relationship between the feature values intheir top nodes.
An analysis is only packed into one that has already been found ifits top node is subsumed by, or is equal to that of the one already found.
An analy-sis, once packed, will thus never need to be unpacked uring parsing (as in Tomita'ssystem) since the value of each feature will always be uniquely determined.Our use of local ambiguity packing does not in practice seem to result in exponen-tially bad performance with respect to sentence l ngth (cf.
Johnson 1989) since we havebeen able to generate packed parse forests for sentences of over 30 words having manythousands of parses.
We have implemented a unification version of Schabes' (1991a)chart-based LR-like parser (which is polynomial in sentence length for CF grammars),but experiments with the ANLT grammar suggest hat it offers no practical advan-tages over our Tomita-style parser, and Schabes' table construction algorithm yieldsless fine-grained and, therefore, less predictive parse tables.
Nevertheless, earchingthe parse forest exhaustively to recover each distinct analysis proved computationallyintractable for sentences over about 22 words in length.
Wright, Wrigley, and Shar-man (1991) describe a Viterbi-like algorithm for unpacking parse forests containingprobabilities of (sub-)analyses to find the n-best analyses, but this approach does notgeneralize (except in a heuristic way) to our approach in which unification failureon the different extensions of packed nodes (resulting from differing super- or sub-44Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingTable 4Chart and LR parse times for the LDOCE definition the state of beingaway or of not being present with the ANLT grammar (in CPU secondson a DEC 3100).Parser Parse timeGDE (bottom-up) chart parser 7.9LR semi-automatic (with 4-choice lookahead) 6.0LR nondeterministic 5.8analyses) cannot be computed 'locally.'
In subsequent work (Carroll and Briscoe 1992)we have developed such a heuristic technique for best-first search of the parse for-est which, in practice, makes the recovery of the most probable analyses much moreefficient (allowing analysis of sentences containing over 30 words).We noticed during preliminary experiments with our unification LR parser that itwas often the case that the same unifications were being performed repeatedly, evenduring the course of a single reduce action.
The duplication was happening in caseswhere two or more pairs of states in the graph-structured stack had identical complexcategories between them (for example due to backbone grammar ambiguity).
During areduction with a given rule, the categories between each pair of states in a backwardstraversal of the stack are collected and unified with the appropriate daughters of therule.
Identical categories appearing here between traversed pairs of states leads toduplication of unifications.
By caching unification results we eliminated this wastedeffort and improved the initially poor performance of the parser by a factor of aboutthree.As for actual parse times, Table 4 compares those for the GDE chart parser, thesemi-automatic, user-directed LR parser, and the nondeterministic LR parser.
Our gen-eral experience is that although the nondeterministic LR parser is only around 30-50%faster than the chart parser, it often generates as little as a third the amount of garbage.
(The relatively modest speed advantage compared with the substantial space savingappears to be due to the larger overheads involved in LR parsing).
Efficient use ofspace is obviously an important factor for practical parsing of long and ambiguoustexts.7.
LR Parsing with Probabilistic DisambiguationSeveral researchers (Wright and Wrigley 1989; Wright 1990; Ng and Tomita 1991;Wright, Wrigley, and Sharman 1991) have proposed using LR parsers as a practi-cal method of parsing with a probabilistic ontext-free grammar.
This approach as-sumes that probabilities are already associated with a CFG and describes techniquesfor distributing those probabilities around the LR parse table in such a way that aprobabilistic ranking of alternative analyses can be computed quickly at parse time,and probabilities assigned to analyses will be identical to those defined by the originalprobabilistic CFG.
However, our method of constructing the training corpus allowsus to associate probabilities with an LR parse table directly, rather than simply withrules of the grammar.
An LR parse state encodes information about the left and rightcontext of the current parse.
Deriving probabilities relative to the parse context willallow the probabilistic parser to distinguish situations in which identical rules reapply45Computational Linguistics Volume 19, Number 1in different ways across different derivations or apply with differing probabilities indifferent contexts.Semi-automatic parsing of the training corpus yields a set of LR parse histories thatare used to construct the probabilistic version of the LALR(1) parse table.
The parsetable is a nondeterministic f nite-state automaton so it is possible to apply Markovmodeling techniques to the parse table (in a way analogous to their application tolexical tagging or CFGs).
Each row of the parse table corresponds to the possibletransitions out of the state represented by that row, and each transition is associatedwith a particular lookahead item and a parse action.
Nondeterminism arises whenmore than one action, and hence transition, is possible given a particular lookaheaditem.
The most straightforward technique for associating probabilities with the parsetable is to assign a probability to each action in the action part of the table (e.g.
Wright1990).
5If probabilities are associated irectly with the parse table rather than derivedfrom a probabilistic CFG or equivalent global pairing of probabilities to rules, thenthe resulting probabilistic model will be more sensitive to parse context.
For example,in a derivation for the sentence he loves her using Grammar 1, the distinction betweenreducing the first pronoun and second pronoun to NP--using rule 5 (NP --> ProNP)--can be maintained in terms of the different lookahead items paired with the reduceactions relating to this rule (in state 5 of the parse table in Figure 2); in the first case, thelookahead item will be Vi, and in the second $ (the end of sentence marker).
However,this approach does not make maximal use of the context encoded into a transitionin the parse table, and it is possible to devise situations in which the reduction ofa pronoun in subject position and elsewhere would be indistinguishable in terms oflookahead alone; for example, if we added appropriate rules for adverbs to Grammar 1,then this reduction would be possible with lookahead Adv in sentences such as hepassionately oves her and he loves her passionately.A slightly less obvious approach is to further subdivide reduce actions accordingto the state reached after the reduce action has applied.
This state is used togetherwith the resultant nonterminal to define the state transition in the goto part of theparse table.
Thus, this move corresponds to associating probabilities with transitionsin the automaton rather than with actions in the action part of the table.
For example,a reduction of pronoun to NP in subject position in the parse table for Grammar 1 inFigure 2 always results in the parser returning to state 0 (from which the goto tabledeterministically prescribes a transition to state 7 with nonterminal RP).
Reduction toNP of a pronoun in object position always results in the parser eturning to state 11.Thus training on a corpus with more subject han nonsubject pronominal NPs will nowresult in a probabilistic preference for reductions that return to 'pre-subject' states with'post-subject' lookaheads.
Of course, this does not mean that it will be impossible todevise grammars in which reductions cannot be kept distinct hat might, in principle,have different frequencies of occurrence.
However, this approach appears to be thenatural stochastic, probabilistic model that emerges when using a LALR(1) table.
Anyfurther sensitivity to context would require sensitivity to patterns in larger sections ofa parse derivation than can be defined in terms of such a table.The probabilities required to create the probabilistic version of the parse table canbe derived from the set of parse histories resulting from the training phase describedin Section 5, by computing the frequency with which each transition from a particularstate has been taken and converting these to probabilities such that the probabilities5 In our implementation, the probabilities are actually stored separately from the parse table to ensurethat otherwise-sharable transitions in the table can still be represented compactly even if theirprobabilities differ.46Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingState  $ Det N@ p ProNP V i  Vt. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.0 s3 s2(.50) (.50).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 rl(0 .83).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.2 r5 r5 r5 r5(8 .33) (0 .50).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.3 s4(i.
00).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.4 r l0  r l0 r l0 r l0 r l0(3 .Ii 6 .ii) (3 .17 5 .22) (3 .ii) (3 .ii 5 .ii).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.5 r6 84 r6 r6 r6(8 .13 Ii .13) (.33) (ii .13) (0 .20).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.6 r8 r8 r8 r8 r8(3 .17 5 .17) (3 .25) (3 .17)s4(.17).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.7 88 s13 sl l(.43) (.43).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.8 83 s2(.50) (.50).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.9 r9 r9 r9 r9(12 .40) (12 .40)88. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.i0 r7 r7 r7 r7(11 .40) (11 .40).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.ii 83 82(.75).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.12 r3 88(7 .43) (.43).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.13 r4(7 .75).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.14 r2(0 .84).
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.15 acc(l.00)Figure 9A probabilistic version of the parse table for Grammar 1.assigned to each transition from a given state sum to one.
In Figure 9 we show aprobabilistic LALR(1) parse table for Grammar 1 derived from a simple, partial (andartificial) training phase.
In this version of the table a probability is associated with eachshift action in the standard way, but separate probabilities are associated with reduce47Computational Linguistics Volume 19, Number 1o) oi) 0 Det  32) 0 Det  3 N@ 43) 0 Det 3 N4) 0 Det  3 N 55) 0 Det  3 N 5 N@ 46) 0 Det  3 N 5 N7) 0 Det  3 N 5 N 6(Det)(N@I) .50(N@2) 1.00(N@2)(N@2) .17(N@3) .33(N@3)(N@3) .228a) 0 Det  3 N 5 N 6 N@ 4 (Vi) .179a) 0 Det  3 N 5 N 6 N (Vi)10a) 0 Det  3 N 5 N 6 N 6 (Vi) .06lla) 0 Det  3 N 5 N (Vi)12a) 0 Det 3 N 5 N 6 (Vi) .0813a) 0 Det  3 N (Vi)8b) 0 Det  3 N (N@3)9b) 0 Det  3 N 5 (N@3) .2510b) 0 Det  3 N 5 N@ 4 (Vi) .33llb) 0 Det  3 N 5 N (Vi)12b) 0 Det  3 N 5 N 6 (Vi) .ii13b) 0 Det  3 N (Vi)14) 0 Det  3 N 5 (Vi) .1715) 0 NP (Vi)16) 0 NP 7 (Vi) .2017) 0 NP 7 V i  13 ($) .4318) 0 NP 7 VP ($)19) 0 NP 7 VP 14 ($) .752o) o s ($)21) 0 S 1 ($) .8322) 0 S' ($)23) 0 S' 15 ($) 1 .00Figure 10Parse derivations for the winter holiday camp closed.actions, depending on the state reached after the action; for example, in state 4 withlookahead N~ the probability of reducing with rule 10 is 0.17 if the state reached is 3 and0.22 if the state reached is 5.
The actions that have no associated probabilities are onesthat have not been utilized during the training phase; each is assigned a smoothedprobability that is the reciprocal of the result of adding one to the total number ofobservations of actions actually taken in that state.
Differential probabilities are thusassigned to unseen events in a manner analogous to the Good-Turing technique.
Forthis reason, the explicit probabilities for each row add up to less than one.
The gotopart of the table is not shown because it is always deterministic and, therefore, we donot associate probabilities with goto transitions.The difference between our approach and one based on probabilistic CFG can bebrought out by considering various probabilistic derivations using the probabilisticparse table for Grammar 1.
Assuming that we are using probabilities imply to rankparses, we can compute the total probability of an analysis by multiplying togetherthe probabilities of each transition we take during its derivation.
In Figure 10, we givethe two possible complete derivations for a sentence such as the winter holiday campclosed consisting of a determiner, three nouns, and an intransitive verb.
The ambiguityconcerns whether the noun compound is left- or right-branching, and, as we saw inSection 2, a probabilistic CFG cannot distinguish these two derivations.
The probabilityof each step can be read off the action table and is shown after the lookahead item inthe figure.In step 8 a shift-reduce conflict occurs so the stack 'splits' while the left- and right-branching analyses of the noun compound are constructed.
The a) branch corresponds48Ted Briscoe and John Carroll Generalized Probabilistic LR Parsingto the right-branching derivation and the product of the probabilities is 4.6 x 10 -8,while the product for the left-branching b) derivation is 5.1 x 10 -7.
Since the tablewas constructed from parse histories with a preponderance of left-branching struc-tures this is the desired result.
In practice, this technique is able to distinguish andtrain accurately on 3 of the 5 possible structures for a 4-word noun-noun compound;but it inaccurately prefers a completely left-branching analysis over structures of theform ((n n)(n n)) and ((n (nn)) n).
Once we move to 5-word noun-noun compounds,performance degrades further.
However, this level of performance on such structuralconfigurations i likely to be adequate, because correct resolution of most ambiguityin such constructions i likely to be dominated by the actual exical items that occurin individual texts.
Nevertheless, if there are systematic structural tendencies evidentin corpora (for example, Frazier's \[1988\] parsing strategies predict a preference forleft-branching analyses of such compounds), then the probabilistic model is sensitiveenough to discriminate them.
6In practice, we take the geometric mean of the probabilities rather than their prod-uct to rank parse derivations.
Otherwise, it would be difficult to prevent he systemfrom always developing a bias in favor of analyses involving fewer rules or equiva-lently 'smaller' trees, almost regardless of the training material.
Of course, the needfor this step reflects the fact that, although the model is more context-dependent thanprobabilistic CFG, it is by no means a perfect probabilistic model of NL.
7 For exam-ple, the stochastic nature of the model and the fact that the entire left context of aparse derivation is not encoded in LR state information means that the probabilisticmodel cannot take account of, say, the pattern of resolution of earlier conflicts in thecurrent derivation.
Another respect in which the model is approximate is that we areassociating probabilities with the context-free backbone of the unification grammar.Successful unification of features at parse time does not affect the probability of a(partial) analysis, while unification failure, in effect, sets the probability of any suchanalysis to zero.
As long as we only use the probabilistic model to rank successfulanalyses, this is not particularly problematic.
However, parser control regimes thatattempt some form of best-first search using probabilistic information associated withtransitions might not yield the desired result given this property.
For example, it is notpossible to use Viterbi-style optimization of search for the maximally probable parsebecause this derivation may contain a sub-analysis that will be pruned locally before asubsequent unification failure renders the current most probable analysis impossible.In general, the current breadth-first probabilistic parser is more efficient han itsnonprobabilistic counterpart described in the previous ection.
In contrast to the parserdescribed by Ng and Tomita (1991), our probabilistic parser is able to merge (state andstack) configurations and in all cases still maintain a full record of all the probabilitiescomputed up to that point, since it associates probabilities with partial analyses of theinput so far rather than with nodes in the graph-structured stack.
We are currently6 Although we define our probabilistic model relative to the LR parsing technique, it is likely that thereis an equivalent encoding in purely grammatical terms.
In general our approach corresponds tomaking the probability of rule application conditional on other rules having applied during the parsederivation (e.g.
Magerman and Marcus 1991) and the lexical category of the next word; for example, itwould be possible to create a grammatical representation f the probabilistic model that emerges froma LR(0) table by assigning a set of probabilities associated with rule numbers to each right-hand sidecategory in each rule of a CFG that would encode the probability of a rule being used to expand thatcategory in that context.7 Magerrnan and Marcus (1991) argue that it is reasonable to use the geometric mean when computingthe probability of two or more sub-analyses because the independence assumptions that motivate usingproducts do not hold for such an approximate model.
In Carroll and Briscoe (1992) we present a moremotivated technique for normalizing the probability of competing sub-analyses in the parse forest.49Computational Linguistics Volume 19, Number 1experimenting with techniques for probabilistically unpacking the packed parse forestto recover the first few most probable derivations without the need for exhaustivesearch or full expansion.8.
Parsing LDOCE Noun DefinitionsIn order to test the techniques and ideas described in previous ections, we undertooka preliminary experiment using a subset of LDOCE noun definitions as our test corpus.
(The reasons for choosing this corpus are discussed in the introduction.)
A corpus ofapproximately 32,000 noun definitions was created from LDOCE by extracting thedefinition fields and normalizing the definitions to remove punctuation, font controlinformation, and so forth, s A lexicon was created for this corpus by extracting theappropriate lemmas and matching these against entries in the ANLT lexicon.
The10,600 resultant entries were loaded into the ANLT morphological system (Ritchie etal.
1987) and this sublexicon and the full ANLT grammar formed the starting pointfor the training process.A total of 246 definitions, selected without regard for their syntactic form, wereparsed semi-automatically using the parser described in Section 5.
During this process,further ules and lexical entries were created for some definitions that failed to parse.Of the total number, 150 were successfully parsed and 63 lexical entries and 14 ruleswere added.
Some of the rules required reflected general inadequacies in the ANLTgrammar; for example, we added rules to deal with new partitives and prepositionalphrase and verb complementation.
However, 7 of these rules cover relatively idiosyn-cratic properties of the definition sublanguage; for example, the postmodification fpronouns by relative clause and prepositional phrase in definitions beginning some-thing that .
.
.
.
that of .
.
.
,  parenthetical phrases headed by adverbs, such as the period...esp the period, and coordinations without explicit conjunctions ending with etc., andso forth.
Further special rules will be required to deal with brackets in definitions tocover conventions such as a man (monk) or woman (nun) who lives in a monastery, whichwe ignored for this test.
Nevertheless, the number of new rules required is not greatand the need for most was identified very early in the training process.
Lexical entriesare more problematic, since there is little sign that the number of new entries requiredwill tail off.
However, many of the entries required reflect systematic nadequacies inthe ANLT lexicon rather than idiosyncrasies of the corpus.
It took approximately oneperson-month o produce this training corpus.
As a rough guide, it takes an averageof 15 seconds to resolve a single interaction with the parser.
However, the time a parsetakes can often be lengthened by incorrect choices (and the consequent eed to backup manually) and by the process of adding lexical entries and occasional rules.The resultant parse histories were used to construct the probabilistic parser (asdescribed in the previous ection).
This parser was then used to reparse the trainingcorpus, and the most highly ranked analyses were automatically compared with theoriginal parse histories.
We have been able to reparse in a breadth-first fashion allbut 3 of the 150 definitions that were parsed manually.
9 (These three are each over8 The corpus contains about 17,000 unique headwords and 13,500 distinct word forms in the definitions.Its perplexity (PP) measures based on bigram and trigram word models and an estimate of an infinitemodel were PP(2) = 104, PP(3) = 41, and PP(inf) = 8 (Sharman 1991).9 The results we report here are from using the latest versions of the ANLT grammar and LR parsingsystem.
Briscoe and Carroll (1991) report an earlier version of this experiment using different versionsof the grammar and parser in which results differed in minor ways.
Carroll and Briscoe (1992) report athird version of the experiment in which results were improved slightly through the use of a betternormalization and parse forest unpacking technique.50i~i~!ii!iiii@!20-Number ofdefinitions10-0Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingFigure 11hi0 20Definition lengthI-11st ranked analysis correct2nd ranked analysis correct3rd ranked analysis correctcorrect analysis not rankedeither 1st, 2nd or 3rdCorrectness of results for reparsed efinitions with respect to length.I3025 words in length.)
There are 22 definitions one word in length: all of these triviallyreceive correct analyses.
There are 89 definitions between two and ten words in lengthinclusive (mean length 6.2).
Of these, in 68 cases the correct analysis (as defined bythe training corpus) is also the most highly ranked.
In 13 of the 21 remaining cases thecorrect analysis is the second or third most highly ranked analysis.
Looking at these21 cases in more detail, in 8 there is an inappropriate structural preference for 'low' or'local' attachment (see Kimball 1973), in 4, an inappropriate preference for compounds,and in 6 of the remaining 9 cases, the highest ranked result contains a misanalysis of asingle constituent two or three words in length.
If these results are interpreted in termsof a goodness of fit measure such as that of Sampson, Haigh, and Atwell (1989), themeasure would be better ttian 96%.
If we take correct parse/sentence as our measurethen the result is 76%.
For definitions longer than 10 words this latter figure tails off,mainly due to misapplication of such statistically induced, but nevertheless tructural,attachment preferences.
Figure 11 summarizes these results.We also parsed a further 55 LDOCE noun definitions not drawn from the trainingcorpus, each containing up to 10 words (mean length 5.7).
Of these, in 41 cases thecorrect parse is the most highly ranked, in 6 cases it is the second or third most highlyranked, and in the remaining 8 cases it is not in the first three analyses.
This yields acorrect parse/sentence measure of 75%.
Examination of the failures again reveals thata preference for local attachment of postmodifiers accounts for 5 cases, a preferencefor compounds for 1, and the misanalysis of a single constituent for 2.
The othersare mostly caused by the lack of lexical entries with appropriate SUBCAT features.
InFigure 12 we show the analysis for the unseen definition of affectation, which has 20parses of which the most highly ranked is correct.51Computational Linguistics Volume 19, Number 1N2N2iN1N1N1 CONJN I  N2 VPfee l inc  or  N1 that  is VPI imanner  pretende?Figure 12Parse tree for afeelingormanner that is pretended.N1N1/N CONJN Iperson  or  N1 N2I Ith ing thatN2\N2IN1SISVPVP CONJVPsuppor t~ E or  VPhelps EFigure 13Parse tree for a person or thing that supports or helps.Figure 13 shows the highest-ranked analysis assigned to one definition of aid.
Thisis an example of a false positive which, in this case, is caused by the lack of a lexicalentry for support as an intransitive verb.
Consequently, the parser finds, and rankshighest, an analysis in which supports and helps are treated as transitive verbs formingverb phrases with object NP gaps, and that supports or helps as a zero relative clausewith that analyzed as a prenominal subject--compare a person or thing that that supportsor helps.
It is difficult to fault this analysis and the same is true for the other falsepositives we have looked at.
Such false positives present he biggest challenge to thetype of system we are attempting to develop.
One hopeful sign is that the analysesassigned such examples appear to have low probabilities relative to most probablecorrect analyses of other examples.
However, considerably more data will be requiredbefore we can decide whether this trend is robust enough to provide the basis forautomatic identification of false positives.52Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingUsing a manually disambiguated training corpus and manually tuned grammarappears feasible with the definitions sublanguage.
Results comparable to those ob-tained by Fujisaki et al (1989) and Sharman, Jelinek, and Mercer (1990) are possibleon the basis of a quite modest amount of manual effort and a very much smallertraining corpus, because the parse histories contain little 'noise' and usefully reflectthe semantically and pragmatically appropriate analysis in the training corpus, andbecause the number of failures of coverage were reduced to some extent by adding therules specifically motivated by the training corpus.
Unlike Fujisaki et al or Sharman,Jelinek, and Mercer, we did not integrate information about lexemes into the rule prob-abilities or make use of lexical syntactic probability.
It seems likely that the structuralpreference for local attachment might be overruled in appropriate contexts if lexeme(or better, word sense) information were taken into account.
The slightly worse results(relative to mean definition length) obtained for the unseen data appear to be causedmore by the nonexistence of a correct analysis in a number of cases, rather than bya marked decline in the usefulness of the rule probabilities.
This again highlights theneed to deal effectively with examples outside the coverage of the grammar.9.
Conclusions and Further WorkThe system that we have developed offers partial and practical solutions to two ofthe three problems of corpus analysis we identified in the introduction.
The problemof tuning an existing grammar to a particular corpus or sublanguage is addressedpartly by manual extensions to the grammar and lexicon during the semi-automatictraining phase and partly by use of statistical information regarding frequency of ruleuse gathered during this phase.
The results of the experiment reported in the lastsection suggest hat syntactic peculiarities of a sublanguage or corpus surface quiterapidly, so that manual additions to the grammar during the training phase are prac-tical.
However, lexical idiosyncrasies are far less likely to be exhausted uring thetraining phase, suggesting that it will be necessary to develop an automatic method ofdealing with them.
In addition, the current system does not take account of differingfrequencies of occurrence of lexical entries; for example, in the LOB corpus the verbbelieve occurs with a finite sentential complement in 90% of citations, although it isgrammatical with at least five further patterns of complementation.
This type of lexicalinformation, which will very likely vary between sublanguages, should be integratedinto the probabilistic model.
This will be straightforward in terms of the model, sinceit merely involves associating probabilities with each distinct lexical entry for a lex-eme and carrying these forward in the computation of the likelihood of each parse.However, the acquisition of the statistical information from which these probabilitiescan be derived is more problematic.
Existing lexical taggers are unable to assign tagsthat reliably encode subcategorization information.
It seems likely that automatic ac-quisition of such information must await successful techniques for robust parsing of,at least, phrases in corpora (though Brent \[1991\] claims to be able to recognize somesubcategorization patterns using large quantities of untagged text).The task of selecting the correct analysis from the set licensed by the grammaris also partially solved by the system.
It is clear from the results of the preliminaryexperiment reported in the previous section that it is possible to make the semanti-cally and pragmatically correct analysis highly ranked, and even most highly rankedin many cases, just by exploiting the frequency of occurrence of the syntactic rules inthe training data.
However, it is also clear that this approach will not succeed in allcases; for example, in the experiment the system appears to have developed a prefer-ence for local attachment of prepositional phrases (PPs), which is inappropriate in a53Computational Linguistics Volume 19, Number 1significant number of cases.
It is not surprising that probabilities based solely on thefrequency of syntactic rules are not capable of resolving this type of ambiguity; in anexample such as John saw the man on Monday again it is the temporal interpretation ofMonday that favors the adverbial interpretation (and thus nonlocal attachment).
Suchexamples are syntactically identical to ones such as John saw the man on the bus again,in which the possibility of a locative interpretation creates a mild preference for theadjectival reading and local attachment.
To select he correct analysis in such cases itwill be necessary to integrate information concerning word sense collocations into theprobabilistic analysis.
In this case, we are interested in collocations between the headof a PP complement, a preposition and the head of the phrase being postmodified.
Ingeneral, these words will not be adjacent in the text, so it will not be possible to useexisting approaches unmodified (e.g.
Church and Hanks 1989), because these applyto adjacent words in unanalyzed text.
Hindle and Rooth (1991) report good resultsusing a mutual information measure of collocation applied within such a structurallydefined context, and their approach should carry over to our framework straightfor-wardly.One way of integrating 'structural' collocational information into the system pre-sented above would be to make use of the semantic omponent of the (ANLT) gram-mar.
This component pairs logical forms with each distinct syntactic analysis thatrepresent, among other things, the predicate-argument structure of the input.
In theresolution of PP attachment and similar ambiguities, it is 'collocation' at this level ofrepresentation that appears to be most relevant.
Integrating a probabilistic rankingof the resultant logical forms with the probabilistic ranking of the distinct syntacticanalyses presents no problems, in principle.
However, once again, the acquisition ofthe relevant statistical information will be difficult, because it will require considerablequantities of analyzed text as training material.
One way to ameliorate the problemmight be to reduce the size of the 'vocabulary' for which statistics need to be gatheredby replacing lexical items with their superordinate t rms (or a disjunction of suchterms in the case of ambiguity).
Copestake (1990, 1992) describes a program capableof extracting the genus term of a definition from an LDOCE definition, resolving thesense of such terms, and constructing hierarchical taxonomies of the resulting wordsenses.
Taxonomies of this form might be used to replace PP complement heads andpostmodified heads in corpus data with a smaller number of superordinate concepts.This would make the statistical data concerning trigrams of head-preposition-headless sparse (cf.
Gale and Church 1990) and easier to gather from a corpus.
Never-theless, it will only be possible to gather such data from determinately syntacticallyanalyzed material.The third problem of dealing usefully with examples outside the coverage of thegrammar even after training is not addressed by the system we have developed.
Nev-ertheless, the results of the preliminary experiment for unseen examples indicate that itis a significant problem, at least with respect to lexical entries.
A large part of the prob-lem with such examples is identifying them automatically.
Some such examples willnot receive any parse and will, therefore, be easy to spot.
Many, though, will receiveincorrect parses (one of which will be automatically ranked as the most probable) andcan, therefore, only be identified manually (or perhaps on the basis of relative improb-ability).
Jensen et al (1983) describe an approach to parsing such examples based onparse 'fitting' or rule 'relaxation' to deal with 'ill-formed' input.
An approach of thistype might work with input that receives no parse, but cannot help with the identifica-tion of those that only receive an incorrect one.
In addition, it involves annotating eachgrammar ule about what should be relaxed and requires that semantic interpretationcan be extended to 'fitted' or partial parses (e.g.
Pollack and Pereira 1988).54Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingSampson, Haigh, and Atwell (1989) propose a more thorough-going probabilisticapproach in which the parser uses a statistically defined measure of 'closest fit' tothe set of analyses contained in a 'tree bank' of training data to assign an analysis.This approach attempts to ensure that analyses of new data will conform as closely aspossible to existing ones, but does not require that analyses assigned are well formedwith respect o any given generative grammar implicit in the tree bank analyses.Sampson, Haigh, and Atwell report some preliminary results for a parser of this typethat uses the technique of simulated annealing to assign the closest fitting analysison the basis of initial training on the LOB treebank and automatic updating of itsstatistical data on the basis of further parsed examples.
Sampson, Haigh, and Atwellgive their results in terms of a similarity measure with respect o correct analysesassigned by hand.
For a 13-sentence sample the mean similarity measure was 80%,and only one example received a fully correct analysis.
These results suggest hat thetechnique is not reliable enough for practical corpus analysis, to date.
In addition,the analyses assigned, on the basis of the LOB treebank scheme, are not syntacticallydeterminate (for example, syntactic relations in unbounded ependency constructionsare not represented).A more promising approach with similar potential robustness would be to infera probabilistic grammar using Baum-Welch re-estimation from a given training cor-pus and predefined category set, following Lari and Young (1990) and Pereira andSchabes (1992).
This approach as the advantage that the resulting grammar definesa well-defined set of analyses for which rules of compositional interpretation mightbe developed.
However, the technique is limited in several ways; firstly, such gram-mars are restricted to small (maximum about 15 nonterminal) CNF CFGs becauseof the computational cost of iterative re-estimation with an algorithm polynomial insentence length and nonterminal category size; and secondly, because some form ofsupervised training will be essential if the analyses assigned by the grammar are tobe linguistically motivated.
Immediate prospects for applying such techniques to real-istic NL grammars do not seem promising--the ANLT backbone grammar discussedin Section 4 contains almost 500 categories.
However, Briscoe and Waegner (1992)describe an experiment in which, firstly, Baum-Welch re-estimation was used in con-junction with other more linguistically motivated constraints on the class of grammarsthat could be inferred, such as 'headedness'; and secondly, initial probabilities wereheavily biased in favor of manually coded, linguistically highly plausible rules.
Thisapproach resulted in a simple tag sequence grammar often able to assign coherent andsemantically/pragmatically plausible analyses to tag sequences drawn from the Spo-ken English Corpus.
By combining such techniques and relaxing the CNF constraint,for example, by adopting the trellis algorithm version of Baum-Welch re-estimation(Kupiec 1991), it might be possible to create a computationally tractable system oper-ating with a realistic NL grammar that would only infer a new rule from a finite spaceof linguistically motivated possibilities in the face of parse failure or improbability.
Inthe shorter term, such techniques combined with simple tag sequence grammars mightyield robust phrase-level 'skeleton' parsers that could be used as corpus analysis tools.The utility of the system reported here would be considerably improved by a moretractable approach to probabilistically unpacking the packed parse forest han exhaus-tive search.
Finding the n-best analyses would allow us to recover analyses for longersentences where a parse forest is constructed and would make the approach generallymore efficient.
Carroll and Briscoe (1992) present a heuristic algorithm for parse for-est unpacking that interleaves normalization of competing sub-analyses with best-firstextraction of the n most probable analyses.
Normalization of competing sub-analyseswith respect o the longest derivation both allows us to prune the search probabilisti-55Computational Linguistics Volume 19, Number 1cally and to treat the probability of analyses as the product of the probability of theirsub-analyses, without biasing the system in favor of shorter derivations.
This modi-fied version of the system presented here is able to return analyses for sentences over31 words in length, yields slightly better results on a replication of the experimentreported in Section 8, and the resultant parser is approximately three times faster atreturning the three highest-ranked parsers than that presented here.In conclusion, the main positive points of the paper are that 1) LR parse tables canbe used to define a more context-dependent a d adequate probabilistic model of NL,2) predictive LR parse tables can be constructed automatically from unification-basedgrammars in standard notation, 3) effective parse table construction and representationtechniques can be defined for realistically sized ambiguous NL grammars, 4) semi-automatic LR based parse techniques can be used to efficiently construct rainingcorpora, and 5) the LR parser and ANLT grammar jointly define a useful probabilisticmodel into which probabilities concerning lexical subcategorization a d structurallydefined word sense collocations could be integrated.AcknowledgmentsThis research is supported bySERC/DTI-IED project 4/1/1261'Extensions to the Alvey Natural LanguageTools' and by ESPRIT BRA 3030'Acquisition of Lexical Information fromMachine-Readable Dictionaries.'
We wouldlike to thank Longman Group Ltd. forallowing us access to the LDOCE MRD andAnn Copestake and Antonio Sanfilippo forconsiderable help in the analysis of theLDOCE noun definition corpus.
RichardSharman kindly calculated the perplexitymeasures for this corpus.
In addition, HiyanAlshawi, David Weir, and Steve Young havehelped clarify our thinking and madeseveral suggestions that have influenced theway this research as developed.
AlexLascarides and four anonymous reviewers'comments on earlier drafts were veryhelpful to us in preparing the final version.All errors and mistakes remain ourresponsibility.ReferencesAho, A.; Sethi, R.; and Ullman, J.
(1986).Compilers: Principles, Techniques and Tools.Addison-Wesley.Alshawi, H., ed.
(1992).
The Core LanguageEngine.
MIT Press.Baker, J.
(1982).
"Trainable grammars forspeech recognition."
SpeechCommunication Papers for the 97thMeeting of the Acoustical Society ofAmerica, 547-550.Baum, L. (1972).
"An inequality andassociated maximization technique instatistical estimation for probabilisticfunctions of Markov processes.
"Inequalities, III, 1-8.Bermudez, M. (1991).
"A unifying model forlookahead LR parsing."
ComputerLanguages, 16(2), 167-178.Boguraev, B.; Carroll, J.; Briscoe, E.; andGrover, C. (1988).
"Software support forpractical grammar development."
InProceedings, 12th International Conference onComputational Linguistics, Budapest,Hungary, 54-58.Brent, M. (1991).
"Automatic acquisition ofsubcategorization frames from untaggedtext."
In Proceedings, 29th Annual Meetingof the Association for ComputationalLinguistics, Berkeley, CA, 209-214.Briscoe, E. (1987).
Modelling Human SpeechComprehension: A Computational Approach.Ellis Horwood and Wiley.Briscoe, E.; Grover, C.; Boguraev, B.; andCarroll, J.
(1987).
"A formalism andenvironment for the development of alarge grammar of English.
In Proceedings,l Oth International Joint Conference onArtificial Intelligence, Milan, Italy, 703-708.Briscoe, E., and Carroll, J.
(1991).
"Generalized probabilistic LR parsing ofnatural language (corpora) withunification-based grammars."
TechnicalReport 224, Computer Laboratory,Cambridge University.Briscoe, E., and Waegner, N. (1992).
"Robuststochastic parsing using theinside-outside algorithm."
In Proceedings,AAAI Workshop on Statistically-based NLPTechniques, San Jose, CA.Carroll, J., and Grover, C. (1989).
"Thederivation of a large computationallexicon for English."
In ComputationalLexicography for Natural Language56Ted Briscoe and John Carroll Generalized Probabilistic LR ParsingProcessing, edited by B. Boguraev andE.
Briscoe, 117-134.
Longman.Carroll, J.; Boguraev, B.; Grover, C.; andBriscoe, E. (1988).
"The grammardevelopment environment: a user guide.
"Technical Report 127, ComputerLaboratory, Cambridge University.Carroll, J., and Briscoe, E.
(1992).
"Probabilistic normalisation andunpacking of packed parse forests forunification-based grammars."
InProceedings, AAAI Fall Symposium onProbabilistic Approaches toNatural Language,Cambridge, MA, 33-38.Chapman, N. (1987).
LR Parsing: Theory andPractice.
Cambridge University Press.Church, K., and Hanks, P. (1989).
"Wordassociation orms, mutual information,and lexicography."
In Proceedings, 27thAnnual Meeting of the Association forComputational Linguistics, Vancouver,British Columbia, 76-83.Church, K., and Patil, R. (1982).
"Copingwith syntactic ambiguity or how to putthe block in the box on the table.
"Computational Linguistics, 8, 139-149.Copestake, A.
(1990).
"An approach tobuilding the hierarchical element of alexical knowledge base from amachine-readable dictionary."
InProceedings, Workshop on Inheritance inNatural Language Processing, Tilburg, 19-29.Copestake, A.
(1992).
"Defaults in lexicalrepresentation."
In Default Inheritance inUnification-based Approaches tothe Lexicon,edited by E. Briscoe, A. Copestake, andV.
de Paiva.
Cambridge University Press.Culic, K. II, and Cohen, R.
(1973).
"LR-regular grammars--an extension ofLR(k) grammars."
Journal of Computer andSystem Sciences, 7,66-96.Cutting, D.; Kupiec, J.; Pedersen, J.; andSibun, P. (1992).
"A practicalpart-of-speech tagger."
3rd Applied ACL,Trento, Italy, 133-140.DeRemer, E, and Pennello, T.
(1982).
"Efficient computation of LALR(1)look-ahead sets."
ACM Transactions onProgramming Languages and Systems, 4(4),615-649.de Rose, S. (1988).
"Grammatical categorydisambiguation by statisticaloptimization."
Computational Linguistics,14(1), 31-39.Earley, J.
(1970).
"An efficient context-freeparsing algorithm."
Communications of theACM, 13(2), 94-102.Frazier, L. (1988).
"Grammar and languageprocessing."
In Linguistics: The CambridgeSurvey, Volume 2, edited by F. Newmeyer,14-45.
Cambridge University Press.Fujisaki, T.; Jelinek, E; Cocke, J.; Black E.;and Nishino, T. (1989).
"A probabilisticmethod for sentence disambiguation."
InProceedings, 1st International Workshop onParsing Technologies, Carnegie-MellonUniversity, Pittsburgh, PA, 105-114.Gale, W., and Church, K. (1990).
"Poorestimates of context are worse thannone."
DARPA Speech and Natural LanguageWorkshop, Hidden Valley, PA, 283-287.Garside, R.; Leech, G.; and Sampson, G.(1987).
The Computational Analysis ofEnglish: A Corpus-Based Approach.Longman.Gazdar, G.; Klein, E.; Pullum, G.; and Sag, I.(1985).
Generalized Phrase StructureGrammar.
Blackwell.Gazdar, G., and Mellish, C. (1989).
NaturalLanguage Processing inLisp.Addison-Wesley.Grosch, J.
(1990).
"Lalr--A generator forefficient parsers."
Software--Practice andExperience, 20(11), 1115-1135.Grover, C.; Briscoe, E.; Carroll, J.; andBoguraev, B.
(1989).
"The Alvey naturallanguage tools grammar (secondrelease)."
Technical Report 162, ComputerLaboratory, Cambridge University.Hektoen, E. (1991).
"LAR processing fornatural language grammars."
Mastersdissertation, Computer Laboratory,Cambridge University, Cambridge, U.K.Hindle, D., and Rooth, M.
(1991).
"Structural ambiguity and lexicalrelations."
In Proceedings, 29th AnnualMeeting of the Association for ComputationalLinguistics, Berkeley, CA, 229-236.Holmes, J.
(1988).
Speech Synthesis andRecognition.
Van Nostrand Reinhold.Workingham, UK.Jensen, K.; Heidorn, G.; Miller, L.; andRavin, Y.
(1983), "Parse fitting and prosefixing: getting a hold on ill-formedness.
"Computational Linguistics, 9, 147-153.Johnson, M. (1989).
"The computationalcomplexity of Tomita's algorithm."
InProceedings, I t International Workshop onParsing Technologies, Carnegie-MellonUniversity, Pittsburgh, PA, 203-208.Kimball, J.
(1973).
"Seven principles ofsurface structure parsing in naturallanguage."
Cognition, 2, 15-47.Kipps, J.
(1989).
"Analysis of Tomita'salgorithm for general context-freeparsing."
In Proceedings, 1st InternationalWorkshop on Parsing Technologies,Carnegie-Mellon University, Pittsburgh,PA, 193-202.Klein, E., and Martin, M. (1989).
"The parsergenerating system PGSU."
Software--Practice and Experience, 19(11), 1015-1028.57Computational Linguistics Volume 19, Number 1Kristensen, B., and Madsen, O.
(1981).
"Methods for computing LALR(k)lookahead."
ACM Transactions onProgramming Languages and Systems, 3(1),60-82.Kupiec, J.
(1991).
"A trellis-based algorithmfor estimating the parameters of a hiddenstochastic context-free grammar," DARPASpeech and Natural Language Workshop,Asilomar, CA.Lari, K., and Young, S. (1990).
"Theestimation of stochastic context-freegrammars using the Inside-Outsidealgorithm."
Computer Speech and LanguageProcessing, 4, 35-56.Leech, G., and Garside, R. (1991).
"Runninga grammar factory: the production ofsyntactically analysed corpora or'treebanks'."
In English Computer Corpora:Selected Papers and Bibliography, edited byS.
Johansson and A. Strenstrom.
Moutonde Gruyter.Magerman, D., and Marcus, M.
(1991).
"Pearl: A probabilistic hart parser."
InProceedings, 2nd International Workshop onParsing Technologies, Cancun, Mexico,193-199.Meteer, M.; Schwartz, R.; and Weischedel, R.(1991).
"POST: Using probabilities inlanguage processing."
In Proceedings, 12thInternational Joint Conference on ArtificialIntelligence, Sydney, Australia, 960-965.Nakazawa, T. (1991).
"An extended LRparsing algorithm for grammars usingfeature-based syntactic ategories."
InProceedings, 5th European Conference oftheAssociation for Computational Linguistics,Berlin, Germany, 69-74.Ng, S.-K., and Tomita, M.
(1991).
"Probabilistic parsing for generalcontext-free grammars."
In Proceedings,2nd International Workshop on ParsingTechnologies, Cancun, Mexico, 154-163.Osborne, M. (1990).
"Corpus parsing.
"Masters dissertation, University ofCambridge, Cambridge, U.K.Pereira, E, and Shieber, S. (1987).
Prolog andNatural Language Analysis.
University ofChicago Press.Pereira, F., and Warren, D. (1980).
"Definiteclause grammars for language analysis--asurvey of the formalism and acomparison with augmented transitionnetworks."
Artificial Intelligence, 13(3),231-278.Pereira, E, and Schabes, Y.
(1992).
"Inside-outside r -estimation for partiallybracketed corpora."
In Proceedings, 30thAnnual Meeting of the Association forComputational Linguistics, Newark, DE,128-135.Pollack, M., and Pereira, E (1988).
"Anintegrated framework for semantic andpragmatic interpretation."
In Proceedings,26th Annual Conference ofthe Association forComputational Linguistics, Buffalo, NY,75-86.Pollard, C., and Sag, I.
(1987).Information~Based Syntax and Semantics:Volume 1--Fundamentals.
ChicagoUniversity Press.Procter, P., ed.
(1978).
The Longman Dictionaryof Contemporary English.
Longman.Ritchie, G.; Pulman, S.; Russell, G.; andBlack, A.
(1987).
"A computationalframework for lexical description.
"Computational Linguistics, 13, 290-307.Sampson, G. (1987).
"The grammaticaldatabase and parsing scheme."
In TheComputational Analysis of English: ACorpus-Based Approach, edited byR.
Garside; G. Leech; and G. Sampson,82-96.
Longman.Sampson, G.; Haigh, R.; and Atwell, E.(1989).
"Natural anguage analysis bystochastic optimization: a progress reporton Project APRIL."
Journal of Experimentaland Theoretical Artificial Intelligence, 1271-287.Santorini, B.
(1990).
"Penn treebank taggingand parsing manual."
University ofPennsylvania, CIS Dept.
Unpublishedmanuscript.Schabes, Y.
(1991a).
"Polynomial time andspace shift-reduce parsing of arbitrarycontexbfree grammars."
In Proceedings,29th Annual Meeting of the Association forComputational Linguistics, Berkeley, CA,106-113.Schabes, Y.
(1991b).
"The valid prefixproperty and left to right parsing oftree-adjoining grammar."
In Proceedings,2nd International Workshop on ParsingTechnologies, Cancun, Mexico, 21-30.Sharman, R. (1989).
"Probabilistic ID/LPgrammars for English."
Report 217, IBMUK Scientific Centre, Winchester, England.Sharman, R. (1991).
"An introduction tolanguage modelling."
Unpublishedmanuscript, IBM UK Scientific Centre,Winchester, England.Sharman, R.; Jelinek, F.; and Mercer, R.(1990).
"Generating a grammar forstatistical training."
DARPA Speech andNatural Language Workshop, Hidden Valley,PA, 267-274.Shieber, S. (1983).
"Disambiguation by ashift-reduce parsing technique."
InProceedings, 21st Annual Meeting of theAssociation for Computational Linguistics,MIT, Cambridge, MA, 113-118.Shieber, S. (1984).
"The design of a58Ted Briscoe and John Carroll Generalized Probabilistic LR Parsingcomputer language for linguisticinformation."
In Proceedings, l OthInternational Conference on ComputationalLinguistics, Stanford, CA, 362-366.Shieber, S. (1985).
"Using restriction toextend parsing algorithms for complexfeature-based formalisms."
In Proceedings,23rd Annual Meeting of the Association forComputational Linguistics, Chicago, IL,145-152.Spector, D. (1983).
"Lexing and parsingmodula-2."
SIGPLANNotices, 18(10),25-32.Taylor, L.; Grover, C.; and Briscoe, E.
(1989).
"The syntactic regularity of English nounphrases."
In Proceedings, 4th EuropeanMeeting of the Association for ComputationalLinguistics, UMIST, Manchester, U.K.,256-263.Tomita, M. (1984).
"Parsers for naturallanguages."
In Proceedings, lOthInternational Conference on ComputationalLinguistics, Stanford, CA, 354-357.Tomita, M. (1987).
"An efficient augmentedcontext-free parsing algorithm.
"Computational Linguistics, 13(1), 31--46.Viterbi, A.
(1967).
"Error bounds forconvolutional codes and anasymptotically optimum decodingalgorithm."
IEEE Trans.
Information Theory,IT-13, 260-269.Wright, J.
(1990).
"LR parsing ofprobabilistic grammars with inputuncertainty for speech recognition.
"Computer Speech and Language, 4, 297-323.Wright, J., and Wrigley, E.
(1989).
"Probabilistic LR parsing for speechrecognition."
In Proceedings, 1stInternational Workshop on ParsingTechnologies, Carnegie-Mellon University,Pittsburgh, PA, 193-202.Wright, J.; Wrigley, E.; and Sharman, R.(1991).
"Adaptive probabilisticgeneralized LR parsing."
In Proceedings,2nd International Workshop on ParsingTechnologies, Cancun, Mexico, 154-163.Zeevat, H.; Calder, J.; and Klein, E. (1987).Unification categorial grammar.
InEdinburgh Working Papers in CognitiveScience, 1: Categorial Grammar, UnificationGrammar, and Parsing, edited byN.
Haddock, E. Klein, and G. Morrill,Centre for Cognitive Science, EdinburghUniversity, U.K., 195-222.59
