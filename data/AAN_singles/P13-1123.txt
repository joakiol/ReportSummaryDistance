Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1254?1263,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsConditional Random Fields for Responsive Surface Realisation usingGlobal FeaturesNina Dethlefs, Helen Hastie, Heriberto Cuaya?huitl and Oliver LemonMathematical and Computer SciencesHeriot-Watt University, Edinburghn.s.dethlefs | h.hastie | h.cuayahuitl | o.lemon@hw.ac.ukAbstractSurface realisers in spoken dialogue sys-tems need to be more responsive than con-ventional surface realisers.
They need tobe sensitive to the utterance context as wellas robust to partial or changing generatorinputs.
We formulate surface realisation asa sequence labelling task and combine theuse of conditional random fields (CRFs)with semantic trees.
Due to their extendednotion of context, CRFs are able to takethe global utterance context into accountand are less constrained by local featuresthan other realisers.
This leads to morenatural and less repetitive surface realisa-tion.
It also allows generation from partialand modified inputs and is therefore ap-plicable to incremental surface realisation.Results from a human rating study confirmthat users are sensitive to this extended no-tion of context and assign ratings that aresignificantly higher (up to 14%) than thosefor taking only local context into account.1 IntroductionSurface realisation typically aims to produce out-put that is grammatically well-formed, natural andcohesive.
Cohesion can be characterised by lexicalor syntactic cues such as repetitions, substitutions,ellipses, or connectives.
In automatic languagegeneration, such properties can sometimes be dif-ficult to model, because they require rich context-awareness that keeps track of all (or much) of whatwas generated before, i.e.
a growing generationhistory.
In text generation, cohesion can span overthe entire text.
In interactive settings such as gen-eration within a spoken dialogue system (SDS), achallenge is often to keep track of cohesion overseveral utterances.
In addition, since interactionsare dynamic, generator inputs from the dialoguemanager can sometimes be partial or subject tosubsequent modification.
This has been addressedby work on incremental processing (Schlangenand Skantze, 2009).
Since dialogue acts are passedon to the generation module as soon as possible,this can sometimes lead to incomplete generatorinputs (because the user is still speaking), or in-puts that are subject to later modification (becauseof an initial ASR mis-recognition).In this paper, we propose to formulate surfacerealisation as a sequence labelling task.
We useconditional random fields (Lafferty et al, 2001;Sutton and McCallum, 2006), which are suitablefor modelling rich contexts, in combination withsemantic trees for rich linguistic information.
Thiscombination is able to keep track of dependen-cies between syntactic, semantic and lexical fea-tures across multiple utterances.
Our model canbe trained from minimally labelled data, which re-duces development time and may (in the future)facilitate an application to new domains.The domain used in this paper is a pedestrianwalking around a city looking for information andrecommendations for local restaurants from anSDS.
We describe here the module for surface re-alisation.
Our main hypothesis is that the use ofglobal context in a CRF with semantic trees canlead to surface realisations that are better phrased,more natural and less repetitive than taking onlylocal features into account.
Results from a humanrating study confirm this hypothesis.
In addition,we compare our system with alternative surfacerealisation methods from the literature, namely, arank and boost approach and n-grams.Finally, we argue that our approach lends itself1254to surface realisation within incremental systems,because CRFs are able to model context acrossfull as well as partial generator inputs which mayundergo modifications during generation.
As ademonstration, we apply our model to incremen-tal surface realisation in a proof-of-concept study.2 Related WorkOur approach is most closely related to Lu etal.
(2009) who also use CRFs to find the bestsurface realisation from a semantic tree.
Theyconclude from an automatic evaluation that usingCRF-based generation which takes long-range de-pendencies into account outperforms several base-lines.
However, Lu et al?s generator does not takecontext beyond the current utterance into accountand is thus restricted to local features.
Further-more, their model is not able to modify generationresults on the fly due to new or updated inputs.In terms of surface realisation from graphicalmodels (and within the context of SDSs), our ap-proach is also related to work by Georgila et al(2002) and Dethlefs and Cuaya?huitl (2011b), whouse HMMs, Dethlefs and Cuaya?huitl (2011a) whouse Bayes Nets, and Mairesse et al (2010) whouse Dynamic Bayes Nets within an Active Learn-ing framework.
The last approach is also con-cerned with generating restaurant recommenda-tions within an SDS.
Specifically, their system op-timises its performance online, during the interac-tion, by asking users to provide it with new textualdescriptions of concepts, for which it is unsure ofthe best realisation.
In contrast to these relatedapproaches, we use undirected graphical modelswhich are useful when the natural directionalitybetween the input variables is unknown.In terms of surface realisation for SDSs, Oh andRudnicky (2000) present foundational work in us-ing an n-gram-based system.
They train a surfacerealiser based on a domain-dependent languagemodel and use an overgeneration and ranking ap-proach.
Candidate utterances are ranked accord-ing to a penalty function which penalises too longor short utterances, repetitious utterances and ut-terances which either contain more or less infor-mation than required by the dialogue act.
Whiletheir approach is fast to execute, it has the dis-advantage of not being able to model long-rangedependencies.
They show that humans rank theiroutput equivalently to template-based generation.Further, our approach is related to the SPaRKysentence generator (Walker et al, 2007).
SPaRKywas also developed for the domain of restaurantrecommendations and was shown to be equivalentto or better than a carefully designed template-based generator which had received high humanratings in the past (Stent et al, 2002).
It generatessentences in two steps.
First, it produces a ran-domised set of alternative realisations, which arethen ranked according to a mapping from sentenceplans to predicted human ratings using a boostingalgorithm.
As in our approach, SPaRKy distin-guishes local and global features.
Local featurestake only information of the current tree node intoaccount, including its parents, siblings and chil-dren, while global features take information of theentire utterance into account.
While SPaRKy isshown to reach high output quality in compari-son to a template-based baseline, the authors ac-knowledge that generation with SPaRKy is ratherslow when applied in a real-time SDS.
This couldpresent a problem in incremental settings, wheregeneration speed is of particular importance.The SPaRKy system is also used by Rieser etal.
(2011), who focus on information presentationstrategies for restaurant recommendations, sum-maries or comparisons within an SDS.
Their sur-face realiser is informed by the highest rankedSPaRKy outputs for a particular information pre-sentation strategy and will constitute one of ourbaselines in the evaluation.More work on trainable realisation for SDSsgenerally includes Bulyko and Ostendorf (2002)who use finite state transducers, Nakatsu andWhite (2006) who use supervised learning, Varges(2006) who uses chart generation, and Konstasand Lapata (2012) who use weighted hypergraphs,among others.3 Cohesion across Utterances3.1 Tree-based Semantic RepresentationsThe restaurant recommendations we generate caninclude any of the attributes shown in Table 1.It is then the task of the surface realiser to findthe best realisation, including whether to presentthem in one or several sentences.
This often isa sentence planning decision, but in our approachit is handled using CRF-based surface realisation.The semantic forms underlying surface realisationcan be produced in many ways.
In our case, theyare produced by a reinforcement learning agentwhich orders semantic attributes in the tree ac-1255Timing and OrderingSurface RealisationUserInteractionMicro-turn dialogueact, inform(food=Thai)Semantic treeString of wordsintervening modulesspeechsemantics ofuser utterance(synthesised)ManagerFigure 1: Architecture of our SDS with a focus onthe NLG components.
While the user is speaking,the dialogue manager sends dialogue acts to theNLG module, which uses reinforcement learningto order semantic attributes and produce a seman-tic tree (see Dethlefs et al (2012b)).
This paper fo-cuses on surface realisation from these trees usinga CRF as shown in the surface realisation module.Slot ExampleADDRESS The venue?s address is .
.
.AREA It is located in .
.
.FOOD The restaurant serves .
.
.
cuisine.NAME The restaurant?s name is .
.
.PHONE The venue?s phone number is .
.
.POSTCODE The postcode is .
.
.QUALITY This is a .
.
.
venue.PRICE It is located in the .
.
.
price range.SIGNATURE The venue specialises in .
.
.VENUE This venue is a .
.
.Table 1: Semantic slots required for our domainalong with example realisations.
Attributes can becombined in all possible ways during generation.cording to their confidence in the dialogue.
Thisis because SDSs can often have uncertainties withregard to the user?s actual desired attribute valuesdue to speech recognition inaccuracies.
We there-fore model all semantic slots as probability distri-butions, such as inform(food=Indian, 0.6) or in-form(food=Italian, 0.4) and apply reinforcementlearning to finding the optimal sequence for pre-sentation.
Please see Dethlefs et al (2012b) fordetails.
Here, we simply assume that a semanticform has been produced by a previous processingmodule.As shown in the architecture diagram in Fig-ure 1, a CRF surface realiser takes a semantictree as input.
We represent these as context-freetrees which can be defined formally as 4-tuplesLexicalfeaturesSyntacticfeaturesSemanticfeaturesThe Beluga is a great Italian restauranty0 y1 y2rootinform(name=Beluga)The Belugarootinform(venue=Restaurant)is a great Italianinform(type=Italian)rootrestaurant(a)(b)TheBelugais a greatItalianrestaurantotherphrases(c)Figure 2: (a) Graphical representation of a linear-chain Conditional Random Field (CRF), whereempty nodes correspond to the labelled sequence,shaded nodes to linguistic observations, and darksquares to feature functions between states and ob-servations; (b) Example semantic trees that are up-dated at each time step in order to provide linguis-tic features to the CRF (only one possible surfacerealisation is shown and parse categories are omit-ted for brevity); (c) Finite state machine of phrases(labels) for this example.
{S, T,N,H}, where S is a start symbol, typicallythe root node of the tree; T = {t0, t1, t2 .
.
.
t|T |}is a set of terminal symbols, corresponding to sin-gle phrases; N = {n0, n1, n2 .
.
.
n|N |} is a set ofnon-terminal symbols corresponding to semanticcategories, and H = {h0, h1, h2 .
.
.
h|H|} is a setof production rules of the form n ?
?, wheren ?
N , ?
?
T ?
N .
The production rules rep-resent alternatives at each branching node wherethe CRF is consulted for the best available expan-sion from the subset of possible ones.
All nodesin the tree are annotated with a semantic concept(obtained from the semantic form) as well as theirparse category.3.2 Conditional Random Fields forPhrase-Based Surface RealisationThe main idea of our approach is to treat surfacerealisation as a sequence labelling task in which asequence of semantic inputs needs to be labelledwith appropriate surface realisations.
The task istherefore to find a mapping between (observed)1256lexical, syntactic and semantic features and a (hid-den) best surface realisation.We use the linear-chain Conditional RandomField (CRF) model for statistical phrase-based sur-face realisation, see Figure 2 (a).
This probabilis-tic model defines the posterior probability of la-bels (surface realisation phrases) y={y1, .
.
.
, y|y|}given features x={x1, .
.
.
, x|x|} (informed by a se-mantic tree, see Figure 2 (b)), asP (y|x) = 1Z(x)T?t=1exp{ K?k=1?k?k(yt, yt?1, xt)},where Z(x) is a normalisation factor over all pos-sible realisations (i.e.
labellings) of x such that thesum of all terms is one.
The parameters ?k areweights corresponding to feature functions ?k(.
),which are real values describing the label state yat time t based on the previous label state yt?1 andfeatures xt.
For example: from Figure 2 (c), ?kmight have the value ?k = 1.0 for the transitionfrom ?The Beluga?
to ?is a great Italian?, and 0.0elsewhere.
The parameters ?k are set to maximisethe conditional likelihood of phrase sequences inthe training data set.
They are estimated using thegradient ascent algorithm.After training, labels can be predicted for newsequences of observations.
The most likely phrasesequence is expressed asy ?
= argmaxyP (y|x),which is computed using the Viterbi algorithm.We use the Mallet package1 (McCallum, 2002) forparameter learning and inference.3.3 Feature Selection and TrainingThe following features define the generation con-text used during training of the CRF.
The genera-tion context includes everything that has been gen-erated for the current utterance so far.
All featurescan be obtained from a semantic input tree.?
Lexical items of parents and siblings,?
Semantic types in expansion,?
Semantic types of parents and siblings,?
Parse category of expansion,?
Parse categories of parents and siblings.We use the StanfordParser2 (Marneffe et al, 2006)to obtain the parse category for each tree node.1http://mallet.cs.umass.edu/2http://nlp.stanford.edu/software/lex-parser.shtmlThe semantics for each node are derived from theinput dialogue acts (these are listed in Table 1) andare associated with nodes.
The lexical items arepresent in the generation context and are mappedto semantic tree nodes.As an example, for generating an utterance (la-bel sequence) such as The Beluga is a great restau-rant.
It is located in the city centre., each gen-eration step needs to take the features of the en-tire generation history into account.
This includesall individual lexical items generated, the seman-tic types used and the parse categories for eachtree node involved.
For the first constituent, TheBeluga, this corresponds to the features {?
BE-GIN NAME} indicating the beginning of a sentence(where empty features are omitted), the beginningof a new generation context and the next semanticslot required.
For the second constituent, is a greatrestaurant, the features are {THE BELUGA NAMENP VENUE}, i.e.
including the generation history(with lexical items and parse category added forthe first constituent) and the semantics of the nextrequired slot, VENUE.
In this way, a sequence ofsurface form constituents is generated correspond-ing to latent states in the CRF.Since global utterance features capture the fullgeneration context (i.e.
beyond the current ut-terance), we are also able to model phenomenasuch as co-references and pronouns.
This is usefulfor longer restaurant recommendations which mayspan over more than one utterance.
If the genera-tion history already contains a semantic attribute,e.g.
the restaurant name, the CRF may afterwardschoose a pronoun, e.g.
it, which has a higher like-lihood than using the proper name again.
Simi-larly, the CRF may decide to realise a new attributeas constituents of different order, such as a sen-tence or PP, depending on the length, number andparse categories of previously generated output.
Inthis way, our approach implicitly treats sentenceplanning decisions such as the distribution of con-tent over a set of messages in the same way as (oras part of) surface realisation.
A further capabil-ity of our surface realiser is that it can generatecomplete phrases from full as well as partial dia-logue acts.
This is useful in interactive contexts,where we need as much robustness as possible.
Ademonstration of this is given in Section 5 in anapplication to incremental surface realisation.To train the CRF, we used a data set of 552restaurant recommendations from the website The1257List.3 The data contains recommendations such asLocated in the city centre, Beluga is a stylish yetlaid-back restaurant with a smart menu of modernEuropean cuisine.3.4 Grammar InductionThe grammar g of surface realisation candidatesis obtained through an automatic grammar induc-tion algorithm which can be run on unlabelleddata and requires only minimal human interven-tion.
This grammar defines the surface realisa-tion space for the CRFs.
We provide the humancorpus of restaurant recommendations from Sec-tion 3.3 as input to grammar induction.
The al-gorithm is shown in Algorithm 1.
It first identi-fies all semantic attributes of interest in an utter-ance, in our case those specified in Table 1, and re-places them by a variable.
These attributes includefood types, such as Mexican, Chinese, particularparts of town, prices, etc.
About 45% of them canbe identified based on heuristics.
The remainderneeds to be hand-annotated at the moment, whichincludes mainly attributes like restaurant names orquality attributes, such as delicate, exquisite, etc.Subsequently, all utterances are parsed using theStanford parser to obtain constituents and are inte-grated into the grammar under construction.
Thenon-terminal symbols are named after the auto-matically annotated semantic attributes containedin their expansion, e.g.
NAME QUALITY ?
The$name$ is of $quality$ quality.
In this way, eachnon-terminal symbol has a semantic representa-tion and an associated parse category.
In total, ourinduced grammar contains more than 800 rules.4 EvaluationTo evaluate our approach, we focus on a sub-jective human rating study which aims to deter-mine whether CRF-based surface realisation thattakes the full generation context into account,called CRF (global), is perceived better by humanjudges than one that uses a CRF but just takes localcontext into account, called CRF (local).
WhileCRF (global) uses features from the entire genera-tion history, CRF (local) uses only features fromthe current tree branch.
We assume that cohe-sion can be identified by untrained judges as natu-ral, well-phrased and non-repetitive surface forms.To examine differences in methodology between3http://www.list.co.ukAlgorithm 1 Grammar Induction.1: function FINDGRAMMAR(utterances u, semantic at-tributes a) return grammar2: for each utterance u do3: if u contains a semantic attribute from a, such asvenue, cuisine, etc.
then4: Find and replace the attribute by its semanticvariable, e.g.
$venue$.5: end if6: Parse the sentence and induce a set of rules ??
?, where ?
is a semantic variable and ?
is its parse.7: Traverse the parse tree in a top-down, depth-firstsearch and8: if expansion ?
exists then9: continue10: else if non-terminal ?
exists then11: add new expansion ?
to ?.12: else write new rule ??
?.13: end if14: Write grammar.15: end for16: end functionCRFs and other state-of-the-art methods, we alsocompare our system to two other baselines:?
CLASSiC corresponds to the system re-ported in Rieser et al (2011),4 which gen-erates restaurant recommendations based onthe SPaRKy system (Walker et al, 2007), andhas received high ratings in the past.
SPaRKyuses global utterance features.?
n-grams represents a simple 5-gram baselinethat is similar to Oh and Rudnicky (2000)?ssystem.
We will sample from the most likelyslot realisations that do not contain a repeti-tion and include exactly the required slot val-ues.
Local context only is taken into account.4.1 Human Rating StudyWe carried out a user rating study on the Crowd-Flower crowd sourcing platform.5 Each partici-pant was shown part of a real human-system dia-logue that emerged as part of the CLASSiC projectevaluation (Rieser et al, 2011).
All dialoguesand data are freely available from http://www.classic-project.org.
Each dialogue containedtwo variations for one of the utterances.
Thesevariations were generated from two out of the foursystems described above.
The order that thesewere presented to the participant was counterbal-anced.
Table 2 gives an example of a dialogue seg-ment presented to the participants.4In Rieser et al (2011), this system is referred to as theTIP system, which generates summaries, comparisons or rec-ommendations for restaurants.
For the present study, we com-1258SYS Thank you for calling the Cambridge Informationsystem.
Your call will be recorded for research pur-poses.
You may ask for information about a placeto eat, such as a restaurant, a pub, or a cafe.
Howmay I help you?USR I want to find an American restaurant which is inthe very expensive area.SYSAThe restaurant Gourmet Burger is an outstanding,expensive restaurant located in the central area.SYSBGourmet Burger is a smart and welcoming restau-rant.
Gourmet Burger provides an expensive diningexperience with great food and friendly service.
Ifyou?re looking for a central meal at an expensiveprice.USR What is the address and phone number?SYS Gourmet Burger is on Regent Street and its phonenumber is 01223 312598.USR Thank you.
Good bye.Table 2: Example dialogue for participants tocompare alternative outputs in italics, USR=user,SYS A=CRF (global), SYS B=CRF(local).System Natural Phrasing Repetit.CRF global 3.65 3.64 3.65CRF local 3.10?
3.19?
3.13?CLASSiC 3.53?
3.59 3.48?n-grams 3.01?
3.09?
3.32?Table 3: Subjective user ratings.
Significance withCRF (global) at p<0.05 is indicated as ?.44 participants gave a total of 1,830 ratings ofutterances produced across the four systems.
Flu-ent speakers of English only were requested andthe participants were from the United States.
Theywere asked to rate each utterance on a 5 point Lik-ert scale in response to the following questions(where 5 corresponds to totally agree and 1 cor-responds to totally disagree):?
The utterance was natural, i.e.
it could havebeen produced by a human.
(Natural)?
The utterance was phrased well.
(Phrasing)?
The utterance was repetitive.
(Repetitive)4.2 ResultsWe can see from Table 3 that across all the cate-gories, the CRF (global) gets the highest overallratings.
This difference is significant for all cat-egories compared with CRF (local) and n-grams(using a 1-sided Mann Whitney U-test, p < 0.001).pare only with the subset of recommendations.5http://www.crowdflower.comPossibly this is because the local context takeninto account by both systems was not enough toensure cohesion across surface phrases.
It is notpossible, e.g., to cover co-references within a lo-cal context only or discourse markers that refer be-yond the current utterance.
This can lead to shortand repetitive phrases, such as Make your way toGourmet Burger.
The food quality is outstanding.The prices are expensive.
generated by the n-grambaseline.The CLASSiC baseline, based on SPaRKy, wasthe most competitive system in our comparison.None-the-less CRF (global) is rated higher acrosscategories and significantly so for Natural (p <0.05) and Repetitive (p < 0.005).
For Phrasing,there is a trend but not a significant difference (p< 0.16).
All comparisons are based on a 1-sidedMann Whitney U-test.
A qualitative comparisonbetween the CRF (global) and CLASSiC outputsshowed the following.
CLASSiC utterances tendto be longer and contain more sentences than CRF(global) utterances.
While CRF (global) often de-cides to aggregate attributes into one sentence,such as the Beluga is an outstanding restaurantin the city centre, CLASSiC tends to rely more onindividual messages, such as The Beluga is an out-standing restaurant.
It is located in the city cen-tre.
A possible reason is that while CRF (global)is able to take features beyond an utterance intoaccount, CLASSiC/SPaRKy is restricted to globalfeatures of the current utterance.We can further compare our results with Rieseret al (2011) and Mairesse et al (2010) who alsogenerate restaurant recommendations and askedsimilar questions to participants as we did.
Rieseret al (2011)?s system received an average ratingof 3.586 in terms of Phrasing which compares toour 3.64.
This difference is not significant, andin line with the user ratings we observed for theCLASSiC system above (3.59).
Mairesse et al(2010) achieved an average score of 4.05 in termsof Natural in comparison to our 3.65.
This differ-ence is significant at p<0.05.
Possibly their betterperformance is due to the data set being more ?indomain?
than ours.
They collected data from hu-mans that was written specifically for the task thatthe system was tested on.
In contrast, our systemwas trained on freely available data that was writ-ten by professional restaurant reviewers.
Unfortu-nately, we cannot compare across other categories,6This was rescaled from a 1-6 scale.1259USR1 I?m looking for a nice restaurant in the centre.SYS1 inform(area=centre [0.2], food=Thai [0.3])inform(name=Bangkok [0.3])So you?re looking for a Thai .
.
.USR2 [barges in] No, I?m looking for a restaurantwith good quality food.SYS2 inform(quality=good [0.6], name=Beluga [0.6])Oh sorry, so a nice restaurant located .
.
.USR3 [barges in] .
.
.
in the city centre.SYS3 inform(area=centre [0.8])Table 4: Example dialogue where the dialoguemanager needs to send incremental updates to theNLG.
Incremental surface realisation from seman-tic trees for this dialogue is shown in Figure 3.because the authors tested only for Phrasing andNatural, respectively.5 Incremental Surface RealisationRecent years have seen increased interest inincremental dialogue processing (Skantze andSchlangen, 2009; Schlangen and Skantze, 2009).The main characteristic of incremental architec-tures is that instead of waiting for the end of a userturn, they begin to process the input stream as soonas possible, updating their processing hypothesesas more information becomes available.
From adialogue perspective, they can be said to work onpartial rather than full dialogue acts.With respect to surface realisation, incremen-tal NLG systems have predominantly relied onpre-defined templates (Purver and Otsuka, 2003;Skantze and Hjalmarsson, 2010; Dethlefs et al,2012a), which limits the flexibility and quality ofoutput generation.
Buschmeier et al (2012) havepresented a system which systematically takesthe user?s acoustic understanding problems intoaccount by pausing, repeating or re-phrasing ifnecessary.
Their approach is based on SPUD(Stone et al, 2003), a constraint satisfaction-basedNLG architecture and marks important progresstowards more flexible incremental surface realisa-tion.
However, given the human labour involved inconstraint specification, cohesion is often limitedto a local context.
Especially for long utterancesor such that are separated by user turns, this maylead to surface form increments that are not wellconnected and lack cohesion.5.1 Application to Incremental SRThis section will discuss a proof-of-concept appli-cation of our approach to incremental surface re-alisation.
Table 4 shows an example dialogue be-tween a user and system that contains a numberof incremental phenomena that require hypothe-sis updates, system corrections and user barge-ins.
Incremental surface realisation for this dia-logue is shown in Figure 3, where processing stepsare indicated as bold-face numbers and are trig-gered by partial dialogue acts that are sent fromthe dialogue manager, such as inform(area=centre[0.2]).
The numbers in square brackets indicatethe system?s confidence in the attribute-value pair.Once a dialogue act is observed by the NLG sys-tem, a reinforcement learning agent determines theorder of attributes and produces a semantic tree, asdescribed in Section 3.1.
Since the semantic formsare constructed incrementally, new tree nodes canbe attached to and deleted from an existing tree,depending on what kind of update is required.In the dialogue in Table 4, the user first asksfor a nice restaurant in the centre.
The dialoguemanager constructs a first attribute-value slot, in-form(area=centre [0.2], .
.
.
), and passes it on toNLG.7 In Figure 3, we can observe the corre-sponding NLG action, a first tree is created withjust a root node and a node representing the areaslot (step 1).
In a second step, the semanticallyannotated node gets expanded into a surface formthat is chosen from a set of candidates (shown incurly brackets).
The CRF is responsible for thislast step.
Since there is no preceding utterance, thebest surface form is chosen based on the semanticsalone.
Active tree nodes, i.e.
those currently undergeneration, are indicated as asterisks in Figure 3.Currently inactive nodes are shown as circles.Step 3 then further expands the current treeadding a node for the food type and the name ofa restaurant that the dialogue manager had passed.We see here that attributes can either be primitiveor complex.
Primitive attributes contain a singlesemantic type, such as area, whereas complex at-tributes contain multiple types, such as food, nameand need to be decomposed in a later processingstep (see steps 4 and 6).
Step 5 again uses the CRF7Note here that the information passed on to the NLG isdistinct from the dialogue manager?s own actions.
In the ex-ample, the NLG is asked to generate a recommendation, butthe dialogue manager actually decides to clarify the user?spreferences due to low confidence.
This scenario is an exam-ple of generator inputs that may get revised afterwards.1260root(1) inform(area=centre)(2) Right in the city centre,{located in $area$, ifyou're looking to eatin $area$, in $area$, ...}inform(area=centre)(3) inform(food=Thainame=Bangkok)Right in the city centre,root(6) inform(food=Thai)(4) inform(name=Bangkok)(5) Bangkok{the $name$,it is called $name$,  ...}rootinform(area=centre)Right in the city centre,inform(food=Thai,name=Bangkok)rootinform(area=centre)Right in the city centre,(7) inform(quality=verygood, name=Beluga)inform(name=Bangkok)inform(food=Thai)Bangkokrootinform(area=centre)inform(quality=nice,name=Beluga)Right in the city centre,(8) inform(name=Beluga)(10) inform(quality=very good)(9) the Beluga{$name$, the venuecalled $name$, ...}(11) is of very good quality.
{is a $quality$ venue, if you want $quality$food, $quality$, a $quality$ place ...}****** *******Figure 3: Example of incremental surface realisation, where each generation step is indicated by a num-ber.
Active generation nodes are shown as asterisks and deletions are shown as crossed out.
Lexical andsemantic features are associated with their respective nodes.
Syntactic information in the form of parsecategories are also taken into account for surface realisation, but have been omitted in this figure.to obtain the next surface realisation that connectswith the previous one (so that a sequence of real-isation ?labels?
appears: Right in the city centreand Bangkok).
It takes the full generation contextinto account to ensure a globally optimal choice.This is important, because the local context wouldotherwise be restricted to a partial dialogue act,which can be much smaller than a full dialogueact and thus lead to short, repetitive sentences.The dialogue continues as the system implicitlyconfirms the user?s preferred restaurant (SYS1).At this point, we encounter a user barge-in correct-ing the desired choice.
As a consequence, the dia-logue manager needs to update its initial hypothe-ses and communicate this to NLG.
Here, the lastthree tree nodes need to be deleted from the treebecause the information is no longer valid.
Thisupdate and the deletion is shown in step 7.
After-wards, the dialogue continues and NLG involvesmainly expanding the current tree into a full se-quence of surface realisations for partial dialogueacts which come together into a full utterance.This example illustrates three incremental pro-cessing steps: expansions, updates and deletions.Expansions are the most frequent operation.
Theyadd new partial dialogue acts to the semantic tree.They also consult the CRF for the best surfacerealisation.
Since CRFs are not restricted by theMarkov condition, they are less constrained by lo-cal context than other models and can take non-local dependencies into account.
For our applica-tion, the maximal context is 9 semantic attributes(for a surface form that uses all possible 10 at-tributes).
While their extended context aware-ness can often make CRFs slow to train, they arefast at execution and therefore very applicable tothe incremental scenario.
For applications involv-ing longer-spanning alternatives, such as texts orparagraphs, the context of the CRF would likelyhave to be constrained.
Updates are triggered bythe hypothesis updates of the dialogue manager.Whenever a new attribute comes in, it is checkedagainst the generator?s existing knowledge.
If itis inconsistent with previous knowledge, an up-date is triggered and often followed by a deletion.Whenever generated output needs to be modified,old expansions and surface forms are deleted first,before new ones can be expanded in their place.5.2 Updates and Processing Speed ResultsSince fast responses are crucial in incremental sys-tems, we measured the average time our systemtook for a surface realisation.
The time is 100mson a MacBook Intel Core 2.6 Duo with 8GB in1261RAM.
This is slightly better than other incremen-tal systems (Skantze and Schlangen, 2009) andmuch faster than state-of-the-art non-incrementalsystems such as SPaRKy (Walker et al, 2007).In addition, we measured the number of neces-sary generation updates in comparison to a non-incremental setting.
Since updates take effect di-rectly on partial dialogue acts, rather than the fullgenerated utterance, we require around 50% lessupdates as if generating from scratch for everychanged input hypothesis.
A qualitative analysisof the generated outputs showed that the quality iscomparable to the non-incremental case.6 Conclusion and Future DirectionsWe have presented a novel technique for surfacerealisation that treats generation as a sequence la-belling task by combining a CRF with tree-basedsemantic representations.
An essential propertyof interactive surface realisers is to keep track ofthe utterance context including dependencies be-tween linguistic features to generate cohesive ut-terances.
We have argued that CRFs are wellsuited for this task because they are not restrictedby independence assumptions.
In a human ratingstudy, we confirmed that judges rated our outputas better phrased, more natural and less repetitivethan systems that just take local features into ac-count.
This also holds for a comparison with state-of-the-art rank and boost or n-gram approaches.Keeping track of the global context is also impor-tant for incremental systems since generator inputscan be incomplete or subject to modification.
In aproof-of-concept study, we have argued that ourapproach is applicable to incremental surface real-isation.
This was supported by preliminary resultson the speed, number of updates and quality dur-ing generation.
As future work, we plan to testour model in a task-based setting using an end-to-end SDS in an incremental and non-incrementalsetting.
This study will contain additional evalu-ation categories, such as the understandability orinformativeness of system utterances.
In addition,we may compare different sequence labelling al-gorithms for surface realisation (Nguyen and Guo,2007) or segmented CRFs (Sarawagi and Cohen,2005) and apply our method to more complex sur-face realisation domains such as text generation orsummarisation.
Finally, we would like to exploremethods for unsupervised data labelling so as tofacilitate portability across domains further.AcknowledgementsThe research leading to this work was funded bythe EC FP7 programme FP7/2011-14 under grantagreement no.
287615 (PARLANCE).ReferencesIvan Bulyko and Mari Ostendorf.
2002.
Efficient in-tegrated response generation from multiple targetsusing weighted finite state transducers.
ComputerSpeech and Language, 16:533?550.Hendrik Buschmeier, Timo Baumann, BenjaminDosch, Stefan Kopp, and David Schlangen.
2012.Incremental Language Generation and IncrementalSpeech Synthesis.
In Proceedings of the 13th An-nual SigDial Meeting on Discourse and Dialogue(SIGdial), Seoul, South Korea.Nina Dethlefs and Heriberto Cuaya?huitl.
2011a.
Com-bining Hierarchical Reinforcement Learning andBayesian Networks for Natural Language Genera-tion in Situated Dialogue.
In Proceedings of the 13thEuropean Workshop on Natural Language Genera-tion (ENLG), Nancy, France.Nina Dethlefs and Heriberto Cuaya?huitl.
2011b.Hierarchical Reinforcement Learning and HiddenMarkov Models for Task-Oriented Natural Lan-guage Generation.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies (ACL-HLT), Portland, Oregon, USA.Nina Dethlefs, Helen Hastie, Verena Rieser, and OliverLemon.
2012a.
Optimising Incremental DialogueDecisions Using Information Density for Interac-tive Systems.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP-CoNLL), Jeju, South Korea.Nina Dethlefs, Helen Hastie, Verena Rieser, and OliverLemon.
2012b.
Optimising Incremental Generationfor Spoken Dialogue Systems: Reducing the Needfor Fillers.
In Proceedings of the International Con-ference on Natural Language Generation (INLG),Chicago, Illinois, USA.Kallirroi Georgila, Nikos Fakotakis, and GeorgeKokkinakis.
2002.
Stochastic Language Modellingfor Recognition and Generation in Dialogue Sys-tems.
TAL (Traitement automatique des langues)Journal, 43(3):129?154.Ioannis Konstas and Mirella Lapata.
2012.
Concept-to-text Generation via Discriminative Reranking.
InProceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics, pages 369?378, Jeju Island, Korea.John D. Lafferty, Andrew McCallum, and Fer-nando C.N.
Pereira.
2001.
Conditional Random1262Fields: Probabilistic Models for Segmenting and La-beling Sequence Data.
In Proceedings of the Eigh-teenth International Conference on Machine Learn-ing (ICML), pages 282?289.Wei Lu, Hwee Tou Ng, and Wee Sun Lee.
2009.Natural Language Generation with Tree ConditionalRandom Fields.
In Proceedings of the 2009 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), Singapore.Franc?ois Mairesse, Filip Jurc??
?c?ek, Simon Keizer,Blaise Thomson, Kai Yu, and Steve Young.
2010.Phrase-Based Statistical Language Generation Us-ing Graphical Models and Active Learning.
In Pro-ceedings of the 48th Annual Meeting of the Associ-ation of Computational Linguistics (ACL), Uppsala,Sweden.Marie-Catherine De Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating TypedDependency Parses from Phrase Structure Parses.
InProceedings of the Fifth International Conferenceon Language Resources and Evaluation (LREC),Genoa, Italy.Andrew McCallum.
2002.
Mallet: A machine learningfor language toolkit.
http://mallet.cs.umass.edu.Crystal Nakatsu and Michael White.
2006.
Learningto Say It Well: Reranking Realizations by PredictedSynthesis Quality.
In In Proceedings of the AnnualMeeting of the Association for Computational Lin-guistics (COLING-ACL) 2006, pages 1113?1120,Sydney, Australia.Nam Nguyen and Yunsong Guo.
2007.
Comparisonsof Sequence Labeling Algorithms and Extensions.In Proceedings of the International Conference onMachine Learning (ICML), Corvallis, OR, USA.Alice Oh and Alexander Rudnicky.
2000.
Stochas-tic Language Generation for Spoken Dialogue Sys-tems.
In Proceedings of the ANLP/NAACL Work-shop on Conversational Systems, pages 27?32, Seat-tle, Washington, USA.Matthew Purver and Masayuki Otsuka.
2003.
In-cremental Generation by Incremental Parsing.
InIn Proceedings of the 6th UK Special-InterestingGroup for Computational Linguistics (CLUK) Col-loquium.Verena Rieser, Simon Keizer, Xingkun Liu, and OliverLemon.
2011.
Adaptive Information Presentationfor Spoken Dialogue Systems: Evaluation with Hu-man Subjects.
In Proceedings of the 13th Euro-pean Workshop on Natural Language Generation(ENLG), Nancy, France.Sunita Sarawagi and William Cohen.
2005.
Semi-Markov Conditional Random Fields for InformationExtraction.
Advances in Neural Information Pro-cessing.David Schlangen and Gabriel Skantze.
2009.
A Gen-eral, Abstract Model of Incremental Dialogue Pro-cessing.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Com-putational Linguistics, Athens, Greece.Gabriel Skantze and Anna Hjalmarsson.
2010.
To-wards Incremental Speech Generation in DialogueSystems.
In Proceedings of the 11th Annual SigDialMeeting on Discourse and Dialogue, Tokyo, Japan.Gabriel Skantze and David Schlangen.
2009.
Incre-mental Dialogue Processing in a Micro-Domain.
InProceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, Athens, Greece.Amanda Stent, Marilyn Walker, Steve Whittaker, andPreetam Maloor.
2002.
User-tailored Generationfor Spoken Dialogue: An Experiment.
In Proceed-ings of the International Conference on Spoken Lan-guage Processing.Matthew Stone, Christine Doran, Bonnie Webber, To-nia Bleam, and Martha Palmer.
2003.
Microplan-ning with Communicative Intentions: The SPUDSystem.
Computational Intelligence, 19:311?381.Charles Sutton and Andrew McCallum.
2006.
Intro-duction to Conditional Random Fields for RelationalLearning.
In Lise Getoor and Ben Taskar, editors,Introduction to Statistical Relational Learning.
MITPress.Sebastian Varges.
2006.
Overgeneration and Rankingfor Spoken Dialogue Systems.
In Proceedings of theFourth International Natural Language GenerationConference (INLG), Sydney, Australia.Marilyn Walker, Amanda Stent, Franc?ois Mairesse,and Rashmi Prasad.
2007.
Individual and Do-main Adaptation in Sentence Planning for Dia-logue.
Journal of Artificial Intelligence Research,30(1):413?456.1263
