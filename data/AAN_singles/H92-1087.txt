Probabi l ist ic Parse Scoring Based on Prosodic  Phras ingN.
M. Veilleuz and M. OstendorfBoston University44 Cummington St.Boston, MA 02215ABSTRACTThe relative size and location of prosodic phrase boundariesprovides an important cue for resolving syntactic ambiguity.In previous work, we have introduced an analysis/synthesisformalism for scoring parses in terms of the similarity be-tween prosodic patterns recognized from a given utteranceand synthesized for the hypothesized parse.
This paper de-scribes a new approach to the synthesis problem, as well asan alternative scoring criterion.
Specifically, a decision treeis designed to predict prosodic phrase structure for a givensyntactic parse, and the tree is used to compute a parsescore, which now is the probability of the recognized breaksequence.
Unlike the rule-based synthesis algorithm used inthe previous work, the decision tree can be automaticallytrained and can therefore be designed specifically for differ-ent speaking styles or task domains.
In experiments with acorpus of ambiguous sentences spoken by FM radio announc-ers ,  we have achieved isambiguation performance similar tothe rule-based algorithm, which is close to the performance ofhuman subjects in perceptual experiments using the scoringalgorithm with hand labeled breaks.1.
IntroductionSpoken language understanding is a difficult problem, inpart because of the many ambiguities inherent in natu-ral language.
Syntactic ambiguity arises when a givenexpression can be described by more than one syntacticstructure, and contributes substantially to the difficultyof the natural anguage processing problem.
Several fac-tors may be involved in resolving such ambiguities, in-cluding semantics, discourse and bias toward a specificsyntactic structure.
In spoken language, prosody, or thesuprasegmental information in an utterance, is an im-portant cue.
Prosody is especially useful in automaticspeech understanding, since computer representations ofsemantics and discourse are not as sophisticated as hu-man knowledge.Experiments have shown that listeners can resolve sev-eral types of syntactic ambiguities by using prosodic in-formation \[3, 6\].
The results of Price el al.
\[6\] indicatedthat human listeners could reliably select the intendedmeaning of two target syntactic structures (86% cor-rect identification for six out of seven types of structuralambiguity).
Of the prosodic patterns studied in thatwork, the relative size and location of phrase boundariesseemed to provide the principal cue for resolving ambigu-ities.
Thus, it seems likely that automatically detectedprosodic phrase breaks could be used in speech under-standing systems to reduce syntactic ambiguity.Assuming that prosodic cues can be detected automat-ically, there are many different ways in which prosodymight be used in syntactic disambiguation for speech un-derstanding.
In earlier work \[9\], we proposed a scoringalgorithm to rank candidate parses based on an analy-sis/synthesis method.
In this approach prosodic patternsrecognized from a given utterance are compared to thosesynthesized using a hypothesized syntactic parse from aset of possible parses.
Specifically the method involves:(1) automatically predicting prosodic break locations foreach candidate syntactic structure (synthesis); (2) au-tomatically recognizing prosodic breaks in the spokenutterance (analysis); and (3) scoring each hypothesizedparse according to a measure of the similarity betweenpredicted and observed prosodic structure.
The scorecan then be used to rank competing hypotheses, as inthe experiments here, or used in combination with otherknowledge sources to choose the correct sentence inter-pretation.This algorithm originally used a rule-based synthesis al-gorithm together with a correlation measure of similaritybetween predicted and observed prosodic phrase struc-ture.
Here, we expand on this approach by presenting analternative prediction and scoring method.
Specifically,we replace the rule-based synthesis component with astochastic model which uses a decision tree to predictprosodic phrase structure.
The probability distributionsat the leaves of the tree can be used to find the proba-bility of an obshrved prosodic structure given a syntacticparse, and this probability is then the prosodic score forthe hypothesized parse.In the following section, we briefly describe the speechcorpus and break index representation f prosodic phrasestructure.
Next, we review the synthesis and scoringcomponents used in our previous parse scoring system429\[9\].
As an alternative, we introduce a probabilistic scor-ing algorithm based on a stochastic model of phrasestructure.
We then present experimental results for thedifferent synthesis/scoring techniques using the task ofautomatically disambiguating confusable sentence pairs,comparing results to those of human listeners.
Finally,we discuss the implications of the results for future work.- 2.
Corpora and Label ingThe experiments presented here are primarily based onthe corpus of ambiguous sentences described in more de-tail in (Price et a/.,1991)\[6\].
Four professional FM ra-dio announcers were asked to read 35 pairs of sentences,where members of a pair were phonetically similar butassociated with different syntactic structures and there-fore different meanings.
The sentences included five ex-amples of each of seven types of structural ambiguity:parenthetical c auses vs. non-parenthetical subordinateclauses, appositions vs. attached noun (or prepositional)phrases, main clauses linked by coordinating conjunc-tions vs. a main clause and a subordinate clause, tagquestions vs. attached noun phrases, far vs. near attach-ment of final phrase 1, left vs. right attachment of middlephrase, and particles vs. prepositions.In addition to the ambiguous entence corpus, we alsoused a corpus of radio news speech for training thenew stochastic synthesis algorithm.
The data consistsof 14 news stories, six from one announcer and eightfrom a second announcer, both female, for a total of211 sentences (4210 words).
These news stories wereused only for training the synthesis algorithm, so justthe word transcriptions were used (no acoustic informa:tion).
These sentences differ from the ambiguous en-tence pairs (the test data) in several ways.
The ambigu-ous sentences are, on the average, shorter (7.6 vs. 19.6words) and have a flatter syntactic structure (4 vs. 7levels).
In addition, the ambiguous entence pairs weredesigned to cover specific syntactic structures, some ofwhich are not generally found in the FM radio news sto-ries.
For example, the fourteen radio stories contain nosentences with tag questions and only five examples ofembedded sentences, although both of these structuresare common in the ambiguous entences.The parse scoring algorithms described here are based onan integer "break index" representation f prosodic on-stituent structure.
Each word boundary in an utteranceis labeled with a break index from 0-6 that correspondsto a level in a constituent hierarchy, or equivalently tothe amount of prosodic decoupling between words.
A1 High vs. low attachment is probably more accurate syntacticterminology, but "far" vs. "near" is used in \[6\] as more descriptive.
"0" represents the most tightly bound words, such as inclitic groups, while a "6" represents the prosodic breakbetween sentences.
The correspondence between thisseven-level system of indices and various hierarchies pro-posed in the literature is discussed in depth in Wight-man et al \[10\].
For training and evaluating our algo-rithms, utterances have been hand-labeled according tothis break indexing system.
Sentences were also anno-tated with skeletal parses as part of a preliminary versionof the University of Pennsylvania Treebank project \[4\].3.
Rule-Based Synthesis  and ScoringThe focus of this paper is on the synthesis and scoringcomponents of our prosodic parse scoring system.
Therule-based synthesis and correlation scoring algorithmsused in previous work are described below for reference.The analysis component, prosodic break recognition, isalso based on classification trees and is described in \[8\].3.1.
Performance St ructure  SynthesisProsodic phrase break prediction algorithms have typi-cally been rule-based.
In our previous work, we inves-tigated a variety of rule-based algorithms designed topredict performance structures, based on Gee and Gros-jean's Phi algorithm \[2\].
Since results for these algo-rithms were similar \[9\], only the performance of the Phialgorithm will be used for comparison here.Given the syntactic structure, the Phi algorithm iter-atively groups successively larger prosodic constituentstogether, beginning at the word level, to form a binarytree.
A break index, which indicates the relative coher-ence between constituents, is deterministically assignedafter each word in the sentence according to node countin the tree.
The absolute value of the breaks is not lin-guistically meaningful and, in addition, has no theoreti-cal upper bound.
We refer to these indices as C-breaksto distinguish them from the seven-level labeling systemused in the analysis.3 .2 .
Cor re la t ion  ScoreIn \[9\], a correlation score was used to compare the C-breaks for competing syntactic structures with observedbreaks for some utterance to be disambiguated.
Specif-ically, the score is simply an estimate of the correlationcoefficient between observed and synthesized breaks.An advantage of the correlation score is that it is invari-ant to linear transformations of the break indices.
Thatis, a high-valued sequence of breaks will have the sameinterpretation as a low-valued sequence of breaks, if rel-atively higher and lower breaks are in the same position.A disadvantage is that it requires a hard decision from430the synthesis tep, and therefore is limited in the amountof variability it allows.4.
Probabilistic Synthesis and ScoringAlthough the performance-structure-based algorithmsappear to be quite useful, rule-based methods have somedisadvantages.
First, they are difficult to implement fordifferent styles or to tailor for a specific task domain,sihce the development of new rules is required.
Second,they do not allow for the natural variability in phras-ing observed in multiple spoken renditions of the samesentence.
An alternative to the rule-based approach isto use a model that can be trained automatically, suchas a stochastic model.
The fact that stochastic modelsassociate a probability with a sequence of break indicessuggests a method of parse scoring based on the proba-bility of a parse given the recognized breaks.4.1.
Decision Tree Break SynthesisExisting break synthesis models that can be automat-ically trained are based on decision trees.
Wang andHirschberg \[7\] first proposed the use of decision treesto predict the presence or absence of a prosodic break,with very successful results.
Although their experimentsinvolved predicting only one type of break, the modelis general and can be extended to predict an arbitrarynumber of levels.Using a set of allowable questions about bracketed wordsequences, binary decision trees partition the labeledtraining data into successively more homogeneous setswith respect to class distributions.
Classes in our caseare different levels of prosodic breaks (i.e., 0 - 6).
Treesare designed using a greedy growing algorithm \[1\], whichiteratively reduces the impurity of the class distributionsat the leaves of the tree 2.
In this work, the size of thetree was determined based on complexity/performancetrade-offs in the training set.
At each terminal node ofthe tree, the training data defines a relative frequencyestimate of the probability for each level of break repre-sented.
The tree can be used for synthesis by choosingthe most probable break level at each terminal node, asin \[7\].
For the parse scoring application, however, thestochastic model can be used to find the probability ofa break sequence given a hypothesized parse.
Using theprobabilities directly has potential performance advan-tages over making a hard decision on predicted parsesbefore a subsequent scoring stage.The decision tree was designed using the FM radio newsstories, based on questions that used part-of-speech in-~Specifically, we use the Gini criterion i(t) = ~iC j  p(ilt)p(jlt)as a measure of impurity.formation, syntactic information and location in the sen-tence in terms of numbers of words.
Part-of-speech in-formation used was based only on capitalization andfunction word tables, and the questions about syn-tactic structure are based on Treebank skeletal parses\[4\].
The different syntactic units used are SBAR orSBARQ (declarative or question embedded sentences), Sor SINV (declarative or inverted main clauses), NP, VP,PP, phrase beginning with Wh-question word, ADJP orADVP.
All questions are based on features derived fromtext information only; no acoustic information is usedin the synthesis algorithm.
The specific questions aredetailed below; motivation for these can be found in \[5\],where a similar set of questions were investigated.
Ab-breviations in parentheses refer to labels used in the re-sulting tree, illustrated in Figure 1.1.
Is this a sentence boundary?
(sent)2.
Is the left word is a content word and the right word afunction word?
(cw-fw)3.
Is the left word a function word and the right word acontent word?
(fw-cw)4.
What is the function word type of word to the right?
I.e.conjunctions, articles, auxiliary verbs and models, pro-nouns, prepositions, and a default category.
(fw-type)5.
Is either adjacent word capitalized, i.e.
a proper name?(cap)6.
How many content words have occurred since the previ-ous function word?
(# cw)7.
How many function words have occurred since the pre-vious function word?
(# fw)8.
What is the relative location in the sentence?
Specifi-cally, what is the ratio of the number of orthographicwords over the sentence length in words quantized tothe nearest eighth?
(sloc)9.
What is the largest syntactic unit that dominates theword preceding the potential boundary location anddoes not dominate the succeeding word?
(dora lft)10.
What is the largest syntactic unit that dominates theword succeeding the potential boundary location anddoes not dominate the preceding word?
(dom rt)11.
What is the smallest syntactic unit that dominatesboth?
(dom both)12.
How many syntactic units end between the two words?
(# \])13.
How many syntactic units begin between the two words?
(# D14.
What is the depth (number of levels from the top) inthe syntax tree of the right word?
Depth was measuredas the number of open brackets minus the number ofclosed brackets.
(depth)15.
What is the total number of initiating and terminatingsyntactic units between the two words?
This numberis roughly related to how far the juncture is from thebottom of the syntax tree.
(height)431yes ~- ,  w no e.,_,,,,~,- -  , o r  PP\or  sixth eighthFigure h Synthesis decision tree used in parse scoring, designed on radio news text.
The syntactic features of eachword juncture determine assignment toa terminal node, which is associated with a probability distribution of breaks.4.2.
P robab i l i ty  ScoreUse of the decision tree for break synthesis suggests analternative approach to the correlation score, which isto compute the probability of the sequence of automat-ically labeled break indices conditioned on the hypoth-esized parse.
The probability score is computed as fol-lows.
The text and the hypothesized parse are processedto generate a sequence of feature vectors \[z 1,..-, zn\], onefor each word, which are subsequently each encoded bythe tree to a node ti = T (z l ) .
The score of the observedbreaks indices \[bl,..., b,\], is then1  logp(b, lt,), se=~i=lwhere p(blt ) is the distribution associated with terminalnode t. The factor I/n normalizes the score to accountfor differences in word length; otherwise, the score isbiased to favor shorter sentences.Rather than computing the probability of the sequenceof breaks, we could have explicitly predicted a sequenceof breaks from text, taking the most probable sequence,and then used the correlation scoring approach withthese synthesized breaks.
However, if the predictedbreak indices are the same for both parses, then it is im-possible to distinguish them using the correlation score,though it was possible to choose between them using theprobability of observed breaks.
This phenomenon doesoccur for the ambiguous sentences and therefore correla-tion scoring has lower disambiguation performance thanprobability scoring.
Of course, if two hypothesized syn-tactic structures result in the same node sequence, thesentence cannot be disambiguated with the tree.
How-ever, in our corpus of 35 pairs of ambiguous sentences,only two were assigned the same node sequence.
Thecorresponding human productions for this sentence pairhad similar ambiguities in break indices labeled for atleast one of the four speakers.5.
Exper imentsWe have tested our analysis/synthesis approach by usingit to perform the same task that the human subjects in\[6\] were asked to perform.
Specifically, we attempt oselect which of two interpretations was intended by thespeaker by choosing the interpretation with the high-est score.
For each test utterance, we use an automaticbreak labeling algorithm to recognize the break indices(the algorithm used in \[8\] with additional acoustic fea-tures) under each of the two possible sentence hypothe-ses.
The two break sequences are then scored accordingto a synthesis model using the syntactic structure of thecorresponding sentence hypothesis.
The candidate sen-tence having the highest score is selected.
In the eventof a tie, the first sentence in the pair is chosen.
Theseexperiments were repeated using both the the rule-basedsynthesis algorithm and the new decision tree algorithm.The Phi algorithm was evaluated in conjunction with the432correlation score, and the decision tree synthesis algo-rithm was used with a probabilistic score.
In addition,we repeat he experiments u ing hand-labeled breaks inorder to examine the perf~rm'ance of the synthesis mod-ule alone.
The results of these experiments are summa-rized in Table 1 for each of the 14 types (7 pairs) ofsyntactic ambiguity, which list the percent of sentencecorrectly identified for each category out of a set of 20sentences/category.
For comparison, Table 1 also con-tains the results reported for the human subjects \[6\].Not all syntactic differences can be disambiguated byprosodic information, and such cases obviously cannotbe handled by our algorithms.
For completeness, Table 1includes results for all categories, although our analysiswill focus mainly on the categories that were most reli-ably identified by human listeners (those for which meanresponse minus standard deviation was greater thanchance, indicated with an asterisk in the table).
In ad-dition, this analysis will ignore the main-main vs. main-subordinate clause category, since in \[6\], the sentenceswere found to be very similar prosodically.The results based on the hand-labeled break indices howthat the decision tree synthesis algorithm in combinationwith a probabilistic score gave disambiguation accuracysimilar to the Phi algorithm, and comparable to perfor-mance of human listeners on this test subset.When using automatically abeled breaks rather thanhand-labeled breaks, there is significant degradation iperformance for both the Phi and decision tree algo-rithms.
The biggest loss in performance was for theparticle category, which was correctly identified with thehand-labeled breaks but identified at the level of chanceusing the automatically labeled breaks.
In this case, au-tomatically detected prominence information may proveto be useful, because particles are often prominentwhereas prepositions are not \[6\].When correlation is used as the similarity measure, thedecision tree performance degrades about 10% in accu-racy, e.g., from 74% to 64% with automatically labeledbreaks and on the reliable categories.
Clearly the prob-abilistic score is preferable.
However, the fact that theaccuracy of the decision tree when used with the corre-lation score is much lower than that for the performancestructure algorithms, uggests that some improvement ispossible in the tree synthesis algorithm.6.
Discuss ionIn summary, we have introduced a decision tree synthe-sis algorithm and probability-based scoring method foruse in an analysis/synthesis formalism.
We have evalu-ated this new probabilistic synthesis/scoring mechanismon a set of 70 ambiguous sentences, each spoken by fourradio announcers, and have compared performance tothe rule-based synthesis algorithm and correlation scor-ing previously investigated.
The performance structure(rule-based) synthesis algorithm and the probabilisticdecision tree approach gave similar results.
Consideringonly eight categories of structures that could be disarmbiguated by humans with high reliability (out of fourteencategories investigated), the algorithms achieve disam-biguation performance comparable to human listenerswhen scoring hand-labeled break indices (89-91% accu-racy).
However, as in the case of the rule-based algo-rithms, performance degrades to 73-74% accuracy whenscoring automatically labeled break indices.The decision tree result is very encouraging, iven thesignificant differences between the training and test data.Since the decision tree can be easily retrained for specificapplications, performance should improve with trainingbased on a larger and more representative sample of sen-tences.
Moreover, the decision tree synthesis methodcould also be improved through the use of new questionsand more detailed part-of-speech labels.
The questionset used here was originally chosen to classify only in-termediate and intonational phrases, and new questionsabout factors that are correlated with the lower levelbreaks might be particularly useful additions.The parse scoring algorithm on hand-labeled data showssome loss in accuracy relative to human performance ifwe also consider the sentences that were less reliablyidentified by the human listeners.
Several different fac-tors probably account for this effect, including the factthat these sentences simply exhibit more variability.
It isalso likely that humans are using other prosodic ues inaddition to phrase breaks to resolve ambiguities, uch asphrasal prominence.
This additional information couldbe incorporated using the analysis/synthesis approachwith a probabilistic synthesis model that predicts bothbreaks and prominences.Using the parse scoring algorithms with automaticallylabeled breaks incurs a significant loss in disambigua-tion performance.
While it is possible that further im-provements in the detection algorithm may be success-ful, using the break detection algorithm jointly with theprobabilistic synthesis model in scoring a parse may alsoimprove perfor~nance.While these results are encouraging, there are several is-sues that may affect performance in a spoken languagesystem.
First, the syntactic parses were hand corrected.Second, the sentences here represent a narrow range ofsyntactic lasses and performance outside of this set mayvary.
Finally, the analysis component used phone seg-433Hand Labels \] Machine LabelsAmbiguity & G-G & T-prob \] & G-G J & T-prob4- Parenthetical 60 70 60 35- Parenthet i ca l  90 70 60 704- Apposition 90 100 95 90- Apposition 60 70 30 50Main-Main 55 60 85 85Main-Subordinate 50 65 70 604- Tag 90 100 90 90- Tag 70 80 55 55Far Attach 100 65 70 65Near A ttach 40 70 40 55Left Attach 100 80 85 80Right Attach 100 95 90 75Particle 100 100 55 55Preposition 95 95 80 80Average 791 80 169 68Average for * 91 89 73 747796*92*91"885495*81786394*95*82*81"8491PerceptionHumanTable 1: Percent correct disambiguation as a function of syntactic ambiguity for: different synthesis algorithmscompared to hand-labeled breaks (G-G: Gee/Grosjean, T-prob: decision tree synthesis); different synthesis algorithmscompared to automatically labeled breaks; and human perceptual results.
Those categories which were identifiedby human listeners with significant reliability are marked with asterisks.
Percentages are based on 5 sentences fromeach of 4 speakers, giving 20 utterances in each category and 280 utterances total.mentations from a recognizer constrained to the correctword sequence.
While these issues need to be investi-gated, it is possible that use of prosodic parse scoringmay help overcome and not be limited by problems inother components of a spoken language system.
For ex-ample, it is possible that using a prosodic parse scorewould enhance the overall performance of the systembecause recognition errors would yield low probabilitybreak index sequences.7.
AcknowledgmentsThe authors gratefully acknowledge Colin Wightman for hiscontributions to the foundation of this work and for his au-tomatic break detection results and Patti Price and Ste-fanie Shattuck-Hufnagel fortheir valuable suggestions and in-sights.
This research was jointly funded by NSF and DARPAunder NSF grant number IRI-8905249, and by NSF undergrant number IRI-8805680.References1.
Breiman, L., Friedman, J. H., Olshen, It.
A.
&Stone C. J.
(1984).
Classification and Regression Trees.Wadsworth and Brooks/Cole Advanced Books and Soft-ware, Monterey, CA.2.
Gee, J. P. & Grosjean, F. (1983).
Performance Struc-tures: A Psycholinguistic and Linguistic Appraisal.
Cog-nitive Psychology 15, 411-458.3.
Lehiste, I.
(1973).
Phonetic Disambiguation f SyntacticAmbiguity.
Glossa  7, 2, 107-121.4.
Marcus, M. P. & Santorini, B.
Building a very large nat-ural language corpora: The Penn treebank.
Submittedmanuscript.5.
Ostendoff, M. & Veilleux, N. A Hierarchical StochasticModel for Automatic Prediction of Prosodic BoundaryLocation.
Submitted manuscript.6.
Price, P., Ostendoff, M., Shattuck-Hufnagel, S. & Fong,C.
(1991).
The Use of Prosody in Syntactic Disambigua-tion.
Journal of the Acoustical Society of America 90,6, 2956-2970.7.
Wang, M. & Hirschberg, J.
(1992).
Automatic Classi-fication of Intonational Phrase Boundaries.
ComputerSpeech and Language, to appear.8.
Wightman, C. W. & Ostendorf, M. (1991).
AutomaticRecognition of Prosodic Phrases.
Proceedings of the In-ternational Conference on Acoustics, Speech and SignalProcessing, 3217-324.9.
Wightman, C. W., Veilleux, N. M. & Ostendorf, M.(1991).
Using Prosodic Phrasing in Syntactic Disam-biguation: An Analysis-by-Synthesis Approach.
Pro-ceedings of the DARPA Workshop on Speech and Natu-ral Language, 384-389.10.
Wightman, C. W., Shattuck-Hufnagel, S.  Ostendorf, M.& P. Price.
(1992).
Segmental Durations in the Vicinityof Prosodic Phrase Boundaries.
Journal oJ the Acousti-cal Society of America March 1992.434
