Proceedings of the 2012 Student Research Workshop, pages 67?72,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsTowards Automatic Construction of Knowledge Bases from Chinese OnlineResourcesLiwei Chen, Yansong Feng, Yidong Chen, Lei Zou, Dongyan ZhaoInstitute of Computer Science and TechnologyPeking UniversityBeijing, China{clwclw88,fengyansong,chenyidong,zoulei,zhaodongyan}@pku.edu.cnAbstractAutomatically constructing knowledge basesfrom online resources has become a crucialtask in many research areas.
Most existingknowledge bases are built from English re-sources, while few efforts have been made forother languages.
Building knowledge basesfor Chinese is of great importance on its ownright.
However, simply adapting existing tool-s from English to Chinese yields inferior re-sults.In this paper, we propose to create Chi-nese knowledge bases from online resourceswith less human involvement.This project willbe formulated in a self-supervised frameworkwhich requires little manual work to extrac-t knowledge facts from online encyclopediaresources in a probabilistic view.In addition,this framework will be able to update the con-structed knowledge base with knowledge factsextracted from up-to-date newswire.Currently,we have obtained encouraging results in ourpilot experiments that extracting knowledgefacts from infoboxes can achieve a high accu-racy of around 95%, which will be then usedas training data for the extraction of plain web-pages.1 IntroductionAs the development of world wide web (WWW),the volume of web data is growing exponentiallyin recent years.
Most of the data are unstructured,while a few are manually structured and only a s-mall part of them are machine-readable.
How tomake these data accessible and useable for end user-s has become a key topic in many research areas,such as information retrieval, natural language pro-cessing, semantic web(Tim et al, 2001) and so on.Among others, constructing knowledge bases (KB)from web data has been considered as a preliminarystep.
However, it is not trivial to extract knowledgefacts from unstructured web data, especially in opendomain, and the accuracy is usually not satisfacto-ry.
On the other hand, with the development of We-b2.0, there are increasing volume of online encyclo-pedias which are collectively created by active vol-unteers, e.g., Wikipedia1.
Surprisingly, experimentevidences show that the confidence of Wikipedia iseven comparable with that of British Encyclopedi-a (Giles, 2005).
Therefore, many efforts have beenmade to distill knowledge facts from Wikipedia orsimilar resources and further build KBs, for exampleYAGO(Suchanek et al, 2007), DBpedia(Bizer et al,2009) and KOG(Wu and Weld, 2008).In the literature, most KBs constructed recentlyare in English as it takes up an overwhelming major-ity on the web, while other major languages receivesless attention, for example, Chinese features similaramounts of web pages with English yet is less fre-quently studied with regarding to building KBs.
Al-though continuous works have been made to processEnglish resources, building Chinese KBs is of greatvalue on its own.
To the best of our knowledge, fewefforts have been made to construct a KB in Chi-nese until now.
Despite of necessary special pre-processings, e.g., word segmentation, for Chinese,building a Chinese KB from web data is quite differ-ent from building English ones, since we have lim-ited resources available in Chinese that are of lower1http://www.wikipedia.com67quality compared to their English counterparts.
Thisbrings more difficulties than that of English.
As aresult, the approaches used in English may not workwell in Chinese.In this paper, we propose a new framework tobuild a KB in Chinese from online resources with-out much human involvement.
Since the Chineseportion of Wikipedia is much smaller than its En-glish part, we harvest knowledge facts from a Chi-nese online encyclopedia, HudongBaike2.
Hudong-Baike is the largest Chinese online encyclopedia andfeatures similar managing rules and writing styleswith Wikipedia.
We first obtain knowledge facts byparsing the infoboxes of HudongBaike.
Then we usethese triples as seeds, and adopt the idea of distantsupervision(Mintz et al, 2009; Riedel et al, 2010;Yao et al, 2010) to extract more facts from otherHudongBaike articles and build a KB accordingly.Moreover, to make the knowledge base more up-to-date, we also propose to propagate the KBwith newsevents.The rest of this paper is organized as follows: wefirst introduce the related work, and briefly introducetwo online encyclopedias.
In Section 4 we describeour framework in detail.
Our current work are dis-cussed in Section 5.
In Section 6 we conclude thispaper.2 Related WorkKB construction is an important task and has at-tracted many research efforts from artificial intelli-gence, information retrieval, natural language pro-cessing, and so on.
Traditional KBs are most-ly manually created, including WordNet(Stark andRiesenfeld, 1998), Cyc or OpenCyc(Matuszek et al,2006), SUMO(Niles and Pease, 2001), and alsosome domain-specific ontologies such as GeneOn-tology3.
These KBs achieve a high accuracy sincethey are manually built or filtered by domain ex-perts.
However, manually creating KB is a time-consuming and labor-intensive work, and continu-ous annotation is required to keep the KB up-to date.Most of them thus suffers from the coverage issue inpractice.In recent years, many researchers turn to auto-2http://www.hudong.com3http://www.geneontology.orgmatically extract knowledge to construct KBs.
Onekind of methods extract knowledge facts from gener-al text corpus.
These approaches, such as TextRun-ner(Banko et al, 2007) and KnowItAll(Etzioni et al,2004), use rule based information extraction tech-nologies to extract relations between entity pairs.Recently, TextRunner is expanded by a life longlearning strategy, which can acquire new facts.
An-other type of approaches aims to automatically de-rive facts from online encyclopedias.
Collectivelycreated by many volunteers, online encyclopediasare more reliable than general web pages.
They al-so contain semi-structured knowledge such as hand-crafted infoboxes.
Therefore, the accuracy of thefacts extracted will be higher.
Researchers utilizethese semi-structured data resources for knowledgeextraction, for example, YAGO extract facts from in-foboxes and category names of Wikipedia, and useWordNet as its taxonomy(Suchanek et al, 2007).A similar approach is adopted by DBpedia, whichalso extract knowledge facts from infoboxes(Bizeret al, 2009).
Unlike YAGO and DBpedia, Kylin us-es the infoboxes and the Wikipedia pages containingthese infoboxes to build a training set, and use ma-chine learning methods to extract facts from plainWikipedia articles(Wu and Weld, 2007).
AlthoughKylin achieves a high precision, it is corpus-specific,which means it can only be used in Wikipedia-likecorpora.
It is noticed that all the above works fo-cus on building an English KB, and few efforts havebeen made in building a Chinese one until now.3 Online EncyclopediaWikipedia is known as an accurate online encyclo-pedia whose accuracy is comparable with Encyclo-pedia Britannica(Giles, 2005).
It?s created by thou-sands of volunteers around the whole world.
Untilnow, the English version ofWikipedia has 3,878,200content pages, making it the largest English on-line encyclopedia.
The Chinese version contains402,781 content pages, which is much smaller thanthe English version.HudongBaike is the largest Chinese online ency-clopedia with over 5 million content pages.
Similar-ly with Wikipedia, HudongBaike is also created byvolunteers, and relies on the community to ensureits quality.
Many HudongBaike pages also contains68Preprocessed HudongBaike PagesExtracted Triples HudongBaike ArticlesTriples Extracted from ArticlesKnowledge BaseUp-to-Date DataSemantic ElementsPropagated KBAnalyzing Infoboxes Cleaning pagesMappingDistant supervisionKB construction Semantic Elements ExtractionPropagating KBFigure 2: The framework of Our projecta hand-crafted summary box, infobox.
An infoboxsummarizes the knowledge of the corresponding en-tity.
The information in the infobox is reliable sincethese are collaboratively crafted by many volunteer-s.
Figure 1 is an example page with an infobox fromHudongBaike, introducing a US general ??????
(George Marshall).4 The FrameworkIn this paper, we formulated the KB constructiontask in a semi-supervised learning fashion which re-quires little manual annotation and supports knowl-edge propagation by up-to-date feeds.
Becausethe Chinese part of Wikipedia is relatively smal-l and may suffer from the coverage problem, we useHudongBaike to build our KB in this project.
In fu-ture we may merge the Wikipedia part into our KB.After necessary preprocessings including word seg-mentation and named entity extraction, we are ableto apply our framework shown in Figure 2.In general, our framework contains the follow-ing steps: (1)Extracting knowledge from onlineencyclopedia; (2)Linking triples and building KB;(3)Propagating KB with up-to-date data.4.1 Entity Relation ExtractionCompared to other resources on the Web, onlineencyclopedias contain less noises and feature moreregular structures, thus are considered easier for usto extract knowledge facts.Analyzing Infoboxes As mentioned before, manyHudongBaike pages contains an infobox, whichhas high accuracy and can be used directly forrelation extraction.
We can conveniently parsethese infoboxes into < S,P,O > triples.
Forexample, from the first entry of this infobox,we can derive the following triple: < ??????
, ???
, ????
>(<GeorgeMarshall, BirthP lace, Uniontown >).The precision of the extraction is over 95%, andthese triples can form a valuable knowledge source.Extracting relations with Distant SupervisionExtracting knowledge from infoboxes is efficien-t and can achieve a high precision.
However, manyweb pages in HudongBaike do not have infoboxes.There is much richer knowledge in the main arti-cles of HudongBaike, which we should also take in-to consideration.Extracting knowledge from unstructured articlesis a challenging task.
Traditionally, researchersuse manually created templates to extract relation-s.
These templates need lots of human efforts andare domain-specific.
Recent methods trend to re-ly on machine learning models, which need a largeamount of labeled data.
One idea is to utilize theinfoboxes to form the training data set, and train anextractor to extract relations from the pages with-out an infobox(Wu and Weld, 2007).
However, therelations extracted from a page are restricted to theinfobox template used by the current page catego-ry, and their subject must be the entity that this pagedescribes.
For example, when we extract relation-s from the page of ?????
(Charles Yeager,Ace of US in WWII) which does not contain an in-fobox, the subject of these relations must be CharlesYeager, and we can only extract the relation typeslisted in infobox template for a military person.
Asa result, this method can only be used in online en-cyclopedias in a Wikipedia style, and the recall willbe relatively low.Distant supervision is widely used in relation ex-traction in recent years.
It hardly need any manualwork, and can overcome the above problems.
It canbe used in any reliable corpus, and doesn?t have thestrict restrictions as previous methods.
We adopt itsidea in our framework.
The basic assumption of dis-tant supervision is the sentences containing two en-69Figure 1: A HudongBaike page about a US general George Marshalltities should express the relation between them moreor less.
It only needs a reliable seed KB (in the formof relation triples) and a corpus.
Here, we can usethe knowledge facts extracted from infoboxes previ-ously as the seed KB, and the articles of Hudong-Baike as text corpus.
For each triple in the seed K-B, we generate positive training data by finding sen-tences containing both its subject and object in thecorpus.
For example, we can map the first entry inFigure 1 to the sentence 1880?12?31????????????
(On December 31th, 1880, Mar-shall was born in Uniontown).
The negative trainingdata can be generated by randomly select some sen-tences which contain neither of the subject and theobject.
A predictive model such as logistic regres-sion model is trained with the training data.
We canuse the model to give predictions for the relationsin a textual knowledge source.
For a HudongBaikepage, we should decide the entity pairs we are in-terested in.
A simple strategy is to select all entitypairs.
But it will be time-consuming, and may sufferfrom weak-related entity pairs.
So we extract top-ic entities which have high tfidf weights from thispage, and generate entity pairs under the restrictionthat they must contain at least one topic entity.
Foreach entity pair, we find the sentences which containboth the subject and object and use the predictivemodel to give the possible relations between themand the confidence of the relations.However, the predictions of distant supervisionis less accurate than those of supervised method-s.
So we should adopt some heuristics to filter therelations extracted.
An easy strategy is to set up athreshold for relation confidences to avoid uncertainrelations and improve the precision.
We adopt thismethod in our project.
Furthermore, we can also usethe strategies of Riedel et al (2010) or Yao et al(2010).4.2 Knowledge Base ConstructionAfter the relation extraction, we must link the ex-tracted knowledge triples in order to construct theknowledge base.
In our scenario this linking task canbe formulated as: given a base KB, a bunch of newlyextracted knowledge triples with the sentences de-scribing them and their contexts, the task of entitylinking aims to link each of the entity mentions inthe plain texts (these sentences mentioned above) toits corresponding entity in the base KB.
At the verybeginning, we initiate a base KB by using the taxon-omy of HudongBaike thus are able to map relationsbetween entities into the KB through entity linking.In online encyclopedias, the synonyms of an en-tity are represented by redirect links.
Synonyms areimportant in entity linking because they provide al-ternative names for entities, and we may miss somemappings without them.
For example, we have anentity ??????
(United States of America)in the KB, and an mention ??
(USA) in a pieceof text.
Redirect links can tell us that we can createa mapping between them.
Basically, for each men-tion, we can find matching candidates for them in aKB through exact matching.
However, if we can-not find an exact match for a mention, we will try70fuzzy matching since a mention may not match ex-actly with its referent entity in KB.Now we need to solve the entity linking task.
Tra-ditional methods did not exploit global interdepen-dence between entity linking decisions.
We thusadopt the collective entity linking approach of Hanet al (2011) to solve this problem.
This method cap-tures the rich semantic relatedness knowledge be-tween entities, and take the interdependence of link-ing decisions into consideration.
They construct agraph by linking name mentions and candidate enti-ties in pairwise using the semantic relatedness be-tween them.
Then they use a random walk algo-rithm on the graph to solve the problem.
However,they did not take the NIL problem into considera-tion.
That is, in entity linking, if the referent enti-ty of an name mention is not in our KB, it shouldbe linked to a pseudo entity NIL.
In our case, weshould abandon the mapping of the current triple bydeciding whether this entity has been listed in theKB(Zheng et al, 2010).4.3 Knowledge base PropagationAlthough we can extract millions of relations andbuilt a KB in previous subsections, it has the sameshortage as most existing KBs: the knowledge ex-tracted are mostly statical attributes of entities (suchas birthdate or occupation of a person) and can notdescribe the latest updates of an entity (such as apolitician is currently visiting a country).In order to settle this problem, we use the dy-namical knowledge extracted from up-to-date datato expand our KB.
One possible solution is extract-ing semantic event elements from online news.
Inthis project, we will synchronies our KB with a Chi-nese newspaper, RenMinRiBao (People?s Daily).5 Current WorkCurrently, we have extracted triples from the in-foboxes of HudongBaike and built the base KB.Manual evaluation shows that the precision of struc-tured content extraction is over 95%.
Most errorsare caused by the web page?s own mistakes or edit-ing errors in infoboxes.To assess the quality of HudongBaike data, in ourpreliminary experiments(Yidong et al, 2012), weextract relation facts from plain HudongBaike arti-cles without infoboxes in a way similar to Kylin.
Wefocus on three categories, including ??
(Nation),??
(Person) and ??
(Actor or Actress).
In eachcategory we select several representative attributesfrom its infobox template.
We manually annotatedmore than 200 testing examples for evaluation: 100in Person, 33 in Nation and 91 in Actor or Actress.The results shows that the HudongBaike data can beused to extract knowledge facts with a high precisionin all three categories: in ??
the average precisionis 79.43%, in ??
it is 78.9%, and in ??
it evengoes up to 90.8%.Distant Supervision We further adopt the ap-proach of distant supervision(Mintz et al, 2009) ina Chinese dataset.
We generate a dataset from Ren-MinRiBao with 10000 sentences, and each sentencecontains at least a pair of entities which correspondto a knowledge triple in HudongBaike?s infobox ex-traction.
We use 60% of the sentences as trainingset and 40% as the testing set.
Our experimentsshow that when the recall is 10%, we can obtain ahigh precision of 87%, which indicates the feasibili-ty of our model.
However, as the recall raises, theprecision drops dramatically.
For example, whenthe recall is 29% the precision is about 65%.
Thiscan be remedied by adopting more encyclopedia-specific filtering strategies and assumptions duringthe distant supervision modeling.6 ConclusionsIn this project, we proposed a framework to buildKBs in Chinese.
It uses the infoboxes of Hudong-Baike as a seed knowledge base, the articles ofHudongBaike as extra textual resources, adopts theidea of distant supervision to extract knowledge fact-s from unstructured data and link the triples to builda knowledge base.
This framework requires lit-tle manual work, and can be used in other reliableknowledge resources.
Our preliminary experimentalresults are encouraging, showing that the Hudong-Baike provides reasonable resources for buildingknowledge bases and the distant supervision fashioncan be adapted to work well in Chinese.For the next, we will further adapt our frame-work into a self-training manner.
By using higherthreshold for confidence in distant supervision wecan make sure the precision of extracted knowledge71is high enough for bootstrapping.
Then we put theextracted knowledge facts into the seed KB, and theframework will repeat iteratively.
On the other hand,we can extract knowledge facts from other reliableknowledge resource, such as Wikipedia, academicliterature, and merge knowledge from different re-sources into one KB.
Moreover, we can also makeour KB multilingual by adopting our framework inother languages.ReferencesBanko, M., Cafarella, M. J., Soderland, S., Broad-head, M., and Etzioni, O.
(2007).
Open informa-tion extraction from the web.
In Proceedings ofIJCAI, IJCAI?07, pages 2670?2676.Bizer, C., Lehmann, J., Kobilarov, G., Auer, S.,Becker, C., Cyganiak, R., and Hellmann, S.(2009).
Dbpedia - a crystallization point for theweb of data.
Web Semant., 7:154?165.Etzioni, O., Cafarella, M., Downey, D., Kok, S.,Popescu, A.-M., Shaked, T., Soderland, S., Weld,D.
S., and Yates, A.
(2004).
Web-scale informa-tion extraction in knowitall.
In Proceedings of the13th WWW, WWW ?04, pages 100?110.Giles, J.
(2005).
Internet encyclopaedias go head tohead.
Nature, 438:900?901.Han, X., Sun, L., and Zhao, J.
(2011).
Collectiveentity linking in web text: a graph-based method.In SIGIR, SIGIR ?11, pages 765?774, New York,NY, USA.
ACM.Matuszek, C., Cabral, J., Witbrock, M., and DeO-liveira, J.
(2006).
An introduction to the syntaxand content of cyc.
In Proceedings of the 2006AAAI Spring Symposium.Mintz, M., Bills, S., Snow, R., and Jurafsky, D.(2009).
Distant supervision for relation extractionwithout labeled data.
In Proceedings of the JointConference of the 47th Annual Meeting of the A-CL and the 4th IJCNLP of the AFNLP: Volume 2- Volume 2, ACL ?09, pages 1003?1011.Niles, I. and Pease, A.
(2001).
Towards a standardupper ontology.
In Proceedings of FIOS - Volume2001, pages 2?9.
ACM Press, New York.Riedel, S., Yao, L., and McCallum, A.
(2010).Modeling relations and their mentions without la-beled text.
In Machine Learning and KnowledgeDiscovery in Databases, volume 6323 of Lec-ture Notes in Computer Science, pages 148?163.Springer Berlin / Heidelberg.Stark, M. M. and Riesenfeld, R. F. (1998).
Wordnet:An electronic lexical database.
In Proceedings of11th Eurographics Workshop on Rendering.
MITPress.Suchanek, F. M., Kasneci, G., and Weikum, G.(2007).
Yago: a core of semantic knowledge.In Proceedings of WWW, WWW ?07, pages 697?706, New York, NY, USA.
ACM.Tim, B.-L., J., H., and O., L. (2001).
The semanticweb.
Scientific American.Wu, F. and Weld, D. S. (2007).
Autonomouslysemantifying wikipedia.
In CIKM, CIKM ?07,pages 41?50, New York, NY, USA.
ACM.Wu, F. and Weld, D. S. (2008).
Automatically re-fining the wikipedia infobox ontology.
In WWW,WWW ?08, pages 635?644, New York, NY, USA.ACM.Yao, L., Riedel, S., and McCallum, A.
(2010).
Col-lective cross-document relation extraction with-out labelled data.
In Proceedings of EMNLP,EMNLP ?10, pages 1013?1023, Stroudsburg, PA,USA.
Association for Computational Linguistics.Yidong, C., Liwei, C., and Kun, X.
(2012).
Learningchinese entity attributes from online encyclopedi-a.
In Proceedings of IEKB workshop in APWeb2012.Zheng, Z., Li, F., Huang, M., and Zhu, X.
(2010).Learning to link entities with knowledge base.
InHLT-NAACL 2010, pages 483?491, Stroudsburg,PA, USA.72
