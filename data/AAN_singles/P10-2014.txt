Proceedings of the ACL 2010 Conference Short Papers, pages 74?79,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsCorrecting Errors in a Treebank Based onSynchronous Tree Substitution GrammarYoshihide Kato1 and Shigeki Matsubara21Information Technology Center, Nagoya University2Graduate School of Information Science, Nagoya UniversityFuro-cho, Chikusa-ku, Nagoya, 464-8601 Japanyosihide@el.itc.nagoya-u.ac.jpAbstractThis paper proposes a method of correct-ing annotation errors in a treebank.
By us-ing a synchronous grammar, the methodtransforms parse trees containing annota-tion errors into the ones whose errors arecorrected.
The synchronous grammar isautomatically induced from the treebank.We report an experimental result of apply-ing our method to the Penn Treebank.
Theresult demonstrates that our method cor-rects syntactic annotation errors with highprecision.1 IntroductionAnnotated corpora play an important role in thefields such as theoretical linguistic researches orthe development of NLP systems.
However, theyoften contain annotation errors which are causedby a manual or semi-manual mark-up process.These errors are problematic for corpus-based re-searches.To solve this problem, several error detectionand correction methods have been proposed so far(Eskin, 2000; Nakagawa and Matsumoto, 2002;Dickinson and Meurers, 2003a; Dickinson andMeurers, 2003b; Ule and Simov, 2004; Murataet al, 2005; Dickinson and Meurers, 2005; Boydet al, 2008).
These methods detect corpus posi-tions which are marked up incorrectly, and findthe correct labels (e.g.
pos-tags) for those posi-tions.
However, the methods cannot correct errorsin structural annotation.
This means that they areinsufficient to correct annotation errors in a tree-bank.This paper proposes a method of correcting er-rors in structural annotation.
Our method is basedon a synchronous grammar formalism, called syn-chronous tree substitution grammar (STSG) (Eis-ner, 2003), which defines a tree-to-tree transfor-mation.
By using an STSG, our method trans-forms parse trees containing errors into the oneswhose errors are corrected.
The grammar is au-tomatically induced from the treebank.
To selectSTSG rules which are useful for error correction,we define a score function based on the occurrencefrequencies of the rules.
An experimental resultshows that the selected rules archive high preci-sion.This paper is organized as follows: Section 2gives an overview of previous work.
Section 3 ex-plains our method of correcting errors in a tree-bank.
Section 4 reports an experimental result us-ing the Penn Treebank.2 Previous WorkThis section summarizes previous methods forcorrecting errors in corpus annotation and dis-cusses their problem.Some research addresses the detection of er-rors in pos-annotation (Nakagawa andMatsumoto,2002; Dickinson and Meurers, 2003a), syntacticannotation (Dickinson and Meurers, 2003b; Uleand Simov, 2004; Dickinson and Meurers, 2005),and dependency annotation (Boyd et al, 2008).These methods only detect corpus positions whereerrors occur.
It is unclear how we can correct theerrors.Several methods can correct annotation errors(Eskin, 2000; Murata et al, 2005).
These meth-ods are to correct tag-annotation errors, that is,they simply suggest a candidate tag for each po-sition where an error is detected.
The methodscannot correct syntactic annotation errors, becausesyntactic annotation is structural.
There is no ap-proach to correct structural annotation errors.To clarify the problem, let us consider an exam-ple.
Figure 1 depicts two parse trees annotated ac-cording to the Penn Treebank annotation 1.
The10 and *T* are null elements.74SNP VP .DTThat PRNS, NP VPPRPthey VBPsay SBAR-NONE- S-NONE-0 *T*, ,,MDwill VPVBbe ADJPJJgood PPINfor NPNNSbonds.SNP VP .DTThat PRNS, NP VPPRPthey VBPsay SBAR-NONE- S-NONE-0 *T*, ,, MDwill VPVBbe ADJPJJgood PPINfor NPNNSbonds.
(a) incorrect parse tree(b) correct parse treeFigure 1: An example of a treebank errorparse tree (a) contains errors and the parse tree(b) is the corrected version.
In the parse tree (a),the positions of the two subtrees (, ,) are erro-neous.
To correct the errors, we need to move thesubtrees to the positions which are directly dom-inated by the node PRN.
This example demon-strates that we need a framework of transformingtree structures to correct structural annotation er-rors.3 Correcting Errors by UsingSynchronous GrammarTo solve the problem described in Section 2, thissection proposes a method of correcting structuralannotation errors by using a synchronous tree sub-stitution grammar (STSG) (Eisner, 2003).
AnSTSG defines a tree-to-tree transformation.
Ourmethod induces an STSG which transforms parsetrees containing errors into the ones whose errorsare corrected.3.1 Synchronous Tree Substitution GrammarFirst of all, we describe the STSG formalism.
AnSTSG defines a set of tree pairs.
An STSG can betreated as a tree transducer which takes a tree asinput and produces a tree as output.
Each grammarrule consists of the following elements:?
a pair of trees called elementary treesPRNS,1 NP2 VP3 ,4PRNS,1 NP2 VP3 ,4source targetFigure 2: An example of an STSG rule?
a one-to-one alignment between nodes in theelementary treesFor a tree pair ?t, t?
?, the tree t and t?
arecalled source and target, respectively.
The non-terminal leaves of elementary trees are called fron-tier nodes.
There exists a one-to-one alignmentbetween the frontier nodes in t and t?.
The rulemeans that the structure which matches the sourceelementary tree is transformed into the structurewhich is represented by the target elementary tree.Figure 2 shows an example of an STSG rule.
Thesubscripts indicate the alignment.
This rule cancorrect the errors in the parse tree (a) depicted inFigure 1.An STSG derives tree pairs.
Any derivationprocess starts with the pair of nodes labeled withspecial symbols called start symbols.
A derivationproceeds in the following steps:1.
Choose a pair of frontier nodes ?
?, ???
forwhich there exists an alignment.2.
Choose a rule ?t, t??
s.t.
label(?)
= root(t)and label(??)
= root(t?)
where label(?)
isthe label of ?
and root(t) is the root label oft.3.
Substitute t and t?
into ?
and ?
?, respectively.Figure 3 shows a derivation process in an STSG.In the rest of the paper, we focus on the rulesin which the source elementary tree is not identi-cal to its target, since such identical rules cannotcontribute to error correction.3.2 Inducing an STSG for Error CorrectionThis section describes a method of inducing anSTSG for error correction.
The basic idea ofour method is similar to the method presented byDickinson andMeurers (2003b).
Their method de-tects errors by seeking word sequences satisfyingthe following conditions:?
The word sequence occurs more than once inthe corpus.75S SSNP VPPRN .
SNP VPPRN .DT DTThat ThatSNP VPPRN .
SNP VPPRN .DT DTThat ThatS, NP VP , S, NP VP ,SNP VPPRN .
SNP VPPRN .DT DTThat ThatS, NP VP , S, NP VP ,, ,PRPthey PRPthey(a)(b)(c)(d)Figure 3: A derivation process of tree pairs in anSTSG?
Different syntactic labels are assigned to theoccurrences of the word sequence.Unlike their method, our method seeks word se-quences whose occurrences have different partialparse trees.
We call a collection of these wordsequences with partial parse trees pseudo paral-lel corpus.
Moreover, our method extracts STSGrules which transform the one partial tree into theother.3.2.1 Constructing a Pseudo Parallel CorpusOur method firstly constructs a pseudo parallelcorpus which represents a correspondence be-tween parse trees containing errors and the oneswhose errors are corrected.
The procedure is asfollows: Let T be the set of the parse trees oc-curring in the corpus.
We write Sub(?)
for theset which consists of the partial parse trees in-cluded in the parse tree ?.
A pseudo parallel cor-pus Para(T ) is constructed as follows:Para(T ) = {?
?, ?
??
| ?, ?
?
????TSub(?)?
?
?= ?
??
yield(?)
= yield(?
?)?
root(?)
= root(?
?
)}PRNS,1 NP2 VP4PRP3they VBP5say SBAR6-NONE-7 S8-NONE-90 *T*, ,10,PRNS,1 NP2 VP4PRP3they VBP5say SBAR6-NONE-7 S8-NONE-90 *T*, ,10,Figure 4: An example of a partial parse tree pairin a pseudo parallel corpusSNP VP .DTThat PRNS, NP VPPRPthey VBPsay SBAR-NONE- S-NONE-0 *T*, ,, VBDwill ADJP PPINof NPPRP$his NNSabilities.JJproudFigure 5: Another example of a parse tree contain-ing a word sequence ?, they say ,?where yield(?)
is the word sequence dominatedby ?
.Let us consider an example.
If the parse treesdepicted in Figure 1 exist in the treebank T , thepair of partial parse trees depicted in Figure 4 isan element of Para(T ).
We also obtain this pairin the case where there exists not the parse tree(b) depicted in Figure 1 but the parse tree depictedin Figure 5, which contains the word sequence ?,they say ,?.3.2.2 Inducing a Grammar from a PseudoParallel CorpusOur method induces an STSG from the pseudoparallel corpus according to the method proposedby Cohn and Lapata (2009).
Cohn and Lapata?smethod can induce an STSG which represents acorrespondence in a parallel corpus.
Their methodfirstly determine an alignment of nodes betweenpairs of trees in the parallel corpus and extractsSTSG rules according to the alignments.For partial parse trees ?
and ?
?, we define a nodealignment C(?, ?
?)
as follows:C(?, ?
?)
= {?
?, ???
| ?
?
Node(?)?
??
?
Node(?
?)?
?
is not the root of ?76?
??
is not the root of ?
??
label(?)
= label(??)?
yield(?)
= yield(??
)}where Node(?)
is the set of the nodes in ?
, andyield(?)
is the word sequence dominated by ?.Figure 4 shows an example of a node alignment.The subscripts indicate the alignment.An STSG rule is extracted by deleting nodes ina partial parse tree pair ?
?, ?
??
?
Para(T ).
Theprocedure is as follows:?
For each ?
?, ???
?
C(?, ?
?
), delete the de-scendants of ?
and ?
?.For example, the rule shown in Figure 2 is ex-tracted from the pair shown in Figure 4.3.3 Rule SelectionSome rules extracted by the procedure in Section3.2 are not useful for error correction, since thepseudo parallel corpus contains tree pairs whosesource tree is correct or whose target tree is incor-rect.
The rules which are extracted from such pairscan be harmful.
To select rules which are use-ful for error correction, we define a score functionwhich is based on the occurrence frequencies ofelementary trees in the treebank.
The score func-tion is defined as follows:Score(?t, t??)
= f(t?
)f(t) + f(t?
)where f(?)
is the occurrence frequency in the tree-bank.
The score function ranges from 0 to 1.
Weassume that the occurrence frequency of an ele-mentary tree matching incorrect parse trees is verylow.
According to this assumption, the score func-tion Score(?t, t??)
is high when the source ele-mentary tree t matches incorrect parse trees andthe target elementary tree t?
matches correct parsetrees.
Therefore, STSG rules with high scores areregarded to be useful for error correction.4 An ExperimentTo evaluate the effectiveness of our method, weconducted an experiment using the Penn Treebank(Marcus et al, 1993).We used 49208 sentences in Wall Street Journalsections.
We induced STSG rules by applying ourmethod to the corpus.
We obtained 8776 rules.
WePRN, SNP ,PRN SNPNP VPSNP VPNPNP NPIN NPNPNP PPIN NP(1) (2)(4)source targetVP , S ,NP VP(3) PPIN NNSDT PPIN NPDT NNSFigure 6: Examples of error correction rules in-duced from the Penn Treebankmeasured the precision of the rules.
The precisionis defined as follows:precision = # of the positions where an error is corrected# of the positions to which some rule is appliedWe manually checked whether each rule appli-cation corrected an error, because the correctedtreebank does not exist2.
Furthermore, we onlyevaluated the first 100 rules which are ordered bythe score function described in Section 3.3, sinceit is time-consuming and expensive to evaluate allof the rules.
These 100 rules were applied at 331positions.
The precision of the rules is 71.9%.
Foreach rule, we measured the precision of it.
70 rulesachieved 100% precision.
These results demon-strate that our method can correct syntactic anno-tation errors with high precision.
Moreover, 30rules of the 70 rules transformed bracketed struc-tures.
This fact shows that the treebank containsstructural errors which cannot be dealt with by theprevious methods.Figure 6 depicts examples of error correctionrules which achieved 100% precision.
Rule (1),(2) and (3) are rules which transform bracketedstructures.
Rule (4) simply replaces a node la-bel.
Rule (1) corrects an erroneous position of acomma (see Figure 7 (a)).
Rule (2) deletes a use-less node NP in a subject position (see Figure 7(b)).
Rule (3) inserts a node NP (see Figure 7 (c)).Rule (4) replaces a node label NP with the cor-rect label PP (see Figure 7 (d)).
These examplesdemonstrate that our method can correct syntacticannotation errors.Figure 8 depicts an example where our methoddetected an annotation error but could not correctit.
To correct the error, we need to attach the node2This also means that we cannot measure the recall of therules.77PRN, SNP ,VPI thinkPRN, SNP ,VPI think NPNP S VPis  one  good  oneall  you  needNP S VPis  one  good  oneall  you  needIN PP NNSof DTthe respondents INPPNNSof DTthe respondentsNPNP NP NPthe  U.S.only  two  or  three  other  major  banksIN NPinNP NP PPthe  U.S.only  two  or  three  other  major  banksIN NPin(a) (b)(c)(d)Figure 7: Examples of correcting syntactic annotation errorsSPP SBAR,INAt NPNPCD10:33, SPP SBAR,INAt NPCD10:33 ,when ... when ...Figure 8: An example where our method detectedan annotation error but could not correct itSBAR under the node NP.
We found that 22 of therule applications were of this type.Figure 9 depicts a false positive examplewhere our method mistakenly transformed a cor-rect syntactic structure.
The score of the ruleis very high, since the source elementary tree(TOP (NP NP VP .))
is less frequent.
Thisexample shows that our method has a risk ofchanging correct annotations of less frequent syn-tactic structures.5 ConclusionThis paper proposes a method of correcting er-rors in a treebank by using a synchronous treesubstitution grammar.
Our method constructs apseudo parallel corpus from the treebank and ex-tracts STSG rules from the parallel corpus.
Theexperimental result demonstrates that we can ob-tain error correction rules with high precision.TOPNP .VPbased on quotations atfive major banksThe average of interbank offered ratesNPTOPNP .VPbased on quotations atfive major banksThe average of interbank offered ratesSFigure 9: A false positive example where a correctsyntactic structure was mistakenly transformedIn future work, we will explore a method of in-creasing the recall of error correction by construct-ing a wide-coverage STSG.AcknowledgementsThis research is partially supported by the Grant-in-Aid for Scientific Research (B) (No.
22300051)of JSPS and by the Kayamori Foundation of Infor-mational Science Advancement.78ReferencesAdriane Boyd, Markus Dickinson, and Detmar Meur-ers.
2008.
On detecting errors in dependency tree-banks.
Research on Language and Computation,6(2):113?137.Trevor Cohn and Mirella Lapata.
2009.
Sentence com-pression as tree transduction.
Journal of ArtificialIntelligence Research, 34(1):637?674.Markus Dickinson and Detmar Meurers.
2003a.
De-tecting errors in part-of-speech annotation.
In Pro-ceedings of the 10th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 107?114.Markus Dickinson and Detmar Meurers.
2003b.
De-tecting inconsistencies in treebanks.
In Proceedingsof the SecondWorkshop on Treebanks and LinguisticTheories.Markus Dickinson and W. Detmar Meurers.
2005.Prune diseased branches to get healthy trees!
howto find erroneous local trees in a treebank and whyit matters.
In Proceedings of the 4th Workshop onTreebanks and Linguistic Theories.Jason Eisner.
2003.
Learning non-isomorphic treemappings for machine translation.
In Proceedings ofthe 41st Annual Meeting of the Association for Com-putational Linguistics, Companion Volume, pages205?208.Eleazar Eskin.
2000.
Detecting errors within a corpususing anomaly detection.
In Proceedings of the 1stNorth American chapter of the Association for Com-putational Linguistics Conference, pages 148?153.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: the Penn Treebank.
Computa-tional Linguistics, 19(2):310?330.Masaki Murata, Masao Utiyama, Kiyotaka Uchimoto,Hitoshi Isahara, and Qing Ma.
2005.
Correction oferrors in a verb modality corpus for machine transla-tion with a machine-learning method.
ACM Trans-actions on Asian Language Information Processing,4(1):18?37.Tetsuji Nakagawa and Yuji Matsumoto.
2002.
Detect-ing errors in corpora using support vector machines.In Proceedings of the 19th Internatinal Conferenceon Computatinal Linguistics, pages 709?715.Tylman Ule and Kiril Simov.
2004.
Unexpected pro-ductions may well be errors.
In Proceedings of 4thInternational Conference on Language Resourcesand Evaluation, pages 1795?1798.79
