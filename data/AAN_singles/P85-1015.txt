Parsing with Discontinuous ConstituentsMark JohnsonCenter for the Study of Language and InformationandDepartment of LinKuktics, StLnford University.AbstractBy generalizing the notion of location of a constituent to allowdiscontinuous Ioctaions, one can describe the discontinuous consti-tuents of non-configurational l nguages.
These discontinuous consti-tuents can be described by a variant of definite clause grammars,and these grammars can be used in conjunction with a proof pro-cedure to create a parser for non-configurational languages.1.
IntroductionIn this paper \[ discuss the problem of describing and computa-tionally processing the discontinuous constituents of non-configurational languages.
In these languages the grammatical func-tion that an argument plays in the clause or the sentence is notdetermined by its position or confguration in the sentence, as it isin configurational languages like English, but rather by some kind ofmorphological marking on tile argument or on the verb.
Word  orderin non-configurational languages is often extremely free: it has beenclaimed that if some string of words S is grammatical in one of theselanguages, then the string S' formed by any arbitrary permutationof the words in S is also grammatical.
Most attempts to describethis word order freedom take mechanisms designed to handle fairlyrigid word order systems and modify them in order to account forthe greater word order freedom of non-configurational languages..Mthough it is doubtful whether any natural language ever exhibitssuch total scrambling, it is interesting to investigate the computa-tional and linguistic implications of systems that allow a ifigh degreeof word order freedom.
So the approach ere is the opposite to theusual one: I start with a system which, unconstrained, allows forunrestricted permutation of the words of a sentence, and captureany word order regularities the language may have by adding res-trictions to the system.
The extremely free word order of non-configurational languages is described by allowing constituents tohave discontinuous \[ocatio,ls.
To demonstrate that it is possible toparse with such discontinuous constituents.
I show how they can beincorporated into a variant of definite clause grammars, and thatthese grammars can be used in conjunction with a proof procedure.such as Ear\[ey deduction, to coestruct a parser, a.s shown in Pereiraand Warren (1983).This paper is organized as follows: section 2 contains an infor-mal introduction to Definite Clause Grammars and ,lisctmses howthey can be used in parsing, section :l giws a brief description ofsome of the grammatical features of o**o non-,'onligurationallanguage.
Guugu Yimhlhirr, section I presents ;t deiinite clause frag-ment for this language, aml shows how this can be u~ed for parsing.Section 5 notes that the use of di~conti*uiot*s con.~l.ituent.~ is *lot lim-ited to definite clause granunars.
\[)lit they could lie incorporatedinto such disparate formalisnts as GP~(;, I,FG or (';\[L Section 6discusses whether a unified account of par.qng both conligurationaland non-configurational l nguages can be given, and section 7 com-pares the notion of discontinuous constituents with other approachesto free word order.2.
Definite C lam Grammars  and Pars ing\[n this section \[ show how to represent both an utterance anda context free granmmz (CI"G) so that tile locations of eoustituentsare explicitly represented in the grammar formalism.
Given this, itwill be easy to generalize the notion of location so that it candescribe the discontinuous constituents of non-configurationallanguages.
The formalism \[ use here is the Definite Clause Gram-mar formalism described in Clocksin and Mellish (1084).
To fatal-liarize the reader with the DCG notation, I discuss a fragment forEnglish in this section.
In fact, the DCG representation is evenmore general than is brought out here: as Pereira and Warren (1083)demonstrated, one can view parsin K algorithms highly specializedproof procedures, and the process of parsing as logical inferencing onthe representation of the utterance, with the grammar functioningas the axioms of the logical system.Given a context free grammar, as in (l), the parsing problem isto determine whether a particular utterance, such as the one in (2},is an S with respect to it.
{1) S - -  NP VPVP ~VNPNP -- Det NDet -- NP  \[?Ce~l('2} 0 the t boy's 2 father 3 hit 4 the s dog sThe subscripts in (2} serve to locate the lexical items: theyindicate that, for instance, the utterance of the word d0~ began attime t s and ended at time t s. That is, the location of the utterance"dog" in example (2) was the interval (t~,tsl.
\[ interpret he sub-scripts aa the points in time that segment the utterance into indivi-dual words or morphemes.
Note that they perform the same func-tion as the vertices of a standard chart parsing system.Parsing {2} is the same as searching for an S node that dom-inates the entire string, ie.
whose location is \[0,6!.
By looking at therules in {I), we see that an S node is composed of an NP  and a VPnode.
The interpretation conventions associated with phrase struc-ture rules like those in (I) tell us this, and also tell us that the loca-tion of the S is the concatenation of the location of tile NP  and theVP.
That is, tile existence of an S node located at i0.t~!
would beimplied by the existetlce of an NP node located at interval r O.z i ( za variable) and a V'P node located at \[: ,8 t.The relationship between the mother constituent's locationanti those of its daughters is made explicit in the definite clausegrauunar, .~hown in (3}, that corresponds to the CFG (l}.
The utter-ante (1) (after lexical analysis} would be represented as in (4).Those familiar with Prolog should note that \[ \[lave reversed theusual orthographic convention by writing variables with a lower ca~eintial letter (they are also italicized), while constants begin with anupper case letter.
(3) S(z ,: ) - -  NP(.r ,y ,0) & VP{V ,: }.VP(: ,: ) - -  V(z ,y ) &NP(y ,: ,O}.NP(z .
: ,case ) - -  Det(z .y ) & N(y ," ,ca** ).Det(z ,y ) - -  NP(x ,y ,Gen)127(4) Det(0,1).N(l,2,Gen).N(.~,3,~).V(3,4).Det(4,5).N(S,8,~).
(3) contains four definite clauses; each corresponds to onephrase structure rule in the CFG (I).
The major difference for usbetween (1) and (3) is that in (3) the locations of the constituentsfie.
the endpoints) are explicit in the formalism: they are argumentsof the constituents, the first argument being the beginning time ofthe constituent's location, the second argument its ending time.ALso note the way that syntactic features arc treated in this system:the difference between genitive and non-genitive case marked nounsis indicated by a third argument in both the N and NP constituents.Genitive nouns and noun phrases have the value Gen for their thirdargument, while non-genitive NP have the value ~, and the rule thatexpands NP explicitly passes the case of the mother to the headdaughter t.We can use (3) and (4) to make inferences about the existenceof constituents in utterance (2).
For example, using the rule thatexpands ~ in (3) together with the first two facts of (4), we caninfer the existence of constituent NP(0,2,Gen).The simplest appruach to parsing is probably to use (t) in atop*down fashion, and start by searching for an S with location \[0,6\];that is, search for goal S(0,6).
This method, top down recursive des-cent, is the method the programming language Prolog uses to per-form deduction on definite clauses ystems, so Prulo g can easily beused to make very efficient op*down parsers.Unfortunately, despite their intuitive simplicity, top downrecursive descent parsers have certain properties that make themless than optimal for handling natural language phenomena.
Unlessthe grammar the parser is using is very specially crafted, theseparsers tend to go into infinite loops.
For example, the rule thatexpands NP  into Det and N in (3) above would be used by a top-down parser to create a Det subgoal from an NP  goal.
But DetLtself can be expanded as a genitive NP, so the parser would createanother NP  subgual from the Det subgoal, and so on infinitely.The problem is that the parser is searching for the same \[NPmany times over: what is needed is a strategy that reduces multiplesearches for the same item to a single search, and arranges to shareits results.
Eariey deduction, based on the Eariey parsing algorithm.is capable of doing this.
For reasons of time, I won't go into detailsof Eariey Deduction (see Pereira and Warren (1983) for details}; \[will simply note here that using Eariey Deduction on the definiteclause grammar in {3) results in behaviour that corresponds exactlyto the way an Earley chart parser wouhl parse (I ).3.
Non-conf lgurat lon~l  Languagesin this section I identify some of the properties of uon-conhgurational languages.
Since this is a paper on discontinuousconstituents, \[ focus on word order properties, as exemplified in thenon-configurational l nguage Guugu Yimidhirr.
The treatment hereis necessarily superficial: \[ have completely ignored many complexphonological, inflectional and syntactic processes that a completegrammar would have to deal with.A non-configurationa\[ language dilfer~ front configurationallanguages like English in that morphological form (eg.
affixes),rather than position fie.
configuration), indicates which words aresyntactically connected to each other, in Engii~h the grammatical,and hence semantic, relationsitip betwe~.n bog.
father and dog in (5)are indicated in surface form by their positiou~, ~t,l changing thesepositions changes these relationships, and hence the meaning, ~s in' Of course, there is nothing special about these two values:any two distinct values would have done.(6).
(5) The boy's father hit the dog(6) The father's dos hit the boyIn Guugu Yimidhirr, an Australian language spoken in north-east Queensland, the relationships in {7) 2 are indicated by the affixeson the various nouns, and to change the relationships, one wouldhave to change the alfLxes.
(7) Yarraga-aga~ mu-n gudaa gunda-y biiba-ngunboy-GEN-mu-ERG dog+ABS hit-PAST father-l~RG'The boy's father hit the dog'The idea, then, is that in these languages morphological formplays the same rule that word order does in a configurationallanguage like English.
One might suspect hat word order would berather irrelevant in a non-configurational l nguage, and infactGuugu Yimidhirr speakers remark that their language, un-like English, can be spoken 'back to front': that is, it ispossible to scramble words and still produce a grammaticalutterance (Haviland 1979, p 26.
)Interestingly, in some Guugu Yimidhirr constructions itappears that information about grammatical relations can be obtaineither through word order or morphology: in the possessive construc-tionWhen a complex NP carries case inflection, each element(in this case, both possession and possessive xpression)may bear case inflection - and both must be inflected forcase if they are not contiguous - but frequently the 'headnoun' (the posac~ion) Idirectly MJ I precedes the possessiveexpre~ion, and only the latter has explicit case inflection(Haviland 1979,p.56)Thus in (8), biiba 'father' shows up without an ergative suffixbecause it is immediately to the left of the NP that possesses it (is.possession is indicated by position).
(8) Biiba yarraga-aga- m~n gudaa gunda-yfather boy-GEN-mu-ERG dog+ABS hit-PAST'The boy's father hit the dog'While ultimate judgement will have to await a full analysis ofthese constructions, it does seem as if word order and morphologicalform do supply the same sort of information.In the sections that follow.
\[ will show how a variant ofdefinite clause grammar can be used to describe the examples givenabove, and how this grammar can be used in conjunction with aproof procedure to construct a parser.4.
Repeesent in$ Discont inuotm Const i tuent8\[ propose to represent discontinuous constituents ratherdirectly, in terms of a syntactic ategory and a discontinuous loca-tion in the utterance.
For example, \[ represent the location of thediscontinous constituent in (7), Yarraga.aea.mu.n ... biiba.ngun"boy's father' a.~ a set of continuous locations, as in (9).
(ol {\[o.tl,{:~.4i}.Alternatively, one could represent discontinuous locations interms of a 'bit-pattern', am in (10), where a 'l' indicates that theconstituent occupies this position.
(10) { ~ 0 0 i \]While the descriptive power of both representations is thesame, \[ will use the representation of (9) because it is Somewhato AJI examples are from Haviland (1979).
The constructionsshown here are used to indicate alienable pcnse~ion (which includeskinship relationships).128easier to state configur~ional notions in it.
For example, therequirement thw; a constituent be contiguous can be expressed byrequiring its location set to have no more than a single intervalmember.To represent the morphological form of NP constituents I usetwo argument positions, rather than the single argument positionused in the DCG in (3).
The firet takes as values either Er~, ~ or~, and the second either Gen or ~.
Thus our discontinuous NP hasthree a4"gument positions in total, and would he represented as (11).
(U) NP(\[\[0,t} ,\[a,4ll,Erz,~).\[Zz (II), the firet argument pmition identifies the constituent'slocation, while the next two are the two morphological form argu-ments discussed immediately above.
The grammar ules must tellus under what conditions we can infer the existence of a constituentlike (I1).
The morphologies/ form features eem to pose no particu-lar problem: they can be handled in a similia~ way to the genitivefeature in the mini-DCG for English in (3) (although a full accountwould have to deal with the dual ergative/ahsohtive andnominative/accusative systems that Guugu Yimidhirr possesses).But the DCG rule format must be extended to allow for discontinu-ous locations of constituents, like (11).\[n the rule~ in (3), the end-points of the mother's location ~reexplicitly constructed from the end-points of the daughter's loca-tions.
\[n general, the realtionship between the mother's location andthat of its daughters can be represented in terms of a predicate thatholds between them.
\[n the DCG rules for Guugu Yimidhirr, (12) to(14}, the relationship between the mother's location and those of itsdaughters i represented by the predicate combines.The definition of combines  ~ ~, follows: combines( I , l , , l~)  istrue if and only if I is equal to the (bit-wise) union of I~ and I~, andthe (bit-wise) intersection of I~ and I~ is null {ie.
I~ and I~ must benon-overlapping locations),(12) S(i) - -  V(I,)  & NP(I:,EnI,~) & NP(Is,Abs,m)~ combine*.
(/,I 1,l~,la)-(~3) NP( / ,cue ,e) - -  N(lz,c~e ,e) & NP(l~.c~e ,Gen)&: combines(/,l z,l~).
(14} NP(/,case t ,caae2) ~ N(/ ,c~c t,casc~)Following Hale (1983), I have not posited a VP node in thisgrammar, a/though it would have trivial to do so.
To a~count forthe 'configurational' possessive shown in (8), \[ add the additions/clause in (15) to the grammar.
(15) NP({{z ,:t\],c~se ,~) - -  NP({\[z ,~ \]\],e,e) & N(II~ ,z}l,case ,Gen)Given this definite clause grammar and a proof procedure sucha~ Earley Deduction, it is quite straight-forward to construct aparser.
In (16) \[ show how one can parse \[7) using the above gram-mar and the Eariey Deduction proof procedure.
The Prolog predi-cate 'p' starts the parser.
First the lexical analyser adds lexicalitems to the state (the workin~ store of the deduction procedure),when this is finished the deduction pr~edure uses the DCG rulesabove to ma&e inferences about the utterance.
The answer '*-yes'given by the parser indicates that it waa able to find an S that spansthe entire utterance.
The command 'print state' prints the state ofthe deduction sy,~tem; since new inferences are always added to thebottom of the state, it provides a chonnlogica/ records of the deduc-tions made by the system.
The state is printed in Prolog notation:variables are written a.s '_I', '_.
~', etc., and the implication symbol(re)a~prologeariey atucnscrUNSW-PROLOG: p(\[y arragaagamun,gudaa, gunday,hiibangun\])?Word yarragaagmman is a n(\[\[O, Z\]\], era, sen)Word q,~u ~ a n(\[\[Z, ~1\], ,~, ,  o)Word ~,.#~v ~ a ~({\[z, 31\])Word b;;66ng~n is a .
(\[\[*, 41\], ~'s, o)** yes: print_sta~e !..
(frO, 111, "g ,  Z" ),,,(\[\[z, 21\], .b,,,, o),,(\[\[2, aid"fills, 4t1, erg, o)~1\[0, 4\]}) :- v(_z), np(_~, erg, o), ~p(_3, abs, o),eombines({{O.
411, _z, _2, _3~8(((0.
4{i ) :.
np(_t, er~, o}, np(_2, abs, o).combines{{\[0, 4J\], {{2, 3\[l, _t, _2)np(_t, erE, o) :- n(_2, er~, o) , rip(_3, ez'~, gen) ,combines(_t, ..2, _3)np(_Z, er&, o) :- rip(_2, erz, sen), combine~_l.
~I3, 411, _2)np(_Z, e~,  sen) :- n(_L erg, zen)np(\[\[o, ill, , , s ,  z~)np(_t, err, o):-  combines(_t, \[\[3, 4H, \[\[0, Z!\])combines(l\[0, tl, \[3,-lJ\], I\[3, 4lJ, {\[0, tJJ),.p(\[\[o, xl, \[3, 41l, ~'s, o)~(({0, 4(0 :- np(_l, abs, o),combines({{O, 411, \[\[2, 31\[, \[\[0, 11, {3, 4\[\], _/)up( J ,  abs, o) :- n(_2, abs, o) , np(..3, abs.
gen) ,combines(_l, _2, 3 )np(L ,  abs, o):-  np(_2, abs, gen), combines(J, IIt 21I, _2)np(_l, abs, gen) :- .
(_1, abs, gen),p(_t.
a~.
o) :.
n{_t.
~ .
o)opfl\[z, 2}h ab., o)s({{0, 41\[ ) :.
combines({\[0 ' 4\[{, \[{2, 3 , \[\[0, l, 3 41\[, I\[1, 2J\]}combin O, 4 , 2, 3 ?
(frO, ~ I I  II {I If, I\[ 0, 1, {3, 4 \[, Ill, -OIl).P{{\[_Z, _?.l\], ~bs, o):- npflI_L _all, o, o), "(if_3,--~/!, abs, St.)np{\[\[_1, _?.If, o, o) :.
n(_3, o, o), np(_~, o, genl,combines({!_l, _211 ' _3, _4)nP{{LI,--~ll, o, o) :- .
({I_t, _.oil, o, o)nl~I\[_i, _2fJ, o, o):-  np(\[(_/, _3\]1 , o, o) , n((\[_3, _2JJ, o, Sen).
IN_I, er~, o) :- n(_/, er~, o).~\ [ \ [a ,  4\]\], ,g ,  o)s({{0, 4{\]):- rip(_/, abs, o), comb nes(\[\[0 4\]J ~\[o 3~ if3 411 ,,?
.ll) , omb,nv(II0, 3!i, !f3 ii .
.
.
.
.
.
.
.I'P~\[- L, - - Ib  erg, o):- np(\[\]_l, _31\] , o, o), n(fI_3 , _2!1 ' erg, gen)6.
Ualnt  Dh~ont inuoua Const i tuents  in GrsmamgrsAhhough the previous ection introduced iscontinuous consti-tuents  in terms of definite cianse grammar, there is no reason wecould not invent a notation that abbreviates or implies the "com-bines' relationship between mother and daughters, just a.s the CFGin (1) "implies" the mother-daughter location relationships madeexplicit in the DCG (3).
For instance, we could choose to interpreta rule like (171 ~s implying the 'combines' relationship between themother and its daughters.
(17) A -* /7  ;C  ;DThen the DC'G grammar presented in the last section could bewritten in the GPSG like notation of (18).
Note that the third ruleis a stamdaed phrase structure rule: it expresses the 'configurationai'p~sessive shown in (81.129(zs~ s - \ [ c~E~l  ; v; \[CAS~'AbelIt is easy to show that grammars based on the 'combines'predicate lie outside the class of context free languages: the s t r inpthe grammar (19) accepts are the permutations of a m b 'c  "; thusthis grammar does not have weakly equivalent CFG.
(,91 S- -= ;b  ; c  ; (S )While it would he interesting to investigate other properties ofthe 'combines' predicate, I suspect hat it is not optimal for describ-ing linguistic systems in general, including non-configurationallanguages.
It is difficult to state word order requirements hat referto a particular constituent position in the utterance.
For instance,the only word order requirement in Waripiri, another non-configurational language, is that the auxilary element must followexactly one syntactic onstituent, and this would be difficult to statein a system with only the predicate 'combines', although it would beeasy to write a special DCG predicate which forces this behaviour.Rather, l suspect it would be more profitable to investigateother predicates on constituent locations besides 'combines' to seewhat implications they have.
\[n particular, the wrapping operationsof Pollard (1984) would seem to be excellent candidates for suchrL,~eagc h.Finally, I note that the discontinuous constituent analysisdescribed here is by no means incompatible with standard theoriesof grammar.
A~ I noted before, the rules in (18) look very much likeGPSG rules, and with a little work much of the machinery of GSPGcould be grafted on to such a formalism.
Similiarly, the CFG partof LFG, the C-structure, could be enriched to allow discontinuousconstituents if one wished.
And introducing some version of discon-tinuous constituents to GB could make the mysterious "mapping"between P-structure and L-structure that Hale (t983) talks about alittle less perplexing.My own feeling is that the approach that would bring the mostimmediate results would be to adopt some of the "head driven"aspects of Pollard's (1984) Head Grammars.
\[n his conception,heads contain as lexical information a list of the items they sub-categorize for.
This strongly suggests that one should parse accord-ing to a "head first" strategy: when one parses a sentence, one looksfor its verb first, and then, based on the lexical form of the verb, onelooks for the other arguments in the clause.
Not only would such anapproach be easy to implement in a DCG framework, but given theempirical fact that the nature of argument NPs in a clause isstrongly determined by that clause's verb, it seems a very reasonablething to do.8.
Imp lementha  g the  ParserIn their 1983 paper, Pereira and Warren point out severalproblems involved in implementing the Earley proof procedure, andproposed ways of circumventing or minimizing these problems.
In:.his section \[ only consider the specialized case of Earley Deductionworking with clauses that correspond to grammars of either the con-tinuous or discontinuous constituent type, rather than the generalca~e of performing deduction on an arbitrary set of clauses.Considering first the case of Earley Deduction applying to aset of clauses like (3) that correspond to a CFG, a sensible thing todo would be to index the derived clauses fie.
the intermediateresults) on the left edge of their location.
Because Earley Deductionon such a set of clauses always proceeds in exactly the same manneras Eariey chart parsing, namely strictly left to right within a consti-tuent, the position of the left edge of any constituent being searchedfor is always determined by the ending location of the constituentimmediately preceeding it in the derivation.
That  is, the proof 15ro-cedure is always searching for constituents with hard, ie.
non-variable, left edges.
I have no empirical data on this point, but thereduction in the number of clauses that need to be checked becauseof this indexing could be quite important.
Note that the vertices ina chart act essentially as indices to edges in the manner described.Unfortunately, indexing on the left edge in system workingwith discontinuous constituents in the manner suggested abovewould not be very useful, since the inferencing does not proceed in aleft to right fashion.
Rather, if the suggestions at the end of the lastsection are heeded, the parser proceeds in a "head first" fashion,looking first for the head of a constituent and then for its comple-ments, the nature and number of which are partially determined byinformation available from the head.
ht such a strategy, it wouldseem reasonable to index clauses not on their location, but on mor-phological or categorial features, such as category, case, etc., sincethese are the features they will be identified by when they aresearched for.It seems then that the optimal data structure for one type ofconstituent is not optimal for the other.
The question then ariseswhether there is a unified parsing strategy for both configurationaland non-configurational l nguages.
Languages with contiguous con-stituents could be parsed with a head first strategy, but I suspectthat this would prove less efficient than a strategy that indexed onleft edge position.
Locations have the useful property that theirnumber grows as the size of the sentence (and hence the number ofconstituents) increases, thus giving more indexing resolution where itis needed, namely in longer sentences.
But of course, one couldalways index on both morphological category and utterance iota-lion...?.
Comptwison  w i th  o th~ Fram~orksIn this section I compare the discontinuous locm~ion approach \[have developed above to some other approaches to free word order:the ID/LP rule format of GPSG, and the non-configurational encod-ing of LFG.
\[ have omitted a discussion of the scrambling and rais-ing rules of Standard Theory and their counterparts in current GBtheory because their properties depend strongly on properties of thegrammatical system as a whole (such a.s a universal theory of "land-ing sites", etc.
): which (as far as I know) have not been given insufficiently specific form to enable a comparison.The ID/LP rule format (Gazdar et al 1985) can be regarded asa factoring of "normal" context free rules a into two components, oneexpressing immediate domination relationships, the other the linearprecedence relationships that hold between daughter constituents.For example, the ID rule in (20) and the LP rule in (21) express thesame mother-daughter r lationships as the rules in (22).
(20) S " Io  {V, NIP, NP, S' }(21) V < S'(22) S - -  V NP NP S'S - -  V NP S* NPS - -VS  f NPNPS- -  NPVNPS 'S - -NPVS f NPS - -  NP NP V S'Because a grammar in ID/LP format always has a stronglyequivalent context free grammar, only context free languages can begenerated by these grammars.
Since it is possible to write grammarss In Gasdar etad.
(1985) the system is more complicated thanthis, since the ID/LP component interacts with the feature instan-elation principles and other components of the grammar.130for non-context-free languages using discontinuous constituents (usshown above), it is clear tha& ID/LP format is I~  powerful than thediscontinuous constituent analysis proposed here.
~n particular,ID/LP allows only reordering of the daughters of a constitiuent rels-tire to the other daughters: it does not allow a constituent to be"scattered" accrom the sentence in the way a discontinuous consti-tuent analysis allows, Thus an ID/LP grammar o\[ Guugu Yimidhirrcould not ana/yse sentence (7) in the same way we did here.
In fa~t,if we added the requirement that all locations be continuous (ie.
tbagthe location sets contain at moat one member) to the DCG r~esusing the 'combines' predicate, the word order freedom allowedwould be the same as that allowed by an ID rule without any LPrestrictions.
I don't claim that it is imposaible to write a GPSGgrammar \[or a ~angua4$e like Guu~pa ~fLmidlxit~ ou the busis of theformatism's not =flowing dL~:outinuous cormtituents: on closer inveS-tiSatio~ it misht  turn out that the "discontinuities" could bedescribed by some set of medium or long distance dependencies.In LFG the nature of the mapping between c-structure and f-structure nables it to achieve many of the effects o\[ discontinuous?onstituenta, even though the phrase structure component (the c-structure) does not allow discontinuous constituents ~ such.
In psi-ticular, the information represented in one component o\[ the f-structure may come from several di~erent c-structure constituentslocated throughout the sentence.
For example, in their analysis ofthe cross serial dependencies in Dutch, Bresnan, Kaptan, Peters andZaenen (1982) propose that the PREP feature of the VCONIP com-ponent of the f-structure is set by a verb located down one branchof the c.structure tree, while the OBJ feature of that component isset by an NP located on another branch o| the c.structure tree.Thus in LFG one would not claim that there was a discontinuousNP in (7~, but ralAer that both the ergative NP and the genitivemsrked e~ative NP were contributing information to the same corn-portent of the f-structUre.\[n the .on-confiquratianai cncodlaf of Bresnan (1982, p.297),the c-structure is relatively impoverished, and the morphology' onthe lexica~ items identifies the component of the f-structure theysupply information to.
For example, the c-structure in (23) togetherwith the lexical items in (24) give sentence (7) the f-structure (25).
(23) S_{  NP,~=\[V }*NP(T SUBJ poss)=LVarraea.aga.mu-n (I, CASE}==Erg(LOcal=+NPg.d== (t OBJ)= \[(t CASE}-~--AbsVgunda.y (T PRED)~ffihit((t SUBJ),(\[ OBJ))NPbiiba.nonn .
(1 SUBJ}==L(t CASE\]-----~rZ(25)CASE =- Erg 1POSS == | Gen == +L PRED == aoySUBJ = CASE == Erg "~PRED = \[ =ther /oASE = Abs /OBJ - PRED = do9 ~.
.
-'~PP~D = h;t( - ~LFG is capable of describing the "discontinuity" of (7)without using discontinuous constituents.
There is, however, a sub-tle difference in the amount of "discontinuity" allowed by the LFGand the discontinuous constituent analyses.
As | remarked at thebeginning of the paper, the discontinuous constituent approachal/ows grammars that accept tots/scrambl ing of the lexical items: ifa string S is accepted, then so is any permutation of S. In particu-lar, the discontinuous constituent approach glows unrestrictedscrambling of elements out of embedded clauses and stacked N'Ps.which the LFC non-configurational encoding analysis cannot.
Thisis because the position in the sentence's f-structure that any lexicalitem occupies is determined solely by the f-equation annotationsattached to thaL lexical item, since the only equations in the c-structure are of the form ~L,  and these create no new componentsin the f-structure for the clause to embed the f-structures from lexi-ca/ i tems into.Suppose, for example, Guugu Yimidhirr allowed stacked NPpoeseesors, in the same way that English allows them in construc-tions like my mother's lather'8 brother, except that, because thelanguage is non-conFigurational, the lexical elements could be scat-tered throughout the entire sentence.
The LFG analysis would runinto problems here, because there would be a potentially infinitenumber of positions in the f-structure where the possessor could belocated: implying that there are an infinite number of lexical entriesfor each poaae~ive NP.Guugu Yimidhirr does not exhibit such stacked possessives.Rather, the possessor of the possessor is indicated by a dative con-struction and so *,he LFG analysis is supported here.
None the less,a similiar argument shows that embedded clausal f-structure com-ponents such a.s adjunts or VCOMP must have corresponding c-structure nodes so that the lexical items in these clauses can beattached sufficiently "far down" in the f-structure for the entire sen-tence.
(Another possibility, which \[ won't explore here, would be toallow f-equation annotations to include regular ezpressiona overitems like VCOMP I- Still, it would be interesting to investigatefurther the restrictions on scrambling that follow from the non-configurational encoding analysis and the bame principles of LFG.For instance, the a~Tinc parsa6dity property (F'ereira and Warren1983) that is required to assure decidablity in LFG (Bresnan andKaplan 1982) essentially prohibits scrambling of single lexical ele-ments from doubly embedded clauses, because such scramblingwould entail one S node exhaustively dominating another.
But thesedistinctions are quite subtle, and, unfortunately, our knowledge ofuon-configurational languages is insufficient o determine whetherthe scrambling they exhibit is within'the limits allowed by non-configurations/encoding.8.
Conchmion\['\[ale (1983) begins his paper by listing three properties tha~.have come to be associated with the typological label ~non-configurational', namely (i) free word order, (ii) the use of :~yntacti-tally discontinuous constituents and (iii) the extensive use of nullanaphora.
\[n this paper \[ have shown that the flint two propertiesfollow from a system that allows constituents that have discontinu-ous constituents and that captures the mother daughter locationrelationships using a predicate like 'combines'.131It is still far too early to ~ell whether this approach really isthe moe~ appropriate way to deal with discontinuous coustituente: itmay be that for a grammar of ressonsble size some other t~echnique,such as the non-configurational encoding of LFG, will be superior onlinguistic and computational grounds.9.
B ib l iosrsphyJ.
Bresnaa (1982), "Control and Complemencation," in TheMental Representation of Gr4mmatizal Rdatione, J. Bresn~n, ed.,pp.
173.281, ~ Pre~, CambridKe, Ma~.J.
Bresnan and R. Kaplan (1982), "Lexical Functional Gram-mar: A Formal System for Grammatical Representation," in TheMental Reprcecntatien of Grammatical Relations, J. Bresnan, ed.,pp.
t73.281, MIT Press, Cambridge, Mass.J.
Bresnan, R. Kaplan, S. Peters and A. Zaenen (1982),Croee.Serial Dependeneic* in Detek, Linguistic Inquiry, II.4, pp.613-635.G.
Ga:ldar, E. Klein, G. Pullum and I.
Sag, (1985) GeneralizedPhrc~e Structure Grammar, Havard University Press, C&mbridge,Ma~s.K.
Hale (1983), "Warlpiri and the Grammar of Non-configur,,tional Languages", Natural Language and LinguieticTheory, t.t, pp.
5-.49.J.
H,~viland (1979), "Guugu Yimidhirr", in tfandbook of Au-tralian Languegce, R. Dixon and B. Blake, eds., Benjamius.
Amster-dam.F.C.N.
Pereira.
and D.H.D.
Warren (1983), "Parsing as Deduc-tion", Prec.
of the 2let Annlal Mecrinf o\[ the ACL, pp.
137-143,A.~ociation for ComputaJ:ional Linguistics.C.
Pollard (1984), Generalized Phrue Streeturc Grammara,\['lead Grammars, and Natural Language, unpublished thesis, Stan-ford Universiey.132
