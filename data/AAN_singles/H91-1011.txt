Model l ing Context Dependency in Acoust ic-Phonet ic  andLexical Representat ions 1Michael Phillips, James Glass, and Victor ZueSpoken Language Systems GroupLaboratory for Computer ScienceMassachusetts Institute of TechnologyCambridge, Massachusetts 02139ABSTRACTIn 1989, our group first reported on the development of SUM-MIT, a segment-based speaker-independent continuous-speech re-cognition system \[13\] .
The initial version of SUMMIT made useof fairly simple context-independent models for the lexical abels.Recently, we have begun to incorporate more complex models oflexical abels that take into account a variety of contextual fac-tors.
These changes, along with an improved corrective trainingprocedure for adapting pronunciation arc weights and a larger setof training data, have resulted in the reduction of error rate byalmost a factor of two on the Resource Management task.INTRODUCTIONVariability in speech arises from many different sources.For example, acoustic variability can be due to noise or chainnel characteristics, phonetic variability can be due to contex-tual or speaker-specific effects, and dialect effects can alterspeakers' pronunciations of words.
Speech recognition sys-tems must have mechanisms to model these various types ofvariability, and sometimes it may be necessary to deal withdifferent ypes of variability with different mechanisms.
Forexample, it may be difficult to find a single model that is ableto deal effectively with both low-level acoustic variability anddialect differences among speakers.find mechanisms that are able to account for many differenttypes of contextual factors.In this paper, we will describe a number of experiments in-tended to address ome of the problems mentioned above.
Sofar, we have attempted to account for some of the contextualeffects on our phonetic models, although the approach thatwe have taken should apply to the higher levels of the systemalso.
Briefly, we have found that we can increase recogni-tion performance by creating context-specific models or byusing more flexible models.
However, we did not see a per-formance increase when we combined the two in a straight-forward manner, presumably due to the fact that more flex-ible models tend to require more training data.
If, insteadof using context-specific models, we accounted for contextby adjusting the input to the phonetic models (creating acontext-normalized input vector), we were able to accountfor contextual effects and were able to use more flexible pho-netic models, resulting in the highest performance for oursystem.In the following sections, we will first provide an overviewof the system.
This will be followed by a more detailed de-scription of the changes we have made to the system, andevaluation results on the Resource Management task.In the SUMMIT system, we have made a rough distinc-tion between the sort of variability that we can deal withwithin our phonetic models (including acoustic variabilityand speaker differences at a phonetic level), and higher levelphonological variation (including dialect effects and word-boundary effects).
In both cases, our goal is to account foras much of the variability as possible, and it is clear thatat least some of the variability is due to contextual effects.Just as there are many types of variability, there are manytypes of contextual effects, including local phonetic effects(coarticulation), effects of stress, phrase-level ffects (such asprepausal lengthening), and higher level effects (such as sen-tential stress or dialect differences).
Therefore, we need to1This research was supported by DARPA under Contract N00014-89-J-1332, monitored through the Office of Naval Research.SYSTEM OVERVIEWComponent  Descr ip t ionA block diagram of the SUMMIT system is shown in Fig-ure 1.
The acoustic processing consists of a model of thehuman peripheral auditory system as a front-end, a hierarchi-cal segmentation algorithm to produce a network of possibleacoustic segments, an automatically defined set of segmentalmeasurements for each hypothesized segment, and finally, astatistical classifier for providing a probability of each labelgiven a segment.
The result of this analysis branch of thesystem is a network of possible phonetic interpretations ofthe speech signal.
Each arc in the network has a list of prob-abilities of the labels used to represent the lexicon \[13\].71Signal Lexicon Higher-LevelLinguisticKnowledgeSignalRepresentationI AcousticSegmentation1Extraction & Lexical LanguagePhoneme Expansion ModelingRecognitioni i ,J i II DecoderDecoded UtteranceFigure 1: The major components of the SUMMIT system.The lexicon is also represented as a network, which is de-rived by applying a set of transformation rules to a set ofbaseform pronunciations of the words in the lexicon.
Thesetransformation rules are defined by hand and are intendedto account for some known phonological effects such as flap-ping and gemination.
The pronunciation etworks for theindividual word~ are combined into a single network allowingall possible word strings.
Inter-word pronunciation rules andlocal granmaatical constraints are taken into account whenthe words are combined into this network.Finding the highest scoring word sequence is accomplishedby finding the best match between a path in the acoustic net-work and a path in the lexical network.
The initial version ofthe system used Viterbi search to find the single best match.More recently we have been using the A*, N-best search de-scribed in \[15\] and \[11\] to find a list of top scoring sentencehypotheses.Scoring StrategySince the overall score of a path consists of a number ofcomponents (acoustic model score, duration model score, seg-mentation score, and, in some cases, language model score),we must determine a way to combine them.
If these were sta-tistically independent probabilities of paths given the acous-tics, we could simply combine them by multiplication.
Un-fortunately, it is unlikely that the component scores are sta-tistically independent.
Besides, they are likely to be poorestimates of probabilities both because of lack of trainingdata and because the models used by these components alsomake mistaken assumptions about their probability distribu-tions and about the statistical independence of the segmentsmaking up the path.In addition, we have the problem in a segment-based sys-tem that different paths contain different acoustic segmentsand therefore have different observation spaces \[6\].
We can-not simply compare probabilities of word sequences givenacoustic observations since the probabilities are computedusing different observations.
Normalizing the probabilitiesby the length of the segments helps to some degree (since allpaths have the same duration), but then longer duration seg-ments have a greater influence on the path score than shortsegments.In the past, we have dealt with these problems by usinga weighted linear combination of estimates of the log prob-ability of component scores along with a segment-transitionpenalty and word-transition penalty as our overall path score.The component weights and transition penalties were ob-tained by optimizing performance on a portion of the trainingdata.Recently we have begun to use the N-best search men-tioned previously to obtain the top N scoring paths.
Withthe availability of these paths, we can then use the individ-ual component scores as input to a classifier which can betrained to discriminate between correct and incorrect paths.So far, we have been using a linear discriminate functionas this classifier, but more complex classifiers can clearly beused.
Treating this as a classification problem allows us tonot make assumptions about the meaning of the componentscores (other than the assumption that we would like themto help discriminate correct from incorrect paths).This new scoring strategy also permits us to apply, asa post-proccess, constraints that do not fit well into the ini-tial search strategy.
For example, we can make use of contextdependent models that can consider the global utterance con-text in addition to the local context.RECO GNIT ION EXPERIMENTSAll the experiments described in this paper are performedon the 1,000-word Resource Management (RM) task \[7\].
Inall cases, we have used the perplexity 60 word-pair languagemodel.
Except for the baseline system, we have used thenow standard 109-speaker t aining set.
To facilitate a mean-ingful comparison, all the experiments were conducted usingthe February 1989 speaker-independent test set consisting of300 utterances, 30 each from 10 different alkers.
The exper-iments that we conducted are summarized in Figure 2, andwill be described in this section.Lex ica l  Mode lsIn the initial version of SUMMIT reported in \[13\], eachlabel used in the pronunciation of words in the lexicon is rep-resented by a single diagonal Gaussian model.
This proce-dure is il lustrated by path (a) in Figure 2.
The input to thesemodels is a transformation f a set of segmental coustic mea-surements, which were determined automatically using an72(a)\[-(b) (?)
(d) (e)Figure 2: Illustration of the various experimental conditions.DG denotes a diagonal Gaussian classifiers, whereas CD Tree andCN Tree denote context-dependent a d context-normalized treeclassifiers, respectively, asdescribed in text.optimization procedure where the optimization criterion wasa measure of phonetic discrimination performance \[8\].
Thesemeasurements are based on an entire segment and thereforecan potentially take into account both the static and dynamicproperties of the segment and its surroundings.
The outputsof these measurements form a vector for each segment.
Thisvector is transformed by a combination of linear discriminantfunctions and principle components analysis to allow for bet-ter modelling by the diagonal Gaussian models.
The resultingvector has 52 dimensions.
This context-independent systemachieved a word error rate of 13.6% on the RM task, as shownin the first row of Table 1.
This baseline system was trainedon the then standard 72 speaker training set.
By increas-ing the training data to 109 speakers and using an improvedcorrective training procedure described in \[14\] for trainingthe pronunciation weights, We reduced the word error rate to12.9%.
This new context-independent result is shown in thesecond row, marked 109-TRAIN, of Table 1.The intention of using such simple models of the lexicallabels was to serve both as a baseline for experiments withmore complex models and to allow us to use a simple dis-tortion measure as a criterion for selecting a set of context-dependent models.
We have begun both sets of experimentsand have been exploring the trade-offs between adding flex-ibility to our models (which generally require more trainingdata per model) and making use of more specific context-dependent models (which generally allow us to use less train-ing data per model).Our initial attempts at using more complex models havefocused on the use of mixtures of diagonal Gaussians, sincethis is a natural extension of our baseline system, and mix-tures of Gaussians have been shown to be effective in othercontinuous-density speech-recognition systems \[3\].
This is il-lustrated by path (b) in Figure 2.
Our mixtures are seededwith a VQ codebook generated with standard hierarchicalprocedures.
A threshold is used to prune away mixtures withtoo few members.
When we replaced the single Gaussianmodel for each label in system 109-TRAIN (cf.
Table 1) by amixture Gaussian model with a maximum of 16 mixtures perclass,-the rror rate decreased from 12.9% to 10.3%.
The de-tailed results can be seen in the row marked CI-MIXTURES(context-independent mixtures) of Table 1.Thus far we have kept the transformation of the origi-nal acoustic input dimensions intact when using these moreflexible models.
There are some indications that this trans-formation may not be necessary, and in fact its eliminationmay lead to better performance.
In addition, we have beenexperimenting with the use of distinctive features as an in-termediate representation \[5\].
The use of distinctive featuresmay turn out to be a better representation in which to ac-count for factors such as context, speaker, and dialect effects.Context  Dependent  Mode lsMany researchers have found that the use of context-dependent models can lead to an increase in word recognitionperformance \[10,4\].
We have been concerned not only withcontext-dependent modelling but also with the more generalproblem of lexical representation.
The choice of lexical repre-sentation involves not only the choice of an inventory of units(such as context-independent or context-dependent models)but also the structure of the pronunciation etworks.
Manysystems currently make use of a rather complex set of units,but then rely on only a single pronunciation path for eachword in the lexicon.
Although context-dependent models canaccount for some of the variability due to context, alteringthe structure of the pronunciation etworks may be a morenatural way to account for phonological effects such as flap-ping and gemination, as well as certain types of inter-speakervariability due to dialect differences.
Since we are interestedin this more general problem of lexical representation, it hasbeen our goal to find a mechanism to automatically defineboth an inventory of lexical units and a set of pronunciationnetworks for a given lexicon.
We have been treating this asan optimization problem where the goal is to find a set oftransformation rules that, when applied to a set of baseformpronunciations, results in a \]exical network that optimizessome measure of recognizer performance.These transformation rules can alter both the labels onthe arcs in the network (resulting in context-dependent u its)and can also alter the structure of the networks (resulting innetworks of alternate pronunciations).
The rules are able totake into account a variety of contextual factors including lo-cal contexts (e.g., whether the left label is a stressed vowelor whether the right label is a / t / ) ,  as well as global contexts(e.g.
whether the segment is in the last syllable of the sen-73tence).
For the experiments reported in this paper, we havelimited the optin~ation to use only rules that alter the la-bels on the arcs in order to cc.mpare to performance increasesachieved by other researchers using only context-dependentmodelling.When applying only label-alteration rules, the optimiza-tion procedure that we use is basically a top-down tree grow-ing procedure similar to that used by other researchers \[1,2,9\].We start with all samples of a given class in the top node ofthe tree and then in each iteration, try splitting each leafnode in the tree with each of the available contextual factors(such as whether the left label is a stressed vowel), keepingthe split that maximizes the criterion over all leaf nodes ofthe tree.
We only allow splits that result in nodes with atleast some minimum number of samples in each node.
Theresulting leaf nodes define the set of context-dependent mod-els.
In our case, we would like to use a splitting criterionthat is related to the overall recognition performance (sincewe are trying to obtain the set of context-dependent labelsthat maximizes recognizer performance).
So far we have onlyexperimented with the total squared istance from the meanfor the resulting lexical models.Currently, we are using the following contextual functionsfor the splits in the context rees:LEFT-LABEL-IN-CATEGORY (class)RIGHT-LABEL-IN-CATEGORY (class)LEFT-WB ORIGHT-WB ()where class refers to one of a number of categories that wehave defined by hand.
So far, we have defined 64 categoriesfor the left and right labels.
These categories include classesbased on broad categories, stress, and distinctive features.Examples of categories include front-vowel, nasal, stressedvowel, etc.
The LEFT-WB () and RIGHT-WB () functions re-turn TRUE or FALSE depending on whether the segment inquestion is at a left or right word boundary.If we grow a tree using these contextual factors, using aminimum of 50 samples per leaf node as a stopping criterion,we are able to reduce the squared error in the resulting modelsby approximately 30%.
Using single diagonal Gaussian mod-els in each of the leaf nodes of the tree, we compute a context-dependent model score for each of the N-best paths obtainedfrom the context-independent recognition system.
This is il-lustrated by path (c) in Figure 2.
Since we are currently onlyusing local constraints in the context-dependent models, wecould have incorporated the models into the initial search.Applying the context-dependent models to the N-best pathssaves computation for the current experiments, but more im-portantly allows us to begin to incorporate more global con-straints without changing the experimental paradigm.
Usingthese models as another input to the discrimination classi-fier discussed above to reorder the N-best paths, we obtaina word error rate of 10.1%.
The detailed results are shownin Table 1 in the row marked CD-TREE.
In this experiment,we are using a total of 1,300 context-dependent models (thisnumber is obtained by counting the number of leaf nodes inall of the contextual trees).
The average number of leaf nodesper contextual tree is approximately 17.Context Normalized InputsWe have also experimented with accounting for contex-tual effects separately for each of the model's input dimen-sions.
That is, rather than growing a single contextual treefor each label, we grow a separate tree for each input dimen-sion.
This allows for a more detailed accounting for contex-tual effects, since different input dimensions are likely to beaffected differently by the context.
In addition, it also alle-viates the dimension scaling problem in the distance metricfor the distortion criterion.
When growing a single contex-tual tree for a label, our distortion measure must take intoaccount he distortion in all the dimensions at once, so thescaling of the input dimensions will affect the results.
Thisproblem disappears if we consider the distortion one dimen-sion at a time.
On the other hand, if context somehow affectsthe relationship among the input dimensions, we could per-haps take that into account in the single contextual tree butnot in the separate input dimension trees.Since diagonal Gaussian models treat each input dimen-sion separately, we can compute statistics for each dimensionbased on the contextual tree for that dimension.
This isillustrated by path (d) in Figure 2.
Using these scores asan additional component into the reordering of the N-bestpaths gives us a word error rate of 8.5%.
The detailed resultsare shown in the row marked CN-TREE (context-normalizedtree) of Table 1.
Since we have a different contextual tree foreach dimension, we can no longer come up with a meaningfulcount of the number of context dependent models.
However,if we count the leaf nodes of each contextual trees, we findwe are using an average 6.8 contexts per input dimension foreach class.Since we have found performance increases both by in-creasing the flexibility of the models (by using mixture Gaus-sian models) and by using more specific models (by havingseparate models depending on context), we wonder if evenbetter results can be obtained by combining both of theseprocedures.
Unfortunately, it turns not to be true due toconflicting requirements of the modelling procedures.
Moreflexible models tend to require a larger number of trainingsamples to obtain good performance, and using more specificmodels causes us to use a smaller portion of the training datafor each model.
For example, when we replaced single diag-onal Gaussian models with mixture Gaussian models in theleaf nodes of the CD-TREE experiment discussed above, wefound no increase in performance.
Even if we vary the stop-ping criterion of the tree splitting procedure (thus control-ling the number of training samples we allow for the mixture74Gaussian models) we were not able to obtain any significantincrease in performance.Rather than using the contextual trees to define more spe-cific models, we can use this contextual information to adjustthe input dimensions for the effects of the context.
This pro-cedure permits us to once again train the models using allof the available training data.
Specifically~ we grow separatecontextual trees for each input dimension as discussed above.Then~ rather than using the means and variances to train aGaussian model for each leaf node, we use only the differencebetween the mean of the leaf node and mean of the overallclass as an adjustment to the vector to account for the con-textual effects on samples falling into that leaf node.
This ofcourse assumes that we can treat the input dimensions epa-rately when accounting for context (because we are using sep-arate contextual trees for each dimension).
It also assumesthat contextual effects only cause a shift in the observed in-put dimensions (and no change in the shape of the distribu-tion of the input dimension).
Note that using single diagonalGaussian models on the resulting context-normalized inputvectors is equivalent to using single diagonal Gaussian modelsin the leaf nodes of the separate dimension contextual treeswith the variances tied across all of the leaf nodes for a giveninput dimension for a given label.Using context-normalized input dimensions (rather thancontext-specific models) allows us to use all of the trainingdata for the models for each class.
When we replace the singlediagonal Gaussian model with the mixture Gaussian models,illustrated by path (el in Figure 2, we obtained a word errorrate of 7%.
This represents he best that we have been able toachieve thus far, reducing the error rate of the baseline systemby nearly one-half..
The detailed scores for this experimentcan be seen in the row labeled CN-MIXTURES (context-normalized mixtures) in Table 1.System Correct Sub DelBaseline 87.6 10.3 2.1109-TRAIN 88.4 9.6 2.0CI-MIXTURES 91.2 7.4 1.4CD-TREE 90.9 7.7 1.4CN-TREE 92.6 6.4 1.0C'N-MIXTURES 93.7 5.3 0.7Ins Error Sent.
Error1.2 13.6 ~ 54.71.3 12.9 54.71.4 10.3 47.71.1 10.1 48.01.1 8.5 43.70.7 7.0 36.0Table 1: This table shows the results obtained for each of theexperiments described in the paper.
The columns indicate thepercentage ofwords correct, the percentage ofsubstitutions, dele-tion, and insertions, the percentage word error (Sub + Del + Ins),and the percentage of sentence rror.
The systems include: thebaseline system, the baseline system trained on the 109 speakertraining set, the context-independent mixture Gaussian system,the system using context-dependent trees, the system using con-text-normalization trees for each input dimension, and finallythe system using context-normalization trees along with mixtureGaussian models.BENCHMARK RESULTSIn connection with the Fourth DARPA Speech and Nat-ural Language workshop, we participated in the benchmarkevaluation of the SUMMIT system on the Resource Managen-emet task, using the February-91 test set released by NIST.The system used context-normalized input dimensions withmixture Gaussian models, and was trained on the standard109-speaker t aining set.
The results are shown in Table 2.Comparing the last row of Table 1 with Table 2, we see thatour system's performance is quite similar on the two differ-ent test sets.
We are encouraged by the results of our firstattempt at context-dependent modelling.
We expect hat ad-ditional performance gain can be realized when more complexmodels are introduced.System Correct,Sub,ON,Ins rror Sent ErrorCN-MIXTUI~ES 93.3 I I 16"0  .7 1.2 8.0 33.7Table 2: SUMMIT benchmark performance on the Resource Man-agement ask with a perplexity 60 language model, using theFebruary-91 test set released by NIST.
The system used con-text-normalization trees for each input dimension, with mixtureGaussian models.DISCUSSION & FUTURE PLANSWhile the experiments presented here only address localcontextual effects, it is important to note that the mechanismthat we have developed can account for both local contextuaeffects and more global contextual effects.
Furthermore, th(general approach we have taken not only allows us to accountfor contextual effects on the phonetic models, but also to al-ter the structure of the pronunciation networks to account forcontextual effects.
Admittedly, we have only experimentedwith context-dependent models in these recognition experi-ments.
Even within the limited scope of the current exper-iments, however, we have achieved substantial performanceimprovements over our baseline system.
In related work, wehave experimented with altering the structure of pronuncia-tion networks, resulting in substantial performance increaseson the task of recognizing a small set of isolated words overtelephone network.
We hope that when we extend the presentexperiments by altering the structure of the pronunciationnetworks and by considering more contextual effects, we willfind further performance increases on the Resource Manage-ment task as well.In the present work we have kept the form of the inputrepresentation fixed.
Since this particular transformation ofthe original acoustic dimensions was intended to allow us tomodel context-independent labels with rather simple diag-onal Caussian models, it may not be an appropriate inputrepresentation for the more flexible models discussed here.In particular, since we have so far found that we can achievethe best performance by using the context-normalized in-put dimensions (which assumes that the normalization can75be carried out for each input dimension independently), wewould now like to have input dimensions where context af-fects the dimensions independently.
It is unlikely that theset of dimensions resulting from our current principle com-ponents analysis is the best input for this type of normaliza-tion.
We are now beginning to experiment with applying thenormalization to the original input dimensions, which shouldbe more directly affected by contextual effects.We would also like to explore the use of distinctive fea-tures as the input representation since there is some evidencethat this might be a better representation for accounting forcontextual effects \[12\].
For example, in the environment ofa nasal, we could expect the nasality feature of a vowel tobe affected in a particular way whereas other features of thevowel would be affected by other contextual effects.Finally, if we account for context by making specific mod-els for particular contexts (e.g., triphones or the context-dependent tree discussed above), we are constrained to somedegree by the amount of training data we would have avail-able to train each of these more specific models.
This has ledus in the past to use fairly simple and easily trained para-metric distributions for these models.Accounting for context by normalizing the input dimen-sions reduces the need to split up the training data, and there-fore should lead to more flexible and robust models for thelabels in the lexicon.
We have thus far presented results usingmixture Gaussian models, but are now experimenting withother types of models and discriminators including multi-layer perceptrons and radial basis functions.REFERENCES\[1\] Breiman, J., R. Friedman, R. Olshen, and C. Stone, Classifi-cation and Regression Trees, Wadsword International Group,Belmont, CA, 1984.\[2\] Chen, F., and J. Shrager,"Automatic Discovery of Contex-tual Factors Describing Phonological Variation", Proc.
FirstDARPA Speech and Natural Language Workshop, p. 284-289, Philadelphia, PA, February 1989.\[3\] Lee, C., L. Rabiner, R. Pieraccini, and J. Wilpon, "AcousticModelling for Large Vocabulary Speech Recognition", Com-puter Speech and Language, Vol.
4, pp 127-165, April 1990.\[4\] Lee, K., Large Vocabulary Speaker Independent ContinuousSpeech Recognition: the Sphinx System, Doctoral Thesis,Carnegie Mellon University, Pittsburgh, PA, 1988.\[5\] Meng, H, V. Zue, and H. Leung,"Investigation of Signal Rep-resentation, Attribute Extraction, and the Use of Distinc-tive Features for Phonetic Classification," These proceedings,1991.\[6\] Ostendoff, M., and S. Roukos,"A Stochastic Segment Modelfor Phoneme-Based Continuous Speech Recognition," IEEEAcoustics, Speech, and Signal Processing, Vol.
37, pp 1857-1869, December 1989.\[7\] Pallett, D., "Benchmark Tests for DARPA ResourceManagement Database Performance Evaluations,"Proc.ICASSP-89, pp.536-539, Glasgow, Scotland, May 1989.\[8\] Phillips, M., "Automatic Discovery of Acoustic Measure-ments for Phonetic Classification," J. Acoustic.
Soc.
Am.,Vol.
84, $216, 1988.\[9\] Sagayama, S., and S. Honma,"Estimation f Unknown Con-text Using a Phoneme Environment Clustering Algorithm",Proc.
International Conference on Spoken Language Process-ing, pp 361-364, Kobe, Japan, 1990.\[10\] Schwartz, R., Y. Chow, O. Kimball, S. Roucos, M. Kras-ner, and J. Makhoul,"Context-dependent Modelling forAcoustic-Phonetic Recognition of Continuous Speech," Proc.ICASSP-85, pp 1205-1208, 1985.\[11\] Soong, F., and E. Huang, "A Tree-Tre\]_lis Based Fast Searchfor Finding the N-best Sentence Hypotheses in ContinuousSpeech Recognition," Proc.
Third DARPA Speech and Nat-ural Language Workshop, p. 12-19, Hidden Valley, PA June1990.\[12\] Stevens, K.~ "Phonetic Features and Lexical Access", Proc.The Second Symposium on Advanced Man-Machine InterfaceThrough Spoken Language, pp.
10.1 - 10.23, Makaha, HI,1988.\[13\] Zue, V., J.
Glass, M. Phillips, and S. Seneff, "The MIT SUM-MIT Speech Recognition System: A Progress Report," Proc.First DARPA Speech and Natural Language Workshop, p.179-189, Philadelphia, PA, February 1989.\[14\] Zue, V., J.
Glass, D. Goodine, M. Phillips, and S. Sen-eft, "The SUMMIT Speech Recognition System: Phonologi-cal Modelling and Lexical Access," Proc.
ICASSP-90, 49-52,Albuquerque, NM, 1990.\[15\] Zue, V., J.
Glass, D. Goodine, H. Leung, M. McCandless~ M.Phillips, J. Polifroni, and S. Seneff, "Recent Progress on theVOYAGER System," Proc.
Third DARPA Speech and Nat-ural Language Workshop, p. 206-211, Hidden Valley, PA,June 1990.76
