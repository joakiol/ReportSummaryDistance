Right  A t tachment  and  Pre ference  Semant ics .Yor i ck  Wi lksComput ing  Research  LaboratoryNew Mex ico  S ta te  Un ivers i tyLas  Cruces ,  1NM 88003,  USA.ABSTRACTThe paper claims that the right attachment rules for phrasesoriginally suggested by Frazier and Fodor are wrong, and that noneof the subsequent patchings of the rules by syntactic methods haveimproved the situation.
For each rule there are perfectly straightfor-ward and indefinitely large classes of simple counter-examples.
Wethen examine suggestions by Ford et M., Schubert and Hirst whichare quasi-semantic in nature and which we consider ingenious butunsatisfactory.
We point towards a straightforward solution withinthe framework of preference semantics, set out in detail elsewhere,and argue that the principal issue is not the type and nature of infor-mation required to get appropriate phrase attachments, but the issueof where to store the information and with what processes to applyit.SYNTACTIC  APPROACHESRecent discussion of the issue of how and where to attachright-hand phrases (and more generally, clauses) in sentence analysiswas started by the claims of Frasier and Fodor (1979).
They offeredtwo rules :(i) R ight  Associat ionwhich is that phrases on the right should be attached as low as possi-ble on a syntax tree, thusJOHN BOUGHT THE BOOK THAT I HAD BEEN TRYINGTO OBT t~/OR SUSAN)which attaches to OBTAIN not to BOUGHT.But this rule fails forJOHN BOUGHT THE BOOK (FOR SUSAN)which requires attachment to BOUGHT not BOOK.A second principle was then added :(ii) M in ima l  A t tachmentwhich is that a phrase must be attached higher in a tree if doing thatminimizes the number of nodes in the tree (and this rule is to takeprecedence over (i)).So, in :V/carriedas part ofVP// ' - .
b,.NP PP for Mary/.
&grocenes for MaryJOHN CARRIED THE GROCERIES  (FOR MARY)attaching FOR MARY to the top of the tree, rather than to the NP,will create a tree with one less node.
Shieber (1983) has an alterna-tive analysis of this phenomenon, based on a clear parsing model,which produces the same effect as rule (ii) by preferring longer reduc-tions in the paining table; i.e., in the present ease, preferring VP <-VNPPPto  NP <-  NP PP.But there axe still problems with (i) and (ii) taken together, asis seen in :SHE WANTED THE DRESS~ THAT RACK)rather than attaching (ON THAT RACK) to WANTED, as (ii) wouldcause .SEMANTIC  APPROACHES(i) Lexieal PreferenceAt this point Ford et al (1981) suggested the use of lexicalpreference, which is conventional case information associated withindividual verbs, so as to select for attachment PPs which matchthat case information.
This is semantic information in the broadsense in which that term has traditionally been used in AI.
Lexicalpreference allows rules (i) and (ii) above to be overridden if a verb'scoding expresses a strong preference for a certain structure.
Theeffect of that rule differs from system to system: within Shieber'sparsing model (1983) that rule means in effect that a verb likeWANT will prefer to have only a single NP to its right.
The parserthen performs the longest reduction it can with the strongest leftmoststack element.
So, if POSITION, say, prefers two entities to its right,Shieber will obtain :THE WOMAN WANTED THE DRESS~ THE RACK)andTHE WOMAN POSITIONED 'THE DRESS (ON THE RACK).89But this iterative patching with more rules does not work,because to every example, under every rule (i, ii and lexical prefer-ence), there are clear and simple counter-examples.
Thus, there is :JOE  TOOK THE BOOK THAT I BOUGHT (FOR SUSAN)which comes under (i) and there isJOE  BROUGHT THE BOOK THAT I LOVED (FOR SUSAN)which Shieber's parser must get wrong and not in a way that (ii)could rescue.
Under (ii) itself, there isJOE  LOST THE T I C ~ O  PARIS)which Shieber's conflict reduction rule must get wrong.
For Shieber'sversion of lexical preference there will be problems with :DAUGHTER)which the rules he gives for WANT must get wrong.
(ii) Schuber tSchubert (1984) presents ome of the above counter-examples inan attack on syntactically based methods.
He proposes a syntactico-semantic network system of what he calls preference trade-offs.
He isdriven to this, he says, because he rejects any system based whollyon lexically-based semantic preferences (which is part of what wehere will call preference semantics, ee below, and which would sub-sume the simpler versions of lexicM preference).
He does this on thegrounds that there are clear cases where "syntactic preferences pre-vail over much more coherent alternatives" (Schubert, 1984, p.248),where by "coherent"" he means interpretations imposed bysemantics/pragmatics.
His examples are :(where full lines show the "natural" pragmatic interpretations, anddotted ones the interpretations that Schubert says are imposed willy-nilly by the syntax).
Our informants disagree with Schubert : theyattach as the syntax suggests to LIVE, but still insist that the leaveis Mary's (i.e.
so interpreting the last clause that it contains anelided (WHILE) SHE WAS (ON....).
If that is so the example doesnot split off semantics from syntax in the way Schubert wants,because the issue is who is on leave and not when something wasdone.
In such circumstances the example presents no special prob-lems.JOHN M E T ~  HAIRED GIRL FROMMONTREAL  THAT HE MARRIED (AT A DANCE)iv- tHere our informants attach the phrase resolutely to MET as corn-monsense dictates (i.e.
they ignore or are able to discount the built-indistance effect of the very long NP).
A more difficult and interestingcase arises if the last phrase is (AT A WEDDING) ,  since the examplethen seems to fall withing the exclusion of an "attachment unless ityields zero information" rule deployed within preference semantics(Wilks, 1973), which is probably, in its turn, a close relative ofGrice's (1975) maxim concerned with information quantity.
In the(AT A WEDDING) case, informants continue to attach to MET,seemingly discounting both the syntactic indication and the informa-tion vacuity of MARRIED AT  A WEDDING.JOHN WAS NAMED (AFTER HIS TWIN SISTER)Here our informants aw genuine ambiguity and did not seemto mind much whether attachment or lexicalization of NAMEDAFTER was preferred.
Again, information vacuity tells against thesyntactic attachment ( he example is on the model of :HE  WAS NAMED AFTER HIS FATHERWilks 1973, which was used to make a closely related point),but normal gendering of names tells against the lexicalization of theverb to NAME+AFTER.Our conclusion from Schubert's examples is the reverse of hisown : these are not simple examples but very complex ones, involvingdistance and (in two cases) information quantity phenomena.
In noneof the cases do they support the straightforward primacy of syntaxthat his case against a generalized "lexical preference hypothesis"(i.e.
one without rules (i) and (ii) as default cases, as in Ford et al'slexicM preference) would require.
We shall therefore consider thathypothesis, under the name preference semantics, to be still underconsideration.
(Ul) H i~Hirst (1984) aims to produce a conflation of the approaches ofFord et al, described above, and a principle of Crain and Steedman(1984) called The Principle of Parsimony, which is to make anattachment that corresponds to leaving the minimum number ofpresuppositions unsatisfied.
The example usually given is that of a"garden path" sentence like :THE HORSE RACED PAST THE BARN FELLwhere the natural (initial) preference for the garden path interpreta-tion is to he explained by the fact that, on that interpretation, onlythe existence of an entity corresponding to THE HORSE is to bepresupposed, and that means less presuppositions to which nothing isthe memory structure corresponds than is needed to opt for theexistence of some THE HORSE RACED PAST THE BARN.
Onedifficulty here is what it is for something to exist in memory: Cralnand Steedman themselves note that readers do not garden path withsentences like :CARS RACED AT MONTE CARLO FETCH HIGH PRICESAS COLLECTOR'S ITEMSbut that is not because readers know of any particular cars raced atMonte Carlo.
Hirst accepts from (Winograd 1972) a general Principleof Referential Success (i.e.
to actual existent entities), hut the generalunsatisfactoriness of restricting a system to actual entities has longbeen known, for so much of our discourse is about possible and vir-tual ontologies (for a full discussion of this aspect of Winograd.
seeRitchie 1978).The strength of Hirst's approach is his attempt o reduce thepresuppositional metric of Craln and Steedman to criteria manipul-able by basic semantie/lexieal codings, and particularly the contrastof definite and indefinite articles.
But the general determination ofcategories like definite and indefinite is so shaky (and only indirectlyrelated to "the" and "a" in English), and cannot possibly bear theweight that he puts on it as the solid basis of a theory of phraseattachment.90So, Hirer invites counter-examples to his Principle of Referen-tial Success (1984, p.149) adapted from Wlnograd: "a non-generic NPpresupposes that the thing it describes exists.....an indefinite NPpresupposes only the plausibility of what it describes."
But this isjust not so in either case :THE PERPETUAL MOTION MACHINE IS THE BANE OFLIFE IN A PATENT OFF ICEA MAN I JUST MET LENT ME FIVE POUNDSThe machine is perfectly definite but the perpetual motion machinedoes not exist and is not presupposed by the speaker.
We concludethat these notions are not yet in a state to be the basis of a theory ofPP attachment.
Moreover, even though beliefs about the world mustplay a role in attachment in certain cases, there is, as yet, no reasonto believe that beliefs and presuppositions can provide the materialfor a basic attachment mechanism.
(iv) Preference SemanticsPreference Semantics has claimed that appropriate structuringscan be obtained using essentially semantic information, given also arule of preferring the most densely connected representations thatcan be constructed from such semantic information (Wilks 1975, Fass& Wilks 1983).Let us consider such a position initially expressed as semanticdictionary information attaching to the verb; this is essentially theposition of the systems discussed above, as well as of case grammar.and the semantics- based parsing systems (e.g.
Riesbeck 1975) thathave been based on it.
When discussing implementation i the lastsection we shall argue (as in Wilks 1976) that semantic material thatis to be the base of a parsing process cannot be thought of as simplyattaching to a verb (rather than to nouns and all other word senses)In what follows we shall assume case predicates in the diction?ary entries of verbs, nouns etc.
that express part of the meaning ofthe concept and determine its semantic relations.
We shall write as\[OBTAIN\] the abbreviation of the semantic dictionary entry forOBTAIN, and assume that the following concepts contain at leastthe case entries shown (as case predicates and the types of argumentfillers) :\ [OBTAIN I (recipient hum) recipient case, human.\[BUY\] (recipient hum) recipient case, human.\[POSITION\] (location *pla) location case, place.\[BRING\] (recipient human)recipient case, human.\[TICKET\] (direction *pla) direction case, place.\[WANT\] (object *physob) object case, physical object.
(recipient hum) recipient case, human.The issue here is whether these are plausible preferential meaningconstituents: e.g.
that to obtain something is to obtain it for a reci-pient;to position something is to do it in association with a place; a ticket(in this sense i.e.
"billet" rather than "ticket" in French) is a ticketto somewhere, and so on.
They do not entail restrictions, but onlypreferences.
Hence, "John brought his dog a bone" in no way violatesthe coding \[BRING\].
We shall refer to these case constituents withinsemantic representations a  semantic preferences of the correspondinghead concept.A F IRST  TRIAL  ATTACHMENT RULEThe examples discussed are correctly attached by the followingrule :Ru le  A : moving leftwards from the right hand end of a sentence,assign the attachment of an entity X (word or phrase) to the firstentity to the left of X that has a preference that X satisfies; thisentails that any entity X can only satisfy the preference of oneentity.
Assume also a push down stack for inserting such entities asX into until they satisfy some preference.
Assume also some distancelimit (to be empirically determined) and a DEFAULT rule such that,if any X satisfies no preferences, it is attached locally, i.e.
immedi-ately to its left.Rule A gets right all the classes of examples discussed (withone exception, see below): e.gJOHN BROUGH BOOK THAT I LOVED (FORM~Y)JOHN TOOK THE BOOK THAT I BOUGHT (F~R MARY)JoHN W T HE DR THE I(FORMARY)where the last requires use of the push-down stack.
The phenomenontreated here is assumed to be much more general than just phrases,as in:P~TF.
DE CANARD TRUFFI~ ,~ .
.
__ .~(i.e.
a truflled pate of duck, not a pate of truflled ducks!)
where weenvisage a preference (POSS STUFF)~--- i .e.
prefers to be predicatedof substances - as part of \[TRUFFE\[.
French gender is of no usehere, since all the concepts are masculine.This rule would of course have to be modified for many specialfactors, e.g.
pronouns, because of :\[ THE D R ~SHE W A N T O N  THE SHELF)A more substantial drawback to this substitution of a singlesemantics- based rule for all the earlier syntactic complexity is thatplacing the preferences essentially in the verbs (as did the systemsdiscussed earlier that used lexical preference) and having little morethan semantic type information on nouns (except in cases like\[TICKET\[ that also prefers associated cases) but, most importantly,having no semantic preferences associated with prepositions thatintroduce phrases, we shall only succeed with rule A by means of asemantic subterfuge for a large and simple class of cases, namely:JOHN LOVED HER (FOR HER BEAUTY)orJOHN SHOT THE GIRL (IN THE PARK)Given the "low default" component of rule A, these can onlybe correctly attached if there is a very general case component in theverbs, e.g.
some statement of location in all "active types" of verbs(to be described by the primitive type heads in their codings) likeSHOOT i.e.
(location *pla), which expresses the fact that acts of thistype are necessarily located.
(location *pla) is then the preferencethat (IN THE PARK) satisfies, thus preventing a low default.91Again, verbs like LOVE would need a (REASON ANY) com-ponent in their coding, expressing the notion that such states (asopposed to actions, both defined i~ terms of the main semantic primi-tives of verbs) are dependent on some reason, which could be any-thing.But the clearest defect of Rule A (and, by implication, of allthe verb- centered approaches discussed earlier in the paper) is thatverbs in fact confront not cases, but PPs fronted by ambiguousprepositions, and it is only by taking account of their preferencesthat a general solution can be found.PREPOSIT ION SEMANTICS:  PREPLATESIn fact rule A was intentionally naive: it was designed todemonstrate (as against Shubcrt's claims in particular) the wide cov-erage of the data of a single semantics-based rule, even if thatrequired additional, hard to motivate, semantic information to begiven for action and states.
It was stated in a verb-based lexicalpreference mode simply to achieve contrast with the other systemsdiscussed.For some years, it has been a principle of preference semantics(e.g.
WilLS 1973, 1975) that attachment relations of phrases, clausesetc.
are to be determined by comparing the preferences emanatingfrom all the entities involved in an attachment: they axe all, as itwere, to be considered as objects seeking other preferred classes ofneighbors, and the best lit, within and between each order of struc-tures built up, is to be found by comparing the preferences andfinding a best mutual fit.
This point was made in (Wilks 1976) bycontrasting preference semantics with the simple verb-based requestsof Riesbeck's (1975) MARGIE parser.
It was argued there thataccount had to be taken of both the preferences of verbs (and nouns),and of the preferences cued from the prepositions themselves.Those preferences were variously called paraplates (WilLS1975), preplates (Bognraev 1979) and they were, for each prepositionsense, an ordered set of predication preferences restricted by actionor noun type.
{WilLS 1975} contains examples of ordered paraplatestacks and their functioning, but in what follows we shall stick to thepreplate notation of (Huang 1984b).We have implemented in CASSEX (see WilLS, Huang and Fass,1985) a range of alternatives to Rule A : controlling both for "low"and "high" default; for examination of verb preferences first (or moregenerally those of any entity which is a candidate for the root of theattachment, as opposed to what is attached) and of what-is-attachedfirst (i.e.
prepositional phrases).
We can also control for the applica-tion of a more redundant form of rule where we attach preferably onthe conjunction of satisfactions of the preferences of the root and theattached (e.g.
for such a rule, satisfaction would require both that theverb preferred a prepositional phrase of such a class, and that theprepositional phrase preferred a verb of such a class}.In (Wilks, Huang & Fass 1985) we describe the algorithm thatbest fits the data and alternates between the use of semantic infor-mation attached to verbs and nouns (i.e.
the roots for attachments ain Rule A) and that of prepositions; it does this by seeking the bestmutual fit between them, and without any fall back to default syn-tactic rules like (i) and (ii).This strategy, implemented within Huang's (1984a, 1984b)CASSEX program, correctly parses all of the example sentences inthis paper.
CASSEX, which is written in Prolog on the Essex GEC-63, uses a definite clause grammar (DCG) to recognize syntactic on-stituents and Preference Semantics to provide their semanticinterpretation.
Its content is described in detail in (WilLS, Huang &Fass 1985) and it consists in allowing the preferences of both theclause verbs and the prepositions themselves tooperate on each otherand compete in a perspicuous and determinate manner, withoutrecourse to syntactic preferences or weightings.REFERENCESBoguraev, B.K.
(1979) "Automatic Resolution of Linguistic Ambigui-ties."
Technical Report No.ll, University of Cambridge Com-puter Laboratory, Cambridge.Crain, 8.
& Steedman, M. (1984) "On Not Being Led Up The GardenPath : The Use of Context by the Psychological Parser."
InD.R.
Dowty, L.J.
Karttunen & A.M. Zwicky (Eds.
), SyntacticTheory and How People Parse Sentences, CambridgeUniversity Press.Fass, D.C. & WilLs, YJk.
(1983) "Preference Semantics, lll-Formedness and Metaphor," Amer ican Journal of Compu-tational Linguistics, 9, pp.
178-187.Ford, M., Bresnan, J.
& Kaplan, R. (1981) "A Competence-BasedTheory of Syntactic Closure."
In J. Bresnan (Ed.
), The  Men-tal Representation of Grammat ica l  Relations, Cambridge,MA : M IT  Press.Frazier, L. & Fodor, J.
(1979) "The Sausage Machine: A New Two-Stage Parsing Model."
Cognition, 6, pp.191-325.Griee, H. P. (1975) "Logic & Conversation."
In P. Cole & J.
Morgan(Eds.
), Syntax and Semantics 3 ."
Speech Acts, AcademicPress, pp.
41-58.Hirst, G. (1983) "Semantic "Interpretation against Ambiguity.
"Technical Report CS-83-25, Dept.
of Computer Science, BrownUniversity.Hirst, G. (1984) "A Semantic Process for Syntactic Disambigua-tion."
Proc.
of A.AAIo84, Austin, Texas, pp.
148-152.Huang, X-M. (1984a) "The Generation of Chinese Sentences from theSemantic Representations of English Sentences."
Proc.
ofInternational Conference on Machine Translation,Cranfield, England.Huang, X-M. (1984b) "A  Computational Treatment of Gapping,Right Node Raising & Reduced Conjunction."
Proc.
ofCOL ING-84 ,  Stanford, CA., pp.
243-246.Riesbeck, C. (1975) "Conceptual Analysis."
In R. C. Schank (Ed.
),Conceptual Information Processing, .Amsterdam : NorthHolland.Ritchie, G. (1978) Computat ional  Grammar .
Hassocks : Harves-ter.Shieber, S.M.
(1983) "Sentence Disambiguatidn by a Shift-ReducedParsing Technique."
Proc.
of IJCAI-83, Kahlsruhe, W.  Ger-many, pp.
699-703.Shubert, L.K.
(1984) "On Parsing Preferences."
Proc.
ofCOL ING-84 ,  Stanford, CA., pp.
247-250.WilLs, y,A.
(1973) "Understanding without Proofs."
Proc.
ofIJCAI-73, Stanford, CA.WilLS, Y.A.
(1975) "A Preferential Pattern-Seeking Semantics forNatural Language Inference."
Artificial Intelligence, 6, pp.53-74.WilLS, Y.A.
(1976) "Processing Case."
American Journal  ofComputational Linguistics, 56.Winograd, T. (1972) Understanding Natural Language.
NewYork : Academic Press.92
