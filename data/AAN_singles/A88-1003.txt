An Architecture for Anaphora ResolutionElaine RichSusann LuperFoyMCC, Advanced Computer Architecture Program3500 West Balcones Center DriveAustin, TX 78759ABSTRACTIn this paper, we describe the pronominalanaphora resolution module of Lucy, a portableEnglish understanding system.
The design of thismo;clule was motivated by the observation that, al-though there exist many theories of anaphora resolu-tion, no one of these theories is complete.
Thus wehave implemented a blackboard-like architecture inwhich individual partial theories can be encoded asseparate modules that can interact to propose can-didate antecedents and to evaluate each other'sproposals.INTRODUCTIONThe Lucy system (Rich, 1987) is a prototypeof a portable English front end for knowledge-based systems.
The major components of Lucyare a syntax-based parser (Wittenburg, 1986), asemant=c translation system, a pronominalanaphora resolution system (which will bedescribed in this paper) and a pragmatic proces-sor.
The parser p..roduces as !ts output a featuregraph that descnoes the syntacticpropenies ovthe constituents of the sen(ence.
The semantictranslation system produces as its output a list ofdiscourse referents and a set of assertionsabout them.
The job of the anaphora resolutionsystem is to augment this assertion set with ad-ditional assertions that describe coreferencerelations between discourse referents.
Figure 1shows the results of semantic processing andanaphora resolution for the simple discourse,"Dave created a file.
He printed it.
"A D ISTR IBUTED ARCHITECTUREDesigning an anaphora resolution system isdifficult because there exists no single, coherenttheory upon which to build, even =f we restrictour attention to pronominal anaphora (which wewill do throughout this paper).
There do,however, exist many partial theories, 1 each ofwhich accounts for a subset of the phenomenathat influence the use and interpretation ofpronominal anaphora.
These partial theoriesrange from purely syntactic ones (for examplethe simple rules of number and genderagreement) to highly semantic and pragmaticones that account for focusing phenomena.
Ifthere were a single, complete theory, then itmight be appropriate to implement it.
If therewere no theories at all, then an ad hoc im-p lementation might be the only alternative.
But ecause there are partial theones but not a com-plete one, we have designed an architecture(patterned after the idea of a blackboard system(Erman, 1981)) that allows for a loosely coupledset of modules, each of which handles a subsetof discourse phenomena by implementing aspecific partial theory.
These modules com-municate by proposing candidate antecedentsand by evaluating each other's proposals.
Anoversight module, called the handler, mediatesthese communications and resolves conflictsamong the modules.All the modules in this system share a com-mon representation of the current discourse.This representation is called the core discoursestructure.
It includes a list of the discoursereferents that have so far been introduced.
As-sociated with each such referent is a set ofassertions, including syntactic facts about theuse of the referent (e.g., its number and genderand whether or not it is reflexive), semantic facts(such as the ones shown in Figure 1), andanaphoric usage facts such as coextension rela-tions.A schematic view of the architecture isshown in Figure 2.
Each of the ovals in thefigure represents an implementation of one ofthe partial theories of anaphora.
Each of theseimplementations is called a constraint source(CS), because each of them is viewed as impos-ing a set of consiraints on the choice of an an-tecedent for a pronominal referent.el: (create el) e2: (pdnt e2)(agent el xt ) (agent e2 x3)(object el x2) (object e2 x4)xl : (= xl Dave) x3:x2: (file x2) x4:(a) The Result of Semantic Processing1All existing theories are partial in the added sense ofbeing fallible.
That is, even when restricted to a narrowsubdomaln of the facts of anaphoric behavior, no accountfully explains coreference possibilities that arise in context.18x3: (coextensive x3 xl ) x4: (coextensive x4 x2)(b) Assertions Added by Anaphora ResolutionFigure 1: Processing "Dave created a file.
He printed it.
"CataphoraGlobalFocusNumberAgreementSemantic -"ConsistencyAnimacy Disioint ReferenceFigure 2: The Architecture of Anaphora ResolutionTHE STRUCTURE OF A CONSTRAINTSOURCEEach constraint source in this system iscomposed of a set of four f.unctions (althoughany ot these functions may be a no-op in anyparticular CS).
These component functions arecalled at different times during the process ofanaphor resolution, but they form a logical unitsince they share knowledge structures that cor-respond to the particular partial theory that isimplemented by the CS to which they belong.The four functions are the following:?
Modeller - This function maintains the CS'slocal model of the ongoing discourse.
Not allCS's need such a model.
Simple syntacticones like number agreement typically do notbuild a local model since all the informationthey need is available in the core discoursestructure and in the anaphoric referent beingresolved.
But CS's that describe more globalphenomena, such as rhetorical structure mayneed access to informat on that is neither lo-cal to a particular referent nor contained in thecore discourse structure.
If a local model isbuilt, it is built to rest top core on of the shareddiscourse structure.
Thecontent of the localmodel is accessible to the other functions ofthe same CS but not to anyone else.?
Constraint poster - This function posts con-straints that describe interactions amonganaphora within a sentence.
.These con-stra~nts are then treated in exactly the sameway as are semantic assertions about thereferents.
The algorithm for resolvinganaphora (which will be described below) ap-I~lies to a single anaphoric referent at a time.But, in some sentences, there are interactionsamong referents that make it impossible totreat them completely separately.
By postinginteraction constraints before processing in-dividual anaphoric referents, we maintain theability to treat the referents separately butalso to guarantee that the complete inter-pretation for the sentence in which they occurwill be consistent.
As an example of this~ henomenon, consider the sentence, "He saw im."
Disjoint reference could post a con-straint that he and him cannot co-refer beforeany attempt is made to find the antecedent foreither of them.
Most simple constraintsources do nothing when their constraintposters are called.?
Proposer - This function takes as input ananaphoric referent and returns as its output alist of candidate antecedents, each with anassociated score (which will be describedlater).
For example, recency proposes allreferents in the two most recent previous sen-tences, as well as any in the current sentencethat occur to the left of the referent that isbeing resolved.
Some CS's, such as numberagreement, never propose candidates.?
Evaluator - This function takes as input ananaphor and a candidate antecedent for thatanaphor.
The evaluator returns a score in-dicating strength of support for that candidateas antecedent to the anaphor.
The returnedscore is based solely on the information avail-able to the CS that ~s doing the evaluation.
Itis left to the handler, which invokes thevarious CS's, to combine scores from differentevaluators and to resolve conflicts.
Althoughevery CS must be able to respond wheneverits evaluator is called, there is a score that willbe interpreted to mean, "1 have no opinion.
"(See below.
)THE ANAPHORA RESOLUTIONPROCEDUREIn the current implementation of Lucy,anaphora resolution occurs once semantic inter-19pretation is complete.
2 The procedureresolve-anaphors does the following for eachsentence that is to be understood:1.
Update the core discourse structure withthe results of syntactic and semanticprocessing of the current sentence.2.
For each CS in the system, invoke themodeller and the constraint poster.3.
For each anaphor in the sentence do:a. Invoke the anaphora resolution hand-ler, which wi l l  in turn invoke thePrrOposers and evaluators for all CS's.he output of the handler is a list ofordered pairings of possible antece-dents with their overall scores.b.
Invoke select-best-antecedent, whichwill decide whether there is enoughevidence to make a coextensionassertion and, if so, will add the asser-tion to the core discourse structureand to both anaphor and antecedentreferents.The anaphora resolution handler takes twoinputs: an ordered list of available CS's and theanaphoric referent that needs to be resolved.The handler exploits a local data structure calledCANDIDATES, which is reinitialized for eachanaphoric referent that is processed and whichcontains a list of all the antecedents that havebeen proposed for that referent.
This makes itpossible to avoid considering any given can-didate more than once, no matter how often it isproposed.
The handler proceeds as follows:1.
For each CS(i) do:a. Invoke CS(i)'s proposer, which willreturn a list (possibly empty) of can-didate antecedents, each with an as-sociated initial score.b.
For each candidate C that is not al-ready on CANDIDATES do:i.
Add C to CANDIDATES.ii.
While running score of C isabove threshold, for each CS(j)where j ~ i do:1.
Pass C to the evaluator toget a score.2.
Update running score for C.Although these algorithms do not care, insome sense, what list of constraint sources theyare given, their success depends on having aset of constraint sources thatcover the range ofphenomena that occur in the discourse thatmust be processed.
Also, the efficiency withwhich they reach a conclusion depends on theorder in which the CS's are invoked.
In Lucy,the recency constraint source is invoked first.The correct antecedent is almost always amongthe candidates recency proposes since itproposes liberally.
To aidefficiency, the recencyCS is followed immediately by the simple syn-2In future releases, a more flexible control structure willbe exploited.tactic filtering CS's (number, gender andanimacy agreement) wh=ch, with little effort andhigh certainty, are able to eliminate most can-didates from the list that must be evaluated bymore complex CS's.The select-best-antecedent procedure ap-plies to the final list of candidate antecedents.
Itmust decide whether there is sufficient infor-mation on which to base a coreference asser-tion.
If there is exactly one candidate with thehighest rating and if the difference between thatratingand the second highest rating exceeds thethreshold 5 (a system parameter currently set at0.5), then a coreference assertion can bemade.
3 If one candidate is not cleady best,however, two actions are possible.
One ~s to donothing (i.e., post no coreference constraint) andthus essentially to produce a partial interpreta-tion of the input sentence.
This may be accept-able, depending on the use to which thesentence's interpretation is to be put.
For ex-ample, it may be possible to wait until sub-sequent sentences are processed to see if theyyield the disambiguating information.
If waiting~s unacceptable, however, the other availableaction is to query the user who input the sen-tence.
This option is available since Lucy isbeing designed to serve as an interactiveEnghsh front end system; if this same approachwere to be used during text comprehension,some alternative, such as choose a candidateand be prepared to back up if necessary, wouldbe requ=red instead.THE CANDIDATE SCORINGPROCEDUREAs we just saw, the final selection of an an-tecedent from among the set of candidatereferents depends on the combined score that isattached to each candidate as a result of theexamination of the candidate by the entire set ofconstraint sources.
Thus the design of the scor-ing procedure has an important effect on theoutcome of the resolution process.
Our first im-plementation of this procedure exploited a singlescore, a number in the range -5 to +5.
Each CSgave each candidate a score and the handleraveraged the individual scores to form a com-posite score.
The major drawback of this simplescheme is that there is no way for a CS to say, "1have no opinion," since any score it gives neces-sarily changes the composite score.
There isalso no way to say, "1 have an opinion and hereit is, (and I'm very)/(but rm not at all) confidentof it."
As a result, the system was highly un-stable.
It could be tuned to perform fa=rly well,3In the current implementation, the value of 8 does notmatter very much, since the available CS's provide only veryweak preferences or absolute filtering.
Future CS's willexploit more domain knowledge to provide more accuratepreferences.2,0but whenever a new CS was added or if a CSwas changed even slightly, the whole systemhad to be retuned.To remedy these problems, we now use ascoring procedure in which each CS providesboth a score and a confidence measure.
Thescore is a number in the range -5 to +5, theconfidence a number in the range 0 to 1.
Thefunction that combines a set of n(score, confidence) pairs isIt~, score(Oxconfidence(Oi=1 running score =IIconfidence(t)i=1This function computes an average that isweighted not by the number of distinct scoresbut by the total confidence expressed for thescores.
Any CS that wishes to assert no opinioncan now do so by giving a confidence of 0 to itsopinion, which wi l l  then have no effect on acandidate's running score.Although, in principle, a constraint sourcemay function both as a proposer and as anevaluator and it may assign any(score, confidence) value it likes to a candidate,it turns out that the CS's that have been imple-mented so far are much more limited in theirbehavior.
Most CS's either propose or evaluate,but not both.
And there are patterns of(score, confidence) values that appear to be par-ticularly useful.
Each CS that has been imple-mented so far falls into one of the following fourclasses:?
Finite set generators (such as disjoint refer-ence when applied to a reflexive pronoun) areconstraint sources that propose a fixed set ofcandidates.
They assign all such candidatesthe same score and that score is a function ofthe number of competing candidates:# of candidates (score, confidence) contributionto propose of this CS1 (5.1) =52 (4, 1) =43 (3, 1) =3These CS's never evaluate (i.e., when askedto do so, they return a confidence of 0.)?
Fading infinite set generators (such asrecency) are constraint sources that couldkeep proposing, perhaps indefinitely, but withlower and lower scores.
Recency, for ex-ample, uses the following scoring:Sentence (score, confidence) contributionof this CSn (current) (1, 0.5) = 2n-1 (2, 0.5) = 1n-2 (0, 0.5) = 0These CS's never evaluate.?
Filters (such as number and genderagreement) are constraint sources that neverpropose candidates.
They serve only to filterout candidates that fail to meet specific re-fqu i rements  (usually syntactic).
Filters use the otlowing two assignme ts when theyevaluate candidates:(score, confidence) contributionof this CSpass (0 4, 0) = 0fail (-5, 0.9) = -5These scores have the following effects:?
pass - Since the confidence level is 0, thescore does not matter and no change willbe made to the composite score as a resultof the evaluator being called.
Thus acandidate's score is insensitive to the num-ber of filter CS's that it passes.?
fail - The low score with high confidenceforces the composite score to drop belowthe minimum threshold eliminating this can-didate from future consideration.?
Preferences (such as semantic contentconsistency) are constraint sources that im-pose preferences, rather than absoluteopinions, on a set of candidates rat ingeachmember relative to others in the set.
Theseconstraint sources may use the full range of(score, confidence) values.Although the scoring scheme we have justdescribed exploits more knowledge about aCS's opinion than did our first, simpler one, it isnot perfect.
It can suffer from the usualproblems that arise when numbers are used torepresent uncertainty.
Future implementationsof this system may move more in the direction otsymbolic justifications (as used, for example, in(Cohen, 1985)) if they appear to be necessary.CONSTRAINT SOURCE EXAMPLESIn this section, we describe the constraintsources that have been implemented in Lucy aswell as some (preceded by an asterisk) that areenvisioned but not yet implemented.Recency, whose function is to proposereferents that have occurred in the recentlypreceding discourse.
Recency has no opinion tooffer on anyone else's proposals.Number Agreement, which knows that sin-gular pronouns must refer to singular things andplural pronouns must refer to plural things.Number Agreement does not propose antece-dents; instead it serves only as a filter on can-didates that are proposed by other CS's.Gender Agreement, which knows that anypronoun that is marked for gender can refer onlyto something of the same gender as itself.Gender serves only as a filter =n the current im-plementation.Animaoy, which knows that neuter pronounsrefer to inanimate things, while masculine and4When the confidence rating is 0, the score is arbitrarygiven the equation for running score values.21feminine pronouns must refer to animate things,usually people.
Animacy functions only as a fil-ter.Disjoint Reference, which knows aboutstructure-based coreference restrictions thatapply to reflexive and to nonreflexive pronouns(as described in theories such as (Reinhart,1983)).
Disjoint Reference proposes antece-dents for reflexive pronouns (as, for example, ina sentence like, "John saw himself.")
For non-reflexive pronouns, it serves as a filter, eliminat-ing, for example, John as the antecedent of himin the sentence, "John saw him.
"Semantic Type Consistency, which func-tions as a filter and constrains antecedents toonly those referents that satisfy the type con-straints imposed by the semantic interpretationof the rest of the sentence.
For example, con-sider the discourse, "The system created an er-ror log.
It printed it."
Assume that the semanticinterpretation of print imposes the following typeconstraints on its arguments:agent: human v computerobject : information-structureThen this CS will reject an error log as the an-tecedent of the first occurrence of it, assumingthat the type hierarchy does not include log as asubclass of either human or computer.
Further,this CS will reject the system as the antecedentof the second occurrence of it, assuming that thetype hierarchy does not include system as asubclass of information-structure.Global Focus, which knows about objectsthat are globally salient throughout a discourse.In the current implementation, global Focus actsonly when the anaphor being considered is it.
Inthat case, it proposes as antecedents allreferents that are in global focus.
(Empiricalevidence in support of this strategy is presentedin (Guindon, 1986).)
In the current implemen-tation, the target system to which the Englishfront end is attached is assumed always to be inglobal focus.Cataphora, which knows about a class ofsyntactic constructions in which a pronoun canpreceed the full lexical NP with which it corefers.This CS will propose John as a candidate an-tecedent for he in the sentence When he ishappy, John sings.
Cataphora acts as a gener-ator and will never reject the proposal of anotherCS.
*Logical accessibility, which knows aboutthe constraints that are imposed on the acces-sibility of referents as a function of their embed-ding within logical structures such as quantifiersand negation (Kamp, 1981).
Logical accessibiltyfunctions only as a filter.
It rules out, for ex-ample, a donkey as the antecedent for it in thesentence, "If a farmer doesn't own a donkey, hebeats it," unless a donkey is interpreted ashaving wide scope over the sentence (i.e., "Ifthere is a donkey such that the farmer doesn'town it then he beats it.
")*Semantic content consistency, which ex-ploits semantic knowledge about context de-pendent phenomena as opposed to simply ap-plying static type constraints.
The boundary be-tween this CS and semantic type consistency isclearly fuzzy in general and depends in any par-ticular case on the structure of the type hierar-chy that is being used.
The key difference be-tween the CS's, though, is that accessing a typehierarchy is fast, whereas there are cases inwhich th~s CS will have to do arbitrary reasoning.
*Local Focus, which tracks objects that arelocally in focus in the discourse.
This is thephenomenon that is addressed by theories suchas focus spaces (Grosz, 1977) and centering(Grosz, 1986, Brennan, 1987).
*Rhetorical Structure, which segments andorganizes the discourse as a set of plans forfulfilling conversational goals.
This is thephenomenon that is addressed by theories suchas (Hobbs, 1985).
*Set generation, which creates set-levelreferents that can serve as antecedents forplural pronouns.
For example, this CS couldpropose Mary and Sue as the antedecent forthey in the discourse, "Mary picked up Sue.They went to the movies.
"*Generic They, which knows about salientindividuals and groups, and proposes them asantecedents for occurrences of the pronoun theyin sentences such as, "Why don't they ever fixthe roads?
"This list is intended to provide an example ofthe range of phenomena that can be combinedus!ng .the.architecture we have .described..
It isnot m~enaed to oe a aefinidve ~is\[ oT constraintsources.
In fact, the architecture allows for morethan one implementation (i.e., CS) of a giventheory or more than one theory (and associatedimplementations) of a given phenomenon.
Thisredundancy can be useful, for example, as wayof comparing the effectiveness of competingconstraint sources within a complete anaphoraresolution system.DEBUGGING WITHINARCHITECTURENOW that the above architecture has beenimplemented, further development of the systemconsists primarily of additions to the set oT con-straint sources and adjustments to score andconfidence assignments.
During a test run thedeveloper needs to know which referents arebeing recognized as anaphors, which CS's getconsulted and in what order and, most impor-tantly, what effect each CS has on the overallrating received by each proposed antecedent.Our tracing tools will display this information foreach anaphor processed by the handler in thefollowing form.
First the name of each proposeras it is called and the list of candidates andratings it returns are displayed in the tracing win-dow.
Then for each of these candidates in turn,the name of every evaluator appears as it is2,2,SAMPLE DISCOURSE:Sen:ence  z : Jon created a fi le for  h imse l f .U-I  xl  el x2 x3TRA CE OUTPUT:InvokJ'ng anaphor handler wi~ anaphor: #<X-6>Invoking proposer  for RECENCYPossible antecedents proposed:(X-3:1) (X-2:1) (E-1:1)cx-,(Xl (u-1 :1)Composite ratings for candidate X-3After polling evaluator of TYPE rating is 1.0After polling evaluator of IDENTITY ralmg is 1.0After polling evaluator of GLOBAL-FOCUS rating is 1.0After polling evaluator of ANIMACY rating is -2.857143CompositeAfter potlingAfter pollingAfter pollingAfter pollingAfter pollingAfter pollingAfter polling.After pollingratinga for candidate X-2evaluator of TYPE rating is 1.0evaluator of IDENTITY rating is 1,0evaluator of GLOBAL-FOCUS rating is 1.0evaluator of ANIMACY rating is 1.0evaluator of DISJOINT-REFERENCE radng is 1.0evaiuator of GENDER rating is 1.0evaluator of NUMBER rating is 1.0evaluator of CATAPHORA ra~ng is 1.0Composite ratings for candidate E-1After polling evaluator of TYPE rating is -2.857143Invoking proposer  for GENDERPossible antecedents proposed: noneInvoking proposer  for NUMBERPossible antecedents proposed: noneInvoking proposer  for CATAPHORAPossible antecedents proposed: noneFinal candidate ratings:X-3 -2.857143X-2 1.0E-1 -2.857143X-1 -2.8571 43U-1 -2.857143E-5 -2.5X-4 -2.5X-9 -2.5Sentence 2: He sent it to Carl and Dave.U-2 x4 e5 x6  x7 x8I Ix9ANNOTATIONS:begin reso lv ing  anaphor  "it"l ist o f  cand idates  and their  init ial scoresevaluate f i rst  candidate, "himself"animate cand idate  cannot corefer with "it"next candidate to be evaluated is "f i le"no CS eva luator  wants  to reject or suppor~this candidate"fi le" surv ives  with orignal score of  !
.0next candidate  is the event "create"event re ferent  f i l tered out due to type mismatch(Recency's remain ing  candidates get f i l te red)begin ca l l ing  other  p roposers  and evaluate anynew re ferents  they introduce as cand idatesf i l ter ing CS's have noth ing  Co pIoposeCataphora and Dis jo int  Reference propose noth ingnew for this anaphor  in this discourseunordered l ist  o f  all candidates ever proposedall candidates  except "f i le" have been re jec tedmin imum score thresho ld  current ly  set at -2.50d i f ference between "f i le" x-2 and f irst runner -up(4.5) exceeds  delta current ly  set at 0.5Figure 3: Tracing the Anaphora Resolution ProcessZ3called followed by the effect of that evaluator'sresponse on the running score for the candidatereferent.
At the end of processing for eachanaphor the list of all candidates ever proposedand their composite ratings is displayed.
Figure3 shows an example of the use of the tracingtools.CONCLUSIONIn this paper, we have described an architec-ture for pronominal anaphora resolution that al-lows implementations of partial theories ofanaphora to be combined into a complete sys-tem, and we have illustrated an implementabonof such a system.
This architecture makes nocommitment on the question of what theoriesshould be used or how conflicts among thetheories should be resolved.
In this respect, itdiffers from other proposals (such as (Hobbs,1978)) in which a specific strategy for applyingknowledge is encoded into the control structureof the system.
As a result of its loose structure,this architecture supports the empirical inves-tigation of the effectiveness of  competingtheories and their implementations within a com-plete anaphora resolution system.One interesting comment that can be madeabout this architecture is its similarity to architec-tures that have been used to perform other partsof the natural language understanding task.
Forexample, TEAM (-Grosz, 1987) uses a similar ar-chitecture and a set of critics to .perform.quan-drier scope assignment.
The criucs Tuncfion inmuch the same way CS's do.
And, like CS's,there are classes of critics.
For example, someare pure filters.
Others impose preferences onthe set of candidate interpretations.ACKNOWLEDG EMENTSWe would like to thank Nicholas Asher, KentWittenburg, Dave Wroblewski, Jim Barnett, JonSchlossberg, and Carl Weir for many discus-sions about this architecture.
We wouldalso liketo thank Carl Weir for his contribution to the im-plementation of this system.REFERENCESBrennan, S. E., M. W. Friedman, & C. J.
Pollard.(1987).
A Centering Approach to Pronouns.Proceedings ACL.
.Cohen, R. R. (1985).
Heuristic Reasoning aboutUncertainty: An Artificia/ IntelligenceApproach.
Boston: Pitman AdvancedPublishing Program.Erman, L. D., P. E. London, & S. F.
Fickas.(1981).
The Design and an Example Use ofHearsay II1.
Proc.
IJCAI 7 .
.Grosz, B. J.
(1977).
The Representation andUse of Focus in a System for UnderstandingDialogs.
IJCAI 5 .
.Grosz, B. J., A. K. Joshi, & S.
Weinstein.(1986).
Towards a Computational Theory ofDiscourse Interpretation.Grosz, B. J., D. E. Appelt, P. A. Martin, &F. C. N. Pereira.
(May 1987).
TEAM: AnExperiment in the Design of TransportableNatural-Language Interfaces.
ArtificialIntelligence, 32(2), 173-243.Guindon, R., P. Sladky, H. Brunner & J.
Conner.(1986).
The Structure of User-AdvisorDialogues: Is there Method in their Mad-ness?
Proceedings of the 24th Meeting ofthe Association for ComputationalLinguistics..Hobbs,J.
R. (1978).
Resolving PronounReferences.
Lingua, 44, 311-338.Hobbs, J. R. (1985).
On the Coherence andStructure of Discourse (Tech.
Rep.).CSLI-85-37,Kamp, H. (1981).
A Theory of Truth andSemantic Representation.
In J. Froenendijk,T.
Janssen, & M. Stokhof (Eds.
), FormalMethods in the Study of Language, Part I.Amsterdam, The Netherlands: MathematischCentrum.Reinhart, T. (1983).
Anaphora and SemanticInterpretation.
Chicago, Ill.: University ofChicago Press.Rich, E. A., J. Barnett, K. Wittenburg &D. Wroblewski.
(1987).
Ambiguity Procras-tination.
Proceedings AAA187.
.Wittenburg, K. (1986).
A Parser for Portable NLInterfaces Using Graph-Unification-BasedGrammars.
Proceedings AAA186.
.2,4
