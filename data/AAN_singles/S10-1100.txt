Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 448?451,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsHITSZ_CITYU: Combine Collocation, Context Words and Neighbor-ing Sentence Sentiment in Sentiment Adjectives DisambiguationRuifeng Xu1,2, Jun Xu11Harbin Institute of Technology,Shenzhen Campus, Chinaxuruifeng@hitsz.edu.cnhit.xujun@gmail.comChunyu Kit22City University of Hong Kong,Hong Kongctckit@cityu.edu.hkAbstractThis paper presents the HIT_CITYU systemsin Semeval-2 Task 18, namely, disambiguat-ing sentiment ambiguous adjectives.
The base-line system (HITSZ_CITYU_3) incorporatesbi-gram and n-gram collocations of sentimentadjectives, and other context words as featuresin a one-class Support Vector Machine (SVM)classifier.
To enhance the baseline system, col-location set expansion and characteristicslearning based on word similarity and semi-supervised learning are investigated, respec-tively.
The final system (HITSZ_CITYU_1/2)combines collocations, context words andneighboring sentence sentiment in a two-classSVM classifier to determine the polarity ofsentiment adjectives.
The final systemsachieved 0.957 and 0.953 (ranked 1st and 2nd)macro accuracy, and 0.936 and 0.933 (ranked2nd and 3rd) micro accuracy, respectively.1 IntroductionSentiment analysis is always puzzled by the con-text-dependent sentiment words that one wordbrings positive, neutral or negative meanings indifferent contexts.
Hatzivassiloglou andMckeown (1997) predicated the polarity of ad-jectives by using the pairs of adjectives linked byconsecutive or negation conjunctions.
Turneyand Littman (2003) determined the polarity ofsentiment words by estimating the point-wisemutual information between sentiment wordsand a set of seed words with strong polarity.
An-dreevskaia and Bergler (2006) used a SentimentTag Extraction Program to extract sentiment-bearing adjectives from WordNet.
Esuli and Se-basian (2006) studied the context-dependent sen-timent words in WordNet but ignored the in-stances in real context.
Wu et al (2008) appliedcollocation plus a SVM classifier in Chinese sen-timent adjectives disambiguation.
Xu et al (2008)proposed a semi-supervised learning algorithm tolearn new sentiment word and their context-dependent characteristics.Semeval-2 Task 18 is designed to provide acommon framework and dataset for evaluatingthe disambiguation techniques for Chinese sen-timent adjectives.
The HITSZ_CITYU groupsubmitted three runs corresponding to one base-line system and one improved systems (two runs).The baseline system (HITSZ_CITYU_3) isbased on collocations between sentiment wordsand their targets as well as their context words.For the ambiguous adjectives, 412 positive and191 negative collocations are built from a 100-million-word corpus as the seed collocation set.Using the context words of seed collocations asfeatures, a one-class SVM classifier is trained inthe baseline system.
Using HowNet-based wordsimilarity as clue, the seed collocations are ex-panded to improve the coverage of collocation-based technique.
Furthermore, a semi-supervisedlearning algorithm is developed to learn new col-locations between sentiment words and their tar-gets from raw corpus.
Finally, the inner sentencefeatures, such as collocations and context words,and the inter sentence features, i.e.
neighboringsentence sentiments, are incorporated to deter-mine the polarity of ambiguous adjectives.
Theimproved systems (HITSZ_CITYU_1/2)achieved 0.957 and 0.953 macro accuracy(ranked 1st and 2nd) and 0.936 and 0.933 microaccuracy (ranked 2nd and 3rd), respectively.
Thisresult shows that collocation, context-words andneighboring sentence sentiment are effective insentiment adjectives disambiguation.The rest of this paper is organized as follows.Section 2 presents the collocation extraction sub-system based on lexical statistics.
Section 3448presents the baseline system and Section 4presents the improved systems.
The experimentresults are given in Section 5 and finally, Section6 concludes.2 Collocation ExtractionA lexical statistics-based collocation extractionsubsystem is developed to identify both the bi-gram and n-gram collocations of sentiment ad-jectives.
This subsystem is based on our previousresearch on Chinese collocation extraction.
Itrecognizes the co-occurring words of a headwordas collocations which have co-occurrence fre-quency significance among all co-occurringwords and co-occurrence position significanceamong all co-occurring positions.For a sentiment adjective, noted as whead, anyword within the [-5,+5] context window is a co-word, denoted as wco-i for 1?
i ?
k, where k is thetotal number of different co-words of whead.BI-Strength(whead,wco-i) between a head wordwhead and a co-word w co-i (i=1, to k) is designedto measure the co-occurrence frequency signifi-cance as follows:)()()()(5.0)()()()(5.0),(minmaxminmax icoicoicoicoheadheadheadheadicoheadicoheadwfwfwfwwfwfwfwfwwfwwStrengthBI?????????+???=?
(1)where, fmax(whead) , fmin(whead) and )( headwf are thehighest, lowest and average co-occurrence fre-quencies among all the co-words of whead,, re-spectively; fmax(wco-i), fmin(wcoi) and )( icowf ?
arerespectively the highest, lowest and average co-occurrence frequencies of the co-words for wco-i.The value of BI-Strength(whead wco-j) ranges from-1 to 1, and a larger value means a stronger asso-ciation.
Suppose f(whead,wco-i, m) is the frequencythat wco-i co-occurs with whead at position m(?5<=m<=5).
The BI-Spread(whead,wco-i) is de-signed to characterizes the significance that wco-iaround whead at neighbouring places as follows:),,(|),(),,(|),(5555???=??=???
?=?micoheadmicoheadicoheadicoheadmwwfwwfmwwfwwSpreadBI(2)where, ),( icohead wwf ?
, fmax(whead,,wco-i), and fmin(whea,,dwco-i) are the average, highest, and lowestco-occurrence frequencies among all 10 posi-tions, respectively.
The value of BI-Spread(whead,wco-i) ranges from 0 to 1.
A larger value meansthat whead and wco-i tend to co-occur in one or twopositions.The word pairs satisfying, (1) BI-Strength(whead wco-j)>K0 and (2) BI-Spread(whead,wco-i)>U0, are extracted as bi-gram collocations,where K0 and U0 are empirical threshold.Based on the extracted bi-gram collocations,the appearance of each co-word in each positionaround whead is analyzed.
For each of the possiblerelative distances from whead, only words occupy-ing the position with a probability greater than agiven threshold T are kept.
Finally, the adjacentwords satisfying the threshold requirement arecombined as n-gram collocations.3 The Baseline SystemThe baseline system incorporates collocation andcontext words as features in a one-class SVMclassifier.
It consists of two steps:STEP 1: To match a test instance containingseed collocation set.
If the instance cannot bematched by any collocations, go to STEP 2.STEP 2: Use a trained classifier to indentifythe sentiment of the word.The collocations of 14 testing sentiment adjec-tives are extracted from a 100-million-word cor-pus.
Collocations with obvious and consistentsentiment are manually identified.
412 positiveand 191 negative collocations are established asthe seed collocation set.We think that the polarity of a word can be de-termined by exploiting the association of its co-occurring words in sentence.
We assume that, thetwo instances of an ambiguous sentiment adjec-tives that have similar neighboring nouns mayhave the same polarity.
Gamon and Aue (2005)made an assumption to label sentiment terms.We extract 13,859 sentences containing collo-cations between negative adjective and targetsin seed collocation set or collocations betweenambiguous adjective and negative modifier(such as ??
too) as the training data.
Thesesentences are assume negative.
A single-classclassifier is then trained to recognize negativesentences.
Three types of features are used:(1) Context features include bag of wordswithin context in window of [-5, +5](2) Collocation features contain bi-grams inwindow [-5,+5](3) Collocation features contain n-grams inwindow [-5,+5]In our research, SVM with linear kernel isemployed and the open source SVM package ?LIBSVM is selected for the implementation.4 The Improved SystemThe preliminary experiment shows that the base-line system is not satisfactory, especially the449coverage is low.
It is observed that the seed col-location set covers 17.54% of sentences contain-ing the ambiguous adjectives while the colloca-tions between adjective and negative modifiercovers only 11.28%.
Therefore, we expand thesentiment adjective-target collocation set basedon word similarity and a semi-supervised learn-ing algorithm orderly.
We then incorporate bothinner-sentence features (collocations, contextwords, etc.)
and inter-sentence features in theimproved systems for sentiment adjectives dis-ambiguation.4.1 Collocation Set Expansion based onWord SimilarityFirst, we expand the seed collocation set on thetarget side.
The words strongly similar to knowntargets are identified by using a word similaritycalculation package, provided by HowNet (aChinese thesaurus).
Once these words co-occurwith adjective within a context window moreoften than a threshold, they are appended to seedcollocation set.
For example, ??-??
(low ca-pacity)?is expanded from a seed collocation ??-??
(low capacity)?.Second, we manually identify the words hav-ing the same ?trend?
as the testing adjectives.For example, ???
increase?
is selected as asame-trend word of ??
high?.
The collocationsof ????
are extracted from corpus.
Its collo-cated targets with confident and consistent sen-timent are appended to the sentiment collocationset of ???
if they co-occurred with ???
morethan a threshold.
In this way, some low-frequency sentiment collocation can be obtained.4.2 Semi-supervised Learning of SentimentCollocationsA semi-supervised learning algorithm is devel-oped to further expand the collocation seed set,which is described as follows.
(It is revised basedon our previous research (Xu et al 2008).
Thebasic assumption here is that, the sentiment of asentence having ambiguous adjectives can beestimated based on the sentiment of its neighbor-ing sentences.Input: Raw training corpus, labeled as Su,Step 1.
The sentences holding strong polaritiesare recognized from Su which satisfies any two offollowing requirements, (1) contains known con-text-free sentiment word (CFSW); (2) containsmore than three known context-dependent senti-ment words (CDSW); (3) contains collocationsbetween degree adverbs and known CDSWs; (4)contains collocations between degree adverbsand opinion operators (the verbs indicate a opi-nion operation, such as??
praise); (5) containsknown opinion indicator and known CDSWs.Step 2.
Identify the strong non-opinionated sen-tences in Su.
The sentences satisfying all of fol-lowing four conditions are recognized as non-opinionated ones, (1) have no known sentimentwords; (2) have no known opinion operators; (3)have no known degree adverbs and (4) have noknown opinion indicators.Step 3.
Identify the opinion indicators in the restsentences.
Determine their polarities if possibleand mark the conjunction (e.g.?
and) or nega-tion relationship (e.g.?
but) in the sentences.Step 4.
Match the CFSWs and known CDSWs inSu.
The polarities of CFSWs are assigned basedon sentiment lexicon.Step 5.
If a CDSW occurs in a sentence with cer-tain orientations which is determined by the opi-nion indicators, its polarity is assigned as thevalue suggested.
If a CDSW co-occur with aseed collocated target, it polarity is assigned ac-cording to the seed sentiment collocation set.Otherwise, if a CDSW co-occur with a CFSW inthe same sentence, or the neighboring continualor compound sentence, the polarity of CDSW isassigned as the same as CFSW, or the reversedpolarity if a negation indicator is detected.Step 6.
Update the polarity scores of CDSWs inthe target set by using the cases where the polari-ty is determined in Step 5.Step 7.
Determine the polarities of CDSWs inthe undetermined sentences.
Suppose Si is a sen-tence and the polarity scores of all its CFSWsand CDSWs are known, its polarity, labeled asPlo(Si), is estimated by using the polarity scoresof all of the opinion words in this sentence, viz.:?
?+ ?= )(_)(_ )(_)(pos_)( CDSWnegPCDSWposP CFSWnegPCFSWPSiPlo (3)A large value (>0) of Plo(si) implies that si tendsto be positive, and vice versa.Step 8.
If the sentence polarity cannot be deter-mined by its components, we use the polarity ofits neighboring sentences sj-1 and sj+1, labeled asPlo(sj-1) and Plo(sj+1), respectively, to help de-termine Plo(sj), viz.
:)(5.0)(*)(5.0)( 11 +?
?++?= jjjj sPlosPlosPlosPlo (4)where, Plo*(sj) is the polarity score of Sj (Fol-lowing Equation 3) but ignore the contribution oftesting adjectives while 0.5 are empirical weights.450Step 9.
After all of the polarities of knownCDSWs in the training data are determined, up-date the collocation set by identifying co-occurred pairs with consistent sentiment.Step 10.
Repeat Step 5 to Step 9 to re-estimatethe sentiment of CDSWs and expand the colloca-tion set, until the collocation set converge.In this way, the seed collocation set is furtherexpanded and their sentiment characteristics areobtained.4.3 Sentiment Adjectives ClassifierWe incorporate the following 8 groups of fea-tures in a linear-kernel two-class SVM classifierto classify the sentences with sentiment adjec-tives into positive or negative:(1) The presence of known positive/negativeopinion indicator and opinion operator(2) The presence of known positive/negativeCFSW(3) The presence of known positive/negativeCDSW(exclude the testing adjectives)(4) The presence of known positive/negativeadjective-target bi-gram collocations(5) The presence of known positive/negativeadjective-target n-gram collocations(6) The coverage of context words surround-ing the adjectives in the context words intraining positive/negative sentences(7) The sentiment of -1 sentence(8) The sentiment of +1 sentenceThe classifier is trained by using the sentenceswith determined sentiment which is obtained inthe semi-supervised learning stage.5 Evaluations and ConclusionThe ACL-SEMEVAL task 18 testing datasetcontains 14 ambiguous adjectives and 2,917 in-stances.
HITSZ_CITYU group submitted threeruns.
Run-1 and Run-2 are two runs correspond-ing to the improved system and Run-3 is thebaseline system.
The achieved performances arelisted in Table 1.Run ID Marco Accuracy Micro Accuracy1 0.953 0.9362 0.957 0.9333(baseline) 0.629 0.665Table 1: Performance of HITSZ_CITYU RunsIt is observed that the improved systemsachieve promising results which is obviouslyhigher than the baseline.
They are ranked 1st and2nd in Macro Accuracy evaluation and 2nd and 3rdin Micro Accuracy evaluation among 16 submit-ted runs, respectively.6 ConclusionIn this paper, we proposed similarity-based andsemi-supervised based methods to expand theadjective-target seed collocation set.
Meanwhile,we incorporate both inner-sentence (collocationsand context words) and inter-sentence features ina two-class SVM classifier for the disambigua-tion of sentiment adjectives.
The achieved prom-ising results show the effectiveness of colloca-tion features, context words features and senti-ment of neighboring sentences.
Furthermore, wefound that the neighboring sentence sentimentsare important features for the disambiguation ofsentiment ambiguous adjectives, which is ob-viously different from the traditional word sensedisambiguation that emphasize the inner-sentence features.ReferencesAndreevskaia, A. and Bergler, S. 2006.
MiningWordNet for fuzzy sentiment: Sentiment tag ex-traction from WordNet glosses.
In Proceedings ofEACL 2006, pp.
209-216Esuli, A. and Sebastian, F. 2006.
SENTIWORDNET:A publicly available lexical resource for opinionmining.
In Proceeding of LREC 2006, pp.
417-422.Hatzivassiloglou, V. and McKeown, K. R. 1997.
Pre-dicting the semantic orientation of adjectives.
InProceeding of ACL 1997, pp.174-181Michael Gamon and Anthony Aue.
2005.
Automaticidentification of sentiment vocabulary: Exploitinglow association with known sentiment terms.
InProceedings of the ACL05 Workshop on FeatureEngineering for Machine Learning in NaturalLanguage Processing, pp.57-64Ruifeng Xu, Kam-Fai Wong et al 2008.
LearningKnowledge from Relevant Webpage for OpinionAnalysis, in Proceedings of 2008 IEEE / WIC /ACM Int.
Conf.
Web Intelligence, pp.
307-313Turney, P. D. and Littman, M. L. 2003.
Measuringpraise and criticism: Inference of semantic orienta-tion from association.
ACM Transactions on In-formation Systems, vol.
21, no.
4, pp.315-346Yunfang Wu, Miao Wang and Peng Jin.
2008.
Dis-ambiguating sentiment ambiguous adjectives, InProceedings of Int.
Conf.
on Natural LanguageProcessing and Knowledge Engineering 2008, pp.1-8451
