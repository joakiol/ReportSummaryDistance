Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 126?133,New York City, June 2006. c?2006 Association for Computational LinguisticsThe Difficulties of Taxonomic Name Extraction and a SolutionGuido Sautter Klemens B?hmDept.
of Computer ScienceUniversit?t Karlsruhe (TH)Germanysautter@ipd.uka.de boehm@ipd.uka.deAbstractIn modern biology, digitization of biosys-tematics publications is an important task.Extraction of taxonomic names from suchdocuments is one of its major issues.
Thisis because these names identify the variousgenera and species.
This article reports onour experiences with learning techniquesfor this particular task.
We say why estab-lished Named-Entity Recognition tech-niques are somewhat difficult to use in ourcontext.
One reason is that we have onlyvery little training data available.
Our ex-periments show that a combining approachthat relies on regular expressions, heuris-tics, and word-level language recognitionachieves very high precision and recall andallows to cope with those difficulties.1 IntroductionDigitization of biosystematics publications cur-rently is a major issue.
They contain the namesand descriptions of taxonomic genera and species.The names are important because they identify thevarious genera and species.
They also position thespecies in the tree of life, which in turn is usefulfor a broad variety of biology tasks.
Hence, rec-ognition of taxonomic names is relevant.
How-ever, manual extraction of these names is time-consuming and expensive.The main problem for the automated recognitionof these names is to distinguish them from thesurrounding text, including other Named Entities(NE).
Named Entity Recognition (NER) currentlyis a big research issue.
However, conventionalNER techniques are not readily applicable herefor two reasons: First, the NE categories are ratherhigh-level, e.g., names of organizations or persons(cf.
common NER benchmarks such as (Carreras2005)).
Such a classification is too coarse for ourcontext.
The structure of taxonomic names varieswidely and can be complex.
Second, those recog-nizers require large bodies of training data.
Sincedigitization of biosystematics documents hasstarted only recently, such data is not yet availablein biosystematics.
On the other hand, it is impor-tant to demonstrate right away that text-learningtechnology is of help to biosystematics as well.This paper reports on our experiences with learn-ing techniques for the automated extraction oftaxonomic names from documents.
The varioustechniques are obviously useful in this context:?
Language recognition ?
taxonomic names area combination of Latin or Latinized words,with surrounding text written in English,?
structure recognition ?
taxonomic names fol-low a certain structure,?
lexica support ?
certain words never are/maywell be part of taxonomic names.On the other hand, an individual technique in iso-lation is not sufficient for taxonomic name extrac-tion.
Mikheev (1999) has shown that a combiningapproach, i.e., one that integrates the results ofseveral different techniques, is superior to the in-dividual techniques for common NER.
Combin-ing approaches are also promising for taxonomicname extraction.
Having said this, the article willnow proceed as follows:First, we have conducted a thorough inspection oftaxonomic names.
An important observation isthat one cannot model taxonomic names bothconcisely and precisely using regular expressions.As is done in bootstrapping, we use two kinds ofregular expressions: precision rules, whose in-stances are taxonomic names with very highprobability, and recall rules, whose instances area superset of all taxonomic names.
We propose ameaningful definition of precision rules and recallrules for taxonomic names.126Second, the essence of a combining approach is toarrange the individual specific approaches in theright order.
We propose such a composition fortaxonomic name extraction, and we say why it issuperior to other compositions that may appearfeasible as well at first sight.Finally, to quantify the impact of the various al-ternatives described so far, we report on experi-mental results.
The evaluation is based on a cor-pus of biosystematics documents marked up byhand.
The best solution achieves about 99.2% inprecision and recall.
It prompts the user for only0.2% of the words.The remainder of the paper is as follows: Sec-tion 2 discusses related approaches.
Section 3 in-troduces some preliminaries.
Section 4 describesone specific combining approach in some detail.Section 5 features an evaluation.
Section 6 con-cludes.2 Related WorkThis section reviews solutions to problems relatedto the extraction of taxonomic names.2.1 Named Entity RecognitionTaxonomic names are a special case of namedentity.
In the recent past, NER has received muchattention, which yielded a variety of methods.
Themost common ones are list lookups, grammars,rules, and statistical methods like SVMs (Bikel1997).
All these techniques have been developedfor tasks like the one presented by Carreras(2005).
Thus, their focus is the recognition ofsomewhat common NE like locations and per-sons.
Consequently, they are not feasible for thecomplex and variable structure of taxonomicnames (see Section 3.3).
Another problem ofcommon NER techniques is that they usually re-quire several hundred thousand words of pre-annotated training data.2.2 List-based TechniquesList-based NER techniques (Palmer 1997) makeuse of lists to determine whether a word is a NEof the category sought.
The sole use of a thesaurusas a positive list is not an option for taxonomicnames.
All existing thesauri are incomplete.
Nev-ertheless, such a list allows recognizing knownparts of taxonomic names.The inverse approach would be list-based exclu-sion, using a common English dictionary.
Koning(2005) combines such an approach with structuralrules.
In isolation, however, it is not an optioneither.
First, it would not exclude proper namesreliably.
Second, it excludes parts of taxonomicnames that are also used in common English.However, exclusion of sure negatives, i.e., wordsthat are never part of taxonomic names, simplifiesthe classification.2.3 Rule Based TechniquesRule based techniques do not require pre-annotated training data.
They extract words orword sequences based on their structure.
Yoshida(1999) applies regular expressions to extract thenames of proteins.
He makes use of the syntax ofprotein names like NG-monomethyl-L-arginine,which is very distinctive.There are also rules for the syntax of taxonomicnames, but they are less restrictive.
For instance,Prenolepis (Nylanderia) vividula Erin subsp.
gua-temalensis Forel var.
itinerans Forel is a taxo-nomic name as well as Dolichoderus decollatus.Because of the wide range of optional parts, it isimpossible to find a regular expression thatmatches all taxonomic names and at the sametime provides satisfactory precision.
Koning(2005) presents an approach based on regular ex-pressions and static dictionaries.
This techniqueperforms satisfactorily compared to commonNER approaches, but their conception of what is apositive is restricted.
For instance, they leaveaside taxonomic names that do not specify a ge-nus.
However, the idea of rule-based filters for thephrases of documents is helpful.2.4 BootstrappingInstead of a large amount of labeled training data,Bootstrapping uses some labeled examples(?seeds?)
and an even larger amount of unlabeleddata for the training.
Jones (1999) has shown thatthis approach performs equal to techniques requir-ing labeled training data.
However, Bootstrappingis not readily applicable to our particular problem.Niu (2003) used an unlabeled corpus of88.000.000 words for training a named entity rec-ognizer.
For our purpose, even unlabeled trainingdata is not available in this order of magnitude, atleast right now.1272.5 Active LearningAccording to Day (1997), the original idea of Ac-tive Learning was to speed up the creation oflarge labeled training corpora from unlabeleddocuments.
The system uses all of its knowledgeduring all phases of the learning.
Thus, it labelsmost of the data items automatically and requiresuser interaction only in rare cases.
In order to in-crease data quality, we include user-interaction inour taxonomic name extractor as well.2.6 Gene and Protein Name ExtractionIn the recent past, the major focus of biomedicalNER has been the recognition of gene and proteinnames.
Tanabe (2002) gives a good overview ofvarious approaches to this task.
Frequently usedtechniques are structural rules, dictionary lookupsand Hidden Markov Models.
Most of the ap-proaches use the output of a part-of-speech taggeras additional evidence.
Both gene and proteinnames differ from taxonomic names in that thenomenclature rules for them are by far stricter.For instance, they never include the names of thediscoverer / author of a given part.
In addition,there are parts which are easily distinguished fromthe surrounding text based on their structure,which is not true for taxonomic names.
Conse-quently, the techniques for gene or protein namerecognition are not feasible for the extraction oftaxonomic names.3 PreliminariesThis section introduces some preliminaries re-garding word-level language recognition.
We alsodescribe a measure to quantify the user effort in-duced by interactions.3.1 Measure for User EffortIn NLP, the f-Measure is popular to quantify theperformance of a word classifier:P(P) := positives classified as positiveN(P) := positives classified as negativeP(N) := negatives classified as positiveN(N) := negatives classified as negativeP(N)P(P)P(P):p ecisionPr +=N(P)  P(P)P(P):r callRe +=rprp2:fMeasure +?
?=But components that use active learning havethree possible outputs.
If the decision betweenpositive or negative is narrow, they may classify aword as uncertain and prompt the user.
This pre-vents misclassifications, but induces intellectualeffort.
To quantify this effort as well, there aretwo further measures:U(P) := positives not classified (uncertain)U(N) := negatives not classified (uncertain)Given this, Coverage C is defined as the fractionof all classifications that are not uncertain:)N(U)N(N)N(P)P(U)P(N)P(P)N(N)N(P)P(N)P(P:C++++++++=To obtain a single measure for overall classifica-tion quality, we multiply f-Measure and coverageand define Quality Q asCfMeasure:Q ?=3.2 Word-Level Language Recognitionfor Taxonomic Name ExtractionIn earlier work (Sautter 2006), we have presenteda technique to classify words as parts of taxo-nomic names or as common English, respectively.It is based on two statistics containing the N-Gram distribution of taxonomic names and ofcommon English.
Both statistics are built fromexamples from the respective languages.
It usesactive learning to deal with the lack of trainingdata.
Precision and recall reach a level of 98%.This is satisfactory, compared to common NERcomponents.
At the same time, the user has toclassify about 3% of the words manually.
In a textof 10.000 words, this would be 300 manual classi-fications.
We deem this relatively high.3.3 Formal Structure of Taxonomic NamesThe structure of taxonomic names is defined bythe rules of Linnaean nomenclature (Ereshefsky1997).
They are not very restrictive and includemany optional parts.
For instance, both Prenole-pis (Nylanderia) vividula Erin subsp.
guatemalen-sis Forel var.
itinerans Forel and Dolichoderusdecollatus are taxonomic names.
There are onlytwo mandatory parts in such a name: the genusand the species.
Table 1 shows the decompositionof the two examples.
The parts with their namesin brackets are optional.
More formally, the rulesof Linnaean nomenclature define the structure oftaxonomic names as follows:?
The genus is mandatory.
It is a capitalizedword, often abbreviated by its first one or twoletters, followed by a dot.128?
The subgenus is optional.
It is a capitalizedword, often enclosed in brackets.?
The species is mandatory.
It is a lower caseword.
It is often followed by the name of thescientist who first described the species.?
The subspecies is optional.
It is a lower caseword, often preceded by subsp.
or subspeciesas an indicator.
It is often followed by thename of the scientist who first described it.?
The variety is optional.
It is a lower caseword, preceded by var.
or variety as an indi-cator.
It is often followed by the name of thescientist who first described it.PartGenus Prenolepis Dolichoderus(Subgenus) (Nylanderia)Species vividula decollatus(Discoverer) Erin(Subspecies) subsp.
guatemalensis(Discoverer) Forel(Variety) var.
itinerans(Discoverer) ForelTable 1: The parts of taxonomic names4 Combining Techniquesfor Taxonomic Name ExtractionDue to its capability of learning at runtime, theword-level language recognizer needs little train-ing data, but it still does.
In addition, the manualeffort induced by uncertain classifications is high.Making use of the typical structure of taxonomicnames, we can improve both aspects.
First, wecan use syntax-based rules to harvest training datadirectly from the documents.
Second, we can usethese rules to reduce the number of words theclassifier has to deal with.
However, it is not pos-sible to find rules that extract taxonomic nameswith both high precision and recall, as we willshow later.
But we have found rules that fulfillone of these requirements very well.
In what fol-lows, we refer to these as precision rules and re-call rules, respectively.4.1 The Classification Process1.
We apply the precision rules.
Every wordsequence from the document that matchessuch a rule is a sure positive.2.
We apply the recall rules to the phrases thatare not sure positives.
A phrase not matchingone of these rules is a sure negative.3.
We make use of domain-specific vocabularyand filter out word sequences containing atleast one known negative word.4.
We collect a set of names from the set of surepositives (see Subsection 4.5).
We then usethese names to both include and exclude fur-ther word sequences.5.
We train the word-level language recognizerwith the surely positive and surely negativewords.
We then apply it to the remaining un-certain word sequences.Figure 1 visualizes the classification process.
Atfirst sight, other orders seem to be possible aswell, e.g., the language recognizer classifies eachword first, and then we apply the rules.
But this isnot feasible: It would require external trainingdata.
In addition, the language recognizer wouldhave to classify all the words of the document.This would incur more manual classifications.Figure 1: The Classification ProcessThis approach is similar to the bootstrapping algo-rithm proposed by Jones (1999).
The difference isthat this process works solely with the documentit actually processes.
In particular, it does notneed any external data or a training phase.
Aver-age biosystematics documents contain about15.000 words, which is less than 0.02% of thedata used by Niu (2003).
On the other hand, withthe classification process proposed here, the accu-racy of the underlying classifier has to be veryhigh from the start.1294.2 Structural RulesIn order to make use of the structure of taxonomicnames, we use rules that refer to this structure.We use regular expressions for the formal repre-sentation of the rules.
In this section, we developa regular expression matching any word sequencethat conforms to the Linnaean rules of nomencla-ture (see 3.3).
Table 2 provides some abbrevia-tions, to increase readability.
We model taxo-nomic names as follows:_ one white space character<LcW> [a-z](3,)<CapW> [A-Z][a-z](2,)<CapA> [A-Z]{[a-z]}?.<Name> {<CapA>_}(0,2)<CapW>Table 2: Abbreviations?
The genus is a capitalized word, often abbre-viated.
We denote it as <genus>, whichstands for {<CapW>|<CapA>}.?
The subgenus is a capitalized word, option-ally surrounded by brackets.
We denote it as<subGenus>, which stands for<CapW>|(<CapW>).?
The species is a lower case word, optionallyfollowed by a name.
We denote it as<species>, which stands for<LcW>{_<Name>}?.?
The subspecies is a lower case word, pre-ceded by the indicator subsp.
or subspecies,and optionally followed by a name.
We de-note it as <subSpecies>, standing for{subsp.|subspecies}_<LcW>{_<Name>}?.?
The variety is a lower case word, preceded bythe indicator var.
or variety, and optionallyfollowed by a name.
We denote it as<variety>, which stands for {var.|variety}_<LcW>{_<Name>}?.A taxonomic name is now modeled as follows.We refer to the pattern as <taxName>:<genus>{_<subGenus>}?_<species>{_<subSpecies>}?
{_<variety>}?4.3 Precision RulesBecause <taxName> matches any sequence ofwords that conforms to the Linnaean rules, it isnot very precise.
The simplest match is a capital-ized word followed by one in lower case.
Any twowords at the beginning of a sentence are a match!To obtain more precise regular expressions, werely on the optional parts of taxonomic names.
Inparticular, we classify a sequence of words as asure positive if it contains at least one of the op-tional parts <subGenus>, <subSpecies> and<variety>.
Even though these regular expres-sions may produce false negatives, our evaluationwill show that this happens very rarely.
Our set ofprecise regular expressions has three elements:?
<taxName> with subgenus in brackets,<subspecies> and <variety> optional:<genus>_(<CapW>)_<species>{_<subSpecies>}?{_<variety>}??
<taxName> with <subspecies> given,<subGenus> and <variety> optional:<genus>{_<subGenus>}?_<species>_<subSpecies>{_<variety>}??
<taxName> with <variety> mandatory,<subGenus> and <subSpecies> optional:<genus>{_<subGenus>}?_<species>{_<subSpecies>}?
{_<variety>}To classify a word sequence as a sure positive if itmatches at least one of these regular expressions,we combine them disjunctively and call the result<preciseTaxName>.A notion related to that of a sure positive is theone of a surely positive word.
A surely positiveword is a part of a taxonomic name that is not partof a scientist?s name.
For instance, the taxonomicname Prenolepis (Nylanderia) vividula Erinsubsp.
guatemalensis Forel var.
itinerans Forelcontains the surely positive words Prenolepis,Nylanderia, vividula, guatemalensis, and itiner-ans.
We assume that surely positive words exclu-sively appear as parts of taxonomic names.4.4 Recall Rules<taxName> matches any sequence of words thatconforms to the Linnaean rules, but there is a fur-ther issue: Enumerations of several species of thesame genus tend to contain the genus only once.For instance, in Pseudomyrma arboris-sanctaeEmery, latinoda Mayr and tachigalide Forel?wewant to extract latinoda Mayr and tachigalideForel as well.
To address this, we make use of thesurely positive words: We use them to extractparts of taxonomic names that lack the genus.130Our technique also extracts the names of the sci-entists from the sure positives and collects themin a name lexicon.
Based on the structure de-scribed in Section 3.3, a capitalized word in a surepositive is a name if it comes after the second po-sition.
From the sure positive Pseudomyrma(Minimyrma) arboris-sanctae Emery, the tech-nique extracts Pseudomyrma, Minimyrma andarboris-sanctae.
In addition, it would add Emeryto the name lexicon.We cannot be sure that the list of sure positivewords suffices to find all species names in anenumeration.
Hence, our technique additionallycollects all lower-case words followed by a wordcontained in the name lexicon.
In the example, weextract latinoda Mayr and tachigalide Forel ifMayr and Forel are in the name lexicon.4.5 Data RulesBecause we want to achieve close to 100% in re-call, the recall rules are very weak.
In conse-quence, many word sequences that are not taxo-nomic names are considered uncertain.
Before theword-level language recognizer deals with them,we see some more ways to exclude negatives.Sure Negatives .
As mentioned in Subsection 4.3,<taxName> matches any capitalized word fol-lowed by a word in lower case.
This includes thestart of any sentence.
Making use of the surenegatives, we can recognize these phrases.
In par-ticular, out technique classifies any word se-quence as negative that contains a word which isalso in the set of sure negatives.
For instance, insentence ?Additional evidence results from ?
?,Additional evidence matches <taxName>.
An-other sentence contains an additional advantage,which does not match <taxName>.
Thus, the set ofsure negatives contains an, additional, and advan-tage.
Knowing that additional is a sure negative,we exclude the phrase Additional evidence.Names of Scientists.
Though the names of sci-entists are valid parts of taxonomic names, theyalso cause false matches.
The reason is that theyare capitalized.
A misclassification occurs if theyare matched with the genus or subgenus part ?<taxName> cannot exclude this.
In addition, theymight appear elsewhere in the text without be-longing to a taxonomic name.
Similarly to surenegatives, we exclude a match of <taxName> ifthe first or second word is contained in the namelexicon.
For instance, in ?
?, and Forel furtherconcludes?, Forel further matches <taxName>.
Ifthe name lexicon contains Forel, we know that itis not a genus, and thus exclude Forel further.4.6 Classification of Remaining WordsAfter applying the rules, some word sequencesstill remain uncertain.
To deal with them, we useword-level language recognition.
We train theclassifier with the sure positive and sure negativewords.
We do not classify every word separately,but compute the classification score of all wordsof a sequence and then classify the sequence as awhole.
This has several advantages: First, if oneword of a sequence is uncertain, this does notautomatically incur a feedback request.
Second, ifa word sequence is uncertain as a whole, the usergives feedback for the entire sequence.
This re-sults in several surely classified uncertain wordsat the cost of only one feedback request.
In addi-tion, it is easier to determine the meaning of aword sequence than the one of a single word.5 EvaluationA combining approach gives rise to many ques-tions, e.g.
: How does a word-level classifier per-form with training data automatically generated?How does rule-based filtering affect precision,recall, and coverage?
What is the effect to dy-namic lexicons?
Which kinds of errors remain?We run two series of experiments: We first proc-ess individual documents.
We then process thedocuments incrementally, i.e., we do neither clearthe sets of known positives and negatives aftereach document, nor the statistics of the word-levellanguage recognizer.
This is to measure the bene-fit of reusing data obtained from one document inthe processing of subsequent ones.
Finally, wetake a closer look at the effects of the individualsteps and heuristics from Section 4.The platform is implemented in JAVA 1.4.2.We use the java.util.regex package to repre-sent the rules.
All tests are based on 20 issues ofthe American Museum Novitates, a natural scienceperiodical published by the American Museum ofNatural History.
The documents contain about260.000 words, including about 2.500 taxonomicnames.
The latter consist of about 8.400 words.1315.1 Tests with Individual DocumentsFirst, we test the combined classifier with indi-vidual documents.
The Docs column in Table 3contains the results.
The combination of rules andword-level classification provides very high pre-cision and recall.
The former is 99.7% on average,the latter 98.2%.
The manual effort is very low:The average coverage is 99.7%.5.2 Tests with Entire CorpusIn the first test the classifier did not transfer anyexperience from one document to later ones.
Wenow process the documents one after another.
TheCorp column of Table 3 shows the results.
Asexpected, the classifier performs better than withindividual documents.
The average recall is99.2%, coverage is 99.8% on average.
Only preci-sion is a little less, 99.1% on average.Docs Corp<preciseTaxName> 22,6<taxName> 414,1SN excluded 78,5Names excluded 176,15Scorings 139,9User Feedbacks 19,6 10,35False positives 4,25 1,5False negatives 0,55 1,5Precision 0,997 0,991Recall 0,982 0,992f-Measure 0,990 0,992Coverage 0,997 0,998Quality 0,987 0,990Table 3: Test resultsThe effect of the incremental learning is obvious.The false positives are less than half of those inthe first test.
A comparison of Line FalsePositives in Table 3 shows this.
The same istrue for the number feedback requests (Line UserFeedbacks).
The slight decrease in precision(Line False Negatives) results from the propa-gation of misclassifications between documents.The reason for the improvement becomes clearfor documents where the number of word se-quences in <preciseTaxName> is low: experiencefrom previous documents compensates the lack ofpositive examples.
This reduces both false posi-tives and manual classifications.5.3 The Data RulesThe exclusion of word sequences containing asure negative turns out to be effective to filter thematches of <taxName>.
Lines <taxName> and SNexcluded of Tables 3 show this.
On average, thisstep excludes about 20% of the word sequencesmatching <taxName>.
Lines <taxName> and Namesexcluded tell us that the rule based on the namesof scientists is even more effective.
On average, itexcludes about 40% of the matches of <taxName>.Both data rules decrease the number of words thelanguage recognizer has to deal with and eventu-ally the manual effort.
This is because they reducethe number of words classified uncertain.5.4 Comparison to Word-Level Classifierand TaxonGrabA word-level classifier (WLC) is the core compo-nent of the combining technique.
We compare itin standalone use to the combining technique(Comb) and to the TaxonGrab (T-Grab) approach(Koning 2005).
See Table 4.
The combining tech-nique is superior to both TaxonGrab and stand-alone word-level classification.
The reason forbetter precision and recall is that it uses more dif-ferent evidence.
The better coverage results fromthe lower number of words that the word-levelclassifier has to deal with.
On average, it has toclassify only 2.5% of the words in a document.This reduces the classification effort, leading toless manual feedback.
It also decreases the num-ber of potential errors of the word-level classifier.All these positive effects result in about 99% f-Measure and 99.7% coverage.
This means theerror is reduced by 75% compared to word-levelclassification, and by 80% compared to Taxon-Grab.
The manual effort decreases by 94% com-pared to the standalone word-level classifier.Precision Recall f-Measure CoverageT-Grab 96% 94% 95% -WLC 97% 95% 96% 95%Comb 99.1% 99.2% 99% 99.7%Table 4: Comparison to Related Approaches5.5 Misclassified WordsDespite all improvements, there still are word se-quences that are misclassified.False Negatives.
The regular expressions in<preciseTaxName> are intended to be 100% pre-cise.
There are, however, some (rare) exceptions.Consider the following phrase: ??
In Guadeloup(Mexico) another subspecies killed F.
Smith.
?Except for the word In, this sentence matches the132regular expression from <preciseTaxName>where <subSpecies> is mandatory.
Similarpathologic cases could occur for the variety part.Another class of false negatives contains twoword sequences, and the first one is the name of agenus.
For instance, ?Xenomyrmex varies ??
fallsinto this category.
The classifier (correctly) rec-ognizes the first word as a part of a taxonomicname.
The second one is not typical enough tochange the overall classification of the sequence.To recognize these false negatives, one might usePOS-tagging.
We could exclude word sequencescontaining words whose meaning does not fit intoa taxonomic name.False Positives.
Though <taxName> matches anytaxonomic name, the subsequent exclusionmechanisms may misclassify a sequence ofwords.
In particular, the word-level classifier hasproblems recognizing taxonomic names contain-ing proper names of persons.
The problem is thatthese words consist of N-Grams that are typicalfor common English.
?Wheeleria rogersi Smith?,for instance, is a fictitious but valid taxonomicname.
A solution to this problem might be to usethe scientist names for constructing and recogniz-ing the genus and species names derived fromthem.6 ConclusionsThis paper has reported on our experiences withthe automatic extraction of taxonomic names fromEnglish text documents.
This task is essential formodern biology.
A peculiarity of taxonomic nameextraction is a shortage of training data.
This isone reason why deployment of established NERtechniques has turned out to be infeasible, at leastwithout adaptations.
A taxonomic-name extractormust circumvent that shortage.
Our experiencehas been that designing regular expressions thatgenerate training data directly from the documentsis feasible in the context of taxonomic name ex-traction.
A combining approach where individualtechniques are carefully tuned and assigned in theright order has turned out to be superior to otherpotential solutions with regard to precision, recall,and number of user interactions.
?
Finally, isseems promising to use document and term fre-quencies as additional evidence.
The ides is thatboth are low for taxonomic names.7 References(Bikel 1997) Daniel M. Bikel, Scott Miller, RichardSchwartz, Ralph Weischedel: Nymble: a high-performance learning name-finder, In Proceedings ofANLP-97, Washington, USA, 1997(Carreras 2005) Xavier Carreras, Lluis Marquez: In-troduction to the CoNLL-2005 Shared Task: SemanticRole Labeling, 2005(Chieu 2002) Hai Leong Chieu, Hwee Tou Ng: NamedEntity Recognition: A Maximum Entropy ApproachUsing Global Information, In Proceedings ofCOLING-02, Taipei, Taiwan, 2002(Cucerzan 1999) Cucerzan, S., D. Yarowsky: Lan-guage independent named entity recognition combin-ing morphological and contextual evidence, In Pro-ceedings of SIGDAT-99, College Park, USA, 1999(Day) David Day, John Aberdeen, Lynette Hirschman,Robyn Kozierok, Patricia Robinson, Marc Vilain:Mixed-Initiative Development of Language ProcessingSystems, In Proceedings of ANLP-97, Washington,USA, 1997(Ereshefsky 1997) Marc Ereshefsky: The Evolution ofthe Linnaean Hierarchy, Springer Science & BusinessMedia B.V., 1997(Jones 1999) Rosie Jones, Andrew McCallum, KamalNigam, Ellen Riloff: Bootstrapping for Text LearningTasks, In Proceedings of IJCAI-99 Workshop on TextMining, 1999(Koning 2005) Drew Koning, Neil Sarkar, ThomasMoritz: TaxonGrab: Extractin Taxonomic Names fromText(Niu 2003) Cheng Niu, Wei Li, Jihong Ding, Rohini K.Srihari: A Bootstrapping Approach to Named EntityClassification Using Successive Learners, In Proceed-ings of 41st Annual Meeting of the ACL, 2003(Palmer 1997) David D. Palmer, David S. Day:A Statistical Profile of the Named Entity Task, In Pro-ceedings of ANLP-97, Washington, USA, 1997.
(Sautter 2006) G. Sautter, K. B?hm, K. Csorba: HowHelpful Is Word-Level Language Recognition to Ex-tract Taxonomic Names?, submitted to DILS, 2006(Tanabe 2002) Lorraine Tanabe, W. John Wilbur:Tagging Gene and Protein Names in Biomedical Text,Bioinformatics, Vol.
18, 2002, pp.
1124-1132(Yoshida 1999) Mikio Yoshida, Ken-ichiro Fukadaand Toshihisa Takagi: PDAD-CSS: a workbench forconstructing a protein name abbreviation dictionary,In Proceedings of the 32nd HICSS, 1999133
