Pre-processing Closed Captions for Machine TranslationDav ide  Turcato  Fred Popowich  Paul  McFet r idgeDev lan  N icho lson  Jan ine  Too leNatural Language Laboratory, School of Computing Science, Simon Fraser University8888 University Drive, Burnaby, British Columbia, V5A 1S6, Canadaandgavagai Technology Inc.P.O.
374, 3495 Cambie Street, Vancouver, British Columbia, V5Z 4R3, Canada{turk, popowich, mcfet, devl an, toole}?cs, sfu.
caAbst rac tWe describe an approach to Machine Transla-tion of transcribed speech, as found in closedcaptions.
We discuss how the colloquial natureand input format peculiarities of closed captionsare dealt with in a pre-processing pipeline thatprepares the input for effective processing bya core MT system.
In particular, we describecomponents for proper name recognition andinput segmentation.
We evaluate the contribu-tion of such modules to the system performance.The described methods have been implementedon an MT system for translating English closedcaptions to Spanish and Portuguese.1 In t roduct ionMachine Translation (MT) technology can beembedded in a device to perform real timetranslation of closed captions included in TVsignals.
While speed is one factor associatedwith the construction of such a device, anotherfactor is the language type and format.
Thechallenges posed by closed captions to MT canbe attributed to three distinct characteristics:Firstly, closed captions are transcribedspeech.
Although closed captions are not a com-pletely faithful transcription of TV programs,they render spoken language and therefore thelanguage used is typically colloquial (Nybergand Mitamura, 1997).
They contain many ofthe phenomena which characterize spoken lan-guage: interjections, repetitions, tuttering, el-lipsis, interruptions, hesitations.
Linguisticallyand stylistically they differ from written lan-guage: sentences are shorter and poorly struc-tured, and contain idiomatic expressions, un-grammaticality, etc.
The associated ifficultiesstem from the inherently colloquial nature ofclosed captions, and, to different degrees, ofall forms of transcribed speech (Hindle, 1983).Such difficulties require a different approachthan is taken for written documents.Secondly, closed captions come in a specificformat, which poses problems for their optimalprocessing.
Closed-captioners may often splita single utterance between two screens, if thecharacter limit for a screen has been exceeded.The split is based on consideration about stringlength, rather than linguistic considerations,hence it can happen at non-constituent bound-aries (see Table 1), thus making the real timeprocessing of the separate segments problem-atic.
Another problem is that captions have noupper/lower case distinction.
This poses chal-lenges for proper name recognition since namescannot be identified by an initial capital.
Addi-tionally, we cannot rely on the initial uppercaseletter to identify a sentence initial word.
Thisproblematic aspect sets the domain of closedcaptions apart from most text-to-text MT do-mains, making it more akin, in this respect, tospeech translation systems.
Although, from atechnical point of view, such input format char-acteristics could be amended, most likely theyare not under a developer's control, hence theyhave to be presumed.Thirdly, closed captions are used under oper-ational constraints.
Users have no control overthe speed of the image or caption flow so (s)hemust comprehend the caption in the limitedtime that the caption appears on the screen.Accordingly, the translation of closed captionsis a "time-constrained" application, where theuser has limited time to comprehend the systemoutput.
Hence, an MT system should producetranslations comprehensible within the limitedtime available to the viewer.In this paper we focus on the first two fac-tors, as the third has been discussed in (Tooleet al, 1998).
We discuss how such domain-38good evening, i'm jim lehrer.on the "newshour" tonight, four members of congress debate theu.n.
deal with iraq; paul solman tells the troubled story ofindonesia's currency; markshields and paul gigot analyze the political week;and elizabeth farnsworth explains how the universe is gettinglarger.Table 1: Closed caption script fragment.dependent, problematic factors are dealt within a pre-processing pipeline that prepares theinput for processing by a core MT system.
Thedescribed methods have been implemented foran MT system that translates English closedcaptions to Spanish and Portuguese.
All theexamples here refer to the Spanish module.2 P re -process ing  des ignInput pre-processing is essential in an embeddedreal time system, in order to simplify the coreprocessing and make it both time- and memory-effective.
In addition to this, we followed theguideline of separating domain-dependent pro-cesses and resources from general purpose ones.On the one hand, grammars and lexicons arecostly resources.
It would be desirable for themto be domain-independent a d portable acrossdifferent domains, as well as declarative andbidirectional.
On the other hand, a domain withdistinctive characteristics requires ome specifictreatment, if a system aims at robustness.
Wedecided to have a domain independent core MTsystem, locating the domain dependent process-ing in a pipeline of low-level components, easyto implement, aiming at fast and robust pro-cessing and using limited linguistic knowledge.We use declarative and bidirectional gram-mars and lexicons.
The lexicMist approach isindeed suitable to the closed caption domain,e.g.
in terms of its capability of handling looselystructured or incomplete sentences.
Also, thelinguistic resources are geared towards this do-main in terms of grammatical nd lexical cover-age.
However, our system architecture and for-malism make them equally usable in any otherdomain and translation direction, as the linguis-tic knowledge therein contained is valid in anydomain.
For the architecture we refer the readerto (Popowich et al, 1997).
In the rest of thispaper we focus on the pre-processing module39and how it deals with the issues discussed inthe introduction.The task of the pre-processing pipeline is tomake the input amenable to a linguistically-principled, domain independent reatment.This task is accomplished in two ways:1.
By normalizing the input, i.e.
removingnoise, reducing the input to standard typo-graphical conventions, and also restructur-ing and simplifying it, whenever this can bedone in a reliable, meaning-preserving way.2.
By annotating the input with linguistic in-formation, whenever this can be reliablydone with a shallow linguistic analysis, toreduce input ambiguity and make a full lin-guistic analysis more manageable.Figure (1) shows the system architecture,with a particular emphasis on the pre-processing pipeline.
The next section describesthe pipeline up to tagging.
Proper namerecognition and segmentation, which deal morespecifically with the problems described in theintroduction, are discussed in further sections.3 Normal i za t ion  and  tagg ingThe label normalization groups three compo-nents, which clean up and tokenize the input.The text-level normalization module performsoperations at the string level, such as remov-ing extraneous text and punctuation (e.g.
curlybrackets , used to mark off sound effects), or re-moving periods from abbreviations.
E.g.
:(I) "I went to high school in the u.s.""I went to high school in the usa.
"The tokenizer breaks a line into words.
Thetoken-level normalization recognizes and an-notates tokens belonging to special categoriesPre-processingNormalization\[Text-level normalization \]\[ Tokenization )\[Token-level normalization I+\[ Proper name recognition \]\[ Segmentation "')Core MTsystemAnal' ,sis \]+i I Oo.o a, on I,1\ ]Pos t -process ing  )Figure 1: System architecture.
(times, numbers, etc.
), expands contractions,recognizes, normalizes and annotates tutters(e.g.
b-b-b-bright), identifies compound wordsand converts number words into digits.
E.g.
:(2) "I" "went" "to" "high" "school""in" "the" "usa" " ""I" "went" "to" "high school" "in""the" "usa" " "(3) "W-wh-wha~'s" "that" "?
"0"what"/stutter "is" "that" "?
"Note that annotations associated with tokensare carried along the entire translation process,so as to be used in producing the output (e.g.stutters are re-inserted in the output).The tagger assigns parts of speech to tokens.Part of speech information is used by the subse-quent pre-processing modules, and also in pars-ing, to prioritize the most likely lexical assign-ments of ambiguous items.4 P roper  name recogn i t ionProper names are ubiquitous in closed captions(see Table 1).
Their recognition is importantfor effective comprehension of closed captions,particularly in consideration of two facts: (i)users have little time to mentally rectify a mis-translation; (ii) a name can occur repeatedlyin a program (e.g.
a movie), with an annoy-ing effect if it is systematically mistranslated(e.g.
a golf tournament where the golfer namedTiger Woods is systematically referred to as losbosques del tigre, lit.
'the woods of the tiger').Name recognition is made harder in the closedcaption domain by the fact that no capitaliza-tion information is given, thus making unusableall methods that rely on capitalization as themain way to identify candidates (Wolinski et al,1995) (Wacholder et al, 1997).
For instance, anexpression like 'mark sh ie lds ' ,  as occurs in Ta-ble (1), is problematic in the absence of capital-ization, as both 'mark' and ' sh ie lds '  are three-way ambiguous (proper name, common nounand verb).
Note that this identical problem maybe encountered if an MT system is embeddedin a speech-to-speech translation as well.
Thissituation forced us to explore different ways ofidentifying proper names.The goal of our recognizer is to identifyproper names in a tagged line and annotatethem accordingly, in order to override anyother possiblelexical assignment in the follow-ing modules.
The recognizer also overrides pre-vious tokenization, by possibly compoundingtwo or more tokens into a single one, whichwill be treated as such thereafter.
Besides partof speech, the only other information used bythe recognizer is the lexical status of words, i.e.their ambiguity class (i.e.
the range of possiblesyntactic ategories it can be assigned) or theirstatus as an unknown word (i.e.
a word thatis not in the lexicon).
The recognizer scans aninput line from left to right, and tries to match40each item against a sequences of patterns.
Eachpattern expresses constraints (in terms of word,part of speech tag and lexical status) on theitem under inspection and its left and right con-texts.
Any number of items can be inspected tothe left and right of the current item.
Such pat-terns also make use of regular expression bpera-tors (conjunction, disjunction, negation, Kleenestar).
For instance (a simplified version of) apattern might look like the following:(4) /the/DEW (NOUNIADJ)*\] X' \['NOUN\]where we adopt the convention of representingwords by lowercase strings, part of speech tagsby uppercase strings and variables by primedXs.
The left and right context are enclosedin square brackets, respectively to the left andright of the current item.
They can also con-tain special markers for the beginning and endof a line, and for the left or right boundary ofthe proper name being identified.
This way to-kenization can be overridden and separate to-kens joined into a single name.
Constraints onthe lexical status of items are expressed as pred-icates associated with pattern elements, e.g.
:(5) proper_and_common (X')A pattern like the one above (4-5) wouldmatch a lexically ambiguous proper/commonnoun preceded by a determiner (with any num-ber of nouns or adjectives in between), and notfollowed by a noun (e.g. '
the b i l l  i s .
.
. '
) .
Be-sides identifying proper names, some patternsmay establish that a given item is not a name(as in the case above).
A return value is as-sociated with each pattern, specifying whetherthe current match is or is not a proper name.Once a successful match occurs, no further pat-terns are tried.
Patterns are ordered from moreto less specific.
At the bottom of the patternsequence are the simplest patterns, e.g.
:(6) ( \[\] X' \[\] ), proper_and_common(X')yeswhich is the default assignment for words like'b i l l '  if no other pattern matched.
However(6) is overridden by more specific patterns like:(7) ( \[x''\] x' \[\] ) ,proper_and_common (X'), common(X")no41(s) ( \[x' \]  x' \[\] ) ,proper_and_common(X'), proper(X")yesThe former pattern covers cases like' te lecommunicat ions  b i l l ' ,  preventing'b i l l '  from being interpreted as a propername, the latter covers cases like 'damianb i l l ' ,  where 'b i l l '  is more likely to be a name.In general, the recognizer tries to disam-biguate lexically ambiguous nouns or to as-sign a category to unknown words on the ba-sis of the available context.
However, in prin-ciple any word could be turned into a propername.
For instance, verbs or adjectives canbe turned into proper names, when the con-text contains strong cues, like a title.
Increas-ingly larger contexts provide evidence for moreinformed guesses, which override guesses basedon narrower contexts.
Consider the followingexamples that show how a word or expressionis treated ifferently depending on the availablecontext.
Recognized names are in italics.
(9) biZ~ ~(i0) the bill is ...(11) the b i l l  clinton is .
.
.
(12) the  b i l l  c l in ton  admin is t ra t ion  isThe lexically ambiguous bill, interpreted asa proper name in isolation, becomes a commonnoun if preceded by a determiner.
However,the interpretation reverts to proper name if an-other noun follows.
Likewise the unknown wordclinton is (incorrectly) interpreted as a com-mon noun in (11), as it is the last item of anoun phrase introduced by a determiner, but itbecomes a proper name if another noun follows.We also use a name memory ,  which patternshave access to.
As proper names are found in aninput stream, they are added to the name mem-ory.
A previous occurrence of a proper name isused as evidence in making decisions about fur-ther occurrences.
The idea is to cache namesoccurred in an 'easy' context (e.g.
a name pre-ceded by a title, which provides trong evidencefor its status as a proper name), to use themlater to make decisions in 'difficult' contexts,where the internal evidence would not be suffi-cient to support a proper name interpretation.Hence, what typically happens is that the samename in the same context is interpreted iffer-ently at different imes, if previously the namehas occurred in an 'easy' context and has beenmemorized.
E.g.
:(13) the individual title went to tigerwoods.mr.
tiger woods struggled todaywith a final round 80.name-memorythe short well publicizedprofessional life of t iger  woodshas been an open book.The name memory was designed to suit thepeculiarity of closed captions.
Typically, in thisdomain proper names have a low dispersion.They are concentrated in sections of an inputstream (e.g.
the name of the main charactersin a movie), then disappear for long sections(e.g.
after the movie is over).
Therefore, aname memory needs to be reset to reflect suchchanges.
However, it is problematic to decidewhen to reset the name memory.
Even if it waspossible to detect when a new program starts,one should take into account the possible sce-nario of an MT system embedded in a consumerproduct, in which case the user might unpre-dictably change channel at any time.
In or-der to keep a name memory aligned with thecurrent program, without any detection of pro-gram changes, we structured the name memoryas a relatively short queue (first in, first out).Every time a new item is added to the end ofthe queue, the first item is removed and all theother items are shifted.
Moreover, we do notcheck whether a name is already in the mem-ory.
Every time a suitable item is found, weadd it to the memory, regardless of whether itis already there.
Hence, the same item couldbe present wice or more in the memory at anygiven time.
The result of this arrangement isthat a name only remains in the memory :for arelatively short time.
It can only remain :\[or alonger time if it keeps reappearing frequently inthe input stream (as typically happens), other-wise it is removed shortly after it stopped ap-pearing.
In this way, the name memory is kept42# of itemsProper names correctly identifiedFalse positivesFalse negatives152857Table 2: Name recognition evaluation results.aligned with the current program, with only ashort transition period, during which names nolonger pertinent are still present in the memory,before getting replaced by pertinent ones.The recognizer currently contains 63 pat-terns.
We tested the recognizer on a sample of1000 lines (5 randomly chosen continuous frag-ments of 200 lines each).
The results, shown intable (2), illustrate a recall of 72.7% and a pre-cision of 95.0%.
These results reflect our cau-tious approach to name recognition.
Since thecore MT system has its own means of identify-ing some proper names (either in the lexicon orvia default assignments o unknown words) weaimed at recognizing names in pre-processingonly when this could be done reliably.
Notealso that 6 out of the 8 false positives were iso-lated interjections that would be better left un-translated (e.g.
p f foo ,  e l  smacko), or closedcaptioner's typos (e.g.
yo4swear).5 SegmentationSegmentation breaks a line into one or moresegments, which are passed separately to sub-sequent modules (Ejerhed, 1996) (Beeferman etal., 1997).
In translation, segmentation is ap-plied to split a line into a sequence of transla-tionally self-contained units (Lavie et al, 1996).In our system, the translation units we iden-tify are syntactic units, motivated by cross-linguistic considerations.
Each unit is a con-stituent that dan be translated independently.Its translation is insensitive to the context inwhich the unit occurs, and the order of the unitsis preserved by translation.One motivation for segmenting is that pro-cessing is faster: syntactic ambiguity is reduced,and backtracking from a module to a previ-ous one does not involve re-processing an en-tire line, but only the segment hat failed.
Asecond motivation is robustness: a failure inone segment does not involve a failure in theentire line, and error-recovery can be limitedonly to a segment.
Further motivations are pro-vided by the colloquial nature of closed cap-tions.
A line often contains fragments with aloose syntactic relation to each other and to themain clause: vocatives, false starts, tag ques-tions, etc.
These are most easily translated asindividual segments.
Parenthetical expressionsare often also found in the middle of a mainclause, thus making complete parses problem-atic.
However, the solution involves a heavierintervention than just segmenting.
Dealing withparentheticals requires restructuring a line, andreducing it to a 'normal' form which ideally al-ways has parenthetical expressions at one end ofa sentence (under the empirical assumption thatthe overall meaning is not affected).
We willsee how this kind of problem is handled in seg-mentation.
A third motivation is given by theformat of closed captions, with input lines splitacross non-constituent boundaries.
One solu-tion would be delaying translation until a sen-tence boundary is found, and restructuring thestored lines in a linguistically principled way.However, the requirements of real time transla-tion (either because of real time captioning atthe source, or because the MT system is embed-ded in a consumer product), together with therequirement that translations be aligned withthe source text and, above all, with the images,makes this solution problematic.
The solutionwe are left with, if we want lines to be bro-ken along constituent boundaries, is to furthersegment a sentence, even at the cost of some-times separating elements that should go to-gether for an optimal translation.
We also ar-gued elsewhere (Toole et al, 1998) that in atime-constrained application the output gram-maticality is of paramount importance, even atthe cost of a complete meaning equivalence withthe source.
For this reason, we also simplifylikely problematic input, when a simplificationis possible without affecting the core meaning.To sum up, the task at hand is broader thanjust segmentation: re-ordering of constituentsand removal of words are also required, to syn-tactically 'normalize' the input.
As with namerecognition, we aim at using efficient and easyto implement techniques, relying on limited lin-guistic information.
The segmenter works bymatching input lines against a set of templatesrepresented by pushdown transducers.
Eachtransducer is specified in a fairly standard way(Gazdar and Mellish, 1989, 82), by defining aninitial state, a final state, and a set of transitionsof the following form:(14) (State I, State2, Label, Transducer>Such a transition specifies that Transducercan move from Statel to State2 when the in-put specified by Label is found.
Label can beeither a pair (InputSymbol, OutputSymbol) orthe name of another transducer, which needsto be entirely traversed for the transition fromState l  to State2 to take place.
An input sym-bol is a <Word, Tag> pair.
An output symbolis an integer anging from 0 to 3, specifying towhich of two output segments an input sym-bol is assigned (0 = neither segment, 3 = bothsegments, 1 and 2 to be interpreted in the ob-vious way).
The output codes are then used toperform the actual split of a line.
A successfulmatch splits a line into two segments at most.However, on a successful split, the resulting seg-ments are recursively fed to the segmenter, untilno match is found.
Therefore, there is no limitto the number of segments obtained from aninput line.
The segmenter currently contains37 top-level transducers, i.e.
segmenting pat-terns.
Not all of them are used at the same time.The implementation of patterns is straightfor-ward and the segmenter can be easily adaptedto different domains, by implementing specificpatterns and excluding others.
For instance, avery simple patterns plit a line at every comma,a slightly more sophisticated one, splits a line atevery comma, unless tagged as a coordination;other patterns plit a final adverb, interjection,prepositional phrase, etc.Note that a segment can be a discontinuouspart of a line, as the same output code can beassigned to non-contiguous elements.
This fea-ture is used, e.g., in restructuring a sentence, aswhen a parenthetical expression is encountered.Thefollowing example shows an input sentence,an assignment, and a resulting segmentation.
(15) this, however, is a politicalscience course.
(16) this/2 ,/0 however/l ,/i is/2 a/2political/2 science/2 course/2.
(17) I. however ,432. this is a po l i t ica l  sc iencecourseWe sometimes use the segmenter's ability tosimplify the input, e.g.
with adverbs like just,which are polysemous and difficult to translate,but seldom contribute to the core meaning of asentence.6 Per fo rmanceWe ran a test to evaluate how the recognizerand segmenter affected the quality of transla-tions.
We selected asample of 200 lines of closedcaptioning, comprising four continuous sectionsof 50 lines each.
The sample was run throughthe MT system twice, once with the recognizerand segmenter activated and once without.
Theresults were evaluated by two native Spanishspeakers.
We adopted a very simple evalua-tion measure, asking the subjects to tell whetherone translation was better than the other.
Thetranslations differed for 32 input lines out of 200(16%).
Table (3) shows the evaluation results,with input lines as the unit of measurement.The third column shows the intersection of thetwo evaluations, i.e.
the evaluations on whichthe two subjects agreed.
The three rows showhow often the translation was better (i) withpre-processing, (ii) without pre-processing, or(iii) no difference could be appreciated.The results show a discrepancy in the evalu-ations.
One evaluator also pointed out that itis hard to make sense of transcribed closed cap-tions, without the audio-visual context.
Thesetwo facts seem to point out that an appropri-ate evaluation should be done in the operationalcontext in which closed captions are normallyused.
Still, the intersection of the subjects' eval-uations shows that pre-processing improves theoutput quality.
In three of the four cases wherethe two evaluators agreed that pre-processingyielded a worse result, the worse performancewas due to an incorrect name recognition oi" seg-mentation.
However, in two of the three cases,the original problem was an incorrect agging.Note that even when the name recognizerand segmenter are off, the system can identifysome names, and recover from translation fail-ures by piecing together translations of frag-ments.
Therefore, what was being tested wasnot so much name recognition and segmenting44per se, but the idea of having separate modulesfor such tasks in the system front end.Finally, the test did not take into accountspeed, as we set higher time thresholds thanan embedded application would require.
Sincesegmentation reduces processing time, it is alsoexpected to reduce the impact of tighter timethresholds, all other things being equal.We are planning to conduct an operationalevaluation of the system.
The goal is to evalu-ate the system output in its proper visual con-text, and compare the results with parallel re-sults for human translated closed captions.
Dif-ferent groups of participants will watch a videoWith either human- or machine-translated sub-titles, and complete a questionnaire based onthe subtitles in the video.
The questionnairewill contain a set of questions to elicit the sub-ject's assessment on the translation quality, anda set of questions to assess the subject's level ofcomprehension f the program.7 Conc lus ionIt is apparent hat the peculiarity of closedcaptions, both in terms of transcribed speechcharacteristic and constraints due to the inputformat, require an ad hoc treatment, consider-ably different from the approaches suitable forwritten documents.
Yet the knowledge abouta language (or the bilingual knowledge abouta language-pair) is largely invariant across dif-ferent applications domains and should there-fore be portable from one application domainto another.
The architecture we have proposedstrives to combine the need for domain indepen-dent linguistic resources and linguistically prin-cipled methods with the need for robust MTsystems tuned to real world, noisy and idiosyn-cratic input, as encountered when embeddingMT in real woi:ld devices.In terms of adequacy, a standard evaluationand a comparison among different MT systemsfrtom different domains is hard, as the ade-quacy of a system depends on its application(Church and Hovy, 1993).
This is even truerwith-closed captions, where the use of transla-tion output is heavily influenced by operationalconstraints (time constraints, the presence ofimages, sound, etc.).
In some cases such con-straints may place a heavier burden on a system(e.g.
the time constraint), in some other casesJudge 1 Judge 2 Both agreedBetter with pre~processingBetter without pre-processingNo difference21 16 154 12 47 4 3Table 3: Evaluation results.they can make an imperfect ranslation accept-able (e.g.
the presence of images and sounds).We did not attempt an assessment in absoluteterms, which we believe should take into ac-count the operational environment and involvereal-world users.
More modestly, we aimed atshowing that our pre-processing techniques pro-vide an improvement in performance.Our work on closed captions also shows thatthe challenges coming from this domain, evenin terms on low-level issues of input format, canlead to interesting developments of new linguis-tic techniques.
We believe that our solutions tospecific problems (namely, proper name recog-nition and segmentation) in the closed captiondomain bear relevance to a wider context, andoffer techniques that can be usefully employedin a wider range of applications.Re ferencesDoug Beeferman, Adam Berger, and John Laf-ferty.
1997.
Text segmentation using expo-nential models.
In Proceedings of the SecondConference on Empirical Methods in Natu-ral Language Processing (EMNLP-2), Prov-idence, USA.Kenneth W. Church and Eduard H. Hovy.1993.
Good applications for crummy machinetranslation.
Machine Translation, 8:239-258.Eva Ejerhed.
1996.
Finite state segmentationof discourse into clauses.
In A. Kornai, ed-itor, Proceedings of the ECAI-96 WorkshopExtended Finite State Models of Language,Budapest,Hungary.Gerald Gazdar and Christopher S. Mellish.1989.
Natural Language Processing in PRO-LOG: an Introduction to Computational Lin-guistics.
Addison-Wesley Publishing Com-pany, Wokingham, England.Donald Hindle.
1983.
Deterministic parsing ofsyntactic non-fluencies.
In Proceedings ofthe21st Annual Meeting of the Association forComputational Linguistics (ACL-83), pages123-128, Cambridge, Massachusetts, USA.Alon Lavie, Donna Gates, Noah Coccaro, andLori Levin.
1996.
Input segmentation ofspontaneous peech in janus: a speech-to-speech translation system.
In Proceed-ings of ECAI-96 Workshop on Dialogue Pro-cessing in Spoken Language Systems, Bu-dapest,Hungary.Eric Nyberg and Teruko Mitamura.
1997.
Areal-time MT system for translating broad-cast captions.
In Proceedings ofthe Sixth Ma-chine Translation Summit, pages 51-57, SanDiego, California, USA.Fred Popowich, Davide Turcato, Olivier Lau-rens, Paul McFetridge, J. Devlan Nicholson,Patrick McGivern, Maricela Corzo-Pena, LisaPidruchney, and Scott MacDonald.
1997.
Alexicalist approach to the translation of collo-quial text.
In Proceedings ofthe 7th Interna-tional Conference on Theoretical nd Method-ological Issues in Machine Translation, pages76-86, Santa Fe, New Mexico, USA.Janine Toole, Davide Turcato, Fred Popowich,Dan Fass, and Paul McFetridge.
1998.
Time-constrained Machine Translation.
In Proceed-ings of the Third Conference of the Associa-tion for Machine Translation in the Ameri-cas (AMTA-98), pages 103-112, Langhorne,Pennsylvania, USA.Nina Wacholder, Yael Ravin, and Misook Choi.?
1997.
Disambiguation of proper names intexts.
In Proceedings of the Fifth Confer-ence on Applied Natural Language Processing(ANLP-97), pages 202-208, Washington, DC,USA.
Association for Computational Linguis-tics.Francis Wolinski, Frantz Vichot, and Bruno Dil-let.
1995.
Automatic processing of propernames in texts.
In Proceedings of the 7thConference of the European Chapter of theAsscociation for Computational Linguistics(EACL-95), pages 23-30, Dublin, Ireland.45
