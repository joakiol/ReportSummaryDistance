Proceedings of the 6th Workshop on Statistical Machine Translation, pages 365?371,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsCMU Syntax-Based Machine Translation at WMT 2011Greg Hanneman and Alon LavieLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213 USA{ghannema, alavie}@cs.cmu.eduAbstractWe present the Carnegie Mellon UniversityStat-XFER group submission to the WMT2011 shared translation task.
We built a hy-brid syntactic MT system for French?Englishusing the Joshua decoder and an automati-cally acquired SCFG.
New work for this yearincludes training data selection and grammarfiltering.
Expanded training data selectionsignificantly increased translation scores andlowered OOV rates, while results on grammarfiltering were mixed.1 IntroductionDuring the past year, the statistical transfer ma-chine translation group at Carnegie Mellon Univer-sity has continued its work on large-scale syntacticMT systems based on automatically acquired syn-chronous context-free grammars (SCFGs).
For the2011 Workshop on Machine Translation, we builta hybrid MT system, including both syntactic andnon-syntactic rules, and submitted it as a constrainedentry to the French?English translation task.
Thisis our fourth yearly submission to the WMT sharedtranslation task.In design and construction, the system is sim-ilar to our submission from last year?s workshop(Hanneman et al, 2010), with changes in the meth-ods we employed for training data selection andSCFG filtering.
Continuing WMT?s general trend,we worked with more data than in previous years,basing our 2011 system on 13.9 million sentencesof parallel French?English training data and an En-glish language model of 1.8 billion words.
Decod-ing was carried out in Joshua (Li et al, 2009), anopen-source framework for parsing-based MT.
Wemanaged our experiments with LoonyBin (Clark andLavie, 2010), an open-source tool for defining, mod-ifying, and running complex experimental pipelines.We describe our system-building process in moredetail in Section 2.
In Section 3, we evaluate the sys-tem?s performance on WMT development sets andexamine the aftermath of training data selection andgrammar filtering.
Section 4 concludes with possi-ble directions for future work.2 System Construction2.1 Training Data SelectionWMT 2011?s provided French?English training dataconsisted of 36.8 million sentence pairs from the Eu-roparl, news commentary, UN documents, and Giga-FrEn corpora (Table 1).
The first three of these are,for the most part, clean data resources that have beensuccessfully employed as MT corpora for a numberof years.
The Giga-FrEn corpus, though the largest,is also the least precise, as its Web-crawled datasources are less homogeneous and less structuredthan the other corpora.
Nevertheless, Pino et al(2010) found significant improvements in French?English MT output quality by including it.
Our goalfor this year was to strike a middle ground: to avoidcomputational difficulties in using the entire 36.8million sentence pairs of training data, but to minethe Giga-FrEn corpus for sentences to increase oursystem?s vocabulary coverage.Our method of training data selection proceededas follows.
We first tokenized all the parallel training365Corpus Released UsedEuroparl 1,825,077 1,614,111News commentary 115,562 95,138UN documents 12,317,600 9,352,232Giga-FrEn 22,520,400 2,839,466Total 36,778,639 13,900,947Table 1: Total number of training sentence pairs released,by corpus, and the number used in building our system.data using the Stanford parser?s tokenizer (Klein andManning, 2003) for English and our own in-housescript for French.
We then passed the Europarl, newscommentary, and UN data through a filtering scriptthat removed lines longer than 95 tokens in eitherlanguage, empty lines, lines with excessively imbal-anced length ratios, and lines containing tokens ofmore than 25 characters in either language.
Fromthe filtered data, we computed a list of the source-side vocabulary words along with their frequencycounts.
Next, we searched the Giga-FrEn corpus forrelatively short lines on the source side (up to 50 to-kens long) that contained either a new vocabularyword or a word that had been previously seen fewerthan 20 times.
Such lines were added to the filteredtraining data to make up our system?s final paralleltraining corpus.The number of sentences retained from each datasource is listed in Table 1; in the end, we trained oursystem from 13.9 million parallel sentences.
Withthe Giga-FrEn data included, the source side of ourparallel corpus had a vocabulary of just over 1.9million unique words, compared with a coverage of545,000 words without using Giga-FrEn.We made the decision to leave the training data inmixed case for our entire system-building process.At the cost of slightly sparser estimates for wordalignments and translation probabilities, a mixed-case system avoids the extra step of building a sta-tistical recaser to treat our system?s output.2.2 Grammar Extraction and ScoringOnce we had assembled the final training corpus,we annotated it with statistical word alignments andconstituent parse trees on both sides.
Unidirec-tional word alignments were provided by MGIZA++(Gao and Vogel, 2008), then symmetrized with thegrow-diag-final-and heuristic (Koehn et al, 2005).For generating parse trees, we used the French andEnglish grammars of the Berkeley statistical parser(Petrov and Klein, 2007).Except for minor bug fixes, our method for ex-tracting and scoring a translation grammar remainsthe same as in our WMT 2010 submission.
We ex-tracted both syntactic and non-syntactic portions ofthe translation grammar.
The non-syntactic gram-mar was extracted from the parallel corpus andword alignments following the standard heuristicsof phrase-based SMT (Koehn et al, 2003).
Thesyntactic grammar was produced using the methodof Lavie et al (2008), which decomposes each pairof word-aligned parse trees into a series of minimalSCFG rules.
The word alignments are first gener-alized to node alignments, where nodes s and t arealigned between the source and target parse trees ifall word alignments in the yield of s land withinthe yield of t and vice versa.
Minimal SCFG rulesare derived from adjacent levels of node alignments:the labels from each pair of aligned nodes forms arule?s left-hand side, and the right-hand side is madeup of the labels from the frontier of aligned nodesencountered when walking the left-hand side?s sub-trees.
Within a phrase length limit, each alignednode pair generate an all-terminal phrase pair ruleas well.Since both grammars are extracted from the sameViterbi word alignments using similar alignmentconsistency constraints, the phrase pair rules fromthe syntactic grammar make up a subset of the rulesextracted according to phrase-based SMT heuristics.We thus share instance counts between identicalphrases extracted in both grammars, then delete thenon-syntactic versions.
Remaining non-syntacticphrase pairs are converted to SCFG rules, with thephrase pair forming the right-hand side and thedummy label PHR::PHR as the left-hand side.
Ex-cept for the dummy label, all nonterminals in the fi-nal SCFG are made up of a syntactic category labelfrom French joined with a syntactic category labelfrom English, as extracted in the syntactic grammar.A sampling of extracted SCFG rules is shown in Fig-ure 1.The combined grammar was scored according tothe 22 translation model features we used last year.For a generic SCFG rule of the form ?s :: ?t ?366PHR :: PHR ?
[, ainsi qu?]
:: [as well as]V :: VBN ?
[modifie?es] :: [modified]NP :: NP ?
[les conflits arme?s] :: [armed conflict]AP :: SBAR ?
[tel qu?
VPpart1] :: [as VP1]NP :: NP ?
[D1 N2 A3] :: [CD1 JJ3 NNS2]Figure 1: Sample extracted SCFG rules.
They includenon-syntactic phrase pairs, single-word and multi-wordsyntactic phrase pairs, partially lexicalized hierarchicalrules, and fully abstract hierarchical rules.
[rs ] :: [rt ], we computed 11 maximum-likelihoodfeatures as follows:?
Phrase translation scores P (rs | rt) andP (rt | rs) for phrase pair rules, using the largernon-syntactic instance counts for rules thatwere also extracted syntactically.?
Hierarchical translation scores P (rs | rt) andP (rt | rs) for syntactic rules with nonterminalson the right-hand side.?
Labeling scores P (?s :: ?t | rs), P (?s :: ?t | rt),and P (?s :: ?t | rs, rt) for syntactic rules.?
?Not syntactically labelable?
scores P (?s ::?t = PHR :: PHR | rs) and P (?s :: ?t =PHR :: PHR | rt), with additive smoothing(n = 1), for all rules.?
Bidirectional lexical scores for all rules withlexical items, calculated from a unigram lexi-con over Viterbi-aligned word pairs as in theMoses decoder (Koehn et al, 2007).We also included the following 10 binary indicatorfeatures using statistics local to each rule:?
Three low-count features that equal 1 when theextracted frequency of the rule is exactly equalto 1, 2, or 3.?
A syntactic feature that equals 1 when the rule?slabel is syntactic, and a corresponding non-syntactic feature that equals 1 when the rule?slabel is PHR::PHR.?
Five rule format features that equal 1 when therule?s right-hand side has a certain composi-tion.
If as and at are true when the source andtarget sides contain only nonterminals, respec-tively, our rule format features are equal to as,at, as ?
a?t, a?s ?
at, and a?s ?
a?t.Finally, our model includes a glue rule indicator fea-ture that equals 1 when the rule is a generic gluerule.
In the Joshua decoder, glue rules monotoni-cally stitch together adjacent parsed translation frag-ments at no model cost.2.3 Language ModelingThis year, our constrained-track system made use ofpart of the English Gigaword data, along with otherprovided text, in its target-side language model.From among the data released directly for WMT2011, we used the English side of the Europarl,news commentary, French?English UN document,and English monolingual news corpora.
From theEnglish Gigaword corpus, we included the entireXinhua portion and the most recent 13 million sen-tences of the AP Wire portion.
Some of these cor-pora contain many lines that are repeated a dispro-portionate number of times ?
the monolingual newscorpus in particular, when filtered to only one oc-currence of each sentence, reaches only 27% of itsoriginal line count.
As part of preparing our lan-guage modeling data, we deduplicated both the En-glish news and the UN documents, the corpora withthe highest percentages of repeated sentences.
Wealso removed lines containing more than 750 char-acters (about 125 average English words) before to-kenization.The final prepared corpus was made up of approx-imately 1.8 billion words of running text.
We builta 5-gram language model from it with the SRI lan-guage modeling toolkit (Stolcke, 2002).
To matchthe treatment given to the training data, the languagemodel was also built in mixed case.2.4 Grammar Filtering for DecodingAs is to be expected from a training corpus of 13.9million sentence pairs, the grammars we extract ac-cording to the procedure of Section 2.2 are quitelarge: approximately 2.53 billion non-syntactic and440 million syntactic rule instances, for a combinedgrammar of 1.26 billion unique rules.
In preparationfor tuning or decoding, we are faced with the engi-neering challenge of selecting a subset of the gram-367mar that contains useful rules and fits in a reasonableamount of memory.Before even extracting a syntactic grammar, wepassed the automatically generated parse trees on thetraining corpus through a small tag-correction scriptas a pre-step.
In previous experimentation, we no-ticed that a surprising proportion of cardinal num-bers in English had been tagged with labels otherthan CD, their correct tag.
We also found errors inlabeling marks of punctuation in both English andFrench, when again the canonical labels are unam-biguous.
To fix these errors, we forcibly overwrotethe labels of English tokens made up of only digitswith CD, and we overwrote the labels of 25 Englishand 24 French marks of punctuation or other sym-bols with the appropriate tag as defined by the rele-vant treebank tagging guidelines.After grammar extraction and combination ofsyntactic and non-syntactic rules, we ran an addi-tional filtering step to reduce derivational ambiguityin the case where the same SCFG right-hand side ap-peared with more than one left-hand-side label.
Foreach right-hand side, we sorted its possible labels byextracted frequency, then threw out the labels in thebottom 10% of the left-hand-side distribution.Finally, we ran a main grammar filtering step priorto tuning or decoding, experimenting with two dif-ferent filtering methods.
In both cases, the phrasepair rules in the grammar were split off and filteredso that only those whose source sides completelymatched the tuning or test set were retained.The first, more naive grammar filtering methodsorted all hierarchical rules by extracted frequency,then retained the most frequent 10,000 rules to joinall matching phrase pair rules in the final translationgrammar.
This is similar to the basic grammar filter-ing we performed for our WMT 2010 submission.It is based on the rationale that the most frequentlyextracted rules in the parallel training data are likelyto be the most reliably estimated and also frequentlyused in translating a new data set.
However, it alsopasses through a disproportionate number of fullyabstract rules ?
that is, rules whose right-hand sidesare made up entirely of nonterminals ?
which canapply more recklessly on the test set because theyare not lexically grounded.Our second, more advanced method of filteringmade two improvements over the naive approach.First, it controlled for the imbalance of hierarchi-cal rules by splitting the grammar?s partially lexical-ized rules into a separate group that can be filteredindependently.
Second, it applied a lexical-matchfilter such that a partially lexicalized rule was re-tained only if all its lexicalized source phrases upto bigrams matched the intended tuning or testingset.
The final translation grammar in this case wasmade up of three parts: all phrase pair rules match-ing the test set (as before), the 100,000 most fre-quently extracted partially lexicalized rules whosebigrams match the test set, and the 2000 most fre-quently extracted fully abstract rules.3 Experimental Results and AnalysisWe tuned each system variant on the newstest2008data set, using the Z-MERT package (Zaidan, 2009)for minimum error-rate training to the BLEU metric.We ran development tests on the newstest2009 andnewstest2010 data sets; Table 2 reports the resultsobtained according to various automatic metrics.The evaluation consists of case-insensitive scoringaccording to METEOR 1.0 (Lavie and Denkowski,2009) tuned to HTER with the exact, stemming,and synonymy modules enabled, case-insensitiveBLEU (Papineni et al, 2002) as implemented bythe NIST mteval-v13 script, and case-insensitiveTER 0.7.25 (Snover et al, 2006).Table 2 gives comparative results for two majorsystems: one based on our WMT 2011 data selec-tion as outlined in Section 2.1, and one based onthe smaller WMT 2010 training data that we usedlast year (8.6 million sentence pairs).
Each systemwas run with the two grammar filtering variants de-scribed in Section 2.4: the 10,000 most frequentlyextracted hierarchical rules of any type (?10k?
), anda combination of the 2000 most frequently extractedabstract rules and the 100,000 most frequently ex-tracted partially lexicalized rules that matched thetest set (?2k+100k?).
Our primary submission to theWMT 2011 shared task was the fourth line of Ta-ble 2 (?WMT 2011 2k+100k?
); we also made a con-strastive submission with the system from the sec-ond line (?WMT 2010 2k+100k?
).Using part of the Giga-FrEn data ?
along withthe additions to the Europarl, news commentary,and UN document courses released since last year368newstest2009 newstest2010System METEOR BLEU TER METEOR BLEU TERWMT 2010 10k 54.94 24.77 56.53 56.66 25.78 55.06WMT 2010 2k+100k 55.16 24.88 56.19 56.89 26.05 54.66WMT 2011 10k 55.82 26.02 54.77 58.13 27.71 52.96WMT 2011 2k+100k 55.77 26.01 54.70 57.88 27.38 53.04Table 2: Development test results for systems based on WMT 2010 data (without the Giga-FrEn corpus) and WMT2011 data (with some Giga-FrEn).
The fourth line is our primary shared-task submission.Applications 10k 2k+100kUnique rules 1,305 1,994Rule instances 14,539 12,130Table 3: Summary of 2011 system syntactic rule applica-tions on both test sets.?
is beneficial to translation quality, as there isa clear improvement in metric scores between the2010 and 2011 systems.
Our BLEU score improve-ments of 1.2 to 1.9 points are statistically significantaccording to the paired bootstrap resampling method(Koehn, 2004) with n = 1000 and p < 0.01.
Theyare also larger than the 0.7- to 1.1-point gains re-ported by Pino et al (2010) when the full Giga-FrEnwas added.
The 2011 system also shows a signifi-cant reduction in the out-of-vocabulary (OOV) rateon both test sets: 38% and 47% fewer OOV types,and 44% and 45% fewer OOV tokens, when com-pared to the 2010 system.Differences between grammar filtering tech-niques, on the other hand, are much less signifi-cant according to all three metrics.
Under pairedbootstrap resampling on the newstest2009 set, thegrammar variants in both the 2010 and 2011 systemsare statistically equivalent according to BLEU score.On newstest2010, the 2k+100k grammar improvesover the 10k version (p < 0.01) in the 2010 system,but the situation is reversed in the 2011 system.We investigated differences in grammar use withan analysis of rule applications in the two variantsof the 2011 system, the results of which are summa-rized in Table 3.
Though the configuration with the2k+100k grammar does apply syntactic rules 20%more frequently than its 10k counterpart, the 10ksystem uses overall 53% more unique rules.
Onecontributing factor to this situation could be that thefully abtract rule cutoff is set too low compared tothe increase in partially lexicalized rules.
The ef-fect of the 2k+100k filtering is to reduce the numberof abstract rules from 4000 to 2000 while increas-ing the number of partially lexicalized rules from6000 to 100,000.
However, we find that the 10ksystem makes heavy use of some short, meaningfulabstract rules that were excluded from the 2k+100ksystem.
The 2k+100k grammar, by contrast, in-cludes a long tail of less frequently used partiallylexicalized grammar rules.In practice, there is a balance between the useof syntactic and non-syntactic grammar rules dur-ing decoding.
We highlight an example of howboth types of rules work together in Figure 2, whichshows our primary system?s translation of part ofnewstest2009 sentence 2271.
The French sourcetext is given in italics and segmented into phrases.The SCFG rules used in translation are shownabove each phrase, where numerical superscripts onthe nonterminal labels indicate those constituents?relative ordering in the original French sentence.
(Monotonic glue rules are not shown.)
While non-syntactic rules can be used for short-distance re-ordering and fixed phrases, such as te?le?phones mo-biles ?
mobile phones, the model prefers syntac-tic translations for more complicated patterns, suchas the head?children reversal in appareils musicauxportables ?
portable music devices.4 Conclusions and Future WorkCompared to last year, the two main differences inour current WMT submission are: (1) a new train-ing data selection strategy aimed at increasing sys-tem vocabulary without hugely increasing corpussize, and (2) a new method of grammar filtering thatemphasizes partially lexicalized rules over fully ab-369PHR::PHRyoung people whoPHR::PHRfrequently useNP::NPN::NNS1devicesA::NN2musicA::JJ3portablePHR::PHRand mobile phonesjeunes qui utilisent fre?quemment des appareils musicaux portables et des te?le?phones mobilesPHR::PHRat fullN::NNvolume,::,,V::MDcanVPpart::VPNP::NP3N::NN2hearingD::PRP$1theirV::VBG1damagingADV::RB2unknowinglya` plein volume , puissent endommager inconsciemment leur auditionFigure 2: Our primary submission?s translation of a partial sentence from the newstest2009 set, showing a combinationof syntactic and non-syntactic rules.stract ones.Based on the results presented in Section 3, wefeel confident in declaring vocabulary-based filter-ing of the Giga-FrEn corpus a success.
By increas-ing the size of our parallel corpus by 26%, we morethan tripled the number of unique words appearingin the source text.
In conjunction with supplementsto the Europarl, news commentary, and UN docu-ment corpora, this improvement led to 44% fewerOOV tokens at decoding time on two different testsets, as well as a boost in automatic metric scoresof 0.6 METEOR, 1.2 BLEU, and 1.5 TER pointscompared to last year?s system.
We expect to em-ploy similar data selection techniques when buildingfuture systems, especially as the amount of paralleldata available continues to increase.We did not, however, find significant improve-ments in translation quality by changing the gram-mar filtering method.
As discussed in Section 3, lim-iting the grammar to only 2000 fully abstract rulesmay not have been enough, since additional abstractrules applied fairly frequently in test data if theywere available.
We plan to experiment with largerfiltering cutoffs in future work.
A complementarysolution could be to increase the number of par-tially lexicalized rules.
Although we found mixedresults in their application within our current sys-tem, the success of Hiero-derived MT systems (Chi-ang, 2005; Chiang, 2010) shows that high transla-tion quality can be achieved with rules that are onlypartially abstract.
A major difference between suchsystems and our current implementation is that ours,at 102,000 rules, has a much smaller grammar.AcknowledgmentsThis research was supported in part by U.S. Na-tional Science Foundation grants IIS-0713402 andIIS-0915327, as well as by the DARPA GALE pro-gram.
Thanks to Kenneth Heafield for processingthe English monolingual data and building the lan-guage model file, and to Jonathan Clark for Loony-Bin support and bug fixes.
We also thank Yahoo!for the use of the M45 research computing clus-ter, where we ran many steps of our experimentalpipeline.ReferencesDavid Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofthe 43rd Annual Meeting of the ACL, pages 263?270,Ann Arbor, MI, June.David Chiang.
2010.
Learning to translate with sourceand target syntax.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, pages 1443?1452, Uppsala, Sweden, July.370Jonathan Clark and Alon Lavie.
2010.
LoonyBin: Keep-ing language technologists sane through automatedmanagement of experimental (hyper)workflows.
InProceedings of the Seventh International Conferenceon Language Resources and Evaluation, pages 1301?1308, Valletta, Malta, May.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engineer-ing, Testing, and Quality Assurance for Natural Lan-guage Processing, pages 49?57, Columbus, OH, June.Greg Hanneman, Jonathan Clark, and Alon Lavie.
2010.Improved features and grammar selection for syntax-based MT.
In Proceedings of the Joint Fifth Workshopon Statistical Machine Translation and MetricsMATR,pages 82?87, Uppsala, Sweden, July.Dan Klein and Christopher D. Manning.
2003.
Fast exactinference with a factored model for natural languageparsing.
In Advances in Neural Information Process-ing Systems 15, pages 3?10.
MIT Press, Cambridge,MA.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT-NAACL 2003, pages 48?54, Edmonton,Alberta, May?June.Philipp Koehn, Amittai Axelrod, Alexandra BirchMayne, Chris Callison-Burch, Miles Osborne, andDavid Talbot.
2005.
Edinburgh system descriptionfor the 2005 IWSLT speech translation evaluation.
InProceedings of IWSLT 2005, Pittsburgh, PA, October.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the ACL 2007 Demo and Poster Sessions, pages177?180, Prague, Czech Republic, June.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP 2004, pages 388?395, Barcelona, Spain, July.Alon Lavie and Michael J. Denkowski.
2009.
TheMETEOR metric for automatic evaluation of machinetranslation.
Machine Translation, 23(2?3):105?115.Alon Lavie, Alok Parlikar, and Vamshi Ambati.
2008.Syntax-driven learning of sub-sentential translationequivalents and translation rules from parsed parallelcorpora.
In Proceedings of the Second ACL Work-shop on Syntax and Structure in Statistical Transla-tion, pages 87?95, Columbus, OH, June.Zhifei Li, Chris Callison-Burch, Chris Dyer, JuriGanitkevitch, Sanjeev Khudanpur, Lane Schwartz,Wren N.G.
Thornton, Jonathan Weese, and Omar F.Zaidan.
2009.
Joshua: An open source toolkit forparsing-based machine translation.
In Proceedings ofthe Fourth Workshop on Statistical Machine Transla-tion, pages 135?139, Athens, Greece, March.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automatic eva-lution of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia, PA,July.Slav Petrov and Dan Klein.
2007.
Improved inferencefor unlexicalized parsing.
In Proceedings of NAACLHLT 2007, pages 404?411, Rochester, NY, April.Juan Pino, Gonzalo Iglesias, Adria` de Gispert, GraemeBlackwood, Jaime Brunning, and William Byrne.2010.
The CUED HiFST system for the WMT10translation shared task.
In Proceedings of the JointFifth Workshop on Statistical Machine Translationand MetricsMATR, pages 155?160, Uppsala, Sweden,July.Matthew Snover, Bonnie Dorr, Richard Schwartz, LinneaMicciulla, and John Makhoul.
2006.
A study of trans-lation edit rate with targeted human annotation.
InProceedings of the Seventh Conference of the Associ-ation for Machine Translation in the Americas, pages223?231, Cambridge, MA, August.Andreas Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In Proceedings of the SeventhInternational Conference on Spoken Language Pro-cessing, pages 901?904, Denver, CO, September.Omar F. Zaidan.
2009.
Z-MERT: A fully configurableopen source tool for minimum error rate training ofmachine translation systems.
The Prague Bulletin ofMathematical Linguistics, 91:79?88.371
