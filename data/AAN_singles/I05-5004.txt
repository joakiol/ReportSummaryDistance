A Class-oriented Approach to Building a Paraphrase CorpusAtsushi FujitaGraduate School of Informatics,Kyoto Universityfujita@pine.kuee.kyoto-u.ac.jpKentaro InuiGraduate School of Information Science,Nara Institute of Science and Technologyinui@is.naist.jpAbstractTowards deep analysis of composi-tional classes of paraphrases, we haveexamined a class-oriented frameworkfor collecting paraphrase examples, inwhich sentential paraphrases are col-lected for each paraphrase class sep-arately by means of automatic can-didate generation and manual judge-ment.
Our preliminary experiments onbuilding a paraphrase corpus have sofar been producing promising results,which we have evaluated according tocost-efficiency, exhaustiveness, and re-liability.1 IntroductionParaphrases are alternative ways of conveying thesame content.
The technology for paraphrasegeneration and recognition has drawn the atten-tion of an increasing number of researchers be-cause of its potential contribution to a broad rangeof natural language applications.Paraphrases can be viewed as monolingualtranslations.
From this viewpoint, research onparaphrasing has adapted techniques fostered inthe literature of machine translation (MT), suchas transformation algorithms (Lavoie et al, 2000;Takahashi et al, 2001), corpus-based techniquesfor paraphrase pattern acquisition (Barzilay andMcKeown, 2001; Shinyama and Sekine, 2003;Quirk et al, 2004), and fluency measurements(Lapata, 2001; Fujita et al, 2004).One thing the paraphrasing community is stilllacking is shared collections of paraphrase ex-amples that could be used to analyze problemsunderlying the tasks and to evaluate the perfor-mance of systems under development.
To our bestknowledge, the paraphrase corpus developed byDolan et al (2004) is one of the very few collec-tions available for free1.
Development of para-phrase corpora raises several issues: what sortsof paraphrases should be collected, where para-phrase examples can be obtained from, how thecoverage and quality of the corpus can be ensured,how manual annotation cost can be effectively re-duced, and how collected examples should be or-ganized and annotated.Obviously these issues should be discussedwith the purpose of each individual corpus takeninto account.
In this paper, we address the is-sues of building a gold-standard corpus that is tobe used to evaluate paraphrase generation modelsand report on our preliminary experiences takingJapanese as a target language.
Our approach ischaracterized by the following:?
We define a set of paraphrase classes basedon the syntactic features of transformationpatterns.?
We separately collect paraphrase examplesfor each paraphrase class that are consideredto be linguistically explainable.?
We use a paraphrase generation system toexhaustively collect candidate paraphrasesfrom a given text collection, which are thenmanually labeled.15801 sentence pairs from their comparable corpus havebeen judged manually and available fromhttp://research.microsoft.com/research/nlp/msr paraphrase.htm252 GoalParaphrases exhibit a wide variety of patternsranging from lexical paraphrases to syntactictransformations and their combinations.
Someof them are highly inferential or idiomatic anddo not seem easy to generate only with syntacticand semantic knowledge.
Such groups of para-phrases require us to pursue corpus-based acquisi-tion methods such as those described in Section 3.More importantly, however, we can also findquite a few patterns of paraphrases that exhibit adegree of regularity.
Those groups of paraphraseshave a potential to be compositionally explainedby combining syntactic and semantic propertiesof their constituent words.
For instance, the fol-lowing paraphrases2 in Japanese are considered tobe of these groups.
(1) s. eiga-ni shigeki-o uke-ta.film-DAT inspiration-ACC to receive-PASTI received an inspiration from the film.t.
eiga-ni shigeki-s-are-ta.film-DAT to inspire-PASS-PASTI was inspired by the film.
(2) s. sentakumono-ga soyokaze-ni yureru.laundry-NOM breeze-DAT to sway-PRESThe laundry sways in the breeze.t.
soyokaze-ga sentakumono-o yurasu.breeze-NOM laundry-ACC to sway-PRESThe breeze makes the laundry sways.
(3) s. glass-ni mizu-o mitashi-ta.glass-DAT water-ACC to fill-PASTI filled water into the glass.t.
glass-o mizu-de mitashi-ta.glass-ACC water-IMP to fill-PASTI filled the glass with water.
(4) s. kare-wa kikai-sousa-ga jouzu-da.he-TOP machine operation-NOM be good-PRESHe is good at machine operation.t.
kare-wa kikai-o jouzu-ni sousa-suru.he-TOP machine-ACC well-ADV to operate-PRESHe operates machines well.
(5) s. heya-wa mou atatamat-teiru.room-TOP already to be warmed-PERFThe room has already been warmed up.t.
heya-wa mou atatakai.room-TOP already be warm-PRESThe room is warm.2For each example, ?s?
and ?t?
denote an original sen-tence and its paraphrase, respectively.In example (1), a verb phrase, ?shigeki-o uke-ta (to receive an inspiration),?
is paraphrased intoa verbalized form of the noun, ?shigeki-s-are-ta(to be inspired).?
We can find a number of para-phrases that exhibit a similar pattern of syntactictransformation in the same language and groupsuch paraphrases into a single class, which ispossibly labeled ?paraphrasing of light-verb con-struction.?
Likewise, paraphrases exemplified by(2) constitute another class, so-called transitiv-ity alternation.
Example (3) is of the locativealternation class and example (4) the compoundnoun decomposition class.
In example (5), a verb?atatamaru (to be warmed)?
is paraphrased intoits adjective form, ?atatakai (be warm).?
Para-phrases involving such a lexical derivation arealso in our concern.One can learn the existence of such groupsof paraphrases and the regularity each group ex-hibits from the linguistic literature (Mel?c?uk andPolgue`re, 1987; Jackendoff, 1990; Kageyama,2001).
According to Jackendoff and Kageyama,for instance, both transitivity alternation and loca-tive alternation can be explained in terms of thesyntactic and semantic properties of the verb in-volved, which are represented by what they callLexical Conceptual Structure.
The systematicityunderlying such linguistic accounts is intriguingalso from the engineering point of view as it couldenable us to take a more theoretically motivatedbut still practical approach to paraphrase genera-tion.Aiming at this goal leads us to consider build-ing a paraphrase corpus which enables us to eval-uate paraphrase generation systems and conducterror analysis for each paraphrase class sepa-rately.
Our paraphrase corpus should therefore beorganized according to paraphrase classes.
Morespecifically, we consider a paraphrase corpus suchthat:?
The corpus consists of a set of subcorpora.?
Each subcorpus is a collection of paraphrasesentence pairs of a paraphrase class.?
Paraphrases collected in a subcorpus suffi-ciently reflect the distribution of the occur-rences in the real world.Given a paraphrase class and a text collection,the goal of building a paraphrase corpus is to col-lect paraphrase examples belonging to the class26as exhaustively as possible from the text collec-tion at a minimal human labor cost.
The resultantcorpus should also be reliable.3 Related workPrevious work on building paraphrase corpus(collecting paraphrase examples) can be classifiedinto two directions: manual production of para-phrases and automatic paraphrase acquisition.3.1 Manual production of paraphrasesManual production of paraphrase examples hasbeen carried out in MT studies.For example, Shirai et al (2001) andKinjo et al (2003) use collections of Japanese-English translation sentence pairs.
Giventranslation pairs, annotators are asked to producenew translations for each side of the languages.Sentences that have an identical translationare collected as equivalents, i.e., paraphrases.Shimohata (2004), on the other hand, takes asimpler approach in which he asks annotators toproduce paraphrases of a given set of Englishsentences.Obviously, if we simply asked human annota-tors to produce paraphrases of a given set of sen-tences, the labor cost would be expensive whilethe coverage not guaranteed.
Previous work,however, has averted their eyes from evaluatingthe cost-efficiency of the method and the cover-age of the collected paraphrases supposedly be-cause their primary concern was to enhance MTsystems.3.2 Automatic paraphrase acquisitionRecently, paraphrase examples have been auto-matically collected as a source of acquiring para-phrase knowledge, such as pairs of synonymousphrases and syntactic transformation templates.Some studies exploit topically related articlesderived from multiple news sources (Barzilay andLee, 2003; Shinyama and Sekine, 2003; Quirk etal., 2004; Dolan et al, 2004).
Sentence pairs thatare likely to be paraphrases are automatically col-lected from the parallel or comparable corpora,using such clues as overlaps of content words andnamed entities, syntactic similarity, and referencedescription, such as date of the article and posi-tions of sentences in the articles.Automatic acquisition from parallel or compa-rable corpora, possibly in combination with man-ual correction, could be more cost-efficient thanmanual production.
However, it would not ensurecoverage and quality, because sentence pairing al-gorithms virtually limit the range of obtainableparaphrases and products tend to be noisy.Nevertheless, automatic methods are useful todiscover a variety of paraphrases that need furtherexploration.
We hope that our approach to corpusconstruction, which we present below, will workcomplementary to those directions of research.4 Proposed methodRecall that we require a corpus that reflects thedistribution of the occurrences of potential para-phrases of each class because we aim to use it forlinguistic analysis and quantitative evaluation ofparaphrase generation models.Since the issues we address here are highly em-pirical, we need to empirically examine a rangeof possible methods to gain useful methodologi-cal insights.
As an initial attempt, we have so farexamined a simple method which falls in the mid-dle of the aforementioned two approaches.
Themethod makes use of an existing paraphrase gen-eration system to reduce human labor cost as wellas to ensure coverage and quality:Step 1.
For a given paraphrase class, develop aset of morpho-syntactic paraphrasing pat-terns and lexical resources.Step 2.
Apply the patterns to a given text collec-tion using the paraphrasing system to gener-ate a set of candidate paraphrases.Step 3.
Annotate each candidate paraphrase withinformation of the appropriateness accord-ing to a set of judgement criteria.We use morpho-syntactic paraphrasing patternsderived from paraphrase samples in an analogousway to previous methods such as (Dras, 1999).For instance, from example (1), we derive a para-phrasing pattern for paraphrasing of light-verbconstructions:(6) s. N -o(?V ) VN -ACC Vt. V (N)V (N)whereN is a variable which matches with a noun,V a verb, V (N) denotes the verbalized form of27(e) confirmed (revised)paraphrase( ) fir  (r i )r r(c) annotator?s judge(correct / incorrect)( ) t t r?
j( rr t / i rr t)(d) error tags( ) rr r t(a) source sentence( ) r  t(b) automaticallygeneratedparaphrase( ) t ti llr tr r(c) second opinion(correct / incorrect)( )  i i( rr t / i rr t)GivenObligatoryObligatoryOptional(f) free comments(f) fr  tOptionalFigure 1: Annotation schema.N , and the subscripted arrow in (6s) indicates thatN -o depends on V .To exhaustively collect paraphrase examplesfrom a given text collection, we should not exces-sively constrain paraphrasing patterns.
To avoidoverly generating anomalies, on the other hand,we make use of several lexical resources.
For in-stance, pairs of a deverbal noun and its transitiveform are used to constrainN and V (N) in pattern(6).
This way, we combine syntactic transforma-tion patterns with lexical constraints to specify aparaphrase class.
This approach is practical giventhe recent advances of shallow parsers.For the judgement on appropriateness in Step 3,we create a set of criteria separately for each para-phrase class.
When the paraphrase class in focusis specified, the range of potential errors in candi-date generation tends to be predictable.
We there-fore specify judgement criteria in terms of a ty-pology of potential errors (Fujita and Inui, 2003);namely, we provide annotators with a set of con-ditions for ruling out inappropriate paraphrases.Annotators judge each candidate paraphrasewith a view of an RDB-based annotation tool(Figure 1).
Given (a) a source sentence and(b) an automatically generated candidate para-phrase, human annotators are asked to (c) judgethe appropriateness of it and, if it is inappropri-ate, they are also asked to (d) classify the un-derlying errors into a predefined taxonomy, andmake (e) appropriate revisions (if possible) and(f) format-free comments.5 Preliminary trialsTo examine how the proposed method actuallywork regarding the issues, we conducted prelim-inary trials, taking two classes of Japanese para-phrases: paraphrasing of light-verb constructionsand transitivity alternation.
This section de-scribes the settings for each paraphrase class.We sampled a collection of source sentencesfrom one year worth of newspaper articles: Ni-hon Keizai Shinbun3, 2000, where the averagesentence length was 25.3 words.
The reasonwhy we selected newspaper articles as a samplesource was that most of the publicly availableshallow parsers for Japanese were trained on atree-bank sampled from newspaper articles, and anewspaper corpus was available in a considerablylarge scale.
We used for candidate generation themorphological analyzer ChaSen4, the dependencystructure analyzer CaboCha5, and the paraphrasegeneration system KURA6.Two native speakers of Japanese, adults grad-uated from university, were employed as annota-tors.
The process of judging each candidate para-phrase is illustrated in Figure 2.
The first annota-tor was asked to make judgements on each candi-date paraphrase.
The second annotator inspectedall the candidates judged correct by the first an-3http://sub.nikkeish.co.jp/gengo/zenbun.htm4http://chasen.naist.jp/5http://chasen.org/?taku/software/cabocha/6http://cl.naist.jp/kura/doc/28Candidateparaphrasei tr rCorrectIncorrect1st annotator 2nd annotatorCorrectIncorrectCorrectIncorrectCorrectDeferredIncorrectDiscussionUnseenDeferredfCorrecttIncorrectI tLabelFigure 2: Judgement procedure.notator.
To reduce the labor cost, only a smallsubset of candidates that the first annotator judgedincorrect were checked by the second annotator,leaving the rest labeled incorrect.
Once in sev-eral days, the annotators discussed cases on whichthey disagreed, and if possible revised the anno-tation criteria.
When the discussion did not reacha consensus, the judgement was deferred.5.1 Paraphrasing of light-verb constructions(LVC)An example of this class is given in (1).
A light-verb construction consists of a deverbal noun(?shigeki (inspiration)?
in example (1)) governedby a light-verb (?ukeru (to receive)?).
A para-phrase of this class is a pair of a light-verb con-struction and its unmarked form, which consistsof the verbalized form of the deverbal noun wherethe light-verb is removed.Let N , V be a deverbal noun and a verb, andV (N) be the verbalized form of N .
Paraphrasesof this class can be represented by the followingparaphrasing pattern:(7) s. N -{ga, o, ni}(?V ) VN -{NOM, ACC, DAT} Vt. V (N)V (N)In the experiment, we used three more patterns togain the coverage.We then extracted 20,155 pairs of deverbalnoun and its verbalized form (e.g.
?shigeki (in-spiration)?
and ?shigeki-suru (to inspire)?)
fromthe Japanese word dictionary, IPADIC (version2.6.3)3.
This set was used as a restriction onnouns that can match with N in a paraphrasingpattern.
On the other hand, we made no restric-tion on V , because we had no exhaustive listof light-verbs.
The patterns were automaticallycompiled into pairs of dependency trees withuninstantiated components, and were applied tosource sentences with the paraphrase generationsystem, which carried out dependency structure-based pattern matching.
2,566 candidate para-phrases were generated from 10,000 source sen-tences.In the judgement phase, the annotators werealso asked to revise erroneous candidates if pos-sible.
The following revision operations were al-lowed for LVC:?
Change of conjugations?
Change of case markers?
Insert adverbs?
Append verbal suffixes, such as voice, as-pect, or mood devicesWhen pattern (7) is applied to sentence (1s), forinstance, we need to add a voice device, ?are (pas-sive),?
to correctly produce (1t).
In example (8),on the other hand, an aspectual device, ?dasu (in-choative),?
is appended, and a case marker, ?no(GEN),?
is replaced with ?o (ACC).?
(8) s. concert-no ticket-no hanbai-o hajime-ta.concert-GEN ticket-GEN sale-ACC to start-PASTWe started to sale tickets for concerts.t.
concert-no ticket-o hanbai-shi-dashi-ta.concert-GEN ticket-ACC to sell-INCHOATIVE-PASTWe started selling tickets for concerts.So far, 1,114 candidates have been judged7 withagreements on 1,067 candidates, and 591 para-phrase examples have been collected.5.2 Transitivity alternation (TransAlt)This class of paraphrases requires a collection ofpairs of intransitive and transitive verbs, such as?yureru (to sway)?
and ?yurasu (to sway)?
in ex-ample (2).
Since there was no available resourceof such knowledge, we newly created a mini-mal set of intransitive-transitive pairs that wererequired to cover all the verbs appearing in thesource sentence set (25,000 sentences).
We firstretrieved all the verbs from the source sentencesusing a set of extraction patterns implemented inthe same manner as paraphrasing patterns.
Ex-ample (9) is one of the patterns used, where Nxmatches with a noun, and V a verb.7983 candidates for the first 4,500 sentences were fullyjudged, and 131 candidates were randomly sampled fromthe remaining portion.29(9) s. N1-ga(?V ) N2-ni(?V ) VN1-NOM N2-DAT Vt. no change.We then manually examined the transitivity ofeach of 800 verbs that matched with V , and col-lected 212 pairs of intransitive verb vi and its tran-sitive form vt.
Using them as constraints, we im-plemented eight paraphrasing patterns as in (10).
(10) s. N1-ga(?Vi) N2-ni(?Vi) ViN1-NOM N2-DAT Vit.
N2-ga(?Vt(Vi)) N1-o(?Vt(Vi)) Vt(Vi)N2-NOM N1-ACC Vt(Vi)where Vi and Vt(Vi) are variables that match withvi and vt, respectively.
By applying the patternsto the same set of source sentences, we obtained985 candidate paraphrases.We created a set of criteria for judging ap-propriateness (an example will be given inSection 6.4) and revision examples for the follow-ing operations allowed for this trial:?
Change of conjugations?
Change of case markers?
Change of voices964 candidates have gained an agreement, and484 paraphrase examples have been collected.6 Results and discussionTable 1 gives some statistics of the resultant para-phrase corpora.
Figures 3 and 4 show the numberof candidate paraphrases, where the horizontalaxes denote the total working hours of two anno-tators, and the vertical axes the number of candi-date paraphrases.
The numbers of judged, correct,incorrect, and deferred candidates are shown.6.1 Efficiency2,031 candidate paraphrases have so far beenjudged in total and 1,075 paraphrase exampleshave been collected in 287.5 hours.
The judge-ment was performed at a constant pace: 7.1 can-didates (3.7 examples) in one hour.
It is hard tocompare these results with other work becauseno previous study quantitatively evaluate the effi-ciency in terms of manual annotation cost.
How-ever, we feel that the results have so far been sat-isfiable.For each candidate paraphrase judged incor-rect, the annotators were asked to classify the un-derlying errors into the fixed error types ((d) inTable 1: Statistics of the resultant corpora.Paraphrase class LVC TransAlt# of source sentences 10,000 25,000# of patterns 4 8Type of lexical resources ?n, vn?
?vi, vt?Size of lexical resource 20,155 212# of candidates 2,566 985# of judged candidates 1,067 964# of incorrect candidates 520 503# of correct candidates 547 461# of paraphrase examples 591 484Working hours 118 169.5Figure 1).
This error classification consumed ex-tra time because it required linguistic expertisewhich the annotators were not familiar with.TransAlt was 1.75 times more time-consumingthan LVC because the definition of TransAlt in-volved several delicate issues, which made thejudgement process complicated.
We return to thisissue in Section 6.4.6.2 ExhaustivenessTo estimate how exhaustively the proposedmethod collected paraphrase examples, we ran-domly sampled 750 sentences from the 4,500sentences that were used in the trial for LVC,and manually checked whether the LVC para-phrasing could apply to each of them.
As a re-sult, 206 examples were obtained, 158 of whichwere those already collected by the proposedmethod.
Thus, the estimated exhaustiveness was77% (158 / 206).
Our manual investigation intothe missed examples has revealed that 47 missescould have been automatically generated by en-hancing paraphrasing patterns and dictionaries,while only one example was missed due to an er-ror in shallow parsing.
34 cases of the 48 missescould have been collected by adding a couple ofparaphrasing patterns.
For example, pattern (11)verbalizes a noun followed by a nominalizing suf-fix, ?ka (-ize),?
as in (12).
(11) s. N -ka-{ga, o, ni}(?V ) VN -ize-{NOM, ACC, DAT} Vt. V (N -ka)V (N -ize)(12) s. kore-wa kin?yu-shijo-no kassei-ka-nithis-TOP financial market-GEN activation-DATmuke-ta kisei-kanwa-saku-da.to address-PAST deregulation plan-COPThis is a deregulation plan aiming at theactivation of financial market.300200400600800100012000  20  40  60  80  100  120#ofjudgedcandidatesworking hoursJudgedCorrectIncorrectDeferredFigure 3: # of judged candidates (LVC).020040060080010000  20  40  60  80  100  120  140  160  180#ofjudgedcandidatesworking hoursJudgedCorrectIncorrectDeferredFigure 4: # of judged candidates (TransAlt).t.
kore-wa kin?yu-shijo-othis-TOP financial market-ACCkassei-ka-suru kisei-kanwa-saku-da.to activate-PRES deregulation plan-COPThis is a deregulation plan which activatesfinancial market.We cannot know if we have adequate para-phrasing patterns and resources before trials.Therefore, manual examination is necessary to re-fine them to bridge gap between the range of para-phrases that can be automatically generated andthose of the specific class we consider.6.3 ReliabilityIdeally, more annotators should be employed toensure the reliability of the products, which, how-ever, leads to a matter of balancing the trade-off.Instead, we specified the detailed judgement cri-teria for each paraphrase class, and asked the an-notators to reconsider marginal cases several dayslater and to make a discussion when judgementsdisagreed.
The agreement ratio for correct candi-dates between two annotators increased as theybecame used to the task.
In the trial for LVC,for example, the agreement ratio for each daychanged from 74% (day 3) to 77% (day 6), 88%(day 9), and 93% (day 11).
This indicates that thejudgement criteria were effectively refined basedon the feedback from inter-annotator discussionson marginal and disagreed cases.
To evaluate thereliability of our judgement procedure more pre-cisely, we are planing to employ the third annota-tor who will be asked to judge all the cases inde-pendently of the others.6.4 How we define paraphrase classesOne of the motivations behind our class-based ap-proach is an expectation that specifying the targetclasses of paraphrases would simplify the awk-ward problem of defining the boundary betweenparaphrases an non-paraphrases.
Our trials for thetwo paraphrase classes, however, have revealedthat it can still be difficult to create a clear cri-terion for judgement even when the paraphraseclass in focus is specified.As one of the criteria for TransAlt, we testedthe agentivity of the nominative case of intransi-tive verbs.
The test used an adverb, ?muzukara(by itself),?
and classified a candidate paraphraseas incorrect if the adverb could be inserted im-mediately before the intransitive verb.
For ex-ample, we considered example (13) as a correctparaphrase of the TransAlt class whereas (14) in-correct because the agentivity exhibited by (14s)did not remain in (14t).
(13) s. kare-ga soup-o atatame-ta.he-NOM soup-ACC to warm up-PASTHe warmed the soup up.t.
soup-ga atatamat-ta.
(correct)soup-NOM to be warmed up-PASTThe soup was warmed up (by somebody).
(14) s. kare-ga koori-o tokashi-ta.he-NOM ice-ACC to melt (vt)-PASTHe melted the ice.t.
koori-ga toke-ta.
(incorrect)ice-NOM to melt (vi)-PASTThe ice melted (by itself).However, one might regard both paraphrasesincorrect because the information given by thenominative argument of the source sentence is31dropped in the target in both cases.
Thus, theproblem still remains.
Nevertheless, our approachwill provide us with a considerable amounts ofconcrete data, which we hope will lead us to bet-ter understanding of the issue.7 ConclusionTowards deep analysis of compositional classes ofparaphrases, we have examined a class-orientedframework for collecting paraphrase examples,in which sentential paraphrases are collected foreach paraphrase class separately by means of au-tomatic candidate generation and manual judge-ment.
Our preliminary experiments on buildinga paraphrase corpus have so far been producingpromising results, which we have evaluated ac-cording to cost-efficiency, exhaustiveness, and re-liability.
The resultant corpus and resources willbe available for free shortly.
Our next step is di-rected to targeting a wider range of paraphraseclasses.ReferencesRegina Barzilay and Kathleen R. McKeown.
2001.Extracting paraphrases from a parallel corpus.
InProceedings of the 39th Annual Meeting of theAssociation for Computational Linguistics (ACL),pages 50?57.Regina Barzilay and Lillian Lee.
2003.
Learn-ing to paraphrase: an unsupervised approach us-ing multiple-sequence alignment.
In Proceedingsof the 2003 Human Language Technology Confer-ence and the North American Chapter of the Associ-ation for Computational Linguistics (HLT-NAACL),pages 16?23.Bill Dolan, Chris Quirk, and Chris Brockett.
2004.Unsupervised construction of large paraphrase cor-pora: exploiting massively parallel news sources.In Proceedings of the 20th International Con-ference on Computational Linguistics (COLING),pages 350?356.Mark Dras.
1999.
Tree adjoining grammar and the re-luctant paraphrasing of text.
Ph.D. thesis, Divisionof Information and Communication Science, Mac-quarie University.Atsushi Fujita and Kentaro Inui.
2003.
Explor-ing transfer errors in lexical and structural para-phrasing.
IPSJ Journal, 44(11):2826?2838.
(inJapanese).Atsushi Fujita, Kentaro Inui, and Yuji Matsumoto.2004.
Detection of incorrect case assignments inautomatically generated paraphrases of Japanesesentences.
In Proceedings of the 1st InternationalJoint Conference on Natural Language Processing(IJCNLP), pages 14?21.Ray Jackendoff.
1990.
Semantic structures.
The MITPress.Taro Kageyama, editor.
2001.
Semantics and syntaxof verb: comparable study between Japanese andEnglish.
Taishukan Shoten.
(in Japanese).Yumiko Kinjo, Kunio Aono, Keishi Yasuda, ToshiyukiTakezawa, and Genichiro Kikui.
2003.
Collec-tion of Japanese paraphrases of basic expressionson travel conversation.
In Proceedings of the 9thAnnual Meeting of the Association for Natural Lan-guage Processing, pages 101?104.
(in Japanese).Maria Lapata.
2001.
A corpus-based account of reg-ular polysemy: the case of context-sensitive ad-jectives.
In Proceedings of the 2nd Meeting ofthe North American Chapter of the Association forComputational Linguistics (NAACL), pages 63?70.Benoit Lavoie, Richard Kittredge, Tanya Korelsky,and Owen Rambow.
2000.
A framework for MTand multilingual NLG systems based on uniformlexico-structural processing.
In Proceedings of the6th Applied Natural Language Processing Confer-ence and the 1st Meeting of the North AmericanChapter of the Association for Computational Lin-guistics (ANLP-NAACL), pages 60?67.Igor Mel?c?uk and Alain Polgue`re.
1987.
A formallexicon in meaning-text theory (or how to do lex-ica with words).
Computational Linguistics, 13(3-4):261?275.Chris Quirk, Chris Brockett, and William Dolan.2004.
Monolingual machine translation for para-phrase generation.
In Proceedings of the 2004 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 142?149.Mitsuo Shimohata.
2004.
Acquiring paraphrasesfrom corpora and its application to machine trans-lation.
Ph.D. thesis, Graduate School of Informa-tion Science, Nara Institute of Science and Tech-nology.Yusuke Shinyama and Satoshi Sekine.
2003.
Para-phrase acquisition for information extraction.
InProceedings of the 2nd International Workshop onParaphrasing: Paraphrase Acquisition and Appli-cations (IWP), pages 65?71.Satoshi Shirai, Kazuhide Yamamoto, and FrancisBond.
2001.
Japanese-English paraphrase corpus.In Proceedings of the 6th Natural Language Pro-cessing Pacific Rim Symposium (NLPRS) Workshopon Language Resources in Asia, pages 23?30.Tetsuro Takahashi, Tomoya Iwakura, Ryu Iida, At-sushi Fujita, and Kentaro Inui.
2001.
KURA:a transfer-based lexico-structural paraphrasing en-gine.
In Proceedings of the 6th Natural LanguageProcessing Pacific Rim Symposium (NLPRS) Work-shop on Automatic Paraphrasing: Theories and Ap-plications, pages 37?46.32
