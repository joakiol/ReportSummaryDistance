Proceedings of the Second ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 9?14,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsTeaching Dialogue to Interdisciplinary Teams through ToolkitsJustine CassellTechnology and Social BehaviorNorthwestern Universityjustine@northwestern.eduMatthew StoneComputer Science and Cognitive ScienceRutgers Universitymatthew.stone@rutgers.eduAbstractWe present some lessons we have learnedfrom using software infrastructure tosupport coursework in natural languagedialogue and embodied conversationalagents.
We have a new appreciationfor the differences between courseworkand research infrastructure?supportingteaching may be harder, because studentsrequire a broader spectrum of implemen-tation, a faster learning curve and the abil-ity to explore mistaken ideas as well aspromising ones.
We outline the collabo-rative discussion and effort we think is re-quired to create better teaching infrastruc-ture in the future.1 IntroductionHands-on interaction with dialogue systems is a nec-essary component of a course on computational lin-guistics and natural language technology.
And yet, itis clearly impracticable to have students in a quarter-long or semester-long course build a dialogue sys-tem from scratch.
For this reason, instructors ofthese courses have experimented with various op-tions to allow students to view the code of a work-ing dialogue system, tweak code, or build their ownapplication using a dialogue system toolkit.
Somepopular options include the NLTK (Loper and Bird,2002), CSLU (Cole, 1999), Trindi (Larsson andTraum, 2000) and Regulus (Rayner et al, 2003)toolkits.
However, each of these options has turnedout to have disadvantages.
Some of the toolkits re-quire too much knowledge of linguistics for the av-erage computer science student, and vice-versa, oth-ers require too much programming for the averagelinguist.
What is needed is an extensible dialoguetoolkit that allows easy application building for be-ginning students, and more sophisticated access to,and tweakability of, the models of discourse for ad-vanced students.In addition, as computational linguists become in-creasingly interested in the role of non-verbal be-havior in discourse and dialogue, more of us wouldlike to give our students exposure to models of theinteraction between language and nonverbal behav-iors such as eye gaze, head nods and hand gestures.However, the available dialogue system toolkits ei-ther have no graphical body or if they do have (partof) a body?as in the case of the CSLU toolkit?thetoolkit does not allow the implementation of alterna-tive models of body?language interaction.We feel, therefore, that there is a need for atoolkit that allows the beginning graduate student?who may have some computer science or some lin-guistics background, but not both?to implement aworking embodied dialogue system, as a way to ex-periment with models of discourse, dialogue, collab-orative conversation and the interaction between ver-bal and nonverbal behavior in conversation.
We be-lieve the community as a whole must be engaged inthe design, implementation and fielding of this kindof educational software.
In this paper, we surveythe experience that has led us to these conclusionsand frame the broader discussion we hope the TNLPworkshop will help to further.92 Our CoursesOur perspective in this paper draws on more thanfifteen course offerings at the graduate level in dis-course and dialogue over the years.
Justine Cassell?scourse Theories and Technologies of Human Com-munication is documented on the web here:http://www.soc.northwestern.edu/justine/discourseMatthew Stone?s courses Natural Language Pro-cessing and Meaning Machines1 are documentedhere:http://www.cs.rutgers.edu/?mdstone/class/533-spring-03/http://www.cs.rutgers.edu/?mdstone/class/672These courses are similar in perspective.
All ad-dress an extremely diverse and interdisciplinary au-dience of students from computer science, linguis-tics, cognitive science, information science, commu-nication, and education.
The typical student is a firstor second-year PhD student with a serious interest indoing a dissertation on human-computer communi-cation or in enriching their dissertation research withresults from the theory or practice of discourse anddialogue.
All are project courses, but no program-ming is required; projects may involve evaluation ofexisting implementations or the prospective designof new implementations based on ongoing empir-ical research.
Nevertheless, the courses retain thedual goals that students should not only understanddiscourse and the theory of pragmatics, but shouldalso understand how the theory is implemented, ei-ther well enough to talk intelligently about the im-plementation or, if they are computer scientists, toactually carry it out.As befits our dual goals, our courses all involvea mix of instruction in human-human dialogue andhuman-computer dialogue.
For example, Cassell be-gins her course with a homework where studentscollect, transcribe and analyze their own recordingsof face-to-face conversation.
Students are asked todiscuss what constitutes a sufficient record of dis-course, and to speculate on what the most challeng-ing processing issues would be to allow a computerto replace one of the participants.
Computer sci-entists definitely have difficulty with this aspect of1The catchy title is the inspiration of Deb Roy at MIT.the course?only fair, since they are at the advan-tage when it comes to implementation.
But com-puter scientists see the value in the exercise: evenif they do not believe that interfaces should be de-signed to act like people, they still recognize thatwell-designed interactive systems must be ready tohandle the kinds of behaviors people actually carryout.
And hands-on experience convinces them thatbehavior in human conversation is both rich and sur-prising.
The computer scientists agree?after turn-ing in impoverished and uninformed ?analyses?
oftheir discourse for a brutal critique?that they willnever look at conversation the same way again.Our experience suggests that we should be try-ing to give students outside computer science thesame kind of eye-opening hands-on experience withtechnology.
For example, we have found that lin-guists are just as challenged and excited by the dis-cipline of technology as computer scientists are bythe discipline of empirical observations.
Linguistsin our classes typically report that successful en-gagement with technology ?exposes a lot of de-tails that were missing from my theoretical under-standing that I never would have considered with-out working through the code?.
Nothing is better atbringing out the assumptions you bring to an anal-ysis of human-human conversation than the thoughtexperiment of replacing one of the participants bysomething that has to struggle consciously to un-derstand it?a space alien, perhaps, or, more real-istically, an AI system.
We are frustrated that nosuccinct assignment, comparable to our transcrip-tion homework, yet exists that can reliably deliverthis insight to students outside computer science.3 Framing the ProblemOur courses are not typical NLP classes.
Our treat-ment of parsing is marginal, and for the most partwe ignore the mainstays of statistical language pro-cessing courses: the low-level technology such asfinite-state methods; the specific language process-ing challenges for machine learning methods; and?applied?
subproblems like named entity extraction,or phrase chunking.
Our focus is almost exclu-sively on high-level and interactional issues, suchas the structure of discourse and dialogue, informa-tion structure, intentions, turn-taking, collaboration,10reference and clarification.
Context is central, andunder that umbrella we explicitly discuss both theperceptual environment in which conversation takesplace and the non-verbal actions that contribute tothe management of conversation and participants?real-world collaborations.Our unusual focus means that we can not readilytake advantage of software toolkits such as NLTK(Loper and Bird, 2002) or Regulus (Rayner et al,2003).
These toolkits are great at helping studentsimplement and visualize the fundamentals of natu-ral language processing?lexicon, morphology, syn-tax.
They make it easy to experiment with machinelearning or with specific models for a small scale,short course assignment in a specific NLP module.You can think of this as a ?horizontal?
approach, al-lowing students to systematically develop a compre-hensive approach to a single processing task.
Butwhat we need is a ?vertical?
approach, which allowsstudents to follow a specific choice about the rep-resentation of communicative behaviors or commu-nicative functions all the way through an end-to-enddialogue system.
We have not succeeded in concep-tualizing how a carefully modularized toolkit wouldsupport this kind of student experience.Still, we have not met with success with alterna-tive approaches, either.
As we describe in Section3.1, our own research systems may allow the kindsof experiments we want students to carry out.
Butthey demand too much expertise of students for aone-semester course.
In fact, as we describe in Sec-tion 3.2, even broad research systems that come withspecific support for students to carry out a range oftasks may not enable the specific directions that re-ally turn students on to the challenge of discourseand dialogue.
However, our experience with im-plementing dedicated modules for teaching, as de-scribed in Section 3.3, is that the lack of synergywith ongoing research can result in impoverishedtools that fail to engage students.
We don?t have thetools we want?but our experience argues that wethink the tools we really want will be developed onlythrough a collaborative effort shared across multiplesites and broadly engaged with a range of researchissues as well as with pedagogical challenges.3.1 Difficulties with REA and BEATCassell has experimented with the use of her re-search platforms REA (Cassell et al, 1999) andBEAT (Cassell et al, 2001) for course projects indiscourse and dialogue.
REA is an embodied con-versational agent that interacts with a user in a realestate agent domain.
It includes an end-to-end dia-logue architecture; it supports speech input, stereovision input, conversational process including pres-ence and turn-taking, content planning, the context-sensitive generation of communicative action andthe animated realization of multimodal communica-tive actions.
BEAT (the behavior expression anima-tion toolkit), on the other hand, is a module that fitsinto animation systems.
It marks up text to describeappropriate synchronized nonverbal behaviors andspeech to realize on a humanoid talking character.In teaching dialogue at MIT, Cassell invited stu-dents to adapt her existing REA and BEAT systemto explore aspects of the theory and practice of dis-course and dialogue.
This led to a range of interest-ing projects.
For example, students were able to ex-plore hypothetical differences among characters?from virtual ?Italians?
with profuse gesture, to vir-tual children whose marked use of a large gesturespace contrasted with typical adults, to characterswho showed new and interesting behavior such asthe repeated foot-tap of frustrated condescension.However, we think we can serve students much bet-ter.
Many of these projects were accomplished onlywith substantial help from the instructor and TAs,who were already extremely familiar with the over-all system.
Students did not have time to learn howto make these changes entirely on their own.The foot-tapping agent is a good example of this.To add foot-tapping is a paradigmatic ?vertical?modification.
It requires adding suitable context tothe discourse state to represent uncooperative userbehavior; it requires extending the process for gener-ating communicative actions to detect this new stateand schedule an appropriate behavioral response;and then it requires extending the animation plat-form to be able to show this behavior.
BEAT makesthe second step easy?as it should be?even for lin-guistics students.
To handle the first and third steps,you would hope that an interdisciplinary team con-taining a communication student and a computer sci-11ence student would be able to bring the expertise todesign the new dialogue state and the new animatedbehavior.
But that wasn?t exactly true.
In order toadd the behavior to REA, students needed not onlybackground in the relevant technology?like what acomputer scientist would learn in a general humananimation class.
To add the behavior, students alsoneeded to know how this technology was realizedin our particular research platform.
This proved toomuch for one semester.We think this is a general problem with new re-search systems.
For example, we think many of thesame issues would arise in asking students to build adialogue system on top of the Trindi toolkit in a onesemester course.3.2 Difficulties with the CSLU toolkitIn Fall 2004, Cassell experimented with using theCSLU dialogue toolkit (Cole, 1999) as a resourcefor class projects.
This is a broad toolkit to supportresearch and teaching in spoken language technol-ogy.
A particular strength of the toolkit is its sup-port for the design of finite-state dialogue models.Even students outside computer science appreciatedthe toolkit?s drag-and-drop interface for scripting di-alogue flow.
For example, with this interface, youcan add a repair sequence to a dialogue flow in oneeasy step.
However, the indirection the toolkit placesbetween students and the actual constructs of dia-logue theory can by quite challenging.
For example,the finite-state architecture of the CSLU toolkit al-lows students to look at floor management and at di-alogue initiative only indirectly: specific transitionnetworks encode specific strategies for taking turnsor managing problem solving by scheduling specificcommunicative functions and behaviors.The way we see it, the CSLU toolkit is more heav-ily geared towards the rapid construction of particu-lar kinds of research prototypes than we would likein a teaching toolkit.
Its dialogue models provide aninstructive perspective on actions in discourse, onethat nicely complements the perspective of DAMSL(Core and Allen, 1997) in seeing utterances as thecombined realization of a specific, constrained rangeof communicative functions.
But we would like tobe able to explore a range of other metaphors fororganizing the information in dialogue.
We wouldlike students to be able to realize models of face-to-face dialogue (Cassell et al, 2000), the information-state approach to domain-independent practical di-alogue (Larsson and Traum, 2000), or approachesthat emphasize the grounding of conversation in thespecifics of a particular ongoing collaboration (Richet al, 2001).
The integration of a talking head intothe CSLU toolkit epitomizes these limitations withthe platform.
The toolkit allows for the automaticrealization of text with an animated spoken deliv-ery, but does not expose the model to programmers,making it impossible for programmers adapt or con-trol the behavior of the face and head.We think this is a general problem with platformsthat are primarily designed to streamline a particularresearch methodology.
For example, we think manyof the same issues would arise in asking students tobuild a multimodal behavior realization system ontop of a general-purpose speech synthesis platformlike Festival (Black and Taylor, 1997).3.3 Difficulties with TAGLETAt this point, the right solution might seem to beto devise resources explicitly for teaching.
In fact,Stone advocated more or less this at the 2002 TNLPworkshop (2002).
There, Stone motivated the poten-tial role for a simple lexicalized formalism for nat-ural language syntax, semantics and pragmatics ina broad NLP class whose emphasis is to introducetopics of current research.The system, TAGLET, is a context-free tree-rewriting formalism, defined by the usual comple-mentation operation and the simplest imaginablemodification operation.
This formalism may in factbe a good way to present computational linguisticsto technically-minded cognitive science students?those rare students who come with interest and ex-perience in the science of language as well as a solidability to program.
By implementing a strong com-petence TAGLET parser and generator students si-multaneously get experience with central computerscience ideas?data structures, unification, recur-sion and abstraction?and develop an effective start-ing point for their own subsequent projects.However, in retrospect, TAGLET does not serveto introduce students outside computer science to thedistinctive insights that come from a computationalapproach to language use.
For one thing, to reacha broad audience, it is a mistake to focus on repre-12sentations that programmers can easily build at theexpense of representations that other students caneasily understand.
These other students need visu-alization; they need to be able to see what the sys-tem computes and how it computes it.
Moreover,these other students can tolerate substantial com-plexity in the underlying algorithms if the systemcan be understood clearly and mechanistically in ab-stract terms.
You wouldn?t ask a computer scientistto implement a parser for full tree-adjoining gram-mar but that doesn?t change the fact that it?s still aperfectly natural, and comprehensible, algorithmicabstraction for characterizing linguistic structure.Another set of representations and algorithmsmight avoid some of these problems.
But a newapproach could not avoid another problem that wethink applies generally to platforms that are de-signed exclusively for teaching: there is no synergywith ongoing research efforts.
Rich resources are socrucial to any computational treatment of dialogue:annotated corpora, wide-coverage grammars, plan-recognizers, context models, and the rest.
We can?tafford to start from scratch.
We have found this con-cretely in our work.
What got linguists involved inthe computational exploration of dialogue semanticsat Rutgers was not the special teaching resourcesStone created.
It was hooking students up with thesystems that were being actively developed in ongo-ing research (DeVault et al, 2005).
These researchefforts made it practical to provide students with thevisualizations, task and context models, and interac-tive architecture they needed to explore substantiveissues in dialogue semantics.
Whatever we do willhave to closely connect teaching and our ongoing re-search.4 Looking aheadOur experience teaching dialogue to interdisci-plinary teams through toolkits has been humbling.We have a new appreciation for the differencesbetween coursework and research infrastructure?supporting teaching may be harder, because stu-dents require a broader spectrum of implementa-tion, a faster learning curve and the ability to ex-plore mistaken ideas as well as promising ones.But we increasingly think the community can andshould come together to foster more broadly usefulresources for teaching.We have reframed our ongoing activities so thatwe can find new synergies between research andteaching.
For example, we are currently workingto expand the repertoire of animated action in ourfreely-available talking head RUTH (DeCarlo et al,2004).
In our next release, we expect to make dif-ferent kinds of resources available than in the initialrelease.
Originally, we distributed only the modelwe created.
The next version will again provide thatmodel, along with a broader and more useful inven-tory of facial expressions for it, but we also wantthe new RUTH to be more easily extensible than thelast one.
To do that, we have ported our model to ageneral-purpose animation environment (Alias Re-search?s Maya) and created software tools that canoutput edited models into the collection of files thatRUTH needs to run.
This helps achieve our ob-jective of quickly-learned extensibility.
We expectthat students with a background in human anima-tion will bring experience with Maya to a dialoguecourse.
(Anyway, learning Maya is much more gen-eral than learning RUTH!)
Computer science stu-dents will thus find it easier to assist a team of com-munication and linguistics students in adding newexpressions to an animated character.Creating such resources to span a general systemfor face-to-face dialogue would be an enormous un-dertaking.
It could happen only with broad inputfrom those who teach discourse and dialogue, as wedo, through a mix of theory and practice.
We hopethe TNLP workshop will spark this kind of process.We close with the questions we?d like to considerfurther.
What kinds of classes on dialogue and dis-course pragmatics are currently being offered?
Whatkinds of audiences do others reach, what goals dothey bring, and what do they teach them?
What arethe scientific and technological principles that oth-ers would use toolkits to teach and illustrate?
Inshort, what would your dialogue toolkit make possi-ble?
And how can we work together to realize bothour visions?5 AcknowledgmentsThanks to Doug DeCarlo, NSF HLC 0308121.13ReferencesAlan Black and Paul Taylor.
1997.
Festi-val speech synthesis system.
Technical ReportHCRC/TR-83, Human Communication Research Cen-ter.
http://www.cstr.ed.ac.uk/projects/festival/.J.
Cassell, T. Bickmore, M. Billinghurst, L. Campbell,K.
Chang, H. Vilhja?lmsson, and H. Yan.
1999.
Em-bodiment in conversational characters: Rea.
In CHI99, pages 520?527.Justine Cassell, Tim Bickmore, Lee Campbell, HannesVilhjalmsson, and Hao Yan.
2000.
Human conver-sation as a system framework.
In J. Cassell, J. Sul-livan, S. Prevost, and E. Churchill, editors, Embod-ied Conversational Agents, pages 29?63.
MIT Press,Cambridge, MA.Justine Cassell, Hannes Vilhja?lmsson, and Tim Bick-more.
2001.
BEAT: the behavioral expression ani-mation toolkit.
In SIGGRAPH, pages 477?486.Ron Cole.
1999.
Tools for research and ed-ucation in speech science.
In Proceedings ofthe International Conference of Phonetic Sciences.http://cslu.cse.ogi.edu/toolkit/.Mark G. Core and James F. Allen.
1997.
Cod-ing dialogs with the DAMSL annotation scheme.In Working Notes of AAAI Fall Symposium onCommunicative Action in Humans and Machines.http://www.cs.rochester.edu/research/cisd/resources/damsl/.Douglas DeCarlo, Corey Revilla, Matthew Stone, andJennifer Venditti.
2004.
Specifying and animating fa-cial signals for discourse in embodied conversationalagents.
Journal of Visualization and Computer Ani-mation.
http://www.cs.rutgers.edu/?village/ruth/.David DeVault, Anubha Kothari, Natalia Kariaeva,Iris Oved, and Matthew Stone.
2005.
Aninformation-state approach to collaborative ref-erence.
In ACL Proceedings Companion Vol-ume (interactive poster and demonstration track).http://www.cs.rutgers.edu/?mdstone/pointers/collabref.html.Staffan Larsson and David Traum.
2000.
In-formation state and dialogue management inthe TRINDI dialogue move engine toolkit.Natural Language Engineering, 6:323?340.http://www.ling.gu.se/projekt/trindi/.Edward Loper and Steven Bird.
2002.
NLTK: the natu-ral language toolkit.
In Proceedings of the ACL Work-shop on Effective Tools and Methodologies for Teach-ing Natural Language Processing and ComputationalLinguistics.
http://nltk.sourceforge.net.Manny Rayner, Beth Ann Hockey, and John Dowd-ing.
2003.
An open source environment for com-piling typed unification grammars into speech recog-nisers.
In Proceedings of the 10th Conference of theEuropean Chapter of the Association for Computa-tion Linguistics (interactive poster and demo track).http://sourceforge.net/projects/regulus.C.
Rich, C. L. Sidner, and N. Lesh.
2001.
COL-LAGEN: applying collaborative discourse theory tohuman-computer interaction.
AI Magazine, 22:15?25.Matthew Stone.
2002.
Lexicalized grammar 101.In ACL Workshop on Effective Tools and Method-ologies for Teaching NLP and CL, pages 76?83.http://www.cs.rutgers.edu/?mdstone/class/taglet/.14
