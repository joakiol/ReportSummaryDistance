Proceedings of the ACL 2007 Demo and Poster Sessions, pages 225?228,Prague, June 2007. c?2007 Association for Computational LinguisticsJapanese Dependency Parsing Using Sequential Labelingfor Semi-spoken LanguageKenji Imamura and Genichiro KikuiNTT Cyber Space Laboratories, NTT Corporation1-1 Hikarinooka, Yokosuka-shi, Kanagawa, 239-0847, Japan{imamura.kenji, kikui.genichiro}@lab.ntt.co.jpNorihito YasudaNTT Communication Science Laboratories, NTT Corporation2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japann-yasuda@cslab.kecl.ntt.co.jpAbstractThe amount of documents directly publishedby end users is increasing along with thegrowth of Web 2.0.
Such documents of-ten contain spoken-style expressions, whichare difficult to analyze using conventionalparsers.
This paper presents dependencyparsing whose goal is to analyze Japanesesemi-spoken expressions.
One characteris-tic of our method is that it can parse self-dependent (independent) segments using se-quential labeling.1 IntroductionDependency parsing is a way of structurally ana-lyzing a sentence from the viewpoint of modifica-tion.
In Japanese, relationships of modification be-tween phrasal units called bunsetsu segments are an-alyzed.
A number of studies have focused on parsingof Japanese as well as of other languages.
Popularparsers are CaboCha (Kudo and Matsumoto, 2002)and KNP (Kurohashi and Nagao, 1994), which weredeveloped to analyze formal written language ex-pressions such as that in newspaper articles.Generally, the syntactic structure of a sentenceis represented as a tree, and parsing is carried outby maximizing the likelihood of the tree (Charniak,2000; Uchimoto et al, 1999).
Units that do notmodify any other units, such as fillers, are difficultto place in the tree structure.
Conventional parsershave forced such independent units to modify otherunits.Documents published by end users (e.g., blogs)are increasing on the Internet alng with the growthof Web 2.0.
Such documents do not use controlledwritten language and contain fillers and emoticons.This implies that analyzing such documents is diffi-cult for conventional parsers.This paper presents a new method of Japanesedependency parsing that utilizes sequential labelingbased on conditional random fields (CRFs) in or-der to analyze semi-spoken language.
Concretely,sequential labeling assigns each segment a depen-dency label that indicates its relative position of de-pendency.
If the label set includes self-dependency,the fillers and emoticons would be analyzed as seg-ments depending on themselves.
Therefore, since itis not necessary for the parsing result to be a tree,our method is suitable for semi-spoken language.2 MethodsJapanese dependency parsing for written languageis based on the following principles.
Our method re-laxes the first principle to allow self-dependent seg-ments (c.f.
Section 2.3).1.
Dependency moves from left to right.2.
Dependencies do not cross each other.3.
Each segment, except for the top of the parsedtree, modifies at most one other segment.2.1 Dependency Parsing Using CascadedChunking (CaboCha)Our method is based on the cascaded chunkingmethod (Kudo and Matsumoto, 2002) proposed asthe CaboCha parser 1.
CaboCha is a sort of shift-reduce parser and determines whether or not a seg-ment depends on the next segment by using an1http://www.chasen.org/?taku/software/cabocha/225SVM-based classifier.
To analyze long-distance de-pendencies, CaboCha shortens the sentence by re-moving segments for which dependencies are al-ready determined and which no other segments de-pend on.
CaboCha constructs a tree structure by re-peating the above process.2.2 Sequential LabelingSequential labeling is a process that assigns eachunit of an input sequence an appropriate label (ortag).
In natural language processing, it is appliedto, for example, English part-of-speech tagging andnamed entity recognition.
Hidden Markov modelsor conditional random fields (Lafferty et al, 2001)are used for labeling.
In this paper, we use linear-chain CRFs.In sequential labeling, training data developerscan design labels with no restrictions.2.3 Cascaded Chunking Using SequentialLabelingThe method proposed in this paper is a generaliza-tion of CaboCha.
Our method considers not onlythe next segment, but also the followingN segmentsto determine dependencies.
This area, including theconsidered segment, is called the window, and N iscalled the window size.
The parser assigns each seg-ment a dependency label that indicates where thesegment depends on the segments in the window.The flow is summarized as follows:1.
Extract features from segments such as thepart-of-speech of the headword in a segment(c.f.
Section 3.1).2.
Carry out sequential labeling using the abovefeatures.3.
Determine the actual dependency by interpret-ing the labels.4.
Shorten the sentence by deleting segments forwhich the dependency is already determinedand that other segments have never dependedon.5.
If only one segment remains, then finish theprocess.
If not, return to Step 1.An example of dependency parsing for writtenlanguage is shown in Figure 1 (a).In Steps 1 and 2, dependency labels are suppliedto each segment in a way similar to that used byLabel Description?
Segment depends on a segment outside of win-dow.0Q Self-dependency1D Segment depends on next segment.2D Segment depends on segment after next.-1O Segment is top of parsed tree.Table 1: Label List Used by Sequential Labeling(Window Size: 2)other sequential labeling methods.
However, oursequential labeling has the following characteristicssince this task is dependency parsing.?
The labels indicate relative positions of the de-pendent segment from the current segment (Ta-ble 1).
Therefore, the number of labels changesaccording to the window size.
Long-distance de-pendencies can be parsed by one labeling processif we set a large window size.
However, growthof label variety causes data sparseness problems.?
One possible label is that of self-dependency(noted as ?0Q?
in this paper).
This is assignedto independent segments in a tree.?
Also possible are two special labels.
Label ?-1O?denotes a segment that is the top of the parsedtree.
Label ???
denotes a segment that dependson a segment outside of the window.
When thewindow size is two, the segment depends on asegment that is over two segments ahead.?
The label for the current segment is determinedbased on all features in the window and on thelabel of the previous segment.In Step 4, segments, which no other segments de-pend on, are removed in a way similar to that usedby CaboCha.
The principle that dependencies donot cross each other is applied in this step.
For ex-ample, if a segment depends on a segment after thenext, the next segment cannot be modified by othersegments.
Therefore, it can be removed.
Similarly,since the ???
label indicates that the segment de-pends on a segment after N segments, all interme-diate segments can be removed if they do not have???
labels.The sentence is shortened by iteration of theabove steps.
The parsing finishes when only onesegment remains in the sentence (this is the segment226(a) Written Language--- 2D 1D 1D -1O2D 1D -1OOutputInputLabelLabelkare wa(he)kanojo no(her)atatakai(warm)magokoro ni(heart)kando-shita.
(be moved)(He was moved by her warm heart.)Seg.
No.
1 2 3 4 5kare wa(he)kanojo no(her)atatakai(warm)magokoro ni(heart)kando-shita.
(be moved)(b) Semi-spoken LanguageInput Uuuum, kyo wa(today)...... choshi(condition)yokatta desu.
(be good)0Q --- 0Q 1D -1O1D -1O(Uuuum, my condition .... was good today.)Seg.
No.
1 2 3 4 5LabelLabelUuuum, kyo wa(today)...... choshi(condition)yokatta desu.
(be good)Output1stLabeling2ndLabelingFigure 1: Examples of Dependency Parsing (Window Size: 2)Corpus Type # of Sentences # of SegmentsKyoto Training 24,283 234,685Test 9,284 89,874Blog Training 18,163 106,177Test 8,950 53,228Table 2: Corpus Sizeat the top of the parsed tree).
In the example in Fig-ure 1 (a), the process finishes in two iterations.In a sentence containing fillers, the self-dependency labels are assigned by sequential label-ing, as shown in Figure 1 (b), and are parsed as in-dependent segments.
Therefore, our method is suit-able for parsing semi-spoken language that containsindependent segments.3 Experiments3.1 Experimental SettingsCorpora In our experiments, we used two cor-pora.
One is the Kyoto Text Corpus 4.0 2, which isa collection of newspaper articles with segment anddependency annotations.
The other is a blog cor-pus, which is a collection of blog articles taken assemi-spoken language.
The blog corpus is manuallyannotated in a way similar to that used for the Kyototext corpus.
The sizes of the corpora are shown inTable 2.Training We used CRF++ 3, a linear-chain CRFtraining tool, with eleven features per segment.
All2http://nlp.kuee.kyoto-u.ac.jp/nl-resource/corpus.html3http://www.chasen.org/?taku/software/CRF++/of these are static features (proper to each segment)such as surface forms, parts-of-speech, inflectionsof a content headword and a functional headwordin a segment.
These are parts of a feature set thatmany papers have referenced (Uchimoto et al, 1999;Kudo and Matsumoto, 2002).Evaluation Metrics Dependency accuracy andsentence accuracy were used as evaluation metrics.Sentence accuracy is the proportion of total sen-tences in which all dependencies in the sentenceare accurately labeled.
In Japanese, the last seg-ment of most sentences is the top of the parsed trees,and many papers exclude this last segment from theaccuracy calculation.
We, in contrast, include thelast one because some of the last segments are self-dependent.3.2 Accuracy of Dependency ParsingDependency parsing was carried out by combiningtraining and test corpora.
We used a window sizeof three.
We also used CaboCha as a reference forthe set of sentences trained only with the Kyoto cor-pus because it is designed for written language.
Theresults are shown in Table 3.CaboCha had better accuracies for the Kyoto testcorpus.
One reason might be that our method man-ually combined features and used parts of com-binations, while CaboCha automatically finds thebest combinations by using second-order polyno-mial kernels.For the blog test corpus, the proposed methodusing the Kyoto+Blog model had the best depen-227Test Corpus Method Training Corpus Dependency Accuracy Sentence Accuracy(Model)Kyoto Proposed Method Kyoto 89.87% (80766 / 89874) 48.12% (4467 / 9284)(Written Language) (Window Size: 3) Kyoto + Blog 89.76% (80670 / 89874) 47.63% (4422 / 9284)CaboCha Kyoto 92.03% (82714 / 89874) 55.36% (5140 / 9284)Blog Proposed Method Kyoto 77.19% (41083 / 53226) 41.41% (3706 / 8950)(Semi-spoken Language) (Window Size: 3) Kyoto + Blog 84.59% (45022 / 53226) 52.72% (4718 / 8950)CaboCha Kyoto 77.44% (41220 / 53226) 43.45% (3889 / 8950)Table 3: Dependency and Sentence Accuracies among Methods/Corpora8888.58989.59090.5911  2  3  4  502e+064e+066e+068e+061e+07DependencyAccuracy(%)#ofFeaturesWindow SizeDependency Accuracy# of FeaturesFigure 2: Dependency Accuracy and Number ofFeatures According to Window Size (The KyotoText Corpus was used for training and testing.
)dency accuracy result at 84.59%.
This result wasinfluenced not only by the training corpus that con-tains the blog corpus but also by the effect of self-dependent segments.
The blog test corpus contains3,089 self-dependent segments, and 2,326 of them(75.30%) were accurately parsed.
This representsa dependency accuracy improvement of over 60%compared with the Kyoto model.Our method is effective in parsing blogs be-cause fillers and emoticons can be parsed as self-dependent segments.3.3 Accuracy According to Window SizeAnother characteristic of our method is that all de-pendencies, including long-distance ones, can beparsed by one labeling process if the window cov-ers the entire sentence.
To analyze this characteris-tic, we evaluated dependency accuracies in variouswindow sizes.
The results are shown in Figure 2.The number of features used for labeling in-creases exponentially as window size increases.However, dependency accuracy was saturated after awindow size of two, and the best accuracy was whenthe window size was four.
This phenomenon impliesa data sparseness problem.4 ConclusionWe presented a new dependency parsing method us-ing sequential labeling for the semi-spoken languagethat frequently appears in Web documents.
Sequen-tial labeling can supply segments with flexible la-bels, so our method can parse independent wordsas self-dependent segments.
This characteristic af-fects robust parsing when sentences contain fillersand emoticons.The other characteristics of our method are us-ing CRFs and that long dependencies are parsed inone labeling process.
SVM-based parsers that havethe same characteristics can be constructed if we in-troduce multi-class classifiers.
Further comparisonswith SVM-based parsers are future work.ReferencesEugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proc.
of NAACL-2000, pages 132?139.Taku Kudo and Yuji Matsumoto.
2002.
Japanese depen-dency analyisis using cascaded chunking.
In Proc.
ofCoNLL-2002, Taipei.Sadao Kurohashi and Makoto Nagao.
1994.
A syntacticanalysis method of long Japanese sentences based onthe detection of conjunctive structures.
ComputationalLinguistics, 20(4):507?534.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In Proc.
ofICML-2001, pages 282?289.Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara.1999.
Japanese dependency structure analysis basedon maximum entropy models.
In Proc.
of EACL?99,pages 196?203, Bergen, Norway.228
