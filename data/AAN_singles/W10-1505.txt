Proceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop, pages 32?40,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsGoogle Web 1T 5-Grams Made Easy (but not for the computer)Stefan EvertInstitute of Cognitive ScienceUniversity of Osnabru?ck49069 Osnabru?ck, Germanystefan.evert@uos.deAbstractThis paper introduces Web1T5-Easy, a sim-ple indexing solution that allows interactivesearches of the Web 1T 5-gram database anda derived database of quasi-collocations.
Thelatter is validated against co-occurrence datafrom the BNC and ukWaC on the automaticidentification of non-compositional VPC.1 IntroductionThe Google Web 1T 5-gram (Web1T5) database(Brants and Franz, 2006) consists of frequencycounts for bigram, trigrams, 4-grams and 5-gramsextracted from 1 trillion words of English Web text,i.e.
from a corpus 10,000 times the size of the BritishNational Corpus (Aston and Burnard, 1998).
Whileprimarily designed as a resource to build better lan-guage models for machine translation and other NLPapplications, its public release in 2006 was greetedwith great enthusiasm by many researchers in com-putational linguistics.
As one example, Mitchell etal.
(2008) used the Web1T5 data successfully to pre-dict fMRI neural activation associated with concretenoun concepts.For linguistic applications, though, the Web1T5database presents three major obstacles:(i) The lack of linguistic annotation: Google?s to-kenisation splits hyphenated compounds (e.g., part-time is split into a three-token sequence part|-|time)and differs in many other ways from the rules usedin liguistic corpora.
The n-grams are neither anno-tated with part-of-speech tags nor lemmatised, andthere are separate entries for sentence-initial upper-case and the corresponding lowercase forms.
(ii) The application of frequency thresholds: De-spite the enormous size of the database, its com-pilers found it necessary to omit low-frequency n-grams with fewer than 40 occurrences.
This meansthat non-adjacent word combinations are listed onlyif the occur in a relatively frequent pattern.
As aconsequence, it is impossible to obtain reliable fre-quency estimates for latent phenomena by poolingdata (e.g.
the co-occurrence frequency of a particu-lar verb with nouns denoting animals).
(iii) The difficulty of interactive search: The com-plete Web1T5 database consists of 24.4 GiB ofbinary-sorted, compressed text files.
While this for-mat is suitable for building n-gram language modelsand other offline processing, searching the databaseis not efficient enough for interactive use.
Except forsimple, case-sensitive prefix searches ?
which canbe restricted to a single file containing 50?90 MiBof compressed text ?
every query requires a linearscan of the full database.This paper presents a simple open-source soft-ware solution to the third problem, called Web1T5-Easy.
The n-gram data are encoded and indexedin a relational database.
Building on convenientopen-source tools such as SQLite and Perl, thesoftware aims to strike a good balance betweensearch efficiency and ease of use and implemen-tation.
With its focus on interactive, but accu-rate search it complements the approximate index-ing and batch processing approaches of Hawker etal.
(2007).
Web1T5-Easy can be downloaded fromhttp://webascorpus.sf.net/Web1T5-Easy/.11An online demo of the complete Web1T5 database is avail-able at http://cogsci.uos.de/~korpora/ws/Web1T5/.32word 1 word 2 word 3 fsupplement depend on 193supplement depending on 174supplement depends entirely 94supplement depends on 338supplement derived from 2668supplement des coups 77supplement described in 200Table 1: Example of Web1T5 3-gram frequency data (ex-cerpt from file 3gm-0088.gz).The rest of this paper is organised as follows.
Sec-tion 2 describes the general system architecture inmore detail.
Section 3 explains how collocations(with a maximal span size of four tokens) and dis-tributional semantic models (DSM) can be approxi-mated on the basis of Web1T5 frequency data.
Sometechnical aspects are summarised in Section 4.
Sec-tion 5 addresses the consequences of problems (i)and (ii).
The linguistic usefulness of Web1T5 col-location data is validated on a multiword extractiontask from the MWE 2008 workshop.2 Section 6 con-cludes with a brief outlook on the future develop-ment of Web1T5-Easy.2 System architectureWhile designing the fastest possible indexing archi-tecture for the Web1T5 database is an interestingcomputer science problem, linguistic applicationstypically do not require the millisecond responsetimes of a commercial search engine.
It is sufficientfor interactive queries to be completed within a fewseconds, and many users will also be willing to waitseveral minutes for the result of a complex searchoperation.
Given the tabular format of the Web1T5n-gram frequency data (cf.
Table 1), it was a naturalchoice to make use of a standard relational database(RDBMS).
Database tables can be indexed on sin-gle or multiple columns for fast access, and the SQLquery languge allows flexible analysis and aggrega-tion of frequency data (see Section 2.2 for some ex-amples).
While the indexing procedure can be verytime-consuming, it is carried out offline and has torun only once.2http://multiword.sf.net/mwe2008/Web1T5-Easy was designed to balance com-putational efficiency against implementation effortand ease of use.
Its main ingredients are thepublic-domain embedded relational database engineSQLite and the open-source scripting language Perlwhich are connected through the portable DBI/DBDinterface.3 The Web1T5-Easy package consists oftwo sets of Perl scripts.
The first set automatespre-processing and indexing, detailed in Section 2.1.The second set, which facilitates command-line ac-cess to the database and provides a Web-based GUI,is described in Section 2.2.
Technical details of therepresentation format and performance figures arepresented in Section 4.The embedded database engine SQLite was pre-ferred over a full-fledged RDBMS such as MySQLor PostgreSQL for several reasons: (i) running thedatabase as a user-level process gives better con-trol over huge database files and expensive indexingoperations, which might otherwise clog up a ded-icated MySQL server computer; (ii) each SQLitedatabase is stored in a single, platform-independentfile, so it can easily be copied to other locations orservers; (iii) an embedded database avoids the over-head of exchanging large amounts of data betweenclient and server; (iv) tight integration with the ap-plication program allows more flexible use of thedatabase than pure SQL queries (e.g., a Perl scriptcan define its own SQL functions, cf.
Section 3).It is quite possible that the sophisticated query op-timisers of MySQL and commercial RDMBS im-plementations would improve performance on com-plex SQL queries.
Since Web1T5-Easy uses thegeneric DBI interface, it can easily be adapted to anyRDMBS back-end for which DBI/DBD drivers areavailable.2.1 The indexing procedureIndexing of the Web1T5 n-gram data is carried outin four stages:1.
In an optional pre-processing step, words arefiltered and normalised to lowercase.4 Each3See the Web pages at http://www.sqlite.org/, http://www.perl.org/ and http://dbi.perl.org/.4The default filter replaces numbers by the code NUM, var-ious punctuation symbols by the code PUN, and all ?messy?strings by the code UNK.
It can easily be replaced by a user-defined normalisation mapping.33word in an n-gram entry is then coded as a nu-meric ID, which reduces database size and im-proves both indexing and query performance(see Section 4 for details on the representationformat).
The resulting tuples of n + 1 integers(n word IDs plus frequency count) are insertedinto a database table.2.
If normalisation was applied, the table will con-tain multiple entries for many n-grams.5 InStage 2, their frequency counts are aggregatedwith a suitable SQL query.
This is one of themost expensive and disk-intensive operationsof the entire indexing procedure.3.
A separate SQL index is created for each n-gram position (e.g., word 1, word 2 and word 3in Table 1).
Multi-column indexes are currentlyomitted, as they would drastically increase thesize of the database files.6 Moreover, the use ofan index only improves query execution speedif it is highly selective, as explained in Sec-tion 4.
If desired, the Perl scripts can triviallybe extended to create additional indexes.4.
A statistical analysis of the database is per-formed to improve query optimisation (i.e., ap-propriate selection of indexes).The indexing procedure is carried out separately forbigrams, trigrams, 4-grams and 5-grams, using ashared lexicon table to look up numeric IDs.
Userswho do not need the larger n-grams can easily skipthem, resulting in a considerably smaller databaseand much faster indexing.2.2 Database queries and the Web GUIAfter the SQLite database has been populated andindexed, it can be searched with standard SQLqueries (typically a join between one of the n-gramtables and the lexicon table), e.g.
using the sqlite35For example, with the default normalisation, bought 2 bot-tles, bought 5 bottles, Bought 3 bottles, BOUGHT 2 BOT-TLES and many other trigrams are mapped to the representationbought NUM bottles.
The database table thus contains multipleentries of the trigram bought NUM bottles, whose frequencycounts have to be added up.6For the 5-gram table, 10 different two-column indexeswould be required to cover a wide range of queries, more thandoubling the size of the database file.command-line utility.
Since this requires detailedknowledge of SQL syntax as well as the databaselayout and normalisation rules, the Web1T5-Easypackage offers a simpler, user-friendly query lan-guage, which is internally translated into appropriateSQL code.A Web1T5-Easy query consists of 2?5 searchterms separated by blanks.
Each search term is ei-ther a literal word (e.g.
sit), a set of words in squarebrackets (e.g.
[sit,sits,sat,sitting]), a prefix(under%) or suffix (%ation) expression, * for an ar-bitrary word, or ?
to skip a word.
The difference be-tween the latter two is that positions marked by * areincluded in the query result, while those marked by ?are not.
If a query term cannot match because of nor-malisation, an informative error message is shown.Matches can be ranked by frequency or by associa-tion scores, according to one of the measures recom-mended by Evert (2008): t-score (t), log-likelihood(G2), chi-squared with Yates?
correction (X2), point-wise MI, or a version of the Dice coefficient.For example, the query web as corpus showsthat the trigram Web as Corpus occurs 1,104times in the Google corpus (case-insensitive).%ly good fun lists ways of having fun suchas really good fun (12,223?
), jolly good fun(3,730?)
and extremely good fun (2,788?).
Thequery [sit,sits,sat,sitting] * ?
chair re-turns the patterns SIT in .
.
.
chair (201,084?
), SITon .
.
.
chair (61,901?
), SIT at .
.
.
chair (1,173?),etc.
Corpus frequencies are automatically summedover all fillers in the third slot.The query implementation is available as acommand-line version and as a CGI script thatprovides a Web-based GUI to the Web1T5-Easydatabase.
The CGI version also offers CSV andXML output formats for use as a Web service.3 Quasi-collocations and DSMMany corpus linguists and lexicographers will par-ticularly be interested in using the Web1T5 databaseas a source of collocations (in the sense of Sinclair(1991)).
While the British National Corpus at bestprovides sufficient data for a collocational analysisof some 50,000 words (taking f ?
50 to be the min-imum corpus frequency necessary), Web1T5 offerscomprehensive collocation data for almost 500,00034Figure 1: Quasi-collocations for the node word corpus in the Web GUI of Web1T5-Easy.words (which have at least 50 different collocates inthe database, and f ?
10,000 in the original Googlecorpus).Unfortunately, the Web1T5 distribution does notinclude co-occurrence frequencies of word pairs,except for data on immediately adjacent bigrams.It is possible, though, to derive approximate co-occurrence frequencies within a collocational spanof up to 4 tokens.
In this approach, each n-gram ta-ble yields information about a specific collocate po-sition relative to the node.
For instance, one canuse the 4-gram table to identify collocates of thenode word corpus at position +3 (i.e., 3 tokens tothe right of the node) with the Web1T5-Easy querycorpus ?
?
*, and collocates at position ?3 (i.e.,3 tokens to the left of the node) with the query* ?
?
corpus.
Co-occurrence frequencies withina collocational span, e.g.
(?3,+3), are obtained bysummation over all collocate positions in this win-dow, collecting data from multiple n-gram tables.It has to be kept in mind that such quasi-collocations do not represent the true co-occurrencefrequencies, since an instance of co-occurrence oftwo words is counted only if it forms part of an n-gram with f ?
40 that has been included in Web1T5.Especially for larger distances of 3 or 4 tokens, thislimitation is likely to discard most of the evidencefor co-occurrence and put a focus on collocationsthat form part of a rigid multiword unit or insti-tutionalised phrase.
Thus, cars becomes the mostsalient collocate of collectibles merely because thetwo words appear in the slogan from collectibles tocars (9,443,572?).
Section 5 validates the linguisticusefulness of Web1T5 quasi-collocations in a multi-word extraction task.Web1T5-Easy compiles frequency data for quasi-collocations in an additional step after the completen-gram data have been indexed.
For each pair of co-occurring words, the number of co-occurrences ineach collocational position (?4,?3, .
.
.
,+3,+4) isrecorded.
If the user has chosen to skip the largestn-gram tables, only a shorter collocational span willbe available.The Web GUI generates SQL code to determineco-occurrence frequencies within a user-defined col-locational span on the fly, by summation over theappropriate columns of the quasi-collocations table.Collocates can be ranked by a range of associationmeasures (t, G2, X2, MI, Dice, or frequency f ),which are implemented as user-defined SQL func-tions in the Perl code.
In this way, sophisticatedstatistical analyses can be performed even if theyare not directly supported by the RDBMS back-end.Figure 1 shows an example of quasi-collocations inthe Web GUI, ranked according to the t-score mea-sure.
On the right-hand side of the table, the distri-bution across collocate positions is visualised.In computational linguistics, collocations playan important role as the term-term co-occurrencematrix underlying distributional semantic models35size (GiB) database file no.
of rows0.23 vocabulary 5,787,5567.24 2-grams 153,634,49132.81 3-grams 594,453,30264.32 4-grams 933,385,62375.09 5-grams 909,734,58131.73 collocations 494,138,116211.42 total 3,091,133,669Table 2: Size of the fully indexed Web1T5 database, in-cluding quasi-collocations.
(DSM), with association scores used as featureweights (see e.g.
Curran (2004, Sec.
4.3)).
TheWeb1T5-Easy quasi-collocations table provides asparse representation of such a term-term matrix,where only 494?106 or 0.0015% of the 5.8?106 ?5.8?106 = 33.5?1012 cells of a full co-occurrencematrix are populated with nonzero entries.4 Technical aspectsAn essential feature of Web1T5-Easy is the numericcoding of words in the n-gram tables, which allowsfor compact storage and more efficient indexing ofthe data than a full character string representation.
Aseparate lexicon table lists every (normalised) wordform together with its corpus frequency and an in-teger ID.
The lexicon is sorted by decreasing fre-quency: since SQLite encodes integers in a variable-length format, it is advantageous to assign low IDnumbers to the most frequent terms.Every table is stored in its own SQLite databasefile, e.g.
vocabulary for the lexicon table andcollocations for quasi-collocations (cf.
Sec-tion 3).
The database files for different n-gram sizes(2-grams, 3-grams, 4-grams, 5-grams) sharethe same layout and differ only in the number ofcolumns.
Table 2 lists the disk size and number ofrows of each database file, with default normalisa-tion applied.
While the total size of 211 GiB by farexceeds the original Web1T5 distribution, it can eas-ily be handled by modern commodity hardware andis efficient enough for interactive queries.Performance measurements were made on amidrange 64-bit Linux server with 2.6 GHz AMDOpteron CPUs (4 cores) and 16 GiB RAM.
SQLitedatabase files and temporary data were stored on afast, locally mounted hard disk.
Similar or betterhardware will be available at most academic institu-tions, and even in recent personal desktop PCs.Indexing the n-gram tables in SQLite took abouttwo weeks.
Since the server was also used for mul-tiple other memory- and disk-intensive tasks duringthis period, the timings reported here should onlybe understood as rough indications.
The indexingprocess might be considerably faster on a dedicatedserver.
Roughly equal amounts of time were spenton each of the four stages listed in Section 2.1.Database analysis in Stage 4 turned out to be oflimited value because the SQLite query optimiserwas not able to make good use of this information.Therefore, a heuristic optimiser based on individualterm frequencies was added to the Perl query scripts.This optimiser chooses the n-gram slot that is mostlikely to speed up the query, and explicitly disablesthe use of indexes for all other slots.
Unless anotherconstraint is much more selective, preference is al-ways given to the first slot, which represents a clus-tered index (i.e.
database rows are stored in indexorder) and can be scanned very efficiently.With these explicit optimisations, Stage 4 of theindexing process can be omitted.
If normalisation isnot required, Stage 2 can also be skipped, reducingthe total indexing time by half.At first sight, it seems to be easy to compile thedatabase of quasi-collocations one node at a time,based on the fully indexed n-gram tables.
However,the overhead of random disk access during indexlookups made this approach intractable.7 A brute-force Perl script that performs multiple linear scansof the complete n-gram tables, holding as much datain RAM as possible, completed the compilation ofco-occurrence frequencies in about three days.Table 3 shows execution times for a selection ofWeb1T5-Easy queries entered in the Web GUI.
Ingeneral, prefix queries that start with a reasonablyspecific term (such as time of *) are very fast,even on a cold cache.
The query %ly good funis a pathological case: none of the terms is selec-tive enough to make good use of the corresponding7In particular, queries like * ?
?
corpus that scan for col-locates to the left of the node word are extremely inefficient,since the index on the last n-gram slot is not clustered and ac-cesses matching database rows in random order.36Web1T5-Easy query cold cache warm cachecorpus linguistics 0.11s 0.01sweb as corpus 1.29s 0.44stime of * 2.71s 1.09s%ly good fun 181.03s 24.37s[sit,sits,sat,sitting] * ?
chair 1.16s 0.31s* linguistics (association ranking) 11.42s 0.05suniversity of * (association ranking) 1.48s 0.48scollocations of linguistics 0.21s 0.13scollocations of web 6.19s 3.89sTable 3: Performance of interactive queries in the Web GUI of Web1T5-Easy.
Separate timings are given for a colddisk cache (first query) and warm disk cache (repeated query).
Re-running a query with modified display or rankingsettings will only take the time listed in the last column.index, and entries matching the wildcard expression%ly in the first slot are scattered across the entiretrigram table.5 Validation on a MWE extraction taskIn order to validate the linguistic usefulnessof Web1T5 quasi-collocations, they were evalu-ated on the English VPC shared task from theMWE 2008 workshop.8 This data set consists of3,078 verb-particle constructions (VPC), which havebeen manually annotated as compositional or non-compositional (Baldwin, 2008).
The task is to iden-tify non-compositional VPC as true positives (TP)and re-rank the data set accordingly.
Evaluation iscarried out in terms of precision-recall graphs, usingaverage precision (AP, corresponding to the area un-der a precision-recall curve) as a global measure ofaccuracy.Frequency data from the Web1T5 quasi-collocations table was used to calculate associationscores and rankings.
Since previous studies suggestthat no single association measure works equallywell for all tasks and data sets, several popular mea-sures were included in the evaluation: t-score (t),chi-squared with Yates?
continuity correction (X2),Dice coefficient (Dice), co-occurrence frequency( f ), log-likelihood (G2) and Mutual Information(MI); see e.g.
Evert (2008) for full equations andreferences.
The results are compared against rank-ings obtained from more traditional, linguistically8http://multiword.sf.net/mwe2008/annotated corpora of British English: the balanced,100-million-word British National Corpus (Astonand Burnard, 1998) and the 2-billion-word Webcorpus ukWaC (Baroni et al, 2009).For BNC and ukWaC, three different extractionmethods were used: (i) adjacent bigrams of verb +particle/preposition; (ii) shallow syntactic patternsbased on POS tags (allowing pronouns and simplenoun phrases between verb and particle); and (iii)surface co-occurrence within a collocational span of3 tokens to the right of the node (+1,+3), filteredby POS tag.
Association scores were calculated us-ing the same measures as for the Web1T5 quasi-collocations.
Preliminary experiments with differentcollocational spans showed consistently lower accu-racy than for (+1,+3).
In each case, the same asso-ciation measures were applied as for Web1T5.Evaluation results are shown in Figure 3 (graphs)and Table 4 (AP).
The latter also describes the cover-age of the corpus data by listing the number of can-didates for which no frequency information is avail-able (second column).
These candidates are alwaysranked at the end of the list.
While the BNC hasa coverage of 92%?94% (depending on extractionmethod), scaling up to Web1T5 completely elimi-nates the missing data problem.However, identification of non-compositionalVPC with the Web1T5 quasi-collocations is consid-erably less accurate than with linguistically anno-tated data from the much smaller BNC.
For recallvalues above 50%, the precision of statistical associ-ation measures such as t and X2 is particularly poor37coverage average precision (%)(missing) t X2 Dice f G2 MIBNC (bigrams) 242 30.04 29.75 27.12 26.55 29.86 22.79BNC (syntactic patterns) 201 30.42 30.49 27.48 25.87 30.64 22.48BNC (span +1 .
.
.+3) 185 29.15 32.12 30.13 24.33 31.06 22.58ukWaC (bigrams) 171 29.28 30.32 27.79 25.37 29.63 25.13ukWaC (syntactic patterns) 162 29.20 31.19 27.90 24.19 30.06 25.08ukWaC (span +1 .
.
.+3) 157 27.82 32.66 30.54 23.03 30.01 25.76Web1T5 (span +1 .
.
.+3) 3 25.83 25.27 25.33 20.88 25.77 20.81BNC untagged (+1 .
.
.+3) 39 27.22 27.85 28.98 22.51 28.13 19.60Table 4: Evaluation results for English non-compositional VPC (Baldwin, 2008): average precision (AP) as a globalindicator.
The baseline AP for random candidate ranking is 14.29%.
The best result in each row is highlighted in bold.
(Figure 3.h).
On the annotated corpora, where nodesand collocates are filtered by POS tags, best resultsare obtained with the least constrained extractionmethod and the chi-squared (X2) measure.
Scal-ing up to the 2-billion-word ukWaC corpus givesslightly better coverage and precision than on theBNC.
Moreover, X2 is now almost uniformly betterthan (or equal to) any other measure (Figure 3.f).lllllllllllllllll lllllllllllll lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll?4 ?2 0 2 4 6?505ukWaC (rescaled X?)Web1T5(rescaledX?
)l TPFPFigure 2: Comparison of X2 association scores on ukWaCand Web1T5.
Axes are rescaled logarithmically, preserv-ing sign to indicate positive vs. negative association.In order to determine whether the poor perfor-mance of Web1T5 is simply due to the lack of lin-guistic annotation or whether it points to an intrin-sic problem of the n-gram database, co-occurrencedata were extracted from an untagged version of theBNC using the same method as for the Web1T5 data.While there is a significant decrease in precision (cf.Figure 3.g and the last row of Table 4), the resultsare still considerably better than on Web1T5.
In theMWE 2008 competition, Ramisch et al (2008) werealso unable to improve on the BNC results using aphrase entropy measure based on search engine data.The direct comparison of X2 association scores onukWaC and Web1T5 in Figure 2 reveals that the lat-ter are divided into strongly positive and stronglynegative association, while scores on ukWaC arespread evenly across the entire range.
It is re-markable that many true positives (TP) exhibit neg-ative association in Web1T5, while all but a fewshow the expected positive association in ukWaC.This unusual pattern, which may well explain thepoor VPC evaluation results, can also be observedfor adjacent bigrams extracted from the 2-grams ta-ble (not shown).
It suggests a general problem ofthe Web1T5 data that is compounded by the quasi-collocations approach.6 Future workA new release of Web1T5-Easy is currently inpreparation.
It will refactor the Perl code intoreusable and customisable modules that can easilybe embedded in user scripts and adapted to otherdatabases such as Brants and Franz (2009).
We arelooking forward to Web1T5 v2, which promises eas-ier indexing and much richer interactive queries.38(a)0 20 40 60 80 1001020304050BNC (bigrams)Recall (%)Precision(%)tX2Dicef0 20 40 60 80 1001020304050ukWaC (bigrams)Recall (%)Precision(%)tX2Dicef(b)(c)0 20 40 60 80 1001020304050BNC (syntactic pattern)Recall (%)Precision(%)tX2Dicef0 20 40 60 80 1001020304050ukWaC (syntactic pattern)Recall (%)Precision(%)tX2Dicef(d)(e)0 20 40 60 80 1001020304050BNC (span +1,+3)Recall (%)Precision(%)tX2Dicef0 20 40 60 80 1001020304050ukWaC (span +1,+3)Recall (%)Precision(%)tX2Dicef(f)(g)0 20 40 60 80 1001020304050BNC untagged (span +1,+3)Recall (%)Precision(%)tX2Dicef0 20 40 60 80 1001020304050Web1T5 quasi?collocations (span +1,+3)Recall (%)Precision(%)tX2Dicef(h)Figure 3: Evaluation results for English non-compositional VPC (Baldwin, 2008): precision-recall graphs.
Rankingsaccording to the Web1T5 quasi-collocations are shown in the bottom right panel (h).
The baseline precision is 14.29%.39ReferencesGuy Aston and Lou Burnard.
1998.
The BNC Hand-book.
Edinburgh University Press, Edinburgh.
Seealso the BNC homepage at http://www.natcorp.ox.ac.uk/.Timothy Baldwin.
2008.
A resource for evaluating thedeep lexical acquisition of English verb-particle con-structions.
In Proceedings of the LREC Workshop To-wards a Shared Task for Multiword Expressions (MWE2008), pages 1?2, Marrakech, Morocco.Marco Baroni, Silvia Bernardini, Adriano Ferraresi, andEros Zanchetta.
2009.
The WaCky Wide Web: Acollection of very large linguistically processed Web-crawled corpora.
Language Resources and Evalua-tion, 43(3):209?226.Thorsten Brants and Alex Franz.
2006.
Web 1T 5-gramVersion 1.
Linguistic Data Consortium, Philadel-phia, PA. http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2006T13.Thorsten Brants and Alex Franz.
2009.
Web1T 5-gram, 10 European Languages Version1.
Linguistic Data Consortium, Philadelphia,PA.
http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2009T25.James Richard Curran.
2004.
From Distributional to Se-mantic Similarity.
Ph.D. thesis, University of Edin-burgh.Stefan Evert.
2008.
Corpora and collocations.
In AnkeLu?deling and Merja Kyto?, editors, Corpus Linguistics.An International Handbook, chapter 58.
Mouton deGruyter, Berlin.Tobias Hawker, Mary Gardiner, and Andrew Bennetts.2007.
Practical queries of a massive n-gram database.In Proceedings of the Australasian Language Technol-ogy Workshop 2007, pages 40?48, Melbourne, Aus-tralia.Tom M. Mitchell, Svetlana V. Shinkareva, Andrew Carl-son, Kai-Min Chang, Vicente L. Malave, Robert A.Mason, and Marcel Adam Just.
2008.
Predictinghuman brain activity associated with the meanings ofnouns.
Science, 320:1191?1195.Carlos Ramisch, Paulo Schreiner, Marco Idiart, and AlineVillavicencio.
2008.
An evaluation of methods forthe extraction of multiword expressions.
In Proceed-ings of the LREC Workshop Towards a Shared Taskfor Multiword Expressions (MWE 2008), pages 50?53,Marrakech, Morocco.John Sinclair.
1991.
Corpus, Concordance, Collocation.Oxford University Press, Oxford.40
