Synchronous Tree-Adjoining GrammarsStuart M. ShieberComputer Science DepartmentHmward UniversityCambridge, MA USAYves SchabesComputer and Information Sciences DepartmentUniversity of PennsylvaniaPhiladelphia, PA USAAbstractThe unique properties of lree-adjoining grammars (TAG)present a challenge for the application of 'FAGs beyondthe limited confines of syntax, for instance, to the task ofsemantic interpretation or automatic translation of nat-ural h'mguage.
We present a variant of "FAGs, calledsynchronous TAGs, which chmacterize correspondencesbetween languages.
"lq\]e formalism's intended usage isto relate expressions of natural anguages to their associ-ated semantics represented in a logical tbrm language, orto their translates in another natural anguage; in sum-mary, we intend it to allow TAGs to be used beyondtheir role in syntax proper.
We discuss the applicationof synchronous TAGs to concrete examples, mention-ing primarily in passing some computational issues thattu:ise in its interpretation.1 IntroductionTree-adjoining rammars (TAG) constitute a grammat-ical formalism with attractive properties for the strongcharacterization f the syntax of natural angtmges, thatis, characterization of the analysis trees of the expres-sions in the language (Kroch and Joshi, 1985; Kroch,1989)) Among these properties are thato The domain of locality in TAGs is larger thanlot formalisms lhat augment context-free grammars(such as lexical-functkmal, or generalized or head-driven phrase-structure grammar), and?
The statements of dependencies and recursion pos-sibilities in a tree are factored, the former followingfrom primitive dependencies in elementary trees,the latter a consequence of an operatkm of adjunc-tion of trees.These unique properties of TAGs present a challengetot the application of TAGs beyond the limited confinesof syntax, for instance, to the task of semantic interpre-tation or automatic tr~mslation of natural anguage.
Theslandm'd methods of moving beyond syntax to interpre-tation make use in one way or another of the compo-sitional structure of the analysis tree that is manifestedin the tree's derivation.
Any version of compositional1We assume familiarity throughout the paper with previous workon TAGs.
See, for instance, the introduction by Joshi (1987).semantics, or syntax.directed translation relies on sucha methodology to some extent.
However, in the case ofTAGs, the compositional structure of the tree is not mirorored by its derivational structure, so that a method forconstructing semantics based on the compositional syn-tactic structure will be inherently nonderivational, thatis, construction of the semantics will be independent ofthe derivation of the tree, and therefore subsequent.On the other hand, a method mirroring the deriva-tional structure will not necessarily be compositionalwith respect to tile derived structures of expressions.
AI+tl~ough such a method would be quite different from ttleprimarily compositional methods previously postulated,it may have advantages, given that certain aspects oflanguage seem to be noncompositional.
(See Section 4.
)In this paper, we present a varim~t of TAGs, calledsynchronous TAGs, which characterize correstxmdencesbetween languages.
The formalism's intended usage isto relate expressions of natural anguages to their asso-ciated semantics represented in a logical form language,or to their translations in another natural language; insummary, we intend the formalism to allow TAGs to beused beyond their role in syntax proper.
We also discussits application to concrete xamples, and mention somecomputational issues that arise in its interpretation.2 Synchronous TAGs--An Infor-mal DescriptionLanguage interpretation tasks can be thought of as asso-ciating a syntactic analysis of a sentence with some otherstmcture,---a logical form representation r an analysis ofa target language sentence, perhaps.
Synchronous TAGsare defined so as to make such associations explicit.
Theoriginal language and its associated structures are bothdefined by grammars tated in a TAG formalism; thetwo TAGs are synchronous in the sense that adjunctionand substitution operations are applied simultaneouslyto related nodes in pairs of trees, one for each language.For convenience, we will call the two languages ourceand target languages, although the formalism is not in-herently directional.As an example, consider the task of relating a frag-ment of English with a simple representation of itspredicate-argument structure.
A synchronous TAG forthis purpose is given in Figure 1.
Each element of the1 253NP V ~  R ~ T T\ V NP$ hates' / /I IGeorge george'N Jb rocco l i )  \br~coli \[vP F \p, A vp F,\]violently violently' Icooked cooked' IFigure 1: A sample synchronous TAG.synchronous TAG is a pair consisting of two elemen-tar2,' trees, one from tlie source language (English) andone from the target (logical form \[LF\]).
Nodes, one fromeach tree, may be linked; ~ such links are depicted graph-ically as thick lines.
If we project the pairs onto theirfirst or second components (ignoring the cross links), theprojections are TAGs for an English fragment and an LFfragment, respectively, qhese grammars are themselveswritten in a particular variant of TAGs; the choice of thisbase formalism, as we will call it, is free.
In the caseat hand, we have chosen single-component lexicalizedTAGs with adjunction and substitution (Schabes et el.,1988).
Later examples are built on other bases.The elementary operation in a synchronous TAG is su-pervenient on the elementary operations in the base for-malism.
A derivation step from a pair of trees (cq, a2)proceeds as follows:1..Nondeterministically choose a link in the pair con-necting two nodes (say, nl in cq and no in c~2).Nondeterministically choose a pair of trees (3~, 32)in the grammar.. Form the resultant pair </3t(oq, nl), ;32(~2, n2))where 3(c~, n) is the result of performing a primi-tive operation in the base formalism on a at noden using 3 (e.g., adjoining or substituting 3 intoat n).
32We will generalize the links later to allow sets of nodes from onetree to be linked to sets from the other.3The definition allows for the operations performed on the firstSynchronous TAG derivation then proceods by choos~ing a pair of initial trees (cq, o~2) that is an element ofthe grammar, and repeatedly applying derivation stepsas above.As an example, suppose we start with the tree pairc~ in Figure 1.
4 We choose the link from the subjectNP to T and the tree pair fl to apply to its nodes.
Theresultant, by synchronous substitution, is the tree pair:i Ny T T,\I I I\George  V " /  ~P, hates' georgeJ /Note that the links from a are preserved in the resul-tant pair cq except for the chosen link, which has nocounterpart in the result.Using tree pair 7 on the remaining link from NP to Tin oq yieldso~ 2 \] NP VP~.
.~ ~ R T .~.
T\ George y ~P hare'george')broccoli'\ hatesbroccoliThis pairing manifests the correspondence b tween thesentence "George hates broccoli" and its logical formhates' (george' , broccoli') (as written in a more tradi-tional notation).
Here we see that the links in the opera?tor trees (those in 7) are preserved in the resultant pair,accounting for the sole remaining link.
Tile trees in 7are linked in this way so that other tree pairs can modifythe N.We can continue the derivation, using 5 and ~ to gen-erate the pair given in Figure 2 thereby associating themeaningviolently' ( hates' (george', cooked'( broccol i') ) ) )with the sentence "George hates cooked broccoli vio-lently.
"A subtle issue mises with respect o link updating inthe resultant pair if two links impinge on the same node.When one of the links is chosen and an adjunction per-formed at the node, the other link must appear in theresultant.
The question as to whether that link shouldnow end at the root or foot of the adjoined tree can be re-solved in several ways.
Although the choice of methoddoes not affect any of the examples in this paper, wemention our current resolution of this problem here.
Ifthe remaining link is connected initially to the top ofand second trees to differ, one being a substitution and the other anadjunetion, for example.aWe uge standard TAG notation, marking foot nodes in auxiliarytrees with '*' and nodes where substitution is m occur with '1/.
Thenonterminal names in the logical form grammar e mnemonic forFormula, Relation (or function) symbol, Term, and Quantifier.254 2FGeorge VP ADVP violently' T ~ ~hates N,,....._ /cooked" broccoli'Icooked broccoliFigure 2: Derived tree pair for "George hates cooked broccoli violently.
"the node serving as the adjunction site, it will connectto the top of the root node of the adjoined auxiliary neeafter the adjunction has been performed; conversely, ifit is connected initially to the bottom of the node, it willconnect o the bottom of the foot node of the auxiliarytree.
In all of the examples in this paper, the links maybe thought of as connecting to the tops of nodes.
Theissue has important ramifications.
For instance, the linkupdating process allows for different derivations of asingle derivation in the source language to correspondto derivations of different derivations in the "target lan~guage; that is, derivation order in synchronous TAGsis in this respect crucial, unlike in the base TAG for-malisms.
We rely on this property in the analysis ofquantifier scope in Section 4.2.3 Why Synchronous TAGs?We turn to the question of why, in augmenting TAGsfor the purposes of encoding semantic information, itis preferable to use the synchronous TAG method overmore conventional methods, such as semantic rules in-volving logical operations (as in Montague grammaror generalized phrase-structure grammar) or complex-feature-structure encodings (as in unification-based orlogic grammar formalisms),First, the arguments for factoring recursion and depen-dencies as TAGs do for the syntax of natural anguagehave their counterparts in the semantics.
The structure ofTAGs allows syntactic dependencies--agreement, sub-categorization, and so forth--to be localized in the prim-itives of a grammar, the elementary trees.
This is mostdramatically evident in the case of long-distance depen-dencies, such as that between a wh-phrase and its as-sociated gap.
Similarly, using TAGs to construct logi-cal forms allows the localization of semantic dependen-cies in the logical forms of natural language xpressions,dependencies such as the signature requirements (argu-ment type and arity) of function and relation symbols,and even the long-distance dependencies between a wh-quantifier and its associated bound variable.
With othermethods of semantics, these dependencies cannot be lo-calized; the semantic aspects of filler-gap dependenciesmust be passed among the features of various nodes in aparse tree or otherwise distributed over the entire deriva-tion.Second, the use of the synchronous TAG augmenta-tion allows ,an even more radical reduction in the roleof features in a TAG grammar.
Because of the extendeddomain of locality that TAGs possess, the role of featuresand unification is reduced from its role in context-freebased systems.
Only finite-valued features are needed,with the possible exception of a feature whose valueencodes an expression's logical form.
In removing theconslz'uction of logical forms from the duties delegateAto features, we can maintain a strictly finiteovalued--and therefore formally dispensable---feature system IbrTAGs.As a side note, we mention a ramification of the syn-chronous TAG analysis concerning the claim of Ka-plan and Zaenen (1989) that the paths over whichlong-distance dependencies operate (in the f-structureof lexieal-functional grammatical theory) form a regu-lar language.
Vijay-Shanker and Joshi (1989) providean argument that this claim follows from several as-sumptions concerning how a feature system for TAGsmight be constrained.
Vijay-Shanker (personal commu-nication) has noted that by placing a simple assumptionon the elementary trees in the logical form componentof a synchronous TAG, the proof of this claim becomesimmediate.
Any TAG in which all foot nodes are im-mediate children of their associated root generates a treepath language that is regular.
~Thus, a synchronous TAG(like the grammar presented in Figure 1) whose semanticcomponent forms a TAG with this property necessarilyobeys the regular language constraint on long-distancesemantic dependencies.4 ApplicationsTo exemplify the formalism's utility, we briefly and in-formally describe its application to the semantics of id-ioms and quantifiers.
A companion paper (Abeill6 et al,1990) uses a mapping between two TAGs for automatictranslation between natural anguages, and constitutesa further application of the synchronous TAG concept.5This is a folk theorem whose straighlforward proof is left as anexercise for the reader,3 255More expansive descriptions of these analyses will beforthcoming in joint work with Anne Abeilld (idiomsand translation) and Anthony Kroch (quantifiers).4,1 Id iomsAbeill6 and Schabes (1989) note that lexicalized TAGsare an appropriate r presentation language for idiomaticconstructions, as their expanded omain of locality canaccount for many syntactic properties of idioms.
Itseems natural to generalize beyond syntax, as they do,to the claim that lexicalized 'FAGs allow one to dealwith semantic noncompositionality.
Their argument tothis claim is based on an intuition that semantics de-pends on the TAG derivation structure, an intuition thatsynchronous TAGs makes precise.
For example, the id-iomatic construction "kick the bucket" cashes out as thefollowing tree pair, under its idiomatic interpretation:a3 d}e' $whereas the literal usage of "kick" is associated witha tree pair similar to that of "hates" in Figure 1.
Twoderivations of the sentence "George kicked the bucket"are possible, each using a different one of these twoelementary tree pairs, but both yielding identical de-rived constituency trees for the English.
They will beassociated, of course, with two different readings, cor-responding to the idiomatic (die'(yeorge')) and literal(kick'(george ~,bucket')) interpretations, respectively.All of the arguments for the TAG analysis of idiomsand light verb constructions can then be maintained ina formalism that allows for semantics for them as well.In particular,?
Discontinuous syntactic onstituents can be seman-tic'ally localized.?
Nonstandard long-distance dependencies are stat-able without resort to reanalysis.?
Both frozen and flexible idioms can be easily char-acterized.4.2 Quant i f ie rsIn order to characterize quantifier scoping possibilities,we use a synchronous TAG whose base formalism ismulti-component TAGs (Joshi, 1987), in which the prim-itive operation is incorporation (by multiple substitutionsand adjunctions) of a set of elementary trees at once.
Insynchronous multi-component TAGs, the links betweentrees connect, in general, a set of nodes in one tree witha set in another.
In particular, an NP will be linked bothto a formula in the semantics (the quantifier's scope) anda term (the position bound by the quantifier).
We willbegin a derivation with just such a pair of elementat3,trees, depicted as at  in Figure 3.To distinguish two separate links from a single linkamong several nodes, we use a coindexing--rather thangraphical~-notation f r links.
Thus, the subject NP nodeon the left is linked with both the F and first T nodeon the right, as indicated by the boxed index 1.
Theinteqgretation f such "hyper-links" is that when a pairis chosen to operate at the link, it must have sets of thecorrect sizes as its left and right component (1 and 2 inthe case at hmad) and the sets are simultaneously usedat the various nodes as in a multi-component "lAG.
Forinstance, a quantifiable noun will be paired with a set oftwo  trees: 6politician R T xpoliticianApplying the latter multi-component tree pair fll to theinitial tree pair a l ,  we derive the next stage in the deriva-tion o~2.
We have highlighted the link being operated onat this and later steps by using thick lines for the indexboxes of the selected link.The determiner can be introduced with the simple pairleading to the derivation step a3.
Completing the deriva-tion using analogous elementary tree pairs, we mightgenerate the final tree pair a4 of Figure 3.
This finalpairing associates the meaningBy : vegetablc' (y).Vx : politician' (z).hates' ( z, y)with the sentence "Every politician hates some veg-etable."
It should be clear that in a structure such as thiswith multiple NPs, the order of substitution of NPs de-termines the relative scope of the quantifiers, although ithas no effect whatsoever on the syntactic structure.
De-veloping this line of reasoning has led to several detailedpredictions of this analysis of quantifier scope, which isbeyond this paper's purview.
In summary, however, theanalysis is slightly more restrictive than that of Hobbsand Shieber (1987), making predictions regarding thescope of topicalized or wh-moved constituents, relativescope of embedded quantifiers, and possibly even syn-tactic structure of complex NPs.5 Using Synchronous TAGsThe synchronous TAG formalism is inherently nondirec-tional.
Derivation is not defined in terms of constructing6The subscript x on certain nodes is the value of a feature onthe nodes corresponding to the variable bound by the quantifier.
Thetechnique of using metavariables to encode object variables is familiarfrom the logic and unification-based grammar literatures, Variablerenaming with respect o these variables proceeds as usual.256 4%I SV NP~\]1hatesNPV NP~Ipolitician hatesmm F \j - -T '~.. .
.NINF /IIiq~, ~x  FR T x R T x NT, I"I 1 politician' hates'%%(fSNPD N V NPDII I tevery politician hatesS .
- - t i ' - -"- - - - .NPD N V NPevery politician hates D NI Ia vegetableF FVR T x R T x ry lT /  I I '~ /  politician" hates' /\9Y F Fvegetable V ,R T x R T x T, / I I Y/ politician' hates" /Figure 3: Sample synchronous TAG derivation steps for "Every politician hates a vegetable.
"a tin'get expression from a source or vice versa.
Thus,it can be used to characterize both of these mappings.Furthermore, the existence of a parsing algorithm forthe base formalism of a synchronous TAG is a sufficientcondition for interpreting a synchronous TAG grammar.Schabes and Joshi (1988) and Vijay-Shanker and Joshi(1985) provide parsing algorithms for TAGs that couldserw:: to parse the base formalism of a synchronous TAG.Given such an algorithm, semantic interpretation canbe performed by parsing the sentence according to thesource grammar; the pairings then determine a deriva-tion in the target language for tile logical form.
Gen-eration from a logical form proceeds by the converseprocess of parsing the logical form expression therebydetermining the derivation for the natural anguage sen-fence.
Machine translation proceeds akmg similar linesby mapping two 'FAGs directly (Abeill6 et al, 1990),In previous work, one of us noted that generation ac-cording to an augmented context-free grammar can bemade more efficient by requiring the grammar to be se-mantically monotonic (Shieber, 1988); the derived se-mantics for an expression must include, in an appropri-ate sense, the semantic material of all its subconstituents.It is interesting to note that synchronous "FAGs are in-herently semantically monotonic.
Furthermore, it is rea-sonable to require that the semantic omponent of a syn-chronous TAG t~ lexicalized (in the sense of Schabes etal.
(1988)), allowing for more efficient parsing accord-ing to the semantic grammar and, consequenlly, moreefficient generation.
In the case of augmented context-free grammars, the semantic monotonicity requirementprecludes "lexicalization" of the semantics.
It is notpossible to require nontrivial semantics to be associatedwith each lexical item.
In summary, just as lexicaliza-lion of the syntactic grammar aids parsing (Schabes andJoshi, 1990), so lexicalization of the semantic gra.,nmz:raids generation.Tile description of parsing and germration above rnayseem to imply that these processes cannot be pcrlormcdincrementally, that is, an entire source derivation mustbe recovered before the corresponding target derivationcan be computed.
The issue deserves clarification.In the case wltere the synchronous TAG is order-independent ( hat is, the order of derivation in one TAGdoes not effect the result in the other, as when no twolinks share an endpoint) there is a one-to-one mappingbetween the source and target derivation.
When par-tial source derivations are recognized by the parser, thecorresponding partial target derivation (for example se-mantic inteq)retation) can be incrementally compuled:as the input is read from left to right, interpretationsof the partial target derivations corresponding to partialsource derivations can be combined in one step to buikla larger partial target derivation.5 257When the synchronous TAG is order-sensitive, how-ever, there may be a many-to-many correspondence b -tween source derivations and target derivations.
This isthe case, for instance, in a grammar in which alterna-tive quantifier scopings may be generated for a singlesentence.
In this case, it is unclear what should even bemeant by incremental computation.
For instance, mid-way in parsing a sentence, at a point at which a singlequantified NP has been analyzed, the incremental inter-pretation could not possibly represent all possible scop-ings that that quantifier might end up taking, as it is notknown what the quantifier might be required to scopewith respect o.
At the point in the parse where thescoping decision can be made, it is not clear whether aninerementality requirement would mean that the variantscopings must all be explicitly generated at that point,or only implicitly generable.With respect o synchronous TAGs, these considera-tions are reflected in choice of parsing algorithm.
Ef-ficiency of parsing necessitates that only one canonicalderivation (say leftmost or rightmost) need to be com-puted; all other derivations yield the same object.
Stan-dard parsing algorithms for both TAGs and CFGs relyon this optimization.
If incrementality requires that wegenerate xplicit representations of all possible interpre-tations (i.e., target derivations) of the string seen so far,then this optimization cannot be used, and parsing willbe highly inefficient.
If the representation can be left im-plicit, the optimization can be maintained, but retrievalof explicit representations will be combinatorially morecomplex.6 ConclusionThe use of tree-adjoining grammars for natural-language-processing tasks requh'es the ability to movebeyond a characterization f syntactic structure, Syn-chronous TAGs provide a simple mechanism that canbe used to graft such an ability onto a base TAG for-realism.AcknowledgementsThis research was partially funded by ARt  grantDAAG29-84-K-0061, DARPA grant N00014-85-K0018,and NSF grant MCS-82-19196 at the University of Penn-sylvania.
We are indebted to Aravind Joshi for his sup-port of this research and to Anne AbeiU6 and AnthonyKroch for their collaboration in the genesis of theseideas and their comments on earlier versions.
K. Vijay-Shanker and Marilyn Walker also provided valuablecomments.
All remaining errors are the authors' re-sponsibility alone.BibliographyAnne Abeill6 and Yves Schabes.
1989.
Parsing idiomsin tree adjoining grammars.
In Proceedings of theFourth Conference of the European Chapter of the As-sociation for Computational Linguistics, Manchester,England.Anne Abeill6, Yves Schabes, and Aravind K. Joshi.1990.
Using lexicalized tree adjoining grammm'sfor machine Ixanslation.
To appear in the 13 ~h In-ternational Conference on Computational Linguistics(COLING'90).Jerry Hobbs and Stuart M. Shieber.
1987.
An algo-rithm for generating quantifier scopings, Computa-tional Linguistics, 13 (1-2):47-63.Aravind K. Joshi and K. Vijay-Shanker.
1989.
Un-bounded ependencies in tags and lfg: functional un-certainty is a corolary in tags.
In Proceedings ofthe 27 th Meeting of the Association for ComputationalLinguistics, Vancouver.Aravind K. Joshi.
1987.
An introduction to tree adjoin-ing grammars.
In A. Manaster-Ramer, ditor, Mathe-matics of Language.
John Benjamins, Amsterdam.Ron Kaplan and Annie Zaenen.
1989.
Long-distancedependencies a a case of functional uncertainty.
InM.
Baltin and A. Kroch, editors, Alternative Concep-tions of Phrase Structure.
University of Chicago Press.Anthony Kroch and Aravind K. Joshi.
1985.
The lin-guistic relevance of tree adjoining grammars.
Techni-cal Report MS-CIS-85-18, Department of Computerand Information Science, University of Pennsylvania,April.Anthony Kroch.
1989.
Asymmetries in long dis-tance extraction in a tag grammar.
In M. Baltin andA.
Kroch, editors, Alternative Conceptions of PhraseStructure, pages 66-98.
University of Chicago Press.Yves Schabes and Aravind K. Joshi.
1988.
An Earley-type parsing algorithm for tree adjoining grammars.In Proceedings of the 26 ~h Meeting of the Associationfor Computational Linguistics, Buffalo, June.Yves Schabes and Aravind K. Joshi.
1990.
Parsingwith lexicalized tree adjoining grammar.
In MasaruTomita, editor, Current Issues in Parsing Technolo-gies.
Kluwer Accademic Publishers.Yves Schabes, Anne Abeill6, and Aravind K. Joshi.1988.
Parsing strategies with 'lexiealized' grammars:Application to tree adjoining grammars.
In Proceed-ings of the 12 th International Conference on Compu-tational Linguistics, Budapest, Hungary, August.Stuart M. Shieber.
1988.
A uniform architecture forparsing and generation.
In Proceedings of the 12 ~hInternational Conference on Computational Linguis-tics, Budapest, August.K.
Vijay-Shanker and Aravind K. Joshi.
1985.
Somecomputational properties of tree adjoining grammars.In 23 ~a Meeting of the Association for ComputationalLinguistics, pages 82-93, Chicago, Illinois, July.258  6
