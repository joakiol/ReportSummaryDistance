Rebuilding the Oxford Dictionary of English  as a semantic networkJames McCRACKENOxford University PressGreat Clarendon StreetOxford OX2 6DP, UKjames.mccracken@oup.comAbstractThis paper describes a project to develop a lexiconfor use both as an electronic dictionary and as adatabase for a range of NLP tasks.
It proposes thata lexicon for such open-ended application may bederived from a human-user dictionary, retainingand enhancing the richness of its editorial contentbut abandoning its entry-list structure in favour ofnetworks of relationships between discrete lexicalobjects, where each object represents a discretelexeme-meaning unit.1 IntroductionDictionaries intended for human users typicallysacrifice strict formalism, structure, andconsistency in the interests of space andreadability.
Furthermore, a dictionary may assumea certain level of knowledge on the part of thereader, and so need not always be exhaustivelyexplicit about all aspects of a given lexeme.
On theother hand, traditional high-level lexicography isvaluable for the rich variety of detailed, complexinformation integrated in each entry, usually withvery low error rates.
Clearly, then, there are bothbenefits and problems in attempting to mine orquery such a dictionary computationally.1 Theproject described here attempts to retain the richeditorial content of a dictionary but to reorganize itin structured networks that are more readilyprocessed and traversed - in other words, topreserve the benefits while smoothing out some ofthe problems.2 MethodThe major steps in this process were as follows:1.
Decomposition of the dictionary as a flatlist of entries, to be replaced by a set oflexical objects (each correspondingroughly to a single lexeme-meaning pair inthe original dictionary, and minimallyretaining all the text of that meaning)(section 4 below).1 See Ide and Veronis 1993 for a good account of thistension.2.
Population of each lexical object with acomplete set of morphological andsyntactic data (section 5 below).3.
Classification connecting lexical objects toeach other in semantic hierarchies andnetworks of domain relationships (section6 below).3 Choice of dictionaryThe dictionary selected was the OxfordDictionary of English  (2003) (ODE).
This is arelatively high-level dictionary, intended for fluentEnglish speakers rather than learners.
Accordingly,it assumes a body of general knowledge and adegree of semantic and grammatical competenceon the part of the user: not everything is madeexplicit in the text.2 Computational analysis of thetext must be designed to identify and aggregatecues, and to employ rules for inheritinginformation from entry or branch level down tosense level, in order to generate the right data toconstruct each lexical object (see section 4 below).On the other hand, ODE has some key featuresthat make it particularly appropriate forenhancement a as comprehensive electronic lexicaldatabase, usable both as a dictionary and as aresource for exploitation in NLP applications:?
even-handed treatment of both British andAmerican spellings, plus extensivecoverage of other World English;?
coverage of proper-name items (places,people, events, etc.);?
relatively codified editorial style,facilitating computational evaluation ofdefinitions;?
detailed and codified indication ofsyntactic characteristics, sense by sense;?
example sentences linked to individualsenses, providing cues about grammaticalbehaviour and collocation.Furthermore, ODE is very much a corpus-baseddictionary: all key editorial decisions - including2 An example of this in ODE is the high number ofrun-on derivatives, which are undefined on theassumption that the user will be able to infer the sensemorphologically.orthography, sense distinctions, choice of examplesentences, and syntactic information - aremotivated primarily by corpus evidence.
Thismeans that a formalized encoding of theinformation presented in the dictionary is likely togenerate robust and comprehensive resources forNLP tasks dealing with arbitrary real-world text.4 Data structure and lexical objectsThe ODE data structure dispenses with the ideaof the entry  as the dictionary's basic unit.
Thismove reflects the proposition that the traditionaldictionary entry is an artefact of human-readabledictionaries, and expresses a predominantlyetymological view of the language.
The dictionaryentry brings together lexical elements (definitions,parts of speech, phrases, etc.)
which may havelittle relationship to each other from the point ofview of language use (meaning, domain,frequency, collocation, etc.).
The entry is thereforean inappropriate unit for computer processing.Instead, the ODE data structure is built as aseries of discrete lexical objects which correspondroughly to individual dictionary senses or to sensesof embedded lemmas (phrases, compounds,derivatives, etc.).
These lexical objects function aspackets of data which exist independently of eachother, each containing all relevant informationabout meaning, morphology, lexical function,semantic category, etc.
Hence every sense may bequeried, extracted, or manipulated as anindependent object without any reference to theentry in which it was originally situated.Although search results, etc., may still(typically) be represented to the user in the form oftraditional dictionary entries, from a functionalpoint of view the entry is rendered redundant as adata object, and for almost all purposes is ignoredwhen handling search queries and otherprocessing.The choice of lexeme-meaning pair rather thanentry as the basic lexical object allows a muchmore detailed and exhaustive specification of theway the language functions on a sense-by-sensebasis.
Each object typically includes (minimally) adefinition, one or more example sentences, a fullspecification of morphology and syntacticbehaviour (see section 5 below), and a range ofclassifiers (see section 6 below).
This creates someredundancy: for example, an entry with numeroussenses may generate several lexical objects whichrepeat the same morphology and syntacticbehaviour.
However, this is more than offset by theadvantages: by integrating data into self-containedlexical objects, the structure (a) supports robustand positive Boolean operations and (b) opens upthe lexicon for reconfiguration according to anynew type of lexical or semantic relation.5 Morphological and phrasal specificationEvery lexical object in ODE provides a completespecification of all the lexical forms relevant to itssense.
This includes not only the morphology ofthe lexemes themselves, but also structured dataabout their syntactic roles, variant spellings, Britishand US spellings, and alternative forms.
This istrue not only for single-word lexemes but also forabbreviations, initialisms, affixes, contractions,compounds, phrases, and proper names.
ODE thusprovides facility for look-up of real-world lexicalforms in context, including:As mentioned above, such data was generatedfor every lexical object (sense).
For somepolysemous headwords this may mean multiplerepetitions of morphological listings.
Moretypically, however, listings vary from sense tosense.
One common variable, for example, is thatfor a given noun headword, some lexical objectsmay include a plural while others do not.
Similarly,variant spellings may often be associated withsome but not all lexical objects.
More pertinentlyperhaps, phrasal patterns associated with thelexeme will vary significantly from sense to sense,particularly for verbs.It should be noted that this formal variability canplay an important role in the early stages ofdisambiguation tasks; the particular form of alexeme or extended phrase may often allow groupsof senses to be reliably discounted or at leastdowngraded as possible meanings.3 This simplifiesthe set of candidate meanings subsequentlypresented to semantic analysis algorithms.Hence it was judged necessary to developdistinctive morphological and phrasalspecifications for each lexical object.
Principallythis was done algorithmically: the dictionary textassociated with each lexical object was examinedfor clues not only in explicit syntax informationbut also in definition patterns and especially inexample sentences.
In default of any strongpointers emerging from this process, forms wereproduced by a simple morphological generator.However, it became apparent that many formalvariations were not cued in any way by thedictionary text.
As a simple example, if anadjective is gradable then this is always indicated3 John Sinclair has proposed that 'Every distinction inmeaning is associated with a distinction in form' (quotedin Hanks 2003, p. 61).
Although doubtful about this as auniversal rule, I agree that for a given lexeme one mayoften link major categories of meaning to typical formalcharacteristics.at headword level in the dictionary, but there isnothing to indicate which senses  are gradable andwhich are not.
Because of limitations like this, asignificant stage of post-processing manualcorrection was necessary.6 ClassificationEach lexical object includes a set of classifierswhich are used to position the object's definition insemantic taxonomies (structures ofsuperordination/subordination) and in subject areas(domains).This may be used in two principal ways.
Firstly,it allows the dictionary to be navigated alongassociative or thesaurus-like routes: it structuresthe lexicon?s set of objects into a network ofconnections between meanings.
Secondly, it allowscalculations of semantic distance between lexicalobjects, supporting NLP tasks relating to sensedisambiguation, context-sensitive look-up, anddocument classification.46.1 Semantic taxonomyAll lexical objects representing noun meanings(about 100,000) have been structured in a semantictaxonomy.
This represents a substantial majority ofall objects; the smaller sets of verbs and adjectiveswill be similarly structured as the next stage of theproject.The taxonomy's high-level nodes (majorclassifications) were originally constructed tofollow the file structure of WordNet nouns.Although the ODE taxonomy has subsequentlydiverged in detail, mappings to WordNet havebeen retained.
At the early stages of the project, arelatively small number of noun objects wereclassified manually.
The definitions contained inthese objects were then used as training data toestablish a definitional 'profile' for each high-levelnode.
Definitional profiles were used toautomatically classify further objects.
Appliediteratively (with manual correction at each stage),this process succeeded in classifying all nounobjects in a relatively coarse-grained way.Beyond this stage, the statistical data which hadpreviously been integrated to build definitionprofiles was instead decomposed to help identifyways in which high-level nodes could besubdivided to develop greater granularity.Definitional profiling here involves twoelements:4 Metrics for using taxonomies to calculate semanticsimilarity are discussed in Leacock and Chodorow1998.
An implementation of ODE as an electronicdictionary uses such metrics in the automatic glossing ofits own text.1.
Identification of the 'key term' in thedefinition.
This is the most significantnoun in the definition.
It is not alwayscoterminous with the genus term; forexample, in a definition beginning 'amorsel of food which?
', the 'key term' iscalculated to be food  rather than morsel .2.
Stemming and scoring of all othermeaningful lexemes in the definition(ignoring articles, conjunctions, etc.).
Asimple weighting scheme is used to givemore importance to lexemes at thebeginning of a definition (e.g.
a modifierof the key term) than to lexemes at the end.These two elements are then assigned mutualinformation scores in relation to each possibleclassification, and the two MI scores are combinedin order to give an overall score.
This overall scoreis taken to be a measure of how 'typical' a givendefinition would be for a given classification.
Thisenables one very readily to rank all the lexicalobjects attached to a given node, and to identifyother objects which are candidates for that node.The semantic taxonomy currently has about2200 nodes on up to 12 levels - on average, 46objects per node.
However, this average disguisesthe fact that there are a small number of nodeswhich classify significantly larger sets of objects.Further subcategorization of large sets is desirablein principle, but is not considered a priority in allcases: subcategorization of a given set isdeprioritized if the set if relatively homogeneous,i.e.
if the distribution of 'typicality' scores for eachobject is relatively small.5Hence the goal is not achieve granularity on theorder of WordNet's 'synset' (a set in which allterms are synonymous, and hence are rarely morethan four or five in number).
Instead, granularity isbased on a more thesaurus-like measure of paritybetween objects in a set.6.2 DomainsAs with semantic classification, a number ofdomain indicators were assigned manually, andthese were then used iteratively to seed assignmentof further indicators to statistically similardefinitions.
Automatic assignment is a little morestraightforward and robust here, since most of thetime the occurrence of strongly-typed vocabularywill be a sufficient cue, and there is little necessity5 For example, the tree set is several times larger thanaverage, but since tree definitions have similar profiles,the set produces a high homogeneity score.
This accordsloosely with the intuition that for most NLP purposes,there is little value in making semantic distinctionsbetween different species of tree.to identify a key term or otherwise to parse thedefinition.Not every lexical object is domain-specific:currently 49% of all objects have been assigned atleast one domain marker.
Each iteration of theassignment process will continue to capture objectswhich are less and less strongly related to thedomain.
Beyond a certain point, the relationshipwill become too tenuous to be of much use in mostcontexts; but that point will differ for each subjectfield (and for each context).
Hence a furtherobjective is to implement a grading scheme whichnot only classifies an object by domain but alsoscores its relevance to that domain.Currently, a set of about 220 domains are used,both technical (Pharmaceutics, Oceanography ,)and thematic (Crime, Sex ).
These were originallyplanned to be organized in a Dewey-liketaxonomy.
However, this was found to beunworkable, since within the lexicon domainsemerged as a series of overlapping fields ratherthan as a hierarchy.
Hence the domains have nowbeen reorganized not taxonomically but rather as anetwork of multiple connections.
Within thenetwork, each edge connecting two domainsrepresents the strength of association betweenthose domains.67 Work in progressOngoing work focuses mainly on thecumulative population of lexical objects withadditional data fields, in particular collocations andfrequency measures.Additionally, further classifier types are beingtrialled in order to define further relations betweenlexical objects.
These include linguistic relationssuch as antonymy and root derivation, and real-world relations such as geographical region.8 ConclusionThe strategy used in constructing the ODEelectronic database was to preserve the fulleditorial content of a human-user dictionary but torebuild its structure, replacing the entry-listparadigm with a manifold network of relationsbetween meanings.The key benefit of this approach is in theversatility of the database.
Lexical objects may bereassembled into entries for display, so ODE canstill function as an electronic human-user6 Strength of association from Domain_A toDomain_B is determined internally to ODE, bycalculating the proportion of (a) lexemes and (b)semantic sets in which both domains appear, as opposedto those in which only Domain_A appears.
Strength ofassociation is not mutual.dictionary, albeit one that takes advantage of novelsearch and navigation features.
Additionally, ODEis directly usable in a number of non-dictionaryapplications.
These include context-sensitivespellchecking, tagging and parsing, documentcategorization, and context-sensitive documentglossing.Feedback from such applications is beingmonitored not only to critically examine andcorrect the source data, but also to examine thesource dictionary itself: because much of theformal and classificatory data is generatedalgorithmically from analysis of the sourceeditorial content of each lexical object (definition,etc.
), anomalies emerging in that data can often betraced back to anomalies in the editorial content(e.g.
inconsistencies in defining style).The ODE project is therefore in part anattempt to bridge the distinction between human-user dictionaries and WordNet-like associativeelectronic lexicons.
By deriving the one from theother, it invites applications to navigate and minethe rich lexicographic content of the originaldictionary by means of a new set of structuredrelations and frameworks.AcknowledgementsI would like to thank Adam Kilgarriff of ITRI,Brighton, who has played a key role in advising onmany aspects of the work described here.ReferencesHanks, P. 2003.
'Lexicography'.
In R. Mitkov (ed.
),The Oxford Handbook of ComputationalLinguistics .
Oxford: Oxford University Press.Ide, N. and J. Veronis, 1993.
'Extractingknowledge bases from machine-readabledictionaries: have we wasted our time?'.
inKB&KS Workshop .
Tokyo.Leacock, C. and M. Chodorow.
1998.
'Combininglocal context and WordNet similarity for wordsense identification'.
In C. Fellbaum (ed.
),WordNet: An Electronic Lexical Database .Cambridge, Mass.
: MIT Press.Rigau, G., 1994.
'An experiment on automaticsemantic tagging of dictionary senses'.
InProceedings of the workshop 'The Future ofDictionary' .
Aix-les-Bains, France.Soanes, C. and A. Stevenson.
2003.
OxfordDictionary of Eng lish.
Oxford: OxfordUniversity Press.
