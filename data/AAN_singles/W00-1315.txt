Empirical Term Weighting and Expansion FrequencyKyoji UmemuraToyohashi University of TechnologyToyohashi Aichi 441-8580 Japanumemura@tut  i cs .
ru t .
ac .
jpKenneth W. ChurchAT&T Labs-Research180 Park Ave., Florham Park, NJ.kwc~research ,  art.
comAbstractWe propose an empirical method for estimatingterm weights directly from relevance judgements,avoiding various standard but potentially trouble-some assumptions.
It is common to assume, for ex-ample, that weights vary with term frequency (t f )and inverse document frequency (idf) in a particu-lar way, e.g., t f .
idf, but the fact that there are somany variants of this formula in the literature sug-gests that there remains considerable uncertaintyabout these assumptions.
Our method is similar tothe Berkeley regression method where labeled rel-evance judgements are fit as a linear combinationof (transforms of) t f, idf, etc.
Training meth-ods not only improve performance, but also ex-tend naturally to include additional factors suchas burstiness and query expansion.
The proposedhistogram-based training method provides a sim-ple way to model complicated interactions amongfactors such as t f ,  idf, burstiness and expansionfrequency (a generalization of query expansion).The correct handling of expanded term is realizedbased on statistical information.
Expansion fre-quency dramatically improves performance froma level comparable to BKJJBIDS, Berkeley's en-try in the Japanese NACSIS NTCIR-1 evaluationfor short queries, to the level of JCB1, the topsystem in the evaluation.
JCB1 uses sophisti-cated (and proprietary) natural anguage process-ing techniques developed by Just System, a leaderin the Japanese word-processing industry.
We areencouraged that the proposed method, which issimple to understand and replicate, can reach thislevel of performance.1 In t roduct ionAn empirical method for estimating term weightsdirectly from relevance judgements is proposed.The method is designed to make as few assump-tions as possible.
It is similar to Berkeley's useof regression (Cooper et al, 1994) (Chen et al,1999) where labeled relevance judgements are fitas a linear combination of (transforms of) t f ,  idf,etc., but avoids potentially troublesome assump-tions by introducing histogram methods.
Termsare grouped into bins.
Weights are computedbased on the number of relevant and irrelevantdocuments associated with each bin.
The result-?
t: a term?
d: a document?
t f ( t ,  d): term freq = # of instances of t in d?
df(t): doc freq = # of docs d with t f(t ,  d) > 1?
N: # of documents in collection?
idf(t): inverse document freq: -log2 d~t)?
df(t ,  tel, t f0): # of relevant documents d witht f(t ,  d) = tfo?
df(t, rel, tfo): # of irrelevant documents dwith tf(t ,  d) = tfo?
el(t): expansion frequency = # docs d inquery expansion with t f ( t ,  d) > 1?
TF(t): standard notion of frequency incorpus-based NLP: TF(t)  = ~d tf(t ,  d)?
B(t): burstiness: B(t) = 1 iff ~ is large.
df(t)Table 1: Notationing weights usually lie between 0 and idf, whichis a surprise; standard formulas like t f .
idf wouldassign values well outside this range.The method extends naturally to include ad-ditional factors such as query expansion.
Termsmentioned explicitly in the query receive muchlarger weights than terms brought in via queryexpansion.
In addition, whether or not a termt is mentioned explicitly in the query, if t ap-pears in documents brought in by query expan-sion (el(t) > 1) then t will receive a much largerweight than it would have otherwise (ef(t) = 0).The interactions among these factors, however, arecomplicated and collection dependent.
It is saferto use histogram methods than to impose unnec-essary and potentially troublesome assumptionssuch as normality and independence.Under the vector space model, the score for adocument d and a query q is computed by sum-ming a contribution for each term t over an ap-propriate set of terms, T. T is often limited toterms shared by both the document and the query(minus stop words), though not always (e.g, queryexpansion).117i#12.8910.879.798.967.756.825.784.743.852.851.780.88t /=O t f= l  t / :=2 t f=3 t f>4-0.37 9.73 11.69 12.45 13.59-0.49 8.00 9.95 11.47 12.06-0.86 7.36 9.38 10.63 10.88-0.60 6.26 7.99 8.99 9.41-0.34 4.62 5.82 6.62 7.98-1.26 3.94 6.05 7.59 8.98-0.83 3.16 5.17 5.77 7.00-0.84 2.46 3.91 4.54 5.58-0.60 1.58 2:.76 3.57 4.55-1.02 1.00 1.72 2.55 3.96-1.33 -0.06 1.05 2.46 4.50-0.16 0.17 0.19 -0.10 -0.37Table 2: Empirical estimates of A as a function oft f  and idf.
Terms are assi._~ed to bins based onidf.
The column labeled idf is the mean idf forthe terms in each bin.
A is estimated separately foreach bin and each t f  value, based on the labeledrelevance judgements.score~(d, q) = E t/(t,  d) .
idf(t)tETUnder the probabilistic retrieval model, docu-ments are scored by summing a similar contribu-tion for each term t.= ~ l P(tJrel)In this work, we use A to refer to term weights.q) = d, q)tETThis paper will start by showing how to estimate Afrom relevance judgements.
Three parameteriza-tions will be considered: (1) fit-G, (2) fit-B, whichintroduces burstiness, and (3) fit-E, which intro-duces expansion frequency.
The evaluation sectionshows that each model improves on the previousone.
But in addition to performance, we are alsointerested in the interpretations of the parameters.2 Superv ised  Tra in ingThe statistical task is to compute A, our best esti-mate of A, based on a training set.
This paper willuse supervised methods where the training mate-rials not only include a large number of documentsbut also a few queries labeled with relevance judge-ments.To make the training task more manageable, itis common practice to map the space of all termsinto a lower dimensional feature space.
In otherwords, instead of estimating a different A for eachterm in the vocabulary, we can model A as a func-tion of tf and idf and various other features ofTrain/ ~4 .~ / 1 ~0 2 4 6 8 10 12IDFTest4 ~ s~-.~ 2  110 2 4 6 8 10 12IDFFigure 1: Empirical weights, A.
Top panel showsvalues in previous table.
Most points fall betweenthe dashed lines (lower limit of A = 0 and upperlimit of A = idf).
The plotting character denotest f .
Note that the line with t f  = 4 is above theline with t f  = 3, which is above the line witht f  = 2, and so on.
The higher lines have largerintercepts and larger slopes than the lower lines.That is, when we fit A ,~, a(tf) + b(tf) ,  idf, withseparate regression coefficients, a(tf) and b(tf),for each value of t f ,  we find that both a(tf) andb(tf) increase with t\].terms.
In this way, all of the terms in a bin areassigned the weight, A.
The common practice,for example, of assigning t f  ?
idf weights can beinterpreted as grouping all terms with the sameidf into a bin and assigning them all the sameweight, namely t f .
idf.
Cooper and his colleaguesat Berkeley (Cooper et al, 1994) (Chen et al,1999) have been using regression methods to fitas a linear combination of idf , log(t f )  and var-ious other features.
This method is also groupingterms into bins based on their features and assign-ing similar weights to terms with similar features.In general, term weighting methods that are fitto data are more flexible than weighting methodsthat are not fit to data.
We believe this additionalflexibility improves precision and recall (table 8).Instead of multiple regression, though, wechoose a more empirical approach.
Parametric as-1181234567891011121314152021Description (function of term t)df(t, rel,O) _-- # tel does d with t f ( t ,d)  = 0dr(t, tel, 1) _= # rel does d with tf(t ,  d) = 1dr(t, rel, 2) _= # rel does d with t f(t ,  d) = 2df(t, rel,3) ~ # rel does d with t f ( t ,d)  = 3df(t, rel,4+) ~ # tel does d with t f ( t ,d)  _>dr(t, tel, O) ~ # tel does d with t f(t ,  d) = 0dr(t, rel, 1) ~_ # tel does d with t f(t ,  d) = 1dr(t, tel, 2) ~ # rel does d with t f(t ,  d) = 2where dr(bin, rel, t f )  is1dr(bin, tel, t f )  ~ Ib/=l ~ df(t, re l , t f )tEbinSimilarly, the denominator can be approximatedas :dr(bin, tel, t \]) P(bin, tfl~) ~ log2df ( t ,~ ,3)  -= #reml does d with t / ( t ,d)  = 3df(t, rel,4+) ~ # tel does d with t f ( t ,d)  _># tel does d# tel does dfreq of term in corpus: TF(t)  = ~a tf (t ,  d)# does d in collection = Ndff = # does d with t f(t ,  d) _> 1where dr(bin, tel, t f )  is1dff(bin, tel, t / )  ~ Ib/nl ~ dff(t, ~ ,  t f)tEbinef  = # does d in query exp.
with t f(t ,  d) > 1 ~re t is an estimate of the total number of relevantwhere: D (description), E (query expansion) documents.
Since some queries have more rele-25 burstiness: BTable 3: Training file schema: a record of 25 fieldsis computed for each term (ngram) in each queryin training set.sumptions, when appropriate, can be very pow-erful (better estimates from less training data),but errors resulting from inappropriate assump-tions can outweigh the benefits.
In this empiricalinvestigation of term weighting we decided to useconservative non-parametric histogram methodsto hedge against the risk of inappropriate para-metric assumptions.Terms are assigned to bins based on featuressuch as idf, as illustrated in table 2.
(Later wewill also use B and/or ef  in the binning process.
)is computed separately for each bin, based on theuse of terms in relevant and irrelevant documents,according to the labeled training material.The estimation method starts with a trainingfile which indicates, among other things, the num-ber of relevant and irrelevant documents for eachterm t in each training query, q.
That is, foreach t and q, we are are given dr(t, rel, tfo) anddr(t, tel, tfo), where dr(t, tel, tfo) is the numberof relevant documents d with tf(t ,  d) = tfo, anddf(t, rel, tfo) is the number of irrelevant docu-ments d with tf(t ,  d) = tfo.
The schema for thetraining file is described in table 3.
From thesetraining observations we wish to obtain a mappingfrom bins to As that can be applied to unseen testmaterial.
We interpret )~ as a log likelihood ratio:, P(bin, tflrel) ~(bin, t / )  = ~og2-z-::--~'\[bin, t / IN )where the numerator can be approximated as:,.~ _ dr(bin, rel, t f )  P(bin, triter) ~ togsNrelvant documents than others, N~t is computed byaveraging:1tEbinTo ensure that Nr~l + ~"~/= N, where N is thenumber of documents in the collection, we defineThis estimation procedure is implemented withthe simple awk program in figure 2.
The awk pro-gram reads each line of the training file, which con-tains a line for each term in each training query.As described in table 3, each training line contains25 fields.
The first five fields contain dr(t, tel, t f)for five values of t f ,  and the next five fields con-tain df(t, rel, t f )  for the same five values of t f .The next two fields contain N ,a  and N;-~.
As theawk program reads each of these lines from thetraining file, it assigns each term in each train-ing query to a bin (based on \[log2(df)\], exceptwhen df < 100), and maintains running sums ofthe first dozen fields which are used for comput-ing dr(bin, rel, t f),  df(bin, re'---l, tf) ,  l~rret and I~--~for five values of t f .
Finally, after reading all thetraining material, the program outputs the tableof ks shown in table 2.
The table contains a col-umn for each of the five t f  values and a row foreach of the dozen idf bins.
Later, we will considermore interesting binning rules that make use ofadditional statistics uch as burstiness and queryexpansion.2.1 Interpolating Between BinsRecall that the task is to apply the ks to new un-seen test data.
One could simply use the ks intable 2 as is.
That is, when we see a new termin the test material, we find the closest bin in ta-ble 2 and report the corresponding ~ value.
Butsince the idf of a term in the test set could easilyfall between two bins, it seems preferable to findthe two closest bins and interpolate between them.119awk ' funct ion  log2(x)  {re turn  log(x ) / log(2)  }$21 - / 'D /  { N = $14; df=$15;# binning ru leif(df < I00) {bin = O}else {bin=int (log2 (dr)) } ;docfreq\[bin\] += df;Nbin \[bin\] ++;# average df(t,rel,tf), df(t,irrel,tf)for(i=l;i<=12;i++) n\[i,bin\]+=$i }END {for(bin in Nbin) {nbin = Nbin\[bin\]Nrel = n\[l l ,bin\]/nbinNirrel = N-Nrelidf = -log2 ( (docfreq \[bin\]/nbin)/N)printf("Y.6.2f ", idf)for (i=l ; i<=5 ; i++) {if(Nrel==O) prel = 0else prel = (n\[i,bin\]/nbin)/Nrelif(Nirrel == O) pirrel = 0else pirrel = (n\[i+5,bin\]/nbin)/Nirrelif(prel <= 0 \]} pirrel <= O) {printf "Y.6s ", "NA" }else {printf "Y.6.2f ", log2(prel/pirrel)} }print ""}}'Figure 2: awk program for computing ks.We use linear regression to interpolate along theidf dimension, as illustrated in table 4.
Table 4 isa smoothed version of table 2 where A ~ a + b.idf.There are five pairs of coefficients, a and b, one foreach value of t f .Note that interpolation is generally not neces-sary on the t f  dimension because t f  is highlyquantized.
As long as t f  < 4, which it usuallyis, the closest bin is an exact match.
Even whentff > 4, there is very little room for adjustments ifwe accept he upper limit of A < idf.Although we interpolate along the idf dimen-sion, interpolation is not all that important alongthat dimension either.
Figure 1 shows that thedifferences between the test data and the train-ing data dominate the issues that interpolation isattempting to deal with.
The main advantage ofregression is computational convenience; it is eas-ier to compute a + b. idf than to perform a binarysearch to find the closest bin.Previous work (Cooper et al, 1994) used mul-tiple regression techniques.
Although our perfor-mance is similar (until we include query expan-sion) we believe that it is safer and easier to treateach value of t f  as a separate regression for rea-sons discussed in table 5.
In so doing, we are ba-sically restricting the regression analysis to suchan extent hat it is unlikely to do much harm (ormuch good).
Imposing the limits of 0 < A _< idfalso serves the purpose of preventing the regres-sion from wandering too far astray.tf a b0 -0.95 0.051 -0.98 0.692 -0.15 0.783 0.53 0.814+ 1.32 0.77Table 4: Regression coefficients for method fit-G.This table approximates the data in table 1 with~ a(t f )  + b(t f ) ,  idf.
Note that both the inter-cepts, a(tf) ,  and the slopes, b(tf), increase witht f  (with a minor exception for b(4+)).tf012345a(tf) bit/)-0.95 0.05-0.98 0.69-0.15 0.780.53 0.811.32 0.771.32 0.77a2 + c2.
log(1 + t f )  b2-4.1 0.66-1.4 0.660.18 0.661.3 0.662.2 0.662.9 0.66Table 5: A comparison of the regression coeffi-cients for method fit-G with comparable coeffi-cients from the multiple regression: A = a2 + b2 ?idf + c2 ?
log(1 + t f )  where a2 ---- -4.1,  b2 = 0.66and c2 = 3.9.
The differences in the two fits areparticularly large when t f  = 0; note that b(0) isnegligible (0.05) and b2 is quite large (0.66).
Re-ducing the number of parameters from 10 to 3 inthis way increases the sum of square errors, whichmay or may not result in a large degradation inprecision and recall.
Why take the chance?3 Burs t inessTable 6 is like tables 4 but the binning rule notonly uses idf, but also burstiness (B).
Burstiness(Church and Gale, 1995)(Katz, 1996)(Church,2000) is intended to account for the fact that somevery good keywords uch as "Kennedy" tend tobe mentioned quite a few times in a documentor not at all, whereas less good keywords uch as"except" tend to be mentioned about the samenumber of times no matter what the documenttf01234+B=0a b-0.05 -0.00 -0.61-1.23 0.63 -0.80-0.76 0.71 -0.050.00 0.69 0.230.68 0.71 0.75B=ia b0.020.790.790.820.83Table 6: Regression coefficients for method fit-B.Note that the slopes and intercepts are larger whenB = 1 than when B = 0 (except when t f  = 0).Even though A usually lies between-0 and idf, werestrict A to 0 < A < idf, just to make sure.120tf ef1 02 03 04+ 01234+1234+22221 32 33 34+ 3where=Da b-1.57 0.37-3.41 0.82-1.30 0.110.40 0.06-1.84 0.87-2.12 1.10-0.66 0.950.84 0.98-1.87 0.92-1.77 1.12-1.72 1.10-3.06 1.71"-2.52 0.95-1.81 1.020.45 0.850.38 1.22where=Ea b-2.64-2.70-2.98-3.35-3.00-2.78-3.07-3.250.680.710.740.780.860.850.930.79-2.71 0.91-2.28 0.88-2.63 0.97-3.66 1.14Table 7: Many of the regression coefficients formethod fit-E. (The coefficients marked with anasterisk are worrisome because the bins are toosmall and/or the slopes fall well outside the nor-mal range of 0 to 1.)
The slopes rarely exceeded .8is previous models (fit-G and fit-B), whereas fit-Ehas more slopes closer to 1.
The larger slopes areassociated with robust conditions, e.g., terms ap-pearing in the query (where = D), the document(t f  > 1) and the expansion (el > 1).
If a termappears in several documents brought in by query?
expansion (el > 2), then the slope can be largeeven if the term is not explicitly mentioned in thequery (where = E).
The interactions among t f  ,idf, ef and where are complicated and not easilycaptured with a straightforward multiple regres-sion.is about.
Since "Kennedy" and "except" havesimilar idf values, they would normally receivesimilar term weights, which doesn't seem right.Kwok (1996) suggested average term frequency,avtf = TF(t)/df(t),  be used as a tie-breaker forcases like this, where TF(t) = ~a if(t ,  d) is thestandard notion of frequency in the corpus-basedNLP.
Table 6 shows how Kwok's suggestion canbe reformulated in our empirical framework.
Thetable shows the slopes and intercepts for ten re-gressions, one for each combination of t f  and B(B = 1 iff avtf is large.
That is, B = 1 iffTF(t)/df(t) > 1.83 - 0.048-idf).4 Query  Expans ionWe applied query expansion (Buckley et al, 1995)to generate an expanded part of the query.
Theoriginal query is referred to as the description (D)and the new part is referred to as the expansion(E).
(Queries also contain a narrative (N) part thatis not used in the experiments below so that ourresults could be compared to previously publishedresults.
)The expansion is formed by applying a base-line query engine (fit-B model) to the descriptionpart of the query.
Terms that appear in the topk = 10 retrieved ocuments are assigned to the Eportion of the query (where(t) = E), unless theywere previously assigned to some other portion ofthe query (e.g., where(t) = D).
All terms, t, nomatter where they appear in the query, also re-ceive an expansion frequency el, an integer from0 to k = 10 indicating how many of the top kdocuments contain t.The fit-E model is: A = a(tf, where, ef) +b( t f , where, el) ?
i df , where the regression coeffi-cients, a and b, not only depend on t f  as in fit-G,but also depend on where the term appears in thequery and expansion frequency el.
We consider 5values of t f ,  2 values of where (D and E) and 6values of ef  (0, 1, 2, 3, 4 or more).
32 of these60 pairs of coefficients are shown in table 7.
Asbefore, most of the slopes are between 0 and 1.is usually between 0 and idf, but we restrict A to0 < A < idf, just to make sure.In tables 4-7, the slopes usually lie between 0and 1.
In the previous models, fit-B and fit-G,the largest slopes were about 0.8, whereas in fit-E, the slope can be much closer to 1.
The largerslopes are associated with very robust conditions,e.g., terms mentioned explicitly in all three areas ofinterest: (1) the query (where = D), (2) the doc-ument (t f  > 1) and (3) the expansion (el > 1).Under such robust conditions, we would expect ofind very little shrinking (downweighting to com-pensate for uncertainty).On the other hand, when the term is not men-tioned in one of these areas, there can be quitea bit of shrinking.
Table 7 shows that the slopesare generally much smaller when the term is notin the query (where = E) or when the term isnot in the expansion (el = 0).
However, there aresome exceptions.
The bottom right corner of ta-ble 7 contains ome large slopes even though theseterms are not mentioned explicitly in the query(where = E).
The mitigating factor in this caseis the large el.
If a term is mentioned in severaldocuments in the expansion (el _> 2), then it isnot as essential that it be mentioned explicitly inthe query.With this model, as with fit-G and fit-B, ~ tendsto increase monotonically with t f  and idf, thoughthere are some interesting exceptions.
When theterm appears in the query (where = D) but notin the expansion (el = 0), the slopes are quitesmall (e.g., b(3,D,0) = 0.11), and the slopes actu-ally decrease as t f  increases (b(2, D, 0) = 0.83 >b(3,D,0) = 0.11).
We normally expect to seeslopes of .7 or more when t.f > 3, but in this case(b(3, D, 0) = 0.11), there is a considerable shrink-ing because we very much expected to see the termin the expansion and we d idn' t .
...As we have seen, the interactions among t f, idf,e f  and where are complicated and probably de-121filter trained on sys.NA ?
JCB12+, El tf, where,ef fit-E2 B,tf fit-B2, K tf + ... BKJJBIDS2, K B,tf fit-B2, K tf  fit-G2, K none log(1 + t f ) .
idf2, K none t f .
idf11.360.354.283.272.264.257.249.112Table 8: Training helps: methods above the lineuse training (with the possible xception of JCB1);methods below the line do not.pend on many factors uch as language, collection,typical query patterns and so on.
To cope withsuch complications, we believe that it is safer touse histogram methods than to try to account forall of these interactions at once in a single multipleregression.
The next section will show that fit-Ehas very encouraging performance.5 ExperimentsTwo measures of performance are reported: (1) 11point average precision and (2) R, precision afterretrieving Nrd documents, where Nrd is the num-ber of relevant documents.
We used the "shortquery" condition of the NACSIS NTCIR-1 TestCollection (Kando et al, 1999) which consists ofabout 300,000 documents in Japanese, plus about30 queries with labeled relevance judgement fortraining and 53 queries with relevance judgementsfor testing.
The result of "short query" is shown inpage 25 of(Kando et al, 1999), which shows that"short query" is hard for statistical methods.Two previously published systems are includedin the tables below: JCB1 and BKJJBIDS.
JCB1,submitted by Just System, a company with a com-mercially successful product for Japanese word-processing, produced the best results using sophis-ticated (and proprietary) natural language pro-cessing techniques.
(Fujita, 1999) BKJJBIDS usedBerkeley's logistic regression methods (with abouthalf a dozen variables) to fit term weights to thelabeled training material.Table 8 shows that training often helps.
Themethods above the line (with the possible excep-tion of JCB1) use training; the methods below theline do not.
Fit-E has very respectable perfor-mance, nearly up to the level of JCB1, not bad fora purely statistical method.The performance of fit-B is close to that ofBKJJBIDS.
For comparison sake, fit-B is shownboth with and without the K filter.
The K filterrestricts terms to sequences of Katakana nd Kanjicharacters.
BKJJBIDS uses a similar heuristic toeliminate Japanese function words.
Although theK filter does not change performance very much,the use of this filter changes the relative order offit-B and BKJJBIDS.
These results suggest hatR ?
2: restrict terms to bigrams explicitly men-.351 tioned in query (where ~- D).363 ?
2+: restrict terms to bigrams, but include.293 where = E as well as where = D.282.282 * W: restrict terms to words, as identified by.267 Chasen (Matsumoto et al, 1997).262 ?
K: restrict terms to sequences of Katakana.138 and/or Kanji characters?
B: restrict erms to bursty (B -- 1) terms?
Ek: require terms to appear in more than kdocs brought in by query expansion (el(t) >k).Table 9: Filters: results vary somewhat dependingon these choices, though not too much, which isfortunate, since since we don't understand stoplists very well.filter trained on sys.2+, E1 tf, where,ef fit-E2+, E2 tf, where,ef fit-E2+, E4 tf, where,ef fit-E2+ tf, where,ef fit-ENA NA JCB111 R.354 .363.350 .359.333 .341.332 .366.360 .351Table 10: The best filters (Ek) improve the per-formance of the best method (fit-E) to nearly thelevel of JCB1.the K filter is slightly unhelpful.A number of filters have been considered (ta-ble 9).
Results vary somewhat depending on thesechoices, though not too much, which is fortunate,since since we don't understand stop lists verywell.
To the extent hat there is a pattern, we sus-pect that words axe slightly better than bigrams,and that the E filter is slightly better than the Bfilter which is slightly better than the K filter.
Ta-ble 10 shows that the best filters (Ek) improve theperformance of the best method (fit-E) to nearlythe level of JCB1.filter sys.
UL2 fit-B +2 fit-B +2 fit-B -2 fit-B -2 fit-G +2 fit-G -2 fit-G +2 fit-G -LL I I+ .283- .280+ .280- .275+ .266?
.251- .248- .232R.293.296.296.288.279.268.259.249Table 11: Limits do no harm: two limits areslightly better than one, and one is  slightly bet-ter than none.
(UL  = upper limit of ~ < idf; LL= lower limit of 0 _< ~)122The final experiment (table 11) shows that re-stricting ~ to 0 < ~ < id\] improves performanceslightly.
The combination of both the upper limitand the lower limit is slightly better than just onelimit which is better than none.
We view limits asa robustness device.
Hopefully, they won't haveto do much but every once in a while they preventthe system from wandering far astray.6 ConclusionsThis paper introduced an empirical histogram-based supervised learning method for estimatingterm weights, ~.
Terms are assigned to bins basedon features uch as inverse document frequency,burstiness and expansion frequency.
A differentis estimated for each bin and each t f  by countingthe number of relevant and irrelevant documentsassociated with the bin and tff value.
Regressiontechniques are used to interpolate between bins,but care is taken so that the regression cannot dotoo much harm (or too much good).
Three varia-tions were considered: fit-G, fit-B and fit-E. Theperformance of query expansion (fit-E) is particu-larly encouraging.
Using simple purely statisticalmethods, fit-E is nearly comparable to JCB1, asophisticated natural language processing systemdeveloped by Just System, a leader in the Japaneseword processing industry..-: In addition to performance, we are also inter-ested in the interpretation of the weights.
Empiri-cal weights tend to lie between 0 and idf.
We findthese limits to be a surprise given that standardterm weighting formulas uch as t f .
idf generallydo not conform to these limits.
In addition, wefind that ~ generally grows linearly with idf, andthat the slope is between 0 and 1.
We interpret theslope as a statistical shrink.
The larger slopes areassociated with very robust conditions, e.g., termsmentioned explicitly in all three areas of interest:(1) the query (where = D), (2) the document( t f  _> 1) and (3) the expansion (ef > 1).
Thereis generally more shrinking for terms brought inby query expansion (where = E), but if a termis mentioned in several documents in the expan-sion (el > 2), then it is not as essential that theterm be mentioned explicitly in the query.
Theinteractions among t f, id\], where, B, el, etc., arecomplicated, and therefore, we have found it saferand easier to use histogram methods than to tryto account for  all of the interactions at once in asingle multiple regression.AcknowdedgementAuthors thank Prof. Mitchell P. Marcus of Uni-versity of Pennsylvania for the valuable discussionabout noise reduction in context of informationretrieval.
This reseach is supported by SumitomoElectric.Re ferencesChris Buckley, Gerard Salton, James Allan, and AmitSinghal.
1995.
Automatic query expansion us-ing smart: Trec 3.
In The Third Text REtrievalConference(TREC-3), pages 69-80.Aitao Chen, Fredric C. Gey, Kazuaki Kishida, HailingJiang, and Qun Liang.
1999.
Comparing multiplemethods for japanese and japanese-english text re-trieval.
In NTCIR Workshop 1, pages 49-58, TokyoJapan, Sep.Kenneth W. Church and William A. Gale.
1995.Poisson mixture.
Natural Language Engineering,1(2):163-190.Kenneth W. Church.
2000.
Empirical estimates ofadaptation: The chance of two noriegas is closerto p/2 than p2.
In Coling-2000, pages 180-186.William S. Cooper, Aitao Chen, and Fredric C. Gey.1994.
Full text retrieval based on probabilistic equa-tion with coefficients fitted by logistic regressions.In The Second Text REtrieval Conference(TREU-2), pages 57-66.Sumio Fujita.
1999.
Notes on phrasal index-ing: Jscb evaluation experiments at ntcir adhoc'.
In NTCIR Workshop 1, pages 101-108,http://www.rd.nacsis.ac.jp/ -ntcadm/, Sep.Noriko Kando, Kazuko Kuriyama, Toshihiko Nozue,Koji Eguchi, and Hiroyuki Katoand Souichiro Hi-daka.
1999.
Overview of ir tasks at the first nt-cir workshop.
In NTCIR Workshop 1, pages 11-44,http://www.rd.nacsis.ac.jp/ "ntcadm/, Sep.Slava M. Katz.
1996.
Distribution of content wordsand phrases in text and language modelling.
NaturalLanguage Engineering, 2(1):15-59.K.
L. Kwok.
1996.
A new method of weighting queryterms for ad-hoc retrieval.
In SIGIR96, pages 187-195, Zurich, Switzerland.Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita,Yoshitaka Hirano, Osamu Imaichi, and TomoakiImamura.
1997.
Japanese morphological nalysissystem chasen manual.
Technical Report NAIST-IS-TR97007, NAIST, Nara, Japan, Feb.123
