Proceedings of the TextInfer 2011 Workshop on Textual Entailment, EMNLP 2011, pages 59?63,Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational LinguisticsDiscovering Commonsense Entailment Rules Implicit in SentencesJonathan GordonDepartment of Computer ScienceUniversity of RochesterRochester, NY, USAjgordon@cs.rochester.eduLenhart K. SchubertDepartment of Computer ScienceUniversity of RochesterRochester, NY, USAschubert@cs.rochester.eduAbstractReasoning about ordinary human situationsand activities requires the availability of di-verse types of knowledge, including expecta-tions about the probable results of actions andthe lexical entailments for many predicates.We describe initial work to acquire such a col-lection of conditional (if?then) knowledge byexploiting presuppositional discourse patterns(such as ones involving ?but?, ?yet?, and ?hop-ing to?)
and abstracting the matched materialinto general rules.1 IntroductionWe are interested, ultimately, in enabling an infer-ence system to reason forward from facts as wellas backward from goals, using lexical knowledge to-gether with world knowledge.
Creating appropriatecollections of general world knowledge to supportreasoning has long been a goal of researchers in Arti-ficial Intelligence.
Efforts in information extraction,e.g., Banko et al (2007), have focused on learningbase facts about specific entities (such as that BarackObama is president), and work in knowledge extrac-tion, e.g., Van Durme and Schubert (2008), has foundgeneralizations (such as that a president may makea speech).
While the latter provides a basis for pos-sibilistic forward inference (Barack Obama proba-bly makes a speech at least occasionally) when itsmeaning is sharpened (Gordon and Schubert, 2010),these resources don?t provide a basis for saying whatwe might expect to happen if, for instance, someonecrashes their car.That the driver in a car crash might be injuredand the car damaged is a matter of common sense,and, as such, is rarely stated directly.
However, itcan be found in sentences where this expectationis disconfirmed: ?Sally crashed her car into a tree,but she wasn?t hurt.?
We have been exploring theuse of lexico-syntactic discourse patterns indicatingdisconfirmed expectations, as well as people?s goals(?Joe apologized repeatedly, hoping to be forgiven?
).The resulting rules, expressed at this point in naturallanguage, are a first step toward obtaining classes ofgeneral conditional knowledge typically not obtainedby other methods.2 Related WorkOne well-known approach to conditional knowledgeacquisition is that of Lin and Pantel (2001), whereinference rules are learned using distributional simi-larity between dependency tree paths.
These resultsinclude entailment rules like ?x is the author of y ?
xwrote y?
(which is true provided x is a literary work)and less dependable ones like ?x caused y ?
y isblamed on x?.
This work was refined by Pantel et al(2007) by assigning the x and y terms semantic types(inferential selectional preferences ?
ISP) based onlexical abstraction from empirically observed argu-ment types.
A limitation of the approach is that theconditional rules obtained are largely limited to onesexpressing some rough synonymy or similarity re-lation.
Pekar (2006) developed related methods forlearning the implications of an event based on theregular co-occurrence of two verbs within ?locallycoherent text?, acquiring rules like ?x was appointedas y?
suggests that ?x became y?, but, as in DIRT, welack information about the types of x and y, and onlyacquire binary relations.Girju (2003) applied Hearst?s (1998) procedure forfinding lexico-syntactic patterns to discover causalrelations between nouns, as in ?Earthquakes gener-ate tsunami?.
Chklovski and Pantel (2004) used pat-59(S < (NP $.
(VP < (/,/ $.
(S < (VP < (VBG <hoping)< (S < (VP < TO))))))))(S < (NP $.
(VP < ((CC < but) $.. (VP < (AUX < did) < (RB < /n[?o]t/))))))(S < (NP $.
(VP < (AUX $.
(ADJP < (JJ $.
((CC < /(but|yet)/) $.
JJ)))))))(S < (NP $.
(VP < (/,/ $.
(S < (VP < ((VBG < expecting) $.
(S < (VP < TO)))))))))Figure 1: Examples of TGrep2 patterns for finding parsetree fragments that might be abstracted to inference rules.See Rohde (2001) for an explanation of the syntax.terns like ?x-ed by y-ing?
(?obtained by borrowing?
)to get co-occurrence data on candidate pairs from theWeb.
They used these co-occurrence counts to obtaina measure of mutual information between pairs ofverbs, and hence to assess the strengths of the rela-tions.
A shortcoming of rules obtained in this way istheir lack of detailed predicative structure.
For infer-ence purposes, it would be insufficient to know that?crashes cause injuries?
without having any idea ofwhat is crashing and who or what is being injured.Schoenmackers et al (2010) derived first-orderHorn clauses from the tuple relations found by TEXT-RUNNER (Banko et al, 2007).
Their system producesrules like ?IsHeadquarteredIn(Company, State) :- Is-BasedIn(Company, City) ?
IsLocatedIn(City, State)?,which are intended to improve inference for question-answering.
A limitation of this approach is that, op-erating on the facts discovered by an informationextraction system, it largely obtains relations amongsimple attributes like locations or roles rather thanconsequences or reasons.3 MethodOur method first uses TGrep2 (Rohde, 2001) to findparse trees matching hand-authored lexico-syntacticpatterns, centered around certain pragmatically sig-nificant cue words such as ?hoping to?
or ?but didn?t?.Some of the search patterns are in Figure 1.
Whilewe currently use eight query patterns, future workmay add rules to cover more constructions.The matched parse trees are filtered to removethose unlikely to produce reasonable results, suchas those containing parentheses or quoted utterances,and the trees are preprocessed in a top-down traversalto rewrite or remove constituents that are usuallyextraneous.
For instance, the parse tree forThe next day he and another Bengali boy wholives near by [sic] chose another way home,hoping to escape the attackers.is preprocessed toPeople chose another way home, hoping toescape the attackers.Examples of the preprocessing rules include re-moving interjections (INTJ) and some prepositionalphrases, heuristically turning long expressions intokeywords like ?a proposition?, abstracting named en-tities, and reordering some sentences to be easier toprocess.
E.g., ?Fourteen inches from the floor it?s sup-posed to be?
is turned to ?It?s supposed to be fourteeninches from the floor?.The trees are then rewritten as conditional expres-sions based on which semantic pattern they match,as outlined in the following subsections.
The samplesentences are from the Brown Corpus (Kuc?era andFrancis, 1967) and the British National Corpus (BNCConsortium, 2001), and the rules are those derivedby our current system.3.1 Disconfirmed ExpectationsThese are sentences where ?but?
or ?yet?
is used toindicate that the expected inference people wouldmake does not hold.
In such cases, we want to flip thepolarity of the conclusion (adding or removing ?not?from the output) so that the expectation is confirmed.For instance, fromThe ship weighed anchor and ran out her bigguns, but did not fire a shot.we get that the normal case is the opposite:If a ship weighs anchor and runs out her bigguns, then it may fire a shot.Or for two adjectives, ?She was poor but proud?
:If a female is poor, then she may not be proud.3.2 Contrasting Good and BadA different use of ?but?
and ?yet?
is to contrast some-thing considered good with something consideredbad, as in ?He is very clever but eccentric?
:If a male is very clever,then he may be eccentric.If we were to treat this as a case of disconfirmed ex-pectation as above, we would have claimed that ?If amale is very clever, then he may not be eccentric?.
Toidentify this special use of ?but?, we consult a lexiconof sentiment annotations, SentiWordNet (Baccianellaet al, 2010).
Finding that ?clever?
is positive while?eccentric?
is negative, we retain the surface polarityin this case.60For sentences with full sentential complements for?but?, recognizing good and bad items is quite difficult,more often depending on pragmatic information.
Forinstance, inCentral government knew this would happenbut did not want to admit to it in its plans.knowing something is generally good while beingunwilling to admit something is bad.
At present, wedon?t deal with these cases.3.3 Expected OutcomesOther sentences give us a participant?s intent, and wejust want to abstract sufficiently to form a generalrule:He stood before her in the doorway, evidentlyexpecting to be invited in.If a male stands before a female in thedoorway, then he may expect to be invited in.When we abstract from named entities (using a va-riety of hand-built gazetteers), we aim low in thehierarchy:Elisabeth smiled, hoping to lighten theconversational tone and distract the Colonelfrom his purpose.If a female smiles, then she may hope tolighten the conversational tone.While most general rules about ?a male?
or ?a female?could instead be about ?a person?, there are ones thatcan?t, such as those about giving birth.
We leave theraising of terms for later work, following Van Durmeet al (2009).4 EvaluationDevelopment was based on examples from the (hand-parsed) Brown Corpus and the (machine-parsed)British National Corpus, as alluded to above.
Thesecorpora were chosen for their broad coverage of ev-eryday situations and edited writing.As the examples in the preceding subsections in-dicate, rules extracted by our method often describecomplex consequences or reasons, and subtle rela-tions among adjectival attributes, that appear to bequite different from the kinds of rules targeted in pre-vious work (as discussed earlier, or at venues suchas that of (Sekine, 2008)).
While we would like toevaluate the discovered rules by looking at inferencesmade with them, that must wait until logical formsare automatically created; here we judge the rulesthemselves.The statement above is a reasonably clear, entirelyplausible, generic claim and seems neither too specificnor too general or vague to be useful:1.
I agree.2.
I lean towards agreement.3.
I?m not sure.4.
I lean towards disagreement.5.
I disagree.Figure 2: Instructions for judging of unsharpened factoids.Judge 1 Judge 2 Correlation1.84 2.45 0.55Table 1: Average ratings and Pearson correlation for rulesfrom the personal stories corpus.
Lower ratings are better;see Fig.
2.For evaluation, we used a corpus of personal storiesfrom weblogs (Gordon and Swanson, 2009), parsedwith a statistical parser (Charniak, 2000).
We sampled100 output rules and rated them on a scale of 1?5(1 being best) based on the criteria in Fig.
2.
Todecide if a rule meets the criteria, it is helpful toimagine a dialogue with a computer agent.
Told aninstantiated form of the antecedent, the agent asks forconfirmation of a potential conclusion.
E.g., forIf attacks are brief,then they may not be intense,the dialogue would go:?The attacks (on Baghdad) were brief.?
?So I suppose they weren?t intense, were they?
?If this is a reasonable follow-up, then the rule is prob-ably good, although we also disprefer very unlikelyantecedents ?
rules that are vacuously true.As the results in Table 1 and Fig.
3 indicate, theoverall quality of the rules learned is good but thereis room for improvement.
We also see a rather lowcorrelation between the ratings of the two judges,indicating the difficulty of evaluating the quality ofthe rules, especially since their expression in naturallanguage (NL) makes it tempting to ?fill in the blanks?of what we understand them to mean.
We hypothesizethat the agreement between judges will be higherfor rules in logical form, where malformed outputis more readily identified ?
for instance, there is noguessing about coreference or attachment.Rules that both judges rated favorably (1) include:If a pain is great, it may not be manageable.If a person texts a male, then he-or-she mayget a reply.610204060801 2 3 4 5FrequencyRatingFigure 3: Counts for how many rules were assigned eachrating by judges.
Lower ratings are better; see Fig.
2.If a male looks around, then he may hope tosee someone.If a person doesn?t like some particular store,then he-or-she may not keep going to it.While some bad rules come from parsing or pro-cessing mistakes, these are less of a problem thanthe heavy tail of difficult constructions.
For instance,there are idioms that we want to filter out (e.g., ?I?membarrassed but.
.
.
?)
and other bad outputs showcontext-dependent rather than general relations:If a girl sits down in a common room, then shemay hope to avoid some pointlessconversations.The sitting-down may not have been because shewanted to avoid conversation but because of some-thing prior.It?s difficult to compare our results to other systemsbecause of the differences of representation, types ofrules, and evaluation methods.
ISP?s best performingmethod (ISP.JIM) achieves 0.88 specificity (defined asa filter?s probability of rejecting incorrect inferences)and 0.53 accuracy.
While describing their SHERLOCKsystem, Schoenmackers et al (2010) argue that ?thenotion of ?rule quality?
is vague except in the contextof an application?
and thus they evaluate the Hornclauses they learn in the context of the HOLMESinference-based QA system, finding that at precision0.8 their rules allow the system to find twice as manycorrect facts.
Indeed, our weak rater agreement showsthe difficulty of judging rules on their own, and futurework aims to evaluate rules extrinsically.5 Conclusion and Future WorkEnabling an inference system to reason about com-mon situations and activities requires more types ofgeneral world knowledge and lexical knowledge thanare currently available or have been targeted by previ-ous work.
We?ve suggested an initial approach toacquiring rules describing complex consequencesor reasons and subtle relations among adjectival at-tributes: We find possible rules by looking at interest-ing discourse patterns and rewriting them as condi-tional expressions based on semantic patterns.A natural question is why we don?t use themachine-learning/bootstrapping techniques that arecommon in other work on acquiring rules.
These tech-niques are particularly successful when (a) they areaimed at finding fixed types of relationships, suchas hyponymy, near-synonymy, part-of, or causal rela-tions between pairs of lexical items (often nominalsor verbs); and (b) the fixed type of relationship be-tween the lexical items is hinted at sufficiently ofteneither by their co-occurrence in certain local lexico-syntactic patterns, or by their occurrences in simi-lar sentential environments (distributional similarity).But in our case, (a) we are looking for a broad rangeof (more or less strong) consequence relationships,and (b) the relationships are between entire clauses,not lexical items.
We are simply not likely to findmultiple occurrences of the same pair of clauses ina variety of syntactic configurations, all indicating aconsequence relation ?
you?re unlikely to find multi-ple redundant patterns relating clauses, as in ?Wentup to the door but didn?t knock on it?.There is more work to be done to arrive at a reli-able, inference-ready knowledge base of such rules.The primary desideratum is to produce a logical rep-resentation for the rules such that they can be used inthe EPILOG reasoner (Schubert and Hwang, 2000).Computing logical forms (as, e.g., in Bos (2008)) andthen deriving logically formulated rules from theserather than deriving sentential forms directly fromtext should also allow us to be more precise aboutdropping modifiers, reshaping into generic presenttense from other tenses, and other issues that affectthe quality of the statements.
We have a preliminaryversion of a logical form generator that derives LFsfrom TreeBank parses that can support this direc-tion.
Further filtering techniques (based both on thesurface form and the logical form) should keep thedesired inference rules while improving quality.AcknowledgementsThis work was supported by NSF grants IIS-1016735 and IIS-0916599, and ONR STTR subcon-tract N00014-10-M-0297.62ReferencesStefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
SentiWordNet 3.0: An enhanced lexicalresource for sentiment analysis and opinion mining.In Proc.
of the Seventh Conference on InternationalLanguage Resources and Evaluation (LREC?10).Michele Banko, Michael J. Cafarella, Stephen Soderland,Matt Broadhead, and Oren Etzioni.
2007.
Open in-formation extraction from the Web.
In Proc.
of theTwentieth International Joint Conference on ArtificialIntelligence (IJCAI-07).BNC Consortium.
2001.
The British National Corpus, v.2.Distributed by Oxford University Computing Services.Johan Bos.
2008.
Wide-coverage semantic analysis withBoxer.
In Proc.
of the Symposium on Semantics in TextProcessing (STEP 2008).Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proc.
of the First Annual Meeting of the NorthAmerican Chapter of the Association for ComputationalLinguistics (NAACL 2000), pages 132?139.Timothy Chklovski and Patrick Pantel.
2004.
VerbOcean:Mining the Web for fine-grained semantic verb relations.In Proc.
of the Conference on Empirical Methods inNatural Language Processing (EMNLP-04).Roxana Girju.
2003.
Automatic detection of causal rela-tions for question answering.
In Proc.
of the ACL 2003Workshop on Multilingual Summarization and QuestionAnswering ?
Machine Learning and Beyond.Jonathan Gordon and Lenhart K. Schubert.
2010.
Quan-tificational sharpening of commonsense knowledge.
InProc.
of the AAAI 2010 Fall Symposium on Common-sense Knowledge.Andrew Gordon and Reid Swanson.
2009.
Identifyingpersonal stories in millions of weblog entries.
In Proc.of the Third International Conference on Weblogs andSocial Media (ICWSM), Data Challenge Workshop.Marti Hearst.
1998.
Automated discovery of WordNetrelations.
In Christiane Fellbaum, editor, WordNet: AnElectronic Lexical Database and Some of Its Applica-tions.
MIT Press.Henry Kuc?era and W. N. Francis.
1967.
ComputationalAnalysis of Present-Day American English.
BrownUniversity Press.Dekang Lin and Patrick Pantel.
2001.
DIRT: Discov-ery of inference rules from text.
In Proc.
of the ACMConference on Knowledge Discovery and Data Mining(KDD).Patrick Pantel, Rahul Bhagat, Timothy Chklovski, and Ed-uard Hovy.
2007.
ISP: Learning inferential selectionalpreferences.
In Proc.
of NAACL-HLT 2007.Viktor Pekar.
2006.
Acquisition of verb entailment fromtext.
In Proc.
of HLT-NAACL 2006.Doug Rohde.
2001.
TGrep2 manual.
Unpublishedmanuscript, Brain & Cognitive Science Department,MIT.Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld, andJesse Davis.
2010.
Learning first-order horn clausesfrom Web text.
In Proc.
of EMNLP 2010.Lenhart K. Schubert and Chung Hee Hwang.
2000.Episodic Logic Meets Little Red Riding Hood: A com-prehensive, natural representation for language under-standing.
In L. Iwanska and S. C. Shapiro, editors,Natural Language Processing and Knowledge Repre-sentation: Language for Knowledge and Knowledge forLanguage.
MIT/AAAI Press.Satoshi Sekine, editor.
2008.
Notebook of the NSF Sympo-sium on Semantic Knowledge Discovery, Organization,and Use.
New York University, 14?15 November.Benjamin Van Durme and Lenhart K. Schubert.
2008.Open knowledge extraction through compositional lan-guage processing.
In Proc.
of the Symposium on Se-mantics in Text Processing (STEP 2008).Benjamin Van Durme, Phillip Michalak, and Lenhart K.Schubert.
2009.
Deriving Generalized Knowledgefrom Corpora using WordNet Abstraction.
In Proc.
ofEACL 2009.63
