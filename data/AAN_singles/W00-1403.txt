An Empirical Study in Multilingual Natural LanguageGeneration: What Should A Text Planner Do?Danie l  MarcuInformation Sciences Institute andDepartment of Computer ScienceUniversity of Southern California4676 Admiralty Way, Suite 1001Marina del Rey, CA 90292marcu@isi, eduLynn CarlsonU.S.
Department of Defense, _Et .
Meade,_ MD~.20755lmcarls@afterlife, ncsc.
railMaki  WatanabeDepartment of Linguistics........ ?
, ~n i .v ,  e rs i ty .o f  Southern~CaliforniaLos Angeles, CA 90089m watanab@usc, eduAbstractWe present discourse annotation work aimed at con-structing a parallel corpus of Rhetorical Structuretrees for a collection of Japanese texts and their cor-responding English translations.
We discuss impli-cations of our empirical findings for the task of textplanning in the context of implementing multilingualnatural anguage generation systems.1 I n t roduct ionThe natural anguage generation community has em-phasized for a number of years the strengths of mul-tilingual generation (MGEN) systems (Iordanskajaet al, 1992; RTsner and Stede, 1992; Reiter and Mel-lish, 1993; Goldberg et al, 1994; Paris et al, 1995;Power and Scott, 1998).
These strengths concern thereuse of knowledge, the support for early drafts inseveral anguages, the support for maintaining con-sistency when making changes, the support for pro-ducing alternative formulations, and the potentialfor producing higher quality outputs than machinetranslation.
(The weaknesses concern the high-costof building large, language-independent k owledgebases, and the dilficulty of producing high-quality.broad-coverage neration algorithms.
)From an economic perspective, the more a sys-tem can rely on language independent modules forthe purpose of multilingual generatiom the better.If an MGEN system needs to develop language de-pendent knowledge bases, and language dependentalgorithms for content selection, text planning, andsentence planning, it-is difficult to justify its eco-nomic viability.
However, if most of these compo-nents are language independent and/or much of thecode can be re-used, an MGEN system becomes aviable option..Many of the earl3 implementations of MGEN sys-tems have adopted the perspective that text plan-ners can be implemented as language-independentmodules (lordanskaja el, ;11., 1992: Goldberg et el.,1994), possibly followed by a hm:aricatwn stage,in which discourse l.rees are re-written to refleet~language-specific constraints (R6sner and Stede.1992; St,ede, 1999).
Although such an approach may17be adequate for highly restricted text genres, suchas weather forecasts, it usually poses problems forless restricted genres.
Studies of instruction man-uals (RTsner and Stede, 1992; Delin et al, 1994:Delin et al, 1996) suggest hat there are variationswith respect to the way high-level communicativegoals  are realized across languages.
For example,Delin et al (1994) noticed that sentences (1), (2),and (3), which were taken from a trilingual instruc-tion manual for a step-aerobics machine, yield non-isomorphic Rhetorical Structure (Mann and Thomp-son, 1988) analyses in English, French, and Germanrespectively (see Figure 1).English: \[The stepping load can be altered I \]\[by loosening the locking lever 2\] \[and changingthe position of the cylinder foota\].
(1)French: \[Pour modifier la charge d'appui, l\]\[desserrer l s levieres 2\] \[puis d6placer le pieddes v6rins a\] (\[To modify the load stepping ~\]\[loosen the levers 2\] \[then change .the foot ofthe cylinder foot.el)(2)German: \[,Nach Lockern der Klelnmhebel 2\] (3)\[kann t \] \[durch Verschieben des Zylinderfudes 3 \]\[die Tretbelastung verS.ndert werden.~ \] (\[Afterloosening of the levers 2\] \[can'\] \[by puslfing ofthe cylinder foot 3\] \[the load changed be, ~\])Hmvever, previous.discourse ,studies do .not es-timate how ubiquitous uch non-isomorphic analy-ses are.
Are the examples above an exception orthe norm?
Are non-isomorphic analyses specificto discourse structures built, across elementary dis-course units of single sentences, or do they alsooccur across sentences and paragraphs?
If non-isomorphism is ubiquitous, how should an MGENsystem be designed in order to effectively deal wit hnon-isomorphic discourse structures when mappingknowledge bases into multiple languages?In this paper, we describe an experiment that wasdesigned to answer these questions.
To investigateEnglish French GermanCircumstance_ .. - -.'
!
: ,  !
'{Modifier)- ~ ~ r - '  O-.
?ckem )2 3 2 3 3 1Loosen Change Loosen Change Change Alter(Desserrer) (Deplacer) (Verschieben) (Verandert)Figure 1: Contrasting multi l ingual discourse structure representations (Delin et al, 1994, p. 63)how discourse structures differ across languages, wemanual ly built a parallel corpus of discourse trees ofnewspaper Japanese texts and their correspondingEnglish translations.
In section 2, we present someof the problems pecific to the construction of sucha corpus.
In section 3, we present our experimentand discuss our empirical findings.
In Section 4, wediscuss the implications of our work for the task oftext planning, in the context of multi l ingual naturallanguage generation.2 Towards bu i ld ing a paral le l  corpusof d iscourse trees: an exampleConsider, for example, Japanese sentence (4), aword-by-word "gloss" of it (5), and a two-sentencetranslation of it that was produced by a professionaltranslator (6).~/rf~ ~ 4\] \ [~afL~, t~,  5\] \ [~< g-~.~oq~t-?
{4)Thompson,  1988).
If we analyze the text frag-ments closely, we will notice that in translat ing sen-tence (4), a professional translator chose to realizethe information in Japanese unit 2 first (unit 2 intext (4) corresponds roughly to unit I in text (6));to realize then some of the information in Japaneseunit 1 (part of unit 1 in text (4) corresponds to unit2 in text (6)); to fuse then information given in units1, 3, and 5 in text (4) and realize it in English asunit 3; and so on.
Also, the translator chose to re-package the information in the original Japanese sen-tence into two English sentences.At the elementary unit level, the correspondencebetween Japanese sentence (4) and its English trans-lation (6) can be represented as in (7), where j C edenotes the fact that the semantic content of unitj is realized fully in unit e; j D e denotes the factthat the semantic content of unit e is realized fullyin unit.
j; j = e denotes the fact that units j and eare semantical ly equivalent; and j ~ e denotes thefact that  there is a semantic overlap between units jand e, but neither proper inclusion nor proper equiv-alence.\[The Ministry of Health and Welfare last yearrevealed 1\] \[population of future estimate ac-cording to 2\] \[m future 1.499 persons as thelowest a\] \[that after *SAB* rising to turn that 4\]\[*they* estimated but 5\] \[already the estimatemisses a point G\] \[prediction became, r\]\[In its future population estimateQ\] \[madepublic last yearf\] \[the Ministry of Health andWelfare predicted that the SAB would drop toa new low of 1.-199 in the future, a\] \[but wouldmake a comeback after that .4\] \[increasing onceagain/;\] \[However.
it looks as if that predictionwill be quickly shattered, t; \](.~)(6)The labeled spans o f  lext represent elementarydiscourse units (~dus).
i.e.. minimal text spans thathave an unambiguous discourse function (Mann and18J l.1233../43s./6Jre2; j l  ~ ca :----eel;C e3;e4; j4  ~ e5 ;e3;C e6;C e6(7)Hence, tile mappings in (7) provide an explicit, rep-resentation of the way information is re-ordered andre-packaged when translated from Japanese into En-glish.
However, when translating text, it is not onlythat information is re-packaged and re-ordered; itis also that the rhetorical rendering changes.
Whatis realized in Japanese using an ELABORATION rela-tion can be realized in English using, for example, aCON' I 'RAST  or  a CONCESSION relation.Figure 2 presents in the style of Mann and Thomp-C oncess~or ._~ "i _ .
.
, .
.
?attriiout+or, a:tr~bmi:~n e aioorahor - oaject- ~.It,lolute- eIe alaorzm~.-mje+t e : : .
.
.
.
.
.  "
.
.
.
.
.
.
.
.
.temporal- a l te r .
.
.+ .
+,~P~a:+m~+ ~~.+.~i=m +~+ +-++++ia ; i+- '> +"::1 ) (Z)  (~ (a)  " + .
.
.
.
.
.
.
.
.
.
.
.
+~ .
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
S + ' .
.
.
.
.
+ + +" "b.?
(The Ministry ~ '(popu alien - X -E~.
'tfutur @g (that - a~erof Health and of future estimate e 1.499 persons \[SAB I rLqng - toWeffare last yeal - a:ccrcling - to) as the lowest) turn lhal)revealed)t - .=I-2 3-3e l a b o r ~ r  |buto--?I11 12) (3) ~.3In Its fulure made pobll?
the Mlnl~ry el:l ~ ~t~,n_.~ d.d ~ i on.~ iI~Jl~liOn ~"  year, ~ Heolth andLIv.~r "~,..estimates WeHare .
(4) (5) but would increasingthe SAB rmk~a c~nce again.comet~sc~rwo~rld rop to after that.a ni~a.
low o~1,4~0 In thefuture,(~,,,~ie+gaiFigure 2: The discourse structures of texts (4) and (6).son (1988) the discourse structures of text frag-ments (4) and (6).
Each discourse structure is atree whose leaves correspond to the edus and whoseinternal nodes correspond t.o contiguous text spans.Each node is characterized by a status (NUCLEUS orSATELLITE) and a rhetorical relation, which is a re-lation that holds between two non-overlapping textspans.
(There are a few exceptions to this rule: somerelations, such as the CONTRAST relation that holdsbetween unit \[3\] and span \[4,.5\] in the structure of theEnglish text are multinuclear.)
The distinction be-tween nuclei and satellites comes from the empiricalobservation that the nucleus expresses what is moreessential to the writer's intention than the satellite:and that the nucleus of a rhetorical relation is com-prehensible independent of the satellite, but not viceversa.
Rhetorical relations'that end.in the.suffix :'-e".denote relations that correspond to embedded syn-tactic constituents.
For example, the ELABORATION-OBJEC'T-ATTRIBUTE-E relation that holds betweenunits 9. and 1 in the English discourse structure cor-responds to a restrictive relative.
We chose to labelthese relations because we have noticed that theyoften dominate complex discourse trees, whose ele-nlentary units are fully fleshed clauses.If one knows the mappings at the ed~l level,one can determine the mappings at.
the span (dis-course constituent) level as well.
For example, us-19ing the elementary mappings in (7), one can deter-mine that Japanese span \[1,2\] corresponds to Englishspan \[1,2\], Japanese unit \[4\] to English span \[4,5\].,Japanese span \[6,7\] to English unit \[6\], Japanesespan \[1,5\] to English span \[1,5\], and so on.
As Fig-ure 2 shows, the CONCESSION relation that holds be-tween spans \[1,5\] and \[6,7\] in the Japanese tree corre-sponds to a similar relation that holds between span\[I.5\] and unit \[6\] in the English tree (modulo the factthat, in Japanese, the relation holds between sen-tence fragments, while in English it holds betweenfldl sentences).
However, the TEMPORAL-AFTER re-lation that holds between units \[3\] and \[4\] in theJapanese tree is realized as a CONTRAST relationbetween unit  \[3\] and span \[4,5\] in the English tree:And because Japanese units \[6\] and \[7\] are fusedinto: unit \[6\] ing:nglish, the  rel,ation .ELA-BORAT.ION-OBJECT-ATTRIBUTE-E iS no longer made explicit inthe English text.Assume now that it is the task of an MGEN sys-tem to produce from a knowledge base texts (4)and (6).
The system will have to select, the ap-propriate information, generate text plans for thetwo texts, generate sentence plans, and realize them.Should the syst.en~ generate a text plan having astructure similar to the PtST analysis at.
the top orthe bottom of Figure 2"?
Or something in between'?As one can see, the discourse trees in Figure 2 arequite different: they suggest hat depending on theoutput language, text plans should use different re-lations, different orderings of elementary units, dif-ferent aggregations across semantic units, etc.Some researchers may argue that the two RSTanalyses in Figure 2 are too specific.
That  they,figures.In computing Position-Dependent (P-D) recalland precision figures, a Japanese span was consid-ered to match an English span when the Japanesespan contained all the Japanese edus that cor-responded to the edus in the English span, andin fact, correspond t0.
:text.,~plaz!s .,tha-t .l!.ave bee.nalready refined by an aggregation module and ar-guably, even by a sentence planner.
After all, there-ordering of units 1 and 2 can be explained onlyin terms of different syntactic ontraints in Japaneseand English.
We agree with such a concern.
Never-theless, as our experiment shows, significant differ-ences across discourse trees are found not only fortrees built at the sentence level, but also for treesbuilt at the paragraph and text levels.
For these lev-els, it is difficult to explain the differences in termsof language-specific syntactic onstraints.
Rather, itseems more adequate to assume that there are sig-nificant differences with respect o the way informa-tion is organized rhetorically across languages.
Theexperiment described in the next section estimatesquantitatively this difference.3 Exper imentIn order to assess how similar discourse structuresare across languages, we built manually a cor-pus of discourse trees for 40 Japanese texts andtheir corresponding translations.
The texts, se-lected randomly from the ARPA corpus (Whiteand O'Connell, 1994), contained on average about460 words.
We developed a discourse annota-tion protocol for ,Japanese and English along thelines followed by Marcu et al (1999).
We usedMarcu's discourse annotation tool (1999) in orderto manually construct he discourse structure of allJapanese and English texts it, the corpus.
10~.
ofthe Japanese and English texts were rhetoricallylabeled by two of us.
The agreement was sta-tistically significant (Kappa = 0.65.0 > 0.01 forJapanese and Kappa = 0.748,0 > 0.01 for En-glish (Carletta, 1996; Siegel-and Castellan, 1988)).The tool and the annotation protocol are availableat.
http://www, isi.edt,/~r, zarcu/softwa,-e/.
For eachpair of Japanese-English discourse, structures, wealso built, manually an alignment file, which specifiedthe correspondence b tween the edus of the Japaneseand English texts.Using labeled recall and precision figures, we com-puted the similarity between English and Japanesediscourse trees with respect t,o their assignment ofedu boundaries, hierarchical spans, nuclearity, andrhetorical relations, Because the trees we comparoddiffer from one language to the other ill the ntnnberof elernent ary units, the order, of these units, and theway the units are grouped rectirsively into discoursespans, we comptlted two types of recall and precision, :+when :~e.J~laa~tese:~-and.~En~lish::spans -ap eared-inthe same position linearly.
For example, the En-glish tree in Figure 2 is characterized by 10 sub-sentential spans, which span across positions \[1,1\],\[2,2\], \[3,3\], \[4,4\], \[5,5\], \[6,6\], \[1,2\], \[4,5\], \[3,5\], and\[1,5\].
(Span \[1,6\] subsumes 2 sentences, so it isnot sub-sentential.)
The Japanese discourse tree hasonly 4 spans that could be matched in the same po-sitions with English spans, namely spans \[1,2\].
\[4,4\],\[5,5\], and \[1,5\].
Hence the similarity between theJapanese tree and the English tree with respect totheir discourse structure below the sentence level hasa recall of 4/10 and a precision of 4 / l l  (in Figure 2,there are 11 sub-sentential Japanese spans).In computing Position-Independent (P-I) recalland precision figures, even when a Japanese span"floated" during the translation to a position in theEnglish tree that was different from the positionin the initial tree, the P-I recall and precision fig-ures are affected less than when computing Position-Dependent figures.
The position-independent fig-ures reflect the intuition that if two trees tl and t2both have a subtree t, tl and 12 are more similarthan if they were if they didn't share ally subtree.For instance, for the spans at the sub-sentential levelin the trees in Figure 2 the position-independentrecall is 6/10 and the position-independent preci-sion is 6/11 because in addition to spans \[1,2\], \[4,4\],\[5,5\], and \[1,5\], one can also match Japanese spat,\[1,1\] to English spa,, \[2,2\] and Japanese spa,, \[2,2\]to Japanese span \[1,1\].
The Position-Independentfigures offer a more optimistic metric for comparingdiscourse trees.
They span a wider range of valuesthan the Position-Dependent figures, which enablesa finer grained comparison, which in turn enablesa better characterization of the differ.ences betweenJapanese and English discourse structures.In order to provide a better estimate of how closetwo  discourse trees were, we computed Position-Dependent and -Independent recall and precision fig-ures for the sentential evel (where units are givenby edus and spans are given by sets of edus or singlesentences); paragraph level (where units are given bysentences and spans are given by sets of sentences orsingle paragraphs): and text level (where units aregiven by paragraphs and spans are given by sets ofparagraphs).
These figures offer a detailed picture ofhow discourse structures and relations are mapped-from one languageto the other.
Some of the differ-ences at the sentence level can be explained by differ-ences between the syntactic structures of Japanese20LevelSentenceParagraphTextWeighted AverageAll .-SentenceParagraphTextWeighted AverageAllUnitsP-D R P-D P29.1 25.053.9 53.441.3 42.636.0 32.5SpansP-D R P-D P27.2 22.746.8 47.331.5 32.631.8 28.4?
8 .2  ..... : 7,4 .. .
.
.
- .5 .9  .
...... 5.3.:P- IR  P - IP71.0 61.062.1 61.674.1 76.569.6 63.074.5 66.8P- IR  P - IP56.0 46.653.2 53.854.4 56.555.2 49.250.6 45.8NucleiP-D R P-D P21.3 17.738.6 39.028.8 29.926.0 23.1..... -.4A ............ 3~9:_P- IR  P - IP44.3 36.943.3 43.848.5 50.444.8 39.939.4 35.7RelationsP-D R P-D P14.9 12.431.9 32.326.1 27.120.1 17.9. .
.
.
..3.3 .
.
.
.
.
.
.
3 .0 .P - IR  P - IP30.5 25.435.1 35.541.1 42.733.1 29.526.8 24.3Table 1: Similarity of the Japanese and English discourse structuresand English.
The differences at the paragraph andtext levels have a purely rhetorical explanation.As expected, when one computes the recall andprecision figures with respect to the nuclearity andrelation assignments, one also factors in the nucle-arity status and the rhetorical relation that is asso-ciated with each span.Table 1 summarizes the results (P-D and P-I(R)ecall and (P)recision figures) for each level (Sen-tence, Paragraph, and Text).
It presents Recall andPrecision figures with respect to span assignment,nuclearity status, and rhetorical relation labeling ofdiscourse spans.
The numbers in the "WeightedAverage" line report averages of the Sentence-,Paragraph-, and Text-specific figures, weighted ac-cording to the number of units at each level.
Thenumbers in the "All" line reflect recall and precisionfigures computed across the entire trees, with no at-tention paid t.o sentence and paragraph boundaries.Given the significantly different syntactic struc-tures of Japanese and English.
we were not surprisedby tile low recall and precision results that reflectthe similarity between discourse trees built belowthe sentence level.
However, as Table 1 shows, thereare astonishing differences between discourse treesat the paragraph and text.
levels as well.
For exam-pie, the Position-Independent figures show that onlyabout 62% of the sentences: and only :about 53% ofthe hierarchical spans built across sentences could bematched between the two corpora.
When one looksat the nuclearity status and rhetorical relations as-sociated with the spans built across sentences, theP-I recall and precision figures drop to about 43c2~and :/5~ respectively.The differences in recall and precision are ex-l)lained both by differen,-es in the way information ispackaged rote paragraphs in the-two languages aridthe way it is structured rhetorically both within andabove the paragraph level.4 How shou ld  a mul t i l i ngua l  textp lanner  work?The results in Section 3 strongly suggest hat if oneis to build text plans in the context of a Japanese-English multilingual generation system, a language-independent text planning module whose output ismapped straightforwardly into sentence plans (Ior-danskaja et al, 1992; Goldberg et al, 1994) will notdo.
The differences between the rhetorical structuresof Japanese and English texts are simply too big tosupport the derivation of a unique text plan, whichwould subsume both the Japanese- and English-specific realizations.
If we are to build MGEN sys-tems capable of generating rich texts in languagesas distant as English and Japanese, we would needto use more sophisticated techniques.
In the rest ofthis section, we discuss a set of possible approaches,which are consistent with work that has been carriedout to date in the NLG field.4.1 Use text  p lan representat ions  that  aremore  abst rac t  than  d iscourse treesDelin et al (1994) have shown that although tilerhetorical renderings in Figure 1 are non-isomorphic.dmy are alt subsumed by one .commol~, more.ab-stract t.ext.-plan representation language that for-realizes the procedural relations of Generation andEnablement (Goldman, 1970).
One caa~ conceive of.text plans being represented as sequences of actionsor hierarchies of actions and goals over which one canidentify Generation and Enablement relations thathold between them.
In such a framework, text plan-ning is carried out ill a language-independent man-ner.
which is then followed by a rhetorical "'fleshingout".
(Delin et al (1994) have shown how Gener-ation and Enablenlent relations are realized rhetor-ically in various languages using relations such asPURPOSE, 'SEQUENCE, CONDITION, and MEANS.
)Bateman and Rondhuis (1997) suggest that thevariability present in Delin et al's Rhetorical Struc-21ture analyses in Figure 1 can be explained by theinadequate mixture of intentional and semantic re-lations, at different levels of granularity.
They pro-pose that discourse phenomena should be accountedfor at a more abstract level than RST relationsand they present a classification system in termsdiscourse-tree r writing module capable of rewritingP-specific discourse structures into O-specific dis-course structures.
When generating texts in lan-guage P, the MGEN system works as a monolin-gum generator.
When generating texts in languageO, the MGEN system generates a text plan in lan-of "stratification", ..'!me?afunction?., ,,and .
::p~radig,: ........ guage.-~, xnapsitdr~to.=taaag,uageO.,~ anti then ~proceeds - ..matic/syntagmatic axiality" that enables one to rep-resent discourse structures at multiple levels of ab-straction.Adopting such an approach could be an extremelyrewarding enterprise.
Unfortunately, the researchof Delin et al (1994) and Bateman and Rond-huis (1997) cannot be applied yet to unrestricted o-mains.
Generation and Enablement are only two ofthe abstract relations that can hold between actionsand goals.
And some texts, such as descriptions, aredifficult to characterize only in terms of actions andgoals.
Building a "complete" taxonomy of such ab-stract relations and identifying adequate mappingsbetween there relations and rhetorical relations arestill open problems.4.2 Derive a language- independentdiscourse structure, and then l inearizeitRSsner and Stede (1992) and Stede (1999) assumethat a discourse representation g la Mann andThompson imposes no contraints on the linear orderof the leaves.
For tile purpose of multilingual textplanning, one can, hence, assume that a language-independent text planner derives first a language-independent rhetorical structure and then linearizesit, i.e., transforms it to make it language specific.The transformations that RSsner and Stede have ap-plied concern primarily re-orderings of the childrenof some nodes and re-assignment of rhetorical rela-tion labels.
But given, for example, tile significantdifferences between the discourse structures in Fig-ure 2, it is difficult to envision what the language-independent text plan might look like.
It is deft-nitely possible to conceive of such a text plan rep-resentation.
However, the linearization module willneed then to be much more sophisticated: it willneed to be able to rewrite full structures, re-orderconstituents, aggregate_across possibly non-adjacentunits, etc.4.3 hnp lement  a text  p lann ing  a lgor i thmfor one language only.
For all o therlanguages,  dev ise d i scourse - t reerewr i t ing  modu lesIn this approach, the system developer assigns a pre-ferrential status to one of the languages that areto be handled I) 3 ' the MGEN system.
Lot's callthis language P. The system developer implenlentstext planning algorithms only for this language.
Forany other language O, the developer itnplements a22further with the sentence planning and realizationstages.
Marcu et al (2000) present and evaluate adiscourse-tree r writing algorithm that exploits ma-chine learning methods in order to map Japanesediscourse trees into discourse trees that resembleEnglish-specific renderings.The advantage of such an approach is that thetree-rewriting modules can be also used in the con-text of machine translation systems in order to re-package and re-organize the input text rhetorically,to reflect constraints pecific to the target language.The disadvantage is that, from an NLG perspective,there is no guarantee that such a system could pro-duce better results than a system that implementslanguage-dependent text planning modules.4.4 Derive language-dependent  text plansAnother viable approach is to acknowledge thattext plans vary significantly across languages and,therefore, should be derived by language-dependentplanners.
To this end, one could use both top-down (How, 1993; Moore and Paris, 1993) andbottom-up (Marcu, t997; Mellish et al, 1998) textplanning algorithms.
The advantage of this ap-proach is that it has the potential of producing treesthat reflect tile peculiarities specific to any language.The disadvantage is that only the text planning al-gorithms are general: the plan operators and therhetorical relations they operate with are language-dependent, and hence, more expensive to developand maintain.4.5 Discuss ionDepending oil tile languages and text genres it op-erates with, all MGEN system may get away witha language-independent text planner.
However,for sophisticated genres and distant languages, im-plementing a language-independent planner that isstraightforwardly'mapped i:nto sentence, plans doesnot appear to be a felicitous solution.
We enu-merated four possible alternatives for addressing thetext planning problem in an MGEN system.
Eachof tile approaches has its own pluses and minuses.Which will eventually win in large-scale deployableMGEN systems remains an open question.Re ferencesJohn A. Bateman and Klaas Jan Flondliuis.
1997.Coherence relations: Towards a general specifica-tion.
Dtsco~u'se Processes, 24:3-49.Jean Carletta.
1996.
Assessing agreement on clas-sification tasks: The kappa statistic.
Computa-tional Linguistics, 22(2):249-254, June.Judy L. Delin, Anthony Hartley, C@ile L. Paris, Do-nia R. Scott, and Keith Vander Linden.
1994.
Ex-pressing procedural relationships in multilingual-.
instructions.
In -P. roeeedirtgs.,of 4he .,geventh:-,tnter~national Workshop on Natural Language Genera-tion, pages 61-70, Kennebunkport, Maine, June.J.
Delin, D. Scott, and A. Hartley.
1996.
Prag-matic congruence through language-specific map-pings from semantics to syntax.
Technical report,ITRI Research Report ITRI-96-12, University ofBrighton.E.
Goldberg, N. Driedger, and R. Kittredge.
1994.Using natural-language processing to produceweather forecasts.
IEEE Expert, 9(2):45-53.A.I.
Goldman.
1970.
A Theory of Human Action.Prentice Hall, Englewood Cliffs, NJ.Eduard H. Hovy.
1993.
Automated iscourse gen-eration using discourse structure relations.
Artifi-cial Intelligence, 63(1-2):341-386, October.L.
Iordanskaja, M. Kim, R. Kittredge, B. Lavoie,and A. Polguere.
1992.
Generation of extendedbilingual statistical reports.
In Proceedings ofthe 14th International Conference on Compu-tational Linguistics (COLING'92), pages 1019-1023, Nantes, France.William C. Mann and Sandra A. Thompson.
1988.Rhetorical structure theory: Toward a functionaltheory of text organization.
Text, 8(3):243-281.Daniel Marcu.
1997.
From local to global coherence:A bottom-up approach to text planning.
In Pro-ceedings of the Fourteenth National Conference onArtificial Intelligence (AAAI-97), pages 629-635,Providence, Rhode Island, July 28-31.Daniel Marcu, Estibaliz Amorrortu, and MagdalenaRomera.
1999.
Experiments in constructing acorpus of discourse trees, tn Proceedings of theACL'99 Workshop on Standards and Tools forDiscourse Tagging, pages 48-.57, University ofMaryland.
June 22.Daniel Marcu, Lynn Carlson, and Maki Watan-abe.
2000.
The automatic translation of discoursestructures.
In Proceedings of the First AnnualMeeting of the A'orth American Chapter of the As-sociation for Computational Linguistics NAACL-2000, Seattle, Washington.
April 29 - May 3.Chris Mellish.
Alistair Knott.
Jon Oberlander,and Mick O'Donnell.
1998.
Experiments usingstochastic search for text planning.
In Proceed-}ngs of lbc 9lh International H'oHcstwp on .VatvralLanguage.
(;era'cation.
pages 98 107.
Niagara-on-the-Lake, Canada.
August 5-7.,lohanna D. Moore and Cdcile L. Paris.
1993.
Plan-ning text \['or advisory dialogues: Capturing inten-23tional and rhetorical information.
Computational _Linguistics, 19(4):651-694.C.
Paris, K. Vander Linden, M. Fischer, A. Hart-Icy, L. Pemberton, R. Power, and D. Scott.
1995.A support tool for writing multilingual instruc-tions.
In Proceedings.
of the 14th InternationalJoint.
,Gonfer~nee.
~on.
:Artificial ~tnt~ttigenee (IJ-CA I'95), pages 1398-1404, Montreal, Canada.Richar Power and Donia Scott.
1998.
Multilingualauthoring using feedback texts.
In Proceedings ofthe 36th Annual Meeting of the Association forComputational Linguistics (ACL'98), Montreal,Canada, August.Ehud Reiter and Chris Mellish.
1993.
Optimizingthe costs and benefits of natural anguage gen-eration.
In Proceedings of the 131h InternationalJoint Conference on Artificial Intelligence, pages1164-1169.Dietmar R6sner and Manfred Stede.
1992.
Cus-tomizing RST for the automatic productionof technical manuals.
In R. Dale, E. How,D.
R6sner, and O.
Stock, editors, Aspects of Au-tomated Natural Language Generation; 6th Inter-national Workshop on Natural Language Gener-ation, number 587 in Lecture Notes in ArtificialIntelligence, pages 199-214, Trento, Italy, April.Springer-Verlag.Sidney Siegel and N.J. Castellan.
1988.
Non-parametric Statistics for the Behavioral Sciences.McGraw-Hill, second edition.Manfred Stede.
1999.
Rhetorical structure and the-matic structure in text generation.
In WorkingNotes of the Workshop on Levels of Represen-tation m Discourse, pages 117-123, Edinburgh,Scotland, July 7-9.J.
White and T. O'Connell.
1994.
Evalua-tion in the ARPA machine-translation pro-gram: 1993 methodology.
In Proceedings ofthe .4RPA Human language Technology Work-shop, pages 135-140, Washington, D.C. See alsoh ttp :/ /  ursula, geowetown, edu/.
