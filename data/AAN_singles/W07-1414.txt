Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 83?88,Prague, June 2007. c?2007 Association for Computational LinguisticsDependency-based paraphrasing for recognizing textual entailmentErwin Marsi, Emiel KrahmerCommunication & CognitionTilburg UniversityThe Netherlandse.c.marsi@uvt.nle.j.krahmer@uvt.nlWauter BosmaHuman Media InteractionUniversity of TwenteThe Netherlandsw.e.bosma@ewi.utwente.nlAbstractThis paper addresses syntax-based para-phrasing methods for Recognizing TextualEntailment (RTE).
In particular, we de-scribe a dependency-based paraphrasing al-gorithm, using the DIRT data set, and itsapplication in the context of a straightfor-ward RTE system based on aligning depen-dency trees.
We find a small positive effectof dependency-based paraphrasing on boththe RTE3 development and test sets, but theadded value of this type of paraphrasing de-serves further analysis.1 IntroductionCoping with paraphrases appears to be an essentialsubtask in Recognizing Textual Entailment (RTE).Most RTE systems incorporate some form of lex-ical paraphrasing, usually relying on WordNet toidentify synonym, hypernym and hyponym rela-tions among word pairs from text and hypothesis(Bar-Haim et al, 2006, Table 2).
Many systemsalso address paraphrasing above the lexical level.This can take the form of identifying or substitut-ing equivalent multi-word strings, e.g., (Bosma andCallison-Burch, 2006).
A drawback of this approachis that it is hard to cope with discontinuous para-phrases containing one or more gaps.
Other ap-proaches exploit syntactic knowledge in the formof parse trees.
Hand-crafted transformation rulescan account for systematic syntactic alternation likeactive-passive form, e.g., (Marsi et al, 2006).
Al-ternatively, such paraphrase rules may be automati-cally derived from huge text corpora (Lin and Pan-tel, 2001).
There are at least two key advantages ofsyntax-based over string-based paraphrasing whichare relevant for RTE: (1) it can cope with discontin-uous paraphrases; (2) syntactic information such asdominance relations, phrasal syntactic labels and de-pendency relations, can be used to refine the coarsematching on words only.Here we investigate paraphrasing on the basis ofof syntactic dependency analyses.
Our sole resourceis the DIRT data set (Lin and Pantel, 2001), an exten-sive collection of automatically derived paraphrases.These have been used for RTE before (de Salvo Brazet al, 2005; Raina et al, 2005), and similar ap-proaches to paraphrase mining have been appliedas well (Nielsen et al, 2006; Hickl et al, 2006).However, in these approaches paraphrasing is al-ways one factor in a complex system, and as a resultlittle is known of the contribution of paraphrasingfor the RTE task.
In this paper, we focus entirelyon dependency-based paraphrasing in order to get abetter understanding of its usefulness for RTE.
In thenext Section, we describe the DIRT data and presentan algorithm for dependency-based paraphrasing inorder to bring a pair?s text closer to its hypothesis.We present statistics on coverage as well as qual-itative discussion of the results.
Section 3 then de-scribes our RTE system and results with and withoutdependency-based paraphrasing.2 Dependency-based paraphrasing2.1 Preprocessing RTE dataStarting from the text-hypothesis pairs in the RTEXML format, we first preprocess the data.
As thetext part may consist of more than one sentence,we first perform sentence splitting using Mxtermi-nator (Reynar and Ratnaparkhi, 1997), a maximum83entropy-based end of sentence classifier trained onthe Penn Treebank data.
Next, each sentence is to-kenized and syntactically parsed using the Miniparparser (Lin, 1998).
From the parser?s tabular outputwe extract the word forms, lemmas, part-of-speechtags and dependency relations.
This information isthen stored in an ad-hoc XML format which repre-sents the trees as an hierarchy of node elements inorder to facilitate tree matching.2.2 DIRT dataThe DIRT (Discovering Inference Rules from Text)method is based on extending Harris DistributionalHypothesis, which states that words that occurred inthe same contexts tend to be similar, to dependencypaths in parse trees (Lin and Pantel, 2001).
Eachdependency path consists of at least three nodes: aroot node, and two non-root terminal nodes, whichare nouns.
The DIRT data set we used consists ofover 182k paraphrase clusters derived from 1GB ofnewspaper text.
Each cluster consists of a uniquedependency path, which we will call the paraphrasesource, and a list of equivalent dependency paths,which we will refer to as the paraphrase transla-tions, ordered in decreasing value of point-wise mu-tual information.
A small sample in the original for-mat is(N:by:V<buy>V:obj:N (simsN:to:V<sell>V:obj:N 0.211704N:subj:V<buy>V:obj:N 0.198728...))The first two lines represent the inference rule: Xbought by Y entails X sold to Y.We preprocess the DIRT data by restoring prepo-sitions, which were originally folded into a depen-dency relation, to individual nodes, as this easesalignment with the parsed RTE data.
For the samereason, paths are converted to the same ad-hoc XMLformat as the parsed RTE data.2.3 Paraphrase substitutionConceptually, our paraphrase substitution algorithmtakes a straightforward approach.
For the purpose ofexplanation only, Figure 1 presents pseudo-code fora naive implementation.
The main function takestwo arguments (cf.
line 1).
The first is a prepro-cessed RTE data set in which all sentences from textand hypothesis are dependency parsed.
The secondis a collection of DIRT paraphrases, each one map-ping a source path to one or more translation paths.For each text/hypothesis pair (cf.
line 2), we lookat all the subtrees of the text parses (cf.
line 3-4)and attempt to find a suitable paraphrase of this sub-tree (cf.
line 5).
We search the DIRT paraphrases(cf.
line 8) for a source path that matches the textsubtree at hand (cf.
line 9).
If found, we checkif any of the corresponding paraphrase translationpaths (cf.
line 10) matches a subtree of the hypoth-esis parse (cf.
line 11-12).
If so, we modify thetext tree by substituting this translation path (cf.
line13).
The intuition behind this is that we only acceptparaphrases that bring the text closer to the hypothe-sis.
The DIRT paraphrases are ordered in decreasinglikelihood, so after a successful paraphrase substitu-tion, we discard the remaining possibilities and con-tinue with the next text subtree (cf.
line 14).The Match function, which is used for matchingthe source path to a text subtree and the translationpath to an hypothesis subtree, requires the path tooccur in the subtree.
That is, all lemmas, part-of-speech tags and dependency relations from the pathmust have identical counterparts in the subtree; skip-ping nodes is not allowed.
As the path?s terminalsspecify no lemma, the only requirement is that theircounterparts are nouns.The Substitute function replaces the matched pathin the text tree by the paraphrase?s translation path.Intuitively, the path ?overlays?
a part of the sub-tree, changing lemmas and dependency relations,but leaving most of the daughter nodes unaffected.Note that the new path may be longer or shorter thanthe original one, thus introducing or removing nodesfrom the text tree.As an example, we will trace our algorithm as ap-plied to the first pair of the RTE3 dev set (id=1).Text: The sale was made to pay Yukos?
US$ 27.5 billion taxbill, Yuganskneftegaz was originally sold for US$ 9.4 bil-lion to a little known company Baikalfinansgroup whichwas later bought by the Russian state-owned oil companyRosneft.Hypothesis: Baikalfinansgroup was sold to Rosneft.Entailment: YesWhile traversing the parse tree of the text, ouralgorithm encounters a node with POS tag V andlemma buy.
The relevant part of the parse tree isshown at the right top of Figure 2.
The logical argu-ments inferred by Minipar are shown between curly84(1) def Paraphrase(parsed-rte-data, dirt-paraphrases):(2) for pair in parsed-rte-data:(3) for text-tree in pair.text-parses:(4) for text-subtree in text-tree:(5) Paraphrase-subtree(text-subtree, dirt-paraphrases, pair.hyp-parse)(6)(7) def Paraphrase-subtree(text-subtree, dirt-paraphrases, hyp-tree):(8) for (source-path, translations) in dirt-paraphrases:(9) if Match(source-path, text-subtree):(10) for trans-path in translations:(11) for hyp-subtree in hyp-tree:(12) if Match(trans-path, hyp-subtree):(13) text-subtree = Substitute(trans-path, text-subtree)(14) returnFigure 1: Pseudo-code for a naive implementation of the dependency-based paraphrase substitution algo-rithmbrackets, e.g., US$ 9.4 billion.
For this combinationof verb and lemma, the DIRT data contains 340 para-phrase sets, with a total of 26950 paraphrases.
Thealgorithm starts searching for a paraphrase sourcewhich matches the text.
It finds the path shownat the left top of Figure 2: buy with a PP modi-fier headed by preposition by, and a nominal object.This paraphrase source has 108 alternative transla-tions.
It searches for paraphrase translations whichmatch the hypothesis.
The first, and therefore mostlikely (probability is 0.22) path it finds is rooted insell, with a PP-modifier headed by to and a nominalobject.
This translation path, as well as its alignmentto the hypothesis parse tree, is shown in the mid-dle part of Figure 2.
Finally, the source path in thetext tree is substituted by the translation path.
Thebottom part of Figure 2 shows the updated text treeas well as its improved alignment to the hypothesistree.
The paraphrasing procedure can in effect beviewed as making the inference that Baikalfinans-group was bought by Rosneft, therefore Baikalfi-nansgroup was sold to Rosneft.The naive implementation of the algorithm is ofcourse not very efficient.
Our actual implementa-tion uses a number of shortcuts to reduce process-ing time.
For instance, the DIRT paraphrases areindexed on the lemma of their root in order to speedup retrieval.
As another example, text nodes withless than two child nodes (i.e.
terminal and unary-branching nodes) are immediately skipped, as theywill never match a paraphrase path.2.4 Paraphrasing resultsWe applied our paraphrasing algorithm to the RTE3development set.
Table 1 gives an impression of howmany paraphrases were substituted.
The first rowlists the total number of nodes in the dependencytrees of the text parts.
The second row shows thatfor roughly 15% of these nodes, the DIRT data con-tains a paraphrase with the same lemma.
The nexttwo rows show in how many cases the source pathmatches the text and the translation path matches thehypothesis (i.e.
giving rise to a paraphrase substitu-tion).
Clearly, the number of actual paraphrase sub-stitutions is relatively small: on average about 0.5%of all text subtrees are subject to paraphrasing.
Still,about one in six sentences is subject to paraphras-ing, and close to half of all pairs is paraphrased atleast once.
Sentences triggering more than one para-phrase do occur.
Also note that paraphrasing occursmore frequently in true entailment pairs than in falseentailment pairs.
This is to be expected, given thattext and hypothesis are more similar when an entail-ment relation holds.2.5 Discussion on paraphrasingType of paraphrases A substantial number of theparaphrases applied are single word synonyms orverb plus particle combinations which might as wellbe obtained from string-based substitution on the ba-sis of a lexical resource like WordNet.
Some ran-domly chosen examples include X announces Y en-tails X supports Y, X makes Y entails X sells Y, andlocates X at Y, discovers X at Y.
Nevertheless, moreinteresting paraphrases do occur.
In the pair below(id=452), we find the paraphrase X wins Y entails X85Table 1: Frequency of (partial) paraphrase matches on the RTE3 dev setIE: IR: QA: SUM: Total:Text nodes: 8899 10610 10502 8196 38207Matching paraphrase lemma: 1439 1724 1581 1429 6173Matching paraphrase source: 566 584 543 518 2211Matching paraphrase translation: 71 55 23 79 228Text sentences: 272 350 306 229 1157Paraphrased text sentences: 63 51 20 66 200Paraphrased true-entailment pairs: 32 25 12 39 108Paraphrased false-entailment pairs: 26 21 5 23 75(is) Y champion.Text: Boris Becker is a true legend in the sport of tennis.
Agedjust seventeen, he won Wimbledon for the first time andwent on to become the most prolific tennis player.Hypothesis: Boris Becker is a Wimbledon champion.Entailment: TrueAnother intriguing paraphrase, which appears to befalse on first sight, is X flies from Y entails X makes(a) flight to Y.
However, in the context of the nextpair (id=777), it turns out to be correct.Text: The Hercules transporter plane which flew straight herefrom the first round of the trip in Pakistan, touched downand it was just a brisk 100m stroll to the handshakes.Hypothesis: The Hercules transporter plane made a flight toPakistan.Entailment: TrueCoverage Although the DIRT data constitutes arelatively large collection of paraphrases, it is clearthat many paraphrases required for the RTE3 dataare missing.
We tried to improve coverage to someextent by relaxing the Match function: instead ofan exact match, we allowed for small mismatchesin POS tag and dependency relation, reversing theorder of a path?s left and right side, and even forskipping nodes.
However, subjective evaluation sug-gested that the results deteriorated.
Alternatively,the coverage might be increased by deducing para-phrases on the fly using the web as a corpus, e.g.,(Hickl et al, 2006).Somewhat surprisingly, the vast majority of para-phrases concerns verbs.
Even though the DIRT datacontains paraphrases for nouns, adjectives and com-plementizers, the coverage of these word classes isapparently not nearly as extensive as that of verbs.Another observation is that fewer paraphrases oc-cur in pairs from the QA task.
We have no explana-tion for this.False paraphrases Since the DIRT data was au-tomatically derived and was not manually checked,it contains noise in the form of questionable or evenfalse paraphrases.
While some of these surface inparaphrased RTE3 data (e.g.
X leaves for Y entailsX departs Y, and X feeds Y entails Y feeds X), theirnumber appears to be limited.
We conjecture this isbecause of the double constraint that a paraphrasemust match both text and hypothesis.Relevance Not all paraphrase substitutions are rel-evant for the purpose of recognizing textual entail-ment.
Evidently, paraphrases in false entailmentpairs are counterproductive.
However, even in trueentailment pairs paraphrases might occur in partsof the text that are irrelevant to the task at hand.Consider the following pair from the RTE3 dev set(id=417).Text: When comparing Michele Granger and Brian Goodell,Brian has to be the clear winner.
In 1976, while still astudent at Mission Viejo High, Brian won two Olympicgold medals at Montreal, breaking his own world recordsin both the 400 - and 1,500 - meter freestyle events.
Hewent on to win three gold medals in he 1979 Pan Ameri-can Games.Hypothesis: Brian Goodell won three gold medals in the 1979Pan American Games.Entailment: TrueThe second text sentence and hypothesis matchthe paraphrases: (1) X medal at Y entails X medal inY, and (2) X record in Y entails X medal in Y. Evenso, virtually all of the important information is in thethird text sentence.3 Results on RTE3 dataSince our contribution focuses on syntactic para-phrasing, our RTE3 system is a simplified version86Table 2: Percent accuracy on RTE3 set withoutparaphrasing (?)
and with paraphrasing (+)Task Dev?
Dev+ Test?
Test+IE 59.5 61.0 53.0 53.5IR 67.0 68.0 58.5 61.5QA 76.0 76.5 69.0 68.0SUM 66.0 67.5 53.0 53.5Overall 66.9 68.2 58.6 59.1of our RTE2 system as described in (ref supressedfor blind reviewing) The core of the system is stillthe tree alignment algorithm from (Meyers et al,1996), but without normalization of node weightsand applied to Minipar instead of Maltparser out-put.
To keep things simple, we do not apply syntac-tic normalization, nor do we use WordNet or otherresources to improve node matching.
Instead, wesimply align each text tree to the corresponding hy-pothesis tree and calculate the coverage, which isdefined as the proportion of aligned content wordsin the hypothesis.
If the coverage is above a task-specific threshold, we say entailment is true, other-wise it is false.The results are summarized in Table 2.
Overallresults on the test set are considerably worse thanon the development set, which is most likely due tooverfitting task-specific parameters for node match-ing and coverage.
Our main interest is to what extentdependency-based paraphrasing improves our base-line prediction.
The improvement on the develop-ment set is more than 1%.
This is reduced to 0.5%in the case of the test set.Our preliminary results indicate a small positiveeffect of dependency-based paraphrasing on the re-sults of our RTE system.
Unlike most earlier work,we did not add resources other than Minipar depen-dency trees and DIRT paraphrase trees, in order toisolate the contribution of syntactic paraphrases toRTE.
Nevertheless, our RTE3 system may be im-proved by using WordNet or other lexical resourcesto improve node matching, both in the paraphrasingstep and in the tree-alignment step.
In future work,we hope to improve both the paraphrasing method(along the lines discussed in Section 2.5) and theRTE system itself.Acknowledgments We would like to thank Dekang Lin andPatrick Pantel for allowing us to use the DIRT data.
This workwas jointly conducted within the DAESO project funded by theStevin program (De Nederlandse Taalunie) and the IMOGENproject funded by the Netherlands Organization for ScientificResearch (NWO).ReferencesR.
Bar-Haim, I. Dagan, B. Dolan, L. Ferro, D. Giampic-colo, B. Magnini, and I. Szpektor.
2006.
The secondpascal recognising textual entailment challenge.
InProceedings of the Second PASCAL Challenges Work-shop on Recognising Textual Entailment, pages 1?9,Venice, Italy.W.
Bosma and C. Callison-Burch.
2006.
Paraphrase sub-stitution for recognizing textual entailment.
In Pro-ceedings of CLEF.R.
de Salvo Braz, R. Girju, V. Punyakanok, D. Roth, andM.
Sammons.
2005.
An inference model for seman-tic entailemnt in natural language.
In Proceedings ofthe First Pascal Challenge Workshop on RecognizingTextual Entailment, pages 29?32.A.
Hickl, J. Williams, J. Bensley, K. Roberts, B. Rink,and Y. Shi.
2006.
Recognizing textual entailmentwith lccs groundhog system.
In Proceedings of theSecond PASCAL Challenges Workshop on Recognis-ing Textual Entailment, pages 80?85, Venice, Italy.Dekang Lin and Patrick Pantel.
2001.
Discovery of infer-ence rules for question answering.
Natural LanguageEngineering, 7(4):343?360.Dekang Lin.
1998.
Dependency-based evaluation ofminipar.
In Proceedings of the Workshop on Evalua-tion of Parsing Systems at LREC 1998, pages 317?330,Granada, Spain.E.
Marsi, E. Krahmer, W. Bosma, and M. Theune.
2006.Normalized alignment of dependency trees for detect-ing textual entailment.
In Proceedings of the SecondPASCAL Challenges Workshop on Recognising Tex-tual Entailment, pages 56?61, venice, Italy.Adam Meyers, Roman Yangarber, and Ralph Grisham.1996.
Alignment of shared forests for bilingual cor-pora.
In Proceedings of 16th International Conferenceon Computational Linguistics (COLING-96), pages460?465, Copenhagen, Denmark.R.
Nielsen, W. Ward, and J.H.
Martin.
2006.
Towarddependency path based entailment.
In Proceedings ofthe Second PASCAL Challenges Workshop on Recog-nising Textual Entailment, pages 44?49, Venice, Italy.R.
Raina, A. Haghighi, C. Cox, J. Finkel, J. Michels,K.
Toutanova, B. MacCartney, M.C.
deMarneffe, C.D.Manning, and A.Y.
Ng.
2005.
Robust textual infer-ence using diverse knowledge sources.
In Proceedingsof PASCAL Recognising Textual Entailment Workshop.J.
C. Reynar and A. Ratnaparkhi.
1997.
A maximum en-tropy approach to identifying sentence boundaries.
InProceedings of the Fifth Conference on Applied Natu-ral Language Processing, Washington, D.C.87buybymod...objbuy...pcomp-nbyRosneft{US$ 9.4 billion}Baikalfinansgroups mod obj{Baikalfinansgroup}subjknownmodcompanynn{fin}relwhichwhnbeilaterpred{which}subjpcomp-nthedetRussianmodstate-ownedmodoil companynnstatelex-mod-lex-modoillex-modselltomod...objsell...pcomp-ntoRosneft{Baikalfinansgroup}Baikalfinansgroupsbebe mod objpcomp-nsellBaikalfinansgroupstomod{US$ 9.4 billion}obj{Baikalfinansgroup}subjknownmodcompanynn{fin}relwhichwhnbeilaterpred{which}subjRosneftpcomp-nthedetRussianmodstate-ownedmodoil companynnstatelex-mod-lex-modoillex-modsellBaikalfinansgroupsbebetomod{Baikalfinansgroup}objRosneftpcomp-nFigure 2: Alignment of paraphrase source to text (top), alignment of paraphrase translation to hypothesis(mid), and alignment of hypothesis to paraphrased text (bottom) for pair 1 from RTE3 dev set88
