Accumulation of Lexical Sets: Acquisition of Dictionary Resourcesand Production of New Lexical SetsDOAN-NGUYEN HaiGETA - CLIPS - IMAGBP 53, 38041 Grenoble, FranceFax: (33) 4 76 51 44 05 - Tel: (33) 4 76 63 59 76 - E-mail: Hai.Doan-Nguyen@imag.frAbstractThis paper presents our work on accumulation oflexical sets which includes acquisition ofdictionary resources and production of  newlexical sets from this.
The method for theacquisition, using a context-free syntax-directedtranslator and text modification techniques,proves easy-to-use, flexible, and efficient.Categories of production are analyzed, andbasic operations are proposed which make up aformalism for specifying and doing production.About 1.7 million lexical units were acquiredand produced from dictionaries of various ~pesand complexities.
The paper also proposes acombinatorial and dynamic organization forlexical systems, which is based on the notion ofvirtual accumulation and the abstraction levelsof lexical sets.Keywords: dictionary resources, lexicalacquisition, lexical production, lexicalaccumulation, computational lexicography.IntroductionAcquisition and exploitation of dictionaryresources (DRs) (machine-readable, on-linedictionaries, computational lexicons, etc) havelong been recognized as important and difficultproblems.
Although there was a lot of work onDR acquisition, such as Byrd & al (1987), Neff& Boguraev (1989), Bl~isi & Koch (1992), etc, itis still desirable to develop general, powerful, andeasy-to-use methods and tools for this.Production of new dictionaries, even only crudedrafts, from available ones, has been much lesstreated, and it seems that no generalcomputational framework has been proposed(see eg, Byrd & al (1987), Tanaka & Umemura(1994), Don" & al (1995)).This paper deals with two problems: acquiringtextual DRs by converting them into structuredforms, and producing new lexical sets from thoseacquired.
These two can be considered as twomain activities of a more general notion: theaccumulation of lexical sets.
The term "lexicalset" (LS) is used here to be a generic term formore specific ones such as "lexicon","dictionary", and "lexical database".Lexical data accumulated will be represented asobjects of the Common Lisp Object System(CLOS) (Steel 1990).
This object-oriented high-level programming environment facilitates anyfurther manipulations on them, such aspresentation (eg in formatted text), exchange (egin SGML), database access, and production ofnew lexical structures, etc; the CLOS object formis thus a convenient pivot form for storing lexicalunits.
This environment also helps us developour methods and tools easily and efficiently.In this paper, we will also discuss some otherrelevant issues: complexity measures fordictionaries, heuristic decisions in acquisition, theidea of virtual accumulation, abstraction levels onLSs, and a design for organization andexploitation of large lexical systems based on thenotions of accumulation.1 Acquisit ionOur method combines the use of a context-freesyntax-directed translator and text modificationtechniques.1.1 A syntax-directed translator foracquisitionTransforming a DR into a structured formcomprises parsing the source text and buildingthe output structures.
Our approach is differentfrom those of other tools specialized for DRacquisition, eg Neff & Boguraev (1989) andBl~.si & Koch (1992), in that it does not imposebeforehand a default output constructionmechanism, but rather lets the user build theoutput as he wants.
This means the outputstructures are not to be bound tightly to theparsing grammar.
Particularly, they can bedifferent from the logic structure of the source,as it is sometimes needed in acquisition.
The usercan also keep any presentation information (egtypographic odes) as needed; our approach isthus between the two extremes in acquisitionapproaches: one is keeping all presentationinformation, and one is transferring it all intostructural representation.Our tool consists of a syntax-directedtranslation (SDT) formalism called h-grammar,and its running engine.
For a given dictionary,one writes an h-grammar describing the text of330its entry and the construction of the output.
Anh-grammar is a context-free grammaraugmented with variables and actions.
Its rulesare of the form:A(ail ai2 ...; aol ao2 ...)->B(bil bi2 ...; bol bo2 ...)C(cil ci2 ...; col co2 ...) ....A is a nonterminal; B, C .
.
.
.
may be anonterminal, a terminal, the null symbol ?, or anaction, ail, ai2 ... .
are input variables, which willbe initialized when the rule is called, aol, ao2 .....bol, bo2 .
.
.
.
.
col, co2 .
.
.
.
are output variables.bil, bi2 ..... cil, ci2 .... are input expressions (inLISP syntax), which may contain variables.
Whenan item in the right-hand side of the rule isexpanded, its input expressions are firstcomputed.
If the item is a nonterminal, a rulehaving it as the left-hand side is chosen toexpand.
If it is a terminal, a corresponding tokenis looked for in the parsed buffer and returned asthe value of its (unique) output variable.
If it isan action which is in fact a LISP function, thefunction is applied to the values of its inputexpressions, and the result values are assigned toits output variables (here we use the multiple-value function model of CLOS).
Finally, thevalues of the output variables of the left-handside nonterminal (aol, ao2 .... ) are collected andreturned as the result of its expanding.With some predefined action functions, outputstructures can be constructed freely, easily, andflexibly.
We usually choose to make them CLOSobjects and store them in LISPO form.
This isour text representation for CLOS objects, whichhelps to read, verify, correct, store and transferthe result easily.
Finally, the running engine hasseveral operational modes, which facilitatedebugging the h-grammars and treating errorsmet in parsing.1 .2  Text  mod i f i ca t ion  in acqu is i t ionIn general, an analyzer, such as the h-grammartool above, is sufficient for acquisition.
However,in practice, some precedent modification on thesource text may often simplify much theanalyzing phase.
In contrast with many otherapproaches, we recognize the usefulness of textmodification, and apply it systematically in ourwork.
Its use can be listed as follows:(1) Facilitating parsing.
By inserting somespecific marks before and/or after some elementsof the source, human work in grammar writingand machine work in parsing can be reducedsignificantly.
(2) Obtaining the result immediately withoutparsing.
In some simple cases, using severalreplacement operations in a text editor, we couldobtain easily the LISPO form of a DR. TheLISPification well-known in a lot of acquisitionwork is another example.
(3) Retaining necessary information andstripping unnecessary one.
In many cases, muchof the typographic information in the source textis not needed for the parsing phase, and can bepurged straightforwardly in an adequate texteditor.
(4) Pre-editing the source and post-editing theresult, eg to correct some simple but commontype of errors in them.It is preferable that text modification be carriedout as automatically as possible.
The main typeof modification needed is replacement using astrong string pattern-matching (or precisely,regular expression) mechanism.
Themodification of a source may consist of manyoperations and they need to be tested severaltimes; it is therefore advantageous to have someway to register the operations and to run them inbatch on the source.
An advanced wordprocessor such as Microsoft Word TM, version 6,seems capable of satisfying those demands.For sources produced with formatting from aspecific editing environment (eg Microsoft Word,HTML editors), making modification in the sameor an equivalent environment may be veryprofitable, because we can exploit format-basedoperations (eg search/replace based on format)provided by the environment.1 .3  Some re la ted  issues1.3.1 Complexity measures for dictionariesIntuitively, the more information types adictionary has, the more complex it is, and theharder to acquire it becomes.
We propose here ameasure for this.
Briefly, the structure complexity(SC) of a dictionary is equal to the sum of thenumber of elementary information types and thenumber of set components in its entry structure.For example, an English-French dictionarywhose entries consist of an English headword, apart-of-speech, and a set of French translations,will have a SC of (1 + 1 + 1 )+ 1-4.Based on this measure, some others can bedefined, eg the average SC, which gives theaverage number of information types present inan entry of a dictionary (because not all entrieshave all components filled).1.3.2 Heuristics in acquisitionContrary to what one may often suppose,decisions made in analyzing a DR are not alwaystotally sure, but sometimes only heuristic ones.For large texts which often contain many errorsand ambiguities like DRs, precise analysis designmay become too complicated, even impossible.331Imagine, eg, some pure text dictionary where thesense numbers of the entries are made from anumber and a point, eg '1.
', '2.
'; and, moreover,such forms are believed not to occur in contentstrings without verification (eg, because thedictionary is so large).
An assumption that suchforms delimit the senses in an entry is veryconvenient in practice, but is just a heuristics.1.4 Result and exampleOur method and tool have helped us acquireabout 30 dictionaries with a total of more than1.5 million entries.
The DRs are of variouslanguages, types, domains, formats, quantity,clarit.y, and complexity.
Some typical examplesare gwen in the following table.Dictionary Resource 1DEC, vol.
II (Mel'cuk & al 1988)French Official Terms (Drlrgationgrnrrale ~ la langue franqaise)Free On-line Dictionary of Computing (D.Howe, http://wombat.doc.ic.ac.uk)English-Esperanto (D. Richardson,Esperanto League for North America)English-UNL (Universal NetworkingLanguage.
The United Nations University)I.
Kind's BABEL - Glossary of ComputerOriented Abbrevations and AcronymsSC Numberof entries79 10019 3,50015 10,80011 6,0006 220,0006 3,400We present briefly here the acquisition of ahighly complex DR, the Microsoft Word sourcefiles of volume 2 of the "Dictionnaire explicatifet combinatoire du fran~ais contemporain "(DEC) (Mel'cuk & al 1988).
Despite thenumerous errors in the source, we were able toachieve a rather fine analysis level with a minimalmanual cleaning of the source.
For example, alexical function expression such asAdv(1 )(Real 1 !IF6 + Real2IIF6 )was analyzed into:(COMP("Adv" NIL (O\[?I'IONAL 1) NIL NIL NIL)(PAREN (+ (COMP ("Real" NIL (1) 2 NIL NIL) ("F" 6))(COMP ("Real" NIL (2) 2 NIL NIL) ("F" 6)))))Compared to the method of direct programmingthat we had used before on the same source,human work was reduced by half (1.5 vs 3person-months), and the result was better (fineranalysis and lower error rate).I All these DRs were used only for my personal research onacquisition, conforming to their authors' permission otes.2 ProductionFrom available LSs it is interesting and .possibleto produce new ones, eg, one can revert abilingual dictionary A-B to obtain a B-Adictionary, or chain two dictionaries A-B and B-C to make an A-B-C, or only A-C (A, B, C arethree languages).
The produced LSs surely needmore correction but they can serve at least assomewhat prepared materials, eg, dictionarydrafts.
Acquisition and production make thenotion of lexical accumulation complete: theformer is to obtain lexical data of (almost) thesame linguistic structure as the source, the latteris to create data of totally new linguisticstructures.Viewed as a computational linguistic problem,production has two aspects.
The linguistic aspectconsists in defining what to produce, ie themapping from the source LSs to the target LSs.The quality of the result depends on thelinguistic decisions.
There were severalexperiments studying some specific issues, suchas sense mapping or attribute transferring (Byrd& al (1987), Dorr & al (1995)).
This aspectseems to pose many difficult lexicographicproblems, and is not dealt with here.The computational aspect, in which we areinterested, is how to do production.
To begeneral, production needs a Turing machinecomputational power.
In this perspective, aframework which can help us specify easily aproduction process may be very desirable.
Tobuild such a framework, we will examine severalcommon categories of production, point outbasic operations often used in them, and finally,establish and implement a formalism forspecifying and doing production.2 .1  Categor ies  o f  productionProduction can be done in one of two directions,or by combining both: "extraction" and"synthesis".
Some common categories ofproduction are listed below.
(1) Selection of a subset by some criteria, egselection of all verbs from a dictionary.
(2) Extraction of a substructure, g extracting abilingual dictionary from a trilingual.
(3) Inversion, eg of an English-Frenchdictionary to obtain a French-English one.
(4) Regrouping some elements to make a"bigger" structure, eg regrouping homographentries into polysemous ones.
(5) Chaining, eg two bilingual dictionaries A-Band B-C to obtain a trilingual A-B-C.(6) Paralleling, eg an English-Frenchdictionary with another English-French, to makean English-\[French( I ), French(2)\] (forcomparison or enrichment .. .
.
).332(7) Starring combination, eg of severalbilingual dictionaries A-B, B-A, A-C, C-A, A-D,D-A, to make a multiligual one with A being thepivot language (B, C, D)-A-(B, C, D).Numeric evaluations can be included inproduction, eg in paralleling several English-French dictionaries, one can introduce a fuzzylogic number showing how well a French wordtranslates an English one: the more dictionariesthe French word occurs in, the bigger thenumber becomes.2 .2  Imp lementat ion  of  product ionStudying the algorithms for the categories aboveshows they may make use of many commonbasic operations.
As an example, the operationregroup set by functionl into function2partitions et into groups of elements having thesame value of applying function1, and appliesfunction2 on each group to make a new element.It can be used to regroup homograph entries (iethose having the same headword forms) of adictionary into polysemous ones, as follows:regroup dictionary by headword into polysem(polysem is some function combining the body of thehomograph entries into a polysemous one.
)It can also be used in the inversion of anEnglish-French dictionary EF-dict whose entriesare of the structure <English-word, French-translations> (eg <love, {aimer, amour}>):for-all EF-entry in EF-dict dosplit EF-entry into <French, English> pairs, egsplit <love, {aimer, amour}> into {<aimer, love><amour, love>}.
Call the result FE-pairs.regroup FE-pairs by French into FE-entry(FE-entry is a function making French-English entries,eg making <aimer, {love, like}> from <aimer, like> and<aimer, love>.
)Our formalism for production was built withfour groups of operations (see Doan-Nguyen(1996) for more details):(1) Low-level operations: assignments,conditionals, and (rarely used) iterations.
(2) Data manipulation functions, eg stringfunctions.
(3) Set and first-order predicate calculusoperations, eg the for-all above.
(4) Advanced operations, which d ocomplicated transformations on objects and sets,eg regroup, split above.Finally, LSs were implemented asLISP lists for"small" sets, and CLOS object databases andLISPO sequential files for large ones.2.3  Result and exampleWithin the framework presented above, about 1 0dictionary drafts of about 200,000 entries wereproduced.
As an example, an English-French-UNL 2 (EFU) dictionary draft was produced froman English-UNL (EU) dictionary, a French-English-Malay (FEM), and a French-English(FE).
The FEM is extracted and inverted to givean English-French dictionary (EF-1), the FIE isinverted to give another (EF-2).
The EFU isproduced then by paralleling the EU, EF-1, andEF-2.
This draft was used as the base forcompiling a French-UNL dictionary at GETA(Boitet & al 1998).
We have not yet had anevaluation on the draft.3 Virtual Accumulat ionAbstract ion of  Lexical  Setsand3 .1  Virtual  accumulat ionAccumulation discussed so far is realaccumulation: the LS acquired or produced isavailable in its whole and its elements are put in a"standard" form used by the lexical system.However, accumulation may also be virtual, ieLSs which are not entirely available may still beused and even integrated in a lexical system, andlexical units may rest in their original format andwill be converted to the standard form only whennecessary.
This means, eg, one can include in hislexical system another's Web online dictionarywhich only supplies an entry to each request.Particularly, in virtual acquisition, the resourceis untouched, but equipped with an acquisitionoperation, which will provide the necessarylexical units in the standard form when it iscalled.
In virtual production, not the whole newLS is to be produced, but only the requiredunit(s).
One can, eg, supply dynamically Germanequivalents of an English word by calling afunction looking up English-French and French-German entries (in corresponding dictionaries)and then chaining them.
Virtual production maynot be suitable, however, for some productioncategories such as inversion.3 .2  Abst ract ion  o f  LSsThe framework of accumulation, real and virtual,presented so far allows us to design a verygeneral and dynamic model for lexical systems.The model is based on some abstraction levels ofLSs as follows.
(1) A physical support is a disk file, database,Web page, etc.
This is the most elementary level.2 UNL: Universal Networking Language (UNL 1996).333(2) A LS support makes up the contents of aLS.
It comprises a set of physical supports (as along dictionary may be divided into severalfiles), and a number of access ways whichdetermine how to access the data in the physicalsupports (as a database may have several index).The data in its physical supports may not be inthe standard form; in this case it will be equippedwith a standardizing function on accessed ata.
(3) A lexical set (LS) comprises a set of LSsupports.
Although having the same contents,they may be different in physical form and dataformat; hence this opens the possibility to querya LS from different supports.Virtual LSs are "sets" that do not have "real"supports, their entries are produced from someavailable sets when required, and there are noinsert, delete activities for them.
(4) A lexical group comprises a number of LSs(real or virtual) that a user uses in a work, and aset of operations which he may need to do onthem.
A lexical group is thus a workstation in alexical system, and this notion helps to view anddevelop the system modularly, combinatorially,and dynamically.Based on these abstractions, a design on theorganization for lexical systems can beproposed.
Fundamentally, a lexical system hasreal LSs as basic elements.
Its performance isaugmented with the use of virtual LSs and lexicalgroups.
A catalogue is used to register andmanage the LSs and groups.
A model of such anorgamzation is shown in the figure below.alo~lex caltnd~upsLEXICAL SYSTEMphysicalsupportsreal lexicalsetsvirtuallexical setslexicalgroupsConclus ion and perspect iveAlthough we have not yet been able to evaluateall the lexical data accumulated, our methods andtools for acquisition and production have shownthemselves useful and efficient.
We have alsodeveloped a rather complete notion of lexicaldata accumulation, which can be summarized as:ACCUMULATION = (REAL + VIRTUAL)(ACQUISITION + PRODUCTION)For the future, we would like to work onmethods and environments for testingaccumulated lexical data, for combining themwith data derived from corpus-based methods,etc.
Some more time and work will be needed toverify the usefulness and practicality of ourlexical system design, of which the essential ideais the combinatorial and dynamic elaboration oflexical groups and virtual LSs.
An experimentfor this may be, eg, to build a dictionary serverusing Intemet online dictionaries as resources.AcknowledgementThe author is grateful to the French Government forher scholarship, to Christian Boitet and Gilles Sdrassetfor the suggestion of the theme and their help, and to theauthors of the DRs for their kind permission of use.ReferencesBl~isi C. & Koch H. (1992), Dictionary Entry ParsingUsing Standard Methods.
COMPLEX '92, Budapest,pp.
61-70.Boitet C. & al (1998), Processing of French in the UNLProject (Year 1).
Final Report, The United NationsUniversity and L'Univeristd J. Fourrier, Grenoble,216 p.Byrd R. & al (1987), Tools and Methods forComputational Lexicology.
ComputationalLinguistics, Vol 13, N ?
3-4, pp.
219-240.Doan-Nguyen H. (1996), Transformations in DictionaryResources Accumulation Towards a GenericApproach.
COMPLEX '96, Budapest, pp.
29-38.Dorr B.
& al (1995), From Syntactic Encodings toThematic Roles: Building Lexical Entries forInterlhtgual MT.
Machine Translation 9, pp.
221-250.Mercuk I.
& al (1988), Dictionnaire explicatif etcombinatoire du fran~ais contemporain.
Volume II.Les Presses de rUniversitd e Montrdal, 332 p.Neff M. & Boguraev B.
(1989), Dictionaries, DictionaryGrammars and Dictionary Entry Parsing.
27th AnnualMeeting of the ACL, Vancouver, pp.
91-101.Steele G. (1990).
Common Lisp - The Language.Second Edition.
Digital Press, 1030 p.Tanaka K. & Umemura K. (1994), Construction of aBilingual Dictionary Intermediated by a ThirdLanguage.
COLING '94, Kyoto, pp.
297-303.UNL (1996).
UNL - Universal Networking Language.The United Nations University, 74 p.334
