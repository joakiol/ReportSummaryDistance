Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 99?106,Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005Comparison, Selection and Use of Sentence Alignment Algorithms for NewLanguage PairsAnil Kumar SinghLTRC, IIITGachibowli, HyderabadIndia - 500019anil@research.iiit.netSamar HusainLTRC, IIITGachibowli, HyderabadIndia - 500019s amar@iiit.netAbstractSeveral algorithms are available for sen-tence alignment, but there is a lack ofsystematic evaluation and comparison ofthese algorithms under different condi-tions.
In most cases, the factors whichcan significantly affect the performanceof a sentence alignment algorithm havenot been considered while evaluating.
Wehave used a method for evaluation thatcan give a better estimate about a sen-tence alignment algorithm?s performance,so that the best one can be selected.
Wehave compared four approaches using thismethod.
These have mostly been triedon European language pairs.
We haveevaluated manually-checked and validatedEnglish-Hindi aligned parallel corpora un-der different conditions.
We also suggestsome guidelines on actual alignment.1 IntroductionAligned parallel corpora are collections of pairs ofsentences where one sentence is a translation of theother.
Sentence alignment means identifying whichsentence in the target language (TL) is a translationof which one in the source language (SL).
Such cor-pora are useful for statistical NLP, algorithms basedon unsupervised learning, automatic creation of re-sources, and many other applications.Over the last fifteen years, several algorithms havebeen proposed for sentence alignment.
Their perfor-mance as reported is excellent (in most cases not lessthan 95%, and usually 98 to 99% and above).
Theevaluation is performed in terms of precision, andsometimes also recall.
The figures are given for oneor (less frequently) more corpus sizes.
While thisdoes give an indication of the performance of an al-gorithm, the variation in performance under varyingconditions has not been considered in most cases.Very little information is given about the conditionsunder which evaluation was performed.
This givesthe impression that the algorithm will perform withthe reported precision and recall under all condi-tions.We have tested several algorithms under differ-ent conditions and our results show that the per-formance of a sentence alignment algorithm variessignificantly, depending on the conditions of test-ing.
Based on these results, we propose a methodof evaluation that will give a better estimate of theperformance of a sentence alignment algorithm andwill allow a more meaningful comparison.
Our viewis that unless this is done, it will not be possible topick up the best algorithm for certain set of con-ditions.
Those who want to align parallel corporamay end up picking up a less suitable algorithm fortheir purposes.
We have used the proposed methodfor comparing four algorithms under different con-ditions.
Finally, we also suggest some guidelines forusing these algorithms for actual alignment.2 Sentence Alignment MethodsSentence alignment approaches can be categorizedas based on sentence length, word correspondence,and composite (where more than one approaches arecombined), though other techniques, such as cog-99nate matching (Simard et al, 1992) were also tried.Word correspondence was used by Kay (Kay, 1991;Kay and Roscheisen, 1993).
It was based on the ideathat words which are translations of each other willhave similar distributions in the SL and TL texts.Sentence length methods were based on the intuitionthat the length of a translated sentence is likely to besimilar to that of the source sentence.
Brown, Laiand Mercer (Brown et al, 1991) used word count asthe sentence length, whereas Gale and Church (Galeand Church, 1991) used character count.
Brown, Laiand Mercer assumed prior alignment of paragraphs.Gale and Church relied on some previously alignedsentences as ?anchors?.
Wu (Wu, 1994) also usedlexical cues from corpus-specific bilingual lexiconfor better alignment.Word correspondence was further developed inIBM Model-1 (Brown et al, 1993) for statisticalmachine translation.
Melamed (Melamed, 1996)also used word correspondence in a different (geo-metric correspondence) way for sentence alignment.Simard and Plamondon (Simard and Plamondon,1998) used a composite method in which the firstpass does alignment at the level of characters asin (Church, 1993) (itself based on cognate match-ing) and the second pass uses IBM Model-1, fol-lowing Chen (Chen, 1993).
The method used byMoore (Moore, 2002) also had two passes, the firstone being based on sentence length (word count) andthe second on IBM Model-1.
Composite methodsare used so that different approaches can compli-ment each other.3 Factors in PerformanceAs stated above, the performance of a sentencealignment algorithm depends on some identifiablefactors.
We can even make predictions aboutwhether the performance will increase or decrease.However, as the results given later show, the algo-rithms don?t always behave in a predictable way.
Forexample, one of the algorithms did worse rather thanbetter on an ?easier?
corpus.
This variation in perfor-mance is quite significant and it cannot be ignoredfor actual alignment (table-1).
Some of these factorshave been indicated in earlier papers, but these werenot taken into account while evaluating, nor weretheir effects studied.Translation of a text can be fairly literal or it canbe a recreation, with a whole range between thesetwo extremes.
Paragraphs and/or sentences can bedropped or added.
In actual corpora, there can evenbe noise (sentences which are not translations at alland may not even be part of the actual text).
This canhappen due to fact that the texts have been extractedfrom some other format such as web pages.
Whiletranslating, sentences can also be merged or split.Thus, the SL and TL corpora may differ in size.All these factors affect the performance of an al-gorithm in terms of, say, precision, recall and F-measure.
For example, we can expect the perfor-mance to worsen if there is an increase in additions,deletions, or noise.
And if the texts were translatedfairly literally, statistical algorithms are likely to per-form better.
However, our results show that this doesnot happen for all the algorithms.The linguistic distance between SL and TL canalso play a role in performance.
The simplest mea-sure of this distance is in terms of the distance onthe family tree model.
Other measures could be thenumber of cognate words or some measure basedon syntactic features.
For our purposes, it may notbe necessary to have a quantitative measure of lin-guistic distance.
The important point is that for lan-guages that are distant, some algorithms may notperform too well, if they rely on some closeness be-tween languages.
For example, an algorithm basedon cognates is likely to work better for English-French or English-German than for English-Hindi,because there are fewer cognates for English-Hindi.It won?t be without a basis to say that Hindi ismore distant from English than is German.
Englishand German belong to the Indo-Germanic branchwhereas Hindi belongs to the Indo-Aryan branch.There are many more cognates between English andGerman than between English and Hindi.
Similarly,as compared to French, Hindi is also distant fromEnglish in terms of morphology.
The vibhaktis ofHindi can adversely affect the performance of sen-tence length (especially word count) as well as wordcorrespondence based algorithms.
From the syntac-tic point of view, Hindi is a comparatively free wordorder language, but with a preference for the SOV(subject-object-verb) order, whereas English is moreof a fixed word order and SVO type language.
Forsentence length and IBM model-1 based sentence100alignment, this doesn?t matter since they don?t takethe word order into account.
However, Melamed?salgorithm (Melamed, 1996), though it allows ?non-monotonic chains?
(thus taking care of some differ-ence in word order), is somewhat sensitive to theword order.
As Melamed states, how it will farewith languages with more word variation than En-glish and French is an open question.Another aspect of the performance which may notseem important from NLP-research point of view, isits speed.
Someone who has to use these algorithmsfor actual alignment of large corpora (say, more than1000 sentences) will have to realize the importanceof speed.
Any algorithm which does worse thanO(n) is bound to create problems for large sizes.
Ob-viously, an algorithm that can align 5000 sentencesin 1 hour is preferable to the one which takes threedays, even if the latter is marginally more accurate.Similarly, the one which takes 2 minutes for 100 sen-tences, but 16 minutes for 200 sentences will be dif-ficult to use for practical purposes.
Actual corporamay be as large as a million sentences.
As an esti-mate of the speed, we also give the runtimes for thevarious runs of all the four algorithms tested.Some algorithms, like those based on cognatematching, may even be sensitive to the encoding ornotation used for the text.
One of the algorithmstested (Melamed, 1996) gave worse performancewhen we used a notation called ITRANS for theHindi text, instead of the WX-notation.14 Evaluation in Previous WorkThere have been attempts to systematically evaluateand compare word alignment algorithms (Och andNey, 2003) but, surprisingly, there has been a lack ofsuch evaluation for sentence alignment algorithms.One obvious problem is the lack of manually alignedand checked parallel corpora.Two cases where a systematic evaluation was per-formed are the ARCADE project (Langlais et al,1996) and Simard et al (Simard et al, 1992).
In theARCADE project, six alignment systems were eval-uated on several different text types.
Simard et alperformed an evaluation on several corpus types and1In this notation, capitalization roughly means aspiration forconsonants and longer length for vowels.
In addition, ?w?
rep-resents ?t?
as in French entre and ?x?
means something similarto ?d?
in French de, hence the name of the notation.corpus sizes.
They, also compared the performanceof several (till then known) algorithms.In most of the other cases, evaluation was per-formed on only one corpus type and one corpus size.In some cases, certain other factors were considered,but not very systematically.
In other words, therewasn?t an attempt to study the effect of various fac-tors described earlier on the performance.
In somecases, the size used for testing was too small.
Oneother detail is that size was sometimes mentioned interms of number of words, not number of sentences.5 Evaluation MeasuresWe have used local (for each run) as well as global(over all the runs) measures of performance of analgorithm.
These measures are:?
Precision (local and global)?
Recall (local and global)?
F-measure (local and global)?
95% Confidence interval of F-measure (global)?
Runtime (local)6 An Evaluation SchemeUnless sentence alignment is correct, everythingelse that uses aligned parallel corpora, such as wordalignment (for automatically creating bilingual dic-tionaries) or statistical machine translation will beless reliable.
Therefore, it is important that the bestalgorithm is selected for sentence alignment.
Thisrequires that there should be a way to systemati-cally evaluate and compare sentence alignment al-gorithms.To take into account the above mentioned factors,we used an evaluation scheme which can give anestimate of the performance under different condi-tions.
Under this scheme, we calculate the measuresgiven in the previous section along the following di-mensions:?
Corpus type?
Corpus size?
Difference in sizes of SL and TL corpora?
Noise101We are also considering the corpus size as a factorin performance because the second pass in Moore?salgorithm is based on IBM Model-1, which needstraining.
This training is provided at runtime by us-ing the tentative alignments obtained from the firstpass (a kind of unsupervised learning).
This meansthat larger corpus sizes (enough training data) arelikely to make word correspondence more effective.Even for sentence length methods, corpus size mayplay a role because they are based on the distributionof the length variable.
The distribution assumption(whether Gaussian or Poisson) is likely to be morevalid for larger corpus sizes.The following algorithms/approaches were evalu-ated:?
Brn: Brown?s sentence length (word count)based method, but with Poisson distribution?
GC: Church and Gale?s sentence length (char-acter count) based method, but with Poissondistribution?
Mmd: Melamed?s geometric correspondencebased method?
Mre: Moore?s two-pass method (word countplus word correspondence)For Brn and GC we used our own implemen-tations.
For Mmd we used the GMA alignmenttool and for Mre we used Moore?s implementation.Only 1-to-1 mappings were extracted from the out-put for calculating precision, recall and F-measure,since the test sets had only 1-to-1 alignments.
En-glish and Hindi stop lists and a bilingual lexiconwere also supplied to the GMA tool.
The parame-ter settings for this tool were kept the same as forEnglish-Malay.
For Brn and GC, the search methodwas based on the one used by Moore, i.e., searchingwithin a growing diagonal band.
Using this searchmethod meant that no prior segmentation of the cor-pora was needed (Moore, 2002), either in termsof aligned paragraphs (Gale and Church, 1991), orsome aligned sentences as anchors (Brown et al,1991).We would have liked to study the effect of linguis-tic distance more systematically, but we couldn?t getequivalent manually-checked aligned parallel cor-pora for other pairs of languages.
We have to relyon the reported results for other language pairs, butthose results, as mentioned before, do not mentionthe conditions of testing which we are consideringfor our evaluation and, therefore, cannot be directlycompared to our results for English-Hindi.
Still, wedid an experiment on the English-French test data(447 sentences) for the shared task in NAACL 2003workshop on parallel texts (see table-1).For all our experiments, the text in Hindi was inWX-notation.In the following sub-sections we describe the de-tails of the data sets that were prepared to study thevariation in performance due to various factors.6.1 Corpus TypeThree different types of corpora were used for thesame language pair (English-Hindi) and size.
Thesewere EMILLE, ERDC and India Today.
We took2500 sentences from each of these, as this was thesize of the smallest corpus.6.1.1 EMILLEEMILLE corpus was constructed by the EMILLEproject (Enabling Minority Language Engineering),Lancaster University, UK, and the Central Instituteof Indian Languages (CIIL), Mysore, India.
It con-sists of monolingual, parallel and annotated corporafor fourteen South Asian languages.
The parallelcorpus part has a text (200000 words) in English andits translations in Hindi, Bengali, Punjabi, Gujaratiand Urdu.
The text is from many different domainslike education, legal, health, social, and consumermarkets.
The documents are mostly in simple, for-mal language.
The translations are quite literal and,therefore, we expected this corpus to be the ?easiest?.6.1.2 ERDCThe ERDC corpus was prepared by ElectronicResearch and Development Centre, NOIDA, India.It also has text in different domains but it is an un-aligned parallel corpus.
A project is going on to pre-pare an aligned and manually checked version of thiscorpus.
We have used a part of it that has alreadybeen aligned and manually checked.
It was our opin-ion that the translations in this corpus are less literaland should be more difficult for sentence alignmentthan EMILLE.
We used this corpus for studying theeffect of corpus size, in addition to corpus type.102Table 1: Results for Various Corpus Types (Corpus Size = 2500)Clean, Same Size Noisy, Same Size Noisy, Different SizeType Brn GC Mmd Mre Brn GC Mmd Mre Brn GC Mmd MreEMILLE P 99.3 99.1 85.0 66.8 85.5 87.4 38.2 66.2 87.2 86.5 48.0 65.5R 96.0 93.0 80.0 63.2 80.4 80.0 36.2 58.0 81.2 79.1 46.5 57.4F 97.6 96.0 82.0 64.9 82.8 83.5 37.2 61.8 84.0 82.6 47.3 61.2T 23 23 261 45 47 44 363 64 25 25 413 47ERDC P 99.6 99.5 94.2 100.0 85.4 84.4 48.0 96.5 84.6 85.5 50.9 97.7R 99.0 99.1 92.7 97.0 81.7 80.6 46.7 78.9 80.5 81.3 49.8 79.1F 99.3 99.3 93.4 98.4 83.5 82.4 47.3 86.8 82.5 83.3 50.3 87.1T 31 29 1024 85 92 90 2268 124 55 52 3172 101India P 91.8 93.9 76.4 99.5 71.5 76.7 49.7 94.4 73.6 75.5 51.7 93.4Today R 81.0 83.0 70.6 81.5 61.0 65.5 47.6 67.5 62.4 64.4 50.1 62.6F 86.1 88.1 73.4 89.6 65.8 70.7 48.6 78.7 67.6 69.5 50.9 75.0T 32 32 755 91 96 101 2120 159 60 68 987 134English- P 100.0 100.0 100.0 100.0 87.4 87.5 77.2 95.2 91.2 93.3 77.7 96.6French R 100.0 99.3 100.0 99.3 85.5 84.3 81.7 84.6 83.2 83.7 82.6 83.0P: Precision, R: Recall, F: F-Measure, T: Runtime (seconds)6.1.3 India TodayIndia Today is a magazine published in both En-glish and Hindi.
We used some parallel text col-lected from the Internet versions of this magazine.
Itconsists of news reports or articles which appearedin both languages.
We expected this corpus to be themost difficult because the translations are often morelike adaptations.
They may even be rewritings of theEnglish reports or articles in Hindi.
This corpus had2500 sentences.6.2 Corpus SizeTo study the effect of corpus size, the sizes usedwere 500, 1000, 5000 and 10000.
All these data setswere from ERDC corpus (which was expected to beneither very easy nor very difficult).6.3 Noise and Difference in Sizes of SL and TLCorporaTo see the effect of noise and the difference in sizesof SL and TL corpora, we took three cases for eachof the corpus types and sizes:?
Same size without noise?
Same size with noise?
Different size with noiseThree different data sets were prepared for eachcorpus type and for each corpus size.
To obtainsuch data sets from the aligned, manually checkedand validated corpora, we added noise to the cor-pora.
The noise was in the form of sentences fromsome other unrelated corpus.
The number of suchsentences was 10% each of the corpus size in thesecond case and 5% to SL and 15% to the TL in thethird case.
The sentences were added at random po-sitions in the SL and TL corpora and these positionswere recorded so that we could automatically cal-culate precision, recall and F-measure even for datasets with noise, as we did for other data sets.
Thus,each algorithm was tested on (3+4)(3) = 21 data sets.7 A LimitationOne limitation of our work is that we are consideringonly 1-to-1 alignments.
This is partly due to prac-tical constraints, but also because 1-to-1 alignmentsare the ones that can be most easily and directly usedfor linguistic analysis as well as machine learning.Since we had to prepare a large number of datasets of sizes up to 10000 sentences, manual check-ing was a major constraint.
We had four options.The first was to take a raw unaligned corpus andmanually align it.
This option would have allowedconsideration of 1-to-many, many-to-1, or partial103Table 2: Results for Various Corpus SizesClean, Same Size Noisy, Same Size Noisy, Different SizeSize Brn GC Mmd Mre Brn GC Mmd Mre Brn GC Mmd Mre500 P 99.2 99.2 93.9 99.8 75.4 78.2 57.4 94.3 83.5 87.2 45.4 92.4R 98.8 98.8 91.8 95.0 71.0 73.4 56.8 70.0 77.0 80.8 44.8 70.8F 99.0 99.0 92.8 97.3 73.1 75.7 57.1 80.4 80.1 83.9 45.1 80.2T 9 9 126 14 10 10 148 13 10 10 181 141000 P 99.3 99.6 96.4 100.0 84.6 84.6 67.8 96.8 82.2 84.0 47.3 95.1R 98.9 99.4 95.1 96.3 81.4 82.2 68.4 73.7 76.3 78.7 46.1 72.7F 99.1 99.5 95.7 98.1 83.0 83.4 68.1 83.7 79.1 81.2 46.7 82.4T 13 13 278 29 24 23 335 34 15 15 453 305000 P 99.8 99.8 93.2 99.9 88.5 88.6 56.1 98.5 85.9 86.6 57.6 97.8R 99.4 99.5 91.6 98.2 83.2 83.3 54.9 86.0 81.7 81.3 56.7 86.3F 99.6 99.7 92.4 99.1 85.7 85.9 55.4 91.8 83.7 83.9 57.2 91.7T 54 53 3481 186 199 185 5248 274 185 174 3639 27510000 P 99.8 99.9 93.2 100.0 88.0 88.9 59.6 98.5 86.8 88.7 57.2 98.4R 99.4 99.6 91.4 98.6 82.9 83.7 58.9 89.9 81.3 82.8 56.2 89.2F 99.6 99.7 92.3 99.3 85.4 86.2 59.2 94.0 84.0 85.6 56.6 94.0T 102 96 4356 305 370 346 4477 467 345 322 4351 479alignments.
The second option was to pass the textthrough an alignment tool and then manually checkthe output for all kinds of alignment.
The third op-tion was to check only for 1-to-1 alignments fromthis output.
The fourth option was to evaluate onmuch smaller sizes.In terms of time and effort required, there is anorder of difference between the first and the secondand also between the second and the third option.
Itis much easier to manually check the output of analigner for 1-to-1 alignments than to align a corpusfrom the scratch.
We couldn?t afford to use the firsttwo options.
The fourth option was affordable, butwe decided to opt for a more thorough evaluation of1-to-1 alignments, than for evaluation of all kinds ofalignments for smaller sizes.
Thus, our starting datasets had only 1-to-1 alignments.In future, we might extend the evaluation to allkinds of alignments, since the manual alignmentcurrently being done on ERDC corpus includes par-tial and 1-to-2 or 2-to-1 alignments.
Incidentally,there are rarely any 2-to-1 alignments in English-Hindi corpus since two English sentences are rarelycombined into one Hindi sentence (when translatingfrom English to Hindi), whereas the reverse is quitepossible.8 Evaluation ResultsThe results for various corpus types are given intable-1, for corpus sizes in table-2, and the globalmeasures in table-3.
Among the four algorithmstested, Moore?s (Mre) gives the best results (ex-cept for the EMILLE corpus).
This is as expected,since Mre combines sentence length based methodwith word correspondence.
The results for Mmd arethe worst, but it should be noted that the results forMmd reported in this paper may not be the best thatcan be obtained with it, because its performance de-pends on some parameters.
Perhaps with better tun-ing for English-Hindi, it might perform better.
An-other expected outcome is that the results for GC(character count) are better than Brn (word count).One reason for this is that there are more of charac-ters than words (Gale and Church, 1991).Leaving aside the tuning aspect, the low perfor-mance of Mmd may be due to the fact that it relieson cognate matching, and there are fewer cognatesbetween Hindi and English.
It might also be due tothe syntactic differences (word order) between Hindiand English.
This could, perhaps be taken care ofby increasing the maximum point dispersal thresh-old (relaxing the linearity constraint), as suggestedby Melamed (Melamed, 1996).104The results of experiment on English-French(table-1) show that Mmd performs better for thislanguage pair than for English-Hindi, but it stillseems to be more sensitive to noise than the otherthree algorithms.
Mre performed the best forEnglish-French too.With respect to speed, Brn and GC are the fastest,Mre is marginally slower, and Mmd is much slower.The effects of the previously mentioned factors onperformance have been summarized below.8.1 Corpus TypeBrn, GC, and Mmd performed almost equally wellfor EMILLE and ERDC corpora, but not that wellfor India Today.
However, surprisingly, Mre per-formed much worse for EMILLE than it did forthe other two corpora.
It could be because of thefact that the EMILLE has a lot of very short (1-3words) sentences, and word correspondence (in thesecond pass) may not be that effective for such sen-tences.
The results don?t support our assumptionthat EMILLE is easier than ERDC, but India Todaydoes turn out to be more difficult than the other twofor all the test cases.
This is understandable sincethe translations in this corpus are much less literal.8.2 Corpus SizeOnly in the case of Mre, the performance almostconsistently increased with size.
This is as expectedsince the second pass in Mre needs training fromthe results of the first pass.
The corpus size has to belarge for this training to be effective.
There doesn?tseem to be a clear relationship between size and per-formance for the other three algorithms.8.3 Noise and Difference in Sizes of SL and TLCorporaAs expected, introducing noise led to a decreasein performance for all the algorithms (table-1 andtable-2).
However (barring EMILLE) Mre seems tobecome less sensitive to noise as the corpus size in-creases.
This again could be due to the unsupervisedlearning aspect of Mre.Making the SL and TL corpora differ in sizetended to reduce the performance in most cases, butsometimes the performance marginally improved.Table 3: Global Evaluation MeasuresBrn GC Mmd MreClean, L 92.6 93.4 81.4 80.8Same Size H 100.0 100.0 96.3 100.0P 98.4 98.7 90.3 95.1R 96.1 96.1 87.6 90.0F 97.2 97.3 88.9 92.4Noisy, L 73.1 75.8 44.1 72.6Same Size H 87.5 86.4 62.4 92.3P 82.7 84.1 53.8 92.2R 77.4 78.4 52.8 74.9F 79.8 81.1 53.3 82.5Noisy, L 74.7 76.4 46.2 71.3Different H 85.6 86.4 55.0 92.0Size P 83.4 84.9 51.2 91.5R 77.2 78.3 50.0 74.0F 80.1 81.4 50.6 81.6Overall L 81.1 82.4 55.4 80.0H 90.4 90.8 73.1 91.0P 88.2 89.2 65.1 92.9R 83.6 84.3 63.5 79.6F 85.7 86.6 64.6 85.5L and H: Lower and higher limits of95% confidence interval for F-measureP, R, and F: Average precision,recall, and F-measure9 Some Notes on Actual Corpus AlignmentBased on the evaluation results and our experiencewhile manually checking alignments, we make someobservations below which could be useful to thosewho are planning to create aligned parallel corpora.Contrary to what we believed, sentence lengthbased algorithms turn out to be quite robust, but alsocontrary to the commonly held view, there is scopefor improvement in the performance of these algo-rithms by combining them with other techniques asMoore has done.
However, as the performance ofMre on EMILLE shows, these additional techniquesmight sometimes decrease the performance.There is a tradeoff between precision and recall,just as between robustness and accuracy (Simard andPlamondon, 1998).
If the corpus aligned automati-cally is to be used without manual checking, then weshould opt for maximum precision.
But if it?s goingto be manually checked before being used, then we105should opt for maximum recall.
It depends on theapplication too (Langlais et al, 1996), but if man-ual checking is to be done, we can as well try toget the maximum number of alignments, since somedecrease in precision is not going to make manualchecking much more difficult.If the automatically aligned corpus is not to bechecked manually, it becomes even more importantto perform a systematic evaluation before aligninga corpus, otherwise the parallel corpus will not bereliable either for machine learning or for linguisticanalysis.10 ConclusionWe used a systematic evaluation method for select-ing a sentence alignment algorithm with English andHindi as the language pair.
We tested four algo-rithms for different corpus types and sizes, for thesame and different sizes of SL and TL corpora, aswell as presence and absence of noise.
The evalu-ation scheme we have described can be used for amore meaningful comparison of sentence alignmentalgorithms.
The results of the evaluation show thatthe performance depends on various factors.
The di-rection of this variation (increase or decrease) was aspredicted in most of the cases, but some results wereunexpected.
We also presented some suggestions onusing an algorithm for actual alignment.ReferencesBrown Peter F., Cocke John, Della Pietra StephenA., Della Pietra Vincent J., Jelinek Frederick, Laf-ferty John D., Mercer Robert L., and Roossin Paul S.1990.
A Statistical Approach to Machine Translation.Computational Linguistics.Brown Peter F., Della Pietra Stephen A., Della Pietra Vin-cent J., and Mercer Robert L. 1993.
Mathematicsof Statistical Machine Translation: Parameter Estima-tion.
Computational Linguistics, 19(2):263?311.Brown Peter F., Lai J. C. and Mercer Robert L. 1991.Aligning Sentences in Parallel Corpora.
Proceedingsof 29th Annual Meeting of the Association for Compu-tational Linguistics, 169?176.
Berkeley, CA.Chen Stanley F. 1993.
Aligning Sentences in BilingualCorpora Using Lexical Information.
Proceedings ofthe 31st Annual Meeting of the Association for Com-putational Linguistics, 9?16.
Columbus, OH.Church Kenneth W. 1993.
Char align: A Program forAligning Parallel Texts at the Character Level.
Pro-ceedings of the 31st Annual Meeting of the Associationfor Computational Linguistics, 1?8.
Columbus, OH.Church Kenneth W. and Hanks Patrick.
1993b.
AligningParallel Texts: Do Methods Developed for English-French Generalize to Asian Languages?.
Proceedingsof Rocling.Gale William A. and Church Kenneth W. 1991.
AProgram for Aligning Sentences in Bilingual Corpora.Proceedings of 29th Annual Meeting of the Associa-tion for Computational Linguistics, 177?184.
Berke-ley, CA.Kay Martin.
1991.
Text-Translation Alignment.ACH/ALLC ?91: ?Making Connections?
ConferenceHandbook.
Tempe, Arizona.Kay Martin and Roscheisen Martin.
1993.
Text-Translation Alignment.
Computational Linguistics,19(1):121?142.Langlais Phillippe, Simard Michel, and Vronis Jean.1996.
Methods and Practical Issues in Evaluat-ing Alignment Techniques.
Proceedings of 16th In-ternational Conference on Computational Linguistics(COLING-96).Melamed I. Dan.
1996.
A Geometric Approach to Map-ping Bitext Correspondence.
IRCS Technical Report,University of Pennsylvania, 96?22.Moore Robert C. 2002.
Fast and Accurate SentenceAlignment of Bilingual Corpora.
Proceedings ofAMTA, 135?144.Och Franz Joseph and Ney Hermann 2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, 29(1):19-51.Simard Michel, Foster George F., and Isabelle Pierre.1992 Using Cognates to Align Sentences in Bilin-gual Corpora.
Proceedings of the Fourth InternationalConference on Theoretical and Methodological Issuesin Machine Translation.
Montreal, Canada.Simard Michel and Plamondon Pierre.
1998 BilingualSentence Alignment: Balancing Robustness and Ac-curacy.
Machine Translation, 13(1):59?80.Wu Dekai.
1994.
Aligning a Parallel English-ChineseCorpus Statistically with Lexical Criteria.
Proceed-ings of 32nd Annual Meeting of the Association forComputational Linguistics, 80?87.
Las Cruces, NM.106
