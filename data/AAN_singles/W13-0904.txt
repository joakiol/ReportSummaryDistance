Proceedings of the First Workshop on Metaphor in NLP, pages 27?35,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsSemantic Signatures for Example-Based Linguistic Metaphor DetectionMichael Mohler and David Bracewell and David Hinote and Marc TomlinsonLanguage Computer Corp.Richardson, Texas, USA{michael,david,dhinote,marc}@languagecomputer.comAbstractMetaphor is a pervasive feature of human lan-guage that enables us to conceptualize andcommunicate abstract concepts using moreconcrete terminology.
Unfortunately, it isalso a feature that serves to confound a com-puter?s ability to comprehend natural humanlanguage.
We present a method to detectlinguistic metaphors by inducing a domain-aware semantic signature for a given text andcompare this signature against a large indexof known metaphors.
By training a suite ofbinary classifiers using the results of severalsemantic signature-based rankings of the in-dex, we are able to detect linguistic metaphorsin unstructured text at a significantly higherprecision as compared to several baseline ap-proaches.1 IntroductionMetaphor is a widely-used literary mechanismwhich allows for the comparison of seemingly un-related concepts.
It has been thoroughly studied inboth the linguistics literature (Ahrens et al 2003;Lakoff and Johnson, 1980; Tourangeau and Stern-berg, 1982; Wilks, 1978) and more recently withinthe field of computational linguistics.1 Althoughthere have been many influential theories regardingthe cognitive basis of metaphor, the most promi-nent among them is Lakoff?s Contemporary The-ory of Metaphor (Lakoff and Johnson, 1980; Lakoff,1993), which popularized the idea of a conceptual1For a broad survey of the relevant literature, see Shutova(2010).metaphor mapping.
Within the cognitive frameworkof a given conceptual mapping, terms pertaining toone concept or domain (the source) can be used fig-uratively to express some aspect of another conceptor domain (the target).
For example, the conceptualmetaphor ?Life is a Journey?
indicates a mediumwithin which the target concept ?life?
may be moreeasily discussed and understood.
This particularmapping allows us to speak of one being stuck in a?dead-end?
job, a crucial decision as being a ?fork inthe road?, or someone?s life ?taking a wrong turn?.By allowing us to discuss an abstract target con-cept using the vocabulary and world knowledgeassociated with a more familiar source concept,metaphor serves as a vehicle for human communica-tion and understanding, and as such, has been foundto be extremely prevalent in natural language, oc-curring as often as every third sentence (Shutova etal., 2010).
As a consequence of this ubiquity, it iscrucial that any system tasked with the understand-ing of natural language be capable of detecting thepresence of metaphor in text and of modeling theintended semantic content of the metaphoric expres-sion.
In this work, we first induce a domain-sensitivesemantic signature which we define as a set of highlyrelated and interlinked WordNet (Fellbaum, 1998)senses drawn and augmented from a text that maybe used to place the text within the semantic spaceof a metaphoric concept.
We then employ a suiteof binary classifiers to detect metaphoricity withina text by comparing its semantic signature to a setof known metaphors.
If the semantic signature ofthe text closely matches the signature of a knownmetaphor, we propose that it is likely to represent27Example MetaphorObama heard a bomb ticking in his left ear.
NoObama heard another political bomb ticking, this time in his left ear.
YesTable 1: The top sentence describes a literal bomb ticking, while the bottom sentence uses metaphoric language todescribe an impending political disaster.an instance of the same conceptual metaphor.
To fa-cilitate this work, we have built an index of knownmetaphors within a particular target domain.
Wehave selected the domain of Governance which wedefine broadly to include electoral politics, the set-ting and enactment of economic policy, and thecreation, application, and enforcement of rules andlaws.The problem of metaphor as it relates to computerunderstanding is illustrated in the example sentencesof Table 1.
A strictly literal reading suggests that thetwo sentences are describing something very similar.At the very least, the semantics of the phrases ?bombticking?
and ?in his left ear?
are indistinguishablewithout the added knowledge that the second sen-tence is using metaphor to convey information aboutsomething altogether different from explosives andbody parts.
From the context of the full sentences,it is clear that while the first sentence is straight-forwardly describing Obama and his perception ofa literal bomb, the second is describing an impend-ing political crisis as though it were a bomb.
Ratherthan a literal ?ear?
this sentence uses the phrase ?inhis left ear?
to suggest that the source of the crisis inon the political ?left?.
In order for an automated sys-tem to correctly understand the intended meaning ofthese sentences, it must first be aware that the textunder consideration is not to be taken literally, andgiven this knowledge, it must employ all availableknowledge of the underlying conceptual mapping toappropriately interpret the text in context.The remainder of this work is organized as fol-lows.
In Section 2, we survey related work in se-mantic representation and linguistic metaphor iden-tification.
Section 3 describes in detail our approachto metaphor identification through the use of seman-tic signatures.
In Section 4, we discuss the setup ofour experiment which includes the creation of ourmetaphor index as well as the extraction and anno-tation of our training and testing data sets.
Finally,we show the results of our experiments in Section 5and share our conclusions in Section 6.2 Related WorkThe phenomenon of metaphor has been studiedby researchers across multiple disciplines, includ-ing psychology, linguistics, sociology, anthropol-ogy, and computational linguistics.
A number oftheories of metaphor have been proposed, includ-ing the Contemporary Theory of Metaphor (Lakoff,1993), the Conceptual Mapping Model (Ahrens etal., 2003), the Structure Mapping Model (Wolff andGentner, 2000), and the Attribute CategorizationHypothesis (McGlone, 1996).
Based on these the-ories, large collections of metaphors have been as-sembled and published for use by researchers.
TheMaster Metaphor List (MML) (Lakoff, 1994) groupslinguistic metaphors together according to theirconceptual mapping, and the Hamburg MetaphorDatabase (HMD) (Eilts and Lo?nneker, 2002) forFrench and German fuses EuroWordNet synsetswith the MML source and target domains for a ro-bust source of metaphoric semantics in those lan-guages.In recent years, the computational linguisticscommunity has seen substantial activity in the de-tection of figurative language (Bogdanova, 2010;Li and Sporleder, 2010; Peters and Wilks, 2003;Shutova, 2011) one aspect of which is the iden-tification of metaphoric expressions in text (Fass,1991; Shutova et al 2010; Mason, 2004).
Much ofthe early work on the identification of metaphor re-lied upon hand-crafted world knowledge.
The met*(Fass, 1991) system sought to determine whether anexpression was literal or figurative by detecting theviolation of selectional preferences.
Figurative ex-pressions were then classified as either metonymic,using hand-crafted patterns, or metaphoric, us-ing a manually constructed database of analogies.The CorMet (Mason, 2004) system determined the28source and target concepts of a metaphoric expres-sion using domain-specific selectional preferencesmined from Internet resources.
More recent workhas examined noun-verb clustering (Shutova et al2010) which starts from a small seed set of one-word metaphors and results in clusters that rep-resent source and target concepts connected via ametaphoric relation.
These clusters are then used toannotate the metaphoricity of text.Similar to our work, the Metaphor Interpreta-tion, Denotation, and Acquisition System (MIDAS)(Martin, 1990) employed a database of conventionalmetaphors that could be searched to find a matchfor a metaphor discovered in text.
If no matchwas found, the metaphoric text was replaced with amore abstract equivalent (e.g.
a hypernym) and thedatabase was searched again.
If a match was found,an interpretation mapping was activated, and thenovel metaphor would be added to the database foruse in future encounters.
Unfortunately, this tech-nique was limited to interpreting known metaphors(and descendants of known metaphors) and was un-able to detect truly novel usages.
By expanding themetaphors using a more robust semantic signature,we attempt to transcend this limitation thereby pro-ducing a more durable system for metaphoric exam-ple linking.An additional vein of metaphor research hassought to model the human processing of metaphoras a semantic space within which source and tar-get concepts can be placed such that the similar-ity between their representations within this space(i.e.
semantic vectors) can be sensibly quantified(Katz, 1992; Utsumi, 2011).
One computationalexample of this approach (Kintsch, 2000) has em-ployed latent semantic analysis (LSA) (Landauerand Dumais, 1997) to represent the semantic spaceof the metaphors in a reduced dimensionality (i.e.using singular value decomposition).
In their ap-proach, metaphors were represented as a set of termsfound using a spreading activation algorithm in-formed by the terms?
independent vector related-ness to the source and target concepts within someLSA space.
By contrast, we have chosen to rep-resent the metaphoric space using WordNet senseswhich have been shown in previous work(Lo?nneker,2003) to represent a viable representation languagefor metaphor.
We believe that the ontological knowl-edge encoded in the semantic relationships of Word-Net represents an improvement over the distribu-tional relatedness encoded within an LSA vector.Also of relevance to the construction and use ofsemantic signatures is current research on the induc-tion of topic signatures.
A topic signature is a set ofrelated words with associated weights which defineand indicate the distinct topics within a text.
In theirwork on automated summarization, Lin and Hovy(2000) developed a method for the construction oftopic signatures which were mined from a large cor-pus.
Similarly, Harabagiu and Lacatusu (2005) ex-plored the use of topic signatures and enhanced topicsignatures for their work on multi-document sum-marization.
By contrast, we explore the use of se-mantic signatures which serve to enrich the seman-tics of the source and target frame concepts beingexpressed in a text for the purpose of detecting thepresence of metaphor.3 MethodologyIn this work, we approach the task of linguis-tic metaphor detection as a classification problem.Starting from a known target domain (i.e.
Gover-nance), we first produce a target domain signaturewhich represents the target-specific dimensions ofthe full conceptual space.
Using this domain sig-nature, we are able to separate the individual termsof a sentence into source frame elements and tar-get frame elements and to independently perform asemantic expansion for each set of elements usingWordNet and Wikipedia as described in our earlierwork (Bracewell et al 2013).
Taken together, thesemantic expansions of a text?s source frame ele-ments and target frame elements make up the full se-mantic signature of the text which can then be com-pared to an index of semantic signatures generatedfor a collection of manually detected metaphors.
Weuse as features for our classifiers a set of metrics thatare able to quantify the similarity between the givensemantic signature and the signatures of metaphorsfound within the index.3.1 Constructing a Target Domain SignatureIn order to produce a semantic representation of thetext, we first build a target domain signature, whichwe define as a set of highly related and interlinked29Figure 1: Focused crawling of Wikipedia articles pertaining to the target concept using intra-wiki linksFigure 2: Constructing the domain signature of the target concept from Wikipedia articles pertaining to the targetconceptWordNet senses that correspond to our particulartarget domain with statistical reliability.
For ex-ample, in the domain of Governance the conceptsof ?law?, ?government?, and ?administrator?, alongwith their associated senses in WordNet, are presentin the domain signature.
We generate this signa-ture using semantic knowledge encoded in the fol-lowing resources: (1) the semantic network encodedin WordNet; (2) the semantic structure implicit inWikipedia; and (3) collocation statistics taken fromthe statistical analysis of a large corpora.
In par-ticular, we use Wikipedia as an important sourceof world knowledge which is capable of provid-ing information about concepts, such as named en-tities, that are not found in WordNet as shown inseveral recent studies (Toral et al 2009; Niemannand Gurevych, 2011).
For example, the organi-zation ?Bilderberg Group?
is not present in Word-Net, but can easily be found in Wikipedia whereit is listed under such categories as ?Global tradeand professional organizations?, ?International busi-ness?, and ?International non-governmental orga-nizations?.
From these categories we can deter-mine that the ?Bilderberg Group?
is highly relatedto WordNet senses such as ?professional organiza-tion?, ?business?, ?international?, and ?nongovern-mental organization?.We begin our construction of the domain signa-ture by utilizing the semantic markup in Wikipediato collect articles that are highly related to the tar-get concept by searching for the target concept (andoptionally content words making up the definitionof the target concept) in the Wikipedia article titlesand redirects.
These articles then serve as a ?seedset?
for a Wikipedia crawl over the intra-wiki linkspresent in the articles.
By initiating the crawl onthese links, it becomes focused on the particular do-main expressed in the seed articles.
The crawlingprocess continues until either no new articles arefound or a predefined crawl depth (from the set ofseed articles) has been reached.
The process is illus-trated in Figure 1.
The result of the crawl is a setof Wikipedia articles whose domain is related to thetarget concept.
From this set of articles, the domainsignature can be built by exploiting the semantic in-formation provided by WordNet.The process of going from a set of target conceptarticles to a domain signature is illustrated in Fig-ure 2 and begins by associating the terms containedin the gathered Wikipedia articles with all of theirpossible WordNet senses (i.e.
no word sense disam-biguation is performed).
The word senses are thenexpanded using the lexical (e.g.
derivationally re-lated forms) and semantic relations (e.g.
hypernymand hyponym) available in WordNet.
These sensesare then clustered to eliminate irrelevant senses us-ing the graph-based Chinese Whispers algorithm(Biemann, 2006).
We transform our collection ofword senses into a graph by treating each word senseas a vertex of an undirected, fully-connected graphwhere edge weights are taken to be the product ofthe Hirst and St-Onge (1998) WordNet similarity be-30tween the two word senses and the first-order cor-pus cooccurrence of the two terms.
In particular, weuse the normalized pointwise mutual information ascomputed using a web-scale corpus.The clusters resulting from the Chinese Whispersalgorithm contain semantically and topically similarword senses such that the size of a cluster is directlyproportional to the centrality of the concepts withinthe cluster as they pertain to the target domain.
Afterremoving stopwords from the clusters, any clustersbelow a predefined size are removed.
Any clusterwith a low2 average normalized pointwise mutualinformation (npmi) score between the word sensesin the cluster and the word senses in the set of termsrelated to the target are likewise removed.
This setof target-related terms used in calculating the npmiare constructed from the gathered Wikipedia articlesusing TF-IDF (term frequency inverse document fre-quency), where TF is calculated within the gatheredarticles and IDF is calculated using the entire textualcontent of Wikipedia.
After pruning clusters basedon size and score, the set of word senses that remainare taken to be the set of concepts that make up thetarget domain signature.3.2 Building Semantic Signatures forUnstructured TextAfter constructing a signature that defines the do-main of the target concept, it is possible to use thissignature to map a given text (e.g.
a sentence) intoa multidimensional conceptual space which allowsus to compare two texts directly based on their con-ceptual similarity.
This process begins by mappingthe words of the text into WordNet and extractingthe four most frequent senses for each term.
In or-der to improve coverage and to capture entities andterms not found in WordNet, we also map termsto Wikipedia articles based on a statistical measurewhich considers both the text of the article and theintra-wiki links.
The Wikipedia articles are thenmapped back to WordNet senses using the text ofthe categories associated with the article.In the next step, source and target frame ele-ments of a given text are separated using the Word-Net senses contained in the target domain signature.2We define low as being below an empirically definedthreshold, ?
.Terms in the text which have some WordNet sensethat is included in the domain signature are clas-sified as target frame elements while those that donot are considered source frame elements.
Figure 3shows an overview of the process for determiningthe source and target concepts within a text.
Theremainder of the signature induction process is per-formed separately for the source and target frame el-ements.
In both cases, the senses are expanded usingthe lexical and semantic relations encoded in Word-Net, including hypernymy, domain categories, andpertainymy.
Additionally, source frame elementsare expanded using the content words found in theglosses associated with each of the noun and verbsenses.
Taken together, these concepts represent thedimensions of a full conceptual space which can beseparately expressed as the source concept dimen-sions and target concept dimensions of the space.Figure 3: Example of a generated conceptual space for agiven text.
In this work, only one iteration of the senseexpansion is performed.In order to determine the correct senses for in-clusion in the semantic signature of a text, cluster-ing is performed using the same methodology asin the construction of the domain signature.
First,a graph is built from the senses with edge weightsassigned based on WordNet similarity and cooccur-rence.
Then, the Chinese Whispers algorithm is usedto cluster the graph which serves to disambiguate thesenses and to prioritize which senses are examinedand incorporated into the source concept dimensionsof the conceptual space.
Word senses are prioritizedby ranking the clusters based on their size and on thehighest scoring word sense contained in the clusterusing:rank(c) = size(c) ?
(?s score(s)|c|)(1)where c is the cluster, s is a word sense in the clus-31ter, and |c| is the total number of word senses in thecluster.
The senses are scored using: (1) the degreedistribution of the sense in the graph (more centralword senses are given a higher weight); and (2) thelength of the shortest path to the terms appearing inthe given text with concepts closer to the surfaceform given a higher weight.
Formally, score(s) iscalculated as:score(s) =degree(s) + dijkstra(s,R)2(2)where degree(s) is degree distribution of s anddijkstra(s,R) is the length of the shortest path inthe graph between s and some term in the originaltext, R.Clusters containing only one word sense or witha score less than the average cluster score (?c) areignored.
The remaining clusters and senses arethen examined for incorporation into the concep-tual space with senses contained in higher rankedclusters examined first.
Senses are added as con-cepts within the conceptual space when their score isgreater than the average word sense score (?s).
Todecrease redundancy in the dimensions of the con-ceptual space, neighbors of the added word sense inthe graph are excluded from future processing.3.3 ClassificationGiven a semantic signature representing the place-ment of a text within our conceptual space, it is pos-sible to measure the conceptual distance to other sig-natures within the same space.
By mapping a setof known metaphors into this space (using the pro-cess described in Section 3.2), we can estimate thelikelihood that a given text contains some metaphor(within the same target domain) by using the seman-tic signature of the text to find the metaphors withthe most similar signatures and to measure their sim-ilarity with the original signature.We quantify this similarity using five related mea-sures which are described in Table 2.
Each of thesefeatures involves producing a score that ranks ev-ery metaphor in the index based upon the seman-tic signature of the given text in a process similar tothat of traditional information retrieval.
In particu-lar, we use the signature of the text to build a queryagainst which the metaphors can be scored.
For eachword sense included in the semantic signature, weadd a clause to the query which combines the vectorspace model with the Boolean model so as to prefera high overlap of senses without requiring an identi-cal match between the signatures.3Three of the features simply take the score ofthe highest ranked metaphor as returned by a query.Most simply, the feature labeled Max Score (na?
?ve)uses the full semantic signature for the text whichshould serve to detect matches that are very simi-lar in both the source concept dimensions and thetarget concept dimensions.
The features Max Score(source) and Max Score (target) produce the queryusing only the source concept dimensions of thesignature and the target concept dimensions respec-tively.The remaining two features score the metaphorswithin the source dimensions and the target dimen-sions separately before combining the results into ajoint score.
The feature Max Score (joint) calculatesthe product of the scores for each metaphor using thesource- and target-specific queries described aboveand selects the maximum value among these prod-ucts.
The final feature, Joint Count, represents thetotal number of metaphors with a score for both thesource and the target dimensions above some thresh-old (?j).
Unlike the more na?
?ve features for which avery good score in one set of dimensions may incor-rectly lead to a high overall score, these joint similar-ity features explicitly require metaphors to match thesemantic signature of the text within both the sourceand target dimensions simultaneously.Altogether, these five features are used to traina suite of binary classifiers to make a decision onwhether a given text is or is not a metaphor.4 Experimental SetupOne crucial component of our linguistic metaphordetection system is the index of metaphors (in thedomain of Governance) against which we com-pare our candidate texts.
As a part of this project,we have produced an ever-growing, metaphor-richdataset taken from political speeches, political web-sites (e.g.
Communist Party USA, Tea Party sites,3This functionality comes standard with the search function-ality of Apache Lucene which we employ for the production ofour index.32Measure DescriptionMax Score (na?
?ve) Find the score of the metaphor that best matches the full semantic signatureMax Score (source) Find the score of the metaphor that best matches the source side of the semantic signatureMax Score (target) Find the score of the metaphor that best matches the target side of the semantic signatureMax Score (joint)Independently score the metaphors by the target side and by the source side.Find the metaphor with the highest product of the scores.Joint CountIndependently score the metaphors by the target side and by the source side.Count the number of metaphors that receive a positive score for both.Table 2: The five features used by our metaphoricity classifiers.etc.
), and political commentary in web-zines and on-line newspapers.
Three annotators have analyzedthe raw texts and manually selected snippets of text(with context) whenever some element in the textseemed to have been used figuratively to describeor stand in for another element not represented inthe text.4 Each of these metaphors is projected intoa conceptual space using the process described inSection 3.2 and assembled into a searchable index.For evaluation purposes, we have selected a sub-set of our overall repository which consists of500 raw documents that have been inspected formetaphoricity by our annotators.
We allocate 80%of these documents for the training of our classi-fiers and evaluate using the remaining 20%.
In total,our training data consists of 400 documents contain-ing 1,028 positive examples of metaphor and around16,000 negative examples.
Our test set consists of100 documents containing 4,041 sentences with 241positive examples of metaphor and 3,800 negativeexamples.
For each sentence in each document, oursystem attempts to determine whether the sentencedoes or does not contain a metaphor within the do-main of Governance.We have experimented with several flavors of ma-chine learning classification.
In addition to an in-house implementation of a binary maximum en-tropy (MaxEnt) classifier, we have evaluated our re-sults using four separate classifiers from the popu-lar Weka machine learning toolkit.5 These includean unpruned decision tree classifier (J48), a supportvector machine (SMO) approach using a quadratic4Generally speaking, each annotator operated within a re-gion of high precision and low recall, and the overlap betweenindividual annotators was low.
As such, we have selected theunion of all metaphors detected by the annotators.5http://www.cs.waikato.ac.nz/ml/weka/kernel with parameters tuned via grid search, a rule-based approach (JRIP), and a random forest clas-sifier (RF).
In addition, we have combined all fiveclassifiers into an ensemble classifier which uses auniformly-weighted voting methodology to arrive ata final decision.5 ResultsWe have evaluated our methodology in two ways.First, we have performed an evaluation which high-lights the discriminatory capabilities of our featuresby testing on a balanced subset of our test data.Next, we performed an evaluation which shows theutility of each of our classifiers as they are appliedto real world data with a natural skew towards literalusages.6 In both cases, we train on a balanced sub-set of our training data using all 1,028 positive ex-amples and a set of negative examples selected ran-domly such that each document under considerationcontains the same number of positive and negativeexamples.
In an initial experiment, we trained ourclassifiers on the full (skewed) training data, but theresults suggested that an error-minimizing strategywould lead to all sentences being classified as ?lit-eral?.As shown in Table 3, the choice of classifier ap-pears significant.
Several of the classifiers (J48,JRIP, and MaxEnt) maintain a high recall suggest-ing the ability of the tree- and rule-based classifiersto reliably ?filter out?
non-metaphors.
On the otherhand, other classifiers (SMO and ENSEMBLE) op-erate in a mode of high precision suggesting that ahigh confidence can be associated with their positiveclassifications.
In all cases, performance is signifi-6Note that metaphors that are not related to the domain ofGovernance are classified as ?literal?.33Classifier Precision Recall F-MeasureJ48 56.1% 93.0% 70.0%JRIP 57.7% 79.3% 66.8%MaxEnt 59.9% 72.6% 65.7%ENSEMBLE 72.0% 42.7% 53.7%RF 55.8% 47.7% 51.5%SMO 75.0% 33.6% 46.4%All metaphor 50.0% 100.0% 66.7%Random baseline 50.0% 50.0% 50.0%Table 3: The results of our experiments using several ma-chine learning classifiers while evaluating on a datasetwith 241 positive examples and 241 negative examples.cantly better than chance as reported by our randombaseline.7Table 4 shows the result of evaluating the samemodels on an unbalanced dataset with a naturalskew towards ?literal?
sentences which reflects amore realistic use case in the context of linguisticmetaphor detection.
The results suggest that, onceagain, the decision tree classification accepts thevast majority of all metaphors (93%), but also pro-duces a significant number of false positives mak-ing it difficult to usefully employ this classifier asa complete metaphor detection system despite itstop-performing F-measure on the balanced dataset.More useful is the SMO approach, which shows aprecision over twice that of the random baseline.
Putanother way, a positive result from this classifier ismore than 110% more likely to be correct than arandom classification.
From the standpoint of util-ity, joining these classifiers in an ensemble config-uration seems to combine the high precision of theSMO classifier with the improved recall of the otherclassifiers making the ensemble configuration a vi-able choice in a real world scenario.6 ConclusionsWe have shown in this work the potential utilityof our example-based approach to detect metaphorwithin a domain by comparing the semantic signa-ture of a text with a set of known metaphors.
Al-though this technique is necessarily limited by thecoverage of the metaphors in the index, we believethat it is a viable technique for metaphor detection7According to Fisher?s exact test (one-tailed): RF (p <0.02); all others (p < 0.0001).Classifier Precision Recall F-MeasureSMO 12.7% 33.6% 18.4%ENSEMBLE 11.2% 42.7% 17.8%MaxEnt 8.7% 72.6% 15.6%JRIP 8.1% 79.3% 14.8%J48 7.6% 93.0% 14.0%RF 7.4% 47.7% 12.7%All metaphor 6.0% 100.0% 11.3%Random baseline 6.0% 50.0% 10.7%Table 4: The results of our experiments using several ma-chine learning classifiers while evaluating on naturallyskewed dataset with 241 positive examples and 3,800negative examples.as more and more examples become available.
Infuture work, we hope to supplement our existing fea-tures with such information as term imageability, thetransmission of affect, and selectional preference vi-olation we believe will result in a robust system forlinguistic metaphor detection to further aid in thecomputer understanding of natural language.AcknowledgmentsThis research is supported by the Intelligence Ad-vanced Research Projects Activity (IARPA) via De-partment of Defense US Army Research Labora-tory contract number W911NF-12-C-0025.
TheU.S.
Government is authorized to reproduce and dis-tribute reprints for Governmental purposes notwith-standing any copyright annotation thereon.
Dis-claimer: The views and conclusions containedherein are those of the authors and should not beinterpreted as necessarily representing the officialpolicies or endorsements, either expressed or im-plied, of IARPA, DoD/ARL, or the U.S. Govern-ment.
We would also like to thank our annotatorswhose efforts have made this work possible.ReferencesK.
Ahrens, S.F.
Chung, and C. Huang.
2003.
Concep-tual metaphors: Ontology-based representation andcorpora driven mapping principles.
In Proceedingsof the ACL 2003 workshop on Lexicon and figura-tive language-Volume 14, pages 36?42.
Associationfor Computational Linguistics.C.
Biemann.
2006.
Chinese whispers: an efficient graphclustering algorithm and its application to natural lan-34guage processing problems.
In Proceedings of theFirst Workshop on Graph Based Methods for NaturalLanguage Processing, pages 73?80.
Association forComputational Linguistics.D.
Bogdanova.
2010.
A framework for figurative lan-guage detection based on sense differentiation.
In Pro-ceedings of the ACL 2010 Student Research Workshop,pages 67?72.
Association for Computational Linguis-tics.D.
Bracewell, M. Tomlinson, and M. Mohler.
2013.
De-termining the conceptual space of metaphoric expres-sions.
In Computational Linguistics and IntelligentText Processing, pages 487?500.
Springer.C.
Eilts and B.
Lo?nneker.
2002.
The Hamburg MetaphorDatabase.D.
Fass.
1991. met*: A method for discriminatingmetonymy and metaphor by computer.
ComputationalLinguistics, 17(1):49?90.C.
Fellbaum.
1998.
WordNet, An Electronic LexicalDatabase.
The MIT Press.S.
Harabagiu and F. Lacatusu.
2005.
Topic themes formulti-document summarization.
In Proceedings of the28th annual international ACM SIGIR conference onResearch and development in information retrieval,pages 202?209.
ACM.G.
Hirst and D. St-Onge.
1998.
Lexical chains as rep-resentations of context for the detection and correctionof malapropism.
In Christiane Fellbaum, editor, Word-Net: An Electronic Lexical Database, pages 305?332.MIT Press.A.N.
Katz.
1992.
Psychological studies in metaphor pro-cessing: extensions to the placement of terms in se-mantic space.
Poetics Today, pages 607?632.W.
Kintsch.
2000.
Metaphor comprehension: A com-putational theory.
Psychonomic Bulletin & Review,7(2):257?266.G.
Lakoff and M. Johnson.
1980.
Metaphors we live by,volume 111.
Chicago London.G.
Lakoff.
1993.
The contemporary theory of metaphor.Metaphor and thought, 2:202?251.G.
Lakoff.
1994.
Master metaphor list.
University ofCalifornia.T.K.
Landauer and S.T.
Dumais.
1997.
A solution toPlato?s problem: The latent semantic analysis theoryof acquisition, induction, and representation of knowl-edge.
Psychological Review; Psychological Review,104(2):211.L.
Li and C. Sporleder.
2010.
Using gaussian mixturemodels to detect figurative language in context.
In Hu-man Language Technologies: The 2010 Annual Con-ference of the North American Chapter of the Associ-ation for Computational Linguistics, pages 297?300.Association for Computational Linguistics.C.
Lin and E. Hovy.
2000.
The automated acquisi-tion of topic signatures for text summarization.
InProceedings of the 18th conference on Computationallinguistics-Volume 1, pages 495?501.
Association forComputational Linguistics.B.
Lo?nneker.
2003.
Is there a way to represent metaphorsin WordNets?
: insights from the Hamburg MetaphorDatabase.
In Proceedings of the ACL 2003 workshopon Lexicon and figurative language-Volume 14, pages18?27.
Association for Computational Linguistics.J.H.
Martin.
1990.
A computational model of metaphorinterpretation.
Academic Press Professional, Inc.Z.J.
Mason.
2004.
CorMet: A computational, corpus-based conventional metaphor extraction system.
Com-putational Linguistics, 30(1):23?44.M.S.
McGlone.
1996.
Conceptual metaphors and figura-tive language interpretation: Food for thought?
Jour-nal of memory and language, 35(4):544?565.E.
Niemann and I. Gurevych.
2011.
The people?s webmeets linguistic knowledge: Automatic sense align-ment of Wikipedia and WordNet.
In Proceedings ofthe 9th International Conference on ComputationalSemantics (IWCS), pages 205?214.
Citeseer.W.
Peters and Y. Wilks.
2003.
Data-driven detectionof figurative language use in electronic language re-sources.
Metaphor and Symbol, 18(3):161?173.E.
Shutova, L. Sun, and A. Korhonen.
2010.
Metaphoridentification using verb and noun clustering.
InProceedings of the 23rd International Conference onComputational Linguistics, pages 1002?1010.
Associ-ation for Computational Linguistics.E.
Shutova.
2010.
Models of metaphor in NLP.
In Pro-ceedings of the 48th Annual Meeting of the Associationfor Computational Linguistics, pages 688?697.
Asso-ciation for Computational Linguistics.E.V.
Shutova.
2011.
Computational approaches to fig-urative language.
Ph.D. thesis, University of Cam-bridge.S.L.
Toral, M.R.
Mart?
?nez-Torres, F. Barrero, andF.
Corte?s.
2009.
An empirical study of the drivingforces behind online communities.
Internet Research,19(4):378?392.R.
Tourangeau and R.J. Sternberg.
1982.
Understandingand appreciating metaphors.
Cognition, 11(3):203?244.A.
Utsumi.
2011.
Computational exploration ofmetaphor comprehension processes using a semanticspace model.
Cognitive science, 35(2):251?296.Y.
Wilks.
1978.
Making preferences more active.
Artifi-cial Intelligence, 11(3):197?223.P.
Wolff and D. Gentner.
2000.
Evidence for role-neutralinitial processing of metaphors.
Journal of Experi-mental Psychology: Learning, Memory, and Cogni-tion, 26(2):529.35
