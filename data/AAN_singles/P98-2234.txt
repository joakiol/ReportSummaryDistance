Some Properties of Preposition and Subordinate ConjunctionAttachments*Alexander  S. Yeh  and Marc  B. V i la inMITRE Corporation202 Burlington RoadBedford, MA 01730USA{asy, mbv}@mitre.orgphone# +1-781-271-2658Abst rac tDetermining the attachments of prepositionsand subordinate conjunctions is a key prob-lem in parsing natural language.
This paperpresents a trainable approach to making theseattachments hrough transformation sequencesand error-driven learning.
Our approach isbroad coverage, and accounts for roughly threetimes the attachment cases that have previouslybeen handled by corpus-based techniques.
Inaddition, our approach is based on a simplifiedmodel of syntax that is more consistent withthe practice in current state-of-the-art languageprocessing systems.
This paper sketches yntac-tic and algorithmic details, and presents exper-imental results on data sets derived from thePenn Treebank.
We obtain an attachment ac-curacy of 75.4% for the general case, the firstsuch corpus-based result to be reported.
For therestricted cases previously studied with corpus-based methods, our approach yields an accuracycomparable to current work (83.1%).1 In t roduct ionDetermining the attachments of prepositionsand subordinate conjunctions i  an importantproblem in parsing natural anguage.
It is alsoan old problem that continues to elude a com-plete solution.
A classic example of the problemis the sentence "I saw a man with a telescope" ,where who had the telescope is ambiguous.Recently, the preposition attachment prob-lem has been addressed using corpus-basedmethods (Hindle and Rooth, 1993; Ratnaparkhi* This paper eports on work performed at the MITRECorporation under the support of the MITRE Spon-sored Research Program.
Useful advice was providedby Lynette Hirschman and David Palmer.
The exper-iments made use of Morgan Pecelli's noun/verb groupannotations and some of David Day's programs.et al, 1994; Brill and Resnik, 1994; Collins andBrooks, 1995; Merlo et al, 1997).
The presentpaper follows in the path set by these authors,but extends their work in significant ways.
Wemade these extensions to solve this problem ina way that can be directly applied in runningsystems in such application areas as informa-tion extraction or conversational interfaces.In particular, we have sought to produce anattachment decision procedure with far broadercoverage than in earlier approaches.
Most re-search to date has focussed on a subset of theattachment problem that only covers 25% of theproblem instances in our training data, the so-called binary VNP subset.
Even the broaderV\[NP\]* subset addressed by (Merlo et al, 1997)only accounts for 33% of the problem instances.In contrast, our approach attempts to form at-tachments for as much as 89% of the probleminstances (modulo some cases that are eitherpathological or accounted for by other means).Work to date has also been concerned pri-marily with reproducing the structure of Tree-bank annotations.
In other words, the underly-ing syntactic paradigm has been the traditionalnotion of full sentential parsing.
This approachdiffers from the parsing models currently be-ing explored by both theorists and practitioners,which include semi-parsing strategies and finite-state approximations to context-free grammars.Our approach to syntax uses a cascade ofrule sequence processors, each of which can bethought of as approximating some aspect of theunderlying rammar by finite-state transduc-tion.
We have thus had to extend previous workat the conceptual level as well, by recasting thepreposition attachment problem in terms of thevocabulary of finite-state approximations (noungroups, etc.
), rather than the traditional syntac-tic categories (noun phrases, etc.
).1436Much of the present paper is thus concernedwith describing our extensions to the prepo-sition attachment problem.
We present theproblem scope of interest o us, as well as thedata annotations required to support our in-vestigation.
We also present a decision pro-cedure for attaching prepositions and subordi-nate conjunctions.
The procedure is trainedthrough error-driven transformation learning(Brill, 1993), and we present a number oftraining experiments and report on the per-formance of the trained procedure.
In brief,on the restricted VNP problem, our proce-dure achieves nearly the same level of test-setperformance (83.1%) as current state-of-the-artsystems (84.5% (Collins and Brooks, 1995)).On the unrestricted ata set, our procedureachieves an attachment accuracy of 75.4%.2 Syntactic ConsiderationsOur outlook on the attachment problem is in-fluenced by our approach to syntax, which sim-plifies the traditional parsing problem in sev-eral way s .
As with many approaches to pro-cessing unrestricted text, we do not attemptas a primary goal to derive spanning senten-tial parses.
Instead, we approximate spanningparses through successive stages of partial pars-ing.
For the purpose of the present paper, weneed to mostly be concerned with the level ofanalysis of core noun phrases and verb phrases.By core phrases, we mean the kind of non-recursive simplifications of the NP and VP thatin the literature go by names uch as noun/verbgroups (Appelt et al, 1993) or chunks, and baseNPs (Ramshaw and Marcus, 1995).The common thread between these ap-proaches and ours is to approximate full nounphrases or verb phrases by only parsing theirnon-recursive core, and thus not attaching mod-ifiers or arguments.
For English noun phrases,this amounts to roughly the span between thedeterminer and the head noun; for English verbphrases, the span runs roughly from the auxil-iary to the head verb.
We call such simplifiedsyntactic ategories groups, and consider in par-ticular noun, verb, adverb and adjective groups.For noun groups in particular, the definitionwe have adopted also includes a limited num-ber of constructs that encompass some depth-bounded recursion.
For example, we also in-clude in the scope of the noun group such com-plex determiners as partitives ("five of the sus-pects") and possessives ("John's book").
Theseconstructs fall under the scope of our noungroup model because they are easy to parsewith simple finite-state cascades, and becausethey more intuitively match the notion of a corephrase than do their individual components.Our model of noun groups also includes an ex-tension of the so-called named entities familiarto the information extraction community (Def,1995).
These consist of names of persons and or-ganizations, location names, titles, dates, times,and various numeric expressions ( uch as moneyterms).
Note in particular that titles and orga-nization names often include embedded prepo-sitional phrases (e.g., "Chief of Staff").
Forsuch cases, as well as for partitives, we con-sider these embedded prepositional phrases tobe within the noun group's scope, and as suchare excluded from consideration as attachmentproblems.
Also excluded are the auxiliary to'sin verb groups for infinitives.Once again, distinguishing syntax groupsfrom traditional syntactic phrases (such as NPs)is of interest because it singles out what is usu-ally thought of as easy to parse, and allows thatpiece of the parsing problem to be addressed bysuch comparatively simple means as finite-statemachines or transformation sequences.
Whatis then left of the parsing problem is the dif-ficult stuff: namely the attachment of preposi-tional phrases, relative clauses, and other con-structs that serve in modificational, adjunctive,or argument-passing roles.
This part of theproblem is harder both because of the ambigu-ous attachment location, and because the rightcombination of knowledge required to reducethis ambiguity is elusive.3 The  At tachment  P rob lemGiven these syntactic preliminaries, we can nowdefine attachment problems in terms of syn-tax groups.
In addition to noun, verb, adjec-tive and adverb groups, we also have I-groups.An I-group is a preposition (including multipleword prepositions) or subordinate conjunction(including wh-words and "that").
Once againprepositions that are embedded in such con-structs as titles and names are not considered I-groups for our purposes.
Each I-group in a sen-1437tence is viewed as attaching to one other groupwithin that sentence.
1 For example, the sen-tence "I had sent a cup to her."
is viewed as\[I\]ng \[had sent\]vg,~ \[a cup\]ng \[tO\]lg,~, \[her\]ng.where ~ indicates the attaching I-group and ,~indicates the group attached to.Generally, coordinations of groups (e.g., dogsand cats) are left as separate groups.
However,prenominal coordination (e.g.
dog and cat food)is deemed as one large noun group.Attachments not to try: Our system is de-signed to attach each I-group in a sentenceto one other group in the sentence on that I-group's left.
In our sample data, about 11% ofthe I-groups have no left ambiguity (either nogroup on the left to attach to or only 1 group).A few (less than 0.5%) of the I-groups have nogroup to its right.
All of these I-groups countas attachments not handled by our system andour system does not attempt o resolve them.Attachments to try: The rest of the I-groupseach have at least 2 groups on their left and 1group on their right from the I-group's entence,and these are the I-groups that our system triesto handle (89% of all the problems in the data).4 P roper t ies  o f  A t tachments  to  T ryIn order to understand how our technique han-dles the attachments hat follow this pattern, itis helpful to consider the properties of this classof attachments.
What we detail here is a spe-cific analysis of our test data (called 7x9x).
Ourtraining sample is similar.In 7x9x, 2.4% of the attachments turn outto be of a form that guarantees our systemwill fail to resolve them.
83% of these un-resolvable "attachments" are about evenly di-vided between right attachments and left at-tachments to a coordination of groups (which inour framework is split into 2 or more groups).
Aright attachment example is that "at" attachesto "lost" in "that at home, they lost a key."
Acoordination attachment example is "with" at-taching to the coordination "cats and dogs" in"cats and dogs with tags".
The other 17% wereeither lexemes erroneously tagged as preposi-t ions/subordinate conjunctions or past partici-ples, or were wh-words that are actually part1Sentential level attachments are deemed to be to themain verb in the sentence attached to.of a question (and not acting as a subordinateconjunction).In 7x9x, 67.7% of attachments are to the ad-jacent group on the I-group's immediate left.Our system uses as a starting point the guessthat all attachments are to the adjacent group.The second most likely attachment point isthe nearest verb group to the I-group's left.
Asurprising 90.3% of the attachments are to ei-ther this verb group or to the adjacent group.
2In our experiments, limiting the choice of pos-sible attachment points to these two tended toimprove the results and also increased the train-ing speed, the latter often by a factor of 3 to 4.Neither of these percentages include attach-ments to coordinations of groups on the left,which are unhandleable.
Including these attach-ments would add ,,~1% to each figure.The attachments can be divided into six cat-egories, based on the contents of the I-group be-ing attached and the types of groups surround-ing that I-group.
The categories are:vnpn  The I-group contains a preposition.
Nextto the preposition on both the left and theright are noun groups.
Next to the leftnoun group is a verb group.
A memberof this category is the \[to\]~g in the sentence"\[I\],~g \[had sent\]~g \[a cup\]ng \[tO\]/g \[her\]ng.
"vnpf i  Like vnpn,  but next to the prepositionon the right is not a noun group.~npn Like vnpn,  but the left neighbor of theleft noun group is not a verb group.~?npfi Another variation on vnpn.xf ipx The I-group contains a preposition.
Butits left neighbor is not a noun group.
Thex's stand for groups that need to exist, butcan be of any type.xxsx The I-group has a subordinate conjunc-tion (e.g.
which) instead of a preposition.
3Table 1 shows how likely the attachments in7x9x that belong to each category are* to attach to the left adjacent group (A)2This attachment preference also appears in the largedata set used in (Merlo et al, 1997).aA word is deemed a preposition if it is among the 66prepositions li ted in Section 6.2's It data set.
Unlistedwords are deemed subordinate conjunctions.1438?
to attach to either the left adjacent groupor the nearest verb group on the left (V-A)?
to have an attachment that our system ac-tually cannot correctly handle (Err).The table also gives the percentage of the at-tachments in 7x9x that belong in each category(Prevalence).
The A and V-A columns do notinclude attachments o coordinations ofgroups.vnpn 55.6% 97.3% 0.8% 22.8%vnpfi 44.4% 92.6% 0.0% 2.4%9npn 61.4% 85.1% 2.5% 30.7%Vnpfi 37.7% 83.0% 3.8% 2.4%xfipx 85.6% 93.6% 3.3% 28.3%xxsx 74.3% 84.2% 3.3% 13.4%Overall 67.7% 90.3~ 2A% 100%Table 1: Category properties in 7x9xMuch of the corpus-based work on attachingprepositions (Ratnaparkhi et al, 1994; Brill andResnik, 1994; Collins and Brooks, 1995) hasdealt with the subset of category vnpn prob-lems where the preposition actually attaches toeither the nearest verb or noun group on theleft.
Some earlier work (Hindle and Rooth,1993) also handled the subset of vnp5 categoryproblems where the attachment is either to thenearest verb or noun group on the left.Some later work (Merlo et al, 1997) dealtwith handling from 1 to 3 prepositional phrasesin a sentence.
The work dealt with preposi-tions in "group" sequences of VNP, VNPNPand VNPNPNP, where the prepositions attachto one of the mentioned noun or verb groups (asopposed to an earlier group on the left).
So thiswork handles attachments hat can be found inthe vnpn,  vnpn, vnpn and ~np5 categories.Still, this work handles less than an estimated33% of our sample text's attachments.
44(Merlo et al, 1997) searches the Penn Treebank fordata samples that they can handle.
They find phraseswhere 78% of the items to attach belong to either thevnpn or vnp5 categories.
So in Penn Treebank, theyhandle 1.28 times more attachments than the other workmentioned in this paper.
This other work handles lessthan 25% of the attachments in our sample data.5 Processing ModelOur attachment system is an extension of therule-based system for VNPN binary preposi-tional phrase attachment described in (Brill andResnik, 1994).
The system uses transformation-based error-driven learning to automaticallylearn rules from training examples.One first runs the system on a training set,which starts by guessing that each I-group at-taches to its left adjacent group.
This trainingrun moves in iterations, with each iteration pro-ducing the next rule that repairs the most re-maining attachment errors in the training set.The training run ends when the next rule foundrepairs less than a threshold number of errors.The rules are then run in the same order onthe test set (which also starts at an all adjacentattachment s ate) to see how well they do.The system makes its decisions based on thehead (main) word of each of the groups ex-amined.
Like the original system, our systemcan look at the head-word itself and also allthe semantic lasses the head-word can belongto.
The classes come from Wordnet (Miller,1990) and consist of about 25 noun classes(e.g., person, process) and 15 verb classes (e.g.,change, communication, status).
As an exten-sion, our system also looks at the word's part-of-speech, possible stem(s) and possible subcat-egorization/complement categories.
The latterconsist of over 100 categories for nouns, adjec-tives and verbs (mainly the latter) from Comlex(Wolff et al, 1995).
Example categories includeintransitive verbs and verbs that take 2 prepo-sitional phrases as a complement (e.g., fly in "Ifly from here to there.").
In addition, Comlexgives our system the possible prepositions (e.g.from and to for the verb fly) and particles usedin the possible subcategorizations.The original system chose between two possi-ble attachment points, a verb and a noun.
Eachrule either attempted to move left (attach tothe verb) or move right (attach to the noun).Our extensions include as possible attachmentpoints every group that precedes the attachingI-group and is in the I-group's sentence.
Therules now can move the attachment either leftor right from the current guess to the nearestgroup that matches the rule's constraints.In addition to running the training and testwith ALL possible attachment points (every1439preceding group) available, one can also re-strict the possible attachment points to only thegroup Adjacent o the I-group and the nearestVerb group on the left, if any (V-A).
One usesthe same attachment choice (ALL versus V-A)in the training run and corresponding test run.6 Exper iments6.1 Data  preparat ionOur experiments were conducted with datamade available through the Penn Treebank an-notation effort (Marcus et al, 1993).
However,since our grammar model is based on syntaxgroups, not conventional categories, we neededto extend the Treebank annotations to includethe constructs of interest o us.This was accomplished in several steps.
First,noun groups and verb groups were manuallyannotated using Treebank data that had beenstripped of all phrase structure markup.
5 Thissyntax group markup was then reconciled withthe Treebank annotations by a semi-automaticprocedure.
Usually, the procedure just needs tooverlay the syntax group markup on top of theTreebank annotations.
However, the Treebankannotations often had to be adjusted to makethem consistent with the syntax groups (e.g.,verbal auxiliaries need to be included in the rel-evant verb phrase).
Some 4-5% of all Treebanksentences could not be automatically reconciledin this way, and were removed from the datasets for these experiments.The reconciliation procedure also automati-cally tags the data for part-of-speech, using ahigh-performance tagger based on (BriU, 1993).Finally, the reconciler introduces adjective, ad-verb, and I-group markup.
I-groups are createdfor all lexemes tagged with the IN, TO, WDT,WP, WP$ or WRB parts of speech, as well asmulti-word prepositions such as according to.The reconciled data are then compiledinto attachment problems using another semi-automatic pattern-matching procedure.
8% ofthe cases did not fit into the patterns and re-quired manual intervention.We split our data into a training set (files2000, 2013, and 200-269) and a test set (files270-299).
Because manual intervention is timeconsuming, it was only performed on the testset.
The training set (called 0x6x) has 26155We used files 200-299. along with files 2000 and 2013.attachment problems and the test set (called7x9x) has 2252 attachment problems.6.2 P re l iminary  testThe preliminary experiment with our systemcompares it to previous work (Ratnaparkhi etal., 1994; Brill and Resnik, 1994; Collins andBrooks, 1995) when handling VNPN binary PPattachment ambiguity.
In our terms, the taskis to determine the attachment of certain vnpncategory I-groups.
The data originally was usedin (Ratnaparkhi et al, 1994) and was derivedfrom the Penn Treebank Wall St. Journal.It consists of about 21,000 training examples(call this lt, short for large-training) and about3000 test examples.
The format of this datais slightly different than for 0x6x and 7x9x:for each sample, only the 4 mentioned groups(VNPN) are provided, and for each group, thisdata just provides the head-word.
As a result,our part-of-speech tagger could not run on thisdata, so we temporarily adjusted our systemto only consider two part-of-speech categories:numbers for words with just commas, periodsand digits, and non-numbers for all other words.The training used a 3 improvement threshold.With these rules, the percent correct on the testset went from 59.0% (guess all adjacent attach-ments) to 83.1%, an error reduction of 58.9%.This result is just a little behind the currentbest result of 84.5% (Collins and Brooks, 1995)(using a binomial distribution test, the differ-ence is statistically significant at the 2% level).
(Collins and Brooks, 1995) also reports a resultof 81.9% for a word only version of the system(Brill and Resnik, 1994) that we extend (differ-ence with our result is statistically significant atthe 4% level).
So our system is competitive ona known task.6.3 The  main  exper imentsWe made 4 training and test run pairs:mm m lmmm'm m mThe test set was always 7x9x, which starts at67.7% correct.
The results report the numberof RULES the training run produces, as well1440as the percent CORrect and Error Reductionin the test.
One source of variation is whetherALL or the V-A Attachment Points are used.The other source is the TRaining SET used.The set lt- is the set It (Section 6.2) withthe entries from Penn Treebank Wall St. Jour-nal files 270 to 299 (the files used to form thetest set) removed.
About 600 entries were re-moved.
Several adjustments were made whenusing lt-: The part-of-speech treatment in Sec-tion 6.2 was used.
Because It- only gives twopossible attachment points (the adjacent nounand the nearest verb), only V-A  attachmentpoints were used.
Finally, because It- is muchslower to train on than 0x6x, training used a 3improvement threshold.
For 0x6x, a 2 improve-ment threshold was used.Set It2 is the data used in (Merlo et al, 1997)and has about 26000 entries.
The set It2- is theset lt2 with the entries from Penn Treebank files270-299 removed.
Again, about 600 entries wereremoved.
Generally, It2 has no information onthe word(s) to the right of the preposition beingattached, so this field was ignored in both train-ing and test.
In addition, for similar reasons asgiven for lt-,  the adjustments made when usingIt- were also made when using lt2-.If one removes the lt2- results, then all theCOR results are statistically significantly differ-ent from the starting 67.7% score and from eachother at a 1% level or better.
In addition, thelt2- and lt-  results are not statistically signifi-cantly different (even at the 20% level).lt2- has more data points and more cate-gories of data than lt-,  but the lt-  run hasthe best overall score.
Besides pure chance, twoother possible reasons for this somewhat sur-prising result are that the It2- entries have noinformation on the word(s) to the right of thepreposition being attached (lt- does) and bothdatasets contain entries not in the other dataset.When looking at the It- run's remaining er-rors, 43% of the errors were in category Vnpn,21% in vnpn,  16% in xfipx, 13% in xxsx, 4%in ~npfi and 3% in vnpfi.6.4 A f te rwardsThe lt- run has the best overall score.
However,the It- run does not always produce the bestscore for each category.
Below are the scores(number correct) for each run that has a bestscore (bold face) for some category:Category 0x6x V-A lt-- lt2-vnpn 345vnpfi 35~npn 441~Ynpfi 32554 xf ipxXXSX 236397 37439 34454 45829 36551 557229 224The location of most of the best subscores isnot surprising.
Of the training sets, lt- has themost vnpn entries, 6 It2- has the most ~np-type entries and 0x6x has the most xxsx entries.The best vnpfi  and xfipx subscore locations aresomewhat surprising.
The best vnpfi subscoreis statistically significantly better than the It2-vnpfi subscore at the 5% level.
A possible ex-planation is that the vnpfi and vnpn categoriesare closely related.
The best xfipx subscore isnot statistically significantly better than the lt-xfipx subscore, even at the 25% level.
Besidespure chance, a possible explanation is that thexfipx category is related to the four np-typecategories (where lt2- has the most entries).The fact that the subscores for the variouscategories differ according to training regimensuggests a system architecture that would ex-ploit this.
In particular, we might apply dif-ferent rule sets for each attachment category,with each rule set trained in the optimal con-figuration for that category.
We would thusexpect the overall accuracy of the attachmentprocedure to improve overall.
To estimate themagnitude of this improvement, we calculateda post-hoc composite score on our test set bycombining the best subscore for each of the 6categories.
When viewed as trying to improveupon the It- subscores, the new ~npfi subscoreis statistically significantly better (4% level) andthe new xxsx subscore ismildly statistically sig-nificantly better (20% level).
The new ~npnand xfipx subscores are not statistically sig-nificantly better, even at the 25% level.
Thiscombination yields a post-hoc improved scoreof 76.5%.
This is of course only a post-hoc es-timate, and we would need to run a new inde-pendent test to verify the actual validity of thiseffect.
Also, this estimate is only mildly statis-tically significantly better (13% level) than theexisting 75.4% score.6For vnpn,  the l t -  score is statistically significantlybetter than the It2- score at the 2% level.14417 D iscuss ionThis paper presents a system for attachingprepositions and subordinate conjunctions thatjust relies on easy-to-find constructs like noungroups to determine when it is applicable.
Insample text, we find that the system is appli-cable for trying to attach 89% of the preposi-tions/subordinate conjunctions that are outsideof the easy-to-find constructs and is 75.4% cor-rect on the attachments hat it tries to handle.In this sample, we also notice that these attach-ments very much tend to be to only one or twodifferent spots and that the attachment prob-lems can be divided into 6 categories.
One justneeds those easy-to-find constructs to determinethe category of an attachment problem.The 75.4% results may seen low compared toparsing results like the 88% precision and re-call in (Collins, 1997), but those parsing resultsinclude many easier-to-parse constructs.
(Man-ning and Carpenter, 1997) presents the VNPNexample phrase "saw the man with a telescope",where attaching the preposition incorrectly canstill result in 80% (4 of 5) recall, 100% preci-sion and no crossing brackets.
Of the 4 recalledconstructs, 3 are easy-to-parse: 2 correspond tonoun groups and 1 is the parse top level.In our experiments, we found that limitingthe choice of possible attachment points to thetwo most likely ones improved performance.This limiting also lets us use the large train-ing sets lt- and It2-.
In addition, we foundthat different raining data produces rules thatwork better in different categories.
This lat-ter result suggests trying a system architecturewhere each attachment category is handled bythe rule set most suited for that category.In the best overall result, nearly half of theremaining errors occur in one category, ~npn,so this is the category in need of most work.Another topic to examine is how many of theremaining attachment errors actually matter.For instance, when one's interest is on findinga semantic interpretation of the sentence "Theyflash letters on a screen.
", whether on attachesto flash or to letters is irrelevant.
Both the let-ters are, and the flashing occurs, on a screen~ReferencesD.
Appelt, J. Hobbs, J.
Bear, D. Israel, andM.
Tyson.
1993.
Fastus: A finite-state pro-cessor for information extraction.
In 13thIntl.
Conf.
On Artificial Intelligence (IJCAI).E.
Brill and P. Resnik.
1994.
A rule-basedapproach to prepositional phrase attachmentdisambiguation.
In 15th International Conf.on Computational Linguistics (COLING).E.
BriU.
1993.
A Corpus-based Approach toLanguage Learning.
Ph.D. thesis, U. Penn-sylvania.M.
Collins and J. Brooks.
1995.
Preposi-tional phrase attachment through a backed-off model.
In Pwc.
of the 3rd Workshop onVery Large Corpora, Cambridge, MA, USA.M.
Collins.
1997.
Three generative, lexicalizedmodels for statistical parsing.
In A CL97.Defense Advanced Research Projects Agency.1995.
Proc.
6th Message Understanding Con-ference (MUC-6), November.D.
Hindle and M. Rooth.
1993.
Structural am-biguity and lexical relations.
ComputationalLinguistics, 19(1):103-120.C.
Manning and B. Carpenter.
1997.
Prob-abilistic parsing using left corner languagemodels.
In Proc.
of the 5th Intl.
Workshopon Parsing Technologies.M.
Marcus, B. Santorini, and M. Marcinkiewicz.1993.
Building a large annotated corpus ofenglish: the penn treebank.
ComputationalLinguistics, 19(2).P.
Merlo, M. Crocker, and C. Berthouzoz.
1997.Attaching multiple prepositional phrases:Generalized backed-off estimation.
In Proc.of the 2nd Conf.
on Empirical Methods inNatural Language Processing.
ACL.G.
Miller.
1990.
Wordnet: an on-line lexicaldatabase.
Intl.
J. of Lexicography, 3(4).L.
Ramshaw and M. Marcus.
1995.
Text chunk-ing using transformation-based l arning.
InProc.
3rd Workshop on Very Large Corpora.A.
Ratnaparkhi, J. Reynar, and S. Roukos.1994.
A maximum entropy model for prepo-sitional phrase attachment.
In Proc.
of theHuman Language Technology Workshop.
Ad-vanced Research Projects Agency, March.S.
Wolff, C. Macleod, and A. Meyers, 1995.Comlex Word Classes.
C.S.
Dept., New YorkU., Feb. prepared for the Linguistic DataConsortium, U. Pennsylvania.1442
