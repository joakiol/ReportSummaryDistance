Unsupervised All-words Word Sense Disambiguationwith Grammatical DependenciesVivi NastaseEML Research gGmbHHeidelberg, 69118, Germanynastase@eml-research.deAbstractWe present experiments that analyze thenecessity of using a highly interconnectedword/sense graph for unsupervised all-words word sense disambiguation.
We showthat allowing only grammatically relatedwords to influence each other?s senses leadsto disambiguation results on a par with thebest graph-based systems, while greatly re-ducing the computation load.
We also com-pare two methods for computing selectionalpreferences between the senses of every twogrammatically related words: one using aLesk-based measure on WordNet, the otherusing dependency relations from the BritishNational Corpus.
The best configurationuses the syntactically-constrained graph, se-lectional preferences computed from thecorpus and a PageRank tie-breaking algo-rithm.
We especially note good performancewhen disambiguating verbs with grammati-cally constrained links.1 IntroductionIt has long been believed that being able to detectthe correct sense of a word in a given context ?
per-forming word sense disambiguation (WSD) ?
willlead to improved performance of systems tacklinghigh end applications such as machine translation(Chan et al, 2007) and summarization(Elhadad etal., 1997).
In order for WSD methods to be useful,they must be robust, portable, scalable, and there-fore preferably not reliant on manually tagged data.These desiderata have lead to an increased interestin developing unsupervised WSD methods, flexiblerelative to the word sense inventory, and which dis-ambiguate all open-class words in a given context asopposed to a selected few.Particularly appropriate from this point of vieware graph-based methods (Navigli and Lapata,2007), which map the open-class words in a givencontext onto a highly interconnected graph.
Eachnode in this graph represents a word sense, andweighted edges will connect every pair of senses(corresponding to different words).
The topologyof the graph and the weights of the edges can con-tribute in a variety of ways to determine the bestsense combination for the words in the consideredcontext.
This approach leads to large and highlyinterconnected graphs, in which distant, unrelated(in the context) words, are nonetheless connected,and allowed to influence each other?s sense prefer-ences.
We study the impact on disambiguation per-formance when connections are restricted to pairs ofword senses corresponding to words that are gram-matically linked in the considered context.The benefits of using grammatical information forautomatic WSD were first explored by Yarowsky(1995) and Resnik (1996), in unsupervised ap-proaches to disambiguating single words in context.Sussna (1993) presents a first approach to disam-biguating together words within a context.
The fo-cus is on nouns, and the sense combination that min-imizes the overall distance in the WordNet nounsnetwork is chosen.Stetina et al (1998) present the first approach, su-pervised, to disambiguating all words in a sentencewith sense association (or selectional) preferencescomputed from a sense-tagged corpus.
An untaggedgrammatically linked word pair will have associateda matrix of sense combination scores, based on theanalyzed sense-tagged corpus, and similarities be-tween the current words and those in tagged pairswith the same grammatical relation.
Once such ma-trices are computed for all grammatically relatedword pairs, the sense preferences are propagatedfrom the bottom of the parse tree towards the top,and the sense selection starts from the top and prop-agates downward.McCarthy and Carroll (2003) also use an unsuper-vised approach and grammatical relations to learnselectional preferences for word classes.
In an ap-proach inspired by the works of Li and Abe (1998)and Clark and Weir (2002), McCarthy and Carrolluse grammatically connected words from a corpusto induce a distribution of senses over subtrees inthe WordNet hierarchy.
McCarthy et al (2004) usea corpus and word similarities to induce a ranking ofword senses from an untagged corpus to be used inWSD.We build upon this previous research, and pro-pose an unsupervised WSD method in which sensesfor two grammatically related words in the sentencewill be connected through directed edges.
We ex-periment with graph edge weights computed usingWordNet, and weights computed using grammati-cal collocation information from a corpus.
These757weights are used to induce an initial scoring of thegraph vertices, starting from the leaves and propa-gating upwards.
The disambiguation process startswith choosing a sense for the head of the sentence,and moves towards the leaves, propagating down-ward the chosen senses at each step, and using theedge weights and vertex scores to guide the senseselection process.We investigate two issues: (i) whether using indisambiguation only syntactically connected wordsleads to results on a par with, or better than, using allword-sense combinations, (ii) whether sense associ-ation strength induced from a sense-unlabeled cor-pus can rival relatedness measures induced from alexical resource - in our case, WordNet.We evaluate this approach on the Senseval-2(Palmer et al, 2001) and Senseval-3(Snyder andPalmer, 2004) English all-words test data.
On theSenseval-2 data we obtain results on a par with thebest unsupervised WSD systems, on the Senseval-3 data, the results are lower overall, but for verbshigher than those obtained with other graph-basedmethods.
In both situations, using only grammat-ically motivated edges leads to improved disam-biguation of verbs compared to disambiguating ina graph with unrestricted connections.2 Disambiguation AlgorithmThe disambiguation method described here usesgrammatical information from the sentential contextto constrain word pairs that are allowed to influenceeach other?s sense choice.
Edge weights in the graphare relatedness scores computed based on WordNetand, in a second set-up, selectional preferences esti-mated from an (sense-)untagged corpus, for disam-biguating together all words in the sentence.
Gram-matical information for the sentential context is ob-tained using the dependency relation output of theStanford Parser (de Marneffe et al, 2006).
Selec-tional preferences are estimated using grammaticalcollocation information from the British NationalCorpus (BNC), obtained with the Word Sketch En-gine (WSE) (Kilgarriff et al, 2004).2.1 Extracting grammatical relationinformationWe parse the Senseval test data using the StanfordParser(Klein and Manning, 2003) generating theoutput in dependency relation format (de Marneffeet al, 2006).
Edges that do not connect open-classwords are filtered out, words are lemmatized, and wereintroduce the copula (it is bypassed as a predicate)because the verb be must be disambiguated as well.To estimate selectional preferences from a sense-untagged corpus, for each grammatically related pairof words in a sentence we extract evidence consist-Dependency relation WSE relationnsubj(verb,noun) subject(verb,noun)subject of(noun,verb)dobj(verb,noun) object(verb,noun)object of(noun,verb)amod(noun,adj) a modifier(noun,adj)modifies(adj,noun)nn(noun1,noun2) n modifier(noun1,noun2)modifies(noun2,noun1)prep of(verb,noun) pp of(verb,noun)pp-obj of(noun,verb)Table 1: Mapping of grammatical relations from the StanfordParser onto the WSE relation set ?
a sample.ing of pairs with the same grammatical relation andeither the same head or dependent, using the WordSketch Engine.
To obtain such pairs we map thegrammatical relations used by the Stanford Parseronto the set of grammatical relations used by theWSE.
Table 1 shows a sample of this mapping.
Wedenote by GR?1 the inverse of grammatical relationGR ?
for example subject of is the inverse of sub-ject.The result of this processing is illustrated inFigure 1, for the following sentence from theSenseval2 test data:The art of change-ringing is peculiar to the English,and, like most English peculiarities, unintelligible to the rest ofthe world.pp_likepp?obj_likeadj_comp_of peculiaritymosta_modifierEnglishmodifiesa_modifiermodifiesunintelligibleworldpp_ofpp_to pp?obj_topp?obj_ofrestsubjectsubject_ofadj_compbeEnglishpp?obj_topp_toadj_comp_ofadj_comppeculiarartchange?ringingpp_ofpp?obj_ofFigure 1: Dependency graph with grammatical relationsmapped onto the WSE setThe dependency between two connected wordsis represented by two asymmetric grammatical re-lations.2.2 Computing sense selectional preferencescoresThe selectional preference scores can be computedusing the lexical resource that provides the inventoryof senses, or using a corpus.Sense-selectional preferences based on depen-dency relations in a corpus For each pair ofwords in a grammatical relation (w1, w2, GR) froma sentence, we compute a score for each sense siw2of w2, that shows the strength of the association758between siw2 and w1.
The strength of the associ-ation will come from collocation information fromthe BNC, combined with sense similarity or related-ness between siw2 and collocates of w1 in grammat-ical relation GR.Let us take an example ?
(rest,world,pp of) fromthe example sentence presented before.
We want toestimate the preferences of rest for senses of world.world has the following senses in WordNet 1.71:world%1:17:02::2, world%1:17:00::, world%1:17:01::,world%1:14:02::, world%1:14:01::, world%1:14:00::,world%1:09:01::, world%1:09:00:: .From the BNC we obtain the following colloca-tion information (the formatting of the list isw1-POS GR wx-POS:co-occurrence frequency):rest-n pp of life-n:639, world-n:518, Europe-n:211,cast-n:44, season-n:90, day-n:253,country-n:158, family-n:134, evening-n:60, Kingdom-n:42, chapter-n:55,team-n:96, week-n:93, society-n:89,afternoon-n:34, population-n:56, ...The list of grammatical collocates with rest in re-lation pp of are: GCpp?ofrest = { life, world, Europe,case, season, day, country, family, evening, King-dom, chapter, team, week, society, afternoon, popu-lation,... }Based on relatedness scores between senses ofthese collocates and senses of world we computeselectional preference scores for each of world?ssenses:world%1:17:02::?1 world%1:17:00::?2world%1:17:01::?3 world%1:14:02::?2world%1:14:01::?3 world%1:14:00::?4world%1:09:01::?1 world%1:09:00::?1The same procedure is applied to compute thesense selectional preference scores of world foreach of rest?s senses, in the grammatical relationpp-obj of (the inverse of pp of in WSE).Formally, for the tuple (w1, w2, GR), we extractfrom the BNC all pairs (w1, wx, GR)3.
The setGCGRw1 = {wx|(w1, wx, GR) ?
corpus}gives w1?s grammatical collocations.
To estimatethe sense association strength between w1 andsenses of w2, for each wx ?
GCGRw1 we computerelatedness between the senses of wx and the sensesof w2.
Asiw2w1|GR, the association strength between w1and sense siw2 of word w2 under relation GR, is the1WordNet 1.7 is the sense inventory for Senseval2, WordNet1.7.1 is the sense inventory for Senseval 3.2Unique sense identifier from the WN lexicographer files.3Only wx collocates that have the same part of speech as w2are considered.sum of these relatedness scores:Asiw2w1|GR =?wx?GCGRw1?sjwx?Swxrel(siw2 , sjwx)where Swx is the set of senses for word wx.If this value is 0, then Asiw2w1|GR =1nw2, where nw2is the number of senses of w2.rel(siw2 , sjwx) can be computed as a similarity orrelatedness measure (Budanitsky and Hirst, 2006).Because the sense inventory for the Senseval datacomes from WordNet and we work at the sense level,we use relatedness measures based on WordNet, asopposed to corpus-based ones.
In the experimentspresented further in the paper, we have used a relat-edness measure based on hypernym and hyponyminformation, in the following manner:rel(siw2 , sjwx) =??????
?1 : siw2 is a hypernym of sjwx1 : siw2 is a hyponym of sjwxand path length(siw2 , sjwx) ?
21 : siw2 similar to/antonym of sjwx0 : otherwiseIn other words, if the sense siw2 of w2 is a hy-pernym of the sense sjwx or a close hyponym (dis-tance at most 2) or connected through a similarto/antonym of relation, we consider the two sensesrelated and relatedness gets a score of 1.
Otherwise,we consider the two senses unrelated.The motivation for using this relatedness mea-sure is that it allows fast computations ?
essen-tial when dealing with a large amount of informa-tion from a corpus ?
and it clusters closely relatedsenses based on WordNet?s hypernym/hyponym re-lations.
By clustering together related senses, wegather more evidence for the selectional preferencesof w2?s senses, which also helps partly with the datasparseness problem.Because at this point it is not determined to whichof wx?s senses the selectional preference is due, allof wx?s senses will have the same selectional prefer-ence to a sense j of wy: Asjwysiwx |GR= Asjwywx|GR, for allsenses siwx of wx.Sense-selectional preferences based on a lexicalresource When using the lexical resource, be-cause we have pairs that connect words under differ-ent parts of speech, we opt for a Lesk-based measure(Banerjee and Pedersen, 2003).
Relatedness scoresare computed for each pair of senses of the gram-matically linked pair of words (w1, w2, GR), usingthe WordNet-Similarity-1.03 package and the lesk759option (Pedersen et al, 2004).
To maintain the nota-tion from above, we denote by Asiwxsjwythe lesk relat-edness score between sense i of wx and sense j ofwy.
These scores are symmetric: Asiwxsjwy= Asjwysiwx, andindependent of grammatical relations GR.2.3 The sense-enhanced dependency treeAfter computing the sense association strengthscores for w1 and w2 in grammatical relation GRin the sentence, we expand the edge (wx, wy, GR)from the dependency tree to the two sets of directededges:{(siwx ?
sjwy , GR)|i = 1, n; j = 1, m},{(sjwy ?
siwx , GR?1)|i = 1, n; j = 1, m}.The weight of an edge (siwx ?
sjwy , GR) isAsjwysiwx |GR.
Figure 2 shows one sense-enhanced edge.%1:17:00::%1:17:02:: %1:14:02::%1:10:00:: %1:06:00:: %1:24:00world%...rest | pp_ofAArest%...world | pp?obj_ofrestworldpp_ofpp?obj_ofworldrest...22121114 1 41 211 412 2...Figure 2: A sense enhanced edge, with weights induced fromcorpus collocations.2.4 Word sense disambiguationWe first compute a score for each vertex (wordsense) using the estimated sense preferences,traversing the dependency graph from the bottomup4.
Each leaf is given a score of 1nw , where nwis the number of senses of the word w to which theleaf pertains.
The score of the other vertices are theweighted sum of the scores of their grammatical de-pendents in the sentence under analysis:Score(siwx) =?
(wx,wy ,GR)?sjwy ?SwyAsjwysiwx |GR?
Score(sjwy )The word sense disambiguation process starts fromthe root node of the dependency tree.
The highestranked score for the root is chosen, and the nodescorresponding to the other senses and their edges aredeleted from the graph.
For each of its dependents4The up-down orientation of the graph is given by the de-pendency tree from which it was expanded.we add the sense preferences imposed by the cho-sen sense to the vertex?s score, and proceed with thesense selection in the same way down through thegraph.Score(sjwy ) = Score(sjwy ) + Asjwysiwx |GR?1where (wx, wy, GR) ((wy, wx, GR?1)) is in thecurrent sentence.Because of data sparseness, there may be notenough evidence in the corpus to produce a clearwinner, and several senses are tied.
All senses arethen kept, and disambiguation proceeds further.
Ifmore than one word has multiple senses left afterthe top-down traversal of the tree, we use two meth-ods: random choosing from the tied senses or thesequence labeling method described in (Mihalcea,2005).
The graph?s vertices are the senses that re-main to be disambiguated, and its edges connect ev-ery pair of these senses (provided that they corre-spond to different words).
The score of each vertexis initially set to 1, and the edge weights are Lesksimilarity scores.
The vertices are scored using aPage Rank algorithm, in which the rank at every it-eration step is computed with the formula:WP (a) = (1?
d) + d?b?In(a)wba?c?Out(b) wbcWP (b)where:a, b, c are vertices in the graph;WP (a) is the weighted PageRank score of node a;d is the probability that there will be a jump from a given vertexto another in the graph.
We use d = 0.85, the value set by(Brin and Page, 1998) for Google?s PageRank model.In(a) is the set of a?s predecessors;Out(a) is the set of a?s successors.When the vertex scores converge5, the highestranking vertex for each word will give the sense pre-diction for that word.For multi-term expressions that are split duringparsing (such as come back), for which there is noprediction since they do not appear as such in theparse tree, the system randomly picks one of theWordNet senses.3 Experiments and ResultsThe WSD algorithm proposed is evaluated on theSenseval-2 and Senseval-3 English-all-words tasktest data.
Table 2 shows the results obtained for fine-grained scoring.
Because for each target there is aprediction, precision and recall have the same value.5An aperiodic, irreducible graph is guaranteed to converge(Grimmett and Stirzaker, 1989).
For every graph we built thathas more than 3 nodes, the aperiodicity condition is met ?
it hascycles of length 2 and 3, therefore the greatest common divisorof its cycle lengths is 1.
The graph is also irreducible ?
it has noleaves because it is highly interconnected.760POS Rand.
Seq.
GRWN GRPRWN GRBNC GRPRBNCSenseval 2noun 41.1% 63.0% 58.9% 62.4% 54.2% 63.3%verb 22.0% 31.6% 31.0% 33.0% 30.9% 32.7%adjective 38.9% 56.8% 52.9% 56.8% 40.4% 56.8%adverb 53.2% 57.5% 53.2% 58.8% 53.2% 59.1%all 36.7% 52.1% 49.0% 52.4% 44.6% 52.7%Senseval 3noun 42.5% 58.2% 53.2% 55.4% 40.3% 58.6%verb 19.4% 40.4% 40.3% 42.3% 19.9% 40.0%adjective 45.0% 56.7% 53.4% 54.5% 46.0% 57.5%adverb 92.9% 92.9% 92.9% 92.9% 92.9% 92.9%all 34.4% 50.8% 48.2% 50.1% 33.8% 51.2%Table 2: Precision ( = Recall) disambiguation results for Sen-seval English-all-words test dataColumn Random (Rand.)
shows a simple ran-dom baseline, and column Sequence (Seq.)
showsthe sequence data labelling method (Mihalcea,2005) ?
one of the best performing graph-methods(Navigli and Lapata, 2007).
The results presentedwere obtained using word similarities computedwith the WordNet-Similarity-1.03 package, on asense graph built using the marked targets in thetest set.
These results are not the same as those re-ported in (Mihalcea, 2005) for the Senseval 2 data(nouns 57.5%, verbs: 36.5%, adjective: 56.7%, ad-verb: 70.9%, for an average precision of 54.2%), be-cause of the difference in computing word similari-ties.
The other 4 columns show results obtained us-ing grammatical relation information between wordsas identified by the parser.
GRWN includes the re-sults obtained using the Lesk-based similarity withthe syntactically-based graph and breaking ties ran-domly, GRPRWN presents results obtained in a simi-lar configuration ?
only the tie breaking is done us-ing PageRank.
GRBNC and GRPRBNC are similarwith the previous two columns, only in this case theedge weights are the selectional preference scoresinduced from the BNC.The performance of GRWN is close to that ofSeq.
When ties are broken randomly, the compu-tation is much faster, since we do two traversals ofa small graph, while PageRank iterates until conver-gence (approx.
15 iterations) on graphs of averagesize of 1500 edges and 52 vertices (on Senseval 2data).
When PageRank is used to solve ties the per-formance on GRPRWN surpasses that of Seq whilestill being faster, having to iterate over graphs withan average of 1074 edges and 40 vertices.
The com-putation load is not only lighter during disambigua-tion, but also in the data preparation stage, whensimilarities must be computed between every sensepair corresponding to every pair of words within asentence (or a window of a given size).There are other important differences.
While thesyntactic structure of the sentence plays no role inthe Sequence method, it is crucial for the othermethods.
In the Senseval data not all words in asentence were tagged as targets, and the Sequencemethod works only on them.
This is not the case forthe GR methods, which work with the full syntactictree ?
and will disambiguate more words at a time.Also, the targets tagged in the data contain ?satel-lites?
information (e.g.
turn out, set up), which maychange the part of speech of the main target (e.g.at the same time (adv) for target time (noun), outof print (adj) for target print (noun)).
Multi-wordexpressions are themselves the subject of ample re-search, and we could not incorporate them into ourcorpus-based approach.
Verb particles in particularpose a problem, as most parsers will interpret theparticle as a preposition or adverb.
This was the casefor the Senseval data, as well.
On the other hand,this is a more realistic set-up, with no reliance onpreviously marked targets.Selectional preferences induced from a corpuswithout sense annotations perform well for verbs,but overall do not perform very well by themselves.The reasons for this are multiple.
The most impor-tant is data sparseness.
Many sense selection prefer-ences are 0.
In order to improve this approach, wewill look into more flexible methods for computingdependency pair similarities (without fixing one ofthe vertices as we did in this paper).
Previous re-search in inducing sense rankings from an untaggedcorpus (McCarthy et al, 2004), and inducing selec-tional preferences at the word level (for other appli-cations) (Erk, 2007) will provide the starting pointfor research in this direction.4 Comparison with Related WorkThe most similar approach to the one we describe,that has been tested on Senseval-2, is the one de-scribed in (McCarthy and Carroll, 2003).
The bestresults reported are 51.1% precision and 23.2% re-call.
This implementation also used grammatical in-formation and selectional preferences induced froma corpus to determine a disjoint partition ?
deter-mined by a cut in the WordNet is-a tree ?
over whichit computes a probability distribution conditionedby the grammatical context and a verb or adjectiveclass.McCarthy et al (2004) report a disambiguationprecision of 53.0% and recall of 49.0% on theSenseval-2 test data, using an approach that derivessense ranking based on word similarity and distribu-tional analysis in a corpus.Mihalcea (2005) reports the highest results on theSenseval-2 data obtained with a graph-based algo-rithm ?
54.2% precision and recall.
The results ob-tained with a PageRank algorithm applied to a sensegraph built from a words within a context of a given761size are also the highest for a completely unsuper-vised WSD6 system in Senseval-2.The best result obtained by an unsupervised sys-tem on the Senseval-3 data is reported by Strappa-rava et al (2004) ?
58.3%.
This implementationuses WordNet-Domains, a version of WordNet en-hanced with domain information (e.g.
economy, ge-ography).
The domain of a given text is automat-ically detected, and this information will constrainthe possible senses of words in the given text.For Senseval 3 data, using a graph method withthe Key Player Problem to measure vertex relevance,Navigli and Lapata (2007) report very close resultsto (Strapparava et al, 2004) on nouns and adjectives,and lower scores for verbs (F1-scores: 61.9% fornouns, 62.8% for adjectives, 36.1% for verbs com-pared with 62.2% for nouns, 66.9% for adjectives,50.4% for verbs).
Mihalcea (2005) reports an over-all score of 52.2% for this data.It is interesting to look at the dependency treewe used for WSD from the point of view of graphconnectivity measures (Navigli and Lapata, 2007).To determine the importance of a node in a graph,whether it represents the words and their senses in agiven context, or people in a social network, one canuse different measures.
According to grammaticaltheories, the importance of a node in the sentenceparse tree is given by the phrase type it heads, andthe number of words it thus dominates.
From thispoint of view, the top-down propagation of sensestraverses and disambiguates the tree in order of thedecreasing importance of nodes.
Other methodscould be used as well, such as disambiguating firstthe most highly connected nodes ?
the ones with themost sense constraints.5 ConclusionsWe have studied the impact of grammatical in-formation for constraining and guiding the wordsense disambiguation process in an unsupervisedall-words setup.
Compared with graph methods, theapproach we described is computationally lighter,while performing at the same level on Senseval-2and Senseval-3 all-words tasks test data.
Grammat-ical constraints serve both to limit the number ofword-senses pair similarities necessary, and also toestimate selectional preferences from an untaggedcorpus.Using only grammatically motivated connectionsleads to better disambiguation of verbs for bothSenseval-2 and Senseval-3 test data, but while thedifference is consistent (1.4%, 1.9%) it is not statis-tically significant.6As opposed to other unsupervised approaches, the sensefrequency information from WordNet was not used.We explored a new method for estimating senseassociation strength from a sense-untagged corpus.Disambiguation when using sense relatedness com-puted from WordNet is very close in performancewith disambiguation based on sense associationstrength computed from the British National Corpus,and on a par with state-of-the-art unsupervised sys-tems on Senseval-2.
This indicates that grammati-cal relations and automatically derived sense associ-ation preference scores from a corpus have high po-tential for unsupervised all-word sense disambigua-tion.ReferencesSatanjeev Banerjee and Ted Pedersen.
2003.
Extended gloss overlap as a mea-sure of semantic relatedness.
In Proc.
of IJCAI-03, Acapulco, Mexico, 9?15August, 2003, pages 805?810.Sergey Brin and Larry Page.
1998.
The anatomy of a large-scale hypertextualweb search engine.
Computer Networks and ISDN Systems, 30:1?7.Alexander Budanitsky and Graeme Hirst.
2006.
Evaluating WordNet-based mea-sures of semantic distance.
Computational Linguistics, 32(1):13?47.Yee Seng Chan, Hwee Tou Ng, and David Chiang.
2007.
Word sense disam-biguation improves statistical machine translation.
In Proc.
of ACL-07, pages33?40.Stephen Clark and David Weir.
2002.
Class-based probability estimation using asemantic hierarchy.
Computational Linguistics, 28(2):187?206.Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning.2006.
Generating typed dependency parses from phrase structure.
In Proc.of LREC-06.Michael Elhadad, Kathleen R. McKeown, and Jaques Robin.
1997.
Floatingconstraints in lexical choice.
Computational Linguistics, 23(2):195?239.Katrin Erk.
2007.
A simple, similarity-based model for selectional preferences.In Proc.
of ACL-07, pages 216?223.Geoffrey Grimmett and David Stirzaker.
1989.
Probability and Random Pro-cesses.
Oxford University Press.Adam Kilgarriff, Pavel Rychly, Pavel Smrz, and David Tugwell.
2004.
TheSketch Engine.
In Proc.
of EuraLex-04, pages 105?116.Dan Klein and Christopher D. Manning.
2003.
Accurate unlexicalized parsing.In Proc.
of ACL-03, pages 423?430.Hang Li and Naoki Abe.
1998.
Generalizing case frames using a thesaurus andthe MDL principle.
Computational Linguistics, 24(2):217?244.Diana McCarthy and John Carroll.
2003.
Disambiguating nouns, verbs and ad-jectives using automatically acquired selectional preferences.
ComputationalLinguistics, 29(4):639?654.Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll.
2004.
Findingpredominant senses in untagged text.
In Proc.
of ACL-04, Barcelona, Spain,21?26 July 2004, pages 280?287.Rada Mihalcea.
2005.
Large vocabulary unsupervised word sense disambigua-tion with graph-based algorithms for sequence data labeling.
In Proc.
of HLT-EMNLP-05, pages 411?418.Roberto Navigli and Mirella Lapata.
2007.
Graph connectivity measures forunsupervised word sense disambiguation.
In Proc.
of IJCAI-07, pages 1683?1688.Martha Palmer, Christiane Fellbaum, Scott Cotton, Lauren Delfs, and Hoa TrangDang.
2001.
English tasks: all-words and verb lexical sample.
In Proc.
of theACL SENSEVAL-2 Workshop, Toulouse, France, 2001.Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi.
2004.
Word-Net::Similarity ?
Measuring the relatedness of concepts.
In Proc.
of HLT-NAACL-04, Boston, Mass., 2?7 May, 2004, pages 267?270.Philip Resnik.
1996.
Selectional constraints: an information-theoretic model andits computational realization.
Cognition, (61):127?159, November.Benjamin Snyder and Martha Palmer.
2004.
The English all-words task.
In Proc.of the ACL SENSEVAL-3 Workshop, Barcelona, Spain, 2004, pages 41?43.Jiri Stetina, Sadao Kurohashi, and Makoto Nagao.
1998.
General word sense dis-ambiguation method based on a full sentential context.
In Sanda Harabagiu,editor, PROC.
of Use of WordNet in Natural Language Processing Systems,pages 1?8.Carlo Strapparava, Alfio Gliozzo, and Claudio Giuliano.
2004.
Pattern abstrac-tion and term similarity for word sense disambiguation.
In Proc.
of the ACLSENSEVAL-3 Workshop, Barcelona, Spain, 2004, pages 229?234.Michael Sussna.
1993.
Word sense disambiguation for free-text indexing using amassive semantic network.
In Proc.
of the CIKM-93, pages 67?74.David Yarowsky.
1995.
Unsupervised word sense disambiguation rivalling su-pervised methods.
In Proc.
of ACL-05, Cambridge, Mass., 26?30 June 1995,pages 189?196.762
