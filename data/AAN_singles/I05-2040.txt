Transformation Based Chinese Entity Detection and TrackingYaqian Zhou?Dept.
Computer Science and EngineringFudan Univ.Shanghai 200433, ChinaZhouYaqian@fudane.edu.cnChangning HuangMicrosoft Research, AsiaBeijing 100080, Chinacnhuang@msrchina.research.microsoft.comJianfeng GaoMicrosoft Research, AsiaBeijing 100080, Chinajfgao@microsoft.comLide WuDept.
of CSE., Fudan Univ.Shanghai 200433, Chinaldwu@fudane.edu.cn?
This work is done while the first author is visiting Microsoft Research Asia.AbstractThis paper proposes a unifiedTransformation Based Learning (TBL,Brill, 1995) framework for ChineseEntity Detection and Tracking (EDT).It consists of two sub models: amention detection model and an entitytracking/coreference model.
The firstsub-model is used to adapt existingChinese word segmentation and NamedEntity (NE) recognition results to aspecific EDT standard to find all thementions.
The second sub-model isused to find the coreference relationbetween the mentions.
In addition, afeedback technique is proposed tofurther improve the performance of thesystem.
We evaluated our methods onthe Automatic Content Extraction(ACE, NIST, 2003) Chinese EDTcorpus.
Results show that itoutperforms the baseline, and achievescomparable performance with the state-of-the-art methods.1 IntroductionThe task of Entity Detection and Tracking (EDT)is suggested by the Automatic Content Extrac-tion (ACE) project (NIST, 2003).
The goal is todetect all entities in a given text and track allmentions that refer to the same entity.
The taskis a fundamental to many Natural LanguageProcessing (NLP) applications, such as informa-tion retrieval and extraction, text classification,summarization, question answering, and ma-chine translation.EDT is an extension of the task ofcoreference resolution in that in EDT we notonly resolve the coreference between mentionsbut also detect the entities.
Each of those entitiesmay have one or more mentions.
In the ACEproject, there are five types of entities defined inEDT: person (PER), geography political Entity(GPE), organization (ORG), location (LOC),and facility (FAC).
Many traditional coreferencetechniques can be extended to EDT for entitytracking.Early work on pronoun anaphora resolutionusually uses rule-based methods (e.g.
Hobbs1976; Ge et al, 1998; Mitkov, 1998), which tryto mine the cues of the relation between the pro-nouns and its antecedents.
Recent research(Soon et al, 2001; Yang et al, 2003; Ng andCardie, 2002; Ittycherah et al, 2003; Luo et al,2004) focuses on the use of statistical machinelearning methods and tries to resolve referencesamong all kinds of noun phases, including name,nominal and pronoun phrase.
One common ap-proach applied by them is to first train a binarystatistical model to measure how likely a pair of232mentions corefer; and then followed by a greedyprocedure to group the mentions into entities.Mention detection is to find all the named en-tity, noun or noun phrase, pronoun or pronounphrase.
Therefore, it needs Named Entity Rec-ognition, but not only.
Though the detection ofentity mentions is an essential problem forEDT/coreference, there has been relatively lessprevious research.
Ng and Cardie (2002) showsthat improving the recall of noun phrase identi-fication can improve the performance of acoreference system.
Florian et al (2004) formu-late the mention detection problem as a charac-ter-based classification problem.
They assign foreach character in the text a label, indicatingwhether it is the start of a specific mention, in-side a specific mention, or outside of any men-tion.In this paper, we propose a unified EDTmodel based on the Transformation BasedLearning (TBL, Brill, 1995) framework for Chi-nese.
The model consists of two sub models: amention detection model and a coreferencemodel.
The first sub-model is used to adapt ex-isting Chinese word segmentation and NamedEntity (NE) recognition system to a specificEDT standard.
TBL is a widely used machinelearning method, but it is the first time it is ap-plied to coreference resolution.
In addition, afeedback technique is proposed to further im-prove the performance of the system.The rest of the paper is organized as follows.In section 2, we propose the unified TBL Chi-nese EDT model framework.
We describe thefour key techniques of our Chinese EDT, theword segmentation adaptation model, the men-tion detection model, the coreference model andthe feedback technique in section 3, 4, 5 and 6accordingly.
The experimental results on theACE Chinese EDT corpus are shown in section7.2 The Unified System FrameworkOur Chinese EDT system consists of two com-ponents, mention detection module and corefer-ence module besides a feedback techniquebetween them as illustrated in Figure 1.MSRSeg (Gao et al, 2003; Gao et al), Mi-crosoft Research Asia?s Chinese word segmen-tation system that is integrated with namedentity recognition, is used to segment Chinesewords.
However MSRSeg can?t well match thestandard of ACE EDT evaluation for eithertypes or boundaries.
The difference of the stan-dard of named entity between MSRSeg andACE cause more than half of the errors forNAME mention detection.
In order to overcomethese problems, we integrate a segmentationadapter to mention detection model.The EDT system is a unified system that usesthe TBL scheme.
The idea of TBL is to learn alist of ordered rules while progressively improveupon the current state of the training set.
An ini-tial assignment is made based on simple statis-tics, and then rules are greedily learned tocorrect the mistakes, until no more improvementcan be made.
There are three main problems inthe TBL framework: An initial state assignment,a set of allowable templates for rules, and anobjective function for learning.Figure 1.
Entity detection and tracking systemflow.3 Word Segmentation AdaptationThe method of applying TBL to adapt the Chi-nese word segmentation standard has been de-scribed in Gao et al (2004).
Our approach isslightly different for not have a correctly seg-mented corpus according to ACE standard.From the un-segmented ACE EDT corpus,we can only obtain mention boundary informa-tion.
So the adapting objective is to detect themention boundary instead of all words in text,correctly.
In the corpus, very few mentions?boundaries are crossing1.The initial state of the segmentation adapta-tion model is the output of MSRSeg.
And we1 The mentions?
extents are frequently crossing, whileheads not.MSRSeg&POSTaggingMentionDetectionModelCoreferenceModelRawDocumentMentions EntitiesSeg/POS/NEDocument233define two actions in the model, inserting andremoving a boundary.
The prefix or suffix ofcurrent word is used to define the boundary ofinserting.
Both inserting and removing actionconsider the combination of POS tag and wordstring of current, left and right words.When inserting a boundary, the right part ofthe word keeps the old POS tag, and the left partintroduces a special POS tag ?new?.
When re-moving a boundary, the new formed word intro-duces a special POS tag ?new?.
The followingtwo examples illustrate the strategy.?????
/nt/court of Russia ?
??
?/new/Russia ?
?/nt/court?/nr/Bo ?/nr/Pu ??
?/new/Bopu4 Mention DetectionSince the word segmentation adaptation modelhas corrected the boundaries of mentions, ourmention detection model bases on word andonly tagging the entity mention types.
Themodel detects the mentions by tagging sixteentags (including the combination of five entitytypes and three mention types and ?OTHER?
tag)for all the words outputted by segmentation ad-aptation model.
The templates, as illustrated intable 1, only refer to local features, such as POStag and word string of left, right, and currentwords; the suffix, and single character feature ofcurrent word.Table 1.
Templates for mention detection.MT1: P0 MT9: R4,P0MT2: W0 MT10: R3,P0MT3: P0,W0 MT11: R2,P0MT4: P_1,W0 MT12: R1,P0MT5: P_1,P0 MT13: S0,P0MT6: W0,P1 MT14: T_1,W0MT7: P0,P1 MT15: T_1,P0MT8: W0,W1 MT16: P0,T1Table 2.
Examples of transformation rules ofmention detection.MR1: MT13 0 ns GPEMR2: MT13 0 nr PERMR3: MT13 0 nt ORGMR4: MT16 n PER NPERMR5: MT16 new ORG GPEIn table 1, ?MT1?
et alrepresent the id of thetemplates; ?R1?, ?R2?, ?R3?
and ?R4?
representthe suffix of current word and the number ofcharacter is 1, 2, 3 and 4 accordingly; other suf-fix ?_1?, ?0?, ?1?
means the left, current andright words?
feature; ?W?
represent the string ofword; ?P?
represent POS tag; ?T?
representmention tag; ?S?
represent the binary-value sin-gle character feature.Five best transformation rules are illustratedin Table 2.
For example, MR3 means ?if currentword?s POS tag is nt, then it is a ORG?.
Follow-ing example well describe the process of apply-ing these rules.??
?/new/Russia ??/nt/court???
?/new/Russia [?
?/nt/court]ORG (MR3)?
[ ?
?
?
/new/Russia]GPE [ ?
?/nt/court]ORG(MR5)5 Entity TrackingIn our entity tracking/coreference model, theinitial state is let each mention in a documentform an entity, as shown in Figure 2 (a).
And theobjective function directs the learning process toinsert or remove chains between mentions (Fig-ure 2 b and c) to approach the goal state (Figure2 f).A list of rules is learned in greedy fashion,according to the objective function.
When norule that improves the current state of the train-ing set beyond a pre-set threshold can be found,the training phrase ends.
The objective functionin our system is driven by the correctness of thebinary classification for pair-wise mention pairs.The TBL entity tracking model has morewidely clustering/searching space as comparewith previous strategies (Soon et al 2001; Ngand Cardie, 2002; Luo et al, 2004).
For example,the state shown in Figure 2 (d) is not reachablefor them.
Because they assume one mentionshould refer to its most confidential mentions orentities that before it, while A and B are obvi-ously not in same entity, as we can see in Figure2 (d).
Thus C can refer to either A or B, but notboth.
While in TBL model, this state is allowed.In order to keep our system robust, the trans-formation templates refer to only six types ofsimple features, as described below.All these features do not need any high leveltools (i.e.
syntactic parser) and little externalknowledge base.
In fact, only a country nameabbreviation list (171 entrances) and a Chinese234province alias list (34 entrances) are used to de-tect ?alias?
relation for String Match feature.String Match feature (STRM): Its possiblevalues are exact, alias, abbr, left, right, other.
Iftwo mentions are exact string matched, then re-turn exact; else if one mention is an alias of theother, then return alias; else if one mention isthe abbreviation of the other, then return abbr;else if one mention is the left substring of theother, then return left; else if one mention is theright substring of the other, then return right;else return other.Figure 2.
The procedure of TBL entity track-ing/coreference modelEdit Distance feature I (ED1): Its possiblevalues are true or false.
If the edit distance of thetwo mentions are less than or equal to 1, thenreturn true, else return false.Token Distance feature I (TD1): Its possi-ble values are true or false.
If the edit distance ofthe two mentions are less than or equal to 1(i.e.,there are not more than one token between thetwo mentions), then return true, else return false.Mention Type (MT): Its possible values areNAME, NOMINAL, or PRONOUN..Entity Type (ET): Its possible values arePER, GPE, ORG, LOC, or FAC.Mention String (M): Its possible values arethe actual mention string.These six features can be divided into twocategories: mention pair features (the first three)and single mention features (the other three).And the single mention features are suffixedwith ?L?
or ?R?
to differentiate for left or rightmentions (i.e.
ETL represent the left mention?sentity type).Based on the six kinds of basic features, foursimple transformation templates are used in oursystem, as listed in table 3.Table 3.
Templates for coreference model.CT1: MTL,MTR,STRMCT2: MTL,MTR,ETL,ETR,ED1CT3: MTL,MTR,ETL,ETR,TD1CT4: MTL,MTR,ML,MRTable 4.
Examples of transformation rules ofcoreference model.CR1:CT1 NAME NAME EXACT LINKCR2:CT2 NOMINAL NAME PER PER 1 LINKCR3:CT1 NAME NAME ALIAS LINKCR4:CT1 PRONOUN PRONOUN EXACT LINKThough trained on different data set willlearn different rules, the four rules listed in table4 is the best rules that always been learned.
Forexample, the first rule means that ?If two NAMEmentions are exact string matched, then insert achain between them?.
The following exampleillustrates the process.[??/US]GPE??[???/Russia]GPE????????[??
/US]GPE[??/businessman]NPER[??/Bopu]PER?
[ ?
?
/US]GPE-1 ?
?
[ ?
?
?/Russia]GPE ????????[??/US]GPE-1[??
/businessman]NPER[??/Bopu]PER(CR1)?
[ ?
?
/US]GPE-1 ?
?
[ ?
?
?/Russia]GPE ????????[??/US]GPE-1[??
/businessman]NPER-2[?
?/Bopu]PER-2(CR2)6 FeedbackThere are three reasons push us apply feedbacktechnique in the EDT system.
The first is to de-termine whether a signal character is an abbre-viation is discourse depended.
For example,Chinese character ???
can represents both acountry name ?China?
and a common preposi-tion ?in?.
If it can links to ???
/China?
bycoreference model, it is likely to representA    BC    DEA    BC    DEA    BC    DEA    BC    DEA    BC    DEA    BC    DE(e)(a)                     (b)                          (c)(d)(f)235?China?.
The second is the definition of men-tions is hard to hold, especially the nominalmentions.
An isolated mention is more likely notto be a mention.
The third is to pick up lost men-tion according to its multi-appearance in the dis-course.
In fact, [Ji and Crishman, 2004] has usedfive hubristic rules based on coreference resultsto improve the name recognition result.
While inthis section we will present an automatic method.The feedback technique is employed by us-ing entity features in mention detection model.In our model, the transformation templates referto the number of mentions in the entity, the sin-gle character feature, the entity type feature, themention type feature and mention string, aslisted follows.SDD: Its possible values are the combinationof the mention type and entity type of the men-tion string in discourse: PER, GPE, ORG, LOC,FAC, NPER (NOMINAL PER), NGPE, NORG,NLOC, NFAC, PPER (PROUNOUN PER),PGPE, PORG, PLOC, and PFAC.SC2, SC3, SC4: Their possible values aretrue or false.
If the word string appear not lessthan 2 (3, 4) times in the discourse then returntrue, else return false.PDD: presents the combination of the men-tion type and entity type of the mention in dis-course.
Its possible values are same with ?SDD?.PC2: Its possible values are true or false.
Ifthe mention belong to an entity has not less than2 mentions then return true, else return false.S0: Its possible values are true or false.
If themention is a single character word then returntrue, else return false.W0: string of the mention.Table 5.
Templates for feedback.FT1: SDD,SC2 FT4: PDD,PC2,S0FT2: SDD,SC3 FT5: PDD,PC2,S0FT3: SDD,SC4 FT6: PDD,PC2,W0Table 6.
Examples of transformation rules offeedback.FR1: FT1 PER T PER FR4: FT4 NORG F OFR2: FT5 GPE F 1 O FR5: FT3 PGPE F OFR3: FT4 NFAC F OThe first rule means that ?if a word in thedocument appears as person name more thantwo times, then it is a person name?.
This rulecan pick up lost person names.
The second rulemeans that ?if a GPE mention is isolated and itis a single character word, then it is not a men-tion?.
This rule can throw away isolated abbre-viation of GPE, as illustrated in the followingexample.?[?
?/Bopu]PER-3 ?????[???/Russia]GPE-2[??
/court]ORG-4[?
/by]GPE-6?????
20???
???[?
?/Bopu]PER-3 ?????[???/Russia]GPE-2[?
?/court]ORG-4?/by ?????
20???
?
(FR2)7 ExperimentsOur experiments are conducted on Chinese EDTcorpus for ACE project from LDC.
This corpusis the training data for ACE evaluation 2003.The corpus has two types, paper news (nwire)and broadcast news (bnews).
the statistics of thecorpus is shown in Table 7.Table 7.
Statistics of the ACE corpus.nwire bnewsDocument 99 122Character 55,000 45,000Entity 2517 2050Mention 5423 4506Because the test data for ACE evaluation isnot public, we randomly and equally divide thecorpus into 3 subsets: set0, set1, set2.
Each con-sists of about 73 documents and 33K ChineseCharacters 2 .
Cross experiments are conductedon these data sets.
ACE-value is used to evaluatethe EDT system; and precision (P), recall (R)and F (F=2*P*R/(P+R)) to evaluate the mentiondetection result.In the experiments, we first use one data settrain the mention detection system; then use an-other set train the coreference model based onthe output of the mention detection; finally usethe other set test.
In practice, we can retrain themention detection model use the two train set toget higher performance.Table 8.
EDT and mention detection results.EDT Mention DetectionMethod ACE-valueR P FTag 55.7?1.6 62.3?1.0 85.0?1.4 71.9?0.6SegTag 61.6?3.6 70.9?4.5 81.9?1.0 75.9?2.6SegTag+F 63.3?2.0 68.0?4.8 83.8?1.2 75.0?3.12 Two of the documents (CTS20001110.1300.0506, andXIN20001102.2000.0207) in the corpus are not use forserious annotation error.236In Table 8, ?SegTag?
represent the mentiondetection system integrated with segmentationadaptation, ?Tag?
represent the mention detec-tion system without segmentation adaptation.?+F?
means with feedback.The ACE-value of our Chinese EDT systemis better than 58.8% of Florian et al (2004).
Infact, the two systems are not comparable for notbasing on the same training and test data.
How-ever both corpora are under the same standardfrom ACE project, and our training data (about66K) is smaller than Florian et al (2004) (about80K).
Therefore, it is an encouraging result.Segmentation adapting and feedback can im-prove 7.5% of ACE-value for the whole system.As we can see from Table 8, using TBL methodto adapt standard or correct errors can improvethe mention detection performance especiallyrecall, and word segmentation adapting is essen-tial for mention detection.
Feedback can im-prove the precision of mention detection withloss of recall.
The two techniques can signifi-cantly improve the EDT performance, since thep-value of the T-test for the performance of?SegTag?
to ?Tag?
is 96.7%, while for ?Seg-Tag+F?
to ?Tag?
is 98.9%.
The recall of men-tion detection is dropped after feedback becauseof the great effect of rule FR2, 3, 4 and 5 as il-lustrated in table 6.8 ConclusionIn this paper, we integrate the mention detectionmodel and entity tracking/coreference modelinto a unified TBL framework.
Experimentalresults show segmentation adapting and feed-back can significantly improve the performanceof EDT system.
And even with very limitedknowledge and shallow NLP tools, our methodcan reach comparable performance with relatedwork.ReferencesEric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: a casestudy in Part-of-Speech tagging.
In: Computa-tional Lingusitics, 21(4).R Florian, H Hassan, A Ittycheriah, H Jing, N Kamb-hatla, X Luo, N Nicolov, and S Roukos.
2004.
Astatistical model for multilingual entity detectionand tracking.
In Proc.
of HLT/NAACL-04, pages1-8, Boston Massachusetts, USA.Jianfeng Gao, Mu Li and Changning Huang.
2003.Improved souce-channel model for Chinese wordsegmentation.
In Proc.
of ACL2003.Jianfeng Gao, Andi Wu, Mu Li, Changning Huang,Hongqiao Li, Xinsong and Xia, Haowei Qin.
2004.Adaptive Chinese word segmentation.
In Proc.
ofACL2004.Niyu Ge, John Hale, and Eugene Charniak.
1998.
Astatistical approach to anaphora resolution.
InProc.
of the Sixth Workshop on Very Large Cor-pora.Sanda M. Harabagiu, Razvan C. Bunescu, and StevenJ.
Maiorano.
2001.
Text and knowledge miningfor coreference resolution.
In Proc.
of NAACL.J.
Hobbs.
1976.
Pronoun resolution.
Technical report,Dept.
of Computer Science, CUNY, TechnicalReport TR76-1.A Ittycheriah, L Lita, N Kambhatla, N Nicolov, SRoukos, and M Stys.
2003.
Identifying and track-ing entity mentions in maximum entropy frame-work.
In HLT-NAACL 2003.Heng Ji and Ralph Grishman.
2004.
ApplyingCoreference to Improve Name Recognition.
InACL04 Reference Resolution and its Application Work-shop.Xiaoqiang Luo, A. Ittycheriah, H. Jing, N. Kamb-hatla, S. Roukos.2004.
A Mention-SynchronousCoreference Resolution Aogorithm Based on theBell Tree.
In Proc.
of ACL2004.R.
Mitkov.
1998.
Robust pronoun resolution withlimited knowledge.
In Proc.
of the 17th Interna-tional Conference on Computational Linguistics,pages 869-875.MUC.
1996.
Proceedings of the Sixth Message Un-derstanding Conference (MUC-6).
Morgan Kauf-mann, San Mateo, CA.NIST.
2003.
The ACE evaluation plan.www.nist.gov/speech/tests/ace/index.htm.Wee Meng Soon, Hwee Tou Ng, and Chung YongLim.
2001.
A machine learning approach tocoreference resolution of noun phrases.
Computa-tional Linguistics, 27(4):521-544.M.
Vilain, J. Burger, J. Aberdeen, D. Connolly and L.Hirschman.
1995.
A Model-Theoretic coreferencescoring scheme.
In Proc.
of MUC-6, page45-52.Morgan Kaufmann.Xiaofeng Yang, Guodong Zhou, Jian Su, and ChewLim Tan.
2003.
Coreference resolution usingcompetition learning approach.
In Proc.
ofACL2003.237
