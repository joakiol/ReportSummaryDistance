Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 226?234,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPRecognizing Stances in Online DebatesSwapna SomasundaranDept.
of Computer ScienceUniversity of PittsburghPittsburgh, PA 15260swapna@cs.pitt.eduJanyce WiebeDept.
of Computer ScienceUniversity of PittsburghPittsburgh, PA 15260wiebe@cs.pitt.eduAbstractThis paper presents an unsupervised opin-ion analysis method for debate-side clas-sification, i.e., recognizing which stance aperson is taking in an online debate.
Inorder to handle the complexities of thisgenre, we mine the web to learn associa-tions that are indicative of opinion stancesin debates.
We combine this knowledgewith discourse information, and formu-late the debate side classification task asan Integer Linear Programming problem.Our results show that our method is sub-stantially better than challenging baselinemethods.1 IntroductionThis paper presents a method for debate-side clas-sification, i.e., recognizing which stance a per-son is taking in an online debate posting.
In on-line debate forums, people debate issues, expresstheir preferences, and argue why their viewpoint isright.
In addition to expressing positive sentimentsabout one?s preference, a key strategy is also toexpress negative sentiments about the other side.For example, in the debate ?which mobile phone isbetter: iPhone or Blackberry,?
a participant on theiPhone side may explicitly assert and rationalizewhy the iPhone is better, and, alternatively, also ar-gue why the Blackberry is worse.
Thus, to recog-nize stances, we need to consider not only whichopinions are positive and negative, but also whatthe opinions are about (their targets).Participants directly express their opinions,such as ?The iPhone is cool,?
but, more often, theymention associated aspects.
Some aspects are par-ticular to one topic (e.g., Active-X is part of IEbut not Firefox), and so distinguish between them.But even an aspect the topics share may distin-guish between them, because people who are pos-itive toward one topic may value that aspect more.For example, both the iPhone and Blackberry havekeyboards, but we observed in our corpus that pos-itive opinions about the keyboard are associatedwith the pro Blackberry stance.
Thus, we need tofind distinguishing aspects, which the topics mayor may not share.Complicating the picture further, participantsmay concede positive aspects of the opposing is-sue or topic, without coming out in favor of it,and they may concede negative aspects of the is-sue or topic they support.
For example, in the fol-lowing sentence, the speaker says positive thingsabout the iPhone, even though he does not pre-fer it: ?Yes, the iPhone may be cool to take it outand play with and show off, but past that, it offersnothing.?
Thus, we need to consider discourse re-lations to sort out which sentiments in fact revealthe writer?s stance, and which are merely conces-sions.Many opinion mining approaches find negativeand positive words in a document, and aggregatetheir counts to determine the final document po-larity, ignoring the targets of the opinions.
Somework in product review mining finds aspects of acentral topic, and summarizes opinions with re-spect to these aspects.
However, they do not finddistinguishing factors associated with a preferencefor a stance.
Finally, while other opinion anal-ysis systems have considered discourse informa-tion, they have not distinguished between conces-sionary and non-concessionary opinions when de-termining the overall stance of a document.This work proposes an unsupervised opinionanalysis method to address the challenges de-scribed above.
First, for each debate side, we minethe web for opinion-target pairs that are associatedwith a preference for that side.
This informationis employed, in conjunction with discourse infor-mation, in an Integer Linear Programming (ILP)framework.
This framework combines the individ-ual pieces of information to arrive at debate-side226classifications of posts in online debates.The remainder of this paper is organized as fol-lows.
We introduce our debate genre in Section 2and describe our method in Section 3.
We presentthe experiments in Section 4 and analyze the re-sults in Section 5.
Related work is in Section 6,and the conclusions are in Section 7.2 The Debate GenreIn this section, we describe our debate data,and elaborate on characteristic ways of express-ing opinions in this genre.
For our currentwork, we use the online debates from the websitehttp://www.convinceme.net.1In this work, we deal only with dual-sided,dual-topic debates about named entities, for ex-ample iPhone vs. Blackberry, where topic1 =iPhone, topic2 =Blackberry, side1 = pro-iPhone,and side2=pro-Blackberry.Our test data consists of posts of 4 debates:Windows vs. Mac, Firefox vs. Internet Explorer,Firefox vs. Opera, and Sony Ps3 vs. NintendoWii.
The iPhone vs. Blackberry debate and twoother debates, were used as development data.Given below are examples of debate posts.
Post1 is taken from the iPhone vs. Blackberry debate,Post 2 is from the Firefox vs. Internet Explorerdebate, and Post 3 is from the Windows vs. Macdebate:(1) While the iPhone may appeal to youngergenerations and the BB to older, there is noway it is geared towards a less rich popula-tion.
In fact it?s exactly the opposite.
It?s agimmick.
The initial purchase may be halfthe price, but when all is said and done youpay at least $200 more for the 3g.
(2) In-line spell check...helps me with bigwords like onomatopoeia(3) Apples are nice computers with an excep-tional interface.
Vista will close the gap onthe interface some but Apple still has theprettiest, most pleasing interface and mostlikely will for the next several years.2.1 ObservationsAs described in Section 1, the debate genre posessignificant challenges to opinion analysis.
This1http://www.forandagainst.com andhttp://www.createdebate.com are other similar debatingwebsites.subsection elaborates upon some of the complexi-ties.Multiple polarities to argue for a side.
Debateparticipants, in advocating their choice, switchback and forth between their opinions towards thesides.
This makes it difficult for approaches thatuse only positive and negative word counts to de-cide which side the post is on.
Posts 1 and 3 illus-trate this phenomenon.Sentiments towards both sides (topics) within asingle post.
The above phenomenon gives riseto an additional problem: often, conflicting sides(and topics) are addressed within the same post,sometimes within the same sentence.
The secondsentence of Post 3 illustrates this, as it has opinionsabout both Windows and Mac.Differentiating aspects and personal prefer-ences.
People seldom repeatedly mention thetopic/side; they show their evaluations indirectly,by evaluating aspects of each topic/side.
Differen-tiating aspects determine the debate-post?s side.Some aspects are unique to one side/topic or theother, e.g., ?3g?
in Example 1 and ?inline spellcheck?
in Example 2.
However, the debates areabout topics that belong to the same domain andwhich therefore share many aspects.
Hence, apurely ontological approach of finding ?has-a?
and?is-a?
relations, or an approach looking only forproduct specifications, would not be sufficient forfinding differentiating features.When the two topics do share an aspect (e.g., akeyboard in the iPhone vs. Blackberry debate), thewriter may perceive it to be more positive for onethan the other.
And, if the writer values that as-pect, it will influence his or her overall stance.
Forexample, many people prefer the Blackberry key-board over the iPhone keyboard; people to whomphone keyboards are important are more likely toprefer the Blackberry.Concessions.
While debating, participants oftenrefer to and acknowledge the viewpoints of the op-posing side.
However, they do not endorse this ri-val opinion.
Uniform treatment of all opinions ina post would obviously cause errors in such cases.The first sentence of Example 1 is an instance ofthis phenomenon.
The participant concedes thatthe iPhone appeals to young consumers, but thispositive opinion is opposite to his overall stance.227DIRECT OBJECT Rule: dobj(opinion, target)In words: The target is the direct object of the opinionExample: I loveopinion1 Firefoxtarget1 and defendedopinion2 ittarget2NOMINAL SUBJECT Rule: nsubj(opinion, target)In words: The target is the subject of the opinionExample: IEtarget breaksopinion with everything.ADJECTIVAL MODIFIER Rule: amod(target, opinion)In words: The opinion is an adjectival modifier of the targetExample: The annoyingopinion popuptargetPREPOSITIONAL OBJECT Rule: if prep(target1,IN) ?
pobj(IN, target2)In words: The prepositional object of a known target is also a target of the same opinionExample: The annoyingopinion popuptarget1 in IEtarget2 (?popup?
and ?IE?
are targets of ?annoying?
)RECURSIVE MODIFIERS Rule: if conj(adj2, opinionadj1) ?
amod(target, adj2)In words: If the opinion is an adjective (adj1) and it is conjoined with another adjective (adj2),then the opinion is tied to what adj2 modifiesExample: It is a powerfulopinion(adj1) and easyopinion(adj2) applicationtarget(?powerful?
is attached to the target ?application?
via the adjective ?easy?
)Table 1: Examples of syntactic rules for finding targets of opinions3 MethodWe propose an unsupervised approach to classify-ing the stance of a post in a dual-topic debate.
Forthis, we first use a web corpus to learn preferencesthat are likely to be associated with a side.
Theselearned preferences are then employed in conjunc-tion with discourse constraints to identify the sidefor a given post.3.1 Finding Opinions and Pairing them withTargetsWe need to find opinions and pair them with tar-gets, both to mine the web for general preferencesand to classify the stance of a debate post.
We usestraightforward methods, as these tasks are not thefocus of this paper.To find opinions, we look up words in a sub-jectivity lexicon: all instances of those words aretreated as opinions.
An opinion is assigned theprior polarity that is listed for that word in the lex-icon, except that, if the prior polarity is positive ornegative, and the instance is modified by a nega-tion word (e.g., ?not?
), then the polarity of that in-stance is reversed.
We use the subjectivity lexiconof (Wilson et al, 2005),2 which contains approxi-mately 8000 words which may be used to expressopinions.
Each entry consists of a subjective word,its prior polarity (positive (+), negative (?
), neu-tral (?
)), morphological information, and part ofspeech information.To pair opinions with targets, we built a rule-based system based on dependency parse informa-tion.
The dependency parses are obtained using2Available at http://www.cs.pitt.edu/mpqa.the Stanford parser.3 We developed the syntacticrules on separate data that is not used elsewhere inthis paper.
Table 1 illustrates some of these rules.Note that the rules are constructed (and explainedin Table 1) with respect to the grammatical relationnotations of the Stanford parser.
As illustrated inthe table, it is possible for an opinion to have morethan one target.
In such cases, the single opin-ion results in multiple opinion-target pairs, one foreach target.Once these opinion-target pairs are created, wemask the identity of the opinion word, replacingthe word with its polarity.
Thus, the opinion-target pair is converted to a polarity-target pair.For instance, ?pleasing-interface?
is converted tointerface+.
This abstraction is essential for han-dling the sparseness of the data.3.2 Learning aspects and preferences fromthe webWe observed in our development data that peoplehighlight the aspects of topics that are the basesfor their stances, both positive opinions toward as-pects of the preferred topic, and negative opinionstoward aspects of the dispreferred one.
Thus, wedecided to mine the web for aspects associatedwith a side in the debate, and then use that infor-mation to recognize the stances expressed in indi-vidual posts.Previous work mined web data for aspects as-sociated with topics (Hu and Liu, 2004; Popescuet al, 2005).
In our work, we search for aspectsassociated with a topic, but particularized to po-larity.
Not all aspects associated with a topic are3http://nlp.stanford.edu/software/lex-parser.shtml.228side1 (pro-iPhone) side2 (pro-blackberry)termp P (iPhone+|termp) P (blackberry?|termp) P (iPhone?|termp) P (blackberry+|termp)storm+ 0.227 0.068 0.022 0.613storm?
0.062 0.843 0.06 0.03phone+ 0.333 0.176 0.137 0.313e-mail+ 0 0.333 0.166 0.5ipod+ 0.5 0 0.33 0battery?
0 0 0.666 0.333network?
0.333 0 0.666 0keyboard+ 0.09 0.12 0 0.718keyboard?
0.25 0.25 0.125 0.375Table 2: Probabilities learned from the web corpus (iPhone vs. blackberry debate)discriminative with respect to stance; we hypoth-esized that, by including polarity, we would bemore likely to find useful associations.
An aspectmay be associated with both of the debate top-ics, but not, by itself, be discriminative betweenstances toward the topics.
However, opinions to-ward that aspect might discriminate between them.Thus, the basic unit in our web mining process isa polarity-target pair.
Polarity-target pairs whichexplicitly mention one of the topics are used to an-chor the mining process.
Opinions about relevantaspects are gathered from the surrounding context.For each debate, we downloaded weblogs andforums that talk about the main topics (corre-sponding to the sides) of that debate.
For ex-ample, for the iPhone vs. Blackberry debate,we search the web for pages containing ?iPhone?and ?Blackberry.?
We used the Yahoo search APIand imposed the search restriction that the pagesshould contain both topics in the http URL.
Thisensured that we downloaded relevant pages.
Anaverage of 3000 documents were downloaded perdebate.We apply the method described in Section3.1 to the downloaded web pages.
That is,we find all instances of words in the lexicon,extract their targets, and mask the words withtheir polarities, yielding polarity-target pairs.
Forexample, suppose the sentence ?The interfaceis pleasing?
is in the corpus.
The systemextracts the pair ?pleasing-interface,?
which ismasked to ?positive-interface,?
which we notateas interface+.
If the target in a polarity-targetpair happens to be one of the topics, we select thepolarity-target pairs in its vicinity for further pro-cessing (the rest are discarded).
The intuition be-hind this is that, if someone expresses an opinionabout a topic, he or she is likely to follow it upwith reasons for that opinion.
The sentiments inthe surrounding context thus reveal factors that in-fluence the preference or dislike towards the topic.We define the vicinity as the same sentence plusthe following 5 sentences.Each unique target word targeti in the web cor-pus, i.e., each word used as the target of an opin-ion one or more times, is processed to generate thefollowing conditional probabilities.P (topicqj |targetpi ) =#(topicqj , targetpi )#targetpi(1)where p = {+,?
,? }
and q = {+,?
,? }
denote thepolarities of the target and the topic, respectively;j = {1, 2}; and i = {1...M}, where M is thenumber of unique targets in the corpus.
For exam-ple, P (Mac+|interface+) is the probability that?interface?
is the target of a positive opinion that isin the vicinity of a positive opinion toward ?Mac.
?Table 2 lists some of the probabilities learnedby this approach.
(Note that the neutral cases arenot shown.
)3.2.1 Interpreting the learned probabilitiesTable 2 contains examples of the learned proba-bilities.
These probabilities align with what wequalitatively found in our development data.
Forexample, the opinions towards ?Storm?
essen-tially follow the opinions towards ?Blackberry;?that is, positive opinions toward ?Storm?
are usu-ally found in the vicinity of positive opinions to-ward ?Blackberry,?
and negative opinions toward?Storm?
are usually found in the vicinity of neg-ative opinions toward ?Blackberry?
(for example,in the row for storm+, P (blackberry+|storm+)is much higher than the other probabilities).
Thus,an opinion expressed about ?Storm?
is usually theopinion one has toward ?Blackberry.?
This is ex-pected, as Storm is a type of Blackberry.
A similarexample is ipod+, which follows the opinion to-ward the iPhone.
This is interesting because an229iPod is not a phone; the association is due to pref-erence for the brand.
In contrast, the probabilitydistribution for ?phone?
does not show a prefer-ence for any one side, even though both iPhoneand Blackberry are phones.
This indicates thatopinions towards phones in general will not beable to distinguish between the debate sides.Another interesting case is illustrated by theprobabilities for ?e-mail.?
People who like e-mailcapability are more likely to praise the Blackberry,or even criticize the iPhone ?
they would thus be-long to the pro-Blackberry camp.While we noted earlier that positive evaluationsof keyboards are associated with positive evalua-tions of the Blackberry (by far the highest prob-ability in that row), negative evaluations of key-boards, are, however, not a strong discriminatingfactor.For the other entries in the table, we see thatcriticisms of batteries and the phone network aremore associated with negative sentiments towardsthe iPhones.The possibility of these various cases motivatesour approach, in which opinions and their polar-ities are considered when searching for associa-tions between debate topics and their aspects.3.3 Debate-side classificationOnce we have the probabilities collected from theweb, we can build our classifier to classify the de-bate posts.Here again, we use the process described in Sec-tion 3.1 to extract polarity-target pairs for eachopinion expressed in the post.
Let N be the num-ber of instances of polarity-target pairs in the post.For each instance Ij (j = {1...N}), we look upthe learned probabilities of Section 3.2 to createtwo scores, wj and uj :wj = P (topic+1 |targetpi ) + P (topic?2 |targetpi ) (2)uj = P (topic?1 |targetpi ) + P (topic+2 |targetpi ) (3)where targetpi is the polarity-target type of whichIj is an instance.Score wj corresponds to side1 and uj corre-sponds to side2.
A point to note is that, if a tar-get word is repeated, and it occurs in differentpolarity-target instances, it is counted as a sepa-rate instance each time ?
that is, here we accountfor tokens, not types.
Via Equations 2 and 3, weinterpret the observed polarity-target instance Ij interms of debate sides.We formulate the problem of finding the over-all side of the post as an Integer Linear Program-ming (ILP) problem.
The side that maximizes theoverall side-score for the post, given all the N in-stances Ij , is chosen by maximizing the objectivefunctionN?j=1(wjxj + ujyj) (4)subject to the following constraintsxj ?
{0, 1}, ?j (5)yj ?
{0, 1}, ?j (6)xj + yj = 1, ?j (7)xj ?
xj?1 = 0, j ?
{2..N} (8)yj ?
yj?1 = 0, j ?
{2..N} (9)Equations 5 and 6 implement binary constraints.Equation 7 enforces the constraint that each Ij canbelong to exactly one side.
Finally, Equations 8and 9 ensure that a single side is chosen for theentire post.3.4 Accounting for concessionAs described in Section 2, debate participants of-ten acknowledge the opinions held by the oppos-ing side.
We recognize such discourse constructsusing the Penn Discourse Treebank (Prasad et al,2007) list of discourse connectives.
In particu-lar, we use the list of connectives from the Con-cession and Contra-expectation category.
Exam-ples of connectives in these categories are ?while,??nonetheless,?
?however,?
and ?even if.?
We useapproximations to finding the arguments to thediscourse connectives (ARG1 and ARG2 in PennDiscourse Treebank terms).
If the connective ismid-sentence, the part of the sentence prior tothe connective is considered conceded, and thepart that follows the connective is considered non-conceded.
An example is the second sentence ofExample 3.
If, on the other hand, the connectiveis sentence-initial, the sentence is split at the firstcomma that occurs mid sentence.
The first part isconsidered conceded, and the second part is con-sidered non-conceded.
An example is the first sen-tence of Example 1.The opinions occurring in the conceded part areinterpreted in reverse.
That is, the weights corre-sponding to the sides wj and uj are interchangedin equation 4.
Thus, conceded opinions are effec-tively made to count towards the opposing side.2304 ExperimentsOn http://www.convinceme.net, the html page foreach debate contains side information for eachpost (side1 is blue in color and side2 is green).This gives us automatically labeled data for ourevaluations.
For each of the 4 debates in our testset, we use posts with at least 5 sentences for eval-uation.4.1 BaselinesWe implemented two baselines: the OpTopic sys-tem that uses topic information only, and theOpPMI system that uses topic as well as relatedword (noun) information.
All systems use thesame lexicon, as well as exactly the same pro-cesses for opinion finding and opinion-target pair-ing.The OpTopic system This system considersonly explicit mentions of the topic for the opin-ion analysis.
Thus, for this system, the stepof opinion-target pairing only finds all topic+1 ,topic?1 , topic+2 , topic?2 instances in the post(where, for example, an instance of topic+1 is apositive opinion whose target is explicitly topic1).The polarity-topic pairs are counted for each de-bate side according to the following equations.score(side1) = #topic+1 + #topic?2 (10)score(side2) = #topic?1 + #topic+2 (11)The post is assigned the side with the higher score.The OpPMI system This system finds opinion-target pairs for not only the topics, but also for thewords in the debate that are significantly related toeither of the topics.We find semantic relatedness of each noun inthe post with the two main topics of the debateby calculating the Pointwise Mutual Information(PMI) between the term and each topic over theentire web corpus.
We use the API provided by theMeasures of Semantic Relatedness (MSR)4 enginefor this purpose.
The MSR engine issues Googlequeries to retrieve documents and finds the PMIbetween any two given words.
Table 3 lists PMIsbetween the topics and the words from Table 2.Each noun k is assigned to the topic with thehigher PMI score.
That is, ifPMI(topic1,k) > PMI(topic2,k) ?k= topic1and if4http://cwl-projects.cogsci.rpi.edu/msr/PMI(topic2,k) > PMI(topic1,k) ?k= topic2Next, the polarity-target pairs are found for thepost, as before, and Equations 10 and 11 are usedto assign a side to the post as in the OpTopicsystem, except that here, related nouns are alsocounted as instances of their associated topics.word iPhone blackberrystorm 0.923 0.941phone 0.908 0.885e-mail 0.522 0.623ipod 0.909 0.976battery 0.974 0.927network 0.658 0.961keyboard 0.961 0.983Table 3: PMI of words with the topics4.2 ResultsPerformance is measured using the follow-ing metrics: Accuracy ( #Correct#Total posts ), Precision(#Correct#guessed), Recall ( #Correct#relevant ) and F-measure( 2?Precision?Recall(Precision+Recall)).In our task, it is desirable to make a pre-diction for all the posts; hence #relevant =#Total posts.
This results in Recall and Accu-racy being the same.
However, all of the systemsdo not classify a post if the post does not con-tain the information it needs.
Thus, #guessed ?#Total posts, and Precision is not the same asAccuracy.Table 4 reports the performance of four systemson the test data: the two baselines, our methodusing the preferences learned from the web cor-pus (OpPr) and the method additionally using dis-course information to reverse conceded opinions.The OpTopic has low recall.
This is expected,because it relies only on opinions explicitly towardthe topics.The OpPMI has better recall than OpTopic;however, the precision drops for some debates.
Webelieve this is due to the addition of noise.
This re-sult suggests that not all terms that are relevant toa topic are useful for determining the debate side.Finally, both of the OpPr systems are better thanboth baselines in Accuracy as well as F-measurefor all four debates.The accuracy of the full OpPr system improves,on average, by 35 percentage points over the Op-Topic system, and by 20 percentage points over the231OpPMI system.
The F-measure improves, on aver-age, by 25 percentage points over the OpTopic sys-tem, and by 17 percentage points over the OpPMIsystem.
Note that in 3 out of 4 of the debates, thefull system is able to make a guess for all of theposts (hence, the metrics all have the same values).In three of the four debates, the system us-ing concession handling described in Section 3.4outperforms the system without it, providing evi-dence that our treatment of concessions is effec-tive.
On average, there is a 3 percentage pointimprovement in Accuracy, 5 percentage point im-provement in Precision and 5 percentage point im-provement in F-measure due to the added conces-sion information.OpTopic OpPMI OpPr OpPr+ DiscFirefox Vs Internet explorer (62 posts)Acc 33.87 53.23 64.52 66.13Prec 67.74 60.0 64.52 66.13Rec 33.87 53.23 64.52 66.13F1 45.16 56.41 64.52 66.13Windows vs. Mac (15 posts)Acc 13.33 46.67 66.67 66.67Prec 40.0 53.85 66.67 66.67Rec 13.33 46.67 66.67 66.67F1 20.0 50.00 66.67 66.67SonyPs3 vs. Wii (36 posts)Acc 33.33 33.33 56.25 61.11Prec 80.0 46.15 56.25 68.75Rec 33.33 33.33 50.0 61.11F1 47.06 38.71 52.94 64.71Opera vs. Firefox (4 posts)Acc 25.0 50.0 75.0 100.0Prec 33.33 100 75.0 100.0Rec 25.0 50 75.0 100.0F1 28.57 66.67 75.0 100.0Table 4: Performance of the systems on the testdata5 DiscussionIn this section, we discuss the results from the pre-vious section and describe the sources of errors.As reported in the previous section, the OpPrsystem outperforms both the OpTopic and theOpPMI systems.
In order to analyze why OpProutperforms OpPMI, we need to compare Tables2 and 3.
Table 2 reports the conditional proba-bilities learned from the web corpus for polarity-target pairs used in OpPr, and Table 3 reports thePMI of these same targets with the debate topicsused in OpPMI.
First, we observe that the PMInumbers are intuitive, in that all the words, ex-cept for ?e-mail,?
show a high PMI relatedness toboth topics.
All of them are indeed semanticallyrelated to the domain.
Additionally, we see thatsome conclusions of the OpPMI system are simi-lar to those of the OpPr system, for example, that?Storm?
is more closely related to the Blackberrythan the iPhone.However, notice two cases: the PMI valuesfor ?phone?
and ?e-mail?
are intuitive, but theymay cause errors in debate analysis.
Because theiPhone and the Blackberry are both phones, theword ?phone?
does not have any distinguishingpower in debates.
On the other hand, the PMImeasure of ?e-mail?
suggests that it is not closelyrelated to the debate topics, though it is, in fact, adesirable feature for smart phone users, even moreso with Blackberry users.
The PMI measure doesnot reflect this.The ?network?
aspect shows a comparativelygreater relatedness to the blackberry than to theiPhone.
Thus, OpPMI uses it as a proxy forthe Blackberry.
This may be erroneous, how-ever, because negative opinions towards ?net-work?
are more indicative of negative opinions to-wards iPhones, a fact revealed by Table 2.In general, even if the OpPMI system knowswhat topic the given word is more related to, itstill does not know what the opinion towards thatword means in the debate scenario.
The OpPr sys-tem, on the other hand, is able to map it to a debateside.5.1 ErrorsFalse lexicon hits.
The lexicon is word based,but, as shown by (Wiebe and Mihalcea, 2006; Suand Markert, 2008), many subjective words haveboth objective and subjective senses.
Thus, onemajor source of errors is a false hit of a word inthe lexicon.Opinion-target pairing.
The syntactic rule-based opinion-target pairing system is a largesource of errors in the OpPr as well as the base-line systems.
Product review mining work has ex-plored finding opinions with respect to, or in con-junction with, aspects (Hu and Liu, 2004; Popescuet al, 2005); however, in our work, we need to find232information in the other direction ?
that is, giventhe opinion, what is the opinion about.
Stoyanovand Cardie (2008) work on opinion co-reference;however, we need to identify the specific target.Pragmatic opinions.
Some of the errors are dueto the fact that the opinions expressed in the postare pragmatic.
This becomes a problem especiallywhen the debate post is small, and we have fewother lexical clues in the post.
The following postis an example:(4) The blackberry is something like $150 andthe iPhone is $500.
I don?t think it?s worthit.
You could buy a iPod separate and havea boatload of extra money left over.In this example, the participant mentions thedifference in the prices in the first sentence.
Thissentence implies a negative opinion towards theiPhone.
However, recognizing this would requirea system to have extensive world knowledge.
Inthe second sentence, the lexicon does hit the word?worth,?
and, using syntactic rules, we can deter-mine it is negated.
However, the opinion-targetpairing system only tells us that the opinion is tiedto the ?it.?
A co-reference system would be neededto tie the ?it?
to ?iPhone?
in the first sentence.6 Related WorkSeveral researchers have worked on similar tasks.Kim and Hovy (2007) predict the results of anelection by analyzing forums discussing the elec-tions.
Theirs is a supervised bag-of-words sys-tem using unigrams, bigrams, and trigrams as fea-tures.
In contrast, our approach is unsupervised,and exploits different types of information.
Bansalet al (2008) predict the vote from congressionalfloor debates using agreement/disagreement fea-tures.
We do not model inter-personal exchanges;instead, we model factors that influence stancetaking.
Lin at al (2006) identify opposing perspec-tives.
Though apparently related at the task level,perspectives as they define them are not the sameas opinions.
Their approach does not involve anyopinion analysis.
Fujii and Ishikawa (2006) alsowork with arguments.
However, their focus is onargument visualization rather than on recognizingstances.Other researchers have also mined data to learnassociations among products and features.
Intheir work on mining opinions in comparative sen-tences, Ganapathibhotla and Liu (2008) look foruser preferences for one product?s features overanother?s.
We do not exploit comparative con-structs, but rather probabilistic associations.
Thus,our approach and theirs are complementary.
Anumber of works in product review mining (Huand Liu, 2004; Popescu et al, 2005; Kobayashi etal., 2005; Bloom et al, 2007) automatically findfeatures of the reviewed products.
However, ourapproach is novel in that it learns and exploits as-sociations among opinion/polarity, topics, and as-pects.Several researchers have recognized the im-portant role discourse plays in opinion analysis(Polanyi and Zaenen, 2005; Snyder and Barzilay,2007; Somasundaran et al, 2008; Asher et al,2008; Sadamitsu et al, 2008).
However, previouswork did not account for concessions in determin-ing whether an opinion supports one side or theother.More sophisticated approaches to identifyingopinions and recognizing their contextual polar-ity have been published (e.g., (Wilson et al, 2005;Ikeda et al, 2008; Sadamitsu et al, 2008)).
Thosecomponents are not the focus of our work.7 ConclusionsThis paper addresses challenges faced by opinionanalysis in the debate genre.
In our method, fac-tors that influence the choice of a debate side arelearned by mining a web corpus for opinions.
Thisknowledge is exploited in an unsupervised methodfor classifying the side taken by a post, which alsoaccounts for concessionary opinions.Our results corroborate our hypothesis that find-ing relations between aspects associated with atopic, but particularized to polarity, is more effec-tive than finding relations between topics and as-pects alone.
The system that implements this in-formation, mined from the web, outperforms theweb PMI-based baseline.
Our hypothesis that ad-dressing concessionary opinions is useful is alsocorroborated by improved performance.AcknowledgmentsThis research was supported in part by theDepartment of Homeland Security under grantN000140710152.
We would also like to thankVladislav D. Veksler for help with the MSR en-gine, and the anonymous reviewers for their help-ful comments.233ReferencesNicholas Asher, Farah Benamara, and Yvette YannickMathieu.
2008.
Distilling opinion in discourse:A preliminary study.
In Coling 2008: Companionvolume: Posters and Demonstrations, pages 5?8,Manchester, UK, August.Mohit Bansal, Claire Cardie, and Lillian Lee.
2008.The power of negative thinking: Exploiting labeldisagreement in the min-cut classification frame-work.
In Proceedings of COLING: Companion vol-ume: Posters.Kenneth Bloom, Navendu Garg, and Shlomo Argamon.2007.
Extracting appraisal expressions.
In HLT-NAACL 2007, pages 308?315, Rochester, NY.Atsushi Fujii and Tetsuya Ishikawa.
2006.
A sys-tem for summarizing and visualizing arguments insubjective documents: Toward supporting decisionmaking.
In Proceedings of the Workshop on Senti-ment and Subjectivity in Text, pages 15?22, Sydney,Australia, July.
Association for Computational Lin-guistics.Murthy Ganapathibhotla and Bing Liu.
2008.
Miningopinions in comparative sentences.
In Proceedingsof the 22nd International Conference on Compu-tational Linguistics (Coling 2008), pages 241?248,Manchester, UK, August.Minqing Hu and Bing Liu.
2004.
Mining opinion fea-tures in customer reviews.
In AAAI-2004.Daisuke Ikeda, Hiroya Takamura, Lev-Arie Ratinov,and Manabu Okumura.
2008.
Learning to shiftthe polarity of words for sentiment classification.
InProceedings of the Third International Joint Confer-ence on Natural Language Processing (IJCNLP).Soo-Min Kim and Eduard Hovy.
2007.
Crystal: An-alyzing predictive opinions on the web.
In Pro-ceedings of the 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 1056?1064.Nozomi Kobayashi, Ryu Iida, Kentaro Inui, and YujiMatsumoto.
2005.
Opinion extraction using alearning-based anaphora resolution technique.
InProceedings of the 2nd International Joint Confer-ence on Natural Language Processing (IJCNLP-05),poster, pages 175?180.Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, andAlexander Hauptmann.
2006.
Which side are youon?
Identifying perspectives at the document andsentence levels.
In Proceedings of the 10th Con-ference on Computational Natural Language Learn-ing (CoNLL-2006), pages 109?116, New York, NewYork.Livia Polanyi and Annie Zaenen.
2005.
Contextualvalence shifters.
In Computing Attitude and Affectin Text.
Springer.Ana-Maria Popescu, Bao Nguyen, and Oren Et-zioni.
2005.
OPINE: Extracting product fea-tures and opinions from reviews.
In Proceedingsof HLT/EMNLP 2005 Interactive Demonstrations,pages 32?33, Vancouver, British Columbia, Canada,October.
Association for Computational Linguistics.R.
Prasad, E. Miltsakaki, N. Dinesh, A. Lee, A. Joshi,L.
Robaldo, and B. Webber, 2007.
PDTB 2.0 Anno-tation Manual.Kugatsu Sadamitsu, Satoshi Sekine, and Mikio Ya-mamoto.
2008.
Sentiment analysis based onprobabilistic models using inter-sentence informa-tion.
In European Language Resources Associa-tion (ELRA), editor, Proceedings of the Sixth In-ternational Language Resources and Evaluation(LREC?08), Marrakech, Morocco, May.Benjamin Snyder and Regina Barzilay.
2007.
Multipleaspect ranking using the good grief algorithm.
InProceedings of NAACL-2007.Swapna Somasundaran, Janyce Wiebe, and Josef Rup-penhofer.
2008.
Discourse level opinion interpre-tation.
In Proceedings of the 22nd InternationalConference on Computational Linguistics (Coling2008), pages 801?808, Manchester, UK, August.Veselin Stoyanov and Claire Cardie.
2008.
Topicidentification for fine-grained opinion analysis.
InProceedings of the 22nd International Conferenceon Computational Linguistics (Coling 2008), pages817?824, Manchester, UK, August.
Coling 2008 Or-ganizing Committee.Fangzhong Su and Katja Markert.
2008.
Fromword to sense: a case study of subjectivity recogni-tion.
In Proceedings of the 22nd International Con-ference on Computational Linguistics (COLING-2008), Manchester, UK, August.Janyce Wiebe and Rada Mihalcea.
2006.
Word senseand subjectivity.
In Proceedings of COLING-ACL2006.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-level sentiment analysis.
In HLT-EMNLP, pages347?354, Vancouver, Canada.234
