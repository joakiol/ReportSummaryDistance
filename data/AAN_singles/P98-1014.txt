Processing Unknown Words in HPSGPetra Barg and Markus Walther*Seminar ftir Allgemeine SprachwissenschaftHeinrich-Heine-Universit~it Dt sseldorfUniversit~itsstr.
1, D-40225 Dtisseldorf, Germany{barg, walther}@ling, uni-duesseldor f. deAbstractThe lexical acquisition system presented in this pa-per incrementally updates linguistic properties of un-known words inferred from their surrounding con-text by parsing sentences with an HPSG grammarfor German.
We employ a gradual, information-based concept of "unknownness" providing a uni-form treatment for the range of completely known tomaximally unknown lexical entries.
"Unknown" in-formation is viewed as revisable information, whichis either generalizable or specializable.
Updatingtakes place after parsing, which only requires amod-ified lexical lookup.
Revisable pieces of informa-tion are identified by grammar-specified declarationswlfich provide access paths into the parse featurestructure.
The updating mechanism revises the cor-responding places in the lexical feature structures iffthe context actually provides new information.
Forrevising generalizable inlbrmation, type union is re-quired.
A worked-out example demonstrates the in-ferential capacity of our implemented system.1 IntroductionIt is a remarkable fact that humans can often un-derstand sentences containing unknown words, in-fer their grammatical properties and incrementallyrefine hypotheses about hese words when encoun-tering later instances.
In contrast, many current NLPsystems till presuppose a complete l xicon.
Notableexceptions include Zernik (1989), Erbach (1990),Hastings & Lytinen (1994).
See Zernik for an intro-duction to the general issues involved.This paper describes an HPSG-based systemwhich can incrementally earn and refine proper-ties of unknown words after parsing individual sen-*This work was carried out within the Sonderforschungs-bereich 282 "Theorie des Lexikons' (project B3), funded by theGerman Federal Research Agency DFG.
We thank James Kil-bury and members of the B3 group for fruitful discussion.tences.
It focusses on extracting linguistic proper-ties, as compared to e.g.
general concept learning(Hahn, Klenner & Schnattinger 1996).
Unlike Er-bach (1990), however, it is not confined to sim-ple morpho-syntactic information but can also han-dle selectional restrictions, emantic types and argu-ment structure.
Finally, while statistical approacheslike Brent (1991) can gather e.g.
valence informa-tion from large corpora, we are more interested infull grammatical processing of individual sentencesto maximally exploit each context.The following three goals serve to structureour model.
It should i) incorporate a gradual,information-based conceptualization f "unknown-ness".
Words are not unknown as a whole, butmay contain unlmown, i.e.
revisable pieces of infor-mation.
Consequently, even known words can un-dergo revision to e.g.
acquire new senses.
This viewreplaces the binary distinction between open andclosed class words.
It should ii) maximally exploitthe rich representations and modelling conventionsof HPSG and associated formalisms, with essen-tially the same grammar and lexicon as comparedto closed-lexicon approaches.
This is important bothto facilitate reuse of existing grammars and to en-able meaningful feedback for linguistic theorizing.Finally, it should iii) possess domain-independent in-ference and lexicon-updating capabilities.
The gram-mar writer must be able to fully declare which piecesof information are open to revision.The system was implemented using MicroCUF,a simplified version of the CUF typed unificationformalism (DOrre & Dorna 1993) that we imple-mented in SICStus Prolog.
It shares both the featurelogic and the definite clause extensions with its bigbrother, but substitutes a closed-world type systemfor CUF's open-world regime.
A feature of our typesystem implementation that will be significant lateron is that type information i  internal feature struc-91tures (FSs) can be easily updated.The HPSG grammar developed with MicroCUFmodels a fragment of German.
Since our focus is onthe lexicon, the range of syntactic variation treatedis currently limited to simplex sentences with canon-ical word order.
We have incorporated some recentdevelopments of HPSG, esp.
the revisions of Pol-lard & Sag (1994, ch.
9), Manning & Sag (1995)'sproposal for an independent level of argument s ruc-ture and Bouma (1997)'s use of argument structureto eliminate procedural lexical rules in favour of re-lational constraints.
Our elaborate ontology of se-mantic types - useful for non-trivial acquisition ofselectional restrictions and nominal sorts - was de-rived from a systematic corpus study of a biologicaldomain (Knodel 1980, 154-188).
The grammar alsocovers all valence classes encountered in the corpus.As for the lexicon format, we currently list full formsonly.
Clearly, a morphology component would sup-ply more contextual information from known affixesbut would still require the processing of unknownstems.2 Incrementa l  Lexical Acquis i t ionWhen compared to a previous instance, a new sen-tential context can supply either identical, more spe-cial, more general, or even conflicting informationalong a given dimension.
Example pairs illustratingthe latter three relationships are given under (1)-(3)(words assumed to be unknown in bold face).
(1) a. Im Axon tritt ein Ruhepotential uf.
'a rest potential occurs in the axon'b.
Das Potential wandert tiber das Axon.
'the potential travels along the axon'(2) a. Das Ohr reagiert auf akustische Reize.
'the ear reacts to acoustic stimuli'b.
Ein Sinnesorgan reagiert auf Reize.
'a sense organ reacts to stimuli'(3) a.
Die Nase ist ftir Geriiche sensibel.
'the nose is sensitive to smells'b.
Die sensible Nase reagiert auf Gertiche.
'the sensitive nose reacts to smells'In contrast to (la), which provides the informationthat the gender of Axon is not feminine (via im), thecontext in (lb) is more specialized, assigning neutergender (via das).
Conversely, (2b) differs from (2a)in providing amore general selectional restriction forthe subject of reagiert, since sense organs includeears as a subtype.
Finally, the adjective sensibel isused predicatively in (3a), but attributively in (3b).The usage types must be formally disjoint, becausesome German adjectives allow for just one usage(ehemalig 'former, attr.
', schuld 'guilty, pred.
').On the basis of contrasts like those in (1)-(3) itmakes sense to statically assign revisable informa-tion to one of two classes, namely specializable orgeneralizable.
1 Apart from the specializable kinds'semantic type of nouns' and 'gender', the inflec-tional class of nouns is another candidate (given amorphological component).
Generalizable kinds ofinformation i clude 'selectional restrictions of verbsand adjectives', predicative vs attributive usage ofadjectives' as well as 'case and form of PP argu-ments' and 'valence class of verbs'.
Note that spe-cializable and generalizable information can cooccurin a given lexical entry.
A particular kind of informa-tion may also figure in both classes, as e.g.
seman-tic type of nouns and selectional restrictions of verbsare both drawn from the same semantic ontology.
Yetthe former must be invariantly specialized - indepen-dent of the order in which contexts are processed -,whereas electional restrictions on NP complementsshould only become more general with further con-texts.2.1 RepresentationWe require all revisable or updateable information tobe expressible as formal types.
2As relational clausescan be defined to map types to FSs, this is not muchof a restriction in practice.
Figure 1 shows a rele-vant fragment.
Whereas the combination of special-nom_sem / \ I ~~ .
.
.
~  pred attr n?n I fern ?era son)omasc neutsound smell nose earFigure 1: Excerpt from type hierarchyizable information translates into simple type unifi-cation (e.g.
non_fern A neut = neut), combining1The different behaviour underlying this classification haspreviously been noted by e.g.
Erbach (1990) and Hastings &Lytinen (1994) but received either no implementational st tus orno systematic association with arbitrary kinds of information.2In HPSG types are sometimes also referred to as sorts.92generalizable information requires type union (e.g.pred V attr = prd).
The latter might pose problemsfor type systems requiring the explicit definition ofall possible unions, corresponding to least commonsupertypes.
However, type union is easy for (Mi-cro)CUF and similar systems which allow for arbi-trary boolean combinations of types.
Generalizableinformation exhibits another peculiarity: we needa disjoint auxiliary type u_g to correctly mark theinitial unknown information state) This is because'content' types like prd, pred, attr are to be inter-preted as recording what contextual information wasencountered in the past.
Thus, using any of these toprespecify the initial value - either as the side-effectof a feature appropriateness declaration (e.g.
prd) orthrough grammar-controlled specification (e.g.
pred,attr) - would be wrong (cf.
prdiniti~t V attr = prd,but u_ginitia l V attr = u_g V attr).Generalizable information evokes another ques-tion: can we simply have types like those in fig.
1within HPSG signs and do in-place type union, justlike type unification?
The answer is no, for essen-tially two reasons.
First, we still want to rule outungrammatical constructions through (type) unifica-tion failure of coindexed values, so that generalizabletypes cannot ahvays be combined by nonfailing typeunion (e.g.
*der sensible Geruch 'the sensitive smell'must be ruled out via sense_organ A smell = J_).We would ideally like to order all type unificationspertaining to a value before all unions, but this vi-olates the order independence of constraint solv-ing.
Secondly, we already know that a given infor-mational token can simultaneously be generalizableand specializable, e.g.
by being coindexed throughHPSG's valence principle.
However, simultaneousin-place union and unification is contradictory.To avoid these problems and keep the declarativemonotonic setting, we employ two independent fea-tures gen and clxt.
ctxt is the repository of contex-tually unified information, where conflicts result inungrammaticality, gen holds generalizable informa-tion.
Since all gen values contain u_g as a type dis-junct, they are always unifiable and thus not restric-tive during the parse.
To nevertheless get correct genvalues we perform type union after parsing, i.e.
dur-ing lexicon update.
We will see below how this worksout.3Actually, the situation is more symmetrical, as we need adual type u_s to correctly mark "unknown" specializable infor-mation.
This prevents incorrect updating of known information.However, u_~ is unnecessary for the examples presented below.The last representational issue is how to identityrevisable information in (substructures ol) the parseFS.
For this purpose the grammar defines revisabilityclauses like the following:(4) a. generalizable(\[~\], \[~) :=synsemlloelcatl head \[adj genb.
specializable(\[\[I) :=\[ \[cat lhead noun "1\]\[synsem J oc \[cont i ind 1 gend2.2 ProcessingThe first step in processing sentences with unknownor revisable words consists of conventional parsing.Any HPSG-compatible parser may be used, subjectto the obvious requirement that lexical lookup mustnot fail if a word's phonology is unknown.
A canon-ical entry for such unknown words is defined as thedisjunction of maximally underspecified generic lex-ical entries for nouns, adjectives and verbs.The actual updating of lexical entries consists offour major steps.
Step 1 projects the parse FS derivedfrom the whole sentence onto all participating wordtokens.
This results in word FSs which are contextu-ally enriched (as compared to their original lexiconstate) and disambiguated (choosing the compatibledisjunct per parse solution if the entry was disjunc-tive).
It then filters the set of word FSs by unificationwith the right-hand side of revisability clauses like in(4).
The output of step 1 is a list of update candidatesfor those words which were unifiable.Step 2 determines concrete update values for eachword: for each matching generalizable clause wetake the type union of the gen value of the old, lexicalstate of the word (LexGen) with the ctxt value of itsparse projection (Ctxt): TU  = LexGenUCtzt .
Foreach matching specializable(Spec) lause we takethe parse value Spec.Step 3 checks whether updating would make a dif-ference w.r.t, the original exical entry of each word.The condition to be met by generalizable informationis that TU D LexGen, for specializable informationwe similarly require Spec C LexSpec.In step 4 the lexical entries of words surviving step3 are actually modified.
We retract he old lexical en-try, revise the entry and re-assert i .
For words neverencountered before, revision must obviously be pre-ceded by making a copy of the generic unknown en-try, but with the new word's phonology.
Revision it-self is the destructive modification of type informa-93tion according to the values determined in step 2,at the places in a word FS pointed to by the revis-ability clauses.
This is easy in MicroCUF, as typesare implemented via the attributed variable mecha-nism of SICStus Prolog, which allows us to substi-tute the type in-place.
In comparison, general updat-ing of Prolog-encoded FSs would typically requirethe traversal of large structures and be dangerous ifstructure-sharing between substituted and unaffectedparts existed.
Also note that we currently assumeDNF-expanded entries, so that updates work on thecontextually selected isjunct.
This can be motivatedby the advantages of working with presolved struc-tures at run-time, avoiding description-level opera-tions and incremental grammar recompilation.2.3 A Worked-Out ExampleWe will illustrate how incremental lexical revisionworks by going through the examples under (5)-(7).
(5) Die Nase ist ein Sinnesorgan.
'the nose is a sense organ'(6) Das Ohr perzipiert.
'the ear perceives'(7) Eine verschnupfte Nase perzipiert denGestank.
'a bunged up nose perceives the stench'The relevant substructures corresponding to the lex-ical FSs of the unknown noun and verb involvedare depicted in fig.
2.
The leading feature pathssynsemlloclcont for Nase and synsemlloclcatlarg-stfor perzipiert have been omitted.After parsing (5) the gender of the unknown ounNase is instantiated to fern by agreement with thedeterminer die.
As the specializable clause (4b)matches and the gend parse value differs from itslexical value gender, gender is updated to fern.
Fur-thermore, the object's emantic type has percolatedto the subject Nase.
Since the objecrs sense_organtype differs from generic initial nom_sem, Nase's ctxtvalue is updated as well.
In place of the still nonex-isting entry for perzipiert, we have displayed the rel-evant part of the generic unknown verb entry.Having parsed (6) the system then knows thatperzipiert can be used intransitively with a nomi-native subject referring to ears.
Formally, an HPSGmapping principle was successful in mediating be-tween surface subject and complement lists and theargument list.
Argument list instantiations are them-selves related to corresponding types by a furtherNaseafter (5)gend fem \]gen u.g |etxt sense.organJperzipiertgen u-g \]ctxt arg.~truclafter (6)gend fem \]gen u_g |ctxt sense.organJafter (7)gend fem \]gen u.g /ctxt nose Igen u..gVnpnom \]ctxt arg.struc |args(\[IoclcontLctxtnom_~em\] \]rgenu_gvear\]\] -\]J\lgen u-gVnpnomVnpnom.npacc \]ctxt arg.struc I\[, , .
\[gen u_gVsense~rgan\]\] I/\[,OC ICOmLctxtnom_sem j \ ] , \ \ ]\ 'oc Icon, g= UogV';en : l I /Figure 2: Updates on lexical FSsmapping.
On the basis of this type classification ofargument structure patterns, the parse derived thectxt value npnom.
Since gen values are generaliz-able, this new value is unioned with the old lexi-cal gen value.
Note that ctxt is properly unaffected.The first (subject) element on the aros list itself istargeted by another revisability clause.
This has theside-effect of further instantiating the underspecifiedlexical FS.
Since selectional restrictions on nominalsubjects must become more general with new con-textual evidence, the union of ear and the old valueu_g is indeed appropriate.Sentence (7) first of all provides more specific evi-dence about the semantic type of partially knownNase by way of attributive modification through ver-schnupfte.
The system detects this through the differ-ence between lexical ctxt value sense_organ and theparse value nose, so that the entry is specialized ac-cordingly.
Since the subject's ynsem value is coin-dexed with the first aros element, \[etxt nose\] simulta-neously appears in the FS ofperzipiert.
However, therevisability clause matching there is of class general-izable, so union takes place, yielding ear V nose =sense_organ (w.r.t.
the simplified ontology of fig.1 used in this paper).
An analogous match with thesecond element of ar9 s identifies the necessary up-date to be the unioning-in of smell, the semantic typeof Gestank.
Finally, the system has learned that anaccusative NP object can cooccur with perzipiert, sothe argument structure type of gen receives anotherupdate through union with npnom_npacc.943 DiscussionThe incremental lexical acquisition approach de-scribed above attains the goals stated earlier.
It re-alizes a gradual, information-based conceptualiza-tion of unknownness by providing updateable formaltypes - classified as either generalizable or special-izable - together with grammar-defined revisabilityclauses.
It maximally exploits standard HPSG rep-resentations, requiring moderate rearrangements ingrammars at best while keeping with the standardassumptions of typed unification formalisms.
Onenoteworthy demand, however, is the need for a typeunion operation.
Parsing is conventional modulo amodified lexical lookup.
The actual exical revisionis done in a domain-independent postprocessing stepguided by the revisability clauses.Of course there are areas requiring further consid-eration.
In contrast to humans, who seem to leap toconclusions based on incomplete vidence, our ap-proach employs a conservative form of generaliza-tion, taking the disjunction of actually observed val-ues only.
While this has the advantage ofnot leadingto overgeneralization, the requirement of having toencounter all subtypes in order to infer their com-mon supertype is not realistic (sparse-data problem).In (2) sense_organ as the semantic type of the firstargument ofperzipiert is only acquired because thesimplified hierarchy in fig.
1 has nose and ear as itsonly subtypes.
Here the work of Li & Abe (1995)who use the MDL principle to generalize over theslots of observed case frames might prove fruitful.An important question is how to administratealternative parses and their update hypotheses.
InDas Aktionspotential erreicht den Dendriten 'theaction potential reaches the dendrite(s)', Dendritenis ambiguous between acc.sg, and dat.pl., givingrise to two valence hypotheses npnom_npacc andnpnom_npdat for erreicht.
Details remain to beworked out on how to delay the choice between suchalternative hypotheses until further contexts provideenough information.Another topic concerns the treatment of 'cooc-currence restrictions'.
In fig.
2 the system has in-dependently generalized over the selectional restric-tions for subject and object, yet there are clear caseswhere this overgenerates (e.g.
*Das Ohr perzipiertden Gestank 'the ear perceives the stench').
An ideaworth exploring is to have a partial, extensible ist oftype cooccurrences, which is traversed by a recursiveprinciple at parse time.A more general issue is the apparent antagonism95between the desire to have both sharp grammaticalpredictions and continuing openness to contextualrevision.
If after parsing (7) we transfer the fact thatsmells are acceptable objects to perzipiert into the re-stricting ctxt feature, a later usage with an object oftype sound falls.
The opposite case concerns newlyacquired specializable values.
If in a later contextthese are used to update a gen value, the result maybe too general.
It is a topic of future research whento consider information certain and when to make re-visable information restrictive.ReferencesBouma, G. (1997).
Valence Alternation without Lexi-cal Rules.
In: Papers from the seventh CLIN Meet-ing 1996, Eindhoven, 25--40.Brent, M. R. (1991).
Automatic Acquisition of Subcat-egorization Frames From Untagged Text.
In: Pro-ceedings of 29th ACL, Berkeley, 209-214.D0rre, J.
& M. Dorna (1993).
CUF - A Formalism forLinguistic Knowledge Representation.
I : J.
DOrre(Exl.
), ComputationaI Aspects of Constraint-BasedLinguistic Description.
IMS, Universitat Stuttgart.Deliverable R1.2.A, DYANA-2 - ESPRIT Project6852.Erbach, G. (1990).
Syntactic Processing of Un-known Words.
IWBS Report 131, Institutefor Knowledge-Based Systems (IWBS), IBMStuttgart.Hahn, U., M. Klenner & K. Schnattinger (1996).Learning from Texts - A Terminological Meta-Reasoning Perspective.
In: S. Wermter, E. Riloff& G. Scheler (Ed.
), Connectionist, Statistical, andSymbolic Approaches to Learning for Natural Lan-guage Processing, 453--468.
Berlin: Springer.Hastings, P. M. & S. L. Lytinen (1994).
The Ups andDowns of Lexical Acquisition.
In: Proceedings ofAAAI'94, 754-759.Knodel, H. (1980).
Linder Biologie - Lehrbuch fardie Oberstufe.
Stuttgart: J.B. Metzlersche Verlags-buchhandlung.Li, H. & N. Abe (1995).
Generalizing Case Frames Us-ing a Thesaurus and the MDL Principle.
In: Pro-ceedings of Recent Advantages in Natural Lan-guage Processing, Velingrad, Bulgaria, 239-248.Manning, C. & I.
Sag (1995).
Dissociations betweenargument s ructure and grammatical relations.
Ms.,Stanford University.Pollard, C. & I.
Sag (1994).
Head-Driven PhraseStructure Grammar.
Chicago University Press.Zernik, U.
(1989).
Paradigms in Lexical Acquisition.In: U. Zernik (Ed.
), Proceedings of the First Inter-national Lexical Acquisition Workshop, Detroit.
