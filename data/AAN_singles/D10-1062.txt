Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 636?645,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsEffects of Empty Categories on Machine TranslationTagyoung Chung and Daniel GildeaDepartment of Computer ScienceUniversity of RochesterRochester, NY 14627AbstractWe examine effects that empty categories haveon machine translation.
Empty categories areelements in parse trees that lack correspondingovert surface forms (words) such as droppedpronouns and markers for control construc-tions.
We start by training machine trans-lation systems with manually inserted emptyelements.
We find that inclusion of someempty categories in training data improves thetranslation result.
We expand the experimentby automatically inserting these elements intoa larger data set using various methods andtraining on the modified corpus.
We show thateven when automatic prediction of null ele-ments is not highly accurate, it neverthelessimproves the end translation result.1 IntroductionAn empty category is an element in a parse treethat does not have a corresponding surface word.They include traces such as Wh-traces which indi-cate movement operations in interrogative sentencesand dropped pronouns which indicate omission ofpronouns in places where pronouns are normallyexpected.
Many treebanks include empty nodes inparse trees to represent non-local dependencies ordropped elements.
Examples of the former includetraces such as relative clause markers in the PennTreebank (Bies et al, 1995).
An example of the lat-ter include dropped pronouns in the Korean Tree-bank (Han and Ryu, 2005) and the Chinese Tree-bank (Xue and Xia, 2000).In languages such as Chinese, Japanese, and Ko-rean, pronouns are frequently or regularly droppedwhen they are pragmatically inferable.
These lan-guages are called pro-drop languages.
Dropped pro-nouns are quite a common phenomenon in these lan-guages.
In the Chinese Treebank, they occur oncein every four sentences on average.
In Korean theTreebank, they are even more frequent, occurringin almost every sentence on average.
Translatingthese pro-drop languages into languages such as En-glish where pronouns are regularly retained couldbe problematic because English pronouns have to begenerated from nothing.There are several different strategies to counterthis problem.
A special NULL word is typicallyused when learning word alignment (Brown et al,1993).
Words that have non-existent counterpartscan be aligned to the NULL word.
In phrase-basedtranslation, the phrase learning system may be ableto learn pronouns as a part of larger phrases.
If thelearned phrases include pronouns on the target sidethat are dropped from source side, the system maybe able to insert pronouns even when they are miss-ing from the source language.
This is an often ob-served phenomenon in phrase-based translation sys-tems.
Explicit insertion of missing words can alsobe included in syntax-based translation models (Ya-mada and Knight, 2001).
For the closely relatedproblem of inserting grammatical function particlesin English-to-Korean and English-to-Japanese ma-chine translation, Hong et al (2009) and Isozaki etal.
(2010) employ preprocessing techniques to addspecial symbols to the English source text.In this paper, we examine a strategy of automat-ically inserting two types of empty elements fromthe Korean and Chinese treebanks as a preprocess-636Korean*T* 0.47 trace of movement(NP *pro*) 0.88 dropped subject or object(WHNP *op*) 0.40 empty operator in relativeconstructions*?
* 0.006 verb deletion, VP ellipsis,and othersChinese(XP (-NONE- *T*)) 0.54 trace of A?-movement(NP (-NONE- *)) 0.003 trace of A-movement(NP (-NONE- *pro*)) 0.27 dropped subject or object(NP (-NONE- *PRO*)) 0.31 control structures(WHNP (-NONE- *OP*)) 0.53 empty operator in relativeconstructions(XP (-NONE- *RNR*)) 0.026 right node raising(XP (-NONE- *?
*)) 0 othersTable 1: List of empty categories in the Korean Treebank(top) and the Chinese Treebank (bottom) and their per-sentence frequencies in the training data of initial experi-ments.ing step.
We first describe our experiments with datathat have been annotated with empty categories, fo-cusing on zero pronouns and traces such as thoseused in control constructions.
We use these an-notations to insert empty elements in a corpus andtrain a machine translation system to see if they im-prove translation results.
Then, we illustrate differ-ent methods we have devised to automatically insertempty elements to corpus.
Finally, we describe ourexperiments with training machine translation sys-tems with corpora that are automatically augmentedwith empty elements.
We conclude this paper bydiscussing possible improvements to the differentmethods we describe in this paper.2 Initial experiments2.1 SetupWe start by testing the plausibility of our ideaof preprocessing corpus to insert empty cate-gories with ideal datasets.
The Chinese Treebank(LDC2005T01U01) is annotated with null elementsand a portion of the Chinese Treebank has beentranslated into English (LDC2007T02).
The KoreanTreebank version 1.0 (LDC2002T26) is also anno-tated with null elements and includes an Englishtranslation.
We extract null elements along withtree terminals (words) and train a simple phrase-BLEUChi-Eng No null elements 19.31w/ *pro* 19.68w/ *PRO* 19.54w/ *pro* and *PRO* 20.20w/ all null elements 20.48Kor-Eng No null elements 20.10w/ *pro* 20.37w/ all null elements 19.71Table 2: BLEU score result of initial experiments.Each experiment has different empty categories added in.
*PRO* stands for the empty category used to mark con-trol structures and *pro* indicates dropped pronouns forboth Chinese and Korean.based machine translation system.
Both datasetshave about 5K sentences and 80% of the data wasused for training, 10% for development, and 10%for testing.We used Moses (Koehn et al, 2007) to trainmachine translation systems.
Default parameterswere used for all experiments.
The same numberof GIZA++ (Och and Ney, 2003) iterations wereused for all experiments.
Minimum error rate train-ing (Och, 2003) was run on each system afterwards,and the BLEU score (Papineni et al, 2002) was cal-culated on the test sets.There are several different empty categories inthe different treebanks.
We have experimented withleaving in and out different empty categories for dif-ferent experiments to see their effect.
We hypoth-esized that nominal phrasal empty categories suchas dropped pronouns may be more useful than otherones, since they are the ones that may be missing inthe source language (Chinese and Korean) but havecounterparts in the target (English).
Table 1 summa-rizes empty categories in Chinese and Korean tree-bank and their frequencies in the training data.2.2 ResultsTable 2 summarizes our findings.
It is clear thatnot all elements improve translation results when in-cluded in the training data.
For the Chinese to En-glish experiment, empty categories that mark con-trol structures (*PRO*), which serve as the sub-ject of a dependent clause, and dropped pronouns(*pro*), which mark omission of pragmatically in-637word P (e | ?pro?)
word P (e | ?PRO?
)the 0.18 to 0.45i 0.13 NULL 0.10it 0.08 the 0.02to 0.08 of 0.02they 0.05 as 0.02Table 3: A lexical translation table from the Korean-English translation system (left) and a lexical transla-tion from the Chinese-English translation system (right).For the Korean-English lexical translation table, the leftcolumn is English words that are aligned to a droppedpronoun (*pro*) and the right column is the conditionalprobability of P (e | ?pro?).
For the Chinese-Englishlexical translation table, the left column is English wordsthat are aligned to a control construction marker (*PRO*)and the right column is the conditional probability ofP (e | ?PRO?
).ferable pronouns, helped to improve translation re-sults the most.
For the Korean to English experi-ment, the dropped pronoun is the only empty cate-gory that seems to improve translation.For the Korean to English experiment, we alsotried annotating whether the dropped pronouns are asubject, an object, or a complement using informa-tion from the Treebank?s function tags, since Englishpronouns are inflected according to case.
However,this did not yield a very different result and in factwas slightly worse.
This is possibly due to data spar-sity created when dropped pronouns are annotated.Dropped pronouns in subject position were the over-whelming majority (91%), and there were too fewdropped pronouns in object position to learn goodparameters.2.3 AnalysisTable 3 and Table 4 give us a glimpse of why havingthese empty categories may lead to better transla-tion.
Table 3 is the lexical translation table for thedropped pronoun (*pro*) from the Korean to En-glish experiment and the marker for control con-structions (*PRO*) from the Chinese to English ex-periment.
For the dropped pronoun in the Koreanto English experiment, although there are errors,the table largely reflects expected translations of adropped pronoun.
It is possible that the system is in-serting pronouns in right places that would be miss-ing otherwise.
For the control construction markerin the Chinese to English experiment, the top trans-lation for *PRO* is the English word to, which is ex-pected since Chinese clauses that have control con-struction markers often translate to English as to-infinitives.
However, as we discuss in the next para-graph, the presence of control construction markersmay affect translation results in more subtle wayswhen combined with phrase learning.Table 4 shows how translations from the systemtrained with null elements and the system trainedwithout null elements differ.
The results are takenfrom the test set and show extracts from larger sen-tences.
Chinese verbs that follow the empty node forcontrol constructions (*PRO*) are generally trans-lated to English as a verb in to-infinitive form, agerund, or a nominalized verb.
The translation re-sults show that the system trained with this null el-ement (*PRO*) translates verbs that follow the nullelement largely in such a manner.
However, it maynot be always closest to the reference.
It is exempli-fied by the translation of one phrase.Experiments in this section showed that prepro-cessing the corpus to include some empty elementscan improve translation results.
We also identifiedwhich empty categories maybe helpful for improv-ing translation for different language pairs.
In thenext section, we focus on how we add these ele-ments automatically to a corpus that is not annotatedwith empty elements for the purpose of preprocess-ing corpus for machine translation.3 Recovering empty nodesThere are a few previous works that have attemptedrestore empty nodes for parse trees using the PennEnglish Treebank.
Johnson (2002) uses rather sim-ple pattern matching to restore empty categories aswell as their co-indexed antecedents with surpris-ingly good accuracy.
Gabbard et al (2006) presenta more sophisticated algorithm that tries to recoverempty categories in several steps.
In each step, oneor more empty categories are restored using pat-terns or classifiers (five maximum-entropy and twoperceptron-based classifiers to be exact).What we are trying to achieve has obvious simi-larity to these previous works.
However, there areseveral differences.
First, we deal with differentlanguages.
Second, we are only trying to recover638Chinese English Reference System trained w/ nulls System trained w/o nulls*PRO*??
implementing implementation implemented*PRO*????
have gradually formed to gradually form gradually formed*PRO*??????
attracting foreign investment attracting foreign investment attract foreign capitalTable 4: The first column is a Chinese word or a phrase that immediately follows empty node marker for Chinesecontrol constructions.
The second column is the English reference translation.
The third column is the translationoutput from the system that is trained with the empty categories added in.
The fourth column is the translation outputfrom the system trained without the empty categories added, which was given the test set without the empty categories.Words or phrases and their translations presented in the table are part of larger sentences.a couple of empty categories that would help ma-chine translation.
Third, we are not interested in re-covering antecedents.
The linguistic differences andthe empty categories we are interested in recoveringmade the task much harder than it is for English.
Wewill discuss this in more detail later.From this section on, we will discuss onlyChinese-English translation because Chinesepresents a much more interesting case, since weneed to recover two different empty categories thatare very similarly distributed.
Data availabilitywas also a consideration since much larger datasets(bilingual and monolingual) are available forChinese.
The Korean Treebank has only about 5Ksentences, whereas the version of Chinese Treebankwe used includes 28K sentences.The Chinese Treebank was used for all experi-ments that are mentioned in the rest of this Section.Roughly 90% of the data was used for the trainingset, and the rest was used for the test set.
As we havediscussed in Section 2, we are interested in recover-ing dropped pronouns (*pro*) and control construc-tion markers (*PRO*).
We have tried three differentrelatively simple methods so that recovering emptyelements would not require any special infrastruc-ture.3.1 Pattern matchingJohnson (2002) defines a pattern for empty node re-covery to be a minimally connected tree fragmentcontaining an empty node and all nodes co-indexedwith it.
Figure 1 shows an example of a pattern.
Weextracted patterns according this definition, and itbecame immediately clear that the same definitionthat worked for English will not work for Chinese.Table 5 shows the top five patterns that match con-trol constructions (*PRO*) and dropped pronouns(*pro*).
The top pattern that matches *pro* and*PRO* are both exactly the same, since the pat-tern will be matched against parse trees where emptynodes have been deleted.When it became apparent that we cannot use thesame definition of patterns to successfully restoreempty categories, we added more context to the pat-terns.
Patterns needed more context for them to beable to disambiguate between sites that need to beinserted with *pro*s and sites that need to be in-serted with *PRO*s. Instead of using minimal treefragments that matched empty categories, we in-cluded the parent and siblings of the minimal treefragment in the pattern (pattern matching method1).
This way, we gained more context.
However,as can be seen in Table 5, there is still a lot of over-lap between patterns for the two empty categories.However, it is more apparent that at least we canchoose the pattern that will maximize matches forone empty category and then discard that pattern forthe other empty category.We also tried giving patterns even more contextby including terminals if preterminals are present inthe pattern (pattern matching method 2).
In this way,we are able have more context for patterns such as(VP VV (IP ( NP (-NONE- *PRO*) ) VP)) by know-ing what the verb that precedes the empty categoryis.
Instead of the original pattern, we would havepatterns such as (VP (VV??)
( IP ( NP (-NONE-*PRO*)) VP)).
We are able to gain more context be-cause some verbs select for a control construction.The Chinese verb ??
generally translates to En-glish as to decide and is more often followed bya control construction than by a dropped pronoun.Whereas the pattern (VP (VV ??)
( IP ( NP (-NONE- *PRO*)) VP)) occurred 154 times in thetraining data, the pattern (VP (VV ??)
(IP (NP(-NONE- *pro*)) VP)) occurred only 8 times in the639IPNP-SBJ-NONE-*pro*VPVV??NP-OBJPN??PU??
IPVPVV??NP-OBJPN??PU?
(IP (NP-SBJ (-NONE- *pro*)) VP PU) (IP VP PU)Figure 1: An example of a tree with an empty node (left), the tree stripped of an empty node (right), and a pattern thatmatches the example.
Sentences are parsed without empty nodes and if a tree fragment (IP VP PU) is encountered ina parse tree, the empty node may be inserted according to the learned pattern (IP (NP-SBJ (-NONE- *pro*)) VP PU).
*PRO* *pro*Count Pattern Count Pattern12269 ( IP ( NP (-NONE- *PRO*) ) VP ) 10073 ( IP ( NP (-NONE- *pro*) ) VP )102 ( IP PU ( NP (-NONE- *PRO*) ) VP PU ) 657 ( IP ( NP (-NONE- *pro*) ) VP PU )14 ( IP ( NP (-NONE- *PRO*) ) VP PRN ) 415 ( IP ADVP ( NP (-NONE- *pro*) ) VP )13 ( IP NP ( NP (-NONE- *PRO*) ) VP ) 322 ( IP NP ( NP (-NONE- *pro*) ) VP )12 ( CP ( NP (-NONE- *PRO*) ) CP ) 164 ( IP PP PU ( NP (-NONE- *pro*) ) VP )*PRO* *pro*Count Pattern Count Pattern2991 ( VP VV NP ( IP ( NP (-NONE- *PRO*) ) VP ) ) 1782 ( CP ( IP ( NP (-NONE- *pro*) ) VP ) DEC )2955 ( VP VV ( IP ( NP (-NONE- *PRO*) ) VP ) ) 1007 ( VP VV ( IP ( NP (-NONE- *pro*) ) VP ) )850 ( CP ( IP ( NP (-NONE- *PRO*) ) VP ) DEC ) 702 ( LCP ( IP ( NP (-NONE- *pro*) ) VP ) LC )765 ( PP P ( IP ( NP (-NONE- *PRO*) ) VP ) ) 684 ( IP IP PU ( IP ( NP (-NONE- *pro*) ) VP ) PU )654 ( LCP ( IP ( NP (-NONE- *PRO*) ) VP ) LC ) 654 ( TOP ( IP ( NP (-NONE- *pro*) ) VP PU ) )Table 5: Top five minimally connected patterns that match *pro* and *PRO* (top).
Patterns that match both *pro*and *PRO* are shaded with the same color.
The table on the bottom show more refined patterns that are given addedcontext by including the parent and siblings to minimally connected patterns.
Many patterns still match both *pro*and *PRO* but there is a lesser degree of overlap.640training data.After the patterns are extracted, we performedpruning similar to the pruning that was done byJohnson (2002).
The patterns that have less than50% chance of matching are discarded.
For exam-ple, if (IP VP) occurs one hundred times in a tree-bank that is stripped of empty nodes and if pattern(IP (NP (-NONE- *PRO*)) VP) occurs less thanfifty times in the same treebank that is annotatedwith empty nodes, it is discarded.1 We also foundthat we can discard patterns that occur very rarely(that occur only once) without losing much accu-racy.
In cases where there was an overlap betweentwo empty categories, the pattern was chosen foreither *pro* or *PRO*, whichever that maximizedthe number of matchings and then discarded for theother.3.2 Conditional random fieldWe tried building a simple conditional random field(Lafferty et al, 2001) to predict null elements.
Themodel examines each and every word boundary anddecides whether to leave it as it is, insert *pro*,or insert *PRO*.
The obvious disadvantage of thismethod is that if there are two consecutive null el-ements, it will miss at least one of them.
Althoughthere were some cases like this in the treebank, theywere rare enough that we decided to ignore them.We first tried using only differently sized local win-dows of words as features (CRF model 1).
We alsoexperimented with adding the part-of-speech tags ofwords as features (CRF model 2).
Finally, we exper-imented with a variation where the model is giveneach word and its part-of-speech tag and its imme-diate parent node as features (CRF model 3).We experimented with using different regulariza-tions and different values for regularizations but itdid not make much difference in the final results.The numbers we report later used L2 regularization.3.3 ParsingIn this approach, we annotated nonterminal symbolsin the treebank to include information about emptycategories and then extracted a context free gram-mar from the modified treebank.
We parsed withthe modified grammar, and then deterministically re-1See Johnson (2002) for more details.
*PRO* *pro*Cycle Prec.
Rec.
F1 Prec Rec.
F11 0.38 0.08 0.13 0.38 0.08 0.122 0.52 0.23 0.31 0.37 0.18 0.243 0.59 0.46 0.52 0.43 0.24 0.314 0.62 0.50 0.56 0.47 0.25 0.335 0.61 0.52 0.56 0.47 0.33 0.396 0.60 0.53 0.56 0.46 0.39 0.427 0.58 0.52 0.55 0.43 0.40 0.41Table 6: Result using the grammars output by the Berke-ley state-splitting grammar trainer to predict empty cate-goriescovered the empty categories from the trees.
Fig-ure 2 illustrates how the trees were modified.
Forevery empty node, the most immediate ancestor ofthe empty node that has more than one child was an-notated with information about the empty node, andthe empty node was deleted.
We annotated whetherthe deleted empty node was *pro* or *PRO* andwhere it was deleted.
Adding where the child wasnecessary because, even though most empty nodesare the first child, there are many exceptions.We first extracted a plain context free grammar af-ter modifying the trees and used the modified gram-mar to parse the test set and then tried to recover theempty elements.
This approach did not work well.We then applied the latent annotation learning pro-cedures of Petrov et al (2006)2 to refine the non-terminals in the modified grammar.
This has beenshown to help parsing in many different situations.Although the state splitting procedure is designed tomaximize the likelihood of of the parse trees, ratherthan specifically to predict the empty nodes, learninga refined grammar over modified trees was also ef-fective in helping to predict empty nodes.
Table 6shows the dramatic improvement after each split,merge, and smoothing cycle.
The gains leveled offafter the sixth iteration and the sixth order grammarwas used to run later experiments.3.4 ResultsTable 7 shows the results of our experiments.
Thenumbers are very low when compared to accuracyreported in other works that were mentioned in thebeginning of this Section, which dealt with the PennEnglish Treebank.
Dropped pronouns are especially2http://code.google.com/p/berkeleyparser/641IPNP-SBJ-NONE-*pro*VPVV??NP-OBJPN??PU??
SPRO0IPVPVV??NP-OBJPN?
?PU?Figure 2: An example of tree modification*PRO* *pro*Prec.
Rec.
F1 Prec Rec.
F1Pattern 1 0.65 0.61 0.63 0.41 0.23 0.29Pattern 2 0.67 0.58 0.62 0.46 0.24 0.31CRF 1 0.66 0.31 0.43 0.53 0.24 0.33CRF 2 0.68 0.46 0.55 0.58 0.35 0.44CRF 3 0.63 0.47 0.54 0.54 0.36 0.43Parsing 0.60 0.53 0.56 0.46 0.39 0.42Table 7: Result of recovering empty nodeshard to recover.
However, we are dealing with a dif-ferent language and different kinds of empty cate-gories.
Empty categories recovered this way maystill help translation.
In the next section, we take thebest variation of the each method use it to add emptycategories to a training corpus and train machinetranslation systems to see whether having empty cat-egories can help improve translation in more realis-tic situations.3.5 AnalysisThe results reveal many interesting aspects about re-covering empty categories.
The results suggest thattree structures are important features for finding siteswhere markers for control constructions (*PRO*)have been deleted.
The method utilizing patternsthat have more information about tree structure ofthese sites performed better than other methods.
Thefact that the method using parsing was better at pre-dicting *PRO*s than the methods that used the con-ditional random fields also corroborates this finding.For predicting dropped pronouns, the method usingthe CRFs did better than the others.
This suggeststhat rather than tree structure, local context of wordsand part-of-speech tags maybe more important fea-tures for predicting dropped pronouns.
It may alsosuggest that methods using robust machine learningtechniques are better outfitted for predicting droppedpronouns.It is interesting to note how effective the parserwas at predicting empty categories.
The method us-ing the parser requires the least amount of supervi-sion.
The method using CRFs requires feature de-sign, and the method that uses patterns needs hu-man decisions on what the patterns should be andpruning criteria.
There is also room for improve-ment.
The split-merge cycles learn grammars thatproduce better parse trees rather than grammars thatpredict empty categories more accurately.
By modi-fying this learning process, we may be able to learngrammars that are better suited for predicting emptycategories.4 Experiments4.1 SetupFor Chinese-English, we used a subset of FBISnewswire data consisting of about 2M words and60K sentences on the English side.
For our develop-ment set and test set, we had about 1000 sentenceseach with 10 reference translations taken from theNIST 2002 MT evaluation.
All Chinese data wasre-segmented with the CRF-based Stanford Chinesesegmenter (Chang et al, 2008) that is trained onthe segmentation of the Chinese Treebank for con-sistency.
The parser used in Section 3 was used toparse the training data so that null elements couldbe recovered from the trees.
The same method forrecovering null elements was applied to the train-642BLEU BP *PRO* *pro*Baseline 23.73 1.000Pattern 23.99 0.998 0.62 0.31CRF 24.69* 1.000 0.55 0.44Parsing 23.99 1.000 0.56 0.42Table 8: Final BLEU score result.
The asterisk indicatesstatistical significance at p < 0.05 with 1000 iterationsof paired bootstrap resampling.
BP stands for the brevitypenalty in BLEU.
F1 scores for recovering empty cate-gories are repeated here for comparison.ing, development, and test sets to insert empty nodesfor each experiment.
The baseline system was alsotrained using the raw data.We used Moses (Koehn et al, 2007) to trainmachine translation systems.
Default parameterswere used for all experiments.
The same numberof GIZA++ (Och and Ney, 2003) iterations wereused for all experiments.
Minimum error rate train-ing (Och, 2003) was run on each system afterwardsand the BLEU score (Papineni et al, 2002) was cal-culated on the test set.4.2 ResultsTable 8 summarizes our results.
Generally, all sys-tems produced BLEU scores that are better than thebaseline, but the best BLEU score came from thesystem that used the CRF for null element insertion.The machine translation system that used trainingdata from the method that was overall the best inpredicting empty elements performed the best.
Theimprovement is 0.96 points in BLEU score, whichrepresents statistical significance at p < 0.002 basedon 1000 iterations of paired bootstrap resampling(Koehn, 2004).
Brevity penalties applied for cal-culating BLEU scores are presented to demonstratethat the baseline system is not penalized for produc-ing shorter sentences compared other systems.3The BLEU scores presented in Table 8 representthe best variations of each method we have triedfor recovering empty elements.
Although the dif-ference was small, when the F1 score were samefor two variations of a method, it seemed that wecould get slightly better BLEU score with the varia-tion that had higher recall for recovering empty ele-3We thank an anonymous reviewer for tipping us to examinethe brevity penalty.ments rather the variation with higher precision.We tried a variation of the experiment where theCRF method is used to recover *pro* and the patternmatching is used to recover *PRO*, since these rep-resent the best methods for recovering the respectiveempty categories.
However, it was not as successfulas we thought would be.
The resulting BLEU scorefrom the experiment was 24.24, which is lower thanthe one that used the CRF method to recover both*pro* and *PRO*.
The problem was we used a veryna?ve method of resolving conflict between two dif-ferent methods.
The CRF method identified 17463sites in the training data where *pro* should beadded.
Of these sites, the pattern matching methodguessed 2695 sites should be inserted with *PRO*rather than *pro*, which represent more than 15%of total sites that the CRF method decided to in-sert *pro*.
In the aforementioned experiment, wher-ever there was a conflict, both *pro* and *PRO*were inserted.
This probably lead the experimentto have worse result than using only the one bestmethod.
This experiment suggest that more sophisti-cated methods should be considered when resolvingconflicts created by using heterogeneous methods torecover different empty categories.Table 9 shows five example translations of sourcesentences in the test set that have one of the emptycategories.
Since empty categories have been auto-matically inserted, they are not always in the cor-rect places.
The table includes the translation resultsfrom the baseline system where the training and testsets did not have empty categories and the transla-tion results from the system (the one that used theCRF) that is trained on an automatically augmentedcorpus and given the automatically augmented testset.5 ConclusionIn this paper, we have showed that adding someempty elements can help building machine transla-tion systems.
We showed that we can still benefitfrom augmenting the training corpus with empty el-ements even when empty element prediction is lessthan what would be conventionally considered ro-bust.We have also shown that there is a lot of room forimprovement.
More comprehensive and sophisti-643source ????
*PRO*???????
?reference china plans to invest in the infrastructuresystem trained w/ nulls china plans to invest in infrastructuresystem trained w/o nulls china ?s investment in infrastructuresource ??
*PRO*???????????
?reference good for consolidating the trade and shipping center of hong kongsystem trained w/ nulls favorable to the consolidation of the trade and shipping center in hong kongsystem trained w/o nulls hong kong will consolidate the trade and shipping centersource ??????
*PRO*?????
?reference some large - sized enterprises to gradually go bankruptsystem trained w/ nulls some large enterprises to gradually becoming bankruptsystem trained w/o nulls some large enterprises gradually becoming bankruptsource *pro*?????
?reference it is not clear nowsystem trained w/ nulls it is also not clearsystem trained w/o nulls he is not clearsource *pro*?????
?reference it is not clear yetsystem trained w/ nulls it is still not clearsystem trained w/o nulls is still not clearTable 9: Sample translations.
The system trained without nulls is the baseline system where the training corpus andtest corpus did not have empty categories.
The system trained with nulls is the system trained with the training corpusand the test corpus that have been automatically augmented with empty categories.
All examples are part of longersentences.cated methods, perhaps resembling the work of Gab-bard et al (2006) may be necessary for more accu-rate recovery of empty elements.
We can also con-sider simpler methods where different algorithmsare used for recovering different empty elements, inwhich case, we need to be careful about how recov-ering different empty elements could interact witheach other as exemplified by our discussion of thepattern matching algorithm in Section 3 and our ex-periment presented in Section 4.2.There are several other issues we may considerwhen recovering empty categories that are miss-ing in the target language.
We only consideredempty categories that are present in treebanks.
How-ever, there might be some empty elements which arenot annotated but nevertheless helpful for improv-ing machine translation.
As always, preprocessingthe corpus to address a certain problem in machinetranslation is less principled than tackling the prob-lem head on by integrating it into the machine trans-lation system itself.
It may be beneficial to includeconsideration for empty elements in the decodingprocess, so that it can benefit from interacting withother elements of the machine translation system.Acknowledgments We thank the anonymous re-viewers for their helpful comments.
This workwas supported by NSF grants IIS-0546554 and IIS-0910611.ReferencesAnn Bies, Mark Ferguson, Karen Katz, and Robert Mac-Intyre.
1995.
Bracketing guidelines for treebank IIstyle.
Penn Treebank Project, January.Peter F. Brown, Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational Linguistics, 19(2):263?311.Pi-Chuan Chang, Michel Galley, and Christopher Man-ning.
2008.
Optimizing Chinese word segmentationfor machine translation performance.
In Proceedingsof the Third Workshop on Statistical Machine Transla-tion, pages 224?232.Ryan Gabbard, Seth Kulick, and Mitchell Marcus.
2006.Fully parsing the Penn Treebank.
In Proceedings ofthe Human Language Technology Conference of theNAACL, Main Conference, pages 184?191, New York644City, USA, June.
Association for Computational Lin-guistics.Na-Rae Han and Shijong Ryu.
2005.
Guidelines forPenn Korean Treebank version 2.0.
Technical report,IRCS, University of Pennsylvania.Gumwon Hong, Seung-Wook Lee, and Hae-Chang Rim.2009.
Bridging morpho-syntactic gap between sourceand target sentences for English-Korean statistical ma-chine translation.
In Proceedings of the ACL-IJCNLP2009 Conference Short Papers, pages 233?236.Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, andKevin Duh.
2010.
Head finalization: A simple re-ordering rule for sov languages.
In Proceedings of theJoint Fifth Workshop on Statistical Machine Transla-tion and Metrics, pages 244?251.Mark Johnson.
2002.
A simple pattern-matching al-gorithm for recovering empty nodes and their an-tecedents.
In Proceedings of the 40th Annual Confer-ence of the Association for Computational Linguistics(ACL-02), Philadelphia, PA.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of ACL, Demonstration Session, pages 177?180.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In 2004 Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP), pages 388?395, Barcelona, Spain, July.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic mod-els for segmenting and labeling sequence data.
In Ma-chine Learning: Proceedings of the Eighteenth Inter-national Conference (ICML 2001), Stanford, Califor-nia.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training forstatistical machine translation.
In Proceedings of the41th Annual Conference of the Association for Com-putational Linguistics (ACL-03).Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Conference of the Association for Com-putational Linguistics (ACL-02).Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand 44th Annual Meeting of the Association for Com-putational Linguistics, pages 433?440, Sydney, Aus-tralia, July.
Association for Computational Linguistics.Nianwen Xue and Fei Xia.
2000.
The bracketing guide-lines for the Penn Chinese Treebank.
Technical ReportIRCS-00-08, IRCS, University of Pennsylvania.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Proceedings of the39th Annual Conference of the Association for Com-putational Linguistics (ACL-01), Toulouse, France.645
