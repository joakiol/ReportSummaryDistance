Proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages, pages 83?88,Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language ProcessingA Hybrid Named Entity Recognition System for South Asian LanguagesPraveen Kumar PLanguage Technologies Research CentreInternational Institute of InformationTechnology - Hyderabadpraveen_p@students.iiit.ac.inRavi Kiran VLanguage Technologies Research CentreInternational Institute of InformationTechnology - Hyderabadravikiranv@students.iiit.ac.inAbstractThis paper is submitted for the contestNERSSEAL-2008.
Building a statisticalbased Named entity Recognition (NER)system requires huge data set.
A rule basedsystem needs linguistic analysis to formu-late rules.
Enriching the language specificrules can give better results than the statis-tical methods of named entity recognition.A Hybrid model proved to be better inidentifying Named Entities (NE) in IndianLanguage where the task of identifyingnamed entities is far more complicatedcompared to English because of variationin the lexical and grammatical features ofIndian languages.1 IntroductionNamed Entities (NE) are phrases that contain per-son, organization, location, number, time, measureetc.
Named Entity Recognition is the task of identi-fying and classifying the Named Entities into pre-define categories such as person, organization, lo-cation, etc in the text.NER has several applications.
Some of them areMachine Translation (MT), Question-AnsweringSystem, Information Retrieval (IR), and Cross-lingual Information Retrieval.The tag set used in the NER-SSEA contesthas12 categories.
This is 4 more than the CONLL-2003 shared task on NER tag-set.
The use of finertag-set aims at improving Machine Translation(MT).
Annotated data for Hindi, Bengali, Oriya,Telugu and Urdu languages was provided to thecontestants.Significant work in the field of NER was donein English, European languages but not in Indianlanguages.
There are many rule-based, HMMbased; Conditional Random Fields (CRF) basedNER systems.
MEMM were used to identify theNE in Hindi (Kumar and Bhattacharyya, 2006).Many techniques were used in CoNLL-2002shared task on NER which aimed at developing alanguage independent NER system.2 Issues: Indian LanguagesThe task of NER in Indian Languages is a difficulttask when compared to English.
Some features thatmake the task difficult are2.1 No CapitalizationCapitalization is an important feature used by theEnglish NER systems to identify the NE.
The ab-sence of the lexical features such as capitalizationin Indian languages scripts makes it difficult toidentify the NE.2.2 Agglutinative natureSome of the Indian language such as Telugu is ag-glutinative in nature.
Telugu allows polyagglutina-tion, the unique feature to being able to add multi-ple suffixes to words to denote more complexwords.Ex:  ?hyderabadlonunci?
= hyderabad+ lo + nunchi2.3 AmbiguitiesThere can be ambiguity among the names of per-sons, locations and organizations such as Washing-ton can be either a person name as well as locationname.2.4 Proper-noun & common noun AmbiguityIn India the common-nouns often occur as the per-son names.
For instance Akash which can mean?sky?
is also name of a person.832.5 Free-word orderSome of the Indian languages such as Telugu arefree word order languages.
The heuristics such asposition of the word in the sentence can not beused as a feature to identify NE in these languages.3 ApproachesA NER system can be either a Rule based or statis-tical or hybrid.
A Rule-based system needs linguis-tic analysis to formulate the rules.
A statisticalNER system needs annotated corpus.
A hybrid sys-tem is generally a rule based system on top of sta-tistical system.For the NER-SSEAL contest we developed CRFbased and HMM based hybrid system.3.1 Hidden Markov ModelWe used a second order Markov model for Namedentity tagging.
The tags are represented by thestates, words by the output.
Transition probabilitiesdepend on the states.
Output probabilities dependon the most recent category.
For a given sentencew1?wTof length T. t1,t2.. tTare elements of thetag-set.
We calculateArgmaxt1...tT[1TP(ti|ti-1,ti-2)P(wi|ti)](P(tT+1|tT)This gives the tags for the words.
We use linearinterpolation of unigrams, bigrams and trigrams fortransition probability smoothing and suffix treesfor emission probability smoothing.3.1.1 HMM based hybrid modelIn the first phase HMM models are trained on thetraining corpus and are used to tag the test data.The first layer is purely statistical method of solv-ing and the second layer is pure rule based methodof solving.
In order to extend the tool for any otherIndian language we need to formulate rules in thesecond layer.
In the first layers HMM models aretraining from the annotated training corpus.
Theannotation follows as: Every word in the corpus ifbelongs to any Named entity class is marked withthe corresponding class name.
And the one?s whichdon?t fall into any of the named entity class fallinto the class of words that are not named entities.The models obtained by training the annotatedtraining corpus are used to tag the test data.
In thefirst layer the class boundaries may not be identi-fied correctly.
This problem of correctly identify-ing the class boundaries and nesting is solved inthe second layer.In the second layer, the chunk information of thetest corpus is used to identify the correct bounda-ries of the named entities identified from the firstlayer.
It?s a type of validation of result from thefirst layer.
Simultaneously, few rules for everyclass of named entities are used in order to identifynesting of named entities in the chunks and toidentify the unidentified named entities from thefirst layer output.
For Telugu these rules includesuffixes with which Named Entities can be identi-fied3.2 Conditional Random FieldsConditional Random Fields (CRFs) are undirectedgraphical models, a special case of which corre-sponds to conditionally-trained finite state ma-chines.
CRFs are used for labeling sequential data.In the special case in which the output nodes ofthe graphical model are linked by edges in a linearchain, CRFs make a first-order Markov independ-ence assumption, and thus can be understood asconditionally-trained finite state machines (FSMs).Let o = (o, o2, o3, o4,... oT) be some observedinput data sequence, such as a sequence of wordsin text in a document,(the values on n input nodesof the graphical model).
Let S be a set of FSMstates, each of which is associated with a label, l ?
?.Let s = (s1,s2,s3,s4,... sT) be some sequence ofstates, (the values on T output nodes).
By theHammersley- Clifford theorem, CRFs define theconditional probability of a state sequence given aninput sequence to be:where Zois a normalization factor over all statesequences is an arbitrary feature function over itsarguments, and ?kis a learned weight for each fea-ture function.
A feature function may, for example,be defined to have value 0 or 1.
Higher ?
weightsmake their corresponding FSM transitions morelikely.
CRFs define the conditional probability of alabel sequence based on the total probability overthe state sequences,where l(s) is the sequence of labels correspondingto the labels of the states in sequence s.84Note that the normalization factor, Zo, (also knownin statistical physics as the partition function) is thesum of the scores of all possible states.And that the number of state sequences is expo-nential in the input sequence length T. In arbitrar-ily structured CRF?s calculating the normalizationfactor in closed form is intractable, but in liner-chain-structure CRFs, the probability that a par-ticular transition was taken between two CRFstates at a particular position in the input can becalculated by dynamic programming.3.2.1 CRF based modelCRF models were used to perform the initial tag-ging.
The features for the Hindi and Telugu modelsinclude the Root, number and gender of the wordfrom the morphological analyzer.
From our previ-ous experiments it is observed that the system per-forms better with the suffix and the prefix as fea-tures.
So the first 4, first 3, first 2 and the 1st letterof the word (prefix) and the last 4, 3, 2, 1 letters ofthe word (suffix) are used as features.The word is a Named Entity depends on thePOS tag.
So the POS tag is used as a feature.
Thechunk information is important to identify theNamed entities with more than one word.
So thechunk information is also included in the featurelist.The resources for the rest of the three languages(Oriya, Urdu and Bengali) are limited.
Since wecouldn?t find the morphological analyzer for theselanguages, the first 4,3,2,1 letters and the last4,3,2,1 letters are used as features.The word being classified as a named entity alsodepends on the previous and next words.
So theseare used as features for all the languages4 EvaluationPrecision, Recall and F-measure are used as metricto evaluate the system.
These are calculated forNested (both nested and largest possible NEmatch), Maximal (largest possible NE match) andLexicon matchesNested matches (n): The largest possible as well asthe nested NEMaximal matches (m): The largest possible NEmatched with reference data.Lexical item (l): The lexical item inside the NE arematched5 ResultsPm, Pn,Plare the precision of maximal, nested, lex-ical matches respectively.
Rm, Rn, Rlare the recallof maximal, nested, lexical matches respectively.Similarly Fm, Fn, Flare the F-measure of   maximal,nested, lexical matches.The precision, recall, F-measure of five lan-guages for CRF system is given in Table1.
Table 2has the lexical F-measure for each category.
Simi-larly Table3 and Table4 give the precision, recalland F-measure for the five languages and the lexi-cal F-measure for each category of HMM basedsystem.The performance of the NER system for fivelanguages using a CRF based system is shown inTable-1.Precision           Recall       F-MeasureLanguage Pm Pn Pl Rm Rn Rl Fm Fn FlBengali 61.28 61.45 66.36  21.18 20.54 24.43 31.48 30.79 35.71Hindi 69.45 72.53 73.30 30.38 29.12 27.97 42.27 41.56 40.49Oriya 37.27 38.65 64.20 19.56 16.19 25.75 25.66 22.82 36.76Telugu 33.50 36.18 61.98 15.90 11.13 36.10 21.56 17.02 45.62Urdu 45.55 46.11  52.35 26.08 24.24 30.13 33.17 31.78 38.25m: Maximal n: Nested l: lexicalTable 1: Performance of NER system for five languages (CRF)85Bengali Hindi Oriya Telugu UrduNEP 33.06 42.31 51.50 15.70 11.72NED 00.00 42.85 01.32 00.00 04.76NEO 11.94 34.83 12.52 02.94 20.92NEA 00.00 36.36 00.00 00.00 00.00NEB NP NP 00.00 00.00 00.00NETP 29.62 00.00 18.03 00.00 00.00NETO 28.96 08.13 03.33 00.00 00.00NEL 34.41 61.08 46.73 12.26 54.59NETI 63.86 70.37 35.22 90.49 62.22NEN 75.34 74.07 21.03 26.32 13.44NEM 46.96 58.33 14.19 42.01 77.72NETE 12.54 13.85 NP 08.63 00.00NP: Not present in reference dataTable 2: Class specific F-Measure for nested lexical match (CRF)MeasurePrecision Recall F-MeasureLanguage Pm Pn Pl Rm Rn Rl Fm Fn FlBengali 50.66 50.78 58.00 25.03 24.26 30.26 33.50 32.8339.77Hindi 69.89 73.37 73.59 36.90 35.75 34.3448.30 47.16 46.84Oriya 33.10 34.70 60.98 24.63 20.61 36.72 28.24 25.8645.84Telugu 15.61 49.67 62.00 11.64 24.00 37.30 13.33 32.3746.58Urdu 42.81 47.14 56.21 29.37 29.69 37.15 34.48 36.8344.73m: Maximal n: Nested l: lexicalTable 3: Performance of NER system for five languages (HMM)Bengali Hindi Oriya Telugu UrduNEP 38.10 53.19 63.04 23.14 34.96NED 00.00 52.94 08.75 06.18 49.18NEO 05.05 40.42 28.52 04.28 31.53NEA 00.00 25.00 10.00 00.00 04.00NEB NP NP 00.00 00.00 00.00NETP 36.25 00.00 19.92 00.00 09.09NETO 07.44 16.39 09.09 05.85 00.00NEL 49.35 72.03 50.09 29.26 58.59NETI 50.81 62.56 46.30 70.75 53.98NEN 66.66 81.96 30.43 86.29 23.63NEM 62.98 54.44 20.68 35.44 82.64NETE 12.56 17.43 NP 11.67 00.00NP: Not present in reference dataTable 4: Class specific F-measure for nested lexical match (HMM)86Table-2 shows the performance for specificclasses of named entities.
Table-3 presents theresults for the HMM based system and Table-4gives the class specific performance of theHMM based system.6 Error AnalysisIn both HMM, CRF based system the pos-tagand the chunk information are being used.
NEsare generally the noun chunks.
The pos-taggerand the chunker that we used had low accuracy.These errors in the POS-Tag contributed signifi-cantly to errors in NER.In Telugu the F-measure for the maximalnamed entities is low for both the CRF, HMMmodels.
This is because the test data had a largenumber of TIME named entities which are 5-6words long.
These entities further had nestednamed entities.
Both the models are able to iden-tify the nested named entities.
We chose not toconsider the Time entities as a maximal entitysince it was not tagged as a maximal NE as insome places.
Considering it as a maximal NEthe F-measure of the system increased signifi-cantly to over 30 for both HMM and CRF basedsystems.It is also observed that many NE?s were re-trieved correctly but were wrongly classified.Working with fewer tag-set will help to increasethe performance of the system but this is notsuggested.7 ConclusionThe overall performance of the HMM modelbased hybrid system is better than the CRFmodel for all the languages.
The performance ofHMM based system is less that that of CRF.
Weobtained a decent Lexical F-measure of 39.77,46.84, 45.84, 46.58, 44.73for Bengali, Hindi,Oriya, Telugu and Urdu using rules over HMMmodel.
HMM based model has a better F-measure for NEP, NEL, NEO classes when com-pared to CRF modelReferencesCRF++: http://crfpp.sourceforge.netP.
Avinesh, G. Karthik.
2007.
Parts-of-Speech Tag-ging and Chunking using Conditional RandomFields and Transformation Based learning.
Pro-ceedings of SPSAL workshop IJCNLP 07Thorsen Brants.
2000.
TnT: a statistical Part-of-Speech Tagger.
Proceeding of sixth conference onApplied Natural Language Processing.N.
Kumar and Pushpak Bhattacharyya.
2006.
NER inHindi using MEMM.J.
Lafferty, A. McCullam, F. Pereira.
2001.
Condi-tional Random Fields: Probabilistic models forsegmenting and labeling sequence data.
18thInter-national Conference on Machine LearningWei Li and A. McCallum.
2003.
Rapid Developmentof Hindi Named Entity Recognition using Condi-tional Random Fields and Feature Induction.Transactions on Asian Language InformationProcessing.8788
