33A Developmental Model of Syntax Acquisition in the Construction GrammarFramework with Cross-Linguistic Validation in English and JapanesePeter Ford DomineySequential Cognition and Language GroupInstitut des Sciences Cognitives, CNRS69675 Bron CEDES, Francedominey@isc.cnrs.frToshio InuiGraduate School of Informatics,Kyoto University,Yoshida-honmachi, Sakyo-ku, 606-8501,Kyoto, Japaninui@kyoto-u.ac.jpAbstractThe current research demonstrates a systeminspired by cognitive neuroscience anddevelopmental psychology that learns toconstruct mappings between the grammaticalstructure of sentences and the structure of theirmeaning representations.
Sentence to meaningmappings are learned and stored asgrammatical constructions.
These are storedand retrieved from a construction inventorybased on the constellation of closed classitems uniquely identifying each construction.These learned mappings allow the system toprocesses natural language sentences in orderto reconstruct complex internal representationsof the meanings these sentences describe.
Thesystem demonstrates error free performanceand systematic generalization for a rich subsetof English constructions that includes complexhierarchical grammatical structure, andgeneralizes systematically to new sentences ofthe learned construction categories.
Furthertesting demonstrates (1) the capability toaccommodate a significantly extended set ofconstructions, and (2) extension to Japanese, afree word order language that is structurallyquite different from English, thusdemonstrating the extensibility of the structuremapping model.1 IntroductionThe nativist perspective on the problem oflanguage acquisition holds that the <sentence,meaning> data to which the child is exposed ishighly indeterminate, and underspecifies themapping to be learned.
This ?poverty of thestimulus?
is a central argument for the existence ofa genetically specified universal grammar, suchthat language acquisition consists of configuringthe UG for the appropriate target language(Chomsky 1995).
In this framework, once a givenparameter is set, its use should apply to newconstructions in a generalized, generative manner.An alternative functionalist perspective holdsthat learning plays a much more central role inlanguage acquisition.
The infant develops aninventory of grammatical constructions asmappings from form to meaning (Goldberg 1995).These constructions are initially rather fixed andspecific, and later become generalized into a moreabstract compositional form employed by the adult(Tomasello 1999, 2003).
In this context,construction of the relation between perceptual andcognitive representations and grammatical formplays a central role in learning language (e.g.Feldman et al 1990, 1996; Langacker 1991;Mandler 1999; Talmy 1998).These issues of learnability and innateness haveprovided a rich motivation for simulation studiesthat have taken a number of different forms.Elman (1990) demonstrated that recurrentnetworks are sensitive to predictable structure ingrammatical sequences.
Subsequent studies ofgrammar induction demonstrate how syntacticstructure can be recovered from sentences (e.g.Stolcke & Omohundro 1994).
From the?grounding of language in meaning?
perspective(e.g.
Feldman et al 1990, 1996; Langacker 1991;Goldberg 1995) Chang & Maia (2001) exploitedthe relations between action representation andsimple verb frames in a construction grammarapproach.
In effort to consider more complexgrammatical forms, Miikkulainen (1996)demonstrated a system that learned the mappingbetween relative phrase constructions and multipleevent representations, based on the use of a stackfor maintaining state information during theprocessing of the next embedded clause in arecursive manner.In a more generalized approach, Dominey(2000) exploited the regularity that sentence tomeaning mapping is encoded in all languages byword order and grammatical marking (bound orfree) (Bates et al 1982).
That model was based on34the functional neurophysiology of cognitivesequence and language processing and anassociated neural network model that has beendemonstrated to simulate interesting aspects ofinfant (Dominey & Ramus 2000) and adultlanguage processing (Dominey et al 2003).2 Structure mapping for language learningThe mapping of sentence form onto meaning(Goldberg 1995) takes place at two distinct levelsin the current model: Words are associated withindividual components of event descriptions, andgrammatical structure is associated with functionalroles within scene events.
The first level has beenaddressed by Siskind (1996), Roy & Pentland(2002) and Steels (2001) and we treat it here in arelatively simple but effective manner.
Ourprinciple interest lies more in the second level ofmapping between scene and sentence structure.Equations 1-7 implement the model depicted inFigure 1, and are derived from aneurophysiologically motivated model ofsensorimotor sequence learning (Dominey et al2003).2.1 Word MeaningEquation (1) describes the associative memory,WordToReferent, that links word vectors in theOpenClassArray (OCA) with their referent vectorsin the SceneEventArray (SEA)1.
In the initiallearning phases there is no influence of syntacticknowledge and the word-referent associations arestored in the WordToReferent matrix (Eqn 1) byassociating every word with every referent in thecurrent scene (?
= 1), exploiting the cross-situational regularity (Siskind 1996) that a givenword will have a higher coincidence with referentto which it refers than with other referents.
Thisinitial word learning contributes to learning themapping between sentence and scene structure(Eqn.
4, 5 & 6 below).
Then, knowledge of thesyntactic structure, encoded in SentenceToScenecan be used to identify the appropriate referent (inthe SEA) for a given word (in the OCA),corresponding to a zero value of ?
in Eqn.
1.
Inthis ?syntactic bootstrapping?
for the new word?gugle,?
for example, syntactic knowledge ofAgent-Event-Object structure of the sentence?John pushed the gugle?
can be used to assign1 In Eqn 1, the index k = 1 to 6, corresponding to the maximumnumber of words in the open class array (OCA).
Index m = 1 to 6,corresponding to the maximum number of elements in the scene eventarray (SEA).
Indices i and j = 1 to 25, corresponding to the word andscene item vector sizes, respectively.?gugle?
to the object of push.WordToReferent(i,j) = WordToReferent(i,j) +OCA(k,i) * SEA(m,j) *max(?, SentenceToScene(m,k)) (1)2.2 Open vs Closed Class Word CategoriesOur approach is based on the cross-linguisticobservation that open class words (e.g.
nouns,verbs, adjectives and adverbs) are assigned to theirthematic roles based on word order and/orgrammatical function words or morphemes (Bateset al 1982).
Newborn infants are sensitive to theperceptual properties that distinguish these twocategories (Shi et al 1999), and in adults, thesecategories are processed by dissociableneurophysiological systems (Brown et al 1999).Similarly, artificial neural networks can also learnto make this function/content distinction (Morganet al 1996).
Thus, for the speech input that isprovided to the learning model open and closedclass words are directed to separate processingstreams that preserve their order and identity, asindicated in Figure 2.Figure 1.
Structure-Mapping Architecture.
1.
Lexical categorization.2.
Open class words in Open Class Array are translated to PredictedReferents in the PRA via the WordtoReferent mapping.
3.
PRAelements are mapped onto their roles in the SceneEventArray by theSentenceToScene mapping, specific to each sentence type.
4.
Thismapping is retrieved from Construction Inventory, via theConstructionIndex that encodes the closed class words thatcharacterize each grammatical construction type.2.3 Mapping Sentence to MeaningMeanings are encoded in an event predicate,argument representation corresponding to theSceneEventArray in Figure 1 (e.g.
push(Block,triangle) for ?The triangle pushed the block?
).There, the sentence to meaning mapping can be35characterized in the following successive steps.First, words in the Open Class Array are decodedinto their corresponding scene referents (via theWordToReferent mapping) to yield the PredictedReferents Array that contains the translated wordswhile preserving their original order from the OCA(Eqn 2) 2.ni 1PRA(k,j) = OCA(k,i) * WordToReferent(i,j)= (2)Next, each sentence type will correspond to aspecific form to meaning mapping between thePRA and the SEA.
encoded in theSentenceToScene array.
The problem will be toretrieve for each sentence type, the appropriatecorresponding SentenceToScene mapping.
Tosolve this problem, we recall that each sentencetype will have a unique constellation of closedclass words and/or bound morphemes (Bates et al1982) that can be coded in a ConstructionIndex(Eqn.3) that forms a unique identifier for eachsentence type.The ConstructionIndex is a 25 element vector.Each function word is encoded as a single bit in a25 element FunctionWord vector.
When afunction word is encountered during sentenceprocessing, the current contents ofConstructionIndex are shifted (with wrap-around)by n + m bits where n corresponds to the bit that ison in the FunctionWord, and m corresponds to thenumber of open class words that have beenencountered since the previous function word (orthe beginning of the sentence).
Finally, a vectoraddition is performed on this result and theFunctionWord vector.
Thus, the appropriateSentenceToScene mapping for each sentence typecan be indexed in ConstructionInventory by itscorresponding ConstructionIndex.ConstructionIndex = fcircularShift(ConstructionIndex,FunctionWord) (3)The link between the ConstructionIndex and thecorresponding SentenceToScene mapping isestablished as follows.
As each new sentence isprocessed, we first reconstruct the specificSentenceToScene mapping for that sentence (Eqn4)3, by mapping words to referents (in PRA) and2 Index k = 1 to 6, corresponding to the maximum number of sceneitems in the predicted references array (PRA).
Indices i and j = 1 to25, corresponding to the word and scene item vector sizes,respectively.3 Index m = 1 to 6, corresponding to the maximum number ofelements in the scene event array (SEA).
Index k = 1 to 6,corresponding to the maximum number of words in the predictedreferents to scene elements (in SEA).
Theresulting, SentenceToSceneCurrent encodes thecorrespondence between word order (that ispreserved in the PRA Eqn 2) and thematic roles inthe SEA.
Note that the quality ofSentenceToSceneCurrent will depend on thequality of acquired word meanings inWordToReferent.
Thus, syntactic learningrequires a minimum baseline of semanticknowledge.ni=1SentenceToSceneCurrent(m,k) =PRA(k,i)*SEA(m,i) (4)Given the SentenceToSceneCurrent mappingfor the current sentence, we can now associate it inthe ConstructionInventory with the correspondingfunction word configuration or ConstructionIndexfor that sentence, expressed in (Eqn 5)4.ConstructionInventory(i,j) = ConstructionInventory(i,j)+ ConstructionIndex(i)* SentenceToScene-Current(j) (5)Finally, once this learning has occurred, fornew sentences we can now extract theSentenceToScene mapping from the learnedConstructionInventory by using theConstructionIndex as an index into this associativememory, illustrated in Eqn.
65.ni=1SentenceToScene(i) =ConstructionInventory(i,j) * ConstructinIndex(j) (6)To accommodate the dual scenes for complexevents Eqns.
4-7 are instantiated twice each, torepresent the two components of the dual scene.
Inthe case of simple scenes, the second component ofthe dual scene representation is null.We evaluate performance by using theWordToReferent and SentenceToScene knowledgeto construct for a given input sentence the?predicted scene?.
That is, the model willreferences array (PRA).
Index i = 1 to 25, corresponding to the wordand scene item vector sizes.4 Note that we have linearized SentenceToSceneCurrent from 2 to1 dimensions to make the matrix multiplication more transparent.Thus index j varies from 1 to 36 corresponding to the 6x6 dimensionsof SentenceToSceneCurrent.5 Again to simplify the matrix multiplication, SentenceToScenehas been linearized to one dimension, based on the original 6x6matrix.
Thus, index i = 1 to 36, and index j = 1 to 25 corresponding tothe dimension of the ConstructionIndex.36construct an internal representation of the scenethat should correspond to the input sentence.
Thisis achieved by first converting the Open-Class-Array into its corresponding scene items in thePredicted-Referents-Array as specified in Eqn.
2.The referents are then re-ordered into the properscene representation via application of theSentenceToScene transformation as described inEqn.
76.PSA(m,i) = PRA(k,i) * SentenceToScene(m,k) (7)When learning has proceeded correctly, thepredicted scene array (PSA) contents should matchthose of the scene event array (SEA) that isdirectly derived from input to the model.
We thenquantify performance error in terms of the numberof mismatches between PSA and SEA.3 Learning ExperimentsThree sets of results will be presented.
First thedemonstration of the model sentence to meaningmapping for a reduced set of constructions ispresented as a proof of concept.
This will befollowed by a test of generalization to a newextended set of grammatical constructions.Finally, in order to validate the cross-linguisticvalidity of the underlying principals, the model istested with Japanese, a free word-order languagethat is qualitatively quite distinct from English.3.1 Proof of Concept with Two Constructions3.1.1 Initial Learning of Active Forms forSimple Event MeaningsThe first experiment examined learning withsentence, meaning pairs with sentences only in theactive voice, corresponding to the grammaticalforms 1 and 2.1.
Active: The block pushed the triangle.2.
Dative: The block gave the triangle to themoon.For this experiment, the model was trained on544 <sentence, meaning> pairs.
Again, meaning iscoded in a predicate-argument format, e.g.push(block, triangle) for sentence 1.
During thefirst 200 trials (scene/sentence pairs), value ?
inEqn.
1 was 1 and thereafter it was 0.
This wasnecessary in order to avoid the effect of erroneous6 In Eqn 7, index i = 1 to 25 corresponding to the size of the sceneand word vectors.
Indices m and k = 1 to 6, corresponding to thedimension of the predicted scene array, and the predicted referencesarray, respectively.
(random) syntactic knowledge on semanticlearning in the initial learning stages.
Evaluationof the performance of the model after this trainingindicated that for all sentences, there was error-freeperformance.
That is, the PredictedScenegenerated from each sentence corresponded to theactual scene paired with that sentence.
Animportant test of language learning is the ability togeneralize to new sentences that have notpreviously been tested.
Generalization in this formalso yielded error free performance.
In thisexperiment, only 2 grammatical constructions werelearned, and the lexical mapping of words to theirscene referents was learned.
Word meaningprovides the basis for extracting more complexsyntactic structure.
Thus, these word meanings arefixed and used for the subsequent experiments.3.1.2 Passive formsThe second experiment examined learning withthe introduction of passive grammatical forms,thus employing grammatical forms 1-4.3.
Passive: The triangle was pushed by the block.4.
Dative Passive: The moon was given to thetriangle by the block.A new set of <sentence, scene> pairs wasgenerated that employed grammaticalconstructions, with two- and three- arguments, andactive and passive grammatical forms for thenarration.
Word meanings learned in Experiment 1were used, so only the structural mapping fromgrammatical to scene structure was learned.
Withexposure to less than 100 <sentence, scene>, errorfree performance was achieved.
Note that only theWordToReferent mappings were retained fromExperiment 1.
Thus, the 4 grammatical formswere learned from the initial naive state.
Thismeans that the ConstructionIndex andConstructionInventory mechanism correctlydiscriminates and learns the mappings for thedifferent grammatical constructions.
In thegeneralization test, the learned values were fixed,and the model demonstrated error-freeperformance on new sentences for all fourgrammatical forms that had not been used duringthe training.3.1.3 Relative forms for Complex EventsThe complexity of the scenes/meanings andcorresponding grammatical forms in the previousexperiments were quite limited.
Here we considercomplex <sentence, scene> mappings that involverelativised sentences and dual event scenes.
A37small corpus of complex <sentence, scene> pairswere generated corresponding to the grammaticalconstruction types 5-105.
The block that pushed the triangle touched themoon.6.
The block pushed the triangle that touched themoon.7.
The block that pushed the triangle was touched bythe moon.8.
The block pushed the triangle that was touched themoon.9.
The block that was pushed by the triangle touchedthe moon.10.
The block was pushed by the triangle that touchedthe moon.After exposure to less than 100 sentencesgenerated from these relativised constructions, themodel performed without error for these 6construction types.
In the generalization test, thelearned values were fixed, and the modeldemonstrated error-free performance on newsentences for all six grammatical forms that hadnot been used during the training.3.1.4 Combined TestThe objective of the final experiment was toverify that the model was capable of learning the10 grammatical forms together in a single learningsession.
Training material from the previousexperiments were employed that exercised theensemble of 10 grammatical forms.
Afterexposure to less than 150 <sentence, scene> pairs,the model performed without error.
Likewise, inthe generalization test the learned values werefixed, and the model demonstrated error-freeperformance on new sentences for all tengrammatical forms that had not been used duringthe training.This set of experiments in ideal conditionsdemonstrates a proof of concept for the system,though several open questions can be posed basedon these results.
First, while the demonstrationwith 10 grammatical constructions is interesting,we can ask if the model will generalize to anextended set of constructions.
Second, we knowthat the English language is quite restricted withrespect to its word order, and thus we can askwhether the theoretical framework of the modelwill generalize to free word order languages suchas Japanese.
These questions are addressed in thefollowing three sections.3.2 Generalization to Extended ConstructionSetAs illustrated above the model can accommodate10 distinct form-meaning mappings orgrammatical constructions, including constructionsinvolving "dual" events in the meaningrepresentation that correspond to relative clauses.Still, this is a relatively limited size for theconstruction inventory.
The current experimentdemonstrates how the model generalizes to anumber of new and different relative phrases, aswell as additional sentence types including:conjoined (John took the key and opened the door),reflexive (The boy said that the dog was chased bythe cat), and reflexive pronoun (The block said thatit pushed the cylinder) sentence types, for a total of38 distinct abstract grammatical constructions.
Theconsideration of these sentence types requires us toaddress how their meanings are represented.Conjoined sentences are represented by the twocorresponding events, e.g.
took(John, key),open(John, door) for the conjoined example above.Reflexives are represented, for example, assaid(boy), chased(cat, dog).
This assumes indeed,for reflexive verbs (e.g.
said, saw), that themeaning representation includes the second eventas an argument to the first.
Finally, for thereflexive pronoun types, in the meaningrepresentation the pronoun's referent is explicit, asin said(block), push(block, cylinder) for "Theblock said that it pushed the cylinder.
"For this testing, the ConstructionInventory isimplemented as a lookup table in which theConstructionIndex is paired with the correspondingSentenceToScene mapping during a single learningtrial.
Based on the tenets of the constructiongrammar framework (Goldberg 1995), if asentence is encountered that has a form (i.e.ConstructionIndex) that does not have acorresponding entry in the ConstructionInventory,then a new construction is defined.
Thus, oneexposure to a sentence of a new construction typeallows the model to generalize to any new sentenceof that type.
In this sense, developing the capacityto handle a simple initial set of constructions leadsto a highly extensible system.
Using the trainingprocedures as described above, with a pre-learnedlexicon (WordToReferent), the model successfullylearned all of the constructions, and demonstratedgeneralization to new sentences that it was nottrained on.That the model can accommodate these 38different grammatical constructions with nomodifications indicates its capability to generalize.This translates to a (partial) validation of thehypothesis that across languages, thematic roleassignment is encoded by a limited set of38parameters including word order and grammaticalmarking, and that distinct grammaticalconstructions will have distinct and identifyingensembles of these parameters.
However, theseresults have been obtained with English that is arelatively fixed word-order language, and a morerigorous test of this hypothesis would involvetesting with a free word-order language such asJapanese.3.3 Generalization to JapaneseThe current experiment will test the model withsentences in Japanese.
Unlike English, Japaneseallows extensive liberty in the ordering of words,with grammatical roles explicitly marked bypostpositional function words -ga, -ni, -wo, -yotte.This word-order flexibility of Japanese withrespect to English is illustrated here with theEnglish active and passive di-transitive forms thateach can be expressed in 4 different commonmanners in Japanese:1.
The block gave the circle to the triangle.1.1 Block-ga triangle-ni circle-wo watashita .1.2 Block-ga circle-wo triangle-ni watashita .1.3 Triangle-ni block-ga circle-wo watashita .1.4 Circle-wo block-ga triangle-ni watashita .2.
The circle was given to the triangle by theblock.2.1 Circle-ga block-ni-yotte triangle-ni watasareta.2.2 Block-ni-yotte circle-ga triangle-ni watasareta .2.3 Block-ni-yotte triangle-ni circle-ga watasareta .2.4 Triangle-ni circle-ga block-ni-yotte watasareta.In the ?active?
Japanese sentences, thepostpositional function words -ga, -ni and ?woexplicitly mark agent, recipient and, objectwhereas in the passive, these are markedrespectively by ?ni-yotte, -ga, and ?ni.
For boththe active and passive forms, there are fourdifferent legal word-order permutations thatpreserve and rely on this marking.
Japanese thusprovides an interesting test of the model?s ability toaccommodate such freedom in word order.Employing the same method as described in theprevious experiment, we thus expose the model to<sentence, meaning> pairs generated from 26Japanese constructions that employ the equivalentof active, passive, relative forms and theirpermutations.
We predicted that by processing the-ga, -ni, -yotte and ?wo markers as closed classelements, the model would be able to discriminateand identify the distinct grammatical constructionsand learn the corresponding mappings.
Indeed, themodel successfully discriminates between all of theconstruction types based on the ConstructionIndexunique to each construction type, and associatesthe correct SentenceToScene mapping with each ofthem.
As for the English constructions, oncelearned, a given construction could generalize tonew untrained sentences.This demonstration with Japanese is animportant validation that at least for this subset ofconstructions, the construction-based model isapplicable both to fixed word order languages suchas English, as well as free word order languagessuch as Japanese.
This also provides furthervalidation for the proposal of Bates andMacWhinney (et al 1982) that thematic roles areindicated by a constellation of cues includinggrammatical markers and word order.3.4 Effects of NoiseThe model relies on lexical categorization ofopen vs. closed class words both for learninglexical semantics, and for building theConstructionIndex for phrasal semantics.
While wecan cite strong evidence that this capability isexpressed early in development (Shi et al 1999) itis still likely that there will be errors in lexicalcategorization.
The performance of the model forlearning lexical and phrasal semantics for activetransitive and ditransitive structures is thusexamined under different conditions of lexicalcategorization errors.
A lexical categorization errorconsists of a given word being assigned to thewrong category and processed as such (e.g.
anopen class word being processed as a closed classword, or vice-versa).
Figure 2 illustrates theperformance of the model with random errors ofthis type introduced at levels of 0 to 20 percenterrors.Figure 2.
The effects of Lexical Categorization Errors (mis-categorization of an open-class word as a closed-class word or vice-versa) on performance (Scene Interpretation Errors) over TrainingEpochs.
The 0% trace indicates performance in the absences of noise,with a rapid elimination of errors .
The successive introduction ofcategorization errors yields a corresponding progressive impairment inlearning.
While sensitive to the errors, the system demonstrates adesired graceful degradation39We can observe that there is a gracefuldegradation, with interpretation errorsprogressively increasing as categorization errorsrise to 20 percent.
In order to further asses thelearning that was able to occur in the presence ofnoise, after training with noise, we then testedperformance on noise-free input.
The interpretationerror values in these conditions were 0.0, 0.4, 2.3,20.7 and 33.6 out of a maximum of 44 for trainingwith 0, 5, 10, 15 and 20 percent lexicalcategorization errors, respectively.
This indicatesthat up to 10 percent input lexical categorizationerrors allows almost error free learning.
At 15percent input errors the model has stillsignificantly improved with respect to the randombehavior (~45 interpretation errors per epoch).Other than reducing the lexical and phrasallearning rates, no efforts were made to optimizethe performance for these degraded conditions,thus there remains a certain degree of freedom forimprovement.
The main point is that the modeldoes not demonstrate a catastrophic failure in thepresence of lexical categorization errors.4 DiscussionThe research demonstrates an implementation ofa model of sentence-to-meaning mapping in thedevelopmental and neuropsychologically inspiredconstruction grammar framework.
The strength ofthe model is that with relatively simple ?innate?learning mechanisms, it can acquire a variety ofgrammatical constructions in English and Japanesebased on exposure to <sentence, meaning> pairs,with only the lexical categories of open vs. closedclass being prespecified.
This lexicalcategorization can be provided by frequencyanalysis, and/or acoustic properties specific to thetwo classes (Blanc et al 2003; Shi et al 1999).
Themodel learns grammatical constructions, andgeneralizes in a systematic manner to newsentences within the class of learned constructions.This demonstrates the cross-linguistic validity ofour implementation of the construction grammarapproach (Goldberg 1995, Tomasello 2003) and ofthe ?cue competition?
model for coding ofgrammatical structure (Bates et al 1982).
Thepoint of the Japanese study was to demonstrate thiscross-linguistic validity ?
i.e.
that nothing extrawas needed, just the identification of constructionsbased on lexical category information.
Of course abetter model for Japanese and Hungarian etc.
thatexploits the explicit marking of grammatical rolesof NPs would have been interesting ?
but itwouldn?t have worked for English!The obvious weakness is that it does not gofurther.
That is, it cannot accommodate newconstruction types without first being exposed to atraining example of a well formed <sentence,meaning> pair.
Interestingly, however, thisappears to reflect a characteristic stage of humandevelopment, in which the infant relies on the useof constructions that she has previously heard (seeTomasello 2003).
Further on in development,however, as pattern finding mechanisms operateon statistically relevant samples of this data, thechild begins to recognize structural patterns,corresponding for example to noun phrases (ratherthan solitary nouns) in relative clauses.
When thisis achieved, these phrasal units can then be insertedinto existing constructions, thus providing the basisfor ?on the fly?
processing of novel relativisedconstructions.
This suggests how the abstractconstruction model can be extended to a moregeneralized compositional capability.
We arecurrently addressing this issue in an extension ofthe proposed model, in which recognition oflinguistic markers (e.g.
?that?, and directlysuccessive NPs) are learned to signal embeddedrelative phrases (see Miikkulainen 1996).Future work will address the impact ofambiguous input.
The classical example ?Johnsaw the girl with the telescope?
implies that agiven grammatical form can map onto multiplemeaning structures.
In order to avoid this violationof the one to one mapping, we must concede thatform is influenced by context.
Thus, the modelwill fail in the same way that humans do, andshould be able to succeed in the same way thathumans do.
That is, when context is available todisambiguate then ambiguity can be resolved.
Thiswill require maintenance of the recent discoursecontext, and the influence of this on grammaticalconstruction selection to reduce ambiguity.5 AcknowledgementsThis work was supported by the ACIComputational Neuroscience Project, TheEurocores OMLL project and the HFSPOrganization.ReferencesBates E, McNew S, MacWhinney B, Devescovi A,Smith S (1982) Functional constraints onsentence processing: A cross linguistic study,Cognition (11) 245-299.Blanc JM, Dodane C, Dominey P (2003)Temporal processing for syntax acquisition.Proc.
25th Ann.
Mtg.
Cog.
Science Soc.
BostonBrown CM, Hagoort P, ter Keurs M (1999)Electrophysiological signatures of visual lexical40processing : Open- and closed-class words.Journal of Cognitive Neuroscience.
11 :3, 261-281Chang NC, Maia TV (2001) Grounded learning ofgrammatical constructions, AAAI Spring Symp.On Learning Grounded Representations,Stanford CA.Chomsky N. (1995) The Minimalist Program.MITCrangle C. & Suppes P. (1994) Language andLearning for Robots, CSLI lecture notes: no.
41,Stanford.Dominey PF, Ramus F (2000) Neural networkprocessing of natural language: I.
Sensitivity toserial, temporal and abstract structure oflanguage in the infant.
Lang.
and CognitiveProcesses, 15(1) 87-127Dominey PF (2000) Conceptual Grounding inSimulation Studies of Language Acquisition,Evolution of Communication, 4(1), 57-85.Dominey PF, Hoen M, Lelekov T, Blanc JM(2003) Neurological basis of language andsequential cognition: Evidence from simulation,aphasia and ERP studies, Brain and Language,86, 207-225Elman J (1990) Finding structure in time.Cognitive Science, 14:179-211.Feldman JA, Lakoff G, Stolcke A, Weber SH(1990) Miniature language acquisition: Atouchstone for cognitive science.
In Proceedingsof the 12th Ann Conf.
Cog.
Sci.
Soc.
686-693,MIT, Cambridge MAFeldman J., G. Lakoff, D. Bailey, S. Narayanan, T.Regier, A. Stolcke (1996).
L0: The First FiveYears.
Artificial Intelligence Review, v10 103-129.Goldberg A (1995) Constructions.
U ChicagoPress, Chicago and London.Hirsh-Pasek K, Golinkof RM (1996) The origins ofgrammar: evidence from early languagecomprehension.
MIT Press, Boston.Kotovsky L, Baillargeon R, The development ofcalibration-based reasoning about collisionevents in young infants.
1998, Cognition, 67,311-351Langacker, R. (1991).
Foundations of CognitiveGrammar.
Practical Applications, Volume 2.Stanford University Press, Stanford.Mandler J (1999) Preverbal representations andlanguage, in P. Bloom, MA Peterson, L Nadeland MF Garrett (Eds) Language and Space, MITPress, 365-384Miikkulainen R (1996) Subsymbolic case-roleanalysis of sentences with embedded clauses.Cognitive Science, 20:47-73.Morgan JL, Shi R, Allopenna P (1996) Perceptualbases of rudimentary grammatical categories:Toward a broader conceptualization ofbootstrapping, pp 263-286, in Morgan JL,Demuth K (Eds) Signal to syntax, LawrenceErlbaum, Mahwah NJ, USA.Pollack JB (1990) Recursive distributedrepresentations.
Artificial Intelligence, 46:77-105.Roy D, Pentland A (2002).
Learning Words fromSights and Sounds: A Computational Model.Cognitive Science, 26(1), 113-146.Shi R., Werker J.F., Morgan J.L.
(1999) Newborninfants' sensitivity to perceptual cues to lexicaland grammatical words, Cognition, Volume 72,Issue 2, B11-B21.Siskind JM (1996) A computational study of cross-situational techniques for learning word-to-meaning mappings, Cognition (61) 39-91.Siskind JM (2001) Grounding the lexical semanticsof verbs in visual perception using forcedynamics and event logic.
Journal of AIResearch (15) 31-90Steels, L. (2001) Language Games forAutonomous Robots.
IEEE Intelligent Systems,vol.
16, nr.
5, pp.
16-22, New York: IEEE Press.Stolcke A, Omohundro SM (1994) Inducingprobabilistic grammars by Bayesian modelmerging/ In Grammatical Inference andApplications: Proc.
2nd Intl.
Colloq.
OnGrammatical Inference, Springer Verlag.Talmy L (1988) Force dynamics in language andcognition.
Cognitive Science, 10(2) 117-149.Tomasello M (1999) The item-based nature ofchildren's early syntactic development, Trends inCognitive Science, 4(4):156-163Tomasello, M. (2003) Constructing a language: Ausage-based theory of language acquisition.Harvard University Press, Cambridge.
