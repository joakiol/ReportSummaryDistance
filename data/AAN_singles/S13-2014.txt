Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 83?87, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsKUL: A Data-driven Approach to Temporal Parsing of DocumentsOleksandr KolomiyetsKU LeuvenCelestijnenlaan 200AHeverlee 3001, BelgiumDepartment of Computer Scienceoleksandr.kolomiyets@cs.kuleuven.beMarie-Francine MoensKU LeuvenCelestijnenlaan 200AHeverlee 3001, BelgiumDepartment of Computer Sciencesien.moens@cs.kuleuven.beAbstractThis paper describes a system for temporalprocessing of text, which participated in theTemporal Evaluations 2013 campaign.
Thesystem employs a number of machine learningclassifiers to perform the core tasks of: identi-fication of time expressions and events, recog-nition of their attributes, and estimation oftemporal links between recognized events andtimes.
The central feature of the proposed sys-tem is temporal parsing ?
an approach whichidentifies temporal relation arguments (event-event and event-timex pairs) and the semanticlabel of the relation as a single decision.1 IntroductionTemporal Evaluations 2013 (TempEval-3) isthe third iteration of temporal evaluations (afterTempEval-1 (Verhagen et al 2007) and TempEval-2 (Verhagen et al 2010)) which addresses thetask of temporal information processing of text.
Incontrast to the previous evaluation campaigns wherethe temporal relation recognition task was simpli-fied by restricting grammatical context (events inadjacent sentences, events and times in the samesentences) and proposed relation pairs, TempEval-3does not set any context in which temporal re-lations have to be identified.
Thus, for temporalrelation recognition the challenges consist of: first,detecting a pair of events, or an event and a timethat constitutes a temporal relation; and, second,determining what semantic label to assign to theproposed pair.
Moreover, TempEval-3 proposes thetask of end-to-end temporal processing in whichevents and times, their attributes and relations haveto be identified from a raw text input.In this paper we present a data-driven approachto all-around temporal processing of text.
A num-ber of machine-learning detectors were designed torecognize temporal ?markables?
(events and times)and their attributes.
The key feature of our approachis that argument pairs, as well as relations betweenthem, are jointly estimated without specifying in ad-vance the context in which these pairs have to occur.2 Our Approach2.1 Timex Processing2.1.1 Timex Recognition and NormalizationThe proposed method for timex recognition im-plements a supervised machine learning approachthat processes each chunk-phrase derived from theparse tree.
Time expressions are detected by themodel as phrasal chunks in the parse with their cor-responding spans.
In addition, the model is boot-strapped by substitutions of temporal triggers withtheir synonyms learned by the Latent Words Lan-guage Model (Deschacht et al 2012) as described in(Kolomiyets et al 2011).
We implemented a logis-tic regression model that makes use of the followingfeatures:?
the head word of the phrase and its POS tag;?
all tokens and POS tags in the phrase as a bagof words;?
the word-shape representation of the head wordand the entire phrase, e.g.
Xxxxx 99 for theexpression April 30;83?
the condensed word-shape representation forthe head word and the entire phrase, e.g.
X(x)(9) for the expression April 30;?
the concatenated string of the syntactic types ofthe children of the phrase in the parse tree;?
the depth in the parse tree.In addition, we considered a special label for sin-gle tokens of time expressions.
In this way, wedetect parts of temporal expressions if they cannotbe found in the chunk-based fashion.
In detail, ifa token is recognized as part of a timex and satis-fies the pre-condition on its POS tag, we employ a?look-behind?
rule for the phrasal chunk to matchthe begin token of the temporal expression.
The le-gitimate start POS tags are determiners, adjectives,and cardinals.
Another set of rules specifies unsuit-able timexes, such as single cardinals with valuesoutside predefined ranges of day-of-month, month-of-year and year numbers.Normalization of temporal expressions is a pro-cess of estimating standard temporal values andtypes for temporal expressions.
Due to a large vari-ance of expressions denoting the same date andvagueness in language, rule-based approaches areusually employed for the normalization task, and ourimplementation is a rule-based system.
The nor-malization procedure is the same as described in(Kolomiyets and Moens, 2010), which participatedin TempEval-2.2.2 Event ProcessingThe proposed method to event recognition imple-ments a supervised machine learning approach thatclassifies every single token in the input sentence asan event instance of a specific semantic type.
We im-plemented a logistic regression model with featureslargely derived from the work of Bethard and Martin(2006):?
the token, its lemma, coarse and fine-grainedPOS tags, token?s suffixes and affixes;?
token?s hypernyms and derivations in Word-Net;?
the grammatical class of the chunk, in whichthe token occurs;?
the lemma of the governing verb of the token;?
phrasal chunks in the contextual window;?
the light verb feature for the governing verb;?
the polarity of the token?s context;?
the determiner of the token and the sentence?ssubject;In addition, we classify the tense attribute for thedetected event by applying a set of thirteen hand-crafted rules.2.3 Temporal Relation ProcessingTemporal relation recognition is the most difficulttask of temporal information processing, as it re-quires recognitions of argument pairs, and subse-quent classifications of relation types.
Our ap-proach employs a shift-reduce parsing technique,which treats each document as a dependency struc-ture of annotations labeled with temporal relations(Kolomiyets et al 2012).
On the one hand, the ad-vantage of the model is that the relation argumentsand the relation between them are extracted as a sin-gle decision of a statistical classification model.
Onthe other hand, such a decision is local and mightnot lead to the optimal global solution1.
The follow-ing features for deterministic shift-reduce temporalparsing are employed:?
the token, its lemma, suffixes, coarse and fine-grained POS tags;?
the governing verb, its POS tag and suffixes;?
the sentence?s root verb, its lemma and POStag;?
features for a prepositional phrase occurrence,and domination by an auxiliary or modal verb;?
features for the presence of a temporal signal inthe chunk and co-occurrence in the same sen-tence;?
a feature indicating if the sentence root verblemmas of the arguments are the same;?
the temporal relation between the argument andthe document creation time (DCT) (see below);?
a feature indicating if one argument is labeledas a semantic role of the other;?
timex value generation pattern (e.g.
YYYY-MMfor 2013-02, or PXY for P5Y) and timexgranularity (e.g.
DAY-OF-MONTH for Friday,MONTH-OF-YEAR for February etc.
);1For further details on the deterministic temporal parsingmodel we refer the reader to (Kolomiyets et al 2012).84Training Test P R F1TimeBankTimeBank10-fold0.907 0.99 0.947AQUAINT 0.755 0.972 0.850Silver 0.736 0.963 0.834AQUAINTTimeBank 0.918 0.986 0.951AQUAINT10-fold0.795 0.970 0.874Silver 0.746 0.959 0.851SilverTimeBank 0.941 0.976 0.958AQUAINT 0.822 0.955 0.883Silver 10-fold 0.798 0.944 0.865Table 1: Results for timex detection in different corpora.As one of the features above provides informationabout the temporal relation between the argumentand the DCT, we employ an interval-based algebrato classify relations between timexes and the DCT.In case the argument is an event, we use a simplelogistic regression classifier with the following fea-tures:?
the event token, its lemma, coarse and fine-grained POS tags;?
tense, polarity, modality and aspect attributes;?
the token?s suffixes;?
the governing verb, its POS tag, tense and thegrammatical class of the chunk, in which theevent occurs;?
preceding tokens of the chunk;3 Results3.1 Pre-Evaluation ResultsThe following results are obtained by 10-fold cross-validations and corpus cross-validations with re-spect to the evaluation criteria and metrics used inTempEval-2.
Tables 1 and 2 present the results forthe timex recognition and normalization tasks (TaskA), and, Tables 3 and 4 present the results for theevent recognition task (Task B).As can be seen from the pre-evaluation results, themost accurate classification of timexes on all cor-pora in terms of F1 score is achieved for the modeltrained on the Silver corpus.
As for timex normaliza-tion, the performances on TimeBank and the SilverTest Corpus Type Acc.
Value Acc.TimeBank 0.847 0.742AQUAINT 0.852 0.714Silver 0.853 0.739Table 2: Results for normalization in different corpora.Training Test P R F1TimeBankTimeBank10-fold0.82 0.641 0.72AQUAINT 0.864 0.649 0.741Silver 0.888 0.734 0.804AQUAINTTimeBank 0.766 0.575 0.657AQUAINT10-fold0.900 0.776 0.836Silver 0.869 0.755 0.808SilverTimeBank 0.827 0.717 0.768AQUAINT 0.906 0.807 0.854Silver 10-fold 0.916 0.888 0.902Table 3: Results for event detection in different corpora.Training Test Class Acc.TimeBankTimeBank 10-fold 0.691AQUAINT 0.717Silver 0.804AQUAINTTimeBank 0.620AQUAINT 10-fold 0.830Silver 0.794SilverTimeBank 0.724AQUAINT 0.829Silver 10-fold 0.900Table 4: Results for event classification in different cor-pora.corpus are not very different for type and value accu-racies.
Similarly, we observe the tendency for a bet-ter performance on larger datasets with an exceptionfor 10-fold cross-validation using the AQUAINTcorpus.3.2 Evaluation ResultsFor the official evaluations we submitted three runsof the system, one of which addresses Tasks Aand B (timex and event recognition)2, one (KUL-2During the official evaluation period, this run was re-submitted with no changes in the output together with KUL-TE3RunABC, which led to duplicate evaluation results known85Run Relaxed EvaluationP R F1 RankKULRun-1 0.929 0.769 0.836 21/23KUL-TE3RunABC0.921 0.754 0.829 22/23Run Strict EvaluationP R F1 RankKULRun-1 0.77 0.63 0.693 22/23KUL-TE3RunABC0.814 0.667 0.733 15/23Table 5: Results for the timex detection task.TE3RunABC) provides a full temporal informa-tion processing pipeline (Task ABC), and the onefor Task C only (KUL-TaskC).
For KULRun-1 weemployed the recognition models described above,all trained on the aggregated corpus comprisingall three available training corpora in the evalua-tions.
For KUL-TE3RunABC we also trained themarkable recognition models on the aggregated cor-pus, but the event recognition output was slightlychanged in order to merge multiple consequentevents of the same semantic class into a single multi-token event.
The temporal dependency parsingmodel was trained on the TimeBank and AQUAINTcorpora only, with a reduced set of relation labels.This decision was motivated by the time constraintsand the training time needed.
The final relation la-bel set contains the following temporal relation la-bels: BEFORE, AFTER, DURING, DURING INV,INCLUDES and IS INCLUDED.
Below we presentthe obtained results for each task separately.
The re-sults for Task A are presented in Tables 5 and 6, forTask B in Tables 7 and 8, and, for Task ABC andTask-C-only in Table 9.
It is worth mentioning thatfor Task B the aspect value was provided as NONE,thus this evaluation criterion is not representative forour system.4 ConclusionFor TempEval-3 we proposed a number of statisti-cal and rule-based approaches.
For Task A we em-ployed a logistic regression classifier whose outputas KULRun-1 and KULRun-2.
Further in the paper, we refer tothis run as simply to KULRun-1.Run RankKULRun-1F1Value Type18/230.629 0.741AccuracyValue Type14/230.752 0.886KUL-TE3RunABCF1Value Type19/230.621 0.733AccuracyValue Type15/230.750 0.885Table 6: Results for the timex normalization task.Run P R F1 RankKULRun-1 0.807 0.779 0.792 5/15KUL-TE3RunABC0.776 0.765 0.77 12/15Table 7: Results for the event detection task.Run RankKULRun-1F1Class Tense Aspect3/150.701 n.a.
n.a.AccuracyClass Tense Aspect3/150.884 n.a.
n.a.KUL-TE3RunABCF1Class Tense Aspect5/150.687 0.497 0.632AccuracyClass Tense Aspect1/150.891 0.644 0.82Table 8: Results for the event attribute recognition task.Run P R F1 RankKUL-TE3RunABC0.18 0.202 0.191 8/8KUL-TaskC 0.234 0.265 0.248 10/13Table 9: Results for Tasks ABC (end-to-end processing)and C (gold entities are given).was augmented by a small number of hand-craftedrules to increase the recall.
For the temporal ex-86pression normalization subtask we employed a rule-based system which estimates the attribute values forthe recognized timexes.
For Task B we proposeda logistic regression classifier which processes in-put tokens and classifies them as event instances ofparticular semantic classes.
The optional tense at-tribute was estimated by a number of manually de-signed rules.
For the most difficult tasks, Task ABCand Task C, we proposed a dependency parsing tech-nique that jointly learns from data what argumentsconstitute a temporal relation and what the temporalrelation label is.
Due to evaluation time constraintsand the time needed to model training, we reducedthe set of relation labels and trained the model ontwo small annotated corpora.The evaluations evidenced that the use of largerannotated data sets did not improve the timex recog-nition performance as it was expected from the pre-evaluations.
Interestingly, we did not observe the ex-pected improvement in terms of recall, as it was thecase in the pre-evaluations.
Yet, the timex normal-ization performance levels in the official evaluationswere slightly higher than in the pre-evaluations.
Incontrast to timex recognition, the use of a large an-notated corpus improved the results for event recog-nition.
The pilot implementation of a temporalparser for newswire articles showed the lowest per-formance in the evaluations for Task ABC, but stillprovided decent results for Task C. One of the ad-vantages of the proposed temporal parser is that theparser selects arguments for a temporal relation andclassifies it at the same time.
The decision is drawnby a statistical model trained on the annotated data,that is, the parser does not consider any particularpredefined grammatical context in which the relationarguments have to be found.
Another weak point ofthe parser is that it requires a large volume of high-quality annotations and long training times.
The lasttwo facts made it impossible to fully evaluate theproposed temporal parsing model, and we will fur-ther investigate the effectiveness of the model.AcknowledgmentsThe presented research was supporter by the TER-ENCE (EU FP7-257410) and MUSE (EU FP7-296703) projects.ReferencesSteven Bethard and James H Martin.
2006.
Identificationof Event Mentions and their Semantic Class.
In Pro-ceedings of the 2006 Conference on Empirical Meth-ods in Natural Language Processing, pages 146?154.Association for Computational Linguistics.Koen Deschacht, Jan De Belder, and Marie-FrancineMoens.
2012.
The Latent Words Language Model.Computer Speech & Language.Oleksandr Kolomiyets and Marie-Francine Moens.
2010.Kul: Recognition and Normalization of Temporal Ex-pressions.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, pages 325?328.Association for Computational Linguistics.Oleksandr Kolomiyets, Steven Bethard, and Marie-Francine Moens.
2011.
Model-Portability Experi-ments for Textual Temporal Analysis.
In Proceed-ings of the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies, pages 271?276.Oleksandr Kolomiyets, Steven Bethard, and Marie-Francine Moens.
2012.
Extracting Narrative Time-lines as Temporal Dependency Structures.
In Proceed-ings of the 50th Annual Meeting of the Association forComputational Linguistics, pages 88?97.
Associationfor Computational Linguistics.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Graham Katz, and James Pustejovsky.2007.
Semeval-2007 Task 15: TempEval TemporalRelation Identification.
In Proceedings of the 4th In-ternational Workshop on Semantic Evaluations, pages75?80.
Association for Computational Linguistics.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
Semeval-2010 Task 13:TempEval-2.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, pages 57?62.
As-sociation for Computational Linguistics.87
