Free Indexation: Combinator ia l  Analysis andA Composi t ional  Algorithm*Sand iway  Fong545 Techno logy  Square ,  Rm.
NE43-810,M IT  Art i f ic ia l  In te l l igence Laboratory ,Cambr idge  MA 02139In ternet :  sand iway@ai .mi t .eduAbst ractThe principle known as 'free indexation' playsan important role in the determination f the refer-ential properties of noun phrases in the principle-and-parameters language framework.
First, by in-vestigating the combinatorics of free indexation,we show that the problem of enumerating all possi-ble indexings requires exponential time.
Secondly,we exhibit a provably optimal free indexation al-gorithm.1 Introduct ionIn the principles-and-parameters model of lan-guage, the principle known as 'free indexation'plays an important part in the process of deter-mining the referential properties of elements uchas anaphors and pronominals.
This paper ad-dresses two issues.
(1) We investigate the combi-natorics of free indexation.
By relating the prob-lem to the n-set partitioning problem, we showthat free indexation must produce an exponen-tial number of referentially distinct phrase struc-tures given a structure with n (independent) nounphrases.
(2) We introduce an algorithm for free in-dexation that is defined compositionally on phrasestructures.
We show how the compositional na-ture of the algorithm makes it possible to incre-mentally interleave the computation of free index-ation with phrase structure construction.
Addi-tionally, we prove the algorithm to be an 'optimal'procedure for free indexation.
More precisely, byrelating the compositional structure of the formu-lation to the combinatorial nalysis, we show thatthe algorithm enumerates precisely all possible in-dexings, without duplicates.2 Free Indexat ionConsider the ambiguous entence:(1) John believes Bill will identify him*The author would like to acknowledge Eric S. Ris-tad, whose interaction helped to motivate much ofthe analysis in this paper.
Also, Robert C. Berwick,Michael B. Kashket, and Tanveer Syeda providedmany useful comments on earlier drafts.
This workis supported by an IBM Graduate Fellowship.In (1), the pronominal "him" can be interpretedas being coreferential with "John", or with someother person not named in (1), but not with "Bill".We can represent these various cases by assigningindices to all noun phrases in a sentence togetherwith the interpretation that two noun phrases arecoreferential if and only if they are coindexed, thatis, if they have the same index.
Hence the follow-ing indexings represent the three coreference op-tions for pronominal "him" :1(2) a. John1 believes Bill2 will identify him1b.
John1 believes Bill2 will identify him3c.
*John1 believes Bills will identify him2In the principles-and-parameters framework(Chomsky \[3\]), once indices have been assigned,general principles that state constraints on the lo-cality of reference of pronominals and names (e.g.
"John" and "Bill") will conspire to rule out theimpossible interpretation (2c) while, at the sametime, allow the other two (valid) interpretations.The process of assigning indices to noun phrasesis known as "free indexation," which has the fol-lowing general form:(4) Assign indices freely to all nounphrases?In such theories, free indexation accounts for thefact that we have coreferential mbiguities in lan-guage.
Other principles interact so as to limit the1Note that the indexing mechanism used above istoo simplistic a framework to handle binding examplesinvolving inclusion of reference such as:(3) a. We1 think that I1 will winb.
We1 think that Is will winc.
*We1 like myself 1d.
John told Bill that they should leaveRicher schemes that address ome of these problems,for example, by representing indices as sets of num-bers, have been proposed.
See Lasnik \[9\] for a discus-sion on the limitations of, and alternatives to, simpleindexation.
Also, Higginbotham \[7\] has argued againstcoindexation (a symmetric relation), and in favour ofdirected links between elements (linking theory).
Ingeneral, there will be twice as many possible 'linkings'as indexings for a given structure.
However, note thatthe asymptotic results of Section 3 obtained for freeindexation will also hold for linking theory.105number of indexings generated by free indexationto those that are semantically well-formed.In theory, since the indices are drawn from theset of natural numbers, there exists an infinitenumber of possible indexings for any sentence.However, we are only interested in those indexingsthat are distinct with respect o semantic interpre-tation.
Since the interpretation of indices is con-cerned only with the equality (and inequality) ofindices, there are only a finite number of seman-tically different indexings.
3 For example, "John1likes Mary2" and "John23 likes Mary4" are con-sidered to be equivalent indexings.
Note that thedefinition in (4) implies that "John believes Billwill identify him" has two other indexings (in ad-dition to those in (2)):(5) a.
*John1 believes Bill1 will identify him1b.
*John1 believes Bill1 will identify him2subsets.
For example, a set of four elements{w, x, y, z} can be partitioned into two subsets inthe following seven ways:{w, z}{y} {w,y, y}y, z){w}The number of partitions obtained thus isusually represented using the notation {~}(Knuth \[8\]).
In general, the number of ways ofpartitioning n elements into m sets is given by thefollowing formula.
(See Purdom & Brown \[10\] fora discussion of (6).
)(6){:++11} = { :}  + (m + 1){m:  1 }In some versions of the theory, indices are onlyfreely assigned to those noun phrases that havenot been coindexed through a rule of movement(Move-a).
(see Chomsky \[3\] (pg.331)).
For exam-ple, in "Who1 did John see  \[NPt\]l?
", the rule ofmovement effectively stipulates that "Who" andits trace noun phrase must be coreferential.
Inparticular, this implies that free indexation mustnot assign different indices to "who" and its traceelement.
For the purposes of free indexation, wecan essentially 'collapse' these two noun phrases,and treat them as if they were only one.
Hence,this structure contains only two independent nounphrases.
43 The  Combinator i cs  o fF ree  Indexat ion  ........In this section, we show that free indexation gen-erates an exponential number of indexings in thenumber of independent noun phrases in a phrasestructure.
We achieve this result by observing thatthe problem of free indexation can be expressed interms of a well-known combinatorial partitioningproblem.Consider the general problem of partitioninga set of n elements into m non-empty (disjoint)2The exact form of (4) varies according to differentversions of the theory.
For example, in Chomsky \[4\](pg.59), free indexation is restricted to apply to A-positions at the level of S-structure, and to A-positionsat the level of logical form.ZIn other words, there are only a finite number ofequivalence classes on the relation 'same core\[erencerelatlons hold.'
This can easily be shown by inductionon the number of indexed elements.4TechnicaJly, "who" and its trace are said to forma chain.
Hence, the structure in question contains twodistinct chains.for n ,m > 0The number of ways of partitioning n elementsinto zero sets, {o}, is defined to be zero for n > 0and one when n = 0.
Similarly, {,no}, the numberof ways of partitioning zero elements into m setsis zero for m > 0 and one when m = 0.We observe that the problem of free indexa-tion may be expressed as the problem of assign-ing 1, 2, .
.
.
,n distinct indices to n noun phraseswhere n is the number of noun phrases in a sen-tence.
Now, the general problem of assigning mdistinct indices to n noun phrases is isomorphicto the problem of partitioning n elements into mnon-empty disjoint subsets.
The correspondencehere is that each partitioned subset represents aset of noun phrases with the same index.
Hence,the number of indexings for a sentence with n nounphrases is:(7)m=l(The quantity in (7) is commonly known asBell's Exponential Number B.; see Berge \[2\].
)The recurrence relation in (6) has the followingsolution (Abramowitz \[1\]):(8)Using (8), we can obtain a finite summationform for the number of indexings:(9)(-1) k" S. = (?7  k-7.
'rn=l  k=0106It can also be shown (Graham \[6\]) that Bn isasymptotically equal to (10):(10)mrtn em~-n- ~where the quantity mn is given by:(11)1mn In mn= n - -2That is, (10) is both an upper and lower boundon the number of indexings.
More concretely, toprovide some idea of how fast the number of pos-sible indexings increases with the number of nounphrases in a phrase structure, the following tableexhibits the values of (9) for the first dozen valuesof n:NPs Indexings NPs Indexings1 1 7 8772 2 8 41403 5 9 211474 15 10 1159755 52 11 6785706 203 12 41235974 A CompositionalAlgorithmIn this section, we will define a compositional go-rithm for freeindexation that provably enumeratesall and only all the possible indexings predicted bythe analysis of the previous ection.The PO-PARSER is a parser basedon a principles-and-parameters framework with auniquely flexible architecture (\[5\]).
In this parser,linguistic principles uch as free indexation may beapplied either incrementally as bottom-up hrasestructure construction proceeds, or as a separateoperation after the complete phrase structure fora sentence is recovered.
The PO-PARSER was de-signed primarily as a tool for exploring how toorganize linguistic principles for efficient process-ing.
This freedom in principle application allowsone to experiment with a wide variety of parserconfigurations.Perhaps the most obvious algorithm for free in-dexation is, first, to simply collect all noun phrasesoccurring in a sentence into a list.
Then, it is easyto obtain all the possible indexing combinationsby taking each element in the list in turn, andoptionally coindexing it with each element follow-ing it in the list.
This simple scheme produceseach possible indexing without any duplicates andworks well in the case where free indexing appliesafter structure building has been completed.The problem with the above scheme is that it isnot flexible enough to deal with the case when free107indexing is to be interleaved with phrase structureconstruction.
Conceivably, one could repeatedlyapply the algorithm to avoid missing possible in-dexings.
However, this is very inefficient, that is,it involves much duplication of effort.
Moreover,it may be necessary to introduce extra machin-ery to keep track of each assignment of indicesin order to avoid the problem of producing du-plicate indexings.
Another alternative is to sim-ply delay the operation until all noun phrases inthe sentence have been parsed.
(This is basicallythe same arrangement as in the non-interleavedcase.)
Unfortunately, this effectively blocks theinterleaved application of other principles that arelogically dependent on free indexation to assignindices.
For example, this means that principlesthat deal with locality restrictions on the bind-ing of anaphors and pronominals cannot be in-terleaved with structure building (despite the factthat these particular parser operations can be ef-fectively interleaved).An algorithm for free indexation that is definedcompositionally on phrase structures can be effec-tively interleaved.
That is, free indexing should bedefined so that the indexings for a phrase is somefunction of the indexings of its sub-constituents.Then, coindexings can be computed incrementallyfor all individual phrases as they are built.
Ofcourse, a compositional gorithm can also be usedin the non-interleaved case.Basically, the algorithm works by maintaining aset of indices at each sub-phrase of a parse tree.
5Each index set for a phrase represents the rangeof indices present in that phrase.
For example,"Whoi did Johnj see tiT' has the phrase structureand index sets shown in Figure 1.There are two separate tasks to be performedwhenever two (or more) phrases combine to forma larger phrase, s First, we must account for thepossibility that elements in one phrase could becoindexed (cross-indexed) with elements from theother phrase.
This is accomplished by allowing in-dices from one set to be (optionally) merged withdistinct indices from the other set.
For example,the phrases "\[NpJohni\]" and "\[vP likes himj\]"have index sets {i} and {j}, respectively.
Freeindexation must allow for the possibilities that"John" and "him" could be coindexed or main-tain distinct indices.
Cross-indexing accounts forthis by optionally merging indices i and j. Hence,we obtain:(12) a. Johnl likes him/, i merged with j5For expository reasons, we consider only pure in-dices.
The actual algorithm keeps track of additionalinformation, such as agreement features like person,number and gender, associated with each index.
Forexample, irrespective of configuration, "Mary" and"him" can never have the same index.\[cP \[NP who/\] \[~- did \[IP \[NP Johnj\] \[vP see \[NP tdl\]\]\]{i,j} {i} {/,j} {i,j} {j} {i} {/}Figure 1 Index sets for "Who did John see?"b.
Johni likes himj, i not merged with jSecondly, we must find the index set of the ag-gregate phrase.
This is just the set union of the in-dex sets of its sub-phrases after cross-indexation.In the example, "John likes him", (12a) and (125)have index sets {i} and {i, j}.More precisely, let Ip be the set of all in-dices associated with the Binding Theory-relevantelements in phrase P. Assume, without lossof generality, that phrase structures are binarybranching.
7 Consider a phrase P = Iv X Y\] withimmediate constituents X and Y.
Then:1.
Cross Indexing: Let fx  represent those ele-ments of Ix which are not also members ofIv, that is, (Ix - I v ) .
Similarly, let iv  be(Iv - Ix).
s(a) If either ix  or f r  are empty sets, thendone.
(b) Let x and y be members of i x  and fy,respectively.
(c) Eifher merge indices z and y or do noth-ing.
(d) Repeat from step ( la)  with ix_ - {z} inplace of ix .
Replace I r  with Iv - {y} ifand y have been merged.2.
Index Set Propagation: Ip = Ix O Iv.The nondeterminism in step (lc) of cross-indexing will generate all and only all (i.e.
with-out duplicates) the possible indexings.
We willshow this in two parts.
First, we will argue thateSome rea?lers may realize that the algorithm musthave an additional step in cases where the largerphrase itself may be indexed, for instance, as in\[NPi\[NP, John's \] mother\].
In such cases, the thirdstep is slCmply to merge the singleton set consisting ofthe index of the larger phrase with the result of cross-indexing in the first step.
(For the above example, theextra step is to just merge {i} with {j}.)
For exposi-tory reasons, we will ignore such cases.
Note that noloss of generality is implied since a structure of theform \[NPI \[NPj... ~.
.
-\] .
.
.
~ .
.
.
\ ]  can be can always behandled as \[P1 \[NPi\]\[P2\[NPj... o?.
.
.
\ ] .
.
.
/~.
.
.
\ ] \ ] .rThe algorithm generalizes to n-ary branching us-ing iteration.
For example, a ternary branching struc-ture such as \[p X Y Z\] would be handled in the sameway as \[p X\[p, Y Z\]\].SNote that ix and iv are defined purely for no-tational convenience.
That is, the algorithm directlyoperates on the elements of Ix and Iy.108/N P k / ~N Pj Y PiFigure 2 Right-branching treethe above algorithm cannot generate duplicate in-dexings: That is, the algorithm only generatesdistinct indexings with respect o the interpreta-tion of indices.
As shown in the previous ection,the combinatorics of free-indexlng indicates thatthere are only B ,  possible indexings.
Next, wewill demonstrate hat the algorithm generates ex-actly that number of indexings.
If the algorithmsatisfies both of these conditions, then we haveproved that it generates all the possible indexingsexactly once.1.
Consider the definition of cross-indexing, ixrepresents hose indices in X that do not ap-pear in Y.
(Similarly for iv.)
Also, whenevertwo indices are merged in step (lb), they are'removed' from ix  and iv  before the next it-eration.
Thus, in each iteration, z and y fromstep (lb) are 'new' indices that have not beenmerged with each other in a previous itera-tion.
By induction on tree structures, it iseasy to see that two distinct indices cannotbe merged with each other more than once.Hence, the algorithm cannot generate dupli-cate indexings.2.
We now demonstrate why the algorithm gen-erates exactly the correct number of index-ings by means of a simple example.
Withoutloss of generality, consider the right-branchingphrase scheme shown in Figure 2.Now consider the decision tree shown in Fig-ure 3 for computing the possible indexings ofthe right-branching tree in a bottom-up fash-ion.Each node in the tree represents he index setof the combined phrase depending on whetherthe noun phrase at the same level is cross-NPsgPii=NPji=NPkDecision Treek i=k  i , j { {i,k} {i, j} {~j} {i, j ,k}: : : :Figure 3 Decision tree11 21 2 2 2 3r',, B. b.
B. b..122232232233334: : : : :Figure 4 Condensed ecision treeindexed or not.
For example, {i} and {i, j}on the level corresponding to NPj  are the twopossible index sets for the phrase Pij.
Thepath from the root to an index set containsarcs indicating what choices (either to coin-dex or to leave free) must have been made inorder to build that index set.
Next, let usjust consider the cardinality of the index setsin the decision tree, and expand the tree onemore level (for NP~) as shown in Figure 4.Informally speaking, observe that each deci-sion tree node of cardinality i 'generates' ichild nodes of cardinality i plus one child nodeof cardinality i + 1.
Thus, at any given level,if the number of nodes of cardinality m is cm,and the number of nodes of cardinality m-  1is c,,-1, then at the next level down, therewill be mcm + c,n-1 nodes of cardinality m.Let c(n,m) denote the number of nodes atlevel n with cardinality m. Let the top levelof the decision tree be level 1.
Then:(13)c(n+l ,  re+l)  = c(n, m)+(m+l)c(n, re+l)Observe that this recurrence relation has thesame form as equation (6).
Hence the al-gorithm generates exactly the same numberof indexings as demanded by combinatorialanalysis.5 Conc lus ionsThis paper has shown that free indexation pro-duces an exponential number of indexings perphrase structure.
This implies that all algorithmsthat compute free indexation, that is, assign in-dices, must also take at least exponential time.
Inthis section, we will discuss whether it is possiblefor a principle-based parser to avoid the combina-torial 'blow-up' predicted by analysis.First, let us consider the question whether the'full power' of the free indexing mechanism is nec-essary for natural anguages.
Alternatively, wouldit be possible to 'shortcut' the enumeration pro-cedure, that is, to get away with producing fewerthan B ,  indexings?
After all, it is not obviousthat a sentence with a valid interpretation can beconstructed for every possible indexing.
However,it turns out (at least for small values of n; seeFigures 5 and 6 below) that language makes useof every combination predicted by analysis.
Thisimplies, that all parsers must be capable of pro-ducing every indexing, or else miss valid interpre-tations for some sentences.There are B3 = 5 possible indexings for threenoun phrases.
Figure 5 contains example sen-tences for each possible indexing.
9 Similarly,there are fifteen possible indexings for four nounphrases.
The corresponding examples are shownin Figure 6.Although it may be the case that a parser mustbe capable of producing every possible indexing,it does not necessarily follow that a parser mustenumerate every indexing when parsing a parlicu-lar sentence.
In fact, for many cases, it is possibleto avoid exhaustively exploring the search spaceof possibilities predicted by combinatorial analy-sis.
To do this, basically we must know, a priori,what classes of indexings are impossible for a givensentence.
By factoring in knowledge about restric-tions on the locality of reference of the items to beindexed (i.e.
binding principles), it is possible toexplore the space of indexings in a controlled fash-ion.
For example, although free indexation impliesthat there are five indexings for "John thought \[sTom forgave himself \] ", we can make use of thefact that "himself" must be coindexed with an el-ement within the subordinate clause to avoid gen-STo make the boundary cases match, just definec(0, 0) to be 1, and let c(0, m) = 0 and c(n, 0) = 0 form > 0 and n > 0, respectively.9PRO is an empty (non-overt) noun phraseelement.109(111)012)(121)(122)(123)John1 wanted PRO1 to forgive himselflJohn1 wanted PRO1 to forgive him2Johnl wanted Mary 2 to forgive himlJohnl wanted Mary 2 to forgive herself2John1 wanted Mary 2 to forgive him3Figure 5 Example sentences for B3(1111)(1222)(1112)(1221)(1223)(1233)(1122)(1211)(1121)(1232)0123)0213)0e31)(1234)John1John1John1JohnlJohnlJohn1JohnlJohn1JOhnlJohn1John1John1John1John1persuaded himselfl that hel should give himselfl uppersuaded Mary 2 PRO2 to forgive herself2persuaded himselfl PRO1 to forgive herspersuaded Mary 2 PROs to forgive himlpersuaded Mary 2 PRO~ to forgive him3wanted Bill2 to ask Mary a PRO3 to leavewantedwantedwantedwantedwantedwantedwantedwantedPRO1 to tell Mary 2 about herself2Mary 2 to tell him1 about himselflPRO1 to tell Mary 2 about himself1Bill2 to tell Marya about himself2PRO1 to tell Mary 2 about TornaMary 2 to tell him1 about Torn3Mary 2 to tell Toma about himlMary2 to tell Toma about Bill4Figure 6 Example sentences for B4crating indexings in which "Tom" and "himself"are not coindexed.
1?Note that the early elimina-tion of ill-formed indexings depends crucially ona parser's ability to interleave binding principleswith structure building.
But, as discussed in Sec-tion 4, the interleaving of binding principles logi-cally depends on the ability to interleave free in-dexation with structure building.
Hence the im-portance of an formulation of free indexation, suchas the one introduced in Section 4, which can beeffectively interleaved.References\[1\] M. Abramowitz ~ I.A.
Stegun, Handbook ofMathematical Functions.
1965.
Dover.\[2\] Berge, C., Principles of Combinatorics.
1971.Academic Press.\[3\] Chornsky, N.A., Lectures on Government andBinding: The Pisa Lectures.
1981.
Foris Pub-lications.1?This leaves only two remaining indexings: (1)where "John" is coindexed with "Tom" and "himself",and (2) where "John" has a separate index.
Similarly,if we make use of the fact that "Tom" cannot be coin-dexed with "John", we can pare the list of indexingsdown to just one (the second case).ii0\[4\] Chomsky, N.A., Some Concepts and Conse-quences of of the Theory of Government andBinding.
1982.
MIT Press.\[5\] Fong, S. &: R.C.
Berwick, "The Compu-tational Implementation of Principle-BasedParsers," InternationM Workshop on Pars-ing Technologies.
Carnegie Mellon University.1989.\[6\] Graham, R.L., D.E.
Knuth, & O. Patash-nik, Concrete Mathematics: A Foundationfor Computer Science.
1989.
Addison-Wesley.\[7\] Higginbotham, J., "Logical Form, Binding,and Nominals," Linguistic Inquiry.
Summer1983.
Volume 14, Number 3.\[8\] Knuth, D.E., The Art of Computer Program-ming: Volume 1 / Fundamental Algorithms.2nd Edition.
1973.
Addison-Wesley.\[9\] Lasnik, H. & J. Uriagereka, A Course in GBSyntax: Lectures on Binding and Empty Cat-egories.
1988.
M.I.T.
Press.\[10\] Purdom, P.W., Jr. ~ C.A.
Brown, The Anal-ysis of Algorithms.
1985.
CBS Publishing.
