Proceedings of NAACL-HLT 2013, pages 502?506,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsImproving speech synthesis quality by reducing pitch peaksin the source recordingsLuisina Violante, Pablo Rodr?
?guez Zivic and Agust?
?n GravanoDepartamento de Computacio?n, FCEyNUniversidad de Buenos Aires, Argentina{lviolante,prodriguez,gravano}@dc.uba.arAbstractWe present a method for improving the perceived nat-uralness of corpus-based speech synthesizers.
It con-sists in removing pronounced pitch peaks in the origi-nal recordings, which typically lead to noticeable dis-continuities in the synthesized speech.
We perceptu-ally evaluated this method using two concatenative andtwo HMM-based synthesis systems, and found that us-ing it on the source recordings managed to improvethe naturalness of the synthesizers and had no effecton their intelligibility.1 IntroductionBy definition, corpus-based speech synthesizers,such as concatenative and HMM-based systems,rely heavily on the quality of the speech corpus usedfor building the systems.
Creating speech corporafor this purpose is expensive and time consuming, sowhen the synthesized speech obtained is not as goodas expected, it may be desirable to modify or correctthe corpus rather than record a new one.
Commoncorrections are limited to discarding mispronouncedwords or noisy units.
In this work we describe a sim-ple method for attenuating pronounced pitch peaks,a frequent problem in recordings made by profes-sional speakers, and evaluate it using four differentcorpus-based systems.
Sections 2 and 3 describe thespeech synthesis systems and corpus employed inthis work.
In Section 4 we present the method forreducing pitch peaks.
In Section 5 we describe howwe evaluated the effect of our method on intelligibil-ity and naturalness of the synthesizers.2 Synthesis systemsFestival1 is a general framework for building speechsynthesis systems, written in C++ and developed bythe Center of Speech Technology Research at theUniversity of Edinburgh (Black et al 2001).
Itprovides an implementation of concatenative speechsynthesis as well as synthesis based on HiddenMarkov Models (HMM).
In this work we used a Fes-tival module called Clunits unit selection engine tobuild concatenative synthesizers.
The unit size is thephone, although since a percentage of the previousunit is included in the acoustic distance measure, theunit size is rather ?phone plus previous phone?, thussimilar to a diphone (Black and Lenzo, 2007).
Ad-ditionally, we used a second Festival module calledClustergen parametric synthesis engine for buildingHMM-based speech synthesizers.MARY TTS2 is an open-source synthesis plat-form written in Java, originally jointly developedby the Language Technology Lab at the GermanResearch Center for Artificial Intelligence (DFKI)and the Institute of Phonetics at Saarland Univer-sity, and currently maintained by DFKI.
Like Fes-tival, MARY provides toolkits for building unit se-lection and HMM-based synthesis voices (Schro?derand Trouvain, 2003).3 CorpusFor building our systems we used the SECYT cor-pus, created by the Laboratorio de Investigacio-nes Sensoriales (Universidad de Buenos Aires) for1http://festvox.org/festival2http://mary.dfki.de502studying the prosody of Argentine Spanish (Torresand Gurlekian, 2004).
It consists of 741 declarativesentences recorded by a female professional speaker(pitch range: 130-380Hz).
On average, sentencesare 7 words and 3.9 seconds long.
The entire corpushas manual phonetic transcriptions and time align-ments, following a version of the Speech AssessmentMethods Phonetic Alphabet (SAMPA) adapted forArgentine Spanish (Gurlekian et al 2001).A priori, this corpus is a very good candidate forbuilding a synthesis system ?
its 741 sentences arephonetically balanced, the audio quality is excellent,and it has precise time-aligned phonetic transcrip-tions.
We thus built two concatenation systems us-ing this corpus: Festival?s diphone-like and MARY?sdiphone systems.
The results were not satisfactory.The new voices presented clearly noticeable discon-tinuities, both in intensity and pitch, which affectedtheir naturalness ?
as judged impressionistically bythe authors and non-expert colleagues.In an attempt to attenuate these problems, we lev-eled the intensity of all recordings to a mean of 72dBusing linear interpolation.
Specifically, each soundwas multiplied by a number such that its new aver-age RMS intensity was 72dB; so that all sentencesin the corpus ended up with the same average inten-sity.
After this conversion, we rebuilt the systems.The resulting voices sounded somewhat better, buttheir most noticeable problem, severe pitch discon-tinuities, persisted.Further analysis of the corpus recordings revealedthat this issue was likely due to the speaking styleemployed by the professional speaker.
It containsfrequent pronounced pitch peaks, a verbal stylisticdevice acquired by the speaker as part of her pro-fessional training.
These events produced units withvery different pitch levels and slopes, thus leading tothe discontinuities mentioned above.4 Reduction of pitch peaksWe searched for ways to reduce the magnitude ofthese pitch peaks by manipulating the pitch trackof the recordings using the Time-Domain Pitch-Synchronous OverLap-and-Add (TD-PSOLA) sig-nal processing technique (Moulines and Charpen-tier, 1990).
We used the implementation of TD-PSOLA included in the Praat toolkit (Boersma andWeenink, 2012).We tried several formulas for TD-PSOLA andended up choosing the one that appeared to yield thebest results, evaluated perceptually by the authors:f(x) ={(x?
T ) ?
s + T if x > Tx otherwise.This formula linearly scales the pitch track by a scal-ing factor s above a threshold T , and leaves it intactbelow T .
When 0 < s < 1, the pitch track gets com-pressed above the threshold.
We experimented withseveral values for the two constants, and selectedT = 200Hz and s = 0.4 as the ones producing thebest results.
Figure 1 illustrates the pitch peak re-duction method.
The black solid line corresponds to1.0 1.5 2.0 2.5Time (s)150200250300HzOriginalModifiedFigure 1: Reduction of pitch peaks.
The original pitchtrack (in black) is scaled down 40% above 200Hz.the pitch track of the original audio; the red dottedline, to the pitch track of the modified audio.
Notethat the modified pitch track is scaled down above200Hz, but identical to the original below it.5 Evaluation of the methodNext we proceeded to evaluate the effect on synthe-sizer quality of reducing pitch peaks in the train-ing corpus.
For this purpose we prepared two ver-sions of the SECYT corpus ?
with and without ap-plying our pitch-peak reduction technique.
We referto these two as the original and modified recordings,respectively.
In both cases, the intensity level of allaudios was first leveled to a mean of 72dB usinglinear interpolation, to compensate for differencesacross recordings.503Subsequently, we built 8 speech synthesizers,consisting in all combinations of: Festival andMARY frameworks, concatenative and HMM-basedsynthesis, and original and modified recordings.
Werefer to these systems using the following nota-tion: {fest, mary} {conc, hmm} {orig, mod}; e.g.,mary conc mod is a concatenative system built us-ing the MARY framework with the modified corpus.We evaluated these systems along two dimen-sions: intelligibility and naturalness.
Our goal wasto compare four system pairs: systems built usingthe original recordings vs. those built using the mod-ified recordings.
The null hypothesis was that therewas no difference between ?orig?
and ?mod?
sys-tems; and the alternative hypothesis was that ?mod?systems were better than ?orig?
ones.5.1 IntelligibilityTo evaluate intelligibility we used the SemanticallyUnpredictable Sentences (SUS) method (Nye andGaitenby, 1974), which consists in asking partici-pants to listen to and transcribe sentences with cor-rect syntax but no semantic sense, for later measur-ing and comparing the number of transcription er-rors.
We used a set of 50 such sentences, each 6-10words long, created by Gurlekian et al(2012) forevaluating Spanish speech synthesizers.
A samplesentence is, El viento dulce armo?
un libro de pan-queques (The sweet wind made a book of pancakes).For each participant, 40 sentences were selectedat random and synthesized with the 8 systems (5 sen-tences per system, with no repetitions).
Participantswere given the following instructions,La primera tarea consiste en escuchar varios audios, ytranscribir para cada audio la oracio?n que escuches.Presta?
atencio?n, porque pode?s escuchar cada audiouna sola vez.
(The first task consists in listening to several audios,and transcribing for each audio the sentence you hear.Pay attention, because you can only listen to each au-dio once.
)5.2 NaturalnessTo evaluate naturalness we used the Mean Opin-ion Score (MOS) method, in which participantsare asked to rate the overall quality of synthe-sized speech on a 10-point scale (Viswanathan andViswanathan, 2005).We used a set of 20 sentences, each 5-20 wordslong, created by Gurlekian et al(2012), plus 20 ad-ditional sentences created for this study.
A samplesentence is, El sector de informa?tica es el nuevogenerador de empleo del pa?
?s (The informationtechnology sector is the country?s new job creator).Again, for each participant, 40 sentences were se-lected at random and synthesized with the 8 systems(5 sentences per system).
Participants were giventhe following instructions,La segunda (y u?ltima) tarea consiste en escuchar otrosaudios, y puntuar la naturalidad de cada uno.
Usaruna escala de 1 a 10, donde 1 significa ?no suena nat-ural en lo absoluto?
y 10 significa ?suena completa-mente natural?.
En este caso, pode?s escuchar cadaaudio una o ma?s veces.
(The second (and last) task consists in listening toother audios, and score the naturalness of each.
Usea scale from 1 to 10, where 1 means ?it does not soundnatural at all?
and 10 means ?it sounds completely nat-ural?.
In this case, you may listen to each audio one ormore times.
)5.3 ResultsSUS and MOS tests were administered on a com-puter interface in a silent laboratory using regularheadphones.
14 graduate and undergraduate stu-dents (11 male, 3 female; mean age: 27.6) com-pleted both tests ?
first SUS, followed by MOS.The transcriptions of the SUS tests were manuallycorrected for obvious typos and spelling errors thatdid not form a valid Spanish word.
Suspected typosand spelling errors that formed a valid word were notcorrected.
For example, peliculas was corrected topel?
?culas, and precion to presio?n; but canto was notcorrected to canto?, since it is a valid word.
Subse-quently, we computed the Levenshtein distance be-tween each transcription and the corresponding sen-tence.
Figure 2 shows the distribution of Leven-shtein distances for each of our eight systems.
Weobserve that all systems had a low error count, witha median of 0 or 1 errors per sentence.
Two-tailWilcoxon signed-rank tests revealed no significantdifferences between the systems built with the origi-nal and modified recordings (p=0.70 for fest conc,p = 0.40 for fest hmm, p = 0.69 for mary conc,p=0.40 for mary hmm, and p=0.41 for all systemstogether).
These results indicate that the intelligibil-ity of all four system types was not affected by the504festconcmodfestconcorigfesthmmmodfesthmmorigmaryconcmodmaryconcorigmaryhmmmodmaryhmmorig101234567Levenshtein distanceFigure 2: Intelligibility (SUS) results.modifications performed on the corpus for reducingpitch peaks.To account for the different interpretations of the10-point scale, we normalized all MOS test scoresby participant using z-scores.3 Figure 3 shows thedistribution of values for each system.festconcorigfestconcmodfesthmmorigfesthmmmodmaryconcorigmaryconcmodmaryhmmorigmaryhmmmod3210123z-scoreFigure 3: Naturalness (MOS) results.We performed a series of Wilcoxon signed-ranktests to assess the statistical significance of the ob-served differences.
The null hypothesis was thatthere was no difference between ?orig?
and ?mod?systems; and the alternative hypothesis was that?mod?
systems were perceived as more natural than?orig?
ones.
Table 5.3 summarizes these results.For mary conc and mary hmm (concatenativeand HMM-based systems built using the MARY3z = (x?
x)/s, where x and s are estimates of the partici-pant?s mean and standard deviation, respectively.W p-valuefest conc 2485 0.559fest hmm 2175 0.126mary conc 1933 0.016mary hmm 1680.5 0.001All systems 34064.5 0.004Table 1: Results of Wilcoxon tests comparing systemsusing the original and modified audios.framework) the perceived naturalness was signifi-cantly higher for systems built using the modifiedrecordings (i.e., after reducing pitch peaks) thanfor systems built with the original recordings.
Forfest conc (concatenative system built with Festival)we found no evidence of such differences.
Finally,for fest hmm (Festival HMM-based) the differenceapproaches significance at 0.126.6 ConclusionsIn this paper we presented a method for improvingthe perceived naturalness of corpus-based speechsynthesizers.
It consists in removing pronouncedpitch peaks in the original recordings, which typ-ically produce discontinuities in the synthesizedspeech.
We evaluated this method using two com-mon technologies (concatenative and HMM-basedsynthesis) and two different implementations (Festi-val and MARY), aiming at a good coverage of state-of-the-art speech synthesizers, and obtained clear re-sults.
First, its utilization on the source recordingshad no effect (negative or positive) on the intelligi-bility of any of the systems.
Second, the natural-ness of the concatenative and HMM-based systemsbuilt with the MARY framework improved signif-icantly; the HMM-based system built with Festivalshowed an improved naturalness at a level approach-ing significance; and the Festival concatenative sys-tem showed no improvement.
In summary, the pre-sented method did not harm the intelligibility of thesystems, and in some cases managed to improvetheir naturalness.
Therefore, since the impact of theproposed modifications on all four systems was pos-itive to neutral, developers may find this methodol-ogy beneficial.505AcknowledgmentsThis work was funded in part by CONICET, ANPCYTPICT 2009-0026, and UBACYT 20020090300087.
Theauthors thank Jorge A. Gurlekian, Humberto M. Torresand Christian G. Cossio-Mercado from LIS (INIGEM,CONICET-UBA) for kindly sharing the SECYT corpusand other materials for the present study, as well as forvaluable suggestions and comments.ReferencesAlan W. Black and Kevin A. Lenzo.
2007.
BuildingSynthetic Voices.
Language Technologies Institute,Carnegie Mellon University, http://festvox.org/bsv.A.
Black, P. Taylor, R. Caley, R. Clark, K. Richmond,S.
King, V. Strom, and H. Zen.
2001.
The festivalspeech synthesis system.Paul Boersma and David Weenink.
2012.
Praat: doingphonetics by computer.
http://www.praat.org/.J.
Gurlekian, L. Colantoni, and H. Torres.
2001.
El al-fabeto fone?tico SAMPA y el disen?o de corpora fone?-ticamente balanceados.
Fonoaudiolo?gica, 47:58?69.J.
A. Gurlekian, C. Cossio-Mercado, H. Torres, and M. E.Vaccari.
2012.
Subjective evaluation of a high qualitytext-to-speech system for Argentine Spanish.
In Pro-ceedings of Iberspeech, Madrid, Spain.E.
Moulines and F. Charpentier.
1990.
Pitch-syn-chronous waveform processing techniques for text-to-speech synthesis using diphones.
Speech communica-tion, 9(5):453?467.P.
W. Nye and J. H. Gaitenby.
1974.
The intelligibilityof synthetic monosyllabic words in short, syntacticallynormal sentences.
Haskins Laboratories Status Reporton Speech Research, 37(38):169?190.M.
Schro?der and J. Trouvain.
2003.
The German text-to-speech synthesis system MARY: A tool for research,development and teaching.
International Journal ofSpeech Technology, 6(4):365?377.H.
M. Torres and J.
A. Gurlekian.
2004.
Automatic de-termination of phrase breaks for Argentine Spanish.
InSpeech Prosody 2004, International Conference.Mahesh Viswanathan and Madhubalan Viswanathan.2005.
Measuring speech quality for text-to-speechsystems: Development and assessment of a modifiedmean opinion score (MOS) scale.
Computer Speech& Language, 19(1):55?83.506
