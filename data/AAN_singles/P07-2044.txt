Proceedings of the ACL 2007 Demo and Poster Sessions, pages 173?176,Prague, June 2007. c?2007 Association for Computational LinguisticsClassifying Temporal Relations Between EventsNathanael Chambers and Shan Wang and Dan JurafskyDepartment of Computer ScienceStanford UniversityStanford, CA 94305{natec,shanwang,jurafsky}@stanford.eduAbstractThis paper describes a fully automatic two-stage machine learning architecture thatlearns temporal relations between pairs ofevents.
The first stage learns the temporalattributes of single event descriptions, suchas tense, grammatical aspect, and aspectualclass.
These imperfect guesses, combinedwith other linguistic features, are then usedin a second stage to classify the temporal re-lationship between two events.
We presentboth an analysis of our new features and re-sults on the TimeBank Corpus that is 3%higher than previous work that used perfecthuman tagged features.1 IntroductionTemporal information encoded in textual descrip-tions of events has been of interest since the earlydays of natural language processing.
Lately, it hasseen renewed interest as Question Answering, Infor-mation Extraction and Summarization domains findit critical in order to proceed beyond surface under-standing.
With the recent creation of the TimebankCorpus (Pustejovsky et al, 2003), the utility of ma-chine learning techniques can now be tested.Recent work with the Timebank Corpus has re-vealed that the six-class classification of temporalrelations is very difficult, even for human annotators.The highest score reported on Timebank achieved62.5% accuracy when using gold-standard featuresas marked by humans (Mani et al, 2006).
This pa-per describes an approach using features extractedautomatically from raw text that not only dupli-cates this performance, but surpasses its accuracyby 3%.
We do so through advanced linguistic fea-tures and a surprising finding that using automaticrather than hand-labeled tense and aspect knowledgecauses only a slight performance degradation.We briefly describe current work on temporal or-dering in section 2.
Section 4 describes the first stageof basic temporal extraction, followed by a full de-scription of the second stage in 5.
The evaluationand results on Timebank then follow in section 6.2 Previous WorkMani et.
al (2006) built a MaxEnt classifier that as-signs each pair of events one of 6 relations from anaugmented Timebank corpus.
Their classifier relieson perfect features that were hand-tagged in the cor-pus, including tense, aspect, modality, polarity andevent class.
Pairwise agreement on tense and aspectare also included.
In a second study, they appliedrules of temporal transitivity to greatly expand thecorpus, providing different results on this enlargeddataset.
We could not duplicate their reported per-formance on this enlarged data, and instead focus onperforming well on the Timebank data itself.Lapata and Lascarides (2006) trained an eventclassifier for inter-sentential events.
They built a cor-pus by saving sentences that contained two events,one of which is triggered by a key time word (e.g.after and before).
Their learner was based on syntaxand clausal ordering features.
Boguraev and Ando(2005) evaluated machine learning on related tasks,but not relevant to event-event classification.Our work is most similar to Mani?s in that we are173learning relations given event pairs, but our work ex-tends their results both with new features and by us-ing fully automatic linguistic features from raw textthat are not hand selected from a corpus.3 DataWe used the Timebank Corpus (v1.1) for evaluation,186 newswire documents with 3345 event pairs.Solely for comparison with Mani, we add the 73document Opinion Corpus (Mani et al, 2006) to cre-ate a larger dataset called the OTC.
We present bothTimebank and OTC results so future work can com-pare against either.
All results below are from 10-fold cross validation.4 Stage One: Learning Event AttributesThe task in Stage One is to learn the five tempo-ral attributes associated with events as tagged in theTimebank Corpus.
(1) Tense and (2) grammaticalaspect are necessary in any approach to temporalordering as they define both temporal location andstructure of the event.
(3) Modality and (4) polar-ity indicate hypothetical or non-occuring situations,and finally, (5) event class is the type of event (e.g.process, state, etc.).
The event class has 7 values inTimebank, but we believe this paper?s approach iscompatible with other class divisions as well.
Therange of values for each event attribute is as follows,also found in (Pustejovsky et al, 2003):tense none, present, past, futureaspect none, prog, perfect, prog perfectclass report, aspectual, state, I stateI action, perception, occurrencemodality none, to, should, would, couldcan, mightpolarity positive, negative4.1 Machine Learning ClassificationWe used a machine learning approach to learn eachof the five event attributes.
We implemented bothNaive Bayes and Maximum Entropy classifiers, butfound Naive Bayes to perform as well or better thanMaximum Entropy.
The results in this paper arefrom Naive Bayes with Laplace smoothing.The features we used on this stage include part ofspeech tags (two before the event), lemmas of theevent words, WordNet synsets, and the appearancetense POS-2-event, POS-1-eventPOS-of-event, have word, be wordaspect POS-of-event, modal word, be wordclass synsetmodality nonepolarity noneFigure 1: Features selected for learning each tempo-ral attribute.
POS-2 is two tokens before the event.Timebank Corpustense aspect classBaseline 52.21 84.34 54.21Accuracy 88.28 94.24 75.2Baseline (OTC) 48.52 86.68 59.39Accuracy (OTC) 87.46 88.15 76.1Figure 2: Stage One results on classification.of auxiliaries and modals before the event.
This lat-ter set included all derivations of be and have auxil-iaries, modal words (e.g.
may, might, etc.
), and thepresence/absence of not.
We performed feature se-lection on this list of features, learning a different setof features for each of the five attributes.
The list ofselected features for each is shown in figure 1.Modality and polarity did not select any featuresbecause their majority class baselines were so high(98%) that learning these attributes does not providemuch utility.
A deeper analysis of event interactionwould require a modal analysis, but it seems that anewswire domain does not provide great variationin modalities.
Consequently, modality and polarityare not used in Stage Two.
Tense, aspect and classare shown in figure 2 with majority class baselines.Tense classification achieves 36% absolute improve-ment, aspect 10% and class 21%.
Performance onthe OTC set is similar, although aspect is not asgood.
These guesses are then passed to Stage Two.5 Stage Two: Event-Event FeaturesThe task in this stage is to choose the temporal re-lation between two events, given the pair of events.We assume that the events have been extracted andthat there exists some relation between them; thetask is to choose the relation.
The Timebank Corpususes relations that are based on Allen?s set of thir-174teen (Allen, 1984).
Six of the relations are inversesof the other six, and so we condense the set to be-fore, ibefore, includes, begins, ends and simultane-ous.
We map the thirteenth identity into simultane-ous.
One oddity is that Timebank includes both dur-ing and included by relations, but during does notappear in Timebank documentation.
While we don?tknow how previous work handles this, we condenseduring into included by (invert to includes).5.1 FeaturesEvent Specific: The five temporal attributes fromStage One are used for each event in the pair, as wellas the event strings, lemmas and WordNet synsets.Mani added two other features from these, indica-tors if the events agree on tense and aspect.
We adda third, event class agreement.
Further, to capturethe dependency between events in a discourse, wecreate new bigram features of tense, aspect and class(e.g.
?present past?
if the first event is in the present,and the second past).Part of Speech: For each event, we include the PennTreebank POS tag of the event, the tags for the twotokens preceding, and one token following.
We usethe Stanford Parser1 to extract them.
We also extendprevious work and create bigram POS features of theevent and the token before it, as well as the bigramPOS of the first event and the second event.Event-Event Syntactic Properties: A phrase P issaid to dominate another phrase Q if Q is a daugh-ter node of P in the syntactic parse tree.
We lever-age the syntactic output of the parser to create thedominance feature for intra-sentential events.
It iseither on or off, depending on the two events?
syn-tactic dominance.
Lapata used a similar feature forsubordinate phrases and an indicator before for tex-tual event ordering.
We adopt these features and alsoadd a same-sentence indicator if the events appear inthe same sentence.Prepositional Phrase: Since preposition heads areoften indicators of temporal class, we created a newfeature indicating when an event is part of a prepo-sitional phrase.
The feature?s values range over 34English prepositions.
Combined with event dom-inance (above), these two features capture direct1http://nlp.stanford.edu/software/lex-parser.shtmlintra-sentential relationships.
To our knowledge, weare the first to use this feature in temporal ordering.Temporal Discourse: Seeing tense as a type ofanaphora, it is a natural conclusion that the rela-tionship between two events becomes stronger asthe textual distance draws closer.
Because of this,we adopted the view that intra-sentential events aregenerated from a different distribution than inter-sentential events.
We therefore train two modelsduring learning, one for events in the same sen-tence, and the other for events crossing sentenceboundaries.
It essentially splits the data on thesame sentence feature.
As we will see, this turnedout to be a very useful feature.
It is called the splitapproach in the next section.Example (require, compromise):?Their solution required a compromise...?Features(lemma1: require) (lemma2: compromise) (dominates: yes)(tense-bigram: past-none) (aspect-bigram: none-none) (tense-match: no) (aspect-match: yes) (before: yes) (same-sent: yes)6 Evaluation and ResultsAll results are from a 10-fold cross validation us-ing SVM (Chang and Lin, 2001).
We also eval-uated Naive Bayes and Maximum Entropy.
NaiveBayes (NB) returned similar results to SVM and wepresent feature selection results from NB to comparethe added value of our new features.The input to Stage Two is a list of pairs of events;the task is to classify each according to one of sixtemporal relations.
Four sets of results are shownin figure 3.
Mani, Mani+Lapata and All+New cor-respond to performance on features as listed in thefigure.
The three table columns indicate how a gold-standard Stage One (Gold) compares against imper-fect guesses (Auto) and the guesses with split distri-butions (Auto-Split).A clear improvement is seen in each row, indi-cating that our new features provide significant im-provement over previous work.
A decrease in per-formance is seen between columns gold and auto,as expected, because imperfect data is introduced,however, the drop is manageable.
The auto-split dis-tributions make significant gains for the Mani andLapata features, but less when all new features are175Timebank Corpus Gold Auto Auto-SplitBaseline 37.22 37.22 46.58Mani 50.97 50.19 53.42Mani+Lapata 52.29 51.57 55.10All+New 60.45 59.13 59.43Mani stage one attributes, tense/aspect-match, event stringsLapata dominance, before, lemma, synsetNew prep-phrases, same-sent, class-match, POS uni/bigrams,tense/aspect/class-bigramsFigure 3: Incremental accuracy by adding features.Same Sentence Diff SentencePOS-1 Ev1 2.5% Tense Pair 1.6%POS Bigram Ev1 3.5% Aspect Ev1 0.5%Preposition Ev1 2.0% POS Bigram 0.2%Tense Ev2 0.7% POS-1 Ev2 0.3%Preposition Ev2 0.6% Word EV2 0.2%Figure 4: Top 5 features as added in feature selectionw/ Naive Bayes, with their percentage improvement.involved.
The highest fully-automatic accuracy onTimebank is 59.43%, a 4.3% gain from our new fea-tures.
We also report 67.57% gold and 65.48% auto-split on the OTC dataset to compare against Mani?sreported hand-tagged features of 62.5%, a gain of3% with our automatic features.7 DiscussionPrevious work on OTC achieved classification accu-racy of 62.5%, but this result was based on ?perfectdata?
from human annotators.
A low number fromgood data is at first disappointing, however, we showthat performance can be improved through more lin-guistic features and by isolating the distinct tasks ofordering inter-sentential and intra-sentential events.Our new features show a clear improvement overprevious work.
The features that capture dependen-cies between the events, rather than isolated featuresprovide the greatest utility.
Also, the impact of im-perfect temporal data is surprisingly minimal.
Us-ing Stage One?s results instead of gold values hurtsperformance by less than 1.4%.
This suggests thatmuch of the value of the hand-coded informationcan be achieved via automatic approaches.
StageOne?s event class shows room for improvement, yetthe negative impact on Event-Event relationships ismanageable.
It is conceivable that more advancedfeatures would better classify the event class, but im-provement on the event-event task would be slight.Finally, it is important to note the difference inclassifying events in the same sentence vs. cross-boundary.
Splitting the 3345 pairs of corpus eventsinto two separate training sets makes our data moresparse, but we still see a performance improvementwhen using Mani/Lapata features.
Figure 4 gives ahint to the difference in distributions as the best fea-tures of each task are very different.
Intra-sentenceevents rely on syntax cues (e.g.
preposition phrasesand POS), while inter-sentence events use tense andaspect.
However, the differences are minimized asmore advanced features are added.
The final row infigure 3 shows minimal split improvement.8 ConclusionWe have described a two-stage machine learningapproach to event-event temporal relation classifi-cation.
We have shown that imperfect event at-tributes can be used effectively, that a range of event-event dependency features provide added utility to aclassifier, and that events within the same sentencehave distinct characteristics from those across sen-tence boundaries.
This fully automatic raw text ap-proach achieves a 3% improvement over previouswork based on perfect human tagged features.Acknowledgement: This work was supported inpart by the DARPA GALE Program and the DTOAQUAINT Program.ReferencesJames Allen.
1984.
Towards a general theory of action andtime.
Artificial Intelligence, 23:123?154.Branimir Boguraev and Rie Kubota Ando.
2005.
Timeml-compliant text analysis for temporal reasoning.
In IJCA-05.Chih-Chung Chang and Chih-Jen Lin, 2001.
LIBSVM: a li-brary for support vector machines.
Software available athttp://www.csie.ntu.edu.tw/ cjlin/libsvm.Mirella Lapata and Alex Lascarides.
2006.
Learning sentence-internal temporal relations.
In Journal of AI Research, vol-ume 27, pages 85?117.Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee,and James Pustejovsky.
2006.
Machine learning of temporalrelations.
In ACL-06, July.James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See,David Day, Lisa Ferro, Robert Gaizauskas, Marcia Lazo,Andrea Setzer, and Beth Sundheim.
2003.
The timebankcorpus.
Corpus Linguistics, pages 647?656.176
