ON CUSTOMIZING PROSODY IN SPEECH SYNTHESIS:NAMES AND ADDRESSES AS A CASE IN POINTKim E. A. SilvermanArtificial Intelligence LaboratoryNYNEX Science and Technology, Inc.500 Westchester AvenueWhite Plains, New York 106041.
ABSTRACTThis work assesses the contribution of domain-specific prosodicmodelling to synthetic speech quality in a name-and-addressinformation service.
A prosodic processor analyzes the textualstructure of labelled input strings, and inserts markers which spec-ify the intended prosody for the DECtalk text-to-speech synthe-sizer.
These markers impose discourse-level prosodicorganization, annotate the information structure, and adapt hespeaking rate to listeners in real time.
In a quantitative comparisonof this domain-specific modelling with the default rules in DEC-talk, the domain-specific prosody was found to reduce the tran-scription error rate from 14.6% to 6.4%, reduce the number ofrepeats requested by listeners from 2.6 to 1.1, and to sound signif-icantly easier to understand and more natural.
This result demon-strates the importance of prosodic modelling in synthesis, andimplies an even more important role for prosody in more compli-cated omains and discourse structures.2.
INTRODUCTIONText-to-speech synthesis could profitably be used to auto-mate or create many information services, if only it were ofbetter quality.
Unfortunately it remains too unnatural andmachine-like for all but the simplest and shortest texts.
Ithas been described as sounding monotonous, boring,mechanical, harsh, disdainful, peremptory, fuzzy, muffled,choppy, and unclear.
Synthesized isolated words are rela-tively easy to recognize, but when these are strung togetherinto longer passages of connected speech (phrases or sen-tences) then it is much more difficult o follow the meaning:the task is unpleasant and the effort is fatiguing \[1\].This less-than-ideal quality seems paradoxical, becausepublished evaluations of synthetic speech yield intelligibil-ity scores that are very close to natural speech.
For exam-ple, Greene, Logan and Pisoni \[2\] found the best syntheticspeech could be transcribed with 96% accuracy; the severalstudies that have used human speech tokens typically reportintelligibility scores of 96% to 99% for natural speech.
(Fora review see \[1\]).However, segmental intelligibility does not always predictcomprehension.
A series of experiments \[3\] compared twohigh-end commercially-available text-to-speech systemson application-like material such as news items, medicalbenefits information, and names and addresses.
The resultwas that the one with the significantly higher segmentalintelligibility had the lower comprehension scores.Although there may be several possible reasons for seg-mental intelligibility failing to predict comprehension, thecurrent work focuses on the single most likely cause: syn-thesis of prosody.
Prosody is the organization imposed ontoa string of words when they are uttered as connectedspeech.
It includes pitch, duration, pauses, tempo, rhythm,and every known aspect of articulation.
When the prosodyis incorrect hen at best the speech will be difficult orimpossible to understand \[4\], at worst listeners will be mis-understand it with being aware that they have done so.Arguments for the importance of prosody in languageabound in the literature.
However, the cited examples ofprosodic resolution of ambiguity usually are either anec-dotal citations or are illustrated by small sets of carefully-constructed cited sentences.
It is not clear how importantprosody is in more normal everyday texts.
This brings us tothe first question addressed in the current study: how muchwill prosody contribute to perception of synthetic speechfor non-contrived, real-world textual material?2.1.
Cur rent  Approaches  to P rosody  in SpeechSynthesisText-to-speech systems are typically designed to cope with"unrestricted text" \[5\].
Each sentence in the input text isanalyzed independently, and the prosody that is applied is atrade-off to avoid one the one hand not sounding toomonotonous, and on the other hand implementing the pro-sodic features o saliently that egregious errors occur whenthe wrong prosodic features are applied.
The approachtaken in these systems to generating the prosody has beento derive it from an impoverished syntactic analysis of thetext to be spoken.
Usually content words receive pitch-related prominence, function words do not.
Small prosodic317boundaries, marked with pitch falls and some lengtheningof the syllables on the left, are inserted wherever there is acontent word on the left and a function word on the right.Larger tmundaries are placed at punctuation marks, accom-panied by a short pause and preceded by either a falling-then-rising pitch shape to cue nonfinality in the case of acomma, or finality in the case of a period.
Declination ofpitch is .imposed over the duration of each sentence.There are several ways in which deviations from the aboveprinciples can be implemented to add variety and interest toan intonation contour.
For example the declination may bepartially reset at commas within a sentence.
Or the extent ofprominence-lending pitch excursions on content words maybe varied according to their lexical class (higher pitch peakson nouns or adjectives, lower on verbs) or their position inthe phrase (alternating higher and lower peaks).
These vari-ations may be based on stochastically trained models.One problem with the above approach is that prosody is nota lexical property of English words - English is not a tonelanguage.
Neither is prosody completely predictable fromEnglish syntax - prosody is not a redundant encoding ofalready-inferable information.Rather, prosody annotates the information structure of theaccompanying text string.
It depends on the prior mutualknowledge of the speaker and listener, and on the role a par-ticular utterance takes within its particular discourse.
Itmarks which concepts are considered by the speaker to benew in the dialogue, which ones are topics, and which onesare comments.
It encodes the speaker's expectations abouthow the current utterance relates to that the listener's cur-rent knowledge, it indicates focussed versus backgroundinformation.
This realm of information is very difficult toderive in an unrestricted text-to-speech system, and it iscorrespondingly difficult to generate correct discourse-rele-vant prosody.
This is a primary reason why long passagesof synthetic speech sound so unnatural.2.2.
Application-specific discourse constraintson prosodyThere are many different applications for synthetic speech,but what they tend to share in common is that usuallywithin each application (i) the text is not unrestricted, butrather is a constrained topic and a limited subset of the lan-guage, and (ii) the speech is spoken within a known dis-course context.
Therefore within the constraints of aparticular application it is possible to make assumptionsabout the type of text structures to expect, the reasons thetext is being spoken, and the expectations of the listener.These are just the types of information that are necessary toconstraint the prosody.
This brings us to the second aim ofthe current research: is it possible to create application-spe-cific rules to improve the prosody in a real text-to-speechsynthesis application?Prior work has shown that discourse characteristics of simu-lated applications can be used to constrain prosody.
Youngand Fallside [6] built a system that enabled remote access tostatus information about East Anglia's water supply system.This system answered queries by generating text aroundnumerical data and then synthesizing the resulting sen-tences.
The desired prosody was generated along with thetext, rather than being left to the default rules of an unre-stricted text-to-speech system.
Silverman developed para-graph-level rules to vary pitch range and place accentsbased on a model of recently-activated concepts.
Hirsch-berg and Pierrehumbert [7] generated the prosody in syn-thetic speech according to a block structure model ofdiscourse in an automated tutor for the v i  text editor.
Davis[8] built a system that generated travel directions within theBoston metropolitan area.
In one version of the system, ele-ments of the discourse structure (such as given-versus-new,repetition, and grouping of sentences into larger units) wereused to manipulate accent placement, boundary placement,and pitch range.Each of these pieces of research consists of a carefully-elab-orated set of rules to improve synthetic speech quality.However the evidence that the speech did indeed sound bet-ter was more intuitive than based on formal perceptualassessments.
Yet systematic and controlled evaluation iscrucial in order to test whether hypothesized rules are cor-rect, and whether they have a measurable effect on how thespeech is perceived.The current work builds on the progress made in the abovesystems by evaluating prosodic modelling in the context ofan existing information-provision service.3.
PROSODY FOR A NAME AND ADDRESSINFORMATION RETRIEVAL SERVICEThe text domain for the current work is synthesis of namesand addresses.
The associated pronunciation rules and textprocessing are well understood, and there are many applica-tions that require this type of information.
At the same timethis represents a particularly stringent test for the contribu-tion of prosody to synthesis quality because names andaddresses have such a simple linear structure.
There is littlestructural ambiguity, no center-embedding, no relativeclauses.
There are no indirect speech acts.
There are nodigressions.
Utterances are usually very short.
In general,names and addresses contain few of the features common incited examples of the centrality of prosody in spoken lan-guage.
This class of text seems to offer little opportunity forprosody to aid perception.On the other hand, if prosody can be shown to influencesynthetic speech quality even on such simple material asnames and addresses, then it is all the more likely to beimportant in spoken language systems where the structureof the material is more complex and the discourse is richer.3.1.
The application dialogueThis work took place within the context of a field trial ofspeech synthesis to automate NYNEX's reverse-directoryservice \[9\].
Callers are real users of the information service.They know the nature of the information provision service,before they call.
They have 10-digit elephone numbers, forwhich they want he associated listing information.
At ran-dom, their call may arrive at the automated position.
Thedialogue with the automated system consists of two phases:information gathering and information provision.
Theinformation-gathering phase used standard Voice ResponseUnit technology: they hear recorded prompts and answerquestions by pressing DTMF keys on their telephones.
Thisphases establishes features of the discourse that are impor-tant for generating the prosody: callers are aware of thetopic and purpose of the discourse and the information theywill be asked to supply by the interlocutor (in this case theautomated voice).
It also establishes that the interlocutorcan and will use the telephone numbers as a key to indicatehow the to-be-spoken i formation (the listings) relates towhat the caller already knows (thus "555 1234 is listed toKim Silverman, 555 2345 is listed to Sara Basson").The second phase is information provision: the listing infor-mation for each telephone number is spoken by a speechsynthesizer.
Specifically, the number and its associatedname and town are embedded incarrier phrases, as in:<number> is listed to <name> in <town>The resultant sentence is spoken by the synthesizer, afterwhich a recorded human voice offers to repeat the listing,spell the name, or continue to the next listing.These features may seem too obvious to be worthy of com-ment, but they very much constrain likely interpretations ofwhat is to be spoken, and similarly define what the appro-priate prosody should be in order for the to-be-synthesizedinformation to be spoken in a compliant way.3.2.
Rules for Prosody in Names and AddressesIn the field trial, text fields from NYNEX's Customer Nameand Address database (approximately 20million entries)are sent o a text processor \[10\] which identifies and labelslogical fields, corrects many errors, and expands abbrevia-tions.
For the current research, a further processor was writ-ten which takes the cleaned-up text which is output fromthat ext processor, analyzes its information structure, andinserts prosodic markers into it before passing it on to aspeech synthesizer.
The prosodic markers control suchthings as accent type, accent location, overall pitch range,boundary tones, pause durations, and speaking rate.
Theseare recognized by the synthesizer and will override thatsynthesizer's own inbuilt prosody rules.The prosodic hoices were based on analyses of 371 inter-actions between real operators and customers.
The opera-tors use a careful, clear, deliberately-helpful style whensaying this information.
The principles that underlie theirchoice of prosody, however, are general and apply to all oflanguage.
The tunes they use appear to be instances of tunesin the repertoire shared by all native speakers, their use ofpitch range is consistent with observational descriptions inthe Ethnomethodology literature, their pauses are neitherunrepresentafively long nor rushed.
What makes their pros-ody different from normal everyday speech is merely whichtunes and categories they select from the repertoire, ratherthan the contents of the repertoire itself.
This reflects thedemand characteristics of the discourse.The synthesizer which was chosen for this prosodic prepro-cessor was DECtalk, within the DECvoice platform.
Thissynthesizer has a reputation for very high segmental intelli-gibility \[2\].
It is widely used in applications and researchlaboratories, and has an international reputation.There are three categories of processing performed by theprosodic rules: (i) discourse-level shaping of the overallprosody; (ii) field-specific accent and boundary placement,and (iii) interactive adaptation of the speaking rate.
(i) Discourse-level shaping of the prosody within a turn.That turn might be one short sentence, as in 914 555 2145shows no listing, or several sentences long, as in "thenumber 914 555 2609 is an auxiliary line.
The mainnumber is 914 555 2000.
That number is handledby US Communicat ions of Westchester doingbusiness as Southern New York Holdings Incorpo-rated in White Plains NY 10604.
The general principlehere is that prosodic organization can span multiple intona-tional phrases, and therefore multiple sentences.
These turnsare all prosodically grouped together by systematic varia-tion of the overall pitch range, lowering the final endpoint,deaccenting items in compounds (e.g.
"auxiliary line"), andplacing accents correctly to indicate backward references{e.g.
"That number...").
The phone number which is beingechoed back to the listener, which the listener only keyed ina few seconds prior, is spoken rather quickly (the 914 5552145, in this example).
The one which is new is spokenmore slowly, with larger prosodic boundaries after the areacode and local exchange, and an extra boundary betweenthe eighth and ninth digits.
This is the way native speakerssay this type of information when it is new and important inthe discourse.Another characteristic ofthis level of prosodic ontrol is thetype and duration of pauses within and between some of thesentences.
Some pauses are inserted within intonationalphrases, immediately prior to information-bearing words.These pauses are NOT preceded by boundary-related pitchtones, and only by a small amount of lengthening ofthe pre-ceding material.
They serve to alert the listener that some-thing important isabout o be spoken, thereby focussing thelistener's attention.
In the TOBI transcription system, thesewould be transcribed as a 2 or 2p boundary.
Example loca-tions of these pauses include: "The main number  is...914 555 2000?'
and "In... White Plains, NY 10604.
"319The duration of the sentence-final pause between amesand their associated addresses i varied according to thelength and complexity of the name.
This allows listenersmore time to finish processing the acoustic signal for thename (to perform any necessary backtracking, ambiguityresolution, or lexical access) before their auditory buffer isoverwritten by the address.
(ii) Signalling the internal structure of labelled fields.The most complicated and extensive set of rules is for namefields.
Rules for this field first of all identify word stringswhich are inferable markers of information structure, ratherthan being information-bearing  themselves, uch as "...doing business as...".
The relative pitch range is reduced,the relative speaking rate is increased, and the stress is low-ered.
These features jointly signal to the listener the rolethat hese words play.
In addition, the reduced range allowsthe synthesizer touse its normal and boosted range to markthe start of information-bearing units on either side of thesemarkers.
These units themselves are either esidential orbusiness names, which are then analyzed for a number ofstructural features.
Prefixed titles (Mr, Dr, etc.)
are cliti-cized (assigned less salience so that they prosodicallymerge with the next word), unless they are head words intheir own right (e.g.
"Misses Incorporated").
Accentablesuffixes (incorporated, the second, etc.)
are separated fromtheir preceding head and placed in an intermediate-levelphrase of their own.
After these are stripped off, the righthand edge of the head itself is searched for suffixes thatindicate a complex nominal.
If one of these is found is hasits pitch accent removed, to yield for example BuildingCompany, Plumbing Supply, Health Services, and SavingsBank.
However if the preceding word is a function wordthen they are NOT deaccented, to allow for constructs suchas "John's Hardware and Supply", or "The Limited".
Therest of the head is then searched for a prefix on the right, inthe form of "<word> and <word>".
If found, then this is putinto its own intermediate phrase, which separates it fromthe following material for the listener.
This causes con-structs like "A and P Tea Company" to NOT sound like "A,and P T Company" (prosodically analogous to "A, and P TBarnum").Within a head, words are prosodically separated from eachother very slightly, to make the word boundaries clearer.The pitch contour at these separations is chosen to signal tothe listener that although slight disjuncture is present, hesewords cohere together as a larger unit.Similar principles are applied within the other addressfields.
In address fields, for example, a longer address tartswith a higher pitch than a shorter one, deaccenting is per-formed to distinguish "Johnson Avenue" from "JohnsonStreet", ambiguities like "120 3rd Street" versus "100 23rdStreet" versus "123rd Street" are detected and resolved withboundaries and pauses, and so on.
In city fields, items like"Warren Air Force Base" have the accents removed fromthe right hand two words.An important component of signalling the internal structureof fields is to mark their boundaries.
Rules concerning inter-field boundaries prevent listings like "Sylvia Rose inBaume Forest" from being misheard as "Sylvia RosenbaumForest".
(iii) Adapting the speaking rate.
Speaking rate is a power-ful contributor to synthesizer intelligibility: it is possible tounderstand even an extremely poor synthesizer if it speaksslowly enough.
But the slower it speaks, the more patholog-ical it sounds.
Moreover as listeners become more familiarwith a synthesizer, they understand it better and become lesstolerant of unnecessarily-slow speech.
Consequently it isunclear what the appropriate speaking rate should be for aparticular synthesizer, since this depends on the characteris-tics of both the synthesizer and the application.To address this problem, a module modifies the speakingrate from listing to listing on the basis of whether customersrequest repeats.
Briefly, repeats of listings are presentedfaster than the first presentation, because listeners typicallyask for a repeat in order to hear only one particular part of alisting.
However if listener consistently requests repeats forseveral consecutive listings, then the starting rate for newlistings within that call is slowed down.
If this happens oversufficient consecutive calls, then the default starting rate fora new call is slowed down.
Similarly, if over successive list-ings or calls there are no repeats, then the speaking rate willbe increased again.
By modelling three different levels ofspeaking rate in this way (within-listing, within-call, andacross-calls), this module attempts to distinguish between aparticularly difficult listing, a particularly confused listener,and an altogether-too-fast (or oo slow) synthesizer.In addition to the above prosodic ontrols, there is a specificmodule to control the way items are spelled when listenersrequest spelling This works in two ways.
Firstly, using thesame prosodic principles and features as above, it employsvariation in pitch range, boundary tones, and pause dura-tions to define the end of the spelling of one item from thestart of the next (to avoid "Terrance C McKay Sr." frombeing spelled "T-E-R-R-A-N-C-E-C, M-C-K-A WhySenior"), and it breaks long strings of letters into groups, sothat "Silverman" is spelled "S-I-L, V-E-R, M-A-N".
Sec-ondly, it spells by analogy letters that are ambiguous overthe telephone, such as "F for Frank", using context-sensi-tive rules to decide when to do this, so that it is not donewhen the letter is predictable by the listener.
Thus N isspelled "N for Nancy" in a name like "Nike", but not in aname like "Chang".
The choice of analogy itself alsodepends on the word, so that "David" is NOT spelled "D forDavid, A ..... "4.
PREL IMINARY EVALUATIONA transcnpton experiment was carried out to evaluate theimpact of the prosodic rules on the synthetic speech quality320in terms of both objective transcription accuracy and ofsubjective ratings.4.1.
Test materialA set of twenty-three names and addresses had been alreadybeen developed by Sara Basson (unpublished ms, 1992) forassessing the accuracy with which listeners can transcribesuch material.
This set had been constructed torepresentthe variation in internal structure and length that occurred inNYNEX's database.
Although it did contain some materialthat would be ambiguous if synthesized with incorrect pros-ody, it was not intended to focus exclusively on prosodicvariability and was developed before the prosodic processorwas finished.
It contained phonemic diversity;, a variety ofpersonal names, cities and states; short and long namefields, and digit strings.
There were roughly equal propor-tions of easy, moderate, and difficult listings, as measuredby how well listeners could transcribe the material whenspoken by a human.
Henceforth each of these names andaddresses shall be referred to as items.4.2.
ProcedureThe 23 items were divided into two sets.
Listeners were allnative speakers of English with no known hearing loss, andall employees of NYNEX Science and Technology.
On thebasis of our previous experience with synthetic speech per-ception experiments, we expect hese listeners will performbetter on the transcription task than general members of thepublic.
Thus the results of this transcription test represent a"best ease" in terms of how well we can expect real users tounderstand the utterances.Listeners called the computer over the public telephone net-work from their office telephones: their task was to tran-scribe each of the 23 items.
Each listener heard andtranscribed the items in two blocks: one of the sets of itemsspoken by DECtalk's default prosody rules, and the otherspoken with application-specific prosody.
The design wascounter-balanced with roughly half of the listeners hearingeach version in the first block, and roughly half hearingeach item set in the first block.
For each item, listenerscould request as many repeats as they wanted in order totranscribe the material as accurately as they felt was reason-ably possible.
Listeners were only allowed to request spell-ing in two of the items, which were constructed tosoundlike pronounceable names and contain every letter in thealphabet.4.3.
Dependent variablesTranscription scores per item.
Each word in each itemcould score up to 3 points.
One point would be deducted ifthe right-hand word boundary was misplaced, one point ifone phoneme was wrong, and two points of more than onephoneme was wrong.Number of repeats requested per item.
For items thatwere spelled, this was the number of times after the firstspelling.Perceived intelligibility.
Each version of the synthesis wasrated by each listener on a five-point scale labelled: "Howeasy was it to understand this voice?"
(where 1 = "Consis-tently failed to understand much of the speech" and 5 ="Consistently effortless to understand").Perceived naturalness.
Each version was similarly rated,on a five-point scale labelled "How natural (i.e.
like ahuman voice) did this voice sound?
(where 1 = extremelyunnatural nd 5 = extremely natural).Preferences.
Since each listener heard each voice, theywere asked for which voice they preferred: voice 1, voice 2,or no preference.4.4.
ResultsSo far results have been analyzed for 17 listeners.
Summingover all transcriptions, the maximum possible transcriptionscore for each synthesizer was 5032.
The per-word errorrate for items spoken with the synthesizer's default prosodywas 14.6%.
With the domain-specific prosody this was only6.4%.
Thus listeners could transcribe the vowels and conso-nants ignificantly more accurately even though the vowelsand consonants are pronounced by exactly the same seg-mental rules in both cases.
The only difference is the pros-ody.Transcription scores do not reflect how much effort listenersexpended to achieve their transcription accuracy.
One mea-sure of that effort is the number of repeats they requested.Listeners needed on average 2.6 repeats per listing for thedefault prosody, but only 1.1 repeats per listing with thedomain-specific prosody.
Interestingly, in a prior transcrip-tion test with a human voice saying asuperset of the listingsused in this experiment, listeners needed 1.2 repeats per list-ing (Sara Basson, personal communication).On the "ease of understanding" scale, the default prosodyscored 1.8 (standard deviation =0.8), while domain-specificprosody scored 3.3 (standard eviation = 0.8).
Thus listen-ers' subjective perceptions matched their objective tran-scription results: they were aware that the version withdomain-specific prosody was easier to understand, thoughclearly it was not effortless.On the "naturalness" cale, the default prosody scored 1.9(standard eviation = 0.9) and domain-specific prosodyscored 2.9 (standard eviation = 0.8).
Though statisticallysignificant, his difference is smaller than on the previousscale.
Alteration of the just the pitch and duration made the321speech made the speech sound somewhat more natural, butit is still is a long way from sounding "extremely natural".One the preference ratings, so far all of the listeners pre-ferred the speech versions with domain-specific prosody.5.
CONCLUSIONAlthough this evaluation is preliminary, it suggests thateven in such simple material as names and addressesdomain-specific prosody can make a clear improvement tosynthetic speech quality.
The transcription error rate wasmore than halved, the number of repetitions was more thanhalved, the speech was rated as more natural and easier tounderstand, aud it was preferred by listeners.
This resultencourages further esearch on methods for capitalizing onapplication constraints o improve prosody.
The principlesin the literature for customizing the prosody will generalizeto other domains where the structure of the material anddiscourse purpose can be inferred.The second conclusion is that at least in this domain,although domain-specific rules can improve synthetic pros-ody over that in domain-independent rules, the domain-spe-cific customizat ion can be severely l imited if thesynthesizer does not make the fight prosodic ontrols avail-able.
In an ideal world, the markers that are embedded inthe text would specify exactly how the text is to be spoken.In reality, however, they specify at best an approximation.This exercise is constrained by the controls made availableby that synthesizer.
Some manipulations that are needed forthis type of customization are not available, and some of thecontrols that are available interact in mutually-detrimentalways.
Consequently tothe extent hat the application-spe-cific prosody did indeed improve synthesis quality, this isall the more supporting evidence for both the importance ofgenerating domain-relevant prosody on the one hand, andfor NOT doing it with such an improper prosodic model onthe other.The immediate next steps in this work are to more system-atically evaluate the perceptual impact of the above rules,both in transcription tests and with the quantitative mea-sures of acceptance by real users that are already being usedin the field trial.
In addition, we are currently developing aset of rules to customize the prosody in a spoken languagesystem for remote financial transactions, combining text-specific rules of the type evaluated in this work, with rulesthat will use the discourse history to dynamically deriveinformation about opics, discourse functions of replies, andgiven versus new information.The development and evaluation of this work furthers ourunderstanding of (i) how to use prosody to clarify namesand addresses in particular, and other texts in general; (ii)prosody's importance in a real application context, ratherthan in laboratory-generated unrepresentative sentences;(iii) one way to incorporate user-modelling of speaking rateinto speech synthesis (speakers should not ignore their lis-teners); and (iv) what prosodic ontrols asynthesizer shouldmake available.6.
ACKNOWLEDGEMENTSThis work could not have proceeded without he contextand focus of the ACNA trial in general, and in particular theefforts and insights of Dina Yashchin, Ashok Kalyanswamy,Sara Basson, John Pitrelli, and Judy Spitz.
Shortcomings ofcourse remain my own responsibility.REFERENCES1.
Silverman, K.E.A.
The Structure and Processing of Funda-mental Frequency Contours.
Ph.D. Dissertation, Cam-bridge University, 1987.2.
Greene, B.G.
; Logan, J.S.
and Pisoni, D.B.
"Perception ofsynthetic speech produced automatically b rule: Intelligi-bility of eight ext-to-speech systems", Behavior ResearchMethods, Instruments, and Computers, Vol.
18, 1986, pp100-1073.
Silverman, K.E.A., Basson, S. and Levas, S. EvaluatingSynthesizer Performance: Is Segmental IntelligibilityEnough?
Proc.
ICSLP-90, Vol.
1, 1990.4.
Huggins, A.W.F.
"Speech Timing and Intelligibility.
In J.Requin (Ed): Attention and Performance VII.
Erlbaurn,Hillsdale.
1978.5.
Allen, J, Hunnicutt, M.S., Klatt, D., Armstrong, R.C.
andPisoni, D.B.
From Text o Speech: The M1Talk System.Cambridge University Press, Cambridge, 19876.
Young, S.J.
and Fallside, E "Synthesis by rule of prosodicfeatures inword concatenation synthesis", Int.
J. Man-Machine Studies, Vol.
12, 1980, pp 241-258.7.
Hirschberg, J. and Pierrehumbert, J.B. "The IntonationalStructuring ofDiscourse", Proc.
24th ACL Meeting, 1986,pp 136-144.8.
Davis, J.R. "Generating intonational support for dis-course", J. Acoust.
Soc.
Am.
Suppl.
1, Vol.
82, 1987, p S17.9.
Yashchin, D Basson, S., Kalyanswamy, A. Silverman,K.E.A.
"Results from automating a name and address ser-vice with speech synthesis".
Proc AVIOS-92, 1992.10.
Kalyanswamy, A. and Silverman, K.E.A.
"Processinginformation i preparation for text-to-speech synthesis".Proc AVIOS-92, 1992.322
