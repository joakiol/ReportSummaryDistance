A Morphologically Sensitive Clustering Algorithm for IdentifyingArabic RootsAnne N. DE ROECKDepartment of Computer ScienceUniversity of EssexColchester, CO4 3SQ, U.K.deroe@essex.ac.ukWaleed AL-FARESComputer Science DepartmentCollege of Business Studies,Hawaly, Kuwaital-fareswaleed@usa.netAbstractWe present a clustering algorithm for Arabicwords sharing the same root.
Root basedclusters can substitute dictionaries inindexing for IR.
Modifying Adamson andBoreham (1974), our Two-stage algorithmapplies light stemming before calculatingword pair similarity coefficients usingtechniques sensitive to Arabic morphology.Tests show a successful treatment of infixesand accurate clustering to up to 94.06% forunedited Arabic text samples, without theuse of dictionaries.IntroductionCanonisation of words for indexing is animportant and difficult problem for Arabic IR.Arabic is a highly inflectional language with85% of words derived from tri-lateral roots (Al-Fedaghi and Al-Anzi 1989).
Stems are derivedfrom roots through the application of a set offixed patterns.
Addition of affixes to stemsyields words.
Words sharing a root aresemantically related and root indexing isreported to outperform stem and word indexingon both recall and precision (Hmeidi et al1997).However, Arabic morphology is excruciatinglycomplex (the Appendix attempts a briefintroduction), and root identification on a scaleuseful for IR remains problematic.Research on Arabic IR tends to treat automaticindexing and stemming separately.
Al-Shalabiand Evans (1998) and El-Sadany and Hashish(1989) developed stemming algorithms.
Hmeidiet al(1997) developed an information retrievalsystem with an index, but does not explain theunderlying stemming algorithm.
In Al-Kharashiand Evans (1994), stemming is done manuallyand the IR index is built by manual insertion ofroots, stems and words.Typically, Arabic stemming algorithms operateby ?trial and error?.
Affixes are stripped away,and stems ?undone?, according to patterns andrules, and with reference to dictionaries.
Rootcandidates are checked against a root lexicon.
Ifno match is found, affixes and patterns are re-adjusted and the new candidate is checked.
Theprocess is repeated until a root is found.Morpho-syntactic parsers offer a possiblealternative to stemming algorithms.
Al-Shalabiand Evans (1994), and Ubu-Salem et al(1999)develop independent analysers.
Some workbuilds on established formalisms such a DATR(Al-Najem 1998), or KIMMO.
This latter strandproduced extensive deep analyses.
Kiraz (1994)extended the architecture with multi-level tape,to deal with the typical interruption of root lettersequences caused by broken plural and weakroot letter change.
Beesley (1996) describes there-implementation of earlier work as a singlefinite state transducer between surface andlexical (root and tag) strings.
This was refined(Beesley 1998) to the current on-line systemcapable of analysing over 70 million words.So far, these approaches have limited scope fordeployment in IR.
Even if substantial, theirmorpho-syntactic coverage remains limited andprocessing efficiency implications are oftenunclear.
In addition, modern written Arabicpresents a unique range of orthographicproblems.
Short vowels are not normally written(but may be).
Different regional spellingconventions may appear together in a single textand show interference with spelling errors.These systems, however, assume text to be inperfect (some even vowelised) form, forcing theneed for editing prior to processing.
Finally, thesuccess of these algorithms depends critically onroot, stem, pattern or affix dictionary quality,and no sizeable and reliable electronicdictionaries exist.
Beesley (1998) is theexception with a reported 4930 roots encodedwith associated patterns, and an additional affixand non-root stem lexicon1.
Absence of largeand reliable electronic lexical resources meansdictionaries would have to be updated as newwords appear in the text, creating a maintenanceoverhead.
Overall, it remains uncertain whetherthese approaches can be deployed and scaled upcost-effectively to provide the coverage requiredfor full scale IR on unsanitised text.Our objective is to circumvent morpho-syntactic analysis of Arabic words, by usingclustering as a technique for grouping wordssharing a root.
In practise, since Arabic wordsderived from the same root are semanticallyrelated, root based clusters can substitute rootdictionaries for indexing in IR and furnishalternative search terms.
Clustering workswithout dictionaries, and the approach removesdictionary overheads completely.
Clusters canbe implemented as a dimension of the index,growing dynamically with text, and withoutspecific maintenance.
They will accommodateeffortlessly a mixture of regional spellingconventions and even some spelling errors.1 Clustering and Arabic.To our knowledge, there is no application ofautomatic root-based clustering to Arabic, usingmorphological similarity without dictionary.Clustering and stemming algorithms havemainly been developed for Western Europeanlanguages, and typically rely on simple heuristicrules to strip affixes and conflate strings.
Forinstance, Porter (1980) and Lovins (1968)confine stemming to suffix removal, yet yieldacceptable results for English, where roots arerelatively inert.
Such approaches exploit themorphological frugality of some languages, butdo not transfer to heavily inflected languagessuch as Arabic.In contrast, Adamson and Boreham (1974)developed a technique to calculate a similarityco-efficient between words as a factor of thenumber of shared sub-strings.
The approach(which we will call Adamson?s algorithm forshort) is a promising starting point for Arabic1 Al-Fedaghi and Al-Anzi (1989) estimate there arearound 10,000 independent roots.clustering because affix removal is not critical togauging morphological relatedness.In this paper, we explain the algorithm, applyit to raw modern Arabic text and evaluate theresult.
We explain our Two-stage algorithm,which extends the technique by (a) lighttemming and (b) refinements sensitive toArabi  morphology.
We show how theadaptation increased successful clustering ofboth the original and new evaluation data.2 Data DescriptionWe focus on IR, so experiments use modern,unedited Arabic text, with unmarked shortvowels (Stalls and Knight 1998).
In all weconstructed five data sets.
The first set iscontrolled, and was designed for testing on abroad spectrum of morphological variation.
Itcontains selected roots with derived wordschosen for their problematic structure, featuringinfixes, root consonant changes and weak letters.It also includes superficially similar wordsbelonging to different roots, and examples ofhamza as a root consonant, an affix and a silentsign.
Table 1 gives details.Table 1: Cluster size for 1st data setroot size root sizektb wrote 49 HSL obtained 7qwm straightened38 s?aL asked 6mr passed 26 HSd cultivated5wSL linked 11 shm shared 4r?as headed 10Data sets two to four contain articles extractedfrom Al-Raya (1997), and the fifth from Al-Watan (2000), both newspapers from Qatar.Following Adamson, function words have beenremoved.
The sets have domain bias with thesecond (575 words) and the fourth (232 words)drawn randomly from the economics and thethird (750 words) from the sports section.
Thefifth (314 words) is a commentary on politicalhistory.
Sets one to three were used to varyingextents in refining our Two-stage algorithm.
Setsfour and five were used for evaluation only.Electronically readable Arabic text has onlyrecently become available on a useful scale,hence our experiments were run on short texts.On the other hand, the coverage of the data setsallows us to verify our experiments ondemanding samples, and their size lets us verifycorrect clustering manually.3.
Testing Adamson?s Algorithm3.1 The AlgorithmAdamson and Boreham (1974) developed atechnique expressing relatedness of strings as afactor of shared sub-strings.
The algorithm dragsan n-sized window across two strings, with a 1character overlap, and removes duplicates.
Thestrings' similarity co-efficient (SC) is calculatedby Dice?s equation: SC (Dice) = 2*(number ofshared unique n-grams)/(sum of unique n-gramsin each string)Table 2: Adamson's Algorithm IllustratedString 2-grams Unique 2-gramsphosphorus ph ho os sp phho or ru usph ho os sp or ruus (7)phosphate ph ho os sp phha at teph ho os sp ha atte (7)Shared unique 2-grams ph ho os sp (4)SC (Dice) = 2(4)/(7+7) = 0.57After the SC for all word pairs is known, thesingle link clustering algorithm is applied.
Asimilarity (or dissimilarity) threshold is set.
TheSC of pairs is collected in a matrix.
Thethreshold is applied to each pair?s SC to yieldclusters.
A cluster absorbs a word as long as itsSC to another cluster item exceeds the threshold(van Rijsbergen 1979).
Similarity to a singleitem is sufficient.
Cluster size is not pre-set.3.2 Background AssumptionsThis experiment tests Adamson's algorithm onArabic data to assess its ability to cluster wordssharing a root.
Each of the data sets wasclustered manually to provide an idealbenchmark.
This task was executed by a nativeArabic speaker with reference to dictionaries.Since we are working with very small texts, wesought to remove the effects of sampling in thetests.
To assess Adamson?s algorithm?s potentialfor clustering Arabic words, we preferred tocompare instances of optimal performance.
Wevaried the SC to yield, for each data set, thehighest number of correct multi-word clusters.Note that the higher the SC cut-off, the lesslikely that words will cluster together, and themore single word clusters will appear.
This hasthe effect of growing the number of correctclusters because the proportion of correct singleword clusters will increase.
As a consequence,for our purposes, the number of correct multi-word clusters (and not just correct clusters) arean important indicator of success.A correct multi-word cluster covers at leasttwo words and is found in the manualbenchmark.
It contains all and only those wordsin the data set which share a root.
Comparisonwith a manual benchmark inevitably introducesa subjective element.
Also, our evaluationmeasure is the percentage of correct benchmarkclusters retrieved.
This is a ?recall?
typeindicator.
Together with the strict definition ofcorrect cluster, it cannot measure cluster quality.Finer grained evaluation of cluster quality wouldbe needed in an IR context.However, our main concern is comparingalgorithms.
The current metrics aim for aconservative gauge of how Adamson?salgorithm can yield more exact clusters from afull range of problematic data.Table 3: Adamson's Algorithm Test ResultsData set Set 1 Set 2 Set 3 Set 4 Set 5Benchmark:Total Manual Clusters(A)9 267 337 151 190Multi-word (B) 9 130 164 50 63Single word (C) 0 137 173 101 127SC cut-off2 0.50 0.54 0.75 0.58-0.60 0.61-0.66Test:(% of Benchmark)Correct Clusters (% of A)11.11% 56.55% 60.83% 70.86% 74.21%Multi-word (% of B) 11.11% 38.46% 21.95% 40% 34.92%Single word (% of C)0.0% 73.72% 97.69% 86.14% 93.70%2 Ranges rather than specific values are given wherecut-offs between the lower and higher value do notalter cluster distribution.Our interpretation of correct clustering isstringent and therefore conservative, adding tothe significance of our results.
Cluster qualitywill be reviewed informally.3.3 Adamson?s Arabic Test ResultsTable 3 shows results for Adamson?salgorithm.
The figures for the first data set haveto be suitably interpreted.
The set deliberatelydid not include single word clusters.The results suggest that the algorithm is verysuccessful at identifying single word clusters butperforms poorly on multi-word clusters.
Thehigh success rate for single word clusters ispartly due to the high SC cut-off, set to yield asmany correct multi-word clusters as possible.In terms of quality, however, only a smallproportion of multi-word clusters were found tocontain infix derivations (11.11%, 4.76%, 0.0%4.35% and 9.09% for each data set respectively),as opposed to other variations.
In other words,strings sharing character sequences in middleposition cluster together more successfully.
Infixrecognition is a weak point in this approach.Whereas the algorithm is successful forEnglish, it is no surprise that it should notperform equally well on Arabic.
Arabic wordstend to be short and the chance of words derivedfrom different roots sharing a significantproportion of characters is high (eg Khbr (news)vs Khbz (bread)).
Dice?s equation assumes theability to identify an uninterrupted sequence ofroot consonants.
The heavy use of infixes runsagainst this.
Similarly, affixes cause interference(see 4.1.1).4 The Two-Stage Algorithm.The challenge of root based clustering forArabic lies in designing an algorithm which willive relevance to root consonants only.
UsingAdamson?s algorithm as a starting point, wedevised a solution by introducing and testing anumber of successive refinements based on themorphological knowledge and the first threedata sets.
The rationale motivating theserefinements is given below.4.1 Refinements4.1.1Affixes and light stemming:The high incidence of affixes keeps accuratecluster formation low, because it increases theSC among words derived from different roots,and lowers the SC between derivations of thesame root using different affixes, as illustrated intables 4 and 5.
Following Popovic and Willet(1992), we introduced stemming to minimise theeffect of affixes.
We found empirically that lightstemming, removing a small number of obviousaffixes, gave better results than heavy stemmingaimed at full affix stripping.
Heavy stemmingbrought the risk of root consonant loss (egt?amyn (insurance) from root amn (sheltered):heavy stemming: t?am, light stemming: t?amn).Light stemming, on the other hand, does littlemore than reducing word size to 3 or 4characters.4.1.2Weak letters, infixes and ?cross?
:Weak letters (alif, waw, ya) occur freely asroot consonants as well as affixes.
Underderivation, their form and location may change,or they may disappear.
As infixes, they interferewith SC, causing failure to cluster (table 6).Their effects were reduced by a method we referto as ?cross?.
It adds a bi-gram combining theletters occurring before and after the weak letter.Table 4: Inflected words from different roots: ?Lm (learned) and arb (arabised)String Unique 2-grams with affixes Unique 2-grams without affixesaL?aLmyh (the universal) aL L?
?a Lm my yh  (6) ?a Lm (2)aL?rbyh (the Arabic)  aL L?
?r rb by yh  (6) ?r rb (2)SC (Dice) 2(3)/(6+6) = 0.50 2(0)/(2+2) = 0Table 5: Inflected words from the same root: mrr (passed)String Unique 2-grams with affixes Unique 2-grams without affixesmstmr (continuous) ms st tm mr (4) mr (1)mr (passed) mr (1) mr (1)SC (Dice) 2(1)/(4+1) = 0.40 2(1)/(1+1) = 1.0Table 6: Infix derivation from root wqf (stopped) - post light stemmingString Unique 2-grams without cross Unique di-grams with crossqaf qa af (2) qa af qf (3)wqf wq qf (2) wq qf (2)SC (Dice) 2(0)/(2+2) = 0 2(1)/(2+3) = 0.44.1.3Suspected affixes and differentialweighting:Our objective is to define an algorithm whichgives suitable precedence to root consonants.Light stemming, however does not remove allaffixes.
Whereas fool proof affix detection isproblematic due to the overlap between affix androot consonants, affixes belong to a closed classand it is possible to identify ?suspect?
letterswhich might be part of an affix.Following Harman (1991) we explored theidea of assigning differential weights to sub-strings.
Giving equal weight of 1 to allsubstrings equates the evidence contributed byall letters, whether they are root consonants ornot.
Suspected affixes, however, should not beallowed to affect the SC between words on a parwith characters contributing stronger evidence.We conducted a series of experiments withdifferential weightings, and determinedempirically that 0.25 weight for stringscontaining weak letters, and 0.50 for stringscontaining suspected non-weak letter affixesgave the best SC for the first three data sets.4.1.4Substring boundaries:N-gram size can curtail the significance ofword boundary letters (Robertson and Willet1992).
To give them opportunity to contributefully to the SC, we introduced word boundaryblanks (Harman 1991).Also, the larger the n-gram, the greater itscapacity to mask the shorter substring which cancontain important evidence of similarity betweenword pairs (Adamson and Boreham 1974).
Ofequal importance is the size of the slidingoverlap between successive n-grams (Adams1991).Table 7: Blank insertion with ?cross?String Unique 2-grams (no)qaf *q qa af qf f* (5)wqf *w wq *q qf f* (5)SC (Dice) 2(3)/(5+5) =  0.60The problem is to find the best setting for n-gram and overlap size to suit the language.
Wesought to determine settings experimentally.
Bi-grams with single character overlap and blankinsertion (* in the examples) at word boundariesraised the SC for words sharing a root in ourthree data sets, and lowered the SC for wordsbelonging to different roots.4.1.5SC formula:Dice?s equation boosts the importance ofunique shared substrings between word pairs, bydoubling their evidence.
As we argued earlier,since Arabic words tend to be short, the relativeimpact of shared substrings will already bedramatic.
We replaced the Dice metric with theJaccard formula below to reduce this effect (seevan Rijsbergen 1979).
SC (Jac) = shared uniquen-grams/(sum of unique n-grams in each string -shared unique n-grams)4.2 The Two-stage AlgorithmThe Two-stage algorithm is fully implemented.Words are first submitted to light stemming toremove obvious affixes.
The second stage isbas d on Adamson?s algorithm, modified asdescribed above.
From the original, we retainedbi-grams with a one character overlap, butinserted word boundary blanks.
Unique bi-gramsare isolated and cross is implemented.
Each bi-gram is assigned a weight (0.25 for bi-gramscontaining weak letters; 0.5 for bi-gramscontaining potential non-weak letter affixes; 1for all other bi-grams).
Jaccard?s equationcomputes a SC for each pair of words.
Weretained the single-link clustering algorithm toensure comparability.4.3 Testing the Two-stage AlgorithmTable 8 shows the results of the Two-stagealgorithm for our data sets.
The maximallyeffective cut of point for all sets lies closer.Figures for the first set have to be treated withcaution.
The perfect clustering is explained bythe text?s perfect spelling and by the samplecontaining exactly those problematic phenomenaon which we wanted to concentrate.Table 8: Two-stage Algorithm Test ResultsData set Set 1 Set 2 Set 3 Set 4 Set 5Benchmark:Total Manual Clusters (A) 9 267 337 151 190Multi-word (B) 9 130 164 50 63Single word (C) 0 137 173 101 127SC cut-off 0.42-0.66 0.54 0.54 0.53-0.540.62-0.66Test:  (% of Benchmark)Correct Clusters (% of A) 100% 88.05% 86.94% 94.04% 86.84%Multi-word (% of B) 100% 85.39% 82.93% 94% 74.60%Single word (% of C) - 90.51% 90.75% 94.06% 92.91%The algorithm deals with weak letter mutation,and infix appearance and disappearance inwords sharing a root (eg the root qwm and itsderived words, especially the role of Hamza asan infix in one of its variations).
Even thoughthe second and third data sets informed themodifications to a limited extent, their resultsshow that the improvements stood up to freetext.
For the second data set, the Two-stagealgorithm showed 31.5% improvement overAdamson?s algorithm.
Importantly, it discovered84.13% of the multi-word clusters containingwords with infixes, an improvement of 79.37%.The values for single word clustering are closeand the modifications preserved the strength ofAdamson?s algorithm in keeping single wordclusters from mixing, because we were able tomaintain a high SC threshold.On the third data set, the Two-stage algorithmshowed an 26.11% overall improvement, with84% successful multi-word clustering of wordswith infixes (compare 0% for Adamson).
Thelargest cluster contained 14 words.
10 clusterscounted as unsuccessful because they containedone superficially similar variation belonging to adifferent root (eg TwL (lengthened) and bTL (tobe abolished)).
If we allow this error margin, thesuccess rate of multi-word clustering rises to90%.
Since our SC cut-off was significantlylower than in Adamson?s base line experiment,we obtained weaker results for single wordclustering.The fourth and fifth data sets played no role inthe development of our algorithm and were usedfor evaluation purposes only.
The Two-stagealgorithm showed an 23.18% overallimprovement in set four.
It successfully built allclusters containing words with infixes (100% -compare with 4.35% for Adamson?s algorithm),an improvement of 95.65%.
The two-stagealgorithm again preserved the strength ofAdamson at distinguishing single word clusters,i  spite of a lower SC cut-off.The results for the fifth data set are particularlyimportant because the text was drawn from adiffer nt source and domain.
Again, significantimprovements in multi and single wordclustering are visible, with a slightly higher SCcut-off.
The algorithm performed markedlybetter at identifying multi-word clusters withinfixes (72.72% - compare with 9.09% forAdamson).The results suggest that the Two-stagealgorithm preserves the strengths of Adamsonand Boreham (1994), whilst adding a markedadvantage in recognising infixes.
The outcomeof the evaluation on fourth and fifth data sets arevery encouraging and though the samples aresmall, they give a strong indication that this kindof approach may transfer well to text fromdifferent domains on a larger scale.5 Two-stage Algorithm LimitationsWeak letters can be root consonants, but ourdifferential weighting technique prevents themfrom contributing strong evidence, whereas non-weak letters featuring in affixes, are allowed tocontribute full weight.
Modifying thisarrangement would interfere with successfulclustering (eg after light stemming: t is a rootconsonant in ntj (produced) and an infix in Ltqy(from root Lqy - encountered).
These limitationsare a result of light stemming.Although the current results are promising,evaluation was hampered by the lack of asizeable data set to verify whether our solutionwould scale up.ConclusionWe have developed, successfully, an automaticclassification algorithm for Arabic words whichshare the same root, based only on theirmorphological similarities.
Our approach workson unsanitised text.
Our experiments show thatalgorithms designed for relatively uninflectedlanguages can be adapted for highly inflectedlanguages, by using morphological knowledge.We found that the Two-stage algorithm gave asignificant improvement over Adamson?salgorithm for our data sets.
It dealt successfullywith infixes in multi-word clustering, an areawhere Adamson?s algorithm failed.
It matchedthe strength of Adamson in identifying singleword clusters, and sometimes did better.
Weakletters and the overlap between root and affixconsonants continue to cause interference.Nonetheless, the results are promising andsuggest that the approach may scale upFuture work will concentrate on two issues.The light stemming algorithm and thedifferential weighting may be modified toimprove the identification of affixes.
The extentto which the algorithm can be scaled up must betested on a large corpus.AcknowledgementsOur thanks go to the Kuwait State's PublicAuthority for Applied Education and Training,for the supporting research studentship, and totwo anonymous referees for detailed, interestingand constructive comments.Appendix - Arabic in a NutshellThe vast majority of Arabic words are derivedfrom 3 (and a few 4) letter roots via a complexmorphology.
Roots give rise to stems by theapplication of a set of fixed patterns.
Addition ofaffixes to stems yields words.Table 9: Stem PatternsRoot Pattern Stemktb wrote fa?L katb writermf?wL mktwb documentqtL killed fa?L qatL killermf?wL mqtwL corpseTable 9 shows examples of stem derivationfrom 3-letter roots.
Stem patterns are formulatedas variations on the characters f?L (pronouncedas f'l - ?
is the symbol for ayn, a strong glottalstop), where each of the successive consonantsmatches a character in the bare root (for ktb, kmatches f, t matches ?
and b matches L).
Stemsfollow the pattern as directed.
As the examplesshow, each pattern has a specific effect onmeaning.
Several hundred patterns exist, but onaverage only about 18 are applicable to eachroot (Beesley 1998).The language distinguishes between long andshort vowels.
Short vowels affect meaning, butare not normally written.
However, patterns mayinvolve short vowels, and the effects of somepatterns are indistinguishable in written text.Readers must infer the intended meaning.Affixes may be added to the word, either underderivation, or to mark grammatical function.
Forinstance, walktab breaks down as w (and) + al(the) + ktab (writers, or book, depending on thevoweling).
Other affixes function as person,number, gender and tense markers, subject anddirect object pronouns, articles, conjunctions andprepositions, though some of these may alsooccur as separate words (eg wal (and the)).Arabic morphology presents some tricky NLPproblems.
Stem patterns ?interdigitate?
with rootconsonants, which is difficult to parse.
Also, thelong vowels a (lif), w (waw) and y (ya) canoccur as root consonants, in which case they areconsidered to be weak letters, and the root aweak root.
Under certain circumstances, weakletters may change shape (eg waw into ya) ordi appear during derivation.
Long vowels alsooccur as affixes, so identifying them as affix orroot consonant is often problematic.The language makes heavy use of infixes aswell as prefixes and suffixes, all of which maybe consonants or long vowels.
Apart frombreaking up root letter sequences (which tend tobe short), infixes are easily confused with rootconsonants, whether weak or not.
The problemfor affix detection can be stated as follows: weakroot consonants are easily confused with longvowel affixes; consonant affixes are easilyconfused with non-weak letter root consonants.Erroneus stripping of affixes will yield thewrong root.Arabic plurals are difficult.
The dual and someplurals are formed by suffixes, in which casethey are called external plurals.
The broken, orinternal plural, however, changes the internalstructure of the word according to a set ofpatterns.
To illustrate the complexity, masculineplurals take a -wn or -yn suffix, as in mhnds(engineer), mhndswn.
Female plurals add the -atsuffix, or change word final -h to -at, as inmdrsh (teacher), mdrsat.
Broken plurals affectroot characters, as in mal (fund from root mwl),amwal, or wSL (link from root wSL), ?aySaL.The examples are rife with long vowels (weakletters?).
They illustrate the degree ofinterference between broken plural patterns andother ways of segmenting words.Regional spelling conventions are common:eg.
three versions of word initial alif occur.
Themost prominent orthographic problem is thebehaviour of hamza, (?
), a sign written over acarrier letter and sounding a lenis glottal stop(not to be confused with ayn).
Hamza is notalways pronounced.
Like any other consonant, itcan take a vowel, long or short.
In word initialposition it is always carried by alif, but may bewritten above or below, or omitted.
Mid-word itis often carried by one of the long vowels,depending on rules whose complexity oftengives rise to spelling errors.
At the end of words,it may be carried or written independently.Hamza is used both as a root consonant and anaffix, and is subject to the same problems asnon-weak letter consonants, compounded byunpredictable orthography: identical words mayhave differently positioned hamzas and wouldbe considered as different strings.ReferencesAdams, E. (1991)  A Study of Trigrams and theirfeasibility as Index Terms in a full text InformationRetrieval System.
PhD Thesis, George WashingtonUniversity, USA.Adamson, George W. and J. Boreham (1974)  Theuse of an association measure based on characterstructure to identify semantically related pairs ofwords and document titles.
Information Storageand Retrieval,.
Vol 10, pp 253-260Al-Fedaghi Sabah S. and Fawaz Al-Anzi (1989)  Anew algorithm to generate Arabic root-patternforms.
Proceedings of the 11th National ComputerConference, King Fahd University of Petroleum &Minerals, Dhahran, Saudi Arabia., pp04-07Al-Kharashi, I. and M. Evens (1994)  Comparingwords, stems, and roots as Index terms in anArabic Information Retrieval system.
Journal of theAmerican Society for Information Science, 45/8,pp.
548-560Al-Naj m, Salah R. (1998).
An Explanation ofComputational Arabic Morphology.
DATRDocumentation Report, University of Sussex.Al-Raya (1997) Newspaper.
Quatar.Al-Shalabi, R. and M. Evens (1998)  AComputational Morphology System for Arabic.Proceedings of COLING-ACL, New Brunswick,NJ.Al-Watan (2000) Newspaper.
Qatar.Beesley, K.B.
(1996)  Arabic Finite-StateMorphological Analysis and Generation.Proceedings of COLING-96, pp 89-94.Beesley, K.B.
(1998)  Arabic Morphological Analysison the Internet.
Proceedings of the 6th InternationalConference and Exhibition on Multi-LingualComputing, Cambridge.El-Sadany, T. and M. Hashish (1989)  An Arabicmorphological system.
IBM System Journal, 28/4Harman, D. (1991)  How effective is suffixing?Journal of the American Society for InformationScience, 42/1, pp 7-15.Hmeidi, I., Kanaan, G. and M. Evens (1997)  Designand Implementation of Automatic Indexing forInformation Retrieval with Arabic Documents.Journal of the American Society for InformationScience, 48/10, pp.
867-881.Kiraz, G. (1994)  Multi-tape two-level Morphology: acase study in Semitic non-linear morphology.Proceedings of COLING-94, pp180-186.Lovins, J.B. (1968)  Development of a StemmingAlgorithm.
Mechanical Translation andComputational Linguistics, 11/1.Popovic, M. and P. Willet (1992)  The effectivenessof stemming for natural language access to Sloventextual data.
Journal of the American Society forInformation Science, 43/5, pp.
384-390.Porter, M.F.
(1980)  An Algorithm for suffixstripping.
Program, 14 /3, pp 130-137Stalls, B. and Knight, K. (1998)  Translating namesand technical terms in Arabic text.
Proceedings ofCOLING-ACL, New Brunswick, NJ, 1998van Rijsbergen, C. J.
(1979)  Information Retrieval.Butterworths, London.Robertson, A. and Willett, P.(1992)  Searching forhistorical word-forms in a database of 17th-centuryEnglish text using spelling-correction methods.
15thAnnual International Conference SIGIR.Ubu-Salem H., Al-Omari M., and M. Evens (1999)Stemming methodologies over individual querywords for an Arabic information retrieval system.Journal of the American Society for InformationScience.
50/6, pp 524-529.
