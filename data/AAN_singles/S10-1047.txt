Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 214?217,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsFBK-IRST: Semantic Relation Extraction using CycKateryna Tymoshenko and Claudio GiulianoFBK-IRSTI-38050, Povo (TN), Italytymoshenko@fbk.eu, giuliano@fbk.euAbstractWe present an approach for semantic re-lation extraction between nominals thatcombines semantic information with shal-low syntactic processing.
We propose touse the ResearchCyc knowledge base asa source of semantic information aboutnominals.
Each source of informationis represented by a specific kernel func-tion.
The experiments were carried outusing support vector machines as a clas-sifier.
The system achieves an overall F1of 77.62% on the ?Multi-Way Classifica-tion of Semantic Relations Between Pairsof Nominals?
task at SemEval-2010.1 IntroductionThe SemEval-2010 Task 8 ?Multi-Way Classifi-cation of Semantic Relations Between Pairs ofNominals?
consists in identifying which seman-tic relation holds between two nominals in a sen-tence (Hendrickx et al, 2010).
The set of rela-tions is composed of nine mutually exclusive se-mantic relations and the Other relation.
Specifi-cally, the task requires to return the most informa-tive relation between the specified pair of nomi-nals e1and e2taking into account their order.
An-notation guidelines show that semantic knowledgeabout e1and e2plays a very important role in dis-tinguishing among different relations.
For exam-ple, relations Cause-Effect and Product-Producerare closely related.
One of the restrictions whichmight help to distinguish between them is thatproducts must be concrete physical entities, whileeffects must not.Recently, there has emerged a large number offreely available large-scale knowledge bases.
Theground idea of our research is to use them assource of semantic information.
Among such re-sources there are DBpedia,1YAGO,2and Open-Cyc.3On the one hand, DBpedia and YAGO havebeen automatically extracted from Wikipedia.They have a good coverage of named entities, buttheir coverage of common nouns is poorer.
Theyseem to be more suitable for relation extraction be-tween named entities.
On the other hand, Cyc isa manually designed knowledge base, which de-scribes actions and entities both in common lifeand in specific domains (Lenat, 1995).
Cyc hasa good coverage of common nouns, making it in-teresting for our task.
The full version of Cyc isfreely available to the research community as Re-searchCyc.4We approached the task using the system intro-duced by Giuliano et al (2007) as a basis.
Theyexploited two information sources: the whole sen-tence where the relation appears, and WordNetsynonymy and hyperonymy information.
In thispaper, we (i) investigate usage of Cyc as a sourceof semantic knowledge and (ii) linguistic infor-mation, which give useful clues to semantic re-lation extraction.
From Cyc, we obtain informa-tion about super-classes (in the Cyc terminologygeneralizations) of the classes which correspondto nominals in a sentence.
The sentence itselfprovides linguistic information, such as local con-texts of entities, bag of verbs and distance betweennominals in the context.The different sources of information are rep-resented by kernel functions.
The final systemis based on four kernels (i.e., local context ker-nel, distance kernel, verbs kernel and generaliza-tion kernel).
The experiments were carried out us-ing support vector machines (Vapnik, 1998) as aclassifier.
The system achieves an overall F1of1http://dbpedia.org/2http://www.mpi-inf.mpg.de/yago-naga/yago/3http://www.cyc.com/opencyc4http://research.cyc.com/21477.62%.2 Kernel Methods for RelationExtractionIn order to implement the approach based on shal-low syntactic and semantic information, we em-ployed a linear combination of kernels, using thesupport vector machines as a classifier.
We de-veloped two types of basic kernels: syntactic andsemantic kernels.
They were combined by exploit-ing the closure properties of kernels.
We define thecomposite kernelKC(x1, x2) as follows.n?i=1Ki(x1, x2)?Ki(x1, x1)Ki(x2, x2).
(1)Each basic kernelKiis normalized.All the basic kernels are explicitly calculated asfollowsKi(x1, x2) = ??
(x1), ?(x2)?
, (2)where ?(?)
is the embedding vector.
The resultingfeature space has high dimensionality.
However,Equation 2 can be efficiently computed explicitlybecause the representations of input are extremelysparse.2.1 Local context kernelLocal context is represented by terms, lemmata,PoS tags, and orthographic features extractedfrom a window around the nominals consideringthe token order.
Formally, given a relation ex-ample R, we represent a local context LC =t?w, ..., t?1, t0, t+1, ..., t+was a row vector?LC(R) = (tf1(LC), tf2(LC), ..., tfm(LC) ) ?
{0, 1}m,(3)where tfiis a feature function which returns 1if the feature is active in the specified positionof LC; 0 otherwise.
The local context kernelKLC(R1, R2) is defined asKLC e1(R1, R2) +KLC e2(R1, R2), (4)where KLC e1and KLC e2are defined by substi-tuting the embedding of the local contexts of e1and e2into Equation 2, respectively.2.2 Verb kernelThe verb kernel operates on the verbs present inthe sentence,5representing it as a bag-of-verbs.5On average there are 2.65 verbs per sentenceMore formally, given a relation example R, werepresent the verbs from it as a row vector?V(R) = (vf(v1, R), ..., vf(vl, R)) ?
{0, 1}l, (5)where the binary function vf(vi, R) shows if aparticular verb is used in R. By substituting?V(R) into Equation 2 we obtain the bag-of-verbskernelKV.2.3 Distance kernelGiven a relation example R(e1, e2), we repre-sent the distance between the nominals as a one-dimensional vector?D(R) =1dist(e1, e2)?
<1, (6)where dist(e1, e2) is number of tokens betweenthe nominals e1and e2in a sentence.
By substitut-ing ?D(R) into Equation 2 we obtain the distancekernelKD.2.4 Cyc-based kernelCyc is a comprehensive, manually-build knowl-edge base developed since 1984 by CycCorp.
Ac-cording to Lenat (1995) it can be considered asan expert system with domain spanning all ev-eryday actions and entities, like Fish live in wa-ter.
The open-source version of Cyc named Open-Cyc, which contains the full Cyc ontology and re-stricted number of assertions, is freely availableon the web.
Also the full power of Cyc has beenmade available to the research community via Re-searchCyc.
Cyc knowledge base contains morethan 500,000 concepts and more than 5 million as-sertions about them.
They may refer both to com-mon human knowledge like food or drinks and tospecialized knowledge in domains like physics orchemistry.
The knowledge base has been formu-lated using CycL language.
A Cyc constant repre-sents a thing or a concept in the world.
It may bean individual, e.g.
BarackObama, or a collection,e.g.
Gun, Screaming.2.4.1 Generalization kernelGiven a nominal e, we map it to a set of Cycconstants EC = {ci}, using the Cyc functiondenotation-mapper.
Nominals in Cyc usually de-note constants-collections.
Notice that we do notperformword sense disambiguation.
For each ci?EC, we query Cyc for collections which general-ize it.
In Cyc collection X generalizes collection215Y if each element of Y is also an element of col-lectionX .
For instance, collection Gun is general-ized by Weapon, ConventionalWeapon, Mechani-calDevice and others.The semantic kernel incorporates the data fromCyc described above.
More formally, given a rela-tion example R each nominal e is represented as?EC(R) = (fc(c1, e), ..., fc(ck, e)) ?
{0, 1}k, (7)where the binary function fc(ci, e) shows if a par-ticular Cyc collection ciis a generalization of e.The bag-of-generalizations kernelKgenls(R1, R2) is defined asKgenls e1(R1, R2) +Kgenls e2(R1, R2) , (8)whereKgenls e1andKgenls e2are defined by sub-stituting the embedding of generalizations e1ande2into Equation 2 respectively.3 Experimental setup and ResultsSentences have been tokenized, lemmatized andPoS tagged with TextPro.6Information for gener-alization kernel has been obtained from Research-Cyc.
All the experiments were performed usingjSRE customized to embed our kernels.7jSREuses the SVM package LIBSVM (Chang and Lin,2001).
The task is casted as multi-class classifica-tion problem with 19 classes (2 classes for eachrelation to encode the directionality and 1 classto encode Other).
The multiple classification taskis handled with One-Against-One technique.
TheSVM parameters have been set as follows.
Thecost-factor Wifor a given class i is set to be theratio between the number of negative and positiveexamples.
We used two values of regularizationparameter C: (i) Cdef=1?K(x,x)where x areall examples from the training set, (ii) optimizedCgridvalue obtained by brute-force grid searchmethod.
The default value is used for the otherparameters.Table 1 shows the performance of different ker-nel combinations, trained on 8000 training exam-ples, on the test set.
The system achieves thebest overall macro-average F1of 77.62% usingKLC+KV+KD+Kgenls.
Figure 1 shows thelearning curves on the test set.
Our experimen-tal study has shown that the size of the training6http://textpro.fbk.eu/7jSRE is a Java tool for relation extraction avail-able at http://tcc.itc.it/research/textec/tools-resources/jsre.html.1000 2000 4000 80000.400.450.500.550.600.650.700.750.800.850.90Cause-EffectComponent-Whole Content-ContainerEntity-Destination Entity-Origin Instrument-Agency Member-CollectionMessage-TopicProduct-ProducerAllNumber of training examplesF1Figure 1: Learning curves on the test set per rela-tionKernels P R F1KLC+KV+KD+Kgenls74.98 80.69 77.62KLC+KV+KD+Kgenls* 78.51 76.03 77.11KLC+KD+Kgenls* 78.14 75.93 76.91KLC+Kgenls* 78.19 75.70 76.81KLC+KD+Kgenls72.98 80.28 76.39KLC+Kgenls73.05 79.98 76.28Table 1: Performance on the test set.
Combina-tions marked with * were run with Cgrid, otherswith Cdef.set influences the performance of the system.
Weobserve that when the system is trained on 8000examples the overall F1increases for 14.01% ascompared to the case of 1000 examples.4 Discussion and error analysisThe experiments have shown thatKLCis the corekernel of our approach.
It has good performanceon its own.
For instance, it achieves precision of66.16%, recall 72.67% and F1of 69.13% evalu-ated using 10-fold cross-validation on the trainingset.Relation KLCKLC+Kgenls?F1Cause-Effect 74.29 76.41 2.12Component-Whole 61.24 66.13 4.89Content-Container 76.36 79.12 2.76Entity-Destination 82.85 83.95 1.10Entity-Origin 72.09 74.13 2.04Instrument-Agency 57.71 65.51 7.80Member-Collection 81.30 83.40 2.10Message-Topic 60.41 69.09 8.68Product-Producer 55.95 63.52 7.57Table 2: The contribution of Cyc evaluated on thetraining set.216Generalization kernel combined with local con-text kernel gives precision of 70.38%, recall of76.96%, and F173.47% with the same exper-imental setting.
The increase of F1per re-lation is shown in the Table 2 in the col-umn ?F1.
The largest F1increase is ob-served for Instrument-Agency (+7.80%),Message-Topic (+8.68%) and Product-Producer (+7.57%).Kgenlsreduces the number of misclassificationsbetween the two directions of the same rela-tion, like Product-Producer(artist,design).
Italso captures the differences among relations,specified in the annotation guidelines.
For in-stance, the system based only on KLCmisclass-fied ?The<e1>species</e1>makes a squelching<e2>noise</e2>?
as Product-Producer(e2,e1).Generalizations for <e2>noise</e2> providedby Cyc include Event, MovementEvent, Sound.According to the annotation guidelines a productmust not be an event.
A system based on the com-bination of KLCand Kgenlscorrectly labels thisexample as Cause-Effect(e1,e2).Kgenlsimproves the performance in general.However, in some cases using Cyc as a source ofsemantic information is a source of errors.
Firstly,sometimes the set of constants for a given nom-inal is empty (e.g., disassembler, babel) or doesnot include the correct one (noun surge is mappedto the constant IncreaseEvent).
In other cases,an ambiguous nominal is mapped to many con-stants at once.
For instance, notes is mappedto a set of constants, which includes Musical-Note, Note-Document and InformationRecording-Process.
Word sense disambiguation should helpto solve this problem.
Other knowledge bases likeDBpedia and FreeBase8can be used to overcomethe problem of lack of coverage.Bag-of-word kernel with all words from thesentence did not impact the final result.9However,the information about verbs present in the sentencerepresented by KVhelped to improve the perfor-mance.
A preliminary error analysis shows that adeeper syntactic analysis could help to further im-prove the performance.For comparison purposes, we also exploitedWordNet information by means of the supersensekernel KSS(Giuliano et al, 2007).
In all exper-iments, KSSwas outperformed by Kgenls.
Forinstance, KLC+ KSSgives overall F1measure8http://www.freebase.com/9This kernel has been evaluated only on the training data.of 70.29% with the same experimental setting asdescribed in the beginning of this section.5 ConclusionThe paper describes a system for semantic rela-tions extraction, based on the usage of semanticinformation provided by ResearchCyc and shal-low syntactic features.
The experiments haveshown that the external knowledge, encoded assuper-class information from ResearchCyc with-out any word sense disambiguation, significantlycontributes to improve overall performance of thesystem.
The problem of the lack of coverage maybe overcome by the usage of other large-scaleknowledge bases, such as DBpedia.
For futurework, we will try to use the Cyc inference en-gine to obtain implicit information about nominalsin addition to the information about their super-classes and perform word sense disambiguation.AcknowledgmentsThe research leading to these results has received fundingfrom the ITCH project (http://itch.fbk.eu), spon-sored by the Italian Ministry of University and Research andby the Autonomous Province of Trento and the Copiloskproject (http://copilosk.fbk.eu), a Joint ResearchProject under Future Internet - Internet of Content programof the Information Technology Center, Fondazione BrunoKessler.ReferencesChih-Chung Chang and Chih-Jen Lin, 2001.
LIB-SVM: a library for support vector machines.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Claudio Giuliano, Alberto Lavelli, Daniele Pighin, andLorenza Romano.
2007.
Fbk-irst: Kernel methodsfor semantic relation extraction.
In Proceedings of theFourth International Workshop on Semantic Evaluations(SemEval-2007), Prague, Czech Republic, June.
Associa-tion for Computational Linguistics.Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, PreslavNakov, Diarmuid?O S?eaghdha, Sebastian Pad?o, MarcoPennacchiotti, Lorenza Romano, and Stan Szpakowicz.2010.
Semeval-2010 task 8: Multi-way classification ofsemantic relations between pairs of nominals.
In Proceed-ings of the 5th SIGLEXWorkshop on Semantic Evaluation,Uppsala, Sweden.Douglas B. Lenat.
1995.
CYC: A large-scale investment inknowledge infrastructure.
Communications of the ACM,38(11):33?38.Vladimir N. Vapnik.
1998.
Statistical Learning Theory.Wiley-Interscience, September.217
