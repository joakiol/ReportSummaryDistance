COMPACT REPRESENTATIONS BY  F IN ITE-STATETRANSDUCERSMehryar MohriInstitut Gaspard Monge-LADLUniversit6 Marne-la-Vall6e2, rue de la But te  verte93160 Noisy- le -Grand,  FRANCEInternet:  mohr i@univ -mlv .
f rAbst rac tFinite-state transducers give efficient represen-tations of many Natural Language phenomena.They allow to account for complex lexicon restric-tions encountered, without involving the use of alarge set of complex rules difficult to analyze.
Wehere show that these representations can be madevery compact, indicate how to perform the corre-sponding minimization, and point out interestinglinguistic side-effects of this operation.1.
MOTIVAT IONFinite-state transducers constitute appropriaterepresentations of Natural Language phenomena.Indeed, they have been shown to be sufficient toolsto describe morphological nd phonetic forms of alanguage (Kaxttunen et al, 1992; Kay and Ka-plan, 1994).
Transducers can then be viewed asfunctions which map lexical representations to thesurface forms, or inflected forms to their phoneticpronunciations, and vice versa.
They allow toavoid the use of a great set of complex rules of.ten difficult to check, handle, or even understand.Finite-state automata nd transducers canalso be used to represent the syntactic onstraintsof languages uch as English or French (Kosken-niemi, 1990; Mohri, 1993; Pereira, 1991; Roche,1993).
The syntactic analysis can then be reducedto performing the intersection of two automata,or to the application of a transducer to an au-tomaton.
However, whereas first results how thatthe size of the syntactic transducer xceeds severalhundreds of thousands of states, no upper boundhas been proposed for it, as the representation fall syntactic entries has not been done yet.
Thus,one may ask whether such representations couldsucceed on a large scale.It is therefore crucial to control or to limitthe size of these transducers in order to avoid ablow up.
Classic minimization algorithms permitto reduce to the minimal the size of a determinis-tic automaton recognizing a given language (Ahoet al, 1974).
No similar algorithm has been pro-posed in the case of sequential transducers, namelytransducers whose associated input automata redeterministic.We here briefly describe an algorithm whichallows to compute a minimal transducer, namelyone with the least number of states, from a givensubsequential transducer.
In addition to the de-sired property of minimization, the transducer ob-tained in such a way has interesting linguisticproperties that we shall indicate.
We have fullyimplemented and experimented this algorithm inthe case of large scale dictionaries.
In the lastsection, we shall describe xperiments and corre-sponding results.
They show this algorithm to bevery efficient.2.
ALGORITHMOur algorithm can be applied to any sequentialtransducer T = (V, i, F, A, B, 6, ~) where: V is theset of the states of T, i its initial state, F the setof its final states, A and B respectively the inputand output alphabet of the transducer, ~ the statetransition function which maps V x A to V, andthe output function which maps V x A to B*.With this definition, input labels are elements ofthe alphabet, whereas output labels can be words.Figure 1 gives an example of a sequential trans-ducer.Transducers can be considered as automataover the alphabet A x B*.
Thus, considered assuch they can be submitted to the minimizationin the sense of automata.
Notice however thatthe application of the minimization algorithm forautomata does not permit to reduce the numberof states of the transducer T. We shall describe inthe following how the algorithm we propose allowsto reduce the number of states of this transducer.This algorithm works in two stages.
The firstone modifies only the output automaton associ-ated with the given sequential transducer T. Thus,we can denote by (V,i,F,A,B,~,~2) the trans-204~b:b  ~,1 b:c> c :c:k J- c-df be QFigure 1.
Transducer T.ducer T2 obtained after this first stage.
Let P bethe function which maps V to B* which associateswith each state q of T the greatest common prefixof all the words which can be read on the outputlabels of T from q to a final state.
The value ofP(5) is for instance db since this is the greatestcommon prefix of the labels of all output pathsleaving 3.
In particular, if q is a final state then P(q) is the empty word e. In order to simplify thispresentation, we shall assume in the following that P(i) = e. The output function ~2 of T2 is definedby:Vq~V, ra tA ,  ~2(q, a)= (P(q))-l~r(q, a)P(6(q, a)).Namely, the output labels of T are modified insuch a way that they include every letter whichwould necessarily be read later on the followingtransitions.
Figure 2 illustrates these modifica-tions.T if beginning with the transition (0, 1).
The out-put label of the following transition of T2 is nowempty.
Indeed, anything which could be read fromthe transition (1, 2) on the output labels has nowbeen included in the previous transition (0,1).It is easy to show that the transducer T2 ob-tained after the first stage is equivalent o T.Namely, these two transducers correspond to thesame function mapping A* to B*.
One may no-tice, however, that unlike T this transducer can beminimized in the sense of automata nd that thisleads to a transducer with only six states.
Figure3 indicates the transducer T3 obtained in such away.The second stage of our algorithm preciselyconsists of the application of the minimization ithe sense of automata, that is, of merging equiv-alent states of the transducer.
It can be showedthat the application of the two presented stages to~b:bcddbb:l~ :- c :E. e "eb:e b:dbFigure 2.
Transducer T2.It shows the transducer T2 obtained from T byperforming the operations described above.
Noticethat only the output labels of T have" been mod-ified.
The output label a corresponding to thetransition linking states 0 and 1 of the transducerhas now become abcdb as this is the longest wordwhich is necessarily read from the initial state 0 ofa sequential transducer T systematically leads toan equivalent sequential transducer with the min-imal number of states (Mohri, 1994).
Indeed, thestates of this minimal transducer can be charac-terized by the following equivalence r lation: twostates of a sequential transducer axe equivalent ifand only if one can read the same words from205a: abcdb d: cdbQb : l~ddb ~ b:dbFigure 3.
Transducer Ta.these states using the left automaton associatedwith this transducer (equivalence in the sense ofautomata) and if the corresponding outputs fromthese states differ by the same prefix for any wordleading to a final state.
Thus, the described algo-rithm can be considered as optimal.Notice that we here only considered sequen-tial transducers, but not all transducers epresent-ing sequential functions are sequential.
However,transducers which are not sequential though repre-senting a sequential function can be determinizedusing a procedure close to the one used for the de-terminization of automata.
The algorithm abovecan then be applied to such determinized trans-ducers.The complexity of the application of a nonsequential transducer to a string is not linear.This is not the case even for non-deterministicautomata.
Indeed, recognizing a word w witha non-deterministic automaton of IV\[ states eachcontaining at most e leaving transitions requiresO(e\[Vl\[w D (see Aho et al, 1974).
The applicationof a non-sequential transducer is even more timeconsuming, so the determinization of transducersclearly improves their application.
We have con-sidered above sequential transducers, but trans-ducers can be used in two ways.
These transduc-ers, although they allow linear time applicationon left, are generally not sequential considered asright input transducers.
However, the first stageof the presented algorithm constitutes a pseudo-determinization of right input transducers.
In-deed, as right labels (outputs) are brought closerto the initial state as much as possible, irrelevantpaths are sooner rejected.Consider for example the string x = abcdbcdbeand compare the application of transducers T andTz to this sequence on right input.
Using thetransducer T, the first three letters of this se-quence lead to the single state 5, but then readingdb leads to a set of states {1,5,6}.
Thus, in or-der to proceed with the recognition, one needs tostore this set and consider all possible transitionsor paths from its states.
Using the transducer T2and reading abcdb give the single state 1.
Hence,although the right input transducer is not sequen-tial, it still permits to reduce the number of pathsand states to visit.
This can be considered as an-other advantage of the method proposed for theminimization of sequential transducers: not onlythe transducer is sequential and minimal on oneside, but it is also pseudo-sequential on the otherside.The representation of language often revealsambiguities.
The sequential transducers we havejust described o not allow them.
However, realambiguities encountered in Natural Language Pro-cessing can be assumed to be finite and boundedby an integer p. The use of the algorithm abovecan be easily extended to the case of subsequentialtransducers and even to a larger category of trans-ducers which can represent ambiguities and whichwe shall call p-subsequential r rgsducers.
Thesetransducers are provided with p final functions ~i,(i E \[1,p\]) mapping F, the set of final states, toB*.
Figure 4 gives an example of a 2-subsequentiaitransducer.d ddFigure 4.
2-subsequential transducer T4.The application of these transducers to astring z is similar to the one generally used forsequential ones.
It outputs a string correspond-ing to the concatenation f consecutive labels en-coutered.
However, the output string obtainedonce reaching state q must here be completed bythe ~i(q) without reading any additional input let-ter.
The application of the transducer T4 to theword abc for instance provides the two outputsabca and abcb.The extension of the use of the algorithmabove is easy.
Indeed, in all cases p-subsequential206transducers can be transformed into sequentialtransducers by adding p new letters to the alpha-bet A, and by replacing the p final functions bytransitions labeled with these new letters on in-put and the corresponding values of the functionson output.
These transitions would leave the finalstates and reach a newly created state which wouldbecome the single final state of the transducer.The minimal transducer associated with the 2-subsequential transducer T4 is shown on figure 5.It results from T4 by merging the states 2 and 4after the first stage of pseudo-determinization.b.~cac.~d boccupying about 1,1 Mb.
Also, as the transduceris sequential, it allows faster ecognition times.In addition to the above results, the trans-ducer obtained by this algorithm has interestingproperties.
Indeed, when applied to an input wordw which may not be a French word this transduceroutputs the longest common prefix of the phonetictranscriptions of all words beginning with w. Theinput w -" opio for instance, though it does notconstitute a French word, yields opjoman.
Also,w - opht gives oftalm.
This property of mini-real transducers a defined above could be used inapplications such as OCR or spellchecking, in or-der to restore the correct form of a word from itsbeginning, or from the beginning of its pronunci-ation.Table 1.
Results of minimization experimentsFigure 5.
Minimal 2-subsequential transducer Ts.In the following section, we shall describesome of the experiments we carried out and thecorresponding results.
These experiments u e thenotion of p-subsequential transducers just devel-opped as they all deal with cases where ambigui-ties appear.3.
EXPERIMENTS,  RESULTS,AND PROPERT IESWe have experimented the algorithm describedabove by applying it to several large scale dictio-naries.
We have applied it to the transducer whichassociates with each French word the set of its pho-netic pronunciations.
This transducer can be builtfrom a dictionary (DELAPF) of inflected forms ofFrench, each followed by its pronunciations (La-porte, 1988).
It can be easily transformed intoa sequential or p-subsequential transducer, wherep, the maximum number of ambiguities for thistransducer, is about four (about 30 words admit4 different pronunciations).
This requires that thetransducer be kept deterministic while new asso-ciations are added to it.The dictionary contains about 480.000 entriesof words and phonetic pronunciations and its sizeis about 10 Mb.
The whole minimization algo-rithm, including building the transducer f om thedictionary and the compression of the final trans-ducer, was quite fast: it took about 9 minutesusing a HP 9000/755 with 128 Mb of RAM.
Theresulting transducer contains about 47.000 statesand 130.000 transitions.
Since it is sequential, itcan be better compressed as one only needs tostore the set of its transitions.
The minimal trans-ducer obtained has been put in a compact formInitial sizeDELAPF FDELAF EDELAFFinal sizeStatesTransitions1,1 Mb47.000130.00013.500,Alphabet1,6 Mb66.000195.00020.00020' Time spent1 Mb47.000115.000\[IEVE,We have also performed the same experi-ment using 2 other large dictionaries: French(FDELAF) (Courtois, 1989) and English (EDF_,-LAF) (Klarsfeld, 1991) dictionaries of inflectedforms.
These dictionaries are made of associ-ations of inflected forms and their correspond-ing canonical representations.
It took about 20minutes constructing the 15-subsequential trans-ducer associated with the French dictionary ofabout 22 Mb.
Here again, properties of the ob-tained transducers seem interesting for various ap-plications.
Given the input w=transducte for in-stance the transducer provides the output trans-ducteur.Nl:m. Thus, although w is not a cor-rect French word, it provides two additional let-ters completing this word, and indicates that it isa masculine noun.
Notice that no information isgiven about the number of this noun as it can becompleted by an ending s or not.
Analogous re-sults were obtained using the English dictionary.A part of them is illustrated by the table above.It allows to compare the initial size of the filerepresenting these dictionaries and the size of theequivalent transducers in memory (final size).
Thethird line of the table gives the maximum num-ber of lexical ambiguities encountered in each dic-tionary.
The following lines indicate the number207of states and transitions of the transducers andalso the size of the alphabet needed to representthe output labels.
These experiments show thatthis size remains small compared to the numberof transitions.
Hence, the use of an additional al-phabet does not increase noticeably the size of thetransducer.
Also notice that the time indicatedcorresponds to the entire process of transforma-tion of the file dictionaries into tranducers.
Thisincludes of course the time spent for I/O's.
Wehave not tried to optimize these results.
Severalavailable methods hould help both to reduce thesize of the obtained transducers and the time spentfor the algorithm.4.
CONCLUSIONWe have informally described an algorithm whichallows to compact sequential transducers used inthe description of language.
Experiments on largescale dictionaries have proved this algorithm to beefficient.
In addition to its use in several applica-tions, it could help to limit the growth of the sizeof the representations of syntactic onstraints.REFERENCESAho, Alfred, John Hopcroft, Jeffery Ullman.
1974.The design and analysis o,f computer algorithms.Reading, Mass.
: Addison Wesley.Courtois, Blandine.
1989.
DELAS: Diction-naire Electronique du LADL pour les roots simplesdu franais Technical Report, LADL, Paris, France.Karttunen, Laura, Ronald M. Kaplan, andAnnie Zaenen.
1992.
Two-level Morphology withComposition.
Proceedings o.f the fifteenth Inter-national Conference on Computational Linguistics(COLING'92}, Nantes, France, August.Kay, Martin, and Ronald M. Kaplan.
1994.Regular Models of Phonological Rule Systems.
Toappear in Computational Linguistics.Klarsfeld, Gaby.phologique de l'anglais.Paris, France.1991.
Dictionnaire mot-Technical Report, LADL,Koskenniemi Kimmo.
1990.
Finite-stateParsing and Disambiguation.
Proceedings of thethirteenth International Conference on Computa-tional Linguistics (COLING'90), Helsinki, Fin-land.Laporte, Eric.
1988.
MJthodes algorithmiqueset lezicales de phon~tisation de teztes.
Ph.D the-sis, Universit4 Paris 7, Paris, France.Mohri, Mehryar.
1993.
Analyse etrepresentation par automates de structures syntaz-iques eompos~es.
Ph.D thesis, Universit4 Paris 7,Paris, France.Mohri, Mehryar.
1994.
Minimization of Se-quential Transducers.
Proceedings of Combinato-rial Pattern Matchnig (CPM'9~), Springer-Verlag,Berlin Heidelberg New York.
Also Submitted toTheoretical Computer Science.Pereira, Fernando C. N. 1991.
Finite-State Approximation of Phrase Structure Gram-mars.
Proceedings of the 29th Annual Meetingof the Association for Computational Linguistics(A CL '91), Berkeley, California.Roche Emmanuel.
1993.
Analyse syntaz-ique translormationnelle dufranfais par transduc-teur et lezique-grammaire.
Ph.D thesis, UniversitdParis 7, Paris, France.208Mehryar MOHRIInstitut Gaspard MongeUniversit4 Marne-la-Val l4e2, Rue de la Butte Verte93166 NOISY-LE-GRAND CEDEXFRANCEPh: 33 (I) 49 32 60 54Fax: 33 (I) 43 04 16 05209
