In: Proceedings of CoNLL-2000 and LLL-2000, pages 145-147, Lisbon, Portugal, 2000.Shallow Parsing as Part-of-Speech Tagging*Mi les  OsborneUniversity of EdinburghDivision of Informatics2 Buccleuch PlaceEdinburgh EH8 9LW , Scotlandosborne@cogsci, ed.
ac.
ukAbst rac tTreating shallow parsing as part-of-speech tag-ging yields results comparable with other, moreelaborate approaches.
Using the CoNLL 2000training and testing material, our best modelhad an accuracy of 94.88%, with an overall FB1score of 91.94%.
The individual FB1 scores forNPs were 92.19%, VPs 92.70% and PPs 96.69%.1 IntroductionShallow parsing has received a reasonableamount of attention in the last few years (forexample (Ramshaw and Marcus, 1995)).
Inthis paper, instead of modifying some existingtechnique, or else proposing an entirely new ap-proach, we decided to build a shallow parser us-ing an off-the-shelf part-of-speech (POS) tagger.We deliberately did not modify the POS tag-ger's internal operation in any way.
Our resultssuggested that achieving reasonable shallow-parsing performance does not in general requireanything more elaborate than a simple POS tag-ger.
However, an error analysis suggested theexistence of a small set of constructs that arenot so easily characterised by finite-state ap-proaches uch as ours.2 The  TaggerWe used Ratnaparkhi's maximum entropy-based POS tagger (Ratnaparkhi, 1996).
Whentagging, the model tries to recover the mostlikely (unobserved) tag sequence, given a se-quence of observed words.For our experiments, we used the binary-onlydistribution of the tagger (Ratnaparkhi, 1996)."
The full version of this paper can be found atht tp: / /www.cogsc i .ed.ac .uk/ 'osborne/shal low.ps3 Conv inc ing  the  Tagger  to  Sha l lowParseThe insight here is that one can view (someof) the differences between tagging and (shal-low) parsing as one of context: shallow pars-ing requires access to a greater part of thesurrounding lexical/POS syntactic environmentthan does simple POS tagging.
This extra in-formation can be encoded in a state.However, one must balance this approachwith the fact that as the amount of informationin a state increases, with limited training ma-terial, the chance of seeing such a state againin the future diminishes.
We therefore wouldexpect performance to increase as we increasedthe amount of information in a state, and thendecrease when overfitting and/or sparse statis-tics become dominate factors.We trained the tagger using 'words' that werevarious 'configurations' (concatenations) of ac-tual words, POS tags, chunk-types, and/or suf-fixes or prefixes of words and/or chunk-types.By training upon these concatenations, wehelpbridge the gap between simple POS tagging andshallow parsing.In the rest of the paper, we refer to what thetagger considers to be a word as a configura-tion.
A configuration will be a concatenation fvarious elements of the training set relevant odecision making regarding chunk assignment.
A'word' will mean a word as found in the train-ing set.
'Tags' refer to the POS tags found inthe training set.
Again, such tags may be partof a configuration.
We refer to what the taggerconsiders as a tag as a prediction.
Predictionswill be chunk labels.4 Exper imentsWe now give details of the experiments we ran.To make matters clearer, consider the following145fragment of the training set:WordPOS TagChunkWl w2 w3t l  t2 t3Cl c2 c3Words  are wl,w2 and w3, tags are t~L,t2 and t3and chunk labels are cl, c2 and ca.
Throughout,we built various configurations when predicting1 the chunk label for word wl.With respect o the situation just mentioned(predicting the label for word wl), we gradu-ally increased the amount of information i  eachconfiguration as follows:1.
A configuration consisting of just words(word wl).
Results:Chunk typeOverallADJPADVPCONJPINTJLSTNPPPPRTSBARVPP88.0667.5774.3454.55100.000.0087.8494.8071.0082.3086.68R88.7151.3774.2566.6750.000.0089.4195.9166.9872.1588.15FB188.3858.3774.296O.0066.670.0088.6295.3568.9376.8987.41Overall accuracy: 92.76%2.
A configuration consisting of just tags (tagt l ) .
Resul ts :Chunk typeOverallADJPADVPCONJPINTJLSTNPPPPRTSBARVPP R FB188.15 88.07 88.1167.99 54.79 60.6871.61 70.79 71.2035.71 55.56 43.480.00 0.00 0.000.00 0.00 0.0089.47 89.57 89.5287.70 95.28 91.3352.27 21.70 30.6783.92 31.21 45.5090.38 91.18 \[ 90.78Overall accuracy 92.66%.3.
Both words, tags and the current chunklabel (wl, tl, Cl) in a configuration.
Weallowed the tagger access to the currentchunk label by training another model with1For space reasons, we had to remove many of theseexperiments.
The longer version of the paper gives rele-vant details.configurations consisting of tags and words(wl and tl).
The training set was then re-duced to consist of just tag-word configura-tions and tagged using this model.
After-wards, we collected the predictions for usein the second model.
Results:Chunk typeOverallADJPADVPCONJPINTJLSTNPPPPRTSBARVPP89.7969.6174.7254.5550.000.0089.8095.1571.8485.6389.54R90.7057.5377.1466.6750.000.0091.1296.2669.8180.1991.31FB190.2463.0075.9160.0050.000.0090.495.7070.8182.8290.41.Overall accuracy: 93.79%The final configuration made an attemptto take deal with sparse statistics.
It con-sisted of the current ag tl, the next tag t2,the current chunk label cl, the last two let-ters of the next chunk label c2, the first twoletters of the current word wl and the lastfour letters of the current word wl.
Thisconfiguration was the result of numerousexperiments and gave the best overall per-formance.
The results can be found in Ta-ble 1.We remark upon our experiments in the com-ments section.5 Er ror  Ana lys i sWe examined the performance of our finalmodel with respect o the testing material andfound that errors made by our shallow parsercould be grouped into three categories: diffi-cult syntactic onstructs, mistakes made in thetraining or testing material by the annotators,and errors peculiar to our approach.
2Taking each category of the three in turn,problematic constructs included: co-ordination,punctuation, treating ditransitive VPs as beingtransitive VPs, confusions regarding adjectiveor adverbial phrases, and copulars een as be-ing possessives.2The raw results can be found at: http://www.cogsci.ed.ac.uk/-osborne/conll00-results.txt The mis-anal-ysed sentences can be found at: http://www.cogsci.ed.ac.uk/-osborne/conll00-results.txt.146Mistakes (noise) in the training and testingmaterial were mainly POS tagging errors.
Anadditional source of errors were odd annotationdecisions.The final source of errors were peculiar to oursystem.
Exponential distributions (as used byour tagger) assign a non-zero probability to allpossible vents.
This means that the tagger willat times assign chunk labels that are illegal, forexample assigning a word the label I-NP whenthe word is not in a NP.
Although these errorswere infrequent, eliminating them would require'opening-up' the tagger and rejecting illegal hy-pothesised chunk labels from consideration.6 CommentsAs was argued in the introduction, increasingthe size of the context produces better esults,and such performance is bounded by issues uchas sparse statistics.
Our experiments suggestthat this was indeed true.We make no claims about the generality ofour modelling.
Clearly it is specific to the taggerused.In more detail, we found that:?
PPs seem easy to identify.?
ADJP and ADVP chunks were hard toidentify correctly.
We suspect that im-provements here require greater syntacticinformation than just base-phrases.?
Our performance at NPs should beimproved-upon.
In terms of modelling, wedid not treat any chunk differently fromany other chunk.
We also did not treat anywords differently from any other words.?
The performance using just words and justPOS tags were roughly equivalent.
How-ever, the performance using both sourceswas better than when using either sourceof information in isolation.
The reason forthis is that words and POS tags have differ-ent properties, and that together, the speci-ficity of words can overcome the coarsenessof tags, whilst the abundance of tags candeal with the sparseness of words.Our results were not wildly worse than thosereported by Buchholz et al(Sabine Buchholzand Daelemans, 1999).
This comparable vel ofperformance suggests that shallow parsing (basetest dataADJPADVPCONJPINT JLSTNPPPPRTSBARVPprecision72.42%75.94%50.00%100.00%0.00%91.92%95.95%73.33%86.40%92.13%recall64.16%79.10%55.56%50.00%0.00%92.45%97.44%72.64%80.75%93.28%all 91.65% 92.23%F fl=l68.0477.4952.6366.670.0092.1996.6972.9983.4892.7091.94Table 1: The results for configuration 4.
Overallaccuracy: 94.88%phrasal recognition) is a fairly easy task.
Im-provements might come from better modelling,dealing with illegal chunk sequences, allowingmultiple chunks with confidence intervals, sys-tem combination etc, but we feel that such im-provements will be small.
Given this, we believethat base-phrasal chunking is close to being asolved problem.AcknowledgementsWe would like to thank Erik Tjong Kim Sangfor supplying the evaluation code, and DonnlaNic Gearailt for dictating over the telephone,and from the top-of-her-head, a Perl programto help extract wrongly labelled sentences fromthe results.Re ferencesClaire Cardie and David Pierce.
1998.
Error-DrivenPruning of Treebank Grammars for Base NounPhrase Identification.
In Proceedings o/the 17 thInternational Conference on Computational Lin-guistics, pages 218-224.Lance A. Ramshaw and Mitchell P. Marcus.1995.
Text Chunking Using Transformation-Based Learning.
In Proceedings of the 3 rd ACLWorkshop on Very Large Corpora, pages 82-94,June.Adwait Ratnaparkhi.
1996.
A Maximum En-tropy Part-Of-Speech Tagger.
In Proceed-ings of Empirical Methods in Natural Lan-guage, University of Pennsylvania, May.
Tagger:ftp ://ftp.
cis.
upenn, edu/pub/adwait / j mx.Jorn Veenstra Sabine Buchholz and Walter Daele-mans.
1999.
Cascaded Grammatical Relation As-signment.
In Proceedings of EMNLP/VLC-99.Association for Computational Linguistics.147
