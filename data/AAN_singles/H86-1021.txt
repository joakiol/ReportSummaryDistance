GUMS 1 : A General User Modeling SystemTim FininComputer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PADavid OragerAdty CorporationConcord, MAAbstractThis paper describes a general architecture of a domain independentsystem for building and maintaining ling term models of individualusers..The user modeling system is intended Io provide a welldefined set of services for an application system which is interactingwith various users and has a need to build and maintain models ofthem.
As the application system interacts with a user, it can acquireknowledge of him and pass that knowledge on 1o the user modelmaintenance system for incorporation.
We describe a prototypegeneral user modeling system (hereafter called GUMSI) which wehave implemented in Prolog.
This system satisfies some of'the "desirable characteristics we discuss.In l roduct ion - The Need for User Model ingSystems which attempt to interact with people in an intelligent andcooperative manner need to know many things about the individualswith whom they are interacting.
Such knowledge can be of severaldilferent varieties and can be represented and used in a number ofdifferent ways.
Taken collectively, the information that a.system hasof its users is typically refered to as its user model.
This is so evenwhen it is distributed through out many components of the system.Examples that we have been involved with include systems whichattempt to provide help and advice \[4, 5, 15\], tutorial systems \[14\],and natural language interlaces \[16\].
Each el these systems has aneed to represent information about individual users.
Most el theinformation is acquired incrementaly through direct observationand/or interaction.
These systems also needed to infer additionalfacts about their users based on the directly acquired informalion.For example, the WIZARD help system \[4, 15\] had to representwhich VMS operating system objects (e.g.
commands, commandqualifiers, concepts, etc) a user was familiar with and to infer whichother objects he was likely to be familiar with.We are evolving the e design of a general user model maintenancesystem which would support the modeling needs of the projectsmentioned above.
The set of services which we envision the modelmaintenance system pedorming includes:?
maintaining a data base of observed facts about theuser.?
infering additional true facts about the user based on theobserved facts.?
infering additional facts which are likely to be true basedon default facts and default roles.?
informing the application system when certain facts canbe infered to be true or assumed true.?
maintaining the consistency of the model by retractingdefault information when it is not consistent with theobserved facts.providing a mechanism for building hierarchies ofstereotypes which can form initial, partial user models.?
recognizing when a set of observed lacts about a user isno longer consistent with a given stereotype andsuggesting alternative stereotypes which are consistent.This paper describes a general amhitectura for a domainindependent system for building and maintaining long term models ofindividual users.
The user mocleling system is intended to provide awell delined set of services for an app/ication system which isinteracting with various users and has a need to build and maintainmodels of Ihenr~ As Ihe application system interacts with a user, itcan acquire knowledge of him and pass that knowledge on to theuser model maintenance system for incorporation.
We describe aprototype genera/user modeling system (hereafter called GUMS1)which we have implemented in Prelog.
This system satisfies someel lhe desirable characteristics we discuss.What is a User Model?The concept of encorporating user models into interactive systemshas become common, but what has been meant by a user modelhas varied and is not always clear.
In trying to specify what is beingrefered to as a user model, one has to answer a number ofquestions: who is being modeled; what aspects of the user are beingmodeled; how is the model to be in'rtially acquired; how will it bemaintained; and how will it be used.
In this section we will attempt tocharacterize our own approach by answering these questions.Who is being modeled?The primary distinctions here are whether one is modeling individualusers or a class of users and whether one is attempting to constructa short or long term model.
We are interested in the aquisition anduse of lonq ter m models of individual users.
We want to representthe knowledge and beliefs of Individuals end to do so In a way thatresults in a persistent record which can grow and change asneccessary.It will be neccessary, of course,to represent generic facts which aretrue of large classes (even all) of users.
In particular, such facts mayinclude inference rules which relate a person's belief, knowledge orunderstanding of one thing to his belief, knowledge andunderstanding of others.
For example In the context of a timesharedcomputer system we may want to include a rule like:ff a user U believes that machine M is running,then U will believe that it is possible for him to logonto M.It is just this sort of rule which is required in order to support thekinds el cooperative interactions studied in \[6\] and \[7\], such as thefollowing:224User: Xs UPZI~-LXNC up?System:  Ces, but .
you  aen ' t  1o9' on now.P~eventatlve maintenance is beingdone until ll:OOam.What is to be mode led?Our current work is focused on building a general purpose, domainindependent model maintenance system.
Exactly whet informationis to be modeled is up to the application.
For example, a naturallanguage system may need to know what language terms a user islikely to be familiar with \[16\], a CAI system for second languageteaming may need to model a user's knowledge of grammatical mias\[14\], an intelligent database query system may want to model whichfields ot a data base reialion a user is Interested in \[10\], and anexpert system may need to model a user's domain goals \[11)..How is the model  to be aqui red and mainta ined?We are exploring a system in which an initial model of the user willbe selected from a set of stereotypical user models \[13\].
Selectingthe most appropriate stereotype from the set can be accomplishedby a number of techniques, from letting the user select one tosurveying the user and having an expert system select one.
Oncean initial model has been selected, it will be updated and maintainedas direct knowledge about the user Is aquired from the interaction.Since the use of stereotypical user models is a kind of defaultreason/ng\[12\], we will use truth maintenance techniques\[9) formaintaining a consistent model.In padicular, if we learn something which contradicts a tact in the ourcurrent model of the user than we need to update the model.Updating the model may lead to an Inconsistency which must besquared away.
If the mode!
can he made consistent by changing anyof the default facts In the model, then this should be done.
If there isa choice of which defaults to alter, then a mechanism must beprovided to do this (e.g.
through further dialogue with.the user).
Ifthere are no defaults which can be altered to make the modelconsistent then the stereotype must be abandoned and a new onesought.How Is the model  to be used?The model can be accessed in two primary ways: facts can beadded, deleted or updated from the model and facts can be lookedup or inlerad.
A forward chaining component together with a truthmaintenance system can be used to update the default assumptionsand keep the model consistent.Architectures for User Modeling SystemsOur goal Is to provide a general user modeling utility organized alongthe lines shown in figures 1 and 2.
The user modeling systemprovides a service to an application program which interacts directlywith a. user.
This application program gathers Information about theuser through this interaction and chosas to store some of thisinformation in the user model.
Thus, one service the user modelprovides is accepting (and storiogl) new Information about the user.This Information may trigger an Inferential process which could havea number of outcomes:?
The user modeling system may detect an Inconsistencyand so Intorm the applioation.?
The user model may infer a new fact about the userwhich Idggers a demon causing some action (e.g.informing the application).G-u,,k~A: an ApplicationGUMS: General User Modeling SystemGUMS(A): Modeling System for Application AGUMS(A,U): Model lor User U in Application AFigure 1: A General Architecture for a User Modeling UtilityU3 ?
S1$2 S3 $4A A 1$5 $6 U2 $7 $8IU1NULL: the Empty StereotypeSt: Stereotype iUI: User IFigure 2: A User Modeling System for an Application225?
The user model may need to update soma previouslyInfered default Information about the userAnother kind of service the user model must provide is answedngqueries posed by the application.
The application may need to lookup or deduce certain Information about its current user.We are currently experimenting with some of these ideas in a systemcalled GUMSp This system is implemented In proiog and used asimple default logic together with a backward chaining Interpreterrather than a truth maintenance system and a forward chainingengine.
The next section describes GUMS t and its use of defaultlogic.Defau l t  Log ic  and  User  Mode l ingA user model is most useful in a situation where the application doesnot have complete Information about the knowledge and beliefs of itsusers.
This leaves us with the problem of how to model a user givenwe have only a limited amount ol knowledge about him.
Ourapproach involves using several forms of default reasoningtechniques: stereotypes, explicit default rules, and failure asnegation.We assume that the GUMS 1 system will be used In an applicationwhich incrementaly gains new knowledge about its users throughoutthe interaction.
But the mere ability to gain new knowledge about theuser is not enough.
We can not waif until we have full knowledgeabout a user to reason about him.
Fortunately we can very oftenmake generalization about users or classes of users.
We call a sucha generalization a stereotype.
A slereotype consists of a set of factsand rules that are believed to applied to a class of users.
Thus astereotype gives us a form of default reasoning.Stereotypes can be organized in hierarchies in which one stereotypesubsumes another if it can be thought to be mare general.
Astereotype S t is said to be mere general than a stereotype S 2 iteveq~,thlng which is true about S t is necoessarily true about S 2.Looking at this from another vantage point, a stereotype inherits allthe facts and rules from every stereotype that it is subsumed by.
Forexample, in the context of a programmer's apprentice application, wemight have stereotypes corresponding to different classes ofprogrammer, as is suggested by the the hierarchy In figure 2.In general, we will want a stereotype to have any number ofImmediate ancestors, allowing us to compose a new stereotype outof several existing ones.
In the cmntext of a programmersapprentice, gor example, we may wish to describe a particular useras a SymbolicsWizard and a UnixNovice and a ScribeUser.
Thus,the stereotype system should form a general lattice.
Our currentsystem constrains the system to a tree.Within a stereotype we can have default Information as well.
Forinstance, we can be sure that a programmer will know what a file is,but we can only guess that a programmer will know what a filedirectoq, is.
If we have categorized a given user under theprogrammer stereotype and discover 1that he is not familiar with theconcept of a file then we can conctudethat we had improperly chosena stereotype and most choose a new one.
But if we got theinformation that he did not know what a file directory was, this wouldnot rule out the possibility of him being a programmer?
Thus GUMS 11perhaps tlwough direct Interac6on with herP EOgEz~wI  E/\.../Progr-~4 -,gWizard!
\/ \LispMachineWizard UnixHackerl \ I\/ \ .
.
.
.
.
.Sy~olicsWizard XeroxWi=ardFigure 3: A Hierachy of Stereotypesallows rules and facts within a stereotype to be either definitely trueor true by default (i.e.
in the absence ol information to the contrary.
)In GUMS t we use the certain/1 predicate to introduce a definite factor rule and the default/1 predicate to indicate a default fact or rule,as in:certain(P).certain(P il Q).a definite fact: P is true.a definite rule: P is true if Q isdefinitely true and P is assumed to betrue if Q is only assumed to be true.default(P), a default fact: P is assumed to be trueunless it is known to be lalse.default(P if Q).
a default rule: P is assumed to be trueif Q is true or assumed to be true andthere is no definite evidence to thecontrary.As an example, consider a situation in which we need to model apersons familiarity with cedain terms.
This is a common situation insystems which need to produce text as explanations or In responseto queries and in which there is a wide varialion in the users'famiflarity with the domain.
We might use the following rules(a) defauit(understandsTerm(ram)).
(b) delauif(understandsTerm(rom)if understandsTerm(ram)).
(c) cedain(understandsTerm(pc)if u nderetandsTerm(ibmpc)).
(d) certain(~understandsTerm(cpu)).to represent these assertions, all of which are considered aspertaining to a particular user with respect to the stereotypecontaining the rules:(a) Assume the user understands the term ram unless weknow othePNise.
(b) Assume the user understands the term rein if we knowor believe he understands the term ram unless weknow otherwise.
(c) This user understands the term pc if he understandsthe term ibmpc.
(d) This user does understand the term cpu.GUMS I also treats negation as failure in some cases as a defaultrule.
In general, logic is interpreted using an open wodd assumption.That is, the failure to be able to prove a proposition is not taken asevidence that it is not tree.
Many logic programming languages, sucha prolog, encourage the interpretation of unprovability as logicalnegation.
Two approaches have been forwarded to justify the226negation as failure rule.
One approach IS the closed worldassumption \[2\].
In tide case we assume that anything not inferablefrom the database is by necessity laise.
One problem with thisassumption is that this IS a mataisvat assumption and we do notknow what the equlvatent obJecl level assumptions are.
A secondapproach originated by Clark is based upon the conce~ of acompleted database \[I\].
A completed database is the databaseconstmctad by rewdtlng the set of clauses deflnlng each predicate toan If and only If dalinltion that Is called the completion of thepredicate.
The purpose of the completed delinition is to Indicate thatthe clauses that define a prodioato define OVOry possible instance ofthat Wedioate.Any approach to negation as failure requires that a negated goal beground before execution, (actually a sfightly less restrictive rule couldagow a partially instanfiated negated goal to run but would producethe wrong answer if any vadable was bound.)
Thus we must havesome way of Insuring that every negated literal will be bound.
InGUMS I we have used a simple vadabla typing scheme to achievethis, as will be discussed later.We have used a vadant of the completed database approach toshow that a predicate within the scope of a negation is closed.
Apredicate is dosed if and only if if is defined by an ill statement andeveP/other predicate in the definition of this predicate IS closed.
Weallow a metaievel statement completed(P) that IS used to signify thatby predicate P we really Intend the iff definition associated withP.
This same technique was used by Kowaiskl\[8\] to indicatecernplation.
By default we believe competed(P) where not indicated.So if P IS not explioltly closed not P IS decided by default.Thus In GUMS I we have the abiflty to express that a default shouldbe taken from the lack of certain information (i.e.
negation as failure)as well as from the presence of certain information (i.e.
defaultrules).
For example, we can have a default cuts for the programmerstereotype that can conclude knowledge about linkers fromknowledge about compilers, as in:default  (knows (linkers) if knows (compilers))We can also have a rule that will take the lack of knowledge aboutcompilers as an indication that the user probably knows aboutinterpreters, as in:cer ta in  (knows (interpreters)if - knOWS (compilers))This system also allows explicit negative facts and default facts.When negation is proved in reference to a negative fact thennegation is not censldered a default case.
Slmilady negation asfailure IS not considered a default when the predicate being negatedIS closed.
Such dlstinstions are possPate because the GUMSfInterpreter Is based on a four value logic.The distinction between truth or falsity by default (i.e.
assumption)and truth or falsity by logical Implication IS an Impodanf one to thissystem.
The central predicate of the system is the two aroumenfpredicate show which relates a goal G expressed as a literal to atruth value.
Thus show(GoaI,Val) returns in the vadable Va/thecurrent beifef In the literal Goal The variable Valcan be Instantlatedto true, false, assume(true), or ansume(fatse).
The meanings ofthese values are as follows:true definitely tree aocording to the currentdatabase.assume(true) true by assumption (i.e.
tree by default)aseume(fatse) false by assumptionfalse ?lefinltely not INs.These values represent truth values for a given user with respect toa given stereotype.
If the stereotype Is net appropriate, then evendefine values may have to change.Having a four value logic allows us to distinguish conclusions madefrom purely iogicat information from those dependent on defaultInformation.
Four value logic also allows a simple type ofintmspeclive reasoning that may be useful for modeling the beifels o!Ihe user.
We currently use a default role to represent an uncertai.belief about what the user knows or believes, but we could imagine asituation where we would like to model uncertainties that Ihe userhas in his beliefs or knowledge.
One such predicate is an embededshow predicate.
For example we might have a rule that a user willuse a operating system command that he believe might erase a fileonly if he is certain that he knows how to 0se that command.
Thismight encode as:cart ain (okay to use (Co~nand) ifcan erase f i les (Co--and),sh~w tkno~(Command) , true) ) .Another pmdioate assumed(PrecO will evaluate the troth of Pred and"strengthen" the result.
That isdemo(assumed(P),V)  :-demo (P, V2),strengthen (V2, V) .where the strengthen relation maps assumed values into definitevalues (e.g.
assume(true) becomes true, assume(false) becomesfalse and true and false remain unchanged).
The assumedpredicate Is used to express a cedain belief from an uncertainknowledge or belief.
For example we might want to express a rolethat a user will always want to use a screen editor if he believes onemay be available.certa in (willUse ( screenEdi tor  ) ifassumed(avai lab le  (screenEdltor)) ) .The interpreter that GUMSf is .base on is a metalevel interpreterwdtten in Prolog.
The interpreter must generate and compare manypossible answers to each subquery, because of the multiple valuelogic and the presence of explicit negative information.
Slronoanswers to a query (i.e.
true and false) are sought first, followed byweak answers (i.e.
assume(true) and assume(faLse)).
Becausestrong answers have precedence over weak ones, it is not necessaryto r4move weak information that contradicts strong information.Another feature of this system is that we can specify the types ofarguments to predicates.
This type information can be used to allowthe system to handle non-ground goals.
In our system, a typeprovides a way to enumerate a complete set of possible valuessubsumed by that type.
When the top-level show predicate is givena partially instantlated goat to solve, it uses the type information togenerate a stream of consistent fully instantiated goals.
Theseground goals are tried sequentially.That goals must be fully intantlated follows from the fact thatnegation as failure is built Into the evaluation algorithm.
Complexterms wifl be instantiated to every pattern allowed by the datatypegiven the full power of unification.
To specify the type information,one should specify argument types tot a predicate, subtypeInformation and type instance information.
For example, the followingsays that the ?anProgmm predicate ranges over instances of thetype person and progmmmlngLanguage, that the typefuncttormlLanguage is a sub-type of programmlngLanguage and227that the value scheme is an instance of thefunctlonalLanguage:declare (eanProgram(person,programmingLanguage) ) .?
subtype (progr Jm4ngLanguag~,funct ionalLanguage} .inst (functionalLanguage, scheme} .typeLimitations of the Present SystemOUr current system has several limitations.
One problem is thai itdoes not extract all of the available information Item a now factleamed of the user.
If we assert thai a predicate is closed, we aresaying that the set o!
(cedain) rules for the predicate form adetinilion, i.e.
a neccessary and sufficient description.
In our currentsystem, however, the information still only liows direction1 Forexample, suppose that we would like to encode the rule that a userknows about YO redirection if and only of they know about files andabout pipes.
Further, let's suppose that the default is that a personin this stereotype does not know about files or pipes.
This can beexpresses as:certain (knows (io redirection} ifknows (pipes),knows (files}) .default  (~knows (pipes}) .default  l-knows (files))c losed {knows (io redirection} ) .It we learn that a particular user doe_._._..s know about I /0 redirectionthen it should follow that she neocessarily knows about i:3oth files andpipes.
Adding the assertioncerta in (knows (io redirection) }however, will make no additional changes in the data base.
Thevalues of knows(pipes) and knows(files) will not changel A samplerun alter this change might be :?- show fknows (io redlrection) ,Val) .Val  = true?- show (knows (pipes}, Val) .Val  = assume( fa l se )?- show (knows (files}, Val} .Val  = assume( fa l se ) .The reason for this problem is that the current interpreter wasdesigned to be able to Incorporate new information without actuallyusing a full truth maintenance system.
Before a fact F with truthvalue V Is to be added to the data base, GUMSf checks to see If aninconsistent ruth value V'can be derived for F. If one can be, then anew stereotype is sought In which the contradiction goes away.
Newknowledge that does not force an obvious inconsistency within thedatabase is added as is.
Neither redundant information or existingdefault information effect the correctness of the Interpreter.
Subtlerinconsistencies are possible, of course.Another limitation of the current system its inefficiency.
The use ofdefault rules requires us to continue to search for solutions for a goaluntil a strong one is found or all solutions have been checked.
Thesetwo limitations may be addressable by redesigning the system to bebased on a forward chaining truth maintenance system.
Thequestion is whether the relative elfioiency of forward chaining willoffset the relative Inefficiency el truth maintenance, "lT'~e use of anassumption based truth maintenance system\[3\] Is anotheralternative that we will Investigate.The GUMS 1 Command LanguageOur current experimental implementation provides the followingcommands to the application.show(Query,Vat) succeeds with Valas the strongest truth value Iorthe gaol Query.
A Query is a partially or tully instantiated positive ornegative literal.
Val is return and is the value the current belief state?I1 Queryis partially instantiated then it will return more answers uponbacklracking il possible.
In general one answer will be provided forevery legal ground substitution that agrees with current typedeclarations.add(Fact,Status) sets belief In Fact to true.
It Fact or any legalInstance of it contradicts the current belief state then the user modeladopts successively higher stereotypes in the hieramhy until one isfound in which all el the added facts are consistent.
II no stereotypeis successful then no stereotype Is used, all answers will be basedentirely on added facts.
Fact must be partially or fully instantiatedand can be either a positive or negative literal.
Status must beuninstantiated and will be bound to a message describing the resultof the addition (e.g.
one of several error messages, ok, the name ofa new stereotype, etc.
).create_user(UserName,Stereotype,File,Status) stores the currentuser it necessary and creates a new user who then is the currentuser.
UserName is instantiated to the desired name.
Stereotype isthe logical name of the stereotype that the system should assume tohold.
File is the name of the file that information pertaining to theuser will be stored.
Status is instantiated by the system and returnserror messages.
A user must be created in order for the system to heable to answer queries.store_current(Status) stores the current users information andclears the workspace for a new user.
Status is instantiated by thesystem on an error.restoreuser(User,Status) restores a previous user alter saving thecurrent user if necessary.
User is the name of the user.
Status isinstantiated by the system to pass error messages.done stores the system state of the user modeling system, savingthe current user if necessary.
This command should be the lastcommand issued and needs to be issued at the end of everysession.ConclusionsMany Interactive systems have a strong need to maintain models ofindividual users.
We have presented a simple architecture for ageneral user modeling utility which is based on the ideas of a defaultlogic.
This approach provides a simple system which can maintain adatabase of known information about users as well as use rules andfacts which am associated with a stereotype which is believed to beappropriate for this user.
The stereotype can contain definite factsand define rules of inference as well as default information and rules.The rules can be used to derive new information, both definite andassumed, from the currently believed information about the user.228We believe that this Idnd of system will prove useful to a wide rangeof applications.
We have Implemented an initial version in Prologand are planning to use it to support the modeling needs of se~,eral ?pmjecls.
We are also exploring a more powedul approach to usermodeling based on the notion of a truth maintenance systen~Bibliography1.
Clark, Keith L. Negation as Failure.
In Logic and Databases,J.
Minker and H. Gailaire, Ed., Plenum Press, New York, 1978.2.
Reiter, R. C~sed Wodd Databases.
In Logic and Databases,H.
Gallaire & J. Minker, Ed., Plenum Press, 1978, pp.
149-177.3.
DeKleer, J.
An Assumption Based Truth Maintenance System,Proceedings of IJCAI-85, UCAI, August, 1985.4.
Finin, T.W.
Help and Advice in Task Oriented Systems.
Proc.71h Int'l.
Joint Conf.
on Art.
Intelligence.
UCAI, August, 1982.5.
Howe, A. and T. Finin.
Using Spreading Activation to IdentifyRelevant Help.
Proceeding of the 1984 Canadian Society lotComputational Studies of Intelligence, CSCSI, 1984. also availableas Technical Report MS-CLS-34-01, Computer and InformationScience, U. of Pennsylvania.6.
Joshi, A., Webber, B.
& Welschedel, R. Preventing FalseInferences.
Proceedings of COLING-84, Stanford CA, July, 1984.7.
Joshi, A., Webber, B.
& Welschedal, R. Living Up toExpectations: Computing Expert Responses.
Proceedings ofAAAI-84, Austin "IX, August, 1984.8.
Kowalsld, Robert.
Logic for Problem So/v/ng.
North-Hogand,New York, 1979.9.
McDermott, D and J. Doyle.
"Non-Monotonic Logic I'.
ArtificialIntelligence 13, 1-2 (1980), 41 - 72.10.
Motto, A. Query Generaifzatlon: A Method for interpreting NullAnswers.
In Larry Kerschberg, Ed., Expert Database Systems, ?8enjandn/Cummings, Menlo Park CA, 1985.11.
Pollack, M. Information Sought and Information Provided.Proceedings of CHr85, Assoc.
for Computing Machinery (ACM), SanFrencisco CA, April, 1985, pp.
155-160.12.
Reiter, Ray.
"A Logic for Default Reasoning'.
ArtificialIntelligence 13, 1 (1980), 81-132.13.
Rich, Elaine.
"User Modeling via Stereotypes'.
CognitiveScience 3 (1979), 329-354.14.
Schuster, E. and T. FINn.
VP2: The Role of User Modelling inCorrecting Errors in Second language Learning.
Prec.
Conferenceon ~l~ficisl Intelligence and the Slmuiatinn of Behavior, AISB, 1985.15.
Shrager, J. and T. Finin.
An Expert System that VolunteersAdvice.
Prec.
Second Annual National Conference In Arti(?ialIntelligence, AAAI, August, 1982.16.
Webber, B. and T. FInin.
in Response: Next Steps In NaturalLanguage Interaction.
In Artificial Intelligence Applications forBusiness, W. Reitman, Ed., Ablex Publ.
Co., Norwood NJ, 1984.Appendix - The Dame PredicateThis appendix defines the derno predicate which Implements theheart of the GUMS!
Interpreter.
The rata|ionshow (Goa l ,  Va lue)holds If the truth value of proposition Goalcan be shown to be Valuefor a particular ground instance of GoaL The show predicate firstmakes sure that Goal Is a ground instance via a call to the blndVarspredicate and then invokes the meta-evaluator demo.
The relationdame (Goa l ,  Va lue ,  Leve l )requires that Goal be a fully instantiated term and Level be aninteger that represents the level of recursion within the demopredicate.
The relation holds if the "strongest" troth value for Goalls, Value.
: -  op(gso, fy, ?- '  ) .z- op(1150, x fy , '  I f ' )  ?ahow(P,V) z- b~ndVa~stP), domo(LP,V, 0).% t ruth  va luesdemotP,P,  } :- t ru thVa lue(P) ,  !
?t re f lect ion .
.
.demo(demo (P,Vl) ,V, D) :-I,nonvar  (V1),dame (P,VI, D) -> V- t rue ;V- fa l se .% d is junct ion  .
..demottP ;Q},v ,n )  :- |,demo (P,VI, D) ,demo (Q,V2, D) ,upperbound (Vl, V2, V) .% con junct ion  ...de~t~P,O) ,V ,D)  ~- \[,dame (P,V1, D),demo (O,V2, D),I owerbound (V1, V2, v) .?
negat lon  ...demot-p,V,D) : -  | ,d~mo (P,VI, D),negate  (V1,V, P) .% assumpt ion  ...demo(assu~d(P) ,V ,D)  :- i,dame (P,VI, D),st rang|hen  iV1, V) .% oa l l  darnel w i th  deeper  depth  and then cut.dame (P, V, Depth) :-Deeper  Is Depth+l ,darnel (P, V, Deeper )  ,re t ra?ta l l  (tamp ( , Deeper)  ) ,I.% def in i te  facts .
.
.demol(P,  true, ) :- cer ta ln (P) .darnel (P,falseT_) :- cer ta in  (~P} .?
f ind  a de f in i te  ru le  that  y ie lds  TRUE or  FALSE.darnel (P,V,D) :-fo rsome (certa ln (P if  Q) , (demo (Q,V, D), demoNote  (V, D) ) ) .darnel (P,V, D) : -fo r lometcer ta~n( -P  if  O),(dame (Q, Vl, D),negate  (Vl, V, P)demo~ote  iV, D) ) ) .?
s top if  the  bQst  so far  was  ASSUME(TRUE) .darnel (P ,assume (true}, D) :-re t ra?t  (tamp (assume (true), D) ) .% defau l t  pos i t ive  faots.demotP,  assumettrue)  , ) :- de fau l t  (P) .?
t ry  de fau l t  ru les  "t l l  one  g ives  a pos i t ive  va lue.darnel (P, assume (true), D) :-fo rsome (default  (P i f  Q) , tdemo (Q,V# D), pos i t ive  (V)) } .% defau l t  negat ive  facts.de~o(P ,assumet fa l se ) , _ )  :- de fau l t ( -P ) .% defau l t  negat ive  rules.229demol  (P,assume (false),D) :-forsome(default(~P i f  Q) , (demo(Q,V ,D) ,pos i t l ve (V) ) ) .% if P is closed, then its false.demol (P , fa l se , )  :- closed(P),l .% the default answer.demol(P,assume(false),_).% demoNote(X,D) succeeds if X is TRUE or FALSE,otherwise it fails after updating temp(A, )to be the strongest value known so far.
--demoNote(V, ) : -  known(V).de.~Note(V ,D)  : -not l tompl ,D l ) ,assert(ten~(V,D)),fail.demoNote(assume(truo),D} :-rotract(temp(_,D)),!,assert(temp(assume(true),D)),fa i l .% Relations on Truth Valuesposit ive (X) :- X -- true ; X -- assume(true).known(X) :- X -- true ; X -- false.hlgher(true, )-hlgher(assum~(trUe) oaSsume(false}).higher(_,false).upperbound(X,Y, Z} :- higher(X,Y) -> Z-X ; Z-Y.lowerbound(X, Y,Z) :- hlgher(X,Y) -> Z-Y ; Z-X.strengthen(assume(X)?X}.strengthen(true,true).strengthen(false, false).% negation is relat ive to a predicate.negate(true, false, ) .negate(assume(truey, assume(false), ).neqate(assume(false),assume(true},--).negate(false, true,P) :- closed(P).--negate(false,assume(true),P) :- not (closed(P)).truthValue(nrue).truthValue(false).cruthValue(assume(X)) :- truthValue(X}.% The Type System% isSubtype(TI,T2) iff type T1 has an% ancestor type T2.isSubtype(TI,T2) :- subtype(Ti,T2}.isSub~ype(T1,T2) :-sub~ype(T1,T),IsSubtype(T, T2).% true if instance I is descendant from type T.isInscance(I,T) :- Inst(I,T).isIns~ance(I,T) :-IsSubtype(TI,T),islnstance(I,T1).i true if T is ?
type.isType(T} :- ins t ( ,T ) .isType(T) :- subtype(T, ).isType(T) :- subtype(_,T}.% Grounding Terms% blndVars (P} ensures that all variables% in P are bound or it fails.blndVsrs(P) :- ,ar(P), I , fai l .bindVara(P) : -  atom/c (P)#|.bindVars(P) :-schema(P,PS),p -.. ( iArgs\],PS -.. T JTypes|,bindArgs~Args,Types).blndArgs(\[}#\[\]) .bindArgs(\[ArgiArgs\],  \[Type lTypes\]) :-bindArg(Arg, Type),blndArgs(Args,Types).bindArg(Arg,Type) :-var(Arg),Is lnstance(Arg,Type).blndArg(Arg,_) :- bindVars(Arg).acheme(P,S) is true if S is the schema for P. egachema(glve(John, X,Y),give(person,person,rhing)).% find a declared schema.schema(P,S) :-functor(P,F,N),functor(S,F,N),declare(S),T.use tire default schema F(thlng, thing,...).schonm (P, S) :-functor(P,F,N),fun~tor(S,F,N),for(I,1,N, arg(I,S, thing}),i.230
