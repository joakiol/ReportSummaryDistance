Proceedings of the ACL Interactive Poster and Demonstration Sessions,pages 85?88, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsTwo diverse systems built usinggeneric components for spoken dialogue(Recent Progress on TRIPS)James Allen, George Ferguson, Mary Swift, Amanda Stent, Scott Stoness,Lucian Galescu, Nathan Chambers, Ellen Campana, and Gregory AistUniversity of RochesterComputer Science DepartmentUR Comp Sci RC 270226Rochester NY 14627 USA{james, ferguson, swift, stoness,campana, gaist}@cs.rochester.eduInstitute forHuman and Machine Cognition40 South Alcaniz St.Pensacola FL 32502{lgalescu,nchambers}@ihmc.usState University of New York atStony Brook1418 Computer ScienceStony Brook UniversityStony Brook NY 11794 USAstent@cs.sunysb.eduAbstractThis  paper  describes  recent  progress  on  theTRIPS architecture for developing spoken-lan-guage dialogue systems.
The interactive postersession will include demonstrations of two sys-tems built using TRIPS: a computer purchas-ing assistant, and an object placement (and ma-nipulation) task.1 IntroductionBuilding a robust spoken dialogue system for a newtask currently requires considerable effort,  includ-ing  extensive  data  collection,  grammar  develop-ment, and building a dialogue manager that drivesthe  system using its  "back-end" application (e.g.database query, planning and scheduling).
We de-scribe progress in an effort to build a generic dia-logue system that  can be rapidly customized to awide range of different types of applications, pri-marily  by  defining a  domain-specific  task  modeland the interfaces to the back-end systems.
This isachieved by  using generic  components  (i.e.,  onesthat apply in any practical domain) for all stages ofunderstanding  and developing techniques for rapid-ly customizing the generic components to new do-mains  (e.g.
Aist,  Allen,  and  Galescu  2004).
Toachieve this goal we have made several innovations,including (1) developing domain independent mod-els of  semantic and  contextual  interpretation,  (2)developing generic  dialogue  management  compo-nents based on an abstract  model of collaborativeproblem solving, and (3) extensively using an ontol-ogy-mapping system that connects the domain inde-pendent representations to the representations/querylanguages used by the back-end applications,  andwhich is used to automatically optimize the perfor-mance of the system in the specific domain.2 Theoretical  Underpinnings:  The Prob-lem-Solving Model of DialogueWhile many have observed that communicationis a specialized form of joint action that happens toinvolve language and that dialogue can be viewedas collaborative problem solving, very few imple-mented systems have been explicitly based on theseideas.
Theories of speech act interpretation as inten-tion recognition have been developed  (including ex-tensive  prior  work  in  TRIPS'  predecessor,  theTRAINS project), but have been generally consid-ered impractical for actual systems.
Planning mod-els  have been more successful  on the  generationside, and some systems have used the notion of exe-cuting explicit task models to track and drive the in-teractions  (e.g.,  Sidner  and  Rich's  COLLAGENframework).
But collaborative problem solving, anddialogue in general, is much more general than exe-cuting tasks.
In our applications, in addition to exe-cuting tasks, we see dialogue that is used to definethe task (i.e., collaborative planning), evaluate thetask (e.g., estimating how long it will take,  com-paring options,  or  likely effects),    debug a  task(e.g., identifying and discussing problems and howto remedy them), learn new tasks (e.g., by demon-stration and instruction).85In the remainder of the paper, we'll first discussthe methods we've developed for building dialoguesystems using generic components.
We'll then de-scribe two systems implemented using the TRIPSarchitecture that we will demonstrate at the interac-tive poster session.3 Generic Methods:  Ontology Mappingsand Collaborative Problem SolvingThe goal of our work is to develop generic spokendialogue technology that can be rapidly customizedto new applications, tasks and domains.
To do this,we have developed generic domain independent rep-resentations not only of sentence meaning but alsoof the collaborative actions that are performed bythe speech acts as one engages in dialogue.
Further-more, we need to be able to easily connect thesegeneric representations to a wide range of differentdomain specific task models and applications, rang-ing from data base query systems to state-of-the-artplanning and scheduling systems.
This  paper  de-scribes  the  approach  we  have  developed  in  theTRIPS system.
TRIPS is now being used in a widerange of diverse applications, from interactive plan-ning (e.g., developing evacuation plans), advice giv-ing  (e.g.,  a  medication  advisor  (Ferguson  et  al.2002)),  controlling teams of robots,   collaborativeassistance (e.g., an assistant that can help you pur-chase a computer, as described in this paper), sup-porting human learning, and most recently havingthe computer  learn (or  be  taught)  tasks,  such aslearning to perform tasks on the web.
Even thoughthe tasks and domains differ dramatically, these ap-plications use the same set of core understandingcomponents.The key to supporting such a range of tasks and ap-plications is the use of a general ontology-mappingsystem.
This allows the developer to express a setof mapping rules that translate the generic knowl-edge representation into the specific representationsused by the back-end applications (called the KRrepresentation).
In  order  to  support  generic dis-course processing, we represent these mappings asa chain of simpler transformations.
These represen-tations are thus transformed in several stages.
Thefirst,  using the ontology mapping rules,  maps theLF representation into an intermediary representa-tion (AKRL - the abstract KR language) that has ageneric syntax  but  whose content is  expressed interms of the KR ontology.
The second stage is asyntactic transformation that occurs at the time thatcalls to the back-end applications actually occur sothat  interactions  occur  in  the  representations  theback-end expects.
In  addition to  using ontologymapping to  deal  with the representational  issues,TRIPS is unique in that it uses a generic model ofcollaborative problem solving to drive the dialogueitself  (e.g.
Allen,  Blaylock,  and  Ferguson 2002).This model forms the basis of a generic component(the collaboration manager) that supports both in-tention recognition to identify the intended speechacts and their content, planning the system's actionsto respond to the user (or that take initiative), andproviding utterance realization goals to the genera-tion system.
To develop this, we have been develop-ing  a  generic  ontology  of  collaborative  problemsolving acts, which provide the framework for man-aging  the  dialogue.
The  collaboration  managerqueries a domain-specific task component in orderto  make  decisions  about  interpretations  and  re-sponses.4 TRIPS  Spoken  Dialogue  Interface  tothe CALO Purchasing AssistantThe CALO project is a large multisite effort whichaims  at  building  a  computerized  assistant  thatlearns how to help you with day-to-day tasks.
Theoverarching goal of the CALO project is to... create cognitive software systems, that is,systems that can reason, learn from experi-ence, be told what to do, explain what theyare doing, reflect on their experience, and re-spond robustly to surprise (Mark and Per-rault 2004).Within this broad mandate, one of our current areasof focus is user-system dialogue regarding the taskof purchasing - including eliciting user needs, de-scribing possibilities, and reviewing & finalizing apurchase  decision.
(Not  necessarily  as  discretestages; these elements may be interleaved as appro-priate for the specific item(s) and setting.)
Withinthe purchasing domain,  we began with computerpurchasing and have branched out to other equip-ment such as projectors.How to help with purchasing?
The family of tasksinvolving purchasing items online, regardless of thetype of item, have a  number of elements in com-mon.
The process of purchasing has some common86dialogue elements - reporting on the range of fea-tures  available,  allowing the user  to specify con-straints, and so forth.
Also, regarding the goal thatmust be reached at the end of the task, the eventualitem must:Meet requirements.
The item needs to meet somesort of user expectations.
This could be as arbitraryas a specific part number, or as compositional - andamenable to machine understanding -  as  a  set  ofphysical  dimensions (length,  width,  height,  mass,etc.
)Be approved.
Either the system will have the au-thority to approve it (cf.
Amazon's one-click order-ing system), or more commonly the user will reviewand confirm the purchase.
In an office environmentthe approval process may extend to include reviewby a supervisor, such as might happen with an itemcosting over (say) $1000.Be available.
(At  one time a  certain  electronicsstore in California had the habit of leaving out floormodels of laptops beyond the point where any wereactually available for sale.
(Perhaps to entice theunwitting customer into an ?upsale?, that is, buyinga  similar  but  more  expensive  computer.))
On  amore serious note, computer specifications changerapidly, and so access to online information aboutavailable  computers  (provided  by  other  researchwithin CALO) would be important in order to en-sure that the user can actually order the machine heor she has indicated a preference for.At  the interactive poster  session,  we will demon-strate some of the current spoken dialogue capabili-ty related to the CALO task of purchasing equip-ment.
We will demonstrate a number of the aspectsof the system such as initiating a conversation, dis-cussing specific requirements,  presenting possibleequipment to purchase,  system-initiated remindersto ask for supervisor approval for large purchases,and finalizing a decision to purchase.Figure 1.
Fruit carts display.875 TRIPS  Spoken  Dialogue  Interface  tochoosing,  placing,  painting,  rotating,and filling (virtual) fruit cartsTRIPS is versatile in its applications, as we've saidpreviously.
We hope to also demonstrate an inter-face to  a  system for  using spoken commands tomodifying, manipulating, and placing objects on acomputer-displayed map.
This  system (aka  ?fruitcarts?)
extends  the  TRIPS  architecture  into  therealm of continuous understanding.
That is, whenstate-of-the-art  dialogue systems listen,  they typi-cally wait for the end of the utterance before decid-ing what to do.
People on the other hand do notwait in this way ?
they can act on partial informa-tion as  it  becomes available.
A classic examplecomes  from  M.  Tanenhaus  and  colleagues  atRochester: when presented with several objects ofvarious colors and told to ?click on the yel-?, peoplewill already tend to be looking relatively more at theyellow object(s) even before the word ?yellow?
hasbeen completed.
To achieve this type of interactivi-ty with a dialogue system ?
at least at the level oftwo or three words at a time, if not parts of words ?imposes some interesting challenges.
For example:1.
Information must flow asynchronously betweendialogue components, so that actions can be trig-gered based on partial utterances even while theunderstanding continues2.
There must be reasonable representations of in-complete information ?
not just ?incomplete sen-tence?,  but  specifying what  is  present  alreadyand perhaps what may potentially follow3.
Speech  recognition,  utterance  segmentation,parsing, interpretation, discourse reasoning, andactions must all be able to happen in real timeThe fruit carts system consists of two main compo-nents:  first,  a  graphical  interface implemented onWindows  2000  using  the  .NET  framework,  andconnected to  a  high-quality  eyetracker;  second,  aTRIPS-driven spoken dialogue interface implement-ed primarily in LISP.
The actions in this domainare as follows:1.
Select an object (?take the large plain square?)2.
Move it (?move it to central park?)3.
Rotate  it  (?and then turn  it  left  a  bit  ?
that'sgood?)4.
Paint it (?and that one needs to be purple?)5.
Fill it (?and there's a grapefruit inside it?
)Figure 1 shows an example screenshot from thefruit carts visual display.
The natural language in-teraction  is  designed to  handle  various  ways  ofspeaking,  including conventional  definite  descrip-tions (?move the large square to central park?)
andmore interactive language such as (?up towards theflag pole ?
right a bit ?
more ?
um- stop there.?
)6 ConclusionIn this brief paper,  we have described some ofthe recent progress on the TRIPS platform.
In par-ticular we have focused on two systems developedin TRIPS: a spoken dialogue interface to a mixed-initiative purchasing assistant, and a spoken inter-face for exploring continuous understanding in anobject-placement task.
In  both  cases  the  systemsmake use of reusable components ?
for input andoutput  such as  parsing and speech synthesis,  andalso for dialogue functionality such as mapping be-tween language,  abstract  semantics,  and  specificrepresentations for each domain.ReferencesAist,  G.  2004.
Speech,  gaze,  and  mouse  data  fromchoosing,  placing,  painting,  rotating,  and  filling(virtual) vending carts.
International Committee forCo-ordination  and  Standardisation  of  SpeechDatabases  (COCOSDA)  2004  Workshop,  Jeju  Is-land, Korea, October 4, 2004.Aist, G.S., Allen, J., and Galescu, L. 2004.
Expandingthe linguistic coverage of a spoken dialogue systemby mining human-human dialogue for new sentenceswith familiar meanings.
Member Abstract, 26th An-nual  Meeting  of  the  Cognitive  Science  Society,Chicago, August 5-7, 2004.James Allen, Nate Blaylock, and George Ferguson.
Aproblem-solving model for collaborative agents.
InFirst International Joint Conference on AutonomousAgents and Multiagent Systems, Bologna, Italy, July15-19 2002.George  Ferguson,  James  F.  Allen,  Nate  J.  Blaylock,Donna K. Byron, Nate W. Chambers, Myrsolava O.Dzikovska, Lucian Galescu, Xipeng Shen, Robert S.Swier, and Mary D. Swift.
The Medication AdvisorProject: Preliminary Report, Technical Report 776,Computer  Science  Dept.,  University  of  Rochester,May 2002.Mark,  B.,  and  Perrault,  R.  (principal  investigators).2004.
Website for Cognitive Assistant  that  Learnsand Organizes.
http://www.ai.sri.com/project/CALO88
