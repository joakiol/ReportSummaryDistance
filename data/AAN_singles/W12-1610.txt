Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 79?83,Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational LinguisticsPredicting Adherence to Treatment for Schizophrenia from DialogueTranscriptsChristine Howes, Matthew Purver, Rose McCabe, Patrick G. T. Healey, Mary LavelleQueen Mary University of LondonMile End Road, London E1 4NSc.howes@qmul.ac.ukAbstractRecent work on consultations between out-patients with schizophrenia and psychiatristshas shown that adherence to treatment canbe predicted by patterns of repair ?
specifi-cally, the pro-activity of the patient in check-ing their understanding, i.e.
patient clarifi-cation.
Using machine learning techniques,we investigate whether this tendency can bepredicted from high-level dialogue features,such as backchannels, overlap and each partic-ipant?s proportion of talk.
The results indicatethat these features are not predictive of a pa-tient?s adherence to treatment or satisfactionwith the communication, although they dohave some association with symptoms.
How-ever, all these can be predicted if we allowfeatures at the word level.
These preliminaryexperiments indicate that patient adherence ispredictable from dialogue transcripts, but fur-ther work is necessary to develop a meaning-ful, general and reliable feature set.1 IntroductionHow conversational partners achieve and maintainshared understanding is of crucial importance inthe understanding of dialogue.
One such mecha-nism, other initiated repair (Schegloff, 1992), whereone conversational participant queries or correctsthe talk of another, has been well documented inboth general and task-based dialogues (Colman andHealey, 2011).
However, how such shared under-standing impacts beyond the level of the conversa-tion has not typically been examined.
Exceptions tothis have highlighted the role of shared understand-ing in schizophrenia (McCabe et al, 2002; Themis-tocleous et al, 2009) and the association betweenpsychiatrist-patient communication and adherence.McCabe et al (in preparation) found that more pa-tient clarification (i.e.
other initiated repair) of thepsychiatrist?s talk was associated with better treat-ment adherence six months later.
Clarification con-sists mainly of asking questions to clarify the mean-ing of the psychiatrist?s utterance (checking under-standing) and correcting something that the psychi-atrist has said (getting the facts straight).
Example 1,taken from a consultation, shows the patient request-ing clarification of something the psychiatrist hasjust said about a possible side effect.
(1) Dr: Yep, well that is a possible side effectPat: Side effect?Dr: Of the er haloperidolThe patient?s request leads to additional explana-tion by the psychiatrist about the medication whichcan cause the possible side effect.
More patient clar-ification reflects greater effort to reach a shared un-derstanding.
McCabe et al (in preparation) foundthat for each unit increase in the patient clarificationfactor,1 the odds of good (versus poor) adherencewere increased by 5.8 (95% CI 1.3 to 25.8, p=0.02).Explaining the link between communicative pat-terns of patients and adherence may create the pos-sibility for new interventions to improve adherence,and has both clinical and theoretical implications.1A regression factor weighted heavily towards patient clar-ifcations (as in e.g.
1).79However, there is no evidence regarding what fac-tors influence patient clarification and may explainthe link with adherence.
If patient clarification isa measure of greater communicational effort, or en-gagement, then wemight expect other dialogue mea-sures, such as the amount of acknowledgements orother grounding cues (Traum and Allen, 1992), orthe proportion of talk per person, to be correlatedwith other initiated repair and therefore similarlypredictive of subsequent adherence behaviour.
Thisis of particular importance if we wish to build a sys-tem to automatically predict possible (lack of) ad-herence from dialogue transcripts, especially giventhat the types of patient clarification which carrythe highest weight in the patient clarification factor(next-turn repair initiators, Schegloff, 1992) are rare,occurring on average only 1.2 times per dialogue.Further, although certain types of repair wereshown to affect how patients reported they felt theconversation went, self-reports of symptoms andcommunicational factors are not predictive of adher-ence.
Although micro-communicational behaviour(in the form of other initiated repair) does have abearing on subsequent adherence behaviour, patientsare unaware of this.
Additional questions thereforeconcern whether we can predict patient?s symptomlevels and subjective analyses of the communicationbased only on overview dialogue factors.2 HypothesesFactors which we would expect to index patient en-gagement, and thus be predictive of adherence totreatment are the amount of backchannel responsespatients make, and the proportion of questions pa-tients ask, both of which ought to be higher for themore engaged patients.
We might also expect thatsuch patients have a greater proportion of the talkoverall, and/or longer turns on average, though notethat this conversational pattern might also be one inwhich the patient is not engaged, as they might notbe responding to the feedback from their consultant.For the symptom scores (see below for details),we should expect that patients with high levelsof negative symptoms (which includes loss of af-fect and poverty of speech) would produce lesstalk overall, and in general produce shorter turns.There should also be more noticeable gaps in thedialogues (defined as greater than approximately200ms, (Heldner and Edlund, 2010)).
Contrarily,for positive symptoms, (including hallucinations anddelusions) patients ought to produce longer turnsand have a greater proportion of the talk.We also expect to see effects on how patients feltthe conversation went from the amount of overlap,though as overlap can be both intended and inter-preted as either interruptive or collaborative (as withe.g.
overlapping backchannels) it is unclear whichdirection such a prediction should take.3 Method131 dialogues from outpatient consultations be-tween patients and psychiatrists were analysed ac-cording to a number of factors.
Each of these fac-tors, detailed in table 1, below, is calculated for eachdialogue participant (with the exception of pauses).Each patient featured in only one of the dialogueshowever, there were only 29 doctors in the study,so the same clinician may have featured in severalof the dialogues with different patients.
The con-sultations varied in length, with the shortest con-sisting of 61 turns (438 words) and the longest881 turns (13178 words), with an average of 320.5turns (2706.4 words).
In addition, a third party waspresent in 47 of the consultations.Following the consultation, each patient wasasked questions from standard questionnaires to as-certain their level of symptoms, and their evalua-tion of aspects of the consultation.
The positiveand negative syndrome scale (PANSS) (Kay et al,1987) assesses positive, negative and general symp-toms on a 7-point scale of severity (1=absent ?
7=ex-treme).
Positive symptoms represent a change inthe patients?
behaviour or thoughts and include sen-sory hallucinations and delusional beliefs.
Negativesymptoms represent a withdrawal or reduction infunctioning, including blunted affect, and emotionalwithdrawal and alogia (poverty of speech).
Positiveand negative subscale scores ranged from 7 (absent)?
49 (extreme), general symptoms (such as anxiety)scores ranged from 16 (absent) ?
112 (extreme).Patient satisfaction with the communication wasassessed using the Patient Experience Questionnaire(PEQ) (Steine et al, 2001).
Three of the five sub-scales (12 questions) were used as the others were80not relevant, having been developed for primarycare.
The three subscales were ?communication ex-periences?, ?communication barriers?
and ?emotionsimmediately after the visit?.
For the communicationsubscales, items were measured on a 5-point Lik-ert scale, with 1=disagree completely and 5=agreecompletely.
The four items for the emotion scalewere measured on a 7-point visual analogue scale,with opposing emotions were at either end.
A higherscore indicates a better experience.Adherence to treatment was rated by the clini-cians as good (> 75%), average (25  75%) or poor(< 25%) six months after the consultation.
Due tothe low incidence of poor ratings (only 8 dialogues),this was converted to a binary score of 1 for good ad-herence (91 patients), and 0 otherwise (37).
Ratingswere not available for the remaining dialogues.Measure DescriptionTurns Total number of turnsWords Total number of words spokenProportion Proportion of total talk in words(by each participant)WordsPerTurn Average length of turn in wordsWhPerWord Proportion of wh-words (e.g.what?
who?)
per wordOCRPerWord Proportion of open class repair ini-tiators (e.g.
pardon?
huh?)
perwordBackchannelPerWord Proportion of backchannels (e.g.uh-huh, yeah) per wordRepeatPerWord Proportion of words repeated frompreceding turn by other personOverlapAny Proportion of turns containing anyoverlapping talkOverlapAll Proportion of turns entirely over-lapping another turnQMark Proportion of turns containing aquestion markTimedPause Pause of more than approx 200ms,as marked on the transcriptsTable 1: Measures from outpatient consultations3.1 Classification ExperimentsWe performed a series of classification experimentsusing the Weka machine learning toolkit (Hall etal., 2009) to predict each of the outcome mea-sures outlined above (symptom measures, satisfac-tion measures, and adherence to treatment).
In eachcase, outcome measures were converted to binaryhigh/low scores on an equal frequency basis (i.e.providing approximately equal numbers of high andlow instances).
Features used were the high-levelmeasures given in Table 1, and/or all unigrams ex-tracted from the transcript; in both cases, featuresfrom doctor and patient were treated separately.
Un-igrams were produced by tokenising the lower-casedtranscripts on white space; no stemming or stop-word removal was performed, and feature valueswere binary i.e.
indicating only presence or ab-sence of the word spoken by the given speaker inthe given dialogue.2 Given the small size of ourdataset (131 instances) and the large feature spaceresulting (> 6500 features), we selected featuresbased on their predictive ability across the entiredataset (using Weka?s CfsSubsetEval selector), re-ducing the number of features to 50-100.
In orderto avoid biasing towards doctor-specific features, weused only words spoken by patients in these exper-iments ?
each patient only features in one dialogue,so patient-specific vocabulary cannot help perfor-mance across dialogues.
All unigram features thusselected were used in at least 3 dialogues.34 ResultsExperiments including unigram features used Lib-SVM?s support vector machine implementation(Chang and Lin, 2001) with a radial basis func-tion kernel; experiments with only high-level fea-tures used J48 decision trees.
In each case, experi-ments used 5-fold cross-validation.4 In experimentspredicting adherence, the distribution between pos-itive and negative (i.e.
good and bad adherence)made it impossible to balance the dataset - as thiscan be problematic for decision tree classifiers, wealso present results for a downsampled dataset withonly 71 instances but which provides balance.
Per-formance is shown in Table 2 as overall percentageaccuracy, and is compared to a majority-class base-line throughout; results which are significantly dif-ferent at the 5% level according to a  2 test from a2Experiments with frequency counts did not affect the re-sults as reported.3Bi- and tri-gram features were not extracted from this databecause of the small amount of data available which we feltwould result in models that suffered from overfitting (note thatthe same concern holds for the unigram features).4Classifiers were trained on 80% and tested on 20% of thesample, with this was repeated 5 times over each possible 80/20combination so as to test the whole dataset.81random distribution and the majority class distribu-tion are shown marked with *.Baseline Words High-levelPANSS positive 51.1 87.0* 56.5*PANSS negative 49.6 87.8* 56.5*PANSS general 48.4 91.1* 54.0PEQ emotions 51.9 89.1* 53.5PEQ communication 50.8 79.8* 52.4PEQ comm.
barriers 51.6 90.6* 51.6PEQ overall 50.8 90.6* 53.9Adherence 73.2 91.1* 63.4Adherence (balanced) 53.5 93.0* 52.1Table 2: Percentage accuracies vs feature setResults show good performance for all experi-ments when including lexical features, with all fac-tors being predictable with around 90% accuracywith the exception of PEQ communication at just be-low 80%.
However, using high-level features alonegives negligible performance, except for a smallbenefit on the PANSS negative and positive symp-tom measures, though contrary to our hypothesesthe most important high-level features were OCR-PerWord by the doctor (negative) and WhWords byan other participant (positive).Examination of the most predictive unigramsshows that sets selected for different outcome mea-sures are different: for example, the 54 fea-tures selected for adherence and the 73 selectedfor PEQ overall have only 1 word in com-mon (?mates?).
Adherence-related words in-clude words related to conditions, treatment andmedication (?schizophrenic?, ?sickness?, ?symp-toms?, ?worse?, ?pains?, ?flashbacks?, ?sodium?,?chemical?, ?monthly?
); PEQ-related words in-clude those related to personal life (?sundays?,?thursdays?, ?television?, ?sofa?, ?wine?, ?per-sonally?, ?played?
), and filled pauses (?eerrmm?,?uhhm?)
?
although more investigation is requiredto draw any firm conclusions from these.
Table 3shows the full lists for adherence and PEQ overall.5 Discussion and ConclusionsThe results show that although we can weakly pre-dict symptoms at levels above chance using onlyhigh-level dialogue factors, we cannot do so for ad-herence, or satisfaction measures.
Despite the linkbetween patient other initiated repair and adherence,this is also not an effective predictor for our machinelearning approach because of the scarcity of the phe-nomenon, and the fact that many of the consulta-tions for which the patients subsequently exhibitedgood adherence behaviour do not feature a singlepatient clarification, which may be linked to psychi-atrist clarity rather than lack of effort or engagementon the patient?s part.The high accuracies with lexical features showthat some aspects of the consultations do enable ac-curate prediction of adherence, PEQ measures andsymptoms.
However, as the features which allow usto achieve such good results rely on specific wordsused, it is unclear how generalisable or interpretablesuch results are.
The lexical features chosen do gen-eralise over our dataset (in which individual patientsappear only once), and exclude doctor talk, so can-not be simply picking out unique unigram signaturesrelating to individual patients or doctors; however,given the small size of the dataset used for this ini-tial investigation with its constrained domain, genreand topics, and the use of the whole dataset to selectpredictive words, it is unclear whether these resultswill scale up to a larger dataset.We therefore suspect that more general, higher-level dialogue features such as specific interac-tion phenomena (repair, question-answering) and/ormore general models of topic may be required.While unigrams are too low-level to be explanatoryand may not generalise, the dialogue features dis-cussed are too high-level to be useful; we are there-fore examining mid-level phenomena and modelsto capture the predictability while remaining gen-eral and providing more interpretable features andresults.
Although the word lists offer clues as tothe relevance of specific words for the overall pre-dictability, we would not like to leave it at that.Further experiments are therefore underway to in-vestigate whether we can find a level of appropri-ate explanatory power and maximal predictivity us-ing an interim level of analysis, for example with n-gram and part-of-speech-based models, topic mod-els based on word distributions, and turn-taking phe-nomena.
Additional experiments also look at theturn-level data to see if the patient led clarificationfactor can be directly extracted from the transcripts.82Adherence PEQ overallair grass schizophrenic 20th electric onto sometimeanyone grave sensation ages energy overweight sonbalanced guitar sickness angry environment oxygen standingbleach h simply anxiety experiencing packed stomachbuild hahaha sodium background facilities percent suddenlybuilding lager stable bladder friendly personally sundaysbusy laying stock booked helps picture supposechallenge lifting symptoms boy ignore played tablechemical lucky talks broken immediately programs teamcomplaining mates teach bus increased progress televisioncup monthly terminology certificate irritated provide thursdaysdates mouse throat dead kick public troublesen nowhere virtually deep later quid uhhmfill pains was drunk lee radio upsettingfinished possibly wave earn loose realised walksfish pr weve eeerrrr low reply watchersflashbacks recent worse eerrmm march sat wineremoved writing eerrrmm mates shakyri moments sofaTable 3: Most predictive unigram featuresReferencesChih-Chung Chang and Chih-Jen Lin, 2001.
LIB-SVM: a library for Support Vector Machines.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.M.
Colman and P. G. T. Healey.
2011.
The distribution ofrepair in dialogue.
In Proceedings of the 33rd AnnualMeeting of the Cognitive Science Society, pages 1563?1568, Boston, MA.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: An update.SIGDKDD Explorations, 11(1):10?18.M.
Heldner and J. Edlund.
2010.
Pauses, gaps andoverlaps in conversations.
Journal of Phonetics,38(4):555?568.S.R.
Kay, A. Fiszbein, and L.A. Opfer.
1987.
Thepositive and negative syndrome scale (PANSS) forschizophrenia.
Schizophrenia bulletin, 13(2):261.R.
McCabe, C. Heath, T. Burns, S. Priebe, and J. Skel-ton.
2002.
Engagement of patients with psychosis inthe consultation: conversation analytic study.
BritishMedical Journal, 325(7373):1148?1151.R.
McCabe, M. Lavelle, S. Bremner, D. Dodwell, P. G. T.Healey, R. Laugharne, S. Priebe, and A. Snell.
inpreparation.
Shared understanding in psychiatrist-patient communication: Association with treatmentadherence in schizophrenia.E.A.
Schegloff.
1992.
Repair after next turn: The laststructurally provided defense of intersubjectivity inconversation.
American Journal of Sociology, pages1295?1345.S.
Steine, A. Finset, and E. Laerum.
2001.
A new,brief questionnaire (PEQ) developed in primary healthcare for measuring patients?
experience of interaction,emotion and consultation outcome.
Family practice,18(4):410?418.M.
Themistocleous, R. McCabe, N. Rees, I. Hassan,P.
G. T. Healey, and S. Priebe.
2009.
Establishing mu-tual understanding in interaction: An analysis of con-versational repair in psychiatric consultations.
Com-munication & Medicine, 6(2):165?176.D.R.
Traum and J.F.
Allen.
1992.
A speech acts ap-proach to grounding in conversation.
In Second Inter-national Conference on Spoken Language Processing.83
