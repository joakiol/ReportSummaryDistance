Supporting anaphor resolution in dialogues with a corpus-basedprobabilistic modelMarco  RochaSchool  of  Cogn i t ive  and Comput ing  Sc iencesUn ivers i ty  of SussexBr ighton  BN1 9QH,  U .K .marco@cogs ,  susx .
ac .
ukAbst ractThis paper describes a corpus-based in-vestigation of anaphora in dialogues, us-ing data from English and Portuguese face-to-face conversations.
The approach relieson the manual annotation of a significantnumber of anaphora cases - around threethousand for each language - in order tocreate a database of real-life usage whichultimately aims at supporting anaphora in-terpreters in NLP systems.
Each case ofanaphora was annotated according to fourproperties described in the paper.
Thecode used for the annotation is also de-scribed.
Once the required number of caseshad been analysed, a probabilistic modelwas built by linking categories in eachproperty to form a probability tree.
Theresults are summed up in an antecedent-likelihood theory, which elaborates on theprobabilities and observed regularities ofthe immediate context o support anaphorresolution by selecting the most likely an-tecedent.
The theory will be tested ona previously annotated ialogue and thenfine-tuned for best performance.
Auto-matic annotation is briefly discussed.
Pos-sible applications comprise machine trans-lation, computer-aided language learning,and dialogue systems in general.1 In t roduct ionThe emergence of corpus-based approaches broughtto the fore the importance of extensive records ofreal-life language.
The technique of corpus annota-tion and the use of statistical measures are standardresearch tools in corpus-based approaches.
This pa-per presents a study which relies on corpus anno-tation to describe anaphoric phenomena in two lan-guages - English and Portuguese.
The investigationconcentrates on dialogues.
The London-Lund Cor-pus is the source of English data, whereas the Por-tuguese data come from a corpus collected especiallyfor the purposes of this research.Fligelstone's (Fii92) study on anaphora bears im-portant similarities to the present one, as it alsouses an annotation to describe features of anaphoricphenomena.
The annotation created for the presentstudy draws on some of the ideas which guide Fligel-stone's, but it is quite distinct in both form andcontent.
Biber's (Bib92) systematic use of statisti-cal techniques to explore corpus data, together withthe broad concept of referring expressions adopted,was also influential in shaping choices made for thisproject.Having in mind Biber's non-restrictive approach,anaphora is defined, for the purposes of this re-search, as the relationship between a term - calledthe anaphor -  which must be linked to an explicitor inferable lement in the discourse - called the an-tecedent  - in order to successfully accomplish se-mantic interpretation.
All types of anaphors areannotated, including pronouns, noun phrases, verbphrases, and all elliptical phenomena.A number of studies on anaphora ttempt o in-corporate the notion of topic, focus, or centre to theanalysis of anaphora (see, among others, (Sial86),(Fox87)), leading to the discussion of ways to tracktopic - under any of the various names - in dis-course (among many others, (Rei85), (GS86) and(GJW95)) and to relate topicality to anaphor eso-lution.
The research described here is no exception.In order to assess the importance of topicality foranaphor esolution, it was decided that topic struc-ture should be made an integral part of the investiga-tion, and, consequently, encoded in the annotation.The notion of topic is, however, notoriously diffi-cult to deal with (see (BY83) for an extensive discus-sion).
A routine dialogue contains a number of dis-54course entities, typically expressed by noun phrases,which, to mention a few possibilities: may retain asalient status throughout he whole dialogue; maypop in and fade out any number of times; may popin once and fade out for good; may pop in and subdi-vide into subordinate topics, then fade out and thenreturn; and several other possible combinations andinteractions.
Moreover, real-life conversations oftencannot be summed up in terms of a title-like globaltopic in any easy way.The study thus aimed at a working definition forthe different levels of saliency so as to make the no-tion of topicality useful for the purpose of anaphorresolution.
A set of categories was created to classifydiscourse ntities into top ica l  roles which cover thevarious levels of saliency.
Global and local topics fora given dialogue had to be established a priori, in-dependently of the analysis of anaphoric relations,so as to avoid circularity, as pointed out in (Fox87),although subsequent adjustments may consider dis-course information related to those anaphoric rela-tions.Procedures to identify each one of the topical roleswere spelled out as precisely as possible, having inmind that a measure of flexibility was necessary.
Thepicture of topicality thus obtained oes not claim tobe any more than part of the truth.
However, theassignment of topical roles to discourse entities isclaimed to be an effective way of supporting anaphorresolution by keeping track of salient discourse nti-ties.2 The  annotat ionThe annotation is manually entered by the analystin separate lines inserted in a machine-readable tran-script of a dialogue.
Lines with one asterisk at thebeginning contain information about the topicalitystructure.
A one-asterisk line is inserted at the topof the transcript, defining which discourse ntity isto be considered the global topic - called the dis-course top ic  and represented by the code dt inthe annotat ion-  for the dialogue.
The procedureto select the discourse topic draws on the work in(Hoe91) and involves a number of steps based onfrequency, distribution, position of first token, andsemantic adequacy for the role.
In case there is aradical and stable change of topic within the dia-logue, the dialogue is split into two fragments, eachone with its own discourse topic.Each local topic - called a segment  top ic  andcoded as st - is specified in one-asterisk lines in-serted at the beginning of the segment in question.New segments introduce new local topics.
The pro-cedure to identify a new topic is based on the workon discourse analysis described in (Sin93) and in(Sin92), making use of concepts uch as prospectionand encapsulation.
Each new utterance is assessedon the basis of these coherence devices to determinewhether it introduces a new topic or not.It is necessary further to divide the dialogue intosubsegments with distinct subtopics, called subseg-ment  topics  and coded sst.
These are subordinatelocal topics within a segment.
Subsegment topicsare also specified in one-asterisk lines by means ofan ss mark that distinguishes them from segmenttopics (marked s).
Therefore, the procedure usedfor segmentation must not only identify a new topicbut also distinguish a local topic from a subordinatelocal topic.Segments and subsegments are sequentially num-bered as they appear in the dialogue.
In case a pre-viously developed segment or subsegment topic be-comes the current topic again, the code r is placedbefore the segment or subsegment code to signal it isa resumptive segment or subsegment.
Subsegmentcodes are followed by a slash which is in turn fol-lowed by the code for the segment which containsthe subsegment (see example (1) below).The procedures used to assign topical roles to dis-course entities aim to be as objective as possible, sothat different analysts hould come to the same con-clusions concerning topical roles in a given dialogue.The procedures constrain choices, but the analystmust use a measure of discretion to make final deci-sions.
A full description of the procedures, as well asthe complete listing of codes used in the annotationscheme, can be found in (Rocng).Once the topicality structure of the dialogue hasbeen fully defined, each case of anaphora is anno-tated according to four properties.
The first prop-erty is the type  of  anaphor .
The categories usedcombine: word classes, such as sub jec t  p ronoun(coded as SP  in example (1) below); phrase struc-ture concepts, such as noun phrase,  marked FNPin (1); and anaphora-world efinitions, like one-anaphora ,  which appears as One_an below.
Thecode is entered in a line with two asterisks at thebeginning, inserted under the anaphor classified.Notions like zero anaphor or zero pronoun are notincluded in the set of categories employed to classifytypes of anaphor.
The word which triggers a searchfor an antecedent is annotated as an anaphor.
Averb which appears without one or more of its essen-tial complements requires the identification of thesecomplements from ongoing discourse and is conse-quently annotated as an anaphoric verb.
This de-cision is particularly important for the annotationof the Portuguese data.
The twenty-seven cate-55gories used in the analysis of the English samplewere grouped into three umbrella categories.
Fre-quencies for these umbrella categories are shown inTable 1 below:Table 1: Frequencies for types of anaphorPronounsVerbs and adverbialsNominalsTotalFrequency Percent1579 51.1318 10.31193 38.63090 100.0The three remaining properties are entered in a linewith three asterisks at the beginning inserted underthe two-asterisk line with the code for the type ofanaphor.
A semicolon separates the code for eachproperty.
An example of annotated text is shownbelow:(1)B: well I think probably what Captain Kay** FNP*** ex_222; dthe l ;  LR;must have said was a will is legal if it's** SP*** ex_224; d the l ;  FtC;witnessed on the back of an envelope* ss4/s38 'Captain's personal witnessing'A: w- d id  he say that** SP*** ex_222;  the l ;  Ft0p;he had personal ly witnessed one** SP One_an*** ex_222; thel; FtCCh; ex_l; dr; SetMb;B: well I could have beenI could have been wrong there** AdvP*** ex_ l l6 ;  p_ss t ;  CK;The first property to have the corresponding codeinserted in the three-asterisk line is the type  of  an-tecedent .
The antecedent for the anaphor in ques-tion is classified according to the explicit/implicitdichotomy, using the marks ex and im followed bya number which identifies the referent in a list.
How-ever, it is a policy of the study to annotate very to-ken of third-person personal pronoun, as well as alldemonstrative pronouns, regardless of the fact thatthey may be nonreferential, and thus not a case ofanaphora strictu sensu.
A third category was cre-ated for the cases of nonreferential pronouns - typi-cally /l or lhat.
Frequencies for the English sampleare shown in Table 2 below:Table 2: Frequencies for types of antecedentFrequency PercentExplicit 2562 82.9Implicit 412 13.3Nonreferential 116 3.8Total 3090 100.0The second slot in the three-asterisk line containscode for the property called the top ica l i ty  s ta tusof  the  antecedent ,  which uses the topical roles de-fined for topic tracking to classify the antecedent ofthe anaphora case in question.
An antecedent whichis not one of the topics is a discourse entity associ-ated to one of the topics.
If it is associated locallyto the segment opic, it is classified as a themat ice lement .
A thematic element may have a cross-segment saliency, in which case it is called a dis-course  themat ic  e lement .
The latter typicallyinclude the participants in the dialogue, other im-portant agents and also objects associated to thediscourse topic.Antecedents can also be discourse chunks.
Theyare classified as predicates of the entity with a topi-cal role to which they are most strongly related.
Thevarious categories used to assign a topicality statusto antecedents were grouped as global (discourse)roles, local (segment) roles, or sublocal (subsegment)roles.
A fourth category - namely, focus ing  dev ice- is used to classify the cases of anaphors with no an-tecedent (nonreferentials) or with antecedents whichwere too vaguely implicit for an accurate assessmentin terms of topical role.
Frequencies for the Englishsample are shown in Table 3 below:Table 3: Frequencies for topical rolesFrequency PercentLocal topical roles 1298 42.0Global topical roles 1068 34.6Sublocal topical roles 585 18.9Focusing devices 139 4.5Total 3090 100.0The fourth property is an attempt o encode psy-cholinguistic information for anaphor resolution.The observation of corpus data revealed that theclassification into types of anaphor - first property- did not cover important processing information.Different strategies are needed to resolve the sametype of anaphor - and often the same anaphoric wordor phrase - in different contexts.
Syntactic informa-tion - as codified in an algorithm like the "naive"algorithm in Hobbs' (Hob86) - may suffice to resolvea given occurrence of /t.
However, another tokenof the same word may demand rather complex dis-course processing, bypassing a number of candidatesto reach the correct antecedent.
A large number of56categories were used to classify tokens according toprocess ing  s t ra tegy .
They were grouped as shownin Table 4 below with the respective frequencies forthe English sample.Table 4: Frequencies for processin~ strategiesFrequency PercentLexical processes 1095 35.4Discourse processes 503 16.3Collocations 279 9.0Syntactic processes 1213 39.3Total 3090 100.03 The probabilistic modelThe frequency counts yielded by the annotationwork - shown in the previous section - were usedto build a probabilistic tree which is a model ofthe anaphora world as described by the annotationscheme.
The root of the tree is a category in the vari-able named type  o f  anaphor .
The choice bears inmind the possibility of automatic annotation.
Givena POS-tagged ialogue, it should not be difficult tomap the tags into the categories used to classify thetype of anaphor.It was necessary then to decide which variableshould occupy the next level in the tree.
In or-der to make an informed choice, cross-tabulationsfor each possible combination of two variables wereproduced, together with a chi-square test and twonon-chi-square-based association measures.
Signifi-cance was achieved in all cases, but association wasnot very strong, except for the relation between typeof anaphor and processing strategy (Goodman andKruskal tau = 0.41).
The Goodman and Kruskaltau is an association measure based on the notionof proportional reduction of error.
The value thusmeans that, once the distribution for type of anaphoris known, the chances of predicting the processingstrategy correctly are forty-one percent higher.Other factors pointed to the processing strategyvariable as the best candidate for the second level ofthe probability tree.
The other two variables clas-sify the antecedent.
Thus, it is impossible to besure of the correct category classification before ac-tually identifying the antecedent.
This means that,although the type of antecedent can occasionaly bepredicted on the basis of the anaphor type, it will notbe possible to offer more than a probability for eachcategory in most cases.
On the other hand, the pro-cessing strategy can be safely predicted on the basisof the anaphor type in at least one case, namely, ifthe processing strategy relies on knowledge of col-locations.
These collocations contain words such asit or that which function in a distinct way when ap-pearing in phrases such as that's it or I mean it.Collocations can be identified by simply checking alist which has been prepared as the annotation workprogressed.The nodes on the second level of the tree arethe categories which classify the processing strategy.Each branch of the tree is assigned two values.
Thefirst one is the probability for that particular branchwithin the universe of the node immediately above,while the second one is the probability for the wholebranch all the way to the root, that is, in relationto the total sample.
Thus, given that the anaphoris a pronoun, the probability that it will be resolvedby means of lexical  p rocess ing  - meaning knowl-edge associated with the semantics of the anaphor -is 0.01267, which is rather small.
In relation to anyanaphor, the probability that it will be a pronounresolved by means of lexical processing is 0.00647,which is extremely small.
However, it is differentfrom zero and must be taken into consideration.The subsequent level in the tree can be occu-pied by any of the two remaining variables.
How-ever, it was decided that probabilities should be cal-culated for all possible combinations of categoriesacross the variables.
Once the frequency counts hadbeen obtained, a program was written which calcu-lates probabilities for every combination in relationto the immediately higher node and for the total inall possible orderings of the variables.
In spite ofthe fact that placing the processing strategy beforethe other two is elear\[); more economic, there maybe one type of anaphor for which this is not true.All options are thus available for use in building theantecedent-likelihood theory.The probabilistie model is the mainstay of the the-ory, but the collocation list and other regularitiesobserved also play an essential role.
For instance,the few cases classified as pronouns resolved by lex-ical processing were looked into in search of a fea-ture that could be the clue for pronoun resolutionsbased on lexical processing.
Probabilities for the un-grouped categories were also calculated and are asource of useful information as well.
The next sec-tion describes how these various inputs are combinedto support anaphora resolution.4 Building the theoryOnce the probabilities for every combination of cate-gories across the variables had been worked out, thetask then was to put these numbers to good use.
Inthe case where pronouns are the root of the proba-bility tree, the results for processing strategy are asshown in Table 5 below.57Table 5: Processing strategies for pronounsFrequency ProbabilityLexical processes 20 0.012Discourse processes 398 0.252Collocat ions 217 0.137Syntactic processes 944 0.597Total 1579 1.000If these results are compared to the percentages inTable 4, some important differences emerge.
Thereis a steep decline in the number of anaphors resolvedby means of lexical processes.
This is not surprising.Lexical processes are an umbrella category group-ing strategies uch as wor ld  knowledge  and lexi-cal repet i t ion .
These strategies are typical of res-olutions related to anaphoric nonpronominal nounphrases, as they rely on the semantic ontent of theanaphor itself to identify the correct antecedent.
Aspronouns characteristically have low semantic value,it is in fact surprising that any of them are resolvedby such means at all.All other three categories how increases in re-lation to the percentages in Table 4, but syntacticprocesses present the highest increase.
One of thestrategies grouped under syntactic processes is thef i r s t -cand ldate  strategy, which may be describedas an adaptation of Hobbs' "naive" algorithm (see(Hob86) to spoken language, since it searches forthe first appropriate noun phrase in the ongoing dis-course and selects it as the antecedent on the basisof agreement and syntactic onstraints.The most frequent processing strategy within syn-tactic processes is the f i r s t -cand idate  chain.
Thisconfirms Biber's (Bib92) findings about the impor-tance of chains in conversations, but it tones downoptimistic expectations of easy anaphor esolution.Chains do not necessarily start with an anaphor e-solved by a first-candidate strategy, although manyof them do.
Consequently, the actual identificationof the antecedent may still need to employ one ofthe less straightforward strategies.
The two first-candidate strategies together account for almost allcases of syntactic processes in pronouns.The list of collocations collected during the anno-tation process shows that, within the pronoun cat-egory, the personal pronoun it and the demonstra-tives this and that are the only tokens which appearin collocations.
There is no need to check the col-location list when the pronoun being resolved is notone of the above.
Virtually all collocations entail aresolution for the anaphors they contain.
Once iden-tified, the collocation can therefore be associated toa distinct way of handling the anaphor.Discourse processes are strategies that demandmore complex information which cannot be obtainedby checking a collocation list or analysing the seman-tic content of the anaphor.
A first-candidate searchwill also fail in these cases, as the correct antecedentis not the first candidate available, either straight-forwardly or in a chain.
The typical case is the pro-noun reference which bypasses the first candidate inspite of the fact that it is an appropriate one, if onlyagreement and syntax are considered.
An exampleis given below:(2)B: I mean what difference could it maketo the directors of Unilever thattheir shares had got down from sayeighty to fifty or whatever it isA: well in the present circumstancesnot very much because I meaneverything has gone down but of courseif they are consistently lowit makes them more diff icultit makes it more diff icult for themto raise moneyThe second occurrence of them - the first one is partof a false start - is to a certain extent ambiguous, asthe antecedent might be said to be either directors ofUnilever or Unilever, although understanding is notmuch affected by choosing one or the other.
Whatis important is that the antecedent is not shares andthus there is no chain of reference.
The first can-didate they has to be bypassed, as well as presentcircumstances, in order to identify the correct an-tecedent.The phrase to raise money has to be semanticallyprocessed before the anaphor can be successfully re-solved.
Information yielded by the syntactic struc-ture, lexical content of the anaphors, or knowledgeof collocations will not achieve the correct identifi-cation of the antecedent.
As the resolution involvesknowledge only available after processing discoursein full, this strategy is named d iscourse  knowl -edge.
The use of lexical clues from the immediatecontext and the topical roles of candidates are ofcrucial importance for the correct resolution of thiskind of anaphor.Other strategies grouped under discourse pro-cesses include: secondary  re ference ,  which is theuse of first and second person pronouns in speech re-ported verbatim to refer to persons previously men-tioned in the dialogue; d i s tant  anaphora ,  whichare pronouns with very distant antecedents - overfifty tone units - but without competing candidates;pronouns which conjoin referents in a set, calledset c reat ion ;  reference to an element within a set,called set member ;  and the cases of antecedent-less anaphors (see (Cor96)), in which the processing58strategy is called deixis.
The categories grouped asdiscourse processes may be seen as the particularlycomplex strategies for anaphor esolution.The example above also contains four tokens of it.Three of them can be resolved by using a more so-phisticated version of collocational knowledge.
Thefirst one is in a make no difference collocation.
Theobservation of corpus data shows that the it in suchcollocations has an explicit clausal or sentential an-tecedent in all cases found.
It also reveals that thereference is cataphoric whenever "make" is the mainverb in a sentence with a subordinate that-clause.Furthermore, this that-clause is the antecedent in alloccurrences of the kind.The collocation list has thus an entry such as:it X -make d i f ference to Ob j  that -c lause?
cataphoric it (Subj)?
antecedent = that-clauseThis sort of knowledge is extended to cleft sen-tences, adding to the collocation list an entry like:it X -be  Sub jC  that -c lause?
cataphoric it (Subj)?
antecedent = that-clauseIn order to resolve the second and third tokens ofit, the entry to be accessed in the collocation list is:it X -VERB Ob j l  Ad j  for Ob j2  NF-c lause?
cataphoric it (Subj)?
antecedent = NF-clause?
if VERB = make and Obj l  = it- it (Obj l)  nonreferentialThe X- symbol means any inflected form of theverb, optionally including tense, aspect and modal-ity.
The major structures of the language, such as af-firmative, interrogative and negative forms, are alsoassumed as included in the entry.
The other sym-bols in the entries above stand for subject (Subj),subject complement (SubjC)object (Obj), adjective(Adj) and nonfinite ( i F ) .The entries in the collocation list are related tospecific pronouns.
As mentioned before, it is theonly personal pronoun to appear in collocations witha pattern of regular resolution.
It is reasonable tothink, thus, that other patterns may emerge if thecategories in the anotation scheme are individuallyanalysed out of the umbrella categories.
Althoughthe grouping was very useful for the significanceand association tests, the antecedent-likelihood (AL)theory requires a return to the original categories, aswell as the analysis of individual pronouns.Suppose then that a dialogue tagged using thetagset in (Sam95) is being analysed according to theAL theory in order to resolve anaphors.
A wordtagged as PPH1 is a token of it.
Suppose further-more that this token of it has been identified as anobject pronoun by means which need not be dis-cussed here.
The header for the word in the ALtheory is:?
syntactic process = 0.729?
discourse process = 0.151?
collocation = 0.080?
lexical process = 0.013If these numbers are compared to the numbers forpronouns as a whole, there is a substantial increasein the number of anaphors resolved by syntactic pro-cesses.
The probabilities for resolutions which relyon knowledge of collocations and on discourse pro-cesses decrease, whereas the probability for lexicalprocesses remains equally low.
The reduction incollocation-related strategies can be explained.
Thenumber of collocations in which it is an object pro-noun is much smaller.
Moreover, cleft sentences arethe most common collocation, and it is a subjectpronoun in these sentences.
The decrease in resolu-tions by means of discourse processes is caused bythe fact that demonstratives have been taken out.The next step is to match the tone unit in whichthe token occurs with the entries in the collocationlist.
If there is a match, the path to resolution isspelled out in the entry.
If there isn't, the next stepis to eliminate rare processing strategies which areonly needed in special cases.
One way to do thatis to use the strategy with the highest probabilityto select a tentative antecedent and check the an-tecedent against information in the theory.
If noappropriate referents are found, not even one whichfits poorly, it must be one of the special situations.In the case of it, the two first-candidate strategiesare by far the most probable and rarely fail to pro-duce an antecedent.
Understandably, all cases in thesample in which both did fail are tokens at the verybeginning of the dialogues in question.The only possibility then is that the anaphor isone of the rare cases of resolution by means of lex-ical processes.
Shared knowledge allows the partic-ipants to identify an antecedent that has not beenmentioned because in the situation where the con-versation occurs, it can only mean one thing.
It is59a rare but interesting case for dialogue systems inwhich the same user is expected to have more thanone session.
The history of communications betweenman and machine would have to be available in or-der to allow resolution, as it is the anaphor thatintroduces the discourse ntity in the dialogue.In all cases in the sample, participants only intro-duce discourse entities in this way when they arecentral to the conversation yet to take place andthus have highly salient global topical roles.
Theantecedent is obviously implicit.
The AL theory forit as an object pronoun specifies then:check co l locat ion  l ist?
if no match foundselect  f i rst  appropr ia te  candidate?
if no appropriate candidate found?
beginning of dialogue ??
if not no record?
if yes lexical process; shared knowledge?
discourse topic or discourse thematic element inall cases?
implicit in all casesResolutions which require discourse processes arethe most difficult to identify, particularly those casesin which the first candidate is not the correct an-tecedent and must be bypassed for a different one,as in example (2) above.
However, antecedents re-quiring this sort of processing strategy for identifica-tion are usually highly salient elements.
Moreover,a lexical clue of some kind is often present in thecontext.In the case of both object and subject pronouns,the verb to which they are attached is of great im-portance.
The provisional antecedent may be ruledout by selectional restrictions.
It seems also impor-tant to have a record of verbs associated to discourseentities, as they are likely to be referred to as argu-ments of the same verb or of a similar one.
Relatedadjectives and noun phrases attached to the sameverb should also be examined.
If the provisional an-tecedent has never appeared as an argument of theverb to which the anaphor is attached, the possibil-ity of bypassing it should be considered.
If bypass-ing it selects a highly salient entity, such as the dis-course topic or a high-frequency discourse thematicelement, and this entity has appeared as an argu-ment of the verb in question, the resolution by dis-ocurse knowledge is probably the best choice.
Thus,the AL theory for it as an object pronoun proceedsas below:?
if an appropriate candidate foundcheck se lect iona l  res t r i c t ions  of  verbcheck h is tory  o f  verb  in d ia loguecheck assoc ia ted  ad jec t ives  and  noun phrases?
if the antecedent fits, accept it?
if the antecedent doesn't fitse lect  next  cand idaterepeat  checks* if the antecedent fitscheck topical  ro le?
if dt, dthel or stbypass  prev ious  candidateThe AL theory is still being finalised.
When com-pleted, it will contain systematised records like thoseabove for all types of anaphor.
It will be then testedon a previously annotated dialogue which has notbeen included in the training sample.
Results will beevaluated according to two standards: the percent-age of correct antecedents identified by the singleor highest-probability choice selected by the theorywhen applied to a case; and the percentage of cor-rect antecedents identified when lower-probabilitychoices are also considered.
The test will assess theefficacy of the theory and will also expose overlookedshortcomings.5 Future  deve lopmentsThis paper presents results for the English sampleonly.
The same set of categories is used for the an-notation of dialogues in Portuguese.
However, sometypes of anaphor only have tokens for one of thelanguages.
For instance, the type of anaphor one-anaphora does not occur in Portuguese.
One of theinteresting developments to be explored, once theanalysis of both samples is completed, is the con-trastive analysis of results.
A database of aligneddiscourse environments related to anaphoric phe-nomena-  covering linguistic information at all levels- could be produced, providing guidance for appli-cations such as machine translation and computer-aided language learning.
If automatic annotationcan be at least partially accomplished, the scheme60may prove its worth in practical applications, in-cluding those which involve only one of the two lan-guages, such as dialogue systems.Automatic annotation using this scheme is adaunting task, particularly because of the need toidentify the discourse ntities selected for the topi-cal roles, as procedures ultimately require a decisionby the analyst.
Other problems not discussed in thispaper, such as the identification of discourse-chunkantecedents for the resolution of demonstrative pro-nouns, are also very difficult.
Nonetheless, the ap-proach seems worth pursuing precisely because thehardest cases are not left out.
The inclusion of vari-ables for topical roles and processing strategy repre-sents an attempt o deal with difficulties which havebeen often avoided in studies on anaphora.6 AcknowledgmentThe project is fully funded by the Conselho Nacionalde Desenvolvimento Cient~fico e TecnolSgico undergrant no.
200608-92/4.Re ferencesDouglas Biber.
Using computer-based text corporato analyse the referential strategies of spoken andwritten texts.
In Jan Svartvik, editor, Directionsin corpus linguistics, pages 215-252, Berlin andNew York, 4-8 August 1991 1992.
Nobel Sympo-sium 82, Mouton de Gruyter.Gillian Brown and George Yule.
Discourse analysis.Cambridge University Press, Cambridge, 1983.Francis Cornish.
Antecedentless anaphors: deixis,anaphora, or what?
Some evidence from Englishand French.
Journal of Linguistics, 32:19-41,1996.Steve Fligelstone.
Developing a scheme for anno-tating text to show anaphoric relations.
In Newdirections in English language corpora: method-ology, results, software development, number 9in Topics in English Linguistics, pages 153-170.Mouton de Gruyter, Berlin and New York, 1992.Barbara Fox.
Discourse structure and anaphora.Cambridge University Press, Cambridge, 1987.Barbara Grosz, Aravind Joshi, and Scott Weinstein.Centering: a framework for modeling the local co-herence of discourse.
Computational Linguistics,21(2):203-225, 1995.Barbara Grosz and Candace Sidner.
Attentions, in-tentions and the structure of discourse.
Computa-tional Linguistics, 12(3):175-204, July-September1986.Jerry Hobbs.
Resolving pronoun references.
In B.L.Webber, Barbara Grosz, and K. Jones, editors,Readings in Natural Language Processing.
MorganKaufmann, Palo Alto, CA., 1986.Michael Hoey.
Patterns of lezis in text.
Oxford Uni-versity Press, Oxford, 1991.Rachel Reichman.
Getting computers to talk like youand me.
MIT Press, Cambridge, MA, 1985.Marco Rocha.
A description of an annotationscheme to analyse anaphora in dialogues.
Tech-nical Report 427, University of Sussex - Schoolof Cognitive and Computing Sciences, Brighton,1997 (forthcoming).Geoffrey Sampson.
English for the computer.Clarendon Press, Oxford, 1995.Candace Sidner.
Focusing in the comprehension ofdefinite anaphora.
In Karen Jones Barbara Groszand Bonnie Webber, editors, Readings in naturallanguage processing.
Morgan Kaufman, Palo Alto,CA, 1986.John Sinclair.
Priorities in discourse analysis.
InR.
Coulthard, editor, Advances in Spoken Dis-course Analysis.
Routledge, London, 1992.John Sinclair.
Written discourse structure.
InJ.
Sinclair, M. Hoey, and G. Fox, editors, Tech-niques of description: spoken and written dis-course: a festschrift or Malcolm Coulthard.
Rout-ledge, London, 1993.61
