An Empirical Architecture for Verb Subcategorization Frame- a Lexicon for a Real-world Scale Japanese-English Interlingual MTNOMURA, Naoyuki and MURAKI, KazunoriNEC CorporationMiyazaki 4-l-1, Miyamae-ku, Kawasaki-city, JAPANnomura@hum.cl.nec.co.jpAbstractThe verb subcategorization frame informationplays a major role of disambiguations in manyNLP applications.
Japanese, however, imposesdifficulties of subcategorizing in part because itallows arbitrary ellipses of case elements.
Wepropose a new type of verb subcategorizationframe code set that combines the verb's surfacecase set and the deep case set, as a solution to thedifficulties of empirical researches on Japanese.The lexicon developed by this design hascomprehensive information on the correspond-ences between the surface case frame and thedeep case frame, and yet restrains the potentialcombinatorial explosion of the number of verbsubcategorization frames by carefully identifyingsuperficially different frames with an idea ofalternative case markers and semantic roles, andby introducing the notion of surface case framepermutations.
The number of different surface/deep case mapping types is 250, after wecompleted the new subcategorization frame codedevelopment for 30,000 verbs and adjectives.1.
IntroductionAn NLP system is supposed to be able to recognizethe differences and commonalities between almost hesame set of words in two different syntacticstructures, such as "Mary bit the dog" vs "Mary wasbit by the dog."
Considering this requirement, hecontents in verb subcategorization frames play amajor role of disambiguations in many NLP systems.These frames should reflect linguistic facts oflexical information being concentrated on verbs.There have been, on the other hand, some researchesthat aim to equally treat lexical information of nounsand that of verbs (see e.g.
EDR94).
Pustejovsky91stepped further into formulating useful, intrinsicinformation in nouns with the notion of eo-compos-itionality among others, so as to recover from anelliptical sentence such as 'he began the book' adefault verb such as 'reading.'
However, in order todevelop a working NLP system, even these recentresearches may presuppose the use of exhaustivecoding of verb subcategorization frame knowledge tolet the new lexical features be automatically extractedand fully functional in their systems.Ellipses appear to be a much more serious problemwith Japanese than with English because all thesupposedly obligatory case elements are virtually freeto be dropped or to be placed anywhere in thesentence xcept for the predicate position at the end.These phenomena seem to have imposed difficultiesupon the design of the lexicon so that no list ofJapanese verb classes and types comparable toGrishman94, Levin93 or Hornby75 for English wasreadily available when our project started 1.
Thus, wedecided to make one by ourselves by a bootstrappingmethod: to make the initial list of the classificationand to make it to grow by developing a workinglexicon for MT systems.
Upon this empirical studyand development of over 30,000 Japanese verbs andadjectives, we propose an architecture for verbsubcategorization that represents the mappinginformation between surface case frame and deep case(thematic role) frame.The proposal is to serve as a solution to the empiricaldifficulties with Japanese verbs and case elementsdescribed above.
The lexicon by this design hascomprehensive information on both the surface frameand the deep frame, and the correspondences betweenthem, which are embedded in a code Yet, the numberof codes has been controlled under a manageablefigure of several hundreds o that the coding systemcould evade the potential combinatorial explosion.This is to be done by identifying superficiallydifferent case patterns with an idea of alternative casemarkers and semantic roles, and by largely extendingthe notion and the formulation of voice conversion forJapanese auxiliary verbs and equivalents.The developed lexicon is adopted in a real worldscale intedingua-based MT system that translatesbetween English and Japanese (Muraki87).
Our aimIMartin75 & FM&T85 contain some lists, but is too partialfor the purpose of developing an MT system.640here is to show an empirical result of the developmentand analysis of the lexicon from the point of view ofspace complexity order (cf.
Jackendoflg0&93).
In thefollowing section are described the major linguisticrequirements of the architecture, the case elements ofwhich are free of word ordering and can increase innumber when their voice is converted.
Thearchitecture that combines the verb surface case frameand deep case frame is described in section 3,followed by extended mechanisms lot applying whatwe generalized from voice conversion phenomenatriggered by auxiliary verbs.
We, then, describe thelexicon structure for ambiguity representations inrelation to word senses.
Finally, we present somestatistic figures from the results of the lexicondevelopment and confirm that the proposedarchitecture and the code system can empiricallyconstrain the potential combinatorial explosions of theverb subcategorization frame representation varieties.2.
Linguistic Requirements of Verbsubcategorization FramesThe most notable syntactic phenomenon of Japaneseis so-called scrambling.
Any verb-modifying NP in asimple sentence in Japanese can appear at anyposition or does not have to appear at all, regardlessof its surface case and deep case.
In other words,word ordering is almost free for the major syntacticelements in a Japanese simple sentence xcept or thepredicate itself, which is to be placed at the end of thesentence.
Not the word ordering but casepostpositions mark the case of these NPs in relation tothe main verb.
All the examples in e.g.
2-1 lead to thesame event structure interpretation, which is sharedby the English translation "X gives Y to Z.
''2e.g.
Z-1 a. ok "X-ga Y-wo Z-ni age-ru"b. ok "Y-wo X-go Z-ni age-ru"c. ok "Y-wo Z-ni X-go oge-ru"d. ok "X-go Z-ni Y-wo age-ru"e. ok "Z-ni X-go Y-wo oge-ru"f .
ok "Z-ni Y-wo X-ga oge-ru"Particles "-ga", "-wo" and "-ni" are the mostfrequently used case postpositions that often marknominative, accusative, and dative cases, respectively ~?
There are various other alternative postpositions thatcan replace or be added to these case postpositions.Discourse representing postpositions uch as "-ha",which had been erroneously treated as general subject2 The differences concern the emphasis and scope that areto be handled by a pragmatics system.3 "-ga" can sometimes mark accusative case and "-ni" canmark various other cases and semantic roles including"locative" and "time.
"marker, could replace "-wo" and "-ga", and could beadded to "-ni".
These replacement or addition do notalter the basic event structure of the sentences (2-1a.,b ..... f.), but sometimes just add ambiguities to thesyntactic structure as is shown in e.g.
2-2.e.g.
2-2 a. ok "X-ha Y-ha Z-ni age-ru"b. ok "Y-ha X-ha Z-ni age-ru"Practical Japanese sentence analyzers would needsome semantic inference and default inference toplausibly identify X and Y using the semanticrestrictions on each case element and the standardword ordering.
Most nominative cases in Japaneseverbs including "agc-ru" ('to give') have strongpreference for human/animate attribute so that ameaningful difference between semantic similarity ofX to animate object and the similarity of Y to otherkind of concrete object leads to allocate nominativecase on X and accusative case on Y in either 2-2 a. or2-2 b.
If there is no such difference in the semanticrestriction score, the standard word ordering "-ga," "-wo," and "-hi" seems to let the listener to interpret'e.g.
2-2 a' as 'e.g.
2-1a'.Japanese not only has typical voice conversionssuch as passivization but also appears to have similarphenomena that alter tile surface case markings uchas the cases with causative construction.
Thisvariation roughly corresponds to the variety ofEnglish auxiliary verbs and higher predicate verbssuch as "dekiru (can)," "rareru (be pp./ can),""kotoga-dekiru (be able to)," "tai (want to)," "seru(make/let)," "garu (feel complement)" etc.e.g.2-3a.
X-ga Y-wo tabe-ru, b. X-hi Y-ga tabe-rareru.X-NOM Y-ACC eat.
X-DAT Y-NOM eat-PASSIVE"X eats Y .
.
.
.
X can eat Y" xor "X is eaten by Y"As is observed in e.g.
2-3, the nominative case marker"-ga" turns into dative case marker "-ni" and theaccu,~ative case marker "-wo" turns into nominativecase marker "-ga" when the passive~potential auxiliaryverb "rareru" is attached.Multiple voice conversions can often occur for asingle verb phrase as is shown in e.g.
2-3c.e.g.2-3 c. X-ga Y-wo Z-ni tabe-sase-rare-taku-nai.X-NOM Y-ACC Z-DAT eat-CAUS-PASS-WANT-NOT.
"X does not want to be lbrced to eat Y by Z"Since three auxiliary verb forms CAUS, PASS andWANT appear by this ordering in e.g.
2-3 c, a simple,natural solution to correctly recognize the scope ofcomplex modality features is to recursively apply thepernmtations of surface case set as is described in thefollowing section.6413.
Combining Surface and Deep Frames3-1.
Basic Representation for Japanese VerbSubcategorization FrameEmpirical studies as we observed in the previoussection have suggested that combining syntactic andsemantic frames could lead to an optimum efficiencyof lexicon descriptions.
Thus we created the basicdescription framework in the verb lexicon as is shownin fig.
1.Slot name: \[WITH FROM BY/IN NOM2NOM ~CC DATSurface GA/deha(pl) iWO NI/hecase frame <animai~e> <time>Deep case AGenT PAT- GOAlframe ientF ig .
l  Subcategorization Frame for "ageru"The example content in Fig.
1 is that of the verb"ageru (give)" used in e.g.
2-1 and e.g.
2-2.
Anaturallanguage analyzer in an MT system is supposed toconvert he case elements in e.g.
2-1 a,..,f, X, Y andZ to AGenT, PATient and GOAl, respectively, asshown in e.g.
3-1.e.g.
3-1 a. ok"X-ga Y-wo Z-ni age-m"b. ok "Y-wo X-ga Z-hi age-m"X = John -> AGenT ; Y = the book -> PATient ;Z = Mary -> GOAlThe analyzer looks up the slots in Surface case frameand find the match of the case postposition; for "-ga",GA in the NOM case slot matches and the deep casethat is stored in the NOM slot is taken out from thesubcategorization frame.
The analyzer checks if thesemantic restriction 'animate' matches the caseelement X (John).
If it fails, the analyzer looks forother slots, the other subcategorization frame of thesame verb, and then the frames of other verbs thatappear in the different place of the sentence.Fig.
1 shows a fixed frame with seven case slots,and this is exactly what the record format of ourJapanese lexicon is.
Why is it not necessary to havemore slots though we know there are definitely morethan seven case postpositions in Japanese?
One ofthe reasons 4 is that other postpositions that can bemapped into a thematic role are supposed to fall intoeither of the seven slot and take the position as thealternative case markers.
For example, "deha" inFig.l could only be used with animate plural nounssuch as "kotira ('our side')," but it certainly couldmark the nominative case.4 The other eason is that there are case postpositions thatare not mapped into thematic role.
They constitutes notargument structure but just adjuncts (free elements) as isexplained in modern Linguistics.The alternative case postposition "deha" alsocomplies with the Unique Case Principle 5 thatprohibits other case elements from filling the sameslot as NOM that is already filled by "X-deha".
Thisis why this use of case postposition "deha," with adifferent semantic restriction, is supposed to occupythe same slot NOM with the major case postposition"-ga".
Another slot DAT in Fig.1 shows that "-he"could replace the major case postposition "-ni" and beassigned the thematic role GOAl.
Again, thefollowing ungrammatical example e.g.
3-2 thatviolates the Unique Case Principle shows that "-ni"and "-he" for the verb "ageru" have to share the sameslot in the subcategorization frame.e.g.
3-2 * X-ga Y-wo Z-ni Z'-he age-ta.X-NOM Y-ACCZ-DAT Z'-DAT give-PERFective"X gave Y to Z '.
"For a simple Japanese analyzer that tries to fill asmany slots as possible for a verb, the Unique CasePrinciple is virtually embedded in the subcategorizat-ion frame of our architecture for the computationallexicon.The slot name NOM2 represent the typical case withtwo-term adjectival predicate?
that require twonominative cases.e.g.3-3 "X-ga Y-ga sukina-no-ha.."X-NOM"That X likes Y is..."3-2.
Generating Permutational Subcatego-rization Frame Triggered by AUX VerbsWe have generalized the notion of voice conversionfor Japanese auxiliary verbs and equivalents byabstracting 14 codes of case frame permutation.These codes, the contents of which are to beelaborated in the fig.
2 & 3, are assigned on theextended category of auxiliary verbs "dekiru (can),""rareru (be pp./can)," "kotoga-dekiru (be able to),""tai (want to)," "seru (make/let)," "garu (feelcomplement)".
Below is the description of theprocedure by which the Japanese analyzer performsthe permutation ofthe verb subcategorization frame.When the morphological analyzer detects anauxiliary verb or an equivalent while checking theinformation contained in the predicate phrase, theanalyzer develops the verb subcategorization framefrom the code in the verb's lexicon and read from the5 - " The Unique Case Principle in Case Grammar andempirical studies is formulated and explained by theLexicalist Hypothesis about hematic roles and the X-barTheory in the school of Universal Grammar (Chomsky88).6 There is only one verb "komaru (be in trouble)", theactive voice of which shows two nominative cases CGA"s).642auxiliary verbs' lexicon what we call the Surface CasePermutation Frame code (SCPF code).
The analyzergenerates the subcategorization frame for the entirepredicate by applying the permutation commandsdeveloped from the SCPF code for one auxiliary verbat a time.
The first permutation is performed for thefirst auxiliary verb next to the main verb, and thelocus moves on from the main verb to the firstauxiliary verb.
The second permutation is performedfor the second auxiliary verb next to the first auxiliaryverb, and the focus moves on to the second attxiliaryverb.
And so on: the N-th permutation is performedfor the N-th auxiliary verb next to the (N-l)-thauxiliary verb, and the locus moves on from the (N-l)-thauxiliary verb to the N-th auxiliary verb.
Themaximum number for N is actually set to three in ourMT system, reflecting the numbers of auxiliary verbsin real utterances and written sentences.e.g.3-3 a. X-gaY-wo taberu.X-NON Y-ACC cat.
"X eats Y "b. Z-ga Y-wo X-nitabe-saseru.Z-NON Y-ACC Z-DAT eat-CAUS.
"Z makes X to eat Y"c. X-ga Y-wo Z-hi tabe-sase-rareru.X-NON Y-ACC Z-DAT eat-CAUS-PASS.
"X was made to eat Y by Z"A correct process would generate the subcategor-ization frames represented in the example sentencesfrom e.g.
3-3a via e.g.
3-3b to e.g.
3-3c, where allcase elements X, Y and Z are consistent in these threesentences.
The SCPF code in the causative auxiliaryverb "saseru" has two ambiguities of the set ofpermutation commands as is shown in Fig.2.pei~t.tion commands I Permutation c mmandsCaus.
NULL > GA \[CAUser\] Caus.
NULL > GA\[CAUser\]\] A I GA >NI/NIYORI I B I GA >WOFig.2 SCPF Codes and PermutQtion Commands for "saseru"The set of original postpositions i described in theleft term (in the source direction of an arc) in thepermutation commands.
'NULL' termunconditionally matches and adds an extra case slotwith a new deep case described within the bracket onthe right term (\[CAUser\]).
If all the left termcondition for matching the case markers meet, thepermutation frame is valid and the number ofsubcategorization frames for a predicated issometimes increases.
In the above example,however, the permutation commands of Causative Bresults in generating two identical case markers 'WO"violating the Unique Surface Case Principle as isshown in e.g.3-4, so the pelxnutation is blocked.e.g.3-4 a. X-gaY-wotaberu.X-NOM Y-ACC eat.
"X eats Y "b.
*Z-ga Y-wo X-wo tabe-saseru.Z-NOM Y-ACC Z-ACC eat-CAUS.The second auxiliary verb "rareru" has even moreambiguities in meaning, each of which corresponds tosix different Permutation Frames as is shown in Fig.3.l irect \] GA > NI/ NIYORI assive\] WO > GA\[ Indirec~ NULL >GA\[EXP\] Passive I GA >NI/NIYORII otive JGA >,I/NIYORI/KARA assivelNI >GAI I I Possibi- GA > NI \] l i ty \]WO > GAHonorif-\] N/A.
}5 IIAutono- I GA > NI_mous WO > GAFig.3 SCPF Codes 0nd Permutation Commands "rareru"The analyzer follows the permutation proceduredescribed above for the second auxiliary verb.
All thepermutation commands in fig.3 actually can match theoriginal surface case flame of e,g.
3-3b.
It is a set ofindependent semantic heuristic rules that drops the'Autonomous' reading of "rareru" and ahnost drops tile'Honorific' reading of "rareru".
All the othersubcategorization frames for 'Direct Passive,' 'IndirectPassive,' 'Dative Passive,' and 'Possibility' aregenerated with slightly different variations ofalternative surface case markers.
The sentence ine.g.
3-3c can mean any of these but 'Indirect Passive,'the whole sentence of which is shown in e.g.
3-3d.e.g.3-3 d. E-gaX-ni Y-wo Z~ni tabe-sase-rareru.E-NON X-DATY-ACC Z-DAT eaDCAUS-PASS.
"E experienced that X was made to eat Y by Z"It is still grammatical, but is much more difficult toget the meaning of it because it has four arguments forthe single verb.
This factor alone can be used by theanalyzer to restrain the application of the generatedsubcategorization frame for the 'Indirect Passive'interpretation.3-3.
Two Cases of Multiple Deep Cases ina Single SlotThere are two kinds of description by whichmultiple deep cases are described in a deep case slotof a subcategorization frame (Fig.l).
One isselectional, and the other is overlapping.
Theselectional one is the use of alternative deep cases andmeets the needs of economical description of thelexicon and also the manageability of it.c.g.3-5a.
"The typhoon\[REAson\] has broken a part he city block."b.
"A monster \[AGenT\] has broken a part he city block.
"643In these examples, not the verb "break", but thesemantics of the subject decides what deep case thesubject should be allocated.
So, instead of assigningonly one deep case onto the deep case slot and createbunch of whole subcategorization frames, weintroduced an ambiguity marker such as AIRM(AGenT/INStrument/REAson/MEAns) to be assignedon the case slot.
In this case, the analyzer does nothave to decide the deep case until when necessary atwhatever point in the phases of MT 7.The other kind of description is 'overlapping' ofdeep cases.Slot nome: NOM ACC DAT WITHDeep cose AGenT PAT- GOAl n/aframe: &\[SOuRce\] ientFig.
4 Deep Case OverlopFig.4 shows ahnost he same deep case frame as inFig.1 that shows the subcategorization frame of verb"ageru (give)".
The only difference is the deep case\[SOuRce\] added to the AGenT.
Other kind oftransitive verbs such as "taberu (eat)" may not let the\[SOuRce\] be added because the AGenT here is notthe SOuRce position of the PATient in theevent/action.
"Taberu (eat)" may let \[GOAl\] be \]added to the AGenT.
This distinction may work inthe later knowledge-based inference phases of the MTsystem.3-4.
Lexicon Structure in Relation toWord SensesThere are cases in which one word sensecorresponds to multiple subcategorization frames,other cases in which one word sense corresponds toone subcategorization frame each, and the other casesin which multiple word senses correspond to lessnumber of subcategorization frames.
Since ourapproach ere is rather empirical so any guidelinesthat help the lexicon to be uniform in quality, we takeadvantage of other literature that aimed at someexhaustive listing of interesting cases.
The examplesentences in e.g.
3-6 are cited from Fillmore68, ande.g.
3-7, from Levin93.e.g.3-6 a. John opened the door with the key.b.
The key opened the door.c.
The door opened.d.
John ate the meal.
e. John ate.e.g.3-7 a. John pounded the metal \[flat\].b.
Metal pounded flat.c.
* Metal pounded.7 The decision point could be even delayed into thegeneration phase of MT.As is briefly mentioned in the previous sections, theentry in our lexicon is composed of three blocks: M(Morphology)-Block, S (Syntax)-Block and C(Concept)-Block.
M-Block contains the very surfaceinformation and can in general be linked to multipleS-Blocks.
A whole subcategorization frame isdescribed and stored in a S-Block coupled withcorresponding other syntactic features uch as aspectfeatures.
A C-Block linked from an S-Block or morerepresents an independent word sense, and, ideally, islinked to by other S-blocks that are linked to by otherM-Blocks, in effect, other words of the same or thedifferent language.The basic principle of the lexicon requires one to onecorrespondences between a subcategorization frameand an S-Block.
So, any sentence in e.g.
3-6 or e.g.
3-7 ~ corresponds to a different S-Block from the others(except for e.g.
3-7c that does not exist).
Any twoS-Blocks can share the same word sense (C-Block) aslong as the deep case (thematic role) frame isconsistent.
That is, all the case roles that appear ine.g.3-6 a, b and c are assigned different deep casesfrom one another: {John = AGenT, door = PATient,key = INStrument}.
So are all the case roles in e.g.3-6 a and b, and all the case roles in e.g.
3.7.
Thus,our system of the lexicon could guarantee that thesesubcategorization frame s of intuitively the same wordsense share the same C-Block.There are other cases in which the above criteriarequire to separate the intuitively single word sense asis shown in e.g.
3-8e.g.3-8a.
John smeared the window\[PATient\] withthe paint.b.
John smeared thepaint\[PATient\] on the window.If a lexicographer is asked to fill in the deep cases asusual in the S-Blocks of e.g.3-8 a and b, he or she willassign PATient on window in e.g.3-8 a, and on paintin e.g.3-8 b.
This inconsistency in the case assign-ment does not allow the lexicon to allocate the sameC-Block to both e.g.3-8 a and b. NJ&B94 gives asolution to this kind of case by introducing somedeeper conceptual primitives than our deep cases.4.
The Development Results of aComputational Japanese Lexicon for MTWe have developed a computational Japaneselexicon with more than 80 thousand words, 30thousand of which are verbs and their derivations.
Akey part of the development was to establish word8 Lexical Entry for the verb 'pound' : M-block: { pound }S-block 1: { Sub=AGT, Dobj=OBJ, \[Comp=TARstat\] } S-block2 {Subj=OBJ, Comp=TARstat \] C-block:CP{POUND}/*Strike repeatedly& forcefully, so the formof object be altered to meet the agent's purposes */644senses by means of comparing synonymousvocabulary sets of Japanese and English \[Nomura89\].Each verb subcategorization frame is coded in whatwe call S-Block that is placed between M-Block thatcontains the very surface level information and C-Block that is supposed to contain languageindependent, purely conceptual information.Among 34 deep cases we defined for the Interlingua,which is fewer than those in previous (e.g.
NagaoS0),16 are currently used in the deep frame of ourJapanese verb frame system.
(Fig.5)PATient,EXPeriencer, AGenT, INStrument, MEAns, REAson,ISOuRce, GOAl, LOCotion, BENeficiory, TARget,~PaRTicipant, CAPacity, FoCuS, MATeriot, ELMenT llqg.5 The 16 Deep Cases Described in the SubcategorizationFrames for Japanese Verbs and Prediwttive AdjectivesThe result of coding subcategorization fi'ames for 30thousand verbs have listed up 18 case postpositionsand standard word order used for verbs, and six, usedfor predicative adjectives.
These figures are muchsmaller than the number of simple combinations: 7!
=823,543.
The numbers of voice conversion types thataffects the surface case pattern was 14% The non-weighted mean number of the case slots tbr eachlexicon is counted to 1.6 ; 30% of verbs are listed upto take multiple case patterns.
This figure seemsappropriate, considering the fact that most of Japanesetransitive verbs and intransitive verbs take separateword lorms.The numbers of the variations of subeategorizationframes in the lexicon was about 250 for ordinaryverbs and adjectives, and we have 150 more foridiomatic ones.
These are the figures alterdisregarding, of course, the variation of selectionalrestrictions.
The sum of these figures are also muchsmaller than that of simple combinations: (16C7) *(7!)
= 57657600.Exhaustive listing of 400 combinatorial subcategor-ization frames has contributed much to improve theaccuracy the contents in the lexicon.
The lexiconspecification by the proposed verb subcategorizationcodes and SCPF codes tins improved uniformity inquality and the speed of lexicon development aswell.5.
ConclusionWe proposed a knowledge representation frameworkfor verb subcategorizations with combinatorial codesfor the verb's surface case frame and deep case(thematic role) frame.
The Japanese lexicondeveloped by this design has comprehensiveThere are four other special ones that onlyreplaces deep case labels.information on the mapping between the surface caseframe and the deep case frame, and yet is free ofpotential combinatorial explosion due to an exhaustiveempirical research and development of Japanese verbsand auxiliary verbs.
The reduction of the number ofverb subeategorization codes was made possible bycarefully identifying superficially different caseframes with the idea of alternative ase markers andsemantic roles.
The benefits include more manage-able, repeatable lexicon realized by reducing theunderlying redundancy of information in somedistributed architecture of the computational lexicon.The future tasks should include further explorations ofproviding the concept dictionary with more syntactictest conditions and extensions to more than twolanguages other than English and Japanese.References:Chomsky88, Chomsky, N., Language and the Problems ofKnowledge: the Managua Lectures, MIT PressEDR94, Electronic Dictionary Research Institute Ltd., EDRElectronic Dictionary User's Guide Ver.
2.0, 1994Filhnore68, Fillmore, C., J., The Case for Case, in : Bachand Harms (eds.
), Universals in Linguistic Theory (Holt,Rinehart and Winston, New York, 1968) 1-90FM&T85: Fukui, N., S. Miyagawa, and C. Tenny.
(1985).Verb Classes in English and Japanese: A Case Study in theInteraction of Syntax, Morphology and Semantics.,Lexicon Project Working Papers #3, MIT.Grishman94: Grishman, R. et al, Comlex Syntax :Building a Computational Lexicon section 2.1SubcategorizationHornby75, Hornby, A., S., Guide to Patterns and Usage inEnglish, second edition, Oxford University Press, 1975Jackendoff90, Jackendoff, R., Semantic Structures,Cambridge, MA: MITPress, 1990Jackendof193, Jackendoff, R. (1993).
On the Role ofConceptual Structure in Argument Selection: A Reply toEmends.
Natural Language and Linguistic Theory, 11.Levin93: Levin, Beth, English Verb Classes andAlternations, English Verb Classes and Alternations ~ APreliminary Investigation, The University of Chicago Press.Martin75, S.E.
(1975).
A Reference Grammar of Japanese,Yale University Press.Muraki87, K.Muraki "PIVOT: A Two Phase MachineTranslation System", MT Summit, pp.81-83, Japan, 1987Nagao80: Nagao,M., Tsujii, J., Mitamura, K., Hirakawa, H.and Kume, M., A Machine Translation System fromJapanese into English," COL1NG-80, pp414-423NJ&B94: Nomura, N., Jones, D., & Berwick, R., AnArchitecture for a Universal Lexicon, in the Proceedings ofCOLING94Nomura89: Nomura, N., Muraki,K.
:'Case frame model ofMachine Translation system PIVOT', Proceedings of 38thIPSJ Conference, 1989Pustejovsky9h Pustejovsky, J., The Generative Lexicon.Computational Linguistics, 17.4.645
