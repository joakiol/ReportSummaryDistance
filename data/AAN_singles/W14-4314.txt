Proceedings of the SIGDIAL 2014 Conference, pages 98?107,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsAn easy method to make dialogue systems incrementalHatim KHOUZAIMIOrange LabsLaboratoire Informatique d?Avignonhatim.khouzaimi@orange.comRomain LAROCHEOrange Labs,Issy-les-Moulineaux,Franceromain.laroche@orange.comFabrice LEFEVRELaboratoire Informatique d?Avignon,Avignon, Francefabrice.lefevre@univ-avignon.frAbstractIncrementality as a way of managing theinteractions between a dialogue systemand its users has been shown to haveconcrete advantages over the traditionalturn-taking frame.
Incremental systemsare more reactive, more human-like, of-fer a better user experience and allow theuser to correct errors faster, hence avoid-ing desynchronisations.
Several incremen-tal models have been proposed, however,their core underlying architecture is dif-ferent from the classical dialogue systems.As a result, they have to be implementedfrom scratch.
In this paper, we propose amethod to transform traditional dialoguesystems into incremental ones.
A newmodule, called the Scheduler is insertedbetween the client and the service so thatfrom the client?s point of view, the sys-tem behaves incrementally, even thoughthe service does not.1 IntroductionAn incremental compiler (Lock, 1965) processeseach instruction irrespectively from the others sothat local modifications of the source code do notaffect the global result.
This idea of incrementalityhas been adapted to the field of natural languageanalysis (Wir?n, 1992): instead of feeding mod-ules with full utterances, the input signal is deliv-ered and processed chunk by chunk (word by wordfor example) and each new piece engenders a newoutput hypothesis.Human beings behave similarly when interact-ing with each other (Levelt, 1989; Clark, 1996).They understand each other gradually when theyspeak, they can interrupt each other and the lis-tener is able to predict the end of an utterance be-fore it is fully pronounced by the speaker (Tanen-haus et al., 1995; Brown-Schmidt and Hanna,2011; DeVault et al., 2011).
Reading is also a taskthat we perform incrementally (Ilkin and Sturt,2011).Traditional dialogue systems1work in a turn-taking manner.
The user pronounces his requestand after a silence is detected, the systems startsprocessing the utterance and planning an answer.Some systems can even allow the user to barge inon them, however, they do not take the timing ofthe interruption into account nor try to link it withthe system?s utterance.
On the other hand, incre-mental dialogue systems process the user?s requestchunk by chunk as the latter is divided in severalincremental units (IU) (Schlangen and Skantze,2011).
They keep a hypothetical user request thatevolves as new IUs arrive as input.
The responseto this hypothesis can be used to make live feed-back to the user using voice or other modalities ifavailable.
As opposed to traditional systems, whenthe user interrupts the system, the content and thetiming of its utterance are taken into account (Mat-suyama et al., 2009; Selfridge et al., 2013) to de-termine how to act on it.
Therefore, incrementalsystems have been shown to be more reactive, tooffer a more human-like experience (Edlund et al.,2008) and to correct errors faster hence achievingbetter results in terms of user experience (Skantzeand Schlangen, 2009; Baumann and Schlangen,2013; El Asri et al., 2014) and task completion(Matthias, 2008; El Asri et al., 2014).Many incremental architectures have alreadybeen proposed.
Nevertheless, designing systemsbased on them requires an implementation fromscratch as they are fundamentally different fromtraditional dialogue systems.
The objective of thispaper is to propose a method of transforming a tra-ditional system into an incremental one at minimalcost.
A new module called the Scheduler is in-serted between the client and the service so that1We will use the expression traditional dialogue systemsto talk about non incremental ones.98from the client?s point of view, the system behavesincrementally, even though the service works in atraditional way.Section 2 draws a state-of-the-art concerning in-cremental dialogue systems.
The architecture pro-posed here and the role of the Scheduler are pre-sented in Section 3.
In Section 4, two implemen-tations of our method are presented: CFAsT andDictaNum.
Then, a discussion is held in Section5 before concluding the paper and presenting ournext objectives in Section 6.2 Related workDialogue systems can be split into four groupsaccording to how they integrate incrementalityin their behaviour.
Traditional dialogue systems(Laroche et al., 2011) form the first categorywhereas the second one refers to systems thatpropose some incremental strategies among tra-ditional others (El Asri et al., 2014).
The ar-chitecture presented in this paper belongs to thethird group which contains incremental systemsbased on a traditional inner behaviour (Hastie etal., 2013; Selfridge et al., 2012).
The fourth cate-gory contains incremental systems where internalmodules work incrementally (Dohsaka and Shi-mazu, 1997; Allen et al., 2001; Schlangen andSkantze, 2011).
Figure 1 discussed later providesa list of the features that are available in each cat-egory.Several dialogue strategies have been imple-mented in NASTIA (El Asri et al., 2014), a dia-logue system helping the user to find a date anda time for an appointment with a technician (com-pleting the work made during the European projectCLASSiC (Laroche and Putois, 2010)).
Amongthem, List of Availabilities is an incremental strat-egy where the system enumerates a list of alterna-tives for the appointment.
The user is supposed tointerrupt this enumeration when he hears an op-tion that is convenient for him.
An experimentshowed that List of Availabilities produced betterresults than other traditional strategies in terms oftask completion and user satisfaction.PARLANCE (Hastie et al., 2013) is an exam-ple of a third category system (it was developedin the European project PARLANCE).
Its archi-tecture is similar to the traditional ones but it inte-grates a new module, called MIM (Micro-turn In-teraction Manager), which decides when the sys-tem should speak, listen to the user and when itshould generate back-channels.
The closest ap-proach to the method introduced in this paper ispresented in (Selfridge et al., 2012) : the IIM (In-cremental Interaction Manager) is an intermediatemodule between an incremental ASR and a TTSon the one hand and the service on the other hand.Instead of replicating the dialogue context as it issuggested in this paper, different instances of theservice are run.
Moreover, the IIM is introduced aspreliminary work in order to simulate incremen-tal dialogue whereas in this paper, the Schedulerapproach is fully studied and placed into the con-text of the current state-of-the-art concerning in-cremental dialogue.
It is also viewed as a newlayer that can be extended later on, into a smartturn-taking manager.The architecture proposed in (Dohsaka and Shi-mazu, 1997) contains eight modules that work inparallel: the Speech Recognizer, the ResponseAnalyzer, the Dialogue Controller, the ProblemSolver, the Utterance Planner, the Utterance Con-troller, the Speech Synthesizer and the Pause Mon-itor.
The user asks the system to solve a problem.Then, his request is submitted incrementally to theSpeech Recognizer which sends its output text tothe Response Analyzer that figures out concepts tobe sent to the Dialogue Controller.
The latter in-teracts with the Problem Solver and the UtterancePlanner in order to compute a solution that is com-municated to the user through the Utterance Con-troller then the Speech Synthesizer.
This systembelongs to the fourth category as all its modulesbehave incrementally in order to start suggestinga solution to the user?s problem before it is to-tally computed.
In the same category, (Allen et al.,2001) proposes another architectures split in threemain modules: the Interpretation Manager, the Be-havioral Agent and the Generation Manager.
Thefirst module catches the user?s request and broad-casts it incrementally inside the system.
The sec-ond one manages the system?s action plan and thethird is in charge of the response delivery.A general and abstract model is introduced in(Schlangen and Skantze, 2011).
A dialogue sys-tem can be viewed as a chain of modules.
Eachmodule has a Left Buffer (LB) where its inputs arepushed, an Internal State (IS) and a Right Buffer(RB) where it makes its outputs available.
Data(audio, text, concepts...) flows through these mod-ules in the form of Incremental Units (IU).
Whenan IU is put in the LB of a module, it can be pro-99cessed immediately hence modifying its RB.
Forexample, every 500 ms, a new IU in the form ofa chunk of audio signal can be put into the LBof the ASR which can modify its output accord-ing to what the user said during this time window.All dialogue systems from the four categories canbe viewed as instances of this general model: wecan now see that a non-incremental system can becharacterised as a special case of an incrementalsystem, namely one where IUs are always maxi-mally complete [...] and where all modules updatein one go.In this paper, we introduce an architecture thatbelongs to the third category.
In comparison withthe first two categories, these systems behave in-crementally during the whole dialogue.
On theother hand, they can be built at a lower cost thanthe systems from the fourth category.3 ArchitectureTraditional dialogue systems are generally com-posed of a client on the user?s terminal and a ser-vice that is deployed on a remote machine.
Theywork in a turn-taking manner as when the userspeaks, the system waits until the end of his re-quest before processing it and vice versa (exceptfor some systems where the user can interrupt thesystem).
To make such a system incremental, wesuggest inserting a new module between the clientand the service: the Scheduler (this denominationis taken from (Laroche, 2010)).
This new archi-tecture can be cast as an instance of the generalabstract model of (Schlangen and Skantze, 2011).The client, the Scheduler and the service are thethree modules that compose the system.
The firsttwo ones are incremental but the last one is not.We will not use the notions of LB and RB andwill consider that these modules interact with eachother through some channel (network in the caseof our implementation, see Section 4).3.1 The traditional architectureIn a traditional architecture, the client receives astream of data (audio signal, string...).
If it is notthe case (a web interface where each button rep-resents a request for example), it does not makesense to transform such a system in an incremen-tal one, so they are out of the scope of this paper.The end of a request is determined by a conditionEndTurnCond.
It can be a long enough silence(Raux and Eskenazi, 2008; Wlodarczak and Wag-ner, 2013) in the case of vocal services or a car-riage return for text systems.
A dialogue turn isthe time interval during which the user sends a re-quest to the system and gets a response.
Theseturns will be called T1, T2, ..., Tk... and each oneof them can be split into a user turn Tk,Uand asystem turn Tk,S: Tk= Tk,U?
Tk,S.
During theuser turn, a request Reqkis sent and during thesystem turn, the corresponding response Respkisreceived.
The instant when a condition goes fromfalse to true will be called its activation time.
Asa consequence, Tk,Uends at the activation timeof EndTurnCond and Tk,Sis finished when thesystem gives the floor to the user.The service is made up of three parts: the inter-nal interface, the internal context and the externalinterface.
The internal interface manages the inter-actions between the service and the client.
The in-ternal context handles the way the client?s requestsshould be acted on and the external interface is incharge of the interactions with the external world(database, remote device...).3.2 Incrementality integrationThe way the client sends the user?s request to theservice should be modified in order to make thesystem incremental.
A new sending condition isdefined: EndMicroTurnCond and it is less re-strictive than EndTurnCond (which makes thelatter imply the former).
Therefore, the new clientsends requests more frequently than the traditionalone.
A user micro-turn is the time interval betweentwo activation times of EndMicroTurnCond sothe user turn Tk,Ucan be divided into nk,Uusermicro-turns ?Tk,Ui: Tk,U=?nk,Ui=1?Tk,Ui.
Wealso define the pthsub-turn of the user turn Tk,Uas: Tk,Up=?pi=1?Tk,Ui.
The union symbol isused as we concatenate time intervals.
In gen-eral, EndMicroTurnCond can be activated ata constant frequency or at each new input madeby the user.
Moreover, when EndTurnCond isactivated, the Scheduler is informed by the clientthanks to a dedicated signal: signal_ETC.
At eachTk,S, the user makes a new request but at themicro-turn ?Tk,Siwith i < nk,U, the complete re-quest is not available yet.
Consequently, a tempo-rary request which we will call sub-request (Reqki)is sent.
Sending the whole request from the begin-ning of the turn at each micro-turn is called restartincremental processing (Schlangen and Skantze,2011).
Let us notice that if i1< i2then Reqki1100is not necessarily a prefix of Reqki2(in spoken di-alogue, a new input in the ASR can modify thewhole or a big part of the output).The Scheduler is an intermediate module be-tween the client and the service whose aim is tomake the combination {Scheduler + Service} be-have incrementally from the client?s point of view.We define ServiceReqCond as the condition con-straining the Scheduler to send a request to the sys-tem or not.
At each user micro-turn ?Tk,Si, it re-ceives a sub-request Reqki.
If ServiceReqCondis true, the latter is sent to the system and thecorresponding response Respkiis stored so thatthe client can ask for it later.
For example,ServiceReqCond can be constantly true whichmakes the Scheduler send all the sub-requests thatit receives or it can be activated only if the newsub-request is different from the previous one (ifthe client already behaves the same way throughEndMicroTurnCond it is redundant to do so inServiceReqCond too).The end of a turn is determined by the Sched-uler.
This module decides when to validate thecurrent sub-request and to no longer wait for newinformation to complete it.
It engages the di-alogue in the direction of this hypothesis as itis considered as the user?s intent.
The Sched-uler is said to commit the sub-request (Schlangenand Skantze, 2011) (this notion is described inSection 3.3).
We define CommitCond as thecondition for the Scheduler to commit a hy-pothesis.
For example, in the case of a sys-tem that asks for a 10 digits phone number,CommitCond = (length(num) == 10) wherelength(num) is the number of digits in each sub-request.
Hence, a user turn ends at the activa-tion time of CommitCond and not when a sig-nal_ETC is received.
However, EndTurnCondimplies CommitCond.The client is made of two threads: the send-ing thread and the recuperation thread.
The firstone is in charge of sending sub-requests at eachmicro-turn and the second one gets the last re-sponse hypothesis available in the Scheduler.
Therecuperation thread is activated at the same fre-quency as micro-turns so that the client is alwaysup to date.
In the case of vocal services, it is theScheduler?s task to decide which intermediate re-sponses should be pronounced by the system andwhich ones should be ignored.
Therefore, a flagin the message must be set by this module to de-clare whether it has to be outputted or not.
Whenthe recuperation thread gets new messages fromthe Scheduler, it decides whether to send it to theText-To-Speech module or not based on the valueof this flag.The service in our architecture is kept un-changed (apart from some changes at the ap-plicative level, see Section 4.2).
The only func-tional modification is that the context is dupli-cated: the simulation context (see Section 3.3) isadded.
When a new sub-request is received bythe Scheduler and ServiceReqCond is true, anincomplete request (sub-request) is sent to the ser-vice.
Therefore, the system knows what would bethe response of a sub-request if it has to be com-mitted.
As the service is not incremental and can-not process the request chunk by chunk, all the in-crements from the beginning of the turn have tobe sent and that is what justifies the choice of therestart incremental mode.The service can also order the Schedulerto commit.
This behaviour is described in(Schlangen and Skantze, 2011) where the IUs inthe RB of a module are grounded in the ones inthe LB that generated them.
Consequently, whena module decides to commit to an output IU, allthe IUs that it is grounded in must be committed.In our architecture, when the service commits tothe result of a request (if it already started deliv-ering the response to the user for example), thisrequest has to be committed by the Scheduler.On the other hand, as we defined the usermicro-turn, we can introduce the system micro-turn.
In traditional systems, the service?s re-sponse is played by the TTS during the system turnTk,S.
In incremental dialogue, this turn can be di-vided into nkSsystem micro-turns ?Tk,Si: Tk,S=?nkSi=1?Tk,Si.
Their duration depends on the waythe service decides to chunk its response (for ex-ample, every item in an enumeration can be con-sidered as a chunk).
When the user interrupts thesystem, the timing of his interruption is given bythe micro-turn during which he reacted.
Moreover,when the user barges in, a new tour is started.
Onlyvocal systems are concerned with this behaviour astextual systems cannot be interrupted (the wholeservice response is displayed instantly).3.3 Commit, rollback and double contextThe request hypothesis fluctuates as long as newincrements are taken into account.
However, at101some point, the system has to take an action thatis based on the last hypothesis and visible by theuser.
For example, a response may be sent to theTTS or a database can be modified.
At that point,the system is said to commit to its last hypothe-sis which means that it engages the dialogue ac-cording to its understanding of the request at thatmoment.
It no longer waits for other incrementalunits to complete the request as it can no longerchange it.
On the contrary, the system can decideto forget its last hypothesis and come back to thestate it was in at the moment of the last commit.This operation is called rollback (both terms aretaken from the database terminology).Most of the requests sent by the Scheduler to theservice are aimed to know what would the latterrespond if the current hypothesis contains all theinformation about the user?s intent.
Consequently,these requests should not modify the current con-text of the dialogue.
We suggest that the servicemaintains two contexts: the real context and thesimulation context.
The first one plays the samerole as the classical context whereas the secondone is a buffer that can be modified by partial re-quests.In our architecture, committing to a hypothesiswill be made by copying the content of the sim-ulation context (generated by the current requesthypothesis) into the real context.
On the opposite,a rollback is performed by copying the real con-text into the simulation one, hence going back tothe state the system was in right after the last com-mit.Every user micro-turn, the client sends to theScheduler the whole user?s sub-request since thelast commit.
This incomplete request is thensent to the service and the answer is stored inthe Scheduler.
If during the next micro-turn, theScheduler does not ask for a commit but needs tosend a new sub-request instead, a rollback signal issent first as the system works in a restart incremen-tal way (in this paper, rollbacks are only performedin this case).
Figures A.1 and A.2 represent theway our three modules interact and how the dou-ble context is handled.
In Figure A.1, the con-ditions EndTurnCond, EndMicroTurnCond,ServiceReqCond and CommitCond are writtenon the left of the streams they generate.
On the leftof the figure, the times where the sending thread ofthe client is active and inactive are represented anddashed arrows represent streams that are receivedby the recuperation thread.
They are not synchro-nized with the rest of the streams, even thoughthey are in this figure (for more clarity).
Also, thecommit decision has been taken by the Schedulerafter it received a signal_ETC which is not alwaysthe case.We call ctxt(Tk) the real context at the end ofTk(ctxt(T0) being the initial context at the begin-ning of the dialogue).
The context is not modifiedduring the system turn, hence, we may notice thatctxt(Tk,U) = ctxt(Tk).
During the commit at theend of Tk,U, the simulated context is copied intothe real context: ctxt(Tk) = ctxt(Tk?1+Tk,Unk,U).4 ImplementationsWe implemented our method in the case of twodialogue systems developed at Orange Labs.
Thefirst one is a text service where the client is a webinterface and the second one is a vocal service de-signed to record numbers.
With only a few modifi-cations, these two systems have been made incre-mental, showing that our solution is easy to im-plement, and demonstrating the incremental be-haviour of the transformed systems, in the limitof the implemented strategies and according tothe modalities that have been used (text and vocalmodes).4.1 CFAsT: Content Finder AssitanTCFAsT is an application developed at Orange Labsand which can be used to generate textual dialoguesystems and whose objective is to help the usersearch for some specific content in a database.The client is a web page with a text-box wherethe user can type a request using natural language(validated by a carriage return or by clicking onthe validate button).
This page also containsbuttons representing keywords or content sugges-tions.
In this implementation, the content basechosen is the list of accepted papers at the NIPS2013 conference.
A list of keywords is maintainedthrough the interaction.
It is initially empty and foreach new request, if new keywords are detected,they are added to the list.
The interaction endswhen the user selects a unique content.In our implementation2, the client is made oftwo screens.
The first one contains the sameview as the classical system and the secondone fluctuates incrementally.
When the user istyping a request, the second view is updated2http://dialogue.orange-labs.fr/CFAsTIncrEng/102each time the space button is hit: it showsthe answer that the service would have givenin case of a carriage return at that moment.When a request is validated, a commit is per-formed and the two views are identical.
In thiscase: EndMicroTurnCond is activated whenthe space button is hit (ServiceReqCond doesnot filtrate any sub-request) and EndTurnCondis true if a carriage return is detected.
In addition,CommitCond = EndTurnCond.4.2 DictaNumThe second implementation is a vocal systemcalled DictaNum and inspired by NUMBERS di-alogue system (Skantze and Schlangen, 2009).
Itasks the user to dictate a number and then givesa feedback to confirm that it has been well un-derstood.
The client is an HTML web page thatinteracts with the Scheduler using AJAX3.
It usesthe Google web API for both the ASR and TTStasks.
Other existing systems ask the user to dic-tate a number (telephone, credit card...) such asHow may I help you?
(Langkilde et al., 1999).Here is an example of an interaction with the tra-ditional version of DictaNum:System: Welcome to the DictaNum service.
Please dictateyour number.User: 01 45 65 79 98.System: The dictated number is: 01 45 67 79 98.
Is thatcorrect?User: No.System: Sorry.
Let us try again.
Please dictate your number.User: 01 45 65 79 98.System: The dictated number is: 01 47 65 79 98.
Is thatcorrect?User: No.System: Sorry.
Let us try again.
Please dictate your number.[...
]System: The dictated number is: 01 45 65 79 98.
Is thatcorrect?User: Yes.System: Thank you for using DictaNum.
Bye.If the user?s request has not been understoodcorrectly in one shot, he has to dictate it again.This is not an optimal strategy.
DictaNum hasbeen modified to support chunk by chunk dicta-tion as in the following example:3http://dialogue.orange-labs.fr/DictaNumEng/System: Welcome to the DictaNum service.
Please dictateyour number.User: 01 45System: 01 45User: 65 79System: 67 79User: No, 65 79System: Sorry, 65 79User: 98System: 98User: ...System: The dictated number is: 01 45 65 79 98.
Is thatcorrect?User: Yes.System: Thank you for using DictaNum.
Bye.In order to generate feedbacks, the service hasbeen modified at the applicative level.
It maintainsa string that is supposed to contain the completenumber at the end of the interaction.
Initially, thisstring is empty.
When a silence is detected af-ter a chunk is dictated, the system repeats the lat-ter as a feedback to the user and concatenates itat the end of the number string.
If the user be-gins a new chunk with No, the system understandsthat it has to correct the last one (starting the nextfeedback with Sorry...), otherwise, it keeps it andmoves forward in the dictation.
Finally, if aftera feedback a silence is detected with nothing dic-tated, the system understands that the dictation isover and makes a general feedback over the wholenumber.These modifications are not enough for the sys-tem to be used in an incremental way.
It is notoptimal for the user to insert silences in his dic-tation.
Of course, he can, but it is not convenientnor natural.
The client has been modified so that itno longer waits for a silence to send the user?s re-quest, instead, it sends a partial request every 500ms (EndMicroTurnCond).
The partial requestis sent on a restart incremental mode.Also, DictaNum can detect silences in a micro-turn level.
We call ?sthe silence threshold usedto determine the end of a request in the tradi-tional system and we introduce a new threshold?ssuch as ?s?
?s.
A silence whose duration isgreater than ?sis called micro-silence.
The sys-tem has been modified in order to detect theseshorter silences during the dictation, to commit(EndTurnCond = CommitCond) and delivera feedback right after.
Additionally, our system?s103response time is very short, the feedback messageis available before the end of the micro-silence, soit is fed to the TTS without any delay.
If ?s= ?s,it is more convenient to dictate the number in oneshot.
Therefore, moving ?sbetween zero and ?screates a continuum between traditional systemsand incremental ones.
One may argue that thesemodifications are enough and no incremental be-haviour is required, but the response delay will behigher, hence, the user will not wait for any feed-back and will try to dictate his number in one shot.If the user manifests a silence that is longer than?sright after a feedback, the dictation ends anda general feedback is made to confirm the wholenumber.
In our system, silences are determined bythe number micro-turns during which there is nonew input from the ASR but we could have usedthe VAD (Voice Activity Detection) (Breslin et al.,2013).We set EndMicroTurnCond to be activatedby a 2 Hz clock and at every micro-turn, theScheduler checks whether the new request is dif-ferent from the previous one (ServiceReqCond).If that is the case, a rollback signal is sent followedby all the digits in the current number fragment.When a micro-silence is detected, a string silenceis sent to the Scheduler (as signal_ETC) and that iswhen the Scheduler decides to commit.
The recu-peration thread requests the last message from theservice with the same frequency as micro-turns, sowhen CommitCond is activated, the feedback isalready available and is delivered instantly to theTTS.Finally, it is also possible for the user to in-terrupt the system during the final feedback.
Todo so, the service sends a feedback message inthe following format: The dictated number is: 01<sep> 45 <sep> 65 <sep> 79 <sep> 98.
Is thatcorrect?.
The <sep> is a separator that is used todelimit the system micro-turns ?Tk,Si.
They arepronounced one after another by the TTS.
As a re-sult, a dictation may end like this:System: The dictated number is: 01 45 67 ...User: No, 65.System: Sorry.
The dictated number is: 01 45 65 79 98.
Isthat correct?User: Yes.System: Thank you for using DictaNum.
Bye.After the interruption, a message sent to the ser-vice under the following format: {part of the re-quest that has been pronounced so far | barge-incontent}.
In our example, this message is {Thedictated number is: 01 45 67 | No, 65} whichmakes the service know how to perform the cor-rection (or not, if the interruption is just a confir-mation for example).5 DiscussionIncremental dialogue systems present new fea-tures compared to traditional ones.
In this section,we analyse the abilities of these systems given theway they integrate incrementality.
To do so, weclassify them as suggested in Section 2.
Figure1 summarizes the features discussed.
These fea-tures are specific to incremental dialogue systems,so they do not exist in the first category.
On thecontrary, they have all been implemented in sys-tems from the fourth category.To interact with the NASTIA service, the userhas to call a vocal platform which handles the ASRand TTS tasks.
It has been configured in order tointerrupt the TTS when activity is detected in theASR.
When using the List of Availabilities strat-egy, each item during an enumeration is a dialogueturn where the timeout duration is set to a lowvalue (time to declare that the user did not answer)so that if he does not barge-in, the system moves tothe next item of the list.
If the user speaks, the TTSis stopped by the vocal platform and the user?s ut-terance and its timing are communicated to the ser-vice.
The latter can ignore the barge-in (if the usersays No for example) or select an item in the listaccording to this input.
Some traditional systemsallow the user to interrupt them but they do nottake the content of the utterance into account norits timing (in order to make the link with the utter-ance of the TTS).
Hence, these two features can beimplemented in a dialogue system provided thatit is permanently listening to the user and that itcatches his utterance and its timing.
These condi-tions are true for systems from the third categorywhich make it possible for them to integrate thesefeatures.Incremental dialogue systems can sometimesdetect desynchronisations before the user has fin-ished his utterance.
Therefore, the dialogue wouldtake less time if the system can interrupt the userasking him to repeat his request.
Feedbacks arealso a form of interrupt as it is the case for Dic-taNum because they are uttered after a short si-104Features Category 1 Category 2 Category 3 Category 4TTS interruption after input analysis - + + +Link interruption time with TTS - + + +User interruption by the system - - + +Better reactivity - - + +Optimal processing cost - - - +Figure 1: Available features for dialogue systems given the way they integrate incrementalitylence (micro-silence).
These features can only beimplemented in systems from the third and thefourth group, as for the the first two ones, the sys-tem is only requested at the end of a user?s utter-ance.As far as reactivity is concerned, systems fromthe third and the fourth category process the user?srequest every time that a new increment is pushedinto the system.
Therefore, when the end of therequest is detected (long enough silence), the ser-vice?s response is already ready and can be de-livered immediately.
On the other hand, systemsfrom group 1 and 2 wait until the end of the user?sutterance to send the request to the service, hence,being less reactive.
However, systems from thethird group work on a restart incremental, repro-cessing the whole request at each new increment.On the contrary, systems from the fourth cate-gory can process the request increment by incre-ment hence optimizing the processing cost.
Some-times, a new increment can modify the whole re-quest (or a part of it) and those systems are de-signed to handle this too by canceling some pre-vious processing (revoke mechanism (Schlangenand Skantze, 2011)).
While integrating incremen-tality in CFAsT and DictaNum, we noticed thatthe system responded so quickly that no efforts arenecessary to optimise the processing time.
How-ever, systems from the fourth group can make thedifference if the system needs to process tasks thatcreate a delay (slow access to a remote databasefor example).In our method, the service is not modified in afunctional level (except from the double contextmanagement).
However, as it is the case for Dic-taNum, some modifications at the applicative levelmight be compulsory.
The Scheduler is not sup-posed to generate messages by himself or to per-form traditional dialogue management tasks.
Asa consequence, when one needs to add some newfeedback messages at the micro-turn level or thepossibility to correct an utterance, these featuresmust be implemented in the service.Finally, in order for the Scheduler to decidewhen to commit and when to take the floor inan optimal way, it might need information com-ing from the back-end modules.
Once again, thisshould be handled in the applicative level.
A fu-ture paper, focused on how to implement systemsusing the Scheduler, will cover the ideas brieflydescribed in the last two paragraphs.6 Conclusion and future workThis paper describes a method for transforminga traditional dialogue system into an incremen-tal one.
The Scheduler is an intermediate mod-ule that is inserted between the client and the ser-vice.
From the client?s point of view, the system?sbehaviour is incremental despite the fact that theservice works in a traditional turn-taking manner.Most requests that are sent by the Scheduler to theservice are aimed to see what would be the answerif the current request hypothesis is the final one.In this case, the service?s context should not bemodified.
Therefore, two context have to be main-tained: the real context and the simulated one.This solution has been implemented in the caseof a textual dialogue system generated by theCFAsT application.
It helps the user navigatethrough the NIPS 2013 proceedings titles.
It hasalso been used to make a vocal system incremen-tal: DictaNum.
This service asks the users to dic-tate a number and confirms that it has been wellunderstood.In the future, we will explore how to make theScheduler learn when to commit the current re-quest hypothesis and when to take the floor.
Wewill use reinforcement learning to figure out theoptimal strategies.105ReferencesJames Allen, George Ferguson, and Amanda Stent.2001.
An architecture for more realistic conversa-tional systems.
In 6th international conference onIntelligent user interfaces.Timo Baumann and David Schlangen.
2013.
Open-ended, extensible system utterances are preferred,even if they require filled pauses.
In Proceedingsof the SIGDIAL 2013 Conference.Catherine Breslin, Milica Gasic, Matthew Henderson,Dongho Kim, Martin Szummer, Blaise Thomson,Pirros Tsiakoulis, and Steve Young.
2013.
Con-tinuous asr for flexible incremental dialogue.
InICASSP, pages 8362?8366.Sarah Brown-Schmidt and Joy E. Hanna.
2011.Talking in another person?s shoes: Incrementalperspective-taking in language processing.
Dia-logue and Discourse, 2:11?33.Herbert H. Clark.
1996.
Using Language.
CambridgeUniversity Press.David DeVault, Kenji Sagae, and David Traum.
2011.Incremental interpretation and prediction of utter-ance meaning for interactive dialogue.
Dialogueand Discourse, 2:143?170.Kohji Dohsaka and Akira Shimazu.
1997.
A systemarchitecture for spoken utterance production in col-laborative dialogue.
In IJCAI.Jens Edlund, Joakim Gustafson, Mattias Heldner, andAnna Hjalmarsson.
2008.
Towards human-likespoken dialogue systems.
Speech Communication,50:630?645.Layla El Asri, Remi Lemonnier, Romain Laroche,Olivier Pietquin, and Hatim Khouzaimi.
2014.NASTIA: Negotiating Appointment Setting Inter-face.
In Proceedings of LREC.Helen Hastie, Marie-Aude Aufaure, et al.
2013.Demonstration of the parlance system: a data-drivenincremental, spoken dialogue system for interactivesearch.
In Proceedings of the SIGDIAL 2013 Con-ference.Zeynep Ilkin and Patrick Sturt.
2011.
Active predic-tion of syntactic information during sentence pro-cessing.
Dialogue and Discourse, 2:35?58.Irene Langkilde, Marilyn Anne Walker, Jerry Wright,Allen Gorin, and Diane Litman.
1999.
Auto-matic prediction of problematic human-computer di-alogues in how may i help you?
In ASRU99.R.
Laroche and G. Putois.
2010.
D5.5: Advancedappointment-scheduling system ?system 4?.
Proto-type D5.5, CLASSIC Project.R.
Laroche, G. Putois, et al.
2011.
D6.4: Final evalua-tion of classic towninfo and appointment schedulingsystems.
Report D6.4, CLASSIC Project.Romain Laroche.
2010.
Raisonnement sur les incerti-tudes et apprentissage pour les systemes de dialogueconventionnels.
Ph.D. thesis, Paris VI University.Willem J. M. Levelt.
1989.
Speaking: From Intentionto Articulation.
Cambridge, MA: MIT Press.Kenneth Lock.
1965.
Structuring programs for mul-tiprogram time-sharing on-line applications.
InAFIPS ?65 (Fall, part I) Proceedings of the Novem-ber 30?December 1, 1965, fall joint computer con-ference, part I.Kyoko Matsuyama, Kazunori Komatani, TetsuyaOgata, and Hiroshi G. Okuno.
2009.
Enabling auser to specify an item at any time during systemenumeration ?
item identification for barge-in-ableconversational dialogue systems ?.
In Proceedingsof the INTERSPEECH 2009 Conference.Gary M. Matthias.
2008.
Incremental speech un-derstanding in a multimodal web-based spoken di-alogue system.
Master?s thesis, Massachusetts Insti-tute of Technology.Antoine Raux and Maxine Eskenazi.
2008.
Optimiz-ing endpointing thresholds using dialogue featuresin a spoken dialogue system.
In SIGDIAL.David Schlangen and Gabriel Skantze.
2011.
A gen-eral, abstract model of incremental dialogue pro-cessing.
Dialogue and Discourse, 2:83?111.Ethan O. Selfridge, Iker Arizmendi, Peter A. Heeman,and Jason D. Williams.
2012.
Integrating incremen-tal speech recognition and pomdp-based dialoguesystems.
In Proceedings of the 13th Annual Meet-ing of the Special Interest Group on Discourse andDialogue, July.Ethan Selfridge, Iker Arizmendi, Peter Heeman, andJason Williams.
2013.
Continuously predicting andprocessing barge-in during a live spoken dialoguetask.
In Proceedings of the SIGDIAL 2013 Confer-ence.Gabriel Skantze and David Schlangen.
2009.
Incre-mental dialogue processing in a micro-domain.
InACL.Michael K. Tanenhaus, Michael J. Spivey-Knowlton,Kathleen M. Eberhard, and Julie C. Sedivy.
1995.Integration of visual and linguistic informationin spoken language comprehension.
Science,268:1632?1634.Mats Wir?n.
1992.
Studies in Incremental NaturalLanguage Analysis.
Ph.D. thesis, Link?ping Uni-versity, Link?ping, Sweden.Marcin Wlodarczak and Petra Wagner.
2013.
Effectsof talk-spurt silence boundary thresholds on distri-bution of gaps and overlaps.
In INTERSPEECHProceedings.106Scheduler ServiceClientReq(1,1)Req(1,1)Processing Resp(1,1)Req(1,2)rollback + Req(1,2)Processing Resp(1,2)Resp(1,1)Resp(1,1)Resp(1.2)Resp(1,2)signal_ETCcommitResp(1,2)Req(2,1)Req(2,1)Processing Resp(2,1)Resp(2,1)Resp(2,1)Req(2,2)rollback + Req(2,2)Processing Resp(2,2)Resp(2,2)Resp(2,2)Req(2,3)EndMicroTurnCondEndTurnCondServiceReqCondCommitCondEndMicroTurnCondEndMicroTurnCondEndMicroTurnCondEndMicroTurnCondServiceReqCondServiceReqCondServiceReqCondFigure A.1: The scheduler sub-requests management (The streams in dashed lines are received by therecuperation thread of the client).Turn User sub-turn Input Real context Simulation contextT1T1,U1Req11ctxt(T0) ctxt(T0+ T1,U1)T1,U2Req12ctxt(T0) ctxt(T0+ T1,U2)... ... ctxt(T0) ...T1,Un1,UReq1n1,Uctxt(T0) ctxt(T0+ T1,Un1,U)COMMIT: ctxt(T1) = ctxt(T0+ T1,Un1,U)T2T2,U1Req21ctxt(T1) ctxt(T1+ T2,U1)... ... ctxt(T1) ...Figure A.2: A double context: the real context and the simulation context.107
