Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 636?643, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsUMCC_DLSI: Semantic and Lexical features for detection andclassification Drugs in biomedical textsArmando Collazo, AlbertoCeballo, Dennys D. Puig, YoanGuti?rrez, Jos?
I. Abreu, RogerP?rezAntonio Fern?ndezOrqu?n, Andr?sMontoyo, Rafael Mu?ozFranc CamaraDI, University of MatanzasAutopista a Varadero km 3 ?Matanzas, Cuba{armando.collazo, dennys.puig,yoan.gutierrez, jose.abreu,roger.perez}@umcc.cu,alberto.ceballo@infonet.umcc.cuDLSI, University of AlicanteCarretera de San VicenteS/N Alicante, Spainantonybr@yahoo.com,{montoyo,rafael}@dlsi.ua.esIndependent ConsultantUSAinfo@franccamara.comAbstractIn this paper we describe UMCC_DLSI-(DDI) system which attempts to detect andclassify drug entities in biomedical texts.We discuss the use of semantic class andwords relevant domain, extracted with ISR-WN (Integration of Semantic Resourcesbased on WordNet) resource to obtain ourgoal.
Following this approach our systemobtained an F-Measure of 27.5% in theDDIExtraction 2013 (SemEval 2013 task9).1.
IntroductionTo understand biological processes, we mustclarify how some substances interact with ourbody and one to each other.
One of theseimportant relations is the drug-drug interactions(DDIs).
They occur when one drug interactswith another or when it affects the level, oractivity of another drug.
DDIs can change theway medications act in the body, they can causepowerful, dangerous and unexpected sideeffects, and also they can make the medicationsless effective.As suggested by (Segura-Bedmar et al 2011),?...the detection of DDI is an important researcharea in patient safety since these interactionscan become very dangerous and increase healthcare costs?.
More recent studies (Percha andAltman, 2013) reports that ?
?Recent estimatesindicate that DDIs cause nearly 74000emergency room visits and 195000hospitalizations each year in the USA?.But, on the other hand, there is an expansion inthe volume of published biomedical research,and therefore the underlying biomedicalknowledge base (Cohen and Hersh, 2005).Unfortunately, as often happens, thisinformation is unstructured or in the best casescenario semi-structured.As we can see in (Tari et al 2010), ?Clinicalsupport tools often provide comprehensive listsof DDIs, but they usually lack the supportingscientific evidences and different tools canreturn inconsistent results?.Although, as mentioned (Segura-Bedmar et al2011) ?there are different databases supportinghealthcare professionals in the detection of DDI,these databases are rarely complete, since theirupdate periods can reach up to three years?.
Inaddition to these and other difficulties, the greatamount of drug interactions are frequentlyreported in journals of clinical pharmacologyand technical reports, due to this fact, medicalliterature becomes most effective source fordetection of DDI.
Thereby, the management ofDDI is a critical issue due to the overwhelmingamount of information available on them(Segura-Bedmar et al 2011).6361.1.
Task DescriptionWith the aim of reducing the time the health careprofessionals invest on reviewing the literature,we present a feature-based system for drugdetection and classification in biomedical texts.The DDIExtraction2013 task was divided intotwo subtasks: Recognition and classification ofdrug names (Task 9.1) and Extraction of drug-drug interactions (Task 9.2).
Our system wasdeveloped to be presented in the Task 9.1.
In thiscase, participants were to detect and classify thedrugs that were present in the test data set whichwas a set of sentences related to the biomedicaldomain obtained from a segmented corpus.
Theoutput consisted of a list mentioning all thedetected drugs with information concerning thesentence it was detected from as well as itsoffset in that sentence (the position of the firstand the last character of the drug in the sentence,0 being the first character of a sentence).
Alsothe type of the drug should have been provided.As to the type, participants had to classifyentities in one of these four groups1:?
Drug: any chemical agent used fortreatment, cure, prevention or diagnose ofdiseases, which have been approved forhuman usage.?
Brand: any drug which firstly have beendeveloped by a pharmaceutical company.?
Group: any term in the text designating arelation among pharmaceutical substances.?
No-Human: any chemical agent whichaffects the human organism.
An activesubstance non-approved for human usageas medication.In the next section of the paper, we presentrelated works (Section 2).
In Section 3, wediscuss the feature-based system we propose.Evaluation results are discussed in Section 4.Finally, we conclude and propose future work(Section 5).2.
Related WorkOne of the most important workshops on thedomain of Bioinformatics has been BioCreAtIve(Critical Assessment of Information Extraction1 http://www.cs.york.ac.uk/semeval-2013/task9in Biology) (Hirschman et al 2005).
Thisworkshop has improved greatly the InformationExtraction techniques applied to the biologicaldomain.
The goal of the first BioCreAtIvEchallenge was to provide a set of commonevaluation tasks to assess the state-of-the-art fortext mining applied to biological problems.
Theworkshop was held in Granada, Spain on March28-31, 2004.According to Hirschman, the firstBioCreAtIvE assessment achieved a high levelof international participation (27 groups from 10countries).
The best system results for a basictask (gene name finding and normalization),where a balanced 80% precision/recall or better,which potentially makes them suitable for realapplications in biology.
The results for theadvanced task (functional annotation from freetext) were significantly lower, demonstrating thecurrent limitations of text-mining approaches.The greatest contribution of BioCreAtIve wasthe creation and release of training and test datasets for both tasks (Hirschman et al 2005).One of the seminal works where the issue ofdrug detection was mentioned was (Gr?nroos etal., 1995).
Authors argue the problem can besolved by using a computerized informationsystem, which includes medication data ofindividual patients as well as information aboutnon-therapeutic drug-effects.
Also, they suggesta computerized information system to builddecision support modules that, automaticallygive alarms or alerts of important drug effectsother than therapeutic effects.
If these warningsconcern laboratory tests, they would be checkedby a laboratory physician and only those withclinical significance would be sent to clinicians.Here, it is important to note the appearance ofthe knowledgebase DrugBank 2 .
Since its firstrelease in 2006 (Wishart et al 2008) it has beenwidely used to facilitate in silico drug targetdiscovery, drug design, drug docking orscreening, drug metabolism prediction, druginteraction prediction and generalpharmaceutical education.
DrugBank has alsosignificantly improved the power and simplicityof its structure query and text query searches.2 http://redpoll.pharmacy.ualberta.ca/drugbank/637Later on, in 2010 Tari propose an approachthat integrates text mining and automatedreasoning to derive DDIs (Tari et al 2010).Through the extraction of various facts of drugmetabolism, they extract, not only the explicitlyDDIs mentioned in text, but also the potentialinteractions that can be inferred by reasoning.This approach was able to find several potentialDDIs that are not present in DrugBank.
Thisanalysis revealed that 81.3% of theseinteractions are determined to be correct.On the DDIExtraction 2011 (Segura-Bedmar etal., 2011) workshop (First Challenge Task onDrug-Drug Interaction Extraction) the bestperformance was achieved by the team WBIfrom Humboldt-Universitat, Berlin.
This teamcombined several kernels and a case-basedreasoning (CBR) system, using a votingapproach.In this workshop relation extraction wasfrequently and successfully addressed bymachine learning methods.
Some of the morecommon used features were co-occurrences,character n-grams, Maximal FrequentSequences, bag-of-words, keywords, etc.Another used technique is distant supervision.The first system evaluating distant supervisionfor drug-drug interaction was presented in(Bobi?
et al 2012), they have proposed aconstraint to increase the quality of data used fortraining based on the assumption that no self-interaction of real-world objects are described insentences.
In addition, they merge informationfrom IntAct and the University of KansasProteomics Service (KUPS) database in order todetect frequent exceptions from the distantsupervision assumption and make use of moredata sources.Another important work related to BiomedicalNatural Language Processing was BioNLP(Bj?rne et al 2011) it is an application ofnatural language processing methods to analyzetextual data on biology and medicine, oftenresearch articles.
They argue that informationextraction techniques can be used to mine largetext datasets for relevant information, such asrelations between specific types of entities.Inspired in the previews works the system wepropose makes use of machine learning methodstoo, using some of the common featuresdescribed above, such as the n-grams andkeywords and co-occurrences, but we also addsome semantic information to enrich thosefeatures.3.
System DescriptionAs it has been mentioned before, the system wasdeveloped to detect and classify drugs inbiomedical texts, so the process is performed intwo main phases:?
drug detection.?
drug classification.Both phases are determined by the followingstages, described in Figure 1:I. PreprocessingII.
Feature extractionIII.
ClassificationFigure 1.
Walkthrough system process.Given a biomedical sentence, the systemobtains the lemmas and POS-tag of every tokenClassificationPre-Processing (using Freeling 2.2)Training set from Semeval 2013DDIExtraction2013 taskRun(3)MFSC?sCSC MF 2-grams, 3-gramsUCUCAMWordNIIIIIITokenizingRun(1) Run(2)CSC - AllEMFSCDRDCDGCInReWNumFeature ExtractionLemmatizingPOS tagging638of the sentence, by means of Freeling tool 3 .After that, it is able to generate candidatesaccording to certain parameters (see section 3.3).Then, all the generated candidates areprocessed to extract the features needed for thelearning methods, in order to determine whichcandidates are drugs.After the drugs are detected, the systemgenerates a tagged corpus, following theprovided training corpus structure, containingthe detected entities, and then it proceeds toclassify each one of them.
To do so, anothersupervised learning algorithm was used (seesection 3.3).3.1.
Candidates generationDrugs and drug groups, as every entity inNatural Language, follow certain grammaticalpatterns.
For instance, a drug is usually a nounor a set of nouns, or even a combination of verbsand nouns, especially verbs in the past participletense and gerunds.
But, one thing we noticed isthat both drugs and drug groups end with a nounand as to drug groups that noun is often in theplural.Based on that idea, we decided to generatecandidates starting from the end of eachsentence and going forward.Generation starts with the search of a pivotword, which in this case is a noun.
When thepivot is found, it is added to the candidates list,and then the algorithm takes the word before thepivot to see if it complies with one of thepatterns i.e.
if the word is a noun, an adjective, agerund or past participle verb.
If it does, then itand the pivot form another candidate.After that, the algorithm continues until it findsa word that does not comply with a pattern.
Inthis case, it goes to the next pivot and stopswhen all the nouns in the sentence have beenprocessed, or the first word of the sentence isreached.3.2.
Feature DescriptionFor the DDIExtraction20134 task 9 three runs ofthe same system were performed with different3 http://nlp.lsi.upc.edu/freeling/features each time.
The next sections describesthe features we used.3.2.1.
Most Frequent Semantic Classes(MFSC)Given a word, its semantic class label (Izquierdoet al 2007) is obtained from WordNet using theISR-WN resource (Guti?rrez et al 2011; 2010).The semantic class is that associated to the mostprobable sense of the word.
For each entity inthe training set we take the words in the samesentence and for each word its semantic class isdetermined.
This way, we identify the 4005 mostfrequent semantic classes associated to wordssurrounding the entities in the training set.For a candidate entity we use 400 features toencode information with regard to whether ornot in its same sentence a word can be foundbelonging to one of the most frequent semanticclasses.Each one of these features takes a valuerepresenting the distance (measured in words) acandidate is from the nearest word with samesemantic class which represents the attribute.If the word is to the left of the candidate, theattribute takes a negative value, if it is to theright, the value is positive, and zero if no wordwith that semantic class is present in thesentence the candidate belongs to.To better understand that, consider A1 is theattribute which indicates if in the sentence of thecandidate a word can be found belonging to thesemantic class 1.
Thus, the value of A1 is thedistance the candidate is from the closest wordwith semantic class 1 in the sentence that isbeing analyzed.3.2.2.
Candidate Semantic Class (CSC)The semantic class of candidates is also includedin the feature set, if the candidate is a multi-word, then the semantic class of the last word(the pivot word) is taken.4 http://www.cs.york.ac.uk/semeval-2013/task9/5 This value was extracted from our previous experiment.6393.2.3.
Most Frequent Semantic Classesfrom Entities (EMFSC)In order to add more semantic information, wedecided to find the most frequent semanticclasses among all the entities that were tagged inthe training data set.
We included, in the featureset, all the semantic classes with a frequency ofeight or more, because all the classes we wantedto identify were represented in that threshold.
Intotal, they make 29 more features.
The values ofevery one of them, is the sum of the number oftimes it appears in the candidate.3.2.4.
Candidate Semantic Class AllWords (CSC-All)This feature is similar to CSC, but in this casethe candidate is a multi-word, we not only lookfor the semantic class of the pivot, but also thewhole candidate as one.3.2.5.
Drug-related domains (DRD)Another group of eight attributes describes howmany times each one of the candidates belongsto one of the following drug-related domains(DRD) (medicine, anatomy, biology, chemistry,physiology, pharmacy, biochemistry, genetics).These domains where extracted from WordNetDomains.
In order to determine the domain thata word belongs to, the proposal of DRelevant(V?zquez et al 2007; V?zquez et al 2004) wasused.To illustrate how the DRD features take theirvalues, consider the following sentence:?
?until the lipid response to Accutane isestablished.
?One of the candidates the system generateswould be ?lipid response?.
It is a two-wordcandidate, so we take the first word and see if itbelongs to one of the above domains.
If it does,then we add one to that feature.
If the word doesnot belong to any of the domains, then its valuewill be zero.
We do the same with the otherword.
In the end, we have a collection whereevery value corresponds to each one of thedomains.
For the example in question thecollection would be:medicine 1anatomy 0biology 0chemistry 0physiology 1pharmacy 0biochemistry 0genetics 0Table 1.
DRD value assignment example.3.2.6.
Candidate word number (WNum)Because there are candidates that are a multi-word and others that are not, it may be the casethat a candidate, which is a multi-word, has anEMFSC bigger than others which are not amulti-word, just because more than one of thewords that conform it, have a frequent semanticclass.We decided to add a feature, called WNum,which would help us normalize the values of theEMFSC.
The value of the feature would be thenumber of words the candidate has.
Same thinghappens with DRD.3.2.7.
Candidate Domain (CD)The value of this nominal feature is the domainassociated to the candidate.
If the candidate is amulti-word; we get the domain of all the wordsas a whole.
In both cases the domain for a singleword as well as for a multi-word is determinedusing the relevant domains obtained by(V?zquez et al 2007; V?zquez et al 2004).3.2.8.
Maximum Frequent 2-grams, 3-gramsDrugs usually contain sequences of charactersthat are very frequent in biomedical domaintexts.
These character sequences are called n-grams, where n is the number of characters inthe sequence.
Because of that, we decided to addthe ten most frequent n-grams with n betweentwo and three.
The selected n-grams are thefollowing: ?in?
(frequency: 8170), ?ne?
(4789),?ine?
(3485), ?ti?
(3234), ?id?
(2768), ?an?
(2704), ?ro?
(2688), ?nt?
(2593), ?et?
(2423),?en?
(2414).These features take a value of one if thecandidate has the corresponding charactersequence and zero if it does not.
For instance: if640we had the candidate ?panobinostat?
it willgenerate the following collection:?in?
1?ne?
0?ine?
0?ti?
0?id?
0?an?
1?ro?
0?nt?
0?et?
0?en?
0Table 2.
MF 2-gram, 3-gram.3.2.9.
Uppercase (UC), Uppercase All(UCA).
Multi-word (MWord) andNumber (N)Other features say if the first letter of thecandidate is an uppercase; if all of the letters areuppercase (UCA); if it is a multi-word (MWord)and also if it is in the singular or in the plural(N).3.2.10.
L1, L2, L3 and R1, R2, R3The Part-of-Speech tags of the closest threesurrounding words of the candidates are alsoincluded.
We named those features L1, L2, andL3 for POS tags to the left of the candidate, andR1, R2, and R3 for those to the right.3.2.11.
POS-tagging combination (GC)Different values are assigned to candidates, inorder to identify its POS-tagging combination.For instance: to the following entity ?combinedoral contraceptives?
taken from DDI13-train-TEES-analyses-130304.xml6 training file, whichwas provided for task 9.1, corresponds 5120.This number is the result of combining the fourgrammatical categories that really matter to us:R for adverb, V for verb, J for adjective, N fornoun.A unique number was given to eachcombination of those four letters.
We named thisfeature  GC.6 http://www.cs.york.ac.uk/semeval-2013/task93.2.12.
In resource feature (InRe)A resource was created which contains all thedrug entities that were annotated in the trainingcorpus, so another attribute tells the system if thecandidate is in the resource.Since all of the entities in the training data setwere in the resource this attribute could take avalue of one for all instances.
Thus the classifiercould classify correctly all instances in thetraining data set just looking to this attribute,which is not desirable.
To avoid that problem,we randomly set its value to zero every 9/10 ofthe training instances.3.3.
ClassificationAll the features extracted in the previous stagesare used in this stage to obtain the two models,one for drug detection phase, and the other fordrug classification phase.We accomplished an extensive set ofexperiments in order to select the best classifier.All algorithms implemented in WEKA, exceptthose that were designed specifically for aregression task, were tried.
In each case weperform a 10-fold cross-validation.
In allexperiments the classifiers were settled with thedefault configuration.
From those tests we selecta decision tree, the C4.5 algorithm (Guti?rrez etal., 2011; 2010) implemented as the J48classifier in WEKA.
This classifier yields thebetter results for both drug detection and drugclassification.The classifier was trained using a set of 463features, extracted from the corpus provided bySemEval 2013, the task 9 in question.As it was mentioned before, three runs wereperformed for the competition.
Run (1) used thefollowing features for drug detection: MFSC(only 200 frequent semantic classes), MF 2-grams, 3-grams, UC, UCA, MWord, N, L1, L2,L3, R1, R2, R3, CSC, CD, WNum, GC andInRe.Drug classification in this run used the samefeatures except for CD, WNum, and GC.
Run(2) has all the above features, but we added theremaining 200 sematic classes that we left out inRun (1) to the detection and the classificationmodels.
In Run (3), we added EMFSC feature tothe detection and the classification models.6414.
ResultsIn the task, the results of the participants werecompared to a gold-standard and evaluatedaccording to various evaluation criteria:?
Exact evaluation, which demands not onlyboundary match, but also the type of thedetected drug has to be the same as that ofthe gold-standard.?
Exact boundary matching (regardless ofthe type).?
Partial boundary matching (regardless ofthe type)?
Type matching.Precision and recall were calculated using thescoring categories proposed by MUC 7:?
COR: the output of the system and thegold-standard annotation agree.?
INC: the output of the system and thegold-standard annotation disagree.?
PAR: the output of the system and thegold-standard annotation are not identicalbut has some overlapping text.?
MIS: the number of gold-standard entitiesthat were not identify by the system.?
SPU: the number of entities labeled by thesystem that are not in the gold-standard.Table 3 , Table 4 and Table 5 show the systemresults in the DDIExtraction2013 competitionfor Run (1).Run (2) and Run (3) results are almost thesame as Run (1).
It is an interesting result sincein those runs 200 additional features weresupplied to the classifier.
In feature evaluation,using CfsSubsetEval and GeneticSearch withWEKA we found that all these new featureswere ranked as worthless for the classification.On the other hand, the following features werethe ones that really influenced the classifiers:MFSC (215 features only), MF 2-grams, 3-grams (?ne?, ?ine?, ?ti?, ?ro?, ?et?, ?en?
),WNum, UC, UCA, L1, R1, CSC, CSC-All, CD,DRD (anatomy, physiology, pharmacy,biochemistry), InRe, GC and EMFS, specificallymusic.n.01, substance.n.01, herb.n.01,artifact.n.01, nutriment.n.01, nonsteroidal_anti-inflammatory.n.01, causal_agent.n.01 have a7http://www.itl.nist.gov/iaui/894.02/related_projects/muc/muc_sw/muc_sw_manual.htmlfrequency of 8, 19, 35, 575, 52, 80, 63respectively.Measure StrictExactMatchingPartialMatchingTypeCOR 319 354 354 388INC 180 145 0 111PAR 0 0 145 0MIS 187 187 187 187SPU 1137 1137 1137 1137Precision 0.19 0.22 0.22 0.24Recall 0.47 0.52 0.62 0.57Table 3.
Run (1), all scores.Measure Drug Brand Group Drug_nCOR 197 20 93 9INC 23 2 43 1PAR 0 0 0 0MIS 131 37 19 111SPU 754 47 433 14Precision 0.2 0.29 016 0.38Recall 0.56 0.34 0.6 0.07F1 0.3 0.31 0.26 0.12Table 4.
Scores for entity types, exact matching inRun (1).Precision Recall F1Macro average 0.26 0.39 0.31Strict matching 0.19 0.46 0.27Table 5.
Macro average and Strict matching measuresin Run (1).5.
Conclusion and future worksIn this paper we show the description ofUMCC_DLSI-(DDI) system, which is able todetect and classify drugs in biomedical textswith acceptable efficacy.
It introduces in thisthematic the use of semantic information such assemantic classes and the relevant domain of thewords, extracted with ISR-WN resource.
Withthis approach we obtained an F-Measure of27.5% in the Semeval DDI Extraction2013 task9.As further work we propose to eliminate somedetected bugs (i.e.
repeated instances,multiwords missed) and enrich our knowledgebase (ISR-WN), using biomedical sources asUMLS8, SNOMED9 and OntoFis10.8 http://www.nlm.nih.gov/research/umls9 http://www.ihtsdo.org/snomed-ct/10 http://rua.ua.es/dspace/handle/10045/14216642AcknowledgmentsThis research work has been partially funded bythe Spanish Government through the projectTEXT-MESS 2.0 (TIN2009-13391-C04),"An?lisis de Tendencias Mediante T?cnicas deOpini?n Sem?ntica" (TIN2012-38536-C03-03)and ?T?cnicas de Deconstrucci?n en laTecnolog?as del Lenguaje Humano?
(TIN2012-31224); and by the Valencian Governmentthrough the project PROMETEO(PROMETEO/2009/199).ReferencesBj?rne, J.; A. Airola; T. Pahikkala and T. SalakoskiDrug-Drug Interaction Extraction fromBiomedical Texts with SVM and RLS ClassifiersProceedings of the 1st Challenge Task on Drug-Drug Interaction Extraction, 2011, 761: 35-42.Bobi?, T.; R. Klinger; P. Thomas and M. Hofmann-Apitius Improving Distantly Supervised Extractionof Drug-Drug and Protein-Protein InteractionsEACL 2012, 2012: 35.Cohen, A. M. and W. R. Hersh A survey of currentwork in biomedical text mining Briefings inbioinformatics, 2005, 6(1): 57-71.Gr?nroos, P.; K. Irjala; J. Heiskanen; K. Torniainenand J. Forsstr?m Using computerized individualmedication data to detect drug effects on clinicallaboratory tests Scandinavian Journal of Clinical& Laboratory Investigation, 1995, 55(S222): 31-36.Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez.
Integration of semantic resources basedon WordNet.
XXVI Congreso de la SociedadEspa?ola para el Procesamiento del LenguajeNatural, Universidad Polit?cnica de Valencia,Valencia, SEPLN 2010, 2010.
161-168 p. 1135-5948Guti?rrez, Y.; A. Fern?ndez; A. Montoyo and S.V?zquez Enriching the Integration of SemanticResources based on WordNet Procesamiento delLenguaje Natural, 2011, 47: 249-257.Hirschman, L.; A. Yeh; C. Blaschke and A. ValenciaOverview of BioCreAtIvE: critical assessment ofinformation extraction for biology BMCbioinformatics, 2005, 6(Suppl 1): S1.Izquierdo, R.; A. Su?rez and G. Rigau A Proposal ofAutomatic Selection of Coarse-grained SemanticClasses for WSD Procesamiento del LenguajeNatural, 2007, 39: 189-196.Percha, B. and R. B. Altman Informatics confrontsdrug?drug interactions Trends in pharmacologicalsciences, 2013.Segura-Bedmar, I.; P. Mart?nez and D. S?nchez-Cisneros The 1st DDIExtraction-2011 challengetask: Extraction of Drug-Drug Interactions frombiomedical texts Challenge Task on Drug-DrugInteraction Extraction, 2011, 2011: 1-9.Tari, L.; S. Anwar; S. Liang; J. Cai and C. BaralDiscovering drug?drug interactions: a text-miningand reasoning approach based on properties ofdrug metabolism Bioinformatics, 2010, 26(18):i547-i553.V?zquez, S.; A. Montoyo and Z. Kozareva.Extending Relevant Domains for Word SenseDisambiguation.
IC-AI?07.
Proceedings of theInternational Conference on Artificial IntelligenceUSA, 2007.V?zquez, S.; A. Montoyo and G. Rigau.
UsingRelevant Domains Resource for Word SenseDisambiguation.
IC-AI?04.
Proceedings of theInternational Conference on Artificial Intelligence,Ed: CSREA Press.
Las Vegas, E.E.U.U., 2004.Wishart, D. S.; C. Knox; A. C. Guo; D. Cheng; S.Shrivastava; D. Tzur; B. Gautam and M. HassanaliDrugBank: a knowledgebase for drugs, drugactions and drug targets Nucleic acids research,2008, 36(suppl 1): D901-D906.643
