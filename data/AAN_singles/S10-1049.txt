Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 222?225,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsISI: Automatic Classification of Relations Between Nominals Using aMaximum Entropy ClassifierStephen Tratz and Eduard HovyInformation Sciences InstituteUniversity of Southern CaliforniaMarina del Rey, CA 90292{stratz,hovy}@isi.eduAbstractThe automatic interpretation of semanticrelations between nominals is an impor-tant subproblem within natural languageunderstanding applications and is an areaof increasing interest.
In this paper, wepresent the system we used to participatein the SEMEVAL 2010 Task 8 Multi-WayClassification of Semantic Relations be-tween Pairs of Nominals.
Our system,based upon a Maximum Entropy classifiertrained using a large number of booleanfeatures, received the third highest score.1 IntroductionSemantic interpretation of the relations betweennominals in text is an area of growing interestwithin natural language processing (NLP).
It haspotential uses for a variety of tasks including ma-chine translation (Baldwin and Tanaka, 2004) andquestion answering (Ahn et al, 2005).
The relatedand more narrowly-focused problem of automaticinterpretation of noun compounds is the focus ofanother SEMEVAL task (Butnariu et al, 2009).In this paper, we discuss the overall setup ofSEMEVAL 2010 Task 8 (Hendrickx et al, 2010),present the system we used to participate, anddiscuss our system?s performance.
Our system,which consists of a Maximum Entropy classifiertrained using a large variety of boolean features,received the third highest official score of all theentries.2 Related WorkThe groundwork for SEMEVAL 2010 Task 8 waslaid by an earlier SEMEVAL task (Girju et al,2007).
For SEMEVAL 2007 Task 4, participantsprovided yes or no answers as to whether a partic-ular relation held for each test example.
For SE-MEVAL 2010, instead of providing a binary out-put for a single class, participants were required toperform multi-way classification, that is, select themost appropriate relation from a set of 10 relationsincluding the OTHER relation.The selection of a semantic relation for a pairof nominals within a sentence is somewhat sim-ilar to the task of noun compound interpretation,which is a more restricted problem focused onlyupon the nouns within noun compounds.
Someof the recent work on this problem includes thatof Butnariu et al (2009), Girju (2007), Girjuet al (2005), Kim and Baldwin (2005), Nakov(2008), Nastase et al (2006), Turney (2006), and?
S?aghdha and Copestake (2009).3 Task OverviewThe task is, given a pair of nominals within theirsentence context, select the most appropriate se-mantic relation from the set of available relationsand indicate the direction of the relation.
Thoughthe final score was based upon the output of thesystem trained using the whole training dataset,participants were also required to submit three ad-ditional label sets using the first 12.5%, 25%, and50% of the training data.3.1 Relation SchemeThe relations were taken from earlier work onnoun compounds by Nastase and Szpakowicz(2003).A total of 10 relations were used includ-ing CAUSE-EFFECT, COMPONENT-WHOLE,CONTENT-CONTAINER, ENTITY-ORIGIN,ENTITY-DESTINATION, INSTRUMENT-AGENCY,MEMBER-COLLECTION, MESSAGE-TOPIC,OTHER, and PRODUCT-PRODUCER.
Since eachrelation except the OTHER relation must have itsdirection specified, there are a total of 19 possiblelabels.2223.2 DataThe training and testing datasets consist of 8000and 2717 examples respectively.
Each exampleconsists of a single sentence with two of its nomi-nals marked as being the nominals of interest.
Thetraining data also provides the correct relation foreach example.4 Method4.1 ClassifierWe use a Maximum Entropy (Berger et al, 1996)classifier trained using a large number of booleanfeatures.
Maximum Entropy classifiers haveproven effective for a variety of NLP problems in-cluding word sense disambiguation (Tratz et al,2007; Ye and Baldwin, 2007).
We use the imple-mentation provided in the MALLET machine learn-ing toolkit (McCallum, 2002).
We used the defaultGaussian prior parameter value of 1.0.4.2 Features UsedWe generate features from individual words, in-cluding both the nominals and their context, andfrom combinations of the nominals.To generate the features for individual words,we first use a set of word selection rules to se-lect the words of interest and then run these wordsof interest through a variety of feature-generatingfunctions.
Some words may be selected by multi-ple word selection rules.
For example, the word tothe right of the first nominal will be identified bythe word 1 to the right of the 1st nominal rule, thewords that are 3 or less to the right of the 1st nom-inal rule, and the all words between the nominalsrule.
In these cases, the actual feature is the com-bination of an identifier for the word selection ruleand the output from the feature-generating func-tion.
The 19 word-selection rules are listed below:Word-Selection Rules?
The {1st, 2nd} nominal (2 rules)?
Word {1, 2, 3} to the {left, right} of the {1st,2nd} nominal (12 rules)?
Words that are 3 or less to the {left, right} ofthe {1st, 2nd} nominal (4 rules)?
All words between the two nominals (1 rule)The features generated from the individualwords come from a variety of sources includ-ing word orthography, simple gazetteers, patternmatching, WordNet (Fellbaum, 1998), and Ro-get?s Thesaurus.Orthographic Features?
Capitalization indicator?
The {first, last} {two, three} letters of eachword?
Indicator if the first letter of the word is a/A.?
Indicator for the overall form of the word(e.g.
jump -> a, Mr. -> Aa., SemEval2 ->AaAa0)?
Indicators for the suffix types (e.g., de-adjectival, de-nominal [non]agentive, de-verbal [non]agentive)?
Indicators for a wide variety of affixes includ-ing those related to degree, number, order,etc.
(e.g., ultra-, poly-, post-)?
Indicators for whether or not a prepositionoccurs within either term (e.g., ?down?
in?breakdown?
)Gazetteer and Pattern Features?
Indicators if the word is one of a number ofclosed classes (e.g.
articles, prepositions)?
Indicator if the word is listed in the U.S. Cen-sus 2000?s most common surnames list?
Indicator if the word is listed in the U.S. Cen-sus 2000?s most common first names list?
Indicator if the word is a name or locationbased upon some simple regular expressionsWordNet-based Features?
Lemmatized version of the word?
Synonyms for all NN and VB entries for theword?
Hypernyms for all NN and VB entries for theword?
All terms in the definitions (?gloss?)
for theword?
Lexicographer file names for the word?
Lists of all link types (e.g., meronym links)associated with the word?
Part-of-speech indicators for the existence ofNN/VB/JJ/RB entries for the word?
All sentence frames for the word?
All part, member, substance-of holonyms forthe wordRoget?s Thesaurus-based Features?
Roget?s divisions for all noun (and verb) en-tries for the word223Some additional features were extracted usingcombinations of the nominals.
These include fea-tures generated using The Web 1T corpus (Brantsand Franz, 2006), and the output of a noun com-pound interpretation system.Web 1T N-gram FeaturesTo provide information related to term usageto the classifier, we extracted trigram and 4-gramfeatures from the Web 1T Corpus (Brants andFranz, 2006).
Only n-grams containing lowercasewords were used.
The nominals were convertedto lowercase if needed.
Only n-grams contain-ing both terms (including plural forms) were ex-tracted.
We included the n-gram, with the nomi-nals replaced with N1 and N2 respectively, as in-dividual boolean features.
We also included ver-sions of the n-gram features with the words re-placed with wild cards.
For example, if the nomi-nals were ?food?
and ?basket?
and the extracted n-gram was ?put_N1_in_the_N2?, we also included?
*_N1_in_the_N2?, ?
*_N1_*_the_N2?, etc.
asfeatures.Noun Compound System FeaturesWe also ran the nominals through an in-housenoun compound interpretation system and took itsoutput as features.
We will not be discussing thenoun compound interpretation system in detail inthis paper.
It uses a similar approach to that de-scribed in this paper including a Maximum En-tropy classifier trained with similar features thatoutputs a ranked list of a fixed set of semantic re-lations.
The relations ranked within the top 5 andbottom 5 were included as features.
For example,if ?Topic of Communication?
was the third high-est relation, both ?top:3:Topic of Communication?and ?top:*:Topic of Communication?
would be in-cluded as features.4.3 Feature FilteringThe aforementioned feature generation processcreates a very large number of features.
To deter-mine the final feature set, we first ranked the fea-tures according to the Chi-Squared metric.
Then,by holding out one tenth of the training dataand trying different thresholds, we concluded that100,000 features was roughly optimal.
For thecases where we used 12.5%, 25%, and 50%, wetested on the remaining training data and came updifferent cutoffs: 25,000, 40,000, and 60,000, re-spectively.5 ResultsEach participating site was allowed to submit mul-tiple runs based upon different systems or config-urations thereof.
The results for the best perform-ing submissions from each team are presented inTable 1.
The official metric for the task was F1macroaveraged across the different relations.
Weare pleased to see that our system received thethird highest score.Our results by the different relation types areshown in Table 2.
We note that the performanceon the OTHER relation is relatively low.Top ResultsSystem Macroaveraged F112.5% 25% 50% 100%UTD 73.08 77.02 79.93 82.19FBK_IRST 63.61 70.20 73.40 77.62ISI 66.68 71.01 75.51 77.57ECNU 49.32 50.70 72.63 75.43TUD 58.35 62.45 66.86 69.23ISTI 50.49 55.80 61.14 68.42FBK_NK 55.71 64.06 67.80 68.02SEKA 51.81 56.34 61.10 66.33JU 41.62 44.98 47.81 52.16UNITN 16.57 18.56 22.45 26.67Table 1: Final results (macroaveraged F1) for thehighest ranking (based upon result for trainingwith the complete training set) submissions foreach site.
12.5%, 25%, 50%, and 100% indicatethe amount of training data used.Results by RelationRelation P R F1Cause-Effect 87.77 87.50 87.63Component-Whole 73.21 75.32 74.25Content-Container 82.74 84.90 83.80Entity-Destination 81.51 81.51 81.51Entity-Origin 81.86 75.19 78.38Instrument-Agency 64.34 58.97 61.54Member-Collection 84.62 84.98 84.80Message-Topic 75.91 79.69 77.76Product-Producer 70.83 66.23 68.46Other 43.28 45.37 44.30Table 2: Precision, recall, and F1 results for oursystem by semantic relation.2246 ConclusionWe explain the system we used to participate inthe SEMEVAL 2010 Task 8: Multi-Way Classi-fication of Semantic Relations Between Pairs ofNominals and present its results.
The overall ap-proach is straight forward, consisting of a singleMaximum Entropy classifier using a large numberof boolean features, and proves effective, with oursystem receiving the third highest score of all thesubmissions.7 Future WorkIn the future, we are interested in utilizing pars-ing and part-of-speech tagging to enrich the fea-ture set.
We also want to investigate the relativelylow performance for the OTHER category and seeif we could develop a method to improve this.AcknowledgementsStephen Tratz is supported by a National De-fense Science and Engineering Graduate Fellow-ship.
We would like to thank the organizers ofthis task for their hard work in putting this tasktogether.ReferencesAhn, K., J. Bos, J. R. Curran, D. Kor, M. Nissim, andB.
Webber.
2005.
Question Answering with QEDat TREC-2005.
In Proc.
of TREC-2005.Baldwin, T. & T. Tanaka 2004.
Translation by machineof compound nominals: Getting it right.
In Proc.
ofthe ACL 2004 Workshop on Multiword Expressions:Integrating Processing.Berger, A., S. A. Della Pietra, and V. J. Della Pietra.1996.
A Maximum Entropy Approach to NaturalLanguage Processing.
Computational Linguistics,22.Brants, T. and A. Franz.
2006.
Web 1T 5-gram CorpusVersion 1.1.
Linguistic Data Consortium.Butnariu, C. and T. Veale.
2008.
A concept-centeredapproach to noun-compound interpretation.
In Proc.of 22nd International Conference on ComputationalLinguistics (COLING 2008).Butnariu, C., S.N.
Kim, P. Nakov, D. ?
S?aghdha, S.Szpakowicz, and T. Veale.
2009.
SemEval Task 9:The Interpretation of Noun Compounds Using Para-phrasing Verbs and Prepositions.
In Proc.
of theNAACL HLT Workshop on Semantic Evaluations:Recent Achievements and Future Directions.Fellbaum, C., editor.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, MA.Girju, R., D. Moldovan, M. Tatu and D. Antohe.
2005.On the semantics of noun compounds.
ComputerSpeech and Language, 19.Girju, R., P. Nakov, V. Nastase, S. Szpakowicz, P. Tur-ney, and D. Yuret.
2007.
SemEval-2007 Task 04:Classification of Semantic Relations between Nom-inals In Proc.
of the 4th Semantic Evaluation Work-shop (SemEval-2007).Hendrickx, I., S. N. Kim, Z. Kozareva, P. Nakov, D.?
S?aghdha, Sebastian Pad?, M. Pennacchiotti, L.Romano, and S. Szpakowicz.
2010.
Improving theinterpretation of noun phrases with cross-linguisticinformation.
In Proc.
of the 5th SIGLEX Workshopon Semantic Evaluation.Girju, R. 2007.
Improving the interpretation of nounphrases with cross-linguistic information.
In Proc.of the 45th Annual Meeting of the Association ofComputational Linguistics (ACL 2007).Kim, S.N.
and T. Baldwin.
2005.
AutomaticInterpretation of Compound Nouns using Word-Net::Similarity.
In Proc.
of 2nd International JointConf.
on Natural Language Processing.McCallum, A. K. MALLET: A Machine Learning forLanguage Toolkit.
http://mallet.cs.umass.edu.
2002.Nakov, P. 2008.
Noun Compound InterpretationUsing Paraphrasing Verbs: Feasibility Study.
InProc.
the 13th International Conference on Artifi-cial Intelligence: Methodology, Systems, Applica-tions (AIMSA?08).Nastase V. and S. Szpakowicz.
2003.
Exploring noun-modifier semantic relations.
In Proc.
the 5th Inter-national Workshop on Computational Semantics.Nastase, V., J. S. Shirabad, M. Sokolova, and S. Sz-pakowicz 2006.
Learning noun-modifier semanticrelations with corpus-based and Wordnet-based fea-tures.
In Proc.
of the 21st National Conference onArtificial Intelligence (AAAI-06).?
S?aghdha, D. and A. Copestake.
2009.
Using lexi-cal and relational similarity to classify semantic re-lations.
In Proc.
of the 12th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics (EACL 2009).Tratz, S., A. Sanfilippo, M. Gregory, A. Chappell, C.Posse, and P. Whitney.
2007.
PNNL: A SupervisedMaximum Entropy Approach to Word Sense Disam-biguation In Proc.
of the 4th International Workshopon Semantic Evaluations (SemEval-2007).Turney, P. D. 2006.
Similarity of semantic relations.Computation Linguistics, 32(3):379-416Ye, P. and T. Baldwin.
2007.
MELB-YB: Prepo-sition Sense Disambiguation Using Rich SemanticFeatures.
In Proc.
of the 4th International Workshopon Semantic Evaluations (SemEval-2007).225
