Proceedings of the NAACL HLT Workshop on Semi-supervised Learning for Natural Language Processing, pages 43?48,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsLatent Dirichlet Allocation with Topic-in-Set Knowledge?David AndrzejewskiComputer Sciences DepartmentUniversity of Wisconsin-MadisonMadison, WI 53706, USAandrzeje@cs.wisc.eduXiaojin ZhuComputer Sciences DepartmentUniversity of Wisconsin-MadisonMadison, WI 53706, USAjerryzhu@cs.wisc.eduAbstractLatent Dirichlet Allocation is an unsupervisedgraphical model which can discover latent top-ics in unlabeled data.
We propose a mech-anism for adding partial supervision, calledtopic-in-set knowledge, to latent topic mod-eling.
This type of supervision can be usedto encourage the recovery of topics which aremore relevant to user modeling goals than thetopics which would be recovered otherwise.Preliminary experiments on text datasets arepresented to demonstrate the potential effec-tiveness of this method.1 IntroductionLatent topic models such as Latent Dirichlet Alloca-tion (LDA) (Blei et al, 2003) have emerged as a use-ful family of graphical models with many interestingapplications in natural language processing.
One ofthe key virtues of LDA is its status as a fully genera-tive probabilistic model, allowing principled exten-sions and variations capable of expressing rich prob-lem domain structure (Newman et al, 2007; Rosen-Zvi et al, 2004; Boyd-Graber et al, 2007; Griffithset al, 2005).LDA is an unsupervised learning model.
Thiswork aims to add supervised information in the formof latent topic assignments to LDA.
Traditionally,topic assignments have been denoted by the variablez in LDA, and we will call such supervised informa-tion ?z-labels.?
In particular, a z-label is the knowl-?
We would like to acknowledge the assistance of BrandiGancarz with the biological annotations.
This work is supportedin part by the Wisconsin Alumni Research Foundation.edge that the topic assignment for a given word po-sition is within a subset of topics.
As such, this workis a combination of unsupervised model and super-vised knowledge, and falls into the category simi-lar to constrained clustering (Basu et al, 2008) andsemi-supervised dimensionality reduction (Yang etal., 2006).1.1 Related WorkA similar but simpler type of topic labeling infor-mation has been applied to computer vision tasks.Topic modeling approaches have been applied toscene modeling (Sudderth et al, 2005), segmen-tation, and classification or detection (Wang andGrimson, 2008).
In some of these vision applica-tions, the latent topics themselves are assumed tocorrespond to object labels.
If labeled data is avail-able, either all (Wang and Mori, 2009) or some (Caoand Fei-Fei, 2007) of the z values can be treated asobserved, rather than latent, variables.
Our modelextends z-labels from single values to subsets, thusoffer additional model expressiveness.If the topic-based representations of documentsare to be used for document clustering or classi-fication, providing z-labels for words can be seenas similar to semi-supervised learning with labeledfeatures (Druck et al, 2008).
Here the words arefeatures, and z-label guidance acts as a feature la-bel.
This differs from other supervised LDA vari-ants (Blei and McAuliffe, 2008; Lacoste-Julien etal., 2008) which use document label information.The ?LDA model for statistical software debug-ging (Andrzejewski et al, 2007) partitions the topicsinto 2 sets: ?usage?
topics which can appear in all43documents, and ?bug?
topics which can only appearin a special subset of documents.
This effect wasachieved by using different ?
hyperparameters forthe 2 subsets of documents.
z-labels can achieve thesame effect by restricting the z?s in documents out-side the special subset, so that the z?s cannot assumethe ?bug?
topic values.
Therefore, the present ap-proach can be viewed as a generalization of ?LDA.Another perspective is that our z-labels mayguide the topic model towards the discovery of sec-ondary or non-dominant statistical patterns in thedata (Chechik and Tishby, 2002).
These topics maybe more interesting or relevant to the goals of theuser, but standard LDA would ignore them in favorof more prominent (and perhaps orthogonal) struc-ture.2 Our Model2.1 Review of Latent Dirichlet AllocationWe briefly review LDA, following the notationof (Griffiths and Steyvers, 2004) 1.
Let there beT topics.
Let w = w1 .
.
.
wn represent a cor-pus of D documents, with a total of n words.
Weuse di to denote the document of word wi, and zithe hidden topic from which wi is generated.
Let?
(w)j = p(w|z = j), and ?
(d)j = p(z = j) fordocument d. LDA involves the following generativemodel:?
?
Dirichlet(?)
(1)zi|?
(di) ?
Multinomial(?
(di)) (2)?
?
Dirichlet(?)
(3)wi|zi, ?
?
Multinomial(?zi), (4)where ?
and ?
are hyperparameters for thedocument-topic and topic-word Dirichlet distribu-tions, respectively.
Even though they can be vectorvalued, for simplicity we assume ?
and ?
are scalars,resulting in symmetric Dirichlet priors.Given our observed words w, the key task is in-ference of the hidden topics z.
Unfortunately, thisposterior is intractable and we resort to a MarkovChain Monte Carlo (MCMC) sampling scheme,specifically Collapsed Gibbs Sampling (Griffithsand Steyvers, 2004).
The full conditional equation1We enclose superscripts in parentheses in this paper.used for sampling individual zi values from the pos-terior is given byP (zi = v|z?i,w, ?, ?)
?
(n(d)?i,v + ?
?Tu (n(d)?i,u + ?
))(n(wi)?i,v + ??Ww?(?
+ n(w?
)?i,v))(5)where n(d)?i,v is the number of times topic v is used indocument d, and n(wi)?i,v is the number of times wordwi is generated by topic v. The ?i notation signifiesthat the counts are taken omitting the value of zi.2.2 Topic-in-Set Knowledge: z-labelsLetqiv =(n(d)?i,v + ?
?Tu (n(d)?i,u + ?
))(n(wi)?i,v + ??Ww?(?
+ n(w?
)?i,v)).We now define our z-labels.
Let C(i) be the set ofpossible z-labels for latent topic zi.
We set a hardconstraint by modifying the Gibbs sampling equa-tion with an indicator function ?
(v ?
C(i)), whichtakes on value 1 if v ?
C(i) and is 0 otherwise:P (zi = v|z?i,w, ?, ?)
?
qiv?
(v ?
C(i)) (6)If we wish to restrict zi to a single value (e.g., zi =5), this can now be accomplished by setting C(i) ={5}.
Likewise, we can restrict zi to a subset of val-ues {1, 2, 3} by setting C(i) = {1, 2, 3}.
Finally, forunconstrained zi we simply set C(i) = {1, 2, ..., T},in which case our modified sampling (6) reduces tothe standard Gibbs sampling (5).This formulation gives us a flexible method for in-serting prior domain knowledge into the inference oflatent topics.
We can set C(i) independently for ev-ery single word wi in the corpus.
This allows us, forexample, to force two occurrences of the same word(e.g., ?Apple pie?
and ?Apple iPod?)
to be explainedby different topics.
This effect would be impossibleto achieve by using topic-specific asymmetric ?
vec-tors and setting some entries to zero.This hard constraint model can be relaxed.
Let0 ?
?
?
1 be the strength of our constraint, where?
= 1 recovers the hard constraint (6) and ?
= 0recovers unconstrained sampling (5):P (zi = v|z?i,w, ?, ?)
?
qiv(??
(v ?
C(i)) + 1?
?
).44While we present the z-label constraints as a me-chanical modification to the Gibbs sampling equa-tions, it can be derived from an undirected extensionof LDA (omitted here) which encodes z-labels.
Thesoft constraint Gibbs sampling equation arises nat-urally from this formulation, which is the basis forthe First-Order Logic constraints described later inthe future work section.3 ExperimentsWe now present preliminary experimental results todemonstrate some interesting applications for topic-in-set knowledge.
Unless otherwise specified, sym-metric hyperparameters ?
= .5 and ?
= .1 wereused and all MCMC chains were run for 2000 sam-ples before estimating ?
and ?
from the final sample,as in (Griffiths and Steyvers, 2004).3.1 Concept ExpansionWe explore the use of topic-in-set for identifyingwords related to a target concept, given a set ofseed words associated with that concept.
For ex-ample, a biological expert may be interested in theconcept ?translation?.
The expert would then pro-vide a set of seed words which are strongly relatedto this concept, here we assume the seed word set{translation,trna,anticodon,ribosome}.
We add thehard constraint that zi = 0 for all occurrences ofthese four words in our corpus of approximately9,000 yeast-related abstracts.We ran LDA with the number of topics T = 100,both with and without the z-label knowledge on theseed words.
Table 1 shows the most probable wordsin selected topics from both runs.
Table 1a showsTopic 0 from the constrained run, while Table 1bshows the topics which contained seed words amongthe top 50 most probable words from the uncon-strained run.In order to better understand the results, thesetop words were annotated for relevance to the tar-get concept (translation) by an outside biological ex-pert.
The words in Table 1 were then colored blueif they were one of the original seed words, red ifthey were judged as relevant, and left black other-wise.
From a quick glance, we can see that Topic0 from the constrained run contains more relevantterms than Topic 43 from the standard LDA run.Topic 31 has a similar number of relevant terms, buttaken together we can see that the emphasis of Topic31 is slightly off-target, more focused on ?mRNAturnover?
than ?translation?.
Likewise, Topic 73seems more focused on the ribosome itself than theprocess of translation.
Overall, these results demon-strate the potential effectiveness of z-label informa-tion for guiding topic models towards a user-seededconcept.3.2 Concept ExplorationSuppose that a user has chosen a set of terms andwishes to discover different topics related to theseterms.
By constraining these terms to only appearin a restricted set of topics, these terms will be con-centrated in the set of topics.
The split within thoseset of topics may be different from what a standardLDA will produce, thus revealing new informationwithin the data.To make this concrete, say we are interested inthe location ?United Kingdom?.
We seed this con-cept with the following LOCATION-tagged terms{britain, british, england, uk, u.k., wales, scotland,london}.
These terms are then restricted to ap-pear only in the first 3 topics.
Our corpus is anentity-tagged Reuters newswire corpus used for theCoNLL-2003 shared task (Tjong Kim Sang andDe Meulder, 2003).
In order to focus on our tar-get location, we also restrict all other LOCATION-tagged tokens to not appear in the first 3 topics.
Forthis experiment we set T = 12, arrived at by trial-and-error in the baseline (standard LDA) case.The 50 most probable words for each topic areshown in Figure 2, and tagged entities are prefixedwith their tags for easy identification.
Table 2ashows the top words for the first 3 topics of our z-label run.
These three topics are all related to thetarget LOCATION United Kingdom, but they alsosplit nicely into business, cricket, and soccer.
Wordswhich are highly relevant to each of these 3 conceptsare colored blue, red, and green, respectively.In contrast, in Table 2b we show topics from stan-dard LDA which contain any of the ?United King-dom?
LOCATION terms (which are underlined)among the 50 most probable words for that topic.We make several observations about these topics.First, standard LDA Topic 0 is mostly concernedwith political unrest in Russia, which is not particu-45Topic 0translation, ribosomal, trna, rrna, initiation, ribosome, protein, ribosomes, is, factor, processing, translationalnucleolar, pre-rrna, synthesis, small, 60s, eukaryotic, biogenesis, subunit, trnas, subunits, large, nucleolusfactors, 40, synthetase, free, modification, rna, depletion, eif-2, initiator, 40s, ef-3, anticodon, maturation18s, eif2, mature, eif4e, associated, synthetases, aminoacylation, snornas, assembly, eif4g, elongation(a) Topic 0 with z-labelTopic 31mrna, translation, initiation, mrnas, rna, transcripts, 3, transcript, polya, factor, 5, translational, decay, codondecapping, factors, degradation, end, termination, eukaryotic, polyadenylation, cap, required, efficiencysynthesis, show, codons, abundance, rnas, aug, nmd, messenger, turnover, rna-binding, processing, eif2, eif4eeif4g, cf, occurs, pab1p, cleavage, eif5, cerevisiae, major, primary, rapid, tail, efficient, upf1p, eif-2Topic 43type, is, wild, yeast, trna, synthetase, both, methionine, synthetases, class, trnas, enzyme, whereas, cytoplasmicbecause, direct, efficiency, presence, modification, aminoacylation, anticodon, either, eukaryotic, betweendifferent, specific, discussed, results, similar, some, met, compared, aminoacyl-trna, able, initiator, samnot, free, however, recognition, several, arc1p, fully, same, forms, leads, identical, responsible, found, only, wellTopic 73ribosomal, rrna, protein, is, processing, ribosome, ribosomes, rna, nucleolar, pre-rrna, rnase, small, biogenesisdepletion, subunits, 60s, subunit, large, synthesis, maturation, nucleolus, associated, essential, assemblycomponents, translation, involved, rnas, found, component, mature, rp, 40s, accumulation, 18s, 40, particlessnornas, factors, precursor, during, primary, rrnas, 35s, has, 21s, specifically, results, ribonucleoprotein, early(b) Standard LDA TopicsFigure 1: Concept seed words are colored blue, other words judged relevant to the target concept are coloredred.larly related to the target location.
Second, Topic 2is similar to our previous business topic, but witha more US-oriented slant.
Note that ?dollar?
ap-pears with high probability in standard LDA Topic2, but not in our z-label LDA Topic 0.
StandardLDA Topic 8 appears to be a mix of both soccer andcricket words.
Therefore, it seems that our topic-in-set knowledge helps in distilling topics related to theseed words.Given this promising result, we attempted torepeat this experiment with some other nations(United States, Germany, China), but without muchsuccess.
When we tried to restrict these LOCATIONwords to the first few topics, these topics tended tobe used to explain other concepts unrelated to thetarget location (often other sports).
We are investi-gating the possible causes of this problem.4 Conclusions and Future WorkWe have defined Topic-in-Set knowledge anddemonstrated its use within LDA.
As shown in theexperiments, the partial supervision provided by z-labels can encourage LDA to recover topics rele-vant to user interests.
This approach combines thepattern-discovery power of LDA with user-providedguidance, which we believe will be very attractive topractical users of topic modeling.Future work will deal with at least two impor-tant issues.
First, when will this form of partialsupervision be most effective or appropriate?
Ourexperimental results suggest that this approach willstruggle if the user?s target concepts are simply notprevalent in the text.
Second, can we modify thisapproach to express richer forms of partial super-vision?
More sophisticated forms of knowledgemay allow users to specify their preferences or priorknowledge more effectively.
Towards this end, weare investigating the use of First-Order Logic inspecifying prior knowledge.
Note that the set z-labels presented here can be expressed as simple log-ical formulas.
Extending our model to general log-ical formulas would allow the expression of morepowerful relational preferences.ReferencesDavid Andrzejewski, Anne Mulhern, Ben Liblit, and Xi-aojin Zhu.
2007.
Statistical debugging using latenttopic models.
In Stan Matwin and Dunja Mladenic,editors, 18th European Conference on Machine Learn-ing, Warsaw, Poland.46Topic 0million, company, ?s, year, shares, net, profit, half, group, [I-ORG]corp, market, sales, share, percentexpected, business, loss, stock, results, forecast, companies, deal, earnings, statement, price, [I-LOC]londonbillion, [I-ORG]newsroom, industry, newsroom, pay, pct, analysts, issue, services, analyst, profits, saleadded, firm, [I-ORG]london, chief, quarter, investors, contract, note, tax, financial, months, costsTopic 1[I-LOC]england, [I-LOC]london, [I-LOC]britain, cricket, [I-PER]m., overs, test, wickets, scores, [I-PER]ahmed[I-PER]paul, [I-PER]wasim, innings, [I-PER]a., [I-PER]akram, [I-PER]mushtaq, day, one-day, [I-PER]mark, final[I-LOC]scotland, [I-PER]waqar, [I-MISC]series, [I-PER]croft, [I-PER]david, [I-PER]younis, match, [I-PER]iantotal, [I-MISC]english, [I-PER]khan, [I-PER]mullally, bat, declared, fall, [I-PER]d., [I-PER]g., [I-PER]j.bowling, [I-PER]r., [I-PER]robert, [I-PER]s., [I-PER]steve, [I-PER]c. captain, golf, tour, [I-PER]sohail, extras[I-ORG]surreyTopic 2soccer, division, results, played, standings, league, matches, halftime, goals, attendance, points, won, [I-ORG]stdrawn, saturday, [I-MISC]english, lost, premier, [I-MISC]french, result, scorers, [I-MISC]dutch, [I-ORG]united[I-MISC]scottish, sunday, match, [I-LOC]london, [I-ORG]psv, tabulate, [I-ORG]hapoel, [I-ORG]sydney, fridaysummary, [I-ORG]ajax, [I-ORG]manchester, tabulated, [I-MISC]german, [I-ORG]munich, [I-ORG]city[I-MISC]european, [I-ORG]rangers, summaries, weekend, [I-ORG]fc, [I-ORG]sheffield, wednesday, [I-ORG]borussia[I-ORG]fortuna, [I-ORG]paris, tuesday(a) Topics with set z-labelsTopic 0police, ?s, people, killed, [I-MISC]russian, friday, spokesman, [I-LOC]moscow, told, rebels, group, officials[I-PER]yeltsin, arrested, found, miles, km, [I-PER]lebed, capital, thursday, tuesday, [I-LOC]chechnya, newssaturday, town, authorities, airport, man, government, state, agency, plane, reported, security, forcescity, monday, air, quoted, students, region, area, local, [I-LOC]russia, [I-ORG]reuters, military, [I-LOC]londonheld, southern, diedTopic 2percent, ?s, market, thursday, july, tonnes, week, year, lower, [I-LOC]u.s., rate, prices, billion, cents, dollarfriday, trade, bank, closed, trading, higher, close, oil, bond, fell, markets, index, points, rosedemand, june, rates, september, traders, [I-ORG]newsroom, day, bonds, million, price, shares, budget, governmentgrowth, interest, monday, [I-LOC]london, economic, august, expected, riseTopic 5?s, match, team, win, play, season, [I-MISC]french, lead, home, year, players, [I-MISC]cup, back, minuteschampion, victory, time, n?t, game, saturday, title, side, set, made, wednesday, [I-LOC]englandleague, run, club, top, good, final, scored, coach, shot, world, left, [I-MISC]american, captain[I-MISC]world, goal, start, won, champions, round, winner, end, years, defeat, lostTopic 8division, [I-LOC]england, soccer, results, [I-LOC]london, [I-LOC]pakistan, [I-MISC]english, matches, playedstandings, league, points, [I-ORG]st, cricket, saturday, [I-PER]ahmed, won, [I-ORG]united, goals[I-PER]wasim, [I-PER]akram, [I-PER]m., [I-MISC]scottish, [I-PER]mushtaq, drawn, innings, premier, lost[I-PER]waqar, test, [I-PER]croft, [I-PER]a., [I-PER]younis, declared, wickets, [I-ORG]hapoel, [I-PER]mullally[I-ORG]sydney, day, [I-ORG]manchester, [I-PER]khan, final, scores, [I-PER]d., [I-MISC]german, [I-ORG]munich[I-PER]sohail, friday, total, [I-LOC]ovalTopic 10[I-LOC]germany, ?s, [I-LOC]italy, [I-LOC]u.s., metres, seconds, [I-LOC]france, [I-LOC]britain, [I-LOC]russiaworld, race, leading, [I-LOC]sweden, [I-LOC]australia, [I-LOC]spain, women, [I-MISC]world, [I-LOC]belgium[I-LOC]netherlands, [I-PER]paul, [I-LOC]japan, [I-MISC]olympic, [I-LOC]austria, [I-LOC]kenya, men, timeresults, [I-LOC]brussels, [I-MISC]cup, [I-LOC]canada, final, minutes, record, [I-PER]michael, meeting, round[I-LOC]norway, friday, scores, [I-PER]mark, [I-PER]van, [I-LOC]ireland, [I-PER]peter, [I-MISC]grand[I-MISC]prix, points, saturday, [I-LOC]finland, cycling, [I-ORG]honda(b) Standard LDA TopicsFigure 2: Topics containing ?United Kingdom?
location words.
Words related to business are colored blue,cricket red, and soccer green.Sugato Basu, Ian Davidson, and Kiri Wagstaff, edi-tors.
2008.
Constrained Clustering: Advances inAlgorithms, Theory, and Applications.
Chapman &Hall/CRC Press.David Blei and Jon McAuliffe.
2008.
Supervised topicmodels.
In J.C. Platt, D. Koller, Y.
Singer, andS.
Roweis, editors, Advances in Neural InformationProcessing Systems 20, pages 121?128.
MIT Press,47Cambridge, MA.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet alocation.
Journal of MachineLearning Research, 3:993?1022.Jordan Boyd-Graber, David Blei, and Xiaojin Zhu.
2007.A topic model for word sense disambiguation.
InProceedings of the 2007 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), pages 1024?1033.Liangliang Cao and Li Fei-Fei.
2007.
Spatially coher-ent latent topic model for concurrent segmentation andclassification of objects and scenes.
In ICCV, pages 1?8.Gal Chechik and Naftali Tishby.
2002.
Extracting rel-evant structures with side information.
In NIPS 15,pages 857?864.
MIT press.Gregory Druck, Gideon Mann, and Andrew McCallum.2008.
Learning from labeled features using general-ized expectation criteria.
In SIGIR 2008, pages 595?602, New York, NY, USA.
ACM.Thomas Griffiths and Mark Steyvers.
2004.
Finding sci-entific topics.
Proceedings of the National Academy ofSciences, 101(suppl.
1):5228?5235.Thomas L. Griffiths, Mark Steyvers, David M. Blei, andJoshua B. Tenenbaum.
2005.
Integrating topics andsyntax.
In NIPS 17.S.
Lacoste-Julien, F. Sha, and M. Jordan.
2008.
Disclda:Discriminative learning for dimensionality reductionand classification.
In Advances in Neural InformationProcessing Systems 21 (NIPS08).David Newman, Kat Hagedorn, ChaitanyaChemudugunta, and Padhraic Smyth.
2007.
Subjectmetadata enrichment using statistical topic models.In JCDL ?07: Proceedings of the 7th ACM/IEEE-CSjoint conference on Digital libraries, pages 366?375,New York, NY, USA.
ACM.Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers, andPadhraic Smyth.
2004.
The author-topic model for au-thors and documents.
In Proceedings of the 20th con-ference on Uncertainty in artificial intelligence (UAI),pages 487?494, Arlington, Virginia, United States.AUAI Press.Erik B. Sudderth, Antonio B. Torralba, William T. Free-man, and Alan S. Willsky.
2005.
Learning hierar-chical models of scenes, objects, and parts.
In ICCV,pages 1331?1338.Erik Tjong Kim Sang and Fien De Meulder.
2003.
In-troduction to the conll-2003 shared task: Language-independent named entity recognition.
In Proceedingsof CoNLL-2003, pages 142?147, Edmonton, Canada.Xiaogang Wang and Eric Grimson.
2008.
Spatial latentdirichlet alocation.
In J.C. Platt, D. Koller, Y. Singer,and S. Roweis, editors, NIPS 20, pages 1577?1584.MIT Press, Cambridge, MA.Yang Wang and Greg Mori.
2009.
Human action recog-nition by semi-latent topic models.
In IEEE Transac-tions on Pattern Analysis and Machine Intelligence.Xin Yang, Haoying Fu, Hongyuan Zha, and Jesse Barlow.2006.
Semi-supervised nonlinear dimensionality re-duction.
In ICML-06, 23nd International Conferenceon Machine Learning.48
