Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1568?1576,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsBeam Search for Solving Substitution CiphersMalte Nuhn and Julian Schamper and Hermann NeyHuman Language Technology and Pattern RecognitionComputer Science Department, RWTH Aachen University, Aachen, Germany<surname>@cs.rwth-aachen.deAbstractIn this paper we address the problem ofsolving substitution ciphers using a beamsearch approach.
We present a concep-tually consistent and easy to implementmethod that improves the current state ofthe art for decipherment of substitution ci-phers and is able to use high order n-gramlanguage models.
We show experimentswith 1:1 substitution ciphers in which theguaranteed optimal solution for 3-gramlanguage models has 38.6% deciphermenterror, while our approach achieves 4.13%decipherment error in a fraction of timeby using a 6-gram language model.
Wealso apply our approach to the famousZodiac-408 cipher and obtain slightly bet-ter (and near to optimal) results than pre-viously published.
Unlike the previousstate-of-the-art approach that uses addi-tional word lists to evaluate possible deci-pherments, our approach only uses a letter-based 6-gram language model.
Further-more we use our algorithm to solve largevocabulary substitution ciphers and im-prove the best published decipherment er-ror rate based on the Gigaword corpus of7.8% to 6.0% error rate.1 IntroductionState-of-the-art statistical machine translation(SMT) systems use large amounts of parallel datato estimate translation models.
However, parallelcorpora are expensive and not available for everydomain.Recently different works have been publishedthat train translation models using only non-parallel data.
Although first practical applicationsof these approaches have been shown, the overalldecipherment accuracy of the proposed algorithmsis still low.
Improving the core decipherment algo-rithms is an important step for making decipher-ment techniques useful for practical applications.In this paper we present an effective beamsearch algorithm which provides high decipher-ment accuracies while having low computationalrequirements.
The proposed approach allows us-ing high order n-gram language models, is scal-able to large vocabulary sizes and can be adjustedto account for a given amount of computationalresources.
We show significant improvements indecipherment accuracy in a variety of experimentswhile being computationally more effective thanprevious published works.2 Related WorkThe experiments proposed in this paper touchmany of previously published works in the deci-pherment field.Regarding the decipherment of 1:1 substitutionciphers various works have been published: Mostolder papers do not use a statistical approach andinstead define some heuristic measures for scoringcandidate decipherments.
Approaches like (Hart,1994) and (Olson, 2007) use a dictionary to checkif a decipherment is useful.
(Clark, 1998) definesother suitability measures based on n-gram countsand presents a variety of optimization techniqueslike simulated annealing, genetic algorithms andtabu search.On the other hand, statistical approaches for1:1 substitution ciphers were published in the nat-ural language processing community: (Ravi andKnight, 2008) solve 1:1 substitution ciphers opti-mally by formulating the decipherment problem asan integer linear program (ILP) while (Corlett andPenn, 2010) solve the problem using A?
search.We use our own implementation of these methodsto report optimal solutions to 1:1 substitution ci-1568phers for language model orders n = 2 and n = 3.
(Ravi and Knight, 2011a) report the first au-tomatic decipherment of the Zodiac-408 cipher.They use a combination of a 3-gram languagemodel and a word dictionary.
We run our beamsearch approach on the same cipher and reportbetter results without using an additional worddictionary?just by using a high order n-gram lan-guage model.
(Ravi and Knight, 2011b) report experiments onlarge vocabulary substitution ciphers based on theTranstac corpus.
(Dou and Knight, 2012) improveupon these results and provide state-of-the-art re-sults on a large vocabulary word substitution ci-pher based on the Gigaword corpus.
We run ourmethod on the same corpus and report improve-ments over the state of the art.
(Ravi and Knight, 2011b) and (Nuhn et al,2012) have shown that?even for larger vocabu-lary sizes?it is possible to learn a full translationmodel from non-parallel data.
Even though thiswork is currently only able to deal with substi-tution ciphers, phenomena like reordering, inser-tions and deletions can in principle be included inour approach.3 DefinitionsIn the following we will use the machine trans-lation notation and denote the ciphertext withfN1 = f1 .
.
.
fj .
.
.
fN which consists of ciphertokens fj ?
Vf .
We denote the plaintext witheN1 = e1 .
.
.
ei .
.
.
eN (and its vocabulary Ve re-spectively).
We definee0 = f0 = eN+1 = fN+1 = $ (1)with ?$?
being a special sentence boundary token.We use the abbreviations V e = Ve ?
{$} and V frespectively.A general substitution cipher uses a tables(e|f) which contains for each cipher token f aprobability that the token f is substituted with theplaintext token e. Such a table for substitutingcipher tokens {A,B,C,D} with plaintext tokens{a, b, c, d} could for example look likea b c dA 0.1 0.2 0.3 0.4B 0.4 0.2 0.1 0.3C 0.4 0.1 0.2 0.3D 0.3 0.4 0.2 0.1The 1:1 substitution cipher encrypts a givenplaintext into a ciphertext by replacing each plain-text token with a unique substitute: This meansthat the table s(e|f) contains all zeroes, except forone ?1.0?
per f ?
Vf and one ?1.0?
per e ?
Ve.For example the textabadcabwould be enciphered toBCBADBCwhen using the substitutiona b c dA 0 0 0 1B 1 0 0 0C 0 1 0 0D 0 0 1 0In contrast to the 1:1 substitution cipher, the ho-mophonic substitution cipher allows multiple ci-pher tokens per plaintext token, which means thatthe table s(e|f) is all zero, except for one ?1.0?
perf ?
Vf .
For example the above plaintext could beenciphered toABCDECFwhen using the homophonic substitutiona b c dA 1 0 0 0B 0 1 0 0C 1 0 0 0D 0 0 0 1E 0 0 1 0F 0 1 0 0We will use the definitionnmax = maxe?fs(e|f) (2)to characterize the maximum number of differentcipher symbols allowed per plaintext symbol.We formalize the 1:1 substitutions with a bijec-tive function ?
: Vf ?
Ve and homophonic sub-stitutions with a general function ?
: Vf ?
Ve.Following (Corlett and Penn, 2010), we callcipher functions ?, for which not all ?
(f)?s arefixed, partial cipher functions .
Further, ??
issaid to extend ?, if for all f that are fixed in ?, itholds that f is also fixed in ??
with ??
(f) = ?
(f).1569The cardinality of ?
counts the number of fixedf ?s in ?.When talking about partial cipher functions weuse the notation for relations, in which ?
?
Vf ?Ve.
For example with?
= {(A, a)} ??
= {(A, a), (B, b)}it follows that ?
?1??
and|?| = 1 |?
?| = 2?
(A) = a ??
(A) = a?
(B) = undefined ??
(B) = bThe general decipherment goal is to obtain amapping ?
such that the probability of the deci-phered text is maximal:??
= argmax?p(?(f1)?(f2)?(f3)...?
(fN )) (3)Here p(.
.
. )
denotes the language model.
De-pending on the structure of the language modelEquation 3 can be further simplified.4 Beam SearchIn this Section we present our beam search ap-proach to solving Equation 3.
We first present thegeneral algorithm, containing many higher levelfunctions.
We then discuss possible instances ofthese higher level functions.4.1 General AlgorithmFigure 1 shows the general structure of the beamsearch algorithm for the decipherment of substi-tution ciphers.
The general idea is to keep trackof all partial hypotheses in two arrays Hs and Ht.During search all possible extensions of the partialhypotheses in Hs are generated and scored.
Here,the function EXT ORDER chooses which ciphersymbol is used next for extension, EXT LIMITSdecides which extensions are allowed, and SCOREscores the new partial hypotheses.
PRUNE then se-lects a subset of these hypotheses which are storedto Ht.
Afterwards the array Hs is copied to Htand the search process continues with the updatedarray Hs.Due to the structure of the algorithm the car-dinality of all hypotheses in Hs increases in eachstep.
Thus only hypotheses of the same cardinality1shorthand notation for ??
extends ?1: function BEAM SEARCH(EXT ORDER,EXT LIMITS, PRUNE)2: init sets Hs, Ht3: CARDINALITY = 04: Hs.ADD((?, 0))5: while CARDINALITY < |Vf | do6: f = EXT ORDER[CARDINALITY]7: for all ?
?
Hs do8: for all e ?
Ve do9: ??
:= ?
?
{(e, f)}10: if EXT LIMITS(??)
then11: Ht.ADD(?
?,SCORE (??
))12: end if13: end for14: end for15: PRUNE(Ht)16: CARDINALITY = CARDINALITY + 117: Hs = Ht18: Ht.CLEAR()19: end while20: return best scoring cipher function in Hs21: end functionFigure 1: The general structure of the beamsearch algorithm for decipherment of substitu-tion ciphers.
The high level functions SCORE,EXT ORDER, EXT LIMITS and PRUNE are de-scribed in Section 4.are compared in the pruning step.
When Hs con-tains full cipher relations, the cipher relation withthe maximal score is returned.2Figure 2 illustrates how the algorithm exploresthe search space for a homophonic substitution ci-pher.
In the following we show several instancesof EXT ORDER, EXT LIMITS, SCORE, and PRUNE.4.2 Extension Limits (EXT LIMITS)In addition to the implicit constraint of ?
beinga function Vf ?
Ve, one might be interested infunctions of a specific form:For 1:1 substitution ciphers(EXT LIMITS SIMPLE) ?
must fulfill that thenumber of cipher letters f ?
Vf that map to anye ?
Ve is at most one.
Since partial hypothesesviolating this condition can never ?recover?
whenbeing extended, it becomes clear that these partialhypotheses can be left out from search.2n-best output can be implemented by returning the n bestscoring hypotheses in the final array Hs.1570?abcdabcdabcdabcdabcd.
.
.. .
.. .
.. .
.. .
.abcdabcdabcdabcd.
.
.. .
.. .
.. .
.abcdabcdabcdabcdB C A DFigure 2: Illustration of the search space explored by the beam search algorithm with cipher vocabularyVf = {A,B,C,D}, plaintext vocabulary Ve = {a, b, c, d}, EXT ORDER = (B,C,A,D), homophonicextension limits (EXT LIMITS HOMOPHONIC) with nmax = 4, and histogram pruning with nkeep = 4.Hypotheses are visualized as nodes in the tree.
The x-axis represents the extension order.
At each levelonly those 4 hypotheses that survived the histogram pruning process are extended.Homophonic substitution ciphers can be han-dled by the beam search algorithm, too.
Herethe condition that ?
must fulfill is that the num-ber of cipher letters f ?
Vf that map to anye ?
Ve is at most nmax (which we will callEXT LIMITS HOMOPHONIC).
As soon as this con-dition is violated, all further extensions will alsoviolate the condition.
Thus, these partial hypothe-ses can be left out.4.3 Score Estimation (SCORE)The score estimation function needs to predicthow good or bad a partial hypothesis (cipher func-tion) might become.
We propose simple heuristicsthat use the n-gram counts rather than the originalciphertext.
The following formulas consider the2-gram case.
Equations for higher n-gram orderscan be obtained analogously.With Equation 3 in mind, we want to estimatethe best possible scoreN+1?j=1p(??(fj)|??
(fj?1)) (4)which can be obtained by extensions ??
?
?.
Bydefining counts3Nff ?
=N+1?i=1?
(f, fi?1)?
(f ?, fi) (5)3?
denotes the Kronecker delta.we can equivalently use the scores?f,f ?
?V fNff ?
log p(??
(f ?)|??
(f)) (6)Using this formulation it is easy to proposea whole class of heuristics: We only presentthe simplest heuristic, which we call TRIV-IAL HEURISTIC.
Its name stems from the fact thatit only evaluates those parts of a given ??
that arealready fixed, and thus does not estimate any fu-ture costs.
Its score is calculated as?f,f ???
?Nff ?
log p(??
(f ?)|??(f)).
(7)Here f, f ?
?
??
denotes that f and f ?
need tobe covered in ??.
This heuristic is optimistic sincewe implicitly use ?0?
as estimate for the non fixedparts of the sum, for which Nff ?
log p(?|?)
?
0holds.It should be noted that this heuristic can be im-plemented very efficiently.
Given a partial hypoth-esis ?
with given SCORE(?)
the score of an exten-sion ??
can be calculated asSCORE(??)
= SCORE(?)
+ NEWLY FIXED(?, ??
)(8)where NEWLY FIXED only includes scores forn-grams that have been newly fixed in ??
duringthe extension step from ?
to ?
?.15714.4 Extension Order (EXT ORDER)For the choice which ciphertext symbol should befixed next during search, several possibilities ex-ist: The overall goal is to choose an extension or-der that leads to an overall low error rate.
Intu-itively it seems a good idea to first try to decipherhigher frequent words rather than the lowest fre-quent ones.
It is also clear that the choice of a goodextension order is dependent on the score estima-tion function SCORE: The extension order shouldlead to informative scores early on so that mislead-ing hypotheses can be pruned out early.In most of our experiments we willmake use of a very simple extension order:HIGHEST UNIGRAM FREQUENCY simply fixesthe most frequent symbols first.In case of the Zodiac-408, we use another strat-egy that we call HIGHEST NGRAM COUNT ex-tension order.
In each step it greedily choosesthe symbol that will maximize the number offixed ciphertext n-grams.
This strategy is use-ful because the SCORE function we use is TRIV-IAL HEURISTIC, which is not able to provide in-formative scores if only few full n-grams are fixed.4.5 Pruning (PRUNE)We propose two pruning methods:HISTOGRAM PRUNING sorts all hypothesesaccording to their score and then keeps only thebest nkeep hypotheses.THRESHOLD PRUNING keeps only those hy-potheses ?keep for whichSCORE(?keep) ?
SCORE(?best)?
?
(9)holds for a given parameter ?
?
0.
Even thoughTHRESHOLD PRUNING has the advantage of notneeding to sort all hypotheses, it has proven dif-ficult to choose proper values for ?.
Due to this,all experiments presented in this paper only useHISTOGRAM PRUNING.5 Iterative Beam Search(Ravi and Knight, 2011b) propose a so called ?it-erative EM algorithm?.
The basic idea is to run adecipherment algorithm?in their case an EM al-gorithm based approach?on a subset of the vo-cabulary.
After having obtained the results fromthe restricted vocabulary run, these results are usedto initialize a decipherment run with a larger vo-cabulary.
The results from this run will then beused for a further decipherment run with an evenlarger vocabulary and so on.
In our large vocabu-lary word substitution cipher experiments we it-eratively increase the vocabulary from the 1000most frequent words, until we finally reach the50000 most frequent words.6 Experimental EvaluationWe conduct experiments on letter based 1:1 sub-stitution ciphers, the homophonic substitution ci-pher Zodiac-408, and word based 1:1 substitutionciphers.For a given reference mapping ?ref , we eval-uate candidate mappings ?
using two error mea-sures: Mapping Error Rate MER(?, ?ref ) andSymbol Error Rate SER(?, ?ref ).
Roughlyspeaking, SER reports the fraction of symbolsin the deciphered text that are not correct, whileMER reports the fraction of incorrect mappingsin ?.Given a set of symbols Veval with unigramcountsN(v) for v ?
Veval, and the total amount ofrunning symbols Neval = ?v?VevalN(v) we defineMER = 1??v?Veval1|Veval|?
?(?
(v), ?ref (v))(10)SER = 1??v?VevalN(v)Neval?
?(?
(v), ?ref (v))(11)Thus the SER can be seen as a weighted form ofthe MER, emphasizing errors for frequent words.In decipherment experiments, SER will often belower than MER, since it is often easier to deci-pher frequent words.6.1 Letter Substitution CiphersAs ciphertext we use the text of the EnglishWikipedia article about History4, remove all pic-tures, tables, and captions, convert all letters tolowercase, and then remove all non-letter and non-space symbols.
This corpus forms the basis forshorter cryptograms of size 2, 4, 8, 16, 32, 64, 128,and 256?of which we generate 50 each.
We makesure that these shorter cryptograms do not end orstart in the middle of a word.
We create the ci-phertext using a 1:1 substitution cipher in whichwe fix the mapping of the space symbol ?
?.
This4http://en.wikipedia.org/wiki/History1572Order Beam MER [%] SER [%] RT [s]3 10 33.15 25.27 0.013 100 12.00 6.95 0.063 1k 7.37 3.06 0.533 10k 5.10 1.42 5.333 100k 4.93 1.31 47.703 ??
4.93 1.31 19 700.004 10 55.97 48.19 0.024 100 18.15 14.41 0.104 1k 5.13 3.42 0.894 10k 1.55 1.00 8.574 100k 0.39 0.06 81.345 10 69.19 60.13 0.025 100 35.57 29.02 0.145 1k 10.89 8.47 1.295 10k 0.38 0.06 11.915 100k 0.38 0.06 120.386 10 74.65 64.77 0.036 100 40.26 33.38 0.176 1k 13.53 10.08 1.586 10k 2.45 1.28 15.776 100k 0.09 0.05 151.85Table 1: Symbol error rates (SER), Mapping er-ror rates (MER) and runtimes (RT) in dependenceof language model order (ORDER) and histogrampruning size (BEAM) for decipherment of lettersubstitution ciphers of length 128.
Runtimes arereported on a single core machine.
Results forbeam size ???
were obtained using A?
search.makes our experiments comparable to those con-ducted in (Ravi and Knight, 2008).
Note that fix-ing the ?
?
symbol makes the problem much eas-ier: The exact methods show much higher com-putational demands for lengths beyond 256 letterswhen not fixing the space symbol.The plaintext language model we use a letterbased (Ve = {a, .
.
.
, z, }) language model trainedon a subset of the Gigaword corpus (Graff et al,2007).We use extension limits fitting the 1:1 substi-tution cipher nmax = 1 and histogram pruningwith different beam sizes.For comparison we reimplemented the ILP ap-proach from (Ravi and Knight, 2008) as well asthe A?
approach from (Corlett and Penn, 2010).Figure 3 shows the results of our algorithm fordifferent cipher length.
We use a beam size of100k for the 4, 5 and 6-gram case.
Most remark-ably our 6-gram beam search results are signifi-cantly better than all methods presented in the lit-erature.
For the cipher length of 32 we obtain asymbol error rate of just 4.1% where the optimalsolution (i.e.
without search errors) for a 3-gram2 4 8 16 32 64 128 2560102030405060708090100Cipher LengthSymbolErrorRate(%)Exact 2gramExact 3gramBeam 3gramBeam 4gramBeam 5gramBeam 6gramFigure 3: Symbol error rates for decipherment ofletter substitution ciphers of different lengths.
Er-ror bars show the 95% confidence interval basedon decipherment on 50 different ciphers.
Beamsearch was performed with a beam size of ?100k?.language model has a symbol error rate as high as38.3%.Table 1 shows error rates and runtimes of ouralgorithm for different beam sizes and languagemodel orders given a fixed ciphertext length of 128letters.
It can be seen that achieving close to op-timal results is possible in a fraction of the CPUtime needed for the optimal solution: In the 3-gram case the optimal solution is found in 1400 thof the time needed using A?
search.
It can alsobe seen that increasing the language model orderdoes not increase the runtime much while provid-ing better results if the beam size is large enough:If the beam size is not large enough, the decipher-ment accuracy decreases when increasing the lan-guage model order: This is because the higher or-der heuristics do not give reliable scores if onlyfew n-grams are fixed.To summarize: The beam search method is sig-nificantly faster and obtains significantly better re-sults than previously published methods.
Further-more it offers a good trade-off between CPU timeand decipherment accuracy.1573i l i k e k i l l i n g p e o p le b e c a u s e i t i s s o m u ch f u n i t i n m o r e f u n t ha n k i l l i n g w i l d g a m ei n t h e f o r r e s t b e c a us e m a n i s t h e m o a t r a ng e r o u e a n a m a l o f a l lt o k i l l s o m e t h i n g g iFigure 4: First 136 letters of the Zodiac-408 cipherand its decipherment.6.2 Zodiac-408 CipherAs ciphertext we use a transcription of theZodiac-408 cipher.
It consists of 54 different sym-bols and has a length of 408 symbols.5 The ci-pher has been deciphered by hand before.
It con-tains some mistakes and ambiguities: For exam-ple, it contains misspelled words like forrest (vs.forest), experence (vs. experience), or paradice(vs. paradise).
Furthermore, the last 17 lettersof the cipher do not form understandable Englishwhen applying the same homophonic substitutionthat deciphers the rest of the cipher.
This makesthe Zodiac-408 a good candidate for testing the ro-bustness of a decipherment algorithm.We assume a homophonic substitution cipher,even though the cipher is not strictly homophonic:It contains three cipher symbols that correspondto two or more plaintext symbols.
We ignore thisfact for our experiments, and count?in case of theMER only?the decipherment for these symbolsas correct when the obtained mapping is containedin the set of reference symbols.
We use extensionlimits with nmax = 8 and histogram pruningwith beam sizes of 10k up to 10M .The plaintext language model is based on thesame subset of Gigaword (Graff et al, 2007) dataas the experiments for the letter substitution ci-phers.
However, we first removed all space sym-5hence its nameOrder Beam MER [%] SER [%] RT [s]4 10k 71.43 67.16 2224 100k 66.07 61.52 1 4604 1M 39.29 34.80 12 7014 10M 19.64 16.18 125 0565 10k 94.64 96.57 2575 100k 10.71 5.39 1 7065 1M 8.93 3.19 14 7245 10M 8.93 3.19 152 7646 10k 87.50 84.80 2626 100k 94.64 94.61 1 9926 1M 8.93 2.70 17 7016 10M 7.14 1.96 167 181Table 2: Symbol error rates (SER), Mapping er-ror rates (MER) and runtimes (RT) in dependenceof language model order (ORDER) and histogrampruning size (BEAM) for the decipherment of theZodiac-408 cipher.
Runtimes are reported on a128-core machine.bols from the training corpus before training theactual letter based 4-gram, 5-gram, and 6-gramlanguage model on it.
Other than (Ravi andKnight, 2011a) we do not use any word lists andby that avoid any degrees of freedom in how to in-tegrate it into the search process: Only an n-gramlanguage model is used.Figure 4 shows the first parts of the cipher andour best decipherment.
Table 2 shows the resultsof our algorithm on the Zodiac-408 cipher for dif-ferent language model orders and pruning settings.To summarize: Our final decipherment?forwhich we only use a 6-gram language model?hasa symbol error rate of only 2.0%, which is slightlybetter than the best decipherment reported in (Raviand Knight, 2011a).
They used an n-gram lan-guage model together with a word dictionary andobtained a symbol error rate of 2.2%.
We thus ob-tain better results with less modeling.6.3 Word Substitution CiphersAs ciphertext, we use parts of the JRC corpus(Steinberger et al, 2006) and the Gigaword cor-pus (Graff et al, 2007).
While the full JRC corpuscontains roughly 180k word types and consists ofapproximately 70M running words, the full Giga-word corpus contains around 2M word types androughly 1.5G running words.We run experiments for three different setups:The ?JRC?
and ?Gigaword?
setups use the firsthalf of the respective corpus as ciphertext, whilethe plaintext language model of order n = 3 was1574Setup Top MER [%] SER [%] RT [hh:mm]Gigaword 1k 81.91 27.38 03h 10mGigaword 10k 30.29 8.55 09h 21mGigaword 20k 21.78 6.51 16h 25mGigaword 50k 19.40 5.96 49h 02mJRC 1k 73.28 15.42 00h 32mJRC 10k 15.82 2.61 13h 03mJRC-Shuf 1k 76.83 19.04 00h 31mJRC-Shuf 10k 15.08 2.58 13h 03mTable 3: Word error rates (WER), Mapping errorrates (MER) and runtimes (RT) for iterative deci-pherment run on the (TOP) most frequent words.Error rates are evaluated on the full vocabulary.Runtimes are reported on a 128-core machine.trained on the second half.
The ?JRC-Shuf?
setupis created by randomly selecting half of the sen-tences of the JRC corpus as ciphertext, while thelanguage model was trained on the complemen-tary half of the corpus.We encrypt the ciphertext using a 1:1 substi-tution cipher on word level, imposing a muchlarger vocabulary size.
We use histogram prun-ing with a beam size of 128 and use extensionlimits of nmax = 1.
Different to the previousexperiments, we use iterative beam search withiterations as shown in Table 3.The results for the Gigaword task are directlycomparable to the word substitution experimentspresented in (Dou and Knight, 2012).
Their fi-nal decipherment has a symbol error rate of 7.8%.Our algorithm obtains 6.0% symbol error rate.
Itshould be noted that the improvements of 1.8%symbol error rate correspond to a larger improve-ment in terms of mapping error rate.
This can alsobe seen when looking at Table 3: An improvementof the symbol error rate from 6.51% to 5.96% cor-responds to an improvement of mapping error ratefrom 21.78% to 19.40%.To summarize: Using our beam search algo-rithm in an iterative fashion, we are able to im-prove the state-of-the-art decipherment accuracyfor word substitution ciphers.7 ConclusionWe have presented a simple and effective beamsearch approach to the decipherment problem.
Wehave shown in a variety of experiments?lettersubstitution ciphers, the Zodiac-408, and wordsubstitution ciphers?that our approach outper-forms the current state of the art while being con-ceptually simpler and keeping computational de-mands low.We want to note that the presented algorithm isnot restricted to 1:1 and homophonic substitutionciphers: It is possible to extend the algorithm tosolve n:m mappings.
Along with more sophis-ticated pruning strategies, score estimation func-tions, and extension orders, this will be left for fu-ture research.AcknowledgementsThis work was partly realized as part of theQuaero Programme, funded by OSEO, FrenchState agency for innovation.
Experiments wereperformed with computing resources granted byJARA-HPC from RWTH Aachen University un-der project ?jara0040?.ReferencesAndrew J. Clark.
1998.
Optimisation heuristics forcryptology.
Ph.D. thesis, Faculty of InformationTechnology, Queensland University of Technology.Eric Corlett and Gerald Penn.
2010.
An exact A*method for deciphering letter-substitution ciphers.In Proceedings of the 48th Annual Meeting of theAssociation for Computational Linguistics (ACL),pages 1040?1047, Uppsala, Sweden, July.
The As-sociation for Computer Linguistics.Qing Dou and Kevin Knight.
2012.
Large scale deci-pherment for out-of-domain machine translation.
InConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL), pages 266?275,Jeju Island, Korea, July.
Association for Computa-tional Linguistics.David Graff, Junbo Kong, Ke Chen, and KazuakiMaeda.
2007.
English Gigaword Third Edition.Linguistic Data Consortium, Philadelphia.George W. Hart.
1994.
To decode short cryptograms.Communications of the Association for ComputingMachinery (CACM), 37(9):102?108, September.Malte Nuhn, Arne Mauser, and Hermann Ney.
2012.Deciphering foreign language by combining lan-guage models and context vectors.
In Proceedingsof the 50th Annual Meeting of the Association forComputational Linguistics (ACL), pages 156?164,Jeju, Republic of Korea, July.
Association for Com-putational Linguistics.Edwin Olson.
2007.
Robust dictionary attack ofshort simple substitution ciphers.
Cryptologia,31(4):332?342, October.1575Sujith Ravi and Kevin Knight.
2008.
Attacking de-cipherment problems optimally with low-order n-gram models.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 812?819, Honolulu, Hawaii.
Asso-ciation for Computational Linguistics.Sujith Ravi and Kevin Knight.
2011a.
Bayesian infer-ence for Zodiac and other homophonic ciphers.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL), pages239?247, Portland, Oregon, June.
Association forComputational Linguistics.Sujith Ravi and Kevin Knight.
2011b.
Decipheringforeign language.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies (ACL-HLT), pages 12?21, Portland, Oregon, USA, June.Association for Computational Linguistics.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Tomaz?
Erjavec, and Dan Tufis?.
2006.The JRC-Acquis: A multilingual aligned parallelcorpus with 20+ languages.
In In Proceedings ofthe 5th International Conference on Language Re-sources and Evaluation (LREC), pages 2142?2147.European Language Resources Association.1576
