Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 108?113, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsClaC: Semantic Relatedness of Words and PhrasesReda SibliniConcordia University1400 de Maisonneuve Blvd.
WestMontreal, Quebec, Canada, H3G 1M8r_sibl@encs.concordia.caLeila KosseimConcordia University1400 de Maisonneuve Blvd.
WestMontreal, Quebec, Canada, H3G 1M8kosseim@encs.concordia.caAbstractThe measurement of phrasal semantic relat-edness is an important metric for many nat-ural language processing applications.
In thispaper, we present three approaches for mea-suring phrasal semantics, one based on a se-mantic network model, another on a distribu-tional similarity model, and a hybrid betweenthe two.
Our hybrid approach achieved an F-measure of 77.4% on the task of evaluatingthe semantic similarity of words and compo-sitional phrases.1 IntroductionPhrasal semantic relatedness is a measurement ofhow multiword expressions are related in meaning.Many natural language processing applicationssuch as textual entailment, question answering, orinformation retrieval require a robust measurementof phrasal semantic relatedness.
Current approachesto address this problem can be categorized into threemain categories: those that rely on a knowledgebase and its structure, those that use the distribu-tional hypothesis on a large corpus, and hybridapproaches.
In this paper, we propose supervisedapproaches for comparing phrasal semantics that arebased on a semantic network model, a distributionalsimilarity model, and a hybrid between the two.Those approaches have been evaluated on the taskof semantic similarity of words and compositionalphrases and on the task of evaluating the composi-tionality of phrases in context.2 Semantic Similarity of Words andCompositional PhrasesThe semantic similarity of words and compositionalphrases is the task of evaluating the similarity of aword and a short phrase of two or more words; forexample, the word Interview and the phrase FormalMeeting.
In the next section we present our seman-tic network model for computing phrasal semanticrelatedness between a word and a phrase, followedby a distributional similarity model, that we evalu-ate on the task of semantic similarity of words andcompositional phrases.2.1 Semantic Network ModelKnowledge-based approaches to semantic related-ness use the features of the knowledge base to mea-sure the relatedness.
One of most frequently usedsemantic network is the Princeton?s WordNet (Fell-baum, 1998) which groups words into synonymssets (called synsets) and includes 26 semantic rela-tions between those synsets, including: hypernymy,hyponymy, meronymy, entailment .
.
.To measure relatedness, most of those approachesrely on the structure of the semantic network, suchas the semantic link path, depth (Leacock andChodorow, 1998; Wu and Palmer, 1994), direction(Hirst and St-Onge, 1998), or type (Tsatsaronis etal., 2010).
Our phrasal semantic relatedness ap-proach is inspired from those methods.
However,our approach is based on the idea that the combi-nation of the least costly types of relations that re-late one concept to a set of concepts are a suitableindicator of their semantic relatedness.
The typeof relations considered includes not only the hy-108Figure 1: Example of the semantic network around the word car.ponym/hypernym relations but also all 26 availablesemantic relations found in WordNet in addition torelations extracted from each of the eXtended Word-Net (Harabagiu et al 1999) synset?s logical form.To implement our idea, we created a weighted anddirected semantic network based on the relations ofWordNet and eXtended WordNet.
We used Word-Net?s words and synsets as the nodes of the network.Each word is connected by an edge to its synsets,and each synset is in turn connected to other synsetsbased on the semantic relations included in Word-Net.
In addition each synset is connected by a la-beled edge to the predicate arguments that are ex-tracted from the eXtended WordNet synset?s logicalform.
Every synset in the eXtended WordNet is re-lated to a logical form, which contains a set of pred-icate relations that relates the synset to set of words.Each predicate in this representation is added as anedge to the graph connecting the synset to a word.For example, Figure 1 shows part of the semanticnetwork created around the word car.
In this graph,single-line ovals represent words, while double-lineovals represent synsets.To compute the semantic relatedness betweennodes in the semantic network, it is necessary to takeinto consideration the semantic relation involved be-tween two nodes.
Indeed, WordNet?s 26 semanticrelations are not equally distributed nor do they con-tribute equally to the semantic relatedness betweenconcept.
In order to indicate the contribution of eachrelation, we have classified them into seven cate-gories: Similar, Hypernym, Sense, Predicate, Part,Instance, and Other.
By classifying WordNet?s re-lations into these classes, we are able to weightthe contribution of a relation based on the class itbelongs to, as opposed to assigning a contributoryweight to each relations.
The weights were assignedby manually comparing the semantic features of aset of concepts that are related by a specific seman-tic relations.
Table 1 shows the seven semantic cat-egories that we defined, their corresponding weight,and the relations they include.
For example the cat-egory Similar includes WordNet?s relations of en-tailment, cause, verb group, similar to, participle ofverb, antonym, and pertainym.
This class of rela-tions has the most common semantic features whencomparing two concepts related with any of thoserelations and hence was assigned the lowest weight1of 1.
All the 26 relations in the table are the onesfound in WordNet, for the exception of the predicate(and inverse predicate) relations which are the predi-cate relations extracted from the eXtended WordNet.This can be seen in Figure 1, for example, where theword car is related to the word Engine with the Pred-icate relation extracted from the eXtended WordNetlogical form and more specifically the predicate pro-pel by.The computation of semantic relatedness be-tween a word and a compositional phrase is thenthe combination of weights of the shortest weightedpath2 in the weighted semantic network betweenthat word and every word in that phrase, normalizedby the maximum path cost.1The weight can be seen as the cost of traversing an edge;hence a lower weight is assigned to a highly contributory rela-tion.2The shortest path is based on an implementation of Dijk-stras graph search algorithm (Dijkstra, 1959)109Category Weight Semantic Relations in WordNet or xWordnetSimilar 1 similar to, pertainym, participle of verb, entailment, cause,antonym, verb groupHypernym 2 hypernym, instance hypernym, derivationally relatedSense 4 lemma-synsetPredicate 6 predicate (extracted from Extended WordNet)Part 8 holonym (instance, member, substance), meronym (instance,member, substance), inverse predicate (extracted from ExtendedWordNet)Instance 10 hyponym, instance hyponymOther 12 attribute, also see, domain of synset (topic, region, usage), memberof this domain (topic, region, usage)Table 1: Relations Categories and Corresponding Weights.Figure 2 shows an extract of the network involv-ing the words Interview and the phrase Formal Meet-ing.
For the shortest path from Interview to Formal,the word Interview is connected with a Sense rela-tion to the synset #107210735 [Interview].
As in-dicated in Table 1, the weight of this relation is de-fined as 4, This synset is connected to the synset Ex-amination through a Hypernym relation type with aweight of 2, which is connected to the word Formalwith a predicate (IS) relation of weight 6.
Overall,the sum of the shortest path from Interview to For-mal Meeting is hence equal to the sum of the edgesshown in Figure 1 (4+2+6+4+6+4+6 = 32).
By nor-malizing the sum to the maximum, In our approach,24 is maximum path cost after which we assumethat two words are not related (which we assume tobe traversing two times maximum weighted path, 2* maximum path weight of 12) and 8 is the mini-mum number of edges between 2 words (which isequal to traversing from the word to itself, 2 * senseweight of 4)).
Taking into consideration the numberof words in the phrase, the semantic relatedness willbe (24*2 - (32-8*2))/24*2 = 66.7%.
In the next sec-tion, we will introduce our distributional similaritymodel.2.2 Distributional Similarity ModelDistributional similarity models rely on the distribu-tional hypothesis (Harris, 1954) to represent a wordby its context in order to compare word semantics.There are various approach for the selection, repre-sentation, and comparison of contextual data.
Mostuse the vector space model to represent the contextas dimensions in a vector space, where the featureare frequency of co-occurrence of the context words,and the comparison is usually the cosine similar-ity.
To go beyond lexical semantics and to repre-sent phrases, a compositional model is created, someuse the addition or multiplication of vectors suchas Mitchell and Lapata (2008), or the use of tensorproduct to account for word order as in the work ofWiddows (2008), or a more complex model as thework of Grefenstette and Sadrzadeh (2011).
In ourmodel, we are inspired by those various work, andmore specifically by the work of Mitchell and Lapata(2008).
The compositional model is based on phrasewords vectors addition, where each vector is com-posed of the collocation pointwise mutual informa-tion of the word up to a window of 3 words left andright of the main word.
The corpus used to collectthe features and their frequencies is the Web 1TBcorpus (Brants and Franz, 2006).
For the Interviewto Formal Meeting example, the vector of the wordinterview is first created from the corpus of the top1000 words collocating interview between the win-dow of 1 to 3 words with their frequencies.
A similarvector is created for the word Formal and the wordMeeting, the vector representing Formal Meeting isthen the addition of vector Formal to vector Meet-ing.
The comparison of vector Interview to vectorFormal Meeting is then the cosine of both vectors.1102.3 EvaluationWe evaluated our approaches for word-phrase se-mantic relatedness on the SemEval task of evalu-ating phrasal semantics, and more specifically onthe sub-task of evaluating the semantic similaritybetween words and phrases.
The task provided anEnglish dataset of 15,628 word-phrases, 60% an-notated for training and 40% for testing, with thegoal of classifying each word-phrase as either pos-itive or negative.
To transform the semantic relat-edness measure to a semantic similarity classifica-tion one, we first calculated the semantic relatednessof each word-phrase in the training set, and usedJRip, WEKA?s (Witten et al 1999) implementationof Cohen?s RIPPER rule learning algorithm (Cohenand Singer, 1999), in order to learn a set of rules thatcan differentiate between a positive semantic simi-larity and a negative one.
The classifier resulted inrules for the semantic network model based related-ness that could be summarized as follows: If the se-mantic relatedness of the word-phrase is over 61%then the similarity is positive, otherwise it is nega-tive.
So for the example Interview - Formal meeting,which resulted in a semantic relatedness of 66.7% inthe semantic network approach, it will be classifiedpositively by the generated rule.
This method wasour first submitted test run to this task, which re-sulted in a recall of 63.79%, a precision of 91.01%,and an F-measure of 75.00% on the testing set.For the second run, we trained the distributionalsimilarity model using the same classifier.
This re-sulted with the following rule that could be summa-rized as follows: If the semantic relatedness of theword-phrase is over 40% then the similarity is pos-itive, otherwise it is negative.
It was obvious fromthe training set that the semantic network modelwas more accurate than the distributional similaritymodel, but the distributional model had more cover-age.
So for our second submitted test run, we usedthe semantic network approach as the main result,but used the distributional model as a backup ap-proach if one of the words in the phrase was notavailable in WordNet, thus combining the precisionand coverage of both approaches.
This method re-sulted in a recall of 69.48%, a precision of 86.70%,and an F-measure of 77.14% on the testing set.For the last run, we used the same classifierbut this time we training it using two features:the semantic network model relatedness measure(SN), and the distributional similarity model (DS).This training resulted in a set of rules that couldbe summarized as follows: if SN > 61% then thesimilarity is positive, else if DS > 40% then thesimilarity is also positive, and lastly if SN > 53%and DS > 31% then also in this case the similarityis positive, otherwise the similarity is negative.
Thiswas our third submitted test run, which resulted arecall of 70.66%, a precision of 85.55%, and anF-measure of 77.39% on the testing set.3 Semantic Compositionality in ContextThe semantic compositional in context is the task ofevaluating if a phrase is used literally or figurativelyin context.
For example, the phrase big picture isused literally in the sentence Click here for a biggerpicture and figuratively in To solve this problem, youhave to look at the bigger picture.Our approach for this task is a supervised ap-proached based on two main components: first, theavailability of the phrases most frequent collocatingexpressions in a large corpus, and more specificallythe top 1000 phrases by frequency in Web 1TB cor-pus (Brants and Franz, 2006).
For example, for thephrase big picture, we collect the top 1000 phrasesthat come before and after the phrase in a corpus,those includes look at the, see the, understand the.....
If the context contain any of those phrase, thenthis component returns 1, indicating that the phraseis most probably used figuratively.
The intuition isthat, the use of phrases figuratively is more frequentthan their use in a literal meaning, and hence themost frequent use will be collocated with phrasesthat indicate this use.The second component, is the phrase compositional-ity.
We calculate the semantic relatedness using thesemantic network model relatedness measure, thatwas explained in Section 2.1, between the phraseand the first content word before it and after it.
Theintuition here is that the semantic relatedness of thefigurative use of the phrase to its context should bedifferent than the relatedness to its literal use.
Sofor the example, the phrase old school in the con-text he is one of the old school versus the hall of111Figure 2: Shortest Path Between the Word Interview and the Phrase Formal Meeting.the old school, we can notice that hall will be morerelated to old school than the word one.
This compo-nent will result in two features: the relatedness to theword before the phrase (SRB) and the relatedness toword after the phrase in context (SRA).To combine both componenets, we evaluated ourapproaches on the data set presented by the Se-mEval task of evaluating phrasal semantics, andmore specifically on the sub task of evaluating se-mantic compositionality in context.
The data setcontains a total of 1114 training instances, and 518test instances.
We use the training data and com-puted the three features (Frequent Collocation (FC),Semantic Relatedness word Before (SRB), and Se-mantic Relatedness word After (SRA), and usedJRip, WEKA?s (Witten et al 1999) implementationof Cohen?s RIPPER rule learning algorithm (Cohenand Singer, 1999) to learn a set of rule that differen-tiate between a figurative and literal phrase use.
Thismethod resulted in a set of rules that can be summa-rized as follows: if FC is equal to 0 and SRB < 75%then it is used literally in this context, else if FC isequal to 0 and SRA < 75% then it is is also used lit-erally, otherwise it is used figuratively.
This methodresulted in an accuracy of 55.01% on the testing set.4 ConclusionIn this paper we have presented state of the artword-phrase semantic relatedness approaches thatare based on a semantic network model, a distribu-tional model, and a combination of the two.
Thenovelty of the semantic network model approach isthe use of the sum of the shortest path between aword and a phrase from a weighted semantic net-work to calculate word-phrase semantic relatedness.We evaluated the approach on the SemEval task ofevaluating phrasal semantics, once in a supervisedstandalone configuration, another with a backup dis-tributional similarity model, and last in a hybrid con-figuration with the distributional model.
The hy-brid model achieved the highest f-measure in thosethree configuration of 77.4% on the task of evaluat-ing the semantic similarity of words and composi-tional phrases.
We also evaluated this approach onthe subtask of evaluating the semantic composition-ality in context with less success, and an accuracy ofof 55.01%.AcknowledgmentsWe would like to thank the reviewers for their sug-gestions and valuable comments.ReferencesThorsten Brants and Alex Franz.
2006.
Web 1t 5-gramversion 1.William W Cohen and Yoram Singer.
1999.
A simple,fast, and effective rule learner.
In Proceedings of theNational Conference on Artificial Intelligence, pages335?342.
John Wiley & Sons Ltd.Edsger W Dijkstra.
1959.
A note on two problemsin connexion with graphs.
Numerische mathematik,1(1):269?271.112Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press.Edward Grefenstette and Mehrnoosh Sadrzadeh.
2011.Experimental support for a categorical compositionaldistributional model of meaning.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing, pages 1394?1404.
Association forComputational Linguistics.Sanda Harabagiu, George Miller, and Dan Moldovan.1999.
Wordnet 2- a morphologically and semanticallyenhanced resource.
In Proceedings of SIGLEX, vol-ume 99, pages 1?8.Zellig S Harris.
1954.
Distributional structure.
Word.Graeme Hirst and David St-Onge.
1998.
Lexical chainsas representations of context for the detection and cor-rection of malapropisms.
WordNet An electronic lexi-cal database, pages 305?332, April.Claudia Leacock and Martin Chodorow.
1998.
Com-bining local context and wordnet similarity for wordsense identification.
WordNet: An electronic lexicaldatabase, 49(2):265?283.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedmodels of semantic composition.
proceedings of ACL-08: HLT, pages 236?244.George Tsatsaronis, Iraklis Varlamis, and Michalis Vazir-giannis.
2010.
Text relatedness based on a wordthesaurus.
Journal of Artificial Intelligence Research,37(1):1?40.Dominic Widdows.
2008.
Semantic vector products:Some initial investigations.
In To appear in SecondAAAI Symposium on Quantum Interaction, volume 26,page 28th.
Citeseer.Ian H Witten, Eibe Frank, Leonard E Trigg, Mark A Hall,Geoffrey Holmes, and Sally Jo Cunningham.
1999.Weka: Practical machine learning tools and techniqueswith java implementations.Zhibiao Wu and Martha Palmer.
1994.
Verbs seman-tics and lexical selection.
In Proceedings of the 32ndannual meeting on Association for Computational Lin-guistics, pages 133?138, New Mexico, June.113
