Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 778?788,Berlin, Germany, August 7-12, 2016. c?2016 Association for Computational LinguisticsChinese Zero Pronoun Resolution with Deep Neural NetworksChen Chen and Vincent NgHuman Language Technology Research InstituteUniversity of Texas at DallasRichardson, TX 75083-0688{yzcchen,vince}@hlt.utdallas.eduAbstractWhile unsupervised anaphoric zero pro-noun (AZP) resolvers have recently beenshown to rival their supervised counter-parts in performance, it is relatively diffi-cult to scale them up to reach the next levelof performance due to the large amountof feature engineering efforts involved andtheir ineffectiveness in exploiting lexicalfeatures.
To address these weaknesses,we propose a supervised approach to AZPresolution based on deep neural networks,taking advantage of their ability to learnuseful task-specific representations and ef-fectively exploit lexical features via wordembeddings.
Our approach achieves state-of-the-art performance when resolving theChinese AZPs in the OntoNotes corpus.1 IntroductionA zero pronoun (ZP) is a gap in a sentence thatis found when a phonetically null form is used torefer to a real-world entity.
An anaphoric zero pro-noun (AZP) is a ZP that corefers with one or morepreceding mentions in the associated text.
Belowis an example taken from the Chinese Treebank(CTB), where the ZP (denoted as *pro*) refers to???
(Russia).[???]
???????????????*pro*?????????????
([Russia] is a consistent supporter of Milo?evi?,*pro* has proposed to mediate the political crisis.
)As we can see, ZPs lack grammatical attributesthat are useful for overt pronoun resolution suchas number and gender.
This makes ZP resolutionmore challenging than overt pronoun resolution.Automatic ZP resolution is typically composedof two steps.
The first step, AZP identification, in-volves extracting ZPs that are anaphoric.
The sec-ond step, AZP resolution, aims to identify an an-tecedent of an AZP.
State-of-the-art ZP resolvershave tackled both of these steps in a supervisedmanner, training one classifier for AZP identifica-tion and another for AZP resolution (e.g., Zhao andNg (2007), Kong and Zhou (2010)).More recently, Chen and Ng (2014b; 2015) haveproposed unsupervised probabilistic AZP resolu-tion models (henceforth the CN14 model and theCN15 model, respectively) that rival their super-vised counterparts in performance.
An appeal-ing aspect of these unsupervised models is thattheir language-independent generative process en-ables them to be applied to languages where dataannotated with ZP links are not readily avail-able.
Though achieving state-of-the-art perfor-mance, these models have several weaknesses.First, a lot of manual efforts need to be spenton engineering the features for generative proba-bilistic models, as these models are sensitive to thechoice of features.
For instance, having featuresthat are (partially) dependent on each other couldharm model performance.
Second, in the absenceof labeled data, it is difficult, though not impos-sible, for these models to profitably employ lexi-cal features (e.g., word pairs, syntactic patterns in-volving words), as determining which lexical fea-tures are useful and how to combine the poten-tially large number of lexical features in an un-supervised manner is a very challenging task.
Infact, the unsupervised models proposed by Chenand Ng (2014b; 2015) are unlexicalized, presum-ably owing to the aforementioned reasons.
Unfor-tunately, as shown in previous work (e.g, Zhao andNg (2007), Chen and Ng (2013)), the use of lex-ical features contributed significantly to the per-formance of state-of-the-art supervised AZP re-solvers.
Finally, owing to the lack of labeled data,the model parameters are learned to maximize data778likelihood, which may not correlate well with thedesired evaluation measure (i.e., F-score).
Hence,while unsupervised resolvers have achieved state-of-the-art performance, these weaknesses togethersuggest that it is very challenging to scale thesemodels up so that they can achieve the next levelof performance.Our goal in this paper is to improve the stateof the art in AZP resolution.
Motivated by theaforementioned weaknesses, we propose a novelapproach to AZP resolution using deep neural net-works, which we believe has three key advantagesover competing unsupervised counterparts.First, deep neural networks are particularly goodat discovering hidden structures from the inputdata and learning task-specific representations viasuccessive transformations of the input vectors,where different layers of a network correspond todifferent levels of abstractions that are useful forthe target task.
For the task of AZP resolution,this is desirable.
Traditionally, it is difficult to cor-rectly resolve an AZP if its context is lexically dif-ferent from its antecedent's context.
This is es-pecially the case for unsupervised resolvers.
Incontrast, a deep network can handle difficult caseslike this via learning representations that make lex-ically different contexts look similar.Second, we train our deep network in a super-vised manner.1 In particular, motivated by re-cent successes of applying the mention-rankingmodel (Denis and Baldridge, 2008) to entity coref-erence resolution (e.g., Chang et al (2013), Dur-rett and Klein (2013), Clark and Manning (2015),Martschat and Strube (2015), Wiseman et al(2015)), we propose to employ a ranking-baseddeep network, which is trained to assign the high-est probability to the correct antecedent of an AZPgiven a set of candidate antecedents.
This con-trasts with existing supervised AZP resolvers, allof which are classification-based.
Optimizing thisobjective function is better than maximizing datalikelihood, as the former is more tightly coupledwith the desired evaluation metric (F-score) thanthe latter.Finally, given that our network is trained in a su-pervised manner, we can extensively employ lex-1Note that deep neural networks do not necessarily have tobe trained in a supervised manner.
In fact, in early research onextending semantic modeling using auto-encoders (Salakhut-dinov and Hinton, 2007), the networks were trained in an un-supervised manner, where the model parameters were opti-mized for the reconstruction of the input vectors.ical features and use them in combination withother types of features that have been shown to beuseful for AZP resolution.
However, rather thanemploying words directly as features, we employword embeddings trained in an unsupervised man-ner.
The goal of the deep network will then beto take these task-independent word embeddingsas input and convert them into embeddings thatwould work best for AZP resolution via super-vised learning.
We call our approach an embed-ding matching approach because the underlyingdeep network attempts to compare the embeddinglearned for an AZPwith the embedding learned foreach of its antecedents.To our knowledge, this is the first approach toAZP resolution based on deep networks.
Whenevaluated on the Chinese portion of the OntoNotes5.0 corpus, our embedding matching approachto AZP resolution outperforms the CN15 model,achieving state-of-the-art results.The rest of the paper is organized as follows.Section 2 overviews related work on zero pro-noun resolution for Chinese and other languages.Section 3 describes our embedding matching ap-proach, specifically the network architecture andthe way we train and apply the network.
Wepresent our evaluation results in Section 4 and ourconclusions in Section 5.2 Related WorkChinese ZP resolution.
Early approaches toChinese ZP resolution are rule-based.
Con-verse (2006) applied Hobbs' algorithm (Hobbs,1978) to resolve the ZPs in the CTB documents.Yeh and Chen (2007) hand-engineered a set ofrules for ZP resolution based on Centering The-ory (Grosz et al, 1995).In contrast, virtually all recent approaches tothis task are learning-based.
Zhao and Ng (2007)are the first to employ a supervised learning ap-proach to Chinese ZP resolution.
They trainedan AZP resolver by employing syntactic and po-sitional features in combination with a decisiontree learner.
Unlike Zhao and Ng, Kong andZhou (2010) employed context-sensitive convolu-tion tree kernels (Zhou et al, 2008) in their re-solver to model syntactic information.
Chen andNg (2013) extended Zhao and Ng's feature set withnovel features that encode the context surroundinga ZP and its candidate antecedents, and exploitedthe coreference links between ZPs as bridges to779Figure 1: The architecture of our embedding matching model.
The number in each box indicates the size of thecorresponding vector.find textually distant antecedents for ZPs.
Asmen-tioned above, there have been attempts to performunsupervised AZP resolution.
For instance, us-ing only data containing manually resolved overtpronouns, Chen and Ng (2014a) trained a super-vised overt pronoun resolver and applied it to re-solve AZPs.
More recently, Chen and Ng (2014b;2015) have proposed unsupervised probabilisticAZP resolution models that rivaled their super-vised counterparts in performance.
While we aimto resolve anaphoric ZPs, Rao et al (2015) re-solved deictic non-anaphoric ZPs, which "referto salient entities in the environment such as thespeaker, hearer or pragmatically accessible refer-ent without requiring any introduction in the pre-ceding text''.ZP resolution for other languages.
There havebeen rule-based and supervised machine learn-ing approaches for resolving ZPs in other lan-guages.
For example, to resolve ZPs in Spanishtexts, Ferr?ndez and Peral (2000) proposed a setof hand-crafted rules that encode preferences forcandidate antecedents.
In addition, supervised ap-proaches have been extensively employed to re-solve ZPs in Korean (e.g., Han (2006)), Japanese(e.g., Seki et al (2002), Isozaki and Hirao (2003),Iida et al (2006; 2007), Sasano et al (2008), Tairaet al (2008), Imamura et al (2009), Sasano et al(2009), Watanabe et al (2010), Hayashibe et al(2011), Iida and Poesio (2011), Sasano and Kuro-hashi (2011), Yoshikawa et al (2011), Hangyo etal.
(2013), Yoshino et al (2013), Iida et al (2015)),and Italian (e.g., Iida and Poesio (2011)).3 ModelIn this section, we first introduce our network ar-chitecture (Section 3.1), and then describe how wetrain it (Section 3.2) and apply it (Section 3.3).3.1 Network ArchitectureThe network architecture is shown in Figure 1.Since we employ a ranking model to rank the can-didate antecedents of an AZP z, the inputs to thenetwork are (1) a feature vector representing theAZP, and (2) n feature vectors representing its ncandidate antecedents, c1, c2, .
.
., cn.
As will beexplained in detail in Section 3.2.2, the features ineach feature vector can be divided into two types:word embedding features and hand-crafted fea-tures.
Each input feature vector will then be passedthrough three hidden layers in the network, whichwill successively map it into a low-dimensionalfeature space.
The resulting vector can be viewedas the low-dimensional semantic embedding of thecorresponding input vector.
Finally, the modelcomputes a matching score between z and eachof its candidate antecedents based on their low-dimensional representations.
These scores are thennormalized into probabilities using a softmax.More formally, let xe(z) and xh(z) be the vec-780tors of embedding and hand-crafted features rep-resenting AZP z respectively, and let xe(ci) andxh(ci) be the vectors of embedding and hand-crafted features representing candidate antecedentcirespectively.
In addition, let y(z) and y(ci) bethe (low-dimensional) output vectors for z and cirespectively, l1, l2, and l3be the intermediate hid-den layers, Wiand W ?ibe the weight matrices as-sociated with z and the ci's in hidden layer i, biandb?ibe the bias terms associated with z and the ci's.2We then have:l1(z) = f(W1xe(z) + b1)l2(z) = l1(z)?
xh(z)l3(z) = f(W2l2(z) + b2)y(z) = f(W3l3(z) + b3)(1)l1(ci) = f(W?1xe(ci) + b?1)l2(ci) = l1(ci)?
xh(ci)l3(ci) = f(W?2l2(ci) + b?2)y(ci) = f(W?3l3(z) + b?3)(2)where f is the activation function at output layery and hidden layers l1and l3.
In this network, weemploy tanh as the activation function.
Hence,f(x) = tanh(x) = 1?
e?2x1 + e?2x(3)The matching score between an AZP z and acandidate antecedent ciis then measured as:R(z, ci) = cos(y(z), y(ci)) =y(z)Ty(ci)||y(z)||||y(ci)||(4)3.2 Training3.2.1 Training Instance CreationWe create one training instance from each AZPin each training document.
Since our model isranking-based, each training instance correspondsto an AZP z and all of its candidate antecedentsCi.
In principle, we can follow previous workand assume that the set of candidate antecedentsC contains all and only those maximal or modifiernoun phrases (NPs) that precede z in the associ-ated text and are at most two sentences away fromit.
However, to improve training efficiency, weselect exactly four candidate antecedents for each2Note that the target AZP and its candidate antecedents usedifferent weight matrices and biases within each layer.
Thisis needed because the features of the AZP and those of thecandidate antecedents come from two different feature spaces.AZP z as follows.
First, we take the closest correctantecedent z to be one of the four candidate an-tecedents.
Next, we compute a salience score foreach of its non-coreferent candidate antecedentsand select the three with the highest salience scoresas the remaining three candidate antecedents.We compute salience as follows.
For each AZPz, we compute the salience score for each (partial)entity preceding z.3 To reduce the size of the list ofpreceding entities, we only consider a partial entityactive if at least one of its mentions appears withintwo sentences of the active AZP z.
We computethe salience score of each active entity w.r.t.
z us-ing the following equation:?m?Eg(m) ?
decay(m) (5)wherem is a mention belonging to active entityE,g(m) is a grammatical score which is set to 4, 2,or 1 depending on whetherm's grammatical role isSubject, Object, or Other respectively, anddecay(m) is a decay factor that is set to 0.5dis(where dis is the sentence distance betweenm andz).Finally, we assign the correct label (i.e., thematching score) to each candidate antecedent.
Thescore is 1 for the correct antecedent and 0 other-wise.3.2.2 FeaturesAs we can see from Figure 1, each input featurevector, regardless of whether it is representing anAZP or one of its candidate antecedents, is com-posed of two types of features, embedding featuresand hand-crafted features, as described below.Embedding features.
To encode the lexical con-texts of the AZP and its candidate antecedents, onecould employ one-hot vectors.
However, the re-sulting lexical features may suffer from sparsity.To see the reason, assuming that the vocabularysize is V and the number of neurons in the firsthidden layer l1is L1, the size of the weight ma-trices W1and W ?1is V ?
L1, which in our datasetis around two million while the number of trainingexamples is much smaller.Therefore, instead of using one-hot vectors, weemploy embedding features.
Specifically, we em-ploy the pre-trainedword embeddings (of size 100)3We compute the list of preceding entities automaticallyusing SinoCoreferencer (Chen and Ng, 2014c), a Chinese en-tity coreference resolver downloadable from http://www.hlt.utdallas.edu/~yzcchen/coreference/.781Syntacticfeatures(13)whether z is the first gap in an IP clause; whether z is the first gap in a subject-less IP clause, and if so,POS(w1); whether POS(w1) is NT; whether w1is a verb that appears in a NP or VP; whether Plis a NPnode; whether Pris a VP node; the phrasal label of the parent of the node containing POS(w1); whether Vhas a NP, VP or CP ancestor; whether C is a VP node; whether there is a VP node whose parent is an IPnode in the path from w1to C.Otherfeatures (6)whether z is the first gap in a sentence; whether z is in the headline of the text; the type of the clause inwhich z appears; the grammatical role of z (Subject, Object, or Other); whetherw?1is a punctuation;whether w?1is a comma.Table 1: Hand-crafted features associated with an AZP.
z is a zero pronoun.
V is the VP node following z. wiisthe ith word to the right of z (if i is positive) or the ith word to the left of z (if i is negative).
C is lowest common ancestor ofw?1and w1.
Pland Prare the child nodes of C that are the ancestors of w?1and w1respectively.Syntacticfeatures(12)whether c has an ancestor NP, and if so, whether this NP is a descendent of c's lowest ancestor IP; whetherc has an ancestor VP, and if so, whether this VP is a descendent of c's lowest ancestor IP; whether c has anancestor CP; the grammatical role of c (Subject, Object, or Other); the clause type in which c appears;whether c is an adverbial NP, a temporal NP, a pronoun or a named entity.Distancefeatures (4)the sentence distance between c and z; the segment distance between c and z, where segments are separatedby punctuations; whether c is the closest NP to z; whether c and z are siblings in the associated parse tree.Otherfeatures (2)whether c is in the headline of the text; whether c is a subject whose governing verb is lexically identical tothe verb governing of z.Table 2: Hand-crafted features associated with a candidate antecedent.
z is a zero pronoun.
c is a candidateantecedent of z. V is the VP node following z in the parse tree.obtained by training word2vec4 on the Chineseportion of the training data from the OntoNotes 5.0corpus.
For an AZP z, we first find the word pre-ceding it and its governing verb, and then concate-nate the embeddings of these two words to formthe AZP's embedding features.
(If z happens tobegin a sentence, we use a special embedding torepresent the word preceding it.)
For a candidateantecedent, we employ the word embedding of itshead word as its embedding features.Hand-crafted features.
The hand-crafted fea-tures are (low-dimensional) features that capturethe syntactic, positional and other relationshipsbetween an AZP and its candidate antecedents.These features are similar to the ones employedin previous work on AZP resolution (e.g., Zhaoand Ng (2007), Kong and Zhou (2010), Chen andNg (2013)).We split these hand-crafted features into twodisjoint sets: those associated with an AZP andthose associated with a candidate antecedent.
Ifa feature is computed based on the AZP, then weregard it as a feature associated with the AZP; oth-erwise, we put it in the other feature set.
A briefdescription of the hand-crafted features associatedwith an AZP and those associated with a candidateantecedent are shown in Table 1 and Table 2 re-spectively.
Note that we convert eachmulti-valuedfeature into a corresponding set of binary-valuedfeatures (i.e., if a feature has N different values,4https://code.google.com/p/word2vec/we will create N binary indicators to representit).
To ensure that the number of hand-crafted fea-tures representing anAZP is equal to the number ofhand-crafted features representing a candidate an-tecedent5, we append to the end of a feature vectoras many dummy zeroes as needed.63.2.3 Parameter EstimationWe employ online learning to train the network,with one training example in a mini-batch.
In otherwords, we update theweights after processing eachtraining example based on the correct matchingscores of the training example (which is 1 for thecorrect antecedent and 0 otherwise) and the net-work's predicted matching scores.To compute the predicted matching score be-tween AZP z and one of its candidate antecedentsci, we apply the following softmax function:P (ci|z,?)
=exp(?R(z, ci))?c?
?Cexp(?R(z, c?
))(6)where (1) ?
is a smoothing factor that is empiri-cally set on a held-out data set, (2) R(z, ci) is thecosine similarity between vector y(z) and vectory(ci) (see Section 3.1), (3) C denotes the set of can-didate antecedents of z, and (4) ?
denotes the setof parameters of our neural network:5As seen in Figure 1, we set the length of the vector to 50.6Appending dummy 0s is solely for the convenience of thenetwork implementation: doing so does not have any effecton any computation.782?
= {W1,W2,W3, b1, b2, b3,W?1,W?2,W?3, b?1, b?2, b?3}(7)To maximize the matching score of the correctantecedent, we estimate the model parameters tominimize the following loss function:Jz(?)
= ??ci?C?
(z, ci)P (ci|z,?)
(8)where ?
(z, ci) is an indicator function indicatingwhether AZP z and candidate antecedent ciarecoreferent:?
(z, ci) ={1, if z and ciare coreferent0, otherwise (9)Since Jz(?)
is differentiable w.r.t.
to ?, wetrain the model using stochastic gradient descent.Specifically, the model parameters ?
are updatedaccording to the following update rule:?t= ?t?1?
?
?J (?t?1)?
?t?1(10)where ?
is the learning rate, and ?tand ?t?1are model parameters at the tth iteration and the(t ?
1)th iteration respectively.
To avoid overfit-ting, we determine the hyperparameters of the net-work using a held-out development set.3.3 InferenceAfter training, we can apply the resulting networkto find an antecedent for each AZP.
Each test in-stance corresponds to an AZP z and four of its can-didate antecedents.
Specifically, the four candi-date antecedents with the highest salience scoreswill be chosen.
Importantly, unlike in training,where we guarantee that the correct antecedents isamong the set of candidate antecedents, in testing,we don't.
We use the network to rank the candidateantecedents by computing the posterior probabilityof each of them being a correct antecedent of z, andselect the one with the highest probability to be itsantecedent.The aforementioned resolution procedure can beimproved, however.
The improvement is moti-vated by a problem we observed previously (Chenand Ng, 2013): an AZP and its closest antecedentcan sometimes be far away from each other, thusmaking it difficult to correctly resolve the AZP.
Toaddress this problem, we employ the following res-olution procedure in our experiments.
Given a testdocument, we process its AZPs in a left-to-rightTraining TestDocuments 1,391 172Sentences 36,487 6,083Words 756,063 110,034AZPs 12,111 1,713Table 3: Statistics on the training and test sets.manner.
As soon as we resolve an AZP to a pre-ceding NP c, we fill the corresponding AZP's gapwith c. Hence, when we process an AZP z, allof its preceding AZPs in the associated text havebeen resolved, with their gaps filled by the NPsthey are resolved to.
To resolve z, we create testinstances between z and its four most salient can-didate antecedents in the same way as describedbefore.
The only difference is that the set of candi-date antecedents of z may now include those NPsthat are used to fill the gaps of the AZPs resolvedso far.
Some of these additional candidate an-tecedents are closer to z than the original candidateantecedents, thereby facilitating the resolution ofz.
If the model resolves z to the additional can-didate antecedent that fills the gap left behind by,say, AZP z?, we postprocess the output by resolv-ing z to the NP that z?
is resolved to.74 Evaluation4.1 Experimental SetupDatasets.
We employ the Chinese portion of theOntoNotes 5.0 corpus that was used in the officialCoNLL-2012 shared task (Pradhan et al, 2012).In the CoNLL-2012 data, the training set and thedevelopment set contain ZP coreference annota-tions, but the test set does not.
Therefore, we trainour models on the training set and perform eval-uation on the development set.
Statistics on thedatasets are shown in Table 3.
The documentsin these datasets come from six sources, namelyBroadcast News (BN), Newswire (NW), Broad-cast Conversation (BC), Telephone Conversation(TC), Web Blog (WB) and Magazine (MZ).Evaluation measures.
Following previouswork on AZP resolution (e.g., Zhao and Ng(2007), Chen and Ng (2013)), we express theresults of AZP resolution in terms of recall (R),precision (P) and F-score (F).
We report thescores for each source in addition to the overallscore.7This postprocessing step is needed because the additionalcandidate antecedents are only gap fillers.783Number of embedding features for a word 100Number of hand-crafted features 50Number of neurons in l1100Number of neurons in l375Number of neurons in y 50Number of epochs over the training data 100Smoothing factor ?
20Learning rate ?
0.01Table 4: Hyperparameter values.Hyperparameter tuning.
We reserve 20% ofthe training set for tuning hyperparameters.
Thetuned hyperparameter values are shown in Table 4.Evaluation settings.
Following Chen and Ng(2013), we evaluate our model in three settings.In Setting 1, we assume the availability of goldsyntactic parse trees and gold AZPs.
In Setting 2,we employ gold syntactic parse trees and system(i.e., automatically identified) AZPs.
Finally, inSetting 3, we employ system syntactic parse treesand system AZPs.
The gold and system syntacticparse trees, as well as the gold AZPs, are obtainedfrom the CoNLL-2012 shared task dataset, whilethe systemAZPs are identified by a learning-basedAZP identifier described in the Appendix.Baseline system.
As our baseline, we employChen and Ng's (2015) system, which has achievedthe best result on our test set.4.2 Results and DiscussionResults of the baseline system and our model onentire test set are shown in row 1 of Table 5.
Thethree major columns in the table show the resultsobtained in the three settings.
As we can see, ourmodel outperforms the baseline significantly by2.0%, 1.8%, and 1.1% in F-score under Settings 1,2, and 3, respectively.8Rows 2?7 of Table 5 show the resolution re-sults on each of the six sources.
As we can see, inSetting 1, our model beats the baseline on all sixsources in F-score: by 2.4% (NW), 2.5% (MZ),4.5% (WB), 1.6% (BN), 1.4% (BC), and 0.4%(TC).
All the improvements are significant exceptfor TC.
These results suggest that our approachworks well across different sources.
In Setting 2,our model outperforms the baseline on all sourcesexcept NW and BC, where the F-scores drop in-significantly by 0.1% for both sources.
Finally,in Setting 3, our model outperforms the baselineon all sources except NW and TC, where F-scores8All significance tests are paired t-tests, with p < 0.05.drop significantly by 0.7% for NW and 1.1% forTC.Given the challenges in applying supervisedlearning (in particular, the difficulty and time in-volved in training the deep neural network as wellas the time and effort involved in manually anno-tating the data needed to train the network), onemay wonder whether the small though statisticallysignificant improvements in these results providesufficient justification for going back to supervisedlearning from the previous state-of-the-art unsu-pervised model.
We believe that this is the begin-ning, not the end, of applying deep neural networksfor AZP resolution.
In particular, there is a lot ofroom for improvements, which may involve incor-porating more sophisticated features and improv-ing the design of the network (e.g., the dimension-ality of the intermediate representations, the num-ber of hidden layers, the objective function), forinstance.4.3 Ablation ResultsRecall that the input of our model is composed oftwo groups of features, embedding features andhand-crafted features.
To investigate the contribu-tion of each of these two feature groups, we con-duct ablation experiments.
Specifically, in eachablation experiment, we retrain the network usingonly one group of features.Ablation results under the three settings areshown in Table 6.
In Setting 1, when the hand-crafted features are ablated, F-score drops signifi-cantly by 12.2%.
We attribute the drop to the factthat the syntactic, positional, and other relation-ships encoded in the hand-crafted features play animportant role in resolving AZPs.
When the em-bedding features are ablated, F-score drops signif-icantly by 3.7%.
This result suggest the effective-ness of the embedding features.Similar trends can be observed w.r.t.
the othertwo settings: in Setting 2, F-score drops signifi-cantly by 6.8% and 2.2% when the hand-craftedfeatures and the embedding features are ablated re-spectively, while in Setting 3, F-score drops signif-icantly by 4.6% and 1.1% when the hand-craftedfeatures and the embedding features are ablated.4.4 Learning CurveWe show in Figure 2 the learning curve of the ourmodel obtained under Setting 1.
As we can see,after the first epoch, the F-score on the entire testset is around 46%, and it gradually increases to784Setting 1: Setting 2: Setting 3:Gold Parses, Gold AZPs Gold Parses, System AZPs System Parses, System AZPsBaseline Our Model Baseline Our Model Baseline Our ModelSource R P F R P F R P F R P F R P F R P FOverall 50.0 50.4 50.2 51.8 52.5 52.2 35.7 26.2 30.3 39.6 27.0 32.1 19.6 15.5 17.3 21.9 15.8 18.4NW 46.4 46.4 46.4 48.8 48.8 48.8 32.1 28.1 30.0 34.5 26.4 29.9 11.9 14.3 13.0 11.9 12.8 12.3MZ 38.9 39.1 39.0 41.4 41.6 41.5 29.6 19.6 23.6 34.0 22.4 27.0 4.9 4.7 4.8 9.3 7.3 8.2WB 51.8 51.8 51.8 56.3 56.3 56.3 39.1 22.9 28.9 44.7 25.1 32.2 20.1 14.3 16.7 23.9 16.1 19.2BN 53.8 53.8 53.8 55.4 55.4 55.4 30.8 30.7 30.7 36.9 31.9 34.2 18.2 22.3 20.0 22.1 23.2 22.6BC 49.2 49.6 49.4 50.4 51.3 50.8 35.9 26.6 30.6 37.6 25.6 30.5 19.4 14.6 16.7 21.2 14.6 17.3TC 51.9 53.5 52.7 51.9 54.2 53.1 43.5 28.7 34.6 46.3 29.0 35.6 31.8 17.0 22.2 31.4 15.9 21.1Table 5: AZP resolution results of the baseline and our model on the test set.Setting 1: Setting 2: Setting 3:Gold Parses Gold Parses System ParsesGold AZPs System AZPs System AZPsSystem R P F R P F R P FFull system 51.8 52.5 52.2 39.6 27.0 32.1 21.9 15.8 18.4Embedding features only 39.2 40.8 40.0 30.9 21.5 25.3 16.3 12.0 13.8Hand-crafted features only 48.2 48.7 48.5 37.0 25.1 29.9 20.6 14.9 17.3Table 6: Ablation results of AZP resolution on the whole test set.Figure 2: The learning curve of our model on theentire test set under Setting 1.52% in the 80th epoch when performance startsto plateau.
These results provide suggestive evi-dence for our earlier hypothesis that our objectivefunction (Equation (8)) is tightly coupled with thedesired evaluation metric (F-score).4.5 Analysis of ResultsTo gain additional insights into our approach, weexamine the outputs of our model obtained underSetting 1.We first analyze the cases where the AZP wascorrectly resolved by our model but incorrectly re-solved by the baseline.
Consider the followingrepresentative examplewith the corresponding En-glish translation.[???]
??????????????[??]????????...
?pro????????????????
[Chen Shui-bian] delivered a short speech beforeboarding, saying that [Taiwan] should stand upand go out.
... ?pro?
also hopes that this trip canbring back international friendship.In this example, the correct antecedent of theAZP is ???
(Chen Shui-bian).
However, thebaseline incorrectly resolves it to ??
(Taiwan).The baseline's mistake can be attributed to the factsthat (1) ??
is the most salient candidate an-tecedent in the discourse, and (2)??
is closer tothe AZP than the correct antecedent???.
Nev-ertheless, our model still correctly identifies???
as the AZP's antecedent because of the embed-ding features.
A closer inspection of the trainingdata reveals that although the word???
neverappeared as the antecedent of an AZP whose gov-erning verb is ??
(hope) in the training data,many AZPs that are governed by??
are corefer-ent with other person names.
Because the word???
has a similar word embedding as those per-son names, our approach successfully generalizessuch lexical context and makes the right resolutiondecision.Next, we examine the errors made by our modeland find that the majority of the mistakes resultfrom insufficient lexical contexts.
Currently, toencode the lexical contexts, we only consider theword preceding the AZP and its governing verb, aswell as the head word of the candidate antecedent.However, this encoding ignored a lot of potentiallyuseful context information, such as the clause fol-lowing the AZP, the modifier of the candidate an-tecedent and the clause containing the candidateantecedent.
Consider the following example:785[?]
??????????...?pro?
????????
[I] was too nervous a while ago.
... ?pro?
am nowcalmer.To resolve the AZP to its correct antecedent?
(I), one needs to compare the two clauses contain-ing the AZP and ?.
However, since our modeldoes not encode a candidate antecedent's context,it does not resolve the AZP correctly.
One way toaddress this problem would be to employ sentenceembeddings to represent the clauses containing theAZP and its candidate antecedents, and then per-form sentence embedding matching to resolve theAZP.
The primary challenge concerns how to trainthe model to match two clauses with probably nooverlapping words and with a limited number oftraining examples.5 ConclusionsWe proposed an embedding matching approach tozero pronoun resolution based on deep networks.To our knowledge, this is the first neural network-based approach to zero pronoun resolution.
Whenevaluated on the Chinese portion of the OntoNotescorpus, our approach achieved state-of-the-art re-sults.AcknowledgmentsWe thank the three anonymous reviewers for theirdetailed comments.
This work was supported inpart by NSFGrants IIS-1219142 and IIS-1528037.Any opinions, findings, conclusions or recommen-dations expressed in this paper are those of the au-thors and do not necessarily reflect the views or of-ficial policies, either expressed or implied, of NSF.ReferencesKai-Wei Chang, Rajhans Samdani, and Dan Roth.2013.
A constrained latent variable model for coref-erence resolution.
In Proceedings of the 2013 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 601--612.Chen Chen and Vincent Ng.
2013.
Chinese zero pro-noun resolution: Some recent advances.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing, pages 1360--1365.Chen Chen and Vincent Ng.
2014a.
Chinese zero pro-noun resolution: An unsupervised approach combin-ing ranking and integer linear programming.
In Pro-ceedings of the 28th AAAI Conference on ArtificialIntelligence, pages 1622--1628.Chen Chen and Vincent Ng.
2014b.
Chinese zeropronoun resolution: An unsupervised probabilisticmodel rivaling supervised resolvers.
In Proceed-ings of the 2014 Conference on Empirical Methodsin Natural Language Processing, pages 763--774.Chen Chen and Vincent Ng.
2014c.
SinoCoreferencer:An end-to-end Chinese event coreference resolver.In Proceedings of the Ninth International Confer-ence on Language Resources and Evaluation, pages4532--4538.Chen Chen and Vincent Ng.
2015.
Chinese zeropronoun resolution: A joint unsupervised discourse-aware model rivaling state-of-the-art resolvers.
InProceedings of the 53rd Annual Meeting of the Asso-ciation for Computational Linguistics and the 7th In-ternational Joint Conference on Natural LanguageProcessing (Volume 2: Short Papers), pages 320--326.Kevin Clark and Christopher D. Manning.
2015.Entity-centric coreference resolution with modelstacking.
In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguisticsand the 7th International Joint Conference on Natu-ral Language Processing (Volume 1: Long Papers),pages 1405--1415.Susan Converse.
2006.
Pronominal Anaphora Resolu-tion in Chinese.
Ph.D. thesis, University of Pennsyl-vania.Pascal Denis and Jason Baldridge.
2008.
Special-ized models and ranking for coreference resolution.In Proceedings of the 2008 Conference on Empiri-cal Methods in Natural Language Processing, pages660--669.Greg Durrett and Dan Klein.
2013.
Easy victories anduphill battles in coreference resolution.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing, pages 1971--1982.Antonio Ferr?ndez and Jes?s Peral.
2000.
A compu-tational approach to zero-pronouns in Spanish.
InProceedings of the 38th Annual Meeting on Associa-tion for Computational Linguistics, pages 166--172.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1995.
Centering: A framework for model-ing the local coherence of discourse.
ComputationalLinguistics, 21(2):203--226.Na-Rae Han.
2006.
Korean zero pronouns: Analysisand resolution.
Ph.D. thesis, University of Pennsyl-vania.Masatsugu Hangyo, Daisuke Kawahara, and SadaoKurohashi.
2013.
Japanese zero reference resolu-tion considering exophora and author/reader men-tions.
In Proceedings of the 2013 Conference onEmpirical Methods in Natural Language Process-ing, pages 924--934.786Yuta Hayashibe, Mamoru Komachi, and Yuji Mat-sumoto.
2011.
Japanese predicate argument struc-ture analysis exploiting argument position and type.In Proceedings of 5th International Joint Conferenceon Natural Language Processing, pages 201--209.Jerry Hobbs.
1978.
Resolving pronoun references.Lingua, 44:311--338.Ryu Iida and Massimo Poesio.
2011.
A cross-lingualILP solution to zero anaphora resolution.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies - Volume 1, pages 804--813.Ryu Iida, Kentaro Inui, andYujiMatsumoto.
2006.
Ex-ploting syntactic patterns as clues in zero-anaphoraresolution.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for Computa-tional Linguistics, pages 625--632.Ryu Iida, Kentaro Inui, and Yuji Matsumoto.
2007.Zero-anaphora resolution by learning rich syntacticpattern features.
ACM Transactions on Asian Lan-guage Information Processing, 6(4).Ryu Iida, Kentaro Torisawa, Chikara Hashimoto, Jong-Hoon Oh, and Julien Kloetzer.
2015.
Intra-sentential zero anaphora resolution using subjectsharing recognition.
In Proceedings of the 2015Conference on Empirical Methods in Natural Lan-guage Processing, pages 2179--2189.Kenji Imamura, Kuniko Saito, and Tomoko Izumi.2009.
Discriminative approach to predicate-argument structure analysis with zero-anaphora res-olution.
In Proceedings of the ACL-IJCNLP 2009Conference Short Papers, pages 85--88.Hideki Isozaki and Tsutomu Hirao.
2003.
Japanesezero pronoun resolution based on ranking rules andmachine learning.
In Proceedings of the 2003 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 184--191.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In Bernhard Scholkopf andAlexander Smola, editors, Advances in Kernel Meth-ods - Support Vector Learning, pages 44--56.
MITPress.Fang Kong and GuoDong Zhou.
2010.
A tree kernel-based unified framework for Chinese zero anaphoraresolution.
In Proceedings of the 2010 Conferenceon EmpiricalMethods in Natural Language Process-ing, pages 882--891.Sebastian Martschat and Michael Strube.
2015.
Latentstructures for coreference resolution.
In Transac-tions of the Association for Computational Linguis-tics, 3:405--418.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 shared task: Modeling multilingual unre-stricted coreference in OntoNotes.
In Proceedings of2012 Joint Conference on EmpiricalMethods in Nat-ural Language Processing and Computational Nat-ural Language Learning: Shared Task, pages 1--40.Sudha Rao, Allyson Ettinger, Hal Daum?
III, and PhilipResnik.
2015.
Dialogue focus tracking for zero pro-noun resolution.
In Proceedings of the 2015 Con-ference of the North American Chapter of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies, pages 494--503.Ruslan Salakhutdinov and Geoffrey Hinton.
2007.
Se-mantic hashing.
In Proceedings of the SIGIR Work-shop on Information Retrieval and Applications ofGraphical Models.Ryohei Sasano and Sadao Kurohashi.
2011.
A dis-criminative approach to Japanese zero anaphora res-olution with large-scale lexicalized case frames.
InProceedings of the 5th International Joint Confer-ence on Natural Language Processing, pages 758--766.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2008.
A fully-lexicalized probabilistic modelfor Japanese zero anaphora resolution.
In Proceed-ings of the 22nd International Conference on Com-putational Linguistics, pages 769--776.Ryohei Sasano, Daisuke Kawahara, and Sadao Kuro-hashi.
2009.
The effect of corpus size on case frameacquisition for discourse analysis.
In Proceedings ofHuman Language Technologies: The 2009 AnnualConference of the North American Chapter of the As-sociation for Computational Linguistics, pages 521--529.Kazuhiro Seki, Atsushi Fujii, and Tetsuya Ishikawa.2002.
A probabilistic method for analyzing Japaneseanaphora integrating zero pronoun detection and res-olution.
In Proceedings of the 19th InternationalConference on Computational Linguistics - Volume1.Hirotoshi Taira, Sanae Fujita, and Masaaki Nagata.2008.
A Japanese predicate argument structure anal-ysis using decision lists.
In Proceedings of the 2008Conference on Empirical Methods in Natural Lan-guage Processing, pages 523--532.Yotaro Watanabe, Masayuki Asahara, and Yuji Mat-sumoto.
2010.
A structured model for joint learn-ing of argument roles and predicate senses.
In Pro-ceedings of the ACL 2010 Conference Short Papers,pages 98--102.SamWiseman, Alexander M. Rush, Stuart Shieber, andJason Weston.
2015.
Learning anaphoricity and an-tecedent ranking features for coreference resolution.In Proceedings of the 53rd Annual Meeting of theAssociation for Computational Linguistics and the7th International Joint Conference on Natural Lan-guage Processing (Volume 1: Long Papers), pages1416--1426.787Yaqin Yang and Nianwen Xue.
2010.
Chasing theghost: recovering empty categories in the ChineseTreebank.
In Proceedings of the 23rd InternationalConference on Computational Linguistics: Posters,pages 1382--1390.Ching-Long Yeh and Yi-Chun Chen.
2007.
Zeroanaphora resolution in Chinese with shallow pars-ing.
Journal of Chinese Language and Computing,17(1):41--56.Katsumasa Yoshikawa, Masayuki Asahara, and YujiMatsumoto.
2011.
Jointly extracting Japanesepredicate-argument relation with Markov Logic.
InProceedings of 5th International Joint Conferenceon Natural Language Processing, pages 1125--1133.Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawa-hara.
2013.
Predicate argument structure analysisusing partially annotated corpora.
In Proceedings ofthe Sixth International Joint Conference on NaturalLanguage Processing, pages 957--961.Shanheng Zhao and Hwee Tou Ng.
2007.
Identifica-tion and resolution of Chinese zero pronouns: A ma-chine learning approach.
In Proceedings of the 2007Joint Conference on Empirical Methods on Natu-ral Language Processing and Computational Natu-ral Language Learning, pages 541--550.GuoDong Zhou, Fang Kong, and Qiaoming Zhu.
2008.Context-sensitive convolution tree kernel for pro-noun resolution.
In Proceedings of the 3rd Interna-tional Joint Conference on Natural Language Pro-cessing, pages 25--31.Appendix: Anaphoric Zero PronounIdentificationRecall that Settings 2 and 3 in our evaluation in-volve the use of system AZPs.
Our supervisedAZP identification procedure is composed of twosteps.
First, in the extraction step, we heuristicallyextract ZPs.
Then, in the classification step, wetrain a classifier to determine which of the ZPs ex-tracted in the first step are AZPs.To implement the extraction step, we use Zhaoand Ng's (2007) observation: ZPs can only occurbefore a VP node in a syntactic parse tree.
How-ever, according to Kong and Zhou (2010), ZPs donot need to be extracted from every VP: if a VPnode occurs in a coordinate structure or is modi-fied by an adverbial node, then only its parent VPnode needs to be considered.
We extract ZPs fromall VPs that satisfy the above constraints.To implement the classification step, we train abinary classifier using SVMlight (Joachims, 1999)on the CoNLL-2012 training set to distinguishAZPs from non-AZPs.
Each instance correspondsto a ZP extracted in the first step and is representedSyntacticfeatures(13)whether z is the first gap in an IP clause;whether z is the first gap in a subject-lessIP clause, and if so, POS(w1); whetherPOS(w1) is NT; whether t1is a verb thatappears in a NP or VP; whether Plis a NP,QP, IP or ICP node; whether Pris a VPnode; the phrasal label of the parent of thenode containing POS(t1); whether V has aNP, VP, QP or CP ancestor; whether C isa VP node; whether the parent of V is an IPnode; whether V's lowest IP ancestor has (1)a VP node as its parent and (2) a VV nodeas its left sibling; whether there is a VP nodewhose parent is an IP node in the path fromt1to C.Lexicalfeatures(13)the words surrounding z and/or theirPOS tags, including w1, w?1, POS(w1),POS(w?1) + POS(w1), POS(w1) +POS(w2), POS(w?2) + POS(w?1),POS(w1) + POS(w2) + POS(w3),POS(w?1) + w1, and w?1+ POS(w1);whether w1is a transitive verb, an intransi-tive verb or a preposition; whether w?1isa transitive verb without an object.Otherfeatures(6)whether z is the first gap in a sentence;whether z is in the headline of the text; thetype of the clause in which z appears; thegrammatical role of z; whether w?1is apunctuation; whether w?1is a comma.Table 7: Features for AZP identification.
z is a zeropronoun.
V is the VP node following z. wiis the ith word tothe right of z (if i is positive) or the ith word to the left of z(if i is negative).
C is lowest common ancestor of w?1andw1.
Pland Prare the child nodes of C that are the ancestorsof w?1and w1respectively.by 32 features, 13 of which were proposed by Zhaoand Ng (2007) and 19 of which were proposed byYang and Xue (2010).
A brief description of thesefeatures can be found in Table 7.When gold parse trees are employed, the recall,precision and F-score of the AZP identifier on ourtest set are 75.1%, 50.1% and 60.1% respectively.Using automatic parse trees, the performance ofthe AZP identifier drops to 43.7% (R), 30.7% (P)and 36.1% (F).788
