EXPERIMENTS US ING STOCHASTIC  SEARCH FOR TEXT PLANNINGChris Mellish, Alistair Knott, Jon Oberlander and Mick O'DonnellDepartment of Artificial Intelligence and Human Communication Research Centre,University of Edinburgh 1Abstract?
Marcu has characterised an important and difficult problem in text planning: given a set of factsto convey and a set of rhetorical relations that can be used to link them together, how can onearrange this material so as to yield the best possible text?
We describe xperiments with a numberof heuristic Search methods for this task.
'1 ?
In t roduct ion :  Text  P lann ing1.1 The  TaskThis paper presents ome initial experiments using stochastic search methods for aspects of textplanning.
The work was motivated by the needs of the ILEX system for generating descriptions ofmuseum artefacts (in particular, 20th Century jewellery) \[Mellish et al98\].
We present results onexamPles emi-automatically generated from datastructures that exist within ILEX.Forming a set of facts about a piece of jewellery into a structure that yields a coherent ext isa non-trivial problem.
Rhetorical Structure Theory\ [Mann and Thompson 87\] claims that a texti s  coherent just in case it can be analysed hierarchically in terms of relations between text spans.Much work in NLG makes the assumption that constructing something like an RS tree is a necessarystep in the planning of a text.
This work takes as its starting point Marcu's \[Marcu 97\] excellent?
formalisation of RST  and the problem of building legal RST trees, and for the purposes of thispaper the phrase "text planning" will generally denote the task characterised by him.
In this task,one is given a set of facts all of which should be included in a text and a set of relations betweenfacts, some of which canbe  included in the text.
The task is to produce a legal RS tree using thefacts and some relations (or the "best" such tree).Following the original work on RST and  assumptions that have been commonly made in sub-sequent work, we wil !
assume that there is a fixed set of possible relations (we include "joint" as asecond-class relation which can be applied to any two facts, but whose use is not preferred).
Eachrelation has a nucleus and a satellite (we don't consider multiple nuclei or satellites here, apartfrom the case of "joint", which is essentially multinuclear).
Each relation may be indicated by adistinctive "cue phrase", with the nucleus and satellite being realised in some fashion around it.Each relation has applicability conditions which can be tested between two atomic facts.
For twocomplex text spans, a relation holds exactly when that relation holds between the nuclei of thosespans.
Relations can thus hold between text spans Of arbitrary size.Figure 1 shows an example of the form of the input that is used for the experiments ?reportedhere.
Each primitive "fact" is represented in terms of a subject, verb and complement (as wellas a unique identifier).
The "subject" is assumed to be the entity that the fact is "about".
Theapproaches reported here have not yet been linked to a realisation component, and so the entit iesa 80 South Bridge, Edinburgh EH1 1HN.
Email: {chrism, micko}~dai, ed.
ac.
uk, {al ik ,  j on}ecogsc?, ed.
ac.
uk?
98IIIIII?
( !|:!I' " IIIifact(fact(fact(fact(fact('this item','is','a figurative jewel',f6).bleufort,'was','a french designer',f3).shiltredge,'was','a british designer',fT).
'this item','was made by',bleufort,f8).titanittm,'is','a refractory metal',f4).rel (contrast, f7, f3, \[\] ).rel(elab,Fi,F2, \[\]) :-mentions (FI, O),mentions (F2, O) ,\+ FI=F2.Figure 1: Example Inputare represented Simply by canned phrases for readability (it is assumed that each entity in thedomain has a fixed distinctive phrase that is always used for it).
Relations are represented interms Of the relation name, the nucleus and satellite facts and a list (in this example, empty)of precondition facts which need to have been assimilated before the :relation can be used (thisrepresents an extension to Marcu's chcracterisation).
This example uses the definition of (object-attribute) "elaboration" that we will be using consistently, namely that one fact can elaborateanother if they have an entity in common (of course, there are other kinds of elaborations, but wewould want to model them differently).1.2 Cont ro l l ing  Search  in Text  P lann ingThere seem to be three main approaches to controlling the search for a good RS tree (or somethingsimilar).
One is to restrict what relations can appear in the nucleus and satellite of others (forinstance, using Hovy's \[Hovy 90\] idea of "growth points"): This is astep towards creating "schemas"for larger pieces of text .
It can therefore be expected that it will produce very good results inrestricted omains where limited text patterns are used, but that it will be hard to extend it tofreer text types.
The second idea is to use information about goals to limit possibilities.
Thisis an element of Hovy's work but is more apparent in the planning work of Moore and Paris\[Moore and Paris 93\].
This second approach will work well if there are strong goals in the domainwhich really can influence textual decisions.
This is not always the case.
For instance, in our ILEXdomain \[Mellish et al98\] the system's goal is something very general ike "say interesting thingsabout item X/subject to length and coherence constraints".The third approach, most obviously exemplified by \[Marcu 97\], is to Use some form of  explicitsearch through possible trees, guided by heuristics about tree quality.
Marcu first of all attemptsto find the best ordering of the facts.
For every relation that could be indicated, constraints aregenerated saying what the order of the two facts involved should be and that the facts should beadjacent.
The constraints are weighted according to attributes of rhetorical relations that havebeen determined empirically.
A standard constraint satisfaction algorithm is used to find the linearsequence such that the total weight of the satisfied constraints i maximal.
Once the sequence offacts is known, a general algorithm \[Marcu 96\] is used to construct all possible RS trees based onthose facts.
It is not clear how the best such tree is selected, though clearly theadjacency andorder constraints-could in principle be reapplied in some way (possibly with other heuristics thatMarcu has used in rhetorical parsing) to select a tree.We are interested in further developing the ideas of Marcu, but seek to address the followingproblems:1.
It is not clear howscalable the approach is.
Constraint satisfaction in general is intractable,99and having weighted constraints eems to make matters worse.
Enumerating all RS treesthat can be built on a given sequence of facts also has combinatorical problems.
Marcu'sapproach may not be much better than one that builds all possible trees.
Yet if there areenough relations to link any pair of facts (which, given the existence of elaboration, may oftenbe nearly the case), the number of trees whose top nucleus are a specified'fact grows from336 to ?
5040 to 95040 as the number of facts grows from 5 to 6 to 7.
In our examples, we havemore like 20-30 facts.2.
As Marcu points out, the constraints on linear order only indirectly reflect requirements onthe tree (becaus e related facts need not appear consecutively).
Though in fact we will use -the idea of planning via a linear sequence later, we would like to experiment using measuresof  quality that  are applied directly to the trees.
We also have a number of factors that wewould llke to take account of in the evaluation (see section 3 below).2 Stochast i c  SearchBuilding a good RS  tree is a search problem.
Stochastic search methods are a form of heuristicsearch that use the following generic algorithm:i .
Construct a set of random candidate Solutions.2.
Until some time limit is reached,Randomly pick one or more items from the set, in such a way as to prefer items withthe  best "scores".Use these to generate one or more new random variations.Add these to the set, possibly removing less preferred items in order to keep the sizeconstant.Examples Of stochastic search approaches are stochastic hillclimbing, simulated annealing and evol-utionary algorithms.
The approaches differ according to factors like the size of the population ofpossible solutions, that is maintained, the operations for generating new possibilities and any spe-cial mechanisms for avoiding local maxima.
They are similar toone  another (and different fromconstraint satisfaction and enumeration approaches) in that they are heuristic (not guaranteed tofind optimal solutions) and they are "anytime".
That is, such an algorithm can be stopped atany?point and it will be able to yield at that point  a result which is the best it has found so far.This is important for?
NLG applications where interface considerations mean that texts have to beproduced within a limited time.3 Evaluating RST trees?
?A key requirement for the use of any stochastic search approach is the ability to: assess the qualityo f  a possible solution.
Thus we are forced to confront ?directly the task of evaluating RST trees.We assign a candidate tree a score which is the sum of scores for particular features the treemay have.
A positive score here indicates a good feature and a negative one indicates a bad one.We cannot make any claims to have the best way of evaluating RS trees.
The problem is far toocomplex and our  knowledge of the issues involved so meagre that only a token gesture can be madei00 -Ii',IIi.lat this point.
We offer the following evaluation scheme merely so that the basis of our experimentsis clear and because we believe that some of the ideas are starting in the right direction.
Here arethe features that we score for:Topic and Interest ingness  We assume that the entity that the text is "about"is pecified withthe input.
It is highly desirable that the "top nucleus" (most important nucleus) of the text beabout this entity.
Also we prefer texts that use interesting relations.
We score as follows:-10 for a top nucleus not mentioning the subject of the text-30 for a joint relation+21 for a relation other than joint and elaboration?
Size of Subst ructures  - Scott and de Souza \[Scott and de Souza 90\] say that the greater theamount of intervening text between the propositions of a relation, the more difficult it will be toreconstruct its message.
We score as follows:-4 for each fact that will come textually between a satellite and its nucleusConstra ints  on In format ion  Order ing  Our relations have preconditions which are facts thatshould be conveyed before them.
we score as follows:-20 for an unsatisfied precondition for a relationFocus Movement  We do nothave a complex model of focus development through the text,though development of such a model would be worthwhile.
As McKeown and others have done, weprefer certain transitions over others.
If consecutive facts mention the same entities or verb, theprospects for aggregation are greater, and this is usually desirable.
We score as follows:-9 for a fact (apart from the first) not mentioning any previously mentioned entity-3 for a fact not mentioning any entity in the previous fact, but whose subject is apreviously mentioned entity?
+3 for a fact retaining the subject of the last fact as its subject ?+3 for a fact using the same verb as the previous oneObject  In t roduct ion  When an entity is first introduced as the subject of a fact, it is usual forthat to be a very general statement about the entity.
Preferring this introduces a mild schema-likeinfluence to the system.
We score as follows:+3 for the first fact with a given entity as subject having verb "is"4 Using Stochastic Search for Text PlanningUsing the above evaluation metric for RS trees, we have experimented with a range?
of stochasticsearch methods.
Space does not permit us to discuss more than one initial experiment in thissection.
In the next section, we describe a Couple of methods based on genetic algorithms whichproved more productive.I014.1 Subt ree  Swapp ingThe subtree swapping approach produces new trees by swapping random subtrees in a candidatesolution.
It works as follows:1.
Initialise with a tree for each combination of interesting (non-elaboration) relations, with anyfact only appearing in one.
Make into a complete tree by combining together these relationsand any unused facts with "joint" relations (or better ones if available).2.
Repeatedly select a random tree and swap over two random subtrees, repairing all relations.Add the new tree to the population.When two subtrees are swapped over in  an RS tree, some of the relations indicated in the treeno longer apply (i:e. those higher relations that  make use of the nuclei of the subtrees).
Theseare "repaired" by in each case selecting the "best" valid relation that really relates the top nuclei(i.e.
a non-elaboration relation is chosen if possible, otherwise an elaboration if that is valid, with"joint" as a last resort) .We investigated variations on this algorithml including having initial random balanced trees(including the "best" relation at each point) and focussing the subtree swapping On subtrees thatcontributed to bad scores, :but the above algorithm was the one that seemed most successful.4.2 In i t ia l  Results ?
.
.
.
.
: :Figure 2 shows an example tex t generated by subtree swapping.
Note that we have taken libertiesin editing by hand the surface text (for instance, by introducing better referring expressions andaggregation).
For clarity, coreference has been indicated by subscripts.
The ordering of the materialand the use of rhetorical relations "are the only things which are determined by the algorithm.Results for subtree swapping are shown together with later results in Figure 5 (the example textshown for subtree swapping is for the item named j-342540).
The most obvious feature of theseresults is the huge variability of the results , which suggests that there are many local maxima inthe search space.
Looking at the texts produced, we can see a number of problems.
If there is only?
one way smoothly to include a fact in the text, the chance of finding it by random subtree swappingis very low.
The Same goes for fixing other local problems in the text.
The introduction of "theprevious jewel" is an example of this.
This entity can only be introduced elegantly through the factthat it, like the current item, is encrusted with jewels.
The text is also still suffering from materialgetting between a satellite and its nucleus.
For instance, there is a relation (indicated by the colon)between "It is encrusted with jewels" and "it has silver links encrusted asymmetrically...", but thisis weakened by the presence of "and is an Organic style jewel" in the middle).The  trouble is that subtree swapping needs incrementally to acquire all good features notpresent in whichever initial tree develops into the best solution.
It can only acquire these features"acCidentally" and  the chances of stumbling on them are small.
Different initial trees will contain?
different good fragments, and it  seems desirable to be able to combine the good parts of different?
solutions.
This motivates using some sort of Crossover operation that can combine lements of twosolutions into a new one \[Goldberg 89\].
But it is not immediately clear how crossover could workon two RS trees, tn particular, two chosen trees will rarely have non-trivial subtrees with equalfringes.
Their way of breaking up the material may be so different hat it is hard to imagine howone could combine elements of both .
i .- !
!
iI?
: ' iI,III\[l!1IIIiIlThis jewel/ is made from diamonds, yellow metal, pearls, oxidized white metal andopals.It~ was made in 1976 and was made in London.This jewe4 draws on natural themes for inspiration: itl uses natural pearls.I t i  was made by Flockinger who is an English designer.Flockinger lived in London which is a city.This jeweli is a necklace and is set with jewels.Iti is encrusted with jewels and is an Organic style jewel: iti has silver links encrustedasymetrically with pearls and diamonds.Indeed, Organic style jewels are usually encrusted with jewels.Organic style jewels usually draw On natural themes for inspiration and are made up ofasymmetrical shapes.Organic style jewels usually have a coarse texture.?
This jewel/is 72.0 cm long.The previous \]ewelj has little diamonds cattered around its edges and has an encrustedbezel.
Itj is encrusted with jewels: itj features diamonds encrusted on a natural shell.Figure 2: Example Text from Subtree Swapping5 Restr ict ing the Space of RST  TreesAs a way of making a crossover operation conceivable, our first step has been to reduce the planningproblem to that of planning the sequential order of the facts (in a way that echoes Marcu's approachto some extent).
We have done this by making certain restrictions on the RS trees that we areprepared to build.
In particular, we make the following assumptions:?
1.
The nucleus and satellite of a non-joint relation can never be separated.2.
"Joint" relations are used to connect unrelated paragraphs.With these assumptions, an RS tree is characterised (almost) by the sequence of facts at its leaves.Indeed, we have an algorithm that almost deterministically builds a tree from a sequence of facts,according to these principles.
?
(The algorithm is not completely deterministic, ?
because there maybe  more than one non-elaboration relation that can be used with two given facts as nucleus andsatellite - our evaluation function won't, of course, differentiate between these).The algorithm for building a tree from a sequence ssentially makes a tree that can be processedby a reader with minimal short-term memory.
The tree will be right-branching and if the readerjus t  remembers the last fact at any point, then they can follow the connection between the text sofar and the next fact 2 Interestingly, Marcu uses "right skew" to b disambiguate between alternative ~-tree s produced in rhetorical parsing.
Here we are setting it as a much harder constraint.
The only2In fact, there is local left-branching for (non-nested) relations whose satellite is presented first.
Such relationsare often presented using embedded clauses in a way that signals the deviation from right-branching clearly to thereader.103exception is "joint" relations, which can join together texts of any size, but since there is no realrelation involved in them there is no memory load in interpreting them.The first two assumptions above make fundamental use of the order in which facts will appearin the text.
For simplicity, we assume that every relation has a fixed order Of nucleus and satellite(though this assumption could be relaxed).
The  approach i scontroversial in that it takes intoaccount realisati0n order in the criterion for a legal tree.
It is likely that the above assumptionswill not apply equally well to all types of text.
Still, they mean that the planningproblem can :bereduced to  that of planning a sequence.
The next experiments were an attempt o evaluate thisidea.?
6 Us ing  a Genet ic  A lgor i thmThe genetic algorithm we used takes the following form:1.
Enumerate a set of random initial sequences by loosely following sequences of factswhere consecutive facts mention the same entity.2.
Evaluate sequences by evaluating the trees they give rise to.- 3.
Perform mutation and crossover on the sequences, with mutation ?
having a relativelysmall probability.4.
When the "best'/ sequence has not changed for a time, invoke mutation repeatedlyuntil it does.5.
Stop after a given number of iterations, and return the tree for the "best"?
sequence.Notice that although the algorithm manipulates sequences, the evaluation is one that operate s ontrees.
Mutation is a unary operation which, given one sequence, generates a new one.
Crossover isbinary in that it generates new solution(s ) based on two existing ones.
The choice of mutation andcrossover operations depends on how the sequences are internally represented and should facilitatethe  exchange of useful subparts of solutions.
Two different representations have been tried so far.The relevant features are summariSed in Figure 3.6.1 Ord ina l  Representat ionThe ordinal representation \[Michalewicz 92\] assumes that ~ there is an initial canonical sequence offacts (in the figure, this is assumed to be 1,2,3,4).
A given sequence is represented by a sequenceof numbers, where the ith element indicates the position of the ith element of the sequence inthat canonical sequence with all previous elements deleted.
So the ith element is always a numberbetween 1 and n + 1 - i, where n is the length of the sequence.
Mutation is implemented by achange of a random element to a random legal value.
?Crossover (here) is implemented by two-pointcrossover - the material between two random points ?of the sequences (the same points for both) i sswapped over, yielding two new sequences.
The ordina !
representation has been used extensivelyfor tasks such as  the travelling salesman problem , and it has the advantage that the crossoveroperation is particulariy simple.6.2 Path  Representat ionin many ways, this is a more obvious encoding, though the operations are chosen to reflect the.'
intuition that order and adjacency information should generally be maintained from old solution(s).104IiIIII!1it!1!1|?
!,1Ordinal Encoding1.3.2., , I112 II I1 ISecond remaining itemMutation111211111 " li1311111Random position changes to a random legal valueCrossover.
e,,I112 I1 I1 I ?1312?12 I1 I - - ' - I11212 II IExchange material between two random positions131211 IIPath EncodingI;3,2,4Mutation111213 I, Iv ACrossover?
Ill 1312t,1II 13 It 12 ISlide random element to random place121~ 13 I11 " I~ 12 13 I l l1Insert sequence atrandom point, deleting duplicates outsideFigure 3: Ordinal and Path Representationsto the new ones they give rise to.
A sequence of facts is represented simply as that sequence.Mutation selects a random element, removes it from the sequence and then inserts it again ina random place.
Crossover inserts a random subsequence of one solution into another, de let ingduplicates that occur outside the inserted subsequence.6.3 Resu l ts?
Figure 4 shows an example text produced using the path encoding operations (for j-342540, after2000 iterations, just under 2 minutes, score I80).
The same remarks about hand editing apply asbefore.
Figure 5 summarises the results for subtree swapping and the two genetic algorithms on aset of examples.
These results summarise the mean and standard eviations of the scores of thesystem run 10 times.
The system was tried with a limit of 2000 and 4000 ?iterations around themain loop of the algorithm.
These took about 2 and 4 minutes respectively.
With each exampleproblem we have specified the number of facts, the number of elaboration relations and the numberof non-elaboration relations.
Note that there is not a very clear basis for comparison between105This jewel/is made from diamonds and yellow metals.It /was made by Flockinger, who was an ?English designer.?
Flockinger lived in London, which is a city.This jeweli was made in London.It / is a necklace.Iti is made from oxidized white metal, pearls and opals.It / is set with jewels.This jewel/ is encrusted with jewels: it/ has silver links encrusted asymetrically withpearls and diamonds.
-This jewel/was made in 1976.Iti is an Organic style jewel and is 72.0 cm long.Iti draws on natural themes for inspiration: it/ uses natural pearls.
Indeed, Organicstyle jewels usually draw on natural themes for inspiration.Organic style jewels usually have ?
a coarse texture, are usually made up of asymmetrical?
shapes and are usually encrusted with jewels.The ?previous jewelj is encrusted With jewels: itj features diamonds encrusted on anatural shell.. Itj has little diamonds cattered around its edgesand an encrusted bezel.Figure 4: Text Planned by GAalgorithms, since each algorithm performs different operations during an "iteration".
Nevertheless,since iterations take roughly the same amount of time one can get a rough idea of the relativeperformance.The ?example text is now in a single paragraph, with a clear link from each sentence to the?
previous ones.
F rom the numerical results, one can see that  there is imuch less variability thanbefore.
This is mainly because the rigid tree-building constraints prevent really bad trees ?
beingbuilt and so the worst results are less bad.
The results are also significantly better than for subtreeswapping, with the edge-sensitive r presentation clearly winning.
?7 DiscussionI t  is necessary to be careful in evaluating:these results, which are 0nly as good as the evaluationfunction.
This is certainly flawed in major ways.
The texts are of a specific type, there are onlythree of them and we have not used all rhetorical relations.
Some independent evaluation by humanreaders is imperative at this point.
The texts a re  especially limited by the fact that there is noaccount taken Of the possibilities for aggregation , ?embedding etc.
in the trees that are produced:NevertheleSs ?
the approach looks promising enough that it is a real candidate to  be used with theI LEX syste m. Future  work needs to look at improving the characterisation f good trees and ifpossible ?introducing more natural  crossover/mutation perations.
Future work could also considerextending the scope o f  the algorithm to deal with aspects of content determination as well as?structuring.106II!liil,Iii!\]!
.~!itiSubtree Swapping 2000 Iterations 4000 IterationsItem facts elabs rels Mean S.D.
Mean S.D.j-342540 28 298 13 -38.9 27.7 -15.0 39.3j-990302 25 297 13 18.5 32.6 31.6 27.9j-990811 24 274 6 -50.7 33.6 -2.2 27.6Ordinal Representation 2000 Iterations 4000 IterationsItem facts elabs rels Mean S.D.
Mean S.D.j-342540 28 298 13 110.2 25.6 127.3 26.1j-990302 25 297 13 109.2 13.6 115.0 18.7j-990811 24 274 6 57.0 17.6 66.7 17.8Path Representation 2000 Iterations 4000 IterationsItem facts elabs rels Mean S.D.
Mean S.D.j-342540 28 298 13 158.4 22.7 171.3 20.1j-990302 25 297 13?
175.0 19.3 192.9 13.7j:990811 24 274 6 90.7 11.4 104.0 17.3Figure 5: Results for 3 Algorithms ?.8 AcknowledgementsThe ILEX project is supported by EPSRC grant GR/K53321.
We acknowledge the valuable as-sistence of the National Museums of Scotland and the useful advice of Andrew Tuson.References\[Goldberg 89\] Goldberg, D., Genetic Algorithms in Search, Optimization and Machine Learning, Addison-Wesley, 1989.\[Hovy 90\] Hovy, E., "Unresolved Issues in Paragraph Planning", in Dale, R., Mellish, C. and Zock, M.,?
Current Research in Natural Language Generation, Academic Press, 1990, pp17.45.\[Mann and Thompson 87\] Mann, W. and Thompson, S., "Rhetorical Structure Theory: Description andConstruction of Text Structures", in Kempen, G., Ed., Natural Language Generation: New Results inArtificial Intelligence, Psychology and Linguistics, Dordrecht: Nijhoff, 1987.
?\[Marcu 96\] Marcu, D., "Building up Rhetorical Struicture Trees", Proceedings of AAAI-96, American As-sociation for Artificial Intelligence, 1996, pp1069-1074:\[Marcu 97\] Marcu, D .
,  "From Local to Global Coherence: A Bottom-up Approach to Text ?Planning",Proceedings of AAAI-97, American Association for Artificial Intelligence, 1997, pp629-635.\[Mellish et a198\] Mellish, C., O'Donnell, M., Oberlander, J. and Knott, A., "An Architecture for Oppor-tunistic Text Generation", Proceedings of INLGW-98, 1998.\[Michalewicz 92\] Michalewicz, Z., Geneti c Algorithm 4- Data Structures = Evolution Programs, SpringerVerlag, 1992.
-\[Moore and Paris 93\] Moore, J. and Paris, C., "Planning Texts for Advisory Dialogues: Capturing Inten ....tional and Rhetorical Information", Computational Linguistics Vol 19, No 4, 1993, pp651-694.\[Scott and de Souza 90\] Scott, D. and de Souza, C., "Getting the Message Across in RST-Based Text Gener-ation", in Dale, R., Mellish, C. and Zock, M., Eds., Current Research in Natural Language Generation,Academic Press, 1990, pp47-73.107
