Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1227?1231,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsAutomatic cognate identification with gap-weighted string subsequences.Taraka RamaSpr?akbankenUniversity of GothenburgBox 200, Gothenburg, Swedentaraka.rama.kasicheyanula@gu.seAbstractIn this paper, we describe the problem of cog-nate identification in NLP.
We introduce theidea of gap-weighted subsequences for dis-criminating cognates from non-cognates.
Wealso propose a scheme to integrate phoneticfeatures into the feature vectors for cognateidentification.
We show that subsequencebased features perform better than state-of-the-art classifier for the purpose of cognateidentification.
The contribution of this paperis the use of subsequence features for cognateidentification.1 IntroductionCognates are words across languages whose ori-gin can be traced back to a common ancestral lan-guage.
For example, English ?
German night ?Nacht ?night?
and English hound ?
German Hund?dog?
are cognates whose origin can be traced backto Proto-Germanic.
Sometimes, cognates are notrevealingly similar but have changed substantiallyover time such that they do not share form simi-larity.
An example of such a cognate pair is theEnglish wheel and Sanskrit chakra ?wheel?, whichcan be traced back to Proto-Indo-European (PIE)?kwekwelo.Automatic cognate identification, in NLP, refersto the application of string similarity or phoneticsimilarity algorithms either independently, or in tan-dem with machine learning algorithms for determin-ing if a given word pair is cognate or not (Inkpenet al, 2005).
In NLP, even borrowed words (loan-words) are referred to as cognates.
In contrast, his-torical linguistics makes a stark distinction betweenloanwords and cognates.
For example, English beefis a loanword from Norman French.In this paper, we use cognates to refer to thosewords whose origin can be traced back to a com-mon ancestor.
We use string subsequence based fea-tures (motivated from string kernels) for automaticcognate identification.
We show that subsequence-based features outperform word similarity measuresat the task of automatic cognate identification.
Wemotivate the use of subsequence based features interms of linguistic examples and then proceed toformulate the subsequence based features that canbe derived from string kernels (Shawe-Taylor andCristianini, 2004).
In information retrieval litera-ture, string subsequences go under the name of skip-grams (J?arvelin et al, 2007).2 Related workThe approaches developed by Kondrak and Sherif(2006) and Inkpen et al (2005) supply differentstring distances between a pair of words as featuresto a linear classifier.
Usually, a linear classifier suchas SVM is trained on labeled positive (?cognates?
)and negative (?non-cognates?)
examples and testedon a held-out dataset.
Basic vocabulary lists suchas the ones devised by Morris Swadesh (Swadesh,1952), provide a suitable testing ground for apply-ing machine learning algorithms to automaticallyidentify cognates.
Some standardized word listscome with cognate information and, subsequently,can used to infer the relationship between the lan-guages (Dyen et al, 1992).1227Ellison and Kirby (2006) use scaled edit distance(normalized by average length) to measure the intra-lexical divergence in a language.
The inter-languagedistance matrix is supplied to a clustering algorithmto infer a tree for the Indo-European language fam-ily.
The authors only perform a qualitative evalua-tion of the inferred tree.
The authors mention stringkernels but do not pursue this line of research fur-ther.Bouchard-C?ot?e et al (2013) employ a graphicalmodel to reconstruct the proto-word forms from thesynchronic word-forms for the Austronesian lan-guage family.
They compare their automated re-constructions with the ones reconstructed by his-torical linguists and find that their model beats anedit-distance baseline.
However, their model has arequirement that the tree structure between the lan-guages under study has to be known beforehand.Hauer and Kondrak (2011) ?
referred to as HK ?supply different string similarity scores as featuresto a SVM classifier for determining if a given wordpair is a cognate or not.
The authors also employan additional binary language-pair feature ?
that isused to weigh the language distance ?
and find thatthe additional feature assists the task of semanticclustering of cognates.
In this task, the cognacyjudgments given by a linear classifier is used to flatcluster the lexical items belonging to a single con-cept.
The clustering quality is evaluated against thegold standard cognacy judgments.
Unfortunately,the experiments of these scholars cannot be repli-cated since the partitioning details of their trainingand test datasets is not available.In our experiments, we compare our system?s per-formance with the performance of the classifierstrained from HK-based features.
In the next section,we will describe string similarity measures, subse-quences features, dataset, and results.3 Cognate identification3.1 String similarity features and issuesEdit distance counts the minimum number of inser-tions, deletions, and substitutions required to trans-form one word into another word.
Identical wordshave 0 edit distance.
For example, the edit dis-tance between two cognates English hound and Ger-man hund is 1.
Similarly, the edit distance betweenSwedish i and Russian v ?in?, which are cognates,is 1.
The edit distance treats both of the cognatesat the same level and does not reflect the amount ofchange which has occurred in the Swedish and Rus-sian words from the PIE word.Dice is another string similarity measure that de-fines similarity between two strings as the ratio be-tween the number of common bigrams to the totalnumber of bigrams.
The similarity between Lusatiandolhi and Czech dluhe ?long?
is 0 since they do notshare any common bigrams and the edit distance be-tween the two strings is 3.
Although the two wordsshare all the consonants, the Dice score is 0 due tothe intervening vowels.Another string similarity measure, Longest Com-mon Subsequence (LCS) measures the length ofthe longest common subsequence between the twowords.
The LCS is 4 (hund), 0 (i and v), and 3(dlh) for the above examples.
One can put fortha number of examples which are problematical forthe commonly-used string similarity measures.
Al-ternatively, string kernels in machine learning re-search offer a way to exploit the similarities betweentwo words without any restrictions on the length andcharacter similarity.3.2 Subsequence featuresSubsequences as formulated below weigh the sim-ilarity between two words based on the number ofdropped characters and combine phoneme classesseamlessly.
Having motivated why subsequencesseems to be a good idea, we formulate subsequencesbelow.We follow the notation given in Shawe-Taylor andCristianini (2004) to formulate our representation ofa string (word).
Let ?
denote the set of phonetic al-phabet.
Given a string s over ?, the subsequencevector ?
(s) is defined as follows.
The string scan be decomposed as s1, .
.
.
, s|s|where |s| denotesthe length of the string.
Let?
?I denote a sequenceof indices (i1, .
.
.
, i|u|) where, 1 ?
i1< .
.
.
<i|u|?
|s|.
Then, a subsequence u is a sequenceof characters s[?
?I ].
Note that a subsequence canoccur multiple times in a string.
Then, the weightof u, ?u(s) is defined as??
?I :u=s[?
?I ]?l(?
?I )where,l(?
?I ) = i|u|?
i1+1 and ?
?
(0, 1) is a decay factor.The subsequence vector ?
(s) is composed of1228?u(s) ?u ?
?pn=1?n, where 1 ?
n ?
p is thelength of u and p is the maximum length of the sub-sequences.
As ?
?
0, a subsequence is constrainedto a substring.
As ?
?
1, ?u(s) counts the fre-quency of u in s. We also experiment with differentvalues of ?
in this paper.The ?
factor is exponential and penalizes u overlong gaps in a string.
Due to the above formula-tion, the frequency of a subsequence u in a singlestring is also taken into account.
The subsequenceformulation also allows for the incorporation of aclass-based features easily.
For instance, each ?in u can be mapped to its Consonant/Vowel class:?
7?
{C, V }.
The subsequence formulation also al-lows us to map each phonetic symbol (for example,from International Phonetic Alphabet [IPA]) to anintermediary phonetic alphabet alo.
Unfortunately,the current dataset is not transcribed in IPA to con-vert it into an intermediary broader format.
In thispaper, we map each string s into its C, V sequencescvand then compute the subsequence weights.1A combined subsequence vector ?
(s+scv) is fur-ther normalized by its norm, ??
(s+ scv)?, to trans-form into a unit vector.
The common subsequencevector ?
(s1, s2) is composed of all the common sub-sequences between s1and s2.
The weight of a com-mon subsequence is ?u(s1) + ?u(s2).Moschitti et al (2012) list the features of theabove weighting scheme.?
Longer subsequences receive lower weights.?
Characters can be omitted (called gaps).?
The exponent of ?
penalizes recurring subse-quences with longer gaps.For a string of length m and subsequence lengthn, the computational complexity is in the order ofO(mn).On a linguistic note, gaps are consistent with theprevalent sound changes such as sound loss, soundgain, and assimilation,2processes which alter wordforms in an ancestral language causing the daugh-ter languages to have different surface forms.
The ?factor weighs the number of gaps found in a sub-sequence.
For instance, the Sardinian word formfor ?fish?
pissi has the subsequence ps occurring1V = {a, e, i, o, u, y}, C = ?
\ V .2A sound can assimilate to a neighboring sound.
Sanskritagni > Prakrit aggi ?fire?.
Compare the Latin form ignis withthe Sanskrit form.twice but with different weights: ?3, ?4.
Hence, ps?sweight is ?3+ ?4.
On another note, the idea of gapsubsequences subsumes the definitions of differentn-gram similarities introduced by Kondrak (2005).The combined feature vector, for a word pair, isused to train a SVM classifier.
In our experiments,we use the LIBLINEAR package (Fan et al, 2008)to solve the primal problem with L2-regularizationand L2-loss.
The next subsection describes themakeup of the dataset.
We use the default SVM pa-rameters since we did not observe any difference inour development experiments.3.3 Dataset and resultsIn this section, we will present the dataset, HK fea-tures, and results of our experiments.Dataset.
We used the publicly available3Indo-European dataset (Dyen et al, 1992) for our experi-ments.
The dataset has 16, 520 lexical items for 200concepts and 84 language varieties.
Each word formis assigned to a unique CCN (Cognate Class Num-ber).
There are more than 200 identical non-cognatepairs in the dataset.
For the first experiment, we ex-tracted all word pairs for a concept and assigned apositive label if the word pair has an identical CCN;a negative label, if the word pair has different CCNs.We extracted a total of 619, 635 word pairs out ofwhich 145, 145 are cognates.
The dataset is tran-scribed in a broad romanized phonetic alphabet.We explored if we could use two other word listdatabases: ASJP (Brown et al, 2008) and Ringeet al (2002) for our experiments.
Although theASJP database has word lists for more than halfof the world?s languages, it has cognacy judgmentsfor few selected languages and is limited to 40 con-cepts.
Moreover, the ASJP database does not havecognacy judgments for Indo-European family.
Theother dataset of Ringe et al (2002) has items for 24Indo-European languages which are transcribed inan orthographic format and not in a uniform pho-netic alphabet.4Moreover, there are a number ofmissing items for some of the languages.
Hence, wedid not use Ringe et al?s dataset in our experiments.In contrast, Dyen?s dataset is much larger and tran-scribed in an uniform format.
Now, we proceed to3http://www.wordgumbo.com/ie/cmp/iedata.txt4http://www.cs.rice.edu/ nakhleh/CPHL/ie-wordlist-07.pdf1229describe the previous best-performing system.HK?s system.
We compare the performance ofsubsequence features against the SVM classifier sys-tem trained on the following word-similarity fea-tures from Hauer and Kondrak (2011):?
Edit distance.?
Length of longest common prefix.?
Number of common bigrams.?
Lengths of individual words.?
Absolute difference between the lengths of thewords.Cross-Validation experiment.
As a first step, weperform a random ten-fold cross-validation of thedataset and report the accuracies for various val-ues of ?
and p. The results of this experiment areFigure 1: Ten-fold cross-validation accuracy for incre-mental ?
and p. The accuracy of the system of HK is82.61%.shown in figure 1.
The best results are obtained at?
= 0.8, p = 3.
The accuracies increase with anincrement in the value of ?
until 0.8 for all p > 1(non-unigram models).
This experiment is mainlydesigned to test the robustness of subsequence fea-tures against random splits in the dataset which turnsout to be robust.
The subsequence features outper-form HK-based classifier in this experiment.positive negativetraining 111, 918 353, 957test 33, 227 120, 533Table 1: Number of positive and negative examples inthe training and test sets.
The ratio of positive to negativeexamples is 1 : 3.62.Concepts experiment.
In this experiment, wesplit our dataset into two sets by concepts; and trainon one set and test on the other.
To replicate ourdataset, we performed an alphabetical sort of theconcepts and split the concepts into training and test-ing datasets with a ratio of 3 : 1.
Now, we extractpositive and negative examples from each subset ofconcepts; and train and test on each concepts?
sub-set.
We also performed a 3-fold cross-validation onthe training set to tune c (SVM hyperparameter).
Weobserved that the value of c did not effect the cross-validation accuracy on the training dataset.
Hencewe fixed c at 1.
We also experimented with radial-basis function kernel and polynomial kernels but didnot find any improvement over the linear kernel clas-sifier.
The composition of the training and test setsis given in table 1.Figure 2: F1-score for different values of p and ?.
TheF1-score of the system of HK is 0.46.In this experiment, we report the F1-score, de-fined as2PRP+R(Precision and Recall), for differentvalues of ?
and p. The results of this experimentare shown in figure 2.
The F1-score of the systemof HK is 0.46 whereas the best performing subse-quence system (?
= 0.7, p = 2) has a score of0.5.
Our system performs better than the system ofHK in terms of cross-validation accuracy as well asF1-score.
Overall, all non-unigram models performbetter than the system of HK at cross-validation andconcepts experiments.4 ConclusionIn this paper, we proposed a string kernel based ap-proach for the purpose of cognate identification.
Weformulated an approach to integrate phonetic fea-tures of a phonetic symbol into the feature vectorand showed that it beats the system of HK at cog-1230nate identification at cross-validation and conceptssubsets experiments.In future, we plan to make a larger dataset ofcognacy judgments for other language families in aricher phonetic transcription and integrate articula-tory phonetic features into the feature vectors for thepurpose of cognate identification.
We also plan ontesting with different feature vector combinations.AcknowledgmentsI thank the three anonymous reviewers for the com-ments that helped improve the paper.
I thank S?renWichmann, Richard Johansson, Gerlof Bouma,Prasanth Kolachina, and Johann-Mattis List for allthe discussions and comments that helped improvethe paper.
This research was supported by Univer-sity of Gothenburg through its support of the Centrefor Language Technology and Spr?akbanken.ReferencesAlexandre Bouchard-C?ot?e, David Hall, Thomas L. Grif-fiths, and Dan Klein.
2013.
Automated reconstruc-tion of ancient languages using probabilistic models ofsound change.
Proceedings of the National Academyof Sciences, 110(11):4224?4229.Cecil H. Brown, Eric W. Holman, S?ren Wichmann, andViveka Velupillai.
2008.
Automated classification ofthe world?s languages: A description of the methodand preliminary results.
Sprachtypologie und Univer-salienforschung, 61(4):285?308.Isidore Dyen, Joseph B. Kruskal, and Paul Black.
1992.An Indo-European classification: A lexicostatisticalexperiment.
Transactions of the American Philosoph-ical Society, 82(5):1?132.T.
Mark Ellison and Simon Kirby.
2006.
Measur-ing language divergence by intra-lexical comparison.In Proceedings of the 21st International Conferenceon Computational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguistics,pages 273?280, Sydney, Australia, July.
Associationfor Computational Linguistics.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
Liblinear: A libraryfor large linear classification.
The Journal of MachineLearning Research, 9:1871?1874.Bradley Hauer and Grzegorz Kondrak.
2011.
Cluster-ing semantically equivalent words into cognate setsin multilingual lists.
In Proceedings of 5th Interna-tional Joint Conference on Natural Language Process-ing, pages 865?873, Chiang Mai, Thailand, Novem-ber.
Asian Federation of Natural Language Processing.Diana Inkpen, Oana Frunza, and Grzegorz Kondrak.2005.
Automatic identification of cognates and falsefriends in French and English.
In Proceedings of theInternational Conference Recent Advances in NaturalLanguage Processing, pages 251?257.Anni J?arvelin, Antti J?arvelin, and Kalervo J?arvelin.
2007.s-grams: Defining generalized n-grams for informa-tion retrieval.
Information Processing &Management,43(4):1005?1019.Grzegorz Kondrak and Tarek Sherif.
2006.
Evaluationof several phonetic similarity algorithms on the task ofcognate identification.
In Proceedings of ACL Work-shop on Linguistic Distances, pages 43?50.
Associa-tion for Computational Linguistics.Grzegorz Kondrak.
2005.
N-gram similarity and dis-tance.
In String Processing and Information Retrieval,pages 115?126.
Springer.Alessandro Moschitti, Qi Ju, and Richard Johansson.2012.
Modeling topic dependencies in hierarchicaltext categorization.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Linguis-tics: Long Papers-Volume 1, pages 759?767.
Associa-tion for Computational Linguistics.Don Ringe, Tandy Warnow, and Ann Taylor.
2002.
Indo-European and computational cladistics.
Transactionsof the Philological Society, 100(1):59?129.John Shawe-Taylor and Nello Cristianini.
2004.
Kernelmethods for pattern analysis.
Cambridge universitypress.Morris Swadesh.
1952.
Lexico-statistic dating of prehis-toric ethnic contacts: with special reference to NorthAmerican Indians and Eskimos.
Proceedings of theAmerican philosophical society, 96(4):452?463.1231
