Proceedings of the ACL Interactive Poster and Demonstration Sessions,pages 101?104, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsMulti-Engine Machine Translation Guided by Explicit Word MatchingShyamsundar Jayaraman Alon LavieLanguage Technologies Institute  Language Technologies InstituteCarnegie Mellon University Carnegie Mellon UniversityPittsburgh, PA 15213 Pittsburgh, PA 15213shyamj@cs.cmu.edu alavie@cs.cmu.eduAbstractWe describe a new approach for syntheti-cally combining the output of several dif-ferent Machine Translation (MT) enginesoperating on the same input.
The goal isto produce a synthetic combination thatsurpasses all of the original systems intranslation quality.
Our approach uses theindividual MT engines as ?black boxes?and does not require any explicit coopera-tion from the original MT systems.
A de-coding algorithm uses explicit wordmatches, in conjunction with confidenceestimates for the various engines and a tri-gram language model in order to scoreand rank a collection of sentence hypothe-ses that are synthetic combinations ofwords from the various original engines.The highest scoring sentence hypothesisis selected as the final output of our sys-tem.
Experiments, using several Arabic-to-English systems of similar quality,show a substantial improvement in thequality of the translation output.1 IntroductionA variety of different paradigms for machinetranslation (MT) have been developed over theyears, ranging from statistical systems that learnmappings between words and phrases in the sourcelanguage and their corresponding translations inthe target language, to Interlingua-based systemsthat perform deep semantic analysis.
Each ap-proach and system has different advantages anddisadvantages.
While statistical systems providebroad coverage with little manpower, the quality ofthe corpus based systems rarely reaches the qualityof knowledge based systems.With such a wide range of approaches to ma-chine translation, it would be beneficial to have aneffective framework for combining these systemsinto an MT system that carries many of the advan-tages of the individual systems and suffers fromfew of their disadvantages.
Attempts at combiningthe output of different systems have proved usefulin other areas of language technologies, such as theROVER approach for speech recognition (Fiscus1997).
Several approaches to multi-engine ma-chine translation systems have been proposed overthe past decade.
The Pangloss system and work byseveral other researchers attempted to combinelattices from many different MT systems (Fred-erking et Nirenburg 1994, Frederking et al1997;Tidhar & K?ssner 2000; Lavie, Probst et al 2004).These systems suffer from requiring cooperationfrom all the systems to produce compatible latticesas well as the hard research problem of standardiz-ing confidence scores that come from the individ-ual engines.
In 2001, Bangalore et alused stringalignments between the different translations totrain a finite state machine to produce a consensustranslation.
The alignment algorithm described inthat work, which only allows insertions, deletionsand substitutions, does not accurately capture longrange phrase movement.In this paper, we propose a new way of com-bining the translations of multiple MT systemsbased on a more versatile word alignment algo-rithm.
A ?decoding?
algorithm then uses thesealignments, in conjunction with confidence esti-mates for the various engines and a trigram lan-guage model, in order to score and rank acollection of sentence hypotheses that are syntheticcombinations of words from the various originalengines.
The highest scoring sentence hypothesisis selected as the final output of our system.
We101experimentally tested the new approach by com-bining translations obtained from combining threeArabic-to-English translation systems.
Translationquality is scored using the METEOR MT evalua-tion metric (Lavie, Sagae  et al2004).
Our ex-periments demonstrate that our new MEMT systemachieves a substantial improvement over all of theoriginal systems, and also outperforms an ?oracle?capable of selecting the best of the original systemson a sentence-by-sentence basis.The remainder of this paper is organized asfollows.
In section 2 we describe the algorithm forgenerating multi-engine synthetic translations.Section 3 describes the experimental setup used toevaluate our approach, and section 4 presents theresults of the evaluation.
Our conclusions and di-rections for future work are presented in section 5.2 The MEMT AlgorithmOur Multi-Engine Machine Translation(MEMT) system operates on the single ?top-best?translation output produced by each of several MTsystems operating on a common input sentence.MEMT first aligns the words of the different trans-lation systems using a word alignment matcher.Then, using the alignments provided by thematcher, the system generates a set of syntheticsentence hypothesis translations.
Each hypothesistranslation is assigned a score based on the align-ment information, the confidence of the individualsystems, and a language model.
The hypothesistranslation with the best score is selected as thefinal output of the MEMT combination.2.1 The Word Alignment MatcherThe task of the matcher is to produce a word-to-word alignment between the words of two giveninput strings.
Identical words that appear in bothinput sentences are potential matches.
Since thesame word may appear multiple times in the sen-tence, there are multiple ways to produce analignment between the two input strings.
The goalis to find the alignment that represents the best cor-respondence between the strings.
This alignmentis defined as the alignment that has the smallestnumber of ?crossing edges.
The matcher can alsoconsider morphological variants of the same wordas potential matches.
To simultaneously alignmore than two sentences, the matcher simply pro-duces alignments for all pair-wise combinations ofthe set of sentences.In the context of its use within our MEMT ap-proach, the word-alignment matcher provides threemain benefits.
First, it explicitly identifies trans-lated words that appear in multiple MT transla-tions, allowing the MEMT algorithm to reinforcewords that are common among the systems.
Sec-ond, the alignment information allows the algo-rithm to ensure that aligned words are not includedin a synthetic combination more than once.
Third,by allowing long range matches, the syntheticcombination generation algorithm can considerdifferent plausible orderings of the matched words,based on their location in the original translations.2.2 Basic Hypothesis GenerationAfter the matcher has word aligned the originalsystem translations, the decoder goes to work.
Thehypothesis generator produces synthetic combina-tions of words and phrases from the original trans-lations that satisfy a set of adequacy constraints.The generation algorithm is an iterative processand produces these translation hypotheses incre-mentally.
In each iteration, the set of existing par-tial hypotheses is extended by incorporating anadditional word from one of the original transla-tions.
For each partial hypothesis, a data-structurekeeps track of the words from the original transla-tions which are accounted for by this partial hy-pothesis.
One underlying constraint observed bythe generator is that the original translations areconsidered in principle to be word synchronous inthe sense that selecting a word from one originaltranslation normally implies ?marking?
a corre-sponding word in each of the other original transla-tions as ?used?.
The way this is determined isexplained below.
Two partial hypotheses that havethe same partial translation, but have a different setof words that have been accounted for are consid-ered different.
A hypothesis is considered ?com-plete?
if the next word chosen to extend thehypothesis is the explicit end-of-sentence markerfrom one of the original translation strings.
At thestart of hypothesis generation, there is a single hy-pothesis, which has the empty string as its partialtranslation and where none of the words in any ofthe original translations are marked as used.In each iteration, the decoder extends a hy-pothesis by choosing the next unused word from102one of the original translations.
When the decoderchooses to extend a hypothesis by selecting word wfrom original system A, the decoder marks w asused.
The decoder then proceeds to identify andmark as used a word in each of the other originalsystems.
If w is aligned to words in any of theother original translation systems, then the wordsthat are aligned with w are also marked as used.For each system that does not have a word thataligns with w, the decoder establishes an artificialalignment between w and a word in this system.The intuition here is that this artificial alignmentcorresponds to a different translation of the samesource-language word that corresponds to w.  Thechoice of an artificial alignment cannot violateconstraints that are imposed by alignments thatwere found by the matcher.
If no artificial align-ment can be established, then no word from thissystem will be marked as used.
The decoder re-peats this process for each of the original transla-tions.
Since the order in which the systems areprocessed matters, the decoder produces a separatehypothesis for each order.Each iteration expands the previous set of partialhypotheses, resulting in a large space of completesynthetic hypotheses.
Since this space can growexponentially, pruning based on scoring of the par-tial hypotheses is applied when necessary.2.3 Confidence ScoresA major component in the scoring of hypothe-sis translations is a confidence score that is as-signed to each of the original translations, whichreflects the translation adequacy of the system thatproduced it.
We associate a confidence score witheach word in a synthetic translation based on theconfidence of the system from which it originated.If the word was contributed by several differentoriginal translations, we sum the confidences of thecontributing systems.
This word confidence scoreis combined multiplicatively with a score assignedto the word by a trigram language model.
Thescore assigned to a complete hypothesis is its geo-metric average word score.
This removes the in-herent bias for shorter hypotheses that is present inmultiplicative cumulative scores.2.4 Restrictions on Artificial AlignmentsThe basic algorithm works well as long theoriginal translations are reasonably word synchro-nous.
This rarely occurs, so several additional con-straints are applied during hypothesis generation.First, the decoder discards unused words in origi-nal systems that ?linger?
around too long.
Second,the decoder limits how far ahead it looks for anartificial alignment, to prevent incorrect long-rangeartificial alignments.
Finally, the decoder does notallow an artificial match between words that do notshare the same part-of-speech.3 Experimental SetupWe combined outputs of three Arabic-to-Englishmachine translation systems on the 2003 TIDESArabic test set.
The systems were AppTek?s rulebased system, CMU?s EBMT system, andSystran?s web-based translation system.We compare the results of MEMT to the indi-vidual online machine translation systems.
Wealso compare the performance of MEMT to thescore of an ?oracle system?
that chooses the bestscoring of the individual systems for each sen-tence.
Note that this oracle is not a realistic sys-tem, since a real system cannot determine at run-time which of the original systems is best on a sen-tence-by-sentence basis.
One goal of the evalua-tion was to see how rich the space of synthetictranslations produced by our hypothesis generatoris.
To this end, we also compare the output se-lected by our current MEMT system to an ?oraclesystem?
that chooses the best synthetic translationthat was generated by the decoder for each sen-tence.
This too is not a realistic system, but it al-lows us to see how well our hypothesis scoringcurrently performs.
This also provides a way ofestimating a performance ceiling of the MEMTapproach, since our MEMT can only producewords that are provided by the original systems(Hogan and Frederking 1998).Due to the computational complexity of run-ning the oracle system, several practical restric-tions were imposed.
First, the oracle system onlyhad access to the top 1000 translation hypothesesproduced by MEMT for each sentence.
While thisdoes not guarantee finding the best translation thatthe decoder can produce, this method provides agood approximation.
We also ran the oracle ex-periment only on the first 140 sentences of the testsets due to time constraints.All the system performances are measured us-ing the METEOR evaluation metric (Lavie, Sagae103et al, 2004).
METEOR was chosen since, unlikethe more commonly used BLEU metric (Papineniet al, 2002), it provides reasonably reliable scoresfor individual sentences.
This property is essentialin order to run our oracle experiments.
METEORproduces scores in the range of [0,1], based on acombination of unigram precision, unigram recalland an explicit penalty related to the averagelength of matched segments between the evaluatedtranslation and its reference.4 ResultsSystem METEOR ScoreSystem A 0.4241System B 0.4231System C 0.4405Choosing best original translation 0.4432MEMT System  0.5183Table 1: METEOR Scores on TIDES 2003 DatasetOn the 2003 TIDES data, the three original sys-tems had similar METEOR scores.
Table 1 showsthe scores of the three systems, with their namesobscured to protect their privacy.
Also shown arethe score of MEMT?s output and the score of theoracle system that chooses the best original transla-tion on a sentence-by-sentence basis.
The score ofthe MEMT system is significantly better than anyof the original systems, and the sentence oracle.On the first 140 sentences, the oracle system thatselects the best hypothesis translation generated bythe MEMT generator has a METEOR score of0.5883.
This indicates that the scoring algorithmused to select the final MEMT output can be sig-nificantly further improved.5 Conclusions and Future WorkOur MEMT algorithm shows consistent im-provement in the quality of the translation com-pared any of the original systems.
It scores betterthan an ?oracle?
that chooses the best originaltranslation on a sentence-by-sentence basis.
Fur-thermore, our MEMT algorithm produces hypothe-ses that are of yet even better quality, but ourcurrent scoring algorithm is not yet able to effec-tively select the best hypothesis.
The focus of ourfuture work will thus be on identifying featuresthat support improved hypothesis scoring.AcknowledgmentsThis research work was partly supported by a grantfrom the US Department of Defense.
The wordalignment matcher was developed by SatanjeevBanerjee.
We wish to thank Robert Frederking,Ralf Brown and Jaime Carbonell for their valuableinput and suggestions.ReferencesBangalore, S., G.Bordel, and G. Riccardi (2001).
Com-puting Consensus Translation from Multiple MachineTranslation Systems.
In Proceedings of IEEE Auto-matic Speech Recognition and Understanding Work-shop (ASRU-2001), Italy.Fiscus, J. G.(1997).
A Post-processing System to YieldReduced Error Word Rates: Recognizer Output Vot-ing Error Reduction (ROVER).
In IEEE Workshopon Automatic Speech Recognition and Understanding(ASRU-1997).Frederking, R. and S. Nirenburg.
Three Heads are Betterthan One.
In Proceedings of the Fourth Conferenceon Applied Natural Language Processing (ANLP-94), Stuttgart, Germany, 1994.Hogan, C. and R.E.Frederking (1998).
An Evaluation ofthe Multi-engine MT Architecture.
In Proceedings ofthe Third Conference of the Association for MachineTranslation in the Americas, pp.
113-123.
Springer-Verlag, Berlin .Lavie, A., K. Probst, E. Peterson, S. Vogel, L.Levin, A.Font-Llitjos and J. Carbonell (2004).
A TrainableTransfer-based Machine Translation Approach forLanguages with Limited Resources.
In Proceedingsof Workshop of the European Association for Ma-chine Translation (EAMT-2004), Valletta, Malta.Lavie, A., K. Sagae and S. Jayaraman (2004).
The Sig-nificance of Recall in Automatic Metrics for MTEvaluation.
In Proceedings of the 6th Conference ofthe Association for Machine Translation in theAmericas (AMTA-2004), Washington, DC.Papineni, K., S. Roukos, T. Ward and W-J Zhu (2002).BLEU: a Method for Automatic Evaluation of Ma-chine Translation.
In Proceedings of 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL-2002), Philadelphia, PA.Tidhar, Dan and U. K?ssner (2000).
Learning to Selecta Good Translation.
In Proceedings of the 17th con-ference on Computational linguistics (COLING2000), Saarbr?cken, Germany.104
