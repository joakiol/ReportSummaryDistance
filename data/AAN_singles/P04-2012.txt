A Framework for Unsupervised Natural Language Morphology InductionChristian MonsonLanguage Technologies InstituteCarnegie Mellon University5000 Forbes Ave.Pittsburgh, PA, USA 15213cmonson@cs.cmu.eduAbstractThis paper presents a framework for unsuper-vised natural language morphology inductionwherein candidate suffixes are grouped intocandidate inflection classes, which are then ar-ranged in a lattice structure.
With similar can-didate inflection classes placed near one an-other in the lattice, I propose this structure isan ideal search space in which to isolate thetrue inflection classes of a language.
This pa-per discusses and motivates possible searchstrategies over the inflection class lattice struc-ture.1 IntroductionMany natural language processing tasks, includ-ing parsing and machine translation, frequentlyrequire a morphological analysis of the language(s)at hand.
The task of a morphological analyzer is toidentify the lexeme, citation form, or inflectionclass of surface word forms in a language.
Striv-ing to bypass the time consuming, labor intensivetask of constructing a morphological analyzer byhand, unsupervised morphology induction tech-niques seek to automatically discover the morpho-logical structure of a natural language through theanalysis of corpora.This paper presents a framework for automaticnatural language morphology induction inspired bythe traditional and linguistic concept of inflectionclasses.
Monson et al (2004) uses the frameworkdiscussed in this paper and presents results usingan intuitive baseline search strategy.
This paperpresents a discussion of the candidate inflectionclass framework as a generalization of corpus triesused in early work (Harris, 1955; Harris, 1967;Hafer and Weiss, 1974) and discusses an as yetunimplemented statistically motivated search strat-egy.
This paper employs English to illustrate itsmain conjectures and a Spanish newswire corpusof 40,011 tokens and 6,975 types for concrete ex-amples.2 Previous WorkIt is possible to organize much of the recentwork on unsupervised morphology induction byconsidering the bias each approach has toward dis-covering morphologically related words that arealso orthographically similar.
Yarowsky et al(2001), who acquire a morphological analyzer fora language by projecting the morphological analy-sis of a second language onto the first through aclever application of statistical machine translationstyle word alignment probabilities, place no con-straints on the orthographic shape of related wordforms.Next along the spectrum of orthographic similar-ity bias is the work of Schone and Jurafsky (2000;2001), who first acquire a list of potential morpho-logical variants using an orthographic similaritytechnique due to Gaussier (1999) in which  pairs ofwords with the same initial string are identified.They then apply latent semantic analysis (LSA) toscore the potential morphological variants with asemantic distance.
Word forms with small seman-tic distance are proposed as morphological variantsof one anther.Goldsmith (2001), by searching over a space ofmorphology models limited to substitution of suf-fixes, ties morphology yet closer to orthography.Segmenting word forms in a corpus, Goldsmithcreates an inventory of stems and suffixes.
Suf-fixes which can interchangeably concatenate ontoa set of stems form a signature.
After defining thespace of signatures, Goldsmith searches for thatchoice of word segmentations resulting in a mini-mum description length local optimum.Finally, the work of Harris (1955; 1967), andlater Hafer and Weiss (1974), has direct bearing onthe approach taken in this paper.
Couched in mod-ern terms, their work involves first building triesover a corpus vocabulary and then selecting, asmorpheme boundaries, those character boundarieswith corresponding high branching count in thetries.The work in this paper also has a strong bias to-ward discovering morphologically related wordsthat share a similar orthography.
In particular, themorphology model I use is, akin to Goldsmith,limited to suffix substitution.
The novel proposal Ibring to the table, however, is a formalization ofthe full search space of all candidate inflectionclasses.
With this framework in place, definingsearch strategies for morpheme discovery becomesa natural and straightforward activity.3 Inflection Classes as MotivationWhen learning the morphology of a foreign lan-guage, it is common for a student to study tables ofinflection classes.
Carstairs-McCarthy formalizesthe concept of an inflection class in chapter 16 ofThe Handbook of Morphology (1998).
In his ter-minology, a language with inflectional morphol-ogy contains lexemes which occur in a variety ofword forms.
Each word form carries two pieces ofinformation:1) Lexical content and2) Morphosyntactic properties.For example, the English word form gave ex-presses the lexeme GIVE plus the morphosyntacticproperty Past, while gives expresses GIVE plus theproperties 3rd Person, Singular, and Non-Past.A set of morphosyntactic properties realizedwith a single word form is defined to be a cell,while a paradigm is a set of cells exactly filled bythe word forms of some lexeme.
A particular natu-ral language may have many paradigms.
In Eng-lish, a language with very little inflectional mor-phology, there are at least two paradigms, a nounparadigm consisting of two cells, Singular andPlural, and a paradigm for verbs, consisting of thefive cells given (with one choice of naming con-vention) as the first column of Table 1.Lexemes that belong to the same paradigm maystill differ in their morphophonemic realizations ofvarious cells in that paradigm?each paradigmmay have several associated inflection classeswhich specify, for the lexemes belonging to thatinflection class, the surface instantiation for eachcell of the paradigm.
Three of the many inflectionclasses within the English verb paradigm are foundin Table 1 under the columns labeled A through C.The task the morphology induction system pre-sented in this paper engages is exactly the discov-ery of the inflection classes of a natural language.Unlike the analysis in Table 1, however, the rest ofthis paper treats word forms as simply strings ofcharacters as opposed to strings of phonemes.4 Empirical Inflection ClassesThere are two stages in the approach to unsuper-vised morphology induction proposed in this pa-per.
First, a search space over a set of candidateinflection classes is defined, and second, this spaceis searched for those candidates most likely to bepart of a true inflection class in the language.
Ihave written a program to create the search spacebut the search strategies described in this paperhave yet to be implemented.4.1 Candidate Inflection Class Search SpaceTo define a search space wherein inflectionclasses of a natural language can be identified, myalgorithm accepts as input a monolingual corpusfor the language and proposes candidate mor-pheme boundaries at every character boundary inevery word form in the corpus vocabulary.
I calleach string before a candidate morpheme boundarya candidate stem or c-stem, and each string after aboundary a c-suffix.
I define a candidate inflectionclass (CIC) to be a set of c-suffixes for which thereexists at least one c-stem, t, such that each c-suffixin the CIC concatenated to t produces a word formin the vocabulary.
I let the set of c-stems whichgenerate a CIC, C, be called the adherent c-stemsof C; the size of the set of adherent c-stems of C beC?s adherent size; and the size of the set of c-suffixes in C be the level of C.I then define a lattice of relations between CIC?s.In particular, two types of relations are defined:1) C-suffix set inclusion relations relate pairsof CIC?s when the c-suffixes of one CIC area superset of the c-suffixes of the other, and2) Morpheme boundary relations occur be-tween CIC?s which propose different mor-Inflection Classes VerbParadigm A B CBasicblameroamsolveshowsowsawsingring3rd PersonSingularNon-past-/z/blamesroamssolves-/z/showssowssaws-/z/singsringsPast-/d/blamedroamedsolved-/d/showedsowedsawedV?
/eI/sangrangPerfectiveor Passive-/d/blamedroamedsolved-/n/shownsownsawnV?
/?/sungrungProgressive-/i?/blamingroamingsolving-/i?/showingsowingsawing-/i?/singingringingTable 1: A few inflection classes of the Eng-lish verb paradigmpheme boundaries within the same wordforms.Figure 1 diagrams a portion of a CIC lattice overa toy vocabulary consisting of a subset of the wordforms found under inflection class A from Table 1.The c-suffix set inclusion relations, representedvertically by solid lines, connect such CIC?s ase.es.ed and e.ed, both of which originate from thec-stem blam, since the first is a superset of the sec-ond.
Morpheme boundary relations, drawn hori-zontally with dashed lines, connect such CIC?s asme.mes.med and e.es.ed, each derived from ex-actly the triple of word forms blame, blames, andblamed, but differing in the placement of the hy-pothesized morpheme boundaryHierarchical links, connect any given CIC to of-ten more than one parent and more than one child.The empty CIC (not pictured in Figure 1) can beconsidered the child of all level one CIC?s (includ-ing the ?
CIC), but there is no universal parent ofall top level CIC?s.Horizontal morpheme boundary links, dashedlines, connect a CIC, C, with a neighbor to theright if each c-suffix in C begins with the samecharacter.
This entails that there is at most onemorpheme boundary link leading to the right ofeach CIC.
There may be, however, as many linksleading to the left as there are characters in the or-thography.
The only CIC with depicted multipleleft links in Figure 1 is ?, which has left links tothe CIC?s e, s, and d.  A number of left links ema-nating from the CIC?s in Figure 1 are not shown;among others absent from the figure is the left linkfrom the CIC e.es leading to the CIC ve.ves withthe adherent sol.While many ridiculous CIC?s are found in Fig-ure 1, such as ame.ames.amed from the vocabu-lary items blame, blames, and blamed and the c-stem bl, there are also CIC?s that seem very rea-sonable, such as ?.s from the c-stems blame andtease.
The key task in automatic morphology in-duction is to autonomously separate the nonsenseCIC?s from the useful ones, thus identifying lin-guistically plausible inflection classes.To better visualize what a CIC lattice looks likewhen derived from real data, Figure 2 contains aportion of a hierarchical lattice automatically gen-erated from the Spanish newswire corpus.
Eachentry in Figure 2 contains the c-suffixes compris-ing the CIC, the adherent size of the CIC, and asample of adherent c-stems.
The lattice in Figure 2covers:1) The productive Spanish inflection class foradjectives, a.as.o.os, covering the four cellsfeminine singular, feminine plural, masculinesingular, and masculine plural, respectively;2) All possible CIC subsets of the adjectiveCIC, e.g.
a.as.o, a.os, etc.
; and3) The imposter CIC a.as.o.os.tro, togetherwith its rogue descendents, a.tro and tro.Other CIC?s that are descendents ofa.as.o.os.tro and that contain the c-suffix tro donot supply additional adherents and hence are notpresent either in Figure 2 or in my program?s rep-resentation of the CIC lattice.
The CIC?s a.as.troand os.tro, for example, both have only the oneadherent, cas, already possessed by their commonancestor a.as.o.os.tro.4.2 SearchWith the space of candidate inflection classesdefined, it seems natural to treat this lattice ofCIC?s as a hypothesis space of valid inflectionclasses and to search this space for CIC?s mostlikely to be true inflection classes in a language.There are many possible search strategies applica-ble to the CIC lattice.
Monson et al (2004) inves-tigate a series of heuristic search algorithms.
Us-ing the same Spanish newswire corpus as this pa-per, the implemented algorithms have achieved F1measures above 0.5 when identifying CIC?s be-longing to true inflection classes in Spanish.
Ine.esblamsolve.edblamesblamsolv?.s.dblame?.sblamesolve?blameblamesblamedroamsroamedroamingsolvesolvessolvinge.es.edblamedblamroamdblameroame?.dblames.dblamesblameroamsolvees.edblameblamsolvme.mesblame.medblamesblame.mes.medblamedblaroames.medblameblaFigure 1: Portion of a CIC lattice from thetoy vocabulary: blame, blames, blamed, roams,roamed, roaming, solve, solves, solvingHierarchical c-suffix set inclusion linksMorpheme boundary linksthis paper I discuss some theoretical motivationsunderlying CIC lattice search.Since there are two types of relations in the CIClattices I construct, search can be broken into twophases.
One phase searches the c-suffix set inclu-sion relations, and the other phase searches themorpheme boundary relations.
The search algo-rithms discussed in Monson et al (2004) focus onsearching the c-suffix set inclusion relations andonly utilize morpheme boundary links as a con-straint.In previous related work, morpheme boundaryrelations and c-suffix set inclusion relations areimplicitly present but not explicitly referred to.For example, Goldsmith (2001) does not separatethese two types of search.
Goldsmith?s triagesearch strategies, which make small changes in thesegmentation positions in words, primarily searchthe morpheme boundary relations, while the verti-cal search is primarily performed by heuristics thatsuggest initial word segmentations.
To illustrate,if, using the Spanish newswire corpus from thispaper, Goldsmith?s algorithm decided to segmentthe word form castro as cas-tro, then there is animplicit vote for the CIC a.as.o.os.tro in Figure 2.If, on the other hand, his algorithm decided not tosegment castro then there is a vote for the lowerlevel CIC a.as.o.os.The next two subsections motivate search overthe morpheme boundary relations and the c-suffixset inclusion relations respectively.4.2.1 Searching Morpheme Boundary RelationsHarris (1955; 1967) and Hafer and Weiss (1974)obtain intriguing results at segmenting word formsinto morphemes by first placing the word formsfrom a vocabulary in a trie, such as the trie pic-tured in the top half of Figure 3, and then propos-ing morpheme boundaries after trie nodes that havea large branching factor.
The rationale behindtheir procedure is that the phoneme, or grapheme,sequence within a morpheme is completely re-stricted, while at a morpheme boundary any num-ber of new morphemes (many with different initialphonemes) could occur.
To assess the flavor ofHarris?
algorithms, the bottom branch of the trie inFigure 3 begins with roam and subsequently en-counters a branching factor of three, leading to thetrie nodes ?, i, and s.  Such a high branching factorsuggests there may be a morpheme boundary afterroam.One way to view the horizontal morphemeboundary links in a CIC lattice is as a character triegeneralization where identical sub-tries within thefull vocabulary trie are conflated.
Figure 3 illus-trates the correspondences between a trie and aportion of a CIC lattice for a small vocabulary con-sisting of the word forms: rest, rests, resting, re-treat, retreats, retreating, retry, retries, retrying,roam, roams, and roaming.
Each circled sub-trieof the trie in the top portion of the figure corre-sponds to one of the four CIC?s in the bottom por-tion of the figure.
For example, the right-branching children of the y node in retry form asub-trie consisting of ?
and ing, but this same sub-trie is also found following the t node in rest, the tnode in retreat, and the m node in roam.
The CIClattice conflates all these sub-tries into the singleCIC ?.ing with the four adherents rest, retreat,retry, and roam.Taking this congruency further, branching factorin the trie corresponds roughly to the level of aCIC.
A level 3 CIC such as ?.ing.s corresponds tosub-tries with initial branching factor of 3.
If sepa-rate c-suffixes in a CIC happen to begin with thesame character, then a lower branching factor maycorrespond to a higher level CIC.
Similarly, thenumber of sub-tries which conflate to form a CICcorresponds to the number of adherents belongingto the CIC.Figure 2: Hierarchical CIC lattice automati-cally derived from Spanisha.as.o.os43africancasjur?dicl...a.as.o.os.tro1casa.as.os50afectadcasjur?dicl...a.as.o59cascitadjur?dicl...a.o.os105impuestindonesiitalianjur?dic...a.as199huelgincluidindustriinundad...a.os134impedidimpuestindonesiinundad...as.os68casimplicadinundadjur?dic...a.o214idindiindonesiinmediat...as.o85internjur?dicjustl...a.tro2cascena1237huelgibidiglesi...as404huelghuelguistincluidindustri...os534humor?stichumanh?gadimpedid...o1139hubhughumanhuyend...tro16catascecencua...as.o.os54casimplicadjur?dicl...o.os268humanimplicadindiciindocumentad...It is interesting to note that while Harris?
stylephoneme successor criteria do often correctly iden-tify morpheme boundaries, they posses one inher-ent class of errors.
Because Harris treats all wordforms with the same initial string as identical, anymorpheme boundary decision is global for allwords that happen to begin with the same string.For example, Harris cannot differentiate betweenthe forms casa and castro.
If a morpheme bound-ary is (correctly) placed after the cas in casa, thena morpheme boundary must be placed (incorrectly)after the cas in castro.
Using a CIC lattice, how-ever, allows an algorithm to first choose whichbranches of a trie are relevant and then select mor-pheme boundaries given the relevant sub-trie.
Ex-ploring the vertical CIC lattice in Figure 2, asearch algorithm might hope to discover that thetro trie branch is irrelevant and search for a mor-pheme boundary along the sub-tries ending ina.as.o.os.
Perhaps the morpheme boundary searchwould use the branching factor of this restrictedtrie as a discriminative criterion.4.2.2 Searching C-suffix Set Inclusion RelationsSince trie branches correspond to CIC level, Iturn now to outline a search method over the verti-cal c-suffix set inclusion relations.
This searchmethod makes particular use of CIC adherentcounts through the application of statistical inde-pendence tests.
The goal of a vertical search algo-rithm is to avoid c-suffixes which occur not as truesuffixes that are part of an inflection class, but in-stead as random strings that happen to be able toattach to a given initial string.To formalize the idea of randomness I treat eachc-suffix, F, as a Boolean random variable which istrue when F attaches to a given c-stem and falsewhen F does not attach to that c-stem.
I then makethe simplifying assumption that c-stems are inde-pendent identically distributed draws from thepopulation of all possible c-stems.
Since my algo-rithm identifies all possible initial substrings of avocabulary as c-stems, the c-stems are clearly nottruly independent?some c-stems are actually sub-strings of other c-stems.Nevertheless, natural language inflection classes,in the model of this paper, consist of c-suffixeswhich interchangeably attach to the same c-stems.Hence, given the assumption of c-suffixes as ran-dom variables, the true inflection classes of a lan-guage are most likely those groups of c-suffixeswhich are positively correlated.
That is, if know-ing that c-suffix F1 concatenates onto c-stem T in-creases the probability that the suffix F2 also con-catenates onto T, then F1 and F2 are likely from thesame inflection class.
On the other hand, if F1 andF2 are statistically independent, or knowing that F1concatenates to T does not change the probabilitythat F2 can attach to T, then it is likely that F1 or F2(or both) is a c-suffix that just randomly happens tobe able to concatenate onto a T.  And finally, if F1and F2 are negatively correlated, i.e.
they occurinterchangeably on the same c-stem less frequentlythan random chance, then it may be that F1 and F2come from different inflection classes within thesame paradigm or are even associated with com-pletely separate paradigms.There are a number of statistical tests designedto assess the probability that two discrete randomvariables are independent.
Here I will look at the ?2independence test, which computes the probabilitythat two random variables are independent by cal-culating a statistic Q distributed as ?2 by comparingthe expected distributions of the two random vari-ables, assuming their independence with their ac-tual distribution.
The larger the values of Q, thelower the probability that the random variables areindependent.Summing the results of each c-stem independenttrial of the c-suffix Boolean random variables, re-reos tt rayi e s?i n gi n gse a t i n g?
?m?i n gsst.ts.tingresretreat.tingresretrea?.ingrestretreatretryroam?.s.ingrestretreatroamFigure 3: A trie (top) with some repeated sub-tries circled.
These sub-tries are then conflatedinto the corresponding CIC lattice (bottom).sults in Bernoulli distributed random variableswhose joint distributions can be described as twoby two contingency tables.
Table 2 gives suchcontingency tables for the pairs of random variablec-suffixes (a, as) and (a, tro).
These tables can becalculated by examining specific CIC?s in the lat-tices.
To fill the contingency table for (a, as) Iproceed as follows: The number of times a occursjointly with as is exactly the adherent size of thea.as CIC, 199.
The marginal number of occur-rences of a, 1237, can be read from the CIC a, andsimilarly the marginal number of occurrences ofas, 404, can be read from the CIC as.
The bottomright-hand cell in the tables in Table 2 is the totalnumber of trials, or in this case, the number ofunique c-stems.
This quantity is easily calculatedby summing the adherent sizes of all level oneCIC?s together.
In the Spanish newswire corpusthere are 22950 unique c-stems.
The remainingcells in the contingency table can be calculated byassuring the rows and columns sum up to theirmarginals.
Using these numbers we can calculatethe Q statistic: Q(a, as) = 1552 and Q(a, tro) =1.587.
These values suggest that a and as are notindependent while a and tro are.5  Future WorkThere is clearly considerable work left to dowithin the CIC framework presented in this paper.I intend to implement the search strategies outlinedin this paper.
I also plan to apply these techniquesto describe the morphologies of a variety of lan-guages beyond English and Spanish.AcknowledgementsThe research presented in this paper was fundedin part by NSF grant number IIS-0121631.ReferencesAndrew Carstairs-McCarthy.
1998.
?ParadigmaticStructure: Inflectional Paradigms and Morpho-logical Classes.?
The Handbook of Morphology.Eds.
Andrew Spencer and Arnold M. Zwicky.Blackwell Publishers Inc., Massachusetts, USA,322-334.
?ric Gaussier.
1999.
Unsupervised learning ofderivational morphology from inflectional lexi-cons.
In Proceedings of ACL ?99 Workshop: Un-supervised Learning in Natural Language Proc-essing.John Goldsmith.
2001.
Unsupervised learning ofthe morphology of a natural language.
Computa-tional Linguistics, 27(2): 153-198.Margaret A. Hafer and Stephen F. Weiss.
1974.Word segmentation by letter successor varieties.Information Storage and Retrieval, 10:371-385.Zellig Harris.
1955.
From phoneme to morpheme.Language, 31:190-222.
Reprinted in Harris1970.Zellig Harris.
1967.
Morpheme boundaries withinwords: Report on a computer test.
Transforma-tion and Discourse Analysis Papers 73, Depart-ment of Linguistics, University of Pennsylvania.Reprinted in Harris 1970.Zellig Harris.
1970.
Papers in Structural andTransformational Linguistics.
D. Reidel,Dordrecht, Holland.Christian Monson, Alon Lavie, Jaime Carbonell,and Lori Levin.
2004.
Unsupervised Induction ofNatural Language Morphology InflectionClasses.
In Proceedings of the Seventh Meetingof the ACL Special Interest Group in Computa-tional Phonology (SIGPHON?04).Patrick Schone and Daniel Jurafsky.
2000.
Knowl-edge-free Induction of Morphology Using LatentSemantic Analysis.
In Proceedings of the FourthConference on Computational Natural LanguageLearning and of the Second Learning Languagein Logic Workshop, 67-72.Patrick Schone and Daniel Jurafsky.
2001.
Knowl-edge-free Induction of Inflectional Morpholo-gies.
In Proceedings of the North AmericanChapter of the Association of ComputationalLinguistics.
183-191.David Yarowsky, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing multilingual text analysistools via robust projection across aligned cor-pora.
In Proceedings of the Human LanguageTechnology Conference, 161-168.Table 2: Contingency tables for a few c-suffixesa ~a marginalas 199 205 404~as 1038 21508 22546marginal 1237 21713 22950a ~a marginaltro 2 14 16~tro 1235 21699 22934marginal 1237 21713 22950
