Proceedings of the ACL Workshop on Feature Engineering for Machine Learning in NLP, pages 1?8,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsA Novel Machine Learning Approach for the Identification ofNamed Entity RelationsTianfang Yao Hans UszkoreitDepartment of Computer Science andEngineeringDepartment of Computational Linguistics andPhoneticsShanghai Jiao Tong University Saarland UniversityShanghai, 200030, China Saarbruecken, 66041, Germanyyao-tf@cs.sjtu.edu.cn uszkoreit@coli.uni-sb.deAbstractIn this paper, a novel machine learningapproach for the identification of namedentity relations (NERs) called positiveand negative case-based learning(PNCBL) is proposed.
It pursues the im-provement of the identification perform-ance for NERs through simultaneouslylearning two opposite cases and auto-matically selecting effective multi-levellinguistic features for NERs and non-NERs.
This approach has been applied tothe identification of domain-specific andcross-sentence NERs for Chinese texts.The experimental results have shown thatthe overall average recall, precision, andF-measure for 14 NERs are 78.50%,63.92% and 70.46% respectively.
In addi-tion, the above F-measure has been en-hanced from 63.61% to 70.46% due toadoption of both positive and negativecases.1 IntroductionThe investigation for Chinese information extrac-tion is one of the topics of the project COLLATEdedicated to building up the German CompetenceCenter for Language Technology.
After accom-plishing the task concerning named entity (NE)identification, we go on studying identificationissues for named entity relations (NERs).
As aninitial step, we define 14 different NERs based onsix identified NEs in a sports domain based Chi-nese named entity recognition system (Yao et al,2003).
In order to learn NERs, we annotate theoutput texts from this system with XML.
Mean-while, the NER annotation is performed by an in-teractive mode.The goal of the learning is to capture valuableinformation from NER and non-NER patterns,which is implicated in different features and helpsus identify NERs and non-NERs.
Generally speak-ing, because not all features we predefine are im-portant for each NER or non-NER, we shoulddistinguish them by a reasonable measure mode.According to the selection criterion we propose -self-similarity, which is a quantitative measure forthe concentrative degree of the same kind of NERsor non-NERs in the corresponding pattern library,the effective feature sets - general-character feature(GCF) sets for NERs and individual-character fea-ture (ICF) sets for non-NERs are built.
Moreover,the GCF and ICF feature weights serve as a proportion determination of the features?
degree ofimportance for identifying NERs against non-NERs.
Subsequently, identification thresholds canalso be determined.In the NER identification, we may be confrontedwith the problem that an NER candidate in a newcase matches more than one positive case, or bothpositive and negative cases.
In such situations, wehave to employ a vote to decide which existing1case environment is more similar to the new case.In addition, a number of special circumstancesshould be also considered, such as relation conflictand relation omission.2 Definition of RelationsAn NER may be a modifying / modified, dominat-ing / dominated, combination, collocation or evencross-sentence constituent relationship betweenNEs.
Considering the distribution of differentkinds of NERs, we define 14 different NERs basedon six identified NEs in the sports domain shownin Table 1.Table 1.
NER CategoryIn order to further indicate the positions of NEsin an NER, we define a general frame for theabove NERs and give the following example usingthis description:Definition 1 (General Frame of NERs):NamedEntityRelation (NamedEntity1, Paragraph-SentenceNamedEntityNo1; NamedEntity2, Para-graphSentenceNamedEntityNo2)Example 1:?????1??????????????
?The Guangdong Hongyuan Team defeated the GuangzhouTaiyangshen Team by 3: 0 in the guest field.In the sentence we observe that there exist twoNERs.
According to the general frame, the firstNER description is HT_VT( ?
?
?
?
?
?
(Guangzhou Taiyangshen Team), 1-1-2; ?????
(Guangdong Hongyuan Team), 1-1-1) and theother is WT_LT( ?
?
?
?
?
(Guangdong1 The underlining of Chinese words means that an NE consists of these words.Hongyuan Team), 1-1-1; ?????
(GuangzhouTaiyangshen Team), 1-1-2).In this example, two NERs represent dominating/ dominated and collocation relationships sepa-rately: namely, the first relation HT_VT gives thecollocation relationship for the NE ?GuangdongHongyuan Team?
and the noun ?guest field?.
Thisimplies that ?Guangdong Hongyuan Team?
is aguest team.
Adversely, ?Guangzhou TaiyangshenTeam?
is a host team; the second relation WT_LTindicates dominating / dominated relationship be-tween ?Guangdong Hongyuan Team?
and?Guangzhou Taiyangshen Team?
by the verb ?de-feat?.
Therefore, ?Guangdong Hongyuan Team?and ?Guangzhou Taiyangshen Team?
are the win-ning and losing team, respectively.NER Cate-gory ExplanationPS_TM The membership of a person in a sports team.PS_CP A person takes part in a sports competition.PS_CPC The origin location of a person.PS_ID A person and her / his position in a sports team or other occasions.HT_VT The home and visiting teams in a sports competition.WT_LT The winning and losing team name in a sports match.DT_DT The names of two teams which draw a match.TM_CP A team participates in a sports competition.TM_CPC It indicates where a sports team comes from.ID_TM The position of a person employed by a sports team.CP_DA The staged date for a sports competition.CP_TI The staged time for a sports competition.CP_LOC It gives the location where a sports match is held.LOC_ CPC The location ownership (LOC belongs to CPC).3 Positive and Negative Case-BasedLearningThe positive and negative case-based learning(PNCBL) belongs to supervised statistical learningmethods (Nilsson, 1996).
Actually, it is a variant ofmemory-based learning (Stanfill and Waltz, 1986;Daelemans, 1995; Daelemans et al, 2000).
Unlikememory-based learning, PNCBL does not simplystore cases in memory but transforms case formsinto NER and non-NER patterns.
Additionally, itstores not only positive cases, but also negativeones.
Here, it should be clarified that the negativecase we mean is a case in which two or more NEsdo not stand in any relationships with each other,i.e, they bear non-relationships which are also in-vestigated objects in which we are interested.During the learning, depending on the averagesimilarity of features and the self-similarity ofNERs (also non-NERs), the system automaticallyselects general or individual-character features(GCFs or ICFs) to construct a feature set.
It alsodetermines different feature weights and identifica-tion thresholds for different NERs or non-NERs.Thus, the learning results provide an identificationreferences for the forthcoming NER identification.3.1 Relation FeaturesRelation features, by which we can effectivelyidentify different NERs, are defined for capturingcritical information of the Chinese language.
Ac-cording to the features, we can define NER / non-2NER patterns.
The following essential factors mo-tivate our definition for relation features:?
The relation features should be selectedfrom multiple linguistic levels, i.e.,  mor-phology, grammar and semantics (Cardie,1996);?
They can help us to identify NERs usingpositive and negative case-based machinelearning as their information do not onlydeal with NERs but also with non-NERs;and?
They should embody the crucial informationof Chinese language processing (Dang et al,2002), such as word order, the context ofwords, and particles etc.There are a total of 13 relation features shownin Table 2, which are empirically defined accord-ing to the above motivations.
It should be ex-plained that in order to distinguish feature namesfrom element names of the NER / non-NER pat-terns, we add a capital letter ?F?
in the ending offeature names.
In addition, a sentence group inthe following definitions can contain one or mul-tiple sentences.
In other words, a sentence groupmust end with a stop, semicolon, colon, exclama-tion mark, or question mark.FeatureCategory ExplanationSGTF The type of a sentence group in which there exists a relation.NESPF The named entities of a relevant relation are located in the same sentence or different sentences.NEOF The order of the named entities of a relevant relation.NEVPFThe relative position between the verbs and the namedentities of a relevant relation.
The verbs of a relevantrelation mean that they occur in a sentence where therelation is embedded.NECFThe context of named entities.
The context only embod-ies a word or a character preceding or following thecurrent named entity.VSPF The verbs are located in the same sentence or different sentences in which there is a relevant relation.NEPPOFThe relative order between parts-of-speech of particlesand named entities.
The particles occur within thesentences where the relation is embedded.NEPF The parts-of-speech of the named entities of a relevant relation.NECPF The parts-of-speech of the context for the named enti-ties associated with a relation.SPF The sequence of parts-of-speech for all sentence con-stituents within a relation range.VVF The valence expression of verbs in the sentence(s) where there is a relation embedded.NECTF The concepts of the named entities of a relevant relation from HowNet (Dong and Dong, 2000).VCTF The concepts of the verbs of a relevant relation from HowNet.Table 2.
Feature CategoryIn 13 features, three features (NECF, NECPFand NEPF) belong to morphological features, threefeatures (NEOF, SPF and SGTF) are grammaticalfeatures, four features (NEPPOF, NESPF, NEVPFand VSPF) are associated with not only morphol-ogy but also grammar, and three features (NECTF,VCTF and VVF) are semantic features.Every feature describes one or more propertiesof a relation.
Through the feature similarity calcu-lation, the quantitative similarity for two relationscan be obtained, so that we can further determinewhether a candidate relation is a real relation.Therefore, the feature definition plays an importantrole for the relation identification.
For instance,NECF can capture the noun ??
(the guest field,it means that the guest team attends a competitionin the host team?s residence.)
and also determinethat the closest NE by this noun is ?????
(the Guangdong Hongyuan Team).
On the otherhand, NEOF can fix the sequence of two relation-related NEs.
Thus, another NE ??????
(theGuangzhou Taiyangshen Team) is determined.Therefore, these two features reflect the propertiesof the relation HT_VT.3.2 Relation and Non-Relation PatternsA relation pattern describes the relationships be-tween an NER and its features.
In other words, itdepicts the linguistic environment in which NERsexist.Definition 2 (Relation Pattern): A relation pat-tern (RP) is defined as a 14-tuple: RP = (NO, RE,SC, SGT, NE, NEC, VERB, PAR, NEP, NECP, SP,VV, NECT, VCT) where NO represents the num-ber of a RP; RE is a finite set of relation expres-sions; SC is a finite set for the words in thesentence group except for the words related tonamed entities; SGT is a sentence group type; NEis a finite set for named entities in the sentencegroup; NEC is a finite set that embodies the con-text of named entities; VERB is a finite set that in-cludes the sequence numbers of verbs andcorresponding verbs; NEP is a finite set of namedentities and their POS tags; NECP is a finite setwhich contains the POS tags of the context fornamed entities; SP is a finite set in which there arethe sequence numbers as well as correspondingPOS tags and named entity numbers in a sentencegroup; VV is a finite set comprehending the posi-3tion of verbs in a sentence and its valence con-straints from Lexical Sports Ontology which isdeveloped by us; NECT is a finite set that has theconcepts of named entities in a sentence group; andVCT is a finite set which gives the concepts ofverbs in a sentence group.Example 2:?????????????????????????????????????????????????????????????????????????????
?According to the news from Xinhua News Agency Beijing onMarch 26th: National Football Tournament (the First BLeague) today held five competitions of the second round,The Guangdong Hongyuan Team defeats the GuangzhouTaiyangshen Team by 3: 0 in the guest field, becoming theonly team to win both matches, and temporarily occupyingthe first place of the entire competition.Relation Pattern:NO = 34;RE = {(CP_DA, NE1-3, NE1-2), (CP_TI, NE1-3, NE1-4), ?,(WT_LT, NE2-1, NE2-2)}SC = {(1, ?, according_to, Empty, AccordingTo), (2, ???
, Xinhua/Xinhua_News_agency, Empty, institu-tion/news/ProperName/China), ?, (42, ?
, ., Empty,{punc})};SGT = multi-sentences;NE = {(NE1-1, 3, LN, {(1, ??
)}), (NE1-2, 4, Date, {(1, ?
),(2, ?
), (3, ??
), (4, ?
)}), ..., (NE2-2, 26, TN, {(1, ??
),(2, ???
), (3, ?
)})};NEC = {(NE1-1, ???,?
), (NE1-2, ?
?, ?
), ..., (NE2-2,?
?, ?)
};VERB = {(8, ??
), (25, ??
), ..., (39, ?
)}PAR = {(1, ?
), (9, ?
), ..., (38, ?
)};NEP = {(NE1-1, {(1, N5)}), (NE1-2, {(1, M), (2, N), (3, M),(4, N)}), ..., (NE2-2, {(1, N5), (2, N), (3, N)})};NECP = {(NE1-1, N, M), (NE1-2, N5, N), ?, (NE2-2, V,W)};SP = {(1, P), (2, N), (3, NE1-1), ..., (42, W)};VV = {(V_8, {Agent|fact/compete|CT, -Time|time|DT}),(V_25, {Agent|human/mass|TN, Patient|human/mass|TN}),...,(V_39, {Agent|human/sport|PN, Agent|human/mass|TN})};NECT = {(NE1-1, place/capital/ProperName/China), (NE1-2,Empty+celestial/unit/time+Empty+ celestial/time/time/morning), ?, (NE2-2, place/city/ProperName/China+Empty+community/human/mass)};VCT = {(V_8, GoForward/GoOn/Vgoingon), (V_25, de-feat), ?, (V_39, reside/situated)}Analogous to the definition of the relation pat-tern, a non-relation pattern is defined as follows:Definition 3 (Non-Relation Pattern): A non-relation pattern (NRP) is also defined as a 14-tuple:NRP = (NO, NRE, SC, SGT, NE, NEC, VERB,PAR, NEP, NECP, SP, VV, NECT, VCT), whereNRE is a finite set of non-relation expressionswhich specify the nonexistent relations in a sen-tence group.
The definitions of the other elementsare the same as the ones in the relation pattern.
Forexample, if we build an NRP for the above sen-tence group in Example 2, the NRE is listed in thefollowing:NRE = {(CP_LOC, NE1-3, NE1-1), (TM_CPC, NE2-1,NE1-1), ..., (DT_DT, NE2-1, NE2-2)}In this sentence group, the named entity (CT) ????????
(National Football Tournament(the First B League)) does not bear the relationCP_LOC to the named entity (LN) ??
(Beijing).This LN only indicates the release location of thenews from Xinhua News Agency.As supporting means, the non-NER patterns alsoplay an important role, because in the NER patternlibrary we collect sentence groups in which theNER exists.
If a sentence group only includes non-NERs, obviously, it is excluded from the NER pat-tern library.
Thus the impact of positive cases can-not replace the impact of negative cases.
With thehelp of non-NER patterns, we can remove misiden-tified non-NERs and enhance the precision of NERidentification.3.3 Similarity CalculationIn the learning, the similarity calculation is a ker-nel measure for feature selection.Definition 4 (Self-Similarity): The self-similarityof a kind of NERs or non-NERs in the correspond-ing library can be used to measure the concentra-tive degree of this kind of relations or non-relations.The value of the self-similarity is between 0 and 1.If the self-similarity value of a kind of relation ornon-relation is close to 1, we can say that the con-centrative degree of this kind of relation or non-relation is very ?tight?.
Conversely, the concentra-tive degree of that is very ?loose?.The calculation of the self-similarity for thesame kind of NERs is equal to the calculation forthe average similarity of the corresponding relationfeatures.
Suppose R(i) is a defined NER in theNER set (1 ?
i ?
14).
The average similarity forthis kind of NERs is defined as follows:?
Sim (R(i)j, R(i)k)1?
j, k ?
m; j ?
kSimaverage(R(i)) =  ???????????
(1)Sumrelation_pair(R(i)j, R(i)k)where Sim (R(i)j, R(i)k) denotes the relation simi-larity between the same kind of relations, R(i)j and4R(i)k. 1 ?
j, k ?
m, j ?
k; m is the total number ofthe relation R(i) in the NER pattern library.
Thecalculation of Sim(R(i)j, R(i)k) depends on differ-ent features.
Sumrelation_pair(R(i)j, R(i)k) is the sum ofcalculated relation pair number.
They can be calcu-lated using the following formulas:Sumf?
Sim (R(i)j, R(i)k) (ft)t = 1Sim (R(i)j, R(i)k ) =  ???????????
(2)                                                            Sim                                   f(s)                                           Sumf1               m = 2Sumrelation_pair(R(i)j, R(i)k)  =              m !
(3)?????
m > 2                                         where R(i) is a defined relation in the NER set (1 ?i ?
14); n is the size of selected features, 1 ?
s, t ?
n;and(m-2) !
* 2 !In the formula (2), ft is a feature in the featureset (1 ?
t ?
13).
Sumf is the total number of fea-tures.
The calculation formulas of Sim (R(i)j, R(i)k)(ft) depend on different features.
For example, if ftis equal to NECF, Sim (R(i)j, R(i)k) (ft) is shown asfollows:1  if all contexts of namedentities for two relationsare the same0.75 if only a  preceding orfollowing context is notthe sameSim (R(i)Sim (X(i)j, X(i)k) (NECF)  =       0.5      if two preceding and / orfollowing contexts arenot the same0.25     if three preceding and / orfollowing contexts arenot the same0       if all contexts of namedentities for two relationsare not the same(4)Notice that the similarity calculation for non-NERs is the same as the above calculations.Before describing the learning algorithm, wewant to define some fundamental conceptions re-lated to the algorithm as follows:Definition 5 (General-Character Feature): If theaverage similarity value of a feature in a relation isgreater than or equal to the self-similarity of thisrelation, it is called a General-Character Feature(GCF).
This feature reflects a common characteris-tic of this kind of relation.Definition 6 (Individual-Character Feature): AnIndividual-Character Feature (ICF) means its aver-age similarity value in a relation is less than orequal to the self-similarity of this relation.
Thisfeature depicts an individual property of this kindof relation.Definition 7 (Feature Weight): The weight of aselected feature (GCF or ICF) denotes the impor-tant degree of the feature in GCF or ICF set.
It isused for the similarity calculation of relations ornon-relations during relation identification.averagef(s)(R(i))w(R(i)) = ?????????
(5)n?
Simaveragef(t)(R(i))t = 1?
Sim (R(i)j, R(i)k) (f(s))1?
j, k ?
m; j ?
kSimaveragef(s)(R(i)) =  ???????????
(6)Sumrelation_pair(R(i)j, R(i)k)j, R(i)k) (f(s)) computes the feature simi-larity of  the feature f(s) between same kinds ofrelations, R(i)j and R(i)k. 1 ?
j, k ?
m, j ?
k; m isthe total number of the relation R(i) in the NERpattern library.
Sumrelation_pair(R(i)j, R(i)k) is the sumof calculated relation pair numbers, which can becalculated by the formula (3).Definition 8 (Identification Threshold): If a can-didate relation is regarded as a relation in the rela-tion pattern library, the identification threshold ofthis relation indicates the minimal similarity valuebetween them.
It is calculated by the average of thesum of average similarity values for selected fea-tures:n?
Simaveragef(t)(R(i))t  = 1IdenThrh(R(i)) =  ????????
(7)nwhere n is the size of selected features, 1 ?
t ?
n.Finally, the PNCBL algorithm is described asfollows:1) Input annotated texts;2) Transform XML format of texts into internaldata format;3) Build NER and non-NER patterns;4) Store both types of patterns in hash tablesand construct indexes for them;55) Compute the average similarity for featuresand self-similarity for NERs and non-NERs;6) Select GCFs and ICFs for NERs and non-NERs respectively;7) Calculate weights for selected features;8) Decide identification thresholds for everyNER and non-NER;9) Store the above learning results.4 Relation IdentificationOur approach to NER identification is based onPNCBL, it can utilize the outcome of learning forfurther identifying NERs and removing non-NERs.4.1 Optimal Identification TradeoffDuring the NER identification, the GCFs of NERcandidates match those of all of the same kind ofNERs in the NER pattern library.
Likewise, theICFs of NER candidates compare to those of non-NERs in the non-NER pattern library.
The comput-ing formulas in this procedure are listed as follows:Sum(GCF)iSim (R(i)can, R(i)j1 ) =  ?
{ wi (GCFk1) * Sim (R(i)can, R(i)j1 ) (GCFk1) }k1 = 1and                                                                     (8)Sum(ICF)iSim (R(i)can, NR(i)j2 ) =  ?
{ wi (ICFk2) * Sim (R(i)can, NR(i)j2 ) (ICFk2) }k2 = 1(9)where R(i) represents the NERi, and NR(i) ex-presses the non-NERi, 1?
i ?
14.
R(i)can is definedas a NERi candidate.
R(i)j1 and NR(i)j2 are the j1-thNERi in the NER pattern library and the j2-th non-NERi in the non-NER pattern library.
1 ?
j1 ?
Sum(R(i)) and 1 ?
j2 ?
Sum (NR(i)).
Sum (R(i)) andSum (NR(i)) are the total number of R(i) in theNER pattern library and that of NR(i) in non-NERpattern library respectively.
wi (GCFk1) and wi(ICFk2) mean the weight of the k1-th GCF for theNERi and that of the k2-th ICF for the non-NERi.Sum (GCF)i and Sum (ICF)i are the total number ofGCF for NERi and that of ICF for non-NERi sepa-rately.In matching results, we find that sometimes thesimilarity values of a number of NERs or non-NERs matched with NER candidates are all morethan the identification threshold.
Thus, we have toutilize a voting method to achieve an identificationtradeoff in our approach.
For an optimal tradeoff,we consider the final identification performance intwo aspects: i.e., recall and precision.
In order toenhance recall, as many correct NERs should becaptured as possible; on the other hand, in order toincrease precision, misidentified non-NERs shouldbe removed as accurately as possible.The voting refers to the similarity calculationresults between an NER candidate and NER / non-NER patterns.
It pays special attention to circum-stances in which both results are very close.
If thishappens, it exploits multiple calculation results tomeasure and arrive at a final decision.
Additionally,notice that the impact of non-NER patterns is torestrict possible misidentified non-NERs.
On theother hand, the voting assigns different thresholdsto different NER candidates (e.g.
HT_VT, WT_LT,and DT_DT or other NERs).
Because the formerthree NERs have the same kind of NEs, the identi-fication for these NERs is more difficult than forothers.
Thus, when voting, the correspondingthreshold should be set more strictly.4.2 Resolving NER ConflictsIn fact, although the voting is able to use similaritycomputing results for yielding an optimal tradeoff,there still remain some problems to be resolved.The relation conflict is one of the problems, whichmeans that contradictory NERs occur in identifica-tion results.
For example:(i) The same kind of relations with different ar-gument position: e.g., the relations HT_VT,HT_VT(ne1, no1; ne2, no2) and HT_VT(ne2, no2; ne1, no1)occur in an identification result at the same time.
(ii)  The different kinds of relations with same ordifferent argument positions: e.g., the relationsWT_LT and DT_DT,WT_LT(ne1, no1; ne2, no2) and DT_DT(ne1, no1; ne2, no2)appear simultaneously in an identification result.The reason for a relation conflict lies in the si-multaneous and successful matching of a pair ofNER candidates whose NEs are the same kind.They do not compare and distinguish themselvesfurther.
Considering the impact of NER and non-NER patterns, we organize the conditions to re-move one of the relations, which has lower averagesimilarity value with NER patterns or higher aver-age similarity value with non-NER patterns.4.3 Inferring Missing NERs6Due to a variety of reasons, some relations thatshould appear in an identification result may bemissing.
However, we can utilize some of the iden-tified NERs to infer them.
Of course, the prerequi-site of the inference is that we suppose identifiedNERs are correct and non-contradictory.
For allidentified NERs, we should first examine whetherthey contain missing NERs.
After determining thetype of missing NERs, we may infer them - con-taining the relation name and its arguments.
Forinstance, in an identification result, two NERs are:PS_ID (ne1, no1; ne2, no2) and PS_TM (ne1, no1; ne3, no3)In the above NER expressions, ne1 is a personalname, ne2 is a personal identity, and ne3 is a teamname, because if a person occupies a position, i.e.,he / she has a corresponding identity in a sportsteam, that means the position or identity belongs tothis sports team.
Accordingly, we can infer the fol-lowing NER:ID_TM (ne2, no2; ne3, no3)5 Experimental Results and EvaluationThe main resources used for learning and identifi-cation are NER and non-NER patterns.
Beforelearning, the texts from the Jie Fang Daily2 in 2001were annotated based on the NE identification.During learning, both pattern libraries are estab-lished in terms of the annotated texts and LexicalSports Ontology.
They have 142 (534 NERs) and98 (572 non-NERs) sentence groups, respectively.To test the performance of our approach, werandomly choose 32 sentence groups from the JieFang Daily in 2002, which embody 117 differentNER candidates.For evaluating the effects of negative cases, wemade two experiments.
Table 3 shows the averageand total average recall, precision, and F-measurefor the identification of 14 NERs only by positivecase-based learning.
Table 4 demonstrates those byPNCBL.
Comparing the experimental results,among 14 NERs, the F-measure values of theseven NERs (PS_ID, ID_TM, CP_TI, WT_LT,PS_CP, CP_DA, and DT_DT) in Table 4 arehigher than those of corresponding NERs in Table3; the F-measure values of three NERs (LOC_CPC,TM_CP, and PS_CP) have no variation; but the F-measure values of other four NERs (PS_TM,2 This is a local newspaper in Shanghai, China.CP_LOC, TM_CPC, and HT_VT) in Table 4 arelower than those of corresponding NERs in Table 3.This shows the performances for half of NERs areimproved due to the adoption of both positive andnegative cases.
Moreover, the total average F-measure is enhanced from 63.61% to 70.46% as awhole.RelationTypeAverageRecallAveragePrecisionAverageF-measureLOC_CPC 100 91.67 95.65TM_CP 100 87.50 93.33PS_ID 100 84.62 91.67PS_TM 100 72.73 84.21CP_LOC 88.89 69.70 78.13ID_TM 90.91 66.67 76.93CP_TI 83.33 71.43 76.92PS_CP 60 75 66.67TM_CPC 100 42.50 59.65HT_VT 71.43 38.46 50WT_LT 80 30.77 44.45PS_CPC 33.33 66.67 44.44CP_DA 0 0 0DT_DT 0 0 0Total Ave. 71.99 56.98 63.61Table 3:  Identification Performance for 14 NERsonly by Positive Case-Based LearningRelationTypeAverageRecallAveragePrecisionAverageF-measureLOC_CPC 100 91.67 95.65TM_CP 100 87.50 93.33CP_TI 100 75 85.71PS_CPC 100 68.75 81.48ID_TM 90.91 68.19 77.93PS_ID 72.22 81.67 76.65CP_LOC 88.89 66.67 76.19PS_TM 80 65 71.72CP_DA 100 50 66.67DT_DT 66.67 66.67 66.67PS_CP 60 75 66.67WT_LT 60 37.50 46.15HT_VT 42.86 30 35.30TM_CPC 37.50 31.25 34.09Total Ave. 78.50 63.92 70.46Table 4:  Identification Performancefor 14 NERs by PNCBLFinally, we have to acknowledge that it is diffi-cult to compare the performance of our method toothers because the experimental conditions andcorpus domains of other NER identification effortsare quite different from ours.
Nevertheless, wewould like to use the performance of Chinese NERidentification using memory-based learning (MBL)(Zhang and Zhou, 2000) for a comparison with ourapproach in Table 5.
In the table, we select similarNERs in our domain to correspond to the threetypes of the relations (employee-of, product-of, andlocation-of).
From the table we can deduce that the7identification performance of relations for PNCBLis roughly comparable to that of the MBL.Method Relation Type Recall Precision F-measureemployee-of 75.60 92.30 83.12product-of 56.20 87.10 68.32 MBL&Ilocation-of 67.20 75.60 71.15PS_TMPS_CPPS_ID806072.22657581.6771.7266.6776.65ID_TMTM_CP90.9110068.1987.5077.9393.33 PNCBL&ICP_LOCPS_CPCTM_CPC88.8910037.5066.6768.7531.2576.1981.4834.09Table 5:  Performances for Relation Identification(PNCBL&I vs. MBL&I)6 ConclusionIn this paper, we propose a novel machine learningand identification approach PNCBL&I.
This ap-proach exhibits the following advantages: (i) Thedefined negative cases are used to improve theNER identification performance as compared toonly using positive cases;  (ii) All of the tasks,building of NER and non-NER patterns, featureselection, feature weighting and identificationthreshold determination, are automatically com-pleted.
It is able to adapt the variation of NER andnon-NER pattern library; (iii) The informationprovided by the relation features deals with multi-ple linguistic levels, depicts both NER and non-NER patterns, as well as satisfies the requirementof Chinese language processing; (iv) Self-similarity is a reasonable measure for the concen-trative degree of the same kind of NERs or non-NERs, which can be used to select general-character and individual-character features forNERs and non-NERs respectively; (v) The strate-gies used for achieving an optimal NER identifica-tion tradeoff, resolving NER conflicts, andinferring missing NERs can further improve theperformance for NER identification; (vi) It can beapplied to sentence groups containing multiple sen-tences.
Thus identified NERs are allowed to crosssentences boundaries.The experimental results have shown that themethod is appropriate and effective for improvingthe identification performance of NERs in Chinese.AcknowledgementThis work is a part of the COLLATE projectunder contract no.
01INA01B, which is supportedby the German Ministry for Education and Re-search.ReferencesC.
Cardie.
1996.
Automating Feature Set Selection forCase-Based Learning of Linguistic Knowledge.
InProc.
of the Conference on Empirical Methods inNatural Language Processing.
University of Pennsyl-vania, Philadelphia, USA.W.
Daelemans.
1995.
Memory-based lexical acquisitionand processing.
In P. Steffens, editor, MachineTranslations and the Lexicon, Lecture Notes in Arti-ficial Intelligence, pages 85-98.
Springer Verlag.Berlin, Germany.W.
Daelemans, A. Bosch, J. Zavrel, K. Van der Sloot,and A. Vanden Bosch.
2000.
TiMBL: Tilburg Mem-ory Based Learner, Version 3.0, Reference Guide.Technical Report ILK-00-01, ILK, Tilburg Univer-sity.
Tilburg, The Netherlands.http://ilk.kub.nl/~ilk/papers/ilk0001.ps.gz.H.
Dang, C. Chia, M. Palmer and F. Chiou.
2002.
Sim-ple Features for Chinese Word Sence Disambigua-tion.
In Proc.
of the 19th International Conference onComputational Linguistics (COLING 2002), pages204-210.
Taipei, Taiwan.Z.
Dong and Q. Dong.
2000.
HowNet.http://www.keenage.com/zhiwang/e_zhiwang.html.N.
Nilsson.
1996.
Introduction to Machine Learning: AnEarly Draft of a Proposed Textbook.
Pages 175-188.http://robotics.stanford.edu/people/nilsson/mlbook.html.C.
Stanfill and D. Waltz.
1986.
Toward memory-basedreasoning.
Communications of the ACM, Vol.29,No.12, pages 1213-1228.T.
Yao, W. Ding and G. Erbach.
2003.
CHINERS: AChinese Named Entity Recognition System for theSports Domain.
In: Proc.
of the Second SIGHANWorkshop on Chinese Language Processing (ACL2003 Workshop), pages 55-62.
Sapporo, Japan.Y.
Zhang and J. Zhou.
2000.
A trainable method forextracting Chinese entity names and their relations.In Proc.
of the Second Chinese Language ProcessingWorkshop (ACL 2000 Workshop), pages 66-72.Hongkong, China.8
