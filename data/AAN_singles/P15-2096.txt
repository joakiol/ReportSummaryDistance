Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 583?587,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsAutomatic Identification of Age-Appropriate Ratings of Song LyricsAnggi Maulidyani and Ruli ManurungFaculty of Computer Science, Universitas IndonesiaDepok 16424, West Java, Indonesiaanggi.maulidyani@ui.ac.id, maruli@cs.ui.ac.idAbstractThis paper presents a novel task, namelythe automatic identification of age-appropriate ratings of a musical track, oralbum, based on its lyrics.
Details areprovided regarding the construction of adataset of lyrics from 12,242 tracks across1,798 albums along with age-appropriateratings obtained from various web re-sources, along with results from varioustext classification experiments.
The bestaccuracy of 71.02% for classifying albumsby age groups is achieved by combiningvector space model and psycholinguisticfeatures.1 IntroductionMedia age-appropriateness can be defined as thesuitability of the consumption of a media item,e.g.
a song, book, film, videogame, etc., by achild of a given age based on norms that are gen-erally agreed upon within a society.
Such normsmay include behavioral, sociological, psycholog-ical, and other factors.
Whilst we acknowledgethat this is largely a subjective judgment, and thatthere may be wide variance between very smallcircles that could be considered demographicallyhomogenous, nevertheless, parents, educators, andpolicymakers may find such judgments valuable inthe process of guiding and supervising the mediaconsumption of children.This topic is closely related to well-known con-tent rating schemes such as the MPAA film ratingsystem1, but whereas such schemes are focusedmore on whether a film contains adult material ornot, age-appropriatness can be thought of as beingmore nuanced, and takes into consideration morefactors such as educational value.1http://www.mpaa.org/film-ratingsOne popular resource for such ratings is Com-mon Sense Media2, a website that provides re-views for various media, with a focus on age ap-propriateness and learning potential for children.Whilst acknowledging that such ratings are ofinterest to many people, the position of this re-search is neutral towards the efficacy and utilityof such ratings: we only seek to ask the questionof whether it is possible to automate the identifi-cation of these age-appropriateness ratings.This work focuses on song lyrics.
There aremany aspects that can contribute to the age-appropriateness of a song, but we believe that byfar the most dominant factor is its lyrics.
Thus, theapproach that is taken to automating the identifi-cation of age-appropriatness ratings is to treat it asa supervised text classification task: first, a corpusof song lyrics along with age-appropriateness rat-ings is constructed, and subsequently this corpusis used to train a model based on various textualfeatures.To give the reader an idea of this task, Fig-ures 1 to 3 show a sampler of snippets of lyrics3from songs along with their age-appropriate rat-ings according to Common Sense Media.
Ourgoal is to be able to automatically predict the age-appropriate rating given the lyrics of a song in suchcases.Oh, I?m Sammy the snakeAnd I look like the letter ?S?ssss.Oh, yes.I?m all wiggly and curvy,And I look like the letter ?S?ssss.I confess.
(age-appropriate rating: 2)Figure 1: Snippet of ?Sammy the Snake?, fromSesame Street Halloween Collection2http://www.commonsensemedia.org3All works are copyrighted to their respective owners.583Do you want to build a snowman?Come on, let?s go and playI never see you anymoreCome out the doorIt?s like you?ve gone away(age-appropriate rating: 5)Figure 2: Snippet of ?Do you want to build asnowman?
?, from Frozen Original Motion PictureSoundtrackYou can take everything I haveYou can break everything I amLike I?m made of glassLike I?m made of paperGo on and try to tear me downI will be rising from the groundLike a skyscraperLike a skyscraper(age-appropriate rating: 9)Figure 3: Snippet of ?Skyscraper?, from Unbro-ken - Demi LovatoIn Section 2 we discuss related work, beforepresenting our work on constructing the corpus(Section 3) and carrying out text classification ex-periments (Section 4).
Finally, we present a tenta-tive summary in Section 5.2 Related WorkTo our knowledge, there is no previous workthat has attempted what is described in this pa-per.
There is some thematically related work,such as automatic filtering of pornographic con-tent (Polpinij et al., 2006; Sood et al., 2012; Xianget al., 2012; Su et al., 2004), but we believe the na-ture of the task is significantly different such thata different approach is required.However, text or document classification, thegeneral technique employed in this paper, is a verycommon task (Manning et al., 2008).
In text clas-sification, given a document d, the task is to assignit a class, or label, c, from a fixed, human-definedset of possible classes C = {c1, c2, .
.
.
, cn}.
In or-der to achieve this, a training set of labelled doc-uments ?d, c?
is given to a learning algorithm tolearn a classifier that maps documents to classes.Documents are typically represented as a vec-tor in a high-dimensional space, such as term-document matrices, or results of dimensional-ity reduction techniques such as Latent SemanticAnalysis (Landauer et al., 1998), or more recently,using vector representations of words produced byneural networks (Pennington et al., 2014).Text classification has many applications,among others spam filtering (Androutsopoulos etal., 2000) and sentiment analysis (Pang and Lee,2008).One particular application that could be deemedof relevance with respect to our work is that ofreadability assessment (Pitler and Nenkova, 2008;Feng et al., 2010), i.e.
determining the ease withwhich a written text can be understood by a reader,since age is certainly a dimension along whichreadability varies.
However, our literature re-view of this area suggested that the aspects be-ing considered in readability assessment are suf-ficiently different from the dimensions that seemto be most relevant for media age appropriatnessratings.
Following Manurung et al.
(2008), we hy-pothesize that utilizing resources such as the MRCPsycholinguistic Database (Coltheart, 1981) couldbe valuable in determining age appropriateness, inparticular various features such as familiarity, im-ageability, age-of-acquisition, and concreteness.3 Corpus ConstructionThere are three steps in obtaining the data requiredfor our corpus: obtaining album details and age-appropriateness ratings, searching for the track-listing of each album, and obtaining the lyrics foreach song.
Each step is carried out by querying adifferent website.
To achieve this, a Java applica-tion that utilizes the jsoup library4was developed.3.1 Obtaining album details andage-appropriateness ratingsThe Common Sense Media website provides re-views for various music albums.
The reviews con-sist of a textual review, the age-appropriate ratingfor the album, which consists of an integer in theinterval [2,17] or the label ?Not For Kids?, andmetadata about the album such as title, artist, andgenre.
Aside from that, there are also other an-notations such as a quality rating (1-5 stars), andspecific aspectual ratings such as positive mes-sages, role models, violence, sex, language, con-sumerism, drinking, drugs & smoking.
The web-site also allows visitors to contribute user ratingsand reviews.
In our experiments we only utilize4http://www.jsoup.org584the album metadata and integer indicating the age-appropriate rating.3.2 Tracklist searchingA tracklist is a list of all the songs, or tracks, con-tained within an album.
From the information pre-viously obtained from Common Sense Media, thenext step is to obtain the tracklist of each album.For this we query the MusicBrainz website5, anopen music encyclopedia that makes music meta-data available to the public.
To obtain the tracklistswe employed the advanced query search mode thatallows the use of boolean operators.
We tried sev-eral combinations of queries involving album ti-tle, singer, and label information, and it turned outthat queries consisting of album title and singerproduced the highest recall.
When MusicBrainzreturns multiple results for a given query, we sim-ply select the first result.
For special cases wherethe tracks on an album are performed by vari-ous artists, e.g.
a compilation album, or a sound-track album, it is during this stage that we also ex-tract information regarding the track-specific artistname.
Finally, we assume that if the album titlecontains the string ?CD Single?
then it only con-tains one track and we skip forward to the nextstep.3.3 Lyrics searchingFor this step, we consulted two websites as thesource reference for song lyrics, songlyrics.comand lyricsmode.com.
The former is first consulted,and only if it fails to yield any results is the latterconsulted.
If a track is not found on both websites,we discard it from our data set.
Similar to the pre-vious step, we perform a query to obtain results,however during this step the query consists of thesong title and singer.
Once again, given multipleresults we simply choose the first result.
In to-tal, we were able to retrieve lyrics from 12,242songs across 1,798 albums.
Table 1 provides anoverview of the number of tracks and albums ob-tained per age rating.4 ExperimentationSince the constructed data set is imbalanced, weuse the SMOTE oversampling technique to over-come this problem (Chawla et al., 2002).
This re-sults in a balanced dataset with the same numberof samples in each class.5http://www.musicbrainz.orgGroup Age #Tracks #AlbumsToddler2 696 1193 130 23Pre-schooler4 251 465 204 31Middle childhood 16 281 417 358 718 654 118Middle childhood 29 237 5010 1,590 25311 580 105Young teen12 1,849 25313 1,767 24214 1,453 177Teenager15 653 11616 521 6417 180 16Adult >17 838 73Total 12,242 1,798Table 1: Statistics of the datasetOnce the dataset is complete, classifiers weretrained and used to carry out experiment scenariosthat vary along several factors.
For the class labels,two scenarios are considered: one where each agerating from 2 to 17 and ?Not For Kids?
is a sepa-rate class, and another where the data is clusteredtogether based on some conventional developmen-tal age groupings6, i.e.
toddlers (ages 2 & 3), pre-schoolers (ages 4 & 5), middle-childhood 1 (ages6 to 8), middle-childhood 2 (ages 9 to 11), young-teens (ages 12 to 14), and teenagers (ages 15 to17), with an additional category for ages beyond17 using the ?Not For Kids?
labelled data.For the instance data, two scenarios are alsoconsidered: one where classification is done on aper-track basis, and one on a per-album basis (i.e.where lyrics from all its constituent tracks are con-catenated).As for the feature representation, three primaryvariations are considered:Vector Space Model.
This is a baseline methodwhere each word appearing in the dataset becomesa feature, and a vector representing an instanceconsists of the tf.idf values of all words.
Addi-tionally, stemming is first performed on the words,and information gain-based attribute selection isapplied.MRC Psycholinguistic data.
For this feature6http://www.cdc.gov/ncbddd/childdevelopment/positiveparenting/585representation, given each distinct word appear-ing in the lyrics of a track (or album), a lookup isperformed on the MRC psycholinguistic database,and if appropriate values exist, they are added tothe tally for the familiarity, imageability, age-of-acquisition, and concreteness scores.
Thus, an in-stance is represented by a vector with four real val-ues.
The vectors are normalized with respect to thenumber of words contributing to the values.GloVe vectors.
GloVe7is a tool that producesvector representations of words trained on verylarge corpora (Pennington et al., 2014).
It is sim-ilar to dimensionality reduction approaches suchas latent semantic analysis.
For this experiment,the 50-dimensional pre-trained vectors trained onWikipedia and Gigaword corpora were used.When combining feature representations, wesimply concatenate their vectors.Finally, for the classification itself, the Wekatoolkit is used.
Given the ordinal nature of theclass labels, classification is carried out via regres-sion (Frank et al., 1998), using the M5P-basedclassifier (Wang and Witten, 1997).
The experi-ments were run using 4-fold cross validation.For the initial experiment, only the baselineVSM feature representation was used, and thetreatment of class labels and instance granularitywas varied.
The results can be seen in Table 2,which shows the average accuracy, i.e.
the per-centage of test instances that were correctly la-belled, across 4 folds.Age group YearPer-track 69.77% 58.58%Per-album 70.60% 57.15%Table 2: Initial experiment varying class and in-stance granularityFor the follow-up experiment, we focus on thetask of classifying at the per-album level of gran-ularity, as ultimately this is the level at whichthe original annotations are obtained.
For theclass labels, both age groups and separate ages areused.
The feature representation was varied rang-ing from VSM, VSM + MRC, VSM + GloVe, andVSM + GloVe + MRC.
The results can be seen inTable 3.7http://nlp.stanford.edu/projects/glove/Features Age group YearVSM 70.60% 57.15%VSM + MRC 71.02% 56.80%VSM + GloVe 70.58% 57.68%VSM + GloVe + MRC 70.47% 57.85%Table 3: Results varying feature representations5 Discussion & SummaryFrom the initial experiment, it appears that distin-guishing tracks at the level of granularity of spe-cific year/age (e.g.
?is this song more appropriatefor a 4 or 5 year old??)
is very difficult, as indi-cated by an accuracy of only 57% to 58%.
Bear inmind, however, that this is a seventeen-way clas-sification task.
Shifting the level of granularity tothat of age groups transforms the task into a morefeasible one, with an accuracy around the 70%mark.
It is surprising to note that the per-trackperformance is better than the per-album perfor-mance when tracks are distinguished by specificage/year rather than age groups.
We had initiallyhypothesized that classifying albums would be amore consistent task given the increased contextand evidence available.As for the various feature representations, wenote that the addition of the MRC psycholinguis-tic features of familiarity, imageability, concrete-ness, and age-of-acquisition does provide a smallaccuracy increase in certain cases, as evidenced bythe highest accuracy of 71.02% when classifyingalbums by age group using the VSM + MRC fea-tures.
The use of the GloVe vectors gives a slightcontribution in the case of classifying albums byspecific age/year, where the highest accuracy of57.85% is obtained when combining VSM withboth the MRC and GloVe features.There are many other features and contexts thatcan also be utilized.
For instance, given the meta-data of artist, album, and genre, additional infor-mation may be extracted from the web, e.g.
theartist?s biography, general-purpose album reviews,genre tendencies, etc., all of which may contributeto discerning age-appropriateness.
Another set offeatures that can be utilized are readability met-rics, as they are often correlated with the age ofthe reader.To summarize, this paper has introduced a noveltask with clear practical applications in the form ofautomatically identifying age-appropriate ratingsof songs and albums based on lyrics.
The work586reported is still in its very early stages, neverthe-less we believe the findings are of interest to NLPresearchers.Another question that needs to be addressedis what sort of competence and agreement hu-mans achieve on this task.
To that end, we planto conduct a manual annotation experiment in-volving several human subjects, themselves variedacross different age groups, and to measure inter-annotator reliability (Passonneau et al., 2006).ReferencesIon Androutsopoulos, John Koutsias, KonstantinosChandrinos, Georgios Paliouras, and Constantine D.Spyropoulos.
2000.
An evaluation of na?
?veBayesian anti-spam filtering.
In Proceedings of theworkshop on Machine Learning in the New Infor-mation Age, 11th European Conference on MachineLearning, pages 9?17, Barcelona, Spain.Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O.Hall, and W. Philip Kegelmeyer.
2002.
Smote: Syn-thetic minority over-sampling technique.
J. Artif.Int.
Res., 16(1):321?357, June.Max Coltheart.
1981.
The MRC psycholinguisticdatabase.
The Quarterly Journal of ExperimentalPsychology, 33(4):497?505.Lijun Feng, Martin Jansche, Matt Huenerfauth, andNo?emie Elhadad.
2010.
A comparison of featuresfor automatic readability assessment.
In Proceed-ings of the 23rd International Conference on Com-putational Linguistics: Posters, COLING ?10, pages276?284, Stroudsburg, PA, USA.
Association forComputational Linguistics.E.
Frank, Y. Wang, S. Inglis, G. Holmes, and I.H.
Wit-ten.
1998.
Using model trees for classification.
Ma-chine Learning, 32(1):63?76.Thomas Landauer, Peter Foltz, and Darrell Laham.1998.
An introduction to latent semantic analysis.Discourse Processes, 25:259?284.Christopher Manning, Prabhakar Raghavan, and Hin-rich Schutze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press.Ruli Manurung, Graeme Ritchie, Helen Pain, An-nalu Waller, Dave O?Mara, and Rolf Black.
2008.The construction of a pun generator for languageskills development.
Applied Artificial Intelligence,22(9):841?869.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and trends in infor-mation retrieval, 2(1-2):1?135.Rebecca Passonneau, Nizar Habash, and Owen Ram-bow.
2006.
Inter-annotator agreement on a multi-lingual semantic annotation task.
In Proceedings ofthe Fifth International Conference on Language Re-sources and Evaluation (LREC 2006), Genoa, Italy,May.Jeffrey Pennington, Richard Socher, and ChristopherManning.
2014.
GloVe: Global vectors for wordrepresentation.
In Proceedings of the 2014 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 1532?1543.
Associa-tion for Computational Linguistics.Emily Pitler and Ani Nenkova.
2008.
Revisitingreadability: A unified framework for predictingtext quality.
In Proceedings of the Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?08, pages 186?195, Stroudsburg, PA,USA.
Association for Computational Linguistics.J.
Polpinij, A. Chotthanom, C. Sibunruang, R. Cham-chong, and S. Puangpronpitag.
2006.
Content-based text classifiers for pornographic web filtering.In Systems, Man and Cybernetics, 2006.
SMC ?06.IEEE International Conference on, volume 2, pages1481?1485, Oct.Sara Owsley Sood, Judd Antin, and Elizabeth FChurchill.
2012.
Using crowdsourcing to improveprofanity detection.
In AAAI Spring Symposium:Wisdom of the Crowd.Gui-yang Su, Jian-hua Li, Ying-hua Ma, and Sheng-hong Li.
2004.
Improving the precision ofthe keyword-matching pornographic text filteringmethod using a hybrid model.
Journal of ZhejiangUniversity Science, 5(9):1106?1113.Y.
Wang and I. H. Witten.
1997.
Induction of modeltrees for predicting continuous classes.
In Posterpapers of the 9th European Conference on MachineLearning.
Springer.Guang Xiang, Bin Fan, Ling Wang, Jason Hong, andCarolyn Rose.
2012.
Detecting offensive tweets viatopical feature discovery over a large scale twittercorpus.
In Proceedings of the 21st ACM Interna-tional Conference on Information and KnowledgeManagement, CIKM ?12, pages 1980?1984, NewYork, NY, USA.
ACM.587
