J apanese  Named Ent i ty  Ext rac t ion  Eva luat ion- Ana lys i s  o f  Resu l t s  -Satosh i  Sek ineComputer  Science Depar tmentNew York University715 Broadway, 7th floorNew York, NY 10003, USAsekine@cs, nyu.
eduYosh io  Er iguch iResearch and Development HeadquartersNTT  Data  Corporat ion1-21-2, Shinkawa, Chuo-ku,Tokyo, 104-0033, Japaner iguch i~rd ,  n t tdata ,  co. jpAbst ractWe will report on one of the two tasks in theIREX (Information Retrieval and ExtractionExercise) project, an ew~luation-based projectfbr Infbrmation Retriewfl and Intbrmation Ex-traction in Japanese (Sekine and Isahara, 2000)(IREX Committee, 1999).
The project stm'tedin 1998 and concluded in September 1999 withmany participants and collaborators (45 groupsin total from Japan and the US).
In this paper,the Nmned Entity (NE) task is reported.
It isa task to extract NE's, such as names of orga-nizations, persons, locations and artifacts, timeexpressions and numeric expressions from news-p~t)er articles.
First, we will explain the taskand the definition, as well as the data we cre-ated and the results.
Second, the analyses of theresults will be described, which include analysisof task diifieulty across the NE types and sys-tern types, amflysis of dolnain dependency andcomparison to hmnan per~brmance.1 I n t roduct ionThe need for II1 and IE technologies i gettinglarger because of the improvements ill computertechnology and the appearance of the Internet.Many researchers in the field feel that the ew~l-uation based projects in the USA, MUC (MUCHomepage, 1999) and TREC (TREC Home-page, 2000), have played a very important rolein each field.
In Japan, however, while there hasbeen good research, we have had some dilficul-ties comparing systems based on the same plat-form, since our researdt is conducted at manydifferent; Ulfiversities, companies, and laborato-ries using different data and evaluation lnea-sures.
Our goal is to have a common platform inorder to evaluate systems with the stone stan-dard.
We believe such projects are nseflfl notonly for comparing system performance lint alsoto address the following issues:1) To share and exchange problems among re-searchers,2) To aeeulntll~,te large quantities of data,3) To let other people know the importanceand the quality of IR and IE techniques.Finishing the project, we believe we achievedthese goals.In this paper we will describe one of the twotasks in the IR.EX project, the Nmned Entitytask.2 IREX NE2.1 TaskNamed Entity extraction involves findingNamed Entities, such as names of organizations,persons, locations, and artifimts, time expres-sions, and numeric expressions, uch as moneyand percentage expressions.
It is one of the ha-sic techniques used in IR and IE.
At the ewfl-uation, participants were asked to identit\[y NEexpressions as correctly as possible.
In orderto avoid a copyright I)robleIn, we made a toolto convert a tagged text to a set of tag off'setinformation and wc only exchanged tag ott;etintbrlnation.2.2 Def in i t ionThe definition of NE's is given in an 18-pagedocument,  which is available through the II1EXhomepage (IREX Homepage, 1999).
Thereare 8 kinds of NE's shown in 'lhfl)le 1.
In or-der to avoid requiring a unique decision ~brambiguous cases where even a lnnnan couldnot tag unambiguously, we introduced a tag"OPTIONAL ''1.
If a system tags an expression1This tag is newly introduced in IREX and does notexist in MUC.
The tag accounts for 5.7% of all NE occur-1106NE Examl)leORGANIZATION The Diet, 1REX Commit;teePERSON Sekine, \?akanohanaLOCATION Japan, '\]bkyo, Mt.FujiARTIFACT Pentiuln II, Nobel PrizeDATE March 5, 1.965; YesterdayTIME 11 PM, nfidnightMONEY 100 yen, $12,345PERCENT 1.0%, a half~i~ble 1: NE Classeswithin the OPTIONAL tag, it; is just ignored forth.e scoring.
The defilfition was created 1)ased onthe MUC/MET definition; however, the processof lnaking the definition was not easy.
In par-ticulaI', the definition of the newly introducedNE tyl)e "artifact" was Colitroversial.
W'e ad-mit that more consideration is needed to makea clem'er definition of the NE typos.Comparing the NE task in Japanese to thatin English, one of the ditIiculties comes from thefact that there is no word delinfiter in Japanese.Sysl;elns have to identity the })oundaries of ex-pressions.
This will 1)ecome complicated whenwe want to tag a sul)string of what ix gener-ally considered a ,Japanes(~ wor(t, l/or (~xaml)le ,il.t .Jal)allese there is a word "Ratnich?"
whichmeans "Visil; 3apa.n" and consists of two Chi-nese eh.aracters, "Ra?"
(Visit;)and "Nichi" (ab-breviation of .Japan).
Although mmly word seg-reenters identif~y it as a single, word, we expectto extrtmt only "Nichi" as a local;ion.
'\]'his isa tricky prol)lem, as opposed to the ease in En-glish where a word is the unit of NE candidates.2+3 Runs  and  DataThere were three kinds of NE exercises, the dryrun, a restricted (hmlMn tbrmal rtm, and a gen-eral domain tbl'mal 1'1111, which will be explainedlater.
Also we created three kinds of training(h~ta: the dry run trailfing data, the CI{.L_NEdata and the formal run domain restricted trail>ing data.
Td)le 2 shows the size of each data set.Note that CRL_NE (lata l)elongs to the Colllnltt-nication ll.esearch Laboratory (CI{L), but it isronces ill the generM dolnaill evMuation and 2.1% in therestricted omain e, valuation (the t.ypes of the evaluationwill be explained later).ineht(ted ill the tat)le, because the data was cre-ated by IREX participants, using the definitionof II{EX-NE, +rod distributed through I\]{,EX.Data Number ofarticlesDry Run trainingDry t.hmCIIL_NE dataD)rlnal l'lln (restricted) trainingFormal run (restricted)Formal run (general)46361.174232071Table 2: Dnta size~n or(let to ensure the, fairness of the exercisein the formal \]'un~ we used newspaper articleswhich no one had ew~r seen.
We, set the date tofl'eeze the system development (April 13, 1999).The date for the evahtation was set one monthafter that (lat;e (May 13 to \]7, 1999) so thatwe could select the test m'ticles fl'om the 1)criedt)etween those dates.
\?e thank the MainichiNewspaper CorI)oration for provi(ling this datafor us t\]:ee of charge.2.4 Rest r i c ted  domainin the fbrmal run, in order to study systemportability and the effect of domains on NEperfoilllanc(',, we had two kinds of evaluation:rest;rioted omain and general domMn.
In thegeneral domain ewthtation, w(, selected articlesregardless of dolnain.
The domain of the re-stricted domain evaluation was a.lmouneed onemonth before the develolmmnt freeze date.
It;was an "arrest;" domain defined as follows and211 the articles in the restricted omain are se-lected based on the definition.77re articles arc 'related to an e'ucnt",,frost".
The event is defined as th, ca'r'rc.st of a .suspect o1' s'~t,5'pects by po-lice, National \])olicc, State police ofother police forces including the o'ncsof foreign countries.
It includes arti-cles mentionirtg an arrest event in thepast.
It: excludes articles which haveonly i'n:formation about requesting anarrest warrant, art accusation or send-ing the pape'rs pc'training to a case toan Attorney's OJJicc.11072.5 Resu l ts8 groups and 11 systems participated in thedry run, and 14 groups and 15 systems partici-pated in the %rmal run 2.
Tim evaluation resultswere made public anonymously using systelnID's.
Table 3 shows the ew~luation results (F-measure) of the formal run.
F-measure is cal-culated from recall and precision (IREX Coin-mittee, 1999).
It ranges from 0 to 100, and thelarger the betterSystem ID12011205121312141215122312241227122912311234124012471250a12501)general57.6980.0566.6070.3466.7472.1875.3077.3757.6374.8271.9660.9683.8669.8257.76restrict54.1778.0859.8780.3774.5674.9077.6185.0264.8181.9472.7758.4687.4370.1255.24diff.-3.52-1.97-6.73+10.03+7.82+2.72+2.31+7.65+7.18+7.12+0.81-2.50+3.57+0.30-2.52~li~ble 3: NE Formal run result3 Ana lyses  o f  the  resu l ts3.1 Diff iculty across NE  typeIn Table 4, tile F-measure of the best perform-ing system is shown in the "Best" column; theaverage F-measures are shown in the "Average"column tbr each NE type on the formal runs.
Itcan be observed that identifying time and nu-lneric expressions is relatively easy, as the av-erage F-measures are more than 80%.
In con-trast, the accuracy of the other types of NE isnot so good.
Ill particular, artifacts are quitedifficult to identify.
It is interesting to see thattagging artifacts in the general domain is mud1harder thins in the restricted domain.
This isbecause of the limited types of artifacts in therestricted domain.
Most of the artifacts in the2The participation to the dry run was not obligatory.This is why the number of participants is smaller in thedry run than that in the formal rmLrestricted omain are the names of laws, as thedoinain is the arrest domain.
Systems lnight beable to find such types of names easily becausethey could be recognized by a small number ofsimple patterns or by a short list.
The typesof tim artifacts in the general donmin are quitediverse, including names of prizes, novels, ships,or paintings.
It nfight be difficult to build pat-terns for these itelns, or systems may need verycomplicated rules or large dictionaries.3.2 Three types of  sys temsBased on the questionnaire for the particit)antswe gatlmred alter the formal runs, we found thatthere are three types of systems.?
Hand created pattern basedThese are pattern based systems where thepatterns are created by hand.
A typicalsystem used prefix, sutlqx and proper noundictionaries.
Patterns in these systems looklike "If proper nouns are followed by a suffixof person name (for example, a commonsuflqx like "San", which is ahnost equivalentto Mr. and Ms.) then the proper nouns area t)erson nmne".
This type of system wasvery common; there were 8 systems in thiscategory.?
Automatically created pattern basedThese are pattern based systems wheresome or all of the patterns are created an-tolnatically using a training corl)us.
Therewere three systems in this category, andthese systems used quite different meth-ods.
One of them used the "error drivenmethod", in which hand created patternswere applied to tagged training data andthe system learned from tlm mistakes.
An-other system learned patterns for a widerange of information, including, syntax,verb frame and discourse information fl'omtraining data.
The last system used thelocal context of training data and severalfilters were applied to get more accuratepatterns.Fully automaticSystems in this category created theirknowledge automatically from a trainingcorpus.
There were four systems in thiscategory.
These systems basicMly tried toassign one of the four tags, beginning, mid-dle or ending of an NE, or out-ofNE, to1108NE type 13estOrgmfization 78Person 87Location 8d:Artifact 44Date 90Time 82Money 86Percent 84Total 84General domainAverage Expert57 9668 9970 9826 9086 9883 9786 10086 9770 98Best75878883939710087Table 4: ResultsRestrict domainAverage Novice Expert556968588990918897947496981009810099921009810072 94 99each word or each character.
The sourceinformation for the training was typicallycharacter type, POS, dictionary in%rma-tion or lexical information.
As tile learn-ing meclmnism, Maximmn Entrot)y models,decision trees, and HMMs were used.It is interesting to see that tile top three sys-tems came, fi'om each category; the best sys-tem was a hand create, d pattern based system,tile second system was an automatically createdpattern based system and the third system wasa fully automatic system.
So we believe we cannot conclude which type is SUl)erior to the eth-el'S.Analyzing the results of the top three sys-to, ms, we observed the, importance of tile dic-tionaries.
The best hand created pattern basedsystem seems to have a wide coverage dictionaryfor person, organization and location namesand achieved very good accuracy tbr those cat-egories.
Howe.ver, the hand created patternbased system failed to capture the evahmtionspecific pattenls like "the middle of April".
Sys-tems wore required to extract the entire ex-1)ression as a date expression, but; the systemonly extracted "April".
The best hand createdrule based system, as well as the best ~mtolnat-ically created pattern lmsed system also missedother specific patterns which inchlde abbrevi-ations ("Rai -Nich i"  = Visit-Japan), conjmm-tions of locations ("Nichi-Be?"
= ,\]alton-US),and street; addresse, s ("Meguro-ku, 0okayama2-12-1") .
The best hilly autolnatic system wassuccessflfl in extracting lllOSt of these specificpatterns.
However, the flflly automatic systemhas a probleln in its coverage.
In lmrticular, thetraining data was newspaper articles publishedin 1994 and the test; data was fro151 1999, sothere are several new names, e.g.
the prilne min-ister's name which is not so co1111noll (0buchi)and a location nmne like "Kosovo", wlfich wererarely mentioned in 1994 but apt)eared a lot in1999.
'.Fhe system missed many of them.3.3 Domain  dependencyIn Table 3, the differences in performance be-tween the general domain and the restricted o-main ~r(' shown ill the cohmm "diff.".
Manysystems 1)erfl)nne(l better in the restri(:ted do-main, although ~ small ntllnl)er of systems per-forlned better ill the genera\] domain.
Therewere two systems which intentiomflly tunedtheir systems towards the restricted domain,which are shown in bold in the table.
Both ofthese were alnong the systelns which perfbrlnedmuch better (more than 7%) ill the restricte.ddomain.
The system which achieved the largestimprovement was a fully automatic system, andit only replaced the training data for the domainrestricted task (so this is an intentionally tunedsystem).
It shows the domain dependency of thetask, although further investigation is needed tosee why some other systems can perform nmchbetter even without domain tinting.3.4 Compar i son  to human per formanceIn Table 4, hulllan performance is shown inthe "Novice" and "Expert" cohtmns.
"Novice"means tile average F-measure of three gradu-ate students all(l "l;xpert" means the averageF-measure of the two people who were most re-1109sponsible for creating tile definition and createdthe answer.
They frst  created two answers in-dependently and checked them by themselves.The results after the checking are shown in thetable, so many careless mistakes were deletedat this time.
We Call say that 98-99 F-measureis the performance of experts who create themvery carefully, and 94 is a usual person's perfofl nance .We can find a similar pattern of performanceamong different NEs.
Hmnans also performedmore poorly for artifacts and very well for timeand numeric expressions.Tile difference t)etween the best system per-formance and hulnan perfbrlnance is 7 or moreF-measure, as opposed to the case in Englishwhere the top systems perform at, a level compa-rable or superior to human perfornlancc.
Therecould be several reasons for this.
One obviousreason is that we introduced a ditficult NE type,artifact~ which degrades the overall performancemore for the system side than the lmman side.Also, the difficulty of identifying the expressionboundaries may contribute to the difference.
Fi-nally, we believe that the systems can possiblyimprove, as IREX was the first evaluation basedproject in Japanese, whereas in English theretrove been 7 MUC's and tile technology mayhave matured by now.5 AcknowledgmentWe would like to thank all the participants ofIREX projects.
The project would never havebeen as successful as it was without the partic-ipants, all of whom were very cooperative andconstructive.ReferencesIREX Committee 1999 Proceedings of theIREX WorkshopSatoshi Sekine, Hitoshi Isahara.
2000 : "IREX:IR and IE Ewdnation Project in Japanese"Proceedings of the LREC-2000 coT@fenceIREX Hornepagehttp: / /cs.nyu.edu/projects/proteus/ i rexMUC Homepage http:/ /www.muc.saic.com/TREC Homepage trec.nist.gov/NTCIR H(nneI)agehttl)://www.rd.nacsis.ac.jp/f itcadm/index-en.htmlTS C ttomeI)agehttl,:// al  ga.jaist.ac.jp:S000/tsc/4 ConclusionWe reported on tile NE task of tim IREXproject.
We first explained tile task and thedefinition, as well a.s the d~ta we created andthe results.
The analyses of the result were de-scribed, which include analysis of task ditficultyacross the NE types and system types, analysisof domain dependency and comparison to hu-man performance.As this is one of the first projects of this typein ,Japan, we may have a lot to do ill the fu-ture and holmflflly tile results of tile projectwill be beneficial for fllture projects.
As tilenext step, II/,EX will be merged with a simi-lar project NTCIR (NTCIR Homepage, 2000)which places more eml)hasis on IR., with a newlycreated project for sumlnarization, TSC (TSCHomepage, 2000), and contilme this kind of ef-fort for tile fllture.1110
