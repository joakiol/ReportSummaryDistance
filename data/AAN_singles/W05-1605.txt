Generating and selecting grammatical paraphrasesClaire GardentCNRS/LORIANancy, Franceclaire.gardent@loria.frEric KowINRIA/LORIANancy, Franceeric.kow@loria.frAbstractNatural language has a high paraphrastic power yetnot all paraphrases are appropriate for all contexts.In this paper, we present a TAG based surface re-aliser which supports both the generation and theselection of paraphrases.
To deal with the combi-natorial explosion typical of such an NP-completetask, we introduce a number of new optimisationsin a tabular, bottom-up surface realisation algo-rithm.
We then show that one of these optimisationssupports paraphrase selection.1 IntroductionAs is well known, natural language has a very high paraphras-tic power so that the same core meaning can be expressed inmany different ways [Gross, 1975; Mel?c?uk, 1988].
Yet notall paraphrases are appropriate for all contexts.
So for in-stance, a sentence and its converse (1a) express the same coremeaning and so can be considered paraphrases of each other.Yet as example (1b) illustrates, they are not interchangeablein the context of a control verb:(1) a. John borrowed a book from Mary.
?Mary lent a book to Johnb.
Peter persuaded John to borrow a book from Mary.6?
Peter persuaded Mary to lend a book to JohnSimilarly, a canonical and a cleft sentence (2a) communi-cate the same core meaning yet a contrastive context (2b) onlyadmits the cleft version.
(2) a. John looks at Mary.?
It is Mary that John looks atb.
* It is not Sarah, John looks at Mary.It is not Sarah, it is Mary that John looks atMore generally, the anaphoric potential (that is, the dis-course status of the entities being talked about) of the pre-ceding discourse, its structure, the presence of an embeddingverb or of a given subordinating or coordinating conjunctionare all factors which may restrict the use of paraphrases.
Topreserve completeness, it is therefore important that a gener-ator be able to produce paraphrases in a systematic fashion.On the other hand, it is also well known that surface real-isation (the task of producing the set of sentences associatedby a grammar with a given semantic representation) is NP-complete [Brew, 1992].In this paper, we present a TAG based surface realiserwhich supports both the generation and the selection of gram-matical paraphrases (section 2 and 3).
To deal with the re-sulting combinatorics, we introduce a number of new opti-misations (section 4).
We then show how one of these op-timisations can be used to support the selection of contextu-ally appropriate paraphrases (section 5).
Finally, we relateour approach to similar proposals and show that it comparesfavourably in terms of efficiency (section 6 and 7).2 The grammarThe grammar used by the surface realiser is Feature-basedTAG, a unification based version of Tree Adjoining Gram-mar.
Briefly1, a Feature-based TAG consists of a set of (aux-iliary or initial) elementary trees and of two tree compositionoperations: substitution and adjunction.
Substitution inserts atree onto a leaf node of another tree2 while adjunction insertsan auxiliary tree into a derived tree (i.e., either an elementarytree or a tree resulting from the combination of two trees).
Inan FTAG, each tree node which is not a substitution node isassociated with two feature structures called top and bottomand during derivation, the following unifications take place.?
The adjunction at some node X with top features tXand bottom features bX , of an auxiliary tree with roottop features r and foot bottom features f entails theunification of tX with r and of bX with f .?
The substitution at some node X with top features tXof a tree with root top features t entails the unificationof tX with t.?
At the end of a derivation, the top and bottom featuresof all nodes in the derived tree are unified.1For more details on FTAG see [Vijay-Shanker and Joshi, 1988].2Leaf nodes where substitution can take place are graphicallydistinguished by a down arrow.In the FTAG used by the surface realisation algorithm, lin-guistic expressions are associated with semantic representa-tions as advocated in [Gardent and Kallmeyer, 2003].
The se-mantic representations used are flat semantic representationsin the sense of [Copestake et al, 2001] and the semantic pa-rameters (that is, the semantic indices representing the miss-ing arguments of the semantic functors) are represented byunification variables.Further, each elementary tree is associated with a semanticrepresentation of the type just described and the appropriatenodes of the elementary trees are decorated with semantic in-dices or parameters.More precisely, the substitution nodes of the tree associatedwith a semantic functor will be associated with semantic pa-rameters whilst root nodes and certain adjunction nodes willbe labelled with semantic indices.
As trees are combined,semantic parameters and semantic indices are unified by theFTAG unification mechanism thus specifying which semanticindex provides the value for which semantic parameter.Generally, the idea is that the association between treenodes and unification variables encodes the syntax/seman-tics interface: it specifies which node in the tree provides thevalue for which semantic parameter in the semantic represen-tation of a semantic functor.
So for instance, the trees forJohn, loves and Mary will be as given in Figure 1.
The tree forloves is associated with a semantic representation includingthe two semantic parameters x and y.
These parameters alsolabel the subject and the object substitution nodes of this tree.Conversely, the root node of the tree for John is labelled withthe semantic index j.
If the string parsed is John loves Mary,this tree will be substituted at the subject substitution node ofthe loves tree thus instantiating the semantic parameter x to j.And similarly, for the Mary tree.SNP?x VPNPj V NP?y NPmJohn loves Maryname(j,john) love(x,y) name(m,mary)?
love(j,m),name(j,john),name(m,mary)Figure 1: John loves MaryCoverage.
The grammar used describes a core fragment forFrench and contains around 4 000 trees.
It covers some 35basic subcategorisation frames and for each of these frames,the set of argument redistributions (active, passive, middle,reflexivisation, impersonal, passive impersonal) and of argu-ment realisations (cliticisation, extraction, omission, permu-tations, etc.)
possible for this frame.
As a result, it capturesmost grammatical paraphrases that is, paraphrases due to di-verging argument realisations or to different meaning pre-serving alternation (e.g., active/passive or clefted/non cleftedsentence).3 The basic algorithmThe basic surface realisation algorithm used is summarised inFigure 1 (appendix).
It is a bottom up, tabular algorithm [Kay,1996] optimised for TAGs.
Its workings can be illustrated bythe following example.
Suppose that the input semantics isthe following :{camp(s,j),john(j),in(s,l),paris(l)}Then the algorithm proceeds as follows.
In a first step (lex-ical selection), the elementary trees whose semantics sub-sumes3 part of the input semantics are retrieved and addedto the agenda.
In our simple example, the selected trees arethe trees for Jean, campe, dans and paris.The second step (the substitution phase) consists in sys-tematically exploring the possibility of combining two treesby substitution.
It is summarised for our example by the ta-ble in figure 2 where each line corresponds to a processingstep.
The words in each column indicate the trees present ateach step in the chart, the agenda and the agenda for auxiliarytrees (AgendaA).
The combination column indicates whichtree combines with which tree by means of which operation(?
indicates a substitution, ?
an adjunction).
The trees result-ing from such a combination are represented using the con-catenation of the names of the combined trees (jeanCampe isthe tree resulting from the combination of the tree anchoredby Jean with that anchored by campe).
Thus, the first line in-dicates that the trees anchored by Jean, campe, dans and Parisare in the agenda and that the chart is empty.
The second lineshows that the next state is a state where the tree anchoredby Jean has been retrieved from the agenda and added to thechart.
The third line indicates that when the trees anchored bycampe and Jean are in the chart, they can be combined usingsubstitution.
The result is added to the agenda etc.More generally, the items are retrieved one by one fromthe agenda to be added either to the chart or to the auxiliaryagenda (in the case of an auxiliary tree devoid of substitutionnode).
For each item added to the chart, all possible substitu-tions are carried out and the resulting derived trees are addedto the agenda.
The loop ends when the agenda is empty.At this stage, all the items containing an empty substitutionnode are erased from the chart (here, the trees anchored bycampe and dans are erased).
The agenda is then reinitialised tothe content of the chart and the chart to the content of the aux-iliary agenda.
The third step (the adjunction phase) occursthen in which all possible adjunctions are performed (figure3).
Finally (retrieval phase), the strings labelling the items inthe chart whose semantics is the input semantics are printed3Subsumption is here taken to denote term unification.
Hencelexical selection is done on a very ?syntactic?
basis: only these lexi-cal entries whose semantics representation matches part of the inputsemantics are selected.
This is partly alleviated by taking lexicalsynonymy into account while developing the grammar so that two(intra- or inter-categorical) synonyms are assigned the same seman-tic representation.
A more complete treatment would require the in-tegration either of a richer lexical semantics or of a lexical selectionmodule permitting inference so that for instance ?adult(x) male(x)human(x)?
can be inferred to be denoted by the word ?man?.Agenda Chart Combination AgendaAJean,campe,dans,Pariscampe,dans,Paris Jeandans,Paris campe,Jean ?
(campe,Jean)Paris,JeanCampe campe,Jean,dansJeanCampe campe,Jean,dans,Paris ?
(dans,Paris)dansParis campe,Jean,dans,Paris,JeanCampecampe,Jean,dans,Paris,JeanCampe dansParisFigure 2: Sample run of the substitution phaseout, which in this case yields the sentence Jean campe dansParis.4 OptimisationsSurface realisation is NP complete [Brew, 1992].
More-over the paraphrastic power of natural language is enormous[Gross, 1975; Mel?c?uk, 1988].
Hence optimisation is a keyissue and so is the possibility to select a given paraphraseon demand.
We now present a number of optimisations weadded to the algorithm just described in order to reduce thecombinatorics.4.1 Tabulation and ordered combinationsTabulation serves to avoid redundant computations.
In analy-sis, the use of the chart to store intermediate constituents andavoid multiple computation of the same structure renders anexponential task polynomial.
In generation however, tabula-tion increases efficiency by avoiding duplicate computationsbut the complexity remains exponential because in particularof multiple modifiers [Brew, 1992].
Suppose for instancethat the input semantic representation is the following:fierce(x),little(x),cat(x),black(x)For this input, a naive bottom-up realisation algorithm willgenerate all intermediate structures that is, n!
intermediatestructures with n the number of modifiers.
These n!
struc-tures will furthermore be multiplied by the context so that forinstance given the input for the fierce little black cat runs, thefollowing structures will all be generated.
(3) a. fierce cat, fierce black cat, little cat,little black cat, fiercelittle cat, black catb.
the fierce cat, the fierce black cat, the little cat, the littleblack cat, the fierce little cat, the black catc.
the fierce cat runs, the fierce black cat runs, the little catruns, the little black cat runs, the fierce little cat runs, the blackcat runsTo minimise the impact of multiple modifiers, the algo-rithm presented here performs all substitutions before con-sidering adjunctions.
In effect, this means that adjunctiononly applies to syntactically complete trees and so that themany intermediate structures induced by the modifiers do notmultiply out with other incomplete structures.
In the aboveexample for instance, (3c) will be computed but neither (3a)nor (3b).4.2 Avoiding spurious derivationsCategorical grammars often allow so called spurious deriva-tions in that one and the same syntactic structure can bederived in several different ways [Hepple, 1991].
TAGs alsoinduce spurious derivations due to the fact that substitutionsand adjunctions on different nodes of the same tree can becarried out in different relative orders all of which result inone and the same structure.
Thus for instance, given thetrees np(Marie), np(Jean), s(np?, v(aime), np?
)and the semantic aime(j,m),jean(j), marie(m), twoderivations are possibles, one where np(Jean) is firstsubstituted in s(np?, v(aime), np?)
before the tree fornp(Marie) is ; and the other where np(Marie) is firstsubstituted before np(Jean) is added.
More generally, for atree containing n substitution nodes, there will be n!
possiblederivations.
For instance given the sentence(4) Jean persuade Marie de promettre a` Claire de donner unlivre a` Marie.Jean persuades Mary to promise Claire to give Mary abookthere will be 3!
?
2!
?
2!
= 24 possible derivations allof them produce the same syntactic tree and hence the samesentence.Adjunction suffers from the same shortcoming.
Given aTAG tree and n auxiliary trees that can adjoin to differentnodes of that tree, there are n!
possible ways of deriving thetree resulting from these n adjunctions.To avoid these spurious derivations, we impose a uniqueorder (from left to right) on the sequences of substitutionsand adjunctions done within a given tree.
Because the al-gorithm systematically examines all pairs of items, this re-striction does not affect completeness : the unique derivationsupported by the imposed constraints will be taken into con-sideration by the algorithm and will therefore be produced.A third source of spurious derivations come from the pos-sibility of having multiple adjunctions on the same node of agiven tree for instance in the case of the little black cat.
Theauxiliary trees anchored by little and black can adjoin in twodifferent orders on the tree anchored by cat: either little is ad-joined to cat and black to the foot node of little in the resultingtree or black is adjoined to cat and little to the root node ofthe resulting derived tree.
To eliminate this type of spuriousderivations, adjunction on a foot node is ruled out ?
which isusual in TAG parsers.Agenda Chart Combination AgendaAJean,Paris,JeanCampe dansParisParis,JeanCampe dansParis,JeanJeanCampe dansParis,Jean,ParisdansParis,Jean,Paris,JeanCampe ?
(JeanCampe,dansParis)JeanCampeDansParis dansParis,Jean,Paris,JeanCampedansParis,Jean,Paris,JeanCampe,JeanCampeDansParisFigure 3: Sample run of the adjunction phase4.3 Filtering of valid lexical sequencesThe most efficient optimisation takes place between the lex-ical selection phase and that of combination by substitutionand adjunction.
At this stage, the number of combinationsthat are a priori possible is?1?i?n ai with ai the degree oflexical ambiguity of the i-th literal and n, the number of lit-erals in the input semantic.
That is, the search space is expo-nential in the number of literals.
To reduce the combinatorics,we use a technique introduced for parsing by [Perrier, 2003]called polarity based filtering.Polarity based filtering is based on the observation thatmany of the combinations of lexical items which cover the in-put semantics are in fact syntactically invalid either becausea syntactic requirement is not fulfilled or because a syntac-tic resource is not used.
Accordingly, polarity based filteringdetects and eliminates such combinations by:1. assigning each lexical item a polarity signature reflectingits syntactic requirements and resources2.
computing for each possible combination of lexicalitems the net sum of its syntactic requirements and re-sources and3.
eliminating all combinations of lexical items that do nothave a net sum of zero (because such combinations can-not possibly lead to a syntactically valid sentence)As we shall see below, polarity based filtering is imple-mented using finite state techniques.Let us see how this works by running through a simpleexample.
Suppose that the input semantic representation is:(5) buy(e,t,j), annoying(e), field(t),john(j)and that the TAG trees selected for this input are the onesgiven in Figure 8 (appendix).In this figure, the literals following the tree name give thepolarities that are automatically assigned to each of thesetrees on the basis of their root and substitution nodes (for in-stance, the v achete has polarity (+p ?
2n) meaning that itprovides a sentence and requires two NPs).
Since in a TAG,substitution nodes indicates syntactic requirements whilst aninitial tree permits fulfilling a syntactic requirement, polaritysignatures can be automatically computed as follows:?
a polarity of the form +C is added to the tree polaritysignature of each initial tree with root node category C.?
a polarity of the form ?S is added to the tree polaritysignature of each initial tree for each substitution nodewith category S in that tree.Now we need to compute the polarity of all possible com-binations of lexical items.
This is done by:1. building a polarity automaton for each polarity categoryoccurring in the set of possible combinations (in thiscase, n and s),2. computing the intersection of these automata and3.
minimising the resulting automaton.In the final automaton, only the combinations that have anull polarity are represented.
These will be the combinationsactually explored by the realiser.For the above example, the final automaton is that given infigure 9 where each state is labelled with the cumulated polar-ity of the path(s) leading to that state and where the transitionsare labelled with the lexical item covered.
As can be seen, thecombinations that are syntactically invalid (in grey in the au-tomaton) have been eliminated.
Thus in particular, the com-bination of the predicative tree n0Vadj with the verb ache`teand its two complements is ruled out (as the n requirement ofn0Vadj cannot be satisfied) and conversely, the combinationof the predicative tree p0Vadj with the relational noun achat(because the p requirement of p0Vadj cannot be satisfied)4 .4.4 Combining polarity based filtering andtabulationTo preserve the factorisation supported by the use of a chart,polarity filtering must furthermore be integrated with the re-alisation algorithm.
Indeed, each path through a polarity au-tomaton represents a combination of lexical items whose totalsemantics is the input semantics and which may lead to a syn-tactically valid expression.
But some of these paths may sharesome subpath(s).
To avoid computing these shared subpathsseveral times, each selected elementary tree is annotated with4For lack of space, we ignore here functional words (determiners,prepositions).
In the full algorithm, their treatment is implementedeither by means of co-anchors (a verb whose comple?ment requires agiven preposition for instance, will be assigned a tree with multipleanchors, one for the verb, the other for the preposition) or by meansof a richer semantic (contrary to what is shown here, a quantifier willhave a non nul semantics).
Note further that lexical items with multi-literal semantics are also handled as well as items whose semanticsis reduced to an index (pronouns, control verb subject, modifiers,etc.
).the set of automaton paths it occurs in.
During realisation,two items will be compared only if the intersection of theirpath sets is not empty (they appear in the same automatonpath).
The result of a combination is labelled with the in-tersection of the labels of the combined constituents.
In thisway, the elementary items appearing in several paths of theautomaton are only introduced once in the chart and the fac-torisation of both elementary and derived items that are com-mon to several automaton path is ensured.5 Paraphrase selectionAs pointed out in the introduction, not all paraphrases are ap-propriate in all contexts.
To test the ability to generate contex-tually appropriate sentences, we augmented the realiser witha paraphrase selection mechanism based on the polarity fil-tering system described in section (4.3).
For instance, it ispossible to select from among the possible realisations forregarde(j,m), jean(j), marie(m), the variant wherejean is verbalised as a cleft subject namely, C?est Jean qui re-garde Marie (It is John who is looking at Mary).More generally, the selection constraints allowed aresyntactico-semantic constraints of the form Synt:SemIndexwhere Synt is a morpho-syntactic feature (declarative, inter-rogative, cleft, pronoun, etc.)
and SemIndex is an index oc-curring in the input semantics.Intuitively, a selection constraint supports the selection,for a given semantic index, of the variant(s) obeying thesyntactico-semantic constraint set by the selection constraintfor that index.Formally, these constraints are imposed during the polarityfiltering phase as follows.
The syntactic properties supportedby the selection constraints are automatically associated dur-ing grammar compilation to the elementary trees of the gram-mar by means of so-called hypertags [Kinyon, 2000].
This ismade possible by the fact that the TAG used is derived froma metagrammar [Crabbe?
and Duchier, 2004] that is, from ahighly factorised way of representing the linguistic conceptsencoded in the TAG trees.
Roughly, the metagrammar for-malism is used (i) to define abstractions over these conceptsand (ii) to combine these abstractions so as to produce the el-ementary trees of a TAG.
During the metagrammar compila-tion process, a so-called hypertag is built for each tree whichrecords the abstractions used to produce that tree.
Thus hy-pertags contain detailed information about the linguistic con-tent of the TAG elementary trees.
In particular, the hypertagof the tree with clefted subject of the n0vn1 family (i.e., theset of verbs taking two nominal arguments) will contain theproperty +cleft:X where X is the semantic index associatedwith the subject node.During lexical selection, this index is instantiated by unifi-cation with the input so that the selected elementary tree forregarde will have the property +cleft:j.Conversely, a restrictor is a property that a lexical item in-tervening in the production of the generated paraphrases musthave.
In the above example, the restrictor is -cleft:jmean-ing that the j index must be realised by a clefted structure.Paraphrase selection is implemented by parameterising therealiser with a restrictor (for instance, -cleft:j).
This re-strictor is then used to initialise the polarity automaton andeliminate (by polarity filtering) all these combinations whichdo not contain the +cleft:j charge (since the negativecharge introduced during initialisation must be cancelled).
Asa result, the realiser will only produce the variant:(6) C?est Jean qui regarde Marie.More generally, the polarity mechanism permits selectingparaphrases on the basis of the information contained in thegrammar hypertags or in the TAG tree features.
This infor-mation, which is decided upon by the grammar writer, can beboth fine grained and of different natures.Feature values can be used to control the feature valuesassociated with the root node of the constructed tree, typicallyrequiring that it is of interrogative, declarative or imperativemood.Hypertags can be used more generally to control the selec-tion of the lexical items entering in the generated construct.Importantly, the information they contain can be specifiedboth at the grammar and at the lexical level so that para-phrase selection can then operate both on features determinedby syntax and on lexically determined characteristics (levelof speech, modality, type of semantic relation, thematic andfore/backgrounding structure, etc;).6 Implementation and ExperimentationThe realiser described here has been implemented in Haskell.It includes a graphical interface as well as a debugger so thatthe user can inspect the content of the chart and of the agendaat each step of the algorithm.
It also supports batch process-ing thus permitting a systematic evaluation of the impact ofvarious optimisations combinations.
In what follows, we dis-cuss the effect of polarity filtering and of paraphrase selectionin that system.6.1 The effect of polarity filteringTo get an estimate of how our realiser compares with exist-ing published results, we revisited the test cases discussedin [Carroll et al, 1999] and [Koller and Striegnitz, 2002] byproducing similar sentences in French namely (7a) and (7b).
(7) a.
Le directeur de ce bureau auditionne un nouveau consul-tant d?Allemagne (The manager in that office interviews anew consultant from Germany)b.
Le directeur organise un nouveau seminaire d?equipe heb-domadaire special (The manager organises an unusual ad-ditional weekly departmental conference).The grammar used contains 2063 trees.
In this grammar,the verb organiser is associated with 107 trees and adjectiveswith 8 trees.
For the purpose of efficiency testing, we fur-thermore treated the PP d?e?quipe as an adjective.
As a result,there are 107 ?
8 (856) combinations of lexical items cover-ing the input semantics for example (7a) while for example(7b), this number is 107?
84.
The effect of polarity filteringfor these two examples is summarised in the following table.That is, polarity filtering reduces the number of lexicalitems combinations actually explored from 856 to 55 in thefirst case and from 438 272 to 232 in the second.Example 7a Example 7bPossible combinations 856 438 272Combinations explored 55 232Sentences (w/o selection) 9 216Figure 4: Filtering out combinationsNote furthermore that despite the overhead introduced bythe construction of the polarity automaton, polarity filteringreduces overall processing times (cf.
Figure 5).Optimisations Example 7a Example 7bnone 14.8 s 93.8 spol 0.8 s 14.7 sCarroll 1.8 s 4.3 sKoller 1.4 s 0.8 sFigure 5: Processing timesThus, for the examples considered, processing times arereduced by 95% and 84% respectively.
The processing timesfor (7a) compares favourably with those published for boththe Carroll et al and the Koller and Striegnitz realisers.
Thiscomparison is not all that meaningful, however, since we areusing different grammars and significantly faster computers,a 3 Ghz Pentium IV to the 700 Mhz Pentium III in [Kollerand Striegnitz, 2002].Indeed, the poor performance of our surface realiser in ex-ample (7b) is directly related to the degree of lexical ambi-guity in our grammar.
As illustrated in section 4.1, input se-mantics with multiple modifiers pose a problem for surfacerealisers.
Although performing adjunction separately fromsubstitution prevents this problem from spilling over into in-complete structures, the fact remains that n translate to n!structures.
Further aggravating the situation is that our gram-mar provides 8 trees for every adjective, leading to 85?5!, or3.9 million possible structures.
When we modified our gram-mar to only have one tree per adjective, our realisation timesdropped to 9s without filtering and 2.7s with.
This exam-ple calls to attention the fact that polarity filtering does notaccount for lexical ambiguity in modifiers.
In section 7, wesuggest some potential mechanisms for dealing with modi-fiers, which we expect to be complementary to the filteringtechnique.6.2 Paraphrase selectionParaphrase selection permits reducing the combinatorics onestep further.
Thus introducing a cleft restrictor for examples(7a) and (7b), causes the generator to produce fewer results,2 sentences instead of 9 in the first example, and 18 insteadof 54 in the second.These figures can be explained as follows.
The grammarallows 9 syntactic structures for the input considered namely:(8) a.
C?est par le directeur de ce bureau qu?un nouveauconsultant d?Allemagne est auditionne?b.
C?est le directeur de ce bureau qui auditionne unnouveau consultant d?Allemagnec.
C?est un nouveau consultant d?Allemagnequ?auditionne le directeur de ce bureaud.
C?est un nouveau consultant d?Allemagne que ledirecteur de ce bureau auditionnee.
C?est un nouveau consultant d?Allemagne qui estauditionne?
par le directeur de ce bureauf.
Le directeur de ce bureau auditionne un nouveauconsultant d?Allemagneg.
Un nouveau consultant d?Allemagne est auditionne?par le directeur de ce bureauSince for the moment the grammar places no constraints onthe respective order of modifiers, there are 9 possible realisa-tions for example (7a) and 9 ?
3!
for example (7b).
With theobject cleft restrictions on ?consultant?, these numbers dropto 2 for the first example and to 2?
3!
for the second.Example 7a Example 7bSentences (w/o selection) 9 54Sentences (with selection) 2 18Figure 6: SelectionAccordingly, the processing time drops by 63% and 88%with respect to simple polarities (cf.
Figure 7).Optimisations Example 7a Example 7bnone 14.8 s 93.8 spol 0.8 s 14.7 spol + select 0.3 s 1.8 sFigure 7: Polarity + Selection7 Related approachesSeveral recent papers focus on improving the efficiency ofsurface realisation.
In this section, we relate our approach tothe HPSG based approach presented in [Carroll et al, 1999],to the statistical and semi-statistical strategies used in [Ban-galore and Rambow, 2000] and in [White, 2004] and to theconstraint based approach described in [Koller and Striegnitz,2002].
We also briefly relate it to the greedy strategy used in[Stone et al, 2003].7.1 Copestake et al?s HPSG approachAs mentioned in section 4.1, multiple modifiers may trig-ger an exponential number of intermediate structures.
The?adjunction after substitution?
idea is inspired from the pro-posal made in [Carroll et al, 1999] that a complete syntacticskeleton be built before modifiers be inserted into that tree.Because the Carroll et al proposal is set within the HPSGframework however, extracted modifiers as in Which officedid John work in?
need specific treatment.
In contrast, inTAG, all modifiers are treated using adjunction so that no spe-cific treatment is required.
All that is needed is that adjunc-tion only be applied after all possible substitutions have beencarried out.
A second, more meaningful difference is that nosuch global optimisation as polarity filtering is proposed tofilter out on the basis of global information about the sets ofpossible combinations, a priori invalid ones.7.2 Statistical approachesInterestingly, [White, 2004] proposes a treatment of modifierswhich is in some sense the converse of the ?adjunction aftersubstitution?
treatment and where complete NPs are first builtbefore they are combined with the verb.
This second option isalso feasible in TAG (adjunction would then apply on specificsets of lexical entries and the results combined with the verb)and it would be interesting to experiment and compare therelative efficiency of both approaches within the TAG frame-work.Both approaches isolate the addition of modifiers to a con-stituent, thereby avoiding spurious combinations with unre-lated constituents; but neither directly address the fact that arestill an exponential n!
ways to combine any n modifiers fora single constituent.
[White, 2004] and [Bangalore and Ram-bow, 2000] propose statistical solutions to this problem basedon a linear n-gram language model.
In White?s approach thestatistical knowledge is used to prune the chart of identicaledges representing different modifier permutations, e.g., tochoose between fierce black cat and black fierce cat.
Bangaloreassumes a single derivation tree that encodes a word lattice (a{fierce black, black fierce} cat), and uses statistical knowledgeto select the best linearilisation.
Our framework does not cur-rently implement either approach, but we hope to adopt an ap-proach similar to Bangalore?s.
Rather than directly perform-ing adjunction, we associate each node with the set of auxil-iary trees (modifiers) that are to be adjoined to that node.
Theorder in which these modifiers are adjoined can be decidedthrough statistical methods.There are three other uses for probabilistic techniques: forlexical selection, optimisation and ranking.
Such techniquesare useful for guiding the surface realiser towards a singlebest result (or a relatively small number thereof).
On theother hand, we aim to produce all possible paraphrases, thatis explore the entire search space of syntactic variants, andso with the exception of modifier ordering, we eschew theuse of probabilities in favour of an ?exact method?
[G. Bon-fante, 2004].
While Bangalore uses a tree model to producea single most probable lexical selection, we use polarities tofilter out all the definitely impossible ones.
While in White?ssystem, the best paraphrase is determined on the basis of n-gram scores that is, on the basis of frequency, in our approach?best?
means ?most contextually appropriate?.
Indeed, therestrictors we use to select a paraphrase, although they arehere given by hand, could equally be set by the context andso permit modelling the effect of contextual constraints onparaphrases.
We believe that our approach, modulo statis-tical handling of modifiers, would be roughly equivalent toWhite?s with anytime-searching disabled.7.3 Koller et al?s constraint-based approachFinally, our approach has interesting connections to theconstraint-based approach proposed by [Koller and Strieg-nitz, 2002].
In this approach, the subset of the TAG grammarwhich is used for a given realisation task is translated into aset of lexical entries in a dependency grammar defining wellformed TAG derivation trees.
This set of entries is then parsedby an efficient constraint-based dependency parser thus pro-ducing the derivation trees associated by the grammar withthe set of input lexical entries.
A post processing phase pro-duces the derived trees on the basis of the derivation treesoutput by the first step.The main similarity between this and our approach is thatthey both use a global mechanism for filtering out combina-tions of lexical entries that cannot possibly lead to a syntac-tically valid sequences.
In the Koller et al approach, thisfiltering is based on well formed derivation trees (only thesecombinations of lexical entries that form a valid derivationtree are considered) whereas in ours, it is based on polaritiesand on the cancelling out of syntactic resources and require-ments.
As a preliminary evaluation shows, such a global op-timisation is very efficient in pruning the search space.There are differences though.
In particular, while Koller etal.
explicitly ignores feature information, our algorithm han-dles a TAG with fully specified feature structures.
Furtherwhile in our approach, the processing of the valid combina-tions is done using a tabular algorithm optimised to avoid spu-rious derivations, the postprocessing step producing derivedtrees from derivation trees is left undefined in the Koller et alapproach.
Finally, while the Koller et al approach is basedon constraint propagation, ours is based on finite state tech-niques.
These differences open up the door for interestingcomparisons and combinations.
It would be interesting forinstance to combine the Koller et alapproach with the tab-ular surface realisation algorithm presented in this paper, orto compare run times once feature structures are taken intoaccount.7.4 Stone?s greedy approach[Stone et al, 2003] presents a greedy approach to TAG basedsurface realisation.
The greedy search applies iteratively toupdate a single state in the search space.
On each iteration,all neighbours of the current state are produced but only onestate is chosen at the next current state, based on a heuristicevaluation.
[Stone et al, 2003]?s search strategy is therefore markedlydifferent from ours.
While we explore the entire searchspace and use polarities to control the combinatorics, Stone?sgreedy strategy is a best first strategy which incrementallytrims the search space using heuristics.
In terms of efficiency,the greedy strategy is of course better.
The goals behind thetwo approaches are distinct however.
Thus while Stone?s ap-proach aims at modelling the interaction of the various mech-anisms involved in microplanning, the present proposal is di-rected towards generating and selecting paraphrases.
In par-ticular, we are interested in using the realiser to debug a para-phrastic grammar that is, a grammar which alleviates the in-ference task by assigning paraphrases the same semantics ?this can only be done by adopting an exhaustive search strat-egy.
More generally, ?exhaustive surface realisation?
pro-vides a natural way to debug grammars and reduce their de-gree of overgeneration.
Since the combinatorics is not onlytheoretically (worse case analysis) but also practically veryhigh, it is worth investigating ways of optimising surface re-alisers which perform an exhaustive search.8 ConclusionWe have presented a surface realiser for TAG which is opti-mised to support the generation of grammatical paraphraseswhile also permitting the selection, on the basis of syntacticosemantic constraints, of a particular paraphrase.
The mostefficient optimisation proposed concerns polarity filtering, aglobal technique that permits the elimination of combinationsof lexical items which cannot possibly lead to a syntacticallyvalid sentence.
While used here for generating with TAG, thetechnique is fully general and can be used for parsing [Perrier,2003] but also for generating with other grammatical frame-works.Future work will concentrate on extending the grammarand the lexicon to other types of paraphrases (in particu-lar, morphoderivational or cross categorical paraphrases), onproviding a systematic evaluation of the paraphrase selectionmechanism and on using the realiser for the debugging of anexisting TAG for French.References[Bangalore and Rambow, 2000] S. Bangalore and O. Ram-bow.
Using TAGs, a tree model and a language modelfor generation.
In Proceedings of TAG+5, Paris, France,2000.
[Brew, 1992] C. Brew.
Letting the cat out of the bag: Gener-ation for shake-and-bake MT.
In Proceedings of COLING?92, Nantes, France, 1992.
[Carroll et al, 1999] J. Carroll, A. Copestake, D. Flickinger,and V. Paznan?ski.
An efficient chart generator for (semi-)lexicalist grammars.
In Proceedings of EWNLG ?99,1999.
[Copestake et al, 2001] A. Copestake, A. Lascarides, andD.
Flickinger.
An algebra for semantic construction inconstraint-based grammars.
In Proceedings of the 39thACL, Toulouse, France, 2001.[Crabbe?
and Duchier, 2004] B. Crabbe?
and D. Duchier.Metagrammar redux.
In International Workshop on Con-straint Solving and Language Processing - CSLP 2004,Copenhagen, 2004.[G.
Bonfante, 2004] G. Perrier G. Bonfante, B. Guillaume.Polarization and abstraction of grammatical formalisms asmethods for lexical disambiguation.
In Proceedings ofCoLing 2004, 2004.
[Gardent and Kallmeyer, 2003] C. Gardent andL.
Kallmeyer.
Semantic construction in ftag.
InProceedings of the 10th EACL, Budapest, Hungary, 2003.
[Gross, 1975] M. Gross.
Me?thodes en syntaxe.
Masson,Paris, 1975.
[Hepple, 1991] M. Hepple.
Efficient incremental processingwith categorial grammar.
In Proceedings of the 29th ACL,Berkeley, 1991.
[Kay, 1996] M. Kay.
Chart Generation.
In 34th ACL, pages200?204, Santa Cruz, California, 1996.
[Kinyon, 2000] A. Kinyon.
Hypertags.
In Proceedings COL-ING, Sarrebruck, 2000.
[Koller and Striegnitz, 2002] A. Koller and K. Striegnitz.Generation as dependency parsing.
In Proceedings of the40th ACL, Philadelphia, 2002.
[Mel?c?uk, 1988] I. Mel?c?uk.
Paraphrase et lexique dans lathe?orie linguistique sens-texte.
Lexique, 6:13?54, 1988.
[Perrier, 2003] G. Perrier.
Les grammaires d?interaction,2003.
Habilitation a` diriger les recherches en informa-tique, universite?
Nancy 2.
[Stone et al, 2003] M. Stone, C. Doran, B. Webber,T.
Bleam, and M. Palmer.
Microplanning with commu-nicative intentions: the SPUD system.
Computational In-telligence, 19(4):311?381, 2003.
[Vijay-Shanker and Joshi, 1988] K. Vijay-Shanker andA.
Joshi.
Feature based tags.
In Proceedings of the 12thACL, pages 573?577, Budapest, 1988.
[White, 2004] M. White.
Reining in CCG chart realization.In INLG, pages 182?191, 2004.A AppendixAlgorithm 1 The GenI algorithm1: procedure GENERATE(Gram,Sem)2: AgendaA?
?
; Agenda?
?
; Chart?
?3: for all trees t ?
Gram such that t?s semantics subsumesSem do4: Agenda?
Agenda + t5: end for6: while Agenda 6= ?
do7: t?
any tree ?
Agenda8: delete t from Agenda9: if t has a foot node and no substitution nodes then10: AgendaA?
AgendaA + t11: else12: for all trees c ?
Chart which can combine with tvia substitution into a new tree ct do13: Agenda?
Agenda + ct14: end for15: Chart?
Chart + t16: end if17: end while18: delete from Chart any tree with a substitution node19: Agenda?
Chart20: Chart?
AgendaA21: while Agenda 6= ?
do22: t?
any tree ?
Agenda23: delete t from Agenda24: if t?s semantics is Sem then25: return the string corresponding to t26: else27: for all trees c ?
Chart which can combine with tvia adjunction into a new tree ct do28: Agenda?
Agenda + ct29: end for30: end if31: end while32: end procedurebuy(e,j,f) annoying(e) field(f)v ache`te (+p -2n) n0Vadj ennuyeux (+p -n) n field (+n)PeN?j Ve N?fache`tePN?e V Adjest ennuyeuxNfterrainjohn(j)n achat (+n -2n) p0Vadj ennuyeux (+p -p) n jean (+n)NeN GP GPachat P N?f P N?jpar dePP?e V Adjest ennuyeuxNjjeanFigure 8: Grammar for example 5Figure 9: A minimised polarity automaton
