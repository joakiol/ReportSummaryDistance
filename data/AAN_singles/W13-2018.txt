Proceedings of the BioNLP Shared Task 2013 Workshop, pages 125?129,Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational LinguisticsIdentification of Genia Events using Multiple ClassifiersRoland Roller and Mark StevensonDepartment of Computer Science,University of SheffieldRegent Court, 211 PortobelloSheffield, S1 4DPUnited Kingdom{R.Roller, M.Stevenson}@dcs.shef.ac.ukAbstractWe describe our system to extract geniaevents that was developed for the BioNLP2013 Shared Task.
Our system uses a su-pervised information extraction platformbased on Support Vector Machines (SVM)and separates the process of event clas-sification into multiple stages.
For eachevent type the SVM parameters are ad-justed and feature selection carried out.We find that this optimisation improvesthe performance of our approach.
Overallour system achieved the highest precisionscore of all systems and was ranked 6thof 10 participating systems on F-measure(strict matching).1 IntroductionThe BioNLP 2013 Shared Task focuses on infor-mation extraction in the biomedical domain andcomprises of a range of extraction tasks.
Our sys-tem was developed to participate within the GeniaEvent Extraction task (GE), which focuses on thedetection of gene events and their regulation.
Thetask considers 13 different types of events whichcan be divided into four groups: simple events,bindings, protein modifications and regulations.All events consist of a core event, which containsa trigger word and a theme.
With the exception ofregulation events, the theme always refer to a pro-tein.
A regulation event theme can either refer toa protein or to another event.
Binding events caninclude up to two proteins as themes.
In additionto the core event, events may include additionalarguments such as ?cause?
or ?to location?.Figure 1 shows examples of events from theBioNLP 2013 corpus.
More details about the Ge-nia Event task can be found in Kim et al(2011).Previous editions of the BioNLP Shared Tasktook place in 2009 (Kim et al 2009) and 2011Figure 1: Two events from the BioNLP 2013 GEtask: a phosphorylation event consisting of a trig-ger and a protein and a positive-regulation eventconsisting of a trigger, a theme referring to anevent and a cause argument.
(Kim et al 2011).
Promising approaches in themost recent competition were event parsing (Mc-Closky et al 2011) and dual decomposition mod-els (Riedel and McCallum, 2011).
The winner ofthe GE task 2011, FAUST (Riedel et al 2011),combined these two approaches by using resultfrom the event parser as an additional input fea-ture for the dual decomposition.The UTurku system of Bjo?rne et al(2009) wasthe winner of the GE task in 2009.
The systemwas based on a pipeline containing three mainstages: trigger detection, argument detection andpost-processing.
Bjo?rne and Salakoski (2011) im-proved the performance of this system for BioNLP2011, but was outperformed by FAUST.Our approach to the BioNLP Shared Task re-lies on separating the process of event classifica-tion into multiple stages and creates separate clas-sifiers for each event type.
Our system begins bypre-processing the input text, followed by multipleclassification stages and a post-processing stage.The pre-processing applies tokenization, sentencesplitting and dictionary-based trigger detection,similar to Bui and Sloot (2011).
Classification isbased on a Support Vector Machine (SVM) anduses three main stages: trigger-protein detection,trigger-event detection and event-cause detection.Post-processing is a combination of classificationand rule-based approaches.
We train a separateclassifier for each event type, rather that relying ona single classifier to recognise trigger-theme rela-125tionships for all event types.
In addition, we alsooptimise the SVM?s parameters and apply featureselection for each event type.Our system participated in subtask 1 of theGE task, which involves the recognition of coreevents, including identification of their ?cause?.The remainder of this paper describes our sys-tem in detail (Section 2), presents results from theGenia Event Extraction task (Section 3) and drawsthe conclusions of this work (Section 4).2 System Description2.1 PreprocessingOur system begins by preprocessing the input text,by applying the sentence splitter and biomedicalnamed entity tagger from LingPipe1.
The sentencesplitter is trained on the MEDLINE data set.
Thetext is then tokenised.
Tokens containing punc-tuation marks are split, as are tokens containinga protein or suffixes which could be utilised asa trigger word.
For instance the term ?Foxp3-expression?
will be split into ?Foxp3 - expression?,since ?Foxp3?
is as a protein and ?expression?
asuffix often used as trigger word.
The tokens arethen stemmed using the Porter Stemmer from theNLTK2 toolkit.
The Stanford Parser3 is used to ex-tract part-of-speech tags, syntax trees and depen-dency trees.2.1.1 Trigger DetectionThe names of proteins in the text are provided inthe GE task, however the trigger words that formpart of the relation have to be identified.
Our sys-tem uses a dictionary-based approach to triggerdetection.
The advantage of this approach is that itis easy to implement and allows us to easily iden-tify as many potential trigger words as possible.However, it will also match many words whichare not true triggers.
We rely on the classificationstage later in our approach to identify the true trig-ger words.A training corpus was created by combining thetraining data from the 2013 Shared Task with allof the data from the 2011 task.
All words that areused as a trigger in this corpus are extracted andstored in a set of dictionaries.
Separate dictionar-ies are created for different event types (e.g.
local-ization, binding).
Each type has its own dictionary,1http://alias-i.com/lingpipe/index.html2http://nltk.org/3http://nlp.stanford.edu/software/lex-parser.shtmlwith the exception of protein modification events(protein modification, phosphorylation, ubiquiti-nation, acetylation, deacetylation).
The corpus didnot contain enough examples of trigger terms forthese events and consequently they are combinedinto a single dictionary.
The words in the dictio-naries are stemmed and sorted by their frequency.Irrelevant words (such as punctuations) are filteredout.Trigger detection is carried out by matching thetext against each of the trigger dictionaries, start-ing with the trigger words with the highest fre-quency.
A word may be annotated as a triggerword by different dictionaries.
If a word is anno-tated as a trigger word for a specific event then itmay not be annotated as being part of another trig-ger word from the same dictionary.
This restric-tion prevents the generation of overlapping triggerwords for the same event as well as preventing toomany words being identified as potential triggers.2.2 ClassificationClassification of relations is based on SVM witha polynomial kernel, using LibSVM (Chang andLin, 2011), and is carried out in three stages.
Thefirst covers the core event, which consists of a trig-ger and a theme referring to a protein.
The secondtakes all classified events and tries to detect regu-lation events consisting of a trigger and a themethat refers to one of these events (see positive-regulation event in figure 1).
In addition to a trig-ger and theme, regulation and protein modificationevents may also include a cause argument.
Thethird stage is responsible for identifying this addi-tional argument for events detected in the previoustwo stages.Classification in each stage is always betweenpairs of object: trigger-protein (stage 1), trigger-event (stage 2), event-protein (stage 3) or event-event (stage 3).
At each stage the role of the clas-sifier is to determine whether there is in fact a re-lation between a given pair of objects.
This ap-proach is unable to identify binding events involv-ing two themes.
These are identified in a post-processing step (see Section 2.3) which consid-ers binding events involving the same trigger wordand decides whether they should be merged or not.2.2.1 Feature SetThe classification process uses a wide range offeatures constructed from words, stemmed words,part of speech tags, NE tags and syntactic analysis.126Object Features: The classification processalways considers a pair of objects (e.g.
trigger-protein, trigger-event, event-protein).
Object fea-tures are derived from the tokens (words, stemmedwords etc.)
which form the objects.
We considerthe head of this object, extracted from the depen-dency tree, as a feature and all other tokens withinthat object as bag of word features.
We also con-sider the local context of each object and includethe three words preceding and following the ob-jects as features.Sentence Features: The tokens between thetwo objects are also used to form features.
Abag of word is formed from the tokens betweenthe features and, in addition, the complete se-quence of tokens is also used as a feature.
Differ-ent sentence features are formed from the words,stemmed words, part of speech tags and NE tags .Syntactic Features: A range of features are ex-tracted from the dependency and phrase-structuretrees generated for each sentence.
These fea-tures are formed from the paths between the theobjects within dependency tree, collapsed depen-dency tree and phrase-structure tree.
The paths areformed from tokens, stemmed tokens etc.The features are organised into 57 groups foruse in the feature selection process described later.For example all of the features relating to the bagof words between the two objects in the depen-dency tree are treated as a single group, as are allof the features related to the POS tags in the threeword range around one of the objects.2.2.2 Generation of Training and Test DataUsing the training data, a set of positive and neg-ative examples were generated to train our classi-fiers.
Pairs of entities which occur in a specificrelation in the training data are used to generatepositive examples and all other pairs used to gen-erate negative ones.
Since we do not attempt toresolve coreference, we only consider pairs of en-tities that occur within the same sentence.Due to the fact that we run a dictionary-basedtrigger detection on a stemmed corpus we mightcover many trigger words, but unfortunately alsomany false ones.
To handle this situation our clas-sifier should learn whether a word serves as a trig-ger of an event or not.
To generate sufficient nega-tive examples we also run the trigger detection onthe training data set, which already contains theright trigger words.2.2.3 Classifier optimisationTwo optimisation steps were applied to the rela-tion classifiers and found to improve their perfor-mance.SVM bias adjustment: The ratio of positiveand negative examples differs in the training datagenerated for each relation.
For instance the datafor the protein catabolism event contains 156 pos-itive examples and 643 negatives ones while thegene expression event has 3617 positive but 34544negative examples.
To identify the best configura-tion for two SVM parameters (cost and gamma),we ran a grid search for each classification stepusing 5-fold cross validation on the training set.Feature Selection: We also perform feature se-lection for each event type.
We remove each fea-ture in turn and carry out 5-fold cross validation onthe training data to identify whether the F-measureimproves.
If improvement is found then the fea-ture that leads to the largest increase in F-measureis removed from the feature set for that event typeand the process repeated.
The process is continueduntil no improvement in F-measure is observedwhen any of the features are removed.
The set offeatures which remain are used as the final set forthe classifier.The feature selection shows the more positivetraining examples we have for an event type thefewer features are removed.
For example, geneexpression events have the highest amount of pos-itive examples (3617) and achieve the best F-measure score without removing any feature.
Onthe other hand, there are just 156 training exam-ples for protein catabolism events and the best re-sults are obtained when 39 features are removed.On average we remove around 14 features for eachevent classifier.
We observed that sentence fea-tures and those derived from the local context ofthe object are those which are removed most of-ten.2.3 Post-ProcessingThe output from the classification stage is post-processed in order to reduce errors.
Two stages ofpost-processing are applied: one of which is basedon a classifier and another which is rule based.Binding Re-Ordering: As already mentionedin Section 2.2, our classification is only capableof detecting single trigger-protein bindings.
How-ever if two binding events share the same trig-ger, they could be merged into a single binding127containing two themes.
A classifier is trained todecide whether to merge pairs of binding events.The classifier is provided with the two themes thatshare a trigger word and is constructed in the sameway as the classifiers that were used for relations.We utilise the same feature set as in the other clas-sification steps and run a grid search to adjust theSVM parameter to decide whether to merge twobindings or not.Rule-Based Post-Processing: The secondstage of post-processing considers all the eventsdetected within a sentence and applies a set ofmanually created rules designed to select the mostlikely.
Some of the most important rules include:?
Assume that the classifier has identified botha simple event (e1) and regulation event (e2)using the same trigger word and theme.
If an-other event uses a different trigger word withe1 as its theme then e2 is removed.?
If transcription and gene expression eventsare identified which use the same trigger andtheme then the gene expression event is re-moved.
This situation occurs since transcrip-tion is a type of a gene expression and theclassifiers applied in Section 2.2 may identifyboth types.?
Assume there are two events (e1 and e2) ofthe same type (e.g.
binding) that use the sametrigger word but refer to different proteins.
Ifthe theme of a regulation event refers to e1then a new regulation event referring to e2 isintroduced.3 ResultsOur approach achieved the highest precision score(63.00) in the formal evaluation in terms of strictmatching in the GE task 1.
The next highest preci-sion scores were achieved by BioSEM (60.67) andNCBI (56.72).
We believe that the classifier opti-misation (Section 2.2.3) for each event and the useof manually created post-processing rules (Section2.3) contributed to the high precision score.
Oursystem was ranked 6th place of 10 in terms of F-measure with a score of 42.06.Table 1 presents detailed results of our systemfor the GE task.
Our approach leads to high preci-sion scores for many of the event types with a pre-cision of 79.23 for all simple events and 92.68 forprotein modifications.
Our system?s performanceis lower for regulation events than other types witha precision of 52.69.
Unlike other types of events,the theme of a regulation event may refer to an-other event.
The detection of regulation events cantherefore be affected by errors in the detection ofsimple events.Results of our system are closer to the best re-ported results when strict matching is used as theevaluation metric.
In this case the F-measure is6.86 lower than the winning system (BioSEM).However, when the approximate span & recursivematching metric is used the results of our sys-tem are 8.74 lower than the best result, which isachieved by the EVEX system.Event Class Recall Prec.
FscoreGene expression 62.20 85.37 71.96Transcription 33.66 45.33 38.64Protein catabolism 57.14 53.33 55.17Localization 23.23 85.19 36.51SIMPLE ALL 54.02 79.23 64.24Binding 31.53 46.88 37.70Phosphorylation 47.50 92.68 62.81PROT-MOD ALL 39.79 92.68 55.68Regulation 11.46 42.86 18.08Positive regulation 23.72 53.60 32.88Negative regulation 20.91 54.19 30.18REG.
ALL 21.14 52.69 30.18EVENT TOTAL 31.57 63.00 42.06Table 1: Evaluation Results (strict matching)4 ConclusionOur approach to the BioNLP GE task 1 was to cre-ate a separate SVM-based classifier for each eventtype.
We adjusted the SVM parameters and ap-plied feature selection for each classifier.
Our sys-tem post-processed the outputs from these classi-fiers using a further classifier (to decide whetherevents should be merged) and manually createdrules (to select between conflicting events).
Re-sults show that our approach achieves the high-est precision of all systems and was ranked 6th interms of F-measure when strict matching is used.In the future we would like to improve the recallof our approach and also aim to explore the use ofa wider range of features.
We would also like toexperiment with post-processing based on a clas-sifier and compare performance with the manuallycreated rules currently used.128ReferencesJari Bjo?rne and Tapio Salakoski.
2011.
Generaliz-ing biomedical event extraction.
In Proceedings ofBioNLP Shared Task 2011 Workshop, pages 183?191, Portland, Oregon, USA, June.
Association forComputational Linguistics.Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2009.
Ex-tracting complex biological events with rich graph-based feature sets.
In Proceedings of the BioNLP2009 Workshop Companion Volume for Shared Task,pages 10?18, Boulder, Colorado, June.
Associationfor Computational Linguistics.Quoc-Chinh Bui and Peter.
M.A.
Sloot.
2011.
Extract-ing biological events from text using simple syntac-tic patterns.
In Proceedings of BioNLP Shared Task2011 Workshop, pages 143?146, Portland, Oregon,USA, June.
Association for Computational Linguis-tics.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A library for support vector machines.
ACMTransactions on Intelligent Systems and Technol-ogy, 2:27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overview ofbionlp?09 shared task on event extraction.
In Pro-ceedings of the BioNLP 2009 Workshop CompanionVolume for Shared Task, pages 1?9, Boulder, Col-orado, June.
Association for Computational Linguis-tics.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-nori Yonezawa.
2011.
Overview of genia eventtask in bionlp shared task 2011.
In Proceedings ofBioNLP Shared Task 2011 Workshop, pages 7?15,Portland, Oregon, USA, June.
Association for Com-putational Linguistics.David McClosky, Mihai Surdeanu, and ChristopherManning.
2011.
Event extraction as dependencyparsing for bionlp 2011.
In Proceedings of BioNLPShared Task 2011 Workshop, pages 41?45, Portland,Oregon, USA, June.
Association for ComputationalLinguistics.Sebastian Riedel and Andrew McCallum.
2011.
Ro-bust biomedical event extraction with dual decom-position and minimal domain adaptation.
In Pro-ceedings of BioNLP Shared Task 2011 Workshop,pages 46?50, Portland, Oregon, USA, June.
Asso-ciation for Computational Linguistics.Sebastian Riedel, David McClosky, Mihai Surdeanu,Andrew McCallum, and Christopher D. Manning.2011.
Model combination for event extraction inbionlp 2011.
In Proceedings of BioNLP SharedTask 2011 Workshop, pages 51?55, Portland, Ore-gon, USA, June.
Association for Computational Lin-guistics.129
