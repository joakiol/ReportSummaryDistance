Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 21?30,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsEnhancing Medical Named Entity Recognitionwith Features Derived from Unsupervised MethodsMaria SkeppstedtDept.
of Computer and Systems Sciences (DSV)Stockholm University, Forum 100, 164 40 Kista, Swedenmariask@dsv.su.seAbstractA study of the usefulness of features ex-tracted from unsupervised methods is pro-posed.
The usefulness of these featureswill be studied on the task of performingnamed entity recognition within one clin-ical sub-domain as well as on the task ofadapting a named entity recognition modelto a new clinical sub-domain.
Four namedentity types, all very relevant for clini-cal information extraction, will be studied:Disorder, Finding, Pharmaceutical Drugand Body Structure.
The named entityrecognition will be performed using con-ditional random fields.
As unsupervisedfeatures, a clustering of the semantic rep-resentation of words obtained from a ran-dom indexing word space will be used.1 IntroductionCreating the annotated corpus needed for traininga NER (named entity recognition) model is costly.This is particularly the case for texts in specialiseddomains, for which expert annotators are often re-quired.
In addition, the need for expert annotatorsalso limits the possibilities of using crowdsourcingapproaches (e.g.
Amazon Mechanical Turk).
Fea-tures from unsupervised machine-learning meth-ods, for which no labelled training data is required,have, however, been shown to improve the per-formance of NER systems (Jonnalagadda et al.,2012).
It is therefore likely that by incorporatingfeatures from unsupervised methods, it is possibleto reduce the amount of training data needed toachieve a fixed level of performance.Due to differences in the use of language, anNLP system developed for, or trained on, textfrom one sub-domain often shows a drop in per-formance when applied on texts from another sub-domain (Martinez et al., 2013).
This has the ef-fect that when performing NER on a new sub-domain, annotated text from this new targeted sub-domain might be required, even when there areannotated corpora from other domains.
It would,however, be preferable to be able to apply a NERmodel trained on text from one sub-domain on an-other sub-domain, with only a minimum of addi-tional data from this other targeted sub-domain.Incorporating features from unsupervised meth-ods might limit the amount of additional annotateddata needed for adapting a NER model to a newsub-domain.The proposed study aims at investigating theusefulness of unsupervised features, both for NERwithin one sub-domain and for domain adaptationof a NER model.
The study has two hypotheses.?
Within one subdomain:For reaching the same level of performancewhen training a NER model, less trainingdata is required when unsupervised featuresare used.?
For adapting a model trained on one subdo-main to a new targeted subdomain:For reaching the same level of performancewhen adapting a NER model to a new subdo-main, less additional training data is requiredin the new targeted subdomain when unsu-pervised features are used.For both hypotheses, the level of performance isdefined in terms of F-score.The proposed study will be carried out on dif-ferent sub-domains within the specialised text do-main of clinical text.2 Related researchThere are a number of previous studies on namedentity recognition in clinical text.
For instance,a corpus annotated for the entities Condition,21Drug/Device and Locus was used for traininga support vector machine with uneven margins(Roberts et al., 2008) and a corpus annotated forthe entities Finding, Substance and Body was usedfor training a conditional random fields (CRF) sys-tem (Wang, 2009) as well as for training an en-semble of different classifiers (Wang and Patrick,2009).
Most studies have, however, been con-ducted on the i2b2 medication challenge corpusand the i2b2 challenge on concepts, assertions,and relations corpus.
Conditional random fields(Patrick and Li, 2010) as well as an ensemble clas-sifier (Doan et al., 2012) has for instance been usedfor extracting the entity Medication names fromthe medication challenge corpus, while all but thebest among the top-performing systems used CRFfor extracting the entities Medical Problem, Testand Treatment from the i2b2 challenge on con-cepts, assertions, and relations corpus (Uzuner etal., 2011).
The best system (de Bruijn et al., 2011)used semi-Markov HMM, and in addition to thefeatures used by most of the other systems (e.g.tokens/lemmas/stems, orthographics, affixes, part-of-speech, output of terminology matching), thissystem also used features extracted from hierarchi-cal word clusters on un-annotated text.
For con-structing the clusters, they used Brown clustering,and represented the feature as a 7-bit showing towhat cluster a word belonged.Outside of the biomedical domain, there aremany studies on English corpora, which haveshown that using features extracted from clustersconstructed on unlabelled corpora improves per-formance of NER models, especially when usinga smaller amount of training data (Miller et al.,2004; Freitag, 2004).
This approach has also beenshown to be successful for named entity recogni-tion in other languages, e.g.
German, Dutch andSpanish (T?ackstr?om et al., 2012), as well as onrelated NLP tasks (Biemann et al., 2007), andthere are NER tools that automatically incorpo-rate features extracted from unsupervised methods(Stanford, 2012).
There are a number of addi-tional studies within the biomedical domain, e.g.using features from Brown and other clusteringapproaches (Stenetorp et al., 2012) or from k-means clustered vectors from a neural networks-based word space implementation (Pyysalo et al.,2014).
Jonnalagadda et al.
(2012) also present astudy in which unsupervised features are used fortraining a model on the i2b2 challenge on con-cepts, assertions, and relations corpus.
As un-annotated corpus, they used a corpus created byextracting Medline abstracts that are indexed withthe publication type ?clinical trials?.
They thenbuilt a semantic representation of this corpus inthe form of a random indexing-based word space.This representation was then used for extracting anumber of similar words to each word in the i2b2challenge on concepts, assertions, and relationscorpus, which were used as features when traininga CRF system.
The parameters of the random in-dexing model were selected by letting the nearestneighbours of a word vote for one of the UMLScategories Medical Problem, Treatment and Testaccording to the category of the neighbour, and bycomparing the category winning the vote to the ac-tual category of the word.
The authors motivatetheir choice of using random indexing for creat-ing features with that this method is scalable tovery large corpora without requiring large compu-tational resources.The method proposed here is similar to themethod used by Jonnalagadda et al.
(2012).
How-ever, the focus of the proposed study is to exploreto what extent unsupervised features can help amachine learning system trained only on very lit-tle data.
It is therefore not feasible to use the largenumber of features that would be generated byusing neighbouring words, as that would requirea large training data set to ensure that there areenough training examples for each generated fea-ture.
Therefore, the proposed method instead fur-ther processes the word space model by construct-ing clusters of semantically related words, therebyreducing the number of generated features, similarto the approach by Pyysalo et al.
(2014).3 Materials and previous resultsTexts from three different clinical sub-domains:cardiac ICU (intensive care unit), orthopaedic ER(emergency room), and internal medicine ER havebeen annotated (Tables 1-3).1All texts are writtenin Swedish, and they all share the characteristicsof text types written under time pressure; all ofthem containing many abbreviations and incom-plete sentences.
There are, however, also differ-ences in e.g.
what abbreviations are used and what1Research on these texts aiming at extracting informa-tion related to Disorders/Findings and Pharmaceutical Drugshas been approved by the Regional Ethical Review Boardin Stockholm (Etikpr?ovningsn?amnden i Stockholm), permis-sion number 2012/834-31/5.22Data set: AllEntity category # entities (Unique)Disorder 1088 (533)Finding 1798 (1295)Pharmaceuticals 1048 (497)Body structure 461 (252)Table 1: Annotated data, Cardiac ICUData set: AllEntity category # entities (Unique)Disorder 1258 (541)Finding 1439 (785)Pharmaceuticals 880 (212)Body structure 1324 (423)Table 2: Annotated data, Orthopaedic ERentities that are frequently mentioned.The texts from cardiac ICU and orthopaedic ERwill be treated as existing annotations in a cur-rent domain, whereas internal medicine ER willbe treated as the new target domain.
Approxi-mately a third of the texts from internal medicineER have been doubly annotated, and an evaluationset has been created by manually resolving differ-ences between the two annotators (Skeppstedt etal., 2014).
This evaluation subset will be used asheld-out data for evaluating the NER task.The following four entity categories have beenannotated (Skeppstedt et al., 2014): (1) Disorder(a disease or abnormal condition that is not mo-mentary and that has an underlying pathologicalprocess), (2) Finding (a symptom reported by thepatient, an observation made by the physician orthe result of a medical examination of the patient),(3) Pharmaceutical Drug (not limited to genericname or trade name, but includes also e.g.
drugsexpressed by their effect, such as painkiller orsleeping pill).
(4) Body Structure (an anatomicallydefined body part).These three annotated corpora will be used inthe proposed study, together with a large corpusof un-annotated text from which unsupervised fea-tures will be extracted.
This large corpus will be asubset of the Stockholm EPR corpus (Dalianis etal., 2009), which is a large corpus of clinical textwritten in Swedish.Named entity recognition on the internalmedicine ER part of the annotated corpus has al-ready been studied, and results on the evaluationset were an F-score of 0.81 for the entity Dis-order, 0.69 for Finding, 0.88 for PharmaceuticalDrug, 0.85 for Body Structure and 0.78 for thecombined category Disorder + Finding (Skeppst-edt et al., 2014).
Features used for training themodel on the development/training part of the in-ternal medicine ER corpus were the lemma formsof the words, their part of speech, their semanticcategory in used vocabulary lists, their word con-stituents (if the words were compounds) as wellas the orthographics of the words.
A narrow con-text window was used, as shown by the entriesmarked in boldface in Figure 1.
As terminologies,the Swedish versions of SNOMED CT2, MeSH3,ICD-104, the Swedish medical list FASS5wereused, as well as a vocabulary list of non-medicalwords, compiled from the Swedish Parole corpus(Gellerstam et al., 2000).4 Methodological backgroundThe proposed method consists of using the train-ing data first for parameter setting (through n-fold cross-validation) and thereafter for training amodel using the best parameters.
This model isthen to be evaluated on held-out data.
A numberof rounds with parameter setting and training willbe carried out, where each new round will makeuse of an increasingly larger subset of the trainingdata.
Two versions of parameter setting and modeltraining will be carried out for each round; oneusing features obtained from unsupervised meth-ods on un-annotated text and one in which suchfeatures are not used.
The results of the two ver-sions are then to be compared, with the hypothesisthat the model incorporating unsupervised meth-ods will perform better, at least for small trainingdata sizes.To accomplish this, the proposed method makesuse of four main components: (1) A system fortraining a NER model given features extractedfrom an annotated corpus.
As this component, aconditional random fields (CRF) system will beused.
(2) A system for automatic parameter set-ting.
As a large number of models are to be con-structed on different sizes of the training data, forwhich optimal parameters are likely to differ, pa-rameters for each set of training data has to bedetermined automatically for it to be feasible to2www.ihtsdo.org3mesh.kib.ki.se4www.who.int/classifications/icd/en/5www.fass.se23Data set: Development Final evaluationEntity category # entities (Unique) # entitiesDisorder 1,317 (607) 681Finding 2,540 (1,353) 1282Pharmaceuticals 959 (350) 580Body structure 497 (197) 253Tokens in corpus 45,482 25,370Table 3: Annotated entities, internal medicine ERToken    Lemma    POS    Termi-  Compound   Ortho-   Cluster member-  ..
Cluster member-  Category                nology         graphics  ship level 1    ship level nDVT    dvt    noun   disorder  -   -   all upper  #40     .. #39423    B-Disorderpatient    patient   noun   person  -   -   -    #3      .. #23498    Owith     with    prep.
parole  -   -   -    #14     .. #30892    Ochestpain	 	 chestpain	 	 noun		 	 finding	 	 chest		 pain	 	 -							 	 	 #40     .. #23409    B-Finding  Currentand    and    conj.
parole  -   -   -    -      .. -      Oproblems	 	 problem	 	 	 noun	 	 	 finding	 	 -   -   -    #40     .. #23409    B-Findingto	 	 	 	 	 to	 	 	 	 	 prep.
finding	 	 -   -   -    -      .. -      I-Findingbreathe	 	 	 breathe	 	 	 verb	 	 	 finding	 	 -   -   -    #90     .. #23409    I-FindingFigure 1: A hypothetical example sentence, with hypothetical features for training a machine learningmodel.
Features used in a previous medical named entity recognition study (Skeppstedt et al., 2014) onthis corpus are shown in boldface.
The last column contains the entity category according to the manualannotation.carry out the experiments.
(3) A system for rep-resenting semantic similarity of the words in theun-annotated corpus.
As this component, a ran-dom indexing based word space model will used.
(4) A system for turning the semantic representa-tion of the word space model into features to usefor the NER model.
As this component, clusteringwill be used.To give a methodological background, the theo-retical foundation for the four components will bedescribed.4.1 Conditional random fieldsConditional random fields (CRF or CRFs), intro-duced by Lafferty et al.
(2001), is a machine learn-ing method suitable for segmenting and labellingsequential data and therefore often used for e.g.named entity recognition.
As described in the re-lated research section, CRFs have been used in anumber of studies for extracting entities from clin-ical text.
In contrast to many other types of data,observed data points for sequential data, such astext, are dependent on other observed data points.Such dependences between data points are prac-tical to describe within the framework of graphi-cal models (Bishop, 2006, p. 359), to which CRFbelongs (Sutton and McCallum, 2006, p. 1).
Inthe special, but frequently used, case of linearchain CRF, the output variables are linked in achain.
Apart from being dependent on the inputvariables, each output variable is then condition-ally independent on all other output variables, ex-cept on the previous and following output variable,given these two neighbouring output variables.
Ina named entity recognition task, the output vari-ables are the named entity classes that are to bepredicted and the observed input variables are ob-served features of the text, such as the tokens ortheir part-of-speech.CRF is closely related to Hidden Markov Mod-els, which is also typically described as a graph-ical model.
A difference, however, is that Hid-den Markov Models belongs to the class of gener-ative models, whereas CRF is a conditional model(Sutton and McCallum, 2006, p. 1).
Generativemodels model the joint distribution between inputvariables and the variables that are to be predicted(Bishop, 2006, p. 43).
In contrast, CRF and otherconditional models instead directly model the con-ditional distribution, enabling the use of a larger24feature set (Sutton and McCallum, 2006, p. 1).For named entity recognition, the IOB-encoding is typically used for encoding the out-put variables.
Tokens not annotated as an entityare then encoded with the label O, whereas labelsfor annotated tokens are prefixed with a B, if itis the first token in the annotated chunk, and anI otherwise (Jurafsky and Martin, 2008, pp.
763?764).
An example of this encoding is shown in thelast column in Figure 1.
In this case, where thereare four types of entities, the model thus learns toclassify in 8+1 different classes: B-Disorder, I-Disorder, B-Finding, I-Finding, B-Drug, I-Drug,B-BodyStructure, I-BodyStructure and O.The dependencies are defined by a large numberof (typically binary) feature functions of input andoutput variables.
E.g.
is all of the following true??
Output: The output at the current position isI-Disorder?
Output: The output at the previous position isB-Disorder?
Input: The token at the current position ischest-pain?
Input: The token at the previous position isexperiencesA feature function in a linear chain CRF canonly include the values of the output variable incurrent position and in the immediate previous po-sition, whereas it can include, and thereby show adependence on, input variables from any position.The CRF model is trained through settingweights for the feature functions, which is carriedout by penalised maximum likelihood.
Penalisedmeans that regularisation is used, and regularisa-tion is performed by adding a penalty term, whichprevents the weights from reaching too large val-ues, and thereby prevents over-fitting (Bishop,2006, p. 10).
The L1-norm and the L2-norm arefrequently used for regularisation (Tsuruoka et al.,2009), and a variable C governs the importanceof the regularisation.
Using the L1-norm also re-sults in that if C is large enough, some of theweights are driven to zero, resulting in a sparsemodel and thereby the feature functions that thoseweights control will not play any role in the model.Thereby, complex models can be trained also ondata sets with a limited size, without being over-fitted.
However, a suitable value of C must still bedetermined (Bishop, 2006, p. 145).The plan for the proposed study is to use theCRF package CRF++6, which has been used in anumber of previous NER studies, also in the med-ical domain.
The CRF++ package automaticallygenerates feature functions from user-defined tem-plates.
When using CRF++ as a linear chain CRF,it generates one binary feature function for eachcombination of output class, previous output classand unique string in the training data that is ex-panded by a template.
This means that L * L *M feature functions are generated for each tem-plate, where L = the number of output classes andM = the number of unique expanded strings.
Ifonly the current token were to be used as a fea-ture, the number of feature functions would be9?9?|unique tokens in the corpus|.
In practice,a lot of other features are, however, used.
Most ofthese features will be of no use to the classifier,which means that it is important to use an infer-ence method that sets the weights of the featurefunctions with irrelevant features to zero, thus aninference method that promotes sparsity.4.2 Parameter settingAs previously explained, a large number of mod-els are to be constructed, which requires a simpleand efficient method for parameter setting.
An ad-vantage with using the L1-norm is that only oneparameter, the C-value, has to be optimised, as theweights for feature functions are driven to zero forfeature functions that are not useful.
The L1-normwill therefore be used in the proposed study.
Avery large feature set can then be used, withoutrunning the risk of over-fitting the model.
Featureswill include those that have been used in previousclinical NER studies (Jonnalagadda et al., 2012;de Bruijn et al., 2011; Skeppstedt et al., 2014),with a context window of four previous and fourfollowing tokens.When maximising the conditional log likeli-hood of the parameters, the CRF++ program willset parameters that are optimal for training themodel for the best micro-averaged results for thefour classes Disorder, Finding, Pharmaceuticaldrug and Body structure.
A hill climbing search(Marsland, 2009, pp.
262?264) for finding a goodC-value will be used, starting with a value veryclose to zero and thereafter changing it in a direc-tion that improves the NER results.
A decreas-ingly smaller step size will be used for changing6crfpp.sourceforge.net25Lemmatised and stop word filtered with a window size of 2 (1+1):complain dermatitis eczema itch patientcomplain: [0 0 0 2 2]dermatitis: [0 0 0 1 0]eczema: [0 0 0 1 0]itch: [2 1 1 0 0]patient: [2 0 0 0 0]Figure 2: Term-by-term co-occurrence matrix forthe small corpus ?Patient complains of itching der-matitis.
Patient complains of itching eczema.
?the C-value, until only small changes in the resultscan be observed.4.3 Random indexingRandom indexing is one version of the word spacemodel, and as all word space models it is a methodfor representing distributional semantics.
The ran-dom indexing method was originally devised byKanerva et al.
(2000), to deal with the performanceproblems (in terms of memory and computationtime) that were associated with the LSA/LSI im-plementations at that time.
Due to its computa-tional efficiency, random indexing remains to bea popular method when building distributional se-mantics models on very large corpora, e.g.
largeweb corpora (Sahlgren and Karlgren, 2009) orMedline abstracts (Jonnalagadda et al., 2012).Distributional semantics is built on the distribu-tional hypothesis, which states that ?Words withsimilar meanings tend to occur in similar con-texts?.
If dermatitis and eczema often occur insimilar contexts, e.g.
?Patient complains of itch-ing dermatitis?
and ?Patient complains of itchingeczema?, it is likely that dermatitis and eczemahave a similar meaning.
One possible methodof representing word co-occurrence information isto construct a term-by-term co-occurrence matrix,i.e.
a matrix of dimensionality w ?
w, in which wis the number of terms (unique semantic units, e.g.words) in the corpus.
The elements of the matrixthen contain the number of times each semanticunit occurs in the context of each other semanticunit (figure 2).The context vectors of two semantic units canthen be compared as a measure of semantic sim-ilarity between units, e.g.
using the the euclid-ian distance between normalised context vectorsor the cosine similarity.1 2 3 ... d... [0 0 1 ... 0]complain: [0 0 0 ... 1]itch: [0 1 1 ... 0]patient: [-1 0 0 ... 0]... [... ... ... ... ..]word w [0 0 -1 ... 0]Figure 3: Index vectors.The large dimension of a term-by-term ma-trix leads, however, to scalability problems, andthe typical solution to this is to apply dimen-sionality reduction on the matrix.
In a semanticspace created by latent semantic analysis, for in-stance, dimensionality reduction is performed byapplying the linear algebra matrix operation sin-gular value decomposition (Landauer and Dutnais,1997).
Random indexing is another solution, inwhich a matrix with a smaller dimension is createdfrom start, using the following method (Sahlgrenet al., 2008):Each term in the data is assigned a unique rep-resentation, called an index vector.
The index vec-tors all have the dimensionality d (where d ?
1000but w).
Most of the elements of the index vec-tors are set to 0, but a few, randomly selected, el-ements are set to either +1 or -1.
(Usually around1-2% of the elements.)
Instead of having orthogo-nal vectors, as is the case for the term-by-term ma-trix, the index vectors are nearly orthogonal.
(SeeFigure 3.
)Each term in the data is also assigned a contextvector, also of the dimensionality d. Initially, allelements in the context vectors are set to 0.
Thecontext vector of each term is then updated by, forevery occurrence of the term in the corpus, addingthe index vectors of the neighboring words.
Theneighboring words are called the context window,and this can be both narrow or wide, depending onwhat semantic relations the word space model isintended to capture.
The size of the context win-dow can have large impact on the results (Sahlgrenet al., 2008), and for detecting paradigmatic re-lations (i.e.
words that occur in similar contexts,rather than words that occur together) a fairly nar-row context window has been shown to be mosteffective.The resulting context vectors form a matrix ofdimension w?d.
This matrix is an approximationof the term-by-term matrix, and the same similar-26Index vectors (never change)1 2 3 ... d...itching: [0 1 1 ... 0]patient: [-1 0 0 ... 0]...___________________________________________________________Context vectors1 2 3 ... d...complain: [-1 1 1 ...
0]...Figure 4: The updated context vectors.0Known term from an other entity categoryKnown term from one entity categoryUnknown term0?dermatitiseczemaMeasure similarity between two terms by e.g.
cosine  ?C1C2C3C4Figure 5: Context vectors for terms in a hypothet-ical word space with d=2.
The context vectors forthe semantically similar words eczema and der-matitis are close in the word space, in which close-ness is measured as the cosine of the angle be-tween the vectors.
Four hypothetical clusters (C1-C4) of context vectors are also shown; clusters thatcontain a large proportion of known terms.ity measures can be applied.A hypothetical word space with d=2 is shown inFigure 5.4.4 ClusteringAs mentioned earlier, for the word space informa-tion to be useful for training a CRF model on asmall data set, it must be represented as a featurethat can only take a limited number of differentvalues.
The proposed methods for achieving thisis to cluster the context vectors of the word spacemodel, similar to what has been done in previousresearch (Pyysalo et al., 2014).
Also similar toprevious research, cluster membership for a wordin the NER training and test data will be used as afeature.
Four named hypothetical clusters of con-text vectors are shown in the word space modelin Figure 5 to illustrate the general idea, and anexample of how to use cluster membership as afeature is shown Figure 1.Different clustering techniques will be evalu-ated, for the quality of the created clusters, as wellas for their computational efficiency.
Having hi-erarchical clusters might be preferable, as clus-ter membership to clusters of different granular-ity then can be offered as features for training theCRF model.
Which granularity that is most suit-able might vary depending on the entity type andalso depending on the size of the training data.However, e.g.
performing hierarchical agglomera-tive clustering (Jurafsky and Martin, 2008, p. 700)on the entire unlabelled corpus might be computa-tionally intractable (thereby defeating the purposeof using random indexing), as it requires pairwisecomparisons between the words in the corpus.
Thepairwise comparison is a part of the agglomera-tive clustering algorithm, in which each word isfirst assigned its own cluster and then each pair ofclusters is compared for similarity, resulting in amerge of the most similar clusters.
This processis thereafter iteratively repeated, having the dis-tance between the centroids of the clusters as sim-ilarity measure.
An alternative, which requires aless efficient clustering algorithm, would be to notcreate clusters of all the words in the corpus, butto limit initially created clusters to include thosewords that occur in available terminologies.
Clus-ter membership of unknown words in the corpuscould then be determined by measuring similarityto the centroids of these initially created clusters.Regardless of what clustering technique that ischosen, the parameters of the random indexingmodels, as well as of the clustering, will be deter-mined by evaluating to what extent words that be-long to one of the studied semantic categories (ac-cording to available terminologies) are clusteredtogether.
This will be measured using purity andinverse purity (Amig?o et al., 2009).
However, ifclusters are to be created from all words in the cor-pus, the true semantic category will only be knownfor a very small subset of clustered words.
In thatcase, the two measures have to be defined as puritybeing to what extent a cluster only contains knownwords of one category and inverse purity being theextent to which known words of the same categoryare grouped into the same cluster.275 Proposed experimentsThe first phase of the experiments will consist offinding the best parameters for the random index-ing model and the clustering, as described above.The second phase will consist of evaluating theusefulness of the clustered data for the NER task.Three main experiments will be carried out in thisphase (I, II and III), using data set(s) from the fol-lowing sources:I: Internal medicine ERII: Internal medicine ER + Cardiac ICUIII: Internal medicine ER + Orthopaedic ERIn each experiment, the following will be car-ried out:1.
Divide internal medicine ER training datainto 5 partitions (into a random division, tobetter simulate the situation when not all datais available, using the same random divisionfor all experiments).2.
Run step 3-5 in 5 rounds.
Each new rounduses one additional internal medicine ER par-tition: (Experiments II and III always use theentire data set from the other domain).
Ineach round, two versions of step 3-5 will becarried out:(a) With unsupervised features.
(b) Without unsupervised features.3.
Use training data for determining C-value (byn-fold cross-validation).4.
Use training data for training a model withthis C-value.5.
Evaluate the model on the held-out internalmedicine ICU data.6 Open issuesWhat clustering technique to use has previouslybeen mentioned as one important open issue.
Thefollowing are examples of other open issues:?
Could the information obtained from randomindexing be used in some other way than astransformed to cluster membership features?Jonnalagadda et al.
(2012) used the termsclosest in the semantic space as a feature.Could this method be adapted in some wayto models constructed with a small amountof training data?
For instance by restrictingwhat terms are allowed to be used as such afeature, and thereby limiting the number ofpossible values this feature can take.?
Would it be better to use other approaches (orcompare different approaches) for obtainingfeatures from unlabelled data?
A possibil-ity could be to use a more standard cluster-ing approach, such as Brown clustering usedin previous clinical NER studies (de Bruijnet al., 2011).
Another possibility could be tokeep the idea of creating clusters from vec-tors in a word space model, but to use othermethods than random indexing for construct-ing the word space; e.g.
the previously men-tioned latent semantic analysis (Landauer andDutnais, 1997), or a neural networks-basedword space implementation (Pyysalo et al.,2014).?
Many relevant terms within the medical do-main are multi-word terms (e.g.
of the typediabetes mellitus), and there are studies onhow to construct semantic spaces with suchmultiword terms as the smallest semanticunit (Henriksson et al., 2013).
Should thewhitespace segmented token be treated as thesmallest semantic unit in the proposed study,or should the use of larger semantic units beconsidered?AcknowledgementsMany thanks to Aron Henriksson, Alyaa Alfalahi,Maria Kvist, Gunnar Nilsson and Hercules Dalia-nis for taking a very active part in the planing ofthe proposed study, as well as to the three anony-mous reviewers for their constructive and detailedcomments.ReferencesEnrique Amig?o, Julio Gonzalo, Javier Artiles, and Fe-lisa Verdejo.
2009.
A comparison of extrinsicclustering evaluation metrics based on formal con-straints.
Inf.
Retr., 12(4):461?486, aug.Chris Biemann, Claudio Giuliano, and Alfio Gliozzo.2007.
Unsupervised part of speech tagging support-ing supervised methods.
In RANLP.Christopher M. Bishop.
2006.
Pattern recognition andmachine learning.
Springer, New York, NY.28Hercules Dalianis, Martin Hassel, and SumithraVelupillai.
2009.
The Stockholm EPR Corpus -Characteristics and Some Initial Findings.
In Pro-ceedings of ISHIMR 2009, Evaluation and imple-mentation of e-health and health information initia-tives: international perspectives.
14th InternationalSymposium for Health Information Management Re-search, Kalmar, Sweden, pages 243?249.Berry de Bruijn, Colin Cherry, Svetlana Kiritchenko,Joel D. Martin, and Xiaodan Zhu.
2011.
Machine-learned solutions for three stages of clinical infor-mation extraction: the state of the art at i2b2 2010.J Am Med Inform Assoc, 18(5):557?562.Son Doan, Nigel Collier, Hua Xu, Hoang Duy Pham,and Minh Phuong Tu.
2012.
Recognition of medi-cation information from discharge summaries usingensembles of classifiers.
BMC Med Inform DecisMak, 12:36.Dayne Freitag.
2004.
Trained named entity recogni-tion using distributional clusters.
In EMNLP, pages262?269.M Gellerstam, Y Cederholm, and T Rasmark.
2000.The bank of Swedish.
In LREC 2000.
The 2nd In-ternational Conference on Language Resources andEvaluation, pages 329?333, Athens, Greece.Aron Henriksson, Mike Conway, Martin Duneld, andWendy W. Chapman.
2013.
Identifying syn-onymy between SNOMED clinical terms of vary-ing length using distributional analysis of electronichealth records.
In Proceedings of the Annual Sym-posium of the American Medical Informatics Asso-ciation (AMIA 2013), Washington DC, USA.Siddhartha Jonnalagadda, Trevor Cohen, Stephen Wu,and Graciela Gonzalez.
2012.
Enhancing clinicalconcept extraction with distributional semantics.
JBiomed Inform, 45(1):129?40, Feb.Daniel Jurafsky and James H. Martin.
2008.
Speechand Language Processing: An Introduction to Nat-ural Language Processing, Computational Linguis-tics and Speech Recognition.
Prentice Hall, secondedition, February.Pentti Kanerva, Jan Kristoferson, and Anders Holst.2000.
Random indexing of text samples for latentsemantic analysis.
In L. R. Gleitman and A. K.Joshi, editors, Proceedings of the 22nd Annual Con-ference of the Cognitive Science Society, Mahwah,NJ.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proc.
18th International Conf.
onMachine Learning, pages 282?289.
Morgan Kauf-mann, San Francisco, CA.Thomas K Landauer and Susan T. Dutnais.
1997.
Asolution to Plato?s problem: The latent semanticanalysis theory of acquisition, induction, and rep-resentation of knowledge.
Psychological review,pages 211?240.Stephen Marsland.
2009.
Machine learning : an algo-rithmic perspective.
Chapman & Hall/CRC, BocaRaton, FL.David Martinez, Lawrence Cavedon, and Graham Pit-son.
2013.
Stability of text mining techniques foridentifying cancer staging.
In Proceedings of the 4thInternational Louhi Workshop on Health DocumentText Mining and Information Analysis - Louhi 2013,Sydney, Australia, February.Scott Miller, Jethran Guinness, and Alex Zamanian.2004.
Name tagging with word clusters and dis-criminative training.
In Proceedings of HLT, pages337?342.Jon Patrick and Min Li.
2010.
High accuracy infor-mation extraction of medication information fromclinical notes: 2009 i2b2 medication extraction chal-lenge.
J Am Med Inform Assoc, 17(5):524?527,Sep-Oct.Sampo Pyysalo, Filip Ginter, Hans Moen, TapioSalakoski, and Sophia Ananiadou.
2014.
Distribu-tional semantics resources for biomedical text pro-cessing.
In Proceedings of Languages in Biologyand Medicine.Angus Roberts, Robert Gaizasukas, Mark Hepple, andYikun Guo.
2008.
Combining terminology re-sources and statistical methods for entity recogni-tion: an evaluation.
In Proceedings of the SixthInternational Conference on Language Resourcesand Evaluation (LREC?08), pages 2974?2979, Mar-rakech, Morocco, may.
European Language Re-sources Association (ELRA).
http://www.lrec-conf.org/proceedings/lrec2008/.Magnus Sahlgren and Jussi Karlgren.
2009.
Termi-nology mining in social media.
In Proceedings ofthe 18th ACM conference on Information and knowl-edge management, CIKM ?09.Magnus Sahlgren, Anders Holst, and Pentti Kanerva.2008.
Permutations as a means to encode orderin word space.
In Proceedings of the 30th An-nual Meeting of the Cognitive Science Society, pages1300?1305.Maria Skeppstedt, Maria Kvist, Gunnar H Nilsson, andHercules Dalianis.
2014.
Automatic recognition ofdisorders, findings, pharmaceuticals and body struc-tures from clinical text: An annotation and machinelearning study.
J Biomed Inform, Feb (in press).NLP Group Stanford.
2012.
Stanford NamedEntity Recognizer (NER).
http://www-nlp.stanford.edu/software/CRF-NER.shtml.
Ac-cessed 2012-03-29.29Pontus Stenetorp, Hubert Soyer, Sampo Pyysalo,Sophia Ananiadou, and Takashi Chikayama.
2012.Size (and domain) matters: Evaluating semanticword space representations for biomedical text.
InProceedings of the 5th International Symposium onSemantic Mining in Biomedicine.Charles.
Sutton and Andrew McCallum.
2006.
An in-troduction to conditional random fields for relationallearning.
In Lise Getoor and Ben Taskar, editors,Introduction to Statistical Relational Learning.
MITPress.Oscar T?ackstr?om, Ryan McDonald, and Jakob Uszko-reit.
2012.
Cross-lingual Word Clusters for DirectTransfer of Linguistic Structure.
In Proceedings ofthe 2012 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pages 477?487, Montr?eal, Canada, June.
Association for Com-putational Linguistics.Yoshimasa Tsuruoka, Jun?ichi Tsujii, and Sophia Ana-niadou.
2009.
Fast full parsing by linear-chain con-ditional random fields.
In Proceedings of the 12thConference of the European Chapter of the Asso-ciation for Computational Linguistics, EACL ?09,pages 790?798, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.?Ozlem.
Uzuner, Brett R. South, Shuying Shen, andScott L. DuVall.
2011.
2010 i2b2/va challenge onconcepts, assertions, and relations in clinical text.
JAm Med Inform Assoc, 18(5):552?556.Yefeng Wang and Jon Patrick.
2009.
Cascading clas-sifiers for named entity recognition in clinical notes.In Proceedings of the Workshop on Biomedical In-formation Extraction, pages 42?49.Yefeng Wang.
2009.
Annotating and recognisingnamed entities in clinical notes.
In Proceedings ofthe ACL-IJCNLP Student Research Workshop, pages18?26, Singapore.30
