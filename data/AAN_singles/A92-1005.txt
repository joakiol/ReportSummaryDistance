Real-time linguistic analysis for continuous speech understanding*Pao lo  Bagg ia  E l i sabet ta  Gerb ino  Eg id io  G iach in  C laud io  Ru l lentCSELT - Centro Studi e Laboratori TelecomunicazioniVia Reiss Romoli, 274 - 10148 Torino, ItalyAbstractThis paper describes the approach followedin the development of the linguistic proces-sor of the continuous speech dialog system im-plemented at our labs.
The application sce-nario (voice-based information retrieval ser-vice over the telephone) poses severe specifi-cations to the system: it has to be speaker-independent, to deal with noisy and corruptedspeech, and to work in real time.
To copewith these types of applications requires toimprove both efficiency and accuracy.
Atpresent, the system accepts telephone-qualityspeech (utterances referring to an electronicmailbox access, recorded through a PABX)and, in the speaker-independent configuration,it correctly understands 72% of the utterancesin about twice real time.
Experimental resultsare discussed, as obtained from an implemen-tation of the system on a Sun SparcStation 1using the C language.1 I n t roduct ionWe call continuous speech, as opposed to isolated-word speech, any utterance mitted without interposingpauses between words.
This is the way humans natu-rally speak, but to enable a machine to deal with thisform of communication constitutes a difficult task be-cause, in addition to the usual speech processing andnatural language issues, there is no hint on where thesingle words of the utterance begin and end.
Giventhe current state-of-the-art, speech understanding pro-totypes concern the comprehension f utterances refer-ring to a well defined semantic domain on a dictionaryof almost one thousand words.Our research group is interested in developing au-tomated voice-based information retrieval services overthe telephone network.
This has some precise impli-cations.
First, we are committed to accept continuous-speech sentences expressed in relatively free syntax, oth-erwise the interaction with the service would be toounnatural.
Second, the service should be public and ac-cessible from every telephone; this means that the un-*This research as been partially supported by EEC ES-PRIT project no.
2218 SUNDIAL.derstanding system has to be speaker independent andable to process noisy and distorted speech.
Third, theresponse time must be confined within a few seconds;that is, the system has to work in real time.The evolution of the research is gradual.
In thepresent status of work the developed system is speakerindependent and it is based on a telephone-line qual-ity speech (a telephone connected through a PABX).
Ithas a vocabulary of 787 words and the processing timeis less than 5 seconds (about twice real time).
The sen-tence correct understanding rate is nearly 72%.
Theapplication task refers to voice access to an electronicmailbox.
In its first version the system has been appliedto access a geographical data base, and is now adapted(with a slightly bigger vocabulary) to information re-trieval from a train timetable data base.
In the follow-ing we present a thorough description of the approachthat led to these results.
Also, the latest developmentsof the system are discussed.
We will focus here on theunderstanding subsystem.
An account of the recogni-tion stage is given in \[Fissore t ai.
1989\] and in thereferences there reported, while the whole system is de-scribed in \[Baggia et al 1991c\].
We will examine therole of the recognition and understanding modules, thetechnique used for language representation, the parsingcontrol strategy, and finally experimental results will bediscussed.2 Recognition and understandingactivitiesSpeech understanding requires the use of different piecesof knowledge.
Consequently, it is not obvious a pri-ori what type of architecture will give the best results.Homogeneous, knowledge-based architectures date backto the late 1970s \[Erman et ai.
1980\] and spurred in-teresting research work in the subsequent years.
How-ever, unified approaches contain a weakness: they havedifficulty in coping with problems of different naturethrough specific, focused techniques.
A division may betraced between lower-level processing of speech, mostlybased on acoustical knowledge, and upper-level pro-cessing, mostly based on natural language knowledge.Therefore, a two-level architecture has been developedbased on this idea \[Fissore t ai.
1988\].
The formerstage, called recognition stage (Fig.
la), hypothesizesa set of words all over the utterance and feeds the lat-33wordla t t i ceutterancel .
.
.
.
.
.
I .\] - I  or==~,n  L.feedback Iver i f i cat ion1.GS i0.5.
;coreutteranceNATURAL I meaningLANGUAGE I =UNDERSTANDING I?Qieri(yes terday)spedito.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
i 'J (sent) Rober to(Robert) Imessagg ioI(message), d._~_aI ; (by)I I I I I= I I I I I t~ I I I t f lFrameFigure 1: System architecture (a).
An example of wordlattice (b).ter stage, or understanding stage, which completes therecognition activity by finding the most plausible wordsequence and by understanding its meaning.
In thisway each level can focus on its own basic problems anddevelop specific techniques, till maintaining the advan-tage of the integration.Most of the approaches based on this idea (e.g.\[Hayes et al 1986\]) are characterized by the use ofknowledge ngineering techniques at both levels, whileour recognition stage is based on a probabilistic tech-nique, the hidden Markov models (HMM).
The mostrecent research indicates that, as far as word recog-nition is concerned, the HMM give the best results\[Lee 1990, Fissore et al 1989\].The set of word hypotheses produced by the recogni-tion stage is called lattice (Fig.
lb).
Every word hypoth-esis is characterized by the starting and ending points ofthe utterance portion in which it has been spotted, andits score, expressing its acoustic likelihood, i.e.
a mea-sure of the probability for the word of having been ut-tered in that position.
Many more hypotheses than theactually uttered words are present in the lattice (thereare about 30 times as many word hypotheses as thereare words), and they are overlapping on one another.The aim of the understanding stage is then twofold: onone side it has to complete the recognition task by ex-tracting the correct word sequence out of the lattice; onthe other it has to understand the sequence meaning.In practice these two activities are performed simulta-neously.
The correct word sequence xtracted by theunderstanding stage may be fed back to the recognizer(Fig.
la) for a post-processing phase called feedback ver-ification, described below, aimed at increasing the un-derstanding accuracy.The problem of analyzing lattices is considered fromthe natural anguage perspective: the goal is to developtechniques to process typed input and to extend themin order to process a "corrupted" form of input suchas a lattice is.
The understanding stage result calledsolution is a sequence of word hypotheses spanning thewhole utterance time so that 1) the sentence is syntacti-cally correct and meaningful according to the linguisticknowledge of the understanding stage, and 2) it ha~the best acoustical score among all of the possible se-quences that satisfy point 1).
The great problem is thaithe search for a solution cannot be made exhaustively:since the lattice contains many incorrect word hypothe-ses, there would be far too many admissible word com-binations to examine.
In addition there is the risk oJincorrect understanding due to the possible selection o~even only one incorrect word hypothesis.
Coping wittthem imposes to carefully design linguistic knowledg~representation methods and analysis control strategie.,in order to gain in both efficiency and correct under.standing reliability.3 Language representationThe task of the machine is to combine together adj&cent word hypotheses, o as to create phrase hypothese~(PHs), which are consistent according to the languag,model.
Such parsing process continues until the systerrreaches a solution.The choice of a suitable linguistic knowledge repre-sentation poses a dilemma.
For the machine, to reactreal-time, the representation must above all be efficientthat is, it must require reasonable computational cos1and must keep low the number of PHs generated ur.ing parsing.
On the other hand, for the developer othe system the representation must be easy to declareinterpret, and maintain.
Ease of maintenance suggestsfor example, that it is preferable to keep syntax an(semantics eparate as much as possible.The previous considerations suggest o adopt two rep.resentations, one suitable for the system developer, th,other for the machine \[Poesio and Rullent 1987\].
Th~translation of the linguistic knowledge from the forme:representation (high-level representation) to the latte:one (low-level representation) is performed off-line b2a compiler (see Fig.
2).
This approach also permit:to maintain separate high-level representations for syntax and for semantics, choosing for each the formalismthat seem most suitable.
For semantics the Casefram,formalism \[Fillmore 1968\] in the form of ConceptuaGraphs \[Sowa 1984\] had been chosen, while for syntax the Dependency Grammar formalism \[Hays 1964has been used.
A Dependency Grammar expresses th,syntactic structure of sentences through rules involvinldependencies between morphological categories.
Th,right-hand side of the rule contains one distinguishe~terminal symbol called governor, while the other symbols are called dependents.
A mechanism has bee\]added to the dependency rules to describe the morphclogical agreements between the governor and the dependents.34Ca~frames--,,.
/I CompilerFigure 2: Language representation3.1 The  compi le rDependency grammars have been selected as a formal-ism for representing syntactic knowledge because theyallow an easy integration with caseframes thanks to thesimilar notion of governor for the dependency rules andof header for the caseframes.The compiler operates off-line and generates internalstructures, called Knowledge Sources (KSs) suitable toallow an efficient parsing strategy.
The basic point isthat each KS is aimed at generating a certain class ofconstituents.
Then each KS must combine the timeadjacency knowledge, the syntactic, morphological ndsemantic knowledge that it is necessary to handle a spe-cific class of phrases.As an example, Table lb represents the dependencyrules used to deal with the sentences of Table la.
Notethat prepositions are never governors as they are usu-ally short and are likely to be missing from the lattice(see section 5).
The star symbol in each rule representsthe governor position.
The associated rules for morpho-logical agreement checks are not reported for simplicity.
(a) sent yesterdaysent yesterday by John(b) rsl) verb = * adverb\[adv-phrase\]rs2) verb * adverb\[adv-phrase\] noun\[by-phrase\]rs3) noun = prep *Table 1: An example of phrases (a).
The necessarydependency rules (b)For each dependency rule the compiler must find allthe conceptual graphs that can be associated to suchrule and to use them to generate a KS.
For this pur-pose, each dependency rule is augmented with informa-tion about grammatical relations, contained in squarebrakets in Table lb; a grammatical relation is associatedSEND ~.
.
_~ ( ~ ) _ ~  YESTERDAYFigure 3: Conceptual graphsto each dependent Di, accounting for the grammaticalrelation existing between the governor G and the lower-level constituent having Di as a governor.For example, the associated grammatical relations forrs2 could be adv-phrase for the first dependent and by-phrase for the second one.
Additional mapping knowl-edge associates one or more conceptual graphs to eachgrammatical relation, so that it is possible to find fromthe conceptual graphs the semantic onstraints that thegovernor and the dependents of the rule have to fol-low.
Referring to the conceptual graphs of Fig.
3, theconceptual relation agnt can be associated to by-phraseand the conceptual relation lime can be associated toadv-phrase.
The semantic onstraints derived from theconceptual graphs are: SEND for the "verb" governor,YESTERDAY for the "adverb" dependent and PERSONfor the "noun" dependent of rule rs2.Each KS built by the compiler has one terminal slotcalled header, representing one single word, and otherslots called fillers representing phrases, positionally re-flecting the symbols of the dependency rules from whichthe KS derives.
The main bulk of knowledge mbeddedin a KS is a set of structures that express constraintsbetween the syntactic-semantic features of the headerand those of the fillers.A first version of the compiler had the goal of enrich-ing the dependency rules with the semantic onstraintsderived from the concepual graphs.
In this case the setof generated KS could be sketched as in Table 3, whererow c4 can correspond, for instance, to the compilationof the dependency rule rs2.
A total of 70 conceptualgraphs and 373 syntactic rules is used in the system.These knowledge bases are able to treat a large vari-ety of sentences, a sample of which is shown in Table 2(nearly literal English translation).Although the obtained efficiency was sufficientlygood, a conceptual improvement to the compiler hasbeen devised, as is described in the next subsection.3.2 Eff ic ient representat ion  o f  l inguist icconstraints: rule fusionOne basic problem to move towards real-time operationis to define the kind of structures that can be build forrepresenting PHs.
Suppose a "classical" grammar likea context free grammar is used and that we are tryingto connect wo words into a grammatical structure.
Ingeneral, this can be done in several ways according to35I'd like to know Thursday's fourth one.Did any mail come in September?Tell me the mails I received since two days ago.Got any mail last week?Read me Giorgio's first two messages.The third one.Did anyone write after last Friday?Make me a list of your mails.Send SIP's first one to Cselt.What messages did Luciano write me fromDecember one to six?Tell me the senders of messages receivedfrom Milan.What are the mails received from Piero ofCselt after October seventeen.Table 2: A sample of task sentencesdifferent grammar ules.
Since structures built with dif-ferent rules may connect with different word hypothe-ses, a new memory object is needed for every struc-ture.
In the case of speech this leads to two undesirableconsequences.
First, a very large memory size is re-quired, owing to the high number of word combinationsallowed by word lattices.
Second, each of the structureswill be separately selected and expanded, possibly withthe same words, during the score-guided analysis, thusintroducing redundant work.
Therefore, the compilershould generate a smaller number of "compact" KSs ,still keeping the maximum discrimination power.The goal of generating a small number of KSs is ac-complished through the fusion technique \[Baggia et al1991a\].
Fusion aims at compacting together KSs.
KSsrow position0 1 \[ 2cl C A1 Ic2 C B1c3 C A1 B1c4 C B1 A1c5 C A2c6 C A2 B1c7 C B1 A2Table 3: A sketchy representation of KSsmay have constituents in different order or even a dif-ferent number of constituents.
Let us suppose we havea WH of class C and we want to connect it to otherwords that can depend on it and that are adjacentto the header on the right.
Table 3 contains, for theheader class C, a sketchy representation of the KSs in-volved (the rows in the table).
The positions of the con-stituents are also shown.
The zero position indicates theheader while positions 1 and 2 indicate dependents onthe right of the header.
The numbers attached to eachclass mean that different constraints act on the corre-sponding constituent.
Table 3 shows that constituentsof both classes A and B are involved.
Let us focus onthe class A case.As we want to find class A constituents, on the rightof the header, four KSs are involved, corresponding torows cl, c3, c5, and c6; the first two KSs propagateconstraints (summarized by A1) that will be consideredby a proper KS of class A; the result is the generation oftwo couples of PHs (two generated by the A KS and twoby the C KS).
Two other couples of PHs are generatedin a completely similar way by the KSs of row c5 andc6, the only difference being that the KSs propagatedifferent constraints.In the fusion case there is just one KS for the sevendifferent rows of Table 3.
The C KS propagates theconstraints for the A KS: it propagates A I+A2 and thetime constraint hat the constituent must be adjacent(on the right) to the header.
Only one search into thelattice is performed by the A KS.
Only a couple of PHis created for the rows cl, c3, c5, and c6 (one by the AKS and one by the C KS).The fusion technique is effective in reducing the num-ber of PHs to be generated and the parsing time.
Theresults of the experiments are reported in Table 4.No.PHs generatedParsing time (s)NoFusion Fusion806 911.56 0.38Table 4: The effect of fusionThe reduction of PtIs would be of no use if it werebalanced by an increased activity for checking and prop-agating constraints.
So, for execution efficiency, bitcoded representations are used for the propagation ofconstraints about active rules, in a way similar to thepropagation of morphological nd semantic onstraints.The system runs on a Sun SparcStation 1 and is imple-mented using the C language, which furtherly increasesspeed.4 Cont ro l  o f  pars ing  ac t iv i t iesThe basic problem that control is cMled to face is thewidth of the search space, due to the combined effectof the non-determinism of the language model and theuncertainty and redundancy of the input.
Since an ex-haustive search is not feasible, scores are used to con-strain it along the most promising directions just fromthe beginning: the analysis proceeds in cycles in a best-first perspective and at each cycle the parser processesthe best-scored element produced so far.
The score of aPH made up by a number of word hypotheses i definedas the average of the scores of its component words,weighted by their time durations.
This "length nor-malization" insures that, when we have to compare twoPHs having different length, we do not privilege longeror shorter ones.The building of parse trees may proceed through top-down or bottom-up steps.
For instance, if the best-scored element selected in one cycle is a header word, a36top-down step consists in hypothesizing fillers and ver-ifying the presence in the lattice of words that can sup-port them.
Hypothesizing headers from already parsedfillers is an example of a bottom-up step.If all of the correct word hypotheses are well-scored,any parsing strategy works satisfactorily.
However, of-ten a correct word happens to be badly recognized andhence receives a bad score, though the overall sentencescore remains good.
This can be due to a burst of noise,or to the fact that the word was badly uttered.
Manyincorrect words will be present in the lattice, scoringbetter than such word.
Now, imagine a pure top-downparsing in the case where such a bad word is one ofthe headers.
Prior to processing that header, the parserwill process all of the better-scored words that are them-selves headers.
This may delay the finding of the correctsolution beyond reasonable imits, or may favor the find-ing of a wrong solution in the meantime.
Similar consid-erations hold in the ease of a pure bottom-up strategy.Such bottlenecks are avoided thanks to a strategy inwhich the good-scored words of the correct solution mayhypothesize the few bad-scored ones in any case.
Thisproperty implies that the parser must be able to dynam-ically switch from top-down steps to bottom-up stepsand vice versa, according to the characteristics of theelement hat has been selected in that cycle.
Apartfrom avoiding bottlenecks, a control strategy that fol-lows this guideline has one important characteristic: itis admissible, that is the first-found solution is surelythe best-scored one.This approach of exploiting only language constraints,if followed to its extremes, leads to an insufficient ex-ploitation of time adjacency, which is a different crite-rion for designing an efficient control strategy.
Timeadjacency is at the base of the so-called island-drivenparsing approaches, which recently received renewed at-tention \[Stock et al 1989\].
Here the idea is to selectonly fillers that are temporally adjacent o the header,so that we can limit the number of word hypothesesthat can be extracted from the lattice (i.e.
that satisfylanguage and time adjacency constraints) and conse-quently the parse trees that have to be generated.The parsing process proceeds through elementary ac-tivities, or operators, that represent op-down steps(EXPAND and FILL operators) or bottom-up steps (Ac-TIVATE and PREDICT operators).
The JOIN operatordescribes the activity in which a KS merges togetherparsing processes that had evolved separately; this maycorrespond either to a bottom-up or to a top-down step.By suitably defining when and how the KSs applythe operators it is possible to trade off with the lan-guage constraint and the time adjacency criteria withthe result of switching down admissibility by a littleamount while simultaneously gain a consistent reduc-tion of the number of generated parse trees.
The con-trol strategy that has been adopted, described in de-tail in \[Giachin and Rullent 1990\], accepts a limited riskof getting the wrong solution in the first place (about1.5%) but is balanced by a great speed-up in the parsingof a lattice.5 Cop ing  w i th  spec ia l  speech  prob lemsThe adjacency between consecutive word hypotheses iseldom perfect, being them affected by a certain amountof gap or overlap.
This is due to the fact that theend of a word is slightly confused with the beginningof the consecutive word.
The understanding level is tol-erant towards these phenomena nd defines thresholdson maximum allowed gap or overlap between suppos-edly consecutive words.While coarticulation affects all words, it severely com-promises the recognition of what are currently called,with an admittedly imprecise term, function words.Function words, such as articles, prepositions, etc., aregenerally short and they tend to be uttered very im-precisely, so that often they are not included in the lat-tice.
Moreover, function words are often acoustically in-eluded in longer words.
The parsing strategy then doesnot rely on function words \[Giaehin and Rullent 1988\].The idea is that KS slots corresponding to functionwords are divided into three categories, namely short,long, and unknown.
Short words are never searched inthe lattice, and a plaeeholder is put in the Phrase Hy-pothesis (PH) that includes it.
Long words are alwayssearched, and failure is declared if no one is found.
Un-known words are searched, but a plaeeholder may beput in the PH if some conditions are met.
In a firstphase, the categorization of a KS slot was made on thebasis of the morphological features of the correspond-ing function words and on their length (e.g., words withone or two phonemes were declared "short" and neversearched).
Subsequent experiments showed that, un-expectedly, some very short words may be recognizedwith virtually no errors, while others, though longer,are much more difficult to recognize.
Hence, better re-sults have been obtained when the categorization hasbeen made on the basis of the phonetic features of thewords rather than of the morphological ones.5.1 Feedback verification procedureThough skipping function words permits to successfullyanalyze sentences for which these words were not de-tected, it also implies that the acoustic information ofsmall portions of the waveform is not exploited, andthis may lead the parser to find a wrong solution.Also, function words may be sometimes essential to cor-rectly understand the meaning of a sentence.
In or-der to cope with these problems, a two-way interac-tion between the recognition module and the parser hasbeen investigated, called feedback verification procedure\[Baggia et aL 1991b\].
According to this procedure, theparser, instead of stopping at the first solution, contin-ues to run until a predefined amount of resources i  con-sumed.
During this period many different solutions arefound, possibly containing multiple possibilities in placeof missing words.
These solutions are then fed back tothe recognizer which analyzes them sequentially.
Therecognizer task realigns the solutions against he acous-tic data and attributes them a new likelihood score.
Tilebest-scored solution is then selected as the correct one.As a side effect, the best-matching candidate for func-tion words that were missing in the lattice is also found.37Solution:CI-SONO MESSAGGI ??
ROSSl ??
VENTI I(ARE THERE MALLS ??
ROSSI ??
TWENTY)Figure 4: Function word detection during FVPThe verification procedure creates the best conditions tofind these words with good reliability: for each place-holder a very small number of candidates are proposed,and the previous and following words are usually nor-real reliable words.
Hence the recognizer can detect heword with good accuracy.
An example of a solution gen-erated by the parser for the utterance "Ci sono messaggida Rossi il venti?"
(literally: "There are mails fromRossi on twenty?")
is shown in Fig.
4.
The "??"
sym-bol in the solution represents a possibly missing func-tion word ignored during parsing, that is expanded intoa set of candidates, according to the grammar, to be fedback to the recognizer.In addition to accurately finding function words, theverification procedure has the advantage that the finalscores assigned to solutions by the recognizer are moreaccurate than those assigned to them by the parser,because these scores have been computed on the sametime interval after a global realignment of the sentences.Hence comparing the solutions on the basis of theirscore is a more reliable procedure.
The drawback of theverification procedure is that total analysis times areslightly increased by the overload imposed to the recog-nizer and by the fact that the parser must continue theanalysis after the first solution is found.6 Exper imenta l  resu l t sIn order to evaluate the performance of a speech under-standing system it is necessary to define some metric.Unfortunately, metrics are still far from standards inthis field.
Let us briefly describe the measures usedin our evaluation and shown in Table 5.
Understoodrefers to the percentage of correctly understood sen-tences.
We define that a sentence has been understood ifthe word sequence selected by the parser and refined bythe feedback verification procedure (if applied) is equalto the uttered sentence or differs from it only for shortfunction words that are not essential for understanding.The failure rate is the percentage of sentences for whichno result has been obtained by the parser within thereal-time imposed constraints.
The misunderstood casearises when the selected solution is not the uttered one.Note that failures and misunderstandings have not thesame effect: in fact in the case of failure the systemis aware of not having understood the question and ina dialogue system the failure can activate a recoveryaction.The parser has been implemented using the C lan-guage and presently runs on a Sun SparcStation 1.Experiments have been performed starting from 60Clattices produced by the recognition system from 60Cdifferent sentences uttered by 10 speakers and per-taining to the voice access to E-mail messages.
Therecognizer \[Fissore t al.
1989\] employs 305 context-dependent units, each of which is represented by a 3-state discrete density HMM.
HMMs are trained with8800 sentences uttered by 110 speakers.
The speechsignal, recorded from a PABX, is low-pass filtered atkHz and sampled at 16 kHz.
Features, computed every10 ms time frame, include 12 cepstrum and 12 delta,cepstrum coefficients, plus energy and delta-energy.UnderstoodFailureMisunderstoodbaseno ver.
verify63.7% 69.2%4.4% 5.7%31.5% 25.2%+best sent.no ver.
verify65.7% 72.2%10.5% 11.3%23.8% 16.5%Table 5: Experimental results on 600 test sentencesTable 5 reports the results for two kinds of configurations, each evaluated with the feedback verificatiolprocedure disactivated (no vet.)
or activated (verify)The first configuration is the baseline one, in whichlattice is analyzed as described in the above sectionsIn the second configuration, we add into the lattice th,best-scored sequence of words initially found by the recognizer as a side-effect of its analysis.
This sequencethough rarely correct, takes better into account interword coarticulation and hence may contribute to th,overall accuracy.
In both configurations the maximurprocessing time is 5 seconds.7 Conc lus ionsThe effectiveness of a two-level architecture for continuous speech understanding has been demonstrate,through a working system tested on several hundre,sentences recorded through a PABX from 10 speaker.,The implementation of the linguistic processor stressethe design of efficient ways of representing language constraints into knowledge sources through the procedurof fusion, and the development of efficient score guide,control algorithms to perform parsing.
A verificatio:procedure permits to increase understanding accurac:by exploiting the capabilities of the recognition modulas a post-processor, able to acoustically reorder sentences hypothesized by the linguistic processor and finout words that were skipped by the parser.
Analysitimes as low as about twice real time are achieved onSun SparcStation 1.38References\[Baggia et al 1991a\] P. Baggia, E. Gerbino, E. Giachin,and C. Rullent, "Efficient Representation of Linguis-tic Knowledge for Continuous Speech Understanding",Proc.
1JCA1 91, Sydney, Australia, August 1991.\[Baggia et al 1991b\] P. Baggia, L. Fissore, E. Gerbino, E.Giachin, and C. Rullent, "Improving Speech Under-standing Performance through Feedback Verification",Proc.
Eurospeech 91, Genova, Italy, September 1991.\[Baggia et al 1991c\] P. Baggia, A. Ciaramella, D. Clemen-tino, L. Fissore, E. Gerbino, E. Giachin, G. Micca, L.Nebbia, R. Pacifici, G. Pirani and C. Rullent, "A Man-Machine Dialogue System for Speech Access to E-Mailusing Telephone: Implementation and First Results",Proc.
Eurospeech 91, Genova, Italy, September 1991.\[Erman et al 1980\] L. D. Erman, F. Hayes-Roth, V. R.Lesser, and D. Raj Reddy, "The Hearsay-II Speech Un-derstanding System: Integrating Knowledge to ResolveUncertainty", A CM Computing Survey 12, 1980.\[Fillmore 1968\] C. J. Fillmore, "The Case for Case", inBach, Harris (eds.
), Universals in Linguistic Theory,Holt, Rinehart, and Winston, New York, 1968.\[Fissore t al.
1988\] L. Fissore, E. Giachin, P. Laface, G.Micca, R. Pieraccini, and C. Rullent, "Experimental Re-suits on Large Vocabulary Continuous Speech Recogni-tion and Understanding", Proc.
ICASSP 88, New York,1988.\[Fissore t al.
1989\] L. Fissore, P. Laface, G. Micca, andR.
Pieraccini, "Lexical Access to Large VocabulariesSpeech Recognition", 1EEE Trans.
ASSP, Vol.
37, no.8, Aug. 1989.\[Giachin and Rullent 1988\] E. Giachin and C. Rullent, "Ro-bust Parsing of Severely Corrupted Spoken Utterances",Proc.
COLING-88, Budapest, 1988.\[Giachin and Rullent 1989\] E. Giachin and C. Rullent, "AParallel Parser for Spoken Natural Language", Proc.
1J-CA189, Detroit, August 1989.\[Giachin and Rullent 1990\] E. Giachin and C. Rullent,"Linguistic Processing in a Speech Understanding Sys-tem", NATO Workshop on Speech Recognition and Un-derstanding', Cetraro, Italy, July 1990, R. de Mori andP.
Laface, (eds.
), Springer Verlag, 1991.\[Hayes et ai.
1986\] P. J. Hayes, A. G. Hauptmann, J. G.Carbonell, and M. Tomita, "Parsing Spoken Language:a Semantic Caseframe Approach", Proc.
COLING 86,Bonn, 1986.\[Lee 1990\] K.-F. Lee, "Context Dependent Phonetic Hid-den Markov Models for Speaker Independent Continu-ous Speech Recognition", 1EEE Trans ASSP, Vol.
38,no.
4, April 1990.\[Hays 1964\] D. G. Hays, "Dependency Theory: a Formalismand Some Observations", Memorandum RM4087 P.R.,The Rand Corporation, 1964.\[Poesio and Rullent 1987\] M. Poesio and C. Rullent, "Mod-ified Caseframe Parsing for Speech Understanding Sys-tems", Proc.
1JCA187, Milano, 1987.\[Sowa 1984\] J. F. Sowa, Conceptual Structures, AddisonWesley, Reading (MA), 1984.\[Stock et al 1989\] O.
Stock, R. Falcone, and P. Insinnamo,"Bidirectional Charts: a Potential Technique for Pars-ing Spoken Natural Language Sentences", Computer,Speech, and Language, 3(3), 1989.\[Tomita nd Carbonell 1987\] M. Tomita and J. G. Carbo-nell, "The Universal Parser Architecture for Knowledge-Based Machine Translation", Proc.
I JCAI  87, Milano,1987.\[Woods 1985\] W. A.
Woods, "Language Processing forSpeech Understanding", in F. Fallside, W. A.
Woods(eds.
), Computer Speech Processing, Prentice Hall Int.,London, UK, 1985.39
