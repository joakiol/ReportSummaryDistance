INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 40?48,Utica, May 2012. c?2012 Association for Computational LinguisticsPerceptions of Alignment and Personality in Generated DialogueAlastair J. GillUniversity of SurreyGuildford GU2 7XH, UKA.Gill@surrey.ac.ukCarsten Brockmann and Jon OberlanderUniversity of EdinburghEdinburgh EH8 9AB, UKCarsten.Brockmann@gmx.netJ.Oberlander@ed.ac.ukAbstractVariation in language style can lead to differ-ent perceptions of the interaction, and differ-ent behaviour outcomes.
Using the CRAG 2language generation system we examine howaccurately judges can perceive character per-sonality from short, automatically generateddialogues, and how alignment (similarity be-tween speakers) alters judge perceptions of thecharacters?
relationship.
Whilst personalityperception of our dialogues is consistent withperceptions of human behaviour, we find thatthe introduction of alignment leads to nega-tive perceptions of the dialogues and the inter-locutors?
relationship.
A follow up evaluationstudy of the perceptions of different forms ofalignment in the dialogues reveals that whilesimilarity at polarity, topic and constructionlevels is viewed positively, similarity at theword level is regarded negatively.
We discussour findings in relation to the literature and inthe context of dialogue systems.1 IntroductionPersonality describes characteristics which are cen-tral to human behaviour, and has implications forsocial interactions: It can affect performance on col-laborative processes, and can increase engagementwhen incorporated within virtual agents (Hernaultet al, 2008).
In addition, personality has also beenshown to influence linguistic style, both in writtenand spoken language (Pennebaker and King, 1999;Gill and Oberlander, 2002).
Whilst individuals of-ten possess individual styles of self-expression, suchas those influenced by personality, in a conversationthey may align or match the linguistic style of theirpartner: For example, by entraining, or converging,on a mutual vocabulary.
Such alignment is associ-ated with increased familiarity, trust, and task suc-cess (Shepard et al, 2001).
People also adjust theirlinguistic styles when interacting with computers,and this affects their perceptions of the interaction(Porzel et al, 2006).
However, when humans ?
ormachines ?
are faced with a choice of matching thelanguage of their conversational partner, this oftenraises a conflict: matching the language of an in-terlocutor may mean subduing one?s own linguisticstyle.
Better understanding these processes relatingto language choice and interpersonal perception caninform our knowledge of human behaviour, but alsohave important implications for the design of dia-logue systems and user interfaces.In this paper, we present and evaluate novelautomated natural language generation techniques,via the Critical Agent Dialogue system version 2(CRAG 2), which enable us to generate dynamic,short-term alignment effects along with stable, long-term personality effects.
We use it to investigatethe following questions: Can personality be accu-rately judged from short, automatically generated di-alogues?
What are the effects of alignment betweencharacters?
How is the quality of the characters?
re-lationship perceived?
Additionally, in our evaluationstudy we examine perceptions of the different formsof alignment present in the dialogues, for example atthe word, phrase or polarity levels.
In the followingwe review relevant literature, before describing theCRAG 2 system and experimental method, and thenpresenting our results and discussion.402 BackgroundResearchers from several traditions have studied as-pects of similarity in dialogue, naming it: entrain-ment, alignment, priming, accommodation, coordi-nation or convergence.
For current purposes, wegloss over some important differences, and borrowthe term ?alignment?, because we will go on to adoptPickering and Garrod?s theoretical mechanisms inour system.
Alignment usually means that if some-thing has happened once in a dialogue (for instance,referring to an object as a vase), it is likely to happenagain?and hence, alternatives become less likely(for instance, referring to the same object as a jug)(Pickering and Garrod, 2004).
From this view, inter-locutors align the representations they use in produc-tion and comprehension and the process is an auto-matic, labour-saving device, but there are of courselimits to periods over which alignment processes op-erate; in corpus studies long-term adaptation pre-dicts communicative success (Reitter, 2008).
Al-ternative approaches view similarity as a process ofnegotiation leading to the establishment of commonground (Brennan and Clark, 1996), or a relativelyconscious process resulting from attraction (Shepardet al, 2001).
Although increased similarity (conver-gence) is generally regarded positively, it can some-times arise during disagreement (Niederhoffer andPennebaker, 2002), with cultural differences influ-encing both convergence and perceptions of others(Bortfeld and Brennan, 1997).
Wizard-of-Oz stud-ies have also shown convergence with a natural lan-guage interface (Brennan, 1996; Porzel et al, 2006).Embodied conversational agents (Cassell et al,2000) are implemented computer characters that ex-hibit multimodal behaviour; the technology can beexploited to give life to automatically generatedscripted dialogues and to make them more engag-ing (van Deemter et al, 2008; Hernault et al, 2008).Aspects of the agents?
personalities and their inter-ests can be pre-configured and affect their dialoguestrategies; the generation is template-based.
A com-mon way to describe personality is using the BigFive traits: Extraversion (preference for, and behav-ior in, social situations); Neuroticism (tendency toexperience negative thoughts and feelings); Open-ness (reflects openness to new ideas); Agreeableness(how we tend to interact with others); and Consci-entiousness (how organised and persistent we are inpursuing our goals).
Relationships between person-ality dimensions and language use appear to be ro-bust: For instance, in monological writing (essaysand e-mails) high Extraverts use more social words,positive emotion words, and express more certainty;high Agreeableness scorers use more first personsingular and positive emotion words, and fewer ar-ticles and negative emotion words (Pennebaker andKing, 1999; Gill and Oberlander, 2002).Personality can not only be projected through, butalso perceived from, asynchronous textual commu-nication.
The extraversion dimension is generallyperceived most accurately in a variety of contexts,while it was more difficult for raters to recogniseneuroticism (Gill et al, 2006; Li and Chignell, 2010)Taking into account the difference between the lan-guage actually used by people with certain person-ality, and the language which others expect themto use, natural language generation (NLG) systemscan exploit either to project personality.
Perhaps theclosest previous work to what we present here is thePersonality Generator (PERSONAGE) (Mairesse andWalker, 2010) which mapped psychological find-ings relating to the personality to the componentsof the NLG system (e.g., content planning, sen-tence planning and realisation).
Evaluation by hu-man raters showed similar accuracy in perceptionof extraversion in the generated language comparedwith human-authored texts.
There is evidence thatcomputer users attribute personality to interfaces,and rate more highly those interfaces that exploitlanguage associated with the user?s own personal-ity, and become more similar to the user over time(Isbister and Nass, 2000).We now turn to describing our automated natu-ral language generation techniques, implemented inCRAG 2, followed by a description of our experi-mental method and evaluation.3 Generation MethodDialogues are composed by CRAG 2, a Java pro-gram that provides a framework for generating dia-logues between two computer characters discussinga movie.
For more details of this system, see Brock-mann (2009).
Within CRAG 2, linguistic personal-ity and alignment are modelled using the OPENNLP41CCG Library (OPENCCG) natural language realiser(White, 2006b).
The realiser consults a grammaradapted to the movie review domain to allow thegeneration of utterances about the following top-ics: Action scenes, characters, dialogue, film, music,plot or special effects.
The realiser also has accessto a set of n-gram language models, used to com-pute probability scores of word sequences.
The gen-eral conversational language model (LM) is basedon data from the SWITCHBOARD corpus and a smallcorpus of movie reviews.
The general LM is used forfallback probabilities, and is integrated with the per-sonality and alignment language models (describedbelow) using linear interpolation.3.1 Personality ModelsLanguage models were trained on a corpus of web-logs from authors of known personality (Nowson etal., 2005).
For each personality dimension, the lan-guage data were divided up into high, medium andlow bands so that the probability of a word sequencegiven a personality type could be derived; see Now-son et al (2005) for further discussion of the pos-itively skewed distribution of the openness dimen-sion in bloggers.
Each individual weblog was used5 times, once for each dimension.
The five modelscorresponding to the character?s assigned personal-ity are uniformly interpolated to give the final per-sonality model, which is then combined with thegeneral model (respective weights, 0.7 and 0.3).3.2 Alignment via Cache Language ModelsMeanwhile, alignment is modelled via cache lan-guage models (CLMs).
For each utterance to begenerated, a language model is computed based onthe utterance that was generated immediately beforeit.
This CLM is then combined with the personalityLM.
A character?s propensity to align correspondsto the weight given to the CLM during this combi-nation, and can be set to a value between 0 and 1.3.3 Character Specification and DialogueGenerationThe characters are parameterised for their per-sonality by specifying values (on a scale from0 to 100) for the five dimensions: extraver-sion (E), neuroticism (N), agreeableness (A),conscientiousness (C) and openness (O).
This pa-rameterisation determines the extent to which utter-ances are weighted for their overlap with the per-sonality generation model for each trait.
Also, eachcharacter receives an agenda of topics they wishto discuss, along with polarities (POSITIVE/NEGA-TIVE) that indicate their opinion on each topic.The character with the higher E score begins thedialogue, and their first topic is selected.
Oncean utterance has been generated, the other charac-ter is selected, and the system selects which topicshould come next.
This process continues untilthere are no topics left on the agenda of the cur-rent speaker.
The system creates a simple XMLrepresentation of the character?s utterance, usingthe specified topic and polarity.
Following themethod described in Foster and White (2004), thebasic utterance specification is transformed, usingstylesheets written in the Extensible Stylesheet Lan-guage Transformations (XSLT) language, into anOPENCCG logical form.
We make use of the fa-cility for defining optional and alternative inputs(White, 2006a) and underspecified semantics tomildly overgenerate candidate utterances.Optional interjections (I mean, you know, sort of )and conversational markers (right, but, and, well)are added where appropriate given the discourse his-tory.
Using synonyms (e.g., plot = story, comedy =humour) and combining sentence types and optionalexpressions, up to 3000 possibilities are created perutterance, and the best candidate is chosen by thespecific combination of n-gram models appropriatefor dialogue history, personality and alignment.4 Experimental Method4.1 ParticipantsData were collected from 80 participants with a va-riety of educational and occupational backgroundsusing an online study (via the Language Experi-ments Portal; www.language-experiments.org).
Toensure integrity of responses, submissions takingless than five minutes (five cases), or more than 45minutes (one case) were examined in relation to theother responses before being included in the analy-sis.
The demographics were as follows: 43 partici-pants (54%) were native, and 37 (46%) non-native,speakers of English; 34 (42%) male, 46 (58%) fe-42Personality Par- Propen-Dialogue ameter Setting sity toType Character E N A C O Align1) High E I 75 50 25 25 50 0vs.
Low E II 25 50 75 75 50 0 or 0.72) Low E I 25 50 25 25 50 0vs.
High E II 75 50 75 75 50 0 or 0.73) High N I 50 75 25 25 50 0vs.
Low N II 50 25 75 75 50 0 or 0.74) Low N I 50 25 25 25 50 0vs.
High N II 50 75 75 75 50 0 or 0.7Table 1: Dialogue type parameter settings.male.
Median age range was 25?29 (mode = 20?24).
Other demographic information (right/left-handedness, area of upbringing, occupation) werecollected, but are not considered here.4.2 MaterialsTo be able to compare human judges?
perceptionsof characters demonstrating different personalities,and dialogues without and with alignment, dialogueswere generated in four different dialogue types, asshown in Table 1.
Each dialogue type sets the twocomputer characters to opposing extremes on eitherthe E or the N dimension, while keeping the respec-tive other dimension at a middle, or neutral, level(for example, in Dialogue Type 1, Character I isHigh E, Character II is Low E, and both charac-ters are Mid N).
Furthermore, Character I is alwaysLow A and C, and Character II is always High A andC.
All characters are set to Mid O.Two dialogues were generated per type, giving atotal of 8 dialogues, with aligning versions of each ofthese dialogues subsequently generated (giving 16dialogues in total).
The movie under discussion andthe characters?
respective agendas and their opinionsabout the topics were randomly assigned.
Each dia-logue was eight utterances long, with characters tak-ing turns, each of them producing four utterancesaltogether.
In each alignment dialogue, the HighA/High C Character II aligned.
The weight for thecache language model was set to 0.7.
In both align-ing and non-aligning versions of the dialogues, ut-terances for the non-aligning speaker were the same.The generation of utterances for the aligning speakerwas seeded with the respective previous utterancefunctioning as the dialogue history.
From the listof generated possible utterances, the top-ranked ut-terance was chosen.4.2.1 Example DialogueTo give an impression of the generated dialogues,Table 2 shows an example of Dialogue Type 1(High E versus Low E) where the characters dis-cuss the movie Mystic River (the first row of Ta-ble 1 gives the full parameter settings).
The othergeneration parameters are (valence of opinions fol-lows each topic): Character I, agenda (PLOT/?,CHARACTERS/?, MUSIC/?, FILM/?
); further opin-ions (SPECIAL EFFECTS/?, ACTION SCENES/+,DIALOGUE/?
); Character II, agenda (ACTIONSCENES/+, SPECIAL EFFECTS/+, PLOT/?, DI-ALOGUE/?
); further opinions (CHARACTERS/?,FILM/?, MUSIC/?
).Alignment is switched on for Character II, withexamples of their utterances from the non-aligningdialogues included beneath.
As can be seen, thealigned utterances closely match the surface formof their primes.
The personality language models?influence on language choice can be seen when theHigh E Character I uses the phrase I mean I didn?tthink, while the (non-aligning) Low E Character IIprefers I (kind of) thought throughout.
Finally, theLow A/Low C Character I has a strategy of switch-ing topics in order to follow his own agenda.4.3 ProcedureAn introductory web page explained the task and de-scribed the four personality dimensions of interest(E, N, A and C; adjectives relating to each personal-ity type were included for reference after each dia-logue).
The first page also contained an example di-alogue similar to those that would be displayed dur-ing the experiment.
The participants were then pre-sented with eight dialogues (two per type; one with,one without alignment).
The dialogues were pre-sented in random order and randomly chosen fromthe pool of available dialogues.
One complete di-alogue was shown at a time, and the participantswere asked to judge which of the two charactersscored higher on the E, N, A and C dimensions (us-ing the previous personality descriptions and adjec-tives).
They also answered questions probing their43PLOT:I ?I mean I didn?t think that the story was great.
?II ?I mean the story wasn?t great.
?Without alignment:?Yes I mean I thought that it wasn?t nicely tied up.
?CHARACTERS:I ?And I mean I thought there was no characterization at all.
?II ?I mean I thought there was no characterization at all.
?Without alignment:?Yeah there was no characterization at all I mean.
?MUSIC:I ?I mean I didn?t think that the music was great.
?II ?I mean the music wasn?t great.
?Without alignment:?Yeah I kind of thought that the music was also very badyou know.
?FILM:I ?I mean I didn?t think the film was good.
?II ?I mean the film wasn?t good.
?Without alignment:?I mean I kind of thought that it was a bit dull.
?Table 2: Example Dialogue.perceptions of the characters?
relationship.
They as-sessed on a seven-point Likert scale how well thecharacters ?got on?
with each other (very badly?verywell), interpreted as indicating positivity or rapportbetween characters, and how smoothly the conver-sation went (not at all smoothly?very smoothly), in-dicating how natural and coherent the interactionswere.
The participants were asked to rate each dia-logue independently from the others.The experimentwas open to both native and non-native speakers ofEnglish; upon supplying an email address, partici-pants were entered into a draw for an Amazon gifttoken.
All data were analysed anonymously.
Notethat this is a further evaluation of data previouslypresented in Brockmann (2009).5 Experimental Results5.1 Personality perceptionTo study the perception of personality in our di-alogues, a nominal logistic regression was run onthe perception ratings obtained from the judges.Here agreement between generated personality andrater judgements was coded as a binary value(agreement=1; disagreement=0), and entered intothe regression model as the dependent variable(DV).
The following independent variables (IVs)were entered into the model: Dialogue Alignment asa binary variable (alignment=1; no alignment=0);Personality Trait judged as a categorical variable(?Extraversion?, ?Neuroticism?
?, ?Agreeableness?,?Conscientiousness?).
We also included an inter-action variable, Generated Alignment ?
PersonalityTrait Rated.
We ran this model in order to under-stand how each of the independent variables, suchas Personality Trait judged, or combinations of vari-ables (in the case of the interactions) best explain theaccuracy of the personality perception judgementsrelative to our generated personality language (theDV).
Throughout this section we report the parame-ter estimates and corresponding one degree of free-dom for the more conservative Likelihood Ratio ChiSquare effect tests for N=1920 (with the exceptionof the four-level variable, Personality Trait DF=3,and Participant ID DF=79).The whole model is significant (?2 = 128.22,p < .0041, R Square (U)= .05; although note thatR Square (U) is not comparable to regular R Square,and therefore cannot be interpreted as a percentageof variance explained; model DF= 89).
To investi-gate effects of native/non-native speaker effects onpersonality judgement accuracy, this variable wasincluded in earlier models as a binary variable (Na-tive Speaker: native=1; non-native=0), but no sig-nificant effect was found (?2 = 0.98, p = .3228).Therefore data from all participants are included inthe analyses here, and the native/non-native variableis not included in the model.
For the interactions,there is a significant relationship between DialogueAlignment and accuracy in judgement of Personal-ity Trait (?2 = 13.67, p = .0034).
Further exami-nation of this relationship shows that in the case ofAgreeableness, accuracy decreases when alignmentis present in the dialogue (?2 = 10.90, p = .0010),whereas in the case of Conscientiousness, percep-tion accuracy significantly increases with alignment(?2 = 4.38, p= .0364).
This is shown in Figure 1.There is a significant main effect for Personal-ity Trait judged (?2 = 17.04, p = .0007): param-eter estimates show that accuracy of judgement issignificantly more accurate for Extraversion (?2 =7.21, p = .0073), but less accurate for Agreeable-ness (?2 = 5.54, p = .0186) and Conscientiousness(?2 = 8.09, p = .0044).
No main effect was foundfor Dialogue Alignment relative to accuracy of per-sonality judgement (?2 = 2.16, p= .1420).44A C E NPersonality TraitAgreement(GeneratedPersonalityvs.RaterJudgements)0.00.20.40.60.81.0 ?
?No AlignmentAlignmentFigure 1: Accuracy of personality judgements.5.2 Ratings of ?Getting on?
and ?Smoothness?In the following we are interested in examining whatdialogue characteristics lead to the rater judgementsof ?getting on?.
Using an ordinal logistic regression(DV: how well the characters were judged to ?geton?, seven point scale from ?very badly?
to ?verywell?)
the following independent variables, coded asdescribed in the previous section, were entered intothe model: Dialogue Alignment and Native Speaker(Personality Trait was also entered into the model,but did not reach significance).
Participant ID wasincluded in the model to account for the repeatedmeasures design.
Again, we use likelihood ratioeffect tests and note parameter estimates for onedegree of freedom (N=2560).
The whole modelis significant (?2 = 1396.75, p < .0001, R Square(U)= .15; model DF=89): A main effect for Dia-logue Alignment (?2 = 244.94, p < .0001), showsalignment decreased perceptions of ?getting on?.Similarly, ordinal logistic regressions were usedto probe influencing factors in decisions of ratingdialogue smoothness (DV: smoothness rated on aseven point scale from ?not at all smoothly?
to ?verysmoothly?).
The following independent variables,coded as described in the previous section, were en-tered into the model: Dialogue Alignment and Na-tive Speaker (again Personality Trait did not reachsignificance for inclusion).
Again, Participant IDwas included in the model to account for the re-peated measures design (parameter estimates andlikelihood ratio effect tests are for one degree offreedom, N=2560, Condition, DF=3; ParticipantID, DF=78).
The whole model is significant (?2 =1291.28, p < .0001), with an R Square (U) of 0.13(model DF=89).
There are strong main effects forDialogue Alignment (?2 = 188.27, p < .0001), andNative Speaker (?2= 110.00, p< .0001).
Examina-tion of the parameter estimates reveals negative rela-tionships between ratings of smoothness and NativeSpeaker, and Dialogue Alignment, implying that na-tive speakers significantly rated the dialogues as be-ing less smooth than the non-native speakers, andalso that dialogues with alignment were rated sig-nificantly less smooth than those without alignment.6 Evaluation MethodTo better understand the linguistic alignment pro-cesses which drive the participants?
judgements inthe previous experiment, we performed further anal-ysis.
In particular, we coded the forms of alignmentpresent in each utterance of each dialogue, relativeto the previous utterance.
The forms of alignmentwere coded as follows: Polarity (matching a posi-tive or negative opinion), Topic (whether the topic isthe same or shifts), Word (instances of alignment ofindividual words of the previous utterance), Phrase(alignment of phrases), Construction (alignment ata grammatical construction level).
Each instance ofalignment for a given utterance was counted, withan overall score generated for the whole dialogue.This coding procedure was performed by one re-searcher and subsequently evaluated by a second,with disputes resolved by mutual agreement.
In thefollowing analysis we do not distinguish between di-alogues intentionally generated with alignment andthose without, but instead include all dialogues inthe analysis to examine which objectively measuredforms of alignment relate to the judges?
perceptionsfor personality, ?getting on?
and ?smoothness?.7 Evaluation Results7.1 Alignment Forms and PersonalityAccuracy of judgements of personality ratings anddialogue alignment was analysed for each of the four45personality traits (A, C, E, N) independently usingnominal logistic regression (DV: rater vs. gener-ated personality agreement coded 0 or 1; IVs: occur-rence scores for Polarity, Topic, Word, Phrase, andConstruction).
For Agreeableness the whole modelis significant (?2 = 85.74, p < .0001, R Square(U)= .10; model DF=5, N=640), with Topic align-ment (?2 = 16.68, p < .0001), followed by Polar-ity (?2 = 10.13, p= .0015) and Construction (?2 =6.19, p = .0128) alignment all positively related toperceptions of Agreeableness.
For Conscientious-ness (whole model ?2 = 11.26, p= .0465, R Square(U)= .01; DF=5, N=640), Polarity alignment is in-versely related to perceptions of Conscientiousness(?2 = 5.12, p = .0236).
In the case of Neuroti-cism and Extraversion, the models are not significant(?2 = 5.37, p = .3719, and ?2 = 1.49, p = .2226,respectively; both DF=5, N=320).7.2 Alignment Forms and ?Getting On?
and?Smoothness?The relationship between the different forms ofalignment present in the dialogues and the judges?ratings of ?getting on?
and ?smoothness?
were eval-uated in two separate ordinal logistic models, inwhich they were entered as the dependent variable.The five alignment types (Polarity, Topic, Word,Phrase, and Construction) were entered as indepen-dent variables.
Participant ID was also entered intothe model as an independent variable, since multipleresponses were collected from each participant.Ratings of ?getting on?
(whole model ?2 =1595.10, p < .0001, R Square (U)= .17; DF=84,N=2560) show that Polarity (?2 = 385.45, p <.0001), Construction (?2 = 72.30, p < .0001) andTopic (?2= 16.68, p= .0014) alignment all relate togreater scores of perceived getting on.
Conversely,Word alignment leads to reduced scores of perceivedgetting on (?2 = 14.13, p = .0002).
For ratings ofdialogue ?smoothness?
(?2 = 1519.31, p= .0014, RSquare (U)= .16; DF=84, N=2560), again Polarity(?2 = 209.55, p < .0001), Topic (?2 = 39.39, p <.0001) and Construction (?2 = 28.01, p < .0001)alignment all lead to increased ratings of ?smooth-ness?.
Similarly, Word alignment has a negativeimpact upon perceptions of dialogue ?smoothness?
(?2 = 29.24, p < .0001).8 DiscussionWe now discuss the perception and evaluation re-sults of the CRAG 2 system in greater detail.
Interms of personality perception, extraversion is ac-curately perceived, with agreeableness and consci-entiousness less so, which matches findings frompersonality perception studies in other contexts, in-cluding text based computer-mediated communica-tion (Li and Chignell, 2010; Gill et al, 2006).
Itis interesting to note, however, that alignment helpsperception of conscientiousness, but hurts ratings ofagreeableness.
Reduced accuracy in perception ofagreeableness, which is important to relationships,may have a negative impact on the use of dialoguesin collaborative settings (Rammstedt and Schupp,2008).
Further work could usefully examine ways inwhich these characteristics can be generated in morereadily perceptible ways.
Interestingly, personalityperception is unaffected by whether the judges arenative English speakers or not.
This is a notablefinding, and apparently implies that the social infor-mation relating to personality is available in the textonly environment, or through the generation pro-cess, it is equally accessible to native and non-nativeEnglish speakers.
Native speaking judges were morecritical in rating dialogue smoothness and charactersgetting on, perhaps indicating a finer-grained aware-ness of linguistic cues in interpersonal interaction,or else just greater confidence in making negativejudgements of their native language.Our finding that our generated alignment actuallydecreases the perceived positivity of the relationshipis contrary to what is generally predicted by the lit-erature (Brennan and Clark, 1996; Shepard et al,2001; Pickering and Garrod, 2004); but cf.
Nieder-hoffer and Pennebaker (2002).
Likewise, we wouldalso have expected the dialogues with alignment tohave been perceived to have gone more smoothly.However, in our evaluation of the different typesof alignment, we note that alignment per se is notnecessarily a bad thing: Generally alignment of Po-larity, Topic, and Construction are seen positivelyleading to higher ratings of ?getting on?, ?smooth-ness?, and increased accurate perception of Agree-ableness; repetition of individual words is howeverviewed negatively, and leads to lower ratings of ?get-ting on?
and ?smoothness?.46There are a number of possible explanations forthese negative responses to our generated dialoguealignment.
They hinge on understanding what isinvolved in generating alignment, or similar be-haviour, in dialogue participants.
First, it could bethat our dialogues encode the ?wrong?
type of simi-larity.
For example, the alignment and entrainmentapproaches to similarity usually study task-based di-alogues, which often focus on establishing a sharedvocabulary for referencing objects (i.e., at the wordlevel).
In such cases, the similarity arises eitherthrough priming mechanisms, or the establishmentof common ground.
Given that we used an align-ment model to generate similarity in our dialogues,this kind of repetition or similarity may seem incon-gruent or out of place in dialogues that are not task-based (cf.
negative impact of word-level alignment).A second explanation might be that similarity re-lates to positive outcomes when it occurs over alonger, rather than shorter, period of time (Reit-ter, 2008).
In the current study the dialogues con-sisted of eight turns, thus similarity was not gener-ated over a long period.
Indeed, linguistic similarityover a longer period of time may be more consis-tent with perceptions of social similarity, such as in-group, rather than outgroup, membership (Shepardet al, 2001).
Indeed, in such contexts word choiceis an important feature in dialogue and would be use-ful to incorporate into a dialogue model to simulateingroup membership.Third, in communication accommodation theoryit is ?convergence?
?
the process of increasing sim-ilarity between interlocutors ?
which is important,rather than similarity alone.
In the current study,convergence was not examined since the dialogueswere generated with static levels of alignment.So how do these findings relate back to the area ofdialogue generation for applied contexts?
Similarlyto findings for the PERSONAGE system (Mairesseand Walker, 2010), personality in our generated di-alogues is perceived with similar accuracy to theway humans perceive personality of other humans.This suggests that our CRAG 2 system can createbelievable characters to whom the user can poten-tially relate while auditing the dialogues, or using adialogue-based interface.
That alignment can havenegative effects on dialogue perception we proposeis due to the form of alignment depicted in these gen-erated dialogues (i.e., task-based nature emphasisingsimilarity at the word level), rather than alignment ingeneral.
We do not take this result to necessarily in-dicate that alignment in generated dialogues shouldbe avoided.
Rather, its implementation should becarefully considered, especially to ensure that theform of similarity achieved makes sense in the com-municative context.
Indeed, as we show in the eval-uation of the generated dialogues, alignment at thePolarity, Topic, and Construction levels is gener-ally viewed positively, however in contrast align-ment at the Word level tends to be viewed more neg-atively.
One of the key suggestions arising from thisstudy is that the different forms of dialogue simi-larity cannot simply be used interchangeably, withalignment found in task-based dialogues which mayinclude many instances of word-level repetition andalignment not necessarily appropriate in non-taskdialogues, and thus not automatically resulting inperceptions of positivity.
We note that non-nativespeakers were more forgiving in their ratings of thedialogues containing alignment.
Given that theywere equally able to perceive the personality of thecharacters, this may be due to non-native speakershaving fewer expectations of alignment behaviourin dialogue.
Indeed in some contexts, greater align-ment, and thus repetition, may be beneficial for non-native speakers auditing dialogues.To conclude, personality in our generated dia-logues was perceived with comparable accuracy tohuman texts, but alignment or similarity betweenspeakers ?
especially at the word level ?
regardednegatively.
We would like to see future work exam-ine further the responses to different forms of align-ment, including convergence, in generated dialogue.9 AcknowledgementsWe acknowledge Edinburgh-Stanford Link funding,and the partial support of the Future and EmergingTechnologies programme FP7-COSI-ICT of the Eu-ropean Commission (project QLectives, grant no.:231200).
We thank Amy Isard, Scott Nowson andMichael White for their assistance in this work.
Aversion of the paper was presented at the TwentiethSociety for Text and Discourse conference; thanksto Herb Clark, Max Louwerse and Michael Schoberfor their insights regarding linguistic similarity.47References[Bortfeld and Brennan1997] H. Bortfeld and S. E. Bren-nan.
1997.
Use and acquisition of idiomatic expres-sions in referring by native and non-native speakers.Discourse Processes, 23:119?147.
[Brennan and Clark1996] Susan E. Brennan and Her-bert H. Clark.
1996.
Conceptual pacts and lexi-cal choice in conversation.
Journal of Experimen-tal Psychology: Learning, Memory, and Cognition,22(6):1482?1493, November.
[Brennan1996] Susan E. Brennan.
1996.
Lexical entrain-ment in spontaneous dialog.
In International Sympo-sium on Spoken Dialog, pages 41?44.
[Brockmann2009] Carsten Brockmann.
2009.
Personal-ity and Alignment Processes in Dialogue: Towards aLexically-Based Unified Model.
Ph.D. thesis, Univer-sity of Edinburgh, UK.
[Cassell et al2000] Justine Cassell, Joseph Sullivan, ScottPrevost, and Elizabeth Churchill, editors.
2000.
Em-bodied Conversational Agents.
MIT Press, Cam-bridge, MA, USA.
[Foster and White2004] Mary Ellen Foster and MichaelWhite.
2004.
Techniques for text planning withXSLT.
In Proceedings of the 4th Workshop on NLPand XML (NLPXML-04) at the 42nd Annual Meet-ing of the Association for Computational Linguistics(ACL-04), pages 1?8, Barcelona, Spain.
[Gill and Oberlander2002] Alastair J. Gill and Jon Ober-lander.
2002.
Taking care of the linguistic features ofextraversion.
In Proceedings of the 24th Annual Con-ference of the Cognitive Science Society (CogSci2002),pages 363?368, Fairfax, VA, USA.
[Gill et al2006] Alastair J. Gill, Jon Oberlander, and Eliz-abeth Austin.
2006.
Rating e-mail personality at zeroacquaintance.
Personality and Individual Differences,40(3):497?507.
[Hernault et al2008] Hugo Hernault, Paul Piwek, HelmutPrendinger, and Mitsuru Ishizuka.
2008.
Generatingdialogues for virtual agents using nested textual coher-ence relations.
In Proceedings of Intelligent VirtualAgents, pages 139?145.
[Isbister and Nass2000] Katherine Isbister and CliffordNass.
2000.
Consistency of personality in inter-active characters: verbal cues, non-verbal cues, anduser characteristics.
International Journal of Human?Computer Studies, 53(2):251?267.
[Li and Chignell2010] J. Li and M. Chignell.
2010.
Birdsof a feather: How personality influences blog writ-ing and reading.
Int.
J. Human-Computer Studies,68:589?602.
[Mairesse and Walker2010] Franc?ois Mairesse and Mari-lyn Walker.
2010.
Towards personality-based useradaptation: Psychologically informed stylistic lan-guage generation.
User Modeling and User-AdaptedInteraction, 20(3):227?278.
[Niederhoffer and Pennebaker2002] Kate G. Niederhof-fer and James W. Pennebaker.
2002.
Linguistic stylematching in social interaction.
Journal of Languageand Social Psychology, 21(4):337?360.
[Nowson et al2005] S. Nowson, J. Oberlander, and A.J.Gill.
2005.
Weblogs, genres and individual differ-ences.
In Proceedings of the 27th Annual Conferenceof the Cognitive Science Society, pages 1666?1671.
[Pennebaker and King1999] James W. Pennebaker andLaura A.
King.
1999.
Linguistic styles: Languageuse as an individual difference.
Journal of Personalityand Social Psychology, 77(6):1296?1312.
[Pickering and Garrod2004] Martin J. Pickering and Si-mon Garrod.
2004.
Toward a mechanistic psychol-ogy of dialogue.
Behavioral and Brain Sciences,27(2):169?225.
[Porzel et al2006] Robert Porzel, Annika Scheffler, andRainer Malaka.
2006.
How entrainment increases di-alogical efficiency.
In Proceedings of Workshop on onEffective Multimodal Dialogue Interfaces.
[Rammstedt and Schupp2008] Beatrice Rammstedt andJu?rgen Schupp.
2008.
Only the congruent survive ?personality similarities in couples.
Personality and In-dividual Differences, 45(6):533?535.
[Reitter2008] David Reitter.
2008.
Context Effects inLanguage Production: Models of Syntactic Priming inDialogue Corpora.
Ph.D. thesis, University of Edin-burgh, UK.
[Shepard et al2001] Carolyn A. Shepard, Howard Giles,and Beth A.
Le Poire.
2001.
Communication accom-modation theory.
In W. Peter Robinson and HowardGiles, editors, The New Handbook of Language andSocial Psychology, chapter 1.2, pages 33?56.
JohnWi-ley & Sons, Chichester, UK.
[van Deemter et al2008] Kees van Deemter, BrigitteKrenn, Paul Piwek, Martin Klesen, Marc Schro?der,and Stefan Baumann.
2008.
Fully generated scripteddialogue for embodied agents.
Artificial Intelligence,172(10):1219?1244.
[White2006a] Michael White.
2006a.
CCG chart real-ization from disjunctive inputs.
In Proceedings of the4th International Natural Language Generation Con-ference (INLG-06), pages 9?16, Sydney, Australia.
[White2006b] Michael White.
2006b.
Efficient realiza-tion of coordinate structures in Combinatory Catego-rial Grammar.
Research on Language and Computa-tion, 4(1):39?75.48
