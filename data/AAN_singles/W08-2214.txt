The Idiom?ReferenceConnectionMarjorie McShaneSergei NirenburgUniversity of Maryland Baltimore County (USA)email: marge@umbc.eduAbstractIdiom processing and reference resolution are two complex aspects of textprocessing that are commonly treated in isolation.
However, closer studyof the reference needs of some idioms suggests that these two phenom-ena will need to be treated together to support high-endNLP applications.Using evidence from Russian and English, this article describes a num-ber of classes of idioms according to their reference needs and suggests amethod of lexical encoding which, supplemented by procedural semanticroutines, can adequately support the full semantic and referential inter-pretation of these idioms.165166 McShane and Nirenburg1 IntroductionReference resolution and idiom processing have received much attention in naturallanguage processing (NLP), but these phenomena are commonly treated in isolationof each other, andmost treatments address only a single aspect of the respective overallproblems.
For example, much of the work on practical reference resolution has con-centrated on establishing textual coreference relations for a subset of pronouns (e.g.Mitkov et al, 2002), and the most widely pursued aspect of idiom processing has beenthe automatic extraction of multi-word expressions (of which idioms are a subtype)from corpora (e.g.
Baldwin and Villavicencio, 2002).
Of course, some contributions inboth of these subfields have ventured much wider;1 however, we have found few prac-tical approaches that explore the interaction of idiomaticity and reference resolutionand its implications for NLP.One might ask, why treat these phenomena together?
Perhaps the best reason is tohighlight the indispensability for real progress in NLP of semantic analysis that goesbeyond what the most researchers are currently pursuing in practical system building.Another reason to integrate the study of reference and idioms is to address the diffi-culties that automatic text analyzers will encounter in detecting and processing idiomswhen some of their components are elided.
Ellipsis, a means of expressing reference,thus, becomes an important component of this study.
The approach suggested hereshould, we believe, alleviate some of the inherent difficulties of these complex tasks.Note that similar kinds of problems are discussed in Pulman (1993), which suggeststhe need for ?contextual reasoning?
applied to idioms, which is ?the process of tak-ing the information that can be derived linguistically from a sentence and fleshing itout with information supplied by the local context or general background knowledge?
(Pulman, 1993, p. 251).The proposed analysis delineates several categories of idioms according to their ref-erence needs and shows how the encoding of idioms in a semantically oriented lexiconcan support both basic semantic analysis and reference resolution.
Although the anal-ysis is theory- and system-neutral, the exposition follows a specific, implemented the-ory of natural language processing.
This theory, called Ontological Semantics (Niren-burg and Raskin, 2004), colors our understanding of the nature of meaning-orientedNLP, including our treatment of reference and idioms.Ontological Semantics seeks to achieve full semantic and pragmatic analysis oftexts such that interpreted structures, rather than textual strings, serve as the input toautomatic reasoners.
Ontological Semantics relies on knowledge obtained throughmany layers of processing: preprocessing followed by morphological, syntactic, se-mantic and discourse analysis.
The static knowledge resources, which are intercon-nected and all use the same metalanguage of description, are a lexicon and onomas-ticon for each language processed, a language-independent ontology (a knowledgebase of concept types), and a language-independent fact repository (a knowledge baseof concept instances).
Static resources are compiled manually, using sophisticatedediting environments, to ensure high quality, though we are experimenting with ma-chine learning to speed the acquisition process.
Text analysis involves the automatic1See, for example, the contributions to recent workshops (e.g., ACL 2004 ?Reference Resolution and itsApplications?
and ?Multi-word Expression: Integrating Processing?
; EACL 2006 ?Multi-word Expressionsin a Multilingual Context?)
and Stanford?s Multi-Word Expression Project (http://mwe.stanford.edu/).The Idiom?Reference Connection 167evaluation of semantic preferences recorded in the lexicon and ontology, as well aspreferences based on stochastically trained measures of semantic distance among on-tological concepts.Within this semantically-oriented, knowledge-based environment we define refer-ence resolution rather differently than in most NLP applications, where resolving ref-erence is understood as linking coreferring text strings.
In fact, our conceptualizationof reference resolution strongly influences how we approach resolving reference inidioms and therefore must be clarified from the outset.2 What is Reference Resolution?We define reference resolution as the anchoring of referring expressions in the episodicmemory of an intelligent text processing agent.
This knowledge base of stored mem-ories, called the fact repository, differs from the ontology in that it contains indexedinstances of ontological concepts and their property-based interconnections.
Anchor-ing entities in the fact repository is the culmination of semantic analysis and referenceresolution.When presented with a new text, the system must first semantically analyze everysentence, creating an unambiguous text meaning representation (TMR); reference isthen resolved for the correct meaning of each string.
The TMR contains the crucialclues for determining which entities are referring expressions: numbered instancesof ontological concepts are referring expressions whereas properties, literal propertyfillers, and so on, are not.
As an example, consider the following context which,although contrived, illustrates many relevant phenomena at one go.
(1) At 4:48 it became clear that the programmers couldn?t finish debugging thesystem before the 5:00 deadline.
All hell broke loose, the boss was fit to betied ?
almost strangled his project manager!Let us concentrate on the second sentence.
In the tables below, each string oridiomatic group of strings from that sentence (top row) is associated with its corre-sponding semantic structure (bottom row).
The concept instances set in italics mustbe resolved.
The important thing to notice is that the system must orient around se-mantic structures rather than strings in order to create the correct inventory of referringexpressions.all broke his projecthell loose the boss was fit to be tied almost strangled managerCHAOS-1 MANAGER-1 ANGER (RANGE 1) HUMAN-1 (MODALITY-2(TYPE EPISTEMIC)(VALUE .9)(SCOPE STRANGLE-1))STRANGLE-1 ASSISTANT-1Highlights of the analysis are as follows:?
Whereas all hell and broke loose could individually be referring expressions insome other context, when the are used in this idiom they together represent asingle meaning, CHAOS, this instance of which is called CHAOS-1 ?
the firstinstance of the concept CHAOS encountered while processing the given text orcorpus.
This event, like all instances of OBJECTs and EVENTs in TMRs, re-quires reference resolution: it must be determined whether this is a new event to168 McShane and Nirenburgbe added to the fact repository or a reference to an event that is already recordedthere.
In this case, it is a new event, since the algorithm used to detect eventcoreference requires either (a) that there be an ample overlap of properties as-sociated with a candidate fact repository ?anchor?
or (b) that the new event bereferred to using a definite description (e.g., the strike), with the definite de-scription triggering the search for a coreferent in the context or fact repository.?
Whereas the boss and his project manager can either be descriptors (as in Thisman is a boss and that man is a project manager) or referring expressions, herethey are referring expressions and must be resolved.?
Whereas fit and tied can be referring expressions in isolation, in this idiom theyare not referring expressions, nor is the idiom on the whole a referring expres-sion: it indicates the highest value of the property ANGER.?
Although the second half of the sentence has no overt subject, he is the under-stood subject.
The reference resolver must detect this missing entity and createa coreference link between it and MANAGER-1.?
Almost is never a referring expression: it indicates a value of less than 1 forepistemic modality scoping over the given event (here, STRANGLE-1).
How-ever, some other adverbs are referring expressions (e.g., here, yesterday) andmust be resolved.?
STRANGLE-1, like all EVENTs, must undergo reference resolution.Once all referring expressions have been detected, the system must resolve themagainst the fact repository.
There are several possible scenarios: (a) the entity has atextual antecedent, in which case the new entity is linked to the same fact repositoryanchor as that antecedent; (b) the entity does not have a textual antecedent but isalready a known entity (like the earth or Plato) and is linked to the existing anchorin the fact repository; (c) the entity is determined to be new and a new anchor isestablished for it in the fact repository.
This, in a nutshell, is how reference is resolvedin our semantic analysis environment, OntoSem.Our reference resolver for English is implemented and covers all the eventualitiesposed by this sentence.
It has not yet undergone formal evaluation.
We will nowdescribe how idioms are encoded to support this process.The examples used for illustration are not from English, they are from Russian,a language that is not currently supported in OntoSem.
The reason for using Rus-sian examples even though the implemented system does not yet cover Russian isthat Russian presents a superset of challenges for reference resolution ?
namely, amuch wider use of ellipsis, or the null referring expression; therefore, showing thatthe scope of phenomena presented by Russian can be handled a fortiori shows thatthe same phenomena can be handled in English.
Indeed, the OntoSem environmentsupports multilingual text processing, using a language-independent ontology and factrepository, and using the same types of lexicon entries regardless of the language pro-cessed (see McShane et al, 2005).The Idiom?Reference Connection 1693 Encoding Idioms to Support their Full AnalysisA cornerstone of theoretical, descriptive, computational and psycholinguistc work onidioms is the attempt to understand to what extent idioms are fixed and to what extentthey are flexible (see, e.g., Cacciari and Tabossi (1993), whose component articlesinclude extensive overviews of the literature).
The competing classifications can de-rive from both theoretical considerations, like psycholinguistic evidence, and practicalconsiderations, like whether an NLP system attempts to analyze only those idioms thatare recorded or whether it attempts to analyze new coinages as well.
The scope of thecurrent analysis is idioms that are recorded as well as certain types of free modifi-cations of them.
Completely new idioms will need to be processed as ?unexpectedinput?, in a similar way as the system attempts to process metaphor and metonymy.Like Stock et al (1993) (in Cacciari and Tabossi (1993)), we integrate idioms intothe lexicon as ?more information about particular words?
(Stock et al, 1993, p. 238)rather than treat them using special lists and idiosyncratic procedures.
In the discus-sion below, we look at some examples of idioms that highlight noteworthy referenceresolution needs and show how our all-purpose lexical encoding mechanisms and ref-erence resolution routines cover idiomatic input as readily as compositional input.
Amore detailed description of how we encode idioms and other multi-word expressions,as well as many additional examples, can be found in McShane et al (2008).3.1 Productive Syntactic Processes in IdiomsEach of the examples below contains an idiom in the second half, and each of thoseidioms shows at least one productive use of ellipsis.
In the examples, the elided cat-egory, [e], and its antecedent, if syntactically available, are in boldface.
Grammaticalinformation is provided sparingly for reasons of space.2(2) Nadoit-is-necessaryzashchishchat?to-defendsvoixself?sACC.PLsotrudnikovcoworkersACC.PLaandnenotprinosit?deliverINFIN[e][e]ACCvaszhertvusacrificeACC.SG.FEM..You should defend your coworkers, not sacrifice them.
(3) JaInedon?txochuwantpreduprezhdat?to-forewarnego,himACC[e][e]1.SGxochuwant1.SG.zastat?
[e]to-catch[e]3.SG.ACC.MASCvrasploxunawares..I don?t want to forewarn him, I want to catch him unawares.These examples represent configurations in which ellipsis is highly promoted in non-idiomatic and idiomatic contexts.3 Example (2) shows VP conjunction with the latterof two coreferential direct objects elided.
Example (3) shows subject and direct object2Most of the Russian examples here are from Lubensky (1995), which is a bilingual learner?s dictionaryof Russian idioms that provides grammatical descriptions but no special treatment of ellipsis.3See McShane (2005) for discussion and extensive examples of ellipsis-promoting configurations usingnon-idiomatic examples.
Idiomatic examples of many of the phenomena have also been found but are notpresented here for reasons of space.170 McShane and Nirenburgellipsis in an ?assertion + elaboration?
strategy (see McShane (2005)), in which thetopic of discourse is asserted then either restated or elaborated upon subsequently.The above idioms are idiomatic VPs that are recorded in the OntoSem lexicon in asimilar way as typical verbs, with just a few special features.
Let us take the exampleof v grob vgonjat?
?to kill?
(literally: to drive to the grave) as an example.
(vgonjat?-v1(def "idiom: v grob vgonjat?
- to kill (drive to the grave)")(ex "Ja v grob vgonju tebja!
I?ll kill you!
")(syn-struc((subject ((root $var1) (cat n)))(root $var0) (cat v)(directobject ((root $var2) (cat n)))(pp ((root $var3) (cat prep) (root v)(obj ((root $var4) (cat n) (root grob)))))(sem-struc(KILL(AGENT (value ^$var1))(THEME (value ^$var2)))(^$var3 (null-sem +)) (^$var4 (null-sem +))))This lexical sense is headed by the verb, vgonjat?
?drive?.
The syntactic zone (syn-struc) says that the verb takes a subject, direct object and prepositional phrase withno unusual syntactic constraints, meaning that the structure is open to the same sortsof variability ?
like different verbal tenses and aspects, free word order, syntactictransformations and ellipsis?
as is typical of non-idiomaticRussian.
The only specialsyntactic feature is that the roots of the lexical components of the prepositional phraseare explicitly listed: v (into) and grob (grave).
The semantic zone (sem-struc) recordsthe semantic interpretation: it is headed by a KILL event whose AGENT and THEMEare productively analyzed as the meaning of the subject and direct object, respectively.The meanings of v (into) and grob (grave), which are ?
under this analysis ?
non-compositional, are attributed null semantics.Two aspects of semantic interpretation require comment.
First, in most contextsthis idiom is not used to threaten actual killing; however, the same can be said forthe lexeme kill used in the threat I?ll kill you!
; this aspect of interpretation is clearlyextra-lexical.
Second, although it is likely that a person who did not know this idiomwould be able to interpret its meaning using the meanings of the component elements,most NLP systems would struggle.
Once we decide to record a phrase as idiomatic toease processing, the level of transparency of the components becomes unimportant.Analysis of a clause that uses vgonjat?
v grob ?kill?
will generate three referringexpressions that must be resolved: the AGENT of the killing, the THEME of the killing(we will not quibble here about which case role to choose for the person killed), andthe act of killing.
These referring expressions might be realized, for example, asHUMAN-23, HUMAN-24 and KILL-4 in a given text meaning representation.
Once thesystem has arrived at these analyses, reference resolution proceeds as it would for anyreferring expressions, whether or not they were part of an idiom: textual coreferents?
recorded as semantic entities in TMR ?
are sought and, whether or not they arefound, the referring expression is anchored in the fact repository.
If we look at what isThe Idiom?Reference Connection 171special about processing the reference in idioms, then, there are only two aspects: (1)ensuring that productive syntactic processes are permitted only if applicable, and (2)ensuring that the correct inventory of referring expressions ?
understood as semanticstructures ?
is generated.Let us compare this treatment of idioms to the one proposed by Villavicencio et al(2004).
They treat the potential variability of idioms using the notion of semanticdecomposition.
If an idiom can be paraphrased in a syntactically parallel way, it is de-composable (spill the beans ?
reveal a secret), even though non-standard meaningsneed to be assigned to each component.
The fundamental differences between theirapproach and ours relate to semantic encoding and reference resolution.
For Villavi-cencio et al, the semantics of idioms is conveyed by paraphrases with other linguisticelements (spill ?
reveal, beans ?
secret).
For us, semantics is formulated using theontologically grounded metalanguage of OntoSem.
As regards the initial syntacticparse, both approaches seem to offer the same coverage of syntactic variability, andresources could be shared with seeminglyminimal work devoted to format conversion.3.2 Essentially Frozen IdiomsWe have just shown how syntactic processes ?
specifically, various types of ellipsis?
can apply to idioms in a language, and how the lexical encoding of such idioms al-lows for syntactic variability.
Other idioms, by contrast, are syntactically frozen.
Suchidioms are commonly treated as strings with spaces, but this only works if absolutelyno modifiers or other entities (e.g., ?ahem?)
can intervene.
If intervening materialis possible, it is preferable to encode the idiom using separate syntactic constituents.However, if one records the components individually, the analysis system must under-stand that diathesis transformations, ellipsis, pronominalization, etc., are not applica-ble.
In OntoSem we label frozen syntactic constituents using immediate constituents,like NP, rather than grammatical function labels, like subject.
Since transformationsapply only to grammatical functions, they become automatically inapplicable if imme-diate constituents are used.
However, since all constituents are still listed individually,intervening material and free modification are permitted in the usual way, as in Hekicked the bloody bucket!Of course, treating free modifications of non-compositional parts of an idiom orother multi-word expression (MWE) is not trivial, as described in some depth in Mc-Shane et al (2008).
To summarize that discussion, our basic approach to treating mod-ifiers within MWEs is to analyze the MWE as indicated in the sem-struc, then attemptto attach the meaning of ?orphan?
modifiers to the meaning of the entire structureusing generalized processes for meaning composition.
In the case of He kicked thebloody bucket, the basic meaning will be rendered in the text meaning representationas (DIE-1 (EXPERIENCER HUMAN-1)).
The modifier bloody has two senses in ourlexicon, semantically described as (RELATION BLOOD) and (EMPHASIS .7).
We havea rule that prefers the stylistic interpretation in the case of non-compositional idioms.So the final text meaning representation will be (DIE-1 (EXPERIENCER HUMAN-1)(EMPHASIS .7)).
((emphasis .7) indicates a high value for the property EMPHASIS onthe abstract scale {0,1}.
)Such meaning composition is not specific to multi-word expressions: our semanticanalyzer carries out the same process in all cases when meaning must be recovered172 McShane and Nirenburgfrom an incomplete parse.
The latter may be due to insufficient coverage of the syn-tactic parser, lexical lacunae that confound the parser, or unexpected (ungrammatical,highly elliptical, etc.)
input.Returning to our main point about how to encode essentially frozen idioms, en-coding their components as separate entities provides the best of both worlds: frozencomponents, fixed word order, and the possibility of intervening strings that typicallyact as modifiers.
One Russian idiom that fits this description is shown below.
(4) Ishchi-svishchiLook-for-whistle-forIMPERvetrawindvinpolefield..?You?ll never find him/her/it/etc.?
(ishchi-svishchi?-v1(def "idiom: ishchi-svishchi vetra v pole?you will never find him/her/it/etc.?
")(syn-struc((root $var0) (cat v) (form imperative)(np ((root $var1) (cat np) (root vetra)))(pp ((root $var2) (cat prep) (root v)(np ((root $var3) (cat np) (root pole)))))(sem-struc(modality((type potential)(value 0)(attributed-to (sem HUMAN))(scope (value refsem1))))(refsem1(FIND(AGENT (sem human))(THEME (sem all))(time (> (find-anchor-time))))(^$var1 (null-sem +))(^$var2 (null-sem +))(^$var3 (null-sem )))(meaning-procedure(seek-specification((value find.modality.attributed-to)(resolve-1st-sing)))(seek-specification((value find.agent) (resolve-2nd-sing)))(seek-specification((value find.theme) (resolve-3rd))))The syntactic description should be self-evident based on the examples and descriptionabove, but the semantic structure requires commentary.The variables $var1, $var2 and $var3 are attributed null semantics because they donot contribute to compositional meaning ?
that is, this idiom (?look for whistle forwind in the field?)
is completely semantically opaque.The sem-struc is headed by a modality statement: it is impossible introducesmodal-ity of the type ?potential?
with a value of 0.
This modality is attributed, by default, toThe Idiom?Reference Connection 173the speaker.
It scopes over a proposition headed by FIND, and the latter is ontologicallydefined as taking an AGENT and a THEME case role.The semantic representation includes four referring expressions that must be re-solved: (1) the speaker, to whom the modality is attributed; (2) the FIND event itself,which will be a new anchor in the fact repository; (3) the AGENT of finding, which isthe interlocutor; and (4) the THEME of finding, which must be contextually computed.The OntoSem analyzer would resolve the reference of the instance of FIND in theusual way; this requires no further comment.
What does require further comment,however, is the way in which we guide the analyzer?s efforts to resolve the under-specified instances of HUMAN, HUMAN and ALL that represent the speaker, the inter-locutor and the object of the FIND event, respectively.
We provide this guidance inthe meaning-procedures zone of the lexicon entry, which contains calls to proceduralsemantic routines that are launched at run time.
For example, we need to know whothe speaker is so that the modality can be attributed to the correct real-world person.This is done using the ?seek-specification?
meaning procedure.
The first argument ofthis procedure is what we are seeking the specification of (i.e., to whom the modalityis attributed), and the second argument is the function that will let us determine this ?i.e., ?resolve-1st-sing?, which is, incidentally, the same routine used to seek the refer-ent of the pronoun I.
The latter meaning procedure includes ordered routines testingfor many cases including:?
the pronoun I being used in a context in which another pronoun I (which itselfshould have been resolved earlier) can serve as an antecedent: I like chocolateice cream and always choose it if I have the option.?
the pronoun I being used within a quotation, and that quotation being the THEMEof a SPEECH-ACT of which the coreferent of I is the AGENT: I/Mary said, ?ButI don?t want strawberry ice cream!??
the pronoun I being used outside of a quotation and the writer of the textbeing available in metadata: <title>Understanding Your Finances</title><author>Mary Smith</author> .
.
.
I believe that the only way to understandyour finances is to consult a financial advisor.In short, using the combination of the information in the sem-struc and meaning-procedures zones we arm the analyzer with the types of the information a personwould use to both understand the idiom and to resolve all implied references.
(Fora more detailed description of meaning procedures in OntoSem, see McShane et al(2004).
)3.3 Subjectless ConstructionsWe conclude our example-based discussion with one category of phenomena in whichidiom processing is actually much simpler than the processing of structurally similarcompositional language since it permits preemptive disambiguation.
The disambigua-tion in question regards subjects, which in Russian can be overt, elided or completelymissing.
Completely missing (uninsertable) subjects occur in the following construc-tions:174 McShane and Nirenburg?
In the indefinite personal construction a 3rd person plural verb form is usedwithout a subject to indicate an unspecified person or people.
It is used incontexts like the Russian equivalent of They say it will rain today.?
In the non-agentive impersonal construction a 3rd person singular verb is usedwithout a subject to show that the event is non-agentive.
It is used in contextslike the Russian equivalent of He?s attracted to girls like that, whose structure-preserving paraphrasewould be ?
[some unnamed force] attracts him to girls likethat.
?The difficulty in processing productive subjectless sentences is determining whetherthe verb has a specific subject that has been elided and must be recovered, or doesnot have a specific subject, in which case the generalized personal or non-agentiveinterpretation should be used.
However, when it comes to idioms that employ theseconstructions, the syntax can be encoded to explicitly block a subject, and the seman-tics can explicitly indicate the interpretation added by the missing subject.An idiom that employs the indefinite personal construction is shown in (5), alongwith the lexical sense of bit?
?hit?
that records it.
(5) LezhachegoLying-down-personACC.SG.MASC.nenotb?jutbeat3.PL.PRES...[L-45]You don?t/shouldn?t kick a man/person/guy when he?s down.
(bit?-v10(def "phrasal: Lezhachego ne b?jut - you shouldn?t dosomething bad to someone who is in a bad position already")(ex "You don?t/shouldn?t kick a guy when he?s down")(syn-struc((np ((root $var1) (cat n) (root lezhachij)(case acc) (gender masc) (number sing)))(verb-neg ((root $var2) (cat verb-neg)))(root $var0) (cat v) (tense present) (person third) (number pl))))(sem-struc(modality ; ??should??
(type obligative)(scope (value refsem1))(value 1)(attributed-to *speaker*))(refsem1(modality ; ??not??
(type epistemic)(scope (value refsem2))(value 0)(attributed-to *speaker*)))(refsem2(ABUSE(AGENT (value refsem3))The Idiom?Reference Connection 175(THEME (value refsem4))))(refsem3(set(member-type human)(cardinality 1)(complete yes)))(refsem4 (HUMAN (EXPERIENCER-OF MISFORTUNE)))(^$var1 (null-sem +)) (^$var2 (null-sem +))(output-syntax (cl)))The syn-struc should be clear based on previous examples; the only new element isverb-neg, which indicates a negating particle.The sem-struc looks more complex than it actually is because many of the slotfillers require reified structures, each of which must be pointed to using numberedvariables called refsems.The sem-struc is headed by obligativemodality, which scopesover an epistemicmodality, which scopes over an ABUSE event.
The obligativemodal-ity has the value 1 (absolute obligation), whereas the epistemic modality has the value0 (negation).
Put plainly, ?it is necessary not to abuse?.
The AGENT of the ABUSEevent is the set of all people, described just as we describe the word everyone.
TheTHEME of the ABUSE event is a HUMAN who is the EXPERIENCER-OF a MISFOR-TUNE.
One might ask, why not record this idiom as a fully fixed entity with whitespaces in between, rather than as a multi-part syntactic structure?
For the same rea-son as discussed earlier: there is an outside chance of modification, so the componentelements must be kept separate.Example (6) shows an idiomatic example of the second type of obligatorily sub-jectless sentence: the non-agentive impersonal construction.
(6) KakimwhatINSTR.SG.MASC.vetromwindINSTR.SG.MASC.vasyouACC.PL/POLITEzaneslobrought3.SG.NEUT.PFVsjudahereDIRECTIONAL?
?What brings you here?/What are you doing here?This idiom will be recorded under the headword zanesti ?bring?.
The core meaningof the idiom ?
COME ?
heads the sem-struc.
There are two variables in this multi-word expression: the direct object, mapped to the AGENT of COME, and the spatialadverbial, mapped to the DESTINATION of COME.
These are productively analyzed atrun-time.
The meaning of ?what wind?
is, of course, attributed null semantics.To summarize this section: recording obligatorily subjectless idioms not only pro-vides for their semantic interpretation, it also removes ambiguity in analysis, since the?elided subject?
reading is explicitly blocked.4 Final ThoughtsThis paper has presented an analysis of phenomena that extends past what any givensystem currently uses or requires.
However, the utility of this analysis reaches wellbeyond the traditional goals of descriptive and theoretical linguistics.
Ideally, systembuilding in NLP should centrally involve the objective of incrementally overcoming176 McShane and Nirenburgsuccessively more difficult challenges and thus lead to more sophisticated systems inthe future.
Looking forward to the next stage can help us to develop methodolog-ical, architectural and knowledge infrastructures to facilitate progress toward futuregoals.
The OntoSem environment does not currently work on Russian, though it hasbeen applied, at least partially, to several languages apart from English in the past ?including such different languages as Turkish, Spanish, Korean and Georgian.
Thereason for exploring the idiom-reference connection in Russian was to judge how wellour approach, which is implemented for and works well in English, holds up cross-linguistically.
Having worked the examples presented in this paper and many others,we are convinced that when the time comes, a Russian OntoSem will be configurablewithout the need to expand the theory and methodology that support our treatment ofidioms, ellipsis and reference overall.A reasonable question would be, why not evaluate the approach on English, sincean English system already exists?
The reason is purely practical: it is far more diffi-cult and expensive to run evaluations of knowledge-based systems that treat complexphenomena than it is to run evaluations of systems that treat less complex phenomena.That being said, we are just completing a new version of our DEKADE knowledgeacquisition and evaluation environment which will make it much easier than before toevaluate the results of text analysis.
We expect regular evaluations to become part ofour development work in the near future.ReferencesBaldwin, T. and A. Villavicencio (2002).
A case study on verb-particles.
In Pro-ceedings of the Sixth Conference on Computational Natural Language Learning(CoNLL 2002), pp.
98?104.Cacciari, C. and P. Tabossi (1993).
Idioms: Processing, Structure and Interpretation.Lawrence Erlbaum and Associates, Inc.Lubensky, S. (1995).
Russian-English Dictionary of Idioms.
Random House.McShane, M. (2005).
A Theory of Ellipsis.
Oxford University Press.McShane, M., S. Beale, and S. Nirenburg (2004).
Some meaning procedures of On-tological Semantics.
In Proceedings of LREC-2004.McShane, M., S. Nirenburg, and S. Beale (2005).
An NLP lexicon as a largely lan-guage independent resource.
Machine Translation 19(2), 139?173.McShane, M., S. Nirenburg, and S. Beale (2008).
Achieving adequacy of descriptionof multiword entities in semantically-oriented computational lexicons.
Submitted.Mitkov, R., R. Evans, and C. Orasan (2002).
A new, fully automatic version ofmitkov?s knowledge-poor pronoun resolution method.
In Proceedings of CICLing-2000.Nirenburg, S. and V. Raskin (2004).
Ontological Semantics.
MIT Press.The Idiom?Reference Connection 177Pulman, S. (1993).
The recognition and interpretation of idioms.
In C. Cacciari andP.
Tabossi (Eds.
), Idioms: Processing, Structure and Interpretation, pp.
249?270.Lawrence Erlbaum and Associates, Inc.Stock, O., J.
Slack, and A. Ortony (1993).
Building castles in the air: Some com-putational and theoretical issues in idiom comprehension.
In C. Cacciari (Ed.
),Idioms: Processing, Structure and Interpretation, pp.
229?248.
Lawrence Erlbaumand Associates, Inc.Villavicencio, A., A. Copestake, B. Waldron, and F. Lambeau (2004).
The lexicalencoding of MWEs.
In Proceedings of the ACL 2004 Workshop on MultiwordExpressions: Integrating processing.
