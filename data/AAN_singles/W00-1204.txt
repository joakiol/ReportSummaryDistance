Using Co-occurrence Statistics as an Information Sourcefor Partial Parsing of ChineseElliott Franeo DRABEKThe State Key Laboratoryfor Intelligent Technology and SystemsDepartment ofComputer ScienceTsinghua University, Beijing 100084elliott_drabek@ACM.orgQiang ZHOUThe State Key Laboratoryfor Intelligent Technology and SystemsDepartment ofComputer ScienceTsinghua University, Beijing 100084zhouq@slOOOe.cs.tsinghua.edu.cnAbstractOur partial parser for Chinese uses a learnedclassifier to guide a bottom-up parsingprocess.
We describe improvements inperformance obtained by expanding theinformation available to the classifier, fromPOS sequences only, to include measures ofword association derived fromco-occurrence statistics.
We compareperformance using different measures ofassociation, and find that Yule's coefficientof colligation Y gives somewhat betterresults over other measures.IntroductionIn learning-based approaches to syntacticparsing, the earliest models developed generallyignored the individual identities of words,making decisions based only on theirpart-of-speech classes.
On the othor hand,many later models see each word as amonolithic entity, with parameters estimatedseparately for each word type.
In between havebeen models which auempt o generalize byconsidering similarity between words, whereknowledge about similarity is deduced fi'omhand-written sources (e.g.
thesauri), or inducedfrom text.
For example, The SPATTER parser(Magerman, 1995) makes use of the output of aclustering algorithm based on co-occurrenceinformation.
Because this co-occurrenceinformation can be derived from inexpensivedata with a minimum of pre-processing, it can bevery inclusive and informative about evenrelatively rare words, thus increasing thegeneralization capability of the parser trained ona much smaller fully annotated corpus.The cunent work is in this spirit, makingcomplementary use of a relatively smalltreebank for syntactic information and arelatively large collection of flat text forco-occurrence information.
However, we donot use any kind of clustering, instead using theco-occurrence data directly.
Our parser is abottom-up arser whose actions are guided by amachine-learning-based decision-makingmodule (we use the SNoW learner developed atthe University of Illinois, Urbana..Champaign(Roth, 1998) for its strength with potentiallyvery large feature sets and for its ease of use).The learner is able to directly use statisticsderived from the co-occu~euce data to guide itsdecisions.We collect a variety of statistical measures ofassociation based on bigram co-occurrence data(specifically, mutual information, t-score, X 2,likelihood ratio and Yule's coefficient ofcolligation Y), and make the statistics availableto the decision-making module.
We uselabelled constituent precision and recall tocompare performance of different versions ofour parser on unseen test data.
We observe amarked improvement in some of the versionsusing the co-occurrence data, with strongestperformance observed in the versions usingYule's coefficient of  colligation Y and mutualinformation, and more modest improvements inthose using the other measures.1 Background1.I Our Task m Partial ParsingThe current work has developed inthe contextof developing a partial or "chunk" parser forChinese, whose task is to identify certain kindsof local syntactic structure.
The syntactic22analysis we use largely follows the outline ofSteven Abney's work (Abney, 1994).
Weadopt he concept of a "e-head" and an "s-head"for each phrase, where the e-head correspondsroughly to the generally used concept of head(e.g., the main verb in a verb phrase, or thepreposition in a prepositional phrase), and thes-bead is the "main content word" of a phrase(e.g., the main verb in a verb phrase, but theobject of the preposition in a prepositionalphrase).
The core of our chunk definition is alsoin line with Abney's: A chunk is essentially thecontiguous range of words s-headed by a givenmajor content word.
Within this basicframework, we make some aecorunaodations tothe Chinese language and to practicality.
Forexample, by our understanding of Abney'sdefinition, a numeral-classifier phrase followedimmediately by the noun it modifies shouldconstitute two separate chunks.
However suchunits seem likely to be useful in furtherprocessing, and easy to accurately identify, sowe chose to include them in our definition ofchunk.For simplicity and consistency, we adopt avery restricted phrase-structured syntacticformalism, somewhat similar to aphrase-structured formulation of a dependencygrammar.
In our formalism, all constituents arebina_ry branching, and the purpose of thenon-terminal labels is restricted to indicating thedirection of dependency between the twochildren.
Figure 1 shows an example sentencewith some indicative structures.Dependencies within individual chunks areshown with heavy arrows.
A fight-pointingdependency, such as the three dependencieswithin the noun phrase " ) l~ .~t :~y~r~" ,corresponds to a constituent labelled"right-headed".
A left-pointing dependency,such as that between the verb "~,.~\[~" and itsaspect particle "T ' ,  corresponds toa constituentlabelled "left-headed".
These are cases wherethe s-head and the e-head of the phrase areidentical.
When they are not identical, wehave a "two-headed" ependency, like those inthe phrase "~_L \ [~ ' .
Here, the relationbetween "~"  and ".J~" (and between "~_.L" and "~")  is that the left constituentprovides the s-head of the phrase, while the rightconstituent provides the e-head.These four non-terminal categories candescn'be high- or low- level syntactic structures.However, for chunking we wish to leave thehigher-level structures of a sentence unspecified,leaving only a list of local structares.
We treatthis in a consistent way by adding a fifthnon-terminM category "unspecified", andreplacing all higher str~tures with a backboneof strictly left-branching "unspecified" nodes,anchored to a special "wall" token to the left ofthe sentence.
This backbone structure is shownby the light lines in the figure.1.2  Our  Data  Sources  ~ One Large and OneSmallDuring development, we made use of twocorpora.
The first is a relatively small-scaletreebank of approximately 3500 sentences,39,000 words, and 55,000 characters (Zhou,1996).
We transformed this corpus by annotatingeach phrase with c-heads and s-heads, using alarge collection of hand-written rules, and thenextracted chunks from this transformed version.The second corpus, which we use only as asource of co-occurrence statistics, ismuch larger,with approximately 67,000 sentences, 1.5million words, and 2.2 million characters, withsentences eparated and words separated andmarked with parts-of-speech, but with no furthersyntactic annotation (Zhou and Sun, 1999).
Inthe current work we make no use of thepart-of-speech annotation, taking co-occurrence?
counts of word-types alone.1.3 Our Framework - -  C lass i f ier -GuidedShi f t -Reduce Pars ingThe parsing framework we use has beenchosen for maximum simplicity, aided by thesimplicity of the syntactic framework.
Inparsing, we model a left-to-right shift-reduceautomaton which builds a parse-treeconstituent-by-constituent in a deterministicleft--to-right process.
The parsing process isthus reduced to making a series of decisions ofexactly what to build.For training, we extract the series of actionsthe shift-reduce parser would have had to maketo produce the trees from the surface structure ofthe sentences.
This gives a long series ofstate-action pairs: "when the parser was instate X, it took action Y'.
The state descriptionX is set of binary predicates describing the localsurface structure of the sentence and the contents23cucurbit vegetable raising methods already occur lperf.\] foundation on \[rel.\] changeMethods of raising cucurbit vegetables have changed fundamentally.Figure 1.
An example sentence annotated according to our system.of the stack.
We describe these predicates indetail below.
This series of state-action pairs ispresented to the SNoW learner, which tries tolearn to predict the parser actions from theparser states, attempting to find a lineardiserimin:mt over these binary predicates whichbest accounts for the corresponding actions inthe training data.These parse actions can be either "shift a wordfrom the right on to the stack", or "reduce the?
, top elements of the stack" into a singleconstituent.
Because our syntactic frameworkis strictly binary branching, each reduce actionoperates on exactly the top two items on thestack, so the automaton eed only choose acategory for the new constituent.
This decisionturns out to be nearly trivial, and we were able toachieve 100% accuracy on our test set usingonly part-of-speech information, so in theremainder of this paper we discuss only issuesrelating to the more difficult decision of whetherto shift or reduce.Within the shift-reduce decisions, over halfare pre<letermined by the basic requirements ofthe framework.
For example, if there are nowords left to shift, we can only reduce.
If thereis only one item on the stack, we can only shift.These decisions are handled by simpledeterministic rules within the parser and are notshown to the classifier either in training or inparsing.In the first version of the parser, prior to theintroduction of co-occurrence statistics, theinformation available to the classifier is limitedto parts-of-speech of words in the surfacestructure of the sentence, nonterminal categoriesof constituents already built on the stack, andparts-of-speech of the s- and e-heads ofconstituents already built on the stack.
Theseare collected into schemas representing sets ofposs~le binary predicates.
Table 1 shows arepresentative subset of this original set of 18predicate schemas (space does not allow us topresent all of them).
The total of all theinstantiations of all these templates presents apotentially huge feature set, so we rely on animportant property of the SNoW architecture,that it can handle an indefinitely large set of24Pred icate  SchemaPOS (Surface-word \[k\] ) = tRange o fParameters-I K k_< 2POS(Sur face-word \ [k \ ] )  = tl /~ POS(Sur face-word \ [k  + I\]) = t2 -2 ~ k ~ 1Category(Stack \ [k \ ]  ) = c 0 ~ k ~ 1Category(Stack \ [k \ ]  ) = ci /k Category  (Stack \[k + I\] ) = c2 0 ~ k -< 1POS(S-head(Stack \ [k \ ] ) )  = t 0 ~ k ~ 2POS(S-head(Stack \ [k \ ] ) )  =t l /k  POS(S-head(Stack \ [k+ I\])) =t2  0 ~ k -< 1POS(S-head(Stack \ [kx \ ]  )) = tx /k POS (Sur face-word \ [k2 \ ] )  = t2 0 --< kx ~ 1- I~  k2-<0Category(Stack\[kx\] )  = c /k POS(C-head(Stack\[kx\]) )  = t~ /~POS (Surface-word \[k2\] ) = t2.0-< kz~ 1- i~  k2-<0Table 1.
A Subset of the Feature Schemas in the Original Version of the Parser.
The variables t, tt,and t2 range over the set of part-of-speech categories, while the variables c, et, and c2 range over theset of non-terminal categories.
Surface words are indexed relative to the parsing position, such thatSurface-word\[O\] is the next word to be shifted.features, actually using only those featureswhich are active.
The set of these actuallyactive features is reasonable for our set ofschemas.2 Enriching the Feature Set withCo-occurrence Statisticsstatist ic(wl,  w2) ~ Xls ta t i s t i c  (wl, w2) ~- X2rather than mutually-exclusive predicates ofthe form:X0 < stat ist ic(wl,  w2) ~-XlX0 < stat ist ic(wl,  w2) ~ X22.1 Measures of AssociationTable 2 shows the definitions of the fivemeasures we have chosen to compare in thecurrent work, taken from (Manning and Shfitze,1999), (Kageura, 1999).These measures are based on empirical countsof word occurrences and co-occurrences.Because these events are very prone tozero-counts, both for unseen bigrams and forunseen words, we applied Simple Good-Turingsmoothing (Gale and Sampson, 1995) to bothbigram and word counts.2.2 Making Measures of Association Available tothe ParserTo make the measures of association availableto the parser, we started by discretizing eachmeasure, that, is substituting for each continuousmeasurement a set of binary predicates coarselydescribing its approximate value.
We used avery simple form of discretization, countingoccurrences of each value, and then dividing thevalues into bins of approximately equal counts.Informal exploration showed consistently betterperformance when bin membership was madecumulative; that is, usingnon-mutually-exclusive pr dicates of the form:Using these cumulative predicates, parsingaccuracy consistently improved with increases inthe number of bins, though the rate ofimprovement slowed at the same time.
Thecost of increasing the number of bins cameprimarily in the algorithm's training time.
Wechose thirty-two to be a good number of bins.The predicates resulting ~om discretizationare predicates over values of a statistic.
Toapply these predicates in parsing, we createdfeatures relating to particular slots withinparse-state descriptions.
Specifically, we madethree new feature schemas available to theWinnow learner, as shown in Table 3.
Each ofthese feature schemas is an extension to oneavailable to the original parser.
In each case,the original schema was of the form:POS(wl) = t~ A POS(w2) = t2And the extended schema was of the form:POS(wl) = tl A POS(w2) = t2 Astat ist ic(wl,  w2) ~ XIn this way, the learner is able to conditionseparately depending on the parts-of-speech ofthe two words in question.
This is based on theintuitions that different eases for part-of-speechcombinations would behave veery differently,and that the training data was sufficient that25Measure  DefinitionMx lo~- c(w~'w2)c(w. .
)c( .
,  w2) )T-score  4C(Wl, w2)f C (Wd~-2~ w2) ~ Cl, W,,W2) 1}x' c(.,.)(c(w.
- c(w. ))2c( , .
)c( , ,)c( .
, )c( .
)Likeli-hoodRatioL I ,  c(*.-) ) ct.,-) ) jNote :  LogL(p; n; k) = k log(p) + (n - k) log(1 - p)Yule's Y .~- I4 +1Note: C(O. o)c(w,,C( WI, W2 )C( WI, W2)Table 2.
Definitions of the Five Measures of Association.
c(x~,wz) represents the count of theevent that x and y occur adjacent and in this order in the training corpus.
- 'w  represents ummationover all words other than w, and ?
represents ummation over all words.performance would not be hurt by the resultingsub-division; however we have no specificempirical support for this.2.3 Experimental ResultsWe trained a series of SNoW networks usingfeatures sets extended with each of thef ivemeasures, and tested five versions of our parser,One using each of the resulting networks.
Thiswas done on a held-out test set comprisingapproximately ten percent of our treebank.
Theresulting measurements for labeled constituentprecision and recall are shown in Table 4,arranged according to the geometric mean of thetwo measurements.It is clear from the table that co-occurrenceinformation can be made useful, and that themeasure used to represent this information has alarge influence on its usefulness.
There is alsoa large disparity between the in~rovement inprecision, 1.7%, and the improvement in recall,4.1%.
We con jec ture  that this is because theparser odg/nally tended to err in the direction ofsplitting words into separate chunks, thecommoner case, while with the co-occurrenceinfommtion, it is able to pick out some caseswhere a strong association suggests that wordsbe joined in the same chunk.3 Related WorkStatistical measures of association appfied tobigram co-occurrence counts have been usedmost extensively in terminology and collocationextraction.
(Manning and Shfitze, 1999)contains a good introduction to this topic.
(Kageura, 1999) is an especially good empiricalcomparison of the performance of severalmeasures of association on a set of tasks in bothterminology extraction and in morphemesplitting of Chinese character sequences.
Thislatter tasks which can be seen as a very restrictedform of parsing, has been treated in a body ofinteresting work, including (Sun, Shen and Tsou,1998), (Lee, 1999) .
This work has generallyused vee/y simple heuristic ontrol policies, suchas repeatedly splitting at the point of lowestmutual information.
The use of similar26Pred icate  SchemaP0S (Sur face -word \ [k \ ] )  = tz A POS (Sur face -word \ [k  + 1\] )Stat ist ic(Surface-word\[k\ ]  , Sur face -word  \[k + I\] ) ~< X=t2  ARange ofParameters-2_< k~ 1POS(S-head(Staek \ [k \ ] ) )  = tx /k POS(S -head(Stack \ [k  + i\])) = t2 /~ 0 ~- k ~ 1S ta t i s t i c (S -head(Stack \ [k \ ] ) ,S -head(Stack \ [k  + i\])) ~- XPOS (S -head(Stack  \[kz\] ) ) = tz /k POS (Sur face-word\ [k2\ ] )Statistic (S -head (Stack \[kl\] ) , Sur face-word  \[k2\] ) ~- XTable 3.
Augmented Feature Schemas.approaches for general parsing received someearly exploration (Brill, Magerman, Marcus andSantofini, 1990), (Magerman and Marcus, 1990),but this approach seems to have lost popularity.This may be because using co-occurrencestatistics as a sole source of guidance maybecome insufficient as the object of parsingmoves from the veery local structure of wordsplitting to the longer-distance dependencies ofgeneral parsing.
The current work attempts toremedy this by using a general eafing deviceto balance co-occurrence statistics with otherinformation to be integrated into a larger controlpolicy.Conclusions and Future WorkOur experiments show that simple statisticalinformation gathered ~om the unprocessedsurface structure of large-scale text has value inguiding parsing decisions.
However, we feelthat there is still a great deal of further advantageto be gained from this approach.
Our next stepwill be to include co-oecu~ence informationfrom a much larger corpus, containing on theorder of 108 characters.We would also like to experiment with otherdefinitions of co-occurrence.
(Yuret, 1998)describes some very interesting work, in adifferent framework from ours, in which a parserusing only co-occurrence mutual informationwas able to achieve a high precision but lowrecall when co-occurrence was defined asadjacent co-occurrence, and low precision buthigh recall when co-occurrence was defined asoccurrence within the same sentence.
Wewould like to experiment with ways of balancingthese two measures.We also suspect hat significant gal.~ arepossible through a more sophisticated inclusionof the statistics in the decision making process.The current diseretization scheme is very simple,but there is ample empirical evidence that= t2 /k 0 ~ kx -< 1-i ~ k2 ~ 0discrefization which takes into account argetcategories can significantly improveclassification accuracy (Dougherty, Kohavi, andSahami, 1995).The several articles we have cited which useexclusively co-occurrence information to predictconstituent boundaries are very interesting forthe simplicity of their control structures, but inone important way they are more complex thanthe current work: they make decisions byexplicitly comparing the measures of associationbetween different pairs of words.
We predictthat augmenting the feature set to allow ourparser to be sensitive to this kind of informationwould be a very valuable xtension.A related issue is the choice of learningmethodology.
The Winnow learner has served uswell with its ability to handle very large featuresets, but it is weak in its ability to takeadvantage of the interaction between features.We would like to experiment with learningmethods which do not suffer from this weakness,and with methods for automatic featureextraction which could supplement Winnow.We experimented with a nondeterministiccontrol policy for the parser, using cost-frontsearch to fred the most probable series ofparsing decisions, but we found this not to bevery useful.
Over a series of comparativeexperiments, the non.deterministic ontrolpolicy consistently raised precision by a smallmargin, lowered recall by a small margin,increased run times by an order of magnitude ormore, and for about 10% of the test.setsentences exhausted system resources beforefinding any parse at all.
We posit that theseproblems may in part be due to the fact thatwhile the Winnow learner is otherwise quitewell adapted for our purposes, its output is notintended to be interpreted probabilistically.
Inthe future we intend to run parallel experimentswith more probabilisticaUy oriented learners; we27Measure of Association Precision RecallYule's Y 0.882 0.875Geometric Mean0.879Mutual Information 0.885 0.857 0.871Likelihood Ratio 0.879 0.845 0.862X z 0.870 0.848 0.859T-score 0.870 0.836 0.853None (Ori~na!
Feature Set) 0.868 0.834 0.851Table 4.
Accuracy Measurements of Parsing with Different Measures of Associationare espeeiaUy interested in experimenting with aMaximum Entropy model.In the larger context, we plan to experimentwith more sophisticated, model-basedunsupervised learning methods, includingclustering and beyond, and ways of providingtheir gathered knowledge to the parser, to makethe fullest possible use of the vast wealth ofun-annotated text available.AcknowledgementsThe research was supported by NationalNatural Science Foundation of China (NSFC)(Grant No.
69903007) and National 973Foundation (Grant No.
G 1998030507-2).ReferencesSteven Abney (1994) Parsing by Chunks.http://www.sfs.phil.uni-tuebingen.de/~abney/Erie Brill, David Magerrnan, Mitch Marcus and B.Santorini (1990) Deducing Linguistic Structurefrom the Statistics of Large Corpora.Proceedings of the DARPA Speech and NaturalLanguage Workshop, pp.
275-281.Kenneth W. Church and P. Hanks (1990) WordAssociaffon Norms, Mutual Information, andLexicography.
Computational Linguistics,Computational Linguistics, 16/1, pp.
22-29.Ted Dunning (1993) Accurate Methods for theStatistics of Surprise and Coincidence.Computational Linguistics, ComputationalLinguistics, 19/1, pp.
61-74.Kyo Kageura (1999) Bigram Statistics R~isited: AComparative Examination of Some StatisticalMeasures in Morphological Analysis of JapaneseKanfi Sequences.
Journal of QuantitativeLinguistics, 6/22, pp.
149-166.James Dougherty, Ron Kohavi and Mehran Sahami(1995) Supervised and Uusupen, isedDiscretization of Continuous Features.
In"Machine Learning: Proceedings of the TwelfthInternational Conference", Morgan KaufmannPublishers.William A. Gale and Geoffrey Sampson (1995)GoOd-Turing Frequency Estimation without Tears.Journal of Quantitative Linguistics, 2, pp.
217-237.Christopher D. Manning and Hinrich Shfitze (1999)Foundaffons of Statistical Natural LanguageProcessing.
The MIT Press, Cambridge,Massachusetts.David M. Magerman (1995) Natural LanguageParsing as Statistical Pattern Recognition.
Ph.D.Dissertation, Stanford University.David Magerman and Mitch Marcus (1990)Parsing a Natural Language Using MutualInformation Statistics.
In "Proceedings, EighthNational Conference on Artificial Intelligence(AAAI 9O)".Adwait Ratnaparkhi (1997) A LinearObserved- Time Statistical Parser Based onMaximum Entropy Models.
In "Proceedings of theSecond Conference on Empirical Methods inNatural Language Processing".Dan Roth (1998) Learning to Resolve NaturalLanguage Ambiguities, a Unified Approach.
In"AAAI'9$ ".K-Y.
Su, M-W. Wu, and J-S. Chang (1994) ACorpus-Based Approach to Automatic CompoundExtraction.
In "Proceedings of the 32rid AnnualMeeting of the ACL", pp.
27-30.Maosong Sun, Dayang Shen, and Benjamin tC Tsou(1998) Chinese Word Segmentation withoutUsing Lexicon and Hand-Crafted Training Data.In "Proceedings of the 36th Annual Meeting of theACL", pp.
1265-1271.Aboy Wong, Dekai Wu (1999) Are PhraseStructured Grammars Useful in StatisticalParsing?.
In "Proceedings of the Fifth NaturalLanguage Processing Pacific Rim Symposium", pp.120-125.Deniz Yuret (1998) Discovery of Lexical Re~tionsUsing Lexical Attraction.
Ph.D. Thesis,Massachusetts In titute of Technology.Qiang Zhou (1996) Phrase Bracketing andAnnotating on Chinese Language Corpus.
(inChinese), Ph.D. Thesis, Beijing University.28
