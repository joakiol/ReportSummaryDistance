Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2082?2093,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsA Rule-Based System for Unrestricted Bridging Resolution:Recognizing Bridging Anaphora and Finding Links to AntecedentsYufang Hou1, Katja Markert2, Michael Strube11Heidelberg Institute for Theoretical Studies gGmbH, Heidelberg, Germany(yufang.hou|michael.strube)@h-its.org2School of Computing, University of Leeds, UKscskm@leeds.ac.ukAbstractBridging resolution plays an importantrole in establishing (local) entity coher-ence.
This paper proposes a rule-basedapproach for the challenging task of unre-stricted bridging resolution, where bridg-ing anaphors are not limited to defi-nite NPs and semantic relations betweenanaphors and their antecedents are not re-stricted to meronymic relations.
The sys-tem consists of eight rules which targetdifferent relations based on linguistic in-sights.
Our rule-based system significantlyoutperforms a reimplementation of a pre-vious rule-based system (Vieira and Poe-sio, 2000).
Furthermore, it performs betterthan a learning-based approach which hasaccess to the same knowledge resourcesas the rule-based system.
Additionally,incorporating the rules and more featuresinto the learning-based system yields a mi-nor improvement over the rule-based sys-tem.1 IntroductionBridging resolution recovers the various non-identity relations between anaphora and an-tecedents.
It plays an important role in establish-ing entity coherence in a text.
In Example 1, thelinks between the bridging anaphors (The five as-tronauts and touchdown) and the antecedent (Thespace shuttle Atlantis) establish (local) entity co-herence.1(1) The space shuttle Atlantis landed at a desertair strip at Edwards Air Force Base, Calif.,ending a five-day mission that dispatchedthe Jupiter-bound Galileo space probe.
The1Examples are from OntoNotes (Weischedel et al., 2011).Bridging anaphora are typed in boldface; antecedents in ital-ics.five astronauts returned to Earth about threehours early because high winds had been pre-dicted at the landing site.
Fog shrouded thebase before touchdown.Bridging or associative anaphora has beenwidely discussed in the linguistic literature (Clark,1975; Prince, 1981; Gundel et al., 1993;L?obner, 1998).
Poesio and Vieira (1998) andBunescu (2003) include cases where antecedentand anaphor are coreferent but do not share thesame head noun (different-head coreference).
Wefollow our previous work (Hou et al., 2013b) andrestrict bridging to non-coreferential cases.
Wealso exclude comparative anaphora (Modjeska etal., 2003).Bridging resolution includes two subtasks: (1)recognizing bridging anaphors and (2) finding thecorrect antecedent among candidates.
In recentempirical work, these two subtasks have beentackled separately: (Markert et al., 2012; Cahilland Riester, 2012; Rahman and Ng, 2012; Hou etal., 2013a) handle bridging recognition as part ofinformation status (IS) classification, while (Poe-sio et al., 1997; Poesio et al., 2004; Markert etal., 2003; Lassalle and Denis, 2011; Hou et al.,2013b) concentrate on antecedent selection only,assuming that bridging recognition has alreadybeen performed.
One exception is Vieira and Poe-sio (2000).
They propose a rule-based system forprocessing definite NPs.
However, they includedifferent-head coreference into bridging.
They re-port results for the whole anaphora resolution butdo not report results for bridging resolution only.Another exception is R?osiger and Teufel (2014).They apply a coreference resolution system withseveral additional semantic features to find bridg-ing links in scientific text where bridging anaphorsare limited to definite NPs.
They report prelim-inary results using the CoNLL scorer.
However,we think the coreference resolution system and theevaluation metric for coreference resolution are2082not suitable for bridging resolution since bridgingis not a set problem.Another vein of research for bridging resolu-tion focuses on formal semantics.
Asher and Las-carides (1998) and Cimiano (2006) model bridg-ing by integrating discourse structure and seman-tics from a formal semantics viewpoint.
However,the implementation of such a theoretical frame-work is beyond the current capabilities of NLPsince it depends heavily on commonsense entail-ment.In this paper, we propose a rule-based systemfor unrestricted bridging resolution.
The systemconsists of eight rules which we carefully designbased on linguistic intuitions, i.e., how the natureof bridging is reflected by various lexical, syntac-tic and semantic features.
We evaluate our rule-based system on a corpus where bridging is reli-ably annotated.
We find that our rule-based sys-tem significantly outperforms a reimplementationof a previous rule-based system (Vieira and Poe-sio, 2000).
We further notice that our rule-basedsystem performs better than a learning-based ap-proach which has access to the same knowledgeresources as the rule-based system.
Surprisingly,incorporating the rules and more features into thelearning-based approach only yields a minor im-provement over the rule-based system.
We ob-serve that diverse bridging relations and relativelysmall-scale data for each type of relations makegeneralization difficult for the learning-based ap-proach.
This work is ?
to the best of ourknowledge ?
the first system recognizing bridginganaphora and finding links to antecedents for unre-stricted phenomenon where bridging anaphors arenot limited to definite NPs and semantic relationsbetween anaphors and their antecedents are not re-stricted to meronymic relations.2 DataAll the data used throughout the paper comefrom the ISNotes corpus2released by Hou et al.(2013b).
This corpus contains around 11,000 NPsannotated for information status including 663bridging NPs and their antecedents in 50 textstaken from the WSJ portion of the OntoNotes cor-pus (Weischedel et al., 2011).
ISNotes is reli-ably annotated for bridging: for bridging anaphorrecognition, ?
is over 60 for all three possible an-2http://www.h-its.org/english/research/nlp/download/isnotes.phpnotator pairings (?
is over 70 for two expert anno-tators); for selecting bridging antecedents, agree-ment is around 80% for all annotator pairings.It is notable that bridging anaphors in ISNotesare not limited to definite NPs as in previous work(Poesio et al., 1997; Poesio et al., 2004; Lassalleand Denis, 2011).
Table 1 shows the bridgingBridging Anaphors 663Non-determiner 44.9%Definite 38.5%Indefinite 15.4%Other-determiner 1.2%Table 1: Bridging anaphora distribution w.r.t.
de-terminers in ISNotes.anaphora distribution with regard to determiners inISNotes: only around 38% of bridging anaphorsare definite NPs (NPs modified by the); 15.4%of bridging anaphors are modified by determinerssuch as a, an or one which normally indicate in-definite NPs.
Most bridging anaphors (43%) arenot modified by any determiners, such as touch-down in Example 1.
A small fraction of bridginganaphors (1.2%) are modified by other determin-ers, such as demonstratives.The semantic relations between anaphor andantecedent in the corpus are extremely diverse:only 14% of anaphors have a part-of/attribute-of relation with the antecedent (see Example 2)and only 7% of anaphors stand in a set relation-ship to the antecedent (see Example 3).
79%of anaphors have ?other?
relations with their an-tecedents (without further distinction), includingencyclopedic relations such as The space shut-tle Atlantis-The five astronauts (see Example 1)as well as context-specific relations such as Thespace shuttle Atlantis-touchdown (Example 1).
(2) At age eight, Josephine Baker was sent byher mother to a white women?s house to dochores in exchange for meals and a place tosleep ?
a place in the basement with coal.
(3) This creates several problems.
One is thatthere are not enough police to satisfy smallbusinesses.In ISNotes, bridging anaphora with distant an-tecedents are common when the antecedent is theglobal focus of a document.
29% of the anaphorsin the corpus have antecedents that are three ormore sentences away.2083Bridging resolution is an extremely challeng-ing task in ISNotes.
In contrast with surface cluesfor coreference resolution, there are no clear sur-face clues for bridging resolution.
In Example 4,the bridging anaphor low-interest disaster loansassociates to the antecedent the Carolinas andCaribbean, whereas in Example 5 the NP loans isa generic use.
In Example 6, the bridging anaphorThe opening show associates to the antecedentMancuso FBI, whereas the NP the show is coref-erent with its antecedent Mancuso FBI.
(4) The $2.85 billion measure comes on top of$1.1 billion appropriated after Hugo stuckthe Carolinas and Caribbean last month, andthese totals don?t reflect the additional benefitof low-interest disaster loans.
(5) Many states already have Enterprise Zonesand legislation that combines tax incentives,loans, and grants to encourage investment indepressed areas.
(6) Over the first few weeks, Mancuso FBI hassprung straight from the headlines.
Theopening show featured a secretary of defensedesignate accused of womanizing (a la JohnTower).. .
.Most of all though, the show is redeemedby the character of Mancuso.Our previous work on bridging resolution onthis corpus only focuses on its subtasks.
InHou et al.
(2013a) we model bridging anaphorarecognition as a subtask of learning fine-grainedinformation status.
We report an F-measureof 0.42 for bridging anaphora recognition.
InHou et al.
(2013b) we propose a joint inferenceframework for antecedent selection by exploringMarkov logic networks.
We report an accuracyof 0.41 for antecedent selection given gold bridg-ing anaphora.
In this paper, we aim to solve thesetwo substasks together, i.e., recognizing bridginganaphora and finding links to antecedents.3 MethodIn this section, we describe our rule-based systemfor unrestricted bridging resolution.
We chooseten documents randomly from the corpus as thedevelopment set.
Then we carefully design rulesfor finding ?bridging links?
among all NPs in adocument based on the generalizations of bridg-ing in the linguistic literature as well as our in-spections of bridging annotations in the develop-ment set.
The system consists of two components:bridging link prediction and post processing.3.1 Bridging Link PredictionThe bridging link prediction component consistsof eight rules.
L?obner (1985; 1998) interpretsbridging anaphora as a particular kind of func-tional concept, which in a given situation assigna necessarily unique correlate to a (implicit) pos-sessor argument.
He distinguishes between rela-tional nouns (e.g.
parts terms, kinship terms, roleterms) and sortal nouns and points out that rela-tional nouns are more frequently used as bridg-ing anaphora than sortal nouns.
Rule1 to Rule4 inour system aim to resolve such relational nouns.We design Rule5 and Rule6 to capture set bridg-ing.
Finally, Rule7 and Rule8 are motivated byprevious work on implicit semantic role labeling(Laparra and Rigau, 2013) which focuses on fewpredicates.For all NPs in a document, each rule r is appliedseparately to predict a set of potential bridginglinks.
Every rule has its own constraints on bridg-ing anaphora and antecedents respectively.
Bridg-ing anaphors are diverse with regard to syntacticform and function: they can be modified by def-inite or indefinite determiners (Table 1), further-more they can take the subject (e.g.
Example 3and Example 6) or other positions (e.g.
Example2 and Example 4) in sentences.
The only fre-quent syntactic property shared is that bridginganaphors most often have a simple internal struc-ture concerning modification.
Therefore we firstcreate an initial list of potential bridging anaphoraA which excludes NPs which have a complex syn-tactic structure.
An NP is added to A if it doesnot contain any other NPs and do not have modifi-cations strongly indicating comparative NPs (suchas other symptoms)3.
Since head match is a strongindicator of coreference anaphora for definite NPs(Vieira and Poesio, 2000; Soon et al., 2001), wefurther exclude definite NPs from A if they havethe same head as a previous NP.
Then a set ofpotential bridging anaphors Aris chosen from Abased on r?s constraints on bridging anaphora.
Fi-nally, for each potential bridging anaphor ana ?3A small list of 10 markers such as such, another .
.
.
andthe presence of adjectives or adverbs in the comparative formare used to predict comparative NPs.2084Ar, a single best antecedent ante from a list ofcandidate NPs (Cana) is chosen if the rule?s con-straint on antecedents is applied successfully.Every rule has its own scope to form theantecedent candidate set Cana.
Instead of usinga static sentence window to construct the list ofantecedent candidates like most previous work forresolving bridging anaphora (Poesio et al., 1997;Markert et al., 2003; Poesio et al., 2004; Lassalleand Denis, 2011), we use the development setto estimate the proper scope for each rule.
Thescope is influenced by the following factors: (1)the nature of the target bridging link (e.g., setbridging is a local coherence phenomenon wherethe antecedent often occurs in the same or upto two sentences prior to the anaphor); and (2)the strength of the rule?s constraint to select thecorrect antecedent (e.g., in Rule8, the abilityto select the correct antecedent decreases withincreasing the scope to contain more antecedentcandidates).
In the following, we describe the mo-tivation for each rule and their constraints in detail.Rule1: building part NPs.
To capture typicalpart-of bridging (see Example 2), we extract alist of 45 nouns which specify building parts (e.g.room or roof ) from the General Inquirer lexicon(Stone et al., 1966).
A common noun phrase fromA is added to Ar1if: (1) its head appears in thebuilding part list; and (2) it does not contain anynominal pre-modifications.
Then for each poten-tial bridging anaphor ana ?
Ar1, the NP withthe strongest semantic connectivity to the potentialanaphor ana among all NPs preceding ana fromthe same sentence as well as from the previous twosentences is predicted to be the antecedent.The semantic connectivity of an NP to a po-tential anaphor is measured via the hit counts ofthe preposition pattern query (anaphor preposi-tion NP) in big corpora4.
An initial effort to ex-tract partOf relations using WordNet yields lowrecall on the development set.
Therefore we usesemantic connectivity expressed by prepositionalpatterns (e.g.
the basement of the house) to cap-ture underlying semantic relations.
Such syntacticpatterns are also explored in Poesio et al.
(2004) toresolve meronymy bridging.4We use Gigaword (Parker et al., 2011) with automaticPOS tag and NP chunk information.Rule2: relative person NPs.
This rule is usedto capture the bridging relation between a relative(e.g.
The husband) and its antecedent (e.g.
She).A list of 110 such relative nouns is extracted fromWordNet.
However, some relative nouns are fre-quently used generically instead of being bridging,such as children.
To exclude such cases, we com-pute the argument taking ratio ?
for an NP usingNomBank (Meyers et al., 2004).
For each NP, ?
iscalculated via its head frequency in the NomBankannotation divided by the head?s total frequencyin the WSJ corpus in which the NomBank anno-tation is conducted.
The value of ?
reflects howlikely an NP is to take arguments.
For instance,the value of ?
is 0.90 for husband but 0.31 forchildren.
To predict bridging anaphora more ac-curately, a conservative constraint is used.
An NPfrom A is added to Ar2if: (1) its head appears inthe relative person list; (2) its argument taking ra-tio ?
is bigger than 0.5; and (3) it does not containany nominal or adjective pre-modifications.
Thenfor each potential bridging anaphor ana ?
Ar2,the closest non-relative person NP among all NPspreceding ana from the same sentence as well asfrom the previous two sentences is chosen as itsantecedent.Rule3: GPE job title NPs.
In news articles, it iscommon that a globally salient geo-political entity(hence GPE, e.g.
Japan or U.S.) is introduced inthe beginning, then later a related job title NP (e.g.officials or the prime minister) is used directlywithout referring to this GPE explicitly.
To resolvesuch bridging cases accurately, we compile a listof twelve job titles which are related to GPEs (e.g.mayor or official).
An NP from A is added to Ar3if its head appears in this list and does not have acountry pre-modification (e.g.
the Egyptian pres-ident).
Then for each potential bridging anaphorana ?
Ar3, the most salient GPE NP among allNPs preceding ana is predicted as its antecedent.We use the NP?s frequency in the whole documentto measure its salience throughout the paper.
Incase of a tie, the closest one is chosen to be thepredicted antecedent.Rule4: role NPs.
Compared to Rule3, Rule4is designed to resolve more general role NPs totheir implicit possessor arguments.
We extract alist containing around 100 nouns which specifyprofessional roles from WordNet (e.g.
chairman,president or professor).
An NP from A is added to2085Ar4if its head appears in this list.
Then for eachpotential bridging anaphor ana ?
Ar4, the mostsalient proper name NP which stands for an orga-nization among all NPs preceding ana from thesame sentence as well as from the previous foursentences is chosen as its antecedent (if such anNP exists).
Recency is again used to break ties.Rule5: percentage NPs.
In set bridging asshown in Example 7, the anaphor (Seventeen per-cent) is indicated by a percentage expression fromA, which is often in the subject position.
The an-tecedent (the firms) is predicted to be the closestNP which modifies another percentage NP via thepreposition ?of?
among all NPs occurring in thesame or up to two sentences prior to the potentialanaphor.
(7) 22% of the firms said employees or ownershad been robbed on their way to or fromwork.
Seventeen percent reported their cus-tomers being robbed.Rule6: other set member NPs.
In set bridg-ing, apart from percentage expressions, numbersor indefinite pronouns are also good indicators forbridging anaphora.
For such cases, the anaphoris predicted if it is: (1) a number expression (e.g.One in Example 3) or an indefinite pronoun(e.g.some, as shown in Example 8) from A; and (2) asubject NP.
The antecedent is predicted to be theclosest NP among all plural, subject NPs preced-ing the potential anaphor from the same sentenceas well as from the previous two sentences (e.g.Reds and yellows in Example 8).
If such an NPdoes not exist, the closest NP among all plural, ob-ject NPs preceding the potential anaphor from thesame sentence as well as from the previous twosentences is chosen to be the predicted antecedent(e.g.
several problems in Example 3).
(8) Reds and yellows went about their businesswith a kind of measured grimness.
Somefrantically dumped belongings into pillow-cases.Rule7: argument-taking NPs I. Laparra andRigau (2013) found that different instances of thesame predicate in a document likely maintain thesame argument fillers.
Here we follow this as-sumption but apply it to nouns and their nomi-nal modifiers only: different instances of the samenoun predicate likely maintain the same argumentfillers indicated by nominal modifiers.
First, acommon noun phrase from A is added to Ar7if:(1) its argument taking ratio ?
is bigger than 0.5;(2) it does not contain any nominal or adjectivepre-modifications; and (3) it is not modified by in-definite determiners5which usually introduce newdiscourse referents (Hawkins, 1978).
Then foreach potential bridging anaphor ana ?
Ar7, wechoose the antecedent by performing the follow-ing steps:1.
We take ana?s head lemma form anahand collect all its syntactic modifications inthe document.
We consider nominal pre-modification, possessive modification as wellas prepositional post-modification.
All real-izations of these modifications which precedeana form the antecedent candidates setCana.2.
We choose the most recent NP from Canaas the predicted antecedent for the potentialbridging anaphor ana.In Example 9, we first predict the two occur-rences of residents as bridging anaphors.
Sincein the text, other occurrences of the lemma ?res-ident?
are modified by ?Marina?
(supported byMarina residents) and ?buildings?
(supported bysome residents of badly damaged buildings), wecollect all NPs whose syntactic head is ?Ma-rina?
or ?buildings?
in Cana(i.e.
Marina, badlydamaged buildings and buildings with substan-tial damage).
Then among all NPs in Cana, themost recent NP is chosen to be the antecedent (i.e.buildings with substantial damage).
(9) She finds the response of Marina residents tothe devastation of their homes ?incredible?..
.
.Out on the streets, some residents of badlydamaged buildings were allowed a 15 minutescavenger hunt through their possessions.. .
.After being inspected, buildings with sub-stantial damage were color - coded.Green allowed residents to re-enter; redallowed residents one last entry to gathereverything they could within 15 minutes.Rule8: argument-taking NPs II.
Prince (1992)found that discourse-old entities are more likely5We compile a list of 17 such determiners, such as a, anor one.2086to be represented by NPs in subject position.Although she could not draw a similar conclu-sion when collapsing Inferrable (= bridging) withDiscourse-old Nonpronominal, we find that in thedevelopment set, an argument-taking NP in thesubject position is a good indicator for bridginganaphora (e.g.
participants in Example 10).
Acommon noun phrase from A is collected in Ar8if: (1) its argument taking ratio ?
is bigger than0.5; (2) it does not contain any nominal or adjec-tive pre-modifications; and (3) it is in the subjectposition.
Semantic connectivity again is used asthe criteria to choose the antecedent: for each po-tential bridging anaphor ana ?
Ar8, the NP withthe strongest semantic connectivity to ana amongall NPs preceding ana from the same sentence aswell as from the previous two sentences is pre-dicted to be the antecedent.
(10) Initial steps were taken at Poland?s first in-ternational environmental conference, whichI attended last month.
.
.
.
While Polish datahave been freely available since 1980, it wasno accident that participants urged the freeflow of information.3.2 Post-processingIn the bridging link prediction component, eachrule is applied separately.
To resolve the conflictsbetween different rules (e.g., two rules predict dif-ferent antecedents for the same potential anaphor),a post processing step is applied.
We first orderthe rules according to their precision for predictingbridging pairs (i.e., recognizing bridging anaphorsand finding links to antecedents) in the develop-ment set.
When a conflict happens, the rule withthe highest order has the priority to decide the an-tecedent.
Table 2 summarizes the rules describedin Section 3.1, the numbers in square brackets inthe first column indicate the order of the rules.
Ta-ble 3 shows the precisions of bridging anaphorarecognition and bridging pairs prediction for eachrule in the development set.
Firing rate is theproportion of bridging links predicted by rule ramong all predicted links.4 Experiments and Results4.1 Experimental SetupWe conduct all experiments on the ISNotes cor-pus.
We use the OntoNotes named entity and syn-tactic annotations to extract features.
Ten doc-uments containing 113 bridging anaphors fromthe ISNotes corpus are set as the development setto estimate parameters for the rule-based system.The remaining 40 documents are used as the testset.
In order to compare the results of differentsystems directly, we evaluate all systems on thetest set.4.2 Evaluation MetricIn ISNotes, bridging is annotated mostly betweenan NP (anaphor) and an entity (antecedent)6, sothat a bridging anaphor could have multiple linksto different instantiations of the same entity (entityinformation is based on the Ontonotes coreferenceannotation).
For bridging resolution, we use anevaluation metric based on bridging anaphors in-stead of all links between bridging anaphors andtheir antecedent instantiations.
A link predicted bythe system is counted as correct if it recognizes thebridging anaphor correctly and links the anaphorto any instantiation of the right antecedent entitypreceding the anaphor.In the evaluation metric, recall is calculatedvia the number of the correct links predicted bythe system (one unique link per each predictedanaphor) divided by the total number of the goldbridging anaphors, precision is calculated via thenumber of the correct links predicted by the sys-tem divided by the total links predicted by the sys-tem.4.3 A Learning-based ApproachTo compare our rule-based system (hence ruleSys-tem, described in Section 3) with other ap-proaches, we implement a learning-based systemfor unrestricted bridging resolution.
We adapt thepairwise model which is widely used in corefer-ence resolution (Soon et al., 2001).
Similar tothe rule-based system, we first create an initial listof possible bridging anaphora Amlwith one moreconstraint.
The purpose is to exclude as many ob-vious non-bridging anaphoric NPs from the listas possible.
An NP is added to Amlif: (1) itdoes not contain any other NPs; (2) it is not mod-ified by pre-modifications which strongly indicatecomparative NPs; and (3) it is not a pronoun or aproper name.
Then for each NP a ?
Aml, a listof antecedent candidates Cais created by includ-ing all NPs preceding a from the same sentence6There are a few cases where bridging is annotated be-tween an NP and a non-NP antecedent (e.g.
verbs or clauses).2087antecedentrule anaphor antecedentcandidates scoperule1 [2] building part NPs the NP with the strongest semantic connectivity to the twopotential anaphorrule2 [5] relative person NPs the closest person NP which is not a relative NP tworule3 [6] GPE job title NPs the most salient GPE NP allrule4 [7] role NPs the most salient organization NP fourrule5 [1] percentage NPs the closest NP which modifies another percentage NP twovia the preposition ?of?rule6 [3] other set member NPs the closest subject, plural NP; twootherwise the closest object, plural NPrule7 [4] argument-taking NPs I the closest NP whose head is an unfilled role of the potential allanaphor (such a role is predicted via syntactic modifications of NPswhich have the same head as the potential anaphor)rule8 [8] argument-taking NPs II the NP with the strongest semantic connectivity to the twopotential anaphorTable 2: Rules for unrestricted bridging resolution.
Antecedent candidates scope are verified in thedevelopment set: ?all?
represents all NPs preceding the potential anaphor from the whole document,?four?
NPs occurring in the same or up to four sentences prior to the potential anaphor, ?two?
NPsoccurring in the same or up to two sentences prior to the potential anaphor.anaphora recognition bridging pairs predictionrule anaphoraprecision precisionfiring raterule1 [2] building part NPs 75.0% 50.0% 6.1%rule2 [5] relative person NPs 69.2% 46.2% 6.1%rule3 [6] GPE job title NPs 52.6% 44.7% 19.4%rule4 [7] role NPs 61.7% 32.1% 28.6%rule5 [1] percentage NPs 100.0% 100.0% 2.6%rule6 [3] other set member NPs 66.7% 46.7% 7.8%rule7 [4] argument-taking NPs I 53.8% 46.4% 6.1%rule8 [8] argument-taking NPs II 64.5% 25.0% 25.5%Table 3: Precision of bridging anaphora recognition and bridging pairs prediction for each rule in thedevelopment set.
The numbers in square brackets in the first column indicate the order of the rules.as well as from the previous two sentences7.
Wecreate a pairwise instance (a, c) for every c ?
Ca.We also add extra pairwise instances from the pre-diction of ruleSystem to the learning-based sys-tem.
In the decoding stage, the best first strat-egy (Ng and Cardie, 2002) is used to predict thebridging links.
Specifically, for each a ?
Aml, wepredict the bridging link to be the most confidentpair (a, cante) among all instances with the posi-tive prediction.
We use SVMlightto conduct theexperiments8.
All experiments are conducted via10-fold cross-validation on the whole corpus9.7In ISNotes, 71% of NP antecedents occur in the sameor up to two sentences prior to the anaphor.
Initial experi-ments show that increasing the window size more than twosentences decreases the performance.8To deal with data imbalance, the SVMlightparameteris set according to the ratio between positive and negativeinstances in the training set.9To compare the learning-based approach to the rule-based system described in Section 3 directly, we report themlSystem ruleFeats We provide mlSys-tem ruleFeats with the same knowledge resourcesas the rule-based system.
All rules from therule-based system are incorporated into mlSys-tem ruleFeats as the features.mlSystem ruleFeats + atomFeats We augmentmlSystem ruleFeats with more features from ourprevious work (Markert et al., 2012; Hou et al.,2013a; Hou et al., 2013b) on bridging anaphorarecognition and antecedent selection.
Some ofthese features overlap with the atomic featuresused in the rule-based system.Table 4 shows all the features we use for rec-ognizing bridging anaphora.
???
indicates the re-sources are used in the rule-based system.
We ap-ply them to the first element a of a pairwise in-stance (a, c).
Markert et al.
(2012) and Hou etresults of learning-based approaches on the same test set asthe rule-based system.2088Markert et al.
local feature setf1 FullPrevMention (b) ?
f2 FullPreMentionTime (n) f3 PartialPreMention (b)f4 ContentWordPreMention (b) f5 Determiner (n) ?
f6 NPtype (n) ?f7 NPlength (int) f8 GrammaticalRole (n) ?
f9 NPNumber (n) ?f10 PreModByCompMarker (b) ?Hou et al.
local feature setfeatures to identify bridging anaphoraf1 IsCoherenceGap (b) f2 IsSentFirstMention (b) f3 IsDocFirstMention (b)f4 IsWordNetRelationalNoun (b) ?
f5 IsInquirerRoleNoun (b) f6 IsBuildingPart (b) ?f7 IsSetElement (b) ?
f8 PreModSpatialTemporal (b) f9 IsYearExpression (b)f10 PreModifiedByCountry (b) ?
f11 AppearInIfClause (b) f12 VerbPosTag (l)f13 IsFrequentGenericNP (b) f14 WorldKnowledgeNP (l) f15 Unigrams (l)f16 PreModByGeneralQuantifier (b) f17 BridgingHeadNP (l) f18 HasChildNP (b) ?features to identify function and worldKnowledge NPsf20 DependOnChangeVerb (b) f21 IsFrequentProperName (b)Table 4: Features for bridging anaphora recognition from Markert et al.
(2012) and Hou et al.
(2013a).?b?
indicates binary, ?n?
nominal, ?l?
lexical features, ???
resources used in the rule-based system.Group Feature Valuesemantic f1 preposition pattern ?
the normalized hit counts of the preposition pattern querya prep.
c (e.g.
participants of the conference) in big corporaf2 verb pattern the normalized hit counts of the verb pattern query c verbaorverbac in big corpora (for set bridging in Example 7, thepattern query is the firms reported)f3 WordNet partOf whether a partOf relation holds between a and c in WordNetf4 semantic class ?
16 classes, e.g.
location, organization, GPE, rolePerson,relativePerson, product, date, money, percentsalience f5 document span the normalized value of the span of text in which c is mentionedf6 utterance distance the sentence distance between a and cf7 local first mention whether c is the first mention within the previous five sentencesf8 global first mention whether c is the first mention in the whole documentsyntactic f9 isSameHead whether a and c share the same head& (exclude coreferent antecedent candidates)lexical f10 isWordOverlap whether a is prenominally modified by the head of c (forbridging where the anaphor is a compound noun, such asthe mine-mine security)f11 isCoArgument whether subject c and object a are dependent on the same verb(the subject can not be the bridging antecedent of the objectin the same clause)f12 WordNet distance the inverse value of the shortest path length between a and cin WordNetTable 5: Features for antecedent selection from Hou et al.
(2013b).
???
indicates resources used in therule-based system.al.
(2013a) classify eight fine-grained informationstatus (IS) categories for NPs: old, new and 6mediated categories (syntactic, worldKnowledge,bridging, comparative, aggregate and function).Features from Markert et al.
(2012) work well toidentify old, new and several mediated categoriesbut fail to recognize most bridging anaphora.
Houet al.
(2013a) remedy this by adding discoursestructure features (f1-f3), semantic features (f4-f10) and features to detect generic nouns (f11-2089Feature Valuefor anaphor candidate af1 preModByNominal whether a contains any nominal pre-modificationsf2 preModByAdj whether a contains any adjective modificationsf3 isGPEJobTitle whether a is a job title about GPE (e.g.
mayor or official)f4 isArgumentTakingNP whether the argument taking ratio of a is bigger than 0.5for antecedent candidate cf5 fullMentionTime the normalized value of the frequency of c in the whole documentfor pairwise instance (a, c)f6 word distance the token distance between a and cTable 6: Additional atomic features from the rule-based system.f14 and f16).Table 5 shows all features we use for selectingantecedents for bridging anaphora.
???
indicatesthe resources that are used in the rule-based sys-tem.
These features are from Hou et al.
(2013b)?slocal pairwise model.
They try to model: (1) thesemantic relations between bridging anaphors andtheir antecedents (f1 to f4); (2) the salience ofan antecedent from different perspectives (f5 tof8); and (3) the syntactic and lexical constraintsbetween anaphor and antecedent (f9 to f12).Apart from the features shown in Table4 and Table 5, we further enrich mlSys-tem ruleFeats+atomFeats with additional atomicfeatures used in the rule-based system (Table 6).mlSystem atomFeats Based on mlSys-tem ruleFeats+atomFeats, the rule featuresfrom the rule-based system are removed.4.4 BaselineWe also reimplement the rule-based system fromVieira and Poesio (2000) as a baseline.
The origi-nal algorithm focuses on processing definite NPs.It classifies four categories for the definite NPs:discourse new, direct anaphora (same-head coref-erent anaphora), lenient bridging and Unknown.This algorithm also finds antecedents for NPswhich belong to direct anaphora or lenient bridg-ing.Since Vieira and Poesio (2000) includedifferent-head coreference into their lenientbridging category, we further divide their le-nient bridging category into two subcategories:different-head coreference and bridging.
Figure1 shows the details of the division after failingto classify an NP as discourse new or directanaphora.
For more details about the wholesystem, see Vieira and Poesio (2000).
We thenapply this slightly revised algorithm to processall NPs in the initial list of potential bridginganaphoraA from ruleSystem (described in Section3.1).4.5 Results and DiscussionTable 7 shows the results on the same test set ofdifferent approaches for unrestricted bridging res-olution.
The results reveal the difficulty of thetask, when evaluating on a realistic scenario with-out constraints on types of bridging anaphora andbridging relations.Both our rule-based system and all learning-based approaches significantly outperform thebaseline at p < 0.01 (randomization test).
Thelow recall in baseline is predictable, since itonly considers meronymy bridging and compoundnoun anaphors whose head is prenominally mod-ified by the antecedent head.
(e.g.
the state?state gasoline taxes).
Under the same features,the learning-based approach (mlSystem ruleFeats)performs slightly worse than the rule-based sys-tem (ruleSystem) with regard to the F-score.R P Fbaseline 2.9 13.3 4.8ruleSystem 11.9 42.9 18.6mlSystem ruleFeats 12.1 35.0 18.0mlSystem ruleFeats+atomFeats 16.7 21.2 18.7mlSystem atomFeats 20.5 10.1 13.5Table 7: Experimental results for the baseline, therule-based system and the learning-based systems.Surprisingly, incorporating rich featuresinto the learning-based approach (mlSys-tem ruleFeats+atomFeats) does not yield muchimprovement over the rule-based system (with an2090Figure 1: Vieria & Poesio?s (2000) original algorithm for processing definite NPs.
We further dividetheir lenient bridging category into two subcategories: 2.1 Different-head coreference and 2.2 Bridging.F-score of 18.7 in mlSystem ruleFeats+atomFeatscompared to 18.6 in ruleSystem).
We suppose thatthe learning-based system generalizes poorly withonly atomic features in Table 4, Table 5 and Table6.
Results on mlSystem atomFeats support ourassumption: the F-score drops considerably afterremoving the rule features.
Although ISNotes isa reasonably sized corpus for bridging comparedto previous work, diverse bridging relations,especially lots of context specific relations suchas pachinko-devotees or palms-the thieves, leadto relatively small-scale training data for eachtype of relation.
Therefore it is difficult for thelearning-based approach to learn effective rules topredict bridging links.However, all learning-based systems tend tohave higher recall but lower precision comparedto the rule-based system.
This suggests that thelearning-based systems are ?greedy?
to predictbridging links.
A close look at these links inmlSystem atomFeats indicates that the learning-based system predicts more correct bridginganaphors but fails to find the correct antecedents.In fact, lots of those ?half?
correct links soundreasonable without the specific context, such asthe story-readers (gold bridging link: this novel-readers) or the executive director?s office-thedesks (gold bridging link: the fund?s building-thedesks).5 ConclusionsWe proposed a rule-based approach for un-restricted bridging resolution where bridginganaphora are not limited to definite NPs and therelations between anaphor and antecedent are notrestricted to meronymic relations.
We designedeight rules to resolve bridging based on linguis-tic intuition.
Our rule-based system performs bet-ter than a learning-based approach which has ac-cess to the same knowledge resources as the rule-based system.
Particularly, the learning-based sys-tem enriched with more features does not yieldmuch improvement over the rule-based system.We speculate that the learning-based system couldbenefit from more training data.
Furthermore, bet-ter methods to model the semantics of the specificcontext need to be explored in the future.This work is ?
to our knowledge ?
the firstbridging resolution system that handles the unre-stricted phenomenon in a realistic setting.AcknowledgementsWe thank Renata Vieira for excavating part of hersource code for us.
We also thank the reviewersfor their helpful comments.
Yufang Hou is fundedby a PhD scholarship from the Research TrainingGroup Coherence in Language Processing at Hei-delberg University.
This work has been partiallyfunded by the Klaus Tschira Foundation.2091ReferencesNicholas Asher and Alex Lascarides.
1998.
Bridging.Journal of Semantics, 15:83?113.Razvan Bunescu.
2003.
Associative anaphora resolu-tion: A Web-based approach.
In Proceedings of theEACL 2003 Workshop on The Computational Treat-ment of Anaphora, Budapest, Hungary, 14 April,2003, pages 47?52.Aoife Cahill and Arndt Riester.
2012.
Automati-cally acquiring fine-grained information status dis-tinctions in German.
In Proceedings of the SIGdial2012 Conference: The 13th Annual Meeting of theSpecial Interest Group on Discourse and Dialogue,Seoul, Korea, 5?6 July 2012, pages 232?236.Philipp Cimiano.
2006.
Ingredients of a first-order ac-count of bridging.
In Proceedings of the 5th Inter-national Workshop on Inference in ComputationalSemantics, Buxton, U.K., 20?21 April 2006, pages139?144.Herbert H. Clark.
1975.
Bridging.
In Proceedingsof the Conference on Theoretical Issues in Natu-ral Language Processing, Cambridge, Mass., June1975, pages 169?174.Jeanette K. Gundel, Nancy Hedberg, and RonZacharski.
1993.
Cognitive status and the formof referring expressions in discourse.
Language,69:274?307.John A. Hawkins.
1978.
Definiteness and indefinite-ness: A study in reference and grammaticality pre-diction.
Humanities Press, Atlantic Highlands, N.J.Yufang Hou, Katja Markert, and Michael Strube.2013a.
Cascading collective classification for bridg-ing anaphora recognition using a rich linguistic fea-ture set.
In Proceedings of the 2013 Conference onEmpirical Methods in Natural Language Process-ing, Seattle, Wash., 18?21 October 2013, pages 814?820.Yufang Hou, Katja Markert, and Michael Strube.2013b.
Global inference for bridging anaphora res-olution.
In Proceedings of the 2013 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Atlanta, Georgia, 9?14 June 2013, pages907?917.Egoitz Laparra and German Rigau.
2013.
ImpAr: Adeterministic algorithm for implicit semantic role la-belling.
In Proceedings of the 51st Annual Meet-ing of the Association for Computational Linguis-tics, Sofia, Bulgaria, 4?9 August 2013, pages 1180?1189.Emmanuel Lassalle and Pascal Denis.
2011.
Leverag-ing different meronym discovery methods for bridg-ing resolution in French.
In Proceedings of the 8thDiscourse Anaphora and Anaphor Resolution Col-loquium (DAARC 2011), Faro, Algarve, Portugal, 6?7 October 2011, pages 35?46.Sebastian L?obner.
1985.
Definites.
Journal of Seman-tics, 4:279?326.Sebastian L?obner.
1998.
Definite associativeanaphora.
Unpublished Manuscript, Heinrich-Heine-Universit?at D?usseldorf.Katja Markert, Malvina Nissim, and Natalia N. Mod-jeska.
2003.
Using the web for nominal anaphoraresolution.
In Proceedings of the EACL Workshopon the Computational Treatment of Anaphora.
Bu-dapest, Hungary, 14 April 2003, pages 39?46.Katja Markert, Yufang Hou, and Michael Strube.
2012.Collective classification for fine-grained informationstatus.
In Proceedings of the 50th Annual Meeting ofthe Association for Computational Linguistics, JejuIsland, Korea, 8?14 July 2012, pages 795?804.Adam Meyers, Ruth Reeves, Catherine Macleod,Rachel Szekely, Veronika Zielinska, Brian Young,and Ralph Grishaman.
2004.
Annotating noun ar-gument structure for NomBank.
In Proceedings ofthe 4th International Conference on Language Re-sources and Evaluation, Lisbon, Portugal, 26?28May 2004, pages 803?806.Natalia M. Modjeska, Katja Markert, and Malvina Nis-sim.
2003.
Using the web in machine learningfor other-anaphora resolution.
In Proceedings of the2003 Conference on Empirical Methods in NaturalLanguage Processing, Sapporo, Japan, 11?12 July2003, pages 176?183.Vincent Ng and Claire Cardie.
2002.
Improving ma-chine learning approaches to coreference resolution.In Proceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics, Philadel-phia, Penn., 7?12 July 2002, pages 104?111.Robert Parker, David Graff, Junbo Kong, Ke Chen, andKazuaki Maeda.
2011.
English Gigaword Fifth Edi-tion.
LDC2011T07.Massimo Poesio and Renata Vieira.
1998.
A corpus-based investigation of definite description use.
Com-putational Linguistics, 24(2):183?216.Massimo Poesio, Renata Vieira, and Simone Teufel.1997.
Resolving bridging references in unrestrictedtext.
In Proceedings of the ACL Workshop on Oper-ational Factors in Practical, Robust Anaphora Res-olution for Unrestricted Text, Madrid, Spain, July1997, pages 1?6.Massimo Poesio, Rahul Mehta, Axel Maroudas, andJanet Hitzeman.
2004.
Learning to resolve bridg-ing references.
In Proceedings of the 42nd AnnualMeeting of the Association for Computational Lin-guistics, Barcelona, Spain, 21?26 July 2004, pages143?150.Ellen F. Prince.
1981.
Towards a taxonomy of given-new information.
In P. Cole, editor, Radical Prag-matics, pages 223?255.
Academic Press, New York,N.Y.2092Ellen F. Prince.
1992.
The ZPG letter: Subjects, defi-niteness, and information-status.
In W.C. Mann andS.A.
Thompson, editors, Discourse Description.
Di-verse Linguistic Analyses of a Fund-Raising Text,pages 295?325.
John Benjamins, Amsterdam.Altaf Rahman and Vincent Ng.
2012.
Learning thefine-grained information status of discourse entities.In Proceedings of the 13th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics, Avignon, France, 23?27 April 2012,pages 798?807.Ina R?osiger and Simone Teufel.
2014.
Resolvingcoreference and associative noun phrases in scien-tific text.
In Proceedings of the Student ResearchWorkshop at the 14th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, Gothenburg, Sweden, 26?30 April 2014,pages 44?55.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,Daniel M. Ogilvie, and Cambridge Computer Asso-ciates.
1966.
General Inquirer: A Computer Ap-proach to Content Analysis.
MIT Press, Cambridge,Mass.Renata Vieira and Massimo Poesio.
2000.
Anempirically-based system for processing definite de-scriptions.
Computational Linguistics, 26(4):539?593.Ralph Weischedel, Martha Palmer, Mitchell Marcus,Eduard Hovy, Sameer Pradhan, Lance Ramshaw,Nianwen Xue, Ann Taylor, Jeff Kaufman, MichelleFranchini, Mohammed El-Bachouti, Robert Belvin,and Ann Houston.
2011.
OntoNotes release 4.0.LDC2011T03, Philadelphia, Penn.
: Linguistic DataConsortium.2093
