Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 1?8Manchester, August 2008TuLiPA: Towards a Multi-Formalism Parsing Environment forGrammar EngineeringLaura KallmeyerSFB 441Universita?t Tu?bingenD-72074, Tu?bingen, Germanylk@sfs.uni-tuebingen.deYannick ParmentierCNRS - LORIANancy Universite?F-54506, Vand?uvre, Franceparmenti@loria.frTimm LichteSFB 441Universita?t Tu?bingenD-72074, Tu?bingen, Germanytimm.lichte@uni-tuebingen.deJohannes DellertSFB 441 - SfSUniversita?t Tu?bingenD-72074, Tu?bingen, Germany{jdellert,kevang}@sfs.uni-tuebingen.deWolfgang MaierSFB 441Universita?t Tu?bingenD-72074, Tu?bingen, Germanywo.maier@uni-tuebingen.deKilian EvangSFB 441 - SfSUniversita?t Tu?bingenD-72074, Tu?bingen, GermanyAbstractIn this paper, we present an open-sourceparsing environment (Tu?bingen LinguisticParsing Architecture, TuLiPA) which usesRange Concatenation Grammar (RCG)as a pivot formalism, thus opening theway to the parsing of several mildlycontext-sensitive formalisms.
This en-vironment currently supports tree-basedgrammars (namely Tree-Adjoining Gram-mars (TAG) and Multi-Component Tree-Adjoining Grammars with Tree Tuples(TT-MCTAG)) and allows computation notonly of syntactic structures, but also of thecorresponding semantic representations.
Itis used for the development of a tree-basedgrammar for German.1 IntroductionGrammars and lexicons represent important lin-guistic resources for many NLP applications,among which one may cite dialog systems, auto-matic summarization or machine translation.
De-veloping such resources is known to be a complextask that needs useful tools such as parsers andgenerators (Erbach, 1992).Furthermore, there is a lack of a common frame-work allowing for multi-formalism grammar engi-neering.
Thus, many formalisms have been pro-posed to model natural language, each comingwith specific implementations.
Having a com-mon framework would facilitate the comparisonc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.between formalisms (e.g., in terms of parsing com-plexity in practice), and would allow for a bettersharing of resources (e.g., having a common lex-icon, from which different features would be ex-tracted depending on the target formalism).In this context, we present a parsing environ-ment relying on a general architecture that canbe used for parsing with mildly context-sensitive(MCS) formalisms1 (Joshi, 1987).
Its underly-ing idea is to use Range Concatenation Grammar(RCG) as a pivot formalism, for RCG has beenshown to strictly include MCS languages while be-ing parsable in polynomial time (Boullier, 2000).Currently, this architecture supports tree-basedgrammars (Tree-Adjoining Grammars and Multi-Component Tree-Adjoining Grammars with TreeTuples (Lichte, 2007)).
More precisely, tree-based grammars are first converted into equivalentRCGs, which are then used for parsing.
The resultof RCG parsing is finally interpreted to extract aderivation structure for the input grammar, as wellas to perform additional processings (e.g., seman-tic calculus, extraction of dependency views).The paper is structured as follows.
In section 2,we present the architecture of the TuLiPA parsingenvironment and show how the use of RCG as apivot formalism makes it easier to design a modu-lar system that can be extended to support severaldimensions (syntax, semantics) and/or formalisms.In section 3, we give some desiderata for gram-mar engineering and present TuLiPA?s current state1A formalism is said to be mildly context sensitive (MCS)iff (i) it generates limited cross-serial dependencies, (ii) it ispolynomially parsable, and (iii) the string languages gener-ated by the formalism have the constant growth property (e.g.,{a2n|n ?
0} does not have this property).
Examples of MCSformalisms include Tree-Adjoining Grammars, CombinatoryCategorial Grammars and Linear Indexed Grammars.1with respect to these.
In section 4, we comparethis system with existing approaches for parsingand more generally for grammar engineering.
Fi-nally, in section 5, we conclude by presenting fu-ture work.2 Range Concatenation Grammar as apivot formalismThe main idea underlying TuLiPA is to use RCGas a pivot formalism for RCG has appealing for-mal properties (e.g., a generative capacity lying be-yond Linear Context Free Rewriting Systems anda polynomial parsing complexity) and there ex-ist efficient algorithms, for RCG parsing (Boullier,2000) and for grammar transformation into RCG(Boullier, 1998; Boullier, 1999).Parsing with TuLiPA is thus a 3-step process:1.
The input tree-based grammar is convertedinto an RCG (using the algorithm ofKallmeyer and Parmentier (2008) when deal-ing with TT-MCTAG).2.
The resulting RCG is used for parsing the in-put string using an extension of the parsingalgorithm of Boullier (2000).3.
The RCG derivation structure is interpreted toextract the derivation and derived trees withrespect to the input grammar.The use of RCG as a pivot formalism, and thusof an RCG parser as a core component of the sys-tem, leads to a modular architecture.
In turns, thismakes TuLiPA more easily extensible, either interms of functionalities, or in terms of formalisms.2.1 Adding functionalities to the parsingenvironmentAs an illustration of TuLiPA?s extensibility, onemay consider two extensions applied to the systemrecently.First, a semantic calculus using the syn-tax/semantics interface for TAG proposed by Gar-dent and Kallmeyer (2003) has been added.
Thisinterface associates each tree with flat semanticformulas.
The arguments of these formulas areunification variables, which are co-indexed withfeatures labelling the nodes of the syntactic tree.During classical TAG derivation, trees are com-bined, triggering unifications of the feature struc-tures labelling nodes.
As a result of these unifica-tions, the arguments of the semantic formulas areunified (see Fig.
1).SNP?x VPNPjV NP?y NPmJohn loves Maryname(j,john) love(x,y) name(m,mary); love(j,m),name(j,john),name(m,mary)Figure 1: Semantic calculus in Feature-BasedTAG.In our system, the semantic support has been in-tegrated by (i) extending the internal tree objects toinclude semantic formulas (the RCG-conversion iskept unchanged), and (ii) extending the construc-tion of the derived tree (step 3) so that during theinterpretation of the RCG derivation in terms oftree combinations, the semantic formulas are car-ried and updated with respect to the feature unifi-cations performed.Secondly, let us consider lexical disambigua-tion.
Because of the high redundancy lying withinlexicalized formalisms such as lexicalized TAG,it is common to consider tree schemata having afrontier node marked for anchoring (i.e., lexical-ization).
At parsing time, the tree schemata areanchored according to the input string.
This an-choring selects a subgrammar supposed to coverthe input string.
Unfortunately, this subgrammarmay contain many trees that either do not lead toa parse or for which we know a priori that theycannot be combined within the same derivation(so we should not predict a derivation from oneof these trees to another during parsing).
As a re-sult, the parser could have poor performance be-cause of the many derivation paths that have tobe explored.
Bonfante et al (2004) proposed topolarize the structures of the grammar, and to ap-ply an automaton-based filtering of the compatiblestructures.
The idea is the following.
One computepolarities representing the needs/resources broughtby a given tree (or tree tuple for TT-MCTAG).A substitution or foot node with category NP re-flects a need for an NP (written NP-).
In the sameway, an NP root node reflects a resource of typeNP (written NP+).
Then you build an automatonwhose edges correspond to trees, and states to po-larities brought by trees along the path.
The au-tomaton is then traversed to extract all paths lead-ing to a final state with a neutral polarity for eachcategory and +1 for the axiom (see Fig.
2, the state27 is the only valid state and {proper., trans., det.,noun.}
the only compatible set of trees).0John1 1eats2 2a3 3cake40 1NP+2S+3S+ NP-4S+5S+ NP-6S+ NP+7S+proper.intrans.trans.det.det.noun.noun.Figure 2: Polarity-based lexical disambiguation.In our context, this polarity filtering has beenadded before step 1, leaving untouched the coreRCG conversion and parsing steps.
The idea isto compute the sets of compatible trees (or treetuples for TT-MCTAG) and to convert these setsseparately.
Indeed the RCG has to encode onlyvalid adjunctions/substitutions.
Thanks to thisautomaton-based ?clustering?
of the compatibletree (or tree tuples), we avoid predicting incompat-ible derivations.
Note that the time saved by usinga polarity-based filter is not negligible, especiallywhen parsing long sentences.22.2 Adding formalisms to the parsingenvironmentOf course, the two extensions introduced in theprevious section may have been added to othermodular architectures as well.
The main gainbrought by RCG is the possibility to parse notonly tree-based grammars, but other formalismsprovided they can be encoded into RCG.
In oursystem, only TAG and TT-MCTAG have beenconsidered so far.
Nonetheless, Boullier (1998)and S?gaard (2007) have defined transformationsinto RCG for other mildly context-sensitive for-malisms.3To sum up, the idea would be to keep the coreRCG parser, and to extend TuLiPA with a specificconversion module for each targeted formalism.On top of these conversion modules, one shouldalso provide interpretation modules allowing to de-code the RCG derivation forest in terms of the in-put formalism (see Fig.
3).2An evaluation of the gain brought by this technique whenusing Interaction Grammar is given by Bonfante et al (2004).3These include Multi-Component Tree-Adjoining Gram-mar, Linear Indexed Grammar, Head Grammar, CoupledContext Free Grammar, Right Linear Unification Grammarand Synchronous Unification Grammar.Figure 3: Towards a multi-formalism parsing envi-ronment.An important point remains to be discussed.
Itconcerns the role of lexicalization with respect tothe formalism used.
Indeed, the tree-based gram-mar formalisms currently supported (TAG and TT-MCTAG) both share the same lexicalization pro-cess (i.e., tree anchoring).
Thus the lexicon formatis common to these formalisms.
As we will seebelow, it corresponds to a 2-layer lexicon made ofinflected forms and lemma respectively, the latterselecting specific grammatical structures.
Whenparsing other formalisms, it is still unclear whetherone can use the same lexicon format, and if notwhat kind of general lexicon management moduleshould be added to the parser (in particular to dealwith morphology).3 Towards a complete grammarengineering environmentSo far, we have seen how to use a generic parsingarchitecture relying on RCG to parse different for-malisms.
In this section, we adopt a broader viewand enumerate some requirements for a linguisticresource development environment.
We also seeto what extent these requirements are fulfilled (orpartially fulfilled) within the TuLiPA system.3.1 Grammar engineering with TuLiPAAs advocated by Erbach (1992), grammar en-gineering needs ?tools for testing the grammarwith respect to consistency, coverage, overgener-ation and accuracy?.
These characteristics maybe taken into account by different interacting soft-ware.
Thus, consistency can be checked by a semi-automatic grammar production device, such as theXMG system of Duchier et al (2004).
Overgen-eration is mainly checked by a generator (or bya parser with adequate test suites), and coverageand accuracy by a parser.
In our case, the TuLiPAsystem provides an entry point for using a gram-mar production system (and a lexicon conversion3tool introduced below), while including a parser.Note that TuLiPA does not include any generator,nonetheless it uses the same lexicon format as theGenI surface realizer for TAG4.TuLiPA?s input grammar is designed usingXMG, which is a metagrammar compiler for tree-based formalisms.
In other terms, the linguist de-fines a factorized description of the grammar (theso-called metagrammar) in the XMG language.Briefly, an XMG metagrammar consists of (i) ele-mentary tree fragments represented as tree descrip-tion logic formulas, and (ii) conjunctive and dis-junctive combinations of these tree fragments todescribe actual TAG tree schemata.5 This meta-grammar is then compiled by the XMG system toproduce a tree grammar in an XML format.
Notethat the resulting grammar contains tree schemata(i.e., unlexicalized trees).
To lexicalize these, thelinguist defines a lexicon mapping words with cor-responding sets of trees.
Following XTAG (2001),this lexicon is a 2-layer lexicon made of morpho-logical and lemma specifications.
The motivationof this 2-layer format is (i) to express linguisticgeneralizations at the lexicon level, and (ii) to al-low the parser to only select a subgrammar accord-ing to a given sentence, thus reducing parsing com-plexity.
TuLiPA comes with a lexicon conversiontool (namely lexConverter) allowing to write a lex-icon in a user-friendly text format and to convert itinto XML.
An example of an entry of such a lexi-con is given in Fig.
4.The morphological specification consists of aword, the corresponding lemma and morphologi-cal features.
The main pieces of information con-tained in the lemma specification are the ?ENTRYfield, which refers to the lemma, the ?CAT fieldreferring to the syntactic category of the anchornode, the ?SEM field containing some semantic in-formation allowing for semantic instantiation, the?FAM field, which contains the name of the treefamily to be anchored, the ?FILTERS field whichconsists of a feature structure constraining by uni-fication the trees of a given family that can beanchored by the given lemma (used for instancefor non-passivable verbs), the ?EQUATIONS fieldallowing for the definition of equations targetingnamed nodes of the trees, and the ?COANCHORSfield, which allows for the specification of co-anchors (such as by in the verb to come by).4http://trac.loria.fr/?geni5See (Crabbe?, 2005) for a presentation on how to use theXMG formalism for describing a core TAG for French.Morphological specification:vergisst vergessen [pos=v,num=sg,per=3]Lemma specification:?ENTRY: vergessen?CAT: v?SEM: BinaryRel[pred=vergessen]?ACC: 1?FAM: Vnp2?FILTERS: []?EX:?EQUATIONS:NParg1 ?
cas = nomNParg2 ?
cas = acc?COANCHORS:Figure 4: Morphological and lemma specificationof vergisst.From these XML resources, TuLiPA parses astring, corresponding either to a sentence or a con-stituent (noun phrase, prepositional phrase, etc.
),and computes several output pieces of informa-tion, namely (for TAG and TT-MCTAG): deriva-tion/derived trees, semantic representations (com-puted from underspecified representations usingthe utool software6, or dependency views of thederivation trees (using the DTool software7).3.2 Grammar debuggingThe engineering process introduced in the preced-ing section belongs to a development cycle, whereone first designs a grammar and correspondinglexicons using XMG, then checks these with theparser, fixes them, parses again, and so on.To facilitate grammar debugging, TuLiPA in-cludes both a verbose and a robust mode allow-ing respectively to (i) produce a log of the RCG-conversion, RCG-parsing and RCG-derivation in-terpretation, and (ii) display mismatching featuresleading to incomplete derivations.
More precisely,in robust mode, the parser displays derivations stepby step, highlighting feature unification failures.TuLiPA?s options can be activated via an intu-itive Graphical User Interface (see Fig.
5).6See http://www.coli.uni-saarland.de/projects/chorus/utool/, with courtesy of AlexanderKoller.7With courtesy of Marco Kuhlmann.4Figure 5: TuLiPA?s Graphical User Interface.3.3 Towards a functional common interfaceUnfortunately, as mentioned above, the linguisthas to move back-and-forth from the gram-mar/lexicon descriptions to the parser, i.e., eachtime the parser reports grammar errors, the linguistfixes these and then recomputes the XML files andthen parses again.
To avoid this tedious task of re-sources re-compilation, we started developing anEclipse8 plug-in for the TuLiPA system.
Thus, thelinguist will be able to manage all these resources,and to call the parser, the metagrammar compiler,and the lexConverter from a common interface (seeFig.
6).Figure 6: TuLiPA?s eclipse plug-in.The motivation for this plug-in comes fromthe observation that designing electronic gram-mars is a task comparable to designing source8See http://www.eclipse.orgcode.
A powerful grammar engineering environ-ment should thus come with development facili-ties such as precise debugging information, syntaxhighlighting, etc.
Using the Eclipse open-sourcedevelopment platform allows for reusing severalcomponents inherited from the software develop-ment community, such as plug-ins for version con-trol, editors coupled with explorers, etc.Eventually, one point worth considering in thecontext of grammar development concerns data en-coding.
To our knowledge, only few environmentsprovide support for UTF-8 encoding, thus guaran-tying the coverage of a wide set of charsets andlanguages.
In TuLiPA, we added an UTF-8 sup-port (in the lexConverter), thus allowing to designa TAG for Korean (work in progress).3.4 Usability of the TuLiPA systemAs mentioned above, the TuLiPA system is madeof several interacting components, that one cur-rently has to install separately.
Nonetheless, muchattention has been paid to make this installationprocess as easy as possible and compatible withall major platforms.9XMG and lexConverter can be installed by com-piling their sources (using a make command).TuLiPA is developed in Java and released as an ex-ecutable jar.
No compilation is needed for it, theonly requirement is the Gecode/GecodeJ library10(available as a binary package for many platforms).Finally, the TuLiPA eclipse plug-in can be installedeasily from eclipse itself.
All these tools are re-leased under Free software licenses (either GNUGPL or Eclipse Public License).This environment is being used (i) at the Univer-sity of Tu?bingen, in the context of the developmentof a TT-MCTAG for German describing both syn-tax and semantics, and (ii) at LORIA Nancy, in thedevelopment of an XTAG-based metagrammar forEnglish.
The German grammar, called GerTT (forGerman Tree Tuples), is released under a LGPL li-cense for Linguistic Resources11 and is presentedin (Kallmeyer et al, 2008).
The test-suite cur-rently used to check the grammar is hand-crafted.A more systematic evaluation of the grammar is inpreparation, using the Test Suite for Natural Lan-guage Processing (Lehmann et al, 1996).9See http://sourcesup.cru.fr/tulipa.10See http://www.gecode.org/gecodej.11See http://infolingu.univ-mlv.fr/DonneesLinguistiques/Lexiques-Grammaires/lgpllr.html54 Comparison with existing approaches4.1 Engineering environments for tree-basedgrammar formalismsTo our knowledge, there is currently no availableparsing environment for multi-component TAG.Existing grammar engineering environments forTAG include the DyALog system12 described inVillemonte de la Clergerie (2005).
DyALog is acompiler for a logic programming language usingtabulation and dynamic programming techniques.This compiler has been used to implement efficientparsing algorithms for several formalisms, includ-ing TAG and RCG.
Unfortunately, it does not in-clude any built-in GUI and requires a good know-ledge of the GNU build tools to compile parsers.This makes it relatively difficult to use.
DyALog?smain quality lies in its efficiency in terms of pars-ing time and its capacity to handle very large re-sources.
Unlike TuLiPA, it does not compute se-mantic representations.The closest approach to TuLiPA corresponds tothe SemTAG system13, which extends TAG parserscompiled with DyALog with a semantic calculusmodule (Gardent and Parmentier, 2007).
UnlikeTuLiPA, this system only supports TAG, and doesnot provide any graphical output allowing to easilycheck the result of parsing.Note that, for grammar designers mainly inter-ested in TAG, SemTAG and TuLiPA can be seenas complementary tools.
Indeed, one may useTuLiPA to develop the grammar and check spe-cific syntactic structures thanks to its intuitive pars-ing environment.
Once the grammar is stable, onemay use SemTAG in batch processing to parsecorpuses and build semantic representations usinglarge grammars.
This combination of these 2 sys-tems is made easier by the fact that both use thesame input formats (a metagrammar in the XMGlanguage and a text-based lexicon).
This approachis the one being adopted for the development of aFrench TAG equipped with semantics.For Interaction Grammar (Perrier, 2000), thereexists an engineering environment gathering theXMG metagrammar compiler and an eLEtrOstaticPARser (LEOPAR).14 This environment is be-ing used to develop an Interaction Grammar forFrench.
TuLiPA?s lexical disambiguation module12See http://dyalog.gforge.inria.fr13See http://trac.loria.fr/?semconst14See http://www.loria.fr/equipes/calligramme/leopar/reuses techniques introduced by LEOPAR.
UnlikeTuLiPA, LEOPAR does not currently support se-mantic information.4.2 Engineering environments for othergrammar formalismsFor other formalisms, there exist state-of-the-artgrammar engineering environments that have beenused for many years to design large deep grammarsfor several languages.For Lexical Functional Grammar, one may citethe Xerox Linguistic Environment (XLE).15 ForHead-driven Phrase Structure Grammar, the mainavailable systems are the Linguistic KnowledgeBase (LKB)16 and the TRALE system.17 ForCombinatory Categorial Grammar, one may citethe OpenCCG library18 and the C&C parser.19These environments have been used to developbroad-coverage resources equipped with semanticsand include both a generator and a parser.
Un-like TuLiPA, they represent advanced projects, thathave been used for dialog and machine translationapplications.
They are mainly tailored for a spe-cific formalism.205 Future workIn this section, we give some prospective viewsconcerning engineering environments in general,and TuLiPA in particular.
We first distinguish be-tween 2 main usages of grammar engineering en-vironments, namely a pedagogical usage and anapplication-oriented usage, and finally give somecomments about multi-formalism.5.1 Pedagogical usageDeveloping grammars in a pedagogical contextneeds facilities allowing for inspection of the struc-tures of the grammar, step-by-step parsing (or gen-eration), along with an intuitive interface.
The ideais to abstract away from technical aspects related toimplementation (intermediate data structures, opti-mizations, etc.
).15See http://www2.parc.com/isl/groups/nltt/xle/16See http://wiki.delph-in.net/moin17See http://milca.sfs.uni-tuebingen.de/A4/Course/trale/18See http://openccg.sourceforge.net/19See http://svn.ask.it.usyd.edu.au/trac/candc/wiki20Nonetheless, Beavers (2002) encoded a CCG in theLKB?s Type Description Language.6The question whether to provide graphical ortext-based editors can be discussed.
As advo-cated by Baldridge et al (2007), a low-level text-based specification can offer more flexibility andbring less frustration to the grammar designer, es-pecially when such a specification can be graph-ically interpreted.
This is the approach chosenby XMG, where the grammar is defined via an(advanced or not) editor such as gedit or emacs.Within TuLiPA, we chose to go further by usingthe Eclipse platform.
Currently, it allows for dis-playing a summary of the content of a metagram-mar or lexicon on a side panel, while editing theseon a middle panel.
These two panels are linkedvia a jump functionality.
The next steps concern(i) the plugging of a graphical viewer to displaythe (meta)grammar structures independently froma given parse, and (ii) the extension of the eclipseplug-in so that one can easily consistently modifyentries of the metagrammar or lexicon (especiallywhen these are split over several files).5.2 Application-oriented usageWhen dealing with applications, one may demandmore from the grammar engineering environment,especially in terms of efficiency and robustness(support for larger resources, partial parsing, etc.
).Efficiency needs optimizations in the parsingengine making it possible to support grammarscontaining several thousands of structures.
Oneinteresting question concerns the compilation of agrammar either off-line or on-line.
In DyALog?sapproach, the grammar is compiled off-line intoa logical automaton encoding all possible deriva-tions.
This off-line compilation can take someminutes with a TAG having 6000 trees, but the re-sulting parser can parse sentences within a second.In TuLiPA?s approach, the grammar is compiledinto an RCG on-line.
While giving satisfactory re-sults on reduced resources21 , it may lead to trou-bles when scaling up.
This is especially true forTAG (the TT-MCTAG formalism is by definition afactorized formalism compared with TAG).
In thefuture, it would be useful to look for a way to pre-compile a TAG into an RCG off-line, thus savingthe conversion time.Another important feature of grammar engineer-ing environments consists of its debugging func-21For a TT-MCTAG counting about 300 sets of trees and anand-crafted lexicon made of about 300 of words, a 10-wordsentence is parsed (and a semantic representation computed)within seconds.tionalities.
Among these, one may cite unit andintegration testing.
It would be useful to extendthe TuLiPA system to provide a module for gen-erating test-suites for a given grammar.
The ideawould be to record the coverage and analyses ofa grammar at a given time.
Once the grammar isfurther developed, these snapshots would allow forregression testing.5.3 About multi-formalismWe already mentioned that TuLiPA was openinga way towards multi-formalism by relying on anRCG core.
It is worth noticing that the XMGsystem was also designed to be further extensi-ble.
Indeed, a metagrammar in XMG correspondsto the combination of elementary structures.
Onemay think of designing a library of such structures,these would be dependent on the target gram-mar formalism.
The combinations may representgeneral linguistic concepts and would be sharedby different grammar implementations, followingideas presented by Bender et al (2005).6 ConclusionIn this paper, we have presented a multi-formalismparsing architecture using RCG as a pivot formal-ism to parse mildly context-sensitive formalisms(currently TAG and TT-MCTAG).
This system hasbeen designed to facilitate grammar developmentby providing user-friendly interfaces, along withseveral functionalities (e.g., dependency extrac-tion, derivation/derived tree display and semanticcalculus).
It is currently used for developing a coregrammar for German.At the moment, we are working on the extensionof this architecture to include a fully functionalEclipse plug-in.
Other current tasks concern op-timizations to support large scale parsing and theextension of the syntactic and semantic coverageof the German grammar under development.In a near future, we plan to evaluate the parserand the German grammar (parsing time, correctionof syntactic and semantic outputs) with respect toa standard test-suite such as the TSNLP (Lehmannet al, 1996).AcknowledgmentsThis work has been supported by the DeutscheForschungsgemeinschaft (DFG) and the DeutscherAkademischer Austausch Dienst (DAAD, grant7A/06/71039).
We are grateful to three anonymousreviewers for valuable comments on this work.ReferencesBaldridge, Jason, Sudipta Chatterjee, Alexis Palmer,and Ben Wing.
2007.
DotCCG and VisCCG: Wikiand programming paradigms for improved grammarengineering with OpenCCG.
In King, Tracy Hol-loway and Emily M. Bender, editors, Proceedings ofthe GEAF07 workshop, pages 5?25, Stanford, CA.CSLI.Beavers, John.
2002.
Documentation: A CCG Imple-mentation for the LKB.
LinGO Working Paper No.2002-08, CSLI, Stanford University, Stanford, CA.Bender, Emily, Dan Flickinger, Frederik Fouvry, andMelanie Siegel.
2005.
Shared representation in mul-tilingual grammar engineering.
Research on Lan-guage & Computation, 3(2):131?138.Bonfante, Guillaume, Bruno Guillaume, and Guy Per-rier.
2004.
Polarization and abstraction of grammat-ical formalisms as methods for lexical disambigua-tion.
In Proceedings of the International Conferenceon Computational Linguistics (CoLing 2004), pages303?309, Geneva, Switzerland.Boullier, Pierre.
1998.
Proposal for a natural lan-guage processing syntactic backbone.
Rapport deRecherche 3342, INRIA.Boullier, Pierre.
1999.
On TAG and MulticomponentTAG Parsing.
Rapport de Recherche 3668, INRIA.Boullier, Pierre.
2000.
Range concatenation gram-mars.
In Proceedings of the International Workshopon Parsing Technologies (IWPT 2000), pages 53?64,Trento, Italy.Crabbe?, Benoit.
2005.
Grammatical development withXMG.
In Proceedings of the conference on LogicalAspects of Computational Linguistics 2005 (LACL05), pages 84?100, Bordeaux, France.Duchier, Denys, Joseph Le Roux, and Yannick Parmen-tier.
2004.
The Metagrammar Compiler: An NLPApplication with a Multi-paradigm Architecture.
InProceedings of the 2nd International Mozart/OzConference (MOZ?2004), pages 175?187, Charleroi,Belgium.Erbach, Gregor.
1992.
Tools for grammar engineer-ing.
In 3rd Conference on Applied Natural Lan-guage Processing, pages 243?244, Trento, Italy.Gardent, Claire and Laura Kallmeyer.
2003.
SemanticConstruction in FTAG.
In Proceedings of the Con-ference of the European chapter of the Associationfor Computational Linguistics (EACL 2003), pages123?130, Budapest, Hungary.Gardent, Claire and Yannick Parmentier.
2007.
Sem-tag: a platform for specifying tree adjoining gram-mars and performing tag-based semantic construc-tion.
In Proceedings of the International Confer-ence of the Association for Computational Linguis-tics (ACL 2007), Companion Volume Proceedings ofthe Demo and Poster Sessions, pages 13?16, Prague,Czech Republic.Joshi, Aravind K. 1987.
An introduction to Tree Ad-joining Grammars.
In Manaster-Ramer, A., editor,Mathematics of Language, pages 87?114.
John Ben-jamins, Amsterdam.Kallmeyer, Laura and Yannick Parmentier.
2008.
Onthe relation between Multicomponent Tree Adjoin-ing Grammars with Tree Tuples (TT-MCTAG) andRange Concatenation Grammars (RCG).
In Pro-ceedings of the 2nd International Conference onLanguage and Automata Theories and Applications(LATA 2008), pages 277?288, Tarragona, Spain.Kallmeyer, Laura, Timm Lichte, Wolfgang Maier, Yan-nick Parmentier, and Johannes Dellert.
2008.
De-velopping an MCTAG for German with an RCG-based Parser.
In Proceedings of the Language, Re-source and Evaluation Conference (LREC 2008),Marrakech, Morocco.Lehmann, Sabine, Stephan Oepen, Sylvie Regnier-Prost, Klaus Netter, Veronika Lux, Judith Klein,Kirsten Falkedal, Frederik Fouvry, Dominique Esti-val, Eva Dauphin, Herve?
Compagnion, Judith Baur,Lorna Balkan, and Doug Arnold.
1996.
TSNLP ?Test Suites for Natural Language Processing.
In Pro-ceedings of the International Conference on Compu-tational Linguistics (Coling 1996), volume 2, pages711?716, Copenhagen, Denmark.Lichte, Timm.
2007.
An MCTAG with tuples for co-herent constructions in German.
In Proceedings ofthe 12th Conference on Formal Grammar, Dublin,Ireland.Perrier, Guy.
2000.
Interaction grammars.
In Pro-ceedings of the International Conference on Compu-tational Linguistics (CoLing 2000), pages 600?606,Saarbruecken, Germany.S?gaard, Anders.
2007.
Complexity, expressivity andlogic of linguistic theories.
Ph.D. thesis, Universityof Copenhagen, Copenhagen, Denmark.Villemonte de la Clergerie, ?Eric.
2005.
DyALog: atabular logic programming based environment forNLP.
In Proceedings of the workshop on ConstraintSatisfaction for Language Processing (CSLP 2005),pages 18?33, Barcelona, Spain.XTAG-Research-Group.
2001.
A lexicalized treeadjoining grammar for english.
Technical Re-port IRCS-01-03, IRCS, University of Pennsylva-nia.
Available at http://www.cis.upenn.edu/?xtag/gramrelease.html.8
