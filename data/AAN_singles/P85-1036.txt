GRAMMATICAL ANALYSIS BY COMPUT~ OF THE LANCASTER-OSLO/BERGEN(LOB) CORPUS OF BRITISH ~NGLISH TEXTS.Andrew David BealeUnit for Computer Research on the English LanguageBowland College, University of LancasterBailrigg, Lancaster, England LA1 aYT.ABSTRACTResearch has been under way at theUnit for Computer Research on the ~hglishLanguage at the University of Lancaster,England, to develop a suite of computerprograms which provide a detailedgrammatical analysis of the LOB corpus,a collection of about 1 million words ofBritish English texts available inmachine readable form.The first phrase of the pruject,completed in September 1983, produced agrammatically annotated version of thecorpus giving a tag showing the wordclass of each word token.
Over 93 percent of the word tags were correctlyselected by using a matrix of tag pairprobabilities and this figure was upgradedby a further 3 per cent by retaggingproblematic strings of words prior todisambiguation and by altering theprobability weightings for sequences ofthree tags.
The remaining 3 to ~ percent were corrected by a human post-editor.The system was originally designed torun in batch mode over the corpus but wehave recently modified procedures to runinteractively for sample sentences typedin by a user at a terminal.
We arecurrently extending the word tag set andimproving the word tagging procedures tofurther reduce manual intervention.
Asimilar probabilistic system is beingdeveloped for phrase and clause tagging.~qE STI~JCTURE A~D PURPOSEOF THE LOB CORPUS.The LOB Corpus (Johansson, Leech andGoodluck, 1978), like its American~/gl~sh counterpart, the Brown CorpusLKucera and Francis, 196a; Hauge and;Iofland, 1978), is a collection of 500samples of British ~hglish texts, eachcontaining about 2,000 word tokens.
Thesamples are representations of 15different ~ext categories: A.
Press(Reportage); B.
Press (Editorial);C. Press (Reviews); D. Religion; E.~ i l l s  and Hobbies; F. Popular Lore;G. Belles Lettres, Biography, r'\[emoirs,293etc.
; H. Miscellaneous ; J.Learned and Scientific; K. GeneralFiction; L. Mystery and DetectiveFiction; M. Science Fiction; N.Adventure and Western Fiction, Romanceand Love Story; R. Humour.
There aretwo main sections, informative prose andimaginative prose, and all the textscontained in the corpus weee printed ina single year (1961).The structure of the LOB corpus wasdesigned to resemble that of the Browncorpus as closely as possible so thata systematic comparison of British andAmerican written English could be made.Both corpora contain samples of textspublished in the same year (1961) sothat comparisons are not distorted bydiachronic factors.The LOB corpus is used as a databasefor linguistic research and languagedescription.
Historically, different\]inguists have been concerned to agreater or lesser extent with the use ofcorpus citations, to some degree, atleast, because of differences in theperceived view of the descriptiverequirements of grammar.
Jespersen(1909-A9), Kruisinga and Erades (1911)gave frequent examples of citations fromassembled corpora of written texts toillustrate grammatical rules.
Work ontext corpora is, of course, very muchalive toda~v.
Storage, retrieval andprocessing of natural language text is amore efficient and less laborious taskwith modern computer hardware than itwas with hand-written card files butdata capture is still a significantproblem (Francis, 1980).
The forthcomingwork, A Comprehensive Grammar of the~E l i sh  Lan~la~e (Quirk, Greenbaum,leech, and ~arr.vik, 1985) contains manycitations from both LOB and BrownCorpora.A GRAF~ATICALLY ANNOTA~ VERSIONOF ~E CORPUSSince 1981, research has been directedtowards writing programs to grammaticallyannotate the LOB cor~is.
From 1981-83,the research effort produced a version ofthe corpus with every word token labelledby a grammatical tag showing the wordclass of each word form.
Subsequentresearch has attempted to build on thetechni~les used for automatic wordtagging by using the output from the wordtagging programs as input to phrase andclause tagging and by using probabilisticmethods to provide a constituent analysisof the LOB corpus.~e  programs and data files used forword tagging were developed from work doneat Brown University (Greene and BAbin,1971).
Staff and research associates atLancaster undertook the programming inPASCAL while colleagues in Oslo revisedand extended the lists used by Greene andR~bin (op.cit.)
for word tag assignment.Half of the corpus was post-edited atLancaster and the other half at theNorwegian Computing Centre for theHumanities.How word tagging works.~he major difficulties to beencountered with word tagging of writtenEnglish are the lack of distinctiveinflectional or derivational endings andthe large proportion of word forms thatbelong to more than one word class.~hdings such as -able, -ly and -ness aregraphic realizations"---of morphologlc'-~lunits indicating word class, but theyoccur infrequently for the purposes ofautomatic word tag assignment; thereader will be able to establishexceptions to rules assigning word classesto words with these suffixes, because thecharacters do not invariably representthe same morphemes.The solution we have adopted is to usea look up procedure to assign one or morepotential ~ags to each input word.
~eappropriate word tag is then selected forwords with more than one potential tagby ca\]culatLug the probability of thetag's occurrence ~iven neighbouringpotential tags.~otential word tag assignment.In cases where more than one potentialtag is assigned to the inpu~ word, thetags represent word classes of the wordwithout taking the syntactic environmeatinto account.
A list of one to five wordflnal characters, known as the's~ffixlist', is used for assignment ofappropriate word class tags to as manyword types as possible.
A list of fullword forms, known as the 'wordlist', i&used for exceptions to the suffixlist,and, in addition, word forms that occurmore than 50 times in the corpus areincluded in the wordlist, for speed ofprocessing.
The term 'suffixlist' isused as a convenient name, and the readeris warned that the list does notnecessarily contain word final morphs;strings of between one and five wordfinal characters are included if theiroccurrence as a gagged form in the Browncorpus merits it.~e  'suffixlist' used by Greene andRubin (op.cit.)
was substantially revisedand extended by Johansson and Jahr (1982)using reverse alphabetical lists ofapproximately 50,000 word types of theBrown Corpus and 75,000 word types ofboth Brown and LOB corpora.
Frequencylists specifying the fre~uehcy of tagsfor word endings consistlng of 1 to 5characters were used to establish theefficiency of each rule.
Johansson andJ~r  were guided by the LongmanDictionary of Contemporary ~hglish (1978)and other dictionaries and grammarsincluding ~/irk, Greenbaum, Leech and~art-vik (1972) in identifying tags foreach item in the wordlist.
For theversion used for Lancaster-Oslo/BerEenword tagging (1985), the suffixlist wasexpanded to about 7~90 strings of wordfinal characters, the wordlist consistedof about 7,000 entries and a total of135 word tag types were used.Potential ~ag disambiguation.~%e problem of resolving lexicalambiguity for the large proportion ofEnglish words that occur in more than oneword class, (BLOW, CONTACT, HIT, LEFT,RA2~, RUN, REFUSE, RDSE, 'dALE, WATCH ...),is solved, whenever possible by examiningthe local context.
'~rd tag selectionfor homographs in Greene a~d Rubin (op.cir.)
was attempted by using 'contextframe rules', an ordered list of 5,300rules designed to take into account thetags assigned to up to two wordspreceding or following the ambiguoushomograph.
~3~e program was 77 per centsuccessful but several errors were due toappropriate rules being blocked whenadjacent ambi~lities were encountered(Marshall, 1983: 140).
Moreover, about80 per cent of rule application tookjust one immediately neighbouring taginto account, even though only a quarterof the context frame rules specifiedonly one immediately neighbouring tag.To overcome these difficulties,research associates at Lancaster havedevised a transition probability matrixof tag pairs to compute the most probable294tag for an ambiguous form given theimmediately preceding and following tags.~his method of calculating one-steptransition probabilities is suitable fordisambiguating strings of ambiguouslytagged words because the most likely paththrough a string of ambiguously taggedwords can be calculated.The likelihood of a tag being selectedin context is also influenced by likeli-hood markers which are assigned toentries with more than one tag in thelists.
Only two markers, '@' and '%',are used, '@' notionally Ludicat~ngthat the tag is correct for theassociated form less than 1 in lOoccasions, '%' notionally indicating thatthe tag occurs less than 1 in lOOoccasions.
The word tag disambiguationprogram uses these markers to reduce theprobability of the less likely tagsoccurring Lu context; '@' results in theprobability being halved, '%' results inthe probability being divided by eight.Hence tags marked with '@' or '%' areonly selected if the context indicatesthat the tag is very likely.Error analysis.At several stages during design andimplementation of the tagging software,error analysis was used to improve variousaspects of the word tagging system.Error statistics were used to amend thelists, the transition matrix entries andeven the formula used for calculatingtransition probabilities (originally thiswas the frequency of potential tag Afollowed by potential tag B divided bythe frequency of A.
Subsequently, it waschanged to the frequency of A followed byB divided by the product of the frequencyof A and the frequency of B (Marshall,1983: l~w~ff)).Error analysis indicated that the one-step transition method for word tagdisambiguation was very successful, butit was evident that further gains could bemade by including a separate list of asmall set of sequences of words such asaccordin~ to, as well as, and so as towhich were retagged prior to word tagdisambigu.~ t ior~.
Another modificationwas to include an algorithm for alteringthe values of sequences of three tags,such as constructions with an interveningadverb or simple co-ordinatedconstructions such that the two words oneither side of a co-ordinating conjunctioncontained the same tag where a choice wasavailable.No value in the matrix was allowed tobe as little as zero, by providing aminimum positive value for even extremelyunlikely tag co-occurrences; this allowedat least some kind of analysis for unusualor eccentric syntax and prevented thesystem from grinding to a halt whenconfronted with a construction that itdid not recognize.Once these refinements to the suite ofword tagging programs were made, thecorpus was word-tagged.
It was estimmtedthat the number of manual post-editinginterventions had been reduced from about230,000 required for word tagging of theBrown corpus to about 35,000 requiredfor the IDB corpus (Leech, Garside andAtwell, 1983: 36).
The method achievesfar greater consistency than could beattained by a human, were such a personable to labour through the task ofattributing a tag to every word token inthe corpus.A record of decisions made at the post-editing stage was kept for the purpose ofrecording the criteria for judgingwhether tags were considered to be corrector not (Atwell, 1982b).Improving word tagging.Work currently being undertaken atLancaster includes revising and extendingthe word tag set and improving the suiteof programs and data files required tocarry out automatic word tagging.Revision of the word tag set.The word tag set is being revised sothat, whenever possible, tags aremnemonic such that the characters chosenfor a tag are abbreviations of thegrammatical categories they represent.This criterion for word tag improvementis solely for the benefit of humanintelligibility and in some cases,because of conflicting criteria ofdistinctiveness and brevity, it is notalways possible to devise clearlymnemonic tags.
For instance, nouns andverbs can be unequivocally tagged by thefirst letter abbreviations 'N' and 'V',but the same cannot be said for articles,adverbs and adjectives.
These categoriesare represented by the tags 'AT', 'RR',and 'JJ'.It was decided, on the grounds ofimproving mnemonicity, to changerepresentation of the category of numberin the tag set.
In the old tag set,singular forms of articles, determiners,pronouns and nouns were unmarked, andplural forms had the same tags as thesingular forms but with 'S' as the endcharacter denoting plural.
As far asmnemonicity is concerned, this isconfusing, especially to someoneuninitiated in the refinements of LOBtagging.
In the new tag set, number is295now marked by having 'I' for singularforms, 'P' for plural forms and no numbercharacter for nouns, articles anddeterminers which exhibit no singular orplural morpLolo~ical distJnctJveaess (COD,A~ is d~siralC,_e, both for the purposesof human intelligibility and formechanical processing, to make the taggedsystem as hierarchized as possible.
Inthe old tag set m,xial verbs, and forms ofthe verbs BE, DO and HAVE were tagged as'r~,'', 'B" ,  'D" ,  and 'H" (where '''~epresents any of the characters used forthese tags denoting sub~lasses of eachtag class).
In the new word tag set,these have been recoded 'V~,~'', 'VB'','VD'', 'V~",  to show that ~hey are, iltfact, verbs, and to Cacilitate verbcouni.inE in a f~equency ~nalysis of thet_agged corpus; "4"I'' is I:he new tag for"\] exical verbs.It has been taken as a design principleof the new tag set that, wherever possible,subc_~.teEories and supercat~gories shouldbe retrieved by referrin E to thezhara<-ter position in \[:,he string ofcharacters ::taking up a tag, major wordclass Codin~ beir~ denoted by the initialcharacter(s) nf the tag and subsequentcharactel.s denoting morpho-syntacticsubcateEor~ ~s.Kierarchization of the new tee set isbest e?e~:'pIi fied by prcnnuns.
'P' '  is apronoun, .~s distinct from other ta~initial characters, s~,~h as "~:'' fornoun, 'V'' fo\]' verb a/~d so on.
'PP''~s a personal pronoun, ~s distinct from'~:'' ~n indefinite pronoun; '~?I''is a first persnn personal pronoun: ~,we, us, as distinct fr'om 'Plm/.
?'
,I{ ~'v ~.n--d" ' ;PX" which a~'e second,third person and r~flex~ve l~ronouI~s;'~'~'IS" is a fib-st pezso:t s:~b~ectp~rsonal prortourl: I and we, 8s distinctfrom fi~'s ~ person o~-ject l~r.~ons\] pronouns,:~e, af~ ,:~s,_Ts denote~i by ';PIO" ' ; finally"r!~pISl : the first person s i~l \ ]  arsubject personal pronoun, _I (~he colonis used tc show that the form mus~ havean .-:xtitial capital letter).~e  thir, l cril:erion for revising andenlarging the word tag set is to improve~nd extend the linguistic cateEorisation.For.
instance, a tag for the category ofpredi~:ative addectJve, 'JA', has beenintroduced fo1" ad~e~-tives like ablaze,adrift and afloat, in addition Uo the~ y  ex - :~d is t~ct ion  betweenattributive and ordinaz~ adjectives,marked 'JB' as distinct from 'JJ'.There is a~ essential distributionalrestriction on subclasses of adjectivesoccurring only attributively orpredicatively, and it was consideredappropriate t~notate  this in the tag setin a consistent manner.
The attributivecategory has been introduced forcomparative adjectives, 'JBR', (bq=PER,~;T~ ...) and superlative adjectives,'JBT', (U~OST,  UTTEI~OST ... ).As a further example of improving thelinguistic categorization withoutaffecting the proportion of correctlytagged word forms, consider the word ONE.In the old tagging system, this wordwas always assigned the tag 'CDI'.This is unsatisfactory, even though ~TEis always assigned the tag it is supposedto receive, because O~FE is not simplya singular cardinal number.
It can be asin~llar impersonal pronoun, One is oftens~r i sed  by the reaction of ~ ~ s~,or  a sinEul-ar" ~mm-~ ~ ,  We ~ts - -~Scontrasting, for instance, w-'~h-'~al form He wants those ones.
It is~herefore approprl'~e f-To'~ ~,~C~,~o beassigned 5 potential tags, 'CDI', '~TI',and '~TNI', one of which is to be selectedby the transition probability procedure.Revision of the programs and data files.Revision of the word tag set hasnecessitated extensive revision of theword- and suffixlists.
The transitionmatrix will be adapted so that thecorpus can be retagged with tags fromthe new word tag set.
In addition,programs are being revised to reduce theneed for special pre-editing and inputformat requirements.
In this way, it willbe possible for th~ system to tag~g l J sh  tex~s or:her than the LOB corpuswithout pre-edJ ring.Reducing Pre-editing.For the 1983 version of the ta~gedcorpus, a pre-editin E stage was carriedout partly by computer and partly by ah,~man pre-editor (Atwell, 1982a).
As partof this stage, the computer automaticallyreduced all sentence-initial capitalletters and the hum~ pre-editor recapit-alizsd those sentence initial charactersthat began proper nouns.
We are nowendeavourin E to cut out this phase so thatthe automatic tagg~n E suite can processinp, xt text in its normal orthographicform as mixed case characters.Eentence boundaries were explicitly?
~arked, an part of thp input ~eq~:irements::o the tag~.in~ procedures, and sincethe word class of a word with an initialcapital letter is significantly affectedby whether it occurs at the beginningof a sentence, it was consideredappropriate to make both sentenceboundary recognition and word classassignment of words with a word init.ialcapital automatic.
All entries in the296word list now appear entirely in lowercase and words which occur with differenttags according to initial letter status(board, march, may, white ...) areassigned tags accordzng t~--"o a fieldselection procedure: the appropriate tagsare given in two fields, one for theinitial upper case form (when not actingas the standard beginning-of-sentencemarker) and the other for the initiallower case form.
The probability of tagsbeing selected from the alternative listsis weighted according to whether the formoccurs at the beginning of the sentenceor elsewhere.Knut Hofland estimated a success rateof about 9a.3 per cent without pre-editing(Leech, Garside and Atwell, 1983: 36).Hence, the success rate only drops byabout 2 per cent without pre-editing.Nevertheless, the problems raised by wordswith tags varying according to initialcapital letter status need to be solvedif the system is to become completelyautomatic and capable of correct taggingof standard text.Constituent ;alalysis.The high success rate of word tagselection achieved by the one-stepprobability disambiguation procedureprompted us to attempt a similar methodfor the more complex tasks of phrase andclause tagging.
The paper by Garside andLeech in this volume deals more fully withthis aspect of the work.Rules and symbols for providinga constituent analysis of each o?
thesentences in the corpus are set ~t  in aCase-law Manual (Sampson, 198~) and aseries of associated documents give thereasoning for the choice of rules andsymbols (Sampson, 1983 - ).
Extensivetree drawing was ,mdertaken while theCase-Law ~anual was beinz written, partlyto establish whether high-level tags andrules for hig~h-level tag assignmentneeded to be modified in the light of theenormous variety and complexity ofordinary sentences in the corpus, andpartly to create a databank of manuallyparsed samples of the LOB corpus, for thepurposes of providing a first-approximation of the statistical datarequired to disambiguate alternativeparses.To date, about 35,O00 words (I,500sentences) have been manually parsed andkeyed into an ICL ~/E 2900 machine.
W~are presently aimin~ for a tree bank ofabout 50,0OO words of evenly distributedsamples taken from different corpuscategories r,presenting a cross-sectionof about 5 per cent of the word taggedc or!m~ s.The future.It should be made clear to the readerthat several aspects of the researchare cumulative.
For instance, thestatistics derived from the tagged Browncorpus were used to devise the one-stepprobability program for word tagdisambiguation.
Similarly, the wordtagged LOB corpus is taken as the inputto automatic parsing.At present, we are attempting to :provide constituent structures for theLOB corpus.
Many of these constructionsare long and complex; it is notoriouslydifficult to summarise the rich varietyof written ~hg!ish, as it actually occursin newspapers and books, by using alimited set of rewrite rules.
Initially,we are attempting to parse the LOBcorpus using the statistics provided bythe tree bank and subsequently, aftererror analysis and post-editing,statistics of the parsed corpus can beused for further research.ACKNOWI/~GI~E~TSThe work described by the author ofthis paper is currently supported byScience and ~h~ine~r~ug Research CouncilGrant GRICI~7700.~ C E SAbbreviation :ICAME _- International Computer Archiveof Modern ~hglish.Atwell, E.S.
(1982a).
LOB Corpus Ta~in~Project: Manual Pr~'/%-dit Handbook.Unpub l i she~- -~ent  : Unit forComputer Research on the ~hglishLanguage, University of lancaster.(1982b).
LOB ~rpus  Taggin~ Project:Manual Po s--~- e~-f-~andb oo k. m ~ -grammar of LOB Corpus English,examining the types of error commonlymade during automatic (computational)analysis of ordinary written English).Unpublished document : Unit forComputer Research on the ~hglishlanguage, University of lancaster.Francis, W.N.
(1980).
'A tagged corpus -problems and prospects', in Studiesin ~hglish lin~listics for Randolph~1980) edited by S-~-'Greenbaum,G .N~ech and J. S~arrvik, 192-209.London : Longman.Greene, B.B.
and Rubin, G.M.
(1971).
'Automatic Grammatical Tagging ofEnglish', Providence, R.I. :Department of Linguistics, BrownUniversity.297Hauge, J. and Hofland, K. (1978).~ticrofiche version of the BrownUniversityCo rpus oi'~Pr--~ent--~yAmerican ~n~-l-~.
\]~rgen:'-e~"~'4~s EDB-Senter for Humanistisk Forskning.Jespersen, O.
(1909-A9).
A Modern ~hElishGrammar on Historical ~r~c~es ,F~un_ks g a ar~.Johansson, S. (1982) (editor).
ComputerCorpora in ~hElish language research.Bergen: -~orwegian Computing Centrefor the Humanities.Johansson, S. and Jahr, M-C.
(1982).
'Grammatical Tagging of the LOB Corpus:Predicting Word Class from Word~hdings', in S. Johansson (1982), ll8-Johansson, S., Leech, G. and Goodluck, H.(1978).
Manual of information toac c omp any- ' -~-~c  as ter-Os lo/Be'-r~en~ o?
r~t ish  Eaglish, for use with i computers.
Unpublish-~ d-~u~ent :Department of English, University ofOslo.Kruisinga, E. and Erades, P.A.
(1911).An ~hElish Grammar.
Nordhoof.Kuc'~a, H. and Francis, W.N.
(196A,revised 1971 and 1979).
Manual ofInformation to accompany A~a- ' rdof Pro-sent-Day Rii~ed Americanor use witRComouters.---~r~-'~de-~, R~ode Island:Brown University Press.Leech, G.N., Garside, R., and Atwell, E.(1983).
'Recent Developments in theus~ of Computer Corpora in EnglishLanguage Research', Transactions of thePhilological Society, 23-aO.~s DictionaIT/ of Cmntemporary ~h~lish ).
London'S- Longman.Marshall, I.
(1983).
'Choice ofGrammatical Word-Class without Global~/ntactic Analysis: Tagging Words inthe LOB Corpus', Computers and theHumanities, Vol.
17, No.
3, 139-150.Quirk, R., Greenbatu~, S., Leech., G.N.and S~arrvik, J.
(1972).
A Grammar ofCon~emporar~ ~hslish.
LondOn: Longing.(1985).
A Comprehensive Grammar of the~h~lish rangua~e.
London : Longman.Sampson, G.R.
(198A).
UCR~, Symbols andl~les for Manual Tree--~aw~n~.~-~l~-~e~' -~en~:  Unit ~or ComputerResearch on the English Language,University of Lancaster.
(1983 -).
Tree Notes I - XIV.Unpublished documents: Unit forComputer Research on the HhglishLanguace, University of Lancaster.298
