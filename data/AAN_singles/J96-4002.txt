An Algorithm to Align Words forHistorical ComparisonMichae l  A. Covington*The University of GeorgiaThe first step in applying the comparative method to a pair of words suspected of being cognate isto align the segments of each word that appear to correspond.
Finding the right alignment mayrequire searching.
For example, Latin dO 'I give' lines up with the middle do in Greek didOmi,not the initial di.This paper presents an algorithm for finding probably correct alignments on the basis ofphonetic similarity.
The algorithm consists of an evaluation metric and a guided search procedure.The search algorithm can be extended to implement special handling of metathesis, assimilation,or other phenomena that require looking ahead in the string, and can return any number ofalignments that meet some criterion of goodness, not just the one best.
It can serve as a front endto computer implementations of the comparative method.1.
The ProblemThe first step in applying the comparative method to a pair of words suspected ofbeing cognate is to align the segments of each word that appear to correspond.
Thisalignment step is not necessarily trivial.
For example, the correct alignment of Latindcr with Greek did~Ymi is- -do - -d idOmiand notdo  .
.
.
.
d - -O  .
.
.
.
.
.
dod idomi  d idOmi  d idOmior numerous other possibilities.
The segments of two words may be misaligned be-cause of affixes (living or fossilized), reduplication, and sound changes that alter thenumber of segments, uch as elision or monophthongization.Alignment is a neglected part of the computerization f the comparative method.The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish(1989) require the alignments to be specified in their input.
The Reconstruction E gineof Lowe and Mazaudon (1994) requires the linguist to specify hypothetical soundchanges and canonical syllable structure.
The cognateness tester of Guy (1994) ignoresthe order of segments, matching any segment in one word with any segment in theother.This paper presents a guided search algorithm for finding the best alignment ofone word with another, where both words are given in a broad phonetic transcription.
* Artificial Intelligence Center, The University of Georgia, Athens, Georgia 30602-7415.
E-mail:mcovingt@ai.uga.edu(~) 1996 Association for Computational LinguisticsComputational Linguistics Volume 22, Number 4The algorithm compares urface forms and does not look for sound laws or phono-logical rules; it is meant to correspond to the linguist's first look at unfamiliar data.A prototype implementation has been built in Prolog and tested on a corpus of 82known cognate pairs from various languages.
Somewhat surprisingly, it needs little orno knowledge of phonology beyond the distinction between vowels, consonants, andglides.2.
AlignmentsIf the two words to be aligned are identical, the task of aligning them is trivial.
In allother cases, the problem is one of inexact string matching, i.e., finding the alignmentthat minimizes the difference between the two words.
A dynamic programming algo-rithm for inexact string matching is well known (Sankoff & Kruskal 1983, Ukkonen1985, Waterman 1995), but I do not use it, for several reasons.
First, the strings beingaligned are relatively short, so the efficiency of dynamic programming on long stringsis not needed.
Second, dynamic programming normally gives only one alignment foreach pair of strings, but comparative reconstruction may need the n best alternatives,or all that meet some criterion.
Third, the tree search algorithm lends itself to modifi-cation for special handling of metathesis or assimilation.
More about this later; first Ineed to sketch what the aligner is supposed to accomplish.An alignment can be viewed as a way of stepping through two words concurrently,consuming all the segments of each.
At each step, the aligner can perform either amatch or skip.
A match is what happens when the aligner consumes a segment fromeach of the two words in a single step, thereby aligning the two segments with eachother (whether or not they are phonologically similar).
A skip is what happens whenit consumes a segment from one word while leaving the other word alone.
Thus, thealignmentabc  --bdeis produced by skipping a, then matching b with b, then matching c with d, thenskipping e. Here as elsewhere, hyphens in either string correspond to skipped segmentsin the other.
1The aligner is not allowed to perform, in succession, a skip on one string and thena skip on the other, because the result would be equivalent to a match (of possiblydissimilar segments).
That is, of the three alignmentsab-c  a -bc  abca -dc  ad-c  adconly the third one is permitted; pursuing all three would waste time because theyare equivalent as far as linguistic claims are concerned.
(Determining whether b and dactually correspond is a question of historical reconstruction, ot of alignment.)
I callthis restriction the no-alternating-skips rule.To identify the best alignment, the algorithm must assign a penalty (cost) to everyskip or match.
The best alignment is the one with the lowest total penalty.
As a first1 Traditionally, the problem is formulated in terms of operations to turn one string into the other.
Skipsin string 1 and string 2 are called deletions and insertions respectively, and matches of dissimilarsegments are called substitutions.
This terminology is inappropriate for historical inguistics, since theultimate goal is to derive the two strings from a common ancestor.482Covington An Algorithm to Align Wordsapproximation, we can use the following penalties:0.0 for an exact match;0.5 for aligning a vowel with a different vowel, or a consonant with adifferent consonant;1.0 for a complete mismatch;0.5 for a skip (so that two alternating skips--the disallowed case----wouldhave the same penalty as the mismatch to which they are equivalent).Then the possible alignments of Spanish el and French le (phonetically \[lo\]) are:e l1 o 2 complete mismatches = 2.0-e l10 -  2 skips + 1 vowel pair -- 1.5e l -- 1 o 2 skips + 1 exact match = 1.0The third of these has the lowest penalty (and is the etymologically correct alignment).3.
The Search SpaceFigure 1 shows, in the form of a tree, all of the moves that the aligner might try whileattempting to align two three-letter words (English \[h~ez\] and German \[hat\]).
We knowthat these words correspond segment-by-segment, 2 but the aligner does not.
It has towork through numerous alternatives in order to conclude thath~ezhatis indeed the best alignment.The alignment algorithm is simply a depth-first search of this tree, beginning atthe top of Figure 1.
That is, at each position in the pair of input strings, the aligner triesfirst a match, then a skip on the first word, then a skip on the second, and computesall the consequences of each.
After completing each alignment it backs up to the mostrecent mtried alternative and tries a different one.
"Dead ends" in the tree are placeswhere further computation is blocked by the no-alternating-skip rule.As should be evident, the search tree can be quite large even if the words beingaligned are fairly short.
Table 1 gives the number of possible alignments for words ofvarious lengths; when both words are of length n, there are about 3 "-1 alignments,not counting dead ends.
Without the no-alternating-skip rule, the number would beabout 5"/2.
Exact formulas are given in the appendix.Fortunately, the aligner can greatly narrow the search by putting the evaluationmetric to use as it works.
The key idea is to abandon any branch of the search tree2 Actually, as an anonymous reviewer points out, the exact correspondence is between German hat andearlier English hath.
The current English -s ending may be analogical.
This does not affect he validityof the example because/t/and /s/are certainly in corresponding positions, regardless oftheirphonological history.483Computational Linguistics Volume 22, Number 4Start0.5;2 0.50.5IL~----al 1.
01.02.0~/  1.5 ~s2  2.0o5M1.oFigure 1Search space for al igning English /h~ez /w i th  German/hat / .endendI t -~- J I  2.0- -  Dead end.:___..dl.)
~ 2 .
0~ D e a d  endU::-Z-=~a.)
~ 3 .
0~ Dead end7 ~ 2 .
5s ~  2.5 Dead end~ Dead end3.0~"  ~ 2 .
5Dead end2.5~ D, ead endDead endL----------~ \]2.
5~ 2 .
5484Covington An Algorithm to Align WordsTable 1Number of alignments as a function of lengths ofwords.Lengths of words Alignments2 2 32 3 52 4 82 5 123 3 93 4 153 5 244 4 274 5 465 5 8310 10 26,797as soon as the accumulated penalty exceeds the total penalty of the best alignmentfound so far.
Figure 2 shows the search tree after pruning according to this principle.The total amount of work is roughly cut in half.
With larger trees, the saving can beeven greater.To ensure that a relatively good alignment is found early, it is important, at eachstage, to try matches before trying skips.
Otherwise the aligner would start by gener-ating a large number of useless displacements of each string relative to the other, allof which have high penalties and do not narrow the search space much.
Even so, thealgorithm is quite able to skip affixes when appropriate.
For example, when asked toalign Greek didomi with Latin dO, it tries only three alignments, of which the best twoare:d idomi  d idOmid - -o  .
.
.
.
dO- -Choosing the right one of these is then a task for the linguist rather than the alignmentalgorithm.
However, it would be easy to modify the algorithm to use a lower penaltyfor skips at the beginning or end of a word than skips elsewhere; the algorithm wouldthen be more willing to postulate prefixes and suffixes than infixes.4.
The Full Evaluation MetricTable 2 shows an evaluation metric developed by trial and error using the 82 cognatepairs shown in the subsequent tables.
To avoid floating-point rounding errors, allpenalties are integers, and the penalty for a complete mismatch is now 100 ratherthan 1.0.
The principles that emerge are that syllabicity is paramount, consonantsmatter more than vowels, and affixes tend to be contiguous.Somewhat surprisingly, it was not necessary to use information about place ofarticulation i  this evaluation metric (although there are a few places where it mighthave helped).
This accords with Anttila's (1989, 230) observation that great phoneticsubtlety is not needed to align words; what one wants to do is find the exact matchesand align the syllabic peaks, matching segments of comparable syllabicity (vowelswith vowels and consonants with consonants).485Computational Linguistics Volume 22, Number 4$20.50.5~ Dead end~ Dead end,,~c i1.
5hh ~---~---- Dead end0.5~ 1 .
5$2~ D e a d  end1.5Start4S10.5~ 1.5 $11.5M/  \].50.5Figure 2Same tree as in Figure 1, after pruning.$21.0- - "11 .5- - -11 .5486Covington An Algorithm to Align WordsTable 2Evaluation metric developed from actual data.Penalty Conditions0 Exact match of consonants or glides (w, y)Exact match of vowels (reflecting the fact thatthe aligner should prefer to match consonantsrather than vowels if it must choose between the two)10 Match of two vowels that differ only in length,or i and y, or u and w30 Match of two dissimilar vowels60 Match of two dissimilar consonants100 Match of two segments with no discernible similarity40 Skip preceded by another skip in the same word(reflecting the fact that affixes tend to becontiguous)50 Skip not preceded by another skip in the same wordIt follows that the input to the aligner should be in broad phonetic transcrip-tion, using symbols with closely similar values in both langauges.
Excessively narrowphonetic transcriptions do not help; they introduce too many subtle mismatches thatshould have been ignored.Phonemic transcriptions are acceptable insofar as they are also broad phonetic, but,unlike comparative reconstruction, alignment does not benefit by taking phonemes asthe starting point.
One reason is that alignment deals with syntagmatic rather thanparadigmatic relations between sounds; what counts is the place of the sound in theword, not the place of the sound in the sound system.
Another reason is that earlierand later languages are tied together more by the physical nature of the sounds thanby the structure of the system.
The physical sounds are handed down from earliergenerations but the system of contrasts is constructed anew by every child learningto talk.The aligner's only job is to line up words to maximize phonetic similarity.
In theabsence of known sound correspondences, it can do no more.
Its purpose is to simulatea linguist's first look at unfamiliar data.
Linguistic research is a bootstrapping processin which data leads to analysis and analysis leads to more and better-interpreted data.In its present form, the aligner does not participate in this process.5.
Resul ts  on  Actual  DataTables 3 to 10 show how the aligner performed on 82 cognate pairs in various lan-guages.
(Tables 5-8 are loosely based on the Swadesh word lists of Ringe 1992.)
33 To briefly address Ringe's main point: if the "best" alignment of a pair of words is used, the likelihoodof finding a chance similarity is much higher than when using a fixed, canonical lignment.487Computational Linguistics Volume 22, Number 4Table 3Alignments obtained with test set of Spanish-French ognate pairs.yo : je T y o2otu : tu 'you' t ut f inosotros : nous 'you' n o s o t r o snu .
.
.
.
.
.quign : qui 'who?'
k y e nk i - -qug: quoi 'what?'
k - ekwatodos : tous 'all' t o d o stu - - -unauna : une 'one' (f.sg.)
ti n -dos : deux 'two' d o sd6-tres: troix 'three' t r - e st rwa -hombre : homme 'man' omb r eo i - n  o ?
_These are "difficult" language pairs.
On closely similar languages, such as Span-ish/Ital ian or German/Danish,  the aligner would have performed much better.
Evenso, on Spanish and French---chosen because they are historically close but phonologi-cally very different--the aligner performed almost flawlessly (Tables 3 and 4).
Its onlyclear mistake is that it missed the hr correspondence in arbre : drbol, but so would thelinguist without other data.With English and German it did almost as well (Tables 5 and 6).
The s in thisis aligned with the wrong s in dieses because that alignment gave greater phoneticsimilarity; taking off the inflectional ending would have prevented this mistake.
Thealignments of mouth with Mund and eye with Auge gave the aligner some trouble; ineach case it produced two alternatives, each getting part of the alignment right.English and Latin (Tables 7 and 8) are much harder to pair up, since they areseparated by millennia of phonological and morphological change, including Grimm'sLaw.
Nonetheless, the aligner did reasonably well with them, correctly aligning, forexample, star with stglla and round with rotundus.
In some cases it was just plainwrong, e.g., aligning tooth with the -tis ending of dentis.
In others it was indecisive;although it found the correct alignment of f ish with piscis, it could not distinguish itfrom three alternatives.
In all of these cases, eliminating the inflectional endings wouldhave resulted in correct or nearly correct alignments.488Covington An Algorithm to Align WordsTable 4Alignments obtained with test set of Spanish-French cognate pairs(continued).drbol : arbre 'tree' a r b - o 1arbro -pluma : plume 'feather'cabeza 'head' : cap 'promontory'p lumap lum-kabe0akap- - -boca : bouche 'mouth' b o k abu~ -pie : pied 'foot' P y e pyecorazdn : coeur 'heart' koraOonk6r  .
.
.
.,~p,~, b - e r voir vel" vwa rvenir : venir 'come' b e n i rvon i  rde0 i r  decir : dire 'say' d - - i rpobre : pauvre 'poor' p o b r epovroTable 9 shows that the algorithm works well with non-Indo-European languages,in this case Fox and Menomini cognates chosen more or less randomly from Bloomfield(1941).
Apart  from some minor trouble with the suffix of the first item, the aligner hadsmooth sailing.Finally, Table 10 shows how the aligner fared with some word pairs involvingLatin, Greek, Sanskrit, and Avestan, again without knowledge of morphology.
Becauseit knows nothing about place of articulation or Gr imm's  Law, it cannot tell whetherthe d in  daughter  corresponds with the th or the g in Greek thugat~r.
But on centum :hekaton and centum : satom the aligner performed perfectly.6.
Improving the Alignment AlgorithmThis al ignment algorithm and its evaluation metric are, in effect, a formal reconstruc-tion of something that historical linguists do intuitively.
As such, they provide anempirical test of theories about how historical reconstruction is practiced.There are limits to how well an aligner can perform, given that it knows nothingabout comparat ive reconstruction or regularity of correspondences.
Nonetheless, thepresent algorithm could be improved in several ways.489Computational Linguistics Volume 22, Number 4Table 5Alignments obtained with test set of English-German cognate pairs.this : dieses 6 i - - sd izosthat : das 6 ~e tdaswhat  : was  wa tvasnot : n icht  n a - t n ix tlong : lang 1 o I 3l aom~e nman : Mann manf le -~f lesh : Fleisch f l ay~blood : B lu t  b 1 o db lQt~oa~er : Feder f e 6 ~ rf@dorhair : Haar  h a~ rharOne obvious improvement would be to implement feature-based phonology.
Im-plicitly, the aligner already uses two features, vocalicity and vowel length.
A fullerset of features would have given a better alignment of p isc i s  with f i sh ,  preferring f :pto f : k .
Features are not all of equal importance for the evaluation metric; syllabicity,for instance, will surely be more important han nasality.
Using multivariate statisticaltechniques and a set of known "good" alignments, the relative importance of eachfeature could be calculated.Another improvement would be to enable the aligner to recognize assimilation,metathesis, and even reduplication, and assign lower penalties to them than to arbi-trary mismatches.
The need to do this is one reason for using tree search rather thanthe standard dynamic programming algorithm for inexact string matching.
Dynamicprogramming is, in effect, a breadth-first search of the tree in Figure 1; Ukkonen's(1985) improvement of it is a narrowed breadth-first earch with iterative broadening.Both of these rely on computing parts of the tree first, then stringing partial solutionstogether to get a complete solution (that is what "dynamic programming" means).They do their partial computations in an order that precludes "looking ahead" alongthe string to undo an assimilation, metathesis, or reduplication.
By contrast, my depth-first search algorithm can look ahead without difficulty.490Covington An Algorithm to Align WordsTable 6Alignments obtained with test set of English-German cognate pairs(continued).ear  : Ohr  i roreye  : Auge  a - - y awg0nose  : Nase  n o w z -na-zomouth  : Mund maw - 0m-unttongue : Zunge t - o ~ - t su~ofoot  :Fur l  f u t fOsknee  : Kn ie  - n i y kn i  -hand:Hand hahn dhanthear t  " Herz  h a r t -her tsl i ver  : Leber  1 i v o rl~boray  ~-awgomawO-m-untAnother crucial difference between my algorithm and dynamic programming isthat, by altering the tree pruning criterion, my algorithm can easily generate, not justthe best alignment or those that are tied for the best position, but the n best alignments,or all alignments that are sufficiently close to the best (by any computable criterion).Multilateral alignments are needed when more than two languages are being com-pared at once.
For example,e l -- l oi l -is the etymologically correct hree-way alignment of the masculine singular definitearticle in Spanish, French, and Italian.
Multilateral alignments can be generated byaligning the second word with the first, then the third word with the second (andimplicitly also the first), and so on, but it would be advantageous to apply the eval-uation metric to the whole set rather than just the pairs that are chained together.Multilateral alignment is also an important problem in DNA sequence analysis, andno general algorithm for it is known, but research is proceeding apace (Kececioglu1993, Waterman 1995).491Computational Linguistics Volume 22, Number 4~b le7Mi~mentsobta inedwi th tes tseto fEng l i sh -Latmco~atepa i rs .and : ante  2end-anteat : ad  a~ tadb low : f la re  b 1 - - ow-f la re -ear : aur i s  i -  r - -awr iseat  : edere i y t - - -e-dere- - - f i~f i sh  : p i sc i s  p i s k i sf l ow : f luere  f l ow - - -f l  -uerestar  : ste-lla s t a r - -s t~ l la- - - fu lfu l l  : p l~nus  p 1 ~ n u sgr  - -~esgrass  : g r~men g r amenhear t  : cord is  (gen.) h a r - - tkord ishorn -  horn  : corn?kornO- -ayI : ego  ego -f - - - i~  f i - - -~  f i~- - -p i sk i s  p i sk i s  p i sk i sf - - - u lp lenusgr~- -s  g r~s- -g ramen gramenhar t - -kord is7.
From Here to the Comparat ive  MethodComparat ive  reconstruct ion consists of three essent ia l  steps:.2.3.A l ign  the segments  in the (putat ive)  cognates;F ind cor respondence  sets (cor respond ing  to proto-a l lophones) ;Ident i fy  some cor respondence  sets as phonet ica l ly  cond i t ioned  var iantsof others  ( thereby reconstruct ing proto -phonemes) .492Covington An Algorithm to Align WordsTable 8Alignments obtained with test set of English-Latin cognate pairs(continued).- -n iyknee  : gen~ g e n o -mother  : mater  mo 6 o rmatermawn t o nmounta in  : mGns  mO-n-  - sname : n f fmen n e ym - -nO -mennyuw-  -new : novus  n - owu sw o n  - -one : anus  - f inusround : ro tundus  r a - wn d - -ro tundusS O W -  - -sew : suere  S - u e r es i t  : s~dere s i t - - -s~dereth ree  : tr~s 0 r i yt r~s- - - tuw0 tooth  dent i s  ~'~ ben'/ dent  i - sth in  : tenu is  0 i n - - -tenu i  smawntonmO-ns - -nyuw-nowusKay (1964) noted that the "right" set of alignments (of each of the cognate pairs) isthe set that produces the smallest otal number of sound correspondences.
Steps 1and 2 could therefore be automated by generating all possible alignments of all of thecognate pairs, then choosing the set of alignments that gives the fewest correspondencesets.As Kay notes, this is not practical.
Suppose the putative cognates are each 3 seg-ments long.
There are then 9 different alignments of each cognate pair, and if 100cognate pairs are to be considered, there are 9 l??
~ 2.65 x 1095 sets of alignments tochoose from, far too many to try on even the fastest computer.However, a guided search along the same lines might well be worthwhile.
Firstchoose one alignment for each cognate pair--the best according to the evaluation met-ric, or if several are equally good, choose one arbitrarily.
Construct he entire set ofcorrespondence s ts.
Then go back and try one or two alternative alignments for each493Computational Linguistics Volume 22, Number 4Table 9Alignments obtained with test set of Fox-Menomini cognate pairs.ki inwaawa : kenuaq 'you (pl.)'
k inwawa-  k inwawa-  ken- -uaq  kenu- -aqniina : nenah T n i n a -nenahnaapeewa : naap~,cw 'man'waapimini  : waapemen 'maize'nameesa : narnccqs 'fish in.
)'okimaawa : okeemaaw 'chief'giigiipa : seeqsep 'duck (n.)'ahkohkwa : ahlcceh 'kettle'pemaatesiweni : pemaatesewen 'life'asenya : aqs~n 'stone (n.)'nap~wanapgw-wap imin iwapemen-nam~-sanam~qs-ok imawaok~maw-g i -g ipa  g ig - ipas~qsep-  s~qsep-ahkohkwaahk~h- - -pemates iwen ipematesewen-a -senyaaqscn- -cognate pair, noting whether the size of the set of correspondence s ts decreases.
If so,adopt the new al ignment instead of the previous one.
For a set of 100 cognate pairs,this requires a total of only a few hundred steps, and the result should be close to theoptimal solution.
Reduction of correspondence s ts to proto-phonemes is, of course,a separate task requiring a knowledge base of phonological features and informationabout phonetic plausibility.Appendix: Size of the Search SpaceThe total number  of al ignments of a pair of words of lengths m and n can be calculatedas follows.
4 Recall that a match consumes a segment of both words; a skip consumes a4 For assistance with mathematics here I am greatly indebted to E. Rodney Canfield.
I also want to thankother mathematicians who offered helpful advice, among them John Kececioglu, Jeff Clark, Jan WillemNienhuys, Oscar Lanzi III, Les Reid, and other participants in sci.math on the Internet.494Covington An Algorithm to Align WordsTable 10Alignments obtained with cognate pairs from other languages.Greek did(Ymi : Latin d6 'I give' d idomi- -dO- -Greek thugat?r : German Tochter 'daughter' thutoEnglish daughter : Greek thugat?r 'daughter' thua -Latin ager : Sanskrit ajras 'field' a jgat~rx - to rdotorgat~rgerrasSanskrit bhar~mi : Greek pher6 'I carry'Latin centum : Greek hekaton '100'Latin centum : Avestan satom '100'd idomid - -O- -d - -o torthugat@rag-er  ager - -a j ras  a j - rasdo - - to rthugat@rbharami  bharamipher - -6  phero - -- -kentumheka- tonkentumsa-  tomsegment from one word but not the other.
The complete al ignment has to consume allthe segments of both words.
Accordingly, any al ignment containing k matches mustalso contain m - k skips on the first word and n - k skips on the second word.
Thenumber  of matches k in turn ranges from 0 to min(m, n).
Thus, in general, the numberof possible al ignments ismin(m,n)Alignments(m, n) = Z number  of al ignments containing k matchesk=0Without the no-alternate-skip rule, the number  of al ignments containing k matches issimply the number  of ways of partitioning a set of k + (m - k) + (n - k) = m + n - kmoves into k matches, m - k skips on word 1, and n - k skips on word 2:min(m,n) (m + n - k)!Al ignments(m,n) -- Z k!
(m - k)!
(n - k)!k=0(To give you an idea of the magnitude, this is close to 5n/2 for cases where m -- n andn < 20 or so.
)With the no-alternate-skip rule, the number  of al ignments is exponentially smaller(about 3 n-1 when m = n) and can be calculated from the recurrence relationn-2 m--2a(m,n) = a (m-  1,n -  1) + Za(m-  1,i) + Za( i ,n -  1)i=0 i=0with the initial conditions a(0,n) = a(m,0) = 1; for a derivation of this formula seeCovington and Canfield (in preparation).495Computational Linguistics Volume 22, Number 4ReferencesAnttila, Raimo.
1989.
Historical andComparative Linguistics.
Second revisededition.
Amsterdam Studies in the Theoryand History of Linguistic Science, W:Current Issues in Linguistic Theory, 6.Benjamins, Amsterdam.Bloomfield, Leonard.
1941.
Algonquian.
InC. Osgood, editor, Linguistic Structures ofNative America.
Viking Fund Publicationsin Anthropology, 6.Reprint, JohnsonReprint Corporation, New York, 1963,pages 85-129.Covington, Michael A. and Canfield, E.Rodney.
In preparation.
The number ofdistinct alignments of two strings.Research report, Artificial IntelligenceCenter, The University of Georgia.Frantz, Donald G. 1970.
A PL/1 program toassist he comparative linguist.Communications of the ACM, 13:353-356.Guy, Jacques B. M. 1994.
An algorithm foridentifying cognates in bilingual wordlistsand its applicability to machinetranslation.
Journal of Quan titativeLinguistics, 1:35-42.Hewson, John.
1974.
Comparativereconstruction the computer.
In JohnM.
Anderson and Charles Jones, editors,Historical Linguistics h Syntax, Morphology,Internal and Comparative Reconstruction.North Holland, Amsterdam, pages191-197.Kay, Martin.
1964.
The logic of cognaterecognition i  historical linguistics.Memorandum RM-4224-PR.
The RANDCorporation, Santa Monica.Kececioglu, John.
1993.
The maximumweight trace problem in multiplesequence alignment.
In A. Apostolico etal., editors, Combinatorial Pattern Matching:4th Annual Symposium, Springer, Berlin,pages 106-119.Lowe, John B. and Martine Mazaudon.1994.
The reconstruction e gine: Acomputer implementation f thecomparative method.
ComputationalLinguistics, 20:381-417.Ringe, Donald A., Jr. 1992.
On Calculating theFactor of Chance in Language Comparison.American Philosophical Society,Philadelphia.Sankoff, David and Joseph B. Kruskal,editors.
1983.
Time Warps, String Edits, andMacromolecules: The Theory and Practice ofSequence Comparison.
Addison-Wesley,Reading, MA.Ukkonen, Esko.
1985.
Algorithms forapproximate string matching.
Informationand Control, 64:100-118.Waterman, Michael S. 1995.
Introduction toComputational Biology: Maps, Sequences andGenomes.
Chapman & Hall, London.Wimbish, John S. 1989.
WORDSURV: Aprogram for analyzing language surveyword lists.
Summer Institute ofLinguistics, Dallas.
Cited by Lowe andMazaudon.
1994.496
