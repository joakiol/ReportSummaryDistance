Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 54?61,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsWishful ThinkingFinding suggestions and ?buy?
wishes from product reviewsJ.
Ramanand Krishna Bhavsar Niranjan PedanekarBFS Innovations  BFS Innovations  BFS InnovationsCognizant Technology Solutions Cognizant Technology Solutions Cognizant Technology SolutionsPune, India Pune, India Pune, Indiaramanand.janardhanan@cognizant.comkrishna.bhavsar@cognizant.comniranjan.pedanekar@cognizant.comAbstractThis paper describes methods aimed at solv-ing the novel problem of automatically dis-covering ?wishes?
from (English) documentssuch as reviews or customer surveys.
Thesewishes are sentences in which authors makesuggestions (especially for improvements)about a product or service or show intentionsto purchase a product or service.
Such?wishes?
are of great use to product managersand sales personnel, and supplement the areaof sentiment analysis by providing insightsinto the minds of consumers.
We describerules that can help detect these ?wishes?
fromtext.
We evaluate these methods on texts fromthe electronic and banking industries.1 IntroductionVarious products and business services are used bymillions of customers each day.
For the makers ofthese products & services, studying these customerexperiences is critical to understanding customersatisfaction and making decisions about possibleimprovements to the products.
Thanks to the ad-vent of weblogs, online consumer forums, andproduct comparison sites, consumers are activelyexpressing their opinions online.
Most of thesereviews are now available on the web, usually atlittle or no cost.
Moreover, these are available for avariety of domains, such as financial services, tele-com services, consumer goods etc.Automated analysis of opinions using such re-views could provide a cheaper and faster means ofobtaining a sense of such customer opinions, thussupplementing more traditional survey methods.
Inaddition, automated analysis can significantlyshorten the time taken to find insights into the cus-tomer's mind and actions.Sentiment analysis of texts such as product re-views, call center notes, and customer surveysaims to automatically infer opinions expressed bypeople with regards to various topics of interest.
Asentiment analysis exercise classifies the overallopinion of a review document into positive, neu-tral, or negative classes.
It may also identify senti-ments at a finer granularity, i.e.
recognizing themix of opinions about the topic(s) expressed in thetext.
However, industry analysts (Strickland, 2009)report some common problems with the results ofthese exercises:1.
The results (usually numerical scores splitacross positive, negative, neutral classes) are hardto meaningfully interpret.2.
These results are more useful to certainroles and domains.
Brand, reputation, and servicemanagers in media and retail industries find senti-ment analysis more useful than product managersor sales teams in various industries.3.
The results do not ?indicate user action?i.e.
opinions do not help identify a future action ofthe author based on the comments.
An example ofthis is: does the consumer indicate that he intendsto stop using a service after a negative experience?4.
The reader of the report often asks ?whatdo I do next??
i.e.
the results are not always ?ac-tionable?.
There is a gap between understandingthe results and taking an appropriate action.54This has led to interest in identifying aspects in-directly related to sentiment analysis, such as gaug-ing possible loss of clientele or tapping into desiresto purchase a product.
Many of these methods at-tempt to identify ?user intent?.In this paper, we propose rule-based methods toidentify two kinds of ?wishes?
?
one, the desire tosee improvement in a product, and the other topurchase a product.
These methods have been de-signed & tested using a variety of corpora contain-ing product reviews, customer surveys, andcomments from consumer forums in domains suchas electronics and retail banking.
From our read-ing, there has been only one published account ofidentifying ?wishes?
(including suggestions) and noknown work on identifying purchasing wishes.
Wehope to build approaches towards more compre-hensive identification of such content.The paper is organized as follows.
We begin bydiscussing some of the work related to this upcom-ing area.
Section 3 details our characterization ofwishes.
Section 4 describes the corpora used forthese methods.
We discuss our proposed algo-rithms and rules in Sections 5 & 6, including a dis-cussion of the results.
Finally, we wrap up with ourconclusions and directions for future work.2 Related WorkThe principal context of our work is in the areaof sentiment analysis, which is now a widely re-searched area because of the abundance of com-mentaries from weblogs, review sites, and socialnetworking sites.
In particular, we are interested inthe analysis of product reviews (Dave et al, 2003;Hu and Liu, 2004), as well as its application tomore service-oriented industries such as banks.We have built a sentiment analyzer that can ana-lyze product and service reviews from a variety ofdomains.
This also accepts social networkingcommentaries, customer surveys and news articles.The implementation follows a lexicon-based ap-proach, similar to the one described in Ding et al(2008), using lexicons for product attributes andopinion words for basic sentiment analysis.Our work is not a sub-task of sentiment analysis,but supplements the area.
A similar example of aclassification task that works on the sentence leveland is also related to sentiment analysis is Jindaland Liu (2006) which aims to identify comparisonsbetween two entities in texts such as product re-views.Goldberg et al (2009) introduced the novel taskof identifying wishes.
This used a ?WISH?
corpusderived from a web site that collected New Year?swishes.
Goldberg et al (2009) studied the corpusin detail, describing the nature, geography, andscope of topics found in them.
The paper alsolooked at building ?wish detectors?, which wereapplied on a corpus of political comments andproduct reviews.
A mix of manual templates andSVM-based text classifiers were used.
A method toidentify more templates was also discussed.Our task, though similar to the above problem,has some novel features.
In particular, there aretwo significant differences from Goldberg et al(2009).
We are interested in two specific kinds ofwishes: sentences that make suggestions about ex-isting products, and sentences that indicate thewriter is interested in purchasing a product.
(Theseare described in detail in Section 3.)
Secondly, ourinterest is limited to product reviews, and not tosocial or political wishes.In Requirements Engineering, some methods ofanalyzing requirement documents have used lin-guistic techniques to understand and correlate re-quirements.
These are somewhat related to ourtask, aiming to detect desired features in the pro-ject to be executed.
och Dag et al (2005) has someuseful discussions on this topic.Kr?ll and Strohmaier (2009) study the idea ofIntent Analysis, noting a taxonomy of Human In-tentions, which could be useful in future discus-sions on the topic.3 What are Wishes3.1 Defining WishesA dictionary definition (Goldberg et al (2009)) ofa ?wish?
is ?a desire or hope for something tohappen.?
Goldberg et al (2009) discuss differenttypes of wishes, ranging from political to social tobusiness.
In our case, we limit our interest tocomments about products and services.
In particu-lar, we are interested in two specific kinds of wish-es.553.2 Suggestion WishesThese are sentences where the commenter wishesfor a change in an existing product or service.These range from specific requests for new productfeatures and changes in existing behaviour, or anindication that the user is unhappy with the currentexperience.
Examples1:1.
I'd love for the iPod shuffle to also mirroras a pedometer.2.
It would be much better if they had moreATMs in my area.We also include sentences that do not fullyelaborate on the required change, but could serveas a pointer to a nearby region that may contain therequired desire.
Examples of these:1.
I wish they?d do this.2.
My wish list would be as follows:It is important to note the difference betweenour definition of wishes and that in Goldberg et al(2009).
That study seeks to discover any sentenceexpressing any desire.
For instance, Goldberg et al(2009) marks the following as wishes:1.
I shouldn?t have been cheap, should havebought a Toshiba.2.
hope to get my refund in a timely manner.In our approach, we do not treat these as wishessince they do not suggest any improvements.In some cases, improvements could be inferredfrom a negative opinion about the product.
Theimplication is that the customer would be happierif the problem could be fixed.
Examples:1.
?My only gripe is the small size of thecamera body?
which implies ?I wish thecamera was bigger?.2.
?The rubber flap that covers the usb portseems flimsy?
which implies ?I wish therubber flap was more robust?.We do not address such implicit wishes.3.3 Purchasing WishesThese are sentences where the author explicitlyexpresses the desire to purchase a product.
In somecases, a preferred price range is also indicated.Examples:1All sentences are taken from review sites such as epin-ions.com1.
I have a Canon digital rebel xt, I am look-ing for a lens that will take sports actions foot-ball shots at night.2.
I want to purchase a cell phone range 12-15000/-... please suggest me some good andstylish phones?3.
We are also thinking of buying a condo ina few months?4 Corpora for Design and Evaluation4.1 Suggestion WishesAs part of building and testing our in-house senti-ment analyzer, we collected a variety of texts fromdifferent sources such as popular consumer reviewsites (such as Epinions.com and MouthShut.com)and weblogs.
These primarily belonged to the do-mains of electronics and retail banking.
Of these,we chose reviews about the Apple iPod and a col-lection of banking reviews about five leading USbanks.
We also used customer surveys conductedfor two products of a financial services company2.The sizes of the corpora are summarized in Table1.Some observations about these texts:1.
The texts are in American or British Englishand are largely well-formed.2.
They cover both reviews of products and de-scriptions of customer service.3.
The customer surveys consisted of sectionsfor positives and negatives feedback, with an op-tional ?suggestions?
section.4.
Wish sentences in the reviews were infre-quent (on average, less than 1% of the total sen-tences).
The surveys had a much larger presence ofwishes (about 5% on average).In addition, Goldberg et al (2009) has madeavailable a WISH corpus, which is a sample of7614 sentences consisting of sentences from politi-cal discussions and product reviews.
Since we areonly interested in the latter, we evaluated our algo-rithm only on the product review sentences (1235in number).
3% (41 sentences3) of these have beenlabeled as wishes.2Anonymous for confidentiality reasons3In the WISH corpus, 149 (12%) are marked as wishes; how-ever we only chose those wishes that suggest improvements.56In a pre-processing step, individual sentences inthe corpora were identified using GATE?s (Cun-ningham, 2002) sentence splitter.4.2 Purchasing WishesSimilar to our collection of sentences for sugges-tions, we collected texts from review sites and con-sumer forums (such as Alibaba.com and Yahoo!Answers) that not only reviewed products andshared complaints but also allowed users to postrequests for purchases.The corpus consisted of 1579 sentences aboutthe following products: Apple iPhone, Cameras,Desktop PCs, and a mix of Credit Cards from fourleading Indian and American banks.5 Finding Suggestions5.1 ApproachThe input to our system consists of the following:1.
Datasets containing sentences.2.
ATTRLEX4: A lexicon of product attributesfor each of the domains.
(e.g.
the iPod attributeswere words like ?battery?, ?interface?
etc.)3.
POSLEX: A lexicon of positive opinions(words such as ?good?, ?better?, ?fast?).4.
NEGLEX: A lexicon of negation words (theseare words that invert the opinion of a sentence.e.g: ?not?, ?wouldn?t?
)We began by manually classifying sentences insamples from each of the corpora as ?wishes?
or?non-wishes?.
We then looked for common phrasesand words across all these wishes to derive patternsand rules.Initial analysis led to some proto-rules.
Theserules were then refined by using further analysisand in some cases, decision trees.
The rules aregrouped as follows.5.1.1 Rules based on modal verbsA majority of the wishes had pivotal phrases in-volving modal verbs such as ?would?, ?could?,?should?
etc.
Examples:4These lexicons were built by semi-automated means usingcomponents built for our in-house sentiment analyzer whichhelp detect opinions and attributes for a domain from relatedtexts1.
It would be a much more valuable service if theywould fix this flaw.2.
It might be nice if one could drag-and-drop mu-sic files and have the iPod reconstruct its index on-the-fly.3.
I would prefer the unit to have a simple on offswitch.This led to the following rules:a. modal verb + auxiliary verb + positive opinionwordMatch sentences which contain the pattern:<modal verb> <auxiliary verb> {window of size 3}<positive opinion word>WhereModal verb belongs to {may, might, could,would, will, should}Auxiliary verb belongs to {be, have been}Positive Opinion word belongs toPOSLEXThe positive word should appear to the right of themodal verb in a pre-defined window size (usually 3to 5).b.
modal verb + preference verbMatch sentences which contain the pattern:<modal verb> {window of size 3} <preference verb>WhereModal verb belongs to {may, might, would,will}Preference verb belongs to {love, like, pre-fer, suggest}c. Other rulesMatch sentences containing:?should be able?
or?should come with?
or?could come with?5.1.2 The ?needs to?
ruleSentences containing the phrase ?needs to?
arecandidate wishes, such as in the examples:1.
Apple needs to step it up and get better longerlasting batteries.2.
Their customer service representatives need tobe educated in assisting customers.3.
need to be able to configure the boxes.57For this pattern, we created a decision tree modelwith the following features:1.
Presence of negation word to the left of ?needsto?2.
Presence of a ?product attribute?
word to the left3.
Whether the sentence is interrogative4.
Subject of the sentence from the list: {I, you, s/he,we, this, that, those, it, they, one, someone, somebody,something}Based on analysis and the combination suggestedby the decision tree experiments, we formulatedrules.
Some of these rules are as follows:1.
Interrogative sentences or those with a negationword to the left of ?need to?
are not wishes.2.
If the product attribute is present (usually as thesubject), the sentence is a wish.3.
If the subject of the sentence is one of ?this, that,these?, the sentence is likely to be a wish.
When thesubject is one of ?I, you, one?, the sentence is not awish.5.1.3 Other rulesSentences containing the patterns:1.
?I wish?
: along with filters such as the subject(?they, you, product?)
etc.
can be matched aswishes.2.
?hopefully?
or ?I hope?3.
?should be able to?
or ?should come with?These rules match very infrequently in the dataset.A summary of rule accuracy can be seen in Table3.5.2 Results5.2.1 Precision of RulesTypeTotalsen-tencesNo.
ofpredictedwishesNo.
ofcorrectwishesPrecisioniPod 21147 90 53 58.89%Banking 15408 75 23 30.67%Product 1 4240 224 187 83.48%Product 2 6850 355 284 80.00%WISHcorpus 1236 28 16 57.14%Table 1 Precision of wish identification for various datasets5.2.2 Recall of RulesRecall was calculated on a 10% random samplefrom each data set, except in case of the WISHcorpus, where all sentences were taken into ac-count.TypeNo.
ofcorrectlypredictedwishes inthe sampleNo.
of actualwishes in thesampleRecalliPod 7 14 50.0%Banking 3 5 60.0%Product 1 24 45 53.3%Product 2 28 70 40.0%WISH corpus 16 41 39.0%Table 2 Recall of wish identification5.2.3 Rule AnalysisThis table analyses performance of the top 3 most fre-quently matched rules.
For each type of data, the firstrow shows the number of wishes predicted by each rule.The succeeding row shows the corresponding precision.Type/Rule Modal, aux, positive opinionModal,preference?Needsto?
OthersiPod 24  8 7  1457% 53% 43% 82%Banking 14  17 7  237% 85.0% 50% 28.5%Product 1 89 56 25 1787%  83.6%  71%  85%Product 2 146  25 50 3090% 71.4% 71% 90.9%WISHCorpus 7 2 3 463.6% 50% 50% 57.1%Table 3 Rule Analysis5.3 Comments on ResultsWishes occur very infrequently in reviews, whereauthors may or may not choose to talk about im-provements.
Surveys produced more wishes be-cause of the design and objectives of the survey.Also, the language used in suggesting improve-ments was more consistent across authors, makingit easier to catch them.
Wishes could be madeabout existing product attributes, but several wish-58wishes were about newer aspects.
This could helpproduct managers envisage features that their cus-tomers are asking for.Experiments on the banking reviews showed theworst results.
The dataset had very few wishes andthe language used was usually part of a narrative,which threw up a lot of false positives.
It couldalso be that the nature of the collected dataset wassuch that it did not contain sufficient number ofwishes.Some of the false positives were difficult toavoid.
Take an example such as:I wish it will be a better year.Though it is a ?wish?
in general, this does not fitour definition of product suggestion though it fits arule well.
More semantic or contextual analysismay be required in this case.
We do not filter outsentences that do not refer to already publishedproduct attributes since authors may be talkingabout adding completely new features, such as inthe case:I wish it will be in magazine form next year.Of the rules, the first rule (modal + auxiliary +positive opinion word) had the highest contributionto make.
The second rule was more consistent indetecting correct wishes.
Incidentally, the ?needsto?
rule for banking reviews outperforms the re-sults for iPod sentences ?
the only time this hap-pens.Different patterns may be applicable for differ-ent domains and types of texts.
A possible ap-proach to improving results would be to have a?rule selection?
phase were rules that fall below acertain threshold are discarded.6 Finding Buy Wishes6.1 ApproachSimilar to finding suggestions, we assembled acorpus of sentences for various products and ser-vices, this time from forums that also contain buy-sell sections.
These may contain comments like:1.
I am trying to find where I can purchase the com-plete 1st season of Army Wives-can you help me?2.
I am seriously looking for a new bank...3.
I want to give a new year?s present to my 5 year oldnephew.
My budget is 1500 Rupees.We derived proto-rules and refined them bymanual analysis and decision trees.
The pattern ofeach rule is:?<rule phrase> <common sub-rule>?If a sentence contains such a pattern, it isdeemed to be a buy wish.To begin, we describe a common sub-rule that isused with all rules.6.1.1 Buy Identification common sub-ruleThis depends on the following three aspects:a.
A ?buy verb?
from among {find, buy, purchase,get, acquire} should be presentb.
Absence of a negation word (from NEGLEX)to the left of rule phrasec.
Subjects:The subject should not be one of these:{you, one, they, someone, those}The subject could be one of these:{I, we, me}6.1.2 Rule phrasesRule phrases are one of the following1.
?want to?2.
?desire to?3.
?would like to?4.
?where can/do I?5.
?place to?6.
?going to?7.
?looking to/for?8.
?searching to/for?9.
?interested in?Of these, in rules involving phrases 7, 8, and 9, wealso check if there are any past tense verbs preced-ing rule phrase.
In such cases, we do not classifythe sentence as a wish.
For phrase 5, interrogativesentences are also ignored.6.2 Results6.2.1 PrecisionTypeTotalsen-tencesNo.
ofpredictedwishesNo.
ofcorrectwishesPrecisioniPhone 193 43 41 95.34%iPod 176 48 37 79.54%CreditCards 865 6 4 66.67%59CanonCameras 170 40 39 97.50%DesktopPCs 175 36 34 94.44%Table 4 Precision of wish identification for various datasets6.2.2 Recall5TypeNo.
of ex-pectedwishesNo.
of cor-rectly pre-dicted wishesRecalliPhone 80 41 51.25%iPod 54 37 68.51%CanonCamera 65 39 60.00%DesktopPCs 66 34 51.52%Table 5 Recall of wish identification6.2.3 Rule AnalysisThis table analyses the precision of the tope three rulesthat matched the most sentences.RulePhraseNo.
ofmatchedsentencesNo.
of cor-rect matches PrecisionLookingfor 98 85 86.73%Want to 24 22 91.67%InterestedIn 6 6 100%Table 6 Rule Analysis6.3 Comments on ResultsBuy wishes tend to occur only in forums wherebuyers can advertise their search and hope to re-ceive advice or meet prospective sellers.
In addi-tion to sites dedicated to specific products, socialnetworks such as Twitter6 also provide such a plat-form.
This is in contrast to regular weblogs.The results for all the electronic productsshowed a precision of about 80% or more.
As inthe case of suggestion wishes, wishes were veryrare in the credit cards postings.The recall in all cases was above 50%.
Buy wishsentences matching The ?looking for?
and ?wantto buy/purchase?
rules were common.
An observa-tion was that in some cases, people would simply5The credit cards set had very few actual wishes (less than 10)with which to carry out a meaningful recall exercise6http://twitter.comlist the expected attributes of the product they werelooking for.
Because of the nature of the forum,other users would interpret it as a buy/sell request.We could not separate these sentences from otherkinds of sentences in the data set.In most cases, the sentences were terse and usedphrases like ?we need?
and ?seeking?.
Furtherexpanding the rule phrases & sub-phrases to in-clude their synonyms is likely to improve recall.7 Conclusions and Future WorkThis paper described two novel problems in theworld of opinion and intention mining, that ofidentifying ?wishes?
relating to improvements inproducts and for purchasing them.
These are likelyto be directly useful to business users.
We buildapproaches towards such detections, by the use ofEnglish-language patterns.
To the best of ourknowledge, this is the first attempt at solving suchproblems.The approach for identifying suggestions worksbest for texts that contain explicit wishes, espe-cially customer surveys.
They work reasonablywell for (electronic) product reviews.
In contrast,reviews about banking services tend to containnarratives and have more implicit opinions andwishes.
Similarly, the algorithm to detect buywishes works well for electronic product reviewsin comparison to banking products.Wish statements appear very infrequently in re-views.
Existing sentiment analysis corpora may notbe sufficient to use in creating wish detectors.Augmenting corpora such as the WISH dataset orcreating even more robust and representative cor-pora would be a must for such exercises.
A possi-ble source could be the ?Make A Wish?foundation.One of the possible future directions could be tolook at tense and mood analysis of sentences.
Wishsentences come under the ?optative?
mood.
Tech-niques that help identify such a mood could pro-vide additional hints to the nature of the sentence.More features related to parts of speech and se-mantic roles could be explored.We also plan to look at machine learning ap-proaches, but the availability of good quality train-ing data is a limiting factor.The emergence of social networking sites mayprovide more challenges for such detectors.
Siteslike Twitter are already being used to advertise60intentions to buy or sell.
However, the nature ofdiscourse in these media is markedly different toregular reviews and forums due to size restrictions.Any system that helps business users to identifynew customers or engage with existing ones wouldneed to tap into all these emerging channels.
Theneed for such detectors is likely to increase in thefuture, thus providing further motivation to studythis nascent area.ReferencesHamish Cunningham, Diana Maynard, KalinaBontcheva, and Tablan, Valentin.
GATE: A frame-work and graphical development environment for ro-bust NLP tools and applications.
2002Kushal Dave, Steve Lawrence, and David M. Pennock.Mining the peanut gallery: Opinion extraction andsemantic classification of product reviews.
Proceed-ings of the 12th international conference on WorldWide Web.
2003.Minqing Hu and Bing Liu.
Mining and summarizingcustomer reviews.
Proceedings of the tenth ACMSIGKDD international conference on Knowledgediscovery and data mining.
2004.Andrew B. Goldberg, Nathanael Fillmore, DavidAndrzejewski, Zhiting Xu, Z, Bryan Gibson, andXiaojin Zhu.
May all your wishes come true: A studyof wishes and how to recognize them.
Proceedings ofHuman Language Technologies: The 2009 AnnualConference of the North American Chapter of theAssociation for Computational Linguistics.
2009.Nitin Jindal and Bing Liu.
Identifying comparative sen-tences in text documents.
Proceedings of the 29th an-nual international ACM SIGIR conference onResearch and development in information retrieval.2006.Mark Kr?ll and Markus Strohmaier, M. Analyzing hu-man intentions in natural language text.
Proceedingsof the fifth international conference on Knowledgecapture.
2009.Johan Natt och Dag, Vincenzo Gervasi, Sjaak Brink-kemper, and Bj?rn Regnell, B.
A linguistic engineer-ing approach to large-scale requirementsmanagement.
Managing Natural Language Require-ments in Large-Scale Software Development.
Vol22-1.
2005.Marta Strickland.
Five Reasons Sentiment AnalysisWon?t Ever Be Enough.http://threeminds.organic.com/2009/09/five_reasons_sentiment_analysi.html.
2009.Xiaowen Ding, Bing Liu, and Philip S.Yu.
A holisticlexicon-based approach to opinion mining.
Proceed-ings of the international conference on Web searchand web data mining.
2008.61
