Prepos i t iona l  Phrase At tachment  through a Backed-Off  Mode lMichael Collins and James BrooksDepartment of Computer and Information ScienceUniversity of PennsylvaniaPhiladelphia, PA 19104{mcollins, jbrooks} @gradient.cis.upenn.eduAbstractRecent work has considered corpus-based or statistical approaches to the problem of prepositionalphrase attachment ambiguity.
Typically, ambiguous verb phrases of the form v rip1 p rip2 areresolved through a model which considers values of the four head words (v, nl ,  p and 77,2).
Thispaper shows that the problem is analogous to n-gram language models in speech recognition,and that one of the most common methods for language modeling, the backed-off estimate, isapplicable.
Results on Wall Street Journal data of 84.5% accuracy are obtained using this method.A surprising result is the importance of low-count events - ignoring events which occur less than 5times in training data reduces performance to 81.6%.1 Int roduct ionPrepositional phrase attachment is a common cause of structural ambiguity in natural anguage.For example take the following sentence:Pierre Vinken, 61 years old, joined the board as a nonexecutive director.The PP 'as a nonexecutive director' can either attach to the NP 'the board' or to the VP 'joined',giving two alternative structures.
(In this case the VP attachment is correct):NP-attach: (joined ((the board) (as a nonexecutive director)))VP-attach: ((joined (the board)) (as a nonexecutive director))Work by Ratnaparkhi, Reynar and Roukos \[RRR94\] and Brill and Resnik \[BR94\] has consideredcorpus-based approaches to this problem, using a set of examples to train a model which is thenused to make attachment decisions on test data.
Both papers describe methods which look at thefour head words involved in the attachment - the VP head, the first NP head, the preposition andthe second NP head (in this case joined, board, as and director respectively).This paper proposes a new statistical method for PP-attachment disambiguation based on the fourhead words.2"72 Background2.1 Tra in ing  and  Test  DataThe training and test data were supplied by IBM, being identical to that used in \[RRR94\].
Examplesof verb phrases eontMning a (v np pp) sequence had been taken fl'om the Wall Street JournalTreebank \[MSM93\].
For each such VP the head verb, first head noun, preposition and second headnoun were extracted, along with the attachment decision (1 for noun attachment, 0 for verb).
Forexample the verb phrase:((joined (the board)) (as a nonexecutive director))would give the quintuple:0 joined board as directorThe elements of this quintuple will from here on be referred to as the random variables A, V, N1,P, and N2.
In the above verb phrase A = 0, V = j o ined ,  N1  = board,  P = as,  and N2 = d i rec tor .The data consisted of training and test files of 20801 and 3097 quintuples respectively.
In addition,a development set of 4039 quintuples was also supplied.
This set was used during development ofthe attachment algorithm, ensuring that there was no implicit training of the method on the testset itself.2.2 Out l ine  o f  the  Prob lemA PP-attachment algorithm must take each quadruple (V = v, N1 = n l ,  P = p, N2  = n2)  in testdata and decide whether the attachment variable A = 0 or 1.
The accuracy of the algorithm isthen the percentage of attachments it gets 'correct' on test data, using the A values taken from thetreebank as the reference set.The probability of the attachment variable A being 1 or 0 (signifying noun or verb attachmentrespectively) is a probability, p, which is conditional on the values of the words in the quadruple.In general a probabilistic algorithm will make an estimate, 15, of this probability:15(A= l lV=v,  N l=n l ,  P=p,  N2=n2)For brevity this estimate will be referred to from here on as:p(l\[v, n l ,p ,  n2)28The decision can then be made using the test:~(llv, nl,p, n2 ) >= 0.5If this is true the attachment is made to the noun, !f not then it is made to the verb.2.3 Lower  and  Upper  Bounds  on  Per fo rmanceWhen evaluating an algorithm it is useful to have an idea of the lower and upper bounds on itsperformance.
Some key results are summarised in the table below.
All results in this section areon the IBM training and test data, with the exception of the two 'average human' results.Method Percentage AccuracyAlways noun attachment 59.0Most likely for each preposition 72.2Average Human (4 head words only) 88.2Average Human (whole sentence) 93.2'Always noun attachment' means attach to the noun regardless of (v,nl,p,n2).
'Most likely for eachpreposition' means use the attachment seen most often in training data for the preposition seen inthe test quadruple.
The human performance results are taken from \[RRR94\], and are the averageperformance of 3 treebanking experts on a set of 300 randomly selected test events from the WSJcorpus, first looking at the four head words alone, then using the whole sentence.A reasonable lower bound seems to be 72.2% as scored by the 'Most likely for each preposition'method.
An approximate upper bound is 88.2% - it seems unreasonable to expect an algorithm toperform much better than a human.3 Es t imat ion  based  on Tra in ing  Data  Counts3.1 Notat ionWe will use the symbol f to denote the number of times a particular tuple is seen in train-ing data.
For example f(1, is, revenue, from, research) is the number of times the quadruple(is, revenue, from, research) is seen with a noun attachment.
Counts of lower order tuples can alsobe made-  for example f(1, P = from) is the number of times (P = from) is seen with noun attach-ment in training data, f (V  = is, N2 = research) is the number of times (V = is, N2 = research)is seen with either attachment and any value of N1 and P.293.2 Max imum L ike l ihood  Es t imat ionA maximum likelihood method would use the training data to give the following estimation for theconditional probability:l~(l\[v, nl,p, n2)= f(1,v, nl,p, n2)f(v, nl, p, n2)Unfortunately sparse data problems make this estimate useless.
A quadruple may appear in testdata which has never been seen in training data.
ie.
f(v, nl,p, n2) = 0.
The above estimate isundefined in this situation, which happens extremely frequently in a large vocabulary domain suchas WSJ.
(In this experiment about 95% of those quadruples appearing in test data had not beenseen in training data).Even if f(v, nl,p, n2) > 0, it may still be very low, and this may make the above MLE estimate in-accurate.
Unsmoothed MLE estimates based on low counts are notoriously bad in similar problemssuch as n-gram language modeling \[GC90\].
However later in this paper it is shown that estimatesbased on low counts are surprisingly useful in the PP-attachment problem.3.3 P rev ious  WorkHindle and Rooth \[HR93\] describe one of the first statistical approaches to the prepositional phraseattachment problem.
Over 200,000 (v, nl,p) triples were extracted from 13 million words of APnews stories.
The attachment decisions for these triples were unknown, so an unsupervised trainingmethod was used (section 5.2 describes the algorithm in more detail).
Two human judges annotatedthe attachment decision for 880 test examples, and the method performed at 80% accuracy on thesecases.
Note that it is difficult to compare this result to results on Wall Street Journal, as the twocorpora may be quite different.The Wall Street Journal Treebank \[MSM93\] enabled both \[RRR94\] and \[BR94\] to extract a largeamount of supervised training material for the problem.
Both of these methods consider the secondnoun, n2, as well as v, n l  and p, with the hope that this additional information will improve results.\[BR94\] use 12,000 training and 500 test examples.
A greedy search is used to learn a sequenceof 'transformations' which minimise the error rate on training data.
A transformation is a rulewhich makes an attachment decision depending on up to 3 elements of the (v, nl,p, n2) quadruple.
(Typical examples would be 'If P=ofthen choose noun attachment' or 'If V=buy and P=for chooseverb attachment').
A further experiment incorporated word-class information from WordNet intothe model, by allowing the transformations to look at classes as well as the words.
(An examplewould be 'If N2 is in the time semantic class, choose verb attachment').
The method gave 80.8%accuracy with words only, 81.8% with words and semantic lasses, and they also report an accuracyof 75.8% for the metric of \[HR93\] on this data.
Transformations (using words only) score 81.9% 1on the IBM data used in this paper.1Personal communication from Brill.30\[RRR94\] use the data described in section 2.1 of this paper - 20801 training and 3097 test examplesfrom Wall Street Journal.
They use a maximum entropy model which also considers ubsets of thequadruple.
Each sub-tuple predicts noun or verb attachment with a weight indicating its strengthof prediction - the weights are trained to maximise the likelihood of training data.
For example(P = of)  might have a strong weight for noun attachment, while (V = buy, P = for )  would havea strong weight for verb attachment.
\[RRR94\] also allow the model to look a.t class inlbrmation,this time the classes were learned automatically from a corpus.
Results of 77.7% (words only) and81.6% (words and classes) are reported.
Crucially they ignore low-count events in training data byimposing a frequency cut-off somewhere between 3 and 5.4 The  Backed-Of f  Es t imate\[KATZ87\] describes backed-off n-gram word models for speech recognition.
There the task is toestimate the probability of the next word in a text given the (n-l) preceding words.
The MLEestimate of this probability would be:f (Wl,W2 .
.
.
.
Wn)p(WnlWl, W2 .... Wn-1) = f'~li~U2....~Vn_l)But again the denominator f (Wl ,  W2 .... Wn_ l )  will frequently be zero, especially for large n. Thebacked-off estimate is a method of combating the sparse data problem.
It is defined recursively asfollows:If f (w l ,  w2 .... Wn-1) > Clf (Wl ,  W2 .... ten)/5(W~lWl,W2 .... W~-l) = S-~l;tV2...~W~-l)Else if f (w2,  w3 .... Wn-1)  > C2P(WnIWl,W2 .
.
.
.
Wn--1) = ~1 XElse if f (w3,  w4 .... Wn--1) > C3iG (w~lwl ,w2 .... W~- l )  = a l  X as XElse backing-off continues in the same way.f (w2, w3 .... Wn)f (w~, W 3 .... Wn-1 )f (w3 ,  W4 .... ten)f(w3, w4 .... w~_~)The idea here is to use MLE estimates based on lower order n-grams if counts are not high enoughto make an accurate stimate at the current level.
The cut off frequencies (O, c2 .... ) are thresholds31determining whether to back-off or not at each level - counts lower than ci at stage i are deemedto be too low to give an accurate stimate, so in this case backing-off continues.
(~1, ~2, .... ) arenormalisation constants which ensure that conditional probabilities um to one.Note that the estimation of 15(wn\[w~, w2 .... Wn-1) is analogous to the estimation of 15(1\]v, nl ,  p, n2),and the above method can therefore also be applied to the PP-attachment problem.
For example asimple method for estimation of 15(1\[v, nl,p, n2) would go from MLE estimates ofiS(llv, nl,p, n2) to~5(11v , nl,p) to ~5(1\[v, nl)  to 15(1\[v) to 15(1).
However a crucial difference between the two problems isthat in the n-gram task the words Wl to wn are sequentiM, giving a natural order in which backingoff takes place - from p(Wn\[Wl, W 2 .
.
.
.
Wn_l) to 15(WnIW2, W3 .... Wn-1) to 15(W~\[W3, W4 .... Wn_l) and soon.
There is no such sequence in the PP-attachment problem, and because of this there are fourpossible triples when backing off from quadruples ((v, nl,p), (v,p, n2), (n l ,p ,  n2) and (v, nl ,  n2))and six possible pairs when backing off from triples ((v,p), (n l ,p) ,  (p, n2), (v, n l) ,  (v, n2) andA key observation i  choosing between these tuples is that the preposition is particularly importantto the attachment decision.
For this reason only tuples which contained the preposition were usedin backed off estimates - this reduces the problem to a choice between 3 triples and 3 pairs ateach respective stage.
Section 6.2 describes experiments which show that tuples containing thepreposition are much better indicators of attachment.The following method of combining the counts was found to work best in practice:15t,ipl~(11v , nl,p, n2) = f(1, v, nl,p) + f(1, v,p, n2) + f(1, nl,p, n2)f(v, nl ,p)  + f(v,p, n2) + f(nl ,p,  n2)andiSp~ir(l\[v, nl,p, n2) = f(1, v,p) + f(1, nl,p) + f(1,p, n2)f(v,p) + f(nl ,p) + f(p, n2)Note that this method effectively gives more weight to tuples with high overall counts.
Anotherobvious method of combination, a simple average 2,gives equal weight to the three tuples regardlessof their total counts and does not perform as well.The cut-off frequencies must then be chosen.
A surprising difference fi'om language modeling isthat a cut-off frequency of 0 is found to be optimum at all stages.
This effectively means howeverlow a count is, still use it rather than backing off a level.2eg.
A simple average for triples would be defined asf(1 ..... 1,p) f(1,v,p,n2) f(1,nl,p,n2)15t,.ipee(l\[v, nl ,p,  n2)= f(v,nl,p) --k f(v,v,n2) "-I- f(nl,p,~2)3324.1 Descr ip t ion  of  the  A lgor i thmThe algorithm is then as follows:1.
I f  3 f(v, nl,p, n2) > 0l~(llv, nl,p, n2)= f(1,v, nl,p, n2)f(v, nl, p, n2)2.
Else if f(v, nl,p) + f(v,p, n2) + f(nl ,p, n2) > 0fi(11 v, nl ,  p, n2) = f( 1, v, nl ,  p) + f( 1, v, p, n2) + .f( 1, nl ,  p, n2)f(v, nl, p) + f(v, p, n2) + f (n l ,  p, n2)3.
Else if f(v,p) + f(nl,p) + f(p, n2) > 015(11v, nl,p, n2 ) = f(1,v,p) + f(1, nl,p) + f(1,p,  n2)f(v,p) + f(nl,p) + f(p, n2)4.
E lse if f(p) > 015(llv, nl,p, n2 ) _ f(1,p)f(P)5.
Else/}(1Iv, nl,p, n2) = 1.0 (default is noun attachment).The decision is then:If 15(11v , nl,p, n2) >= 0.5 choose noun attachment.Otherwise choose verb attachment5 Resu l tsThe figure below shows the results for the method on the 3097 test sentences, also giving the totalcount and accuracy at each of the backed-off stages.Stage Total Number Number Correct Percent CorrectQuadruples 148 134 90.5Triples 764 688 90.1Doubles 1965 1625 82.7Singles 216 155 71.8Defaults 4 4 100.0Totals 3097 2606 84.1aAt stages 1 and 2 backing off was also continued if ~(l lv ,  n l ,p ,  n2 ) = 0.5. ie.
the counts were 'neutra l '  withrespect to a t tachment  at this stage.335.1 Results with Morphological AnalysisIn an effort to reduce sparse data problems the following processing was run over both test andtraining data:?
All 4-digit numbers were replaced with the string 'YEAR'.?
All other strings of numbers (including those which had commas or decimal points) werereplaced with the token 'NUM'.?
The verb and preposition fields were converted entirely to lower case.?
In the nl  and n2 fields M1 words starting with a capital letter followed by one or more lowercase letters were replaced with 'NAME'.?
All strings 'NAME-NAME' were then replaced by 'NAME'.?
All verbs were reduced to their morphological stem using the morphological analyser describedin \[KSZE94\].These modifications are similar to those performed on the corpus used by \[BR94\].The result using this modified corpus was 84.5%, an improvement of 0.4~0 on the previous result.Stage TotM Number Number Correct Percent CorrectQuadruples 242 224 92.6Triples 977 858 87.8Doubles 1739 1433 82.4Singles 136 99 72.8Default 3 3 100.0Totals 3097 2617 84.55.2 Compar i son  w i th  Other  WorkResults from \[RRR94\], \[BR94\] and the backed-off method are shown in the table below 4.
All resultsare for the IBM data.
These figures should be taken in the context of the lower and upper boundsof 72.2%-88.2% proposed in section 2.3.Method Percentage Accuracy\[RRR94\] (words only) 77.7\[RRR94\] (words and classes) 81.6\[BR94\] (words only) 81.9Backed-off (no processing) 84.1Backed-off (morphological processing) 84.54Results for \[BR94\] with words and classes were not available on the IBM data34IfIff(nl,p) f(v,p)f (n l )  f(v)then choose noun attachment, else choose verb attachment.Here f(w,p) is the number of times preposition p is seen attached to word w in the table.
~tndf(w) = Ep f(w, p).If we ignore n2 then the IBM data is equivalent o Hindle and Rooth's (v, hi,  p} triples, with theadvantage of the attachment decision being known, allowing a supervised algorithm.
The test usedin \[HR93\] can then be stated as follows in our notation:35f(1,nl,p) f(O,v,p) >=/(1,  nl)  f(O,v)then choose noun attachment, else choose verb attachment.This is effectively a comparison of the maximum likelihood estimates of/)(pll ,  nl ) and P(PI(}, v), adifferent measure from the backed-off estimate which gives i5(lIv,p , nl).The backed-off method based on just the f(v,p) and f(nl,p) counts would be:If15(llv , n l ,p)  >= 0.5then choose noun attachment, else choose verb attachment,wherel~(lIv, nl,p) = f(1, v,p)+ f (1 ,n l ,p )f(v,p) + f(nl,p)5This ignores refinements to the test such ~ smoothing of the estimate, and a measure of the confidence of thedecision.
However the measure given is at the core of the algorithm./ ,On the surface the method described in \[HR93\] looks very similar to the backed-off estimate.
Forthis reason the two methods deserve closer comparison.
Itindle and Rooth used a partial paxserto extract head nouns from a corpus, together with a preceding verb and a followillg preposition,giving a table of (v, n l ,p)  triples.
An iterative, unsupervised method was thell used to decidebetween noun and verb attachment for each triple.
The decision was made as followsZ:An experiment was implemented to investigate the difference in performance between these twomethods.
The test set was restricted to those cases where f (1 ,n l )  > 0, .f(0, v) > 0, and Hindleand Rooth's method gave a definite decision.
(ie.
the above inequality is strictly less-than orgreater-than).
This gave 1924 test cases.
Hindle and Rooth's method scored 82.1% accuracy (1580correct) on this set, whereas the backed-off measure scored 86.5% (1665 correct).6 A Closer Look at Backing-Off6.1 Low Counts  a re  Impor tantA possible criticism of the backed-off estimate is that it uses low count events without any smooth-ing, which has been shown to be a mistake in similar problems such as n-gram language models.In particular, quadruples and triples seen in test data will frequently be seen only once or twice intrMning data.An experiment was made with all counts less than 5 being put to zero, 6 effectively making thealgorithm ignore low count events.
In \[RRR94\] a cut-off 'between 3 and 5' is used for all events.The training and test data were both the unprocessed, original data sets.The results were as follows:Stage Total Number Number Correct Percent CorrectQuaduples 39 38 97.4Triples 263 243 92.4Doubles 1849 1574 85.1Singles 936 666 71.2Defaults 10 5 50.0Totals 3097 2526 81.6The decrease in accuracy from 84.1% to 81.6% is clear evidence for the importance of low counts.6.2 Tup les  w i th  P repos i t ions  a re  Bet terWe have excluded tuples which do not contain a preposition from the model.
This section givesresults which justify this.The table below gives accuracies for the sub-tuples at each stage of backing-off.
The accuracy figurefor a particular tuple is obtained by modifying the algorithm in section 4.1 to use only informationfrom that tuple at the appropriate stage.
For example for (v, nl ,  n2), stage 2 would be modified toread6Specif ically: if for a subset  x of the  quadrup le  f(x) < 5, then  make f(x) = f (1 ,  x) = f (0 ,  x) = 0.36If f (v,  n l ,n2)  > 0,15(llv, nl,p, n2) = f(1, v, nl,  n2).f( v, '/~, 1, n2)All other stages in the algorithm would be unchanged.
The accuracy figure is then the percentageaccuracy on the test cases where the (v, nl,  n2) counts were used.
The development set with nomorphologicM processing was used for these tests.Triples Doubles II SinglesTuple I Accuracy Tuple Accuracy II Tuple Accuracynl p n2 i 90.9v p n2 i 90.3v nl  p i 88.2v nl  n2 68.4nl p 82.1 p 72.1v p 80.1 nl 55.7p n2 75.9 v 52.7nl n2 65.4 n2 47.4v nl 59.0v n2 53.4At each stage there is a sharp difference in accuracy between tuples with and without a preposition.Moreover, if the 14 tuples in the above table were ranked by accuracy, the top 7 tuples wouhl bethe 7 tuples which contain a preposition.7 Conc lus ionsThe backed-off estimate scores appreciably better than other methods which have been tested onthe Wall Street Journal corpus.
The accuracy of 84.5% is close to the hmna.n peribrnlance figure of88% using the 4 head words alone.
A particularly surprising result is the significance of low countevents in training data.
The Mgorithm has the additional advantages of being conceptually simple,and computationMly inexpensive to implement.There are a few possible improvements which may raise performance further.
Firstly, while wehave shown the importance of low-count events, some kind of smoothing 1nay improve peribrmancefurther - this needs to be investigated.
Word-classes of semantically similar words may be used tohelp the sparse data problem - both \[RRR94\] and \[BR94\] report significant improvements hroughthe use of word-classes.
Finally, more training data is almost certain to improve results.References\[BR94\] E. Brill and P. Resnik.
A Rule-Based Approach to Prepositional Phrase AttachmentDisambiguation.
In Proceedings of the fifteenth international conference on computationallinguistics (COLING-1994), 1994.37\[oc9o\]\[KSZE94\]\[HR93\]\[KATZ87\]\[MSM93\]\[RRR941W.
Gale and K. Church.
Poor Estimates of Context are Worse than None.
ht Proceed-ings of the June 1990 DARPA Speech and Natural L~mguage Workshop, ftidden Valley,Pennsylva.nia.Daniel Karp, Yves Scha,bes, Martin Zaidel and Dania Egedi.
A Freely Available WideCoverage Morphological Analyzer for English.
In Proceedings of the 15th, InternationalConference on Computational Li'nguistics, 1994.D.
IIindle and M. Rooth.
Structural Ambiguity and Lexical Relations.
ComputationalLinguistics , 19(1):103-120, 1993.S.
Katz.
Estima.tion of Probabilities fi:om Sparse Data for the Language Model Com-ponent of a.
Speech Recogniser.
IEEE Transaetion,s on Acoustics, Speech, and SignalProcessing, Vol.
ASSP-35, No.
3, 1987.M.
Marcus, B. Santorini and M. Marcinkiewicz.
Building a Large Annotated Corpus ofEnglish: the Penn Treebank.
Computational Linguistics, 19(2), 1993.A.
Ratnaparkhi, J. Reyna.r and S. Roukos.
A Maximum Entropy Model for Preposi-tional Phrase Attachment.
In Proceeding s of the ARPA Workshop on Human LanguageTechnology, Plainsboro, N J, March 1994.38
