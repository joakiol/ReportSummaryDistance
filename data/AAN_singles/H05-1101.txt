Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 803?810, Vancouver, October 2005. c?2005 Association for Computational LinguisticsSome Computational Complexity Resultsfor Synchronous Context-Free GrammarsGiorgio SattaDept.
of Information EngineeringUniversity of Paduavia Gradenigo, 6/AI-35131 PadovaItalysatta@dei.unipd.itEnoch PesericoDept.
of Information EngineeringUniversity of Paduavia Gradenigo, 6/AI-35131 PadovaItalyenoch@dei.unipd.itAbstractThis paper investigates some computa-tional problems associated with proba-bilistic translation models that have re-cently been adopted in the literature onmachine translation.
These models can beviewed as pairs of probabilistic context-free grammars working in a ?synchronous?way.
Two hardness results for the classNP are reported, along with an exponen-tial time lower-bound for certain classesof algorithms that are currently used in theliterature.1 IntroductionState of the art architectures for machine transla-tion are all based on mathematical models calledtranslation models.
Generally speaking, a transla-tion model accounts for all the elementary opera-tions that rule the process of translation between thewords and the different word orderings of the sourceand target languages.
Translation models are usu-ally enriched with statistical parameters, to drive thesearch toward the most likely translation(s).
Special-ized algorithms are provided for the automatic esti-mation of these parameters from corpora of trans-lation pairs.
Besides the task of natural languagetranslation, statistical translation models are also ex-ploited in other applications, such as word align-ment, multilingual document retrieval and automaticdictionary construction.The most successful translation models that arefound in the literature exploit finite-state machinery.The approach started with the so-called IBM mod-els (Brown et al, 1988), implementing a set of ele-mentary operations, such as movement, duplicationand translation, that independently act on individ-ual words in the source sentence.
These word-to-word models have been later enriched with the in-troduction of larger units such as phrases; see forinstance (Och et al, 1999; Och and Ney, 2002).Still, the generative capacity of these models lieswithin the realm of finite-state machinery (Kumarand Byrne, 2003), so they are unable to handlenested structures and do not provide the expressivityrequired to process language pairs with very differ-ent word orderings.Recently, more sophisticated translation modelshave been proposed, borrowing from the theory ofcompilers and making use of synchronous rewrit-ing.
In synchronous rewriting, two formal gram-mars are exploited, one describing the source lan-guage and the other describing the target language.Furthermore, the productions of the two gram-mars are paired and, in the rewriting process, suchpairs are always applied synchronously.
Formalismsbased on synchronous rewriting have been empow-ered with the use of statistical parameters, and spe-cialized estimation and translation (decoding) algo-rithms were newly developed.
Among the severalproposals, we mention here the models presentedin (Wu, 1997; Wu and Wong, 1998), (Alshawi et al,2000), (Yamada and Knight, 2001), (Gildea, 2003)and (Melamed, 2003).In this paper we consider synchronous modelsbased on context-free grammars and probabilisticextensions thereof.
This is the most common choice803in statistical translation models that exceed the gen-erative power of finite-state machinery.
We focuson two associated computational problems that havebeen defined in the literature.
One is the member-ship problem, which involves testing whether an in-put string pair can be generated by the model.
Theother is the translation problem (also called the de-coding problem) which involves the search for asuitable translation of an input string/structure.
Ithas been often informally stated in the literaturethat the use of structured models results in efficient,polynomial time algorithms for the above problems.We show here that sometimes this is not the case.The contribution of this paper can be stated as fol-lows:?
we show that the membership problem is NP-hard, unless a constant bound is imposed on thelength of the productions (Section 3);?
we show an exponential time lower bound forthe membership problem, in case chart parsingis adopted (Section 3);?
we show that translating an input string intothe best parse tree in the target language is NP-hard, even in case productions are bounded inlength (Section 4).Investigation of the computational complexity oftranslation models has started in (Knight, 1999) forword-to-word models.
This paper can be seen as thecontinuation of that line of research.2 Synchronous context-free grammarsSeveral definitions for synchronous context-freegrammars have been proposed in the literature; seefor instance (Chiang, 2004; Chiang, 2005).
Ourdefinition is based on syntax-directed translationschemata (SDTS; Aho and Ullman, 1972), with thedifference that we do not impose the restriction thattwo paired context-free productions have the sameleft-hand side.
As it will be discussed in Section 4,this results in an enriched generative capacity whenprobabilistic extensions are considered.
We assumethe reader is familiar with the definition of context-free grammar (CFG) and with the associated notionof derivation.Let VN and VT be sets of nonterminal and termi-nal symbols, respectively.
In what follows we needto represent bijections between all the occurrencesof nonterminals in two strings over VN ?
VT .
Thiscan be done by annotating nonterminals with indicesfrom an infinite set.
We define I(VN ) = {A(t) |A ?
VN , t ?
N} and VI = I(VN ) ?
VT .
Wewrite index(?
), ?
?
V ?I , to denote the set of all in-dices (the integers t) that appear in symbols in ?.Two strings ?, ??
?
V ?I are synchronous if each in-dex in index(?)
occurs only once in ?, each indexin index(??)
occurs only once in ?
?, and index(?)
=index(??).
Therefore synchronous strings have thegeneral formu10A(t1)11 u11A(t2)12 u12 ?
?
?
u1r?1A(tr)1r u1r,u20A(tpi(1))21 u21A(tpi(2))22 u22 ?
?
?
u2r?1A(tpi(r))2r u2r,where r ?
0, u1i, u2i ?
V ?T , A(ti)1i , A(tpi(i))2i ?I(VN ), ti 6= tj for i 6= j and pi is some permuta-tion defined on set {1, .
.
.
, r}.Definition 1 A synchronous context-free gram-mar (SCFG) is a tuple G = (VN , VT , P, S), whereVN , VT are finite, disjoint sets of nonterminal andterminal symbols, respectively, S ?
VN is the startsymbol and P is a finite set of synchronous produc-tions, each of the form [A1 ?
?1, A2 ?
?2], withA1, A2 ?
VN and ?1, ?2 ?
V ?I synchronous strings.The size of a SCFG G is defined as |G| =?[A1?
?1, A2?
?2]?P |A1?1A2?2|.
Based on an ex-ample from (Yamada and Knight, 2001), we providea sample SCFG fragment translating from English toJapanese, specified by means of the following syn-chronous productions:s1 : [VB ?
PRP(1) VB1(2) VB2(3),VB ?
PRP(1) VB2(3) VB1(1)]s2 : [VB2 ?
VB(1) TO(2),VB2 ?
TO(2) VB(1) ga]s3 : [TO ?
TO(1) NN(2), TO ?
NN(2) TO(1)]s4 : [PRP ?
he, PRP ?
kare ha]s5 : [VB1 ?
adores, VB1 ?
daisuki desu]s6 : [VB ?
listening, VB ?
kiku no]s7 : [TO ?
to, TO ?
wo]s8 : [NN ?
music, NN ?
ongaku]Note that in production s2 above, the nonterminalsVB and TO generated from nonterminal VB2 in804the English component are inverted in the Japanesecomponent, where some additional lexical materialis also added.In a SCFG, the ?derives?
relation is defined onsynchronous strings in terms of simultaneous rewrit-ing of two nonterminals with the same index.
Someadditional notation will help us defining this rela-tion precisely.
A reindexing is a one-to-one func-tion on N. We extend a reindexing f to VI by lettingf(A(t)) = A(f(t)) for A(t) ?
I(VN ) and f(a) = afor a ?
VT .
We also extend f to strings in V ?I byletting f(?)
= ?
and f(X?)
= f(X)f(?
), for eachX ?
VI and ?
?
V ?I .
We say that strings ?1, ?2 ?V ?I are independent if index(?1) ?
index(?2) = ?.Definition 2 Let G = (VN , VT , P, S) be a SCFGand let ?1, ?2 be synchronous strings in V ?I .
Thederives relation [?1, ?2] ?G [?1, ?2] holdswhenever there exist an index t in index(?1), a syn-chronous production [A1 ?
?1, A2 ?
?2] in Pand some reindexing f such that(i) f(?1?2) and ?1?2 are independent; and(ii) ?i = ?
?iA(t)i ??
?i , ?i = ??if(?i)??
?i , for i = 1, 2.We also write [?1, ?2] ?sG [?1, ?2] to explicitlyindicate that the derives relation holds through somesynchronous production s ?
P .Since ?1 and ?2 in Definition 2 are synchronousstrings, we can define the reflexive and transitiveclosure of ?G, written ??G.
This relation is usedto represent derivations in G. In case we have[?1i?1, ?2i?1] ?siG [?1i, ?2i] for 1 ?
i ?
n,n ?
1, we also write [?10, ?20] ?
?G [?1n, ?2n],where ?
= s1s2 ?
?
?
sn.
We always assume somecanonical form for derivations (as for instance left-most derivation on the left component).
Similarly tothe case of context-free grammars, each derivationin G can be associated with a pair of parse trees, thatis, one parse tree for each dimension.Back to our example, we report a fragment of aderivation of the string pair [he adores listening tomusic, kare ha ongaku wo kiku no ga daisuki desu]:[VB(1), VB(1)]?s1G [PRP(2) VB1(3) VB2(4),PRP(2) VB2(4) VB1(3)]?s4G [he VB1(3) VB2(4),kare ha VB2(4) VB1(3)]?s5G [he adores VB2(4),kare ha VB2(4) daisuki desu]?s2G [he adores VB(5) TO(6),kare ha TO(6) VB(5) ga daisuki desu].The translation generated by a SCFG G is a bi-nary relation over V ?T defined asT (G) = {[w1, w2] | [S(1), S(1)] ?
?G [w1, w2],w1, w2 ?
V?T }.The set of strings that are translations of a givenstring w1 is defined as:T (G,w1) = {w2 | [w1, w2] ?
T (G)}.A probabilistic SCFG (PSCFG) is a pair (G, pG)where G = (VN , VT , P, S) is a SCFG and pG is afunction from P to real numbers in [0, 1] such that,for each A1, A2 ?
VN , we have:?
?1,?2pG([A1 ?
?1, A2 ?
?2] = 1.If for n ?
1 and si ?
P , 1 ?
i ?
n, string?
= s1s2 ?
?
?
sn is a canonical derivation of the form[S(1), S(1)] ?
?G [w1, w2], we write pG(?)
=?ni=1 pG(si).
If D([w1, w2]) is the set of all canon-ical derivations in G for pair [w1, w2], we writepG([w1, w2]) =??
?D([w1,w2]) pG(?
).3 The membership problemWe consider here the membership problem forSCFG, defined as follows: for input instance aSCFG G and a pair [w1, w2], decide whether[w1, w2] is in T (G).
This problem has been con-sidered for instance in (Wu, 1997) for his inver-sion transduction grammars and has applications inthe support of several tasks of automatic annotationof parallel corpora, as for instance segmentation,bracketing, phrasal and word alignment.
We showthat the membership problem for SCFGs is NP-hard.
The result could be derived from the findingsin (Melamed et al, 2004) that synchronous rewritingsystems as SCFGs are related to the class of so calledlinear context-free rewriting systems (LCFRSs) andfrom the result that the membership problem for805LCFRSs is NP-hard (Satta, 1992; Kaji and others,1994).
However, we provide here a direct proof, tosimplify the presentation.Theorem 1 The membership problem for SCFGs isNP-hard.Proof.
We reduce from the three-satisfiabilityproblem (3SAT, Garey and Johnson, 1979).
Let?U,C?
be an instance of the 3SAT problem, whereU = {u1, .
.
.
, up} is a set of variables and C ={c1, .
.
.
, cn} is a set of clauses.
Each clause is a setof three literals from {u1, u1, .
.
.
, up, up}.The general idea of the proof is to use a stringpair [w1w2 ?
?
?wp, wc], where wc is a string repre-sentation of C and each wi is a string controlling thetruth assignment for the variable ui.
We then con-struct a SCFG G such that each wi can be derivedin two possible ways only, using some specializedproductions of G, encoding the truth assignment ofvariable ui.
In this way the derivation of the wholestring w1 ?
?
?wp in the left dimension corresponds toa guess of a truth assignment for U .
Accordingly, onthe right dimension only those symbols of wc willbe derived that represent clauses that hold true un-der the guessed assignment.We need some additional notation.
Below wetreat C as an alphabet of atomic symbols.
We usea function d such that, for every i with 1 ?
i ?p, cd(i,1), cd(i,2), .
.
.
, cd(i,si) is the sequence of allclauses that include literal ui, in the left to rightorder in which they appear within c1c2 ?
?
?
cn, andcd(i,si+1), cd(i,si+2), .
.
.
, cd(i,ti) is the sequence of allclauses that include literal ui, again as they appearwithin c1c2 ?
?
?
cn from left to right.
Note that wemust have?pi=1 ti = 3n.
We also use a functione such that, for every 1 ?
i ?
p and 1 ?
j ?
ti,e(i, j) = j +?i?1k=1 tk (assume?0k=1 tk = 0).Consider the alphabet {ai, bi | 1 ?
i ?
p}.
Forevery i, 1 ?
i ?
p, let wi denote a sequence ofexactly ti + 1 alternating symbols ai and bi, i.e.,wi ?
(aibi)+ ?
(aibi)?ai.
For every 1 ?
i ?
p,let x(i, 1) = aibi and let x(i, h) = ai (resp.
bi)if h is even (resp.
odd), 2 ?
h ?
ti.
Letalso x(i, h) = ai (resp.
bi) if h is odd (resp.even), 1 ?
h ?
ti ?
1, and let x(i, ti) = aibi(resp.
biai) if ti is odd (resp.
even).
There-fore we can write wi = x(i, 1)x(i, 2) ?
?
?x(i, t1) =x(i, 1)x(i, 2) ?
?
?x(i, t1).Finally, we need a permutation pi defined on theset {1, .
.
.
, 3n} as follows.
Fix i and j with 1 ?
i ?p and 1 ?
j ?
ti, and let h be the number of oc-currences of the clause cd(i,j) found in the sequencecd(1,1), cd(1,2), .
.
., cd(1,t1), cd(2,1), .
.
., cd(i,j).
Notethat we must have 1 ?
h ?
3.
Then we setpi(e(i, j)) = 3 ?
[d(i, j)?
1] + h.We can now define the target instance?G, [w,w?]?
of our reduction.
Let [w,w?]
=[w1w2 ?
?
?wp, c1c2 ?
?
?
cn].
Let alo G = (VN , VT ,P, S), with VN = {S} ?
{Ai | 1 ?
i ?
3n} andVT = C ?
{ai, bi | 1 ?
i ?
p}.
The productionsbelow define set P :(i) for every 1 ?
i ?
p:(a) for 1 ?
h ?
si:[Ae(h,i) ?
x(i, h), Ae(h,i) ?
ce(i,h)],[Ae(h,i) ?
x(i, h), Ae(h,i) ?
?
],[Ae(h,i) ?
x(i, h), Ae(h,i) ?
?
];(b) for si + 1 ?
h ?
ti:[Ae(h,i) ?
x(i, h), Ae(h,i) ?
?
],[Ae(h,i) ?
x(i, h), Ae(h,i) ?
ce(i,h)],[Ae(h,i) ?
x(i, h), Ae(h,i) ?
?
];(ii) [S ?
A(e(1,1))e(1,1) A(e(1,2))e(1,2) ?
?
?A(e(1,t1))e(1,t1) A(e(2,1))e(2,1) ?
?
?A(e(p,tp))e(p,tp),S ?
A(pi(e(1,1)))pi(e(1,1)) A(pi(e(1,2)))pi(e(1,2)) ?
?
?A(pi(e(1,t1)))pi(e(1,t1)) A(pi(e(2,1)))pi(e(2,1)) ?
?
?A(pi(e(p,tp)))pi(e(p,tp))].It is easy to see that |G|, |w| and |w?| are polyno-mially related to |U | and |C|.
From a derivation of[w,w?]
?
T (G), we can exhibit a truth assignmentthat satisfies C simply by reading off the derivationof the left string w1w2 ?
?
?wp.
Conversely, startingfrom a truth assignment that satisfiesC we can provew ?
L(G) by means of (finite) induction on |U |: thispart requires a careful inspection of all items in thedefinition of G.From Theorem 1 we may conclude that algo-rithms for the membership problem for SCFGs arevery unlikely to run in polynomial time.
In theliterature, several algorithms for this problem havebeen proposed using tabular methods (chart pars-ing).
In the worst case, all these algorithms run intime ?
(|G| ?
nk(G)), with G an SCFG and n the806length of the input string pair.
We know that, un-less P = NP, k(G) cannot be a constant.
We nowprove a lower bound on k(G), providing thereby anexponential time lower bound result for our problemunder the assumption of the tabular paradigm.Tabular methods for the membership problem arebased on the following representation.
Given a syn-chronous productions : [A1 ?
B(1)11 ?
?
?B(r)1r ,A2 ?
B(pi(1))21 ?
?
?B(pi(r))2r ], (1)the already recognized constituent pairs B1i, B2pi(i)are gather together in several steps, keeping a recordof the spanned substrings of the input.
To pro-vide a concrete example, if we gather all the B1i?son the left dimension from left to right, the partialanalysis we obtain after the first step can be repre-sented as a state ?s(1), (i11, j11), (i21, j21)?, mean-ing that B11 and B2pi(1) span substrings w1[i11, j11]and w2[i21, j21], respectively.1 At the secondstep we have a state ?s(2), (i11, j12), (i21, j21),(i22, j22)?, meaning that B11B12 together spanw1[i11, j12], B2pi(1) spans w2[i21, j21] and B2pi(2)spans w2[i22, j22].
We can see that, for some worstcase permutations, the left-to-right strategy demandsfor increasingly more pairs of indices, so that the ex-ponent in the time complexity linearly grows with r.How much better can we do, if we exploit somestrategy other than the left-to-right above?
Moreprecisely, we ask how many unconnected spanningsa state may require for some worst case permutationpi, under the choice of the best possible parsing strat-egy for pi itself.Theorem 2 In the worst case, standard tabularmethods for the SCFG membership problem requirean amount of time ?(|G|nc?
?r), with r the length ofthe longest production in G and c a constant.Proof.
For any r ?
8 we let q = b?r/2c ?b?8/2c = 2, and define a permutation pir on{1, .
.
.
, r}.
We view the domain of pir as composedof 2q blocks with q adjacent integers each, possi-bly followed by r ?
2q2 additional ?padding?
in-tegers, and its codomain as composed of q blocks1For a string w = a1 ?
?
?
an, we write w[i, j] to denote thesubstring ai+1 ?
?
?
aj .with 2q adjacent integers each, again possibly fol-lowed by r ?
2q2 ?padding?
integers.
Permutationpir transposes all blocks by sending the j-th elementof the i-th block in the domain into the i-th elementof the j-th block in the codomain, while mappingeach padding integer identically into itself.
For-mally, for all positive integers i ?
2q and j ?
q,pir(q ?
(i ?
1) + j) = 2q ?
(j ?
1) + i, and for allintegers i with 2q2 < i ?
r, pir(i) = i.We count below how many spans are instanti-ated by a state that has gathered p constituent pairs,1 ?
p ?
r, in parsing production (1) under any pos-sible strategy.
When a constituent pair B1i, B2pir(i)is gathered, we say integer i in the domain of pir andinteger pir(i) in the codomain have been pebbled.
Inthis way each span (i, j) in a state corresponds tosome run i, i + 1, .
.
.
j of pebbled integers, with ei-ther i = 1 or i?
1 unpebbled, and with either j = ror j + 1 unpebbled.
We call each such run a seg-ment, and show that every parsing strategy demandsat least q = b?r/2c segments either in the domainor in the codomain of pir.We say that a block in the domain of pir is empty,full, or mixed if, respectively, none, all, or some butnot all of its elements have been pebbled.
Assumethat, for a given parsing strategy, the last block thatbecomes mixed does so when we place the i-th peb-ble, and the first block that becomes full does sowhen we place the j-th pebble.
Obviously i 6= j:the first pebble placed in a previously empty blockcan not make it full since every block contains atleast 2 elements.If i < j, after placing the i-th pebble and beforeplacing the j-th pebble every block in the domain ofpir is mixed.
Each of these 2q blocks then containsat least one pebbled element which is adjacent to anunpebbled one and must therefore be either the firstor the last element of a segment.
The domain of pirthen contains at least 2q/2 = q segments.If j < i, after placing the j-th pebble and be-fore placing the i-th pebble at least one block in thedomain of pir (e.g., the h-th block) is full, and atleast one (e.g., the k-th) is empty.
Then, in eachof the q blocks in the codomain of pir, the h-th el-ement is pebbled while the k-th is not.
Thereforethe h-th elements of any two consecutive blocks inthe codomain of pir must belong to two distinct seg-ments, since at least one intermediate element is not807pebbled.
The codomain of pir then contains at leastq segments.4 The translation problemIn this section we consider some formulations of thetranslation problem for PSCFG that have been pro-posed in the literature.
The most general definitionof the translation problem for PSCFG is this: foran input PSCFG Gp = (G, pG) and an input stringw, produce a representation of all possible parsetrees, along with their probabilities, that are assignedbyG to a string in the set T (G,w) under some trans-lation of w.Variant of this definition can be found where theinput is a single parse tree for w (Yamada andKnight, 2001), or where the output is a single parsetree, chosen according to some specific criteria (WuandWong, 1998).
To formally study these problems,in what follows we focus on single parse trees asso-ciated with derivations in Gp.
For a derivation ?
ofthe form [S(1), S(1)] ?
?G [w1, w2], we write t?,l andt?,r to denote the left and the right parse trees, re-spectively, associated with ?.
The probability thatt?,r is obtained as a translation of t?,l through Gp isthus pG([t?,l, t?,r]) = pG(?).
Let t be some parsetree; we write y(t) to denote the string in the yieldof t. For a string w ?
V ?T and a parse tree t, wealso consider the probability that t is obtained fromw through Gp, defined as:pG([w, t]) =?y(t?
)=wpG([t?, t]).
(2)We can now precisely define the variants of thetranslation problem we are interested in.
Givenas input a PSCFG Gp = (G, pG) and two stringsw1, w2 ?
V ?T , output the pair of parse treesargmaxy(t1) = w1,y(t2) = w2pG([t1, t2]).
(3)If the synchronous productions in the underlyingSCFG G have length bounded by some constant,then the above problem can be solved in polynomialtime using extensions of the Viterbi search strategyto parse forests.
This has been shown for instancein (Wu and Wong, 1998; Yamada and Knight, 2001;Melamed, 2004).A second interesting problem is defined as fol-lows.
Given as input a PSCFG Gp = (G, pG) and astring w ?
V ?T , output the parse treeargmaxtpG([w, t]).
(4)Even in case we impose some constant bound onthe length of the synchronous productions in G, theabove problem is NP-hard, as we show in what fol-lows.We assume the reader is familiar with the defini-tion of probabilistic context-free grammar (PCFG)and with the associated notion of derivation prob-ability (Wetherell, 1980).
We denote a PCFG asa pair (G, pG), with G = (VN , VT , P, S) the un-derlying context-free grammar and pG the associ-ated function providing the probability distributionsfor the productions in P , conditioned on their left-hand side.
A probabilistic regular grammar (PRG)is a PCFG with underlying productions of the formA ?
aB or A ?
?, with A,B nonterminal symbolsand a a terminal symbol.We consider below a decision problem associatedwith PRG, called the consensus problem, defined asfollows: Given as input a PRG (G, pG) and a ra-tional number d ?
[0, 1], decide whether there ex-ists a string w in the language generated by G suchthat pG(w) ?
d. It has been shown in (Casacubertaand de la Higuera, 2000) that, for a PRG G whoseproductions have all probabilities expressed by ra-tional numbers, the above problem is NP-complete.
(Essentially the same result is also reported in (Lyn-gso and Pedersen, 2002), stated in terms of hiddenMarkov models.)
We reduce the consensus problemfor PRG to a decision version of the problem in (4),called the best translated derivation problem anddefined as follows.
Given as input a PCFG Gp =(G, pG), a string w ?
V ?T and a rational numberd ?
[0, 1], decide whether maxt pG([w, t]) ?
d.Theorem 3 The best translated derivation problemfor the class PSCFG is NP-hard.Proof.
We provide a reduction from the consensusproblem for the class PRG with rational productionprobabilities.
The main idea is described in what fol-lows.
Given the input PRG Gp, we construct a targetPSCFG G?p that translates string $ into $, with $ aspecial symbol.
Given as input the string $, G?p sim-ulates all possible derivations of Gp through its own808derivations.
This is done by encoding the nontermi-nals appearing in a derivation ?
of Gp within the leftcomponent of some derivation ?
of G?p, and by en-coding the terminal string generated by ?
within theright component of ?.
The probability of ?
is alsopreserved by ?.Let Gp = (G, pG), d be an instance of the con-sensus problem as above, with G = (VN , VT , P, S).We specify a PSCFG G?p = (G?, pG?)
with G?
=(V ?N , {$}, P?, S) and V ?N = VN ?
VT .
Set P?
is con-structed as follows:(i) for every (S ?
aA) ?
P , s : [S ?
A(1), S ?a(1)] is added to P ?, with pG?
(s) = pG(S ?aA);(ii) for every (S ?
?)
?
P , s : [S ?
$, S ?
$] isadded to P ?, with pG?
(s) = pG(S ?
?
);(iii) for every a ?
VT and (A ?
bB) ?
P , s :[A ?
B(1), a ?
b(1)] is added to P ?, withpG?
(s) = pG(A ?
bB)(iv) for every a ?
VT and (A ?
?)
?
P ,s : [A ?
$, a ?
$] is added to P ?, withpG?
(s) = pG(A ?
?
).Note that the construction of G?p can be carried outin quadratic time in the size of Gp.
It is not diffi-cult to see that there exists a derivation of the formS ?G a1A1 ?G a1a2A2 ?
?
?
?G a1a2 ?
?
?
anAnif and only if there exist a derivation in G?
asso-ciated with unary trees t1 and t2, such that stringSA1A2 ?
?
?An is read from the spine of t1 and stringSa1a2 ?
?
?
an is read from the spine of t2.
Further-more, the two derivations are composed of ?corre-sponding?
productions with the same probabilities.We conclude that there exists a string w in L(G)with pG(w) > d if and only if there exists a unarytree t with string Sw$ read from the spine such thatpG?
([$, t]) > d.We discuss below an interesting consequence ofTheorem 3.
The SDTS formalism discussed in Sec-tion 1 has been extended to the probabilistic casein (Maryanski and Thomason, 1979), called stochas-tic SDTS (SSDTS).
As a corollary to the proof ofTheorem 3, we obtain that one can define, throughsome PSCFG Gp and some fixed string w, a proba-bility distribution pG([w, t]) on parse trees that can-not be obtained through any SSDTS.
Without pro-viding the details of the definition of SSDTS, wegive here only an outline of the proof.
We also as-sume that the reader is familiar with probabilisticfinite automata and with their distributional equiv-alence with PRG.Consider the PSCFG G?p = (G?, pG?)
defined inthe proof of Theorem 3, and assume there existssome SSDTS G?
?p = (G?
?, pG??)
such that, for everytree t, we have pG??
([$, t]) = pG?
([$, t]).
Since in aderivation of an SDTS the generated trees are alwaysisomorphic, up to some reordering of sibling nodes,we obtain that the productions of G??
must have theform [S ?
a(1), S ?
a(1)], [a ?
b(1), a ?
b(1)]and [a ?
$, a ?
$].
From these productions wecan construct a probabilistic deterministic finite au-tomaton generating the same language as the PRGGp, and with the same distribution.
But this is im-possible since there are string distributions definedby some PRG that cannot be obtained through prob-abilistic deterministic finite automata; see for in-stance (Vidal et al, 2005).We conclude by remarking that in (Casacubertaand de la Higuera, 2000) it is shown that findingthe best output string for a given input string is NP-hard for stochastic SDTS with a single nonterminalin each production?s right-hand side.
Our result inTheorem 3, stated for PSCFG, is stronger, since it in-vestigates individual parse trees rather than strings.5 Concluding remarksThe presented results are based on worst case analy-sis: further experimental evaluation needs to be car-ried out on multilingual corpora in order to asses thepractical impact of these findings.AcknowledgmentWe are indebted to Dan Melamed and Mark-JanNederhof for technical discussion on topics relatedto this paper.
Dan Melamed also suggested to us theproblem investigated by Theorem 2.
The first authoris partially supported by MIUR under project PRINNo.
2003091149 005.ReferencesA.
V. Aho and J. D. Ullman.
1972.
The Theory of Pars-ing, Translation and Compiling, volume 1.
Prentice-Hall, Englewood Cliffs, NJ.809Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas.2000.
Learning dependency translation models as col-lections of finite state head transducers.
Computa-tional Linguistics, 26(1):45?60, March.Peter F. Brown, John Cocke, Stephen A. Della Pietra,Vincent J. Della Pietra, Fredrick Jelinek, Robert L.Mercer, and Paul Roossin.
1988.
A statistical ap-proach to language translation.
In Proceedings ofthe International Conference on Computational Lin-guistics (COLING) 1988, pages 71?76, Budapest,Hungary, August.F.
Casacuberta and C. de la Higuera.
2000.
Computa-tional complexity of problems on probabilistic gram-mars and transducers.
In L. Oliveira, editor, Gram-matical Inference: Algorithms and Applications; 5thInternational Colloquium, ICGI 2000, pages 15?24.Springer.D.
Chiang.
2004.
Evaluating Grammar Formalisms forApplications to Natural Language Processing and By-ological Sequence Analysis.
Ph.D. thesis, Departmentof Computer and Information Science, University ofPennsylvania.D.
Chiang.
2005.
A hierarchical phrase-based model forstatistical machine translation.
In Proc.
of the 43rdACL, pages 263?270.M.
R. Garey and D. S. Johnson.
1979.
Computers andIntractability.
Freeman and Co., New York, NY.Daniel Gildea.
2003.
Loosely tree-based alignment formachine translation.
In Proceedings of the 40th An-nual Meeting of the Association for ComputationalLinguistics (ACL), Sapporo, Japan, July.Y.
Kaji et al 1994.
The computational complexity ofthe universal recognition problem for parallel multiplecontext-free grammars.
Computational Intelligence,10(4):440?452.Kevin Knight.
1999.
Decoding complexity in word-replacement translation models.
Computational Lin-guistics, Squibs and Discussion, 25(4).S.
Kumar and W. Byrne.
2003.
A weighted finite statetransducer implementation of the alignment templatemodel for statistical machine translation.
In Proceed-ings of HLT-NAACL.R.
B. Lyngso and C. N. S. Pedersen.
2002.
The con-sensus string problem and the complexity of compar-ing hidden markov models.
Journal of Computing andSystem Science, 65:545?569.Fred J. Maryanski and Michael G. Thomason.
1979.Properties of stochastic syntax-directed translationschemata.
International Journal of Computer and In-formation Sciences, 8(2):89?110.I.
Dan Melamed, Giorgio Satta, and Benjamin Welling-ton.
2004.
Generalized multitext grammars.
In Pro-ceedings of the 42nd Annual Meeting of the Associa-tion for Computational Linguistics (ACL), Barcelona,Spain.I.
Dan Melamed.
2003.
Multitext grammars and syn-chronous parsers.
In Proceedings of the Human Lan-guage Technology Conference and the North Ameri-can Association for Computational Linguistics (HLT-NAACL), pages 158?165, Edmonton, Canada.I.
Dan Melamed.
2004.
Statistical machine translationby parsing.
In Proceedings of the 42nd Annual Meet-ing of the Association for Computational Linguistics(ACL), Barcelona, Spain.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for statis-tical machine translation.
In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics (ACL), Philadelphia, July.Franz Josef Och, Christoph Tillmann, and Hermann Ney.1999.
Improved alignment models for statistical ma-chine translation.
In Proceedings of the 4nd Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP), pages 20?28, College Park, Mary-land.G.
Satta.
1992.
Recognition of linear context-free rewrit-ing systems.
In Proc.
of the 30th ACL, Newark,Delaware.E.
Vidal, F. Thollard, C. de la Higuera, F. Casacuberta,and R. C. Carrasco.
2005.
Probabilistic finite-statemachines ?
Part I. IEEE Trans.
on Pattern analysisand Machine Intelligence.
To appear.C.
S. Wetherell.
1980.
Probabilistic languages: A re-view and some open questions.
Computing Surveys,12(4):361?379.Dekai Wu and Hongsing Wong.
1998.
Machine trans-lation with a stochastic grammatical channel.
In Pro-ceedings of the 35th Annual Meeting of the Associa-tion for Computational Linguistics (ACL), Montreal,Canada, July.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):377?404, Septem-ber.Kenji Yamada and Kevin Knight.
2001.
A syntax-basedstatistical translation model.
In Proceedings of the39th Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 531?538, Toulouse,July.810
