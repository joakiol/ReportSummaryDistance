Language Independent Named Entity Recognition CombiningMorphological and Contextual EvidenceS i lv iu  Cucerzan  and Dav id  YarowskyDepartment  of Computer  ScienceCenter for Language and Speech ProcessingJohns Hopkins UniversityBalt imore,  Maryland,  21218{si lviu,yarowsky}@cs.jhu.eduAbst rac tIdentifying and classifying personal, geographic, in-stitutional or other names in a text is an impor-tant task for numerous applications.
This paper de-scribes and evaluates a language-independent boot-strapping algorithm based on iterative learning andre-estimation of contextual nd mOrphological pat-terns captured in hierarchically smoothed trie mod-els.
The algorithm learns from unannotated text andachieves competitive performance when trained on avery short labelled name list with no other requiredlanguage-specific nformation, tokenizers or tools.1 In t roduct ionThe ability to determine the named entities in atext has been established as an important task forseveral natural language processing areas, includinginformation retrieval, machine translation, informa-tion extraction and language understanding.
For the1995 Message Understanding Conference (MUC-6),a separate named entity recognition task was devel-oped and the best systems achieved impressive accu-racy (with an F-measure approaching 95%).
Whatshould be underlined here is that these systems weretrained for a specific domain and a particular lan-gnage (English), typically making use of hand-codedrules, taggers, parsers and semantic lexicons.
In-deed, most named entity recognizers that have beenpublished either use tagged text, perform syntacticaland morphological nalysis or use semantic informa-tion for contextual c ues.
Even the systems that donot make use of extensive knowledge about a partic-ular language, such as Nominator (Choi et al, 1997),still typically use large data files containing lists ofnames, exceptions, personal and organizational iden-tifiers.Our aim has been to build a maximally langnage-independent system for both named-entity identi-fication and classification, using minimal informa-tion about he source language.
The applicability ofAI-style algorithms and supervised methods is lim-ited in the multilingual case because of the cost ofknowledge databases and manually annotated cor-pora.
Therefore, a much more suitable approach isto consider an EM-style bootstrapping algorithm.
Interms of world knowledge, the simplest and most rel-evant resource for this task is a database of knownnames.
For each entity class to be recognized andtagged, it is assumed that the user can provide ashort list (order of one hundred) of unambiguousexamples (seeds).
Of course the more examples pro-vided, the better the results, but what we try toprove is that even with minimal knowledge good re-sults can be achieved.
Additionally some basic par-ticularities of the language should be known: cap-italization (if it exists and is relevant - some lan-guages do not make use of capitalization; in others,such as German, the capitalization is not of greathelp), allowable word separators (if they exist), anda few frequent exceptions (like the pronoun "/" inEnglish).
Although such information can be utilisedif present, it is not required, and no other assump-tions are made in the general model.1.1 Word- Internal  and ContextualInformationThe algorithm relies on both word internal andcontextual clues as relatively independent evidencesources that drive the bootstrapping algorithm.
Thefirst category refers to the morphological structureof the word and makes use of the paradigm thatfor certain classes of entities ome prefixes and suf-fixes are good indicators.
For example, knowing that"Maria", "Marinela" and "Maricica" are femininefirst names in Romanian, the same classification maybe a good guess for "Mariana", based on commonprefix.
Suffixes are typically even more informa-tive, for example "-escu" is an almost perfect indi-cator of a last name in Romanian, the same appliesto "-wski" in Polish, "-ovic" and "-ivic" in Serbo-Croatian, "-son" in English etc.
Such morphologicalinformation is automatically earned during boot-strapping.Contextual patterns (e.g.
"Mr.", "in" and"mayor of" in left context) are also clearly crucialto named entity identification and classification, es-pecially for names that do not follow a typical mor-phological pattern for their word class, are of foreignorigin or polysemous (for example, many places or90Iinstitutions are named after persons, such as "Wash-ington" or "Madison", or, in some cases, vice-versa:"Ion Popescu Topolog" is the name of a Romanianwriter, who added to his name the name of the river"Topolog").Clearly, in many: cases, the context for only oneoccurrence of a new word and its morphological in-formation is not enough to make a decision.
But, asnoted in Katz (1996), a newly introduced entity willbe repeated, "if not for breaking the monotonous ef-fect of pronoun use~ then for emphasis and clarity".Moreover, he claims that the number of instances ofthe new entity is not associated with the documentlength but with the importance of the entity with re-gard to the subject/discourse.
We will use this prop-erty in conjunction with the one sense per discoursetendency noted by Gale, Church and Yarowsky(1992b), who showed that words strongly tend toexhibit only one sense in a document/discourse.
Bygathering contextual information about the entityfrom each of its occurrences in the text and usingmorphological c ues as well, we expect o classify en-tities more effectively than if they are considered inisolation, especially those that are very importantwith regard to the' subject.
When analyzing largetexts, a segmentation phase should be considered, sothat all the instances of a name in a segment havea high probability of  belonging to the same class,and thus the contextual information for all instanceswithin a segment c'an be used jointly when makinga decision.
Since the precision of the segmentationis not critical, a language independent segmentationsystem like the one presented by Amithay, Richmondand Smith (1997) is adequately reliable for this task.1.2 Tokenized Text  vs. P la in  TextThere are two basic alternatives for handling a text.The first one is to tokenize it and classify the in-dividual tokens or group of tokens.
This alterna-tive works for languages that use word separators(such as spaces or punctuation), where a relativelysimple set of separator patterns can adequately to-kenize the text.
The second alternative is to clas-sify entities simply with respect o a given startingand ending character position, without knowing theword boundaries, but just the probability (that canbe learned automatically) of a boundary given theneighboring contexts.
This second alternative worksfor languages like Chinese, where no separators be-tween the words are typically used.
Since for thefirst class of languages we can define a priori prob-abilities for boundaries that will match the actualseparators, this second approach represents a gener-alization of the one using tokenized text.However, the first method, in which the text istokenized, presents!
the advantage that statistics forboth tokens and types can be kept and, as the re-sults show, the statistics for types seem to be morereliable than those for tokens.
Using the secondmethod, there is no single definition of "type", giventhat there are multiple possible boundaries for eachtoken instance, but there are ways to gather statis-tics, such as considering what we may call "probabletypes" according to the boundary probabilities orkeeping statistics on sistrings (semi-infinite strings).Some other advantages and disadvantages of the twomethods will be discussed below.2 The  Bas ic  Mode lBefore describing the algorithm, we will present abrief overview of some of its goals:?
a language independent core model?
the ability to exploit basic language-specific fea-tures?
the ability to learn from small named entity lists(on the order of 100 total training names)?
the capability to handle both large and smalltexts?
good class-scalability properties (the possibilityof defining as many named entity types as de-sired, so that for different languages or differentpurposes the user can choose different classes ofwords to be recognized)?
the capability to store the information learnedfrom each instance for further useThree important concepts are used in our model:2.1 'rrie s t ruc tures  are used  for bothmorpho log ica l  and contextua lin fo rmat ionTries provide an effective, efficient and flexible datastructure for storing both contextual and morpho-logical patterns and statistics.
First, they are verycompact representations.
Second, they support anatural hierarchical smoothing procedure for dis-tributional class statistics.
We consider character-based tries, in which each node contains a probabil-ity distribution (when working with tokenized text,two distributions are considered in each node, one fortokens and one for types).
The distribution stored ateach node contain the probability of each name classgiven the history ending at that node.
Each distribu-tion also has two standard classes, named "question-able" (unassigned probability mass in terms of entityclasses, to be motivated below) and "non-entity'.To simplify the notations, we will refer to a startand end point bounded portion of text being ana-lyzed (in order to determine if it represents a namedentity or not) as a token.Two tries are used for context (left and right) andtwo for internal morphological patterns of tokens.Figure i shows an example of a morphological pre-fix trie, which stores the characters of tokens from91root )a c n# !
n r o iI I I I Ie d e u cI I I Ix # a # p e!
#eI#information stored in a node:character("#")raw distribution:quest I non-entity I person I place I instlist of  (right) context linksare#a#nice# \[Figure 1: Morphological prefix trie for "Alex andAnda are a nice couple"left to right from given starting points (with optionalword boundaries indicated by "#") .Suffix tries (typically more informative) haveequivalent structure but reversed irection.
The leftand right context tries have the same structure aswell, but the list of links refers now to the tokenswhich have the particular context represented by thepath from the root to the current node.
For rightcontext, the letters are introduced in the trie in nor-mal order, for left context hey are considered in thereversed order (in our example, "Anda" has as leftcontext "dna#xela#") .
Similarly, nodes of the con-text tries contain links to the tokens that occurredin the particular contexts defined by the paths.
Twobipartite graph structures are created in this way bythese links.For reasons that will be explained later, rawcounts are kept for the distributions.The probability of a token/context as being inor indicating a class is computed along the wholepath from the root to the terminal node of the to-ken/context.
In this way, effective smoothing is re-alized for rare tokens or contexts.Considering a token/context formed from charac-ters l l l2...ln, (i.e.
the path in the trie is root - ll -12 - ... - In) the general smoothing model is:nP(class~ltl l2.. .
In ) = ~ A~P(class3111t2...li),i=1nwhereas E \[O, 1\]and ~Ai=li=1It is reasonable to expect that smaller lambdasshould correspond to smaller indices, or even thatA1 _< A2 _< ... _< An.
In order to keep the number ofparameters low, we used the following model:F(class~llal2... ln) = ~F(class~llx )n+ ~ ?tn-iF(cclassj\[ l l l2""l i)i=2where a, ~ E (0, 1), ~ having a small valueThe symbol F is used instead of P since we haveraw distributions (frequencies) and a normalizationstep is needed to compute the final probability dis-tribution.A simpler model can use just one parameter (set-ting g = an), but this has limited flexibility in op-timizing the hierarchical inheritance - the probabil-ity of a class given the first letter is often not veryinformative for some languages (such as English orRomanian) or, by contrast, may be extremely im-portant for others (e.g.
Japanese).2.2 EM-s ty le  boots t rapp ingThe basic concept of this bootstrapping procedure isto iteratively leverage relatively independent sourcesof information.
Beginning with some seed names foreach class, the algorithm learns contextual patternsthat are indicative for those classes and then itera-tively learns new class members and word-internalmorphological c ues.
Through this cycle, probabil-ity distributions for class given token, prefix/suffixor context are incrementally refined.
More detailsare given when describing stage 2 of the algorithm.2.3 Unass igned  probab i l i ty  mass asopposed  to  the  c lass ica l  max imument ropy  pr inc ip leWhen faced with a highly skewed observed class dis-tribution for which there is little confidence due tosmall sample size, a typical response to this uncer-tainty in statistical machine learning systems is tobackoff or smooth to the more general class distri-bution, which is typically more uniform.
Unfortu-nately, this representation is difficult to distinguishfrom a conditional distribution based on a very largesample (and hence estimated with confidence) that92just happens to have a similar fairly uniform truedistribution.
One would like a representation thatdoes not obscure this distinction, and represents heuncertainty of the distribution separately.We resolve this lproblem while retaining a sin-gle probability distribution over classes by addinga separate "questi0nable" (or unassigned) cell thatreflects the uncertainty of the distribution.
Proba-bility mass continues to be distributed among theremaining class cells proportional to the observeddistribution in the :data, but with a total sum (< 1)that reflects the confidence in the distribution andis equal to 1 - P(q'uestionable).This approach as the advantage ofexplicitly rep-resenting the uncertainty in a given class distribu-tion, facilitating the further development of an in-teractive system, while retaining a single probabil-ity distribution that simplifies trie architecture andmodel combinatiofi.
Incremental learning essentiallybecomes the process of gradually shifting probabil-ity mass from questionable/uncertain to one of theprimary categories.3 The  A lgor i thmThe algorithm can!
be divided into five stages, whichare summarized below.Stage 0: build the initial training list of classrepresentativesStage 1: read the text and build the left and rightmorphological nd context riesStage 2: introduce the training information inthe tries and re-estimate the distributions by boot-strappingStage 3: identify and classify the named entitiesin the text using competing classifiersStage 4: update the entity and context rainingspace, using the new extracted informationStage O:This stage is performed once for each lan-gnage/task and cbnsists of defining the classes andfilling in the initial class seed data with examplesprovided by the user.
The list of class training namesshould be as unambiguous as possible and (ideally)also relatively common.
It is also necessary to have arelatively large unannotated text for bootstrappingthe contextual models and classifying new named en-tities.
Examples Of such training seeds and text forRomanian language are given in Tables 1 and 21 .
Forthe primary experiments reported in this paper, wehave studied a relatively difficult 3-way named entitypartition between:First (given) names, Last (family)names and Place 'names.
The first two tend to berelatively hard to distinguish in most languages.
A1The text refers %0 the mayor of a small town of Albacounty, who was so drunk while officiating at a wedding thathe shook the bride's hand and kissed the groom.simpler person/place-based distinction more compa-rable to the MUC-6 EMAMEX task is evaluated inTable 3(d).Tra in ing Data  (seed wordlists):F.NAME L.NAME PLACEAndreiAdamAlexandruAurelBogdanCosminConstantinC~t~linCostinClaudiuTableIliescuPopescuIonescuNituT~naseTudoseRotariuCiureaBucurGhermanAbrudAlba-IuliaAradBac~uBotosaniBucurestiBrasovBr~ilaBuz~uCalafath Sample training wordlists for RomanianTarget  Eva luat ion  Text(labels not used for training)Primarul comunei <place> Rosia Montane</place> judetul <place> Alba </place><fname> David </fname> <iname> Botar</iname> a intrat in legend~ datori%~ unorintimpl~ri de-a dreptul penibile, relatate in"Evenimentul zilei".
Practic, primul gospodaral celei mai bogate comune in aur din <p lace>Muntii Apuseni </p lace> este mai tot timpulbeat-crit~, drept pentru care, la oficierea uneic~s~torii, a s~rutat mina mirelui, a strins minamiresei si a intocmit certificat de deces in loculcelui de c~s~torie.
Recent, <fname> Andrei</fname> <iname> P~tunescu </iname> fiulpoetului, a intentionat s~ achizitioneze gospod~riaunei bucurestence care se stabilise de o vremein <place> Rosia MontanK </place> Laprim~trie ~ns~, turmentatul primar 1-a trimis pefiul lui <fname> Adrian </fname> <iname>P~unescu </ iname> s~-i cumpere ceva de b~ut,pentru a se putea concentra ~ndeajuns asuprahirtiilor tranzactiei imobiliare.<fname> LUCIAN </fname><iname> DOBRATER </iname>Table 2: Sample test data for RomanianStage 1:There are two ways to start this stage, either bytokenizing the text or considering it in raw form.When tokenization is used, each token is insertedin the two morphological tries: one that keeps theletters of the tokens in the normal (prefix) order,another that keeps the letter in the reverse (suffix)order.
For each letter on the path, the raw distribu-tions are changed by adding the a priori probability93Probability distribution order:node non- n a m e ~ ~I N 10.1,110.3810.2710.=1 0.2I\[ A 10.07110.0410.6310.2210.04 I\ [ i  Io.1511o.o31o.271o.551 o II u 10.07110.2210.5510.1210.04 \[I c 10.05110-2110.7010.031 0 II s Io.olll 0 10.99\] 0 I 0 II E lo l l  0 I a I0101 z~,~?"311??'
l?sTI ?
I ?
II E 10.99110;011 0 I 0 I 0 II T10.99110.011 o l 0101I s 10.99110.011 0 I 0 I 0 I("sterian" subtree)I L Io.,11 0 I 0 Io.s7\[ 0 \]I U Io.1311 0 I 0 10.87I 0 II f  10.1311 0 I 0 \[o.a71 0 \[("iulian" subtree)("-escu" subtree)Figure 2: An example of normalized but unsmoothed distributions from the suffix morphological trie forRomanian.
The paths shown are for Iulian, a "first name" entity, contained in the training word list; Ster/ana "last name", not in the training data; and a partial path for the tokens ending in -escu.of the token belonging to each class (language depen-dent information may be used here).
For example,in the case of Indo-European languages, if the tokenstarts with an upper-case l tter, we add 1 full count(all probability mass) to the "questionable" sum, asthis entity is initially fully ambiguous.
If the to-ken starts with lower-case (and hence is an unlikelyname) in this case we add the bulk of the proba-bility mass 6 (e.g.6 t> 0.9) to "non-entity" and theremainder (1-5) to "questionable" (otherwise unas-signed).
Other language-specific orthographic cluescould potentially affect his initial probability massassignment.When no tokenization is applied, we have to con-sider possible starting and ending points.
Therefore,the strings (which, for simplicity, we will refer aswell as tokens) introduced in the prefix morpholog-ical trie and the ones introduced in the suffix triemay differ.The left context of each token is introduced, let-ters in reverse order, in the left context rie, withpointers to the token in the morphlogical prefix trie;the right context of each token is introduced, in nor-mal order, in the right context rie, keeping pointersto the token in the suffix trie.
The distributionsalong the paths are modified according to the a pr/-ori distribution of the targeted token.Stage 2:This stage is the core bootstrapping phase of thealgorithm.
In essence, as contextual models becomebetter estimated, they identify additional named en-tities with increasing confidence, allowing reestima-tion and improvement of the internal morphologicalmodels.
The additional training data that this yieldsallows the contextual models to be augmented andreestimated, and the cycle continues until conver-gence.
One approach to this bootstrapping processis to use a standard continuous EM (Expectation-Maximization) family of algorithms (Baum, 1972;Dempster et al, 1977).
The proposed approach out-lined below is a discrete variant that is much lesscomputationally intensive, and has the advantageof distinguishing between unknown probability dis-tributions and those which are simply evenly dis-tributed.
The approach is conservative in that itonly utilizes the class estimations for newly classifieddata in the retraining process if the class probabil-ity passes a confidence threshold, as defined below.The concept of confidence threshold can be capturedthrough the following definitions of dominant andsemi-dominant.Let us consider a discrete finite probability distri-bution P = (Pl, ...,Pn).
We say that P has a domi-nant if there is an i in {1...n} such that pi > 0.5, orin other words ifn~Pj  <Pi-j=l94IWe say that P has an a-semi-dominant with re-spect to an event k, where a > 1, if it does not havek as dominant and there exist i in {1...n} such thatnj : ljCkA few commentsi about these definitions are nec-essary: it can be .easily observed that not everydistribution has a dominant, even though it has amaximum value.
The second definition, of a-semi-dominant, makes sense if we consider a particularevent k that is not relevant (or the result cannot bemeasured).
By rembving this event and normalizingthe rest of the values, we obtain a new distribution(of size n-l) having i an a-dominant.The core of stage 2 is the bootstrapping procedure.The known names (either from the original traininglist or otherwise learned data) are inserted sequen-tially into the morphological tries, modifying theprobability distributions of the nodes on the pathsaccordingly (the data structure is illustrated in Fig-ures 1 and 2) .
If the new distribution in one of thenodes on the path of a known token gains a dominant(for example "placer') then the effect of this change ispropagated by reestimating other node distributionsgiven this change.
Each distribution on the con-text paths in which that token occurred in the textis modified, by subtracting from the "questionable"mass a quantity proportional to the number of timesthe respective token was found in that context andadding it to the dominant-position (e.g.
"place")mass.
For the newly obtained distributions thatgained a dominant :(in our example "place") in thecontext rie, the bootstrapping procedure is calledfor all tokens that Occurred in that context, and soon, recursively.
Here it is very important hat weconsider aw distributions and not normalize them.For example, if word "Mariana" occurs x times withthe right context "merge" (meaning "goes") and thedistribution for "rhariana#" has now been identi-fied with the dominant "first name", then x unitsfrom the "questionable" mass can be moved to "firstname" mass along the path of "merge#" in the rightcontext rie.
If semi-dominants are used instead ofdominants then we have to account for the fact thatthe semi-dominants may change over time, so theprobability mass must be moved either from "ques-tionable" position Or previous semi-dominant posi-tion, if a semi-dominant s ate has been reached be-fore.It may be easily observed that stage 2 has a se-quential characteristic, because the updating is doneafter reading each name incrementally.
When us-ing dominants the Order does not affect the process,because of the face that once a dominant state isreached, it cannot change to another dominant statein the future (probability mass is moved only from"questionable").
In the case of semi-dominants, thedata ordering in the training file does influence thelearning procedure.The more conservative strategy of using domi-nants rather then semi-dominants has, on the otherhand, the disadvantage of cancelling or postponingthe utilisation of many words.
For example, if both"questionable" and "first name" have 49% of themass then subsequent reestimation iterations are notinitiated for this data, even though the alternativename classes are very unlikely.Considering those advantages and disadvantages,we used the less conservative semi-dominant ap-proach as the default model.Stage 3:In this stage the text is re-analysed sequentially,and for each token (given a start-end point pair)a decision is made.
Here the bipartite structureof the two pairs of tries has a central role: dur-ing stage 2, the left context and prefix tries inter-act with each other and so do the right context andsuffix tries, but there's no interference between thetwo pairs during the bootstrapping stage.
There-fore, for each instance of a token in the text, fourclassifiers are available, a different one given by eachtrie.
The decision with regard to the presence ofan entity and its classification is made by combin-ing them.
Comparative trials indicate that higherperformance is achieved by initially having the clas-sifters vote.
Results indicate that the most accurateclassifications are obtained from the two indepen-dently bootstrapped morphological tries (they incor-porate the morphological information about the to-ken to be classified, and, during the bootstrapping,they also incorporate information from all the con-texts in which the token occurred).
If the two agree(they have semi-dominants and they are the same)then the corresponding class is returned.
Otherwise,agreement is tested between other paired indepen-dent classifiers (in order of empirically measured re-liability).
If no agreement is found, then a simplelinear combination of all four is considered for thedecision.
This approach yields 6% higher F-measurethan the simple interpolation of classifiers for thedefault parameters.Stage ~ :The newly classified tokens and contexts are savedfor future use as potential seed data in subsequentnamed-entity classification on new texts.4 Resu l tsThe basic measures for evaluation of this work areprecision and recall.
Precision (P) represents thepercentage of the entities that the system recognized95which are actually correct.
Recall (R) representsthe percentage of the correct named entities in thetext that the system identified.
Both measures areincorporated in the F-measure, F = 2PR/ (P  + R).It would be inappropriate to compare the resultsof a language independent system with the ones de-signed for only one language.
As Day and Palmer(1997) observed, "the fact that existing systems per-form extremely well on mixed-case English newswirecorpora is certainly related to the years of researchand organized evaluations on this specific task in thislanguage.
It is not clear what resources are requiredto adapt systems to new languages.
"It is important o mention that the F-measure forthe human performance on this task is about 96%,(Sundheim 1995).
Our experiments on Romaniantext were consistent with this figure.4.1 Basel ine measuresIn order to obtain a baseline performance for thismethod we considered the performance of a sys-tem that tags only the examples found in one ofthe the original training wordlists.
We consider thisto be a plausible lower bound measure if the train-ing words have not been selected from the test text.Day and Palmer (1997) showed that a baseline F-measure score for the ENAMEX task varies from21.2% for English to 73.2% for Chinese.
It is im-portant o mention that, when they computed thesefigures, they trained their language independent sys-tem on large annotated corpora (e.g.
the Wall StreetJournal for English).The fact that the precision obtained by the base-line approach is not 100% indicates that the seedtraining names for each class are not completely un-ambiguous, and that a certain degree of ambiguityis generally unavoidable (in this case, mainly be-cause of the interference between first names andlast names).Another significant performance measure is forcedclassification accuracy, where the entities have beenpreviously identified in the text and the only task isselecting their name class.
To obtain baseline per-formance for this measure, we considered a Systemthat uses the original training word labels if there isan exact match, with all other entities labeled witha default "last name" tag, the most common classin all languages tudied.
The baseline accuracy wasmeasured at 61.18% for Romanian.
System accura-cies range from 77.12% to 91.76% on this same data.4.2 Eva luat ion  of  basic es t imat ion  methodsThe results shown in Table 3 were obtained for aRomanian text having 12320 words, from which 438were entities, using a training seed set of 300 names(115 first names, 125 last names, and 60 city/countrynames).The baseline measures and default system (a) areas described above.In configuration (b), the based parameters of thesystem have been optimized for Romanian, usinggreedy search on an independent development test(devtest) set, yielding a slight increase in F-measure.Configuration (c) used the default parameters, butthe more conservative "dominant" criterion was uti-lized, clearly favoring precision at the expense of re-call.Configuration (d), which is relevant for theENAMEX task, represents the performance of thesystem when classes "first name" and "last name"are combined into "person" (whenever two or moresuch entities are adjacent, we consider the wholegroup as a "person" entity).Configuration (e) shows contrastive performancewhen using standard continuous EM smoothing onthe same data and data structures.4.3 Eva luat ion  by language and knowledgesourceTable 4 shows system performance for 5 fairly di-verse languages: Romanian, English, Greek, Turk-ish and Hindi.
The initial 4 rows provide some basicdetails on the training data available for each lan-guage.
Note that when annotators were generatingthe lists of 150-300 seed words, they had access to adevelopment test from which to extract samples, butthey were not constrained to this text and could addadditional ones from memory.
Furthermore, it wasquite unpredictable how many contexts would actu-ally be found for a given word in the developmenttexts, as some appeared several times and many didnot appear at all.
Thus the total number of contex-tual matches for the seed words was quite variable,from 113-249, and difficult to control.
It is also thecase that not all additional contexts bring compa-rable new benefit, as many secondary instances ofthe same word in a given related document collec-tion tend to have similar or identical surroundingcontexts to the first instance (e.g.
"Mayor of XXX"or "XXX said"), so in general it is quite difficult tocontrol the actual training information content justby the number of raw seed word types that are an-notated.For each of these languages, 5 levels of informationsources are evaluated.
The baseline case is as previ-ously described for Table 3.
The context-only caserestricts ystem training to the two (left and right)contextual tries, ignoring the prefix/suffix morpho-logical information.
The morphology only case, incontrast, restricts the system to only the two (prefixand suffix) morphological models.
These can be esti-mated from the 3 training wordlists (150-300 wordstotal), but without an independent source of infor-mation (e.g.
context) via which bootstrapping caniterate, there is no available path by which these96RomanianPrecision Recall F-measure AccuracyBaseline: 98.67 34.02 50.58 61.18System Performance using:(a) default settings (using semi-dominants)(b) re-estimated smoothing parameters(c) learning wi~h dominants(d) ENAMEX~like "Person" / "Place" classes(e) continuous:EM approach76.9580.1791.0682.3874.0264.9962.9351.3869.5760.6470.4770.5165.6975.4366.6778.4978.9378.2691.7677.12Table 3: Comparison of the performance of basic estimation methods on RomaninanLanguage !
\[ Romanian  English Greek Turkish HindiTraining text siz~ 12320 15738 10445 5207 18806Total training seed words 300 190 210 150 150Contextual matches for seeds 149 205 113 133 249Labeled entities for testing 438 204 210 203 303Baseline:(Precision/Recal i//F-measure)Context Only:(Precision/Recal\]//F-measure)Morpho logy  Only:(Precision/Recall//F-measure)Context and Morphology:(Precision/Recal!//F-measure)Full bootstrapping:( Precision/ Recall / / F-measure )98.67 \] 34.0150.5896.59 \[ 19.4532.3873.79 \[ 52.9761.6778.381 53.0963.3076.95 I 64.9970.4783.33 \[ 12.2521.3682.35 I 6.8612.6784.42 \[ 31.8646.2682.95 \[ 35.7850.0083.67 \] 40.2054.30100 \[ 18.0930.6487.50 I 3.336.4278.35 I 36.1949.5177.06 I 40.0052.6676.47 \[ 43.3355.3286.66 \[ 19.2131.4553.331 11.8219.3575.32 \] 28.5741.4360.99 \[ 42.3650.006o.38 1 47.2953.0494.42 \] 20.2633.2384.21 \[ 9.5817.2089.01 I 24.2538.1281.37 I 24.8538.0783.04 I 27.8441.7061.18 62.74 55.23 I 61.08 \[ 61.79 Baseline classification accuracySystem classification accuracyTable 4: Comparison of performancemodels can learn the behaviour of previously unseenaffixes and conquer new territory.
Thus the modelis entirely static On just the initial training data.For the same reasOns, the context only model is alsostatic.
In this case there is a possible bootstrappingpath using alternating left and right context o ex-pand coverage to new contexts, but this tends to benot robust and wa s not pursued.
Interestingly, recallfor morphology only is typically much higher than inthe context only case.
The reason for this is that themorphology models are full hierarchically smoothedcharacter tries rather than word token tries, andhence have much '~ denser initial statistics for smalltraining data sets~ proving greater partial matchingpotential for previously unseen words.In an effort to I test the contribution of the fulliterative boostrapping, the "context and morphol-ogy only" results ', are based on the combination ofall 4 tries, but w:ithout any bootstrapping.
Thusthey are trained ekclusively on the 150-300 trainingexamples.
Performance for the combined sourcesby language and knowledge sourceis in all cases greater than for the morphology orcontext source used alone.
Furthermore, the full it-erative bootstrapping clearly yields substantial im-provement over the static models, almost exclusivelyin the form of increased recall (and its correspondingboost the the F-measure).Cross-language analysis yields further insight.First, recall is much higher for the 4 languagesin which case is explicitly marked and is a cluefor named entity identification (Romanian, English,Greek and Turkish) than for a language like Hindi,where there are no case distinctions and hence anyword could potentially be a named entity.
A lan-guage such as German would be roughly in the mid-dle, where lower-case words have low probability asnamed entities, but capitalized words are highly am-biguous between common and proper nouns.
Be-cause approximately 96% of words in the Hindi textare not named entities, without additional ortho-graphic clues the prior probability for "non-entity"is so strong that the morphological orcontextual evi-97806040200- - I  i x l  I~q"l/,/ , I  15~N '~ Nlk  2k 5k 10kSize of the raw text forbootstrapping (words)m~ B~m\ [ \ ]  PrecisionE\] Recall\ [ \ ]  F-measure8O60bb40 ~ \F xF20 t ~'.t ~F40 75 150 300Total number of  seednamesFigure 3: Learning curves for Romaniandence in favor of one of the named entity classes mustbe very compelling to overcome this bias.
With only50 training words per context this is difficult, and inthe face of such strong odds against any of the namedentity classes the conservative nature of the learningalgorithm only braves an entity label (correctly) for38% more words than the baseline model.
In con-trast, its performance on entity classification ratherthan identification, measured by forced choice accu-racy in labelling the given entities, is comparable toall the other languages, with 79% accuracy relativeto the 62% baseline.
24.4 Evaluation at different training set sizesFigure 3 demonstrates that the performance of thealgorithm is highly sensitive to the size of the train-ing data.
Based on Romanian, the first graph showsthat as the size of the raw text for bootstrappingincreases, F-measure performance increases roughlylogrithmically, due almost exclusively to increasesin precision.
(Approximately the same number ofunique entities are being identified, but due to theincreased number of examples of each, their classi-fication is more accurate).
This is avery encour-aging trend, as the web and other online sourcesprovides virtually unlimited raw text in most majorlanguages, and substantial on-line text for virtuallyall languages.
So extrapolating far beyond the 10Kword level is relatively low cost and very feasible.The second graph shows that F-measure perfor-mance also increases roughly logrithmically with thetotal length of the seed wordlists in the range 40-300.
This increase is due entirely to improved recall,which doubles over this small range.
This trend sug-2Note again that this baseline is more competitive thantypical, as it not only assigns the majority tag ("last name"),but when there is an exact match with the training wordlist(e.g.
"deepak"), a common occurrence given repeated high-frequency names in the Hindi data, the training classificationis used as the baseline answergests that there is considerable benefit o be gainedby additional human annotation, orseed wordlist ac-quisition from existing online lexicons.
However, rel-ative to case of raw text acquisition, such additionalannotations tend to be much costlier, and there isa clear cost-benefit tradeoff to further investment inannotation.In summary, however, these evaluation results aresatisfying in that they (a) show clear and consistenttrends across several diverse languages, (b) showclear trends for improvement as training resourcesgrow, and (c) show that comparable (and robust)classification results can be achieved on this diver-sity of languages.5 Future  workFor future work, natural next steps include incorpo-rating a language independent word segmentationphase like the one proposed by Amitay, Richmondand Smith (1997), to improve the performance onlarge texts.
Different statistics can be pre-computedfor different languages and language families andstored in external files.
For example, the a prioriprobability of a named entity given the set of charac-teristics of its representation in the text, such as po-sition, capitalization, and relative position of otherentities (e.g.
: first name followed by last name).
Afurther step is the implementation f a supervisedactive learning system based on the present algo-rithm, in which the most relevant words for futuredisambiguation is presented to the user to be classi-fied and the feedback used for bootstrapping.
Theselection of candidate examples for tagging would bebased on both the unassigned probability mass andthe frequency of occurrence.
Active learning strate-gies (Lewis and Gale, 1994) are a natural path forefficiently selecting contexts for human annotation.986 ConclusionThis paper has presented an algorithm for the mini-mally supervised learning of named entity recogniz-ers given short name lists as seed data (typically 40-100 example wordS per entity class).
The algorithmuses hierarchically ismoothed trie structures for mod-eling morphological nd contextual probabilities ef-fectively in a language independent framework, over-coming the need for fixed token boundaries or his-tory lengths.
Th e combination of relatively indepen-dent morphological nd contextual evidence sourcesin an iterative bootstrapping framework convergesupon a successful inamed entity recognizer, achiev-ing a competitive 70.5%-75.4% F-measure (measur-ing both named entity identification and classifica-tion) when applied to Romanian text.
Fixed k-wayclassification accuracy on given entities ranges be-tween 73%-79% on 5 diverse languages for a dif-ficult firstname/l~stname/place partition, and ap-proaches 92% accuracy for the simpler person/placediscrimination.
These results were achieved usingonly unannotated training texts, with absolutely norequired language-specific information, tokenizers orother tools, and requiring no more than 15 minutestotal human effort in training (for short wordlistcreation) The observed robust and consistent per-formance and very rapid, low cost rampup across 5quite different languages shows the potential for fur-ther successful and diverse applications of this workto new languages and domains.7 AcknowledgementsThe authors would like to thank Eric Brill, RaduFlorian, Shankar Kumar, Murat Saraclar, DimitraVergyri and Jun Wu for both their feedback on thiswork and their help in annotating the named-entitydata for the languages studied.Re ferences  :Amithay, E., K. Richmond , and A. Smith.
1997.
De-tecting Subject Boundaries within Text: A Lan-guage Independent Statistical ApproachIn Pro-ceedings of the Second Conference on EmpiricalMethods in Natural Language Processing, pp.
47-54.Aone, C., S. Benett, and C. Lovell, 1997.
Learningto Tag Multilingual Texts Through Observation.In Proceedings of the Second Conference on Em-pirical Methods in Natural Language Processing,pp.
109-116.Baum, L. 1972.
An Inequality and Associated Max-imization Technique in Statistical Estimation ofProbabilistic Functions of a Markov Process.
In-equalities, 3:1-8.Choi, M., Y. Ravia, and N. Wacholder.
1997.
Disam-biguation of Proper Names in Text.
In Proceedingof the Fifth Conference on Applied Natural Lan-guage Processing, pp.
202-208.Day, D., and D. Palmer.
1997.
A Statistical Pro-file of the Named Entity Task.
In Proceedings ofthe Fifth Conference on Applied Natural LanguageProcessing, pp.
190-193.Dempste.r, A., N. Laird and D. Rubin.
1977.
Max-imum Likelihood from Incomplete Data Via theEM Algorithm.
Journal of the Royal StatisticalSociety, 39:1-38.Gale, W., K. Church and D. Yarowsky.
1992.
AMethod for Disambiguating Word Senses in aLarge Corpus.
Computers and the Humanities,26(5):415-439.Gale, W., K. Church, and D. Yarowsky.
1992b.
OneSense per Discourse.
In Proceedings of the 4thDARPA Speech and Natural Language Workshop,pp.
233-237.Gale, W., K. Church and D. Yarowsky.
1995.
Dis-crimination Decisions for 100,000 DimensionalSpaces.
Annals of Operation Research, 55:323-344.Katz, S.M.
1996.
Distribution of Context Words andPhrases in Text and Language Modeling.
NaturalLanguage Engineering 2(1):15-59.Lewis, D. and W. Gale.
1994.
A Sequential Algo-rithm for Training Text Classifiers.
In Proceedingsof SIGIR'94, pp.
3-12, Dublin.Sundheim, B.M.
1995.
Overview of Results of theMUC6 Evaluation.
Proceedings of the Sixth Mes-sage Understanding Conference, pp.
13-31.Yarowsky, D. 1995.
Unsupervised Word Sense Dis-ambiguation Rivaling Supervised Methods.
Pro-ceedings of the 33rd Annual Meeting of the Associ-ation for Computational Linguistics, pp.
189-196.99
