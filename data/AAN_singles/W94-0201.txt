AUTOMATED TONE TRANSCRIPT IONSteven  B i rdUniversity of Edinburgh,  Centre for Cognit ive Science2 Buccleuch Place, Edinburgh,  EH8 9LW, UKInternet:  S teven .
B i rd ied .
ac .
ukAbst rac tIn this paper I report on an investigation i to thcproblem of assigning tones to pitch contours.
Theproposed model is intended to serve as a tool forphonologists working on instrumentally obtainedpitch data from, tone languages.
Motivation andexemplification for the model is provided by datataken from my fieldwork on Bamileke Dschang(Cameroon).
Following recent work by Libermanand others, l provide a parametrised F0 predictionfuuction ~o which generates F0 values from a tonesequence, and I explore the asymptotic behaviourof downstel,.
Next., i observe that transcribing asequence X of pitch (i.e.
F0) values amounts to fin-dil~g a tone sequence T such that P(T) ~ X. Thisis a combimttorial optimisation problem, for whichtwo non-deterministic search techniques are provi-d~d: a genetic algorithm and a simulated annea-Iblg algorithm.
Finally, two implementations--Oll,~ for each technique~are d scribed and thenco,npared using both artificial and real data fors~.quences of up to 20 tones.
These programs canbe adapted to other tone languages by adjustingtiw F0 predh:tion function.INTRODUCTIONTim wealth of literature on tone and intonationhas amply demonstrated that voice pitch (F0) insp,~ech is umier independent linguistic ontrol.
InEnglish, w,h'e pitch alone can signal the distin-cthm bctwccu a st~ttement and a question.
Si-milarly, in many tone languages,voice pitch alonesiglmls the tense of a verb.
Phonologists usuallyd,~scribe a pitclf contour nmch as they describesp~ech more generally, namely as a sequence ofdiscrete units (i,e.
a transcription).
This is illu-strated in Figure 1, where L indicates a low tonea~Jd ~.H indicates a downstepped high tone.
Thequestion addressed in this paper concerns how weshould relate pitch contours to tone sequences.This paper is divided into four main sections,smnmarised in turn below.Tone Transcr ipt ion In this section I present theproblem of relating sequences of F0 values toton~ transcriptions.
I argue that Hidden Mar-kov Models are unsuited to the task and I de-monstrate the importance of having a compllta-tional tool which allows phonologists o experi-ment with F0 scaling parameters.Fo Scaling This section gives a mathematicalbasis for a general approach to F0 scaling which,it is hoped, will be applicable to any tone lan-guage.
I derive an F0 prediction function fromfirst, principles and show how the model of Li-berman et al (1993) for tile Nigerian iangu:~geIgbo is a special case.Tone and Fo in Bamileke Dschang Here Ipresent some data from my own fieldwork andgive a statistical analysis, using the same tech-nique used by Liberman et al I then show howthe general model of the previous ection is in-stantiated for this language.
This demonstratesthe versatility of the general model, since it canbe applied to two very different one languages.Imphunentat lons This section provides twonon-deterministic te hniques for transcribing anF0 string.
The first method uses a genetic algo-rithm while the second method uses simulatedannealing.
The performance ofboth implemen-tations is evaluated and compared on a rangeof artificial and real data.
Finally, I give someexamples of multiple, automatically-generatedtranscriptions of the same F0 data.TONE TRANSCRIPT IONGenerat ion  and  Recogn i t ionA prot nising way of generating contours from tonesequences is to specify one or more pitch tar-gets per tone and then to interpolate between thetargets; the task then becomes one of providinga suitable sequence of targets (Pierrehumbert &Beckman, 1988).
It is perhaps less clear how weshould go about recognising tone sequences frompitch contours.
Hidden Markov Models (HMMs)IIz200t50i00\]/.
* ?
":~.x.., j/'k"'~@.SH L ,I.H L SH L SH L SH L SH L SH L $H 1, SH I.,m3 mb3 m3 mb~ m~ tuba nu) mb~ 1113 mb~ m~ mb~ m~ lab3 m~ ml)3 m3 lab:)Figure 1:F0 Trace for Bamileke Dschang Utterance: 'child and child and ... '(Huang et al, 1990) offer a powerful statistical ap-proach to this problem, though it is unch:ar howthey could be used to rccognise the units of in-terest to phonologists, ttMMs do not encode ti-ming information in a way that would allow themto output, say, one tone per syllable (or vowel).Moreover, the same section of a pitch contour maycorrespond to either H or L tones.
For example,a H between two Hs looks just like an L betweentwo Ls.
There is no principled upper bound onthe amount of context that needs to be inspec-ted in order to resolve the ambiguity, lea(ling toa multiplication of state information required bythe HMM and problems for training it.In the present context, the emphasis is noton automatic speech recognition but on a tool tosupport phonologists working with tone.
As weshall see in the next section, once the phonologisthas identified the salient location to measure the'F0 value' of a syllable (or some other phonologi-cal unit), the task will be to automatically map astring of these values to a string of tones.A Too l  for  Phono log is tsConnell and Ladd have devised a set of heuristicsfor identifying key points in an F0 contour to re-cord F0 values (Connell & Ladd, 1990, 21If).
Inthe absence of a program which enshrines theseheuristics, it was decided to develop a system forproducing a tone transcription from a sequence ofF0 values.
Apart from the obvious benefits of au-tomating the process, such as speed and accuracy,it ~'ould show up cases where there is more thanone possible tone transcription, possibly with dif-ferent parameter settings for the F0 scaling fun-ction.
Having the set of tone transcriptions thatare compatible with an utterance has consideral,levalue to an analyst, searching for invariances in I.hetonal assignments o individual morphenaes.To exemplify this point, it is worth conskteringa recent example where an alternatiw~ transcrip-tion of some data proved valuable in providing afresh analysis of the data.
In their analyses of tonein Bamileke Dschang, Hyman gives tile transcrip-tion in (la) while Stewart gives the one in (lb),for the phrase meaning machete of dogs.
(1) a. flJai mSmSbhd - -  (Hyman, 1985, 50)b. J~Jai't' SmSmbh6-  (Stewart, 1993, 2(10)These two possibilities exist because of different F0scaling parameters.
These parameters deternfinethe way in which the different tones are scaledrelative to each other and to the speaker's pitchrange.
This is illustrated in (2), adapting Hyman'searlier notation (Hyman, 1979).
(2) a. Hyman: flJli m~m,l.bhti.fl p l  f mo $ mbhfiL L H L ./.
It3 3 l 3 10 0 0 0 1 13 3 1 3 2b.
Stewart: ~lpi't" SmSmbh4p l  J" f $ mb mbhfiL L "t H .1.
L H2 2 1 2 l1 1 0 0 1 t I3 3 1 3 2Example (2) displays a kind of phonetic inter-pretation function.
Immediately below the tworOWS o f  tOllC'S we see a row o f  in l lnbers  correspon-ding to the tones.
For Hyman, L=3 and H=I ,while for Stewart, 1,=2 and H=I.
Observe in Hy-nllUi'S example that a rising tone.--synlbolised byawedge abow: the i .--.is modelled as all btl scquencl:in keeping with standard practice in African toneanalysis.The second row of numbers corresponds to do-wnstep (.1.)
and upstep ('1").
For Hymart's model,this row begins at 0 and is increased by 1 for eachdownstep encountered.
For Stewart's model, thisrow begins at.
1 and is increased by 1 for each do-wnstep encountered and decreased by 1 for eachupstep encountered.
The two rows are summedvertically to give the last row of numbers.
Ob-serve that the last rows of Stewart's and Hyman'smodels are identical.The parameter which distinguishes the twoapproaches i partial vs. total downstep.
Hymantreats Dschang as a partial downstep language,i.e.
where .I.H appears as a mid tone (with respectto the material to its left).
Stewart treats it as atotal downstep language, i.e.
where ~H appears asan I, tone (with:respect to the material to its left).While Hyman and Stewart present rather dif-ferent analyses of rather different looking tran-scriptions, we can see that they are really analy-zing the same data, given the above interpretationfunction.
Therefore, phonologists who do not wishto limit themselves to the transcriptions which re-suit from certain parameter settings in the pho-netic interpretation function would be better offw,,rkiug directly with number sequences like thelast row in (2).
This paper describes a tool whichlets them do just that.Fo SCAL INGC, onsider again the F0 contour in Figure 1.
Inparticular, ilote that the F0 decay seems to be toa non-zero asymptote, and that H and L appear tohave different asymptotes which we symbolise as hand I respectively.
These observations are clearerin Figure 2, which (roughly speaking) displays thepeaks and valleys from Figure 1.Although this is admittedly a rather artificialex:unple, it remains true that there is no princip-h,,I upper limit ou the number of downsteps thatC;i.II oCcllr in an utterance (C.\]eluents, 1979, 540),lul, I so the a.sytnptotic behaviour off Fll scaling stillIIC,'ds I.o I)c addressed.NOw Sul)pose tllat we have a sequence T oft(mcs where ti is the ith tone (H or L) and a se-quence X of F0 values where xi is the F0 valuecorresponding to ti.
Then we would like a formulawhich predicts xi given xi-1, ti and ti-x (i > 1).We express this as follows:Hz200150100v ~I I,i';?IENI) I- -=11Figure 2: Asymptotic Behaviour of F0?
i = P , , - , , , (~ i -dThe question, now, is what should this functionlook like?
Suppose for sake of argument that theratio of L to the immediately preceding tt in Fi-gure 2 is constant, with respect to the baselinesfor H and L, namely h and I.
Then we have:xi -- l- -  Cxi-x - hMore generally, suppose that we have a sequenceof two arbitrary tones.
Ignoring the possibility ofdownstep for the present, we have a static two-tone system where HH and LL sequences are leveland sequences like HLHLHL are realised as simpleoscillation between two pitches.
We can write thefollowing formula, where \[i = h if tl = H andti = l ifti = L .Xi  - -  t iX i -1  - -  t i -1x i  --  t'i--1 'Xi--1The situation becomes more interesting when weallow for downdrift and downstep.
Downdrift isthe automatic lowering of the second of two H to-nes when an L intervenes, so HLH is realised as\ [ - - \ ]  rather than as \[-_-\], while downstcp is thelowering of the second of two tones when an inter-vening l, is lost, so HI.H is rea.lised as \[ \] (llyman& Schuh, 1974).
Bamileke l)schang has downstepbut m>t downdrift while lgbo has downdril't butonly wiry limited downstep.
Now we deline ti = hiftl  --I\[, ,IH and ii = l ift i  =L, ,I.L.
Generalisingour equation once more, we have the following,where R is a factor called the transition ratio.zi - / i  /'i R $- t i - l t lX i - -1  - -  t i - -1  ~i- -1Zl : ~t i _ , t i (X i - -1 )  --  - -R t i _ , t l .
x i -1t i -1+ ti(1 - Rt,_,t , )Now I shall show how this general equation relatesto the equations for \[gbo (Liberman et al, 1993,151 ), reproduced below:(3) HH xi = x i -  1HL xi = ( l " l /h )x i_ l  + l(1 - F)LH xi = (h./ l)xi-1LL xl = Fx i -1  + l(1 - F)ItSH xi = Oxi - I  + h(1 - D)P can be instantiated to the set of equations in(3) by setting R as follows:tit~_~ H L SH \] 0 < F < lI H' $I~ 1 F l  F D_ I 0<D<IIt will be helpful to introduce one more levelof generality.
P relates adjacent F0 values, butwe would also like to relate non-adjacent values,given the sequence of intervening tones.
Supposethat T = t0 ?
- ?
t,~ is a tone sequence where the F0value of to is x.
Then we shall write the F0 valueof tn as PT(X).
By repeated applications of 'P  wecan write down the following expression for 'PT:"Pr(x) = ~RT.X  ?t .
(1  - RT)where RT = YI~=i Rtk_~th, n > 2.
Now, supposethat S = so" ' sm and T = to" .
tn  are tone se-quences and that s0 =/0 ,  .sin = t'n and T~.s = T~T.Then it is straightforward to show that Rs  = RT.Notice also that if 7~T(X) = x for all x and iff0 = t-~ then RT = 1.
These results will be usefulin the next section.Finally, it is worth comparing ~ with Hyman'sand Stewart's interpretation functions which wereillustrated in (2).
As pointed out already, Hy-man's is a partial downstep model while Stewart'sis a total downstep model.
Partial and total down-step can be visualised as follows, where the dottedlines indicate the abstract register inside which to-nes are scaled, and where downstep corresponds tolowering of the register.Partial downstep Total downstep: n. .
.
.
.
.
.
: H - : H: .
.
.
.
.
.
.
.
.
.
.
.
.
.Observe that for partial downstep, it.
is necessaryto have two downsteps before a high tone is atthe level of a preceding low, while for total do-wnstep, it is only necessary to haw, a single do-wnstep for a high tone to be at the same level asthe preceding low.
We can express these obser-vations about partial and total dowustep in themodel as follows.
For partial downstep, we have'Pt.$tt4U(Z) = x while for total downste i) we have'PL~.H(X) = x.
For both of these equations we :ireforced to have h = I which does not semn to be em-pirically justifiable in view of the data in Figur, l.It might be argued that this indicates a flaw iu I.hemodel being presented here, since partial and totaldownstep are widely attested in the literature ontone languages.
Unfortunately, it is not possiblein general to provide a model for partial or totaldownstep which permits distinct asymptotes for Itand L J  Therefore, to the extent that Figure I istypical of tone languages in having dilferent H a .dL asymptotes, one must conclude that total andpartial downstep are qualitative tern,s only.
Ihr-wever, they may yet re-emerge in the ,nodel undera different guise, as we shall see later.The effect of the distinction between partialand total downstep is to allow different ranscrip-tions of the same string, as we saw in (2).
Ingeneral, we have the following mappiug betweentranscriptions under the two views of downstep:(4) partial totalHH - -  HHHL - -  HALLH - -  LtHLL ~ LLH.IJi - -  H.I.Hpartial totalL~H ~- LHL.I.L - - L.I.
I,HtH H'tHHtL -- HI,LtL LtLIt is clear that changing from one view of down-step to the other amounts to adding and deleting $and t while leaving the tones themselves unchan-ged.
Thus, the model admits both transcriptionschemes that result from the two views of down-step, and another besides, as shown later in (7).This concludes the discussion of the F0 pre-diction function.
In the next section i shall inve-stigate the phonetic interpretation of tone in Ba-mileke Dschang, and determine the values of R forthis language.tTo see why this is so for the case of total down-step, suppose that such a model did exist, and so I < h.Let x E \[1, h), a valid F0 value for a low tone.
Now,whatever interpretation function 'P' we use, wc stillrequire that "PL4H(X) = x by definition of total down-step, which means that there is now a high tone witha F0 value less than h. But h is tile asymptote belowwhich no high tones should ever be realised, and so wehave a contradiction.
The case for partial downstepfollows similarly.TONE AND Fo INBAMILEKE DSCHANGIn a recent fiekl trip to Western (',ameroon tostudy the Bamileke Dschang ~ noun associativeconstruction, I was able to collect a small amount,of data relating to F0 scaling throughout a par-ticular informant's pitch range.
Following Liber-man et al, voice pitch was varied by getting theinformant to speak at different volmnes and byadjusting the recording level appropriately.
Ho-wever, rather than asking the informant o ima-gin,: speaking to a subject at different distances,I controlled the volume by having the informantwear headphones and played white noise from adetuned radio.
Thus, I could set the informant'svoice pitch by using the volume control on my ra-dio.
My hypothesis i that this technique producesmore consistent volume (and hence, pitch scaling)over long utterances and may make informants lessself-conscious about speaking loudly than simplyasking them to imagine speaking to subjects atvarious distances away.
Measurements were takenfrom the following data.
(5) HH d 3u5 sS1) t6 VI~U:5 t5 o t6 n3t~5 tdO t6nSu3 kd.p t?~ nStt3 k ipHe s ,w the bird before, he saw the hat beforehe saw the b~r~k'et before he saw the pipebefore he saw the cupLL  ~tp/lk - -  side, halfL~LH, HL~5 rob5 ~$s5 mb5 ... ~5jealousy and jealousy and ... jealousy15~p5 mb5 155p5 mb5 ... 15.l.pabreast and breast and ... breastmb.l.vt~t rob5 mbSvt~t rnb5 ... mbSv~toil and oil and ... oil$m5 rob5 ,~m5 rob5 ... $m5child and child and ... childII,egrettably, the LL data was only availablefr, ,n isolat,,, I disyllal des, and other sequences sucha.~ IAI and 115It were not available at all.
ttowever,from the F0 data for the above utterances we canhypothesise the behaviour of these unseen sequen-ces, and this can be tested in subsequent empiricalw,,rk.
The r,'sults for utterances involving HH andLI, sequences are displayed in Figure 3, while re-suits for L.~II and HI, are displayed in Figure 4.The regression equations obtained from thesedata are displayed in (6), where the number of oc-2Bamileke Dschang is a grassfields Bantu languagespoken in the Western Province of Cameroon.
Thename 'Bamileke' (pron: \[ba'mileke\]) represents bothau e~,hnic grouping and a language cluster; Dschang(pron: \[tfmJ\]) is an important .own around which oneof the Bamileke languages i spoken.
The data here isfrom the Balbu dialect.x,(Hz)200150100I,EG END .~-o - -o = I !11  o 1?
= LL ?~oo~?Q 0 0100 150 200 Xi_l(HZ )Figure 3: Plot of x/-1 vs x / for  HH, LL200150100LEGEND ~ ~ /.=HL ~100 150 200 z/_l(Hz)Figure 4: Plot of x/-1 vs x/ for L~H, HLcurrences of each tone sequence is given in paren-theses after the sequence.
The third column givesthe standard error for the gradient and intercept.
(6) 'l'one Regression Standm'dSequence Equation l_~\]rrorI il l (119) x~ = 0.99xi_l + 0.91 0.012, 5.0I,L (l l) x, = 1.02xi_\] - 1.39 0.057, 3.6IlL (40) x~ = 0.65x~_~ + 25.0 0.015, :3.1I,~H (38) x~ = 1.10xi_~ + 0.54 0.026, 4.3From this, we conclude that.
HL is the only se-quence with an intercept significantly differentfrom zero, and that x{ = x{-1 for HH and LLsequences.
We also conclude that .RHH : .RLL =RL.tH = 1, ( l /h = 1.1) and RHL = 0.72.
This lastvalue will be referred to as the quantity d. Wealso see that I -- 88Hz and h = 96Hz.
Fortuna-tely, these figures are sufficient to determine theR values for all other pairs of tones in BarnilekeDschang.A further observation is that BamilekeDschang does not have downdrift, and so thereis no F0 difference across HLH and LHL sequen-ces.
This is evident in Figure 5.
Therefore, wecan write PHLH(X) = X, and by a result we sho-wed above, RHL.RLH = 1.
Given that RHL = d itfollows that RLH = ~.Concerning downstep, I shall assume that themagnitude of downstep is independent of the toneson either side, and so ~OHL4H = 'PH$H ---- "\])LSL ----~LII.I.L.
A separate instrumental study supportsthis hypothesis t(Bird & Stegen, 1993).
Therefore,we lave l~st = 7Pt,s.Lt -- dRstt, where s is any toneand t is 1I or L.Finally, it is itnportant o briefly consider up-step,  since it has been used in some analyses ofBanfileke Dschang (e.g.
Stewart's).
Given that up-step and downstep are intended as inverses of eachother, we have the identities 79~4t,rt = "Pat = P~'rt~.t,with ~, t as before.
We now have a complete tablefor R:titi-1 H L SH SL I"H TL In,$n ,~n 1 d d d z d -~ 1 !L ,$L ,~L  d -1 1 1 d d -2 d -1Observe the symmetries in this table.
The confi-guration of four R values that we find when ti isnot downstepped or upstepped (the first two co-hmms) is reproduced in the columns for downstep(multiplied by d) and in the columns for upstep(divided by d).Note also that the above table is dependentupon how the data in (5) was transcribed.
Sup-pose that we had not used repetitions of HLSH(a transcription scheme based on partial down-step) but HSLH (a scheme based on total down-step).
Then we would have had RH4L = d and/'~.LH ---- 1.
Accordingly, the table for R would beas follows:t i -t  H L $H SL tH TTLH, SH, I"H 1 1 d d d -1 d -1L, SL, tL 1 1 d d d -1 d -xThe fact that we have two possible tables forR is no cause for alarm.
Recall that the transitionbetween two tones ti-1 and ti also involves thefactor {i/\[i-x.
This factor is manifested in tonetransitions according to the following pattern:titi- 1 H L SH SL tH I"LII, SH, I"H 1 l /h 1 l/h 1 l/hL, SL, ~L h/l 1 h/l 1 h/l 1I therefore conclude that the presence of morethan one table for R indicates an interplay bet-ween R values and the ratio h/l.
This raises aninteresting question.
Suppose we have two tonesequences T = t0 .
.
.
t ,  and 7 '~ = t~.
.
.
t~,  and twointerpretation functions "it:' and P '  based on R andR ~ respectively.
Then under what circumstances isthe phonetic interpretation of both sequences thesame under their respective interpretation fimc-tions?
A sufficient condition for them to be thesame is that \[i tr~ and that Rt~_,t, = = R 'q_ , , : .The reader can check that these conditions aremet by the mapping in (4) and the two tables fi:)rR given above.
Note that this observation h,,hlsfor the model in general, not just for the specia-lised version of the model as applied to Bamih'keDschang.It can also be shown that R is completely de-termined once RHL is specified.
A possible charac-terisation of total vs. partial downstep now arises:if RHL = 1 then we have total downstep, but ifRHL = d < 1 then we have partial downstep.However, the interpretation of these terms mustnecessarily be different from the standard inter-pretation, since I have shown that the standardinterpretation is not compatible with the presentmodel.This concludes the discussion of F0 scaling inBamileke Dschang.
I shall now present he imple-mentations.IMPLEMENTATIONSIn this section, I show how it is possible to gettwo programs to produce a sequence of tones T(i.e.
a tone transcription) given a sequence of nF0 values X.
The programs make crucial use ofthe prediction function "P in evaluating candidatetone transcriptions.Both programs involve search, and in general,the aim in searching is to discover tile values forxl, .
.
.
,  xn so as to optimise the value of a specifiedevaluation fimction f (x l , .
.
.
, xn ) .
When f hasmany local optima, deterministic methods uch ashill-climbing perform poorly.
This is because theyterminate in a local opt imum and the particularone found-depends heavily on the starting point inthe search, and there is usually no way of choosinga good starting point.Exhaustive search for the global optimum isnot an option when the search space is prohibi-tively large.
In the present context, say for asequence of 20 tones, the search space contains6 ~?
~ 10 is possible tone transcriptions, and foreach of these there are thousands of possible pa-rameter settings, too large a search space for ex-haustive search in a reasonable amount of compu-6150100"X%JH Lso~ mb~H L H L H L Hsoo mb~ sol 3 mb:) soo mba sayFigure 5:F0 Trace for 'bird and bird and ... 'L Hmba s~ration time.Non-determin is t i c  search methods  have beendevised as a way of tackling large-scale combinato-rial optimisation problems, problems that involvefin(ling optima of functions of discrete variables.
'I'hcse methods are only designed to yield an ap-proximate solution, but they do so in a reasona-ble amount of computation time.
The best knownsuch methods are genetic search (Goldberg, 1989)and annealing search (van Laarhoven & Aarts,1987).
Recently, annealing search has been suc-cessfully applied to the learning of phonologicalconstraints expressed as finite-state automata (El-lison, 1993).
In the following sections I describe agenetic algorithm and an annealing algorithm forthe tone transcription problem.A Genetic AlgorithmFor a cogent introduction to genetic search and anexplanation of why it works, the reader is referredto (South et al, 1993).
Before presenting the ver-sion of the algorithm used in the implementation,!
.~hall informally define the key data types it usesah,ng with tim standard operations on those types.g,,ne A line;at encoding of a solution.
In the pre-sent setti,Lg, it is an array of n tones, where eachtone is oim of H, SH, TH, L, SL or tL.
A genealso contains 16 bit eucodings of the parametersh, l and ,I.
These encodings were scaled to befloating i)oint numbers in the range \[90,110\] for/,, \[70, I0,)\] for t and \[0.6, 0.9\] for d.gene pool  An array of genes, P. One of the see-arch parameters i the size of P, known as thepopu lat ion .
The gene pool is renewed each gene-ration, and the number of generations i  anothersearch parameter.eva luat ion A measure of the fitness of a gene asa solution to the problem.
Suppose that X isthe sequence of F0 values we wish to transcribe.Suppose also that T is a particular gene.
Thethe evaluation function is as follows: "x(T) = !
- x,?n/ - -2crossover This is an operation which takes twogenes and produces a single gene as the result.Suppose that A = a l " -an  and B = b l .
.
.b , .Then the crossover function Cr is defined as fol-lows, where r is the (randomly selected) crosso-ver  po in t  (0 < r < n) .Cr (a l  .
.
.
a ra r+ l  " "a ,~,b l  " "b rbr+ l  " "bn)-- a l  " "a rbr+ l  " "bnIn other words, the genes A and B are cut ata position determined by r and the first part ofA is spliced with the second part of B to createa new gene.
Crossover builds in the idea thatgood genes tend to produce good offspring.
Tosee why this is so, suppose that the transcrip-tioln contained in tile first part of A is relativelygood while the rest is poor, while the trallscrip-tion contained in the first part of B is poor andthe rest is relatively good.
Then the off,springcontaining the first part of A and the secondpart of B will be an improvement on both Aand B; other possible offspring from A and Bwill be significantly worse and may not surviveto the next generation.
The program performsthis kind of crossover for the parameters h, land d, employing independent crossover pointsfor each, and randomising the argument orderin C',.
so that the high order bits in the offspringare equally likely to come from either parent.An extension to crossover allows more than onecrossing point.
The current model permits anarbitrary number of crossing points for crossoveron the transcription string.
The resulting geneis optimal since we choose the crossing points insuch a way as to rninimise (~t i _ l t i (X i -1 )  - -  Zi) 2at each position.
In developing the system, ex-ploiting the decomposability of the ewduationfimction in this way caused a significant impro-vement in system performance over the versionwhich used simple crossover.breeding For each generation, we create, a newgene pool from the previous one.
Each new geneis created by mating the best of three randomlychosen genes with the best of three other ran-domly chosen genes.mutat ion  In order to maintain some genetic di-versity and an element of randomness throug-hout the search (rather than just in the initialconfiguration), a further operation is applied toeach gene in every generation.
With a certainprobability (known as the mutation probability),for each gene T and each tone in T, the toneis randomly set to any of the six possible tones.Likewise, the parameter encodings are mutated.The mutation rate is set to 0.005 but raised to0.5 for a single generation if the evaluation of thebest gene is UO improvement on the evaluationof the best gene ten generations earlier.
Thcbest gene is never mutated.The building blocks of genetic search discus-sed above are structured into the following algo-rithm, expressed in pseudo-Pascal:p rocedure  genetic_searchbegininitialise Pool, NewPool;for g := 1 to generations dobeginif good_performance(10) thenmutation_rate := (}.005;elsemutation_rate := 0.5;NewPool\[1\] := find_best_gene(Pool);for n := 2 to population dobegingenel := best_of_three(Pool);gene2 := best_of_three(Pool);NcwPool\[n\] := crossover(genel, geue2);mutate(NewPool\[n\], mutation_rate);endPool := NewPool;evaluate (Pool);eudwrite find_best_gene(Pool);endThe main loop is executed for each generation.EaCh time through this loop, the program checksperformance over the last ten generations and ifperformance has been good, the mutation ratestays low, otherwise it is changed to high.
Thenit copies the best gene to the new pool.
Now wereach the inner loop, which selects two genes, per-forms crossover, and mutates tim result.
Next, thecurrent pool is updated, an evaluation is perfor-med, and the program continues with the next ge-neration.
Once all the generations have been com-pleted, the program displays the best gene fromthe final population and terminates.An  Annea l ing  A lgor i thmAs with genetic algorithms, simulated annealing(van Laarhoven & Aarts, 1987) is a combinatorialoptimisation technique based on an analogy witha natural process.
Annealing is the heating andslow cooling of a solid which allows the formati,mof regular crystalline structure having a mininu,nof excess energy.
In its early stages when the tem-perature is high, annealing search rcsembles ran-dom search.
There is so much free euergy in thesystem that a transition to a higher energy stateis highly probable.
As the temperature decreasesthe search begins to resemble hill-climbing.
Nowthere is much less free energy and so transitionsto higher energy states are h'ss and loss likely.
Inwhat follows, I explain some of the I)arameters ofannealing search as used in the curreut implemen-tation.temperature  At the start of the search the tem-perature, t is set to 1.
During the search, thetemperature is reduced at a rate set by the 'cocr-ling rate' parameter, until it reaches a valne lossthan 10 -?
.per turbat ion  At each step of the search, the cu r-rent state is perturbed by an amount which de-pends on the temperature.
The temperature d -termines the fraction of the search space thatis covered by a single perturbation step.
Fora tone sequence of length n, we randomly resetthe worst n..t tones according to (Pt,_,t~ (xi - I ) -xi) 2.
For the parameters we proceed as tbi-lows, here exemplified for h. First, set p =t(hma?-hmi~).
Now, add to h a random numberin the range \[-p, p\] and check that the result isstill in the range \[h,nin, hmax\].equi l ibr ium At each temperature, the system isrequired to reach 'thermal equilibrium' beforethe temperature is lowered.
In the present con-text, equilibrium is reached if no more than oneof the last eight perturbations yielded a newstate that was accepted.free energy funct ion This is the amount ofavailable nergy for transitions to higher energystates.
In the current system, it is the distribu-tion -lO00.t.log(p), where p is a uniform ran-dom variable in the range (0, 1\].
If the energydifference A between an old and a new state isless than the available nergy, then the transi-tion is accepted.
The factor of 1000 is intendedto scale the energy distribution to typical valuesof the evaluation function.Now the algorithm itself is presented:p rocedure  annea l ing_searchbegini n i t ia l i se  Trans, NewTrans, BestTrans;randomise  Trans;t := 1;while t > 0.000001 dobeginrepeatNew'lh'ans := perturb(Trans ,  t);A := evaluate(NewTrans)- evaluate(Trans);if A < 0 orexp(-A/1000.t)  > random(0,1) thenTrans := NewTrans;if evaluate(Trans) < evaluate(BestTrans)BestTrans := Trans;until equ i l ib r ium_reached;Trans := BestTrans;temperature := temperature / 1.2;endwrite Trans;endThe program is made up of two loops.
The ou-ter loop simply iterates through the temperaturerange, beginning with a temperature of 1 and stea-dily decreasing it until it gets very close to zero.The nested loop performs the task of reachingthermal equilibrium at each temperature.
Thefirst step is to perturb the previous transcriptionto make a new one.
Notice that the temperature tis a parameter of the perturb function.
Next, thedifference ?x between the old and new evaluationsis calculated.
If the new transcription has a bet-ter evaluation than the old one, then ?x is negative.Next, the program accepts the new transcriptionif (i) A is negative or (ii) A is positive and thereis sufficient free energy in the system to allow theworse transcription to be accepted.
Finally, wecheck if the new transcription is better than thebest transcription found so far (BestTrans) and ifso, we set BestTrans to be the new transcription.Once equilibrium is reached, the current ranscrip-tion is set to be the best transcription found so far,and the search continues.Per fo rmance  Resu l tsBoth the genetic and annealing search algorithmshave been implemented in CA-+.
In this section, theperformance of the two implementations is compa-red.
Performance statistics are based on 1,200 exe-100806040205 10 15 20Figure 6: Performance results (no upstep)cutions of each program.
Search parameters wereset so that each execution took around 5 secondson a Sun Sparc 10.
Three performance trials wereundertaken.Tr ia l  1: Art i f ic ia l  Data .
In the first trial,both programs generated random sequences of to-nes, then computed the corresponding F0 sequenceusing P, then set about transcribing the F0 se-quence.
Since these sequences were ideal, the bestpossible evaluation for a transcription was zero.The performance of the programs could then bemeasured to see how close they came to findingthe optimal solution.
Each program was tested onF0 sequences of length 5, 10, 15 and 20.
For eachlength, each program transcribed 100 randomly-generated sequences.
The results are displayed inFigure 6.
Each pair of bars corresponds to a giventranscription length.
The left member of each pairis for the genetic search program, while the rightmember is for the annealing search program.The heavily shaded bars corresponding toeva-luations less than 1 are the most important.
Theseindicate the number of times out of 100 that theprograms found a transcription with an evalua-tion less than 1.
This evaluation means that theaverage of the squared ifference between the pre-dicted F0 values and the actual F0 values wasless than 1Hz.
Observe that the annealing searchprogram performs ignificantly better in all cases.Note that the mutation operation in the geneticsearch program treats each bit in the parameterencodings equally, while the perturbation opera-tion in the annealing search program is sensitiveto the distinction between more significant vs. lesssignificant bits.
This may explain the better con-vergence behaviour of the annealing search.Notice also in Figure 6 that performancelOOL ?
<o., [] <,[] <10 [] <100100I ?
<4[] <7 [] <10 [] <2080 8060 6040 4020 205 10 15 20Figure 7: Performance results (upstep)1 2 3 4Figure 8: Performance results for actual datadoes not degrade with transcription length as thelength doubles from 10 to 20.
This is probably be-cause a randomly generated sequence will containdownsteps on every second tone (on average) cau-sing a general downtrend in the F0 values and se-verely limiting the combinatorial explosion of pos-sible transcriptions.Tr ia l  2: Art i f ic ia l  Data  w i th  Upstep .
Trial2 was the same as trial 1 except that this timeupstep was permitted as well.
The results are dis-played in Figure 7.
Again the annealing programfares better than the genetic program.
Consideragain the bars corresponding to evaluations lessthan 1.
For both programs, however, observe thatthe performance degrades more uniformly than intrial 1, probably because the inclusion of upstepgreatly increases the number of possible transcrip-tions (and hence, the number of local optima).Tr ia l  3: Ac tua l  Data .
The final trial invol-ved real data, including data from the utterancegiven in Figure 1.
This trial involved four sub-trials.
The first and second had F0 sequences oflength 10, while the third and fourth had length18 and 19.
The first and second sequences weretaken by extracting the initial 10 F0 values fromthe third and fourth sequences, thereby avoidingthe asymptotic behaviour of the longer sequences.The data is tabulated below, and it comes fromthe sentences in (5).Trial F0 sequence1 219,168,183,150,160,136,144,123,131,I 52 205,224,16'7,200,156,175,136,156,127,1403 219,168,183,150,160,136,144,123,131,115,122,107,113,105,118,100,113,954 205,224,167,200,156,175,136,156,127,140,118,129,109,119,103,120,102,111,95Performance r sults are given in Figure 8.
Noticethat he interpretation of the shading in this figureis different from that in previous figures.
This isbecause valuations near zero were less likely withreal data.
In fact, the annealing program neverfound an evaluation less than 3 while the geneticprogram never found an evaluation less than 4.Since the programs performed about equallyon finding transcriptions with an evaluation lessthan 7, I shall display these transcriptions alongWith an indication of how many times eachprogram found the transcription (G = genetic,A = annealing).
I give transcriptions which occur-red at least twice in one of the programs, during100 executions of each.Trial 1: Transcriptions G AHSLSHSLSHSLSHSLSHSL 27 37HSLSHSLSHLSH.I.LSHL 7 0HSLSHLSHLSHL,IML 3 0HSLHSLHSLH,~LHSL 2O 2HLSHL,IMLSHLSHL 24 39Trial 2: Transcriptions G ALSHSLHSLSH$LSH.I.LSH 5 0L.I.H,~LHSLSHSLHSLSH 66 54Trial 3: Transcriptions G AH.I.L.I, HSL.IMLSHSLSHL~HSLSHLH~LH%L I i  0HSLSHLSHLSHLSHLSHSLSHLHSLHSL 1 2HSLSHLSHLSHLSHLSHLSHLHSLHSL I0 14HLSHLSHLSHLSHLSHLSHLHSLHSL 30 56Trial 4: Transcriptions G ALSHSLHSLSHSLHSLSHSL+HSLSHSLHSLSHSL 60 29L.I.HSLHSLSHSLHSLSHLSHSLSHSLHSLSHSL 5 19LSHSLHSL.I.H$LH.I.LSHLSHSLSHLHSLSHSL 7 7LSH,I.LHSLSHSLHSLSH$LSHSL+HLHSLSHSL 0 4LSHSLHSLSHSLH,I.LSHLSHLSHSLHSL.~HSL 0 3LSHSLHSLSHSLHSLSHLSHLSHLHSLSHSL 0 6The results from trial 1 deserve special attention.In trial 1, three transcriptions were found by bothprograms.
The best evaluations found are givenbelow:10II I,'~.H 1,4H L4H LLII LI141, II4L l14L 11~.t, H4LHI.i,41141,.IAI41,4tI41,$tISLE: 3 h: 107 1:100 d: 0.68E :4  h :90  1:93 d:0.76E: 3 It: 107 l: 100 d: 0.82It is striking to note that the first two transcrip-tions above are what Hyman and Stewart (respec-tively) would have given as transcriptions for theabstract F0 sequence 1 324354657.
This is(temoustrated in (7a,b).
The third transcriptionpoints to another possibility, given in (7c).
(7) a. Hyman's  t ranscr ip t ion  schemeH L .I.H L ,I.H L ~II L J(H L1 3 1 3 1 3 1 3 1 30 0 1 1 2 2 3 3 4 4I 3 2"4  3 5 4 6 5 7I).
Ste~wal't's t ranscr ip t ion  schemeH ,1,1, ll: ,I,L H SL H SL tI J,I,121  2121 2120 1 1 2 2 3 3 4 4 51 3 2 4 3 5 4 6 5 7c.
Nove l  t ranscr ip t ion  schemeH SL SH SL SU SL 4H .I.L SH SL1 ~ 1 ~ 1 ~ 1 ~ I ~'29 o?1 2 3 41 3 2" 4 3 5 4 6 5 7Therefore, there are encouraging signs thatthe program is living up to its promise of produ-cing alternative, equally acceptable transcriptions,a.~ desired from an analytical standpoint.Mu l t ip le  So lu t ionsAll,hougJt we have seen more than one transcrip-tion I'or a giwm !
"0 sequence, it is inconvenient toI)o required to run the programs everal times inorder to see if more than one solution can be fo-und.
Furthermore, the programs are designed notto get caught in local optima, which is a problemsince interesting alternative transcriptions may ac-tually be local optima.
Therefore, both programsare set up to report the k best solutions, where theuser specifies the number of solutions desired.
Theprogram ensures that the same area of the searchspace is not re-explored by subsequent searches.This is done by defining a distance metric on tran-scriptions which counts the number of tones in onetra.nscription that have to be changed in order tomake.
it, identical to the other transcription.
Thatpa.rt of the search space within a distance of n/3I'rom any I)reviously found solut.ion is not exploredagain.
The lu'ograms give up before linding k so-lutions if 5 randomly generated transcriptions allfidl within distance n/3 of previous solutions.Now, consider the following randondy genera-ted sequence of tones:201 215 20l 173 163 201 173 d: 0.87 :The annealing program was set the task of fin-ding ten transcriptions of this tone sequence.
Theprogram was run only twice, and it reporte(I thefollowing solutions with evaluations less than orequal to 1.
Both runnings of the program foundthe same solutions, and in the same order.
(Notethat two transcriptions are taken to be the same ifone or both begin with an initial upstep or down-step; this has no effect on the phonetic interpreta-tion).
In the following displays, the predicted F0values are given below each solution to facilitatecomparison with the input sequence.?
I.H TH .I.H L J~L tH  L201 215 201 172 163 201 172.I.H I"H SH tL SL n ~L201 215 201 174 163 201 174L SH .I.H L SL tn  L201 217 201 174 163 201 174h:101 1:92d: 0.88 ?
: 0.20h : 109 1:94d: 0.87 ?
: 0.23h : 105 l: 97d : 0.86 ?
: 1.00It TH ~H L ,L TH L201 214 201 173 164 201 173~H ~H ~H ~L SL H TL201 215 201 174 164 201 174~L SH SH L ~L tH  L201 217 201 174 163 201 174h : l l0  1:100d : 0.88 ?
: 0.86h : 102 l: 88d: 0.88 ?
: 0.66h : 104 l: 96d : 0.86 ?
: 1.00Since all executions to this point have beenbased on the first table of R values, it was decidedto try a test with the second table of R values tosee if the performance was different.
Interestingly,the third solution in both of the above executi-ons was not found, though two new solutions wereOluld.I"I-I f i l  SH L SL I"lI \[,201 216 201 173 \[62 201 173L .LH .~a L SL I"H L201 215 201 174 163 201 174?
I.H ~H ~H TL ~L H TL201 215 201 174 163 201 174~L I I L SH L tL  .IAI201 214 201 173 163 201 173h: 94 1:80d : 0.88 t: : 0,49h: 97 l: 84d: 0.88 ?
: 0.65h: 100 l: 81d : 0.88 C : 0.92h: 92 l: 86d : 0.67 E : 0.48.I.H "I"H -I.H L .I.L tH  L h: 107 l: 92201 216 201 173 162 201 173 d:0.87 ~: 0.40L H L SH L TL SH h:99 1:93201 214 201 173 163 201 173 d:0.65 S: 0.82SL .l.H SH L ,I.L ~H L h :90 1:78201 217 202 174 163 202 174 d: 0.88 ?
: 0.86Observe that the value of d ill tile above solu-tions clusters around 0.66 and 0.87.
Simila.r clu-stering may bc occurring with the ratio h/l.
Ho-wever, all analysis of the relationship between thekinds of solutions found, tile two It tables and theparameter values h, l and d has not been attemp-ted.11Areas  for  Fur ther  ImprovementIt is rather unsatisfying that the performance ofthe two programs is heavily dependent on (,he set-ting of several search parameters, and it seems tobe a combinatorial optimisation problem in itselfto find good parameter settings.
My triM-and-error approach will not necessarily have found op-timal parameter values, and so it would I,e pre-mature to conclude from tile performance compa-rison thai.
annealing search is better than geneticsearch for the problem of tone transcription.
Amore thoroughgoing comparison of these two ap-proaches to the problem needs to be undertaken.Since the parameters are continuous variables,and since the evaluation function--which we couldwrite as CT,x(h,l,d)--is a smoothly continuousfunction in h, l, d, it would be worthwhile to tryother (deterministic) search methods for optimi-sing h, l and d, once a candidate tone transcriptionT has been found.Finally, it would be interesting to integrate asystem like either of the ones presented here into aspeech workstation.
As the phonologist identifiessalient points with a cursor the system would dothe traJ~scril)tion , incrementally and interactively.ThisblemsicalthatCONCLUSIONpaper began with a discussion of the pro-of relating tone transcriptions to their phy-counterparts, namely F0 traces.
I showedit is desirable for phonologists working ontone to use sequences of F0 values as their pri-mary data, rather than impressionistic transcrip-tions which make (usually implicit) assumptionsabout F0 scaling.
I provided an F0 prediction fun-ction 'P which estimated the F0 value of a tone,given the F0 value of the previous tone a.nd theidentities of the two tones.
I presented instru-mental data from Bamileke Dschang and showedhow the function could be specialised for this lan-guage.
The function was then incorporated intothe evaluation functions of two implement~,d non-deterministic search algorithms.
The performanceresults were encouraging and demonstrate he pro-raise of automated tone transcription.ACKNOWLEDGEMENTSThis research is funded by the UK Economicand Social Research Council, under grant R000234439 A Computational Model for the Phonology-Phonetics Interface in Tone Languages.
I am in-debted to SIL Cameroon for their logistical sup-port on nly field trip in September and October of1993, during which the data presented in i.he pa-p(~r (and much other data besides) was gathered,and especially to Nancy Haynes, Gretchen Harrofor helping me collect the data and Jean-ClaudeGnintedem who endured many recording sessions.I am gratefifl to John Coleman, Michael Gasserand Marie South for helpfnl comments on an ear-lier version of this paper.
The F0 data was ex-tracted using the ESPS Waves+ package in theEdinburgh University Phonetics Laboratory.Re ferencesBird, S. & Stegen, O.
(1993).
'lbne in the Banfih'keDschang Associative Construction: All EI-ectrolaryngographic Study and C, onlparisonwith Hyman (1985).
RP 57, University ofEdinburgh, Centre for Cognitive Science.Clements, G. N. (1979).
The description ofterraced-level tone languages.
Language, 55,536-558.Connell, B.
& Ladd, D. R. (1990).
Aspects of pitchrealisation in Yoruba.
Phonology, 7, 1-29.Ellison, T. M. (1993).
Machine Learning of Pho-nological Structure.
PhD thesis, I lniversity ofWestern Australia.Goldberg, D. E. (1989).
Genetic Algorithms inSearch, Oplimization, and Mm'him' I,carnin.q.Addison-Wesley.Iluang, X. D., Ariki, Y., ,~ Jack, M. (1!19(I).Hidden Markov Models tier Speech Recogni-tion.
Edinburgh Information Technology Se-ries.
Edinburgh University Press.Hyman, L. M. (1979).
A reanalysis of tomd do-wnstep.
Journal of African Languages andLinguistics, i, 9-29.Hyman, L. M. (1985).
Word domains and down-step in Bamileke-Dschang.
Phonology Year-book, 2, 45-83. iHyman, L. M. & Schuh, R. G. (1974).
Univer-sals of tone rules: evidence from West Aft'lea.Linguistic Inquiry, 5, 81-115.Liberman, M., SchUltz, J. M., Hong, S., g: Okeke,V.
(1993).
The Phonetic Interpretation ofTone in Igbo.
Phonetica, 50; 147 160.Pierrehumbert, J.
~ Beckman, M. (1988)..lapa-nese Tone Structm~.
Cambridge Mass.
: M!
'l'Press.South, M. C., Wetherill, G. B., & Tham, M. T.(1993).
Hitch-hiker's guide to genetic algo-rithms.
Journal of Applied Statistics, 20, 153-175.Stewart, J. M. (1993).
Dschang and Ebri6 as Akan-type total downstep languages.
In H. van derHulst & K. Snider (Eds.
), The Phonology ofTone - The Representation f Tonal Register(pp.
185-244).
Berlin; New York: Mouton deGruyter.
Linguistic models, Volume 17.van Laarhoven, P. J. M. k Aarts, E. II.
L. (1987).Simulated Annealing.
Dordrccht:lt.ei(lel.12
