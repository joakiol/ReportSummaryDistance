!IiiI!I!
!IIIIIIIIITHE NATURE OF PERCEPTUAL REPRESENTATION:AN EXAMINATION OF THEANALOG/PROPOSITIONAL CONTROVERSYStephen E. PalmerDepartment of PsychologyUniversity of California, BerkeleyIn recent years a number of theoristshave proposed that perceptual informationcan be represented in terms of propositi6nal(or relational) data structures (e.g.,Baylor, 1971; Palmer, 1975: Winston, 1973).This development has provoked considerablecontroversy among psychologists and computerscientists over the type of representationmost suitable for perceptual information,especially in the case of perceptual imagery(e.g., Bower, 1972; Kosslyn & Pommerantz, inpreparation; Pylyshyn, 1973).
The argumentstypically pit some form of "analog"representation against some form of"propositional" representation.
The tackoften taken is to contrast a reasonableversion of the favored type against anunreasonable version of the other type.This is particularly easy to do since thereis considerable latitude within thecategories of "analog" and "propositional"representations.
While the argumentsbetween the opposing schools of thought havebeen provocative and useful as an initialenterprise, their continuation in thepresent vein seems unlikely to produceeventual agreement on the nature ofperceptual representation.It is clearly in the spirit of thisconference to analyze the problem in termsof the underlying issues to reach consensusat more basic levels.
In this paper Idiscuss briefly a number of issues relevantto representing perceptual knowledge: isperceptual representation uninterpreted orinterpreted, complete or partial, implicitor explicit, holistic or atomic,quantitative or qualitative, absolute orrelative?
I do not pretend that the problemsconsidered here are exhaustive.
(See Bobrow(1975) for some other issues to beresolved.)
I have chosen to discuss theproblems I see as being most central to  thecurrent analog/propositional controversy.For each topic I make a few theoretical,empirical, and methodological observationsthat seem to merit consideration.
Theconclusion I reach on many issues is thatsome kind of synthesis or compromise isrequired.
Throughout the discussion Ipresent my current approach to perceptualrepresentation (see also Palmer, 1975) whichillustrates how synthesis and compromise canbe achieved within a single formal system.Structural and Parametric InformationBefore turning to the issues, I want tomake a distinction between two fundamentallydifferent types of information: structural(or organizational) and parametric (ordimensional) information.
Structuralinformation refers to the organization ofperceptual elements into groups.151Figure-ground and part-whole relationshipsare paradigm examples of structuralinformation.
Parametric information refersto the values of the stimulus along variousperceivable dimensions.
Color, size, shape,position, orientation and so forth areexamples of parametric information.Perhaps the most basic distinctionbetween these two types of information isthat parameters are properties of both theperceptual representation and the stimulusitself, while structure is a property of therepresentation alone.
If the parameters oftwo perceptual representations aredifferent, they necessarily correspond totwo physically different stimuli.
If thestructure of two perceptual representationsare different, they might correspond to thevery same stimulus.
Figure I i l lustratesthis point by showing a case in whichstructure and parameters are combinedorthogonally.I do not want to give the impressionthat structural and parametric informationare independent.
Clearly, the parameters ofa stimulus affect its perceived structure.This fact is manifest in the work of Gestaltpsychologists and codified in their laws oforganization.
Context and world knowledgecan also affect the assignment of structuralorganization -- e.g., the figure ~ will bestructured as a single unit in the contextof~O~l and as two units in the context of13y7.It is also true that perceivedstructure can affect the representation ofparameters.
Someone perceiving the"parallelogram" organization of the form inFigure I might perceive it as taller andthinner than someone who perceived the sameform with the "triangle" organization.
Onceagain, context and world knowledge canaffect the parameters of a perceptualrepresentation -- e.g., the height of twopeople in an Ames room.It is important to make clear thedistinction between structural andparametric information because failure to doso can lead to mistaken conclusions aboutthe nature of perceptual representation.
Acase in point is the frequency with whichthe results of mental rotation experiments(e.g., Cooper, 1975; Cooper & Shepard, 1973:Shepard & Metzler, 1971) are cited asevidence that perceptual representations andprocesses are "analog" and continuous in allrespects.
When the process of rotation isconsidered in light of thestructural/parametric distinction, it isseen that it deals only with changes inparameters -- namely, the orientation ofthe figure in space.
The structure of thefigure presumably remains constant, and thusdoes not contribute to the measured reactiontimes.To demonstrate the operation ofstructural variables in perceptual andimaginal processes, I have developed a"mental synthesis" task.
In mentalsynthesis, subjects are required to imaginesynthesizing two spatially separated partsby moving the right part onto the left part(see Figure 2), such that they know what theresulting figure looks like.
The data ofinterest are the times required tosynthesize two "good" parts of theto-be-synthesized figure (parts AI and A2 inFigure 2) versus two "bad" parts (BI andB2).
The results are unequivocal.Synthesizing the bad parts took more thantwice as long as synthesizing the goodparts, even when the to-be-moved parts werevirtually identical, as in Figure 2.
I donot yet know exactly what is happening inthe mental synthesis task, but I submit thatit cannot be accounted for by the simpleparametric transformation of translationalmotion.
Once the parametric change inposition is performed, structuralmanipulations (e.g., local and globalgrouping of segments) must be done in orderto construct the perceptual representationof the synthesized figure.
I suggest thatstructural and parametric operations arefundamentally different because the types ofinformation upon  which they operate arefundamentally different.
As a result,structural and parametric information willbe considered separately at appropriatepoints in the discussion that follows.The Uninterpreted/Interpreted IssueOne fundamental issue which oftenarises in debates over analog versuspropositional representation is that ofinterpretation.
Are the contents ofperceptual representations "raw" sensorydata or ,,interpreted" conceptual structures?Before such a question can be answered, wemust be clear about what ,,interpretation"means.I view the interpretation of sensorydata as having several levels, each beingcharacterized by additional inferences whichadd meaning to the data being processed.
Atthe lowest level there is the raw sensorydata -- the stimulation of the retinalmosaic, if you wish.
Some minimalinterpretation is added when these raw dataare organized into areas and low-levelperceptual properties are extracted; thisblue, rectangular portion of the scene  issome sort of unit as distinct from thatgreen oval portion nearby.
(I do not wishto imply that the verbal description givenis the same as the evolving perceptualrepresentation.
The representation of theregions has information about the particularcolors and particular shapes.)
Theselow-level interpretations in terms ofcolors, shapes, sizes, and so forth provideinformation from which the observeridentifies the areas as objects; the bluearea is identified as a car and the greenarea as a tree.I think at this level we would allagree that the sensory data have been"interpreted," but there can be yet furtherinterpretations.
For example, suppose thecar is identified as that of the observer'sfriend, and it is parked in the observer'sdriveway.
The observer will very likelymake the further inference that the friend152has come to visit.
One might now objectthat this is no longer a "perceptual"interpretation, but the fact is that it willinfluence subsequent perceptions.
Theperson standing at the door will more quickybe identified as the friend than if the carhad not been noticed.Thus, there can be many levels ofinterpretation and for each there can be arepresentation.
Which one is called theperceptuai representation is a matter ofpersonal preference and may be responsiblefor some of the misunderstandings betweenthose who argue about the nature ofperceptual representation.
My ownpreference is to consider them allperceptual representations, but at differentpoints along a sensory-cognitive dimension.The representations are increasinglymodality-specific at the sensory end andincreasingly modality-independent at thecognitive end.
For example, the inferencethat the friend had come to visit might beequally well made by recognizing theparticular sound the friend's car made as itcame into the driveway, or by recognizingthe friend's distinctive knocking pattern onthe front door.it should be clear that I am advocatingan integrated approach to sensation,perception, and cognition (see also Norman &Bobrow, 1975) which is somewhat at variancewith modularized, box-theory approaches.Within this framework, the nature ofperceptual representation is different atdifferent interpretive levels.
At thesensory end, I view the representation asbeing very much analog, even in the strongform.
At the cognitive end, I view therepresentation as being very muchpropositional, also in the strong form.
Butit is about the middle levels that most ofthe arguments seem to take place, and hereneither pure analog or pure propositionalrepresentation seem to make much sense.There must be a transition between the twowhich is likely to be some sort of hybrid.In the discussion that follows, it should beassumed that I am considering a level ofperceptual representation in which thestimulus has already been operated upon bylow-level perceptual processes, but has notyet been conceptually categorized.The Complete/Partial IssueThe picture-metaphor is usuallycharacterized as a complete representation.It is complete in the sense that an analogimage contains (explicitly or implicitly)all the information present in the stimulus.The quasi-l inguistic description is usuallya partial representation, since it would becumbersome (at best) if it described all theinformation in the stimulus.I think it can be stated flatly thatthere are very few (if any) objects orscenes about which people have completeperceptual knowledge.
A completerepresentation of some object implies thatits perceptual representation can bediscriminated from that of any differentIIII!IIIIobject, regardless of their  similarity,context, or any other factors.
This simplyis not the case.
For example, I performedan informal study for perceptual memory of abuilding in which all of the subjects hadworked for at least two years.
They couldnot discriminate an accurate drawing of thebuilding from three qualitatively similardrawings which differed substantially in theoverall height-to-width ratio and the numberof windows per floor (see Norman, 1975).
Infact, the most preferred drawing was theleast accurate one, and the least preferreddrawing was the most accurate one.The real issue is not whetherperceptual knowledge is complete or partial,but what part of the information is encodedand why it is selected.
I favor an approachbased on pragmatic considerations ofcontextual factors.
The building mentionedabove stands among a group of other gray,concrete buildings similar in architecturalstyle, but quite different in overall size,height, specific detail, and (of course)position.
What information is required todescriminate this building from the others?Relative position alone would be sufficient,or height, or size, or any combination ofthese three parameters.
One simply does notneed to know details like the exactheight-to-width ratio or the number ofwindows per floor to find it.The strongest form of the pragmaticview implies that only discriminativeinformation will be represented at any givenlevel.
The models  developed by Quillian(1968) and Winston (1973) for representingcategories and their instances follow thisgeneral principle.
I am suggesting that itmight be fruitful to extend this strategy tocontextually dependent descriptions (of.,Norman & Bobrow, 1975; Bobrow & Norman,1975).
That is, a person may not encode theperceptual description of a building interms of its similarities and differencesrelative to all other buildings, butrelative to Just those buildings from whichit must be discriminated in its givencontext or set of contexts.This strongly pragmatic view leads tocertain testable predictions.
Suppose thata subject is presented with a designatedtarget stimulus, S~, in a set of otherstimuli, and is told that he or she willlater be asked to pick the target item fromthat set.
Performance on subsequentrecognition tests for S~ and variousdistractor items should depend strongly onthe context in which they originallyappeared.
For example, the discriminabil ityof distractors that differ from S~ on somedimension should depend whether thatdimension was a discriminative feature of S twithin the presented contextual set.Reaction time measures might provide someinsight into what information was storedexplicitly (in the representation of thetarget item) and what information was storedimplicitly (in the contextualrepresentation).This is but one example of the kind ofexperiments that might provide insight intothe rules that govern the specific ?information content of perceptualrepresentations in context.The Explicit/Implicit IssueOne of the thorniest problems faced byanyone dealing with perceptualrepresentation is that of explicit versusimplicit representation of information.
Inlarge measure, the difficulty is that ofseparating structure from process.
If aperson can perform a task on a perceptualrepresentation requiring certaininformation, it cannot be readily determinedwhether the information was storedexplicitly and simply retrieved, or whetherit was stored implicitly and then madeexplicit by some inferential process thatwould not otherwise have been invoked.
Theanalog "picture-metaphor,, constitutes arepresentation in which virtually allinformation (except point locations) isimplicit.
The propositionalquasi-l inguistic description is arepresentation in which a good deal ofinformation (but not all) is explicit.Given the astonishing flexibility ofthe perceptual information processingsystem, I doubt that many (if any)hard-and-fast generalizations can be madeabout what information is representedexplicitly and what implicitly~ It dependsstrongly on the requirements of the taskbeing ~erformed.
In reading coherent,connected discourse, for example, it may bethat only global information is representedexplicitly because expectations derived fromlinguistic context are strong enough toallow identification without detailedprocessing of low-level components.
Incomparing two novel figures for asame/different Judgment, however, thelow-level components may be representedspecifically because their use is requiredfor the task.
Perhaps the best one can hopefor is to draw conclusions about therepresentation of information in a givencontextual situation with certain analyzabletask requirements and possible strategies.The Holistic/Atomie IssueThe issue of whether perception inholistic or compossed of smaller componentshas a long history in psychology, mostnotably in the confrontations between thestructuralist and Gestalt movements.
Thisproblem has been resurrected to some extentin the analog/propositional controversy.The strong form of analog representation isdecidedly holistic, while the strong form ofpropositional representation is atomic (orcomponential).S - - ~ i - D ~ ~ .
Consider thesimple form shown in Figure 3.
It is quiteeasily decomposed into a triangle andrectangle in a particular arrangement.These parts, in turn, have lower-levelcomponents in the angles and lines of which153they are composed.
Recent data (Palmer,1974; Reed, 1974) have demonstrated thatpeople can find a "good" or "natural" partwithin a figure (i.e., a subset of thefigure corresponding to a single structuralunit such as triangle ABE) much more quicklyand accurately than a "bad" or "unnatural"part(i.e., a subset which crosses structuralboundaries, such as segments AB, BE, andDE).
I find it difficult to explain suchresults without positing some representationof component structure.The Gestalt maxim "the whole is morethan the sum of its parts," however, cannoteasily be denied.
Placing a series ofpoints in the configuration of a line, forexamPle , adds new dimensions to thefigure -- the "emergent" properties oflength and orientation which are undefinedfor the individual points that comprise it.Similarly, arranging three lines to form atriangle produces properties likeclosedness, area, and symmetry which are notproprties of the lines alone.
The thrust ofthis argument is that if emergent propertiesare to be given explicit representation,there must be a mechanism for encoding bothparts and wholes.A simple formalism for doing this isthe hierarchical network (c.f.
Baylor,1971;Palmer, 1975; Winston, 1973).
At each levela node representing the global unitdominates its local parts.
An example isgiven in Figure 3.
The node \[ABCDE\]represents the whole figure, nodes \[ABE\] and\[BCDE\] represent the triangle and rectangleparts, nodes \[AB\], \[BC\],\[CD\], etc.represent the lines comprising the parts ofthe triangle and rectangle, and nodes \[A\],\[B\], \[C\], etc.
represent the individualpoints.
There are several aspects of therepresentation worth noting.
The first isthat if all the points were shown, then thelowest level of the structure wouldcorrespond to an "analog" representation.It is not until the second level that anyinterpretive information isrepresented -- e.g., the grouping of polntsinto lines.
Second, the structure is anetwork rather than a tree.
A given unitcan be part of more than one higher orderunit -- e.g., segment \[BE\] is an element ofboth the triangle and the rectangle.
Third,I have not yet specified the nature of thestructural units or the connectors betweenthem.
The nodes might stand for featurelists, propositional structures, or evenmini-templates.
The connections might beuni- or bi-directional associations,explicit part/whole relations, or parametricrelations such as relative position,orientation and size.P~rameters.
Any structural unit can becharacterized by values along certaindimensions -- its size, shape, color,position, and so forth.
In thepicture-metaphor, all such dimensions arerepresented holistically and implicitly inthe image.
They are encoded inte~rally andcan only be separated by some set of?
processes which extract this informationfrom thhe holistic image.
In thelanguage-metaphor representation, most154dimensional information is encodedcomponentially and explicitly -- e.g., SIZE(OBJECT, LARGE), COLOR (OBJECT, RED), and soforth.
Here the parameters are representedseoarabl~ and can only be integrated by someprocess that combines them into a compositeunit (such as a point in a multidimensionalspace).
What evidence is there for theintegrality or separability of perceptualparameters.Both personal experience andpsychological results suggest that peoplesometimes can remember, say, the locationand shape of an object without rememberingits orientation (cf., Frost & Wolf, 1973).At least under certain circumstances, then,some kinds of parametric information must beseparable, since there is no reasonablemechanism by which components of integrallystored information can be differentiallyforgotten.There are certain dimensions, however,that seem to function integrally.
Perhapsthe clearest example is that of color.
Hue,saturation, and brightness function as apackage which is only "unpacked" into itscomponents under unusual circumstances.
(The reader is referred to Garner (1974) fora clear and elegant presentation of thedifferences between integral and separabledimensions in terms of experimental tasks.
)There is also some evidence that distantlyrelated parameters (e.g., color, size, andshape) can function integrally in simplesame/different tasks.
Egeth (1966) andNickerson (1967) have reported reaction-timeresults with multidimensional stimuli whichare consistent with a matching process thatfirst evaluates all parameters integrallyand then evaluates each component separately(see Reed, 1973, PP.
58-61).Given the evidence, I conclude thatparametric information should have bothholistic (integral) and atomic (separable)levels of representation, with certainconstraints.
For example, Figure 4 shows apossible representation for a rectangle of agiven size and color.
The node representingthe whole object has parametric informationassociated with it -- color and size.
Thus,these dimensions are integrated at theobject node, such that it could be evaluatedas a point in a multidimensional space.Color and size, however, are separated atthe next level, and could be processedseparately if required by the task.
At thislevel, the components of color (hue,saturation, and brightness) and size (lengthand width) are represented as integralunits, such that each could be evaluated asa point in different multidimensionalspaces.
These components are then separatedat the lowest level.
Thus they could beprocessed separately if necessary.I do not know whether this formulationis consistent with all of the data, but thegeneral thrust seems right.
Certain typesof parametric information (e.g., length andwidth) are represented integrally at onelevel and separately at a lower level.Other types of information (e.g, length andhue) are never represented as aIIIIIIIIiIIIIIIIIIIsel f -contained integral unit~ To the extentthat this is a reasonable scheme forrepresenting parameters, we must begin toexamine the structural aspects of parametricinformation.The Qual i tat ive/quant i tat ive IssueAnother recurrent theme in debates overthe relative merits of analog andproposit ional  representat ion is that ofwhether qual i tat ive or quant i tat iveinformation is encoded.
The typical claimsare that analog representat ions arequantitat ive while proposit ionalrepresentaions are qual itat ive.Structure.
Structural re lat ionshipsthemselves -- e.g., PART OF (EYE, FACE) --are qual i tat ive in nature.
If perceptualstructure is to be represented explicit ly,there must be a qual i tat ive mechanism fordoing so.
I am not certain, however, thatit does not have quantitat ive aspects.
Apart icular perceptual  element might- begrouped within two different units wlthdifferent "strengths", especial ly during theinit ial  process of assigning structure.I have proposed that the "goodness" ofa set of components as a structural unit isdetermined by context-sensl t ive associat ionsbetween its elements (Palmer, 1974).Suppose there is a pattern composed o felements A, B, C, D, E, and F within whichA, B, and C are a possible structural  unit.The more strongly A, B, and C are associatedwith each other, according to Gestaltp r inc ip les  of organization, the "better"they are as a part within the figure.
Themore weakly A, B, and C are associated withD, E, and F, the "better" they are as a partwithin the figure.
This idea has much incommon with hierarchical  c luster ingprograms.
I conceive of the process oforganizat ion as one in which quantitat ive,low-level associat ions between elementsinteract with each other -- strengtheningand weakening various groupings -- unt i l  astable organizat ion determines "the"structure perceived.A similar s i tuat ion may occur incategorical  assignments.
People are able tomake discrete decisions about whether arobin is a bird.
However, current evidencesuggests that quantitat ive processes are atwork prior to the decision (see Smith,Shobin & Rips, 1975).
Certain birds arerated as "better" examplars than others(Rosch, in press) and the "better" the bird,the faster it can be categorized (Rips,Shobin, & Smith, 1974).
The point is thatthe qual i tat ive discrete result of acognit ive process may be reached byquantitat ive processing of quant i tat iveinformation.Parameters.
There are two separateissues for parametric information withregard to quant i tat ive versus qual i tat iveinformation.
The first concerns the natureof the dimensions themselves; the secondconcerns the nature of the values along thedimensions.Clearly, the perceptual dimensions (or"qualit ies") of the representaion arequalitative.
Color is undeniably dif ferentin nature from location or shape or anyother perceptual  parameter.
If thisdimensional information is to be encodedexplicit ly, the representat ion of eachdimension must be qual i tat ively distinct.The nature of dimensional values is amore complex problem.
Is the color of someobject to be represented by a quantitat ivevalue or is it to be represented by aqual i tat ive category such as COLOR (OBJECT,RED)?
The quest ion is really about thenature of general izat ion along dimensions.Suppose I show someone a patch of a colorbetween red and orange, but enough towardred that the observer would call it "red" ifforced to choose.
What wil l  the subsequentrecognit ion errors look like?
If the coloris represented by coordinates in the colorspace, then the errors should be distr ibutedas a simple function of distance from thecolor presented.
If the color isrepresented by a qualitative, categor icaldescription, then the errors should bedistr ibuted either uniformly within thecategory boundaries or as a simple functionof distance from the categorical  prototype,depending on whether the categories aredefined by boundaries or prototypes.Although I do not know of such anexperiment, I expect that the results wouldbe more like the quantitat ive predict ionthan the qual l tat ive-categor lca l  one.
Itseems likely, though, that if there were adrift or skew in the errors, it should betoward the center of the category into whichthe presented st imulus fell.
Tosome extent, I favor quant i tat iverepresentaion of parametric values becauseit seems simpler and more natural.
Metricoperations on parameters, for example, aresimpler to accompl ish with quant i tat ivevalues.
Of course, one can approximate aquant i tat ive scale by having many smallcategories, but beyond some reasonably smallnumber, the categories lose theirqual i tat ive nature and begin to look morelike a quant i tat ive dimension.
That is, thecategories become funct ional ly quantitat ive.The Absolute/Relat ive l~s~eCan the information in a perceptualrepresentat ion be best character ized asencoded in an absolute form or an encodedrelative to some other information?
Giventhe emphasis I have placed on contextualfactors, it should come as no surprise thatI strongly favor the relative approach.
Butonce again, there are constraints whichlimit the general izat ions that can be made.Structure.
The structural  organizat ionof perceptual  representat ion is c learly arelative concept.
It would be fool ish tothink that any part icular set of perceptualelements wil l  always be grouped together.The Gestalt demonstrat ions of "hiddenfigures" are unequivocal  evidence thatorganizat ion depends on (in fact, is largelydetermined by) contextual  factors.S imi la r ly ,  my own research on the155part-structure of f igures shows that a givenset of segments will only be perceived as astructural  unit within certain contextualsegments (Palmer, 1974).
In my view, noreasonable case can be made for absolutedetermination of structural organization.Parameters.
The issue is more complexfor parametr ic information.
Since peoplecan recognize most objects at variousorientations, perspectives, and distances,relative encoding seems desirable.
But itis a fact that people are not equal ly goodat recogniz ing objects from all or ientat ionsand perspectives.
There seem to bepreferred or ientat ions and perspect ives formost objects which depend on experience withthem.
There are even some rather subtlerecognit ions (e.g., a par t i cu la r  person'sface) which cannot be made if the absoluteor ientat ion is too different from thatnormally experienced.
(The reader isreferred to Rock's (1974) studies ofor ientat ion for further information.)
Howare we to resolve these apparentinconsistencies?One type of solution is shown in Figure5 for or ientat ion information.
Both"absolute" and relative or ientat ions of theface and eyes are encoded.
The "absolute"or ientat ion (shown in brackets) of astructure is encoded as the or ientat ion ofits long axis (from broad to narrow)relative to the ground.
The importantparameters for the representat ion of theface schema or frame are the re lat ionships(shown in ovals) betwen the "absolute"or ientat ions of the eyes and face.
If theface were rotated, the absolute or ientat ionsof each structure change, but theiror ientat ions relative to each other remainconstant.
Thus, the representat ion is notor ientat ion specif ic, and a face can, inprinciple, be recognized as a face in anyorientation.The absolute or ientat ions have twofunctions.
In the expectat ion-dr iven mode,the or ientat ion of a known (or hypothesized)structure wil l  determine the or ientat ion ofan expected structure via the re lat ionshipsbetween them.
For example, if some set ofdata have been tentat ively interpreted as aface at +45, then the expected or ientat ionof the eyes are +135 and -45 as computedfrom the encoded relat ionships.
The otherfunction of absolute or ientat ion informationis to suggest possible interpretat ions forsensory data in the data-dr iven mode.
It ishere that the preferred or ientat ion wil laffect perceptual  identi f icat ion.
A face,for example, is more l ikely to be suggestedas a possible interpretat ion for an oval at180 ?
or ientat ion than at a 90" orientation.According to this account, the di f f icul ty inrecogniz ing forms at atypical  or ientat ionsis due to a reduction in the ef fect ivenessof the data-dr iven mode.
For all objectsthat have typical  absolute or ientat ions,however, using them to generate possibleinterpretat ions is an eff ic ient heurist ic.A price is paid when the or ientat ion iswrong, but the net effect is probablyfavorable.156Simply stated, I propose thatparametric information be representedrelative to its immediate structuralcontext: superordinate whole and the othercomponent parts at that level.
Someproblems remain.
Should all types ofparametric information be represented inthis way, or are there some types (e.g.color) that are better representedabsolutely.
What constitutes a level withina given object, and what level of one objectcorresponds to a given level of anotherobject when they appear together?
Kosslyn's(1974) recent experiments in imagery lead meto the view that levels within a scene maybe defined by parameters like the overal lsize of the perceptual  element.
If theperceptual  system analyzes only at one levelof resolut ion at a time, then thoseperceptual  elements that fall within thatlevel will be encoded together and relat iveto each other.ConclusionIt was my or iginal  intent to c lar i fySome issues involved in theanalog/propos i t ional  debate in order toreach a deeper level of understanding aboutthe nature of perceptual  knowledge.
Afterhaving made this attempt, I wonder whetheranything has real ly been clarif ied.
Atfirst glance, the big, messy problem ofwhether perceptual  representat ions areanalog or proposit ional  has become a seriesof a lmost-as-messy,  l itt le problems.
Tomake matters worse, these l itt le problemsare subtly intertwined within the fabric ofa complex and integrated system.
Even so, Ithink we are on firmer ground with the morebasic problems and their interre lat ionshipsthan we were before.
This does not meanthat we should focus myopical ly  on thesmal ler problems, for in the end they mustfit together into a coherent whole.
Inanalogy with the view presented earl ier thatthere are both separable parts andintegrated wholes, we must work at bothlevels in our attempts to understand thenature of perceptual  representat ion.During the course of the discussion, Ihave presented my own approach to anintegrated system for represent ingperceptual  knowledge.
At present, it is buta sketch of what a complete theory mightlook like.
(The system is presented ingreater detai l  in another paper (Palmer,1975) to which the reader is referred forfurther information.)
In developing thisformal izat ion I have tried to bui ld- in anumber of general properties.
A few of thedesirable features are as follows.I.
F lex ib i l~t?
and ~eneral iSy.
Theproposed system blends analog, feature, andproposit ional  representat ion into a singleformalism, even though the representat ionalformat is i tsel f  proposit ional.
As notedearlier, the primit ive point- levelrepresentat ion is (second-order) isomorphicwith the st imulus and can be viewed as ananalog representat ion.
At each level withinthe network, the structural  units of therepresentat ion are associated with theIiIIIIiIIIIIIIIIiIIIIIIIIglobal features of that unit at its holisticlevel of resolution.
The various units areorganized into structural networkscharacteristic of many propositionalsystems.
The blend is achieved naturallyfrom a simple rule: each structural unit (or"schema" or "frame") is represented globallyby its holistic parameters and locally byits structural parts.2.
Variable resolution.
The proposednetworks are capable of representingdifferent level of resolution through thedifferent structural levels at which theyare described.
Each scene, object, or parthas many possible levels at which it can beexamined.
The appropriate level of analysisw i l l  vary with the stimulus itself (e.g.,its size on the retina), the task at hand,and the contextual information available.3.
Functional autonomy.
The inclusionof global properties for each structuralunit gives them functional independence(within limits).
In the data-driven mode,any unit may be activated directly bysensory data via the global parameterswithout first activating the lower levelunits.
This means that analysis can beginat virtually any level within the network.In the expectatlon-driven mode, any unit canlook for confirmation of its globalparameters before requesting more finelyresolved information from lower structurallevels.4.
Interactive capability.
Thestructural and parametric relationshipswithin the network provide communicationmechanisms through which the units caninteract in both data-driven andexpectation-drlven modes.
The current stateof one unit can be communicated to relatedunits such that positive results for relatedunits serve to strengthen each other.
Thisallows for a "bootstrap convergence" processamong the units of a schema duringinterpretation.5.
Contextual denendence.
Thestructure of the network and the relativerepresentation mechanisms give contextualfactors paramount importance in a simple butpowerful way.
Given a non-random world inwhich contextual regularities are frequent,the ability to use this information isdesirable, possibly even necessary.Regardless of whether my particularapproach proves to be a good way to realizethese objectives, I have confidence thatthey are important in the design of aworkable model of perceptual representationand processing.REFERENCESBaylor, G.W., A treatise on the mind's eye:an empirical investigation of visualmental imagery.
Unpublished doctoraldissertation, Carnegie-MellonUniversity, 1971.157Bobrow, D.G., Dimensions of representation.In D.G.
Borrow and A.M. Collins (eds.
)Representation and Understanding.
NewYork: Academic Press, 1975.Bobrow, D.G.
and Norman, D.A., Someprinicples of memory schemata.
In D.G.Bobrow and A.M. Collins (eds.
)Re resentation and Understandin .
NewYork: Academic Press 1975.Bower, G.H., Mental imagery and associativelearning.
In L.W.
Gregg (ed.
)Cognition in _~rn in~ an___~d Memory.
NewYork: Wiley, 1972.Cooper, L.A., Mental transformation ofrandom two-dimensional shapes.Psvchol__~, 1975.Cooper, L.A. and Shepard, R.N.,Chronometric studies of the rotation ofmental images.
In W.G.
Chase (ed.
)Visual Information Processing.
NewYork: Academic Press, 1973.Egeth,H.W., Parallel versus serial processesin multidimensional stimulusdiscrimination.
~ and~svchoDhvsics, 1966, i, 245-252.Frost, N. and Wolf, J., How "visual" isvisual memory?
Paper presented at the14th Annual Meeting of the PsychonomicSociety, St. Louis, Missouri, November1973.Garner, W.R., The ~ ~f InformatioStructure.
Potomac, Maryland:Erlbaum, 1974.Kosslyn, S.M., Constructing visual images:An exercise in neo-mentalism.Unpublished doctoral dissertationStanford University, 1974.Kosslyn, S.M.
and Pommerantz, J.R., Mentalimagery reconsidered: An analysis ofPylyshyn's critique, in preparation.Nickerson, R.S., Same-dlfferent reactiontimes with multi-attribute stimulusdifferences.
~ and MotorSk i~,  1967, 24, 543-554.Norman, D.A.
and Bobrow, D.G., On the roleof active memory processes in perceptionand cognition.
In C.N.
Cofer (ed.)
T~St r_~ of Human ~emoFy.
SanFrancisco: W.~.
Freeman, 1975.Norman, D.A.
and Rumelhart, D.E., Memoryand Knowledge.
in D.A.
Norman, D.E.Rumelhart, and LNR Research Group.in ~ .
SanFrancisco: W.H.
Freeman, 1975.Palmer, S.E., Structural aspects ofperceptual organization.
Unpublisheddoctoral dissertation, University ofCalifornia, San Diego, 1974.Palmer, S.E., Visual perception and worldknowledge.
In D.A.
Norman, D.E.Rumelhart, and LNR Research Group,i_nn ~ .
SanFrancisco: W.H.
Freeman, 1975,Pylyshyn, Z.W., What the mind's eye tellsthe mind's brain: A critique of mentalimagery.
Psychological Bulletin, 1973,80, 1-24.Quillian, M.R., Semantic Memory.
In M.Minsky (ed.)
Semantic InformationProcessing.
Cambridge, Massachusetts:MIT Press, 1968.Reed, S.K., PsFchological Processes .
i_nnPattern Recognition.
New York: AcademicPress, 1973.Reed, S.K., Structural descriptions and thelimitation of visual images.
Memory andCognition, 1974, ~, 329-336.Rips, L.J., Sh~ben, E.J.
and Smith E.E.,Semantic distance and the verificationof semantic relations.
Journal ofVerbal Learning an~ Verbal Behavior,1973, 12, 1-20.Rock, I., Orientation an~ Form.
New York:Academic Press, 1974.Rosch, E., Cognitive representations ofsemantic categories.
Journal ofExperimental Psychology.
General, inDress.Shepard, R.N.
and Metzler, J., Mentalrotation of three-dimensional objects.Scienqg, 1971, 171, 701-703.Smith, E.E., Shoben, E.J.
and Rips, L.J.,Structure and processing in semanticmemory; A feature model for semanticdecisions.
Psycological Review, 1974,81, 214-241.Winston, P.H., Learning to identify toyblock structures.
In R.L.
Solso (ed.
)Coqtemporary Issues in CognitivePsychology: The Loyola Symposium.Washington, D.C.: Winston, 1973.158IIIIIIIIIII1I1IIlIIIIIIIIIIIIIIIIIIIFigure i:An illustration of structural andparametric differences?Figure 2:An example of stimuli used in themental synthesis task and correspondingsynthesis times (Palmer, 1974).Figure 3:An example of structural organizationshowing points, lines, parts, and thewhole figure,Figure 4:The structure of integral andseparable parameters,Figure 5:An il lustration of relative and absoluterepresentation of orientation parametersfor a FACE and two EYES.SameSTRUCTUREDifferentSynthesizedFigureGoodParts?
o ??
?
?
oMEAN SYNTHESESTIME (in seconds)Figure All 20shown figures2.16 2.04Bad Parts?
?
0 ?5.03 5.05AE ~ 'BD C?
y?
\\[~\] \[ ~eD~.\]\[~\] [~\] [~\] [Be\] \[c~\] [DE\]\[El \[B\] \[C\]C\] \ [ \ ]  C \ ] .
C\] \ [ \ ]0-90 ~ +90\[FACE\]~ \[~_18o\] -~159
