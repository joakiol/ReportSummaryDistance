Unsupervised Learning of Morphology for English and InuktitutHoward JohnsonInstitute for Information Technology,National Research CouncilHoward.Johnson@nrc.gc.caJoel MartinInstitute for Information TechnologyNational Research CouncilJoel.Martin@nrc.gc.caAbstractWe describe a simple unsupervised techniquefor learning morphology by identifying hubsin an automaton.
For our purposes, a hub is anode in a graph with in-degree greater thanone and out-degree greater than one.
We cre-ate a word-trie, transform it into a minimalDFA, then identify hubs.
Those hubs markthe boundary between root and suffix,achieving similar performance to more com-plex mixtures of techniques.1 IntroductionTo recognize a morpheme boundary, for example be-tween a root and a suffix, a learner must have seen atleast two roots with that suffix and at least two suffixeswith that root.
For instance, 'helpful', 'helpless', 'harm-ful?, and 'harmless' would be enough evidence to guessthat those words could be divided as 'help/ful','help/less', 'harm/ful', and 'harm/less'.
Without seeingvarying roots and varying suffixes, there is no reason toprefer one division to another.We can represent a language's morphology as agraph or automaton, with the links labeled by charactersand the nodes organizing which characters can occurafter specific prefixes.
In such an automaton, the mor-pheme boundaries would be hubs, that is, nodes with in-degree greater than one and out-degree greater than one.Furthermore, this automaton could be simplified by pathcompression to remove all nodes with in-degree andout-degree of one.
The remaining automaton could befurther modified to produce a graph with one source,one sink, and all other nodes would be hubs.A hub-automaton, as described above, matches theintuitive idea that a language's morphology allows oneto assemble a word by chaining morphemes together.This representation highlights the morphemes while alsorepresenting morphotactic information.
Phonologicalinformation can be represented in the same graph butmay be more economically represented in a separatetransducer that can be composed with the hub-automaton.For identifying the boundary between roots and suf-fixes, the idea of hubs is essentially the same as Gold-smith?s (2001) signatures or the variations betweenGaussier?s (1999) p-similarity words.
A signature is aset of suffixes, any of which can be added to severalroots to create a word.
For example, in English anysuffix in the set: NULL, ?s?, ?ed?, ?ing?, can be added to?want?
or ?wander?
to form a word.
Here, NULL meansthe empty suffix.In a hub automaton, the idea is more general than inprevious work and applies to more complex morpholo-gies, such as those for agglutinative or polysyntheticlanguages.
In particular, we are interested in unsuper-vised learning of Inuktitut morphology in which a singlelexical unit can often include a verb, two pronouns, ad-verbs, and temporal information.In this paper, we describe a very simple techniquefor identifying hubs as a first step in building a hub-automaton.
We show that, for English, this techniquedoes as well as more complex collections of techniquesusing signatures.
We then show that the technique alsoworks, in a limited way, for Inuktitut.
We close with adiscussion of the limitations and our plans for morecomplete learning of hub-automata.2 Searching for hubsThe simplest way to build a graph from a raw corpus ofwords is to construct a trie.
A trie is a tree representa-tion of the distinct words with a character label on eachbranch.
The trie can be transformed into a minimal,acyclic DFA (deterministic finite automaton), sharingnodes that have identical continuations.
There are wellknown algorithms for doing this (Hopcroft & Ullman,1969).
For example, suppose that, in a given corpus, theprefix ?friend?
occurs only with the suffixes ?NULL?,?s?, and ?ly?
and the word ?kind?
occurs only with thesame suffixes.
The minimal DFA has merged the nodesthat represent those suffixes, and as a result has fewerlinks and fewer nodes than the original trie.In this DFA, some hubs will be obvious, such as forthe previous example.
These are morpheme boundaries.There will be other nodes that are not obvious hubs.Some may have high out-degree but an in-degree ofone; others will have high in-degree but an out-degreeof one.Many researchers, including Schone and Jurafsky(2000), Harris (1958), and D?jean (1998), suggestlooking for nodes with high branching (out-degree) or alarge number of continuations.
That technique is alsoused as the first step in Goldsmith?s (2001) search forsignatures.
However, without further processing, suchnodes are not reliable morpheme boundaries.Other candidate hubs are those nodes with high out-degree that are direct descendants, along a single path,of a node with high in-degree.
In essence, these arestretched hubs.
Figure 1 shows an idealized view of ahub and a stretched hub.Figure 1: An idealized view of a hub and astretched hub.
The lines are links in the automatonand each would be labeled with a character.
Theovals are nodes and are only branching points.In a minimized DFA of the words in a corpus, wecan identify hubs and the last node in stretched hubs asmorpheme boundaries.
These roughly correspond to thesignatures found by other methods.The above-mentioned technique for hub searchingmisses boundaries if a particular signature only appearsonce in a corpus.
For instance, the signature for ?help?might be ?ed?, ?s?, ?less?, ?lessly?, and NULL; and sup-pose there is no other word in the corpus with the samesignature.
The morpheme boundaries ?help-less?
and?help-ed?
will not be found.The way to generalize the hub-automaton to includewords that were never seen is to merge hubs.
This is acomplex task in general.
In this paper, we propose avery simple method.
We suggest merging each nodethat is a final state (at the end of a word) with each hubor stretched hub that has in-degree greater than two.Doing so sharply increases the number of words ac-cepted by the automaton.
It will identify more correctmorpheme boundaries at the expense of including somenon-words.These two techniques, hub searching and simplenode merging, were implemented in a program called?HubMorph?
(hub-automaton morphology).3 Related WorkMost previous work in unsupervised learning of mor-phology has focused on learning the division betweenroots and suffixes (e.g., Sproat, 1992; Gaussier, 1999;D?jean, 1996; Goldsmith, 2001).
The hope is that thesame techniques will work for extracting prefixes.However, even that will not handle the complex combi-nations of infixes that are possible in agglutinative lan-guages like Turkish or polysynthetic languages likeInuktitut.This paper presents a generalization of one class oftechniques that search for signatures or positions in atrie with a large branching factor.
Goldsmith (2001)presents a well-developed and robust version of thisclass and has made his system, Linguistica, freely avail-able (Goldsmith, 2002).Linguistica applies a wide array of techniques in-cluding heuristics and the application of the principle ofMinimum Description Length (MDL) to find the bestdivision of words into roots and suffixes, as well as pre-fixes in some cases.
The first of these techniques findsthe points in a word with the highest number of possiblesuccessors in other words.
With all these techniques,Linguistica seeks optimal breakpoints in each word.
Inthis case, optimal means the minimal number of bitsnecessary to encode the whole collection.There are also techniques that attempt to use seman-tic cues, arguing that knowing the signatures is not suf-ficient for the task.
For example, Yarowsky andWicentowski (2000; cf.
Schone & Jurafsky, 2000) pre-sent a method for determining whether singed can besplit into sing and ed based on whether singed and singappear in the same contexts.
Adopting a technique likethis would increase the precision of HubMorph.
In ad-dition, some semantic approach is absolutely essentialfor identifying fusional morphology, where the word(sang) is not a simple composition of a root (sing) andmorphemes.4 EvaluationAs noted above, Linguistica uses many techniques tolearn morphology, including a fairly complex system forcounting bits.
We tested whether the two techniquespresented in this paper, hub searching and simple nodemerging, achieve the same performance as Linguistica.If so, the simpler techniques might be preferred.
Also,we would be justified using them for more complexmorphologies.The input to Linguistica and HubMorph was the textof Tom Sawyer.
The performance of both was com-pared against a gold standard division of the distinctwords in that novel.
The gold standard was based ondictionary entries and the judgment of two Englishspeakers.In matching the gold standard words to divisionspredicted by either system, we made the following as-sumptions.
a) Words with hyphens are split at the hy-phen to match Linguistica?s assumption.
b) If the goldstandard has a break before and after a single character,to capture non-concatenative modification, either breakmatches.
An example would be ?mud-d-y?.
c) An apos-trophe at a morpheme boundary is ignored for compari-son matching to allow it to stick to the root or to thesuffix.
d) The suffix split proposed must result in a suf-fix of 5 or fewer characters, again to match Linguis-tica?s assumption.Table 1 show the results of this comparison for Lin-guistica, hub-searching alone, and HubMorph (both hubsearching and node merging).
Hub-searching alone issufficient to achieve the same precision as Linguisticaand nearly the same recall.
Both of the techniques to-gether are sufficient to achieve the same precision andrecall as Linguistica.
The recall for all is low becausethe list of words in Tom Sawyer is not long enough toinclude most acceptable combinations of roots and suf-fixes.
A longer input word list would improve thisscore.System Recall PrecisionLinguistica 0.5753 0.9059Hub-Searching 0.4451 0.9189HubMorph 0.5904 0.9215Table 1: The recall and precision of Linguistica,Hub-searching alone, and HubMorph.
Recall is theproportion of distinct words from Tom Sawyer thatare correctly divided into root and suffix.
Precisionis the proportion of predicted divisions that are cor-rect.5 DiscussionHubMorph achieves the same performance as Linguis-tica on the words in Tom Sawyer.
It does so with ageneral technique based on building a hub-automaton.In addition to being simple, HubMorph can be general-ized to deal with more complex morphologies.We have applied HubMorph to Inuktitut for dividingsuch words as ikajuqtaulauqsimajunga (?I was helped inthe recent past?, ikajuq-tau-lauq-sima-junga).
The pathin a hub automaton for most Inuktitut words would havemany hubs, because the words have many divisions.Currently, there are many limitations.
The searchfor hubs in the middle of words is very difficult andrequires merging nodes to induce new words.
This willbe necessary because Inuktitut theoretically has billionsof words and only a small fraction of them has occurredin our source (the Nunavut, Canada Hansards).Also, because each word has many morphemes, it isdifficult to correctly detect the divisions for roots andsuffixes.
In general, there are no prefixes in Inuktitut,only infixes and suffixes.Finally, there are many dialects of Inuktitut andmany spelling variations.
In general, the written lan-guage is phonetic and the spelling reflects all the varia-tions in speech.When HubMorph performs unsupervised learning ofInuktitut roots, it achieves a precision of 31.8% and arecall of 8.1%.
It will be necessary to learn more ofthe infixes and suffixes to improve these scores.We believe that hub-automata will be the basis of ageneral solution for IndoEuropean languages as well asfor Inuktitut.ReferencesD?jean, H. 1998.
Morphemes as necessary concepts forstructures: Discovery from untagged corpora.
Uni-v e r s i t y  o f  Caen-Basse Normandie.http://citeseer.nj.nec.com/19299.htmlGaussier E. (1999).
Unsupervised learning of deriva-tional morphology from inflectional lexicons.
In:Kehler A and Stolcke A, eds, ACL workshop on Un-supervised Methods in Natural Language Learning,College Park, MD.Goldsmith, J.A.
(2001).
Unsupervised Learning of theMorphology of a Natural Language.
ComputationalLinguistics, 27:2 pp.
153-198.Goldsmith, J.A.
(2002).
Linguistica software.http://humanities.uchicago.edu/faculty/goldsmith/Linguistica2000/.Harris, Z.
(1951).
Structural Linguistics.
University ofChicago Press.Hopcroft, J.E.
& Ullman, J.D.
(1969).
Formal Lan-guages and their Relation to Automata.
Addison-Wesley, Reading, MA.Schone, P., & Jurafsky, D. (2000).
Knowledge-free in-duction of morphology using latent semantic analy-sis.
In Proceedings of CoNLL-2000 and LLL-2000,pp.
67--72 Lisbon, Portugal.Sproat, R. (1992).
Morphology and Computation, Cam-bridge, MA, MIT Press.Yarowsky, D. & Wicentowski, R. (2000).
Minimallysupervised morphological analysis by multimodalalignment.
In K. Vijay-Shanker and Chang-NingHuang, editors, Proceedings of the 38th Meeting ofthe Association for Computational Linguistics, pages207-216, Hong Kong.
