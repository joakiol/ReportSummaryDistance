Chinese Part-of-Speech Tagging:One-at-a-Time or All-at-Once?Word-Based or Character-Based?Hwee Tou Ng  and  Jin Kiat LowDepartment of Computer ScienceNational University of Singapore3 Science Drive 2, Singapore 117543{nght, lowjinki}@comp.nus.edu.sgAbstractChinese part-of-speech (POS) taggingassigns one POS tag to each word in aChinese sentence.
However, since words arenot demarcated in a Chinese sentence,Chinese POS tagging requires wordsegmentation as a prerequisite.
We couldperform Chinese POS tagging strictly afterword segmentation (one-at-a-timeapproach), or perform both wordsegmentation and POS tagging in acombined, single step simultaneously (all-at-once approach).
Also, we could choose toassign POS tags on a word-by-word basis,making use of word features in thesurrounding context (word-based), or on acharacter-by-character basis with characterfeatures (character-based).
This paperpresents an in-depth study on such issues ofprocessing architecture and featurerepresentation for Chinese POS tagging,within a maximum entropy framework.
Wefound that while the all-at-once, character-based approach is the best, the one-at-a-time,character-based approach is a worthwhilecompromise, performing only slightly worsein terms of accuracy, but taking shorter timeto train and run.
As part of our investigation,we also built a state-of-the-art Chinese wordsegmenter, which outperforms the bestSIGHAN 2003 word segmenters in theclosed track on 3 out of 4 test corpora.1 IntroductionMost corpus-based language processing researchhas focused on the English language.Theoretically, we should be able to just portcorpus-based, machine learning techniquesacross different languages since the techniquesare largely language independent.
However, inpractice, the special characteristics of differentlanguages introduce complications.
For Chinesein particular, words are not demarcated in aChinese sentence.
As such, we need to performword segmentation before we can proceed withother tasks such as part-of-speech (POS) taggingand parsing, since one POS tag is assigned toeach Chinese word (i.e., all characters in aChinese word have the same POS tag), and theleaves of a parse tree for a Chinese sentence arewords.To build a Chinese POS tagger, the followingquestions naturally arise:(1) Should we perform Chinese POS taggingstrictly after word segmentation in two separatephases (one-at-a-time approach), or perform bothword segmentation and POS tagging in acombined, single step simultaneously (all-at-onceapproach)?
(2) Should we assign POS tags on a word-by-word basis (like in English), making use of wordfeatures in the surrounding context (word-based),or on a character-by-character basis withcharacter features (character-based)?This paper presents an in-depth study on suchissues of processing architecture and featurerepresentation for Chinese POS tagging, within amaximum entropy framework.
We analyze theperformance of the different approaches in ourattempt to find the best approach.
To ourknowledge, our work is the first to systematicallyinvestigate such issues in Chinese POS tagging.2 Word SegmentationAs a first step in our investigation, we built aChinese word segmenter capable of performingword segmentation without using POS taginformation.
Since errors in word segmentationwill propagate to the subsequent POS taggingphase in the one-at-a-time approach, in order forour study to give relevant findings, it is importantthat the word segmenter we use gives state-of-the-art accuracy.The word segmenter we built is similar to themaximum entropy word segmenter of (Xue andShen, 2003).
Our word segmenter uses amaximum entropy framework and is trained onmanually segmented sentences.
It classifies eachChinese character given the features derivedfrom its surrounding context.
Each character canbe assigned one of 4 possible boundary tags: ?b?for a character that begins a word and is followedby another character, ?m?
for a character thatoccurs in the middle of a word, ?e?
for acharacter that ends a word, and ?s?
for acharacter that occurs as a single-character word.2.1 Word Segmenter FeaturesBesides implementing a subset of the featuresdescribed in (Xue and Shen, 2003), we also cameup with three additional types of features ((d) ?
(f) below) which improved the accuracy of wordsegmentation.
The default feature, boundary tagfeature of the previous character, and boundarytag feature of the character two before the currentcharacter used in (Xue and Shen, 2003) weredropped from our word segmenter, as they didnot improve word segmentation accuracy in ourexperiments.In the following feature templates used in ourword segmenter, C refers to a Chinese characterwhile W refers to a Chinese word.
Templates (a)?
(c) refer to a context of five characters (thecurrent character and two characters to its leftand right).
0C  denotes the current character, nC( nC? )
denotes the character n  positions to theright (left) of the current character.
(a) )2,1,0,1,2(n Cn ?
?=(b) )1,0,1,2n(CC 1nn ?
?=+(c) 11CC?
(d) 00CW(e) )C(Pu 0(f) )C(T)C(T)C(T)C(T)C(T 21012 ?
?For example, given the character sequence????
??
?, when considering the character??
?, template (a) results in the followingfeatures 2-C =?
1-C =?
0C =?
1C =?
2C =?to be set to 1, template (b) results in the features12- CC ?
=??
01- CC =??
10CC =?
?21CC =??
to be set to 1.2.2 Our Additional Features:CW 00 This feature captures the wordcontext in which the current character is found.For example, the character  ???
within the word?????
will have the feature00CW =???_?
set to 1.
This feature helps inrecognizing seen words.
:)C(Pu 0 A punctuation symbol is usually agood indication of a word boundary.
This featurechecks whether the current character is apunctuation symbol (such as ??
?, ?-?, ???).
:)C(T)C(T)C(T)C(T)C(T 21012 ??
Thisfeature is especially helpful in predicting theword segmentation of dates and numbers, whoseexact characters may not have been seen in thetraining text.
Four type classes are defined:numbers represent class 1, dates (??
?, ???,??
?, the Chinese character for ?day?, ?month?,?year?, respectively) represent class 2, Englishletters represent class 3, and other charactersrepresent class 4.
For example, when consideringthe character ???
in the character sequence????
?R?, the feature)()( 22 CTCT K?
=11243 will be set to 1 ( ??
?and ???
are the Chinese characters for ?9?
and?0?
respectively).2.3 TestingDuring testing, the probability of a boundary tagsequence assignment n...tt1  given a charactersequence ncc ...1  is determined by using themaximum entropy classifier to compute theprobability that a boundary tag ti is assigned toeach individual character ci.
If we were to justassign each character the boundary tag with thehighest probability, it is possible that theclassifier produces a sequence of invalid tags(e.g., ?m?
followed by ?s?).
To eliminate suchpossibilities, we implemented a dynamicprogramming algorithm which considers onlyvalid boundary tag sequences given an inputcharacter sequence.
At each character position i,the algorithm considers each last word candidateending at position i and consisting of Kcharacters in length (K = 1, ?, 20 in ourexperiments).
To determine the boundary tagassignment to the last word W with K characters,the first character of W is assigned boundary tag?b?, the last character of W is assigned tag ?e?,and the intervening characters are assigned tag?m?.
(If W is a single-character word, then thesingle character is assigned ?s?.)
In this way, thedynamic programming algorithm only considersvalid tag sequences, and we are also able to makeuse of the 00CW feature during testing.After word segmentation is done by themaximum entropy classifier, a post-processingstep is applied to correct inconsistentlysegmented words made up of 3 or morecharacters.
A word W is defined to beinconsistently segmented if the concatenation of2 to 6 consecutive words elsewhere in thesegmented output document matches W. In thepost-processing step, the segmentation of thecharacters of these consecutive words is changedso that they are segmented as a single word.
Toillustrate, if the concatenation of 2 consecutivewords ???
???
in the segmented outputdocument matches another word ?????
?,then ???
???
will be re-segmented as?????
?.2.4 Word Segmenter Experimental ResultsTo evaluate the accuracy of our word segmenter,we carried out 10-fold cross validation (CV) onthe 250K-word Penn Chinese Treebank (CTB)(Xia et al, 2000) version 3.0.
The Java opennlpmaximum entropy package from sourceforge1was used in our implementation, and trainingwas done with a feature cutoff of 2 and 100iterations.The accuracy of word segmentation ismeasured by recall (R), precision (P), and F-measure ( )/(2 PRRP + ).
Recall is theproportion of correctly segmented words in thegold-standard segmentation, and precision is theproportion of correctly segmented words in wordsegmenter?s output.Figure 1 gives the word segmentation F-measure of our word segmenter based on 10-foldCV on the 250K-word CTB.
Our wordsegmenter achieves an average F-measure of95.1%.
This accuracy compares favorably with1 http://maxent.sourceforge.net(Luo, 2003), which reported 94.6% wordsegmentation F-measure using his full parserwithout additional lexical features, and about94.9%2 word segmentation F-measure using onlyword boundaries information, no POS tags orconstituent labels, but with lexical featuresderived from a 58K-entry word list.The average training time taken to train on90% of the 250K-word CTB was 12 minutes,while testing on 10% of CTB took about 1minute.
The running times reported in this paperwere all obtained on an Intel Xeon 2.4GHzcomputer with 2GB RAM.93.594.094.595.095.596.096.597.01 2 3 4 5 6 7 8 9 10Experiment NumberWordSegF-Measure(%)Figure 1: CTB 10-fold CV word segmentation F-measure for our word segmenterAs further evaluation, we tested our wordsegmenter on all the 4 test corpora (CTB,Academia Sinica (AS), Hong Kong CityU (HK),and Peking University (PK)) of the closed trackof the 2003 ACL-SIGHAN-sponsored FirstInternational Chinese Word SegmentationBakeoff (Sproat and Emerson, 2003).
For each ofthe 4 corpora, we trained our word segmenter ononly the official released training data of thatcorpus.
Training was conducted with featurecutoff of 2 and 100 iterations (these parameterswere obtained by cross validation on the trainingset), except for the AS corpus where we usedcutoff 3 since the AS training corpus was too bigto train with cutoff 2.Figure 2 shows our word segmenter?s F-measure (based on the official wordsegmentation scorer of 2003 SIGHAN bakeoff)compared to those reported by all the 2003SIGHAN participants in the four closed tracks(ASc, HKc, PKc, CTBc).
Our word segmenterachieved higher F-measure than the best reportedF-measure in the SIGHAN bakeoff on the ASc,HKc, and PKc corpus.
For CTBc, due to the2 Based on visual inspection of Figure 3 of (Luo,2003)exceptionally high out-of-vocabulary (OOV) rateof the test data (18.1%), our word segmenter?s F-measure ranked in the third position.
(Note thatthe top participant of CTBc (Zhang et al, 2003)used additional named entity knowledge/data intheir word segmenter).82838485868788899091929394959697980 1 2 3 4 5 6WordSegF-Measure(%)Sighan Paticipants Our Word SegmenterHKCASC PKC CTBC CTBoFigure 2: Comparison of word segmentation F-measure for SIGHAN bakeoff3 tasksWe also compared the F-measure of our wordsegmenter on CTBO, the open category of theCTB corpus, where participants were free to useany available resources and were not restricted toonly the official released training data of CTB.On this CTBO task, we used as additional trainingdata the AS training corpus provided bySIGHAN, after converting the AS trainingcorpus to GB encoding.
We found that with thisadditional AS training data added to the original3 Last ranked participant of SIGHAN CTB (closed)with F-measure 73.2% is not shown in Figure 2 due tospace constraint.official released CTB training data of SIGHAN,our word segmenter achieved an F-measure of92.2%, higher than the best reported F-measurein the CTB open task.
With sufficient trainingdata, our word segmenter can perform very well.In our evaluation, we also found that theadditional features we introduced in Section 2.2and the post-processing step consistentlyimproved average word segmentation F-measure,when evaluated on the 4 SIGHAN test corpora inthe closed track.
The additional featuresimproved F-measure by an average of about0.4%, and the post-processing step added on topof the use of all features further improved F-measure by 0.3% (i.e., for a cumulative total of0.7% increase in F-measure).3 One-at-a-Time, Word-Based POS TaggerNow that we have successfully built a state-of-the-art Chinese word segmenter, we are ready toexplore issues of processing architecture andfeature representation for Chinese POS tagging.An English POS tagger based on maximumentropy modeling was built by (Ratnaparkhi,1996).
As a first attempt, we investigatedwhether simply porting the method used by(Ratnaparkhi, 1996) for English POS taggingwould work equally well for Chinese.
Applyingit in the context of Chinese POS tagging,Ratnaparkhi?s method assumes that words arepre-segmented, and it assigns POS tags on aword-by-word basis, making use of wordfeatures in the surrounding context.
This givesrise to a one-at-a-time, word-based POS tagger.Note that in a one-at-a-time approach, theword-segmented input sentence given to the POStagger may contain word segmentation errors,which can lower the POS tagging accuracy.3.1 FeaturesThe following feature templates were chosen.W refers to a word while POS  refers to the POStag assigned.
The feature )W(Pu 0  checks if allcharacters in the current word are punctuationcharacters.
Feature (e) encodes the class ofcharacters that constitute the surrounding words(similar to feature (f) of the word segmenter inSection 2.1).
Four type classes are defined: aword is of class 1 if it is a number; class 2 if theword is made up of only numeric charactersfollowed by ??
?, ???
?or ???
; class 3 whenthe word is made up of only English charactersand optionally punctuation characters; class 4otherwise.
(a) )2,1,0,1,2n(Wn ?
?=(b) )1,0,1,2n(WW 1nn ?
?=+(c) 11WW?
(d) )W(Pu 0(e) )W(T)W(T)W(T)W(T)W(T 21012 ??
(f) )W(POS 1?
(g) )W(POS)W(POS 12 ?
?3.2 TestingThe testing procedure is similar to the beamsearch algorithm of (Ratnaparkhi, 1996), whichtags each word one by one and maintains, as itsees a new word, the N most probable POS tagsequence candidates up to that point in thesentence.
For our experiment, we have chosen Nto be 3.3.3 Experimental ResultsThe 250K-word CTB corpus, tagged with 32different POS tags (such as ?NR?, ?PU?, etc)was employed in our evaluation of POS taggersin this study.
We ran 10-fold CV on the CTBcorpus, using our word segmenter?s output foreach of the 10 runs as the input sentences to thePOS tagger.
POS tagging accuracy is simplycalculated as (number of characters assignedcorrect POS tag) / (total number of characters).79808182838485868788891 2 3 4 5 6 7 8 9 10Experiment NumberPOSAccuracy(%)Figure 3: POS tagging accuracy using one-at-a-time, word-based POS taggerThe POS tagging accuracy is plotted in Figure3.
The average POS tagging accuracy achievedfor the 10 experiments was only 84.1%, far lowerthan the 96% achievable by English POS taggerson the English Penn Treebank tag set.
Theaverage training time was 25 minutes, whiletesting took about 20 seconds.
As an experiment,we also conducted POS tagging using only thefeatures (a), (f), and (g) in Section 3.1, similar to(Ratnaparkhi, 1996), and we obtained an averagePOS tagging accuracy of 83.1% for that set offeatures.The features that worked well for English POStagging did not seem to apply to Chinese in themaximum entropy framework.
Languagedifferences between Chinese and English haveno doubt made the direct porting of an EnglishPOS tagging method to Chinese ineffective.4 One-at-a-Time, Character-Based POSTaggerSince one-at-a-time, word-based POS taggingdid not yield good accuracy, we proceeded toinvestigate other combinations of processingarchitecture and feature representation.
Weobserved that character features weresuccessfully used to build our word segmenterand that of (Xue and Shen, 2003).
Similarly,character features were used to build a maximumentropy Chinese parser by (Luo, 2003), where hisparser could perform word segmentation, POStagging, and parsing in an integrated, unifiedapproach.
We hypothesized that assigning POStags on a character-by-character basis, makinguse of character features in the surroundingcontext may yield good accuracy.
So we nextinvestigate such a one-at-a-time, character-basedPOS tagger.4.1 FeaturesThe features that were used for our wordsegmenter ((a) ?
(f)) in Section 2.1 were yetagain applied, with two additional features (g)and (h) to aid POS tag prediction.
(a) )2,1,0,1,2(n Cn ?
?=(b) )1,0,1,2n(CC 1nn ?
?=+(c) 11CC?
(d) 00CW(e) )C(Pu 0(f) )C(T)C(T)C(T)C(T)C(T 21012 ??
(g) )C(POS0W1?
(h) )C(POS)C(POS00 W1W2 ??:)C(POS0W1?
This feature refers to thePOS tag of the previous character before thecurrent word.
For example, in the charactersequence ??
?
??
?, when considering thecharacter ??
?, the feature )C(POS0W1?
=PN isset to 1 (assuming ???
was tagged as PN).
:)C(POS)C(POS00 W1W2 ??
For the sameexample given above, when considering thecharacter ??
?, the feature)C(POS)C(POS00 W1W2 ??
=P_PN is set to 1(assuming ???
was tagged as P and ???
wastagged as PN).4.2 TestingThe testing algorithm is similar to that describedin Section 3.2, except that the probability of aword being assigned a POS tag t is estimated bythe product of the probability of its individualcharacters being assigned the same POS tag t.For example, when estimating the probability of?????
being tagged NR, we find the productof the probability of ???
being tagged NR, ??
?being tagged NR, and ???
being tagged NR.That is, we enforce the constraint that allcharacters within a segmented word in the pre-segmented input sentence must have the samePOS tag.4.3 Experimental Results10-fold CV for CTB is repeated for this POStagger.
Figure 4 shows the detailed POS taggingaccuracy.
With a one-at-a-time, character-basedPOS tagger, the average POS tagging accuracyimproved to 91.7%, 7.6% higher than thatachieved by the one-at-a-time, word-based POStagger.
The average training timing was 55minutes, while testing took about 50 seconds.899091929394951 2 3 4 5 6 7 8 9 10Experiment NumberPOSAccuracy(%)Figure 4: POS tagging accuracy using one-at-a-time, character-based POS taggerWhen a paired t-test was carried out tocompare character-based and word-based one-at-a-time approaches, the character-based approachwas found to be significantly better than theword-based approach, at the level of significance0.01.Assuming a one-at-a-time processingarchitecture, Chinese POS tagging using acharacter-based approach gives higher accuracycompared to a word-based approach.5 All-at-Once, Character-Based POSTagger and SegmenterEncouraged by the success of character features,we next explored whether a change in processingarchitecture, from one-at-a-time to all-at-once,while still retaining the use of character features,could give further improvement to POS taggingaccuracy.
In this approach, both wordsegmentation and POS tagging will be performedin a combined, single step simultaneously.
Eachcharacter is assigned both a boundary tag and aPOS tag, for example ?b_NN?
(i.e., the firstcharacter in a word with POS tag NN).
Thus,given 4 possible boundary tags and 32 uniquePOS tags present in the training corpus, eachcharacter can potentially be assigned one of(4?32) classes.5.1 FeaturesThe features we used are identical to thoseemployed in the character-based POS taggerdescribed in section 4.1, except that features (g)and (h) are replaced with those listed below.
Inthe following templates, B refers to the boundarytag assigned.
For example, given the charactersequence ??
?
??
?, when considering thecharacter ??
?, template (g) results in the feature)C(POS)C(B00 W1W1 ??
=s_PN to be set to 1.
(assuming ???
was tagged as PN).
(g) )C(POS)C(B00 W1W1 ??
(h) )C(POS)C(B)C(POS)C(B0000 W1W1W2W2 ???
?Note that this approach is essentially that usedby (Luo, 2003), since his parser performs bothword segmentation and POS tagging (as well asparsing) in one unified approach.
The features weused are similar to his tag features, except thatwe did not use features with three consecutivecharacters, since we found that the use of thesefeatures did not improve accuracy.
We alsoadded additional features (d) ?
(f).5.2 TestingBeam search algorithm is used with N = 3 duringthe testing phase.5.3 Experimental Results10-fold CV on CTB was carried out again, usingunsegmented test sentences as input to theprogram.Figure 5 shows the word segmentation F-measure, while Figure 6 shows the POS taggingaccuracy achieved by this approach.
With an all-at-once, character-based approach, an averageword segmentation F-measure of 95.2% and anaverage POS tagging accuracy of 91.9% wasachieved.
The average training timing was 3hours, while testing took about 20 minutes.There is a slight improvement in wordsegmentation and POS tagging accuracy usingthis approach, compared to the one-at-a-time,character-based approach.
When a paired t-testwas carried out at the level of significance 0.01,the all-at-once approach was found to besignificantly better than the one-at-a-timeapproach for POS tagging accuracy, although thedifference was insignificant for wordsegmentation.93.093.594.094.595.095.596.096.597.01 2 3 4 5 6 7 8 9 10Experiment NumberWordSegF-Measure(%)Figure 5: CTB 10-fold CV word segmentation F-measure using an all-at-once approach899091929394951 2 3 4 5 6 7 8 9 10Experiment NumberPOSAccuracy(%)Figure 6: CTB 10-fold CV POS tagging accuracyusing an all-at-once approachHowever, the time required for training andtesting is increased significantly for the all-at-once approach.
When efficiency is a majorconsideration, or if high quality hand-segmentedtext is available, the one-at-a-time, character-based approach could indeed be a worthwhilecompromise, performing only slightly worse thanthe all-at-once approach.
Table 1 summarizes themethods investigated in this paper.
Total testingtime includes both word segmentation and POStagging on 10% of CTB data.
Note that an all-at-once, word-based approach is not applicable asword segmentation requires character features todetermine the word boundaries.Method Word SegF-measure(%)POSAccuracy(%)TotalTestingTimeOne-at-a-TimeWord-Based95.1 84.1 1 min20 secsOne-at-a-TimeChar-Based95.1 91.7 1 min50 secsAll-At-OnceChar-Based95.2 91.9 20 minsTable 1: Summary table on the various methodsinvestigated for POS tagging6 DiscussionsWord-based or character-based?
The findingsthat a character-based approach is better than aword-based approach for Chinese POS tagging isnot too surprising.
Unlike in English where eachEnglish letter by itself does not possess anymeaning, many Chinese characters have welldefined meanings.
For example, the singleChinese character ???
means ?know?.
Andwhen a character appears as part of a word, theword derives part of its meaning from thecomponent characters.
For example, ???
?means ?knowledge??
????
means ?ignorant?,????
means ?well-known?, etc.
In addition,since the out-of-vocabulary (OOV) rate forChinese words is much higher than the OOV ratefor Chinese characters, in the presence of anunknown word, using the component charactersin the word to help predict the correct POS tag isa good heuristic.One-at-a-time or all-at-once?
The all-at-onceapproach, which considers all aspects ofavailable information in an integrated, unifiedframework, can make better informed decisions,but incurs a higher computational cost.7 Related WorkMuch previous research on Chinese languageprocessing focused on word segmentation(Sproat et al, 1996; Teahan et al, 2000; Sproatand Emerson, 2003).
Relatively less work hasbeen done on Chinese POS tagging.
Kwong andTsou (2003) discussed the implications of POSambiguity in Chinese and the possibleapproaches to tackle this problem when tagging acorpus for NLP tasks.
Zhou and Su (2003)investigated an approach to build a Chineseanalyzer that integrated word segmentation, POStagging and parsing, based on a hidden Markovmodel.
Jing et al (2003) focused on Chinesenamed entity recognition, considering issues likecharacter-based versus word-based approaches.To our knowledge, our work is the first tosystematically investigate issues of processingarchitecture and feature representation forChinese POS tagging.Our maximum entropy word segmenter issimilar to that of (Xue and Shen, 2003), but theadditional features we used and the post-processing step gave improved wordsegmentation accuracy.The research most similar to ours is (Luo,2003).
Luo presented a maximum entropycharacter-based parser, which as a consequenceof parsing also performed word segmentationand POS tagging.
The all-at-once, character-based approach reported in this paper isessentially the approach proposed by Luo.
Whileour investigation reveals that such an approachgives good accuracy, our findings howeverindicate that a one-at-a-time, character-basedapproach to POS tagging gave quite comparableaccuracy, with the benefit of incurring muchreduced computational cost.8 ConclusionLanguage differences between English andChinese have made direct porting of an EnglishPOS tagging method to Chinese ineffective.
InChinese, individual characters encodeinformation that aids in POS tagging.
Using acharacter-based approach for Chinese POStagging is more effective than a word-basedapproach.
Our study has also revealed that theone-at-a-time, character-based approach givesrelatively good POS tagging accuracy with amuch improved training and testing time,compared with the all-at-once, character-basedapproach previously proposed.9 AcknowledgementsThis research is partially supported by a researchgrant R252-000-125-112 from NationalUniversity of Singapore Academic ResearchFund.ReferencesH.
Jing, R. Florian, X. Luo, T. Zhang, and A.Ittycheriah.
2003.
HowtogetaChineseName(Entity): segmentation and combination issues.In Proc.
of EMNLP.O.
Y. Kwong and B. K. Tsou.
2003.
Categorialfluidity in Chinese and its implications forpart-of-speech tagging.
In Proc.
of EACL.X.
Luo.
2003.
A maximum entropy Chinesecharacter-based parser.
In Proc.
of EMNLP.A.
Ratnaparkhi.
1996.
A maximum entropymodel for part-of-speech tagging.
In Proc.
ofEMNLP.R.
Sproat, C. Shih, W. Gale, and N. Chang.1996.
A stochastic finite-state word-segmentation algorithm for Chinese.Computational Linguistics, 22(3):377-404.R.
Sproat and T. Emerson.
2003.
The firstinternational Chinese word segmentationbakeoff.
In Proc.
of SIGHAN Workshop.W.
J. Teahan, Y. Wen, R. McNab, and I. H.Witten.
2000.
A compression-based algorithmfor Chinese word segmentation.
ComputationalLinguistics, 26(3): 375-393.F.
Xia, M. Palmer, N. Xue, M. E. Okurowski, J.Kovarik, F-D Chiou, S. Huang, T. Kroch, andM.
Marcus.
2000.
Developing guidelines andensuring consistency for Chinese textannotation.
In Proc.
of LREC.N.
Xue and L. Shen.
2003.
Chinese wordsegmentation as LMR tagging.
In Proc.
ofSIGHAN Workshop.H-P Zhang, H-K Yu, D-Y Xiong, and Q. Liu.2003.
HHMM-based Chinese lexical analyzerICTCLAS.
In Proc.
of SIGHAN Workshop.G.
Zhou and J. Su, 2003.
A Chinese efficientanalyser integrating word segmentation, part-of-speech tagging, partial parsing and fullparsing.
In Proc.
of SIGHAN Workshop.
