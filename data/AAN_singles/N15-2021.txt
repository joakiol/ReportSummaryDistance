Proceedings of NAACL-HLT 2015 Student Research Workshop (SRW), pages 154?160,Denver, Colorado, June 1, 2015.c?2015 Association for Computational LinguisticsBilingual lexicon extraction for a distant language pair using a small parallelcorpusXimena Gutierrez-VasquesGIL IINGENUNAMMexico City, Mexicoxim@unam.mxAbstractThe aim of this thesis proposal is to performbilingual lexicon extraction for cases in whichsmall parallel corpora are available and it isnot easy to obtain monolingual corpus for atleast one of the languages.
Moreover, the lan-guages are typologically distant and there isno bilingual seed lexicon available.
We fo-cus on the language pair Spanish-Nahuatl, wepropose to work with morpheme based rep-resentations in order to reduce the sparsenessand to facilitate the task of finding lexical cor-respondences between a highly agglutinativelanguage and a fusional one.
We take intoaccount contextual information but instead ofusing a precompiled seed dictionary, we usethe distribution and dispersion of the positionsof the morphological units as cues to comparethe contextual vectors and obtaining the trans-lation candidates.1 IntroductionParallel corpora are a rich source of bilingual lex-ical information, they are a valuable resource thatallows the development of several language tech-nologies such as automatic construction of bilinguallexicons and statistical machine translation systems(SMT).
Automatic construction of bilingual lexi-cons is useful since bilingual dictionaries are expen-sive resources and not many are available when oneof the languages is resource-poor.One way to perform bilingual lexical extractionfrom a parallel corpus is through word alignment.However, most of the methods to perform word-alignment, and in general the approaches to SMT, re-quire huge amounts of parallel data.
The task of ex-tracting bilingual lexicon becomes even harder whenwe are dealing with very different languages, i.e.,languages from different linguistic families that donot share orthographic, morphological or syntacticsimilarity.The goal of this thesis is to propose a method forbilingual lexicon extraction that could be suitablefor low-resource settings like the mentioned above.We work with the language pair Spanish-Nahuatlwhich are languages distant from each other (Indo-European and Uto-Aztecan language families) withdifferent morphological phenomena.
Nahuatl is anagglutinative language with polysynthetic tendency,this means that it can agglutinate many differentmorphemes to build highly complex words.
On theother hand, Spanish can be classified as a fusionallanguage where the words don?t contain many dif-ferent morphemes since several morphemes can befused or overlaid into one encoding several mean-ings.Although both languages are spoken in the samecountry, there is scarcity of parallel and monolingualcorpora for Nahuatl.
It is not easy to find generalstandard dictionaries due to the big dialectal varia-tion and the lack of orthographical normalization ofNahuatl.
Automatic extraction of a bilingual lexi-con could be useful for contributing with machine-readable resources for the language pair that we arestudying.
Spanish is one of the most widely spokenlanguages in the world but, in the case of Nahuatl,few digital resources are available even though thereexist around two million speakers of this language.Our proposal aims to explore which information154can be combined in order to estimate the bilingualcorrespondences and therefore building a bilinguallexicon.
We plan to take into account correlationmeasures, positional cues and contextual informa-tion.
Many of the methods that exploit contextualinformation require a precompiled digital seed dic-tionary or lexicon.
We would like to propose a wayto leave aside this language dependent requirementsince many language pairs can face the same situa-tion in which it is not easy to obtain a precompileddigital dictionary.Unlike other approaches, we plan to take into ac-count morphological information for building theword representations.
The motivation behind is thatmorpheme-based representations can be useful toovercome the sparseness problem when building se-mantic vectors for morphologically rich languageswith small corpus available.The structure of the paper is as follows: Section2 contains a general overview of the existing meth-ods that tackle the bilingual extraction task and a de-scription of our particular problem.
In section 3, wedescribe the dataset and our proposal to address thebilingual lexical extraction for our low-resource set-ting.
Finally, section 4 contains the conclusions.2 Research Problem2.1 Bilingual Lexicon ExtractionBilingual lexicon extraction is the task of obtaininga list of word pairs deemed to be word-level trans-lations (Haghighi et al, 2008).
This has been anactive area of research for several years, especiallywith the availability of big amounts of parallel cor-puora that allow to model the relations between lex-ical units of the translated texts.
One direct wayto perform bilingual lexicon extraction is throughword alignment from a parallel corpus.
Word align-ment is a fundamental part of SMT systems whichbuild probabilistic translation models, based on sev-eral millions of parallel sentences, in order to esti-mate word and phrase level alignments (Brown etal., 1993).However, the quality of word alignment methodsused in SMT are heavily dependant on the amountof data and they require even more parallel data ifwe are dealing with very different languages.
Sincemost of the language pairs do not have large amountsof clean parallel corpora readily available, there arealternative approaches for extracting multilingual in-formation.
Some methods rely on association andsimilarity measures to estimate the lexical corre-spondences, e.g., log-likelihood measures (Tufis?and Barbu, 2002), t-scores (Ahrenberg et al, 1998),positional difference between two successive occur-rences of a word (Fung, 2000), just to mentionsome.2.2 The low-resource settingIf there is not enough parallel corpora for a lan-guage pair, another alternative is to assume that thereis enough comparable corpora or monolingual cor-pora for each of the languages.
In these approachesbilingual lexicons are induced by taking into accountseveral features, e.g, orthographic similarity, tem-poral similarity (Schafer and Yarowsky, 2002), as-sociation measures, topical information (Mimno etal., 2009) and contextual features.
There are manyworks focused on the latter, they are based on thedistributional notion (Harris, 1954) that a word thatoccurs in a given context in a language should havea translation that occurs in a similar context in theother language.The general approach for using contextual infor-mation includes: 1. building a context vector foreach lexical unit in both languages 2.
Translating orprojecting these context vectors to a common spaceusing a seed dictionary or lexicon 3.
Computingthe similarity between the source and target wordsto find the translation candidates.
There are severalworks that use contextual information, they vary inthe way they represent the contexts and how theymeasure the similarity of the contextual vectors toextract translation candidates.
(Rapp, 1995; Fungand Yee, 1998; Rapp, 1999; Diab and Finch, 2000;D?ejean et al, 2002; Gaussier et al, 2004; Haghighiet al, 2008; Shezaf and Rappoport, 2010; Larocheand Langlais, 2010)Another alternative is to use pivot languages asan intermediary language to extract bilingual lexicon(Tanaka and Umemura, 1994; Wu and Wang, 2007;Tsunakawa et al, 2008; Seo and Kim, 2013).Lately there has been interest in multilingual dis-tributed representation learning (Klementiev et al,2012; Zou et al, 2013).
These approaches are re-lated with the ones that transfer information between155languages using distributed representations and deeplearning techniques (Lauly et al, 2014; Hermannand Blunsom, 2014).
These approaches have thepotential of semantic transfer into low-resource lan-guages.2.3 Our case of studyWe focus on the language pair Spanish-Nahuatl, thisrepresents a setting in which there is a small parallelcorpus available, the two languages are very distantfrom each other and it is not easy to obtain compa-rable corpora or monolingual corpora for one of thelanguages.These two languages are spoken in same countrybut Nahuatl does not have a web presence or textproduction comparable to Spanish.
Most of the doc-uments that can be easily found in Nahuatl are trans-lations, that is why it is easier to obtain parallel cor-pora than monolingual.
Although there are existingdictionaries for this language pair, not all of themare machine readable, the most extensive ones weremade several centuries ago causing that some Span-ish entries do not correspond anymore to the lan-guage spoken nowadays.
Moreover, there is a bigdialectal variation that complicates having one stan-dard dictionary.Under these conditions traditional statisticalmethods for word alignment are not the most suit-able, in fact, to our knowledge it does not exist aSMT system yet for this language pair.
We cannotrely either on orthographic similarity and there is noa pivot language that could be useful.
On the otherhand, practically all the methods based on contex-tual information require at some point a seed bilin-gual dictionary.
This represents a chicken-egg prob-lem (Koehn and Knight, 2002): If we have a bilin-gual lexicon we can translate the context vectors butwe can only generate a bilingual lexicon with thesemethods if we are able to translate the context vec-tors.The transfer based approaches have the poten-tial of transferring semantic knowledge to low re-source languages, e.g., alignment between sentencesor phrases.
However, they need to be trained with re-source fortunate languages, usually requiring somesupervised signal like word alignments to learn thebilingual embeddings.We aim to address our low resource setting bycombining several sources of information, mainlycontextual features and association measures.
In or-der to counteract the sparseness derived from work-ing with a small parallel corpus of morphologicallyrich languages, we aim to use to morpheme repre-sentations instead of words.
For the contextual ap-proach, we prefer not to use the available noisy dic-tionaries as seed lexicon.
Instead, we would like toexplore features like the distribution and the disper-sion of the positions of a morpheme in a text in orderto be able to compare two contextual vectors repre-senting lexical units in different languages.Our conjecture is that the combination of severalfeatures, some of them usually applied for extract-ing lexicon from comparable corpora, could be suit-able for a small, noisy parallel corpus of a distantlanguage pair.
Unlike other methods, our proposalaims to prescind from prior knowledge, e.g., a pre-compiled seed lexicon.3 Methodology3.1 The parallel corpusTo our knowledge, it did not exist a digital Spanish-Nahuatl parallel corpus publicly available.
We hadto build one, most of the sources were non dig-ital books.
As we have mentioned before, forsome languages is not easy to extract parallel con-tent from the typical web sources.
Working with alow resource language sometimes implies difficul-ties that are not common when working with otherlanguages, e.g., we had to perform a manual correc-tion of the texts after being digitized since the OCRsoftware confused several character patterns (it wasprobably assuming that it was processing a differentlanguage).The documents of the parallel corpus are not quitehomogeneous in the sense that there is dialectal, di-achronic and orthographical variation.
This varia-tion can represent noise for many of the statisticalmethods, as an attempt to reduce it we performed anorthographic normalization.
It does not exist a gen-eral agreement regarding to the appropriate way towrite nahuatl language.
We chose a set of normaliza-tion rules (around 270) proposed by linguists to nor-malize classical nahuatl (Thouvenot and Maynez,2008) in order to obtain a more systematic writing.We implement them in FOMA (Hulden, 2009) a fi-156nite state toolkit used mainly for computational mor-phology.
The set of rules that we used reduces thevariation of many of the texts but unfortunately notfrom all them.The total size of the corpus is around 1 milliontokens (included both languages) which is still verysmall for the SMT approaches.
To this scarcity, wehave to add the fact that we will only work with asubset of documents, those that do not have a bigdialectal or orthographical variation3.2 MorphologyIn order to perform the bilingual lexicon extraction,we would like to take into account the morphologyof the language pair since the alignment complex-ity between typologically different languages is faraway from the alignment complexity between simi-lar languages (Cakmak et al, 2012).Nahuatl is a polysynthetic language that allowscompact nominal and verbal constructions where thecomplements, adjectives and adverbs can aggluti-nate with the verbal or nominal roots.
This languagealso has incorporation and some other morpholog-ical phenomena.
In contrast, Spanish is a fusionallanguage in which a single morpheme can simul-taneously encode several meanings.
Regarding tothe word order, Nahuatl and Spanish are relativetelyflexible, specially Nahuatl.Dealing with the morphology could be impor-tant to reduce the negative impact of sparseness andtherefore having better representations of the lexicalunits.
Specially in cases like ours where the corpusis small and the languages are morphologically rich,this may cause many different word types but fewrepetitions of them in the documents.
If we have fewcontexts characterizing a word, then the contextualsvectors will not have a good quality, affecting theperformance of the methods that exploit contextualfeatures.
Building morpheme based representationscould be also useful for pairing the bilingual lexicalunits, since in agglutinative languages a single wordcan correspond to many in another language.
Thenext example shows a morphologically segmentedword in nahuatl and its correspondence to Spanish:ti- nech - maca- z - nequi2SG.S-1S.O-?give?-FUT-?want?
?Tu me quieres dar?
(Spanish)?You want to give me?Recent approaches take into account morphol-ogy and investigate how compositional morpholog-ical distributed representations can improve wordrepresentations (Lazaridou et al, 2013) and lan-guage models (Botha and Blunsom, 2014; El-Desoky Mousa et al, 2013; Luong et al, 2013).We aim to use, already implemented, unsuper-vised methods to perform morphological segmen-tation.
Software like Morfessor (Creutz and La-gus, 2005) that seems to work well for agglutina-tive languages could be useful as well for languageslike Nahuatl.
Additionally, there is a morphologi-cal analysis tool based on rules for classical nahuatl(Thouvenot, 2011) that could be used to improve theunsupervised morphological segmentation.
As forthe Spanish case, there are unsupervised approachesthat have proven to be successful in discoveringSpanish affixes (Urrea, 2000; Medina-Urrea, 2008).Once we have the segmented morphemes, we canbuild morpheme-based representations to extract thebilingual correspondences.
Initially we plan to focusin extracting bilingual lexicon only for words withlexical meaning and not the grammatical ones.At this moment, we have not still decided if wewill work only with vector representations of eachmorpheme or with a composed representation of thewords based on the morphemes.3.3 Bilingual lexicon extraction without using aseed dictionaryFor the bilingual lexical extraction we aim to com-bine several cues including correlation measures andcontextual information.
As we have mentioned be-fore, most of the contextual methods have in com-mon a need for a seed lexicon of translations to effi-ciently bridge the gap between languages.
We wouldlike to prescind from this requirement.Seed lexicons are necessary to compare the con-texts between the word representations in differentlanguages.
Few works have tried to circumventthis requirement, e.g., building a seed lexicon basedon spelling and cognate cues (Koehn and Knight,2002), using punctuation marks as a small seed lex-icon and find alignments by measuring intralingualassociation between words (Diab and Finch, 2000).Lately some works have explored training a cross-language topic model on comparable corpora in or-der to obtain a seed lexicon without prior knowl-157edge (Vuli?c and Moens, 2012).We would like to explore the positions in which aword occurs in a text and the dispersion of these po-sitions as cues for finding similar words in both lan-guages and being able to compare the context vec-tors that characterize the words in both languages.The hypothesis is that words that are translations ofeach other tend to occur in similar positions of a par-allel text and the distributions have similar disper-sions.
It is noteworthy that in our case we attemptto work at the morpheme level instead of the wordlevel.For each type in the text, in our case morphemes,we can store a vector of offsets, i.e.
the positions inwhich the type occurs relative to the size of corpus.After recollecting all the positions for a lexical unitwe can also measure the dispersion by calculatingthe variance or the standard deviation.We conjecture that those lexical units betweenlanguages that obtain high similarity in their posi-tion distributions and their dispersion, are useful tocompare the context vectors.
They can be seen as asort of initial seed lexicon constructed in a languageindependent way.
The similarity can be calculatedin terms of measurements like cosine similarity ormeasurements that take into account correlations ordivergence between distributions.Regarding to the construction of vectors encodingcontextual information of the lexical units, we planto try different experimental setups, examining dif-ferent representations of word contexts, i.e., differ-ent association measures and weighting schemes forbuilding the semantic vectors, different sizes of con-text windows and other important parameters thatmust be taken into account when working with dis-tributional semantic representations.Once we have the contextual vectors that repre-sent the lexical units (in our case representationsbased on morphology) translation candidates can beobtained.
Based on the contexts that are similar be-tween the two vectors we can compare a source anda target contextual vector using different techniquesor projecting them into a joint space and calculatethe distance between them.Taking into account the contexts and positions ofthe words in the whole document could be useful fornoisy parallel corpora where there is not always aone to one correspondence between sentences.
Thisis the case of some of the texts of our parallel corpus.3.4 Combination of features and evaluationIt is very common for bilingual extraction methodsto use a diverse set of cues and then combine them inorder to obtain better translation candidates (Koehnand Knight, 2002; Tiedemann, 2003; Irvine, 2013).We will not use some of the typical cues like ortho-graphic similarity or temporal, but we would like tocombine the contextual information explained in theabove section with some association measures be-tween words or morphemes.
Our intention is to pro-pose a weighting scheme that allows to combine theseveral criteria and to obtain a rank of the translationcandidates.Once the translation candidates are extracted, wecan establish a baseline by using some of the meth-ods suitable for parallel corpora, e.g., the typicalword alignment methods used in SMT.
Addition-ally, it would be interesting to try different languagepairs with more resources, in order to evaluate if ourmethod can be competitive to more downstream ap-proaches that rely on more data.
For instance, wecan evaluate in resource fortunate distant pairs likeSpanish-German, since German is also morphologi-cally rich with extensive use of compounds.4 ConclusionsIn this work we have presented a thesis proposalwhere the goal is to extract a bilingual lexicon un-der a particular low-resource setting in which is dif-ficult to obtain big amounts of parallel or monolin-gual corpora and also is not easy to have an exten-sive standard electronical dictionary.
The particular-ities of the methods are not completely defined sincethe work is in progress, we propose to combine mor-pheme based representations with contextual and as-sociation features in order to obtain translation can-didates for the lexical units.In our proposal we try to circumvent the need of abilingual electronic dictionary which can be hard toobtain when working with low-resource languages.Although we focus in a particular language pair,the proposed methods are language independent andthey could be used for languages with similar set-tings or even for comparable corpora.Some of the aspects that are missing to tackle are158the problems that may arise when dealing with syn-onyms and polysemic words.5 AcknowledgementsThis work is supported by the Mexican Councilof Science and Technology (CONACYT), funds370713 and CB-2012/178248.
Thanks to the re-viewers for their valuable comments.ReferencesLars Ahrenberg, Mikael Andersson, and Magnus Merkel.1998.
A simple hybrid aligner for generating lex-ical correspondences in parallel texts.
In Proceed-ings of the 17th international conference on Computa-tional linguistics-Volume 1, pages 29?35.
Associationfor Computational Linguistics.Jan A Botha and Phil Blunsom.
2014.
Compositionalmorphology for word representations and languagemodelling.
arXiv preprint arXiv:1405.4273.Peter F Brown, Vincent J Della Pietra, Stephen A DellaPietra, and Robert L Mercer.
1993.
The mathematicsof statistical machine translation: Parameter estima-tion.
Computational linguistics, 19(2):263?311.Mehmet Talha Cakmak, S?uleyman Acar, and G?ulsenEryigit.
2012.
Word alignment for english-turkishlanguage pair.
In LREC, pages 2177?2180.Mathias Creutz and Krista Lagus.
2005.
Unsuper-vised morpheme segmentation and morphology induc-tion from text corpora using Morfessor 1.0.
HelsinkiUniversity of Technology.Herv?e D?ejean,?Eric Gaussier, and Fatia Sadat.
2002.An approach based on multilingual thesauri and modelcombination for bilingual lexicon extraction.
In Pro-ceedings of the 19th international conference on Com-putational linguistics-Volume 1, pages 1?7.
Associa-tion for Computational Linguistics.Mona Diab and Steve Finch.
2000.
A statistical word-level translation model for comparable corpora.
Tech-nical report, DTIC Document.A El-Desoky Mousa, H-KJ Kuo, Lidia Mangu, and Ha-gen Soltau.
2013.
Morpheme-based feature-rich lan-guage models using deep neural networks for lvcsr ofegyptian arabic.
In Acoustics, Speech and Signal Pro-cessing (ICASSP), 2013 IEEE International Confer-ence on, pages 8435?8439.
IEEE.Pascale Fung and Lo Yuen Yee.
1998.
An ir approachfor translating new words from nonparallel, compara-ble texts.
In Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguisticsand 17th International Conference on ComputationalLinguistics-Volume 1, pages 414?420.
Association forComputational Linguistics.Pascale Fung.
2000.
A statistical view on bilingual lex-icon extraction.
In Parallel Text Processing, pages219?236.
Springer.Eric Gaussier, J-M Renders, Irina Matveeva, CyrilGoutte, and Herv?e D?ejean.
2004.
A geometric viewon bilingual lexicon extraction from comparable cor-pora.
In Proceedings of the 42nd Annual Meeting onAssociation for Computational Linguistics, page 526.Association for Computational Linguistics.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In ACL, volume 2008,pages 771?779.Zellig S Harris.
1954.
Distributional structure.
Word.Karl Moritz Hermann and Phil Blunsom.
2014.
Multilin-gual models for compositional distributed semantics.arXiv preprint arXiv:1404.4641.Mans Hulden.
2009.
Foma: a finite-state compiler andlibrary.
In Proceedings of the 12th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics: Demonstrations Session, pages 29?32.
Association for Computational Linguistics.Ann Irvine.
2013.
Statistical machine translation in lowresource settings.
In HLT-NAACL, pages 54?61.Alexandre Klementiev, Ivan Titov, and Binod Bhattarai.2012.
Inducing crosslingual distributed representa-tions of words.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
In Pro-ceedings of the ACL-02 workshop on Unsupervisedlexical acquisition-Volume 9, pages 9?16.
Associationfor Computational Linguistics.Audrey Laroche and Philippe Langlais.
2010.
Revisitingcontext-based projection methods for term-translationspotting in comparable corpora.
In Proceedings ofthe 23rd international conference on computationallinguistics, pages 617?625.
Association for Computa-tional Linguistics.Stanislas Lauly, Alex Boulanger, and Hugo Larochelle.2014.
Learning multilingual word representationsusing a bag-of-words autoencoder.
arXiv preprintarXiv:1401.1803.Angeliki Lazaridou, Marco Marelli, Roberto Zamparelli,and Marco Baroni.
2013.
Compositional-ly derivedrepresentations of morphologically complex words indistributional semantics.
In ACL (1), pages 1517?1526.
Citeseer.Minh-Thang Luong, Richard Socher, and Christopher DManning.
2013.
Better word representations withrecursive neural networks for morphology.
CoNLL-2013, 104.159Alfonso Medina-Urrea.
2008.
Affix discovery based onentropy and economy measurements.
ComputationalLinguistics for Less-Studied Languages, 10:99?112.David Mimno, Hanna M Wallach, Jason Naradowsky,David A Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 2-Volume 2, pages 880?889.
Association for Computational Linguistics.Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the 33rd annualmeeting on Association for Computational Linguistics,pages 320?322.
Association for Computational Lin-guistics.Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated english and german cor-pora.
In Proceedings of the 37th annual meeting of theAssociation for Computational Linguistics on Compu-tational Linguistics, pages 519?526.
Association forComputational Linguistics.Charles Schafer and David Yarowsky.
2002.
Induc-ing translation lexicons via diverse similarity mea-sures and bridge languages.
In proceedings of the 6thconference on Natural language learning-Volume 20,pages 1?7.
Association for Computational Linguistics.Hong-Seok Kwon Hyeong-Won Seo and Jae-Hoon Kim.2013.
Bilingual lexicon extraction via pivot languageand word alignment tool.
ACL 2013, page 11.Daphna Shezaf and Ari Rappoport.
2010.
Bilingual lex-icon generation using non-aligned signatures.
In Pro-ceedings of the 48th annual meeting of the associationfor computational linguistics, pages 98?107.
Associa-tion for Computational Linguistics.Kumiko Tanaka and Kyoji Umemura.
1994.
Construc-tion of a bilingual dictionary intermediated by a thirdlanguage.
In Proceedings of the 15th conference onComputational linguistics-Volume 1, pages 297?303.Association for Computational Linguistics.Marc Thouvenot and Romero-Galvan Ruben Maynez, Pi-lar.
2008.
La normalizacion grafica del codice flo-rentino.
In El universo de Sahagun pasado y presente.UNAM.Marc Thouvenot.
2011.
Chachalaca en cen, junta-mente.
In Compendio Enciclopedico del Nahuatl,DVD.
INAH.J?org Tiedemann.
2003.
Combining clues for word align-ment.
In Proceedings of the tenth conference on Eu-ropean chapter of the Association for ComputationalLinguistics-Volume 1, pages 339?346.
Association forComputational Linguistics.Takashi Tsunakawa, Naoaki Okazaki, and Jun?ichi Tsujii.2008.
Building a bilingual lexicon using phrase-basedstatistical machine translation via a pivot language.
InCOLING (Posters), pages 127?130.Dan Tufis?
and Ana-Maria Barbu.
2002.
Lexical to-ken alignment: Experiments, results and applications.In Proceedings from The Third International Confer-ence on Language Resources anrd Evaluation (LREC-2002), Las Palmas, Spain, pages 458?465.Alfonso Medina Urrea.
2000.
Automatic discovery ofaffixes by means of a corpus: A catalog of spanish af-fixes.
Journal of quantitative linguistics, 7(2):97?114.Ivan Vuli?c and Marie-Francine Moens.
2012.
Detectinghighly confident word translations from comparablecorpora without any prior knowledge.
In Proceedingsof the 13th Conference of the European Chapter ofthe Association for Computational Linguistics, pages449?459.
Association for Computational Linguistics.Hua Wu and Haifeng Wang.
2007.
Pivot languageapproach for phrase-based statistical machine transla-tion.
Machine Translation, 21(3):165?181.Will Y Zou, Richard Socher, Daniel M Cer, and Christo-pher D Manning.
2013.
Bilingual word embeddingsfor phrase-based machine translation.
In EMNLP,pages 1393?1398.160
