WSD system based on Specialized Hidden Markov Model (upv-shmm-eaw)Antonio Molina, Ferran Pla and Encarna SegarraDepartament de Sistemes Informa`tics i Computacio?Universitat Polite`cnica de Vale`nciaCam??
de Vera s/n Vale`ncia (Spain){amolina,fpla,esegarra}@dsic.upv.esAbstractWe present a supervised approach to Word SenseDisambiguation (WSD) based on Specialized Hid-den Markov Models.
We used as training data theSemcor corpus and the test data set provided bySenseval 2 competition and as dictionary the Word-net 1.6.
We evaluated our system on the Englishall-word task of the Senseval-3 competition.1 Description of the WSD SystemWe consider WSD to be a tagging problem (Molinaet al, 2002a).
The tagging process can be formu-lated as a maximization problem using the HiddenMarkov Model (HMM) formalism.
Let O be theset of output tags considered, and I , the input vo-cabulary of the application.
Given an input sen-tence, I = i1, .
.
.
, iT , where ij ?
I , the tag-ging process consists of finding the sequence of tags(O = o1, .
.
.
, oT , where oj ?
O) of maximumprobability on the model, that is:O?
= arg maxOP (O|I)= arg maxO(P (O) ?
P (I|O)P (I)); O ?
OT (1)Due to the fact that the probability P (I) is a con-stant that can be ignored in the maximization pro-cess, the problem is reduced to maximize the nu-merator of equation 1.
To solve this equation, theMarkov assumptions should be made in order tosimplify the problem.
For a first-order HMM, theproblem is reduced to solve the following equation:arg maxO??
?j:1...TP (oj |oj?1) ?
P (ij |oj)??
(2)The parameters of equation 2 can be representedas a first-order HMM where each state correspondsto an output tag oj , P (oj |oj?1) represent the transi-tion probabilities between states and P (ij |oj) rep-resent the probability of emission of input symbols,ij , in every state, oj .
The parameters of this modelare estimated by maximum likelihood from seman-tic annotated corpora using an appropriate smooth-ing method (linear interpolation in our work).Different kinds of available linguistic informationcan be useful to solve WSD.
The training corpus weused provides as input features: words (W), lemmas(L) and the corresponding POS tags (P); and it alsoprovides as output tags the WordNet senses.WordNet senses can be represented by a sense keywhich has the form lemma%lex sense.
The highnumber of different sense keys and the scarce an-notated training data make difficult the estimationof the models.
In order to alleviate this sparnessproblem we considered the lex sense field (S) of thesense key associated to each lemma as the semantictag.
This assumption reduces the size of the outputtag set and it does not lead to any loss of informationbecause we can obtain the sense key by concatenat-ing the lemma to the output tag.Therefore, in our system the input vocabulary isI = W ?
L ?
P , and the output vocabulary isO = S .
In order to incorporate this kind of in-formation to the model we used Specialized HMM(SHMM) (Molina et al, 2002b).
This techniquehas been successfully applied to other disambigua-tion tasks such as part-of-speech tagging (Pla andMolina, 2004) and shallow parsing (Molina and Pla,2002).Other HMM-based approaches have also beenapplied to WSD.
In (Segond et al, 1997), they esti-mated a bigram model of ambiguity classes from theSemCor corpus for the task of disambiguating thesemantic categories corresponding to the lexicogra-pher level.
These semantic categories are codifiedinto the lex sense field.
A second-order HMM wasused in (Loupy et al, 1998) in a two-step strategy.First, they determined the semantic category associ-ated to a word.
Then, they assigned the most prob-able sense according to the word and the semanticcategory.A SHMM consists of changing the topology ofthe HMM in order to get a more accurate modelAssociation for Computational Linguisticsfor the Semantic Analysis of Text, Barcelona, Spain, July 2004SENSEVAL-3: Third International Workshop on the Evaluation of Systemswhich includes more information.
This is done bymeans of an initial step previous to the learning pro-cess.
It consists of the redefinition of the input vo-cabulary and the output tags.
This redefinition isdone by means of two processes which transformthe training set: the selection process, which is ap-plied to the input vocabulary, and the specializationprocess, which redefines the output tags.1.1 Selection processThe aim of the selection process is to choose whichinput features are relevant to the task.
This pro-cess applies a determined selection criterion to Ithat produces a new input vocabulary (I?).
This newvocabulary consists of the concatenation of the rel-evant input features selected.Taking into account the input vocabulary I =W ?L?P , some selection criteria could be as fol-lows: to consider only the word (wi), to consideronly the lemma (li), to consider the concatenationof the word and its POS1 (wi ?
pi), and to considerthe concatenation of the lemma and its POS (li ?
pi).Moreover, different criteria can be applied depend-ing on the kind of word (e.g.
distinguishing contentand non-content words).For example, for the input word interest, whichhas an entry in WordNet and whose lemma and POSare interest and NN (common noun) respectively,the input considered could be interest?1.
For a non-content word, such as the article a, we could con-sider only its lemma a as input.1.2 Specialization processThe specialization process allows for the codifica-tion of certain information into the context (that is,into the states of the model).
It consists of redefin-ing the output tag set by adding information fromthe input.
This redefinition produces some changesin the model topology, in order to allow the modelto better capture some contextual restrictions and toget a more accurate model.The application of a specialization criterion to Oproduces a new output tag set (O?
), whose elementsare the result of the concatenation of some relevantinput features to the original output tags.Taking into account that the POS input feature isalready codified in the lex sense field, only wordsor lemmas can be considered in the specializationprocess (wi?
lex sensei or li?
lex sensei).This specialization can be total or partial depend-ing on whether we specialize the model with all theelements of a feature or only with a subset of them.1We mapped the POS tags to the following tags: 1 fornouns, 2 for verbs, 3 for adjectives and 4 for adverbs.For instance, the input token interest?1 is taggedwith the semantic tag 1:09:00:: in the training dataset.
If we estimate that the lemma interest shouldspecialize the model, then the semantic tag is rede-fined as interest?1:09:00::.
Non-content words, thatshare the same output tag (the symbol notag in oursystem), could be also considered to specialize themodel.
For example, for the word a, the specializedoutput tag associated could be a?notag.1.3 System schemeThe disambiguation process is presented in (Figure1).
First, the original input sentence (I) is processedin order to select its relevant features, providing theinput sentence (I?).
Then, the semantic tagging iscarried out through the Viterbi algorithm using theestimated SHMM.
WordNet is used to know all thepossible semantic tags associated to an input word.If the input word is unknown for the model (i.e., theword has not been seen in the training data set) thesystem takes the first sense provided by WordNet.The learning process of a SHMM is similar to thelearning of a basic HMM.
The only difference is thatSHMM are based on an appropriate definition of theinput information to the learning process.
This in-formation consists of the input features (words, lem-mas and POS tags) and the output tag set (senses)provided by the training corpus.
A SHMM is builtaccording to the following steps (see Figure 2):1.
To define which available input information isrelevant to the task (selection criterion).2.
To define which input features are relevant toredefine or specialize the output tag set (spe-cialization criterion).3.
To apply the chosen criteria to the originaltraining data set to produce a new one.4.
To learn a model from the new training dataset.5.
To disambiguate a development data set usingthat model.6.
To evaluate the output of the WSD system inorder to compare the behavior of the selectedcriteria on the development set.These steps are done using different combina-tions of input features in order to determine the bestselection criterion and the best total specializationcriterion.
Once these criteria are determined, somepartial specializations are tested in order to improvethe performance of the model.Selectionof RelevantFeaturesDisambiguated sentenceWSDHMM WORDNETSelectioncriterionI~IOriginal Input sentence Input sentenceFigure 1: System DescriptionSpecializationcriterion (2)SETTRAININGSETDEVELOPMENTOutput TagsofSpecializationREFERENCE SETDEVELOPMENTSelectionof RelevantFeaturesHMM WORDNETTraining setsentenceInputSelectionDisambiguatedsentencecriterion (1)NewModeltheLearning4 6WSD53EvaluationFigure 2: Learning Phase Description2 Experimental WorkWe used as training data the part of the SemCor cor-pus which is semantically annotated and supervisedfor nouns, verbs, adjectives and adverbs (that is, thefiles contained in the Brown1 and the Brown2 fold-ers of SemCor corpus), and the test data set providedby Senseval-2.
We used 10% of the training corpusas a development data set in order to determine thebest selection and specialization criteria.In the experiments, we used WordNet 1.6 as adictionary which supplies all the possible semanticsenses for a given word.
Our system disambiguatedall the polysemic lemmas, that is, the coverage ofour system was 100% (therefore, precision and re-call were the same).
For unknown words (wordsthat did not appear in the training data set), we as-signed the first sense in WordNet.The best selection criterion determined from theexperimental work on the development set is as fol-lows: if a word wi has a sense in WordNet we con-catenate the lemma (li) and the POS (pi) associ-ated to the word (wi) as input vocabulary.
For non-content words, we only consider their lemma (li) asinput.The best specialization criterion consisted of se-lecting the lemmas whose frequency in the trainingdata set was higher than a certain threshold (otherspecialization criteria could have been chosen, butfrequency criterion usually worked well in othertasks as we reported in (Molina and Pla, 2002)).
Inorder to determine which threshold maximized theperformance of the model, we conducted a tuningexperiment on the development set.
The best per-formance was obtained using the lemmas whose fre-quency was higher than 20 (about 1,600 lemmas).The performance of our system on the Senseval 3data test set was 60.9% of precision and recall.3 Concluding remarksIn our WSD system, the choice of the best special-ization criterion is based on the results of the systemon the development set.
The tuning experiments in-cluded totally specialized models, which is equiva-lent to consider the sense keys as the output vocab-ulary, non-specialized models, which is equivalentto consider the lex senses as the output vocabulary,and partially specialized models using different setsof lemmas.For the best specialization criterion, we have notstudied the linguistic characteristics of the differentgroups of synsets associated to the same lex sensefor non-specialized output tags.
We think that wecould improve our WSD system through a more ad-equate definition of the selection and specializationcriteria.
This definition could be done using seman-tic knowledge about the domain of the task.4 AcknowledgmentsThis work has been supported by the Spanishresearch projects CICYT TIC2003-07158-C04-03and TIC2003-08681-C02-02.ReferencesC.
Loupy, M. El-Beze, and P. F. Marteau.
1998.Word Sense Disambiguation using HMM Tag-ger.
In Proceedings of the 1st International Con-ference on Language Resources and Evaluation,LREC, pages 1255?1258, Granada, Spain, May.Antonio Molina and Ferran Pla.
2002.
ShallowParsing using Specialized HMMs.
Journal ofMachine Learning Research, 2:595?613.Antonio Molina, Ferran Pla, and Encarna Segarra.2002a.
A Hidden Markov Model Approach toWord Sense Disambiguation.
In Proceedingsof the VIII Conferencia Iberoamericana de In-teligencia Artificial, IBERAMIA2002, Sevilla,Spain.Antonio Molina, Ferran Pla, and Encarna Segarra.2002b.
Una formulaci o?n unificada para resolverdistinto problemas de ambigu?edad en PLN.
Re-vista para el Procesamiento del Lenguaje Natu-ral, (SEPLN?02), Septiembre.Ferran Pla and Antonio Molina.
2004.
Improv-ing Part-of-Speech Tagging using LexicalizedHMMs.
Natural Language Engineering, 10.
Inpress.F.
Segond, A. Schiller, G. Grefenstette, and J-P.Chanod.
1997.
An Experiment in Semantic Tag-ging using Hidden Markov Model Tagging.
InProceedings of the Joint ACL/EACL Workshopon Automatic Information Extraction and Build-ing of Lexical Semantic Resources, pages 78?81,Madrid, Spain.
