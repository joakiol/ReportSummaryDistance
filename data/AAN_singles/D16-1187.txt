Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1817?1826,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsDeceptive Review Spam Detectionvia Exploiting Task Relatedness and Unlabeled DataZhen Hai?
Peilin Zhao?
Peng Cheng?
Peng Yang?
Xiao-Li Li ?
Guangxia Li?
?Institute for Infocomm Research, A*STAR, Singapore, {haiz,xlli}@i2r.a-star.edu.sg?Ant Financial, Hangzhou, China, peilin.zpl@alipay.com?SCSE, Nanyang Technological University, Singapore, pcheng1@ntu.edu.sg?Tencent AI Lab, Shenzhen, China, henryppyang@tencent.com?SCST, Xidian University, Xi?an, China, gxli@xidian.edu.cnAbstractExisting work on detecting deceptive reviewsprimarily focuses on feature engineering andapplies off-the-shelf supervised classificationalgorithms to the problem.
Then, one realchallenge would be to manually recognizeplentiful ground truth spam review data formodel building, which is rather difficult andoften requires domain expertise in practice.
Inthis paper, we propose to exploit the related-ness of multiple review spam detection tasksand readily available unlabeled data to addressthe scarcity of labeled opinion spam data.We first develop a multi-task learning methodbased on logistic regression (MTL-LR), whichcan boost the learning for a task by sharingthe knowledge contained in the training sig-nals of other related tasks.
To leverage theunlabeled data, we introduce a graph Lapla-cian regularizer into each base model.
Wethen propose a novel semi-supervised multi-task learning method via Laplacian regular-ized logistic regression (SMTL-LLR) to fur-ther improve the review spam detection per-formance.
We also develop a stochastic al-ternating method to cope with the optimiza-tion for SMTL-LLR.
Experimental results onreal-world review data demonstrate the benefitof SMTL-LLR over several well-establishedbaseline methods.1 IntroductionNowadays, more and more individuals and organi-zations have become accustomed to consulting user-generated reviews before making purchases or on-line bookings.
Considering great commercial ben-efits, merchants, however, have tried to hire peo-ple to write undeserving positive reviews to promotetheir own products or services, and meanwhile topost malicious negative reviews to defame those oftheir competitors.
The fictitious reviews and opin-ions, which are deliberately created in order to pro-mote or demote targeted entities, are known as de-ceptive opinion spam (Jindal and Liu, 2008; Ott etal., 2011).By formulating deceptive opinion spam detectionas a classification problem, existing work primarilyfocuses on extracting different types of features andapplies off-the-shelf supervised classification algo-rithms to the problem (Jindal and Liu, 2008; Ott etal., 2011; Feng et al, 2012; Chen and Chen, 2015).Then, one weakness of previous work lies in the de-mand of manually recognizing a large amount ofground truth review spam data for model training.Unlike other forms of spamming activities, such asemail or web spam, deceptive opinion spam, whichhas been deliberately written to sound authentic, ismore difficult to be recognized by manual read.
Inan experiment, three undergraduate students were(randomly) invited to identify spam reviews fromnonspam ones in hotel domain.
As shown in Table 1,their average accuracy is merely 57.3% (Ott et al,2011).
Then, given a limited set of labeled reviewdata for a domain, e.g., hotel, it is almost impossibleto build a robust classification model for detectingdeceptive spam reviews in reality.In this work, we deal with the problem of de-tecting a textual review as spam or not, i.e., non-spam.
We consider each deceptive review spam de-tection problem within each domain, e.g., detecting1817Judge-1 Judge-2 Judge-3Accuracy 61.9% 56.9% 53.1%F-spam 48.7% 30.3% 43.6%F-nonspam 69.7% 68.8% 59.9%Table 1: Performance of human judges for review spamdetection in hotel domain (Ott et al, 2011), where F-spam/F-nonspammeans F-score for spam/nonspam label.spam hotel/restuarnt reviews from hotel/restaurnatdomain, to be a different task.
Previous studieshave empirically shown that learning multiple re-lated tasks simultaneously can significantly improveperformance relative to learning each task indepen-dently, especially when only a few labeled data pertask are available (Caruana, 1997; Bakker and Hes-kes, 2003; Argyriou et al, 2006).
Thus, given thelimited labeled review data for each domain, we for-mulate the review spam detection tasks for multi-ple domains, e.g., hotel, restaurant, and so on, as amulti-task learning problem.We develop a multi-task learning method via lo-gistic regression (MTL-LR) to address the problem.One key advantage of the method is that it allowsto boost the learning for one review spam detectiontask by leveraging the knowledge contained in thetraining signals of other related tasks.
Then, thereis often a large quantity of review data freely avail-able online.
In order to leverage the unlabeled data,we introduce a graph Laplacian regularizer into eachbase logistic regression model.
We extend MTL-LR, and propose a novel semi-supervised multi-tasklearning model via Laplacian regularized logistic re-gression (SMTL-LLR) to further boost the reviewspam detection performance under the multi-tasklearning setting.
Moreover, to cope with the opti-mization problem for SMTL-LLR, we also developa stochastic alternating optimization method, whichis computationally efficient.To the best of our knowledge, this is the first workthat generalizes opinion spam detection from in-dependent single-task learning to symmetric multi-task learning setting.
By symmetric, we mean thatthe setting seeks to improve the performance of alllearning tasks simultaneously.
In this sense, it is dif-ferent from transfer learning (Pan and Yang, 2010),where the objective is to improve the performanceof a target task using information from source tasks.Under this new setting, we can exploit the com-monality shared by related review spam detectiontasks as well as readily available unlabeled data, andthen alleviate the scarcity of labeled spam reviewdata.
Experimental results on real-world review datademonstrate the superiority of SMTL-LLR over sev-eral representative baseline methods.The rest of this paper is organized as follows.
Sec-tion 2 presents related work.
Section 3 introducesthe proposed methods and stochastic alternating op-timization algorithm.
Then, in Section 4, we presentthe experimental results in detail, and conclude thispaper in Section 5.2 Related WorkPrevious work typically formulates deceptive opin-ion spam detection as a classification problem, andthen presents different types of features to train su-pervised classification algorithms for the problem.Jindal and Liu (2008) first studied opinion spam de-tection problem.
They built the ground truth reviewdata set by treating the duplicate reviews in a givencorpus as spam reviews and the rest as nonspam re-views.
They presented review, product, and reviewerrelated features, and then trained logistic regression(LR) model on the features for finding fake reviewspam.
Ott et al (2011) created the ground truth re-view data via a crowd-sourcing service called Ama-zon Mechanical Turk1.
They presented three dif-ferent types of features for opinion spam detection,i.e., genre identification features, psycholinguisticdeception features, and standard n-gram text fea-tures.
They found that the supervised support vec-tor machines (SVM) trained on the textual n-gramfeatures can achieve good performance.
Feng et al(2012) presented syntactic stylometry features andtrained SVM model for deception detection, whileChen and Chen (2015) built the SVM classifier ona diversity of features, such as content and threadfeatures, for opinion spam detection in web forum.In addition, Li et al (2014) employed a feature-based additive model to explore the general rule fordeceptive opinion spam detection.
Generally, in or-der to build robust supervised review spam detectionmodels, we have to manually recognize large-scaleground truth spam data.
But this could be very ex-1https://www.mturk.com1818pensive, and often requires domain expertise.Though a large amount of unlabeled review dataare freely available online, very limited work hasbeen done on developing semi-supervised methodsfor review spam detection.
Li et al (2011) useda two-view co-training method (Blum and Mitchell,1998) for semi-supervised learning to identify fakereview spam.
One limitation of the work is that itneeds additional reviewer information when build-ing model.
Given a corpus of textual reviews, thereviewer related view may not be always availablein reality.
Moreover, the co-training method is notintrinsically geared to learning from the unlabeledreview data, instead, simply makes use of the un-labeled reviews within a fully supervised learningframework, negating the semi-supervised learningbenefit.
For some particular scenarios, the availabletraining data could be only a partially labeled set ofpositive examples, e.g., spam reviews, and a largeset of unlabeled reviews.
Positive unlabeled learn-ing (PU) (De Comite et al, 1999; Liu et al, 2002)may be then used for deceptive review spam detec-tion (Hernandez et al, 2013).
However, this clearlycontrasts with our problem, where our training datacontains a complete labeled set of positive (spam)and negative (nonspam) reviews besides the unla-beled set of review data.In addition, instead of detecting spam reviews di-rectly, considerable efforts have been made to recog-nize review spammers, i.e., online users who havewritten spam reviews.
Lim et al (2010) studieddifferent types of spamming behavioral indicators,and then used a regression method on the indicatorsfor finding review spammers.
Wang et al (2012)investigated the relationships among reviewers, re-views, and stores, and developed a social reviewgraph based method to identify online store spam-mers.
Mukherjee et al (2013) developed an authorspamicity Bayesian model to exploit the observedbehavioral footprints for spammer detection.
In re-ality, a group of online users may work together tocreate spam reviews.
Mukherjee et al (2012) de-veloped a group spam ranking algorithm to detectspammer groups.Multi-task learning is a learning paradigm thatseeks to boost generalization performance by learn-ing a task together with other tasks at the same timewhile using a shared representation (Caruana, 1997).Most majority of existing work on multi-task learn-ing does not infer actual task relations from train-ing data automatically, instead, they typically makethe assumptions that the relations are existent or aregiven as prior knowledge (Thrun and O?Sullivan,1996; Bakker and Heskes, 2003; Evgeniou and Pon-til, 2004; Argyriou et al, 2006; Liu et al, 2009).To better fit the multi-task learning model to real-world data, Zhang and Yeung (2010) proposed aconvex regularization formulation named multi-taskrelation learning (MTRL), which can learn real rela-tionships between tasks under a multi-task learningframework.In this work, we focus on detecting online decep-tive review spam.
We formulate review spam detec-tion for multiple domains (e.g., hotel and restaurant)as a multi-task learning problem.
Following the con-vex framework of MTRL, we first develop a multi-task learning method via logistic regression (MTL-LR).
We employ logistic regression as base classifi-cation model, because: 1) It is a robust model thatdoes not have configuration parameters to tune; 2) Itcan be straightforwardly extended, and be efficientlytrained using convex optimization techniques (Hoiet al, 2006; Minka, 2003); and 3) It has been showneffective for large-scale text classification and fakereview detection problems (Hoi et al, 2006; Jindaland Liu, 2008).
Then, to leverage the large volumeof unlabeled review data, we extend the base logis-tic regression model, and incorporate a graph Lapla-cian regularizer into it.
We thus develop a new semi-supervised multi-task learning paradigm via Lapla-cian regularized logistic regression, which is able tofurther boost the performance for review spam de-tection.3 Methodology3.1 Multi-task Learning via LogisticRegressionGiven m review domains D1, .
.
.
,Dm, we ac-cordingly have m review spam detection tasksT1, .
.
.
, Tm, which share a common feature spacewith d dimensions.
For the task Ti in the domainDi, there is a small labeled set of li review examplesLi = {(xi1, yi1), .
.
.
, (xili , yili)}, where xij ?
Rd isthe vectorial representation of the review j in the la-beled set Li, and yij ?
{+1,?1} refers to the spam1819(+1) or nonspam (?1) label of the review.When there is only one review spam detectiontask, for example, Ti, we can use logistic regression(LR) model to learn a supervised classifier based onthe labeled set Li.
The objective function of LR forsingle-task learning isP iLR(wi)= 1lili?j=1ln(1 + exp(?yijw?i xij)) +?2 ?wi?2,where wi ?
Rd, ?
> 0 refers to regularization pa-rameter.Once the model is learned from solving the opti-mization problem, given a test review instance xj?of the task Ti, we can employ the model to predict itas spam, i.e., y?j?
= 1, with probabilityProb(y?j?
= 1) =11 + exp(?w?i xij?
).Now we have m review spam detection tasks formultiple domains, and we would learn m supervisedclassification models simultaneously.
To achievethis, we introduce a covariance matrix?
to representthe correlations among the m review spam detectiontasks, where ?ij refers to the relation/covariance be-tween a pair of tasks Ti and Tj .
Since ?
is a taskcovariance matrix, we require it to satisfy the con-straint ?
?
0, i.e., positive semidefinite.
We also re-strict Tr(?)
= 1 without of loss of generality, sincefor any covariance matrix Tr(?)
?= 1, we can use?Tr(?)
as ?.
If the covariance matrix is given as priorknowledge, then we introduce a supervised multi-task learning (MTL) framework via logistic regres-sion as followsP?MTL(W)=m?i=11lili?j=1ln(1 + exp(?yijwTi xij))+?2Tr(WWT) + ?2Tr(W?
?1WT ),whereW = (w1, .
.
.
,wm), and ?
> 0 is a regular-ization parameter.Under this multi-task learning setting, the firstterm refers to the sum of all the average empiricalloss, the second term refers to the regularizer used toavoid over-fitting, and the last term is introduced toleverage the shared knowledge from multiple learn-ing tasks according to their relationships.In reality, the covariance matrix may be not pro-vided a priori.
We then present the following multi-task learning model, which can learn the model pa-rameters W and ?
automatically from training re-view dataPMTL(W,?
)=m?i=11lili?j=1ln(1 + exp(?yijwTi xij))+?2Tr(WWT) + ?2Tr(W?
?1WT )s.t.
?
?
0, T r(?)
= 1,If we have only one review spam detection task, i.e.,m = 1, then it is straightforward to verify that theabove multi-task learning formulation would be re-duced to single-task objective function of logistic re-gression.3.2 Semi-supervised Multi-task Learning viaLaplacian Regularized Logistic RegressionGenerally, for a given review domain Di, thereis a large set of unlabeled reviews Ui ={xili+1, .
.
.
,xini} in addition to the labeled reviewset Li.
Then, for each review spam detection taskTi, we constracut a weighted neighborhood graphGi = (Vi, Ei) based on both labeled and unlabeledreview sets Li and Ui.
V refers to the set of datapoints, each of which stands for a review examplexij (j : 1, .
.
.
, ni) from either Li or Ui.
E refers tothe set of weighted edges.
Specifically, if a reviewexample/point xij is among the K nearest neighborsof the review point xik, we put an edge linking thetwo examples, and vice versa.
We also assign an ad-jacent weight score sijk to the edge, which representsthe similarity or closeness between the two reviews.Once the neighborhood graph Gi has been built foreach task, a Laplacian regularizer can be then con-strcted on the graph to extend the regular logistic re-gression model.Considering the similarity matrix Si that corre-sponds to the graph Gi for the task Ti, it is expectedthat a good model would also minimize the follow-1820ing objective?jksijk(w?i xij ?w?i xik)2,This objective implies thatw?i xij should be close tow?i xik if the similarity sijk is large.
The objectivecan be simplified as?jksijk(w?i xij ?w?i xik)2= Tr(w?i Xi(Di ?
Si)X?i wi)= Tr(w?i XiLiX?i wi),where Di = diag(Dijj) is a diagonal matrix, Dijj =?k sijk, and Li = Di?Si refers to the graph Lapla-cian matrix.Then, given both labeled review set Li and un-labeled set Ui for the task Ti, we extend the ba-sic logistic regression by incorporating the graphLaplacian regularizer into its learning framework,and develop a new semi-supervised Laplacian regu-larized logistic regression (LLR) model.
The objec-tive function of LLR for semi-supervised single-tasklearning is given belowP iLLR(wi)= 1lili?j=1ln(1 + exp(?yijw?i xij))+?2 ?wi?2 + ?2Tr(w?i XiLiX?i wi),where ?
> 0 and ?
> 0 are regularization parame-ters.The semi-supervised formulation of LLR bal-ances several desires.
The first term is used to min-imize the loss of the model on the labeled reviewdata, the second term is used to minimize the com-plexity of the model, and the last term refers to theLaplacian regularizer, which is introduced to makethe prediction of the model smooth on the whole re-view data set.Next, based on the objective function of the aboveLLR model, we extend the supervised multi-tasklearning framework, and propose a novel semi-supervised multi-task learning paradigm via Lapla-cian regularized logistic regression (SMTL-LLR) asfollowsPSMTL(W,?
)=m?i=11lili?j=1ln(1 + exp(?yijwTi xij))+?2Tr(WW?)
+ ?2Tr(W??1W?
)+?2m?i=11niTr(wTi XiLiXTi wi)s.t., ?
?
0, T r(?)
= 1.Under this new semi-supervised unified frame-work, our proposed SMTL-LLR model can lever-age the large amount of unlabeled review data in ad-dition to the labeled ones to learn multiple reviewspam detection models simultaneously, and then,what is learned for one task can help other relatedtasks be learned better.
In contrast, previous single-task learning based review spam detection models,which are trained independently, and are typicallybuilt on a limited set of labeled review data, cannotbenefit from this.3.3 Stochastic Alternating MethodThere are two parametersW and ?
in the objectivefunction of the proposed SMTL-LLR model.
It isnot easy to optimize the objective function againstthe two parameters at the same time.
We then de-velop a stochastic alternating method to cope withthe optimization problem for SMTL-LLR, i.e., alter-natively updating one parameter by fixing the other.In particular, we initialize W with the values ran-domly chosen from [0, 1], and initialize ?
as a di-agonal matrix, where ?ii = 1m .
For each iteration,the key update steps for the two parameters are de-scribed as follows?
Step 1: UpdateW while ?
is fixed.W?
argminWPSMTL(W,?)?
Step 2: Update ?
whileW is fixed.??
argmin?PSMTL(W,?
)18213.3.1 UpdatingWWhile Fixing ?For Step 1 of the alternating optimization method,we introduce a stochastic gradient descent methodto efficiently update the parameter W, while ?
isfixed.
Formally, given a learning task Ti, we ran-domly choose a subset or mini-batch of reviewsAib = {(xij , yij)|j ?
[li]} from the labeled set Li ina particular iteration, where [li] denotes {1, .
.
.
, li}and |Aib| = r ?
li.
Based on the subset of labeledreviews Aib, we can construct an unbiased estimateof the objective functionPSMTL(W,?, {Aib}mi=1)=m?i=11r?j?Aibln(1 + exp(?yijwTi xij))+?2Tr(WWT) + ?2Tr(W?
?1WT )+?2m?i=11niTr(wTi XiLiXTi wi)We can then obtain an unbiased stochastic gradi-ent of the objective?WPSMTL(W,?, {Aib}mi=1)= [g1b , .
.
.
,gmb ] + ?W + ?W??1+[?
1n1X1L1XT1 w1, .
.
.
, ?1nmXmLmXTmwm],wheregib =1r?j?Aib?yijxij1 + exp(yijwTi xij).Next, the model parameterW can be updated viastochastic gradient descent methodWt+ 12 = Wt ?
?t?WPSMTL(W,?, {Aib}mi=1)where ?t > 0 refers to learning rate in iteration t.Note that, after each update step for the parame-ter W, we perform a scaling process by forcing thesolution?Wt+1?F ?
?2m ln(2)/?,and then have the following update ruleWt+1 = min(1,?2m ln(2)/?
?Wt+ 12 ?F)Wt+ 12 .We provide a straightforward theoretical analysis,which shows an upper bound of the norm of the op-tima solutionW?, and explains why we perform theabove scaling step.
Using the fact thatPSMTL(W?)
?
PSMTL(0),we thus have?2 ?W?
?2F ?
PSMTL(W?)?
PSMTL(0) = m ln(2).The fist inequality is guaranteed byln(1 + exp(?yijw?i xij)) > 0,T r(W??1W?)
?
0,andTr(w?i XiLiX?i wi) ?
0.3.3.2 Updating ?
While FixingWThe second step of the stochastic alternatingmethod is equivalent to solving the following opti-mization problemmin?Tr(W??1W?
)s.t., ?
?
0, T r(?)
= 1.This convex formulation enjoys the followingclosed-form solution (Zhang and Yeung, 2010)?
= (W?W) 12Tr((W?W) 12 ).It is obviously observed that ?
models the correla-tions between each pair of the tasks or the models.Algorithm 1 summarizes the stochastic alternat-ing optimization method for SMTL-LLR.
Given la-beled and unlabeled review data for multiple reviewdomains, we run the algorithm for P alternatingloops.
Within each loop p, we update the model pa-rameter W for T iterations via stochastic gradientdescent method, where B is number of mini-batches;after that, we update the task covariance matrix ?once based on newW.
The procedure is performediteratively until it is converged.
Then, multiple op-timized review spam detection models and task co-variance matrix would be learned finally.1822Algorithm 1 Stochastic Alternating MethodInput:Labeled and unlabeled review data for multiple tasksInitial learning rate ?0, hyper-parameter ?Regularization parameters ?, ?, ?Initialization:InitializeW with values randomly chosen from [0, 1]Initialize ?
= diag(1/m, .
.
.
, 1/m)for p = 1, .
.
.
, P doW?1 = Wfor t = 1, .
.
.
, T doLearning rate ?t = ?01+?0?tRandomly shuffle reviews in the training setfor b = 1, .
.
.
, B doCompute?WPSMTL(W,?, {Aib}mi=1)Update W?t+ 12 = W?t?
?t?WPSMTL(W,?, {Aib}mi=1)W?t+1 = min(1,?2m ln(2)/?
?W?t+12 ?F)W?t+ 12end forend forUpdateW = W?T+1Update ?
= (W?W)12Tr((W?W)12 )end forOutput: W and ?In addition, we also rely on the stochastic alter-nating method to optimize the proposed MTL-LRmethod.
Differently, we need to remove all the termsrelated to unlabeled data, i.e., discarding the Lapla-cian regularization term from the objective functionand gradient.4 ExperimentsIn this section, we evaluate the proposed multi-task learning methods MTL-LR and SMTL-LLRfor review spam detection, and demonstrate the im-proved effectiveness of the methods over other well-established baselines.4.1 Data SetsDue to big challenge in manually recognizing de-ceptive reviews, there are limited benchmark opin-ion spam data in this field.
We used three groundtruth data sets from the review domains, doctor2,2https://www.ratemds.comhotel3, and restaurant4, respectively, to evaluate theproposed methods, which were created by followingthe similar rules used in (Ott et al, 2011).
Then, foreach ground truth review data set, we randomly col-lected a large number of unlabeled reviews (10,000),which were written about the same entities or do-main.
Table 2 shows some data statistics, where thelast column computes the ratio of labeled reviews tounlabeled ones.Spam/Nonspam Unlabeled RatioDoctor 200/200 10,000 4.0%Hotel 300/300 10,000 6.0%Restaurant 200/200 10,000 4.0%Table 2: Some statistics of review data sets.4.2 Experimental SetupWe followed previous work (Mihalcea and Strappa-rava, 2009; Ott et al, 2011), and leveraged text un-igram and bigram term-frequency features to trainour models for review spam detection.
This problemsetting is quite useful, for example, when user be-havior data are sparse or even not available in prac-tical applications.Supervised classification models, such as logis-tic regression (LR) and support vector machines(SVM), have been used to identify fake reviewspam (Jindal and Liu, 2008; Ott et al, 2011).
Wecompared our methods with the two models.
Semi-supervised positive-unlabeled (PU) learning wasemployed for review spam detection, then we choseone representative PU learning method (Liu et al,2002) to evaluate our models.
We did not compareour methods with the two-view co-training method,which was used for fake review detection (Li etal., 2011), because the reviewer view data are notavailable in the ground truth review sets.
Instead,we selected a well-known semi-supervised trans-ductive SVM (TSVM) (Joachims, 1999) to evaluateour models.
Different from the proposed methods,we trained each of above baselines in a single do-main, because they are single-task learning methods.Moreover, we also compared our methods with onewell-established multi-task learning baseline MTRL(Zhang and Yeung, 2010), which has not been used3https://www.tripadvisor.com4http://www.yelp.com1823for review spam detection problem.It is important to specify appropriate values forthe parameters in the proposed methods.
In oursetting, we used the learning rates ?t that asymp-totically decrease with iteration numbers (Bottou,2012).
Following previous work (Ott et al, 2011;Chen and Chen, 2015), we conducted five-foldcross-validation experiments, and determined thevalues of the regularization and hyper parameters viaa grid-search method.4.3 Experimental ResultsTable 3 reports the spam and nonspam review detec-tion accuracy of our methods SMTL-LLR andMTL-LR against all other baseline methods.
In termsof 5% significance level, the differences betweenSMTL-LLR and the baseline methods are consid-ered to be statistically significant.Doctor Hotel Restaurant AverageSMTL-LLR 85.4% 88.7% 87.5% 87.2%MTL-LR 83.1% 86.7% 85.7% 85.2%MTRL 82.0% 85.4% 84.7% 84.0%TSVM 80.6% 84.2% 83.8% 82.9%LR 79.8% 83.5% 83.1% 82.1%SVM 79.0% 83.5% 82.9% 81.8%PU 68.5% 75.4% 74.0% 72.6%Table 3: Spam and nonspam review detection results inthe doctor, hotel, and restaurant review domains.Under symmetric multi-task learning setting, ourmethods SMTL-LLR and MTL-LR outperform allother baselines for identifying spam reviews fromnonspam ones.
MTL-LR achieves the average ac-curacy of 85.2% across the three domains, which is3.1% and 3.4% better than LR and SVM trained inthe single task learning setting, and 1.2% higher thanMTRL.
Training with a large quantity of unlabeledreview data in addition to labeled ones, SMTL-LLRimproves the performance of MTL-LR, and achievesthe best average accuracy of 87.2% across the do-mains, which is 3.2% better than that of MTRL, andis 4.3% better than TSVM, a semi-supervised sin-gle task learning model.
PU gives the worst perfor-mance, because learning only with partially labeledpositive review data (spam) and unlabeled data maynot generalize as well as other methods.4.4 Performance versus Unlabeled Data SizeFigure 1 plots SMTL-LLR accuracy versus unla-beled data sizes from 0 to 10,000, where 0 corre-sponds to using only labeled data to build the model,i.e., MTL-LR.
Note that we first randomly sampled2,000 unlabeled reviews to build the first set, andthen created the second set by appending anotherrandomly selected set of 2,000 reviews to the pre-vious one.
We repeated the process until all the un-labeled review data sets were created.Figure 1: Accuracy versus Unlabeled Data Size.We observed that learning from unlabeled reviewsdoes help to boost the performance of MTL-LR,which was trained with labeled data alone.
Theperformance of SMTL-LLR improves when trainingwith more and more unlabeled review data.
This isbecause the useful patterns learned from unlabeleddata perhaps supports SMTL-LLR to generalize bet-ter.
But continuing to learn from much more unla-beled reviews may even harm the performance.
Oneexplanation is that appending more unlabeled datamay also incur noisy information to learning pro-cess.
Interestingly, the performance of SMTL-LLRkeeps increasing on the doctor domain, when train-ing with more and more unlabeled reviews up to10,000.
From above observations, we conclude thatan elaborately selected set of high-quality unlabeledreview data may help SMTL-LLR to learn better.4.5 Task CorrelationBased on the covariance matrix (?)
learned from thereview spam detection tasks, we obtained the corre-lation between each pair of tasks for doctor, hotel,and restaurant domains, as shown in Table 4.
The re-view spam detection tasks are highly correlated witheach other for hotel and restaurant domains (0.772).1824This is reasonable due to the large amount of com-monality shared between the two domains.
We cansee that the tasks are also positively correlated be-tween hotel and doctor, as well as between doctorand restaurant domains.Doctor Hotel RestaurantDoctor 1.0 0.688 0.638Hotel 0.688 1.0 0.772Restaurant 0.638 0.772 1.0Table 4: Task correlations.4.6 Shared Text Features among TasksTable 5 lists top weighted shared text features amongthe review spam detection tasks for doctor, hotel,and restaurant domains.
Generally, review spam-mers demonstrate similar motivations when creat-ing deceptive review spam, i.e., promoting their ownproducts/services or defaming those of their com-petitors.
Though different aspects or entities canbe commented on across different domains, we findthat many features or expressions are indeed sharedamong the three review domains.
As we know,deceptive reviewers normally write up reviews formaking money, thus they prefer choosing exagger-ated language in their lies, no matter which domainsthey are working with.
As shown in the first rowfor spam category, they tend to exaggerate their sen-timents using the words like ?definitely?, ?sure?,?highly?, and so on.In contrast, truthful reviewers contribute reviewsfor sharing their true feelings or personal anecdotes.They are willing to write up detailed factual expe-riences, for example, about the doctors they visitedor delicious foods they enjoyed.
Their reviews thustend to contain language patterns in past tense, suchas ?went?, ?did?, and ?took?
shown in the secondrow.5 ConclusionsWe have coped with the problem of detecting de-ceptive review spam.
Given the limited labeled re-view data for individual domains, we formulatedit as a multi-task learning problem.
We first de-veloped a multi-task learning method via logisticregression (MTL-LR), which allows to boost theLabels FeaturesSpam staff, friendly,comfortable, really,right, experience, best, way, amazing,check, away, staff friendly, definitely,sure, highly recommendNonspam good, just, like, went, did, people,excellent, took, wonderful, things,day, fantastic, know, going, niceTable 5: Top weighted shared text features forspam/nonspam category across the three review domains.learning for one task by sharing the knowledge con-tained in the training signals of other related tasks.To leverage the unlabeled data, we introduced agraph Laplacian regularizer into each base model,and proposed a semi-supervised multi-task learningmodel via Laplacian regularized logistic regression(SMTL-LLR).
Moreover, to deal with the optimiza-tion problem, we developed a stochastic alternatingmethod.
Experimental results on real-world reviewdata demonstrated the superiority of SMTL-LLRover several well-established baseline methods.For future work, we plan to create much moreground truth review data from other review domainsand different applications like forums or microblogs,and further test our proposed models for deceptiveopinion spam detection.
We also plan to incorporateour model into a practical opinion mining system, inthis way, more reliable opinion and sentiment anal-ysis results can be then expected.ReferencesAndreas Argyriou, Theodoros Evgeniou, and Massimil-iano Pontil.
2006.
Multi-task feature learning.
InProceedings of the Twentieth Annual Conference onNeural Information Processing Systems, pages 41?48,Vancouver, British Columbia, Canada.Bart Bakker and Tom Heskes.
2003.
Task clustering andgating for bayesian multitask learning.
The Journal ofMachine Learning Research, 4:83?99.Avrim Blum and Tom Mitchell.
1998.
Combining la-beled and unlabeled data with co-training.
In Proceed-ings of the eleventh annual conference on Computa-tional learning theory, pages 92?100.Le?on Bottou.
1997.
Stochastic gradient descent tricks.In Neural Networks: Tricks of the Trade, pages 421?436.Rich Caruana.
1997.
Multitask learning.
In MachineLearning, pages 41?75.1825Yu-Ren Chen and Hsin-Hsi Chen.
2015.
Opinion spamdetection in web forum: A real case study.
In Proceed-ings of the 24th International Conference on WorldWide Web, pages 173?183, Republic and Canton ofGeneva, Switzerland.Francesco De Comite, Francois Denis, Remi Gilleron,and Fabien Letouzey.
1999.
Positive and Unla-beled Examples Help Learning.
In Proceedings of theTenth International Conference on Algorithmic Learn-ing Theory, Lecture Notes in Artificial Intelligence,pages 219?230, Tokyo, Japan.
Springer Verlag.Theodoros Evgeniou and Massimiliano Pontil.
2004.Regularized multi?task learning.
In Proceedings ofthe Tenth ACM SIGKDD International Conference onKnowledge Discovery and Data Mining, pages 109?117, New York, NY, USA.Song Feng, Ritwik Banerjee, and Yejin Choi.
2012.
Syn-tactic stylometry for deception detection.
In Proceed-ings of the 50th Annual Meeting of the Association forComputational Linguistics: Short Papers - Volume 2,pages 171?175.D.
Hernandez, R. Guzman, M. Montes-y-Gomez, and P.Rosso 2013.
Using PU-learning to detect deceptiveopinion spam.
In Proceedings of the 4th Workshopon Computational Approaches to Subjectivity, Senti-ment and Social Media Analysis, pages 38?45, At-lanta, Georgia, USA.Steven C. H. Hoi, Rong Jin, and Michael R. Lyu.
2006.Large-scale text categorization by batch mode activelearning.
In Proceedings of the 15th InternationalConference on World Wide Web, pages 633?642, NewYork, NY, USA.Nitin Jindal and Bing Liu.
2008.
Opinion spam and anal-ysis.
In Proceedings of the International Conferenceon Web Search and Data Mining, pages 219?230, PaloAlto, California, USA.Thorsten Joachims.
1999.
Transductive inference fortext classification using support vector machines.
InProceedings of the Sixteenth International Conferenceon Machine Learning, pages 200?209, San Francisco,CA, USA.Fangtao Li, Minlie Huang, Yi Yang, and Xiaoyan Zhu.2011.
Learning to identify review spam.
In IJCAIProceedings-International Joint Conference on Artifi-cial Intelligence, page 2488.Jiwei Li, Myle Ott, Claire Cardie, and Eduard H. Hovy.2014.
Towards a general rule for identifying decep-tive opinion spam.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Linguis-tics, pages 1566?1576, Baltimore, MD, USA.Ee-Peng Lim, Viet-An Nguyen, Nitin Jindal, Bing Liu,and Hady Wirawan Lauw.
2010.
Detecting productreview spammers using rating behaviors.
In Proceed-ings of the 19th ACM International Conference on In-formation and Knowledge Management, pages 939?948.Bing Liu, Wee Sun Lee, Philip S Yu, and Xiaoli Li.
2002.Partially supervised classification of text documents.In Proceedings of the Nineteenth International Con-ference on Machine Learning, pages 387?394.Jun Liu, Shuiwang Ji, and Jieping Ye.
2009.
Multi-taskfeature learning via efficient l 2, 1-norm minimization.In Proceedings of the twenty-fifth conference on uncer-tainty in artificial intelligence, pages 339?348.
AUAIPress.Rada Mihalcea and Carlo Strapparava.
2009.
The liedetector: Explorations in the automatic recognitionof deceptive language.
In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 309?312, Stroudsburg, PA, USA.Thomas P. Minka.
2003.
A comparison of numericaloptimizers for logistic regression.
Technical report,CMU Technical Report.Arjun Mukherjee, Bing Liu, and Natalie Glance.
2012.Spotting fake reviewer groups in consumer reviews.
InProceedings of the 21st International Conference onWorld Wide Web, pages 191?200.Arjun Mukherjee, Abhinav Kumar, Bing Liu, JunhuiWang, Meichun Hsu, Malu Castellanos, and Riddhi-man Ghosh.
2013a.
Spotting opinion spammers us-ing behavioral footprints.
In Proceedings of the 19thACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, pages 632?640.Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T. Han-cock.
2011.
Finding deceptive opinion spam by anystretch of the imagination.
In Proceedings of the 49thAnnual Meeting of the Association for ComputationalLinguistics: Human Language Technologies - Volume1, pages 309?319, Portland, Oregon.Sinno Jialin Pan and Qiang Yang.
2010.
A survey ontransfer learning.
IEEE Transactions on Knowledgeand Data Engineering, 22(10):1345?1359, October.S.
Thrun and J. O?Sullivan.
1996.
Discovering struc-ture in multiple learning tasks: The TC algorithm.
InL.
Saitta, editor, Proceedings of the 13th InternationalConference on Machine Learning, San Mateo, CA.Morgen Kaufmann.Guan Wang, Sihong Xie, Bing Liu, and Philip S. Yu.2012.
Identify online store review spammers via so-cial review graph.
ACM Trans.
Intell.
Syst.
Technol.,3(4):61:1?61:21, September.Yu Zhang and Dit-Yan Yeung.
2010.
A convex formula-tion for learning task relationships in multi-task learn-ing.
In Proceedings of the Twenty-Sixth Conference onUncertainty in Artificial Intelligence, pages 733?442,Catalina Island, CA, USA.1826
