Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 682?686,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsData point selection for cross-language adaptation of dependency parsersAnders S?gaardCenter for Language TechnologyUniversity of CopenhagenNjalsgade 142, DK-2300 Copenhagen Ssoegaard@hum.ku.dkAbstractWe consider a very simple, yet effective, ap-proach to cross language adaptation of depen-dency parsers.
We first remove lexical itemsfrom the treebanks and map part-of-speechtags into a common tagset.
We then train alanguage model on tag sequences in otherwiseunlabeled target data and rank labeled sourcedata by perplexity per word of tag sequencesfrom less similar to most similar to the target.We then train our target language parser onthe most similar data points in the source la-beled data.
The strategy achieves much betterresults than a non-adapted baseline and state-of-the-art unsupervised dependency parsing,and results are comparable to more complexprojection-based cross language adaptation al-gorithms.1 IntroductionWhile unsupervised dependency parsing has seenrapid progress in recent years, results are still farfrom the results that can be achieved with supervisedparsers and not yet good enough to solve real-worldproblems.
In this paper, we will be interested in analternative strategy, namely cross-language adapta-tion of dependency parsers.
The idea is, briefly put,to learn how to parse Arabic, for example, from, say,a Danish treebank, comparing unlabeled data fromboth languages.
This is similar to, but more diffi-cult than most domain adaptation or transfer learn-ing scenarios, where differences between source andtarget distributions are smaller.Most previous work in cross-language adapta-tion has used parallel corpora to project dependencystructures across translations using word alignments(Smith and Eisner, 2009; Spreyer and Kuhn, 2009;Ganchev et al, 2009), but in this paper we showthat similar results can be achieved by much simplermeans.
Specifically, we build on the cross-languageadaptation algorithm for closely related languagesdeveloped by Zeman and Resnik (2008) and extendit to much less related languages.1.1 Related workZeman and Resnik (2008) simply mapped part-of-speech tags of source and target language treebanksinto a common tagset, delexicalized them (removedall words), trained a parser on the source languagetreebank and applied it to the target language.
Theintuition is that, at least for relatively similar lan-guages, features based on part-of-speech tags areenough to do reasonably well, and languages are rel-atively similar at this level of abstraction.
Of courseannotations differ, but nouns are likely to be depen-dents of verbs, prepositions are likely to be depen-dents of nouns, and so on.Specifically, Zeman and Resnik (2008) trained aconstituent-based parser on the training section ofthe Danish treebank and evaluated it on sentencesof up to 40 words in the test section of the Swedishtreebank and obtained an F1-score of 66.40%.
Dan-ish and Swedish are of course very similar languageswith almost identical syntax, so in a way this result isnot very surprising.
In this paper, we present similarresults (50-75%) on full length sentences for verydifferent languages from different language fami-lies.
Since less related languages differ more in theirsyntax, we use data point selection to find syntactic682constructions in the source language that are likelyto be similar to constructions in the target language.Smith and Eisner (2009) think of cross-languageadaptation as unsupervised projection using wordaligned parallel text to construct training material forthe target language.
They show that hard projectionof dependencies using word alignments performsbetter than the unsupervised dependency parsingapproach described in Klein and Manning (2004),based on EM with clever initialization, and thata quasi-synchronous model using word alignmentsto reestimate parameters in EM performs even bet-ter.
The authors report good results (65%-70%) forsomewhat related languages, training on English andtesting on German and Spanish, but they modifiedthe annotation in the German data making the treat-ment of certain syntactic constructions more similarto the English annotations.Spreyer and Kuhn (2009) use a similar approachto parse Dutch using labeled data from German andobtain good results, but again these are very simi-lar languages.
They later extended their results toEnglish and Italian (Spreyer et al, 2010), but alsomodified annotation considerably in order to do so.Finally, Ganchev et al (2009) report results of asimilar approach for Bulgarian and Spanish; they re-port results with and without hand-written language-specific rules that complete the projected partial de-pendency trees.We will compare our results to the plain approachof Zeman and Resnik (2008), Ganchev et al (2009)without hand-written rules and two recent contribu-tions to unsupervised dependency parsing, Gillen-water et al (2010) and Naseem et al (2010).
Gillen-water et al (2010) is a fully unsupervised exten-sion of the approach described in Klein and Man-ning (2004), whereas Naseem et al (2010) rely onhand-written cross-lingual rules.2 DataWe use four treebanks from the CoNLL 2006 SharedTask with standard splits.
We use the tagset map-pings also used by Zeman and Resnik (2008) to ob-tain a common tagset.12 They define tagset map-1https://wiki.ufal.ms.mff.cuni.cz/user:zeman:interset2We use the first letter in the common tag as coarse-grainedpart-of-speech, and the first three as fine-grained part-of-speech.pings for Arabic, Bulgarian, Czech, Danish, Por-tuguese and Swedish.
We only use four of these tree-banks, since Bulgarian and Czech as well as Danishand Swedish are very similar languages.The four treebanks used in our experiments arethus those for Arabic, Bulgarian, Danish and Por-tuguese.
Arabic is a Semitic VSO language withrelatively free word order and rich morphology.
Bul-garian is a Slavic language with relatively free wordorder and rich morphology.
Danish is a GermanicV2 language with relatively poor morphology.
Fi-nally, Portuguese is a Roman language with rela-tively free word order and rich morphology.
In sum,we consider four languages that are less related thanthe language pairs studied in earlier papers on cross-language adaptation of dependency parsers.3 Experiments3.1 Data point selectionThe key idea in our experiments is that we can use asimple form of instance weighting, similar to what isoften used for correcting sample selection bias or fordomain adaptation, to improve the approach in Ze-man and Resnik (2008) by selecting only sentencesin the source data that are similar to our target do-main or language, considering their perplexity perword in a language model trained on target data.
Theidea is that we order the labeled source data frommost similar to least similar to our target data, usingperplexity per word as metric, and use only a portionof the source data that is similar to our target data.In cross-language adaptation, the sample selec-tion bias is primarily a bias in marginal distribu-tion P (x).
This is the covariate shift assumption(Shimodaira, 2000).
Consequently, each sentenceshould be weighted by Pt(x)Ps(x) where Pt is the targetdistribution, and Ps the source distribution.To see this let x ?
X in lowercase denote a spe-cific value of the input variable, an unlabeled exam-ple.
y ?
Y in lowercase denotes a class value, and?x, y?
is a labeled example.
P (?x, y?)
is the jointprobability of the labeled example, and P?
(?x, y?)
itsempirical distribution.In supervised learning with N labeled data points,we minimize the empirical risk to find a good model??
for a loss function l : X ?
Y ??:683??
= argmin?????x,y??X?YP?
(?x, y?
)l(x, y, ?
)= argmin??
?N?i=1l(xi, yi, ?
)In domain adaptation, we can rewrite this as:??
= argmin?????x,y?
?X?YPt(?x, y?
)Ps(?x, y?
)P?s(?x, y?
)l(x, y, ?
)= argmin??
?Ns?i=1Pt(?xsi , ysi ?
)Ps(?xsi , ysi ?
)l(xsi , ysi , ?
)Under the covariate shift assumption Pt(?x,y?)Ps(?x,y?)
for apair ?x, y?
can be replaced with Pt(x)Ps(x) .
We simplifythis function further assuming thatPt(x)Ps(x)={0 if Pt(x) is low1 if Pt(x) is high}We use perplexity per word of the source lan-guage POS sequences relative to a model trainedon target language POS sequences to guess whetherPt(x) is high or low.The treebanks are first delexicalized and all fea-tures except part-of-speech tags removed.
Thepart-of-speech tags are mapped into a commontagset using the technique described in Zeman andResnik (2008).
For our main results, which are pre-sented in Figure 1, we use the remaining three tree-banks as training material for each language.
Thetest section of the language in question is used fortesting, while the POS sequences in the target train-ing section is used for training the unsmoothed lan-guage model.
We use an unsmoothed trigram lan-guage model rather than a smoothed language modelsince modified Knesser-Ney smoothing is not de-fined for sequences of part-of-speech tags.3In our experiments we use a graph-based second-order non-projective dependency parser that inducesmodels using MIRA (McDonald et al, 2005).4 Wedo not optimize parameters on the different lan-guages, but use default parameters across the board.3http://www-speech.sri.com/projects/srilm/4http://sourceforge.net/projects/mstparser/We present two results and a baseline for each lan-guage in Figure 1.
Our baseline is the accuracy ofour dependency parser trained on three languagesand evaluated on the fourth language, where tree-banks have been delexicalized, and part-of-speechtags mapped into a common format.
This is the pro-posal by Zeman and Resnik (2008).
We then presentresults using the 90% most similar data points andresults where the amount of labeled data used is se-lected using 100 sentences sampled from the train-ing data as held-out data.
It can be seen that using90% of the labeled data seems to be a good strat-egy if using held-out data is not an option.
Since weconsider the unsupervised scenario where no labeleddata is available for the target language, we considerthe results obtained using the 90% most similar sen-tences in the labeled data as our primary results.That we obtain good results training on all thethree remaining treebanks for each language illus-trates the robustness of our approach.
However, itmay in some cases be better to train on data froma single resource only.
The results presented inFigure 2 are the best results obtained with varyingamounts of source language data (10%, 20%, .
.
.
, or100%).
The results are only explorative.
In all cases,we obtain slightly results with training material fromonly one language that are better than or as good asour main results, but differences are marginal.
Weobtain the best results for Arabic training using la-beled data from the Bulgarian treebank, and the bestresults for Bulgarian training on Portuguese only.The best results for Danish were, somewhat surpris-ingly, obtained using the Arabic treebank,5 and thebest results for Portuguese were obtained trainingonly on Bulgarian data.4 Error analysisConsider our analysis of the Arabic sentence in Fig-ure 3, using the three remaining treebanks as sourcedata.
First note that our dependency labels are allwrong; we did not map the dependency labels ofthe source and target treebanks into a common setof labels.
Otherwise we only make mistakes aboutpunctuation.
Our labels seem meaningful, but come5Arabic and Danish have in common that definiteness is ex-pressed by inflectional morphology, though, and both languagesfrequently use VSO constructions.684Arabic Bulgarian Danish Portuguese?
10 ?
?
10 ?
?
10 ?
?
10 ?Ganchev et al (2009) - - 67.8 - - - - -Gillenwater et al (2010) - - 54.3 - 47.2 - 59.8 -Naseem et al (2010) - - - - 51.9 - 71.5 -100% (baseline) - 45.5 - 44.5 - 51.7 - 37.190% 48.3 48.4 77.1 70.2 59.4 51.9 83.1 75.1Held-out % - 49.2 - 70.3 - 52.8 - 75.1Figure 1: Main results.source/target Arabic Bulgarian Danish PortugueseArabic - 45.8 56.5 37.8Bulgarian 50.2 - 50.8 76.9Danish 46.9 60.4 - 63.5Portuguese 50.1 70.3 52.2 -Figure 2: Best results obtained with different combinations of source and target languages.Figure 3: A predicted analysis for an Arabic sentence andits correct analysis.from different treebanks, e.g.
?pnct?
from the Danishtreebank and ?PUNC?
from the Portuguese one.If we consider the case where we train on all re-maining treebanks and use the 90% data points mostsimilar to the target language, and compare it to our100% baseline, our error reductions are distributedas follows, relative to dependency length: For Ara-bic, the error reduction in F1 scores decreases withdependency length, and more errors are made at-taching to the root, but for Portuguese, where theimprovements are more dramatic, we see the biggestimprovements with attachments to the roots andlong dependencies:Portuguese bl (F1) 90% (F1) err.redroot 0.627 0.913 76.7%1 0.720 0.894 62.1%2 0.292 0.768 67.2%3?6 0.328 0.570 36.0%7?
0.240 0.561 42.3%For Danish, we see a similar pattern, but for Bul-garian, error reductions are equally distributed.Generally, it is interesting that cross-languageadaptation and data point selection were less effec-tive for Danish.
One explantation may be differ-ences in annotation, however.
The Danish depen-dency treebank is annotated very differently frommost other dependency treebanks; for example, thetreebank adopts a DP-analysis of noun phrases.Finally, we note that all languages benefit from re-moving the least similar 10% of the labeled sourcedata, but results are less influenced by how much ofthe remaining data we use.
For example, for Bulgar-ian our baseline result using 100% of the source datais 44.5%, and the result obtained using 90% of thesource data is 70.2%.
Using held-out data, we onlyuse 80% of the source data, which is slightly better(70.3%), but even if we only use 10% of the sourcedata, our accuracy is still significantly better than thebaseline (66.9%).5 ConclusionsThis paper presented a simple data point selectionstrategy for semi-supervised cross language adapta-tion where no labeled target data is available.
Thisproblem is difficult, but we have presented very pos-itive results.
Since our strategy is a parameter-freewrapper method it can easily be applied to otherdependency parsers and other problems in naturallanguage processing, incl.
part-of-speech tagging,named entity recognition, and machine translation.685ReferencesKuzman Ganchev, Jennifer Gillenwater, and Ben Taskar.2009.
Dependency grammar induction via bitext pro-jection constraints.
In ACL.Jennifer Gillenwater, Kuzman Ganchev, Joao Graca, Fer-nando Pereira, and Ben Taskar.
2010.
Sparsity in de-pendency grammar induction.
In ACL.Dan Klein and Christopher Manning.
2004.
Corpus-based induction of syntactic structure: models of de-pendency and constituency.
In ACL.Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In ACL.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowledgeto guide grammar induction.
In EMNLP.Hidetoshi Shimodaira.
2000.
Improving predictive in-ference under covariate shift by weighting the log-likelihood function.
Journal of Statistical Planningand Inference, 90:227?244.David Smith and Jason Eisner.
2009.
Parser adaptationand projection with quasi-synchronous grammar fea-tures.
In EMNLP.Kathrin Spreyer and Jonas Kuhn.
2009.
Data-driven de-pendency parsing of new languages using incompleteand noisy training data.
In CoNLL.Kathrin Spreyer, Lilja ?vrelid, and Jonas Kuhn.
2010.Training parsers on partial trees: a cross-languagecomparison.
In LREC.Daniel Zeman and Philip Resnik.
2008.
Cross-languageparser adaptation between related languages.
In IJC-NLP.686
