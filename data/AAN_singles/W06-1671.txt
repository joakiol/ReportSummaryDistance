Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 603?611,Sydney, July 2006. c?2006 Association for Computational LinguisticsLearning Field Compatibilitiesto Extract Database Records from Unstructured TextMichael Wick, Aron Culotta and Andrew McCallumDepartment of Computer ScienceUniversity of MassachusettsAmherst, MA 01003{mwick, culotta, mccallum}@cs.umass.eduAbstractNamed-entity recognition systems extractentities such as people, organizations, andlocations from unstructured text.
Ratherthan extract these mentions in isolation,this paper presents a record extraction sys-tem that assembles mentions into records(i.e.
database tuples).
We construct aprobabilistic model of the compatibilitybetween field values, then employ graphpartitioning algorithms to cluster fieldsinto cohesive records.
We also investigatecompatibility functions over sets of fields,rather than simply pairs of fields, to ex-amine how higher representational powercan impact performance.
We apply ourtechniques to the task of extracting contactrecords from faculty and student home-pages, demonstrating a 53% error reduc-tion over baseline approaches.1 IntroductionInformation extraction (IE) algorithms populate adatabase with facts discovered from unstructuredtext.
This database is often used by higher-leveltasks such as question answering or knowledgediscovery.
The richer the structure of the database,the more useful it is to higher-level tasks.A common IE task is named-entity recognition(NER), the problem of locating mentions of en-tities in text, such as people, places, and organi-zations.
NER techniques range from regular ex-pressions to finite-state sequence models (Bikel etal., 1999; Grishman, 1997; Sutton and McCallum,2006).
NER can be viewed as method of populat-ing a database with single-tuple records, e.g.
PER-SON=Cecil Conner or ORGANIZATION= IBM.We can add richer structure to these single-tuplerecords by extracting the associations among en-tities.
For example, we can populate multi-fieldrecords such as a contact record [PERSON=SteveJobs, JOBTITLE = CEO, COMPANY = Apple,CITY = Cupertino, STATE = CA].
The relationalinformation in these types of records presents agreater opportunity for text analysis.The task of associating together entities is of-ten framed as a binary relation extraction task:Given a pair of entities, label the relation be-tween them (e.g.
Steve Jobs LOCATED-IN Cuper-tino).
Common approaches to relation extractioninclude pattern matching (Brin, 1998; Agichteinand Gravano, 2000) and classification (Zelenko etal., 2003; Kambhatla, 2004).However, binary relation extraction alone is notwell-suited for the contact record example above,which requires associating together many fieldsinto one record.
We refer to this task of piecingtogether many fields into a single record as recordextraction.Consider the task of extracting contact recordsfrom personal homepages.
An NER system maylabel all mentions of cities, people, organizations,phone numbers, job titles, etc.
on a page, fromboth semi-structured an unstructured text.
Evenwith a highly accurate NER system, it is not obvi-ous which fields belong to the same record.
Forexample, a single document could contain fivenames, three phone numbers and only one email.Additionally, the layout of certain fields may beconvoluted or vary across documents.Intuitively, we would like to learn the compat-ibility among fields, for example the likelihoodthat the organization University of North Dakotais located in the state North Dakota, or that phonenumbers with area code 212 co-occur with the603city New York.
Additionally, the system shouldtake into account page layout information, so thatnearby fields are more likely to be grouped into thesame record.In this paper, we describe a method to induce aprobabilistic compatibility function between setsof fields.
Embedding this compatibility func-tion within a graph partitioning method, we de-scribe how to cluster highly compatible fields intorecords.We evaluate our approach on personal home-pages that have been manually annotated withcontact record information, and demonstrate a53% error reduction over baseline methods.2 Related WorkMcDonald et al (2005) present clustering tech-niques to extract complex relations, i.e.
relationswith more than two arguments.
Record extractioncan be viewed as an instance of complex relationextraction.
We build upon this work in three ways:(1) Our system learns the compatibility betweensets of fields, rather than just pairs of field; (2) oursystem is not restricted to relations between en-tities in the same sentence; and (3) our problemdomain has a varying number of fields per record,as opposed to the fixed schema in McDonald et al(2005).Bansal et al (2004) present algorithms for therelated task of correlational clustering: finding anoptimal clustering from a matrix of pairwise com-patibility scores.
The correlational clustering ap-proach does not handle compatibility scores calcu-lated over sets of nodes, which we address in thispaper.McCallum and Wellner (2005) discriminativelytrain a model to learn binary coreference deci-sions, then perform joint inference using graphpartitioning.
This is analogous to our work, withtwo distinctions.
First, instead of binary coref-erence decisions, our model makes binary com-patibility decisions, reflecting whether a set offields belong together in the same record.
Second,whereas McCallum and Wellner (2005) factor thecoreference decisions into pairs of vertices, ourcompatibility decisions are made between sets ofvertices.
As we show in our experiments, factoringdecisions into sets of vertices enables more power-ful features that can improve performance.
Thesehigher-order features have also recently been in-vestigated in other models of coreference, bothdiscriminative (Culotta and McCallum, 2006) andgenerative (Milch et al, 2005).Viola and Narasimhan (2005) present a prob-abilistic grammar to parse contact informationblocks.
While this model is capable of learn-ing long-distance compatibilities (such as City andState relations), features to enable this are not ex-plored.
Additionally, their work focuses on la-beling fields in documents that have been pre-segmented into records.
This record segmentationis precisely what we address in this paper.Borkar et al (2001) and Kristjannson et al(2004) also label contact address blocks, but ig-nore the problem of clustering fields into records.Also, Culotta et al (2004) automatically extractcontact records from web pages, but use heuristicsto cluster fields into records.Embley et al (1999) provide heuristics to de-tect record boundaries in highly structured webdocuments, such as classified ads, and Embleyand Xu (2000) improve upon these heuristics forslightly more ambiguous domains using a vectorspace model.
Both of these techniques apply todata for which the records are highly contiguousand have a distinctive separator between records.These heuristic approaches are unlikely to be suc-cessful in the unstructured text domain we addressin this paper.Most other work on relation extraction focusesonly on binary relations (Zelenko et al, 2003;Miller et al, 2000; Agichtein and Gravano, 2000;Culotta and Sorensen, 2004).
A serious difficultyin applying binary relation extractors to the recordextraction task is that rather than enumerating overall pairs of entities, the system must enumerateover all subsets of entities, up to subsets of sizek, the maximum number of fields per record.
Weaddress this difficulty by employing two samplingmethods: one that samples uniformly, and anotherthat samples on a focused subset of the combina-torial space.3 From Fields to Records3.1 Problem DefinitionLet a fieldF be a pair ?a, v?, where a is an attribute(column label) and v is a value, e.g.
Fi = ?CITY,San Francisco?.
Let record R be a set of fields,R = {F1 .
.
.
Fn}.
Note that R may contain mul-tiple fields with the same attribute but differentvalues (e.g.
a person may have multiple job ti-tles).
Assume we are given the output of a named-604entity recognizer, which labels tokens in a doc-ument with their attribute type (e.g.
NAME orCITY).
Thus, a document initially contains a setof fields, {F1 .
.
.
Fm}.The task is to partition the fields in each anno-tated document into a set of records {R1 .
.
.
Rk}such that each record Ri contains exactly the setof fields pertinent to that record.
In this paper, weassume each field belongs to exactly one record.3.2 Solution OverviewFor each document, we construct a fully-connected weighted graph G = (V,E), with ver-tices V and weighted edges E. Each field in thedocument is represented by a vertex in V , and theedges are weighted by the compatibility of adja-cent fields, i.e.
a measure of how likely it is thatFi and Fj belong to the same record.Partitioning V into k disjoint clusters uniquelymaps the set of fields to a set of k records.
Be-low, we provide more detail on the two principalsteps in our solution: (1) estimating the compati-bility function and (2) partitioning V into disjointclusters.3.3 Learning field compatibilityLet F be a candidate cluster of fields forming apartial record.
We construct a compatibility func-tion C that maps two sets of fields to a real value,i.e.
C : Fi ?
Fj ?
R. We abbreviate the valueC(Fi,Fj) as Cij .
The higher the value of Cij themore likely it is that Fi and Fj belong to the samerecord.For example, in the contact record domain, Cijcan reflect whether a city and state should co-occur, or how likely a company is to have a certainjob title.We represent Cij by a maximum-entropy clas-sifier over the binary variable Sij , which is true ifand only if field set Fi belongs to the same recordas field set Fj .
Thus, we model the conditionaldistributionP?
(Sij |Fi,Fj) ?
exp(?k?kfk(Sij ,Fi,Fj))where fk is a binary feature function that com-putes attributes over the field sets, and ?
= {?k}is the set of real-valued weights that are the pa-rameters of the maximum-entropy model.
We setCij = P?
(Sij =true|Fi,Fj).
This approach canbe viewed as a logistic regression model for fieldcompatibility.Examples of feature functions include format-ting evidence (Fi appears at the top of the docu-ment, Fj at the bottom), conflicting value infor-mation (Fi and Fj contain conflicting values forthe state field), or other measures of compatibility(a city value in Fi is known to exist in a state inFj).
A feature may involve more than one field,for example, if a name, title and university occursconsecutively in some order.
We give a more de-tailed description of the feature functions in Sec-tion 4.3.We propose learning the ?
weights for each ofthese features using supervised machine learning.Given a set of documents D for which the truemapping from fields to set of records is known,we wish to estimate P (Sij |Fi,Fj) for all pairs offield sets Fi,Fj .Enumerating all positive and negative pairs offield sets is computationally infeasible for largedatasets, so we instead propose two samplingmethods to generate training examples.
The firstsimply samples pairs of field sets uniformly fromthe training data.
For example, given a documentD containing true records {R1 .
.
.
Rk}, we sam-ple positive and negative examples of field sets ofvarying sizes from {Ri .
.
.
Rj}.
The second sam-pling method first trains the model using the exam-ples generated by uniform sampling.
This modelis then used to cluster the training data.
Additionaltraining examples are created during the clusteringprocess and are used to retrain the model parame-ters.
This second sampling method is an attempt tomore closely align the characteristics of the train-ing and testing examples.Given a sample of labeled training data, we setthe parameters of the maximum-entropy classi-fier in standard maximum-likelihood fashion, per-forming gradient ascent on the log-likelihood ofthe training data.
The resulting weights indi-cate how important each feature is in determin-ing whether two sets of fields belong to the samerecord.3.4 Partitioning Fields into RecordsOne could employ the estimated classifier to con-vert fields into records as follows: Classify eachpair of fields as positive or negative, and performtransitive closure to enforce transitivity of deci-sions.
That is, if the classifier determines that Aand B belong to the same record and that B andC belong to the same record, then by transitivity605A and C must belong to the same record.
Thedrawback of this approach is that the compatibilitybetween A and C is ignored.
In cases where theclassifier determines that A and C are highly in-compatible, transitive closure can lead to poor pre-cision.
McCallum and Wellner (2005) explore thisissue in depth for the related task of noun corefer-ence resolution.With this in mind, we choose to avoid transitiveclosure, and instead employ a graph partitioningmethod to make record merging decisions jointly.Given a document D with fields {F1 .
.
.
Fn},we construct a fully connected graph G = (V,E),with edge weights determined by the learned com-patibility functionC.
We wish to partition verticesV into clusters with high intra-cluster compatibil-ity.One approach is to simply use greedy agglom-erative clustering: initialize each vertex to its owncluster, then iteratively merge clusters with thehighest inter-cluster edge weights.
The compati-bility between two clusters can be measured usingsingle-link or average-link clustering.
The clus-tering algorithm converges when the inter-clusteredge weight between any pair of clusters is belowa specified threshold.We propose a modification to this approach.Since the compatibility function we have de-scribed maps two sets of vertices to a real value,we can use this directly to calculate the compati-bility between two clusters, rather than performingaverage or single link clustering.We now describe the algorithmmore concretely.?
Input: (1) Graph G = (V,E), where eachvertex vi represents a field Fi.
(2) A thresholdvalue ?
.?
Initialization: Place each vertex vi in its owncluster R?i.
(The hat notation indicates thatthis cluster represents a possible record.)?
Iterate: Re-calculate the compatibility func-tion Cij between each pair of clusters.
Mergethe two most compatible clusters, R?
?i , R?
?j .?
Termination: If there does not exist a pair ofclusters R?i, R?j such that Cij > ?
, the algo-rithm terminates and returns the current set ofclusters.A natural threshold value is ?
= 0.5, since thisis the point at which the binary compatibility clas-sifier predicts that the fields belong to differentrecords.
In Section 4.4, we examine how perfor-mance varies with ?
.3.5 Representational power of clustercompatibility functionsMost previous work on inducing compatibilityfunctions learns the compatibility between pairs ofvertices, not clusters of vertices.
In this section,we provide intuition to explain why directly mod-eling the compatibility of clusters of vertices maybe advantageous.
We refer to the cluster compat-ibility function as Cij , and the pairwise (binary)compatibility function as Bij .First, we note that Cij is a generalization ofsingle-link and average-link clustering methodsthat use Bij , since the output of these methodscan simply be included as features in Cij .
For ex-ample, given two clusters R?i = {v1, v2, v3} andR?j = {v4, v5, v6}, average-link clustering calcu-lates the inter-cluster score between R?i and R?j asSAL(R?i, R?j) =1|R?i||R?j |?a?R?i,b?R?jBabSAL(R?i, R?j) can be included as a feature forthe compatibility function Cij , with an associatedweight estimated from training data.Second, there may exist phenomena of the datathat can only be captured by a classifier that con-siders ?higher-order?
features.
Below we describetwo such cases.In the first example, consider three vertices ofmild compatibility, as in Figure 1(a).
(For theseexamples, let Bij , Cij ?
[0, 1].)
Suppose thatthese three phone numbers occur nearby in a doc-ument.
Since it is not uncommon for a person tohave two phone numbers with different area codes,the pairwise compatibility function may score anypair of nearby phone numbers as relatively com-patible.
However, since it is fairly uncommon fora person to have three phone numbers with threedifferent area codes, we would not like all threenumbers to be merged into the same record.Assume an average-link clustering algorithm.After merging together the 333 and 444 numbers,Bij will recompute the new inter-cluster compat-ibility as 0.51, the average of the inter-clusteredges.
In contrast, the cluster compatibility func-tion Cij can represent the fact that three numberswith different area codes are to be merged, and canpenalize their compatibility accordingly.
Thus, in606333-555-5555666-555-5555444-555-5555.6.49.53333-555-5555666-555-5555444-555-5555.6C = 0.1B = 0.51(a)Univ of NorthDakota,PleasantvillePleasantvilleNorthDakota.48.49.9Univ of NorthDakota,PleasantvillePleasantvilleNorthDakotaC = 0.8B = 0.485.9(b)Figure 1: Two motivating examples illustrating why the cluster compatibility measure (C) may havehigher representational power than the pairwise compatibility measure (B).
In (a), the pairwise measureover-estimates the inter-cluster compatibility when there exist higher-order features such as A personis unlikely to have phone numbers with three different area codes.
In (b), the pairwise measure under-estimates inter-cluster compatibility when weak features like string comparisons can be combined into amore powerful feature by examining multiple field values.this example, the pairwise compatibility functionover-estimates the true compatibility.In the second example (Figure 1(b)), we con-sider the opposite case.
Consider three edges,two of which have weak compatibility, and one ofwhich has high compatibility.
For example, per-haps the system has access to a list of city-statepairs, and can reliably conclude that Pleasantvilleis a city in the state North Dakota.Deciding that Univ of North Dakota, Pleas-antville belongs in the same record as NorthDakota and Pleasantville is a bit more difficult.Suppose a feature function measures the stringsimilarity between the city field Pleasantville andthe company field Univ of North Dakota, Pleas-antville.
Alone, this string similarity might notbe very strong, and so the pairwise compatibil-ity is low.
However, after Pleasantville and NorthDakota are merged together, the cluster compat-ibility function can compute the string similarityof the concatenation of the city and state fields,resulting in a higher compatibility.
In this ex-ample, the pairwise compatibility function under-estimates the true compatibility.These two examples show that the cluster com-patibility score can have more representationalpower than the average of pairwise compatibilityscores.FirstName MiddleNameLastName NickNameSuffix TitleJobTitle CompanyNameDepartment AddressLineCity1 City2State CountryPostalCode HomePhoneFax CompanyPhoneDirectCompanyPhone MobilePager VoiceMailURL EmailInstantMessageTable 1: The 25 fields annotated in the contactrecord dataset.4 Experiments4.1 DataWe hand-labeled a subset of faculty and studenthomepages from the WebKB dataset1.
Each pagewas labeled with the 25 fields listed in Table 1.In addition, we labeled the records to which eachfield belonged.
For example, in Figure 2, we la-beled the contact information for Professor Smithinto a separate record from that of her administra-tive assistant.
There are 252 labeled pages in total,containing 8996 fields and 16679 word tokens.
Weperform ten random samples of 70-30 splits of thedata for all experiments.4.2 SystemsWe evaluate five different record extraction sys-tems.
With the exception of Transitive Closure,all methods employ the agglomerative clustering1http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/607Professor Jane SmithSomesuch University555-555-5555Professor Smith is the Director of the Knowledge Lab ...Mr. John DoeAdministrative Assistant555-367-7777Record 1Record 2Figure 2: A synthetic example representative of the labeled data.
Note that Record 1 contains informationboth from an address block and from free text, and that Record 2 must be separated from Record 1 eventhough fields from each may be nearby in the text.algorithm described previously.
The difference isin how the inter-cluster compatibility is calculated.?
Transitive Closure: The method describedin the beginning of Section 3.4, where hardclassification decisions are made, and transi-tivity is enforced.?
Pairwise Compatibility: In this approach,the compatibility function only estimates thecompatibility between pairs of fields, not setsof fields.
To compute inter-cluster compat-ibility, the mean of the edges between theclusters is calculated.?
McDonald: This method uses the pairwisecompatibility function, but instead of calcu-lating the mean of inter-cluster edges, it cal-culates the geometric mean of all pairs ofedges in the potential new cluster.
That is,to calculate the compatibility of records Riand Rj , we construct a new record Rij thatcontains all fields of Ri and Rj , then calcu-late the geometric mean of all pairs of fieldsin Rij .
This is analogous to the method usedin McDonald et al (2005) for relation extrac-tion.?
Cluster Compatibility (uniform): Inter-cluster compatibility is calculated directly bythe cluster compatibility function.
This is themethod we advocate in Section 3.
Trainingexamples are sampled uniformly as describedin Section 3.3.?
Cluster Compatibility (iterative): Same asabove, but training examples are sampled us-ing the iterative method described in Section3.3.4.3 FeaturesFor the pairwise compatibility classifier, we ex-ploit various formatting as well as knowledge-based features.
Formatting features include thenumber of hard returns between fields, whetherthe fields occur on the same line, and whether thefields occur consecutively.
Knowledge-based fea-tures include a mapping we compiled of cities andstates in the United States and Canada.
Addition-ally, we used compatibility features, such as whichfields are of the same type but have different val-ues.In building the cluster compatibility classifier,we use many of the same features as in the bi-nary classifier, but cast them as first-order existen-tial features that are generated if the feature existsbetween any pair of fields in the two clusters.
Ad-ditionally, we are able to exploit more powerfulcompatibility and knowledge-base features.
Forexample, we examine if a title, a first name and alast name occur consecutively (i.e., no other fieldsoccur in-between them).
Also, we examine multi-ple telephone numbers to ensure that they have thesame area codes.
Additionally, we employ countfeatures that indicate if a certain field occurs morethan a given threshold.4.4 ResultsFor these experiments, we compare performanceon the true record for each page.
That is, we cal-culate how often each system returns a completeand accurate extraction of the contact record per-taining to the owner of the webpage.
We refer to608this record as the canonical record and measureperformance in terms of precision, recall and F1for each field in the canonical record.Table 2 compares precision, recall and F1 acrossthe various systems.
The cluster compatibilitymethod with iterative sampling has the highest F1,demonstrating a 14% error reduction over the nextbest method and a 53% error reduction over thetransitive closure baseline.Transitive closure has the highest recall, but itcomes at the expense of precision, and hence ob-tains lower F1 scores than more conservative com-patibility methods.
The McDonald method alsohas high recall, but drastically improves precisionover the transitivity method by taking into consid-eration all edge weights.The pairwise measure yields a slightly higherF1 score than McDonald mostly due to precisionimprovements.
Because the McDonald methodcalculates the mean of all edge weights ratherthan just the inter-cluster edge weights, inter-cluster weights are often outweighed by intra-cluster weights.
This can cause two densely-connected clusters to be merged despite low inter-cluster edge weights.To further investigate performance differences,we perform three additional experiments.
The firstmeasures how sensitive the algorithms are to thethreshold value ?
.
Figure 3 plots the precision-recall curve obtained by varying ?
from 1.0 to 0.1.As expected, high values of ?
result in low recallbut high precision, since the algorithms halt witha large number of small clusters.
The highlightedpoints correspond to ?
= 0.5.
These results indi-cate that setting ?
to 0.5 is near optimal, and thatthe cluster compatibility method outperforms thepairwise across a wide range of values for ?
.In the second experiment, we plot F1 versusthe size of the canonical record.
Figure 4 indi-cates that most of the performance gain occursin smaller canonical records (containing between6 and 12 fields).
Small canonical records aremost susceptible to precision errors simply be-cause there are more extraneous fields that maybe incorrectly assigned to them.
These precisionerrors are often addressed by the cluster compati-bility method, as shown in Table 2.In the final experiment, we plot F1 versus thetotal number of fields on the page.
Figure 5 indi-cates that the cluster compatibility method is bestat handling documents with large number of fields.F1 Precision RecallCluster (I) 91.81 (.013) 92.87 (.005) 90.78 (.007)Cluster (U) 90.02 (.012) 93.56 (.007) 86.74 (.011)Pairwise 90.51 (.013) 91.07 (.004) 89.95 (.006)McDonald 88.36 (.012) 83.55 (.004) 93.75 (.005)Trans Clos 82.37 (.002) 70.75 (.009) 98.56 (.020)Table 2: Precision, recall, and F1 performance forthe record extraction task.
The standard error iscalculated over 10 cross-validation trials.0.55 0.60.65 0.70.75 0.80.85 0.90.95 1  00.10.20.30.40.50.60.70.80.91precisionrecallclusterpairwiseFigure 3: Precision-recall curve for cluster, pair-wise, and mcdonald.
The graph is obtained byvarying the stopping threshold ?
from 1.0 to 0.1.The highlighted points correspond to ?
= 0.5.When there are over 80 fields in the document, theperformance of the pairwise method drops dramat-ically, while cluster compatibility only declinesslightly.
We believe the improved precision of thecluster compatibility method explains this trend aswell.We also examine documents where cluster com-patibility outperforms the pairwise methods.
Typ-ically, these documents contain interleaving con-tact records.
Often, it is the case that a single pairof fields is sufficient to determine whether a clus-ter should not be merged.
For example, the clusterclassifier can directly model the fact that a con-tact record should not have multiple first or lastnames.
It can also associate a weight with the factthat several fields overlap (e.g., the chances thata cluster has two first names, two last names andtwo cities).
In contrast, the binary classifier onlyexamines pairs of fields in isolation and averagesthese probabilities with other edges.
This averag-ing can dilute the evidence from a single pair offields.
Embarrassing errors may result, such asa contact record with two first names or two last6090.740.760.780.80.820.840.860.880.90.920.940.966-9 9-12 12+number fields per recordF1pairwisemcdonaldclusterFigure 4: Field F1 as the size of the canonicalrecord increases.
This figure suggests that clus-ter compatibility is most helpful for small records.0.80.820.840.860.880.90.920.940.960-20 20-40 40-60 60-80 80+number fields per documentF1pairwisemcdonaldclusterFigure 5: Field F1 as the number of fields inthe document increases.
This figure suggests thatcluster compatibility is most helpful when the doc-ument has more than 80 fields.names.
These errors are particularly prevalent ininterleaving contact records since adjacent fieldsoften belong to the same record.5 Conclusions and Future WorkWe have investigated graph partitioning methodsfor discovering database records from fields anno-tated in text.
We have proposed a cluster compat-ibility function that measures how likely it is thattwo sets of fields belong to the same cluster.
Weargue that this enhancement to existing techniquesprovides more representational power.We have evaluated these methods on a set ofhand-annotated data and concluded that (1) graphpartitioning techniques are more accurate than per-forming transitive closure, and (2) cluster compat-ibility methods can avoid common mistakes madeby pairwise compatibility methods.As information extraction systems becomemore reliable, it will become increasingly impor-tant to develop accurate ways of associating dis-parate fields into cohesive records.
This will en-able more complex reasoning over text.One shortcoming of this approach is that fieldsare not allowed to belong to multiple records,because the partitioning algorithm returns non-overlapping clusters.
Exploring overlapping clus-tering techniques is an area of future work.Another avenue of future research is to considersyntactic information in the compatibility func-tion.
While performance on contact record extrac-tion is highly influenced by formatting features,many fields occur within sentences, and syntacticinformation (such as dependency trees or phrase-structure trees) may improve performance.Overall performance can also be improved byincreasing the sophistication of the partitioningmethod.
For example, we can examine ?blockmoves?
to swap multiple fields between clustersin unison, possibly avoiding local minima of thegreedy method (Kanani et al, 2006).
This can beespecially helpful because many mistakes may bemade at the start of clustering, before clusters arelarge enough to reflect true records.Additionally, many personal web pages con-tain a time-line of information that describe a per-son?s educational and professional history.
Learn-ing to associate time information with each con-tact record enables career path modeling, whichpresents interesting opportunities for knowledgediscovery techniques, a subject of ongoing work.AcknowledgmentsWe thank the anonymous reviewers for helpfulsuggestions.
This work was supported in part bythe Center for Intelligent Information Retrieval, inpart by U.S. Government contract #NBCH040171through a subcontract with BBNT Solutions LLC,in part by The Central Intelligence Agency, theNational Security Agency and National ScienceFoundation under NSF grant #IIS-0326249, and inpart by the Defense Advanced Research ProjectsAgency (DARPA), through the Department of theInterior, NBC, Acquisition Services Division, un-der contract number NBCHD030010.
Any opin-610ions, findings and conclusions or recommenda-tions expressed in this material are the author(s)and do not necessarily reflect those of the sponsor.ReferencesEugene Agichtein and Luis Gravano.
2000.
Snow-ball: Extracting relations from large plain-text col-lections.
In Proceedings of the Fifth ACM Interna-tional Conference on Digital Libraries.Nikhil Bansal, Avrim Blum, and Shuchi Chawla.
2004.Correlation clustering.
Machine Learining, 56:89?113.Daniel M. Bikel, Richard Schwartz, and Ralph M.Weischedel.
1999.
An algorithm that learns what?sin a name.
Machine Learning, 34:211?231.Vinayak R. Borkar, Kaustubh Deshmukh, and SunitaSarawagi.
2001.
Automatic segmentation of textinto structured records.
In SIGMOD Conference.Sergey Brin.
1998.
Extracting patterns and rela-tions from the world wide web.
In WebDB Work-shop at 6th International Conference on ExtendingDatabase Technology.Aron Culotta and Andrew McCallum.
2006.
PracticalMarkov logic containing first-order quantifiers withapplication to identity uncertainty.
In HLT Work-shop on Computationally Hard Problems and JointInference in Speech and Language Processing, June.Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In ACL.Aron Culotta, Ron Bekkerman, and Andrew McCal-lum.
2004.
Extracting social networks and contactinformation from email and the web.
In First Con-ference on Email and Anti-Spam (CEAS), MountainView, CA.David W. Embley and Lin Xu.
2000.
Record locationand reconfiguration in unstructured multiple-recordweb documents.
In WebDB, pages 123?128.David W. Embley, Xiaoyi Jiang, and Yiu-Kai Ng.1999.
Record-boundary discovery in web docu-ments.
In SIGMOD Conference, pages 467?478.Ralph Grishman.
1997.
Information extraction: Tech-niques and challenges.
In SCIE, pages 10?27.Nanda Kambhatla.
2004.
Combining lexical, syntac-tic, and semantic features with maximum entropymodels for extracting relations.
In ACL.Pallika Kanani, Andrew McCallum, and Chris Pal.2006.
Improving author coreference by resource-bounded information gathering from the web.
Tech-nical note.Trausti Kristjannson, Aron Culotta, Paul Viola, andAndrew McCallum.
2004.
Interactive informationextraction with conditional random fields.
Nine-teenth National Conference on Artificial Intelligence(AAAI 2004).Andrew McCallum and Ben Wellner.
2005.
Condi-tional models of identity uncertainty with applica-tion to noun coreference.
In Lawrence K. Saul, YairWeiss, and Le?on Bottou, editors, Advances in Neu-ral Information Processing Systems 17.
MIT Press,Cambridge, MA.Ryan McDonald, Fernando Pereira, Seth Kulick, ScottWinters, Yang Jin, and Pete White.
2005.
Simplealgorithms for complex relation extraction with ap-plications to biomedical ie.
In 43rd Annual Meetingof the Association for Computational Linguistics.Brian Milch, Bhaskara Marthi, and Stuart Russell.2005.
BLOG: Probabilistic models with unknownobjects.
In IJCAI.Scott Miller, Heidi Fox, Lance A. Ramshaw, and RalphWeischedel.
2000.
A novel use of statistical parsingto extract information from text.
In ANLP.Charles Sutton and Andrew McCallum.
2006.
An in-troduction to conditional random fields for relationallearning.
In Lise Getoor and Ben Taskar, editors,Introduction to Statistical Relational Learning.
MITPress.
To appear.Paul Viola and Mukund Narasimhan.
2005.
Learningto extract information from semi-structured text us-ing a discriminative context free grammar.
In SIGIR?05: Proceedings of the 28th annual internationalACM SIGIR conference on Research and develop-ment in information retrieval, pages 330?337, NewYork, NY, USA.
ACM Press.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relation ex-traction.
Journal of Machine Learning Research,3:1083?1106.611
