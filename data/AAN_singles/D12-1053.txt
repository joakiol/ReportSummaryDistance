Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 579?589, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsA Statistical Relational Learning Approach to IdentifyingEvidence Based Medicine CategoriesMathias Verbeke?
Vincent Van Asch?
Roser Morante?Paolo Frasconi?
Walter Daelemans?
Luc De Raedt??
Department of Computer Science, Katholieke Universiteit Leuven, Belgium{mathias.verbeke, luc.deraedt}@cs.kuleuven.be?
Department of Linguistics, Universiteit Antwerpen, Belgium{roser.morante, vincent.vanasch, walter.daelemans}@ua.ac.be?
Dipartimento di Sistemi e Informatica, Universita` degli Studi di Firenze, Italyp-f@dsi.unifi.itAbstractEvidence-based medicine is an approachwhereby clinical decisions are supported bythe best available findings gained from scien-tific research.
This requires efficient accessto such evidence.
To this end, abstracts inevidence-based medicine can be labeled usinga set of predefined medical categories, the so-called PICO criteria.
This paper presents anapproach to automatically annotate sentencesin medical abstracts with these labels.
Sinceboth structural and sequential information areimportant for this classification task, we usekLog, a new language for statistical relationallearning with kernels.
Our results show a clearimprovement with respect to state-of-the-artsystems.1 IntroductionEvidence-based medicine (EBM) or evidence-basedpractice (EBP) combines clinical expertise, the pref-erences and values of the patient and the bestavailable evidence to make good patient care deci-sions.
Clinical research findings are systematicallyreviewed, appraised and used to improve the patientcare, for which efficient access to such evidence isrequired.
In order to facilitate the search process,medical documents are labeled using a set of prede-fined medical categories, the PICO criteria.
PICO isan acronym for the mnemonic concepts that are usedto construct queries when searching for scientific ev-idence in the EBM process.
The need to automatizethe annotation process has initiated research into au-tomatic approaches to annotate sentences in medicaldocuments with the PICO labels.As indicated by Kim et al2011), both the struc-tural information of the words in the sentence, andthat of the sentences in the document are importantfeatures for this task.
Furthermore, sequential infor-mation can leverage the dependencies between dif-ferent sentences in the text.
Therefore we propose anapproach using kLog (Frasconi et al2012) to tacklethis problem.
kLog is a new language for statisticalrelational learning with kernels, that is embedded inProlog, and builds upon and links together conceptsfrom database theory, logic programming and learn-ing from interpretations.
Learning from interpreta-tions is a logical and relational learning setting (DeRaedt et al2008) in which the examples are inter-pretations, that is, sets of tuples that are true in theexamples.
In a sense, each example can be viewedas a small relational database.
kLog is able to trans-form relational into graph-based representations andapply kernel methods to extract an extended high-dimensional feature space.The choice for kLog was motivated by previousresults (Verbeke et al2012), where we showed thata statistical relational learning approach using kLogis able to process the contextual aspects of languageimproving on state-of-the-art results for hedge cuedetection.
However, the current task adds two levelsof complexity.
First, next to the relations betweenthe words in the sentence, now also the relations be-tween the sentences in the document become impor-tant.
In the proposed approach, we first generate afeature space with kLog that captures the intrasen-tential properties and relations.
Hereafter, these fea-tures serve as input for a structured output supportvector machine that can handle sequence tagging579(Tsochantaridis et al2004), in order to take theintersentential features into account.
Second, sincethere are more than two categories, and each sen-tence can have multiple labels, the problem is now amulticlass multilabel classification task.The main contribution of this paper is that weshow that kLog?s relational nature and its abilityto declaratively specify and use background knowl-edge is beneficial for natural language learning prob-lems.
This is shown on the NICTA-PIBOSO corpus,for which we present results that indicate a clear im-provement on the state-of-the-art.The remainder of this paper is organized as fol-lows.
In Section 2, we outline earlier work that isrelated to the research presented here.
Section 3 de-scribes the methodology of our method.
We presenta thorough evaluation of our method in Section4.
The last section draws conclusions and presentssome ideas for future work.2 Related WorkEBM is an approach to clinical problem-solvingbased on ?systematically finding, appraising, and us-ing contemporaneous research findings as the ba-sis for clinical decisions?
(Rosenberg and Donald,1995).
The evidence-based process consists of foursteps: (1) Formulating a question from a patient?sproblem; (2) Searching the literature for relevantclinical articles; (3) Evaluating the evidence; And(4) implementing useful findings in clinical prac-tice.
Given the amounts of medical publicationsavailable in databases such as PubMed, automatingstep 2 is crucial to help doctors in their practice.Efforts in this direction from the NLP communityhave so far focused on corpus annotation (Demner-Fushman and Lin, 2007; Kim et al2011), text cate-gorization (Davis-Desmond and Molla?, 2012), sum-marization (Molla?
and Santiago-Mart?
?nez, 2011),and question-anwering (Niuet al2003; Demner-Fushman and Lin, 2007).The existing corpora are usually annotated withthe PICO mnemonic (Armstrong, 1999) concepts,that are used to build queries when searching forliterature for EBM purposes.
The PICO conceptsare: primary Problem (P) or population, main Inter-vention (I), main intervention Comparison (C), andOutcome of intervention (O).
PICO helps determin-ing what terms are important in a query and there-fore it helps building the query, which is sent to thesearch repositories.
Once the documents are found,they need to be read by a person who eliminates ir-relevant documents.The first attempt to classify PICO concepts is pre-sented in Demner-Fushman and Lin (2007), whoapply a rule-based approach to identify sentenceswhere PICO concepts occur and a supervised ap-proach to classify sentences that contain an Out-come.
The features used by this classifier are n-grams, position, and semantic information from theparser used to process the data.
The system is trainedon 275 abstracts manually annotated.
The accura-cies reported range from 80% for Population, 86%for Problem, 80% for Intervention, and, from 64%to 95% for Outcome depending on the test set of ab-stracts.Kim et al2011) perform a similar classificationtask in two steps.
First a classifier identifies the sen-tences that contain PICO concepts, and then anotherclassifier assigns PICO tags to the sentences foundto be relevant by the previous classifier.
The sys-tem is based on a CRF algorithm and is trained onthe NICTA-PIBOSO corpus.
This dataset contains1,000 medical abstracts manually annotated with anextension of the PICO tagset, for which the defini-tions are listed in Table 1.
The annotation is per-formed at sentence level and one sentence may havemore than one tag.
An example of an annotatedabstract from the corpus can be found in the sup-plementary material.
The features used by the al-gorithm include features derived from the context,semantic relations, structure and sequencing of thetext.
The system is evaluated for 5-way and 6-wayclassification and results are provided apart fromstructured and unstructured abstracts.
The F-scoresfor structured abstracts is 89.32% for 5-way classifi-cation and 80.88% for 6-way classification, whereasfor unstructured abstracts it is 71.54% for 5-wayclassification and 64.66% for 6-way classification.Chung (2009) uses CRF to classify PICO con-cepts by combining them with general categories as-sociated with rhetorical roles: Aim, Method, Resultsand Conclusion.
Her system is tested on corpora ofabstracts of randomized control trials.
First struc-tured abstracts with headings labeled with PICO580Background Material that informs and may place the current study in perspective, e.g.
work that preceded thecurrent; information about disease prevalence; etc.Population The group of individual persons, objects or items comprising the study?s sample, or from whichthe sample was taken for statistical measurementIntervention The act of interfering with a condition to modify it or with a process to change its course (includesprevention)Outcome The sentence(s) that best summarizes the consequences of an interventionStudy Design The type of study that is described in the abstractOther Any sentence not falling into one of the other categories and presumed to provide little help withclinical decision making, i.e.
non-key or irrelevant sentencesTable 1: Definitions of the semantic tags used as annotation categories (taken from Kim et al2011)).concepts are used.
A sentence level classificationtask is performed, assigning only one rhetorical roleper sentence.
The F-scores obtained range from 0.93to 0.98.
Then another sentence level classificationtask is performed to automatically assign the labelsIntervention, Participant and Outcome Measures tosentences in unstructured and structured abstractswithout headings.
F-scores of up to 0.83 and 0.84are obtained for Intervention and Outcome Measuresentences.Other work aimed at identifying rhetorical zonesin biomedical articles.
In this case areas of text areclassified in terms of the rhetorical categories In-troduction, Methods, Results and Discussion (IM-RAD) (Agarwal and Yu, 2009) or richer categories,such as problem-setting or insight (Mizuta et al2006).There exists a wide range of statistical relationallearning systems (Getoor and Taskar, 2007; DeRaedt et al2008), and many of these systemsare in principle useful for natural language process-ing.
The most popular formalism today is MarkovLogic, which has already been used for natural lan-guage processing tasks such as semantic role label-ing (Riedel and Meza-Ruiz, 2008) and coreferenceresolution (Poon and Domingos, 2008).
With re-spect to Markov Logic, two distinguishing featuresof kLog are that 1) it employs kernel based meth-ods grounded in statistical learning theory, and 2) itemploys a Prolog like language for defining and us-ing background knowledge.
As Prolog is a program-ming language, this is more flexible that the formal-ism used by Markov Logic.3 MethodologyIn learning from examples, or interpretations (DeRaedt et al2008), the instances are sampled iden-tically and independently from some unknown butfixed distribution.
They can be represented as pairsz = (x, y), in which x represents the inputs and ythe outputs.
An example interpretation can be foundin Figure 3, where the hasCategory relation repre-sents y in this case, since it is the target relation wewant to predict.
The inputs x are formed by all otherfacts.
The task is now to learn a function h : X ?
Ythat maps the inputs to the outputs.
Sentences mayhave multiple labels.
Hence this is a structured out-put task where the output is a sequence of sets oflabels attached to the sentences in a given document.kLog is the new statistical relational language forlearning with kernels that we use to tackle the PICOcategories classification task.
The novelty of kLogis that, based on the regular, linguistic features, itallows to define an extended high-dimensional fea-ture space that is also able to take relational featuresinto account in a principled manner.
Furthermore,its declarative approach offers a flexible and inter-pretable way to construct features.The choice of kLog is motivated by our previousresults (Verbeke et al2012), where we showed thatthe relational representation of the domain as usedby kLog is able to take the contextual aspects of lan-guage into account.
Whereas there we only usedthe relations at the sentence level, the current taskadds a new level of complexity, since the identifica-tion of PICO categories in abstracts also requires totake into account various relations between the sen-tences of an abstract.
The general workflow of ourapproach is depicted in Figure 1, which will be de-581Database(Fig.
3)ExtensionalizeddatabaseGraph(Fig.
4)Kernel matrix/feature vectorsStatisticallearnerRaw data(sentence)Feature extraction(lemma, POS,?
)Declarative featureconstructionGraphicalizationFeaturegenerationGraph kernel(NSPDK)kLogFigure 1: General kLog workflow.scribed step by step in the following paragraphs.Preprocessing The sentences have been prepro-cessed with a named entity tagger and a dependencyparser.Named entity tagging has been performed withthe BiogaphTA named entity module, whichmatches token sequences with entries in the UMLSdatabase1.
UMLS integrates over 2 million namesfor some 900,000 concepts from more than 60 fami-lies of biomedical vocabularies (Bodenreider, 2004).The tagger matches sequences with a length of max-imum 4 tokens.
This covers 66.2% of the UMLSentries.
By using UMLS, different token sequencesreferring to the same concept can be mapped tothe same concept identifier (CID).
The BiographTAnamed entity tagger has been evaluated on theBioInfer corpus (Pyysalo et al2007) obtaining a72.02 F1 score.Dependency parsing has been performed with theGENIA dependency parser GDep (Sagae and Tsu-jii, 2007), which uses a best-first probabilistic shift-reduce algorithm based on the LR algorithm (Knuth,1965) and extended by the pseudo-projective pars-ing technique.
This parser is a version of the KSDepdependency parser trained on the GENIA Treebankfor parsing biomedical text.
KSDep was evaluatedin the CoNLL Shared Task 2007 obtaining a La-beled Attachment Score of 89.01% for the Englishdataset.
GDEP outputs the lemmas, chunks, Genianamed entities and dependency relations of the to-kens in a sentence.This information can be represented as anEntity/Relationship (E/R) diagram, a modelingparadigm that is frequently used in database theory(Garcia-Molina et al2008).
The E/R-model for the1From UMLS only the MRCONSO.RRF and MRSTY.RRFfiles are used.problem under consideration is shown in Figure 2,which provides an abstract representation of the ex-amples, i.e.
medical abstracts in this case.
We willshow later how this abstract representation can beunrolled for each example, resulting in a graph; cf.also Figure 4 for our example sentence.
This rela-tional database representation will serve as the inputfor kLog.wdepHeadnextwordIDdepRellemmaPOS-tagchunktagwordStringNEGeniaNEUMLSsentencehasWordclasssentIDhasCategorynextSFigure 2: E/R-diagram modeling the sentence identifica-tion task.The entities are the words and sentences in theabstract.
They are represented by the rectangles inthe E/R-model.
Each entity can have a number ofproperties attached to it, depicted by the ovals andhas a unique identifier (underlined properties).
Asin database theory, each entity corresponds with atuple, or fact, in the database.Figure 3 shows a part of an example interpretationz.
For example, w(w4 1,?Surgical?,?Surgical?,b-np,jj,?O?,?O?)
specifies a word entity, with w4 1 asidentifier and the other arguments as properties.
Asindicated before, as lexical information we take thetoken string itself, its lemma, the part-of-speech tagand the chunk tag into account.
We also includesome semantic information, namely two binary val-ues indicating if the word is a (biological) namedentity.
sentence(s4,4) represents a sentence entity,with its index in the abstract as a property.Furthermore, the E/R-diagram also contains anumber of relationships, which are represented by582sentence(s4,4)hasCategory(s4,?background?)w(w4_1,?Surgical?,?Surgical?,b-np,jj,?O?,?O?)
hasWord(s4,w4_1)dh(w4_1,w4_2,nmod)nextW(w4_2,w4_1)w(w4_2,?excision?,?excision?,i-np,nn,?O?,?O?)
hasWord(s4,w4_2)dh(w4_2,w4_5,sub)nextW(w4_3,w4_2)w(w4_3,?of?,?of?,b-pp,in,?O?,?O?)hasWord(s4,w4_3)dh(w4_3,w4_2,nmod)nextW(w4_4,w4_3)w(w4_4,?CNV?,?CNV?,b-np,nn,?B-protein?,?O?)
hasWord(s4,w4_4)dh(w4_4,w4_3,pmod)nextW(w4_5,w4_4)...Figure 3: Part of an example interpretation z, represent-ing the example sentence in Figure 4.the diamonds.
They are linked to the entities thatparticipate in the relationship, or stand alone if theycharacterize general properties of the interpretation.An example relation is nextW(w4 2,w4 1), whichindicates the sequence of the words in the sentence.dh(w4 1,w4 2,nmod) specifies that word w4 1 isa noun modifier of word w4 2, and thus serves toincorporate the dependency relationships betweenthe words.
hasCategory(s4,?background?)
signi-fies that sentence s4 is a sentence describing back-ground information.
This relation is the target re-lation that we want to predict for this task and willnot be taken into account as a feature, but is listed inthe database and only used during the training of themodel.Since the previously described entities and rela-tionships are listed explicitly in the database, theseare called extensional relations, in contrast to the in-tensional relations, as we will describe next.Declarative feature construction A strength ofkLog is that it is also capable of constructing fea-tures declaratively, by using intensional relations.This enables one to encode additional backgroundknowledge based on a small set of preprocessed fea-tures, which renders experimentation very flexibleand makes the results more interpretable.
It further-more allows one to limit the required features to thecore discriminative ones.
These intensional featuresare defined through definite clauses, and is done us-ing an extension of the declarative programming lan-guage Prolog.
The following features were used.We make a distinction between the features used forstructured and unstructured abstracts.For structured abstracts, four intensional relationswere defined.
The relation lemmaRoot(S,L) isspecified as:lemmaRoot(S,L) ?hasWord(S, I),w(I,_,L,_,_,_,_),dh(I,_,root).For each sentence, it only selects the lemmasof the root word in the dependency tree, whichmarkedly limits the number of word features used.The following relations are related to, and try tocapture the document structure imposed by the sec-tion headers present in the structured abstracts.hasHeaderWord(S,X) identifies whether a sen-tence is a header of a section.
In order to realize this,it selects the words of a sentence that count morethan four characters (to discard short names of bio-logical entities), which all need to be uppercase.hasHeaderWord(S,X) ?w(W,X,_,_,_,_,_),hasWord(S,W),(atom(X) -> name(X,C) ; C = X),length(C,Len),Len > 4,all_upper(C).Also the sentences below a certain section headerneed to be marked as belonging to this sec-tion, which is done by the relation hasSection-Header(S,X).hasSectionHeader(S,X) ?nextS(S1,S),hasHeaderWord(S1,X).hasSectionHeader(S,X) ?nextS(S1,S),not isHeaderSentence(S),once(hasSectionHeader(S1,X)).583For the unstructured abstracts, also the lemma-Root relation is used, but next to the lemma, nowalso the part-of-speech tag of the root word is takeninto account.
Since the unstructured abstracts lacksection headers, other features were needed to dis-tinguish between the different sections, for whichthe relation prevLemmaRoot proved to be very in-formative.
It adds the lemma of the root word in theprevious sentence as a property to the current sen-tence under consideration.prevLemmaRoot(S,L) ?nextS(S1,S),lemmaRoot(S1,L,_).The intensional predicates are grounded.
This isa proces similar to materialization in databases, thatis, the atoms implied by the background knowledgeand the facts in the example are all computed usingProlog?s deduction mechanism.
This leads to theextensionalized database, in which both the exten-sional as well as the grounded intensional predicatesare listed.Graphicalization and feature generation In thethird step, the interpretations are graphicalized, i.e.transformed into graphs.
Since the facts that formthe interpretation still conform to the E/R-diagram,this can be interpreted as unfolding the E/R-diagramover the data.
An example illustrating this processis given in Figure 4.
Each interpretation is convertedinto a bipartite graph, for which there is a vertex forevery ground atom of every E-relation, one for everyground atom of every R-relation, and an undirectededge {e, r} if an entity e participates in relationshipr.The obtained graphs can then be used in the nextstep for feature generation.
This is done by meansof a graph kernel ?, which calculates the similar-ity between two graphicalized interpretations.
Anygraph kernel that allows fast computations on largegraphs and has a flexible bias to enable heteroge-neous features can in theory be applied.
In the cur-rent implementation, an extension of the Neighbor-hood Subgraph Pairwise Distance Kernel (NSPDK)(Costa and De Grave, 2010) is used.NSPDK is a decomposition kernel (Haussler,1999), in which pairs of subgraphs are compareds0s1s2s3nextSnextSnexts4s5s6s7s8s9titletitleSurgical  excision  of  CNV  may  allow  stabilisation  or  improvement  of  vision.backgroundnext nextdh(nmod)dh(sub)dh(pmod)hasWordFigure 4: Graphicalization Gz of interpretation z.to each other in order to calculate the similarity be-tween two graphs.
These subgraphs can be seen ascircles in the graph, and are defined by three hyper-parameters.
First of all, there is the center of thesubgraph, the kernel point, which can be any entityor relation in the graph.
The entities and relationsto be taken into account as kernel points are markedbeforehand as a subset of the intensional and exten-sional domain relations.
The radius r determinesthe size of the subgraphs and defines which entitiesor relations around the kernel point are taken into ac-count.
Each entity or relation that is within a numberof r edges away from the kernel point is consideredto be part of the subgraph.
The third hyperparam-eter, the distance d, determines how far apart fromeach other the kernel points can be.
Each subgrapharound a kernel point that is within a distance d orless from the current kernel point will be considered.This is captured by the relation Rr,d(Av, Bu, G) be-tween two rooted subgraphs Av, Bu and a graph G,which selects all pairs of neighborhood graphs of ra-dius r whose roots are at distance d in a given graphG.The kernel ?r,d(G,G?)
between graphs G and G?on the relation Rr,d is then defined as:?r,d(G,G?)
=?Av , Bu ?
R?1r,d(G)A?v?
, B?u?
?
R?1r,d(G?)?
(Av, A?v?)?
(Bu, B?u?
)(1)584For efficiency reasons, an upper bound is imposedon the radius and distance parameters, which leadsto the following kernel definition:Kr?,d?(G,G?)
=r??r=0d??d=0?r,d(G,G?)
(2)We hereby limit the sum of the ?r,d kernels for allincreasing values of the radius and distance parame-ter up to a maximum given value of r?, respectivelyd?.The result of this graphicalization and featuregeneration process is an extended, high-dimensionalfeature space, which serves as input for the statisti-cal learner in the next step.Learning The constructed feature space containsone feature vector per sentence.
This implies thatthe sequence information of the sentences at the doc-ument level is not taken into account yet.
Since theorder of the sentences in the abstract is a valuablefeature for this prediction problem, a learner thatreflects this in the learning process is needed, al-though in principle any statistical learner can be usedon the feature space constructed by kLog.
There-fore we opted for SVM-HMM2 (Tsochantaridis etal., 2004), which is an implementation of structuralsupport vector machines for sequence tagging.
Incontrast to a conventional Hidden Markov Model,SVM-HMM is able to take these entire feature vec-tors as observations, and not just atomic tokens.In our case, the instances to be tagged are formedby the sentences for which feature vectors were cre-ated in the previous step.
The qid is a special fea-ture that is used in the structured SVM to restrictthe generation of constraints.
Since every documentneeds to be represented as a sequence of sentences,in SVM-HMM, the qid?s are used to obtain the doc-ument structure.
The order of the HMM was setto 2, which means that the two previous sentenceswere considered for collective classification.
Thecost value was set to 500, and was determined viacross-validation.
For epsilon, the default value, 0.5,was kept, since this mainly only influences the run-ning time and memory consumption during training.2http://www.cs.cornell.edu/people/tj/svm_light/svm_hmm.htmlAll S UNb.
Abstracts 1000 376 624Nb.
Sentences 10379 4774 5605- Background 2557 669 1888- Intervention 690 313 377- Outcome 4523 2240 2283- Population 812 369 443- Study Design 233 149 84- Other 1564 1034 530Table 2: Number of abstracts and sentences for Struc-tured (S) and Unstructured (U) abstract sets, includingnumber of sentences per class (taken from (Kim et al2011)).4 EvaluationWe evaluate the performance of kLog against a base-line system and a memory-based tagger (Daelemansand van den Bosch, 2005).
The results are also com-pared against those from Kim et al2011), which isthe state-of-the-art system for this task.4.1 DatasetsWe perform our experiments on the NICTA-PIBOSO dataset from Kim et al2011) (kindly pro-vided by the authors).
It contains 1,000 abstracts ofwhich 500 were retrieved from MEDLINE by query-ing for diverse aspects in the traumatic brain injuryand spinal cord injury domain.
The dataset consistsof two types of abstracts.
If the abstract containssection headings (e.g.
Background, Methodology,Results, etc.
), it is considered to be structured.
Thisinformation can be used as a feature in the model.The other abstracts are regarded unstructured.The definitions of the semantic tags used as an-notations categories are a variation on the PICO tagset, with the addition of two additional categories(see Table 1 in Section 2).
Each sentence can be an-notated with multiple classes.
This renders the taska multiclass multilabel classification problem.
Thestatistics on this dataset can be found in Table 2.In order to apply the same evaluation setting asKim et al2011), we used the dataset from Demner-Fushman et al2005) as external dataset.
It con-sists of 100 sentences of which 51 are structured.Because the semantic tag set used for annotationslightly differs from the one presented in Table 1,and to make our results comparable, we will use thesame mapping as used in Kim et al2011).5854.2 Baseline and benchmarksWe compare the kLog system to three other systems:a baseline system, a memory-based system, and thescores reported by Kim et al2011).The memory-based system that we use is basedon the memory-based tagger MBT3 (Daelemans andvan den Bosch, 2005).
This machine learner is orig-inally designed for part-of-speech tagging.
It pro-cesses data on a sentence basis by carrying out se-quential tagging, viz.
the class label or other featuresfrom previously tagged tokens can be used whenclassifying a new token.
In our setup, the sentencesof an abstract are taken as the processing unit andthe collection of all sentences in an abstract is takenas one sequence.The features that are used to label a sentence arethe class labels of four previous sentences, the am-bitags of the following two sentences, the lemma ofthe dependency root of the sentence, the position ofthe sentence in the abstract, the lemma of the rootof the previous sentence, and section information.For each root lemma, all possible class labels, as ob-served in the training data, are concatenated into oneambitag.
These tags are stored in a list.
An am-bitag for a sentence is retrieved by looking up theroot lemma in this list.
The position of the sentenceis expressed by a number.
Section information is ob-tained by looking for a previous sentence that con-sists of only one token in uppercase.
Finally, basiclemmatization is carried out by removing a final S.All other settings of MBT are the default settingsand no feature optimization nor feature selection hasbeen carried out to prevent overfitting.When a class label contains multiple labels, likee.g.
population and study design, these labels areconcatenated in an alphabetically sorted manner.This method of working reduces the multilabel prob-lem to a problem with many different labels, i.e.
thelabel powerset method of Tsoumakas et al2010).The baseline system is exactly the same asthe memory-based system except that no machinelearner is included.
The most frequent class label inthe training data, i.e.
Outcome, is assigned to eachinstance.
The memory-based system enables us tocompare kLog against a basic machine learning ap-proach, using few features.
The majority baseline3http://ilk.uvt.nl/mbt [16 March 2012]system enables us to compare the memory-basedsystem and kLog against a baseline in which no in-formation about the observations is used.4.3 ParametrizationFrom the kernel definition it might be clear thatthe kLog hyperparameters, namely the distance dand radius r, can have a strong influence on theresults.
This requires a deliberate choice duringparametrization.
From a linguistic perspective, theuse of unigrams and bigrams is justifiable, sincemost phrases that reveal clues on the structure of theabstract (e.g.
evaluation measures, methodolody, fu-ture work) can be expressed with single or pairs ofwords.
This is reflected by a distance and radius bothset to 1, which enables to take all possible combina-tions of consecutive words into account and capturesthe relational information attached to the word in fo-cus, i.e.
the current kernel point.
This is confirmedby cross-validation on other settings for the hyper-parameters.Since kLog generates a feature vector, only thesequence information at word level is taken into ac-count by kLog.
Since we use a sequence labelingapproach as statistical learner, i.e.
SVM-HMM, atthe level of the abstract this information is howeverimplicitly taken into account during learning.
ForSVM-HMM, only the cost parameter C, which reg-ulates the trade-off between the slack and the mag-nitude of the weight-vector, and , that specifies theprecision to which constraints are required to be sat-isfied by the solution, were optimized by means ofcross-validation.
For the other parameters, the de-fault values were used.4.4 ResultsExperiments are run on structured and unstructuredabstracts separately.
On the NICTA-PIBOSO cor-pus, we performed 10-fold cross-validation.
Overall folds, all labels, i.e.
the parts of the multilabels,are compared in a binary way between gold standardand prediction.
Summing all true positives, falsepositives, and false negatives over all folds leads tomicro-averaged F-scores.
This was done for two dif-ferent settings.
In one setting, CV/6-way, we com-bined the labeling of the sentences with the identifi-cation of irrelevant information, by adding the Other586label as an extra class in the classification.
The re-sults are listed in Table 3.CV/6-way MBT Kim et alLogLabel S U S U S UBackground 71.0 61.3 81.84 68.46 86.19 76.90Intervention 24.3 6.4 20.25 12.68 26.05 16.14Outcome 87.9 70.4 92.32 72.94 92.99 77.69Population 50.6 15.9 56.25 39.80 35.62 21.58Study Design 45.9 13.10 43.95 4.40 45.5 6.67Other 86.1 20.9 69.98 24.28 87.98 24.42Table 3: F-scores per class for structured (S) and unstruc-tured (U) abstracts.For this setting, kLog is able to outperform bothMBT and the system of Kim et al2011), for bothstructured and unstructured abstracts on all classesexcept Population.
From Table 4, where the micro-average F-scores over all classes and for all settingsare listed, it can be observed that kLog performs upto 3.73% better than MBT over structured abstracts,and 9.67% better over unstructured ones.Although to a lesser extent for the structured ab-stracts, the same pattern can be observed for theCV/5-way setting, where we tried to classify the sen-tences only, without considering the irrelevant ones.The per-class results for this setting are shown in Ta-ble 5.
Now the scores for Population are comparableto the other systems, due to which we assume thesesentences are similar in structure to the ones labeledwith Other.For the external corpus, the results are listed in Ta-ble 6.
Although kLog performs comparably for theindividual classes Background and Intervention, itsoverall performance is worse on the structured ab-stracts.
In case of the unstructured abstracts, kLogperforms better on the majority of the individualclasses and in overall performance for the 5-way set-ting, and comparable for the 4-way setting.Baseline MBT kLogMethod S U S U S UCV/6-way 43.90 41.87 80.56 57.47 84.29 67.14CV/5-way 61.79 46.66 86.96 64.37 87.67 72.95Ext/5-way 66.18 6.76 36.34 11.56 20.50 14.00Ext/4-way 30.11 27.23 67.29 55.96 50.40 50.50Table 4: Micro-averaged F1-score obtained for structured(S) and unstructured (U) abstracts, both for 10-fold cross-validation (CV) and on the external corpus (Ext).CV/5-way MBT Kim et alLogLabel S U S U S UBackground 87.1 64.9 87.92 70.67 91.45 80.06Intervention 48.0 6.9 48.08 21.39 45.58 22.65Outcome 95.8 75.9 96.03 80.51 96.21 83.04Population 70.9 21.4 63.88 43.15 63.96 23.32Study Design 50.0 7.4 47.44 8.6 48.08 4.50Table 5: F-scores per class for 5-way classification overstructured (S) and unstructured (U) abstracts.MBT Kim et alLogLabel S U S U S UExt/5-wayBackground 58.9 15.7 56.18 15.67 58.30 29.10Intervention 21.5 13.8 15.38 28.57 40.00 34.30Outcome 29.3 17.8 81.34 60.45 27.80 24.10Population 10.7 17.8 35.62 28.07 5.60 28.60Other 40.7 3.5 46.32 15.77 11.40 8.50Ext/4-wayBackground 90.4 67.5 77.27 37.5 65 68.6Intervention 29 23.1 28.17 8.33 28.1 32.3Outcome 74.1 74.6 90.5 78.77 72.4 72.7Population 48.7 23.8 42.86 28.57 11.8 15.4Table 6: F-scores per class for 5-way and 4-way classifi-cation over structured (S) and unstructured (U) abstractson the external corpus.As a general observation, it is important to notethat there is a high variability between the differentlabels.
Due to kLog?s ability to take the structuredinput into account, we assume a correlation betweenthe sentence structure of the label and the predic-tion quality.
We intend to perform an extensive erroranalysis, in order to detect patterns which may allowus to incorporate additional declarative backgroundknowledge into our model.5 ConclusionsWe presented a statistical relational learning ap-proach for the automatic identification of PICO cat-egories in medical abstracts.
To this extent, we usedkLog, a new framework for logical and relationallearning with kernels.
Due to its graphical approach,it is able to exploit the full relational representation,that is often inherent in language structure.
Sincecontextual features are often essential and relationsare prevalent, the aim of this paper was to showthat statistical relational learning in general, and thegraph kernel-based approach of kLog in particular,is specifically suited for problems in natural lan-587guage learning.In future work, we intend to explore additionalways to incorporate background knowledge in adeclarative way, since it renders the language learn-ing problem more intuitive and gives a better under-standing of feature contribution.
Furthermore, wealso want to investigate the use of SRL approachesfor high-relational domains, and make a clear com-parison with related techniques.6 AcknowledgementsThis research is funded by the Research FoundationFlanders (FWO project G.0478.10 - Statistical Re-lational Learning of Natural Language), and madepossible through financial support from the KU Leu-ven Research Fund (GOA project 2008/08 Proba-bilistic Logic Learning), the University of Antwerp(GOA project BIOGRAPH) and the Italian Min-istry of Education, University, and Research (PRINproject 2009LNP494 - Statistical Relational Learn-ing: Algorithms and Applications).
The authorswould like to thank Fabrizio Costa, Kurt De Graveand the anonymous reviewers for their valuablefeedback.ReferencesShashank Agarwal and Hong Yu.
2009.
AutomaticallyClassifying Sentences in Full-text Biomedical Articlesinto Introduction, Methods, Results and Discussion.Bioinformatics, 25(23):3174?3180.E.
C. Armstrong.
1999.
The Well-built Clinical Ques-tion: the Key to Finding the Best Evidence Efficiently.WMJ, 98(2):25?28.Olivier Bodenreider.
2004.
The Unified MedicalLanguage System (UMLS): Integrating Biomed-ical Terminology.
Nucleic Acids Research,32(Suppl.1):D267?D270.Grace Y Chung.
2009.
Sentence Retrieval for Abstractsof Randomized Controlled Trials.
BMC Medical In-formatics and Decision Making, 9(10).Fabrizio Costa and Kurt De Grave.
2010.
Fast Neighbor-hood Subgraph Pairwise Distance Kernel.
Proceed-ings of the 26th International Conference on MachineLearning, 255?262, Haifa, Israel.
Omnipress.Walter Daelemans and Antal van den Bosch.
2005.Memory-Based Language Processing.. Studies inNatural Language Processing.
Cambridge UniversityPress, Cambridge, UK.P.
Davis-Desmond and Diego Molla?.
2012.
Detection ofEvidence in Clinical Research Papers.
Proceedings ofthe Australasian Workshop On Health Informatics andKnowledge Management (HIKM 2012), Melbourne,Australia, 129:13?20.
Australian Computer Society,Inc.Dina Demner-Fushman, Barbara Few, Susan E. Hauser,and George Thoma.
2005.
Automatically IdentifyingHealth Outcome Information in MEDLINE Records.Journal of the American Medical Informatics Associa-tion (JAMIA), 13:52?60.Dina Demner-Fushman and Jimmy Lin.
2007.
An-swering Clinical Questions with Knowledge Basedand Statistical Techniques.
Computational Linguis-tics, 33(1):63?103.Luc De Raedt, Paolo Frasconi, Kristian Kersting, andStephen Muggleton, editors.
2008.
Probabilistic In-ductive Logic Programming.
In: Lecture Notes inComputer Science (LNCS), 4911.
Springer-Verlag,Heidelberg, Germany.Paolo Frasconi, Fabrizio Costa, Luc De Raedt, andKurt De Grave.
2012. kLog - a Languagefor Logical and Relational Learning with Kernels.arXiv:1205.3981v2.Hector Garcia-Molina, Jeff Ullman, and Jennifer Widom.2008.
Database Systems: The Complete Book.
Pren-tice Hall Press, Englewood Cliffs, NJ, USA.Lise Getoor and Ben Taskar.
2007.
Introduction to Sta-tistical Relational Learning (Adaptive Computationand Machine Learning).
The MIT Press, Cambridge,MA, USA.David Haussler.
1999.
Convolution kernels on discretestructures.
Technical report (UCSC-CRL-99-10), Uni-versity of California at Santa Cruz.Su Nam Kim, David Martinez, Lawrence Cavedon, andLars Yencken.
2011.
Automatic Classification of Sen-tences to Support Evidence Based Medicine.
BMCBioinformatics, 12(2):S5.Donald E. Knuth.
1965.
On the Translation of Lan-guages from Left to Right.
Information and Control,8: 607?639.Y.
Mizuta, A. Korhonen, T. Mullen, and N. Collier.2006.
Zone Analysis in Biology Articles as a Basisfor Information Extraction.
International Journal ofMedical Informatics, 75(6):468?487.Diego Molla?
and Mara Elena Santiago-Mart??nez.
2011.Development of a Corpus for Evidence MedicineSummarisation.
Proceedings of the 2011 AustralasianLanguage Technology Workshop (ALTA 2011), Can-berra, Australia, 86?94.
Association for Computa-tional Linguistics.Yun Niu, Graeme Hirst, Gregory McArthur, and Patri-cia Rodriguez-Gianolli.
2003.
Answering Clinical588Questions with Role Identification.
Proceedings of theACL, Workshop on Natural Language Processing inBiomedicine.
Sapporo, Japan, 73?80.
Association forComputational Linguistics.Hoifung Poon and Pedro Domingos.
2008.
Joint un-supervised coreference resolution with Markov logic.Proceedings of the Conference on Empirical Methodsin Natural Language Processing (EMNLP 2008.
Hon-olulu, Hawaii, 650?659.
Association for Computa-tional Linguistics.Sampo Pyysalo, Filip Ginter, Juho Heimonen, JariBjo?rne, Jorma Boberg, Jouni Ja?rvinen, and TapioSalakoski.
2007.
BioInfer: a Corpus for InformationExtraction in the Biomedical Domain.
BMC Bioinfor-matics, 8:50.Sebastian Riedel and Ivan Meza-Ruiz.
2008.
Collectivesemantic role labelling with Markov logic.
Proceed-ings of the Twelfth Conference on Computational Nat-ural Language Learning (CoNLL 2008.
Manchester,United Kingdom, 193?197.
Association for Computa-tional Linguistics.William Rosenberg and Anna Donald.
1995.
EvidenceBased Medicine: an Approach to Clinical ProblemSolving.
British Medical Journal, 310(6987):1122?1126.Kenji Sagae and Jun?ichi Tsujii.
2007.
DependencyParsing and Domain Adaptation with LR Models andParser Ensembles.
Proceedings of the CoNLL SharedTask Session of EMNLP-CoNLL 2007, Prague, CzechRepublic, 1044?1050.
Association for ComputationalLinguistics.Ioannis Tsochantaridis, Thomas Hofmann, ThorstenJoachims, and Yasemin Altun.
2004.
Support VectorMachine Learning for Interdependent and StructuredOutput Spaces.
Proceedings of the twenty-first inter-national conference on Machine learning (ICML), Al-berta, Canada, 104?111.
ACM.Grigorios Tsoumakas and Ioannis Katakis and Ioannis P.Vlahavas.
Oded Maimon and Lior Rokach, editors.2010.
Mining Multi-label Data.
In: Data Mining andKnowledge Discovery Handbook, 2nd ed., 667?685.Springer-Verlag, Heidelberg, Germany.Mathias Verbeke, Paolo Frasconi, Vincent Van Asch,Roser Morante, Walter Daelemans, and Luc De Raedt.2012.
Kernel-based Logical and Relational Learningwith kLog for Hedge Cue Detection.
Proceedings ofthe 21th International Conference on Inductive LogicProgramming, in press.589
