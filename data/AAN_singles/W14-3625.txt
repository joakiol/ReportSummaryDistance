Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 180?186,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsArabic Native Language IdentificationShervin MalmasiCentre for Language TechnologyMacquarie UniversitySydney, NSW, Australiashervin.malmasi@mq.edu.auMark DrasCentre for Language TechnologyMacquarie UniversitySydney, NSW, Australiamark.dras@mq.edu.auAbstractIn this paper we present the first appli-cation of Native Language Identification(NLI) to Arabic learner data.
NLI, the taskof predicting a writer?s first language fromtheir writing in other languages has beenmostly investigated with English data, butis now expanding to other languages.
Weuse L2 texts from the newly released Ara-bic Learner Corpus and with a combina-tion of three syntactic features (CFG pro-duction rules, Arabic function words andPart-of-Speech n-grams), we demonstratethat they are useful for this task.
Our sys-tem achieves an accuracy of 41% againsta baseline of 23%, providing the first evi-dence for classifier-based detection of lan-guage transfer effects in L2 Arabic.
Suchmethods can be useful for studying lan-guage transfer, developing teaching mate-rials tailored to students?
native languageand forensic linguistics.
Future directionsare discussed.1 IntroductionResearchers in Second Language Acquisition(SLA) investigate the multiplex of factors thatinfluence our ability to acquire new languagesand chief among these factors is the role of thelearner?s mother tongue.
Recently this fundamen-tal factor has been studied in Native LanguageIdentification (NLI), which aims to infer the nativelanguage (L1) of an author based on texts writ-ten in a second language (L2).
Machine Learningmethods are usually used to identify language usepatterns common to speakers of the same L1.The motivations for NLI are manifold.
The useof such techniques can help SLA researchers iden-tify important L1-specific learning and teachingissues.
In turn, the identification of such issues canenable researchers to develop pedagogical mate-rial that takes into consideration a learner?s L1 andaddresses them.
It can also be applied in a forensiccontext, for example, to glean information aboutthe discriminant L1 cues in an anonymous text.While almost all NLI research to date has fo-cused on English L2 data, there is a growing needto apply the techniques to other language in or-der to assess the cross-language applicability.
Thisneed is partially driven by the increasing numberof learners of various other languages.One such case is the teaching of Arabic as aForeign Language, which has experienced unpar-alleled growth in the past two decades.
For a longtime the teaching of Arabic was not considered apriority, but this view has now changed.
Arabic isnow perceived as a critical and strategically use-ful language (Ryding, 2013), with enrolments ris-ing rapidly and already at an all time high (Wahbaet al., 2013).
This trend is also reflected in theNLP community, evidenced by the continuouslyincreasing research focus on Arabic tools and re-sources (Habash, 2010).A key objective of this study is to investigatethe efficacy of syntactic features for Arabic, a lan-guage which is significantly different to English.Arabic orthography is very different to Englishwith right-to-left text that uses connective letters.Moreover, this is further complicated due to thepresence of word elongation, common ligatures,zero-width diacritics and allographic variants.
Themorphology of Arabic is also quite rich with manymorphemes that can appear as prefixes, suffixes oreven circumfixes.
These mark grammatical infor-mation including case, number, gender, and defi-niteness amongst others.
This leads to a sophisti-cated morphotactic system.Given the aforementioned differences with En-glish, the main objective of this study is to deter-mine if NLI techniques can be effective for detect-ing L1 transfer effects in L2 Arabic.1802 BackgroundNLI has drawn the attention of many researchersin recent years.
With the influx of new researchers,the most substantive work in this field has comein the last few years, leading to the organizationof the inaugural NLI Shared Task in 2013 whichwas attended by 29 teams from the NLP and SLAareas.
A detailed exposition of the shared task re-sults and a review of prior NLI work can be foundin Tetreault et al.
(2013).While there exists a large body of literature pro-duced in the last decade, almost all of this workhas focused exclusively on L2 English.
The mostrecent work in this field successfully presentedthe first application of NLI to a large non-Englishdataset (Malmasi and Dras, 2014a), evidencing theusefulness of syntactic features in distinguishingL2 Chinese texts.3 DataAlthough the majority of currently availablelearner corpora are based on English L2 (Granger,2012), data from learners of other languages suchas Chinese have also attracted attention in the pastseveral years.No Arabic learner corpora were available for along time.
This paucity of data has been noted byresearchers (Abuhakema et al., 2008; Zaghouaniet al., 2014) and is thought to be due to issues suchas difficulties with non-Latin script and a lack oflinguistic and NLP software to work with the data.More recently, the first version of the ArabicLearner Corpus1(ALC) was released by Alfaifiand Atwell (2013).
The corpus includes texts byArabic learners studying in Saudi Arabia, mostlytimed essays written in class.
In total, 66 differentL1 backgrounds are represented.
While texts bynative Arabic speakers studying to improve theirwriting are also included, we do not utilize these.We use the more recent second version of theALC (Alfaifi et al., 2014) as the data for our exper-iments.
While there are 66 different L1s in the cor-pus, the majority of these have less than 10 textsand cannot reliably be used for NLI.
Instead weuse a subset of the corpus consisting of the topseven native languages by number of texts.
Thelanguages and document counts in each class areshown in Table 1.Both plain text and XML versions of the learner1http://www.arabiclearnercorpus.com/Native Language TextsChinese 76Urdu 64Malay 46French 44Fulani 36English 35Yoruba 28Total 329Table 1: The L1 classes included in this experi-ment and the number of texts within each class.texts are provided with the corpus.
Here we usetext versions and strip the metadata informationfrom the files, leaving only the author?s writings.4 Experimental MethodologyIn this study we employ a supervised multi-classclassification approach.
The learner texts are or-ganized into classes according on the author?s L1and these documents are used for training and test-ing in our experiments.
A diagram conceptualiz-ing our NLI system is shown in Figure 1.4.1 Word SegmentationThe tokenization and word segmentation of Arabicis an important preprocessing step for addressingthe orthographic issues discussed in ?1.
For thistask we utilize the Stanford Word Segmenter2.4.2 Parsing and Part-of-Speech TaggingTo extract the syntactic information required forour models, the Arabic texts are POS tagged andparsed using the Stanford Arabic Parser3.4.3 ClassifierWe use a linear Support Vector Machine to per-form multi-class classification in our experiments.In particular, we use the LIBLINEAR4package(Fan et al., 2008) which has been shown to be effi-cient for text classification problems such as this.4.4 Evaluation MethodologyIn the same manner as many previous NLI stud-ies and also the NLI 2013 shared task, we reportour results as classification accuracy under k-foldcross-validation, with k = 10.
In recent years this2http://nlp.stanford.edu/software/segmenter.shtml3http://nlp.stanford.edu/projects/arabic.shtml4http://www.csie.ntu.edu.tw/%7Ecjlin/liblinear/181Arabic Text Chinese L1NLIArabic TextArabic TextArabic TextFrench L1English L1Malay L1Figure 1: Illustration of our NLI system that identifies the L1 of Arabic learners from their writing.has become a de facto standard for reporting NLIresults.5 ExperimentsWe experiment using three syntactic feature typesdescribed in this section.
As the ALC is not bal-anced for topic, we do not consider the use of lex-ical features such as word n-grams in this study.Topic bias can occur as a result of the subject mat-ters or topics of the texts to be classified not notevenly distributed across the classes.
For exam-ple, if in our training data all the texts written byEnglish L1 speakers are on topic A, while all theFrench L1 authors write about topic B, then wehave implicitly trained our classifier on the topicsas well.
In this case the classifier learns to dis-tinguish our target variable through another con-founding variable.5.1 Context-free Grammar Production RulesContext-free phrase structure rules (without lexi-calizations) are extracted from parse trees of thesentences in each learner text.
One such con-stituent parse tree and extracted rules are shownin Figure 2.
These production rules are used asclassification features5.
Linguistically, they cap-ture the global syntactic structures used by writers.5.2 Arabic Function WordsThe distributions of grammatical function wordssuch as determiners and auxiliary verbs haveproven to be useful in NLI.
This is considered tobe a useful syntactic feature as these words indi-cate the relations between content words and are5All models use relative frequency feature representations?????
??
??????
????
??
????
???
??
???????
??????
??
????
?????????????
??
?????
???
?.DTNN IN NN DTNN PRP VBD VBP IN VBN DTNN IN NN DTNN CC NN PRP$ IN NN JJ PUNCFigure 3: An example of a sentence written by alearner and its Part-of-Speech tag sequence.
Un-igrams, bigrams and trigrams are then extractedfrom this tag sequence.topic independent.
The frequency distributions ofa set of 150 function words were extracted fromthe learner texts and used as features in this model.5.3 Part-of-Speech n-gramsIn this model POS n-grams of size 1?3 were ex-tracted.
These n-grams capture small and very lo-cal syntactic patterns of language production andwere used as classification features.6 ResultsThe results from all experiments are shown in Ta-ble 2.
The majority baseline is calculated by us-ing the largest class, in this case Chinese6, asthe default classification.
The frequency distri-butions of the production rules yield 31.7% accu-racy, demonstrating their ability to identify struc-tures that are characteristic of L1 groups.
Simi-larly, the distribution of function words is helpful,with 29.2% accuracy.While all the models provide results well abovethe baseline, POS tag n-grams are the most usefulfeatures, with bigrams providing the highest accu-racy for a single feature type with 37.6%.
This676/329 = 23.1%182The options for nodes are all handled by TikZ and are described in detailin the TikZ documentation.
For example, if you have a font named \ar andwant to set all the leaf labels in this font:.ROOT.S ..PUNC....S ..VP ..NP ..NP.NN.??????..CD.200..VBD.???
?..NP ..NP.PRP$.??..NN.???..CC.
?..S ..VP ..NP ..NP ..PP ..NP.DTNN.??????..IN.??
..NP.NN.?????..NN.??..VBD.????
..NP.NNP.?????..CC.
?1S ?
S CC S PUNC VP ?
VBD NPNP ?
DTNN PP ?
IN NPFigure 2: A constituent parse tree for a sentence from the corpus along with some of the context-freegrammar production rules extracted from it.Feature Accuracy (%)Majority Baseline 23.1CFG Production Rules 31.7Function Words 29.2Part-of-Speech unigrams 36.0Part-of-Speech bigrams 37.6Part-of-Speech trigrams 36.5All features combined 41.0Table 2: Arabic Native Language Identificationaccuracy for the three experiments in this study.seems to suggest that the greatest difference be-tween groups lies in their word category ordering.Combining all of the models into a single fea-ture space provides the highest accuracy of 41%.This demonstrates that the information capturedby the various models is complementary and thatthe feature types are not redundant.7 DiscussionThe most prominent finding here is that NLI tech-niques can be successfully applied to Arabic, amorphologically complex language differing sig-nificantly from English, which has been the focusof almost all previous research.This is one of the very first applications of NLIto a language other than English and an importantstep in the growing field of NLI, particularly withthe current drive to investigate other languages.This research, though preliminary, presents an ap-proach to Arabic NLI and can serve as a step to-wards further research in this area.NLI technology has practical applications invarious fields.
One potential application of NLIis in the field of forensic linguistics (Gibbons,2003; Coulthard and Johnson, 2007), a juncturewhere the legal system and linguistic stylisticsintersect (Gibbons and Prakasam, 2004; McMe-namin, 2002).
In this context NLI can be used as atool for Authorship Profiling (Grant, 2007) in or-der to provide evidence about the linguistic back-ground of an author.There are a number of situations where a text,such as an anonymous letter, is the central piece ofevidence in an investigation.
The ability to extractadditional information from an anonymous textcan enable the authorities and intelligence agen-cies to learn more about threats and those respon-sible for them.
Clues about the native languageof a writer can help investigators in determiningthe source of anonymous text and the importanceof this analysis is often bolstered by the fact that insuch scenarios, the only data available to users andinvestigators is the text itself.
One recently studiedexample is the analysis of extremist related activ-ity on the web (Abbasi and Chen, 2005).Accordingly, we can see that from a forensicpoint of view, NLI can be a useful tool for intel-ligence and law enforcement agencies.
In fact, re-cent NLI research such as that related to the workpresented by (Perkins, 2014) has already attracted183interest and funding from intelligence agencies(Perkins, 2014, p. 17).In addition to applications in forensic linguis-tics, Arabic NLI can aid the development of re-search tools for SLA researchers investigating lan-guage transfer and cross-linguistic effects.
Simi-lar data-driven methods have been recently appliedto generate potential language transfer hypothe-ses from the writings of English learners (Malmasiand Dras, 2014c).
With the use of an error anno-tated corpus, which was not the case in this study,the annotations could be used in conjunction withsimilar linguistic features to study the syntacticcontexts in which different error types occur (Mal-masi and Dras, 2014b).Results from such approaches could be usedto create teaching material that is customized forthe learner?s L1.
This approach has been pre-viously shown to yield learning improvements(Laufer and Girsai, 2008).
The need for suchSLA tools is particularly salient for a complex lan-guage such as Arabic which has several learningstages (Mansouri, 2005), such as phrasal and inter-phrasal agreement morphology, which are hierar-chical and generally acquired in a specific order(Nielsen, 1997).The key shortcoming of this study, albeit be-yond our control, is the limited amount of dataavailable for the experiments.
To the best of ourknowledge, this is the smallest dataset used for thistask in terms of document count and length.
In thisregard, we are surprised by relatively high classifi-cation accuracy of our system, given the restrictedamount of training data available.While it is hard to make comparisons withmost other experiments due to differing numberof classes, one comparable study is that of Wongand Dras (2009) which used some similar featureson 7-class English dataset.
Despite their use ofa much larger dataset7, our individual models areonly around 10% lower in accuracy.We believe that this is a good result, givenour limited data.
In their study of NLI corpora,Brooke and Hirst (2011) showed that increasingthe amount of training data makes a very signifi-cant difference in NLI accuracy for both syntacticand lexical features.
This was verified by Tetreaultet al.
(2012) who showed that there is a very steeprise in accuracy as the corpus size is increased to-7Wong and Dras (2009) had 110 texts per class, with av-erage text lengths of more than 600 words.wards 11,000 texts8.
Based on this, we are con-fident that given similarly sized training data, anArabic NLI system can achieve similar accuracies.On a broader level, this highlights the need formore large-scale L2 Arabic corpora.Future work includes the application of ourmethods to large-scale Arabic learner data as it be-comes available.
With the ongoing developmentof the Arabic Learner Corpus and other projectslike the Qatar Arabic Language Bank (Mohit,2013), this may happen in the very near future.The application of more linguistically sophisti-cated features also merits further investigation, butthis is limited by the availability of Arabic NLPtools and resources.
From a machine learning per-spective, classifier ensembles have been recentlyused for this task and shown to improve classifi-cation accuracy (Malmasi et al., 2013; Tetreault etal., 2012).
Their application here could also in-crease system accuracy.We also leave the task of interpreting the lin-guistic features that differentiate and characterizeL1s to future work.
This seems to be the next log-ical phase in NLI research and some methods toautomate the detection of language transfer fea-tures have been recently proposed (Swanson andCharniak, 2014; Malmasi and Dras, 2014c).
Thisresearch, however, is still at an early stage andcould benefit from the addition of more sophisti-cated machine learning techniques.More broadly, additional NLI experiments withdifferent languages are needed.
Comparative stud-ies using equivalent syntactic features but with dis-tinct L1-L2 pairs can help us better understandCross-Linguistic Influence and its manifestations.Such a framework could also help us better un-derstand the differences between different L1-L2language pairs.8 ConclusionIn this work we identified the appropriate data andtools to perform Arabic NLI and demonstrated thatsyntactic features can be successfully applied, de-spite a scarcity of available L2 Arabic data.
Suchtechniques can be used to generate cross-linguistichypotheses and build research tools for ArabicSLA.
As the first machine learning based inves-tigation of language transfer effects in L2 Ara-bic, this work contributes important additional ev-idence to the growing body of NLI work.8Equivalent to 1000 texts per L1 class.184ReferencesAhmed Abbasi and Hsinchun Chen.
2005.
Applyingauthorship analysis to extremist-group Web forummessages.
IEEE Intelligent Systems, 20(5):67?75.Ghazi Abuhakema, Reem Faraj, Anna Feldman, andEileen Fitzpatrick.
2008.
Annotating an ArabicLearner Corpus for Error.
In LREC.Abdullah Alfaifi and Eric Atwell.
2013.
ArabicLearner Corpus v1: A New Resource for ArabicLanguage Research.Abdullah Alfaifi, Eric Atwell, and I Hedaya.
2014.Arabic learner corpus (ALC) v2: a new written andspoken corpus of Arabic learners.
In Proceedings ofthe Learner Corpus Studies in Asia and the World(LCSAW), Kobe, Japan.Julian Brooke and Graeme Hirst.
2011.
Na-tive language detection with ?cheap?
learner cor-pora.
In Conference of Learner Corpus Research(LCR2011), Louvain-la-Neuve, Belgium.
Pressesuniversitaires de Louvain.Malcolm Coulthard and Alison Johnson.
2007.
An in-troduction to Forensic Linguistics: Language in evi-dence.
Routledge.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.John Gibbons and Venn Prakasam.
2004.
Language inthe Law.
Orient Blackswan.John Gibbons.
2003.
Forensic Linguistics: An Intro-duction To Language In The Justice System.Sylviane Granger.
2012.
Learner corpora.
The Ency-clopedia of Applied Linguistics.Tim Grant.
2007.
Quantifying evidence in forensicauthorship analysis.
International Journal of SpeechLanguage and the Law, 14(1):1?25.Nizar Y Habash.
2010.
Introduction to Arabic naturallanguage processing.
Synthesis Lectures on HumanLanguage Technologies, 3(1):1?187.Batia Laufer and Nany Girsai.
2008.
Form-focusedinstruction in second language vocabulary learning:A case for contrastive analysis and translation.
Ap-plied Linguistics, 29(4):694?716.Shervin Malmasi and Mark Dras.
2014a.
ChineseNative Language Identification.
Proceedings of the14th Conference of the European Chapter of the As-sociation for Computational Linguistics.Shervin Malmasi and Mark Dras.
2014b.
From Vi-sualisation to Hypothesis Construction for SecondLanguage Acquisition.
In Graph-Based Methods forNatural Language Processing, Doha, Qatar, Octo-ber.
Association for Computational Linguistics.Shervin Malmasi and Mark Dras.
2014c.
LanguageTransfer Hypotheses with Linear SVM Weights.Proceedings of the 2014 Conference on Empir-ical Methods in Natural Language Processing(EMNLP).Shervin Malmasi, Sze-Meng Jojo Wong, and MarkDras.
2013.
Nli shared task 2013: Mq submission.In Proceedings of the Eighth Workshop on Innova-tive Use of NLP for Building Educational Applica-tions, pages 124?133, Atlanta, Georgia, June.
Asso-ciation for Computational Linguistics.Fethi Mansouri.
2005.
Agreement morphology in Ara-bic as a second language.
Cross-linguistic aspects ofProcessability Theory, pages 117?253.Gerald R McMenamin.
2002.
Forensic linguistics:Advances in Forensic Stylistics.
CRC press.Behrang Mohit.
2013.
QALB: Qatar Arabic languagebank.
In Qatar Foundation Annual Research Con-ference, number 2013.Helle Lykke Nielsen.
1997.
On acquisition order ofagreement procedures in Arabic learner language.Al-Arabiyya, 30:49?93.Ria Perkins.
2014.
Linguistic identifiers of L1 Persianspeakers writing in English: NLID for authorshipanalysis.
Ph.D. thesis, Aston University.Karin C. Ryding.
2013.
Teaching Arabic in the UnitedStates.
In Kassem M Wahba, Zeinab A Taha, andLiz England, editors, Handbook for Arabic languageteaching professionals in the 21st century.
Rout-ledge.Ben Swanson and Eugene Charniak.
2014.
DataDriven Language Transfer Hypotheses.
EACL 2014,page 169.Joel Tetreault, Daniel Blanchard, Aoife Cahill, BeataBeigman-Klebanov, and Martin Chodorow.
2012.Native Tongues, Lost and Found: Resources andEmpirical Evaluations in Native Language Identifi-cation.
In Proc.
Internat.
Conf.
on Computat.
Lin-guistics (COLING).Joel Tetreault, Daniel Blanchard, and Aoife Cahill.2013.
A report on the first native language identi-fication shared task.
In Proceedings of the EighthWorkshop on Innovative Use of NLP for Build-ing Educational Applications, pages 48?57, Atlanta,Georgia, June.
Association for Computational Lin-guistics.Kassem M Wahba, Zeinab A Taha, and Liz England.2013.
Handbook for Arabic language teaching pro-fessionals in the 21st century.
Routledge.Sze-Meng Jojo Wong and Mark Dras.
2009.
Con-trastive analysis and native language identification.In Proc.
Australasian Language Technology Work-shop (ALTA), pages 53?61.185Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-sama Obeid, Nadi Tomeh, Alla Rozovskaya, NouraFarra, Sarah Alkuhlani, and Kemal Oflazer.
2014.Large Scale Arabic Error Annotation: Guidelinesand Framework.
In Nicoletta Calzolari (ConferenceChair), Khalid Choukri, Thierry Declerck, HrafnLoftsson, Bente Maegaard, Joseph Mariani, Asun-cion Moreno, Jan Odijk, and Stelios Piperidis, ed-itors, Proceedings of the Ninth International Con-ference on Language Resources and Evaluation(LREC?14), Reykjavik, Iceland, may.
EuropeanLanguage Resources Association (ELRA).186
