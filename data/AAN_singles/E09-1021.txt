Proceedings of the 12th Conference of the European Chapter of the ACL, pages 175?183,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsTranslation and Extension of Concepts Across LanguagesDmitry DavidovICNCThe Hebrew University of Jerusalemdmitry@alice.nc.huji.ac.ilAri RappoportInstitute of Computer ScienceThe Hebrew University of Jerusalemarir@cs.huji.ac.ilAbstractWe present a method which, given a fewwords defining a concept in some lan-guage, retrieves, disambiguates and ex-tends corresponding terms that define asimilar concept in another specified lan-guage.
This can be very useful forcross-lingual information retrieval and thepreparation of multi-lingual lexical re-sources.
We automatically obtain termtranslations from multilingual dictionariesand disambiguate them using web counts.We then retrieve web snippets with co-occurring translations, and discover ad-ditional concept terms from these snip-pets.
Our term discovery is based on co-appearance of similar words in symmetricpatterns.
We evaluate our method on a setof language pairs involving 45 languages,including combinations of very dissimilarones such as Russian, Chinese, and He-brew for various concepts.
We assess thequality of the retrieved sets using both hu-man judgments and automatically compar-ing the obtained categories to correspond-ing English WordNet synsets.1 IntroductionNumerous NLP tasks utilize lexical databases thatincorporate concepts (or word categories): setsof terms that share a significant aspect of theirmeanings (e.g., terms denoting types of food, toolnames, etc).
These sets are useful by themselvesfor improvement of thesauri and dictionaries, andthey are also utilized in various applications in-cluding textual entailment and question answer-ing.
Manual development of lexical databases islabor intensive, error prone, and susceptible toarbitrary human decisions.
While databases likeWordNet (WN) are invaluable for NLP, for someapplications any offline resource would not be ex-tensive enough.
Frequently, an application re-quires data on some very specific topic or on veryrecent news-related events.
In these cases evenhuge and ever-growing resources like Wikipediamay provide insufficient coverage.
Hence appli-cations turn to Web-based on-demand queries toobtain the desired data.The majority of web pages are written in En-glish and a few other salient languages, hencemost of the web-based information retrieval stud-ies are done on these languages.
However, dueto the substantial growth of the multilingual web1,queries can be performed and the required infor-mation can be found in less common languages,while the query language frequently does notmatch the language of available information.Thus, if we are looking for information aboutsome lexical category where terms are given ina relatively uncommon language such as Hebrew,it is likely to find more detailed information andmore category instances in a salient language suchas English.
To obtain such information, we needto discover a word list that represents the desiredcategory in English.
This list can be used, for in-stance, in subsequent focused search in order toobtain pages relevant for the given category.
Thusgiven a few Hebrew words as a description forsome category, it can be useful to obtain a simi-lar (and probably more extended) set of Englishwords representing the same category.In addition, when exploring some lexical cate-gory in a common language such as English, it is1http://www.internetworldstats.com/stats7.htm175frequently desired to consider available resourcesfrom different countries.
Such resources are likelyto be written in languages different from English.In order to obtain such resources, as before, itwould be beneficial, given a concept definition inEnglish, to obtain word lists denoting the sameconcept in different languages.
In both cases aconcept as a set of words should be translated as awhole from one language to another.In this paper we present an algorithm that givena concept defined as a set of words in some sourcelanguage discovers and extends a similar set insome specified target language.
Our approachcomprises three main stages.
First, given a fewterms, we obtain sets of their translations to the tar-get language from multilingual dictionaries, anduse web counts to select the appropriate wordsenses.
Next, we retrieve search engine snippetswith the translated terms and extract symmetricpatterns that connect these terms.
Finally, we usethese patterns to extend the translated concept, byobtaining more terms from the snippets.We performed thorough evaluation for variousconcepts involving 45 languages.
The obtainedcategories were manually verified with two humanjudges and, when appropriate, automatically com-pared to corresponding English WN synsets.
Inall tested cases we discovered dozens of conceptterms with state-of-the-art precision.Our major contribution is a novel framework forconcept translation across languages.
This frame-work utilizes web queries together with dictio-naries for translation, disambiguation and exten-sion of given terms.
While our framework relieson the existence of multilingual dictionaries, weshow that even with basic 1000 word dictionarieswe achieve good performance.
Modest time anddata requirements allow the incorporation of ourmethod in practical applications.In Section 2 we discuss related work, Section 3details the algorithm, Section 4 describes the eval-uation protocol and Section 5 presents our results.2 Related workSubstantial efforts have been recently made tomanually construct and interconnect WN-likedatabases for different languages (Pease et al,2008; Charoenporn et al, 2007).
Some stud-ies (e.g., (Amasyali, 2005)) use semi-automatedmethods based on language-specific heuristics anddictionaries.At the same time, much work has been doneon automatic lexical acquisition, and in particu-lar, on the acquisition of concepts.
The two mainalgorithmic approaches are pattern-based discov-ery, and clustering of context feature vectors.
Thelatter represents word contexts as vectors in somespace and use similarity measures and automaticclustering in that space (Deerwester et al, 1990).Pereira (1993), Curran (2002) and Lin (1998) usesyntactic features in the vector definition.
(Panteland Lin, 2002) improves on the latter by cluster-ing by committee.
Caraballo (1999) uses conjunc-tion and appositive annotations in the vector rep-resentation.
While a great effort has focused onimproving the computational complexity of thesemethods (Gorman and Curran, 2006), they still re-main data and computation intensive.The current major algorithmic approach forconcept acquisition is to use lexico-syntactic pat-terns.
Patterns have been shown to produce moreaccurate results than feature vectors, at a lowercomputational cost on large corpora (Pantel et al,2004).
Since (Hearst, 1992), who used a manu-ally prepared set of initial lexical patterns in orderto acquire relationships, numerous pattern-basedmethods have been proposed for the discovery ofconcepts from seeds (Pantel et al, 2004; Davidovet al, 2007; Pasca et al, 2006).
Most of thesestudies were done for English, while some showthe applicability of their method to some otherlanguages including Russian, Greek, Czech andFrench.Many papers directly target specific applica-tions, and build lexical resources as a side ef-fect.
Named Entity Recognition can be viewedas an instance of the concept acquisition problemwhere the desired categories contain words thatare names of entities of a particular kind, as donein (Freitag, 2004) using co-clustering and in (Et-zioni et al, 2005) using predefined pattern types.Many Information Extraction papers discover re-lationships between words using syntactic patterns(Riloff and Jones, 1999).Unlike in the majority of recent studies wherethe acquisition framework is designed with spe-cific languages in mind, in our task the algorithmshould be able to deal well with a wide varietyof target languages without any significant manualadaptations.
While some of the proposed frame-works could potentially be language-independent,little research has been done to confirm it yet.176There are a few obstacles that may hinder apply-ing common pattern-based methods to other lan-guages.
Many studies utilize parsing or POS tag-ging, which frequently depends on the availabil-ity and quality of language-specific tools.
Moststudies specify seed patterns in advance, and it isnot clear whether translated patterns can work wellon different languages.
Also, the absence of clearword segmentation in some languages (e.g., Chi-nese) can make many methods inapplicable.A few recently proposed concept acquisitionmethods require only a handful of seed words(Davidov et al, 2007; Pasca and Van Durme,2008).
While these studies avoid some of the ob-stacles above, it still remains unconfirmed whethersuch methods are indeed language-independent.In the concept extension part of our algorithm weadapt our concept acquisition framework (Davi-dov and Rappoport, 2006; Davidov et al, 2007;Davidov and Rappoport, 2008a; Davidov andRappoport, 2008b) to suit diverse languages, in-cluding ones without explicit word segmentation.In our evaluation we confirm the applicability ofthe adapted methods to 45 languages.Our study is related to cross-language infor-mation retrieval (CLIR/CLEF) frameworks.
Bothdeal with information extracted from a set of lan-guages.
However, the majority of CLIR stud-ies pursue different targets.
One of the mainCLIR goals is the retrieval of documents basedon explicit queries, when the document lan-guage is not the query language (Volk and Buite-laar, 2002).
These frameworks usually developlanguage-specific tools and algorithms includingparsers, taggers and morphology analyzers in or-der to integrate multilingual queries and docu-ments (Jagarlamudi and Kumaran, 2007).
Ourgoal is to develop and evaluate a language-independent method for the translation and exten-sion of lexical categories.
While our goals are dif-ferent from CLIR, CLIR systems can greatly ben-efit from our framework, since our translated cate-gories can be directly utilized for subsequent doc-ument retrieval.Another field indirectly related to our researchis Machine Translation (MT).
Many MT tasks re-quire automated creation or improvement of dic-tionaries (Koehn and Knight, 2001).
However,MT mainly deals with translation and disambigua-tion of words at the sentence or document level,while we translate whole concepts defined inde-pendently of contexts.
Our primary target is nottranslation of given words, but the discovery andextension of a concept in a target language whenthe concept definition is given in some differentsource language.3 Cross-lingual Concept TranslationFrameworkOur framework has three main stages: (1) givena set of words in a source language as definitionfor some concept, we automatically translate themto the target language with multilingual dictionar-ies, disambiguating translations using web counts;(2) we retrieve from the web snippets where thesetranslations co-appear; (3) we apply a pattern-based concept extension algorithm for discoveringadditional terms from the retrieved data.3.1 Concept words and sense selectionWe start from a set of words denoting a categoryin a source language.
Thus we may use wordslike (apple, banana, ...) as the definition of fruitsor (bear, wolf, fox, ...) as the definition of wildanimals2.
Each of these words can be ambiguous.Multilingual dictionaries usually provide manytranslations, one or more for each sense.
We needto select the appropriate translation for each term.In practice, some or even most of the categoryterms may be absent in available dictionaries.In these cases, we attempt to extract ?chain?translations, i.e., if we cannot find Source?Targettranslation, we can still find some indirectSource?Intermediate1?Intermediate2?Targetpaths.
Such translations are generally muchmore ambiguous, hence we allow up to twointermediate languages in a chain.
We collect allpossible translations at the chains having minimallength, and skip category terms for whom thisprocess results in no translations.Then we use the conjecture that terms of thesame concept tend to co-appear more frequentlythan ones belonging to different concepts3.
Thus,2In order to reduce noise, we limit the length (in words)of multiword expressions considered as terms.
To calculatethis limit for a language we randomly take 100 terms fromthe appropriate dictionary and set a limit as Limmwe =round(avg(length(w))) where length(w) is the number ofwords in term w. For languages like Chinese without inherentword segmentation, length(w) is the number of characters inw.
While for many languages Limmwe = 1, some languageslike Vietnamese usually require two words or more to expressterms.3Our results in this paper support this conjecture.177we select a translation of a term co-appearingmost frequently with some translation of a differ-ent term of the same concept.
We estimate howwell translations of different terms are connectedto each other.
Let C = {Ci} be the given seedwords for some concept.
Let Tr(Ci, n) be then-th available translation of word Ci and Cnt(s)denote the web count of string s obtained by asearch engine.
Then we select translation Tr(Ci)according to:F (w1, w2) =Cnt(?w1 ?
w2?)?
Cnt(?w2 ?
w1?)Cnt(w1)?
Cnt(w2)Tr(Ci) =argmaxsi(maxsjj 6=i(F (Tr(Ci, si), T r(Cj , sj))))We utilize the Y ahoo!
?x * y?
wildcard that al-lows to count only co-appearances where x and yare separated by a single word.
As a result, we ob-tain a set of disambiguated term translations.
Thenumber of queries in this stage depends on the am-biguity of concept terms translation to the targetlanguage.
Unlike many existing disambiguationmethods based on statistics obtained from parallelcorpora, we take a rather simplistic query-basedapproach.
This approach is powerful (as shownin our evaluation) and only relies on a few webqueries in a language independent manner.3.2 Web mining for translation contextsWe need to restrict web mining to specific tar-get languages.
This restriction is straightforwardif the alphabet or term translations are language-specific or if the search API supports restriction tothis language4.
In case where there are no suchnatural restrictions, we attempt to detect and addto our queries a few language-specific frequentwords.
Using our dictionaries, we find 1?3 of the15 most frequent words in a desired language thatare unique to that language, and we ?and?
themwith the queries to ensure selection of the properlanguage.
While some languages as Esperanto donot satisfy any of these requirements, more than60 languages do.For each pair A, B of disambiguated term trans-lations, we construct and execute the following 2queries: {?A * B?, ?B * A?}5.
When we have3 or more terms we also add {A B C .
.
.
}-likeconjunction queries which include 3?5 terms.
Forlanguages with Limmwe > 1, we also construct4Yahoo!
allows restrictions for 42 languages.5These are Yahoo!
queries where enclosing words in ?
?means searching for an exact phrase and ?*?
means a wild-card for exactly one arbitrary word.queries with several ?*?
wildcards between terms.For each query we collect snippets containing textfragments of web pages.
Such snippets frequentlyinclude the search terms.
Since Y ahoo!
allows re-trieval of up to the 1000 first results (100 in eachquery), we collect several thousands snippets.
Formost of the target languages and categories, only afew dozen queries (20 on the average) are requiredto obtain sufficient data.
Thus the relevant datacan be downloaded in seconds.
This makes ourapproach practical for on-demand retrieval tasks.3.3 Pattern-based extension of concept termsFirst we extract from the retrieved snippets con-texts where translated terms co-appear, and de-tect patterns where they co-appear symmetrically.Then we use the detected patterns to discover ad-ditional concept terms.
In order to define wordboundaries, for each target language we manu-ally specify boundary characters such as punctu-ation/space symbols.
This data, along with dic-tionaries, is the only language-specific data in ourframework.3.3.1 Meta-patternsFollowing (Davidov et al, 2007) we seek symmet-ric patterns to retrieve concept terms.
We use twometa-pattern types.
First, a Two-Slot pattern typeconstructed as follows:[Prefix] C1 [Infix] C2 [Postfix]Ci are slots for concept terms.
We allow up toLimmwe space-separated6 words to be in a sin-gle slot.
Infix may contain punctuation, spaces,and up to Limmwe ?
4 words.
Prefix and Post-fix are limited to contain punctuation charactersand/or Limmwe words.Terms of the same concept frequently co-appearin lists.
To utilize this, we introduce two additionalList pattern types7:[Prefix] C1[Infix] (Ci[Infix])+ (1)[Infix] (Ci[Infix])+ Cn [Postfix] (2)As in (Widdows and Dorow, 2002; Davidov andRappoport, 2006), we define a pattern graph.Nodes correspond to terms and patterns to edges.If term pair (w1, w2) appears in pattern P , we addnodes Nw1 , Nw2 to the graph and a directed edgeEP (Nw1 , Nw2) between them.6As before, for languages without explicit space-basedword separation Limmwe limits the number of characters in-stead.7(X)+ means one or more instances of X .1783.3.2 Symmetric patternsWe consider only symmetric patterns.
We definea symmetric pattern as a pattern where some cate-gory terms Ci, Cj appear both in left-to-right andright-to-left order.
For example, if we consider theterms {apple, pineapple} we select a List pattern?
(one Ci, )+ and Cn.?
if we find both ?one apple,one pineapple, one guava and orange.?
and ?onewatermelon, one pineapple and apple.?.
If no suchpatterns are found, we turn to a weaker definition,considering as symmetric those patterns where thesame terms appear in the corpus in at least two dif-ferent slots.
Thus, we select a pattern ?for C1 andC2?
if we see both ?for apple and guava,?
and ?fororange and apple,?.3.3.3 Retrieving concept termsWe collect terms in two stages.
First, we obtain?high-quality?
core terms and then we retrieve po-tentially more noisy ones.
In the first stage we col-lect all terms8 that are bidirectionally connected toat least two different original translations, and callthem core concept terms Ccore.
We also add theoriginal ones as core terms.
Then we detect therest of the terms Crest that appear with more dif-ferent Ccore terms than with ?out?
(non-core) termsas follows:Gin(c)={w?Ccore|E(Nw, Nc) ?
E(Nc, Nw)}Gout(c)={w/?Ccore|E(Nw, Nc) ?
E(Nc, Nw)}Crest={c| |Gin(c)|>|Gout(c)| }where E(Na, Nb) correspond to existence of agraph edge denoting that translated terms a and bco-appear in a pattern in this order.
Our final termset is the union of Ccore and Crest.For the sake of simplicity, unlike in the ma-jority of current research, we do not attempt todiscover more patterns/instances iteratively by re-examining the data or re-querying the web.
If wehave enough data, we use windowing to improveresult quality.
If we obtain more than 400 snip-pets for some concept, we randomly divide thedata into equal parts, each containing up to 400snippets.
We apply our algorithm independentlyto each part and select only the words that appearin more than one part.4 Experimental SetupWe describe here the languages, concepts and dic-tionaries we used in our experiments.8We do not consider as terms the 50 most frequent words.4.1 Languages and categoriesOne of the main goals in this research is to ver-ify that the proposed basic method can be appliedto different languages unmodified.
We examineda wide variety of languages and concepts.
Table3 shows a list of 45 languages used in our experi-ments, including west European languages, Slaviclanguages, Semitic languages, and diverse Asianlanguages.Our concept set was based on English WNsynsets, while concept definitions for evaluationwere based on WN glosses.
For automated evalua-tion we selected as categories 150 synsets/subtreeswith at least 10 single-word terms in them.
Formanual evaluation we used a subset of 24 of thesecategories.
In this subset we tried to select genericcategories, such that no domain expert knowledgewas required to check their correctness.Ten of these categories were equal to ones usedin (Widdows and Dorow, 2002; Davidov and Rap-poport, 2006), which allowed us to indirectlycompare to recent work.
Table 1 shows these 10concepts along with the sample terms.
While thenumber of tested categories is still modest, it pro-vides a good indication for the quality of our ap-proach.Concept Sample termsMusical instruments guitar, flute, pianoVehicles/transport train, bus, carAcademic subjects physics, chemistry, psychologyBody parts hand, leg, shoulderFood egg, butter, breadClothes pants, skirt, jacketTools hammer, screwdriver, wrenchPlaces park, castle, gardenCrimes murder, theft, fraudDiseases rubella, measles, jaundiceTable 1: 10 of the selected categories with sample terms.4.2 Multilingual dictionariesWe developed a set of tools for automatic accessto several dictionaries.
We used Wikipedia cross-language links as our main source (60%) for of-fline translation.
These links include translationof Wikipedia terms into dozens of languages.
Themain advantage of using Wikipedia is its wide cov-erage of concepts and languages.
However, oneproblem in using it is that it frequently encodes toospecific senses and misses common ones.
Thusbear is translated as family Ursidae missing itscommon ?wild animal?
sense.
To overcome these179difficulties, we also used Wiktionary and comple-mented these offline resources with a few auto-mated queries to several (20) online dictionaries.We start with Wikipedia definitions, then if notfound, Wiktionary, and then we turn to online dic-tionaries.5 Evaluation and ResultsWhile there are numerous concept acquisitionstudies, no framework has been developed so farto evaluate this type of cross-lingual concept dis-covery, limiting our ability to perform a meaning-ful comparison to previous work.
Fair estimationof translated concept quality is a challenging task.For most languages there are no widely acceptedconcept databases.
Moreover, the contents of thesame concept may vary across languages.
Fortu-nately, when English is taken as a target language,the English WN allows an automated evaluation ofconcepts.
We conducted evaluation in three differ-ent settings, mostly relying on human judges andutilizing the English WN where possible.1.
English as source language.
We applied ouralgorithm on a subset of 24 categories usingeach of the 45 languages as a target language.Evaluation is done by two judges9.2.
English as target language.
All other lan-guages served as source languages.
In thiscase human subjects manually provided in-put terms for 150 concept definitions in eachof the target languages using 150 selectedEnglish WN glosses.
For each gloss theywere requested to provide at least 2 terms.Then we ran the algorithm on these termlists.
Since the obtained results were Englishwords, we performed both manual evaluationof the 24 categories and automated compari-son to the original WN data.3.
Language pairs.
We created 10 different non-English language pairs for the 24 concepts.Concept definitions were the same as in (2)and manual evaluation followed the sameprotocol as in (1).The absence of exhaustive term lists makes recallestimation problematic.
In all cases we assess thequality of the discovered lists in terms of precision(P ) and length of retrieved lists (T ).9For 19 of the languages, at least one judge was a nativespeaker.
For other languages at least one of the subjects wasfluent with this language.5.1 Manual evaluationEach discovered concept was evaluated by twojudges.
All judges were fluent English speakersand for each target language, at least one was a flu-ent speaker of this language.
They were given one-line English descriptions of each category and thefull lists obtained by our algorithm for each of the24 concepts.
Table 2 shows the lists obtained byour algorithm for the category described as Rela-tives (e.g., grandmother) for several language pairsincluding Hebrew?French and Chinese?Czech.We mixed ?noise?
words into each list of terms10.These words were automatically and randomly ex-tracted from the same text.
Subjects were re-quired to select all words fitting the provided de-scription.
They were unaware of algorithm detailsand desired results.
They were instructed to ac-cept common abbreviations, alternative spellingsor misspellings like yel?ow?color and to accept aterm as belonging to a category if at least oneof its senses belongs to it, like orange?color andorange?fruit.
They were asked to reject terms re-lated or associated but not belonging to the targetcategory, like tasty/?food, or that are too general,like animal/?dogs.The first 4 columns of Table 3 show averagedresults of manual evaluation for 24 categories.
Inthe first two columns English is used as a sourcelanguage and in the next pair of columns English isused as the target.
In addition we display in paren-theses the amount of terms added during the ex-tension stage.
We can see that for all languages,average precision (% of correct terms in concept)is above 80, and frequently above 90, and the aver-age number of extracted terms is above 30.
Inter-nal concept quality is in line with values observedon similarly evaluated tasks for recent concept ac-quisition studies in English.
As a baseline, only3% of the inserted 20-40% noise words were in-correctly labeled by judges.
Due to space limita-tion we do not show the full per-concept behavior;all medians for P and T were close to the average.We can also observe that the majority (> 60%)of target language terms were obtained during theextension stage.
Thus, even when consideringtranslation from a rich language such as English(where given concepts frequently contain dozensof terms), most of the discovered target languageterms are not discovered through translation but10To reduce annotator bias, we used a different number ofnoise words, adding 20?40% of the original number of words.180English?Portuguese:afilhada,afilhado,amigo,avo?,avo?,bisavo?,bisavo?,bisneta,bisneto,co?njuge,cunhada,cunhado,companheiro,descendente,enteado,filha,filho,irma?,irma?o,irma?os,irma?s,madrasta,madrinha,ma?e,marido,mulher,namorada,namorado,neta,neto,noivo,padrasto,pai,papai,parente,prima,primo,sogra,sogro,sobrinha,sobrinho,tia,tio,vizinhoHebrew?French:amant,ami,amie,amis,arrie`re-grand-me`re,arrie`re-grand-pe`re,beau-fre`re,beau-parent,beau-pe`re,bebe,belle-fille,belle-me`re,belle-soeur,be`be`,compagnon,concubin,conjoint,cousin,cousine,demi-fre`re,demi-soeur,e?pouse,e?poux,enfant,enfants,famille,femme,fille,fils,foyer,fre`re,garcon,grand-me`re,grand-parent,grand-pe`re,grands-parents,maman,mari,me`re,neveu,nie`ce,oncle,papa,parent,pe`re,petit-enfant,petit-fils,soeur,tanteEnglish?Spanish:abuela,abuelo,amante,amiga,amigo,confidente,bisabuelo,cun?ada,cun?ado,co?nyuge,esposa,esposo,esp?
?ritu,familia,familiar,hermana,hermano,hija,hijo,hijos,madre,marido,mujer,nieta,nieto,nin?o, novia,padre,papa?,primo,sobrina,sobrino,suegra,suegro,t??a,t?
?o,tutor, viuda,viudoChinese?Czech:babic?ka,bratr,bra?cha,chlapec,dcera,de?da,de?dec?ek,druh,kamara?d,kamara?dka,mama,manz?el,manz?elka,matka,muz?,otec,podnajemnik,pr??
?telkyne?, sestra,stars??
?,stry?c,stry?c?ek, syn,se?gra,tcha?n,tchyne?,teta,vnuk,vnuc?ka,z?enaTable 2: Sample of results for the Relatives concept.
Notethat precision is not 100% (e.g.
the Portuguese set includes?friend?
and ?neighbor?
).during the subsequent concept extension.
In fact,brief examination shows that less than half ofsource language terms successfully pass transla-tion and disambiguation stage.
However, morethan 80% of terms which were skipped due to lackof available translations were re-discovered in thetarget language during the extension stage, alongwith the discovery of new correct terms not exist-ing in the given source definition.The first two columns of Table 4 show similarresults for non-English language pairs.
We can seethat these results are only slightly inferior to theones involving English.5.2 WordNet based evaluationWe applied our algorithm on 150 concepts withEnglish used as the target language.
Since wewant to consider common misspellings and mor-phological combinations of correct terms as hits,we used a basic speller and stemmer to resolvetypos and drop some English endings.
The WNcolumns in Table 3 display P and T values forthis evaluation.
In most cases we obtain > 85%precision.
While these results (P=87,T=17) arelower than in manual evaluation, the task is muchharder due to the large number (and hence sparse-ness) of the utilized 150 WN categories and theincomplete nature of WN data.
For the 10 cat-egories of Table 1 used in previous work, wehave obtained (P=92,T=41) which outperformsthe seed-based concept acquisition of (Widdowsand Dorow, 2002; Davidov and Rappoport, 2006)(P=90,T=35) on the same concepts.
However, itshould be noted that our task setting is substan-tially different since we utilize more seeds andthey come from languages different from English.5.3 Effect of dictionary size and sourcecategory sizeThe first stage in our framework heavily relies onthe existence and quality of dictionaries, whosecoverage may be insufficient.
In order to checkthe effect of dictionary coverage on our task, were-evaluated 10 language pairs using reduced dic-tionaries containing only the 1000 most frequentwords.
The last columns in Table 4 show evalu-ation results for such reduced dictionaries.
Sur-prisingly, while we see a difference in coverageand precision, this difference is below 8%, thuseven basic 1000-word dictionaries may be usefulfor some applications.This may suggest that only a few correct trans-lations are required for successful discovery ofthe corresponding category.
Hence, even a smalldictionary containing translations of the most fre-quent terms could be enough.
In order to testthis hypothesis, we re-evaluated the 10 languagepairs using full dictionaries while reducing theinitial concept definition to the 3 most frequentwords.
The results of this experiment are shown atcolumns 3?4 of Table 4.
We can see that for mostlanguage pairs, 3 seeds were sufficient to achieveequally good results, and providing more exten-sive concept definitions had little effect on perfor-mance.5.4 Variance analysisWe obtained high precision.
However, we also ob-served high variance in the number of terms be-tween different language pairs for the same con-cept.
There are many possible reasons for this out-come.
Below we briefly discuss some of them; de-tailed analysis of inter-language and inter-conceptvariance is a major target for future work.Web coverage of languages is not uniform (Pao-lillo et al, 2005); e.g.
Georgian has much lessweb hits than English.
Indeed, we observed a cor-relation between reported web coverage and thenumber of retrieved terms.
Concept coverage and181English English as targetLanguage as sourceManual Manual WNT[xx] P T[xx] P T PArabic 29 [12] 90 41 [35] 91 17 87Armenian 27 [21] 93 40 [32] 92 15 86Afrikaans 40 [29] 89 51 [28] 86 19 85Bengali 23 [18] 95 42 [34] 93 18 88Belorussian 23 [15] 91 43 [30] 93 17 87Bulgarian 46 [36] 85 58 [33] 87 19 83Catalan 45 [29] 81 56 [46] 88 21 86Chinese 47 [34] 87 56 [22] 90 22 89Croatian 46 [26] 90 57 [35] 92 16 89Czech 58 [40] 89 65 [39] 94 23 88Danish 48 [35] 94 59 [38] 97 17 90Dutch 41 [28] 92 60 [36] 94 20 88Estonian 35 [21] 96 47 [24] 96 16 90Finnish 34 [21] 88 47 [29] 90 19 85French 56 [30] 89 61 [31] 93 17 87Georgian 22 [15] 95 39 [31] 96 16 90German 54 [32] 91 62 [34] 92 21 83Greek 27 [16] 93 44 [30] 95 17 91Hebrew 38 [28] 93 45 [32] 93 18 92Hindi 30 [10] 92 46 [28] 93 16 86Hungarian 43 [27] 90 44 [28] 93 15 87Italian 45 [26] 89 51 [29] 88 16 81Icelandic 27 [21] 90 39 [27] 92 15 85Indonesian 33 [25] 96 49 [25] 95 15 90Japanese 40 [16] 89 50 [22] 91 20 83Kazakh 22 [14] 96 43 [36] 97 16 92Korean 33 [15] 88 46 [29] 89 16 85Latvian 41 [30] 92 55 [46] 90 19 83Lithuanian 36 [26] 94 44 [35] 95 16 89Norwegian 37 [25] 89 46 [29] 93 15 85Persian 17 [6] 98 40 [29] 96 15 92Polish 38 [25] 89 55 [36] 92 17 96Portuguese 55 [34] 87 64 [33] 90 21 85Romanian 46 [29] 93 56 [25] 96 15 91Russian 58 [40] 91 65 [35] 92 22 84Serbian 19 [11] 93 36 [30] 95 17 90Slovak 32 [20] 89 56 [39] 90 15 87Slovenian 28 [16] 94 43 [36] 95 18 89Spanish 53 [37] 90 66 [32] 91 23 85Swedish 52 [33] 89 62 [39] 93 16 87Thai 26 [13] 95 41 [34] 97 16 92Turkish 42 [33] 92 50 [25] 93 16 88Ukrainian 47 [33] 88 54 [28] 88 16 83Vietnamese 26 [8] 84 48 [25] 89 15 82Urdu 27 [14] 84 42 [36] 88 14 82Average 38 [24] 91 50 [32] 92 17 87Table 3: Concept translation and extension results.
Thefirst column shows the 45 tested languages.
Bold are lan-guages evaluated with at least one native speaker.
P: preci-sion, T: number of retrieved terms.
?[xx]?
: number of termsadded during the concept extension stage.
Columns 1-4 showresults for manual evaluation on 24 concepts.
Columns 5-6show automated WN-based evaluation on 150 concepts.
Forcolumns 1-2 the input category is given in English, in othercolumns English served as the target language.content is also different for each language.
Thus,concepts involving fantasy creatures were foundto have little coverage in Arabic and Hindi, andwide coverage in European languages.
For ve-hicles, Snowmobile was detected in Finnish andLanguage pair Regular Reduced ReducedSource-Target data seed dict.T[xx] P T P T PHebrew-French 43[28] 89 39 90 35 87Arabic-Hebrew 31[24] 90 25 94 29 82Chinese-Czech 35[29] 85 33 84 25 75Hindi-Russian 45[33] 89 45 87 38 84Danish-Turkish 28[20] 88 24 88 24 80Russian-Arabic 28[18] 87 19 91 22 86Hebrew-Russian 45[31] 92 44 89 35 84Thai-Hebrew 28[25] 90 26 92 23 78Finnish-Arabic 21[11] 90 14 92 16 84Greek-Russian 48[36] 89 47 87 35 81Average 35[26] 89 32 89 28 82Table 4: Results for non-English pairs.
P: precision, T:number of terms.
?[xx]?
: number of terms added in the exten-sion stage.
Columns 1-2 show results for normal experimentsettings, 3-4 show data for experiments where the 3 most fre-quent terms were used as concept definitions, 5-6 describeresults for experiment with 1000-word dictionaries.Swedish while Rickshaw appears in Hindi.Morphology was completely neglected in thisresearch.
To co-appear in a text, terms frequentlyhave to be in a certain form different from thatshown in dictionaries.
Even in English, pluralslike spoons, forks co-appear more than spoon,fork.
Hence dictionaries that include morphol-ogy may greatly improve the quality of our frame-work.
We have conducted initial experiments withpromising results in this direction, but we do notreport them here due to space limitations.6 ConclusionsWe proposed a framework that when given a setof terms for a category in some source languageuses dictionaries and the web to retrieve a similarcategory in a desired target language.
We showedthat the same pattern-based method can success-fully extend dozens of different concepts for manylanguages with high precision.
We observed thateven when we have very few ambiguous transla-tions available, the target language concept canbe discovered in a fast and precise manner with-out relying on any language-specific preprocess-ing, databases or parallel corpora.
The averageconcept total processing time, including all webrequests, was below 2 minutes11.
The short run-ning time and the absence of language-specific re-quirements allow processing queries within min-utes and makes it possible to apply our method toon-demand cross-language concept mining.11We used a single PC with ADSL internet connection.182ReferencesM.
Fatih Amasyali, 2005.
Automatic Construction ofTurkish WordNet.
Signal Processing and Commu-nications Applications Conference.Sharon Caraballo, 1999.
Automatic Construction ofa Hypernym-Labeled Noun Hierarchy from Text.ACL ?99.Thatsanee Charoenporn, Virach Sornlertlamvanich,Chumpol Mokarat, Hitoshi Isahara, 2008.
Semi-Automatic Compilation of Asian WordNet.
Pro-ceedings of the 14th NLP-2008, University of Tokyo,Komaba Campus, Japan.James R. Curran, Marc Moens, 2002.
Improvementsin Automatic Thesaurus Extraction.
SIGLEX ?02,59?66.Dmitry Davidov, Ari Rappoport, 2006.
EfficientUnsupervised Discovery of Word Categories Us-ing Symmetric Patterns and High Frequency Words.COLING-ACL ?06.Dmitry Davidov, Ari Rappoport, Moshe Koppel, 2007.Fully Unsupervised Discovery of Concept-SpecificRelationships by Web Mining.
ACL ?07.Dmitry Davidov, Ari Rappoport, 2008a.
UnsupervisedDiscovery of Generic Relationships Using PatternClusters and its Evaluation by Automatically Gen-erated SAT Analogy Questions.
ACL ?08.Dmitry Davidov, Ari Rappoport, 2008b.
Classificationof Semantic Relationships between Nominals UsingPattern Clusters.
ACL ?08.Scott Deerwester, Susan Dumais, George Furnas,Thomas Landauer, Richard Harshman, 1990.
In-dexing by Latent Semantic Analysis.
Journal of theAmerican Society for Info.
Science, 41(6):391?407.Beate Dorow, Dominic Widdows, Katarina Ling, Jean-Pierre Eckmann, Danilo Sergi, Elisha Moses, 2005.Using Curvature and Markov Clustering in Graphsfor Lexical Acquisition and Word Sense Discrimi-nation.
MEANING ?05.Oren Etzioni, Michael Cafarella, Doug Downey, S.Kok, Ana-Maria Popescu, Tal Shaked, StephenSoderland, Daniel S. Weld, Alexander Yates, 2005.Unsupervised Named-Entity Extraction from theWeb: An Experimental Study.
Artificial Intelli-gence, 165(1):91134.Dayne Freitag, 2004.
Trained Named Entity Recogni-tion Using Distributional lusters.
EMNLP ?04.James Gorman , James R. Curran, 2006.
Scaling Dis-tributional Similarity to Large Corpora COLING-ACL ?06.Marti Hearst, 1992.
Automatic Acquisition of Hy-ponyms from Large Text Corpora.
COLING ?92.Jagadeesh Jagarlamudi, A Kumaran, 2007.
Cross-Lingual Information Retrieval System for IndianLanguages Working Notes for the CLEF 2007 Work-shop.Philipp Koehn, Kevin Knight, 2001.
Knowl-edge Sources for Word-Level Translation Models.EMNLP ?01.Dekang Lin, 1998.
Automatic Retrieval and Cluster-ing of Similar Words.
COLING ?98.Margaret Matlin, 2005.
Cognition, 6th edition.
JohnWiley & Sons.Patrick Pantel, Dekang Lin, 2002.
Discovering WordSenses from Text.
SIGKDD ?02.Patrick Pantel, Deepak Ravichandran, Eduard Hovy,2004.
Towards Terascale Knowledge Acquisition.COLING ?04.John Paolillo, Daniel Pimienta, Daniel Prado, et al,2005.
Measuring Linguistic Diversity on the In-ternet.
UNESCO Institute for Statistics Montreal,Canada.Marius Pasca, Dekang Lin, Jeffrey Bigham, AndreiLifchits, Alpa Jain, 2006.
Names and Similari-ties on the Web: Fact Extraction in the Fast Lane.COLING-ACL ?06.Marius Pasca, Benjamin Van Durme, 2008.
Weakly-Supervised Acquisition of Open-Domain Classesand Class Attributes from Web Documents andQuery Logs.
ACL ?08.Adam Pease, Christiane Fellbaum, Piek Vossen, 2008.Building the Global WordNet Grid.
CIL18.Fernando Pereira, Naftali Tishby, Lillian Lee, 1993.Distributional Clustering of English Words.
ACL?93.Ellen Riloff, Rosie Jones, 1999.
Learning Dictionar-ies for Information Extraction by Multi-Level Boot-strapping.
AAAI ?99.Martin Volk, Paul Buitelaar, 2002.
A Systematic Eval-uation of Concept-Based Cross-Language Informa-tion Retrieval in the Medical Domain.
In: Proc.
of3rd Dutch-Belgian Information Retrieval Workshop.Leuven.Dominic Widdows, Beate Dorow, 2002.
A GraphModel for Unsupervised Lexical Acquisition.
COL-ING ?02.183
