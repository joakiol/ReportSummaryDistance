Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 795?802,Sydney, July 2006. c?2006 Association for Computational LinguisticsUnsupervised Induction of Modern Standard Arabic Verb Classes UsingSyntactic Frames and LSANeal SniderLinguistics DepartmentStanford UniversityStanford, CA 94305snider@stanford.eduMona DiabCenter for Computational Learning SystemsColumbia UniversityNew York, NY 10115mdiab@cs.columbia.eduAbstractWe exploit the resources in the ArabicTreebank (ATB) and Arabic Gigaword(AG) to determine the best features for thenovel task of automatically creating lexi-cal semantic verb classes for Modern Stan-dard Arabic (MSA).
The verbs are clas-sified into groups that share semantic el-ements of meaning as they exhibit simi-lar syntactic behavior.
The results of theclustering experiments are compared witha gold standard set of classes, which isapproximated by using the noisy Englishtranslations provided in the ATB to cre-ate Levin-like classes for MSA.
The qual-ity of the clusters is found to be sensitiveto the inclusion of syntactic frames, LSAvectors, morphological pattern, and sub-ject animacy.
The best set of parametersyields an F?=1 score of 0.456, comparedto a random baseline of an F?=1 score of0.205.1 IntroductionThe creation of the Arabic Treebank (ATB) andArabic Gigaword (AG) facilitates corpus basedstudies of many interesting linguistic phenomenain Modern Standard Arabic (MSA).1 The ATBcomprises manually annotated morphological andsyntactic analyses of newswire text from differentArabic sources, while the AG is simply a huge col-lection of raw Arabic newswire text.
In our on-going project, we exploit the ATB and AG to de-termine the best features for the novel task of au-tomatically creating lexical semantic verb classes1http://www.ldc.upenn.edu/for MSA.
We are interested in the problem of clas-sifying verbs in MSA into groups that share se-mantic elements of meaning as they exhibit simi-lar syntactic behavior.
This manner of classifyingverbs in a language is mainly advocated by Levin(1993).
The Levin Hypothesis (LH) contends thatverbs that exhibit similar syntactic behavior shareelement(s) of meaning.
There exists a relativelyextensive classification of English verbs accordingto different syntactic alternations.
Numerous lin-guistic studies of other languages illustrate that LHholds cross linguistically, in spite of variations inthe verb class assignment.
For example, in a widecross-linguistic study, Guerssel et al(1985) foundthat the Conative Alternation exists in the Aus-tronesian language Warlpiri.
As in English, thealternation is found with hit- and cut-type verbs,but not with touch- and break-type verbs.A strong version of the LH claims that compara-ble syntactic alternations hold cross-linguistically.Evidence against this strong version of LH is pre-sented by Jones et al(1994).
For the purposes ofthis paper, we maintain that although the syntac-tic alternations will differ across languages, the se-mantic similarities that they signal will hold crosslinguistically.
For Arabic, a significant test of LHhas been the work of Fareh and Hamdan (2000),who argue the existence of the Locative Alterna-tion in Jordanian Arabic.
However, to date no gen-eral study of MSA verbs and alternations exists.We address this problem by automatically induc-ing such classes, exploiting explicit syntactic andmorphological information in the ATB using un-supervised clustering techniques.This paper is an extension of our previous workin Snider and Diab (2006), which found a prelim-inary effect of syntactic frames on the precisionof MSA verb clustering.
In this work, we find795effects of three more features, and report resultsusing both precision and recall.
This project isinspired by previous approaches to automaticallyinduce lexical semantic classes for English verbs,which have met with success (Merlo and Steven-son, 2001; Schulte im Walde, 2000) , compar-ing their results with manually created Levin verbclasses.
However, Arabic morphology has wellknown correlations with the kind of event struc-ture that forms the basis of the Levin classification.
(Fassi-Fehri, 2003).
This characteristic of the lan-guage makes this a particularly interesting task toperform in MSA.
Thus, the scientific goal of thisproject is to determine the features that best aidverb clustering, particularly the language-specificfeatures that are unique to MSA and related lan-guages.Inducing such classes automatically allows fora large-scale study of different linguistic phenom-ena within the MSA verb system, as well as cross-linguistic comparison with their English coun-terparts.
Moreover, drawing on generalizationsyielded by such a classification could potentiallybe useful in several NLP problems such as Infor-mation Extraction, Event Detection, InformationRetrieval and Word Sense Disambiguation, not tomention the facilitation of lexical resource cre-ation such as MSA WordNets and ontologies.Unfortunately, a gold standard resource compa-rable to Levin?s English classification for evalua-tion does not exist in MSA.
Therefore, in this pa-per, as before, we evaluate the quality of the au-tomatically induced MSA verb classes both qual-itatively and quantitatively against a noisy MSAtranslation of Levin classes in an attempt to createsuch classes for MSA verbs.The paper is organized as follows: Section 2describes Levin classes for English; Section 3 de-scribes some relevant previous work; In Section4 we discuss relevant phenomena of MSA mor-phology and syntax; In Section 5, we briefly de-scribe the clustering algorithm; Section 6 gives adetailed account of the features we use to inducethe verb clusters; Then, Section 7, describes ourevaluation data, metric, gold standard and results;In Section 8, we discuss the results and draw onsome quantitative and qualitative observations ofthe data; Finally, we conclude this paper in Section9 with concluding remarks and a look into futuredirections.2 Levin ClassesThe idea that verbs form lexical semantic clus-ters based on their syntactic frames and argu-ment selection preferences is inspired by the workof Levin, who defined classes of verbs based ontheir syntactic alternation behavior.
For example,the class Vehicle Names (e.g.
bicycle, canoe,skate, ski) is defined by the following syntactic al-ternations (among others):1.
INTRANSITIVE USE, optionally followed bya pathThey skated (along the river bank).2.
INDUCED ACTION (some verbs)Pat skated (Kim) around the rink.Levin lists 184 manually created classes for En-glish, which is not intended as an exhaustive clas-sification.
Many verbs are in multiple classesboth due to the inherent polysemy of the verbsas well as other aspectual variations such as ar-gument structure preferences.
As an example ofthe latter, a verb such as eat occurs in two differ-ent classes; one defined by the Unspecified Ob-ject Alternation where it can appear both with andwithout an explicit direct object, and another de-fined by the Connative Alternation where its sec-ond argument appears either as a direct objector the object of the preposition at.
It is impor-tant to note that the Levin classes aim to groupverbs based on their event structure, reflecting as-pectual and manner similarities rather than sim-ilarity due to their describing the same or simi-lar events.
Therefore, the semantic class similar-ity in Levin classes is coarser grained than whatone would expect resulting from a semantic clas-sification based on distributional similarity such asLatent Semantic Analysis (LSA) algorithms.
Forillustration, one would expect an LSA algorithmto group skate, rollerblade in one class and bicy-cle, motorbike, scooter in another; yet Levin putsthem all in the same class based on their syntacticbehavior, which reflects their common event struc-ture: an activity with a possible causative partici-pant.
One of the purposes of this work is to testthis hypothesis by examining the relative contri-butions of LSA and syntactic frames to verb clus-tering.3 Related WorkBased on the Levin classes, many researchers at-tempt to induce such classes automatically.
No-796tably the work of Merlo and Stevenson (2001) at-tempts to induce three main English verb classeson a large scale from parsed corpora, the classof Ergative, Unaccusative, and Object-drop verbs.They report results of 69.8% accuracy on a taskwhose baseline is 34%, and whose expert-basedupper bound is 86.5%.
In a task similar to oursexcept for its use of English, Schulte im Waldeclusters English verbs semantically by using theiralternation behavior, using frames from a statisti-cal parser combined with WordNet classes.
Sheevaluates against the published Levin classes, andreports that 61% of all verbs are clustered into cor-rect classes, with a baseline of 5%.4 Arabic Linguistic PhenomenaIn this paper, the language of interest is MSA.Arabic verbal morphology provides an interestingpiece of explicit lexical semantic information inthe lexical form of the verb.
Arabic verbs have twobasic parts, the root and pattern/template, whichcombine to form the basic derivational form of averb.
Typically a root consists of three or four con-sonants, referred to as radicals.
A pattern, on theother hand, is a distribution of vowel and conso-nant affixes on the root resulting in Arabic deriva-tional lexical morphology.
As an example, the rootk t b,2 if interspersed with the pattern 1a2a3 ?
thenumbers correspond to the positions of the first,second and third radicals in the root, respectively?
yields katab meaning write.
However, if the pat-tern were ma1A2i3, resulting in the word makAtib,it would mean offices/desks or correspondences.There are fifteen pattern forms for MSA verbs, ofwhich ten are commonly used.
Not all verbs occurwith all ten patterns.
These root-pattern combina-tions tend to indicate a particular lexical semanticevent structure in the verb.5 ClusteringTaking the linguistic phenomena of MSA as fea-tures, we apply clustering techniques to the prob-lem of inducing verb classes.
We showed in Snider& Diab (2006) that soft clustering performs beston this task compared to hard clustering, thereforewe employ soft clustering techniques to induce theverb classes here.
Clustering algorithms partitiona set of data into groups, or clusters based on asimilarity metric.
Soft clustering allows elements2All Arabic in the paper is rendered in the Buckwaltertransliteration scheme http:://www.ldc.upenn.edu.to be members of multiple clusters simultaneously,and have degrees of membership in all clusters.This membership is sometimes represented in aprobabilistic framework by a distribution P (xi, c),which characterizes the probability that a verb xiis a member of cluster c.6 FeaturesSyntactic frames The syntactic frames are de-fined as the sister constituents of the verb in a VerbPhrase (VP) constituent, namely, Noun Phrases(NP), Prepositional Phrases (PP), and SententialComplements (SBARs and Ss).
Not all of theseconstituents are necessarily arguments of the verb,so we take advantage of functional tag annota-tions in the ATB.
Hence, we only include NPswith function annotation: subjects (NP-SBJ), top-icalized subjects (NP-TPC),3 objects (NP-OBJ),and second objects in dative constructions (NP-DTV).
The PPs deemed relevant to the particularsense of the verb are tagged by the ATB annota-tors as PP-CLR.
We assume that these are argu-ment PPs, and include them in our frames.
Fi-nally, we include sentential complements (SBARand S).
While some of these will no doubt be ad-juncts (i.e.
purpose clauses and the like), we as-sume that those that are arguments will occur ingreater numbers with particular verbs, while ad-juncts will be randomly distributed with all verbs.Given Arabic?s somewhat free constituent or-der, frames are counted as the same when theycontain the same constituents, regardless of order.Also, for each constituent that is headed by a func-tion word (PPs and SBARs) such as prepositionsand complementizers, the headword is extractedto include syntactic alternations that are sensitiveto preposition or complementizer type.
It is worthnoting that this corresponds to the FRAME1 con-figuration described in our previous study.
(Sniderand Diab, 2006) Finally, only active verbs are in-cluded in this study, rather than attempt to recon-struct the argument structure of passives.Verb pattern The ATB includes morphologicalanalyses for each verb resulting from the Buck-walter Analyzer (BAMA).4 For each verb, oneof the analyses resulting from BAMA is chosenmanually by the treebankers.
The analyses are3These are displaced NP-SBJ marked differently in theATB to indicate SVO order rather than the canonical VSOorder in MSA.
NP-TPC occurs in 35% of the ATB.4http://www.ldc.upenn.edu797matched with the root and pattern information de-rived manually in a study by Nizar Habash (per-sonal communication).This feature is of particularscientific interest because it is unique to Semiticlanguages, and, as mentioned above, has an inter-esting potential correlation with argument struc-ture.Subject animacy In an attempt to allow the clus-tering algorithm to use information closer to actualargument structure than mere syntactic frames, weadd a feature that indicates whether a verb re-quires an animate subject.
Merlo and Stevenson(2001) found that this feature improved their En-glish verb clusters, but in Snider & Diab (2006),we found this feature to not contribute signifi-cantly to Arabic verb clustering quality.
How-ever, upon further inspection of the data, we dis-covered we could improve the quality of this fea-ture extraction in this study.
Automatically deter-mining animacy is difficult because it requires ex-tensive manual annotation or access to an exter-nal resource such as WordNet, neither of whichcurrently exist for Arabic.
Instead we rely on anapproximation that takes advantage of two gen-eralizations from linguistics: the animacy hierar-chy and zero-anaphora.
According to the animacyhierarchy, as described in Silverstein (1976), pro-nouns tend to describe animate entities.
Follow-ing a technique suggested by Merlo and Steven-son(2001), we take advantage of this tendencyby adding a feature that is the number of timeseach verb occurs with a pronominal subject.
Wealso take advantage of the phenomenon of zero-anaphora, or pro-drop, in Arabic as an additionalindicator subject animacy.
Pro-drop is a commonphenomenon in Romance languages, as well asSemitic languages, where the subject is implicitand the only indicator of a subject is incorporatedin the conjugation of the verb.
According to workon information structure in discourse (Vallduv?
?,1992), pro-drop tends to occur with more givenand animate subjects.
To capture this generaliza-tion, we add a feature for the frequency with whicha given verb occurs without an explicit subject.
Wefurther hypothesize that proper names are morelikely to describe animates (humans, or organiza-tions which metonymically often behave like an-imates), adding a feature for the frequency withwhich a given verb occurs with a proper name.With these three features, we provide the cluster-ing algorithm with subject animacy indicators.LSA semantic vector This feature is the semanticvector for each verb, as derived by Latent Seman-tic Analysis (LSA) of the AG.
LSA is a dimension-ality reduction technique that relies on SingularValue Decomposition (SVD) (Landauer and Du-mais, 1997).
The main strength in applying LSAto large quantities of text is that it discovers thelatent similarities between concepts.
It may beviewed as a form of clustering in conceptual space.7 Evaluation7.1 Data PreparationThe four sets of features are cast as the columndimensions of a matrix, with the MSA lemma-tized verbs constituting the row entries.
The dataused for the syntactic frames is obtained fromthe ATB corresponding to ATB1v3, ATB2v2 andATB3v2.
The ATB is a collection of 1800 sto-ries of newswire text from three different pressagencies, comprising a total of 800, 000 Arabictokens after clitic segmentation.
The domain ofthe corpus covers mostly politics, economics andsports journalism.
To extract data sets for theframes, the treebank is first lemmatized by lookingup lemma information for each word in its man-ually chosen (information provided in the Tree-bank files) corresponding output of BAMA.
Next,each active verb is extracted along with its sisterconstituents under the VP in addition to NP-TPC.As mentioned above, the only constituents keptas the frame are those labeled NP-TPC, NP-SBJ,NP-OBJ, NP-DTV, PP-CLR, and SBAR.
For PP-CLRs and SBARs, the head preposition or com-plementizer which is assumed to be the left-mostdaughter of the phrase, is extracted.
The verbsand frames are put into a matrix where the rowentries are the verbs and the column entries arethe frames.
The elements of the matrix are thefrequency of the row verb occurring in a givenframe column entry.
There are 2401 verb typesand 320 frame types, corresponding to 52167 totalverb frame tokens.For the LSA feature, we apply LSA to the AGcorpus.
AG (GIGAWORD 2) comprises 481 mil-lion words of newswire text.
The AG corpusis morphologically disambiguated using MADA.5MADA is an SVM based system that disam-biguates among different morphological analysesproduced by BAMA.
(Habash and Rambow, 2005)We extract the lemma forms of all the words in AG5http://www.ccls.columbia.edu/cadim/resources798and use them for the LSA algorithm.
To extract theLSA vectors, first the lemmatized AG data is splitinto 100 sentence long pseudo-documents.
Next,an LSA model is trained using the Infomap soft-ware 6 on half of the AG (due to size limitationsof Infomap).
Infomap constructs a word similaritymatrix in document space, then reduces the dimen-sionality of the data using SVD.
LSA reduces AGto 44 dimensions.
The 44-dimensional vector isextracted for each verb, which forms the LSA dataset for clustering.Subject animacy information is represented asthree feature columns in our matrix.
One columnentry represents the frequency a verb co-occurswith an empty subject (represented as an NP-SBJdominating the NONE tag, 21586 tokens).
An-other column has the frequency the NP-SBJ/NP-TPC dominates a pronoun (represented in the cor-pus as the tag PRON 3715 tokens).
Finally, thelast subject animacy column entry represents thefrequency an NP-SBJ/NP-TPC dominates a propername (tagged NOUN PROP, 4221 tokens).The morphological pattern associated with eachverb is extracted by looking up the lemma inthe output of BAMA.
The pattern information isadded as a feature column to our matrix of verbsby features.7.2 Gold Standard DataThe gold standard data is created automaticallyby taking the English translations correspondingto the MSA verb entries provided with the ATBdistributions.
We use these English translationsto locate the lemmatized MSA verbs in the LevinEnglish classes represented in the Levin Verb In-dex (Levin, 1993), thereby creating an approxi-mated MSA set of verb classes corresponding tothe English Levin classes.
Admittedly, this is acrude manner to create a gold standard set.
Givenlack of a pre-existing classification for MSA verbs,and the novelty of the task, we consider it a firstapproximation step towards the creation of a realgold standard classification set in the near future.Since the translations are assigned manually to theverb entries in the ATB, we assume that they are afaithful representation of the MSA language used.Moreover, we contend that lexical semantic mean-ings, if they hold cross linguistically, would bedefined by distributions of syntactic alternations.Unfortunately, this gold standard set is more noisy6http://infomap.stanford.edu/than expected due to several factors: each MSAmorphological analysis in the ATB has severalassociated translations, which include both poly-semy and homonymy.
Moreover, some of thesetranslations are adjectives and nouns as well asphrasal expressions.
Such divergences occur natu-rally but they are rampant in this data set.
Hence,the resulting Arabic classes are at a finer levelof granularity than their English counterparts be-cause of missing verbs in each cluster.
There arealso many gaps ?
unclassified verbs ?
when thetranslation is not a verb, or a verb that is not inthe Levin classification.
Of the 480 most frequentverb types used in this study, 74 are not in thetranslated Levin classification.7.3 Clustering AlgorithmsWe use the clustering algorithms implementedin the library cluster (Kaufman and Rousseeuw,1990) in the R statistical computing language.
Thesoft clustering algorithm, called FANNY, is a typeof fuzzy clustering, where each observation is?spread out?
over various clusters.
Thus, the out-put is a membership function P (xi, c), the mem-bership of element xi to cluster c. The member-ships are nonnegative and sum to 1 for each fixedobservation.
The algorithm takes k, the numberof clusters, as a parameter and uses a Euclideandistance measure.
We determine k empirically, asexplained below.7.4 Evaluation MetricThe evaluation metric used here is a variation onan F -score derived for hard clustering (Chklovskiand Mihalcea, 2003).
The result is an F?
measure,where ?
is the coefficient of the relative strengthsof precision and recall.
?
= 1 for all results wereport.
The score measures the maximum over-lap between a hypothesized cluster (HYP) and acorresponding gold standard cluster (GOLD), andcomputes a weighted average across all the GOLDclusters:F?
=?C?C?C?VtotmaxA?A(?2 + 1)?A ?
C?
?2?C?+ ?A?A is the set of HYP clusters, C is the set ofGOLD clusters, and Vtot =?C?C?C?
is the totalnumber of verbs to be clustered.
This is the mea-sure that we report, which weights precision andrecall equally.7997.5 ResultsTo determine the features that yield the best clus-tering of the extracted verbs, we run tests com-paring seven different factors of the model, in a2x2x2x2x3x3x5 design, with the first four param-eters being the substantive informational factors,and the last three being parameters of the clus-tering algorithm.
For the feature selection experi-ments, the informational factors all have two con-ditions, which encode the presence or absence ofthe information associated with them.
The firstfactor represents the syntactic frame vectors, thesecond the LSA semantic vectors, the third thesubject animacy, and the fourth the morphologicalpattern of the verb.The fifth through seventh factors are parame-ters of the clustering algorithm: The fifth factoris three different numbers of verbs clustered: the115, 268, and 406 most frequent verb types, re-spectively.
The sixth factor represents numbersof clusters (k).
These values are dependent onthe number of verbs tested at a time.
Therefore,this factor is represented as a fraction of the num-ber of verbs.
Hence, the chosen values are 16 ,13 ,and 12 of the number of verbs.
The seventh andlast factor is a threshold probability used to derivediscrete members for each cluster from the clus-ter probability distribution as rendered by the softclustering algorithm.
In order to get a good rangeof the variation in the effect of the threshold, weempirically choose five different threshold values:0.03, 0.06, 0.09, 0.16, and 0.21.
The purpose ofthe last three factors is to control for the amountof variation introduced by the parameters of theclustering algorithm, in order to determine the ef-fect of the informational factors.
Evaluation scoresare obtained for all combinations of all seven fac-tors (minus the no information condition - the al-gorithm must have some input!
), resulting in 704conditions.We compare our best results to a random base-line.
In the baseline, verbs are randomly assignedto clusters where a random cluster size is on av-erage the same size as each other and as GOLD.7The highest overall scored F?=1 is 0.456 and itresults from using syntactic frames, LSA vectors,subject animacy, 406 verbs, 202 clusters, and athreshold of 0.16.
The average cluster size is 3,7It is worth noting that this gives an added advantage tothe random baseline, since a comparable to GOLD size im-plicitly contibutes to a higher overlap score.because this is a soft clustering.
The random base-line achieves an overall F?=1 of 0.205 with com-parable settings of 406 verbs randomly assigned to202 clusters of approximately equal size.To determine which features contribute signif-icantly to clustering quality, a statistical analysisof the clustering experiments is undertaken in thenext section.8 DiscussionFor further quantitative error analysis of the dataand feature selection, we perform an ANOVA totest the significance of the differences among in-formation factors and the various parameter set-tings of the clustering algorithm.
This error anal-ysis uses the error metric from Snider & Diab(2006) that allows us to test just the HYP verbsthat match the GOLD set.
The emphasis on preci-sion in the feature selection serves the purpose ofcountering the large underestimation of recall thatis due to a noisy gold standard.
We believe thatthe features that are found to be significant by thismetric stand the best chance of being useful oncea better gold standard is available.The ANOVA analyzes the effects of syntacticframe, LSA vectors, subject animacy, verb pattern,verb number, cluster number, and threshold.
Syn-tactic frame information contributes positively toclustering quality (p < .03), as does LSA (p <.001).
Contrary to the result in Snider & Diab(2006), subject animacy has a significant positivecontribution (p < .002).
Interestingly, the mor-phological pattern contributes negatively to clus-tering quality (p < .001).
As expected, the controlparameters all have a significant effect: number ofverbs (p < .001), number of clusters (p < .001),and threshold (p < .001).As evident from the results of the statisticalanalysis, the various informational factors have aninteresting effect on the quality of the clusters.Both syntactic frames and LSA vectors contributeindependently to clustering quality.
This indicatesthat successfully clustering verbs requires infor-mation at the relatively coarse level of event struc-ture, as well as the finer grained semantics pro-vided by word co-occurrence techniques such asLSA.Subject animacy is found to improve clustering,which is consistent with the results for Englishfound byMerlo and Stevenson.
This is definite im-provement over our previous study, and indicates800that the extraction of the feature has been muchimproved.Most interesting from a linguistic perspective isthe finding that morphological pattern informationabout the verb actually worsens clustering qual-ity.
This could be explained by the fact that themorphological patterns are productive, so that twodifferent verb lemmas actually describe the sameevent structure.
This would worsen the cluster-ing because these morphological alternations thatare represented by the different patterns actuallychange the lemma form of the verb, unlike syntac-tic alternations.
If only syntactic alternation fea-tures are taken into account, the different patternforms of the same root could still be clustered to-gether; however, our design of the pattern featuredoes not allow for variation in the lemma form,therefore, we are in effect preventing the useful ex-ploitation of the pattern information.
Further evi-dence comes from the positive effect of the LSAfeature, which effectively clusters together theseproductive patterns hence yielding the significantimpact on the clustering.Overall, the scores that we report use the eval-uation metric that equally weights precision andrecall.
This metric disfavors clusters that are toolarge or too small.
Models perform better whenthe average size of HYP is the same as that ofGOLD.
It is worth noting that comparing our cur-rent results to those obtained in Snider & Diab(2006), we show a significant improvement giventhe same precision oriented metric.
In the samecondition settings, our previous results are an F?score of 0.51 and in this study, a precision orientedmetric yields a significant improvement of 17 ab-solute points, at an F?
score of 0.68.
Even thoughwe do not report this number as the main result ofour study, we tend to have more confidence in itdue to the noise associated with the GOLD set.The score of the best parameter settings with re-spect to the baseline is considerable given the nov-elty of the task and lack of good quality resourcesfor evaluation.
Moreover, there is no reason toexpect that there would be perfect alignment be-tween the Arabic clusters and the correspondingtranslated Levin clusters, primarily because of thequality of the translation, but also because thereis unlikely to be an isomorphism between Englishand Arabic lexical semantics, as assumed here asa means of approximating the problem.
In fact, itwould be quite noteworthy if we did find a highlevel of agreement.In an attempt at a qualitative analysis of the re-sulting clusters, we manually examine four HYPclusters.?
The first cluster includes the verbs >aloqaY[meet], $ahid [view], >ajoraY [run an inter-view], {isotaqobal [receive a guest], Eaqad[hold a conference], >aSodar [issue].
Wenote that they all share the concept of con-vening, or formal meetings.
The verbs areclearly related in terms of their event struc-ture (they are all activities, without an associ-ated change of state) yet are not semanticallysimilar.
Therefore, our clustering approachyields a classification that is on par with theLevin classes in the coarseness of the clustermembership granularity.?
The second consists of ?akar [mention],>afAd [report] which is evaluated againstthe GOLD cluster class comprising the verbs>aEolan [announce], >a$Ar [indicate],?akar [mention], >afAd [report], Sar?aH[report/confirm], $ahid [relay/witness],ka$af [uncover] corresponding to the SayVerb Levin class.
The HYP cluster, thoughcorrect, loses significantly on recall.
Thisis due to the low frequency of some of theverbs in the GOLD set, which in turn affectsthe overall score of this HYP cluster.?
Finally, the HYP cluster comprising Eamil[work continuously on], jA?
[occur],{isotamar [continue], zAl [remain], baqiy[remain], jaraY [occur] corresponds to theOccurrence Verb Levin class.
Thecorresponding GOLD class comprises jA?
[occur], HaSal [happen], jaraY [occur].
TheHYP cluster contains most of the relevantverbs and adds others that would fall in thatsame class such as {isotamar [continue],zAl [remain], baqiy [remain], since theyhave similar syntactic diagnostics where theydo not appear in the transitive uses and withlocative inversions.
However they are notfound in the Levin English class since it isnot a comprehensive listing of all Englishverbs.In summary, we observe very interesting clus-ters of verbs which indeed require more in depthlexical semantic study as MSA verbs in their ownright.8019 ConclusionsWe found new features that help us successfullyperform the novel task of applying clustering tech-niques to verbs acquired from the ATB and AG toinduce lexical semantic classes for MSA verbs.
Indoing this, we find that the quality of the clustersis sensitive to the inclusion of information aboutthe syntactic frames, word co-occurence (LSA),and animacy of the subject, as well as parame-ters of the clustering algorithm such as the numberof clusters, and number of verbs clustered.
Ourclassification performs well with respect to a goldstandard clusters produced by noisy translations ofEnglish verbs in the Levin classes.
Our best clus-tering condition when we use all frame informa-tion and the most frequent verbs in the ATB anda high number of clusters outperforms a randombaseline by F?=1 difference of 0.251.
This anal-ysis leads us to conclude that the clusters are in-duced from the structure in the dataOur results are reported with a caveat on thegold standard data.
We are in the process of manu-ally cleaning the English translations correspond-ing to the MSA verbs.
Moreover, we are ex-ploring the possibility of improving the gold stan-dard clusters by examining the lexical semanticattributes of the MSA verbs.
We also plan toadd semantic word co-occurrence information viaother sources besides LSA, to determine if hav-ing semantic components in addition to the ar-gument structure component improves the qual-ity of the clusters.
Further semantic informationwill be acquired from a WordNet similarity of thecleaned translated English verbs.
In the long term,we envision a series of psycholinguistic experi-ments with native speakers to determine whichArabic verbs group together based on their argu-ment structure.Acknowledgements We would like to thank threeanonymous reviewers for their helpful comments.We would like to acknowledge Nizar Habash forsupplying us with a pattern and root list for MSAverb lemmas.
The second author was supported bythe Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-06-C-0023.ReferencesT.
Chklovski and R. Mihalcea.
2003.
Exploitingagreement and disagreement of human annotatorsfor word sense disambiguation.
In Proceedings ofRecent Advances In NLP (RANLP 2003).Shehdeh Fareh and Jihad Hamdan.
2000.
Locativealternation in english and jordanian spoken arabic.In Poznan Studies in Contemporary Linguistics, vol-ume 36, pages 71?93.
School of English, AdamMickiewicz University, Poznan, Poland.Abdelkader Fassi-Fehri.
2003.
Verbal plurality, tran-sitivity, and causativity.
In Research in AfroasiaticGrammar, volume 11, pages 151?185.
John Ben-jamins, Amsterdam.M.
Guerssel, K. Hale, M. Laughren, B. Levin, andJ.
White Eagle.
1985.
A cross linguistic study oftransitivity alternations.
In Papers from the Parases-sion on Causatives and Agentivity, volume 21:2,pages 48?63.
CLS, Chicago.Nizar Habash and Owen Rambow.
2005.
Arabictokenization, morphological analysis, and part-of-speech tagging in one fell swoop.
In Proceedings ofthe Conference of American Association for Compu-tational Linguistics (ACL05).D.
Jones.
1994.
Working papers and projects on verbclass alternations in Bangla, German, English, andKorean.
AI Memo 1517, MIT.L.
Kaufman and P.J.
Rousseeuw.
1990.
FindingGroups in Data.
John Wiley and Sons, New York.Thomas K. Landauer and Susan T. Dumais.
1997.A solution to platos problem: The latent semanticanalysis theory of acquisition, induction and rep-resentation of knowledge.
Psychological Review,104:2:211?240.Beth Levin.
1993.
English Verb Classes and Alter-nations: A Preliminary Investigation.
University ofChicago Press, Chicago.Paola Merlo and Suzanne Stevenson.
2001.
Automaticverb classification based on statistical distributionsof argument structure.
Computational Linguistics,27(4).Sabine Schulte im Walde.
2000.
Clustering verbs se-mantically according to their alternation behaviour.In 18th International Conference on ComputationalLinguistics (COLING 2000), Saarbrucken, Ger-many.Michael Silverstein.
1976.
Hierarchy of features andergativity.
In Robert Dixon, editor, GrammaticalCategories in Australian Languages.
Australian In-stitute of Aboriginal Studies, Canberra.N.
Snider and M. Diab.
2006.
Unsupervized inductionof modern standard arabic verb classes.
In Proceed-ings of HLT-NAACL.Enric Vallduv??.
1992.
The Informational Component.Garland, New York.802
