Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 183?193,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsLiteral and Metaphorical Senses in Compositional DistributionalSemantic ModelsE.
Dar?
?o Guti?errez1Ekaterina Shutova2Tyler Marghetis3Benjamin K. Bergen41University of California San Diego2University of Cambridge3Indiana University Bloomingtonedg@icsi.berkeley.edu tmarghet@cogsci.ucsd.edues407@cam.ac.uk bkbergen@ucsd.eduAbstractMetaphorical expressions are pervasivein natural language and pose a substan-tial challenge for computational seman-tics.
The inherent compositionality ofmetaphor makes it an important test casefor compositional distributional semanticmodels (CDSMs).
This paper is the first toinvestigate whether metaphorical compo-sition warrants a distinct treatment in theCDSM framework.
We propose a methodto learn metaphors as linear transforma-tions in a vector space and find that, acrossa variety of semantic domains, explicitlymodeling metaphor improves the result-ing semantic representations.
We then usethese representations in a metaphor iden-tification task, achieving a high perfor-mance of 0.82 in terms of F-score.1 IntroductionAn extensive body of behavioral and corpus-linguistic studies suggests that metaphors are per-vasive in everyday language (Cameron, 2003;Steen et al, 2010) and play an important role inhow humans define and understand the world.
Ac-cording to Conceptual Metaphor Theory (CMT)(Lakoff and Johnson, 1981), individual metaphor-ical expressions, or linguistic metaphors (LMs),are instantiations of broader generalizations re-ferred to as conceptual metaphors (CMs).
Forexample, the phrases half-baked idea, food forthought, and spoon-fed information are LMs thatinstantiate the CM IDEAS ARE FOOD.
Thesephrases reflect a mapping from the source domainof FOOD to the target domain of IDEAS (Lakoff,1989).
Two central claims of the CMT are thatthis mapping is systematic, in the sense that it con-sists of a fixed set of ontological correspondences,such as thinking is preparing, communication isfeeding, understanding is digestion; and that thismapping can be productively extended to producenovel LMs that obey these correspondences.Recent years have seen the rise of statisticaltechniques for metaphor detection.
Several ofthese techniques leverage distributional statisticsand vector-space models of meaning to classify ut-terances as literal or metaphorical (Utsumi, 2006;Shutova et al, 2010; Hovy et al, 2013; Tsvetkovet al, 2014).
An important insight of these studiesis that metaphorical meaning is not merely a prop-erty of individual words, but rather arises throughcross-domain composition.
The meaning of sweet,for instance, is not intrinsically metaphorical.
Yetthis word may exhibit a range of metaphori-cal meanings?e.g., sweet dreams, sweet person,sweet victory?that are created through the inter-play of source and target domains.
If metaphoris compositional, how do we represent it, and howcan we use it in a compositional framework formeaning?Compositional distributional semantic models(CDSMs) provide a compact model of composi-tionality that produces vector representations ofphrases while avoiding the sparsity and storageissues associated with storing vectors for eachphrase in a language explicitly.
One of the mostpopular CDSM frameworks (Baroni and Zampar-elli, 2010; Guevara, 2010; Coecke et al, 2010)represents nouns as vectors, adjectives as matricesthat act on the noun vectors, and transitive verbs asthird-order tensors that act on noun or noun phrasevectors.
The meaning of a phrase is then de-rived by composing these lexical representations.The vast majority of such models build a singlerepresentation for all senses of a word, collaps-ing distinct senses together.
One exception is thework of Kartsaklis and Sadrzadeh (2013a), whoinvestigated homonymy, in which lexical items183have identical form but unrelated meanings (e.g.,bank).
They found that deriving verb tensors fromall instances of a homonymous form (as com-pared to training a separate tensor for each distinctsense) loses information and degrades the resul-tant phrase vector representations.
To the best ofour knowledge, there has not yet been a study ofregular polysemy (i.e.
metaphorical or metonymicsense distinctions) in the context of compositionaldistributional semantics.
Yet, due to systematicityin metaphorical cross-domain mappings, there arelikely to be systematic contextual sense distinc-tions that can be captured by a CDSM, improvingthe resulting semantic representations.In this paper, we investigate whether metaphor,as a case of regular polysemy, warrants distincttreatment under a compositional distributional se-mantic framework.
We propose a new approachto CDSMs, in which metaphorical meanings aredistinct but structurally related to literal mean-ings.
We then extend the generalizability of ourapproach by proposing a method to automaticallylearn metaphorical mappings as linear transforma-tions in a CDSM.
We focus on modeling adjec-tive senses and evaluate our methods on a newdata set of 8592 adjective-noun pairs annotatedfor metaphoricity, which we will make publiclyavailable.
Finally, we apply our models to clas-sify unseen adjective-noun (AN) phrases as literalor metaphorical and obtain state-of-the-art perfor-mance in the metaphor identification task.2 Background & Related WorkMetaphors as Morphisms.
The idea ofmetaphor as a systematic mapping has beenformalized in the framework of category theory(Goguen, 1999; Kuhn and Frank, 1991).
Incategory theory, morphisms are transformationsfrom one object to another that preserve someessential structure of the original object.
Categorytheory provides a general formalism for analyzingrelationships as morphisms in a wide range ofsystems (see Spivak (2014)).
Category theoryhas been used to formalize the CM hypothesiswith applications to user interfaces, poetry, andinformation visualization (Kuhn and Frank, 1991;Goguen and Harrell, 2010; Goguen and Harrell,2005).
Although these formal treatments ofmetaphors as morphisms are rigorous and well-formalized, they have been applied at a relativelylimited scale.
This is because this work does notsuggest a straightforward and data-driven wayto quantify semantic domains or morphisms, butrather focuses on the transformations and rela-tions between semantic domains and morphisms,assuming some appropriate quantification hasalready been established.
In contrast, our methodscan learn representations of source-target domainmappings from corpus data, and so are inherentlymore scalable.Compositional DSMs.
Similar issues arose inmodeling compositional semantics.
Formal se-mantics has dealt with compositional meaning fordecades, by using mathematical structures fromabstract algebra, logic, and category theory (Mon-tague, 1970; Partee, 1994; Lambek, 1999).
How-ever, formal semantics requires manual craftingof features.
The central insight of CDSMs is tomodel the composition of words as algebraic op-erations on their vector representations, as pro-vided by a conventional DSM (Mitchell and La-pata, 2008).
Guevara (2010) and Baroni and Zam-parelli (2010) were the first to treat adjectives andverbs differently from nouns.
In their models, ad-jectives are represented by matrices that act onnoun vectors.
Adjective matrices can be learnedusing regression techniques.
Other CDSMs havealso been proposed and successfully applied totasks such as sentiment analysis and paraphrase(Socher et al, 2011; Socher et al, 2012; Tsubakiet al, 2013; Turney, 2013).Handling Polysemy in CDSMs.
Several re-searchers argue that terms with ambiguous sensescan be handled by DSMs without any recourse toadditional disambiguation steps, as long as con-textual information is available (Boleda et al,2012; Erk and Pad?o, 2010; Pantel and Lin, 2002;Sch?utze, 1998; Tsubaki et al, 2013).
Baroni etal.
(2014) conjecture that CDSMs might largelyavoid problems handling adjectives with multiplesenses because the matrices for adjectives implic-itly incorporate contextual information.
However,they do draw a distinction between two ways inwhich the meaning of a term can vary.
Contin-uous polysemy?the subtle and continuous vari-ations in meaning resulting from the differentcontexts in which a word appears?is relativelytractable, in their opinion.
This contrasts withdiscrete homonymy?the association of a singleterm with completely independent meanings (e.g.,light house vs. light work).
Baroni et al con-cede that homonymy is more difficult to handle in184CDSMs.
Unfortunately, they do not propose a def-inite way to determine whether any given variationin meaning is polysemy or homonymy, and of-fer no account of regular polysemy (i.e., metaphorand metonymy) or whether it would pose similarproblems as homonymy for CDSMs.To handle the problematic case of homonymy,Kartsaklis and Sadrzadeh (2013b) adapt a cluster-ing technique to disambiguate the senses of verbs,and then train separate tensors for each sense, us-ing the previously mentioned CDSM frameworkof Coecke et al (2010).
They found that prior dis-ambiguation resulted in semantic similarity mea-sures that correlated more closely with humanjudgments.In principle, metaphor, as a type of regular pol-ysemy, is different from the sort of semantic am-biguity described above.
General ambiguity orvagueness in meaning (e.g.
bright light vs brightcolor) is generally context-dependent in an unsys-tematic manner.
In contrast, in regular polysemymeaning transfer happens in a systematic way (e.g.bright light vs. bright idea), which can be explic-itly modeled within a CDSM.
The above CDSMsprovide no account of such systematic polysemy,which is the gap this paper aims to fill.Computational Work on Metaphor.
There isnow an extensive literature on statistical ap-proaches to metaphor detection.
The investigatedmethods include clustering (Birke and Sarkar,2006; Shutova et al, 2010; Li and Sporleder,2010); topic modeling (Bethard et al, 2009; Liet al, 2010; Heintz et al, 2013); topical struc-ture and imageability analysis (Strzalkowski et al,2013); semantic similarity graphs (Sporleder andLi, 2009), and feature-based classifiers (Gedigianet al, 2006; Li and Sporleder, 2009; Turney et al,2011; Dunn, 2013a; Dunn, 2013b; Hovy et al,2013; Mohler et al, 2013; Neuman et al, 2013;Tsvetkov et al, 2013; Tsvetkov et al, 2014).
Werefer readers to the survey by Shutova (2015) for amore thorough review.Most relevant to the present work are ap-proaches that attempt to identify whetheradjective-noun phrases are metaphorical orliteral.
Krishnakumaran and Zhu (2007) useAN co-occurrence counts and WordNet hy-ponym/hypernym relations for this task.
If thenoun and its hyponyms/hypernyms do not occurfrequently with the given adjective, then the ANphrase is labeled as metaphorical.
Krishnaku-maran and Zhu?s system achieves a precision of0.67.
Turney et al (2011) classify verb and adjec-tive phrases based on their level of concretenessor abstractness in relation to the noun they appearwith.
They learn concreteness rankings for wordsautomatically (starting from a set of examples)and then search for expressions where a concreteadjective or verb is used with an abstract noun(e.g., dark humor is tagged as a metaphor; darkhair is not).
They measure performance on a setof 100 phrases involving one of five adjectives,attaining an average accuracy of 0.79.
Tsvetkovet al (2014) train a random-forest classifierusing several features, including abstractness andimageability rankings, WordNet supersenses, andDSM vectors.
They report an accuracy of 0.81 onthe Turney et al (2011) AN phrase set.
They alsointroduce a new set of 200 AN phrases, on whichthey measure an F-score of 0.85.3 Experimental DataCorpus.
We trained our DSMs from a corpus of4.58 billion tokens.
Our corpus construction pro-cedure is modeled on that of Baroni and Zampar-elli (2010).
The corpus consisted of a 2011 dumpof English Wikipedia, the UKWaC (Baroni et al,2009), the BNC (BNC Consortium, 2007), andthe English Gigaword corpus (Graff et al, 2003).The corpus was tokenized, lemmatized, and POS-tagged using the NLTK toolkit (Bird and Loper,2004) for Python.Metaphor Annotations.
We created an anno-tated dataset of 8592 AN phrases (3991 literal,4601 metaphorical).
Our choice of adjectiveswas inspired by the test set of Tsvetkov et al(2014), though our annotated dataset is consid-erably larger.
We focused on 23 adjectives thatcan have both metaphorical and literal senses, andwhich function as source-domain words in rel-atively productive CMs: TEMPERATURE (cold,heated, icy, warm), LIGHT (bright, brilliant, dim),TEXTURE (rough, smooth, soft); SUBSTANCE(dense, heavy, solid), CLARITY (clean, clear,murky), TASTE (bitter, sour, sweet), STRENGTH(strong, weak), and DEPTH (deep, shallow).
Weextracted all AN phrases involving these adjec-tives that occur in our corpus at least 10 times.
Wefiltered out all phrases that require wider contextto establish their meaning or metaphoricity?e.g.,bright side, weak point.The remaining phrases were annotated using a185procedure based on Shutova et al (2010).
Annota-tors were encouraged to rely on their own intuitionof metaphor, but were provided with the followingguidance:?
For each phrase, establish the meaning of theadjective in the context of the phrase.?
Try to imagine a more basic meaning of thisadjective in other contexts.
Basic meaningstend to be: more concrete; related to embod-ied actions/perceptions/sensations; more pre-cise; historically older/more ?original?.?
If you can establish a basic meaning distinctfrom the meaning of the adjective in this con-text, it is likely to be used metaphorically.If requested, a randomly sampled sentence fromthe corpus that contained the phrase in questionwas also provided.
The annotation was performedby one of the authors.
The author?s annotationswere compared against those of a university grad-uate native English-speaking volunteer who wasnot involved in the research, on a sample of 500phrases.
Interannotator reliability (Cohen, 1960;Fleiss et al, 1969) was ?
= 0.80 (SE = .02).
Ourannotated data set is publicly available at http://bit.ly/1TQ5czN4 Representing Metaphorical Senses in aCompositional DSMIn this section we test whether separate treatmentof literal and metaphorical senses is justified in aCDSM framework.
In that case, training adjectivematrix representations on literal and metaphoricalsubsets separately may result in systematically im-proved phrase vector representations, despite eachmatrix making use of fewer training examples.4.1 MethodOur goal is to learn accurate vector represen-tations for unseen adjective-noun (AN) phrases,where adjectives can take on metaphorical or lit-eral senses.
Our models build off the CDSMframework of Baroni and Zamparelli (2010), asextended by Li et al (2014).
Each adjective a istreated as a linear map from nouns to AN phrases:p = Aan,where p is a vector for the phrase, n is a vector forthe noun, and Aais a matrix for the adjective.Contextual Variation Model.
The traditionalrepresentations do not account for the differencesin meaning of an adjective in literal vs metaphor-ical phrases.
Their assumption is that the con-textual variations in meaning that are encodedby literal and metaphorical senses may be subtleenough that they can be handled by a single catch-all matrix per adjective, ABOTH(a).
In this model,every phrase i can be represented bypi= ABOTH(a)ni(1)regardless of whether a is used metaphorically orliterally in i.
This model has the advantage of sim-plicity and requires no information about whetheran adjective is being used literally or metaphori-cally.
In fact, to our knowledge, all previous liter-ature has handled metaphor in this way.Discrete Polysemy Model Alternatively, themetaphorical and literal senses of an adjectivemay be distinct enough that averaging the twosenses together in a single adjective matrix pro-duces representations that are not well-suited foreither metaphorical or literal phrases.
Thus, theliteral-metaphorical distinction could be problem-atic for CDSMs in the way that Baroni et al(2014) suggested that homonyms are.
Just as Kart-saklis and Sadrzadeh (2013a) solve this problemby representing each sense of a homonym by adifferent adjective matrix, we represent literal andmetaphorical senses by different adjective matri-ces.
Each literal phrase i is represented bypi= ALIT(a)ni, (2)where ALIT(a)is the literal matrix for adjective a.Likewise, a metaphorical phrase is represented bypi= AMET(a)ni, (3)where AMET(a)is the metaphorical matrix for a.Learning.
Given a data set of noun and phrasevectors D(a) = {(ni,pi)}Ni=1for AN phrases in-volving adjective a extracted using a conventionalDSM, our goal is to learn AD(a).
This can betreated as an optimization problem, of learningan estimate?AD(a)that minimizes a specified lossfunction.
In the case of the squared error loss,L(AD(a)) =?i?D(a)?pi?AD(a)ni?22, the op-timal solution can be found precisely using ordi-nary least-squares regression.
However, this mayresult in overfitting because of the large number ofparameters relative to the number of samples (i.e.,phrases).
Regularization parameters ?
= (?1, ?2)can be introduced to keep?AD(a)small:186?i?D(a)?pi??AD(a)ni?22+R(?
;?AD(a)),where R(?
;?AD) = ?1?
?AD?1+ ?2??AD?2.
Thisapproach, known as elastic-net regression (Zouand Hastie, 2005), produces better adjective matri-ces than unregularized regression (Li et al, 2014).Note that the same procedure can be used to learnthe adjective representations in both the Contex-tual Variation model and the Discrete Polysemymodel by varying what phrases are included inthe training set D(a).
In the Contextual VariationmodelD(a) includes both metaphorical and literalphrases, while in the Discrete Polysemy model itincludes only metaphorical phrases when learning?AMET(a)and testing on metaphorical phrases (andonly literal phrases when learning?ALIT(a)and test-ing on literal phrases).4.2 Experimental SetupExtracting Noun & Phrase Vectors.
Our ap-proach for constructing term vector representa-tions is similar to that of Dinu et al (2013).
Wefirst selected the 10K most frequent nouns, adjec-tives, and verbs to serve as context terms.
We thenconstructed a co-occurrence matrix that recordedterm-context co-occurrence within a symmetric5-word context window of the 50K most fre-quent POS-tagged terms in the corpus.
We thenused these co-occurrences to compute the positivepointwise mutual information (PPMI) between ev-ery pair of terms, and collected these into a term-term matrix.
Next, we reduced the dimensionalityof this matrix to 100 dimensions using singular-value decomposition.
Additionally, we computed?ground truth?
distributional vectors for all the an-notated AN phrases in our data set by treating thephrases as single terms and computing their PPMIwith the 50K single-word terms, and then project-ing them onto the same 100-dimensional basis.Training Adjective Matrices.
For each adjec-tive a that we are testing, we split the phrases in-volving that adjective into two subsets, the literal(LIT) subset and the metaphorical (MET) subset.We then split the subsets into 10 folds, so thatwe do not train and test any matrices on the samephrases.
For each fold k, we train three adjectivematrices:?AMET(a)using all phrases from the METset not in fold k;?ALIT(a)using all phrases from theLIT set not in fold k; and?ABOTH(a)using all thephrases from either subset not in fold k. Withineach fold, we use nested cross-validation as out-Figure 1: Reduction in error from training on tar-geted subset (MET/LIT) rather than on all phrases.lined in Li et al (2014) to determine the regular-ization parameters for each regression problem.4.3 Evaluating Vector RepresentationsEvaluation.
Our goal is to produce a vector pre-diction of each phrase that will be close to itsground truth distributional vector.
Phrase vectorsdirectly extracted from the corpus by treating thephrase as a single term are the gold standard forpredicting human judgment and producing para-phrases (Dinu et al, 2013), so we use these as ourground truth.
The quality of the vector predictionfor phrase i is measured using the cosine distancebetween the phrase?s ground truth vector piandthe vector prediction p?i:err(p?i) = 1?
cos(p?i,pi).We then analyze the benefit of training on a re-duced subset by calculating a ?subset improve-ment?
(SI) score for the MET and LIT subsets ofeach adjective a.
We define the SI for each subsetD(a) ?
{LIT(a),MET(a)} as:SI(D(a)) = 1?
?i?D(a)err(?AD(a)ni)?i?D(a)err(?ABOTH(a)ni)Positive values of SI thus indicate improved per-formance when trained on a reduced subset com-pared to the full set of phrases.
For exampleSILIT(a)= 5% tells us that predicting the phrasevectors for LIT phrases of adjective a using the LITmatrix resulted in a 5% reduction in mean cosineerror compared to predicting the phrase vectors us-ing the BOTH matrix.Results.
The results are summarized in Fig.
1.Each point indicates the SI for a single adjectiveand for a single subset.
Adjectives are groupedby source domain along the y-axis.
Overall, al-most every item shows a subset improvement; and,for every source domain, the majority of adjectivesshow a subset improvement.187We analyzed per-adjective SI by fitting a linearmixed-effects model, with a fixed intercept, a fixedeffect of test subset (MET vs. LIT), a random ef-fect of source domain, and the maximal converg-ing random effects structure (uncorrelated randomintercepts and slopes) (Barr et al, 2013).
Train-ing on a targeted subset improved performanceby 4.4% ?
0.009(SE) (p = .002).
There wasno evidence that this differed by test subset (i.e.,metaphorical vs. literal senses, p = .35).
The pos-itive SI from training on a targeted subset suggeststhat metaphorical and literal uses of the same ad-jective are semantically distinct.4.4 Metaphor ClassificationMethod.
The results of the previous section sug-gest a straightforward classification rule: classifyunseen phrase i involving adjective a as metaphor-ical if cos(pi,?AMET(a)ni) < cos(?ALIT(a)ni).
Oth-erwise, we classify it as literal.Evaluation.
We test this method on our data setof 8593 annotated AN phrases using 10-fold crossvalidation.
It is possible that our method?s clas-sification performance is not due to the composi-tional aspect of the model, but rather to some se-mantic coherence property among the nouns in theAN phrases that we are testing.
To control for thispossibility, we compare the performance of ourmethod against four baselines.
The first baseline,NOUN-NN, measures the cosine distance betweenthe vector for the noun of the AN phrase beingtested and the noun vectors of the nouns partici-pating in an AN phrase in the training folds.
Thetest phrase is then assigned the label of the ANphrase whose noun vector is nearest.
PHRASE-NN proceeds similarly, but using the ground-truthphrase vectors for the test phrase and the train-ing phrases.
The test phrase is then assigned thelabel of the AN phrase whose vector is nearest.The baseline NOUN-CENT first computes the cen-troid of the noun vectors of the training phrasesthat are literal, and the centroid of the noun vec-tors of the training phrases that are metaphorical.It then assigns the test phrase the label of the cen-troid whose cosine distance from the test phrase?snoun vector is smallest.
PHRASE-CENT, proceedssimilarly, but using phrase vectors.
We measureperformance against the manual annotations.Results.
Our classification method achieved aheld-out F-score of 0.817, recall of 0.793, preci-sion of 0.842, and accuracy of 0.809.
These re-Method F-score Precision Recall AccuracyMET-LIT 0.817 0.842 0.793 0.809NOUN-NN 0.709 0.748 0.675 0.703PHRASE-NN 0.590 0.640 0.547 0.592NOUN-CENT 0.717 0.741 0.695 0.706PHRASE-CENT 0.629 0.574 0.695 0.559Table 1: Performance of the method of ?4.4 (MET-LIT) against various baselines.sults were superior to those of the baselines (Table1).
These results are competitive with the state ofthe art and demonstrate the importance of compo-sitionality in metaphor identification.5 Metaphors as Linear TransformationsOne of the principal claims of the CM hypothesisis that CMs are productive: A CM (i.e., mapping)can generate endless new LMs (i.e., linguistic ex-pressions).
Cases where the LMs involve an ad-jective that has already been used metaphoricallyand for which we have annotated metaphorical andliteral examples can be handled by the methodsof ?4, but when the novel LM involves an ad-jective that has only been observed in literal us-age, we need a more elaborate model.
Accordingto the CM hypothesis, an adjective?s metaphori-cal meaning is a result of the action of a source-to-target CM mapping on the adjective?s literalsense.
If so, then given an appropriate represen-tation of this mapping it should be possible to in-fer the metaphorical sense of an adjective withoutever seeing metaphorical exemplars?that is, us-ing only the adjective?s literal sense.
Our next ex-periments seek to determine whether it is possi-ble to represent and learn CM mappings as linearmaps in distributional vector space.5.1 ModelWe model each CM mapping M from source totarget domain as a linear transformation CM:AMET(a)ni?
CMALIT(a)ni(4)We can apply a two-step regression to learn CM.First we apply elastic-net regression to learn theliteral adjective matrix?ALIT(a)as in ?4.2.
Thenwe can substitute this estimate into Eq.
(4), andapply elastic-net regression to learn the?CMthatminimizes the regularized squared error loss:?a?M?i?D(a)?pi??CM?ALIT(ai)ni?22+R(?
;?CM).188To learn CMin this regression problem, we canpool together and train on phrases from many dif-ferent adjectives that participate inM.5.2 Experimental SetupWe used a cross-validation scheme where wetreated each adjective in a source domain as a foldin training the domain?s metaphor transformationmatrix.
The nested cross-validation procedure weuse to set regularization parameters ?
and evalu-ate performance requires at least 3 adjectives in asource domain, so we evaluate on the 6 source do-main classes containing at least 3 adjectives.
Thetotal number of phrases for these 19 adjectives is6987 (3659 metaphorical, 3328 literal).5.3 Evaluating Vector RepresentationsEvaluation.
We wish to test whether CM map-pings learned from one set of adjectives are trans-ferable to new adjectives for which metaphoricalphrases are unseen.
As in ?4, models were eval-uated using cosine error compared to the groundtruth phrase vector representation.
Since ourgoal is to improve the vector representation ofmetaphorical phrases given no metaphorical an-notations, we measure performance on the METphrase subset for each adjective.
We comparethe performance of the transformed LIT matrixCMALIT(a)against the performance of the orig-inal LIT matrix ALIT(a)by defining the metaphortransformation improvement (MTI) as:MTI(a) = 1??i?METerr(CM?ALIT(a))?i?METerr(?ALIT(a)).Results.
Per-adjective MTI was analyzed with alinear mixed-effects model, with a fixed intercept,a random effect of source domain, and random in-tercepts.
Transforming the LIT matrix using theCM mapping matrix improved performance by11.5% ?
0.023(SE) (p < .001).
On average,performance improved for 18 of 19 adjectives andfor every source domain (p = .03, binomial test;Fig.
2).
Thus, mapping structure is indeed sharedacross adjectives participating in the same CM.5.4 Metaphor ClassificationMethod.
Once again our results suggest a pro-cedure for metaphor classification.
This pro-cedure can classify phrases involving adjectiveswithout seeing any metaphorical annotations.For any unseen phrase i involving an adjec-tive ai, we classify the phrase as metaphoricalFigure 2: Reduction in error from transformingLIT matrix using metaphorical mapping.
Meanchange was positive for every domain (largeblack), and for all but one adjective (small red).Method F-score Precision Recall AccuracyTRANS-LIT 0.793 0.716 0.819 0.804MET-LIT 0.838 0.856 0820 0.833NOUN-NN 0.692 0.732 0.655 0.693PHRASE-NN 0.575 0.625 0.532 0.587NOUN-CENT 0.703 0.722 0.685 0.696PHRASE-CENT 0.610 0.552 0.681 0.542Table 2: Performance of method of ?5.4 (TRANS-LIT) against method of ?4.4 (MET-LIT) and vari-ous baselines.if cos(pi,?CM?ALIT(ai)ni) < cos(pi,?ALIT(ai)ni).Otherwise, we classify it as literal.
We used thesame procedure as in ?4.2 to learn?ALIT(ai).Results.
Our method achieved an F-score of0.793 on the classification of phrases involvingunseen adjectives.
On this same set of phrases,the method of ?4.4 achieved an F-score of 0.838.Once again, the performance of our method wassuperior to the performance of the baselines (Ta-ble 2; the MET-LIT figures in Table 2 differ slightlyfrom those in Table 1 because only 19 of 23 adjec-tives are tested).
For comparison, we also includethe classification performance using the MET-LITmethod of ?4.4.
While MET-LIT slightly outper-forms TRANS-LIT, the latter has the benefit of notneeding annotations for metaphorical phrases forthe test adjective.
Hence, our approach is gener-alizable to cases where such annotations are un-available with only slight performance reduction.6 DiscussionOverall, our results show that taking metaphor intoaccount has the potential to improve CDSMs andexpand their domain of applicability.
The findingsof ?4 suggest that collapsing across metaphoricaland literal uses may hurt accuracy of vector rep-189resentations in CDSMs.
While the method in ?4depends on explicit annotations of metaphoricaland literal senses, the method in ?5 provides away to generalize these representations to adjec-tives for which metaphorical training data is un-available, by showing that metaphorical mappingsare transferable across adjectives from the samesource domain.
Note that an accurate matrix rep-resentation of the literal sense of each adjective isstill required in the experimental setup of ?5.
Thisparticular choice of setup allowed a proof of con-cept of the hypothesis that metaphors function ascross-domain transformations, but in principle itwould be desirable to learn transformations froma general BOTH matrix representation for any ad-jective in a source domain to its MET matrix rep-resentation.
This would enable improved vectorrepresentations of metaphorical AN phrases with-out annotation for unseen adjectives.The success of our models on the metaphorclassification tasks demonstrates that there is in-formation about metaphoricity of a phrase inher-ent in the composition of the meanings of itscomponents.
Notably, our results show that thismetaphorical compositionality can be capturedfrom corpus-derived distributional statistics.
Wealso noticed some trends at the level of individ-ual phrases.
In particular, classification perfor-mance and vector accuracy tended to be lower formetaphorical phrases whose nouns are distribu-tionally similar to nouns that tend to participatein literal phrases (e.g., reception is similar to foyerand refreshment in our corpus; warm reception ismetaphorical while warm foyer is literal).
An-other area where classification accuracy is low isin phrases with low corpus occurrence frequency.The ground truth vectors for these phrases exhibithigh sample variance and sparsity.
Many suchphrases sound paradoxical (e.g., bitter sweetness).Our results could also inform debates withincognitive science.
First, cognitive scientists de-bate whether words that are used both literallyand figuratively (e.g., long road, long meeting) arebest understood as having a single, abstract mean-ing that varies with context or two distinct but re-lated meanings.
For instance, some argue that do-mains like space, time, and number operate overa shared, generalized magnitude system, yet oth-ers maintain that our mental representation of timeand number is distinct from our mental represen-tation of space, yet inherited metaphorically fromit (Winter et al, 2015).
Our results suggest thatfigurative and literal senses involve quite differentpatterns of use.
This is statistical evidence that ad-jectives that are used metaphorically have distinctrelated senses, not a single abstract sense.Second, the Conceptual Metaphor Theory ac-count hypothesizes that LMs are an outgrowthof metaphorical thought, which is in turn anoutgrowth of embodied experiences that conflatesource and target domains?experience structuresthought, and thought structures language (Lakoff,1993).
However, recent critics have argued forthe opposite causal direction: Linguistic regulari-ties may drive the mental mapping between sourceand target domains (Hutchinson and Louwerse,2013; Casasanto, 2014; Hutchinson and Louw-erse, 2014).
Our results show that, at least for ANpairs, the semantic structure of a source domainand its mapping to a metaphorical target domainare available in the distributional statistics of lan-guage itself.
There may be no need, therefore, toinvoke embodied experience to explain the preva-lence of metaphorical thought in adult languageusers.
A lifetime of experience with literal andmetaphorical language may suffice.7 ConclusionWe have shown that modeling metaphor explicitlywithin a CDSM can improve the resulting vectorrepresentations.
According to our results, the sys-tematicity of metaphor can be exploited to learnlinear transformations that represent the action ofmetaphorical mappings across many different ad-jectives in the same semantic domain.
Our classi-fication results suggest that the compositional dis-tributional semantics of a phrase can inform clas-sification of the phrase for metaphoricity.Beyond improvements to the applications wepresented, the principles underlying our meth-ods also show potential for other tasks.
For in-stance, the LIT and MET adjective matrices andthe CM mapping matrix learned with our meth-ods could be applied to improve automated para-phrasing of AN phrases.
Our work is also directlyextendable to other syntactic constructions.
In theCDSM framework we apply, verbs would be rep-resented as third-order tensors.
Tractable and ef-ficient methods for estimating these verb tensorsare now available (Fried et al, 2015).
It may alsobe possible to extend the coverage of our systemby using automated word-sense disambiguation tobootstrap annotations and therefore construct LIT190and MET matrices in a minimally supervised fash-ion (Kartsaklis et al, 2013b).
Finally, it wouldbe interesting to investigate modeling metaphor-ical mappings as nonlinear mappings within thedeep learning framework.AcknowledgmentsThis work used the Extreme Science and Engi-neering Discovery Environment (XSEDE), whichis supported by National Science Foundation grantnumber ACI-1053575.
Ekaterina Shutova?s re-search is supported by the Leverhulme Trust EarlyCareer Fellowship.ReferencesMarco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Representingadjective-noun constructions in semantic space.
InProceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, pages1183?1193.
Association for Computational Linguis-tics.M.
Baroni, S. Bernardini, A. Ferraresi, andE.
Zanchetta.
2009.
The WaCky wide web:A collection of very large linguistically processedweb-crawled corpora.
Language Resources andEvaluation, 43(3):209?226.Marco Baroni, Raffaela Bernardi, and Roberto Zam-parelli.
2014.
Frege in space: A program of compo-sitional distributional semantics.
Linguistic Issuesin Language Technology, 9.Dale J. Barr, Roger Levy, Christoph Scheepers, andHarry J. Tily.
2013.
Random effects structure forconfirmatory hypothesis testing: Keep it maximal.Journal of Memory and Language, 68(3):255?278.Steven Bethard, Vicky Tzuyin Lai, and James H. Mar-tin.
2009.
Topic model analysis of metaphor fre-quency for psycholinguistic stimuli.
In Proceedingsof the Workshop on Computational Approaches toLinguistic Creativity, pages 9?16.
Association forComputational Linguistics.Steven Bird and Edward Loper.
2004.
NLTK: The nat-ural language toolkit.
In Proceedings of the 42ndAnnual Meeting of the Association for Computa-tional Linguistics, pages 1?4.Julia Birke and Anoop Sarkar.
2006.
A clustering ap-proach for nearly unsupervised recognition of non-literal language.
In Proceedings of the 11th Confer-ence of the European Chapter of the Association forComputational Linguistics, pages 329?336.BNC Consortium.
2007.
British National Corpus, Ver-sion 3 BNC XML edition.Gemma Boleda, Eva Maria Vecchi, Miquel Cornudella,and Louise McNally.
2012.
First-order vs. higher-order modification in distributional semantics.
InProceedings of the 2012 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning, pages1223?1233.
Association for Computational Linguis-tics.Lynne Cameron.
2003.
Metaphor in Educational Dis-course.
A&C Black, London.Daniel Casasanto.
2014.
Development of metaphori-cal thinking: The role of language.
In Mike Borkent,Barbara Dancygier, and Jennifer Hinnell, editors,Language and the Creative Mind, pages 3?18.
CSLIPublications, Stanford.Bob Coecke, Mehrnoosh Sadrzadeh, and StephenClark.
2010.
Mathematical foundations for a com-positional distributional model of meaning.
In Lin-guistic Analysis (Lambek Festschrift), pages 345?384.Jacob Cohen.
1960.
A coefficient of agreement fornominal scales.
educational and psychosocial mea-surement.Georgiana Dinu, Nghia The Pham, and Marco Baroni.2013.
General estimation and evaluation of compo-sitional distributional semantic models.
In Proceed-ings of the ACL 2013 Workshop on Continuous Vec-tor Space Models and their Compositionality (CVSC2013), pages 50?58, East Stroudsburg, Pennsylva-nia.
ACL.Jonathan Dunn.
2013a.
Evaluating the premises andresults of four metaphor identification systems.
InComputational Linguistics and Intelligent Text Pro-cessing, pages 471?486.
Springer.Jonathan Dunn.
2013b.
What metaphor identificationsystems can tell us about metaphor-in-language.
InProceedings of the First Workshop on Metaphor inNLP, pages 1?10.Katrin Erk and Sebastian Pad?o.
2010.
Exemplar-basedmodels for word meaning in context.
In Proceedingsof the ACL 2010 Conference Short Papers, pages92?97.
Association for Computational Linguistics.Joseph L. Fleiss, Jacob Cohen, and B.S.
Everitt.
1969.Large sample standard errors of kappa and weightedkappa.
Psychological Bulletin, 72(5):323.Daniel Fried, Tamara Polajnar, and Stephen Clark.2015.
Low-rank tensors for verbs in compositionaldistributional semantics.
In Proceedings of the 53ndAnnual Meeting of the Association for Computa-tional Linguistics, Beijing.Matt Gedigian, John Bryant, Srini Narayanan, and Bra-nimir Ciric.
2006.
Catching metaphors.
In Pro-ceedings of the Third Workshop on Scalable NaturalLanguage Understanding, pages 41?48, New York.Association for Computational Linguistics.191Joseph A. Goguen and D. Fox Harrell.
2005.
7 infor-mation visualisation and semiotic morphisms.
Stud-ies in Multidisciplinarity, 2:83?97.Joseph A. Goguen and D. Fox Harrell.
2010.
Style:A computational and conceptual blending-based ap-proach.
In The Structure of Style, pages 291?316.Springer, New York.Joseph Goguen.
1999.
An introduction to algebraicsemiotics, with application to user interface design.In Computation for metaphors, analogy, and agents,pages 242?291.
Springer.David Graff, Junbo Kong, Ke Chen, and KazuakiMaeda.
2003.
English Gigaword.
Linguistic DataConsortium, Philadelphia.Emiliano Guevara.
2010.
A regression model ofadjective-noun compositionality in distributional se-mantics.
In Proceedings of the 2010 Workshop onGEometrical Models of Natural Language Seman-tics, pages 33?37.
Association for ComputationalLinguistics.Ilana Heintz, Ryan Gabbard, Mahesh Srinivasan, DavidBarner, Donald S Black, Marjorie Freedman, andRalph Weischedel.
2013.
Automatic extraction oflinguistic metaphor with lda topic modeling.
In Pro-ceedings of the First Workshop on Metaphor in NLP,pages 58?66.Dirk Hovy, Shashank Srivastava, Sujay Kumar Jauhar,Mrinmaya Sachan, Kartik Goyal, Huiying Li, Whit-ney Sanders, and Eduard Hovy.
2013.
Identifyingmetaphorical word use with tree kernels.
In Pro-ceedings of the First Workshop on Metaphor in NLP,pages 52?57.Sterling Hutchinson and Max Louwerse.
2013.
Lan-guage statistics and individual differences in pro-cessing primary metaphors.
Cognitive Linguistics,24(4):667?687.Sterling Hutchinson and Max M. Louwerse.
2014.Language statistics explain the spatial?numerical as-sociation of response codes.
Psychonomic Bulletin& Review, 21(2):470?478.Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, et al2013a.
Prior disambiguation of word tensors forconstructing sentence vectors.
In Proceedings of the2013 Conference on Empirical Methods in NaturalLanguage Processing, pages 1590?1601.Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, and StephenPulman.
2013b.
Separating disambiguation fromcomposition in distributional semantics.
In Pro-ceedings of the 2013 Conference on ComputationalNatural Language Learning, pages 114?123.Saisuresh Krishnakumaran and Xiaojin Zhu.
2007.Hunting elusive metaphors using lexical resources.In Proceedings of the Workshop on Computationalapproaches to Figurative Language, pages 13?20.Association for Computational Linguistics.Werner Kuhn and Andrew U Frank.
1991.
A formal-ization of metaphors and image-schemas in user in-terfaces.
In Cognitive and linguistic aspects of geo-graphic space, pages 419?434.
Springer.George Lakoff and Mark Johnson.
1981.
Metaphorswe live by.
University of Chicago Press, Chicago.George Lakoff.
1989.
Some empirical results aboutthe nature of concepts.
Mind & Language, 4(1-2):103?129.George Lakoff.
1993.
The contemporary theory ofmetaphor.
In Andrew Ortony, editor, Metaphor andThought.
Cambridge University Press, Cambridge.Joachim Lambek.
1999.
Type grammar revisited.
InLogical aspects of computational linguistics, pages1?27.
Springer, Berlin.Linlin Li and Caroline Sporleder.
2009.
Classifiercombination for contextual idiom detection withoutlabelled data.
In Proceedings of the 2009 Confer-ence on Empirical Methods in Natural LanguageProcessing: Volume 1-Volume 1, pages 315?323.Association for Computational Linguistics.Linlin Li and Caroline Sporleder.
2010.
Using Gaus-sian mixture models to detect figurative language incontext.
In Human Language Technologies: The2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, pages 297?300.
Association for Computa-tional Linguistics.Linlin Li, Benjamin Roth, and Caroline Sporleder.2010.
Topic models for word sense disambiguationand token-based idiom detection.
In Proceedings ofthe 48th Annual Meeting of the Association for Com-putational Linguistics, pages 1138?1147.
Associa-tion for Computational Linguistics.Jiming Li, Marco Baroni, and Georgiana Dinu.
2014.Improving the lexical function composition modelwith pathwise optimized elastic-net regression.
InProceedings of the 14th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 434?442.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedmodels of semantic composition.
In ACL-08: HLT,pages 236?244.Michael Mohler, David Bracewell, David Hinote, andMarc Tomlinson.
2013.
Semantic signatures forexample-based linguistic metaphor detection.
InProceedings of the First Workshop on Metaphor inNLP, pages 27?35.Richard Montague.
1970.
English as a formal lan-guage.
In B Visentini and et al editors, Linguagginella Societ`a e nella Tecnica.
Edizioni di Comunit?a,Milan.192Yair Neuman, Dan Assaf, Yohai Cohen, Mark Last,Shlomo Argamon, Newton Howard, and OphirFrieder.
2013.
Metaphor identification in large textscorpora.
PLoS ONE, 8:e62343.Patrick Pantel and Dekang Lin.
2002.
Discoveringword senses from text.
In Proceedings of the EighthACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, pages 613?619.ACM.Barbara H. Partee.
1994.
Lexical semantics and com-positionality.
In Lila Gleitman and Mark Liberman,editors, Invitation to Cognitive Science 2nd Edition,Part I: Language.
MIT Press, Cambridge, Mass.,USA.Hinrich Sch?utze.
1998.
Automatic word sense dis-crimination.
Computational Linguistics, 24(1):97?123.Ekaterina Shutova, Lin Sun, and Anna Korhonen.2010.
Metaphor identification using verb and nounclustering.
In Proceedings of the 23rd InternationalConference on Computational Linguistics, pages1002?1010.
Association for Computational Linguis-tics.Ekatrina Shutova.
2015.
Design and evaluation ofmetaphor processing systems.
volume Forthcoming.Richard Socher, Jeffrey Pennington, Eric H. Huang,Andrew Y. Ng, and Christopher D. Manning.
2011.Semi-supervised recursive autoencoders for predict-ing sentiment distributions.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 151?161.
Association forComputational Linguistics.Richard Socher, Brody Huval, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Semantic composi-tionality through recursive matrix-vector spaces.
InProceedings of the 2012 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning, pages1201?1211.
Association for Computational Linguis-tics.David I. Spivak.
2014.
Category Theory for the Sci-ences.
MIT Press, Cambridge, Mass., USA.Caroline Sporleder and Linlin Li.
2009.
Unsupervisedrecognition of literal and non-literal use of idiomaticexpressions.
In Proceedings of the 12th Conferenceof the European Chapter of the Association for Com-putational Linguistics, pages 754?762.
Associationfor Computational Linguistics.Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann,Anna Kaal, Tina Krennmayr, and Trijntje Pasma.2010.
A method for linguistic metaphor identifica-tion: From MIP to MIPVU, volume 14.
John Ben-jamins Publishing, Amsterdam/Philadelphia.Tomek Strzalkowski, George A. Broadwell, Sarah Tay-lor, Laurie Feldman, Boris Yamrom, Samira Shaikh,Ting Liu, Kit Cho, Umit Boz, Ignacio Cases, andKyle Elliot.
2013.
Robust extraction of metaphorsfrom novel data.
In Proceedings of the First Work-shop on Metaphor in NLP, pages 67?76, Atlanta,Georgia.
Association for Computational Linguistics.Masashi Tsubaki, Kevin Duh, Masashi Shimbo, andYuji Matsumoto.
2013.
Modeling and learning se-mantic co-compositionality through prototype pro-jections and neural networks.
In The 2013 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 130?140.Yulia Tsvetkov, Elena Mukomel, and Anatole Gersh-man.
2013.
Cross-lingual metaphor detection usingcommon semantic features.Yulia Tsvetkov, Leonid Boytsov, Anatole Gershman,Eric Nyberg, and Chris Dyer.
2014.
Metaphor de-tection with cross-lingual model transfer.
In Pro-ceedings of the Annual Meeting of the Associationfor Computational Linguistics.Peter D. Turney, Yair Neuman, Dan Assaf, and YohaiCohen.
2011.
Literal and metaphorical senseidentification through concrete and abstract con-text.
In Proceedings of the 2011 Conference on theEmpirical Methods in Natural Language Process-ing, EMNLP ?11, pages 680?690, Stroudsburg, PA,USA.
Association for Computational Linguistics.Peter D. Turney.
2013.
Distributional semantics be-yond words: supervised learning of analogy andparaphrase.
Transactions of the Association forComputational Linguistics (TACL), 1:353?366.Akira Utsumi.
2006.
Computational exploration ofmetaphor comprehension processes.
In Proceedingsof the 28th Annual Meeting of the Cognitive ScienceSociety (CogSci2006), pages 2281?2286.Bodo Winter, Tyler Marghetis, and Teenie Matlock.2015.
Of magnitudes and metaphors: Explain-ing cognitive interactions between space, time, andnumber.
Cortex, 64:209?224.Hui Zou and Trevor Hastie.
2005.
Regularizationand variable selection via the elastic net.
Journalof the Royal Statistical Society: Series B (StatisticalMethodology), 67(2):301?320.193
