Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 182?189,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsDomain Adaptation for Statistical Machine Translationwith Monolingual ResourcesNicola Bertoldi Marcello FedericoFBK-irst - Ricerca Scientifica e TecnologicaVia Sommarive 18, Povo (TN), Italy{bertoldi, federico}@fbk.euAbstractDomain adaptation has recently gainedinterest in statistical machine translationto cope with the performance drop ob-served when testing conditions deviatefrom training conditions.
The basic ideais that in-domain training data can be ex-ploited to adapt all components of an al-ready developed system.
Previous workshowed small performance gains by adapt-ing from limited in-domain bilingual data.Here, we aim instead at significant per-formance gains by exploiting large butcheap monolingual in-domain data, eitherin the source or in the target language.We propose to synthesize a bilingual cor-pus by translating the monolingual adap-tation data into the counterpart language.Investigations were conducted on a state-of-the-art phrase-based system trained onthe Spanish?English part of the UN cor-pus, and adapted on the correspondingEuroparl data.
Translation, re-ordering,and language models were estimated aftertranslating in-domain texts with the base-line.
By optimizing the interpolation ofthese models on a development set theBLEU score was improved from 22.60%to 28.10% on a test set.1 IntroductionA well-known problem of Statistical MachineTranslation (SMT) is that performance quickly de-grades as soon as testing conditions deviate fromtraining conditions.
The very simple reason is thatthe underlying statistical models always tend toclosely approximate the empirical distributions ofthe training data, which typically consist of bilin-gual texts and monolingual target-language texts.The former provide a means to learn likely trans-lations pairs, the latter to form correct sentenceswith translated words.
Besides the general diffi-culties of language translation, which we do notconsider here, there are two aspects that makemachine learning of this task particularly hard.First, human language has intrinsically very sparsestatistics at the surface level, hence gaining com-plete knowledge on translation phrase pairs or tar-get language n-grams is almost impractical.
Sec-ond, language is highly variable with respect toseveral dimensions, style, genre, domain, topics,etc.
Even apparently small differences in domainmight result in significant deviations in the un-derlying statistical models.
While data sparsenesscorroborates the need of large language samples inSMT, linguistic variability would indeed suggestto consider many alternative data sources as well.By rephrasing a famous saying we could say that?no data is better than more and assorted data?.The availability of language resources for SMThas dramatically increased over the last decade,at least for a subset of relevant languages and es-pecially for what concerns monolingual corpora.Unfortunately, the increase in quantity has notgone in parallel with an increase in assortment, es-pecially for what concerns the most valuable re-source, that is bilingual corpora.
Large paralleldata available to the research community are forthe moment limited to texts produced by interna-tional organizations (European Parliament, UnitedNations, Canadian Hansard), press agencies, andtechnical manuals.The limited availability of parallel data poseschallenging questions regarding the portability ofSMT across different application domains and lan-guage pairs, and its adaptability with respect tolanguage variability within the same applicationdomain.This work focused on the second issue, namelythe adaptation of a Spanish-to-English phrase-based SMT system across two apparently closedomains: the United Nation corpus and the Euro-182pean Parliament corpus.
Cross-domain adaptationis faced under the assumption that only monolin-gual texts are available, either in the source lan-guage or in the target language.The paper is organized as follows.
Section 2presents previous work on the problem of adap-tation in SMT; Section 3 introduces the exemplartask and research questions we addressed; Sec-tion 4 describes the SMT system and the adapta-tion techniques that were investigated; Section 5presents and discusses experimental results; andSection 6 provides conclusions.2 Previous WorkDomain adaptation in SMT has been investigatedonly recently.
In (Eck et al, 2004) adaptation islimited to the target language model (LM).
Thebackground LM is combined with one estimatedon documents retrieved from the WEB by usingthe input sentence as query and applying cross-language information retrieval techniques.
Refine-ments of this approach are described in (Zhao etal., 2004).In (Hildebrand et al, 2005) information retrievaltechniques are applied to retrieve sentence pairsfrom the training corpus that are relevant to the testsentences.
Both the language and the translationmodels are retrained on the extracted data.In (Foster and Kuhn, 2007) two basic settings areinvestigated: cross-domain adaptation, in whicha small sample of parallel in-domain text is as-sumed, and dynamic adaptation, in which onlythe current input source text is considered.
Adap-tation relies on mixture models estimated on thetraining data through some unsupervised cluster-ing method.
Given available adaptation data, mix-ture weights are re-estimated ad-hoc.
A varia-tion of this approach was also recently proposedin (Finch and Sumita, 2008).
In (Civera and Juan,2007) mixture models are instead employed toadapt a word alignment model to in-domain par-allel data.In (Koehn and Schroeder, 2007) cross-domainadaptation techniques were applied on a phrase-based SMT trained on the Europarl task, in or-der to translate news commentaries, from Frenchto English.
In particular, a small portion of in-domain bilingual data was exploited to adapt theEuroparl language model and translation modelsby means of linear interpolation techniques.
Ueff-ing et al (2007) proposed several elaborate adap-tation methods relying on additional bilingual datasynthesized from the development or test set.Our work is mostly related to (Koehn andSchroeder, 2007) but explores different assump-tions about available adaptation data: i.e.
onlymonolingual in-domain texts are available.
Theadaptation of the translation and re-ordering mod-els is performed by generating synthetic bilingualdata from monolingual texts, similarly to whatproposed in (Schwenk, 2008).
Interpolation ofmultiple phrase tables is applied in a more prin-cipled way than in (Koehn and Schroeder, 2007):all entries are merged into one single table, cor-responding feature functions are concatenated andsmoothing is applied when observations are miss-ing.
The approach proposed in this paper hasmany similarities with the simplest technique in(Ueffing et al, 2007), but it is applied to a muchlarger monolingual corpus.Finally, with respect to previous work we alsoinvestigate the behavior of the minimum errortraining procedure to optimize the combination offeature functions on a small in-domain bilingualsample.3 Task descriptionThis paper addresses the issue of adapting an al-ready developed phrase-based translation systemin order to work properly on a different domain,for which almost no parallel data are available butonly monolingual texts.1The main components of the SMT system arethe translation model, which aims at porting thecontent from the source to the target language, andthe language model, which aims at building fluentsentences in the target language.
While the formeris trained with bilingual data, the latter just needsmonolingual target texts.
In this work, a lexical-ized re-ordering model is also exploited to controlre-ordering of target words.
This model is alsolearnable from parallel data.Assuming some large monolingual in-domaintexts are available, two basic adaptation ap-proaches are pursued here: (i) generating syn-thetic bilingual data with an available SMT sys-tem and use this data to adapt its translation andre-ordering models; (ii) using synthetic or pro-vided target texts to also, or only, adapt its lan-guage model.
The following research questions1We assume only availability of a development set and anevaluation set.183summarize our basic interest in this work:?
Is automatic generation of bilingual data ef-fective to tackle the lack of parallel data??
Is it more effective to use source languageadaptation data or target language adaptationdata??
Is it convenient to combine models learnedfrom adaptation data with models learnedfrom training data??
How can interpolation of models be effec-tively learned from small amounts of in-domain parallel data?4 System descriptionThe investigation presented in this paper was car-ried out with the Moses toolkit (Koehn et al,2007), a state-of-the-art open-source phrase-basedSMT system.
We trained Moses in a standard con-figuration, including a 4-feature translation model,a 7-feature lexicalized re-ordering model, one LM,word and phrase penalties.The translation and the re-ordering model re-lied on ?grow-diag-final?
symmetrized word-to-word alignments built using GIZA++ (Och andNey, 2003) and the training script of Moses.
A5-gram language model was trained on the tar-get side of the training parallel corpus using theIRSTLM toolkit (Federico et al, 2008), exploitingModified Kneser-Ney smoothing, and quantizingboth probabilities and backoff weights.
Decodingwas performed applying cube-pruning with a pop-limit of 6000 hypotheses.Log-linear interpolations of feature functionswere estimated with the parallel version of mini-mum error rate training procedure distributed withMoses.4.1 Fast Training from Synthetic DataThe standard procedure of Moses for the estima-tion of the translation and re-ordering models froma bilingual corpus consists in three main steps:1.
A word-to-word alignment is generated withGIZA++.2.
Phrase pairs are extracted from the word-to-word alignment using the method proposedby (Och and Ney, 2003); countings and re-ordering statistics of all pairs are stored.
Aword-to-word lexicon is built as well.3.
Frequency-based and lexicon-based directand inverted probabilities, and re-orderingprobabilities are computed using statisticsfrom step 2.Recently, we enhanced Moses decoder to alsooutput the word-to-word alignment between theinput sentence and its translation, given that theyhave been added to the phrase table at trainingtime.
Notice that the additional information intro-duces an overhead in disk usage of about 70%, butpractically no overhead at decoding time.
How-ever, when training translation and re-orderingmodels from synthetic data generated by the de-coder, this feature allows to completely skip thetime-expensive step 1.2We tested the efficiency of this solution fortraining a translation model on a synthesized cor-pus of about 300K Spanish sentences and 8.8Mrunning words, extracted from the EuroParl cor-pus.
With respect to the standard procedure, thetotal training time was reduced by almost 50%,phrase extraction produced 10% more phrasepairs, and the final translation system showed aloss in translation performance (BLEU score) be-low 1% relative.
Given this outcome we decidedto apply the faster procedure in all experiments.4.2 Model combinationOnce monolingual adaptation data is automati-cally translated, we can use the synthetic parallelcorpus to estimate new language, translation, andre-ordering models.
Such models can either re-place or be combined with the original models ofthe SMT system.
There is another simple optionwhich is to concatenate the synthetic parallel datawith the original training data and re-build the sys-tem.
We did not investigate this approach becauseit does not allow to properly balance the contribu-tion of different data sources, and also showed tounderperform in preliminary work.Concerning the combination of models, in thefollowing we explain how Moses was extendedto manage multiple translation models (TMs) andmultiple re-ordering models (RMs).4.3 Using multiple models in MosesIn Moses, a TM is provided as a phrase table,which is a set S = {(f?
, e?)}
of phrase pairs as-sociated with a given number of features values2Authors are aware of an enhanced version of GIZA++,which allows parallel computation, but it was not taken intoaccount in this work.184h(f?
, e?;S).
In our configuration, 5 features for theTM (the phrase penalty is included) are taken intoaccount.In the first phase of the decoding process, Mosesgenerates translation options for all possible in-put phrases f?
through a lookup into S; it simplyextracts alternative phrase pairs (f?
, e?)
for a spe-cific f?
and optionally applies pruning (based onthe feature values and weights) to limit the num-ber of such pairs.
In the second phase of decod-ing, it creates translation hypotheses of the fullinput sentence by combining in all possible ways(satisfying given re-ordering constraints) the pre-fetched translation options.
In this phase the hy-potheses are scored, according to all features func-tions, ranked, and possibly pruned.When more TMs Sj are available, Moses canbehave in two different ways in pre-fetching thetranslation options.
It searches a given f?
in all setsand keeps a phrase pair (f?
, e?)
if it belongs to eitheri) their intersection or ii) their union.
The formermethod corresponds to building one new TM SI ,whose set is the intersection of all given sets:SI = {(f?
, e?)
| ?j (f?
, e?)
?
Sj}The set of features of the new TM is the union ofthe features of all single TMs.
Straightforwardly,all feature values are well-defined.The second method corresponds to building onenew TM SU , whose set is the union of all givensets:SU = {(f?
, e?)
| ?j (f?
, e?)
?
Sj}Again, the set of features of the new TM is theunion of the features of all single TMs; but for aphrase pair (f?
, e?)
belonging to SU \Sj , the featurevalues h(f?
, e?
;Sj) are undefined.
In these unde-fined situations, Moses provides a default value of0, which is the highest available score, as the fea-ture values come from probabilistic distributionsand are expressed as logarithms.
Henceforth, aphrase pair belonging to all original sets is penal-ized with respect to phrase pairs belonging to fewof them only.To address this drawback, we proposed anew method3 to compute a more reliable andsmoothed score in the undefined case, based onthe IBM model 1 (Brown et al, 1993).
If (f?
=f1, .
.
.
, fl, e?
= e1, .
.
.
, el) ?
SU \ Sj for any j the3Authors are not aware of any work addressing this issue.phrase-based and lexical-based direct features aredefined as follows:h(f?
, e?
;Sj) =(l + 1)mm?k=1l?h=0?
(ek | fh)Here, ?
(ek | fh) is the probability of ek given fhprovided by the word-to-word lexicon computedon Sj .
The inverted features are defined simi-larly.
The phrase penalty is trivially set to 1.
Thesame approach has been applied to build the unionof re-ordering models.
In this case, however, thesmoothing value is constant and set to 0.001.As concerns as the use of multiple LMs, Moseshas a very easy policy, consisting of querying eachof them to get the likelihood of a translation hy-potheses, and uses all these scores as features.It is worth noting that the exploitation of mul-tiple models increases the number of features ofthe whole system, because each model adds itsset of features.
Furthermore, the first approach ofMoses for model combination shrinks the size ofthe phrase table, while the second one enlarges it.5 Evaluation5.1 Data DescriptionIn this work, the background domain is given bythe Spanish-English portion of the UN parallelcorpus,4 composed by documents coming fromthe Office of Conference Services at the UN inNew York spanning the period between 1988 and1993.
The adaptation data come from the Eu-ropean Parliament corpus (Koehn, 2002) (EP) asprovided for the shared translation task of the2008 Workshop on Statistical Machine Transla-tion.5 Development and test sets for this task,namely dev2006 and test2008, are supplied aswell, and belong to the European Parliament do-main.We use the symbol S?
(E?)
to denote syntheticSpanish (English) data.
Spanish-to-English andEnglish-to-Spanish systems trained on UN datawere exploited to generate English and Spanishsynthetic portions of the original EP corpus, re-spectively.
In this way, we created two syntheticversions of the EP corpus, named SE?-EP and S?E-EP, respectively.
All presented translation systemswere optimized on the dev2006 set with respect to4Distributed by the Linguistic Data Consortium, cata-logue # LDC94T4A.5http://www.statmt.org/wmt08185the BLEU score (Papineni et al, 2002), and testedon test2008.
(Notice that one reference translationis available for both sets.)
Table 1 reports statisticsof original and synthetic parallel corpora, as wellof the employed development and evaluation datasets.
All the texts were just tokenized and mixedcase was kept.
Hence, all systems were developedto produce case-sensitive translations.corpus sent Spanish Englishword dict word dictUN 2.5M 50.5M 253K 45.2M 224KEP 1.3M 36.4M 164K 35.0M 109KSE?-EP 1.3M 36.4M 164K 35.4M 133KS?E-EP 1.3M 36.2M 120K 35.0M 109Kdev 2,000 60,438 8,173 58,653 6,548test 2,000 61,756 8,331 60,058 6,497Table 1: Statistics of bilingual training corpora,development and test data (after tokenization).5.2 Baseline systemsThree Spanish-to-English baseline systems weretrained by exploiting different parallel or mono-lingual corpora summarized in the first three linesin Table 2.
For each system, the table reports theperplexity and out-of-vocabulary (OOV) percent-age of their LM, and its translation performanceachieved on the test set in terms of BLEU score,NIST score, WER (word error rate) and PER (po-sition independent error rate).The distance in style, genre, jargon, etc.
be-tween the UN and the EP corpora is made evidentby the gap in perplexity (Federico and De Mori,1998) and OOV percentage between their EnglishLMs: 286 vs 74 and 1.12% vs 0.15%, respectively.Performance of the system trained on the EPcorpus (third row) can be taken as an upper boundfor any adaptation strategy trying to exploit partsof the EP corpus, while those of the first lineclearly provide the corresponding lower-bound.The system in the second row can instead be con-sider as the lower bound when only monolingualEnglish adaptation data are assumed.The synthesis of the SE?-EP corpus was per-formed with the system trained just on the UNtraining data (first row of Table 2), because we hadassumed that the in-domain data were only mono-lingual Spanish and thus not useful for neither theTM, RM nor target LM estimation.Similarly, the system in the last row of Table 2was developed on the UN corpus to translate theEnglish part of the EP data to generate the syn-thetic S?E-EP corpus.
Again, any in-domain datawere exploited to train this sytem.
Of course, thissystem cannot be compared with any other be-cause of the different translation direction.In order to compare reported performance withthe state-of-the-art, Table 2 also reports resultsof the best system published in the EuroMatrixproject website6 and of the Google online trans-lation engine.75.3 Analysis of the tuning processIt is well-known that tuning the SMT system isfundamental to achieve good performance.
Thestandard tuning procedure consists of a minimumerror rate training (mert) (Och and Ney, 2003)which relies on the availability of a developmentdata set.
On the other hand, the most importantassumption we make is that almost no parallel in-domain data are available.conf sent n-best time (min) BLEU (?)?
?
?
?
22.28a 2000 1000 2034 23.68 (1.40)b 2000 200 391 23.67 (1.39)c 200 1000 866 23.13 (0.85)d 200 200 551 23.54 (1.26)Table 3: Global time, not including decoding, ofthe tuning process and BLEU score achieved onthe test set by the uniform interpolation weights(first row), and by the optimal weights with differ-ent configurations of the tuning parameters.In a preliminary phase, we investigated differentsettings of the tuning process in order to under-stand how much development data is required toperform a reliable weight optimization.
Our mod-els were trained on the SE?-EP parallel corpus andby using uniform interpolation weights the systemachieved a BLEU score of 22.28% on the test set(see Table 3).We assumed to dispose of either a regularin-domain development set of 2,000 sentences(dev2006), or a small portion of it of just 200 sen-6http://www.euromatrix.net.
Translations of the best sys-tem were downloaded on November 7th, 2008.
Publishedresults differ because we performed a case-sensitive evalua-tion.7Google was queried on November 3rd, 2008.186language pair training data PP OOV (%) BLEU NIST WER PERTM/RM LMSpanish-English UN UN 286 1.12 22.60 6.51 64.60 48.52?
UN EP 74 0.15 27.83 7.12 60.93 45.19?
EP EP ?
?
32.80 7.84 56.47 41.15?
UN SE?-EP 89 0.21 23.52 6.64 63.86 47.68?
SE?-EP SE?-EP ?
?
23.68 6.65 63.64 47.56?
S?E-EP EP 74 0.15 28.10 7.18 60.86 44.85?
Google na na 28.60 7.55 57.38 57.38?
Euromatrix na na 32.99 7.86 56.36 41.12English-Spanish UN UN 281 1.39 23.24 6.44 65.81 49.61Table 2: Description and performance on the test set of compared systems in terms of perplexity, out-of-vocabulary percentage of their language model, and four translation scores: BLEU, NIST, word-error-rate, and position-independent error rate.
Systems were optimized on the dev2006 development set.050010001500200025005  10  15  20  25  30  35time (minutes)iterationa) large dev, 1000 bestb) large dev, 200 bestc) small dev, 1000 bestd) small dev, 200 best1920212223245  10  15  20  25  30  35BLEU(%)iterationa) large dev, 1000 bestb) large dev, 200 bestc) small dev, 1000 bestd) small dev, 200 bestFigure 1: Incremental time of the tuning process (not including decoding phase) (left) and BLEU score onthe test set using weights produced at each iteration of the tuning process.
Four different configurationsof the tuning parameters are considered.tences.
Moreover, we tried to employ either 1,000-best or 200-best translation candidates during themert process.From a theoretical point of view, computationaleffort of the tuning process is proportional to thesquare of the number of translation alternativesgenerated at each iteration times the number of it-erations until convergence.Figure 1 reports incremental tuning time andtranslation performance on the test set at each it-eration.
Notice that the four tuning configurationsare ranked in order of complexity.
Table 3 sum-maries the final performance of each tuning pro-cess, after convergence was reached.Notice that decoding time is not included in thisplot, as Moses allows to perform this step in par-allel on a computer cluster.
Hence, to our viewthe real bottleneck of the tuning process is actu-ally related to the strictly serial part of the mertimplementation of Moses.As already observed in previous literature(Macherey et al, 2008), first iterations of the tun-ing process produces very bad weights (even closeto 0); this exceptional performance drop is at-tributed to an over-fitting on the candidate reposi-tory.Configurations exploiting the small develop-ment set (c,d) show a slower and more unstableconvergence; however, their final performance inTable 3 result only slightly lower than that ob-tained with the standard dev sets (a, b).
Due to thelarger number of iterations they needed, both con-figurations are indeed more time consuming thanthe intermediate configuration (b), which seemsthe best one.
In conclusion, we found that the sizeof the n-best list has essentially no effect on thequality of the final weights, but it impacts signif-icantly on the computational time.
Moreover, us-ing the regular development set with few transla-tion alternatives ends up to be the most efficient187configuration in terms of computational effort, ro-bustness, and performance.Our analysis suggests that it is important to dis-pose of a sufficiently large development set although reasonably good weights can be obtainedeven if such data are very few.5.4 LM adaptationA set of experiments was devoted to the adapta-tion of the LM only.
We trained three differentLMs on increasing portions of the EP and we em-ployed them either alone or in combination withthe background LM trained on the UN corpus.2 LMs (+UN)1 LM202224263010050250BLEU(%)Percentage of monolingual English adaptation data28Figure 2: BLEU scores achieved by systems ex-ploiting one or two LMs trained on increasing per-centages of English in-domain data.Figure 2 reports BLEU score achieved by thesesystems.
The absolute gain with respect to thebaseline is fairly high, even with the smallestamount of adaptation data (+4.02).
The benefitof using the background data together with in-domain data is very small, and rapidly vanishesas the amount of such data increases.If English synthetic texts are employed to adaptthe LM component, the increase in performanceis significantly lower but still remarkable (see Ta-ble 2).
By employing all the available data, thegain in BLEU% score was of 4% relative, that isfrom 22.60 to 23.52.5.5 TM and RM adaptationAnother set of experiments relates to the adapta-tion of the TM and the RM.
In-domain TMs andRMs were estimated on three different versions ofthe full parallel EP corpus, namely EP, SE?-EP, andS?E-EP.
In-domain LMs were trained on the cor-responding English side.
All in-domain modelswere either used alone or combined with the base-line models according to multiple-model paradigmexplained in Section 4.3.
Tuning of the interpola-tion weights was performed on the standard devel-opment set as usual.
Results of these experimentsare reported in Figure 3.Results suggest that regardless of the used bilin-gual corpora the in-domain TMs and RMs workbetter alone than combined with the original mod-els.
We think that this behavior can be explainedby a limited disciminative power of the result-ing combined model.
The background translationmodel could contain phrases which either do ordo not fit the adaptation domain.
As the weightsare optimized to balance the contribution of allphrases, the system is not able to well separate thepositive examples from the negative ones.
In ad-dition to it, system tuning is much more complexbecause the number of features increases from 14to 26.Finally, TMs and RMs estimated from syntheticdata show to provide smaller, but consistent, con-tributions than the corresponding LMs.
When En-glish in-domain data is provided, BLEU% scoreincreases from 22.60 to 28.10; TM and RM con-tribute by about 5% relative, by covering the gapfrom 27.83 to 28.10.
When Spanish in-domaindata is provided BLEU% score increases from22.60 to 23.68; TM and RM contribute by about15% relative, by covering the gap from 23.52 to23.68 .Summarizing, the most important role in the do-main adaptation is played by the LM; neverthelessthe adaptation of the TM and RM gives a smallfurther improvement..2 TMs, RMs, LMs (+UN)1 TM, RM, LM20222426283234bilingualEnglishSpanishnothingBLEU(%)Type of adaptation data30Figure 3: BLEU scores achieved by system ex-ploiting both TM, RM and LM trained on differentcorpora.6 ConclusionThis paper investigated cross-domain adaptationof a state-of-the-art SMT system (Moses), by ex-ploiting large but cheap monolingual data.
Weproposed to generate synthetic parallel data by188translating monolingual adaptation data with abackground system and to train statistical modelsfrom the synthetic corpus.We found that the largest gain (25% relative) isachieved when in-domain data are available for thetarget language.
A smaller performance improve-ment is still observed (5% relative) if source adap-tation data are available.
We also observed that themost important role is played by the LM adapta-tion, while the adaptation of the TM and RM givesconsistent but small improvement.We also showed that a very tiny development setof only 200 parallel sentences is adequate enoughto get comparable performance as a 2000-sentenceset.Finally, we described how to reduce the timefor training models from a synthetic corpus gen-erated through Moses by 50% at least, by exploit-ing word-alignment information provided duringdecoding.ReferencesPeter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
Themathematics of statistical machine translation: Pa-rameter estimation.
Computational Linguistics,19(2):263?312.Jorge Civera and Alfons Juan.
2007.
Domain adap-tation in statistical machine translation with mixturemodelling.
In Proceedings of the Second Workshopon Statistical Machine Translation, pages 177?180,Prague, Czech Republic.Matthias Eck, Stephan Vogel, and Alex Waibel.
2004.Language model adaptation for statistical machinetranslation based on information retrieval.
In Pro-ceedings of the International Conference on Lan-guage Resources and Evaluation (LREC), pages327?330, Lisbon, Portugal.Marcello Federico and Renato De Mori.
1998.
Lan-guage modelling.
In Renato DeMori, editor, SpokenDialogues with Computers, chapter 7, pages 199?230.
Academy Press, London, UK.Marcello Federico, Nicola Bertoldi, and Mauro Cet-tolo.
2008.
Irstlm: an open source toolkit for han-dling large scale language models.
In Proceedingsof Interspeech, pages 1618?1621, Melbourne, Aus-tralia.Andrew Finch and Eiichiro Sumita.
2008.
Dy-namic model interpolation for statistical machinetranslation.
In Proceedings of the Third Workshopon Statistical Machine Translation, pages 208?215,Columbus, Ohio.George Foster and Roland Kuhn.
2007.
Mixture-model adaptation for SMT.
In Proceedings of theSecond Workshop on Statistical Machine Transla-tion, pages 128?135, Prague, Czech Republic.Almut Silja Hildebrand, Matthias Eck, Stephan Vo-gel, and Alex Waibel.
2005.
Adaptation of thetranslation model for statistical machine translationbased on information retrieval.
In Proceedings ofthe 10th Conference of the European Association forMachine Translation (EAMT), pages 133?142, Bu-dapest.Philipp Koehn and Josh Schroeder.
2007.
Experi-ments in domain adaptation for statistical machinetranslation.
In Proceedings of the Second Workshopon Statistical Machine Translation, pages 224?227,Prague, Czech Republic.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics Companion Volume Proceed-ings of the Demo and Poster Sessions, pages 177?180, Prague, Czech Republic.Philipp Koehn.
2002.
Europarl: A multilingual corpusfor evaluation of machine translation.
Unpublished,http://www.isi.edu/?koehn/europarl/.Wolfgang Macherey, Franz Och, Ignacio Thayer, andJakob Uszkoreit.
2008.
Lattice-based minimum er-ror rate training for statistical machine translation.In Proceedings of the 2008 Conference on Empiri-cal Methods in Natural Language Processing, pages725?734, Honolulu, Hawaii.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting of the Association ofComputational Linguistics (ACL), pages 311?318,Philadelphia, PA.Holger Schwenk.
2008.
Investigations on Large-ScaleLightly-Supervised Training for Statistical MachineTranslation.
In Proc.
of the International Workshopon Spoken Language Translation, pages 182?189,Hawaii, USA.Nicola Ueffing, Gholamreza Haffari, and AnoopSarkar.
2007.
Semi-supervised model adaptationfor statistical machine translation.
Machine Trans-lation, 21(2):77?94.Bing Zhao, Matthias Eck, and Stephan Vogel.
2004.Language model adaptation for statistical machinetranslation via structured query models.
In Pro-ceedings of Coling 2004, pages 411?417, Geneva,Switzerland.189
