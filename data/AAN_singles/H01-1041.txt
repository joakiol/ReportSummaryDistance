Interlingua-Based Broad-Coverage Korean-to-EnglishTranslation in CCLINCYoung-Suk Lee               Wu Sok Yi            Stephanie Seneff        Clifford J. WeinsteinMIT Lincoln Laboratory     MIT Lincoln Laboratory                 MIT/LCS                     MIT Lincoln Laboratory244 Wood Street               244 Wood Street               77 Mass Avenue                     244 Wood StreetLexington, MA 02420         Lexington, MA 02420      Cambridge, MA 02673             Lexington, MA 02420U.S.A                                   U.S.A                                U.S.A                                       U.S.A1-781-981-2703                 1-781-981-4609                1-617-254-0456             1-781-981-7621YSL@LL.MIT.EDU           WUYI@LL.MIT.EDU     SENEFF@LCS.MIT.EDU          CJW@LL.MIT.EDUABSTRACTAt MIT Lincoln Laboratory, we have been developing a Korean-to-English machine translation system CCLINC (CommonCoalition Language System at Lincoln Laboratory).
The CCLINCKorean-to-English translation system  consists of two coremodules, language understanding and generation modulesmediated by a language neutral meaning representation called asemantic frame.
The key features of the system include: (i) Robustefficient parsing of Korean (a verb final language with overt casemarkers, relatively free word order, and frequent omissions ofarguments).
(ii) High quality translation via word sensedisambiguation and accurate word order generation of  the targetlanguage.
(iii) Rapid system development and porting to newdomains via knowledge-based automated acquisition ofgrammars.
Having been trained on Korean newspaper articles on?missiles?
and ?chemical biological warfare,?
the system producesthe translation output sufficient for content understanding of theoriginal document.1.
SYSTEM OVERVIEWThe CCLINC  The CCLINC Korean-to-English translationsystem is a component of the CCLINC Translingual InformationSystem, the focus languages of which are English and Korean,[11,17].
Translingual Information System Structure is given inFigure 1.Given the input text or speech, the language understanding systemparses the input, and transforms the parsing output into a languageneutral meaning representation called a semantic frame, [16,17].The semantic frame ?
the key properties of which will bediscussed in Section 2.3 ?
becomes the input to the generationsystem.
The generation system produces the target to thegeneration system, the semantic frame can be utilized for otherapplications such as translingual information extraction andlanguage translation output after word order arrangement,vocabulary replacement, and the appropriate surface formrealization in the target language, [6].
Besides serving as the inputquestion-answering, [12].?
In this paper, we focus on the Korean-to-English text  translation component of CCLINC.1Figure 1.
CCLINC Translingual Information SystemStructure2.
ROBUST PARSING, MEANINGREPRESENTATION, AND AUTOMATEDGRAMMAR ACQUISITION?
This work was sponsored by the Defense Advanced ResearchProject Agency under the contract number F19628-00-C-0002.Opinions, interpretations, conclusions, and recommendationsare those of the authors and are not necessarily endorsed by theUnited States Air Force.1 For other approaches to Korean-to-English translation, thereaders are referred to Korean-to-English translation by Egedi,Palmer, Park and Joshi 1994, a transfer-based approach usingsynchronous tree adjoining grammar, [5], and Dorr 1997, asmall-scale interlingua-based approach, using Jackendoff?slexical conceptual structure as the interlingua, [4].OTHER LANGUAGESSEMANTIC FRAMES(COMMONCOALITIONLANGUAGE)SEMANTIC FRAMES(COMMONCOALITIONLANGUAGE)UNDERSTANDINGUNDERSTANDING UNDERSTANDINGUNDERSTANDINGGENERATIONGENERATION GENERATIONGENERATIONC4IINFORMATIONACCESSC4IINFORMATIONACCESSENGLISHTEXT ORSPEECHKOREANTEXT ORSPEECH1.1 Robust ParsingThe CCLINC parsing module, TINA [16], implements the top-down chart parsing and the best-first search techniques, driven bycontext free grammars rules compiled into a recursive transitionnetwork augmented by features, [8].
The following properties ofKorean induce a great degree of ambiguity in the grammar: (i)relatively free word order for arguments --- given a sentence withthree arguments, subject, object, indirect object, all 6 logical wordorder permutations are possible in reality, (ii) frequent omissionsof subjects and objects, and (iii) the strict verb finality, [10].
Dueto the free word order and argument omissions, the first word ofan input sentence can be many way ambiguous  --- it can be a partof a subject, an object, and any other post-positional phrases.2The ambiguity introduced by the first input word grows rapidly asthe parser processes subsequent input words.
Verbs,  whichusually play a crucial role in reducing the ambiguity in English bythe subcategorization frame information, are not available untilthe end, [1,3,11].Our solution to the ambiguity problem lies in a novel grammarwriting technique, which reduces the ambiguity of the first inputword.
We hypothesize that (i) the initial symbol in the grammar(i.e.
Sentence) always starts with the single category generic_np,the grammatical function (subject, object) of which isundetermined.
This ensures that the ambiguity of the first inputword is reduced to the number of different ways the categorygeneric_np can be rewritten.
(ii) The grammatical function of thegeneric_np is determined after the parser processes the followingcase marker via a trace mechanism.3Figure 2 illustrates a set of sample context free grammar rules, andFigure 3 (on the next page) is a sample parse tree for the inputsentence ?URi Ga EoRyeoUn MunJe Reul PulEox Da (We solveda difficult problem).
?4(i)           sentence ?
generic_np clause sentence_marker(ii) clause ?
subject generic_np object verbs(iii) subject ?
subj_marker np_traceFigure 2.
Sample context free grammar rules for  Korean2 Post-positional phrases in Korean correspond to pre-positionalphrases in English.
We use the term post-positional phrase toindicate that the function words at issue are located after thehead noun.3 The hypothesis that all sentences start with a single categorygeneric_np is clearly over simplified.
We can easily find asentence starting with other elements such as coordinationmarkers which do not fall under generic_np.
For the sentenceswhich do not start with the category generic_np, we discardthese elements for parsing purposes.
And this method hasproven to be quite effective in the overall design of thetranslation system, especially due to the fact that most of  nongeneric_np sentence initial elements (e.g.
coordination markers,adverbs, etc.)
do not contribute to the core meaning of the inputsentence.4 Throughout this paper, ?subj_marker?
stands for ?subjectmarker?, and ?obj_marker?, ?object marker?.The generic_np dominated by the initial symbol sentence in (i) ofFigure 2 is parsed as an element moved from the positionoccupied by np_trace in (iii), and therefore corresponds to thecategory np_trace dominated by subject in Figure 3 (placed onthe next page for space reasons).
All of the subsequentgeneric_np?s, which are a part of a direct object, an indirectobject, a post-positional phrase, etc.
are unitarily handled by thesame trace mechanism.
By hypothesizing that all sentences startwith generic_np, the system can parse Korean robustly andefficiently.
The trace mechanism determines the grammaticalfunction of generic_np by repositioning it after the appropriatecase marker.Utilization of overt case markers to improve the parsing efficiencyprecisely captures  the commonly shared intuition for parsingrelatively free word order languages with overt case markers suchas Korean and Japanese, compared with parsing relatively strictword order languages with no overt case markers such as English:In languages like English, the verb of a sentence plays the crucialrole in reducing the ambiguity via the verb subcategorizationframe information on the co-occuring noun phrases, [1,3,11].
Inlanguages like Korean, however, it is typically the case markerwhich identifies the grammatical function of the co-occuring nounphrase, assuming the role similar to that of verbs in English.
Thecurrent proposal is the first explicit implementation of thisintuition, instantiated by the novel idea that all noun phrases aremoved out of  the case marked phrases immediately followingthem.2.2 Meaning Representation and GenerationThe CCLINC Korean-to-English translation system achieves highquality translation by (i) robust mapping of the parsing output intothe semantic frame, and  (ii) word sense disambiguation on thebasis of the selection preference between two grammaticalrelations (verb-object, subject-verb, head-modifier) easilyidentifiable from the semantic frame, [13].
The former facilitatesthe accurate word order generation of various target languagesentences, and the latter, the accurate choice of the target languageword given multiple translation candidates for the same sourcelanguage word.
Given the parsing output in Figure 3, the systemproduces the semantic frame in Figure 4:55 Strictly speaking, the meaning representation in Figure 4 is nottruly language neutral in that the terminal vocabularies arerepresented in Korean rather than in interlingua vocabulary.
It isfairly straightforward to adapt our system to produce the meaningrepresentation with the terminal vocabularies specified by aninterlingua.
However, we have made a deliberate decision toleave the Korean vocabularies in the representation largely (1) toretain the system efficiency for mapping parsing output intomeaning representation, and (2) for unified execution ofautomation algorithms for both Korean-to-English and English-to-Korean translation.
And we would like to point out that thisminor compromise in meaning representation still ensures themajor benefit of interlingua approach to machine translation,namely, 2 x N sets of grammar rules for N language pairs, asopposed to 2N.
{c statement:topic {q  pronoun:name ?URi?
}:pred {p pul_v:topic {q problem:name ?MunJe?
:pred {p EoRyeoUn } } }Figure 4.
Semantic Frame  for the input sentence ?URi GaEoRyeoUn MunJe Reul PulEox Da.
?The semantic frame captures the core predicate-argumentstructure of the input sentence in a hierarchical manner, [9,10](i.e.
the internal argument, typically object, is embedded under theverb, and the external argument, typically subject, is at the samehierarchy as the main predicate, i.e.
verb phrase in syntacticterms).
The predicate and the arguments along with theirrepresentation categories are bold-faced in Figure 4.
With thesemantic frame as input, the generation system generates theEnglish translation using the grammar rules in (1), and the Koreanparaphrase using the grammar rules in (2).The semantic frame captures the core predicate-argumentstructure of the input sentence in a hierarchical manner, [9,10](i.e.
the internal argument, typically object, is embedded under theverb, and the external argument, typically subject, is at the samehierarchy as the main predicate, i.e.
verb phrase in syntacticterms).
The predicate and the arguments along with theirrepresentation categories are bold-faced in Figure 4.
With thesemantic frame as input, the generation system generates theEnglish translation using the grammar rules in (1), and the Koreanparaphrase using the grammar rules in (2).
(1)  a. statement :topic :predicateb.
pul_v  :predicate :topic(2) a. statement :topic :predicateb.
pul_v  :topic :predicate(1b) and (2b) state that the topic category for the object followsthe verb predicate in English, whereas it precedes the verbpredicate in Korean.The predicate-argument structure also provides a means for wordsense disambiguation, [13,15].
The verb pul_v is at least two-wayambiguous between  solve and  untie.
Word sense disambiguationis performed by applying the rules, as in (3).
(3) a .pul_v   b .pul_vproblem pul+solve_v     thread  pul+untie_v(3a) states that if the verb pul_v occurs with an object of typeproblem, it is disambiguated as pul+solve_v.
(3b) states that theverb occurring with an object of type thread is disambiguated aspul+untie_v.
The disambiguated verbs are translated into solveand untie, respectively, in the Korean-to-English translationlexicon.1.2 Knowledge-Based Automated Acquisitionof GrammarsTo overcome the knowledge bottleneck for robust translation andefficient system porting in an interlingua-based system [7], wehave developed a technique for automated acquisition of grammarrules which leads to a simultaneous acquisition of  rules for (i) theparser, (ii) the mapper between the parser and the semantic frame,and (iii) the generator.The technique utilizes a list of words and their correspondingparts-of-speech in the corpus as the knowledge source,presupposes a set of knowledge-based rules to be derived from aword and its part-of-speech pair, and gets executed according tothe procedure given in Figure 5.
The rationale behind thetechnique is that (i) given a word and its part-of-speech, most ofthe syntactic rules associated with the word can be automaticallyderived according to the projection principle (the syntacticsubj_markersentenceclause sentence_markersubject object verbsnp_trace obj_marker modifier np_tracenoun adj noun verbstatementGa URi Reul EoRyeoUn MunJe PulEox DaFigure 1.
Parse Tree for the Sentence URi Ga   EoRyeoUn MunJe    Reul PulEoxrepresentation must observe the subcategorization properties ofeach lexical item) and the X-bar schema (major syntacticcategories such as N, V, Adj, Adv project to the same syntacticstructures)  in linguistic theories, [2], and (ii) the mapping fromthe syntactic structure to the semantic frame representation isalgorithmic.
The specific rules to be acquired for a languagelargely depend on the grammar of the language  for parsing.Some example rules acquired for the verb BaiChiHa (arrange) inKorean ?
consistent with the parsing technique discussed inSection 2.1 ?
are given in (4) through (7).Initialization: Create the list of words and their parts-of-speech inthe corpus.Grammar Update: For each word and its associated part-of-speech, check to see whether or not the word and the rulesassociated with the corresponding part-of-speech occur in eachlexicon and grammar.If they already occur, do nothing.If not:(i) Create the appropriate rules and vocabulary itemsfor  each entry.
(ii) Insert the newly created rules and vocabulary itemsinto the appropriate positions of thegrammar/lexicon files for the parser, the grammarfile for the mapper between the parser and  thesemantic frame, and the grammar/lexicon files forthe generator .Figure 5.
Automated Gammar Acquistion Procedure(4) Rules for the parser6.verbs[negation] vBaiChiHa [negation] [aspect] [tense] [auxiliary][negation] [aspect] [tense] [and_verbs] [or_verbs].vBaiChiHa#BaiChiHa(5) Rules for the mapper from the parser to the semantic frame.bachiha_vvBaiChiHa6 The rules for the parser for the verb tell in English are givenbelow, to illustrate the dependency of the rules acquired  to thespecific implementation of the grammar of the language forparsing:.vp_tellvtell [adverb_phrase] dir_object [v_pp]vtell [adverb_phrase] indir_object dir_objectvtell [adverb_phrase] dir_object v_to_pp [v_pp]vtell [adverb_phrase] dir_object that_clausevtell [and_verb] [or_verb] [adverb_phrase] dir_object wh_clauseThe contrast in  complexity of verb rules in (4) for Korean, and (i)for English, reflects the relative importance of the role played byverbs for parsing in each language.
That is, verbs play the minimalrole in Korean, and the major role in English for ambiguityreduction and efficiency improvement.
(6) Lexicon for the generation vocabularybaichiha_v V2 ?arrang?V2    V ?e?
ING ?ing?
PP ?ed?
THIRD ?es?
ROOT ?e?PAST ?ed?
PASSIVE ?ed?
(7) Rules for the generation grammarbaichiha_v        :predicate :conj :topic :sub_clausenp-baichiha_v   :noun_phrase :predicate :conj :topic :sub_clauseThe system presupposes the flat phrase structure for a sentence inKorean, as shown in Figure 3, and therefore the rules for the verbsdo not require the verb subcategorization information, as in (4).The optional elements such as [negation], [tense], etc.
are possibleprefixes and suffixes to be attached to the verb stem, illustrating afairly complex verb morphology in this language.
The rules forthe generation grammar in (7) are the subcategorization frames forthe verb arrange in English, which is the translation of theKorean verb baichiha_v, as given in (6).The current technique is quite effective in expanding the system?scapability when there is no large syntatically annotated corpusavailable from which we can derive and train the grammar rules,[14], and applicable across languages in so far as the notion ofpart-of-speech, the projection principle and the X-bar schema islanguage independent.
With this technique, manual acquisition ofthe knowledge database for the overall translation system isreduced to the acquisition of  (i) the bilingual lexicon, and (ii) thecorpus specific top-level grammar rules which constitute less than20% of the total grammar rules in our system.
And this hasenabled us to produce a fairly large-scale interlingua-basedtranslation system within a short period of time.
One apparentlimitation of  the technique, however, is that it still requires themanual acquisition of corpus-specific rules  (i.e.
the patternswhich do not fall under the linguistic generalization).
And we arecurrently developing a technique for automatically derivinggrammar rules and obtaining the rule production probabilitiesfrom a syntactically annotated corpus.3.
EVALUATION AND RESEARCHISSUESWe have trained the system with about 1,600 Korean newspaperarticles on ?missiles?
and ?chemical biological warfare?, as inTable 1.Table 1.
Korean-to-English translation training data statistics# ofarticles# ofsents/article# ofwords/sent# of distinctwords1,631           24 17 15,220For quality evaluation, we have adopted a 5-point scale evaluationscore, defined as follows.
Score 4: Translation is both accurateand natural.
Score 3: Translation is accurate with minorgrammatical errors which do not affect the intended meaning ofthe input, e.g.
morphological errors such as ?swam vs.
swimmed.
?Score 2: Translation is partially accurate, and sufficient forcontent understanding.
Most errors are due to inaccurate wordchoice, inaccurate word order, and partial translation.
Score 1:Translation is word-for-word, and partial content understanding ispossible.
Score 0: There is no translation output, or no contentunderstanding is possible.We have performed the quality evaluation on 410 clauses from thetraining data, and 80 clauses from the test data.
We haveconducted the evaluation in 3 phases.
Eval 1: Baseline evaluationafter grammar and lexicon acquisition.
Eval 2: Evaluation afteraugmenting word sense disambiguation rules.
Eval 3: Evaluationafter augmenting word sense disambiguation rules and accurateword order generation rules.
The purpose of the 3-phaseevaluation was to examine the contribution of parsing, word sensedisambiguation and accurate word order generation to the overalltranslation quality.
Once the score had been assigned to eachclause, the translation score was obtained by the formula:  (Sumof  the scores for each clause *  25) / Number of clausesevaluated.Evaluation results are shown in Table 2 and Table 3 in terms ofparsing coverage (P) and the translation score (T).7Table 2.
Translation Quality Evaluation on Training DataEval 1             Eval 2             Eval 3P         T        P        T         P        T92      58        94       69       94      74Table 3.
Translation Quality Evaluation on Test DataEval 1             Eval 2             Eval 3P       T         P        T         P       T79      55       89       63       89      65For both training and test data, the baseline translation qualityscore is over 50, sufficient for content understanding of thedocuments.
Word sense disambiguation (Eval 1 vs. Eval 2)increases the translation score by about 10%, indicating thateffective word sense disambiguation has a great potential forimproving the translation quality.We would like to point out  that the evaluations reported in thispaper are performed on clauses rather than sentences (which oftenconsist of more than one clause).
In a very recent evaluation, wehave found out that evaluations on sentences decrease the overalltranslation score about by 15.
Nevertheless, the translationquality is still good enough for content understanding with someeffort.
The primary cause for the lower translation scores whenthe evaluation unit is a sentence as opposed to a clause is due toeither an incorrect clause boundary identification, or someinformation (e.g.
missing arguments in embedded clauses) whichcannot be easily recovered after a sentence  is fragmented intoclauses.
This has led to the ability to handle complex sentences as7 We would like to note that the evaluation reported here was aself-evaluation of the system by a system developer, primarily toidentify the key research issues in system development.
We willreport evaluation results by non system developers who have noknowledge of  Korean in the future.
A system evaluation by  anon-bilingual speaker will avoid the issue of implicitly utilizingthe knowledge  the  evaluator has about the source language inthe evaluation process.the primary research issue, and we are working out the solution ofutilizing syntactically annotated corpus for both grammar andprobability acquisition, as discussed in Section 2.3.4.
SUMMARY AND ONGOING WORKWe have described the key features of the CCLINC interlingua-based Korean-to-English translation system which is capable oftranslating a large quantity of Korean newspaper articles onmissiles and chemical biological warfare in real time.
Translationquality evaluations on the training and test data indicate that thecurrent system produces translation sufficient for contentunderstanding of a document in the training domains.
The keyresearch issues identified from the evaluations include (i) parsingcomplex sentences, (ii) automated acquisition of word sensedisambiguation rules from the training corpus,  and (iii)development of discourse module to identify the referents ofmissing arguments.
Our solution to the key technical challengescrucially draws upon the utilization of annotated corpora: Forcomplex sentence parsing, we acquire both rules and ruleproduction probabilities from syntactically annotated corpus.
Forautomated word sense disambiguation, we utilize a sense-taggedcorpus to identify various senses of a word, and obtainprobabilities for word senses in various contexts.
For discourseunderstanding, we are developing an algorithm for our 2-wayspeech translation work, [12], and plan to expand the module fordocument translations.5.
ACKNOWLEDGMENTSWe would like to acknowledge Dr. Jun-Tae Yoon, who providedus with a high-quality robust Korean morphological analyzercalled morany during his stay at the Institute for Research inCognitive Science, University of Pennsylvania as a postdoctoralfellow.
Morany has served as a pre-processor of the understandingmodule in the CCLINC Korean-to-English translation system.6.
REFERENCES[1] Srinivas Bangalore and Aravind Joshi.
?Some NovelApplications of Explnation-Based Learning for ParsingLexicalized Tree-Adjoining Grammars,?
Proceedings of  33rdAssociation for Computational Linguistics.
pp.
268?275.
1995.
[2] Noam Chomsky.
Barriers.
Linguistic Inquiry Monograph 13.MIT Press, Cambridge, MA.
1986.
[3] Michael Collins.
Three Generative, Lexicalized Models forStatistical Parsing.
Procceedings of the 35th Annual Meeting ofACL.
pp.
16?23.
Madrid, Spain.
July.
1997.
[4] Bonnie Dorr.
?LCS-based Korean Parsing and Translation,?Ms.
Institute for Advanced Computer Studies and Department ofComputer Science, University of Maryland.
1997.
[5] Diana Egedi, Martha Palmer, H-S. Park, Aravind Joshi.
?Korean to English Translation Using Synchronous TAGs,?Proceedings of  the First Conference of the Association forMachine Translation in the Americas.
pp.
48?55.
Columbia,Maryland.
October 1994.
[6] James Glass, Joe Polifroni and Stephanie Seneff.
?Multilingual Language Generation across Multiple Domains,?Proceedings of International Conference on Spoken LanguageProcessing, pp.
983?986.
Yokohama, Japan.
September, 1994.
[7] W.J.
Hutchins and H.L.
Somers.
An Introduction to MachineTranslation.
Academic Press.
London.
1992.
[8] James Allen.
Natural Language Understanding, 2nd Edition.Benjamin-Cummings Publisher.
1995[9] Ken Hale.
?Preliminary Remarks on Configurationality,?Proceedings of NELS 12,  pp.
86?96.
1982.
[10] Young-Suk Lee.
Scrambling as Case-Driven ObligatoryMovement.
PhD Thesis (IRCS Report No.
: 93-06 ).
University ofPennsylvania.
1993.
[11] Young-Suk Lee, Clifford Weinstein, Stephanie Seneff,Dinesh Tummala, ?Ambiguity Resolution for MachineTranslation of  Telegraphic Messages,?
Proceedings of  the 35thAnnual Meeting of ACL.
pp.
120?127.
Madrid, Spain.
July 1997.
[12] Young-Suk Lee and Clifford Weinstein.
?An IntegratedApproach to English-Korean Translation and TranslingualInformation Access,?
Proceedings of CSTAR Workshop.Schwetzingen, Germany.
September, 1999.
[13] Young-Suk Lee, Clifford Weinstein, Stephanie Seneff,Dinesh Tummala.
?Word Sense Disambiguation for MachineTranslation in Limited Domains,?
Manuscript.
InformationSystems Technology Group.
MIT Lincoln Laboraotry.
January1999.
[14]  Mitch Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
?Building a large annotated corpus of English: thePenn Treebank,?
Computational Linguistics 19 (2).
pp.
313?330.
1993.
[15] Philip Resnik.
?Semantic Similarity in a Taxonomy: AnInformation-Based Measure and Its Application to Problems ofAmbiguity in Natural Language,?
Journal of ArtificialIntelligence Research (JAIR) 11. pp.
95?130.
1999.
[16] Stephanie Seneff.
?TINA: A Natural Language System forSpoken Language Applications,?
Computational Linguistics 18(1).
pp.
61?92.
1992.
[17] Clifford Weinstein, Young-Suk Lee, Stephanie Seneff,Dinesh Tummala, Beth Carlson, John T. Lynch, Jung-TaikHwang, Linda Kukolich.
?Automated English-Korean Translationfor Enhanced Coalition Communications,?
The LincolnLaboratory Journal 10 (1).
pp.
35?60.
1997.
