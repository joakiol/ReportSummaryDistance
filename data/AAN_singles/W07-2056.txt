Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 261?263,Prague, June 2007. c?2007 Association for Computational LinguisticsPKU: Combining Supervised Classifiers with Features SelectionPeng Jin, Danqing Zhu, *Fuxin Li and Yunfang WuInstitute of Computational LinguisticsPeking University, Beijing, China*Institute of Automation Chinese Academy of SciencesBeijing, China{jandp,zhudanqing,wuyf}@pku.edu.cn *Fuxin.li@ia.ac.cnAbstractThis paper presents the word sense disam-biguation system of Peking Universitywhich was designed for the SemEval-2007competition.
The system participated in theWeb track of task 11 ?English LexicalSample Task via English-Chinese ParallelText?.
The system is a hybrid model bycombining two supervised learning algo-rithms SVM and ME.
And the method ofentropy-based feature chosen was experi-mented.
We obtained precision (and recall)of 81.5%.1 IntroductionThe PKU system participated in the web track oftask 11.
In this task, the organizers propose anEnglish lexical sample task for word sense disam-biguation (WSD), where the sense-annotated ex-amples are (semi)-automatically gathered fromword-aligned English-Chinese parallel texts.
Afterassigning appropriate Chinese translations to eachsense of an English word, the English side of theparallel texts can then serve as the training data, asthey are considered to have been disambiguatedand "sense-annotated" by the appropriate Chinesetranslations.
This proposed task is thus similar tothe multilingual lexical sample task in Senseval3,except that the training and test examples are col-lected without manually annotating each individualambiguous word occurrence.The system consists of two supervised learningclassifiers, support vector machines (SVM) andmaximum entropy (ME).
A method of entropy-based feature chosen was experimented to reducethe feature dimensions.
The training data was lim-ited to the labeled data provided by the task, and aPoS-tagger (tree-tagger) was used to get more fea-tures.2 Features SelectionWe used tree-tagger to PoS-tag the texts before thefeature extractor.
No other resource is used in thesystem.
The window size of the context is set to 5around the ambiguous word.
Only the followingfeatures are used in the system:Local wordsLocal PoSsBag-of-wordsLocal collocationsHere local collocation means any two wordswhich fall into the context window to form collo-cation pair.Two methods are used to reduce the dimensionsof feature space.
One comes from the linguisticknowledge, some words whose PoSs are IN, DT,SYM, POS, CC or ?``?
are not included as the fea-tures.The second method is based on entropy.
To eachword, the training data was split to two parts forparameter estimation.
One (usually consist of 30 ?50 instances) as the simultaneous test and the restinstances form the other part.First the entropy of each feature was calculated.For example, the target word ?work?, it has twosenses and the dimensions of its feature space is N.For feature , if it appears in m instances belong-ing to sense A and n instances in sense B.
So theif261probability distributions are:nmmp +=1   andnmnp +=2 .
The entropy of  is: if?==211log)(j jji ppfHWe rank all the features according to their en-tropy from small to big.
And then first percentlambda features are chosen as the final feature set.Using this smaller feature set, we use the classifierto make a new prediction.The parameter ?
is estimated by comparing thesystem performance on the simultaneous test.
Inour system, .68 is chosen.
It means that 68% origi-nal features used to form the new feature space.The same classifier was tried on different featuresets to get different outputs and then were com-bined.3 ClassifiersThe Support Vector Machines (SVM) are a groupof supervised learning methods that can be appliedto classification or regression.
It is developed byVapnik and has been applied into WSD (Lee et al,2004).
Since most of the target words have morethan two senses, we used the implementation ofSVM that includes lib-svm (Chang and Lin, 2001)and svm-multiclass (Joachims, 2004).
To lib-svm,the parameter of ?b?
which is used to obtain prob-ability information after training is set 0 or 1 indi-vidually to form different classifiers.
The defaultlinear kernel is used.Each vector dimension represents a feature.
Thenumerical value of a vector entry is the numericalvalue of the corresponding feature.
In our system,we use binary features.
If the context of an instancehas a particular feature, then the feature value is setto 1, otherwise the value is set to 0.ME modeling provides a framework for inte-grating information for classification from manyheterogeneous information sources.
The intuitionbehind the maximum entropy principle is: given aset of training data, model what is known and as-sume no further knowledge about the unknown byassigning them equal probability (entropy ismaximum).
There are also some researchers usingME to WSD (Chao and Dyer, 2002).
Dekang Lin?simplementation of ME was used.
He used General-ized Iterative Scaling (GIS) algorithm.4 DevelopmentBecause of time constraints, we could not experi-ment all the training data by cross-validation.
Toeach target word, we extract first 50 training in-stances as the test.Lib-svmProb.
OutputTargetWordSvm-Multi-classMEOrig.F.S.Red.FSNon-prob.OutputAge .68 .70 .70 .70 .66Area .80 .70 .80 .74 .82Body .84 .84 .90 .92 .16Change .48 .42 .66 .42 .58Director .96 .94 .96 .96 .96Experience .90 .88 .88 .90 .88Future .94 .94 .94 .98 .94interest .84 .82 .82 .88 .84issue .88 .88 .84 .90 .88Life .92 .94 .98 1.0 .94Material .88 .92 .94 .94 .88Need .86 .86 .86 .86 .86performance .78 .82 .80 .82 .80Program .70 .74 .72 .72 .72Report .94 .94 .94 .94 .94System .76 .70 .76 .76 .70Time .70 .64 .68 .60 .76today .72 .70 .74 .68 .76Water .90 .92 .88 .82 .90Work .90 .86 .90 .92 .90Table 1: The Performance on NounsFor some adjectives, we just extract first 30 be-cause the training data is small.
For ten of adjec-tives, the training data is too small, we directly usethe lib-svm (with probability output) as the finalclassifier.Both SVM and ME could output the probabilityfor each instance to each class.
So we try to com-bine them to improve the performance.
Severalmethods of combining classifiers have been inves-tigated (Radu et al, 2002).
The enhanced Counted-based Voting (CBV) and Rank-Based Voting,Probability Mixture Model, and best single Classi-fier are experimented in the training data.
Table 1and Table 2 indicate the results of nouns and adjec-tives individually, which were achieved with eachof the different methods.
In these tables, "OrigF.S."
and "Red.
F.S."
mean original feature set andreduced feature set.
"Prob.
output" and "Non Prob.262output" are two implementation of lib-svm.
Theformer output the probability of each instance be-longing to each class, otherwise the latter not.
Dif-ferent from the results of Radu, choosing the bestsingle classifier get the better performance thanany kinds of combination.
In this paper, we did notlist the performances of combining.According to Table 1 and Table 2, the particularclassifier chosen for that word was the one with thehighest score in the training data.Lib-svmProb.
OutputTargetWordSvm-Multi-classMEOrig.F.S.Red.F.S.Non-prob.outputEarly .77 .80 .77 .80 .77Educational .87 .87 .87 .83 .87Free .74 .80 .84 .90 82Human .96 .92 .96 .90 .96Long .70 .70 .73 .87 .70Major .78 .78 .78 .80 .78Medical .76 .86 .78 .84 .78New .73 .77 .63 .43 .63Simple .73 .77 .77 .77 .80Third .98 .94 .98 1.0 .96Table 2:  The performance on AdjectivesTwo parameters are different from these twoSVMs.
One is the ?-c?, which is the tradeoff be-tween training error and margin.
In lib-svm thevalue of ?-c?
is set 1; but in svm-multiclass is 0.01.The other is the strategy of how to utility binary-classification to resolve multi-class.
In svm-multiclass, no strategy is needed since the algo-rithm in (Crammer and Singer, 2001) solves themulti-class problem directly.
In lib-svm, we usethe one-against-all approach which is the default inlib-svm.
Down-sampling is used if some result istrivial classification.
The reason is that the unbal-anced distribution of training data.
We comparedselecting support vectors and down-sampling.
Thelatter is better.5 ResultsWe participated in the subtask of SemEval-2007English lexical sample task via English-Chineseparallel text.
The organizers make use of English-Chinese documents gathered from the URL pairsgiven by the STRAND Bilingual Databases.
Theyused this corpus for the evaluation of 40 Englishwords (20 nouns and 20 adjectives).Our system gives exactly one sense for each testexample.
So the recall is always the same as preci-sion.
Micro-average precision is 81.5%.
Accordingto the task organizers, the recall of the best partici-pating in this subtask is 81.9%.
So the performanceof our system compares favorably with the bestparticipating system.6 AcknowledgementsThis research is supported by Humanity and SocialScience Research Project of China State EducationMinistry (No.
06JC740001) and National BasicResearch Program of China (No.
2004CB318102).We are indebted to Helmut Schmid, IMS, Uni-versity of Stuttgart, for making Tree-Tagger avail-able free of charge.Finally, the authors thank the organizers HweeTou Ng and Yee Seng Chan, for their hard work tocollect the training and test data.ReferencesChih-Chung Chang and Chih-Jen Lin.
2001.
LIBSVM :a library for support vector machines.www.csie.ntu.edu.tw/~cjlin/libsvmGerald Chao and Michael G. Dyer.
2002.
Maximumentropy models for word sense disambiguation.
Pro-ceedings of the 19th international conference onComputational linguistics.Vol (1):1-7Koby Crammer and Yoram Singer.
2001.
On the Algo-rithmic Implementation of Multiclass Kernel-basedVector Machines.
Journal of Machine Learning Re-search, 2, 265-292Radu Florian, Silviu Cucerzan, Charles Schafer andDavid Yarowsky.
2002.
Combining Classifiers forWord Sense Disambiguation.
Natural Language En-gineering, 8(4): 327 ?
341.Thorsten Joachims.
SVM-Multiclass.http://svmlight.joachims.org/svm-multiclass.html,2004.Yoong Keok Lee, Hwee Tou Ng and Tee Kiah Chia,Supervised Word Sense Disambiguation with Sup-port Vector Machines and Multiple KnowledgeSources.
Proceedings of SENSEVAL-3.
137 - 140263
