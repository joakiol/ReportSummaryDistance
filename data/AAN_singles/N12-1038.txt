2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 362?366,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsGetting More from Segmentation EvaluationMartin ScaianoUniversity of OttawaOttawa, ON, K1N 6N5, Canadamscai056@uottawa.caDiana InkpenUniversity of OttawaOttawa, ON, K1N 6N5, Canadadiana@eecs.uottawa.comAbstractWe introduce a new segmentation evaluationmeasure, WinPR, which resolves some of thelimitations of WindowDiff.
WinPR distin-guishes between false positive and false nega-tive errors; produces more intuitive measures,such as precision, recall, and F-measure; is in-sensitive to window size, which allows us tocustomize near miss sensitivity; and is basedon counting errors not windows, but still pro-vides partial reward for near misses.1 IntroductionWindowDiff (Pevzner and Hearst, 2002) has be-come the most frequently used measure to evalu-ate segmentation.
Segmentation is the task of di-viding a stream of data (text or other media) intocoherent units.
These units may be motivated top-ically (Malioutov and Barzilay, 2006), structurally(Stokes, 2003) (Malioutov et al, 2007) (Jancsary etal., 2008), or visually (Chen et al, 2008), dependingon the domain and task.
Segmentation evaluationis difficult because exact comparison of boundariesis too strict; a partial reward is required for closeboundaries.2 WindowDiff?The WindowDiff metric is a variant of the Pk mea-sure, which penalizes false positives and near missesequally.?
(Malioutov et al, 2007).
WindowDiff usesa sliding window over the segmentation; each win-dow is evaluated as correct or incorrect.
WindowD-iff is effectively 1 ?
accuracy for all windows,but accuracy is sensitive to the balance of positiveand negative data being evaluated.
The positiveand negative balance is determined by the windowsize.
Small windows produce more negatives, thusWindowDiff recommends using a window size (k)of half the average segment length.
This producesan almost equal number of positive windows (con-taining boundaries) and negative windows (withoutboundaries).Equation 1 represents the window size (k), whereN is the total number of sentences (or content units).Equation 2 is WindowDiff?s traditional definition,where R is the number of reference boundaries inthe window from i to i+k, and C is the numberof computed boundaries in the same window.
Thecomparison (> 0) is sometimes forgotten, whichproduces strange values not bound between 0 and 1;thus we prefer equation 3 to represent WindowDiff,as it emphasizes the comparison.k =N2 * number of segments(1)WindowDiff =1N ?
kN?k?i=0(|Ri,i+k ?
Ci,i+k| > 0)(2)WindowDiff =1N ?
kN?k?i=0(Ri,i+k 6= Ci,i+k) (3)Figure 1 illustrates WindowDiff?s sliding win-dow evaluation.
Each rectangle represents a sen-tence, while the shade indicates to which segmentit truly belongs (reference segmentation).
The ver-tical line represents a computed boundary.
This ex-ample contains a near miss (misaligned boundary).In this example, we are using a window size of 5.The columns i, R, C, W represent the window po-sition, the number of boundaries from the reference(true) segmentation in the window, the number ofboundaries from the computed segmentation in thewindow, and whether the values agree, respectively.Only windows up to i = 5 are shown, but to process362the entire segmentation 8 windows are required.i R C W0 0 0 D1 0 0 D2 0 1 X3 1 1 D4 1 1 D5 1 0 XFigure 1: Illustration of counting boundaries in windowsFranz et al (2007) note that WindowDiff does notallow different segmentation tasks to optimize dif-ferent aspects, or tolerate different types of errors.Tasks requiring a uniform theme in a segment mighttolerate false positives, while tasks requiring com-plete ideas or complete themes might accept falsenegatives.Georgescul et al (2009) note that while Win-dowDiff technically penalizes false positives andfalse negatives equally, false positives are in factmore likely; a false positive error occurs anywherewere there are more computed boundaries thanboundaries in the reference, while a false negativeerror can only occur when a boundary is missed.Consider figure 1, only 3 of the 8 windows contain aboundary; only those 3 windows may have false neg-atives (a missed boundary), while all other windowsmay contain false positives (too many boundaries).Lamprier et al (2008) note that errors near thebeginning and end of a segmentation are actuallycounted slightly less than other errors.
Lamprier of-fers a simple correction for this problem, by addingk?1 phantom positions, which have no boundaries,at the beginning and at the end sequence.
The ad-dition of these phantom boundaries allows for win-dows extending outside the segmentation to be eval-uated, and thus allowing for each position to becount k times.
Example E in figure 4 in the nextsection will illustrate this point.
Consider exampleD in figure 4; this error will only be accounted for inthe first window, instead of the typical k windows.Furthermore, tasks may want to adjust sensitiv-ity or reward for near misses.
Naturally, one wouldbe inclined to adjust the window size, but changingthe window size will change the balance of positivewindows and negative windows.
Changing this bal-ance has a significant impact on how WindowDifffunctions.Some researchers have questioned what the Win-dowDiff value tells us; how do we interpret it?3 WinPRWinPR is derived from WindowDiff, but differs onone main point: WinPR evaluates boundary posi-tions, while WindowDiff evaluates regions (or win-dows).
WinPR is a set of equations (4-7) (Figure 2)producing a confusion matrix.
The confusion matrixallows for the distinction between false positive andnegative errors, and can be used with Precision, Re-call, and F-measure.
Furthermore, the window sizemay be changed to adjust near-miss sensitivity with-out affecting the the interpretation of the confusionmatrix.N is the number of content units and k repre-sents the window size.
WinPR includes the Lam-prier (2008) correction, thus the sum is from 1 ?
kto N instead of 1 to N ?
k as with WindowDiff.min and max refer to the tradition computer sci-ence functions which select the minimal or maximalvalue from a set of two values.
True negatives (5)start with a negative term, which removes the valueof the phantom positions.Each WinPR equation is a summation over allwindows.
To understand the intuition behind eachequation, consider Figure 3.
R and C represent thenumber of boundaries from the reference and com-puted segmentations, respectively, in the ith win-dow, up to a maximum of k. The overlapping regionrepresents the TPs.
The difference is the error, whilethe sign of the difference indicates whether they areFPs or FNs.
The WinPR equations select the differ-ence using the max function, forcing negative val-ues to 0.
The remainder, up to k, represents the TNs.kCiRi0CRTPerrorTNFigure 3: WinPR within Window Counting DemostrationConsider how WindowDiff and WinPR handlethe examples in Figure 4.
These examples use thesame basic representation as Figure 1 in section 2.Each segment is 6 units long and the window size is363True Positives = TP =N?i=1?kmin(Ri,i+k, Ci,i+k) (4)True Negatives = TN = ?k(k ?
1) +N?i=1?k(k ?max(Ri,i+k, Ci,i+k)) (5)False Positives = FP =N?i=1?kmax(0, Ci,i+k ?Ri,i+k) (6)False Negatives = FN =N?i=1?kmax(0, Ri,i+k ?
Ci,i+k) (7)Figure 2: Equations for the WinPR confusion matrix3 = (6/2).
Each window contains 3 content units,thus we consider 4 potential boundary positions (theedges are inclusive).A) Correct boundaryB) Missed boundaryC) Near boundaryD) Extra boundaryE) Extra boundariesFigure 4: Example segmentationsExample A provides a baseline for comparison; Bis a false negative (a missed boundary); C is a nearmiss; D is an extra boundary at the beginning of thesequence, providing an example of Lamprier?s criti-cism.
E includes two errors near each other.
Noticehow the additional errors in E have have a very smallimpact on the WindowDiff value.
Table 1 lists thenumber of correct and incorrect windows, and theWindowDiff value for each example.Example Correct Incorrect WindowDiffA 10 0 0B 6 4 0.4C 8 2 0.2D 9 1 0.1E 4 6 0.6Table 1: WindowDiff values for examples A to EWindowDiff should penalize an error k times,once for each window in which it appears, with theexception of near misses which have partial rewardand penalization.
D is only penalized in one win-dow, because most of the other windows would beoutside the sequence.
E contains two errors, but theyare not fully penalized because they appear in over-lapping windows.
Furthermore, using a single met-ric does not indicate if the errors are false positivesor false negatives.
This information is important tothe development of a segmentation algorithm.If we apply WinPR to examples A-E, we get theresults in Table 2.
We will calculate precision andrecall using the WinPR confusion matrix, shown un-der WinP and WinR respectively.
You will note thatwe can easily see whether an error is a false posi-tive or a false negative.
As we would expect, falsepositives affect precision, and false negatives affectrecall.
Near misses manifest as equal parts false pos-itive and false negative.
In example E, each error iscounted, unlike WindowDiff.Example TP TN FP FN WinP WinRa 4 40 0 0 1 1.0b 0 40 0 4 - 0c 3 40 1 1 0.75 0.75d 4 36 4 0 0.5 1.0e 4 32 8 0 0.33 1.0Table 2: WinPR values for examples A to EIn Table 2, note that each potential boundary posi-tion is considered k (the window size) times.
Thus,each positive or negative boundary assignment iscounted k times; near misses producing a blend ofvalues: TP, FP, FN.
We refer to the normalized con-364fusion matrix (or normalized WinPR), as the con-fusion matrix divided by the window size.
If nearmisses are not considered, this confusion matrixgives the exact count of boundary assignments.What is not apparent in Table 2, is that WinPRis insensitive to window size, with the exception ofnear misses.
Thus adjusting the window size canbe used to adjust the tolerance or sensitivity to nearmisses.
Large window sizes are more forgiving ofnear misses, smaller window size are more strict.3.1 Near Misses and Window SizeWinPR does not provide any particular values in-dicating the number of near misses, their distance,or contribution to the evaluation.
Because WinPR?swindow size only affects near miss sensitivity, andnot the positive/negative balance like in WindowD-iff, we can subtract two normalized confusion ma-trices using different window sizes.
The differencebetween the confusion matrices gives the impact ofnear misses under different window sizes.
Choosinga very strict window size (k = 1), and subtracting itfrom another window size would effectively providethe contribution of the near misses to the confusionmatrix.
In many circumstances, using several win-dow sizes may be desirable.3.2 Variations in Segment Size: Validation bySimulationWe ran numerous tests on artificial segmentationdata composed of 40 segments, with a mean segmentlength of 40 content units, and standard deviationsvarying from 10 to 120.
All tests showed that a falsepositive or a false negative error is always penalizedk times, as expected.3.3 WinPR Applied to a CompleteSegmentationUsing a reference segmentation of 40 segments, wederived two flawed segments: we added 20 extraboundaries to one, and removed 18 boundaries fromthe other.
Both produced WindowDiff values of0.22, while WinPR provided WinP = 0.66 and WinR= 1.0 for the addition of boundaries and WinP =1.00 and WinR = 0.54 for the removal of bound-aries.
WinPR highlights the differences in the na-ture of the two flawed segmentations, while WinDiffmasks both the number and types of errors.4 ConclusionWe presented a new evaluation method for segmen-tation, called WinPR because it produces a confu-sion matrix from which Precision and Recall can bederived.
WinPR is easy to implement and providesmore detail on the types of errors in a computed seg-mentation, as compared with the reference.
Some ofthe major benefits of WinPR, as opposed to Win-dowDiff are presented below:1.
Distinct counting of false positives and falsenegatives, which helps in algorithm selectionfor downstream tasks and helps with analysisand optimization of an algorithm.2.
The confusion matrix is easier to interpret thana WindowDiff value.3.
WinPR counts errors from boundaries, not win-dows, thus close errors are not masked4.
Precision, and Recall are easier to understandthan WindowDiff.5.
F-measure is effective when a single value isrequired for comparison.6.
WinPR incorporates Lamprier (2008) correc-tion.7.
Adjusting the window size can customize anevaluation?s tolerance of near misses8.
WinPR provides a method of detecting the im-pact of near misses on an evaluationWinPR counts boundaries, not windows, whichhas analytical benefits, but WindowDiff?s countingof windows provides an evaluation of segmentationby region.
Thus WindowDiff is more appropriatewhen an evaluator is less interested in the types andthe number of errors and more interested in the per-centage of the sequence that is correct.AcknowledgmentsThanks to Dr. Stan Szpakowicz for all his help refin-ing the arguments and the presentation of this paper.Thanks to Anna Kazantseva for months of discus-sions about segmentation and the evaluation prob-lems we each faced.
Thanks to Natural Sciences andEngineering Research Council of Canada (NSERC)for funding our research.365ReferencesL Chen, YC Lai, and H Liao.
2008.
Movie scenesegmentation using background information.
PatternRecognition, Jan.M Franz, J McCarley, and J Xu.
2007.
User-orientedtext segmentation evaluation measure.
SIGIR ?07 Pro-ceedings of the 30th annual international ACM SIGIRconference on Research and development in informa-tion retrieval, Jan.M Georgescul, A Clark, and S Armstrong.
2009.
Ananalysis of quantitative aspects in the evaluation of the-matic segmentation algorithms.
SigDIAL ?06 Proceed-ings of the 7th SIGdial Workshop on Discourse andDialogue, Jan.J Jancsary, J Matiasek, and H Trost.
2008.
Revealing thestructure of medical dictations with conditional ran-dom fields.
EMNLP ?08 Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, Jan.S Lamprier, T Amghar, and B Levrat.
2008.
On evalu-ation methodologies for text segmentation algorithms.19th IEEE International Conference on Tools with Ar-tificial Intelligence - Vol.2, Jan.I Malioutov and R Barzilay.
2006.
Minimum cut modelfor spoken lecture segmentation.
ACL-44 Proceedingsof the 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Associ-ation for Computational Linguistics, Jan.I Malioutov, A Park, R Barzilay, and R Glass.
2007.Making sense of sound: Unsupervised topic segmen-tation over acoustic input.
Proceeding of the AnnualMeeting of the Association for Computation Linguis-tics 2007, Jan.L Pevzner and M Hearst.
2002.
A critique and improve-ment of an evaluation metric for text segmentation.Computational Linguistics, Jan.N Stokes.
2003.
Spoken and written news story seg-mentation using lexical chains.
Proceedings of the2003 Conference of the North American Chapter of theAssociation for Computational Linguistics on HumanLanguage Technology: HLT-NAACL2003 Student Re-search Workshop, Jan.366
