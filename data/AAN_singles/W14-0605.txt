Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 32?41,Gothenburg, Sweden, April 26 2014.c?2014 Association for Computational LinguisticsA Multilingual Evaluation of Three Spelling NormalisationMethods for Historical TextEva Pettersson1,2, Be?ta Megyesi1and Joakim Nivre1(1) Department of Linguistics and PhilologyUppsala University(2) Swedish National Graduate Schoolof Language Technologyfirstname.lastname@lingfil.uu.seAbstractWe present a multilingual evaluation ofapproaches for spelling normalisation ofhistorical text based on data from fivelanguages: English, German, Hungarian,Icelandic, and Swedish.
Three differentnormalisation methods are evaluated: asimplistic filtering model, a Levenshtein-based approach, and a character-based sta-tistical machine translation approach.
Theevaluation shows that the machine transla-tion approach often gives the best results,but also that all approaches improve overthe baseline and that no single methodworks best for all languages.1 IntroductionLanguage technology for historical text is a fieldof research imposing a variety of challenges.
Nev-ertheless, there is an increasing need for naturallanguage processing (NLP) tools adapted to his-torical texts, as an aid for researchers in the hu-manities field.
For example, the historians in theGender and Work project are studying what menand women did for a living in the Early Mod-ern Swedish society (?gren et al., 2011).
In thisproject, researchers have found that the most im-portant words in revealing this information areverbs such as fishing, selling etc.
Instead of man-ually going through written sources from this timeperiod, it is therefore assumed that an NLP toolthat automatically searches through a number ofhistorical documents and presents the containedverbs (and possibly their complements), wouldmake the process of finding relevant text passagesmore effective.A major challenge in developing language tech-nology for historical text is that historical languageoften is under-resourced with regard to annotateddata needed for training NLP tools.
This prob-lem is further aggravated by the fact that histori-cal texts may refer to texts from a long period oftime, during which language has changed.
NLPtools trained on 13th century texts may thus notperform well on texts from the 18th century.
Fur-thermore, historical language usually shows a sub-stantial variation in spelling and grammar betweendifferent genres, different authors and even withinthe same text written by the same author, due tothe lack of spelling conventions.To deal with the limited resources and the highdegree of spelling variation, one commonly ap-plied approach is to automatically normalise theoriginal spelling to a more modern spelling, be-fore applying the NLP tools.
This way, NLP toolsavailable for the modern language may be usedto analyse historical text.
Even though there maybe structural differences as well between histor-ical and modern language, spelling is the moststriking difference.
Moreover, language technol-ogy tools such as taggers often to some degreerely on statistics on word form n-grams and to-ken frequencies, implying that spelling moderni-sation is an important step for improving the per-formance of such tools when applied to historicaltext.
This paper presents an evaluation of threeapproaches to spelling normalisation: 1) a filter-ing approach based on corpus data, 2) an approachbased on Levenshtein edit distance, and 3) anapproach implementing character-based statisticalmachine translation (SMT) techniques.
These ap-proaches have previously solely been evaluated inisolation, without comparison to each other, andfor one or two languages only.
We compare theresults of the different methods in a multilingualevaluation including five languages, and we showthat all three approaches have a positive impact onnormalisation accuracy as compared to the base-line.
There is no single method that yields thehighest normalisation accuracy for all languages,but for four out of five languages within the scope32of our study, the SMT-based approach gives thebest results.2 Related WorkSpelling normalisation of historical text has pre-viously been approached using techniques such asdictionary lookup, edit distance calculations, andmachine translation.Rayson et al.
(2005) tried an approach based ondictionary lookup, where a mapping scheme fromhistorical to modern spelling for 16th to 19th cen-tury English texts was manually created, resultingin the VARD tool (VARiant Detector) comprising45,805 entries.
The performance of the normal-isation tool was evaluated on a set of 17th cen-tury texts, and compared to the performance ofmodern spell checkers on the same text.
The re-sults showed that between a third and a half ofall tokens (depending on which test text was used)were correctly normalised by both VARD and MSWord, whereas approximately one third of the to-kens were correctly normalised only when usingVARD.
The percentage of tokens correctly nor-malised only by MS Word was substantially lower;approximately 6%.
VARD was later further devel-oped into VARD2, combining the original wordlist with data-driven techniques in the form of pho-netic matching against a modern dictionary, andletter replacement rules based on common spellingvariation patterns (Baron and Rayson, 2008).Jurish (2008) argued that due to the lack of or-thographic conventions, spelling generally reflectsthe phonetic form of the word to a higher de-gree in historical text.
Furthermore, it is assumedthat phonetic properties are less resistant to di-achronic change than orthography.
Accordingly,Jurish explored the idea of comparing the simi-larity between phonetic forms rather than ortho-graphic forms.
For grapheme-to-phoneme conver-sion, a module of the IMS German Festival text-to-speech system (Black and Taylor, 1997) wasused, with a rule-set adapted to historical wordforms.
Evaluation was performed on a corpus ofhistorical German verse quotations extracted fromDeutsches W?rterbuch, containing 5,491,982 to-kens (318,383 types).
Without normalisation, ap-proximately 84% of the tokens were recognisedby a morphological analyser.
After normalisa-tion, 92% of the tokens were recognised.
Addinglemma-based heuristics, coverage increased fur-ther to 94% of the tokens.A Levenshtein similarity approach to normal-isation was presented by Bollmann et al.
(2011)for Early New High German, where Levenshtein-based normalisation rules were automatically de-rived from a word-aligned parallel corpus consist-ing of the Martin Luther Bible in its 1545 edi-tion and its 1892 version, respectively.
Using thisnormalisation technique, the proportion of wordswith a spelling identical to the modern spelling in-creased from 65% in the original text to 91% in thenormalised text.
This normalisation method wasfurther evaluated by Bollmann (2013), comparingthe performance of the RFTagger applied to histor-ical text before and after normalisation.
For everyevaluation text, the tagger was trained on between100 and 1,000 manually normalised tokens, andevaluated on the remaining tokens in the same text.For one manuscript from the 15th century, taggingaccuracy was improved from approximately 29%to 78% using this method.Another Levenshtein-based approach to nor-malisation was presented by Pettersson et al.
(2013b), using context-sensitive, weighted editdistance calculations combined with compoundsplitting.
This method requires no annotated his-torical training data, since normalisation candi-dates are extracted by Levenshtein comparisonsbetween the original historical word form andpresent-day dictionary entries.
However, if a cor-pus of manually normalised historical text is avail-able, this can optionally be included for dictio-nary lookup and weighted Levenshtein calcula-tions, improving precision.
This technique wasevaluated for Early Modern Swedish, and in thebest setting, the proportion of words in the his-torical text with a spelling identical to the mod-ern gold standard spelling increased from 64.6%to 86.9%.Pettersson et al.
(2013a) treated the normalisa-tion task as a translation problem, using character-based SMT techniques in the spelling normalisa-tion process.
With the SMT-based approach, theproportion of tokens in the historical text witha spelling identical to the modern gold standardspelling increased from 64.6% to 92.3% for EarlyModern Swedish, and from 64.8% to 83.9% for15th century Icelandic.
It was also shown that nor-malisation had a positive effect on subsequent tag-ging and parsing.Language technology for historical text also hasa lot in common with adaptation of NLP tools33for handling present-day SMS messages and mi-croblog text such as Twitter.
In both genres thereis a high degree of spelling variation, ad hoc ab-breviations and ungrammatical structures impos-ing the problem of data sparseness.
Similar meth-ods for spelling normalisation may thus be usedfor both tasks.
Han and Baldwin (2011) pre-sented a method for normalising SMS and Twittertext based on morphophonemic similarity, com-bining lexical edit distance, phonemic edit dis-tance, prefix substring, suffix substring, and thelongest common subsequence.
Context was takeninto account by means of dependency structuresgenerated by the Stanford Parser applied to a cor-pus of New York Times articles.
In the best set-ting, a token-level F-score of 75.5% and 75.3%was reported for SMS messages and Twitter textsrespectively.3 Approaches3.1 The Filtering ApproachThe filtering approach presupposes access to a par-allel training corpus of token pairs with historicalword forms mapped to their modernised spelling.In the normalisation process, whenever a token isencountered that also occurred in the training data,the most frequent modern spelling associated withthat token in the training corpus is chosen for nor-malisation.
Other tokens are left unchanged.3.2 The Levenshtein-based ApproachThe Levenshtein-based approach was originallypresented by Pettersson et al.
(2013b).
In its basicversion, no historical training data is needed,which is an important aspect considering thecommon data sparseness issue, as discussed inSection 1.
Instead, a modern language dictionaryor corpus is required, from which normalisationcandidates are extracted based on edit distancecomparisons to the original historical word form.If there is parallel data available, i.e.
the sametext in its historical and its modernised spelling,this data can be used to make more reliable Lev-enshtein calculations by assigning weights lowerthan 1 to frequently occurring edits observed inthe training data.
The weights are then calculatedby comparing the frequency of each edit occurringin the training corpus to the frequency with whichthe specific source characters are left unchanged,in accordance with the following formula:Frequency of UnchangedFrequency of Edit + Frequency of UnchangedContext-sensitive weights are added to handle ed-its affecting more than one character.
The context-sensitive weights are calculated by the same for-mula as the single-character weights, and includethe following operations:?
double deletion: personnes?
persons?
double insertion: strait?
straight?
single-to-double substitution: juge?
judge?
double-to-single substitution: moost?
mostFor all historical word forms in the training cor-pus that are not identical in the modern spelling,all possible single-character edits as well as multi-character edits are counted for weighting.
Hence,the historical word form personnes, mapped tothe modern spelling persons, will yield weightsfor double-to-single deletion of -ne, as illustratedabove, but also for single deletion of -n and singledeletion of -e.Finally, a tuning corpus is used to set athreshold for which maximum edit distanceto allow between the original word form andits normalisation candidate(s).
Based on theaverage edit distance between the historicalword forms and their modern spelling in thetuning corpus, the threshold is calculated by thefollowing formula (where 1.96 times the stan-dard deviation is added to cover 95% of the cases):avg editdistance +(1.96?standard deviation)If several normalisation candidates have the sameedit distance as compared to the source word, themost frequent candidate is chosen, based on mod-ern corpus data.
If none of the highest-ranked nor-malisation candidates are present in the corpus, orif there are several candidates with the same fre-quency distribution, a final candidate is randomlychosen.3.3 The SMT-based ApproachIn the SMT-based approach, originally presentedby Pettersson et al.
(2013a), spelling normali-sation is treated as a translation task.
To ad-dress changes in spelling rather than full transla-tion of words and phrases, character-based trans-lation (without lexical reordering) is performed,a well-known technique for transliteration and34character-level translation between closely relatedlanguages (Matthews, 2007; Vilar et al., 2007;Nakov and Tiedemann, 2012).
In character-levelSMT, phrases are modeled as character sequencesinstead of word sequences, and translation modelsare trained on character-aligned parallel corporawhereas language models are trained on characterN-grams.Since the set of possible characters in a lan-guage is far more limited than the number of pos-sible word forms, and the same corpus will presenta larger quantity of character instances than tokeninstances, only a rather small amount of paralleldata is needed for training the translation modelsand the language models in character-based trans-lation.
Pettersson et al.
(2013a) showed that witha training and tuning set of only 1,000 pairs of his-torical word forms mapped to modern spelling, anormalisation accuracy of 76.5% was achieved forIcelandic, as compared to 83.9% with a full-sizedtraining corpus of 33,888 token pairs.
Their fullexperiment on varying the size of the training datais illustrated in Figure 1.76 7778 7980 8182 8384 850  5  10  15  20  25  30  35NormalisationaccuracySize of training data (K tokens)Normalisation accuracy for different sizes of the alignment training dataFigure 1: Normalisation accuracy when varyingthe size of the alignment training data.We use the same set of training data for the SMTapproach as for the filtering approach and for theassignment of weights in the Levenshtein-basedapproach, i.e.
a set of token pairs mapping his-torical word forms to their manually modernisedspelling.
These corpora have the format of one to-ken per line, with blank lines separating sentences.To fully adapt this format to the format neededfor training the character-based translation mod-els, the characters within each token are separatedby space.
The SMT system will now regard eachcharacter as a word, the full token as a sentenceand the entire sentence as a section.The SMT engine used is Moses with all its stan-dard components.
A phrase-based model is ap-plied, where the feature weights are trained us-ing MERT with BLEU over character-sequencesas the objective function.
The maximum size of aphrase (sequence of characters) is set to 10.Two different character alignment techniquesare tested: (i) the word alignment toolkit GIZA++(Och and Ney, 2000), and (ii) a weighted finitestate transducer implemented in the m2m-aligner(Jiampojamarn et al., 2007).
GIZA is run withstandard word alignment models for character un-igrams and bigrams, whereas the m2m alignerimplements transducer models based on context-independent single character and multi-characteredit operations.
The transducer is trained us-ing EM on (unaligned) parallel training data, andthe final model can then be used to produce aViterbi alignment between given pairs of charac-ter strings.An example is given in Figure 2, where the Ice-landic word forms me?r?
me?ur and giallda?galda have been aligned at a character-level usingthe m2m-aligner.
In this example, the  symbolrepresents empty alignments, meaning insertionsor deletions.
The  symbol in the source wordme?r denotes the insertion of u in the target wordme?ur.
Likewise, the  symbol in the target wordgalda denotes the deletion of i as compared to thesource word giallda.
Furthermore, the alignmentof giallda to galda illustrates the inclusion ofmulti-character edit operations, where the colondenotes a 2:1 alignment where both letters l and din the source word correspond to the single letterd in the target word.m|e|?||r| m|e|?|u|r|g|i|a|l|l:d|a| g||a|l|d|a|Figure 2: m2m character-level alignment.4 DataIn the following, we will describe the data setsused for running the filtering approach, the Lev-enshtein edit distance approach, and the character-based SMT approach for historical spelling nor-malisation applied to five languages: English, Ger-man, Hungarian, Icelandic, and Swedish.
Forconvenience, we use the notions of training, tun-35ing and evaluation corpora, which are well-knownconcepts within SMT.
These data sets have beencreated by extracting every 9th sentence from thetotal corpus to the tuning corpus, and every 10thsentence to the evaluation corpus, whereas the restof the sentences have been extracted to a trainingcorpus.1In the filtering approach, there is in fact nodistinction between training and tuning corpora,since both data sets are combined in the dictionarylookup process.
As for the Levenshtein edit dis-tance approach, the training corpus is used for ex-tracting single-character and multi-character editsby comparing the historical word forms to theirmodern spelling.
The edits extracted from thetraining corpus are then weighted based on theirrelative frequency in the tuning corpus.The historical texts used for training and evalu-ation are required to be available both in their orig-inal, historical spelling and in a manually mod-ernised and validated spelling.
A modern trans-lation of a historical text is generally not usable,since word order and sentence structure have to re-main the same to enable training and evaluation ofthe proposed methods.
The access to such data isvery limited, meaning that the data sets used in ourexperiments vary in size, genres and time periodsbetween the languages.4.1 EnglishFor training, tuning and evaluation in the En-glish experiments, we use the Innsbruck Cor-pus of English Letters, a manually normalisedcollection of letters from the period 1386?1698.This corpus is a subset of the Innsbruck Com-puter Archive of Machine-Readable English Texts,ICAMET (Markus, 1999).
A subset of the BritishNational Corpus (BNC) is used as the single mod-ern language resource both for the Levenshtein-based and for the SMT-based approach.
Table 1presents in more detail the data sets used in theEnglish experiments.4.2 GermanFor training, tuning and evaluation in the Germanexperiments, we use a manually normalised sub-set of the GerManC corpus of German texts fromthe period 1650?1800 (Scheible et al., 2011).
Thissubset contains 22 texts from the period 1659?1780, within the genres of drama, newspaper text,1For information on how to access the data sets used inour experiments, please contact the authors.Resource Data Tokens TypesTraining ICAMET 148,852 18,267Tuning ICAMET 16,461 4,391Evaluation ICAMET 17,791 4,573Lev.
dict.
BNC 2,088,680 69,153Lev.
freq.
BNC 2,088,680 69,153SMT lm BNC 2,088,680 69,153Table 1: Language resources for English.letters, sermons, narrative prose, humanities, sci-ence och legal documents.
The German Parolecorpus is used as the single modern language re-source both for the Levenshtein-based and for theSMT-based approach (Teubert (ed.
), 2003).
Table2 presents in more detail the data sets used in theGerman experiments.Resource Data Tokens TypesTraining GerManC 39,887 9,055Tuning GerManC 5,418 2,056Evaluation GerManC 5,005 1,966Lev.
dict.
Parole 18,662,243 662,510Lev.
freq.
Parole 18,662,243 662,510SMT lm Parole 18,662,243 662,510Table 2: Language resources for German.4.3 HungarianFor training, tuning and evaluation in the Hungar-ian experiments, we use a collection of manuallynormalised codices from the Hungarian Gener-ative Diachronic Syntax project, HGDS (Simon,To appear), in total 11 codices from the time pe-riod 1440?1541.
The Szeged Treebank is usedas the single modern language resource both forthe Levenshtein-based and for the SMT-based ap-proach (Csendes et al., 2005).
Table 3 presentsin more detail the data sets used in the Hungarianexperiments.Resource Data Tokens TypesTraining HGDS 137,669 45,529Tuning HGDS 17 181 8 827Evaluation HGDS 17,214 8,798Lev.
dict.
Szeged 1,257,089 144,248Lev.
freq.
Szeged 1,257,089 144,248SMT lm Szeged 1,257,089 144,248Table 3: Language resources for Hungarian.364.4 IcelandicFor training, tuning and evaluation in the Ice-landic experiments, we use a manually normalisedsubset of the Icelandic Parsed Historical Cor-pus (IcePaHC), a manually tagged and parsed di-achronic corpus of texts from the time period1150?2008 (R?gnvaldsson et al., 2012).
This sub-set contains four texts from the 15th century: threesagas (Vilhj?lm?s saga, Jarlmann?s saga, and Ec-tor?s saga) and one narrative-religious text (Mi?al-da?vint?ri).
As a dictionary for Levenshtein cal-culations we use a combination of Beygingar-l?sing ?slensks N?t?mam?ls, B?N (a database ofmodern Icelandic inflectional forms (Bjarnad?t-tir, 2012)), and all tokens occurring 100 times ormore in the Tagged Icelandic Corpus of Contem-porary Icelandic texts, M?M (Helgad?ttir et al.,2012).2The frequency-based choice of a final nor-malisation candidate in the Levenshtein approach,as well as the training of a language model in theSMT approach, are done on all tokens occurring100 times or more in the M?M corpus.
Table 4presents in more detail the data sets used in theIcelandic experiments.Resource Data Tokens TypesTraining IcePaHC 52,440 9,748Tuning IcePaHC 6,443 2,270Evaluation IcePaHC 6,384 2,244Lev.
dict.
B?N+M?M 27,224,798 2,820,623Lev.
freq.
M?M 21,339,384 9,461SMT lm M?M 21,339,384 9,461Table 4: Language resources for Icelandic.4.5 SwedishFor training, tuning and evaluation in the Swedishexperiments, we use balanced subsets of the Gen-der and Work corpus (GaW) of court records andchurch documents from the time period 1527?1812 (?gren et al., 2011).
As a dictionary for Lev-enshtein calculations we use SALDO, a lexical re-source developed for present-day written Swedish(Borin et al., 2008).
For frequency-based choice ofa final normalisation candidate, we use the Stock-holm Ume?
corpus (SUC) of text representative ofthe Swedish language in the 1990s (Ejerhed andK?llgren, 1997).
The SUC corpus is also used2The B?N database alone is not sufficient for Levenshteincalculations, since it only contains content words.to train a language model in the SMT-based ap-proach.
Table 5 presents in more detail the datasets used in the Swedish experiments.Resource Data Tokens TypesTraining GaW 28,237 7,925Tuning GaW 2,590 1,260Evaluation GaW 33,544 8,859Lev.
dict.
SALDO 1,110,731 723,138Lev.
freq.
SUC 1,166,593 97,670SMT lm SUC 1,166,593 97,670Table 5: Language resources for Swedish.5 ResultsTable 6 presents the results for different languagesand normalisation methods, given in terms of nor-malisation accuracy, i.e.
the percentage of tokensin the normalised text with a spelling identicalto the manually modernised gold standard, andcharacter error rate (CER), providing a more pre-cise estimation of the similarity between the nor-malised token and the gold standard version at acharacter level.
Table 7 summarises the results interms of Precision (Pre), Recall (Rec) and F-score(F) for the filtering approach, the Levenshtein-based approach (with and without filtering), andthe best-performing SMT-based approach.For the Levenshtein experiments, we have usedcontext-sensitive weights, as described in Section3.2.
In the SMT approach, we run GIZA withstandard word alignment models for character un-igrams (un) and bigrams (bi).
The m2m aligner isimplemented with single character edit operations(1:1) and multi-character operations (2:2).The baseline case shows the proportion of to-kens in the original, historical text that alreadyhave a spelling identical to the modern gold stan-dard spelling.
In the Hungarian text, only 17.1%of the historial tokens have a modern spelling,with a character error rate of 0.85.
For Germanon the other hand, accuracy is as high as 84.4%,with a character error rate of only 0.16.
At afirst glance, the historical spelling in the Hungar-ian corpus appears to be very similar to the mod-ern spelling.
A closer look however reveals re-current differences involving single letter substi-tutions and/or the use of accents, as for fiayval?fiaival, m?eghalanac?meghal?nak and hazaba?h?z?ba.37English German Hungarian Icelandic SwedishAcc CER Acc CER Acc CER Acc CER Acc CERbaseline 75.8 0.26 84.4 0.16 17.1 0.85 50.5 0.51 64.6 0.36filter 91.7 0.20 94.6 0.26 75.0 0.30 81.7 0.25 86.2 0.27Lev 82.9 0.19 87.3 0.13 31.7 0.71 67.3 0.35 79.4 0.22Lev+filter 92.9 0.09 95.1 0.06 76.4 0.35 84.6 0.19 90.8 0.10giza un 94.3 0.07 96.6 0.04 79.9 0.21 71.8 0.30 92.9 0.07giza bi 92.4 0.09 95.5 0.05 80.1 0.21 71.5 0.30 92.5 0.08m2m 1:1 un 90.6 0.11 96.0 0.04 79.4 0.21 71.2 0.31 92.3 0.08m2m 1:1 bi 88.0 0.14 95.6 0.05 79.5 0.21 71.5 0.30 92.2 0.08m2m 2:2 un 90.7 0.11 96.4 0.04 77.3 0.24 71.0 0.31 91.3 0.09m2m 2:2 bi 87.5 0.14 95.5 0.05 79.1 0.22 71.4 0.31 92.1 0.08Table 6: Normalisation results given in accuracy (Acc) and character error rate (CER).English German Hungarian Icelandic SwedishPre Rec F Pre Rec F Pre Rec F Pre Rec F Pre Rec Ffilter 93.6 97.8 95.7 95.0 99.6 97.2 77.4 96.0 85.7 89.3 90.6 89.9 87.5 98.3 92.6Lev 92.7 88.6 90.7 91.0 95.6 93.2 68.0 37.3 48.2 85.4 76.1 80.5 90.5 86.6 88.5Lev+filter 97.4 95.2 96.3 97.3 97.7 97.5 96.2 78.8 86.7 95.6 88.0 91.7 96.6 93.8 95.2SMT 98.2 95.9 97.0 98.7 97.9 98.3 98.3 81.3 89.0 82.0 85.2 83.6 98.6 94.1 96.3Table 7: Normalisation results given in precision (Pre), recall (Rec) and F-score (F).The Icelandic corpus also has a relatively lownumber of tokens with a spelling identical to themodern spelling.
Even though the Hungarian andIcelandic texts are older than the English, German,and Swedish texts, the rather low proportion of to-kens with a modern spelling in the Icelandic cor-pus is rather surprising, since the Icelandic lan-guage is generally seen as conservative in spelling.A closer inspection of the Icelandic corpus revealsthe same kind of subtle single letter divergencesand differences in the use of accents as for Hun-garian, e.g.
ad?
a?
and hun?
h?n.The simplistic filtering approach (filter), re-lying solely on previously seen tokens in thetraining data, captures frequently occurring wordforms and works surprisingly well, improvingnormalisation accuracy by up to 63 percentageunits.
The Levenshtein-based approach (Lev)in its basic version, with no parallel trainingdata available, also improves normalisation ac-curacy as compared to the baseline.
However,for all languages, the simplistic filtering approachyields significantly higher normalisation accuracythan the more sophisticated Levenshtein-based ap-proach does.
This could be partly explained bythe fact that frequently occurring word forms havea high chance of being captured by the filter-ing approach, whereas the Levenshtein-based ap-proach runs the risk of consistently normalisinghigh-frequent word forms incorrectly.
For exam-ple, in the English Levenshtein normalisation pro-cess, the high-frequent word form stonde has con-sistently been normalised to stone instead of stand,due to the larger edit distance between stonde andstand.
The even more common word form ben,which should optimally be normalised to been, hasconsistently been left unchanged as ben, since theBNC corpus, which is used for dictionary lookupin the English setup, contains the proper nameBen.
The issue of proper names would not bea problem if a modern dictionary were used forLevenshtein comparisons instead of a corpus, or ifcasing was taken into account in the Levenshteincomparisons.
There would however still be casesleft like stonde being incorrectly normalised tostone as described above, which would be disad-vantageous to the Levenshtein-based method.
Thelow recall figures, especially for Hungarian, alsoindicates that there may be old word forms thatare not present in modern dictionaries and thus areout of reach for the Levenshtein-based method, asfor the previously discussed Hungarian word formmeghal?nak.In the Lev+filter setting, the filter is used as afirst step in the normalisation process.
Only to-kens that could not be matched through dictio-nary lookup based on the training corpus are nor-malised by Levenshtein comparisons.
The idea is38that combining these two techniques would per-form better than one approach only, since high-frequent word forms are consistently normalisedcorrectly by the filter, whereas previously unseentokens are handled through Levenshtein compar-isons.
This combination does indeed perform bet-ter for all languages, and for Icelandic this is by farthe most successful normalisation method of all.For the SMT-based approach, it is interesting tonote that the simple unigram models in many casesperform better than the more advanced bigram andmulti-character models.
We also tried adding thefilter to the SMT approach, so that only tokens thatcould not be matched through dictionary lookupbased on the training corpus, would be consideredfor normalisation by the SMT model.
This didhowever not have a positive effect on normalisa-tion accuracy, probably because the training datahas already been taken care of by the SMT model,so adding the filter only led to redundant informa-tion and incorrect matches, deteriorating the re-sults.
For four out of five languages, the GIZA un-igram setting yields the highest normalisation ac-curacy of all SMT models evaluated.
For Hungar-ian, the GIZA bigram modell performs marginallybetter than the unigram model.From the presented results, it is not obviouswhich normalisation approach to choose for a newlanguage.
For Icelandic, the Levenshtein-basedapproach combined with the filter leads to thehighest normalisation accuracy.
For the rest ofthe languages, the SMT-based approach with theGIZA unigram or bigram setting gives the best re-sults.
Generally, the Levenshtein-based methodcould be used for languages lacking access to an-notated historical data with information on bothoriginal and modernised spelling.
If, on the otherhand, such data is available, the filtering approach,or the combination of filtering and Levenshteincalculations, would be likely to improve normal-isation accuracy.
Moreover, the effort of traininga character-based SMT system for normalisationwould be likely to further improve the results.It would be interesting to also compare the re-sults between the languages, in a language evo-lution perspective.
This is however not feasiblewithin the scope of this study, due to the differ-ences in corpus size, genres and covered time pe-riods, as discussed in Section 4.6 ConclusionWe have performed a multilingual evaluationof three approaches to spelling modernisationof historical text: a simplistic filtering model,a Levenshtein-based approach and a character-based statistical machine translation method.
Theresults were evaluated on historical texts fromfive languages: English, German, Hungarian, Ice-landic and Swedish.
We see that all approaches aresuccessful in increasing the proportion of tokens inthe historical text with a spelling identical to themodernised gold standard spelling.
We concludethat the proposed methods have the potential ofenabling us to use modern NLP tools for analysinghistorical texts.
Which approach to choose is notclear, since the results vary for the different lan-guages in our study, even though the SMT-basedapproach generally works best.
If no historicaltraining data is available, the Levenshtein-basedapproach could still be used, since only a mod-ern dictionary is required for edit distance com-parisons.
If there is a corpus of token pairs withhistorical and modern spelling available, trainingan SMT model could however result in improvednormalisation accuracy.
Since the SMT modelsare character-based, only a rather small amount oftraining data is needed for this task, as discussedin Section 3.3.We believe that our results would be of interestto several research fields.
From a language evolu-tion perspective, future research would include athorough investigation of why certain approacheswork better for some languages but not for otherlanguages, and what the results would be if thedata sets for the different languages were moresimilar with regard to time period, size, genre etc.The latter could however be problematic, due todata sparseness.
For historians interested in us-ing modern NLP tools for analysing historical text,an extrinsic evaluation is called for, comparingthe results of tagging and parsing using moderntools, before and after spelling normalisation.
Fi-nally, the proposed methods all treat words in iso-lation in the normalisation process.
From a lan-guage technology perspective, it would be inter-esting to also explore ways of handling grammat-ical and structural differences between historicaland modern language as part of the normalisationprocess.
This would be particularly interestingwhen evaluating subsequent tagging and parsingperformance.39ReferencesMaria ?gren, Rosemarie Fiebranz, Erik Lindberg, andJonas Lindstr?m.
2011.
Making verbs count.
Theresearch project ?Gender and Work?
and its method-ology.
Scandinavian Economic History Review,59(3):271?291.
Forthcoming.Alistair Baron and Paul Rayson.
2008.
Vard2: A toolfor dealing with spelling variation in historical cor-pora.
In Postgraduate Conference in Corpus Lin-guistics, Aston University, Birmingham.Krist?n Bjarnad?ttir.
2012.
The Database of ModernIcelandic Inflection.
In AfLaT2012/SALTMIL jointworkshop on Language technology for normalisa-tion of less-resourced languages, Istanbul, May.Alan W. Black and Paul Taylor.
1997.
Festival speechsynthesis system: system documentation.
Technicalreport, University of Edinburgh, Centre for SpeechTechnology Research.Marcel Bollmann, Florian Petran, and Stefanie Dipper.2011.
Rule-based normalization of historical texts.In Proceedings of the Workshop on Language Tech-nologies for Digital Humanities and Cultural Her-itage, pages 34?42, Hissar, Bulgaria.Marcel Bollmann.
2013.
POS tagging for historicaltexts with sparse training data.
In Proceedings ofthe 7th Linguistic Annotation Workshop & Interop-erability with Discourse, pages 11?18, Sofia, Bul-garia, August.
Association for Computational Lin-guistics.Lars Borin, Markus Forsberg, and Lennart L?nngren.2008.
Saldo 1.0 (svenskt associationslexikon ver-sion 2).
Spr?kbanken, University of Gothenburg.C.
Csendes, J. Csirik, T. Gyim?thy, and A. Kocsor.2005.
The Szeged Treebank.
In Proceedings ofthe Eighth International Conference on Text, Speechand Dialogue (TSD 2005), Karlovy Vary, Czech Re-public.Eva Ejerhed and Gunnel K?llgren.
1997.
StockholmUme?
Corpus.
Version 1.0.
Produced by Depart-ment of Linguistics, Ume?
University and Depart-ment of Linguistics, Stockholm University.
ISBN91-7191-348-3.Bo Han and Timothy Baldwin.
2011.
Lexical normali-sation of short text messages: Makn sens a #twitter.In Association for Computational Linguistics, edi-tor, Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics, pages368?378, Portland, Oregon, USA, June.Sigr?n Helgad?ttir, ?sta Svavarsd?ttir, Eir?kur R?gn-valdsson, Krist?n Bjarnad?ttir, and Hrafn Loftsson.2012.
The Tagged Icelandic Corpus (M?M).
InProceedings of the Workshop on Language Tech-nology for Normalisation of Less-Resourced Lan-guages, pages 67?72.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden markov models to letter-to-phonemeconversion.
In Proceedings of the Annual Confer-ence of the North American Chapter of the Asso-ciation for Computational Linguistics (NAACL-HLT2007), pages 372?379, Rochester, NY, April.Bryan Jurish.
2008.
Finding canonical formsfor historical German text.
In Angelika Storrer,Alexander Geyken, Alexander Siebert, and Kay-Michael W?rzner, editors, Text Resources and Lex-ical Knowledge: Selected Papers from the 9th Con-ference on Natural Language Processing (KON-VENS 2008), pages 27?37.
Mouton de Gruyter,Berlin.Manfred Markus, 1999.
Manual of ICAMET (Inns-bruck Computer Archive of Machine-Readable En-glish Texts).
Leopold-Franzens-Universit?t Inns-bruck.David Matthews.
2007.
Machine transliteration ofproper names.
Master?s thesis, School of Informat-ics.Preslav Nakov and J?rg Tiedemann.
2012.
Combin-ing word-level and character-level models for ma-chine translation between closely-related languages.In Proceedings of the 50th Annual Meeting of the As-sociation for Computational Linguistics (Volume 2:Short Papers), pages 301?305, Jeju Island, Korea,July.
Association for Computational Linguistics.F.
J. Och and H. Ney.
2000.
Improved statistical align-ment models.
pages 440?447, Hongkong, China,October.Eva Pettersson, Be?ta Megyesi, and Tiedemann J?rg.2013a.
An SMT approach to automatic annotationof historical text.
In Proceedings of the NoDaLiDa2013 workshop on Computational Historical Lin-guistics, May.Eva Pettersson, Be?ta Megyesi, and Joakim Nivre.2013b.
Normalisation of historical text usingcontext-sensitive weighted Levenshtein distance andcompound splitting.
In Proceedings of the 19thNordic Conference on Computational Linguistics(NoDaLiDa), May.Paul Rayson, Dawn Archer, and Nicholas Smith.
2005.VARD versus Word ?
A comparison of the UCRELvariant detector and modern spell checkers on En-glish historical corpora.
In Proceedings from theCorpus Linguistics Conference Series on-line e-journal, volume 1, Birmingham, UK, July.Eir?kur R?gnvaldsson, Anton Karl Ingason, Einar FreyrSigurdsson, and Joel Wallenberg.
2012.
The Ice-landic Parsed Historical Corpus (IcePaHC).
In Pro-ceedings of the Eight International Conference onLanguage Resources and Evaluation (LREC?12), Is-tanbul, Turkey, May.
European Language ResourcesAssociation (ELRA).40Silke Scheible, Richard J. Whitt, Martin Durrell, andPaul Bennett.
2011.
A Gold Standard Corpus ofEarly Modern German.
In Proceedings of the 5thLinguistic Annotation Workshop, pages 124?128,Portland, Oregon, USA, June.
Association for Com-putational Linguistics.Eszter Simon.
To appear.
Corpus building from OldHungarian codices.
In Katalin ?.
Kiss, editor, TheEvolution of Functional Left Peripheries in Hungar-ian Syntax.
Oxford University Press.Wolfgang Teubert (ed.).
2003.
German Parole Corpus.Electronic resource, Oxford Text Archive.David Vilar, Jan-Thorsten Peter, and Hermann Ney.2007.
Can we translate letters?
In Proceedings ofthe Second Workshop on Statistical Machine Trans-lation, pages 33?39, Prague, Czech Republic, June.Association for Computational Linguistics.41
