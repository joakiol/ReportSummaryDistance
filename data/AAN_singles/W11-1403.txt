Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 20?29,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsGenerating Varied Narrative Probability ExercisesMarie?t Theune1 Roan Boer Rookhuiszen1 Rieks op den Akker1 Hanneke Geerlings2Department of Computer Science1Department of Research Methodology, Measurement and Data Analysis2University of TwenteEnschede, The Netherlandsm.theune@utwente.nl, a.r.boerrookhuiszen@alumnus.utwente.nl,h.j.a.opdenakker@utwente.nl, h.geerlings@gw.utwente.nlAbstractThis paper presents Genpex, a system for au-tomatic generation of narrative probability ex-ercises.
Generation of exercises in Genpex isdone in two steps.
First, the system createsa specification of a solvable probability prob-lem, based on input from the user (a researcheror test developer) who selects a specific ques-tion type and a narrative context for the prob-lem.
Then, a text expressing the probabilityproblem is generated.
The user can tune thegenerated text by setting the values of somelinguistic variation parameters.
By varyingthe mathematical content of the exercise, itsnarrative context and the linguistic parametersettings, many different exercises can be pro-duced.
Here we focus on the natural languagegeneration part of Genpex.
After describinghow the system works, we briefly present ourfirst evaluation results, and discuss some as-pects requiring further investigation.1 IntroductionNarrative exercises (also called word problems orstory problems) are mathematical exercises embed-ded in a story or text.
They are commonly used astest items, to assess or train a student?s understand-ing of the underlying mathematical concepts.
Whensolving a narrative exercise, the student is requiredto derive the underlying mathematical question fromthe story and to calculate the correct answer to thismathematical problem.This paper presents Genpex, a system for generat-ing narrative exercises expressing probability prob-lems.
Genpex was created in the context of an inter-national project on item generation for testing stu-dent competencies in solving probability problems.Automatic item generation is an effective way ofconstructing many items with controlled difficulties,based on a set of predefined task parameters (Enrightet al, 2002; Deane and Sheehan, 2003; Arendasy etal., 2006; Holling et al, 2009).
The goal of our itemgeneration project is to develop a model to supportoptimal problem and test construction.
A large col-lection of narrative exercises is needed to test the de-veloped models in field trials.
All of these narrativeexercises should be different, but the properties thatdefine the difficulty of the exercise should be known.Genpex was designed to enable easy creation of newexercises meeting these requirements.Figure 1 shows a narrative probability exercisegenerated by Genpex.
The text of the exercise is inGerman, because the target group of our project areGerman high school students.
The texts producedby Genpex are based on a set of example narrativeexercises that were created earlier within the project(Zeuch, In preparation).A property that sets Genpex apart from othernarrative exercise generation systems is that it wasspecifically designed to support variation in the gen-erated exercises.
Unlike other systems, it not onlychanges the context of the narrative exercise (e.g.,instead of bikes, the example exercise could alsohave been about hotel rooms with different proper-ties) but it also varies the way the texts are formu-lated.
Most existing systems for narrative exercisegeneration use fixed sentence templates to expressmathematical content, which means that the samecontent is always expressed in the same way (Fa-20In einer gro?en Halle ist eine Mischung von Fahrra?dern.
In a big hall there are a variety of bicycles.Es gibt insgesamt 100 Fahrra?der.
There are 100 bicycles in total.Es gibt 30 gru?ne Fahrra?der und es gibt 70 wei?e.
40Fahrra?der sind Mountainbikes, 50 sind Rennra?der undes gibt 10 Hollandra?der.
70 Fahrra?der sind billiger als500 Euro und 30 Fahrra?der teurer als 500 Euro.
41Fahrra?der sind billiger als 500 Euro und sind Rennra?der.There are 30 green bicycles and there are 70 white ones.40 bicycles are mountain bikes, 50 are road bikes, andthere are 10 Dutch bikes.
70 bicycles are less expensivethan 500 Euros and 30 bicycles more expensive than 500Euros.
41 bicycles are less expensive than 500 Euros andare road bikes.Fahrradtyp und Preis sind abha?ngig voneinander undalle anderen Merkmale sind unabha?ngig voneinander.Bicycle type and price are dependent on each other andall other properties are independent of each other.Wie gro?
ist die Wahrscheinlichkeit, dass ein Fahrradnicht sowohl ein Mountainrad als auch gru?n ist?What is the probability that a bicycle is not both a moun-tain bike and green?Wie gro?
ist die Wahrscheinlichkeit, dass ein Fahrradentweder billiger als 500 Euro oder ein Rennrad ist?What is the probability that a bicycle is either cheaperthan 500 Euros or a road bike?Figure 1: The text of an exercise generated by Genpex.
(Left: German original, right: English translation.
)iron and Williamson, 2002; Arendasy et al, 2006;Holling et al, 2009).
A system that uses a linguisti-cally sophisticated approach, thus in principle allow-ing for similar text variations as Genpex, is Model-Creator (Deane and Sheehan, 2003; Higgins et al,2005).
However, this system focuses on semanticfactors influencing the expression of events with dif-ferent participants (e.g., different types of vehicles)rather than on generating linguistic variations.Below, we first describe how a probability prob-lem is constructed by Genpex, based on input by theuser.
Then we explain in some detail how the nat-ural language generation (NLG) module of Genpexcreates a text expressing the probability problem, fo-cusing on the creation of variation in the generatedtexts.
We end with a brief discussion of our firstevaluation results and some pointers to future work.2 Probability ProblemsFigure 2 presents the probability problem underly-ing the narrative exercise of Figure 1.
It specifies thecontext, the total number of entities (numEntities),and the distribution of (combinations of) attributevalues over the entities.
Number information may besuppressed so as not to give the answer away; this isdone by inserting a question mark in the place of thenumber (e.g., colour[green] = ?).
Explicitly listingsuch ?hidden?
information in the probability prob-lem ensures that all possible values of each attributeare mentioned in the text of the exercise.
A basic as-sumption in creating the probability problems is thatall entities have exactly one value for each attribute.For example, all bikes must have some colour, andthey cannot have two colours at the same time.In addition to the number statements, the proba-bility problem also lists which pairs of attributes aredependent on each other.
In the example, these aretype and price.
This means that if we look at thesubset of bikes of a specific type, the probability thatone of these bikes has a certain price is not the sameas when we look at the entire collection of bikes (andvice versa).
If a pair of attributes is not specified asbeing dependent, it is independent.Q delineates the question part of the probabilityproblem; we refer to the other parts (except Con-text) as ?statements?.
All questions require the cal-culation of a probability.
A question of the form Q:P(A) asks for the probability of event A, which canbe described as ?Someone randomly draws one en-tity out of a (sub)set of entities and this entity hasproperty A?.
For example, the question could be tocalculate the probability that a bike is black if werandomly pick one bike from the set of all bikes.
Weequate the probability of event A with the relativefrequency of the set A of objects that satisfy prop-erty A, computed as |A|/|U |, where U is the set ofall entities (that is, |U | = numEntities).
In general,the set we draw from is the entire set of entities, butthis set can be limited by a conditional statement:the event A|B can be described as ?Someone ran-domly draws one entity with property A from a sub-set of entities that have property B?.
In this case, the21Context: bikesnumEntities: 100colour[green] = 30colour[white] = 70type[mountainbike] = 40type[sportsbike] = 50type[hollandbike] = 10price[<500] = 70price[>500] = 30price[<500] ?
type[sportsbike] = 41dependentAttributes: price & typeQ: P(?
(type[mountainbike] ?
colour[green]))Q: P(price[<500] ?
type[sportsbike])Figure 2: The probability problem underlying Figure 1.probability P (A|B) is computed as |A?B|/|B|.
Allevents involve a single draw of exactly one entity.Probability problems such as the one in Figure 2are automatically created by Genpex; the only thingthe user has to do is to select one or more questiontypes (defining the difficulty of the exercise) and acontext for the exercise.
All available question typesare of the form P(A) or P(A|B), where A (but not B)can be a complex event, i.e., involving a conjunc-tion or disjunction of properties.
For example, Q:P(A ?
B) asks for the probability that an entity hasboth property A and property B.
Moreover, parts ofa question can be negated.Currently, Genpex can handle 25 different ques-tion types.
Some restrictions we put on the avail-able questions are the following.
Each question in-volves at most two different attributes, to avoid com-plex dependencies.
There are no recursive questions(e.g., double negations) and no conditional questionsabout independent attributes.
Finally, we excludequestions that are likely to result in ambiguous lan-guage.
For example, if we try to express the ques-tion Q: P(?
(colour[white]) ?
type[sportsbike]) inEnglish, it will be something like ?What is the prob-ability that a bike is not white and a road bike?
?.Due to scope ambiguity of the negation, this sen-tence may be misinterpreted as ?What is the prob-ability that a bike is not white and also not a roadbike??.
The same ambiguity is found in the Ger-man sentence expressing this question.1 Excluding1Genpex does include a re-ordered, mathematically equi-these types of questions does not simplify the taskfor Genpex; the excluded questions are not more dif-ficult to generate than the included ones.
The mainreason to exclude certain question types was to avoidcreating exercises that might be unclear to the reader.In addition to selecting one or more questiontypes as input for Genpex, the user also selects acontext for the exercise.
As a resource, Genpex usesa repository of context files2 with information con-cerning the entities that the exercise should be about(?bikes?
in our example) and the properties they mayhave.
Each attribute in the context file is linked toa lexical lemma for the word that expresses its rela-tion to the entity (e.g., bikes are of a certain colouror type but have a certain price).
Similarly, for eachattribute, a list of possible attribute values and thewords expressing them is provided.
For example,the type attribute in the bikes context can have thevalues ?mountainbike?, ?sportsbike?, ?hollandbike?and ?seniorbike?, respectively associated with thewords ?Mountainbike?
(mountain bike), ?Rennrad?
(road bike), ?Hollandrad?
(Dutch bike) and ?Se-niorenrad?
(senior bike).
Other NLG-related infor-mation in the context files is discussed in Section 3.The context file also specifies world knowledge suchas the range of numEntities (a context about roomsin a hotel will involve fewer entities than a contextabout books in a bookshop) and possible dependen-cies between attributes (in the bikes context, price ismore likely to be dependent on type than on colour).Taking the selected question type(s) and contextas input, Genpex automatically constructs a proba-bility problem.
This involves selecting a number ofattributes and values, depending on the question orquestions that need to be answered, and creating acorrect and complete world: an internal represen-tation of the situation in which all entities are fullydefined (all their properties are known), and thereare no inconsistencies.
A part of this world is re-flected in the statements of the probability problem.Currently, all statements provide information that isvalent version of the same question: Q: P(type[sportsbike] ??
(colour[white])).
Because the generated questions follow theorder of the attributes in the question specification, this versioncan be expressed without ambiguity as ?What is the probabilitythat a bike is a road bike and not white?
?2In the current Genpex prototype, five different contexts areavailable.
The system comes with an editor for the creation ofnew context files.22required to solve the exercise; redundant informa-tion is not included.
If the user manually edits thegenerated probability problem, Genpex reconstructsthe world, and tries to solve the exercise using the in-formation in the edited problem.
The user is warnedin case of inconsistencies or missing information.
Awarning is also issued if the edited problem containsproperties for which no lexical information is avail-able.
See Boer Rookhuiszen (2011) for more detailson how probability problems are constructed.3 Language GenerationThe NLG process of Genpex has two goals: generat-ing a correct textual representation of a given prob-ability problem, and enabling variation, so that mul-tiple runs will result in different texts.
The gener-ated texts should be in grammatically correct Ger-man, and they must be unambiguous: the formula-tion of the text should not leave the reader uncertainabout the underlying mathematical exercise.An overview of the NLG component of Genpexis given in Figure 3.
Its architecture reflects the lan-guage generation pipeline of Reiter and Dale (2000),with three modules: Document Planner, Microplan-ner and Surface Realizer.
Information between themodules is exchanged in the form of a list of sen-tence trees, each defining the content and grammat-ical structure of a sentence.
The Document Plannercreates basic sentence trees.
These are manipulatedby the Microplanner to create variations.
The mi-croplanning stage can in principle be skipped, butthat will result in very monotonous texts.
Finally,the Surface Realizer applies the correct morphologyto the sentence trees and creates the layout of thetext.
Below, we discuss each module in turn.3.1 Document Planning: Creating BasicSentence StructuresThe input of the Document Planner is a probabilityproblem, which defines the content and the structureof the narrative exercise.
The output is a documentplan: a structured list of sentence trees expressingthe statements and questions in the probability prob-lem.
The document plan also includes an introduc-tion: a simple ?canned?
text specified in the contextfile.
If multiple introduction texts are available, oneis randomly selected.Figure 3: The NLG module of Genpex.The sentences included in the document plan areall very simple, with the same basic structure.
Takefor example the statement colour[white] = 70.
TheDocument Planner first creates a subject NP ex-pressing the number of entities involved, e.g., ?70Fahrra?der?
(70 bicycles).
Then it creates a VP ex-pressing the relation and the attribute value, e.g.,?sind wei??
(are white).
The relevant words andtheir parts of speech are looked up in the contextfile.
For the example statement, this process resultsin the following basic tree, shown in a simplified no-tation.
Note that the words in the tree have not yetbeen inflected.
[s][np grammaticalRole=su][det grammaticalRole=num]70[/det][noun grammaticalRole=hd]Fahrrad[/noun][/np][vp][verb grammaticalRole=hd]sind[/verb][adj grammaticalRole=predc]weiss[/adj][/vp][/s]All sentence trees for questions start with thephrase ?Wie gro?
ist die Wahrscheinlichkeit dass?
(What is the probability that), included as cannedtext in a tree node with syntactic category ?clause?.23This main clause is followed by an indefinite NP re-ferring to the type of entities discussed in the exer-cise, e.g., ?ein Fahrrad?
(a bicycle).
The structureof the rest of the sentence tree depends on the ques-tion type.
Sentence tree templates are available forall possible question types.
They can be used recur-sively: slots in the templates can be filled with anexpression for an attribute value, or with one of theother templates.Figure 4 shows the construction of a sentence treefor a fairly complex question of type P(A ?
B |?
C), using multiple question templates.
For ques-tions about conditional probabilities Genpex usesthe slightly formal ?vorausgesetzt?
(given that), be-cause simpler phrasings are likely to be ambiguous.For example, assume we want to ask the questionQ: P(type[mountainbike] | colour[green]).
A sim-ple way to ask this question would be ?Wie gro?ist die Wahrscheinlichkeit dass ein gru?nes Fahrradein Mountainbike ist??
(What is the probability thata green bike is a mountain bike?).
However, sucha question could be mistakenly interpreted as ask-ing for a joint probability: Q: P(colour[green] ?type[mountainbike]).
For this reason, the more com-plex formulation is preferred.3.2 Microplanning: Creating VariationThe Microplanner modifies the sentence trees pro-duced by the Document Planner by applying a num-ber of variation techniques.
These techniquesplace specific requirements on the sentences towhich they can be applied, and therefore not everytechnique can be applied to all sentence trees.When introducing variation in the narrative formof the exercise, it is important that variations of thesame exercise should all have the same meaningand approximately the same difficulty.
According toDeane and Sheehan (2003), it is possible to changethe wording of a text without changing its difficulty.Reiter and Dale (2000) state that for example ag-gregating multiple sentences does not change the in-formation they express, but improves the readabil-ity and fluency of the text.
This is what we wantto achieve: adding variation to the text without af-fecting its interpretation.
Genpex therefore usesaggregation as well as a number of text variationtechniques, assuming that they do not influence themeaning or difficulty of an exercise.Figure 4: Construction of a question combining multipletemplates.
Translation, with brackets marking the tem-plate boundaries: ?What is the probability that a bicycle[[is either black or white] given that this bicycle [is not amountainbike]]?
?Below we discuss the operations applied to basicsentence trees in the Microplanner.
They are onlyapplied to sentences expressing statements, eventhough it would be practically possible to applysome of the variations to the questions too.
Giventhat understanding the question is crucial for solv-ing the exercise, and that varying the way the ques-tions are asked might cause confusion, we chose toadhere to a fixed format for the questions, cf.
Faironand Williams (2002).Aggregation.
As a first step, the Microplannerapplies aggregation: grouping multiple simple sen-tences and combining them into one complex sen-tence.
This process leaves the original order of thesentences in the Document Plan intact.
Sentencesreferring to different attributes are never grouped to-gether, to avoid possible misinterpretations.
For ex-ample, a complex sentence such as ?70 bicycles arewhite and 40 bicycles are mountain bikes?
mightsuggest that the 40 mountain bikes are different en-tities than the 70 white bikes, excluding the possibil-ity of white mountain bikes.
Since this is not the in-tended meaning, we avoid creating this kind of com-plex sentences.
Sentences referring to the same at-tribute can be grouped together without risk, becausethere can never be any overlap between the sets ofentities mentioned in these sentences (an entity can-not have multiple values for the same attribute).Aggregation is performed on a maximum of threesentences to prevent the generation of overly largeconjunctions.
Groups of four basic sentences are ag-24gregated into two new complex sentences.
This waywe avoid creating unbalanced texts like example 1below, preferring to generate sentences that are sim-ilar in both length and complexity, as in example 2.1.
42 Fahrra?der sind Mountainbikes, 168 Fahrra?dersind Rennra?der und 200 Fahrra?der sind Hol-landra?der.
10 Fahrra?der sind Seniorenra?der.
(42 bicycles are mountain bikes, 168 bicycles areroad bikes, and 200 bicycles are Dutch bikes.
10bicycles are senior bikes.)2.
42 Fahrra?der sind Mountainbikes und 168 Fahrra?dersind Rennra?der.
200 Fahrra?der sind Hollandra?derund 10 Fahrra?der sind Seniorenra?der.
(42 bicycles are mountain bikes and 168 bicyclesare road bikes.
200 bicycles are Dutch bikes and 10bicycles are senior bikes.
)Aggregation in Genpex is not optional; it is al-ways applied under the assumption that this willmake the generated texts more coherent and pleas-ant to read.
Moreover, it enables variation throughellipsis, as discussed later in this section.
Variationsin aggregation can be achieved by manually reorder-ing the statements in the probability problem.
Thiswill lead to a different Document Plan and as a con-sequence, to different aggregations, within the re-strictions stated above.Adjectivication.
The text variation technique wecall ?adjectivication?
changes the position and gram-matical role of the adjective (if any) expressing theattribute value in a sentence.
In basic sentence trees,attribute values expressed by adjectives are includedas predicative complements in the VP.
If we applyadjectivication to a sentence, the adjective is insteadadded as a modifier to the subject NP, and the orig-inal verb is removed.
To make the sentence treecomplete again, the words ?Es gibt?
(There are?
)are added in front.
For example, the sentence ?30Fahrra?der sind gru?n?
(30 bicycles are green) will bechanged to ?Es gibt 30 gru?ne Fahrra?der?
(There are30 green bikes).
In German, adjectivication maycause the inflection of the adjective to change, be-cause it gets a different grammatical role: when usedas a modifier its inflection reflects the gender andcase of the noun it modifies.
This is taken care of bythe Surface Realizer.Entity substitution.
In case an attribute valueis expressed as a noun, e.g., ?Rennrad?
(road bike)the text variation technique we call ?entity substitu-tion?
can be applied.
It involves replacing the nounthat represents the entity in a basic sentence with thenoun that represents the attribute value.
As with ad-jectivication, the original verb is removed and in-stead ?Es gibt?
(There are) is added to the sentence.For example, entity substitution changes the basicsentence ?50 Fahrra?der sind Rennra?der?
(50 bicyclesare road bikes) to ?Es gibt 50 Rennra?der?
(There are50 road bikes).Marked word order.
Another source of variationis topicalizing the phrase expressing the attributevalue by moving it to the front of the sentence.Applying this variation technique changes the ba-sic sentence ?30 Fahrra?der sind teurer als 500 Euro?
(30 bicycles are more expensive than 500 Euros) to?Teurer als 500 Euro sind 30 Fahrra?der?
(More ex-pensive than 500 Euros are 30 bicycles).
Since usingsuch a marked word order may come across as un-natural in a neutral discourse context, this type ofvariation should be applied with caution.Ellipsis.
This is the removal of duplicate wordsfrom sentences, which typically applies to aggre-gated sentences (Harbusch and Kempen, 2009).Genpex can apply different types of ellipsis, such asGapping and Conjunction Reduction.
Gapping is theremoval of all except the first verb in an aggregatedsentence.
An example from Figure 1 is the sen-tence ?70 Fahrra?der sind billiger als 500 Euro und30 Fahrra?der teurer als 500 Euro?
(70 bicycles areless expensive than 500 Euros and 30 bicycles moreexpensive than 500 Euros), where the verb ?sind?
(are) has been deleted from the second clause.
(For-ward) Conjunction Reduction deletes the subject ofsubsequent clauses if it is identical to the subject ofthe first clause.
The following sentence is an exam-ple: ?40 Fahrra?der sind Mountainbikes und 50 sindRennra?der?
(40 bicycles are mountain bikes and 50are road bikes).
It is possible to combine Gappingand Conjunction Reduction, e.g., ?40 Fahrra?der sindMountainbikes und 50 Rennra?der?
(40 bicycles aremountain bikes and 50 road bikes).Ellipsis is also possible in sentences with markedword order.
For example, ?Gru?n sind 30 Fahrra?derund wei?
sind 40 Fahrra?der?
(Green are 30 bicyclesand white are 40 bicycles) could be reduced to?Gru?n sind 30 Fahrra?der und wei?
sind 40?
(Green25are 30 bicycles and white are 40).
However, inthis sentence, the verb cannot be removed from thelast clause.
Genpex currently allows aggregatedsentences in which some of the clauses havemarked word order.
In these cases, ellipsis isnot applied, because it will most likely result ingrammatically incorrect sentences.
For example, inthe sentence ?30 Fahrra?der sind gru?n und Wei?
sind40 Fahrra?der?
(30 bicycles are green and white are40 bicycles) the system will not apply ellipsis.For every sentence in the document plan, the sys-tem will check which of the variation techniques de-scribed above can be applied to it, by analyzing thestructure of the sentence tree.
If a technique is inprinciple applicable, the probability of it being ac-tually applied depends on information in the contextfile, and on parameters set by the user through theGUI of Genpex.
For every attribute in the contextfile, the author of the file can prevent Genpex fromapplying a specific technique by giving it a probabil-ity of 0, if it is never suitable in the case of this spe-cific attribute.
For example, applying marked wordorder to a sentence expressing the ?type?
attribute inthe bikes context would lead to odd sentences suchas ?Mountainbikes sind 40 Fahrra?der?
(Mountain-bikes are 40 bicycles).
Though grammatically cor-rect, such sentences would be hard to interpret andtherefore are best avoided.During generation, the user can directly influ-ence the probability that certain variations are ap-plied through sliders in the GUI; see Figure 5.
Theprobability holds for every sentence that satisfies thestructural requirements of the variation techniquein question, unless the technique is excluded basedon the information in the context file, as explainedabove.
After having set the variation probabilities,the user can click ?Update Text?
to see the effect.The user can also choose to have the text automati-cally updated every time a slider is moved.When the user saves a generated exercise, infor-mation about the variation techniques that have beenapplied is logged and saved together with the exer-cise.
If further research shows that a certain varia-tion technique has an unintended influence on exer-cise difficulty, it will be easy to exclude this tech-nique from the creation of new exercises by settingits probability to 0 in the GUI.3.3 Surface Realisation: the Final PolishThe main task of the Surface Realizer is to convertthe sentence trees that have been manipulated by theMicroplanner to actual text, applying correct mor-phology and orthography.Information about German morphology is re-trieved from a lexicon listing the possible wordforms of each lemma in the context files.
Germanhas a rich inflectional system compared to English,with suffixes reflecting the gender, number and caseof determiners, adjectives and nouns.
Gender can bemasculine, feminine or neuter, number is singular orplural, and case is nominative, accusative, dative orgenitive.
In the type of exercises currently generatedby Genpex, all words are in nominative case.
Num-ber information for nouns and verbs is given in thesentence tree, while the inflection of determiners andadjectives in an NP depends on the properties of thenoun.
For the inflection of adjectives, Genpex alsohas to consider the determiner that is used beforethe adjective.
In German, so-called ?strong inflec-tion?
has to be used after a cardinal number, ?weakinflection?
after a definite determiner and ?mixed in-flection?
after an indefinite determiner.
We currentlyuse canoonet3 as the source for German morpholog-ical information in Genpex.Orthography is the process that converts the sen-tence trees to text.
This is quite easy, because theword order is already defined by the tree structure.All values of the nodes in the tree can be joinedtogether in a sentence in that order, separated bywhite spaces.
The clauses in aggregated sentencesare joined by a comma, except for the last conjunc-tion where the word ?und?
is used.
A characteristicof German is that all nouns are capitalized.
The Sur-face Realiser takes care of this, and also of the cap-italization of the first word in each sentence, punc-tuation and the placement of paragraph boundaries.The generated texts are marked up with HTML foreasy display in web browsers.4 EvaluationPotential users of Genpex (researchers working ontest design) have been involved at different stagesof development of the system, such as requirementsspecification and usability testing.
Field trials with3http://www.canoo.net/26Figure 5: Screenshot of the GUI of Genpex, showing a variation of the narrative exercise in Figure 1.
The introductorytext was taken from Zeuch (In preparation).students are future work, but we did carry out somepreliminary, qualitative evaluations with a few na-tive speakers of German (including one item gen-eration expert) to test the grammaticality and un-derstandability of the generated exercises.
This re-vealed some small mistakes that have since been cor-rected, but also a few bigger problems with some ofthe variation techniques and other NLG aspects.One of the things noted by the native speakers wasthat applying ellipsis sometimes leads to slightly un-natural sentences.
The preferred type and degree ofellipsis is different for each type of sentence, but thisis not taken into account by Genpex.
As a conse-quence, the system frequently applies too much ortoo little ellipsis to the generated sentences, with lessthan ideal (though not ungrammatical) results.
Theexistence of such preferred formulations is in linewith the results of Cahill and Forst (2010), who car-ried out an experiment in which native speakers ofGerman evaluated a number of alternative realisa-tions of the same sentence.
Their subjects acceptedsome variation in word order, but showed a clearpreference for some of the alternatives.Some of the generated question sentences alsosounded a bit forced to the native speakers.
For ex-ample, the question template for joint probabilities(A?B) uses the formal phrasing ?sowohl... als auch?
(both ... and), whereas a simple ?und?
(and) wouldbe the more natural choice for most questions.
How-ever, in some question contexts, in particular thoseinvolving negations, using the simpler formulationmight lead to the kind of scope ambiguities men-tioned in Section 2.
Therefore, the choice was madeto use ?sowohl... als auch?
in all cases, even in thosewhere it is not strictly necessary.
Similarly, ques-tions asking for a conditional probability were foundto be somewhat difficult to understand.
For thesequestions, readability might be improved by using27two sentences to express them, along the lines of?Consider the set of bicycles that are not mountainbikes.
What is the probability that one of those bi-cycles is either black or white??
as an alternative tothe more complex formulation given in Figure 4.The comments by the native speakers suggest thatin some cases, Genpex goes too far in its ?one sizefits all?
approach, and that we should try to addmore flexibility to the NLG component, allowing itto make finer distinctions in the application of varia-tion techniques to specific sentences and of questiontemplates to specific question types.5 DiscussionThe texts currently being generated by Genpex aregrammatical, but our native speakers reported thatsome sentences had to be studied carefully before itwas possible to get the information needed to solvethe problem.
No actual misinterpretations occurred,but the increased reading time (as compared to morepreferred formulations) may still increase the diffi-culty of the exercise.
A thorough investigation intothe effect of textual variations on item difficulty istherefore necessary.
Genpex supports this type ofresearch by enabling the systematic application ofdifferent variations, while logging all textual oper-ations that have been applied and saving them to-gether with the generated text.
The underlying prob-ability problem is saved together with the text aswell, so all factors that certainly or potentially in-fluence item difficulty are known.
This makes it rel-atively easy to test the influence of those factors onthe difficulty of the exercise, for example by carry-ing out the kind of statistical and cognitive analysisadvocated by Graf et al (2005).The effect of the main parameters of the proba-bility problems in Genpex (i.e., the type of questionbeing asked) was already statistically analyzed byHolling et al (2009) and Zeuch (In preparation).They used automatically generated items similar tothe exercises generated by Genpex, except that theirexercises did not have variations in wording apartfrom context-related ones.
Also, the exercises usedby Holling et al (2009) mentioned probabilities in-stead of counts in the statements.Once we know more about the effects of the tex-tual variations, Genpex can be of great value to testdevelopers, given that there exists a great need forlarge amounts of learning and assessment materi-als with a controlled level of difficulty (Enright etal., 2002; Fairon and Williamson, 2002; Deane andSheehan, 2003; Arendasy et al, 2006; Holling et al,2008; Holling et al, 2009).
The initial developmentand testing of the system is a one-time investment,which we expect will pay off afterward when largeamounts of test items can be created with little effort.In particular, we think Genpex can be very usefulin combination with Computerized Adaptive Test-ing (CAT).
The system could be used for on-the-flygeneration of new items for each individual student,adapted to that student?s skill level estimated fromhis or her previous answers.
Because every studentgets custom exercises, the risk of frequently useditems becoming known among students is reduced,thus increasing test security.In principle, given that the factors influencingitem difficulty are known, generating difficult itemsis not more complicated than generating easy ones.However, as illustrated in Section 2, combining mul-tiple difficulty factors such as negation and jointprobability may lead to textual formulations that areambiguous or hard to understand, and which ?
if notsuccessfully prevented in advance ?
may need to befiltered out or corrected by hand.
For that reason,Genpex seems most suitable for the generation ofexercises up to a moderate level of complexity.
Still,even if the need for hand-crafting will not be com-pletely eliminated, reducing it to complex items thatrequire particularly careful wording already repre-sents a big gain in efficiency.AcknowledgementsWe thank our anonymous reviewers and everybodywho helped testing Genpex.
Special thanks goto our colleagues from the University of Mu?nsterfor providing the reference exercises on whichthe Genpex output was modelled.
This researchwas funded by the Deutsche Forschungsgemein-schaft (DFG), Schwerpunktprogramm ?Kompetenz-modelle zur Erfassung individueller Lernergebnisseund zur Bilanzierung von Bildungsprozessen?
(SPP1293), project ?Rule-based Item Generation of Al-gebra Word Problems Based upon Linear LogisticTest Models for Item Cloning and Optimal Design?.28ReferencesMartin Arendasy, Markus Sommer, Georg Gittler, andAndreas Hergovich.
2006.
Automatic generation ofquantitative reasoning items: A pilot study.
Journal ofIndividual Differences, 27(1):2?14.Roan Boer Rookhuiszen.
2011.
Generation of Germannarrative probability excercises.
Master?s thesis, Uni-versity of Twente.Aiofe Cahill and Martin Forst.
2010.
Human evaluationof a German surface realisation ranker.
In E. Krahmerand M. Theune, editors, Empirical Methods in NaturalLanguage Generation, volume 5790 of Lecture Notesin Computer Science, pages 201?221.
Springer, Berlin/ Heidelberg.Paul Deane and Kathleen Sheehan.
2003.
Automaticitem generation via frame semantics: Natural languagegeneration of math word problems.
Educational Test-ing Service, Princeton.
Paper presented at the AnnualMeeting of the National Council on Measurement inEducation (Chicago, IL, April 22-24, 2003).Mary K. Enright, Mary Morley, and Kathleen M. Shee-han.
2002.
Items by design: The impact of systematicfeature variation on item statistical characteristics.
Ap-plied Measurement in Education, 15(1):49?74.Ce?drick Fairon and David M. Williamson.
2002.
Auto-matic item text generation in educational assessment.In Proceedings of TALN 2002, pages 395?401.Edith Aurora Graf, Stephen Peterson, Manfred Steffen,and Rene?
Lawless.
2005.
Psychometric and cogni-tive analysis as a basis for the design and revision ofquantitative item models.
Technical Report RR-05-25,Educational Testing Service, Princeton.Karin Harbusch and Gerard Kempen.
2009.
Generatingclausal coordinate ellipsis multilingually: A uniformapproach based on postediting.
In Proceedings of the12th European Workshop on Natural Language Gen-eration, pages 138?145.Derrick Higgins, Yoko Futagi, and Paul Deane.
2005.Multilingual generalization of the ModelCreator soft-ware for math item generation.
Technical Report RR-05-02, Educational Testing Service, Princeton.Heinz Holling, Helen Blank, Karoline Kuchenba?cker,and Jo?rg-Tobias Kuhn.
2008.
Rule-based item designof statistical word problems: A review and first imple-mentation.
Psychology Science Quarterly, 50(3):363?378.Heinz Holling, Jonas P. Bertling, and Nina Zeuch.
2009.Automatic item generation of probability word prob-lems.
Studies In Educational Evaluation, 35(2-3):71?76.Ehud Reiter and Robert Dale.
2000.
Building NaturalLanguage Generation Systems.
Cambridge UniversityPress, Cambridge, UK.Nina Zeuch.
In preparation.
Rule-based item construc-tion: Analysis with and comparison of linear logistictest models and cognitive diagnostic models with twoitem types.
Ph.D. thesis, University of Mu?nster.29
