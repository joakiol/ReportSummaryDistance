AUTOMATIC  SEMANTIC CLASSIFICATION OF VERBS FROM THEIRSYNTACTIC CONTEXTS: AN IMPLEMENTED CLASSIFIER FOR STATIVITYMichael R. BrentM IT  AI Lab545 Technology SquareCambr idge,  Massachusetts  02139michael@ai .mit .eduAbst rac tThis paper discusses an implementedprogram that automatically classifiesverbs into those that ~ describe onlystates of the world, such as to know, andthose that describe events, such as tolook.
It works by exploiting the con,straint between the syntactic environ-ments in which a verb can occur andits meaning.
The only input is on-linetext.
This demonstrates an importantnew technique for the automatic gener-ation of lexical databases.1 In t roduct ionYoung children and natural language process-ing programs face a common problem: everyoneelse knows a lot more about words.
Children, it ishypothesized, catch up by observing the linguis-tic and non-linguistic contexts in which words areused.
This paper focuses on the value and acces-sibility of the linguistic context.
It argues thatlinguistic ontext by itself can provide useful cuesabout verb meaning to an artificial learner.
This isdemonstrated bya program that exploits two par-ticular cues from the linguistic ontext o classifyverbs automatically into those whose sole sense isone describing astate, and those that have a sensedescribing an event.
1 The approach described hereaccounts for a certain degree of noise in the inputdue both to mis-apprehension f input sentencesand to their occasional real.formation.
This workshows that the two cues are available and are re-liable given the statistical methods applied.Language users, whether natural or artificial,need detailed semantic and syntactic lassifica-tions of words.
Ultimately, any artificial anguageIThe input  sentences are those compiled in the Lan-caster/Oslo/Bergen (LOB) Corpus, a balanced corpusof one million words of British English.
The LOB con-sists primarily of edited prose.user must be able to add new words to its lexicon,if only to accommodate he many neologisms i twill encounter.
And our lexicographic needs growwith our understanding of language.
A numberof current approaches to satisfying the lexical re-quirements for artificial devices do not involve un-supervised learning from examples.
Boguraev andBriscoe (1987)discusses interpreting the informa-tion published in on-line dictionaries, while Zernika/~d Dyer (1987) discuss tutored learning in a con.trolled environment.
But any method that re-quires explicit human intervention - - be it that oflexicographers, knowledge ngineers, or "tutors"- -  will lag behind both the growth of vocabu-lary and the growth of linguistics, and even withthe lag their maintenance will be expensive.
Bycontrast, dictionaries constructed by automatedlearners from real sentences will not lag behindvocabulary growth; examples of current languageuse are free and nearly infinite.
These observa-tions have led ~everal researchers, including Hindle(1990) and Smadja nd McKeown (1990), to begininvestigating automatic acquisition of semantics.Hindle and Smadja and McKeown rely purely onthe ability of one particular word to statisticallypredict the occurrence of another in a particularposition.
In contrast, he approach described hereis targeted at particular semantic lasses that arerevealed by specific linguistic onstructions.2 The  Quest ionsThis section discusses work on two linguis-tic cues that reveal the availability of non-stativesenses for verbs.
This work attempts to determinethe difficulty of using the cues to classify verbs:into those describing states and those describingevents.
To that end, it focuses on two questions:1.
Is it possible to reliably detect he two cuesusing only a simple syntactic mechanism andminimal syntactic knowledge?
How simplecan the syntax be?
(The less knowledge re-quired to learn using a given technique, the- 222 -Jmore useful the technique will be.)2.
Assuming minimal syntactic power, how re-liable are our two cues in real text, whichis subject to performance limitations?
Arethere learning strategies under which their re-liability is adequate?Section 2.1 describes yntactic onstructions stud-ied and demonstrates their relation to the stativesemantic lass.
Sections 2.2 answers questions 1in the affirmative.
Section 2.4 answers question 2in the affirmative, discusses the statistical methodused for noise reduction, and demonstrates theprogram that learns the state-event distinction.2.1 l ' teveaHng Const ruct ionsThe differences between verbs describingstates (statives) and those describing events (non-statives) has been studied by linguists at leastsince Lakoff (1965).
(For a more precise seman-tic characterization f stativ?s ee Dowty, 1979.
)Classic examples of stative verbs are know, believe,desire, and love.
A number of syntactic tests havebeen proposed to distinguish between statives andnon-statives (again see Dowry, 1979).
For exam-ple, stative verbs are anomalous when used in theprogressive aspect and when 'modified by rate ad-verbs such as quickly and slowly:(1) a.
* Jon is knowing calculusb.
* Jon knows calculus quicklyPerception verbs like see and hear share with st~-rives a strong resistance to the progressive aspect,but not to rate adverbs:(2) a.
* Jon is seeing the carb.
OK Jon quickly saw the carAgentive verbs describing attempts to gain per-ceptions, like look and listen, do not share eitherproperty:(3) a. OK Jon is looking at a carb.
OK Jon quickly looked at his watchThe classification program relies primarily on theprogressive cue, but uses evidence from the rateadverb cue when it is available.2.2 Syntact i c  Requ i rements  for  CueDetect ionConsider first how much syntactic analysis isneeded to detect the progressive and rate adverbconstructions.
Initially, suppose that the availabil-ity of a non-stative sense is aii intrinsic property ofa verb 2 not affected by its syntactic ontext.
Todetect progressives one need only parse a trivialpart of the auxiliary system, which is known to2This is not true in general, as shown by the f&ctthat think that.., is stative while think about.., is not.be finite-state.
Detecting the rate aclverb cue re-quires determining what the adverb modifies, andthat can be trickier.
For example, adverbs mayappear after the direct object, (4a), and this mustnot be confused with the case where they appearafter the subject of an embedded clause, (4b).
(4) a. ,Ion fixed the robot quicklyb.
,Ion knew his hostess rapidly lost inter-eat in such thingsUsing simple, finite-state machinery one would beforced to deal with (4b) by recognizing the po-sition of the adverb as ambiguous and rejectingthe example.
Or one could deploy more sophist i -cated syntax to try determining the boundaries ofembedded sentences.
But even the best syntacticparser will fail on truly ambiguous cases like thefollowing:(5) a. Jon fixed the robot that had spokenslowlyb.
Jon believed the robot that had spokenslowlyThe data on rate adverbs were collected usingthe parsing approach, which required a substantialamount of machinery, but a finite-state approachmight do almost as well.
(See Brent and Berwick,1991, for automatic iexical acquisition using sim-ple finite-state parsing.
)2.3 Data  on Cues f rom the  CorpusTo test the power of the two proposed cues,the LOB corpus was automatically processed todetermine what percentage of each verb's occur-rences were in the progressive, and what percent.age were modified by rate adverbs.
Sampling errorwas handled by calculating the probability distri-bution of the true percentage for each verb assum-ing that the sentences in the corpus were drawnat random from some infinitely large corpus.
Theoverall frequency of the progressive constructionwas substantially higher than that of the rate ad-verb construction and so provided more significantdata.
Figure 1 shows a histogram constructed bysumming these distributions of true frequency inthe progressive over each of the 38 most commonverbs in the corpus.
3 Figure 1 shows that, at leastfor these most common verbs, there are three andperhaps four distinct populations.
In other words,these verbs do not vary continuously in their fre-quency of occurrence in the progressive, but rathershow a marked tendency to cluster around certainvalues.
As will be shown in the next section, the3Histograms that include less frequent verbs havethe same general character, but the second local maxi-mum gets somewhst blurred by the many verbs whosetrue frequency in the progressive is poorly localizeddue to insufficient sample size.- 223 -(p r ln t -h l s togren  h$?S :wax- index  200 : sca le  tOO0)NILI I I I I I i I I I I I I I \[ I-\[T -I IO.O 0 .0 |  0.02 III.OS 0.84 O.IIS 0?06 O.OT (I.O0 II.O* 0.1 I I .
| |  0.12 | .13  0.14 O.
IS 0. l?
II.I\]P I I .
lO 0.19 0 .2I~ic L/so Liatener fFigure 1: A h i s togram const ructed  by  smnming the  probab i l i ty  d i s t r ibut ions  o f  t rue  f requencyin the  progress ive  over  each o f  the  38 most  common verbs  in the  corpusstative verbs fall in the first population, to the leftof the slight discontinuity at 1.35% of occurrencein the progressive.2,4 The  Class i f icat ion Program1 implemented a program that attempts toclassify verbs into those with event senses, andthose whose only meaning describes a state ratherthan an event.
It does this by first detecting oc-currences of the progressive and rate adverb con-structions in the LOB corpus, and then computingconfidence intervals on the true frequency of occur-rence of each verb in an arbitrarily large corpusof the same composition.
The program classifiesthe verbs according to bounds, which are for themoment supplied by the researcher, on the confi-dence intervals.
For example, on the run shownin Figure 2, the program classifies verbs which oc-cur at least .1% of the time either in the progres-sive or modified by a rate adverb, as having anevent (non-stative) sense.
The classifier acts on.1% bound only if the sample-size is large enoughto guarantee the bound with 95% confidence.
Ac-curacy in ascribing non-stative senses accordingwith this technique is excellent - -  no purely sta.t ire verbs are ntis-classified as having non-stativesenses.
In fact, this result is not very sensitive toraising the minimum progressive frequency from.1% to as high as .6% or .7%, since most verbswith non-stative senses yield observed frequenciesof at least two or three percent.Now consider the other side of the problem,classifying verbs as purely stative.
Here the pro-gram takes verbs that fail the test for having anon-stative sense, and in addition whose true fre-quency in the progressive falls below a given upperbound with sufficient confidence.
The rate-adverbconstruction is not used, except insofar as theverbs must fail the .
1% lower bound, because thisconstruction turns out to be so rare that only afew of the most frequent verbs provide sufficientlytight bounds.
The results for identifying pure sta-- 224 -(?lass i ry -s ta t lve -non-s ta t lve  :nax-proor - fo r - s ta t lve  .OlOS~n ln - r l te - fo r -non-s ta t lve  .OOI:n ln-proor - for -non-stat lve .00 | )LRCKS-NRN-STRTIVE-SERSE:KHOU SEER LIKE RELIEVE URHT OERRIN HERR HERR REOUIRE UNDEGSTRHO RCGEEHRS-UOH-STRTIVE-SEHSE:UEflR URZT 00 TRLK SROU SO ?TRY TRY VISIT LISTEN LIE SIT PREPRRE FRIL SEEK HONOEG FIGHT UORK STOOYB(GZH ORIVE URTCH OERL OCT EHJOY SETTLE SflILE PLRY OZE LIVE HUH HOVE 8TRRO HOPPER HOLK CRERTE PROVECRUSE OR(OK DROP LOOK CRRRY FRCE RTTEND EXPECT FRLL (HO OEVELOP OFFER ERT URIT\[ OEO0 CLOSE RECOil( POIHT OORU RETURN RISE BUILD CHRHCE DIN COnE LERRN PUBLISH PICK RSSOCIRTE GET PRODUCE REPLY PRY LEROZRTRODUC\[ COflPLETE REFUGE SRV( NOTICE PULL OVOID RECEIVE SERVE PDES?RT STOP OPEN ENTER SET SPEHO ~IGHFORGET HOTE RGSURE PLRCE IHCRERSE OCCUR COHPRRE COHSIOER SUGGEST COVER DISCOVER SELL THINK OEGOGO RFF~CT KEEP HOLO FOLLOU PUT HEET RCCEPT 8EHO HELP REVERL BOISG ORIGE OPPERR PGOVIO\[ TONE GEH?HOEO SPEEKFINISH TURN DSK RERCH LET TELL RRK\[ FELL RHSUER FIND LERV\[ RCHIEVE FEEL CRLL 6HON USE (XPLRIN GIVEOGTRIN OECIOE DRY SEEIHOETEGHIRATE:THROU REFER BRSE CHOOSE CRrCH ORRIVE KRRRGE SUPPORT EXIST BELONG OHISE BERD REEO CUT IHTEHO IRRCIUE CLRIH FQRfl BUY HE STRTE gILL RPPLY REISQVE RERLISE HOPE RRINTRIN JOIN HEHTIGN FILL OOnI!
OEPEHO REPORTOLLOU flROOY ESTRRLISR IHOICRTE LRY LOOSE SPERK SUPPOSE REDUCE REPRESENT LOVE ZHUOLUE COHTRIH OO0 STORY8R IHCLUOE COHCERH COHTIHU\[ OE$CRIBEHILOynarnic Lisp Listener fFigure 2: One  run  o f  the s ta t ive /non-s ta t ive  c lassi f icat ion program on verbs  occur r ing  at  least100 t imes in the  LOB corpustives are also quite good, although more sensitiveto the precise bounds than were the results foridentifying non-statives.
If the upper bound onprogressive frequency is set at 1.35%, as in Fig-ure 2, then eleven verbs are identified as purelystative, of the 204 distinct verbs occurring at least100 times each in the corpus.
Two of these, hearand agree, have relatively rare non-stative senses,meaning to imagine one hears ("I am hearing aringing in my ears") and to communicate agree-ment ("Rachel was already agreeing when Jon in-terrupted her with yet another tirade").
If the up-per bound on progressive frequency is tightened to1.20% then hear and agree drop into the "indeter-minate" category of verbs that pass neither test.So, too, do three pure statives, mean, require, andunderstand.It is worth noting the importance of usingsome sort of noise reduction technique, such asthe confidence intervals used here.
There are twosources of noise in the linguistic input.
Firstspeakers do utter anomalous entences.
For ex.ample, the stative verb mean occurred one timeout of 450 in the progressive.
The sentence, "It'sa stroke, that was what he was meaning" is clearlyanomalous.
The second source of noise is failureof the learner to detect the cue accurately.
Theaccuracy of our automatic ue detection detectionis described in the following section.2.5 Accuracy  o f  Cue  Detect ionSection 2.2 discussed how much structure mustbe imposed on sentences if the progressive andrate-adverb constructions are to be detected.
Sec-tion 2.3 showed that the progressive and rate-adverb constructions are indeed reliable cues forthe availability of a non-stative sense.
This sec-tion discusses tile accuracy with which these cuescan be detected.It is not practical to check manually everyverb occurrence that our program judged tO beprogressive.
Instead, I checked 300 such sentences225 -selected at random from among the most com-monly occurring verbs.
This check revealed onlyone sentence that did not truly describe a progres-sive event.
That sentence is shown in (6a).
(6) a. go: What that means in this case is go.ing back to the war years...b. see: The task was solely to see howspeedily it could be met...c. compare: ...the purchasing power of theunderdeveloped countries in the com-monwealth will rise slowly comparedwith that of Europe.It is not clear how to automatically determinethat (6a) does not describe an event of going inprogress.
Rate adverbs are infrequent enough thatit was possible to verify manually all 281 cases theprogram found.
In four of those cases the rate ad-verb actually modified a verb other than the onethat the program chose.
Three of these four caseshad the structure of (6b), where a wh- relativeis not recognized as signaling the beginning of anew clause.
This reflects an oversight in the gram-mar that should be easily correctable.
The one re-maining case of a mis-attributed rate adverb, (6c),would again require some work, and perhaps ub-stantial syntactic knowledge, to correct.
The rateof false positives in cue detection, then can be esti-mated at about one serious hazard in 300 for both"t'~sts.3 Conc lus ionsThis work demonstrates a promising ap-proach to automatic semantic classification ofverbs based only on their immediate linguistic on-texts.
Some sort of statistical smoothing is essen-tial to avoid being permanently mislead by anoma-lous and misunderstood utterances, and this workdemonstrated the sufficiency of an-approach basedon binomial confidence-intervals.
These meth-ods, in combination with pure collocational meth-ods like those of \[Hindle, 1990\] and \[Smadja ndMcKeown, 1990\], may eventually ield substan-tial progress toward automatic acquisition of wordmeaning, or some aspects thereof, by language us-ing devices.The initial results described here suggestmany more experiments, ome of which are al-ready u~nderway (see Brent and Berwick, 1991).These include attempting to take into account heability of local syntactic ontext to influence averb's meaning as well as to reveal it.
For exam-ple, think that is stative while think about and thinkof are not.
Separating these two senses automati-cally could add substantial power to our classifier.Next, there are many more linguistic ues to verbmeaning to be detected and exploited.
For exam-ple, the ability to take both adirect object and apropositional complement, asin "tell him that he'sa fool", reveal verbs of communication.
While theprogressive cue is not available in Romance lan-guages, the ability to take a direct object and apropositional complement seems to be diagnosticof communication verbs in Romance as well as inEnglish.
It would be valuable to demonstrate cueslike this on non-English text.
It would also bevaluable to apply these techniques to a greater va-riety of input sentences, including transcriptionsof mother's peech to their children.
Finally, sub-stantially larger corpora should be used in orderto enlarge the number of verbs classified.
All ofthese planned extensions serve the goal of auto-matically classifying thousands of verbs by dozensof different syntactic riteria, and thereby ieldinga valuable, adaptable l xicon for natural anguageprocessing and artificial intelligence.Re ferences\[Boguraev and Briscoe, 1987\] B. Boguraev andT.
Briscoe.
Large Lexicons for Natural Lan-guage Processing: Utilising the Grammar Cod-ing System of LDOCE.
Comp.
Ling., 13(3),1987.\[Brent and Berwick, 1991\] M. Brent andR.
Berwick.
Automatic Acquisition of Subcate-gorization Frames From Free Text Corpora.
InProceedings of the 4th Darpa Speech and Natu-ral Language Workshop.
Defense Advanced Re-search Projects Agency, Arlington, VA, USA,1991.\[Dowty, 1979\] D. Dowty.
Word Meaning andMontague Grammar.
Synthese Language Li-brary.
D. Reidel, Boston, 1979.\[Hindle, 1990\] D. Hindle.
Noun cla-qsification frompredicate argument structures.
In Proceedingsof the ~Sth Annual Meeting of the ACL, pages268-275.
ACL, 1990.\[Lakoff, 1965\] G. Lakoff.
On the Nature of Syntac.tic Irregularity.
PhD thesis, Indiana University,1965.
Published by Holt, Rinhard, and Winstonas Irregularity in Syntax, 1970.\[Smadja and McKeown, 1990\]F. Smadja and K. McKeown.
Automaticallyextracting and representing collocations for lan-guage generation.
In ~8th Annual Meeting ofthe Association for Comp.
Ling., pages 252-259.ACL, 1990.\[Zernik and DYer, 1987\] U. Zernik and M. Dyer.The self-extending phrasal lexicon.
Comp.Ling., 13(3), 1987.- 226 -
