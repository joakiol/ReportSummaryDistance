BUILDING AN MT I)ICTIONARY FROM PARAI~LEI~ TEXTSBASED ON LINGUISTIC AND STATISTICAL INIi'ORMATIONAkira Kumano ltidcki ltirakawaR & D Center, Toshiba Corporation1, Komukai Toshiba-cho, Saiwai-ku, Kawasaki, 210, JAPAN{ km n,hirakawa} @ist.rdc.toshiba.co.jpAbstractA method for generating a machine translation(MT) dictionary from parallel texts is described.This method utilizes both statistical informationand linguistic information to obtain correspondingwords or phrases in parallel texts.
By combiningthese two types of information, translation pairswhich cannot be obtained by a linguistic-basedmethod can be extntcted.
Over 70% accurate transla-tions of compound nouns and over 50% of unknownwords are obtained as tbe first candidate from smallJapanese/Englisb parallel texts containing severe dis-tortions.1 INTRODUCTIONParallel texts (corpora) are useful resources foracquiring a variety of linguistic knowledge (Dangan,1991; Matsumoto, 1993), especially for machinetranslation systems which inherently require cus-tomizations.
Translation dictionaries are, needlessto say, the most basic and powerful knowledgesource for improving and customizing translationsystems.
Our research interest lies in automatic gen-eration of translation dictionaries from paralleltexts.
In this perspective, finding correspondingwords or phrases in bilingual texts will be the fun-damental factor for accurate translation.Statistics-based processing has proven to be verypowerful for aligning sentences and words in paral-lel corpora (Brown, 1991; Gale, 1993; Chen, 1993).Kupiec proposes an Mgorithm for finding ~loun phras-es in bilingual corpora (Kupiec, 1993).
In this algo orithm, noui~-phrase candidates are extracted fromtagged and aligned parallel texts using a noun phraserecognizer and tile correspondences of these nonnphrases are calculated based on the EM algorithm.Accuracy of around 90% has been attained for theImndred highest ranking con'espondenccs.
Statistics-based processing is effective when a relatively largeamount of parallel texts is available, i.e.
when highfrequencies are obtained.On the other hand, existing linguistic knowl-edge can be used for finding corresponding words orphrases in parallel texts.
For example, possible tar-get expressions for a source expression provided by atranslation system (linguistic knowledge source) canbe a key in searching the corresponding expressionsin a corpus (Nogami, 1991; Katoh, 1993).
Yanramo-to (1993) proposes a method for generating a transla-tion dictionary from Japanese/English paralleltexts.
In this method, English and Japanese com-pound noun phrases are extracted from paralleltexts and their correspondences are searched bymatching their possible translations generated by tileexisting translation dictionary.
However,acquirable noun phrases are limited by tile linguisticgenerative power of the translation dictionary.
Fur-thernlore, tiffs method utilizes no sentence align-meat information which can reduce errors in findingnoun phrase correspondences.This paper proposes a new method for generat-ing an MT dictionary from parallel texts.
It uti-lizes both statistical and linguistic information toobtain corresponding words or phrases in paralleltexts.
By combining these two types of informa-tion, translation pairs which cannot be obtained bythe above linguistic-based method can be extracted,and a highly accurate translation dictionary is gener-ated from relatively small par:dlel texts.2 APPROACtt  TO BUILDING AN MT1) ICT IONARYOur goal in building an MT dictionary from par-allcl texts is to develop a robust method whichenables highly accurate extraction of translationpairs from a relatively small amount of paralleltexts as well as from parallel texts containingsevere distortions.In real-world applications, generally it isextremely difficult especially for MT users toobtain a large amount of high quality parallel textsof one specific domain.
If source and target lan-guages do not belong to the same linguistic family,like Japanese and Fnglish, tile situation becomesgrave.As one typical example of MT dictionary compi-lation, we have selected Japanese and English patentdoemnents which contain many state-of-the-m~t tech-nical terms.
Althougb thes~ documents are not cul-76Japanese \[--English 1Text l Text; ,,nit extractio,, I\[Corresponding \]-.. ~- - ->' L~nil Table \[ \ I Linguistic- - r+- -  '?d?
?List \[ ~l candidate v_~-  ~-\[ j ____._j-'-'-----~ generation ~_____~ /I statistical I /j /f , .mation J\[ Translation PairsFig.
1: Flow of building an MT dictionaryfrom paralh.q textsturally biased, in many cases, tile organizationbetween Japanese and English greatly differs andextensive changes are made ill translating fromJapanese to English text and vice vm.~a.
Hence, tiledifficulty of word extraction from patents.To solve this problem, we explored the appro-priate integration method considering the use of lin-guistic information and statistical information tothis end.
Lingt, istic information is useful in makingan intelligent judgment about correspondencebetween two languages even from partial textsbecause of its lexical, syntactic, and semantic knowl-edge; statistical information is characterized by itsrobustness against noise because it can tnmsformmany actual examples into an abstract fom~.Below is the flow of ot, r method illustrated inFig.
1 :(1) Unit Extraction:Pmls of documents ("units") are extracted fromboth Japanese and English texts.
(2) Unit Mapping:I&mh Japanese nnit is mapped into English units.
(3) Term Extraction:Japanese term candidates are extracted by theNP recognizer.
(4) Translation Candidate Generation:English translation candidates for Japaneseterms are extracted from English units.
(5) English Translation D;timation:Tim translation candidates are evah, ated toobtain the best one,Tim subsequent sections show tim details of eachprocessing.3 FORMING UNIT  CORRI{SPON-DENCESThe plausible hypothesis that parallel sentencescont,,in corresponding linguistic expressions is themajor premise in Kupiec (1993).
This type of info,-mation should be wklely used.
The problem is thattim alignment method based on tile sentence beadmodel (Brown, 1991) is not applicable to patent doc-uments due to their severe disto,fions in doculnentstrtlctures and sel l tence correspol ldences.
Conse--quently, we have introduced a concept called "unit"which corresponds to a pa~t of sentence and adopteda new method to extract corresponding units byusing linguistic knowledge as a primaxy source ofhi formation.3.1 l , :xh 'ac l ion  of  Un i tsFirst, units are extracted from parallel texts.The unit corresponds to sentences or phrases ill tiletext.
Terms which should be extracted can be foundwithin a unit.
"File rest of words in the unit iscalled contextual infommtion for tile extractedterm.
Tile size of units determines tile effectivenessof the st,eceeding unit mapping process.
For exa,n-pie, if we set noun phrases (enny words in a dictio-naly) as :.1 unit, no contextual information is avail-able, and thus tim probability that correspondingrelations hold decreases.
In our present implementa-tion, we set sentences as a unit for tile first approxi-mation.3.2 Ma l )p ing  of  Un i i sNext, the unit mapping process creates a cone-sponding unit table from Japanese ~,nd Englishvails.
This table stores the correslmndenee r lation-ship between milts and its likelihood.
The likeli..hood is calculated based on the linguistic informa-tion in an MT bilingual dictionary,Our trait mapping algorithm is given below:(1) l,ct ,1 be a set of all content words in tileJapanese unit JU.
(m iS tim number of words),1 ={ J l ' J2  ..... lm}(2) l.et E be a set of all content words in theF, nglish unit \[{\[J.
(n is tile number of words)E=:{ E 1,1{2...F; n} J(3) .v is the number of .li's whose translation candi-77date list includes ome Ej in E.(4) y is the number of Ej's which is included in thetranslation candidate list of some Ji in J.
(5) The correspondence likelihood CL is given byCL(JU, EU) = - x + ym+nFor each JU, M (currently 3) English unitswith the highest CL(JU, EU) are stored in the corre-sponding unit table.4 GENERATING TRANSLAT IONCANDIDATES4.1 Ext rac t ion  o f  Japanese  TermsErrors in the extraction of terms and phrasesfrom parallel texts eventually lead to a failure inacquiring the correct term/phrase correspondences.In Kupiec (1993) and Yamamoto (1993), term andphrase extraction is applied to both of paralleltexts.
In contrast, we  extract from units onlyJapanese terms, thereby reducing the errors caused byterm/phrase r cognizer.
Japanese NP's can be recog-nized more accurately than English NP's becauseJapanese has considerably ess multi-category words.In the current implementation, the followingtwo types of term candidates are extracted by theNP recognizer:(A) Compound nouns (including verbal nouns)Examples: "~-  7" y e" :, l- ~'~3i~"(=open bit line colfiguration)"/i~4-/JiJm~l-fJ~"(=minimum featuring size)(B) Unknown words (nouns, verbal nouns)Examples: "~- J -  ~" (=to laminate, to form)" ,l-t 1.1 .~, 9 :."
"Y'" (=polishing)Our NP recognizer utilizes the sentence awdyzerof a practical MT system.
The word dictionaryincludes approximately 70,000 Japanese ntries.4.2 F ind ing  Trans la t ion  Cand idatesGeneration of English translation candidates fora Japanese term is essentially based on the followinghypothesis:Hypothesis 1The English translation of an extracted term ina Japanese unit is contained in the English corm-sponding unit.Now an arbitrary word sequence in correspon-ding units can be a translation candidate of theJapanese term.
We extract English translation candi-dates in two steps:Step 1 : Select English corresponding units.Step 2: Extract n-gram data from the units.Step 1 :When the extracted term appears in N Japaneseunits, N?M English units will be stored in the cor-responding unit table with their correspondence like-lihood.
The N highest corresponding units withinN?M combinations are extracted.
When N is lessthan M, the M highest combinations arc selected.Step 2:Suppose that tile correct English translation ofthe Japanese term JW is EW, and that the mnnber ofJapanese units in which JW appears is FJU(JW) (=N).
From ltypothesis 1 that the translation is con-tained in the corresponding units EU I, EU 2 .....EUFJU(JW ), EW would be a word sequence whichoften appears in corresponding units.
In order to getsuch EW, we use n-gram data.The frequency of each n-gram (1 <_ n _< 2 x (thenumber of component words in JW)) data inFJU(JW) English units is calculated and then EWcandidates are ranked by the frequency as EWC 1,EWC 2 .... EWCj.
Because EWC with a low frequen-cy in the corresponding units is unlikely to be thecorrect wanslation, the data with a frequency lessthan FJU(JW) 4 are heuristically excluded from thecandidates.
The data containing be verb and the datawhich starts or ends with a preposition or an articleare also excluded from the candidates.5 EST IMAT ING ENGL ISH TRANSLA-T IONSThe translation likelihood (TL) of one transla-tion candidate EWCi for the term JW is defined as:TL(JW, EWCi) =F(TLS(JW, EWCi), TLL(JW, EWCi))where TI~S(JW, EWCi) is "'Franslation Likelihoodbased on Statistical information," and TLL(JW,EWCi) "Translatiou Likelihood based on Linguisticinfo rmat ion 25.1 Stat is t ica l  h f fo rmat ionTLS(JW, EWCi) is the frequency score based onthe statistical information from Hypothesis 1 that aword which appears as often in tile correspondingunits as JW in Japanese units is more likely to beEW.
It is quantitatively defined as tile probabilityin which the translation candidate appears in the cor-responding traits.
That is,78vrsu0~.wc?~_ TLS(JW, EWCi) = F3U(JW)where FEU(EWCi) is the number of correspondingunits in which EWCi appears.5.2  L ingu is t i c  I n fo rmat ionTLL(JW, EWCi) is tile word similarity scorebased on the accuracy of the correspondence t rm JWand the translation candidate EWCi obtained byusing linguistic information in tile MT bilingual dic-tionary.
Suppose one translation candidate of termJW=WJl, wJ2 .... wJk is EWCi=we 1, we 2 .... we I.Then we use the following hypottmsis.Hypothesis 2(a) If the length of EWCi is close to the lengthof JW, JW and EWCi are likely to correspondeach other.
(b) JW and EWCi with more word translationcorrespondences are likely to correspond eachother.Under this hypothesis, the following correspon-dence relation (1) is the best.
Term JW and transla-tion candidate EWCi have the same length k(-I), andall of their component words correspond in the dic-tionary, wJi:~we i indicates that we i is included inwJi's translation candidates in the MT bilingual dic-tionary.
(1) wJl=*we 1, wJ2~we 2 .. .
.
.
.
wJk~We kMore generally, tim relation of each word (w j)in term JW and each word (we) in translation candi-date EWCi is classified into the following fourclasses:i) w j~ weii) wj --* weiii) wj -4iv) ~ ---> we (qb indicates no word)it) shows a pair whose correspondence is notdescribed in the bilingual dictionary, iii) and iv)indicate that the corresponding word for wj or we ismissing.
In iii), JW is longer than EWCi; and viceversa in iv).In order to estimate correspondence between JWand EWCi, i) and it) are scored by similarity to thevirtual translation which holds the relation (I).When the nmnber of words is the same, score Q(constant) is given, c~Q (ct>0) is added to Q whenthere is a translation relation to reflect higher relia-bility of i).
Therefore, Q+aQ=(I-,c~)Q is given tothe word pair of i), and Q to the word pair of it).Now since we disregard the word order of aterm, JW and EWCi are represented as sets of words:JW = wJl, wJ2,.., wJk ~- {wJl, w j2,.., wJk }EWCi = we I , we2,.., we I - {wel, we2,.., wel}The number of words with a lexical correspon-dence relation in wj and we, the number of words inwj without a relation and the number of words inwe without a relation are counted as x, y, z respec-tively.
That is, x -~ y = k and x + z= l.T\[.I.
(JW, EWCi) is given as the ratio of tilescore of the vmual translation to the score ofFWCi.When y>_z,x(l-t ct)Q t-zQTI2_.
(JW, EWCi) = (x l y)(l -t a.)QOtherwise,Thus,Tl.
l .
(JW, EWCi) = x(1-I a)Q + yO - (z - y)Q (x-ly)(l-~ c*)QTI.I.
(JW, Ewc i )  -.x(l -t ~) + z (y_>_z)(x-~y)(l q cQx(l-~ ~x) + 2y - z(x+y)(1-tcx) (otherwise)By definition, TI.L(JW, t!WCi) < 1.
The valueof c~ is determined as 2 by evaluating sample tnmsla-lion pairs.Followings are the TLI, 's of three EWC's forJW:vk -- 7" :./ ff .
:t I.
~ Jy : ,~  which consists of fourcomponent words (k=4); ":,l--- 7" :/(=open)," t f  .~, I-(-bit)," "~(=line)," and "Jj3~.
(-method, process).
"bit line configurationx :2 ,y -2 ,  z=l .
'.T\[.I~ - (2x3+l)/4x3 =0.58open bit linex::3, y:  1, z:-O .'.
Tl.l.
= (3x3)/4x3 = 0.75open bit line configurationx=3,y : l , z - I  .'.
TLL = (3?3+1)/4x3 =0.835.3 Combinat ion  o f  S ta t i s t i ca l  and  L in -gu is t i c  In fo rmat ionWe define the translation likelihood TL(JW,EWCi) as below:TL(JW, EWCi) -:m TLS(JW, F.WCi) + n TLL(JW, EWCi)m-{ tlExamining the value with the ratio n/ttl con-stant, a low value of TI.S(JW, EWCi) ill affectsthe total score, especially when the frequency79FJU(JW) is 5 or less.
This shows that TLS(JW,EWCi) should be much weighed for JW's whichappear often, but not for JW's with a low freqt,en-cy.
Therefore we tentatively define ~ = n/m as afunction of frequency FJU(JW), because !3 sbould behigher when FJU(JW) is low.\]3 = G(FJU(JW)) P + s{FJU(JW)} q - rwhere r is a possible minimum frequency, aqd s islimit of 13 as the word frequency is high enough.Values p=4, q=l, r=l, and s=0.5 are used in tile fol-lowing experiments.
By introducing 13, F is rewrit-ten as:F(TLS(JW, EWCi), TLL(JW, EWCi) ) =_TLS(JW, EWCi) + 13 TLL(JW, EWCi)1+13In case {FJU(JW)} q is equal to or less than r,is meaningless, For such JW's, TL(JW, EWCi) isredefined as simply:TL(JW, EWCi) = TLL(JW, EWCi).Finally the translation candidate EWC i withthe largest value of TL(JW, EWCi) is assumed to bethe correct English translation.Table 1 shows the translation candidates for JW:~ 7" >" ~" ~, I- ,~ jY~ with the best three TL's.
Itsfrequency in Japanese text is FJU(JW) = 19 (134 + 0.5 = 0.72).
Consequently, the correct 19-1translation EWC 3, open bit line cotfiguration, isobtained.Table 1: Estimation of English translationEWCi FEU 'I'LS TLL 'I'Lbit line configuration 19 1.00 0.58 0.82open bit line 18 0.95 0.75 0.86open bit line configuration 18 0.95 0.83 0.906 EVALUATION AND DISCUSSIONTo evaluate this method, we have estimatedEnglish translations of Japanese terms in seven paral-lel texts (Japanese specifications of patents on semi-conductors and their English translations by humantranslators) and compared the translations with thecorrect data given by experts in building an MT dic-tionary.
The size of a Japanese text is 7,508 to 26,927 characters in 127 to 616 sentences; 99,286 charac-ters in 2,148 sentences in total.
Examples of cor-rect translation pairs estimated with the highest TLCompound nouns:\]'~-'J")3ll ~-" J" ~./2 minimum featuring size~ -j'-5}l~f\[i~.t~t~ element separation region71- - ':7" :-" t::" 'u I" ~7,t)':,:~ open bit line configurationcohtmn address trobe-e )t, 3" ~.4 cell arrayUnknown words:~lt I) ,~, ,~ >, p" po l i sh ing1/~ # collector~I~-Y  ~ to formFig.
2: Correct translation pairsare listed in Fig.
2.Table 2 shows the ranking of the correctly esti-mated translation pairs in seven sample texts.
Theupper row shows the average of seven individualtexts; the lower shows the result using all seventexts in one time.
The translation of over 70% ofcompound nouns is obtained as the first candidate,and over 80% in the top three.
The result forunknown words is 54.0% and 65.0%.
Though theaccuracy for tile unknown words is relatively low,the estimation has been impossible for Yamamoto(1993).
itere, tile terms whose cor,ect translationsare not found in English texts are excepted fromevaluation.
.Such data occur when human expertsgive a noun translation for Japanese verbal nounterm which is translated as a verb in the actualtext.
Tile ratio of this kind of translation pairs isabot, t 3%.
Tile rate of the correct data is calculatedby the ratio of the total occurrences.The accuracy for the average of unknown wordsis 52.4% in the top three.
The result using all textsis significantly better than tile average because tilestatistical information is the major factor in the cur-rent implementation.
Use of more linguistic infor-mation such as in Dangan (1991) and Matsumoto(1993) would improve the total performance.Linguistic information has proven effective toestimate translations of low-frequency terms.
Ofterms which appeared only once in a Japanese text,215 translations are obtained correctly as the firstcandidate from 327 terms (65.7%) in seven texts.The fourth example of compound nouns in Fig.2 shows the advantage of statistical informationbecause the correct translation was obtained in spiteof the wrong word segmentation.
The Japanese termreally consists of three words (~J 9 A ,  7" F 1t ~ ,  .z\].
~ - .7" ), each of whicb corresponds to "cohtmn,""address" and "strobe" respectively.
But word seg-mentation output four word.~ (~J 5' \ ] , ,  T F 1t ~ ,l., ~ - .7") because ":< I.
~- -  7"" is unknown and "-~80Table 2: Aeeur'lcy of transl'dion estimatesCompound nouns (occurrences)-total T l - i~ ' t  cstq,n--at~'~ to,;~-e~-tq m:ZteT"1 text ,,7 {ext_s~ 3 ,224_~.9% (2,349) 83.3% (2,680)Unkilown words occtnrences)-t-ot~al--\[- first estimate top 3 estimates?
I O - - -  55 6 I 30.1~, (16.7) 52.4% (29.1)I389 | 54.0%, (210) 65.0% (253)k1-" is known as "strike.
"The CASES where no correct translatkm has beenobtained needs to be examined.
The major reasonsfor faih, res are:1.
Errors in mappi,lg conesponding units.2.
Errors in word segmentation of unknowncompound wo,ds.Mapping unit errm.
's occur when the one-to-onennit correspondence does not exist.
The experimentusing one text shows that 12 out of 98 Japanese sen-tences have no onE-to-one corresponding English sen-tence.
For better unit correspondence, the trailsshould be smaller, for example, a clause or a verbphrase, so as to make the corresponding accuracy andfrequency in text higher and statistical infornmtionmore effective.
It would improve the unit mapl)ingwhen one Japanese sentence is tnmslatcd into severalEnglish sentences or vice vmsa.ThE segmentation errors of unknown wordsarise often in case of Katakana compotmd word.Katakana is the phonetic alphabet in Jal)anese forspelling foreign words?
Since many compoundnourLs in a technical field consist of Katakana's withno space between component words, much larger lex-icon will contribute to more accurate segmelltation.7 CONCLUSIONAn MT dictionary has been generated fromJapanese and English parallel texts.
The methodproposed in this paper assumes t, nit correspondenceand utilizes linguistic information in an MT bilin-gual dictionary as well as statistical information,namely, word frequency, to estimate the Englishtranslatio,L Over 70% accun~te translations for com-pound nouns are obtained as the first candidate fromsmall (about 300 sentences) Japanese/Fnglish paral-lel texts (patent specifications) containing severedistortions.
The accnracy of the first translaticmcandidates Ior unknown words, which calmot beobtained by a linguistic-based method, is over 50%?Tim current implementation shows promisingresults for a cliff let, It target (patent texts) despiterelatively shnple linguistic knowledge?
The overalllmfformance will be imlnOved by using more linguis-tic knowledge and optimizing panuneters calculatedby sh~tistical information?ReferencesBrown, P. F.; l,ai, J. C.; and MErcer, R. 1, (1991).
"Aligning sentences in parallel corlx),a."
InProe.
of the 29th Annual Meeting of the ACL,16%176.Chen, S. F. (1993).
"Aligning sentences in bilingualcorpora using Iexical informatio,L" In Proc.
ofthe 3 lxt A tmual Meeting of the A CL, 9-16.Dagan, I.; ltai, A.; and Schwall, U.
(1991).
"Twolanguages are mo,'e intkmnative than one."
InProc.
of the 29th Ammal Meeting of the ACL,130-137.Gale, W. A., and Chnrcb, K. W. (1993).
"A pro-gram for aligning sentences in bilingt,al corpo-ra."
Computational Linguistics, 19(1 ), 75-90.Katoh, N. (1993).
"Word selection by searching thetranslation candidates on monolingnal texts intarget language."
7>chuieal Report of IEICE,NLC93-32.
(in Japanese)Kupiec, J.
(1993).
"An algorithm for finding nounphrase correspondences in bilingual corpora."
InI'roc.
e( the 31st Ammal Meeting rg" the ACL,17-22.Matsumoto, Y.; \[shimoto, ll.
; and Utsuro, T.(1993).
"Structural Matching of ParallelTexts."
In I'roc.
of the 31st Annual Meeting ofthe ACL, 23-30.Nogami, lI.
; Kumano, A.; Tanaka, K.; and Anmno,S.
(1991).
"l.earning of translation words usingtarget-hmguage documents."
In Proc.
(f 42ridA m~ual Meeting of II'S.I, 2C- 6.
(in Ja panes E)Yamamolo, Y., and Sakamoto, M.
(1993).
"Extraction of teclmical te,'m bilingual dictio-nary from bilingual corpus."
IPSJ SIG Notes,N1,94-12.
(in Japanese)81
