Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 206?213,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsUsing Natural Language Processing to Identify Pharmacokinetic Drug-Drug Interactions Described in Drug Package InsertsRichard Boyce, PhDUniversity of Pittsburgh5607 Baum AvenuePittsburgh, PA 15206, USArdb20@pitt.eduGregory Gardner, MSUniversity of Pittsburgh5607 Baum AvenuePittsburgh, PA 15206, USAgag30@pitt.eduHenk Harkema, PhDUniversity of Pittsburgh6425 Penn Ave.Pittsburgh, PA 15206hendrik.harkema@nuance.comAbstractThe package insert (aka drug product label) isthe only publicly-available source of infor-mation on drug-drug interactions (DDIs) forsome drugs, especially newer ones.
Thus, anautomated method for identifying DDIs indrug package inserts would be a potentiallyimportant complement to methods for identi-fying DDIs from other sources such as thescientific literature.
To develop such an algo-rithm, we created a corpus of Federal DrugAdministration approved drug package insertstatements that have been manually annotatedfor pharmacokinetic DDIs by a pharmacistand a drug information expert.
We then evalu-ated three different machine learning algo-rithms for their ability to 1) identifypharmacokinetic DDIs in the package insertcorpus and 2) classify pharmacokinetic DDIstatements by their modality (i.e., whetherthey report a DDI or no interaction betweendrug pairs).
Experiments found that a supportvector machine algorithm performed best onboth tasks with an F-measure of 0.859 forpharmacokinetic DDI identification and 0.949for modality assignment.
We also found thatthe use of syntactic information is very helpfulfor addressing the problem of sentences con-taining both interacting and non-interactingpairs of drugs.1 IntroductionPackage inserts (PIs, aka drug product label) arethe primary source of information for newly ap-proved drugs and a potentially authoritative sourceof drug information from a medical-legal stand-point (Marroum & Gobburu 2002).
Among theinformation provided by PIs are drug-drug interac-tions (DDIs): known and predicted drug combina-tions that could lead to a clinically meaningfulalteration in the effect of one of the drugs.
TheUnited States Federal Drug Administration (FDA)mandates that PIs for FDA-approved drugs includeboth observed and predicted clinically significantDDIs, as well as the results of pharmacokineticstudies that establish the absence of effect (FDA.2010).
Moreover, the PI is the only publically-available source of information on DDIs for somedrugs, especially newer ones (Dal-R?
et al 2010).Hence, an automated method for identifying DDIsfrom drug PIs would be an important complementto methods for identifying DDIs from othersources such as the scientific literature.
In this pa-per we describe the creation of a new corpus ofFDA-approved drug package insert statements thathave been manually annotated for pharmacokineticDDIs.
We then discuss how three different ma-chine learning algorithms were evaluated for theirability to 1) identify pharmacokinetic DDIs in drugpackage inserts and 2) classify pharmacokineticDDI statements by their modality (i.e., whetherthey report a DDI or that a drug pair does not in-teract).2 Materials and Methods2.1 The DDI Corpus and SchemaA corpus of annotated statements derived fromFDA-approved drug PIs was created for use astraining and test data while developing automatedDDI extraction algorithms.
The statements werederived from PIs using a strategy that ensured there206would be a representative sample of statementsthat 1) unambiguously identified interacting drugpairs, 2) unambiguously identified non-interactingdrug pairs, and 3) included no mention of interact-ing drug pairs.
Previous experience by our researchgroup suggested that the manner in which DDIstatements are described in PIs has changed overtime in response to changing FDA regulations.Most notably, an FDA guidance document issuedin 1999 was (to our knowledge) the first to explic-itly suggest the inclusion of brief descriptions ofpharmacokinetic DDI studies within specific sec-tions of drug PIs (FDA.
1999).
To account for this,investigators selected 64 PIs using a strategy thatensured the corpus would have a balanced sampleof statements from drugs marketed before and after2000.
For the purpose of this study we designatedall PIs for drugs marketed prior to 2000 as ?older?and those for drugs marketed in or after 2000 as?newer.?
PIs were downloaded from the DailyMedwebsite,1 and the entire ?Drug Interactions?
and?Clinical Pharmacology?
sections were selected astext sources from ?newer?
PIs.
For ?older?
PIs,which often lacked these two sections, investiga-tors chose a section containing an apparent interac-tion statement and one randomly-selected section.DDIs are typically classified as occurring byeither pharmacodynamic or pharmacokineticmechanisms.
A pharmacodynamic DDI involvesthe additive or synergistic amplification of a drug?seffect.
In a pharmacokinetic (PK) DDI, one drug,called a precipitant, affects (inhibits or induces)the absorption, distribution, metabolism, or excre-tion of another drug, called the object.
To simplifyour task, we decided to focus specifically on PKDDIs.
Prior to annotating the PI statements, aschema was created for the entities that the investi-gators considered important components of a PKDDI.
The schema modeled drugs as having twocharacteristics, type and role.
The type of drugcould be active ingredient (e.g., simvastatin),drug product (e.g., Zocor), or metabolite(e.g., beta-OH-simvastatin).
Drugs annotated asmetabolite also referred to the active ingre-dient parent compound.
The role of a drug couldbe either an object or a precipitant.
Two oth-er properties were provided to model each PKDDI: 1) whether the statement from which the DDIwas identified suggested an observed effect or a1 http://dailymed.nlm.nih.gov/lack of an observed effect between two coadminis-tered drugs (i.e., positive vs negative modali-ty statements), and 2) whether the statementincluded quantitative or qualitative data in describ-ing an interaction or non-interaction between adrug pair (i.e., quantitative vs qualitativestatements).
Finally, the segment of text in whichthe interaction claim was made was annotated asan interaction phrase.
With the corpus andschema in place, drugs and PK DDIs present in thePI statements were then annotated by two inde-pendent reviewers using Knowtator, an annotationtool integrated with the Prot?g?
ontology editor(Ogren 2006).One annotator was a pharmacist and DDIexpert, and the other a librarian specializing indrug information retrieval.
To help the annotators,co-investigator RB ran the NCBO Annotator (Jon-quet, Shah & Musen 2009) over the corpus usingthe RxNorm drug terminology (Nelson et al 2011)to pre-annotate as many active ingredients anddrug products as possible.
The annotators reviewedthese ?pre-annotations?
while identifying entitiesthat missed during the pre-annotation process.
Co-investigator HH used Knowtator to calculate inter-annotator agreement statistics from the annotators?initial annotation sets.
RB then worked with thetwo annotators to achieve consensus on the finalcorpus of annotated DDI statements.2.2 Setting up the DDI statement extractionexperimentOnce the set of DDI annotations was compiled, wedevised two machine learning tasks.
The first taskwas to determine whether two drugs mentioned ina statement taken from a PI are noted as either in-teracting or not interacting with each other bypharmacokinetic mechanisms (i.e., does the state-ment report a PK DDI with the drug pair of eithera positive or negative modality?).
The second taskwas to determine the modality of a given PK DDI.The first task did not include determining the rolesof the drugs if an interaction is found, i.e., whichmember of the pair of drug mentions is the precipi-tant and which one is the object.
To enable the ex-ploration of the performance of multiple machinelearning methods, we divided two-thirds of theannotated PI statements into a development set andone-third into a blind test set.
PI statements anno-tated as reporting DDIs were stratified within the207two sets using a random selection method that en-sured a representative balance of sentence distancebetween drug mentions, DDI modality, DDI type,and drug PI age designation (see above).
State-ments not containing an interaction were stratifiedby sentence distance between drug mentions, andPI age designation.
Stratification was done on thelevel of statements.
Thus, statements taken fromthe same package insert may have been distributedover the development and test set.We observed that 99% of corpus statementsannotated as a PK DDI mentioned an interactingdrug pair within a three sentence region.
Thus, wecreated a baseline dataset by iterating through PIstatements in the development set and identifyingall drug pair mentions that occurred within a three-sentence span.
Throughout the remainder of thispaper we refer to the statements identified by thisprocess as instances.Instances containing drug pairs that weremanually annotated as participating in an interac-tion (either with positive or negative modality)were labeled as positive instances for the extractiontask; all other pairs were labeled as negative in-stances.
Prior to generating features for machinelearning, each instance was pre-processed.
Num-bers (e.g.
?1?, ?34?, ?5.2?, etc.)
were replaced bythe string ?num?
to make them more meaningful toa learning algorithm across instances.
This allowedthe algorithm to associate numerical referenceswith each other using a general pattern, instead oflearning phrases with specific numbers (e.g.
thephrase ?num mg?
may be significant, whereas ?10mg?
may be less significant).
Similarly, to abstractaway from specific names, the names of drugproducts, active ingredients, and metabolites ineach statement were replaced by the string?drugname?.
This forces the learning algorithm togeneralize over the participants of interactions,preventing it from identifying interactions based onthe identity of the participants.In the baseline dataset, each instance?s pre-processed sentence text was translated to bigramsusing TagHelper, a text analysis program writtenon top of the Weka machine learning software(Hall et al 2009; Ros?
et al 2008).
Bigrams are acomprehensive set of consecutive word pairs thatappear in a sentence.
Words in bigrams werestemmed by TagHelper to facilitate learning moregeneral concepts conveyed by phrases.
For exam-ple, the commonly occurring phrases ?increasesauc?
and ?increased auc?
are stemmed to ?increaseauc?
and then merged to the bigram.
The baselineset of instances was loaded into Weka and threemodels were built using three different machinelearning algorithms.
The three algorithms were arule learner (?JRip?
), a decision tree (?J48?
), andan SVM algorithm (?SMO?).
Algorithm parame-ters were left at Weka defaults and 10-fold cross-validation was used to develop each model.Exploration of Weka predictions from thebaseline dataset showed that a major source of con-fusion for the machine learning algorithms was aninability to distinguish between pairs of drugs thatdo and do not interact within the same sentence.
Afrequent source of this kind of occurrence in thepackage insert text was coordinate structures suchas ?Drug A interacts with Drugs B and C?, where?B and C?
is a coordinate structure.
For such sen-tences, the baseline dataset contains the interactingpairs (A,B) and (A,C), along with the non-interacting pair (B,C).
However, because all threepairs are represented by the same set of bigrams, itis obvious that information from bigrams alone isinsufficient to distinguish which pairs interact andwhich simply co-occur within the sentence.Another problem was that of multiple men-tions of the same drug within an instance?s sen-tence span, as, for example, in the sentence ?Co-administration of A and B leads to increased AUClevels for B.?
Because the annotators had identifiedonly one drug mention per annotated interaction,the algorithms incorrectly considered other men-tions of the same drug as part of a non-interactingpair.
Two solutions were implemented to help alle-viate these problems.
First, the dataset was con-densed to a set of instances with unique drug pairsand sentence spans.
If any of the baseline instanc-es contributing to the condensed instance containedinteractions, the condensed instance was said tocontain an interaction.
In this way, multiple drugmentions within a sentence span containing an in-teraction would translate to a single instance repre-senting an interaction between the two drugs.Second, two natural language dependencyparsers were used to extract extra features from thesentence text for each instance: the Stanford NLPParser (Klein & Manning 2003) and ClearParser(Choi 2011).
Following approaches to relationextraction proposed in other domains e.g., (Bunes-cu & Mooney 2005), the dependency structureproduced by each parser was searched for the208shortest path between the pair of drug mentions ofthe instance.
The words on this path werestemmed using the Stanford NLP Tools stemmer(Stanford NLP 2011), and added to the dataset asthe instance?s ?syntactic path?.Once a statement is classified as describing aPK DDI between two drugs, it is important toknow if there is an observed effect or a lack of ef-fect between two coadministered drugs (i.e., posi-tive vs negative modality statements).
To presentthe learning algorithms with the most relevanttraining data, modality prediction was treated as aseparate task from interaction prediction.
Devel-opment and test sets were created in the samemanner as for interaction prediction, however in-stances that did not represent interactions were ex-cluded.
Only bigram features were used formodality prediction.
Model training and testingproceeded in the same manner as for interactionprediction.3 ResultsA total of 208 multi-sentence sections were ex-tracted from 64 PIs.
Prior to consensus, inter-annotator agreement between the two annotatorson PK DDI, active ingredient, drug product, me-tabolite mentions and was found to be 60%,96.3%, 99.5%, and 60.8% respectively.
The major-ity of disagreements about DDIs were due to a ten-dency of one annotator to incorrectly annotatesome pharmacodynamic DDIs as PK DDIs.
Also,one annotator incorrectly assumed that all metabo-lites had been pre-annotated and so did not activelyattempt to annotate metabolite entities.
These andother minor issues were corrected and full consen-sus was reached by both annotators.
The final drugpackage insert PK DDI corpus contains 592 PKDDIs, 3,351 active ingredient mentions, 234 drugproduct mentions, and 201 metabolite mentions.2Tables 1 and 2 provide more details on the mo-dality and drug types present in the 592 consensusPK DDI statements.
Table 1 shows that 388 state-2 http://purl.org/NET/nlprepository/PI-PK-DDI-Corpusments indicated that a PK DDI would occur be-tween a drug pair, while 204 statements indicatedthat an interaction would not occur.
The table alsoshows that 204 statements reported quantitativemeasures while 388 did not.
Table 2 shows that themajority (86%) of PK DDI statements reportedinteractions by stating the two active ingredientsinvolved in the DDI, with a much smaller propor-tion using a drug product in the description.
Also,35 DDI statements reported an effect on a drugmetabolite.A total of 11,048 PI instances were generatedfor the baseline dataset.
This was reduced to 5,015instances after condensing the instances down tounique drug pairs and sentence spans.
In the finaldataset, about a third of instances were drug pairswithin the same sentence (1,583).
The rest weresplit between drug pairs in adjacent sentences(1,717), and drug pairs with two sentences of sepa-ration (1,715).
The dataset included 542 interac-tions of which 493 included the drug pair within asingle sentence.
355 interactions were positivemodality and 187 negative; 360 were qualitative,182 quantitative.
1,636 instances were categorizedas ?new?
based on drug release data while 3,379were classified as ?old?.Results for interaction and modality predictionare shown in Table 3.
For both the interaction andmodality prediction tasks, the SVM algorithm(SMO) outperformed the rule learner (Jrip) anddecision tree (J48).
On the test set which was notused in training, the SVM classifier identified PKDDIs with an F-measure of 0.859 vs 0.762 for therule learner and 0.802 for the decision tree algo-rithm.
All algorithms performed quite well on themodality classification task but the SVM algorithmperformed best with an F-measure of 0.949 vs0.929 (rule learner) and 0.917 (decision tree).4 DiscussionThe automatic identification of DDIs in unstruc-tured text is a topic that is gaining much interest.This work makes an important contribution to thefield by being the first to demonstrate that machinelearning can be applied quite effectively to the taskof extracting PK DDIs from FDA-approved PIs.Interaction TypeModality Qualitative Quantitative TotalNegative 202 2 204Positive 186 202 388Total 388 204 592Table 1.
PK DDI statement modality shown by in-teraction type.209Object TypePrecipitant Type Active ingredient Drug product Metabolite TotalActive ingredient 506 14 34 554Drug product 37 - 1 38Total 543 14 35 592Table 2.
A summary of consensus annotated PK DDIs by precipitant and object type.As our work focuses on extracting PK DDIs, it ismost similar to that of Karnik et al (Karnik et al2011) who explored the performance of an ?allpaths?
graph kernel (Airola et al 2008) on a corpo-ra of PK DDIs derived from 219 MEDLINE ab-stracts.
The best performing algorithm in theirexperiments had an F-measure of 0.658 which isconsiderably less than the F-measure of 0.859 thatour SVM achieved.
However, the two results arenot directly comparable because of unknown dif-ferences between the corpora.
For example, it maybe that PIs use more standard language patterns toreport PK DDIs than what is found in MEDLINEabstracts.
In future work we will explore how wellthe SVM algorithm performs over MEDLINE ab-stracts and contrast any differences between thetwo DDI sources that might affect NLP.The only other project we are aware of that fo-cused explicitly on extracting PK DDIs from un-structured text is that of Tari et al (Tari et al2010), who evaluated a rule-based algorithm forextracting PK DDIs from papers and abstracts inthe scientific literature.
In this study the authorsdistinguished between explicit DDIs (statementsindicating a direct observation of a PK effect froma give drug combination) and implicit DDIs (DDIsthat can be inferred based on claims about drugmetabolic properties extracted from scientifictexts).
The algorithm was ran over ~17 millionMEDLINE abstracts and the output DDIs werecompared with a reference standard set of 494DDIs identified manually from 265 DrugBankdrug pages.
The algorithm?s recall of DrugBankinteractions was only 12%.
However, a manualinspection of the results found that 78% of theDDIs extracted by the algorithm were valid basedon the source texts, even though they were not pre-sent in their reference standard.
These results areimportant because they suggest that the set of DDIspresent in DrugBank are incomplete and highlightthe need for corpora derived from other textsources such as the one we developed from drugPIs for this study.A larger body of research exists for the task ofextracting DDIs of any type (i.e., PK or pharmaco-dynamic DDIs).
Ten research papers were present-ed at the recent ?Challenge Task on Drug-DrugInteraction Extraction?
held at the 2011 SemEvalConference (Segura-Bedmar, Martinez & Sanchez-Cisneros 2011).
All systems in this challenge weretested against the ?DrugDDI corpus?
; a set of 579documents from the DrugBank database with3,160 manually-annotated DDIs (Segura-Bedmar,Martinez & Pablo-Sanchez 2010).
The best per-forming system in this challenge utilized an en-semble learning approach (Thomas et al 2011) andproduced an F-measure of 0.657.
The  second bestperforming method utilized composite kernels, amethod that combines feature-based and kernel-based methods, and was found to perform with anF-measure of 0.64 (Chowdhurry et al 2011).
Airo-la et als ?all paths?
graph kernel (mentionedabove) performed much more poorly on the Drug-DDI corpora than on the Karnik?s PK-DDI corpus(F-measure 0.16 vs 0.658).
The authors note thatthere were significant differences between in thetwo corpora with regards to the length and com-plexity of the sentences reporting DDIs .To the best of our knowledge, only one otherNLP study that has focused specifically on druginteractions reported in drug product labeling (Ru-brichi & Quaglini 2012).
The investigators com-pared the ability of an SVM classifier and aconditional random fields (CRF) classifier for as-signing 13 semantic labels to Italian language textpresent in the interaction section of  ?Summary ofProduct Characteristics?
documents (the Italianequivalent of PIs).
The investigators explored theinfluence of a range of features on classifier per-formance, including orthographical, neighboringword, syntactic, parts of speech, and dictionaryfeatures.
When all features were employed, theSVM had slightly better performance than the CRFclassifier (micro-averaged F-measure: 91.41 vs91.13, macro-averaged F-measure: 84.99 vs80.83).210Jrip J48 SMOModel (dataset) Prec Recall F Prec Recall F Prec Recall FBaseline (development) 0.588 0.656 0.62 0.584 0.573 0.578 0.639 0.677 0.658Stanford Parser (develop-ment) 0.762 0.68 0.719 0.809 0.804 0.807 0.851 0.815 0.833ClearParser (development) 0.787 0.793 0.79 0.822 0.791 0.806 0.828 0.887 0.856Stanford Parser (test) 0.778 0.665 0.717 0.828 0.832 0.83 0.843 0.838 0.84ClearParser (test) 0.764 0.76 0.762 0.85 0.76 0.802 0.836 0.883 0.859Modality (test) 0.963 0.897 0.929 0.887 0.948 0.917 0.941 0.957 0.949Table 3.
Results for interaction prediction on the baseline, development, and blind test set.
Also shown are re-sults for modality prediction for the blind test set (results over the development set are similar but not shown).One key difference between the Rubrichi studyand ours is that the task of tagging unstructuredtext with semantic elements that describe a DDI isnot the same as classifying whether or not a state-ment containing a drug pair is reporting a DDI be-tween the drugs.
The difference is especiallyapparent when considering coordinate structuressuch as ?Drug A interacts with Drugs B and C?,Semantic tagging would be useful for identifyingthe drug entities but is not useful (on its own) foridentifying which of the three drug pairs interactwith each other.It is interesting to note that most recent work onDDI extraction had not made the distinction be-tween PK and pharmacodynamic DDIs that isstandard in the fields of pharmacology and phar-macy.
This distinction might be relevant to DDIextraction because the two types of interactions arediscovered in distinct ways that might lead to sig-nificant differences in how they are described inscientific documents.
For example, there is a fairlystandard set of in vitro experiments and clinicaltrials that have been a routine part of drug devel-opment for more than a decade (FDA.
1999).
Thesame is not true for pharmacodynamic DDIs,which are more challenging to study because theyinvolve additive and synergistic effects that are notnecessarily related to a drug?s dose or clearance.Since it is reasonable that the methods used to in-vestigate a DDI strongly influences its description,we think future work should examine if PK andpharmacodynamic DDI descriptions are differentenough to warrant distinct DDI extraction efforts.An error analysis of the final dataset suggestedsome reasons for cases where the machine learningalgorithms misclassified instances.
Instances thatwere not interactions, but were classified as such,contained a large number of sentences with de-scriptions of studies or biochemical processes andmeasurements.
These types of statements mayshare a number of features with actual interactions(e.g.
numerical data, changing levels of drug, etc.
)without containing an interaction.
There also re-main cases where several drug names occur andthe classifiers were unable to differentiate betweenthe interacting pair and non-interacting pairs.
Un-fortunately, no such clear pattern was apparent forinstances that descrived interactions, but were clas-sified as containing no interaction statement.
Anumber of large sentences were observed in theseinstances, suggesting sentence complexity mayplay a role, increasing the difficulty of natural lan-guage parsing.Analysis of the attribute weights assigned bythe SVM  algorithm (SMO) after training for inter-action prediction shows some commonality regard-less of whether the data was processed by theStanford Parser or the ClearParser.
For example,19 out of the 20 most significant features identifiedby the algorithm from the dataset when processedby the Stanford Parser were words on the syntacticpath; one less than when the dataset was processedby the ClearParser.
Common significant featuresinclude words such as ?coadminister?, ?auc?,?pharmacokinetic?, and ?absorption?.
The algo-rithm placed greater importance on the words ?in-crease?
and ?decrease?
when the dataset wasprocessed by the Stanford Parser, while the words?reduce?
and ?enhance?
received greater attributeweights when the data was processed by theClearParser.
A similar analysis of the SVM algo-rithm developed for PK DDI modality predictionshows that bigrams with the words ?no?
or ?not?are clearly the features of most importance to themodel.211We also note that the algorithm?s performanceon the test set of PI statements is very similar tothe algorithm?s performance over the developmentset (see Table 3).
We think that this finding islargely due to the careful stratification approachwe used when creating the development and testsets.
It might also be possible that the features inthe unstructured PI text do not vary greatly be-tween PIs regardless of their age.
However, Table2 shows that our PK DDI corpora had considerablevariation in terms of quantitative vs qualitative andpositive vs negative DDI statements.
Thus, we an-ticipate that the SVM algorithm?s performance willbe maintained when ran against a much larger PIcorpus and future work will test how well the algo-rithm generalizes to other sets of PIs.5 ConclusionWe created a new, publically available, corpus ofFDA-approved drug PI statements that have beenmanually annotated for PK DDIs by a pharmacistand a drug information expert.
Also, we evaluatedthree different machine learning algorithms fortheir ability to 1) identify PK DDIs in drug PIs and2) classify PK DDI statements by their modality(i.e., whether they report a DDI or no interactionbetween drug pairs).
Experiments found that anSVM algorithm performed best on both tasks withan F-measure of 0.859 for PK DDI identificationand 0.949 for modality assignment.
We found thatthe use of syntactic information is very helpful foraddressing the problem of sentences containingboth interacting and non-interacting pairs of drugs.The strong performance of our algorithm for PKDDIs suggests that approaching pharmacokineticand pharmacodynamic interactions as differentNLP tasks is a potentially promising approach foradvancing automated DDI extraction.
Given themarked difference in performance between ourextraction methods and previous work, we areplanning further experiments to establish whetherthis difference reflects the comparative simplicityof the extraction task represented by our corpus,some specific strength of the applied extractionmethods, or some other factor.AcknowledgementThis project was funded by grant K12-HS019461from the Agency for Healthcare Research andQuality (AHRQ).
The content is solely the respon-sibility of the authors and does not represent theofficial views of AHRQ.
We also thank John Horn,PharmD (University of Washington) and Mr. RobGuzman (University of Pittsburgh) for their workannotating the corpus and identifying related re-search.ReferencesAirola, Antti, Sampo Pyysalo, Jari Bj?rne, TapioPahikkala, Filip Ginter & Tapio Salakoski.2008.
All-paths graph kernel for protein-protein interaction extraction with evaluationof cross-corpus learning.
BMC Bioinformatics9(Suppl 11).
S2.
doi:10.1186/1471-2105-9-S11-S2 (3 May, 2012).Bunescu, Razvan C. & Raymond J. Mooney.
2005.
Ashortest path dependency kernel for relationextraction.
Proceedings of the conference onHuman Language Technology and EmpiricalMethods in Natural Language Processing,724?731.
(HLT  ?05).
Stroudsburg, PA, USA:Association for Computational Linguistics.doi:10.3115/1220575.1220666.http://dx.doi.org/10.3115/1220575.1220666 (2May, 2012).Choi, Jinho.
2011.
ClearParser GoogleCode page.clearparser.http://code.google.com/p/clearparser/ (10 De-cember, 2011).Chowdhurry, Md.
Faisal Mahbub, Asma Ben Abacha,Alberto Lavelli & Pierre Zweigenbaum.
2011.Two Different Machine Learning Techniquesfor Drug-Drug Interaction Extraction.
1st Chal-lenge task on Drug-Drug Interaction Extrac-tion (DDIExtraction 2011), 19?26.
Huelva,Spain.Dal-R?, R., A. Pedromingo, M. Garc?a-Losa, J. Lahuer-ta & R. Ortega.
2010.
Are results from phar-maceutical-company-sponsored studiesavailable to the public?
European Journal ofClinical Pharmacology 66(11).
1081?1089.doi:10.1007/s00228-010-0898-y (5 August,2011).FDA.
1999.
FDA Guideline: In Vivo Drug Metabo-lism/Drug Interaction Studies ?
Study Design,Data Analysis, and Implications for Dosingand Labeling.
Rockville, MD: Food and DrugAdministration.http://www.fda.gov/downloads/Drugs/GuidanceComplianceRegulatoryInfor-mation/Guidances/ucm072119.pdf.FDA.
2010.
CFR - Code of Federal Regulations Title21.212http://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfcfr/CFRSearch.cfm?fr=201.57 (7 June,2011).Hall, Mark, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann & Ian H Witten.2009.
The WEKA data mining software: anupdate.
SIGKDD Explorations 11(1).
10?18.Jonquet, Clement, Nigam H Shah & Mark A Musen.2009.
The open biomedical annotator.
Summiton Translational Bioinformatics 2009.
56?60.
(10 December, 2011).Karnik, Shreyas, Abhinita Subhadarshini, ZhipingWang, Luis M Rocha & Lang Li.
2011.
Extrac-tion Of Drug-Drug Interactions Using AllPaths Graph Kernel.
1st Challenge task onDrug-Drug Interaction Extraction (DDIExtrac-tion 2011).
Huelva, Spain.Klein, Dan & Christopher D Manning.
2003.
Fast ExactInference with a Factored Model for NaturalLanguage Parsing.
(Ed.)
S Thrun S Becker &Keditors Obermayer.
Science 15.
3?10.Marroum, P.J.
& J. Gobburu.
2002.
The product label:how pharmacokinetics and pharmacodynamicsreach the prescriber.
Clinical Pharmacokinetics41(3).
161?169.
(7 June, 2011).Nelson, Stuart J, Kelly Zeng, John Kilbourne, TammyPowell & Robin Moore.
2011.
Normalizednames for clinical drugs: RxNorm at 6 years.Journal of the American Medical InformaticsAssociation: JAMIA 18(4).
441?448.doi:10.1136/amiajnl-2011-000116 (10 Decem-ber, 2011).Ogren, Philip V. 2006.
Knowtator: a Prot?g?
plug-in forannotated corpus construction.
Proceedings ofthe 2006 Conference of the North AmericanChapter of the Association for ComputationalLinguistics on Human Language Technology,273?275.
Morristown, NJ, USA: Associationfor Computational Linguistics.doi:http://dx.doi.org/10.3115/1225785.1225791.Ros?, Carolyn, Yi-Chia Wang, Yue Cui, Jaime Arguel-lo, Karsten Stegmann, Armin Weinberger &Frank Fischer.
2008.
Analyzing collaborativelearning processes automatically: Exploitingthe advances of computational linguistics incomputer-supported collaborative learning.
In-ternational Journal of Computer-SupportedCollaborative Learning 3(3).
237?271.doi:10.1007/s11412-007-9034-0 (10 Decem-ber, 2011).Rubrichi, S & S Quaglini.
2012.
Summary of ProductCharacteristics content extraction for a safedrugs usage.
Journal of Biomedical Informatics45(2).
231?239.
doi:10.1016/j.jbi.2011.10.012(3 May, 2012).Segura-Bedmar, Isabel, Paloma Martinez & CesarPablo-Sanchez.
2010.
Extracting drug-drug in-teractions from biomedical texts.
Workshop onAdvances in Bio Text Mining, vol.
11 Suppl 5,9.
Madrid, Spaim: BMC Bioinformatics.http://www.biomedcentral.com/1471-2105/11/S5/P9.Segura-Bedmar, Isabel, Paloma Martinez & DanielSanchez-Cisneros (eds.).
2011.
Proceedings ofthe First Challenge Task: Drug-Drug Interac-tion Extraction 2011.
Huelva, Spain.http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-761/ (9December, 2011).Stanford NLP.
2011.
The Stanford NLP (Natural Lan-guage Processing) Group.http://nlp.stanford.edu/software/ (10 December,2011).Tari, Luis, Saadat Anwar, Shanshan Liang, James Cai &Chitta Baral.
2010.
Discovering drug-drug in-teractions: a text-mining and reasoning ap-proach based on properties of drug metabolism.Bioinformatics (Oxford, England) 26(18).i547?553.
doi:10.1093/bioinformatics/btq382(9 December, 2011).Thomas, Philippe, Mariana Neves, Illes Solt, DomonkosTikk & Ulf Leser.
2011.
Relation Extractionfor Drug-Drug Interactions using EnsembleLearning.
1st Challenge task on Drug-Drug In-teraction Extraction (DDIExtraction 2011),11?18.
Huelva, Spain.213
