Extraction of User Preferences from a Few Positive DocumentsByeong Man Kim, Qing LiDept.
of Computer SciencesKumoh National Institute of TechnologyKumi, kyungpook, 730-701,South Korea(Bmkim, liqing)@se.Kumoh.ac.krJong-Wan KimSchool of Computer & InformationTaegu UniversityKyungsan-City, Kyungpook, South Koreajwkim@biho.taegu.ac.krAbstractIn this work, we propose a new methodfor extracting user preferences from a fewdocuments that might interest users.
Forthis end, we first extract candidate termsand choose a number of terms called ini-tial representative keywords (IRKs) fromthem through fuzzy inference.
Then, byexpanding IRKs and reweighting them us-ing term co-occurrence similarity, the fi-nal representative keywords are extracted.Performance of our approach is heavilyinfluenced by effectiveness of selectionmethod for IRKs so we choose fuzzy in-ference because it is more effective inhandling the uncertainty inherent in se-lecting representative keywords of docu-ments.
The problem addressed in thispaper can be viewed as the one of findinga representative vector of documents inthe linear text classification literature.
So,to show the usefulness of our approach,we compare it with two famous methods -Rocchio and Widrow-Hoff - on theReuters-21578 collection.
The resultsshow that our approach outperforms theother approaches.1 IntroductionAgent technology is able to provide increasinglymore services for individuals, groups, and organi-zations.
Agents, which have been developed forInternet, have addressed many tasks such as infor-mation finding, filtering and presentation, contractnegotiation, and electronic commerce (Soltysiakand Crabtree, 2000).
Most of them rely on theknowledge of the user.
The inclusion of user in-formation becomes a key area.A user model that represents some aspects of auser?s information needs or preferences can be use-ful in any information system design, and in thecase of information filtering (Kim et al, 2000).User models can be constructed by hand, orlearned automatically based on feedback providedby the users.
Some systems require users to explic-itly specify their profiles, often as a set of key-words or categories.
But it is difficult for a user toexactly and correctly specify their informationneeds.
The machine learning techniques offer thepotential to automatic construction and continuousrefinement of user model.The research systems adopting the machinelearning techniques have been applied feedbacktechniques that explicitly provide relevance judg-ments on documents.
Studies have shown that suchexplicit feedback from the user is clearly useful(Goldberg, 1992; Yan and Garcia-Molina, 1995),but, in practice, many users are unwilling to pro-vide relevance judgments on documents (Pazzani,M., Billsus, 1997; Baeza-Yates and  Ribeiro-Neto,1999) .
Users may have problems to decide aboutsome documents.
An alternative is to use implicitfeedback where document relevance is inferredfrom user?s behavior, which has received increasedattention in recent years (Nichols, 1997; Konstan etal., 1997; Kim, 2000)This paper focuses upon the extraction of userpreferences from a few documents that might in-terest a user.
It does not consider how to providerelevance judgment on documents, i.e.
it assumesThis work was supported by grant No.
2000-1-51200-008-2from the Korea Science & Engineering Foundationthat relevant documents are given explicitly or im-plicitly.
Our approach is based on the vector spacemodel (Baeza-Yates and Ribeiro-Neto, 1999),where text-based documents are represented asvectors of term weights.
So, the problem addressedin this paper is how to extract representative key-words from documents provided by a user andwhat weights should be assigned to these keywords.We present a new technique to solve this problem.The proposed method is composed of two parts,one is to select initial representative keywords(IRKs) and the other is to automatically expandand reweight IRKs.
For the first part, we can con-sider feature selection methods (Yang and Peder-sen, 1997) that focus on performance improvementand dimensionality reduction of document classifi-ers for a huge amount of documents covering vari-ous categories.
However, since this kind ofmethods select features using information of othercategories and negative document sets as well aspositive ones, it is impossible to apply these to thetarget problem in this paper that extract featurekeywords from only few positive documents in thesame category.
As alternatives, we can considerthe Rocchio algorithm and Widrow-Hoff algorithmused as a training algorithm for linear text classi-fier since these algorithms can extract keywordsand assign weights to them effectively with onlypositive document sets.
However, here, a newtechnique that adopts fuzzy inference to extract orgenerate IRKs from a few example documents (theset of documents judged relevant by the users) issuggested since the existing algorithms did notshow good results as we expected.For the second part, we can choose one ofquery term expansion and term weight modifica-tion methods based on vector model (Xu and Croft ,1996; Mitra et al,1998; Baeza-Yates and  Ribeiro-Neto, 1999).
Instead, we take a new approachwhere the term co-occurrence similarity is intro-duced as a measure of similarity between the dis-tributions within the feedbacked documents of agiven term and the initial query.
With this similar-ity and the document frequency in feedbackeddocuments, the weight of the term in the new querywas calculated.In the next section, Rocchio and Widrow-Hoffalgorithms are reviewed.
Section 3 presents amethod for user?s preference extraction.
The ex-periments to test the proposed method will be out-lined in Section 4.
Finally, conclusion is followed.2 BackgroundTo extract a user?s preference from example docu-ments is the same problem as finding theirrepresentative vector in linear text classifiers.
Avariety of algorithms for training linear classifiershave been suggested.
Among them, here, we onlyreview two widely used algorithms, Rocchio algo-rithm and Widrow-Hoff algorithm, for comparingwith our method.The Rocchio algorithm (David et al, 1996) is abatch algorithm.
So, it produces a new weight vec-tor w  from an existing weight vector oldw  by ana-lyzing the entire set of training data at once.
Thej th?
component of w   is :cCijicCijijoldj nnxnxww ???
?+= ?
?,,, ???
(1)where, ,i jx  means j th?
component of i th?
docu-ment vector ix  and  n  is the number of trainingdocuments.
C is the set of positive training docu-ments, and cn is the number of positive trainingdocuments.
The parameter ??
, and ?
control therelative impact of the original weight vector, thepositive examples, and the negative examples, re-spectively.
However, in our experiments, ?
= 0,?
=1, and ?
= 0 because only positive examplesare given in our application.
Neither originalweight vector nor negative examples is given.The Widrow-Hoff algorithm (David et al, 1996)is an online algorithm where one training exampleis presented at a time.
It updates its current weightvector based on the example and then discards theexample, retaining only the new weight vector.
Anew weight vector wi+1 is computed from an oldweight vector iw  and a training document ix  withclass label iy .
The class label iy  is 1 if a trainingdocument ix  is in the set of positive or relevanttraining documents, otherwise 0.
In our application,iy  is always 1 because we deal with only positiveexamples.
The initial weight vector w1 is typicallyset to zero vector, w1 = (0, ... 0).1, , ,2 ( )i j i j i i i i jw w w x y x?+ = ?
?
?
(2)where,  ?
is the learning rate which controls howquickly the weight vector w is allowed to changeand ii xw ?
is the cosine value of the two vectors.3 Extraction of user preferencesUser preferences are extracted from a few exampledocuments through two steps: a) the first step gen-erates a set of keywords called IRKs (Initial Repre-sentative Keywords) which corresponds to theinitial user query in the relevance feedback tech-niques of IR and b) these IRKs are expanded andreweighted by a relevance feedback technique.It is very important to select IRKs reflectinguser?s preferences well from example or trainingdocuments (set of documents judged relevant bythe user) because we have to calculate term co-occurrences similarity between these IRKs andcandidate terms within each example document.Three factors of a term (term frequency, documentfrequency within positive examples, and IDF) areused to calculate the importance of a specific term.Since these factors essentially have inexact anduncertain characteristics, we combine them byfuzzy inference instead of a simple equation.The IRKs are selected based on the selectioncriteria that each example document has at leastone or more IRKs.
After selecting the IRKs, weperform term modification process based on theterm co-occurrence similarity between these IRKsand candidate terms.
The Rocchio and Widrow-Hoff algorithms do not consider the term co-occurrence relationship within training documents.But, we regard the term co-occurrence relationshipas the key factor to calculate the importance ofterms under the assumption that the IRKs reflectuser?s preferences well.3.1 Calculation of the Representativeness ofTerms through Fuzzy InferenceThe given positive examples are transformed intothe set of candidate terms through eliminatingstopwords and stemming by Porter?s algorithm.The TF, DF, and IDF of each term are calculatedbased on this set and used as inputs of fuzzy infer-ence.
From now on, we will explain these threeinput variables.
The TF (Term Frequency) is theterm frequency of a specific term not in a docu-ment but in a set of documents, which is calculatedby dividing total occurrences of the term in a set ofdocuments by the number of documents in the setcontaining the term.
It needs to be normalized forbeing used in fuzzy inference.
The followingshows the normalized term frequency (NTF).maxiiijjjTFDFNTFTFDF= ?
??
??
??
?
(3)where, iTF  is the frequency of term ti in the exam-ple documents, iDF  is the number of documentshaving term ti in the example document,[ ]j jMax x means the maximum value of vari-able jx .The DF (Document Frequency) represents thefrequency of documents having a specific termwithin the example documents.
The normalizeddocument frequency, NDF, is defined in equation(4), where iDF is the number of documents havingterm ti in the example documents.maxiij jDFNDFDF=                        (4)The IDF (Inverse Document Frequency) repre-sents the inverse document frequency of a specificterm over an entire document collection not exam-ple documents.
The normalized inverse documentfrequency, NIDF, is defined as follows:,    logmaxii ij j iIDF NNIDF IDFIDF n= =              (5)where, N is the total number of documents and inis the number of documents containing term ti .Figure 1.
Fuzzy input/output variables0 0.2 0.4 0.6 0.8 1Z S M XX L1TW11 0.2 0.7L S L10.80.61 0.1 0.3M1NTF=S NDF, NIDF1(a) Input variable(b) Output variableZ: zeroS: smallM: middleL : largeX: x largeXX:xxlargerSFigure 1 shows the membership functions of theinput/output variables - 3 inputs (NTF, NDF, NIDF)and 1 output (TW) - used in our method.
As youcan see in Figure 1(a), NTF variable has{ S(Small), L(Large) }, and NDF and NIDF vari-ables have { S(Small), M(Middle), L(Large) } aslinguistic labels (or terms).
The fuzzy output vari-able, TW (Term Weight) which represents the im-portance of a term, has six linguistic labels asshown in Figure 1(b).The 18 fuzzy rules are involved to infer theterm weight (TW).
The rules are constructed basedon the intuition that the important or representativeterms may occur across many positive exampledocuments but not in general documents, i.e., theirNDF and NIDF are very high.
As shown in Table 1,the TW of a term is Z in most cases regardless ofits NDF and NTF if its NIDF is S, because suchterm may occur frequently in any document andthus its NDF and NTF can be high.
When NDF ofa term is high and its NIDF is also high, the term isconsidered as a representative keyword and thenthe output value is between X and XX.
The otherrules were set similarly.Table 1.
Fuzzy inference rulesNIDFNDFS M L NIDFNDFS M LS Z Z S S Z S MM Z M L M Z L XL S L X L S X XXNTF = S NTF = LWe can get the term weight TW through thefollowing procedure.
But, the output is in the formof fuzzy set and thus has to be converted to thecrisp value.
In this paper, the center of gravitymethod is used to defuzzify the output  (Lee, 1990).?
Apply the NTF, NDF, and NIDF fuzzy val-ues to the antecedent portions of 18 fuzzyrules.?
Find the minimum value among the mem-bership degrees of three input fuzzy values.?
Classify every 18 membership degree into 6groups according to the fuzzy output vari-able TW.?
Calculate the maximum output value foreach group and then generate 6 output val-ues.3.2 Selection of Initial Representative Key-wordsAfter calculation of the term weights of candidateterms through fuzzy inference, some candidateterms are selected as IRKs based on their weightswith the constraint that each example documentshould contain at least one or more IRKs.
The al-gorithm for selection of IRKs is given in Figure 2.Let us consider the following example to under-stand our selection procedure.i) An example document set, DS, is composed ofdocuments d1, d2, d3, d4, d5, and d6.
Eachdocument contains the following terms:d1 = {a, b, f}, d2 = {a, c, d}, d3 = {d, e, f},d4 = {d, f},  d5 = {b, c, e},  d6 = {e, f}ii) A candidate term set, TS, is composed of {(a,0.9), (b, 0.8), (c, 0.7), (d, 0.6), (e, 0.5), (f, 0.4)},where (ti, TWi) represents that TWi is the termweight of term ti.If we apply the algorithm in Figure 2 to this ex-ample, then temporary variables in line 2, 3 and 4are initialized.
The statement block from line 5 toline 14 is executed repeatedly until at least one ormore IRKs are extracted from every exampledocument in DS.
Let us assume that the documentsin the example document set are processed in se-quence.
After the first loop of the statement blockfrom line 5 to line 14 is executed, the output valueof ITS contains only term ?a?.
There is no changein ITS after the second loop of the block becauseterm ?a?
has already been included in ITS.
Afterd3, the third loop of the block, is processed, a term?d?
is newly added to ITS.
So, there is {a, d} inITS.
After d4, d5, and d6 are sequentially proc-essed, none, term ?b?, and term ?e?
are added toITS, respectively.
Therefore the algorithm returnITS having a set of terms {a, b, d, e}.
We can findthe algorithm in Figure 2 works well according toour constraint.Input: DS (Example Documents Set)TS (Candidate Terms Set)1] Procedure get_ITS(DS, TS)2] ITS: Initial Representative Terms Set, initialized to empty.3] TS': Temporary Terms Set, initialized to TS.4] d, t: Document and Term element respectively.5] Repeat6]   Select a document element as d from DS.7]   Repeat8]      Select the highest element as t in TS'according to the weight.9]      If t appears in d and not member in ITSThen Add t to ITS.10]     Remove t from TS.11]   Until t appears in d.12]   Remove d from DS.13]   Assign TS to TS'.14] Until DS is empty.15] Return ITS.Figure 2.
The algorithm for selection of initial rep-resentative terms3.3 Automatic Expansion and Reweighting ofIRKsAfter the IRKs are selected, additional terms areselected to be expanded in the order of theirweights calculated by the method in Section 3.1.Let us assume that 5 terms are used to represent auser's preference and the number of IRKs is 3.Then, 2 terms with highest weights except IRKsare selected additionally.
The IRKs and these termsconstitute the final representative keywords(FRKs) and are reweighted by considering the co-occurrence similarity with IRKs.
For this end, therelevance degrees of the FRKs in every documentare calculated with the equation (6).
Each positiveexample document represents user?s preferablecontent.
In other words, each document tends tocontain general or specific or partial contents.
Weregard the IRKs as the essential terms of the givenpositive examples.
So, the possibility that the re-lated terms, e.g., synonym, collocated terms and soon, occurred together with these IRKs in the samedocument set increases.1)(log1 12+?
?
?= =ntfkfRDnjikjkpik              (6)where, RDik is the relevance degree between IRKsand candidate term ti in document dk, kfjk is the fre-quency of initial representative keyword j indocument dk, tfik is the frequency of candidate termti in document dk, n is the number of IRKs, p is acontrol parameter.
In our experiments, p is set to10.
The RDik is treated as 0 if it has negative value.For example, let K be a set of IRKs consistingof k1, k2 and k3 terms and their frequencies indocument d1 be 4, 3, and 1, respectively.
Also, letthe frequency of term t1 be 2.
Then, its relevancedegree is calculated as follows:13)1(12log12221011 +?++?=RD =  0.762As shown in the above equation, RDik is in-versely proportional to the sum of term frequencydifference between initial representative term andcandidate term.
So, the higher is the value of Rd,the more similar the co-occurrence is, that is, theequation reflects the co-occurrence similarity be-tween initial representative terms and a candidateterm appropriately.
After calculating the relevancedegree of a candidate term, the weight of the termin the set of example documents is determined bythe following equation:iikiknkikikriIDFTFwRDww?=?
?==1)((7)where, wri is the weight of term ti in the documentset, wik is the weight of term ti in document dk, TFikis the frequency of term ti in document dk, IDFi isthe inverse document frequency of term ti, and n isthe number of example documents.The equation (7) is a modification of the Roc-chio's in Section 2.
Different from that equation,we additionally use the term relevance degree be-tween initial representative terms and a candidateterm.
Let us assume that the IDF value of the can-didate term t1 is 1.0 and it occurs 3, 2, and 1 withindocument d1, d2 and d3, respectively.
If the rele-vance degrees for three documents are also as-sumed to 0.3, 0.5, and 0.7, respectively, then theweight of candidate term ti is calculated as below.82.1))7.00.1()5.00.2()4.00.3((1 =?+?+?=rwFinally, the weights of the FRKs are calculatedby the following equation:rikii www +=                              (8)where, wki, is  the initial weight of term ti.
Insteadof using the weight obtained by fuzzy inference,the initial weight wki of term ti is recalculated bythe equation (9), if the term is in IRKs and other-wise 0.
The equation is the one introduced to as-sign a weight to an initial query term in IR systemsbased on the vector space model (Baeza-Yates andRibeiro-Neto, 1999).?????????????????
?+=ijjiki nNfreqfreqw logmax5.05.0        (9)where, freqi is the frequency of initial representa-tive keyword ti, ni is the frequency of documents inwhich ti appear, and N is the total number of docu-ments.Let K = {t1, t3, t4} be the set of IRKs, WK ={3.0, 2.0, 1.0} be the set of their weights calculatedby the equation (9), T = {t1, t2, t3, t4, t5} be theset of FRKs, and WT = {5.0, 4.0, 3.0, 2.0, 1.0} betheir weights through the equation (7).
Then, wecan get the final weights of FRKs, {8.0,4.0, 5.0,3.0, 1.0}.4 ExperimentsWe used Reuters-21578 data as an experimentaldocument set.
This collection has five different setsof contents related categories.
They areEXCHANGES, ORGS, PEOPLE, PLACES andTOPICS.
Some of the categories set have up to 265categories, but some of them have just 39 catego-ries.
We chose the TOPICS categories set whichhas 135 categories.
We divided the documents ac-cording to the ?ModeApte?
split.
There are 9603training documents and 3299 test documents.Among the 135 categories, we first chose only 90ones that have at least one training example andone testing example.
Then, we finally selected 21categories that have from 10 to 30 training docu-ments.
The 3019 documents of those categories areused as testing documents.
The document fre-quency information from 7770 training documentsin 90 categories is used to calculate IDF values ofterms.
We did not consider negative documentsunder the assumption that only positive documentscoincident with users?
preferences were given im-plicitly or explicitly .Documents are ranked by the cosine similarityand the following F-measure (Baeza-Yates andRibeiro-Neto, 1999), which is a weighted combina-tion of recall and precision and popularly used forperformance evaluation.
Since the maximum valuefor F can be interpreted as the best possible com-promise between recall and precision, we use thismaximum value.
)/(2112jjjjjjj RPRPRPF +=+=          (10)where, Rj and Pj are the recall and precision for thej?th document in the ranking and Fj is their har-monic mean.First, our method was compared to the Rocchioand Widrow-Hoff algorithms.
To see the effect ofthe number of FRKs, we made experiments byvarying it from 5 to 30 in increment 5 and for thecase that all terms are used.
Table 2 shows theoverall or summary result of the proposed methodcompared to the two existing algorithms for21categories.
The result shows that our method isbetter than the others in all cases, especially when10 terms are used to represent user preferences.Table 3 shows the detail result in that case, i.e.
theF-values and the performance improvement ratioswhen 10 terms are used.
The proposed method hasachieved about 20% over Rocchio algorithm and10% over Widrow-Hoff algorithm on the average.When 5 terms are used to represent user prefer-ences, 19 categories among 21 categories are usedbecause ?strategic-metal?
and ?pet-chem?
catego-ries do not satisfy the constraint in Section 3.2, i.e.,5 terms are too few to cover all training documents.Table 2.
Performance of 21 categories in theREUTERS corpus and comparison with two exist-ing algorithms.Our Rocchio W.H.5 0.582 0.511 0.56610 0.594 0.496 0.54015 0.571 0.490 0.52920 0.552 0.489 0.52225 0.545 0.491 0.49330 0.541 0.495 0.500All 0.490 0.467 0.483It is not clear which component of our methodmainly contributes to such improvement since ourmethod consists of two main components - one isfor extracting IRKs, the other for expanding andreweighting of IRKs.
To analyze our method, wemade several variants of the proposed method anddid experiments with them.
The variants are namedby the sequence of the following symbols.IF, IR, IW: mean that IRKs are selected based onthe weight obtained by the method in Section 3.1,the Rocchio algorithm, and the Widrow-Hoff algo-rithm, respectively.RC, RR, RW: mean that terms are reweighted bythe method in Section 3.3, the Rocchio algorithm,and the Widrow-Hoff algorithm, respectively.EC, EF, ER, EW: mean that expanded terms areselected based on the weight obtained by applyingthe method in Section 3.3, the method in Section3.1, the Rocchio algorithm, and the Widrow-Hoffalgorithm, respectively.For example, the proposed method in Section 3 isnamed as IF_EF_RC, which means IRKs, and ex-panded terms are selected based on the weight cal-culated by the method in Section 3.1 and thenreweighted by the method in Section 3.3.
For an-other example, the method called by IF_RC_ECmeans that IRKs are selected based on the weightobtained by the method in Section 3.1 and then allterms are reweighed by the method in Section 3.3before expanded terms are selected.In the proposed method, fuzzy inference tech-nique is used to extract IRKs.
So, we tried twovariants, IR_ER_RC and IW_EW_RC, where theRocchio and Widrow-Hoff algorithms are usedrespectively to calculate the representativeness (orweights) of terms instead of the method in Section3.1, and then IRKs and expanded terms are se-lected based on these weights.
The variants all usethe reweighting scheme in Section 3.3.
Table 4shows that other keyword extraction algorithms donot show any benefit over the fuzzy inference ap-proach.
We can also observe that when one of theexisting algorithms is combined with the secondcomponent of our method, the performance im-provement over the case that the algorithm solelyis used is negligible.The method to extract IRKs reflecting user?spreference directly affects the result of the termreweighting process because the process is basedon the term co-occurrence similarity with the IRKs.If the terms that are far from user?s preference areextracted as IRKs, then some terms that actuallyare improper in representing user?s informationneeds may be assigned with high weights duringthe reweighting process and then the final vectorgenerated from the results may be disqualifiedfrom representing user?s preferences.
So, we canknow that our fuzzy inference technique is effec-tive to extract IRKs from the results in Table 4.To demonstrate the usefulness of the secondpart of our method, i.e., the expansion and re-weighting technique, we also tried the 5 variants ofour method (IF_RC_EC, IF_RR_ER, IF_RW_EW,IF_EF_RR, IF_EF_RW).
Table 5 shows the allvariants are not better than the original though theyoutperform Rocchio and Widrow-Hoff algorithms.5 ConclusionsIn this study, we apply fuzzy inference techniqueand term reweighting scheme based on the termco-occurrence similarity to the problem that extractimportant keywords representing contents ofdocuments presented by users.
We have conductedextensive experiments on the Reuters-21578 col-lection.
The results show that our method outper-forms two well-known training algorithms forlinear text classifiers.
Moreover, some variants ofour method have been explored to analyze thecharacteristics of our method.
Though this paperonly describes how to extract user preferencesfrom example documents, the technique will beapplicable to several areas such as query modifica-tion in IR, user profile modification in informationfiltering, text summarization and so forth directlyor with some modifications.Since only positive examples are considered inour method, the method is not applicable to adocument set containing negative examples.
Forcovering negative examples, it needs to modify thefuzzy inference rules with considering additionalinput variables.
The proposed method was alsodesigned for a small set of documents.
So, wecould not achieve performance improvement asdescribed in this paper when our method is appliedto a large set of documents.
However, such a prob-lem will be alleviated if clustering techniques areused together as in (Alberto et al, 2001; Lam andHo, 1998; Ugur et al, 2000).Table 3.
The detail result when 10 terms are usedfor user preferencesOur Rocchio W.H.lumber 0.7273 0.4444 0.6667dmk 0.4 0.4444 0.4sunseed 0.5714 0.3333 0.3333lei 1 0.8 1soy-meal 0.6667 0.5143 0.5185fuel 0.4615 0.4615 0.4615heat 0.75 0.75 0.75soy-oil 0.3704 0.2692 0.32lead 0.5625 0.5 0.5strategic- 0.13333 0.1053 0.1408hog 0.8 0.6 0.8orange 0.9091 0.9091 0.8571housing 0.5714 0.6667 0.5714tin 0.96 0.7857 0.9231rapeseed 0.6154 0.5714 0.6154wpi 0.5714 0.5882 0.5882pet-chem 0.3704 0.2727 0.2759silver 0.381 0.4 0.5zinc 0.8966 0.6667 0.6842retail 0.1667 0.0548 0.0548sorghum 0.5882 0.2727 0.3871Average 0.5940 0.4957 0.5404Table 4.
The performance of our method and itstwo variants that use Rocchio and Widrow-Hoffalgorithms instead of fuzzy inference, respectively.Table 5.
The performance of our method and itsfive variants that use different reweighting and ex-panding approaches.ReferencesAlberto Diaz Esteban, Manuel J. Mana Lopez, Manuelde Buenaga Rodriguez, Jose Ma Gomez Hidalgo andPablo Gervas Gomez-Navarro.
2001.
Using linearclassifiers in the integration of user modeling andtext content analysis in the personalization of a web-based Spanish news servic, In Proceedings.
of theWorkshop on Machine Learning, Information Re-trieval and User Modeling, 8th International Confer-ence on User Modeling.Baeza-Yates, R. and Ribeiro-Neto B.. 1999.
ModernInformation Retrieval, ACM Press, USA.David D. Lewis, Robert E. Schapire , James P. Callanand Ron Papka.
1996.
Training algorithms for lineartext classifiler, In Proc.
of SIGIR-96, 19th ACM In-ternational Conference on Research and Develop-ment in Information Retrieval.Goldberg D., Nichols D., Oki B. M., and Terry D.. 1992.Using collaborative filtering to weave an informationtapestr, Communication of the ACM, 35(12), p61-70.Kim, J., Oard, D.W., and Romanik, K.. 2000.
Usermodeling for information filtering based on implicitfeedback, In Proceedings.
of ISKO-France.Konstan J.
A. , Miller B. N., Maltz D., Herlocker J. L.,Gordon L.R.
and Riedl J.. 1997.
GroupLens: Apply-ing collaborative filtering to Usenet News, Commu-nication of the ACM, 40(3), p 77-87.Lam K. and Ho C.. 1998.
Using a generalized instanceset for automatic text categorization, In 21th Ann.
Int.ACM SIGIR Conference on Research and Develop-ment in Information Retrieval, p81-89.Lee C.C.. 1990.
Fuzzy logic in control systems: fuzzylogic controller-part I, IEEE Trans.
On Systems,Man, and Cybernetics, 20 (2) , p408-418.Mitra, M., Singhal, A., and Buckley, C.,.
1998.
Improv-ing Automatic Query Expansion, In Proceedings ofthe 21st Annual International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval, p206-214, 1998.Nichols D. M.. 1997.
Implicit ratings and filteri?, InProceedings of the 5th DELOS Workshop on Filter-ing and Collaborative Filtering, p10-12.Pazzani, M. and  Billsus, D.. 1997.
Learning and revis-ing user profiles: the identification of interesting Website, Machine Learning, 1997.Seo, Y. and Zhang, B.. 2001.
Personalized Web Docu-ment Filtering Using Reinforcement Learning, Ap-plied Artificial Intelligence.Soltysiak, S. J. and Crabtree, I.
B.. 2000.
AutomaticLearning of User Profiles?Towards the Personaliza-tion of Agent Services, BT Technology Journal, 16(3), p110?117.Ugur ?etintemel, Franklin Michael J. and Lee Giles C..2000 .
Self-Adaptive User Profiles for Large-ScaleData Delivery, ICDE, p622-633.Xu Jinix and Croft W. B.. 1996.
Query Expansion Us-ing Local and Global Document Analysis, In Pro-ceeding of ACM SIGIR International Conference onResearch and Development in Information Retrieval,p4-11.Yan T. W. and Garcia-Molin H.. 1995.
SIFT- A tool forwide-area information dissemination, In Proceedingsof the 1995 USENIX Technical Conference, p177-186.Yang, Y. and  Pedersen, J..  1997.
A comparative studyon feature selection in text categorization, In Pro-ceedings of the 14th International Conference onMachine Learning, p412-420.IF_EF_RC IR_ER_RC IW_EW_RC5 0.582 0.509 0.57110 0.594 0.505 0.52815 0.571 0.502 0.53720 0.552 0.491 0.52625 0.545 0.487 0.51830 0.541 0.497 0.510All 0.490 0.478 0.490IF_EF_RCIF_RC_ECIF_RR_ERIF_RW_EWIF_EF_RRIF_EF_RW5 0.582 0.571 0.546 0.580 0.545 0.57010 0.594 0.520 0.498 0.549 0.551 0.56115 0.571 0.514 0.491 0.508 0.518 0.51720 0.552 0.513 0.495 0.533 0.497 0.53825 0.545 0.509 0.498 0.503 0.491 0.52130 0.541 0.515 0.506 0.512 0.498 0.511All 0.490 0.488 0.478 0.494 0.465 0.483
