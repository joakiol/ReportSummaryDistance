Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 57?64,Sydney, July 2006. c?2006 Association for Computational LinguisticsAcceptability Prediction by Means of Grammaticality QuantificationPhilippe Blache, Barbara Hemforth & Ste?phane RauzyLaboratoire Parole & LangageCNRS - Universite?
de Provence29 Avenue Robert Schuman13621 Aix-en-Provence, France{blache,hemforth,rauzy}@lpl.univ-aix.frAbstractWe propose in this paper a method forquantifying sentence grammaticality.
Theapproach based on Property Grammars,a constraint-based syntactic formalism,makes it possible to evaluate a grammat-icality index for any kind of sentence, in-cluding ill-formed ones.
We compare ona sample of sentences the grammaticalityindices obtained from PG formalism andthe acceptability judgements measured bymeans of a psycholinguistic analysis.
Theresults show that the derived grammatical-ity index is a fairly good tracer of accept-ability scores.1 IntroductionSyntactic formalisms make it possible to describeprecisely the question of grammaticality.
Whena syntactic structure can be associated to a sen-tence, according to a given grammar, we can de-cide whether or not the sentence is grammatical.In this conception, a language (be it natural or not)is produced (or generated) by a grammar by meansof a specific mechanism, for example derivation.However, when no structure can be built, nothingcan be said about the input to be parsed except,eventually, the origin of the failure.
This is a prob-lem when dealing with non canonical inputs suchas spoken language, e-mails, non-native speakerproductions, etc.
From this perspective, we needrobust approaches that are at the same time ca-pable of describing precisely the form of the in-put, the source of the problem and to continue theparse.
Such capabilities render it possible to arriveat a precise evaluation of the grammaticality of theinput.
In other words, instead of deciding on thegrammaticality of the input, we can give an indica-tion of its grammaticality, quantified on the basisof the description of the properties of the input.This paper addresses the problem of ranking thegrammaticality of different sentences.
This ques-tion is of central importance for the understandingof language processing, both from an automaticand from a cognitive perspective.
As for NLP,ranking grammaticality makes it possible to con-trol dynamically the parsing process (in choosingthe most adequate structures) or to find the beststructure among a set of solutions (in case of non-deterministic approaches).
Likewise the descrip-tion of cognitive processes involved in languageprocessing by human has to explain how thingswork when faced with unexpected or non canoni-cal material.
In this case too, we have to explainwhy some productions are more acceptable andeasier to process than others.The question of ranking grammaticality hasbeen addressed from time to time in linguistics,without being a central concern.
Chomsky, forexample, mentioned this problem quite regularly(see for example (Chomsky75)).
However herephrases it in terms of ?degrees of ?belonging-ness?
to the language?, a somewhat fuzzy notionboth formally and linguistically.
More recently,several approaches have been proposed illustrat-ing the interest of describing these mechanismsin terms of constraint violations.
The idea con-sists in associating weights to syntactic constraintsand to evaluate, either during or after the parse,the weight of violated constraints.
This approachis at the basis of Linear Optimality Theory (see(Keller00), and (Sorace05) for a more general per-spective) in which grammaticality is judged on thebasis of the total weights of violated constraints.
Itis then possible to rank different candidate struc-57tures.
A similar idea is proposed in the frameworkof Constraint Dependency Grammar (see (Men-zel98), (Schro?der02)).
In this case too, acceptabil-ity is function of the violated constraints weights.However, constraint violation cannot in itselfconstitute a measure of grammaticality withouttaking into account other parameters as well.
Thetype and the number of constraints that are sat-isfied are of central importance in acceptabilityjudgment: a construction violating 1 constraintand satisfying 15 of them is more acceptable thanone violating the same constraint but satisfyingonly 5 others.
In the same way, other informa-tions such as the position of the violation in thestructure (whether it occurs in a deeply embeddedconstituent or higher one in the structure) plays animportant role as well.In this paper, we propose an approach over-coming such limitations.
It takes advantage of afully constraint-based syntactic formalism (calledProperty Grammars, cf.
(Blache05b)) that of-fers the possibility of calculating a grammatical-ity index, taking into account automatically de-rived parameters as well as empirically determinedweights.
This index is evaluated automatically andwe present a psycholinguistic study showing howthe parser predictions converge with acceptabilityjudgments.2 Constraint-based parsingConstraints are generally used in linguistics as acontrol process, verifying that a syntactic struc-ture (e.g.
a tree) verifies some well-formednessconditions.
They can however play a more generalrole, making it possible to express syntactic infor-mation without using other mechanism (such as ageneration function).
Property Grammars (notedhereafter PG) are such a fully constraint-based for-malism.
In this approach, constraints stipulate dif-ferent kinds of relation between categories such aslinear precedence, imperative co-occurrence, de-pendency, repetition, etc.
Each of these syntacticrelations corresponds to a type of constraint (alsocalled property):?
Linear precedence: Det ?
N (a determinerprecedes the noun)?
Dependency: AP ; N (an adjectival phrasedepends on the noun)?
Requirement: V[inf] ?
to (an infinitivecomes with to)?
Exclusion: seems < ThatClause[subj] (theverb seems cannot have That clause subjects)?
Uniqueness : UniqNP {Det} (the determineris unique in a NP)?
Obligation : ObligNP {N, Pro} (a pronoun ora noun is mandatory in a NP)?
Constituency : ConstNP {Det, AP, N, Pro}(set of possible constituents of NP)In PG, each category of the grammar is de-scribed with a set of properties.
A grammar is thenmade of a set of properties.
Parsing an input con-sists in verifying for each category of descriptionthe set of corresponding properties in the gram-mar.
More precisely, the idea consists in verifying,for each subset of constituents, the properties forwhich they are relevant (i.e.
the constraints thatcan be evaluated).
Some of these properties aresatisfied, some others possibly violated.
The re-sult of a parse, for a given category, is the set of itsrelevant properties together with their evaluation.This result is called characterization and is formedby the subset of the satisfied properties, noted P+,and the set of the violated ones, noted P?.For example, the characterizations associated totheNPs ?the book?
and ?book the?
are respectivelyof the form:P+={Det ?
N; Det ; N; N < Pro; Uniq(Det),Oblig(N), etc.
}, P?=?P+={Det ; N; N < Pro; Uniq(Det), Oblig(N),etc.
}, P?={Det ?
N}This approach allows to characterize any kindof syntactic object.
In PG, following the pro-posal made in Construction Grammar (see (Fill-more98), (Kay99)), all such objects are calledconstructions.
They correspond to a phrase (NP,PP, etc.)
as well as a syntactic turn (cleft, wh-questions, etc.).
All these objects are described bymeans of a set of properties (see (Blache05b)).In terms of parsing, the mechanism consistsin exhibiting the potential constituents of a givenconstruction.
This stage corresponds, in constraintsolving techniques, to the search of an assignmentsatisfying the constraint system.
The particular-ity in PG comes from constraint relaxation.
Here,the goal is not to find the assignment satisfyingthe constraint system, but the best assignment (i.e.the one satisfying as much as possible the system).In this way, the PG approach permits to deal withmore or less grammatical sentences.
Provided that58some control mechanisms are added to the pro-cess, PG parsing can be robust and efficient (see(Blache06)) and parse different material, includ-ing spoken language corpora.Using a constraint-based approach such as theone proposed here offers several advantages.
First,constraint relaxation techniques make it possi-ble to process any kind of input.
When pars-ing non canonical sentences, the system identi-fies precisely, for each constituent, the satisfiedconstraints as well as those which are violated.It furnishes the possibility of parsing any kindof input, which is a pre-requisite for identifyinga graded scale of grammaticality.
The secondimportant interest of constraints lies in the factthat syntactic information is represented in a non-holistic manner or, in other words, in a decentral-ized way.
This characteristic allows to evaluateprecisely the syntactic description associated withthe input.
As shown above, such a description ismade of sets of satisfied and violated constraints.The idea is to take advantage of such a represen-tation for proposing a quantitative evaluation ofthese descriptions, elaborated from different indi-cators such as the number of satisfied or violatedconstraints or the number of evaluated constraints.The hypothesis, in the perspective of a gradi-ence account, is to exhibit a relation between aquantitative evaluation and the level of grammat-icality: the higher the evaluation value, the moregrammatical the construction.
The value is thenan indication of the quality of the input, accordingto a given grammar.
In the next section we proposea method for computing this value.3 Characterization evaluationThe first idea that comes to mind when trying toquantify the quality of a characterization is to cal-culate the ratio of satisfied properties with respectto the total set of evaluated properties.
This infor-mation is computed as follows:Let C a construction defined in the grammar bymeans of a set of properties SC , let AC an assign-ment for the construction C,?
P+ = set of satisfied properties for AC?
P?
= set of violated properties for AC?
N+ : number of satisfied properties N+ =card(P+)?
N?
: number of violated properties N?
=card(P?)?
Satisfaction ratio (SR): the number of satis-fied properties divided by the number of eval-uated properties SR = N+EThe SR value varies between 0 and 1, the twoextreme values indicating that no properties aresatisfied (SR=0) or none of them are violated(SR=1).
However, SR only relies on the evalu-ated properties.
It is also necessary to indicatewhether a characterization uses a small or a largesubpart of the properties describing the construc-tion in the grammar.
For example, the VP in ourgrammar is described by means of 25 constraintswhereas the PP only uses 7 of them.
Let?s imag-ine the case where 7 constraints can be evaluatedfor both constructions, with an equal SR. However,the two constructions do not have the same qual-ity: one relies on the evaluation of all the possibleconstraints (in the PP) whereas the other only usesa few of them (in the VP).
The following formulatakes these differences into account :?
E : number of relevant (i.e.
evaluated) prop-erties E = N+ +N??
T= number of properties specifying con-struction C = card(SC)?
Completeness coefficient (CC) : the numberof evaluated properties divided by the num-ber of properties describing the constructionin the grammar CC = ETThese purely quantitative aspects have to becontrasted according to the constraint types.
Intu-itively, some constraints, for a given construction,play a more important role than some others.
Forexample, linear precedence in languages with poormorphology such as English or French may have agreater importance than obligation (i.e.
the neces-sity of realizing the head).
To its turn, obligationmay be more important than uniqueness (i.e.
im-possible repetition).
In this case, violating a prop-erty would have different consequences accordingto its relative importance.
The following examplesillustrate this aspect:(1) a.
The the man who spoke with me is my brother.b.
The who spoke with me man is my brother.In (1a), the determiner is repeated, violatinga uniqueness constraint of the first NP, whereas(1c) violates a linearity constraint of the same NP.59Clearly, (1a) seems to be more grammatical than(1b) whereas in both cases, only one constraint isviolated.
This contrast has to be taken into accountin the evaluation.
Before detailing this aspect, it isimportant to note that this intuition does not meanthat constraints have to be organized into a rank-ing scheme, as with the Optimality Theory (see(Prince93)).
The parsing mechanism remains thesame with or without this information and the hi-erarchization only plays the role of a process con-trol.Identifying a relative importance of the types ofconstraints comes to associate them with a weight.Note that at this stage, we assign weights to con-straint types, not directly to the constraints, dif-ferently from other approaches (cf.
(Menzel98),(Foth05)).
The experiment described in the nextsection will show that this weighting level seemsto be efficient enough.
However, in case of neces-sity, it remains possible to weight directly someconstraints into a given construction, overridingthus the default weight assigned to the constrainttypes.The notations presented hereafter are used todescribe constraint weighting.
Remind that P+and P?
indicate the set of satisfied and violatedproperties of a given construction.?
p+i : property belonging to P+?
p?i : property belonging to P??
w(p) : weight of the property of type p?
W+ : sum of the satisfied properties weightsW+ =N+?i=1w(p+i )?
W?
: sum of the violated properties weightsW?
=N?
?i=1w(p?i )One indication of the relative importance of theconstraints involved in the characterization of aconstruction is given by the following formula:?
QI: the quality index of a constructionQI =W+ ?W?W+ +W?The QI index varies then between -1 and 1.A negative value indicates that the set of violatedconstraints has a greater importance than the set ofsatisfied one.
This does not mean that more con-straints are violated than satisfied, but indicates theimportance of the violated ones.We now have three different indicators that canbe used in the evaluation of the characterization:the satisfaction ratio (noted SR) indicating the ra-tio of satisfied constraints, the completeness coef-ficient (noted CC) specifying the ratio of evalu-ated constraints, and the quality index (noted QI)associated to the quality of the characterization ac-cording to the respective degree of importance ofevaluated constraints.
These three indices are usedto form a global precision index (noted PI).
Thesethree indicators do not have the same impact in theevaluation of the characterization, they are thenbalanced with coefficients in the normalized for-mula:?
PI = (k?QI)+(l?SR)+(m?CC)3As such, PI constitutes an evaluation of thecharacterization for a given construction.
How-ever, it is necessary to take into account the ?qual-ity?
of the constituents of the construction as well.A construction can satisfy all the constraints de-scribing it, but can be made of embedded con-stituents more or less well formed.
The overallindication of the quality of a construction has thento integrate in its evaluation the quality of each ofits constituents.
This evaluation depends finallyon the presence or not of embedded constructions.In the case of a construction made of lexical con-stituents, no embedded construction is present andthe final evaluation is the precision index PI as de-scribed above.
We will call hereafter the evalua-tion of the quality of the construction the ?gram-maticality index?
(noted GI).
It is calculated asfollows:?
Let d the number of embedded constructions?
If d = 0 then GI = PI , elseGI = PI ?
?di=1GI(Ci)dIn this formula, we note GI(Ci) the grammat-icality index of the construction Ci.
The generalformula for a construction C is then a function ofits precision index and of the sum of the grammat-icality indices of its embedded constituents.
This60formula implements the propagation of the qualityof each constituent.
This means that the grammati-cality index of a construction can be lowered whenits constituents violate some properties.
Recipro-cally, this also means that violating a property atan embedded level can be partially compensated atthe upper levels (provided they have a good gram-maticality index).4 Grammaticality index from PGWe describe in the remainder of the paper predic-tions of the model as well as the results of a psy-cholinguistic evaluation of these predictions.
Theidea is to evaluate for a given set of sentences onthe one hand the grammaticality index (done auto-matically), on the basis of a PG grammar, and onthe other hand the acceptability judgment given bya set of subjects.
This experiment has been donefor French, a presentation of the data and the ex-periment itself will be given in the next section.We present in this section the evaluation of gram-maticality index.Before describing the calculation of the differ-ent indicators, we have to specify the constraintsweights and the balancing coefficients used in PI.These values are language-dependent, they arechosen intuitively and partly based on earlier anal-ysis, this choice being evaluated by the experimentas described in the next section.
In the remainder,the following values are used:Constraint type WeightExclusion, Uniqueness, Requirement 2Obligation 3Linearity, Constituency 5Concerning the balancing coefficients, we givea greater importance to the quality index (coeffi-cient k=2), which seems to have important conse-quences on the acceptability, as shown in the pre-vious section.
The two other coefficients are signi-ficatively less important, the satisfaction ratio be-ing at the middle position (coefficient l=1) and thecompleteness at the lowest (coefficient m=0,5).Let?s start with a first example, illustrating theprocess in the case of a sentence satisfying all con-straints.
(2)Marie a emprunte?
un tre`s long cheminpour le retour.Mary took a very long way for the return.The first NP contains one lexical constituent,Mary.
Three constraints, among the 14 describingthe NP, are evaluated and all satisfied: Oblig(N),stipulating that the head is realized, Const(N), in-dicating the category N as a possible constituent,and Excl(N, Pro), verifying that N is not realizedtogether with a pronoun.
The following valuescome from this characterization:N+ N- E T W+ W- QI SR CC PI GI3 0 3 14 10 0 1 1 0.21 1.04 1.04We can see that, according to the fact thatall evaluated constraints are satisfied, QI and SRequal 1.
However, the fact that only 3 constraintsamong 14 are evaluated lowers down the gram-matical index.
This last value, insofar as no con-stituents are embedded, is the same as PI.These results can be compared with anotherconstituent of the same sentence, the VP.
Thisconstruction also only contains satisfied prop-erties.
Its characterization is the following :Char(VP)=Const(Aux, V, NP, PP) ; Oblig(V) ;Uniq(V) ; Uniq(NP) ; Uniq(PP) ; Aux?V[part]; V?NP ; Aux?V ; V?PP.
On top of this setof evaluated constraints (9 among the possible25), the VP includes two embedded constructions: a PP and a NP.
A grammaticality index hasbeen calculated for each of them: GI(PP) = 1.24GI(NP)=1.23.
The following table indicates thedifferent values involved in the calculation of theGI.N+ N- E T W+ W- QI SR CC PI9 0 9 25 31 0 1 1 0.36 1.06GI Emb Const GI1.23 1.31The final GI of the VP reaches a high value.
Itbenefits on the one hand from its own quality (in-dicated by PI) and on another hand from that ofits embedded constituents.
In the end, the final GIobtained at the sentence level is function of its ownPI (very good) and the NP and VP GIs, as shownin the table:N+ N- E T W+ W- QI SR CC PI5 0 5 9 17 0 1 1 0.56 1.09GI Emb Const GI1.17 1.28Let?s compare now these evaluations with thoseobtained for sentences with violated constraints,as in the following examples:(3) a.Marie a emprunte?
tre`s long chemin unpour le retour.Mary took very long way a for the return.b.
Marie a emprunte?
un tre`s chemin pour le retour.Mary took a very way for the return.In (2a), 2 linear constraints are violated: a de-terminer follows a noun and an AP in ?tre`s longchemin un?.
Here are the figures calculated forthis NP:N+ N- E T W+ W- QI SR CC PI GI8 2 10 14 23 10 0.39 0.80 0.71 0.65 0.7161The QI indicator is very low, the violated con-straints being of heavy weight.
The grammatical-ity index is a little bit higher because a lot of con-straints are also satisfied.
The NP GI is then prop-agated to its dominating construction, the VP.
Thisphrase is well formed and also contains a well-formed construction (PP) as sister of the NP.
Notethat in the following table summarizing the VPindicators, the GI product of the embedded con-stituents is higher than the GI of the NP.
This isdue to the well-formed PP constituent.
In the end,the GI index of the VP is better than that of theill-formed NP:N+ N- E T W+ W- QI SR CC PI9 0 9 25 31 0 1 1 0.36 1.06GI Emb Const GI0.97 1.03For the same reasons, the higher level construc-tion S also compensates the bad score of the NP.However, in the end, the final GI of the sentenceis much lower than that of the corresponding well-formed sentence (see above).N+ N- E T W+ W- QI SR CC PI5 0 5 9 17 0 1 1 0.56 1.09GI Emb Const GI1.03 1.13The different figures of the sentence (2b) showthat the violation of a unique constraint (in thiscase the Oblig(Adj) indicating the absence of thehead in the AP) can lead to a global lower GI thanthe violation of two heavy constraints as for (2a).In this case, this is due to the fact that the AP onlycontains one constituent (a modifier) that does notsuffice to compensate the violated constraint.
Thefollowing table indicates the indices of the differ-ent phrases.
Note that in this table, each phrase isa constituent of the following (i.e.
AP belongs toNP itself belonging to VP, and so on).N+ N- E T W+ W- QI SR CC PIAP 2 1 3 7 7 3 0.40 0.67 0.43 0.56NP 10 0 10 14 33 0 1 1 0.71 1.12VP 9 0 9 25 31 0 1 1 0.36 1.06S 5 0 5 9 17 0 1 1 0.56 1.09GI Emb Const GIAP 1 0.56NP 0.56 0.63VP 0.93 0.99S 1.01 1.115 Judging acceptability of violationsWe ran a questionnaire study presenting partic-ipants with 60 experimental sentences like (11)to (55) below.
44 native speakers of Frenchcompleted the questionnaire giving acceptabilityjudgements following the Magnitude Estimationtechnique.
20 counterbalanced forms of the ques-tionnaire were constructed.
Three of the 60 ex-perimental sentences appeared in each version ineach form of the questionnaire, and across the 20forms, each experimental sentence appeared oncein each condition.
Each sentence was followedby a question concerning its acceptability.
These60 sentences were combined with 36 sentences ofvarious forms varying in complexity (simple mainclauses, simple embeddings and doubly nestedembeddings) and plausibility (from fully plausibleto fairly implausible according to the intuitions ofthe experimenters).
One randomization was madeof each form.Procedure: The rating technique used was mag-nitude estimation (ME, see (Bard96)).
Partici-pants were instructed to provide a numeric scorethat indicates how much better (or worse) the cur-rent sentence was compared to a given referencesentence (Example: If the reference sentence wasgiven the reference score of 100, judging a tar-get sentence five times better would result in 500,judging it five times worse in 20).
Judging the ac-ceptability ratio of a sentence in this way results ina scale which is open-ended on both sides.
It hasbeen demonstrated that ME is therefore more sen-sitive than fixed rating-scales, especially for scoresthat would approach the ends of such rating scales(cf.
(Bard96)).
Each questionnaire began with awritten instruction where the subject was made fa-miliar with the task based on two examples.
Afterthat subjects were presented with a reference sen-tence for which they had to provide a referencescore.
All following sentences had to be judgedin relation to the reference sentence.
Individualjudgements were logarithmized (to arrive at a lin-ear scale) and normed (z-standardized) before sta-tistical analyses.Global mean scores are presented figure 1.
Wetested the reliability of results for different ran-domly chosen subsets of the materials.
Construc-tions for which the judgements remain highly sta-ble across subsets of sentences are marked by anasterisk (rs > 0.90; p < 0.001).
The mean relia-bility across subsets is rs > 0.65 (p < 0.001).What we can see in these data is that in par-ticular violations within prepositional phrases arenot judged in a very stable way.
The way theyare judged appears to be highly dependent on thepreposition used and the syntactic/semantic con-text.
This is actually a very plausible result, giventhat heads of prepositional phrases are closed classitems that are much more predictable in many syn-tactic and semantic environments than heads of62noun phrases and verb phrases.
We will there-fore base our further analyses mainly on violationswithin noun phrases, verb phrases, and adjectivalphrases.
Results including prepositional phraseswill be given in parentheses.
Since the constraintsdescribed above do not make any predictions forsemantic violations, we excluded examples 25, 34,45, and 55 from further analyses.6 Acceptability versus grammaticalityindexWe compare in this section the results comingfrom the acceptability measurements described insection 5 and the values of grammaticality indicesobtained as proposed section 4.From the sample of 20 sentences presented in fig-ure 1, we have discarded 4 sentences, namely sen-tence 25, 34, 45 and 55, for which the propertyviolation is of semantic order (see above).
We areleft with 16 sentences, the reference sentence sat-isfying all the constraints and 15 sentences violat-ing one of the syntactic constraints.
The resultsare presented figure 2.
Acceptability judgment(ordinate) versus grammaticality index (abscissa)is plotted for each sentence.
We observe a highcoefficient of correlation (?
= 0.76) between thetwo distributions, indicating that the grammatical-ity index derived from PG is a fairly good tracer ofthe observed acceptability measurements.The main contribution to the grammaticality in-dex comes from the quality index QI (?
= 0.69)while the satisfaction ratio SR and the complete-No violations11.
Marie a emprunte?
un tre`s long chemin pour le retour 0.465NP-violations21.
Marie a emprunte?
tre`s long chemin un pour le retour -0.643 *22.
Marie a emprunte?
un tre`s long chemin chemin pour le retour -0.161 *23.
Marie a emprunte?
un tre`s long pour le retour -0.871 *24.
Marie a emprunte?
tre`s long chemin pour le retour -0.028 *25.
Marie a emprunte?
un tre`s heureux chemin pour le retour -0.196 *AP-violations31.
Marie a emprunte?
un long tre`s chemin pour le retour -0.41 *32.
Marie a emprunte?
un tre`s long long chemin pour le retour -0.216 -33.
Marie a emprunte?
un tre`s chemin pour le retour -0.619 -34.
Marie a emprunte?
un grossie`rement long chemin pour le retour -0.058 *PP-violations41.
Marie a emprunte?
un tre`s long chemin le retour pour -0.581 -42.
Marie a emprunte?
un tre`s long chemin pour pour le retour -0.078 -43.
Marie a emprunte?
un tre`s long chemin le retour -0.213 -44.
Marie a emprunte?
un tre`s long chemin pour -0.385 -45.
Marie a emprunte?
un tre`s long chemin dans le retour -0.415 -VP-violations51.
Marie un tre`s long chemin a emprunte?
pour le retour -0.56 *52.Marie a emprunte?
emprunte?
un tre`s long chemin pour le retour -0.194 *53.Marie un tre`s long chemin pour le retour -0.905 *54.
Marie emprunte?
un tre`s long chemin pour le retour -0.322 *55.
Marie a persuade?
un tre`s long chemin pour le retour -0.394 *Figure 1: Acceptability resultsness coefficient CC contributions, although signif-icant, are more modest (?
= 0.18 and ?
= 0.17respectively).We present in figure 3 the correlation betweenacceptability judgements and grammaticality in-dices after the removal of the 4 sentences pre-senting PP violations.
The analysis of the experi-ment described in section 5 shows indeed that ac-ceptability measurements of the PP-violation sen-tences is less reliable than for others phrases.
Wethus expect that removing these data from the sam-ple will strengthen the correlation between the twodistributions.
The coefficient of correlation of the12 remaining data jumps to ?
= 0.87, as expected.Figure 2: Correlation between acceptability judgement andgrammaticality indexFigure 3: Correlation between acceptability judgement andgrammaticality index removing PP violationsFinally, the adequacy of the PG grammatical-ity indices to the measurements was investigatedby means of resultant analysis.
We adapted theparameters of the model in order to arrive at agood fit based on half of the sentences materials(randomly chosen from the full set), with a cor-relation of ?
= 0.85 (?
= 0.76 including PPs)between the grammaticality index and acceptabil-ity judgements.
Surprisingly, we arrived at thebest fit with only two different weights: A weightof 2 for Exclusion, Uniqueness, and Requirement,and a weight of 5 for Obligation, Linearity, andConstituency.
This result converges with the hard63and soft constraint repartition idea as proposed by(Keller00).The fact that the grammaticality index is basedon these properties as well as on the number ofconstraints to be evaluated, the number of con-straints to the satisfied, and the goodness of em-bedded constituents apparently results in a finedgrained and highly adequate prediction even withthis very basic distinction of constraints.Fixing these parameters, we validated the pre-dictions of the model for the remaining half of thematerials.
Here we arrived at a highly reliable cor-relation of ?
= 0.86 (?
= 0.67 including PPs) be-tween PG grammaticality indices and acceptabil-ity judgements.7 ConclusionThe method described in this paper makes it pos-sible to give a quantified indication of sentencegrammaticality.
This approach is direct and takesadvantage of a constraint-based representation ofsyntactic information, making it possible to repre-sent precisely the syntactic characteristics of an in-put in terms of satisfied and (if any) violated con-straints.
The notion of grammaticality index wehave proposed here integrates different kind of in-formation: the quality of the description (in termsof well-formedness degree), the density of infor-mation (the quantity of constraints describing anelement) as well as the structure itself.
These threeparameters are the basic indicators of the gram-maticality index.The relevance of this method has been ex-perimentally shown, and the results described inthis paper illustrate the correlation existing be-tween the prediction (automatically calculated)expressed in terms of GI and the acceptabilityjudgment given by subjects.This approach also presents a practical interest:it can be directly implemented into a parser.
Thenext step of our work will be its validation on largecorpora.
Our parser will associate a grammaticalindex to each sentence.
This information will bevalidated by means of acceptability judgments ac-quired on the basis of a sparse sampling strategy.ReferencesBard E., D. Robertson & A. Sorace (1996) ?MagnitudeEstimation of Linguistic Acceptability?, Language72:1.Blache P. & J.-P. Prost (2005) ?Gradience, Construc-tions and Constraint Systems?, in H. Christiansen &al.
(eds), Constraint Solving and NLP, Lecture Notesin Computer Science, Springer.Blache P. (2005) ?Property Grammars: A FullyConstraint-Based Theory?, in H. Christiansen & al.
(eds), Constraint Solving and NLP, Lecture Notes inComputer Science, Springer.Blache P. (2006) ?A Robust and Efficient Parser forNon-Canonical Inputs?, in proceedings of RobustMethods in Analysis of Natural Language Data,EACL workshop.Chomsky N.. (1975) The Logical Structure of Linguis-tic Theory, Plenum PressCroft W. & D. Cruse (2003) Cognitive Linguistics,Cambridge University Press.Foth K., M. Daum & W. Menzel (2005) ?Parsing Unre-stricted German Text with Defeasible Constraints?,in H. Christiansen & al.
(eds), Constraint Solv-ing and NLP, Lecture Notes in Computer Science,Springer.Fillmore C. (1998) ?Inversion and Contructional In-heritance?, in Lexical and Constructional Aspects ofLinguistic Explanation, Stanford University.Kay P. & C. Fillmore (1999) ?Grammatical Construc-tions and Linguistic Generalizations: the what?s xdoing y construction?, Language.Keller F. (2000) Gradience in Grammar.
Experimentaland Computational Aspects of Degrees of Grammat-icality, Phd Thesis, University of Edinburgh.Keller F. (2003) ?A probabilistic Parser as a Modelof Global Processing Difficulty?, in proceedings ofACCSS-03Menzel W. & I. Schroder (1998) ?Decision proceduresfor dependency parsing using graded constraints?,in S. Kahane & A. Polgue`re (eds), Proc.
Colin-gACL Workshop on Processing of Dependency-based Grammars.Prince A.
& Smolensky P. (1993) Optimality The-ory: Constraint Interaction in Generative Gram-mars, Technical Report RUCCS TR-2, Rutgers Cen-ter for Cognitive Science.Sag I., T. Wasow & E. Bender (2003) Syntactic Theory.A Formal Introduction, CSLI.Schro?der I.
(2002) Natural Language Parsing withGraded Constraints.
PhD Thesis, University ofHamburg.Sorace A.
& F. Keller (2005) ?Gradience in LinguisticData?, in Lingua, 115.64
