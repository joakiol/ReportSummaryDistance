Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 71?78,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsAn Unsupervised Model for Text Message NormalizationPaul CookDepartment of Computer ScienceUniversity of TorontoToronto, Canadapcook@cs.toronto.eduSuzanne StevensonDepartment of Computer ScienceUniversity of TorontoToronto, Canadasuzanne@cs.toronto.eduAbstractCell phone text messaging users express them-selves briefly and colloquially using a varietyof creative forms.
We analyze a sample of cre-ative, non-standard text message word formsto determine frequent word formation pro-cesses in texting language.
Drawing on theseobservations, we construct an unsupervisednoisy-channel model for text message normal-ization.
On a test set of 303 text messageforms that differ from their standard form, ourmodel achieves 59% accuracy, which is on parwith the best supervised results reported onthis dataset.1 Text MessagingCell phone text messages?or SMS?contain manyshortened and non-standard forms due to a varietyof factors, particularly the desire for rapid text entry(Grinter and Eldridge, 2001; Thurlow, 2003).1 Fur-thermore, text messages are written in an informalregister; non-standard forms are used to reflect this,and even for personal style (Thurlow, 2003).
Thesefactors result in tremendous linguistic creativity, andhence many novel lexical items, in the language oftext messaging, or texting language.Normalization of non-standard forms?converting non-standard forms to their standardforms?is a challenge that must be tackled beforeother types of natural language processing cantake place (Sproat et al, 2001).
In the case oftext messages, text-to-speech synthesis may be1The number of characters in a text message may also belimited to 160 characters, although this is not always the case.particularly useful for the visually impaired; au-tomatic translation has also been considered (e.g.,Aw et al, 2006).
For texting language, given theabundance of creative forms, and the wide-rangingpossibilities for creating new forms, normalizationis a particularly important problem, and has indeedreceived some attention in computational linguistics(e.g., Aw et al, 2006; Choudhury et al, 2007;Kobus et al, 2008).In this paper we propose an unsupervised noisychannel method for texting language normalization,that gives performance on par with that of a super-vised system.
We pursue unsupervised approachesto this problem, as large collections of text mes-sages, and their corresponding standard forms, arenot readily available.2 Furthermore, other forms ofcomputer-mediated communication, such as Inter-net messaging, exhibit creative phenomena similarto text messaging, although at a lower frequency(Ling and Baron, 2007).
Moreover, technologicalchanges, such as new input devices, are likely tohave an impact on the language of such media (Thur-low, 2003).3 An unsupervised approach, drawingon linguistic properties of creative word formations,has the potential to be adapted for normalization oftext in other similar genres?such as Internet dis-cussion forums?without the cost of developing alarge training corpus.
Moreover, normalization maybe particularly important for such genres, given the2One notable exception is Fairon and Paumier (2006), al-though this resource is in French.
The resource used in ourstudy, Choudhury et al (2007), is quite small in comparison.3The rise of other technology, such as word prediction, couldreduce the use of abbreviations, although it?s not clear suchtechnology is widely used (Grinter and Eldridge, 2001).71Formation type Freq.
ExampleStylistic variation 152 betta (better)Subseq.
abbrev.
111 dng (doing)Prefix clipping 24 hol (holiday)Syll.
letter/digit 19 neway (anyway)G-clipping 14 talkin (talking)Phonetic abbrev.
12 cuz (because)H-clipping 10 ello (hello)Spelling error 5 darliog (darling)Suffix clipping 4 morrow (tomorrow)Punctuation 3 b/day (birthday)Unclear 34 mobs (mobile)Error 12 gal (*girl)Total 400Table 1: Frequency of texting forms in the developmentset by formation type.need for applications such as translation and ques-tion answering.We observe that many creative texting forms arethe result of a small number of specific word for-mation processes.
Rather than using a generic er-ror model to capture all of them, we propose a mix-ture model in which each word formation process ismodeled explicitly according to linguistic observa-tions specific to that formation.2 Analysis of Texting FormsTo better understand the creative processes presentin texting language, we categorize the word forma-tion process of each texting form in our developmentdata, which consists of 400 texting forms paired withtheir standard forms.4 Several iterations of catego-rization were done in order to determine sensiblecategories, and ensure categories were used consis-tently.
Since this data is only to be used to guidethe construction of our system, and not for formalevaluation, only one judge (a native English speak-ing author of this paper) categorized the expressions.The findings are presented in Table 1.Stylistic variations, by far the most frequent cat-egory, exhibit non-standard spelling, such as repre-4Most texting forms have a unique standard form; however,some have multiple standard forms, e.g., will and well can bothbe shortened to wl.
In such cases we choose the category of themost frequent standard form; in the case of frequency ties wechoose arbitrarily among the categories of the standard forms.senting sounds phonetically.
Subsequence abbrevi-ations, also very frequent, are composed of a sub-sequence of the graphemes in a standard form, of-ten omitting vowels.
These two formation types ac-count for approximately 66% of our developmentdata; the remaining formation types are much lessfrequent.
Prefix clippings and suffix clippings con-sist of a prefix or suffix, respectively, of a standardform, and in some cases a diminutive ending; wealso consider clippings which omit just a g or h froma standard form as they are rather frequent.5 A sin-gle letter or digit can be used to represent a syllable;we refer to these as syllabic (syll.)
letter/digit.
Pho-netic abbreviations are variants of clippings and sub-sequence abbreviations where some sounds in thestandard form are represented phonetically.
Severaltexting forms appear to be spelling errors; we tookthe layout of letters on cell phone keypads into ac-count when making this judgement.
The items thatdid not fit within the above texting form categorieswere marked as unclear.
Finally, for some expres-sions the given standard form did not appear to beappropriate.
For example, girl is not the standardform for the texting form gal; rather, gal is an En-glish word that is a colloquial form of girl.
Suchcases were marked as errors.No texting forms in our development data corre-spond to multiple standard form words, e.g., wannafor want to.6 Since such forms are not present in ourdevelopment data, we assume that a texting form al-ways corresponds to a single standard form word.It is important to note that some text forms haveproperties of multiple categories, e.g., bak (back)could be considered a stylistic variation or a subse-quence abbreviation.
In such cases, we simply at-tempt to assign the most appropriate category.The design of our model for text message normal-ization, presented below, uses properties of the ob-served formation processes.3 An Unsupervised Noisy Channel Modelfor Text Message NormalizationLet S be a sentence consisting of standard formss1s2...sn; in this study the standard forms are reg-5Thurlow (2003) also observes an abundance of g-clippings.6A small number of similar forms, however, appear with asingle standard form word, and are therefore marked as errors.72ular English words.
Let T be a sequence of textingforms t1t2...tn, which are the texting language real-ization of the standard forms, and may differ fromthe standard forms.
Given a sequence of textingforms T , the challenge is then to determine the cor-responding standard forms S.Following Choudhury et al (2007)?and vari-ous approaches to spelling error correction, suchas, e.g., Mays et al (1991)?we model text mes-sage normalization using a noisy channel.
Wewant to find argmaxSP (S|T ).
We apply Bayesrule and ignore the constant term P (T ), givingargmaxSP (T |S)P (S).
Making the independenceassumption that each ti depends only on si, and noton the context in which it occurs, as in Choudhuryet al, we express P (T |S) as a product of probabili-ties: argmaxS (?i P (ti|si))P (S).We note in Section 2 that many texting forms arecreated through a small number of specific word for-mation processes.
Rather than model each of theseprocesses at once using a generic model for P (ti|si),as in Choudhury et al, we instead create several suchmodels, each corresponding to one of the observedcommon word formation processes.
We thereforerewrite P (ti|si) as ?wf P (ti|si,wf )P (wf) wherewf is a word formation process, e.g., subsequenceabbreviation.
Since, like Choudhury et al, we focuson the word model, we simplify our model as below.argmaxsi?wfP (ti|si,wf )P (wf )P (si)We next explain the components of the model,P (ti|si,wf ), P (wf ), and P (si), referred to as theword model, word formation prior, and languagemodel, respectively.3.1 Word ModelsWe now consider which of the word formation pro-cesses discussed in Section 2 should be capturedwith a word model P (ti|si,wf ).
We model stylis-tic variations and subsequence abbreviations simplydue to their frequency.
We also choose to modelprefix clippings since this word formation process iscommon outside of text messaging (Kreidler, 1979;Algeo, 1991) and fairly frequent in our data.
Al-though g-clippings and h-clippings are moderatelyfrequent, we do not model them, as these very spe-cific word formations are also (non-prototypical)graphemes w i th ou tphonemes w I T au tTable 2: Grapheme?phoneme alignment for without.subsequence abbreviations.
We do not model syl-labic letters and digits, or punctuation, explicitly; in-stead, we simply substitute digits with a graphemicrepresentation (e.g., 4 is replaced by for), and re-move punctuation, before applying the model.
Theother less frequent formations?phonetic abbrevia-tions, spelling errors, and suffix clippings?are notmodeled; we hypothesize that the similarity of theseformation processes to those we do model will allowthe system to perform reasonably well on them.3.1.1 Stylistic VariationsWe propose a probabilistic version of edit-distance?referred to here as edit-probability?inspired by Brill and Moore (2000) to modelP (ti|si, stylistic variation).
To compute edit-probability, we consider the probability of each editoperation?substitution, insertion, and deletion?instead of its cost, as in edit-distance.
We then sim-ply multiply the probabilities of edits as opposed tosumming their costs.In this version of edit-probability, we allow two-character edits.
Ideally, we would compute the edit-probability of two strings as the sum of the edit-probability of each partitioning of those strings intoone or two character segments.
However, followingBrill and Moore, we approximate this by the prob-ability of the partition with maximum probability.This allows us to compute edit-probability using asimple adaptation of edit-distance, in which we con-sider edit operations spanning two characters at eachcell in the chart maintained by the algorithm.We then estimate two probabilities: P (gt|gs, pos)is the probability of texting form grapheme gt givenstandard form grapheme gs at position pos , wherepos is the beginning, middle, or end of the word;P (ht|ps, hs, pos) is the probability of texting formgraphemes ht given the standard form phonemes psand graphemes hs at position pos .
ht, ps, and hs canbe a single grapheme or phoneme, or a bigram.We compute edit-probability between thegraphemes of si and ti.
When filling each cellin the chart, we consider edit operations between73segments of si and ti of length 0?2, referred to as aand b, respectively.
If a aligns with phonemes in si,we also consider those phonemes, p. In our lexicon,the graphemes and phonemes of each word arealigned according to the method of Jiampojamarnet al (2007).
For example, the alignment forwithout is given in Table 2.
The probability ofeach edit operation is then determined by threeproperties?the length of a, whether a aligns withany phonemes in si, and if so, p?as shown below:|a|= 0 or 1, not aligned w/ si phonemes: P (b|a, pos)|a|= 2, not aligned w/ si phonemes: 0|a|= 1 or 2, aligned w/ si phonemes: P (b|p, a, pos)3.1.2 Subsequence AbbreviationsWe model subsequence abbreviations accordingto the equation below:P (ti|si, subseq abrv) ={c if ti is a subseq of si0 otherwisewhere c is a constant.Note that this is similar to the error model forspelling correction presented by Mays et al (1991),in which all words (in our terms, all si) withina specified edit-distance of the out-of-vocabularyword (ti in our model) are given equal probability.The key difference is that in our formulation, weonly consider standard forms for which the textingform is potentially a subsequence abbreviation.In combination with the language model,P (ti|si, subseq abbrev) assigns a non-zero prob-ability to each standard form si for which ti isa subsequence, according to the likelihood of si(under the language model).
The models interactin this way since we expect a standard form to berecognizable relative to the other words for which ticould be a subsequence abbreviation3.1.3 Prefix ClippingsWe model prefix clippings similarly to subse-quence abbreviations.P (ti|si, prefix clipping) =????
?c if ti is possiblepre.
clip.
of si0 otherwiseKreidler (1979) observes that clippings tend to bemono-syllabic and end in a consonant.
Further-more, when they do end in a vowel, it is oftenof a regular form, such as telly for television andbreaky for breakfast.
We therefore only considerP (ti|si, prefix clipping) if ti is a prefix clipping ac-cording to the following heuristics: ti is mono-syllabic after stripping any word-final vowels, andsubsequently removing duplicated word-final con-sonants (e.g, telly becomes tel, which is a candidateprefix clipping).
If ti is not a prefix clipping accord-ing to these criteria, P (ti|si) simply sums over allmodels except prefix clipping.3.2 Word Formation PriorKeeping with our goal of an unsupervised method,we estimate P (wf ) with a uniform distribution.
Wealso consider estimating P (wf ) using maximumlikelihood estimates (MLEs) from our observationsin Section 2.
This gives a model that is not fullyunsupervised, since it relies on labelled trainingdata.
However, we consider this a lightly-supervisedmethod, since it only requires an estimate of the fre-quency of the relevant word formation types, and notlabelled texting form?standard form pairs.3.3 Language ModelChoudhury et al (2007) find that using a bigram lan-guage model estimated over a balanced corpus ofEnglish had a negative effect on their results com-pared with a unigram language model, which theyattribute to the unique characteristics of text messag-ing that were not reflected in the corpus.
We there-fore use a unigram language model for P (si), whichalso enables comparison with their results.
Never-theless, alternative language models, such as higherorder ngram models, could easily be used in place ofour unigram language model.4 Materials and Methods4.1 DatasetsWe use the data provided by Choudhury et al (2007)which consists of texting forms?extracted from acollection of 900 text messages?and their manu-ally determined standard forms.
Our developmentdata?used for model development and discussed inSection 2?consists of the 400 texting form typesthat are not in Choudhury et al?s held-out test set,and that are not the same as one of their standard74forms.
The test data consists of 1213 texting formsand their corresponding standard forms.
A subset of303 of these texting forms differ from their standardform.7 This subset is the focus of this study, but wealso report results on the full dataset.4.2 LexiconWe construct a lexicon of potential standard formssuch that it contains most words that we expect toencounter in text messages, yet is not so large asto make it difficult to identify the correct standardform.
Our subjective analysis of the standard formsin the development data is that they are frequent,non-specialized, words.
To reflect this observation,we create a lexicon consisting of all single-word en-tries containing only alphabetic characters found inboth the CELEX Lexical Database (Baayen et al,1995) and the CMU Pronouncing Dictionary.8 Weremove all words of length one (except a and I) toavoid choosing, e.g., the letter r as the standard formfor the texting form r. We further limit the lexiconto words in the 20K most frequent alphabetic uni-grams, ignoring case, in the Web 1T 5-gram Corpus(Brants and Franz, 2006).
The resulting lexicon con-tains approximately 14K words, and excludes onlythree of the standard forms?cannot, email, and on-line?for the 400 development texting forms.4.3 Model Parameter EstimationMLEs for P (gt|gs, pos)?needed to estimateP (ti|si, stylistic variation)?could be estimatedfrom texting form?standard form pairs.
However,since our system is unsupervised, no such data isavailable.
We therefore assume that many textingforms, and other similar creative shortenings, occuron the web.
We develop a number of charactersubstitution rules, e.g., s?
z, and use them to createhypothetical texting forms from standard words.We then compute MLEs for P (gt|gs, pos) using thefrequencies of these derived forms on the web.7Choudhury et al report that this dataset contains 1228 tex-ting forms.
We found it to contain 1213 texting forms cor-responding to 1228 standard forms (recall that a texting formmay have multiple standard forms).
There were similar incon-sistencies with the subset of texting forms that differ from theirstandard forms.
Nevertheless, we do not expect these small dif-ferences to have an appreciable effect on the results.8http://www.speech.cs.cmu.edu/cgi-bin/cmudictWe create the substitution rules by examining ex-amples in the development data, considering fastspeech variants and dialectal differences (e.g., voic-ing), and drawing on our intuition.
The derivedforms are produced by applying the substitutionrules to the words in our lexicon.
To avoid con-sidering forms that are themselves words, we elimi-nate any form found in a list of approximately 480Kwords taken from SOWPODS9 and the Moby WordLists.10 Finally, we obtain the frequency of the de-rived forms from the Web 1T 5-gram Corpus.To estimate P (ht|ps, hs, pos), we first esti-mate two simpler distributions: P (ht|hs, pos) andP (ht|ps, pos).
P (ht|hs, pos) is estimated in thesame manner as P (gt|gs, pos), except that two char-acter substitutions are allowed.
P (ht|ps, pos) is es-timated from the frequency of ps, and its align-ment with ht, in a version of CELEX in whichthe graphemic and phonemic representation of eachword is many?many aligned using the method ofJiampojamarn et al (2007).11 P (ht|ps, hs, pos)is then an evenly-weighted linear combination ofP (ht|hs, pos) and P (ht|ps, pos).
Finally, wesmooth each of P (gt|gs, pos) and P (ht|ps, hs, pos)using add-alpha smoothing.We set the constant c in our word models forsubsequence abbreviations and prefix clippings suchthat?si P (ti|si,wf )P (si) = 1.
We similarly nor-malize P (ti|si, stylistic variation)P (si).We use the frequency of unigrams (ignoring case)in the Web 1T 5-gram Corpus to estimate our lan-guage model.
We expect the language of text mes-saging to be more similar to that found on the webthan that in a balanced corpus of English.4.4 Evaluation MetricsTo evaluate our system, we consider three accuracymetrics: in-top-1, in-top-10, and in-top-20.12 In-top-n considers the system correct if a correct stan-dard form is in the n most probable standard forms.The in-top-1 accuracy shows how well the systemdetermines the correct standard form; the in-top-109http://en.wikipedia.org/wiki/SOWPODS10http://icon.shef.ac.uk/Moby/11We are very grateful to Sittichai Jiampojamarn for provid-ing this alignment.12These are the same metrics used by Choudhury et al(2007), although we refer to them by different names.75Model % accuracyTop-1 Top-10 Top-20Uniform 59.4 83.8 87.8MLE 55.4 84.2 86.5Choudhury et al 59.9 84.3 88.7Table 3: % in-top-1, in-top-10, and in-top-20 accuracyon test data using both estimates for P (wf ).
The resultsreported by Choudhury et al (2007) are also shown.and in-top-20 accuracies may be indicative of theusefulness of the output of our system in other taskswhich could exploit a ranked list of standard forms,such as machine translation.5 Results and DiscussionIn Table 3 we report the results of our system usingboth the uniform estimate and the MLE of P (wf ).Note that there is no meaningful random baselineto compare against here; randomly ordering the14K words in our lexicon gives very low accuracy.The results using the uniform estimate of P (wf )?a fully unsupervised system?are very similar tothe supervised results of Choudhury et al (2007).Surprisingly, when we estimate P (wf ) using MLEsfrom the development data?resulting in a lightly-supervised system?the results are slightly worsethan when using the uniform estimate of this proba-bility.
Moreover, we observe the same trend on de-velopment data where we expect to have an accurateestimate of P (wf ) (results not shown).
We hypothe-size that the ambiguity of the categories of text forms(see Section 2) results in poor MLEs for P (wf ),thus making a uniform distribution, and hence fully-unsupervised approach, more appropriate.Results by Formation Type We now consider in-top-1 accuracy for each word formation type, in Ta-ble 4.
We show results for the same word forma-tion processes as in Table 1, except for h-clippingsand punctuation, as no words of these categories arepresent in the test data.
We present results using thesame experimental setup as before with a uniformestimate of P (wf ) (All), and using just the modelcorresponding to the word formation process (Spe-cific), where applicable.1313In this case our model then becomes, for each word forma-tion process wf , argmaxsiP (ti|si,wf )P (si).Formation type Freq.
% in-top-1 acc.n = 303 Specific AllStylistic variation 121 62.8 67.8Subseq.
abbrev.
65 56.9 46.2Prefix clipping 25 44.0 20.0G-clipping 56 - 91.1Syll.
letter/digit 16 - 50.0Unclear 12 - 0.0Spelling error 5 - 80.0Suffix clipping 1 - 0.0Phonetic abbrev.
1 - 0.0Error 1 - 0.0Table 4: Frequency (Freq.
), and % in-top-1 accuracy us-ing the formation-specific model where applicable (Spe-cific) and all models (All) with a uniform estimate forP (wf ), presented by formation type.We first examine the top panel of Table 3 wherewe compare the performance on each word forma-tion type for both experimental conditions (Specificand All).
We first note that the performance usingthe formation-specific model on subsequence abbre-viations and prefix clippings is better than that ofthe overall model.
This is unsurprising since we ex-pect that when we know a texting form?s formationprocess, and invoke a corresponding specific model,our system should outperform a model designed tohandle a range of formation types.
However, this isnot the case for stylistic variations; here the over-all model performs better than the specific model.We observed in Section 2 that some texting formsdo not fit neatly into our categorization scheme; in-deed, many stylistic variations are also analyzableas subsequence abbreviations.
Therefore, the subse-quence abbreviation model may benefit normaliza-tion of stylistic variations.
This model, used in iso-lation on stylistic variations, gives an in-top-1 accu-racy of 33.1%, indicating that this may be the case.Comparing the performance of the individualword models on only word types that they were de-signed for (column Specific in Table 4), we see thatthe prefix clipping model is by far the lowest, in-dicating that in the future we should consider waysof improving this word model.
One possibility isto incorporate phonemic knowledge.
For example,both friday and friend have the same probability un-76der P (ti|si, prefix clipping) for the texting form fri,which has the standard form friday in our data.
(Thelanguage model, however, does distinguish betweenthese forms.)
However, if we consider the phonemicrepresentations of these words, friday might emergeas more likely.
Syllable structure information mayalso be useful, as we hypothesize that clippings willtend to be formed by truncating a word at a syllableboundary.
We may similarly be able to improve ourestimate of P (ti|si, subseq.
abrrev.).
For example,both text and taxation have the same probability un-der this distribution, but intuitively text, the correctstandard form in our data, seems more likely.
Wecould incorporate knowledge about the likelihood ofomitting specific characters, as in Choudhury et al(2007), to improve this estimate.We now examine the lower panel of Table 4, inwhich we consider the performance of the overallmodel on the word formation types that are not ex-plicitly modeled.
The very high accuracy on g-clippings indicates that since these forms are also atype of subsequence abbreviation, we do not need toconstruct a separate model for them.
We in fact alsoconducted experiments in which g-clippings and h-clippings were modeled explicitly, but found theseextra models to have little effect on the results.Recall from Section 3.1 our hypothesis that suf-fix clippings, spelling errors, and phonetic abbrevia-tions have common properties with formation typesthat we do model, and therefore the system will per-form reasonably well on them.
Here we find pre-liminary evidence to support this hypothesis as theaccuracy on these three word formation types (com-bined) is 57.1%.
However, we must interpret thisresult cautiously as it only considers seven expres-sions.
On the syllabic letter and digit texting formsthe accuracy is 50.0%, indicating that our heuris-tic to replace digits in texting forms with an ortho-graphic representation is reasonable.The performance on types of expressions thatwe did not consider when designing the system?unclear and error?is very poor.
However, this haslittle impact on the overall performance as these ex-pressions are rather infrequent.Results by Model We now consider in-top-1 ac-curacy using each model on the 303 test expres-sions; results are shown in Table 5.
No model on itsModel % in-top-1 accuracyStylistic variation 51.8Subseq.
Abbrev.
44.2Prefix clipping 10.6Table 5: % in-top-1 accuracy on the 303 test expressionsusing each model individually.own gives results comparable to those of the over-all model (59.4%, see Table 3).
This indicates thatthe overall model successfully combines informa-tion from the specific word formation models.Each model used on its own gives an accuracygreater than the proportion of expressions of theword formation type for which the model was de-signed (compare accuracies in Table 5 to the num-ber of expressions of the corresponding word forma-tion type in the test data in Table 4).
As we note inSection 2, the distinctions between the word forma-tion types are not sharp; these results show that theshared properties of word formation types enable amodel for a specific formation type to infer the stan-dard form of texting forms of other formation types.All Unseen Data Until now we have discussed re-sults on our test data of 303 texting forms which dif-fer from their standard forms.
We now consider theperformance of our system on all 1213 unseen tex-ting forms, 910 of which are identical to their stan-dard form.
Since our model was not designed withsuch expressions in mind, we slightly adapt it forthis new task; if ti is in our lexicon, we return thatform as si, otherwise we apply our model as usual,using the uniform estimate of P (wf ).
This givesan in-top-1 accuracy of 88.2%, which is very sim-ilar to the results of Choudhury et al (2007) on thisdata of 89.1%.
Note, however, that Choudhury et alonly report results on this dataset using a uniformlanguage model;14 since we use a unigram languagemodel, it is difficult to draw firm conclusions aboutthe performance of our system relative to theirs.6 Related WorkAw et al (2006) model text message normaliza-tion as translation from the texting language into the14Choudhury et al do use a unigram language model for theirexperiments on the 303 texting forms which differ from theirstandard forms (see Section 3.3).77standard language.
Kobus et al (2008) incorporateideas from both machine translation and automaticspeech recognition for text message normalization.However, both of these approaches are supervised,and have only limited means for normalizing textingforms that do not occur in the training data.Our work, like that of Choudhury et al (2007),can be viewed as a noisy-channel model for spellingerror correction (e.g., Mays et al, 1991; Brill andMoore, 2000), in which texting forms are seen asa kind of spelling error.
Furthermore, like our ap-proach to text message normalization, approaches tospelling correction have incorporated phonemic in-formation (Toutanova and Moore, 2002).The word model of the supervised approach ofChoudhury et al consists of hidden Markov models,which capture properties of texting language similarto those of our stylistic variation model.
We pro-pose multiple word models?corresponding to fre-quent texting language formation processes?and anunsupervised method for parameter estimation.7 ConclusionsWe analyze a sample of texting forms to determinefrequent word formation processes in creative tex-ting language.
Drawing on these observations, weconstruct an unsupervised noisy-channel model fortext message normalization.
On an unseen test setof 303 texting forms that differ from their standardform, our model achieves 59% accuracy, which is onpar with that obtained by the supervised approach ofChoudhury et al (2007) on the same data.More research is required to determine the impactof our normalization method on the performance ofa system that further processes the resulting text.
Inthe future, we intend to improve our word models byincorporating additional linguistic knowledge, suchas information about syllable structure.
Since con-text likely plays a role in human interpretation oftexting forms, we also intend to examine the perfor-mance of higher order ngram language models.AcknowledgementsThis work is financially supported by the Natu-ral Sciences and Engineering Research Council ofCanada, the University of Toronto, and the Dictio-nary Society of North America.ReferencesJohn Algeo, editor.
1991.
Fifty Years Among the NewWords.
Cambridge University Press, Cambridge.AiTi Aw, Min Zhang, Juan Xiao, and Jian Su.
2006.
Aphrase-based statistical model for SMS text normaliza-tion.
In Proc.
of the COLING/ACL 2006 Main Confer-ence Poster Sessions, pages 33?40.
Sydney.R.H.
Baayen, R. Piepenbrock, and L. Gulikers.
1995.
TheCELEX Lexical Database (release 2).
Linguistic DataConsortium, University of Pennsylvania.Thorsten Brants and Alex Franz.
2006.
Web 1T 5-gramCorpus version 1.1.Eric Brill and Robert C. Moore.
2000.
An improved errormodel for noisy channel spelling correction.
In Pro-ceedings of ACL 2000, pages 286?293.
Hong Kong.Monojit Choudhury, Rahul Saraf, Vijit Jain, AnimeshMukherjee, Sudeshna Sarkar, and Anupam Basu.2007.
Investigation and modeling of the structure oftexting language.
International Journal of DocumentAnalysis and Recognition, 10(3/4):157?174.Ce?drick Fairon and Se?bastien Paumier.
2006.
A trans-lated corpus of 30,000 French SMS.
In Proceedings ofLREC 2006.
Genoa, Italy.Rebecca E. Grinter and Margery A. Eldridge.
2001. y dotngrs luv 2 txt msg.
In Proceedings of the 7th Euro-pean Conf.
on Computer-Supported Cooperative Work(ECSCW ?01), pages 219?238.
Bonn, Germany.Sittichai Jiampojamarn, Gregorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignments andhidden markov models to letter-to-phoneme conver-sion.
In Proc.
of NAACL-HLT 2007, pages 372?379.Rochester, NY.Catherine Kobus, Franc?ois Yvon, and Ge?raldineDamnati.
2008.
Normalizing SMS: are two metaphorsbetter than one?
In Proc.
of the 22nd Int.
Conf.
onComputational Linguistics, pp.
441?448.
Manchester.Charles W. Kreidler.
1979.
Creating new words by short-ening.
English Linguistics, 13:24?36.Rich Ling and Naomi S. Baron.
2007.
Text messagingand IM: Linguistic comparison of American collegedata.
Journal of Language and Social Psychology,26:291?98.Eric Mays, Fred J. Damerau, and Robert L. Mercer.
1991.Context based spelling correction.
Information Pro-cessing and Management, 27(5):517?522.Richard Sproat, Alan W. Black, Stanley Chen, ShankarKumar, Mari Ostendorf, and Christopher Richards.2001.
Normalization of non-standard words.
Com-puter Speech and Language, 15:287?333.Crispin Thurlow.
2003.
Generation txt?
The sociolin-guistics of young people?s text-messaging.
DiscourseAnalysis Online, 1(1).Kristina Toutanova and Robert C. Moore.
2002.
Pronun-ciation modeling for improved spelling correction.
InProc.
of ACL 2002, pages 144?151.
Philadelphia.78
