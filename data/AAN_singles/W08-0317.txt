Proceedings of the Third Workshop on Statistical Machine Translation, pages 135?138,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsEffects of Morphological Analysis in Translation between German andEnglishSara Stymne, Maria Holmqvist and Lars AhrenbergDepartment of Computer and Information ScienceLinko?ping University, Sweden{sarst,marho,lah}@ida.liu.seAbstractWe describe the LIU systems for German-English and English-German translation sub-mitted to the Shared Task of the Third Work-shop of Statistical Machine Translation.
Themain features of the systems, as comparedwith the baseline, is the use of morphologi-cal pre- and post-processing, and a sequencemodel for German using morphologically richparts-of-speech.
It is shown that these addi-tions lead to improved translations.1 IntroductionResearch in statistical machine translation (SMT)increasingly makes use of linguistic analysis in orderto improve performance.
By including abstract cat-egories, such as lemmas and parts-of-speech (POS),in the models, it is argued that systems can becomebetter at handling sentences for which training dataat the word level is sparse.
Such categories can beintegrated in the statistical framework using factoredmodels (Koehn et al, 2007).
Furthermore, by pars-ing input sentences and restructuring based on theresult to narrow the structural difference betweensource and target language, the current phrase-basedmodels can be used more effectively (Collins et al,2005).German differs structurally from English in sev-eral respects (see e.g.
Collins et al, 2005).
In thiswork we wanted to look at one particular aspectof restructuring, namely splitting of German com-pounds, and evaluate its effect in both translation di-rections, thus extending the initial experiments re-ported in Holmqvist et al (2007).
In addition, sinceGerman is much richer in morphology than English,we wanted to test the effects of using a sequencemodel for German based on morphologically sub-categorized parts-of-speech.
All systems have beenspecified as extensions of the Moses system pro-vided for the Shared Task.2 Part-of-speech and MorphologyFor both English and German we used the part-of-speech tagger TreeTagger (Schmid, 1994) to obtainPOS-tags.The German POS-tags from TreeTagger were re-fined by adding morphological information froma commercial dependency parser, including case,number, gender, definiteness, and person for nouns,pronouns, verbs, adjectives and determiners in thecases where both tools agreed on the POS-tag.
Ifthey did not agree, the POS-tag from TreeTaggerwas chosen.
This tag set seemed more suitable forSMT, with tags for proper names and foreign wordswhich the commercial parser does not have.3 Compound AnalysisCompounding is common in many languages, in-cluding German.
Since compounding is highly pro-ductive it increases vocabulary size and leads tosparse data problems.Compounds in German are formed by joiningwords, and in addition filler letters can be insertedor letters can be removed from the end of all but thelast word of the compound (Langer, 1998).
We havechosen to allow simple additions of letter(s) (-s, -n,-en, -nen, -es, -er, -ien) and simple truncations (-e,135-en, -n).
Example of compounds with additions andtruncations can be seen in (1).
(1) a. Staatsfeind (Staat + Feind)public enemyb.
Kirchhof (Kirche + Hof)graveyard3.1 Splitting compoundsNoun and adjective compounds are split by a mod-ified version of the corpus-based method presentedby Koehn and Knight (2003).
First the German lan-guage model data is POS-tagged and used to calcu-late frequencies of all nouns, verbs, adjectives, ad-verbs and the negative particle.
Then, for each nounand adjective all splits into these known words fromthe corpus, allowing filler additions and truncations,are considered, choosing the splitting option withthe highest arithmetic mean1 of the frequencies ofits parts.A length limit of each part was set to 4 charac-ters.
For adjectives we restrict the number of partsto maximum two, since they do not tend to havemultiple parts as often as nouns.
In addition weadded a stop list with 14 parts, often mistagged, thatgave rise to wrong adjective splits, such as arische(?Aryan?)
in konsularische (?consular?
).As Koehn and Knight (2003) points out, parts ofcompounds do not always have the same meaningas when they stand alone, e.g.
Grundrechte (?basicrights?
), where the first part, Grund, usually trans-lates as foundation, which is wrong in this com-pound.
To overcome this we marked all compoundparts but the last, with the symbol ?#?.
Thus they arehandled as separate words.
Parts of split words alsoreceive a special POS-tag, based on the POS of thelast word of the compound, and the last part receivesthe same POS as the full word.We also split words containing hyphens based onthe same algorithm.
Their parts receive a differentPOS-tag, and the hyphens are left at the end of allbut the last part.1We choose the arithmetic mean over the geometric meanused by Koehn and Knight (2003) in order to increase the num-ber of splits.3.2 Merging compoundsFor translation into German, the translation outputcontains split compounds, which need to be merged.An algorithm for merging has been proposed byPopovic?
et al (2006) using lists of compounds andtheir parts.
This method cannot merge unseen com-pounds, however, so instead we base merging onPOS.
If a word has a compound-POS, and the fol-lowing word has a matching POS, they are merged.If the next POS does not match, a hyphen is addedto the word, allowing for coordinated compounds asin (2).
(2) Wasser- und Bodenqualita?twater and soil quality4 System DescriptionsThe main difference of our system in relation to thebaseline system of the Shared Task2 is the pre- andpost-processing described above, the use of a POSfactor, and an additional sequence model on POS.We also modified the tuning to include compoundmerging, and used a smaller corpus, 600 sentencespicked evenly from the dev2006 corpus, for tuning.We use the Moses decoder (Koehn et al, 2007) andSRILM language models (Stolcke, 2002).4.1 German ?
EnglishWe used POS as an output factor, as can be seen inFigure 1.
Using additional factors only on the tar-get side means that only the training data need to bePOS-tagged, not the tuning data or translation input.However, POS-tagging is still performed for Ger-man as input to the pre-processing step.
As Figure 1shows we have two sequence models.
A 5-gram lan-guage model based on surface form using Kneser-Ney smoothing and in addition a 7-gram sequencemodel based on POS using Witten-Bell3 smoothing.The training corpus was filtered to sentences with2?40 words, resulting in a total of 1054688 sen-tences.
Training was done purely on Europarl data,but results were submitted both on Europarl and2http://www.statmt.org/wmt08/baseline.html3Kneser-Ney smoothing can not be used for the POS se-quence model, since there were counts-of-counts of zero.
How-ever, Witten-Bell smoothing gives good results when the vocab-ulary is small.1367?gramPOSPOSwordwordSource Target5?gramwordFactors SequencemodelsFigure 1: Architecture of the factored systemNews data.
The news data were submitted to seehow well a pure out-of-domain system could per-form.In the pre-processing step compounds were split.This was done for training, tuning and translation.In addition German contracted prepositions and de-terminers, such as zum from zu dem (?to the?
), whenidentified as such by the tagger, were split.4.2 English ?
GermanAll features of the German to English system wereused, and in addition more fine-grained GermanPOS-tags that were sub-categorized for morpholog-ical features.
This was done for training, tuningand sequence models.
At translation time no pre-processing was needed for the English input, but apost-processing step for the German output is re-quired, including the merging of compounds andcontracted prepositions and determiners.
The latterwas done in connection with uppercasing, by train-ing an instance of Moses on a lower cased corpuswith split contractions and an upper-cased corpuswith untouched contractions.
The tuning step wasmodified so that merging of compounds were doneas part of the tuning.4.3 BaselineFor comparison, we constructed a baseline accord-ing to the shared-task description, but with smallertuning corpus, and the same sentence filtering for thetranslation model as in the submitted system, usingonly sentences of length 2-40.In addition we constructed a factored baselinesystem, with POS as an output factor and a se-quence model for POS.
Here we only used the orig-inal POS-tags from TreeTagger, no additional mor-phology was added for German.De-En En-DeBaseline 26.95 20.16Factored baseline 27.43 20.27Submitted system 27.63 20.46Table 1: Bleu scores for Europarl (test2007)De-En En-DeBaseline 19.54 14.31Factored baseline 20.16 14.37Submitted system 20.61 14.77Table 2: Bleu scores for News Commentary (nc-test2007)5 ResultsCase-sensitive Bleu scores4 (Papineni et al, 2002)for the Europarl devtest set (test2007) are shown intable 1.
We can see that the submitted system per-forms best, and that the factored baseline is betterthan the pure baseline, especially for translation intoEnglish.Bleu scores for News Commentary5 (nc-test2007)are shown in Table 2.
Here we can also see that thesubmitted system is the best.
As expected, Bleu ismuch lower on out-of-domain news text than on theEuroparl development test set.5.1 CompoundsThe quality of compound translations were analysedmanually.
The first 100 compounds that could befound by the splitting algorithm were extracted fromthe Europarl reference text, test2007, together withtheir English translations6 .System translations were compared to the an-notated compounds and classified into seven cate-gories: correct, alternative good translation, correctbut different form, part of the compound translated,no direct equivalent, wrong and untranslated.
Outof these the first three categories can be consideredgood translations.We performed the error analysis for the submittedand the baseline system.
The result can be seen in4The %Bleu notation is used in this report5No development test set for News test were provided, so wepresent result for the News commentary, which can be expectedto give similar results.6The English translations need not be compounds.
Com-pounds without a clear English translation were skipped.137De ?
En En ?
DeSubm Base Subm BaseCorrect 50 46 40 39Alternative 36 26 32 29Form 5 7 6 8Part 2 5 10 15No equivalent 6 2 8 5Wrong 1 7 1 1Untranslated ?
7 3 3Table 3: Results of the error analysis of compound trans-lationsTable 3.
For translation into English the submittedsystem handles compound translations considerablybetter than the baseline with 91% good translationscompared to 79%.
In the submitted system all com-pounds have a translation, compared to the baselinesystem which has 7% of the compounds untrans-lated.
In the other translation direction the differenceis smaller, the biggest difference is that the submit-ted system has fewer cases of partial translation.5.2 Agreement in German NPsTo study the effects of using fine-grained POS-tagsin the German sequence model, a similar close studyof German NPs was performed.
100 English NPshaving at least two dependents of the head nounwere selected from a randomly chosen subsectionof the development test set.
Their translations inthe baseline and submitted system were then identi-fied.
Translations that were not NPs were discarded.In about two thirds (62 out of 99) of the cases, thetranslations were identical.
For the remainder, 12translations were of equal quality, the submitted sys-tem had a better translation in 17 cases (46%), and aworse one in 8 cases (22%).
In the majority of caseswhere the baseline was better, this was due to wordselection, not agreement.6 ConclusionsAdding morphological processing improved trans-lation results in both directions for both text types.Splitting compounds gave a bigger effect for trans-lation from German.
Marking of compound partsworked well, with no untranslated parts left in thesample used for evaluation.
The mini-evaluationof German NPs in English-German translation in-dicates that the morphologically rich POS-based se-quence model for German also had a positive effect.AcknowledgementWe would like to thank Joe Steinhauer for help withthe evaluation of German output.ReferencesM.
Collins, P. Koehn, and I. Kuc?erova?.
2005.
Clause re-structuring for statistical machine translation.
In Pro-ceedings of the 43rd Annual Meeting of the ACL, pages531?540, Ann Arbor, Michigan.M.
Holmqvist, S. Stymne, and L. Ahrenberg.
2007.
Get-ting to know Moses: Initial experiments on German-English factored translation.
In Proceedings of theSecond Workshop on Statistical Machine Translation,pages 181?184, Prague, Czech Republic.
Associationfor Computational Linguistics.P.
Koehn and K. Knight.
2003.
Empirical methods forcompound splitting.
In Proceedings of the tenth con-ference of EACL, pages 187?193, Budapest, Hungary.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkit forstatistical machine translation.
In Proceedings of the45th Annual Meeting of the ACL, demonstration ses-sion, Prague, Czech Republic.S.
Langer.
1998.
Zur Morphologie und Semantik vonNominalkomposita.
In Tagungsband der 4.
Konferenzzur Verarbeitung natu?rlicher Sprache (KONVENS),pages 83?97.K.
Papineni, S. Roukos, T. Ward, and W.-J.
Zhu.
2002.BLEU: a method for automatic evaluation of machinetranslation.
In Proceedings of the 40th Annual Meet-ing of the ACL, pages 311?318, Philadelphia, Pennsyl-vania.M.
Popovic?, D. Stein, and H. Ney.
2006.
Statistical ma-chine translation of German compound words.
In Pro-ceedings of FinTAL - 5th International Conference onNatural Language Processing, pages 616?624, Turku,Finland.H.
Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In Preoceedings of the Interna-tional Conference on New Methods in Language Pro-cessing, Manchester, UK.A.
Stolcke.
2002.
SRILM - an extensible languagemodeling toolkit.
In Proceedings of the InternationalConference on Spoken Language Processing (ICSLP),pages 901?904, Denver, Colorado.138
