A Divide-and-Conquer Strategy for Shallow Parsing of GermanFree TextsGi in ter  Neumann*  Chr i s t ian  Braun t Jakub  P i skorsk i  ~Abst ractWe present a divide-and-conquer st ategy based onfinite state technology for shallow parsing of real-world German texts.
In a first phase only the topo-logical structure of a sentence (i.e., verb groups,subclauses) are determined.
In a second phase thephrasal grammars are applied to the contents of thedifferent fields of the main and sub-clauses.
Shallowparsing is supported by suitably configured prepro-cessing, including: morphological and on-line com-pound analysis, efficient POS-filtering, and namedentity recognition.
The whole approach proved tobe very useful for processing of free word order lan-guages like German.
Especially for the divide-and-conquer parsing strategy we obtained an f-measureof 87.14% on unseen data.1 In t roduct ionCurrent information extraction (IE) systems arequite successful in efficient processing of large freetext collections due to the fact that they can providea partial understanding of specific types of text witha certain degree of partial accuracy using fast and ro-bust language processing strategies (basically finitestate technology).
They have been "made sensitive"to certain key pieces of information and thereby pro-vide an easy means to skip text without deep anal-ysis.
The majority of existing IE systems are ap-plied to English text, but there are now a number ofsystems which process other languages as well (e.g.,German (Neumann et al, 1997), Italian (Ciravegnaet al, 1999) or Japanese (Sekine and Nobata, 1998)).The majority of current systems perform a partialparsing approach using only very few general syntac-tic knowledge for the identification of nominal andprepositional phrases and verb groups.
The combi-nation of such units is then performed by means ofdomain-specific templates.
Usually, these templates* DFKI GmbH, Stuhlsatzenhausweg 3, 66123 Saarbriicken,Germany, neumann@dfki, det DFKI GmbH, Stuhlsatzenhausweg 3, 66123 Saarbriicken,Germany, cbratm@dfki, deDFKI GmbH, Stuhlsatzenhausweg 3, 66123 Saarbriicken,Germany, piskorsk@dfki, deare triggered by domain-specific predicates attachedonly to a relevant subset of verbs which expressdomain-specific selectional restrictions for possibleargument fillers.In most of the well-known shallow text process-ing systems (cf.
(Sundheim, 1995) and (SAIC,1998)) cascaded chunk parsers are used which per-form clause recognition after fragment recognitionfollowing a bottom-up style as described in (Abne),1996).
We have also developed a similar bottom-up strategy for the processing of German texts, cf.
(Neumann et al, 1997).
However, the main prob-lem we experienced using the bottom-up strategywas insufficient robustness: because the parser de-pends on the lower phrasal recognizers, its perfor-mance is heavily influenced by their respective per-formance.
As a consequence, the parser frequentlywasn't able to process tructurally simple sentences,because they contained, for example, highly complexnominal phrases, as in the following example:"\[Die vom Bundesgerichtshof und denWettbewerbshfitern als Verstofi gegendas Kartellverbot gegeiflelte zentrale TV-Vermarktung\] ist g~ngige Praxis.
"Central television raarketing, censured by theGerman Federal High Court and the guardsagainst unfair competition as an infringementof anti-cartel legislation, is common practice.During free text processing it might be not possible(or even desirable) to recognize such a phrase com-pletely.
However, if we assume that domain-specifictemplates are associated with certain verbs or verbgroups which trigger template filling, then it will bevery difficult to find the appropriate fillers withoutknowing the correct clause structure.
Furthermorein a sole bottom-up approach some ambiguities - forexample relative pronouns - can't be resolved with-out introducing much underspecification into the in-termediate structures.Therefore we propose the following divide-and-conquer parsing strategy: In a first phase onlythe verb groups and the topological structure ofa sentence according to the linguistic field the-239"\[CooraS \[sse,,* Diese Angaben konnte der Bundes-grenzschutz aber nicht best~itigen\], [ssent Kinkelsprach von Horrorzahlen, \[relct denen er keinenGlauben schenke\]\]\].
"This information couldn't be verified by the BorderPolice, Kinkel spoke of horrible figures that he didn'tbelieve.Figure 1: An example of a topological structure.PREPROCESSOR-TokeNlatl~, v .
!DC-PARSERTOPOt.OGICAL P ~v , ,~ ,~,~ ..FRAGMENT RECOGNIZERUnderspeclfied dependency treesFigure 2: Overview of the system's architecture.ory (cf.
(Engel, 1988)) are determined omain-independently.
In a second phase, general (as wellas domain-specific) phrasal grammars (nominal andprepositional phrases) are applied to the contents ofthe different fields of the main and sub-clauses ( eefig.
1)This approach offers several advantages:?
improved robustness, because parsing of thesentence topology is based only on simple in-dicators like verbgroups and conjunctions andtheir interplay,?
the resolution of some ambiguities, includingrelative pronouns vs. determiner, sub junctionvs.
preposition and sentence coordination vs.NP coordination, and?
a high degree of modularity (easy integration ofdomain-dependent subcomponents).The shallow divide-and-conquer parser (DC-PARSER) is supported by means of powerful mor-phological processing (including on-line compoundanalysis), efficient POS-filtering and named entityrecognition.
Thus the architecture of the completeshallow text processing approach consists basicallyof two main components: the preprocessor and theDC-PARSER itself (see fig.
2).2 PreprocessorThe DC-PARSER relies on a suitably configured pre-processing strategy in order to achieve the desiredsimplicity and performance.
It consists of the fol-lowing main steps:Tokenization The tokenizer maps sequences ofconsecutive characters into larger units called tokensand identifies their types.
Currently we use morethan 50 domain-independent token classes includinggeneric classes for semantically ambiguous tokens(e.g., "10:15" could be a time expression or volley-ball result, hence we classify this token as number-dot compound) and complex classes like abbrevia-tions or complex compounds (e.g., "AT&T-Chief").It proved that such variety of token classes impli-fies the processing of subsequent submodules signif-icantly.Morphology Each token identified as a potentialwordform is submitted to the morphological nalysisincluding on-line recognition of compounds (which iscrucial since compounding is a very productive pro-cess of the German language) and hyphen coordina-tion (e.g., in "An- und Verkauf" (purchase and sale)"An-" is resolved to "Ankauf" (purchase)).
Eachtoken recognized as a valid word form is associatedwith the list of its possible readings, characterizedby stem, inflection information and part of speechcategory.POS-fi ltering Since a high amount of Germanword forms is ambiguous, especially word forms witha verb reading 1 and due to the fact that the qual-ity of the results of the DC-PARSER relies essen-tially on the proper recognition of verb groups, ef-ficient disambiguation strategies are needed.
Usingcase-sensitive rules is straightforward since generallyonly nouns (and proper names) are written in stan-dard German with a capitalized initial letter (e.g.,"das Unternehmen" - the enterprise vs. "wir un-ternehmen" - we undertake).
However for disam-biguation of word forms appearing at the beginningof the sentence local contextual filtering rules areapplied.
For instance, the rule which forbids theverb written with a capitalized initial letter to befollowed by a finite verb would filter out the verbreading of the word "unternehmen" i  the sentence130% of the wordforms in the test corpus"Wirtschaftswoche" (business news journal) ,  which have averb reading, turned to have at least one other non-verbreading.240"Unternehmen sind an Gewinnmaximierung intere-siert."
(Enterprises are interested in maximizingtheir profits).
A major subclass of ambiguous word-forms are those which have an adjective or attribu-tivly used participle reading beside the verb reading.For instance, in the sentence "Sie bekannten, diebekannten Bilder gestohlen zu haben."
(They con-fessed they have stolen the famous paintings.)
thewordform "bekannten" is firstly used as a verb (con-fessed) and secondly as an adjective (famous).
Sinceadjectives and attributively used participles are inmost cases part of a nominal phrase a convenientrule would reject the verb reading if the previousword form is a determiner or the next word form isa noun.
It is important o notice that such rulesare based on some regularities, but they may yieldfalse results, like for instance the rule for filteringout the verb reading of some word forms extremelyrarely used as verbs (e.g., "recht" - right, to rake(3rd person,sg)).
All rules are compiled into a sin-gle finite-state transducer according to the approachdescribed in (Roche and Schabes, 1995).
2Named ent i ty  f inder  Named entities such as or-ganizations, persons, locations and time expressionsare identified using finite-state grammars.
Sincesome named entities (e.g.
company names) may ap-pear in the text either with or without a designator,we use a dynamic lexicon to store recognized namedentities without their designators (e.g., "Braun AG"vs. "Braun") in order to identify subsequent occur-rences correctly.
However a named entity, consistingsolely of one word, may be also a valid word form(e.g., "Braun" - brown).
Hence we classify suchwords as candidates for named entities since gen-erally such ambiguities cannot be resolved at thislevel.
Recognition of named entities could be post-poned and integrated into the fragment recognizer,but performing this task at this stage of processingseems to be more appropriate.
Firstly because theresults of POS-filtering could be partially verifiedand improved and secondly the amount of the wordforms to be processed by subsequent modules couldbe considerably reduced.
For instance the verb read-ing of the word form "achten" (watch vs. eight) inthe time expression "am achten Oktober 1995" (atthe eight of the October 1995) could be filtered outif not done yet.3 A Sha l low D iv ide -and-ConquerS t ra tegyThe DC-PARSER consists of two major domain-independent modules based on finite state technol-2The manually constructed rules proved to be a usefulmeans for disambiguation, however not sufficient enough tofilter out all unplausible readings.
Hence supplementary rulesdetermined by Brill's tagger were used in order to achievebroader coverage.ogy: 1) construction of the topological sentencestructure, and 2) application of phrasal grammarson each determined subclause (see also fig.
3).
Inthis paper we will concentrate on the first step, be-cause it is the more novel part of the DC-PARSER,and will only briefly describe the second step in sec-tion 3.2.3.1 Topo log ica l  s t ruc tureThe DC-PARSER applies cascades of finite-stategrammars to the stream of tokens and named en-titles delivered by the preprocessor in order to de-termine the topological structure of the sentence ac-cording to the linguistic field theory (Engel, 1988).
3Based on the fact that in German a verb group(like "h~tte fiberredet werden mfissen" - -  *have con-vinced been should meaning should have been con-vinced) can be split into a left and a right verb part("h?tte" and "fiberredet werden miissen") theseparts (abbreviated as LVP and RVP) are used for thesegmentation of a main sentence into several parts:the front field (VF), the left verb part, middle field(MF), right verb part, and rest field (RF).
Subclausescan also be expressed in that way such that the left"verb part is either empty or occupied by a relativepronoun or a sub junction element, and the completeverb group is placed in the right verb part, cf.
figure3.
Note that each separated field can be arbitrarilycomplex with very few restrictions on the orderingof the phrases inside a field.Recognition of the topological structure of a sen-tence can be described by the following four phasesrealized as cascade of finite state grammars (see alsofig.
2; fig.
4 shows the different steps in action).
4Initially, the stream of tokens and named entities isseparated into a list of sentences based on punctua-tion signs.
5Verb  groups  A verb grammar ecognizes all sin-gle occurrences of verbforms (in most cases corre-sponding to LVP) and all closed verbgroups (i.e., se-quences of verbforms, corresponding to RVP).
Theparts of discontinuous verb groups (e.g., separatedLvP and RVP or separated verbs and verb-prefixes)cannot be put together at that step of processingbecause one needs contextual information which willonly be available in the next steps.
The major prob-lem at this phase is not a structural one but the3Details concerning the implementation f the topologicalparsing strategy can be found in (Braun, 1999).
Details con-cerning the representation a d compilation of the used finitestate machinery can be found in (Neumann et al, 1997)4In this paper we can give only a brief overview of thecurrent coverage of the individual steps.
An exhaustive de-scription of the covered phenomena can be found in (Braun,1999).5 Performing this step after preprocessing has the advan-tage that the tokenizer and named entity finder already havedetermined abbreviation signs, so that this sort of disam-biguation is resolved.241'$KERH~TE$SENT~ERI  " .
"VERBI IMODUERB$FORrl~ "lK~s~e uer-k~ut'en"flORPHO-INFOt rRCR: ~toPphix-FUek~or$\]GE}I~: IRKEHSE .. :FI~'SFORM: "ve~kau~em"P~RPHO-IHFO= R(~R= ~rZ%~'l~iX-i:V~kto~*FIHIT| =INFG~HUS: ~TI~SE = :PRESLST~= "~=ue"  jSTEM: "w JeSS"XSU~J-CL/~CONTENT~ 'ZSPANNSAT L~I1FI "~REL-CL$CONTKHT| Z.SF'FIHHSAT ~L ~,  (-~,') J h='/\[z: /\[~: m~-phlx-FVel~to~* J ,?RB: *VERB*F01~I.. ?
leb%"~INFO."
rp~,Rl :l~to~phix-FVek*Oe:l:L~ lHI Ts T GEHUSt IR~ ENSIEI IPRIESTEM: =leb  ~;~EL-P1RI~4: (" die')"RB, \[*~* 1 FORM: "er l i t~en ha%~?e"EHSE~ IPERFLsTErh "er le id"  J)Figure 3: The result of the DC-PARSER for the sentence "Weil die Siemens GmbH, die vom Export lebt,Verluste erlitten hat, musste sie Aktien verkaufen."
(Because the Siemens GmbH which strongly depends onexports suffered from losses they had to sell some of the shares.)
abbreviated where convenient.
It showsthe separation of a sentence into the front field (vF), the verb group (VERB), and the middle field (MF).
Theelements of different fields have been computed by means of fragment recognition which takes place afterthe (possibly recursive) topological structure has been computed.
Note that the front field consists only ofone but complex subclause which itself has an internal field structure.Well die Siemens GmbH, die vom Export lebt, Verluste erlitt, musste sie Aktien verkaufen.Well die Siemens GmbH, die ...\[Verb-Fin\], Verl.
\[Verb-Fin\], \[Modv-Fin\] sie Akt.
\[FV-Inf\].Weil die Siemens GmbH \[ReI-CI\], Verluste \[Verb-Fin\], \[Modv-Fin\] sie Aktien \[FV-Inf\].\[Subconj-CL\], \[Modv-Fin\] sie Aktien \[FV-Inf\].\[Subconj-CL\], \[Modv-Fin\] sie Aktien \[FV-Inf\].\[clause\]Figure 4: The different steps of the DC-PARSER for the sentence of figure 3.massive morphosyntactic ambiguity of verbs (for ex-ample, most plural verb forms can also be non-finiteor imperative forms).
This kind of ambiguity can-not be resolved without taking into account a widercontext.
Therefore these verb forms are assigned dis-junctive types, similar to the underspecified chunkcategories proposed by (Federici et al, 1996).
Thesetypes, like for example Fin-Inf-PP or Fin-PP, re-flect the different readings of the verbform and en-able following modules to use these verb fonns ac-cording to the wider context, thereby removing theambiguity.
In addition to a type each recognizedverb form is assigned a set of features which rep-resent various properties of the form like tense andmode information.
(cf.
figure 5).Base clauses (BC)  are subclauses of type sub-junctive and subordinate.
Although they are embed-ded into a larger structure they can independently9~L9 242I Type VG-f inal 1 Subtype Mod-Perf-Ak Modal-stem kSnn Stem lob Form nicht gelobt haben kann Neg T Agr ...Figure 5: The structure of the verb fragment "nichtgelobt haben kann" - *not praised have could-beenmeaning could not have been praisedand simply be recognized on the basis of commas,initial elements (like complementizer, interrogativeor relative item - see also fig.
4, where SUBCONJ-CL and REL-CL are tags for subclauses) and verbfragments.
The different ypes of subclauses are de-scribed very compactly as finite state expressions.Figure 6 shows a (simplified) BC-structure in fea-ture matrix notation.
"Type Subj-ClSubj wenn-Type SpannsatzVerb J"Type stelltenJ Verb .For mMF die Arbeitgeber Forderungen)Cont \['Type Iohfi\[l 1~ \] \[Type   mp e-Io: I II \[Verb rType Ve.b 1!
!I L~.o.
rm .u 'eb"enJl||L MF (als Gegenleistung / / /  neue Stellen) j j /Figure 6: Simplified feature matrix of the base clause"... ,  wenn die Arbeitgeber Forderungen steUten,ohne als Gegenleistung neue Stellen zu schaffen."
...if the employers make new demands, without compensat-ing by creating new jobs.Clause combination It is very often the case thatbase clauses are recursively embedded as in the fol-lowing example:.
.
.
well der Hund den Braten gefressenhatte, den die Frau, nachdem sie ihn zu-bereitet hatte, auf die Fensterbank gestellthatte.Because the dog ate the beef which was put onthe window sill after it had been prepared bythe woman.Two sorts of recursion can be distinguished: 1)middle field (MF) recursion, where the embeddedbase clause is framed by the left and right verb partsof the embedding sentence, and 2) the rest field (RF)recursion, where the embedded clause follows theright verb part of the embedding sentence.
In orderto express and handle this sort of recursion usinga finite state approach, both recursions are treatedas iterations uch that they destructively substituterecognized embedded base clauses with their type.Hence, the complexity of the recognized structureof the sentence is reduced successively.
However,because subclauses of MF-recursion may have theirown embedded RF-recursion the CLAUSE COMBINA-TION (CC) is used for bundling subsequent baseclauses before they would be combined with sub-clauses identified by the outer MF-recursion.
TheBC and CC module are called until no more baseclauses can be reduced.
If the CC module would notbe used, then the following incorrect segmentationcould not be avoided:.
.
.
*\[daft das Gliick \[, das JochenKroehne ernpfunden haben sollte Rel-C1\]\[, als ihm jiingst sein Groflaktion/ir dieUbertragungsrechte bescherte Sub j -e l f ,nicht mehr so recht erwKrmt Sub j-C1\]In the correct reading the second subclause "... alsihm jiingst sein ..
."
is embedded into the first one".. .
das Jochen Kroehne ..
.
".Ma in  c lauses (MC)  Finally the MC modulebuilds the complete topological structure of the in-put sentence on the basis of the recognized (remain-ing) verb groups and base clauses, as well as on theword form information ot yet consumed.
The latterincludes basically punctuations and coordinations.The following figure schematically describes the cur-rent coverage of the implemented MC-module (seefigure 1 for an example structure):CSentSSentCoordSAsyndSentCmpCSentAsyndCond:: .
.
.
.
LVP .. .
\[RVP\] .
.
.
::= LVP ...\[RVP\] .
.
.
::= CSent ( , CSent)* Coord CSent \]::= CSent (, SSent)* Coord SSent::= CSent , CSent::= CSent , SSent I CSent , CSent::= SSent , SSent3.2 Phrase recognitionAfter the topological structure of a sentence has beenidentified, each substring is passed to the FRAG-MENT RECOGNIZER in order to determine the in-ternal phrasal structure.
Note that processing ofa substring might still be partial in the sense thatno complete structure need be found (e.g., if wecannot combine sequences of phrases to one largerunit).
The FRAGMENT RECOGNIZER uses finite stategrammars in order to extract nominal and preposi-tional phrases, where the named entities recognizedby the preprocessor are integrated into appropriateplaces (unplausibte phrases are rejected by agree-ment checking; see (Neumann et al, 1997) for more243details)).
The phrasal recognizer currently only con-siders processing of simple, non-recursive structures(see fig.
3; here, *NP* and *PP* are used for de-noting phrasal types).
Note that because of thehigh degree of modularity of our shallow parsingarchitecture, it is very easy to exchange the cur-rently domain-independent fragment recognizer witha domain-specific one, without effecting the domain-independent DC-PARSER.The final output of the parser for a sentence is anunderspecified dependence structure UDS.
An UDSis a flat dependency-based structure of a sentence,where only upper bounds for attachment and scop-ing of modifiers are expressed.
This is achieved bycollecting all NPs and PPs of a clause into sepa-rate sets as long as they are not part of some sub-clauses.
This means that although the exact attach-ment point of each individual PP is not known itis guaranteed that a PP can only be attached tophrases which are dominated by the main verb of thesentence (which is the root node of the clause's tree).However, the exact point of attachment is a matterof domain-specific knowledge and hence should bedefined as part of the domain knowledge of an ap-plication.4 Evaluat ionDue to the limited space, we concentrate on theevaluation of the topological structure.
An eval-uation of the other components (based on a sub-set of 20.000 tokens of the mentioned corpus fromthe "Wirtschaftswoche", see below) yields: Fromthe 93,89% of the tokens which were identified bythe morphological component as valid word forms,95,23% got a unique POS-assignment with an ac-curacy of 97,9%.
An initial evaluation on the samesubset yielded a precision of 95.77% and a recall of85% (90.1% F-measure) for our current named en-tity finder.
Evaluation of the compound analysisof nouns, i.e.
how often a morphosyntactical cor-rect segmentation was found yield: Based on the20.000 tokens, 1427 compounds are found, where1417 have the correct segmentation (0.9929% preci-sion).
On a smaller subset of 1000 tokens containing102 compounds, 101 correct segmentations wherefound (0.9901% recall), which is a quite promisingresult.
An evaluation of simple NPs yielded a recallof 0.7611% and precision of 0.9194%.
The low recallwas mainly because of unknown words.During the 2nd and 5th of July 1999 a test cor-pus of 43 messages from different press releases (viz.DEUTSCHE PREESSEAGENTUR (dpa), ASSOCIATEDPRESS (ap) and REUTERS) and different domains(equal distribution of politics, business, sensations)was collected.
6 The corpus contains 400 sentences6This data collection and evaluation was carried out by(Braun, 1999).with a total of 6306 words.
Note that it also wascreated after the DC-PARSER and all grammars werefinally implemented.
Table 1 shows the result ofthe evaluations (the F-measure was computed with/3=1).
We used the correctness criteria as defined infigure 7.The evaluation of each component was measuredon the basis of the result of all previous components.For the BC and MC module we also measured theperformance by manually correcting the errors of theprevious components (denoted as "isolated evalua-tion").
In most cases the difference between the pre-cision and recall values is quite small, meaning thatthe modules keep a good balance between coverageand correctness.
Only in the case of the MC-modulethe difference is about 5%.
However, the result forthe isolated evaluation of the MC-module suggeststhat this is mainly due to errors caused by previouscomponents.A more detailed analysis showed that the major-ity of errors were caused by mistakes in the prepro-cessing phase.
For example ten errors were causedby an ambiguity between different verb stems (onlythe first reading is chosen) and ten errors becauseof wrong POS-filtering.
Seven errors were caused byunknown verb forms, and in eight cases the parserfailed because it could not properly handle the ambi-guities of some word forms being either a separatedverb prefix or adverb.The evaluation has been performed with theLisp-based version of SMES (cf.
(Neumann et al,1997)) by replacing the original bidirectional shal-low buttom-up arsing module with the DC-PARSER.The average run-time per sentence (average length26 words) is 0.57 sec.
A C++-version is nearlyfinished missing only the re-implementation f thebase and main clause recognition phases, cf.
(Pisko-rski and Neumann, 2000).
The run-time behavioris already encouraging: processing of a German textdocument (a collection of business news articles fromthe "Wirtschaftswoche") of 197118 tokens (1.26 MB)needs 45 seconds on a PentiumII, 266 MHz, 128RAM, which corresponds to 4380 tokens per second.Since this is an increase in speed-up by a factor > 20compared to the Lisp-version, we expect o be ableto process 75-100 sentences per second.5 Re lated  WorkTo our knowledge, there are only very few othersystems described which process free German texts.The new shallow text processor is a direct succes-sor of the one used in the SMES-system, an IE-coresystem for real world German text processing (Neu-mann et al, 1997).
Here, a bidirectional verb-drivenbottom-up arser was used, where the problems de-scribed in this paper concerning parsing of longersentences were encountered.
Another similar divide-9,a~ 244Cr i ter ium Match ing of annotated  ata  and results Used by moduleBordersTypePartialTopStructlStruct2start  and end pointss tar t  and end points, types tar t  or end point, types tar t  and end points, typefor the largest tagsee Top, plus test of substructuresusing Par t ia lsee Top, plus test of substructuresusing Typeverbforms, BCverbforms, BC, MCBCMCMCMCFigure 7: Correctness criteria used during evaluation.Verb-Modu lecorrectness Verb fragments Recallcriterium total found correct in %Borders 897 894 883 98.43Type 897 894 880 98.10Base-C lause-Modu lecorrectness B C- Fragments Recallcmterium total found correct in%Type 130 129 121 93.08Par t ia l  130 129 125 96.15Precision F-measurei n% in%98.77 98.5998.43 98.26Precision F-measurein % in %93180 93.4396.89 96.51Base-C lause-Modu le  (isolated evaluation)correctnesscriteriumTypePartialBase-Clauses Recalltotal found correct in %130 131 123 94.61130 131 127 97.69Ma in -C lause-Modu lecorrectness Main-Clauses Recallcmtemum total found correct in%Top 400 377 361 90.25St ruct l  400 377 361 90.25Struct2 400 377 356 89.00Precision F-measurein % in %93.89 94.2496.94 97.31Precision F-measurein % in %95.75 92.9195.75 92.9194.42 91.62Precision F-measurein % in ,%96.65 95.3096.65 95.3095.62 94.29Ma ln -C lause-Modu le  (isolated evaluation)correctness Main- Clauses Recallcriterium total found correct in %Top 400 389 376 94.00St ruct l  400 389 376 94.00Struct2 400 389 372 93.00complete  analys iscorrectness all components Recall Precision F-measurecriterium total \[ found \[ correct in% in% in%Struct2 400 \[ \ ]377  339 84.75 89.68 87.14Table 1: Results of the evaluation of the topological structureand-conquer approach using a chart-based parserfor analysis of German text documents was pre-sented by (Wauschkuhn, 1996).
Nevertheless, com-paring its performance with our approach seems tobe rather difficult since he only measures for an un-annotated test corpus how often his parser finds atleast one result (where he reports 85.7% "coverage"of a test corpus of 72.000 sentences) disregarding tomeasure the accuracy of the parser.
In this sense,our parser achieved a "coverage" of 94.25% (com-puting faund/total), ahnost certainly because weuse more advanced lexical and phrasal components,245e.g., pos-filter, compound and named entity process-ing.
(Peh and Ting, 1996) also describe a divide-and-conquer approach based on statistical methods,where the segmentation f the sentence is done byidentifying so called link words (solely punctuations,conjunctions and prepositions) and disambiguatingtheir specific role in the sentence.
On an annotatedtest corpus of 600 English sentences they report anaccuracy of 85.1% based on the correct recognition ofpart-of-speech, comma nd conjunction disambigua-tion, and exact noun phrase recognition.6 Conc lus ion and future workWe have presented a divide-and-conquer st ategyfor shallow analysis of German texts which is sup-ported by means of powerful morphological process-ing, efficient POS-filtering and named entity recog-nition.
Especially for the divide-and-conquer pars-ing strategy we obtained an F-measure of 87.14%on unseen data.
Our shallow parsing strategy hasa high degree of modularity which allows the inte-gration of the domain-independent sentence recog-nition part with arbitrary domain-dependent sub-components (e.g., specific named entity finders andfragment recognizers).Considered from an application-oriented point ofview, our main experience is that even if we are onlyinterested in some parts of a text (e.g., only in thoselinguistic entities which verbalize certain aspects ofa domain-concept) wehave to unfold the structuralrelationship between all elements of a large enougharea (a paragraph or more) up to a certain levelof depth in which the relevant information is em-bedded.
Beside continuing the improvement of thewhole approach we also started investigations to-wards the integration of deep processing into theDC-PARSER.
The core idea is to call a deep parseronly to the separated field elements which containsequences of simple NPs and PPs (already deter-mined by the shallow parser).
Thus seen the shallowparser is used as an efficient preprocessor for divid-ing a sentence into syntactically valid smaller units,where the deep parser's task would be to identify theexact constituent s ructure only on demand.AcknowledgmentsThe research underlying this paper was supportedby a research grant from the German Bundesmin-isterium fiir Bildung, Wissenschaft, Forschungund Technologie (BMBF) to the DFKI projectPARADIME, FKZ ITW 9704.
Many thanks toThierry Declerck and Milena Valkova for their sup-port during the evaluation of the system.ReferencesS.
Abney.
1996.
Partial parsing via finite-state cas-cades.
Proceedings ofthe ESSLLI 96 Robust Pars-ing Workshop.C.
Braun.
1999.
Flaches und robustes ParsenDeutscher Satzgeffige.
Master's thesis, Universityof the Saarland.F.
Ciravegna, A. Lavelli, N. Mana, L. Gilardoni,S.
Mazza, M. Ferraro, J. Matiasek, W. Black,F.
Rinaldi, and D. Mowatt.
1999.
Facile: Clas-sifying texts integrating pattern matching and in-formation extraction.
In Proceedings of IJCAI-99,Stockholm.Ulrich Engel.
1988.
Deutsche Grammatik.
JuliusGroos Verlag, Heidelberg, 2., improved edition.S.
Federici, S. Monyemagni, and V. Pirrelli.
1996.Shallow parsing and text chunking: A view on umderspecification in syntax.
In Workshop on RobustParsing, 8th ESSLLI, pages 35-44.G.
Neumann, R. Backofen, J. Baur, M. Becker,and C. Braun.
1997.
An information extractioncore system for real world german text processing.In 5th International Conference of Applied Natu-ral Language, pages 208-215, Washington, USA,March.L.
Peh and Christopher H. Ting.
1996.
A divide-and-conquer strategy for parsing.
In Proceedingsof the ACL/SIGPARSE 5th International Work-shop on Parsing Technologies, pages 57-66.J.
Piskorski and G. Neumann.
2000.
An intelligenttext extraction and navigation system.
In 6th In-ternational Conference on Computer-Assisted In-formation Retrieval (RIAO-2000).
Paris, April.18 pages.E.
Roche and Y. Schabes.
1995.
Deterministic part-of-speech tagging with finite state transducers.Computational Linguistics, 21(2):227-253.SAIC, editor.
1998.
Seventh MessageUnderstanding Conference (MUC- 7),http://www.muc.saic.com/.
SAIC InformationExtraction.S.
Sekine and C. Nobata.
1998.
An infor-mation extraction system and a customizationtool.
In Proceedings of Hitachi workshop-98,http://cs.nyu.edu/cs/projects/proteus/sekine/.B.
Sundheim, editor.
1995.
Sixth Message Un-derstanding Conference (MUC-6), Washington.Distributed by Morgan Kaufmann Publishers,Inc.,San Mateo, California.O.
Wauschkuhn.
1996.
Ein Werkzeug zur par-tiellen syntaktischen Analyse deutscher Textko-rpora.
In Dafydd Gibbon, editor, Natural Lan-guage Processing and Speech Technology.
Resultsof the Third KONVENS Conference, pages 356-368.
Mouton de Gruyter, Berlin.246
