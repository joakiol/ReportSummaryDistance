Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 263?271,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsMay All Your Wishes Come True:A Study of Wishes and How to Recognize ThemAndrew B. Goldberg, Nathanael Fillmore, David AndrzejewskiZhiting Xu, Bryan Gibson, Xiaojin ZhuComputer Sciences Department, University of Wisconsin-Madison, Madison, WI 53706, USA{goldberg, nathanae, andrzeje, zhiting, bgibson, jerryzhu}@cs.wisc.eduAbstractA wish is ?a desire or hope for somethingto happen.?
In December 2007, people fromaround the world offered up their wishes tobe printed on confetti and dropped from thesky during the famous New Year?s Eve ?balldrop?
in New York City?s Times Square.
Wepresent an in-depth analysis of this collectionof wishes.
We then leverage this unique re-source to conduct the first study on buildinggeneral ?wish detectors?
for natural languagetext.
Wish detection complements traditionalsentiment analysis and is valuable for collect-ing business intelligence and insights into theworld?s wants and desires.
We demonstratethe wish detectors?
effectiveness on domainsas diverse as consumer product reviews andonline political discussions.1 IntroductionEach year, New York City rings in the New Yearwith the famous ?ball drop?
in Times Square.
InDecember 2007, the Times Square Alliance, co-producer of the Times Square New Year?s Eve Cele-bration, launched a Web site called the Virtual Wish-ing Wall1 that allowed people around the world tosubmit their New Year?s wishes.
These wishes werethen printed on confetti and dropped from the skyat midnight on December 31, 2007 in sync with theball drop.We obtained access to this set of nearly 100,000New Year?s wishes, which we call the ?WISH cor-pus.?
Table 1 shows a selected sample of the WISH1http://www.timessquarenyc.org/nye/nye interactive.htmlcorpus.
Some are far-reaching fantasies and aspi-rations, while others deal with everyday concernslike economic and medical distress.
We analyze thisfirst-of-its-kind corpus in Section 2.The New Oxford American Dictionary defines?wish?
as ?a desire or hope for something to hap-pen.?
How wishes are expressed, and how suchwishful expressions can be automatically recog-nized, are open questions in natural language pro-cessing.
Leveraging the WISH corpus, we conductthe first study on building general ?wish detectors?for natural language text, and demonstrate their ef-fectiveness on domains as diverse as consumer prod-uct reviews and online political discussions.
Suchwish detectors have tremendous value in collectingbusiness intelligence and public opinions.
We dis-cuss the wish detectors in Section 3, and experimen-tal results in Section 4.1.1 Relation to Prior WorkStudying wishes is valuable in at least two aspects:1.
Being a special genre of subjective expression,wishes add a novel dimension to sentiment analy-sis.
Sentiment analysis is often used as an auto-matic market research tool to collect valuable busi-ness intelligence from online text (Pang and Lee,2008; Shanahan et al, 2005; Koppel and Shtrim-berg, 2004; Mullen and Malouf, 2008).
Wishesdiffer from the recent focus of sentiment analysis,namely opinion mining, by revealing what peopleexplicitly want to happen, not just what they like ordislike (Ding et al, 2008; Hu and Liu, 2004).
For ex-ample, wishes in product reviews could contain newfeature requests.
Consider the following (real) prod-263514 peace on earth351 peace331 world peace244 happy new year112 love76 health and happiness75 to be happy51 i wish for world peace21 i wish for health and happiness for my family21 let there be peace on earth16 i wish u to call me if you read this 555-123416 to find my true love8 i wish for a puppy7 for the war in iraq to end6 peace on earth please5 a free democratic venezuela5 may the best of 2007 be the worst of 20085 to be financially stable1 a little goodness for everyone would be nice1 i hope i get accepted into a college that i like1 i wish to get more sex in 20081 please let name be healthy and live all year1 to be emotionally stable and happy1 to take over the worldTable 1: Example wishes and their frequencies in theWISH corpus.uct review excerpt: ?Great camera.
Indoor shotswith a flash are not quite as good as 35mm.
I wishthe camera had a higher optical zoom so that I couldtake even better wildlife photos.?
The first sentencecontains positive opinion, the second negative opin-ion.
However, wishful statements like the third sen-tence are often annotated as non-opinion-bearing insentiment analysis corpora (Hu and Liu, 2004; Dinget al, 2008), even though they clearly contain im-portant information.
An automatic ?wish detector?text-processing tool can be useful for product manu-facturers, advertisers, politicians, and others lookingto discover what people want.2.
Wishes can tell us a lot about people: their in-nermost feelings, perceptions of what they?re lack-ing, and what they desire (Speer, 1939).
Manypsychology researchers have attempted to quantifythe contents of wishes and how they vary withfactors such as location, gender, age, and per-sonality type (Speer, 1939; Milgram and Riedel,1969; Ehrlichman and Eichenstein, 1992; King andBroyles, 1997).
These studies have been small scalewith only dozens or hundreds of participants.
TheWISH corpus provides the first large-scale collec-tion of wishes as a window into the world?s desires.Beyond sentiment analysis, classifying sentencesas wishes is an instance of non-topical classifica-tion.
Tasks under this heading include compu-tational humor (Mihalcea and Strapparava, 2005),genre classification (Boese and Howe, 2005), au-thorship attribution (Argamon and Shimoni, 2003),and metaphor detection (Krishnakumaran and Zhu,2007), among others (Mishne et al, 2007; Mihal-cea and Liu, 2006).
We share the common goal ofclassifying text into a unique set of target categories(in our case, wishful and non-wishful), but use dif-ferent techniques catered to our specific task.
Ourfeature-generation technique for wish detection re-sembles template-based methods for information ex-traction (Brin, 1999; Agichtein and Gravano, 2000).2 Analyzing the WISH CorpusWe analyze the WISH corpus with a variety of sta-tistical methods.
Our analyses not only reveal whatpeople wished for on New Year?s Eve, but also pro-vide insight for the development of wish detectors inSection 3.The complete WISH corpus contains nearly100,000 wishes collected over a period of 10 daysin December 2007, most written in English, with theremainder in Portuguese, Spanish, Chinese, French,and other languages.
For this paper, we consideronly the 89,574 English wishes.
Most of these En-glish wishes contain optional geographic meta dataprovided by the wisher, indicating a variety of coun-tries (not limited to English-speaking) around theworld.
We perform minimal preprocessing, includ-ing TreeBank-style tokenization, downcasing, andpunctuation removal.
Each wish is treated as a sin-gle entity, regardless of whether it contains multiplesentences.
After preprocessing, the average lengthof a wish is 8 tokens.2.1 The Topic and Scope of WishesAs a first step in understanding the content of thewishes, we asked five annotators to manually an-notate a random subsample of 5,000 wishes.
Sec-tions 2.1 and 2.2 report results on this subsample.The wishes were annotated in terms of two at-264(a) Topic of Wishes(b) Scope of WishesFigure 1: Topic and scope distributions based on manualannotations of a random sample of 5,000 wishes in theWISH corpus.tributes: topic and scope.
We used 11 pre-definedtopic categories, and their distribution in this sub-sample of the WISH corpus is shown in Figure 1(a).The most frequent topic is love, while health,happiness, and peace are also common themes.Many wishes also fell into an other category, in-cluding specific individual requests (?i wish for anew puppy?
), solicitations or advertisements (?callme 555-1234?, ?visit website.com?
), or sinisterthoughts (?to take over the world?
).The 5,000 wishes were also manually assigneda scope.
The scope of a wish refers to the rangeof people that are targeted by the wish.
We used6 pre-defined scope categories: self (?I want to behappy?
), family (?For a cure for my husband?
), spe-cific person by name (?Prayers for name?
), country(?Bring our troops home!?
), world (?Peace to every-one in the world?
), and other.
In cases where mul-tiple scope labels applied, the broadest scope wasselected.
Figure 1(b) shows the scope distribution.It is bimodal: over one third of the wishes are nar-rowly directed at one?s self, while broad wishes atthe world level are also frequent.
The in-betweenscopes are less frequent.2.2 Wishes Differ by Geographic LocationAs mentioned earlier, wishers had the option to entera city/country when submitting wishes.
Of the man-ually annotated wishes, about 4,000 included validlocation information, covering all 50 states in theU.S., and all continents except Antarctica.We noticed a statistically significant differencebetween wishes submitted from the United States(about 3600) versus non-U.S. (about 400), both interms of their topic and scope distributions.
For eachcomparison, we performed a Pearson ?2-test usinglocation as the explanatory variable and either topicor scope as the response variable.2 The null hypoth-esis is that the variables are independent.
For bothtests we reject the null hypothesis, with p < 0.001for topic, and p = 0.006 for scope.
This indicates adependence between location and topic/scope.
As-terisks in Figure 2 denote the labels that differ sig-nificantly between U.S. and non-U.S. wishes.3In particular, we observed that there are signif-icantly more wishes about love, peace, and travelfrom non-U.S. locales, and more about religion fromthe U.S.
There are significantly more world-scopedwishes from non-U.S. locales, and more country-and family-scoped wishes from the U.S.We also compared wishes from ?red states?
ver-sus ?blue states?
(U.S. states that voted a majorityfor the Republican and Democratic presidential can-didates in 2008, respectively), but found no signifi-cant differences.2The topic test examined a 2 ?
11 contingency table, whilethe scope test used a 2 ?
6 contingency table.
In both tests, allof the cells in the tables had an expected frequency of at least 5,so the ?2 approximation is valid.3To identify the labels that differ significantly by location,we computed the standardized residuals for the cells in the twocontingency tables.
Standardized residuals are approximatelyN (0, 1)-distributed and can be used to locate the major con-tributors to a significant ?2-test statistic (Agresti, 2002).
Theasterisks in Figure 2 indicate the surprisingly large residuals,i.e., the difference between observed and expected frequenciesis outside a 95% confidence interval.265(a) Wish topics differ by Location(b) Wish scopes differ by LocationFigure 2: Geographical breakdown of topic and scopedistributions based on approximately 4,000 location-tagged wishes.
Asterisks indicate statistically significantdifferences.2.3 Wishes Follow Zipf?s LawWe now move beyond the annotated subsample andexamine the full set of 89,574 English wishes.
Wenoticed that a small fraction (4%) of unique wishesaccount for a relatively large portion (16%) of wishoccurrences, while there are also many wishes thatonly occur once.
The question naturally arises: dowishes obey Zipf?s Law (Zipf, 1932; Manning andSchu?tze, 1999)?
If so, we should expect the fre-quency of a unique wish to be inversely proportionalto its rank, when sorted by frequency.
Figure 3plots rank versus frequency on a log-log scale andreveals an approximately linear negative slope, thussuggesting that wishes do follow Zipf?s law.
It alsoshows that low-occurrence wishes dominate, hencelearning might be hindered by data sparseness.2.4 Latent Topic Modeling for WishesThe 11 topics in Section 2.1 were manually pre-defined based on domain knowledge.
In contrast,in this section we applied Latent Dirichlet Alloca-tion (LDA) (Blei et al, 2003) to identify the latenttopics in the full set of 89,574 English wishes in an100 101 102 103 104 105100101102103 peaceto find my true loveto take overthe worldlog(rank)log(frequency)Figure 3: The rank vs. frequency plot of wishes, approx-imately obeying Zipf?s law.
Note the log-log scale.unsupervised fashion.
The goal is to validate andcomplement the study in Section 2.1.To apply LDA to the wishes, we treated each indi-vidual wish as a short document.
We used 12 topics,Collapsed Gibbs Sampling (Griffiths and Steyvers,2004) for inference, hyperparameters ?
= 0.5 and?
= 0.1, and ran Markov Chain Monte Carlo for2000 iterations.The resulting 12 LDA topics are shown in Ta-ble 2, in the form of the highest probability wordsp(word|topic) in each topic.
We manually addedsummary descriptors for readability.
With LDA, it isalso possible to observe which words were assignedto which topics in each wish.
For example, LDA as-signed most words in the wish ?world(8) peace(8)and my friends(4) in iraq(1) to come(1) home(1)?to two topics: peace and troops (topic numbers inparentheses).
Interestingly, these LDA topics largelyagree with the pre-defined topics in Section 2.1.3 Building Wish DetectorsWe now study the novel NLP task of wish detection,i.e., classifying individual sentences as being wishesor not.
Importantly, we want our approach to trans-fer to domains other than New Year?s wishes, in-cluding consumer product reviews and online politi-cal discussions.
It should be pointed out that wishesare highly domain dependent.
For example, ?I wishfor world peace?
is a common wish on New Year?sEve, but is exceedingly rare in product reviews; andvice versa: ?I want to have instant access to the vol-ume?
may occur in product reviews, but is an un-266Topic Summary Top words in the topic, sorted by p(word|topic)0 New Year year, new, happy, 2008, best, everyone, great, years, wishing, prosperous, may, hope1 Troops all, god, home, come, may, safe, s, us, bless, troops, bring, iraq, return, 2008, true, dreams2 Election wish, end, no, more, 2008, war, stop, president, paul, not, ron, up, free, less, bush, vote3 Life more, better, life, one, live, time, make, people, than, everyone, day, wish, every, each4 Prosperity health, happiness, good, family, friends, all, love, prosperity, wealth, success, wish, peace5 Love love, me, find, wish, true, life, meet, want, man, marry, call, someone, boyfriend, fall, him6 Career get, wish, job, out, t, hope, school, better, house, well, want, back, don, college, married7 Lottery wish, win, 2008, money, want, make, become, lottery, more, great, lots, see, big, times8 Peace peace, world, all, love, earth, happiness, everyone, joy, may, 2008, prosperity, around9 Religion love, forever, jesus, know, loves, together, u, always, 2, 3, 4, much, best, mom, christ10 Family healthy, happy, wish, 2008, family, baby, life, children, long, safe, husband, stay, marriage11 Health com, wish, s, me, lose, please, let, cancer, weight, cure, mom, www, mother, visit, dadTable 2: Wish topics learned from Latent Dirichlet Allocation.
Words are sorted by p(word|topic).likely New Year?s wish.
For this initial study, we doassume that there are some labeled training data inthe target domains of interest.To transfer the knowledge learned from the out-of-domain WISH corpus to other domains, our keyinsight is the following: while the content of wishes(e.g., ?world peace?)
may not transfer across do-mains, the ways wishes are expressed (e.g., ?I wishfor ?)
may.
We call these expressions wish tem-plates.
Our novel contribution is an unsupervisedmethod for discovering candidate templates from theWISH corpus which, when applied to other targetdomains, improve wish detection in those domains.3.1 Two Simple Wish DetectorsBefore describing our template discovery method,we first describe two simple wish detectors, whichserve as baselines.1.
[Manual]: It may seem easy to locatewishes.
Perhaps looking for sentences containingthe phrases ?i wish,?
?i hope,?
or some other sim-ple patterns is sufficient for identifying the vast ma-jority of wishes in a domain.
To test this hypothe-sis, we asked two native English speakers (not theannotators, nor affiliated with the project; no expo-sure to any of the wish datasets) to come up withtext patterns that might be used to express wishes.They were shown three dictionary definitions of ?towish (v)?
and ?wish (n)?.
They produced a rankedlist of 13 templates; see Table 3.
The underscorematches any string.
These templates can be turnedinto a simple rule-based classifier: If part of a sen-tence matches one of the templates, the sentence isi wishi hopei wanthopefullyif onlywould be better ifwould like ifshouldwould thatcan?t believe didn?tdon?t believe didn?tdo wanti can hasTable 3: Manual templates for identifying wishes.classified as a wish.
By varying the depth of the list,one can produce different precision/recall behaviors.Overall, we expect [Manual] to have relatively highprecision but low recall.2.
[Words]: Another simple method for detectingwishes is to train a standard word-based text clas-sifier using the labeled training set in the target do-main.
Specifically, we represent each sentence asa binary word-indicator vector, normalized to sumto 1.
We then train a linear Support Vector Ma-chine (SVM).
This method may have higher recall,but precision may suffer.
For instance, the sentence?Her wish was carried out by her husband?
is not awish, but could be misclassified as one because ofthe word ?wish.
?Note that neither of the two baseline methods usesthe WISH corpus.2673.2 Automatically Discovering Wish TemplatesWe now present our method to automatically dis-cover high quality wish templates using the WISHcorpus.
The key idea is to exploit redundancy inhow the same wish content is expressed.
For ex-ample, as we see in Table 1, both ?world peace?
and?i wish for world peace?
are common wishes.
Sim-ilarly, both ?health and happiness?
and ?i wish forhealth and happiness?
appear in the WISH corpus.It is thus reasonable to speculate that ?i wish for ?is a good wish template.
Less obvious templates canbe discovered in this way, too, such as ?let there be?
from ?peace on earth?
and ?let there be peaceon earth.
?We formalize this intuition as a bipartite graph, il-lustrated in Figure 4.
Let W = {w1, .
.
.
, wn} be theset of unique wishes in the WISH corpus.
The bi-partite graph has two types of nodes: content nodesC and template nodes T , and they are generated asfollows.
If a wish wj (e.g., ?i wish for world peace?
)contains another wish wi (e.g., ?world peace?
), wecreate a content node c1 = wi and a template nodet1 =?i wish for ?.
We denote this relationship bywj = c1+ t1.
Note the order of c1 and t1 is insignif-icant, as how the two combine is determined by theunderscore in t1, and wj = t1 + c1 is just fine.
Inaddition, we place a directed edge from c1 to t1 withedge weight count(wj), the frequency of wish wj inthe WISH corpus.
Then, a template node appears tobe a good one if many heavy edges point to it.On the other hand, a template is less desirableif it is part of a content node.
For example, whenwj =?health and happiness?
and wi =?health?, wecreate the template t2 =?
and happiness?
and thecontent node c3 = wi.
If there is another wishwk =?i wish for health and happiness?, then therewill be a content node c2 = wj .
The template t2thus contains some content words (since it matchesc2), and may not generalize well in a new domain.We capture this by backward edges: if ?c?
?
C, and?
string s (s not necessarily in C or W ) such thatc?
= s+ t, we add a backward edge from t to c?
withedge weight count(c?
).Based on such considerations, we devised the fol-lowing scheme for scoring templates:score(t) = in(t)?
out(t), (1)health and happinessc1c2c3t1t2i wish for ______ and happinessworld peacehealthcount(c1+t1)count(c2)Figure 4: The bipartite graph to create templates.where in(t) is the in-degree of node t, defined as thesum of edge weights coming into t; out(t) is the out-degree of node t, defined similarly.
In other words, atemplate receives a high score if it is ?used?
by manyfrequent wishes but does not match many frequentcontent-only wishes.
To create the final set of tem-plate features, we apply the threshold score(t) ?
5.This produces a final list of 811 templates.
Table 4lists some of the top templates ranked by score(t).While some of these templates still contain time- orscope-related words (?for my family?
), they are de-void of specific topical content.
Notice that we haveautomatically identified several of the manually de-rived templates in Table 3, and introduce many newvariations that a learning algorithm can leverage.Top 10 Others in Top 200in 2008 i want toi wish for for everyonei wish i hopei want my wish isthis year pleasei wish in 2008 wishing fori wish to may youfor my family i wish i hadi wish this year to finallyin the new year for my family to haveTable 4: Top templates according to Equation 1.3.3 Learning with Wish Template FeaturesAfter discovering wish templates as describedabove, we use them as features for learning in a newdomain (e.g., product reviews).
For each sentence inthe new domain, we assign binary features indicat-ing which templates match the sentence.
Two typesof matching are possible.
Strict matching requiresthat the template must match an entire sentence frombeginning to end, with at least one word filling in forthe underscore.
(All matching during the templategeneration process was strict.)
Non-strict matching2680 0.2 0.4 0.6 0.8 100.10.20.30.40.50.60.70.80.91RecallPrecisionManualWordsTemplatesWords + TemplatesFigure 5: Politics domain precision-recall curves.requires only that template match somewhere withina sentence.
Rather than choose one type of match-ing, we create both strict and non-strict template fea-tures (1622 binary features total) and let the machinelearning algorithm decide what is most useful.Our third wish detector, [Templates], is a linearSVM with the 1622 binary wish template features.Our fourth wish detector, [Words + Templates], isa linear SVM with both template and word features.4 Experimental Results4.1 Target Domains and Experimental SetupWe experimented with two domains, manually la-beled at the sentence-level as wishes or non-wishes.4Example wishes are listed in Table 6.Products.
Consumer product reviews: 1,235 sen-tences selected from a collection of amazon.com andcnet.com reviews (Hu and Liu, 2004; Ding et al,2008).
12% of the sentences are labeled as wishes.Politics.
Political discussion board postings:6,379 sentences selected from politics.com (Mullenand Malouf, 2008).
34% are labeled as wishes.We automatically split the corpora into sen-tences using MxTerminator (Reynar and Ratna-parkhi, 1997).
As preprocessing before learning, wetokenized the text in the Penn TreeBank style, down-4These wish-annotated corpora are available for downloadat http://pages.cs.wisc.edu/?goldberg/wish data.0 0.2 0.4 0.6 0.8 100.10.20.30.40.50.60.70.80.91RecallPrecisionManualWordsTemplatesWords + TemplatesFigure 6: Products domain precision-recall curves.cased, and removed all punctuation.For all four wish detectors, we performed 10-foldcross validation.
We used the default parameter inSVMlight for all trials (Joachims, 1999).
As thedata sets are skewed, we compare the detectors us-ing precision-recall curves and the area under thecurve (AUC).
For the manual baseline, we producethe curve by varying the number of templates ap-plied (in rank order), which gradually predicts moresentences as wishes (increasing recall at the expenseof precision).
A final point is added at recall 1.0,corresponding to applying an empty template thatmatches all sentences.
For the SVM-based meth-ods, we vary the threshold applied to the real-valuedmargin prediction to produce the curves.
All curvesare interpolated, and AUC measures are computed,using the techniques of (Davis and Goadrich, 2006).4.2 ResultsFigure 5 shows the precision-recall curves for thePolitics corpus.
All curves are averages over 10folds (i.e., for each of 100 evenly spaced, interpo-lated recall points, the 10 precision values are aver-aged).
As expected, [Manual] can be very precisewith low recall?only the very top few templatesachieve high precision and pick out a small num-ber of wishes with ?i wish?
and ?i hope.?
As weintroduce more templates to cover more true wishes,precision drops off quickly.
[Templates] is similar,269Corpus [Manual] [Words] [Templates] [Words + Templates]Politics 0.67?
0.03 0.77?
0.03 0.73?
0.03 0.80?
0.03Products 0.49?
0.13 0.52?
0.16 0.47?
0.16 0.56?
0.16Table 5: AUC results (10-fold averages ?
one standard deviation).Products:the only area i wish apple had improved upon would be the screeni just want music to eminate from it when i want how i wantthe dial on the original zen was perfect and i wish it was on this modeli would like album order for my live albums and was just wonderingPolitics:all children should be allowed healthcareplease call on your representatives in dc and ask them to please stop the waste in iraqi hope that this is a new beginning for the middle eastmay god bless and protect the brave men and that we will face these dangers in the futureTable 6: Example target-domain wishes correctly identified by [Words + Templates].with slightly better precision in low recall regions.
[Words] is the opposite: bad in high recall but goodin low recall regions.
[Words + Templates] is thebest, taking the best from both kinds of features todominate other curves.
Table 5 shows the averageAUC across 10 folds.
[Words + Templates] is sig-nificantly better than all other detectors under pairedt-tests (p = 1 ?
10?7 vs. [Manual], p = 0.01 vs.[Words], and p = 4 ?
10?7 vs. [Templates]).
Allother differences are statistically significant, too.Figure 6 shows the precision-recall curves forthe Products corpus.
Again, [Words + Templates]mostly dominates other detectors.
In terms of av-erage AUC across folds (Table 5), [Words + Tem-plates] is also the best.
However, due to the smallsize of this corpus, the AUC values have high vari-ance, and the difference between [Words + Tem-plates] and [Words] is not statistically significant un-der a paired t-test (p = 0.16).Finally, to understand what is being learned inmore detail, we take a closer look at the SVM mod-els?
weights for one fold of the Products corpus(Table 7).
The most positive and negative featuresmake intuitive sense.
Note that [Words + Templates]seems to rely on templates for selecting wishes andwords for excluding non-wishes.
This partially ex-plains the synergy of combining the feature types.Sign [Words] [Templates] [Words +Templates]+ wish i hope hoping+ hope i wish i hope+ hopefully hoping i just want+ hoping i just want i wish+ want i would like i would like- money family micro- find forever about- digital let me fix- again d digital- you for my dad youTable 7: Features with the largest magnitude weights inthe SVM models for one fold of the Products corpus.5 Conclusions and Future WorkWe have presented a novel study of wishes froman NLP perspective.
Using the first-of-its-kindWISH corpus, we generated domain-independentwish templates that improve wish detection perfor-mance across product reviews and political discus-sion posts.
Much work remains in this new researcharea, including the creation of more types of fea-tures.
Also, due to the difficulty in obtaining wish-annotated training data, we plan to explore semi-supervised learning for wish detection.Acknowledgements We thank the Times Square Al-liance for providing the WISH corpus, and the WisconsinAlumni Research Foundation.
AG is supported in part bya Yahoo!
Key Technical Challenges Grant.270ReferencesEugene Agichtein and Luis Gravano.
2000.
Snowball:Extracting relations from large plain-text collections.In In Proceedings of the 5th ACM International Con-ference on Digital Libraries, pages 85?94.Alan Agresti.
2002.
Categorical Data Analysis.
Wiley-Interscience, second edition.Shlomo Argamon and Anat Rachel Shimoni.
2003.
Au-tomatically categorizing written texts by author gen-der.
Literary and Linguistic Computing, 17:401?412.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
Journal of MachineLearning Research, 3:993?1022.Elizabeth Sugar Boese and Adele Howe.
2005.
Genreclassification of web documents.
In Proceedings ofthe 20th National Conference on Artificial Intelligence(AAAI-05), Poster paper.Sergey Brin.
1999.
Extracting patterns and relationsfrom the world wide web.
In WebDB ?98: Selectedpapers from the International Workshop on The WorldWide Web and Databases, pages 172?183.
Springer-Verlag.Jesse Davis and Mark Goadrich.
2006.
The relationshipbetween precision-recall and roc curves.
In ICML ?06:Proceedings of the 23rd international conference onMachine learning, New York, NY, USA.
ACM.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
Aholistic lexicon-based approach to opinion mining.
InWSDM ?08: Proceedings of the international confer-ence on Web search and web data mining, pages 231?240.
ACM.Howard Ehrlichman and Rosalind Eichenstein.
1992.Private wishes: Gender similarities and difference.Sex Roles, 26(9):399?422.Thomas Griffiths and Mark Steyvers.
2004.
Finding sci-entific topics.
Proceedings of the National Academy ofSciences, 101(suppl.
1):5228?5235.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of KDD ?04,the ACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 168?177.
ACMPress.Thorsten Joachims.
1999.
Making large-scale svmlearning practical.
In B. Scho?lkopf, C. Burges, andA.
Smola, editors, Advances in Kernel Methods - Sup-port Vector Learning.
MIT Press.Laura A.
King and Sheri J. Broyles.
1997.
Wishes, gen-der, personality, and well-being.
Journal of Personal-ity, 65(1):49?76.Moshe Koppel and Itai Shtrimberg.
2004.
Good newsor bad news?
let the market decide.
In AAAI SpringSymposium on Exploring Attitude and Affect in Text,pages 86?88.Saisuresh Krishnakumaran and Xiaojin Zhu.
2007.Hunting elusive metaphors using lexical resources.In Proceedings of the Workshop on ComputationalApproaches to Figurative Language, pages 13?20,Rochester, New York, April.
Association for Compu-tational Linguistics.Christopher D. Manning and Hinrich Schu?tze.
1999.Foundations of Statistical Natural Language Process-ing.
The MIT Press, Cambridge, Massachusetts.Rada Mihalcea and Hugo Liu.
2006.
A corpus-based ap-proach to finding happiness.
In Proceedings of AAAI-CAAW-06, the Spring Symposia on Computational Ap-proaches to Analyzing Weblogs.Rada Mihalcea and Carlo Strapparava.
2005.
Makingcomputers laugh: Investigations in automatic humorrecognition.
In Empirical Methods in Natural Lan-guage Processing.Norman A. Milgram and Wolfgang W. Riedel.
1969.Developmental and experiential factors in makingwishes.
Child Development, 40(3):763?771.Gilad Mishne, Krisztian Balog, Maarten de Rijke, andBreyten Ernsting.
2007.
Moodviews: Tracking andsearching mood-annotated blog posts.
In Proceed-ings International Conf.
on Weblogs and Social Media(ICWSM-2007), pages 323?324.Tony Mullen and Robert Malouf.
2008.
Taking sides:User classification for informal online political dis-course.
Internet Research, 18:177?190.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and Trends in Infor-mation Retrieval, 2(1-2):1?135.Jeffrey C. Reynar and Adwait Ratnaparkhi.
1997.
Amaximum entropy approach to identifying sentenceboundaries.
In Fifth Conference on Applied NaturalLanguage Processing.James Shanahan, Yan Qu, and Janyce Wiebe, editors.2005.
Computing attitude and affect in text.
Springer,Dordrecht, The Netherlands.George S. Speer.
1939.
Oral and written wishes ofrural and city school children.
Child Development,10(3):151?155.G.
K. Zipf.
1932.
Selected Studies of the Principle ofRelative Frequency in Language.
Harvard UniversityPress.271
