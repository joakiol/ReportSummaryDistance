Proceedings of the 8th International Conference on Computational Semantics, pages 33?44,Tilburg, January 2009. c?2009 International Conference on Computational SemanticsSemantic annotations as complementary tounderspecified semantic representationsHarry BuntDepartment of Communication and Information SciencesTilburg University, Netherlandsharry.bunt@uvt.nlAbstractThis paper presents a new perspective on the use of semantic an-notations.
We argue that semantic annotations should (1) capturesemantic information that is complimentary to the information that isexpressed in the source text; (2) have a formal interpretation.
If theseconditions are fullfilled, then the information in semantic annotationscan be effectively combined with the information in the source textby interpreting a semantic annotation language through the transla-tion of annotations into the same formalism as underspecified semanticrepresentations obtained through compositional semantic analysis.1 IntroductionAnnotations add information to a source text.
In the pre-digital age, ad-notations characteristically took the form of an editor?s bibliographical orhistorical comments, presented in notes that are added to the source text.In the digital age, annotations take on a different form, but their function isessentially the same: they add information to a source text.
The followingexample illustrates this.In (1a) an annotation in the form of a note adds certain historical in-formation to the text; it is indeed additive in the sense that it containsinformation which is not in the text itself.
In (1b), by contrast, the infor-mation in the note is in fact already contained in the text itself, and theannotation therefore does not make any sense.
(1) a.
In 1634 he proposed to distinguish sixty-four elements.132)Note 132.
A proposal to this effect had in fact been made before33by Larochelle in 1544 in his epistle ?Plus d?aspects fondamentals dela materia?
)b.
In 1634 He proposed to distinguish sixty-four elements.
(A proposalto this effect had in fact been made before by Larochelle in 1544 inhis epistle ?Plus d?aspects fondamentals de la materia?
).132)Note 132.
Also proposed by Larochelle in 1544.It may seem obvious that annotations do not make sense if they do notadd any information, but consider the following example of annotating textwith temporal information using TimeML (Pustejovsky et al, 2003):(2) <timeml>The CEO announced that he would resign as of<TIMEX3 tid="t1" type="date" value="2008-12-01"/ >the first of December 2008</TIMEX3></timeml>The annotation in this case does not contain any information which isnot already in the text itself; it only casts the description of a date the firstof December 2008 in the alternative format ?2008-12-01.By contrast, a case where semantic annotation would really add some-thing, is the following.
(3) John called today.In the absence of further temporal information (when was this sentenceuttered/written/published/..?)
we don?t know what day is referred to by?today?.
In this case it would help to have the semantic annotation (4), addedby someone (or by a computer program) who possesses that information oris able to find it, for instance by having access to relevant metadata.
(4) <timeml>John<EVENT called id="e1"/ ><TIMEX3 tid=t1 type="date" value="2008-10-13"/ >today</TIMEX3><TLINK event="e1" relatedToTime="t1" relType="DURING"/ ></timeml>34If the point of annotations is to add certain information to a given sourcetext, then the point of semantic annotations can only be to add semanticinformation that is not already in the text.
We suggest that this additionalinformation can be precisely the information whose absence causes the in-terpretation of sentences to be underspecified, as illustrated in (3), or thatcauses ambiguities such as the one in (5).
(5) John saw Peter when he left the house.The semantic analysis of this sentence tells us that someone called ?John?saw someone called ?Peter?, and that this happened at the moment that oneof them left the house.
If it is known that ?he?
actually refers to Peter, thiscould be captured by the semantic annotation in (6):(6) <refml><REFENTITY id=r1 John/ >saw<REFENTITY id=r2 Peter / >when<REFENTITY id=r3 he / >left the house<REFLINK anaphor=r3 antecedent=r2 relType=IDENTITY/ ></refml>Other types of ambiguity which could benefit from additional informa-tion in semantic annotations for example concern relative scoping, semanticroles, discourse relations, and dialogue acts, as illustrated in (7) - (10).
(7) Angry men and women demonstrated against the proposal.
(8) a.
The movie scared Jane.b.
John scared Jane.
(intentionally: Agent role; unintentionally: Cause role)(9) a. John called Mary; he missed her.
(Effect - Cause relation)b. John called Mary; she was delighted to hear from him.
(Cause - Effect relation)(10) You?re not going to the cinema tonight.
(Statement/verification/prohibition)35These examples all have in common that they contain an ambiguity whichcannot be resolved on the basis of the text alone.
The additional informationthat is needed to deal with such ambiguities has to come from elsewhere, suchas from donain knowledge, from knowledge about the situation of utterance,or from metadata.Ambiguities whose resolution requires information from outside the textare a problem for compositional semantics approaches.
Compositional gen-eration of all the possible alternative semantic representations (and sub-sequent filtering) leads to a combinatorial explosion in the interpretationprocess (see Bunt & Muskens, 1999).
Underspecified semantic representa-tions (USRs) have been proposed as way to get around this, but suffer fromthe limitation that reasoning directly with USRs is problematic; in mostapplications, it is necessary to resolve the underspecifications at some stageand to create a fully disambiguated representation.In this paper we argue that semantic annotations can be helpful foreffectively dealing with ambiguities if they have a formal semantics, andin particular if their interpretation makes use of the same representationalformalism as that of underspecified semantic representations.Since digital texts and their annotations are machine-readable and elec-tronically exchangeable, an issue for annotation in the digital age is thatit would be beneficial if different researchers use the same concepts for ex-pressing the same information and put their annotations in a suitable inter-change format, thus allowing the effective re-use of each other?s annotatedresources.
This ideal has in recent years been taken up by an expert groupof the international organization for standardization ISO, concerned withthe interoperability of language resources.The inspiration for this paper comes from participating in the ?SemanticAnnotation Framework?
initiative of the ISO organization and the Euro-pean eContent project LIRICS (Linguistic Infrastructure for InteroperableResources and Systems, http://lirics.loria.fr), that was set up andcarried out by ISO expert group members.
Building on studies on in the LIR-ICS project, two ISO projects have started in 2007 and 2008, respectively,that aim at proposing standards for the annotation of temporal informa-tion and for annotating the communicative functions of dialogue utterances.Both projects include the design of sets of well-defined and well-documentedconcepts for semantic annotation which are made publicly available in an on-line registry (following ISO standard 12620 - see http://www.isocat.org).Modern annotations typically take the form of XML tags, as illustratedin (2), (4), and (6), where the kind of attributes and values in the tagsdepend on the purpose of the annotation: morphosyntactic, part-of-speech,36syntactic, etc.
Following the Linguistic Annotation Framework (Ide andRomary, 2004; ISO, 2008b), ISO projects insist on using standoff annotation,where the annotations are contained in a separate file with pointers to thesource text file, rather than using in-line annotation as in (2), (4), and (6).We will return to this in section 3, where this will turn out to be importantfor the correct combination of semantic annotations and USRs.The rest of this paper is organized as follows.
In Section 2 we verybriefly consider recent work aiming at the definition of semantic annota-tion languages that have a formal semantics.
Sections 3 and 4 deal withtwo ?alignment?
problems that arise in the combination of semantic anno-tations with underspecified semantic representations.
First, the two shouldpreferably be ?aligned?
in using the same representation formalism.
This isthe subject of Section 3.
Second, the components of semantic annotationstructures and underspecified semantic representation structures should bealigned in that they relate to the same stretches of source text.
This is thesubject of Section 4.
Section 5 closes with some concluding remarks.2 The semantics of semantic annotationsLike other forms of annotation, such as POS annotation, semantic annota-tion has mostly been viewed as a form of text labelling.
This may for examplebe useful in corpus-linguistic research, supporting the search of certain lin-guistic patterns, or for finding certain types of information, such as temporalinformation.
On the other hand when we look at the (simplified) TimeMLannotations shown in (2) and (4), we note that there is in fact an effort touse XML attributes and values to not just put a flag in a text, signallingthat there is temporal information there, but also to describe the contentthat information.
What is lacking ?only?
is a semantics of this language.Recent attempts to provide a semantics for semantic annotations in-clude the Interval Temporal Logic semantics for TimeML by Pratt-Hartman(2005); the event-based semantics for TimeML by Bunt & Overbeeke (2008a),and other attempts to formally interpret temporal annotations by Katz(2007) and Lee (2008).
The most elaborate proposal for a semantics ofsemantic annotation is formulated in Bunt (2007) and Bunt & Overbeeke(2008b), where a semantic annotation language is presented with a formalsemantics, that integrates temporal information, semantic roles, and coref-erence relations.
This semantics translates annotations in a systematic,compositional manner into first-order or second-order logic.11First-order logic suffices in most cases, but second-order logic is needed for cases of37Since first-order logic is formally equivalent with Discourse Representa-tion Structures (and second-order logic to DRSs with second-order discoursereferents), this semantics can be recast in the form of a translation intoDRSs.
Rather than spelling out how this can be done, we refer to Bunt &Overbeeke (2008b) and exploit the well-established equivalence with DRSs.For example, the annotation representation in (6) translates into the DRS< {x, y, z}, {john(x), peter(y), saw(x, y),male(z), leftthehouse(z), z = y}} >3 Combining USRs and semantic annotationsReasoning is the combination of pieces of information ?
so that?s what needsto be done when the information in semantic annotations is combined withthat in USRs.
If we are able to interpret semantic annotations by translatingthem into the same representational format as USRs, then the reasoningprocess can take on a very simple form: unification.A range of representational and processing techniques have been pro-posed for underspecified semantic representation; in the overview in Bunt(2007), it is argued that the use of labels (as in UDRT, Reyle,1993) andhole variables (as in Hole Semantics, Bos, 1996) or ?handles?
(as in MRS,Copestake et al, 1997), in combination with the use of metavariables (asproposed e.g.
by Pinkal, 1999) allows the underspecified representation ofa wide range of semantic phenomena.
Labels etc.
are particularly usefulfor the underspecified respresentation of structural ambiguities like relativescoping and PP attachment, while metavariables are suitable for local ambi-guities like anaphora, metonymy, and sense ambiguities.
We will thereforecast the formal semantics of semantic annotations in the form of UDRSswith labels and hole variables, extended by allowing metavariables to occurin conditions.23.1 Unifying USRs and annotation interpretationWe first illustrate the combination of USRs and semantic annotations forsimple cases of (a) relative scope resolution; (b) coreference resolution; (c)the interpretation of temporal deixis.
In the next subsection we show thatmore complex cases may involve a technical complication for ensuring thatthe underspecified parts of USRs and the information in semantic annota-collective coreference.2Another extension, which we will not consider here, is that of allowing second-orderdiscourse referents; cf.
previous footnote.38tions refer to the same segments of the source text, and we indicate how this?alignment?
problem can be solved.In (11b) we see on the left the underspecified representation of the quan-tifier scopes in (sentence 11a), and on the right the AIR of the annotation,indicating in its bottom part that the universal quantifier has wider scope.The bottom part of the USR contains the scope constraints on the possibleways of combining the various conditions and sub-DRS?s contained in theupper part into a complete DRS.
The operator ???
constructs a DRS fromthe labeled structures that it operates on.
(11) a.
Every man loves a woman.b.USR AIRL4: x, L8: y T1: a, T4: bL1: L3 ?
h1 T2: man(a),L2: ?
{h2,h3}, T3: ?
{T1,T2},L3: ?
{L4,L5}, T5: woman(b),L5: man(x), T6: ?
{T4,T5}L6: love(x,y),L7: ?
{L8,L9},L9: woman(y)L3 > L6, L7 > L6 T3 > T6Unification of the two representations includes the label unifications T3=L3and T6=L7, which has the effect that the AIR scope constraint adds theconstraint L3 > L7 to the USR.
This has the result that of the two possible?pluggings?
of the hole variables in the USR (h0=L1, h1=L2, h2=L6, h3=L7;and h0=L2, h1=L6, h2=L1, h3=L7) the second one is ruled out.
Thisreflects that the semantic annotation resolves the ambiguity.In (12b), the part on the left shows the USR of the sentence (12a), whilethe part on the right shows the Annotation Interpretation Representation(AIR) in the same UDRS-based formalism.
Combination of the two takesthe form of a simple unification, where label variables are unified as well asdiscourse markers.
The unification(with T1=L1, a=x; T3=L3, b=y; L2=T2;L4=T4; L8=T6), results in (13), which is an ordinary DRS (of which theunified labels have been suppressed).
(12) a. John saw Bill ?
he was happy39b.USR AIRL1: x, L3: y, L5: e, L7: z T1: a, T3: b, T5: cL2: john(x), T2: john(a),L4: bill (y), T4: bill (b),L6: saw (e,x,y), T6: he(c),L8: he(z), T7: c=a,L9: happy(z),(13)x, y, e, zjohn(x),bill (y),saw (e,x,y),he(z),happy(z),z=xExample (14) shows the use of metavariables in the USR for representingunderspecified deictic information.
The predicates representing ?me?
and?today?
have an asterisk to indicate their status as metavariables.
(14) a. John called me todayb.USR AIR.L1: x, L3: y, L5: e, L7: t1 T1: a, T3: b, T5: t2L2: john(x), T2: john(a),L4: *ME(y), T4: harrybunt(b),L6: call(e,x,y, t1), T6: 20080923(t2)L8: *TODAY(t1)The use of metavariables assumes an interpretation process where thesevariables are at some stage instantiated by ordinary expressions of the rep-resentation language.
By treating metavariables indeed as variables in theunification process, they are instantiated by the corresponding terms in thesemantic annotations.The above examples all suggest that the information contained in se-mantic annotations can be combined with that in underspecified semanticrepresentations in a straightforward way, using unification.
There is a com-plication, however, which does not turn up in these simple examples, namelythat the correct combination of the two pieces of information requires the40components of the two representation sructures to be ?aligned?
in the senseof being related to the same parts of the source text.
This issue of ?textualalignment?
is addressed in the next subsection.3.2 Textual alignmentConsider the text fragment (15), in which the anaphoric pronoun ?he?
hasthree occurrences, which are ambiguous between having John or Bill as theirantecedent.
(15) a. John saw Bill when he left the house.
He was happy.
Bill hadphoned him last week and warned that he might be unable to come.b.USR AIRL1: x, L3: y, L5: e1, L6: t1, L8: z, T1: a, T3: b, T5: c, T8: d,L11: t2, L12: e2, L15: u, L19: v T11: f, T14: g, T16: hL2: john(x), T2: john(a),L4: bill (y), T4: bill (b),L7: saw (e1,x,y,t1), T6: he(c),L9: he(z), T7: c=b,L10: z=x ?
z=y, T9: he(d),L13: leftthehouse(e2,z,t2), T10: d=a,L14: t1=t2, T12: bill(f),L16: he(u), T13: f=b,L17: happy(u), T1: him(g),L18 bill(v), T15: g=a,L20: T17: he(h),etc.
etc.The AIR in (15) makes perfect sense if we interpret the discourse referent?c?
as corresponding to the first occurrence of ?he?
; ?d?
to the second; and?h?
to the third.
There is however nothing in the AIR that enforces thisinterpretation; the AIR is not in any way ?aligned?
with the source text orwith the USR, and allows e.g.
the components {T5: c, T6: he(c), T7: c=b}to be unified with the USR components {L1: x, L2: john(x)}.This problem can be resolved by taking into account that, as mentionedabove, according to the ISO Linguistic Annotation Framework annotationsshould be represented in a stand-off format, in a separate file with pointers tosource text segments.
This means that, instead of an in-line representationlike (6), we should consider annotations in a format like (16), where thereferential information is ?anchored?
to source text segments:41(16) <refml><SOURCE m1="John" m2="saw" m3="Bill" m4="when" m5="he"m6="left the house"/ ><REFENTITY id="r1" anchor="m1" / ><REFENTITY id="r2" anchor="m3" / ><REFENTITY id="r3" anchor="m5" gender="male"/ ><REFLINK anaphor="r3" antecedent="r2" relType="IDENTITY"/ ><refml/ >The interpretation of semantic annotations should not throw this textualanchoring away.
This information can subsequently be exploited when com-bining the AIR with the USR, if the USR components are likewise anchoredto the source text segments that they interpret ?
see (17).
(17) a. John saw Bill when he left the house.
He was happy.b.
m1="John" m2="saw" m3="Bill" m4="when" m5="he" m6="left"m7="the" m8="house" m9="he" m10="was" m11="happy"USR AIR<m1, L1: x>, <m3, L3: y>, <m1, T1: a>,<m2, L5: e>, <m1..m3, L6: t1>, <m3, T3: b>,<m5, L8: z>, <m9, L11:e2>, <m5, T5: c>,<[m5..m8], L12:t2>, <m10, L15: u> <m9, T8: d><m1, L2: john(x)>, <m1, T2: john(a)>,<m3, L4: bill (y)>, <m3, T4: bill (b)>,<[m1,m2,m3]: L7: saw (e,x,y,t1)>, <m5: T6: he(c)>,<m5, L9: he(z)>, <m5: T7: c=a>,<m5, L10: z=x ?
z=y>, <m9: T9: he(d)>,<[m5..m8], L13:leftthehouse(e2,z,t2)>, <m9: T10: d=a>,<m4, L14: t2=t1>, <[m1,m3,m4],<m9, L16: he(u)>, T11: ?
{T1,...,T10}><m9, L17: u=x ?
u=y><[m9..m11], L18: happy(u)>,<[m1,..,m7], L19: ?
{L1,...,L18} >By unifying pairs < m,L : ?
> of the USR and < m?, T : ?
> of theAIR rather than elements < L : ?
> and < T : ?
>, we enforce that theunifications consider only AIR and USR components that apply to the samesource text segments.Note that, contrary to what the title of this paper suggests, the AIRand the USR parts in the above examples are in fact not entirely compli-mentary.
In (12), for example, they both include representations of John42and Bill and of the discourse referent introduced by ?he?.
The conditions?john(a)?, ?bill(b)?
and ?he(c)?
would seem to anchor ?a?, ?b?
and ?c?
to theirintended antecedents in the USR, but example (15) showed that this is anoptical illusion.
The textual anchoring of the AIR and the USR makes con-ditions like ?john(a)?
in the AIR fully redundant, and allows it to be reducedto the introduction of the discourse referents and the conditions specify-ing the coreference relations.
The corresponding annotation is then indeedcomplimentary to the USR.4 Conclusions and perspectivesIn this paper we have indicated how the information, contained in seman-tic annotations, may effectively be used to resolve ambiguities and to nar-row down underspecified meanings, by exploiting their semantics.
We havethereby assumed that the annotations are expressed in an annotation lan-guage that has a formal semantics.
This is often not the case, but underthe influence of efforts of the international organisation for standards ISO,projects are under way that do indeed aim to define such annotation lan-guages, and preliminary studies by Pratt-Hartmann, Katz, Lee, and the au-thor have demonstrated the feasibility of doing so for substantial fragmentsof semantic annotation languages.This approach opens the possibility to exploit semantic annotations in acomputational interpretation process, as we have shown by casting the in-terpretation of semantic annotations in a UDRS-like representation formatthat is also suitable for underspecified semantic representation, allowingfairly straightforward unification to combine the information from annota-tions with that obtained through local, compositional semantic analysis.Is this useful?
Isn?t the (automatic) construction of the semantic anno-tations the most difficult part of the interpretation enterprise, rather thansomething that?s waiting to be exploited?
Maybe so; that depends verymuch on the kind of linguistic material to be interpreted and on the kindsof semantic information that annotations aim to capture.
One thing isclear: semantic annotations are constructed using entirely different tech-niques (machine learning from corpora, exploitation of domain ontologies,searching metadata,..) than the compositional syntactic-semantic analysistechniques that make the semantic content at sentence level explicit.
Theapproach that we have outlined here makes it possible to effectively combinesuch very heterogeneous processes and sources of information.43References[1] Bos, J.
(1997).
Predicate Logic Unplugged.
In Proc.
10th Amsterdam Colloquium,Amsterdam.
ILLC.
[2] Bunt, H. (2007a).
The Semantics of Semantic Annotation.
In Proceedings of the21st Pacific Asia Conference on Language, Information and Computation (PACLIC21),pages 13?28.
[3] Bunt, H. (2007b).
Underspecified semantic representation: Which technique for whatpurpose?
In Bunt, H. and Muskens, R.
(eds.)
Computing Meaning, Vol.
3, pages115?140.
Springer, Dordrecht.
[4] Bunt, H. and Muskens, R. (1999).
Computational semantics.
In H.Bunt and Muskens,R., (eds.)
Computing Meaning, Vol.
1, pages 1?15.
Kluwer Academic Press, Dordrecht.
[5] Bunt, H. and Overbeeke, C. (2008a).
An extensible compositional semantics for tem-poral annotation.
In Proceedings LAW-II: Second Linguistic Annotation Workshop,Marrakech, Morocco.
Paris: ELRA.
[6] Bunt, H. and Overbeeke, C. (2008b).
Towards formal interpretation of semantic an-notations.
In Proceedings 6th International Conference on Language Resources andEvaluation (LREC 2008), Marrakech, Morocco.
Paris: ELRA.
[7] Bunt, H. and Romary, L. (2002).
Towards Multimodal Content Representation.
InChoi, K. S.
(ed.)
Proceedings of LREC 2002, Workshop on International Standards ofTerminology and Language Resources Management, pages 54?60, Las Palmas, Spain.Paris: ELRA.
[8] Copestake, A., Flickinger, D., and Sag, I.
(1997).
Minimal Recursion Semantics: anIntroduction.
CSLI, Stanford University.
[9] Ide, N. and Romary, L. (2004).
International Standard for a Linguistic AnnotationFramework.
Natural Language Engineering, 10:211?225.
[10] Katz, G. (2007).
Towards a Denotatial Semantics for TimeML.
In Schilder, F., Katz,G., and Pustejovsky, J.
(eds.)
Annotation, Extraction, and Reasoning about Time andEvents.
Springer, Dordrecht.
[11] Lee, K. (2008).
Formal Semantics for Interpreting Temporal Annotation.
In P.van Sterkenburg (ed)Unity and Diversity of Languages: Special Lectures for the 18thInternational Congress of Linguists.
Amsterdam: Benjamins.
[12] Pinkal, M. (1999).
On semantic underspecification.
In Bunt, H. and Muskens, R.(eds.)
Computing Meaning, vol.
1, pages 33?56.
Kluwer, Dordrecht.
[13] Pratt-Hartmann, I.
(2007).
From TimeML to Interval Temporal Logic.
In Proc.Seventh International Workshop on Computational Semantics (IWCS-7), pages 166?180, Tilburg.
[14] Pustejovsky, J., Castano, J., Ingria, R., Gaizauskas, R., Katz, G., Saur?
?, R., andSetzer, A.
(2003).
TimeML: Robust Specification of Event and Temporal Expressionsin Text.
In Proc.
Fifth International Workshop on Computational Semantics (IWCS-5),pages 337?353, Tilburg.
[15] Pustejovsky, J., Knippen, R., Littman, J., and Saur?
?, R. (2007).
Temporal and EventInformation in Natural Language Text.
In Bunt, H. and Muskens, R.
(eds.)
ComputingMeaning, vol.
3, pages 301?346.
Springer, Dordrecht.
[16] Reyle, U.
(1993).
Dealing with ambiguities by underspecification: construction, rep-resentation, and deduction.
Journal of Semantics, 10:123?179.44
