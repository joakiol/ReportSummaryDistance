Proceedings of the Workshop on Language in Social Media (LASM 2013), pages 69?79,Atlanta, Georgia, June 13 2013. c?2013 Association for Computational LinguisticsTowards the Detection of Reliable Food-Health RelationshipsMichael Wiegand and Dietrich KlakowSpoken Language SystemsSaarland UniversityD-66123 Saarbru?cken, Germany{Michael.Wiegand|Dietrich.Klakow}@lsv.uni-saarland.deAbstractWe investigate the task of detecting reli-able statements about food-health relation-ships from natural language texts.
For thatpurpose, we created a specially annotatedweb corpus from forum entries discussing thehealthiness of certain food items.
We ex-amine a set of task-specific features (mostly)based on linguistic insights that are instrumen-tal in finding utterances that are commonlyperceived as reliable.
These features are in-corporated in a supervised classifier and com-pared against standard features that are widelyused for various tasks in natural language pro-cessing, such as bag of words, part-of speechand syntactic parse information.1 IntroductionIn this paper, we explore some linguistic high-levelfeatures to detect food-health relationships in naturallanguage texts that are perceived reliable.
By food-health relationships we mean relations that claimthat a food item is suitable (1) or unsuitable (2) forsome particular health condition.
(1) Baking soda is an approved remedy againstheartburn.
(2) During pregnancy women should not consumeany alcohol.The same health claim may be uttered in differ-ent ways (3)-(5) and, as a consequence, may be per-ceived and judged differently.
For the automatic ex-traction of health claims, we believe that statementsthat are perceived as reliable (4)-(5) are the most im-portant to retrieve.
(3) Eggs do not have a negative impact on peoplesuffering from heart diseases.
(4) According to a leading medical scientist, theconsumption of eggs does not have a negativeimpact on people suffering from heart diseases.
(5) I?m suffering from a heart disease and all mylife I?ve been eating many eggs; it never hadany impact on my well-being.In this work, we will mine a web corpus of fo-rum entries for such relations.
Social media are apromising source of such knowledge as, firstly, thelanguage employed is not very technical and thus,unlike medical texts, accessible to the general pub-lic.
Secondly, social media can be considered as anexclusive repository of popular wisdom.
With re-gard to the health conditions, we can find, for ex-ample, home remedies.
Despite the fact that manyof them are not scientifically proven, there is still agreat interest in that type of knowledge.
However,even though such content is usually not subject toany scientific review, users would appreciate an au-tomatic assessment of the quality of each relation ex-pressed.
In this work, we attempt a first step towardsthis endeavour by automatically classifying these ut-terances with regard to reliability.The features we examine will be (mostly) basedon linguistic insights that are instrumental in findingutterances that are commonly perceived as reliable.These features are incorporated in a supervised clas-sifier and compared against standard features thatare widely used for various tasks in natural languageprocessing, such as bag of words, part-of speech andsyntactic parse information.69Our experiments are carried out on German data.We believe, however, that our findings carry overto other languages since the linguistic aspects thatwe address are (mostly) language universal.
For thesake of general accessibility, all examples will begiven as English translations.2 Related WorkAs far as the extraction of health relations fromsocial media are concerned, the prediction of epi-demics (Fisichella et al 2011; Torii et al 2011;Diaz-Aviles et al 2012; Munro et al 2012) has re-cently attracted the attention of the research commu-nity.Relation extraction involving food items has alsobeen explored in the context of ontology align-ment (van Hage et al 2005; van Hage et al 2006;van Hage et al 2010) and also as a means of knowl-edge acquisition for virtual customer advice in a su-permarket (Wiegand et al 2012a).The works most closely related to this paper areYang et al(2011) and Miao et al(2012).
Bothof these works address the extraction of food-healthrelationships.
Unlike this work, they extract rela-tions from scientific biomedical texts rather than so-cial media.
Yang et al(2011) also cover the taskof strength analysis which bears some resemblanceto the task of finding reliable utterances to some ex-tent.
However, the features applied to that classifica-tion task are only standard features, such as bag ofwords.3 Data & AnnotationAs a corpus for our experiments, we used a crawlof chefkoch.de1 (Wiegand et al 2012a) consistingof 418, 558 webpages of food-related forum entries.chefkoch.de is the largest web portal for food-relatedissues in the German language.
From this dataset,sentences in which some food item co-occurred withsome health condition (e.g.
pregnancy, diarrhoeaor flu) were extracted.
(In the following, we willalso refer to these entities as target food item andtarget health condition.)
The food items were iden-tified with the help of GermaNet (Hamp and Feld-weg, 1997), the German version of WordNet (Milleret al 1990), and the health conditions were used1www.chefkoch.defrom Wiegand et al(2012b).
In total, 2604 sen-tences were thus obtained.For the manual annotation, each target sentence(i.e.
a sentence with a co-occurrence of target fooditem and health condition) was presented in combi-nation with the two sentences immediately preced-ing and following it.
Each target sentence was man-ually assigned two labels, one specifying the typeof suitability (?3.1) and another specifying whetherthe relation expressed is considered reliable or not(?3.2).3.1 Types of SuitabilityThe suitability-label indicates whether a polar rela-tionship holds between the target food item and thetarget health condition, and if so, which.
Rather thanjust focusing on positive polarity, i.e.
suitability,and negative polarity, i.e.
unsuitability, we considermore fine-grained classes.
As such, the suitability-label does not provide any explicit information aboutthe reliability of the utterance.
In principle, ev-ery polar relationship between target food item andhealth condition expressed in a text could also beformulated in such a way that it is perceived reliable.In this work, we will consider the suitability-label asgiven.
We use it as a feature in order to measure thecorrelation between suitability and reliability.
Theusage of fine-grained labels is to investigate whethersubclasses of suitability or unsuitability have a ten-dency to co-occur with reliability.
(In other words:we may assume differences among labels with thesame polarity type.)
We define the following set offine-grained suitability-labels:3.1.1 Suitable (SUIT)SUIT encompasses all those statements in whichthe consumption of the target food item is claimed tobe suitable for people affected by a particular healthcondition (6).
By suitable, we mean that there willnot be a negative effect on the health of a persononce he or she consumes the target food item.
How-ever, this relation type does not state that the con-sumption is likely to improve the condition of theperson either.
(6) I also got dermatitis which is why my motherused spelt flour [instead of wheat flour]; youdon?t taste a difference.70positive labels BENEF, SUIT, PREVENTnegative labels UNSUIT, CAUSETable 1: Categorization of suitability-labels.3.1.2 Beneficial (BENEF)While SUIT only states that the consumption ofthe target food item is suitable for people with a par-ticular health condition, BENEF actually states thatthe consumption alleviates the symptoms of the con-dition or even cures it (7).
While both SUIT andBENEF have a positive polarity, SUIT is much moreneutral than BENEF.
(7) Usually, a glass of milk helps me when I got asore throat.3.1.3 Prevention (PREVENT)An even stronger positive effect than the relationtype BENEF presents PREVENT which claims thatthe consumption of the target food item can preventthe outbreak of a particular disease (8).
(8) Citric acid largely reduces the chances ofkidney stones to develop.3.1.4 Unsuitable (UNSUIT)UNSUIT describes cases in which the consump-tion of the target food item is deemed unsuitable (9).Unsuitability means that one expects a negative ef-fect (but it need not be mentioned explicitly), thatis, a deterioration of the health situation on the partof the person who is affected by a particular healthcondition.
(9) Raw milk cheese should not be eaten duringpregnancy.3.1.5 Causation (CAUSE)CAUSE is the negative counterpart of PREVENT.It states that the consumption of the target food itemcan actually cause a particular health condition (10).
(10) It?s a common fact that the regular consumptionof coke causes caries.The suitability-labels can also be further sepa-rated into two polar classes (i.e.
positive and neg-ative labels) as displayed in Table 1.3.2 ReliabilityEach utterance was additionally labeled as towhether it was considered reliable (4)-(5) or not (3).It is this label that we try to predict in this work.
Byreliable, we understand utterances in which the re-lations expressed are convincing in the sense that areputable source is cited, some explanation or empir-ical evidence for the relation is given, or the relationitself is emphasized by the speaker.
In this work,we are exclusively interested in detecting utteranceswhich are perceived reliable by the reader.
We leaveaside whether the statements from our text corpusare actually correct.
Our aim is to identify linguis-tic cues that evoke the impression of reliability onbehalf of the reader.3.3 Class Distributions and AnnotationAgreementTable 2 depicts the distribution of the reliability-labels on our corpus while Table 3 lists the class dis-tribution of the suitability-labels including the pro-portion of the reliable instances among each cate-gory.
The proportion of reliable instances variesquite a lot among the different suitability-labels,which indicates that the suitability may be some ef-fective feature.Note that the class OTHER in Table 3 comprisesall instances in which the co-occurrence of a healthcondition and a food item was co-incidental (11) orthere was some embedding that discarded the valid-ity of the respective suitability-relation, as it is thecase, for example, in questions (12).
(11) It?s not his diabetes I?m concerned about butthe enormous amounts of fat that he consumes.
(12) Does anyone know whether I can eat tofu dur-ing my pregnancy?In order to measure interannotation agreement,we collected for three health conditions their co-occurrences with any food item.
For the suitability-labels we computed Cohen?s ?
= 0.76 and for thereliability-labels ?
= 0.61.
The agreement for reli-ability is lower than for suitability.
We assume thatthe reason for that lies in the highly subjective no-tion of reliability.
Still, both agreements can be in-terpreted as substantial (Landis and Koch, 1977) andshould be sufficiently high for our experiments.71Type Frequency PercentageReliable 480 18.43Not Reliable 2124 81.57Table 2: Distribution of the reliability-labels.Type Frequency Perc.
Perc.
ReliableBENEF 502 19.28 33.39CAUSE 482 18.51 22.57SUIT 428 16.44 17.91UNSUIT 277 10.64 34.05PREVENT 74 2.84 14.04OTHER 841 32.30 0.00Table 3: Distribution of the suitability-labels.4 Feature Design4.1 Task-specific High-level Feature TypesWe now describe the different task-specific high-level feature types.
We call them high-level featuretypes since they model concepts that typically gen-eralize over sets of individual words (i.e.
low-levelfeatures).4.1.1 Explanatory Statements (EXPL)The most obvious type of reliability is asuitability-relation that is also accompanied by someexplanatory statement.
That is, some reason for therelation expressed is given (13).
We detect reasonsby scanning a sentence for typical discourse cues(more precisely: conjunctions) that anchor such re-marks, e.g.
which is why or because.
(13) Honey has an antiseptic effect which is why itis an ideal additive to milk in order to cure asore throat.4.1.2 Frequent Observation (FREQ)If a speaker claims to have witnessed a certainrelation very frequently or even at all times, thenthere is a high likelihood that this relation actuallyholds (14).
We use a set of adverbs (18 expressions)that express high frequency (e.g.
often, frequentlyetc.)
or constancy (e.g.
always, at all times etc.).
(14) What always helps me when I have the flu is ahot chicken broth.4.1.3 Intensifiers (INTENS)Some utterances may also be perceived reliable iftheir speaker adds some emphasis to them.
One wayof doing so is by adding intensifiers to a remark (15).
(15) You can treat nausea with ginger very effec-tively.The intensifiers we use are a translation of the lex-icon introduced in Wilson et al(2005).
For the de-tection, we divide that list into two groups:The first group INTENSsimple are unambiguousadverbs that always function as intensifiers no mat-ter in which context they appear (e.g.
very or ex-tremely).The second group includes more ambiguous ex-pressions, such as adjectives that only function asan intensifier if they modify a polar expression(e.g.
horrible pain or terribly nice) otherwise theyfunction as typical polar expressions (e.g.
youare horrible?
or he sang terribly?).
We employtwo methods to detect these ambiguous expressions.INTENSpolar requires a polar expression of a polar-ity lexicon to be modified by the intensifier, whileINTENSadj requires an adjective to be modified.
Inorder to identify polar expressions we use the polar-ity lexicon underlying the PolArt system (Klenneret al 2009).
We also consider adjectives since wemust assume that our polarity lexicon does not coverall possible polar expressions.
We chose adjectivesas a complement criterion as this part of speech isknown to contain most polar expressions (Hatzivas-siloglou and McKeown, 1997; Hatzivassiloglou andWiebe, 2000).4.1.4 Strong Polar Expressions (STROPO)Instead of adding intensifiers in order to put moreemphasis to a remark (?4.1.3), one may also usepolar expressions that convey a high polar inten-sity (16).
For instance, nice and excellent refer tothe same scale and convey positive polarity but ex-cellent has a much higher polar intensity than nice.Taboada et al(2011) introduced an English polar-ity lexicon SO-CAL in which polar expressions werealso assigned an intensity label.
As our Germanpolarity lexicon (?4.1.3) does not contain compara-ble intensity labels, we used a German translationof SO-CAL.
We identified polar expressions with ahigh intensity score (i.e.
?4 or ?5) as strong po-lar expressions.
It includes 221 highly positive and344 highly negative polar expressions.
We also dis-tinguish the polarity type (i.e.
STROPO+ refers topositive and STROPO?
refers to negative polarity).72(16) Baking soda is an excellent remedy againstheartburn.4.1.5 Superlatives (SUPER)Another way of expressing high polar intensity isby applying superlatives (17).
Superlatives can onlybe formed from gradable adjectives.
At the sametime, the greatest amount of such adjectives are alsosubjective expressions (Hatzivassiloglou and Wiebe,2000).
As a consequence, the detection of thisgrammatical category does not depend on a subjec-tivity/polarity lexicon but on simple morphologicalsuffixes (e.g.
-est in strongest)2 or combinationswith certain modifiers (e.g.
most in most terrific).
(17) Baking soda is the most effective remedyagainst heartburn.4.1.6 Statements Made by Authorities (AUTH)If a statement is quoted from an authority, then itis usually perceived more reliable than other state-ments (4).
Authorities in our domain are mostly sci-entists and medical doctors.
Not only does a men-tion of those types of professions indicate an author-ity but also the citation of their work.
Therefore,for this feature we also scan for expressions, such asjournal, report, survey etc.
Our final look-up list ofcues comprises 53 expressions.We also considered using the knowledge of userprofiles in order to identify speakers whose profes-sion fall under our defined set of authorities.
Unfor-tunately, the overwhelming majority of users whoactually specified their profession cannot be consid-ered as authorities (for the relations that we are inter-ested in) by mere consideration of their profession.Most users of chefkoch.de are either office employ-ees, housewifes, students or chefs.
Less than 1% areauthorities according to our definition.
Due to thesevere sparsity of authorities, we refrained from us-ing the professions as they are specified in the userprofiles.2We could not use part-of-speech tagging for the detec-tion of superlatives since, unlike the standard English part-of-speech tag set (i.e.
the Penn Treebank Tag Set (Marcus et al1993)), information regarding gradation (i.e.
comparative andsuperlative) is not reflected in the standard German tag set (i.e.Stuttgart Tu?binger Tag Set (Schiller et al 1995)).4.1.7 Doctors?
Prescriptions (PRESC)Some of our food-health relations are also men-tioned in the context of doctors?
prescriptions (5).That is, a doctor may prescribe a patient to con-sume a particular food item since it is consideredsuitable for their health condition, or he/she mayforbid a food item in case it is considered unsuit-able.
As already pointed out in ?4.1.6, doctors usu-ally present an authority with regard to food-healthrelations.
That is why, their remarks should be con-sidered reliable.In order to detect doctors?
prescriptions, wemainly look for (modal) verbs in a sentence that ex-press obligations or prohibitions.
We found that, onour dataset, people rarely mention their doctor ex-plicitly if they refer to a particular prescription.
In-stead, they just mention that they must or must notconsume a particular food item.
From the context,however, it is obvious that they refer to their doc-tor?s prescription (18).
(18) Due to my diabetes I must not eat any sweets.4.1.8 Hedge Cues (HEDGE)While all previous features were designed to iden-tify cases of reliable statements, we also include fea-tures that indicate the opposite.
The most obvioustype of utterances that are commonly considered un-reliable are so-called hedges (Lakoff, 1973) or spec-ulations (19).
(19) Coke may cause cancer.For this feature, we use a German translation of En-glish cue words that have been found useful in pre-vious work (Morante and Daelemans, 2009) whichresults in 47 different expressions.4.1.9 Types of Suitability-Relations (REL)Finally, we also incorporate the informationabout what type of suitability-relation a statementwas labeled with.
The suitability-labels were al-ready presented and motivated in ?3.1.
The con-crete features are: RELSUIT (?3.1.1), RELBENEF(?3.1.2), RELPREVENT (?3.1.3), RELUNSUIT(?3.1.4), RELCAUSE (?3.1.5).73Suffix Description-WNDfood context window around food item-WNDcond context window around health condition-TS target sentence only-EC entire (instance) contextTable 4: Variants for the individual feature types.4.2 Variants of Feature TypesFor our feature types we examine several variantsthat differ in the size of context/scope.
We distin-guish between the target sentence and the entire con-text of an instance, i.e.
the target sentence plus thetwo preceding and following sentences (?3).
If onlythe target sentence is considered, we can also con-fine the occurrence of a cue word to a fixed window(comprising 5 words) either around the target fooditem or the target health condition rather than con-sidering the entire sentence.Small contexts usually offer a good precision.
Forexample, if a feature type occurs nearby a mentionof the target food item or health condition, the fea-ture type and the target expression are likely to berelated to each other.
The downside of such narrowcontexts is that they may be too sparse.
Wide con-texts may be better suited to situations in which ahigh recall is desirable.
However, ambiguous fea-ture types may perform poorly with these contextsas their co-occurrence with a target expression at alarge distance is likely to be co-incidental.Table 4 lists all the variants that we use.
Thesevariants are applied to all feature types except thetypes of suitability (?4.1.9) as this label has onlybeen assigned to an entire target sentence.4.3 Other FeaturesTable 5 lists the entire set of features that we ex-amine in this work.
The simplest classifier that wecan construct for our task is a trivial classifier thatpredicts all statements as reliable statements.
Theremaining features comprise bag of words, part-of-speech and syntactic parse information.
For thelatter two features, we employ the output of theStanford Parser for German (Rafferty and Manning,2008).Features Descriptionall trivial classifier that always predicts a reliable state-mentbow bag-of-words features: all words between the targetfood item and target health condition and the wordsimmediately preceding and following each of thempos part-of-speech features: part-of-speech sequence be-tween target food item and health condition and tagsof the words immediately preceding and followingeach of the target expressionssynt path from syntactic parse tree from target food itemto target health conditiontask all task-specific high-level feature types from ?4.1with their respective variants (?4.2)Table 5: Description of all feature sets.5 ExperimentsEach instance to be classified is a sentence in whichthere is a co-occurrence of a target food item anda target health condition along its respective con-text sentences (?3).
We only consider sentences inwhich the co-occurrence expresses an actual suit-ability relationship between the target food item andthe target health condition, that is, we ignore in-stances labeled with the suitability-label OTHER(?3.3).
We make this restriction as the instanceslabeled as OTHER are not eligible for being reli-able statements (Table 3).
In this work, we take thesuitability-labels for granted (this allows us to easilyexclude the instances labeled as OTHER).
The au-tomatic detection of suitability-labels would requirea different classifier with a different set of featureswhose appropriate discussion would be beyond thescope of this paper.5.1 Comparison of the Different Task-specificHigh-level FeaturesIn our first experiment, we want to find out howthe different task-specific high-level features that wehave proposed in this work compare to each other.More specifically, we want to find out how the in-dividual features correlate with the utterances thathave been manually marked as reliable.
For thatpurpose, Table 6 shows the top 20 features accord-ing to Chi-square feature selection computed withWEKA (Witten and Frank, 2005).
More informa-tion regarding the computation of Chi-square statis-tics in the context of text classification can be foundin Yang and Pederson (1997).
Note that we applyfeature selection only as a means of feature compar-74Rank Feature Score1 FREQ-WNDfood 105.12 FREQ-TS 102.83 FREQ-WNDcond 75.94 FREQ-EC 29.25 AUTH-EC 23.76 STROPO+-WNDcond 20.57 RELBENEF 20.28 RELSUIT 16.89 INTENSsimple-WNDcond 16.410 AUTH-TS 15.411 STROPO+-TS 15.012 INTENSsimple-EC 14.113 STROPO+-WNDfood 13.714 INTENSadj-WNDfood 13.215 INTENSsimple-WNDfood 12.116 INTENSsimple-TS 11.617 PRESC-WNDfood 11.018 INTENSadj-WNDcond 9.719 INTENSpolar-EC 9.020 AUTH-WNDfood 7.9Table 6: Top 20 features according to Chi-square fea-ture ranking (for each feature type the most highly rankedvariant is highlighted).ison.
For classification (?5.2), we will use the entirefeature set.5.1.1 What are the most effective features?There are basically five feature types that dom-inate the highest ranks.
They are FREQ, AUTH,STROPO, REL and INTENS.
This already indicatesthat several features presented in this work are ef-fective.
It is interesting to see that two types ofsuitability-labels, i.e.
RELBENEF and RELSUIT ,are among the highest ranked features which sug-gests that suitability and reliability are somehowconnected.Table 7 shows both precision and recall for eachof the most highly ranked variant of the feature typesthat appear on the top 20 ranks according to Chi-square ranking (Table 6).
Thus, we can have an ideain how far the high performing feature types differ.We only display one feature per feature type due tothe limited space.
The table shows that for most ofthese features precision largely outperforms recall.RELBENEF is the only notable exception (its recallactually outperforms precision).5.1.2 Positive Orientation and ReliabilityBy closer inspection of the highly ranked features,we found quite a few features with positive ori-Feature Prec RecFREQ-WNDfood 71.13 14.38AUTH-EC 41.81 15.42STROPO+-WNDcond 63.38 3.54RELBENEF 33.39 39.17INTENSsimple-WNDcond 41.73 11.04PRESC-WNDfood 45.00 5.63Table 7: Precision and recall of different features (we listthe most highly ranked variants of the feature types fromTable 6).entation, i.e.
STROPO+-WNDcond, RELBENEF ,RELSUIT , STROPO+-WNDcond, while their nega-tive counterparts are absent.
This raises the questionwhether there is a bias for positive orientation for thedetection of reliability.We assume that there are different reasons whythe positive suitability-labels (RELBENEF andRELSUIT ) and strong positive polarity (STROPO+)are highly ranked features:As far as polarity features are concerned, it isknown from sentiment analysis that positive polar-ity is usually easier to detect than negative polar-ity (Wiegand et al 2013).
This can largely be as-cribed to social conventions to be less blunt withcommunicating negative sentiment.
For that reason,for example, one often applies negated positive polarexpressions (e.g.
not okay) or irony to express a neg-ative sentiment rather than using an explicit negativepolar expression.
Of course, such implicit types ofnegative polarity are much more difficult to detectautomatically.The highly ranked suitability-labels may be labelswith the same orientation (i.e.
they both describerelationships that a food item is suitable rather thanunsuitable for a particular health condition), yet theyhave quite different properties.3 While RELBENEFis a feature positively correlating with reliable ut-terances, the opposite is true of RELSUIT , that is,there is a correlation but this correlation is nega-tive.
Table 8 compares their respective precisionand also includes the trivial (reference) classifier allthat always predicts a reliable statement.
The ta-ble clearly shows that RELBENEF is above the triv-3It is not the case that the proportion of reliable utterancesis larger among the entire set of instances tagged with positivesuitability-labels than among the instances tagged with negativesuitability-labels (Table 1).
In both cases, they are at approx.26%.75ial feature while RELSUIT is clearly below.
(Onemay wonder why the gap in precision between thosedifferent features is not larger.
These features arealso high-recall features ?
we have shown this forRELBENEF in Table 7 ?
so the smaller gaps mayalready have a significant impact.)
In plain, thisresult means that a statement conveying that somefood item alleviates the symptoms of a particulardisease or even cures it (RELBENEF ) is more likelyto be an utterance that is perceived reliable ratherthan statements in which the speaker merely statesthat the food item is suitable given a particular healthcondition (RELSUIT ).
Presumably, the latter typeof suitability-relations are mostly uttered parenthet-ically (not emphatically), or they are remarks inwhich the relation is inferred, so that they are un-likely to provide further background information.
InSentence (20), for example, the suitability of whole-meal products is inferred as the speaker?s father eatsthese types of food due to his diabetes.
The focusof this remark, however, is the psychic well-being ofthe speaker?s father.
That entire utterance does notpresent any especially reliable or otherwise helpfulinformation regarding the relationship between dia-betes and wholemeal products.
(20) My father suffers from diabetes and is fed upwith eating all these wholemeal products.
Weare worried that he is going to fall into a de-pression.Having explained that the two (frequently occur-ring) positive suitability-labels are highly rankedfeatures because they separate reliable from less re-liable statements, one may wonder why we do notfind a similar behaviour on the negative suitability-labels.
The answer to this lies in the fact that thereis no similar distinction between RELBENEF andRELSUIT among utterances expressing unsuitabil-ity.
There is no neutral negative suitability-labelsimilar to RELSUIT .
The relation RELUNSUITexpresses unsuitability which is usually connectedwith some deterioration in health.5.1.3 How important are explanatorystatements for this task?We were very surprised that the feature type toindicate explanatory statements EXPL (?4.1.1) per-formed very poorly (none of its variants is listed inFeature RELSUIT all RELBENEFPrec 17.81 26.46 33.39Table 8: The precision of different REL-features com-pared to the trivial classifier all that always predicts a re-liable utterance.Type EXPLall EXPLcuePercentage 22.59 8.30Table 9: Proportion of explanatory statements among re-liable utterances (EXPLall: all reliable instances that areexplanatory statements; EXPLcue: subset of explanatorystatements that also contain a lexical cue).Table 6) since we assumed explanatory statementsto be one of the most relevant types of utterances.In order to find a reason for this, we manually an-notated all reliable utterances as to whether they canbe regarded as an explanatory statement (EXPLall)and, if so, whether (in principle) there are lexicalcues (such as our set of conjunctions) to identifythem (EXPLcue).
Table 9 shows the proportion ofthese two categories among the reliable utterances.With more than 20% being labeled as this subtype,explanatory statements are clearly not a fringe phe-nomenon.
However, lexical cues could only be ob-served in approximately 1/3 of those instances.
Themajority of cases, such as Sentence (21), do not con-tain any lexical cues and are thus extremely difficultto detect.
(21) Citrus fruits are bad for dermatitis.
They in-crease the itch.
Such fruits are rich in acids thatirritate your skin.In addition, all variants of our feature type EXPLhave a poor precision (between 20 ?
25%).
Thismeans that the underlying lexical cues are too am-biguous.5.1.4 How important are the differentcontextual scopes?Table 6 clearly shows that the contextual scopeof a feature type matters.
For example, for the fea-ture type FREQ, the most effective scope achievesa Chi-square score of 105.1 while the worst vari-ant only achieves a score of 29.2.
However, thereis no unique contextual scope which always outper-forms the other variants.
This is mostly due to the76Feature Set Prec Rec F1all 26.46 100.00 41.85bow 37.14 62.44 46.45bow+pos 36.85 57.64 44.88bow+synt 39.05 58.01 46.58task 35.16 72.89 47.21bow+task 42.54 66.01 51.56?Table 10: Comparison of different feature sets (summaryof features is displayed in Table 5); ?
significantly betterthan bow at p < 0.05 (based on paired t-test).fact the different feature types have different proper-ties.
On the one hand, there are unambiguous fea-ture types, such as AUTH, which work fine witha wide scope.
But we also have ambiguous fea-ture types that require a fairly narrow context.
Atypical example are strong (positive) polar expres-sions (STROPO+).
(Polar expressions are knownto be very ambiguous (Wiebe and Mihalcea, 2006;Akkaya et al 2009).
)5.2 ClassificationTable 10 compares the different feature sets withregard to extraction performance.
We carry outa 5-fold cross-validation on our manually labeleddataset.
As a classifier, we chose Support VectorMachines (Joachims, 1999).
As a toolkit, we useSVMLight4 with a linear kernel.Table 10 clearly shows the strength of the high-level features that we proposed.
They do not onlyrepresent a strong feature set on their own but theycan also usefully be combined with bag-of-wordsfeatures.
Apparently, neither part-of-speech norparse information are predictive for this task.5.3 Impact of Training DataFigure 1 compares bag-of-words features and ourtask-specific high-level features on a learning curve.The curve shows that the inclusion of our task-specific features improves performance.
Interest-ingly, with task alone we obtain a good performanceon smaller amounts of data.
However, this classifieris already saturated with 40% of the training data.From then onwards, it is more effective to use thecombination bow+task.
Our high-level features gen-eralize well which is particularly important for situ-ations in which only few training data are available.4http://svmlight.joachims.org2530354045505510  20  30  40  50  60  70  80  90  100F-scorePercentage of training databag of words (bow)task-specific high-level features (task)combination (bow+task)Figure 1: Learning curve of the different feature sets.However, in situations in which large training setsare available, we additionally need bag of words thatare able to harness more sparse but specific informa-tion.6 ConclusionIn this paper, we examined a set of task-specifichigh-level features in order to detect food-health re-lations that are perceived reliable.
We found that,in principle, a subset of these features that includeadverbials expressing frequent observations, state-ments made by authorities, strong polar expressionsand intensifiers are fairly predictive and complementbag-of-words information.
We also observed a cor-relation between some suitability-labels and relia-bility.
Moreover, the effectiveness of the differentfeatures depends very much on the context to whichthey are applied.AcknowledgementsThis work was performed in the context of the Software-Cluster project EMERGENT.
Michael Wiegand wasfunded by the German Federal Ministry of Education andResearch (BMBF) under grant no.
?01IC10S01?.
Theauthors would like to thank Stephanie Ko?ser for annotat-ing the dataset presented in the paper.
The authors wouldalso like to thank Prof. Dr. Wolfgang Menzel for provid-ing the German version of the SO-CAL polarity lexiconthat has been developed at his department.77ReferencesCem Akkaya, Janyce Wiebe, and Rada Mihalcea.
2009.Subjectivity Word Sense Disambiguation.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), pages 190?199,Singapore.Ernesto Diaz-Aviles, Avar Stewart, Edward Velasco, Ker-stin Denecke, and Wolfgang Nejdl.
2012.
EpidemicIntelligence for the Crowd, by the Crowd.
In Proceed-ings of the International AAAI Conference on Weblogsand Social Media (ICWSM), Dublin, Ireland.Marco Fisichella, Avar Stewart, Alfredo Cuzzocrea, andKerstin Denecke.
2011.
Detecting Health Events onthe Social Web to Enable Epidemic Intelligence.
InProceedings of the International Symposium on StringProcessing and Information Retrieval (SPIRE), pages87?103, Pisa, Italy.Birgit Hamp and Helmut Feldweg.
1997.
GermaNet - aLexical-Semantic Net for German.
In Proceedings ofACL workshop Automatic Information Extraction andBuilding of Lexical Semantic Resources for NLP Ap-plications, pages 9?15, Madrid, Spain.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the Semantic Orientation of Adjec-tives.
In Proceedings of the Conference on EuropeanChapter of the Association for Computational Linguis-tics (EACL), pages 174?181, Madrid, Spain.Vasileios Hatzivassiloglou and Janyce Wiebe.
2000.
Ef-fects of Adjective Orientation and Gradability on Sen-tence Subjectivity.
In Proceedings of the InternationalConference on Computational Linguistics (COLING),pages 299?305, Saarbru?cken, Germany.Thorsten Joachims.
1999.
Making Large-Scale SVMLearning Practical.
In B. Scho?lkopf, C. Burges, andA.
Smola, editors, Advances in Kernel Methods - Sup-port Vector Learning.
MIT Press.Manfred Klenner, Stefanos Petrakis, and Angela Fahrni.2009.
Robust Compositional Polarity Classification.In Proceedings of Recent Advances in Natural Lan-guage Processing (RANLP), pages 180?184, Borovets,Bulgaria.George Lakoff.
1973.
Hedging: A Study in Media Crite-ria and the Logic of Fuzzy Concepts.
Journal of Philo-sophical Logic, 2:458 ?
508.J.
Richard Landis and Gary G. Koch.
1977.
The Mea-surement of Observer Agreement for Categorical Data.Biometrics, 33(1):159?174.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a Large AnnotatedCorpus of English: The Penn Treebank.
Computa-tional Linguistics, 19(2):313?330, June.
Special Issueon Using Large Corpora.Qingliang Miao, Shu Zhang, Bo Zhang, Yao Meng, andHao Yu.
2012.
Extracting and Visualizing Seman-tic Relationships from Chinese Biomedical Text.
InProceedings of the Pacific Asia Conference on Lan-guage, Information and Compuation (PACLIC), pages99?107, Bali, Indonesia.George Miller, Richard Beckwith, Christiane Fellbaum,Derek Gross, and Katherine Miller.
1990.
Introduc-tion to WordNet: An On-line Lexical Database.
Inter-national Journal of Lexicography, 3:235?244.Roser Morante and Walter Daelemans.
2009.
Learningthe Scope of Hedge Cues in Biomedical Texts.
In Pro-ceedings of the BioNLP Workshop, pages 28?36, Boul-der, CO, USA.Robert Munro, Lucky Gunasekara, Stephanie Nevins,Lalith Polepeddi, and Evan Rosen.
2012.
Track-ing Epidemics with Natural Language Processing andCrowdsourcing.
In Proceedings of the Spring Sympo-sium for Association for the Advancement of ArtificialIntelligence (AAAI), pages 52?58, Toronto, Canada.Anna Rafferty and Christopher D. Manning.
2008.
Pars-ing Three German Treebanks: Lexicalized and Un-lexicalized Baselines.
In Proceedings of the ACLWorkshop on Parsing German (PaGe), pages 40?46,Columbus, OH, USA.Anne Schiller, Simone Teufel, Christine Sto?ckert, andChristine Thielen.
1995.
Vorla?ufige Guidelinesfu?r das Tagging deutscher Textcorpora mit STTS.Technical report, Universita?t Stuttgart, Insitut fu?rmaschinelle Sprachverarbeitung, and Seminar fu?rSprachwissenschaft, Universita?t Tu?bingen.Maite Taboada, Julian Brooke, Milan Tofiloski, KimberlyVoll, and Manfred Stede.
2011.
Lexicon-Based Meth-ods for Sentiment Analysis.
Computational Linguis-tics, 37(2):267 ?
307.Manabu Torii, Lanlan Yin, Thang Nguyen, Chand T.Mazumdar, Hongfang Liu, David M. Hartley, andNoele P. Nelson.
2011.
An exploratory study of a textclassification framework for internet-based surveil-lance of emerging epidemics.
Internal Journal ofMedical Informatics, 80(1):56?66.Willem Robert van Hage, Sophia Katrenko, and GuusSchreiber.
2005.
A Method to Combine LinguisticOntology-Mapping Techniques.
In Proceedings of In-ternational Semantic Web Conference (ISWC), pages732 ?
744, Galway, Ireland.
Springer.Willem Robert van Hage, Hap Kolb, and Guus Schreiber.2006.
A Method for Learning Part-Whole Relations.In Proceedings of International Semantic Web Con-ference (ISWC), pages 723 ?
735, Athens, GA, USA.Springer.Willem Robert van Hage, Margherita Sini, Lori Finch,Hap Kolb, and Guus Schreiber.
2010.
The OAEI food78task: an analysis of a thesaurus alignment task.
Ap-plied Ontology, 5(1):1 ?
28.Janyce Wiebe and Rada Mihalcea.
2006.
Word Senseand Subjectivity.
In Proceedings of the InternationalConference on Computational Linguistics and AnnualMeeting of the Association for Computational Linguis-tics (COLING/ACL), pages 1065?1072, Syndney, Aus-tralia.Michael Wiegand, Benjamin Roth, and Dietrich Klakow.2012a.
Web-based Relation Extraction for the FoodDomain.
In Proceeding of the International Confer-ence on Applications of Natural Language Process-ing to Information Systems (NLDB), pages 222?227,Groningen, the Netherlands.
Springer.Michael Wiegand, Benjamin Roth, Eva Lasarcyk,Stephanie Ko?ser, and Dietrich Klakow.
2012b.
AGold Standard for Relation Extraction in the Food Do-main.
In Proceedings of the Conference on LanguageResources and Evaluation (LREC), pages 507?514, Is-tanbul, Turkey.Michael Wiegand, Manfred Klenner, and DietrichKlakow.
2013.
Bootstrapping polarity classifiers withrule-based classification.
Language Resources andEvaluation, Online First:1?40.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing Contextual Polarity in Phrase-levelSentiment Analysis.
In Proceedings of the Conferenceon Human Language Technology and Empirical Meth-ods in Natural Language Processing (HLT/EMNLP),pages 347?354, Vancouver, BC, Canada.Ian Witten and Eibe Frank.
2005.
Data Mining: Practi-cal Machine Learning Tools and Techniques.
MorganKaufmann Publishers, San Francisco, US.Yiming Yang and Jan Pederson.
1997.
A ComparativeStudy on Feature Selection in Text Categorization.
InProceedings the International Conference on MachineLearning (ICML), pages 412?420, Nashville, US.Hui Yang, Rajesh Swaminathan, Abhishek Sharma, Vi-las Ketkar, and Jason D?Silva, 2011.
Learning Struc-ture and Schemas from Documents, volume 375 ofStudies in Computational Intelligence, chapter Min-ing Biomedical Text Towards Building a QuantitativeFood-disease-gene Network, pages 205?225.
SpringerBerlin Heidelberg.79
