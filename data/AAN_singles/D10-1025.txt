Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 251?261,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsTranslingual Document Representations from Discriminative ProjectionsJohn C. Platt Kristina ToutanovaMicrosoft Research1 Microsoft WayRedmond, WA 98005, USA{jplatt,kristout,scottyih}@microsoft.comWen-tau YihAbstractRepresenting documents by vectors that areindependent of language enhances machinetranslation and multilingual text categoriza-tion.
We use discriminative training to createa projection of documents from multiple lan-guages into a single translingual vector space.We explore two variants to create these pro-jections: Oriented Principal Component Anal-ysis (OPCA) and Coupled Probabilistic LatentSemantic Analysis (CPLSA).
Both of thesevariants start with a basic model of docu-ments (PCA and PLSA).
Each model is thenmade discriminative by encouraging compa-rable document pairs to have similar vectorrepresentations.
We evaluate these algorithmson two tasks: parallel document retrievalfor Wikipedia and Europarl documents, andcross-lingual text classification on Reuters.The two discriminative variants, OPCA andCPLSA, significantly outperform their corre-sponding baselines.
The largest differences inperformance are observed on the task of re-trieval when the documents are only compa-rable and not parallel.
The OPCA method isshown to perform best.1 IntroductionGiven the growth of multiple languages on the In-ternet, Natural Language Processing must operateon dozens of languages.
It is becoming critical thatcomputers reach high performance on the followingtwo tasks:?
Comparable and parallel document re-trieval ?
Cross-language information retrievaland text categorization have become impor-tant with the growth of the Web (Oard andDiekema, 1998).
In addition, machine trans-lation (MT) systems can be improved bytraining on sentences extracted from paral-lel or comparable documents mined from theWeb (Munteanu and Marcu, 2005).
Compa-rable documents can also be used for learningword-level translation lexicons (Fung and Yee,1998; Rapp, 1999).?
Cross-language text categorization ?
Appli-cations of text categorization, such as sentimentclassification (Pang et al, 2002), are now re-quired to run on multiple languages.
Catego-rization is usually trained on the language ofthe developer: it needs to be easily extended toother languages.There are two broad approaches to comparabledocument retrieval and cross-language text catego-rization.
One approach is to translate queries or atraining set from different languages into a singletarget language.
Standard monolingual retrieval andclassification algorithms can then be applied in thetarget language.Alternatively, a cross-language system can projecta bag-of-words vector into a translingual lower-dimensional vector space.
Ideally, vectors in thisspace represent the semantics of a document, inde-pendent of the language.The advantage of pre-translation is that MT sys-tems tend to preserve the meaning of documents.However, MT can be very slow (more than 1 secondper document), preventing its use on large trainingsets.
When full MT is not practical, a fast word-by-word translation model can be used instead, (Balles-teros and Croft, 1996) but may be less accurate.Conversely, applying a projection into a low-dimensional space is quick.
Linear projection al-gorithms use matrix-sparse vector multiplication,which can be easily parallelized.
However, as seenin section 3, the accuracies of previous projection251techniques are not as high as machine translation.This paper presents two techniques: OrientedPCA and Coupled PLSA.
These techniques retainthe high speed of projection, while approaching orexceeding the quality level of word glossing.
We im-prove the quality of the projections by the use of dis-criminative training: we minimize the difference be-tween comparable documents in the projected vec-tor space.
Oriented PCA minimizes the differenceby modifying the eigensystem of PCA (Diamantarasand Kung, 1996), while Coupled PLSA uses poste-rior regularization (Graca et al, 2008; Ganchev etal., 2009) on the topic assignments of the compara-ble documents.1.1 Previous workThere has been extensive work in projecting mono-lingual documents into a vector space.
The ini-tial algorithm for projecting documents was LatentSemantic Analysis (LSA), which modeled bag-of-word vectors as low-rank Gaussians (Deerwester etal., 1990).
Subsequent projection algorithms werebased on generative models of individual terms inthe documents, including Probabilistic Latent Se-mantic Analysis (PLSA) (Hofmann, 1999) and La-tent Dirichlet Allocation (LDA) (Blei et al, 2003).Work on cross-lingual projections followed a sim-ilar pattern of moving from Gaussian models toterm-wise generative models.
Cross-language La-tent Semantic Indexing (CL-LSI) (Dumais et al,1997) applied LSA to concatenated comparable doc-uments from multiple languages.
Similarly, Polylin-gual Topic Models (PLTM) (Mimno et al, 2009)generalized LDA to tuples of documents from mul-tiple languages.
The experiments in section 3 useCL-LSI and an algorithm similar to PLTM as bench-marks.The closest previous work to this paper is theuse of Canonical Correlation Analysis (CCA) to findprojections for multiple languages whose results aremaximally correlated with each other (Vinokourovet al, 2003).PLSA-, LDA-, and CCA-based cross-lingualmodels have also been trained without the use of par-allel or comparable documents, using only knowl-edge from a translation dictionary to achieve sharingof topics across languages (Haghighi et al, 2008; Ja-garlamudi and Daume?, 2010; Zhang et al, 2010).Such work is complementary to ours and can beused to extend the models to domains lacking par-allel documents.Outside of NLP, researchers have designed al-gorithms to find discriminative projections.
Webuild on the Oriented Principal Component Analysis(OPCA) algorithm (Diamantaras and Kung, 1996),which finds projections that maximize a signal-to-noise ratio (as defined by the user).
OPCA has beenused to create discriminative features for audio fin-gerprinting (Burges et al, 2003).1.2 Structure of paperThis paper now presents two algorithms for translin-gual document projection (in section 2): OPCA andCoupled PLSA (CPLSA).
To explain OPCA, wefirst review CL-LSI in section 2.1, then discuss thedetails of OPCA (section 2.2), and compare it toCCA (section 2.3).
To explain CPLSA, we firstintroduce Joint PLSA (JPLSA), analogous to CL-LSI, in section 2.4, and then describe the details ofCPLSA (section 2.5).We have evaluated these algorithms on two dif-ferent tasks: comparable document retrieval (sec-tion 3.2) and cross-language text categorization(section 3.3).
We discuss the findings of the evalua-tions and extensions to the algorithms in section 4.2 Algorithms for translingual documentprojection2.1 Cross-language Latent Semantic IndexingCross-language Latent Semantic Indexing (CL-LSI)is Latent Semantic Analysis (LSA) applied to multi-ple languages.
First, we review the mathematics ofLSA.LSA models an n ?
k document-term matrix D,where n is the number of documents and k is thenumber of terms.
The model of the document-termmatrix is a low-rank Gaussian.
Originally, LSA waspresented as performing a Singular Value Decompo-sition (Deerwester et al, 1990), but here we presentit as eigendecomposition, to clarify its relationshipwith OPCA.LSA first computes the correlation matrix be-tween terms:C = DTD.
(1)252The Rayleigh quotient for a vector ~v with the matrixC is~vTC~v~vT~v, (2)and is equal to the variance of the data projected us-ing the vector ~v, normalized by the length of ~v, if Dhas columns that are zero mean.
Good projectionsretain a large amount of variance.
LSA maximizesthe Rayleigh ratio by taking its derivative against ~vand setting it to zero.
This yields a set of projectionsthat are eigenvectors of C,C~vj = ?j~vj , (3)where ?j is the jth-largest eigenvalue.
Each eigen-value is also the variance of the data when projectedby the corresponding eigenvector ~vj .
LSA simplyuses top d eigenvectors as projections.LSA is very similar to Principal ComponentsAnalysis (PCA).
The only difference is that the cor-relation matrix C is used, instead of the covariancematrix.
In practice, the document-term matrix D issparse, so the column means are close to zero, andthe correlation matrix is close to the covariance ma-trix.There are a number of methods to form thedocument-term matrix D. One method that workswell in practice is to compute the log(tf)-idf weight-ing: (Dumais, 1990; Wild et al, 2005)Dij = log2(fij + 1) log2(n/dj), (4)where fij is the number of times term j occurs indocument i, n is the total number of documents,and dj is the total number of documents that con-tain term j.
Applying a logarthm to the term countsmakes the distribution of matrix entries approachGaussian, which makes the LSA model more valid.Cross-language LSI is an application of LSAwhere each row of D is formed by concatenatingcomparable or parallel documents in multiple lan-guages.
If a single term occurs in multiple lan-guages, the term only has one slot in the concate-nation, and the term count accumulates for all lan-guages.
Such terms could be proper nouns, such as?Smith?
or ?Merkel?.In general, the elements of D are computed viaDij = log2(?mfmij + 1)log2(n/dj), (5)where fmij is the number of times term j occurs indocument i in language m. Here, dj is the numberof documents term j appears in, and n is the totalnumber of documents across all languages.Because CL-LSI is simply LSA applied to con-catenated documents, it models terms in documentvectors jointly across languages as a single low-rankGaussian.2.2 Oriented Principal Component AnalysisThe limitations of CL-LSI can be illustrated by con-sidering Oriented Principal Components Analysis(OPCA), a generalization of PCA.
A user of OPCAcomputes a signal covariance matrix S and a noisecovariance matrix N. OPCA projections ~vj max-imize the ratio of the variance of the signal pro-jected by ~vj to the variance of the noise projectedby ~vj .
This signal-to-noise ratio is the generalizedRayleigh quotient: (Diamantaras and Kung, 1996)~vTS~v~vTN~v.
(6)Taking the derivative of the Rayleigh quotient withrespect to the projections ~v and setting it to zeroyields the generalized eigenproblemS~vj = ?jN~vj .
(7)This eigenproblem has no local minima, and can besolved with commonly available parallel code.PCA is a specialization of OPCA, where the noisecovariance matrix is assumed to be the identity (i.e.,uncorrelated noise).
PCA projections maximize thesignal-to-noise ratio where the signal is the empiri-cal covariance of the data, and the noise is sphericalwhite noise.
PCA projections are not truly appropri-ate for forming multilingual document projections.Instead, we want multilingual document projec-tions to maximize the projected covariance of doc-ument vectors across all languages, while simulta-neously minimizing the projected distance betweencomparable documents (see Figure 1).
OPCA givesus a framework for finding such discriminative pro-jections.
The covariance matrix for all documentsis the signal covariance in OPCA, and captures themeaning of documents across all languages.
Theprojection of this covariance matrix should be max-imized.
The covariance matrix formed from differ-ences between comparable documents is the noise253covariance in OPCA: we wish to minimize the lat-ter covariance, to make the projection language-independent.Specifically, we create the weighted document-term matrix Dm for each language:Dij,m = log2(fmij + 1)log2(n/dj).
(8)We then derive a signal covariance matrix over alllanguages:S =?mDTmDm/n?
~?Tm~?m, (9)where ~?m is the mean of each Dm over its columns,and a noise covariance matrix,N =?m(Dm ?D)T (Dm ?D)/n+ ?I, (10)where D is the mean across all languages of thedocument-term matrix,D =1M?mDm, (11)and M is the number of languages.
Applying equa-tion (7) to these matrices and taking the top gener-alized eigenvectors yields the projection matrix forOPCA.Note the regularization term of ?I in equation(10).
The empirical sample of comparable docu-ments may not cover the entire space of translationnoise the system will encounter in the test set.
Forsafety, we add a regularizer that prevents the vari-ance of a term from getting too small.
We tuned ?on the development sets in section 3.2: for log(tf)-idf weighted vectors, C = 0.1 works well for thedata sets and dimensionalities that we tried.
We useC = 0.1 for all final tests.2.3 Canonical Correlation AnalysisCanonical Correlation Analysis (CCA) is a tech-nique that is related to OPCA.
CCA was kernelizedand applied to creating cross-language documentmodels by (Vinokourov et al, 2003).
In CCA, a lin-ear projection is found for each language, such thatthe projections of the corpus from each language aremaximally correlated with each other.
Similar toOPCA, this linear projection can be found by find-ing the top generalized eigenvectors of the systemenesen enenes esesMaximizes overall variance?
while minimizing distancebetween comparable pairsFigure 1: OPCA finds a projection that maximizes thevariance of all documents, while minimizing distance be-tween comparable documents(7), where S is now a matrix of cross-correlationsthat the projection maximizes,S =[0 C12C21 0], (12)and N is a matrix of autocorrelations that the projec-tion minimizes,N =[C11 + ?I 00 C22 + ?I].
(13)Here, Cij is the (cross-)covariance matrix, with di-mension equal to the vocabulary size, that is com-puted between the document vectors for languagesi and j. Analogous to OPCA, ?
is a regularizationterm, set by optimizing performance on a validationset.
Like OPCA, these matrices can be generalizedto more than two languages.
Unlike OPCA, CCAfinds projections that maximize the cross-covariancebetween the projected vectors, instead of minimiz-ing Euclidean distance.1By definition, CCA cannot take advantage of theinformation that same term occurs simultaneously incomparable documents.
As shown in section 3, this1Note that the eigenvectors have length equal to the sum ofthe length of the vocabularies of each language.
The projectionsfor each language are created by splitting the eigenvectors intosections, each with length equal to the vocabulary size for eachlanguage.254information is useful and helps OPCA perform bet-ter then CCA.
In addition, CCA encourages compa-rable documents to be projected to vectors that aremutually linearly predictable.
This is not the sameOPCA?s projected vectors that have low Euclideandistance: the latter may be preferred by algorithmsthat consume the projections.2.4 Cross-language Topic ModelsWe now turn to a baseline generative model thatis analogous to CL-LSI.
Our baseline joint PLSAmodel (JPLSA) is closely related to the poly-lingualLDA model of (Mimno et al, 2009).
The graphicalmodel for JPLSA is shown at the top in Figure 2.We describe the model for two languages, but it isstraightforward to generalize to more than two lan-guages, as in (Mimno et al, 2009).zz??ww?TDN1N2zz?1?ww?TDN1N2?2?
?Figure 2: Graphical models for JPLSA (top) and CPLSA(bottom)The model sees documents di as sequences ofwords w1, w2, .
.
.
, wni from a vocabulary V .
Thereare T cross-language topics, each of which has a dis-tribution ?t over words in V .
In the case of mod-els for two languages, we define the vocabulary Vto contain word types from both languages.
In thisway, each topic is shared across languages.Each topic-specific distribution ?t, for t =1 .
.
.
T , is drawn from a symmetric Dirichlet priorwith concentration parameter ?.
Given the topic-specific word distributions, the generative processfor a corpus of paired documents [d1i , d2i ] in two lan-guages L1 and L2 is described in the next paragraph.For each pair of documents, pick a distributionover topics ?i, from a symmetric Dirichlet prior withconcentration parameter ?.
Then generate the doc-uments d1i and d2i in turn.
Each word token in eachdocument is generated independently by first pick-ing a topic z from a multinomial distribution withparameter ?i (MULTI(?i)), and then generating theword token from the topic-specific word distributionfor the chosen topic MULTI(?z).The probability of a document pair [d1, d2] withwords [w11, w12, .
.
.
, w1n1 ], [w21, w22, .
.
.
, w2n2 ], topicassignments [z11 , .
.
.
, z1n1 ], [z21 , .
.
.
, z2n2 ], and a com-mon topic vector ?
is given by:P (?|?
)n1?j=1P (z1j |?
)P (w1j |?z1j )n2?j=1P (z2j |?
)P (w2j |?z2j )The difference between the JPLSA model and thepoly-lingual topic model of (Mimno et al, 2009)is that we merge the vocabularies in the two lan-guages and learn topic-specific word distributionsover these merged vocabularies, instead of havingpairs of topic-specific word distributions, one foreach language, like in (Mimno et al, 2009).
Thusour model is more similar to the CL-LSI model, be-cause it can be seen as viewing a pair of documentsin two languages as one bigger document containingthe words in both documents.Another difference between our model and thepoly-lingual LDA model of (Mimno et al, 2009)is that we use maximum aposteriori (MAP) insteadof Bayesian inference.
Recently, MAP inferencewas shown to perform comparably to the best in-ference method for LDA (Asuncion et al, 2009),if the hyper-parameters are chosen optimally forthe inference method.
Our initial experiments withBayesian versus MAP inference for parallel docu-ment retrieval using JPLSA confirmed this result.In practice our baseline model outperforms poly-lingual LDA as mentioned in our experiments.2.5 Coupled Probabilistic Latent SemanticAnalysisThe JPLSA model assumes that a pair of translatedor comparable documents have a common topic dis-tribution ?.
JPLSA fits its parameters to optimize theprobability of the data, given this assumption.For the task of comparable document retrieval, wewant our topic model to assign similar topic distri-butions ?
to a pair of corresponding documents.
But255this is not exactly what the JPLSA model is doing.Instead, it derives a common topic vector ?
whichexplains the union of all tokens in the English andforeign documents, instead of making sure that thebest topic assignment for the English document isclose to the best topic assignment of the foreign doc-ument.
This difference becomes especially appar-ent when corresponding documents have differentlengths.
In this case, the model will tend to derivea topic vector ?
which explains the longer documentbest, making the sum of the two documents?
log-likelihoods higher.
Modeling the shorter document?sbest topic carries little weight.Modeling both documents equally is what Cou-pled PLSA (CPLSA) is designed to do.
The graphi-cal model for CPLSA is shown at the bottom of Fig-ure 2.
In this figure, the topic vectors of a pair ofdocuments in two languages are shown completelyindependent.
We use the log-likelihood according tothis model, but also add a regularization term, whichtries to make the topic assignments of correspond-ing documents close.
In particular, we use poste-rior regularization (Graca et al, 2008; Ganchev etal., 2009) to place linear constraints on the expec-tations of topic assignments to two correspondingdocuments.For two linked documents d1 and d2, we wouldlike our model to be such that the expected fractionof tokens in d1 that get assigned topic t is approxi-mately the same as the expected fraction of tokens ind2 that get assigned the same topic t, for each topict = 1 .
.
.
T .
This is exactly what we need to makeeach pair of corresponding documents close.Let z1 and z2 denote vectors of topic assignmentsto the tokens in document d1 and d2, respectively.Their dimensionality is equal to the lengths of thetwo documents, n1 and n2.
We define a space ofposterior distributions Q over hidden topic assign-ments to the tokens in d1 and d2, that has the desiredproperty: the expected fraction of each topic is ap-proximately equal in d1 and d2.
We can formulatethis constrained space Q as follows:Q = {q1(z1), q2(z2)}such thatEq1 [?n1j=1 1(z1j = t)n1]?Eq2 [?n2j=1 1(z2j = t)n2] ?
tEq2 [?n2j=1 1(z2j = t)n2]?Eq1 [?n1j=1 1(z1j = t)n1] ?
tWe then formulate an objective function that max-imizes the log-likelihood of the data while simulta-neously minimizing the KL-divergence between thedesired distribution set Q and the posterior distri-bution according to the model: P (z1|d1, ?1, ?)
andP (z2|d2, ?2, ?
).The objective function for a single document pairis as follows:logP (d1|?1, ?)
+ logP (d2|?2, ?
)?KL(Q||P (z1|d1, ?1, ?
), P (z2|d2, ?2, ?
))?||||The final corpus-wide objective is summed overdocument-pairs, and also contains terms for theprobabilities of the parameters ?
and ?
given theDirichlet priors.
The norm of  is minimized, whichmakes the expected proportions of topics in two doc-uments as close as possible.Following (Ganchev et al, 2009), we fit the pa-rameters by an EM-like algorithm, where for eachdocument pair, after finding the posterior distri-bution of the hidden variables, we find the KL-projection of this posterior onto the constraint set,and take expected counts with respect to this projec-tion; these expected counts are used in the M-step.The projection is found using a simple projected gra-dient algorithm.2For both the baseline JPLSA and the CPLSAmodels, we performed learning through MAP infer-ence using EM (with a projection step for CPLSA).We did up to 500 iterations for each model, and didearly stopping based on task performance on the de-velopment set.
The JPLSA model required more it-erations before reaching its peak accuracy, tendingto require around 300 to 450 iterations for conver-gence.
CPLSA required fewer iterations, but eachiteration was slower due to the projection step.2We initialized the models deterministically by assigningeach word to exactly one topic to begin with, such that all topicshave roughly the same number of words.
Words were sorted byfrequency and thus words of similar frequency are more likelyto be assigned to the same topic.This initialization method out-performed random initialization and we use it for all models.256All models use ?
= 1.1 and ?
= 1.01 for thevalues of the concentration parameters.
We foundthat the performance of the models was not very sen-sitive to these values, in the region that we tested(?, ?
?
[1.001, 1.1]).
Higher hyper-parameter val-ues resulted in faster convergence, but the final per-formance was similar across these different values.3 Experimental validationWe test the proposed discriminative projections ver-sus more established cross-language models on thetwo tasks described in the introduction: retrievingcomparable documents from a corpus, and traininga classifier in one language and using it in another.We measure accuracy on a test set, and also examinethe sensitivity to dimensionality of the projection ondevelopment sets.3.1 Speed of training and evaluationWe first test the speed of the various algorithms dis-cussed in this paper, compared to a full machinetranslation system.
When finding document projec-tions, CL-LSI, OPCA, CCA, JPLSA, and CPLSAare equally fast: they perform a matrix multiplica-tion and require O(nk) operations, where n is thenumber of distinct words in the documents and k isthe dimensionality of the projection.3 A single CPUcore can read the indexed documents into memoryand take logarithms at 216K words per second.
Pro-jecting into a 2000-dimensional space operates at41K words per second.
Translating word-by-wordoperates at 274K words per second.
In contrast, ma-chine translation processes 50 words per second, ap-proximately 3 orders of magnitude slower.Total training time for OPCA on 43,380 pairs ofcomparable documents was 90 minutes, running onan 8-core CPU for 2000 dimensions.
On the samecorpus, JPLSA requires 31 minutes per iteration andCPLSA requires 377 minutes per iteration.
CPLSArequires a factor of five times fewer iterations: over-all, it is twice as slow as JPLSA.3.2 Retrieval of comparable documentsIn comparable document retrieval, a query is a doc-ument in one language, which is compared to a cor-3For JPLSA and CPLSA this is the case only when perform-ing a single EM iteration at test time, which we found to per-form best.pus of documents in another language.
By mappingall documents into the same vector space, the com-parison is a vector comparison.
For our experimentswith CL-LSI, OPCA, and CCA, we use cosine sim-ilarity between vectors to rank the documents.For the JPLSA and CPLSA models, we map thedocuments to corresponding topic vectors ?, andcompute distance between these probability vectors.The mapping to topic vectors requires EM iterations,or folding-in (Hofmann, 1999).
We found that per-forming a single EM iteration resulted in best per-formance so we used this for all models.
For com-puting distance we used the L1-norm of the differ-ence, which worked a bit better than the Jensen-Shannon divergence between the topic vectors usedin (Mimno et al, 2009).We test all algorithms on the Europarl data setof documents in English and Spanish, and a set ofWikipedia articles in English and Spanish that con-tain interlanguage links between them (i.e., articlesthat the Wikipedia community have identified ascomparable across languages).For the Europarl data set, we use 52,685 doc-uments as training, 11,933 documents as a devel-opment set, and 18,415 documents as a final testset.
Documents are defined as speeches by a sin-gle speaker, as in (Mimno et al, 2009).4 For theWikipedia set, we use 43,380 training documents,8,675 development documents, and 8,675 final testset documents.For both corpora, the terms are extracted by word-breaking all documents, removing the top 50 mostfrequent terms and keeping the next 20,000 most fre-quent terms.
No stemming or folding is applied.We assess performance by testing each documentin English against all possible documents in Span-ish, and vice versa.
We measure the Top-1 accu-racy (i.e., whether the true comparable is the clos-est in the test set), and the Mean Reciprocal Rankof the true comparable, and report the average per-formance over the two retrieval directions.
Ties arecounted as errors.We tuned the dimensionality of the projections onthe development set, as shown in Figures 3 and 4.4The training section contains documents from the years 96through 99 and the year 02; the dev section contains documentsfrom 01, and the test section contains documents from 00 plusthe first 9 months of 03.257We chose the best dimension on the development setfor each algorithm, and used it on the final test set.The regularization ?
was tuned for CCA: ?
= 10 forEuroparl, and ?
= 3 for Wikipedia.Figure 3: Mean reciprocal rank versus dimension for Eu-roparlFigure 4: Mean reciprocal rank versus dimension forWikipediaIn the two figures, we evaluate the five projec-tion methods, as well as a word-by-word transla-tion method (denoted by WbW in the graphs).
Here?word-by-word?
refers to using cosine distance afterapplying a word-by-word translation model to theSpanish documents.The word-by-word translation model was trainedon the Europarl training set, using the WDHMMmodel (He, 2007), which performs similarly to IBMModel 4.
The probability matrix of generatingEnglish words from Spanish words was multipliedby each document?s log(tf)-idf vector to produce atranslated document vector.
We found that multi-plying the probability matrix to the log(tf)-idf vectorwas more accurate on the development set than mul-tiplying the tf vector directly.
This vector was eithertested as-is, or mapped through LSA learned fromthe English training set of the corpus.
In the figures,the dimensionality of WbW translation refers to thedimensionality of monolingual LSA.The overall ordering of the six models is dif-ferent for the Europarl and Wikipedia developmentdatasets.
The discriminative models outperformthe corresponding generative ones (OPCA vs CL-LSI) and (CPLSA vs JPLSA) for both datasets, andOPCA performs best overall, dominating the bestfast-translation based model, as well as the otherprojection methods, including CCA.On Europarl, JPLSA and CPLSA outperform CL-LSI, with the best dimension or JPLSA also slightlyoutperforming the best setting for the word-by-wordtranslation model, whereas on Wikipedia the PLSA-based models are significantly worse than the othermodels.The results on the final test set, evaluating eachmodel using its best dimensionality setting, confirmthe trends observed on the development set.
The fi-nal results are shown in Tables 1 and 2.
For theseexperiments, we use the unpaired t-test with Bon-ferroni correction to determine the smallest set ofalgorithms that have statistically significantly betteraccuracy than the rest.
The p-value threshold for sig-nificance is chosen to be 0.05.
The accuracies forthese significantly superior algorithms are shown inboldface.For Wikipedia and Europarl, we include an ad-ditional baseline model,?Untranslated?
: this refersto applying cosine distance to both the Spanish andEnglish documents directly (since they share somevocabulary terms).
For Wikipedia, comparable doc-uments seem to share many common terms, so co-sine distance between untranslated documents is areasonable benchmark.From the final Europarl results we can see that thebest models can learn to retrieve parallel documentsfrom the narrow Europarl domain very well.
Alldimensionality reduction methods can learn from258cleanly parallel data, but discriminative training canbring additional error reduction.In previously reported work, (Mimno et al, 2009)evaluate parallel document retrieval using PLTM onEuroparl speeches in English and Spanish, usingtraining and test sets of size similar to ours.
Theyreport an accuracy of 81.2% when restricting to testdocuments of length at least 100 and using 50 topics.JPLSA with 50 topics obtains accuracy of 98.9% fordocuments of that length.The final Wikipedia results are also similar to thethe development set results.
The problem setting forWikipedia is different, because corresponding doc-uments linked in Wikipedia may have widely vary-ing degrees of parallelism.
While most linked doc-uments share some main topics, they could coverdifferent numbers of sub-topics at varying depths.Thus the training data of linked documents is noisy,which makes it hard for projection methods to learn.The word-by-word translation model in this settingis trained on clean, but out-of-domain parallel data(Europarl), so it has the disadvantage that it may nothave a good coverage of the vocabulary; however,it is not able to make use of the Wikipedia train-ing data since it requires sentence-aligned transla-tions.
We find it encouraging that the best projectionmethod OPCA outperformed word-by-word trans-lation.
This means that OPCA is able to uncovertopic correspondence given only comparable docu-ment pairs, and to learn well in this noisy setting.The PLSA-based models fare worse on Wikipediadocument retrieval.
CPLSA outperforms JPLSAmore strongly, but both are worse than CL-LSI andeven the Untranslated baseline.
We think this ispartly explained by the diverse vocabulary in the het-erogenous Wikipedia collection.
All other modelsuse log(tf)-idf weighting, which automatically as-signs importance weights to terms, whereas the topicmodels use word counts.
This weighting is very use-ful for Wikipedia.
For example, if we apply theuntranslated matching using raw word counts, theMRR is 0.1024 on the test set, compared to 0.5383for log(tf)-idf.
We hypothesize that using a hierar-chical topic model that automatically learns aboutmore general and more topic-specific words wouldbe helpful in this case.
It is also possible that PLSA-based models require cleaner data to learn well.The overall conclusion is that OPCA outper-Algorithm Dimension Accuracy MRROPCA 1000 0.9742 0.9806CPLSA 1000 0.9716 0.9782Word-by-word N/A 0.9707 0.9779Word-by-word 5000 0.9706 0.9778JPLSA 1000 0.9645 0.9726CCA 1500 0.9613 0.9705CL-LSI 3000 0.9457 0.9595Untranslated N/A 0.1595 0.2564Table 1: Test results for comparable document retrievalin Europarl.
Boldface indicates statistically significantsuperior results.Algorithm Dimension Accuracy MRROPCA 2000 0.7255 0.7734Word-by-word N/A 0.7033 0.7467CCA 1500 0.6894 0.7378Word-by-word 5000 0.6786 0.7236CL-LSI 5000 0.5302 0.6130Untranslated N/A 0.4692 0.5383CPLSA 200 0.4579 0.5130JPLSA 1000 0.3322 0.3619Table 2: Test results for comparable document retrievalin Wikipedia.
Boldface indicates statistically significantbest result.formed all other document retrieval methods wetested, including fast machine translation of docu-ments.
Additionally, both discriminative projectionmethods outperformed their generative counterparts.3.3 Cross-language text classificationThe second task is to train a text categorization sys-tem in one language, and test it with documents inanother.
To evaluate on this task, we use the Mul-tilingual Reuters Collection, defined and providedby (Amini et al, 2009).
We test the English/Spanishlanguage pair.
The collection has news articles inEnglish and Spanish, each of which has been trans-lated to the other by the Portage translation sys-tem (Ueffing et al, 2007).From the English news corpus, we take 13,131documents as training, 1,875 documents as develop-ment, and 1,875 documents as test.
We take the En-glish training documents translated into Spanish asour comparable training data.
For testing, we use theentire Spanish news corpus of 12,342 documents, ei-259ther mapped with cross-lingual projection, or trans-lated by Portage.The data set was provided by (Amini et al,2009) as already-processed document vectors, usingBM25 weighting.
Thus, we only test OPCA, CL-LSI, and related methods: JPLSA and CPLSA re-quire modeling the term counts directly.The performance on the task is measured by clas-sification accuracy on the six disjoint category la-bels defined by (Amini et al, 2009).
To introduceminimal bias due to the classifier model, we use 1-nearest neighbor on top of the cosine distance be-tween vectors as a classifier.
For all of the tech-niques, we treated the vocabulary in each languageas completely separate, using the top 10,000 termsfrom each language.Note that no Spanish labeled data is providedfor training any of these algorithms: only Englishand translated English news is labeled.
The op-timal dimension (and ?
for CCA) on the devel-opment set was chosen to maximize the accuracyof English classification and translated English-to-Spanish classification.Algorithm Dim.
English SpanishAccuracy AccuracyFull MT 50 0.8483 0.6484OPCA 100 0.8412 0.5954Word-by-word 50 0.8483 0.5780CCA 150 0.8388 0.5384Full MT N/A 0.8046 0.5323CL-LSI 150 0.8401 0.5105Word-by-word N/A 0.8046 0.4481Table 3: Test results for cross-language text categoriza-tionThe test classification accuracy is shown in Ta-ble 3.
As above, the smallest set of superior al-gorithms as determined by Bonferroni-corrected t-tests are shown in boldface.
The results for MT andword-by-word translation use the log(tf)-idf vectordirectly for documents that were written in English,and use a Spanish-to-English translated vector if thedocument was written in Spanish.
As in section 3.2,word-by-word translation multiplied each log(tf)-idfvector by the translation probability matrix trainedon Europarl.The tests show that OPCA is better than CCA,CL-LSI, plain word-by-word translation, and evenfull translation for Spanish documents.
However,if we post-process full translation by an LSI modeltrained on the English training set, full translationis the most accurate.
If full translation is time-prohibitive, then OPCA is the best method: it is sig-nificantly better than word-by-word translation fol-lowed by LSI.4 Discussion and ExtensionsOPCA extends naturally to multiple languages.However, it requires memory and computation timethat scales quadratically with the size of the vocab-ulary.
As the number of languages goes up, it maybecome impractical to perform OPCA directly on alarge vocabulary.Researchers have solved the problem of scalingOPCA by using Distortion Discriminant Analysis(DDA) (Burges et al, 2003).
DDA performs OPCAin two stages which avoids the need for solving avery large generalized eigensystem.
As future work,DDA could be applied to mapping documents inmany languages simultaneously.Spherical Admixture Models (Reisinger et al,2010) have recently been proposed that combine anLDA-like hierarchical generative model with the useof tf-idf representations.
A similar model could beused for CPLSA: future work will show whethersuch a model can outperform OPCA.5 ConclusionsThis paper presents two different methods for creat-ing discriminative projections: OPCA and CPLSA.Both of these methods avoid the use of artificialconcatenated documents.
Instead, they model docu-ments in multiple languages, with the constraint thatcomparable documents should map to similar loca-tions in the projected space.When compared to other techniques, OPCA hadthe highest accuracy while still having a run-timethat allowed scaling to large data sets.
We thereforerecommend the use of OPCA as a pre-processingstep for large-scale comparable document retrievalor cross-language text categorization.260ReferencesMassih-Reza Amini, Nicolas Usunier, and Cyril Goutte.2009.
Learning from multiple partially observedviews - an application to multilingual text categoriza-tion.
In Advances in Neural Information ProcessingSystems 22 (NIPS 2009), pages 28?36.Arthur Asuncion, Max Welling, Padhraic Smyth, andYee Whye Teh.
2009.
On smoothing and inferencefor topic models.
In Proceedings of Uncertainty in Ar-tificial Intelligence, pages 27?34.Lisa Ballesteros and Bruce Croft.
1996.
Dictionarymethods for cross-lingual information retrieval.
InProceedings of the 7th International DEXA Confer-ence on Database and Expert Systems Applications,pages 791?801.David M. Blei, Andrew Y. Ng, Michael I. Jordan, andJohn Lafferty.
2003.
Latent Dirichlet alocation.Journal of Machine Learning Research, 3:993?1022.Christopher J.C. Burges, John C. Platt, and Soumya Jana.2003.
Distortion discriminant analysis for audio fin-gerprinting.
IEEE Transactions on Speech and AudioProcessing, 11(3):165?174.Scott Deerwester, Susan T. Dumais, George W. Furnas,Thomas K. Landauer, and Richard Harshman.
1990.Indexing by latent semantic analysis.
Journal of theAmerican Society for Information Science, 41(6):391?407.Konstantinos I. Diamantaras and S.Y.
Kung.
1996.
Prin-cipal Component Neural Networks: Theory and Appli-cations.
Wiley-Interscience.Susan T. Dumais, Todd A. Letsche, Michael L. Littman,and Thomas K. Landauer.
1997.
Automatic cross-language retrieval using latent semantic indexing.
InAAAI-97 Spring Symposium Series: Cross-LanguageText and Speech Retrieval.Susan T. Dumais.
1990.
Enhancing performance in la-tent semantic indexing (LSI) retrieval.
Technical Re-port TM-ARH-017527, Bellcore.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compa-rable texts.
In Proceedings of COLING-ACL, pages414?420.Kuzman Ganchev, Joao Graca, Jennifer Gillenwater, andBen Taskar.
2009.
Posterior regularization for struc-tured latent variable models.
Technical Report MS-CIS-09-16, University of Pennsylvania.Joao Graca, Kuzman Ganchev, and Ben Taskar.
2008.Expectation maximization and posterior constraints.In J.C. Platt, D. Koller, Y.
Singer, and S. Roweis, edi-tors, Advances in Neural Information Processing Sys-tems 20, pages 569?576.
MIT Press, Cambridge, MA.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proc.
ACL, pages 771?779.Xiaodong He.
2007.
Using word-dependent transitionmodels in HMM based word alignment for statisticalmachine translation.
In ACL 2nd Statistical MT work-shop, pages 80?87.Thomas Hofmann.
1999.
Probabilistic latent semanticanalysis.
In Proceedings of Uncertainty in ArtificialIntelligence, pages 289?296.Jagadeesh Jagarlamudi and Hal Daume?, III.
2010.
Ex-tracting multilingual topics from unaligned compara-ble corpora.
In ECIR.David Mimno, Hanna W. Wallach, Jason Naradowsky,David A. Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of Empir-ical Methods in Natural Language Processing, pages880?889.Dragos Stefan Munteanu and Daniel Marcu.
2005.
Im-proving machine translation performance by exploit-ing non-parallel corpora.
Computational Linguistics,31:477?504.Douglas W. Oard and Anne R. Diekema.
1998.
Cross-language information retrieval.
In Martha Williams,editor, Annual Review of Information Science (ARIST),volume 33, pages 223?256.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification using ma-chine learning techniques.
In Proc.
EMNLP, pages79?86.Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated English and German cor-pora.
In Proceedings of the ACL, pages 519?526.Joseph Reisinger, Austin Waters, Bryan Silverthorn, andRaymond J. Mooney.
2010.
Spherical topic models.In Proc.
ICML.Nicola Ueffing, Michel Simard, Samuel Larkin, andJ.
Howard Johnson.
2007.
NRC?s PORTAGE systemfor WMT 2007.
In ACL-2007 2nd Workshop on SMT,pages 185?188.Alexei Vinokourov, John Shawe-Taylor, and Nello Cris-tianini.
2003.
Inferring a semantic representationof text via cross-language correlation analysis.
InS.
Thrun S. Becker and K. Obermayer, editors, Ad-vances in Neural Information Processing Systems 15,pages 1473?1480, Cambridge, MA.
MIT Press.Fridolin Wild, Christina Stahl, Gerald Stermsek, andGustaf Neumann.
2005.
Parameters driving effective-ness of automated essay scoring with LSA.
In Pro-ceedings 9th Internaional Computer-Assisted Assess-ment Conference, pages 485?494.Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai.
2010.Cross-lingual latent topic extraction.
In Proc.
ACL,pages 1128?1137, Uppsala, Sweden.
Association forComputational Linguistics.261
