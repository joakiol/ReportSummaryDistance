Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 193?199,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsThe RWTH Aachen Machine Translation System for WMT 2013Stephan Peitz, Saab Mansour, Jan-Thorsten Peter, Christoph Schmidt,Joern Wuebker, Matthias Huck, Markus Freitag and Hermann NeyHuman Language Technology and Pattern Recognition GroupComputer Science DepartmentRWTH Aachen UniversityD-52056 Aachen, Germany<surname>@cs.rwth-aachen.deAbstractThis paper describes the statistical ma-chine translation (SMT) systems devel-oped at RWTH Aachen University forthe translation task of the ACL 2013Eighth Workshop on Statistical MachineTranslation (WMT 2013).
We partici-pated in the evaluation campaign for theFrench-English and German-English lan-guage pairs in both translation directions.Both hierarchical and phrase-based SMTsystems are applied.
A number of dif-ferent techniques are evaluated, includinghierarchical phrase reordering, translationmodel interpolation, domain adaptationtechniques, weighted phrase extraction,word class language model, continuousspace language model and system combi-nation.
By application of these methodswe achieve considerable improvementsover the respective baseline systems.1 IntroductionFor the WMT 2013 shared translation task1RWTH utilized state-of-the-art phrase-based andhierarchical translation systems as well as an in-house system combination framework.
We givea survey of these systems and the basic meth-ods they implement in Section 2.
For boththe French-English (Section 3) and the German-English (Section 4) language pair, we investigateseveral different advanced techniques.
We con-centrate on specific research directions for eachof the translation tasks and present the respec-tive techniques along with the empirical resultsthey yield: For the French?English task (Sec-tion 3.2), we apply a standard phrase-based sys-tem with up to five language models including a1http://www.statmt.org/wmt13/translation-task.htmlword class language model.
In addition, we em-ploy translation model interpolation and hierarchi-cal phrase reordering.
For the English?Frenchtask (Section 3.1), we train translation mod-els on different training data sets and augmentthe phrase-based system with a hierarchical re-ordering model, a word class language model,a discriminative word lexicon and a insertionand deletion model.
For the German?English(Section 4.3) and English?German (Section 4.4)tasks, we utilize morpho-syntactic analysis to pre-process the data (Section 4.1), domain-adaptation(Section 4.2) and a hierarchical reordering model.For the German?English task, an augmented hi-erarchical phrase-based system is set up and werescore the phrase-based baseline with a continu-ous space language model.
Finally, we perform asystem combination.2 Translation SystemsIn this evaluation, we employ phrase-based trans-lation and hierarchical phrase-based translation.Both approaches are implemented in Jane (Vilar etal., 2012; Wuebker et al 2012), a statistical ma-chine translation toolkit which has been developedat RWTH Aachen University and is freely avail-able for non-commercial use.22.1 Phrase-based SystemIn the phrase-based decoder (source cardinalitysynchronous search, SCSS), we use the standardset of models with phrase translation probabilitiesand lexical smoothing in both directions, word andphrase penalty, distance-based distortion model,an n-gram target language model and three bi-nary count features.
Optional additional modelsused in this evaluation are the hierarchical reorder-ing model (HRM) (Galley and Manning, 2008), aword class language model (WCLM) (Wuebker et2http://www.hltpr.rwth-aachen.de/jane/193al., 2012), a discriminative word lexicon (DWL)(Mauser et al 2009), and insertion and deletionmodels (IDM) (Huck and Ney, 2012).
The param-eter weights are optimized with minimum errorrate training (MERT) (Och, 2003).
The optimiza-tion criterion is BLEU.2.2 Hierarchical Phrase-based SystemIn hierarchical phrase-based translation (Chiang,2007), a weighted synchronous context-free gram-mar is induced from parallel text.
In addition tocontinuous lexical phrases, hierarchical phraseswith up to two gaps are extracted.
The search iscarried out with a parsing-based procedure.
Thestandard models integrated into our Jane hierar-chical systems (Vilar et al 2010; Huck et al2012c) are: phrase translation probabilities andlexical smoothing probabilities in both translationdirections, word and phrase penalty, binary fea-tures marking hierarchical phrases, glue rule, andrules with non-terminals at the boundaries, fourbinary count features, and an n-gram languagemodel.
Optional additional models comprise IBMmodel 1 (Brown et al 1993), discriminative wordlexicon and triplet lexicon models (Mauser et al2009; Huck et al 2011), discriminative reorderingextensions (Huck et al 2012a), insertion and dele-tion models (Huck and Ney, 2012), and severalsyntactic enhancements like preference grammars(Stein et al 2010) and soft string-to-dependencyfeatures (Peter et al 2011).
We utilize the cubepruning algorithm for decoding (Huck et al 2013)and optimize the model weights with MERT.
Theoptimization criterion is BLEU.2.3 System CombinationSystem combination is used to produce consensustranslations from multiple hypotheses generatedwith different translation engines.
First, a wordto word alignment for the given single system hy-potheses is produced.
In a second step a confusionnetwork is constructed.
Then, the hypothesis withthe highest probability is extracted from this con-fusion network.
For the alignment procedure, oneof the given single system hypotheses is chosen asprimary system.
To this primary system all otherhypotheses are aligned using the METEOR (Lavieand Agarwal, 2007) alignment and thus the pri-mary system defines the word order.
Once thealignment is given, the corresponding confusionnetwork is constructed.
An example is given inFigure 1.The model weights of the system combinationare optimized with standard MERT on 100-bestlists.
For each single system, a factor is added tothe log-linear framework of the system combina-tion.
Moreover, this log-linear model includes aword penalty, a language model trained on the in-put hypotheses, a binary feature which penalizesword deletions in the confusion network and a pri-mary feature which marks the system which pro-vides the word order.
The optimization criterion is4BLEU-TER.2.4 Other Tools and TechniquesWe employ GIZA++ (Och and Ney, 2003) to trainword alignments.
The two trained alignments areheuristically merged to obtain a symmetrized wordalignment for phrase extraction.
All languagemodels (LMs) are created with the SRILM toolkit(Stolcke, 2002) and are standard 4-gram LMswith interpolated modified Kneser-Ney smooth-ing (Kneser and Ney, 1995; Chen and Goodman,1998).
The Stanford Parser (Klein and Manning,2003) is used to obtain parses of the training datafor the syntactic extensions of the hierarchical sys-tem.
We evaluate in truecase with BLEU (Papineniet al 2002) and TER (Snover et al 2006).2.5 Filtering of the Common Crawl CorpusThe new Common Crawl corpora contain a largenumber of sentences that are not in the labelledlanguage.
To clean these corpora, we first ex-tracted a vocabulary from the other provided cor-pora.
Then, only sentences containing at least70% word from the known vocabulary were kept.In addition, we discarded sentences that containmore words from target vocabulary than sourcevocabulary on the source side.
These heuristicsreduced the French-English Common Crawl cor-pus by 5,1%.
This filtering technique was also ap-plied on the German-English version of the Com-mon Crawl corpus.3 French?English SetupsWe trained phrase-based translation systems forFrench?English and for English?French.
Cor-pus statistics for the French-English parallel dataare given in Table 1.
The LMs are 4-grams trainedon the provided resources for the respective lan-guage (Europarl, News Commentary, UN, 109,Common Crawl, and monolingual News Crawl194015:that/17:this/323:is/38:was/130:*EPS*/34:it/140:*EPS*/32:in/150:*EPS*/36:the/160:*EPS*/11:future/3Figure 1: Confusion network of four different hypotheses.Table 1: Corpus statistics of the preprocessedFrench-English parallel training data.
EPPS de-notes Europarl, NC denotes News Commentary,CC denotes Common Crawl.
In the data, numeri-cal quantities have been replaced by a single cate-gory symbol.French EnglishEPPS Sentences 2.2M+ NC Running Words 64.7M 59.7MVocabulary 153.4K 132.2KCC Sentences 3.2MRunning Words 88.1M 80.9.0MVocabulary 954.8K 908.0KUN Sentences 12.9MRunning Words 413.3M 362.3MVocabulary 487.1K 508.3K109 Sentences 22.5MRunning Words 771.7M 661.1MVocabulary 1 974.0K 1 947.2KAll Sentences 40.8MRunning Words 1 337.7M 1 163.9MVocabulary 2 749.8K 2 730.1Klanguage model training data).33.1 Experimental Results English?FrenchFor the English?French task, separate translationmodels (TMs) were trained for each of the fivedata sets and fed to the decoder.
Four additionalindicator features are introduced to distinguish thedifferent TMs.
Further, we applied the hierar-chical reordering model, the word class languagemodel, the discriminative word lexicon, and theinsertion and deletion model.
Table 2 shows theresults of our experiments.As a development set for MERT, we use new-stest2010 in all setups.3.2 Experimental Results French?EnglishFor the French?English task, a translation model(TM) was trained on all available parallel data.For the baseline, we interpolated this TM with3The parallel 109 corpus is often also referred to as WMTGiga French-English release 2.an in-domain TM trained on EPPS+NC and em-ployed the hierarchical reordering model.
More-over, three language models were used: The firstlanguage model was trained on the English sideof all available parallel data, the second one onEPPS and NC and the third LM on the News Shuf-fled data.
The baseline was improved by adding afourth LM trained on the Gigaword corpus (Ver-sion 5) and a 5-gram word class language modeltrained on News Shuffled data.
For the WCLM,we used 50 word classes clustered with the toolmkcls (Och, 2000).
All results are presented in Ta-ble 3.4 German?English SetupsFor both translation directions of the German-English language pair, we trained phrase-basedtranslation systems.
Corpus statistics for German-English can be found in Table 4.
The languagemodels are 4-grams trained on the respective tar-get side of the bilingual data as well as on theprovided News Crawl corpus.
For the Englishlanguage model the 109 French-English, UN andLDC Gigaword Fifth Edition corpora are used ad-ditionally.4.1 Morpho-syntactic AnalysisIn order to reduce the source vocabulary size forthe German?English translation, the German textis preprocessed by splitting German compoundwords with the frequency-based method describedin (Koehn and Knight, 2003).
To further reducetranslation complexity, we employ the long-rangepart-of-speech based reordering rules proposed byPopovic?
and Ney (2006).4.2 Domain AdaptationThis year, we experimented with filtering andweighting for domain-adaptation for the German-English task.
To perform adaptation, we define ageneral-domain (GD) corpus composed from thenews-commentary, europarl and Common Crawlcorpora, and an in-domain (ID) corpus usinga concatenation of the test sets (newstest{2008,2009, 2010, 2011, 2012}) with the correspond-ing references.
We use the test sets as in-domain195Table 2: Results for the English?French task (truecase).
newstest2010 is used as development set.BLEU and TER are given in percentage.newstest2008 newstest2009 newstest2010 newstest2011 newstest2012English?French BLEU TER BLEU TER BLEU TER BLEU TER BLEU TERTM:EPPS + HRM 22.9 63.0 25.0 60.0 27.8 56.7 28.9 54.4 27.2 57.1TM:UN + HRM 22.7 63.4 25.0 60.0 28.3 56.4 29.5 54.2 27.3 57.1TM:109 + HRM 23.5 62.3 26.0 59.2 29.6 55.2 30.3 53.3 28.0 56.4TM:CC + HRM 23.5 62.3 26.2 58.8 29.2 55.3 30.3 53.3 28.2 56.0TM:NC 21.0 64.8 22.3 61.6 25.6 58.7 26.9 56.6 25.7 58.5+ HRM 21.5 64.3 22.6 61.2 26.1 58.4 27.3 56.1 26.0 58.2+ TM:EPPS,CC,UN 23.9 61.8 26.4 58.6 29.9 54.7 31.0 52.7 28.6 55.6+ TM:109 24.0 61.5 26.5 58.4 30.2 54.2 31.1 52.3 28.7 55.3+ WCLM, DWL, IDM 24.0 61.6 26.5 58.3 30.4 54.0 31.4 52.1 28.8 55.2Table 3: Results for the French?English task (truecase).
newstest2010 is used as development set.BLEU and TER are given in percentage.newstest2010 newstest2011 newstest2012French?English BLEU TER BLEU TER BLEU TERSCSS baseline 28.1 54.6 29.1 53.3 - -+ GigaWord.v5 LM 28.6 54.2 29.6 52.9 29.6 53.3+ WCLM 29.1 53.8 30.1 52.5 29.8 53.1(newswire) as the other corpora are coming fromdiffering domains (news commentary, parliamen-tary discussions and various web sources), and oninitial experiments, the other corpora did not per-form well when used as an in-domain representa-tive for adaptation.
To check whether over-fittingoccurs, we measure the results of the adaptedsystems on the evaluation set of this year (new-stest2013) which was not used as part of the in-domain set.The filtering experiments are done similarly to(Mansour et al 2011), where we compare filteringusing LM and a combined LM and IBM Model 1(LM+M1) based scores.
The scores for each sen-tence pair in the general-domain corpus are basedon the bilingual cross-entropy difference of thein-domain and general-domain models.
DenotingHLM (x) as the cross entropy of sentence x ac-cording to LM , then the cross entropy differenceDHLM (x) can be written as:DHLM (x) = HLMID(x)?HLMGD(x)The bilingual cross entropy difference for a sen-tence pair (s, t) in the GD corpus is then definedby:DHLM (s) + DHLM (t)For IBM Model 1 (M1), the cross-entropyHM1(s|t) is defined similarly to the LM cross-entropy, and the resulting bilingual cross-entropydifference will be of the form:DHM1(s|t) + DHM1(t|s)The combined LM+M1 score is obtained bysumming the LM and M1 bilingual cross-entropydifference scores.
To perform filtering, the GDcorpus sentence pairs are scored by the appropri-ate method, sorted by the score, and the n-best sen-tences are then used to build an adapted system.In addition to adaptation using filtering, we ex-periment with weighted phrase extraction similarto (Mansour and Ney, 2012).
We differ from theirwork by using a combined LM+M1 weight to per-form the phrase extraction instead of an LM basedweight.
We use a combined LM+M1 weight asthis worked best in the filtering experiments, mak-ing scoring with LM+M1 more reliable than LMscores only.4.3 Experimental Results German?EnglishFor the German?English task, the baseline istrained on all available parallel data and includesthe hierarchical reordering model.
The results ofthe various filtering and weighting experiments aresummarized in Table 5.196Table 5: German-English results (truecase).
BLEU and TER are given in percentage.
Correspondingdevelopment set is marked with *.
?
labels the single systems selected for the system combination.newstest2009 newstest2010 newstest2011 newstest2012 newstest2013German?English BLEU TER BLEU TER BLEU TER BLEU TER BLEU TERSCSS baseline 21.7 61.1 24.8* 58.9* 22.0 61.1 23.4 60.0 26.1 56.4LM 800K-best 21.6 60.5 24.7* 58.3* 22.0 60.5 23.6 59.7 - -LM+M1 800K-best 21.4 60.5 24.7* 58.1* 22.0 60.4 23.7 59.2 - -(LM+M1)*TM 22.1 60.2 25.4* 57.8* 22.5 60.1 24.0 59.1 - -(LM+M1)*TM+GW 22.8 59.5 25.7* 57.2* 23.1 59.5 24.4 58.6 26.6 55.5(LM+M1)*TM+GW?
22.9* 61.1* 25.2 59.3 22.8 61.5 23.7 60.8 26.4 57.1SCSS baseline 22.6* 61.6* 24.1 60.1 22.1 62.0 23.1 61.2 - -CSLM rescoring?
22.0 60.4 25.1* 58.3* 22.4 60.2 23.9 59.3 26.0 56.0HPBT?
21.9 60.4 24.9* 58.2* 22.3 60.3 23.6 59.6 25.9 56.3system combination - - - - 23.4* 59.3* 24.7 58.5 27.1 55.3Table 6: English-German results (truecase).
newstest2009 was used as development set.
BLEU and TERare given in percentage.newstest2008 newstest2009 newstest2010 newstest2011 newstest2012English?German BLEU TER BLEU TER BLEU TER BLEU TER BLEU TERSCSS baseline 14.9 70.9 14.9 70.4 16.0 66.3 15.4 69.5 15.7 67.5LM 800K-best 15.1 70.9 15.1 70.3 16.2 66.3 15.6 69.4 15.9 67.4(LM+M1) 800K-best 15.8 70.8 15.4 70.0 16.2 66.2 16.0 69.3 16.1 67.4(LM+M1) ifelse 16.1 70.6 15.7 69.9 16.5 66.0 16.2 69.2 16.3 67.2Table 4: Corpus statistics of the preprocessedGerman-English parallel training data (Europarl,News Commentary and Common Crawl).
In thedata, numerical quantities have been replaced by asingle category symbol.German EnglishSentences 4.1MRunning Words 104M 104MVocabulary 717K 750KFor filtering, we use the 800K best sentencesfrom the whole training corpora, as this se-lection performed best on the dev set among100K,200K,400K,800K,1600K setups.
Filteringseems to mainly improve on the TER scores, BLEUscores are virtually unchanged in comparison tothe baseline.
LM+M1 filtering improves furtheron TER in comparison to LM-based filtering.The weighted phrase extraction performs bestin our experiments, where the weights from theLM+M1 scoring method are used.
Improvementsin both BLEU and TER are achieved, with BLEUimprovements ranging from +0.4% up-to +0.6%and TER improvements from -0.9% and up-to -1.1%.As a final step, we added the English Gigawordcorpus to the LM (+GW).
This resulted in furtherimprovements of the systems.In addition, the system as described above wastuned on newstest2009.
Using this developmentset results in worse translation quality.Furthermore, we rescored the SCSS baselinetuned on newstest2009 with a continuous spacelanguage model (CSLM) as described in (Schwenket al 2012).
The CSLM was trained on the eu-roparl and news-commentary corpora.
For rescor-ing, we used the newstest2011 set as tuning set andre-optimized the parameters with MERT on 1000-best lists.
This results in an improvement of up to0.8 points in BLEU compared to the baseline.We compared the phrase-based setups with ahierarchical translation system, which was aug-mented with preference grammars, soft string-to-dependency features, discriminative reorderingextensions, DWL, IDM, and discriminative re-197ordering extensions.
The phrase table of the hier-archical setup has been extracted from News Com-mentary and Europarl parallel data only (not fromCommon Crawl).Finally, three setups were joined in a systemcombination and we gained an improvement of upto 0.5 points in BLEU compared to the best singlesystem.4.4 Experimental Results English?GermanThe results for the English?German task areshown in Table 6.
While the LM-based filter-ing led to almost no improvement over the base-line, the LM+M1 filtering brought some improve-ments in BLEU.
In addition to the sentence fil-tering, we tried to combine the translation modeltrained on NC+EPPS with a TM trained on Com-mon Crawl using the ifelse combination (Mansourand Ney, 2012).
This combination scheme con-catenates both TMs and assigns the probabilitiesof the in-domain TM if it contains the phrase,else it uses the probabilities of the out-of-domainTM.
Appling this method, we achieved further im-provements.5 ConclusionFor the participation in the WMT 2013 sharedtranslation task, RWTH experimented with bothphrase-based and hierarchical translation systems.Several different techniques were evaluated andyielded considerable improvements over the re-spective baseline systems as well as over our lastyear?s setups (Huck et al 2012b).
Among thesetechniques are a hierarchical phrase reorderingmodel, translation model interpolation, domainadaptation techniques, weighted phrase extraction,a word class language model, a continuous spacelanguage model and system combination.AcknowledgmentsThis work was achieved as part of the Quaero Pro-gramme, funded by OSEO, French State agencyfor innovation.ReferencesPeter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation: Pa-rameter Estimation.
Computational Linguistics,19(2):263?311, June.Stanley F. Chen and Joshua Goodman.
1998.
AnEmpirical Study of Smoothing Techniques for Lan-guage Modeling.
Technical Report TR-10-98, Com-puter Science Group, Harvard University, Cam-bridge, Massachusetts, USA, August.David Chiang.
2007.
Hierarchical Phrase-BasedTranslation.
Computational Linguistics, 33(2):201?228.Michel Galley and Christopher D. Manning.
2008.
ASimple and Effective Hierarchical Phrase Reorder-ing Model.
In Proceedings of the 2008 Conferenceon Empirical Methods in Natural Language Pro-cessing, pages 847?855, Honolulu, Hawaii, USA,October.Matthias Huck and Hermann Ney.
2012.
Insertion andDeletion Models for Statistical Machine Translation.In Proceedings of the North American Chapter of theAssociation for Computational Linguistics - HumanLanguage Technologies conference, pages 347?351,Montre?al, Canada, June.Matthias Huck, Saab Mansour, Simon Wiesler, andHermann Ney.
2011.
Lexicon Models for Hierar-chical Phrase-Based Machine Translation.
In Pro-ceedings of the International Workshop on SpokenLanguage Translation (IWSLT), pages 191?198, SanFrancisco, California, USA, December.Matthias Huck, Stephan Peitz, Markus Freitag, andHermann Ney.
2012a.
Discriminative ReorderingExtensions for Hierarchical Phrase-Based MachineTranslation.
In 16th Annual Conference of the Eu-ropean Association for Machine Translation, pages313?320, Trento, Italy, May.Matthias Huck, Stephan Peitz, Markus Freitag, MalteNuhn, and Hermann Ney.
2012b.
The RWTHAachen Machine Translation System for WMT2012.
In NAACL 2012 Seventh Workshop onStatistical Machine Translation, pages 304?311,Montre?al, Canada, June.Matthias Huck, Jan-Thorsten Peter, Markus Freitag,Stephan Peitz, and Hermann Ney.
2012c.
Hierar-chical Phrase-Based Translation with Jane 2.
ThePrague Bulletin of Mathematical Linguistics, 98:37?50, October.Matthias Huck, David Vilar, Markus Freitag, andHermann Ney.
2013.
A Performance Study ofCube Pruning for Large-Scale Hierarchical MachineTranslation.
In Proceedings of the NAACL 7thWork-shop on Syntax, Semantics and Structure in Statis-tical Translation, pages 29?38, Atlanta, Georgia,USA, June.Dan Klein and Christopher D. Manning.
2003.
Accu-rate Unlexicalized Parsing.
In Proc.
of the 41th An-nual Meeting of the Association for ComputationalLinguistics (ACL), pages 423?430, Sapporo, Japan,July.198Reinhard Kneser and Hermann Ney.
1995.
Im-proved Backing-Off for M-gram Language Model-ing.
In Proceedings of the International Conferenceon Acoustics, Speech, and Signal Processing, vol-ume 1, pages 181?184, May.Philipp Koehn and Kevin Knight.
2003.
EmpiricalMethods for Compound Splitting.
In Proceedings ofEuropean Chapter of the ACL (EACL 2009), pages187?194.Alon Lavie and Abhaya Agarwal.
2007.
METEOR:An Automatic Metric for MT Evaluation with HighLevels of Correlation with Human Judgments.
InACL 2007 Second Workshop on Statistical MachineTranslation, pages 228?231, Prague, Czech Repub-lic, June.Saab Mansour and Hermann Ney.
2012.
A Simple andEffective Weighted Phrase Extraction for MachineTranslation Adaptation.
In Proceedings of the Inter-national Workshop on Spoken Language Translation(IWSLT), pages 193?200, Hong Kong, December.Saab Mansour, Joern Wuebker, and Hermann Ney.2011.
Combining Translation and Language ModelScoring for Domain-Specific Data Filtering.
In Pro-ceedings of the International Workshop on SpokenLanguage Translation (IWSLT), pages 222?229, SanFrancisco, California, USA, December.Arne Mauser, Sas?a Hasan, and Hermann Ney.
2009.Extending Statistical Machine Translation with Dis-criminative and Trigger-Based Lexicon Models.
InProc.
of the Conf.
on Empirical Methods for Natu-ral Language Processing (EMNLP), pages 210?218,Singapore, August.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
Computational Linguistics, 29(1):19?51,March.Franz Josef Och.
2000. mkcls: Trainingof word classes for language modeling.http://www.hltpr.rwth-aachen.de/web/Software/mkcls.html.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proc.
of the41th Annual Meeting of the Association for Compu-tational Linguistics (ACL), pages 160?167, Sapporo,Japan, July.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a Method for AutomaticEvaluation of Machine Translation.
In Proceed-ings of the 41st Annual Meeting of the Associa-tion for Computational Linguistics, pages 311?318,Philadelphia, Pennsylvania, USA, July.Jan-Thorsten Peter, Matthias Huck, Hermann Ney, andDaniel Stein.
2011.
Soft String-to-DependencyHierarchical Machine Translation.
In InternationalWorkshop on Spoken Language Translation, pages246?253, San Francisco, California, USA, Decem-ber.Maja Popovic?
and Hermann Ney.
2006.
POS-basedWord Reorderings for Statistical Machine Transla-tion.
In International Conference on Language Re-sources and Evaluation, pages 1278?1283, Genoa,Italy, May.Holger Schwenk, Anthony Rousseau, and MohammedAttik.
2012.
Large, Pruned or Continuous SpaceLanguage Models on a GPU for Statistical MachineTranslation.
In NAACL-HLT 2012 Workshop: WillWe Ever Really Replace the N-gram Model?
On theFuture of Language Modeling for HLT, pages 11?19, Montre?al, Canada, June.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Study ofTranslation Edit Rate with Targeted Human Annota-tion.
In Proceedings of the 7th Conference of the As-sociation for Machine Translation in the Americas,pages 223?231, Cambridge, Massachusetts, USA,August.Daniel Stein, Stephan Peitz, David Vilar, and HermannNey.
2010.
A Cocktail of Deep Syntactic Fea-tures for Hierarchical Machine Translation.
In Conf.of the Association for Machine Translation in theAmericas (AMTA), Denver, Colorado, USA, Octo-ber/November.Andreas Stolcke.
2002.
SRILM ?
An Extensible Lan-guage Modeling Toolkit.
In Proc.
of the Int.
Conf.on Speech and Language Processing (ICSLP), vol-ume 2, pages 901?904, Denver, Colorado, USA,September.David Vilar, Daniel Stein, Matthias Huck, and Her-mann Ney.
2010.
Jane: Open Source Hierarchi-cal Translation, Extended with Reordering and Lex-icon Models.
In ACL 2010 Joint Fifth Workshop onStatistical Machine Translation and Metrics MATR,pages 262?270, Uppsala, Sweden, July.David Vilar, Daniel Stein, Matthias Huck, and Her-mann Ney.
2012.
Jane: an advanced freely avail-able hierarchical machine translation toolkit.
Ma-chine Translation, 26(3):197?216, September.Joern Wuebker, Matthias Huck, Stephan Peitz, MalteNuhn, Markus Freitag, Jan-Thorsten Peter, SaabMansour, and Hermann Ney.
2012.
Jane 2:Open Source Phrase-based and Hierarchical Statis-tical Machine Translation.
In International Confer-ence on Computational Linguistics, pages 483?491,Mumbai, India, December.199
