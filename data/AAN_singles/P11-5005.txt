Rich Prior Knowledge inLearning for NLPGregory Druck, Kuzman Ganchev, Jo?o Gra?aWhy Incorporate Prior Knowledge?have: unlabeled dataoption: hirelinguistannotatorsWhy Incorporate Prior Knowledge?have: unlabeled dataoption: hirelinguistannotatorsThis approach does notscale to every task anddomain of interest.However, we alreadyknow a lot about mostproblems of interest.Example: Document Classification?Prior Knowledge:?labeled features: information about the labeldistribution when word w is present--- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- --DocumentsLabelsnewsgroups classificationbaseball Mac politics...hit Apple senate...Braves Macintosh taxes...runs Powerbook liberal...sentiment polaritypositive negativememorable terribleperfect boringexciting messExample: Information Extraction?Prior Knowledge:?labeled features:?the word ACM should be labeled either journal orbooktitle most of the time?non-Markov (long-range) dependencies:?each reference has at most one segment of each typeW.
H. Enright.
Improving the efficiency of matrix operationsin the numerical solution of stiff ordinary differentialequations.
ACM Trans.
Math.
Softw., 4(2), 127-136, June 1978.extraction fromresearch papers:Example: Part-of-speech Induction?Prior Knowledge:?linguistic knowledge: each sentence should have a verb?posterior sparsity: the total number of different POS tagsassigned to each word type should be smallTagsA career with the Europeaninstitutions must become moreattractive.
Too many young, new...TextExample: Dependency Grammar Induction?Prior Knowledge:?linguistic rules: nouns are usually dependents of verbs?noisy labeled data: target language parses should besimilar to aligned parses in a resource-rich source languageExample: Word Alignment?Prior Knowledge:?Bijectivity: alignment should be mostly one-to-one?Symmetry: source?target and target?sourcealignments should agreeA career with the European institutions must become more attractive.Uma carreira nas institui?
?es europeias t?m de se tornar mais atractiva.This TutorialIn general, how can we leverage such knowledgeand an unannotated corpus during learning?Notation & Modelsinput variables (documents, sentences):structured output variables (parses, sequences):unstructured output variables (labels):input / output variables for entire corpus:probabilistic model parameters:generative models:discriminative models:model feature function:p ?(y|x)p?
(x,y)xy?f(x , y)X YyLearning Scenarios?Unsupervised:?unlabeled data + prior knowledge?Lightly Supervised:?unlabeled data + ?informative?
prior knowledge?i.e.
provides specific information about labels?Semi-Supervised:?labeled data + unlabeled data + prior knowledgeRunning Example #1:Document Classification?model: Maximum Entropy Classifier (Logistic Regression)?setting: lightly supervised; no labeled data?prior knowledge:?labeled features: information about the labeldistribution when word w is present?label is often hockey or baseball when game is presentp?
(y|x) =1Z(x)exp(?
?
f(x, y))Running Example #2:Word Alignment?model: first-order Hidden Markov Model (HMM)?setting: unsupervised?prior knowledge:?Bijectivity: alignment should be mostly one-to-one1 12 3we knowthe waysabemos       el       camino      null1 2 3 0p?
(y,x) = p?(y0)N?i=1p?(yi|yi?1)p?
( x i|yi)Problem?This output does not agree with prior knowledge!
?six target words align to source word animada?five source words do not align with any target wordgameconvivialvery,animatedanwasitcordialmuyyanimadamaneraunadejugabanmodeldata outputx1x2x3y1y2y3+Limited Approach: Labeling Datalimitation: Often unclear how to do conversion?Example #1: often (not always) game ?
{hockey,baseball}?Example #2: alignment should be mostly one-to-onepriorknowledge--- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- --approach: Convert prior knowledge to labeled data.Prototypes (+ cluster features):?
[Haghighi & Klein 06]Others:?
[Raghavan & Allan 07]?
[Schapire et al 02]Limited Approach: Bayesian Approachapproach: Encode prior knowledge with a prior on parameters.limitation: Our prior knowledge is not about parameters!Parameters are difficult to interpret; hard to get desired effect.
?Example #1: often (not always) game ?
{hockey,baseball}?Example #2: alignment should be mostly one-to-onenatural: ?
should be small (or sparse)??
( informative prior )possible: ?
should be close to   ?
?i ?
?ip (?)specifyingx1x2x3y1y2y3??
[Dayanik et al 06][Johnson 07], among many othersLimited Approach: Augmenting Modellimitation: can be difficult to get desired effect?Example #1: often (not always) game ?
{hockey,baseball}limitation: may make exact inference intractable?Example #2: Bijectivity makes inference #P-completex1x2x3y1y2y3z1approach: Encode prior knowledge withadditional variables and dependencies.This Tutorialdevelop:?a language for directly encoding prior knowledge?methods for learning with knowledge in this language?
( approximations to modeling this language directly )?
(loosely) these methods perform mappings for us:?encoded prior knowledge            parameters?encoded prior knowledge            labeling?--- -------- -- ----- ------- --- ------ -------- -- ----- ------- --- ------ -------- -- ----- ------- --- ---?
?A Language for Encoding Prior KnowledgeOur prior knowledge is about distributions over latentoutput variables.
(output variables are interpretable)Specifically, we know some properties of this distribution:?Example #1: often (not always) game?
{hockey,baseball}Formulation: know about the expectations of somefunctions under distribution over latent output variablesConstraint Features?constraint feature function:?Example #1:?for document x, returns a vector with a 1 in the lthposition if y is the lth label and the word w is in x?Example #2:?returns a vector with mth value = number of targetwords in sentence x that align with source word m?
(x , y )?w(x, y) = 1 (y = l )1( w ?
x)?
(x,y) =N?i=11(yi = m)Expectations of Constraint Features?Example #1:  Corpus expectation:?vector with expected distribution over labels fordocuments that contain w (     is the count of w)?Example #2:  Per-example expectation:?vector with mth value = expected number of targetwords that align with source word mEp?
[?
(X,Y)] =1c w?x?yp?
(y|x)?w(x, y)E p ?
[?
(x,y)] =?yp?(y|x)?
(x,y)c wExpressing Preferences?express preferences using target values:?Example #1:?label distribution for game is close to [40% 40% 20%]?Example #2:?expected number of target words that align with eachsource word is at most one?
?E p ?
[?
w ( X , Y )] ?
?
?E p ?
[?
(x , y)] ?
?
?Preview: Labeled FeaturesUser Experiments [Druck et al 08]0 100 200 300 400 500 600 700 8000.40.50.60.70.80.91labeling time in secondstestingaccuracyGEER~2 minutes, 100features labeled(or skipped):82% accuracy~15 minutes, 100documents labeled(or skipped):78% accuracyPC vs. Maccomplete set oflabeled featuresPC Macdos macibm applehp quadradxtargets set withsimple heuristic:majority label gets90% of massPreview:  Word Alignment[Gra?a et al 10]6068.7577.586.2595En-Pt Pt-En En-Es Es-EnHMM HMM + Bijectivity ConstraintOverview of the FrameworksRunning ExampleModel Family: conditional exponential modelsare model featuresp?
(Y|X) =exp( ?
?
f(X,Y))Z(X)Z(X) =?Ye x p( ?
?
f(X , Y))f( X , Y )Choosing parametersModel Family: conditional exponential modelsObjective: maximize observed data likelihoodNote: Frameworks also suitable forgenerative models (no labeled data necessary)?p?
(Y|X) =exp( ?
?
f(X,Y))Z(X)max?log p?
( Y L | X L ) + log p(?
)d e f= L (?
; D L )Visual Example: Maximum LikelihoodModel:Objective:-+oooo oo o omax?log p?
( Y L | X L )?
0.
1??
?22p(Y|X) =?iexp( y i x i ?
?
)Z ( x i)A language for prior informationThe expectations of user-defined constraintfeatures             are close to some value?
( X , Y ) ?
?E [?
( X , Y )] ?
?
?Running Example:Want to ensure that 25% of unlabeleddocuments are about politics?constraint features?preferred expected value?Expectation w.r.t.
unlabeled data?
(x , y) =?1 if y is ?politics?0 otherwise??
= 0 .
25Constraint-Driven LearningMotivation: Hard EM algorithm with preferencesHard EM:Constraint Driven Learning:M - Step: set ?
= arg max?log p ?
(?Y | X )E-Step: set ?Y = argmaxYlog p ?
( Y | X )?penalty( Y )M - Step: set ?
= arg max?log p ?
(?Y | X )E-Step: set ?Y = argmaxYlog p ?
( Y | X )M. Chang, L. Ratinov, D. Roth (2007).Constraint-Driven LearningMotivation: Hard EM algorithm with preferencesConstraint Driven Learning:?penalties encode similar information as* more on this later *?E-Step can be hard; use beam searchE-Step: set ?Y = argmaxYlog p ?
( Y | X )?penalty( Y )M - Step: set ?
= arg max?log p ?
(?Y | X )E [ ? ]
?
?
?Visual Example: Constraint Driven Learningwhere     are ?imagined?
labels and?Y-+oooo oo o o?
[ ?Y ] = count(+ , ?Y )max?,Y?log p?
( Y L| X L)?
0.
1??
?22 s.t.
?
(?Y ) = 2Posterior RegularizationMotivation: EM algorithm with sane posteriorsEM:Constrained EM:E-Step: set q ( Y ) = argminqD KL ( q ( Y )||p?
( Y | X ))M-Step: set ?
= argmax?E q ( Y ) [ p ?
( Y | X )]E-Step: set q ( Y ) = argminq ?QD KL ( q ( Y )||p?
(y|x))M-Step: set ?
= argmax?E q ( Y )[ p ?
( Y | X )]J. Gra?a, K. Ganchev, B. Taskar (2007).Posterior RegularizationMotivation: EM algorithm with sane posteriorsIdea:                  provide constraintsObjective:E [ ? ]
?
?
?define Q : set of q such that E q [?]
?
?
?m ax?L(?
; D L )?D KL (Q || p?
( Y | X ))run EM-like procedure but use proposal q ?
QwhereD KL is Kullback-Leibler divergenceX = D U are the input variables for unlabeled corpusY is label for entire unlabeled corpusPosterior RegularizationHard constraints:Soft constraints:max?L(?
; D L) ?
minq ?QD KL ( q ( Y )|| p ?
( Y | X ))Q =?q ( Y ) :???
E q [?
( Y )] = ?????22?
??max?L(?
;D L ) ?
minq?D KL (q( Y )|| p?
( Y | X )) +????
E q [?
( Y )] = ????
?22?Visual Example: Posterior Regularizationwhere:-+oooo oo o omax?log p?
( Y L | X L )?
0.
1??
?22 ?
D KL ( Q|| p?
)D KL ( Q|| p?)
= minqD KL ( q ||p?)
s.t.
E q [?]
= 2Generalized Expectation ConstraintsMotivation: augment log-likelihood with cost for ?bad?posteriors.Objective:whereis short-handOptimization: gradient descent onmax?L (?
; D L)????
E p ?
( Y | X ) [?]
?
?????
?E p ?
( Y | X )[?]
= E p ?
( Y | X ) [?
( X , Y )]=?Yp?
( Y | X )?
( X , Y )?G.
Mann, A. McCallum (2007).A visual comparison of the frameworksObjective: Generalized Expectation Constraints-+oooo oo o omax?log p?
( Y L | X L ) ?
0.
1??
?22 ?
500?E p ?
[?]
?
2?22Types of constraintsConstraint Driven Learning: Penalized Viterbi?Easy if                           decompose as the model.and?Otherwise:?Beam search?Integer linear programp ( Y | X ) =?cp c (y c | X )argmaxYlog p?
( Y | X ) ?
??
( X , Y )?
??????
( X , Y )?
??????
( X , Y )?
????
=?c?
c ( X , y c )Types of constraintsPosterior Regularization: KL projection?Usually easy if               decompose as the model:and?Otherwise: Sample (e.g.
K. Bellare, G. Druck, and A. McCallum, 2009)?
( Y , X )p ( Y | X ) =?cp c (y c | X )q ( Y | X ) =?cq c (y c | X )?
( X , Y ) =?c?
c ( X , y c )?minqD KL ( q ||p?)
s.t.
?E q [?]
?
????
?
?Types of constraintsGeneralized Expectation Constraints: Direct gradient?Usually easy if:?decomposes as the model?Can compute                * more on this later *?Unstructured?Sequence, Grammar (semiring trick)?Otherwise: sample or approximate the gradient.?
( Y , X )max?L (?
; D L)????
E p ?
( Y | X ) [?]
?
???????
( X , Y ) =?c?
c ( X , y c )E [ ??
f ]A Bayesian View: MeasurementsObjective: mode of    given observationsX L ?
XY L Y?
( X , Y )bFigure 4.1: The model used by Liang et al [2009], using our notation.
We have separatedtreatment of the labeled data (XL,YL) from treatment of the unlabeled data X.and produce some value ?
(X,Y), which is never observed directly.
Instead, we observesome noisy version b ?
?(X,Y).
The measured values b are distributed according tosome noise model pN(b|?(X,Y)).
Liang et al [2009] note that the optimization is convexfor log-concave noise and use box noise in their experiments, giving b uniform probabilityin some range near ?
(X,Y).In the Bayesian setting, the model parameters ?
as well as the observed measurementvalues b are random variables.
Liang et al [2009] use the mode of p(?|XL,YL,X,b) as apoint estimate for ?
:argmax?p(?|XL,YL,X,b) = argmax?
?Yp(?,Y,b|X,XL,YL), (4.6)with equality because p(?|XL,YL,X,b) ?
p(?,b|XL,YL,X) =?Y p(?,Y,b|X,XL,YL).
Liang et al [2009] focus on computing p(?,Y,b|X,XL,YL).They define their model for this quantity as follows:p(?,Y,b|X,XL,YL) = p(?|XL,YL) p?
(Y|X) pN(b|?
(X,Y)) (4.7)where the Y and X are particular instantiations of the random variables in the entire unla-beled corpusX.
Equation 4.7 is a product of three terms: a prior on ?, the model probabilityp?
(Y|X), and a noise model pN(b|?).
The noise model is the probability that we observea value, b, of the measurement features ?, given that its actual value was ?(X,Y).
Theidea is that we model errors in the estimation of the posterior probabilities as noise in themeasurement process.
Liang et al [2009] use a uniform distribution over ?
(X,Y) ?
?,which they call ?box noise?.
Under this model, observing b farther than ?
from ?
(X,Y)has zero probability.
In log space, the exact MAP objective, becomes:max?L(?)
+ logEp?(Y|X)?pN(b|?(X,Y))?.
(4.8)31max?l og p(?)
+?
( x , y ) ?
D Ll og p?
( y |x) = L (?
; D L )?P.
Liang, M. Jordan, D. Klein (2009)Objective: mode of    given observationsA Bayesian View: MeasurementsX L ?
XY L Y?
( X , Y )bFigure 4.1: The model used by Liang et l. [2009], using our notation.
We have separatedtreatment of the labeled data (XL,YL) from treatment of the unlabeled data X.and produce some value ?
(X,Y), which is never observed directly.
Instead, we observesome noisy version b ?
?(X,Y).
The measured values b are distributed according tosome noise model pN(b|?(X,Y)).
Liang et al [2009] note that the optimization is convexfor log-concave noise and use box noise in their experiments, giving b uniform probabilityin some range near ?
(X,Y).In the Bayesian setting, the model parameters ?
as well as the observed measurementvalues b are random variables.
Liang et al [2009] use the mode of p(?|XL,YL,X,b) as apoint estimate for ?
:argmax?p(?|XL,YL,X,b) = argmax?
?Yp(?,Y,b|X,XL,YL), (4.6)with equality because p(?|XL,YL,X,b) ?
p(?,b|XL,YL,X) =?Y p(?,Y,b|X,XL,YL).
Liang et al [2009] focus on computing p(?,Y,b|X,XL,YL).They define their model for this quantity as follows:p(?,Y,b|X,XL,YL) = p(?|XL,YL) p?
(Y|X) pN(b|?
(X,Y)) (4.7)where the Y and X are particular instantiations of the random variables in the entire unla-beled corpusX.
Equation 4.7 is a product of three terms: a prior on ?, the model probabilityp?
(Y|X), and a noise model pN(b|?).
The noise model is the probability that we observea value, b, of the measurement features ?, given that its actual value was ?(X,Y).
Theidea is that we model errors in the estimation of the posterior probabilities as noise in themeasurement process.
Liang et al [2009] use a uniform distribution over ?
(X,Y) ?
?,which they call ?box noise?.
Under this model, observing b farther than ?
from ?
(X,Y)has zero probability.
In log space, the exact MAP objective, becomes:max?L(?)
+ logEp?(Y|X)?pN(b|?(X,Y))?.
(4.8)31max?L (?
;D L ) + log E p ?
( Y | X )?p(??|?
( X , Y ))?
?What's wrong with this picture?Objective: mode of    given observationsExample: Exactly 25% of articles are ?politics?What is the probability exactly 25% of the articles arelabeled ``politics''?How do we optimize this with respect to  ?max?L (?
; D L ) + log E p ?
(Y | X)?p(??|?
( X , Y ))???p(??|?
( X , Y )) = 1???
= ?
( X , Y )?E p ?
(Y | X)?1 (??
= ?
(X , Y))?What's wrong with this picture?Example: Compute prob:  25% of docs are ?politics?.Naively:in this case we can use a DP, but ifthere are many constraints, that doesn?twork.Easier: What is the expected number of ?politics?
articles?Article p(?politics?
)1 0.22 0.43 0.14 0.60 .
2 + 0 .
4 + 0 .
1 + 0 .
60 .
2 ?
(1 ?
0 .
4) ?
(1 ?
0 .
1) ?
(1 ?
0 .
6)+ .
.
.
++(1 ?
0 .
2) ?
(1 ?
0 .
4) ?
(1 ?
0 .
1) ?
0 .
6Probabilities and Expectationsdifficult to compute expectations of arbitrary functions but...Usually:             decomposes as a sume.g.
25% of articles are ?politics?Idea: approximate?
( X , Y )?
(X , Y) =?instances?
( x , y )E p ?
(Y | X)?p???
| ?
( X , Y )???
p???
| E p ?
(Y | X) [?
( X , Y )]?Probabilities and ExpectationsApproximation:Objective:Example:                      is Gaussianisso for appropriate                           this is identical to GE!E p ?
( Y | X )?p???
| ????
p???
| E p ?
( Y | X ) [ ?
]?max?L (?
;D L ) + log p???
| E p ?
(Y | X) [?
]?l og p???
| E [?]??p???
| E [ ?
]?l og p???
| E [ ?
]?????
E [ ? ]
?
????
?22Optimizing GE objectiveGE Objective:?Gradient involves covariancethis can be hard becauseand the usual dynamic programs (inside outside, forwardbackward) can?t compute this.C ov( ?
, f) = E [ ??
f ] ?
E [ ? ]
?
E [ f ]E [??
f ] =?Yp ( Y )?
( Y )?
f ( Y )O GE = max?L (?
; D L )????
E p ?
(Y | X) [ ?
( X , Y )] ?
?????
?Optimizing GE ObjectiveMaintaining both     and      in the DP is expensive* Semiring trick can help for some problems *x1 x2 x3 x3y1 y2 y3 y4E [??
f ] =?Yp ( Y )?
( Y )?
f ( Y )?
( Y )?
f ( Y ) =??i?(yi)????
?jf (y j )?
?yi y jE.g.
if inference is a hypergraph problem.A Variational ApproximationGE Objective:?Can be hard to compute                   in gradient.Idea: use variational approximation* Note: this is the PR objective *q ( Y ) ?
p?
( Y | X )max?
, q (Y) L(?
; D L )?D KL?q ( Y ) || p?
( Y | X )?????
E q [?
( X , Y )] ?
?????
?C ov( ?
, f )O GE = max?L (?
; D L )???????
E p ?
(Y|X) [ ?
( X , Y )]???
?Approximating with the modePR Objective:sometimes minimizing the KL is hard.Idea: use hard assignment                               :?becomes?becomes?use EM-like procedure to optimizeConstraint Driven Learning Objective:max?
, q ( Y ) L(?
; D L )?D KL?q ( Y ) || p?
( Y | X )?????
E q [?
( X , Y )] ?
?????
?q ( Y ) ?
1 ( Y = ?Y )???
E q [?
( X , Y )] ?
?????
?l og p ( ?Y )D KL?q ( Y ) || p?
( Y | X )?l og p(??
| ?
( X , ?Y ))m ax?, ?YL (?
; D L) + log p ?
(?Y ) + log p (??|?
( X , ?Y ))Visual SummaryMeasurementsGeneralizedExpectationDistributionMatchingPosteriorRegularizationCoupled Semi-SupervisedLearningConstraintDrivenLearningvariational approximation;Jensen?s inequalityvariationalapproximationMAPapproximationMAPapproximationlogE[ p N (??|?)]
?
log p N (??|E[?
])Applications?Unstructured problems:?Document Classification?Sequence problems:?Information Extraction?Pos-Induction?Word Alignment?Tree problems:?Grammar InductionDocument Classification?Model: Max.
Entropy Classifier (Logistic Regression)?Challenge: What if we have no labeled data?
?cannot use standard unsupervised learning:--- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- ----- --- ------- -- --- ------- --- --- ----- ---------------- ---- --DocumentsLabelsp ?
(y|x) =exp(?
?
f(x, y))?yexp(?
?
f(x, y))?yp?
( y | x )= 1Labeled Features?often we can still provide some light supervision?prior knowledge: labeled features?formally: have an estimate of the distribution over labelsfor documents that contain word w:??
wnewsgroups classificationbaseball Mac politics...hit Apple senate...Braves Macintosh taxes...runs Powerbook liberal...sentiment polaritypositive negativememorable terribleperfect boringexciting messLeveraging Labeled Features with GE[Mann & McCallum 07], [Druck et al 08]?constraint feature:?for a document x, returns a vector with a 1 in the lthposition if y is the lth label and the word w is in x?expectation: label distribution for docs that contain w?GE penalty: KL divergence from target distribution?
w (x, y) = 1 (y = l )1( w ?
x)1c w?xE p?
( y | x ) [ ?w(x, y)]D KL??
?w||1c w?xEp?
(y | x)[?w(x , y )]?User Experiments with Labeled Features[Druck et al 08]0 100 200 300 400 500 600 700 8000.40.50.60.70.80.91labeling time in secondstestingaccuracyGEER~2 minutes, 100features labeled(or skipped):82% accuracy~15 minutes, 100documents labeled(or skipped):78% accuracyPC vs. Maccomplete set oflabeled featuresPC Macdos macibm applehp quadradxtargets set withsimple heuristic:majority label gets90% of massExperiments with Labeled Features[Druck et al 08]6065707580sentiment (50) webkb (100) newsgroups (500)GE (model contains only labeled features)GE (model also contains unlabeled features)15x3.5x6.5xlearning about ?unlabeled features?
throughcovariance improves generalizationestimated speed-up overlabeling documentsInformation Extraction: Example Tasks?citation extraction:?apartment listing extraction:Detached single family house.
3 bedrooms 1 1/2 baths.
Almost1000 square feet in living area.
1 car garage.
New pergo floorand tile kitchen floor.
New interior/exterior paint.
Close toshopping mall and bus stop.
Near 101/280.
Available July 1,2004.
If you are interested, email for more details.Cousot, P. and Cousot, R. 1978.
Static determination ofdynamic properties of recursive procedures.
In Proceedings ofthe IFIP Conference on Programming Concepts, E. Neuhold,Ed.
North-Holland Pub.
Co., 237-277.Information Extraction: Markov Models?models for sequence labeling based IE?Hidden Markov Model (HMM):?Conditional Random Field (CRF):p?
(y,x) = p?(y0)N?i=1p?(yi|yi?1)p?
( x i|yi)p?
(y|x) =1Z(x)exp(N?i =1?
?
f (x, yi?
1 , yi))expectation:label distribution when q is truemodel: Linear Chain CRFnote: Semiring trick makes GEO(L2) instead of O(L3) as in[Mann & McCallum 08]Information Extraction: Labeled Features[Mann & McCallum 08], [Liang et al 09]ROOMMATES respectfulCONTACT *phone*FEATURES laundryapartments examplelabeled features:1c q?x?iE p?
(yi | x )[?q(x, yi, i )]constraint features:vector with a 1 in the lthposition if y is the lth labeland predicate q is true (i.e.
wis present at i)?
q (x, yi , i) = 1 (y i = l)q(x, i)Information Extraction: Labeled Features[Haghighi & Klein 06], [Mann & McCallum 08], [Liang et al 09]apartment listing extractionPrototypeGE (KL)Measurements/PR6507007508008500 labeled 10 labeled 100 labeledsupervised CRF (100) [MM08]?accurate with constraints alone?outperform fully supervised withconstraints and labeled dataLimitations of Markov Models?predicted:?prediction has two author and two title segments:?error #1: Neuhold, Ed.
should be editor?error #2: North-Holland Pub.
Co., should bepublisher?A Markov model cannot represent that at most one segmentof each type appears in each reference.Cousot, P. and Cousot, R. 1978.
Static determination ofdynamic properties of recursive procedures.
In Proceedings ofthe IFIP Conference on Programming Concepts, E. Neuhold,Ed.
North-Holland Pub.
Co., 237-277.Long-Range Constraints[Chang et al 07] [Bellare et al 09]?
?Each field is a contiguous sequence of tokens and appearsat most once in a citation.?
?constraint feature: counts the number of segments ofeach type?constrained to be ?
1 using PR or CODL?additional constraints: 10 labeled features such as:?pages?pages?proc.
?booktitleLong-Range Constraints[Chang et al 07] [Bellare et al 09]constraints improve bothCRF (PR) and HMM (CODL)50607080905 labeled 20 labeledCRF CRF + PRHMM HMM + CODLcitation model method description[Mann et al 07] MaxEnt GEconstraints onlabel marginals[Druck et al 09] CRF GEactively labeledfeatures[Bellare &McCallum 09]alignmentCRFGE labeled features[Singh et al 10]semi-MarkovCRFPR labeled gazetteers[Druck et al 10] HMM PRconstraints derivedfrom labeled dataOther Applications inInformation ExtractionPos InductionLow Tag Ambiguity[Gra?a et al 09]JJVBNNcarobjectromanticoffensivebeingE[degree] = 1.5E[degree] = 10000  0 2 4 6 8 10  0  200  400  600  800  1000 1200 1400 1600 1800L 1L !
rank of word by L1L!SupervisedHMMDistribution of word ambiguityN V ADJ Prep ADV0.9 0.1 0 0 00.7 0.1 0.1 0 0.10.1 0.3 0 0.6 00.3 0.6 0 0 0.10.3 0.7 0 0 0?Pick a particular word type: run?Stack all occurrences?Calculate posterior probability?Take the maximum for each tag?Sum the maxesa run into town.of the mile run.run gold.run errands.run for mayor.Sum1Sum11110.9 0.7 0.1 0.6 0.2MaxSum2.5Measuring Tag Ambiguity[Gra?a et al 09]?wti :Word type w  has hidden state t at occurrence im i ncwtE q ( y ) [?wti] ?
c wt?1 / ??
=?w tc w tTag Sparsity[Gra?a et al 09]01.252.53.755En Pt EsAmbiguitydifferenceHMM L1LMaxAverage ambiguitydifference 0 2 4 6 8 10  0  200  400  600  800  1000 1200 1400 1600 1800L 1L !
rank of word by L1L!SupervisedHMMHMM+SpDistribution of word ambiguityResults[Gra?a et al 09]5057.56572.580En Pt Bg Es Dk TrHMM HMM+Sp3.86.77.47.6 9.63.86.5 % Average ImprovementWord Alignments[Gra?a et al 10]?Bijectivity constraints:?Each word should align to at most one other word?Symmetry constraints:?Directional models should agreeBijectivity Constraints[Gra?a et al 10]Bijective Constraints0 1 2 3 4 5 6 7 80 ?
?
?
?
?
?
?
?
?
jugaban ?
?
11 ?
?
?
?
?
?
?
?
?
de ?
?
12 ?
?
?
?
?
?
?
?
?
una ?
?
13 ?
?
?
?
?
?
?
?
?
manera ?
?
14 ?
?
?
?
?
?
?
?
?
animada ?
?
15 ?
?
?
?
?
?
?
?
?
y ?
?
16 ?
?
?
?
?
?
?
?
?
muy ?
?
17 ?
?
?
?
?
?
?
?
?
cordial ?
?
18 ?
?
?
?
?
?
?
?
?.
?
?
1it was an animated, very convivialgame.50 / 74Bijective Constraints - After projection0 1 2 3 4 5 6 7 80 ?
?
?
?
?
?
?
?
?
jugaban ?
?
11 ?
?
?
?
?
?
?
?
?
de ?
?
12 ?
?
?
?
?
?
?
?
?
una ?
?
13 ?
?
?
?
?
?
?
?
?
manera ?
?
14 ?
?
?
?
?
?
?
?
?
animada ?
?
15 ?
?
?
?
?
?
?
?
?
y ?
?
16 ?
?
?
?
?
?
?
?
?
muy ?
?
17 ?
?
?
?
?
?
?
?
?
cordial ?
?
18 ?
?
?
?
?
?
?
?
?
.
?
?
1it was an animated, very convivialgame.51 / 74Feature:Constraint:?
(x,y) =N?i=11(yi = m)E q [?
(x , y)] ?
1Symmetry Constraints[Gra?a et al 10]Feature:Constraint:Sym metric - Original posteriors0 1 2 3 4?
?p ?t (z | x)0 ?
?
?
?
?
no1 ?
?
?
?
?
hay2 ?
?
?
?
?
estad?
?sticas3 ?
?
?
?
?.0 1 2 3 4?
?p ?t (z | x)0 ?
?
?
?
?
no1 ?
?
?
?
?
hay2 ?
?
?
?
?
estad?
?sticas3 ?
?
?
?
?.no statisticaldataexists.p ?
tq?
?p ?
t?
?p ?
t55 / 74Eq [ ?
(x , y)] = 0?
(x, y ) =????
?+ 1 y ??
?y and?
?y i = j?
1 y ??
?y and?
?y j = i0 otherwise?
?p ?
( y | )?
?p ?
( y )Symmetry Constraints[Gra?a et al 10]Before projection: After projection:Symmetric - After projectionE-Step qs(z) = arg minq(z)?
Q sKL [qs(z) || p?t (z | xs)]0 1 2 3 4?
?p ?t (z | x)0 ?
?
?
?
?
no1 ?
?
?
?
?
hay2 ?
?
?
?
?
estad?
?sticas3 ?
?
?
?
?.0 1 2 3 4?
?p ?t (z | x)0 ?
?
?
?
?
no1 ?
?
?
?
?
hay2 ?
?
?
?
?
estad?
?sticas3 ?
?
?
?
?.no statisticaldataexists.0 1 2 3 40 ?
?
?
?
?
no?
?q (z)1?
?
?
?
?
hay2 ?
?
?
?
?
estad?
?sticas3 ?
?
?
?
?.0 1 2 3 40 ?
?
?
?
?
no?
?q (z)1?
?
?
?
?
hay2 ?
?
?
?
?
estad?
?sticas3 ?
?
?
?
?.no statisticaldataexists.M-Step Does not change56 / 74?
?p ?
( y |x)?
?p ?
( y |x?q ( y )?q ( y )Results[Gra?a et al 10]50 60 70 80 90 100 1000  10000  100000  1e+06precision size S-HMMB-HMMHMM 50 60 70 80 90 100 1000  10000  100000  1e+06precision size S-HMMB-HMMHMMEvolution with data size 50 60 70 80 90 100 1000  10000  100000  1e+06precision size S-HMMB-HMMM4HMM  50 60 70 80 90 100 1000  10000  100000  1e+06precision size S-HMMB-HMMM4HMM?
Specially useful for low data situations6 1 / 74Evolution with data size 50 60 70 80 90 100 1000  10000  100000  1e+06precision size S-HMMB-HMMM4HMM  50 60 70 80 90 100 1000  10000  100000  1e+06precision size S-HMMB-HMMM4HMM?
Specially useful for low data situations6 1 / 74Results[Gra?a et al 10]60 65 7075 80 8590 95En-Pt Pt-En Pt-Fr Fr-Pt En-Es Es-En Es-Fr Fr-Es Pt-Es Es-Pt En-Fr Fr-EnLanguagesHMM70.5 67.573.0 77.6 75.7 74.9 80.9 84.0 82.4 79.8 76.3 78.3B-HMM85.0 74.4 71.386.3 88.4 87.2 87.2 86.5 82.5 90.1 90.8 91.6S-HMM86.2 85.0 82.4 87.9 82.7 84.6 89.1 88.9 84.6 91.8 93.4 94.6Dependency ParsingDMV Model[Gra?a et al 04]Dependency model with valence(Klein and Manning, ACL 2004)xyRegularizationNcreatesVsparseADJgrammarsNp?
(x, y) = ?root(V )?
?stop(nostop|V ,right,false) ?
?child(N|V ,right)?
?stop(stop|V ,right,true) ?
?stop(nostop|V ,left,false) ?
?child(N|V ,left).
.
.3/9Dependency Parsing?Transfer annotations from another language?
[Ganchev et al 09]?Constrain the number of child/parentrelations?
[Gillenwater et al 11]?Use linguistic rules?
[Druck et al 09] [Naseem et al 10]Dependency ParsingTransfer annotations[Ganchev et al 09]?Use information from a resource richlanguage?Make the annotation transfer robust?Preserve n % of the edgesDependency ParsingTransfer annotations[Ganchev et al 09]E q [?
(x,y)] =1| Cx|?y?
C xq (y|x)E q [ ?
(x,y)] ?
bDependency ParsingTransfer annotations[Ganchev et al 09]6667686970ES BGDMV PR-TransferDependency ParsingPosterior Sparsity[Gra?a et al 10]?ML learns very ambiguous grammars?all productions have some probability?constrain the number of possibleproductionsDependency ParsingPosterior Sparsity[Gillenwater et al 11]Measuring ambiguity on distributions over treesN?NV?NADJ?NN?VV?VADJ?VN?ADJV?ADJADJ?ADJSparsityN isV workingV0.40.6 0 1 0SparsityN isV workingV0.4 0.6 .4 .6 0UseV goodADJ grammarsN0.70.3 0 .7 .3UseV goodADJ grammarsN0.40.6 .4 .6 0max ?sum = 3.3 ?
0 1 .3 .4 .6 0 .4 .6 07/9Dependency ParsingPosterior Sparsity[Gillenwater et al 11]GILLENWATER, GANCHEV, GRA?A, PEREIRA, TASKARUnadpapelerancesvsundobjetonccivilizadoaqUnadpapelerancesvsundobjetonccivilizadoaq1.001.00 1.000.490.511.000.570.43Unadpapelerancesvsundobjetonccivilizadoaq1.00 0.83 0.75 0.990.920.350.48Figure 14: Posterior edge probabilities for an example sentence from the Spanish test corpus.
Topis Gold, middle is EM, and bottom is PR.since then it does not have to pay the cost of assigning a parent with a new tag to cover each nounthat does not come with a determiner.Table 4 contrasts the most frequent types of errors EM, SDP, and PR make on several test setswhere PR does well.
The ?acc?
column is accuracy and the ?errs?
column is the absolute numberof errors of the key type.
Accuracy for the key ?parent POS truth/guess?
child POS?
is computedas a function of the true relation.
So, if the key is pt /p g ?
c , then accuracy is:acc =# of pt ?
c in Viterbi parses# of pt ?
c in gold parses.
(25)In the following subsections we provide some analysis of the results from Table 4.7.1 English CorrectionsConsidering English first, there are several notable differences between EM and PR errors.
Similarto the example for Spanish, the direction of the noun-determiner relation is corrected by PR.
This isreflected by the VB/DT?
NN key, the NN/VBZ?
DT key, the NN/IN?
DT key, the IN/DT?NN key, the NN/VBD?
DT key, the NN/VBP?
DT key, and the NN/VB?
DT key, which forEM and SDP have accuracy 0.
PR corrects these errors.A second correction PR makes is reflected in the VB/TO?
VB key.
One explanation for thereason PR is able to correctly identify VBs as the parents of other VBs instead of mistakenly makingTO the parent of VBs is that ?VB CC VB?
is a frequently occurring sequence.
For example, ?buildand hold?
and ?panic and bail?
are two instances of the ?VB CC VB?
pattern from the test corpus.Presented with such scenarios, where there is no TO present to be the parent of VB, PR chooses thefirst VB as the parent of the second.
It maintains this preference for making the first VB a parent ofthe second when encountered with ?VB TO VB?
sequences, such as ?used to eliminate?, because itwould have to pay an additional penalty to make TO the parent of the second VB.
In this manner,PR corrects the VB/TO?
VB key error of EM and SDP.26Gold:DVM:DMV+Sparsity:Dependency ParsingPosterior Sparsity[Gillenwater t al.
11]017.53552.570English Bulgarian Portuguese Checz Spanish GermanDMV DMV+SparsityDependency ParsingLinguistic Rules[Naseem et al 10]Using Universal Linguistic Knowledge to Guide Grammar InductionTahira Naseem, Harr Chen, Regina BarzilayComputer Science and Artificial Intelligence LaboratoryMassachusetts Institute of Technology{ tahira, harr, regina} @csail.mit.eduMark JohnsonDepartment of ComputingMacquarie Universitymark.johnson@mq.edu.auAbstractWe present an approach to grammar induc-tion that utilizes syntactic universals to im-prove dependency parsing across a range oflanguages.
Our method uses a single setof manually-specified language-independentrules that identify syntactic dependencies be-tween pairs of syntactic categories that com-monly occur across languages.
During infer-ence of the probabilistic model, we use pos-terior expectation constraints to require that aminimum proportion of the dependencies weinfer be instances of these rules.
We also auto-matically refine the syntactic categories givenin our coarsely tagged input.
Across six lan-guages our approach outperforms state-of-the-art unsupervised methods by a significant mar-gin.11 IntroductionDespite surface differences, human languages ex-hibit striking similarities in many fundamental as-pects of syntactic structure.
These structural corre-spondences, referred to as syntactic universals, havebeen extensively studied in linguistics (Baker, 2001;Carnie, 2002; White, 2003; Newmeyer, 2005) andunderlie many approaches in multilingual parsing.In fact, much recent work has demonstrated thatlearning cross-lingual correspondences from cor-pus data greatly reduces the ambiguity inherent insyntactic analysis (Kuhn, 2004; Burkett and Klein,2008; Cohen and Smith, 2009a; Snyder et al, 2009;Berg-Kirkpatrick and Klein, 2010).1The source code for the work presented in this paper isavailable at http://groups.csail.mit.edu/rbg/code/dependency/Root?
Auxiliary Noun?
AdjectiveRoot?
Verb Noun?
ArticleVerb?
Noun Noun?
NounVerb?
Pronoun Noun?
NumeralVerb?
Adverb Preposition?
NounVerb?
Verb Adjective?
AdverbAuxiliary?
VerbTable 1: The manually-specified universal dependencyrules used in our experiments.
These rules specify head-dependent relationships between coarse (i.e., unsplit)syntactic categories.
An explanation of the ruleset is pro-vided in Section 5.In this paper, we present an alternative gram-mar induction approach that exploits these struc-tural correspondences by declaratively encoding asmall set of universal dependency rules.
As inputto the model, we assume a corpus annotated withcoarse syntactic categories (i.e., high-level part-of-speech tags) and a set of universal rules defined overthese categories, such as those in Table 1.
Theserules incorporate the definitional properties of syn-tactic categories in terms of their interdependenciesand thus are universal across languages.
They canpotentially help disambiguate structural ambiguitiesthat are difficult to learn from data alone ?
forexample, our rules prefer analyses in which verbsare dependents of auxiliaries, even though analyz-ing auxiliaries as dependents of verbs is also consis-tent with the data.
Leveraging these universal ruleshas the potential to improve parsing performancefor a large number of human languages; this is par-ticularly relevant to the processing of low-resourceSmall set ofuniversal rules= 1 if edge in rule setE q [ ?
(x,y)] ?
b?
(x , y)Dependency ParsingLinguistic Rules[Nas em et al 10]020406080English Danish Portuguese Slovene Spanish SwedishDMV DMV+RulesDependency Parsing:Applications using Other Models?Tree CRF?
[Druck et al 09]?MST Parser?
[Ganchev et al 09]Other Applications?Multi view learning:?
[Ganchev et al 08]?Relation extraction:?
[Chen et al 11]Implementation Tips and TricksOff-the-Shelf Tools: MALLEThttp://mallet.cs.umass.edu?off-the-shelf support for labeled features?models: MaxEnt Classifier, Linear Chain CRF (one and twolabel constraints)?methods: GE and PR?constraints on label distributions for input features?GE penalties:  KL divergence,     (+ soft inequalities)?PR penalties:     (+ soft inequalities)?in development: Tree CRF,      and other penalties?22?22?1Off-the-Shelf Tools: MALLEThttp://mallet.cs.umass.edu?import data in SVMLight-like or CoNLL03-like formats?import constraints in a simple text format:?easily specify method options (i.e.
SimpleTagger):positive interesting:2 film:1 ...negative tired:1 sequel:1 ...positive best:1 recommend:2 ...U.N.       NNP  B-NP  B-ORGofficial   NN   I-NP  Oheads      VBZ  B-VP  Otired negative:0.8 positive:0.2best positive:0.9 negative:0.1U.N.
B-ORG:0.7,0.9B-VP O:0.95,java cc.mallet.fst.semi_supervised.tui.SemiSupSimpleTagger \--train true --test lab --loss l2 --learning ge \unlabeled.txt test.txt constraints.txtNew GE Constraints: MALLEThttp://mallet.cs.umass.edu?Java Interfaces for implementing new GE constraints?covariance computation implemented (MaxEnt, CRF)?primarily need to write methods to:?restriction: constraints must factor with model?restriction: GE objective must be differentiablecompute constraint features and expectationscompute GE objective valuecompute GE objective gradient (but not covariance)New PR Constraints: MALLEThttp://mallet.cs.umass.edu?Java Interfaces for implementing new PR constraints?inference algorithms implemented (MaxEnt, CRF)?primarily need to write methods for E-step (projection):?restriction: constraints must factor with modelcompute constraint features and expectationscompute scores under q for E-stepcompute objective function for E-stepcompute gradient for E-stepGE Implementation Advice?computing covariance (required for gradient):?trick: compute cov.
of composite constraint feature?example:     penalty:?result: only need to store vectors of size            incomputation, rather than covariance matrix?trick: efficient gradient computation in hypergraphs?use semiring algorithms of [Li & Eisner 09]?result: same time complexity as supervised (w. both)?
c (x , y) =?
?2( ???
E [?])?
(x , y)?22d i m( f )GE Implementation Advice?parameter regularization:?regularization encourages bootstrapping by penalizingvery large parameter values:?optimization: non-convex?usually L-BFGS still preferable (use ?restart trick?
)?zero initialization usually works well?other init: supervised, MaxEnt, GE in simpler model?22>Off-the-Shelf Tools: PR Toolkithttp://code.google.com/p/pr-toolkit/?off-the-shelf support for PR?models:?MaxEnt Classifier, HMM,DMV?applications:?Word Alignment, Pos Induction, Grammar Induction?constraints: posterior sparsity, bijectivity, agreement?No command line mode?Smaller support basePR Implementation example:Word Alignment - Bijectivity?Learning: EM, PR?void eStep(counts, lattices);?void mStep(counts);?lattice constraint.project(lattice);?Model: HMM?lattice computePosteriors(lattice);?void addCount(lattice, counts);?void updateParameters(counts);?Constraints: Bijectivity?lattice project(lattice);PR Implementation example:EMclass EM {model;void em(n){lattices= model.getLattices();counts = model.counts();for(i=0; i< n; i++) {eStep(counts, lattices);mStep(counts);}}void eStep(counts, lattices) {counts.clear();for(l : lattices)  {model.computePosterior(l);model.addCount(l,counts);}}void mStep(counts) {model.updateParameters(counts);}......}PR Implementation example:PRclass PR {model;constraint;void em(n){lattices= model.getLattices();counts = model.counts();for(i=0; i< n; i++) {eStep(counts, lattices);mStep(counts);}}void eStep(counts, lattices) {counts.clear();for(l : lattices){model.computePosterior(l);constraint.project(l);model.addCount(l,counts);}}void mStep(counts) {model.updateParameters(counts);}......}PR Implementation example:HMMclass HMM {obsProb, transProbs,initProbs;lattice computerPosteriors(lattice){?Run forward backward?
}void addCount(lattice,counts){?Add posteriors to count table?
}void updateParams(counts){?Normalize counts?
?Copy counts to params table?
}void getCounts(){?return copy of params structures?
}void getLattices(){?return structure of all latticesin the corpus?}......
}PR Implementation example:Bijective constraints?Constraint: returns a vector with mth value = number oftarget words in sentence x that align with source word m?
(x,y) =N?i=11(yi = m) Q = { q : E q [?
(x,y)] ?
1}?Primal: HardD KL ( Q| p?)
= arg minqD KL ( q |p?
)?Dual: Easyarg max??
0?
b T ?
??
l og Z (?)?
||?|| 2Z (?)
=?yp?
( y |x) exp(??
?
?
(x , y ))PR Implementation example:Bijective Constraintsclass BijectiveConstraints {model;lattice project(lattice){obj = BijectiveObj(model,lattice);Optimizer.optimize(obj);}}class BijectiveObj {lattice;void updateModel(newLambda){lattice_ = lattice*exp(newLambda);computerPosteriors(lattice)}double getObj(){obj = -dot(lambda,b);obj -= lattice.likelihood;obj -= l2Norm(lambda);}double[] getGrad(){grad = lattice.posteriors - b;grad -= norm(lambda);return grad;}Other Software Packages?Learning Based Java:?http://cogcomp.cs.illinois.edu/page/software_view/11?support for Constraint-Driven Learning?Factorie:?http://code.google.com/p/factorie/?support for GE and PR in developmentRich Prior Knowledge in Learning for NaturalLanguage ProcessingBibliographyFor a more up-to-date bibliography as well as additional information aboutthese methods, point your browser to: http://sideinfo.wikkii.com/1 Constraint-Driven LearningConstraint driven learning (CoDL) was first introduced in Chang et al [2007],and has been used also in Chang et al [2008].
A further paper on the topic isin submission [Chang et al, 2010].2 Generalized ExpectationGeneralized Expectation (GE) constraints were first introduced by Mann andMcCallum [2007] 1 and were used to incorporate prior knowledge about the labeldistribution into semi-supervised classification.
GE constraints have also beenused to leverage ?labeled features?
in document classification [Druck et al, 2008]and information extraction [Mann and McCallum, 2008, Druck et al, 2009b,Bellare and McCallum, 2009], and to incorporate linguistic prior knowledgeinto dependency grammar induction [Druck et al, 2009a].3 Posterior RegularizationThe most clearly written overview of Posterior Regularization (PR) is Ganchevet al [2010].
PR was first introduced in Graca et al [2008], and has beenapplied to dependency grammar induction [Ganchev et al, 2009, Gillenwateret al, 2009, 2011, Naseem et al, 2010], part of speech induction [Grac?a et al,2009a], multi-view learning [Ganchev et al, 2008], word alignment [Graca et al,2008, Ganchev et al, 2009, Grac?a et al, 2009b], and cross-lingual semanticalignment [Platt et al, 2010].
The framework was independently discoveredby Bellare et al [2009] as an approximation to GE constraints, under the nameAlternating Projections, and used under that name also by Singh et al [2010]and Druck and McCallum [2010] for information extraction.
The frameworkwas also independently discovered by Liang et al [2009] as an approximation to1In Mann and McCallum [2007] the method was called Expectation Regularization.a Bayesian model motivated by modeling prior information as measurements,and applied to information extraction.4 Closely related frameworksQuadrianto et al [2009] introduce a distribution matching framework veryclosely related to GE constraints, with the idea that the model should pre-dict the same feature expectations on labeled and undlabeled data for a set offeatures, formalized as a kernel.Carlson et al [2010] introduce a framework for semi-supervised learningbased on constraints, and trained with an iterative update algorithm very similarto CoDL, but introducing only confident constraints as the algorithm progresses.Gupta and Sarawagi [2011] introduce a framework for agreement that isclosely related to the PR-based work in Ganchev et al [2008], with a slightlydifferent objective and a different training algorithm.ReferencesK.
Bellare, G. Druck, and A. McCallum.
Alternating projections for learningwith expectation constraints.
In Proc.
UAI, 2009.Kedar Bellare and Andrew McCallum.
Generalized expectation criteria for boot-strapping extractors using record-text alignment.
In EMNLP, pages 131?140,2009.Andrew Carlson, Justin Betteridge, Richard C. Wang, Estevam R. Hruschka Jr.,and Tom M. Mitchell.
Coupled Semi-Supervised Learning for InformationExtraction.
In Proceedings of the Third ACM International Conference onWeb Search and Data Mining (WSDM), 2010.M.
Chang, L. Ratinov, and D. Roth.
Guiding semi-supervision with constraint-driven learning.
In Proc.
ACL, 2007.Ming-Wei Chang, Lev Ratinov, and Dan Roth.
Structured learning with con-strained conditional models.
2010.
In submission.M.W.
Chang, L. Ratinov, N. Rizzolo, and D. Roth.
Learning and inferencewith constraints.
In Proceedings of the National Conference on ArtificialIntelligence (AAAI).
AAAI, 2008.G.
Druck, G. Mann, and A. McCallum.
Learning from labeled features usinggeneralized expectation criteria.
In Proc.
SIGIR, 2008.G.
Druck, G. Mann, and A. McCallum.
Semi-supervised learning of dependencyparsers using generalized expectation criteria.
In Proc.
ACL-IJCNLP, 2009a.Gregory Druck and Andrew McCallum.
High-performance semi-supervisedlearning using discriminatively constrained generative models.
In Proceedingsof the International Conference on Machine Learning (ICML 2010), pages319?326, 2010.Gregory Druck, Burr Settles, and Andrew McCallum.
Active learning by label-ing features.
In EMNLP, pages 81?90, 2009b.K.
Ganchev, J. Grac?a, J. Blitzer, and B. Taskar.
Multi-view learning overstructured and non-identical outputs.
In Proc.
UAI, 2008.K.
Ganchev, J. Gillenwater, and B. Taskar.
Dependency grammar induction viabitext projection constraints.
In Proc.
ACL-IJCNLP, 2009.Kuzman Ganchev, Joo Graa, Jennifer Gillenwater, and Ben Taskar.
Posteriorsparsity in unsupervised dependency parsing.
Journal of Machine Learn-ing Research, 11:2001?2049, July 2010.
URL http://jmlr.csail.mit.edu/papers/v11/ganchev10a.html.Jennifer Gillenwater, Kuzman Ganchev, Joo Graa, Ben Taskar, and FernandoPereira.
Sparsity in grammar induction.
In NIPS Workshop on GrammarInduction, Representation of Language and Language Learning, 2009.Jennifer Gillenwater, Kuzman Ganchev, Joo Graa, Fernando Pereira, and BenTaskar.
Posterior sparsity in unsupervised dependency parsing.
Journal ofMachine Learning Research, 12:455?490, February 2011.
URL http://jmlr.csail.mit.edu/papers/v12/gillenwater11a.html.Joao Graca, Kuzman Ganchev, and Ben Taskar.
Expectation maximizationand posterior constraints.
In J.C. Platt, D. Koller, Y.
Singer, and S. Roweis,editors, Advances in Neural Information Processing Systems 20, pages 569?576.
MIT Press, Cambridge, MA, 2008.J.
Grac?a, K. Ganchev, F. Pereira, and B. Taskar.
Parameter vs. posteriorsparisty in latent variable models.
In Proc.
NIPS, 2009a.J.
Grac?a, K. Ganchev, and B. Taskar.
Postcat - posterior constrained alignmenttoolkit.
In The Third Machine Translation Marathon, 2009b.Rahul Gupta and Sunita Sarawagi.
Joint training for open-domain extractionon the web: exploiting overlap when supervision is limited.
In Proceedings ofthe Fourth ACM International Conference on Web Search and Data Mining(WSDM), 2011.P.
Liang, M. I. Jordan, and D. Klein.
Learning from measurements in exponen-tial families.
In Proc.
ICML, 2009.G.
S. Mann and A. McCallum.
Simple, robust, scalable semi-supervised learningvia expectation regularization.
In Proc.
ICML, 2007.G.
S. Mann and A. McCallum.
Generalized expectation criteria for semi-supervised learning of conditional random fields.
In Proc.
ACL, 2008.Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson.
Using uni-versal linguistic knowledge to guide grammar induction.
In Proceedings ofthe 2010 Conference on Empirical Methods in Natural Language Processing,pages 1234?1244, Cambridge, MA, October 2010.
Association for Computa-tional Linguistics.
URL http://www.aclweb.org/anthology/D10-1120.John Platt, Kristina Toutanova, and Wen-tau Yih.
Translingual document rep-resentations from discriminative projections.
In Proceedings of the 2010 Con-ference on Empirical Methods in Natural Language Processing, pages 251?261,Cambridge, MA, October 2010.
Association for Computational Linguistics.URL http://www.aclweb.org/anthology/D10-1025.Novi Quadrianto, James Petterson, and Alex Smola.
Distribution matching fortransduction.
In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams,and A. Culotta, editors, Advances in Neural Information Processing Systems22, pages 1500?1508.
MIT Press, 2009.Sameer Singh, Dustin Hillard, and Chris Leggetter.
Minimally-supervised ex-traction of entities from text advertisements.
In Human Language Tech-nologies: The 2010 Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages 73?81, Los Angeles,California, June 2010.
Association for Computational Linguistics.
URLhttp://www.aclweb.org/anthology/N10-1009.
