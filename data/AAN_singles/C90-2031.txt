On Trying to Do Things with WordsAnother plan-based approach to speech act interpretationMichael J. Hul~mannHeinz GenzmannlFB Informatik, Universit/it HamburgRothenbaumchaussee 67-69D-2000 Hamburg 13, West Germanye-maih hussmann@rz.informatik.uni-hamburg.dbp.deAbst rac tUsnal plan-based approaches to speech act interpreta-tiott require that perib~zning a speech act implies its suc-ces:s. These approaches are thus useless for describingfailing illecut~onary or perlocutionary acts.
We proposean t~lternatiw~ plan-based view of speech acts centeredaround the notion of trying to do - as opposed to actuallydo ing-  an action.
This approach is contrasted with thatof I'errault which aims to overcome similar problems.1.
:~ntroductionThe., plan-based approach to the analysis of natural an-gu~bge dialogues, inspired by the work of Austin \[Austin62\] and Searle \[Searle 75\] \[Searle/Vanderveken 85\], hasdominated most of the dialogue-oriented NLU researchsince the late seventies, cf.
\[Allen 79\], \[Allen 84\], \[Cohen78\], \[CohenfPerrault 791\], \[Perrault/Allen 80\], \[Litman85\]~ \[Pollack 86\].
It is characterized by the following as-sumptions:o Utterances are actions planned and executed by thespeaker to satisfy some of her goals.?
Speech acts can be represented as operators in plan-ning systems such as STRIPS \[Fikes/Nilsson 71\]which relate actions to their preconditions and ef-fects.$ The speaker's beliefs and intentions can be inferredby observing her utterances.Sew~ral variants of describing actions in planning sys-tems have been proposed in the lkerature.
We will usethe tbllowing c, onventions: an action is defined by a quin-tuple comprising?
an ac t ion  descr ip t ion ,  e.g.
(pick-up ?x) in theblocks world domain,o a set of precondit ions,  e.g.
(on-table ?x),?
the add-llst, a set of propositions which become trueonce the action has been performed, e.g.
(holding ?x),?
the delete-l ist,  a set of propositions which are nolonger true after the action has been pertbrmed, e.g.
(on-table ?x),?
the body, a list of lower-level actions comprising thedescribed action, e.g.
the movements of a robot arm:in the blocks world domain.1Thi:~ paper was written by the first author but describes workjointly undertaken with the second.The relationship between these elements is interpretedas condit ional generation (following \[Goldman 70\],\[Pollack 86\]): the execution of the body actions generatesthe defined action (and thus its effects as described inthe add- and delete-list) iffthe preconditions hold.All three acts involved in making an utterance, the lo-cutionary, illocutionary, and perlocutionary acts, mayfail: the addressee may not hear the utterance, she maynot understand the speaker, or she may not react accord-ing to the speaker's intentions.But when actions are defined in terms of their effects,a failure to achieve the effects implies a correspondingfailure to perlbrm the action.
When I try to drive a nailinto the wall with a hammer, and fail, then I have notdriven a nail into the wall.
Similarly, when I utter adeclarative sentence, and fail to convince the hearer, Ihave failed to perform the intended perlocutionary act.When the addressee does not understand me, 1 have noteven performed an illocutionary act, and so on.
Regard-less of the level of description there's always the chancethat the action may fail, i.e.
that there was no action.Even granted that we could capture practically all of therelevant cases by describing the action on the level of,say, producing sounds, there's no way to relate that levelof description to the intentions of the speaker.This is a rather unfortunate r sult, as we take the ob-served action as the starting point for inferring thespeakers beliefs and intentions - -  which may well be thesame, regardless of the speech act's success.
Clearly, anapproach facilitating a uniform treatment of succeedingand failing speech acts would be most welcome.There are two ways to cope with failing speech acts.The first amounts to weakening the inference from theperformance ofan action to its effects being achieved, i.e.making it defeasible.
The other solution is to describe ac-tions in terms not presupposing their successful execu-tion.
The former approach was proposed by Perrault\[Perrault 87\] and further efined by Appelt and Konolige\[Appelt/Konolige 88\], while the latter is the one we use.2.
Perrault 's approachPerrault describes the way assertions influence peoplesbeliefs by distinguishing between axioms describingstrong evidence for beliefs, and default rules capturingthe effects of (sometimes failing) speech acts.
The mostimportant axioms are:179Memory: I'- Bx,tP ~ Bx, t+l\]~x,tpPersistence: l -  Bx, t+lBx,tP:3 Bx,t+lPObseroability: ~ DOx,ta & DOy,tObs(x)DBy,t+lDOx~taAgents remember their previous beliefs (memory), theystick to what they believe they believed previously(persistence).
If an agent observes another agent, sheknows of all actions the observed agent performs (ob-servability).
Memory and persistence together imply thatagents never forget and never change their beliefs.
Ob-serving is regarded as the only dependable mode of ac-quiring new knowledge.Speech acts are considered to be a weaker kind of evi-dence, and thus the effect of uttering a declarative sen-tence is modelled by default rules:Declarative rule: DOx,t(p.) ~ Bx, tpBelief transfer: Bx,tBy, tp~ 13x,tpi.e., an agent believes what she thinks other agents be-lieve, provided this is consistent with her previous be-liefs (belief transfer ule).
Uttering a declarative sentenceimplies by default hat the speaker believes its proposi-tional content (declarative rule).For the most part, this theory makes correct predic-tions.
For example:?
The hearer will not be convinced by an assertion if itcontradicts one of her previous beliefs.?
A liar will not be convinced by her own lie, but maystill believe that she successfully deceived the un-suspecting hearer.In both of these cases do the axioms (memory and persis-tence) override the defaults.However, adopting Perrault's olution has the unfor-tunate side effect of depriving speech act rules of theirdefinitional import: an action may be executed withoutits effects being achieved.
What are the effects anyway?According to Perrault, uttering a declarative sentenceimplies (by default) that the speaker believes its proposi-tional content ~ this can hardly be thought of as an ef-fect of the speech act, and it isn't a precondition, either.As neither the effects of an assertion or its constitutingbody actions are specified, this leaves assertions as a pri-mitive, 'undefined notion.
But what is a theory of asser-tions worth if it does not say what an assertion is orwhat would count as "making an assertion"?.There's also another, more technical problem: when aspeaker has no belief whatsoever about P, she can con-vince herself that P is true by simply uttering "P.': as it'sperfectly consistent for her to believe P, both of thedeclarative rule and the belief transfer ule are applica-ble and will lead to her believing P. Thus, a speaker mayconvince herself of anything she is incompetent of.As Appelt and Konolige have shown, this deficiencycan be overcome by employing a more sophisticatednonmonotonic theory, cf.
\[Appelt/Konolige 88\].
But isthis added complexity really necessary?
Even thoughAppelt and Konolige claim (without proof) that there canbe no specification of the effects of an assertion that ap-plies under all possible circumstances, we aim to achievejust that.
Instead of assuming that speech acts some-times fail to achieve their normal effects, we admit thatin fact no (successful) speech act was performed in thesecases and relate the speakers behaviour to the intendedact by some other means, namely by making explicit thenotion of"tlTing'.3.
Trying to do things with wordsThe missing link between an agent's intentions and her(sometimes unsuccessful) performance of the intendedaction is the notion of"trying~: when an agent has a pre-sent directed intention to A (cf.
\[Bratman 87\]), she willtry to do A, and - -  if the preconditions for doing A aresat is f ied-  she will thereby do A.
Fig.
1 illustrates this:(S  intendsA)leads toinFig.
2: From intention to actionThe try-to-do level of description provides an ideal basisfor analyzing the agent's intentions, as such an analysisis independent ofthe action's uccess.The interpretation process uses a default rule to de-termine whether an action was executed successfully:F rom try-to-do to do: If it is known that anagent S tries-to-do A in the situation SITA2 , thenassume (by default) that S does A in SIT'A.The consequence of this conclusion is modelled by an-other (non default) rule:F rom act ion to effect: If an agent S does A inthe situation SITA, then the preconditions of Aare satisfied in a situation SITp temporally in-cluding SIT A (because otherwise it would havebeen impossible to do A), and the effects of A aresatisfied in a situation SIT E temporally met bySITA.If this conclusion contradicts a previous belief, the de-fault assumption that S had successfully done A is de-feated.Here lies one of the main differences betweenPerrault's approach and our's: where he uses defaults forthe inference from the performance of an action to itseffects, we use defaults for the inference from try-to-do todo.
rFhe results are similar, but this move allows us to2perrault associates belief~ and other propositional ttitudes withtime points, whereas we use situations as partial descriptions ofthe world over a time interval.
For the purpose of this paper wedeliberatly slur over this distinction as it is unimportant for the is-sue at hand.180use strict definitions of speech acts.
For example, the,!~peech act assertion is defined as follows:Aetion~ Assert P (in SITu)Pre~ondi t ionm The hearer believes that thespeaker is sincere and competent in SIT U.Add-list: The hearer believes that the speakerbelieves P.Body: Utter ~P."
(in SIT v)':\[~e effect (as specified in the add-list) is what we take tobe the fllocutionary point: to achieve that the hearer be-lieves that the speaker believes the propositional con-~nt.Let us assume the following scenario: a speaker S ut-4~ers "P." (referring to a situation SIT R) in the situationSIT v. Sincerity and competence of the speaker can bejudged by an observer O (who may be identical to the~!~peaker) using the following rules:Ins incer i ty  o f  a speaker  in ut ter ing an asser-t ion: If it is known to O that for some situationSIT 1 temporally included in SITR, S believes P tobe false in SIT1, then O knows that S is insincerein SITu.I ncompetence  of a speaker  in u t te r ing  anassert ion:  If it is known to O that for some situa-tion SIT 2 temporally including SITR, S has no be-lief regarding the truth of P in SIT2, then Oknows that S is incompetent inSITu,To complete the picture, we use a belief transfer ulequite similar to the one Perrault uses, except that it~flocks inferences of the formBxByBxp ~ BxBxp -~ BxPwhich we think are unreasonable: an agent does not~dopt he beliefs she thinks other people have of her - -at least not automatically.
Fig.
2 illustrates the overall:~tructure of the interpretation process, which is the~mme for the speaker, the hearer, or any incidental over-hearer:H :::::::::::::::::::::::::::::::~ :-:: : i : : : : :  .
.
.
.
.
.
.
.
:::!::iii:!
: :,!i: | {i ~ Illocution.
.
.
.
.
.
.
:!!
::, :+:+: .
: , :  :.
: : .
: .
.
.
.
.
.
.
.
.
, .
.
.
.
.
, , .
, .
.
.
.
.
.
.
: .
: , :+:  :.:,.
:.:.Fig.
2: Interpreting an assertionThe thick gray line encloses the aspects of the interpre-~;ation process described in this paper.An example: the speaker S and the hearer H original-ly beth believe that -P. There are no other relevant be-liefs.
When S utters "P.',?
S recognizes herself to be insincere and thus herassertion - -  as an utterance to herse l f -  fails.
Onthe other hand, it is consistent for S to believe thatH will take her to be competent and sincere by de-fault, and that as an utterance to H the assertionwill succeed, i.e.
BsBHBsp and thus BsBtl p.?
H believes S to be competent and sincere by defaultand therefore the illocutionary act succeeds as an ut-terance to H. H believes that S believes P (BnBsp),but sticks to her previous belief that -P.As a result, beth S and H will continue to believe -~P, butwill also (wrongly) attribute to the other a belief that P.If instead the speaker had no belief about P initially, shewould judge herself incompetent and again would nottrust her own words.Determining the speaker's intentions is considerablymore complex, as it requires earch in a web of action de-scriptions linked by (conditionally-) generates and gener.ated-by relations.
In general, the observed action A o andthe intended action A x are linked by a pathAo generated-by generates A 1The separation of the analysis of belief and intentionsenables a straight-forward interpretation of a speechact's effects while offering a sound basis for the subse-quent analysis of the speaker's and hearer's intentions.4.
Intending to tryWe have described trying-to.do A as an intermediatestep between intending to A and doing A.
An agent maydescribe her actions as "doing A" or "trying to do A', andthe latter will often just reflect her doubts as to whethershe will succeed.
Nevertheless, i fA is an action, then sois tryA, and intending to tryA is a genuine intention dis-tinct from an intention to A.In both cases will the intending agent ry-to-do A, andsometimes doA, but even if she fails to do A, she cannotfail to try A.
Trying A will sometimes have the effects ofA-ing --  and, if it does, will have caused these effects - -but its only necessary result is that A has been tried.Therefore, trying A can be successful where A-ing is not.For example, I may intend to try to move a heavy log (cf.\[Bratman 87:38f\]) while strongly believing I will fail - -just to demonstrate hat I cannot move it.
This demon-stration is successful only if I do not succeed in movingthe log despite trying real hard to do so.Bratman (cf.
\[Bratman 87:111ff\]) did not recognizethe difference between trying.to-do A as a consequence ofintending toA and trying-to-do A as a consequence of in-tending to try A.
His term endeavoring (adopted from\[Chisholm 76\]) encompasses both cases.
This missingdistinction seems to be responsible for most of the lesselegant aspects of Bratman's theory, especially the wayhe relates acting with an intention to acting intentional-ly.
On the "Simple View", ml agents doing A intentionallyimplies her intention to A. Bratman dismisses thisSimple View on the grounds that an agent will some-times act intentionally without (in a strong sense) in-tending the action.181Consider the following example taken from \[Bratman87:137\]: Bratman very much wants to mar~ T Susan, andhe equally much wants to marry Jane.
He knows he can-not marry both but is unable to resolve the conflict.Therefore he hopes that Susan and Jane will settle theissue for him: he tries to persuade both women to marryhim, expecting that just one of the two will agree.
Thiskind of behaviour seems perfectly rational ~ thoughprobably immoral - -  but according to Bratman's trongconsistency requirement for intentions he should not in-tend to persuade Susan and Jane to marry him when heknows he cemnot marry both (and thus cannot achieveboth perlocutionary acts).
Bratman concludes that he in-tentionally persuades Susan as well as Jane, withoutendorsing the inconsistent intention to persuade both.Instead he proposes "guiding desires ~as a weaker kindof intentions guiding an agents conduct.We can offer a simpler solution: while sticking to theSimple View, we agree that it is irrational for Bratmanto intend to persuade two women to marry him.
It is not(necessarily) irrational, however, to intend to try to per-suade both women, believing that at most one of the twowill agree, and such an intention will lead to the samebehaviour towards Susan and Jane as an intention topersuade them simpliciter would.
The distinction be-tween stronger and weaker kinds of intentions is there-fore unnecessary.Returning to the issue of speech act interpretation,consider the following case: Mary is tried for a crime shedid not commit.
She has all the evidence against her,though, and thus she is convinced no one will believe herif she pleads "Not guilty", or even trust her she believesit herself.
Unfortunately, Mary cannot rationally intendto assert she is innocent when she is certain of her fail-ure, so what could she do?
Again, the intention to trycomes to the rescue: poor Mary may rationally intend totry to assert she is innocent (as she has every reason todo so), and this intention will lead to her uttering "Notguilty ~.5.
What has been achieved?We have developed a descriptive framework to provide auniform account of successful as well as unsuccessfulspeech acts.
The notion of trying-to.do an action is appli-cable in both cases and can serve as the basis for ana-lyzing the ~,peaker's intentions.
Our theory makes all thecorrect predictions that Perrault's theory makes, but itdoes additionally handle the cases which are problematicfor Perrault's account.MEDIAS, a module for speech act interpretationalong the lines of the approach presented here has beenimplemented using the expert system shell HARES as arapid prototyping tool \[Genzmann 89\].
MEDIAS handlesassertions as well as yes/no questions, distinguishing in-formation-seeking from information-probing questions.We are currently investigating the role of natural an-guage utterances in initiating, planning, and coordinat-ing cooperative behaviour (cf.
\[Werner 89\]).
This re-search will build upon and extend the first prototype ofthe MEDI~LS system.References\[Allen 79\] James F. Allen: A Plan Based Approach toSpeech Act Recognition.
Technical Report TR121/79, University of Toronto, 1979.\[Allen 84\] James F. Allen: Recognizing intentions fromnatural language utterances.
In: Michael Brady,Robert C. Berwick (eds.
): Computational models ofdiscourse.
Cambridge, Massachusetts: The MITPress 1984.
107--166.\[Appelt/Konolige 88\] Douglas Appelt, Kurt Konolige: APractical Nonmonotonic Theory for Reasoning aboutSpeech Acts.
In: Proc.
of the 26th Annual Meeting ofthe ACL, State University of New York a~,t Buffalo,June 1988.
170--178.\[Austin 62\] J.
A. Austin: How to Do Things with Words.London: Oxford University Press 1962.\[Bratman 87\] Michael E. Bratman: Intention, Plans, andPractical Reason.
Cambridge, Massachusetts:Harvard University Press 1987.\[Chisholm 76\] Roderick Chisholm: Person and Object.LaSalle, Ill.: Open Court 1976.\[Cohen 78\] Philip R. Cohen: On Knowing What to Say:Planning Speech Acts.
PhD thesis, University ofToronto, 1978.\[Cohen/Perrault 79\] Philip R. Cohen, C. RaymondPerrault:  Elements of a Plan-based Theory ofSpeech Acts.
In: Cognitive Science, Vol.
3, 1979.117--212.\[Fikes/Nilsson 71\] Richard E. Fikes, Nils J. Nflsson:STRIPS: A New Approach to the Application of The-orem Proving to Problem Solving.
In: Artificial Intel-ligence, Vol.
2, 1971.
189--208.\[Genzmann 89\] Heinz Genzmann: Eine Untersuchungzur automatischen Modellierung natfirlichsprach-licher Dialogstrukturen i der Mensch?Maschine-Kommunikation.
Diploma thesis at the ComputerScience Department of the University of Hamburg,August 1989.\[Goldman 70\] Alvin I. Goldman: A Theory of Human Ac-tion.
Engleweod Cliffs, N.J.: Prentice-Hall 1970.\[Litman 85\] Diane Judith Litman: Plan Recognition andDiscourse Analysis: An integrated Approach for Un-derstanding Dialogues.
Technical Report 170, Dept.of Computer Science, University of Rochester 1985.\[Perrault/Mlen 80\] C. Raymond Perrault, James F.Allen: A plan-based analysis of indirect .~Jpeech acts.In: American Journal of Computational Linguistics,No.
6, Vol.
3, 1980.
167--182.\[Perrault 87\] C. Raymond Perrault: An Application ofDefault Logic to Speech Act Theory.
Report CSL1-87-90.
CSLI, Stanford, California, March 1987.\[Pollack 86\] Martha Elizabeth Pollack: Inferring DomainPlans in Question-Answering.
Technical Note 403.AI Center, Computer and Information Sciences Di-vision, SRI International, December I, 1986.\[Searle 75\] John R. Searle: A Taxonomy of IllocutionaryActs.
In: K. Gunderson (ed.
): Language, Mind, andKnowledge.
Minneapolis: University of MinnesotaPress 1975.\[Searle/Vanderveken 85\] John R. Searle, DanielVanderveken: Foundations of Illocutionary Logic.Cambridge: Cambridge University Press 1985.\[Werner 89\] Eric Werner: Cooperating Agents: A UnifiedTheory of Communication and Social Structure.
In:M. Huhns, L. Gasser (eds.
): Distributed ArtificialIntelligence, Vol.
2.
Morgan Kaufman and PitmanPublishers, 1989.182
