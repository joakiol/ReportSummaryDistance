Proceedings of the ACL-2012 Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM-2012),pages 47?56, Jeju, Republic of Korea, 13 July 2012. c?2012 Association for Computational LinguisticsBridging the Gap Between Scope-based and Event-basedNegation/Speculation Annotations: A Bridge Not Too FarPontus Stenetorp1 Sampo Pyysalo2,3 Tomoko Ohta2,3Sophia Ananiadou2,3 and Jun?ichi Tsujii2,3,41Department of Computer Science, University of Tokyo, Tokyo, Japan2School of Computer Science, University of Manchester, Manchester, United Kingdom3National Centre for Text Mining, University of Manchester, Manchester, United Kingdom4Microsoft Research Asia, Beijing, People?s Republic of China{pontus,smp,okap}@is.s.u-tokyo.ac.jpsophia.ananiadou@manchester.ac.ukjtsujii@microsoft.comAbstractWe study two approaches to the marking ofextra-propositional aspects of statements intext: the task-independent cue-and-scope rep-resentation considered in the CoNLL-2010Shared Task, and the tagged-event representa-tion applied in several recent event extractiontasks.
Building on shared task resources andthe analyses from state-of-the-art systems rep-resenting the two broad lines of research, weidentify specific points of mismatch betweenthe two perspectives and propose ways of ad-dressing them.
We demonstrate the feasibilityof our approach by constructing a method thatuses cue-and-scope analyses together with asmall set of features motivated by data anal-ysis to predict event negation and speculation.Evaluation on BioNLP Shared Task 2011 dataindicates the method to outperform the nega-tion/speculation components of state-of-the-art event extraction systems.The system and resources introduced in thiswork are publicly available for research pur-poses at: https://github.com/ninjin/eepura1 IntroductionUnderstanding extra-propositional aspects of textsis key to deeper understanding of statements con-tained in natural language texts.
Extra-propositionalaspects such as the polarity of key statements havelong been acknowledged to be critical for user-facing applications such as information retrieval(Friedman et al, 1994; Hersh, 1996).
In recogni-tion of this need, a number of recent informationextraction (IE) resources involving structured repre-sentations of text statements have explicitly includedsome marking of certainty and polarity (LDC, 2005;Kim et al, 2009; Saur and Pustejovsky, 2009; Kimet al, 2011a; Thompson et al, 2011).Although extra-propositional aspects are recog-nised as important, there is no clear consensus onhow to address their annotation and extraction fromtext.
Some comparatively early efforts focused onthe detection of negation cue phrases associated withspecific (previously detected) terms through regu-lar expression-based rules (Chapman et al, 2001).A number of later efforts identified the scope ofnegation cues with phrases in constituency analy-ses in sentence structure (Huang and Lowe, 2007).Drawing in part on this work, the BioScope corpus(Vincze et al, 2008) applied a representation whereboth cues and their associated scopes are marked ascontiguous spans of text (Figure 1 bottom).
This ap-proach was also applied in the CoNLL-2010 SharedTask (Farkas et al, 2010), in which 13 participat-ing groups proposed approaches for Task 2, whichrequired the identification of uncertainty cues andtheir associated scopes in text.
In the following,we will term this task-independent, linguistically-motivated approach as the cue-and-scope represen-tation (please see Vincze et al (2008) for details re-garding the representation).For IE efforts, more task-oriented representationsare commonly applied.
In an effort to formaliseand drive research for extracting structured repre-sentations of statements regarding molecular biol-ogy, the ongoing series of BioNLP shared taskshave addressed biomedical Event Extraction (EE)(Kim et al, 2009; Kim et al, 2011a).
The extra-propositional targets of negation and speculation47Figure 1: Example illustrating cue-and-scope andevent-based negation marking.
?Crossing-out?marks events as negated.
PRO, TH and NEG are ab-breviations for PROTEIN, THEME and NEGATION,respectively.of extracted events were already included in thefirst task in the series, using a representation whereevents can be assigned ?flags?
to mark them as beingnegated, speculated, or both (Figure 1 upper).
Dueto space limitations we refer the reader to Kim et al(2009) for a detailed explanation of the representa-tion; similar representations have been applied alsoin previous event extraction tasks (LDC, 2005).There are a number of ways in which task-oriented, event-based approaches could benefit fromthe existing linguistically-oriented cue-and-scopemethods for identifying extra-propositional aspectsof text statements.
However, there has been sur-prisingly little work exploring the combination ofthe approaches, and comparatively few methods ad-dressing the latter task in detail.
Only three outof the 24 participants in the BioNLP Shared Task2009 submitted results for the non-mandatory nega-tion/speculation task, and although negation andspeculation were also considered in three main tasksfor the 2011 follow-up event (Kim et al, 2011a),the trend continued, with only two participants ad-dressing the negation/speculation aspects of the task.We are aware of only two studies exploring the rela-tionship between the cue-and-scope and event-basedrepresentations: in a manual analysis of scope over-lap with tagged events, Vincze et al (2011) identi-fied a number of issues and mismatches in annota-tion scope and criteria, which may explain in partthe lack of methods combining these two lines ofresearch.
Kilicoglu and Bergler (2010) approachedthe problem from the opposite direction and used anexisting EE system to extract cue-and-scope annota-tions in the CoNLL-2010 Shared Task.In this work, we take a high-level perspective,seeking to bridge the linguistically oriented frame-work and the more application-oriented event frame-work to overcome the mismatches demonstratedby Vincze et al (2011).
Specifically, we aim todetermine how cue-and-scope recognition systemscan be used to produce a state-of-the-art nega-tion/speculation detection system for the EE task.2 ResourcesSeveral existing resources can support the investiga-tion of the relationship between the linguistically-oriented and task-oriented perspectives on nega-tion/speculation detection.
In this study, we makeuse of the following resources.First, we study the three BioNLP 2011 SharedTask corpora that include annotation for negationand speculation: the GE, EPI and ID main task cor-pora (Table 1).
Second, we make use of support-ing analyses provided for these corpora in responseto a call sent by the BioNLP Shared Task organis-ers to the developers of third-party systems (Stene-torp et al, 2011).
Specifically, we use the outputof the BiographTA NeSp Scope Labeler (here re-ferred to as CLiPS-NESP) (Morante and Daelemans,2009; Morante et al, 2010) provided by the Univer-sity of Antwerp CLiPS center.
This system providescue-and-scope analyses for negation and speculationand was demonstrated to have state-of-the-art per-formance at the relevant CoNLL-2010 Shared Task.Finally, we make use of the event analyses createdby systems that participated in the BioNLP SharedTask, made available to the research community forthe majority of the shared task submissions (Pyysaloet al, 2012).
These analyses represent the state-of-the-art in event extraction and their capability todetect event structures as well as marking them fornegation and speculation.The above three resources present us with manyopportunities to relate scope-based annotations tothree highly relevant event-based corpora containingnegation/speculation annotations.3 Manual AnalysisTo gain deeper insight into the data and the chal-lenges in combining the cue-and-scope and event-oriented perspectives, we performed a manual anal-ysis of the corpus annotations using the manually48Name Negated Events Speculated Events Negated Spans Speculated Spans PublicationEPI 103 (5.6%) 70 (3.8%) 561 1,032 Ohta et al (2011)GE 759 (7.4%) 623 (6.0%) 1,308 1,968 Kim et al (2011b)ID 69 (3.3%) 26 (1.2%) 415 817 Pyysalo et al (2011)Table 1: Corpora used for our experiments along with annotation statistics for their respective training sets.The parenthesised values are the relative proportion of negated/speculated event annotations.Occ.
(Ratio) EPI IDCovered 26 (15.03%) 52 (56.52%)Not-covered 135 (78.03%) 38 (41.30%)Error-in-gold 12 (6.94%) 2 (2.18%)Morphological 48 (27.75%) 11 (11.96%)Hypothesis 44 (25.43%) 15 (16.30%)Ellipsis 5 (2.89%) 0 (0.00%)Argument-only 2 (1.16%) 10 (10.87%)Table 2: Results from the Manual Data Analysis ofthe EPI and ID test sets.created BioNLP Shared Task training data event an-notations, and the automatic annotations created forthis data by the CLiPS-NESP system.
The testdata was held out and was not directly examinedat any point of our study.
We performed the anal-ysis specifically on the EPI and ID corpora, as theGE corpus training set texts overlap with the train-ing data for the CLiPS-NESP system (BioScope cor-pus), and results on this data would thus not reflectthe performance of the system on unseen data, anda comparison of the GE and BioScope gold anno-tations was previously performed by Vincze et al(2011).The analysis was performed by an experiencedannotator with a doctoral degree in a related fieldin biology, who individually examined each of theevents marked as negated and speculated in theEPI and ID training corpora.
For the analysis,the CLiPS-NESP system output was super-imposedonto the BioNLP Shared Task event annotations.The annotator was asked to assign three primaryflags for each event that was marked as negated orspeculated: Covered if the event trigger was coveredby span(s) of the correct type with a correct cue inthe cue-and-span analysis, Not-covered if not Cov-ered, and Error-in-gold if the negation/speculationflag on the event annotation was itself incorrect.
Wealso identified a number of additional properties thatinitial analysis suggested to frequently characteriseinstances where the coverage of the cue-and-scopesystem is lacking: Morphological was assigned ifthe negation/speculation of an event could be in-ferred only from the morphology of the word ex-pressing the event, rather than from cue words in itscontext (e.g.
unphosphorylated, non-glycosylated);Hypothesis for cases where speculation is markedfor events stated as hyphotheses1 under consider-ation, e.g.
?We analysed the methylation status ofMGMT?
; Ellipsis for cases where the modified ex-pression is elided (e.g.
?A was phosphorylated but Bwas not?
); and Argument-only if the CLiPS-NESPoutput had marked the argument of an event asnegated rather than the event trigger (we use argu-ment in the sense it is used in the BioNLP SharedTasks, for example, in Figure 1 upper, the two argu-ments of the event are ?fMimR?
and ?fimA?
).The results of the analysis are summarised in Ta-ble 2.
We find that that the system shows a clear dif-ference in coverage depending on the dataset.
Forthe ID dataset, a majority of the annotations are cov-ered by the appropriate spans, while only a small mi-nority are covered for EPI.
Instead, the EPI datasetcontains a significant portion of events where extra-propositional aspects can only be distinguished bythe morphology of the word expressing the event(all Morphological cases were negation) as well asevents marked as speculated due to being expressedas hypotheses under study.The analysis thus identified specific ways inwhich the applicability of negation-detection sys-tems using a span-and-scope representation could beimproved for some tasks.1While it is arguable whether such cases represent specula-tion (Vincze et al, 2008), separation from affirmatively madeclaims is clearly motivated for many applications.49Event-basedScope-basedNegation/speculationdetectionEventextractionOursystemFigure 2: An illustration of our approach.4 MethodsWe next introduce the methods we apply for as-signing negation and speculation flags to extractedevents.4.1 ApproachTo focus on the extra-propositional aspects of eventextraction, we only consider the assignment of thenegation and speculation flags, not the extraction ofthe event structures that these mark.
To our knowl-edge, no previous work studying this subtask in iso-lation from event extraction exists.
Thus, in order tobe able to relate the performance of the methods weconsider to the performance of previously proposedapproaches, it is necessary to base the negation andspeculation detection on an event extraction analy-sis.
For this reason, we construct our methods us-ing system outputs for systems participating in theBioNLP Shared Task 2011, in effect creating a nega-tion/speculation processing stage for a pipeline sys-tem where the previous stage is the completion ofevent analysis without negation/speculation detec-tion (Figure 2).Our methods thus take extracted events as inputand attempt to enrich the output with negation andspeculation annotations.
This enables us to producea general system with the potential to be appliedtogether with any existing event extraction system.Additionally, this allows us to directly compare oursystem output with that of the negation/speculationcomponents of previously proposed monolithic sys-tems by removing the existing negation and spec-ulation output from submissions including this andrecreating these annotations using our methods.4.2 Rule-based MethodsThe most straightforward way of carrying over in-formation from scope-based to event-based annota-tions is to consider any event structure for which theword or words stating the event (i.e.
the event trig-ger) is within the scope of a negation or speculationbe negated or speculated (respectively).
We imple-mented this simple heuristic as our initial rule-basedmethod.One relatively common category of cases wherethis heuristic fails that was identified in analysis re-lates to events that take other events as arguments.Consider, for example, the case illustrated in Fig-ure 3.
The speculation span is correctly identified ascovering the statement ?FimR modulates mfa1 ex-pression?, and the event expressed through ?mod-ulates?
is identified as speculated.
However, thenested event, the expression of mfa1, is not spec-ulated.
To cover this case, we implemented whatwe refer to as the root-heuristic, which prevents thepropagation of negation/speculation marking fromscopes to events that are the arguments of anotherevent contained in the same scope.
The second rule-based method we consider incorporates this addi-tional heuristic.Preliminary development set experiments indi-cated that while the root-heuristic could improveprecision, the performance of the rule-based meth-ods remained poor, in particular on the EPI dataset.The results of the manual analysis (Section 3) sug-gested this to trace in particular to two main issues,namely differences between annotation criteria be-tween BioScope and the shared task data (as notedalso by Vincze et al (2011)) and events which arenegated not by external cues but by morphologicalalternations of the event trigger, such as ?unphos-phorylated?
expressing the absence of phosphory-lation.
As it would have been difficult to system-atically incorporate both morphology and contextinto the rule-based method without compromisingthe generality of the approach, we opted to move to amachine learning framework for further method de-velopment.
This allows us to continue to make useof the existing cue-and-scope annotations while ex-ploring the effects of other aspects of the text andmaintaining generality through retraining.4.3 Machine Learning-based MethodsIn developing a machine learning-based approach tothe negation/speculation task, we aimed to identifyand evaluate a minimal set of features directly mo-50Feature Example Value(s)Heuristic ROOT/NON-ROOTHeuristic-Cue possibilityHeuristic-Span One, possibility, .
.
.Trigger-Text non-phosphorylatedTrigger-Prefixes no, non, non-, .
.
.Trigger-Preceding-Context is, that, .
.
.Trigger-Proceeding-Context mfa1, expression, .
.
.Table 3: Machine learning features.
The fea-tures are categorised into three groups: featuresbased on cue-and-scope based heuristics (top), non-contextual features derived from the event trigger(middle), and features derived from the context ofthe event trigger (bottom).
These three feature setsare abbreviated as E, M and C, respectively.Figure 3: Example of a speculation span containingtwo events, of which only one is speculated (markedby a dashed border).tivated by the analysis of the data and to use thecue-and-scope analyses as much as possible.
In par-ticular, we wanted to avoid features requiring com-putationally expensive analyses such as full pars-ing or replicating the type of analyses performed bythe CLiPS-NESP system, focusing rather on specificpoints where its output does not meet the needs ofthe event-based approach.We introduced features representing the heuristicsdescribed in Section 4.2, marking each case as be-ing either a root or non-root event in its scope (ifany).
Drawing further on the cue-and-scope analy-sis, we included as features the cue word and bag-of-words features for all tokens in the scope (using sim-ple white-space tokenisation).
To address the issuesidentified in manual analysis, we introduced featuresfor the event trigger text as well as character-basedprefixes of lengths 2 to 7 of the, intended primarilyto capture morphological negation.All features presented above are derived onlyfrom those parts of the sentence already marked ei-ther by the event extraction or the cue-and-scopesystem.
However, due to the differences in anno-tation guidelines for speculation annotations, we ex-pect that the scope-based system will fail to marka significant portion of the speculation annotations.To allow the system to learn to detect these, we in-troduce a minimal set of contextual features, limitedto a bag-of-words representation of the three wordspreceding and following the event trigger.5 ExperimentsWe perform two sets of experiments, the first to eval-uate our approach on gold annotations to give a fairupper-limit to how well our negation/speculation de-tection system could perform under ideal settings,and the second to enrich the output of an event ex-traction system with negation and speculation an-notations, to evaluate real-world performance andto allow direct comparison of our methods withthose incorporated in monolithic event extractionand negation/speculation detection systems.5.1 CorporaFor our experiments we used the GE, EPI and IDcorpora of the BioNLP Shared Task 2011 (Table 1).We note that while the GE training set texts overlapwith the BioScope corpus used to train the CLiPS-NESP system, the GE test set does not, and thus testset results are not expected to be overfit.We noted when performing development setexperiments that training machine learning-basedmethods on the negation/speculation annotations ofthe event-annotated corpora was problematic due tothe sparseness of these flags in the annotation.
Toaddress this issue, we merge the training data of thethree corpora in all experiments with machine learn-ing methods.5.2 Baseline methodsWe use the event analyses created by the UTurku(Bjo?rne and Salakoski, 2011) and UConcordia (Kil-icoglu and Bergler, 2011) systems for the BioNLP2011, the only systems that included negation andspeculation analyses.
To investigate the impact on asystem that did not include a negation/speculationcomponent, we further consider analyses created51Negation (R/P/F) EPI GE IDH 29.23/31.67/30.40 53.92/52.84/53.38 44.00/31.88/36.97HR 27.69/32.73/30.00 53.24/71.89/61.18 44.00/37.93/40.74M 47.69/20.00/28.18 43.00/25.25/31.82 46.00/26.74/33.82ME 60.00/66.10/62.90 58.36/70.08/63.69 54.00/69.23/60.67MC 40.00/74.29/52.00 58.36/76.34/66.15 52.00/61.90/56.52MCE 58.46/73.08/64.96 61.77/83.03/70.84 58.00/70.73/63.74Table 4: Results for Negation for our two heuristics and the four combinations of machine learning features.Speculation (R/P/F) EPI GE IDH 13.46/6.48/8.75 33.77/18.12/23.58 54.17/6.50/11.61HR 11.54/5.66/7.59 32.79/29.45/31.03 54.17/7.98/13.90M 1.92/0.62/0.93 25.65/10.84/15.24 45.83/10.58/17.19ME 3.85/12.50/5.88 22.08/42.24/29.00 29.17/28.00/28.57MC 51.92/52.94/52.43 27.27/50.30/35.37 37.50/31.03/33.96MCE 48.08/51.02/49.50 31.82/53.85/40.00 33.33/42.11/37.21Table 5: Results for Speculation for our two heuristics and the four combinations of ML features.by the FAUST system, which achieved the high-est performance at two of the three tasks consid-ered (Riedel et al, 2011).
The UTurku system isa pipeline ML-based EE system, while the UCon-cordia system is strictly rule-based.
FAUST is anML-based model combination system incorporatinginformation from the parser-based Stanford system(McClosky et al, 2011) and the jointly-modelledUMass system (Riedel and McCallum, 2011).We also performed preliminary experiments forthe other released submissions to the BioNLP 2011Shared Task, but due to space limitations focus onlyon the three above-mentioned systems.5.3 Evaluation criteriaWe use the primary evaluation criteria of theBioNLP 2011 Shared Task (Kim et al, 2011a) toassure comparability, reporting all results using thestandard precision, recall and their harmonic mean(F-score).5.4 MethodsWe apply the rule-based simple heuristic methodand its root extension (Section 4.2) as well as Sup-port Vector Machines (SVM) trained with the fea-tures introduced in Section 4.3.
For the SVM, weseparately evaluate models based on all permuta-tions of the feature sets introduced in Table 3.
In theresults tables we abbreviate the feature set names asdone in Table 3 and use H for the heuristic methodand R for its root extension.
As our machine learn-ing component we use LIBLINEAR (Fan et al,2008) with a L2-regularised L2-loss SVM model.We optimise the SVM regularisation parameter Cusing 10-fold cross-validation on the training data.We use the training, development and test set par-tition provided by the shared task organisers.
In linewith standard ML methodology the test set was heldout during development and was only used whencarrying out the final experiments prior to submit-ting the manuscript.6 Results and DiscussionOur initial experiments, building on gold event data(Tables 4 and 5), support our manual analysis, show-ing nearly uniform performance improvement withadditional features.
First, we find that the root-heuristic gives an improvement over the originalheuristic in four out of six cases.
To justify our us-age of the cue-and-scope based heuristic feature (E)we find that adding it as a feature improves on the Mfeature set and the MC feature set, showing that evengiven context, the cue-and-scope perspective is stilluseful.
The only anomaly is for speculation on theEPI dataset, where adding this heuristic feature ac-tually hampers performance, possibly relating to the52Negation (R/P/F) EPI GE IDUConcordia 16.92/61.11/26.51 18.43/43.44/25.88 22.00/23.91/22.92UConcordia* 20.00/70.59/31.17 20.14/42.96/27.42 28.00/31.58/29.68UTurku 12.31/38.10/18.60 22.87/48.85/31.15 26.00/44.83/32.91UTurku* 43.08/48.28/45.53 21.16/38.56/27.33 26.00/41.94/32.10FAUST* 29.23/59.38/39.18 21.50/41.18/28.25 28.00/46.67/35.00Table 6: Results of the Negation enrichment experiment.Speculation (R/P/F) EPI GE IDUConcordia 5.77/8.33/6.82 21.10/38.46/27.25 8.33/2.00/3.23UConcordia* 1.92/4.55/2.70 12.99/29.20/17.98 8.33/2.22/3.51UTurku 30.77/48.48/37.65 17.86/32.54/23.06 12.50/18.75/15.00UTurku* 46.15/47.06/46.60 11.04/26.56/15.60 8.33/3.33/4.76FAUST* 36.54/48.72/41.76 10.39/26.50/14.93 12.50/12.50/12.50Table 7: Results of the Speculation enrichment experiment.
(R/P/F) EPI IDUConcordia 20.83/42.14/27.88 49.00/40.27/44.21UConcordia* 20.83/42.94/28.05 49.20/41.78/45.19UTurku 52.69/53.98/53.33 37.85/48.62/42.57UTurku* 54.72/53.86/54.29 37.79/47.76/42.19FAUST 28.88/44.51/35.03 48.03/65.97/55.59FAUST* 31.64/45.17/37.21 49.20/64.66/55.88Table 8: Overall scores for the EPI and ID data sets.sparseness of useful annotations due to the differingannotation guidelines, as noted in manual analysis.The numbers from these initial experiments serve asan upper bound when we proceed to our enrichmentexperiments, as they do not suffer from the possibil-ity of producing false positives negation/speculationannotations for false positive event structures.In addition to the above in preliminary experi-ments we also considered two features inspired byfindings made by Vincze et al (2011).
A distance-based feature, measuring the distance in tokens be-tween the cue-word and the event trigger, and alsotrigger suffixes to capture some cases of morpholog-ical speculation (?induced?
vs.
?inducible?).
How-ever, we failed to establish any consistent benefitsfrom these features and only for the EPI dataset didthe suffix features improve performance.For the enrichment evaluation, adding nega-F EPI GE IDUConcordia 57.43 60.68 67.28UTurku 81.31 66.27 55.84FAUST 74.91 66.14 67.13Table 9: Estimated F-score upper-bound for an ora-cle system precision assigning negation/speculationannotations to events predicted by an up-stream EEsystem.tion/speculation flags to the output of event extrac-tion systems (Tables 6 and 7), our results are some-what more modest.
For negation we see an improve-ment in four out of six cases, and for speculation intwo out of six.
Despite the fact that a major limi-tation to our approach are the false positive eventsthat are propagated from the original EE system, wemanage to improve the global score for all data setswhere a global score is provided by the organisers(Table 8).
We improve a full point in F-score forUTurku on EPI, but only sub-percentage for Fauston ID, the latter most likely since ID contains fewernegation and speculation annotations and the globalscores are microaverages over all annotations.As a final analysis we estimate the upper-boundin F-score performance for all three EE systems(Table 9).
We do so by assuming that the recallfor events marked by negation and speculation is53equal to that of the overall recall of the up-streamEE system and that negation/speculation annotationsassigned by an oracle.
What we can see is thatthere is still room for improvement, both for ourenrichment approach and for the EE system?s inter-nal negation/speculation components, although re-call of the EE output is a limiting factor we canexpect further efforts towards improving the extra-propositional aspects of the system to yield perfor-mance improvements.7 Conclusions and Future WorkIn this study, we have considered two broad linesof research on extra-propositional aspects of keystatements in text, one using the task-independent,linguistically-motivated cue-and-scope representa-tion applied in the recent CoNLL-2010 Shared Task,and the other using the task-oriented flagged-eventrepresentation applied e.g.
in the ACE and BioNLPShared Task evaluations.
We presented a detailedmanual analysis exploring points of disagreementand evaluated in detail rule-based and machinelearning-based methods joining state-of-the-art sys-tems representing the two approaches.Our manual analysis identified a number of phe-nomena that limit the applicability of existing cue-and-scope based systems to the event extractiontask, such as negation expressed through morpho-logical change of words expressing events (e.g.
un-phosphorylated).
To address these issues, we pro-posed a combination of heuristics and simple lexicalfeatures, carefully selected to address differences inperspective between the cue-and-scope and event-based frameworks and aiming to complement cue-and-scope analyses for creating task-oriented out-puts.To test our approach, we created a method suit-able for use as a component of an event extractionpipeline that incorporates information from a previ-ously proposed state-of-the-art cue-and-scope basednegation/speculation detection system and a mini-mal set of features in an SVM-based system that wasshown to enhance and in several cases improve uponthe output of existing EE systems.
Experiments onthe BioNLP Shared Task 2011 EPI and ID datasetsdemonstrated that the combined approach could im-prove the results of the best-performing systems atthe original task in 5 out of 6 cases, outperformingthe highest results reported for any system for thesetwo tasks.There exist several potential targets for futurework on improving our introduced system andto join cue-and-scope and event-based approaches.Since none of the existing EE corpora was con-structed with the aim to solely cover negation andspeculation annotations and taking into account ourfinding that merging datasets to compensate for datasparseness is beneficial, it might be worth consid-ering other possible corpora or resources and howthey can be used for training our machine learningsystem.Also, it would be worthwhile to attempt to com-bine an existing EE system capable of detect-ing negation/speculation with our proposed method.Combining the two could yield an ensemble, im-proving upon an already strong system by bridgingthe differences in perspectives and tapping into thepotential benefits of both approaches.The system and all resources introduced in thiswork are publicly available for research purposes at:https://github.com/ninjin/eepuraAcknowledgementsThe authors would like to thank the anonymous re-viewers for their many insightful comments and sug-gestions for improvements.This work was funded in part by UK Biotechnol-ogy and Biological Sciences Research Council (BB-SRC) under project Automated Biological Event Ex-traction from the Literature for Drug Discovery (ref-erence number: BB/G013160/1), by the Ministry ofEducation, Culture, Sports, Science and Technologyof Japan under the Integrated Database Project andby the Swedish Royal Academy of Sciences.ReferencesJari Bjo?rne and Tapio Salakoski.
2011.
Generaliz-ing Biomedical Event Extraction.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, pages 183?191.Wendy W. Chapman, Will Bridewell, Paul Hanbury, Gre-gory F. Cooper, and Bruce G. Buchanan.
2001.
Asimple algorithm for identifying negated findings anddiseases in discharge summaries.
Journal of biomedi-cal informatics, 34(5):301?310.54Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A Li-brary for Large Linear Classification.
Journal of Ma-chine Learning Research, 9:1871?1874.Richa?rd Farkas, Veronika Vincze, Gyo?rgy Mo?ra, Ja?nosCsirik, and Gyo?rgy Szarvas.
2010.
The CoNLL-2010Shared Task: Learning to Detect Hedges and theirScope in Natural Language Text.
In Proceedings ofthe Fourteenth Conference on Computational NaturalLanguage Learning, pages 1?12.Carol Friedman, Philip O. Alderson, John H.M. Austin,James J. Cimino, and Stephen B. Johnson.
1994.
Ageneral natural-language text processor for clinical ra-diology.
Journal of the American Medical InformaticsAssociation, 1(2):161?174.William R. Hersh.
1996.
Information retrieval: a healthcare perspective.
Springer.Yuang Huang and Henry J. Lowe.
2007.
A novel hybridapproach to automated negation detection in clinicalradiology reports.
Journal of the American MedicalInformatics Association, 14(3):304?311.Halil Kilicoglu and Sabine Bergler.
2010.
A High-Precision Approach to Detecting Hedges and theirScopes.
In Proceedings of the Fourteenth Conferenceon Computational Natural Language Learning, pages70?77.Halil Kilicoglu and Sabine Bergler.
2011.
Adapting aGeneral Semantic Interpretation Approach to Biolog-ical Event Extraction.
In Proceedings of the BioNLP2011 Workshop Companion Volume for Shared Task,pages 173?182.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overview ofBioNLP?09 Shared Task on Event Extraction.
In Pro-ceedings of the BioNLP 2009 Workshop CompanionVolume for Shared Task, pages 1?9.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, Ngan Nguyen, and Jun?ichi Tsujii.
2011a.Overview of BioNLP Shared Task 2011.
In Proceed-ings of the BioNLP 2011 Workshop Companion Vol-ume for Shared Task, pages 1?6.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-nori Yonezawa.
2011b.
Overview of Genia EventTask in BioNLP Shared Task 2011.
In Proceedingsof the BioNLP 2011 Workshop Companion Volume forShared Task, pages 7?15.LDC.
2005.
ACE (Automatic Content Extraction) En-glish Annotation Guidelines for Events.
Technical re-port, Linguistic Data Consortium.David McClosky, Mihai Surdeanu, and Christopher Man-ning.
2011.
Event Extraction as Dependency Parsingfor BioNLP 2011.
In Proceedings of BioNLP 2011,pages 41?45.Roser Morante and Walter Daelemans.
2009.
Learn-ing the scope of hedge cues in biomedical texts.
InProceedings of the Workshop on Current Trends inBiomedical Natural Language Processing, pages 28?36.Roser Morante, Vincent Van Asch, and Walter Daele-mans.
2010.
Memory-based resolution of in-sentencescopes of hedge cues.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning ?
Shared Task, CoNLL 2010: SharedTask, pages 40?47.Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011.Overview of the Epigenetics and Post-translationalModifications (EPI) task of BioNLP Shared Task2011.
In Proceedings of the BioNLP 2011 WorkshopCompanion Volume for Shared Task, pages 16?25.Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-livan, Chunhong Mao, Chunxia Wang, Bruno So-bral, Jun?ichi Tsujii, and Sophia Ananiadou.
2011.Overview of the Infectious Diseases (ID) task ofBioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, pages 26?35.Sampo Pyysalo, Pontus Stenetorp, Tomoka Ohta, Jin-Dong Kim, and Sophia Ananiadou.
2012.
New Re-sources and Perspectives for Biomedical Event Extrac-tion.
In Proceedings of BioNLP 2012 Workshop.
toappear.Sebastian Riedel and Andrew McCallum.
2011.
RobustBiomedical Event Extraction with Dual Decomposi-tion and Minimal Domain Adaptation.
In Proceedingsof the BioNLP 2011 Workshop Companion Volume forShared Task, pages 46?50.Sebastian Riedel, David McClosky, Mihai Surdeanu, An-drew McCallum, and Christopher D. Manning.
2011.Model Combination for Event Extraction in BioNLP2011.
In Proceedings of the BioNLP 2011 WorkshopCompanion Volume for Shared Task, pages 51?55.Roser Saur and James Pustejovsky.
2009.
Fact-Bank: a corpus annotated with event factuality.Language Resources and Evaluation, 43:227?268.10.1007/s10579-009-9089-9.Pontus Stenetorp, Goran Topic?, Sampo Pyysalo, TomokoOhta, Jin-Dong Kim, and Jun?ichi Tsujii.
2011.BioNLP Shared Task 2011: Supporting Resources.
InProceedings of the BioNLP 2011 Workshop Compan-ion Volume for Shared Task, pages 112?120.Paul Thompson, Raheel Nawaz, John McNaught, andSophia Ananiadou.
2011.
Enriching a biomedicalevent corpus with meta-knowledge annotation.
BMCBioinformatics, 12(1):393.Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gy-orgy Mora, and Janos Csirik.
2008.
The Bio-55Scope corpus: biomedical texts annotated for uncer-tainty, negation and their scopes.
BMC Bioinformat-ics, 9(Suppl 11):S9.Veronika Vincze, Gyorgy Szarvas, Gyorgy Mora,Tomoko Ohta, and Richard Farkas.
2011.
Linguis-tic scope-based and biological event-based specula-tion and negation annotations in the BioScope and Ge-nia Event corpora.
Journal of Biomedical Semantics,2(Suppl 5):S8.56
