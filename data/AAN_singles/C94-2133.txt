Mul t i -Moda l  Def in i te  C lause  GrammarHideo  Sh imazu ,  Se igo  Ar i ta ,  and  Yosuke  Takash imaIn fo rmat ion  Techno logy  Research  Lal)or~tor ies,  NEC Corporat ion4-1-1 Miya.zaki, Miya.mae Kawasak i ,  216 Ja.pan{sh?mazu,  a r i ta ,  yosuke}@joke .c l .nec .co .
jpAbstractThis paper describes the first reported gram-matical framework for a nmltimodal inter-face.
Although multimodal interfaces offer thepromise of a flexible and user fl'iendly meansof human-coml)uter interaction, no study hasyet appeared on formal granunatical f'l'ame-works for theln.
We have developed Multi-Modal Definite Clause Ch'ammar (MM-I)CG),an extension of Definite Clause Gramumr.
Themajor features of MM-I)CG inch, de eal)abilityto handle an arbitrary mlmber of modes andtemporal information in grammar ules, l:ur-ther, we have developed MM-DCG translatorto transfer ules in MM-DCG into Prolog pred-icates.1 In t roduct ionThis paper describes tile first reported grammaticalfi'amework for a multimodal interface.
Specifically, theauthors have developed MM-DC.G (Multi-Modal l)cfi-nite Clause Gra,nmar), an extension of I)CCI \[Pereiraand Warren, 1980\] for lnultm3odal input processing.The major features of MM-DCG include capability tohandle an arbitrary nn,nber of modes and temporal in-formation in grammar ules.The motivation behind this research was two-foht.First, the extension to multimodal was found t.o bethe minimum requirement \[br natural language inter-face systems to be insta.lled in real al~plications.
Wehave developed natural language interface for relationaldatabase (RDB) \[Shimazu et.
al., I9!
)2; Arita et.
al.,1992a; Arita et.
al., 1992b\].
Spoken user queries aretransformed into SQL specifications, and dispatched t.oRDBMS.
The retrieved results are displayed at a com-puter terminal.
The results include not only table formsbut also picture images, like Figure 1.
When users seepicture images on the terminal, they naturally want togenerate following queries by referring to such pictureimages.
For example, they want to say, "Show me theinterior of this one" or "Are there the same type of carsas this ear" while pointing at a specific picture on thedisplay.
If such multi-modal utterances be accept.able,the natural language interface will be more practicalFigure I: Natural Language Interface Screen hnageenough to be used in many real world applications.Second, no st;udy has yet appeard on developing for-real grammatical fi'amework for multi-modal interfaces.Although there have been many researches on multi-modal systems, these systems are built as task-specificexpert systems.
The capability of such systems to pro-cess multi-moda.l inputs is too limited to interpret com-plex multi-modal expressions.
This is mainly due to thefact that they have not developed their systems on for-nml grammatical framework for multi-modal interfaces.MM-DCG is the first reported grammatical frame-work for a multimodal interface.
Multi-modal inputprocessing rules can be written in MM-I)CG simply andeffectively.
Rules in MM-I)CG are translated into Pro-log predicates easily.2 Mul t i -Moda l  Input  P rocess ingConsider a query (.
'xample to a nmlti-modal interfacewith a screen image like Figure.
1.
A user states "Canthis, attach this," pointing at a picture on the screenand clicking the mouse during the first "this" and thenchoosing an item fl'om a lllenu during the second.
Thesystem must realize that the first point is to a spe-cific autonaobile and the second is to the menu item"CD player".
After integrating the two mouse pointingevents into the two "this" in the utterance, the systemnmst create an internal representation f this query thatconforms to SQI, specifications.
\[n tiffs example, evenif the order of the two mouse clicking events is opposite,832the system Intlst generate the salne SQI, spcciiicaI.ion,but the interl>retation will I>e i\]l(>l'e dill|cult.
In orderto interpret such complex (:ombinatio,s of lmllti-modalinputs, the following requirement.s exist:(1) Modes  should be inter I ) reted equal ly  an<t in-del)ende.ntly.
In <:onventiomtl multi-modal systems,natural language mode plays a major role, aml othermodes such as mouse input mode are auxilia.ry.
Inl)utsof auxiliary modes are merged into <;orresl)onding at-ural language expressions iu a surl'ace level, and themerged natural language query is interpreted I>y con-ventionatl natural language parsers.
Therefore, varie.l.yof accepte<l multi-modatl exl>r<'.ssions is very limited.llowever, If each tnode is treated wit, Is the same man-sler as that  of ssatsls'atl \]allgSH/ge IlSOde, SyllldtX assd s(,-mantics of iulmts of each mode are (lefim~d with gram-sBar forlnulat;ion.
'Fhus, ccmq)lex exl)rcsskms can l>e defined declaratively and more easily(2) Mode int<~'rI)reta|;ion should be r<4'(!l'red toone another ,  lnl)uts or each mode should be inter-preted independently.
Ilowever, the interl)retatiol~ ofsuch inputs should be referred I>y other lnode interl)re-tattions.
There are alnbiguities which arc solved only byintegrating partial interl)retabi<ms oF related modes.
Forexaml>le, if user states "tiffs car", l>oi~ttit~g at an objectwhich is overlal>l)ed on the.
car object., the alnhiguity ofthe object pointing must he solved by conHlaring (lietwo mode interpretations.
(3) Mode interpre, tai;icm should handle  temI>oralin thrmat ion .
Tetlq>oral iuformation of inputs, suchas input arriving time, inl,erwd between two inl)uts,plays an important role to i,~terl)rct mull.i-modal inputs.Consider an exasnl>le that a user states "\]low muc\[s isthis car", and points at, a car i>icture a litt.le after theutterance.
If tile interwd is three .scco~sds, the l>ointingevent should be integrated with "this car" in the ut-.terance.
Ilowever, if the ilH.erwd is three illi~sles, tileevent should not I)e int.egraled.3 MM-DCG Des ign  l )ec i s ionsThis section describes major design decisions made indeveloping MM-1)CG.
Ih:eause MM-I)(X; is n supersetof I)CG, everything possihle isl I)(!G is also possibhe inMM-I)CG.
llowever, two major extensions are provided3.1 l l .eceiving Mu l t ip le  Input  S t reamsMM-I)CG cau receive arbitrary mind>ors o\[' different, in-put streams, while I)CG receives only ore!, I';ach modeis assigned an individual stl'ealll.
Tlscrefore, a singlegrammar ule in MM-1)(:C, can allow the coexistence ofgrammatical categories in ditSwent modes, thus allow-ing for their integration.
In addition, coa|.ext sensitiw~inlbrnmtion can be inl.crclmnged among cattegories ofdifferent modes in a single rule.
Figure 2 illustratesa multi-modal input processing luodule which acceptsthree independent streams.~ '  word wordword wordclick clickMulti-modal IngratorMM-DCG Rules:::::::::::::::::::::::::::::::::::::::::::::::::!
:N~i~i:~& li:i~a~?
:!
:i!iii!iiilProlog I, nterpfeterk.l,'igm.e 2: Multi-modal Input Processing ModuleT1 T2 T3 T4 T5 T6I/ II(tl, t2, "the") (t3, 14, "blue") (t5, td, "car")Chronological DiroclionFigure 3: Time Calculation of Instant|areal Semantic(i:attegorics3.2 Cal<:ulating the Ins tant ia ted  T ime ofGrammat ica l  Categorh,,sInputs of a single mode invariably have ordering rela-tions among them.
A parser like DCG uses such orderrelations to amdyze syntax, semantics, and pragmatics.h,pul.s of differe.nt modes, however, have no inherent or-dering rehd.ions.
Therefore, MM-I)CG requires tim at-t.achmelH: of both the beginning time and the end timeto each individual piece or input data.
MM-DCG au-tomatically calculates the beginning time and the endtiuw of any lew4 of grammatical categories generatedduring Imrsing.MM-I)C(; translator automatically generates thecode which calculates the beginsfing and end times ofany body goal in at grammar ule.
The translator gen-erates two extra argnments to store the beginning timeand end time into each head and body goals in MM-I)CG rules.
The beg|truing time argument of the headis unified with the beg|truing time argulner, t of the firsthody goal.
The end time a.rgu,nent of the head is uniIiedwith the end time argument of the last body goal.
Fig-m'e 3 shows the argtH\]lellt organization of noun_phraserule.Thus, for example, if a noun phra~se category is in-stantiatcd by pa.rsing "tile blue car", the beginning timeof the instant|areal category becomes equal to tile begin-,ring tilsle of "the", and the end time of the category isequal to the end time of "car".8.33Mouse input stream(button(left, (10, 20))  (button(left> (7, 25)) 9Time IntervalFigure 4: Thneout C.onceptMM-DCG requires any input frolu every mode tohave begimfing and end times.
Thus, each item in aninput sequence will haw; the following sl.ructilre:input(beginning-time, end-time, <actual input>)which means that the actual input was inputted frolllstart-tlme and completed at.
end-time.
Adding of thistime information is easy for ally of the SOl'l.s of till)ill.modes we are considering (i.e.
speecll recognition, key-board inputs, mouse 1)oint, ing, el.c).One other iml)orta.nt item of notation: \[l'a variableis explicitly bound within at goal, the variable ret.urusthe beginning and end times of the goal hi the R)rlll ofa finletor.
Thus,Time^goalmeans that "if goal succeeds, the beginnhlg time andend time of tile goal are rctnl'ned ill the wu'iable Time.
"Using the time iiflbrmation of instautiated categories,rule writers can define chronological collstra.ints aniongcategories, for exaniple, the following descriptiotl ex-presses a constraint hat pronoun category and pointingcategory nnist be both instantiated wittliu a five se(:-onds~Tl 'pronoun, T2"point ?ng,{Dill is T2 - TI, Di f f< 5}3.3 Def in ing T imeout  in I{.ulesTimeout is a constraint of intervals belween an inputand its succeeding input of n. streanl (See Figure 4).
Ifan interval between inputs of a st rean| hecomes largerthan a threshold defined in gralluiu/r rllles, tile tinieoutoccurs, and tile streani is regarded C.llipl.y l.einporariiyalthough there still exist inputs in it..The following points rule llleaus that "l/eceive i/louseclicking inputs wllile, tile interval between I.wo inputs isless thau 5 seconds or ilnti\] a stream I'Jecoines null, thenreturn the list of the hlputs"po ints (E \ ] )  - -> mouse : E\] (s .
o) .po in ts ( \ [P t  I Pts \ ] )  --> po in t (P t ) ,  po in~s(Pts)point(Loc)  - -> mouse: \ [but ton( le f t ,  Loc)\] .4 Rules Wr i t ten in MM~DCG4.1 SyntaxMM-DCG syntax extends I)CG in the following ways:?
A body goal may o,' may not be specified its con-smiting stream:Irl' a body goal consumes inputs from specificstreams, the goal must be accompanied by thestream names.
For example, tile following rulenoun_phrase --> keyboard:pronoun.nieans that "if the pronoun category is found whichis generated by inputs from the keyboard stream,noun_phrase is found."
If a body goal is not accom-pa,iied by any stream name, the goal is regarded asconsunling sonic amount of inputs fi'om all modes.For example, the following rulenoun_phrase --> noun.lneans that "if the noun category is found whichis generated by inpufos frorn certain streams,noun_phrase is found."?
A terminal synibol should always be accompaniedby a specific stream name:For example, the following rulepointing--> mouse:\[button(left, loc(X, Y)\].means that "if a flmctor button(left, Ice(X, Y)) isfound at the mouse strea.nl, pointing is found".4.2 l ime ExampleTo demonstrate how MM-I)CG rules are written, thissection describes a simple grammar needed to handle"object" with multi-modal inputs.Figure 5 shows the definition of "object".
A rulewriter defines existing slmeams pecifically using a unitclause, active_stream/1.
"Object" are specilied by usingeitller one of the abow~' inodes or their combinations.The first object/ l  delhfition interprets natural lan-guage specifh:ations such as "the blue car".
The secondobject/ l  interprets a nlouse clicking which points at a.sl>ecific grai>hical object on the display.
The third ob-ject/ l  definition izd.erprets a combination of a naturallanguage utterance and a inouse pointing, such as stat-ing "the bhle car" while pointing at a graphical objectoil the display.
A natural language utterance is inter-preted at.
the noun_phrase body goal, and the identifiedobject is bound to Objl.
A mouse pointing event is in-terpreted at the pointing body goal, and the identifiedobject is bound to Obj2.Then, Objl and Obj2 are compared their values in aProlog predicate enclosed inside curly brackets { and}.
Both variables honld be equal.
If not, because theinterpretation of noun_phrase or point ing must be wrong,bacld.racking occurs.As seen above, a single grammar rule in MM-I)CGcan allow the coexistence of grammatical categories indifferent niodes, thus allowing for their integration.
Inaddition, teniporal and context sensitive informationcan be interchanged aniong categories of different modesin a single rule.834~, stream def in i t : ionact ive_stream(speech,  mouse, keyboard).
?, For natural  language modeobject (0bj )  --> notm_phrase(\[Ibj).noun_phl-ase(Obj) -~> ar t i c le ,  adject ive(Att : t ,  A value) ,  noun(Noun),{at t r ibute( type ,  Noun, 0bj ) ,  at t r~bute(Att r ,  A va\]ue, 0bj )}.a r t i c le  - -> (speech or keyboard): \ [ the\] .adjective(color, blue) --> (speech or keyboard):\[b\]ue\].noml(automobile) ---> (speech or keyboaid) : \ [car\] .~.
For mouse modeobject(Obj) =-> po~nting(Ubj).poil lt ing({\]bj) -~> mouse: \ [button( \ ]efL ,  lee(X,  Y))\] ,{at t r ibute( locat ion ,  (X, Y), 0b j )} ,?, For combinations of modesobject(Obj l )  - -> noun phrase(t )b j i ) ,  po int ing(Obj2) ,  {0bjl == 0bj2}.Figure 5: ( ; ramlnar I)cscriplion l",xample Using MM-I)C(;5 T rans la t ing  MM- I )CG in to  P ro logThis secl,ion describes lranslaLioll lcchniquos o\[' MM-I)C(; rules into Prolog i)redi('alcs, l"irst, we explainthe translat, ion method of I~IM.I)(:(; ruh!s with a sin-gle stream.
Even in the single, st rca.
i  cas~', MM-I)(?
(;translation method is dill'err,hi from Ihal of I)( I( ',.
Then,the ira.sial, ion tecludqu<e wit.h tlmlliph' Sll'eaHiS is CXpie|ned.5.1 MM-DCG Trans la | ; ion  for  a S ing le  S t reamA head and body goals i .
a gra .mtar  ride ar~, I re,s latedinto ;~ predicate with four exLra al'guntcl~l.s Lwo for i hebeginning time mid l, he end l inle and Iwo tLr ~'xpressinga eOllSttllled ill\[)ll{, Si, l'i!alll.
'\['h<!
l;ll.\[l!r two al'gtlHtelllS aretim same its the gelleral,cd al'g/llllCIll,S W\]I(!II I)(I(~ ruie,%are translated into Ih'olog prmlicai.es.The beginning tinlc arglmllml, of l, hc head is uni/icdwith i, he begin,ring l,ilnC arguuleul, of i, he lirsl, body goal,and the end t;inlc argumenl, of the head is unilied withthe elK| I, inle of the last, body goal.
For eXalllp\]e, \[,h,.
!following MM-I)C(;  rule (for a single ,%r<un):nounphrase  -- > ar t i c le ,  ad j ,  noun.is translates inl,o:noun_phrase(T0 ,  T, N0, N) : -a r t i c le (T0 ,  TI, NO, Nl),adjective(T2, T3, NI, N~),noun(T4, T, N2, N).or, in Fmglish,There is a retail-phrase l~etu,ecn NO and N i fthere is an article Iwtwccn NO and NI, aud ifthere is an adjectiw!
I,etu,~,,,u NI and N-), aml ifthere is a noun hetwec'n N2 and N, The noun-t~hrasc starts at (1'0, nml cm/s at T. The articlestarts at TO, a11d eu,ls at TI .
"l'lw a+(j('ctivcstarts at T2, and ends at "1'3 \[l'hc tloutl startsat T4, aml ends at T.A rule with a terniinal sylllboI is II'allS\]alcd illlO aullil; ciallse, l"or examl)lc ,noun --> keyboard:\[window\].trails\[aLes into:noun(Ts,Te, \[input(Ts,Te, + <window' ') IN\] ,N) .A funcLor input/3 is inseri,cd into the third argunmntforlllili,~ the input, s\[,rCalll of {,he+ predicate.
The thirdal'~lllllOnl, of t, he t'llllCl\[,or input/3 is the act, ual input item,the "wimhm," string in this example.The first and second al'gUillelll, of input/3 is unitiedwiLh the first and second argument of this unit clauser{~spectiw!ly, Th,~refore, if a string "window" is input vialhe keyboard ~t, reum, the noun category is instant|areal,and the beginldng and end time of the noun categoryis Llle same as t, lle start and (!lid Lime attached to the"window" input.5.2 Exte, ns ion  |;o Ar td t rary  Nmntmr  o fS treal l iSExl, ension frol.
a single st, ream to nmltiple streams iseasy.
E;t('h stream needs four extra arguments - two fort, imiug iuformnt, iou and two for express i .g  a consumedinput Si.l'Calll, Thus, i\[' there are n modes, 4n argumentsarc ~.ldcd into head and goals argunlenl;s.For e?anll~lc: , if l, hcre are two streams, the noun_phrasedefiuitioa in Lhc previous section is translated into thefollowing prolog l , 'edicaws with eight (2 x 4) extra ar-gillllell\[,S:llOUU_i3hras e (TxO, Tx, ~IxO, Nx, Ty O, Ty, NyO, Ny) : -article(TxO,Txl ,NxO,Nxi,TyO,Tyl,NyO,Nyl),adjective (Tx2,Tx3, Nxl ,Nx2,Ty2,Ty3, Nyi ,Ny2),noun(Tx4,Tx,Nx2,Nx,Ty4,Ty,Ny2,Ny).5.3 Ext rac t ions  o f  Tempora l  In fo rmat ionIf there is at variable bindi\]tg within a goal like,Tinle -goalthe goal is t, ranslat, cd into a con,jullcl,ion of two bodygoals (for u single mode):(goa l (T0 ,  "1'1, R0, R ) ,T ime- -  (T0, T1) )835I f there  exist n streams, tim variable Time is boundto a list of n time pairs, such as ~n'two modes:(goal(TxO,Txl,NxO,gxl,TyO,Tyl,NyO,Nyl),Time = \[(TxO, Txl), (TyO, Tyl)\] )6 Related workThe idea of understandillg multi-modal inputs in con-junction with each other, as presented in this paper, isnot particularly new.
The idea of a nnllti-n/odal inputcombining motions and pointing has been explored in anumber of contexts.
The classic 1980 paper "I>ut-That-There" \[Bolt, 1980\] describes an early system that pro-cedurally combined voice and gesture inputs.
This ideawas further explored in terms of integrating natural an-guage and pointing by \[/Iayes, 1988\], who related nmlti-modal inputs to anaphoric reference in imtural languageprocessing, particularly to t.he work o\[' \[Grosz, 1977\] and\[Sidner, 1979\].
Recent work in the design of direct ma-nipulation interfaces has also explored the notion of in-tegrating a set of diverse inpuls.
Othe.r palmrs explor-ing multimodal interfaces include \[Allgayer el.
al., 1989;Cohen el.
a l .
,  1989; Cohen, 1991; Kobsa et.
al., 1986;Wahlster, 1989\].
Most of this work, howew.
'r, has tb-cused on the application of the ideas, and not on theprinciples for integrating the different inputs.
17 ConclusionIn this paper, we haw; proposed the use of a grammarfor dealing with input ewmt.s in a lmdti-modal user in-terface.
We proposed MM-I)C(~, a novel gralnmaticalframework for amult imodal  inl.erface.
MM-I)(:G is anextension of 1)CG for rnull.i-modal inpuls processing.The major features of MM-D(:G inchldc capability tohandle an arbitrary nnnaber of modes and feral)oral in-formation in grammar rules.
We showed its use \['or asimple example.
The translation technique of the MM-DCG rules into Prolog predicates was also presented.An initiM implementation of MM-I)CG has been devel-oped at NEC Corporation, alld is currently being usedfor the development of a l)rototype mull.i-modal inter-face.References\[Allgayer el.
al., 1989\] Allgayer, .\]., Jansen-\Vinke.ln, R.,reddig, C., and Reithing N.,\[Arita et.
al., 1992a\]Arita, S., Shimazu, H., and 'lakashima, Y., "I~orl.ableNatural Language Interface", Proc.
of I.he 8th I\]nnlanInterface Symposium, 1992, (in Japanese).\[Arita et.
al., 1992b\]Arita, S., Shimazu, Ii., and Takashima, Y., "Siml)le+ Robust = Pragmatic: A Natural Lal,guage QueryProcessing Model h)r Card-type 1)atabases", Proc.
ofthe 13th Annual Conference of Ihe Cogldtive Sc:ience.Society, 1992.1A survey of this work is beyond I\[le scope O\[' this paper,the interested reader is directed to the review in \[Shneider-man, 1991\].\[Bolt, 1980\] Bolt, R.A., "Pat-That There: Voice and Ges-ture at the Graphics Interface", Computer Graphics 14,3, 1980.\[Clocksin and Mellish, 1981\] (31ocksin, W.F.
and Mellish,C.S., "Progrannning in Prolog", Springer-Verlag, 1981.\[Cohen et.
al.
, 1989\] Cohen, P.R., l)alryml)le, M., Moran,I).B., Pereira., F.G'.N., et al, "Synergistic Use of DirectManipuhttion and Natnral Language", Proc.
of CHI-88,1989.\[Cohen, 1991\] Cohen, P.R., "The Role of Natural Languagein a MultinlodM Interface", 1991 lnternationM Sympo-sium on Next Generation Human Interface, 1991.\[Grosz, 1977\] Grosz, B.
"The representation a d use of fo-cus in a system for understanding dialogs," Proc.
IJCAI1977, Boston, MA.\[ilayes, 1987\] Hayes, P.J., "Steps towards Integrating natu-ral Language and Graphical Interaction for Knowledge-based Systems", Advances in Artificial Intelligence- II,Elsevier Science Publishers, 1987.\[llayes, 1988\] llayes, P.J., "Using A Knowledge Base ToDrive An Expert Systenl Interface With A Natural Lan-guage Component," in J. IIendler (ed.)
Expert Systems:The User h~terface, Ablex Publishing, 1988.\[Kobsa et.
al., 1986\] Kobsa, A., Allgayer, J., Reddig, C.,Reithing, NI, Schumauks, D., lIarbusch, K., andWahlster, W, "Combining Deictic Gestures and Nat-ural Language for Referent Identification", Proc.
ofCOLING-86, 1986.\[Pereira nd Warren, 1980\] Pereira,l"., and Warren, I).II.D., p"Definite Clause Grammarsfor l,angua.ge Analysis- A survey of the Formalism anda Comparison with Augmented Tl'ausitioll Networks",Artificial Intelligence, vol.
13, no.
3, 1980.\[Shimazu et.
al., 1992\] Shimazu, 11., Arita, S., andTakashima, Y., "Design Tool Combining Keyword An-alyzer and Case-Based Parser \['or Developing NaturalLanguage I)ataBase Interfaces", Proc.
of COLING-92,1992.\[Shneiderman, 1991\] Designing The User Interface, Addi-son Wesley Publ., Reading, MA.\[Sidner, 1979\] Sidner, C. Towards a computational theory o\]definite anaphora comprehension i  English Discourse,T1{-537, MIT AI l,ab, Cambridge, Ma.\[Wahlster, 1989\] Wahlster, W., "User and discourse, modelsfor multimodal communication", in a.W.
Sullivan andS.W.
'\]'yler, editors, Intelligent User Interfaces, chap-ter3, ACM Press Frontiers Series, Addison Wesley Pub-lishing, 1989.836
