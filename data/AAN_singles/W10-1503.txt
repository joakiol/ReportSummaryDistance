Proceedings of the NAACL HLT 2010 Sixth Web as Corpus Workshop, pages 17?25,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsSketching Techniques for Large Scale NLPAmit Goyal, Jagadeesh Jagarlamudi, Hal Daume?
III, and Suresh VenkatasubramanianUniversity of Utah, School of Computing{amitg,jags,hal,suresh}@cs.utah.eduAbstractIn this paper, we address the challengesposed by large amounts of text data byexploiting the power of hashing in thecontext of streaming data.
We exploresketch techniques, especially the Count-Min Sketch, which approximates the fre-quency of a word pair in the corpus with-out explicitly storing the word pairs them-selves.
We use the idea of a conservativeupdate with the Count-Min Sketch to re-duce the average relative error of its ap-proximate counts by a factor of two.
Weshow that it is possible to store all wordsand word pairs counts computed from 37GB of web data in just 2 billion counters(8 GB RAM).
The number of these coun-ters is up to 30 times less than the streamsize which is a big memory and space gain.In Semantic Orientation experiments, thePMI scores computed from 2 billion coun-ters are as effective as exact PMI scores.1 IntroductionApproaches to solve NLP problems (Brants et al,2007; Turney, 2008; Ravichandran et al, 2005) al-ways benefited from having large amounts of data.In some cases (Turney and Littman, 2002; Pat-wardhan and Riloff, 2006), researchers attemptedto use the evidence gathered from web via searchengines to solve the problems.
But the commer-cial search engines limit the number of automaticrequests on a daily basis for various reasons suchas to avoid fraud and computational overhead.Though we can crawl the data and save it on disk,most of the current approaches employ data struc-tures that reside in main memory and thus do notscale well to huge corpora.Fig.
1 helps us understand the seriousness ofthe situation.
It plots the number of unique word-s/word pairs versus the total number of words in5 10 15 20 25510152025Log2 of # of wordsLog 2of# of uniqueItemsItems=word?pairsItems=wordsFigure 1: Token Type Curvea corpus of size 577 MB.
Note that the plot is inlog-log scale.
This 78 million word corpus gen-erates 63 thousand unique words and 118 millionunique word pairs.
As expected, the rapid increasein number of unique word pairs is much largerthan the increase in number of words.
Hence, itshows that it is computationally infeasible to com-pute counts of all word pairs with a giant corporausing conventional main memory of 8 GB.Storing only the 118 million unique word pairsin this corpus require 1.9 GB of disk space.
Thisspace can be saved by avoiding storing the wordpair itself.
As a trade-off we are willing to toleratea small amount of error in the frequency of eachword pair.
In this paper, we explore sketch tech-niques, especially the Count-Min Sketch, whichapproximates the frequency of a word pair in thecorpus without explicitly storing the word pairsthemselves.
It turns out that, in this technique,both updating (adding a new word pair or increas-ing the frequency of existing word pair) and query-ing (finding the frequency of a given word pair) arevery efficient and can be done in constant time1.Counts stored in the CM Sketch can be used tocompute various word-association measures like1depend only on one of the user chosen parameters17Pointwise Mutual Information (PMI), and Log-Likelihood ratio.
These association scores are use-ful for other NLP applications like word sensedisambiguation, speech and character recognition,and computing semantic orientation of a word.
Inour work, we use computing semantic orientationof a word using PMI as a canonical task to showthe effectiveness of CM Sketch for computing as-sociation scores.In our attempt to advocate the Count-Minsketch to store the frequency of keys (words orword pairs) for NLP applications, we perform bothintrinsic and extrinsic evaluations.
In our intrinsicevaluation, first we show that low-frequent itemsare more prone to errors.
Second, we show thatcomputing approximate PMI scores from thesecounts can give the same ranking as Exact PMI.However, we need counters linear in size of streamto achieve that.
We use these approximate PMIscores in our extrinsic evaluation of computing se-mantic orientation.
Here, we show that we do notneed counters linear in size of stream to performas good as Exact PMI.
In our experiments, by us-ing only 2 billion counters (8GB RAM) we get thesame accuracy as for exact PMI scores.
The num-ber of these counters is up to 30 times less than thestream size which is a big memory and space gainwithout any loss of accuracy.2 Background2.1 Large Scale NLP problemsUse of large data in the NLP community is notnew.
A corpus of roughly 1.6 Terawords was usedby Agirre et al (2009) to compute pairwise sim-ilarities of the words in the test sets using theMapReduce infrastructure on 2, 000 cores.
Pan-tel et al (2009) computed similarity between 500million terms in the MapReduce framework over a200 billion words in 50 hours using 200 quad-corenodes.
The inaccessibility of clusters for every onehas attracted the NLP community to use stream-ing, randomized, approximate and sampling algo-rithms to handle large amounts of data.A randomized data structure called Bloom fil-ter was used to construct space efficient languagemodels (Talbot and Osborne, 2007) for Statis-tical Machine Translation (SMT).
Recently, thestreaming algorithm paradigm has been used toprovide memory and space-efficient platform todeal with terabytes of data.
For example, We(Goyal et al, 2009) pose language modeling asa problem of finding frequent items in a streamof data and show its effectiveness in SMT.
Subse-quently, (Levenberg and Osborne, 2009) proposeda randomized language model to efficiently dealwith unbounded text streams.
In (Van Durme andLall, 2009b), authors extend Talbot Osborne Mor-ris Bloom (TOMB) (Van Durme and Lall, 2009a)Counter to find the highly ranked k PMI responsewords given a cue word.
The idea of TOMB issimilar to CM Sketch.
TOMB can also be used tostore word pairs and further compute PMI scores.However, we advocate CM Sketch as it is a verysimple algorithm with strong guarantees and goodproperties (see Section 3).2.2 Sketch TechniquesA sketch is a summary data structure that is usedto store streaming data in a memory efficient man-ner.
These techniques generally work on an inputstream, i.e.
they process the input in one direc-tion, say from left to right, without going back-wards.
The main advantage of these techniquesis that they require storage which is significantlysmaller than the input stream length.
For typicalalgorithms, the working storage is sublinear in N ,i.e.
of the order of logk N , where N is the inputsize and k is some constant which is not explicitlychosen by the algorithm but it is an artifact of it..Sketch based methods use hashing to map items inthe streaming data onto a small-space sketch vec-tor that can be easily updated and queried.
It turnsout that both updating and querying on this sketchvector requires only a constant time per operation.Streaming algorithms were first developed inthe early 80s, but gained in popularity in the late90s as researchers first realized the challenges ofdealing with massive data sets.
A good surveyof the model and core challenges can be found in(Muthukrishnan, 2005).
There has been consid-erable work on coming up with different sketchtechniques (Charikar et al, 2002; Cormode andMuthukrishnan, 2004; Li and Church, 2007).
Asurvey by (Rusu and Dobra, 2007; Cormode andHadjieleftheriou, 2008) comprehensively reviewsthe literature.3 Count-Min SketchThe Count-Min Sketch (Cormode and Muthukr-ishnan, 2004) is a compact summary data structureused to store the frequencies of all items in the in-put stream.
The sketch allows fundamental queries18on the data stream such as point, range and in-ner product queries to be approximately answeredvery quickly.
It can also be applied to solve thefinding frequent items problem (Manku and Mot-wani, 2002) in a data stream.
In this paper, we areonly interested in point queries.
The aim of a pointquery is to estimate the count of an item in the in-put stream.
For other details, the reader is referredto (Cormode and Muthukrishnan, 2004).Given an input stream of word pairs of length Nand user chosen parameters ?
and ?, the algorithmstores the frequencies of all the word pairs with thefollowing guarantees:?
All reported frequencies are within the truefrequencies by at most ?N with a probabilityof at least ?.?
The space used by the algorithm isO(1?
log 1?
).?
Constant time of O(log(1? ))
per each updateand query operation.3.1 CM Data StructureA Count-Min Sketch with parameters (?,?)
is rep-resented by a two-dimensional array with width wand depth d :??
?sketch[1,1] ?
?
?
sketch[1,w].........sketch[d,1] ?
?
?
sketch[d,w]??
?Among the user chosen parameters, ?
controls theamount of tolerable error in the returned count and?
controls the probability with which the returnedcount is not within the accepted error.
These val-ues of ?
and ?
determine the width and depth of thetwo-dimensional array respectively.
To achievethe guarantees mentioned in the previous section,we set w=2?
and d=log(1?
).
The depth d denotesthe number of pairwise-independent hash func-tions employed by the algorithm and there existsan one-to-one correspondence between the rowsand the set of hash functions.
Each of these hashfunctions hk:{1 .
.
.
N} ?
{1 .
.
.
w} (1 ?
k ?
d)takes an item from the input stream and maps itinto a counter indexed by the corresponding hashfunction.
For example, h2(w) = 10 indicates thatthe word pair w is mapped to the 10th position inthe second row of the sketch array.
These d hashfunctions are chosen uniformly at random from apairwise-independent family.Figure 2: Update Procedure for CM sketch and conserva-tive update (CU)Initially the entire sketch array is initializedwith zeros.Update Procedure: When a new item (w,c) ar-rives, where w is a word pair and c is its count2,one counter in each row, as decided by its corre-sponding hash function, is updated by c. Formally,?1 ?
k ?
dsketch[k,hk(w)]?
sketch[k,hk(w)] + cThis process is illustrated in Fig.
2 CM.
The item(w,2) arrives and gets mapped to three positions,corresponding to the three hash functions.
Theircounts before update were (4,2,1) and after updatethey become (6,4,3).
Note that, since we are usinga hash to map a word into an index, a collision canoccur and multiple word pairs may get mapped tothe same counter in any given row.
Because ofthis, the values stored by the d counters for a givenword pair tend to differ.Query Procedure: The querying involves find-ing the frequency of a given item in the inputstream.
Since multiple word pairs can get mappedinto same counter and the observation that thecounts of items are positive, the frequency storedby each counter is an overestimate of the truecount.
So in answering the point query, we con-sider all the positions indexed by the hash func-tions for the given word pair and return the mini-mum of all these values.
The answer to Query(w)is:c?
= mink sketch[k,hk(w)]Note that, instead of positive counts if we had neg-ative counts as well then the algorithm returns themedian of all the counts and the bounds we dis-cussed in Sec.
3 vary.
In Fig.
2 CM, for the wordpair w it takes the minimum over (6,4,3) and re-turns 3 as the count of word pair w.2In our setting, c is always 1.
However, in other NLPproblem, word pairs can be weighted according to recency.19Both update and query procedures involve eval-uating d hash functions and a linear scan of all thevalues in those indices and hence both these pro-cedures are linear in the number of hash functions.Hence both these steps require O(log(1? ))
time.
Inour experiments (see Section 4.2), we found that asmall number of hash functions are sufficient andwe use d=3.
Hence, the update and query oper-ations take only a constant time.
The space usedby the algorithm is the size of the array i.e.
wdcounters, where w is the width of each row.3.2 PropertiesApart from the advantages of being space efficient,and having constant update and constant queryingtime, the Count-Min sketch has also other advan-tages that makes it an attractive choice for NLPapplications.?
Linearity: given two sketches s1 and s2 com-puted (using the same parameters w and d)over different input streams, the sketch ofthe combined data stream can be easily ob-tained by adding the individual sketches inO(1?
log 1? )
time which is independent of thestream size.?
The linearity is especially attractive because,it allows the individual sketches to be com-puted independent of each other.
Whichmeans that it is easy to implement it in dis-tributed setting, where each machine com-putes the sketch over a sub set of corpus.?
This technique also extends to allow the dele-tion of items.
In this case, to answer a pointquery, we should return the median of all thevalues instead of the minimum value.3.3 Conservative UpdateEstan and Varghese introduce the idea of conser-vative update (Estan and Varghese, 2002) in thecontext of networking.
This can easily be usedwith CM Sketch to further improve the estimateof a point query.
To update an item, word pair, wwith frequency c, we first compute the frequencyc?
of this item from the existing data structure andthe counts are updated according to: ?1 ?
k ?
dsketch[k,hk(w)]?
max{sketch[k,hk(w)], c?
+ c}The intuition is that, since the point query returnsthe minimum of all the d values, we will updatea counter only if it is necessary as indicated bythe above equation.
Though this is a heuristic, itavoids the unnecessary updates of counter valuesand thus reduces the error.The process is also illustrated in Fig.
2CU.When an item ?w?
with a frequency of 2 arrivesin the stream, it gets mapped into three positionsin the sketch data structure.
Their counts beforeupdate were (4,2,1) and the frequency of the itemis 1 (the minimum of all the three values).
In thisparticular case, the update rule says that increasethe counter value only if its updated value is lessthan c?
+ 2 = 3.
As a result, the values in thesecounters after the update become (4,3,3).However, if the value in any of the countersis already greater than 3 e.g.
4, we cannot at-tempt to correct it by decreasing, as it could con-tain the count for other items hashed at that posi-tion.
Therefore, in this case, for the first counterwe leave the value 4 unchanged.
The query pro-cedure remains the same as in the previous case.In our experiments, we found that employing theconservative update reduces the Average RelativeError (ARE) of these counts approximately by afactor of 2.
(see Section 4.2).
But unfortunately,this update prevents deletions and items with neg-ative updates cannot be processed3.4 Intrinsic EvaluationsTo show the effectiveness of the Count-Min sketchin the context of NLP, we perform intrinsic evalu-ations.
The intrinsic evaluations are designed tomeasure the error in the approximate counts re-turned by CMS compared to their true counts.
Bykeeping the total size of the data structure fixed,we study the error by varying the width and thedepth of the data structure to find the best settingof the parameters for textual data sets.
We showthat using conservative update (CU) further im-proves the quality of counts over CM sketch.4.1 Corpus StatisticsGigaword corpus (Graff, 2003) and a copy of webcrawled by (Ravichandran et al, 2005) are usedto compute counts of words and word pairs.
Forboth the corpora, we split the text into sentences,tokenize and convert into lower-case.
We generatewords and word pairs (items) over a sliding win-dow of size 14.
Unlike previous work (Van Durme3Here, we are only interested in the insertion case.20Corpus Sub Giga 50% 100%set word Web WebSize.15 6.2 15 31GB# of sentences 2.03 60.30 342.68 686.63(Million)# of words 19.25 858.92 2122.47 4325.03(Million)Stream Size 0.25 19.25 18.63 39.0510 (Billion)Stream Size 0.23 25.94 18.79 40.0014 (Billion)Table 1: Corpus Descriptionand Lall, 2009b) which assumes exact frequen-cies for words, we store frequencies of both thewords and word pairs in the CM sketch4.
Hence,the stream size in our case is the total number ofwords and word pairs in a corpus.
Table 1 givesthe characteristics of the corpora.Since, it is not possible to compute exact fre-quencies of all word pairs using conventional mainmemory of 8 GB from a large corpus, we use asubset of 2 million sentences (Subset) from Giga-word corpus for our intrinsic evaluation.
We storethe counts of all words and word pairs (occurringin a sliding window of length 14) from Subset us-ing the sketch and also the exact counts.4.2 Comparing CM and CU counts andtradeoff between width and depthTo evaluate the amount of over-estimation in CMand CU counts compared to the true counts, wefirst group all items (words and word pairs) withsame true frequency into a single bucket.
We thencompute the average relative error in each of thesebuckets.
Since low-frequent items are more proneto errors, making this distinction based on fre-quency lets us understand the regions in which thealgorithm is over-estimating.
Average Relative er-ror (ARE) is defined as the average of absolute dif-ference between the predicted and the exact valuedivided by the exact value over all the items ineach bucket.ARE = 1NN?i=1|Exacti ?
Predictedi|ExactiWhere Exact and Predicted denotes values of exactand CM/CU counts respectively; N denotes thenumber of items with same counts in a bucket.In Fig.
3(a), we fixed the number of countersto 50 million with four bytes of memory per each4Though a minor point, it allows to process more text.counter (thus it only requires 200 MB of mainmemory).
Keeping the total number of countersfixed, we try different values of depth (2, 3, 5 and7) of the sketch array and in each case the widthis set to 50Md .
The ARE curves in each case areshown in Fig.
3(a).
There are three main observa-tions: First it shows that most of the errors occuron low frequency items.
For frequent items, in al-most all the different runs the ARE is close to zero.Secondly, it shows that ARE is significantly lower(by a factor of two) for the runs which use conser-vative update (CUx run) compared to the runs thatuse direct CM sketch (CMx run).
The encouragingobservation is that, this holds true for almost alldifferent (width,depth) settings.
Thirdly, in our ex-periments, it shows that using depth of 3 gets com-paratively less ARE compared to other settings.To be more certain about this behavior with re-spect to different settings of width and depth, wetried another setting by increasing the number ofcounters to 100 million.
The curves in 3(b) followa pattern which is similar to the previous setting.Low frequency items are more prone to error com-pared to the frequent ones and employing conser-vative update reduces the ARE by a factor of two.In this setting, depth 3 and 5 do almost the sameand get lowest ARE.
In both the experiments, set-ting the depth to three did well and thus in the restof the paper we fix this parameter to three.Fig.
4 studies the effect of the number of coun-ters in the sketch (the size of the two-dimensionalsketch array) on the ARE.
Using more number ofcounters decreases the ARE in the counts.
This isintuitive because, as the length of each row in thesketch increases, the probability of collision de-creases and hence the array is more likely to con-tain true counts.
By using 200 million counters,which is comparable to the length of the stream230 million (Table.
1), we are able to achieve al-most zero ARE over all the counts including therare ones5.
Note that the actual space requiredto represent the exact counts is almost two timesmore than the memory that we use here becausethere are 230 million word pairs and on an aver-age each word is eight characters long and requireseight bytes (double the size of an integer).
Thesummary of this Figure is that, if we want to pre-serve the counts of low-frequent items accurately,then we need counters linear in size of stream.5Even with other datasets we found that using counterslinear in the size of the stream leads to ARE close to zero ?counts.210 2 4 6 8 10 1200.511.522.533.54Log2 of true frequency counts of words/word?pairsAverageRelativeErrorCM7CM5CM3CM2CU7CU5CU3CU2(a) 50M counters0 2 4 6 8 10 1200.10.20.30.40.50.60.70.8Log2 of true frequency counts of words/word?pairsAverageRelativeErrorCM7CM5CM3CM2CU7CU5CU3CU2(b) 100M countersFigure 3: Comparing 50 and 100 million counter models with different (width,depth) settings.
The notation CMx representsthe Count-Min Sketch with a depth of ?x?
and CUx represents the CM sketch along with conservative update and depth ?x?.0 2 4 6 8 10 120123456Log2 of true frequency counts of words/word?pairsAverageRelativeError20M50M100M200MFigure 4: Comparing different size models with depth 34.3 Evaluating the CU PMI rankingIn this experiment, we compare the word pairs as-sociation rankings obtained using PMI with CUand exact counts.
We use two kinds of measures,namely accuracy and Spearman?s correlation, tomeasure the overlap in the rankings obtained byboth these approaches.4.3.1 PointWise Mutual InformationThe Pointwise Mutual Information (PMI) (Churchand Hanks, 1989) between two words w1 and w2is defined as:PMI(w1, w2) = log2P (w1, w2)P (w1)P (w2)Here, P (w1, w2) is the likelihood that w1 and w2occur together, and P (w1) and P (w2) are their in-dependent likelihoods respectively.
The ratio be-tween these probabilities measures the degree ofstatistical dependence between w1 and w2.4.3.2 Description of the metricsAccuracy is defined as fraction of word pairs thatare found in both rankings to the size of top rankedword pairs.Accuracy = |CP-WPs ?
EP-WPs||EP-WPs|Where CP-WPs represent the set of top ranked Kword pairs under the counts stored using the CUsketch and EP-WPs represent the set of top rankedword pairs with the exact counts.Spearman?s rank correlation coefficient (?
)computes the correlation between the ranks ofeach observation (i.e.
word pairs) on two variables(that are top N CU-PMI and exact-PMI values).This measure captures how different the CU-PMIranking is from the Exact-PMI ranking.?
= 1?
6?
d2iF (F 2 ?
1)Where di is the difference between the ranks ofa word pair in both rankings and F is the numberof items found in both sets.Intuitively, accuracy captures the number ofword pairs that are found in both the sets and thenSpearman?s correlation captures if the relative or-der of these common items is preserved in both therankings.
In our experimental setup, both thesemeasures are complimentary to each other andmeasure different aspects.
If the rankings matchexactly, then we get an accuracy of 100% and acorrelation of 1.4.3.3 Comparing CU PMI rankingThe results with respect to different sized counter(50, 100 and 200 million) models are shown in Ta-ble 2.
Table 2 shows that having counters linear22Counters 50M 100M 200MTop K Acc ?
Acc ?
Acc ?50 .20 -0.13 .68 .95 .92 1.00100 .18 .31 .77 .80 .96 .95200 .21 .68 .73 .86 .97 .99500 .24 .31 .71 .97 .95 .991000 .33 .17 .74 .87 .95 .985000 .49 .38 .82 .82 .96 .97Table 2: Evaluating the PMI rankings obtained using CMSketch with conservative update (CU) and Exact countsin size of stream (230M ) results in better rank-ing (i.e.
close to the exact ranking).
For example,with 200M counters, among the top 50 word pairsproduced using the CU counts, we found 46 pairsin the set returned by using exact counts.
The ?score on those word pairs is 1 means that the rank-ing of these 46 items is exactly the same on bothCU and exact counts.
We see the same phenom-ena for 200M counters with other Top K values.While both accuracy and the ranking are decentwith 100M counters, if we reduce the number ofcounters to say 50M , the performance degrades.Since, we are not throwing away any infrequentitems, PMI will rank pairs with low frequencycounts higher (Church and Hanks, 1989).
Hence,we are evaluating the PMI values for rare wordpairs and we need counters linear in size of streamto get alost perfect ranking.
Also, using coun-ters equal to half the length of the stream is decent.However, in some NLP problems, we are not inter-ested in low-frequency items.
In such cases, evenusing space less than linear in number of coun-ters would suffice.
In our extrinsic evaluations, weshow that using space less than the length of thestream does not degrades the performance.5 Extrinsic Evaluations5.1 Experimental SetupTo evaluate the effectiveness of CU-PMI wordassociation scores, we infer semantic orientation(S0) of a word from CU-PMI and Exact-PMIscores.
Given a word, the task of finding the SO(Turney and Littman, 2002) of the word is to iden-tify if the word is more likely to be used in positiveor negative sense.
We use a similar framework asused by the authors6 to infer the SO.
We take theseven positive words (good, nice, excellent, posi-tive, fortunate, correct, and superior) and the nega-tive words (bad, nasty, poor, negative, unfortunate,6We compute this score slightly differently.
However, ourmain focus is to show that CU-PMI scores are useful.wrong, and inferior) used in (Turney and Littman,2002) work.
The SO of a given word is calculatedbased on the strength of its association with theseven positive words, and the strength of its asso-ciation with the seven negative words.
We com-pute the SO of a word ?w?
as follows:SO-PMI(W) = PMI(+, w)?
PMI(?, w)PMI(+,W) =?p?Pwordslog hits(p, w)hits(p) ?
hits(w)PMI(-,W) =?n?Nwordslog hits(n,w)hits(n) ?
hits(w)Where, Pwords and Nwords denote the seven pos-itive and negative prototype words respectively.We compute SO score from different sized cor-pora (Section 4.1).
We use the General Inquirerlexicon7 (Stone et al, 1966) as a benchmark toevaluate the semantic orientation scores similar to(Turney and Littman, 2002) work.
Words withmultiple senses have multiple entries in the lexi-con, we merge these entries for our experiment.Our test set consists of 1619 positive and 1989negative words.
Accuracy is used as an evaluationmetric and is defined as the fraction of number ofcorrectly identified SO words.Accuracy = Correctly Identified SO Words ?
100Total SO words5.2 ResultsWe evaluate SO of words on three different sizedcorpora: Gigaword (GW) 6.2GB, GigaWord +50% of web data (GW+WB1) 21.2GB and Gi-gaWord + 100% of web data (GW+WB2) 31GB.Note that computing the exact counts of all wordpairs on these corpora is not possible using mainmemory, so we consider only those pairs in whichone word appears in the prototype list and theother word appears in the test set.We compute the exact PMI (denoted using Ex-act) scores for pairs of test-set words w1 and proto-type words w2 using the above data-sets.
To com-pute PMI, we count the number of hits of individ-ual words w1 and w2 and the pair (w1,w2) within asliding window of sizes 10 and 14 over these data-sets.
After computing the PMI scores, we computeSO score for a word using SO-PMI equation fromSection 5.1.
If this score is positive, we predictthe word as positive.
Otherwise, we predict it as7The General Inquirer lexicon is freely available athttp://www.wjh.harvard.edu/ inquirer/23Model Accuracy window 10 Accuracy window 14#of counters Mem.
Usage GW GW+WB1 GW+WB2 GW GW+WB1 GW+WB2Exact n/a 64.77 75.67 77.11 64.86 74.25 75.30500M 2GB 62.98 71.09 72.31 63.21 69.21 70.351B 4GB 62.95 73.93 75.03 63.95 72.42 72.732B 8GB 64.69 75.86 76.96 65.28 73.94 74.96Table 3: Evaluating Semantic Orientation of words with different # of counters of CU sketch with increasing amount of dataon window size of 10 and 14.
Scores are evaluated using Accuracy metric.negative.
The results on inferring correct SO fora word w with exact PMI (Exact) are summarizedin Table 3.
It (the second row) shows that increas-ing the amount of data improves the accuracy ofidentifying the SO of a word with both the win-dow sizes.
The gain is more prominent when weadd 50% of web data in addition to Gigaword aswe get an increase of more than 10% in accuracy.However, when we add the remaining 50% of webdata, we only see an slight increase of 1% in accu-racy8.
Using words within a window of 10 givesbetter accuracy than window of 14.Now, we use our CU Sketches of 500 million(500M ), 1 billion (1B) and 2 billion (2B) coun-ters to compute CU-PMI.
These sketches containthe number of hits of all words/word pairs (not justthe pairs of test-set and prototype words) within awindow size of 10 and 14 over the whole data-set.
The results in Table 3 show that even withCU-PMI scores, the accuracy improves by addingmore data.
Again we see a significant increase inaccuracy by adding 50% of web data to Gigawordover both window sizes.
The increase in accuracyby adding the rest of the web data is only 1%.By using 500M counters, accuracy with CU-PMI are around 4% worse than the Exact.
How-ever, increasing the size to 1B results in only 2% worse accuracy compared to the Exact.
Go-ing to 2B counters (8 GB of RAM), results in ac-curacy almost identical to the Exact.
These re-sults hold almost the same for all the data-setsand for both the window sizes.
The increase inaccuracy comes at expense of more memory Us-age.
However, 8GB main memory is not large asmost of the conventional desktop machines havethis much RAM.
The number of 2B counters isless than the length of stream for all the data-sets.For GW, GW+WB1 and GW+WB2, 2B countersare 10, 20 and 30 times smaller than the streamsize.
This shows that using counters less than thestream length does not degrade the performance.8These results are similar to the results reported in (Tur-ney and Littman, 2002) work.The advantage of using Sketch is that it con-tains counts for all words and word pairs.
Supposewe are given a new word to label it as positive ornegative.
We can find its exact PMI in two ways:First, we can go over the whole corpus and com-pute counts of this word with positive and nega-tive prototype words.
This procedure will returnPMI in time needed to traverse the whole corpus.If the corpus is huge, this could be too slow.
Sec-ond option is to consider storing counts of all wordpairs but this is not feasible as their number in-creases rapidly with increase in data (see Fig.
1).Therefore, using a CM sketch is a very good al-ternative which returns the PMI in constant timeby using only 8GB of memory.
Additionally, thisSketch can easily be used for other NLP applica-tions where we need word-association scores.6 ConclusionWe have explored the idea of the CM Sketch,which approximates the frequency of a word pairin the corpus without explicitly storing the wordpairs themselves.
We used the idea of a conserva-tive update with the CM Sketch to reduce the av-erage relative error of its approximate counts bya factor of 2.
It is an efficient, small-footprintmethod that scales to at least 37 GB of web datain just 2 billion counters (8 GB main memory).
Inour extrinsic evaluations, we found that CU Sketchis as effective as exact PMI scores.Word-association scores from CU Sketch can beused for other NLP tasks like word sense disam-biguation, speech and character recognition.
Thecounts stored in CU Sketch can be used to con-struct small-space randomized language models.In general, this sketch can be used for any applica-tion where we want to query a count of an item.AcknowledgmentsWe thank the anonymous reviewers for helpfulcomments.
This work is partially funded by NSFgrant IIS-0712764 and Google Research GrantGrant for Large-Data NLP.24ReferencesEneko Agirre, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pas?ca, and Aitor Soroa.
2009.A study on similarity and relatedness using distri-butional and wordnet-based approaches.
In NAACL?09: Proceedings of Human Language Technolo-gies: The 2009 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics.Thorsten Brants, Ashok C. Popat, Peng Xu, Franz J.Och, and Jeffrey Dean.
2007.
Large languagemodels in machine translation.
In Proceedings ofthe 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL).Moses Charikar, Kevin Chen, and Martin Farach-colton.
2002.
Finding frequent items in datastreams.K.
Church and P. Hanks.
1989.
Word AssociationNorms, Mutual Information and Lexicography.
InProceedings of the 27th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 76?83,Vancouver, Canada, June.Graham Cormode and Marios Hadjieleftheriou.
2008.Finding frequent items in data streams.
In VLDB.Graham Cormode and S. Muthukrishnan.
2004.
Animproved data stream summary: The count-minsketch and its applications.
J. Algorithms.Cristian Estan and George Varghese.
2002.
New direc-tions in traffic measurement and accounting.
SIG-COMM Comput.
Commun.
Rev., 32(4).Amit Goyal, Hal Daume?
III, and Suresh Venkatasub-ramanian.
2009.
Streaming for large scale NLP:Language modeling.
In North American Chap-ter of the Association for Computational Linguistics(NAACL).D.
Graff.
2003.
English Gigaword.
Linguistic DataConsortium, Philadelphia, PA, January.Abby Levenberg and Miles Osborne.
2009.
Stream-based randomised language models for SMT.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing, pages756?764, Singapore, August.
Association for Com-putational Linguistics.Ping Li and Kenneth W. Church.
2007.
A sketch algo-rithm for estimating two-way and multi-way associ-ations.
Comput.
Linguist., 33(3).G.
S. Manku and R. Motwani.
2002.
Approximatefrequency counts over data streams.
In Proceedingsof the 28th International Conference on Very LargeData Bases.S.
Muthukrishnan.
2005.
Data streams: Algorithmsand applications.
Foundations and Trends in Theo-retical Computer Science, 1(2).Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-Maria Popescu, and Vishnu Vyas.
2009.
Web-scale distributional similarity and entity set expan-sion.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Process-ing, pages 938?947, Singapore, August.
Associationfor Computational Linguistics.S.
Patwardhan and E. Riloff.
2006.
Learning Domain-Specific Information Extraction Patterns from theWeb.
In Proceedings of the ACL 2006 Workshop onInformation Extraction Beyond the Document.Deepak Ravichandran, Patrick Pantel, and EduardHovy.
2005.
Randomized algorithms and nlp: usinglocality sensitive hash function for high speed nounclustering.
In ACL ?05: Proceedings of the 43rd An-nual Meeting on Association for Computational Lin-guistics.Florin Rusu and Alin Dobra.
2007.
Statistical analysisof sketch estimators.
In SIGMOD ?07.
ACM.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,and Daniel M. Ogilvie.
1966.
The General In-quirer: A Computer Approach to Content Analysis.MIT Press.David Talbot and Miles Osborne.
2007.
SmoothedBloom filter language models: Tera-scale LMs onthe cheap.
In Proceedings of the 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning (EM NLP-CoNLL).Peter D. Turney and Michael L. Littman.
2002.Unsupervised learning of semantic orientationfrom a hundred-billion-word corpus.
CoRR,cs.LG/0212012.Peter D. Turney.
2008.
A uniform approach to analo-gies, synonyms, antonyms, and associations.
In Pro-ceedings of COLING 2008.Benjamin Van Durme and Ashwin Lall.
2009a.
Prob-abilistic counting with randomized storage.
In IJ-CAI?09: Proceedings of the 21st international jontconference on Artifical intelligence, pages 1574?1579.Benjamin Van Durme and Ashwin Lall.
2009b.Streaming pointwise mutual information.
In Ad-vances in Neural Information Processing Systems22.25
