Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 31?36,Beijing, China, July 26-31, 2015.c?2015 ACL and AFNLPNEED4Tweet: A Twitterbot for Tweets Named Entity Extraction andDisambiguationMena B. HabibDatabase ChairUniversity of TwenteEnschede, The Netherlandsm.b.habib@ewi.utwente.nlMaurice van KeulenDatabase ChairUniversity of TwenteEnschede, The Netherlandsm.vankeulen@utwente.nlAbstractIn this demo paper, we presentNEED4Tweet, a Twitterbot for named en-tity extraction (NEE) and disambiguation(NED) for Tweets.
The straightforwardapplication of state-of-the-art extractionand disambiguation approaches on infor-mal text widely used in Tweets, typicallyresults in significantly degraded perfor-mance due to the lack of formal structure;the lack of sufficient context required;and the seldom entities involved.
In thispaper, we introduce a novel frameworkthat copes with the introduced challenges.We rely on contextual and semanticfeatures more than syntactic featureswhich are less informative.
We believethat disambiguation can help to improvethe extraction process.
This mimics theway humans understand language.1 IntroductionTwitter is an important source for continuouslyand instantly updated information.
It contains alarge amount of unstructured information aboutusers, locations, events, etc.
Shortness and infor-mality of Tweets are challenges for Natural Lan-guage Processing (NLP) tasks.
Information Ex-traction (IE) is the NLP field of research that isconcerned with obtaining structured informationfrom unstructured text.
IE systems attempt to in-terpret human language text in order to extract in-formation about different types of events, entities,or relationships.
Named entity extraction (NEE) isa subtask of IE that aims to locate phrases (men-tions) in the text that represent names of persons,organizations, or locations regardless of their type.Named entity disambiguation (NED) is the task ofdetermining which concrete person, place, event,etc.
is referred to by a mention.
Wikipedia articlesare widely used as an entity?s reference.Challenges: NEE and NED in informal text arechallenging.
Here we summarize the challenges ofNEE and NED for Tweets:?
The informal language widely used in Tweetsmakes the extraction process more difficult.Proper capitalization is a key feature that thestate-of-the-art NEE approaches have reliedon.
However, this feature gets less atten-tion from Twitter users when they write theirTweets.?
The limited length (140 characters) of Tweetsforces the senders to provide dense informa-tion by using acronyms and informal lan-guage.
This makes both the extraction andthe disambiguation processes more complex.?
The limited coverage of a Knowledge Base(KB) is another challenge facing NED fortweets.
According to (Lin et al., 2012), 5 mil-lion out of 15 million mentions on the Webcannot be linked to Wikipedia.
This meansthat relying only on a KB for NED leads toaround 33% loss in the disambiguated enti-ties.
This percentage is higher on Twitter be-cause of its social nature where users also dis-cuss information about seldom entities.?
The processes of NEE and NED involvedegrees of uncertainty.
For example, inthe tweet ?history should show that bush jrshould be in jail or at least never shouldhave been president?, for some NEE systems,it may be uncertain whether the word ?jr?should be part of the mention bush or not.This motivates us to fundamentally considersets of possible alternatives in an early stageof the extraction and the disambiguation pro-cesses and do a later filtration instead of mak-ing hard decisions from the beginning.?
Named entity (NE) representation in KBsposes another NED challenge.
The YAGO31KB (Suchanek et al., 2007) uses theWikipedia anchor text as a possible mentionrepresentation for named entities.
However,there may be more representations that donot appear in the Wikipedia anchor text, butare meant to refer to the entity because of aspelling mistake or because of a new abbre-viation for the entity.In this demo, we introduce NEED4Tweet, aTwitterbot for a combined system for NEE andNED in Tweets that uses their interdependencyand mimics how humans exploit it in languageunderstanding.
The system is based on our work(Habib and van Keulen, 2015).
We use a genericopen world approach for NED in Tweets for anynamed entity even though it has no Wikipedia ar-ticle.
Mentions are disambiguated by assigningthem to either a Wikipedia article or a home page.We handle the uncertainty involved in the extrac-tion process by considering possible alternativesin an early stage then evaluate these alternativeslater based on disambiguation outcomes.
The pro-posed approach is shown to be robust against thecoverage of KBs and the informality of the usedlanguage.2 Related work2.1 Named Entity DisambiguationNED in Web documents is a topic that is wellcovered in literature.
Recently, researchers haveattempted NED for informal short text such asTweets.
Most of this research investigate the prob-lem of entity-oriented disambiguation.
Within thistheme, (Spina et al., 2011), (Christoforaki et al.,2011), (Yerva et al., 2012) and (Delgado et al.,2012) focus on the task of filtering Tweets con-taining a given a mention of topic-centric entity,depending whether the Tweet is actually related tothe entity or not.
They develop a set of features(co-occurrence, Web-based features, collection-based features) to find keywords for positive andnegative cases.Similar to our problem discussed in Section 3.2,is the problem of entity home page finding, whichwas part of the TREC Web and entity tracks.One of the proposed approaches for this task was(Westerveld et al., 2002).
The authors combinecontent information with other sources as diverseas inlinks, URLs and anchors to find an entry page.Although the TREC problem looks similar to ours,the Tweets?
short informal nature makes it moretricky to find an entity reference page.2.2 Named Entity ExtractionMany tools and services have been developed forthe NEE task in web documents written in for-mal language.
In spite of this, few research effortsstudied NEE in Tweets.
In (Ritter et al., ), the au-thors built an NLP pipeline to perform NEE.
Thepipeline involves part-of-speech tagging, shallowparsing, and a novel SVM classifier that predictsthe informativeness of capitalization in a Tweet.
Ittrains a Conditional Random Fields (CRF) modelwith all the aforementioned features for NEE.
Forclassification, LabeledLDA is applied where entitytypes are used as classes.
A bag-of-words-basedprofile is generated for each entity type, and thesame is done with each extracted mention.
Clas-sification is done based on the comparison of thetwo.The contextual relationship between the micro-posts is considered by (Jung, 2012).
The pa-per proposes merging the microtexts by discov-ering contextual relationship between the micro-texts.
A group of microtexts contextually linkedwith each other is regarded as a microtext clus-ter.
Once this microtext cluster is obtained, theyexpect that the performance of NEE can be better.The authors provide some suggestions for Contex-tual closure, Microtext cluster, Semantic closure,Temporal closure, and Social closure.
Those clo-sures are used by Maximum Entropy for the NERtask.Similarly, (Li et al., 2012) exploits the gregari-ous property in the local context derived from theTwitter stream in an unsupervised manner.
Thesystem first leverages the global context obtainedfrom Wikipedia and Web N-Gram corpus to par-tition Tweets into valid segments (phrases) usinga dynamic programming algorithm.
Each suchTweet segment is a candidate NE.
Afterwards, aranking approach tries to rank segments accordingto their probability of being an NE.
The highly-ranked segments have a higher chance of beingtrue NEs.
Each segment is represented as a nodein a graph, and using the Wikipedia and the con-text of Tweet (adjacent nodes (segments)), a scoreis assigned to that segment if it is an NE or not.32ExtractionPhase1: NE CandidatesGenerationExtractionPhase2: NE CandidatesFilteringDisambiguationOur Approach For NEE & NEDExtraction DisambiguationTraditional Approaches For NEE & NEDFigure 1: Traditional approaches versus our approach for NEE and NED.3 NEED4TweetAlthough the logical order for a traditional IEsystem is to complete the extraction process be-fore commencing with the disambiguation pro-cess, we start with an initial extraction-like phaseaiming for high recall (i.e.
aiming to find as manyreasonable mention candidates as possible).
Wethen attempt disambiguation for all the extractedmentions.
Finally we classify extracted mentioncandidates into true and false NE using features(clues) derived from the results of the disambigua-tion phase such as KB information and entity co-herency.
Figure 1 illustrates our general approachcontrasted with the traditional process.The potential of this order is that the disam-biguation step gives extra clues (such as Entity-Tweet context similarity) about each NE candi-date.
This information can help in the decisionwhether the candidate is a true NE or not.3.1 Mention Candidates GenerationThis phase is aiming to find as many reasonablemention candidates as possible.
For this task, weunionize the output of the following mention can-didates generation methods:?
Tweet Segmentation: Tweet text is seg-mented using the segmentation algorithm de-scribed in (Li et al., 2012).
Each segment isconsidered a mention candidate.?
KBLookup: We scan all possible n-grams ofthe Tweet against the mentions-entities tableof YAGO KB.
N-grams that matches a YAGOmention are considered mention candidates.3.2 DisambiguationFor NED, we use a generic open world NEDapproach where mentions are disambiguated byassigning them to either a Wikipedia article(Wikipedia entity) or a home page (non-Wikipediaentity) (Habib and van Keulen, 2013).
The NEDapproach is composed of three modules; matcher,feature extractor, and SVM ranker.?
Matcher: This module is responsible forfinding the possible candidate entities of agiven mention.
For this task, we use themention-entity table of YAGO KB to get thepossible entities for the given mention.
Fur-thermore, we use the mention as an inputquery for the Google API.
The top 18 Webpages retrieved by Google are also consid-ered candidate entities for that mention.?
Feature Extractor: For each entity pagecandidate, we extract a set of context andURL features.
Context features (such aslanguage model and overlapping terms be-tween tweet and document) measure thecontext similarity between mention context(the tweet text) and entity candidates?
homepages.
URL features (such as path length andmention-URL string similarity) measure thelikelihood of the candidate URL being a rep-resentative of the entity home page.
Thesefeatures give indicators on how likely thecandidate entity page could be a representa-tive to the mention.?
SVM Ranker: After extracting the afore-mentioned set of features, SVM classifier isused to rank candidate entity pages of a men-tion.
We consider the top ranked page to be33the entity of the input mention.
In this demo,we use an SVM which is trained on the twoNED datasets presented in (Habib and vanKeulen, 2013).3.3 Mention Candidates FilteringAfter generating the mentions candidate list, weapply our disambiguate approach to disambiguateeach mention candidate.
After that, we use anotherSVM classifier to predict which mention candi-dates are true positives and which ones are not.
Foreach mention candidate, we extract the followingset of features :?
Shape Features: If the mention candidate isinitially or fully capitalized and if it containsdigits.?
Probabilistic Features:?
The joint and conditional probability ofthe mention candidate obtained from theMicrosoft Web N-Gram service.?
The stickiness of the segment as de-scribed in (Li et al., 2012).?
The segment frequency over around5 million tweets1.?
KB Features:?
Whether the segment appears in Word-Net.?
Whether the segment appears in theYAGO mention-entity look-up table.?
Disambiguation Features: All the featuresdescribed in Section 3.2 derived from the en-tity page linked to the given mention candi-date.In this demo, we use an SVM which is trainedon four different NEE datasets presented in (Ritteret al., ), (Basave et al., 2013), (Locke and Martin,2009), and (Habib and van Keulen, 2012).3.4 Final NE Set GenerationBeside the SVM, we also use a trained CRF modelfor NEE.
We use the CRF model described in (Zhuet al., 2014) trained on the four collections men-tioned in Section 3.3.
To train the CRF, Tweet textis tokenized using a special tweet tokenizer (Gim-pel et al., 2011) and the following features are ex-tracted and used for training:1http://wis.ewi.tudelft.nl/umap2011/ +TREC 2011 Microblog track collection.
(a) Example 1: Tweet for testing both NEE and NED.
(b) Example 2: Tweet for testing NED only.
(c) Tweet reply.
(d) Results of example 1(e) Results of example 2Figure 2: NEED4Tweet Twitterbot?
The Part of Speech (POS) tag of the tokenprovided by a special POS tagger designedfor tweets (Gimpel et al., 2011).?
Whether the token?s initial is capitalized.?
Whether the token?s characters are all capi-talized.?
Whether the token has any capital letters.We consider the best annotation set for the tweetgiven by the CRF model as true positives.
To gen-erate the final NE set, we take the union of theCRF annotation set (after being disambiguated)and the SVM results, after removing duplicate andoverlapped extractions.
To resolve the overlappedmentions, we select the mention that appears inYago KB.
If both mentions appear in Yago or bothdon?t, we select the one with the longer length.The idea behind this combination is that theSVM and the CRF work in a different way.
The34former is a distance based classifier that uses nu-meric features for classification which CRF cannot handle, while the latter is a probabilistic modelthat can naturally consider state-to-state depen-dencies and feature-to-state dependencies.
On theother hand, SVM does not consider such depen-dencies.
The hybrid approach of both makes useof the strength of each.
While the CRF makesbetter use of the traditional features like POS andCapitalization, the SVM makes better use of thedisambiguation (coherency) features.4 TwitterbotA Twitterbot is a program used to produce au-tomated posts on the Twitter microblogging ser-vice.
We developed our system as a Twitter-bot which receives the Tweet, processes it andsends a reply message contains a link to a pagethat shows the generated annotations.
We useTwitter API2for both receiving the Tweets andsending the replies.
To use NEED4Tweet Twit-terbot, one should send a Tweet contains eitherthe mention ?
@UT NEED4Tweet?
or the hashtag?#NEED4Tweet?
as shown in Figures 2(a) and 2(b)respectively.
Withing few seconds after sendingthe tweet, the sender will get a reply Tweet (seeFigure 2(c)) that includes link to a simple HTMLpage contains the generated annotations (see Fig-ures 2(d) and 2(e)).
The page contains a list ofthe extracted mentions, their start offset in theTweet, and their linked entities.
It is also possi-ble to test only the disambiguation component bymanually coating the mentions required to be dis-ambiguated using double square brackets ([[]])asshown in Figure 2(b).5 Evaluation5.1 Data setsTo validate our approach, we use three collectionsof tweets.
The first two data sets are mainly de-signed for a NER task.
We manually construct theNED ground truth by linking each NE to only oneappropriate entity page.
We give higher priority toWikipedia pages.
When no Wikipedia page existsfor a mention, we link it to a non-Wikipedia homepage or profile page.The first data set (Locke collection) is the oneused in (Locke and Martin, 2009).
The seconddata set (Habib collection) is the one used in2https://dev.twitter.com/(a) Locke collectionPre.
Rec.
F1DBpedia Spotlight 0.1004 0.2669 0.1459Stanford + AIDA 0.5005 0.2940 0.3704NEED4Tweet 0.5455 0.5640 0.5546(b) Habib collectionPre.
Rec.
F1DBpedia Spotlight 0.3711 0.5333 0.4377Stanford + AIDA 0.7263 0.5569 0.6304NEED4Tweet 0.6861 0.7157 0.7006(c) #Microposts collectionPre.
Rec.
F1DBpedia Spotlight 0.1873 0.3349 0.2403Stanford + AIDA 0.5092 0.2795 0.3609NEED4Tweet 0.5337 0.5343 0.5339Table 1: Combined evaluation of NEE and NED.
(Habib and van Keulen, 2012) which is relativelysmall in the number of tweets but rich in the num-ber of NEs.
It is composed mainly from tweetednews about sportsmen, celebrities, politics, etc.The third data set (#Microposts collection)is provided by the #Microposts Named EntityExtraction & Linking (NEEL) Challenge (CanoBasave et al., 2014).
The NEEL Challenge taskrequired participants to build systems to extractentity mentions from a tweet and to link the ex-tracted mentions to DBpedia.
Note that this dataset does not contain any non-Wikipedia entities.We have done the mapping from the YAGO KB toDBpedia by identifying the Wikipedia page as acommon property for the identical entities.5.2 Experimental ResultsIn this experiment, we compare the performanceof NEED4Tweet against two competitors: AIDA3and DBpedia Spotlight.4AIDA is a disambigua-tion system although it uses Stanford NER forautomatic NE extraction.
We consider the com-bination of Stanford NER and the AIDA disam-biguation system as one competitor to our extrac-tion and disambiguation system.
DBpedia Spot-light (Mendes et al., 2011) is a tool for automat-ically annotating mentions of DBpedia resourcesin text.
We used DBpedia Spotlight through itsAnnotate Web Service endpoint.
We used the3https://d5gate.ag5.mpi-sb.mpg.de/webaida/4https://github.com/dbpedia-spotlight/dbpedia-spotlight/wiki35NESpotter implementation for the extraction con-figuration.
The results in Table 1 show the superi-ority of NEED4Tweet over DBpedia Spotlight andthe combined Stanford and AIDA system.
Moreexperimental results and analysis can be found in(Habib and van Keulen, 2015).6 ConclusionIn this demo paper, we present NEED4Tweet, aTwitterbot for NEE and NED in tweets.
The sys-tem is composed of three phases.
The first phaseaims to generate NE candidates with an emphasison achieving high recall.
The second phase aimsto disambiguate all the candidates generated in thefirst phase.
For this task, we use a generic non-entity oriented disambiguation approach.
Men-tions are disambiguated by assigning them to ei-ther a Wikipedia article or a home page.
Finally,the third phase is to filter the NE candidates usingfeatures derived from disambiguation and othershape and KB features.
The proposed approachis shown to be robust against the coverage of KBsand the informality of the used language.ReferencesAmparo Elizabeth Cano Basave, Andrea Varga,Matthew Rowe, Milan Stankovic, and Aba-SahDadzie.
2013.
Making sense of microposts(#msm2013) concept extraction challenge.
In Mak-ing Sense of Microposts (#MSM2013) Concept Ex-traction Challenge, pages 1?15.Amparo Elizabeth Cano Basave, Giuseppe Rizzo, An-drea Varga, Matthew Rowe, Milan Stankovic, andAba-Sah Dadzie.
2014.
Making sense of microp-osts (#microposts2014) named entity extraction &linking challenge.
In Proc.
of (#Microposts2014)Workshop, pages 54?60.Maria Christoforaki, Ivie Erunse, and Cong Yu.
2011.Searching social updates for topic-centric entities.In Proc.
of exploreWeb 2011 Workshop, pages 34?39.A.
D. Delgado, R.
Mart?
?nez, A. P?erez Garc?
?a-Plaza,and V. Fresno.
2012.
Unsupervised Real-Time com-pany name disambiguation in twitter.
In Proc.
ofRAMSS 2012 Workshop, pages 25?28.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: annotation, features, and experiments.
InProc.
of ACL 2011, HLT ?11, pages 42?47.Mena B. Habib and Maurice van Keulen.
2012.
Unsu-pervised improvement of named entity extraction inshort informal context using disambiguation clues.In Proc.
of SWAIE 2012 Workshop, pages 1?10.Mena B. Habib and M. van Keulen.
2013.
A genericopen world named entity disambiguation approachfor tweets.
In Proc.
of KDIR 2013, pages 267?276.Mena B. Habib and Maurice van Keulen.
2015.
Twit-terneed: A hybrid approach for named entity extrac-tion and disambiguation for tweets.
To appear in thejournal of Natural Language Engineering.Jason J. Jung.
2012.
Online named entity recogni-tion method for microtexts in social networking ser-vices: A case study of twitter.
Expert Syst.
Appl.,39(9):8066?8070.Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao, An-witaman Datta, Aixin Sun, and Bu-Sung Lee.
2012.Twiner: named entity recognition in targeted twitterstream.
In Proc.
of SIGIR 2012, pages 721?730.Thomas Lin, Mausam, and Oren Etzioni.
2012.
En-tity linking at web scale.
In Proc.
of AKBC-WEKEX2012 Workshop, pages 84?88.Brian Locke and James Martin.
2009.
Named en-tity recognition: Adapting to microblogging.
SeniorThesis, University of Colorado.Pablo N. Mendes, Max Jakob, Andr?es Garc?
?a-Silva,and Christian Bizer.
2011.
Dbpedia spotlight: Shed-ding light on the web of documents.
In Proc.
of I-Semantics 2011, pages 1?8.A.
Ritter, S. Clark, Mausam, and O. Etzioni.
Namedentity recognition in tweets: An experimental study.In Proc.
of EMNLP 2011, pages 1524?1534.Damiano Spina, Enrique Amig?o, and Julio Gonzalo.2011.
Filter keywords and majority class strate-gies for company name disambiguation in twitter.
InProc.
of CLEF 2011, pages 50?61.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowl-edge.
In Proc.
of WWW 2007, pages 697?706.Thijs Westerveld, Wessel Kraaij, and Djoerd Hiemstra.2002.
Retrieving web pages using content, links,urls and anchors.
In Tenth Text REtrieval Confer-ence, TREC 2001, volume SP 500, pages 663?672.Surender Reddy Yerva, Zolt?an Mikl?os, and KarlAberer.
2012.
Entity-based classification of twittermessages.
IJCSA, 9(1):88?115.Zhemin Zhu, Djoerd Hiemstra, and Peter Apers.
2014.Linear co-occurrence rate networks (l-crns) for se-quence labeling.
In Statistical language and speechprocessing, volume 8791 of Lecture notes in com-puter science, pages 185?196.36
