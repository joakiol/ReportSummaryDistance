Proceedings of the 2009 Workshop on Grammar Engineering Across Frameworks, ACL-IJCNLP 2009, pages 37?45,Suntec, Singapore, 6 August 2009. c?2009 ACL and AFNLPConstruction of a German HPSG grammar from a detailed treebankBart Cramer?
and Yi Zhang?
?Department of Computational Linguistics & Phonetics, Saarland University, Germany?LT-Lab, German Research Center for Artificial Intelligence, Germany?
{bcramer,yzhang}@coli.uni-saarland.deAbstractGrammar extraction in deep formalismshas received remarkable attention in re-cent years.
We recognise its value, but tryto create a more precision-oriented gram-mar, by hand-crafting a core grammar, andlearning lexical types and lexical itemsfrom a treebank.
The study we performedfocused on German, and we used the Tigertreebank as our resource.
A completelyhand-written grammar in the framework ofHPSG forms the inspiration for our coregrammar, and is also our frame of refer-ence for evaluation.
11 IntroductionPrevious studies have shown that treebanks canbe helpful when constructing grammars.
Themost well-known example is PCFG-based statis-tical parsing (Charniak and Johnson, 2005), wherea PCFG is induced from, for instance, the PennTreebank.
The underlying statistical techniqueshave been refined in the last decade, and previ-ous work indicates that the labelled f-score of thismethod converges to around 91%.An alternative to PCFGs, with more linguisticrelevance, is formed by deeper formalisms, suchas TAG (Joshi and Schabes, 1997), CCG (Steed-man, 1996), LFG (Kaplan and Bresnan, 1995)and HPSG (Pollard and Sag, 1994).
For LFG(Butt et al, 2002) and HPSG (Flickinger, 2000;Mu?ller, 2002), large hand-written grammars havebeen developed.
In the case of HPSG, the gram-mar writers found the small number of principlestoo restrictive, and created more rules (approxi-mately 50 to 300) to accommodate for phenomena1The research reported in this paper has been carried outwith financial support from the Deutsche Forschungsgemein-schaft and the German Excellence Cluster of MultimodalComputing & Interaction.that vanilla HPSG cannot describe correctly.
Theincreased linguistic preciseness comes at a cost,though: such grammars have a lower out-of-the-box coverage, i.e.
they will not give an analysis ona certain portion of the corpus.Experiments have been conducted, where alexicalised grammar is learnt from treebanks, amethodology for which we coin the name deepgrammar extraction.
The basic architecture ofsuch an experiment is to convert the treebank toa format that is compatible with the chosen lin-guistic formalism, and read off the lexicon fromthat converted treebank.
Because all these for-malisms are heavily lexicalised, the core gram-mars only consist of a small number of principlesor operators.
In the case of CCG (Hockenmaierand Steedman, 2002), the core grammar consistsof the operators that CCG stipulates: function ap-plication, composition and type-raising.
StandardHPSG defines a few schemata, but these are usu-ally adapted for a large-scale grammar.
Miyao etal.
(2004) tailor their core grammar for optimal usewith the Penn Treebank and the English language,for example by adding a new schema for relativeclauses.Hockenmaier and Steedman (2002), Miyao etal.
(2004) and Cahill et al (2004) show fairly goodresults on the Penn Treebank (for CCG, HPSG andLFG, respectively): these parsers achieve accura-cies on predicate-argument relations between 80%and 87%, which show the feasibility and scalabil-ity of this approach.
However, while this is a sim-ple method for a highly configurational languagelike English, it is more difficult to extend to lan-guages with more complex morphology or withword orders that display more freedom.
Hocken-maier (2006) is the only study known to the au-thors that applies this method to German, a lan-guage that displays these properties.This article reports on experiments where theadvantages of hand-written and derived grammars37are combined.
Compared to previous deep gram-mar extraction approaches, a more sophisticatedcore grammar (in the framework of HPSG) is cre-ated.
Also, more detailed syntactic features arelearnt from the resource treebank, which leads toa more precise lexicon.
Parsing results are com-pared with GG (German Grammar), a previouslyhand-written German HPSG grammar (Mu?ller,2002; Crysmann, 2003; Crysmann, 2005).2 Core grammar2.1 Head-driven phrase structure grammarThis study has been entirely embedded in theHPSG framework (Pollard and Sag, 1994).
Thisis a heavily lexicalised, constraint-based theory ofsyntax, and it uses typed feature structures as itsrepresentation.
HPSG introduces a small num-ber of principles (most notably, the Head FeaturePrinciple) that guide the construction of a few Im-mediate Dominance schemata.
These schemataare meant to be the sole basis to combine wordsand phrases.
Examples of schemata are head-complement, head-subject, head-specifier, head-filler (for long-distance dependencies) and head-modifier.In this study, the core grammar is an extensionof the off-the-shelf version of HPSG.
The type hi-erarchy is organised by a typed feature structurehierarchy (Carpenter, 1992), and can be read bythe LKB system (Copestake, 2002) and the PETparser (Callmeier, 2000).
The output is given inMinimal Recursion Semantics (Copestake et al,2005) format, which can be minimally describedas a way to include scope information in depen-dency output.2.2 The German languageNot unlike English, German uses verb positionto distinguish between different clause types.
Indeclarative sentences, verbs are positioned in thesecond position, while subordinate classes areverb-final.
Questions and imperatives are verb-initial.
However, German displays some morefreedom with respect to the location of subjects,complements and adjuncts: they can be scram-bled rather freely.
The following sentences areall grammatical, and have approximately the samemeaning:(1) a.
DerThe.NOMPra?sidentPresident.NOMhathasgesternyesterdaydasthe.ACCBuchbook.ACCgelesen.read.PERF.
?The president read the book yester-day?b.
Gestern hat der Pra?sident das Buchgelesen.c.
Das Buch hat der Pra?sident gesterngelesen.As can be seen, the main verb is placed at sec-ond position (the so-called ?left bracket?
), but allother verbs remain at the end of the sentence,in the ?right bracket?.
Most linguistic theoriesabout German recognise the existence of topolog-ical fields: the Vorfeld before the left bracket, theMittelfeld between both brackets, and the Nach-feld after the right bracket.
The first two aremainly used for adjuncts and arguments, whereasthe Nachfeld is typically, but not necessarily, usedfor extraposed material (e.g.
relative clauses orcomparative phrases) and some VPs.
Again, thefollowing examples mean roughly the same:(2) a. ErHehathasdasthe.ACCBuch,Book.ACC,dasthatsiesheempfohlenrecommendedhat,has,gelesen.read.PERF.He has read the book that she recom-mended.b.
Er hat das Buch gelesen, das sie emp-fohlen hat.c.
Das Buch hat er gelesen, das sie emp-fohlen hat.Another distinctive feature of German is its rela-tively rich morphology.
Nominals are marked withcase, gender and number, and verbs with number,person, tense and mood.
Adjectives and nounshave to agree with respect to gender, number anddeclension type, the latter being determined bythe (non-)existence and type of determiner usedin the noun phrase.
Verbs and subjects have toagree with respect to number and person.
Ger-man also displays highly productive noun com-pounding, which amplifies the need for effectiveunknown word handling.
Verb particles can ei-ther be separated from or concatenated to the verb:compare ?Er schla?ft aus?
(?He sleeps in?)
and ?Er38Amerikaner?
?no-detVAL[SPEC ?
?SUBCAT ??]???
?nounVAL[SPEC ?det?SUBCAT ??]??mu?ssen???????
?verbVAL 1SLASH 2XCOMP?
?verbVAL 1SLASH 2?????????
?hart[adverbMOD verb]arbeiten?
?verb-infVAL[SUBJ ?np-nom?
]SLASH ?????
?slash-subjVAL[SUBJ ??
]SLASH ?np-nom????
?mod-headVAL[SUBJ ??
]SLASH ?np-nom????
?head-clusterVAL[SUBJ ??
]SLASH ?np-nom????
?filler-headVAL[SUBJ ??
]SLASH ???
?Figure 1: This figure shows a (simplified) parse tree of the sentence ?Amerikaner mu?ssen hart arbeiten?
(?Americans have to work hard?
).wird ausschlafen?
(?He will sleep in?).
In suchverbs, the word ?zu?
(which translates to the En-glish ?to?
in ?to sleep?)
can be infixed as well: ?erversucht auszuschlafen?
(?He tries to sleep in?
).These characteristics make German a compar-atively complex language to parse with CFGs:more variants of the same lemma have to be mem-orised, and the expansion of production rules willbe more diverse, with a less peaked statistical dis-tribution.
Efforts have been made to adapt existingCFG models to German (Dubey and Keller, 2003),but the results still don?t compare to state-of-the-art parsing of English.2.3 Structure of the core grammarThe grammar uses the main tenets from Head-driven Phrase Structure Grammar (Pollard andSag, 1994).
However, different from earlier deepgrammar extraction studies, more sophisticatedstructures are added.
Mu?ller (2002) proposes anew schema (head-cluster) to account for verbclusters in the right bracket, which includes thepossibility to merge subcategorisation frames ofe.g.
object-control verbs and its dependent verb.Separate rules for determinerless NPs, genitivemodification, coordination of common phrases,relative phrases and direct speech are also created.The free word order of German is accounted forby scrambling arguments with lexical rules, andby allowing adjuncts to be a modifier of unsat-urated verb phrases.
All declarative phrases areconsidered to be head-initial, with an adjunct orargument fronted using the SLASH feature, whichis then discharged using the head-filler schema.The idea put forward by, among others, (Kiss andWesche, 1991) that all sentences should be right-branching is linguistically pleasing, but turns outbe computationally very expensive (Crysmann,2003), and the right-branching reading should bereplaced by a left-branching reading when theright bracket is empty (i.e.
when there is no auxil-iary verb present).An example of a sentence is presented in fig-ure 1.
It receives a right-branching analysis, be-cause the infinitive ?arbeiten?
resides in the rightbracket.
The unary rule slash-subj moves the re-quired subject towards the SLASH value, so that itcan be discharged in the Vorfeld by the head-fillerschema.
?mu?ssen?
is an example of an argumentattraction verb, because it pulls the valence fea-ture (containing SUBJ, SUBCAT etc; not visiblein the diagram) to itself.
The head-cluster rule as-sures that the VAL value then percolates upwards.Because ?Amerikaner?
does not have a specifier, aseparate unary rule (no-det) takes care of discharg-ing the SPEC feature, before it can be combinedwith the filler-head rule.As opposed to (Hockenmaier, 2006), this study39(a)teure Detektive kann sich der Supermarkt nicht leistenNPMO HDNPDET HDVPHDNGOA DASSBOCHD(b)teure Detektive kann sich der Supermarkt nicht leistenNPMO HDNPDET HDSOA HD REFL SB MO VCFigure 2: (a) shows the original sentence, whereas (b) shows the sentence after preprocessing.
Note thatNP is now headed, that the VP node is deleted, and that the verbal cluster is explicitly marked in (b).
Theglossary of this sentence is ?Expensive.ACC detectives.ACC can REFL the.NOM supermarket.NOM notafford?employs a core lexicon for words that have markedsemantic behaviour.
These are usually closedword classes, and include items such as raisingand auxiliary verbs, possessives, reflexives, arti-cles, complementisers etc.
The size of this corelexicon is around 550 words.
Note that, becausethe core lexicon only contains function words, itscoverage is negligible without additional entries.3 Derivation of the lexicon3.1 The Tiger treebankThe Tiger treebank (Brants et al, 2002) is a tree-bank that embraces the concept of constituency,but can have crossing branches, i.e.
the tree mightbe non-projective.
This allowed the annotators tocapture the German free word order.
Around one-third of the sentences received a non-projectiveanalysis.
An example can be found in figure 2.Additionally, it annotates each branch with a syn-tactic function.The text comes from a German newspaper(Frankfurter Rundschau).
It was annotated semi-automatically, using a cascaded HMM model.
Af-ter each phase of the HMM model, the output wascorrected by human annotators.
The corpus con-sists of over 50,000 sentences, with an averagesentence length of 17.6 tokens (including punc-tuation).
The treebank employs 26 phrase cate-gories, 56 PoS tags and 48 edge labels.
It also en-codes number, case and gender at the noun termi-nals, and tense, person, number and mood at verbs.Whether a verb is finite, an infinitive or a partici-ple is encoded in the PoS tag.
A peculiarity in theannotation of noun phrases is the lack of headed-ness, which was meant to keep the annotation astheory-independent as reasonably possible.3.2 PreprocessingA number of changes had to be applied to the tree-bank to facilitate the read-off procedure:?
A heuristic head-finding procedure is appliedin the spirit of (Magerman, 1995).
We usepriority lists to find the NP?s head, deter-miner, appositions and modifiers.
PPs andCPs are also split into a head and its depen-dent.?
If a verb has a separated verb particle, thisparticle is attached to the lemma of the verb.For instance, if the verb ?schlafen?
has a parti-cle ?aus?, the lemma will be turned into ?auss-chlafen?
(?sleep in?).
If this is not done, sub-categorisation frames will be attributed to thewrong lemma.?
Sentences with auxiliaries are non-projective,if the adjunct of the embedded VP is in theVorfeld.
This can be solved by flattening thetree (removing the VP node), and markingthe verbal cluster (VC) explicitly.
See fig-ure 2 for an example.
67.6% of the origi-nal Tiger treebank is projective, and with thisprocedure, this is lifted to 80.1%.?
The Tiger treebank annotates reflexive pro-nouns with the PoS tag PRF, but does notdistinguish the syntactic role.
Therefore, if averb has an object that has PRF as its part-of-speech, the label of that edge is changed intoREFL, so that reflexive verbs can be found.40(a)0 10 20 30 40 5001000020000300004000050000(b)0 10 20 30 40 5002004006008001000(c)0 10 20 30 40 5000.10.20.30.40.5Figure 3: These graphs show learning curves of the algorithm on the first 45,000 sentences of the Tigertreebank.
Graph (a) indicates the amount of lemmas learnt (from top to bottom: nouns, names, adjec-tives, verbs and adverbs).
The graph in (b) shows the number of distinct lexical types for verbs that arelearnt.
Graph (c) shows the average proportion of morphological forms that is observed per verb lemma,assuming that each verb has 28 different forms: infinitive, zu (to) + infinitive, participle, imperative and24 finite forms (3 (person) * 2 (number) * 2 (tense) * 2 (mood)).The preprocessing stage failed in 1.1% of theinstances.3.3 Previous workThe method described in Hockenmaier (2006) firstconverts the Tiger analysis to a tree, after whichthe lexical types were derived.
Because it wasthe author?s goal to convert all sentences, somerather crude actions had to be taken to rendernon-projective trees projective: whenever a cer-tain node introduces non-projectivity, some of itsdaughters are moved to the parent tree, until thatnode is projective.
Below, we give two exampleswhere this will lead to incorrect semantic compo-sition, with the consequence of flawed lexicon en-tries.
We argue that it is questionable whether theimpressive conversion scores actually represent ahigh conversion quality.
It would be interesting tosee how this grammar performs in a real parsingtask, but no such study has been carried out so far.The first case deals with extraposed material inthe Nachfeld.
Typical examples include relativephrases, comparatives and PH/RE constructions2.2NPs, AVPs and PPs can, instead of their usual headedstructure, be divided in two parts: a ?placeholder?
anda ?repeated element?.
These nodes often introduce non-projectivity, and it is not straightforward to create a valid lin-guistic analysis for these phenomena.
Example sentences ofthese categories (NPs, AVPs and PPs, respectively) are:(1) [ PH Es ] ist wirklich schwer zu sagen, [ RE welchePositionen er einnimmt ](2) Man mu?
sie also [ PH so ] behandeln , [ RE wie maneine Weltanschauungsbewegung behandelt ](3) Alles deutet [ PH darauf ] hin [ RE da?
sie es nichtschaffen wird ]These examples all have the RE in the Nachfeld, but theirplacement actually has a large variety.The consequence is that the head of the extraposedmaterial will be connected to the verb, instead ofto the genuine head.Another example where Hockenmaier?s algo-rithm will create incorrect lexical entries is whenthe edge label is PAR (for ?parentheses?)
or in thecase of appositions.
Consider the following sen-tence:(3) mitwith160160Planstellenpermanent posts(etliche(severalsindareallerdingshowevernochstillunbesetzt)unoccupied)The conclusion that will be drawn from this sen-tence is that ?sind?
can modify nouns, which isonly true due to the parentheses, and has no re-lation with the specific characteristics of ?sind?.Similarly, appositions will act as modifiers ofnouns.
Although one might argue that this is thecanonical CCG derivation for these phenomena, itis not in the spirit of the HPSG grammars, and webelieve that these constructions are better handledin rules than in the lexicon.3.4 ProcedureIn our approach, we will be more conservative,and the algorithm will only add facts to its knowl-edge base if the evidence is convincing.
Thatmeans that less Tiger graphs will get projectiveanalyses, but that doesn?t have to be a curse: wecan derive lexical types from non-projective anal-yses just as well, and leave the responsibility forsolving the more complex grammatical phenom-ena to the core grammar.
For example, lexicalrules will deal with fronting and Mittelfeld scram-bling, as we have stated before.
This step of the41procedure has indeed strong affinity with deep lex-ical acquisition, except for the fact that in DLA alllexical types are known, and this is not the case inthis study: the hand-written lexical type hierarchyis still extended with new types that are derivedfrom the resource treebank, mostly for verbs.The basic procedure is as follows:?
Traverse the graph top-down.?
For each node:?
Identify the node?s head (or the deepestverb in the verb cluster3);?
For each complement of this node, addthis complement to the head?s subcate-gorisation frame.?
For each modifier, add this head to thepossible MOD values of the modifier?shead.?
For each lexical item, a mapping of (lemma,morphology)?
word form is created.After this procedure, the following informationis recorded for the verb lemma ?leisten?
from fig-ure 2:?
It has a subcategorisation frame ?npnom-refl-npacc?.?
Its infinitive form is ?leisten?.The core grammar defines that possible sub-jects are nominative NPs, expletive ?es?
and CPs.Expletives are considered to be entirely syntac-tic (and not semantic), so they will not receive adependency relation.
Complements may includepredicative APs, predicative NPs, genitive, dativeand accusative NPs, prepositional complements,CPs, reflexives, separable particles (also purelysyntactic), and any combination of these.
For non-verbs, the complements are ordered (i.e.
it is alist, and not a verb).
Verb complementation pat-terns are sets, which means that duplicate com-plements are not allowed.
For verbs, it is alsorecorded whether the auxiliary verb to mark theperfect tense should be either ?haben?
(default) or?sein?
(mostly verbs that have to do with move-ment).
Nouns are annotated with whether they canhave appositions or not.3That means that the head of a S/VP-node is assumedto be contained in the lexicon, as it must be some sort ofauxiliary.Results from the derivation procedure aregraphed in figure 3.
The number of nouns andnames is still growing after 45,000 sentences,which is an expected result, given the infinite na-ture of names and frequent noun compounding.However, it appears that verbs, adjectives and ad-verbs are converging to a stable level.
On the otherhand, lexical types are still learnt, and this shows adownside of our approach: the deeper the extrac-tion procedure is, the more data is needed to reachthe same level of learning.The core grammar contains a little less than 100lexical types, and on top of that, 636 lexical typesare learnt, of which 579 are for verbs.
It is inter-esting to see that the number of lexical types isconsiderably lower than in (Hockenmaier, 2006),where around 2,500 lexical types are learnt.
Thisshows that our approach has a higher level of gen-eralisation, and is presumably a consequence ofthe fact that the German CCG grammar needs dis-tinct lexical types for verb-initial and verb-finalconstructions, and for different argument scram-blings in the Mittelfeld, whereas in our approach,hand-written lexical rules are used to do the scram-bling.The last graph shows that the number of wordforms is still insufficient.
We assume that eachverb can have 28 different word forms.
As can beseen, it is clear that only a small part of this areais learnt.
One direction for future research mightbe to find ways to automatically expand the lexi-con after the derivation procedure, or to hand-codemorphological rules in the core grammar.4 Parsing4.1 MethodologyAll experiments in this article use the first 45,000sentences as training data, and the consecutive5,000 sentences as test data.
The remaining 472sentences are not used.
We used the PET parser(Callmeier, 2000) to do all parsing experiments.The parser was instructed to yield a parse error af-ter 50,000 passive edges were used.
Ambiguitypacking (Oepen and Carroll, 2000) and selectiveunpacking (Zhang et al, 2007) were used to re-duce memory footprint and speed up the selectionof the top-1000 analyses.
The maximum entropymodel, used for selective unpacking, was based on200 treebanked sentences of up to 20 words fromthe training set.
Part-of-speech tags delivered bythe stock version of the TnT tagger (Brants, ) were42Tiger T.+TnT GGOut of vocabulary 71.9 % 5.2 % 55.6 %Parse error 0.2 % 1.5 % 0.2 %Unparsed 7.9 % 37.7 % 28.2 %Parsed 20.0 % 55.6 % 16.0 %Total 100.0 % 100.0 % 100.0 %Avg.
length 8.6 12.8 8.0Avg.
nr.
of parses 399.0 573.1 19.2Avg.
time (s) 9.3 15.8 11.6Table 1: This table shows coverage results on the held-out test set.
The first column denotes how theextracted grammar performs without unknown word guessing.
The second column uses PoS tags andgeneric types to guide the grammar when an unknown word is encountered.
The third column is theperformance of the fully hand-written HPSG German grammar by (Mu?ller, 2002; Crysmann, 2003).OOV stands for out-of-vocabulary.
A parse error is recorded when the passive edge limit (set to 50,000)has been reached.
The bottom three rows only gives information about the sentences where the grammaractually returns at least one parse.Training set Test setAll 100.0 % 100.0 %Avg.
length 14.2 13.5Coverage 79.0 % 69.0 %Avg.
length 13.2 12.8Correct (top-1000) 52.0% 33.5 %Avg.
length 10.4 8.5Table 2: Shown are the treebanking results, giv-ing an impression of the quality of the parses.The ?training set?
and ?test set?
are subsets of 200sentences from the training and test set, respec-tively.
?Coverage?
means that at least one analysisis found, and ?correct?
indicates that the perfectsolution was found in the top-1000 parses.used when unknown word handling was turnedon.
These tags were connected to generic lexicaltypes by a hand-written mapping.
The version ofGG that was employed (Mu?ller, 2002; Crysmann,2003) was dated October 20084.4.2 ResultsTable 1 shows coverage figures in three differentsettings.
It is clear that the resulting grammar hasa higher coverage than the GG, but this comes at acost: more ambiguity, and possibly unnecessaryambiguity.
Remarkably, the average processingtime is lower, even when the sentence lengths and4It should be noted that little work has gone in to provid-ing unknown word handling mechanisms, and that is why wedidn?t include it in our results.
However, in a CoNLL-2009shared task paper (Zhang et al, 2009), a coverage of 28.6%was reported when rudimentary methods were used.ambiguity rates are higher.
We attribute this tothe smaller feature structure geometry that is in-troduced by the core grammar (compared to theGG).
Using unknown word handling immediatelyimproved the coverage, by a large margin.
Largerambiguity rates were recorded, and the number ofparser errors slightly increased.Because coverage does not imply quality, wewanted to look at the results in a qualitative fash-ion.
We took a sample of 200 sentences fromboth the training and the test set, where the onesfrom the training set did not overlap with the setused to train the MaxEnt model, so that both set-tings were equally influenced by the rudimentaryMaxEnt model.
We evaluated for how many sen-tences the exactly correct parse tree could be foundamong the top-1000 parses (see table 2).
The dif-ference between the performance on the trainingand test set give an idea of how well the gram-mar performs on unknown data: if the differenceis small, the grammar extends well to unseen data.Compared to evaluating on lexical coverage, webelieve this is a more empirical estimation of howclose the acquisition process is to convergence.Based on the kind of parse trees we observed,the impression was that on both sets, performancewas reduced due to the limited predictive powerof the disambiguation model.
There were quitea few sentences for which good parses could beexpected, because all lexical entries were present.This experiment also showed that there were sys-tematic ambiguities that were introduced by in-consistent annotation in the Tiger treebank.
For in-43stance, the word ?ein?
was learnt as both a number(the English ?one?)
and as an article (?a?
), leadingto spurious ambiguities for each noun phrase con-taining the word ?ein?, or one of its morphologicalvariants.
These two factors reinforced each other:if there is spurious ambiguity, it is even harder fora sparsely trained disambiguation model to pullthe correct parse inside the top-1000.The difference between the two ?correct?
num-bers in table 2 is rather large, meaning that the?real?
coverage might seem disappointingly low.Not unexpectedly, we found that the generic lex-ical types for verbs (transitive verb, third personsingular) and nouns (any gender, no appositionsallowed) was not always correct, harming the re-sults considerably.A quantitative comparison between deep gram-mars is always hard.
Between DELPH-IN gram-mars, coverage has been the main method of eval-uation.
However, this score does not reward rich-ness of the semantic output.
Recent evidence fromthe ERG (Ytrest?l et al, 2009) suggests that theERG reaches a top-500 coverage of around 70%on an unseen domain, a result that this experimentdid not approximate.
The goal of GG is not com-putational, but it serves as a testing ground for lin-guistic hypotheses.
Therefore, the developers havenever aimed at high coverage figures, and craftedthe GG to give more detailed analyses and to besuited for both parsing and generation.
We arehappy to observe that the coverage figures in thisstudy are higher than GG?s (Zhang et al, 2009),but we realise the limited value of this evaluationmethod.
Future studies will certainly include amore granular evaluation of the grammar?s perfor-mance.5 Conclusion and discussionWe showed how a precise, wide-coverage HPSGgrammar for German can be created successfully,by constructing a core grammar by hand, and ap-pending it with linguistic information from theTiger treebank.
Although this extracted gram-mar suffers considerably more from overgenera-tion than the hand-written GG, we argue that ourconservative derivation procedure delivers a moredetailed, compact and correct compared to pre-vious deep grammar extraction efforts.
The useof the core lexicon allows us to have more lin-guistically motivated analyses of German than ap-proaches where the core lexicon only comprisesthe textbook principles/operators.
We comparedour lexicon extraction results to those from (Hock-enmaier, 2006).
Also, preliminary parsing exper-iments are reported, in which we show that thisgrammar produces reasonable coverage on unseentext.Although we feel confident about the successfulacquisition of the grammar, there still remain somelimiting factors in the performance of the grammarwhen actually parsing.
Compared to coverage fig-ures of around 80%, reported by (Riezler et al,2001), the proportion of parse forests containingthe correct parse in this study is rather low.
Thefirst limit is the constructional coverage, mean-ing that the core grammar is not able to constructthe correct analysis, even though all lexical en-tries have been derived correctly before.
The mostfrequent phenomena that are not captured yet arePH/RE constructions and extraposed clauses, andwe plan to do an efficient implementation (Crys-mann, 2005) of these in a next version of the gram-mar.
Second, as shown in figure 3, data scarcity inthe learning of the surface forms of lemmas neg-atively influences the parser?s performance on un-seen text.In this paper, we focused mostly on the cor-rectness of the derivation procedure.
We wouldlike to address the real performance of the gram-mar/parser combination in future work, which canonly be done when parses are evaluated accordingto a more granular method than we have done inthis study.
Furthermore, we ran into the issue thatthere is no straightforward way to train larger sta-tistical models automatically, which is due to thefact that our approach does not convert the sourcetreebank to the target formalism?s format (in ourcase HPSG), but instead reads off lexical typesand lexical entries directly.
We plan to investigatepossibilities to have the annotation be guided auto-matically by the Tiger treebank, so that the disam-biguation model can be trained on a much largeramount of training data.AcknowledgementsWe would like to thank Rebecca Dridan, AntskeFokkens, Stephan Oepen and the anonymous re-viewers for their valuable contributions to this pa-per.44ReferencesT.
Brants.
TnT: a statistical part-of-speech tagger.
InProceedings of the Sixth Conference on Applied Nat-ural Language Processing.S.
Brants, S. Dipper, S. Hansen, W. Lezius, andG.
Smith.
2002.
The TIGER Treebank.
In Proceed-ings of the Workshop on Treebanks and LinguisticTheories, pages 24?41.M.
Butt, H. Dyvik, T.H.
King, H. Masuichi, andC.
Rohrer.
2002.
The parallel grammar project.In International Conference On Computational Lin-guistics, pages 1?7.A.
Cahill, M. Burke, R. ODonovan, J.
Van Genabith,and A.
Way.
2004.
Long-distance dependencyresolution in automatically acquired wide-coveragePCFG-based LFG approximations.
In Proceedingsof ACL-2004, pages 320?327.U.
Callmeier.
2000.
PET?a platform for experimen-tation with efficient HPSG processing techniques.Natural Language Engineering, 6(01):99?107.B.
Carpenter.
1992.
The Logic of Typed Feature Struc-tures: With Applications to Unification Grammars,Logic Programs, and Constraint Resolution.
Cam-bridge University Press, Cambridge, UK.E.
Charniak and M. Johnson.
2005.
Coarse-to-fine n-best parsing and MaxEnt discriminative reranking.In Proceedings of ACL-2005, pages 173?180.A.
Copestake, D. Flickinger, C. Pollard, and I. Sag.2005.
Minimal Recursion Semantics: An Intro-duction.
Research on Language & Computation,3(4):281?332.A.
Copestake.
2002.
Implementing Typed FeatureStructure Grammars.
CSLI Publications, Stanford,CA, USA.B.
Crysmann.
2003.
On the efficient implementationof German verb placement in HPSG.
In Proceedingsof RANLP-2003, pages 112?116.B.
Crysmann.
2005.
Relative Clause Extraposition inGerman: An Efficient and Portable Implementation.Research on Language & Computation, 3(1):61?82.A.
Dubey and F. Keller.
2003.
Probabilistic parsingfor German using sister-head dependencies.
In Pro-ceedings of the 41st Annual Meeting on Associationfor Computational Linguistics, pages 96?103.D.
Flickinger.
2000.
On building a more effcient gram-mar by exploiting types.
Natural Language Engi-neering, 6(1):15?28.J.
Hockenmaier and M. Steedman.
2002.
Acquiringcompact lexicalized grammars from a cleaner tree-bank.
In Proceedings of LREC-2002, pages 1974?1981.J.
Hockenmaier.
2006.
Creating a CCGbank and aWide-Coverage CCG Lexicon for German.
In Pro-ceedings of ACL-2006, pages 505?512.A.K.
Joshi and Y. Schabes.
1997.
Tree-adjoininggrammars.
Handbook of formal languages, 3:69?124.R.M.
Kaplan and J. Bresnan.
1995.
Lexical-FunctionalGrammar: A formal system for grammatical rep-resentation.
Formal Issues in Lexical-FunctionalGrammar, pages 29?130.T.
Kiss and B. Wesche.
1991.
Verb order and headmovement.
Text Understanding in LILOG, LectureNotes in Artificial Intelligence, 546:216?242.D.
Magerman.
1995.
Statistical decision-tree mod-els for parsing.
In Proceedings of ACL-1995, pages276?283.Y.
Miyao, T. Ninomiya, and J. Tsujii.
2004.
Corpus-oriented grammar development for acquiring aHead-driven Phrase Structure Grammar from thePenn Treebank.
In Proceedings of IJCNLP-2004.S.
Mu?ller.
2002.
Complex Predicates: VerbalComplexes, Resultative Constructions, and ParticleVerbs in German.
CSLI Publications, Stanford, CA,USA.S.
Oepen and J. Carroll.
2000.
Ambiguity packing inconstraint-based parsing: practical results.
In Pro-ceedings of NAACL-2000, pages 162?169.C.J.
Pollard and I.A.
Sag.
1994.
Head-Driven PhraseStructure Grammar.
University Of Chicago Press,Chicago, IL, USA.S.
Riezler, T.H.
King, R.M.
Kaplan, R. Crouch, J.T.Maxwell III, and M. Johnson.
2001.
Parsingthe Wall Street Journal using a Lexical-FunctionalGrammar and discriminative estimation techniques.In Proceedings of ACL-2001, pages 271?278.M.
Steedman.
1996.
Surface structure and interpreta-tion.
MIT Press, Cambridge, MA, USA.G.
Ytrest?l, D. Flickinger, and S. Oepen.
2009.
Ex-tracting and Annotating Wikipedia Sub-Domains.In Proceedings of the Seventh International Work-shop on Treebanks and Linguistic Theories, pages185?197.Y.
Zhang, S. Oepen, and J. Carroll.
2007.
Efficiencyin Unification-Based N-Best Parsing.
In Proceed-ings of the Tenth International Conference on Pars-ing Technologies, pages 48?59.Y.
Zhang, R. Wang, and S.. Oepen.
2009.
Hybrid Mul-tilingual Parsing with HPSG for SRL.
In Proceed-ings of CoNLL-2009, to appear.45
