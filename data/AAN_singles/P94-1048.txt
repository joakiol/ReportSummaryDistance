DUAL-CODING THEORY AND CONNECTIONIST LEXICALSELECTIONYe-Yi Wang*Computat iona l  L inguist ics ProgramCarnegie  Mel lon Univers i tyPittsburgh, PA 15232Internet: yyw@cs .cmu.eduAbstractWe introduce the bilingual dual-coding theory as amodel for bilingual mental representation.
Based onthis model, lexical selection eural networks are imple-mented for a connectionist transfer project in machinetranslation.IntroductionPsycholinguistic knowledge would be greatly helpful,as we believe, in constructing an artificial anguageprocessing system.
As for machine translation, weshould take advantage of our understandings of (1)how the languages are represented in human mind; (2)how the representation is mapped from one languageto another; (3) how the representation a d mapping areacquired by human.The bilingual dual-coding theory (Paivio, 1986)partially answers the above questions.
It depicts theverbal representations for two different languages astwo separate but connected logogen systems, charac-terizes the translation process as the activation alongthe connections between the logogen systems, and at-tributes the acquisition of the representation to someunspecified statistical processes.We have explored an information theoretical neu-ral network (Gorin and Levinson, 1989) that can ac-quire the verbal associations in the dual-coding theory.It provides a learnable lexical selection sub-system fora conneetionist transfer project in machine translation.Dual-Coding TheoryThere is a well-known debate in psycholinguisticsconcerning the bilingual mental representation: i de-pendence position assumes that bilingual memory isrepresented by two functionally independent s orageand retrieval systems, whereas interdependence po-sition hypothesizes that all information of languagesexists in a common memory store.
Studies on cross-language transfer and cross-language priming have*This work was partly supported by ARPA and ATR In-terpreting Telephony Research Laboratorie.provided evidence for both hypotheses (de Groot andNas, 1991; Lambert, 1958).Dual-coding theory explains the coexistence ofin-dependent and interdependent phenomena with sepa-rate but connected structures.
The general dual-codingtheory hypothesizes that human represents languagewith dual systems - -  the verbal system and the im-agery system.
The elements of the verbal system arelogogens for words in a language.
The elements ofthe imagery system, called "imagens", are connectedto the logogens in the verbal systems via referentialconnections.
Logogens in a verbal system are also in-terconnected with associative connections.
The bilin-gual dual-coding theory proposes an architecture inwhich a common imagery system is connected to twoverbal systems, and the two verbal systems are inter-connected to each other via associative connections\[Figure 1\].
Unlike the within-language associations,which are rich and diverse, these between-languageassociations involve primarily translation equivalentterms that are experienced together frequently.
Theinterconnections among the three systems explain theinterdependent functional behavior.
On the other hand,the different characteristics of within-language andbetween-language associations account for the inde-pendent functional behavior.Based on the above structural assumption, dual-"coding theory proposes a parallel set of processingassumptions.
Activation of connections between ref-erentially related imagens and logogens is called ref-erential processing.
Naming objects and imaging towords are prototypical examples.
Activation of asso-ciative connections between logogens is called asso-ciative processing.
Lexical translation is an exampleof associative processing between two languages.Connectionist Lexical SelectionLexical SelectionLexical selection is the task of choosing target lan-guage words that accurately reflect he meaning of thecorresponding source language words.
It plays an im-portant role in machine translation (Pustejovsky and325L1 Verbal Systemf.. -~V I Association NetworkL2 Verbal SystemfV 2 Association NelworkV I  - I Connections V 2 - I Connect ionsImagery SystemFigure 1: Bilingual Dual-Coding RepresentationNirenburg, 1987).A common lexical selection practice involvesan intermediate r presentation.
It disambiguates thesource language words to entities in the intermediaterepresentation, then maps from the entities to the targetlexical entries.
This intermediate r presentation maybe Lexical Concept Structure (Dorr, 1989) or inter-lingua (Nirenberg, 1987).
This engineering approachrequires great effort in designing the representation andthe mapping rules.Currently, there are some efforts in statistical lex-ical selection.
A target language word W t can be se-lected with the posterior probability Pr(Wt I Ws) giventhe source language word Ws.
Several target languagelexicai entries may be selected for a single source lan-guage word.
Then the correct selections can be iden-tiffed by the language model of the target language(Brown, 1990).
This approach is learnable.
However,the accuracy is low.
One reason is that it does not useany structural information of a language.In next subsections, we propose information-theoretical networks based on the bilingual dual-codingtheory for lexical selection.In format ion-Theoret ica l  NetworksInformation-theoretical network is a neural networkformalism that is capable of doing associations be-tween two layers of representations.
The associationscan be obtained statistically according to the network'sexperiences.An information-theoretical network has two lay-ers.
Each unit of a layer represents an element in theinput or output of a training pattern, which might be alogogen or a word.
Units in different layers are con-nected.
The weight of the connection between unit iin one layer and unit j in the other layer is assignedwith the mutual information between the elements rep-resenled by the two units(1) wij = l(vi, vj) = log(Pr(vjvi) /er(vi))  lEach layer also contains a bias unit, which is al-ways activated.
The weight of the connection betweenthe bias unit in one layer and unitj in the other layer is(2) woj = loger(v j )Both the information-theoretical network and theback-propagation network compute the posterior prob-abilities for an association task (Gorin and Levin-son, 1989; Robinson, 1992).
However, only theinformation-theoretical network is isomorphic to thedirectly interconnected verbal systems in the dual-coding theory.
Besides, an information-theoretical net-work has the following advantages: (1) it learns fast.The network can learn in a single pass without gra-dient decent.
(2) it is adaptive.
It can incrementallyadapt o new experiences simply by adding new datato the training samples and modifying the associationsaccording to the changed statistics.
These make thenetwork more psychologically plausible.Lexical Select ion as an Assoc iat ive ProcessWe tried to map source language f-structures to targetlanguage f-structure in a connectionist transfer project(Wang, 1994).
Functionally, there were two sub-tasks:1. finding the target sub-structures, their phrasal cat-egories and their corresponding source structures; 2.finding the head of a target structure.
The second sub-task is a problem of lexical selection.
It was first im-plemented with a back-propagation network.We replaced the back-propagation networks forlexical selection with information-theoretical networkssimulating the associative process in the dual-codingtheory.
The networks have two layers of units.
Eachsource (target) language lexical item is represented bya unit in the input (output) layer.
One network is con-structed for each phrasal category (NP, VP, AP, etc.
).The networks works in the following way: for atarget-language f-structure to be generated, the transfersystem knows its phrasal category and its correspond-ing source-language f-structure from the networks thatperform the sub-task 1.
It then activates the lexical se-lection etwork for that phrasal category with the inputunits that correspond to the heads of the source lan-guage f-structure and its sub-structures.
Through theconnections between the two layers, the output unitsare activated, and the lexical item that corresponds tothe most active output unit is selected as the head ofthe target f-structure.
The following example illus-trates how the system selects the head anmelden for1Where vi means the event that unit i is activated.326the German XCOMP sub-structure when it does thetransfer from\[sentence \[subj i\] would \[xcomp \[subj \]\] like \[xeomp \[subjI\] register \[pp-adjfor the conference\]\]\]\] to\[sentence \[subj Ich\] werde \[xcomp \[subj Ich\] \[adj gerne\]anmelden \[pp-aajfuer der Konferenz\]\]\] 2.Since the structure networks find that there is aVP sub-structure of XCOMP in the target structurewhose corresponding input structure is \[xcomp \[subjto register \[pp-adjfor the conference\]\]\], it activates theVP lexical selection etwork's input units for I, registerand conference.
By propagating the activation via theassociative connections, the unit for anmelden is themost active output.
Therefore, anmelden is chosen asthe head of the xcomp sub-structure.Preliminary ResultThe domain of our work was the Conference Registra-tion Telephony Conversations.
The lexicon for the taskcontained about 500 English and 500 German words.There were 300 English/German f-structurepairs avail-able from other research tasks (Osterholtz, 1992).
Aseparate set of 154 sentential f-structures was used totest the generalization performance of the system.
Thetesting data was collected for an independent task (Jain,1991).From the 300 sentential f-structure pairs, everyGerman VP sub-structure is extracted and labeled withits English counterpart.
The English counterpart's headand its immediate sub-structures' heads serve as theinput in a sample of VP association, and the Germanf-structure's head become the output of the association.For the above example, the association (\]input I, regis-ter, conference\] \[output anmelden\]) is a sample drawnfrom the f-structures for the VP network.
The trainingsamples for all the other networks are created in thesame way.The accuracy of our system with information-theoretical network lexical selection is lower than theone with back-propagation networks (around 84% ver-sus around 92%) for the training data.
However, thegeneralization performance onthe unseen inputs is bet-ter (around 70% versus around 62%).
The information-theoretical networks do not over-learn as the back-propagation etworks.
This is partially due to thereduced number of free parameters in the information-theoretical networks.SummaryThe lexical selection approach discussed here has twoadvantages.
First, it is learnable.
Little human efforton knowledge ngineering is required.
Secondly, it ispsycholinguisticaUy well-founded in that the approach2The f-structures are simplified here for the sake ofconciseness.adopts a local activation processing model instead ofrelies upon symbol passing, as symbolic systems usu-ally do.ReferencesP.
F. Brown and et al A statistical pproach to machinetranslation.
ComputationalLinguistics, 16(2):73-85, 1990.A.
M. de Groot and G. L. Nas.
Lexical representationof cognates and noncognates in compound bilin-gums.
Journal of Memory and Language, 30(1),1991.B.
J. Dorr.
Conceptual basis of the lexicon in ma-chine translation.
Technical Report A.I.
MemoNo.
1166, Artificial Intelligence Laboratory, MIT,August, 1989.A.
L. Gorin and S. E. Levinson.
Adaptive acquisition oflanguage.
Technical report, Speech Research De-partment, AT&T Bell Laboratories, Murray Hill,1989.A.
N. Jain.
Parsec: A connectionist learning archi-tecture for parsing spoken language.
TechnicalReport CMU-CS-91-208, Carnegie Mellon Uni-versity, 1991.W.
E. Lambert, J. Havelka and C. Crosby.
The influ-ence of language acquisition contexts on bilingual-ism.
Journal of Abnormal and Social Psychology,56, 1958.S.
Nirenberg, V. Raskin and A.
B. Tucker.
The struc-ture of interlingua in translator.
In S. Niren-burg, editor, Machine Translation: TheoreticalandMethodologicallssues.
Cambridge UniversityPress, Cambridge, England, 1987.L.
Osterholtz and et al Janus: a multi-lingual speechto speech translation system.
In Proceedings ofthe IEEE International Conference on Acoustics,Speech and Signal Processing, volume 1, pages209-212.
IEEE, 1992.A.
Paivio.
Mental Representations ~ A Dual CodingApproach.
Oxford University Press, New York,1986.J.
Pustejovsky and S. Nirenburg.
Lexical selection inthe process of language generation.
In Proceed-ings of the 25th Annual Conference of the Associ-ation for Computational Linguistics, pages 201-206, Standford University, Standford, CA, 1987.A.
Robinson.
Practical network design and implemen-tation.
In Cambridge Neural Network SummerSchool, 1992.Y.
Wang and A. Waibel.
Connectionist transfer in ma-chine translation.
Inprepare, 1994.327
