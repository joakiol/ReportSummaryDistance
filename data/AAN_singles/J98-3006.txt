Squibs and DiscussionsDo the Right Thing ... but Expect theUnexpectedJon Ober lander"University of Edinburgh1.
Do the Right ThingDale and Reiter (1995) have recently discussed the nature of referring expression gen-eration, focusing on the case of definite noun phrases.
In particular, they considerGricean approaches, whereby the speaker is supposed to take into account likely in-ferences by the hearer, in accord with Gricean maxims (Grice 1989), and select thegenerated NP accordingly, so as to avoid false or misleading inferences (Joshi 1982).They observe that previous accounts (including their own) have attempted tooptimiz ethe generated noun phrase, making it as brief as possible, within the constraints ofaccurately distinguishing the intended referent from any other candidate referents.
Forinstance, consider a situation containing three animals: one small white cat and twodogs, one large and black and the other small and white.
It is usually assumed thatan optimal description of the first dog is either the large dog or the black dog, whereasthe large black dog will be suboptimal, since it contains two adjectives where one willdo; it is longer than strictly necessary, and suffers from a degree of redundancy (Dale1992; Reiter 1990).However, Dale and Reiter argue that the previous algorithms proposed for thistask are computationally inefficient, and that the task itself must be reconsidered.
Inparticular, they suggest that there is substantial psycholinguistic evidence that peopledon't generate the shortest, most efficient NPs, and that this behavior is regarded asperfectly natural (see Levelt \[1989\] for a survey).
Hence, generation algorithms neednot optimize their descriptions either.Dale and Reiter go further; they state that:One could even argue that an algorithm based on psycholinguistic observationsof human speakers may in fact be superior to one that attempts to interpret themaxims as strictly as (computationally) possible.
This would be justified if onebelieved that the Gricean maxims were simply an approximation tothe generalprinciple of "if a speaker utters an unexpected utterance, the hearer may try toinfer a reason for the speaker's failure to use the expected utterance"; under thisperspective, a system that imitated human behaviour would be more likely togenerate ' xpected' utterances than a system that simply tried to obey generalprinciples uch as brevity, relevance, and so on.
(p. 253)The primary point is that the behavior of human speakers involves the productionof nonrninimal utterances, and their hearers expect his behavior.
Conversely, hearersdo not expect speakers to produce optimal, minimized utterances; uch an unexpectedutterance would in fact provoke its hearer to search for reasons for its speaker's failure* Human Communication Research Centre, University ofEdinburgh, 2 Buccleuch Place, Edinburgh EH89LW, Scotland(~) 1998 Association for Computational LinguisticsComputational Linguistics Volume 24, Number 3to use an expected utterance.
Both people and natural anguage generation systemsshould therefore strive to produce the most expected utterance, if they are to avoidunwanted implicatures.
It has been suggested that this position can be encapsulatedin a new high-level maxim:Spike Lee's MaximDo the right filing.
1Gricean maxims have been discussed in considerable detail; by analogy, we can scru-tinize the ideas underlying this "Spikean maxim," and the injunction to "do the rightthing."
The key question is whether we can make consistent sense of the notion of agenerator attempting to generate an "expected" utterance.2.
What's Right?So, let us equate generating expected utterances with doing the right thing; the failureto generate them counts as "doing the wrong thing," and leads to additional process-ing effort on the part of the hearer.
But what is the "right" thing?
What counts as"expected"?
Given Dale and Reiter's evidence, we can immediately concede that theshortest, most efficient description eed not be the most expected, and hence is notalways the right thing.
But is there any way of spelling out the injunction in moredetail?In fact, there are two ways of adding detail and both seem to be intended by Daleand Reiter; we may thus consider them Spikean submaxims:.2.Do the human thing.Do the simple thing.The first of these trades on the obvious fact that human language users are sensitive tothe conventional behavior of other human language users.
We learn those conventionsand, by generating in accord with them, produce the kinds of utterance expected underthe circumstances.
We thereby maximize our chances of being understood.
So, at anengineering level, the best thing for natural language ngineers to do is to buildsystems that emulate human behavior as faithfully as possible.The second submaxim is slightly less obvious, but should come as a relief for theengineers.
The right thing might after all be characterized asthe simplest output--solong as the simplicity lies in the algorithm that produced it, instead of in the relativecomplexity of the output string itself.
The nature of the algorithm is an empiricalmatter, and a good way of uncovering it is, of course, through observing humanbehavior.Indeed, according to Dale and Reiter, the psycholinguistic evidence on definitenoun phrases is that doing the human thing and doing the simple thing go hand1 The suggested formulation is Robert Frederking's, and it was proposed at the 1996 AAAI SpringSymposium on Computational Implicature, chaired by Barbara Di Eugenio and Nancy Green.
Thename of the maxim was settled by popular consensus, and is a reference to Spike Lee's 1989 film Do theRight Thing.
As we shall see, this maxim mainly provides a convenient label, bringing together themore detailed aims made by Dale and Reiter.502Oberlander Do the Right Thingin hand; people use a simple algorithm, which doesn't waste excessive resources oncomputing possible misinterpretations:The principle that has emerged from our study of the referring expressiongeneration task is that a simple and nonliteral interpretation f the Griceanmaxims is to be preferred... Perhaps it may some day be possible to make avery general statement such as "human speakers in general use very simple (incomputational terms) interpretations ofthe maxims of conversationalimplicature, and hence computer natural language generation systems shouldalso use such interpretations."
(p. 262)It is easy to see how one might be tempted to assume that the human thing is thesimple thing, and that this grounds out the notion of an expected utterance.
For onething, if speakers follow simple algorithms, then since most hearers are themselvesspeakers, they could conceivably predict speakers' behavior by unconsciously antic-ipating what they themselves would do.
But of course, this only stays simple--andavoids infinite recursion--so l ng as the predicted speaker behavior doesn't involveconsultation of a sophisticated model of the hearer.
However, a more convincing rea-son might lie in the conventional behavior of language communities.
In a communityof language users, if speakers follow simple algorithms, then simply generated ut-terances will provide the corpus of observed human language use from which anyconventions will arise, and from there guide future behavior.
The simple algorithmfor referring expressions could involve run-time computation of the set of predicatesto use, or it could involve selection from precompiled items in a phrasal exicon; buteither wan behavior in accord with the simple algorithm becomes what is expectedby other speakers.To summarize this position: human speakers can do the right thing, and henceobserve the Spikean maxim, by following simple algorithms.
Emulating human gen-eration behavior, via the use of a simple, empirically discovered algorithm, delivers asystem that generates the expected utterances.3.
What's Wrong with This?Unfortunately, this position might be plausible in the case of definite noun phrasegeneration, but it cannot be correct in general.
The difficulties hinge on the notionof expectation.
Dale and Reiter's argument relies on psycholinguistic findings on thegeneration of definites to help reveal what people regard as expected or unexpected.But there are other empirical results, concerning the generation and interpretation fpronouns, which do not fit into this picture.A good deal of work has been carried out on human behavior with respect othe processing of pronominal expressions.
In particular, one strand of research asexamined the psychological plausibility of Grosz, Joshi, and Weinstein's (1983, 1995)Centering Theory.
Hudson D'Zmura (1988), for instance, is one of several researchersto have shown that pronouns in subject position that specify the highest-ranked Cf(forward-looking center) of the preceding utterance are interpreted more rapidly thanrepeated names in subject position.
This is attributed to an expectancy effect becausethe subject position is the preferred site of the Cb (backward-looking center), which isnormally a pronoun specifying the highest ranked Cf.
A related strand of research, byStevenson and her collaborators (Stevenson, Crawle~ and Kleinman 1994; Stevensonand Urbanowicz 1995), connects this work on centering to other possible influenceson processing, including preferences concerning thematic roles (Dowty 1991), and theeffects of connective xpressions in multiclause sentences.503Computational Linguistics Volume 24, Number 3Stevenson and her collaborators have pursued two main types of empirical study:continuation tasks~ and reading time tasks.
In continuation tasks, a subject is typicallypresented with a sentence or sentence fragment, and asked to continue it.
When thefragment contains two sentences (or clauses), the first mentioning two entities, andthe second either empty, or containing merely an initial pronoun, the completions canbe categorized on the basis of which entity functions as antecedent, and the resultsanalyzed to reveal preferences for particular patterns of anaphoric reference.
In readingtime studies, a subject is presented with a complex sentence, or pair of sentences, andthe time they take to read it is measured and analyzed.Both types of study are highly relevant o the current issue.
Continuation studiesexamine the kinds of (written) utterances that people prefer to generate in given,carefully controlled contexts.
Reading time studies examine the relative ease withwhich people interpret he (written) utterances they are presented with in carefullycontrolled contexts.
So, on the one side, we would predict hat continuation preferenceswill reveal the output that speakers are most likely to generate in a given context; onthe other side, we would predict that reading times will reveal which inputs hearersexpect most strongly in a given context.
It is worth reiterating the latter point: a goodguide as to whether an utterance is expected or not is the amount of processing itgives rise to; certainly, Dale and Reiter are not alone in assuming that an unexpectedutterance will give rise to additional inferences on the part of its hearer.
In the case ofwritten text, the amount of processing is operationally detected by measuring readingtimes: unexpected sentence fragments in a given context will take longer to read thanexpected fragments in the same context.Now, Stevenson's own hypothesis i that preferences due to centering constraintsinteract with those due to the thematic roles of the entities referred to.
On this view,centering primarily influences how an entity introduced in one sentence will be re-ferred to in the next (by pronoun, or by name, for instance); thematic roles influencewhich entities will be subsequently referred to (the Agent, or the Patient, from thefirst sentence, for instance).
In particular, centering tells us to expect a pronoun insubject position to specify the highest ranked Cf from the previous sentence.
On theother hand, thematic role information tells us to expect hat the subject of the currentsentence is more likely to specify an entity associated with the consequences of theevent introduced in the previous sentence; thus, if the verb in the previous sentenceintroduced roles for Goal and Source, then the subject of the current sentence is mostlikely to be the Goal from the previous entence.To illustrate, analysis of continuation data confirms that people prefer to use apronoun to refer to the entity in initial position and to use a repeated name for theentity in second position.
This effect is independent of who gets referred to, whichdepends on the thematic role of each referent.
Compare examples (1) and (2):(1)(2)John gave the book to Bill and ...Bill took the book from John and ...People continue the fragment with a pronoun when they want to refer to John in (1)and Bill in (2), but they are more likely to repeat he name when they want to refer toBill in (1) and John in (2).
This is despite the fact that in both sentences Bill (the Goal)is the person they are most likely to refer to.Now, there are some very interesting apparent discrepancies between certain re-sults from the continuation studies and the reading time studies.
Take an example ofthe form in (3).
Look at four variants, all using the connective so:504Oberlander Do the Right Thing(3) a. John gave the book to Bill so he ... \[he = John\]b. John gave the book to Bill so John ...c. John gave the book to Bill so he ... \[he = Bill\]d. John gave the book to Bill so Bill ...First, consider the results of continuation studies for such examples; the evidence hereis from Stevenson, Crawley and Kleinman's (1994) third experiment, he results ofwhich confirm the findings from two other continuation experiments reported there.The materials contained three initial fragment types: goal-source; xperiencer-stimulus;and agent-patient.
Each fragment ended in a connective.
The design manipulated twofactors: order of thematic roles in the initial fragment (for instance, source-goaL as in(3a), or goal-source); and connective (so versus because).It was found that, if a person generated the pronoun he as the first word in theircontinuation, it was almost always used to refer to John (pp.
537-39).
It seems that theeffects of centering swamp the effects of thematic role--the generator here prefers towrite about John.
Thus, (a)-type continuations would be preferred to (c)-type contin-uations.Now, compare the results of reading time studies for such examples; the evidencehere is from Stevenson and Urbanowicz (1995).
The materials consisted of two-clausesentences, uch as (4):(4) Malcolm won some money from Stuart because he was very good atpoker.Each sentence was presented a clause at a time, followed by a comprehension ques-tion, which probed the correct resolution of any anaphor that appeared.
The designmanipulated four factors: type of anaphor in second clause (pronoun, such as he, ver-sus repeated name, such as Malcolm); order of thematic roles in the initial fragment(source-goal versus goal-source); connective (so versus because); and antecedent (Goalor Source).It was found that, when encountered, (c)-type sentences were read significantlyfaster than (a)-type sentences (p. 331).
That is, with so and he, complex sentences wherethe antecedent is the Goal-in-second-position prove faster to read than those in whichthe antecedent is Source-in-initial-position.
It seems that effects of thematic role winout--the interpreter expects to read about Bill.Bringing the results of these studies together, there is an apparent asymmetrybetween interpretive and generative behavior.
At a thematic level, both generatorsand interpreters prefer to talk about goals, and so (c)-type and (d)-type sentencesare most likely to be generated, and are most expected by interpreters.
However, atthe syntactic realization level, generators will only rarely produce (c)-type utterances.Given a fragment ending with so, a generator that next outputs he will usually goon to produce an (a)-type sentence.
Yet, given that reading time is an indication ofexpectedness, it seems that, on the contrar~ (c)-type sentences are more expected, andeasier to process, than (a)-types.To put it another way, given a certain type of prior context, generators will sys-tematically fail to produce the utterance that is easiest o process.
And to put it yetanother way, this is evidence against the hypothesis that people do the right thing, inthe sense of generating the most expected utterance.In fact, this body of evidence simultaneously undermines the idea that the out-put of a simple, highly plausible algorithm will be what is most expected, and the505Computational Linguistics Volume 24, Number 3idea that the emulation of human behavior will invariably produce the most expectedutterances.
The first idea falls because a simple centering-based generator would in-variably generate (a)-type continuations--and these are less expected than (c)-typecontinuations.
Now, it could be suggested that we replace the simple centering al-gorithm with one that also includes thematic role preferences.
Unfortunately, even ifthis algorithm correctly emulates human behavior, it will still generate (a)-type con-tinuations in preference to (c)-types--because that is what people do, too.
And forthis reason, the second idea also falls: emulating human behavior here cannot hope toproduce the most expected utterances, for the good reason that people don't producethe most expected utterances in the first place.To summarize this argument: if you emulate human behavior, you must--as amatter of course--expect to generate unexpected utterances.
Thus, if doing the rightthing is doing the simple thing, or even just doing the human thing, it is here doomedto fail to generate the expected utterance.4.
Expect the UnexpectedNow, how serious is this problem for Dale and Reiter?
If a psycholinguistically inspiredalgorithm for pronoun generation leads us to expect unexpected output, should weconclude that doing the right thing--the human thing, the simple thing--will alwaysget the wrong results?Obviously not.
Dale and Reiter's algorithm was for generating definite nounphrases, not pronouns.
It might be thought that by comparing continuation andreading time studies on definites, we could undermine their position more directly.However, there is a sense in which this would be immaterial; their algorithm clearlyachieves reasonable output much of the time.
Thus, it is tempting to conclude thatSpike Lee's maxim simply has limited applicability: people (and machines) should dothe right thing, but only on some---not all--generation tasks.However, this does not seem quite right, either.
Rather, the key lesson from thework on pronoun generation and interpretation is that we must develop amore sophis-ticated view of "expectation."
In all the examples like (3), Bill is the person a generatoris expected to talk about--and for whom a pronoun would thus make good sense--but this thematically based expectation must be played off against he centering-basedexpectation; there are multiple factors underlying any expectation.
The existence ofsuch multiple factors is the fundamental reason why speakers can always be put intoa context in which they will generate utterances they themselves find relatively hardto interpret.
The existence of multiple factors also carries a more general lesson forcomputational linguists.
If we hope to trade in psycholinguistic findings for new al-gorithms, we must resist the temptation to be overly selective concerning the resultswe pick on.
2Thus, Dale and Reiter could be strategically correct: careful study of human gen-erative behavior may well reveal that it is less complex than we have come to believe,and that emulating this simple behavior is the right policy in general.
Doing the rightthing, emulating human performance is generally better than slavishly following literalinterpretations of the maxims.Nonetheless, it remains true that, because there are multiple factors underlyingany expectation, a human-inspired algorithm for generating the expected utterancecan in fact produce unexpected utterances.
However simple or complex the algorithm2 This paper has itself obviously been selective; but it is not intended to be perniciously so.506Oberlander Do the Right Thingfor choosing what to talk about next, and how to refer to it, people will still say thingsthey would find surprising.
Human performance thus embraces a mild paradox, whichmeans that even the best emulator will always generate unexpected utterances, whichviolate Spike Lee's maxim, and cause unwanted implicatures.Some would argue that the semblance of paradox is simply evidence that thereare limits to the experimental paradigm.
That there are such limits is not in doubt.But there remains omething odd about the fact that not only would I myself gener-ate the unexpected utterance, but everyone lse would too.
Thus, over time, I reallyshould come to expect his unexpected utterance---and it should therefore stop beingunexpected.
Perhaps I am exposed to too few instances of the paradoxical behaviorin my lifetime to become attuned to it, but the language community as a whole hasalready had plenty of time to adjust its expectations.
It has not done so: the asymmetryin behavior appears to be stable.
Thus, individual language users will continue to besurprised by the behavior of their language community.
By contrast, researchers innatural language generation should not be surprised at such asymmetries in behavior.Once we understand better both the behavior, and the interplay of expectations whichunderlies it, analysts and engineers alike will know exactly when they should expectthe unexpected.AcknowledgmentsThe support of the Economic and SocialResearch Council for HCRC is gratefullyacknowledged.
The author is supported byan EPSRC Advanced Fellowship.
This paperwas inspired by discussions withparticipants at the AAAI Spring Symposiumon Computational Implicature, held atStanford, in March 1996; my thanks also toRosemary Stevenson and Keith Stenning,and to the paper's anonymous reviewers,for very helpful comments.ReferencesDale, Robert.
1992.
Generating ReferringExpressions: Building Descriptions inaDomain of Objects and Processes.
MIT Press,Cambridge, MA.Dale, Robert and Ehud Reiter.
1995.Computational interpretations of theGricean maxims in the generation ofreferring expressions.
Cognitive Science, 19:233-263.Dowty, David R. 1991.
Thematic proto-rolesand argument selection.
Language, 67:547-619.Grice, H. Paul.
1989.
Studies in the Way ofWords.
Harvard University Press,Cambridge, MA.Grosz, Barbara J., Aravind K. Joshi, andScott Weinstein.
1983.
Providing a unifiedaccount of definite noun phrases indiscourse.
In Proceedings ofthe 21st AnnualMeeting, pages 44-50.
Association forComputational Linguistics.Grosz, Barbara J., Aravind K. Joshi, andScott Weinstein.
1995.
Centering: Aframework for modeling the localcoherence ofdiscourse.
ComputationalLinguistics, 21: 202-225.Hudson D'Zmura, Susan B.
1988.
TheStructure of Discourse and AnaphorResolution: The Discourse Center and theRoles of Nouns and Pronouns.
Ph.D. thesis,University of Rochester.Joshi, Aravind K. 1982.
Mutual beliefs inquestion answering systems.
In NeilsonV.
Smith, editor, Mutual Knowledge.Academic Press, New York.Levelt, William.
1989.
Speaking: FromIntention to Articulation.
MIT Press,Cambridge, MA.Reiter, Ehud.
1990.
The computationalcomplexity of avoiding unwantedcomputational implicatures.
In Proceedingsof the 28th Annual Meeting, pages 97-104.Association for ComputationalLinguistics.Stevenson, Rosemary J., Rosalind A.Crawle~ and David Kleinman.
1994.Thematic roles, focus and therepresentation f events.
Language andCognitive Processes, 9:519-548.Stevenson, Rosemary J. and Agnieszka J.Urbanowicz.
1995.
Structural focusing,,thematic role focusing and thecomprehension f pronouns.
InProceedings ofthe 17th Annual Conference ofthe Cognitive Science Society, pages 328-332.507
