Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 651?656,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsAdding High-Precision Links to WikipediaThanapon Noraset Chandra Bhagavatula Doug DowneyDepartment of Electrical Engineering & Computer ScienceNorthwestern UniversityEvanston, IL 60208{nor|csbhagav}@u.northwestern.edu, ddowney@eecs.northwestern.eduAbstractWikipedia?s link structure is a valuableresource for natural language processingtasks, but only a fraction of the conceptsmentioned in each article are annotatedwith hyperlinks.
In this paper, we studyhow to augment Wikipedia with additionalhigh-precision links.
We present 3W, asystem that identifies concept mentions inWikipedia text, and links each mentionto its referent page.
3W leveragesrich semantic information present inWikipedia to achieve high precision.
Ourexperiments demonstrate that 3W can addan average of seven new links to eachWikipedia article, at a precision of 0.98.1 IntroductionWikipedia forms a valuable resource formany Natural Language Processing andInformation Extraction tasks, such as EntityLinking (Cucerzan, 2007; Han and Zhao,2009), Ontology Construction (Wu and Weld,2008; Syed et al., 2008) and Knowledge BasePopulation (Hoffart et al., 2013; Lehmann et al.,2013).
Wikipedia?s links provide disambiguatedsemantic information.
For example, when asystem processes the text ?Chicago was receivedwith critical acclaim?
from an article, the systemdoes not need to infer the referent entity of?Chicago?
if the word is already hyperlinked tothe Wikipedia page of the Oscar-winning film.Unfortunately, in Wikipedia only a fraction of thephrases that can be linked are in fact annotatedwith a hyperlink.
This is due to Wikipedia?sconventions of only linking to each concept once,and only when the links have a certain level ofutility for human readers.1We see this as an1http://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style_(linking)opportunity to improve Wikipedia as a resourcefor NLP systems.
Our experiments estimate thatas of September 2013, there were an average of30 references to Wikipedia concepts left unlinkedwithin each of English Wikipedia?s four millionpages.In this paper, our goal is to augment Wikipediawith additional high-precision links, in orderto provide a new resource for systems thatuse Wikipedia?s link structure as a foundation.Identifying references to concepts (calledmentions) in text and linking them to Wikipediais a task known as Wikification.
Wikification forgeneral text has been addressed in a wide varietyof recent work (Mihalcea and Csomai, 2007;Milne and Witten, 2008b; McNamee and Dang,2009; Ratinov et al., 2011).
The major challengeof this task is to resolve the ambiguity of phrases,and recent work makes use of various kinds ofinformation found in the document to tacklethe challenge.
In contrast to this body of work,here we focus on the special case of WikifyingWikipedia articles, instead of general documents.This gives us an advantage over general-textsystems due to Wikipedia?s rich content andexisting link structure.We introduce 3W, a system that identifiesmentions within Wikipedia and links eachto its referent concept.
We show how aWikipedia-specific Semantic Relatedness measurethat leverages the link structure of Wikipedia(Milne and Witten, 2008b) allows 3W to beradically more precise at high levels of yield whencompared to baseline Wikifiers that target generaltext.
Our experiment shows that 3W can add onaverage seven new links per article at precision of0.98, adding approximately 28 million new linksto 4 million articles across English Wikipedia.22http://websail.cs.northwestern.edu/projects/3W6512 Problem DefinitionIn this section, we define our link extraction task.A link l is a pair of a surface form sland aconcept tl.
A surface form is a span of tokensin an article, and the concept is a Wikipediaarticle referred to by the surface form.
Forexisting hyperlinks, the surface form correspondsto the anchor text and the concept is the linktarget.
For example, a hyperlink [[Chicago City| Chicago]] has surface form ?Chicago City?
andreferent concept Chicago.3Given documentsD ={d1, ..., d|D|} and a set of links L = {l1, .., l|L|} ?D, our goal is to generate a set of high-precisionlinks L?for D, distinct from L. In this paper, thedocument set D consists of articles from EnglishWikipedia, and L is the set of existing links onWikipedia.The task can be divided into 3 steps.
The firststep is to extract a set of potential mentionsM ={m1, ..,m|M|} where m is, similar to l, a pair ofsurface form smand a set of candidate conceptsC(m) = {t1, ..., t|C(m)|}.
For m having |C(m)| >1, we need to disambiguate it by selecting onlyone target concept tm?
C(m).
Since the correctconcept may not exist in C(m) and the previousstep could output an incorrect concept, the finalstep is to decide whether to link and include m inL?.
We describe the details of these steps in thefollowing section.3 System OverviewIn this section, we describe in detail how 3W addshigh-precision links to Wikipedia.3.1 Mention ExtractionIn this step, we are given a document d, andthe goal is to output a set of mentions M. Oursystem finds a set of potential surface forms, sm,by finding substrings in d that match the surfaceform of some links in L. For example, from thephrase ?map of the United States on the wall?,we can match 4 potential surface forms: ?map?,?United States?, ?map of the United States?, and?wall?.
Notice that some of them are overlapping.The system selects a non-overlapping subset of thesurface forms that maximizes the following scorefunction:Score(M) =?m?MT (sm)PL(sm)|C(m)|(1)3http://en.wikipedia.org/wiki/Chicagowhere PL(sm) is the probability that the text smis linked (that is, the fraction of the occurrences ofthe string smin the corpus that are hyperlinked),T (sm) is the number of tokens in sm, and |C(m)|is the number of candidate concepts.
Intuitively,we prefer a longer surface form that is frequentlylinked and has a specific meaning.
Furthermore,we eliminate common surface forms (i.e.
?wall?
)by requiring that PL(sm) exceed a threshold.
Inthe previous example, we are left with only ?mapof the United States?.Because Wikipedia?s concepts are largely nounphrases, 3W only looks for surface forms fromtop-level noun phrases generated by the StanfordParser (Socher et al., 2013).
In addition, eachname entity (NE) (Finkel et al., 2005) is treatedas an atomic token, meaning that multi-word NEssuch as ?California Institute of the Arts?
will notbe broken into multiple surface forms.Finally, the system pairs the result surface formswith a set of candidate concepts, C(m), andoutputs a set of mentions.
C(m) consists of thoseconcepts previously linked to the surface form inL.
For instance, the surface form ?map of theUnited States?
has been linked to three distinctconcepts in English Wikipedia.3.2 DisambiguationGiven a set of mentions M from the previousstep, The next step is to select a concept t ?C(m) for each m ?
M. We take the commonapproach of ranking the candidate concepts.3W uses a machine learning model to performpair-wise ranking of t ?
C(m) and select thetop-ranked candidate concept.
We refer to 3W?sdisambiguation component as the ranker.
Theranker requires a feature vector for each candidateconcept of a mention.
The rest of this sectiondescribes the features utilized by the ranker.
Thefirst two feature groups are commonly used inWikification systems.
The third feature group isspecifically designed for mentions in Wikipediaarticles.3.2.1 Prior Probability FeaturesThe conditional probability of a concept t givenmention surface sm, P (t|sm), is a commonfeature used for disambiguation.
It formsa very strong Wikification baseline (?
86%in micro-accuracy).
This probability can beestimated using Wikipedia links (L).
Inaddition, we use the external partition of the652Google ?Cross-Lingual Dictionary?
described in(Spitkovsky and Chang, 2012) to get the estimatesfor the probability from links outside Wikipedia.3.2.2 Lexical FeaturesTo make use of text around a mention m,we create bag-of-word vectors of the mention?ssource document d(m), and of a set of wordssurrounding the mention, referred to as the contextc(m).
To compare with a concept, we alsocreate bag-of-word vectors of candidate concept?sdocument d(t) and candidate concept?s contextc(t).
We then compute cosine similarities betweenthe mention?s vectors for d(m) and c(m), withthe concept candidate vectors for d(t) and c(t) asin the Illinois Wikifier (Ratinov et al., 2011).
Inaddition to similarities computed over the top-200words (utilized in the Illinois Wikifier), we alsocompute similarity features over vectors of allwords.3.2.3 Wikipedia-specific FeaturesBecause the links in an article are often relatedto one another, the existing links in a documentform valuable clues for disambiguating mentionsin the document.
For each concept candidatet ?
C(m), we compute a Semantic Relatedness(SR) measure between t and each concept fromexisting links in the source document.
Our SRmeasure is based on the proportion of sharedinlinks, as introduced by Milne and Witten(2008b).
However, because Milne and Wittenwere focused on general text, they computed SRonly between t and the unambiguous mentions(i.e.
those m with |C(m)| = 1) identifiedin the document.
In our work, d(m) is aWikipedia article which is rich in existing linksto Wikipedia concepts, and we can computeSR with all of them, resulting in a valuablefeature for disambiguation as illustrated in ourexperiments.
We use the SR implementation ofHecht et al.
(2012).
It is a modified version ofMilne and Witten?s measure that emphasizes linksin Wikipedia article?s overview.
In addition, weadd boolean features indicating whether smor thas already been linked in a document.3.2.4 RerankingThe millions of existing Wikipedia links in L forma valuable source of training examples for ourranker.
However, simply training on the linksin L may result in poor performance, becausethose links exhibit systematic differences from thementions inM that the ranker will be applied to.The reason is that our mention extractor attemptsto populate M with all mentions, whereasL which contains only the specific subset ofmentions that meet the hyperlinking conventionsof Wikipedia, As a result, the features for Mare distributed differently from those in L, and amodel trained on L may not might not performwell on M. Our strategy is to leverage L totrain an initial ranker, and then hand-label a smallset of mentions from M to train a second-stagere-ranker that takes the ranking output of theinitial ranker as a feature.3.3 LinkerOur linker is a binary classifier that decideswhether to include (link) each mention in Mto the final output L?.
Previous work hastypically used a linker to determine so-called NILmentions, where the referred-to concept is notin the target knowledge base (e.g., in the TACKBP competition, half of the given mentions areNIL (Ji and Grishman, 2011)).
The purposeof our linker is slightly different, because wealso use a linker to control the precision of ouroutput.
We use a probabilistic linker that predictsa confidence estimate that the mention with itstop-ranked candidate is correct.
Our linker usesthe same features as the ranker and an additionalset of confidence signals: the number of times thetop candidate concept appears in L, and the scoredifference between the top-ranked candidate andthe second-ranked candidate.4 Experiments and ResultIn this section, we provide an evaluation of oursystem and its subcomponents.4.1 Experiment SetupWe trained our initial ranker models from 100,000randomly selected existing links (L).
These linkswere excluded when building feature values (i.e.the prior probability, or Semantic Relatedness).We formed an evaluation set of new links byapplying our mention extractor to 2,000 randomlyselected articles, and then manually labeling 1,900of the mentions with either the correct conceptor ?no correct concept.?
We trained and testedour system on the evaluation set, using 10-foldcross validation.
For each fold, we partitioned data653Model Acc Prec Recall F1Prior 0.876 0.891 0.850 0.870OnlyWikiLink?Wiki0.896 0.905 0.871 0.888OnlyWikiLink 0.944 0.950 0.920 0.935Table 1: 10-fold cross validation performance of the initialrankers by Accuracy (excluded ?-candidate mentions), BOTPrecision, BOT Recall, BOT F1 on the 100,000 existing links.into 3 parts.
We used 760 mentions for trainingthe final ranker.
The linker was trained with 950mentions and we tested our system using the other190 mentions.
Previous work has used various MLapproaches for ranking, such as SVMs (Dredze etal., 2010).
We found logistic regression producessimilar accuracy to SVMs, but is faster for ourfeature set.
For the linker, we use an SVM withprobabilistic output (Wu et al., 2004; Chang andLin, 2011) to estimate a confidence score for eachoutput link.4.2 ResultWe first evaluate 3W?s mention extraction.
Fromthe selected 2, 000 articles, the system extracted59, 454 mentions (?30/article), in addition tothe original 54, 309 links (?27/article).
Fromthe 1, 900 hand-labeled mentions, 1, 530 (80.5%)were solvable in that 3W candidate set containedthe correct target.As described in section 3.2.4, 3W employsa 2-stage ranker.
We first evaluate just theinitial ranker, using 10-fold cross validationon 100,000 existing links.
We show microaccuracy and bag-of-title (BOT) performanceused by Milne and Witten (2008b) in Table1.
The ranker with all features (OnlyWikiLink)outperforms the ranker without Wikipedia-specificfeatures (OnlyWikiLink?Wiki) by approximatelyfive points in F1.
This demonstrates thatWikipedia?s rich semantic content is helpful fordisambiguation.Next, we evaluate our full system performance(disambiguation and linking) over thehand-labeled evaluation set.
We experimentedwith different configurations of the rankers andlinkers.
Our Baseline system disambiguatesa mention m by selecting the most commonconcept for the surface s(m).
OnlyWikiLinkuses the ranker model trained on only Wikipedialinks, ignoring the labeled mentions.
3W is oursystem using all features described in section 3.2,Model Acc Yield %YieldBaseline 0.828 5 0.33%OnlyWikiLink 0.705 150 9.80%3W?Wiki 0.868 253 16.54%3W 0.877 365 23.86%Table 2: 10-fold cross validation performance of the systemover 1,900 labeled mentions.
Acc is disambiguation accuracyof solvable mentions.
Yield is the number of output newmentions at precision ?
0.98, and %Yield is the percentageof Yield over the solvable mentions (recall).0 0.2 0.4 0.6 0.8 10.50.60.70.80.91RecallPrecisionPrecision Recall ComparisonsBaselineOnlyWikiLinks3W?Wiki3WFigure 1: Plot between Precision and Recall of systems on1,900 mentions from 10-fold cross validation.and 3W?Wiki is 3W without Wikipedia-specificfeatures.
The last two configurations are trainedusing the labeled mentions.Table 2 shows the disambiguation accuracy ofeach system over the solvable mentions.
Our finalsystem, 3W, has the best disambiguation accuracy.To evaluate the linking performance, we selectthe confidence threshold such that the systemoutputs mentions with precision of ?
0.98.
Thethird column in Table 2 shows the yield, i.e.
thenumber of mentions output at precision 0.98.
3Woutputs the largest number of new links (365).Nearly half (157) are new concepts that have notbeen linked in the source article.
We find that theRerank feature helps increase recall: without it,the yield of 3W drops by 27%.
Using %Yield,we estimate that 3W will output 14, 000 new linksfor the selected 2, 000 articles (?7/article), andapproximately 28 million new links across the 4million articles of English Wikipedia.Adjusting the confidence threshold allowsthe system to trade off precision and recall.Figure 1 shows a precision and recall curve.3W and OnlyWikiLink are comparable for654many high-precision points, but below 0.95OnlyWikiLink?s precision drops quickly.
Plotsthat finish at higher rightmost points in the graphindicate systems that achieve higher accuracy onthe complete evaluation set.5 Conclusions and Future WorkWe presented 3W, a system that addshigh-precision links to Wikipedia.
Whereasmany Wikification systems focus on general text,3W is specialized toward Wikipedia articles.We showed that leveraging the link structure ofWikipedia provides advantages in disambiguation.In experiments, 3W was shown to Wikipedia with?7 new links per article (an estimated 28m across4 million Wikipedia articles) at high precision.AcknowledgmentsThis work was supported in part by DARPAcontract D11AP00268 and the Allen Institute forArtificial Intelligence.ReferencesChih-Chung Chang and Chih-Jen Lin.
2011.LIBSVM: A library for support vector machines.ACM Transactions on Intelligent Systems andTechnology, 2:27:1?27:27.
Software available athttp://www.csie.ntu.edu.tw/?cjlin/libsvm.Silviu Cucerzan.
2007.
Large-scale namedentity disambiguation based on Wikipedia data.In Proceedings of EMNLP-CoNLL 2007, pages708?716.Mark Dredze, Paul McNamee, Delip Rao, AdamGerber, and Tim Finin.
2010.
Entitydisambiguation for knowledge base population.
InProceedings of the 23rd International Conferenceon Computational Linguistics, pages 277?285.Association for Computational Linguistics.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-localinformation into information extraction systemsby gibbs sampling.
In Proceedings of the 43rdAnnual Meeting on Association for ComputationalLinguistics, pages 363?370.
Association forComputational Linguistics.Xianpei Han and Jun Zhao.
2009.
Namedentity disambiguation by leveraging wikipediasemantic knowledge.
In Proceedings of the 18thACM conference on Information and knowledgemanagement, pages 215?224.
ACM.Brent Hecht, Samuel H Carton, Mahmood Quaderi,Johannes Sch?oning, Martin Raubal, Darren Gergle,and Doug Downey.
2012.
Explanatorysemantic relatedness and explicit spatialization forexploratory search.
In Proceedings of the 35thinternational ACM SIGIR conference on Researchand development in information retrieval, pages415?424.
ACM.Johannes Hoffart, Fabian M Suchanek, KlausBerberich, and Gerhard Weikum.
2013.
Yago2: Aspatially and temporally enhanced knowledge basefrom wikipedia.
Artificial Intelligence, 194:28?61.Heng Ji and Ralph Grishman.
2011.
Knowledgebase population: Successful approaches andchallenges.
In Proceedings of the 49th AnnualMeeting of the Association for ComputationalLinguistics: Human Language Technologies-Volume1, pages 1148?1158.
Association for ComputationalLinguistics.Jens Lehmann, Robert Isele, Max Jakob, AnjaJentzsch, Dimitris Kontokostas, Pablo N Mendes,Sebastian Hellmann, Mohamed Morsey, Patrick vanKleef, S?oren Auer, et al.
2013.
Dbpedia-alarge-scale, multilingual knowledge base extractedfrom wikipedia.
Semantic Web Journal.Paul McNamee and Hoa Trang Dang.
2009.
Overviewof the tac 2009 knowledge base population track.
InText Analysis Conference (TAC), volume 17, pages111?113.Rada Mihalcea and Andras Csomai.
2007.
Wikify!
:linking documents to encyclopedic knowledge.In Proceedings of the sixteenth ACM conferenceon Conference on information and knowledgemanagement, pages 233?242.
ACM.David Milne and Ian H Witten.
2008b.
Learning tolink with wikipedia.
In Proceedings of the 17thACM conference on Information and knowledgemanagement, pages 509?518.
ACM.Lev Ratinov, Dan Roth, Doug Downey, and MikeAnderson.
2011.
Local and global algorithms fordisambiguation to wikipedia.
In ACL.Richard Socher, John Bauer, Christopher D Manning,and Andrew Y Ng.
2013.
Parsing withcompositional vector grammars.
In In Proceedingsof the ACL conference.
Citeseer.Valentin I. Spitkovsky and Angel X. Chang.
2012.A cross-lingual dictionary for english wikipediaconcepts.
In Nicoletta Calzolari (Conference Chair),Khalid Choukri, Thierry Declerck, Mehmet UurDoan, Bente Maegaard, Joseph Mariani, Jan Odijk,and Stelios Piperidis, editors, Proceedings ofthe Eight International Conference on LanguageResources and Evaluation (LREC?12), Istanbul,Turkey, may.
European Language ResourcesAssociation (ELRA).655Zareen Saba Syed, Tim Finin, and Anupam Joshi.2008.
Wikipedia as an ontology for describingdocuments.
In ICWSM.Fei Wu and Daniel S Weld.
2008.
Automaticallyrefining the wikipedia infobox ontology.
InProceedings of the 17th international conference onWorld Wide Web, pages 635?644.
ACM.Ting-Fan Wu, Chih-Jen Lin, and Ruby C Weng.
2004.Probability estimates for multi-class classificationby pairwise coupling.
Journal of Machine LearningResearch, 5(975-1005):4.656
