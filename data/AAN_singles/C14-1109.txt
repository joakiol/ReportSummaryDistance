Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1154?1164, Dublin, Ireland, August 23-29 2014.Automatic Corpus Expansion for Chinese Word Segmentationby Exploiting the Redundancy of Web InformationXipeng Qiu, ChaoChao Huang and Xuanjing HuangShanghai Key Laboratory of Intelligent Information ProcessingSchool of Computer Science, Fudan University, Shanghai, Chinaxpqiu@fudan.edu.cn, superhuang007@gmail.com, xjhuang@fudan.edu.cnAbstractCurrently most of state-of-the-art methods for Chinese word segmentation (CWS) arebased on supervised learning, which depend on large scale annotated corpus.
However,these supervised methods do not work well when we deal with a new different domainwithout enough annotated corpus.
In this paper, we propose a method to automaticallyexpand the training corpus for the out-of-domain texts by exploiting the redundant in-formation on Web.
We break up a complex and uncertain segmentation by resorting toWeb for an ample supply of relevant easy-to-segment sentences.
Then we can pick outsome reliable segmented sentences and add them to corpus.
With the augmented corpus,we can re-train a better segmenter to resolve the original complex segmentation.
Theexperimental results show that our approach can more effectively and stably improve theperformance of CWS.
Our method also provides a new viewpoint to enhance the perfor-mance of CWS by automatically expanding corpus rather than developing complicatedalgorithms or features.1 IntroductionWord segmentation is a fundamental task for Chinese language processing.
In recent years,Chinese word segmentation (CWS) has undergone great development.
The popular method isto regard word segmentation as a sequence labeling problems (Xue, 2003; Peng et al., 2004).The goal of sequence labeling is to assign labels to all elements in a sequence, which can behandled with supervised learning algorithms, such as Maximum Entropy (ME) (Berger et al.,1996), Conditional Random Fields (CRF)(Lafferty et al., 2001).After years of intensive researches, Chinese word segmentation achieves a quite high precision.However, the performance of segmentation is not so satisfying for the practical demands toanalyze Chinese texts.
The key reason is that most of annotated corpora are drawn from newstexts.
Therefore, the system trained on these corpora cannot work well with the out-of-domaintexts.Since these supervised approaches often has a high requirement on the quality and quantity ofannotated corpus, which is always not easy to create.
As a result, many methods were proposedto utilize the information of unlabeled data.There are three kinds of methods for domain adaptation problem in CWS.The first is to use unsupervised learning algorithm to segment texts, like branching entropy(BE) (Jin and Tanaka-Ishii, 2006), normalized variation of branching entropy (nVBE)(Magistryand Sagot, 2012).This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers andproceedings footer are added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1154The second is to use unsupervised or domain-independent features in supervised learning forChinese word segmentation, such as punctuation and mutual information(MI), word accessoryvariance (Feng et al., 2004; Zhao and Kit, 2008; Sun and Xu, 2011)The third is to use semi-supervised learning (Zhu, 2005) in sequence labeling to address thedifference in source and target distributions (Jiao et al., 2006; Altun et al., 2006; Suzuki andIsozaki, 2008).Although these methods improve the performance of out-of-domain texts, the performance isstill worse than that of in-domain texts obviously.We firstly investigate the reasons of lower performance in new domain for state-of-the-artCWS systems and find that most of error segmentation were caused by out-of-vocabulary (OOV)words, also called new words or unknown words (see details in Section 3).
It is difficult to devoteefforts to building a corpus for out-of-domain texts, since new words are produced frequently asthe development of the society, especially the Internet society.
It is also impractical to manuallymaintain an up-to-date corpus to include all geographical names, person names, organizationnames, technical terms, etc.In this paper, we propose a method to automatically expand the training corpus for the out-of-domain texts by exploiting the redundant information on Web.
When we meet a complexand potentially difficult-to-segment sentence, we do not expect to solve it with more complicatedlearning algorithm or elaborate features.
We assume that there are some relevant sentences thatare relatively easy to process.
These simple sentences can help to solve the complex one.For example, the sentence ???????
(L?Oreal, Maybelline)?is difficult to segment ifboth ????
(L?Oreal)?and ????
(Maybelline)?are unknown words.
However, we canalways find some easy-to-segment sentences, such as???????
(I use Maybelline)?,???????
(production of L?Oreal)?, and so on.
When we use these simple sentences to re-trainthe segmenter, we can solve the previous complex sentence.Our method relies on breaking up the complex problems into relevant smaller, simpler prob-lems that can be solved easily.
Fortunately, we can resort to the scale and redundancy of theweb for an ample supply of simple sentences that are relatively easy to process.Our method is very easy to implement upon a trainable base segmenter.
Given the out-of-domain texts, we firstly choose some uncertain segmentations and select the candidate expansionseeds.
Secondly, we use these seeds to get the relevant texts from Web search engine.
Then wesegment these texts and add the texts with high confidence to training corpus.
Finally, we canget a better segmenter with the new corpus.The rest of the paper is organized as follows: we review the related works in section 2.
Insection 3, we analyze the influence factor for CWS.
Then we describe our method in section 4.Section 5 introduces the base segmenter.
Section 6 gives the experimental results.
Finally weconclude our work in section 7.2 Related WorksThe idea of exploring information redundancy on Web was introduced in question answeringsystem (Kwok et al., 2001; Clarke et al., 2001; Banko et al., 2002) and the famous informationextraction system KNOWITALL(Etzioni et al., 2004).
However, this idea is rarely mentionedin Chinese word segmentation.Nonetheless, there are three kinds of related methods on Chinese word segmentation.One is active learning.
Both (Li et al., 2012) and (Sassano, 2002) try to use active learningmethod to expand annotated corpus, but they still need to manually label some new raw textsin order to enlarge the training corpus.
Different with these methods, our method do not requireany manual oracle labeling at all.Another is self-training, also called bootstrapping or self-teaching (Zhu, 2005).
Self-trainingis a general semi-supervised learning approach.
In self-training, a classifier is first trained withthe small amount of labeled data.
The classifier is then used to classify the unlabeled data.11550.70.750.80.850.90.9510 1 2 3 4 5F1Number of Continuous OOV Words(a) Number of continuous OOVwords0.100.200.300.400.500.600.700.800.901.000 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.6 0.7 1F1OOV Rate(b) OOV rate0.100.200.300.400.500.600.700.800.901.001 2 3 4 5 6 7 8 9 10F1Word Length(c) Word LengthThe blue horizontal line is the overall F1 score, and the red line is the F1 scores with different values of thefactor.Figure 1: Analysis of Influence FactorsTypically the most confident unlabeled points, together with their predicted labels, are addedto the training set.
The classifier is re-trained and the procedure repeated.
Note that theclassifier uses its own predictions to teach itself.
Self-training has been applied to several naturallanguage processing (NLP) tasks, such as word sense disambiguation (Yarowsky, 1995), POS-tagging (Clark et al., 2003; Jiang and Zhai, 2007; Liu and Zhang, 2012), parsing (Steedmanet al., 2003; McClosky et al., 2006; Reichart and Rappoport, 2007; Sagae, 2010), informationextraction(Etzioni et al., 2004)and so on.
It has been proven that self-training can improvesystem performance on the target domain by simultaneously modeling annotated source-domaindata and unannotated target domain data in the training process.
However, the data on targetdomain cannot always help itself (Steedman et al., 2003).The third is weakly supervised learning.
(Li and Sun, 2009; Jiang et al., 2013) utilized themassive manual natural annotations or punctuation information on the Internet to improve theperformance of CWS.
However, these natural annotations are just partial annotations and theirroles depend on the qualities of the selected resource, such as Wikipedia.In this paper, we wish to propose a method to obtain new fully-annotated data in moreaggressive way, which can combine the advantages of the above works.3 Analysis of Influence Factors for CWSBefore describing our method, we give an analysis of the impact of out-of-vocabulary (OOV)words for segmentation.
We first conduct experiments on the Chinese Treebank (CTB6.0)dataset (Xue et al., 2005) (The detailed information of dataset is shown in Section 6).Table 1 shows the performance of base segmenter.
The F1 score of OOV words is significantlylower than that of in-vocabulary (INV) words.Precision Recall F1INV 95.86 96.58 96.21OOV 74.12 66.77 70.25Total 94.64 94.73 94.69Table 1: Performances of INV and OOV wordsWe also investigate the impacts of three different factors: number of continuous OOV words,OOV rate and word length.
Figure 1 shows the F1 scores with the changes of the differentfactors.
We find that OOV words significantly improve the difficulty of segmentation, while theword length does not always harm the accuracy.These findings also indicate that we can improve the performance of CWS if we have adictionary or annotated corpus including these OOV words.
With the redundancy of the Webinformation, it is not difficult to automatically obtain the expected dictionary or corpus.11564 Our MethodIn this section, we describe our method to automatically expand the training corpus.4.1 Framework of Automatic Corpus ExpansionOur framework of automatic corpus expansion is similar to standard process self-training oractive learning for domain adaptation.
Given a trainable base segmenter, the texts in out-of-domain, we firstly choose some uncertain segmentations and select the candidate expansionseeds.
Secondly, we use these seeds to get the relevant texts from Web search engine.
Then wesegment these texts and add the texts with high confidence to training corpus.
Finally, we canget a better segmenter with the new corpus.Algorithm 1 illustrates the framework of automatic corpus expansion.Algorithm 1 Framework of Automatic Corpus ExpansionInput:Annotated Corpus CAUnannotated Corpus in Target domain CTUncertainty Threshold TuSeed Extraction Threshold TseAcceptation Threshold TaMaximum Iteration Number: MOutput: Expanded Annotated Corpus CA1: for i = 1 to M do2: Train a basic segmenter using current CAwith base learner3: Use the basic segmenter to do segmentation for each sentence in CTand calculate itsconfidence.4: Choose out the sentences collection CTS, in which the segmentation confidence of eachsentence is less than Tu.5: Extract the expansion seeds collection Cseedsfrom CTSand use search engine to acquirerelevant raw texts CRRT.6: Segment and calculate the confidence for each sentence in CRRT.7: Pick the reliable segmentations Cnewwith confidence more than Tafrom CRRT.8: Add Cnewinto CA.9: end for10: return CA;4.2 Uncertainty SamplingThe first key step in our method is to find the uncertain segmentations.
There are many proposeduncertainty measures in the literature of active learning (Settles, 2010), such as entropy andquery-by-committee (QBC) algorithm.In our works, we investigate four following uncertainty measures for each sentence x.
We useS1(x), S2(x), ?
?
?
, SN(x) to represent the top N scores given by the segmenter.Normalized Score UNSThe first measures is normalized score by the length of x, the normalized score UNSis calcu-lated byUNS=S1(x)L(1)where L is the length of x.Standard Deviation USD1157The standard deviation is calculate with the top N scores.USD=???
?1NN?i=1(Si(x) ?
?
)2 (2)where ?
= 1N?Ni=1Si(x) is the average or expected value of Si(x).Entropy UEntropyEntropy is a measure of unpredictability or information content.
Since we use character-basedmethod for word segmentation, each character is labeled as one of {B, M, E, S} to indicatethe segmentation.
{B, M, E} represent Begin, Middle, End of a multi-character segmentationrespectively, and S represents a Single character segmentation.Given the top N labeled results for a sentence, each labeled sequence consists of the labels{B, M, E, S}.
We define l ?
{B,M,E, S} to represent the label variable, and countj(l) to bethe number of occurrences of l on position j among the top N results.
Thus, we can calculatethe entropy for the labeling uncertainty of each character.The entropy Hj(l) for the character on position j is calculated byHj(l) = ?
?lcountj(l)Nlog countj(l)N, (3)where ?lcountj(l) = N .The entropy of sentence UEntropyis the sum of the entropies of all the characters in thesentence.UEntropy=L?j=1Hj(l).
(4)Margin UMarginMargin is the deviation of top 2 scores, which is often used in machine learning algorithms,such as support vector machine (Cristianini and Shawe-Taylor, 2000) and passive-aggressivealgorithm (Crammer et al., 2006).UMargin= S1(x) ?
S2(x) (5)Among the above four measures, the larger the entropy is, the more uncertain the result is.For the rest three factors, the less the score is, the more uncertain the result is.We test these four uncertainty measures on the development set in order to choose the bestone as our confidence measure.In figure 2, we illustrate the relationship between each uncertainty measure and the OOVcount.
We assume that the more OOV words are, the more uncertainty is.
Meanwhile, a steeplearning curve imply a good ability to distinguish whether the result is uncertain.Obviously, the entropy is not helpful according to our assumption.
The normalized score isokay but not good, and both the standard deviation and margin seem to be useful because theycan give a better threshold to distinguish uncertain segmentation.
Finally, we choose margin asour uncertainty measure.4.3 Expansion Seeds ExtractionFor the uncertain segmentation, not every word is unreliable.
We just pick the suspiciousfragments.
Therefore, we need to extract some seed phrases to get the relevant texts.
It isnotable that these seed phrases do not need to be words.
They can be the combinations ofseveral words or only parts of words.Take the following sentence for example.11580.3450.350.3550.360.3650.370.3750.380.3850 2 4 6 8 10U NSOOV count(a) NScore00.0010.0020.0030.0040.0050.0060.0070 2 4 6 8 10U SDOOV count(b) STDEV00.511.522.533.544.550 2 4 6 8 10U EntropyOOV count(c) Entropy00.0020.0040.0060.0080.010.0120 2 4 6 8 10U MarginOOV count(d) MarginFigure 2: Different Uncertainty Measures??????????????
(L?Oreal, Maybelline, Lancome are good brands)The first fragment?????????
?is difficult to segment if these words does not appear intraining corpus.
Conversely, the second fragment is easy to segment since the containing wordsare very common.We use base segmenter to get the top five results as follows:?
?
?
?
?
?
?
?
?
?
?
?
?
?1 B M M M E B M E S B E S B E2 B M M E B E B E S B E S B E3 B M E B E B M E S B E S B E4 S B M M E B E S S B E S B E5 S B M M M E B E S B E S B E(Li et al., 2012) proposed a good way to select the candidate words for active learning withdiversity measurement to avoid duplicate annotation.
However, their method is not suitable forour work.
The reason is that they regarded CWS as a binary classification problem, while ourbase segmenter uses 1st-order sequence labeling.In our work, we choose the expansion seeds by calculating the entropy of each character.
Ifthe entropy of the character is larger than threshold Tse, we say that this character may be inan uncertain context.
Thus, we extract the consecutive uncertain characters and their contextsas the expansion seeds.For the above example, we select the ?????????
(L?Oreal, Maybelline, Lancome)?and its context ??
(is)?as a seed ??????????
?.4.4 Collect relevance texts by using Web Search EnginesAfter obtaining the expansion seeds, we collect the relevant texts on multiple search enginesincluding Google, Baidu and Bing.For the seed ??????????
?, we can get the following relevance sentence, which iseasy to segment.???????????????????
500 ????
(L?Oreal owns more than 500 brands, including Lancome, L?Oreal, Maybelline, Vichy, etc.
)In our work, we just get the top 100 relevant texts returned by each search engine withoutmanual intervention.
We do not use any search API and directly use the returned webpages bysearch engine, then extract the snippets and titles.
Therefore, we just write a simple programto collect the webpages and clean them.4.5 Expand Training CorpusSince the qualities of these relevant texts are spotty, we just pick the reliable texts with highconfidence scores.
In contrast to uncertainty sampling, we find the certain segmentations fromthe collecting raw texts and add them to training corpus.
Here, we also use a margin to findthe reliable ones as new training data.In our experiments, the number of selected sentence is 1 ?
5 for each seed.Thus, we can re-train a new segmenter on the expanded corpus.
After several iteration, wewill get a segmenter with the best performance.11595 Base SegmenterWe use discriminative character-based sequence labeling for base word segmentation.
Eachcharacter is labeled as one of {B, M, E, S} to indicate the segmentation.We use online Passive-Aggressive (PA) algorithm (Crammer and Singer, 2003; Crammer etal., 2006) to train the model parameters.
Following (Collins, 2002), the average strategy is usedto avoid the overfitting problem.6 ExperimentTo evaluate our algorithm, we use both CTB6.0 and CTB7.0 datasets in our experiments.
CTBis a segmented, part-of-speech tagged, and fully bracketed corpus in the constituency formalism.It is also a popular data set to evaluate word segmentation methods, such as (Sun and Xu, 2011).Since CTB dataset is collected from different sources, such as newswire, magazine, broadcastnews and web blogs, it is suitable to evaluate the performance of CWS systems on differentdomains.We conduct two experiments on different divisions of datasets.1.
The first experiment is performed on CTB6.0 for comparison with state-of-the-art systemswhich also utilize the unlabeled data for word segmentation.2.
The second experiment is performed on CTB7.0 for better evaluation on out-of-domaintexts.
CTB7.0 contains some newer news texts and web blogs texts, which is more suitableto evaluate our method for out-of-domain data.In our experiments, we set C = 0.01 for PA algorithm.
We also try to use the different valuesof C, and found that larger values of C imply a more aggressive update step and result to fastconvergence, but it has little influence on the final accuracy.
The maximum iteration numberM?
of PA algorithm is set to 50.The feature templates are CiT0, (i = ?1, 0, 1),C?1,0T0, C0,1T0, C?1,1T0, T?1,0.
C represents aChinese character, and the subscript of C indicates its position relative to the current character,whose subscript is 0.
T represents the character-based tag.The evaluation measure are reported are precision, recall, and an evenly-weighted F1.6.1 Experiments on CTB6.0Train Dev Test81-325, 400-454, 500-554, 590-596,600-885, 900, 1001-1017, 1019,1021-1035, 1037-1043, 1045-1059,1062-1071, 1073-1078, 1100-1117,1130-1131 1133-1140, 1143-1147,1149-1151,2000-2139, 2160-2164,2181-2279,2311-2549, 2603-2774,2820-307941-80,1120-1129,2140-2159,2280-2294,2550-2569,2775-2799,3080-3109(1-40,901-931 newswire)(1018, 1020, 1036,1044,1060-1061, 1072,1118-1119, 1132,1141-1142,1148 magazine) (2165-2180,2295-2310, 2570-2602, 2800-2819, 3110-3145 broadcastnews)Table 2: CTB6.0 Dataset DivisionOn CTB 6.0, we divide the training, development and test sets according to (Yang and Xue,2012).
, which are shown in Table 2 The detailed statistical information is shown in Table 3.Firstly, We use the development set to determine the parameters in Algorithm 1.
For Tu, Tseand Ta, we have three rounds to determine the parameters.
In first round, we find the best valuet1 in the range to 0 ?
1 with the interval of 0.1.
In second round, we find the best value t2 inrange t1?
0.1 ?
t1+0.1 with the interval of 0.01.
In third round, we find the final best value t3116094.594.794.995.195.395.595.795.996.10 1 2 3 4 5F1Iterations(a) F1 score70727476788082840 1 2 3 4 5RoovIterations(b) OOV RecallFigure 3: Iterative Learning Curve onCTB6.092.592.792.993.193.393.593.793.994.194.394.50 1 2 3 4 5F1Iterations(a) F1 score60.562.564.566.568.570.572.574.576.578.50 1 2 3 4 5RoovIterations(b) OOV RecallFigure 4: Iterative Learning Curve onCTB7.0in the range to t2?
0.01 ?
t1+ 0.01 with the interval of 0.001.
The maximum iteration numberM is just determined based on convergence with the range 1 ?
10.Finally, we set these parameters as following: uncertainty threshold Tu= 0.003, seed extrac-tion threshold Tse= 0.65, acceptation threshold Ta= 0.004 and maximum iteration numberM = 5.Figure 3 shows the changing curve of F1 and OOV recall in the process of corpus expansion.The performance of the baseline segmenter is shown at iteration 0.
The curve shows that theF1 score and OOV recall have continuous improvement with the increasing of train corpus.
Themaximum performance is achieved at the 5th iteration.
The detailed results are shown in Table4.
Compared with the baseline, the expanded corpus leads to a segmenter with significantlyhigher accuracy.
The relative error reductions are 26.37% and 43.63% in terms of the balancedF-score and the recall of OOV words respectively.Dataset Sents Words Chars OOV RateTrain.
22757 639506 1053426 -Dev.
2003 59764 100038 5.45%Test 2694 81304 133798 5.58%Table 3: Corpus Information of CTB 6.0Test P R F1 RoovBaseline 94.64 94.73 94.69 70.25Final 95.66 96.51 96.09 83.23(Sun and Xu, 2011) 95.86 95.62 95.74 79.28Table 4: Performance on CTB6.06.2 Experiments on CTB7.0CTB7.0 includes documents from newswire, magazine articles, broadcast news, broadcast con-versations, newsgroups and weblogs.
The newly added documents contains texts from webblogs, which is very different with news texts.
Therefore, we use the documents (No.
4198 4411,weblogs) as test dataset, and the rest as training dataset.
The detailed statistical informationis shown in Table 5.
We can see that the OOV rate is higher than the dataset in the firstexperiment.Dataset Sents Words Chars OOV RateTrain.
40425 987307 1601142 -Test 10177 209827 342061 7.09%Table 5: Corpus Information of CTB 7.0Test P R F1 RoovBaseline 93.58 92.40 92.98 60.72Final 94.47 94.40 94.43 79.24Table 6: Performance on CTB7.0Figure 4 shows the changing curve of F1 and OOV recall in the process of corpus expansion.The performance of the baseline segmenter is shown at iteration 0.
The curve shows that theF1 score and OOV recall have continuous improvement with the increasing of train corpus.
Themaximum performance is achieved at iteration 5.
The detailed results are shown in Table 6.Compared with the baseline, the expanded corpus leads to a segmenter with significantly higheraccuracy.
The relative error reductions are 20.66% and 47.15% in terms of the balanced F-scoreand the recall of OOV words respectively.11616.3 AnalysisThe experimental results show that our method is very effective to improve the performance ofChinese word segmentation.
Especially, our method gives a significant boost on OOV words.For the words such as ????????
(Borussia Moenchengladbach)?, ??????(catalase)?,????
(Yi ZhongTian, a Chinese person name)?and????
(prime time)?,it is still difficult to segment them correctly even if we can obtain useful features from unlabeleddata.
When we take advantage of the redundant information from Web, we can easily collectthe relevant easy-to-segment sentences to expand the training corpus.Our method can result to a segmenter significantly better than the systems which finds theinformative features derived from unlabeled data, such as (Sun and Xu, 2011).
This also suggeststhat expanding corpus is more effective than developing complicated algorithm or well-designfeatures.
Of course, our method is compatible with these technologies, which can further improvethe performance of CWS by combining the Web redundancy.7 ConclusionIn this paper, we propose a method to automatically expand the training corpus for the out-of-domain texts.
Given the out-of-domain texts, we first choose some uncertain segmentationsas candidate expansion seeds, and use these seeds to get the relevant texts from search engine.Then we segment the texts and add the texts with high confidence to training corpus.
We canalways obtain some easily-segmented texts due to the large amount of redundancy texts on Web,especially for new words.
Our experimental results show that our proposed method can moreeffectively and stably utilize the unlabeled examples to improve the performance.
Our methodalso provides a new viewpoint to enhance the performance of CWS by expanding corpus ratherthan developing complicated algorithms or features.The long term goal of our method is to build an online and constant learning system, whichcan identify the difficult tasks and seek help from crowdsourcing.
Search engines are specialcases of crowdsourcing.
In the future, we wish to investigate our method for other NLP tasks,such as POS tagging, Named Entity Recognition, and so on.AcknowledgmentsWe would like to thank the anonymous reviewers for their valuable comments.
This work wasfunded by NSFC (No.61003091), Science and Technology Commission of Shanghai Municipality(14ZR1403200) and Shanghai Leading Academic Discipline Project (B114).ReferencesY.
Altun, D. McAllester, and M. Belkin.
2006.
Maximum margin semi-supervised learning for structuredvariables.
Advances in neural information processing systems, 18:33.Michele Banko, Eric Brill, Susan Dumais, and Jimmy Lin.
2002.
AskMSR: Question answering using theworldwide web.
In Proceedings of 2002 AAAI Spring Symposium on Mining Answers from Texts andKnowledge Bases, pages 7?9.A.L.
Berger, V.J.
Della Pietra, and S.A. Della Pietra.
1996.
A maximum entropy approach to naturallanguage processing.
Computational Linguistics, 22(1):39?71.Stephen Clark, James R Curran, and Miles Osborne.
2003.
Bootstrapping POS taggers using unlabelleddata.
In Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4, pages 49?55.
Association for Computational Linguistics.C.L.A.
Clarke, G.V.
Cormack, and T.R.
Lynam.
2001.
Exploiting redundancy in question answering.Proceedings of the 24th annual international ACM SIGIR conference on Research and development ininformation retrieval, pages 358?365.1162Michael Collins.
2002.
Discriminative training methods for hidden markov models: Theory and exper-iments with perceptron algorithms.
In Proceedings of the 2002 Conference on Empirical Methods inNatural Language Processing.K.
Crammer and Y.
Singer.
2003.
Ultraconservative online algorithms for multiclass problems.
Journalof Machine Learning Research, 3:951?991.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Onlinepassive-aggressive algorithms.
Journal of Machine Learning Research, 7:551?585.N.
Cristianini and J. Shawe-Taylor.
2000.
An introduction to support Vector Machines: and otherkernel-based learning methods.
Cambridge Univ Pr.Oren Etzioni, Michael Cafarella, Doug Downey, Stanley Kok, Ana-Maria Popescu, Tal Shaked, StephenSoderland, Daniel S. Weld, and Alexander Yates.
2004.
Web-scale information extraction in knowitall:(preliminary results).
In Proceedings of the 13th international conference on World Wide Web, WWW?04, pages 100?110, New York, NY, USA.
ACM.H.
Feng, K. Chen, X. Deng, and W. Zheng.
2004.
Accessor variety criteria for chinese word extraction.Computational Linguistics, 30(1):75?93.Jing Jiang and ChengXiang Zhai.
2007.
Instance weighting for domain adaptation in NLP.
In ACL,volume 2007, page 22.Wenbin Jiang, Meng Sun, Yajuan L?, Yating Yang, and Qun Liu.
2013.
Discriminative learning withnatural annotations: Word segmentation as a case study.
In ACL, pages 761?769.Feng Jiao, Shaojun Wang, Chi-Hoon Lee, Russell Greiner, and Dale Schuurmans.
2006.
Semi-supervisedconditional random fields for improved sequence segmentation and labeling.
In Proceedings of the 21stInternational Conference on Computational Linguistics and the 44th annual meeting of the Associationfor Computational Linguistics, pages 209?216.
Association for Computational Linguistics.Zhihui Jin and Kumiko Tanaka-Ishii.
2006.
Unsupervised segmentation of Chinese text by use of branch-ing entropy.
In Proceedings of the COLING/ACL on Main conference poster sessions, pages 428?435.Association for Computational Linguistics.C.C.T.
Kwok, O. Etzioni, and D.S.
Weld.
2001.
Scaling question answering to the web.
Proceedings ofthe 10th international conference on World Wide Web, pages 150?161.John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labeling sequence data.
In Proceedings of the EighteenthInternational Conference on Machine Learning.Zhongguo Li and Maosong Sun.
2009.
Punctuation as implicit annotations for chinese word segmentation.Computational Linguistics, 35(4):505?512.Shoushan Li, Guodong Zhou, and Chu-Ren Huang.
2012.
Active learning for Chinese word segmentation.In COLING (Posters), pages 683?692.Yang Liu and Yue Zhang.
2012.
Unsupervised domain adaptation for joint segmentation and pos-tagging.In COLING (Posters), pages 745?754.Pierre Magistry and Beno?t Sagot.
2012.
Unsupervized word segmentation: the case for mandarinchinese.
In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics:Short Papers-Volume 2, pages 383?387.
Association for Computational Linguistics.David McClosky, Eugene Charniak, and Mark Johnson.
2006.
Effective self-training for parsing.
InProceedings of the main conference on human language technology conference of the North AmericanChapter of the Association of Computational Linguistics, pages 152?159.
Association for ComputationalLinguistics.F.
Peng, F. Feng, and A. McCallum.
2004.
Chinese segmentation and new word detection using condi-tional random fields.
Proceedings of the 20th international conference on Computational Linguistics.Roi Reichart and Ari Rappoport.
2007.
Self-training for enhancement and domain adaptation of statis-tical parsers trained on small datasets.
In Proceedings of the 45th Annual Meeting of the Associationof Computational Linguistics, pages 616?623, Prague, Czech Republic, June.
Association for Compu-tational Linguistics.1163Kenji Sagae.
2010.
Self-training without reranking for parser domain adaptation and its impact onsemantic role labeling.
In Proceedings of the 2010 Workshop on Domain Adaptation for NaturalLanguage Processing, pages 37?44.
Association for Computational Linguistics.Manabu Sassano.
2002.
An empirical study of active learning with support vector machines for japaneseword segmentation.
In Proceedings of the 40th Annual Meeting on Association for ComputationalLinguistics, pages 505?512.
Association for Computational Linguistics.Burr Settles.
2010.
Active learning literature survey.
University of Wisconsin, Madison.Mark Steedman, Miles Osborne, Anoop Sarkar, Stephen Clark, Rebecca Hwa, Julia Hockenmaier, PaulRuhlen, Steven Baker, and Jeremiah Crim.
2003.
Bootstrapping statistical parsers from small datasets.In Proceedings of the tenth conference on European chapter of the Association for ComputationalLinguistics-Volume 1, pages 331?338.
Association for Computational Linguistics.Weiwei Sun and Jia Xu.
2011.
Enhancing Chinese word segmentation using unlabeled data.
In Pro-ceedings of the Conference on Empirical Methods in Natural Language Processing, pages 970?979.Association for Computational Linguistics.Jun Suzuki and Hideki Isozaki.
2008.
Semi-supervised sequential labeling and segmentation using giga-word scale unlabeled data.
In ACL, pages 665?673.
Citeseer.Naiwen Xue, Fei Xia, Fu-Dong Chiou, and Martha Palmer.
2005.
The Penn Chinese TreeBank: Phrasestructure annotation of a large corpus.
Natural language engineering, 11(2):207?238.Nianwen Xue.
2003.
Chinese word segmentation as character tagging.
Computational Linguistics andChinese Language Processing, 8(1):29?48.Yaqin Yang and Nianwen Xue.
2012.
Chinese comma disambiguation for discourse analysis.
In Proceed-ings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume1, pages 786?794.
Association for Computational Linguistics.D.
Yarowsky.
1995.
Unsupervised word sense disambiguation rivaling supervised methods.
In Proceedingsof the 33rd annual meeting on Association for Computational Linguistics, pages 189?196.
Associationfor Computational Linguistics.H.
Zhao and C. Kit.
2008.
Unsupervised segmentation helps supervised learning of character taggingfor word segmentation and named entity recognition.
In The Sixth SIGHAN Workshop on ChineseLanguage Processing, pages 106?111.
Citeseer.Xiaojin Zhu.
2005.
Semi-supervised learning literature survey.
Technical Report 1530, Computer Sci-ences, University of Wisconsin-Madison.1164
