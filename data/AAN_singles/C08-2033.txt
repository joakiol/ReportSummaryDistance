Coling 2008: Companion volume ?
Posters and Demonstrations, pages 131?134Manchester, August 2008Explaining Similarity of TermsVishnu VyasUSC Information Sciences InstituteMarina del Rey, CAvishnu@isi.eduPatrick PantelYahoo!
Inc.Santa Clara, CA 95054me@patrickpantel.comAbstractComputing the similarity between entitiesis a core component of many NLP taskssuch as measuring the semantic similarityof terms for generating a distributional the-saurus.
In this paper, we study the problemof explaining post-hoc why a set of termsare similar.
Given a set of terms, our task isto generate a small set of explanations thatbest characterizes the similarity of thoseterms.
Our contributions include: 1) aninformation-theoretic objective functionfor quantifying the utility of an explana-tion set; 2) a survey of psycholinguisticsand philosophy for evidence of differentsources of explanations such as descriptiveproperties and prototypes; 3) computa-tional baseline models for automaticallygenerating various types of explanations;and 4) a qualitative evaluation of ourexplanation generation engine.1 IntroductionComputing similarity is at the core of manycomputer science tasks.
Many have developedalgorithms for computing the semantic similarityof words (Lee, 1999), of expressions to gener-ate paraphrases (Lin and Pantel, 2001) and ofdocuments (Salton and McGill, 1983).
However,little investigation has been spent on automaticallyexplaining why a particular set of elements aresimilar to one another.Explaining similarity is an important part ofvarious natural language applications such asquestion answering and building lexical ontolo-gies such as WordNet (Fellbaum, 1998).
Severalquestions must be addressed before one can beginto explore this topic.
First, what constitutes a goodc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.explanation and what are the sources of theseexplanations?
Second, how can we automaticallygenerate these different types of explanations?Third, how do we empirically evaluate the qualityof an explanation?
In this paper, we propose a firstanalysis of these questions.2 Related WorkThe task of generating explanations has been stud-ied in relation to Question Answering (Hirschmanand Gaizauskas, 2001) and Knowledge Represen-tation and Reasoning (Cohen et al, 1998).
WithinQuestion Answering, explanations have mostlybeen viewed from a deductive framework andhave focused on proof trees and inference tracesas sources of explanations (Moldovan and Rus,2001).
Summarization and text generation fromproof trees have also been explored as explanationsin QA systems (Barker et al, 2004).
Lester (1997)proposed explanation design packages, a hybridrepresentation for discourse knowledge thatgenerates multi-sentential explanations.Detailed psycholinguistic studies into howpeople explain things suggests that people explainsimilarity using ?feature complexes?
(Fillenbaum,1969), a bundle of features semantically relatedwith a term.
This suggests considering explana-tions of similarity as the shared features amonga set of terms.
Another competing idea fromlinguistic philosophy is the Prototype theory byRosch (1975).
It is argued that objects withina semantic category are represented by another,more commonly used or much simpler memberof the same semantic category, called a prototype.And, within this view, explanations for similarityare prototypes from the same semantic categoryas the given terms.
Deese (1966) investigatedsimilarity in terms of stimulus-response wordassociation experiments providing empiricalevidence to consider other semantically similarwords as explanations.1313 An Information Theoretic Framework forExplaining SimilarityIn this section, we present an information-theoreticframework that defines a good explanation usingthe intuition that they are highly informative andreduce the uncertainty in the set of query terms.For example, consider the set of query terms{Maybach, Maserati, Renault}.
One possibleexplanation of their similarity which is very infor-mative is they are all like a Ford (i.e., a prototypeexplanation).
Other possible explanations includethey can be driven using a steering wheel andthey have wheels (i.e., descriptive properties asexplanations).
Each of these explanations reducesthe uncertainty regarding the semantics of theoriginal set of terms.
In information theory, theconcept of reduction in uncertainty is related toinformation gain, and good explanation sets canbe quantified in terms of information gain.Formally, given a set of query termsQ, and a setof explanations E, we define the best explanationset as one which provides maximum informationto the set Q, or in other words,E = argmaxE???(?)I(Q;E?)
(1)where ?
is the set of all explanations (discussedin detail in Section 4) and ?
(X) represents thepower set of X .
The problem of choosing thebest explanation set for a given query set is nowreduced to a problem of optimization under I .3.1 The Information FunctionThe information function I in Eq.
(1) is a setfunction which defines the amount of informationcontributed by the set of explanations E?to theset of query words Q.
There are many possibleinformation functions, but we would like all ofthem to have some common properties.ConsistencyThe information function should be consis-tent.
For two sets, E and E?, if E ?
E?thenI(Q;E?)
?
I(Q;E).
In other words, given twoexplanation sets E and E?, with E?containingextra explanations, not in E, the informationfunction should assign larger values to E?withrespect to Q than it assigns to E.Explanation Set CardinalityAnother important requirement regarding I , isthe size of the explanation sets.
Any consistentinformation function would assign larger valuesto larger sets of explanations.
This leads to aproblem where the optimal solution is always theset of all explanations.
We overcome this by fixingan upper bound for the size of explanation setsthat are generated by the function I .Redundancy and Joint InformationMany explanations in an explanation set mightoverlap semantically and the information functionhas to account for such overlaps.
However,information functions which take such semanticoverlap into account are computationally hardto optimize.
One approach to this problem is tofind approximate solutions using heuristic searchtechniques, however, relaxing this constraint letsus use common association measures such asmutual information (Cover and Thomas, 1991) asinformation functions.3.2 Marginal Formulation of the InformationFunctionAnother equivalent formulation of Eq.
(1) is touse marginal information gains.
This formulationalso gives a simple greedy algorithm to the op-timization problem when the size of explanationset is fixed.
Let us define the marginal gain ininformation to the set Q, when the explanation eis added to the set of explanations E as:IGQ;E(e) = I(Q;E ?
{e})?
I(Q;E)Then, the best set of explanations of size k can berecursively defined asE0= {}En= En?1?
{e}such thate = argmaxe???IGQ;En?1(e?
)and|En| ?
kIf our marginal information gain is independentof the set of explanations to which it is added,we can rank explanations by their marginalinformation gains as added to the empty set.
Then,choosing the top k explanations gives us the k-bestexplanation set for the query.4 Sources for Similarity ExplanationsIn Section 3, we presented a framework forquantifying a good explanation set.
In this sectionwe present two sources of explanations, usingdescriptive properties and using prototypes.4.1 Explanations from Descriptive PropertiesThe concept of essence as discussed by earlyempiricists was the first study of using descriptiveproperties to explain the similarity of a set ofterms.
Descriptive properties are the sharedessential attributes of a set of similar terms andone way of explaining the similarity of a set ofterms is to generate descriptive properties.Within our framework in Section 3, let the queryset Q be a set of similar words, and let ?, theset of all explanations be the set of all properties132that are shared by all the words within the queryset.
Using mutual information as our measure ofassociation between properties and terms we canrewrite our information function I as:I(Q;E) =?q?Qp(q)?e?Ep(e | q) logp(e | q)p(e)The marginal information gain for a singleexplanation e is:IGQ;E(e) =?q?Qp(q) ?
p(e | q) logp(e | q)p(e)Since the information gain is independent ofthe explanation set E, we can find the best set ofsize k by greedily choosing explanations until ourexplanation set reaches the desired size.4.2 Explanations from PrototypesAs discussed in Section 2 given a set of queryterms, people can represent their meaning usingother common members from the same semanticcategory, called prototypes.
Within the frameworkof Section 3, let Q be our set of query terms.To generate the set of all explanations ?, we useclusters in the CBC resource (Pantel and Lin,2002) as an approximation to semantic categoriesand we collect all possible words that belong tothat cluster which then becomes our candidate set.Let Cqdenote the cluster to which the queryterm q belongs to.
Also let the set C(Q) be theset of all clusters to which the query terms of Qbelong to.
Then?
= {w|Cw?
C(Q)}Now our information function can be written as:I(Q;E) =?q?Qp(Cq)?e?Ep(e | Cq) logp(e | Cq)p(e)The marginal formulation of the above function is:IQ;E(e) =?q?Qp(Cq) ?
p(e | Cq) logp(e | Cq)p(e)We can find the optimal set of explanations of sizek using a greedy algorithm as in Section 4.1.5 Experimental Results5.1 Experimental SetupFor each source of explanation discussed inSection 4, we estimated the model probabilitiesusing corpus statistics extracted from the 1999AP newswire collection (part of the TREC-2002Aquaint collection).In order to obtain a representative set of similarterms as queries to our systems, we randomlychose 100 concepts from the CBC collection (Pan-tel and Lin, 2002) consisting of 1628 clusters ofnouns.
For each of these concepts, we randomlychose a set of cluster instances (nouns), where thesize of each set was randomly chosen to consist oftwo to five nouns.Each of these samples forms a query.
Foreach explanation source described in Section 4,we generated explanation sets for the randomsamples and in the next section we show a randomselection of these system outputs.5.2 Examples of Explanations using Descrip-tive PropertiesFor the algorithm discussed in Section 4.1, wederived our descriptive properties using the outputof the dependency analysis generated by theMinipar (Lin, 1994) dependency parser.
We usesyntactic dependencies between words to modeltheir semantic properties.
The assumption here isthat some grammatical relations, such as subjectand object can yield semantic properties of terms.For example, from a phrase like ?students eatmany apples?, we can infer the properties can-be-eaten for apples and can-eat for students.
In thispaper, we use a combination of corpus statisticsand manual filters for grammatical relations touncover candidate semantic properties.Table 1: Explanations generated using descriptiveproperties.Query Sets ExplanationsPalestinian-Israeli,India-Pakistantalks(NN), conflict(NN),dialogue(NN),relation(NN), peace(NN).TV, television-station cable(NN), watch(obj),see(ON), channel(NN),local(ADJ-MOD)BritneySpears, Janet Jacksonlike(OBJ),concert(NN), video(NN),fan(NN), album(GEN)Crisis,Uncertainty, Difficultyface(OBJ), resolve(OBJ),overcome(OBJ),financial(ADJ-MOD),political(ADJ-MOD)Intuitively, one would prefer adjectival modi-fiers and verbal propositions as good descriptiveproperties for explanations, and from the exam-ples, we can see our algorithm generates suchdescriptive properties because of the high infor-mation contribution of such properties to the queryset.
However, our algorithm does not try to reducethe redundancy within the sets of explanations.
Wecan see redundant explanations for examples in Ta-ble 1.
The reason is that each explanation added tothe set is independent of the ones already presentin the set.
In Pantel and Vyas (2008) we propose ajoint information model to overcome this problem.5.3 Explanations using PrototypesThe algorithm discussed in Section 4.2 uses wordsthat share the semantic category with words withinthe query set as the set of candidate explanations.133We can approximate the notion of semanticcategories using clusters of semantically similarwords.
For this we used the CBC collection (Pan-tel and Lin 2002) of nouns.
Using these clusters assemantic categories, the candidate set of all expla-nations is the set of all the words that belong to thesame cluster.
Table 2 shows some system outputs.Table 2: Explanations generated using prototypes.Query Sets ExplanationsTV, televisionstationstation, network, radio, channel,televisionBudweiser, CoorsLightAnheuser-Busch, Heineken, Coors,San Miguel, Lion Nathanatom, elec-tron,photonparticle, molecule, proton, Ion,isotopeTemple Univer-sity,Michigan StateUniversityUniversity of Texas, University ofMassachusetts, University of NorthCarolina,University of Virginia,University of Minnesota6 Conclusions and Future WorkComputing the similarity between entities formsthe basis of many computer science algorithms.However, we have little understanding of whatconstitutes the underlying similarity.
In thispaper, we investigated the problem of explainingwhy a set of terms are similar.
We proposedan information-theoretic objective function forquantifying the utility of an explanation set, bycapturing the intuition that the best explanationwill be the one that is highly informative to theoriginal query terms.
We also explored varioussources of explanations such as descriptive prop-erties and prototypes.
We then proposed baselinealgorithms to automatically generate these typesof explanations and we presented a qualitativeevaluation of the baselines.However, many other explanation sources werenot addressed.
Hypernyms and other hierarchicalrelations among words also form good explanationsources; for example the similarity of the terms{Ford, Toyota} can be explained using the termcar, a hypernym.
Also our current explanationtypes would fail for query sets consisting of relatedterms such as {bus, road}.
More appropriate forthese queries would be identifying the relationlinking the terms or giving analogies such as{boat, water}.
We are working on algorithmsto generate these explanation types within ourinformation-theoretic framework.
We are alsoinvestigating application-level quantitative evalu-ation methodologies.
Candidate applications in-clude providing answer support by explaining theanswers generated by a QA system and explainingwhy a document was returned in an IR system.ReferencesBarker, K., Chaw, S., Fan, J., Porter, B., Tecuci, D., Yeh,P.
Z., Chaudhri, V., Israel, D., Mishra, S., Romero, P.,and Clark, P. 2004.
A Question-Answering Systemfor AP Chemistry: Assessing KR&R Technologies.
InProceedings of the Ninth International Conference on thePrinciples of Knowledge Representation and Reasoning(KR 2004).
Whistler, 488-497Cohen, P., Schrag, R., Jones, E., Pease, A., Lin, A., Start,B., Gunning, D., and Burke, M. 1998.
The DARPA HighPerformance Knowledge Bases Project.
AI Magazine19(4): 5-49.Cover, T. M. and Thomas, J.
A.
1991.
Elements ofInformation Theory.
Wiley Interscience, New York.Deese, J.
1966.
The Structure of Associations in Languageand Thought.
John Hopkins Press, Oxford, England.Fellbaum, C. 1998.
WordNet: An electronic lexical database.MIT Press.Fillenbaum, S. 1969.
Words as feature complexes : falserecognition of antonyms and synonyms Journal ofExp.Psychology, 1969.L Hirschman, R Gaizauskas - Natural Language Engineering2001.
Natural language question answering: the viewfrom here.
Natural Language Engineering.Lee, Lillian.
1999.
Measures of Distributional Similarity.
InProceedings of ACL-93.
pp.
25-32.
College Park, MDLester, J. C., and Porter, B. W. 1997.
Developing andEmpirically Evaluating Robust Explanation Generators:The KNIGHT Experiments Computational Linguistics,v.23(1) p.65-101.Lin, D. and Pantel, P. 2001.
Discovery of Inference Rulesfor Question Answering.
Natural Language Engineering7(4):343-360.Lin, D. 1994.
Principar - an efficient, broad-coverage,principle-based parser.
In Proceedings of COLING-94.pp.
4248.
Kyoto, Japan.Moldovan, D. I., and Rus, V. 2001.
Logic Form Trans-formation of WordNet and its Applicability to QuestionAnswering Meeting of the Association for ComputationalLinguistics, p. 394-401.Pantel, P. and Lin, D. 2002.
Discovering Word Sensesfrom Text.
In Proceedings of SIGKDD-02.
pp.
613619.Edmonton, Canada.Pantel, P. and Vyas, V. 2008 A Joint Information Modelfor n-best Ranking In Procesedings of COLING-2008.Manchester, UK.Rosch, E. 1975.
Cognitive representations of semanticcategories.
Journal of Exp.Psychology: General, 104,192-233.Salton, G. and McGill, M. J.
1983.
Introduction to ModernInformation Retrieval.
McGraw Hill.134
