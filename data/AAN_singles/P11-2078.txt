Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 445?449,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsOn-line Language Model Biasing for Statistical Machine TranslationSankaranarayanan Ananthakrishnan, Rohit Prasad and Prem NatarajanRaytheon BBN TechnologiesCambridge, MA 02138, U.S.A.{sanantha,rprasad,pnataraj}@bbn.comAbstractThe language model (LM) is a critical com-ponent in most statistical machine translation(SMT) systems, serving to establish a proba-bility distribution over the hypothesis space.Most SMT systems use a static LM, inde-pendent of the source language input.
Whileprevious work has shown that adapting LMsbased on the input improves SMT perfor-mance, none of the techniques has thus farbeen shown to be feasible for on-line sys-tems.
In this paper, we develop a novel mea-sure of cross-lingual similarity for biasing theLM based on the test input.
We also illustratean efficient on-line implementation that sup-ports integration with on-line SMT systems bytransferring much of the computational loadoff-line.
Our approach yields significant re-ductions in target perplexity compared to thestatic LM, as well as consistent improvementsin SMT performance across language pairs(English-Dari and English-Pashto).1 IntroductionWhile much of the focus in developing a statisticalmachine translation (SMT) system revolves aroundthe translation model (TM), most systems do notemphasize the role of the language model (LM).
Thelatter generally follows a n-gram structure and is es-timated from a large, monolingual corpus of targetsentences.
In most systems, the LM is independentof the test input, i.e.
fixed n-gram probabilities de-termine the likelihood of all translation hypotheses,regardless of the source input.The views expressed are those of the author and do not reflect the official policy or position ofthe Department of Defense or the U.S. Government.Some previous work exists in LM adaptation forSMT.
Snover et al (2008) used a cross-lingual infor-mation retrieval (CLIR) system to select a subset oftarget documents ?comparable?
to the source docu-ment; bias LMs estimated from these subsets wereinterpolated with a static background LM.
Zhaoet al (2004) converted initial SMT hypotheses toqueries and retrieved similar sentences from a largemonolingual collection.
The latter were used tobuild source-specific LMs that were then interpo-lated with a background model.
A similar approachwas proposed by Kim (2005).
While feasible in off-line evaluations where the test set is relatively static,the above techniques are computationally expensiveand therefore not suitable for low-latency, interac-tive applications of SMT.
Examples include speech-to-speech and web-based interactive translation sys-tems, where test inputs are user-generated and pre-clude off-line LM adaptation.In this paper, we present a novel technique forweighting a LM corpus at the sentence level basedon the source language input.
The weighting schemerelies on a measure of cross-lingual similarity evalu-ated by projecting sparse vector representations ofthe target sentences into the space of source sen-tences using a transformation matrix computed fromthe bilingual parallel data.
The LM estimated fromthis weighted corpus boosts the probability of rele-vant target n-grams, while attenuating unrelated tar-get segments.
Our formulation, based on simpleideas in linear algebra, alleviates run-time complex-ity by pre-computing the majority of intermediateproducts off-line.Distribution Statement ?A?
(Approved for Public Release, Distribution Unlimited)4452 Cross-Lingual SimilarityWe propose a novel measure of cross-lingual simi-larity that evaluates the likeness between an arbitrarypair of source and target language sentences.
Theproposed approach represents the source and targetsentences in sparse vector spaces defined by theircorresponding vocabularies, and relies on a bilingualprojection matrix to transform vectors in the targetlanguage space to the source language space.Let S = {s1, .
.
.
, sM} and T = {t1, .
.
.
, tN} rep-resent the source and target language vocabularies.Let u represent the candidate source sentence in aM -dimensional vector space, whose mth dimensionum represents the count of vocabulary item sm in thesentence.
Similarly, v represents the candidate tar-get sentence in a N -dimensional vector space.
Thus,u and v are sparse term-frequency vectors.
Tra-ditionally, the cosine similarity measure is used toevaluate the likeness of two term-frequency repre-sentations.
However, u and v lie in different vectorspaces.
Thus, it is necessary to find a projection ofv in the source vocabulary vector space before sim-ilarity can be evaluated.Assuming we are able to compute a M ?
N -dimensional bilingual word co-occurrence matrix ?from the SMT parallel corpus, the matrix-vectorproduct u?
= ?v is a projection of the target sen-tence in the source vector space.
Those source termsof the M -dimensional vector u?
will be emphasizedthat most frequently co-occur with the target termsin v. In other words, u?
can be interpreted as a ?bag-of-words?
translation of v.The cross-lingual similarity between the candi-date source and target sentences then reduces to thecosine similarity between the source term-frequencyvector u and the projected target term-frequencyvector u?, as shown in Equation 2.1:S(u,v) = 1?u??u?
?uT u?= 1?u??
?v?uT?v (2.1)In the above equation, we ensure that both u andu?
are normalized to unit L2-norm.
This preventsover- or under-estimation of cross-lingual similaritydue to sentence length mismatch.We estimate the bilingual word co-occurrencematrix ?
from an unsupervised, automatic wordalignment induced over the parallel training corpusP.
We use the GIZA++ toolkit (Al-Onaizan et al,1999) to estimate the parameters of IBM Model4 (Brown et al, 1993), and combine the forwardand backward Viterbi alignments to obtain many-to-many word alignments as described in Koehn et al(2003).
The (m,n)th entry ?m,n of this matrix isthe number of times source word sm aligns to targetword tn in P.3 Language Model BiasingIn traditional LM training, n-gram counts are evalu-ated assuming unit weight for each sentence.
Ourapproach to LM biasing involves re-distributingthese weights to favor target sentences that are ?sim-ilar?
to the candidate source sentence according tothe measure of cross-lingual similarity developed inSection 2.
Thus, n-grams that appear in the trans-lation hypothesis for the candidate input will be as-signed high probability by the biased LM, and vice-versa.Let u be the term-frequency representation of thecandidate source sentence for which the LM must bebiased.
The set of vectors {v1, .
.
.
,vK} similarlyrepresent the K target LM training sentences.
Wecompute the similarity of the source sentence u toeach target sentence vj according to Equation 3.1:?j = S(u,vj)= 1?u??
?vj?uT?vj (3.1)The biased LM is estimated by weighting n-gramcounts collected from the jth target sentence withthe corresponding cross-lingual similarity ?j .
How-ever, this is computationally intensive because: (a)LM corpora usually consist of hundreds of thou-sands or millions of sentences; ?j must be eval-uated at run-time for each of them, and (b) theentire LM must be re-estimated at run-time fromn-gram counts weighted by sentence-level cross-lingual similarity.In order to alleviate the run-time complexity ofon-line LM biasing, we present an efficient methodfor obtaining biased counts of an arbitrary target446n-gram t. We define ct =[c1t , .
.
.
, cKt]T to bethe indicator-count vector where cjt is the unbi-ased count of t in target sentence j.
Let ?
=[?1, .
.
.
, ?K ]T be the vector representing cross-lingual similarity between the candidate source sen-tence and each of the K target sentences.
Then, thebiased count of this n-gram, denoted by C?
(t), isgiven by Equation 3.2:C?
(t) = cTt ?=K?j=11?u??
?vj?cjtuT?vj= 1?u?uTK?j=11?
?vj?cjt?vj= 1?u?uTbt (3.2)The vector bt can be interpreted as the projectionof target n-gram t in the source space.
Note that bt isindependent of the source input u, and can thereforebe pre-computed off-line.
At run-time, the biasedcount of any n-gram can be obtained via a simpledot product.
This adds very little on-line time com-plexity because u is a sparse vector.
Since bt is tech-nically a dense vector, the space complexity of thisapproach may seem very high.
In practice, the massof bt is concentrated around a very small number ofsource words that frequently co-occur with target n-gram t; thus, it can be ?sparsified?
with little or noloss of information by simply establishing a cutoffthreshold on its elements.
Biased counts and proba-bilities can be computed on demand for specific n-grams without re-estimating the entire LM.4 Experimental ResultsWe measure the utility of the proposed LM bias-ing technique in two ways: (a) given a parallel testcorpus, by comparing source-conditional target per-plexity with biased LMs to target perplexity with thestatic LM, and (b) by comparing SMT performancewith static and biased LMs.
We conduct experi-ments on two resource-poor language pairs commis-sioned under the DARPA Transtac speech-to-speechtranslation initiative, viz.
English-Dari (E2D) andEnglish-Pashto (E2P), on test sets with single as wellas multiple references.Data set E2D E2PTM Training 138k pairs 168k pairsLM Training 179k sentences 302k sentencesDevelopment 3,280 pairs 2,385 pairsTest (1-ref) 2,819 pairs 1,113 pairsTest (4-ref) - 564 samplesTable 1: Data configuration for perplexity/SMT experi-ments.
Multi-reference test set is not available for E2D.LM training data in words: 2.4M (Dari), 3.4M (Pashto)4.1 Data ConfigurationParallel data were made available under the Transtacprogram for both language pairs evaluated in this pa-per.
We divided these into training, held-out devel-opment, and test sets for building, tuning, and evalu-ating the SMT system, respectively.
These develop-ment and test sets provide only one reference trans-lation for each source sentence.
For E2P, DARPAhas made available to all program participants anadditional evaluation set with multiple (four) refer-ences for each test input.
The Dari and Pashto mono-lingual corpora for LM training are a superset of tar-get sentences from the parallel training corpus, con-sisting of additional untranslated sentences, as wellas data derived from other sources, such as the web.Table 1 lists the corpora used in our experiments.4.2 Perplexity AnalysisFor both Dari and Pashto, we estimated a statictrigram LM with unit sentence level weights thatserved as a baseline.
We tuned this LM by varyingthe bigram and trigram frequency cutoff thresholdsto minimize perplexity on the held-out target sen-tences.
Finally, we evaluated test target perplexitywith the optimized baseline LM.We then applied the proposed technique to es-timate trigram LMs biased to source sentences inthe held-out and test sets.
We evaluated source-conditional target perplexity by computing the to-tal log-probability of all target sentences in a par-allel test corpus against the LM biased by the cor-responding source sentences.
Again, bigram andtrigram cutoff thresholds were tuned to minimizesource-conditional target perplexity on the held-outset.
The tuned biased LMs were used to computesource-conditional target perplexity on the test set.447Eval set Static Biased ReductionE2D-1ref-dev 159.3 137.7 13.5%E2D-1ref-tst 178.3 156.3 12.3%E2P-1ref-dev 147.3 130.6 11.3%E2P-1ref-tst 122.7 108.8 11.3%Table 2: Reduction in perplexity using biased LMs.Witten-Bell discounting was used for smoothingall LMs.
Table 2 summarizes the reduction in targetperplexity using biased LMs; on the E2D and E2Psingle-reference test sets, we obtained perplexity re-ductions of 12.3% and 11.3%, respectively.
This in-dicates that the biased models are significantly betterpredictors of the corresponding target sentences thanthe static baseline LM.4.3 Translation ExperimentsHaving determined that target sentences of a paralleltest corpus better fit biased LMs estimated from thecorresponding source-weighted training corpus, weproceeded to conduct SMT experiments on both lan-guage pairs to demonstrate the utility of biased LMsin improving translation performance.We used an internally developed phrase-basedSMT system, similar to Moses (Koehn et al, 2007),as a test-bed for our translation experiments.
Weused GIZA++ to induce automatic word alignmentsfrom the parallel training corpus.
Phrase translationrules (up to a maximum source span of 5 words)were extracted from a combination of forward andbackward word alignments (Koehn et al, 2003).The SMT decoder uses a log-linear model that com-bines numerous features, including but not limited tophrase translation probability, LM probability, anddistortion penalty, to estimate the posterior proba-bility of target hypotheses.
We used minimum errorrate training (MERT) (Och, 2003) to tune the featureweights for maximum BLEU (Papineni et al, 2001)on the development set.
Finally, we evaluated SMTperformance on the test set in terms of BLEU andTER (Snover et al, 2006).The baseline SMT system used the static trigramLM with cutoff frequencies optimized for minimumperplexity on the development set.
Biased LMs(with n-gram cutoffs tuned as above) were estimatedfor all source sentences in the development and testTest set BLEU 100-TERStatic Biased Static BiasedE2D-1ref-tst 14.4 14.8 29.6 30.5E2P-1ref-tst 13.0 13.3 28.3 29.4E2P-4ref-tst 25.6 26.1 35.0 35.8Table 3: SMT performance with static and biased LMs.sets, and were used to decode the corresponding in-puts.
Table 3 summarizes the consistent improve-ment in BLEU/TER across multiple test sets andlanguage pairs.5 Discussion and Future WorkExisting methods for target LM biasing for SMTrely on information retrieval to select a comparablesubset from the training corpus.
A foreground LMestimated from this subset is interpolated with thestatic background LM.
However, given the large sizeof a typical LM corpus, these methods are unsuitablefor on-line, interactive SMT applications.In this paper, we proposed a novel LM biasingtechnique based on linear transformations of targetsentences in a sparse vector space.
We adopted afine-grained approach, weighting individual targetsentences based on the proposed measure of cross-lingual similarity, and by using the entire, weightedcorpus to estimate a biased LM.
We then sketched animplementation that improves the time and space ef-ficiency of our method by pre-computing and ?spar-sifying?
n-gram projections off-line during the train-ing phase.
Thus, our approach can be integratedwithin on-line, low-latency SMT systems.
Finally,we showed that biased LMs yield significant reduc-tions in target perplexity, and consistent improve-ments in SMT performance.While we used phrase-based SMT as a test-bedfor evaluating translation performance, it should benoted that the proposed LM biasing approach is in-dependent of SMT architecture.
We plan to test itseffectiveness in hierarchical and syntax-based SMTsystems.
We also plan to investigate the relativeusefulness of LM biasing as we move from low-resource languages to those for which significantlylarger parallel corpora and LM training data areavailable.448ReferencesYaser Al-Onaizan, Jan Curin, Michael Jahr, KevinKnight, John Lafferty, Dan Melamed, Franz Josef Och,David Purdy, Noah A. Smith, and David Yarowsky.1999.
Statistical machine translation: Final report.Technical report, JHU Summer Workshop.Peter E. Brown, Vincent J. Della Pietra, Stephen A.Della Pietra, and Robert L. Mercer.
1993.
The math-ematics of statistical machine translation: parameterestimation.
Computational Linguistics, 19:263?311.Woosung Kim.
2005.
Language Model Adaptation forAutomatic Speech Recognition and Statistical MachineTranslation.
Ph.D. thesis, The Johns Hopkins Univer-sity, Baltimore, MD.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In NAACL?03: Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology,pages 48?54, Morristown, NJ, USA.
Association forComputational Linguistics.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondr?ej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: open sourcetoolkit for statistical machine translation.
In Proceed-ings of the 45th Annual Meeting of the ACL on Inter-active Poster and Demonstration Sessions, ACL ?07,pages 177?180, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In ACL ?03: Pro-ceedings of the 41st Annual Meeting on Associationfor Computational Linguistics, pages 160?167, Mor-ristown, NJ, USA.
Association for Computational Lin-guistics.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
BLEU: A method for automaticevaluation of machine translation.
In ACL ?02: Pro-ceedings of the 40th Annual Meeting on Associationfor Computational Linguistics, pages 311?318, Mor-ristown, NJ, USA.
Association for Computational Lin-guistics.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings AMTA, pages 223?231, August.Matthew Snover, Bonnie Dorr, and Richard Schwartz.2008.
Language and translation model adaptation us-ing comparable corpora.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, EMNLP ?08, pages 857?866, Stroudsburg,PA, USA.
Association for Computational Linguistics.Bing Zhao, Matthias Eck, and Stephan Vogel.
2004.Language model adaptation for statistical machinetranslation with structured query models.
In Proceed-ings of the 20th international conference on Compu-tational Linguistics, COLING ?04, Stroudsburg, PA,USA.
Association for Computational Linguistics.449
