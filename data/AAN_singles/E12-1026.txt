Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 255?265,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsAdapting Translation Models to Translationese Improves SMTGennadi LemberskyDept.
of Computer ScienceUniversity of Haifa31905 Haifa, Israelglembers@campus.haifa.ac.ilNoam OrdanDept.
of Computer ScienceUniversity of Haifa31905 Haifa, Israelnoam.ordan@gmail.comShuly WintnerDept.
of Computer ScienceUniversity of Haifa31905 Haifa, Israelshuly@cs.haifa.ac.ilAbstractTranslation models used for statistical ma-chine translation are compiled from par-allel corpora; such corpora are manuallytranslated, but the direction of translation isusually unknown, and is consequently ig-nored.
However, much research in Trans-lation Studies indicates that the direction oftranslation matters, as translated language(translationese) has many unique proper-ties.
Specifically, phrase tables constructedfrom parallel corpora translated in the samedirection as the translation task performbetter than ones constructed from corporatranslated in the opposite direction.We reconfirm that this is indeed the case,but emphasize the importance of using alsotexts translated in the ?wrong?
direction.We take advantage of information pertain-ing to the direction of translation in con-structing phrase tables, by adapting thetranslation model to the special proper-ties of translationese.
We define entropy-based measures that estimate the correspon-dence of target-language phrases to transla-tionese, thereby eliminating the need to an-notate the parallel corpus with informationpertaining to the direction of translation.We show that incorporating these measuresas features in the phrase tables of statisti-cal machine translation systems results inconsistent, statistically significant improve-ment in the quality of the translation.1 IntroductionMuch research in Translation Studies indicatesthat translated texts have unique characteristicsthat set them apart from original texts (Toury,1980; Gellerstam, 1986; Toury, 1995).
Knownas translationese, translated texts (in any lan-guage) constitute a genre, or a dialect, of thetarget language, which reflects both artifacts ofthe translation process and traces of the origi-nal language from which the texts were trans-lated.
Among the better-known properties oftranslationese are simplification and explicitation(Baker, 1993, 1995, 1996): translated texts tendto be shorter, to have lower type/token ratio, andto use certain discourse markers more frequentlythan original texts.
Incidentally, translated textsare so markedly different from original ones thatautomatic classification can identify them withvery high accuracy (van Halteren, 2008; Baroniand Bernardini, 2006; Ilisei et al 2010; Koppeland Ordan, 2011).Contemporary Statistical Machine Translation(SMT) systems use parallel corpora to train trans-lation models that reflect source- and target-language phrase correspondences.
Typically,SMT systems ignore the direction of translationused to produce those corpora.
Given the uniqueproperties of translationese, however, it is reason-able to assume that this direction may affect thequality of the translation.
Recently, Kurokawaet al(2009) showed that this is indeed the case.They train a system to translate between Frenchand English (and vice versa) using a French-translated-to-English parallel corpus, and then anEnglish-translated-to-French one.
They find thatin translating into French the latter parallel cor-pus yields better results, whereas for translatinginto English it is better to use the former.Usually, of course, the translation direction of aparallel corpus is unknown.
Therefore, Kurokawaet al(2009) train an SVM-based classifier to pre-dict which side of a bi-text is the origin and whichone is the translation, and only use the subsetof the corpus that corresponds to the translationdirection of the task in training their translationmodel.255We use these results as our departure point,but improve them in two major ways.
First,we demonstrate that the other subset of the cor-pus, reflecting translation in the ?wrong?
direc-tion, is also important for the translation task, andmust not be ignored; second, we show that ex-plicit information on the direction of translation ofthe parallel corpus, whether manually-annotatedor machine-learned, is not mandatory.
This isachieved by casting the problem in the frameworkof domain adaptation: we use domain-adaptationtechniques to direct the SMT system toward pro-ducing output that better reflects the propertiesof translationese.
We show that SMT systemsadapted to translationese produce better transla-tions than vanilla systems trained on exactly thesame resources.
We confirm these findings usingan automatic evaluation metric, BLEU (Papineniet al 2002), as well as through a qualitative anal-ysis of the results.Our departure point is the results of Kurokawaet al(2009), which we successfully replicate inSection 3.
First (Section 4), we explain why trans-lation quality improves when the parallel corpusis translated in the ?right?
direction.
We do soby showing that the subset of the corpus that wastranslated in the direction of the translation task(the ?right?
direction, henceforth source-to-target,or S ?
T ) yields phrase tables that are bettersuited for translation of the original language thanthe subset translated in the reverse direction (the?wrong?
direction, henceforth target-to-source, orT ?
S).
We use several statistical measures thatindicate the better quality of the phrase tables inthe former case.Then (Section 5), we explore ways to build atranslation model that is adapted to the uniqueproperties of translationese.
We first show thatusing the entire parallel corpus, including textsthat are translated both in the ?right?
and in the?wrong?
direction, improves the quality of the re-sults.
Furthermore, we show that the direction oftranslation used for producing the parallel corpuscan be approximated by defining several entropy-based measures that correlate well with transla-tionese, and, consequently, with the quality of thetranslation.Specifically, we use the entire corpus, create asingle, unified phrase table and then use the statis-tical measures mentioned above, and in particularcross-entropy, as a clue for selecting phrase pairsfrom this table.
The benefit of this method is thatnot only does it yield the best results, but it alsoeliminates the need to directly predict the direc-tion of translation of the parallel corpus.
The maincontribution of this work, therefore, is a method-ology that improves the quality of SMT by build-ing translation models that are adapted to the na-ture of translationese.2 Related WorkKurokawa et al(2009) are the first to addressthe direction of translation in the context of SMT.Their main finding is that using the S ?
T por-tion of the parallel corpus results in mucqqh bettertranslation quality than when the T ?
S portionis used for training the translation model.
We in-deed replicate these results here (Section 3), andview them as a baseline.
Additionally, we showthat the T ?
S portion is also important for ma-chine translation and thus should not be discarded.Using information-theory measures, and in par-ticular cross-entropy, we gain statistically signif-icant improvements in translation quality beyondthe results of Kurokawa et al(2009).
Further-more, we eliminate the need to (manually or au-tomatically) detect the direction of translation ofthe parallel corpus.Lembersky et al(2011) also investigate the re-lations between translationese and machine trans-lation.
Focusing on the language model (LM),they show that LMs trained on translated textsyield better translation quality than LMs compiledfrom original texts.
They also show that perplex-ity is a good discriminator between original andtranslated texts.Our current work is closely related to researchin domain-adaptation.
In a typical domain adap-tation scenario, a system is trained on a large cor-pus of ?general?
(out-of-domain) training mate-rial, with a small portion of in-domain trainingtexts.
In our case, the translation model is trainedon a large parallel corpus, of which some (gener-ally unknown) subset is ?in-domain?
(S ?
T ),and some other subset is ?out-of-domain?
(T ?S).
Most existing adaptation methods focus onselecting in-domain data from a general domaincorpus.
In particular, perplexity is used to scorethe sentences in the general-domain corpus ac-cording to an in-domain language model.
Gaoet al(2002) and Moore and Lewis (2010) applythis method to language modeling, while Foster256et al(2010) and Axelrod et al(2011) use it onthe translation model.
Moore and Lewis (2010)suggest a slightly different approach, using cross-entropy difference as a ranking function.Domain adaptation methods are usually appliedat the corpus level, while we focus on an adap-tation of the phrase table used for SMT.
In thissense, our work follows Foster et al(2010), whoweigh out-of-domain phrase pairs according totheir relevance to the target domain.
They usemultiple features that help distinguish betweenphrase pairs in the general domain and those inthe specific domain.
We rely on features that aremotivated by the findings of Translation Studies,having established their relevance through a com-parative analysis of the phrase tables.
In particu-lar, we use measures such as translation model en-tropy, inspired by Koehn et al(2009).
Addition-ally, we apply the method suggested by Mooreand Lewis (2010) using perplexity ratio insteadof cross-entropy difference.3 Experimental SetupThe tasks we focus on are translation betweenFrench and English, in both directions.
Weuse the Hansard corpus, containing transcripts ofthe Canadian parliament from 1996?2007, as thesource of all parallel data.
The Hansard is abilingual French?English corpus comprising ap-proximately 80% English-original texts and 20%French-original texts.
Crucially, each sentencepair in the corpus is annotated with the directionof translation.
Both English and French are lower-cased and tokenized using MOSES (Koehn et al2007).
Sentences longer than 80 words are dis-carded.To address the effect of the corpus size, wecompile six subsets of different sizes (250K,500K, 750K, 1M, 1.25M and 1.5M parallelsentences) from each portion (English-originaland French-original) of the corpus.
Addition-ally, we use the devtest section of the Hansardcorpus to randomly select French-original andEnglish-original sentences that are used for tun-ing (1,000 sentences each) and evaluation (5,000sentences each).
French-to-English MT sys-tems are tuned and tested on French-original sen-tences and English-to-French systems on English-original ones.To replicate the results of Kurokawa et al(2009) and set up a baseline, we train twelveFrench-to-English and twelve English-to-Frenchphrase-based (PB-) SMT systems using theMOSES toolkit (Koehn et al 2007), each trainedon a different subset of the corpus.
We useGIZA++ (Och and Ney, 2000) with grow-diag-final alignment, and extract phrases of length upto 10 words.
We prune the resulting phrase tablesas in Johnson et al(2007), using at most 30 trans-lations per source phrase and discarding singletonphrase pairs.We construct English and French 5-gram lan-guage models from the English and Frenchsubsections of the Europarl-V6 corpus (Koehn,2005), using interpolated modified Kneser-Neydiscounting (Chen, 1998) and no cut-off on alln-grams.
Europarl consists of a large numberof subsets translated from various languages, andis therefore unlikely to be biased towards a spe-cific source language.
The reordering model usedin all MT systems is trained on the union ofthe 1.5M French-original and the 1.5M English-original subsets, using msd-bidirectional-fe re-ordering.
We use the MERT algorithm (Och,2003) for tuning and BLEU (Papineni et al 2002)as our evaluation metric.
We test the statisticalsignificance of the differences between the resultsusing the bootstrap resampling method (Koehn,2004).A word on notation: We use ?English-original?
(EO) and ?French-original?
(FO) to refer to thesubsets of the corpus that are translated from En-glish to French and from French to English, re-spectively.
The translation tasks are English-to-French (E2F) and French-to-English (F2E).
Wethus use ?S ?
T ?
when the FO corpus is used forthe F2E task or when the EO corpus is used forthe E2F task; and ?T ?
S?
when the FO corpusis used for the E2F task or when the EO corpus isused for the F2E task.Table 1 depicts the BLEU scores of the baselinesystems.
The data are consistent with the findingsof Kurokawa et al(2009): systems trained onS ?
T parallel texts outperform systems trainedon T ?
S texts, even when the latter are muchlarger.
The difference in BLEU score can be ashigh as 3 points.4 Analysis of the Phrase TablesThe baseline results suggest that S ?
T andT ?
S phrase tables differ substantially, presum-ably due to the different characteristics of original257Task: French-to-EnglishCorpus subset S ?
T T ?
S250K 34.35 31.33500K 35.21 32.38750K 36.12 32.901M 35.73 33.071.25M 36.24 33.231.5M 36.43 33.73Task: English-to-FrenchCorpus subset S ?
T T ?
S250K 27.74 26.58500K 29.15 27.19750K 29.43 27.631M 29.94 27.881.25M 30.63 27.841.5M 29.89 27.83Table 1: BLEU scores of baseline systemsand translated texts.
In this section we explainthe better translation quality in terms of the bet-ter quality of the respective phrase tables, as de-fined by a number of statistical measures.
We firstrelate these measures to the unique properties oftranslationese.Translated texts tend to be simpler than originalones along a number of criteria.
Generally, trans-lated texts are not as rich and variable as origi-nal ones, and in particular, their type/token ratiois lower.
Consequently, we expect S ?
T phrasetables (which are based on a parallel corpus whosesource is original texts, and whose target is trans-lationese) to have more unique source phrases anda lower number of translations per source phrase.A large number of unique source phrases suggestsbetter coverage of the source text, while a smallnumber of translations per source phrase means alower phrase table entropy.
Entropy-based mea-sures are well-established tools to assess the qual-ity of a phrase table.
Phrase table entropy capturesthe amount of uncertainty involved in choosingcandidate translation phrases (Koehn et al 2009).Given a source phrase s and a phrase table Twith translations t of s whose probabilities arep(t|s), the entropy H of s is:H(s) = ??t?Tp(t|s)?
log2p(t|s) (1)There are two major flavors of the phrase tableentropy metric: Lambert et al(2011) calculatethe average entropy over all translation optionsfor each source phrase (henceforth, phrase tableentropy or PtEnt), whereas Koehn et al(2009)search through all possible segmentations of thesource sentence to find the optimal covering set oftest sentences that minimizes the average entropyof the source phrases in the covering set (hence-forth, covering set entropy or CovEnt).We also propose a metric that assesses the qual-ity of the source side of a phrase table.
The met-ric finds the minimal covering set of a given textin the source language using source phrases froma particular phrase table, and outputs the averagelength of a phrase in the covering set (henceforth,covering set average length or CovLen).Lembersky et al(2011) show that perplexitydistinguishes well between translated and origi-nal texts.
Moreover, perplexity reflects the de-gree of ?relatedness?
of a given phrase to originallanguage or to translationese.
Motivated by thisobservation, we design two cross-entropy-basedmeasures to assess how well each phrase table fitsthe genre of translationese.
Since MT systems areevaluated against human translations, we believethat this factor may have a significant impact ontranslation performance.
The cross-entropy of atext T = w1, w2, ?
?
?wN according to a languagemodel L is:H(T, L) = ?1NN?i=1log2L(wi) (2)We build language models of translated textsas follows.
For English translationese, weextract 170,000 French-original sentences fromthe English portion of Europarl, and 3,000English-translated-from-French sentences fromthe Hansard corpus (disjoint from the training,development and test sets, of course).
We useeach corpus to train a trigram language modelwith interpolated modified Kneser-Ney discount-ing and no cut-off.
All out-of-vocabulary wordsare mapped to a special token, ?unk?.
Then,we interpolate the Hansard and Europarl languagemodels to minimize the perplexity of the targetside of the development set (?
= 0.58).
ForFrench translationese, we use 270,000 sentencesfrom Europarl and 3,000 sentences from Hansard,?
= 0.81.
Finally, we compute the cross-entropyof each target phrase in the phrase tables accord-ing to these language models.258As with the entropy-based measures, we definetwo cross-entropy metrics: phrase table cross-entropy or PtCrEnt calculates the average cross-entropy over weighted cross-entropies of all trans-lation options for each source phrase, and cover-ing set cross-entropy or CovCrEnt finds the opti-mal covering set of test sentences that minimizesthe weighted cross-entropy of the source phrasein the covering set.
Given a phrase table T and alanguage model L, the weighted cross-entropyWfor a source phrase s is:W (s, L) = ?
?t?TH(t, L)?
p(t|s) (3)where H(t, L) is the cross-entropy of t accordingto a language model L.Table 2 depicts various statistical measurescomputed on the phrase tables corresponding toour 24 SMT systems.1 The data meet our pre-liminary expectations: S ?
T phrase tables havemore unique source phrases, but fewer translationoptions per source phrase.
They have lower en-tropy and cross-entropy, but higher covering setlength.In order to asses the correspondence of eachmeasure to translation quality, we compute thecorrelation of BLEU scores from Table 1 witheach of the measures specified in Table 2; wecompute the correlation coefficientR2 (the squareof Pearson?s product-moment correlation coeffi-cient) by fitting a simple linear regression model.Table 3 lists the results.
Only the covering setcross-entropy measure shows stability over theFrench-to-English and English-to-French transla-tion tasks, with R2 equals to 0.56 and 0.54, re-spectively.
Other measures are sensitive to thetranslation task: covering set entropy has thehighest correlation with BLEU (R2 = 0.94) whentranslating French-to-English, but it drops to 0.46for the reverse task.
The covering set averagelength measure shows similar behavior: R2 dropsfrom 0.75 in French-to-English to 0.56 in English-to-French.
Still, the correlation of these measureswith BLEU is high.Consequently, we use the three best measures,namely covering set entropy, cross-entropy andaverage length, as indicators of better transla-tions, more similar to translationese.
Crucially,1The phrase tables were pruned, retaining only phrasesthat are included in the evaluation set.Measure R2 (FR?EN) R2 (EN-FR)AvgTran 0.06 0.22PtEnt 0.03 0.19CovEnt 0.94 0.46PtCrEnt 0.33 0.44CovCrEnt 0.56 0.54CovLen 0.75 0.56Table 3: Correlation of BLEU scores with phrase tablestatistical measuresthese measures are computed directly on thephrase table, and do not require reference trans-lations or meta-information pertaining to the di-rection of translation of the parallel phrase.5 Translation Model AdaptationWe have thus established the fact that S ?
Tphrase tables have an advantage over T ?
S onesthat stems directly from the different characteris-tics of original and translated texts.
We have alsoidentified three statistical measures that explainmost of the variability in translation quality.
Wenow explore ways for taking advantage of the en-tire parallel corpus, including translations in bothdirections, in light of the above findings.
Our goalis to establish the best method to address the is-sue of different translation direction componentsin the parallel corpus.First, we simply take the union of the two sub-sets of the parallel corpus.
We create three dif-ferent mixtures of FO and EO: 500K sentenceseach of FO and EO (?MIX1?
), 500K sentencesof FO and 1M sentences of EO (?MIX2?
), and1M sentences of FO and 500K sentences of EO(?MIX3?).
We use these corpora to train French-to-English and English-to-French MT systems,evaluating their quality on the evaluation sets de-scribed in Section 3.
We use the same Moses con-figuration as well as the same language and re-ordering models as in Section 3.Table 4 reports the results, comparing themto the results obtained for the baseline MT sys-tems trained on individual French-original andEnglish-original bi-texts (see Section 3).2 Notethat the mixed corpus includes many more sen-tences than each of the baseline models; this is a2Recall that when translating from French to English,S ?
T means that the bi-text is French-original; when trans-lating from English to French, S ?
T means it is English-original.259Task: French-to-EnglishSet Total Source AvgTran PtEnt CovEnt PtCrEnt CovCrEnt CovLenS ?
T250K 231K 69K 3.35 0.86 0.36 3.94 1.64 2.44500K 360K 86K 4.21 0.98 0.35 3.52 1.30 2.64750K 461K 96K 4.81 1.05 0.35 3.24 1.10 2.771M 544K 103K 5.27 1.10 0.34 3.09 0.99 2.851.25M 619K 109K 5.66 1.14 0.34 2.98 0.91 2.921.5M 684K 114K 6.01 1.18 0.33 2.90 0.85 2.97T ?
S250K 199K 55K 3.65 0.92 0.45 4.00 1.87 2.25500K 317K 69K 4.56 1.05 0.43 3.57 1.52 2.42750K 405K 78K 5.19 1.12 0.43 3.39 1.35 2.531M 479K 85K 5.66 1.16 0.42 3.21 1.21 2.611.25M 545K 90K 6.07 1.20 0.41 3.11 1.12 2.671.5M 602K 94K 6.43 1.24 0.41 3.04 1.07 2.71Task: English-to-FrenchSet Total Source AvgTran PtEnt CovEnt PtCrEnt CovCrEnt CovLenS ?
T250K 224K 49K 4.52 1.07 0.63 3.48 1.88 2.08500K 346K 61K 5.64 1.21 0.59 3.08 1.49 2.25750K 437K 68K 6.39 1.29 0.57 2.91 1.33 2.331M 513K 74K 6.95 1.34 0.55 2.75 1.18 2.411.25M 579K 78K 7.42 1.38 0.54 2.63 1.09 2.461.5M 635K 81K 7.83 1.41 0.53 2.58 1.03 2.50T ?
S250K 220K 46K 4.75 1.12 0.63 3.62 2.09 2.02500K 334K 57K 5.82 1.24 0.60 3.24 1.70 2.16750K 421K 64K 6.54 1.31 0.58 2.97 1.48 2.251M 489K 69K 7.10 1.36 0.57 2.84 1.35 2.321.25M 550K 73K 7.56 1.40 0.55 2.74 1.25 2.371.5M 603K 76K 7.92 1.43 0.55 2.66 1.17 2.41Table 2: Statistic measures computed on the phrase tables: total size, in tokens (?Total?
); the number of uniquesource phrases (?Source?
); the average number of translations per source phrase (?AvgTran?
); phrase table entropy(?PtEnt?)
and covering set entropy (?CovEnt?
); phrase table cross-entropy (?PtCrEnt?)
and covering set cross-entropy (?CovCrEnt?
); and the covering set average length (?CovLen?
)realistic scenario, in which one can opt either touse the entire parallel corpus, or only its S ?
Tsubset.
Even with a corpus several times as large,however, the ?mixed?
MT systems perform onlyslightly better than the S ?
T ones.
On onehand, this means that one can train MT systemson S ?
T data only, at the expense of only a mi-nor loss in quality.
On the other hand, it is obvi-ous that the T ?
S component also contributes totranslation quality.
We now look at ways to betterutilize this portion.We compute the measures established in theprevious section on phrase tables trained on theMIX corpora, and compare them with the samemeasures computed for phrase tables trained onthe relevant S ?
T corpus for both translationtasks.
Table 5 displays the figures for the MIX1corpus: Phrase tables trained on mixed corporahave higher covering set average length, similarcovering set entropy, but significantly worse cov-ering set cross-entropy.
Consequently, improvingcovering set cross-entropy has the greatest poten-tial for improving translation quality.
We there-fore use this feature to ?encourage?
the decoder to260Task: French-to-EnglishSystem MIX1 MIX2 MIX3Union 35.27 35.36 35.94S ?
T 35.21 35.21 35.73T ?
S 32.38 33.07 32.38Task: English-to-FrenchSystem MIX1 MIX2 MIX3Union 29.27 30.01 29.44S ?
T 29.15 29.94 29.15T ?
S 27.19 27.19 27.88Table 4: Evaluation of the MIX systemsselect translation options that are more related tothe genre of translated texts.French-to-EnglishMeasure MIX1 S ?
TCovLen 2.78 2.64CovEnt 0.37 0.35CovCrEnt 1.58 1.10English-to-FrenchMeasure MIX1 S ?
TCovLen 2.40 2.25CovEnt 0.55 0.58CovCrEnt 2.09 1.48Table 5: Statistical measures computed for mixed vs.source-to-target phrase tablesWe do so by adding to each phrase pair in thephrase tables an additional factor, as a measure ofits fitness to the genre of translationese.
We ex-periment with two such factors.
First, we use thelanguage models described in Section 4 to com-pute the cross-entropy of each translation optionaccording to this model.
We add cross-entropyas an additional score of a translation pair thatcan be tuned by MERT (we refer to this systemas CrEnt).
Since cross-entropy is ?the lower thebetter?
metric, we adjust the range of values usedby MERT for this score to be negative.
Sec-ond, following Moore and Lewis (2010), we de-fine an adapting feature that not only measureshow close phrases are to translated language, butalso how far they are from original language, anduse it as a factor in a phrase table (this systemis referred to as PplRatio).
We build two addi-tional language models of original texts as fol-lows.
For original English, we extract 135,000English-original sentences from the English por-tion of Europarl, and 2,700 English-original sen-tences from the Hansard corpus.
We train a tri-gram language model with interpolated modifiedKneser-Ney discounting on each corpus and weinterpolate both models to minimize the perplex-ity of the source side of the development set forthe English-to-French translation task (?
= 0.49).For original French, we use 110,000 sentencesfrom Europarl and 2,900 sentences from Hansard,?
= 0.61.
Finally, for each target phrase t in thephrase table we compute the ratio of the perplex-ity of t according to the original language modelLo and the perplexity of twith respect to the trans-lated modelLt (see Section 4).
In other words, thefactor F is computed as follows:F (t) =H(t, Lo)H(t, Lt)(4)We apply these techniques to the French-to-English and English-to-French phrase tables builtfrom the mixed corpora and use each phrase ta-ble to train an SMT system.
Table 6 summa-rizes the performance of these systems.
All sys-tems outperform the corresponding Union sys-tems.
?CrEnt?
systems show significant improve-ments (p < 0.05) on balanced scenarios (?MIX1?
)and on scenarios biased towards the S ?
T com-ponent (?MIX2?
in the French-to-English task,?MIX3?
in English-to-French).
?PplRatio?
sys-tems exhibit more consistent behavior, showingsmall, but statistically significant improvement(p < 0.05) in all scenarios.Task: French-to-EnglishSystem MIX1 MIX2 MIX3Union 35.27 35.36 35.94CrEnt 35.54 35.45 36.75PplRatio 35.59 35.78 36.22Task: English-to-FrenchSystem MIX1 MIX2 MIX3Union 29.27 30.01 29.44CrEnt 29.47 30.44 29.45PplRatio 29.65 30.34 29.62Table 6: Evaluation of MT SystemsNote again that all systems in the same columnare trained on exactly the same corpus and haveexactly the same phrase tables.
The only differ-ence is an additional factor in the phrase table that?encourages?
the decoder to select translation op-261tions that are closer to translated texts than to orig-inal ones.6 AnalysisIn order to study the effect of the adaptation qual-itatively, rather than quantitatively, we focus onseveral concrete examples.
We compare transla-tions produced by the ?Union?
(henceforth base-line) and by the ?PplRatio?
(henceforth adapted)French-English SMT systems.
We manually in-spect 200 sentences of length between 15 and 25from the French-English evaluation set.In many cases, the adapted system producesmore fluent and accurate translations.
In the fol-lowing examples, the baseline system generatescommon translations of French words that are ad-equate for a wider context, whereas the adaptedsystem chooses less common, but more suitabletranslations:Source J?ai eu cette perception et j?e?tais assezcertain que c?a allait se faire.Baseline I had that perception and I was enoughcertain it was going do.Adapted I had that perception and I was quitecertain it was going do.Source J?attends donc que vous en demandiez lapermission, monsieur le Pre?sident.Baseline I look so that you seek permission, mr.chairman.Adapted I await, then, that you seek permission,mr.
chairman.In quite a few cases, the baseline system leavesout important words from the source sentence,producing ungrammatical, even illegible transla-tions, whereas the adapted system generates goodtranslations.
Careful traceback reveals that thebaseline system ?splits?
the source sentence intophrases differently (and less optimally) than theadapted system.
Apparently, when the decoder iscoerced to select translation options that are moreadapted to translationese, it tends to select sourcephrases that are more related to original texts, re-sulting in more successful coverage of the sourcesentence:Source Pourtant, lorsqu?
on les avait pre?sente?s,c?e?tait pour corriger les proble`mes lie?s auPCSRA.Baseline Yet when they had presented, it was tocorrect the problems the CAIS program.Adapted Yet when they had presented, it was tocorrect the problems associated with CAIS.Source Cependant, je pense qu?il est pre?mature?de le faire actuellement, e?tant donne?
que leministre a lance?
cette tourne?e.Baseline However, I think it is premature to theright now, since the minister launched thistour.Adapted However, I think it is premature to doso now, given that the minister has launchedthis tour.Finally, there are often cultural differences be-tween languages, specifically the use of a 24-hourclock (common in French) vs. a 12-hour clock(common in English).
The adapted system ismore consistent in translating the former to thelatter:Source On avait de?cide?
de poursuivre la se?ancejusqu?
a` 18 heures, mais on n?aura pas letemps de faire un autre tour de table.Baseline We had decided to continue the meetinguntil 18 hours, but we will not have the timeto do another round.Adapted We had decided to continue the meetinguntil 6 p.m., but we won?t have the time to doanother round.Source Vu qu?il est 17h 20, je suis d?accordpour qu?on ne discute pas de ma motionimme?diatement.Baseline Seen that it is 17h 20, I agree that we arenot talking about my motion immediately.Adapted Given that it is 5:20, I agree that we arenot talking about my motion immediately.In (human) translation circles, translating out ofone?s mother tongue is considered unprofessional,even unethical (Beeby, 2009).
Many professionalassociations in Europe urge translators to workexclusively into their mother tongue (Pavlovic?,2007).
The two kinds of automatic systems builtin this paper reflect only partly the human sit-uation, but they do so in a crucial way.
TheS ?
T systems learn examples from many hu-man translators who follow the decree accordingto which translation should be made into one?s na-tive tongue.
The T ?
S systems are flipped di-rections of humans?
input and output.
The S ?
Tdirection proved to be more fluent, accurate andeven more culturally sensitive.
This has to do withfact that the translators ?cover?
the source textsmore fully, having a better ?translation model?.2627 ConclusionPhrase tables trained on parallel corpora that weretranslated in the same direction as the translationtask perform better than ones trained on corporatranslated in the opposite direction.
Nonethe-less, even ?wrong?
phrase tables contribute to thetranslation quality.
We analyze both ?correct?
and?wrong?
phrase tables, uncovering a great deal ofdifference between them.
We use insights fromTranslation Studies to explain these differences;we then adapt the translation model to the natureof translationese.We incorporate information-theoretic measuresthat correlate well with translationese into phrasetables as an additional score that can be tunedby MERT, and show a statistically significant im-provement in the translation quality over all base-line systems.
We also analyze the results qual-itatively, showing that SMT systems adapted totranslationese tend to produce more coherent andfluent outputs than the baseline systems.
An addi-tional advantage of our approach is that it does notrequire an annotation of the translation directionof the parallel corpus.
It is completely genericand can be applied to any language pair, domainor corpus.This work can be extended in various direc-tions.
We plan to further explore the use of twophrase tables, one for each direction-determinedsubset of the parallel corpus.
Specifically, we willinterpolate the translation models as in Foster andKuhn (2007), including a maximum a posterioricombination (Bacchiani et al 2006).
We alsoplan to upweight the S ?
T subset of the parallelcorpus and train a single phrase table on the con-catenated corpus.
Finally, we intend to extend thiswork by combining the translation-model adap-tation we present here with the language-modeladaptation suggested by Lembersky et al(2011)in a unified system that is more tuned to generat-ing translationese.AcknowledgmentsWe are grateful to Cyril Goutte, George Fosterand Pierre Isabelle for providing us with an anno-tated version of the Hansard corpus.
This researchwas supported by the Israel Science Foundation(grant No.
137/06) and by a grant from the IsraeliMinistry of Science and Technology.ReferencesAmittai Axelrod, Xiaodong He, and Jianfeng Gao.Domain adaptation via pseudo in-domain data se-lection.
In Proceedings of the 2011 Conferenceon Empirical Methods in Natural Language Pro-cessing, pages 355?362.
Association for Computa-tional Linguistics, July 2011.
URL http://www.aclweb.org/anthology/D11-1033.Michiel Bacchiani, Michael Riley, Brian Roark, andRichard Sproat.
MAP adaptation of stochasticgrammars.
Computer Speech and Language, 20:41?68, January 2006.
ISSN 0885-2308. doi: 10.1016/j.csl.2004.12.001.
URL http://dl.acm.org/citation.cfm?id=1648820.1648854.Mona Baker.
Corpus linguistics and translation stud-ies: Implications and applications.
In Gill Fran-cis Mona Baker and Elena Tognini-Bonelli, editors,Text and technology: in honour of John Sinclair,pages 233?252.
John Benjamins, Amsterdam, 1993.Mona Baker.
Corpora in translation studies: Anoverview and some suggestions for future research.Target, 7(2):223?243, September 1995.Mona Baker.
Corpus-based translation studies:The challenges that lie ahead.
In Gill FrancisMona Baker and Elena Tognini-Bonelli, editors,Terminology, LSP and Translation.
Studies in lan-guage engineering in honour of Juan C. Sager,pages 175?186.
John Benjamins, Amsterdam, 1996.Marco Baroni and Silvia Bernardini.
A newapproach to the study of Translationese: Machine-learning the difference between original andtranslated text.
Literary and Linguistic Com-puting, 21(3):259?274, September 2006.
URLhttp://llc.oxfordjournals.org/cgi/content/short/21/3/259?rss=1.Alison Beeby.
Direction of translation (directional-ity).
In Mona Baker and Gabriela Saldanha, edi-tors, Routledge Encyclopedia of Translation Stud-ies, pages 84?88.
Routledge (Taylor and Francis),New York, 2nd edition, 2009.Stanley F. Chen.
An empirical study of smoothingtechniques for language modeling.
Technical report10-98, Computer Science Group, Harvard Univer-sity, November 1998.George Foster and Roland Kuhn.
Mixture-model adap-tation for SMT.
In Proceedings of the SecondWorkshop on Statistical Machine Translation, pages128?135.
Association for Computational Linguis-tics, June 2007.
URL http://www.aclweb.org/anthology/W/W07/W07-0717.George Foster, Cyril Goutte, and Roland Kuhn.
Dis-criminative instance weighting for domain adap-tation in statistical machine translation.
In263Proceedings of the 2010 Conference on Em-pirical Methods in Natural Language Process-ing, pages 451?459, Stroudsburg, PA, USA,2010.
Association for Computational Linguis-tics.
URL http://dl.acm.org/citation.cfm?id=1870658.1870702.Jianfeng Gao, Joshua Goodman, Mingjing Li, and Kai-Fu Lee.
Toward a unified approach to statistical lan-guage modeling for Chinese.
ACM Transactionson Asian Language Information Processing, 1:3?33, March 2002.
ISSN 1530-0226. doi: http://doi.acm.org/10.1145/595576.595578.
URL http://doi.acm.org/10.1145/595576.595578.Martin Gellerstam.
Translationese in Swedish novelstranslated from English.
In Lars Wollin and HansLindquist, editors, Translation Studies in Scandi-navia, pages 88?95.
CWK Gleerup, Lund, 1986.Iustina Ilisei, Diana Inkpen, Gloria Corpas Pastor,and Ruslan Mitkov.
Identification of translationese:A machine learning approach.
In Alexander F.Gelbukh, editor, Proceedings of CICLing-2010:11th International Conference on ComputationalLinguistics and Intelligent Text Processing, vol-ume 6008 of Lecture Notes in Computer Science,pages 503?511.
Springer, 2010.
ISBN 978-3-642-12115-9.
URL http://dx.doi.org/10.1007/978-3-642-12116-6.Howard Johnson, Joel Martin, George Foster, andRoland Kuhn.
Improving translation quality by dis-carding most of the phrasetable.
In Proceedings ofthe Joint Conference on Empirical Methods in Nat-ural Language Processing and Computational Nat-ural Language Learning (EMNLP-CoNLL), pages967?975.
Association for Computational Linguis-tics, June 2007.
URL http://www.aclweb.org/anthology/D/D07/D07-1103.Philipp Koehn.
Statistical significance tests for ma-chine translation evaluation.
In Proceedings ofEMNLP 2004, pages 388?395, Barcelona, Spain,July 2004.
Association for Computational Linguis-tics.Philipp Koehn.
Europarl: A Parallel Corpusfor Statistical Machine Translation.
In Confer-ence Proceedings: the tenth Machine TranslationSummit, pages 79?86, Phuket, Thailand, 2005.AAMT.
URL http://mt-archive.info/MTS-2005-Koehn.pdf.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, and Evan Herbst.
Moses:Open source toolkit for statistical machine transla-tion.
In Proceedings of the 45th Annual Meetingof the Association for Computational LinguisticsCompanion Volume Proceedings of the Demo andPoster Sessions, pages 177?180, Prague, Czech Re-public, June 2007.
Association for ComputationalLinguistics.
URL http://www.aclweb.org/anthology/P07-2045.Philipp Koehn, Alexandra Birch, and Ralf Steinberger.462 machine translation systems for Europe.
In Ma-chine Translation Summit XII, 2009.Moshe Koppel and Noam Ordan.
Translationeseand its dialects.
In Proceedings of the 49th An-nual Meeting of the Association for Computa-tional Linguistics: Human Language Technolo-gies, pages 1318?1326, Portland, Oregon, USA,June 2011.
Association for Computational Lin-guistics.
URL http://www.aclweb.org/anthology/P11-1132.David Kurokawa, Cyril Goutte, and Pierre Isabelle.Automatic detection of translated text and its im-pact on machine translation.
In Proceedings of MT-Summit XII, 2009.Patrik Lambert, Holger Schwenk, Christophe Ser-van, and Sadaf Abdul-Rauf.
Investigations ontranslation model adaptation using monolingualdata.
In Proceedings of the Sixth Workshopon Statistical Machine Translation, pages 284?293.
Association for Computational Linguistics,July 2011.
URL http://www.aclweb.org/anthology/W11-2132.Gennadi Lembersky, Noam Ordan, and Shuly Wint-ner.
Language models for machine translation:Original vs. translated texts.
In Proceedings of the2011 Conference on Empirical Methods in NaturalLanguage Processing, pages 363?374, Edinburgh,Scotland, UK, July 2011.
Association for Computa-tional Linguistics.
URL http://www.aclweb.org/anthology/D11-1034.Robert C. Moore and William Lewis.
Intelligentselection of language model training data.
InProceedings of the ACL 2010 Conference, ShortPapers, pages 220?224, Stroudsburg, PA, USA,2010.
Association for Computational Linguis-tics.
URL http://dl.acm.org/citation.cfm?id=1858842.1858883.Franz Josef Och.
Minimum error rate training in sta-tistical machine translation.
In ACL ?03: Proceed-ings of the 41st Annual Meeting on Association forComputational Linguistics, pages 160?167, Morris-town, NJ, USA, 2003.
Association for Computa-tional Linguistics.
doi: http://dx.doi.org/10.3115/1075096.1075117.Franz Josef Och and Hermann Ney.
Improved statisti-cal alignment models.
In ACL ?00: Proceedings ofthe 38th Annual Meeting on Association for Com-putational Linguistics, pages 440?447, Morristown,264NJ, USA, 2000.
Association for Computational Lin-guistics.
doi: http://dx.doi.org/10.3115/1075218.1075274.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
BLEU: a method for automatic eval-uation of machine translation.
In ACL ?02: Proceed-ings of the 40th Annual Meeting on Association forComputational Linguistics, pages 311?318, Morris-town, NJ, USA, 2002.
Association for Computa-tional Linguistics.
doi: http://dx.doi.org/10.3115/1073083.1073135.Natas?a Pavlovic?.
Directionality in translation and in-terpreting practice.
Report on a questionnaire sur-vey in Croatia.
Forum, 5(2):79?99, 2007.Gideon Toury.
In Search of a Theory of Translation.The Porter Institute for Poetics and Semiotics, TelAviv University, Tel Aviv, 1980.Gideon Toury.
Descriptive Translation Studies and be-yond.
John Benjamins, Amsterdam / Philadelphia,1995.Hans van Halteren.
Source language markers in EU-ROPARL translations.
In COLING ?08: Proceed-ings of the 22nd International Conference on Com-putational Linguistics, pages 937?944, Morristown,NJ, USA, 2008.
Association for Computational Lin-guistics.
ISBN 978-1-905593-44-6.265
