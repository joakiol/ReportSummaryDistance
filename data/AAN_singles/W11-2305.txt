Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 43?51,Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational LinguisticsAsynchronous fixed-grid scanning with dynamic codesRuss Beckley and Brian RoarkCenter for Spoken Language Understanding, Oregon Health & Science University{beckleyr,roark}@cslu.ogi.eduAbstractIn this paper, we examine several methodsfor including dynamic, contextually-sensitivebinary codes within indirect selection typingmethods using a grid with fixed symbol posi-tions.
Using Huffman codes derived from acharacter n-gram model, we investigate bothsynchronous (fixed latency highlighting) andasynchronous (self-paced using long versusshort press) scanning.
Additionally, we lookat methods that allow for scanning past a tar-get and returning to it versus methods that re-move unselected items from consideration.
Fi-nally, we investigate a novel method for dis-playing the binary codes for each symbol tothe user, rather than using cell highlighting, asthe means for identifying the required inputsequence for the target symbol.
We demon-strate that dynamic coding methods for fixedposition grids can be tailored for very diverseuser requirements.1 IntroductionFor many years, a key focus in Augmentative andAlternative Communication (AAC) has been provid-ing text processing capabilities to those for whomdirect selection of symbols on a keyboard (virtual orotherwise) is not a viable option.
In lieu of directselection, a binary (yes/no) response can be giventhrough any number of switches, including buttonsor pads that are pressed with hand, head, or foot,eyeblink detectors, or other switches that can lever-age whatever reliable movement is available.
Theseindirect selection methods typically involve system-atically scanning through options and eliciting thebinary yes/no response at each step of scanning.
Forexample, row/column scanning is a very commonapproach for indirect selection.
Auto row/columnscanning on a square grid, such as that shown in Fig-ure 1, will highlight each row in turn for some fixedduration (dwell time); if the binary switch is trig-gered before the dwell time expires, the row is se-lected; otherwise the next row is highlighted.
Oncea row is selected, cells in this row are then individu-ally highlighted in turn, until one is selected, whichidentifies the intended character.This sort of indirect selection method amounts toassigning a binary code to every symbol in the grid.If triggering the switch (e.g., pressing a button orblinking) is taken as a ?yes?
or 1, then its absence istaken as a ?no?
or 0.
In such a way, every letter in thegrid has a binary code based on the scanning strat-egy.
For example, in Figure 1, the letter ?n?
is in thethird row and fourth column; if row scanning startsat the top, it takes two ?no?s and a ?yes?
to select thecorrect row; and then three ?no?s and a ?yes?
to selectthe correct column.
This translates to a binary codeof ?0010001?.In the preceding example, the codes for all sym-bols are determined by their position in the alpha-ordered grid.
However, faster input can be achievedby assigning shorter codes to likely symbols.
For ex-ample, imagine a user has just typed ?perso?
and isready to type the next letter.
In this context, the let-ter ?n?
is quite likely in English, hence if a very shortcode is assigned to that letter (e.g., ?01?
), then theuser requires only two actions (a ?no?
and a ?yes?
)to produce the letter, rather than the 7 actions re-Figure 1: Spelling grid in rough alpha order.43quired by the row/column code given above.
Thereare methods for assigning codes that minimize theexpected code length for a given probability model(Huffman, 1952).
The quality of the probabilitymodel used for deriving codes can make a large dif-ference in the code length and hence in the efficiencyof the input method.
When the model can accuratelyassign probabilities to symbols, the shortest binarycodes can be assigned to the likeliest symbols, whichthus require the fewest inputs (either yes or no) fromthe user.
The best probabilistic models will take intoaccount what has already been typed to assign prob-ability to each symbol.
The probabilities are contex-tually dependent, and therefore so are the optimalbinary code assignments.
This was illustrated in the?person?
example provided earlier.
To provide an-other example, the probability of the letter ?u?
is notparticularly high overall in English (less than 0.02),but if the previously typed symbol is ?q?, its proba-bility is very high.
Thus, in many contexts, there areother letters that should get the shortest code, butin that particular context, following ?q?, ?u?
is verylikely, hence it should receive the shortest code.Common scanning methods, however, present aproblem when trying to leverage contextually sen-sitive language models for efficient scanning.
Inparticular, methods of scanning that rely on high-lighting contiguous regions ?
such as widely usedrow/column scanning ?
define their codes in termsof location in the grid, e.g., upper left-hand cor-ner requires fewer keystrokes to select than lowerright-hand corner using row/column scanning.
Toimprove the coding in such an approach requiresmoving characters to short-code regions of the grid.In other words, with row/column scanning meth-ods, the symbol needing the shortest code mustmove into the upper left-hand corner of the grid.Yet the cognitive overhead of dealing with frequentgrid reorganization is typically thought to outweighany speedup that is achieved through more efficientcoding (Baletsa et al, 1976; Lesher et al, 1998).If one assumes a fixed grid, i.e., no dynamic re-organization of the symbols, then row/column scan-ning can gain efficiency by placing frequent char-acters in the upper left-hand corner, but cannot usecontextually informed models.
This is akin to Morsecode, which assigns fixed codes to symbols based onoverall frequency, without considering context.Figure 2: Scanning of non-contiguous sets of cellsRoark et al (2010) presented a new approachwhich dropped the requirement of contiguous high-lighting, thus allowing the use of variable codes on afixed grid.
For example, consider the grid in Figure2, where two symbols in different rows and columnsare jointly highlighted.
This approach, which wewill term ?Huffman scanning?, allowed the binarycodes to be optimized using Huffman coding meth-ods (see Section 2.2) with respect to contextuallysensitive language models without dynamic reorga-nization of the grid.
The method resulted in typingspeedups over conventional row/column scanning.One downside to the variable scanning that resultsfrom Huffman scanning is that users cannot antici-pate their target symbol?s binary code in any givencontext.
In row/column scanning, the binary codeof each symbol is immediately obvious from its lo-cation in the grid, hence users can anticipate whenthey will need to trigger the switch.
In Huffmanscanning, users must continuously monitor and reactwhen their target cells light up.
The time required toallow for this motor reaction means that scan ratesare typically slower than in row/column scanning;and stress levels ?
due to the demands of immediateresponse to highlighting ?
higher.Huffman scanning is not the only way to allowvariable coding on a fixed grid.
In this paper, we in-vestigate alternatives to Huffman scanning that alsoallow for efficient coding on a fixed grid.
The threealternative methods that we investigate are asyn-chronous methods, i.e., all of the scanning is self-paced; there is no scan rate that must be matched bythe user.
Rather than ?yes?
being a button press and?no?
a timeout, these approaches, like Morse code,differentiate between short and long presses1.
Thereare several benefits of this sort of asynchronous ap-1Alternatively, two switches can be used.44proach: individuals who struggle with the timing re-quirements of auto, step or directed scanning canproceed without having to synchronize their move-ments to the interface; individuals can interrupt theircommunication ?
e.g., for side talk ?
for an arbitraryamount of time and come back to it in exactly thesame state; and it reduces the stress of constantlymonitoring the scanning sequence and reacting to itwithin the time limits of the interface.The last of our alternative methods is a novel ap-proach that displays the code for each symbol atonce as a series of dots and dashes underneath thesymbol ?
as used in Morse code ?
rather than us-ing cell highlighting to prompt the user as in theother conditions.
Unlike Morse code, these codesare derived using Huffman coding based on n-gramlanguage models, thus change with every context.Since they are displayed for the user, no code mem-orization is required.
This novel interface differsfrom Huffman scanning in several ways, so we alsopresent intermediate methods that differ in only oneor another dimension, so that we can assess the im-pact of each characteristic.Our results show that displaying entire codes atonce for asynchronous scanning was a popular andeffective method for indirect selection, despite thefact that it shared certain dis-preferred characteris-tics with the least popular of our methods.
Thispoints the way to future work investigating methodsto combine the preferred characteristics from our setof alternatives into a yet more effective interface.2 Background and Related Work2.1 Indirect selectionSome of the key issues influencing the work in thispaper have already been mentioned above, such asthe tradeoffs between fixed versus dynamic grids.For a full presentation of the range of indirect selec-tion methods commonly in use, we refer the read-ers to Beukelman and Mirenda (1998).
But in thissection we will highlight several key distinctions ofparticular relevance to this work.As mentioned in the previous section, indirect se-lection strategies allow users to select target sym-bols through a sequence of simpler operations, typi-cally a yes/no indication.
This is achieved by scan-ning through options displayed in the user inter-face.
Beukelman and Mirenda (1998) mention cir-cular scanning (around a circular interface), linearscanning (one at a time), and group-item scanning(e.g., row/column scanning to find the desired cell).Another variable in scanning is the speed of scan-ning ?
e.g., how long does the highlighting lingeron the options before advancing.
Finally, there aredifferences in selection control strategy.
Beukel-man and Mirenda (1998) mention automatic scan-ning, where highlighted options are selected by ac-tivating a switch, and advance automatically if theswitch is not activated within the specified dwelltime; step scanning, where highlighted options areselected when the switch is not activated within thespecified dwell time, and advance only if the switchis activated; and directed scanning, where the high-lighting moves while the switch is activated and se-lection occurs when the switch is released.
In all ofthese methods, synchrony with the scan rate of theinterface is paramount.Speech and language pathologists working withAAC users must assess the specific capabilities ofthe individual to determine their best interface op-tion.
For example, an individual who has difficultyprecisely timing short duration switch activation butcan hold a switch more easily might do better withdirected scanning.Morse code, with its dots and dashes, is also an in-direct selection method that has been used in AAC,but it is far less common than the above mentionedapproaches due to the overhead of memorizing thecodes.
Once learned, however, this approach canbe an effective communication strategy, as discussedwith specific examples in Beukelman and Mirenda(1998).
Often the codes are entered with switchesthat allow for easy entry of both dots and dashes,e.g., using two switches, one for dot and one fordash.
In this study, we have one condition thatis similar to Morse code in using dots and dashes,but without requiring code memorization2.
The in-terface used for the experiments identifies dots anddashes with short and long keypresses.2Thanks to a reviewer for pointing out that DynaVox Series5 displays dynamically-assigned codes for non-letter buttons intheir Morse code interface, much as we do for the entire symbolset.
In contrast to our approach, their codes are not assignedusing probabilistic models, rather to contrast with the standardMorse codes, which are used for the letters.
Further, the cursorthat we use to identify position within the code (see Section 3.5)is not used in the Dynavox interface.452.2 Binary codesIn indirect selection, the series of actions required toselect a given character is determined by the binarycode.
As mentioned in Section 1, row/column scan-ning assigns binary codes based on location withinthe grid.
Ordering the symbols so that frequentcharacters are located in the upper left-hand cor-ner of the grid will provide those frequent charac-ters with short codes with a row/column scanningapproach, though not the minimal possible binarycodes.
Given a probability distribution over sym-bols, there are known algorithms for building a bi-nary code that has the minimum expected bits ac-cording to the distribution, i.e., codes will be op-timally short (Huffman, 1952).
The quality of thecodes, however, depends on the quality of the prob-ability model, i.e., whether the model fits the actualdistribution in that context.Roark et al (2010) presented a scanning approachfor a fixed grid that used Huffman codes derivedfrom n-gram language models (see Section 2.3).The approach leveraged better probability models toachieve shorter code lengths, and achieved an over-all speedup over row/column scanning for the 10subjects in the trial, despite the method being closelytied to reaction time.
The method requires monitor-ing of the target cell in the grid and reaction when itis highlighted, since the pattern of highlighting is notpredictable from symbol position in the grid, unlikerow/column scanning.2.3 Language modelingLanguage models assign probabilities to strings inthe language being modeled, which has broad utilityfor many tasks in speech and language processing.The most common language modeling approach isthe n-gram model, which estimates probabilities ofstrings as the product of the conditional probabilityof each symbol given previous symbols in the string,under a Markov assumption.
That is, for a stringS = s1 .
.
.
sn of n symbols, a k+1-gram model isdefined asP(S) = P(s1)n?i=2P(si | s1 .
.
.
si?1)?
P(s1)n?i=2P(si | si?k .
.
.
si?1)where the approximation is made by imposing theMarkov assumption.
Note that the probability of thefirst symbol s1 is typically conditioned on the factthat it is first in the string.
Each of the conditionalprobabilities in such a model is a multinomial dis-tribution over the symbols in a vocabulary ?, andthe models are typically regularized (or smoothed)to avoid assigning zero probability to strings in ?
?.See Chen and Goodman (1998) for an excellentoverview of modeling and regularization methods.For the current application, the conditional prob-ability P(si | si?k .
.
.
si?1) can be used to as-sign probabilities to all possible next symbols, andthese probabilities can be used to assign Huff-man codes.
For example, if the user has typed?the perso?
and is preparing to type the next letter,we estimate P( n | t h e p e r s o ) as well asP( m | t h e p e r s o ) and every other possi-ble next symbol, from a large corpus.
Note thatsmoothing methods mentioned above ensure that ev-ery symbol receives non-zero probability mass.
Alsonote that the space character (represented above as?
?)
is a symbol in the model, hence the models takeinto account context across word boundaries.
Giventhese estimated probabilities, known algorithms forassigning Huffman codes are used to assign shortcodes to the most likely next symbols, in a way thatminimizes expected code length.3 MethodsSince this paper aims to compare new methods withHuffman scanning presented in Roark et al (2010),we follow that paper in many key respects, includingtraining data, test protocol, and evaluation measures.For all trials we use a 6?6 grid, as shown in Fig-ures 1 and 2, which includes the 26 characters in theEnglish alphabet, 8 punctuation characters (comma,period, double quote, single quote, dash, dollar sign,colon and semi-colon), a white space delimiter (de-noted with underscore) and a delete symbol (de-noted with ?).
Unlike Roark et al (2010), ourgrid is in rough alphabetic order rather than in fre-quency order.
In that paper, they compared Huffmanscanning with row/column scanning, which wouldhave been put at a disadvantage with alphabetic or-der, since frequent characters would have receivedlonger codes than they do in a frequency orderedgrid.
In this paper, however, all of the approaches46are using Huffman codes and scanning of possiblynon-contiguous subsets of characters, so the codeefficiency does not depend on location in the grid.Thus for ease of visual scanning, we chose in thisstudy to use alphabetic ordering.3.1 Language models and binary codesWe follow Roark et al (2010) and build character-based smoothed 8-gram language models from anormalized 42M character subset of the English gi-gaword corpus and the CMU pronunciation dictio-nary.
This latter lexicon is used to increase coverageof words that are unobserved in the corpus, and is in-cluded in training as one observation per word in thelexicon.
Smoothing is performed with a generalizedversion of Witten-Bell smoothing (Witten and Bell,1991) as presented in Carpenter (2005).
Text nor-malization and smoothing parameterizations were aspresented in Roark et al (2010).
Probability of thedelete symbol ?
was taken to be 0.05 in all trials(the same as the probability of an error, see Sec-tion 3.2), and all other probabilities derived from thetrained n-gram language model.3.2 Huffman scanningOur first scanning condition replicates the Huffmanscanning from Roark et al (2010), with two differ-ences.
First, as stated above, we use an alphabeticordering of the grid as shown in Figure 2, in placeof their frequency ordered grid.
Second, rather thancalibrating the scan rate of each individual, we fixedthe scan rate at 600 ms across all subjects.One key aspect of their method is dealing witherrors of omission and commission, i.e., what hap-pens when a subject misses their target symbol.
Instandard row/column scanning, rows are highlightedstarting from the top of the grid, incrementing down-wards one row at a time.
If no row has been selectedafter iterating through all rows, the scanning beginsagain at the top.
In such a way, if the subject mistak-enly neglects to select their intended row, they canjust wait until it is highlighted again.
Similarly, if thewrong row is selected, there is usually a mechanismwhereby the columns are scanned for some numberof iterations, at which point row scanning resumes.The upshot of this is that users can make an error andstill manage to select their intended symbol after thescanning system returns to it.Roark et al (2010) present a method for allow-ing the same kind of robustness to error in Huff-man scanning, by recomputing the Huffman codeafter every bit.
If the probability that the bit wascorrect is p, then the probability that it was incor-rect is 1?p.
In Huffman scanning, a subset is high-lighted and the user indicates yes or no ?
yes, thetarget symbol is in the set; or no, the target symbolis not in the set.
If the answer is ?yes?
and the setincludes exactly one symbol, it is typed.
Otherwise,for all symbols in the selected set (highlighted sym-bols if ?yes?
; non-highlighted if ?no?
), their proba-bilities are multiplied by p (the probability of beingcorrect), while the probabilities of the other set ofsymbols are multiplied by 1?p.
The probabilitiesare then re-normalized and a new Huffman code isgenerated, the first bit of which drives which sym-bols are highlighted at the next step.
In such a way,even if the target symbol is in the highlighted setwhen it is not selected (or vice versa), it is not elim-inated from consideration; rather its probability isdiminished (by multiplying by 1?p, which in thispaper is set to 0.05) and scanning continues.
Even-tually the symbol will be highlighted again, muchas is the case in row/column scanning.
We also usethis method within the Huffman scanning conditionreported in this paper.3.3 Asynchronous scanningOur second condition replaces the scan rate of 600ms from the Huffman scanning approach outlinedin Section 3.2 with an asynchronous approach thatdoes not rely upon a scan rate.
The grid and scan-ning method remain identical, but instead of switchversus no switch, we use short switch (rapid release)versus long switch (slower release).
This is similarto the dot/dash distinction in Morse code.
For thispaper, we used a threshold of 200 ms to distinguisha short versus a long switch, i.e., if the button pressis released within 200 ms it is short; otherwise long.Since Huffman scanning already has switch activa-tion as ?yes?, this could be thought of as having thelong press replace no-press in the interface.With this change, the scanning does not automat-ically advance to the next set, but waits indefinitelyfor the user to enter the next bit of the code.
Thesame method for dealing with errors as with Huff-man scanning is employed in this condition, i.e., re-47Figure 3: Scanning of non-contiguous sets of cells, withsymbols that have been eliminated from considerationdeemphasized (a, b, c, e, o, t)computing the Huffman code after every bit and tak-ing into account the probability of the bit being inerror.
One might see this as a self-paced version ofHuffman scanning.One benefit of this approach is that it does not re-quire the user to synchronize their movements to aparticular scan rate of the interface.
One potentialdownside for some users is that it does require moreactive keypresses than auto scanning.
In auto scan-ning, only the ?1?
bits of the code require switch ac-tivation; the ?0?
bits are produced passively by wait-ing for the dwell time to expire.
In contrast, all bitsin the asynchronous approaches require one of twokinds of switch activation.3.4 Not returning to non-selected symbolsOur third condition is just like the second exceptit does not recompute the Huffman codes after ev-ery bit, changing the way in which user errors arehandled.
At the start of the string or immediatelyafter a letter has been typed, the Huffman codesare calculated in exactly the same way as the pre-vious two conditions, based on the n-gram languagemodel given the history of what has been typed sofar.
However, after each bit is entered for the cur-rent symbol, rather than multiplying by p and 1?p asdetailed in Section 3.2, symbols that have not beenselected are eliminated from consideration and willnot be highlighted again, i.e., will not be returned tofor subsequent selection.
For example, in Figure 3we see that there is a set of highlighted characters,but also a set of characters that have been eliminatedfrom consideration and are deemphasized in the in-terface to indicate that they can no longer be selected(specifically: a, b, c, e, o and t).
Those are symbolsthat were not selected in previous steps of the scan-ning, and are no longer available to be typed in thisposition.
If the user makes a mistake in the input,eliminating the actual target symbol, the only wayto fix it is to type another symbol, delete it, and re-type the intended symbol.This condition is included in the study becauserecalculation of codes after every bit becomes prob-lematic when the codes are explicitly displayed (thenext condition).
By including these results, we cantease apart the impact of not recalculating codes af-ter every bit versus the impact of displaying codes inthe next condition.
Later, in the discussion, we willreturn to this characteristic of the interface and dis-cuss some alternatives that may allow for differenterror recovery strategies.This change to the interface has a couple of impli-cations.
First, the optimal codes are slightly shorterthan with the previous Huffman scanning methods,since no probability mass is reserved for errors.
Inother words, the perfect user that never makes a mis-take would be able to type somewhat faster withthis method, which is not surprising, since reserv-ing probability for returning to something that wasrejected is of no utility if no mistakes are ever made.The experimental results presented later in the pa-per will show explicitly how much shorter the codesare for our particular test set.
Second, it is possi-ble to type a symbol without ever actively selectingit, if all other symbols in the grid have been elimi-nated.
For example, if there are two symbols left andthe system highlights one symbol, which is rejected,then the other symbol is typed.
This contrasts withthe previous methods that only type when a singlecharacter set is actively selected.3.5 Displaying codesOur final condition also does not recompute codesafter every bit, but in addition does away with high-lighting of cells as the mechanism for scanning, andinstead displays dots and dashes directly beneatheach letter in the fixed grid.
For example, Figure4 shows the dots and dashes required for each let-ter directly below that letter in the grid, and Figure5 shows a portion of that grid magnified for easierdetailed viewing.
Each code includes the dots anddashes required to input that symbol, plus a cursor?|?
that indicates how much of the code has already48Figure 4: Scanning of non-contiguous sets of cells, dis-playing dots and dashes rather than highlightingFigure 5: A magnification of part of the above gridbeen entered.
For example, to type the letter ?s?
us-ing the code in Figure 5 , one must input: long, short,short, long, short.Since these codes are displayed, there is no mem-orization required to input the target symbol.
Likerow/column scanning, once the target symbol hasbeen found in the grid, the input sequence is knownin entirety by the user, which can facilitate planningof sequences of actions rather than simply reactingto updates in the interface.
The cursor helps the userknow where they are in the code, which can be help-ful for long codes.
Figure 6 shows a magnificationof the interface when there are only two options re-maining ?
a dot selects ?l?
and a dash selects ?u?.4 ExperimentsWe recruited 10 native English speaking subjects be-tween the ages of 26 and 50 years, who are not usersFigure 6: Cursor shows how much of code has been en-teredof scanning interfaces for typing and have typicalmotor function.
Following Roark et al (2010), weuse the phrase set from MacKenzie and Soukoreff(2003) to measure typing performance, and the samefive strings from that set were used as evaluationstrings in this study as in Roark et al (2010).
Prac-tice strings were randomly selected from the rest ofthe phrase set.
Subjects used an Ablenet Jellybean R?button as the binary switch.
The error rate parameterwas fixed at 5% error rate.The task in all conditions was to type the pre-sented phrase exactly as it is presented.
Symbolsthat are typed in error ?
as shown in Figure 7 ?
mustbe repaired by selecting the delete symbol (?)
todelete the incorrect symbol, followed by the correctsymbol.
The reported times and bits take into ac-count the extra work required to repair errors.We tested subjects under four conditions.
All fourconditions made use of 8-gram character languagemodels and Huffman coding, as described in Sec-tion 3.1, and an alpha-ordered grid.
The first condi-tion is a replication of the Huffman scanning condi-tion from Roark et al (2010), with the difference inscan rate (600ms versus mean 475ms in their paper)and the grid layout.
This is an auto scan approach,where the highlighting advances at the end of thedwell time, as described in Section 3.2.
The secondcondition is asynchronous scanning, i.e., replacingthe dwell time with a long button press as describedin Section 3.3, but otherwise identical to condition 1.The third condition was also asynchronous, but didnot recompute the binary code after every bit, so thatthere is no return to characters eliminated from con-sideration, as described in Section 3.4, but otherwiseidentical to condition 2.
Finally, the fourth conditionFigure 7: After an incorrect symbol is typed, it must bedeleted and the correct symbol typed in its place49Speed (cpm) Bits per character Error rate Long code rateScanning condition mean (std) mean (std) opt.
mean (std) mean (std)1.Huffman Roark et al (2010) 23.4 (3.7) 4.3 (1.1) 2.6 4.1 (2.2) 19.3 (14.2)synchronous This paper 25.5 (3.2) 3.3 (0.4) 2.6 1.8 (1.1) 7.3 (4.1)2.
Huffman asynchronous 20.0 (3.7) 3.1 (0.2) 2.6 3.1 (2.5) 3.8 (1.2)3.
Huffman asynch, no return 17.2 (3.2) 3.1 (0.3) 2.4 7.7 (2.7) 0 (0)4.
Huffman asynch, display codes 18.7 (3.9) 3.0 (0.3) 2.4 6.9 (2.5) 0 (0)Table 1: Typing results for 10 users on 5 test strings (total 31 words, 145 characters) under 4 conditions.displays the codes for each character as described inSection 3.5, without highlighting, but is otherwiseidentical to condition 3.Subjects were given a brief demo of the four con-ditions by an author, then proceeded to a practicephase.
Practice phrases were given in each of thefour conditions, until subjects reached sufficient pro-ficiency in the method to type a phrase with fewerthan 10% errors.
After the practice phases in all fourconditions were completed, the test phases com-menced.
The ordering of the conditions in the testphase was random.
Subjects again practiced in acondition until they typed a phrase with fewer than10% errors, and then were presented with the fivetest strings in that condition.
After completion ofthe test phase for a condition, they were prompted tofill out a short survey about the condition.Table 1 presents means and standard deviationsacross our subjects for characters per minute, bitsper character, error rate and what Roark et al (2010)termed ?long code rate?, i.e., percentage of sym-bols that were correctly selected after being scannedpast.
For condition 1, we also present the result forthe same condition reported in Roark et al (2010).Comparing the first two rows of that table, we cansee that our subjects typed slightly faster than thosereported in Roark et al (2010) in condition 1, withfewer bits per character, mainly due to lower errorrates and less scanning past targets.
This can be at-tributed to either the slower scanning speed or the al-phabetic ordering of the grid (or both).
In any case,even with the slower scan rate, the overall speed isfaster in this condition than what was reported in thatpaper.The other three conditions are novel to this paper.Moving from synchronous to asynchronous (withlong press) but leaving everything else the sameSurvey Huffman Huffman No DisplayQuestion synch asynch return codesFatigued 2.1 3.2 3.4 2.5Stressed 1.9 2.2 2.9 2.0Liked it 3.8 3.0 2.3 3.5Frustrated 1.9 2.8 4.0 2.4Table 2: Mean Likert scores to survey questions (5 = alot; 1 = not at all)(condition 2) leads to slower typing speed but fewerbits per character.
The error rate is higher than inthe synchronous condition 1, but there is less scan-ning past the target symbol.
In discussion with sub-jects, the higher error rate might be attributed to los-ing track of which button press (short or long) goeswith highlighting, or also to intended short pressesbeing registered by the system as long.The final two conditions allow no return to char-acters once they have been scanned past, hence the?long code rates?
go to zero, and the error rates in-crease.
Note that the optimal bits per character areslightly better than in the other trials, as mentionedin Section 3.4, yet the subject bits per character staymostly the same as with condition 2.
Typing speedis slower in these two conditions, though slightlyhigher when the codes are displayed versus the useof highlighting.In Table 2 we present the mean Likert scores fromthe survey.
The four statements that subjects as-sessed were:1.
I was fatigued by the end of the trial2.
I was stressed by the end of the trial3.
I liked this trial4.
I was frustrated by this trialThe scores were: 1 (not at all); 2 (a little); 3 (notsure); 4 (somewhat) and 5 (a lot).50The results in Table 2 show high frustration andstress with condition 3, and much lower fatigue,stress and frustration (hence higher ?liking?)
for con-dition 4, where the codes are displayed.
Overall,there seemed to be a preference for Huffman syn-chronous, followed by displaying the codes.5 DiscussionThere are several take-away lessons from this ex-periment.
First, the frustration and slowdown thatresult from the increased error rates in condition 3make this a dispreferred solution, even though dis-allowing returning to symbols that have been ruledout in scanning reduced the bits per character (opti-mal and in practice).
Yet in order to display a stablecode in condition 4 (which was popular), recalcula-tion of codes after every bit (as is done in the firsttwo conditions) is not an option.
To make condi-tion 4 more effective, some effective means for al-lowing scanning to return to symbols that have beenscanned past must be devised.Second, asynchronous scanning does seem to bea viable alternative to auto scanning, which may beof utility for certain AAC users.
Such an approachmay be well suited to individuals using two switchesfor asynchronous row/column scanning.
Other usersmay find the increased level of switch activation re-quired for scanning in these conditions too demand-ing.
One statistic not shown in Table 1 is numberof keypresses required.
In condition 1, some of the?bits?
required to type the character are produced bynot pressing the button.
In the other three conditions,all ?bits?
result from either a short or long press, sothe button is pressed for every bit.
In condition 1,the mean number of key presses per character was1.5, which is approximately half of the total buttonpresses required per character in the other methods.Future directions include investigations intomethods that combine some of the strengths of thevarious approaches.
In particular, we are interestedin methods that allow for the direct display of codesfor either synchronous or asynchronous scanning,but which also allow for scanning past and return totarget characters that were mistakenly not selected.The benefit of displaying codes ?
allowing for an-ticipation and planning in scanning ?
are quite high,and this paper has not exhausted the exploration ofsuch approaches.
Among the alternatives being con-sidered are: requiring all codes to have a short press(confirmation) bit as the last bit of the code; havinga ?reset?
symbol or gesture; and recalculating codesafter some number of bits, greater than one.
Eachof these methods would somewhat increase the op-timal bits per character, but may result in superioruser performance.
Finally, we intend to include ac-tive AAC users in subsequent studies of these meth-ods.ReferencesG.
Baletsa, R. Foulds, and W. Crochetiere.
1976.
Designparameters of an intelligent communication device.
InProceedings of the 29th Annual Conference on Engi-neering in Medicine and Biology, page 371.D.
Beukelman and P. Mirenda.
1998.
Augmentative andAlternative Communication: Management of SevereCommunication Disorders in Children and Adults.Paul H. Brookes, Baltimore, MD, second edition.B.
Carpenter.
2005.
Scaling high-order character lan-guage models to gigabytes.
In Proceedings of the ACLWorkshop on Software, pages 86?99.Stanley Chen and Joshua Goodman.
1998.
An empiricalstudy of smoothing techniques for language modeling.Technical Report, TR-10-98, Harvard University.D.A.
Huffman.
1952.
A method for the construction ofminimum redundancy codes.
In Proceedings of theIRE, volume 40(9), pages 1098?1101.G.W.
Lesher, B.J.
Moulton, and D.J.
Higginbotham.1998.
Techniques for augmenting scanning commu-nication.
Augmentative and Alternative Communica-tion, 14:81?101.I.S.
MacKenzie and R.W.
Soukoreff.
2003.
Phrase setsfor evaluating text entry techniques.
In Proceedings ofthe ACM Conference on Human Factors in ComputingSystems (CHI), pages 754?755.B.
Roark, J. de Villiers, C. Gibbons, and M. Fried-Oken.2010.
Scanning methods and language modeling forbinary switch typing.
In Proceedings of the NAACL-HLT Workshop on Speech and Language Processingfor Assistive Technologies (SLPAT), pages 28?36.I.H.
Witten and T.C.
Bell.
1991.
The zero-frequencyproblem: Estimating the probabilities of novel eventsin adaptive text compression.
IEEE Transactions onInformation Theory, 37(4):1085?1094.51
