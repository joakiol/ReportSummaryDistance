Proceedings of the Second Workshop on Natural Language Processing for Social Media (SocialNLP), pages 59?65,Dublin, Ireland, August 24 2014.Content+Context=Classification: Examining the Roles of SocialInteractions and Linguist Content in Twitter User Classification?W.
M. CampbellHuman Language TechnologyMIT Lincoln LaboratoryLexington, MA 01740wcampbell@ll.mit.eduE.
Baseman?School of Computer ScienceUniv.
of Mass.
AmherstAmherst, MA 01003ebaseman@cs.umass.eduK.
GreenfieldHuman Language TechnologyMIT Lincoln LaboratoryLexington, MA 01740kara.greenfield@ll.mit.eduAbstractTwitter users demonstrate many characteristics via their online presence.
Connections, commu-nity memberships, and communication patterns reveal both idiosyncratic and general propertiesof users.
In addition, the content of tweets can be critical for distinguishing the role and impor-tance of a user.
In this work, we explore Twitter user classification using context and contentcues.
We construct a rich graph structure induced by hashtags and social communications inTwitter.
We derive features from this graph structure?centrality, communities, and local flow ofinformation.
In addition, we perform detailed content analysis on tweets looking at offensivenessand topics.
We then examine user classification and the role of feature types (context, content)and learning methods (propositional, relational) through a series of experiments on annotateddata.
Our work contrasts with prior approaches in that we use relational learning and alterna-tive, non-specialized feature sets.
Our goal is to understand how both content and context arepredictive of user characteristics.
Experiments demonstrate that the best performance for userclassification uses relational learning with varying content and context features.1 IntroductionIn recent years, Twitter has become an extremely prolific social media engine, attracting an extremelydiverse user base, ranging from teenagers discussing the latest in pop culture, to businesses lookingfor free advertising space, to the president of the United States trying to reach a broader audience thantraditional media will allow.
Twitter is the place to say whatever you want to whoever you want..., aslong as it is less than 140 characters.
This conciseness constraint forced the Twitter user base to developinnovative ways of maximizing the information content of each letter.
As such, the resulting tweetsconstitute a vast data set of rich textual content.
Additionally, these tweets traverse through and define asocial network comprised of all kinds of people tweeting to people about people.In this work, we try to identify who some of these people are by performing user classification.
Severalprior methods have been proposed.
Teng and Chen (2006) performed a similar study on bloggers inorder to classify them by interest type.
Twitter, however, provides a much richer feature set due to thedenser network structure and nearly ubiquitous adoption of user profiles.
Romero et al.
(2011) defined asocial graph structure for Twitter data.
While this was the first paper of its kind to explore the benefitsof extracting a network structure from textual data, they only considered a limited graph comprisingthe retweet structure.
Rao et al.
(2010) and Pennacchiotti and Popescu (2011) expanded the notion ofa Twitter graph to more broadly encompass social communication and used this jointly with contentfeatures to predict some attributes of Twitter users.
Only limited graph analysis was performed and?This work was performed under an internship at MIT Lincoln Laboratory.
?This work was sponsored by the Defense Advanced Research Projects Agency under Air Force Contract FA8721-05-C-0002.
Opinions, interpretations, conclusions, and recommendations are those of the authors and are not necessarily endorsedby the United States Government.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/59learning was based on the user and not relational methods.
In (Wu et al., 2011), a special feature, Twitterlists, was used as a simple approach to user classification.Our goal is to explore the role of different features and learning methods in user classification.
Themotivation for this study is multifold.
First, prior work has only performed limited analysis on Twittergraph structures and their role in user characterization.
Second, the interplay between content, context,and learning method (relational versus propositional) has not been fully explored.
Third, user classifica-tion using profile information or specific Twitter features may not always be available or accurate.
In ourstudy, we find 20% of the users do not have an accessible profile.
Additionally, since profile informationcontains self-reported fields, its accuracy is questionable.In this paper, our contribution consists of multiple parts.
First, we develop a rich network repre-sentation of Twitter data that combines the traditionally exploited social network features (retweeting,at-mentions), user tweeting behaviors (hashtag usage), and hashtag co-occurrence without requiring stor-age of all tweets.
We perform network analysis on this graph and show that community structure andcentrality in the network are qualitatively interesting and relevant for user classification.
Second, we per-form tweet level topic clustering and offensiveness detection.
We propose a new method for propagatingposterior class probabilities to both hashtag and at-mention graph nodes.
This provides topic and offen-siveness associations for both users and hashtags in the Twitter graph.
Finally, in constrast to prior work,we perform relational learning on the Twitter graph and show significant improvements in performanceby using information from hashtag-neighbors and user-neighbors of a user node.2 Corpus CollectionOver the 8 month period from September 2012 to March 2013, we used Twitter?s streaming API to collecta < 1% sample of the entire twitter feed, totaling approximately 686 million tweets, which (Morstatteret al., 2013) showed to be a representative sample of the entire Twitter space.
These tweets contain basicinformation?tweet id, date and time, user id, user location, and tweet text.
The tweets are representativeof the Twitter population and display a wide variety of user accounts, topics, languages, and locations.In addition to collecting a corpus of tweets, we used Twitter?s REST API to collect the user profilesfor all users who were either an author of or at-mentioned in at least one of the previously collectedtweets.
User profiles contain both user generated and automatically generated content.
The user gen-erated content includes information such as webpage link, location, time zone, screen name, language,and a textual description of the account.
Since these are self-reported attributes, their veracity is oftennoisy or over-generalized?e.g., location reported as ?all around the world.?
The automatically generateduser account content consists of account information and statistics such as number of followers, date ofaccount creation, number of tweets (statuses count), verified status, and favorite count.We augmented our tweet + profile corpus by labeling a subset of user profiles with their user type.Annotation was performed by multiple annotators.
We considered the following partitioning of userprofiles into user classes.
individual:famous : Famous person: writer, actor, former politician, etc.individual:generic : Generic (everyday) user tweeting.
individual:other : An individual that doesn?tfall into the categories above.
organization : Business, non-profit, government organization.
fake :Fictional characters, celebrity impersonations, deceased individuals, etc.
info : Information source?news, trivia, jokes, quotes.
bots : Produces automated posts via Twitter.
missing : User doesn?t exist(deleted page or misspelled user id).
dontcare : Spam, offensive services.
other : Not in one of theabove categories.
We selected this schema as an initial exploration of interesting categories and manyalternate schema are possible.3 Twitter Graph ConstructionIn order to construct an analytics platform, we applied a mapping that converts a corpus of tweets andcorresponding user profiles into a Twitter graph.
There are several methods of representing Twitter dataas a graph which capture diferent levels of data richness at inversely proportional computational expense(both in processing and storage requirements).
In this work, we consider a graph with multityped nodesin one-to-one correspondence with the union of the set of user profiles (e.g., @blueman) and the set of60Table 1: Example communities obtained from Infomap community detection with the Twitter GraphCommunities and High-Pagerank Members Highest Pagerank Node#me, #cute, #instagood, #beautiful, #fashion #love#500aday, #tfb, #instantfollowback, #teamfollowback#teamautofollow, #followback#breakoutartist, #musicfans, #peopleschoice#onedirection, #popartist, #celebrityjudge#android, #androidgames, #ipad, #ipadgames, #iphone #gamesinsight@harry styles, @real liam payne, @louis tomlinson, @niallofficial@zaynmalik, @onedirection#football, #49ers, #packers, #ravens, #redskins #nfl#p2, #teaparty, #tlot, #gop, #obama #tcot#believecoustic, #believe, #believetour, #kiss, @alfredoflores @justinbieberhashtags (e.g., #yankees) that occur in one or more of the collected tweets.
We chose not to includeindividual tweets as nodes in the graph in order to maintain tractability.In addition to the two classes of nodes, we considered five classes of edges.
There are three classesof edges that connect two user profile nodes.
The first is a directed, weighted edge corresponding tothe number of times one user at-mentions another user (e.g., @blueman writes a tweet containing@greenman).
The second type of user to user edge is a directed, weighted edge corresponding tothe number of times one user retweets another user (e.g., @blueman writes a tweet containing RT@greenman).
Unlike the at-mentions and retweets edges, the third type of user to user edge doesn?tmap to communication between users; rather this edge classification refers to an undirected, weightedcount of the number of times at-mentions of two users co-occur in the same tweet (e.g., @redman writesa tweet containing @greenman and @blueman).
Similarly to the user to user co-occurence edge clas-sification, there is an undirected, weighted edge classification corresponding to the co-occurrence of twohashtags.
The final class of edges are weighted, directed edges corresponding to the number of times agiven user tweets a particular hashtag.4 Graph FeaturesWe extracted network features from the Twitter graph based on community detection and centrality(Pagerank).
We partitioned the node set into commuties by leveraging the infomap approach (Rosvalland Bergstrom, 2008).
We use Pagerank to calculate the centrality of each node and we define communitycentrality as the sum of the Pageranks for all nodes in the community.
The community ?Pagerank?
allowsus to rank communities by centrality.
After computing both Pagerank and communities, we added thesenode features to the original (directed) graph.Optimizing the communities in the Twitter graph yields communities with both user and hashtagnodes.
Nodes with high-pagerank in a community serve as a community summarizations.
We showa summary of some of the largest Pagerank sum communities in Table 1.
Cursory analysis reveals thatqualitatively the communities are very interpretable?user Justin Bieber is associated with the Believetour, the hashtag #gameinsight is associated with different platforms and game types, followbacksare grouped together, and the #love community has the highest community Pagerank.5 Content AnalysisContent analysis uses natural language processing to extract additional structured features from unstruc-tured tweets.
We discussed simple content analysis based on parsing tweets in order to identify com-munication (at-mentions and retweets) and content (hashtags) in a previous section.
In this section, wecover more advanced techniques?topic modeling and offensiveness detection.Before covering the details of content analysis, we describe the general framework for incorporatingcontent features into our classification framework.
We assume that content analysis produces a vector ofposterior probabilities,cj=[p(?i|tweetj)](1)61where ?iis the indicator for the class label i.
In general, including all tweets as nodes in a graph forclassification leads to a graph of prohibitive size.
Instead, we propagate the information contained intweets to corresponding user and hashtag nodes and compute the expected posterior probability; i.e., weaverage all of the vectors propagated to a certain node.The rules for propagating cjfor at-mentions are as follows.
If user @blueman tweets with no recip-ient or multiple recipients, then cjis propagated to the @blueman node.
If user @blueman retweetsfrom user @greenman, then cjis propagated to both @blueman and @greenman.
Similarly forhashtags nodes, we propagate the cjvector to all hashtags used in tweetj.Averaging the content vectors that were propagated to user and hashtag nodes defines representativecontent vectors for those nodes.
A drawback of this aggregation strategy is that the average estimator canhave a variable variance proportional to the number of vectors propagated to a node, which can introducenoise into the classification process.5.1 Topic ModelingOur topic modeling is based upon probabilistic latent semantic analysis (PLSA).
PLSA models the jointprobability between documents and words by introducing a latent variable z representing possible topicsin a document.
We trained the PLSA model with an EM algorithm.An analysis of the topics produced by PLSA provides meaningful interpretation of many of the highscoring topics.
For instance, topics such as money, sleep habits, the ubiquitous Justin Bieber, birth-days and Valentine?s day, and love are easily seen.
Expressions of happiness via emoticons are also atopic.
The topics in general represent broad categories (love, football) and specific events (video awards,Valentine?s day).
In addition, topics that represent common linguistic phenomena?African Americanvernacular English (AAVE), various expletives, and teen lifestyle (class, teacher, parents, ...).
We remarkthat the topics are related to but not the same as the community detection applied to the Twitter graph.Qualitatively, the Twitter graph communities appear to be better defined and more easily interpreted thantheir PLSA counterparts.5.2 OffensivenessAnother significant attribute of a tweet is linguistic register?the variation due to the social setting.
Inan attempt to capture some of the phenomena that occurs due to formality, familiarity, etc., we trainedan offensiveness detector.
The goal of building this detector is that variations in offensiveness mightdistinguish user type (e.g., politician versus generic user).Offensiveness is a broad term and could be defined in many different ways.
We define offensivenessusing a pragmatic two-stage approach.
First, we obtained a set of offensive tweets by issuing queriesvia Lucene of offensive terms.
To obtain a set of putative non-offensive tweets, we took a randomsample of the remaining tweets from a large pool, assuming that in this case offensiveness has a lowerprior.
We then trained a classifier with the offensive and non-offensive data sets.
The resulting output ofthe detector yields a consistent definition of offensiveness.
Additionally, training a detector rather thanusing just a dictionary approach captures some of the additional co-occurring terms and allows learningappropriate weightings of terms.We split the annotated data into distinct train and test sets for performance measurement and cali-bration of the detector.
Approximately 14000 tweets were in both sets.
We trained an SVM by usingnormalized word-count vectors and a linear kernel.
The SVM regularization parameter was tuned foroptimal performance to c = 0.1.
The equal error rate is 12.4% for the detector.
The detector appears toproduce consistent results.
Given that tweets are short messages, this performance level appears reason-able.We needed two additional steps in order to apply the detector to all English tweets.
First, we convertedthe output of the SVM to a posterior probability using the standard approach in Platt (Platt, 2000) andoptimized by using a conjugate gradient method.
Second, there were numerous cases in the data whereunseen vocabulary in the training set resulted in a zero-vector for vi.
In these cases, we used an imputedposterior of offensiveness by taking the average value across all nodes.626 User ClassificationOur goal in this work is to identify the saliency of network and content features as well as relational versuspropositional learning methods for classifying Twitter users.
We cast the user classication problem as adetection problem; i.e., for each label (verified, generic, etc.
), we build a 1-versus-rest detector to predictthat attribute of the user.Since our representation of the Twitter data involves user-user, user-hashtag, and hashtag-hashtag re-lationships, we apply a relational learning approach to user classification.
Relational learning techniquesleverage the structure of the neighborhood around a user of interest as well as the attributes of that userand its neighbors.
In this work, we construct queries consisting of the user of interest, and the nodes ad-jacent to and edges incident to that user.
We use relational probability trees (RPTs) (Neville et al., 2003)to leverage these subgraphs for classification.
An RPT is a decision tree which automatically calculatesand considers aggregate features within the subgraphs.7 Experiments7.1 Experimental SetupFrom a 1% sample of raw tweets, we created a Twitter graph combining content and network features.We included network structure in the graph by letting edges indicate retweets, communication and co-occurance of users in tweets, or co-occurrence of hashtags within tweets.
In addition, we annotated eachedge with counts for each interaction type.
We added additional content features for topic and offensive-ness as well as network features for cluster and cluster pagerank for each user and hashtag.
Topic vectorswere assigned using a PLSA approach, and offensiveness was determined using an SVM.
Clusteringand pagerank were achieved using the infomap approach.
In addition, we hand-annotated approximately1300 users (individual:famous, individual:generic, individual:other, organization, info source, bot, etc.
)by examining their profiles and tweets.
The resulting graph had 252K nodes (189K users and 64K hash-tags), and 1.16M edges.We performed experiments using multiple feature subsets (content, network and content+network)and different learning methods (propositional, relational).
The content features we generated for usersand hashtags are topic and offensiveness.
We include the top three most likely topics for each user andhashtag in our feature set for these experiments.
Our network features for users and hashtags are clusterand cluster pagerank.
We cast the user classification process as a detection problem.
For each user label(verified, generic, etc.
), we create a detector using an RPT that uses a one-versus-rest labeling.To predict whether or not a user has a verified account, we learn decision trees with Proximity?withvarying features included in the analysis.
There were a total of 84k users with a verified label in ourgraph from downloaded Twitter profiles.
We subsampled 10% of this data set to give reasonable runtimes for Proximity.For the remaining hand-annotated classes, we used all available labeled data.
We learned decisiontrees using Proximity with a maximum tree depth of 3.
For some user types, there were not enoughlabeled users to make reliable models and predictions; we excluded user types with probability less thanor equal to 1% (fake, other, spam).
We also found prediction of organization to be unreliable.
Therefore,we focused our experiments on high-prior hand-annotated classes?generic, info, and famous.For both relational and propositional (user-only) learning, we divided the data into 5 random splitswith 80% of the data in training and 20% of the data in test.
For each split, we measured the area underthe curve (AUC) from the trained detector on the heldout test set.
Results are reported in terms of themean and standard deviation (SD) of the AUC across all splits.Relational learning was somewhat complicated by the varying structure of user neighborhoods.
Ide-ally, we would like our graph queries to return subgraphs that consist of a central labeled user, and allusers and hashtags that are immediate neighbors of this labeled user.
However, the RPTs need to be ableto calculate the same aggregate features for each subgraph.
A problem arises because some labeled usernodes only have neighbors that are users, while other user nodes have only hashtag neighbors, and still?Software and documentation is available at http://kdl.cs.umass.edu/proximity63more nodes have both user and hashtag neighbors.
There is also an unusual case where some users donot have any neighbors.
We find that user nodes from these four neighborhood structure cases (no neigh-bors, only user neighbors, only hashtag neighbors, and both user and hashtag neighbors) cannot all bemixed together in the same training and test sets.
This diffculty occurs because aggregate attributes thatare well-defined on the users with only hashtag neighbors, such as average offensiveness of neighboringhashtags, are undefined for nodes with only user neighbors.
We handle this by running separate sets ofexperiments for each of these four neighborhood structure cases.7.2 User Classification Experiments7.2.1 Verified User ResultsTable 2 shows average AUC results for propositional and relational prediction of account verification.Note that an AUC of 0.5 indicates chance performance.
From the table, we see that we can performreasonable user classification of verified users using our extracted features.From the table, we can reach multiple conclusions.
First, propositional learning performs similarlywith either network-only or content-only features.
Second, content and network features together pro-vide a significant boost in performance.
This observation has been noted in other domains such as Enrone-mail (Coppersmith and Priebe, 2012).
Third, the introduction of relational learning gives substantialperformance improvements over propositional learning.
For instance, the performance of content fea-tures is substantially increased in the relational case with ?users only.?
A fourth observation is that ?notall neighbors are created equal.?
In all cases, the use of information about user neighbors is substan-tially more important than hashtag neighbors.
We found that most neighborhoods contained users; thedistribution was none (11%), user only (43%), hashtag only (9%), and both (37%).7.2.2 Hand-Annotated ResultsAdditional experiments on the three labels famous, generic, and info were also performed and resultsare shown in Table 2.
Note that the small number of labels is most likely impacting two aspects ofperformance.
First, since we have a smaller training set size, best absolute AUC is typically lower thanthe verified case.
Also, in some cases performance is worse than chance showing that it is difficult togeneralize well from a small training set.
In general, though, similar trends in AUC performance aresimilar to the verified case.For both the famous and generic labels with propositional learning, we found that network-only fea-tures work substantially better than content-only features.
For info labels, content-only features areslightly better demonstrating that info is a unique case.Further examination of relational results shows similar trends to the verified user case.
Relationalmethods are superior to propositional methods.
In addition, using both network and content features ishelpful or at least not detrimental to performance.
The case of the info user class is interesting from theviewpoint of neighbors; we see that the gap in performance between hashtag-only neighbors and user-only neighbors is less than other user classes.
In terms of features appearing in the RPTs, we found thatall features were valuable in user classification.
Aggregate features were common as decision points inthe relational case.8 ConclusionsTwitter contains a rich set of social network, content, and individual user cues that give insight into usercharacteristics.
In this paper, we explored features that captured these characteristics via topic cluster-ing, offensiveness detection, and network analytics.
Additionally, we examined various classificationstrategies which used both propositional and relational methods.
Our different approaches demonstratedthat the different feature types are complementary and all indicative of user classification.
For example,finding ?interesting?
Twitter accounts (the opposite of generic users) can be accomplished with contentand network features.
This process emphasizes the fact that user classification can be accomplishedwith many strategies.
Possible future work includes performing alternative classification studies, ana-lyzing the effects of different sample sizes, extending to other languages, and predicting additional userclasses.64Table 2: Average and standard deviation AUC for detection of verified and annotated accounts.
Proposi-tional results are indicated by a ?-?
in neighborhood structure.Feature Neighborhood Verified Famous Generic InfoSets Structure AUC Avg (SD) AUC Avg (SD) AUC Avg (SD) AUC Avg (SD)Content - 0.6201 ( 0.0219 ) 0.5549 ( 0.0215 ) 0.5725 ( 0.0390 ) 0.7716 ( 0.0436 )Network - 0.6916 ( 0.0339 ) 0.7685 ( 0.0529 ) 0.7110 ( 0.0468 ) 0.6438 ( 0.0791 )Content+Network - 0.7443 ( 0.0349 ) 0.7901 ( 0.0136 ) 0.7301 ( 0.0290 ) 0.7002 ( 0.1682 )Content No Neighbors 0.5935 ( 0.0306 ) 0.5970 ( 0.1583 ) 0.5842 ( 0.1535 ) 0.4006 ( 0.1777 )Content Users Only 0.8945 ( 0.0248 ) 0.8172 ( 0.0375 ) 0.7558 ( 0.0560 ) 0.6813 ( 0.1321 )Content Hashtags Only 0.6501 ( 0.0416 ) 0.4939 ( 0.1548 ) 0.5557 ( 0.1518 ) 0.6153 ( 0.1151 )Content Users and Hashtags 0.9213 ( 0.0202 ) 0.8420 ( 0.0564 ) 0.7790 ( 0.0589 ) 0.5583 ( 0.0954 )Network No Neighbors 0.5123 ( 0.1292 ) 0.6227 ( 0.1707 ) 0.4085 ( 0.0505 ) 0.4040 ( 0.1224 )Network Users Only 0.8760 ( 0.0310 ) 0.8383 ( 0.0262 ) 0.7708 ( 0.0527 ) 0.6433 ( 0.1336 )Network Hashtags Only 0.4821 ( 0.0657 ) 0.4502 ( 0.1418 ) 0.5995 ( 0.0576 ) 0.5778 ( 0.1241 )Network Users and Hashtags 0.9091 ( 0.0257 ) 0.8437 ( 0.0157 ) 0.8014 ( 0.0559 ) 0.8038 ( 0.0760 )Content+Network No Neighbors 0.5939 ( 0.0801 ) 0.5654 ( 0.1141 ) 0.6572 ( 0.1299 ) 0.3917 ( 0.1487 )Content+Network Users Only 0.8823 ( 0.0317 ) 0.8019 ( 0.0520 ) 0.7566 ( 0.0474 ) 0.5815 ( 0.1708 )Content+Network Hashtags Only 0.6699 ( 0.0525 ) 0.4510 ( 0.1312 ) 0.5543 ( 0.0954 ) 0.4260 ( 0.2057 )Content+Network Users and Hashtags 0.9325 ( 0.0087 ) 0.8431 ( 0.0535 ) 0.7831 ( 0.0192 ) 0.8021 ( 0.0608 )ReferencesGlen A Coppersmith and Carey E Priebe.
2012.
Vertex nomination via content and context.
arXiv preprintarXiv:1201.4118.Fred Morstatter, Jurgen Pfeffer, Huan Liu, and Kathleen M Carley.
2013.
Is the sample good enough?
comparingdata from twitter?s streaming api with twitter?s firehose.
Proceedings of ICWSM.Jennifer Neville, David D. Jensen, Lisa Friedland, and Michael Hay.
2003.
Learning relational probability trees.
InLise Getoor, Ted E. Senator, Pedro Domingos, and Christos Faloutsos, editors, Proceedings of the Ninth ACMSIGKDD International Conference on Knowledge Discovery and Data Mining, pages 625?630, Washington,DC, August.
ACM Press, New York, NY.
Poster session: Research track.Marco Pennacchiotti and Ana-Maria Popescu.
2011.
A machine learning approach to twitter user classification.In ICWSM.John C. Platt.
2000.
Probabilities for SV machines.
In Alexander J. Smola, Peter L. Bartlett, Bernhard Sch?olkopf,and Dale Schuurmans, editors, Advances in Large Margin Classifiers, pages 61?74.
The MIT Press.Delip Rao, David Yarowsky, Abhishek Shreevats, and Manaswi Gupta.
2010.
Classifying latent user attributes intwitter.
In Proceedings of the 2nd international workshop on Search and mining user-generated contents, pages37?44.
ACM.Daniel M Romero, Wojciech Galuba, Sitaram Asur, and Bernardo A Huberman.
2011.
Influence and passivity insocial media.
In Machine learning and knowledge discovery in databases, pages 18?33.
Springer.Martin Rosvall and Carl T. Bergstrom.
2008.
Maps of random walks on complex networks reveal communitystructure.
Proceedings of the National Academy of Sciences.Chun-Yuan Teng and Hsin-Hsi Chen.
2006.
Detection of bloggers?
interests: using textual, temporal, and interac-tive features.
In Proceedings of the 2006 IEEE/WIC/ACM International Conference on Web Intelligence, pages366?369.
IEEE Computer Society.Shaomei Wu, Jake M Hofman, Winter A Mason, and Duncan J Watts.
2011. Who says what to whom on twitter.In Proceedings of the 20th international conference on World wide web, pages 705?714.
ACM.65
