NPtool~ a detector  o f  Eng l i sh  noun phrases  *Atro  Vout i la inenResearch Unit  for Computat iona l  L inguist icsP.O.
Box 4 (Keskuskatu  8)F IN-00014 Univers i ty  of HelsinkiF in landE-mai l :  avout i la@l ing.Hels inki .F IAbstractNPtool is a fast and accurate system for ex-tracting noun phrases from English textsfor the purposes of e.g.
information re-trieval, translation unit discovery, and cor-pus studies.
After a general introduction,the system architecture is presented in out-line.
Then follows an examination of a re-cently written Constraint Syntax.
Section 6reports on the performance of the system.1 In t roduct ionThis paper outlines NPiool, a noun phrase detector.At the heart of this modular system is reduct ion-istic word-or iented morphosyntact i c  analysisthat expresses head-modifier dependencies.
Previ-ous work on this approach, largely based on Karls-son's original proposal \[Karlsson, 1990\], is docu-mented in \[Karlsson et ai., forthcoming\].
Let us sum-marise a few key features of this style of analysis.?
As most parsing frameworks, also the presentstyle of analysis employs a lexicon and a grammar.What may distinguish the present approach frommost other frameworks i the considerable degree ofattention we pay to the morpholog ica l  nd lexicaldescr ipt ion:  morphological nalysis is based on anextensive and detailed description that employs in-flectional and central derivational categories as wellas other morphosyntactic features that can be use-ful for stating syntactic generalisations.
In this way"This paper is based on a longer manuscript with thesame title.
The development of ENGCG wLs supportedby TEKES, the Finnish Technological Development Cen-ter, ?nd a part of the work on Finite-state syntax hubeen supported by the Academy of Finland.a carefully built and informative lexicon facilitatesthe construction of accurate, wide-coverage parsinggrammars.?
We use tags to encode morphological distinc-tions, part of speech, and also syntactic information;for instance:I PRON ~ItEADsee V PRES @VERBa ART @>Nbi rd  N @HEADFULLSTOPIn this type of analysis, each word is provided withtags indicating e.g.
part of speech, inflection, deriva-tion, and syntactic function.?
Morphological and syntactic descriptions arebased on hand-coded l inguist ic rules rather thanon corpus-based statistical models.
They employstructural categories that can be found in descrip-tive grammars, e.g.
\[Quirk, Greenbaum, Leech andSvartvik, 1985\].Regarding the at times heated methodological de-bate on whether statistical or rule-based informationis to he preferred in grammatical nalysis of runningtext (cf.
e.g.
\[Sampson, 1987a; Taylor, Grover andBriscoe, 1989; Church, 1992\]), we do not object toprobabilistic methods in principle; nevertheless, itseems to us that rule-based escriptions are prefer-able bemuse they can provide for more accurate andreliable analyses than current probabilistic systems,e.g.
part-of-speech taggers \[Voutilainen, Heikkil~ andAnttila, 1992; Voutilainen, forthcoming a\].
I Proba-IConsider for instance the question posed in \[Church,1992\] whether lexical probabilities contribute more tomorphological or parLor-speech disambiguation thancontext does.
The ENGCG morphological disambigua-tor, which is entirely based on context rules, uniquely48bilistic or heuristic techniques may still be a use-ful add-on to linguistic information, if potentially re-maining ambiguities must be resolved - though witha higher risk of error.?
In the design of our grammar schemes, we havepaid considerable attention to the question on the re-solvability of grammat ica l  distinctions.
In thedesign of accurate parsers of running text, this ques-tion is very important: if the description aboundswith distinctions that can be dependably resolvedonly with extrasyntactic knowledge ~, then either theambiguities due to these distinctions remain to bur-den the structure-based parser (as well as the poten-tial application based on the analysis), or a guess,i.e.
a misprediction, has to be hazarded.This descriptive policy brings with it a certain de-gree of shal lowness;  in terms of information con-tent, a tag-based syntactic analysis is somewherebetween morphological (e.g.
part-of-speech) analysisand a conventional syntactic analysis, e.g.
a phrasestructure tree or a feature-based analysis.
What wehope to achieve with this compromise in informationcontent is the higher reliability of the proposed anal-yses.
A superior accuracy could be considered as anargument for postulating a new, 'intermediary' levelof computational syntactic description.
For more de-tails, see e.g.
\[Voutilainen and Tapanainen, 1993\].?
Our grammar  schemes are also learnable: accord-ing to double-blind experiments on manually assign-ing morphological descriptions, a 100% interjudgeagreement is typical \[Voutilainen, forthcoming a\].
3?
The ability to parse running text is of a highpriority.
Not only a structurally motivated descrip-tion is important; in the construction of the pars-ing grammars and lexica, attention should also bepaid to corpus evidence.
Often a grammar rule,as we expr~s it in our parsing grammars, is formedas a generalisation 'inspired' by corpus observations;in this sense the parsing grammar is corpus-based.However, the description need not be restricted tothe corpus observation: the linguist is likely to gen-eralise over past experience, and this is not necessar-ily harmful - as long as the generalisations can alsoand correctly identifies more than 97% of all appropriatedescriptions, and this is considerably more than the near-90% success rate achieved with lexical probabilities alone\[Church, 1992\].
Moreover, note that in all, the ENGCGdisaanbiguator identifies more than 99.5% of all appropri-ate descriptions; only, some 2-3% of all anMyses remainambiguous and thus do not become uniquely identified.For more details, see \[Voutila.inen, forthcoming 1993\].2Witness, for instance, ambiguities due to adverbialattachment or modifier scope.3The 95% interjudge agreement rate reported in\[Church, 1992\] probably indicates that in the case ofdebatable constructions, explicit descriptive conventionshave not been consistently established.
Only a carefullydefined grammar scheme makes the evaluation of the ac-curacy of the parsing system a meaningful enterprise (seealso \[Sampson, 1987b\]).be validated against representative test corpora.
* At least in a practical application, a parsinggrammar should assign the best available anal-ysis to its input rather than leave many of the inpututterances unrecognised e.g.
as ill-formed.
This doesnot mean that the concept of well-formedness is irrel-evant for the present approach.
Our point is simply:although we may consider some text utterance as de-viant in one respect or another, we may still be inter-ested in extracting as much information as possiblefrom it, rather than ignore it altogether.
To achievethis effect, the grammar rules should be used in sucha manner 4 that no input becomes entirely rejected,although the rules as such may express categoricalrestrictions on what is possible or well-formed in thelanguage.?
In our approach, parsing consists of two mainkinds of operation:i. Context-insensitive lookup of (alternative) de-scriptions for input words2.
Elimination of unacceptable or contextually il-legitimate alternatives.Morphological  analysis typically corresponds tothe lookup module: it produces the desired mor-phosyntactic analysis of the sentence, along witha number of inappropriate ones, by providing eachword in the sentence with all conventional analyses asa list of alternatives.
The grammar itself exerts therestrictions on permitted sequences of words and de-scriptors.
In other words, syntactic analysis proceedsby way of ambiguity resolution or dlsambigua-tion: the parser eliminates ill-formed readings, andwhat 'survives' the grammar is the (syntactic) anal-ysis of the input utterance.
Since the input containsthe desired analysis, no new structure will be builtdtvdng syntactic analysis itself.?
Our grammars consist of constraints - par-tim distributional definitions of morphosyntactic cat-egories, such as parts of speech or syntactic func-tions.
Each constraint expresses a piecemeal linear-precedence generalisation about the language, andthey are independent of each other.
That is, the con-straints can be applied in any order: a true grammarwill produce the same analysis, whatever the order.The grammarian is relatively free to select thelevel of abstraction at which (s)he is willing to ex-press the distributional generalisation.
In particular,also reference to very low-level categories is possi-ble, and this makes for the accuracy of the parser:while the grammar will contain more or less ab-stract, feature-oriented rules, often it is also expe-dient to state further, more particular restrictionson more particular distributional classes, even atthe word-form level.
These 'smaller' rules do notcontradict the more general rules; often it is sim-4e.g.
by ranking the graanmar ules in terms ofcompromisability49ply the case that further restrictions can be im-posed on smaller lexical classes s This flexibility inthe grammar formalism greatly contributes to theaccuracy of the parser \[Voutilainen, forthcoming a;Voutilainen, forthcoming 1993\].2 Uses  o f  a noun  phrase  parserThe recognition and analysis of subclausal structuralunits, e.g.
noun phrases, is useful for several pur-poses.
Firstly, a noun phrase detector can be usefulfor research purposes: automatic large-scale analy-sis of running text provides the linguist with bettermeans to conduct e.g.
quantitative studies over largeamounts of text.An accurate though somewhat superficial analysiscan also serve as a 'preprocessor' p ior to more ambi-tious, e.g.
feature-based syntactic analysis.
This kindof division of labour is likely to be useful for technicalreasons.
One major problem with e.g.
unification-based parsers is parsing time.
Now if a substan-tial part of the overall problem is resolved withmore simple and efficient techniques, the task of theunification-based parser will become more manage-able.
In other words, the more expressive but compu-tationally heavier machinery of e.g.
the unification-based parser can be reserved entirely for the analysisof the descriptively hardest problems.
The less com-plex parts of the overall problem can be tackled withmore simple and efficient techniques.Regarding production uses, even lower levels ofanalysis can be directly useful.
For instance, the de-tection of noun phrases can provide e.g.
informationmanagement and retrieval systems with a suitableinput for index term generation.Noun phrases can also serve as translation units;for instance, \[van der Eijk, 1993\] suggests that nounphrases are more appropriate translation units thanwords or part-of-speech lasses.3 P rev ious  workThis section consists of two subsections.
Firstly, aperformance-oriented survey of some related systemsis presented.
Then follows a more detailed presenta-tion of ENGCG, a predecessor f the NPIool parserin an information retrieval system.3.1 Re lated systemsSo far, I have found relatively little documentationon systems whose success in recognising or parsingnoun phrases has been reported.
I am aware of threesystems with some relevant evaluations.Church's Parts of speech \[Church, 1988\] performsnot only part-of-speech analysis, but it also identi-ties the most simple kinds of noun phrases - mostlysequences of determiners, premodifiers and nominalheads - by inserting brackets around them, e.g.s Consider for instance the attachment of prepositions\]phrases in general and of ofphrues in particular.\[A/AT ~former/AP top/NN a?de/NN\] to/ IN\[Attorney/NP/NP General/NP/NP Ed~in/NP/NPMeese/NP/NP\] in~erceded/VBD .
.
.The appendix in \[Church, 1988\] lists the analysis ofa small text.
The performance of the system on thetext is quite interesting: 0f243 noun phrase bracket, sonly five are omitted.
- The performance of PaNs ofspeech was also very good in part-of-speech analysison the text: 99.5% of all words got the appropri-ate tag.
The mechanism for noun phrase identifica-tion relies on the part-of-speech analysis; the part-of-speech tagger was more successful on the text thanon an average; therefore the average performance ofthe system in noun phrase identification may not bequite as good as the figures in the appendix of thepaper suggest.Bourigault's LECTER \[Bourigault, 1992\] is asurface-syntactic analyser that extracts 'maximal-length noun phrases' -mainly sequences of determin-ers, premodifiers, nominal heads, and certain kindsof postmodifying prepositional phrases and adjec-tives - from French texts for terminology applica-tions.
The system is reported to recognise 95% of allmaximal-length noun phrases (43,500 out of 46,000noun phrases in the test corpus), but no figures aregiven on how much 'garbage' the system suggests asnoun phrases.
It is indicated, however, that manualvalidation is necessary.Rausch, Norrback and Svensson \[1992\] have de-signed a noun phrase extractor that takes as its in-put part-of-speech analysed Swedish text, and insertsbrackets around noun phrases.
In the recognition of'Nuclear Noun Phrases' - sequences of determiners,premodifiers and nominal heads - the system wasable to identify 85.9% of all nuclear noun phrases in atext collection, some 6,000 words long in all, whereassome 15.7% of all the suggested noun phrases werefalse hits, i.e.
the precision t' of the system was 84.3%.The performance of a real application would proba-bly be lower because potential misanalyses due toprevious stages of analysis (morphological nalysisand part-of-speech disarnbiguation, for instance) arenot accounted for by these figures.3.2 ENGCG and the SIMPB.
pro jectSIMPR, Structured Information Management: Pro-cessing and Retrieval, was a 64 person year ESPRITII project (Nr.
2083, 1989-1992), whose objectivewas to develop new methods for the managementand retrieval of large amounts of electronic texts.
Acentral function of such a system is to recognise thosewords in the stored texts that represent i in a con-cise fashion - in short, index terms.Term indices created with traditional methods 7are based on isolated, perhaps truncated words.eFor definitions of the terms recall and preciJion, seeSection 6.7See e.g.
\[Stlton and McGill, 1983\].50These largely string-based statistical methods aresomewhat unsatisfactory because many content iden-tifiers consist of word sequences - compounds, head-modifier constructions, even simple verb - nounphrase sequences.
One of the SIMPR objectiveswas also to employ more complex constructions, therecognition of which would require a shallow gram-matical analysis.
The Research Unit for Computa-tional Linguistics at the University of Helsinki par-ticipated in this project, and ENGTWOL, a Twol-styled morphological analyser as well as ENGCG,a Constraint Grammar  of English, were written1989-1992 by Voutilainen, Heikkil~i and Anttila\[forthcoming\].
The resultant S IMPR system is animprovement over previous systems \[Smart (Ed.
),forthcoming\] - it is not only reasonably accurate, butalso it operates on more complex constructions, e.g.postmodifying constructions and simple verb-objectconstructions.There were also some persistent problems.
Theoriginal plan was to use the output of the wholeENGCG parser for the indexing module.
However,the last module of the three sequential modules inthe ENGCG grammar, namely Constraint Syntaxproper, was not used in the more mature versions ofthe indexing module - only lexical analysis and mor-phological disambiguation were applied.
The omis-sion of the syntactic analysis was mainly due to thesomewhat high error rate (3--4% of all words lost theproper syntactic tag) and the high rate of remainingambiguities (15-25% of all words remained syntacti-cally ambiguous.Here, we will not go into a detailed analysis of theproblems s, suffice it to say that the syntactic gram-mar scheme was unnecessarily ambitious for the rela-tively simple needs of the indexing application.
Oneof the improvements in NPtoal is a more optimal syn-tactic grammar scheme, as will be seen in Section 5.1.4 NPtool  in  out l ineIn this section, the architecture of NPtool is pre-sented in outline.
Here is a flow chart of the system:Preprocess ingVMorphological analysisVConstra int  Grammar pars ing%/ VNP-hostile finite IP-friendly finitestate pars ing state pars ingV VIP extraction liP extractionV VI n te rsect ion  of noun phrase setsSSee e.g.
\[VoutLla/aen, Heikkil?
and AnttAIa, 1992\] fordetails.In the rest of this section, we will observe the analysisof the following sample sentence, taken from a carmaintenance manual:The ~n\]e~ and exhaust manifolds are mountedon opposi te s ides of the cy l inder  head, theexhaust manifold channelling the gases to asingle exhaust pipe and silencer system.4.1 Preprocessing and morphologicalanalysisThe input ASCII text, preferably SGML-annotated,is subjected to a preprocessor that e.g.
determinessentence boundaries, recognises fixed syntagms 9,normalises certain typographical conventions, andverticalises the text.This preprocessed text is then submitted to mor-phological analysis.
ENGTWOL, a morphologicalanalyser of English, is a Koskenniemi-style morpho-logical description that recognises all inflections andcentral derivative forms of English.
The presentlexicon contains some 56,000 word stems, and al-together the analyser ecognises several hundreds ofthousands of different word-forms.
The analyser alsoemploys a detailed parsing-oriented morphosyntac-tic description; the feature system is largely derivedfrom \[Quirk, Greenbaum, Leech and Svartvik, 1985\].Here is a small sample:("<*the>"("the" DET CENTRAL ART SG/PL (?>7)))("<inlet>"( " in le t "  N lfOM SG))("<and>"("and" cc (ecc) ) )( "<exhaust>"("exhaust" <SVO> V SUBJUNCTIVE VFIN (~V))("exhaust" <SVO> V IMP VFIN (~V))("exhaust" <SVO> V INF)("exhaust" <SVO> V PRE$ -SG3 VFIN (@V))("exhaust" N NOM SG))( "<manif olds>"("manifold" N NOM PL))All running-text word-forms are given on the left-hand margin, while all analyses are on indented linesof their own.
The multiplicity of these lines for aword-form indicates morphological mbiguity.For words not represented in the ENGTWOL lex-icon, there is a 99.5% reliable utility that assignsENGTWOL-style descriptions.
These predictionsare based on the form of the word, but also someheuristics are involved.4.2 Const ra int  Grammar  pars ingThe next main stage in NPtoei analysis is Con-straint Grammar parsing.
Parsing consists of twomain phases: morphological disambiguation andConstraint syntax.?e.g.
multiword prepositions and compounds51?
Morphological disambiguation.
The taskof the morphological disambiguator is to discard allcontextually illegitimate morphological readings inambiguous cohorts.
For instance, consider the fol-lowing fragment:("<aT"("a" <Indef> DET CESTRAL ART SG (a>S)))( "<s ingle>"("single" <SVO> V IMP VFIS (av))("single" <SVO> V IIF)("single" A ABS))Here an unambiguous determiner is directly followedby a three-ways ambiguous word, two of the analysesbeing verb readings, and one, an adjective reading.- A determiner is never followed by a verbl?
; oneof the 1,100-odd constraints in the disambiguationgrammar \[Voutilainen, forthcoming a\] expresses thisfact about English grammar; so the verb readings ofsingle are discarded here.The morphological disambiguator seldom discardsan appropriate morphological reading: after morpho-logical disambiguation, 99.7-100% of all words re-tain the appropriate analysis.
On the other hand,some 3-6% of all words remain ambiguous, e.g.head in this sentence.
There is also an additionalset of some 200 constraints - after the applicationof both constraint sets, 97-98% of all words be-come fully disambiguated, with an overall error rateof up to 0.4% \[Voutilainen, forthcoming b\].
Thepresent disambiguator compares quite favourablywith other known, typically probabilistic, disam-biguators, whose maximum error rate is as high as5%, i.e.
some 17 times as high as that of the ENGCGdisambiguator.?
Const ra in t  syntax.
After morphological dis-ambiguation, the syntactic constraints are applied.In the NPtool syntactic description, all syntactic am-biguities are introduced directly in the lexicon, sono extra lookup module is needed.
Like disambigua-tion constraints, yntactic onstraints seek to discardall contextually illegitimate syntactic function tags.Here is the syntactic analysis of our sample sentence,as produced by the current parser.
To save space,most of the morphological codes are omitted.
("<*the>"("the" O~ (?>N)))( "<in let>"("inlet" i (@>I ~NH)))("<and>"("and" CC (eCC)))( "<exhaus 1;>"("exhaust" I (@>N)))("<manifolds>"("manifold" I (aIll)))("<are>*'l?save for no, which can be followed by an -ing-form;d. no in There is no going home("be" V (av)) )("<mounted>"("mount" PCP2 (av)))( "<on>"("on" PREP (aAH)))("<opposite>"("opposite" A (a>S)))("<sides>"("s ide"  S CASH)))(*'<of>"("of" PREP (?S<)))("<the>"("the" DET (a>N)))("<cylinder>"("cylinder" I (a>s asH)))( "<head>"("head" V (av))("head" S (aSH)))(,,<$,>,')("<the>"("the" DET Ca>S)))("<exhaust>"("exhaust" N (?>S)))("<manifold>"("manifold" N (aSH)))("<channelling>"("char-el" PCP1 (av)) )("<the>'?
("the" DET (a>I) ) )("<gases>"("gas" I (aNH)))("<?o>"("to" PREP (aAH)))("<a>"("a" DET (a>I)))("<single>"( "s ing le"  A Ca>I)))("<oxhaust>"("exhaust" I Ca>I)))("<pips>"("pipe" X (aN'H)))( "<and>"("and" cc (acc)))("<silencer>"("silencer" I Ca>N)))("<system>"("system" N (@NH)))(,,<$.>,,)All syntactic-function tags are flanked with '@'.
Forinstance, the tag '@>N' indicates that the word isa determiner or a premodifier of a nominal in theright-hand context (e.g.
fhe).
The second word, in-#or, remains yntactically ambiguous due to a pre-modifier reading and a nominal head @NH reading- note that the ambiguity is structurally genuine, acoordination ambiguity.
The tag @V is reserved forverbs and auxiliaries, cf.
are as well as mounted.
Thesyntactic description will be outlined below.52Pasi Tapanainen 11has recently made a new imple-mentation of the Constraint Grammar parser thatperforms morphological disambiguation and syntac-tic analysis at a speed of more than 1,000 words persecond on a Sun SparcStation 10, Model 30.4.3 T reatment  of remain ing  ambiguit iesThe Constraint Grammar parser recognises onlyword-level ambiguities, therefore some of the trover-sale through an ambiguous entence representationmay be blatantly ill-formed.NPtool eliminates locally unacceptable analyses byusing a finite-state parser \[Tapanainen, 1991\] 1~ as akind of 'post-processing module' that distinguishesbetween competing sentence readings.
The parseremploys a small finite-state grammar that I havewritten.
The speed of the finite-state parser is com-parable to that of the Constraint Grammar parser.The finite-state parser produces all sentence read-ings that are in agreement with the grammar.
Camsider the following two adapted readings from thebeginning of our sample sentence:the/?>N inlet/?>N and/?CC exhaust/?>Nmanifolds/?NH are/BY mounted/?Von/?AH opposite/?>N sides/?NHof/@N< the/@>N cylinder/@NH head/BYthe/~>N inlet/?>N and/%CC exhaust/?>Nmanifolds/?NH axe/QV moun~ed/@Von/?AH opposite/Q>N sides/?NHof/QN< the/@>N cylinder/@>N head/?NHThe only difference is in the analysi s of cylinder head:the first analysis reports cylinder as a noun phrasehead which is followed by the verb head, while thesecond analysis considers cylinder head as a nounphrase.
Now the last remaining problem is, howto deal with ambiguous analyses like these: shouldcylinder be reported as a noun phrase, or is cylinderhead the unit to be extracted?The present system provides all proposed nounphrase candidates in the output, but each with anindication of whether the candidate noun phrase isunambiguously analysed as such, or not.
In this so-lution, I do not use all of the multiple analyses pro-posed by the finite-state parser.
For each sentence,no more than two competing analyses are selected forfurther processing: one with the highest number ofwords as part of a maximally long noun phrase anal-ysis, and the other with the lowest number of wordsas part of a maximally short noun phrase analysis.This 'weighing' can be done during finite-stateparsing: the formalism employs a mechanism for im-posing penalties on regular expressions, e.g.
on tags.nKesearch Unit for Computational Linguistics, Uni-versity of Helsinki12For other work m this approach, see also \[Kosken-niemi, 1990; Koskenniemi, Tapanalnen and Voutilainen,1992; Voutilainen and Tapanalnen, 1993\].A penalised reading is not discarded as ungrammat-ical, only the parser returns all accepted analyses inan order where the least penalised analyses are pro-duced first and the 'worst' ones last.Thus there is an 'NP-hostile' finite-state parserthat penalises noun phrase readings; this wouldprefer the sentence reading with cylinder/@NHhead/@V. The 'NP-friendly' parser, on the otherhand, penalises all readings which are not part of anoun phrase reading, so it would prefer the analysiswith eylinder/@>N head/@NIY.
Of all analyses, theselected two parses are maximally dissimilar with re-gard to NP-hood.
The motivation for selecting max-imally conflicting analyses in this respect is that acandidate noun phrase that is agreed upon as a nounphrase by the two finite-state parsers ystems just asit is - neither longer nor shorter - is likely to be anunambiguously identified noun phrase.
The compar-ison of the outputs of the two competing finite-stateparsers is carried out during the extraction phase.4.4 Ext ract ion  of noun phrasesAn unambiguous sentence reading is a linear se-quence of symbols, and extracting noun phrases fromthis kind of data is a simple pattern matching task.In the present version of the system, I have usedthe gawk program that allows the use of regular ex-pressions.
With gawk's gsub function, the bound-aries of the longest non-overlapping expressions thatsatisfy the search key can be marked.
If we formu-late our search query as something like the followingschematic regular expression:ElM>N+ \[CC M>N+\]*\]* HEADIN< \[D/M>N+ \[CC D/M>N+\]*\]* HEAD\]*\]ghere' \ [ '  and ' \ ] 'cH>JJ'D/M>N'~HF.AD JiN<,axe :for grouping,stands for  one or moreoccurrences of i t s  argument,stands for  zero  or moreoccur rences  o f  i t s  axgmnen$,stands for  p remodi f ie rs ,stands fo r  determiners  andpremodi f ie rs ,stands for  nominal headsexcept pronouns,stands fo r  p repos i t ionss tar t ing  a poszmodi fy ingprepos i t iona l  phrase,and do some additional formatting and 'cleaning',the above two finite-state analyses will look like thefollowing13:thenp: i n le t  and exhaust manifold13Note that the noun phrase heads are here ~ven inthe bLse form, hence the absence of the plural form ofe.g.
'manifold'.53are mounted onnp: opposite side of the cyl inderhead, thenp: exhaust manifoldchannelling thenp: gasto anp: single exhaust pipeandnp: silencer systemthenp: inlet and exhaust manifoldare mounted onnp: opposite side of the cylinder head, thenp: exhaust manifoldchannelling thenp: gasto anp: single exhaust pipeandnp: silencer systemThe proposed noun phrases are given on indentedlines, each marked with the symbol 'np:'.
The can-didate noun phrases are then subjected to furtherroutines: all candidate noun phrases with at leastone occurrence in the output of both the NP-hostileand NP-friendly parsers are labelled with the sym-bol 'ok:', and the remaining candidates are labelledas uncertain, with the symbol '?:'.
From the outputsgiven above, the following list can be produced:ok: in le t  and exhaust manifoldok: exhaust manifoldok: gasok: s ingle exhaust pipeok: s i lencer  system?
: opposite side of the cyl inder?
: opposite side of the cy l inder  headThe linguistic analysis is relatively neutral as towhat is to be extracted from it.
Here we have con-centrated on noun phrase extraction, but from thiskind of input, also many other types of constructioncould be extracted, e.g.
simple verb-argument struc-tures.5 The  syntact i c  descr ip t ionThis section outlines the syntactic description that Ihave written for 2gPtool purposes.
The ENGTWOLlexicon or the disambiguation constraints will not bedescribed further in this paper; they have been doc-umented extensively elsewhere (see the relevant ar-ticles in Karlsson & al.
\[forthcoming\]).According to the SIMP/t experiences, the vast ma-jority of index terms represent relatively few con-structions.
By far the most common constructionis a nominal head with optional, potentially coordi-nated premodifiers and postmodifying prepositionalphrases, typically of phrases.
The remainder, lessthan 10%, consists almost entirely of relatively sim-ple verb-NP patterns.The syntactic description used in SIMPR em-ployed some 30 dependency-oriented syntactic func-tion tags, which differentiate (to some extent) be-tween various kinds of verbal constructions, yntac-tic functions of nominal heads, and so on.
Some ofthe ambiguity that survives ENGCG parsing is inpart due to these distinctions \[Anttila, forthcoming\].The relatively simple needs of an index term ex-traction utility on the one hand, and the relativeabundance of distinctions in the ENGCG syntacticdescription on the other, suggest hat a less distinc-tive syntactic description might be more optimal forthe present purposes: a more shallow descriptionwould entail less remaining ambiguity without un-duly compromising its usefulness e.g.
for an indexingapplication.5.1 Syntact ic tagsI have designed a new syntactic grammar schemethat employs even function tags.
These tags cap-italise on the opposition between oun phrases andother constructions on the one hand, and betweenheads and modifiers, on the other.
Here we will notgo into details; a gloss with a simple illustration willsuf~ce.?
~V represents auxiliary and main verbs as wellas the infinitive marker to in both finite and non-finite constructions.
For instance:She should/?V know/@V what to/QV do/?V.?
~NH represents nominal heads, especiallynouns, pronouns, numerals, abbreviations and -ing-forms.
Note that of adjectival categories, only thosewith the morphological feature <Nominal>, e.g.
En-glish, are granted the @NH status: all other adjec-tives (and -ed-forms) are regarded as too unconven-tional nominal heads to be granted this status in thepresent description.
An example:The English/@Ne may l ike  the conventional .?
Q>N represents determiners and premodifiersof nominals (the angle-bracket '> '  indicates the di-rection in which the head is to be found).
The headis the following nominal with the tag @NH, or a pre-modifier in between.
An example:the/@>N fat/@>l| butchsr's/@>N wife?
ON< represents prepositional phrases that un-ambiguously postmodify a preceding nominal head.Such unambiguously postmodifying constructionsare typically of two types: (i) in the absence of cer-tain verbs like 'accuse', postnominal of-phrases and(ii) preverbal NP- -PP sequences, e.g.The man i n /?~< 'the moon hada g lass  of/@N< a le .54Currently the description does not account for othertypes of postmodifier, e.g.
postmodifying adjectives,numerals, other nominals, or clausal constructions.?
~CC and @CS represent co-ordinating and sub-ordinating conjunctions, respectively:Either/CCC you or/CCC I will goif/COS necessary.?
@AH represents the 'residual': adjectival heads,adverbials of various kinds, adverbs (also intensi-fiers), and also those of the prepositional phrases thatcannot be dependably analysed as a postmodifier.An example is in order:There/CAH have al~ays/?AH been very/CAHmany people in/QAH Shis area.5.2 Syntact ic  constra intsThe syntactic grammar contains ome 120 syntacticconstraints.
Like the morphological disambiguationconstraints, these constraints are essentially negativepartial linear-precedence d finitions of the syntacticcategories.The present grammar isa partial expression of fourgeneral grammar statements:1.
Part of speech determines the order of determin-ers and modifiers.2.
Only likes coordinate.3.
A determiner or a modifier has a head.4.
An auxiliary is followed by a main verb.We will give only one illustration of how thesegeneral statements can be expressed in ConstraintGrammar.
Let us give a partial paraphrase of thestatement Part of speech determines the order of de.termiuers and modifiers: 'A premodifying noun oc-curs closest o its head'.
In other words, premodifiersfrom other parts of speech do not immediately fol-low a premodifying noun.
Therefore, a noun in thenominative immediately followed by an adjective isnot a premodifier.
Thus a constraint in the grammarwould discard the @>N tag of Harry in the followingsample sentence, where Harry is directly followed byan unambiguous adjective:("<*iU>"("be" <SVC/N> <SVC/A> V PKES $G3 (@V)))( "<*harry>"( "harry"  <Proper> N N0M SG (eNH @>N)))("<foolish>"( " foo l i sh"  ?
?BS (@AH)))(,,<?
?>,,)We require that the noun in question is a nominativebecause premodifying nouns in the genitive can occuralso before adjectival premodifiers; witness Harry'sin Harry's foolish self.5.3 Eva luat ionThe present syntax has been applied to largeamounts of journalistic and technical text (news-papers, abstracts on electrical engineering, manualson car maintenance, etc.
), and the analysis of some20,000-30,000 words has been proofread to get anestimate of the accuracy of the parser.After the application of the NPtool syntax, some93-96% of all words become syntactically unambigu-ous, with an error rate of less than i% 14 .To find out how much ambiguity remains at thesentence level, I also applied a 'NP-neutral' version 15of the finite-state parser on a 25,500 word text fromThe Grolier Electronic Encyclopaedia.
The resultsare given in Figure 1.Figure 1: Ambiguity rates after finite-state parsingin a text of 1,495 sentences (25,500 words).
R in-dicates the number of analyses per sentence, and Findicates the frequency of these sentences.\ [R  F \[ IR \[ F HR I F f IR \[ F_-\]i 960 6 19 "12 6 !32 2i 2 304 7 i 3' 14 3 '48 23 54 8 28 165  64 14 93 9 3 24j 1 72 15 4 i I0 3 281 1Some 64% (960) of the 1,495 sentences becamesyntactically unambiguous, while only some 2% ofall sentences analyses contain more than ten read-ings, the worst ambiguity being due to 72 analyses.This compares favourably with the ENGCG perfor-mance: after ENGCG parsing, 23.5% of all sentencesremained ambiguous due to a number of sentencereadings greater than the worst case in NPtool syn-tax.6 Per fo rmance  o f  NPtoolVarious kinds of metrics can be proposed for the eval-uation of a noun phrase extractor; our main metricsare recal l  and precis ion, defined as followslU:?
Recall: the ratio 'retrieved intended NPs '17 /'all intended NPs'?
Precision: the ratio 'all retrieved NPs' / 're-trieved intended NPs'14This figure also covers errors due to previous stagesof analysis.zSi.e.
?
parser which does not contain the mechanismfor penalising or fsvouring noun phrue analyses; ee Sec-tion 4.3 ?hove.16Thls definition also agrees with that used in Rauschk al.
\[1992\].17An 'intended NP' is the longest non-overlappingmatch of the ?eaxch query given in extraction phue.55To paraphrase, a recall of less than 100% indicatesthat the system missed some of the desired nounphrases, while a precision of less than 100% indicatesthat the system retrieved something that is not re-garded as a correct result.The performance of the whole system has beenevaluated against several texts from different do-mains.
In all, the analysis of some 20,000 words hasbeen manually checked.If we wish to extract relatively complex nounphrases with optional coordination, premodifiers andpostmodifiers ( ee the search query above in Sec-tion 4.4), we reach a recall of 98.5-100%, with aprecision of some 95-98%.As indicated in Section 4.4, the extraction utilityannotates each proposed noun phrase as a 'sure hit'('ok:') or as an 'uncertain hit' ('?:').
This distinctionis quite useful for manual validation: approximately95% of all superfluous noun phrase candidates aremarked with the question mark.7 Conc lus ionIn terms of accuracy, NPtool is probably one of thebest in the field.
In terms of speed, much remains tobe optimised.
Certainly the computationally mostdemanding tasks - disambiguation a d parsing - arealready carried out quite efficiently, but the moretrivial parts of the system could be improved.8 AcknowledgementsI wish to thank Krister Linden, Pasi Tapanainen andtwo anonymous referees for useful comments on anearlier version of this paper.
The usual disclaimershold.References\[Anttila, fortheoming\] Anttila, A.
(forthcoming).How to recognise subjects in English.
In Karlsson& at.\[Bourigault, 1992\] Bourigault, D. 1992.
Surfacegrammatical analysis for the extraction of termi-nological noun phrases.
In Proceedings of the fif-teenth International Conference on ComputationalLinguistics.
COLING-g2, Vol.
IIL Nantes, France.977-981.\[Church, 1988\] Church, K. 1988.
A Stochastic PartsProgram and Noun Phrase Parser for UnrestrictedText.
Proceedings ofthe Second Conference on Ap-plied Natural Language Processing, ACL.
136-143.\[Church, 1992\] Church, K. 1992.
Current Practice inPart of Speech Tagging and Suggestions for theFuture, in Simmons (ed.
), Sboruik praci: In Honorof Henry Ku~era.
Michigan Slavic Studies.\[van der Eijk, 1993\] van der Eijk, P. 1993.
Automat,-ing the acquisition of bilingual terminology.
Pro-ceedings of EACL'93.
Utrecht, The Netherlands.\[Heikkil~i, forthcoming a\] Heikkil~i, J.
(forthcominga).
A TWOL-Based Lexicon and Feature Systemfor English.
In Karlsson & at.\[Heikkil~, forthcoming b\] Heikkil~i, J.
(forthcomingb).
ENGTWOL English lexicon: solutions andproblems.
In Karlsson & al.\[Karlsson, 1990\] Karlsson, F. 1990.Constraint Grammar as a Framework for Pars-ing Running Text.
In H. Karlgren (ed.
), Paperspresented to the 13th International Conference onComputational Linguistics, Vol.
3.
Helsinki.
168-173.\[Karlsson, forthcoming\] Karlsson, F. (forthcoming).Designing a parser for unrestricted text.
In Karls-son & at.\[Karlsson et al, forthcoming\] Karlsson, F., Vouti-lainen, A., Heikkil~i, J. and Anttila, A. Con-straint Grammar: a Language-Independent Sys-tem for Parsing Unrestricted Tezt.
Mouton deGruyter.\[Koskenniemi, 1990\] Koskenniemi,K.
(1990).
Finite-state parsing and disambigua-tion.
In Karlgren, H.
(ed.)
COLING-90.
Paperspresented to the 13th International Conference onComputational Linguistics, Vol.
2.
Helsinki, Fin-land.
229-232.\[Koskenniemi, Tapanainen and Voutilainen, 1992\]Koskenniemi, K., Tapanainen, P. and Voutilainen,A.
(1992).
Compiling and using finite-state syn-tactic rules.
In Proceedings of the fifteenth later-national Conference on Computational Linguist-ics.
COLING-9~, Vol.
L Nantes, France.
156-162.\[Quirk, Greenbaum, Leech and Svartvik, 1985\]Quirk, R., Greenbanm, S., Leech, G. and Svartvik,J.
1985.
A Comprehensive Grammar of the EnglishLanguage.
London & New York: Longman.\[Bausch, Norrhack and Svensson, 1992\] Bausch, B.,Norrback, R., and Svensson, T. 1992.
Excerper-ing av nominMfraser u  15pande text.
Manuscript.Stockholms universitet, Institutionen F6r Lingvis-tik.\[Salton and McGill, 1983\] SMton, G. and McGill,M.
1983.
Introduction to Modern Information Re-trieval.
McGraw-Hill, Auckland.\[Sampson, 1987a\] Sampson, G. 1987.
ProbabilisticModels of Analysis.
In Garside, Leech and Samp-son (eds.)
1987.
16-29.\[Sampson, 1987b\] Sampson, G. 1987.
The grammat-ical database and parsing scheme.
In Garside,Leech and Sampson (eds.)
1987.82-96.\[Smart (Ed.
), forthcoming\] Smart (Ed.)
(forthcom-ing).
Structured Information Management: Pro-cessing and Retrieval.
(provisional title).56\[Tapanainen, 1991\] Tapanainen, P. 1991..~.grellisin~.automaatteina esitettyjen kielioppis~?~.ntSjen so-veltaminen luonnollisen kielen j~ent~.j~.s.sg (Nat-ural language parsing with finite-state syntacticrules).
Master's thesis.
Dept.
of computer science,University of Helsinki.\[Taylor, Graver and Briscoe, 1989\] Taylor, L., Gra-ver, C. and Briscoe, T. 1989.
The Syntactic Regu-larity of English Noun Phrases.
In Proceedings ofthe Fourth Conference of the European Chapter ofthe ACL.
256-263.\[Voutilainen, forthcoming a\] Voutilainen, A.
(forth-coming a).
Context-sensitive disambiguation.
InKarlsson & al.\[Voutilainen, forthcoming b\] Voutilainen, A.
(forth-coming b).
Experiments with heuristics.
In Karls-son & al.\[Voutilainen, forthcoming 1993\]Voutilainen, A.
(forthcoming 1993).
Designing aparsing grammar.\[Voutilainen, Heikkil~i and Anttila, 1992\]Voutilainen, A., Heikkil~, J. and Anttila, A.(1992).
Constraint Grammar of English: APerformance.Oriented Introduction.
PublicationNo.
21, Department of General Linguistics, Uni-versity of Helsinki.\[Voutilainen and Tapanainen, 1993\] Voutilninen, A.and Tapanainen, P. 1993.
Ambiguity resolution ina reductionistic parser.
Proceedings of EACL'93.Utrecht, Holland.APPENDIXHere is given the NPtool analysis of a small samplefrom the CACM text collection.
- Here is the inputtext:The binary number system o f fe rs  manyadvantages over a decimal representat ionfo r  a high-performance, general -purposecomputer.
The greater simplicity of abinary arithmetic unit and the greatercompactness of b inary numbers bothcont r ibute  d i rec t ly  to ar i thmet icspeed.
Less obvious and perhaps moreimportant is  the ray binary addressingand ins t ruct ion  formats can increase theovera l l  performance.
Binary addressesare also essent ia l  to cer ta in  poeerfu loperat ions which are not p ract i ca l  e i thdecimal ins t ruct ion  formats.
On the otherhand, decimal numbers are essent ia l  fo rcommunicating betgeen man and thecomputer.
In app l icat ions  requi r ing  theprocess ing of  a la rge  vo lume o fi nherent ly  decimal input and outputdata,  the time fo r  decimal-binaryconversion eeded by a purely binarycomputer may be significant.
?
slowerdecimal adder may take less time thana fast binary adder doing an additionand 'two conversions.
A careful reviewof the significance of decimal andbinary addressing and both binaryand decimal data ar i thmet ic ,supplemented by efficientconversion instructions.Here is the list of noun phrases extracted by NPtool.For the key, see Section 4.4.ok: addit ionok: advantageok: app l icat ionok: ar i thmet ic  speedok: binary addressok: binary addressingok: binary and decimal data ar i thmet icok: binary computerok: binary number systemok: carefu l  review of the s ign i f i canceof decimal and binary addressingok: certain powerful operationok: computerok: decimal instruction formatok: decimal numberok: decimal representationok: decimal-binary conversionok: efficient conversion instructionok:  fas t  binary adderok:  high-performance, general -purposecomputerok:  Ereater  compactness of binary numberok:  greater  s impl i c i ty  of a binaryarithmetic tulitok: instruction formatok:  manok:  overa l l  performanceok:  slower decimal adderok:  timeok:  two conversionok:  ray?
: communicatin E?
:  processing of a la rge volume ofinherent ly  decimal input?
:  processing of a large vo lume o f~-herent ly  decimal input andoutput  data?
: output  data57
