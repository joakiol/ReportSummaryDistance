Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 289?292,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPAutomatic Cost Estimation for Tree Edit Distance Using Particle SwarmOptimizationYashar MehdadUniversity of Trento and FBK - IrstTrento, Italymehdad@fbk.euAbstractRecently, there is a growing interest inworking with tree-structured data in differ-ent applications and domains such as com-putational biology and natural languageprocessing.
Moreover, many applicationsin computational linguistics require thecomputation of similarities over pair ofsyntactic or semantic trees.
In this context,Tree Edit Distance (TED) has been widelyused for many years.
However, one of themain constraints of this method is to tunethe cost of edit operations, which makesit difficult or sometimes very challengingin dealing with complex problems.
In thispaper, we propose an original method toestimate and optimize the operation costsin TED, applying the Particle Swarm Op-timization algorithm.
Our experiments onRecognizing Textual Entailment show thesuccess of this method in automatic esti-mation, rather than manual assignment ofedit costs.1 IntroductionAmong many tree-based algorithms, Tree EditDistance (TED) has offered many solutions forvarious NLP applications such as information re-trieval, information extraction, similarity estima-tion and textual entailment.
Tree edit distance isdefined as the minimum costly set of basic oper-ations transforming one tree to another.
In com-mon, TED approaches use an initial fixed cost foreach operation.Generally, the initial assigned cost to each editoperation depends on the nature of nodes, appli-cations and dataset.
For example the probabil-ity of deleting a function word from a string isnot the same as deleting a symbol in RNA struc-ture.
According to this fact, tree comparison maybe affected by application and dataset.
A solu-tion to this problem is assigning the cost to eachedit operation empirically or based on the expertknowledge and recommendation.
These methodsemerge a critical problem when the domain, fieldor application is new and the level of expertise andempirical knowledge is very limited.Other approaches towards this problem tried tolearn a generative or discriminative probabilisticmodel (Bernard et al, 2008) from the data.
Oneof the drawbacks of those approaches is that thecost values of edit operations are hidden behindthe probabilistic model.
Additionally, the cost cannot be weighted or varied according to the treecontext and node location.In order to overcome these drawbacks, we areproposing a stochastic method based on ParticleSwarm Optimization (PSO) to estimate the cost ofeach edit operation based on the user defined ap-plication and dataset.
A further advantage of themethod, besides automatic learning of the opera-tion costs, is to investigate the cost values in orderto better understand how TED approaches the ap-plication and data in different domains.As for the experiments, we learn a model forrecognizing textual entailment, based on TED,where the input is a pair of strings represented assyntactic dependency trees.
Our results illustratethat optimizing the cost of each operation can dra-matically affect the accuracy and achieve a bettermodel for recognizing textual entailment.2 Tree Edit DistanceTree edit distance measure is a similarity metricfor rooted ordered trees.
Assuming that we havetwo rooted and ordered trees, it means that onenode in each tree is assigned as a root and thechildren of each node are ordered.
The edit op-erations on the nodes a and b between trees aredefined as: Insertion (?
?
a), Deletion (a ?
?
)and Substitution (a ?
b).
Each edit operation has289an associated cost (denoted as ?
(a ?
b)).
Anedit script on two trees is a sequence of edit op-erations changing a tree to another.
Consequently,the cost of an edit script is the sum of the costs ofits edit operations.
Based on the main definitionof this approach, TED is the cost of minimum costedit script between two trees (Zhang and Shasha,1989).In the classic TED, a cost value is assigned toeach operation initially, and the distance is com-puted based on the initial cost values.
Consideringthat the distance can vary in different domains anddatasets, converging to an optimal set of values foroperations is almost empirically impossible.
Inthe following sections, we propose a method forestimating the optimum set of values for opera-tion costs in TED algorithm.
Our method is builton adapting the PSO optimization approach as asearch process to automate the procedure of costestimation.3 Particle Swarm OptimizationPSO is a stochastic optimization technique whichwas introduced recently based on the social be-haviour of bird flocking and fish schooling (Eber-hart et al, 2001).
PSO is one of the population-based search methods which takes advantage ofthe concept of social sharing of information.
Inthis algorithm each particle can learn from the ex-perience of other particles in the same population(called swarm).
In other words, each particle inthe iterative search process would adjust its fly-ing velocity as well as position not only based onits own acquaintance but also other particles?
fly-ing experience in the swarm.
This algorithm hasfound efficient in solving a number of engineeringproblems.
PSO is mainly built on the followingequations.Xi= Xi+ Vi(1)Vi= ?Vi+ c1r1(Xbi?Xi)+ c2r2(Xgi?Xi) (2)To be concise, for each particle at each itera-tion, the position Xi(Equation 1) and velocity Vi(Equation 2) is updated.
Xbiis the best positionof the particle during its past routes and Xgiisthe best global position over all routes travelledby the particles of the swarm.
r1and r2are ran-dom variables drawn from a uniform distributionin the range [0,1], while c1and c2are two accel-eration constants regulating the relative velocitieswith respect to the best local and global positions.The weight ?
is used as a tradeoff between theglobal and local best positions.
It is usually se-lected slightly less than 1 for better global explo-ration (Melgani and Bazi, 2008).
Position opti-mally is computed based on the fitness functiondefined in association with the related problem.Both position and velocity are updated during theiterations until convergence is reached or iterationsattain the maximum number defined by the user.4 Automatic Cost Optimization for TEDIn this section we proposed a system for estimat-ing and optimizing the cost of each edit operationfor TED.
As mentioned earlier, the aim of this sys-tem is to find the optimal set of operation costs to:1) improve the performance of TED in differentapplications, and 2) provide some information onhow different operations in TED approach an ap-plication or dataset.
In order to obtain this, thesystem is developed using an optimization frame-work based on PSO.4.1 PSO SetupOne of the most important steps in applying PSOis to define a fitness function, which could leadthe swarm to the optimized particles based on theapplication and data.
The choice of this functionis very crucial since, based on this, PSO evalu-ates the quality of each candidate particle for driv-ing the solution space to optimization.
Moreover,this function should be, possibly, application anddata independent, as well as flexible enough to beadapted to the TED based problems.
With the in-tention of accomplishing these goals, we definetwo main fitness functions as follows:1) Bhattacharyya Distance: This statisticalmeasure determines the similarity of two discreteprobability distributions (Bhattacharyya, 1943).In classification, this method is used to mea-sure the distance between two different classes.Put it differently, maximizing the Bhattacharyyadistance would increase the separability of twoclasses.2) Accuracy: By maximizing the accuracy ob-tained from 10 fold cross-validation on the devel-opment set, as the fitness function, we estimate theoptimized cost of the edit operations.2904.2 Integrating TED with PSOThe procedure to estimate and optimize the costof edit operations in TED applying the PSO algo-rithm, is as follows.a) Initialization1) Generate a random swarm of size n (cost ofedit operations).2) For each position of the particle from theswarm, obtain the fitness function value.3) Set the best position of each particle with itsinitial position (Xbi).b) Search4) Detect the best global position (Xgi) in theswarm based on maximum value of the fit-ness function over all explored routes.5) Update the velocity of each particle (Vi).6) Update the position of each particle (Xi).7) For each candidate particle calculate the fit-ness function.8) Update the best position of each particle ifthe current position has a larger value.c) Convergence9) Run till the maximum number of iteration(in our case set to 10) is reached or start thesearch process.5 Experimental DesignOur experiments were conducted on the basis ofRecognizing Textual Entailment (RTE) datasets1.Textual Entailment can be explained as an associ-ation between a coherent text(T) and a languageexpression, called hypothesis(H).
The entailmentfunction for the pair T-H returns the true valuewhen the meaning of H can be inferred from themeaning of T and false otherwise.
In anotherword, Textual Entailment can be defined as hu-man reading comprehension task.
One of the ap-proaches to textual entailment problem is based onthe distance between T and H.In this approach, the entailment score for a pairis calculated on the minimal set of edit operationsthat transform T into H. An entailment relation isassigned to a T-H pair in the case that overall costof the transformations is below a certain thresh-old.
The threshold, which corresponds to tree edit1http://www.pascal-network.org/Challenges/RTE1-4distace, is empirically estimated over the dataset.This method was implemented by (Kouylekov andMagnini, 2005), based on TED algorithm (Zhangand Shasha, 1989).
Each RTE dataset includesits own development and test set, however, RTE-4was released only as a test set and the data fromRTE-1 to RTE-3 were exploited as developmentset for evaluating RTE-4 data.In order to deal with TED approach to textualentailment, we used EDITS2package (Edit Dis-tance Textual Entailment Suite) (Magnini et al,2009).
In addition, We partially exploit JSwarm-PSO3package with some adaptations as an im-plementation of PSO algorithm.
Each pair in thedatasets converted to two syntactic dependencytrees using Stanford statistical parser4, developedin the Stanford university NLP group by (Kleinand Manning, 2003).We conducted six different experiments in twosets on each RTE dataset.
The costs were esti-mated on the training set, then we evaluate the es-timated costs on the test set.
In the first set of ex-periments, we set a simple cost scheme based onthree operations.
Implementing this cost scheme,we expect to optimize the cost of each edit opera-tion without considering that the operation costsmay vary based on different characteristics of anode, such as size, location or content.
The resultswere obtained using: 1) The random cost assign-ment, 2) Assigning the cost based on the exper-tise knowledge and intuition (So called Intuitive),and 3) Automatic estimated and optimized cost foreach operation.
In the second case, we applied thesame cost values which was used in EDITS by itsdevelopers (Magnini et al, 2009).In the second set of experiments, we tried totake advantage of an advanced cost scheme withmore fine-grained operations to assign a weight tothe edit operations based on the characteristics ofthe nodes (Magnini et al, 2009).
For example if anode is in the list of stop-words, the deletion costshould be different from the cost of deleting a con-tent word.
By this intuition, we tried to optimize 9specialized costs for edit operations (A swarm ofsize 9).
At each experiment, both fitness functionswere applied and the best results were chosen forpresentation.2http://edits.fbk.eu/3http://jswarm-pso.sourceforge.net/4http://nlp.stanford.edu/software/lex-parser.shtml291Data setModel RTE4 RTE3 RTE2 RTE1SimpleRandom 49.6 53.62 50.37 50.5Intuitive 51.3 59.6 56.5 49.8Optimized 56.5 61.62 58 58.12Adv.Random 53.60 52.0 54.62 53.5Intuitive 57.6 59.37 57.75 55.5Optimized 59.5 62.4 59.87 58.62Baseline 57.19RTE-4 Challenge 57.0Table 1: Comparison of accuracy on all RTEdatasets based on optimized and unoptimized costschemes.6 ResultsOur results are summarized in Table 1.
We showthe accuracy gained by a distance-based base-line for textual entailment (Mehdad and Magnini,2009) in compare with the results achieved by therandom, intuitive and optimized cost schemes us-ing EDITS system.
For the better comparison,we also present the results of the EDITS system(Cabrio et al, 2008) in RTE-4 challenge usingcombination of different distances as features forclassification (Cabrio et al, 2008).Table 1 shows that, in all datasets, accuracy im-proved up to 9% by optimizing the cost of eachedit operation.
Results prove that, the optimizedcost scheme enhances the quality of the systemperformance even more than the cost scheme usedby the experts (Intuitive cost scheme).
Further-more, using the fine-grained and weighted costscheme for edit operations we could achieve thehighest results in accuracy.
Moreover, by explor-ing the estimated optimal cost of each operation,we could find even some linguistics phenomenawhich exists in the dataset.
For instance, in mostof the cases, the cost of deletion was estimatedzero, which shows that deleting the words fromthe text does not effect the distance in the entail-ment pairs.
In addition, the optimized model canreflect more consistency and stability (from 58 to62 in accuracy) than other models, while in unop-timized models the result varies more, on differentdatasets (from 50 in RTE-1 to 59 in RTE-3).7 ConclusionIn this paper, we proposed a novel approach for es-timating the cost of edit operations in TED.
Thismodel has the advantage of being efficient andmore transparent than probabilistic approaches aswell as having less complexity.
The easy imple-mentation of this approach, besides its flexibility,makes it suitable to be applied in real world appli-cations.
The experimental results on textual entail-ment, as one of the challenging problems in NLP,confirm our claim.AcknowledgmentsBesides my special thanks to F. Melgani, B.Magnini and M. Kouylekov for their academic andtechnical support, I acknowledge the reviewers fortheir comments.
The EDITS system has been sup-ported by the EU-funded project QALL-ME (FP6IST-033860).ReferencesM.
Bernard, L. Boyer, A. Habrard, and M. Sebban.2008.
Learning probabilistic models of tree edit dis-tance.
Pattern Recogn., 41(8):2611?2629.A.
Bhattacharyya.
1943.
On a measure of diver-gence between two statistical populations defined byprobability distributions.
Bull.
Calcutta Math.
Soc.,35:99109.E.
Cabrio, M. Kouylekovand, and B. Magnini.
2008.Combining specialized entailment engines for rte-4.In Proceedings of TAC08, 4th PASCAL ChallengesWorkshop on Recognising Textual Entailment.R.
C. Eberhart, Y. Shi, and J. Kennedy.
2001.
SwarmIntelligence.
The Morgan Kaufmann Series in Arti-ficial Intelligence.D.
Klein and C. D. Manning.
2003.
Fast exact in-ference with a factored model for natural languageparsing.
In Advances in Neural Information Pro-cessing Systems 15, Cambridge, MA.
MIT Press.M.
Kouylekov and B. Magnini.
2005.
Recognizingtextual entailment with tree edit distance algorithms.In PASCAL Challenges on RTE, pages 17?20.B.
Magnini, M. Kouylekov, and E. Cabrio.
2009.
Edits- Edit Distance Textual Entailment Suite User Man-ual.
Available at http://edits.fbk.eu/.Y.
Mehdad and B. Magnini.
2009.
A word overlapbaseline for the recognizing textual entailment task.Available at http://edits.fbk.eu/.F.
Melgani and Y. Bazi.
2008.
Classification of elec-trocardiogram signals with support vector machinesand particle swarm optimization.
IEEE Transac-tions on Information Technology in Biomedicine,12(5):667?677.K.
Zhang and D. Shasha.
1989.
Simple fast algorithmsfor the editing distance between trees and relatedproblems.
SIAM J.
Comput., 18(6):1245?1262.292
