Proceedings of the Third Workshop on Statistical Machine Translation, pages 107?110,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsLIMSI?s statistical translation systems for WMT?08Daniel D?chelotte, Gilles Adda, Alexandre Allauzen, H?l?ne Bonneau-Maynard,Olivier Galibert, Jean-Luc Gauvain, Philippe Langlais?
and Fran?ois YvonLIMSI/CNRSfirstname.lastname@limsi.frAbstractThis paper describes our statistical machinetranslation systems based on the Moses toolkitfor the WMT08 shared task.
We address theEuroparl and News conditions for the follow-ing language pairs: English with French, Ger-man and Spanish.
For Europarl, n-best rescor-ing is performed using an enhanced n-gramor a neuronal language model; for the Newscondition, language models incorporate extratraining data.
We also report unconvincing re-sults of experiments with factored models.1 IntroductionThis paper describes our statistical machine trans-lation systems based on the Moses toolkit for theWMT 08 shared task.
We address the Europarl andNews conditions for the following language pairs:English with French, German and Spanish.
For Eu-roparl, n-best rescoring is performed using an en-hanced n-gram or a neuronal language model, andfor the News condition, language models are trainedwith extra training data.
We also report unconvinc-ing results of experiments with factored models.2 Base System architectureLIMSI took part in the evaluations on Europarl dataand on News data, translating French, German andSpanish from and to English, amounting a totalof twelve evaluation conditions.
Figure 1 presentsthe generic overall architecture of LIMSI?s transla-tion systems.
They are fairly standard phrase-based?Univ.
Montr?al, felipe@iro.umontreal.caOtherTargettextTargettextMosestextSource orTranslation model 4g language model 4g language modeland extractionRescoring$n$?besttranslationsLM InterpolationPhrase pairextraction Neural networkoror+ News Co.EuroparlEuroparl EuroparlNews Co.sourcesFigure 1: Generic architecture of LIMSI?s SMT systems.Depending on the condition, the decoder generates ei-ther the final output or n-best lists.
In the latter case,the rescoring incorporates the same translation features,except for a better target language model (see text).translation systems (Och and Ney, 2004; Koehn etal., 2003) and use Moses (Koehn et al, 2007) tosearch for the best target sentence.
The search usesthe following models: a phrase table, providing 4scores and a phrase penalty, a lexicalized reorderingmodel (7 scores), a language model score and a wordpenalty.
These fourteen scores are weighted and lin-early combined (Och and Ney, 2002; Och, 2003);their respective weights are learned on developmentdata so as to maximize the BLEU score.
In the fol-lowing, we detail several aspects of our systems.2.1 Translation modelsThe translation models deployed in our systems forthe europarl condition were trained on the providedEuroparl parallel data only.
For the news condition,they were trained on the Europarl data merged with107the news-commentary parallel data, as depicted onFigure 1.
This setup was found to be more favor-able than training on Europarl data only (for obviousmismatching domain reasons) and than training onnews-commentary data only, most probably becauseof a lack of coverage.
Another, alternative way ofbenefitting from the coverage of the Europarl corpusand the relevance of the news-commentary corpusis to use two phrase-tables in parallel, an interest-ing feature of Moses.
(Koehn and Schroeder, 2007)found that this was the best way to ?adapt?
a transla-tion system to the news-commentary task.
These re-sults are corroborated in (D?chelotte, 2007)1 , whichadapts a ?European Parliament?
system using a ?Eu-ropean and Spanish Parliaments?
development set.However, we were not able to reproduce those find-ings for this evaluation.
This might be caused by theincrease of the number of feature functions, from 14to 26, due to the duplication of the phrase table andthe lexicalized reordering model.2.2 Language Models2.2.1 Europarl language modelsThe training of Europarl language models (LMs)was rather conventional: for all languages used inour systems, we used a 4-gram LM based on theentire Europarl vocabulary and trained only on theavailable Europarl training data.
For French, forinstance, this yielded a model with a 0.2 out-of-vocabulary (OOV) rate on our LM development set,and a perplexity of 44.9 on the development data.For French also, a more accurate n-gram LM wasused to rescore the first pass translation; this largermodel includes both Europarl and giga word corpusof newswire text, lowering the perplexity to 41.9 onthe development data.2.2.2 News language modelsFor this condition, we took advantage of the apriori information that the test text would be ofnewspaper/newswire genre and from the November-december 2007 period.
We consequently built muchlarger LMs for translating both to French and to En-glish, and optimized their combination on appropri-1(D?chelotte, 2007) further found that giving an increasedweight to the small in-domain data could out-perform the setupwith two phrase-tables in parallel.
We haven?t evaluated thisidea for this evaluation.ate source of data.
For French, we interpolated fivedifferent LMs trained on corpus containing respec-tively newspapers, newswire, news commentary andEuroparl data, and tuned their combination with textdownloaded from the Internet.
Our best LM had anOOV rate of about 2.1% and a perplexity of 111.26on the testset.
English LMs were built in a similarmanner, our largest model combining 4 LMs fromvarious sources, which, altogether, represent about850M words.
Its perplexity on the 2008 test set wasapproximately 160, with an OOV rate of 2.7%.2.2.3 Neural network language modelsNeural-Network (NN) based continuous spaceLMs similar to the ones in (Schwenk, 2007) werealso trained on Europarl data.
These networks com-pute the probabilities of all the words in a 8192 wordoutput vocabulary given a context in a larger, 65000-word vocabulary.
Each word in the context is firstassociated with a numerical vector of dimension 500by the input layer.
The activity of the 500 neurons inthe hidden layer is computed as the hyperbolic tan-gent of the weighted sum of these vectors, projectingthe context into a [?1, 1] hypercube of dimension500.
Final projection on a set of 8192 output neuronsyields the final probabilities through a softmax-ed,weighted sum of the coordinates in the hypercube.The final NN-based model is interpolated with themain LM model in a 0.4-0.6 ratio, and yields a per-plexity reduction of 9% relative with respect to then-gram LM on development data.2.3 Tuning procedureWe use MERT, distributed with the Moses decoder,to tune the first pass of the system.
The weightswere adjusted to maximize BLEU on the develop-ment data.
For the baseline system, a dozen Mosesruns are necessary for each MERT optimization, andseveral optimization runs were started and comparedduring the system?s development.
Tuning was per-formed using dev2006 for the Europarl task and onNews commentary dev2007 for the news task.2.4 Rescoring and post processingFor the Europarl condition, distinct 100 best trans-lations from Moses were rescored with improvedLMs: when translating to French, we used theFrench model described in section 2.2.1; when108Es-En En-Es Fr-En En-Frbaseline 32.21 31.62 32.41 29.31Limsi 32.49 31.23 32.62 30.27Table 1: Comparison of two tokenization policiesAll results on Europarl test2007CI system CS systemEn?Fr 27.23 27.55Fr?En 30.96 30.98Table 2: Effect of training on true case texts, for Englishto French (case INsensitive BLEU scores, untuned sys-tems, results on test2006 dataset)translating to English, we used the neuronal LM de-scribed in section 2.2.3.For all the ?lowcase?
systems (see below), recase-ing was finally performed using our own recaseingtool.
Case is restored by creating a word graph al-lowing all possible forms of caseing for each wordand each component of a compound word.
Thisword graph is then decoded using a cased 4-gramLM to obtain the most likely form.
In a final step,OOV words (with respect to the source languageword list) are recased to match their original form.3 Experiments with the base system3.1 Word tokenization and caseWe developed our own tokenizer for English, Frenchand Spanish, and used the baseline tokenizer forGerman.
Experiments on the 2007 test dataset forEuroparl task show the impact of the tokenizationon the BLEU scores, with 3-gram LMs.
Results arealways improved with our own tokenizer, except forEnglish to Spanish (Table 1).Our systems were initially trained on lowercasetexts, similarly to the proposed baseline system.However, training on true case texts proved bene-ficial when translating from English to French, evenwhen scoring in a case insensitive manner.
Table 2shows an approximate gain of 0.3 BLEU for that di-rection, and no impact on French to English perfor-mance.
Our English-French systems are thereforecase sensitive.3.2 Language ModelsFor Europarl, we experimented with LMs of increas-ing orders: we found that using a 5-gram LM onlyyields an insignificant improvement over a 4-gramLM.
As a result, we used 4-gram LMs for all ourfirst pass decodings.
For the second pass, the useof the Neural Network LMs, if used with an appro-priate (tuned) weight, yields a small, yet consistentimprovement of BLEU for all pairs.Performance on the news task are harder to ana-lyze, due to the lack of development data.
Throwingin large set of in-domain data was obviously helpful,even though we are currently unable to adequatelymeasure this effect.4 Experiments with factored modelsEven though these models were not used in our sub-missions, we feel it useful to comment here our (neg-ative) experiments with factored models.4.1 OverviewIn this work, factored models (Koehn and Hoang,2007) are experimented with three factors : the sur-face form, the lemma and the part of speech (POS).The translation process is composed of differentmapping steps, which either translate input factorsinto output factors, or generate additional output fac-tors from existing output factors.
In this work, fourmapping steps are used with two decoding paths.The first path corresponds to the standard and di-rect mapping of surface forms.
The second decod-ing path consists in two translation steps for respec-tively POS tag and the lemmas, followed by a gener-ation step which produces the surface form given thePOS-lemma couple.
The system also includes threereordering models.4.2 TrainingFactored models have been built to translate fromEnglish to French for the news task.
To estimate thephrase and generation tables, the training texts arefirst processed in order to compute the lemmas andPOS information.
The English texts are tagged andlemmatized using the English version of the Tree-tagger2.
For French, POS-tagging is carried outwith a French version of the Brill?s tagger trained2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger109on the MULTITAG corpus (Allauzen and Bonneau-Maynard, 2008).
Lemmatization is performed witha French version of the Treetagger.Three phrase tables are estimated with the Mosesutilities, one per factor.
For the surface forms, theparallel corpus is the concatenation of the officialtraining data for the tasks Europarl and News com-mentary, whereas only the parallel data of newscommentary are used for lemmas and POS.
For thegeneration step, the table built on the parallel texts ofnews commentary is augmented with a French dic-tionary of 280 000 forms.
The LM is the largest LMavailable for French (see section 2.2.2).4.3 Results and lessons learnedOn the news test set of 2008, this system obtains aBLEU score of 20.2, which is worse than our ?stan-dard?
system (20.9).
A similar experiment on theEuroparl task proved equally unsuccessful.Using only models which ignore the surface formof input words yields a poor system.
Therefore, in-cluding a model based on surface forms, as sug-gested (Koehn and Hoang, 2007), is also neces-sary.
This indeed improved (+1.6 BLEU for Eu-roparl) over using one single decoding path, but notenough to match our baseline system performance.These results may be explained by the use of auto-matic tools (POS tagger and lemmatizer) that are notentirely error free, and also, to a lesser extend, by thenoise in the test data.
We also think that more efforthas to be put into the generation step.Tuning is also a major issue for factored trans-lation models.
Dealing with 38 weights is an op-timization challenge, which took MERT 129 itera-tions to converge.
The necessary tradeoff betweenthe huge memory requirements of these techniquesand computation time is also detrimental to their use.Although quantitative results were unsatisfactory,it is finally worth mentioning that a manual exami-nation of the output revealed that the explicit usageof gender and number in our models (via POS tags)may actually be helpful when translating to French.5 ConclusionIn this paper, we presented our statistical MT sys-tems developed for the WMT 08 shared task.
As ex-pected, regarding the Europarl condition, our BLEUimprovements over the best 2007 results are limited:paying attention to tokenization and caseing issuesbrought us a small pay-off; rescoring with betterlanguage models gave also some reward.
The newscondition was new, and more challenging: our satis-factory results can be attributed to the use of large,well tuned, language models.
In comparison, our ex-periments with factored models proved disappoint-ing, for reasons that remain to be clarified.
On amore general note, we feel that the performance ofMT systems for these tasks are somewhat shadowedby normalization issues (tokenization errors, incon-sistent use of caseing, typos, etc), making it difficultto clearly analyze our systems?
performance.ReferencesA.
Allauzen and H. Bonneau-Maynard.
2008.
Trainingand evaluation of POS taggers on the French multitagcorpus.
In Proc.
LREC?08, To appear.D.
D?chelotte.
2007.
Traduction automatique de la pa-role par m?thodes statistiques.
Ph.D. thesis, Univ.Paris XI, December.P.
Koehn and H. Hoang.
2007.
Factored translation mod-els.
In Proc.
EMNLP-CoNLL, pages 868?876.P.
Koehn and J. Schroeder.
2007.
Experiments in domainadaptation for statistical machine translation.
In Proc.of the Workshop on Statistical Machine Translation,pages 224?227, Prague, Czech Republic.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proc.
HLT-NAACL, pages127?133, Edmonton, Canada, May.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkit forstatistical machine translation.
In ACL, demonstrationsession, Prague, Czech Republic.F.J.
Och and H. Ney.
2002.
Discriminative trainingand maximum entropy models for statistical machinetranslation.
In Proc.
ACL, pages 295?302.Franz J. Och and Hermann Ney.
2004.
The alignmenttemplate approach to statistical machine translation.Computational Linguistics, 30(4):417?449.F.
J. Och.
2003.
Minimum error rate training in statisticalmachine translation.
In Proc.
ACL, Sapporo, Japan.H.
Schwenk.
2007.
Continuous space language models.Computer Speech and Language, 21:492?518.110
