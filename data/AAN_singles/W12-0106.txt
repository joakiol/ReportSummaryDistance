Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 48?58,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsCombining EBMT, SMT, TM and IR Technologies for Quality and ScaleSandipan Dandapat1, Sara Morrissey1, Andy Way2, Joseph van Genabith11 CNGL, School of ComputingDublin City University, Glasnevin, Dublin 9, Ireland{sdandapat,smorri,josef}@computing.dcu.ie2 Applied Language Solutions, Delph, UKandy.way@appliedlanguage.comAbstractIn this paper we present a hybrid statisti-cal machine translation (SMT)-example-basedMT (EBMT) system that shows significantimprovement over both SMT and EBMT base-line systems.
First we present a runtimeEBMT system using a subsentential transla-tion memory (TM).
The EBMT system is fur-ther combined with an SMT system for effec-tive hybridization of the pair of systems.
Thehybrid system shows significant improvementin translation quality (0.82 and 2.75 abso-lute BLEU points) for two different languagepairs (English?Turkish (En?Tr) and English?French (En?Fr)) over the baseline SMT sys-tem.
However, the EBMT approach suffersfrom significant time complexity issues for aruntime approach.
We explore two methods tomake the system scalable at runtime.
First, weuse an heuristic-based approach.
Secondly, weuse an IR-based indexing technique to speedup the time-consuming matching procedure ofthe EBMT system.
The index-based match-ing procedure substantially improves run-timespeed without affecting translation quality.1 IntroductionState-of-the-art phrase-based SMT (Koehn, 2010a)is the most successful MT approach in many largescale evaluations, such as WMT,1 IWSLT2 etc.
Atthe same time, work continues in the area of EBMT.Some recent EBMT systems include Cunei (Phillips,1http://www.statmt.org/wmt11/2http://www.iwslt2011.org/2011), CMU-EBMT (Brown, 2011) and OpenMa-TrEx (Dandapat et al, 2010).
The success of anSMT system often depends on the amount of paralleltraining corpora available for the particular languagepair.
However, low translation accuracy has beenobserved for language pairs with limited training re-sources (Islam et al, 2010; Khalilov et al, 2010).SMT systems effectively discard the actual trainingdata once the models (translation model and lan-guage model) have been estimated.
This can lead totheir inability to guarantee good quality translationfor sentences closely matching those in the train-ing corpora.
By contrast, EBMT systems usuallymaintain a linked relationship between the full sen-tence pairs in source and target texts.
Because of thisEBMT systems can often capture long range depen-dencies and rich morphology at runtime.
In contrastto SMT, however, most EBMT models lack a well-formed probability model, which restricts the use ofstatistical information in the translation process.Keeping these in mind, our objective is to de-velop a good quality MT system choosing the bestapproach for each input in the form of a hybrid SMT-EBMT approach.
It is often the case that an EBMTsystem produces a good translation where SMT sys-tems fail and vice versa (Dandapat et al, 2011).An EBMT system relies on past translations toderive the target output for a given input.
Run-time EBMT approaches generally do not includeany training stage, which has the advantage of nothaving to depend on time-consuming preprocessing.On the other hand, their runtime complexity can beconsiderable.
This is due to the time-consumingmatching stage at runtime that finds the example48(or set of examples) which most closely matchesthe source-language sentence to be translated.
Thismatching step often uses some variation of stringedit-distance measures (Levenshtein, 1965) whichhas quadratic time complexity.3 This is quite time-consuming even when a moderate amount of train-ing examples are used for the matching procedure.We adopt two alternative approaches to tackle theabove problem.
First we use heuristics which are of-ten useful to avoid some of the computations.
For ainput sentence, in the matching process, we may notneed to compute the string edit distance with all sen-tences in the example base.
In order to prune someof the computation, we rely on the fact that the in-put sentence and its closest match sentence from theexample-base are likely to have a similar sentencelength.
Search engine indexing is an effective wayof storing data for fast and accurate retrieval of in-formation.
During retrieval, a set of documents areextracted based on their similarity to the input query.In our second approach, we use this concept to effi-ciently retrieve a potential set of suitable candidatesentences from the example-base to find the closestmatch.
We index the entire example-base consider-ing each source-side sentence as a document for theindexer.
We show that improvements can be madewith our approach in terms of time complexity with-out affecting the translation quality.The remainder of this paper is organized as fol-lows.
The next section presents work related to ourEBMT approach.
Section 3 describes the MT sys-tems used in our experiments.
Section 4 focuses onthe two techniques used to make the system scalable.Section 5 presents the experiments in detail.
Section6 presents and discusses the results and provides anerror analysis.
We conclude in Section 7.2 Related WorkThe EBMT framework was first introduced by Na-gao (1984) as the ?MT by analogy principle?.
Thetwo main approaches to EBMT are distinguishedby the inclusion or exclusion of a preprocess-ing/training stage.
Approaches that incorporate a3Ukkonen (1983) gave an algorithm for computing edit-distance with the worst case complexity O(md), where m isthe length of the string and d is their edit distance.
This is ef-fective when m  d. We use word-based edit distance, so mis shorter in length.training stage are commonly called ?compiled ap-proaches?
(Cicekli and Gu?venir, 2001).
Approachesthat do not include a training stage are often referredto as ?pure?
or ?runtime?
EBMT approaches, e.g.
(Lepage and Denoual, 2005).
These approacheshave the advantage that they do not depend on anytime-consuming preprocessing stages.
On the otherhand, their runtime complexity can be considerable.EBMT is often linked with the related concept oftranslation memory (TM).
A TM essentially storessource- and target-language translation pairs for ef-fective reuse of previous translations originally cre-ated by human translators.
TMs are often used tostore examples for EBMT systems.
After retriev-ing a set of examples with associated translations,EBMT systems automatically extract translations ofsuitable fragments and combine them to produce agrammatical target output.Phrase-based SMT systems (Koehn, 2010a), pro-duce a source?target algned subsentential phrasetable which can be adapted as an additional TMto be used in a CAT environment (Simard, 2003;Bic?ici and Dymetman, 2008; Bourdaillet et al,2009; Simard and Isabelle, 2009).
Koehn and Senel-lart (2010b) use SMT to produce the translation ofthe non-matched fragments after obtaining the TM-based match.
EBMT phrases have also been usedto populate the knowledge database of an SMT sys-tem (Groves et al, 2006).
However, to the best ofour knowledge, the use of SMT phrase tables withinan EBMT system as an additional sub-sentential TMhas not been attempted so far.
Some work has beencarried out to integrate MT in a CAT environmentto translate the whole segment using the MT sys-tem when no sufficiently well matching translationunit (TU) is found in the TM.
The TransType sys-tem (Langlais et al, 2002) integrates an SMT sys-tem within a text editor to suggest possible continua-tions of the translations being typed by the translator.By contrast, our approach attempts to integrate thesubsentential TM obtained using SMT techniqueswithin an EBMT system.3 MT SystemsThe SMT system used in our hybrid SMT-EBMT approach is the vanilla Moses4 decoder.4http://www.statmt.org/moses/49Moses (Koehn et al, 2007) is a set of SMT toolsthat include routines to automatically train a transla-tion model for any language pair and an efficient de-coder to find the most probable translation.
Due tolack of space and the wide usage of Moses, here wefocus more on the novel EBMT system we have de-veloped for our hybrid SMT-EBMT approach.
TheEBMT system described in this section is based onprevious work (Dandapat et al, 2010) and some ofthe material has been reproduced here to make thepaper complete.Like all other EBMT systems, our particular ap-proach comprises three stages: matching, alignmentand recombination.
Our EBMT system also uses asubsentential TM in addition to the sentence alignedexample-base.
Using the original TM as a train-ing set, additional subsentential TUs (words andphrases) are extracted from it based on word align-ments and phrase pairs produced by Moses.
Thesesubsentential TUs are used for alignment and recom-bination stages of our EBMT system.3.1 Building a Subsentential TM for EBMTA TM for EBMT usually contains TUs linked atthe sentence, phrasal and word level.
TUs can bederived manually or automatically (e.g.
using themarker-hypothesis (Groves et al, 2006)).
Usually,TUs are linguistically motivated translation units.In this paper however, we explore a different route,as manual construction of high-quality TMs is timeconsuming and expensive.
Furthermore, only con-sidering linguistically motivated TUs may limit thematching potential of a TM.
Because of this, weused SMT technology to automatically create thesubsentential part of our TM at the phrase (i.e.no longer necessarily linguistically motivated) andword level.
Based on Moses word alignment (usingGIZA++ (Och and Ney, 2003)) and phrase table con-struction, we construct the additional TM for furtheruse within an EBMT approach.Firstly, we add entries to the TM based on thealigned phrase pairs from the Moses phrase table us-ing the following two scores:1.
Direct phrase translation probabilities: ?(t|s)2.
Direct lexical weight: lex(t|s)Table 1 shows an example of phrase pairs with theassociated probabilities learned by Moses.
We keepall target equivalents in a sorted order based on theTable 1: Moses phrase equivalence probabilities.English (s) Turkish (t) p(t|s) lex(t|s)a hotel bir otel 0.826087 0.12843a hotel bir otelde 0.086957 0.07313a hotel otel mi 0.043478 0.00662a hotel otel 0.043478 0.22360above probabilities.
This helps us in the matchingprocedure, but during recombination we only con-sider the most probable target equivalent.
The fol-lowing shows the resulting TUs in the TM for theEnglish source phrase a hotel.a hotel?
{bir otel, bir otelde, otel, otem mi}Secondly, we add entries to the TM based on thesource-to-target word-aligned file.
We also keepthe multiple target equivalents for a source word ina sorted order.
This essentially adds source- andtarget-language equivalent word pairs into the TM.Note that the entries in the TM may contain in-correct source-target equivalents due to unreliableword/phrase alignments produced by Moses.3.2 EBMT EngineThe overview of the three stages of the EBMT en-gine is given below:Matching: In this stage, we find a sentence pair?sc, tc?
from the example-base that closely matcheswith the input sentence s. We used a fuzzy-matchscore (FMS) based on a word-level edit distancemetric (Wagner and Fischer, 1974) to find the closestmatching source-side sentence from the example-base ({si}N1 ) based on Equation (i).score(s, si) = 1?
ED(s, si)/max(|s|, |si|) (i)where |x| denotes the length (in words) of a sen-tence, and ED(x, y) refers to the word-level edit dis-tance between x and y.
The EBMT system considersthe associated translation tc of the closest matchingsource sentence sc, to build a skeleton for the trans-lation of the input sentence s.Alignment: After retrieving the closest fuzzy-matched sentence pair ?sc, tc?, we identify the non-matching fragments from the skeleton translation tcin two steps.50Firstly, we find the matched and non-matchedsegments between s and sc using edit distancetrace.
Given the two sentences (s and sc), the al-gorithm finds the minimum possible number of op-erations (substitutions, additions and deletions) re-quired to change the closest match sc into the in-put sentence s. For example, consider the inputsentence s = w1w2w3w4w5w6w7w8 and sc =w?1w?3w4w5w7w8w?9.
Figure 1 shows the matchedand non-matched sequence between s and sc usingedit-distance trace.s = w1 w2 w3 w4 w5 w6 w7 w8 ?| | | | |sc = w1 ?
w?3 w4 w5 ?
w7 w8 w?9?s = w1 w2 w3 w4 w5 w6 w7 w8 null| ?
| ?
| ?sc = w1 w?3 w4 w5 null w7 w8 w?9Figure 1: Extraction of matched (underlined) and non-matched (boxed) segments between s and sc.Secondly, we align each non-matched segment insc with its associated translation using the TM andthe GIZA++ alignment.
Based on the source-targetaligned pair in the TM, we mark the mismatchedsegment in tc.
We find the longest possible seg-ment from the non-matched segment in sc that has amatching target equivalent in tc based on the source-target equivalents in the TM.
We continue the pro-cess recursively until no further segments of the non-matched segment in sc can be matched with tc us-ing the TM.
Remaining non-matching segments insc are then aligned with segments in tc using theGIZA++ word alignment information.Recombination: In the recombination stage, weadd or substitute segments from the input sentence swith the skeleton translation equivalent tc.
We alsodelete some segments from tc that have no corre-spondence in s. After obtaining the source segments(needs to be added or substituted in tc) from the in-put s, we use our subsentential TM to translate thesesegments.
Details of the recombination process aregiven in Algorithm 1.3.3 An Illustrative ExampleAs a running example, for the input sentence in (1a)the corresponding closest fuzzy-matched sentenceAlgorithm 1 recombination(X,TM)In: source segment X ,subsentential translation memory TMOut: translation of source segment X1: mark all words of X as untranslated(untranslatedPortions(X)?
{X})2: repeat3: U = untranslatedPortions(X)4: x = longest subsegment in untranslatedPortions(X)such that (x, tx) ?
TM;5: substitute(X,x ?
tx) {substitute x with its targetequivalent tx in X}6: remove x from untranslatedPortions(X)7: until (untranslatedPortions(X) = U )8: return Xpair ?sc, tc?
is shown in (1b) and (1c).
The portionmarked with angled brackets in (1c) are aligned withthe mismatched portion in (1b).
The character andthe following number in angled brackets indicate theedit operation (?s?
indicates substitution) and the in-dex of the mismatched segment from the alignmentprocess respectively.1.
(a) s: i ?d like a <s#0:present> for <s#1:mymother> .
(b) sc: i ?d like a <s#0:shampoo> for<s#1:greasy hair> .
(c) tc: <s#1:yag?l?
sac?lar> ic?in bir<s#0:s?ampuan> istiyorum .During recombination, we need to replace twosegments in (1c) {yag?l?
sac?lar (greasy hair) ands?ampuan (shampoo)} with the two correspondingsource segments in (1a) {my mother and present}as an intermediate stage (2) along the way towardsproducing a target equivalent.
(2)<1:my mother> ic?in bir <0:present> istiyorum .Furthermore, replacing the untranslated segmentsin (2) with the translations obtained using TM, wederive the output translation in (3) of the original in-put sentence in (1).
(3) <annem> ic?in bir <hediye> istiyorum .4 ScalabilityThe main motivation of scalability is to improvethe speed of the EBMT system when using a largeexample-base.
The matching procedure in an EBMTsystem finds the example (or a set of examples)which closely matches the source-language string to51be translated.
All matching processes necessarily in-volve a distance or similarity measure.
The mostwidely used distance measure in EBMT matchingis Levenshtein distance (Levenshtein, 1965; Wagnerand Fischer, 1974) which has quadratic time com-plexity.
In our EBMT system, we find the clos-est sentence at runtime from the whole example-base for a given input sentence using the edit dis-tance matching score.
Thus, the matching step ofthe EBMT system is a time-consuming process witha runtime complexity of O(nm2), where n denotesthe size of the example-base and m denotes the av-erage length (in words) of a sentence.
Due to asignificant runtime complexity, the EBMT systemcan only handle a moderate size example-base in thematching stage.
However, it is important to handle alarge example-base to improve the quality of an MTsystem.
In order to make the system scalable witha larger example-base, we adopt two approaches forfinding the closest matching sentences efficiently.4.1 GroupingOur first attempt is heuristic-based.
We divide theexample-base into bins based on sentence length.
Itis anticipated that the sentence from the example-base that most closely matches an input sentencewill fall into the group which has comparable lengthto the length of the input sentence.
First, we dividethe example-baseE into different bins based on theirword-level length E =?li=1Ei and Ei?Ej = ?for all i 6= j where 0 ?
i, j ?
l. Ei denotes theset of sentences with length i and l is the maximumlength of a sentence in E. In order to find the clos-est match for a test sentence (s of length k), we onlyconsider examples EG =?xm=0Ek?m, where x in-dicates the window size.
In our experiment, we con-sider the value of x from 0 to 2.
We find the closest-match sc from EG for a given test sentence s. EGhas fewer sentences compared to E which will ef-fectively reduce the time of the matching procedure.4.2 IndexingOur second approach to addressing time complexityis to use indexing.
We index the complete example-base using an open-source IR engine SMART5 andretrieve a potential set of candidate sentences (likely5An open source IR system from Cornell University.
ftp://ftp.cs.cornell.edu/pub/smart/to contain the closest match sentence) from theexample-base.
Unigrams extracted from the sen-tences of the example-base are indexed using thelanguage model (LM) and complete sentences areconsidered as retrievable units.
In LM-based re-trieval we assume that a given query is generatedfrom a unigram document language model.
The ap-plication of the LM retrieval model in our case re-turns a sorted list of sentences from the example-base ordered by the estimated probabilities of gen-erating the given input sentence.In order to improve the run-time performance,we integrate the SMART retrieval engine within thematching procedure of our EBMT system.
The re-trieval engine estimates a potential set of candidateclose-matching sentences from the example-base Efor a test sentence s. We assume that the closestsource-side match sc of the input sentence s cantake the value from the set EIR(s), where EIR(s) isthe potential set of close-matching sentences com-puted by the LM-based retrieval engine.
We haveused the top 50 candidate sentences from EIR(s).Since the IR engine tries to retrieve the document(sentences from E) for a given query (input) sen-tence, it is likely to retrieve the closest match sen-tence sc in the set EIR(s).
Due to a much re-duced set of possibilities, this approach improves therun-time performance of the EBMT system withouthampering system accuracy.
Finding this potentialset of candidate sentences will be much faster thantraditional edit-distance-based retrieval on the fullexample-base as the worst case run time of the re-triever is O(?
?wisi), where wi is a word in the in-put sentence and si is the number of sentences in theexample-base that contain wi.
Finding a set of can-didate sentences took only 0.3 seconds and 116 sec-onds, respectively, for 414 and 10,000 example in-put sentences given 20k and 250k sentence example-base in our En?Tr and En?Fr experiment on a 3GHzCore 2 Duo machine with 4GB RAM.5 ExperimentsWe conduct different experiments to report the ac-curacy of our EBMT systems for En?Tr and En?Frtranslation tasks.
In order to compare the perfor-mance of our approaches we use two baseline sys-tems.
We use the Moses SMT system as one base-52line.
Furthermore, based on the matching step (Sec-tion 3.2) of the EBMT approach, we obtain the clos-est target-side equivalent (the skeleton sentence) andconsider this as the baseline output for the input tobe translated.
This is referred to as TM in the exper-iment below.
We will consider this as the baselineaccuracy for our EBMT using TM approach.In addition, we conduct two experiments with ourEBMT system.
After obtaining the skeleton trans-lation through the matching and alignment steps, inthe recombination step, we use TM to translate anyunmatched segments based on Algorithm 1.
We callthis EBMTTM.We found that there are cases where theEBMTTM system produces the correct translationbut SMT fails and vice-versa (Dandapat et al, 2011).In order to further improve translation quality, weuse a combination of EBMT and SMT.
Here we usesome features to decide whether to rely on the out-put produced by the EBMTTM system.
These fea-tures include fuzzy match scoreFMS (as in (i)) andthe number of mismatched segments in each of s,sc, tc (EqUS6 as in (1)).
We assume that the transla-tions of an input sentence s produced by EBMTTMand SMT systems are respectively TEBMT(s) andTSMT(s).
If the value of FMS is greater than somethreshold and EqUS exists between s and sc, werely on the output TEBMT(s); otherwise we take theoutput from TSMT(s).
We refer to this system asEBMTTM + SMT.To test the scalability of the system, we con-ducted two more experiments based on the ap-proach described in Section 4.
First, we con-ducted an experiment based on the sentence length-based grouping heuristics (Section 4.1).
We re-fer to this system asEBMTTM + SMT+ groupi,where i indicates the window size while compar-ing the length of the input sentence with the bins.We conduct a second experiment based on the LM-based indexing technique (Section 4.2) we have usedto retrieve a potential set of candidate sentencesfrom the indexed example-base.
We call this sys-tem EBMTTM + SMT+ index.
Note that theEBMTTM + SMT system is used as the baselineaccuracy while conducting the experiments for scal-6If s, sc and tc agree in the number of mismatched segments,EqUS evaluates to 1, otherwise 0.ability of the EBMT system.5.1 Data Used for ExperimentsWe used two data sets for all our experiments rep-resenting two language pairs of different size andtype.
In the first data-set, we have used the En?Trcorpus from IWSLT09.7 The training data consistsof 19,972 parallel sentences.
We used the IWSLT09development set as our testset which consists of 414sentences.
The IWSLT09 data set is comprised ofshort sentences (with an average of 9.5 words persentence) from a particular domain (the C-STARproject?s Basic Travel Expression Corpus).Our second data set consists of an En?Frcorpus from the European Medicines Agency(EMEA)8 (Tiedemann and Nygaard, 2009).
Thetraining data consists of 250,806 unique parallel sen-tences.9 As a testset we use a set of 10,000 ran-domly drawn sentences disjoint from the trainingcorpus.
This data also represents a particular domain(medicine) but with longer sentence lengths (with anaverage of 18.8 words per sentence) compared to theIWSLT09 data.6 Results and ObservationsWe used BLEU (Papineni et al, 2002) for automaticevaluation of our EBMT systems.
Table 2 showsthe accuracy obtained for both En?Tr and En?Fr bythe EBMTTM system described in Section 3.
Herewe have two baseline systems (SMT and TM) as de-scribed in the first two experiments in Section 5.Table 2: Baseline BLEU scores of the two systemsand the scores for EBMTTM system.System Language pairsEn?Tr En?FrSMT 23.59 55.04TM 15.60 40.23EBMTTM 20.08 48.31Table 2 shows that EBMTTM has a lower systemaccuracy than SMT for both the language pairs, but7http://mastarpj.nict.go.jp/IWSLT2009/2009/12/downloads.html8http://opus.lingfil.uu.se/EMEA.php9A large number of duplicate sentences exists in the originalcorpus (approximately 1M sentences).
We remove duplicatesand consider sentences with unique translation equivalents.53better scores than TM alone.
Tables 3 and 4 showthat combining EBMT with SMT systems shows im-provements of 0.82 and 2.75 BLEU absolute overthe SMT baseline (Table 2) for both the En?Tr andthe En?Fr data sets.
In each case, the improvementof EBMTTM + SMT over the baseline SMT is sta-tistically significant (reliability of 98%) using boot-strap resampling (Koehn, 2004).Table 3: En?Tr MT system accuracies of the com-bined systems (EBMTTM + SMT) with differentcombining factors.
The second column indicates thenumber (and percentage) of sentences translated bythe EBMTTM system during combination.System: EBMTTM + SMTCondition timesEBMTTMusedBLEU(in %)FMS>0.85 35 (8.5%) 24.22FMS>0.80 114 (27.5%) 23.99FMS>0.70 197 (47.6%) 22.74FMS>0.80 OR(FMS>0.70 & EqUS)165 (40.0%) 23.87FMS>0.85 & EqUS 24 (5.8%) 24.41FMS>0.80 & EqUS 76 (18.4%) 24.19FMS>0.70 & EqUS 127 (30.7%) 24.08Table 4: En?Fr MT system accuracies for the com-bined systems (EBMTTM + SMT) with differentcombining factors.System: EBMTTM + SMTCondition timesEBMTTMusedBLEU(in %)FMS>0.85 3323 (33.2%) 57.79FMS>0.80 4300 (43.0%) 57.55FMS>0.70 5283 (52.8%) 57.05FMS>0.60 6148 (61.5%) 56.25FMS>0.80 OR(FMS>0.70 & EqUS)4707 (47.1%) 57.46FMS>0.85 & EqUS 2358 (23.6%) 57.24FMS>0.80 & EqUS 2953 (29.5%) 57.16FMS>0.70 & EqUS 3360 (33.6%) 57.08A particular objective of our work is to scale theruntime EBMT system to a larger amount of train-ing examples.
We experiment with the two ap-proaches described in Section 4 to improve the runtime of the system.
Table 5 compares the run time ofthe three systems (EBMTTM, EBMTTM + groupiand EBMTTM + index) for both En?Tr and En?Frtranslation.
Note that the SMT decoder takes 140seconds and 310 minutes respectively for En?Tr andEn?Fr translation test sets.Table 5: Running time of the three different systems.System Language pairsEn?Tr En?Fr(seconds) (minutes)SMT 140.0 310.0EBMTTM 295.9 2267.0EBMTTM + group0 34.0 63.4EBMTTM + group1 96.2 183.5EBMTTM + group2 148.5 301.4EBMTTM + index 2.7 2.6Both the grouping and indexing methodologiesproved successful for system scalability with a max-imum speedup of almost 2 orders of magnitude.
Wealso need to estimate the accuracy while combininggrouping and indexing techniques with the baselinesystem (EBMTTM + SMT) to understand their rel-ative performance.
Table 6 provides the system ac-curacy using the grouping and indexing techniquesfor both the language pairs.
We report the transla-tion quality under three conditions.
Similar trendshave been observed for other conditions.6.1 Observations and DiscussionsWe find that the EBMTTM system has a lower ac-curacy on its own compared to baseline SMT forboth the language pairs (Table 2).
Nevertheless,there are sentences which are better translated by theEBMTTM approach compared to SMT, althoughthe overall document translation score is higher withSMT.
Thus, we combined the two systems based ondifferent features and found that the combined sys-tem performs better.
The highest relative improve-ments in BLEU score are 3.47% and 1.05% respec-tively for En?Tr and En?Fr translation.
We foundthat if an input has a high fuzzy match score (FMS)with the example-base, then the EBMTTM systemdoes better compared to SMT.
With our current ex-perimental setup, we found that an FMS over 0.8showed an improvement for En?Tr and a FMS over0.6 showed improvement for En?Fr over the SMTsystem.
Figure 2 shows the effect in the translation54Table 6: BLEU scores of the three different systems for En?Tr and En?Fr under different conditions.
idenotes the number of bins considered during grouping.Condition SystemEBMTTM + SMT EBMTTM + SMT EBMTTM + SMT+groupi +indexi=0 i=?1 i=?2En?TrFMS>0.85 24.22 24.18 24.18 24.23 24.24FMS>0.80 OR (FMS>0.70 & EqUS) 23.87 23.34 23.90 24.40 24.37FMS>0.85 & EqUS 24.41 24.17 24.38 24.34 24.39En?FrFMS>0.85 57.79 56.47 57.48 57.76 57.92FMS>0.80 OR (FMS>0.70 & EqUS) 57.46 55.69 57.07 57.33 57.56FMS>0.85 & EqUS 57.24 56.48 57.23 57.29 57.32quality when different FMS thresholds were used tocombine the two systems.However, FMS might not be the only factor fortriggering the EBMTTM system.
We consideredEqUs as another factor which showed improvementfor En?Tr but showed negative effect for En?Fr.Though an FMS over 0.7 for En?Tr shows no im-provement in overall system accuracy, inclusion ofthe EqUs feature along with FMS shows improve-ment.
Thus, the EBMTTM system is sometimesmore effective when the number of unmatched seg-ment matches in s, sc and tc.These observations show the effective use of ourEBMT approach in terms of translation quality.However, we found that the EBMTTM system hasa very considerable runtime complexity.
In order totranslate 414 test sentences from English into Turk-ish, the basic EBMT system takes 295.9 seconds.The situation becomes worse when using the largeexample-base for En?Fr translation.
Here, we foundthat the system takes around 38 hours to translate10k source English sentences into French.
This isa significant time complexity by any standard for aruntime approach.
However, both grouping and in-dexing reduce the time complexity of the approachconsiderably.
The time reduction with grouping de-pends on the number of bins considered to find theclosest sentence during the matching stage.
Systemswith a lower number of bins take less time but causemore of a drop in translation quality.
The effect ismore prominent with the En?Fr system which usesa larger example-base.
We found a drop of abso-lute 1.32 BLEU points while considering a singlebucket whose length is equal to the length of thetest sentence.
This configuration takes 63 minutes totranslate 10k English sentences into French.
Thereis only a drop of 0.03 BLEU points when consider-ing the 5 nearest bins (?2) for a given test sentence.Nevertheless, there is not much of a reduction but itincreases the run time to 5 hours for the translationof 10k sentences.
Thus, the group-based method isnot effective enough to balance system accuracy andrun time.Incorporation of the indexing technique into thematching stage of EBMT shows the highest effi-ciency gains in run time.
Translating 10k sen-tences from English into French takes only 158 sec-onds.
It is also interesting to note that with index-ing, the BLEU score remained the same or even in-creased.
This is due to the fact that, compared toFMS-based matching, a different closest-matchingsentence sc is selected for some of the input sen-tences while using indexing, thus resulting in a dif-ferent outcome to the system.
Figure 3 comparesthe number of times the EBMTTM + SMT + indexsystem is used in the hybrid system and the num-ber of same closest-matching sentences selected byEBMTTM + SMT + index systems under differentconditions for En?Tr.
The use of index-based candi-date selection for EBMT matching shows effective5548.3155.0457.790.2  0.4  0.6  0.8 0.9 1BLEU (%)Fuzzy Match ScoreEBMTTM+SMTSMTEBMTTM(a) En?Fr20.0823.59 24.220.3  0.4  0.6  0.8 0.9  1BLEU (%)Fuzzy Match ScoreEBMTTM+SMTSMTEBMTTM(b) En?TrFigure 2: Effect of FMS in the combined EBMTTM + SMT system.Table 7: The effect of indexing in selection sc andin final translation.Input: zeffix belongs to a group of medicines calledantivirals.Ref : zeffix appartient a` une classe deme?dicaments appele?s antiviraux.baseline EBMTTM systemsc: simulect belongs to a group of medicinescalled immunosuppressants.st: simulect fait parti d ?
une classe deme?dicaments appele?s immunosuppresseurs.Output: zeffix fait parti d ?
une classe deme?dicaments appele?s antiviraux.EBMTTM + SMT + index systemsc: diacomit belongs to a group of medicinescalled antiepileptics.st: diacomit appartient a` un groupe deme?dicaments appele?s antie?pileptiques.Output: zeffix appartient a` un groupe deme?dicaments appele?s antiviraux.improvement in translation time, and BLEU scoresremained the same or increased.
Due to the selec-tion of different closest-matching sentence sc, some-times the system produces better quality translationwhich increases the system level BLEU score.
Ta-ble 7 shows one such En?Fr example where anindex-based technique produced a better translationthan the baseline (EBMTTM + SMT) system.7 ConclusionOur experiments show that EBMT approaches workbetter compared to the SMT-based system for cer-tain sentences when a high fuzzy match score isFigure 3: Number of times EBMTTM + SMT + indexused in the hybrid system and the number of timesthe same closest-matching sentences are selected by thesystems.
a=FMS>0.85, b=FMS>0.85 & EqUS andc=FMS>0.80 OR (FMS>0.70 & EqUS)obtained for the input sentence with the example-base.
Thus a feature-based combination of EBMT-and SMT-based systems produces better translationquality than either of the individual systems.
Inte-gration of a SMT technology-based sub-sententialTM with the EBMT framework (EBMTTM) has im-proved translation quality in our experiments.Our baseline EBMTTM system is a runtime ap-proach which has high time complexity when us-ing a large example-base.
We found that the inte-gration of IR-based indexing substantially improvesrun time without affecting BLEU score.
So far oursystems have been tested using moderately sizedexample-bases from a closed domain corpus.
In ourfuture work, we plan to use a much larger example-base and wider-domain corpora.56AcknowledgmentsThis research is supported by Science FoundationIreland (Grants 07/CE/I1142, Centre for Next Gen-eration Localisation).ReferencesS.
Armstrong, C. Caffrey, M. Flanagan, D. Kenny, M.O?Hagan and A.
Way.
2006.
Improving the Qualityof Automated DVD Subtitles via Example-Based Ma-chine Translation.
Translating and the Computer 28,[no page number], London: Aslib, UK.E.
Bic?ici and M. Dymetman.
2008.
Dynamic TranslationMemory: Using Statistical Machine Translation to Im-prove Translation Memory.
In Gelbukh, Alexander F.,editor, In Proceedings of the 9th International Confer-ence on Intelligent Text Processing and ComputationalLinguistics (CICLing), volume 4919 of Lecture Notesin Computer Science, pp 3-57 Springer Verlag.J.
Bourdaillet, S. Huet, F. Gotti, G. Lapalme and P.Langlais.
2009.
Enhancing the bilingual concor-dancer TransSearch with word-level alignment.
InProceedings, volume 5549 of Lecture Notes in Artifi-cial Intelligence: 22nd Canadian Conference on Ar-tificial of Intelligence (Canadian AI 2009), Springer-Verlag, pp.
27-38.R.
D. Brown.
2011.
The CMU-EBMT machine transla-tion system.
Machine Translation, 25(2):179?195.I.
Cicekli and H. A. Gu?venir.
2001.
Learning trans-lation templates from bilingual translation examples.Applied Intelligence, 15(1):57?76.S.
Dandapat, S. Morrissey, A.
Way and M.L.
Forcada.2011.
Using Example-Based MT to Support Sta-tistical MT when Translating Homogeneous Data inResource-Poor Settings.
In Proceedings of the 15thAnnual Meeting of the European Association for Ma-chine Translation (EAMT 2011), pp.
201-208.
Leu-ven, Belgium.S.
Dandapat, M.L.
Forcada, D. Groves, S. Penkale,J.
Tinsley and A.
Way.
2010.
OpenMaTrEx:a free/open-source marker-driven example-based ma-chine translation system.
In Proceedings of the 7th In-ternational Conference on Natural Language Process-ing (IceTAL 2010), pp.
121-126.
Reykjav?
?k, Iceland.D.
Groves and A.
Way.
2006.
Hybridity in MT: Exper-iments on the Europarl Corpus.
In Proceedings of the11th Conference of the European Association for Ma-chine Translation (EAMT 2006), pp.
115-124.
Oslo,Norway.M.
Islam, J. Tiedemann and A. Eisele.
2010.
English?Bengali Phrase-based Machine Translation.
In Pro-ceedings of the 14th Annual Conference of the Eu-ropean Association of Machine Translation, (EAMT2010), [no page number], Saint-Raphae?l, France.M.
Khalilov, J.A.R.
Fonollosa, I. Skadina, E. Bralitisand L. Pretkalnina.
2010.
English?Latvian SMT: theChallenge of Translating into a Free Word Order Lan-guage.
In Proceedings of the 2nd International Work-shop on Spoken Language Technologies for Under-resourced Languages (SLTU 2010), [no page num-ber], Saint-Raphae?l, France.P.
Koehn.
2010.
Statistical Machine Translation, Cam-bridge University Press, Cambridge, UK.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch, M.Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran,R.
Zens, C. Dyer, O. Bojar, A. Constantin and E.Herbst.
2007.
Moses: open source toolkit for statisti-cal machine translation.
In Proceedings of the Demon-stration and Poster Sessions at the 45th Annual Meet-ing of the Association of Computational Linguistics(ACL 2007), pp.
177-180.
Prague, Czech Republic.P.
Koehn.
2004.
Statistical significance tests for machinetranslation evaluation.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP 2004), pp.
388-395.
Barcelona,Spain.P.
Koehn and J. Senellart.
2004.
Convergence of Trans-lation Memory and Statistical Machine Translation.
InProceedings of the AMTA workshop on MT Researchand the Translation Industry, pp.
21-23.
Denever, CO.P.
Langlais, G. Lapalme and M. Loranger.
2002.Development-evaluation cycles to boost translator?sproductivity.
Machine Translation, 15(4):77?98.Y.
Lepage and E. Denoual.
2005.
Purest ever example-based machine translation: Detailed presentation andassessment.
Machine Translation, 19(3-4):251?282.V.
I. Levenshtein.
1965.
Binary Codes Capable of Cor-recting Deletions, Insertions, and Reversals.
Dok-lady Akademii Nauk SSSR, 163(4):845-848., Englishtranslation in Soviet Physics Doklady,10(8), 707-710.C.
D. Manning, P. Raghavan and H. Schu?tze.
2008.
In-troduction to Information Retrieval.
Cambridge Uni-versity Press, Cambridge, UK.M.
Nagao.
1984.
A Framework of a Machine Translationbetween Japanese and English by Analogy Principle.In Elithorn, A. and Banerji, R., editors, Artificial Hu-man Intelligence, pp.
173?180, North-Holland, Ams-terdam.F.
Och and H. Ney.
2003.
A Systematic Comparison ofVarious Statistical Alignment Models.
ComputationalLinguistics, 29(1):19?51.K.
Papineni, S. Roukos, T. Ward and W. J. Zhu.
2002.BLEU: a Method for Automatic Evaluation of Ma-chine Translation.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Linguis-tics, (ACL 2002), pp.
311?318, Philadelphia, PA.57A.
B. Phillips.
2011.
Cunei: open-source machine trans-lation with relevance-based models of each translationinstance.
Machine Translation, 25(2):161?177.M.
Simard and P. Isabelle.
2009.
Phrase-based MachineTranslation in a Computer-assisted Translation Mem-ory.
In Proceedings of the 12th Machine TranslationSummit, (MT Summit XII), pp.
120?127, Ottawa,Canada.M.
Simard.
2003.
Translation spotting for translationmemories.
In Proceedings of the HLT-NAACL 2003,Workshop on Building and Using Parallel Texts: DataDriven Machine Translation and Beyond, pp.
65?72,Edmonton, Canada.H.
Somers.
2003.
An Overview of EBMT.
In M. Carland A.
Way , editors, Recent Advances in Example-based Machine Translation, pp.
3-57, Kluwer Aca-demic Publishers, Dordrecht, The Netherlands.J.
Tiedemann and L. Nygaard.
2009.
News from OPUS- A Collection of Multilingual Parallel Corpora withTools and Interfaces, in N. Nicolov, K. Bontcheva,G.
Angelova, R. Mitkov.
(eds.
), Recent Advances inNatural Language Processing, V:237?248, John Ben-jamins, Amsterdam, The Netherlands.E.
Ukkonen.
1983.
On Approximate String Matching.
InProceedings of International Conference on Founda-tions of Computing Theory, (FCT 1983), pp.
487?496,Borgholm, Sweden.R.
Wagner and M. Fischer.
1974.
The String-to-StringCorrection Problem.
Journal of the Association forComputing Machinery, 21:168?173.58
