Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 435?445,Baltimore, Maryland, USA, June 23-25 2014. c?2014 Association for Computational LinguisticsHybrid Simplification using Deep Semantics and Machine TranslationShashi NarayanUniversite?
de Lorraine, LORIAVillers-le`s-Nancy, F-54600, Franceshashi.narayan@loria.frClaire GardentCNRS, LORIA, UMR 7503Vandoeuvre-le`s-Nancy, F-54500, Franceclaire.gardent@loria.frAbstractWe present a hybrid approach to sentencesimplification which combines deep se-mantics and monolingual machine transla-tion to derive simple sentences from com-plex ones.
The approach differs from pre-vious work in two main ways.
First, itis semantic based in that it takes as in-put a deep semantic representation ratherthan e.g., a sentence or a parse tree.
Sec-ond, it combines a simplification modelfor splitting and deletion with a monolin-gual translation model for phrase substi-tution and reordering.
When comparedagainst current state of the art methods,our model yields significantly simpler out-put that is both grammatical and meaningpreserving.1 IntroductionSentence simplification maps a sentence to a sim-pler, more readable one approximating its con-tent.
Typically, a simplified sentence differs froma complex one in that it involves simpler, moreusual and often shorter, words (e.g., use insteadof exploit); simpler syntactic constructions (e.g.,no relative clauses or apposition); and fewer mod-ifiers (e.g., He slept vs.
He also slept).
In prac-tice, simplification is thus often modeled usingfour main operations: splitting a complex sen-tence into several simpler sentences; dropping andreordering phrases or constituents; substitutingwords/phrases with simpler ones.As has been argued in previous work, sentencesimplification has many potential applications.
Itis useful as a preprocessing step for a variety ofNLP systems such as parsers and machine trans-lation systems (Chandrasekar et al, 1996), sum-marisation (Knight and Marcu, 2000), sentencefusion (Filippova and Strube, 2008) and semanticrole labelling (Vickrey and Koller, 2008).
It alsohas wide ranging potential societal application as areading aid for people with aphasis (Carroll et al,1999), for low literacy readers (Watanabe et al,2009) and for non native speakers (Siddharthan,2002).There has been much work recently on de-veloping computational frameworks for sentencesimplification.
Synchronous grammars have beenused in combination with linear integer program-ming to generate and rank all possible rewrites ofan input sentence (Dras, 1999; Woodsend and La-pata, 2011).
Machine Translation systems havebeen adapted to translate complex sentences intosimple ones (Zhu et al, 2010; Wubben et al, 2012;Coster and Kauchak, 2011).
And handcraftedrules have been proposed to model the syntactictransformations involved in simplifications (Sid-dharthan et al, 2004; Siddharthan, 2011; Chan-drasekar et al, 1996).In this paper, we present a hybrid approach tosentence simplification which departs from thisprevious work in two main ways.First, it combines a model encoding probabil-ities for splitting and deletion with a monolin-gual machine translation module which handlesreordering and substitution.
In this way, we ex-ploit the ability of statistical machine translation(SMT) systems to capture phrasal/lexical substi-tution and reordering while relying on a dedi-cated probabilistic module to capture the splittingand deletion operations which are less well (dele-tion) or not at all (splitting) captured by SMT ap-proaches.Second, our approach is semantic based.
Whileprevious simplification approaches starts from ei-ther the input sentence or its parse tree, our modeltakes as input a deep semantic representationnamely, the Discourse Representation Structure(DRS, (Kamp, 1981)) assigned by Boxer (Curranet al, 2007) to the input complex sentence.
As we435shall see in Section 4, this permits a linguisticallyprincipled account of the splitting operation in thatsemantically shared elements are taken to be thebasis for splitting a complex sentence into sev-eral simpler ones; this facilitates completion (there-creation of the shared element in the split sen-tences); and this provide a natural means to avoiddeleting obligatory arguments.When compared against current state of the artmethods (Zhu et al, 2010; Woodsend and Lapata,2011; Wubben et al, 2012), our model yields sig-nificantly simpler output that is both grammaticaland meaning preserving.2 Related WorkEarlier work on sentence simplification reliedon handcrafted rules to capture syntactic sim-plification e.g., to split coordinated and subor-dinated sentences into several, simpler clausesor to model active/passive transformations (Sid-dharthan, 2002; Chandrasekar and Srinivas, 1997;Bott et al, 2012; Canning, 2002; Siddharthan,2011; Siddharthan, 2010).
While these hand-crafted approaches can encode precise and linguis-tically well-informed syntactic transformation (us-ing e.g., detailed morphological and syntactic in-formation), they are limited in scope to purely syn-tactic rules and do not account for lexical simpli-fications and their interaction with the sententialcontext.Using the parallel dataset formed by Simple En-glish Wikipedia (SWKP)1 and traditional EnglishWikipedia (EWKP)2, more recent work has fo-cused on developing machine learning approachesto sentence simplification.Zhu et al (2010) constructed a parallel cor-pus (PWKP) of 108,016/114,924 complex/simplesentences by aligning sentences from EWKP andSWKP and used the resulting bitext to train a sim-plification model inspired by syntax-based ma-chine translation (Yamada and Knight, 2001).Their simplification model encodes the probabil-ities for four rewriting operations on the parsetree of an input sentences namely, substitution, re-ordering, splitting and deletion.
It is combinedwith a language model to improve grammatical-ity and the decoder translates sentences into sim-1SWKP (http://simple.wikipedia.org) is acorpus of simple texts targeting ?children and adults who arelearning English Language?
and whose authors are requestedto ?use easy words and short sentences?.2http://en.wikipedia.orgpler ones by greedily selecting the output sentencewith highest probability.Using both the PWKP corpus developed byZhu et al (2010) and the edit history of SimpleWikipedia, Woodsend and Lapata (2011) learn aquasi synchronous grammar (Smith and Eisner,2006) describing a loose alignment between parsetrees of complex and of simple sentences.
Fol-lowing Dras (1999), they then generate all possi-ble rewrites for a source tree and use integer lin-ear programming to select the most appropriatesimplification.
They evaluate their model on thesame dataset used by Zhu et al (2010) namely,an aligned corpus of 100/131 EWKP/SWKP sen-tences and show that they achieve better BLEUscore.
They also conducted a human evaluationon 64 of the 100 test sentences and showed againa better performance in terms of simplicity, gram-maticality and meaning preservation.In (Wubben et al, 2012; Coster and Kauchak,2011), simplification is viewed as a monolingualtranslation task where the complex sentence is thesource and the simpler one is the target.
To ac-count for deletions, reordering and substitution,Coster and Kauchak (2011) trained a phrase basedmachine translation system on the PWKP corpuswhile modifying the word alignment output byGIZA++ in Moses to allow for null phrasal align-ments.
In this way, they allow for phrases to bedeleted during translation.
No human evaluationis provided but the approach is shown to result instatistically significant improvements over a tradi-tional phrase based approach.
Similarly, Wubbenet al (2012) use Moses and the PWKP data to traina phrase based machine translation system aug-mented with a post-hoc reranking procedure de-signed to rank the output based on their dissim-ilarity from the source.
A human evaluation on20 sentences randomly selected from the test dataindicates that, in terms of fluency and adequacy,their system is judged to outperform both Zhu etal.
(2010) and Woodsend and Lapata (2011) sys-tems.3 Simplification FrameworkWe start by motivating our approach and explain-ing how it relates to previous proposals w.r.t.,the four main operations involved in simplifica-tion namely, splitting, deletion, substitution andreordering.
We then introduce our framework.436Sentence Splitting.
Sentence splitting is ar-guably semantic based in that in many cases, split-ting occurs when the same semantic entity partici-pates in two distinct eventualities.
For instance, inexample (1) below, the split is on the noun brickswhich is involved in two eventualities namely,?being resistant to cold?
and ?enabling the con-struction of permanent buildings?.
(1) C. Being more resistant to cold, bricks enabled the con-struction of permanent buildings.S.
Bricks were more resistant to cold.
Bricks enabledthe construction of permanent buildings.While splitting opportunities have a clear coun-terpart in syntax (i.e., splitting often occurs when-ever a relative, a subordinate or an appositiveclause occurs in the complex sentence), comple-tion i.e., the reconstruction of the shared elementin the second simpler clause, is arguably seman-tically governed in that the reconstructed elementcorefers with its matching phrase in the first sim-pler clause.
While our semantic based approachnaturally accounts for this by copying the phrasecorresponding to the shared entity in both phrases,syntax based approach such as Zhu et al (2010)and Woodsend and Lapata (2011) will often fail toappropriately reconstruct the shared phrase and in-troduce agreement mismatches because the align-ment or rules they learn are based on syntax alone.For instance, in example (2), Zhu et al (2010)fails to copy the shared argument ?The judge?
tothe second clause whereas Woodsend and Lapata(2011) learns a synchronous rule matching (VPand VP) to (VP.
NP(It) VP) thereby failing to pro-duce the correct subject pronoun (?he?
or ?she?
)for the antecedent ?The judge?.
(2) C. The judge ordered that Chapman should receivepsychiatric treatment in prison and sentenced him totwenty years to life.S1.
The judge ordered that Chapman should get psychi-atric treatment.
In prison and sentenced him to twentyyears to life.
(Zhu et al, 2010)S2.
The judge ordered that Chapman should receivepsychiatric treatment in prison.
It sentenced him totwenty years to life.
(Woodsend and Lapata, 2011)Deletion.
By handling deletion using a proba-bilistic model trained on semantic representations,we can avoid deleting obligatory arguments.
Thusin our approach, semantic subformulae which arerelated to a predicate by a core thematic roles (e.g.,agent and patient) are never considered for dele-tion.
By contrast, syntax based approaches (Zhuet al, 2010; Woodsend and Lapata, 2011) do notdistinguish between optional and obligatory argu-ments.
For instance Zhu et al (2010) simplifies(3C) to (3S) thereby incorrectly deleting the oblig-atory theme (gifts) of the complex sentence andmodifying its meaning to giving knights and war-riors (instead of giving gifts to knights and war-riors).
(3) C. Women would also often give knights and warriorsgifts that included thyme leaves as it was believed tobring courage to the bearer.S.
Women also often give knights and warriors.
Giftsincluded thyme leaves as it was thought to bringcourage to the saint.
(Zhu et al, 2010)We also depart from Coster and Kauchak (2011)who rely on null phrasal alignments for deletionduring phrase based machine translation.
In theirapproach, deletion is constrained by the trainingdata and the possible alignments, independent ofany linguistic knowledge.Substitution and Reordering SMT based ap-proaches to paraphrasing (Barzilay and Elhadad,2003; Bannard and Callison-Burch, 2005) and tosentence simplification (Wubben et al, 2012) haveshown that by utilising knowledge about align-ment and translation probabilities, SMT systemscan account for the substitutions and the reorder-ings occurring in sentence simplification.
Fol-lowing on these approaches, we therefore rely onphrase based SMT to learn substitutions and re-ordering.
In addition, the language model we in-tegrate in the SMT module helps ensuring betterfluency and grammaticality.3.1 An ExampleFigure 1 shows how our approach simplifies (4C)into (4S).
(4) C. In 1964 Peter Higgs published his second paper inPhysical Review Letters describing Higgs mechanismwhich predicted a new massive spin-zero boson for thefirst time.S.
Peter Higgs wrote his paper explaining Higgs mech-anism in 1964.
Higgs mechanism predicted a new ele-mentary particle.The DRS for (4C) produced using Boxer (Cur-ran et al, 2007) is shown at the top of the Figureand a graph representation3 of the dependenciesbetween its variables is shown immediately below.Each DRS variable labels a node in the graph andeach edge is labelled with the relation holding be-tween the variables labelling its end vertices.
The3The DRS to graph conversion goes through several pre-processing steps: the relation nn is inverted making modi-fier noun (higgs) dependent of modified noun (mechanism),named and timex are converted to unary predicates, e.g.,named(x, peter) is mapped to peter(x) and timex(x) =1964 is mapped to 1964(x); and nodes are introduced fororphan words (e.g., which).437((X0named(X0, higgs, per)named(X0, peter, per)?(X1male(X1)?
(X2second(X2)paper(X2)of(X2, X1)?
(X3publish(X3)agent(X3, X0)patient(X3, X2);(X4named(X4, physical, org)named(X4, review, org)named(X4, letters, org)?X5thing(X5)event(X3)in(X3, X4)in(X3, X5)timex(X5) = 1964)))));(X6;(X7, X8mechanism(X8)nn(X7, X8)named(X7, higgs, org)?X9, X10, X11, X12new(X9)massive(X9)spin-zero(X9)boson(X9)predict(X10)event(X10)describe(X11)event(X11)first(X12)time(X12)agent(X10, X8)patient(X10, X9)agent(X11, X6)patient(X11, X8)for(X10, X12)[Discourse Representation Structure produced by BOXER]ROOTO1X10X12X9R10R11X11X8X7R8X6R6R7X3X5X4X2X1R3X0R1R2R4R5R9[DRS Graph Representation]O116 which/WDTX1224, 25, 26 first/a, time/nX1113describe/v, eventX1017predict/v, eventX918, 19, 2021, 22new/a, spin-zero/amassive/a, boson/nX814, 15 mechanism/nX714higgs/orgX66, 7, 8?
?X52thing/n, 1964X410, 11, 12physical/orgreview/org, letters/orgX35publish/v, eventX26, 7, 8 second/a, paper/aX16 male/aX03, 4 higgs/per, peter/pernode pos.
in S predicate/typeR1123for,X10?
X12R1017patient,X10?
X9R917agent,X10?
X8R8??
nn,X8?
X7R713patient,X11?
X8R613agent,X11?
X6R51in,X3?
X5R49in,X3?
X4R36of,X2?
X1R25patient,X3?
X2R15agent,X3?
X0rel pos.
in S predicateROOTX11X8X7R8X6R6R7X3X5X4X2X1R3X0R1R2R4R5ROOTO1X10X12X9X8X7R8R9R10R11( )wwwwSPLITROOTX11X8X7R8X6R6R7X3X5X?2X1R3X0R1R2R5In 1964 Peter Higgs published hispaper describing Higgs mechanismROOTX10X?9X8X7R8R9R10Higgs mechanism predicteda new boson( )wwwwDELETIONPeter Higgs wrote his paper explainingHiggs mechanism in 1964 .Higgs mechanism predicteda new elementary particle .
( )wwwwPBMT+LMFigure 1: Simplification of ?In 1964 Peter Higgs published his second paper in Physical Review Lettersdescribing Higgs mechanism which predicted a new massive spin-zero boson for the first time .
?438two tables to the right of the picture show the pred-icates (top table) associated with each variable andthe relation label (bottom table) associated witheach edge.
Boxer also outputs the associated po-sitions in the complex sentence for each predicate(not shown in the DRS but in the graph tables).
Or-phan words (OW) i.e., words which have no cor-responding material in the DRS (e.g., which at po-sition 16), are added to the graph (node O1) thusensuring that the position set associated with thegraph exactly matches the positions in the inputsentence and thus deriving the input sentence.Split Candidate isSplit prob.
(agent, for, patient) - (agent, in, in,patient)true 0.63false 0.37Table 1: Simplification: SPLITGiven the input DRS shown in Figure 1, simpli-fication proceeds as follows.Splitting.
The splitting candidates of a DRS areevent pairs contained in that DRS.
More precisely,the splitting candidates are pairs4 of event vari-ables associated with at least one of the core the-matic roles (e.g., agent and patient).
The featuresconditioning a split are the set of thematic roles as-sociated with each event variable.
The DRS shownin Figure 1 contains three such event variablesX3,X11and X10with associated thematic rolesets {agent, in, in, patient}, {agent, patient} and{agent, for, patient} respectively.
Hence, there are3 splitting candidates (X3-X11, X3-X10and X10-X11) and 4 split options: no split or split at one ofthe splitting candidates.
Here the split with highestprobability (cf.
Table 1) is chosen and the DRS issplit into two sub-DRS, one containing X3, andthe other containing X10.
After splitting, dan-gling subgraphs are attached to the root of the newsubgraph maximizing either proximity or positionoverlap.
Here the graph rooted in X11is attachedto the root dominating X3and the orphan word O1to the root dominating X10.Deletion.
The deletion model (cf.
Table 2) reg-ulates the deletion of relations and their associatedsubgraph; of adjectives and adverbs; and of orphanwords.
Here, the relations in between X3and X4and for between X10and X12are deleted resultingin the deletion of the phrases ?in Physical ReviewLetters?
and ?for the first time?
as well as the ad-4The splitting candidates could be sets of event variablesdepending on the number of splits required.
Here, we con-sider pairs for 2 splits.jectives second, massive, spin-zero and the orphanword which.Substitution and Reordering.
Finally the trans-lation and language model ensures that published,describing and boson are simplified to wrote, ex-plaining and elementary particle respectively; andthat the phrase ?In 1964?
is moved from the be-ginning of the sentence to its end.3.2 The Simplification ModelOur simplification framework consists of a prob-abilistic model for splitting and dropping whichwe call DRS simplification model (DRS-SM); aphrase based translation model for substitutionand reordering (PBMT); and a language modellearned on Simple English Wikipedia (LM) forfluency and grammaticality.
Given a complex sen-tence c, we split the simplification process intotwo steps.
First, DRS-SM is applied to Dc(theDRS representation of the complex sentence c)to produce one or more (in case of splitting) in-termediate simplified sentence(s) s?.
Second, thesimplified sentence(s) s?
is further simplified to susing a phrase based machine translation system(PBMT+LM).
Hence, our model can be formallydefined as:s?
= argmaxsp(s|c)= argmaxsp(s?|c)p(s|s?
)= argmaxsp(s?|Dc)p(s?|s)p(s)where the probabilities p(s?|Dc), p(s?|s) andp(s) are given by the DRS simplification model,the phrase based machine translation model andthe language model respectively.To get the DRS simplification model, we com-bine the probability of splitting with the probabil-ity of deletion:p(s?|Dc) =??:str(?
(Dc))=s?p(Dsplit|Dc)p(Ddel|Dsplit)where ?
is a sequence of simplification opera-tions and str(?
(Dc)) is the sequence of words as-sociated with a DRS resulting from simplifying Dcusing ?.The probability of a splitting operation for agiven DRS Dcis:p(Dsplit|Dc) =??
?SPLIT(sptruecand), split at spcand?spcandSPLIT(spfalsecand), otherwise439relation candidate isDrop prob.relationwordlengthrangein 0-2 true 0.22false 0.72in 2-5 true 0.833false 0.167mod.
cand.
isDrop prob.mod wordnewtrue 0.22false 0.72massive true 0.833false 0.167OW candidate isDrop prob.orphanword isBoundaryand true true 0.82false 0.18which false true 0.833false 0.167Table 2: Simplification: DELETION (Relations, modifiers and OW respectively)That is, if the DRS is split on the splitting candi-date spcand, the probability of the split is then givenby the SPLIT table (Table 1) for the isSplit value?true?
and the split candidate spcand; else it is theproduct of the probability given by the SPLIT tablefor the isSplit value ?false?
for all split candidateconsidered for Dc.
As mentioned above, the fea-tures used for determining the split operation arethe role sets associated with pairs of event vari-ables (cf.
Table 1).The deletion probability is given by three mod-els: a model for relations determining the deletionof prepositional phrases; a model for modifiers(adjectives and adverbs) and a model for orphanwords (Table 2).
All three deletion models use theassociated word itself as a feature.
In addition, themodel for relations uses the PP length-range as afeature while the model for orphan words relies onboundary information i.e., whether or not, the OWoccurs at the associated sentence boundary.p(Ddel|Dsplit) =?relcandDELrel(relcand)?modcandDELmod(modcand)?owcandDELow(owcand)3.3 Estimating the parametersWe use the EM algorithm (Dempster et al, 1977)to estimate our split and deletion model parame-ters.
For an efficient implementation of EM algo-rithm, we follow the work of Yamada and Knight(2001) and Zhu et al (2010); and build traininggraphs (Figure 2) from the pair of complex andsimple sentence pairs in the training data.Each training graph represents a complex-simple sentence pair and consists of two typesof nodes: major nodes (M-nodes) and operationnodes (O-nodes).
An M-node contains the DRSrepresentation Dcof a complex sentence c and theassociated simple sentence(s) siwhile O-nodesdetermine split and deletion operations on theirparent M-node.
Only the root M-node is consid-ered for the split operations.
For example, givenfindel-rel?
; del-mod?
; del-ow?splitrootFigure 2: An example training graphthe root M-node (Dc, (s1, s2)), multiple success-ful split O-nodes will be created, each one furthercreating two M-nodes (Dc1, s1) and (Dc2, s2).
Forthe training pair (c, s), the root M-node (Dc, s) isfollowed by a single split O-node producing an M-node (Dc, s) and counting all split candidates in Dcfor failed split.
The M-nodes created after split op-erations are then tried for multiple deletion opera-tions of relations, modifiers and OW respectively.Each deletion candidate creates a deletion O-nodemarking successful or failed deletion of the can-didate and a result M-node.
The deletion processcontinues on the result M-node until there is nodeletion candidate left to process.
The governingcriteria for the construction of the training graphis that, at each step, it tries to minimize the Leven-shtein edit distance between the complex and thesimple sentences.
Moreover, for the splitting op-eration, we introduce a split only if the referencesentence consists of several sentences (i.e., thereis a split in the training data); and only considersplits which maximises the overlap between splitand simple reference sentences.We initialize our probability tables Table 1 andTable 2 with the uniform distribution, i.e., 0.5 be-cause all our features are binary.
The EM algo-rithm iterates over training graphs counting modelfeatures from O-nodes and updating our probabil-ity tables.
Because of the space constraints, wedo not describe our algorithm in details.
We referthe reader to (Yamada and Knight, 2001) for moredetails.440Our phrase based translation model is trainedusing the Moses toolkit5 with its default commandline options on the PWKP corpus (except the sen-tences from the test set) considering the complexsentence as the source and the simpler one as thetarget.
Our trigram language model is trained us-ing the SRILM toolkit6 on the SWKP corpus7.Decoding.
We explore the decoding graph sim-ilar to the training graph but in a greedy approachalways picking the choice with maximal probabil-ity.
Given a complex input sentence c, a split O-node will be selected corresponding to the deci-sion of whether to split and where to split.
Next,deletion O-nodes are selected indicating whetheror not to drop each of the deletion candidate.
TheDRS associated with the final M-node Dfinis thenmapped to a simplified sentence s?finwhich isfurther simplified using the phrase-based machinetranslation system to produce the final simplifiedsentence ssimple.4 ExperimentsWe trained our simplification and translation mod-els on the PWKP corpus.
To evaluate perfor-mance, we compare our approach with three otherstate of the art systems using the test set providedby Zhu et al (2010) and relying both on automaticmetrics and on human judgments.4.1 Training and Test DataThe DRS-Based simplification model is trainedon PWKP, a bi-text of complex and simple sen-tences provided by Zhu et al (2010).
To constructthis bi-text, Zhu et al (2010) extracted complexand simple sentences from EWKP and SWKP re-spectively and automatically aligned them usingTF*IDF as a similarity measure.
PWKP contains108016/114924 complex/simple sentence pairs.We tokenize PWKP using Stanford CoreNLPtoolkit8.
We then parse all complex sentencesin PWKP using Boxer9 to produce their DRSs.Finally, our DRS-Based simplification model istrained on 97.75% of PWKP; we drop out 2.25%of the complex sentences in PWKP which are re-peated in the test set or for which Boxer fails toproduce DRSs.5http://www.statmt.org/moses/6http://www.speech.sri.com/projects/srilm/7We downloaded the snapshots of Simple Wikipediadated 2013-10-30 available at http://dumps.wikimedia.org/.8http://nlp.stanford.edu/software/corenlp.shtml9http://svn.ask.it.usyd.edu.au/trac/candc, Version 1.00We evaluate our model on the test set used byZhu et al (2010) namely, an aligned corpus of100/131 EWKP/SWKP sentences.
Boxer pro-duces a DRS for 96 of the 100 input sentences.These input are simplified using our simplifica-tion system namely, the DRS-SM model and thephrase-based machine translation system (Section3.2).
For the remaining four complex sentences,Boxer fails to produce DRSs.
These four sen-tences are directly sent to the phrase-based ma-chine translation system to produce simplified sen-tences.4.2 Automatic Evaluation MetricsTo assess and compare simplification systems, twomain automatic metrics have been used in previ-ous work namely, BLEU and the Flesch-KincaidGrade Level Index (FKG).The FKG index is a readability metric takinginto account the average sentence length in wordsand the average word length in syllables.
In itsoriginal context (language learning), it was ap-plied to well formed text and thus measured thesimplicity of a well formed sentence.
In the con-text of the simplification task however, the auto-matically generated sentences are not necessarilywell formed so that the FKG index reduces to ameasure of the sentence length (in terms of wordsand syllables) approximating the simplicity levelof an output sentence irrespective of the lengthof the corresponding input.
To assess simplifica-tion, we instead use metrics that are directly re-lated to the simplification task namely, the numberof splits in the overall (test and training) data andin average per sentences; the number of generatedsentences with no edits i.e., which are identical tothe original, complex one; and the average Leven-shtein distance between the system?s output andboth the complex and the simple reference sen-tences.BLEU gives a measure of how close a system?soutput is to the gold standard simple sentence.
Be-cause there are many possible ways of simplifyinga sentence, BLEU alone fails to correctly assessthe appropriateness of a simplification.
MoreoverBLEU does not capture the degree to which thesystem?s output differs from the complex sentenceinput.
We therefore use BLEU as a means to eval-uate how close the systems output are to the refer-ence corpus but complement it with further man-ual metrics capturing other important factors when441evaluating simplifications such as the fluency andthe adequacy of the output sentences and the de-gree to which the output sentence simplifies theinput.4.3 Results and DiscussionNumber of Splits Table 3 shows the proportionof input whose simplification involved a splittingoperation.
While our system splits in proportionsimilar to that observed in the training data, theother systems either split very often (80% of thetime for Zhu and 63% of the time for Woodsend)or not at all (Wubben).
In other words, when com-pared to the other systems, our system performssplits in proportion closest to the reference bothin terms of total number of splits and of averagenumber of splits per sentence.Data Total numberof sentences % splitaverage split /sentencePWKP 108,016 6.1 1.06GOLD 100 28 1.30Zhu 100 80 1.80Woodsend 100 63 2.05Wubben 100 1 1.01Hybrid 100 10 1.10Table 3: Proportion of Split Sentences (% split)in the training/test data and in average per sen-tence (average split / sentence).
GOLD is thetest data with the gold standard SWKP sentences;Zhu, Woodsend, Wubben are the best output of themodels of Zhu et al (2010), Woodsend and Lap-ata (2011) and Wubben et al (2012) respectively;Hybrid is our model.Number of Edits Table 4 indicates the edit dis-tance of the output sentences w.r.t.
both the com-plex and the simple reference sentences as well asthe number of input for which no simplificationoccur.
The right part of the table shows that oursystem generate simplifications which are closestto the reference sentence (in terms of edits) com-pared to those output by the other systems.
Italso produces the highest number of simplifica-tions which are identical to the reference.
Con-versely our system only ranks third in terms of dis-similarity with the input complex sentences (6.32edits away from the input sentence) behind theWoodsend (8.63 edits) and the Zhu (7.87 edits)system.
This is in part due to the difference insplitting strategies noted above : the many splitsapplied by these latter two systems correlate witha high number of edits.System BLEUEdits (Complexto System)Edits (Systemto Simple)LD No edit LD No editGOLD 100 12.24 3 0 100Zhu 37.4 7.87 2 14.64 0Woodsend 42 8.63 24 16.03 2Wubben 41.4 3.33 6 13.57 2Hybrid 53.6 6.32 4 11.53 3Table 4: Automated Metrics for Simplification:average Levenshtein distance (LD) to complex andsimple reference sentences per system ; number ofinput sentences for which no simplification occur(No edit).BLEU score We used Moses support tools:multi-bleu10 to calculate BLEU scores.
TheBLEU scores shown in Table 4 show that our sys-tem produces simplifications that are closest to thereference.In sum, the automatic metrics indicate that oursystem produces simplification that are consis-tently closest to the reference in terms of edit dis-tance, number of splits and BLEU score.4.4 Human EvaluationThe human evaluation was done online using theLG-Eval toolkit (Kow and Belz, 2012)11.
Theevaluators were allocated a trial set using a LatinSquare Experimental Design (LSED) such thateach evaluator sees the same number of outputfrom each system and for each test set item.
Dur-ing the experiment, the evaluators were presentedwith a pair of a complex and a simple sentence(s)and asked to rate this pair w.r.t.
to adequacy (Doesthe simplified sentence(s) preserve the meaningof the input?)
and simplification (Does the gen-erated sentence(s) simplify the complex input?
).They were also asked to rate the second (sim-plified) sentence(s) of the pair w.r.t.
to fluency(Is the simplified output fluent and grammatical?
).Similar to the Wubben?s human evaluation setup,we randomly selected 20 complex sentences fromZhu?s test corpus and included in the evaluationcorpus: the corresponding simple (Gold) sentencefrom Zhu?s test corpus, the output of our system(Hybrid) and the output of the other three sys-tems (Zhu, Woodsend and Wubben) which wereprovided to us by the system authors.
The eval-uation data thus consisted of 100 complex/simplepairs.
We collected ratings from 27 participants.10http://www.statmt.org/moses/?n=Moses.SupportTools11http://www.nltg.brighton.ac.uk/research/lg-eval/442All were either native speakers or proficient in En-glish, having taken part in a Master taught in En-glish or lived in an English speaking country foran extended period of time.Systems Simplification Fluency AdequacyGOLD 3.57 3.93 3.66Zhu 2.84 2.34 2.34Woodsend 1.73 2.94 3.04Wubben 1.81 3.65 3.84Hybrid 3.37 3.55 3.50Table 5: Average Human Ratings for simplicity,fluency and adequacyTable 5 shows the average ratings of the humanevaluation on a slider scale from 0 to 5.
Pairwisecomparisons between all models and their statisti-cal significance were carried out using a one-wayANOVA with post-hoc Tukey HSD tests and areshown in Table 6.Systems GOLD Zhu Woodsend WubbenZhu ??Woodsend ??
??Wubben ?N ??
?Hybrid N ?
?N ?NTable 6: ?/ is/not significantly different (sig.diff.)
wrt simplicity.
/ is/not sig.
diff.
wrtfluency.
?/N is/not sig.
diff.
wrt adequacy.
(sig-nificance level: p < 0.05)With regard to simplification, our system ranksfirst and is very close to the manually simpli-fied input (the difference is not statistically signif-icant).
The low rating for Woodsend reflects thehigh number of unsimplified sentences (24/100 inthe test data used for the automatic evaluation and6/20 in the evaluation data used for human judg-ments).
Our system data is not significantly differ-ent from the manually simplified data for simplic-ity whereas all other systems are.For fluency, our system rates second behindWubben and before Woodsend and Zhu.
Thedifference between our system and both Zhuand Woodsend system is significant.
In partic-ular, Zhu?s output is judged less fluent proba-bly because of the many incorrect splits it li-censes.
Manual examination of the data showsthat Woodsend?s system also produces incorrectsplits.
For this system however, the high propor-tion of non simplified sentences probably counter-balances these incorrect splits, allowing for a goodfluency score overall.Regarding adequacy, our system is against clos-est to the reference (3.50 for our system vs.3.66 for manual simplification).
Our system, theWubben system and the manual simplificationsare in the same group (the differences betweenthese systems are not significant).
The Wood-send system comes second and the Zhu systemthird (the difference between the two is signifi-cant).
Wubben?s high fluency, high adequacy butlow simplicity could be explained with their min-imal number of edit (3.33 edits) from the sourcesentence.In sum, if we group together systems for whichthere is no significant difference, our system ranksfirst (together with GOLD) for simplicity; firstfor fluency (together with GOLD and Wubben);and first for adequacy (together with GOLD andWubben).5 ConclusionA key feature of our approach is that it is seman-tically based.
Typically, discourse level simplifi-cation operations such as sentence splitting, sen-tence reordering, cue word selection, referring ex-pression generation and determiner choice are se-mantically constrained.
As argued by Siddharthan(2006), correctly capturing the interactions be-tween these phenomena is essential to ensuringtext cohesion.
In the future, we would like toinvestigate how our framework deals with suchdiscourse level simplifications i.e., simplificationswhich involves manipulation of the coreferenceand of the discourse structure.
In the PWKP data,the proportion of split sentences is rather low (6.1%) and many of the split sentences are simple sen-tence coordination splits.
A more adequate butsmall corpus is that used in (Siddharthan, 2006)which consists of 95 cases of discourse simplifica-tion.
Using data from the language learning or thechildren reading community, it would be interest-ing to first construct a similar, larger scale corpus;and to then train and test our approach on morecomplex cases of sentence splitting.AcknowledgmentsWe are grateful to Zhemin Zhu, Kristian Wood-send and Sander Wubben for sharing their data.We would like to thank our annotators for partic-ipating in our human evaluation experiments andto anonymous reviewers for their insightful com-ments.443ReferencesColin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Pro-ceedings of the 43rd Annual Meeting on Associationfor Computational Linguistics (ACL), pages 597?604.
Association for Computational Linguistics.Regina Barzilay and Noemie Elhadad.
2003.
Sen-tence alignment for monolingual comparable cor-pora.
In Proceedings of the 2003 conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 25?32.
Association for Computa-tional Linguistics.Stefan Bott, Horacio Saggion, and Simon Mille.
2012.Text simplification tools for spanish.
In Proceedingsof the 8th International Conference on LanguageResources and Evaluation (LREC), pages 1665?1671.Yvonne Margaret Canning.
2002.
Syntactic simplifica-tion of Text.
Ph.D. thesis, University of Sunderland.John Carroll, Guido Minnen, Darren Pearce, YvonneCanning, Siobhan Devlin, and John Tait.
1999.Simplifying text for language-impaired readers.
InProceedings of 9th Conference of the EuropeanChapter of the Association for Computational Lin-guistics (EACL), volume 99, pages 269?270.
Cite-seer.Raman Chandrasekar and Bangalore Srinivas.
1997.Automatic induction of rules for text simplification.Knowledge-Based Systems, 10(3):183?190.Raman Chandrasekar, Christine Doran, and Banga-lore Srinivas.
1996.
Motivations and methods fortext simplification.
In Proceedings of the 16th In-ternational conference on Computational linguistics(COLING), pages 1041?1044.
Association for Com-putational Linguistics.William Coster and David Kauchak.
2011.
Learning tosimplify sentences using wikipedia.
In Proceedingsof the Workshop on Monolingual Text-To-Text Gen-eration, pages 1?9.
Association for ComputationalLinguistics.James R Curran, Stephen Clark, and Johan Bos.
2007.Linguistically motivated large-scale NLP with C&Cand Boxer.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguistics(ACL) on Interactive Poster and Demonstration Ses-sions, pages 33?36.
Association for ComputationalLinguistics.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum likelihood from incomplete data via theem algorithm.
Journal of the Royal Statistical Soci-ety, Series B, 39(1):1?38.Mark Dras.
1999.
Tree adjoining grammar and thereluctant paraphrasing of text.
Ph.D. thesis, Mac-quarie University NSW 2109 Australia.Katja Filippova and Michael Strube.
2008.
Depen-dency tree based sentence compression.
In Proceed-ings of the Fifth International Natural LanguageGeneration Conference (INLG), pages 25?32.
Asso-ciation for Computational Linguistics.Hans Kamp.
1981.
A theory of truth and semantic rep-resentation.
In J.A.G.
Groenendijk, T.M.V.
Janssen,B.J.
Stokhof, and M.J.B.
Stokhof, editors, Formalmethods in the study of language, number pt.
1 inMathematical Centre tracts.
Mathematisch Centrum.Kevin Knight and Daniel Marcu.
2000.
Statistics-based summarization-step one: Sentence compres-sion.
In Proceedings of the Seventeenth NationalConference on Artificial Intelligence (AAAI) andTwelfth Conference on Innovative Applications ofArtificial Intelligence (IAAI), pages 703?710.
AAAIPress.Eric Kow and Anja Belz.
2012.
LG-Eval: A Toolkitfor Creating Online Language Evaluation Experi-ments.
In Proceedings of the 8th InternationalConference on Language Resources and Evaluation(LREC), pages 4033?4037.Advaith Siddharthan, Ani Nenkova, and KathleenMcKeown.
2004.
Syntactic simplification for im-proving content selection in multi-document sum-marization.
In Proceedings of the 20th InternationalConference on Computational Linguistics (COL-ING), page 896.
Association for Computational Lin-guistics.Advaith Siddharthan.
2002.
An architecture for a textsimplification system.
In Proceedings of the Lan-guage Engineering Conference (LEC), pages 64?71.IEEE Computer Society.Advaith Siddharthan.
2006.
Syntactic simplificationand text cohesion.
Research on Language and Com-putation, 4(1):77?109.Advaith Siddharthan.
2010.
Complex lexico-syntacticreformulation of sentences using typed dependencyrepresentations.
In Proceedings of the 6th Inter-national Natural Language Generation Conference(INLG), pages 125?133.
Association for Computa-tional Linguistics.Advaith Siddharthan.
2011.
Text simplification us-ing typed dependencies: a comparison of the robust-ness of different generation strategies.
In Proceed-ings of the 13th European Workshop on Natural Lan-guage Generation (ENLG), pages 2?11.
Associationfor Computational Linguistics.David A Smith and Jason Eisner.
2006.
Quasi-synchronous grammars: Alignment by soft projec-tion of syntactic dependencies.
In Proceedings ofthe HLT-NAACL Workshop on Statistical MachineTranslation, pages 23?30.
Association for Compu-tational Linguistics.444David Vickrey and Daphne Koller.
2008.
Sentencesimplification for semantic role labeling.
In Pro-ceedings of the 46th Annual Meeting of the Associ-ation for Computational Linguistics (ACL) and theHuman Language Technology Conference (HLT),pages 344?352.Willian Massami Watanabe, Arnaldo Candido Junior,Vin?
?cius Rodriguez Uze?da, Renata Pontin de Mat-tos Fortes, Thiago Alexandre Salgueiro Pardo, andSandra Maria Alu??sio.
2009.
Facilita: reading as-sistance for low-literacy readers.
In Proceedings ofthe 27th ACM international conference on Design ofcommunication, pages 29?36.
ACM.Kristian Woodsend and Mirella Lapata.
2011.
Learn-ing to simplify sentences with quasi-synchronousgrammar and integer programming.
In Proceedingsof the Conference on Empirical Methods in Natu-ral Language Processing (EMNLP), pages 409?420.Association for Computational Linguistics.Sander Wubben, Antal van den Bosch, and EmielKrahmer.
2012.
Sentence simplification by mono-lingual machine translation.
In Proceedings of the50th Annual Meeting of the Association for Com-putational Linguistics (ACL): Long Papers-Volume1, pages 1015?1024.
Association for ComputationalLinguistics.Kenji Yamada and Kevin Knight.
2001.
A syntax-based statistical translation model.
In Proceedingsof the 39th Annual Meeting on Association for Com-putational Linguistics (ACL), pages 523?530.
Asso-ciation for Computational Linguistics.Zhemin Zhu, Delphine Bernhard, and Iryna Gurevych.2010.
A monolingual tree-based translation modelfor sentence simplification.
In Proceedings of the23rd International Conference on ComputationalLinguistics (COLING), pages 1353?1361, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.445
