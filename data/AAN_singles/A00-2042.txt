Understanding "Each Other"Cla i re  GardentComputat iona l  L ingu is t i csUn ivers i ty  of  the  Saar landSaarbr f i cken ,  Germanyclaire@coli, uni-sb, deKars ten  KonradComputer  Sc ienceUn ivers i ty  of  the  Saar landSaarbr i i cken ,  Germanykonrad?ags, un i - sb ,  deAbst ractAlthough natural anguage is ambiguous, vari-ous linguistic and extra-linguistic factors oftenhelp determine a preferred reading.
In this pa-per, we show that model generation can be usedto model this process in the case of reciprocalstatements.
The proposed analysis builds on in-sights from Dalrymple t al.
98 and is shown toprovide an integrated, computational ccountof the interplay between model theoretic inter-pretation, knowledge-based reasoning and pref-erences that characterises the interpretation ofreciprocals.1 In t roduct ionAlthough there is widespread agreement thatinference is an essential component of naturallanguage processing, little work has been doneso far on whether existing automated reason-ing systems uch as theorem provers and modelbuilders could be fruitfully put to work in thearea of natural anguage interpretation.In this paper, we focus on the inference prob-lems raised by the reciprocal expression eachother and show that model generation providesan adequate tool for modeling them.The paper is structured as follows.
Section 3discusses the meaning of reciprocal statementsand proposes a formal semantics for each other.Section 2 shows how model generation can beused to provide this semantics with a compu-tational interpretation.
Section 4 compares ourapproach with the account of reciprocals whichinspired it in the first place namely, (Dalrympleet al, 1998).
Section 5 concludes with pointersfor further esearch.2 The  mean ing  of  rec ip roca ls ta tementsIn the linguistic literature, the reciprocal ex-pression each other is often taken to denote adyadic quantifier over a first-order set, which wewill call the antecedent  set, and a binary first-order relation, which we will call the scope re-lation.
In what follows, we assume an approachof this type and will use the symbol RcP forsuch reciprocal quantifiers o that the seman-tic representation f e.g.
Jon and Bill saw eachother will be:(1) RcP({jon, saw(x, y))When antecedent sets of just two membersare considered, each set member is required tostand in the scope relation to each other mem-ber.
For larger sets however, research on recip-rocal statements has uncovered a variety of log-ical contributions that the reciprocal can pro-vide.
Here are some examples.
(2) The students like each other.Vx (std(x) -+ Vy ( x  y A std(y) -+like(x,y))(3) The students tare at each other in sur-prise.Vx (std(x) -+ ~y (x ?
y A std(y) Astare_at(x, y ) )(4) The students gave each other measles.Vx (std(x) -+ 3y (x ?
y A std(y) A(gave_measles(x, y) V gave_measle(y, x))))We can accept (2) to be true only if for eachpair x and y of two students it holds that xlikes y.
But an analogous interpretation wouldbe invalid in the case of (3) and (4) where notall pairs in the antecedent set the students canconsistently stand in the scope relation (one canonly stare at most at one person at a time, and319one can only get measles from at most one per-son).
More generally, (Langendoen, 1978; Dal-rymple et al, 1998) convincingly argues thatdifferent reciprocal statements can have verydifferent ruth conditions.
The challenge to beaddressed is thus the following: How can wedetermine a (computational) semantics for thereciprocal expressions each other that accountsfor these multiplicity of meanings while predict-ing the specific meaning of a particular ecipro-cal statement?Clearly knowledge based reasoning plays animportant role: only those readings are possiblethat are consistent with our knowledge aboutthe situation and the world.
Specifically, knowl-edge based reasoning constrains the strength ofthe truth conditions of a reciprocal statement.Thus if we abstract away from the specific scoperelations, the truth conditions of examples uchas (2),(3) and (4) are ordered through entail-ment as follows (with A the antecedent set andR the scope relation):Vx (A(x) --~ Vy (A(y) --).
R(xy))Vx (A(x) ~ 9y (A(y) A e(xy))Vx (A(x) --~ 3y (A(y) A (e(xy) V (e(yx)))Specifically, example (2), which does not in-volve any strong knowledge based constraint,has the strongest truth-conditions of the threeexamples.
By contrast in (3), the knowledgethat one can stare at most at one person, forcesa V3 reading while in (4), a weaker meaning stillis imposed by knowledge based constraints: thex gave y measles relation is asymmetric hencethe k~/reading is ruled out; moreover, since onecannot be infected twice, some students in thegroup will be infected but not pass on the dis-ease to anyone.
Hence the strongest truth con-ditions that can be assigned the sentence are theVS disjunctive reading indicated in (4).But are there any other constraints on theinterpretation process than these knowledgebased constraints?
And which meaning shallwe assign a reciprocal expression?
The compu-tational semantics we will propose is inspiredfrom (Dalrymple t al., 1998) and relies on thefollowing observations.First, we note that (Dalrymple t al., 1998)identifies a lower bound for the truth conditionsof reciprocal sentences which they dub InclusiveAlternative Ordering (IAO).
It is exemplified bysentence (4) above and corresponds to the fol-lowing definition of RcP.
(5) RCPIAO ~-- APAR (\[P\[ > 2 A Vx (P(x) =v3y p(y) ^  x # y ^  (R(x, v) v R(V, x))))This definition only adequately characterises x-amples such as (4).
It does not cover thestronger meanings of the reciprocal in sentencessuch as (2) and (3).
However, each known formof reciprocity entails RCPIAO'S truth conditions,and RCPIAO therefore provides us with a mini-mal semantics for reciprocals.Further, we observe that given a particularreciprocal statement, here seems to be a pref-erence for consistent interpretations where thenumber of pairs that are in the scope relationis as large as possible.
For instance in (3), notevery student can stare at every other student(one can stare at at most one person), but intu-itively, the sentence requires that every studentstares at some other student.
While such aninterpretation is much weaker than that of (2),this maximisation of the scope relation yields areading that is also much stronger than the min-imal IAO interpretation of (4).
More generally,while IAO provides us with a lower bound forthe interpretation of reciprocal statements, wewill see in section 3 that the maximisation ofthescope relation that is consistent with contextualknowledge yields the upper bound for the inter-pretation of a particular eciprocal statementi.e., its meaning.Based on these observations, the principle de-termining the actual logical contribution of areciprocal statement can be stated as follows:Maximise Meaning Hypothesis(MMH) :  The valid interpretations ofa reciprocal sentence S in a context F(where I" includes knowledge about theprevious discourse, the discourse situ-ation and the world) are those which(a) are consistent both with the IAOform of reciprocity and the informa-tion provided by F, and (b) whose con-tributions to the scope relation are thestrongest.The MMH selects from the set of interpreta-tions that are consistent with IAO and contex-tual knowledge, those that maximise the scoperelation.
Crucially, this view of reciprocals leads320to an inference method that can actually com-pute the preferred interpretations of reciprocalsentences.
We now turn to this.3 In terpretat ion  as Mode lGenerat ionIn Discourse Representation Theory (DRT,(Kamp, 1981; Kamp and Reyle, 1993)), a sen-tence with semantic representation (I) is truewith respect o a model M iff there is an embed-ding of (I) onto M. Intuitively, this requirementsays that a sub-model M'  of M must be foundwhich satisfies (I).
So for instance, sentence (6a)is true in M iff there are two individuals bugsand bunny in M such that bugs and bunny standin the love relation; or in other words, iff thepartial model sketched in (6b) is part of M.(6) a. Bugs likes Bunny.b.
{love(bugs, bunny)}As shown in (Gardent and Konrad, To ap-pear), model generators (i.e., programs thatcompute some of the models satisfying a finiteset of logical formulas) can be used to provideDRT, and more generally model-theoretic ap-proaches to natural anguage semantics, with aprocedural interpretation: Given the semanticrepresentation of a discourse and the relevantworld knowledge (I) (i.e., a finite set of logicalformulas), a model generator proves that (I) issatisfiable by generating some of its models.Intuitively, satisfying models explain how dis-courses can be made true.
They give anabstract representation of how (part of) theworld should be for a discourse to be true.Concretely, satisfying models can be seen ascapturing the meaning of discourses: data-bases that can be queried e.g.
as part ofa query/answer system or to interpret subse-quent discourse.
Satisfying models are alsoremininiscent of Johnson-Laird's mental mod-els (Johnson-Laird and Byrne, 1991) and inessence, mental models are very much like theHerbrand models we are making use of here.Formally, a mode l  is a mathematical struc-ture that describes how the symbols of a logi-cal theory are interpreted.
Given a first-orderlanguage ?, a model is a pair (I, D) with D anon-empty set of entities (the domain  o f  indi-v iduals)  and I an interpretation function whichmaps relation symbols in ?
to relations of ap-propriate arity in D and constant symbols in ?
:to elements of D. Here we identify these mod-els with sets of positive assumptions that unam-biguously define the interpretation of the rela-tion symbols and fix the interpretation of termsto first-order entities that carry a unique name.These are known in the literature as Herbrandmodels.The set (7c) is such a model for the logicalform (7b) which is a semantic representation fthe sentence (7a).
(7) a. Jon likes his cousin.b.
3x cousin_of(x, jon) A like(ion, x)c. ~'il = {cousin_of(cl,jon),like (jon, cl) }The model A41 defines an interpretation ofthe predicates cousin and like over the universeof discourse 7) = {jon, cl }.
It can also be takenas a valid interpretation of (7a).There are, how-ever, infinitely many models for (7b) that donot correspond to such interpretations e.g.
(8) .M2 = {cousin_of(jon, jon), like(jon, j on)}(9) Ad3 = {cousin_of(c1, jon), fike(jon, C1) ,like( cl , jon ) }The model ..A42 explains the truth of (Ta) bydeclaring Jon as his own cousin.
This is a re-sult of the inappropriate semantic representa-tion (7b) which fails to specify that the relationexpressed by the noun cousin is irreflexive.
Inthe case of A43, the model contains uperfluousinformation.
While it is consistent o assumelike(cl,jon) it is not necessary for explainingthe truth of the input.3.1 M in imal i tyFor applications to natural-language, weare in-terested in exactly those models that capturethe meaning of a discourse, or at least capturethe preferred interpretations that a hearer asso-ciates with it.
As discussed in (Gardent andWebber, January 2000), obtaining only thesemodels requires eliminating both models thatare "too small" (e.g.
A42) and models that are"too big" (e.g.
J~43).Models such as A42 can be eliminated simplyby using more appropriate truth conditions forNL expressions (e.g.
3x cousin(x) A of(x, jon) Ax ~ jon A like(jon, x) for (7a)).
In general how-ever, eliminating models that are "too small"is a non-trivial task which involves the interac-tion of model-theoretic interpretation not only321with world knowledge reasoning but also withsyntax, prosody and pragmatics.
The issue isdiscussed at some length (though not solved) in(Gardent and Webber, January 2000).To eliminate models that are "too big", somenotion of minimality must be resorted to.
Forinstance, (Gardent and Konrad, 1999; Gardentand Konrad, To appear) argues that local min-imality is an adequate form of minimality forinterpreting definite descriptions.
Local mini-mality is defined as follows.Local  Min imal i ty :  Let ~ be a set of first-order formulas and D be the set of Herbrandmodels of ?
that use some finite domain Dwhose size is minimal.
Then a model ( I ,D) ED is locally min imal  iff there is no othermodel (I t, D ~) E D such that I I C I.Locally minimal models are models that sat-isfy some input ?
within a minimal domain :D ofindividuals and are subset-minimal with respectto all other domain minimal models.
Thesemodels are the simplest in the sense of Occam'sRazor and often the best explanation for thetruth of an observation.
In particular, if we as-sume that A42 is ruled out by a more appro-priate semantics for the word cousin, local min-imality rules out -1~3 as non locally minimal andtherefore A41 is correctly identified as giving thepreferred interpretation for example (7).3.2 The  MMH as a M in ima l i tyConstra intIn the case of reciprocals, local minimalityis clearly not a characterisation of preferredinterpretations.
Our semantic representationRCPIA 0 will only capture a reciprocal's mean-ing if the reciprocal group has exactly two mem-bers or if the input meets IAO, the weakest formof reciprocity.
For instance, the locally minimalmodel (10c) of formula (10b) is too weak to con-stitute an acceptable interpretation f (10a).
In-stead, the model capturing the meaning of (10a)is the model given in (10d).
(10) a. Jon, Bill and Dan like each other.b.
RCPIAO({jon, bill, dan})()~y)~x like(x, y))c. {like(yon, bill), like(bill, dan)}d. {like(ion, bill), like(jon, dan), like(bill, dan),like(bill, jon), like (dan, bill), like(dan, ion)}Since the MMH ma.ximises rather than min-imises the logical contribution of formulas, itseems at first sight incompatible with local min-imality.
However, a simple method to combinethe MMH and model minimality is to considerthe maximisation of reciprocal relations as aminimisation of their complement sets.
Afterall, the difference in acceptability between (10c)and (10d) as models for (10a) is due to exactlythose pairs (x, y) (with x ~ y) that are not inthe like relation.
To capture this intuition, weintroduce a special predicate $R that indicatesassumptions whose truth is considered "costly".In our case, these assumptions correspond to thepairs of individuals that are not in the scope re-lation.
The semantic representation f recipro-cal each other is then as follows.
(11) RcP =__ )~P)~R (RCPIAo(P)(R) AVxVy (e(x) A P(y) A x ?
y A -~R(x, y) ~=~$R(x, y)))The first conjunct says that a reciprocal sen-tence has as weakest possible meaning an IAOreading.
Since IAO is entailed by other identi-fied meaning for reciprocal statements, this iscompatible with the fact that reciprocal sen-tences can have other, stronger meanings.
Thesecond conjunct says that each pair (x, y) (withx ?
y) that is not  in the like relation is inthe $R relation.
This encoding leads to mod-els like (12b) and (12c) for (12a).
We say thatmodel (125) has a $R-cost of 4 ($R4), whilemodel (12c) has a cost of 0.
(12) a. RcP({jon, bill, dan})(XyXx like(x, y))b.
{like(ion, bill), like(ion, dan), $R(bill, dan),$R(bill, jon), SR(dan, bill), SR(dan, ion)}$R4c.
{like(ion, bill), like(ion, dan), like(bill, dan),like(bill, ion), like(dan, bill), like(dan, ion)}$ROWe now introduce a new form of minimalitywhose definition is as follows.Conservat ive  Min imal i ty :  Let ~ be a setof first-order formulas and D be the set of Her-brand models of ~2 with a minimal domain T).Then D has a subset C of models that carrya minimal cost.
A model ( I ,D) E C is con-servative minimal iff there is no other model(I', D') E C such that I' C. I.Conservative minimality is a conservative ex-tension of local minimality: if there are nocosts at all, then all local minimal models are322also conservative models.
Conservative mini-reality is a combination of local minimality andcost minimisation that correctly identifies thepreferred interpretation of reciprocal sentences.For instance since (12c) carries a minimal cost,it is a conservative minimal model for (12a)whereas (12b) isn't.
Intuitively the approachworks as follows: the more pairs there are thatdo not stand in the scope relation of the re-ciprocal, the bigger the SR predicate and themore costly (i.e.
the least preferred) the model.That is, the combined use of a $R-predicate andof conservative minimality allows us to enforcea preference for interpretations (i.e.
models)maximising R.3.3 The  SystemKIMBA (Konrad and Wolfram, 1999) is a finitemodel generator for first-order and higher-orderlogical theories that is based on a translationof logics into constraint problems over finite-domain integer variables.
KIMBA uses an effi-cient constraint solver to produce solutions thatcan be translated back into Herbrand models ofthe input.We have tailored KIMBA such that it enumer-ates the conservative models of its input.
In-tuitively, this works as follows.
First, KIMBAsearches for some arbitrary model of the inputthat mentions a minimum number of individu-als.
Then, it takes the SR-cost of this modelas an upper bound for the cost of all successormodels and further minimises the cost as faxas possible by branch-and-bound search.
AfterKIMBA has determined the lowest cost possi-ble, it restarts the model search and eliminatesthose models from the search space that havea non-minimal cost.
For each model .h/\[ thatit identifies as a cost-minimal one, it proves byrefutation that there is no other cost-minimalmodel A/l t that uses only a subset of the pos-itive assumptions in A/\[.
Each succesful proofyields a conservative minimal model.All the examples discussed in this paper havebeen tested on Kimba and can be tried out at:http://www.coli.uni-sb.de/cl/projects /lisa/kimba.html3.4 A spect rum of possib le mean ingsLet us see in more detail what the predictions ofour analysis are.
As we saw in section 2, recip-rocal statements can have very different ruthconditions.
Intuitively, these truth-conditionslie on a spectrum from the weakest IAO inter-pretation (A is the antecedent set and R thescope relation):IAl >_ 2 A Vx E A(x) 3y (A(y) A x ?
y^(R(x, y) v R(y,to the strongest so-called Strong Reciprocity(SR) interpretation namely:IAI > 2AVx g(x)Vy A(y)(x ~ y ==v R(x,y))We now see how the MMH allows us to cap-ture this spectrum.Let us start with example (2) whose truth-conditions are the strongest Strong Reciprocityconditions: every distinct x and y in the an-tecedent set are related to each other by thescope relation.
In this case, there is no con-straining world knowledge hence the content ofthe like relation can be fully maximised.
Forinstance if there are five students, the cheapestmodel is one in which the cardinality of like istwenty (and consequently the cardinatity of $Ris zero).
(13) {like(sl, s2),/ike(sl, s3), like(sl, s4),/ike(sl, sh),/ike(s2, sl),/ike(s2, s3),like(s2, s4), like(s2, sh), like(s3, sl),like(s3, s2 ) , like(s3, s4), like(s3, sh),I;ke(s4, sl), like(s4, s3), like(s4, s2),like(s4, sh), like(sh, sl),  like(sh, s3),like( sh, s2), like( sh, s4)} $ROBy contrast, example (3) has a much weakermeaning.
In this case there is a strong worldknowledge constraint at work, namely that onecan stare at only one other person at sometime.
The cheapest models compatible with thisknowledge are models in which every studentstare at exactly one other student.
Thus in auniverse with five students, the preferred inter-pretations are models in which the cardinalityof the scope relation x stares at y in surpriseis five.
The following are example models.
Forsimplicity we ommit the $R propositions andgive the cost of the model instead (i.e.
the car-dinality of the complement set of the scope re-lation).
(14) {stare_at(sl, s2), stare_at(s2, s3),stare_at(s3, s4), stare_at(s4, sh),stare_at( sh, s3)} $R15323(15) (stare_at(sl, s2), stare_at(s2, s3),stare_at(s3, s4), stare_at(s4, s5),stare_at(s5, sl)} $R15Sentence (4) illustrates an intermediate casewith respect to strength of truth conditions.World knowledge implies that the scope rela-tion x give y measles is assymetric and furtherthat every individual is given measles by at mostone other individual.
Given a set of five stu-dents, model (16) and (17) are both acceptableinterpretations of (4), (16) being the preferredinterpretation.
(16) {gave_measles(sl, s2), gave_meas\]es(sl, s3),gave_measles(s2, s4), gave_measles(s3, s5)}$R16(17) (gave_measles(sl, s2), gave_measles(s2, 4),gave_measles(s3, s5)~} $R17In short, these examples how the MMH atwork.
They show how given a single seman-tic representation for reciprocals, a variety ofmeanings can be derived as required by eachspecific reciprocal statement.
Two elements arecrucial to the account: the use of model build-ing, and that of minimality as an implemen-tation of preferences.
Model building allowsus to compute all the finite interpretations ofa sentence that are consistent with contextualknowledge and with an IAO interpretation ofthe reciprocal expression.
Preferences on theother hand (i.e.
the use of the cost predicate$R and the search for conservative mininal mod-els), permits choosing among these interpreta-tions the most likely one(s) namely, the inter-pretation(s) maximising the scope relation.4 Re la ted  Work(Dalrymple t al., 1998) (henceforth DKKMP)proposes the following taxonomy of mean-ings for reciprocal statements (A stands forthe antecedent set and R for the scope relation):Strong Reciprocity (SR)Vx, y E A(x ?
y ~ xRy).Intermediate reciprocity (IR)Vx, y E A 3zl , .
.
.3Zm E A(xxRzl  A .
.
.
A ZmRy)~= y --+One-way Weak Reciprocity (OWR)Vx E A 3y e A (xRy)Intermediate Alternative Reciprocity (IAR)Vx, y E A3zl, .
.
.
3Zm E A(x ~ y -+(xRzl Y zlRx) A ... A (zmRy Y yRzm))Inclusive Alternative Ordering (IAO)Vx E A Sy E A(xRy Y yRx)To predict the meaning of a specific recip-rocal sentence, DKKMP then postulate theStrongest Meaning Hypothesis which says thatthe meaning of a reciprocal sentence is the log-ically strongest meaning consistent with worldand contextual knowledge.The main difference between the DKKMP ap-proach and the present approach lies in howthe best reading is determined: it is the logi-cally strongest of the five postulated meaningsin DKKMP, whereas in our approach, it is thatreading which maximises the scope relation ofthe reciprocal.
This difference has both empiri-cal and computational consequences.Empirically, the predictions are the same inmost cases because maximising the scope rela-tion often results in yielding a logically strongermeaning.
In particular, as is illustrated by theexamples in section 2, the present approach cap-tures the five meanings postulated by DKKMP.Thus model (13) exemplifies an SR reading,model (15) an IR reading and model (14) anOWR reading.
Further, model (16) is an IARinterpretation while model (17) shows an IAOreading.But as the examples also show there arecases where the predictions differ.
In particu-lar, in the DKKMP approach, sentence (3) isassigned the IR reading represented by model(15).
However as they themselves observe, thesentence also has a natural OWR interpretationnamely, one as depicted in model (14), in whichsome pairs of students reciprocally stare at eachother.
This is predicted by the present approachwhich says that models (14) and (15) are equallyplausible since they both maximise the stare atrelation to cardinality five.On the other hand, the DKKMP account ismore appropriate for examples uch as:(18) The students at next to each othera.
forming a nice cercle.324b.
filling the bench.c.
some to the front and others to the backof the church.An IR interpretation is predicted for (18)which is compatible with both continuation(18a) and continuation (18b).
By contrast, themodel generation approach predicts that thepreferred interpretation is a model in which thestudents form a circle, an interpretation com-patible with continuation (18a) but not withcontinuations (18b-c).However, both approaches fail to predict hereading made explicit by continuation (18c)since this corresponds to the weaker OWR in-terpretation under the DKKMP account and toa model which fails to maximise the scope re-lation under the present approach.
More gen-erally, both approaches fail to capture the se-mantic vagueness of reciprocal statements illus-trated by the following examples1:(19) a.
The students often help each other withtheir homework.b.
In the closing minutes of the game, themembers of the losing team tried to encour-age each other.In both cases, the sentences can be true with-out maximising either the strength of its truthconditions (Strong Reciprocity) or the scope re-lation.
This suggests that an empirically morecorrect analysis of reciprocals hould involveprototypical and probabilistic knowledge - asit is essentially a computational pproximationof the DKKMP approach, the present accountdoes not integrate such information though it iscompatible with it: just as we restrict the setof generated models to the set of conservativeminimal models, we could restrict it to the setof models having some minimal probability.Computationally, the difference between theDKKMP and the present approach is as fol-lows.
In essence, the DKKMP approach re-quires that each of the five possible readings(together with the relevant world knoweldge)be checked for consistency: some will be con-sistent, others will not.
Since the first orderconsistency and validity problems are not de-cidable, we know that there can be no method1I am thankfu l  to an anonymous NAACL referree forthese examples.guaranteed to always return a result.
In orderto implement the DKKMP approach, one musttherefore resort to the technique advocated in(Blackburn et al, 1999) and use both a theo-rem prover and a model builder: for each possi-ble meaning Mi, the theorem is asked to prove~Mi and the model builder to satisfy Mi.
Mi isinconsistent if the theorem prover succeeds, andconsistent if the model builder does.
Theoreti-cally however, cases may remain where neithertheorem proving nor model building will returnan answer.
If these cases occur in practice, theapproach simply is not an option.
Further, theapproach is linguistically unappealing as it inessence requires the reciprocal each other to befive-way ambiguous.By contrast, the model generation approachassigns a single semantic representation to eachother.
The approach strengthens the logicalcontribution of the weak semantic representa-tion as a process based on computational con-straints on a set of effectively enumerable mod-els.
As a result, we will never encounter un-decidable logical problems as long as the repre-sented iscourse is consistent.
The model gener-ator is the only computational tool that we needfor determining preferable readings, and our ex-periment shows that for the examples discussedin this paper, it returns preferred readings ina few seconds on standard PCs as long as thebackground theory and the size of the domainremain managably small.5 Conc lus ionWe have argued that model building can be usedto provide a computational pproximation ofDKKMP's analysis of reciprocals.One crucial feature of the account is thatit permits building, comparing and ranking ofnatural-language interpretations against eachother.
In the case of reciprocals, the ranking isgiven by the size of the scope relation, but otherranking criteria have already been identified inthe literature as well.
For instance, (Gardentand Konrad, To appear) shows that in the caseof definite descriptions, the ranking defined bylocal minimality permits capturing the prefer-ence of binding over bridging, over accomoda-tion.
Similarly (Baumgartner and Kiihn, 1999)shows that a predicate minimisation togetherwith a preference for logically consequent reso-325lutions can be used to model the interpretationof pronominal anaphora.This suggests that one of the most promisingapplication of model generators i  as a device fordeveloping and testing preference systems forthe interpretation of natural language.
Infer-ence and knowledge based reasoning are neededin NLP not only to check for consistency andinformativity (as illustrated in e.g.
(Blackburnet al, 1999)), but also to express preferencesbetween, or constraints on, possible interpreta-tions.
For this, finite model builders are naturaltools.Another area that deserves further investi-gation concerns the use of minimality for dis-ambiguation.
In this paper, conservative min-imality is used to choose among the possibleinterpretations of a particular eciprocal state-ment.
On the other hand, (Gardent and Web-ber, January 2000) shows that minimality isalso an important tool for disambiguating oun-compounds, logical metonymy and definite de-scriptions.
As the paper shows though, manyquestions remains open about this use of mini-mality for disambiguation which are well worthinvestigating.In further work, we intend to look at otherambiguous natural anguage constructs and toidentify and model the ranking criteria deter-mining their preferred interpretation.
Pluralsare a first obvious choice.
But more generally,we hope that looking at a wider range of datawill unveil a broader picture of what the gen-eral biases are which help determine a preferredreading - -  either in isolation, as here, or in con-text, as in (Gardent and Webber, January 2000)- -  and of how these biases can be modelled us-ing automated reasoning systems.Acknowledgement  sWe are grateful to audiences from ITRI-Brighton, the Edinburgh School of CognitiveScience, the Paris VI TALANA seminar and theAmsterdam DIP colloquium for helpful com-ments and discussion on the material presentedhere as well as to the three NAACL anony-mous referrees for constructive feedback.
Thiswork was partially supported by the ProjectC2 (LISA) in SFB-378, grant by the DeutscheForschungsgemeinschaft to the University ofSaarbriicken.ReferencesPeter Baumgartner and Michael Kiihn.
1999.Abductive coreference by model construction.In ICoS-1 Inference in Computational Se-mantics, Institute for Logic, Language andComputation, University of Amsterdam, Au-gust.P.
Blackburn, J. Bos, M. Kohlhase, andH.
de Neville.
1999.
Inference and Com-putational Semantics.
In Third Interna-tional Workshop on Computational Seman-tics (IWCS-3), Tilburg, The Netherlands.Mary Dalrymple, Makoto Kanasawa, YookyungKim, Sam Mchombo, and Stanley Peters.1998.
Reciprocal expressions and the con-cept of reciprocity.
Linguistics and Philoso-phy, 21(2):159-210, April.Claire Gardent and Karsten Konrad.
1999.Definites and the proper treatment of rabbits.In Proceedings of ICOS.
Also CLAUS Report111, http://www.coli.uni-sb.de/claus/.Claire Gardent and Karsten Konrad.
To ap-pear.
Interpreting Definites using ModelGeneration.
Journal of Language and Com-putation.Claire Gardent and Bonnie Webber.
Jan-uary 2000.
Automated deduction anddiscourse disambiguation.
Submitted forPublication.
Also CLAUS Report 113,http://www.coli, uni-sb.de/claus/.P.N.
Johnson-Laird and Ruth M.J. Byrne.1991.
Deduction.
Lawrence Erlbaum Asso-ciates Publishers.Hans Kamp and Uwe Reyle.
1993.
From Dis-course to Logic.
Kluwer, Dordrecht.Hans Kamp.
1981.
A theory of truth andsemantic representation.
In J. Groenendijk,Th.
Janssen, and M. Stokhof, editors, FormalMethods in the Study of Language, pages 277- 322.
Mathematisch Centrum Tracts, Ams-terdam.Karsten Konrad and D. A. Wolfram.
1999.Kimba, a model generator for many-valuedfirst-order logics.
In Proc., 16th Interna-tional Conference on Automated Deduction,CADE 99, LNCS, forthcoming, Trento, Italy.Springer.D.
Terence Langendoen.
1978.
The logic of reci-procity.
Linguistic Inquiry, 9(2):177-197.326
