A FLEXIBLE APPROACH TO COOPERATIVE RESPONSE GENERATIONIN INFORMATION-SEEKING DIALOGUESLiliana Ardissono, Alessandro Lombardo, Dario SesteroDipart imento  di In format ica  - Univers i ta '  di Tor inoC.so Sv izzera  185 - 10149 - Tor ino  - I talyE-Mai l :  l i l iana@di.unito.
i tAbstractThis paper presents a cooperative consultation systemon a restricted omain.
The system builds hypotheseson the user's plan and avoids misunderstandings (withconsequent repair dialogues) through clarificationdialogues in case of ambiguity.
The role played byconstraints in the generation of the answer is charac-terized in order to limit the cases of ambiguities re-quiring a clarification dialogue.
The answers of thesystem are generated at different levels of detail, ac-cording to the user's competence in the domain.INTRODUCTIONThis paper presents a plan-based consultation systemfor getting information on how to achieve a goal in arestricted omain, l The main purpose of the system isto recognize the user's plans and goals to build coop-erative answers in a flexible way \[Allen, 83\],\[Carberry, 90\].
The system is composed of two parts:hypotheses construction and response generation.The construction of hypotheses i  based on ContextModels (CMs) \[Carberry, 90\].
Carberry uses defaultinferences \[Carberry, 90b\] to select a single hypothe-sis for building the final answer of the system and, incase the choice is incorrect, a repair dialogue isstarted.
Instead, in our system, we consider all plau-sible hypotheses and if the ambiguity among them isrelevant for the generation of the response, we try tosolve it by starting aclarification dialogue.
Accordingto \[van Beek and Cohen, 91\], clarification dialoguesare simpler for the user than repair ones, because theyonly involve yeshlo questions on the selected ambigu-ous plans.
Furthermore, repair dialogues generally re-quire a stronger participation of the user.
Finally, ifthe misunderstanding is not discovered, the systemdelivers information that is not proper to the user'scase.
For these reasons, it is preferable to solve therunbiguity a priori, by asking the user information onhis intentions.
In van Beek and Cohen's approachcl,'wification dialogues are started, even in case theanswers associated with the plausible hypotheses aredistinguished by features that could dhectly bemanaged in the answer.
We avoid this by identifyingthe constraints relevant for a clarification dialogueand those which can be mentioned in the answer.
Inthis way, the friendliness of the system is improvedlThe system is concerned with information about a CSDeparunent.and the number and the length of the clarification dia-logues are reduced.In the perspective of generating flexiblecooperative answers, it is important to differentiatetheir detail level by adapting them to the user'scompetence in the domain.
In our work, we want tostudy how to embed information obtained from a usermodel component in the system.
As a first step in thisdirection, we introduce a preliminary classification ofusers in three standard levels of competencecorresponding to the major users' prototypes thesystem is devoted to.
Then, in order to producedifferentiated answers, the hypotheses are expandedaccording to the user's competence l vel.The knowledge about actions and plans is stored ina plan library structured on the basis of two main hier-archies: the Decomposition Hierarchy (DH) and theGeneralization Hierarchy (GH) \[Kautz and Allen, 86\].The first one describes the plans associated with theactions and is used for explaining how to execute acomplex action.
The second one expresses therelation among genera/and specific actions (the majorspecificity is due to additional restrictions onparameters).
It supports an inheritance mechanismand a top-down form of clarification dialogue.THE ALGORITHMThe algorithm consists of two parts: a hypothesesconstruction and a response generation phase.?
111 the hypotheses construction phase the followingsteps are repeated for each sentence of the user:1- Action identification: on the basis of the user's ut-terance, a set of candidate actions is selected.2- Focusing: CMs built after the analysis of the pre-vious sentences are analyzed to find a connectionwith any candidate action identified in step 1 and, foreach established connection, a new CM is built.
(Atthe beginning of the dialogue, from each candidateaction a CM is created).3- Upward expansion along the DH: each CM is ex-panded (when possible) by appending it to the morecomplex action having the root of the CM itself in itsdecomposition.
111 this way we get a higher lever de-scription of the action that the user wants to pursue.4- Weighted expansion along the DH: for each CM,its actions are repeatedly decomposed in more ele-mentary ones, until all the steps of the CM are suffi-ciently simple for the user's competence l vel in thedomain.
In this way, the information ecessary togenerate an answer suitable to the user is collected.2745- Weighted expansion backward through enable-ment links: each CM is expanded in order to includethe actions necessary for satisfying the preconditionswhich the user is supposed not to be able to plata byhimself (according to his competence l vel).?
In the response generation phase, the ambiguityamong the hypotheses i evaluated.
If it is relevant, atop-down clarification dialogue guided by the GH isstarted up.
Finally, the answer is extracted from theCMs selected through the clarification dialogue.THE REPRESENTATION OF  GOALS,PLANS AND ACT IONSThe basic elements of representation f the domainknowledge are goals and actions.
Actions can be ele-mentary or complex and in the second case one ormore plans (decompositions) can be associated withthem.
All these plans share the same main effect.Each action is characterized by the preconditions,constraints, restrictions on the action parmneters, ef-fects, associated plans mid position in the GH.
The re-strictions pecify die relationship among the par,'une-ters of the main action and diose of the action sub-steps.
During the response generation phase, if thevalue of some parameters is still unknown, their refer-ent can be substituted in die answer by a linguistic de-scription extracted from the restrictions, so avoidingfurther questions to the user.
For example, if the usersays that he wants to talk to the advisor for a courseplan, but he does not specify which (so it is not possi-ble to determine the name of the advisor), still thesystem may suggest: "talk with the advisor for thecourse plan you are interested in".The GH supports an inheritance mechanism in theplan library.
Moreover, it allows to describe the de-composition of an action by means of a more abstractspecification of some of its substeps when no specificinformation is available.
For exainple, a step of dieaction of getting information on a course plan is totalk with the curriculum advisor, that can be?
specialized in different ways according to the topic ofthe conversation (talking by phone and talking face toface).
If in a specific situation the actual topic is un-known, it is not possible to select one possibility.
So,the more general action of talking is considered.In order to support he two phases of weighted ex-pansion, information about he difficulty degree of theactions is embedded in the plan library by labellingthem with a weight that is a requested competencethreshold (if the user is expert for an action, it is takenas elementary for him, otherwise its steps must bespecified).
Preconditions are labelled in an analogousway, so as to specify which users know how to planthem by themselves and which need an exph'mation.THE CONSTRUCTION OF  THEHYPOTHESESIn the action identification phase a set of actions isselected from the plan library, each of them possiblyrepl~esenting the aspect of the task on which the user'sattention is currently focused.
The action identifica-tion is accomplished by means of partially orderedrules (a rule is more specific than another one if it im-poses greater constraints on the structure of the log-ical form of the user's utterance).
Restrictions on thepmameters of conditions and actions are used to selectthe most specific action from the plan library that issupported by the user's utterance.In the focusing phase the set of CMs produced bythe analysis of the previous entences and the set ofcandidate actions selected in the action identificationphase are considered.
A new set of CMs is built, all ofwhich are obtained by expanding one of the givenCMs so as to include a candidate action.
CMs forwhich no links with the candidate actions have beenfound are discarded.
The expansion of the CMs issimilar to that of Carberry.
However, because of ourapproach to the response generation, when a focusingrule fires, the expansion is tried backward through theenablement links and along the DH and the GH, so tofind all the connections with the candidate actionswithout preferring any possibility.
I f  a heuristic rulesuggests more than one connection, a new CM isgenerated for each one.After the focusing phase, a further expansion upthrough tim DH is provided for each CM whose rootis part of only one higher-level plan.In the weighted expansion along the DH, for eachCM, every action to be included in the answer is ex-panded with its decomposition if it is not elementaryfor the user's competence l vel.
Actually, only actionswith a single decomposition are expanded 2 The ex-pansion is performed until the actions to bementioned in the answer are not decomposable orthey suit the user's competence l vel.In the weighted expansion backward through en-ablement links, for each CM, preconditions whoseplanning is not immediate for the user are expandedby attaching to their CMs the actions having them aseffects.
When a precondition to be expanded is of theform "Know(IS, x)" and the system knows the valueof "x", it includes such information in the response;so, the expansion is avoided.
While in the previousphase the expansion is performed recursively, here itis not, because expanding along the enablementchain extends the CM far from the current focus.2 In the last two expansion phases we did not want toextend the set of alternative hypotheses.
In particular, in theweighted expansion along the DH, the choice does notreduce the generality of our approach because this kind ofambiguity lies at a more detailed level than that of the user'sexpressions.
Anyway, the specificity of the actionsmentioned in the answer can be considered a matter oftxade-off between the need of being cooperative and the riskof generating too complex answers.275THE RESPONSE GENERATIONIn the relevance valuation phase, the ambiguityamong candidate hypotheses filtered out in the focus-ing phase is considered.
The notion of relevance de-fined by van Beek and Cohen is principally based onthe conditions (corresponding to our constraints) as-sociated with the selected plans.
We further specifythis notion in two ways, in order to avoid a clarifica-tion dialogue when it is not necessary because amorestructured answer is sufficient for dealing with theambiguity.
First we classify constraints into three cat-egories: those with a value known to the system, thatare the only to be used in order to evaluate the rele-vance of ambiguity; those that involve informationpeculiar to the user (e.g.
if he is a studen0, that can bementioned in the answer as assumptions for its valid-ity; finally, those with a value unknown to both theuser and the system, but that the user can verify byhimself (e.g.
the availability of books in the library).Also constraints of the last category should be in-cluded in the answer providing a recormnendation tocheck them.
Second, clarification dialogues can beavoided even when the ambiguity is relevant, but allthe selected hypotheses are invalidated by some falseconstraints whose truth value does not cllange in theconsidered situation; hence, a definitive negative an-swer can be provided.
Clarification dialogues are or-ganized in a top-down way, along the GH.In our approach, answers hould include not onlyinformation about the involved constraints, but alsoabout the specific description of how the user shouldaccomplish is task.
For this reason, we consider aclarification dialogue based on constraints as a firststep towards a more complex one, that takes into ac-count the ambiguity among sequences of steps aswell.
In the future work, we are going to complete theanswer generation phase by developing tiffs part, aswell as the proper answer generation part.AN EXAMPLELet us suppose that a CM produced in the previousanalysis is composed by tile action Get-info-on-course-plan (one of whose steps is the Talk-prof ac-tion) and the user asks if Prof. Smith is in his office.The action identification phase selects the Talk-by-phone and Meet actions, that share tile constraint thatthe professor is ill his office.
Since the two actions aredecompositions of tile Talk-prof action, the focusingphase produces two CMs from the previous one.
Iftile user is expert on the domain, no further expansionof the CMs is needed for the generation of the answer,that could be "Yes, he is; you can phone him to num-ber 64 or meet him in office 42".
On tile other hand, ifthe user has a lower degree of competence, tile stepsdifficult for him are expanded.
For example, the Talk-by-phone action is detailed by specifying: "To phonehim go to the internal phone in tile entrance".
In orderto show one of the cases that differentiate van Beekand Cohen's approach from ours, suppose to add tothe action Meet the constraint Is-meeting-time andthat the user asks his question when the professor isnot in the office and it is not his meeting time.
In thiscase, the false constraint Is-meeting-time causes theambiguity to be relevant for van Beek and Cohen; onthe other hand, our system provides the user with aunique negative answer, so avoiding any clarificationdialogue.CONCLUSIONSThe paper presented a plan-based consultation sys-tem whose main purpose is to generate cooperativeanswers on the basis of recognition of the user's plansand goals.
In the system, repair dialogues due to mis-understandings of the user's intentions are preventedthrough a possible clarification dialogue.In order to enhance the flexibility of the system,different detail levels have been provided for the an-swers, according to the competence of the varioususers.
This has been done by specifying the difficultydegree of the various components of the plan libraryand by expanding the CMs until the information pro-vided for the generation of an answer is suitable forthe user.
Van Beek and Cohen' notion of therelevance of ambiguity has been refined on the basisof the characteristics of the constraints present in theplans.In the future work, we are going to refine the notionof relevance of ambiguity in order to deal with thepresence of different sequences of actions in the pos-sible answers.
Finally we are going to complete theproper answer generation.A C KNOWLEDGEMENTSThe authors are indebted to Leonardo Lesmo formany useful discussions on the topic presented in thepaper.
The authors are also grateful to the fouranonimous referees for their useful comments.This research as been supported by CNR in theproject Pianificazione Automatica.REFERENCES\[Allen, 83\] J.F.Allen.
Recognizing intentions fromnatural anguage utterances.
In M. Brady and R.C.Berwick editors, Computational Models of Discourse.107-166.
MIT Press, 1983.\[Carberry, 90\] S.Carberry.
Plan Recognition inNatural Language Dialogue.
ACL-MIT Press, 1990.\[Carberry 90b\] S.Carberry.
Incorporating DefaultInferences into Plan Recognition.
Proc.
8th Conf.AAAI, 471-478 Boston, 1990.\[Kautz and Allen, 86\] H.A.Kautz, J.F.Allen.Generalized Plan Recognition.
Proc.
5th Conf.
AAAL32-37 Philadelphia, 1986.\[van Beek and Cohen, 91\] P.van Beek, R.Cohen.Resolving Plan Ambiguity for Cooperative ResponseGeneration.
Proc.
12th Int.
Joint Conf.
on ArtificialIntelligence, 938-944 Sydney, 1991.276
