Parsing Parallel Grammatical RepresentationsDerrick HigginsDepartment  of LinguisticsUniversity of Chicago1050 East 59th StreetChicago, IL 60626dchiggin@midway.uchicago.eduAbst rac tTraditional accounts of quantifier scope em-ploy qualitative constraints or rules to accountfor scoping preferences.
This paper outlinesa feature-based parsing algorithm for a gram-mar with multiple simultaneous levels of repre-sentation, one of which corresponds to a par-tial ordering among quantifiers according toscope.
The optimal such ordering (as well asthe ranking of other orderings) is determinedin this grammar not by absolute constraints,but by stochastic heuristics based on the de-gree of alignment among the representationallevels.
A Prolog implementation is describedand its accuracy is compared with that of otheraccounts.1 In t roduct ionIt has long been recognized that the possibilityand preference rankings of scope readings de-pend to a great degree on the position of scope-taking elements in the surface string (Chomsky,1975; Hobbs and Shieber, 1987).
Yet most tra-ditional accounts of semantic scopal phenomenain natural anguage have not directly tied thesetwo factors together.
Instead, they allow onlycertain derivations to link the surface structureof a sentence with the representational levelat which scope relations are determined, placeconstraints upon the semantic feature-passingmechanism, or otherwise mulate a constraintwhich requires some degree of congruence be-tween the surface syntax of a sentence and itspreferred scope reading(s).A simpler and more direct approach is sug-gested by constraint-based, multistratal theo-ries of grammar (Grimshaw, 1997; Jackendoff,1997; Sadock, 1991; Van Valin, 1993).
In thesemodels, it is possible to posit multiple represen-tational evels for a sentence without accordingontological primacy to any one of them, as inall varieties of transformational grammar.
Thisallows constraints to be formulated which placelimits on structural discrepancies between lev-els, yet need not be assimilated into an overrid-ing derivational mechanism.This paper will examine the model of one ofthese theories, Autolexical Grammar (Sadock,1991; Sadock, 1996; Schiller et al, 1996), as itis implemented in a computational scope gen-erator and critic.
This left-corner chart parsergenerates urface syntactic structures for eachsentence (as the only level of syntactic represen-tation), as well as Function-Argument seman-tic structures and Quantifier/Operator-Scopestructures.
These latter two structures togetherdetermine the semantic interpretation of a sen-tence.It will be shown that this model is bothcategorical enough to handle standard gener-alizations about quantifier scope, such as banson extraction from certain domains, and fuzzyenough to present reasonable preference rank-ings among scopings and account for lexicaldifferences in quantifier strength (Hobbs andShieber, 1987; Moran, 1988).2 A Mu l t id imens iona l  Approach  toQuant i f ie r  Scoping2.1 The  Auto lex ica l  Mode lThe framework of Autolexical Grammar treatsa language as the intersection of numerous inde-pendent CF-PSGs, or hierarchies, each of whichcorresponds to a specific structural or functionalaspect of the language.
Semantic, syntactic,morphological, discourse-functional and manyother hierarchies have been introduced in theliterature, but this project focuses on the in-teractions among only three major hierarchies:Surface Syntax, Function-Argument S ructure,545and Operator Scope Structure.The surface syntactic hierarchy is a feature-based grammar expressing those generalizationsabout a sentence which are most clearly syn-tactic in nature, such as agreement, case, andsyntactic valency.
The function-argument hi-erarchy expresses that (formal) semantic infor-mation about a sentence which does not involvescope resolution, e.g., semantic valency and as-sociation of referential terms with argument po-sitions, as in Park (1995).
The operator scopehierarchy, naturally, imposes a scope orderingon the quantifiers and operators found in theexpression.
Two other, minor hierarchies areemployed in this implementation.
The linear or-dering of words in the surface string is treatedas a hierarchy, and a lexical hierarchy is intro-duced in order to express the differing lexical"strength" of quantifiers.Each hierarchy can be represented as a treein which the terminal nodes are not orderedwith respect o one another.
This implies that,for example, \[John \[saw Mary\]\] and \[Mary \[sawJohn\]\] will both be acceptable syntactic rep-resentations for the surface string Mary sawJohn.
The optimal set of hierarchies for a stringconsists of the candidate hierarchies for eachlevel of representation which together are moststructurally congruous.
The structural similar-ity between hierarchies is determined in Au-tolexical Grammar by means of an AlignmentConstraint, which in the implementation de-scribed here counts the number of overlappingconstituents in the two trees.
Thus, while struc-tures similar to \[Mary \[saw John\]\] and \[John\[saw Mary\]\] will both be acceptable as syntac-tic and function-argument structure representa-tions, the alignment constraint will strongly fa-vor a pairing in which both hierarchies share thesame representation.
Structural hierarchies areadditionally evaluated by means of a Contigu-ity Constraint, which requires that the terminalnodes of each constituent of a hierarchy shouldbe together in the surface string, or at least asclose together as possible.2.2 Quantifier Ordering HeuristicsThe main constraints which this model placeson the relative scope of quantifiers and opera-tors are the alignment of the operator scope hi-erarchy with syntax, function-argument struc-ture, and the lexical hierarchy of quantifierstrength.
The first of these constraints reflects"the principle that left-to-right order at thesame syntactic level is preserved in the quan-tifier order" 1 and accounts for syntactic extrac-tion restrictions.
The second will favor operatorscope structures in which scope-taking elementsare raised as little as possible from their base ar-gument positions.
The last takes account of thescope preferences of individual quantifiers, suchas the fact that each tends to have wider scopethan all other quantifiers (Hobbs and Shieber,1987; Moran, 1988).As an example of the sort of syntactically-based restrictions on quantifier ordering whichthis model can implement, consider the general-ization listed in Moran (1988), that "a quanti-fier cannot be raised across more than one ma-jor clause boundary."
Because the approachpursued here already has a general constraintwhich penalizes candidate parses according tothe degree of discrepancy between their syntaxand scope hierarchies, we do not need to accorda privileged theoretical status to "major clauseboundaries.
"Figure 1 illustrates the approximate optimalstructure accorded to the sentence Some pa-tients believe all doctors are competent on thesyntactic and scopal hierarchies, in which anextracted quantifier crosses one major clauseboundary.
It will be given a misalignment indexof 4 (considering for the moment only the inter-action of these two levels), because of the fouroverlapping constituents on the two hierarchies.This example would be misaligned only to de-gree 2 if the other quantifier order were chosen,and depending on the exact sentence type con-sidered, an example with a scope-taking elementcrossing two major clause boundaries should bemisaligned to about degree 8.The fact that the difference between the pri-mary and secondary scopings of this sentenceis 2 degrees of alignment, while the differencebetween crossing one clause boundary and twoclause boundaries i 4 degrees of alignment, cor-responds with generally accepted assumptionsabout the acceptability of this example.
Whilethe reading in which the scope of quantifiersmirrors their order in surface structure is cer-tainly preferred, the other ordering is possibleas well.
If the extraction crosses another clause1Hobbs and Shieber (1987), p. 49546SSome patients believe all doctors are competent@Figure 1: Illustration of the Alignment Constraint.
The four highlighted nodes count against hiscombination of structures, because they overlap with constituents in the other tree.boundary, however, as in Some patients believeMary thinks all doctors are competent, he re-versed scoping is considerably more unlikely.2.3 Lexical  P roper t ies  of  Quant i f iersIn addition to ranking the possible scopings ofa sentence based on the surface syntactic posi-tions of its quantifiers and operators, the pars-ing and alignment algorithm employed in thisproject takes into account he "strength" of dif-ferent scope-taking elements.
By introducing alexical hierarchy of quantifier strength, in whichthose elements more likely to take wide scopeare found higher in the tree, we are able to usethe same mechanism of the alignment constraintto model the facts which other approaches treatwith stipulative heuristics.For example, in Some patient paid each doc-tor, the preferred reading is the one in whicheach takes wide scope, contrary to our expecta-tions based on the generalization that the pri-mary scoping tends to mirror surface syntacticorder.
An approach employing some variant ofCooper storage would have to account for thisby assigning to each pair of quantifiers a like-lihood that one will be raised past the other.In this case, it would be highly likely for eachto be raised past some.
The autolexical ap-proach, however, allows us to achieve the sameeffect without introducing an additional device.Given a proper weighting of the result of align-ing the scope hierarchy with this lexical hierar-chy, it is a simple matter to settle on the correctcandidates.3 The  A lgor i thm3.1 Pars ing  S t ra tegyThis implementation f the Autolexical accountof quantifier scoping is written for SWI-Prolog,and inherits much of its feature-based grammat-ical formalism from the code listings of Gazdarand Mellish (1989), including dagun i fy .p l ,  byBob Carpenter.
The general strategy employedby the program is first to find all parses whicheach hierarchy's grammar permits for the string,and then to pass these lists of structures to func-tions which implement the alignment and con-tiguity constraints.
These functions perform apairwise evaluation of the agreement betweenstructures, eventually converging on the opti-mal set of hierarchies.The same parsing engine is used to generatestructures for each of the major hierarchies con-tributing to the representation f a string.
It isbased on the left-corner parser of p ro_pat r .p lin Gazdar and Mellish (1989), attributed origi-nally to Pereira and Shieber (1987).
This parserhas been extended to store intermediate r sultsfor lookup in a hash table.At present, the parsing of each hierarchy is in-dependent of that of the other hierarchies, butultimately it would be preferable to allow, e.g.,edges from the syntactic parse to contribute to547the function-argument parsing process.
Such adevelopment would allow us to express catego-rial prototypes in a natural way.
For example,the proposition that "syntactic NPs tend to de-note semantic arguments" could be modeled asa default rule for incorporating syntactic edgesinto a function-argument structure parse.The "generate and test" mechanism em-ployed here to maximize the congruity of repre-sentations on different levels is certainly some-what inefficient.
Some of the structures whichit considers will be bizarre by all accounts.
Toa certain degree, this profligacy is held in checkby heuristic cutoffs which exclude a combina-tion from consideration as soon as it becomesapparent that is misaligned to an unacceptabledegree.
Ultimately, however, the solution maylie in some sort of parallel approach.
A develop-ment of this program designed either for parallelProlog or for a truly parallel architecture couldeffect a further restriction on the candidate setof representations by implementing constraintson parallel parsing processes, rather than (or inaddition to) on the output of such processes.3.2 A l ignmentThe alignment constraint (applied by thea l ign /3  predicate here) compares two trees(Prolog lists), returning the total number ofoverlapping constituents in both trees as a mea-sure of their misalignent.
Constituents are saidto overlap if the sets of terminal nodes whichthey dominate intersect, but neither is a subsetof the other.The code fragment below provides a roughoutline of the operation of this predicate.
First,both trees being compared are "pruned" so thatneither contains any terminal nodes not foundin the other.
The terminal elements of eachof the tree's constituents are then recorded inlists.
Once those constituents which occur inboth trees are removed, the sum of the lengthof these two lists is the total number of overlap-ping constituents.align(Li,L2,Num) "-flatten(LI,Fl), flatten(L2,F2),union(FI,F2,AllTerms),intersection(FI,F2,GoodTerms),subtract(AllTerms,GoodTerms,BadTerms),Delete constits without correlatesrmbad(LI,BadTerms,Goodl),rmbad(L2,BadTerms,Good2),Z Get list of constits in each treeconstits(Goodl,CListl),constits(Good2,CList2),Z Delete dup l i ca tesin tersect ion(CL is t l ,CL i s t2 ,CL is t3 ) ,subtract(CListl,CList3,Finall),subtract(CList2,CList3,Final2),Z Count mismatcheslength(Finall,Sizel),length(Final2,Size2),Num is Sizel + Size2.3.3 ContiguityWhile the alignment constraint evaluates thesimilarity of two trees, the contiguity constraint(cont ig/3 in this project) calculates the degreeof fit between a hierarchy and a string (in thiscase, the surface string).
The relevant measureof "goodness of fit" is taken here to be the min-imal number of crossing branches the structureentails.
It is true that this approach makes thecontiguity constraint dependent on the partic-ular grammatical rules of each representationallevel.
However, since an Autolexical model doesnot attempt o handle syntax directly in thesemantic representation, or morphology in thesyntactic representation, there is no real dan-ger of proliferating nonterminal nodes on anyparticular level.The definition of the cont ig  predicate issomewhat more complex than that for al ign,because it must find the minimum number ofcrossing branches in a structure.
It works bymaintaining a chart (based on the contvalpredicate) of the number of branches "covering"each constituent, as it works its way up the tree.The contmin predicate keeps track of the cur-rent lowest contiguity violation for the struc-ture, so that worse alternatives can be aban-doned as soon as they cross this threshold.contig(\[\],_,0).contig(A,_,0) "-not(is_list(A)),!.contig(\[A\],Flat,Num) "-548is_list (A),cont ig (A, Flat, Num),!.contig(\[A,B\] ,Flat,Num) "-cont ig (A ,Flat, Numl),contig (B ,Flat, Num2),contval (A ,Left I ,Right I, Num3),contval (B, Left2, Right2, Num4),NumO is Numl + Num2 + Num3 + Num4,forall (contmin (Min),(NumO >= Min) *-> fail ; true),Num is NumO,forall (contval (X,L,R, N),(L > min(Leftl,Left2),R < max(Rightl,Right2)) *->(retract (contval (X, L, R, N) ),asserta (contval (X ,L ,R, N+I ) ) ); true) ,asserta(contval ( \[A,B\] ,min(Left I ,Left2),max (Right I, Right 2), O) ).contig( \[B ,A\] ,Flat ,Num) ?
-contig (A ,Flat, Numl),contig (B ,Flat, Num2),contval (A ,Left I ,Right I, Num3),contval (B, Left2, Right 2, Num4),NumO is Numl + Num2 + Num3 + Num4,forall (contmin (Min),(NumO >= Min) *-> fail ; true),Num is NumO,forall (contval (X, L,R, N),(L > min(Leftl,Left2),R < max(Rightl,Right2)) *->(retract (contval (X, L, R, N) ),asserta(contval (X, L,R, N+I) ) ); true),asserta(contval ( \[A,B\] ,min(Left I ,Left2),max (Right I, Right 2), O) ).4 Conc lus ionMultistratal theories of grammar are not oftenchosen as guidelines for computational linguis-tics, because of performance and manageabilityconcerns.
This project, however, should at leastdemonstrate hat even in a high-level languagelike Prolog a multistratal parsing model can bemade to produce consistent results in a reason-able length of time.Furthermore, the project described here doesmore than simply emulate the output of a stan-dard, monostratal CF-PSG parser; it yields apreference ranking of readings for each string,rather than a single right answer.
While theAutolexical model may not now be correct forapplications in which speed is of primary con-cern, it has only begun to be implemented com-putationally, and any serious attempt at infer-encing from natural anguage input will have toproduce similar, graded output (Moran, 1988).Re ferencesNoam Chomsky.
1975.
Deep structure, sur-face structure, and semantic interpretation.In Studies on Semantics in Generative Gram-mar, pages 62-119.
Mouton.Gerald Gazdar and Chris Mellish.
1989.
Natu-ral Language Processing in PROLOG.
Addi-son Wesley.Jane Grimshaw.
1997.
Projection, heads, andoptimality.
Linguistic Inquiry, 28(3):373-422.Jerry R. Hobbs and Stuart M. Shieber.
1987.An algorithm for generating quantifier scop-ings.
Computational Linguistics, 13:47-63.Ray Jackendoff.
1997.
The Architecture of theLanguage Faculty.
Number 28 in LinguisticInquiry Monographs.
The MIT Press.Douglas B. Moran.
1988.
Quantifier scoping inthe SRI core language ngine.
In A CL Pro-ceedings, 26th Annual Meeting, pages 33-40.Jong C. Park.
1995.
Quantifier scope and con-stituency.
In A CL Proceedings, 33rd AnnualMeeting.Fernando C.N.
Pereira and Stuart M. Shieber.1987.
Prolog and Natural-Language Analysis,volume 10 of CSLI Lecture Notes.
Center forthe Study of Language and Information.Jerrold M. Sadock.
1991.
Autolexical Syntax: aTheory of Parallel Grammatical Representa-tions.
University of Chicago Press.Jerrold M. Sadock.
1996.
Reflexive reference inwest greenlandic.
Contemporary Linguistics,1:137-160.Eric Schiller, Elisa Steinberg, and BarbaraNeed, editors.
1996.
Autolexical Theory:Ideas and Methods.
Mouton de Gruyter.Robert D. Van Valin, editor.
1993.
Advancesin Role and Reference Grammar.
Number 82in Current Issues in Linguistic Theory.
JohnBenjamins Publishing Company.549
