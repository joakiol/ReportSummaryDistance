Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 128?132,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsAcquiring a Dictionary of Emotion-Provoking EventsHoa Trong Vu?,?, Graham Neubig?, Sakriani Sakti?, Tomoki Toda?, Satoshi Nakamura?
?Graduate School of Information Science, Nara Institute of Science and Technology8916-5 Takayama-cho, Ikoma-shi, Nara, Japan?Vietnam National University, University of Engineering and TechnologyE3 Building - 144 Xuan Thuy Street, Cau Giay, Hanoi, VietnamAbstractThis paper is concerned with the discov-ery and aggregation of events that provokea particular emotion in the person whoexperiences them, or emotion-provokingevents.
We first describe the creation of asmall manually-constructed dictionary ofevents through a survey of 30 subjects.Next, we describe first attempts at auto-matically acquiring and aggregating theseevents from web data, with a baseline fromprevious work and some simple extensionsusing seed expansion and clustering.
Fi-nally, we propose several evaluation meas-ures for evaluating the automatically ac-quired events, and perform an evaluationof the effectiveness of automatic event ex-traction.1 Introduction?You look happy today, did something good hap-pen??
This is a natural question in human dia-logue, and most humans could think of a variety ofanswers, such as ?I met my friends?
or ?I passed atest.?
In this work, we concern ourselves with cre-ating resources that answer this very question, ormore formally ?given a particular emotion, whatare the most prevalent events (or situations, con-texts) that provoke it?
?1Information about theseemotion-provoking events is potentially useful foremotion recognition (recognizing emotion basedon events mentioned in a dialogue), response gen-eration (providing an answer to emotion-relatedquestions), and answering social-science relatedquestions (discovering events that affect the emo-tion of a particular segment of the population).1This is in contrast to existing sentiment lexicons (Riloffet al., 2003; Valitutti, 2004; Esuli and Sebastiani, 2006; Ve-likovich et al., 2010; Mohammad and Turney, 2013), whichonly record the sentiment orientation of particular words(such as ?meet?
or ?friend?
), which, while useful, are less dir-ectly connected to the emotions than the events themselves.While there is very little previous research onthis subject, one previous work of note by Tok-uhisa et al.
(2008) focused on emotion-provokingevents purely from the viewpoint of emotion re-cognition.
They used large corpus of examplescollected from the Web using manual patterns tobuild a k-nearest-neighbors emotion classifier fordialog systems and found that the classifier sig-nificantly outperforms baseline methods.
Thismethod provides both an inspiration and a baselinefor our work, but still lacks in that it makes noattempt to measure the quality of the extractedevents, aggregate similar events, or rank events byprevalence, all essential factors when attemptingto use extracted events for applications other thansimple emotion recognition.In this paper, we describe work on creat-ing prevalence-ranked dictionaries of emotion-provoking events through both manual labor andautomatic information extraction.
To create amanual dictionary of events, we perform a sur-vey asking 30 participants to describe events thatcaused them to feel a particular emotion, andmanually cleaned and aggregated the results intoa ranked list.
Next, we propose several methodsfor extracting events automatically from large datafrom the Web, which will allow us to increase thecoverage over the smaller manually created dic-tionary.
We start with Tokuhisa et al.
(2008)?s pat-terns as a baseline, and examine methods for im-proving precision and coverage through the use ofseed expansion and clustering.
Finally, we dis-cuss evaluation measures for the proposed task,and perform an evaluation of the automatically ex-tracted emotion-provoking events.
The acquiredevents will be provided publicly upon acceptanceof the paper.2 Manual Creation of EventsIn order to create a small but clean set of gold-standard data for each emotion, we first performed128Emotions Wordshappiness happy, gladsadness sad, upsetanger angry, irritatedfear afraid, scaredsurprise surprised, astonisheddisgust disgusted, terribleTable 2: Seed words for each emotion.a survey on emotion-provoking events.
We did soby asking a total of 30 subjects (a mixture of maleand female from 20-40 years of age) to write downfive events that provoke each of five emotions:happiness, sadness, anger, fear, and surprise.
Asthese events created according to this survey stillhave a large amount of lexical variation, we manu-ally simplify them to their core and merge togetherevents that have similar meanings.Finally, for each emotion we extract all theevents that are shared by more than one person.
Itshould be noted that this will not come anywhereclose to covering the entirety of human emotion,but as each event is shared by at least two peoplein a relatively small sample, any attempt to createa comprehensive dictionary of emotion-provokingevents should at least be able to cover the pairs inthis collection.
We show the most common threeevents for each emotion in Table 1.3 Automatic Extraction of EventsWe also performed experiments attempting toautomatically extract and aggregate events fromWeb data.
As a starting point, we follow Tokuhisaet al.
(2008) in defining a single reliable pattern asa starting point for event extraction:I am EMOTION that EVENTAs this pattern is a relatively reliable indicator thatthe event is correct, most events extracted by thispattern will actually be emotion-provoking events.For instance, this pattern will be matched with thesentence ?I am happy that my mother is feelingbetter?, in which my mother is feeling better cer-tainly causes happiness.For the EMOTION placeholder, we take into ac-count 6 emotions - happiness, sadness, anger, fear,disgust, and surprise - argued by Ekman (1992) tobe the most basic.
We manually create a short listof words that can be inserted into the above patternappropriately, as shown in Table 2.For the EVENT placeholder, we allow any stringof words, but it is necessary to choose the scopeof the string that is referring to the emotion-provoking event.
To this end, we use a syntacticparser and set a hard restriction that all events mustbe a subtree having root tag S and containing atleast one noun phrase and one verb phrase.Given these two restrictions, these patternsprovide us with high quality event-emotion pairs,but the method is still lacking in two respects, lackof coverage and lack of ability to aggregate sim-ilar events.
As both of these are essential to cre-ating a high-quality and non-redundant dictionaryof events, we make two simple extensions to theextraction process as follows.3.1 Pattern ExpansionPattern expansion, or bootstrapping algorithms arewidely used in the information extraction field(Ravichandran and Hovy, 2002).
In particular Es-presso (Pantel and Pennacchiotti, 2006) is knownas a state-of-the-art pattern expansion algorithmwidely used in acquiring relationships betweenentities.
We omit the details of the algorithmfor space concerns, but note that applying the al-gorithm to our proposed task is relatively straight-forward, and allows us to acquire additional pat-terns that may be matched to improve the cover-age over the single seed pattern.
We do, however,make two changes to the algorithm.
The first isthat, as we are interested in extracting events in-stead of entities, we impose the previously men-tioned restriction of one verb phrase and one nounphrase over all events extracted by the patterns.The second is that we perform normalization ofevents to reduce their variability, namely removingall function words, replacing proper nouns withspecial symbol, and lemmatizing words.3.2 Grouping eventsThe second improvement we perform is group-ing the extracted events together.
Grouping has anumber of potential practical advantages, as notedfrequently in previous work (Becker et al., 2011).The first is that by grouping similar events to-gether, we can relieve sparsity issues to someextent by sharing statistics among the events ina single group.
The second is that aggregatingevents together allows humans to browse the listsmore efficiently by reducing the number of re-dundant entries.
In preliminary experiments, weattempted several clustering methods and even-129Emotions Eventshappiness meeting friends going on a date getting something I wantsadness someone dies/gets sick someone insults me people leave me aloneanger someone insults me someone breaks a promise someone is too lazyfear thinking about the future taking a test walking/driving at nightsurprise seeing a friend unexpectedly someone comes to visit receiving a giftTable 1: The top three events for each emotion.tually settled on hierarchical agglomerative clus-tering and the single-linkage criterion using co-sine similarity as a distance measure (Gower andRoss, 1969).
Choosing the stopping criterion foragglomerative clustering is somewhat subjective,in many cases application dependent, but for theevaluation in this work, we heuristically choosethe number of groups so the average number ofevents in each group is four, and leave a furtherinvestigation of the tuning to future work.4 Evaluation MeasuresWork on information extraction typically uses ac-curacy and recall of the extracted information asan evaluation measure.
However, in this work, wefound that it is difficult to assign a clear-cut dis-tinction between whether an event provokes a par-ticular emotion or not.
In addition, recall is diffi-cult to measure, as there are essentially infinitelymany events.
Thus, in this section, we propose twonew evaluation measures to measure the precisionand recall of the events that we recovered in thistask.To evaluate the precision of the events extrac-ted by our method, we focus on the fact that anevent might provoke multiple emotions, but usu-ally these emotions can be ranked in prominenceor appropriateness.
This is, in a way, similar to thecase of information retrieval, where there may bemany search results, but some are more appropri-ate than others.
Based on this observation, we fol-low the information retrieval literature (Voorhees,1999) in adapting mean reciprocal rank (MRR) asan evaluation measure of the accuracy of our ex-traction.
In our case, one event can have multipleemotions, so for each event that the system out-puts, we ask an annotator to assign emotions indescending order of prominence or appropriate-ness, and assess MRR with respect to these rankedemotions.2We also measure recall with respect to the2In the current work we did not allow annotators to assign?ties?
between the emotions, but this could be accommodatedin the MRR framework.manually created dictionary described in Section2, which gives us an idea of what percent of com-mon emotions we were able to recover.
It shouldbe noted that in order to measure recall, it is ne-cessary to take a matching between the events out-put by the system and the events in the previouslydescribed list.
While it would be ideal to do thisautomatically, this is difficult due to small lexicalvariations between the system output and the list.Thus, for the current work we perform manualmatching between the system hypotheses and thereferences, and hope to examine other ways ofmatching in future work.5 ExperimentsIn this section, we describe an experimental eval-uation of the accuracy of automatic extraction ofemotion-provoking events.5.1 Experimental SetupWe use Twitter3as a source of data, as it is itprovides a massive amount of information, andalso because users tend to write about what theyare doing as well as their thoughts, feelings andemotions.
We use a data set that contains morethan 30M English tweets posted during the courseof six weeks in June and July of 2012.
To removenoise, we perform a variety of preprocessing, re-moving emoticons and tags, normalizing usingthe scripts provided by Han and Baldwin (2011),and Han et al.
(2012).
CoreNLP4was used toget the information about part-of-speech, syntacticparses, and lemmas.We prepared four systems for comparison.
As abaseline, we use a method that only uses the ori-ginal seed pattern mentioned in Section 3 to ac-quire emotion-provoking events.
We also evalu-ate expansions to this method with clustering, withpattern expansion, and with both.We set a 10 iteration limit on the Espresso al-gorithm and after each iteration, we add the 203http://www.twitter.com4http://nlp.stanford.edu/software/corenlp.shtml130Methods MRR RecallSeed 46.3 (?5.0) 4.6 (?0.5)Seed + clust 57.2 (?7.9) 8.5 (?0.9)Espresso 49.4 (?2.8) 8.0 (?0.5)Espresso + clust 71.7 (?2.9) 15.4 (?0.8)Table 3: MRR and recall of extracted data (withstandard deviation for 3 annotators).most reliable patterns to the pattern set, and in-crease the seed set by one third of its size.
Thesevalues were set according to a manual inspectionof the results for several settings, before any eval-uation was performed.We examine the utility of each method accord-ing to the evaluation measures proposed in Sec-tion 4 over five emotions, happiness, sadness, an-ger, fear, and surprise.5To measure MRR andrecall, we used the 20 most frequent events orgroups extracted by each method for these fiveemotions, and thus all measures can be interpretedas MRR@20 and recall@20.
As manual annota-tion is required to calculate both measures, we ac-quired results for 3 annotators and report the aver-age and standard deviation.5.2 Experimental ResultsThe results are found in Table 3.
From these res-ults we can see that clustering the events causes asignificant gain on both MRR and recall, regard-less of whether we use Espresso or not.
Lookingat the results for Espresso, we see that it allows forsmall boost in recall when used on its own, dueto the fact that the additional patterns help recovermore instances of each event, making the estimateof frequency counts more robust.
However, Es-presso is more effective when used in combinationwith clustering, showing that both methods arecapturing different varieties of information, bothof which are useful for the task.In the end, the combination of pattern expansionand clustering achieves an MRR of 71.7% and re-call of 15.4%.
While the MRR could be deemedsatisfactory, the recall is still relatively low.
Onereason for this is that due to the labor-intensivemanual evaluation, it is not realistic to check manymore than the top 20 extracted events for eachemotion, making automatic evaluation metrics thetop on the agenda for future work.5We exclude disgust, as the seed only matched 26 timesover entire corpus, not enough for a reasonable evaluation.Emotions MRR Recallhappiness 93.9 23.1sadness 76.9 10.0anger 76.5 14.0fear 48.3 24.3surprise 59.6 0.0Table 4: Average MRR and recall by emotion forthe Espresso + clustering method.However, even without considering this, wefound that the events extracted from Twitterwere somewhat biased towards common, everydayevents, or events regarding love and dating.
On theother hand, our annotators produced a wide vari-ety of events including both everyday events, andevents that do not happen every day, but leave aparticularly strong impression when encountered.This can be seen particularly in the accuracy andrecall results by emotion for the best system shownin Table 4.
We can see that for some emotions weachieved recall approaching 25%, but for surprisewe didn?t manage to extract any of the emotionscreated by the annotators at all, instead extractingmore mundane events such as ?surprised I?m notfat yet?
or ?surprised my mom hasn?t called meyet.?
Covering the rare, but important events is aninteresting challenge for expansions to this work.6 Conclusion and Future WorkIn this paper we described our work in creat-ing a dictionary of emotion-provoking events, anddemonstrated results for four varieties of auto-matic information extraction to expand this dic-tionary.
As this is the first attempt at acquiring dic-tionaries of emotion-provoking events, there arestill many future directions that deserve further in-vestigation.
As mentioned in the experimental dis-cussion, automatic matching for the evaluation ofevent extraction, and ways to improve recall overrarer but more impressive events are necessary.There are also many improvements that could bemade to the extraction algorithm itself, includingmore sophisticated clustering and pattern expan-sion algorithms.
Finally, it would be quite interest-ing to use the proposed method as a tool for psy-chological inquiry, including into the differencesbetween events that are extracted from Twitter andother media, or the differences between differentdemographics.131ReferencesHila Becker, Mor Naaman, and Luis Gravano.
2011.Beyond trending topics: Real-world event identific-ation on Twitter.
In Proceedings of the Fifth Inter-national AAAI Conference on Weblogs and SocialMedia (ICWSM11).Paul Ekman.
1992.
An argument for basic emotions.Cognition & Emotion, 6(3-4):169?200.Andrea Esuli and Fabrizio Sebastiani.
2006.
Senti-wordnet: A publicly available lexical resource foropinion mining.
In In Proceedings of the 5th Con-ference on Language Resources and Evaluation,pages 417?422.John C Gower and GJS Ross.
1969.
Minimum span-ning trees and single linkage cluster analysis.
Ap-plied statistics, pages 54?64.Bo Han and Timothy Baldwin.
2011.
Lexical normal-isation of short text messages: makn sens a #twitter.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies - Volume 1, HLT ?11, pages368?378.Bo Han, Paul Cook, and Timothy Baldwin.
2012.Automatically constructing a normalisation diction-ary for microblogs.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning, pages 421?432, Jeju Island, Korea,July.
Association for Computational Linguistics.Saif M Mohammad and Peter D Turney.
2013.
Crowd-sourcing a word?emotion association lexicon.
Com-putational Intelligence, 29(3):436?465.Patrick Pantel and Marco Pennacchiotti.
2006.
Es-presso: leveraging generic patterns for automatic-ally harvesting semantic relations.
In Proceedingsof the 21st International Conference on Computa-tional Linguistics and the 44th annual meeting of theAssociation for Computational Linguistics, ACL-44,pages 113?120.Deepak Ravichandran and Eduard Hovy.
2002.
Learn-ing surface text patterns for a question answeringsystem.
In Proceedings of the 40th Annual Meetingon Association for Computational Linguistics, ACL?02, pages 41?47.Ellen Riloff, Janyce Wiebe, and Theresa Wilson.
2003.Learning subjective nouns using extraction patternbootstrapping.
In Proceedings of the seventh confer-ence on Natural language learning at HLT-NAACL2003-Volume 4, pages 25?32.
Association for Com-putational Linguistics.Ryoko Tokuhisa, Kentaro Inui, and Yuji Matsumoto.2008.
Emotion classification using massive ex-amples extracted from the web.
In Proceedingsof the 22nd International Conference on Computa-tional Linguistics - Volume 1, COLING ?08, pages881?888.Ro Valitutti.
2004.
Wordnet-affect: an affective ex-tension of wordnet.
In In Proceedings of the 4th In-ternational Conference on Language Resources andEvaluation, pages 1083?1086.Leonid Velikovich, Sasha Blair-Goldensohn, KerryHannan, and Ryan McDonald.
2010.
The viabilityof web-derived polarity lexicons.
In Human Lan-guage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics, pages 777?785.Ellen M Voorhees.
1999.
The trec-8 question an-swering track report.
In Proceedings of TREC,volume 99, pages 77?82.132
