EXAMPLE-BASED CORRECTION OF WORD SEGMENTATIONAND PART OF SPEECH LABELLINGTomoyoshi Matsukawa , Scott Miller, and Ralph WeischedelBBN Systems and Technologies70 Fawcett St.Cambridge, MA 02138A B S T R A C TThis paper describes an example-based correctioncomponent for Japanese word segmentation and part ofspeech labelling (AMED), and a way of combining it with apre-existing rule-based Japanese morphological nalyzer anda probabilistic part of speech tagger.Statistical algorithms rely on frequency of phenomena orevents in corpora; however, low frequency events are ofteninadequately represented.
Here we report on an example-based technique used in finding word segments and their partof speech in Japanese text.
Rather than using hand-craftedrules, the algorithm employs example data, drawinggeneralizations during training.1.
INTRODUCTIONProbabilistic part of speech taggers have proven to besuccessful in English part of speech labelling \[Church1988; DeRose, 1988; de Marcken, 1990; Meteer, et.
al.1991, etc.\].
Such stochastic models perform very wellgiven adequate amounts of training data representative ofoperational data.
Instead of merely stating what ispossible, as a non-stochastic rule-based model does,probabilistic models predict he likelihood of an event.In determining the part of speech of a highly ambiguousword in context or in determining the part of speech of anunknown word, they have proven quite effective forEnglish.By contrast, rule-based morphological analyzersemploying a hand-crafted lexicon and a hand-craftedconnectivity matrix are the traditional approach toJapanese word segmentation a d part of speech labelling\[Aizawa nd Ebara 1973\].
Such algorithms have alreadyachieved 90-95% accuracy in word segmentation a d 90-95% accuracy in part-of-speech labelling (given correctword segmentation).
The potential advantage of a rule-based approach is the ability of a human coding rules thatcover events that are rare, and therefore may beinadequately represented in most training sets.Furthermore, it is commonly assumed that large trainingsets are not required.A third approach combines a rule-based part of speechtagger with a set of correction templates automaticallyderived from a training corpus \[Brill 1992\].We faced the challenge of processing Japanese text, whereneither spaces nor any other delimiters mark thebeginning and end of words.
We had at our disposal thefollowing:A rule-based Japanese morphological processor(JUMAN) from Kyoto University.- A context-free grammar of Japanese based on part ofspeech labels distinct from those produced by JUMAN.- A probabilistic part-of-speech tagger (POST) \[Meteer,et al, 1991\] which assumed a single sequence of wordsas input.- Limited human resources for creating training data.This presented us with four issues:1) how to reduce the cost of modifying therule-based morphological analyzer toproduce the parts of speech needed by thegrammar,2) how to apply probabilistic modeling toJapanese, e.g., to improve accuracy to-97%, which is typical of results inEnglish,3) how to deal with unknown words, whereJUMAN typically makes no predictionregarding part of speech, and4) how to estimate probabilities for lowfrequency phenomena.Here we report on an example-based technique forcorrecting systemmatic errors in word segmentation a dpart of speech labelling in Japanese text.
Rather thanusing handcrafted rules, the algorithm employs exampledata, drawing generalizations during training.
Inmotivation, it is similar to one of the goals of Brill(1992).2272.
ARCHITECTUREThe architecture in Figure 1 was chosen to minimizelabor and to maximize use of existing software.
Itemploys JUMAN first to provide initial wordsegmentation f the text, an annotation-based algorithmsecond to correct both segmentation errors and part ofspeech errors in JUMAN output, and POST third both toselect among ambiguous alternative segmentations/part-of-speech assignments and also to predict the part ofspeech of unknown words.JapaneseTextI JUMAN \[iWord segmentswith Part ofSpeechSegmentCorrectionModelPart-of-speecl~ModelFigure 1: ArchitectureLet us briefly review each component.
JUMAN,available from Kyoto University makes segmentationdecisions and part of speech assignments oJapanese text.To do this, it employs a lexicon of roughly 40,000words, including their parts of speech.
Where alternativesegmentations are possible, the connectivity matrixeliminates ome possibilities, since it states what partsof speech may follow a given part of speech.
Where theconnectivity matrix does not dictate a singlesegmentation a d part of speech, generally longer wordsare preferred over shorter segmentations.An example JUMAN output is provided in Figure 2.The Japanese segment is given first, followed by a slashand the part of speech.
JUMAN employs approximately45 parts of speech.
1FIGURE 2a: A Short Example Sentence~) ~"~NB ?
/KTFIGURE 2b: JUMAN output for example 2a aboveThe correction algorithm (AMED) is trained with twoparallel annotations of the same text.
One of theannotations is JUMAN's output.
The second ismanually annotated corresponding to correct segmentationand correct part-of-speech assignments for each word.During training, AMED aligns the parallel annotations,identifies deviations as "corrections", and automaticallygeneralizes these into correction rules.
An example ofautomatic alignment appears in Figure 3.AMED performs the following functions:?
Corrects ome segmentation errors made byJUMAN.Corrects some part-of-speech assignmenterrors made by JUMAN.
Some of these"corrections" actually introduce ambiguitywhich POST later resolves.Transforms the tag set produced byJUMAN into the tag set required by thegrammar.Note that all of these functions are the result of thelearning algorithm, no rules for correction nor fortranslating JUMAN parts of speech into those for thegrammar were written by hand.The third component is POST, which assigns parts ofspeech stochastically via a Hidden Markov model, hasbeen described elsewhere \[Meteer, et al, 1991\].
POSTperforms two vital functions in the case of our Japaneseprocessing:1 CN = common noun; SN = sa-inflection noun (nominalized .verb); VB = verb; VSUF = verb suffix; CM =case marker; etc.228POST decides among ambiguous part-of-speech labellings and segmentations,particularly in those cases where AMED'straining data includes cases where JUMANis prone to error.POST predicts the most likely part ofspeech for an unknown word segment incontext.3.
HOW THE ARCHITECTUREADDRESSES THE ISSUESIn principle, a Hidden Markov Model implementation,such as POST, can make both part-of-speech decisionsand segment text quite reliably.
Therefore, why not justuse POST; why use three components instead?The clear reason was to save human effort.
We did nothave access to segmented and labelled Japanese text.Labelling tens of thousands (or even hundreds ofthousands of words of text) for supervised training wouldhave taken more effort and more time in a project withtight schedules and limited resources.
JUMAN existedand functioned above 90% accuracy in segmentation.A secondary reason was the opportunity to investigate analgorithm that learned correction rules from examples.
Athird reason was that we did not have an extensive l xiconusing the parts of speech required by the grammar.The architecture addressed the four issues raised in theintroduction as follows:1) AMED learned rules to transformJUMAN's parts of speech to those requiredby the grammar.2) Accuracy was improved both by AMED'scorrection rules and by POST's HiddenMarkov Model.3) POST hypothesizes the most likely part ofspeech in context for unknown words,words not in the JUMAN lexicon.4) The sample inspection method in AMEDestimates probabilities for low frequencyphenomena.4.
THE CORRECTION MODELThe only training data for our algorithm is manuallyannotated word segmentation and part of speech labels.Examples of corrections of JUMAN's output are extractedby a procedure that automatically aligns the annotateddata with JUMAN's output and collects pairs ofdifferences between sequences of pairs of word segmentand part of speech.
Each pair of differing stringsrepresents a correction rule; the procedure also generalizesthe examples to create more broadly applicable correctionrules.JUMAN~.~b/SN)~T/SN~/rrM~/SNLAB~P.??~P.?
?- -  E'.X/SN~/eMOUTPUT~ 6/PT9 ~VVB?
/KTFigure 3a: Alignmentmanually annotated correction data.DESIRED OUTPUTGrrTM~LNB,~/VSUF~/SNUNB~P.??~P.?
?-- U X/CN~/CM~ ~ /PT?
/KTof JUMANb/VB~b ,~/VSUFoutput withqh ~J/CNFigure 3b: Pairs of differences collected fromalignment in Figure 3a.
above.We estimate probabilities for the correction rules via thesample inspection method.
(see the Appendix.)
Here,significance level is a parameter, from a low of 0.1 forambitious correction through a high of 0.9 forconservative correction.
The setting gives us some trade-off between accuracy and the degree of ambiguity in theresults.
One selects an appropriate value by empiricallytesting performance over a range of parameter settings.Correction rules are ordered and applied based onprobability estimates.When a rule matches, l) AMED corrects JUMAN'soutput if the probability estimate xceeds auser-specifiedthreshold, 2) AMED introduces an alternative if theprobability falls below that threshold but exceeds asecond user-supplied threshold, or 3) AMED makes nochange if the probability estimate falls below boththresholds.229As a result, a chart representing word segmentation a dpart of speech possibilities is passed to POST, whichwas easily modified to handle a chart as input, since theunderlying Viterbi algorithm applies equally well to achart.
POST then selects the most likely combination ofword segmentation a d part of speech labels according toa bi-gram probability model.CNVB VSUFPT VB KTFigure 4: Chart of alternatives produced by AMED.~j~\[-/CN ~,~/CN G/ ITM ~,~ LNB ~ ,~/VSUF ~.
JCN~/NCM ~.~/CN "~- -~ 'X /CN ~/CM ~_~ Bb'~J/CN~ ~/PT ~-~ r) ~- /VB ?
/KTFigure 5: Final segmentation a d labelling afterPOST.5.
EXPERIENCEThe motivation for this study was the need to port ourPLUM data extraction system \[Weischedel, etal., 1992\]to process Japanese text.
The architecture was successfulenough that it is part of (the Japanese version of) PLUMnow, and has been used in Government-sponsoredevaluations of data extraction systems in two domains:extracting data pertinent to joint ventures and extractingdata pertinent to advances in microelectronics fabricationtechnology.
It has therefore been run over corpora ofover 300,000 words.There are two ways we can illustrate the effect of thisarchitecture: a small quanitative experiment andexamples of generalizations made by AMED.5.1 A Small ExperimentWe ran a small experiment to measure the effect of thearchitecture (JUMAN + AMED + POST), contrastedwith JUMAN alone.
Japanese linguistics studentscorrected JUMAN's output; the annotation rate of anexperienced annotator is roughly 750 words per hour,using the TREEBANK annotation tools (which we hadported to Japanese).
In the first experiment, we used14,000 words of training data and 1,400 words of testdata.
In a second experiment, we used 81,993 words oftraining data and a test set of 4,819 words.Remarkably the results for the two cases were almostidentical in error rate.
In the smaller test (of 1,400words), the error rate on part-of-speech labelling (givencorrect segmentation) was 3.6%, compared to 8.5%;word segmentation error was reduced from 9.4% to 8.3%using the algorithm.
In the larger test (of 4,819 words),the error rate on part-of-speech labelling (given correctsegmentation) was 3.4%, compared to 8.2%; wordsegmentation error was reduced from 9.4% to 8.3% usingthe algorithm.Therefore, using the AMED correction algorithm plusPOST's hidden Markov model reduced the error rate inpart of speech by more than a factor of two.
Reductionin word segmentation was more modest, a 12%improvement.Error rate in part-of-speech labelling was therefore reducedto roughly the error rate in English, one of our originalgoals.Both segmentation error and part of speech error could bereduced further by increasing the size of JUMAN'slexicon and/or by incorporating additional generalizationpatterns in AMED's learning alogrithm.
However, interms of improving PLUM's overall performance inextracting data from Japanese text, reducing wordsegmentation error or part-of-speech error are not thehighest priority.5.2 Examples of Rules LearnedOne restriction we imposed on generalizations consideredby the algorithm is that rules must be based on the firstor last morpheme of the pattern.
This is based on theobservation i skimming the result of alignment that thefirst or last morpheme is quite informative.
Rules whichdepend critically on a central element in the differencebetween aligned JUMAN output and supervised trainingwere not considered.
A second limitation that weimposed on the algorithm was that the fight hand side ofany correction rule could only contain one element,instead of the general case.
Three kinds of correctionrules can be inferred.?
A specific sequence of parts of speech inJUMAN's output can be replaced by asingle morpheme with one part of speech.?
A specific sequence of parts of speech plusa specific word at the left edge can bereplaced by a single morpheme with onepart of speech.230A specific sequence of parts of speech plusa specific word at the right edge can bereplaced by a single morpheme with onepart of speech.The critical statistic in selecting among theinterpretations is the fraction of times a candidate rulecorrectly applies in the training data versus the number oftimes it applies in the training.
In spite of these self-imposed limitations in this initial implementation, therules that are learned improved both segmentation andlabelling by part of speech, as detailed in Section 5.1.Here we illustrate some useful generalizations made bythe algorithm and used in our Japanese version of thePLUM data extraction system.In example (1) below, the hyptohesized rule essentiallyrecognizes proper names arising from an unknown, apunctuation mark, and a proper noun; the rulehypothesizes that the three together are a proper noun.This pattern only arises in the case of person names (aninitial, a period, and a last name) in the training corpus.1.
*/?.??
*,YKG */PN ===> PNE/????
/KG"7 --  Y 9 '~ F/PNE ?
~- -~9,~,F /PNExample (2) is a case where an ambiguous word Cnerai",meaning a"aim" or "purpose") is rarely used as a verb,but JUMAN's symbolic rules are predicting it as a verb.The rule corrects the rare tag to the more frequent one,common noun.2.
~.\[t ~,~NB ===> CN~t.
~ a/VB ~'jl~.
VCNExample (3) represents he equivalent of learning a lexicalentry from annotation; if JUMAN had had it in itslexicon, no correction of segmentation (and part ofspeech) would have been necessary.
There are manysimilar, multi-character, idiomatic particles in Japanese.Parallel cases arise in English, such as "in spite off and"in regard to".3.
~/NCM */PT */CN */PT===> PT/NCM?
)/PTI~L/CN"~TPTExample (4) is interesting since the rule learnedcorresponds to a general morphological phenomenon iJapanese.
"Shita" converts an adverb to an adjective.4.
*/ADV \[., T~NB ===> ADJ~_ 5/ADV ?
5 L, gC/ADJL/~/VBExample (5) represents a lexical omission where aninflected form, corresponding to the modal "can", islearned.5.
*/'?.??
7a/?.??
===> VSUF~/)P, ??
~/) 7~NSUF~/7776.
CONCLUSIONThe most interesting aspect of this work is theimplementation and testing of a simple algorithm tolearn correction rules from examples.
Except for theannotation of text as to the correct data, the process isfully automatic.
Even with as little data as we hadinitially (under 15,000 words), the learned correction rulesimproved the performance of morphological processingcompared to the baseline system.
Furthermore, thoughthe original error rate of JUMAN was more than doublethe rate typically reported for stochastic part-of-speechlabellers in English, the result of the correction algorithmplus our hidden Markov model (POST) reduced the errorrate to a level comparable with that experienced inEnglish.
On the other hand, increasing the training databy a factor of five did not reduce the error ratesubstantially.The architecture proposed is the morhpologicalcomponent of the Japanese version of the PLUM dataextraction system, and has been tested on more than300,000 words of text in both a financial domain and atechnical domain.Hidden Markov Models, as implementd in POST, wereapplied to Japanese with relative ease.
When additionaldata becomes available, we would like to test theperformance of POST for both word segmentation andlabelling part of speech in Japanese.ACKNOWLEDGEMENTSWe wish to thank Professors Matsumoto and Nagao ofKyoto University who graciously made the JUMANsystem available to us.231REFERENCES1.2.3.4.5.6.7.Aizawa, T. and Ebara, T. (1973) "MechanicalTranslation System of "Kana' Representations to"Kanji-kana' Mixed Representations," NHKThechnical Journal 138 Vol.25 No.5, 1973.Brill, E. (1992) "A Simple Rule-Based Part of SpeechTagger," Proceedings of the Fifth DARPA Workshopon Speech and Natural Language, Morgan KaufmannPublishers, San Mateo, CA.
February 1992, pp.
112-116.Church, K. A (1988), "Stochastic Parts Program andNoun Phrase Parser for Unrestricted Text,"Proceedings of the Second Conference on AppliedNatural Language Processing, ACL, 1988, 136-143.de Marcken, C.G.
(1990) "Parsing the LOB Corpus,"Proceedings of the 28th Annual Meeting of theAssociation for Computational Linguistics 1990,243-251.DeRose, S.J.
(1988) "Grammatical CategoryDisambiguation by Statistical Optimization,"Computational Linguistics 14: 31-39, 1988.Meteer, M., Schwartz, R., and Weischedel, R. (1991)"Empirical Studies in Part of Speech Labelling,"Proceedings of the Fourth DARPA Workshop onSpeech and Natural Language, Morgan KaufmannPublishers, San Mateo, CA.
February 1991, pp.
331-336.Weischedel, R. (1991) "A New Approach to TextUnderstanding," Proceedings of the Fourth DARPAWorkshop on Speech and Natural Language, MorganKaufmann Publishers, San Mateo, CA.
February1991, pp.
316-322.APPENDIXTo estimate the reliability of hypothesized correctionrules, we used the sample inspection method.
If  thesample size is small, high frequency cases may tend toreceive a higher probability estimate than if the samplewere larger.The sample inspection method provides an objectivemeasure of how likely estimation error may be, givensmall samples.
Suppose we have:?
a total of N elements in a population,?
R elements in a desired class,?
n sample lements in total, and?
r sample lements in the desired classp(R>Rll r=rl) - p(R>R1, r=rl)p(r=rl)Since we assume the elements of R occur independently,we haveE p(R) p(r=rlIR)R>R1p(R) p(r=rllR)R>OAssuming p(R) is approximately constant, we have= ~ p(r=rll R) (1)R>R~Here p(r = rl I R), the conditional probability of r desiredelements given R desired elements in the population, isgiven by a hypergeometric distribution.
The distributionwill approach a binomial distribution as N gets larger.p(r=rl IR)- (Rr) (Nn --rR) (aN)N --> oo....... > (rn)qr(1- q)n-r(2)Therefore, substituting (2) to (1), given a significancelevel k (the probability that the conclusion is correct; foreacmple 0.9), we search for the largest q' which satisfies:p{q>q'l r=rl)= / 1 (~) qr (1- q)n-r > k&The conditional probaiblity of R > R1, given r = rl willbe:232
