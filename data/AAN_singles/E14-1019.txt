Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 174?182,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsAbout Inferencesin a Crowdsourced Lexical-Semantic NetworkManel ZarroukUM2-LIRMM161 rue Ada34095 Montpellier, FRANCEmanel.zarrouk@lirmm.frMathieu LafourcadeUM2-LIRMM161 rue Ada34095 Montpellier, FRANCEmathieu.lafourcade@lirmm.frAlain JoubertUM2-LIRMM161 rue Ada34095 Montpellier, FRANCEalain.joubert@lirmm.frAbstractAutomatically inferring new relationsfrom already existing ones is a way toimprove the quality of a lexical networkby relation densification and error de-tection.
In this paper, we devise suchan approach for the JeuxDeMots lexi-cal network, which is a freely avalaiblelexical network for French.
We firstpresent deduction (generic to specific)and induction (specific to generic) whichare two inference schemes ontologicallyfounded.
We then propose abductionas a third form of inference scheme,which exploits examples similar to a tar-get term.1 IntroductionBuilding resources for Computational Linguis-tics (CL) is of crucial interest.
Most of exist-ing lexical-semantic networks have been builtby hand (like for instance WordNet (Miller etal., 1990)) and, despite that tools are generallydesigned for consistency checking, the task re-mains time consuming and costly.
Fully auto-mated approaches are generally limited to termco-occurrences as extracting precise semanticrelations between terms from corpora remainsreally difficult.
Meanwhile, crowdsourcing ap-proaches are flowering in CL especially withthe advent of Amazon Mechanical Turk or in abroader scope Wikipedia and Wiktionary, to citethe most well-known examples.
WordNet is sucha lexical network, constructed by hand at greatcost, based on synsets which can be roughlyconsidered as concepts (Fellbaum, 1988).
Eu-roWordnet (Vossen., 1998) a multilingual ver-sion of WordNet and WOLF (Sagot., 2008) aFrench version of WordNet, were built by auto-mated crossing of WordNet and other lexical re-sources along with some manual checking.
Nav-igli (2010) constructed automatically BabelNet alarge multilingual lexical network from term co-occurrences in Wikipedia.A lexical-semantic network can contain lem-mas, word forms and multi-word expressions asentry points (nodes) along with word meaningsand concepts.
The idea itself of word senses inthe lexicographic tradition may be debatable inthe context of resources for semantic analysis,and we generally prefer to consider word us-ages.
A given polysemous word, as identifiedby locutors, has several usages that might dif-fer substantially from word senses as classicallydefined.
A given usage can also in turn haveseveral deeper refinements and the whole setof usages can take the form of a decision tree.For example, frigate can be a bird or a ship.
Afrigate>boat can be distinguished as a modernship with missiles and radar or an ancient vesselwith sails.
In the context of a collaborative con-struction, such a lexical resource should be con-sidered as being constantly evolving and a gen-eral rule of thumb is to have no definite certi-tude about the state of an entry.
For a polysemicterm, some refinements might be just missing ata given time notwithstanding evolution of lan-guage which might be very fast, especially intechnical domains.
There is no way (unless byinspection) to know if a given entry refinementsare fully completed, and even if this question isreally relevant.The building of a collaborative lexical network(or, in all generality, any similar resource) canbe devised according to two broad strategies.First, it can be designed as a contributive system174like Wikipedia where people willingly add andcomplete entries (like for Wiktionary).
Second,contributions can be made indirectly thanks togames (better known as GWAP (vonAhn, 2008))and in this case players do not need to be awarethat while playing they are helping building alexical resource.
In any case, the built lexicalnetwork is not free of errors which are correctedalong their discovery.
Thus, a large number ofobvious relations are not contained in the lexi-cal network but are indeed necessary for a highquality resources usable in various NLP applica-tions and notably semantic analysis.
For exam-ple, contributors seldom indicate that a particu-lar bird type can fly, as it is considered as an obvi-ous generality.
Only notable facts which are noteasily deductible are naturally contributed.
Wellknown exceptions are also generally contributedand take the form of a negative weight and anno-tated as such (for example, flyag ent :?100????????
ostrich[exception: bird]).In order to consolidate the lexical network,we adopt a strategy based on a simple in-ference mechanism to propose new relationsfrom those already existing.
The approach isstrictly endogenous (i.e.
self-contained) as itdoesn?t rely on any other external resources.
In-ferred relations are submitted either to contrib-utors for voting or to experts for direct valida-tion/invalidation.
A large percentage of the in-ferred relations has been found to be correcthowever, a non-negligible part of them are foundto be wrong and understanding why is both in-teresting and useful.
The explanation processcan be viewed as a reconciliation between the in-ference engine and contributors who are guidedthrough a dialog to explain why they foundthe considered relation incorrect.
The possiblecauses for a wrong inferred relation may comefrom three possible origins: false premises thatwere used by the inference engine, exception orconfusion due to some polysemy.In (Sajous et al., 2013) an endogenous enrich-ment of Wiktionary is done thanks to a crowd-sourcing tool.
A quite similar approach of us-ing crowdsourcing has been considered by (Ze-ichner, 2012) for evaluating inference rules thatare discovered from texts.
In (Krachina, 2006),some specific inference methods are conductedon text with the help of an ontology.
Simi-larly, (Besnard, 2008) capture explanation withontology-based inference.
OntoLearn (Velardi,2006) is a system that automatically build on-tologies of specific domains from texts and alsomakes use of inferences.
There have beenalso researchs on taxonomy induction based onWordNet (Snow, 2006).
Although extensive workon inference from texts or handcrafted resourceshas been done, almost none endogenously onlexical network built by the crowds.
Most prob-ably the main reason of that situation is the lackof such specific resources.In this article, we first present the principlesbehind the lexical network construction withcrowdsourcing and games with a purpose (alsoknow as human-based computation games) andillustrated them with the JeuxDeMots (JDM)project.
Then, we present the outline of an elici-tation engine based on an inference engine usingdeduction, induction and especially abductionschemes.
An experimentation is then presented.2 Crowdsourced Lexical NetworksFor validating our approach, we used the JDMlexical network, which is constructed thanks toa set of associatory games (Lafourcade, 2007)and has been made freely available by its au-thors.
There is an increasing trend of using on-line GWAPs (game with a purpose (Thaler etal., 2011)) method for feeding such resources.Beside manual or automated strategies, con-tributive approaches are flowering and becom-ing more and more popular as they are bothcheap to set up and efficient in quality.The network is composed of terms (as ver-tices) and typed relations (as links betweenvertices) with weight.
It contains terms andpossible refinements.
There are more than 50types of relations, that range from ontological(hypernym, hyponym), to lexical-semantic(synonym, antonym) and to semantic role(agent, patient, instrument).
The weight of arelation is interpreted as a strength, but notdirectly as a probability of being valid.
The JDMnetwork is not an ontology with some cleanhierarchy of concepts or terms.
A given termcan have a substantial set of hypernyms thatcovers a large part of the ontological chain toupper concepts.
For example, hypernym(cat) ={feline,mammal, living being,pet,vertebrate, ...}.Heavier weights associated to relations are thosefelt by users as being the most relevant.
The1751st January 2014, there are more than 6 700 000relations and roughly 310 000 lexical items in theJDM lexical network (according to the figuresgiven by the game site: http://jeuxdemots.org).To our knowledge, there is no other existingfreely available crowdsourced lexical-network,especially with weighted relations, thus enablingstrongly heuristic methods.3 Inferring with Deduction & InductionAdding new relations to the JDM lexical networkmay rely on two components: (a) an inferenceengine and (b) a reconciliator.
The inference en-gine proposes relations as a contributor to bevalidated by other human contributors or ex-perts.
In case of invalidation of an inferred re-lation, the reconciliator is invoked to try to as-sess why the inferred relation was found wrong.Elicitation here should be understood as the pro-cess to transform some implicit knowledge of theuser into explicit relations in the lexical network.The core ideas about inferences in our engine arethe following:?
inferring is to derive new premises (asrelations between terms) from previouslyknown premises, which are existing rela-tions;?
candidate inferences may be logicallyblocked on the basis of the presence or theabsence of some other relations;?
candidate inferences can be filtered out onthe basis of a strength evaluation.3.1 Deduction SchemeInferring by deduction is a top-down schemebased on the transitivity of the relation is-a (hy-pernym).
If a term A is a kind of B and B holdssome relation R with C, then we can expect that Aholds the same relation type with C. The schemecan be formally written as follows: ?
A i s?a????
B?
?
B R??
C ?
A R??
C.For example, shark i s?a????
fish and fishhas?par t????????
fin, thus we can expect that sharkhas?par t????????
fin.
The inference engine is appliedon terms having at least one hypernym (thescheme could not be applied otherwise).
Ofcourse, this scheme is far too naive, especiallyconsidering the resource we are dealing withand may produce wrong relations (noise).
Ineffect, the central term B is possibly polysemousand ways to avoid probably wrong inferencescan be done through a logical blocking: ifthere are two distinct meanings for B that holdrespectively the first and the second relation,then most probably the inferred relation R(3)is wrong (see figure 1) and hence should beblocked.
Moreover, if one of the premises istagged by contributors as true but irrelevant,then the inference is blocked.BBiBjAC(1)is-a:w 1(3) R?
: w3(4)is-a(2)R: w2(5)RFigure 1: Triangular inference scheme where thelogical blocking based on the polysemy of thecentral term B which has two distinct meaningsBi and B j is applied.
The two arrows without la-bel are those of word meanings.It is possible to evaluate a confidence level (onan open scale) for each produced inference, in away that dubious inferences can be eliminatedout through statistical filtering.
The weight wof an inferred relation is the geometric mean ofthe weight of the premises (relations (1) and (2)in Figure 1).
If the second premise has a nega-tive value, the weight is not a number and theproposal is discarded.
As the geometric mean isless tolerant to small values than the arithmeticmean, inferences which are not based on tworather strong relations (premises) are unlikely topass.w(A R??
C) = ( w(A i s?a????
B) ?
w(B R??
C) )1/2?
w3 = (w1 ?
w2)1/2Inducing a transitive closure over a knowledgebase is not new, but doing so considering wordmeanings over a crowdsourced lexical network isan original approach.3.2 Induction SchemeAs for the deductive inference, induction ex-ploits the transitivity of the relation is-a.
If a termA is a kind of B and A holds a relation R with C ,then we might expect that B could hold the sametype of relation with C .
More formally we canwrite: ?
A i s?a????
B ?
?
A R??
C ?
B R??
C.For example, shark i s?a????
fish and sharkhas?par t?????
?jaw, thus we might expect that fishhas?par t??????
jaw.This scheme is a generalization inference.
Theprinciple is similar to the one applied to the de-176duction scheme and similarly some logical andstatistical filtering may be undertaken.BCAAiAj(1)is-a:w 1(2)R: w3(5)is-a(4)R(3)R?
:w2Figure 2: (1) and (2) are the premises, and (3)is the induction proposed for validation.
TermA may be polysemous with meanings holdingpremises, thus inducing a probably wrong rela-tion.The central term here A, is possibly polyse-mous (as shown in Figure 2).
In that case, wehave the same polysemy issues than with the de-duction, and the inference may be blocked.
Theestimated weight for the induced relation is:w(B R??
C) = (w(A R??
C))2 / w(A i s?a????
B)?
w2 = (w3)2/w13.3 Performing ReconciliationInferred relations are presented to the validatorto decide of their status.
In case of invalida-tion, a reconciliation procedure is launched inorder to diagnose the reasons: error in one of thepremises (previously existing relations are false),exception or confusion due to polysemy (the in-ference has been made on a polysemous centralterm).
A dialog is initiated with the user (Cohen?skappa of 0.79).
To know in which order to pro-ceed, the reconciliator checks if the weights ofthe premises are rather strong or weak.Errors in the premises.
We suppose that rela-tion (1) (in Figure 1 and 2) has a relatively lowweight.
The reconciliation process asks the val-idator if the relation (1) is true.
It sets a negativeweight to this relation if not so that the engineblocks further inferences.
Else, if relation (1) istrue, we ask about relation (2) and proceed asabove if the answer is negative.
Otherwise, wecheck the other cases (exception, polysemy).Errors due toExceptions.
For the deduction, incase we have two trusted relations, the reconcil-iation process asks the validators if the inferredrelation is a kind of exception relatively to theterm B .
If it is the case, the relation is stored inthe lexical network with a negative weight andannotated as exception.
Relations that are ex-ceptions do not participate further as premisesfor deducing.
For the induction, in case we havetwo trusted relations, the reconciliator asks thevalidators if the relation (A R??
C) (which servedas premise) is an exception relatively to the termB .
If it is the case, in addition to storing the falseinferred relation (B R??
C) in the lexical networkwith a negative weight, the relation (A R??
C) isannotated as exception.
In the induction case,the exception is a true premise which leads to afalse induced relation.
In both cases of induc-tion and deduction, the exception tag concernsalways the relation (A R??
C).
Once this relationis annotated as an exception, it will not partic-ipate as a premise in inferring generalized rela-tions (bottom-up model) but can still be used ininducing specified relations (top-down model).Errors due to Polysemy.
If the central term(B for deduction and A for induction) present-ing a polysemy is mentioned as polysemousin the network, the refinement terms ter m1,ter m2, .
.
.
ter mn are presented to the validatorso she/he can choose the appropriate one.
Thevalidator can propose new terms as refinementsif she/he is not satisfied with the listed ones (in-ducing the creation of new appropriate refine-ments).
If there is no meta information indicat-ing that the term is polysemous, we ask first thevalidator if it is indeed the case.
After this proce-dure, new relations will be included in the net-work with positive values and the inference en-gine will use them later on as premises.4 Abductive InferenceThe last inferring scheme is built upon abduc-tion and can be viewed as an example basedstrategy.
Hence abduction relies on similaritybetween terms, which may be formalized in ourcontext as sharing some outgoing relations be-tween terms.
The abductive inferring layoutsupposes that relations held by a term can beproposed to similar terms.
Here, abduction firstselects a set of similar terms to the target term Awhich are considered as proper examples.
Theoutgoing relations from the examples which arenot common with those of A are proposed aspotential relations for A and then presented forvalidation/invalidation to users.
Unlike induc-tion and deduction, abduction can be applied on177terms with missing or irrelevant ontological rela-tions, and can generate ontological relations tobe used afterward by the inference loop.4.1 Abduction SchemeWe note an outgoing relation as a 3-uple of a typet , a weight w and a target node n:Ri = ?
ti , wi , ni?.
For example, consider the term A having noutgoing relations.
Amongst these relations, wehave for example:?
beakhas?par t????
A & ?
nest locati on????
A.We found 3 examples sharing those two rela-tions with the term A:?
beakhas?par t????
{ex1,ex2,ex3}?
nest l ocati on????
{ex1,ex2,ex3}We consider these terms as a set of exam-ples to follow and similar to A.
These exampleshave also other outgoing relations which are pro-posed as potential relations for A.
For example :?
{ex1,ex2}ag ent?1????
fly ?
{ex2}car ac????
colorful?
{ex1,ex2,ex3}has?par t????
feather?
{ex3}ag ent?1????
singWe infer that A can hold these relations and wepropose them for validation.?
Aag ent?1????
fly ?
?
Ahas?par t????
feather ??
A car ac????
colorful ?
?
Aag ent?1????
sing ?4.2 Abduction FilteringApplying the abduction procedure crudely onthe terms generates a lot of waste as a consid-erable amount of erroneous inferred relations.Hence, we elaborated a filtering strategy to avoidhaving a lot of dubious proposed candidates.
Forthis purpose, we define two different thresholdpairs.
The first threshold pair (?1, ?1) is used toselect proper examples x1,x2...xn and is definedas follows:?1 =max(3,nbogr(A)?0.1) (1)where nbogr(A) is the number of outgoing rela-tions from the term A.?1 =max(25,mwogr(A)?0.5) (2)where mwogr(A) is the mean of weights of outgo-ing relations from A.
The second threshold pair(?2, ?2) is used to select proper candidate re-lations from outgoing relations of the examplesR ?1,R?2...R?q .
?2 =max(3,{xi }?0.1) (3)where {xi } is the cardinal of the set {xi }.
?2 =max(25,mwogr({xi })?0.5) (4)where mwogr({xi }) is the mean of weights of out-going relations from the set of examples xi .If a term A is sharing at least ?1 relations, hav-ing a weight over ?1, of the total of the rela-tions R1, R2, .
.
.
Rp toward terms T1, T2, .
.
.
Tpwith a group of examples x1, x2, .
.
.
xn , we admitthat this term has a degree of similarity strongenough with these examples.
After building upa set of examples on which we can apply our ab-duction engine we proceed with the second partof the strategy.
If we have at least ?2 examples xiholding a specific relation R ?k weighting over ?2with a term Bk , more formally R ?k = ?
t , w ?
?2,Bk ?, we can suppose that the term A may holdthis same relation R ?k with the same target termBk (figure 3).x1x2x3xnT1T2TpAB1B2BqR1R2RpR ?1R ?qR ?2R ?1?R ?q ?Figure 3: Abduction scheme with examples xisharing relations with A and proposing new ab-ducted relations.On figure 3, we simplified thresholds to 2for illustrative purpose.
So, to be selected, theexamples x1 ,x2, x3, .
.
.
xn must have at least 2common relations with A.
A relation R ?1?q mustbe hold by at least 2 examples to be proposed asa potential relation for A.
More clearly:?
x1R ?1????
B1 and x2R ?1????
B1 ?
R ?1 : 2=?
propose AR ?1?????
B1?
xnR ?2????
B2 ?
R ?2 : 1=?
do not propose this relation.?
x1R ?q????
Bq , x3R ?q????
Bq and xnR ?q????
Bq?
R ?q : 3=?
propose AR ?q ?????
BqFor statistical filtering, we can act on the178threshold (?2, ?2) as the minimum number ofexamples xi being R ?
related with a target termBk .
It is also possible to evaluate the weight ofthe abducted relation as following:w(AR ?k??
Bk )=1nbR ?cdn,p,q?i=1, j=1,k=13pw1w2w3 (5)where nbR ?cd is the number of the relations R?candidate to be proposed and w1=AR j????
T j &w2=xiR j????
T j & w3=xiR ?k????
Bk .This filtering parameters are adjustable ac-cording to the user?s requirements, so it can fulfilvarious expectations.
Constant values in thresh-old formulas have been determined empirically.5 ExperimentationWe made an experiment with a unique run ofthe deduction, induction and abduction enginesover the lexical network.
Contributors have ei-ther accepted or rejected a subset of those can-didates during the normal course of their activ-ity.
This experiment is for an evaluation pur-pose only, as actually the system is running iter-atively along with contributors and games.
Theexperiment has been done with the parametersgiven previously, which are determined empri-cally as those maximizing recall and precision(over a very small subset of the JDM lexical net-work, around 1?
).5.1 Appliying Deductions and InductionsWe applied the inference engine on around25 000 randomly selected terms having at leastone hypernym or one hyponym and thus pro-duced by deduction more than 1 500 000 infer-ences and produced by induction over 360 000relation candidates.
The threshold for filteringwas set to a weight of 25.
This value is relevantas when a human contributor proposed relationis validated by experts, it is introduced with a de-fault weight of 25.The transitive is-a (Table1) is not very produc-tive which might seems surprising at first glance.In fact, the is-a relation is already quite popu-lated in the network, and as such, fewer new re-lations can be inferred.
The figures are invertedfor some other relations that are not so well pop-ulated in the lexical network but still are poten-tially valid.
The has-parts relation and the agentsemantic role (the agent-1 relation) are by far themost productive types.Relation type Proposed%is-a (x is a type of y) 6.1has-parts (x is composed of y) 25.1holonym (y specific of x) 7.2typical place (of x) 7.2charac (x as characteristic y) 13.7agent-1 (x can do y) 13.3instr-1 (x instrument of y) 1.7patient-1 (x can be y) 1place-1 (x located in the place y) 9.8place > action (y can be done in place x) 3.4object > mater (x is made of y) 0.3Table 1: Global percentages of relations pro-posed per type for deduction and induction.Deduction % valid % errorRelation type rlvt ?
rlvnt prem excep polis-a 76% 13% 2% 0% 9%has-parts 65% 8% 4% 13% 10%holonym 57% 16% 2% 20% 5%typical place 78% 12% 1% 4% 5%charac 82% 4% 2% 8% 4%agent-1 81% 11% 1% 4% 3%instr-1 62% 21% 1% 10% 6%patient-1 47% 32% 3% 7% 11%place-1 72% 12% 2% 10% 6%place > action 67% 25% 1% 4% 3%object > mater 60% 3% 7% 18% 12%Table 2: Number of propositions produced bydeduction and ratio of relations found as true orfalse.In tables 2 and 3 are presented some evalu-ations of the status of the inferences proposedby the inference engine through deduction andinduction respectively.
Inferences are valid foran overall of 80-90% with around 10% valid butnot relevant (like for instance doghas?par t s????????
pro-ton).
We observe that error number in premisesis quite low, and nevertheless errors can be eas-ily corrected.
Of course, not all possible errorsare detected through this process.
More inter-estingly, the reconciliation allows in 5% of thecases to identify polysemous terms and refine-ments.
Globally false negatives (inferences votedfalse while being true) and false positives (infer-ences voted true while being false) are evaluatedto less than 0.5%.For the induction process, the relation is-a isnot obvious (a lexical network is not reductibleto an ontology and multiple inheritance is possi-ble).
Result seems about 5% better than for thededuction process: inferences are valid for anoverall of 80-95%.
The error number is very low.The main difference with the deduction processis on errors due to polysemy which is lower withthe induction process.179To try to assess a baseline for those results,we compute the full closure of the lexical net-work, i.e.
we produce iteratively all possible can-didate relations until no more could be found,each candidate being considered as correct andparticipating to the process.
We got more than6 000 000 relations out of which 45% were wrong(evaluation on around 1 000 candidates ran-domly chosen).5.2 Unleashing the Abductive EngineWe applied systematically the abduction engineon the lexical items contained in the network,and produce 629 987 abducted relations out ofwhich 137 416 were not already existing in thenetwork.
Those 137 416 are candidate relationsconcerning 10 889 distinct lexical entries, henceproducing a mean of around 12 new relationsper entry.
The distribution of the proposed re-lations follows a power law, which is not totallysurprising as the relation distribution in the lex-ical network is by itself governed by such a dis-tribution.
Those figures indicate that abductionseems to be still quite productive in terms of rawcandidates, even not relying on ontological ex-isting relations.The table 4 presents the number of relationsproposed by the inference engine through ab-duction.
The different relation types are var-iously productive, and this is mainly due tothe number of existing relations and the dis-tribution of their type.
The most productiverelation is has-part and the least one is holo(holonym/whole).
Correct relations representaround 80% of the relations that have been eval-uated (around 5.6% of the total number of pro-duced relations).One suprising fact, is that the 80% seem tobe quite constant notwithstanding the relationtype, the lowest value being 77% (for instr-1which is the relation specifying what can be donewith x as an instrument) and the highest being85% (for action-place which is the relation asso-ciating for an action the typical locations whereit can occur).
The abduction process is not onto-logically based, and hence does not rely on thegeneric (is-a) or specific (hyponym) relations,but on the contrary on any set of examples thatseems to be alike the target term.
The apparentstability of 80% correct abducted relations maybe a positive consequence of relying on a set ofexamples, with a potentially irreductible of 20%wrong abducted relations.Figure 4 presents two types of data: (1) thepercentage of correct abducted relations accord-ing to the number of examples required to pro-duce the inference, and (2) the proportion be-tween the produced relations and the total of107 416 relations according to the minimal num-ber of examples allowed.
What can clearly beseen is that when the number of required ex-amples is increased, the ratio of correct abduc-tions increases accordingly, but the number ofproposed relations dramaticaly falls.
The num-ber of abductions is an inverse power law of thenumber of examples required.Figure 4: Production of abducted relations andpercentage of correctness according to examplesnumber.At 3 examples, only 40% of the proposed re-lations are correct, and with a minimum of 6examples, more than 3/4 of the proposals aredeemed correct.
The balanced F-score is opti-mal at the intersection of both curves, that is tosay for at least 4 examples.In figure 5, is showed the mean number ofnew relations during an iteration of the infer-ence engine on abduction.
Between two runs,users and validators are invited to accept or re-ject abducted relations.
This process is doneat their discretion and users may leave somepropostions unvoted.
Experiments showed thatusers are willing to validate strongly true rela-tions and invalidate clearly false relations.
Rela-tions whose status may be difficult are more of-ten left aside than other easiest proposals.
Thethird run is the most productive with a mean ofalmost 20 new abducted relations.
After 3 runs,the abductive process begins to be less produc-tive by attrition of new possible candidates.
No-tice that the abduction process may, on subse-quent runs, remove some previsouly done pro-posals and as such is not monotonous.180Figure 5: Mean number of new relations rela-tively to runs in iterated abduction.5.3 Figures on ReconciliationReconciliation in abduction is simpler than indeduction or induction, as the potential adverseeffect of polysemy is counterbalanced by thestatistical approach implemented by the largenumber of examples (when available).
The rec-onciliation in the case of abduction is to deter-mine if the wrong proposal has been producedlogically considering the support examples.
In97% of the cases, the wrong abducted relationhas been qualified as wrong but logical by vot-ers or validators.
For examples: ?
Boeing747has?par t??????
propeller* ?
whalepl ace????
lake *?
pelicanag ent?1??????
sing *.
All those wrong ab-ducted relations given as examples above mighthave been correct.
Considering the examples ex-ploited to produce the candidates, in those casesthere is no possible way to guess those relationsare wrong.
This is even reinforced by the fact thatabduction does not rely on ontological relations,which in some cases could have avoided wrongabduction.
However, abduction compared to in-duction and deduction, can be used on termsthat do not hold ontological relations, either theyare missing or they are not relevant (for verbs, in-stances...).6 ConclusionWe presented some issues in inferring new rela-tions from existing ones to consolidate a lexical-semantic network built with games and usercontributions.
New inferred relations are storedto avoid having to infer them again and again dy-namically.
To be able to enhance the networkquality and coverage, we proposed an elicitationengine based on inferences (induction, deduc-tion and abduction) and reconciliation.
If an in-ferred relation is proven wrong, a reconciliationprocess is conducted in order to identify the un-derlying cause and solve the problem.
The ab-duction scheme does not rely on the ontologi-cal relation (is-a) but merely on examples thatare similarly close to the target term.
Experi-ments showed that abduction is quite produc-tive (compared to deduction and induction), andis stable in correctness.
User evaluation showedthat wrong abducted relations (around 20% ofall abducted relations) are still logically soundand could not have been dismissed a priori.
Ab-duction can conclusively be considered as a use-full and efficient tool for relation inference.
Themain difficulty relies in setting the various pa-rameter in order to achieve a fragile tradeoff be-tween an overrestrictive filter (many false nega-tives, resulting in information losses) and the op-posite (many false postive, more human effort).The elicitation engine we presented throughschemas based on deduction, induction and ab-duction is an efficient error detector, a polysemyidentifier but also a classifier by abduction.
Theactions taken during the reconciliation forbidan inference proven wrong or exceptional to beinferred again.
Each inference scheme is sup-ported by the two others, and if a given inferencehas been produced by more than one of thesethree schemas, it is almost surely correct.Induction % valid % errorRelation types rlvt ?rlvnt prem excep polis-a - - - - -has-parts 78% 10% 3% 2% 7%holonyme 68% 17% 2% 8% 5%typical place 81% 13% 1% 2% 3%charac 87% 6% 2% 2% 3%agent-1 84% 12% 1% 2% 1%instr-1 68% 24% 1% 4% 3%patient-1 57% 36% 3% 2% 2%place-1 75% 16% 2% 5% 2%place > action 67% 28% 1% 3% 1%object > mater 75% 10% 7% 5% 3%Table 3: Number of propositions produced by in-duction and ratio of relations found as true orfalse.Abduction #prop #eval (%) True (%) False (%)is-a 7141 421 (5.9) 343 (81.5) 78 (18.5)has-parts 26517 720 (2.7) 578 (80.3) 142 (19.7)holo 1592 153 (9.6) 124 (81) 29 (18.9)agent 7739 298 (3.9) 236 (79.2) 62 (20.8)place 17148 304 (1.8) 253 (83.2) 51 (16.8)instr 10790 431 (4) 356 (82.6) 75 (17.4)charac 7443 319 (4.3) 251 (78.7) 68 (21.3)agent-1 18147 955 (5.3) 780 (81.7) 175 (18.3)instr-1 11867 886 (7.5) 682 (77) 204 (23)place-1 14787 1106 (7.5) 896 (81) 210 (19)place>act 8268 270 (3.3) 214 (79.3) 56 (20.7)act>place 5976 170 (2.8) 145 (85.3) 25 (14.7)Total 137416 6033 (4.3) 4858 (81) 1175 (19)Table 4: Number of propositions produced byabduction and ratio of relations found as true orfalse.181Referencesvon Ahn, L. and Dabbish, L. 2008.
Designing gameswith a purpose.
in Communications of the ACM,number 8, volume 51. p 58-67.Besnard, P. Cordier, M.-O., and Moinard, Y.
2008.Ontology-based inference for causal explanation.Integrated Computer-Aided Engineering , IOSPress, Amsterdam, Vol.
15 , No.
4, 351-367, 2008.Fellbaum, C. and Miller, G. 1988.
(eds) WordNet.
TheMIT Press.Krachina, O., Raskin, V. 2006.
Ontology-Based Infer-ence Methods.
CERIAS TR 2006-76, 6 p.Lafourcade, M. 2007.
Making people play for Lex-ical Acquisition.
In Proc.
SNLP 2007, 7th Sym-posium on Natural Language Processing.
Pattaya,Thailande, 13-15 December.
8 p.Lafourcade, M., Joubert, A.
2012.
Long Tail inWeighted Lexical Networks.
In proc of Cogni-tive Aspects of the Lexicon (CogAlex-III), COLING,Mumbai, India, December 2012.Lieberman, H, Smith, D. A and Teeters, A 2007.Common consensus: a web-based game for col-lecting commonsense goals.
In Proc.
of IUI,Hawaii,2007.12 p .Marchetti, A and Tesconi, M and Ronzano, F andMosella, M and Minutoli, S. 2007.
SemKey: A Se-mantic Collaborative Tagging System.
in Procs ofWWW2007, Banff, Canada.
9 p.Mihalcea, R and Chklovski, T. 2003.
Open MindWordExpert: Creating large annotated data collectionswith web users help..
In Proceedings of the EACL2003, Workshop on Linguistically Annotated Cor-pora (LINC).
10 p.Miller, G.A.
and Beckwith, R. and Fellbaum, C. andGross, D. and Miller, K.J.
1990.
Introduction toWordNet: an on-line lexical database.
Interna-tional Journal of Lexicography.
Volume 3, p 235-244.Navigli, R and Ponzetto, S. 2010.
BabelNet: Build-ing a very large multilingual semantic network.
inProceedings of the 48th Annual Meeting of the As-sociation for Computational Linguistics, Uppsala,Sweden, 11-16 July 2010.p 216-225.Sagot, B. and Fier, D. 2010.
Construction d?un word-net libre du fran?ais ?
partir de ressources multi-lingues.
in Proceedings of TALN 2008, Avignon,France, 2008.12 p.Sajous, F., Navarro, E., Gaume, B,.
Pr?vot, L. andChudy, Y.
2013.
Semi-Automatic Enrichment ofCrowdsourced Synonymy Networks: The WISIG-OTH system applied to Wiktionary.
Language Re-sources & Evaluation, 47(1), pp.
63-96.Siorpaes, K. and Hepp, M. 2008.
Games with a Pur-pose for the Semantic Web.
in IEEE Intelligent Sys-tems, number 3, volume 23.p 50-60.Snow, R. Jurafsky, D., Y.
Ng., A.
2006.
Semantic tax-onomy induction from heterogenous evidence.
inProceedings of COLING/ACL 2006, 8 p.Thaler, S and Siorpaes, K and Simperl, E. and Hofer,C.
2011.
A Survey on Games for Knowledge Acqui-sition.
STI Technical Report, May 2011.19 p.Velardi, P. Navigli, R. Cucchiarelli, A. Neri, F. 2006.Evaluation of OntoLearn, a methodology for Auto-matic Learning of Ontologies.
in Ontology Learn-ing and Population, Paul Buitelaar Philipp Cim-miano and Bernardo Magnini Editors, IOS press2006).Vossen, P. 2011.
EuroWordNet: a multilingualdatabase with lexical semantic networks.
KluwerAcademic Publishers.Norwell, MA, USA.200 p.Zeichner, N., Berant J., and Dagan I.
2012.
Crowd-sourcing Inference-Rule Evaluation.
in proc of ACL2012 (short papers).182
