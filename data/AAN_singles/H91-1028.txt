FIELD TEST EVALUATIONS andOPTIMIZATION of SPEAKER INDEPENDENTSPEECH RECOGNIT ION for TELEPHONE APPLICATIONSChristian GA GNOULET and Christel SORINCNET D6pt RCP 22301 LANNION-FranceABSTRACTThis paper presents, in a first part, the detailed results ofseveral field evaluations of the CNET speakerindependent speech recognition system in a context of 2voice-activatedservers accessible by the general Frenchpublic over the telephone.
The analysis of roughly l l  000user's tokens indicates that the rejection of incorrect inputis a major problem and that the gap between therecognition rates observed in real use conditions and inthe most "realistic" laboratory tests remains very large.The second part of the paper describes the currentimprovements of the system : better ejection procedures,enhancement of the recognition performances resultingfrom both the introduction of field data in the trainingdata and the increase of the number of parameters,automatic adjustments of the HMM topology allowing toeither reduce overall model complexity or improverecognition performance.
Tested on long distancetelep.hone databases (450 to 750 speakers), the currentversion of the CNET recognition system yields alaboratory error rate of 0.7 % on the 10 French digits andof 0.95 % on a 36 word vocabulary.INTRODUCTIONAt CNET, the speech recognition studies are specificallyoriented toward the development of telecommunicationsapplications.
This implies the development of robust,speaker independent speech recognition systems but alsothe design and the evaluation of complete spokendialogue systems, for which human factor studies areessential.SYSTEM OVERVIEW and FIELD TESTEVALUATIONSSystem overviewThe connected speech recognition algorithm developed atCNET in 1986 \[1\] uses the HMM approach and has beenimplemented on several devices (RDP 20 and RDP 50boards) \[2\].
In the implemented version of the algorithm,6 Mel cepstral coefficients, the energy and its derivativeare computed every 16 ms to obtain the input vectors.The observation probabilities are represented by gaussianfunctions with diagonal covariance matrices and are tiedto the transitions of the Markov chains.
Various kinds ofmodellinlg can be implemented : either word units or sub-word units such as phonemes, diphones or allophones.For each application, the network is fully compiled andincludes imtial and final silence models for each word.This system has been tested on several databases ofisolated and connected words recorded over thetelephone network with willing subjects (mainly longdistance lines, speakers representing different regionalaccents) : DIGITS-1 (455 speakers, 10 French digits),NUMBERS (730 speakers, 00...99 in French), TREGOR(513 speakers, 36 French words).
For each database, onehalf of the data was used for training, the other half fortesting.
Using word models, the obtained word error rates(for the first version of the system) were 2 .1% forDIGITS-l, 2.7 % for TREGOR and 9.6 % forNUMBERS.Field test evaluationsExperimental server" MAIRIE-VOXIn 1988, an experimental, one-port voice interactivesystem, MAIRIEVOX \[3\], was built on a PC computerusing the RDP 50 board (word models, 13 states/word, 3~gaussian pdfs per state).
Designed to give variouslnformations about local services around the city ofLannion (20 000 inhabitants), MAIRIEVOX is accessibleby the general public over the telephone since mid-88.The input interface for the user is restricted to voice inputwithout any keypad complementary command.
A treestructure is used to access information.
The completevocabulary contains 21 words (extracted from the 36words TREGOR data-base) but the dialogue modulelimits the active vocabulary to 6 words at each step.Since that time, MAIRIEVOX has been the subject ofseveral field trials allowing to identify its critical pointsand to substantially improve both the speech recognitionperformances and the acceptability of the service.The first evaluations (during which the input signal wasnot recorded) mainly allowed to improve the ergonomy ofthe service.
For example, it appeared extremely usefull toauthorize the recognition of the speech commands duringthe delivery of the voice messages : this allows the regularusers of the service to anticipate the commands andtherefore to quickly reach the required information in thedialog.ue-tree.
An echo-cancellation procedure (nonrecurswe filter with a 8 ms window) was thus introducedon the speech recognition board.
The dialogue strategywas also modified to take into account he necessity ofrecovering from the largest part of recognition errors("confirmation" procedures with Yes/No commands incase of recognition difficulties).
With these two mainimprovements, the acceptability of the isolated-word,160menu-driven speech command server has beendemonstrated (less than 10 % failure in the access to therequested informations).During 1990, a new set of evaluations has been done :roughly 4600 voice inputs (corresponding to 340telephone calls) were systematically recorded, listened toand labelled as "correct inputs" (55.5 %), '~ncorrect speech inputs" (i.e.
non permitted by the dialogue) (17.8 %) and'gto/se" (26.7 %).From the application point of view, the rejection ofincorrect inputs appears therefore to be a crucialpoint :despite clear instructions to the caller, roughly 45% ofthe inputs to MAIRIEVOX are incorrect (words outsidethe vocabulary or noise).
The simple rejection procedureused in MAIRIEVOX (all the vocabulary words arecandidates at any time even if the dialogue module filtersthe words which are not valid in the context, use of asimple duration-based rejection threshold) allowed tol!mtt the false rejection error rate to roughly 10 %('correct inputs").
For incorrect inputs, 82 % are corectlyrejected but 18 % induce an error (false acceptance).From the recognition point of view ("correct inputs" only),we observed a 12.2 % error rate (21 valid words), 36 % ofwhich being due to bad end point detection (truncatedwords).
On the other hand, contrary to previousobservations, the need for modelling hesitauons (orsurrounding speech) didn't really appear to be crucial :less than 5 % of the speech inputs contain hesitations orsupplementary words (the design of the dialogue seems toplay an essential role in this phonemenons).Industrial Server "Horoscope"A commercial voice-activated server "HOROSCOPE" wasoperating since April 1990 over the 9 taxation areas of theFrench telephone network.
Based on the samerecognition technology as MAIRIEVOX, it involves therecognition of the 12 horoscope signs spoken in anisolated manner.
The calling person had the ability to askfor a horoscope sign at any time (branching factor of 12),any number of times, by waiting for the end of a messageplayback, or by interrupting it.
The very direct dialogueprocedure prevented the use of any dialogue-drivenrejection process (contrary to MAIRIEVOX).During June 1990, 6446 tokens from 1724 calls \[4\] wererecorded, listened to and labelled as "correct speech inputs" (73 %), "incorrect speech inputs" (speech without ai~!
a"rbe~woelr~ls~nWo~i~!g b'('l ep5mro~?m mn~ s~i~ n(?~2e~Pf ~ ~ct~ ~c~speech" inputs contain hesitations or supplementarywords.The lack of perfect noise/speech discrimination i  theendpoint detector aggravates the problem, as alreadyobserved for MAIRIEVOX : from the 27.1% word errorrate observed on "correct inputs", roughly 50 % are due tobad endpoint detection.
The very low recognition scoreobserved here results from 3 main short comings in therealisation of this industrial system : 1) only 1gaussian/state was used in the 13 state word models, 2)only 150 speakers were used for training the models, 3)the implemented echo-cancellation procedure was a verysimplified version of the procedure proposed by CNET (a10 dB difference was observed between the 2 attenuationrates).In conclusion, after assessing two general-public word-recognition applications in use over the French telephonenetwork, it was found that, despite clear instructions tothe caller, a considerable proportion of the input liesoutside the permitted vocabulary.
These extraneousinputs are either incorrect speech tokens or non-speechtokens for which the caller is not always responsible(DTMF dialing, line bursts, outside noise etc...).
There istherefore an urgent need for efficient rejectionprocedures.
Moreover, the gap between the recognitionerror rates observed in real use conditions and in thelaboratory tests is very large : a multiplicative factor of 3-4is observed ; it can reach 10 if the application is carelesslydesigned and modelized !...NEW REJECTION PROCEDURESTwo rejection procedures \[5\] have been investigated andcompared on the "HOROSCOPE" field databasecontaining all the "correct" and "extraneous" tokensrecorded during the "Horoscope" field trials, to whichwere added 1699 tokens from 151 willing subjectsrecorded through the telephone network.
Half of the datawas used for training, the other half for testing.The first rejection procedure uses 3 sink models trainedwith the "extraneous" tokens (incorrect or noise inputs) ofthe training corpus and imposes thresholds on word-model scoring : the rejection threshold is applied on a '~orrected score" which is the word HMM score minus thecontribution of the silence models.The second rejection procedure operates on the "trace" ofthe HMM (i.e.
informations on the optimal Viterbi path).It involves the extraction of the HMM trace from a giveninput token and the classification of this trace into"acceptance" or "rejection" by a multi-layer perceptron(MLP).
This rejection procedure is independent from therecognition process : it uses HMMs designed with the solepurpose of producing informative traces.For the '?race" rejection procedure, the best results wereobtained with a trace containing 1) the number of framesobserved per gaussian, 2) the average nergy coefficientand 3) the average first Mel frequency coefficient of theframes observed per gaussian, i.e.
with a trace exhibitingboth a duration and a signal representation.The results of both procedures are illustrated on Figure 1where the sum of the SE rate and the FR rate measuresperformance on correct tokens and the FA rate measuresperformance on extraneous tokens.SE rate =number of substitution errorsnumber of correct okensFR rate =number of false rejectionnumber of correct okensFA rate =number of false acceptancenumber of extraneous tokens161+\[ ' ++"03 : , ,  ~ !
+ ~ ~ i i i i i i i25 ........... + .
.
.
.
.
.
.
+++l'''' t IIp+''~ 111 "" @ ........................ { ................................ + ........... + ......... ll''ll+''+4411"'t .....k .
.
.
_ .
:?J + + + o~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
i .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.+ .
.
-  .+ .
.
.
.
- .+  .
.
.
.
.?
?
.
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
.
.
.
.
.+  " i , .
.
.
.+ .
.
.
.
, - :  .
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
t .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.  }
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.+ .
.
.
.
.~  .
.
.
.
.+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
+ .
.
.
.
.
.
.
.
.
.
.
.
.
.,+  .......... ........... i .................. + .............. + ........... + ......... i + + ..... i ~ 1 : i " , k  : i i ~ : : :o : !
: : : '  ' : : ; : : : : :?
i !
\[ i i i : + i + + + +, o  .
.
.
.
.
.
.
.
.
.
i ......... 1 .
.
.+-+.
.++ ............. !
........... + .................. + ' -+  ......... + .
.
.++~ ..... ++ ......... iiiii+ ii!
!i +++: \[ \[ : : .
.
.
.
.
.
.
.
: .
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.+ ,=f0 12 14 18 l$  20 2S 30 40 SO 80 70 80 90 100% er ror  ra te  on  cor rec t  tokens  (SE+FR)Figure 1 :Rejection using the HMM trace (full curve) and rejectionusing sink models and a score threshold (dashed curve)Although the performances of both procedures appears tobe simdar within the confidence interval, there is oneaspect unique to the rejection by trace ."
its ability to rejecta large proportion of the substitution errors instead ofproposing them to the user (substitution rejection errorrate of 66 %).Work is currently underway to refine the trace-basedprocedure.
Another promising direction seems to be tocombine this two complementary methods.RECOGNITION OPTIMIZATIONSUse of field data in HMM trainingThe constant gap between the recognition rates observedin real use conditions and in the laboratory tests led us toinvestigate the introduction of field data in the trainingdatabase to see if it can significantly improve therecognition performances.In this experiment \[6\], 2 sets of a telephone-speechdatabase corresponding to the 21 word vocabulary of theMAIRIEVOX server have been used :- a "LABoratory database" corresponding toa subset of theTREGOR database : 513 willing subjects, 9797 uniformlydistributed tokens,- an "EXPloitation database" corresponding to anextension of the previously introduced field database :1547 naive speakers (real users) produced 9536 "correcttokens", non uniformly distributed among the 21 words.Both databases exclusively hold manually validated ata,i.e.
data labelled as "perfect" (non truncated and withouthesitations or supplementary words) after listening.
Eachdatabase was spht into two equal parts : one for training,the other one for testing.The training of the HMM word models was done eitheron the LAB database, on the EXP database or on aMIXed database containing an equal proportion oflaboratory and field data.
The results are illustrated ontable 1 (word error rate).LAB test EXP testdatabase databaseLAB models 2.3 % \[ + 0.4\] 5.8 % \[ + 0.7\]EXP models 9.8 % \[ + 0.8\] 4.4 % \[ + 0.6\]MIX models 3.6 % \[ + 0.5\] 3.9 % \[ + 0.5\]Table 1 :Word error rate for a 21 word vocabulary (long distancetelephone speech) : influence of "field" data introduced intrainingIt can be seen that the use of "MiXed" models leads to a30 % reduction of the recognition error rate on the fielddatabases : the introduction of field data in the trainingphase does improve the field recognition performances.Work is currently underway for achieving on-lineselection of the "correct" field data to be introduced in a'~'etraining" phase of systems in exploitation.Increasing the number of parametersSeveral studies have shown the usefulness of adding time-de..pendent information in the HMM input vectors.
Table2 illustrates the results of various tests on the DIGITS-1data base (455 speakers) using input vectors containingeither 9 acoustic oefficients (8 MFCC and energy), 18acoustic oefficients (the same as above plus their firstderivative) \[7\] or 27 acoustic coefficients (secondderivative added).It is also well known that increasing the size of the models(i.e.
number of states and pdf's) yields betterperformance, at least for isolated word recognition.Comparative results between 13 state and 30 state wordmodels are shown in Table 2.9 coeff.
18 coeff.
27 coeff.13 states 5.9 % 2.2 % -30 states 3.5 % 1.2 % -41 states' - 1.1% 0.7 %Table 2 :Word error rate on the DIGITS-1 telephone speech data-base (455 speakers) : influence of the number of acousticcoefficients and states(* 775 speakers database)162The new version of the recognition algorithmimplemented on the RDP 50 board (TMS 320C25) yieldsan error rate of 0.69 % (4I state word models, 27 acousticcoefficients) on an expanded version of the long distancetelephone DIGITS database (775 speakers) and of 0.95 %(18 acoustic oefficients, word model size depending ofthe word length) for the TREGOR long distancetelephone database (36 words, 513 speakers).Automatic adjustments of the structure of HMMmodelsUsing whole word basic units is generally a good choicefor small vocabulary isolated word recognition, andincreasing the size of the models usually leads to betterperformance.
However, this also increases thecomputation time, due to the number of observationrobabilities (gaussian functions) that must be computedr each frame.
Thus, in order to use the best possiblemodel in real time industrial devices, it was usefull toinvestigate the possibility of reducing the number ofgaussian functions by clustering "similar" pdf's.
This wasdone by iteratively merging the 2 gaussian pdf's inducingthe smallest decrease of the total probability of thetraining observations, until the desired number of pdfs isreached \[8\].
On the 36 word TREGOR database, thisprocedure allowed to reduce b}, 40 % the number ofgaussian functions while keeping Identical performances.Using sub-word basic units leads to more compact models(since all the occurrences of a given unit share the sameset of pdf's), but it is difficult to increase the a priori sizeof the acoustical models (they may become too long).
Analgorithm has thus been developped \[8\] around the twofollowing basic ideas : splitting the pdfs having thehighest contribution to the probability of the trainingdata, and discarding the transitions which are scarcelyused.
These two operators (splitting and discarding) areapplied successively, and the model is re-trained aftereach modification.
By applying this procedure on apseudo-diphone based model \[I\], the recognition errorrate has been reduced from 2.5 % to 1.8 % on the 36word TREGOR telephone database used above;CONCLUSIONExhaustive analysis of field trials allowed to betteridentify the most crucial shortcomings of the speechrecognition systems developed in the laboratory and tosubstantially improve both the speech recognitionperformance and the acceptability of the resultingservices.
From our experience, it appears that both therejection of incorrect inputs and the noise-speech end-point detection are among the most crucial problems.A new reiection procedure has been presented which stillrequires turther efinements.
Introducing field data in thetraining database proves to be an efficient procedure forrapidly improving the performances of systems that canbe re-trained uring their exploitation.
Recognition scoreimprovements were obtained by increasing the number ofacoustic coefficients and HMM model parameters.Finally, dynamic adjustments of the structure of Markovmodels allowed to either reduce the overall modelcomplexity (a crucial point for industrial implemen-tations) or improve the recognition performanceespecially for larger vocabularies where the use of sub-word basic units becomes necessary.ACKNOWLEDGMENTSThe authors would like to gratefully acknowledge all themembers of the Speech Recognition and Voice ServicesGroups : Jean Monn6, Denis Jouvet, Michel Toularhoat,Katarina Bartkova, Dominique Dubois, Patrick Haffner,Guy Mercier, Laurent Miclet, Gaby Gargan, JacquesR6jaud, Luc Mathan, Laurent Mauuary, DominiqueMorin, for their participation to the work reported here.REFERENCES\[1\] D. JOUVET, J. MONNE, D. DUBOIS (1986) : "Anew network-based speaker independent connected wordrecognition system", Proc.
IEEE/ICASSP 86, 1109-1112.\[2\] J.P. TUBACH, C. GAGNOULET, J.L GAUVAIN(1989) :"Advances in speech recognition products fromi t  France, Proc.
SPEECH TECH 89.\[3\] C. GAGNOULET, D. JOUVET, J. DAMAY (1991) :"MAIRIEVOX : a voice activated information system",Speech Communication, Vol 10, N ?
1.\[4\] L. MATHAN, D. MORIN (1991) :"Speech fielddatabases : development and analysis", submitted toEUROSPEECH Conf., Genova, sept. 91.\[5\] L. MATHAN, L. MICLET (1991) : "Rejection in anisolated word ASR system using multi-layer perceptronsand the trace of HMMs", to appear in Proc.IEEE/ICASSP 91.\[6\] D. MORIN (1991) : "Influence of field data in HMMtraining for a voice-activated telephone server, submittedto EUROSPEECH Conf., Genova, sept. 91.\[7\] D. DUBOIS (1991) : "Comparison of time-dependentacoustic features for a speaker-independent speechrecognition system", submitted to EUROSPEECH Conf.,Genova, sept.
91.!8\] D. JOUVET, L. MAUUARY, J. MONNE (1990) :'Automatic adjustments of the Markov models topologyfor speech recognition applications over the telephone",NATO/ASI Workshop, Cetraro, July 1-13 (to appear).163
