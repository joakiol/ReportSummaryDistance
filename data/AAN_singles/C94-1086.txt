REFERRING TO WORLD OBJECTS WITH TEXT AND P ICTURESElisabcth Andr6, Thomas RistGcrman Research Center for Artificial Intelligence (DFKI)D-66123 Saarbriickcn, Germany, c-mail: {andre, fist} @dfki.uni-sb.dcABSTRACT: It oftcn makes sense to employ both textand pictures wheu referring to world objects.
In this pa-per, we present a model for referring which is based onthe assumption that concepts may be activated not only byIcxt, but also by pictures and tcxt-pieturc combiniltious.
Bymeans of a case study, we demouslrale that l'ailure aml suc-cess of referring acts can be cxplalncd by thc user's abilityto infer ccrtaiu links between mental representations andobject descriptions.
Finally, we show how the model hasbeen incorporated into a plan-t)ased multimedia prcseata-tion system by defiaiug operators lk)r concept activation.1 INTRODUCTIONFrom a speech act theoretical point of view, referring is aplanncd action to achicve certalu go:ds (Appclt aud Kroa-fold, 1987).
Although natur~ language may be the mostconventional vehicle for referring, it has been widely ac-ccpted that pictures cau be used ~s well.
For example,Goodmann (1969) points out that pictures can be cmploycdto refer to both an individual object and the type of whichan objcct is an exemplary of.
Morcovcr, there arc goodreasons to include pictures in refcrring acts.
l'icturcs ef-fectively convey discriminating object properties uch assurface atlributes and shape.
If au object can only be dis-criminated against alternatives through ils location, a pic-ture may provide the spatted context of the object.
Sincedepictions arc explicit material representations of the worldobjects to which they correspond, new attributes of the type'being dcpicted as ...' arc iutroducc(l which, in ttlrn, pro-vide an additiomd source for object discriminatiou (e.g.,the knob which is reprcscnlcd by thc black circle ...).
Lastbut not least, several graphical focusing tcchniqucs can bcapplied to effcctivcly constraiu the set of alternatives (c.g.,arrows, blinking).
Unfortunately, there is also a dark sideof the picture.
An obvious drawback is that pictures donot provide for syutactical devices to distinguish betweena reference-specifying and a predication-specifying partsince objects and their properties are hardly separable oncedepict "cd.
Auothcr difliculty is that pictures lack the meansto distinguish deliuitc from indefinite descriptions.
Thus, itmay remain unclear whcthcr a particular object or whether~m ,-u-biUzu-y exemplary of a class is depicted.
The conclu-sion we can draw from these considerations is that it oftenmakes sensc to employ bofll text lind pictures when rcfcr-riug to domain objects.
Pictures may be used in order tosimplify verbal reference xpressions.
On the other hand,ambiguitics of pictures cau be rcsolvcd by providing addi-tional information throngh text.
When an~dyzing illustrateddocumeuls uch as assembly matmals and iustructions foruse, diffcrcnt kinds of rcfcrring expression can be found:Multimedia referring expressions rcfcr to world objectsvia a combination of at least wo media.
:Each medium con-vcys somc discriminatlug attributcs which in sum ,allow fora proper identification of the intended object.
Examples ~ueNL expressions that are accompanied by pointing esturesand text-picture combinations where the picture providesinformation about he appe~u'ance of au object mid the textrestricts the visual search space as in "the switch on thefrontsidc".Anaphoric referring expressions refer to world objects inan abbreviated form (llirst, 1981) presuming that they arealready explicitly or implicitly introduced in the discourse.Thc presentation part to which ,-m anaphoric expressionrefers back is called the antecedent of the referring expres-sion.
In a multimedia discourse, we have not only to h,'mdlelinguistic anaphora with linguistic antecedents, but also lin-guistic anaphora with pictorial antecedents, mid pictorialanaphora with linguistic or pictorial m~tecedents.
Ex,'un-pies, such as "the hatched switch," show that the boundarybctwcen multimedia referring expressions and ,'maphora isindistinct, llere, we have to consider whether the user isintended to employ all parts of a presentation for object dis-ambiguation or whethcr one wants him to infer anaphoricrclations bctwcen them.Cross-media referring expressions do not refcr to worldobjects, but to document parts in other prcscnultiou mcdia(Wahlslcr et at., 1991).
Examples of cross-media referringexpressious are "the upper left comer of the picture" or"Fig.
x".
in most c,'tses, cross-media referring cxprc,ssionsare part of a complex multimedia referring expresssiouwhere they serve to direct he rc~lder's attention to part.s ofa document that has ,also to be employed in order to findthe intended referent.When viewing referring as a planned action, we have tospecify which goals uuderly the use of different ypes ofreferring expressions.
Appelt ,'rod Kronfeld (1987) distin-guish between the literal goal and the discourse purposeof a refcrence act.
Wherc~ls the literal goal is to establishmutuld belief between a speaker and a hearer that a partic-ular object is being talked about, the discourse purpose isto make the hearer ecognize what kind of identification isappropriate and to have him identify the referent accord-ingly.
When addressing illustrated ocmncnts, the questionarises of what idcutification means when domain objectsare referred to via pictures (,'rod text).
As with h'mguagethis varies from discourse to discourse.
For exmnple, ifthe user is confronted with a picture showiug how to insertthe filter of a coffee machine, he has to recognize whether530SystembelievesPigurc(llas-position rl s pl s)(Temperature-control rl_s)(llas-position r3_.s p3s)(Onhfff switch r3s)(Corcfrl_s rl u)(Corcfrl s r230(Corefr3_s r3 u)(Corcf r3 s r4.u)SystembelievesWsel"believes(this-position rl_u pl_u)(Teml)cr ature-control r2u)(Ilas-position r3 u p3 u)(On/off-swilch r4u)iC)r (ArM (Corcf x'l u r2u)(Corer r3 t, l~- u))(Aqd (Coref rl u r4 u)(Corer r3 u r2_u)))I: Modell ing Example: I)iffl:renl Knowledge Concerning the Identity of Objectsany object with the feature 'being a liltcr' can be insertedor whctlter a particular object is lUCallt.
Ill the first case,he has to idenlify the piclurc t)l~,jccl as all cxemphuy of acertain class whereas, ill tile second case, hc has to look forsomethiug in lhe workl which tits the graphical depiction.lu other siluations, )dentil)cation involves establishing akind of cohesive link between doeluneut parts.
If Ihe useris coufrouled with a sequeuce of pictures showing an ob-ject lmm different angles, he has to recognize that in allpictures the same ol~jcct is depicted (pictorial anaphor withpictorial anlecedent).
When re:aliug an utterance, such as"the resistor in the ligurc above," he has to recognize auanaphoric rchttionship between the textual closer)p lion andIhc graphical depiclion (linguistic anaphor with pictorialantecet&nt).Previous work on Ihc generation of rclc) ring expressionsin a multimedia cnvirotuncnt has mainly cotlcclltrated Oilsingle refercnce phenomena, such as references to pictorialmaterial via natural language and pointing gestures (Allogayer et al, 1989; C.laasseu, 1992; Stock el al., 1993) andthe generation of cross-media references lrom text to grlqfl>ics (McKcown ct al., 1992; Wahlster ct al., 1993).
The aimof this paper is, however, to provide a more general modelIha!
explains which kinds of corcferculial link bctweeu re-ferring expressions, objects of the world :rod ol2iccts of themultimedia preseutalion have Io be established to ensurerite coutpreheusibility of at rclcrring expression.2 A MODEl ,  F()R RI,.3,'ER1UN(; WIT I I  TEXT ANDPICTURI' ;SWhen referring to domain objects a presentation system h;tsto lind intelligible object descriptions which will activateaplnOl~riate represcutations.
We assume thai reprcscnla-lions can be act)wiled in the sense of picking them outof a set of representations which arc already available orwhich have to be built lip (c.g., by localiziug an object ina user's visual licld).
Rcprcscnlations can bc act)wiled bytextual descriptions, by graphical descriptions or by mixeddescriptions.
Whereas the order in which representationsare activated by a text is ittlhmtlccd by the discourse struc-ture, it is less than clear ill which order a picture activatesrepresentations.
If scvcral objects are depictcd, the conc-SlXmding rcprescntatious may be activated simultaneously.2.1 Rcprcsenlations of World ()bjeclsqb ensure tile transferal))lily of our al)pmach, wc don'tpresuppose a cer|aill kllowledge representation language.l\[owcvcl, iu\] essential part of the model concerns file dis-tinct)on between the system's belicl\s about the world andthe system's beliefs about the user's beliefs.
We representthese beliefs ill different models.
For example, the systemmay classify a cert:du object )ks ml espresso machine whileit asstllUeS tile user regards tile object as a coffee machine.l:urtherniore, we have to COllsider that the user's alld thesystem's beliefs al?mt the identity of objects may differ.The system may bclicve that the user has different repre-sentations for ouc and tile.
salne object without knowinghow they arc rclattxl to each other.
Conversely, it may hap-pen that the user is assumed to have only one representationfor objccls which tile systeln considers as distinct entities.As a coascquence, our models can coutaiu dill'ereut rcpre-seutaliolls for one and the sanle world object.
We use tilepredicate(Corer IW~I rep2)I0 c, XplCSs thai rep 1 and rep2 arc representations of the stuneworld object.Fig.
1 gives an example of how to use the concepts intro-duced above, l.ct's start li'om the bil lowing situation takenfrom an espresso machine d/mudu: "lain system knows that|here are two switches (the temperature coutrol and tileon/off switch) and also knows where they m'e k~cated.
1.etrl_s mid r3_s corrcspoud to lhe system's internal rcprcscmrations of the switches.
The user is assumed to look at theespresso machine aud to see two switches.
Let rl_u andr3_u corresl?md to iutenml reprcscnlatious of the switcheswhich Ihe user builds up when looking at tim machine.
Weassume that tile user idso knows of the existeuce of theon/off switch and file temperature control, but is not ableto localize them.
l.et r2_u and r4_u be the user's represen-tations for tile temperature control and the on/off switch.
"l lie fact that he o)lly knows that one of tile switches lie sccsmust be the temperature control and the other file on/oi lswitch can be expressed by metals of a disjunction.
Eithera corer ,elation holds between rl_u and r2_u and betweenr3_u aud r4_u or conversely, between rl_u and r4_u and be~twecu r3_u and r2_u.
The couucctiou between the system'srcprcscnlations rl_s and r3_s to tim rcpresentalious tile useris assumed to have.
is also expressed by corelizreuce rela-tions.2.2 Reln'esent:dion of DescriptionsAs nmntioncd ill section 1, descriptions can be co;nlx)stal531of text, graphics mid further presenUUion media.
To copewith such descriptions, we associate with each syntacticalunit (depictions, noun phrases, etc.)
the set of objcct rcp-reseutations which will be activated by that particular part.The referent of tile whole description is then consideredas a member of thc intersection of all sets resulting frompartial descriptions.An important prerequisite of our approach is that thesystem explicitly represents how it has encoded in formationin a presentation.
Inspired by (Mackinlay, 1986), we use arelation tuplc of tim form:(Encodes nwans itlformation context-slmce)to specify tim semantic relationship Imtwccn a textual orgraphical means, and tim inh)rmatiou tim means is to con-vey in a cerladn context space.
In our approach, the thirdargulnent refers to tile context space to which the encod-ing relation corresponds R~ and not to a graphical languageas in Mackinlay's al~proach.
This enables us to use oneand the same presentation means differently in differentcontext spaces.
For example, a depiction of an csprcssomachine may refer to an individual machine in one contextspace, but may serve as a prototypical representative ofan espresso machine in mmthcr.
In addition, we not onlyspecify encoding relations bctwccn individual objccls, but~dso specify encoding relations on a generic level (e.g., thattile property of being red in a picture ncodes tile propertyof being defect iu tile world).While it can be assumed that a user reads a text in se-queutial order, it is often not clear at which times a userlooks at a picture.
ThercR)re, it makes not ,'always ense tofurther distinguish between an mlaphor and its antecedent.Fortunately, our approach does not require identi lying partsof a presentation as anaphora nd antecedents.
It sufficesto recognize which parts of a description ~u'e intended toencode a uniquely determined object.
~Ib express uch co-hesive relationships between presentation parts p 1 and p2,we define the predicate:(EncodesSame pl p2 c) : =(Exists w (And (Encodes pl w c) (Encodes 1)2 w c)(Forall v (Implies (Or (Encodes p lv  c) (Encodes p2 v c))(Coref w v)))))The first part of this dcfiuition expresses that there existsan object w thai pl and p2 encode in tile context space cwhile the second part means that this object w is uniquelydetermined.2.3 Links between Representations and DescriptionsIn uuderstanding a referring expression, the user has torecognize certain links between actiwttcd mental represen-tations, between descriptions and mental representations,and between textual and graphic,'d parts of dcscriptions.Which links are present in a description and which have tobe inferred varies from sifimtiou to situation.
To illustratethis, let's have a look at a case study carried ot, t in ourespresso machine domaiu where text-picture combinationsare used to explain how to operate an espresso machiuc.
Weassume that tile user is rexlUested to tunl the temperaturecontrol of an espresso machine.
In this case, identificationmeans actiwtting a representation the user builds up whenlocalizing the referent in his visual field.
Furthermore, wepresume tile user knowledge of the espresso machine asin Scction 2.1; i.e., file user knows of the existence of tileon/off~ and the temperature control, has visual access totile two switches in the world but is not able to tell themapart.
In the diagrams below, we use the abbreviations ES,C aud E for die relations EncodesSame, Coref and Eucodesrespectively.In tile document fragment shown in Fig.
2, the tex-tual rcfcrcncc expression uniquely determines a referent,but activates a reprcscutation (r2_u) which docsn't containany information to localize rile referent.
Colwersely, therepresentations activated by tim picture contain locative in-formation, but here we have the problem that several objcctrepresentations arcactivated to tile siune extent.
Since onlythe prope,ty of being a switch, but not tile property of be-ing a temperature control is conveyed by the picture, bothswitch depictions become possible as antecedents of thetextual referring expression.?
?lhetemperal.re ~ E ~controlFigure 2: Missing Cohesive Liuk between Text and PictureIn Fig.
3, tile verbal descriptiou discriminates tim refer-ent from its alternatives by attributes of the world object,umncly 'being a switch', and 'being depicted in tile figure'and an attribute of the depiction, namely 'being dark'.
But,in contrast to tim previous example, only one of the repre-sentations activated by the picture fits tim verbal descrip-lion.
"llius, the user should be able to discover the anaphoriclink between the verbal description and the graphical de-piction and activate an appropriate r presentation.the dark switch '.~ r2~uFigure 3: Establishing a Cohesive Liuk by IncorporatingPicture Attributes in Vcrbal DescriptionsIn tile previous example, an anaphoric link between textand picture has been established by including pictorial at-tributes in the vcrbal descriptiou.
All altcrnative is to applygraphical focusing tcclmiqucs ,as in Fig.
4.
Ilere, it's vcrylikely that the user will be able to draw a link betweentext mid picture because he will assume that the pictorial,'rod the textual focus cx)incide.
This ex~unple also illus-trates how tile user's knowledge of rile identity of objectscml be enriched by means of a referring act.
The verbal532descripthm without he graphics and tim graphical dcpic-thin witimut the text actiwtte different reprcseatalions oftim switch.
When coasidering bolh text and graphics, timuser will conclude timt they refer to tile same object.
Thus,he is not only able to identify tim switch ,as required, heis ,also able to combine tim different representations of tileswitch into one.
Note that this phenomenon cm~ ~dso beexplained in tcnns of centering tiltx)ry (Gmsz et ~d., 1983).In tim example, tim prcferrcd center of tim picture wouhlcoincide with the backward looking center of tim text.O I .
, ' tTtlrn the tclluleralure Ihe ;control clockwise.
/ tern ~erat,re ~ '" *.,-.- \[ r2 u )Figure 4: F.slablishiag a Cohesive IAnk by Correlaling%xtu~d aud Pictorial Focusqhe example shown in Fig.
5 differs from the previousones in that ao corrcspondency link between picture objectsand real world objects can be established.
Although the useris able to draw an anaphoric link between the verbal audtim pictorial description, he is not able to visually identifythe intended referent.l 'r|lrll |he |r, lllplt!r~|tllrt!
COlltrlll clockwise.
@ '., @fkS I ?the -e 13 ~ t rz .u) telllllerlttllrecontrolFigure 5: Missing Corrcspondency between Picture andWorldSumming up, it can be said that a rcfcrrinp act is onlysuccessful whell tile description provides an access path toan al)l)ropriate represeatation.
"lhe user has to iufcr sucha path li'om encoding relationships and cohesive links be-.twccn tim parts of a description.
As lhc cxamplcs how,tim following cases occur: a) if tile user does nol recog-nize which picture parts correspond to which world object,tim referring act ciflmr fMls (cf.
Fig.
5) or the picturecontributes uolhing to ils success, b) If tim relationshipbetween pictori',d epictions and verbal dcscriptions i un-clear, tim referent can either not bc lound (cf.
Fig.
2) orone of Ihe media has no inllocuce oil refereut identilica-lion.
c) if at graphic~d cpiclion aad a vcrbal tiescriptionacliw|te dill~crent rcprescnlations of one and tile Sallle t)\[) ~ject and Ihe user recognizes not only these links, but :dso alink between tim two presenlatiou parts, he is uot only ableto lind the refcrcnt, but also able to combine tim tliffcrentrep,escntations i to one (cf.
t:ig.
4).3 US ING TILE" MODEL TO GENERATE REFER-R ING EXPRESSIONSIn tim lbllowing, we will sketch how we have integratexltile approach into tim multimcdia presentation system WlP(Wahlstcr et al, 1993).
At tile hcau't of tim WIP system is aprcscnUttion planner that is reslxansible for determining thecontents aad selccti,lg an appropriate medium combination.
"llle presenlatioll planner eceives ~ks input a presentationgoal (e.g., the user should know where a certain switch islocated), it then tries to fiad a presentation strategy whichmalchcs this goal and gencrales a refiue,nent-style plan intim form of a directed acyclic graph (DAG).
This DAGrellecls rellccls lhe proposithmal contents of the potcnti;ddocument paris, Ihe intcntkmal gems behind tim parts aswell as tim rhetoric~d relationships between them, lot de-tails see (Andr6 and Rist, 1993).
While tim top of thepresenlalion plan is a more or less complex presentationgoal (e.g., instrucling tim user in switching on a device),the lowest level is formed by specilications of elementarypresentatioa l sks (e.g., formulating a r~lucst or depictingan object).
These elementary tasks m'e directly forwardcxlto tim mcdium-spccilic generators, currcntly for text (Kil-gel, 1994) aud graphics (Rist, and Andr6, 1992).
"llm contcut of referring expressions i determined byIhe presentation planucr Ihat Mso decides which represen-tations should be actiwttcd and which medium should bechosen for tiffs.
"lb be able to pcrlbnn these steps, we needpresentation slrategics for linking propositional cts withactivation acts.
An exmnplc of such a strategy is \[1\].\[t\] Ileader: (Request S U (Action ?action)'l~xt)I'.
;lliect: (BMB S U (Goal S (Done U ?action)))Applicability Conditions:(And (Goal S (l)one U ?action))(Bel S (Complex-OF.crating-Action ?action))(Bcl S (Agent ?agent ?action))(Bel S (Object ?object ?action)))Main Acls:(S-Request S l\[J(?action-spec (Agent ?agent-spec) (Object 7object-spec)))Subsidiary Acts:(Activate S U (Action ?action) ?action-spec'li:xt)(Activate S IJ (Agent ?agent) ?agent-spec Text)(Activate S tJ (Object ?object) ?object-spec "l~xt)This strategy can be used to request he user to perfomlan action, h, Ihis strategy, two kinds of act occur: anclcmenlary speech act S(urface)-Rcquest aad three activa-tion acts for specifying tim action mid the scmantic ascroles ;Lssociatcd with tim action (Activate).
The strategyprcscrilx:s text for tile subsidiary acts 'because the result-ing rcfcn'ing expressions (?action-six:c, ?agent-SlrCC and?object-spot) are obligatory c~tse roles of an S-Requestspeech act which will bc conveyexl by tcxt.
For optionalcase roles any medium c;nl be taken.
In addition to strate-gies for linking propositionM aud activation acts, we.
needstrategies lot diffcrcnt kinds of actiwttion mid lot establish-ing Corcf- and l';ncodesSamc-relationships.
For cxmnplc,strategy \[2\] caq be used to aclivale a representation ?r-1by text and to simultaneously enrich the user's knowlex.lge.5,3.3about he identity of objects.
The strategy only applies ifIhcre exists already an image ?pic-obj which encodes 71"-1,the system believes that ?r-1 and ?r-2 are representationsof the same world object and if the system's model of theuser's belicls contains ?r-2.
If the strategy is applied, thesystem a) provides a unique description ?d for ?r-2 (re:finact) mid b) ensures that he user ecognizes that his descrip-tion mid the corresponding image specify the same object(subsidiary act).\[2\] lleader: (Activate S U (?case-t'ole ?r-1) ?d "li~xt)Effect: (BMB S lI (Corer ?r-I '/r~2))Applicability Conditions:(And (BMB 5 U (l';ncodes ?pic-t~bj ?l=l ?c))(Bet S (Corer ?r-I ?r-2))(Bel S (Bel U (Thing ?r-2))))Main Acts:(Provide-Uniqueq)escriptitm .
'; \[ I ?r~2 ?d Text)Subsidiary Acts:(Achieve S(BMB S U (Enct)desSame 7d 7pie-oh ?c)) ?medium)For ~0, we use a discrimination algorithm similar to thealgorithm presented in (Reiter and Dale, 1992).
Ilowev-or, we have investigated a ditional possibilities for distin-guishing objects from their alternatives.
We can refer notonly to features of an object in a scene, but also to tidal ures ofthe graphical model, Ihcir interprclalion ~md to the positionof picture objects within the picture, scc ~dso (Wazinski,1992).
A dclailed description of our discrimination algo-rithm can be found in (Schueiderl0chuer, 1994).
Task b)c,'m bc accomplished by correlating the visu~fl and the tex-tual locus, by redundantly encoding objccl atlribules, orby explicitly informing Ihc user about a Corcf-rclalionship.Such a Corer-relationship can bc established by strategiesfor the gcneration of cross-media rcfcrring exprcssions (asiu "The left switch in lhc ligurc is Ihe lcmpcraturc control")or by slralcgics for annotating objects in a ligurc.4 CONCLUSIONWe h~we presented a model of referring which is based onthe lollowing ~Lssumptions: 1)Ment~d representations ofol2jccts may be activated not only by textural, but "also bygraphicsd and mixed descriptions.
2)Failure ,'rod success ofreferring acts can be expl~fincd by the user's ability to rcc-ognize ccrtain links between Ihcse mcnt~d representations,-rod the corresponding object descriptions.
"lo demonstratethat he model is of praclical use lk)r the gencration ofrcfcr-enccs, we have delinc.d presentation strategies for conceptactivation whidt scrve as operators in the plan-based pre-sentation system WIE WIP is ablc to generate mullimedia,auaphoric attd cross-lncdia referring expressions.ACKNOWLEDGEMENTS: This work is supportcd bythe BMH" under grant lqW8901 8.
Wc would like to thankDoug Appelt lk)r wduable discussions attd comntcnls.REI,'I~I~,ENCESAllgayer, J., llarbusch, K., Kobsa, A., Reddig, C., Rei-thingcl, N. and Schmaucks, D. (1989).
XTt?A: A Natural-l~nguage Access System to Expert Systems.
Intern..lournal of Man-Machine Studies, 31, pp.
161-195,Andr6, E., and Rist, q: (1993).
1"he Design of Illustratedl)ocuments as a Planning Task.
In M.'I: Maybury I~.,hltelligent Multimedia lnterfaces,'lhe MIT Press, MenloPark, pp.
94-116.Appcll, D., and Kronfeld, A.
(1987).
A ComputationalModel of Referring.
1'roe.
of lJCAl-87, pp.
640-647.Cl~msseu, W. (1992).
Generating Re.ferring Expressionsin a Multimodal Environment.
ht R. Dale, E. llovy, D.R6sucr ~utd O.
Stock 1~., Aspects of Automated NaturalLanguage Generation: Proc.
of the 6th InternationalWorkshop on Natural I~tnguage Generation.
Springer,Berlin, pp.
247-262.Goodmau, N. (1969).
L(uzguages ofArt.
Oxlord UniversityPress, Oxford.Grosz, B., Joshi, A.K., and Weinstciu, S. (1983).
Providinga UnifiedAccount of Definite Noun Phrases in Discourse.Proc.
of the 21stACL, pp.
44-50.IIirsl, G. (1981).
Anaphora in Natural Language Umler-standing.
Springer, Berlin.Kilgcr, A.
(1994).
Using U1AGs for htctemental and Par-allel Generation.
Computational lntelligence, to appear.Mackiulay, J.
(1986).
Automating the Design of GraphicalPresentations of Rehttional Infornultion.
ACM Transac-tions on Graphics, 5(2), pp.
110-141.McKeowu, K.R., Feiner, S.K., Robin, J., Seligmaun, D.D.and Tancnbiatt, M. (1992).
Generating Cross-Referencesfi)r Multimedia Exl)ktnation.
Plot.
AAAI-92, pp.
9-16.Reitcr, E., and Dale, R. (1992).
A Fast Algorithm for theGeneration of Referring l?al)ressions.
Proc.
of COLING-92, 1, pp.
232-238.Rist, T., ~md Andr6 (1992).
b)otn Presentation Tasks toPictures: "lbwards an Approach to Autonvatic GraphicsDesign.
Proc.
of ECAI-92, Vienna, Austria, pp.
764-768.Schneiderli3chne~, I:.
(1994).
Generierung von Referen-zausdrficken i einem multimodalen Diskurs.
DiplomaThesis, Universitat des ,Satrlandes, Genmmy, to appear.Stock O., ,'utd the ALFRESCO l'rojcct Tram (1993).
AL-FRESCO: Enjoying the Combination of Natural Lan-guage Processing and tfypermedia for Information Ex-ploration, ht: In M.'I: Maybury Ed., lntelligentMultime-dia lnterfaces,qlm MIT Press, Menlo Park, pp.
197-224.Wahlstc~, W., Andr6, E., Gral, W., ,'rod Rist, T. (1991).Designing Illustrated 7i'xts: How Language ProductionIs h!fluenced by Graphics Generation.
Proc.
of EACL-92, Berlin, pp.
8-14.Wahlster, W., Andr6, E., Finklct, W., Profitlidl, II.J., andRisl, T. (1993).
Plan-Based h~tegration f Natural Lan.guage atzd Graphics Generation.
AI Journal, 63, pp.387-427.Wazinski, I~.
(1992).
Generatitlg Spatial Description forCtvss-modal Referet~ces.
Proc.
of ANLP-92, Treuto,Italy, pp.
56-63,534
