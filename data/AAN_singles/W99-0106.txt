Discourse Structure and Co-Reference: An Empirical StudyDan CristeaDepartment ofComputer ScienceUniversity "A.I.
Cuza"Ia4i, Romaniadcristea @ info iasi.
r@Nancy IdeDepartment of Computer ScienceVassar CollegePoughkeepsie, NY, USAideOcs.vassar.eduDaniel MarcuInformation Sciences Institute andDepartment ofComputer ScienceUniversity of Southern CaliforniaLos Angeles, CA, USAmarcu @ isi.
eduValentin TablanDepartment ofComputer ScienceUniversity "A.I.
Cuza'"la~i, Rom~Lniavalyt@ infoiasi.roAbstractWe compare the potential of two classes of finearand hierarchical models of discourse to determineco-reference links and resolve anaphors.
The com-parison uses a corpus of thirty texts, which weremanually annotated for co-reference'and discoursestructure.1 Introduct ionMost current anaphora resolution systems im-plement a pipeline architecture with three mod-ules CLappin and Leass," 1994; Mitkov, 1997;Kameyama, 1997).1.
A COLLECT module determines a list of poten-tial antecedents (LPA) for each anaphor (pro-noun, definite noun, proper name, etc.)
thathave the potential to resolve it,2.
A FILTER module liminates referees incom-patible with the anaphor f~m the LPA.3.
A PREFEI~NCE module detennm" esthe mostlikely antecedent onthe basis of an Orderingpolicy.In most cases,, the COLLECT module determinesan LPA by enumerating all antecedents in a win-dow of text that pLeced__es the anaphor underscrutiny (Hobbs, 1978; Lappin and Leass, 1994;Mitkov, 1997; Kameyama, 1997; Ge et al, 1998).This window can be as small as two or three sen-tences or as large as the entire preceding text.The FILTER module usually imposes emantic con-straints by requiring that the anaphor and poten-tial antecedents have the same number and gender,that selectional restrictions are obeyed, etc.
ThePREFERENCE module imposes preferences on po-tential antecedents on the basis of their grammati-cal roles, parallelism, frequency, proximity, etc.
Insome cases, anaphora esolution systems implementthese modules explicitly (I-Iobbs, 1978; Lappin andLeass, 1994; Mitkov, 1997; Kameyama, 1997).
Inother cases, these modules are integrated by meansof statistical (Ge et al, 1998) or uncertainty reason-ing techniques (Mitkov, 1997).The fact that current anaphora resolution systemsrely exclusively on the linear nature of texts in Or-der to determine the LPA of an anaphor seems odd,given that several studies have claimed that thereis a strong relation between discourse structure andreference (Sidner, 1981; Gmsz and Sidner, 1986;Grosz et aL, 1995; Fox, 1987; Vonk et al, 1992;Azzam et al, 1998; Hitzeman and P .oesio, 1998).These studies claim, on the one hand, that he use ofreferents in naturally occurring texts imposes con-stmints on the interpretation f discourse; and, onthe other, that the structure of discourse constrainsthe HAs to which anaphors can be resolved.
Theoddness of the situation can be explained by the factthat both groups eem primafacie to be righL Em-pkical experiments studies that employ linear tech-niques for determining the LPAs of anaphom reportrecall and precision anaphora resolution results inthe range of 80% ~in  and I.eass, 1994; Ge et al,1998).
Empirical experiments that investigated therelation between discourse structure and referencealso claim that by exploiting the structure of dis-course one has the potential of determining correctco-referential links for more than 80% of the refer-ential expressions (Fox, 1987; Cristea et al, 1998)although to date, no discourse-based anaphora res-olution system has been implemented.
Since no di-4600000Q00000000000B0000000000000000000000000rect comparison of these two classes of approacheshas been made, ?
it is difficult to determine whichgroup is right, and what method is the best.In this paper, we attempt to fill this gap by em-pirically comparing the potential of linear- and hi-erarchical models of discourse to correctly establishco-referential links in texts, and hence, their poten-tiai to correctly resolve anaphors.
Since it is likelythat both linear- and discourse-based anaphora res-olution systems can implement similar FILTER andPREFERENCE strategies, we focus here only on thestrategies that can be used to COLLECT lists of po-tential antecedents.
Specifically, we focus on de-termining whether discourse theories can help ananaphora esolution system determine LPAs that are"better" than the LPAs that can be computed froma linear interpretation f texts.
Section 2 outlinesthe theoretical s.~umptions of our empirical inves-tigation.
Section 3 describes our experiment.
Weconclude with a discussion of the results.2 Background2.1 AssumptionsOur approach is based on the following assump-tions:1.
For each anaphor in a text, an anaphora reso-lution s~,stem ust produce an LPA that con-rains a referent to which the anaphor can beresolved.
The size of this LPA varies from sys-tem to system, depending on the theory a sys-tem implements.2.
The smaller the LPA (while retaining a correctantecedent), the less likely that errors in theFILTER and PREFERENCE modules will affectthe ability of a system to select he appropriatereferent..
Theory A is better than theory B for the taskof reference resolution if theory A producesLPAs that contain more antecedents to whichanaphors can be correctly resolved than theoryB, and if the LPAs produced by theory A aresmaller than those produced by theory B. Forexample, if for a given anapbor, theory A pro-duces an LPA that contains a referee to whichthe anaphor can be resolved, while theory Bproduces an LPA that does not contain such areferee, theory A is better than theory B. More-over, if for a given anaphor, theory A producesan LPA with two referees and theory B pro-duces an LPA with seven referees (each LPAcontaining a referee to which the.
anaphor canbe resolved), theory A is considered better thantheory B because ithas a higher probability ofsolving that anaphor correctly.We ?consider two Classes of models for determiningthe LPAs of anaphors in a text:Linearok models.
This is a class of linear modelsin which the LPAs include all the references foundin the discourse unit under scrutiny and the k dis-course:ufiits hat immediately precede it.
Linear-Omodels an approach that assumes that all anaphorscan be resolved intra-uuit; Linear-I models an ap-preach that corresponds roughly to centering (Groszet aL, 1995).
Linear-k is consistent with the assump-tions that underlie most current anaphora resolutionsystems, which look back k units in order to resolvean anaphor.Discourse-VT-k models.
In this class of models,LPAs include all the referential expressions found inthe discourse unit under scrutiny and the k discourseunits that hierarchically precede it.
The units that hi-erarchically precede a given unit are determined ac-cording to Veins Theory (VT) (Cristea et al, 1998),which is described briefly below.2.2 Veins TheoryVT extends and formalizes the relation betweendiscourse structure and reference proposed byFox (1987).
It identifies "veins", i.e., chains of el-ementary discourse units, over discourse stmctmetrees that are built according to the requirements putforth in Rhetorical Sa-acture Theory (RST) (Mannand Thompson, 198g).One of the conjectures of VT is that the vein ex-pression of an elementary discourse unit provides acoherent "abstract" of the discourse fragment thatcontains that unit.
As an internally coherent dis-course fragment, all anaphors and referential ex-pressions (REs) in a unit must be resolved to ref-erees that occur in the text subsumed by the unitsin the vein.
This conjecture is consistent with Fox'sview (1987) that the units that contain referees towhich anaphors can be resolved are determined bythe nuclearity of the discourse units that precede theanaphors and the.overall structure of discourse.
Ac-cording to VT, REs of both satellites and nuclei canaccess referees of immediately preceding nucleusnodes.
REs of nuclei can only access referees ofpreceding nuclei nodes and of directly subordinatedsatellite nodes.
And the interposition of a nucleus47after a satellite blocks the accessibility of the satel-lite for all nodes that are lower in the correspondingdiscourse structure (see (Cristea et el., 1998) for afull definition).Hence, the fundamental intuition underlying VTis that the RST-specific distinction between ucleiand satellites constrains the range of referents towhich anaphors can be resolved; in other words,the nucleus-satellite distinction induces for eachanaphor (and each referential expression) a Do-main of Referential Accessibility (DRA).
For eachanaphor a in a discourse unit u, VT hypothesizesthat a can be resolved by examining referential ex-pressions that were used in a subset of the discourseunits that precede u; this subset is called the DRAof u.
For any elementary unit u in a text.
the corre-sponding DRA is computed automatically from therhetorical representation f that ext in two steps:.
Heads for each node are computed bottom-upover the rhetorical representation tree.
Heads?
of elementary discoune units are the unitsthemselves.
Heads of internal nodes, i.e., dis-course spans, are computed by taking the union?
of the heads of the immediate child nodes thatare nuclei.
For example, for the text in Fig-ure 1, whose rhetorical structure is shown inFigure 2, the head of span \[5,7\] is unit 5 be-cause the head of the immediate nucleus, theelementary unit 5, is 5.
However, the head ofspan \[6,7\] is the list (6,7) because both imme-diate children are nuclei of a multlnuclesr rela-tion..
Using the results of step 1, Vein expressionsare computed top.down for each node in thetree.
The vein of the root is its head.
Veinsof child nodes are computed recursively ac-cording to the rules described by Cristea etal.(1998).
The DRA of a unit u is given by theunits in the vein that precede u.For example, for the text and RST tree in Fig-ures 1 and 2, the vein expression of unit 3,?
which contains units 1 and 3, suggests thatanaphors from unit 3 should be resolved onlyto referential expressions in units I and 3.
Be-cause unit 2 is a satellite to unit 1, it is consid-ered to be "blocked" to referential links fromunit 3.
In contrast, he DRA of unit 9, consist-ing of units I, 8, and 9, reflects the intuitionthat anaphon from unit 9 can be resolved onlyto referential expressions from unit 1, which1.
l .~ch- - /D .
, .
, .
\ ] .
cop ~oh.o .~oh~o.manager, moved co ~ ,a small  b~o~chnology concern hero,2.
to  becgme~t~ presLdent a'ncl ch ie fol~srlt~ng o f f i cer .
I3.
J Pit.
c~.asey, 46 years oXcl,\] was~ presAdent; ofJ~ ' I  HCNoxL Phantaceutxca l  subsJ,ldJ.ary, |4.
which ,,qm merged w~th another ~r~r urtlg,OrCho pharnacsut:?ca/ Corp., chLa year  in?
cosC-cut.t.Jng move.S.
Hr.
Case~ succeeds N .
~ r r e t t ,  SO,"6.
Mr. l)a~\]c'et, lr, z'em,,;x~ ch ie f  execut4ve o f f .
i cer7.
and becomes chA~rnan, me'I ?9.
h. ln .e ,  th,  nov. co10.
"becsuse\['h~\]saw hee11:h care  mov4ng Cowardtec~hnologiea J.$.ke ~ g e n e  therapyproducts.11.
J'X'~be.l.Aeve the .
~'.he f j .e ld  i s  energ ing  and Aspro f i ted  I;o brsO.
loose,~.. \ [ '~  mtid.Figure h An example of text and its elementaryunits.
The referential expressions surroundedbyboxes and ellipses correspond to two distinct co-referential equivalence lasses.
Referential expres-sions surrounded by boxes refer to Mr. Casey;those surrounded by ellipses refer to Genetic Ther-apy Inc..Oeeoe@oo@eOis the most important unit in span \[1,7\], andto unit 8, a satellite that immediately precedesunit 9.
Figure 2 shows the heads and veins ofall internal nodes in the rhetorical representa-tion.2.3 Comparing modelsThe premise underlying our experiment is that hereare potentially significant differences in the size ofthe search space required to resolve referential ex-pressions when using Linear models vs. Discourse-VT models.
For example, for text and the RSTtree in Figures I and 2, the D/scourse-VT modelnarrows the search space required to resolve theanaphor the smaller company in unit 9.
Accord-ing to VT, we look for potential antecedents for thesmaller Company in the DRA of unit 9, which lists48OO @OOOOOO H=I9  *O V=lg*H ' I  " H '9  O V=I9*  ~ ~"~.
V '19*V=Ig* * V-19\[*O v -19 .
3~9- _w v -~679,  v -19 .
I ~  ~I.~- -  V=l(g~9*1 2 3 4 8 101910.6 7.
.~ .
.
H = II\[H= 3 \[ 9 V -  1 9 10 l l "Iv'13591 _~I v~-  131 \[H. 9 ~ \[ 10\ [v - i~9  I IDRA.
XS ~ 11 nFigure 2: The RST analysis of the text in figure 1.
The tree is represented using the conventions proposedby Mann and Thompson (1988).
@@O0OO@@@0O@@O0O @00@@O@units 1, 8, and 9.
The antecedent Genetic Ther-ap3 Inc. appears in unit 1; therefore, using VT wesearch back 2 units (units 8 and 1) to find a correctantecedent.
In contrast, o resolve the same refer-ence using a finear model, four units (units 8, 7.6, and 5) must be examined before Gene6c Ther-apy is found.
Assuming that referential links are es-tablished as the text is processed, Gene~c Therapywould be linked back to pronoun its in unit 2, whichwould in mm be linked to the first occurrence oftheantecedent,Genetic Therapy.
Inc., in unit 1, the an-tecedent determined directly by using Wl'.In general, when hierarchical djacency is con-sidere& an anaphor may be resolved to a referentthat is not the closest in a linear interpretation fa text~ Similarly, a referential expression can belinked to a referee flint is not the closest in a lin-ear interpretation f a text.
However, this does notcreate problems because we are focusing here onlyon co-referential relations of identity (see section3).
Since these relations induce quivalence lassesover the set of referential expressions in a text, itis sufficient hat an anaphor or referential expres-sion is resolved to any of the members of the rule-v-ant equivalence class, For example, according toVT, the referential expression Mr. Casey in unit 5in Figure I can be linked directly only to the ref-eree Mr Casey in unit !.
because the DRA of unit 5is { 1,5}.
By considen'ng the co-referential links ofthe REs in the other units, the full equivalence lasscan be determined.
This is consistent with the dis-tinction between "direct" and "indirect" referencesdiscussed by Cristea, et ai.
(1998).3 The Experiment3.1 MaterhJsWe used thirty newspaper texts whose lengths var-ied widely; the mean o is 408 words and the stan-dard deviation/~ is 376.
The texts were anno-tated manually for co-reference r lations of iden-tity (ITh'schman and Chinchor, 1997).
The co-reference r lations define quivalence lasses on theset of all marked referents in a text.
The texts werealso manually annotated with discourse structuresbuilt in the style of Mann and Thompson (1988).Each analysis yielded an average of 52 elementarydiscourse units.
Details of the discourse annotationprocess are given in (Marcu et al, 1999).3-~ Comparing potential to establishco-referential links3~,.1 MethodThe annotations for co-reference relations andrhetorical structure trees for the thirty texts werefused, yielding representations tha t ~flect not onlythe discourse structure, but also the c~reference49equivalence lasses pecific to each text.
Based onthis information, we evaluated the potential of eachof the two classes of models discussed in section2 (Linear-k and Discourse-VT-k) to correctly estab-?
lish co-referential links as follows: For each model,each k, and each marked referential expression a,we determined whether or not the correspondingLPA (defined over k elementary units) contained areferee from the same equivalence lass.
For exam-ple, for the Linear-2 model and referential expres-sion the smaller company in unit 9, we estimatedwhether a co-referential link could be establishedbetween the smaller company and another referen-tial expression i  units 7, 8, or 9.
For the Discourse-VT-2 model and the same referential expression, weestimated whether a co-referential link could be es-tablished between the smaller company and anotherreferential expression i units 1, 8, or 9. which cor-respond to the DRA of unit 9.To enable a fair comparison of the two models,?
when k is larger than the size of the DRA of a givenunit, we extend that DRA using the closest units thatprecede the unit under scrutiny and are not alreadyin the DRA.
Hence, for the Linear-3 model and thereferential expression the smaller company in unit 9,we estimate whether a co-referential link can be es-tablished between the smaller company and anotherreferential expression i units 6, 7, 8, or 9.
For theDiscourse-VT-3 model and the same referential ex-pression, we estimate whether a co-referential linkcan be established between the smaller companyand another referential expression i  units 1, 8, 9,or 7, which c:orrespond tothe DRA of unit 9 (units1, 8, and 9) and to unit 7, the closest unit precedingunit 9 that is not in its DRA.For the Discourse-VT-k models, we assume thatthe Extended DRA (EDRA) of size k of a unitu (EDRAk(u)) is given by the first I < k units ofa sequence that lists, in reverse order, the units ofthe DRA of u plus the k - I units that precede u butare not in its DRA.
For example, for the text in Fig-me 1, the following relations hold: F_~RAo(9) =9; F, DP, A~(9) = 9,8; F_,DRAa(9) = 9,8,1;EDP~(9) = 9, 8,1, 7; EDRA4(9) - 9, 8,1, 7, 6.For Linear-k models, the EDRAt(u) is given by uand the k units that immediately precede u.The potential p( M, a, EDRAt) of a model M todetermine correct co-referential links with respectto a referential expression a in unit u, given a corre-sponding EDRA of size k (EDRAt(u)), is assignedthe value 1 if the EDRA contains a co-referentfrom the same equivalence class as a. Otherwise,p(M, a, EDRAk) is assigned the value 0.
The poten-tial p(M, C, k) of a model M to determine correctco-referential links for all referential expressions ina corpus of texts C, using EDRAs of size k, is com-puted as the sum of the potentials p(M, a, EDRAk)of all referential expressions a in C. This potentialis normalized to a value between 0 and I by dividingp(M, 6", k) by the number of referential expressionsin the corpus that have an antecedent.By examining the potential of each model to cor-rectiy determine co-referential expressions for eachk, it is possible to determine the degree to whichan implementation f a given approach can con-tribute to the overall efficiency of anaphora resolu-tion systems.
That is, if a given model has the po-tential to correctly determine a significant percent-age of co-referential expressions with small DR/is,an anaphora resolution system implementing thatmodel will have to consider fewer options overall.Hence, the probabifity of error is reduced.3.2.2 ResultsThe graph in Figure 3 shows the potentials of theLinear-k and Discourse-VT-k models to correctlydetermine co-referential links for each k from 1 to20.
The graph in Figure 4 represents he same po-tentials but focuses only on ks in the interval \[2,9\].As theze two graphs how, the potentials increasemonotonically with k, the VT-k models always do-ing better than the Linear-k models.
Eventually, forlarge ks, the potential performance ofthe two mod-els converges to 100~.The graphs in Figures 3 and 4 also suggest reso-lution strategies for implemented systems.
For ex-ample, the graphs uggests hat by choosing to workwith EDRAs of size 7, a discourse-based system hasthe potential of resolving more thun 90~ of the co-referential links in a text correctly.
To achieve thesame potential, a linear-based system needs to lookback 8 units.
If a system does not look back atall and attempts o resolve co-referential links onlywithin the unit under scrutiny (k -- 0), it has thepotential to correctly resolve about 40~ of  the co-referential links.To provide aclearer idea of how the two modelsdiffer, Figure 5 shows, for each k, the value of theDiscourse-VT-k potentials divided by the value ofthe Linear-k potentials.
For k = 0, the potentials ofboth models are equal because both use only the unitin focus in order to determine cwreferential links.For k = 1, the Discourse-VT-I model is about 7%5000000000000000000000000000O0000000O0 Q0OOOOOq)OOOO0eOOOO,9OOO5,8O0O%70 U)~6000~~000q,40.00%oI t  I t lA  o J te- VT .
.k  .
.
.
.
.
.
.
L ima- I tFigure 3: The potential of Linear-k and Discourse-VT-k models to determine correct co-referentiallinks (0 < ~ < 20).OOOOO0O0OOOOOlUO~t7~0l \]BE l la  oSnoFigure 4: The potential of Linear-k and Discourse-VT-k models to determine correct co-referentlal.nks (2 _ k < 9).better than the IAnear-I model.
As the value of kincreases, the value Discourse-VT-k/Linear-k con-verges to I .In Figures 6 and 7, we display the number ofexceptions, i.e., co-referential links that Discourse-VT-k and Linear-k models cannot determine cor-rectly.
As one can see, .
over the whole corpus, foreach k _< 3, the Discourse-VT-k models have thepotential to determine correctly about tO0 mote co-referential links than the Linear-k models.
AS kincreases, the performance of the two models con-verges.n.
o~'1.
agi .o !~t .99O.
g |o ,  ~7? '
t t  o L , , ,  ~ ~, ..~ e , -.
.
.
.
.
.
iIJ.
.
z .
.
VTJO,.m JtHgure 5: A direct comparison of Discourse-VT-kand Linear-V'r-k potentials to correctly determineco-referential links (0 _< k _< 20).. .
.
.
I !iiE l la  .
the?
, wY~tmj .
- - -8 -  ?
?
k t~BmO.Figure 6: The number of co-referential link.~ thatcannot be correctly determined by Discourse-VT-kand Linear-k models (0 _.< k _< 20).3.2.3 Statistical Sig-ifieRnceIn order to assess the statistical significance of thedifference between the potentials of the two modelsto establish correct co-referential links, we carriedout a Paired-Samples T Test for each k. In general, aPaired-Samples T Test checks whether the mean ofcasewise differences between two variables differsfrom 0.
For each text in the corpus and each k, wedetermined the potentials of both VT-k and Line.ar-k models to establish correct co-referential links inthat text.
For ks smaller than 4, the difference inpotentials was statistically significant.
For example,for k -- 3, t -- 3.345, df - 29, P = 0.002.
Forvalues of k larger than or equal to 4, the differencewas no longer significant.
These results are consis-tent with the graphs shown in Figure 3 to 7, whichall show that the potentials of Discourse-VT-k andLinear-k models converges to the same value as thevalue of k increases.51100 ?j:j~j=I000.
.
,.
.
.
, J , | .}
?
5 S f g | I0I ~" ' re '~.
.
.
.
.
.
.
,,,.a.,.~ 1 ' " "  " " "Figure 7: The number of co-referential links thatcannot be correctly determined by Discourse-VT-kand Linear-k models (1 _< k < I0).3.3 Comparing the effort required to establishco-referential links3.3.1 MethodThe method escribed insection 3.2.1 estimates thepotential of Linear-k and Discourse-VT-k modelsto determine correct co-referential links by treatingEDRAs as sets.
However, from a computational per-spective (and presumably, from a psycholinguisticperspective aswell) it also makes ense to comparethe effort required by the two classes of models toestablish correct co-referential links.
We estimatethis effort using a very simple metric that assumesthat the closer an an ~teo~__ent is to a correspond-ing referential expression i  the EDRA, the better.Hence, in estimating the effort to estabfish a co-referential link, we treat EDRAs as ordered lists.
Forexample, using the Linesr-9 model, to determine thecorrect antecedent of the referential expression thesmaller company in unit 9 of Hgure 1, it is neces-sary to search back through 4units (to unit 5, whichcontains the refezent Genet/c Therapy).
Had unit 5been Mr. Cosset succeeds M. James Barrett, .50, wewould have had to go back 8 units (to unit 1 ) in orderto correctly resolve the RE the smaller company.
Incontrast, in the Discourse-VT-9 model, we go backonly 2 units because unit 1 is two units away from?
unit 9 (EDRAg(9) = 9,8,1,7,8,5,4,3,2).We consider that he effort e(M, a, EDRAt) of amodel M to determine correct c0-referential linkswith respect o one referential  in unit u, given acorrespondingEDRA of size k (EDRAt(u)) is givenby the number of units between u and the first unit inEDRAt(u) that contains aco-referential expressionofa.The effort e(M, C, k) of a model M to deter-gNO " .
o ~ .
.
.
.
.
~  i~.
,  ,21~.  '
1 g !I I ) l&  a ,zeVT g '~us  -.
.
.
.
.
.
.
Un g '~snHgure 8: The effort required by Linear-k andDiscourse-VT-k models to determine correct co-referential links (0 < k < 100).mine correct co-referential links for all referent/alexpressions in a corpus of .tex~ C using EDRAsof size k was computed as the sum of the effortse(M,a, EDRAk) of all referential expressions a inC.3.3.2 ResultsFigure 8 shows the Discourse-VT-k and Linear-k ef-forts computed over all referential expressions inthecorpus and all ks.
It is possible, for a given referenta and a given k, that no co-referential link exists inthe units of the corresponding EDRAt.
In this case.we consider that he effort is equal to k. As a conse-quence, for small ks the effort required to establishco-referential linksis similar for both theories, be-cause both can establish only a limited number oflinks.
However, as k increases, the effort computedover the entire corpus diverges dramatically: usingthe Discourse-VT model, the search space for co-referential links is reduced by about 800 units for acorpus containing roughly 1200 referential expres-sions.3.3.3 Statistical signiflcaneeA Paired-Samples T Test was performed foreach k.For each text in the corpus and each k, we deter-mined the effort of both VT-k and Linear-k modelsto establish correct co-referential links in that text.For all ks the difference in effort was statisticallysignificant.
For example, for k = 7, we obtainedthe values t = 3.51, df = 29, P = 0.001.
These re-sults are intuitive: because EDRAs are treated as or-dered lists and not as sets, the effect of the discoursestructure on establishing correct co-referential linksis not diminished as k increases.520@@@0@0@@B@0000@@B00@00@@00@@@0@e @0e@OOOOO@0.00@@@@@@@O@@@OOO@@@@OO0OO@O@@@@@@@04 ConclusionWe an~,lyzed mpirically the potentials of discourseand linear models of text o determine co-referentiallinks.
Our analysis suggests that by exploitingthe hierarchical structure of texts, one can increasethe potential of natural anguage systems to cor-rectly determine co-referential links, which is a re-quirement for correctly resolving anaphors.
If onetreats all discourse units in the preceding discourseequally, the increase is statistically significant onlywhen a discourse-based corefererice system looksback at most four discourse units in order to estab-lish co-referenfial links.
However, if one assumesthat proximity plays an important role in establish-ing co-referential links and that referential expres-sions are more likely to be linked to referees thatwere used recently in discourse, the increase is sta-tistically significant no matter how many units adiscourse-based co-reference system looks back inorder toestablish co-referenfial links.Acknowledgements.
We ate grateful to LynetteHirschman and Nancy Chinchor for making avail-able their corpus of co-reference annotations.
Weare also grateful to Graeme Hirst for comments andfeedback on a previous draft of this paper.ReferencesSaliha Azzam, Kevin Humphreys, and RobertGaizauskas.
1998.
Evaluating a focus-based ap-proach to anaphora resolution.
In Proceedings ofthe 36th Annual Meeting of the Association forComputational Linguistics and of the 17th Inter-national Conference on Computational Linguis-tics (COLING/ACL'98), pages 74-78, Montreal,Canada, August 10--14.Dan Criste~ Nancy Ide, and Lanrent Romary.
1998.Veins theory: A model of global discourse co-hesion and cohexence.
In Proceedings of the36th Annual Mee~g of the Association for Com-putational Linguistics and of the 17th Interna-tional Conference on Computational Linguistics(COLING/ACL'98), pages 281-285, :Montreal,Canada, August.Barbara Fox.
1987.
Discourse Structure andAnaphora.
Cambridge Studies in Linguistics; 48.Cambridge University Press.Niyu Ge" John Hale, and Eugene Chamiak.
1998.A statistical pproach to anaphora resolution.
InProceedings ofthe Sixth Workshop n Very LargeCorpora, pages 161-170, Montreal, Canada, Au-gust 15-16.Barbara J. Grosz and Candace L. Sidner.
1986.
At-tention, intentions, and the structure of discourse.ComputationalLinguistics, 12(3): 175-204, July-September.Barbara J. Grosz, Aravind K. Joshi, and Scott We-instein.
1995.
Centering: A framework for mod-eling the local coherence ofdiscourse.
Computa-tional Linguistics, 21 (2):203-226, June.Lynette Hirschman and Nancy Chinchor, 1997.M U C- 7 Coreference TaskDefinition* July 13;Janet Hitzeman and Massimo Poesio.
1998.
Longdistance pronominalizafion a d global focus.
InProceedings ofthe 36th Annual Meeting of theAssociation for Computational Linguistics andof the 17th International Conference "on Com-putational Linguistics (COLING/ACL'98), pages550-556, Montreal, Canada, August.Jerry H. Hobbs.
1978.
Resolving pronoun refer-;ences.
Lingua, 44:311-338.Megumi Kameyama.
1997.
Recogni'zing referen-fial links: An information extraction perspec-five.
In Proceedings ofthe ACL/F~CL'97 Work-shop on Operational Factors in Practical, RobustAnaphora Resolution, pages 46--53.Shalom Lappin and Herbert J. Leass.
1994.
Analgorithm for pronominal anaphora resolution.Computational Linguistics, 20(4): 535- 561.William C. Mann and Sandra A. Thompson.
1988.Rhetorical structure theory: .Toward a functionaltheory of text organization.
Text, 8(3):243-281.Daniel Marcu, Estibaliz Amorrortu, and MagdalenaRomera.
1999~ Experiments in constmcfing acorpus of discourse trees.
In Proceedings oftheACL'99 Workshop on Standards and Tools forDiscourse Tagging, University of Maryland, June22.Ruslan Mitkov.
1997.
Factors in anaphora reSo-lution: They am not the only things that mat-ter.
a case study based on two different ap-proaches.
In Proceedings of the ACL/F~CL'97Workshop on Operational Factors in Practical,Robust Anaphora Re.solution, pages 14--21.Candace L. Sidner.
1981.
Focusing for interpre-tation of pronouns.
Corona l  Linguistics,7(4):217-231, October-December.Wietske Vonk, I.etfica G.M.M.
Hustinx, and WhnH.G.
Simons.
1992.
The use of referential ex-pressions instructuring discourse, l.anguag e andCognitive Processes, 7(3,4):301-333.53
