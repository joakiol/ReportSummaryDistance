Proceedings of the Third Workshop on Issues in Teaching Computational Linguistics (TeachCL-08), pages 36?44,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsStrategies for Teaching ?Mixed?
Computational Linguistics classesEric Fosler-LussierDept.
of Computer Science and EngineeringDept.
of LinguisticsThe Ohio State UniversityColumbus, OH 43210, USAfosler@cse.ohio-state.eduAbstractMany of the computational linguistics classesat Ohio State draw a diverse crowd of students,who bring different levels of preparation tothe classroom.
In the same classroom, we of-ten get graduate and undergraduate studentsfrom Linguistics, Computer Science, Electri-cal Engineering and other departments; teach-ing the same material to all of these studentspresents an interesting challenge to the in-structor.
In this paper, I discuss some of theteaching strategies that I have employed tohelp integrate students in two classes on auto-matic speech recognition topics; strategies fora graduate seminar class and a standard ?lec-ture?
class are presented.
Both courses makeuse of communal, online activities to facilitateinteraction between students.1 IntroductionAs one of the themes of the Teach-CL08 workshopsuggests, teaching students of many kinds and manylevels of preparation within a single course can bean interesting challenge; this situation is much moreprevalent in a cross-disciplinary area such as compu-tational linguistics (as well as medical bioinformat-ics, etc.).
At Ohio State, we also define the compu-tational linguistics field relatively broadly, includingautomatic speech recognition and (more recently)information retrieval as part of the curriculum.
Thus,we see three major variations in the preparation ofstudents at OSU:1.
Home department: most of the students tak-ing CL courses are either in the Linguisticsor Computer Science and Engineering depart-ments, although there have been students fromforeign language departments, Electrical En-gineering, Psychology, and Philosophy.
Al-though there are exceptions, typically the en-gineers have stronger mathematical and com-putational implementation skills and the non-engineers have a stronger background in thetheoretical linguistics literature.
Bringing thesegroups together requires a balancing betweenthe strengths of each group.2.
Specialization (or lack thereof): Many of thestudents, particularly in seminar settings, haveparticular research agendas that are not tradi-tionally aligned with the topic of the class (e.g.,students interested in parsing or computer vi-sion taking an ASR-learning course).
Further-more, there are often students who are not se-nior enough to have a particular research track,but are interested in exploring the area of thecourse.
Our courses need to be designed toreach across areas and draw on other parts ofthe curriculum in order to both provide con-nections with the student?s current knowledgebase, and allow the student to take away use-ful lessons even they do not plan to pursue thetopic of the course further.3.
Graduate vs. undergraduate students: inboth the CSE and Linguistics departments atOhio State, CL (and many other) courses areopen to both undergraduates and graduate stu-dents.
These courses fall far enough down theprerequisite chain that the undergraduates who36enroll are usually very motivated (and conse-quently do well), but one must keep in mindthe differences in abilities and time constraintsof each type of student.
If the graduate stu-dents outnumber the undergraduates, introduc-ing mentoring opportunities can provide a re-warding experience for all concerned.From a practical perspective, this diversitypresents a significant challenge ?
especially in uni-versities where enrollment concerns drive curricularmatters to some degree.
Inclusiveness is also a rea-sonable goal from a financial, not just a pedagog-ical, perspective.
CSE enrollments have declinedsignificantly since the dot-com bust (Vegso, 2008),and while the declines are not as sharp as they oncewere, the current environment makes it more diffi-cult to justify teaching narrow, advanced courses toonly a few students (even if this were the practice inthe past).In this paper, I describe a number of strategiesthat have been successful in bringing all of thesediverse populations into two different classes of-fered at OSU: a graduate seminar and a under-grad/graduate lecture class.
The topic of both classeswas statistical language processing, with a signif-icant emphasis on ASR.
Sample activities are dis-cussed from each class.While there are significant differences in the waythat each class runs, there are several common ele-ments that I try to provide in all of my classes.
:I first establish the golden rule: primaryamong my self-imposed rules is to make clear toall participants that all points of view are to be re-spected (although not necessarily agreed with), andthat students are coming to this class with differentstrengths.
If possible, an activity that integrates bothlinguistic and computer science knowledge shouldbe brought in within the first week of the class; inteaching CSE courses, I tend to emphasize the lin-guistics a bit more in the first week.I try to help students to engage with eachother: a good way to foster inter- and intra-disciplinary respect is to have the students work col-laboratively towards some goal.
This can be chal-lenging in a diverse student population setting; mon-itoring progress of students and gently suggestingturn-taking/mentoring strategies as well as design-ing activities that speak to multiple backgroundscan help ease the disparity between student back-grounds.
Preparing the students to engage with eachother on the same level by introducing online pre-class activities can also help bring students together.I try to allow students to build on previousknowledge via processes other than lecturing: alecture, presented by either a student or a profes-sor, is a ?one-size-fits-all?
solution that in a diversepopulation can sometimes either confuse unpreparedstudents, bore prepared students, or both.
Interac-tive in-class and out-of-class activities have the ad-vantage of real-time evaluation of the understandingof students.
This is not to say that I never lecture;but as a goal, lecturing should be short in durationand focused on coordinating understanding amongthe students.
Over the years, I am gradually reduc-ing the amount of lecturing I do, replacing it withother activities.By putting some simple techniques into place,both students and I have noticed a significant im-provement in the quality of classes.
In Section 2,I describe improvements to a graduate seminar thatfacilitated interaction among a diverse group of par-ticipants.
The most recent offering of the 10-weekseminar class had 22 participants: 14 from CSE,7 from Linguistics, and one from another depart-ment.
In my informal evaluation of background, 13of the 22 participants were relatively new to the fieldof computational linguistics (< 2 years experience).Student-directed searching for background materi-als, pre-posing of questions via a class website, andblind reviewing of extended project abstracts by fel-low students were effective strategies for providingcommon ground.Section 3 describes improvements in a lecture-style class (Foundations of Spoken Language Pro-cessing) which has a similarly diverse participantbase: the most recently completed offering had 7CSE and 3 Linguistics Students, with the under-grad/graduate student ratio 3:7.
Devoting one of thetwo weekly sessions to in-class group practical ex-ercises also bolstered performance of all students.2 Seminar structureIn developing a graduate seminar on machine learn-ing for language processing, I was faced with a seri-37ous challenge: the previous seminar offering (on se-quential machine learning) two years prior was notas inspiring as one would hope, with several studentsnot actively participating in the class.
This happenedin part because students were permitted to suggestpapers to read that week, which usually came fromtheir own research area and often had esoteric termi-nology and mathematics.
There was nothing wrongwith the papers per se, but many of the students werenot able to bridge the gap from their own experienceto get into the depths of the current paper.
While Ithought having students partially control the seminaragenda might provide ownership of the material, inpractice it gave a few students control of the sessioneach time.
In the more recent offering, this problemwas likely to be exacerbated: the increased diversityof backgrounds of the students in the class suggestedthat it would be difficult to find common ground fordiscussing advanced topics in machine learning.In previous seminars, students had givencomputer-projected presentations of papers, whichled to rather perfunctory, non-engaged discussions.In the offering two years prior, I had bannedcomputerized presentations, but was faced withthe fact that many students still came unpreparedfor discussions, so the sessions were somewhathit-and-miss.In sum, a reorganization of the class seemed de-sirable that would encourage more student partici-pation, provide students the opportunity to improvetheir background understanding, and still cover ad-vanced topics.2.1 A revised seminar structureThe previous instantiation of the seminar met twiceweekly for 1 1/2 hours; in the most recent offeringthe seminar was moved to a single 2 1/2 hour blockon Fridays.
Each week was assigned a pair of stu-dent facilitators who were to lead the discussion forthe week.
The instructor chose roughly four paperson the topic of the week: one or two were more ba-sic, overview papers (e.g., the Rabiner HMM tuto-rial (Rabiner, 1989) or Lafferty et al?s ConditionalRandom Fields paper (Lafferty et al, 2001)), andthe remaining were more advanced papers.
Studentsthen had varying assigned responsibilities relatingto these papers and the topic throughout the week.Out-of-class assignments were completed using dis-cussion boards as part of Ohio State?s online coursemanagement system.The first assignment (due Tuesday evening) wasto find relevant review articles or resources (such asclass or tutorial slides) on the internet relating to thetopic of the week.
Each student was to write andpost a short, one-paragraph summary of the tuto-rial and its strengths and weaknesses.
Asking thestudents to find their own ?catch-up?
resources pro-vided a wealth of information for the class to lookat, as well as boosting the confidence of many stu-dents by letting them find the information that bestsuited them.
I usually picked one (or possibly two)of the tutorials for the class to examine as a wholethat would provide additional grounding for classdiscussions.The second assignment (due Thursday eveningat 8 pm) was for each student to post a series ofquestions on the readings of the week.
At a min-imum, each student was required to ask one ques-tion per week, but all of the students far exceededthis.
Comments such as ?I totally don?t understandthis section?
were welcome (and encouraged) by theinstructor.
Often (but not exclusively) these ques-tions would arise from students whose backgroundknowledge was sparser.
In the forum, there was ageneral air of collegiality in getting everyone up tospeed: students often read each others?
questionsand commented on them inline.
Figure 1 shows asample conversation from the course; many of thesmall clarifications that students needed were han-dled in this manner, whereas the bigger discussiontopics were typically dealt with in class.
Studentsoften pointed out the types of background informa-tion that, if discussed in class, could help them betterunderstand the papers.The facilitators of the week then worked Thurs-day evening to collate the questions, find the onesthat were most common across the attendees or thatwould lead to good discussion points, and developan order for the discussion on Friday.
Facilitatorsstarted each Friday session with a summary of themain points of the papers (10-15 minutes maximum)and then started the discussion by putting the ques-tions up to the group.
It was important that the facil-itators did not need to know the answers to the ques-tions, but rather how to pose the questions so that agroup discussion ensued.
Facilitators almost always38Student 1: After reading all of these papers on [topic], astoundingly, a few of the concepts have started to sink in.
Theformulas are mostly gibberish, but at least they?re familiar.
Anyhow, I have only mostly dumb questions....?
[Paper 1]:?
Anyone want to talk about Kullback-Leibler divergence??
We?ve see this before, but I forget.
What is an l2 norm??
What?s the meaning of an equal symbol with a delta over it??
When it talked about the ?SI mode?, does that mean ?speaker independent???
[Paper 2]:?
In multiple places, we see the where we have a vector and a matrix, and they compute the product of thetranspose of the vector with the matrix with the vector.
Why are they doing that??
[Paper 3]:?
I came away from this paper feeling like they gave a vague description of what they did, followed by results.I mean, nice explanation of [topic] in general, but their whole innovation, as far as I can tell, fits into section[section number].
I feel like I?m missing something huge here.?
[Paper 4]:?
So, they want to maximize 2/|w|, so they decide instead to minimize |w|2/2.
Why?
I mean, I get that it?s areciprocal, so you change from max to min, and that squaring it still makes it a minimization problem.
Butwhy square it?
Is this another instance of making the calculus easier??
What are the ?sx?
and ?si?
training sentences?Student 2: But why square it?
Is this another instance of making the calculus easier?
I think so.
I think it has to dowith the fact that we will take its derivative, hence the 2 and 1/2 cancel each other.
And since they?re just getting anargmax, the 2 exponent doesn?t matter, since the maximum x2 can be found by finding the maximum x.Student 3: ?sx?
are the phonetically-compact sentences in the TIMIT database and ?si?
are the phonetically-diversesentences.Student 4: Ah thanks for that; I?ve wondered the same thing when seeing the phrase ?TIMIT si/sx?Student 5: Oh, so ?si?
and ?sx?
do not represent the phones they are trying to learn and discern?Figure 1: Conversation during question posting period in online discussion forum.
Participants and papers have beenanonymized to protect the students.had something to contribute to the conversation; re-leasing them from absolutely needing to be sure ofthe answer made them (and other participants) ableto go out on a limb more in the discussion.I found that since the instructor usually has morebackground knowledge with respect to many of thequestions asked, it was critical for me to have asense of timing for when the discussion was falter-ing or getting off track and needed for me to jumpin.
I spent roughly a half hour total of each session(in 5-10 minute increments) up at the blackboardquickly sketching some material (such as algorithmsunknown to about half of the class) to make a con-nection.
However, it was also important for me torealize when to let the control of the class revert tothe facilitators.The blackboard was a communal workspace: insome of the later classes students also started to getup and use the board to make points, or make pointson top of other students drawings.
In the future, Iwill encourage students to use this space from thefirst session.
I suspect that the lack of electronic pre-sentation media contributed to this dynamism.2.2 Class projectsThe seminar required individual or team projectsthat were developed through the term; presentationstook place in the last session and in finals week.Three weeks prior to the end of term, each team sub-mitted a two-page extended abstract describing their39What single aspect of the course did you find most helpful?
Why?Discussions.Very good papers used.Style of teaching atmosphere.Just the discussion style.Informal, discussion based.The project.
[Instructor] really explained the intuitions behind the dense math.
The pictorial method to explain algorithms.The breadth of NLP problems addressed.Instructor?s encouragement to get students involved in the classroom discussion.Interaction between students, sharing questions.Reading many papers on these topics was good training on how to pull out the important parts of the papers.What single change in the course would you most like to see?
Why?There are a lot of papers ?
keeps us busy and focused on the course, but it may be too much to comprehend in a singleterm.More background info.None.I think it is highly improved from 2 years ago.
Good job.Less emphasis on ASR.Have some basic optional exercises on some of the math techniques discussed.Less reading, covered at greater depth.Make the material slightly less broad in scope.More quick overviews of the algorithms for those of us who haven?t studied them before.Figure 2: Comments from student evaluation forms for the seminar classwork, as if for a conference submission.Each abstract was reviewed by three membersof the class using a standard conference reviewingform; part of the challenge of the abstract submis-sion is that it needed to be broad enough to be re-viewed by non-experts in their area, but also neededto be detailed enough to show that it was a reason-able project.
The reviews were collated and pro-vided back to authors; along with the final projectwriteup the team was required to submit a letter ex-plaining how they handled the criticisms of the re-viewers.
This proved to be an excellent exercisein perspective-taking (both in reviewing and writingthe abstract) and provided experience in tasks thatare critical to academic success.I believe that injecting the tutorial-finding andquestion-posting activities also positively affectedthe presentations; many of the students used ter-minology that was developed/discussed during thecourse of the term.
The project presentationswere generally stronger than presentations for otherclasses that I have run in the past.2.3 Feedback on new course structureThe student evaluations of the course were quitepositive (in terms of numeric scores), but perhapsmore telling were the free-form comments on thecourse itself.
Figure 2 shows some of the comments,which basically show that students enjoyed the dy-namic, interactive atmosphere; the primary negativecomment was about how much material was pre-sented in the course.After this initial experiment, some of my col-leagues adopted the technique of preparing the stu-dents for class via electronic discussion boards fortheir own seminars.
This has been used already fortwo CL seminars (one at Ohio State and another atUniversity of Tu?bengen), and plans for a third semi-nar at OSU (in a non-CL setting) are underway.
Theprofessors leading those courses have also reportedpositive experiences in increased interaction in theclass.40All in all, while the course was clearly not perfect,it seems that many of the simple strategies that wereput into place helped bridge the gap between thebackgrounds of students; almost all of the studentsfound the class a rewarding experience.
It is notclear how this technique will scale to large classes:there were roughly 20 participants in the seminar(including auditors who came occasionally); dou-bling the number of postings would probably makefacilitation much more difficult, so modificationsmight be necessary to accommodate larger classes.3 Group work within a lecture classI have seen similar issues in diversity of prepara-tion in an undergraduate/graduate lecture class enti-tled ?Foundations of Spoken Language Processing.
?This class draws students from CSE, ECE, and Lin-guistics departments, and from both undergraduateand graduate populations.3.1 Course structureIn early offerings of this class, I had primarily pre-sented the material in lecture format; however, whenI taught it most recently, I divided the materialinto weekly topics.
I presented lectures on Tues-day only, whereas on most Thursdays students com-pleted group lab assignments; the remaining Thurs-days were for group discussions.
For the practi-cal labs, students would bring their laptops to class,connect wirelessly to the departmental servers, andwork together to solve some introductory problems.The course utilizes several technologies for build-ing system components: MATLAB for signal pro-cessing, the AT&T Finite State Toolkit (Mohri etal., 2001) for building ASR models and doing textanalysis1, and the SRI Language Modeling Toolkit(Stolcke, 2002) for training n-gram language mod-els.
One of the key ideas behind the class is thatstudents learn to build an end-to-end ASR systemfrom the component parts, which helps them iden-tify major research areas (acoustic features, acous-tic models, search, pronunciation models, and lan-guage models).
We also re-use the same FST toolsto build the first pieces of a speech synthesis mod-ule.
Componentized technologies allow the students1Subsequent offerings of the course will likely use the Open-FST toolkit (Riley et al, 2008).to take the first step beyond using a black-box sys-tem and prepare them to understand the individualcomponents more deeply.
The FST formalism helpsthe Linguistics students, who often come to the classwith knowledge of formal language theory.The group activities that get students of varyingbackgrounds to interact constitute the heart of thecourse, and provide a basis for the homework assign-ments.
Figure 3 outlines the practical lab sessionsand group discussions that were part of the most re-cent offering of the course.Weeks 1 and 3 offer complementary activities thattend to bring the class together early on in the term.In the first week, students are given some speechexamples from the TIMIT database; the first ex-ample they see is phonetically labeled.
Using theWavesurfer program (Sjo?lander and Beskow, 2000),students look for characteristics in spectrograms thatare indicative of particular phonemes.
Students arethen presented with a second, unlabeled utterancethat they need to phonetically label according to apronunciation chart.
The linguists, who generallyhave been exposed to this concept previously, tendto lead groups; most students are surprised at howdifficult the task is, and this task provokes gooddiscussion about the difference between canonicalphonemes versus realized phones.In the third week, students are asked to recreatethe spectrograms by implementing the mel filter-bank equations in MATLAB.
Engineering studentswho have seen MATLAB before tend to take thelead in this session, but there has been enough rap-port among the students at this point, and there isenough intuition behind the math in the tutorial in-structions, that nobody in the previous session hadtrouble grasping what was going on with the math:almost all of the students completed the follow-onhomework, which was to fully compute Mel Fre-quency Cepstral Coefficients (MFCCs) based on thespectrogram code they developed in class.
Becauseboth linguists and engineers have opportunities totake the lead in these activities they help to buildgroups that trust and rely on each other.The second week?s activity is a tutorial that I haddeveloped for the Johns Hopkins University Sum-mer School on Human Language Technology (sup-ported by NSF and NAACL) based around the FiniteState Toolkit; the tutorial acquaints students with41Week Lecture topic Group activity1 Speech production &perceptionGroup discussion about spectrograms and phonemes; groups useWavesurfer (Sjo?lander and Beskow, 2000) to transcribe speech data.2 Finite state representations Use FST tools for a basic language generation task where parts of speechare substituted with words; use FST tools to break a simple letter-substitution cipher probabilistically.3 Frequency analysis &acoustic featuresUse MATLAB to implement Mel filterbanks and draw spectrograms (re-ferring back to Week 1); use spectral representations to develop a ?RadioRex?
simulation.4 Dynamic Time Warping,Acoustic ModelingQuiz; Group discussion: having read various ASR toolkit manuals, if youwere a technical manager who needed to direct someone to implementa system, which would you choose?
What features does each toolkitprovide?5 HMMs, EM, and Search The class acts out the token passing algorithm (Young et al, 1989), witheach group acting as a single HMM for a digit word (one, two, three...),and post-it notes being exchanged as tokens.6 Language models Build language models using the SRILM toolkit (Stolcke, 2002), andcompute the perplexity of Wall Street Journal text.7 Text Analysis &Speech SynthesisUse FST tools to turn digit strings like ?345?
into the corresponding wordstring (?three hundred and forty five?).
This tutorial grants more indepen-dence than previous ones; students are expected to figure out that ?0?
canbe problematic, for example.8 Speech SynthesisSpeaker RecognitionGroup discussion on a speaker recognition and verification tutorial paper(Campbell, 1997)9 Spoken Dialogue Systems Quiz; General discussion of any topic in the class.10 Project presentations over the course of both sessionsWeek Homework Task2 Rank poker hands and develop end-to-end ASR system, both using finite state toolkit.3 Finish Radio Rex implementation, compute MFCCs.4 Replace week 2 homework?s acoustic model with different classifier/probabilistic model.5 Implement Viterbi algorithm for isolated words.6 Lattice rescoring with language models trained by the student.7 Text normalization of times, dates, money, addresses, phone numbers, course numbers.Figure 3: Syllabus for Foundations of Spoken Language Processing class with group activities and homeworks.various finite state operations; the two tasks are asimplified language generation task (convert the se-quence ?DET N V DET N?
into a sentence like ?theman bit the dog?)
and a cryptogram solver (solvea simple substitution cipher by comparing frequen-cies of crypttext letters versus frequencies of plain-text letters).
The students get experience, in par-ticular, with transducer composition (which is novelfor almost all of the students); these techniques areused in the first homework, which involves build-ing a transducer-based pronunciation model for dig-its (converting ?w ah n?
into ?ONE?)
and imple-menting a FST composition chain for an ASR sys-tem, akin to that of (Mohri et al, 2002).
A sub-sequent homework reuses this chain, but asks stu-dents to implement a new acoustic model and re-place the acoustic model outputs that are given inthe first homework.
Similarly, practical tutorials onlanguage models (Week 6) and text analysis (Week7) feed into homework assignments on rescoringlattices with language models and turning differentkinds of numeric strings (addresses, time, coursenumbers) into word strings.Using group activities raises the question of howto evaluate individual understanding.
Homeworkassignments in this class are designed to extendthe work done in-class, but must be done individ-ually.
Because many people will be starting from a42group code base, assignments will often look simi-lar.
Since the potential for plagiarism is a concern,it is important that the assignments extend the groupactivities enough that one can distinguish betweengroup and individual effort.Another group activity that supports a homeworkassignment is the Token Passing tutorial (Week 5).The Token Passing algorithm (Young et al, 1989)describes how to extend the Viterbi algorithm tocontinuous speech: each word in the vocabulary isrepresented by a single HMM, and as the Viterbi al-gorithm reaches the end of an HMM at a particu-lar timeframe, a token is ?emitted?
from the HMMrecording the ending time, word identity, acous-tic score, and pointer to the previous word-token.The students are divided into small groups and eachgroup is assigned a digit word (one, two, ...) witha particular pronunciation.
The HMM topology as-sumes only one, self-looping state per phone forsimplicity.
The instructor then displays on the pro-jector a likelihood for every phone for the first timeframe.
The groups work to assign the forward prob-abilities for the first frame.
Once every group is syn-chronized, the second frame of data likelihoods isdisplayed, and students then again calculate forwardprobabilities, and so forth.
After the second frame,some groups (?two?)
start to emit tokens, which areposted on the board; groups then have to also con-sider starting a new word at the third time step.
Theactivity continues for roughly ten frames, at whichpoint the global best path is found.
Including this ac-tivity has had a beneficial effect on homework per-formance: a significantly higher proportion of stu-dents across all backgrounds correctly completed anassignment to build an isolated word decoder in thisoffering of the class compared to the previous offer-ing.Some of the activities were more conceptual innature, involving reading papers or manuals anddiscussing the high-level concepts in small groups(Weeks 4 and 8), with each group reporting back tothe class.
One of the skills I hope to foster in stu-dents is the ability to pick out the main points of pa-pers during the reports back to the main group; I amstill thinking about ways to tie these activities intostrengthening the project presentations (Week 10).For the next offering of the class in the upcomingquarter, I would like to reuse the ideas developed inthe seminar to reduce the amount of lecturing.
Thestrategy I am considering is to give the students theold lecture slides as well as readings, and have thempost questions the evening before class; we can thenfocus discussion on the points they did not under-stand.
This will likely require the instructor to seedthe online pre-discussion with some of the impor-tant points from the slides.
These changes can bediscussed at the workshop.3.2 FeedbackStudent evaluations of the course were very positive;in response to ?what single aspect of the course didyou find most helpful?,?
half of the students chose torespond, and all of the responses focused on the util-ity of the hands-on practicals or homeworks.
Anec-dotally, I also felt that students were better able to re-tain the concepts presented in the course in the mostrecent offering than in previous offerings.4 SummaryIn trying to serve multiple populations of studentswith different aims and goals, I have found thatactivities can be designed that foster students?
de-velopment through team problem-solving and smallgroup work.
Online resources such as discussionboards and tutorials using software toolkits can beeffectively deployed to minimize the discrepancy inpreparations of the students.Moving away from lecture formats (either in lec-ture class or seminar presentations) has been helpfulin fostering cross-disciplinary interaction for bothseminar and lecture classes.
I have found that ac-tive learning techniques, such as the ones describedhere, provide more immediate feedback to the in-structor as to what material is understood and whatmaterial needs extra emphasis.AcknowledgmentsThe author would like to thank the anonymous studentswho agreed to have their conversations published andwhose comments appear throughout the paper, as well asMike White for providing input on the use of the seminarstrategies in other contexts.
This work was supported inpart by NSF CAREER grant IIS-0643901.
The opinionsand findings expressed here are of the author and not ofany funding agency.43ReferencesJ.P.
Campbell.
1997.
Speaker recognition: A tutorial.Proceedings of IEEE, 85:1437?1462.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proc.
18th In-ternational Conference on Machine Learning.M.
Mohri, F. Pereira, and M. Riley, 2001.
AT&T FSMLibraryTM ?
General-Purpose Finite-State MachineSoftware Tools.
AT&T, Florham Park, New Jersey.Available at http://research.att.com/?fsmtools/fsm.M.
Mohri, F. Pereira, and M. Riley.
2002.
Weightedfinite-state transducers in speech recognition.
Com-puter Speech and Language, 16(1):69?88.L.
Rabiner.
1989.
A tutorial on hidden Markov modelsand selected applications in speech recognition.
Pro-ceedings of the IEEE, 77(2).M.
Riley, J. Schalkwyk, W. Skut, C. Allauzen, andM.
Mohri.
2008.
OpenFst library.
www.openfst.org.K.
Sjo?lander and J. Beskow.
2000.
Wavesurfer ?
an opensource speech tool.
In Proceedings of ICSLP, Beijing.A.
Stolcke.
2002.
SRILM ?
an extensible languagemodeling toolkit.
In Proc.
Int?l Conf.
on Spoken Lan-guage Processing (ICSLP 2002), Denver, Colorado.J.
Vegso.
2008.
Enrollments and degree produc-tion at us cs departments drop further in 2006/2007.http://www.cra.org/wp/index.php?p=139.S.
Young, N. Russell, and J. Thornton.
1989.
To-ken passing: a simple conceptual model for connectedspeech recognition systems.
Technical Report TR-38,Cambridge University Engineering Department, Cam-bridge, England.44
