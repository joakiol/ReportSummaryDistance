Proceedings of the 4th International Workshop on Computational Terminology, pages 77?85,Dublin, Ireland, August 23 2014.Automatic Annotation of Parameters from Nanodevice DevelopmentResearch PapersThaer M. DiebGraduate school ofIST, Hokkaido Uni-versity, Sapporo,Japandiebt@kb.ist.hokudai.ac.jpMasaharu YoshiokaGraduate school ofIST, Hokkaido Uni-versity, Sapporo,Japanyoshi-oka@ist.hokudai.ac.jpShinjiro HaraRCIQE, HokkaidoUniversity, Sapporo,Japanhara@rciqe.hokudai.ac.jpMarcus C. NewtonPhysics & Astron-omy, University ofSouthampton,Southampton, UKM.C.Newton@soton.ac.ukAbstractIn utilizing nanodevice development research papers to assist in experimental planning and de-sign, it is useful to identify and annotate characteristic categories of information contained inthose papers such as source material, evaluation parameter, etc.
In order to support this annota-tion process, we have been working to construct a nanodevice development corpus and a com-plementary automatic annotation scheme.
Due to the variations of terms, however, recall of theautomatic annotation in some information categories was not adequate.In this paper, we propose to use a basic physical quantities list to extract parameter informa-tion.
We confirmed the efficiency of this method to improve the annotation of parameters.Recall for parameters increases between 4% and 7% depending on the type of parameter andanalysis metric.1   Introduction?Nanoinformatics?
is an emerging interdisciplinary research field in developing a computationalframework to support nanoscale research (Karl et al.
2004).
Nanoinformatics is the science and prac-tice of determining which information is relevant to the nanoscale science and engineering commu-nity, and then developing and implementing effective mechanisms for collecting, validating, storing,sharing, analyzing, modeling, and applying this information (De la Iglesia et al.
2011).
In order tosupport nanodevice development process, we have been working on a project that aims at analyzingthe experiment results related to nanodevice development to provide insights for nanodevice noviceresearchers to help them planning their experiments more effectively (Yoshioka et al.
2010).
In thisproject, we have proposed a framework to annotate useful information from research papers related tonanodevice development (e.g., source material, evaluation parameter, and so on), and use them foranalyzing experiment results (Dieb et al.
2011).
In order to speed up the annotation process, we havebuilt an automatic annotation framework using machine-learning techniques to annotate research pa-pers (Dieb et al.
2012).However, due to the variations of terms, this framework may miss to annotate terms that are not inthe training data set.
Therefore, we have used chemical named entity recognition system to add gener-alized feature to extract ?source material?
terms.
This generalized information is useful to extract?source material?
terms and recall of this category increased.
However, there are several other catego-ries whose recall is inadequate.This work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/77In this paper, we propose to use a physical quantities list for adding generalized feature for extract-ing parameter terms in two categories (?evaluation parameter?
and ?experiment parameter?).
In thosetwo categories, since ?experiment parameter?
represents a control parameter for the experimentalequipment and ?evaluation parameter?
represents ones measured by measuring devices, most of theterms are associated with physical quantities and they contains (a) term(s) that represent(s) its charac-teristics.
We use 2 methods for the identification: first one we try to identify parameters (experimentand evaluation) using the new automatic annotated framework.
The other one, we identify the parame-ters (in general) using the automatic annotation framework, and then classify the parameters into ex-periment and evaluation using SVM (Support Vector Machine) (Li 2005).Several attempts have been made to use dictionary to enhance machine-learning performance.
Forexample, Usi?
et al.
(2013) is using a dictionary to assist in identifying certain categories of chemicalentities in biomedical text.
Our method is using the physical quantities list to enhance the identifica-tion of parameter information.This paper has five sections.
The first one is introduction.
Second one introduces the nanodevicedevelopment papers corpus we have developed (Dieb et al, 2011) and the automatic annotationframework we have built (Dieb et al., 2012) in brief.
Section 3 discusses parameter identificationmethods.
In section 4, we demonstrate the experiment and discuss the results, and section 5 is a con-clusion.2   Automatic Annotation Framework for Nanodevice Development Papers2.1   Nanodevice Development Papers CorpusIn order to analyze experiment results related to nanodevice development, we constructed nanodevicedevelopment papers corpus that annotates characteristic information from research papers Dieb et al.(2011).
It was very critical to decide on what categories of information are necessary and adequate forthe analysis of experiment results.
Based on discussion with nanodevice development researchers, wewere able to build an abstract for a development experiment in order to define the necessary terms forthe analysis.
We have defined eight categories of information for annotation as below:?
Source Material (SMaterial) e.g., As, InGaAs?
Source Material Characteristic  (SMChar) e.g.,(111)B?
Experiment Parameter (ExP) e.g., total pressure?
Value of the Experiment parameter (ExPVal) e.g., 50 nm?
Evaluation Parameter (EvP) e.g., peak energy, FWHMs?
Value of the Evaluation Parameter (EvPVal) e.g., 1.22eV?
Manufacturing Method (MMethod) e.g., SA-MOVPE?
Final Product (TArtifact) e.g., semiconductorThe information in the papers is annotated using XML format.
Figure 1 shows an example of an an-notated paper.Fig.
1: Example of annotated paperWe demonstrate the successful formation of <TArtifact><SMChar>ferromagnetic</SMChar> <SMaterial>MnAs</SMaterial> nano-clusters </TArtifact> self-assembled on <SMaterial>GaInAs</SMaterial><SMChar> (1 1 1) B </SMChar> surfaces by <MMe-thod>metalorganic vapor phase epitaxy</MMethod><MMethod>MOVPE</MMethod>).The <TArtifact><SMChar>hexagonal</SMChar> <SMate-rial>MnAs</SMaterial>nanoclusters</TArtifact> show <EvP-Val>strong</EvPVal> <EvP>ferromagnetic coupling</EvP><ExPVal>at roomtemperature </ExPVal> when the <ExP>external magnetic fields </ExP> are ap-plied <ExPVal>in a direction parallel to the <SMate-rial>InP</SMaterial><SMChar>(1 1 1) B</SMChar> wafer planes</ExPVal>.78nanocluster ferromagnetic MnAsTArtifact SMaterial SMCharManual annotation of research papers is a time consuming process.
Papers were first annotated bygraduate students in nanodevice development domain.
Several experiments and discussions have beenheld to improve the reliability of the corpus by resolving mismatches between different annotators.Papers then were corrected manually based on discussion with annotators.
So far, we were able tocomplete five fully annotated papers, which can allow us to start our preliminary experiments concern-ing extracting and utilizing characteristic information in supporting nanodevice development.
Thesepapers are currently from the same research group (e.g., (Hara et al.
2006)).
We also started to collabo-rate with other research groups to enlarge and include different research topics related to nanodevicedevelopment.
Other information categories can be added to our model as needed along the way of thecorpus development.
Currently this corpus is still under construction, and not yet available.2.2   Automatic Annotation FrameworkIn order to speed up the annotation process that also require domain expert, we have built an automaticannotation framework using the machine learning techniques to annotate the desired categories of in-formation Dieb et al.
(2012).There are two main issues to be discussed in this automatic annotation framework:(1) Chemical entity recognition:In literature related to nanodevice development, most of the source material items are chemicalcompounds.
If large training data set is available, the machine might be able to identify source mate-rial based on the training data only with no need to additional clue.
However, since training data size isstill very small, more clues are needed to identify Source Material.
Identifying chemical entities canadd more clues and will help the machine to recognize Source Material terms.A new chemical entity recognizer called SERB-CNER (Syntactically Enhanced Rule-Based CNER)is used to enhance the identification of Source Material terms.
SERB-CNER is a rule-based chemicalentity recognizer that uses regular expressions to identify chemical compounds.
In addition to that,SERB-CNER uses syntactic rules to eliminate some mismatches that might occur between chemicalentities and general text.
(2) Overlapped term structure:In nanodevice development domain, terms sometimes can overlap within each other, and not alwayssimple.
This might be a common issue in several other domains.
Figure 2 shows an example of termoverlapping.Fig.
2 Example of overlapped term structureBecause of this overlapping between different terms, same chunk of text might have information re-lated to more than one term at the same time.
That makes it difficult for the machine to learn to set thecorrect term information all at once.
To tackle this issue, we have separated overlapped term catego-ries into four groups where terms do not overlap within other terms from the same group.
Based onthese 4 groups, the machine learning process also divided into 4 cascading levels i.e.
cascading namedentity recognition (Kano et al.
2011).For the automatic annotation framework, YamCha 0.33 (YamCha) was used, as a machine learningbased sequence labelling tools.
For the features, we use linguistic features like POS tag and orthogonalfeature.
POS tag was generated using rb tagger (rb tagger), which is A Simple Ruby Rule-Based Partof Speech Tagger based on the work of Eric Brill.
Orthogonal feature was calculated using regularexpressions.
Chemical entity feature (CM) was calculated using SERB-CNER that identifies chemicalentities as we discussed before.
Term group's features were estimated in cascading style.
In each levelof this cascading style, we apply machine-learning technique to estimate the target feature for thislevel using information estimated from previous levels.
For example, in cascading level 1, the machinewill try to estimate term group 1 (TG1) using information of {Word, POS, Orth, CM}.
In cascadinglevel two, the machine will try to estimate term group 2 (TG2) using information of {Word, POS,79Orth, CM}, and TG1 that the machine estimated in cascading level 1.
Figure 3 illustrates the cascadingstyle annotation on an example of input data in IOB format.Fig.
3 Cascading style annotation on input data for the automatic annotation frameworkWe have tested this system using only two fully annotated papers with 10 fold cross validation.
Weuse two metrics for analysis.
One is tight agreement, which takes term category and term boundaryinto consideration and the other one is loose agreement, which checks term categories only.
Table 1shows the result of the automatic annotation framework.
As we can see from the table, some catego-ries have low recall, for example, EvP and EvPVal that depends on EvP for assessment.Table 1: Automatic annotation framework performance3   Usage of Physical Quantities for Parameter Identification3.1   Basic IdeaIn the framework we proposed (Dieb et.
al, 2012), recall and precision of each categories are evalu-ated, and recall and precision of ?evaluation parameter?
(EvP) is lower than average.
One of the rea-sons about this problem is a variety of parameter terms used in the paper.
Machine learning based se-quence labelling tools is good at extracting terms that are also exists in the training data set, but it isnecessary to extract more generalized clue to identify terms that do not appear in the training data set.Tight/precisionTight/recallLoose/precisionLoose/recallSMaterial 0.99 0.96 0.99 0.96SMChar 0.89 0.69 0.89 0.69MMethod 0.93 0.86 0.95 0.88TArtifact 0.86 0.73 0.93 0.79ExP 0.91 0.81 0.97 0.86EvP 0.76 0.60 0.87 0.69ExPVal 0.72 0.57 0.85 0.67EvPVal 0.86 0.60 0.97 0.67Overall 0.89 0.76 0.94 0.80Word POS Orth CM TG1 TG2 TG3 TG4hexagonal JJ Lowercase O B-SMChar B-TArtifact O OMnAs NNP TwoCaps B-CM B-SMaterial I-TArtifact O Onanoclusters NNS Lowercase O O I-TArtifact O Oshow VBP Lowercase O O O O Ostrong JJ Lowercase O O O O B-EvPValferromagnetic JJ Lowercase O O O B-EvP ONote: POS=POS tag, Orth=orthogonal feature, CM=chemical compound, TG1, ?
TG4=term group.level 1level 2level 3level 4Input features Targetfeature80Identification of chemical named entity is helpful to extract such clue from the corpus, but it is notsufficient.As Nakagawa and Mori ?2003?
discussed, most of the compound nouns are constructed from basicnoun and identification of terms that contribute to make up compound noun is useful to extract terms.Since ?experiment parameter?
(ExP) represents a control parameter for the experimental equipmentand ?evaluation parameter?
(EvP) represents ones measured by measuring devices, most of the termsare associated with physical quantities and they contains (a) term(s) that represent(s) its characteristics.For example, ?density of the nanoclusters?
and ?height of the nanoclusters?
contains physical quantityterm ?density?
and ?height?
respectively.
Identification of physical quantities of test data may supportto extract new terms.
For example, identification of "size" as a physical quantity might support identi-fication of ?size of nanoclusters?
as a parameter.There are two types of parameters exist in this nanodevice development papers corpus; Experimentparameter that is used to control the conditions of the experiment like temperature, pressure, gas flowrate, and so on; The other type is evaluation parameter that is used to evaluate the quality of the ex-periment output like smoothness of the surface, conductivity, and so on.
In this paper, a list of physicalquantities is used to support extracting terms of those two types of parameters.3.2   Physical Quantities ListIn order to construct a list of physical quantities, we started with a basic list of physical properties ofmatter, collected by Dr. Anne Marie Helmenstine, Ph.D. in biomedical science.
1 This list includes butnot limited to the physical properties of an object.
For example, concentration, density, and so on.
Inaddition to this list, we have added several other common parameters that commonly found in nanode-vice development research papers.
For example, height, conductivity, and so on.
Additionally, wehave added several keywords that usually in close relation with parameters like ratio, rate, percentage,and so on.
We collected these keywords from research papers related to nanodevice development.
Thecompiled list then checked by nanodevice researchers as a basic list for physical quantities.3.3   Parameter ClassificationIn the automatic annotation framework, we proposed (Dieb et al, 2012), experiment and evaluationparameters (ExP and EvP) are exclusive categories and identified at the same time.
However, in thisapproach, recall and word boundary identification rate of terms is lower than SMaterial and MMethod.In order to identify good term boundaries to identify parameter terms, it is better to have large varia-tion of compound terms for representing parameter.
However, since our corpus size is limited, it isbetter to merge two parameter categories into one "Parameter" category to enlarge training examplefor making compound parameter terms.
After extracting parameter terms, another machine learningclassifier is used for categorize each extracted parameter.Since two parameter categories (ExP and EvP) represent role of parameter in the paper, it is betterto include results of dependency analysis and verbs related to the terms.
Therefore, in this paper, weuse SVM with following features to identify its category.1.
Information about termA) Surface description of the termB) lemmatized element(s) of the termC) (a) term(s) that is (are) identified as physical quantity by a physical quantities list2.
Dependency structure resultsA) First verb that given parameter terms directly dependsB) First preposition that given parameter terms directly dependsC) Lemmas that parameter terms depends.Following is example of extracted features for a sentence that contains parameter term ?tempera-ture?Figure 4 represents an example of feature extraction.
Stanford Core NLP tools are used for generat-ing dependency analysis results.
Features that start with  ?1stVB++?, ?1stIN++?, ?plemma++?, and?PAR++?
represents 2-A,B,C and 1-C respectively.
Other elements correspond to 1-A and 1-B.1 This list of physical properties of matter is available online at: http://chemistry.about.com/od/matter/a/Physical-Properties-List.htm81Fig.
4 Example of feature extraction for two parameters from a text4   Experiments4.1   SetupIn order to confirm the effectiveness of our proposed framework, we conduct automatic annotationexperiments by using nanodevice development papers corpus with following three systems.?
Base line system: we use the automatic annotation framework we previously proposed (Dieb et al.2012) without physical quantities list for parameter identification.?
Suggested system without parameter classification: we integrated the physical quantities list forparameter identification component in the automatic annotation framework.
This component can-not separate experiment (ExP) from evaluation parameter (EvP) because that depends on the con-text, so the CRF will handle this separation based on training data.?
Suggested system with parameter classification using SVM: after annotating parameters usingautomatic annotation framework with physical quantities for parameter identification componentintegrated, SVM will handle the classification of parameters using statistical data into experiment(ExP) and evaluation parameter (EvP).All systems use CRF++ (CRFpp) implementation of Conditional Random field (CRF) (John et al.2001) as the machine learning system.
Additionally, we have added one more level for the cascadingfor the SMChar term category, since we found some cases that caused overlap between SMChar andSMaterial that used to be in the same term group.
Figure 5 shows an example of the input data in IOBformat.
Since chemical compound and parameters do not overlap between each other, we use the samefeature column for both (CM is chemical entity feature, and PAR is parameter feature based on thephysical quantity list).For experiment 1: the feature CM/PAR has only CM type of values.For experiment 3: the feature TG4 has Param type of values (general parameter replaces ExP, andEvP without separation.
Classification is done independently with SVM)4.2   Results and DiscussionWe have five fully annotated papers.
In order to check the performance of these three systems, we usefive cross fold validation (training on four papers, and testing on the 5th) for each system.
We use tightand loose agreement metrics for analysis (same as explained in section 2.2).
Table 2 shows compara-tive average results for the three experiments.
In this experiment, since it is necessary to identify newterms that are only exists in one paper; recall of baseline system is lower than the value in Table 1.Statistical significance test is conducted for the difference between value of baseline system and valueof proposed system.
?*?
represents difference is statistically significant (P<0.05) in both side test.Input: The size of the MnAs nanoclusters are controllableby optimizing MOVPE growth conditions.Experiment parameter (ExP): MOVPE growth conditions?MOVPE__growth__conditions MOVPE growth conditionplemma++condition plemma++optimize 1stVB++optimizeplemma++by 1stIN++by plemma++controllablePAR++sizeEvaluation parameter (EvP): size of the MnAs nanoclusters?The__size__of__the__MnAs the size of the mnaplemma++size plemma++controllable-> controllable-JJ (root)-> size-NN (nsubj)-> The-DT (det)-> of-IN (prep)-> nanoclusters-NNS (pobj)-> the-DT (det)-> MnAs-NNS (nn)-> are-VBP (cop)-> by-IN (prep)-> optimizing-VBG (pcomp)-> conditions-NNS (dobj)-> MOVPE-NNP (nn)-> growth-NN (nn)Dependency analysis results82Fig.
5 Example of input data for our suggested systemTable 2: Performance comparison between base line system and suggested oneFrom this result, identification of physical quantities may not affect earlier stage of cascading termextraction (SMaterial, MMethod, SMChar, and TArtifact).
For both ExP and EvP, recall is increasedwhen we use physical quantities list, and increase even more when we use SVM classification.
Espe-cially for EvP, improvement of recall for loose agreement of both suggested systems are statisticallysignificant at the 5% level.
In addition, improvement of recall for tight agreement of using SVM forparameter classification is also statistically significant.
These improvements justify usage of physicalquantities list is good for improving recall of ExP and EvP.
In addition, using both examples of ExPand EvP for identification of compound word boundary is also helpful.
Even though precision of ExPand EvP are decreased from baseline system, precision of parameter term (terms that belongs to ExPor EvP) identification is almost same as baseline system.In order to evaluate detailed behaviour of our proposed system, we check the data whose annotationresults are different from baseline system and proposed system.
We confirm there are some cases inwhich new parameters terms that did not exist in training data are extracted.
For example, "tempera-ture of (MeCp)2Mn" did not exist at all in the training data, and was not able to be annotated by CRFin test data before adding physical quantities list.
After marking "temperature" as parameter, CRF wasable to find "temperature of (MeCp)2Mn" by learning compound term construction rule (i.e., PAR ofCM may be a parameter term).
On the other hand, merging parameters into one category then classify-ing them seems to be effective, because we can get use of a larger training data.
For example, "partialpressure" (where "pressure" is in the physical quantities list) did not exist in the training data.
It wasnot recognized neither by the baseline system nor by the suggested system without parameter classifi-cation; However, when we merge the parameters into one category (allowing for larger training datafor the identification of parameter), the suggested system with parameter classification was able toidentify such entity.
Another example, "period of the mask openings" where "period" is in the physicalBase line systemOur system without pa-rameter classificationOur system with parameterclassification using SVMT_pre T_rec L_pre L_rec T_pre T_rec L_pre L_rec T_pre T_rec L_pre L_recSMaterial 0.94 0.92 0.97 0.95 0.94 0.92 0.97 0.95 0.94 0.92 0.97 0.95MMethod 0.97 0.70 0.98 0.70 0.98 0.72 0.98 0.72 0.98 0.72 0.98 0.72SMChar 0.87 0.68 0.90 0.70 0.87 0.69 0.90 0.71 0.87 0.69 0.90 0.71TArtifact 0.88 0.72 0.93 0.76 0.89 0.72 0.93 0.75 0.89 0.72 0.93 0.75Param 0.67 0.45 0.86 0.58 0.67 0.49 0.87 0.64 0.66 0.52 0.85 0.67ExP 0.85 0.59 0.91 0.63 0.84 0.62 0.91 0.67 0.80 0.63 0.88 0.70EvP 0.50 0.32 0.78 0.51 0.50 0.35 0.78 0.55* 0.50 0.38* 0.76 0.57*ExPVal 0.67 0.42 0.81 0.53 0.67 0.42 0.80 0.52 0.70 0.43 0.82 0.52EvPVal 0.62 0.34 0.79 0.43 0.63 0.37 0.78 0.46 0.62 0.37 0.78 0.46overall 0.82 0.63 0.90 0.69 0.82 0.64 0.90 0.71 0.81 0.64 0.89 0.71Note: T_pre=Tight precision T_rec=Tight recall, L_pre=Loose, L_rec= Loose recall, param= general parameter resulted from mergingExP and EvPWord POS Orth CM/PAR TG1 TG2 TG3 TG4 TG5V/ NP Other O O O O B-ExP OMn NP InitCap B-CM B-SMaterial O O I-ExP Oratio NN Lowercase B-PAR O O O I-ExP Owere VBD Lowercase O O O O O O850 CD DigitNumber O O O O O B-ExPVal?C NN Other O O O O O I-ExPValNote: POS=POS tag, Orth=orthogonal feature, CM/PAR=chemical compound/parameter list, TG1, ?
TG5=term group.83quantities list.
In this example also, only the suggested system with parameter classification were ableto identify such entity using physical quantities list.Regarding the precision, there are several cases whose parameter types are difficult to identify byusing sentence information only.
For example, "diameter" can be some cases as experiment parameter,and can be evaluation parameter in other cases depending on the context.
In "the typical diameter ofthe initial circular opening" it is ExP, however, in ?diameter of the NCs", it is EvP.
Even though bothtexts have similar style, "diameter" can be of different types.
In order to improve the quality of pa-rameter type classification, it is better to use other information that cannot be extracted from one sen-tence (e.g., description of same parameter in other sentences of the same paper, position of first pa-rameter term appearance).5   Conclusion and Future DevelopmentIn this paper, we proposed to use a basic physical quantities list in combination with machine learningtechnique to improve the extraction of parameter information from research papers related to nanode-vice development.
We confirmed our proposed system improve recall of parameters between 4% and7% depending on the type of parameter and analysis metric,  and using both example of Experimentparameter and Evaluation parameter for term boundary identification is helpful.In future studies, and as further manuscripts are annotated, we plan to make use of a larger corpusthus allowing us to evaluate our system on a larger text collection.
Additionally, we are planning todevelop a new POS tagger for the nanodevice development domain.
Brill tagger is developed for gen-eral language POS tagging purposes, and changing it with specialized POS tagger might improve theresults.
It is beneficial to study the impact of each component of the system (POS tagger, the chemicalnamed entity recognizer, or the machine learning system) on the overall performance (Kolluru et al,2011)AcknowledgementsThis work was partially supported by MEXT/JSPS KAKENHI Grant Number 24240021 and26540165.ReferenceCRFpp: available online at http://crfpp.googlecode.com/svn/trunk/doc/index.htmlGPoSTTL: available online at http://gposttl.sourceforge.net.Thaer M. Dieb, Masaharu Yoshioka, and Shinjiroh Hara.
Automatic Information Extraction of Experiments fromNanodevices Development Papers, IIAIAAI 2012 Proceedings of 2012 IIAI International Conference on Ad-vanced Applied Informatics,pp.42-47,2012Thaer M. Dieb, Masaharu Yoshioka, and Shinjiroh Hara.
Construction of Tagged Corpus for Nanodevices De-velopment Papers, GrC, 2011 Proceedings of the 2011 IEEE International Conference on Granular Comput-ing, pp.
167?170, 2011.Shinjiroh Hara, and Takahashi Fukui.
Hexagonal ferromagnetic MnAs nanocluster formation on GaInAs/InP(111) B layers by metal?organic vapor phase epitaxy.
Applied Physics Letters, Vol.
89, 113111, 2006.Diana de la Iglesia, Stacey Harper, Mark D. Hoover, Fred Klaessig, Phil Lippel, Bettye Maddux, Jeff Morse,Andr?
Nel, Krishna Rajan, Rebecca Reznik-Zellen, and Mark Tuominen, (2011, Apr.).
Nanoinformatics 2020Roadmap, National Nanomanufacturing Network.
Amherst, MA 01003.
[Online].
Available:http://eprints.internano.org/607/1/Roadmap_FINAL041311.pdf, 2011.Yoshinobu Kano, Makoto Miwa, K Bretonnel  Cohen, Lawrence E Hunter, Sophia Ananiadou, and Jun'ichiTsujii.
U-Compare: a modular NLP workflow construction and evaluation system.
In IBM Journal of Re-search and Development, vol.
55, no.
3, pp.
11:1-11:10, 2011.BalaKrishna Kolluru, Lezan Hawizy, Peter Murray-Rust, Junichi Tsujii, Sophia Ananiadou.
Using Workflows toExplore and Optimise Named Entity Recognition for Chemistry.
PLoS ONE, 6(5), 2011.
DOI:10.1371/journal.pone.002018184John D Lafferty, Andrew McCallum, Fernando Pereira.
Conditional random fields: Probabilistic models forsegmenting and labeling sequence data.
In Proceedings of the Eighteenth International Conference on Ma-chine Learning.
ICML ?01, San Francisco, CA, USA, Morgan Kaufmann Publishers Inc. (2001) 282?289Yaoyong Li, Kalina Bontcheva, Hamish Cunningham SVM-based learning system for information extraction.
InProceedings of the First international conference on Deterministic and Statistical Methods in Machine Learn-ing, pp.
319?339, 2005.Hiroshi Nakagawa and Tatsunori Mori: Automatic term recognition based on statistics of compound nouns andtheir components, In Terminology, Vol.
9, No.
2, pp.
201-219, 2003rb tagger: available online at http://rbtagger.rubyforge.org/Karl Ruping and Woody Sherman.
Nanoinformatics: Emerging computational tools in nanoscale research.
InTechnical Proceedings of the 2004 NSTI Nanotechnology Conference and Trade Show, Volume 3, pp.
525?528, 2004Anabel Usi?, Joaquim Cruz, Jorge Comas, Francesc Solsona, Rui Alves.
A tool for the identification of chemicalentities (CheNER-BioC).
Proceedings of the Fourth BioCreative Challenge Evaluation Workshop vol.
2 ,66-69 (2013)YamCha : available on line at http://chasen.org/ taku/software/yamcha/.Masaharu Yoshioka, Katsuhiro Tomioka, Shinjiroh Hara, and Takahashi Fukui.
Knowledge exploratory projectfor nanodevice design and manuacturing.
In iiWAS ?10 Proceedings of the 12th International Conference onInformation Integration and Web-based Application & Services, pp.
869-872, 2010.85
