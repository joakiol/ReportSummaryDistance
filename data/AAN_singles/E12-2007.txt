Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 31?34,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsJust Title It!
(by an Online Application)Ce?dric Lopez, Violaine Prince, and Mathieu RocheLIRMM, CNRS, University of Montpellier 2161, rue AdaMontpellier, France{lopez,prince,mroche}@lirmm.frAbstractThis paper deals with an application of au-tomatic titling.
The aim of such applicationis to attribute a title for a given text.
So,our application relies on three very differ-ent automatic titling methods.
The first oneextracts relevant noun phrases for their useas a heading, the second one automaticallyconstructs headings by selecting words ap-pearing in the text, and, finally, the thirdone uses nominalization in order to proposeinformative and catchy titles.
Experimentsbased on 1048 titles have shown that ourmethods provide relevant titles.1 IntroductionThe important amount of textual documents isin perpetual growth and requires robust applica-tions.
Automatic titling is an essential task forseveral applications: Automatic titling of e-mailswithout subjects, text generation, summarization,and so forth.
Furthermore, a system able to ti-tle HTML documents and so, to respect one ofthe W3C standards about Web site accessibility,is quite useful.
The titling process goal is to pro-vide a relevant representation of a document con-tent.
It might use metaphors, humor, or emphasis,thus separating a titling task from a summariza-tion process, proving the importance of the rhetor-ical status in both tasks.This paper presents an original application con-sisting in titling all kinds of texts.
For that pur-pose, our application offers three main meth-ods.
The first one (called POSTIT) extracts nounphrases to be used as headings, the second one(called CATIT) automatically builds titles by se-lecting words appearing in the text, and, finally,the third one (called NOMIT) uses nominalizationin order to propose relevant titles.
Morphologicand semantic treatments are applied to obtain ti-tles close to real titles.
In particular, titles have torespect two characteristics: Relevance and catch-iness.2 Text Titling ApplicationThe application presented in this paper was de-veloped with PHP, and it is available on theWeb1.
It is based on several methods using Nat-ural Language Processing (NLP) and InformationRetrieval (IR) techniques.
So, the input is a textand the output is a set of titles based on differentkinds of strategies.A single automatic titling method is not suffi-cient to title texts.
Actually, it cannot respect di-versity, noticed in real titles, which vary accord-ing to the writer?s personal interests or/and his/herwriting style.
With the aim of getting closer to thisvariety, the user can choose the more relevant titleaccording to his personal criteria among a list oftitles automatically proposed by our system.A few other applications have focused on ti-tling: One of the most typical, (Banko, 2000),consists in generating coherent summaries thatare shorter than a single sentence.
These sum-maries are called ?headlines?.
The main diffi-culty is to adjust the threshold (i.e, the headlinelength), in order to obtain syntactically correcttitles.
Whereas our methods create titles whichare intrinsically correct, both syntactically and se-mantically.In this section, we present the POSTIT, CATIT,and NOMIT methods.
These three methods run1https://www2.lirmm.fr/?lopez/Titrage_general/31in parallel, without interaction with each other.Three very different titles are thus determined forevery text.
For each of them, an example of theproduced title is given on the following sampletext: ?In her speech, Mrs Merkel has promisedconcrete steps towards a fiscal union - in effectclose integration of the tax-and-spend polices ofindividual eurozone countries, with Brussels im-posing penalties on members that break the rules.[...]?.
Even if examples are in English, the ap-plication is actually in French (but easily repro-ducible in English).
The POS tagging was per-formed by Sygfran (Chauche?, 1984).2.1 POSTIT(Jin, 2001) implemented a set of title generationmethods and evaluated them: The statistical ap-proach based on the TF-IDF obtains the best re-sults.
In the same way, the POSTIT (Titling usingPosition and Statistical Information) method usesstatistical information.
Related works have shownthat verbs are not as widely spread as nouns,named entities, and adjectives (Lopez, 2011a).Moreover, it was noticed that elements appearingin the title are often present in the body of the text(Zajic et al 2002).
(Zhou and Hovy, 2003) sup-ports this idea and shows that the covering rate ofthose words present in titles, is very high in thefirst sentences of a text.
So, the main idea is toextract noun phrases from the text and to selectthe more relevant for its use as title.
The POSTITapproach is composed of the following steps:1.
Candidate Sentence Determination.
We as-sume that any text contains only a few rel-evant sentences for titling.
The goal of thisstep consists in recognizing them.
Statisticalanalysis shows that, very often, terms usefulfor titling are located in the first sentences ofthe text.2.
Extracting Candidate Noun Phrases for Ti-tling.
This step uses syntactical filters re-lying on the statistical studies previouslyled.
For that purpose, texts are tagged withSygfran.
Our syntactical patterns allowingnoun phrase extraction are also inspired from(Daille, 1996).3.
Selecting a Title.
Last, candidate nounphrases (t) are ranked according to a scorebased on the use of TF-IDF and informationabout noun phrase position (NPPOS) (seeLopez, 2011a).
With ?
= 0.5, this methodobtains good results (see Formula 1).NPscore(t) = ?
?NPPOS(t)+ (1?
?
)?NPTF?IDF (t) (1)Example of title with POSTIT: Concrete stepstowards a fiscal union.On one hand, this method proposes titles whichare syntactically correct.
But on the other hand,provided titles can not be considered as original.Next method, called CATIT, enables to generatemore ?original?
titles.2.2 CATITCATIT (Automatic Construction of Titles) is anautomatic process that constructs short titles.
Ti-tles have to show coherence with both the text andthe Web, as well as with their dynamic context(Lopez, 2011b).
This process is based on a globalapproach consisting in three main stages:1.
Generation of Candidates Titles.
The pur-pose is to extract relevant nouns (using TF-IDF criterion) and adjectives (using TF cri-terion) from the text.
Potential relevant cou-ples (candidate titles) are built respecting the?Noun Adjective?
and/or ?Adjective Noun?syntactical patterns.2.
Coherence of Candidate Titles.
Among thelist of candidate titles, which ones are gram-matically and semantically consistent ?
Theproduced titles are supposed to be consis-tent with the text through the use of TF-IDF.
To reinforce coherence, we set up adistance coefficient between a noun and anadjective which constitutes a new coherencecriterion in candidate titles.
Besides, the fre-quency of appearance of candidate titles onthe Web (with Dice measure) is used in orderto measure the dependence between the nounand the adjective composing a candidate ti-tle.
This method thus automatically favorswell-formed candidates.3.
Dynamic Contextualization of Candidate Ti-tles.
To determine the most relevant candi-date title, the text context is compared withthe context in which these candidates are met32on the Web.
They are both modeled as vec-tors, according to Salton?s vector model.Example of title with CATIT: Fiscal penalties.The automatic generation of titles is a complextask because titles have to be coherent, grammat-ically correct, informative, and catchy.
These cri-teria are a brake in the generation of longer ti-tles (being studied).
That is why we suggest anew approach consisting in reformulating rele-vant phrases in order to determine informative andcatchy ?long?
titles.2.3 NOMITBased on statistical analysis, NOMIT (Nominal-ization for Titling) provides original titles relyingon several rules to transform a verbal phrase in anoun phrase.1.
Extracting Candidates.
First step consists inextracting segments of phrases which con-tain a past participle (in French).
For exam-ple: In her speech, Mrs Merkel has promised?concrete steps towards a fiscal union?
-in effect close integration of the tax-and-spend polices of individual eurozone coun-tries, with Brussels imposing penalties onmembers that break the rules.2.
Linguistic Treatment.
The linguistic treat-ment of the segments retained in the previousstep consists of two steps aiming at nominal-izing the ?auxiliary + past participle?
form(very frequent in French).
First step consistsin associating a noun for each past participle.Second step uses transforming rules in orderto obtain nominalized segments.
For exam-ple: has promised?
promise.3.
Selecting a Title.
Selection of the most rel-evant title relies on a Web validation.
Theinterest of this validation is double.
On onehand, the objective is to validate the connec-tion between the nominalized past partici-ple and the complement.
On the other hand,the interest is to eliminate incorrect semanticconstituents or not popular ones (e.g., ?an-nunciation of the winners ?
), to prefer thosewhich are more popular on Web (e.g.
, ?an-nouncement of the winners?
).Figure 1: Screenshot of Automatic Titling EvaluationExample of title with NOMIT: Mrs Merkel:Promise of a concrete step towards a fiscal union.This method enables to obtain even more orig-inal titles than the previous one (i.e.
CATIT).A positive aspect is that new transforming rulescan be easily added in order to respect morpho-syntactical patterns of real titles.3 Evaluations3.1 Protocol DescriptionAn online evaluation has been set up, accessi-ble to all people (cf.
Figure 1)2.
The benefit ofsuch evaluation is to compare different automaticmethods according to several judgements.
So, foreach text proposed to the human user, several ti-tles are presented, each one resulting from one ofthe automatic titling methods presented in this pa-per (POSTIT, CATIT, and NOMIT).
Furthermore,random titles stemming from CATIT and POSTITmethods are evaluated (CATIT-R, and POSTIT-R), i.e., candidate titles built by our methods butnot selected because of their bad score.
The ideais to measure the efficiency of our ranking func-tions.This evaluation is run on French articles stem-ming from the daily newspaper ?Le Monde?.
Weretained the first article published every day forthe year 1994, up to a total of 200 journalistic ar-ticles.
190 people have participated to the onlineexperiment, evaluating a total of 1048 titles.
Onaverage, every person has evaluated 41 titles.
Ev-ery title has been evaluated by several people (be-tween 2 and 10).
The total number of obtainedevaluations is 7764.2URL: http://www2.lirmm.fr/?lopez/Titrage_general/evaluation_web2/333.2 ResultsResults of this evaluation indicate that the mostadapted titling method for articles is NOMIT.
Thisone enables to title 82.7% of texts in a relevantway (cf.
Table 1).
However, NOMIT does not de-termine titles for all the texts (in this evaluation,NOMIT determined a title for 58 texts).
Indeed,if no past participle is present in the text, there isno title returned with this method.
It is thus essen-tial to consider the other methods which assure atitle for every text.
POSTIT enables to title 70%of texts in a relevant way.
It is interesting to notethat both gathered methods POSTIT and NOMITprovide at least one relevant title for 74 % of texts(cf.
Table 2).
Finally, even if CATIT obtains aweak score, this method provides a relevant titlewhere POSTIT and NOMIT are silent.
So, thesethree gathered methods propose at least one rele-vant title for 81% of journalistic articles.Concerning catchiness, the three methods seemequivalent, proposing catchy titles for approxi-mately 50% of texts.
The three gathered methodspropose at least one catchy title for 78% of texts.Real titles (RT) obtain close score (80.5%).% POSTIT POSTIT-R CATIT CATIT-R NOMIT RTVery relevant (VR) 39.1 16.4 15.7 10.3 60.3 71.4Relevant (R) 30.9 22.3 21.3 14.5 22.4 16.4(VR) and (R) 70.0 38.7 37.0 24.8 82.7 87.8Not relevant 30.0 61.4 63.0 75.2 17.2 12.3Catchy 49.1 30.9 47.2 32.2 53.4 80.5Not catchy 50.9 69.1 52.8 67.8 46.6 19.5Table 1: Average scores of our application.% POSTIT & NOMIT POSTIT & CATIT NOMIT & CATIT POSTIT, CATIT, & NOMIT(VR) 47 46 28 54(R) or (VR) 74 78 49 81Catchy 57 73 55 78Table 2: Results of gathered methods.Also, let us note that our ranking functionsare relevant since CATIT-R and POSTIT-R obtainweak results compared with CATIT and POSTIT.4 ConclusionsIn this paper, we have compared the efficiency ofthree methods using various techniques.
POSTITuses noun phrases extracted from the text, CATITconsists in constructing short titles, and NOMITuses nominalization.
We proposed three differentmethods to approach the real context.
Two per-sons can propose different titles for the same text,depending on personal criteria and on its own in-terests.
That is why automatic titling is a complextask as much as evaluation of catchiness whichremains subjective.
Evaluation shows that our ap-plication provides relevant titles for 81% of textsand catchy titles for 78 % of texts.
These re-sults are very encouraging because real titles ob-tain close results.A future work will consist in taking into ac-count a context defined by the user.
For exam-ple, the generated titles could depend on a polit-ical context if the user chooses to select a giventhread.
Furthermore, an ?extended?
context, au-tomatically determined from the user?s choice,could enhance or refine user?s desiderata.A next work will consist in adapting this appli-cation for English.ReferencesMichele Banko, Vibhu O. Mittal, and Michael J Wit-brock.
1996.
Headline generation based on statisti-cal translation.
COLING?96.
p. 318?325.Jacques Chauche?.
1984.
Un outil multidimensionnelde l?analyse du discours.
COLING?84.
p. 11-15.Be?atrice Daille.
1996.
Study and implementationof combined techniques for automatic extraction ofterminology.
The Balancing Act: Combining Sym-bolic and Statistical Approaches to language.
p. 29-36.Rong Jin, and Alexander G. Hauptmann.
1996.
Au-tomatic title generation for spoken broadcast news.Proceedings of the first international conference onHuman language technology research.
p. 1?3.Ce?dric Lopez, Violaine Prince, and Mathieu Roche.2011.
Automatic titling of Articles Using Positionand Statistical Information.
RANLP?11.
p. 727-732.Ce?dric Lopez, Violaine Prince, and Mathieu Roche.2011.
Automatic Generation of Short Titles.LTC?11.
p. 461-465.Gerard Salton and Christopher Buckley.
1988.
Term-weighting approaches in automatic text retrieval.Information Processing and Management 24. p.513-523.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
International Confer-ence on New Methods in Language Processing.
p.44-49.Franck Smadja, Kathleen R. McKeown, and VasileiosHatzivassiloglou.
1996.
Translating collocationsfor bilingual lexicons: A statistical approach.
Com-putational linguistics, 22(1).
p. 1-38.David Zajic, Bonnie Door, and Rich Schwarz.
2002.Automatic headline generation for newspaper sto-ries.
ACL 2002.
Philadelphia.Liang Zhou and Eduard Hovy.
2002.
Headline sum-marization at ISI.
DUC 2003.
Edmonton, Alberta,Canada.34
