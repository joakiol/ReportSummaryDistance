TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 1?8,Rochester, April 2007 c?2007 Association for Computational LinguisticsAnalysis of the Wikipedia Category Graph for NLP ApplicationsTorsten Zesch and Iryna GurevychUbiquitous Knowledge Processing GroupTelecooperation DivisionDarmstadt University of Technology, Hochschulstra?e 10D-64289 Darmstadt, Germany{zesch,gurevych} (at) tk.informatik.tu-darmstadt.deAbstractIn this paper, we discuss two graphs inWikipedia (i) the article graph, and (ii)the category graph.
We perform a graph-theoretic analysis of the category graph,and show that it is a scale-free, smallworld graph like other well-known lexi-cal semantic networks.
We substantiateour findings by transferring semantic re-latedness algorithms defined on WordNetto the Wikipedia category graph.
To as-sess the usefulness of the category graphas an NLP resource, we analyze its cover-age and the performance of the transferredsemantic relatedness algorithms.1 IntroductionWikipedia1 is a free multi-lingual online encyclo-pedia that is constructed in a collaborative effortof voluntary contributors and still grows exponen-tially.
During this process, Wikipedia has proba-bly become the largest collection of freely availableknowledge.
A part of this knowledge is encoded inthe network structure of Wikipedia pages.
In par-ticular, Wikipedia articles form a network of seman-tically related terms, while the categories are orga-nized in a taxonomy-like structure calledWikipediaCategory Graph (WCG).In this paper, we perform a detailed analysis ofthe WCG by computing a set of graph-theoretic pa-rameters, and comparing them with the parametersreported for well-known graphs and classical lexicalsemantic networks.
We show that the WCG, whichis constructed collaboratively, shares many proper-ties with other lexical semantic networks, such as1http://www.wikipedia.orgC 1C 2C 3C 4C 5A 1A 2A 3A 4WCGArticle GraphFigure 1: Relations between article graph andWCG.WordNet (Fellbaum, 1998) or Roget?s Thesaurus2that are constructed by expert authors.
This impliesthat the WCG can be used as a resource in NLP ap-plications, where other semantic networks have beentraditionally employed.To further evaluate this issue, we adapt algorithmsfor computing semantic relatedness on classical se-mantic networks like WordNet to the WCG.
Weevaluate their performance on the task of computingsemantic relatedness using three German datasets,and show that WCG based algorithms perform verywell.Article graph Wikipedia articles are heavilylinked, as links can be easily inserted while editingan article.
If we treat each article as a node, andeach link between articles as an edge running fromone node to another, then Wikipedia articles forma directed graph (see right side of Figure 1).
Thearticle graph has been targeted by numerous stud-ies, and is not addressed in this paper.
Buriol et al(2006) analyze the development of the article graphover time, and find that some regions are fairly sta-ble, while others are advancing quickly.
Zlatic et al2http://thesaurus.reference.com1Figure 2: Structures of semantic networks after Steyvers and Tenenbaum (2005).
a) a taxonomy, b) anarbitrary graph, c) scale-free, small-world graph.
(2006) give a comprehensive overview of the graphparameters for the largest languages in Wikipedia.Capocci et al (2006) study the growth of the articlegraph and show that it is based on preferential at-tachment (Barabasi and Albert, 1999).
Voss (2005)shows that the article graph is scale-free and growsexponentially.Category graph Categories in Wikipedia are or-ganized in a taxonomy-like structure (see left side ofFigure 1 and Figure 2-a).
Each category can have anarbitrary number of subcategories, where a subcate-gory is typically established because of a hyponymyor meronymy relation.
For example, a category ve-hicle has subcategories like aircraft or watercraft.Thus, the WCG is very similar to semantic word-nets like WordNet or GermaNet (Kunze, 2004).
AsWikipedia does not strictly enforce a taxonomic cat-egory structure, cycles and disconnected categoriesare possible, but rare.
In the snapshot of the Ger-manWikipedia3 fromMay 15, 2006, the largest con-nected component in the WCG contains 99,8% of allcategory nodes, as well as 7 cycles.In Wikipedia, each article can link to an arbitrarynumber of categories, where each category is a kindof semantic tag for that article.
A category back-links to all articles in this category.
Thus, articlegraph and WCG are heavily interlinked (see Fig-ure 1), and most studies (Capocci et al, 2006; Zlaticet al, 2006) have not treated them separately.
How-ever, the WCG should be treated separately, as itdiffers from the article graph.
Article links are es-tablished because of any kind of relation between3Wikipedia can be downloaded from http://download.wikimedia.org/articles, while links between categories are typicallyestablished because of hyponymy or meronymy re-lations.Holloway et al (2005) create and visualize a cat-egory map based on co-occurrence of categories.Voss (2006) pointed out that the WCG is a kind ofthesaurus that combines collaborative tagging andhierarchical indexing.
Zesch et al (2007a) identifiedthe WCG as a valueable source of lexical semanticknowledge, but did not analytically analyze its prop-erties.
However, even if the WCG seems to be verysimilar to other semantic wordnets, a graph-theoreticanalysis of the WCG is necessary to substantiate thisclaim.
It is carried out in the next section.2 Graph-theoretic Analysis of the WCGA graph-theoretic analysis of the WCG is requiredto estimate, whether graph based semantic related-ness measures developed for semantic wordnets canbe transferred to the WCG.
This is substantiated ina case study on computing semantic relatedness insection 4.For our analysis, we treat the directed WCG asan undirected graph G := (V,E),4 as the relationsconnecting categories are reversible.
V is a set ofvertices or nodes.
E is a set of unordered pairs ofdistinct vertices, called edges.
Each page is treatedas a node n, and each link between pages is modeledas an edge e running between two nodes.Following Steyvers and Tenenbaum (2005), wecharacterize the graph structure of a lexical semanticresource in terms of a set of graph parameters: The4Newman (2003) gives a comprehensive overview about thetheoretical aspects of graphs.2PARAMETER Actor Power C.elegans AN Roget WordNet WikiArt WCG|V | 225,226 4,941 282 5,018 9,381 122,005 190,099 27,865D - - - 5 10 27 - 17k 61.0 2.67 14.0 22.0 49.6 4.0 - 3.54?
- - - 3.01 3.19 3.11 2.45 2.12L 3.65 18.7 2.65 3.04 5.60 10.56 3.34 7.18Lrandom 2.99 12.4 2.25 3.03 5.43 10.61 ?
3.30 ?
8.10C 0.79 0.08 0.28 0.186 0.87 0.027 ?
0.04 0.012Crandom 0.0003 0.005 0.05 0.004 0.613 0.0001 ?
0.006 0.0008Table 1: Parameter values for different graphs.Values for Actor (collaboration graph of actors in feature films), Power (the electrical power grid of the western UnitedStates) andC.elegans (the neural network of the nematode worm C. elegans) are fromWatts and Strogatz (1998).
Valuesfor AN (a network of word associations by Nelson et al (1998)), Roget?s thesaurus and WordNet are from Steyversand Tenenbaum (2005).
Values for Wikiart (German Wikipedia article graph) are from Zlatic et al (2006).
We tookthe values for the page set labelled M on their website containing 190,099 pages for German, as it comes closest to agraph of only articles.
Values marked with ?-?
in the table were not reported in the studies.
The values for the WCG arecomputed in this study.degree k of a node is the number of edges that areconnected with this node.
Averaging over all nodesgives the average degree k. The degree distributionP (k) is the probability that a random node will havedegree k. In some graphs (like the WWW), the de-gree distribution follows a power law P (k) ?
k??
(Barabasi and Albert, 1999).
We use the power lawexponent ?
as a graph parameter.A path pi,j is a sequence of edges that connectsa node ni with a node nj .
The path length l(pi,j)is the number of edges along that path.
There canbe more than one path between two nodes.
Theshortest path length L is the minimum of all thesepaths, i.e.
Li,j = min l(pi,j).
Averaging over allnodes gives the average shortest path length L.The diameterD is the maximum of the shortest pathlengths between all pairs of nodes in the graph.The cluster coefficient of a certain node ni canbe computed asCi =Tiki(ki?1)2=2Tiki(ki ?
1)where Ti refers to the number of edges between theneighbors of node ni and ki(ki ?
1)/2 is the maxi-mum number of edges that can exist between the kineighbors of node ni.5 The cluster coefficient C forthe whole graph is the average of all Ci.
In a fullyconnected graph, the cluster coefficient is 1.5In a social network, the cluster coefficient measures howmany of my friends (neighboring nodes) are friends themselves.For our analysis, we use a snapshot of the GermanWikipedia fromMay 15, 2006.
We consider only thelargest connected component of the WCG that con-tains 99,8% of the nodes.
Table 1 shows our resultson the WCG as well as the corresponding values forother well-known graphs and lexical semantic net-works.
We compare our empirically obtained valueswith the values expected for a random graph.
Fol-lowing Zlatic et al (2006), the cluster coefficient Cfor a random graph isCrandom =(k2?
k)2|V |kThe average path length for a random network canbe approximated as Lrandom ?
log |V | / log k(Watts and Strogatz, 1998).From the analysis, we conclude that all graphsin Table 1 are small world graphs (see Figure 2-c).Small world graphs (Watts and Strogatz, 1998) con-tain local clusters that are connected by some longrange links leading to low values of L and D. Thus,small world graphs are characterized by (i) smallvalues of L (typically L & Lrandom), together with(ii) large values of C (C  Crandom).Additionally, all semantic networks are scale-freegraphs, as their degree distribution follows a powerlaw.
Structural commonalities between the graphsin Table 1 are assumed to result from the growingprocess based on preferential attachment (Capocciet al, 2006).3Our analysis shows that WordNet and the WCGare (i) scale-free, small world graphs, and (ii) have avery similar parameter set.
Thus, we conclude thatalgorithms designed to work on the graph structureof WordNet can be transferred to the WCG.In the next section, we introduce the task of com-puting semantic relatedness on graphs and adapt ex-isting algorithms to the WCG.
In section 4, we eval-uate the transferred algorithms with respect to corre-lation with human judgments on SR, and coverage.3 Graph Based Semantic RelatednessMeasuresSemantic similarity (SS) is typically defined via thelexical relations of synonymy (automobile ?
car)and hypernymy (vehicle ?
car), while semantic re-latedness (SR) is defined to cover any kind of lexi-cal or functional association that may exist betweentwo words (Budanitsky and Hirst, 2006).
Dissimi-lar words can be semantically related, e.g.
via func-tional relationships (night ?
dark) or when they areantonyms (high ?
low).
Many NLP applications re-quire knowledge about semantic relatedness ratherthan just similarity (Budanitsky and Hirst, 2006).We introduce a number of competing approachesfor computing semantic relatedness between wordsusing a graph structure, and then discuss the changesthat are necessary to adapt semantic relatedness al-gorithms to work on the WCG.3.1 Wordnet Based MeasuresA multitude of semantic relatedness measures work-ing on semantic networks has been proposed.Rada et al (1989) use the path length (PL) be-tween two nodes (measured in edges) to computesemantic relatedness.distPL = l(n1, n2)Leacock and Chodorow (1998, LC) normalize thepath-length with the depth of the graph,simLC(n1, n2) = ?
logl(n1, n2)2?
depthwhere depth is the length of the longest path in thegraph.Wu and Palmer (1994, WP) introduce a measurethat uses the notion of a lowest common subsumer oftwo nodes lcs(n1, n2).
In a directed graph, a lcs isthe parent of both child nodes with the largest depthin the graph.simWP =2 depth(lcs)l(n1, lcs) + l(n2, lcs) + 2 depth(lcs)Resnik (1995, Res), defines semantic similarity be-tween two nodes as the information content (IC)value of their lcs.
He used the relative corpus fre-quency to estimate the information content value.Jiang and Conrath (1997, JC) additionally use theIC of the nodes.distJC(n1, n2) = IC(n1) + IC(n2)?
2IC(lcs)Note that JC returns a distance value instead of asimilarity value.Lin (1998, Lin) defined semantic similarity usinga formula derived from information theory.simLin(n1, n2) = 2?IC(lcs)IC(n1) + IC(n2)Because polysemous words may have more thanone corresponding node in a semantic wordnet, theresulting semantic relatedness between two wordsw1 and w2 can be calculated asSR =????
?minn1?s(w1),n2?s(w2)dist(n1, n2) pathmaxn1?s(w1),n2?s(w2)sim(n1, n2) ICwhere s(wi) is the set of nodes that represent sensesof word wi.
That means, the relatedness of twowords is equal to that of the most related pair ofnodes.3.2 Adapting SR Measures to WikipediaUnlike other wordnets, nodes in the WCG do notrepresent synsets or single terms, but a general-ized concept or category.
Therefore, we cannot usethe WCG directly to compute SR. Additionally, theWCG would not provide sufficient coverage, as it isrelatively small.
Thus, transferring SR measures tothe WCG requires some modifications.
The task ofestimating SR between terms is casted to the taskof SR between Wikipedia articles devoted to theseterms.
SR between articles is measured via the cate-gories assigned to these articles.4ORX X+1 X X+1XX+1X+1XX+1X+1XX+1X+1Figure 3: Breaking cycles in the WCG.We define C1 and C2 as the set of categories as-signed to article ai and aj , respectively.
We then de-termine the SR value for each category pair (ck, cl)with ck ?
C1 and cl ?
C2.
We choose the bestvalue among all pairs (ck, cl), i.e.
the minimum forpath based and the maximum for information con-tent based measures.SRbest =??
?minck?C1,cl?C2(sr(ck, cl)) path basedmaxck?C1,cl?C2(sr(ck, cl)) IIC basedSee (Zesch et al, 2007b) for a more detailed descrip-tion of the adaptation process.We substitute Resnik?s information content withthe intrinsic information content (IIC) by Seco etal.
(2004) that is computed only from structural in-formation of the underlying graph.
It yields betterresults and is corpus independent.
The IIC of a nodeni is computed as a function of its hyponyms,IIC(n) = 1?log(hypo(ni) + 1log(|C|)where hypo(ni) is the number of hyponyms of nodeni and |C| is the number of nodes in the taxonomy.Efficiently counting the hyponyms of a node re-quires to break cycles that may occur in a WCG.We perform a colored depth-first-search to detect cy-cles, and break them as visualized in Figure 3.
Alink pointing back to a node closer to the top of thegraph is deleted, as it violates the rule that links inthe WCG typically express hyponymy or meronymyrelations.
If the cycle occurs between nodes on thesame level, we cannot decide based on that rule andsimply delete one of the links running on the samelevel.
This strategy never disconnects any nodesfrom a connected component.4 Semantic Relatedness ExperimentsA commonly accepted method for evaluating SRmeasures is to compare their results with a gold stan-dard dataset based on human judgments on wordpairs.64.1 DatasetsTo create gold standard datasets for evaluation, hu-man annotators are asked to judge the relatedness ofpresented word pairs.
The average annotation scoresare correlated with the SR values generated by a par-ticular measure.Several datasets for evaluation of semantic re-latedness or semantic similarity have been createdso far (see Table 2).
Rubenstein and Goodenough(1965) created a dataset with 65 English noun pairs(RG65 for short).
A subset of RG65 has beenused for experiments by Miller and Charles (1991,MC30) and Resnik (1995, Res30).Finkelstein et al (2002) created a larger datasetfor English containing 353 pairs (Fin353), that hasbeen criticized by Jarmasz and Szpakowicz (2003)for being culturally biased.
More problematic is thatFin353 consists of two subsets, which have been an-notated by a different number of annotators.
We per-formed further analysis of their dataset and foundthat the inter-annotator agreement7 differs consider-ably.
These results suggest that further evaluationbased on this data should actually regard it as twoindependent datasets.As Wikipedia is a multi-lingual resource, we arenot bound to English datasets.
Several Germandatasets are available that are larger than the exist-ing English datasets and do not share the problemsof the Finkelstein datasets (see Table 2).
Gurevych(2005) conducted experiments with a German trans-lation of an English dataset (Rubenstein and Good-enough, 1965), but argued that the dataset is toosmall and only contains noun-noun pairs connected6Note that we do not use multiple-choice synonym questiondatasets (Jarmasz and Szpakowicz, 2003), as this is a differenttask, which is not addressed in this paper.7We computed the correlation for all annotators pairwise andsummarized the values using a Fisher Z-value transformation.5CORRELATION rDATASET YEAR LANGUAGE # PAIRS POS TYPE SCORES # SUBJECTS INTER INTRARG65 1965 English 65 N SS continuous 0?4 51 - .850MC30 1991 English 30 N SS continuous 0?4 38 - -Res30 1995 English 30 N SS continuous 0?4 10 .903 -Fin353 2002 English 353 N, V, A SR continuous 0?10 13/16 - -153 13 .731 -200 16 .549 -Gur65 2005 German 65 N SS discrete {0,1,2,3,4} 24 .810 -Gur350 2006 German 350 N, V, A SR discrete {0,1,2,3,4} 8 .690 -ZG222 2006 German 222 N, V, A SR discrete {0,1,2,3,4} 21 .490 .647Table 2: Comparison of German datasets used for evaluating semantic relatedness.by either synonymy or hyponymy.
Thus, she cre-ated a larger German dataset containing 350 wordpairs (Gur350).
It contains nouns, verbs and ad-jectives that are connected by classical and non-classical relations (Morris and Hirst, 2004).
How-ever, word pairs for this dataset are biased to-wards strong classical relations, as they were man-ually selected.
Thus, Zesch and Gurevych (2006)used a semi-automatic process to create word pairsfrom domain-specific corpora.
The resulting ZG222dataset contains 222 word pairs that are connectedby all kinds of lexical semantic relations.
Hence, itis particularly suited for analyzing the capability ofa measure to estimate SR.4.2 Results and DiscussionFigure 4 gives an overview of our experimental re-sults of evaluating SR measures based on the WCGon three German datasets.
We use Pearson?s prod-uct moment correlation r to compare the results withhuman judgments.
From each dataset, we only useword pairs where Wikipedia articles correspondingto these words are available (see section 4.3 for a de-tailed discussion of word pair coverage).
For com-parison, we give the best results obtained by Ger-maNet based measures (abbreviated as GN).8Our results show that the graph-based SR mea-sures have been successfully transferred to theWCG.
Results on the Gur65 dataset (containing onlyword pairs connected by strong classical relations)are lower than values computed using GermaNet.This is to be expected, as the WCG is created col-laboratively without strictly enforcing a certain type8Additionally, Table 2 gives the inter annotator agreementfor each subset.
It constitutes an upper bound of a measure?sperformance on a certain dataset.0.000.200.400.600.80Correlationr0.750.500.420.510.340.450.35GNResJCLinPLWPLCGur650.000.200.400.600.80Correlationr0.500.440.410.450.550.520.39GNResJCLinPLWPLCGur3500.000.200.400.600.80Correlationr0.300.320.430.350.500.450.36GNResJCLinPLWPLCZG222Figure 4: Correlations on different datasets.6of semantic relation between categories, while Ger-maNet is carefully modelled to represent the strongclassical relations captured by Gur65.
Results on thetwo other datasets, which contain a majority of wordpairs connected by non-classical semantic relations,show that the WCG is better suited than GermaNetto estimate SR.Performance of WCG based measures depends onthe dataset and the kind of knowledge used.
IICbased measures (Res, JC and Lin) outperform pathbased measures (PL, LC and WP ) on the Gur65dataset, while path based measures are clearly bet-ter on SR datasets (Gur350 and ZG222).
The im-pressive performance of the simple PL measure onthe SR datasets cannot be explained with the struc-tural properties of the WCG, as they are very similarto those of other semantic networks.
Semanticallyrelated terms are very likely to be categorized un-der the same category, resulting in short path lengthsleading to high SR.
The generalization process thatcomes along with classification seems to capture thephenomenon of SR quite well.
As each article canhave many categories, different kinds of semanticrelations between terms can be established, but thetype of relation remains unknown.4.3 Coverage of Word PairsIf the WCG is to be used as a lexical semantic re-source in large scale NLP applications, it shouldprovide broad coverage.
As was described in sec-tion 3.2, computing SR using the WCG relies oncategories assigned to articles.
Thus, we considera word to be covered by the WCG, if there is a cate-gorized article with matching title.Table 3 gives an overview of the number of wordpairs covered in GermaNet or the WCG.
Only fewwords from Gur65 were not found in one of the re-sources.
This proportion is much higher for Gur350and ZG222, as these datasets contain many domainspecific terms that are badly covered in GermaNet,and many word pairs containing verbs and adjectivesthat are badly covered in the WCG.9 A number ofword pairs (mostly containing combinations of verbsor adjectives) were found neither in GermaNet nor9Resulting from an editorial decision, Wikipedia only con-tains articles devoted to terms of encyclopedic interest - mainlynouns.
Adjectives and verbs redirect to their correspondingnouns, if they are covered at all.Wikipedia (see GN ?
WCG).
If we consider onlynoun-noun pairs (NN), the coverage of Wikipediaexceeds that of GermaNet.
The high proportion ofword pairs that are either only found in GermaNetor in the WCG indicates that they are partially com-plementary with respect to covered vocabulary.5 ConclusionIn this paper, we performed a graph-theoretic anal-ysis of the Wikipedia Category Graph and showedthat it is a scale-free, small-world graph, like othersemantic networks such as WordNet or Roget?s the-saurus.
From this result, we concluded that theWCG can be used for NLP tasks, where other se-mantic networks have been traditionally employed.As Wikipedia is a multi-lingual resource, this en-ables the transfer of NLP algorithms to languagesthat do not have well-developed semantic wordnets.To substantiate this claim, we described howmea-sures of semantic relatedness operating on seman-tic wordnets, like WordNet or GermaNet, can beadapted to work on the WCG.
We showed that theWCG is well suited to estimate SR between words.This is due to the categorization process that con-nects terms which would not be closely related ina taxonomic wordnet structure.
Consequently, Ger-maNet outperforms the WCG on the task of estimat-ing semantic similarity.
Furthermore, the WCG can-not be used for tasks that require knowledge aboutthe exact type of semantic relation.We performed an analysis of the coverage ofWikipedia.
It covers nouns very well, but is lesssuited to compute semantic relatedness across parts-of-speech.
In this case, conventional semantic word-nets are likely to provide a better knowledge source.In Zesch et al (2007b), we show that knowledgefrom wordnets and from Wikipedia is complemen-tary, and can be combined to improve the perfor-mance on the SR task.
As the simple PL measureperforms remarkably well on the SR datasets, in ourfuture work, we will also consider computing SR us-ing the path length on the Wikipedia article graphrather than on the WCG.AcknowledgmentsThis work was supported by the German ResearchFoundation under the grant "Semantic Information7DATASET # PAIRS GN WCG GN ?
WCG GN \ WCG WCG \ GN GN ?
WCGGur65 65 57 61 65 4 8 53Gur350 350 208 161 248 87 40 121Gur350 NN 173 109 115 129 14 20 95ZG222 222 86 86 118 32 30 56ZG222 NN 119 57 61 73 12 16 45Table 3: Number of covered word pairs based on GermaNet (GN) and the WCG on different datasets.Retrieval from Texts in the Example Domain Elec-tronic Career Guidance" (SIR), GU 798/1-2.ReferencesA.
Barabasi and R. Albert.
1999.
Emergence of scaling inrandom networks.
Science, 286:509?512.A.
Budanitsky and G. Hirst.
2006.
Evaluating WordNet-basedMeasures of Semantic Distance.
Computational Linguistics,32(1).L.
Buriol, C. Castillo, D. Donato, S. Leonardi, and S. Millozzi.2006.
Temporal Analysis of the Wikigraph.
In Proc.
of WebIntelligence, Hong Kong.A.
Capocci, V. D. P. Servedio, F. Colaiori, L. S. Buriol, D. Do-nato, S. Leonardi, and G. Caldarelli.
2006.
Preferential at-tachment in the growth of social networks: The internet en-cyclopedia Wikipedia.
Physical Review E, 74:036116.C.
Fellbaum.
1998.
WordNet An Electronic Lexical Database.MIT Press, Cambridge, MA.L.
Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan,and G. Wolfman.
2002.
Placing Search in Context: TheConcept Revisited.
ACM TOIS, 20(1):116?131.I.
Gurevych.
2005.
Using the Structure of a Conceptual Net-work in Computing Semantic Relatedness.
In Proc.
of IJC-NLP, pages 767?778.T.
Holloway, M. Bozicevic, and K. B?rner.
2005.
Analyzingand Visualizing the Semantic Coverage of Wikipedia and ItsAuthors.
ArXiv Computer Science e-prints, cs/0512085.M.
Jarmasz and S. Szpakowicz.
2003.
Roget?s thesaurus andsemantic similarity.
In Proc.
of RANLP, pages 111?120.J.
J. Jiang and D. W. Conrath.
1997.
Semantic Similarity Basedon Corpus Statistics and Lexical Taxonomy.
In Proc.
ofthe 10th International Conference on Research in Compu-tational Linguistics.C.
Kunze, 2004.
Computerlinguistik und Sprachtechnologie,chapter Lexikalisch-semantische Wortnetze, pages 423?431.Spektrum Akademischer Verlag.C.
Leacock and M. Chodorow, 1998.
WordNet: An Elec-tronic Lexical Database, chapter Combining Local ContextandWordNet Similarity for Word Sense Identification, pages265?283.
Cambridge: MIT Press.D.
Lin.
1998.
An Information-Theoretic Definition of Similar-ity.
In Proc.
of ICML.G.
A. Miller and W. G. Charles.
1991.
Contextual Correlatesof Semantic Similarity.
Language and Cognitive Processes,6(1):1?28.J.
Morris and G. Hirst.
2004.
Non-Classical Lexical Seman-tic Relations.
In Proc.
of the Workshop on ComputationalLexical Semantics, NAACL-HLT.D.
L. Nelson, C. L. McEvoy, and T. A. Schreiber.
1998.
TheUniversity of South Florida word association, rhyme, andword fragment norms.
Technical report, U. of South Florida.M.
E. J. Newman.
2003.
The structure and function of complexnetworks.
SIAM Review, 45:167?256.R.
Rada, H. Mili, E. Bicknell, and M. Blettner.
1989.
Develop-ment and Application of a Metric on Semantic Nets.
IEEETrans.
on Systems, Man, and Cybernetics,, 19(1):17?30.P.
Resnik.
1995.
Using Information Content to Evaluate Se-mantic Similarity.
In Proc.
of IJCAI, pages 448?453.H.
Rubenstein and J.
B. Goodenough.
1965.
ContextualCorrelates of Synonymy.
Communications of the ACM,8(10):627?633.N.
Seco, T. Veale, and J. Hayes.
2004.
An Intrinsic InformationContent Metric for Semantic Similarity inWordNet.
In Proc.of ECAI.M.
Steyvers and J.
B. Tenenbaum.
2005.
The Large-ScaleStructure of Semantic Networks: Statistical Analyses and aModel of Semantic Growth.
Cognitive Science, 29:41?78.J.
Voss.
2005.
Measuring Wikipedia.
In Proc.
of the 10th In-ternational Conference of the International Society for Sci-entometrics and Informetrics, Stockholm, Sweden.J.
Voss.
2006.
Collaborative thesaurus tagging the Wikipediaway.
ArXiv Computer Science e-prints, cs/0604036.D.
J. Watts and S. H. Strogatz.
1998.
Collective Dynamics ofSmall-World Networks.
Nature, 393:440?442.Z.
Wu and M. Palmer.
1994.
Verb Semantics and Lexical Se-lection.
In Proc.
of ACL, pages 133?138.T.
Zesch and I. Gurevych.
2006.
Automatically CreatingDatasets for Measures of Semantic Relatedness.
In Proc.of the Workshop on Linguistic Distances, ACL, pages 16?24.T.
Zesch, I. Gurevych, and M. M?hlh?user.
2007a.
Analyzingand Accessing Wikipedia as a Lexical Semantic Resource.In Proc.
of Biannual Conference of the Society for Compu-tational Linguistics and Language Technology, pages 213?221.T.
Zesch, I. Gurevych, and M. M?hlh?user.
2007b.
Compar-ing Wikipedia and German Wordnet by Evaluating SemanticRelatedness on Multiple Datasets.
In Proc.
of NAACL-HLT,page (to appear).V.
Zlatic, M. Bozicevic, H. Stefancic, and M. Domazet.
2006.Wikipedias: Collaborative web-based encyclopedias as com-plex networks.
Physical Review E, 74:016115.8
