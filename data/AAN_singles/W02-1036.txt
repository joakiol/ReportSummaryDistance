Combining Outputs of Multiple Japanese Named Entity Chunkersby StackingTakehito UtsuroDepartment of Informationand Computer Sciences,Toyohashi University of TechnologyTenpaku-cho, Toyohashi 441-8580, Japanutsuro@ics.tut.ac.jpManabu SassanoFujitsu Laboratories, Ltd.4-4-1, Kamikodanaka, Nakahara-ku,Kawasaki 211-8588, Japansassano@jp.fujitsu.comKiyotaka UchimotoKeihanna Human Info-Communications Research Center,Communications Research LaboratoryHikaridai Seika-cho, Kyoto 619-0289, Japanuchimoto@crl.go.jpAbstractIn this paper, we propose a method forlearning a classifier which combines out-puts of more than one Japanese namedentity extractors.
The proposed combi-nation method belongs to the family ofstacked generalizers, which is in principlea technique of combining outputs of sev-eral classifiers at the first stage by learn-ing a second stage classifier to combinethose outputs at the first stage.
Individ-ual models to be combined are based onmaximum entropy models, one of whichalways considers surrounding contexts ofa fixed length, while the other consid-ers those of variable lengths according tothe number of constituent morphemes ofnamed entities.
As an algorithm for learn-ing the second stage classifier, we employa decision list learning method.
Experi-mental evaluation shows that the proposedmethod achieves improvement over thebest known results with Japanese namedentity extractors based on maximum en-tropy models.1 IntroductionIn the recent corpus-based NLP research, sys-tem combination techniques have been successfullyapplied to several tasks such as parts-of-speechtagging (van Halteren et al, 1998), base nounphrase chunking (Tjong Kim Sang, 2000), and pars-ing (Henderson and Brill, 1999; Henderson andBrill, 2000).
The aim of system combination is tocombine portions of the individual systems?
outputswhich are partial but can be regarded as highly ac-curate.
The process of system combination can bedecomposed into the following two sub-processes:1.
Collect systems which behave as differently aspossible: it would help a lot if at least the col-lected systems tend to make errors of differ-ent types, because simple voting technique canidentify correct outputs.Previously studied techniques for collectingsuch systems include: i) using several exist-ing real systems (van Halteren et al, 1998;Brill and Wu, 1998; Henderson and Brill, 1999;Tjong Kim Sang, 2000), ii) bagging/boostingtechniques (Henderson and Brill, 1999; Hen-derson and Brill, 2000), and iii) switching thedata expression and obtaining several mod-els (Tjong Kim Sang, 2000).2.
Combine the outputs of the several systems:previously studied techniques include: i) vot-ing techniques (van Halteren et al, 1998;Tjong Kim Sang, 2000; Henderson and Brill,1999; Henderson and Brill, 2000), ii) switch-ing among several systems according to con-fidence values they provide (Henderson andBrill, 1999), iii) stacking techniques (Wolpert,1992) which train a second stage classifier forAssociation for Computational Linguistics.Language Processing (EMNLP), Philadelphia, July 2002, pp.
281-288.Proceedings of the Conference on Empirical Methods in Naturalcombining outputs of classifiers at the firststage (van Halteren et al, 1998; Brill and Wu,1998; Tjong Kim Sang, 2000).In this paper, we propose a method for combiningoutputs of (Japanese) named entity chunkers, whichbelongs to the family of stacking techniques.
Inthe sub-process 1, we focus on models which dif-fer in the lengths of preceding/subsequent contextsto be incorporated in the models.
As the base modelfor supervised learning of Japanese named entitychunking, we employ a model based on the maxi-mum entropy model (Uchimoto et al, 2000), whichperformed the best in IREX (Information Retrievaland Extraction Exercise) Workshop (IREX Commit-tee, 1999) among those based on machine learningtechniques.
Uchimoto et al (2000) reported that theoptimal number of preceding/subsequent contexts tobe incorporated in the model is two morphemes toboth left and right from the current position.
In thispaper, we train several maximum entropy modelswhich differ in the lengths of preceding/subsequentcontexts, and then combine their outputs.As the sub-process 2, we propose to apply a stack-ing technique which learns a classifier for com-bining outputs of several named entity chunkers.This second stage classifier learns rules for accept-ing/rejecting outputs of several individual named en-tity chunkers.
The proposed method can be appliedto the cases where the number of constituent systemsis quite small (e.g., two).
Actually, in the experimen-tal evaluation, we show that the results of combiningthe best performing model of Uchimoto et al (2000)with the one which performs poorly but extractsnamed entities quite different from those of thebest performing model can help improve the perfor-mance of the best model.2 Named Entity Chunking based onMaximum Entropy Models2.1 Task of the IREX WorkshopThe task of named entity recognition of the IREXworkshop is to recognize eight named entity typesin Table 1 (IREX Committee, 1999).
The organizerof the IREX workshop provided 1,174 newspaperarticles which include 18,677 named entities as thetraining data.
In the formal run (general domain)Table 1: Statistics of NE Types of IREXfrequency (%)NE Type Training TestORGANIZATION 3676 (19.7) 361 (23.9)PERSON 3840 (20.6) 338 (22.4)LOCATION 5463 (29.2) 413 (27.4)ARTIFACT 747 (4.0) 48 (3.2)DATE 3567 (19.1) 260 (17.2)TIME 502 (2.7) 54 (3.5)MONEY 390 (2.1) 15 (1.0)PERCENT 492 (2.6) 21 (1.4)Total 18677 1510of the workshop, the participating systems were re-quested to recognize 1,510 named entities includedin the held-out 71 newspaper articles.2.2 Named Entity ChunkingWe first provide our definition of the task ofJapanese named entity chunking (Sekine et al,1998; Borthwick et al, 1998; Uchimoto et al,2000).
Suppose that a sequence of morphemes isgiven as below:(LeftContext ) (Named Entity) (RightContext )?
?
?ML?k?
?
?ML?1MNE1?
?
?MNEi?
?
?MNEmMR1?
?
?MRl?
?
??
(Current Position)Given that the current position is at the morphemeMNEi, the task of named entity chunking is to assigna chunking state (to be described in section 2.3.1) tothe morpheme MNEiat the current position, consid-ering the patterns of surrounding morphemes.
Notethat in the supervised learning phase, we can use thechunking information on which morphemes consti-tute a named entity, and which morphemes are in theleft/right contexts of the named entity.2.3 The Maximum Entropy ModelIn the maximum entropy model (Della Pietra et al,1997), the conditional probability of the output ygiven the context x can be estimated as the follow-ing p?
(y | x) of the form of the exponential family,where binary-valued indicator functions called fea-ture functions fi(x, y) are introduced for expressinga set of ?features?, or ?attributes?
of the context xand the output y.
A parameter ?iis introduced foreach feature fi, and is estimated from a training data.p?
(y | x) =exp(?i?ifi(x, y))?yexp(?i?ifi(x, y))Uchimoto et al (2000) defines the context x as thepatterns of surrounding morphemes as well as that atthe current position, and the output y as the namedentity chunking state to be assigned to the mor-pheme at the current position.2.3.1 Named Entity Chunking StatesUchimoto et al (2000) classifies classes ofnamed entity chunking states into the following 40tags:?
Each of eight named entity types plus an ?OP-TIONAL?
type are divided into four chunkingstates, namely, the beginning/middle/end of annamed entity, or an named entity consisting ofa single morpheme.
This amounts to 9?4 = 36classes.?
Three more classes are distinguished for mor-phemes immediately preceding/following anamed entity, as well as the one between twonamed entities.?
Other morphemes are assigned the class?OTHER?.2.3.2 FeaturesFollowing Uchimoto et al (2000), feature func-tions for morphemes at the current position as wellas the surrounding contexts are defined.
Morespecifically, the following three types of featurefunctions are used: 11.
2052 lexical items that are observed five timesor more within two morphemes from namedentities in the training corpus.2.
parts-of-speech tags of morphemes2.3.
character types of morphemes (i.e., Japanese(hiragana or katakana), Chinese (kanji), num-bers, English alphabets, symbols, and theircombinations).As for the number of preceding/subsequent mor-phemes as contextual clues, we consider the follow-ing models:1Minor modifications from those of Uchimoto et al (2000)are: i) we used character types of morphemes because they areknown to be useful in the Japanese named entity chunking, andii) the sets of parts-of-speech tags are different.2As a Japanese morphological analyzer, we used BREAK-FAST (Sassano et al, 1997) with the set of about 300 part-of-speech tags.
BREAKFAST achieves 99.6% part-of-speech accu-racy against newspaper articles.5-gram modelThis model considers the preceding two mor-phemes M?2, M?1as well as the subsequent twomorphemes M1, M2as the contextual clue.
Both in(Uchimoto et al, 2000) and in this paper, this is themodel which performs the best among all the indi-vidual models without system combination.
( LeftContext ) (CurrentPosition ) (RightContext )?
?
?
M?2M?1M0M1M2?
?
?7-gram modelThis model considers the preceding three mor-phemes M?3, M?2, M?1as well as the subsequentthree morphemes M1, M2, M3as the contextualclue.
( LeftContext ) (CurrentPosition ) (RightContext )?
?
?
M?3M?2M?1M0M1M2M3?
?
?9-gram modelThis model considers the preceding four mor-phemes M?4, M?3, M?2, M?1as well as the subse-quent four morphemes M1, M2, M3, M4as the con-textual clue.
( LeftContext ) (CurrentPosition ) (RightContext )?
?
?
M?4?
?
?M?1M0M1?
?
?M4?
?
?For both 7-gram and 9-gram models, we considerthe following three modifications to those models:?
with all features?
with lexical items and parts-of-speechtags (without the character types) ofM{(?4),?3,3,(4)}?
with only the lexical items of M{(?4),?3,3,(4)}In our experiments, the number of features is13,200 for 5-gram model and 15,071 for 9-grammodel.
The number of feature functions is 31,344for 5-gram model and 35,311 for 9-gram model.Training a variable length (5?9-gram) model,testing with 9-gram modelThe major disadvantage of the 5/7/9-gram modelsis that in the training phase it does not take into ac-count whether or not the preceding/subsequent mor-phemes constitute one named entity together withthe morpheme at the current position.
Consider-ing this disadvantage, we examine another model,namely, variable length model, which incorporatesvariable length contextual information.
In the train-ing phase, this model considers which of the preced-ing/subsequent morphemes constitute one namedentity together with the morpheme at the current po-sition (Sassano and Utsuro, 2000).
It also considersseveral morphemes in the left/right contexts of thenamed entity.
Here we restrict this model to explic-itly considering the cases of named entities of thelength up to three morphemes and only implicitlyconsidering those longer than three morphemes.
Wealso restrict it to considering two morphemes in bothleft and right contexts of the named entity.
( LeftContext ) (Named Entity) (RightContext )?
?
?
ML?2ML?1MNE1?
?
?MNEi?
?
?MNEm(?3)MR1MR2?
?
??
(Current Position)1.
In the cases where the current named entityconsists of up to three morphemes, all the con-stituent morphemes are regarded as within thecurrent named entity.
The following is an ex-ample of this case, where the current namedentity consists of three morphemes, and thecurrent position is at the middle of those con-stituent morphemes as below:( LeftContext ) (Named Entity) (RightContext )?
?
?
ML?2ML?1MNE1MNE2MNE3MR1MR2?
?
??
(1)(Current Position)2.
In the cases where the current named entityconsists of more than three morphemes, onlythe three constituent morphemes are regardedas within the current named entity and the restare treated as if they were outside the namedentity.
For example, suppose that the cur-rent named entity consists of four morphemes:( LeftContext ) (Named Entity) (RightContext )?
?
?
ML?2ML?1MNE1MNE2MNE3MNE4MR1MR2?
?
??
(Current Position)In this case, the fourth constituent morphemeMNE4is treated as if it were in the right contextof the current named entity as below:( LeftContext ) (Named Entity) (RightContext )?
?
?
ML?2ML?1MNE1MNE2MNE3MNE4MR1?
?
??
(Current Position)In the testing phase, we apply this model consid-ering the preceding four morphemes as well as thesubsequent four morphemes at every position, as inthe case of 9-gram model3.We consider the following three modifications tothis model, where we suppose that the morpheme atthe current position be M0:?
with all features?
with lexical items and parts-of-speech tags(without the character types) of M{?4,?3,3,4}?
with only the lexical items of M{?4,?3,3,4}3 Learning to Combine Outputs of NamedEntity Chunkers3.1 Data SetsThe following gives the training and test data setsfor our framework of learning to combine outputs ofnamed entity chunkers.1.
TrI : training data set for learning individualnamed entity chunkers.2.
TrC: training data set for learning a classifierfor combining outputs of individual named en-tity chunkers.3.
Ts: test data set for evaluating the classifier forcombining outputs of individual named entitychunkers.3.2 ProcedureThe following gives the procedure for learning theclassifier to combine outputs of named entity chun-kers using TrI and TrC.1.
Train the individual named entity chunkersNEchki(i = 1, .
.
.
, n) using TrI .2.
Apply the individual named entity chunkersNEchki(i = 1, .
.
.
, n) to TrC, respectively,and obtain the list of chunked named entitiesNEListi(TrC) for each named entity chun-ker NEchki.3Note that, as opposed to the training phase, the length ofpreceding/subsequent contexts is fixed in the testing phase ofthis model.
Although this discrepancy between training andtesting damages the performance of this single model (sec-tion 4.1), it is more important to note that this model tends tohave distribution of correct/over-generated named entities dif-ferent from that of the 5-gram model.
In section 4, we exper-imentally show that this difference is the key to improving thenamed entity chunking performance by system combination.Table 2: Examples of Event Expressions for Combining Outputs of Multiple SystemsSegment Morpheme(POS) NE Outputs ofIndividual Systems Event ExpressionsSystem 0 System 1...SegEvirainen(?next year?,temporal noun)10gatsu(?October?,temporal noun)rainen(DATE)10gatsu(DATE)rainen-10gatsu(DATE){systems=?0?,mlength=1,NEtag=DATE,POS=?temporal noun?, classNE=?
}{systems=?0?,mlength=1,NEtag=DATE,POS=?temporal noun?, classNE=?
}{systems=?1?,mlength=2,NEtag=DATE,POS=?temporal noun, temporal noun?,classNE=+}...SegEvi+1seishoku(?reproductive?, noun)iryou(?medical?, noun)gijutsu(?technology?, noun)seishoku-iryou-gijutsu(ARTIFACT){systems=?0?, classsys=?no outputs?
}{systems=?1?,mlength=3,NEtag=ARTIFACT,POS=?noun,noun,noun?, classNE=?
}nitsuite(?about?, particle)...3.
Align the lists NEListi(TrC) (i = 1, .
.
.
, n)of chunked named entities according to the po-sitions of the chunked named entities in the textTrC, and obtain the event expression TrCevof TrC.4.
Train the classifier NEchkcmbfor combiningoutputs of individual named entity chunkers us-ing the event expression TrCev.The following gives the procedure for applying thelearned classifier to Ts.1.
Apply the individual named entity chunkersNEchki(i = 1, .
.
.
, n) to Ts, respectively,and obtain the list of chunked named entitiesNEListi(Ts) for each named entity chunkerNEchki.2.
Align the lists NEListi(Ts) (i=1, .
.
.
, n) ofchunked named entities according to the posi-tions of the chunked named entities in the textTs, and obtain the event expression Tsev ofTs.3.
Apply NEchkcombto Tsev and evaluate itsperformance.3.3 Data Expressions3.3.1 EventsThe event expression TrCev of TrC is obtainedby aligning the lists NEListi(TrC) (i =1, .
.
.
, n)of chunked named entities, and is represented as asequence of segments, where each segment is a setof aligned named entities.
Chunked named enti-ties are aligned under the constraint that those whichshare at least one constituent morpheme have to bealigned into the same segment.
Examples of seg-ments, into which named entities chunked by twosystems are aligned, are shown in Table 2.
In thefirst segment SegEvi, given the sequence of the twomorphemes, the system No.0 decided to extract twonamed entities, while the system No.1 chunked thetwo morphemes into one named entity.
In thoseevent expressions, systems indicates the list of theindices of the systems which output the named en-tity, mlength gives the number of the constituentmorphemes, NEtag gives one of the nine namedentity types, POS gives the list of parts-of-speechof the constituent morphemes, and classNEindi-cates whether the named entity is a correct one com-pared against the gold standard (?+?
), or the oneover-generated by the systems (???
).In the second segment SegEvi+1, only the sys-tem No.1 decided to extract a named entity fromthe sequence of the three morphemes.
In this case,the event expression for the system No.0 is the onewhich indicates that no named entity is extracted bythe system No.0.In the training phase, each segment SegEvjofevent expression constitutes a minimal unit of anevent, from which features for learning the classi-fier are extracted.
In the testing phase, the classesof each system?s outputs are predicted against eachsegment SegEvj.3.3.2 Features and ClassesIn principle, features for learning the classifier forcombining outputs of named entity chunkers are rep-resented as a set of pairs of the system indices list?p, .
.
.
, q?
and a feature expression F of the namedentity:f ={?systems=?p, .
.
.
, q?, F ??
?
?
?systems=?p?, .
.
.
, q?
?, F ??
}(2)In the training phase, any possible feature of thisform is extracted from each segment SegEvjofevent expression.
The system indices list ?p, .
.
.
, q?indicates the list of the systems which output thenamed entity.
A feature expression F of the namedentity can be any possible subset of the full featureexpression {mlength= ?
?
?
, NEtag= ?
?
?
, POS =?
?
?
}, or the set indicating that the system outputs nonamed entity within the segment.F =??????
?any subset of{mlength= ?
?
?
,NEtag= ?
?
?
, POS= ?
?
?
}{classsys=?no outputs?
}In the training and testing phases, within eachsegment SegEvjof event expression, a class is as-signed to each system, where each class classisysforthe i-th system is represented as a list of the classesof the named entities output by the system:classisys={+/?, .
.
.
, +/?
?no output?
(i = 1, .
.
.
, n)3.4 Learning AlgorithmWe apply a simple decision list learning methodto the task of learning a classifier for combiningoutputs of named entity chunkers4.
A decisionlist (Yarowsky, 1994) is a sorted list of decisionrules, each of which decides the value of class givensome features f of an event.
Each decision rule ina decision list is sorted in descending order withrespect to some preference value, and rules withhigher preference values are applied first when ap-plying the decision list to some new test data.
Inthis paper, we simply sort the decision list accordingto the conditional probability P (classi| f) of theclassiof the i-th system?s output given a feature f .4 Experimental EvaluationWe experimentally evaluate the performance of theproposed system combination method using theIREX workshop?s training and test data.4.1 Comparison of Outputs of IndividualSystemsFirst, Table 3 shows the performance of the indi-vidual models described in the section 2.3.2, wheretrained with the IREX workshop?s training data, andtested against the IREX workshop?s test data as Ts.The 5-gram model performs the best among thoseindividual models.Next, assuming that each of the models otherthan the 5-gram model is combined with the 5-grammodel, Table 4 compares the named entities of theiroutputs.
Recall rate of the correct named entities inthe union of their outputs, as well as the overlap rate5of the over-generated entities against those includedin the output of the 5-gram model are shown.From the Tables 3 and 4, it is clear that the 7-gramand 9-gram models are quite similar to the 5-grammodel both in the performance and in the distribu-tion of correct/over-generated named entities.
Onthe other hand, variable length models have distri-bution of correct/over-generated named entities a lit-4It is quite straightforward to apply any other supervisedlearning algorithms to this task.5For a model X , the overlap rate of the over-generated enti-ties against those included in the output of the 5-gram model isdefined as: (# of the intersection of the over-generated entitiesoutput by the 5-gram model and those output by the model X)/(# of the over-generated entities output by the 5-gram model).Table 3: Performance of Individual Models againstTs (F-measure (?
= 1) (%))Features for M{(?4),?3,3,(4)}All Lex+POS Lex7-gram 80.78 80.81 80.719-gram 80.13 80.53 80.53variable length 45.12 77.02 75.165-gram 81.16Table 4: Difference between 5-gram model andOther Individual Models (Recall of the Union /Overlap Rate of Over-generated Entities) (%)Features for M{(?4),?3,3,(4)}All Lex+POS Lex7-gram 79.8/85.2 79.8/85.2 79.7/91.29-gram 79.7/84.7 79.7/86.1 79.5/90.7variablelength 82.6/27.3 81.4/63.4 80.4/72.7tle different from that of the 5-gram model.
Vari-able length models have lower performance mainlybecause of the difference between the training andtesting phases with respect to the modeling of con-text lengths.
Especially, the variable length modelwith ?all?
features of M{?4,?3,3,4}has much lowerperformance as well as significantly different dis-tribution of correct/over-generated named entities.This is because character types features are so gen-eral that many (erroneous) named entities are over-generated, while sometimes they contribute to find-ing named entities that are never detected by any ofthe other models.4.2 Results of Combining System OutputsThis section reports the results of combining the out-put of the 5-gram model with that of 7-gram models,9-gram models, and the variable length models.
Asthe training data sets TrI and TrC, we evaluate thefollowing two assignments (a) and (b), where DCRLdenotes the IREX workshop?s training data:(a) TrI: DCRL?
D200CRL(200 articles from DCRL)TrC: D200CRL(b) TrI = TrC = DCRLWe use the IREX workshop?s test data for Ts.In the assignment (a), TrI and TrC are disjoint,while in the assignment (b), individual named entitychunkers are applied to their own training data, i.e.,closed data.
The assignment (b) is for the sake ofavoiding data sparseness in learning the classifier forcombining outputs of two named entity chunkers.Table 5 shows the peformance in F-measure (?
=1) for both assignments (a) and (b).
For both (a) andTable 5: Performance of Combining 5-gram modeland Other Individual Models (against Ts, F-measure(?
= 1) (%))(a) TrI = DCRL?
D200CRL, TrC = D200CRLFeatures for M{(?4),?3,3,(4)}All Lex+POS Lex7-gram 81.54 81.53 80.609-gram 81.31 81.26 80.60variable length 83.43 81.55 81.85(b) TrI = TrC = DCRLFeatures for M{(?4),?3,3,(4)}All Lex+POS Lex7-gram 81.97 81.83 81.589-gram 81.53 81.66 81.52variable length 84.07 83.07 82.50(b), ?5-gram + variable length (All)?
significantlyoutperforms the 5-gram model, which is the bestmodel among all the individual models without sys-tem combination.
It is remarkable that models whichperform poorly but extract named entities quite dif-ferent from those of the best performing model canactually help improve the best model by the pro-posed method.
The performance for the assignment(b) is better than that for the assignment (a).
This re-sult claims that the training data size should be largerwhen learning the classifier for combining outputs oftwo named entity chunkers.In the Table 6, for the best performing result (i.e.,5-gram + variable length (All)) as well as the con-stituent individual models (5-gram model and vari-able length model (All)), we classify the systemoutput according to the number of constituent mor-phemes of each named entity.
In the Table 7, weclassify the system output according to the namedentity types.
The following summarizes several re-markable points of these results: i) the benefit of thesystem combination is more in the improvement ofprecision rather than in that of recall.
This meansthat the proposed system combination technique isuseful for detecting over-generation of named en-tity chunkers, ii) the combined outputs of the 5-grammodel and the variable length model improve the re-sults of chunking longer named entities quite wellcompared with shorter named entities.
This is theeffect of the variable length features of the variablelength model.Table 6: Evaluation Results of Combining System Outputs, per # of constituent morphemes(TrI = TrC = DCRL, F-measure (?
= 1) / Recall / Precision (%))n Morphemes to 1 Named Entityn ?
1 n = 1 n = 2 n = 3 n ?
45-gram 81.16 83.60 86.94 68.42 50.5978.87/83.60 84.97/82.28 85.90/88.00 63.64/73.98 35.83/86.00variable length (All) 45.12 53.77 56.63 33.74 16.7851.50/40.15 38.69/88.14 71.37/47.93 57.34/23.91 40.00/10.625-gram + variable length (All) 84.07 85.06 88.96 75.19 65.9681.45/86.86 85.12/84.99 87.42/90.56 69.93/81.30 51.67/91.18Table 7: Evaluation Results of Combining System Outputs, per NE type(TrI = TrC = DCRL, F-measure (?
= 1) (Recall, Precision) (%))ORGANI- PER- LOCA- ARTI- DATE TIME MONEY PER-ZATION SON TION FACT CENT67.74 81.82 77.04 30.43 91.49 93.20 92.86 87.185-gram (58.45) (79.88) (71.91) (29.17) (88.85) (88.89) (86.67) (80.95)(80.53) (83.85) (82.96) (31.82) (94.29) (97.96) (100.00) (94.44)35.48 48.45 38.47 5.80 78.60 56.90 60.61 87.18variable length (All) (37.40) (48.52) (32.93) (22.92) (81.92) (61.11) (66.67) (80.95)(33.75) (48.38) (46.26) (3.32) (75.53) (53.23) (55.56) (94.44)5-gram + 72.18 84.15 79.58 38.71 92.86 93.20 92.86 87.18variable length (All) (62.88) (81.66) (73.61) (37.50) (90.00) (88.89) (86.67) (80.95)(84.70) (86.79) (86.61) (40.00) (95.90) (97.96) (100.00) (94.44)5 ConclusionThis paper proposed a method for learning a classi-fier to combine outputs of more than one Japanesenamed entity chunkers.
Experimental evaluationshowed that the proposed method achieved improve-ment in F-measure over the best known results withan ME model (Uchimoto et al, 2000), when a com-plementary model extracted named entities quite dif-ferently from the best performing model.ReferencesA.
Borthwick, J.
Sterling, E. Agichtein, and R. Grishman.1998.
Exploiting diverse knowledge sources via max-imum entropy in named entity recognition.
In Proc.6th Workshop on VLC, pages 152?160.E.
Brill and J. Wu.
1998.
Classifier combination for im-proved lexical disambiguation.
In Proc.
17th COLINGand 36th ACL, pages 191?195.S.
Della Pietra, V. Della Pietra, and J. Lafferty.
1997.Inducing features of random fields.
IEEE Transac-tions on Pattern Analysis and Machine Intelligence,19(4):380?393.J.
C. Henderson and E. Brill.
1999.
Exploiting diversityin natural language processing: Combining parsers.
InProc.
1999 EMNLP and VLC, pages 187?194.J.
C. Henderson and E. Brill.
2000.
Bagging and boost-ing a treebank parser.
In Proc.
1st NAACL, pages 34?41.IREX Committee, editor.
1999.
Proceedings of the IREXWorkshop.
(in Japanese).M.
Sassano and T. Utsuro.
2000.
Named entity chunkingtechniques in supervised learning for Japanese namedentity recognition.
In Proceedings of the 18th COL-ING, pages 705?711.M.
Sassano, Y. Saito, and K. Matsui.
1997.
Japanesemorphological analyzer for NLP applications.
In Proc.3rd Annual Meeting of the Association for NaturalLanguage Processing, pages 441?444.
(in Japanese).S.
Sekine, R. Grishman, and H. Shinnou.
1998.
A deci-sion tree method for finding and classifying names inJapanese texts.
In Proc.
6th Workshop on VLC, pages148?152.E.
Tjong Kim Sang.
2000.
Noun phrase recognition bysystem combination.
In Proc.
1st NAACL, pages 50?55.K.
Uchimoto, Q. Ma, M. Murata, H. Ozaku, and H. Isa-hara.
2000.
Named entity extraction based on a maxi-mum entropy model and transformation rules.
In Proc.38th ACL, pages 326?335.H.
van Halteren, J. Zavrel, and W. Daelemans.
1998.
Im-proving data driven wordclass tagging by system com-bination.
In Proc.
17th COLING and 36th ACL, pages491?497.D.
H. Wolpert.
1992.
Stacked generalization.
NeuralNetworks, 5:241?259.D.
Yarowsky.
1994.
Decision lists for lexical ambiguityresolution: Application to accent restoration in Span-ish and French.
In Proc.
32nd ACL, pages 88?95.
