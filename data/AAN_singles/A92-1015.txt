Detecting and Correcting Morpho-syntactic Errors in Real TextsTheo Vosse*Nijmegen Institute for Cognition and InformationUniversity of NijmegenandCognitive Technology FoundationP.O.
Box 91046500 HE Nijmegen, The Netherlandse-mail: vosse@nici.kun.nlAbstractThis paper presents a system which detects andcorrects morpho-syntactic errors in Dutch texts.
Itincludes aspelling corrector and a shift-reduceparser for Augmented Context-free Grammars.The spelling corrector isbased on trigram andtriphone analysis.
The parser is an extension ofthe well-known Tomita algorithm (Tomita, 1986).The parser interacts with the spelling correctorand handles certain types of structural errors.Both modules have been integrated with acompound analyzer and a dictionary of 275,000word forms into a program for stand-aloneproof-reading ofDutch texts on a large scale.
Thesystem is in its final testing phase and will becommercially available as from 1992.1.
IntroductionOne of the most widely used applications of naturallanguage processing is spell, grammar and stylechecking.
Although most probably semantic analysisis required to obtain entirely satisfactory results, it isnever used - -  for obvious reasons.
Even worse, mostlanguage checkers today even restrain from syntacticanalysis.
This denies them the possibility to findmorpho-syntactic errors, which form a large and fre-quently occurring class of spelling errors.
One of thebest known systems for English, which does performsyntactic analysis, is Critique (Richardson, 1988).In order to detect and correct morpho-syntacticerrors a system needs (I) modules for word-levelspell checking and correction, (2) a parser whichcontains a comprehensive grammar and an efficientparsing algorithm, and (3) a mechanism to detectand correct grammatical errors as well as to assist incorrecting spelling errors.
I will first define thedomain of morpho-syntactic errors and motivate the*The author's current address is: ExperimentalPsychology Unit, Leiden University, P.O.
Box 9555,2300 RB Leiden, The Netherlands.need for a parser.
After a brief overview of the sys-tem and a discussion of the word-level modules, Iwill describe the grammar formalism, the parser, itsmechanism for error detection, and a pre-processorfor word lattices.
Finally, after looking at the integra-tion of the modules and at some useful heuristics, Iwill give a summary of the results obtained by anon-interactive Dutch grammar-driven spellchecker.2.
Morpho-syntactic ErrorsThis paper is concerned with three types of errors:typographical errors (typing errors or OCR scanningerrors), orthographical errors (erroneous translitera-tions of phonemes to graphemes) and, most impor-tantly, morpho-syntactic errors (resulting from mis-application of morphological inflection and syntacticrules).
Simple spell checkers are only able to spot er-rors leading to non-words; errors involving legallyspelled words go unnoticed.
These morpho-syntacficerrors occur quite frequently in Dutch texts, though,and are considered serious because they are seen asresulting from insufficient language competencerather than from incidental mistakes, such as typo-graphical errors.
Therefore they constitute an inter-esting area for grammar checking in office and lan-guage teaching applications.
I will now present aclassification of the morpho-syntacfic errors andsome related errors in Dutch (Kempen and Vosse,1990).2.1.
Agreement violationsTypically syntactic errors are agreement violations.Though none of the words in the sentence She walkhome is incorrect, the sentence is ungrammatical.
Nosimple spelling checking mechanism can find the er-ror, let alne correct it, since it is caused by a relationbetween two words that need not be direct neigh-hours.
Detection and correction of this type of errorrequires a robust parser, that can handle ungram-matical input.1112.2.
Homophonous wordsHomophony is an important source of orthographi-cal errors: words having the same pronunciation buta different spelling.
Dutch examples are ze/and zij,sectie and sexy, wort and wordt and achterruit andachteruit.
Such words are easily replaced by one of itshomophonous counterparts in written text.The problem of current spell checkers is that theydo not notice this substitution as the substitutes arelegal words themselves.
In order to detect his sub-stitution, aparser is required since often a change ofsyntactic ategory is involved.
In section 4.3.2 1 willdemonstrate hat the treatment of these errorsstrongly resembles the treatment of non-words 1.Unfortunately, a parser cannot detect substitutionsby homophones which have the same syntacticproperties.2.3.
Homophonous inflectionsA special case of homophonous words are wordswhich differ only in inflection.
This type of homo-phony is very frequent in Dutch and French.
Frenchexamples are donner, donnez, donnd, donnde, donndsand donndes or cherche, cherches and cherchent.
Dutchexamples typically involve d/t-errors: -d, -t and -dtsound identical at the end of a word but they oftensignal different verb inflections.
Examples are theforms gebeurt (third person singular, present ense)and gebeurd (past participle) of the verb gebeuren;word (first person, singular, present ense) and wordt(third person, singular, present tense) of the verbworden; and besteden (infinitive and plural, presenttense),besteedden (plural, past tense), and bestede (anadjective, derived from the past participle).However, unlike the general case of homophon-ous words, homophonous inflections, by their verynature, do not alter the syntactic ategory of theword but rather its (morpho-syntactic) features.
Sothis type of error can be regarded as a homophonousword or a spelling error, or as an agreementviolation.2.4.
Word doublingNotoriously difficult to spot are word doublingerrors, especially at the end of a line ("Did youactually see the the error in this sentence?").
Aparser surely notices it, but it should not fail toanalyze the sentence because of this.2.5.
Errors in idiomatic expressionsIdiomatic expressions often cause problems forparsers ince they often do not have a regular syn-tactic structure and some of their words may be ille-gal outside the idiomatic ontext.
A Dutch exampleis te allen tijde (English: at all times), with the word1I will not discuss typographical errors resulting inlegal words (such as rotsen and rosten) since theirtreatment is similar.tijde only occurring in idiomatic expressions.Whenever it occurs in a normal sentence it must beconsidered to be a spelling error.
(An English exam-ple might be in lieu of.)
The problem is even moreserious in case of spelling errors.
E.g.
the expressionabove is more often than not written as te alle tijden,which consists of legal words and is syntacticallycorrect as well.2.6.
Split CompoundsSomewhat similar to idiomatic expressions i  thecase of compound nouns, verbs, etc.
In both Dutchand German these must be written as single words.However, under the ever advancing influence ofEnglish on Dutch, many compounds, especially newones such as tekst verwerker (text processor) andcomputer terminal are written separated by a blank,thus usually confusing the parser.3.
Sys tem overv iewThe system presented here consists of two mainlevels: word level and sentence l vel.
Before enteringthe sentence l vel (i.e., parsing a sentence), a spellingmodule should check on all the words in the sen-tence.
This is a rather simple task for a languagesuch as English, but for morphologically complexlanguages such as Dutch and German, it is by nomeans trivial.
Because compound nouns, verbs andadjectives are written as a single word, they cannotalways be looked up in a dictionary, but have to beanalyzed instead.
There are three problems involvedin compound analysis: (1) not every sequence of dic-tionary words forms a legal compound, (2) certainparts of a compound cannot be found in the dic-tionary and (3) full analysis usually comes up withtoo many alternatives.
My solution follows the linesset out in (Daelemans, 1987): a deterministic wordparser, constrained by the grammar for legal com-pounds, that comes up with the left-most longestsolution first.
This solution is rather fast on legalcompounds, while it takes at most O(n 2) time fornonexistent words and illegal compounds.
The wordparser is built upon a simple morphologicalanalyzer, which can analyze prefixes, suffixes andsome types of inflection.
Both use a dictionary,containing 250,000 word forms 2, derived from 90,000Dutch lemmata, which appears to be sufficient formost purposes.
There is also a possibility to addextra dictionaries for special types of text.2For each lemma the dictionary contains all theinflections and derivations that were found in a largecorpus of Dutch text (the INL corpus, compiled by theInstituut voor Nederlandse L xicografie nLeyden).
Thedictionary itself is a computerised xpanded version of the"Hedendaags Nederlands" ( Contemporary Dutch")dictionary, published by Van Dale Lexicografie (Utrecht),which was enriched with syntactic nformation from theCELEX database (University of Nijmegen).112If a word does not appear in one of the dictionar-ies and is not a legal compound either, the spellchecker can resort o a correction module.
In aninteractive situation such a module might presentthe user as many alternatives as it can find.Although this 'the-more-the-better' approach is verypopular in commercially available spell checkers, itis not a very pleasant one.
It is also unworkable in abatch oriented system, such as the one I am describ-ing here.
Ideally, a spelling corrector should comeup with one (correct!)
solution, but if the correctorfinds more than one alternative, it should assign ascore or ranking order to each of the alternatives.The system presented here employs a correctionmechanism based on both a variation of trigramanalysis (Angell et al, 1983) and triphone analysis(Van Berkel and De Smedt, 1988), extended with ascoring and ranking mechanism.
The latter is alsoused in pruning the search space 3.
Thus the systemcan handle typographical errors as well as ortho-graphical errors, and includes a satisfactory mecha-nism for ranking correction alternatives, which issuitable both for interactive nvironments a well asfor stand-alone systems.When all words of a text have been checked and,if necessary, corrected, a pre-processor (to bedescribed in section 4.4) combines the words andtheir corrections into a word lattice.
The syntacticparser then checks the grammatical relations be-tween the elements in this lattice.
If the parsing re-sult indicates that the sentence contains errors, asyntactic orrector inspects the parse tree and pro-poses corrections.
If there is more than one possiblecorrection, it ranks the correction alternatives andexecutes the top-most one.
Section 4 will describe theparser and the pre-processor in some detail.
Due tospace limitations, I have to refer to (Vosse, 1991) forfurther information, e.g.
the adaptations that need tobe made to the Tomita algorithm in order to keepthe parsing process efficient.4.
Shift-Reduce Parsing with ACFGs4.1.
Augmented Context-free GrammarsAugmented Context-Free Grammars (ACFGs forshort) form an appropriate basis for error detectionand correction.
Simply put, an ACFG is a Context-Free Grammar where each non-terminal symbol hasa (finite) sequence of attributes, each of which canhave a set of a finite number of symbols as its value.3pruning the search space is almost obligatory, sincetrigram and triphone analysis require O(n*m) space,where n is the length of the word and m the number ofentries in the dictionary.
The constant factor involved canbe very large, e.g.
for words containing the substring ver,which occurs in more than seven out of every hundredwords (13,779 triphones and 16,881 trigrams in 237,000words).In a rule, the value of an attribute can be representedby a constant or by a variable.A simple fragment of an ACFG is for example:1 S -~ NP(Num nora) VP(Num)2 NP(Num ) -9 Det(Num) ADJs Noun(Num)3 NP(Num Case) -4 Pro(Num Case)4 VP(Num) -~ Verb(Num intrans)5 VP(Num) --)Verb(Num trans) NP( acc)6 ADJs -97 ADJs -9 ADJ  ADJsThe derivation of a sentence might go like this:S ~ NP(sg3 nom) VP(sg3) ~ Det (sg3) ADJsNoun(sg3) VP(sg3) ~ Det (sg3) Noun(sg3) VP(sg3)Det(sg3) Noun(sg3) Verb(sg3 intrans) ~ aman eatsIn the actual implementation f the parser, thegrammatical formalism is slightly more complex asit uses strongly typed attributes and allows restric-t ions on the values the variables can take, therebymaking grammar writing easier and parsing morereliable.
The Dutch grammar employed in the sys-tem contains nearly 500 rules.4.2.
The parserThe construction of the parsing table is accom-plished by means of standard LR-methods, e.g.SLR(0) or LALR(1), using the "core" grammar (i.e.leaving out the attributes).
The parsing algorithm it-self barely changes as compared to a standard shift-reduce algorithm.
The shift step is not changedexcept for the need to copy the attributes from lexi-cal entries when using a lexicon and a grammar withpre-terminals.
The reduction step needs to be ex-tended with an instantiation algorithm to computethe value of the variables and a succeed/fail result.
Itshould fail whenever an instantiation fails or thevalue of a constant is not met.To accomplish this, the trees stored on the stackshould include the values resulting from the evalua-tion of the right-hand side of the reduced rule.
Thismakes the instantiation step fairly straightforward.The variables can be bound while the elements arepopped from the stack.
If a variable is alreadybound, it must be instantiated with the correspond-ing value on the stack.
If this cannot be done or if aconstant value in a rule does not match the value onthe stack, the reduction step fails.
A simple example(not completely) following the grammar sampleabove may clarify this.In Figure la parsing succeeds just as it wouldhave done if only the context-free part of the gram-mar had been used.
The only difference is that thesymbols on the stack have attributes attached tothem.
In Figure lb however, parsing fails - -  not be-cause the context-free part of the grammar does notaccept he sentence (the parse table does contain anentry for this case) but because the instantiation ofp l  and sg3 in rule 1 causes the reduction to fail.Note that the mechanism for variable binding isnot completely equivalent to unification.
It typicallydiffers from unification in the reduction of the fol-lowing two rules113a Det(sg3)I man Noun(sg3) \[a Det(sg3) I NP(sg3)eats  Verb(sg3)NP(sg3)\[ VP(sg3)NP(sg3) I SFigure la.
Parsing of "a man eats".a Det(sg3) ,I man Noun(sg3) a Det(sg3) eat Verb(pl) I NP(sg3) I NP(sg3) VP(pl) NP(sg3)Figure lb.
Parsing of " a man eat"1 A --~ ... B (X ,  Y) ...2 B (X ,  X) --~ ...The reduction of rule 2 will leave two values onthe stack rather than an indication that the two vari-ables are one and the same.
Therefore X and Y maydiffer after the reduction of rule 1.4.3.
Parsing Erroneous Input4.3.1.
Coercing syntactic agreementFigure lb shows one type of problem I am interestedin, but clearly not the way to solve it.
Though theparser actually detects the error, it does not giveenough information on how to correct it.
It does noteven stop at the right place 4, since the incongruity isonly detected once the entire sentence has been read.Therefore the reduction step should undergo furthermodification.
It should not fail whenever the instan-tiation of a variable fails or a constant in the left-hand side of the rule being reduced oes not matchthe corresponding value on the stack, but mark theincongruity and continue parsing instead.
Later inthe process, when the parsing has finished, the syn-tactic corrector checks the marks for incongruity andcoerces agreement by feature propagation.This approach contrasts with, e.g., the approachtaken by (Schwind, 1988), who proposes to devise anerror rule (cf.
section 4.3.3) for every unificationerror of interest.
However, this makes efficient pars-ing with a large grammar nearly impossible sincethe size of the parsing table is exponentially relatedto the number of rules.4.3.2.
Syntactic filteringConsider the error in The yelow cab stops.
The Englishspelling corrector on my word processor (MS-Word)offers two alternatives: yellow and yellows.
Since the4This of course is caused by the context-free part of thegrammar.
If we had created a unique non-terminal forevery non-terminal-feature combination, e.g.
s ->NP_s ing3_nom VP_s ing3 ,  parsing would have stopped atthe right place (i.e.
between "man" and "eat").
Thishowever depends mainly on the structure of the grammar.E.g.
in Dutch the direct object may precede the finite verb,in which case agreement can only be checked after havingparsed the subject following the finite verb.
Then theparser cannot fail before the first NP following the finiteverb.
This is too late in general.string yelow is obviously incorrect, it has no syntacticcategory and the sentence cannot be parsed.
Onemight therefore try to substitute both alternativesand see what the parser comes up with, as in Figure2.
This example clearly shows that the only gram-matically correct alternative is yellow.
In this way aparser can help the spelling corrector to reduce theset of correction alternatives.
Since a realistic naturallanguage parser is capable of parsing words withmultiple syntactic ategories (e.g.
stop is both a nounand a verb), the two entries for yelow can be parsedin a similar fashion.
The grammatical ternative(s)can be found by inspecting the resulting parse treesafterwards.In order to handle errors caused by homophonesas well, this mechanism needs to be extended.
Whendealing with legal words it should use their syntacticcategories plus the syntactic ategories of all possiblehomophones, plus - -  to be on the safe side - -  everyalternative suggested by the spelling corrector.Afterwards the parse trees need to be examined tosee whether the original word or one of its alterna-tives is preferred.4.3.3.
Error rulesThe third and last category of errors the systemattempts to deal with consists of the structuralerrors.
General techniques for parsing sentences con-taining errors are difficult, computationaUy ratherexpensive and not completely fool-proof.
For thesereasons, and because only a very limited number ofstructural errors occur in real texts, I have developeda different approach.
Instead of having a specialmechanism in the parser find out the proper alterna-tive, I added error rules to the formalism.
Thegrammar should now contain foreseen improperconstructions.
These might treat some rare con-stituent order problems and punctuation problems.4.3.4.
Parsing weightsNatural anguage sentences are highly syntacticallyambiguous, and allowing errors makes things con-siderably worse.
Even the simple toy grammarabove yields a great number of useless parses on thesentence They think.
The word think may have differ.ent entries for 1st and 2nd person singular, 1st, 2ndand 3rd person plural and for the infinitive.
This114the ye l low cab stops01 Det 013 yel low 1 Det 0ii ADJ  1 Det 020 ADJs ii ADJ  1 Det12 ADJs 1 Det 021 Noun 12 ADJs 1 Det2 NP 015 Verb 2 NP 014 VP 2 NP 04 S 0Acceptthe yel lows cab stops01 Det 012 ADJs 1 Det 025 Noun 12 ADJs 1 DetFai lsFigure 2.
The parsing of the two alternatives for "the yelow cab stops".would result in one parse tree without an error mes-sage and five parse trees indicating that the numberof they does not agree with the number of think.
Byusing sets of values instead of single values thisnumber can be reduced, but in general the numberof parses will be very large.
Especially with largergrammars and longer sentences there will be largeamounts of parses with all sorts of error messages.A simple method to differentiate between theseparses is to simply count the number of errors,agreement violations, structural errors and spellingerrors in each parse, and to order the parses accord-ingly.
Then one only has to look at the parse(s) withthe smallest number of errors.
However, this conceptof weight needs to be extended since not all errorsare equally probable.
Some types of agreement viola-tion simply never occur whereas others are oftenfound in written texts.
Orthographical nd typo-graphical errors and homophone substitution arefrequent phenomena while structural errors are rela-tively rare.
Suppose the parser encounters a sentencelike Word je broer geopereerd?
(Eng.
: Are your brother(being) operated?).
In Dutch this is a frequent error(see section 2.3), since the finite verb should indeedbe word if je instead of je broer were the subject.
(Translating word-by-word into English, the correc-tion is either/s your brother (being) operated?
or Areyou brother (being) operated?
Je is either you or your.
)The most likely correction is the first one.
How can asyntactic parser distinguish between these twoalternatives?
My solution involves adding errorweights to grammar rules.
These cause a parse inwhich verb transitivity is violated to receive a heav-ier penalty than one with incorrect subject verbagreement.
Thus, parse trees can be ordered accord-ing to the sum of the error weight of each of theirnodes.4.4.
Word LatticesAs noted in section 2.5, idiomatic expressions causeparsers a lot of trouble.
I therefore propose that theparser should not operate directly on a linear sen-tence, but on a word lattice that has been preparedby a pre-processor.
For a sentence like Hij kan te allentijde komen logeren (he can come to stay at all tim~)such a structure might look like Figure 3.
Instead ofparsing each word of the expression te allen tijde sep-arately, the parser can take it as a single word span-ning three word positions at once or as three sepa-rate words.
Should one of the words in the expres-sion have been misspelled, the pre-processor buildsa similar structure, but labels it with an error mes-sage containing the correct spelling obtained fromthe spelling corrector.
Word lattices can of coursebecome much more complex than this example.Since there is a pre-processor that is able to com-bine multiple words into a single item, it might aswell be used to aid the parser in detecting two fur-ther types of errors as well.
The first one is the Dutchsplit compound.
By simply joining all the adjacentnouns (under some restrictions) the grammar andthe parser can proceed as if split compounds do notoccur.
The second error type is word doubling.
Thepre-processor can join every subsequent repetition ofa word with the previous occurrence so that theywill be seen both as two distinct words and as onesingle word (since not every occurrence of wordrepetition is wrong).
Another possibility is to con-catenate adjacent words when the concatenated formoccurs as one entry in the dictionary.
E.g.
manypeople do not know whether to write er op toe zien,erop toezien, erop toezien or any other combination(though a parser might not always have the rightanswer either).5.
Integration and HeuristicsThe combination of the modules described above- -  a spell checker with compound analysis, aspelling corrector, a robust parser and a syntacticcorrector - -  does not lead by itself to a batch-oriented proof-reading system.
Most texts do notonly contain sentences, but also rifles and chapterheadings, captions, jargon, proper names, neolo-gisms, interjections, dialogues ("yes", she sa/d, "yes,that is true, but..."), quotations in other languages,literature references, etcetera, not to mention mark-up and typesetting codes.
The system therefore hasa mechanism for dealing with the layout aspects of115?ologeren IFigure 3.
A word lattice.texts and some heuristics for dealing with propernames, jargon and neologisms.
The layout aspectsinclude mark-up codes and graphics, title markersand a mechanism for representing diacritics, such asthe diaeresis, which is frequent in Dutch.Dictionaries eldom contain all words found in atext.
In Dutch, part of the problem can be solved byusing compound analysis.
However, a misspelledword can sometimes be interpreted as a compound,or as two words accidentally written together.
I par-tially solved this problem by having the compoundanalyzer repeat he analysis without he word gram-mar if it fails with the word grammar, and by defin-ing a criterion which marks certain compounds as"suspicious " .
If the analyzer marks the compoundas either suspicious or ungrammatical, the spellingcorrector is invoked to see if a good alternative (i.e.closely resembling and frequent word) can be foundinstead, or, else, if the compound was ungrammati-cal, whether it can be split into separate words.
Thisprocess is further improved by adding the correctcompounds in the text to the internal word list of thespelling corrector.Other words that do not appear in a dictionaryare proper names, jargon and neologisms.
Thereforethe system first scans the entire text for all wordtypes while counting the tokens before it starts pars-ing.
My rule of thumb is to treat words, that appearmainly capitalized in the text as proper names.Frequently occurring words, that do not have a goodcorrection, are supposed to be neologisms.
Bothproper nouns and neologisms are added to the in-ternal word list of the spelling corrector.
The maindisadvantage of this approach is that it misses con-sistently misspelled words.
At the end of the runtherefore, the system provides a list of all the wordsit tacitly assumed to be correct, which must then bechecked manually.Another feature of the system is that it coercesvariant spelling into preferred spelling.
This featurealso takes compounds which have is no official pre-ferred spelling into consideration, thus preventingcompound to be written in different ways.
E.g.
both5Misspelled word can often be analyzed as sequencesof very small words.
E.g.
the misspelledkwaliteitesverbetering (which should be kwaliteitsverbetering,Eng.
: quality improvement) can be divided intokwaliteit +es+verbetering, which could mean quality ashimprovement.
The amount of overgeneration correlatesstrongly with the size of the dictionary.spellingcorrectie and spellingscorrectie (Eng.
: spellingcorrection) are correct in Dutch.
My system onlyallows one to occur in a text and coerces the leastfrequently occurring variants into the most frequentone.The last but not least important tricks help to re-duce parsing time.
Since the system cannot detect alltypes of errors with equal reliability (cf.
section 6), Iadded a d/t-mode in which only sentences that mightcontain a d/t-error (cf.
section 2.2) are parsed.
In thismode a pre-processor fi st checks whether the sen-tence contains uch a "d/t-risk" word.
If this is thecase the parser is invoked, but the error messagesnot pertaining to this class of errors are suppressed.As d/t-risks show up in less than a quarter of all sen-tences, parsing time is cut by a factor of four at least.Although this solution can hardly be called elegant,it gives the user a faster and more reliable system.There also is an upper bound on the number ofallowed parses.
Because analyzing a parse tree takessome time, this speeds up the process.
The disadvan-tage is that the system may choose an unlikely cor-rection more often as it cannot compare all parsetrees.
Large sentences with multiple errors may pro-duce thousands of parse trees, each of which has tobe scored for comparison.
As the allowed number ofparses becomes less than the potential number ofparses, the probability that the system overlooks alikely correction grows.
But since it produces anerror message anyway, albeit an unlikely one, theadvantage outweighs the disadvantage.6.
Results and EvaluationThe system described in this paper has been built asa practical writing aid that operates non-inter-actively, because the first phase (determining wordtypes, compound analysis, initial spelling correction,and cross-checking corrections for the entire text)takes too long.
Nevertheless, it can easily processmore than 25 words per second 6for a large text,which may easily take up half an hour or more.As an example of the performance in the wordlevel checking phase, I presented the system with a6I have written the system in the programminglanguage C. The results reported below were obtainedwith the program running on a DECstation 3100.
Part ofthe speed erives from the frequent repetition of manywords in large texts.116random sample of 1000 lines from two large texts 7.The sample contained nearly 6000 words, with 30true spelling errors.
Of these, 14 were correctedappropriately, and 14 were found but substituted byan incorrect alternative or not corrected at all.
Of the14 appropriately corrected errors, 9 were errors indiacritics only.
The system only missed 2 errors,which it assumed to be proper names (both reportedat the end of the file (cf.
section 5)).
It also produced18 false alarms, 11 of which were caused by very in-frequent jargon or inflected word forms missingfrom the dictionary.Comparison with other spell checkers i  hardlypossible.
For Dutch, only elementary spell checkersbased on simple word lookup are available.
If thismethod is applied to the sample text with the samedictionary as used in the full system, the result is en-tirely different.
Such a simple spell checker marks217 words as misspelled.
Among these are not onlythe 21 true errors and the 9 errors wrongly placeddiacritics, but also 37 abbreviations and propernames, and 150 compounds.
This amounts to a totalof 187 false alarms!The sentence level requires considerably moretime.
Error-free short sentences can be parsed at aspeed of four or more words per second, but longsentences containing one or more errors may requireseveral seconds per word (including correction,which is also rather time consuming).
For the textsmentioned in footnote 7 (110,000 words in total), theCPU time required for parsing was approximately 7hours.But what counts is not only speed; quality is atleast equally important.
Preliminary tests haveshown satisfactory results.
A 150 sentence spellingtest for secretaries and typists, with an average sen-tence length between six and seven, was performedwithin nine minutes (elapsed time) leaving onlythree errors undetected, correcting the other 72errors appropriately and producing no false alarms.
(Human subjects passed the test if they could com-plete it within ten minutes making at most ten mis-takes.)
The three undetected errors involved seman-tic factors, and were therefore beyond the scope ofthe system.
The rightly corrected errors were typo-graphical and (mainly) orthographical errors,agreement errors and errors in idiomatic expres-sions.7These manuscripts are representative fortextssubmitted to the system by a publisher who has access toit.
A typical example isa text concerning employmentlegislation and collective wage legislation of over 660,000characters (atotal of 92,000 words) of plain text withmark-up instructions.
Checking the words and correctingmisspelled words took 16 CPU minutes, which results in aspeed of nearly 100 words per CPU second.
A smaller textin the same content domain (150,000 characters in27,500words) was checked and corrected at word level in 4.5minutes of CPU time, which is over 100 words per CPUsecond.Other spelling exercises also showed good results(most errors detected and most corrected properly,very few false alarms, if any).
A typical text was cho-sen from a text book with correction exercises forpupils.
In contrast with the spelling test described inthe previous paragraph, most sentences in this testcontained more than one spelling error.
The errorsvaried from superfluous or missing diaeresis to splitcompounds and d/t-errors.
On a total of 30 sentences,the system discovered 75 errors, of which 62 werecorrected properly, 12 miscorrected and one wasgiven no correction at all; it missed 7 errors, whileproducing one false alarm.
Although the total num-ber of words was only half the number of words inthe previous test (457 to be precise), the system tookalmost hree times as much time to process it.
Thiswas partly due to the greater average sentencelength (over 15 words per sentence) and the occur-rence of more than one error per sentence (up to fourper sentence).
The number of errors that could nothave been detected without a parser was 18.
Ofthese, 10 were corrected and 1 was detected butsubstituted by a wrong alternative, while the parsermissed the 7 errors mentioned earlier.On large real texts, i.e.
not constructed for thepurpose of testing one's knowledge of spelling, thesystem performed less well due to parsing problems.As an example of a well written text, I took the first1000 lines of a text mentioned in footnote 7.
Thissample consisted of 7443 words in 468 sentences (anaverage of nearly 16 words per sentence).
At wordlevel it performed quite satisfactorily.
It caused 12false alarms 8, while detecting 11 true errors, ofwhich only 4 were properly corrected.
The com-pound analysis functioned almost flawlessly.However, it caused 6 of the 12 false alarms, becauseone single word, which was not in the dictionary,appeared in 4 different compounds.
The heuristicsfor suspicious words cooperated very well with thespelling correcter (6 correct guesses, 2 wrong).The parser's performance however degradedconsiderably.
One reason was the great length ofmany sentences (up to 86 words).
This sometimescaused the parser to exceed its built-in time limit, sothat it could not give a correct error message 9.
Longsentences are also highly ambiguous.
This increasesthe probability of finding a very awkward but error-free parse, thereby overlooking real errors.
Anotherreason for the performance degradation was theabundant use of interjections, names (betweenquotes, dashes or parentheses) and colloquial(ungrammatical) expressions.
Although the parserhas some provisions for simply skipping such con-8In 4 cases, the false alarm was caused by wordcontraction.
E g. the word echtgeno(o)t(e), which issupposed to mean echtgenoot f echtgenote (husband or wife),was marked incorrect and substituted by echtgenoot.9Unfortunately, the program does not keep track ofthis, so no data can be specified.117structions, they more often than not interfere witherror detection.
Fortunately, subject-verb agreementerrors indicating d/t-errors were spotted quite reli-ably, although their number (two in this sample,which were both corrected) is too small to draw anyfirm conclusion.
The detection of punctuation errorsand split compounds still needs improvement.Whether the results justify the 30 minutes CPU timeit took to parse the 468 sentences remains to be seen.7.
ConclusionsI have shown the feasibility of building a practicalgrammar-based spell checker that detects and cor-rects the important class of morpho-syntactic errorsin normal texts (i.e., texts that have not been spe-dally prepared before processing).
The system de-scribed in this paper is the first example of such aspell checker for Dutch.
It is currently being tested ata large publishing company.I have demonstrated what can be expected of theapproach I have taken.
Depending on the complexityof the sentences, the combination ofa word-levelspell checker plus a syntactic parser performs fromnearly perfect to satisfactory in regard to morpho-syntactic errors.
Other types of errors cannot behandled reliably with the current framework, partlydue to the permissive nature of both grammar anddictionary.
However, enrichment ofgrammar andlexicon is only possible on an ad hoc basis.
It will notlead to a systematic improvement of the correctionprocess.
Moreover, it is likely to interfere with theother components.
Although many details till haveto be worked out, the limits of this approach becomevisible.
The next major improvement must comefrom analysis beyond syntax.AcknowledgementsThe author would like to thank (in random order):Edwin Bos for commenting on earlier versions ofthis paper; Alice Dijkstra, for her work on this pro-ject and for proof-reading and commenting on thispaper; and Gerard Kempen, project leader, for dis-cussions and comments.ReferencesAngell, R.C., G.E.
Freund, P. Willet.
1983.
Automaticspelling correction using a trigram similaritymeasure.
Information Processing and Management (19),pp.
255-261.Berkel, Brigitte van, and Koenraad e Smedt.
1988.Triphone analysis: a combined method for thecorrection of orthographical and typographicalerrors.
In: Proc.
2nd Conference on applied naturallanguage processing.
Association for ComputationalLinguistics, pp.
77-83.Daelemans, W. 1987.
Studies in language technology:an object-oriented model of morpho-phonological aspectsof Dutch.
Ph.D. dissertation, University of Leuven.Kempen, Gerard, and Theo Vosse.
1990.
A languagesensitive ditor for Dutch.
In: Proc.
Computer &Writing III Conference, Edinburgh.Nakazawa, Tsuneko.
1991.
An extended LR parsingalgorithm for grammars using feature-basedsyntactic categories.
In: Proc.
5th Conference oftheEuropean chapter of the ACL, Berlin.
pp.
69-74.Richardson, S.D.
1988.
The experience ofdevelopinga large-scale natural language text processingsystem: CRITIQUE.
In: Proc.
2nd Conference onApplied Natural Language Processing.
Association forComputational Linguistics.Schwind, Camilla.
1988.
Sensitive parsing: erroranalysis and explanation i an intelligent languagetutoring system.
In: Proc.
COLING "88, Budapest, pp.608-613.Tomita, Masaru.
1986.
Efficient parsing for naturallanguage: a fast algorithm for practical systems.Dordrecht, Kluwer.Vosse, Theo.
1991.
Detection and correction ofmorpho-syntactic errors in shift-reduce parsing.
In:Tomita' sAlgorithm: Extensions and Applications.
R.Heemels, A. Nijholt, K. Sikkel (Eds.).
MemorandaInformatica 91-68, Univ.
of Twente, 1991, pp.
69-78.118
