Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1006?1016, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsEmploying Compositional Semantics and Discourse Consistency inChinese Event ExtractionPeifeng Li, Guodong Zhou, Qiaoming Zhu, Libin HouSchool of Computer Science & TechnologySoochow University, Suzhou, 215006, China{pfli, gdzhou, qmzhu, 20094227021}@suda.edu.cnAbstractCurrent Chinese event extraction systems suffermuch from two problems in triggeridentification: unknown triggers and wordsegmentation errors to known triggers.
Toresolve these problems, this paper proposes twonovel inference mechanisms to explore specialcharacteristics in Chinese via compositionalsemantics inside Chinese triggers and discourseconsistency between Chinese trigger mentions.Evaluation on the ACE 2005 Chinese corpusjustifies the effectiveness of our approach overa strong baseline.1 IntroductionEvent extraction, a classic information extractiontask, is to identify instances of a predefined eventtype and can be typically divided into four subtasks:trigger identification, trigger type determination,argument identification and argument roledetermination.
In the literature, most studies focuson English event extraction and have achievedcertain success (e.g.
Grishman et al 2005; Ahn,2006; Hardy et al 2006; Maslennikov and Chua,2007; Finkel et al 2005; Ji and Grishman, 2008;Patwardhan and Riloff, 2009, 2011; Liao andGrishman 2010; Hong et al 2011).In comparison, there are few successful storiesregarding Chinese event extraction due to specialcharacteristics in Chinese trigger identification.
Inparticular, there are two major reasons for the lowperformance: unknown triggers 1  and wordsegmentation errors to known triggers.
Table 1gives the statistics of unknown triggers and wordsegmentation errors to known triggers in both the1 In this paper, a trigger word/phrase occurring in the trainingdata is called a known trigger and otherwise, an unknowntrigger.ACE 2005 Chinese and English corpora2 using 10-fold cross-validation.
In each validation, we leave10% trigger mentions as the test set and theremaining ones as the training set.
If a mention inthe test set doesn?t occurred in the training set, weregard it as an unknown trigger.
It shows that thesetwo cases cover almost 30% of Chinese triggermentions while this figure reduces to only about9% in English.
It also shows that given the samenumber of event mentions, there are 30% moredifferent triggers in Chinese than that in English.This justifies the low performance (specifically,the recall) of a Chinese event extraction system,which normally extracts those known triggersoccurring in the training data as candidateinstances and uses a classifier to distinguish correcttriggers from wrong ones.Language Chinese English%unknown triggers 33.7% 18.5%%unknown trigger mentions 20.9% 8.9%%word segmentation errorsto known trigger mentions8.7% 0%#triggers 763 586Table 1.
Statistics: a comparison between Chinese andEnglish event extraction with regard to unknowntriggers and word segmentation errors to known triggers.Note that word segmentation only applies to Chinese.In this paper, we propose two novel inferencemechanisms to Chinese trigger identification byemploying compositional semantics inside Chinesetriggers and discourse consistency betweenChinese trigger mentions.The first mechanism is motivated by thecompositional nature of Chinese words, whosesemantics can be often determined by thecomponent characters.
Hence, it is natural to infer2  The whole Chinese ACE corpus has about 3300 eventmentions.
For the sake of fair comparison, we choose the samenumber of event mentions from the English corpus as thecross-validation data.1006unknown triggers by employing compositionalsemantics inside Chinese triggers.The second mechanism is enlightened by thewide use of discourse consistency in naturallanguages, particularly for Chinese, due to itsdiscourse-driven nature (Zhu, 1980).
Very often,distinguishing true trigger mentions from pseudoones is only possible with contextual information.The rest of this paper is organized as follows.Section 2 overviews the related work.
Section 3introduces a state-of-the-art baseline system forChinese event extraction.
Sections 4 and 5 describetwo novel inference mechanisms to Chinese triggeridentification by employing compositionalsemantics inside Chinese triggers and discourseconsistency between Chinese trigger mentions.Section 6 presents the experimental results.
Section7 concludes the paper and points out future work.2 Related WorkAlmost all the existing studies on event extractionconcern English.
While earlier studies focus onsentence-level extraction (Grishman et al 2005;Ahn, 2006; Hardy et al 2006), later ones turn toemploy high-level information, such as document(Maslennikov and Chua, 2007; Finkel et al 2005;Patwardhan and Riloff, 2009), cross-document (Jiand Grishman, 2008), cross-event (Liao andGrishman, 2010; Gupta and Ji, 2009) and cross-entity (Hong et al 2011) information.2.1 Chinese Event ExtractionCompared with tremendous efforts in Englishevent extraction, there are only a few studies onChinese event extraction.Tan et al(2008) modeled event extraction as apipeline of classification tasks.
Specially, they useda local feature selection approach to ensure theperformance of trigger classification (triggeridentification + trigger type determination) andapplied multiple levels of patterns to improve thecoverage of patterns in argument classification(argument identification + argument roledetermination).
Chen and Ji (2009a) proposed abootstrapping framework, which exploited extrainformation captured by an English eventextraction system.
Chen and Ji (2009b) appliedvarious kinds of lexical, syntactic and semanticfeatures to address the specific issues in Chinese.They also constructed a global errata table torecord the inconsistency in the training set andused it to correct the inconsistency in the test set.
Ji(2009) extracted cross-lingual predicate clustersusing bilingual parallel corpora and a cross-lingualinformation extraction system, and then used thederived clusters to improve the performance ofChinese event extraction.2.2 Compositional SemanticsAlmost all the related studies on compositionalsemantics focus on how to combine words togetherto convey complex meanings, such as semanticparser (Zettlemoyer and Collins, 2007; Wong andMooney, 2007; Liang et al 2011).
However, thecompositional semantics mentioned in this paper ismore fined-grained and focuses on how toconstruct Chinese characters into a word and minethe semantics of words from the word structures,especially of verbs as event triggers.To our knowledge, there is only one paperassociated with compositional semantics insideChinese words.
Li (2011) discussed the internalstructures inside Chinese nouns and used it in wordsegmentation.2.3 Discourse ConsistencyDiscourse consistency is an important hypothesisin natural languages and has been applied to manynatural language processing applications, such asnamed entity recognition and coreferenceresolution.
Specially, several studies havesuccessfully incorporated trigger or entityconsistency constraint into event extraction.Yarowsky (1995) and Yangarber et al(Yangarber and Jokipii, 2005; Yangarber et al2007) applied cross-document inference to refinelocal extraction results for disease name, locationand start/end time.
Mann (2007) proposed somespecific inference rules to improve extraction ofpersonal information.
Ji and Grishman (2008)employed a rule-based approach to propagateconsistent triggers and arguments across topic-related documents.
Gupta and Ji (2009) used asimilar approach to recover implicit timeinformation for events.
Liao and Grishman (2011)also used a similar approach and a self-trainingstrategy to extract events.
Liao and Grishman(2010) employed cross-event consistencyinformation to improve sentence-level eventextraction.
Hong et al(2011) regarded entity type1007consistency as a key feature to predict eventmentions and adopted this inference method toimprove the traditional event extraction system.3 BaselineAs a baseline, we re-implement a state-of-the-artsystem, which consists of four typical components(trigger identification, trigger type determination,argument identification and argument roledetermination), in a pipeline way and employ thesame set of features as described in Chen and Ji(2009b).Besides, the Maximum-Entropy (ME) model isemployed to train individual component classifiersfor the above four components.
During testing,each word in the test set is first scanned forinstances of known triggers from the training set.When an instance is found, the trigger identifier isapplied to distinguish true trigger mentions frompseudo ones.
If true, the trigger type determiner isthen applied to recognize its event type.
For anyentity mentions in the sentence, the argumentidentifier is employed to assign possible argumentsto them afterwards.
Finally, the argument roledeterminer is introduced to assign a role to eachargument.One problem with Chen and Ji?s system is itsignoring effective long-distance features.
In orderto resolve this problem and provide a strongerbaseline, we introduce more refined anddependency features in four components:?
Trigger Identification and Trigger TypeDetermination: 1) syntactic features: path tothe root of the governing clause, 2) nearestentity information: entity type of leftsyntactically/physically nearest entity to thetrigger + entity, entity type of rightsyntactically/physically nearest entity to thetrigger mention in the sentence + entity; 3)dependency features: the subject and the objectof the trigger when they are entities.?
Argument Identification and Argument RoleDetermination: 1) basic features: POS oftrigger; 2) neighboring words: left neighboringword of the entity + its POS, right neighborword of the entity + its POS, left neighbor wordof the trigger + its POS, right neighbor word ofthe trigger + its POS; 3) dependency feature:dependency path from the entity to the trigger;4) semantic role features: Arg0 and Arg1 whichtagged by semantic role labeling tool (Li, et al2010).3.1 Experimental SettingThe ACE 2005 Chinese corpus (only the trainingdata is available) is used in all our experiments.The corpus contains 633 Chinese documentsannotated with 8 predefined event types and 33predefined subtypes.
Similar to previous studies,we treat these subtypes simply as 33 separate eventtypes and do not consider the hierarchical structureamong them.Following Chen and Ji (2009b), we randomlyselect 567 documents as the training set and theremaining 66 documents as the test set.
Besides,we reserve 33 documents in the training set as thedevelopment set, and follow the setting of ACEdiagnostic tasks and use the ground truth entities,times and values for our training and testing.For evaluation, we follow the standards asdefined in Ji (2009):?
A trigger is correctly identified if its position inthe document matches a reference trigger;?
A trigger type is correctly determined if itsevent type and position in the document matcha reference trigger;?
An argument is correctly identified if itsinvolved event type and position in thedocument match any of the reference argumentmentions;?
An argument role is correctly determined if itsinvolved event type, position in the document,and role match any of the reference argumentmentions.Finally, all sentences in the corpus are dividedinto words using a word segmentation toolICTCLAS3 with all entities annotated in the corpuskept.
Besides, we use Stanford Parser (Levy andManning, 2003, Chang, et al 2009) to create theconstituent and dependency parse trees and employthe ME model to train individual componentclassifiers.3.2 Experimental ResultsTable 2 and 3 show the Precision (P), Recall (R)and F1-Measure (F) on the held-out test set.
Itshows that our baseline system outperforms Chenand Ji (2009b) by 1.8, 2.2, 3.9 and 2.3 in F1-measure on trigger identification, trigger type3 http://ictclas.org/1008determination, argument identification andargument role determination, respectively, withboth gains in precision and recall.
This is simplydue to contribution of the newly-added refined anddependency features.PerformanceSystemTriggerIdentificationTrigger TypeDeterminationP(%) R(%) F P(%) R(%) FChen and Ji(2009b)71.5 51.2 59.7 66.5 47.7 55.6Our Baseline 75.2 52.0 61.5 70.3 49.0 57.8Table 2.
Performance of trigger identification andtrigger type determinationPerformanceSystemArgumentIdentificationArgument RoleDeterminationP(%) R(%) F P(%) R(%) FChen and Ji(2009b)56.1 38.2 45.4 53.1 36.2 43.1Our Baseline 58.4 42.7 49.3 55.2 38.6 45.4Table 3.
Performance of argument identification andargument role determinationFor our baseline system, given the smallperformance gaps between trigger identificationand trigger type determination (3.7 in F1-measure:61.5 vs. 57.8) and between argument identificationand argument role determination (3.9 in F1-measure: 49.3 vs. 45.4), the performancebottlenecks of our baseline system mainly exist intrigger identification and argument identification,particularly for the former one.
While argumentidentification has the performance gap of 8.5 inF1-measure compared to trigger typedetermination (49.3 vs. 57.8), the former one,trigger identification, can only achieve theperformance of 61.5 in F1-measure (in particularthe recall with only 52.0).
In this paper, we willfocus on trigger identification to improve itsperformance, particularly for the recall, viacompositional semantics inside Chinese triggersand discourse consistency between Chinese triggermentions.4 Employing Compositional Semanticsinside Chinese TriggersLanguage is perhaps the only communicativesystem in nature, which compositionally buildsstructured meanings from smaller pieces, and thiscompositionality is the cognitive mechanism thatallows for what Humboldt called language?s?infinite use of finite means.?
As usual, the lexicalsemantics is the smallest piece in most Chineselanguage processing applications.
In this section,we introduce a more fine-grained semantics - thecompositional semantics in Chinese verb structure- and unveil its effect and usage in Chineselanguage processing by employing it into Chineseevent extraction.4.1 Compositional Semantics inside ChineseTriggersIn English, a component character is just the basicunit to form a word instead of a semantics unit.
Incomparison, almost all Chinese characters havetheir own meanings and can be formed as SCWs(Single Character Words) themselves.
If a Chineseword contains more than one character, itsmeaning can be often inferred from the meaningsof its component characters (Yuan, 1998).
Actually,it is the normal way of understanding a newChinese word in everyday life of a Chinese nativespeaker.
A general method to this problem is tosystematically explore the morphologicalstructures in Chinese words.
In this paper,compositional semantics provides a simple buteffective compromise to the general method andwe leave the general method in the future work.Table 4 shows samples of such compositionalsemantics in Chinese words.
For example, ???
?is composed of two characters: ???
and ??
?which have their own semantics and the semanticsof ???
?
comes from that of its componentcharacters ???
and ??
?.Words Characters??
(interview4) ?
(meet) ?(meet)??
(shoot and kill) ?
(shoot) ?
(kill)??(come)??
(private letter)?
(come) ?
(to)?
(private) ?
(letter)Table 4.
Examples of compositional semantics inChinese wordsTherefore, it is natural to infer unknown triggersby employing compositional semantics insideChinese triggers.
Take following two sentences asexamples:(1) 4?????????
(Known trigger)4  Most Chinese words have more than one sense.
Here, wejust give the one when it acts as a trigger.1009(Four students were scratched by the glass.
)(2)  1???????
(Unknown trigger)(A passenger was stabbed.
)where ????
is a known trigger and ????
is anunknown one.In above examples, the semantics of ????
(injure by scratching) can be largely determinedfrom those of its component characters ??
?
(scratch) and ???
(injure) while the semantics of???
?
(injure by stabbing) from those of itscomponent characters ???
(stab) and ???
(injure).Since these two triggers have similar internalstructures, we can easily infer that ????
is atrigger of injure event if ????
is known as atrigger of injure event.
Similarly, we can infermore triggers for injure event, such as ????
(injure by burning), ????
(injure by hitting), ???
?
(injure by pressing), all with componentcharacter ???
(injure) as the head and the othercomponent character as the way of causing injury.Since most triggers in Chinese event extractionare verbs 5 , we focus on the compositionalsemantics in the verb structure.
Statistics on thetraining set shows that 3.3% triggers (e.g.
?????
(open letter), ????
(event), ????
(patient'scondition), etc.)
don?t contain a BV and all of themare nouns.
Normally, almost all verbs contain oneor more single-character verbs as the basic elementto construct a verb (we call it basic verb, shorted asBV) and the semantics of such a verb thus can beinferred from its BV.
There are some studies on theChinese verb structure in linguistics.
However,their structures are much more complex and thereare no annotated corpora available.
We definefollowing six main structures from our empiricalobservations:(1) BV (e.g.
???
(see), ???
(kill))(2) BV + verb (e.g.
????
(meet))(3) verb + BV (e.g.
????
(fire) )(4) BV + complementation (e.g.
????
(kill) )(5) BV + noun/adj.
(e.g.
????
(go to home))(6) noun/adj.
+BV (e.g.
????
(shoot usinggun)).5 Actually, in the ACE 2005 Chinese (training) corpus, morethan 90% of triggers are either verbs al or verbal nouns (thoseverbs which act as nouns).
For simplicity, we don?tdifferentiate these two types in this paper.From above structures, a BV plays an importantrole in the verb structure and most of semantics ofa verb can be interred from its contained BV andtwo words normally have very similar semantics ifthey have the same BV (e.g.
????
(meet) and????
(meet)).
Actually, sometime the verb canbe shortened to its contained BV (e.g.
??????
?
and ???????
?
have the samesemantics.
).4.2 Inferring via Compositional Semanticsinside Chinese TriggersHere a simple rule is employed to infer triggers viacompositional semantics inside Chinese triggers: averb is a trigger if it contains a BV which occursas a known trigger or is contained in a knowntrigger.
Table 5 shows the distribution of the set oftriggers (contains the same BV 6 ) classified bynumber of triggers.From Table 5, we can find out that 85.3% ofBVs occur in more than one trigger and 56.2% ofthem in more than 4 triggers.
As for triggermentions, these percentages become 89.1% and65.2% respectively.
A extreme example is that85.2% (75/88) of triggers of Trial-Hearing eventmentions contain ???
(trial) and 85.4% (117/138)of triggers of injure event mentions contains ???
(injure).Number  Distribution overTriggersDistribution overTrigger Mentions1 14.7% 10.9%2~4 29.1% 23.9%5~9 28.1% 32.9%>=10 28.1% 32.3%Table 5.
Distribution of BVs in the number oftriggers/trigger mentionsIn this paper, the inference is done as follows:?
Add all single-character triggers into the BV setif it?s a verb;?
Split all other triggers in the training set into aset of single characters and include all singlecharacters into the BV set if it?s a verb;?
For each word in the test set, it is identified as atrigger if it contains a BV.It is worthwhile to note that such inferenceworks for unknown triggers and word6 We didn?t tag BVs in the training set and regards all single-character verbs contained in triggers as BVs.1010segmentation errors to known triggers since in bothcases, their BVs will always exist as either a SCWor a component of a word.4.3 Noise FilteringOne problem with above inference is that while itis able to recover some true triggers and increasethe recall, it may introduce many pseudo ones andharm the precision.
To filter out those pseudotriggers, we propose following rules according toour intuition and statistics over the training set.Non-trigger FilteringA Chinese word will not be a trigger if itappears in the training set but never trigger anevent.
Statistics on the training set shows that thisrule applies at 99.7% of cases.POS filteringA Chinese word will not be a trigger if it has adifferent POS from that of the same knowntrigger or similar known triggers 7  in thetraining set.
In Chinese, a single-character verbhas very high probability of composing words (e.g.???
(come), ???
(act as), ???
(combine), etc)with different POS from the single-character verbitself, such as preposition (e.g.
???
?
(for)),conjunction (e.g.
????
(and)), etc.
Statistics onthe training set shows that this rule applies at97.3% of cases.Verb structure filteringA Chinese word will not be a trigger if its verbstructure is different from that of the sameknown trigger or similar known triggers in thetraining set.
Figure 1 shows different distributionsof three BVs over six verb structures as describedin subsection 4.1.
For example, we can find that alltriggers including ???
(unbind) (e.g.
????
(fire),????
(fire), ????
(disband)) just have one verbstructure (BV + verb) and those of ???
(kill) have4 structures.
Obviously, we can use suchdistribution information to filter out pseudotriggers.
For example, although both word ????
(console) and ????
(decompose) are constructedform verb ??
?, their verb structure (verb + BV)does not appear in the training set.
Therefore, theywill be filtered our via verb structure filtering.7 Similar triggers are those ones which have the same BV andverb structure.Statistics on the training set shows that this ruleapplies at 95.5% of cases.00.20.40.60.81BV verb+BVBV+VerbN/Adj+BVBV+CompBV+N/Adj??
?Figure 1.
Distribution of three BVs (???
(unbind), ???
(trial) and ???
(kill)) over six verb structures inconstructing triggers5 Employing Discourse Consistencybetween Chinese Trigger MentionsChinese event extraction may suffer much from theerrors propagated from upstream processing suchas part-of-speech tagging and parsing, especiallyword segmentation.
To alleviate wordsegmentation errors to known triggers, Chen and Ji(2009b) constructed a global errata table to recordthe inconsistency in the training set and proved itseffectiveness.
In this paper, a merge and splitmethod is applied to recover those known triggers.In this way, word segmentation errors can bealleviated to certain extent.For unknown triggers, we can merge two ormore neighboring short words or single charactersas a trigger candidate.
In this paper, for eachsingle-character verb in a document after wordsegmentation, this single-character verb can bemerged with either previous SCW or next SCW toform a trigger candidate if this single-characterverb has occurred in the training set with the sameverb structure.Given above recovered triggers for both knownand unknown triggers, the key issue here is how todistinguish true triggers from pseudo ones.
In thispaper, we employ discourse consistency betweenChinese trigger mentions for Chinese eventextraction.
Previous studies on English eventextraction have proved the effectiveness of bothcross-entity and cross-document consistency.5.1 Discourse Consistency between ChineseTrigger MentionsAs a discourse-driven language, the syntax of1011Chinese is not as strict as English and sometimewe must infer from the discourse-level informationto understand the meaning of a sentence.
Kim(2000) compared the use of overt subjects inEnglish and Chinese and he found that overtsubjects occupy over 96% in English, while thispercentage drops to only 64% in Chinese.Similarly, argument missing is another issue inChinese event extraction and almost 55% ofarguments are missing in the ACE 2005 Chinesecorpus.
Normally, using a feature-based approachto distinguish true triggers from pseudo ones isvery difficult from the sentence level if some ofrelated arguments are missing from the trigger-occurring sentence.
Take following two contingentsentences as examples:(3) ?????
3????????????
(The United States and the DemocraticPeople's Republic of Korea finished missiletalks in Kuala Lumpur.
)(4) ????????
(The talks are serious.
)While it is relatively easy to determine thatmention ????
in sentence (3) indicates a meetevent from the contained information in itself(there are many entities, such as agents, time andplace in the sentence) and difficult to determinethat mention ????
in sentence (4) is a meet eventfrom the contained information in itself, we caneasily infer from sentence (3) that sentence (4) alsoindicates a meet event, using discourse consistency:if one instance of a word is a trigger mention, otherinstances in the same discourse will be a triggermention with high probability.Language Discourse-based Instance-basedEnglish 70.2% 87.5%Chinese 90.5% 95.4%Table 6.
Comparison of discourse consistency betweenChinese and English trigger mentionsTable 6 compares the probabilities of discourseconsistency between Chinese and English triggermentions in the ACE 2005 Chinese and Englishcorpora.
A trigger may appear many times in adiscourse.
It?s considered discourse-consistentwhen all the appearances of a trigger have thesame event type while instance-based consistencyrefers to pair-wired cases.
It shows that within thediscourse, there is a strong consistency in bothChinese and English between trigger mentions: ifone instance of a word is a trigger, other instancesin the same discourse will be a trigger of the sameevent type with very high probability.0.850.90.951???
???
??????????
?Figure 2.
Probabilities of discourse-level consistency oftop 10 frequent triggersIt also shows that discourse consistency inChinese triggers holds much more likely than theEnglish counterpart.
Figure 2 give the probabilitiesof discourse-level consistency of top 10 frequenttriggers, which occupy 18% of event mentions inthe ACE 2005 Chinese corpus.5.2 Inference via Discourse Consistencybetween Chinese Trigger MentionsGiven a discourse and different mentions of atrigger returned by the trigger identifier, we cansimply accept those mentions with high probabilityas true mentions of the trigger and discard thosewith low probability8.
However, for those mentionsin-between, an additional discourse-level triggeridentifier is further employed to determine whethera trigger mention is true or not from the discourselevel by augmenting the normal trigger identifierwith several features to explore the consistencyinformation between trigger mentions in thediscourse (first three features) and the relatedinformation returned from the trigger typeidentifier (last two features).?
Probability of the discourse consistency of thecandidate trigger mention in the training set.
Ifit doesn?t exist in the training set, we infer itsprobability from that of all of its similar triggers?
Number of candidate trigger mentions being atrigger in the same discourse via triggeridentification?
Number of candidate trigger mentions being anon-trigger in the same discourse via triggeridentification8 The high and low probability thresholds are fine-tuned to95% and 5% respectively, using the development set.1012?
Event type of candidate trigger mention viatrigger type determination?
Confidence of trigger type determination6 ExperimentsIn this section, we evaluate our two inferencemechanisms in Chinese trigger identification andits application to overall Chinese event extraction,using the same experimental settings as describedin Subsection 3.1.6.1 Chinese Trigger IdentificationTable 7 shows the impact of compositionalsemantics in trigger identification.
Here, thebaseline just extracts those triggers occurring in thetraining data.
It justifies the effectiveness of ourcompositional semantics-based inferencemechanism in recovering true triggers and its threefiltering rules in removing pseudo triggers.NumbersApproachesTriggers Non-triggersBaseline 266 629+Compositional semanticswithout filtering334 1885+ Non-trigger filtering 328 1062+ POS filtering 325 974+ Verb structure filtering 302 444Gold 367 -Table 7.
Impact of compositional semantics in triggeridentificationTo reduce those pseudo triggers after aboveinference process, three rules are introduced.The first rule, the non-trigger filtering rule,filters out those pseudo ones in the test set whichdo not frequently occur as trigger mentions in thetraining set.
In particular, to keep true triggers inour candidate set as many as possible, we just filterout those candidates which occur as non-triggersmore than 5 times in the training set according toour validation on the development set.
Table 7shows that 43.7% (823) of pseudo triggers arefiltered out while only 1.8% (6) of true ones iswrongly filtered out.The second rule, the POS filtering rule, justfilters out 8.3% (88) of pseudo triggers, due toPOS errors in word segmentation and constituentparsing (e.g.
9.4% of candidate triggers havewrong POS tags in the development set.).
Manualinspection shows that if we correct those wrongPOS tags, that percentage will be increased to14.5%.The third rule, the verb structure filtering rule, isdeployed in following steps: 1) keeping allcandidates if they act as a trigger in the training set;2) if the candidate is a SCW, removing it when itdoes not occur as a BV in any triggers in thetraining set; 3) if the candidate is not a SCW,calculating the condition probability of its similartrigger words as triggers in the training set9 andthen deleting all candidates whose conditionalprobabilities are less than a threshold ?
, which isfine-tuned to 0.5.
Figure 3 shows the effect onprecision, recall and F1-measure of varying thethreshold?
on the development set.0.50.60.70.80 0.10.20.30.40.50.60.7PRFFigure 3.
Effect of threshold ?
on the developmentsetPerformanceSystemTrigger IdentificationP(%) R(%) FBaseline 75.2 52.0 61.5+Compositional semanticswithout filtering34.8 66.8 45.8+ Non-trigger filtering 49.4 66.5 56.7+ POS filtering 50.2 65.9 57.0+ Verb structure filtering 73.5 62.1 67.4+Discourse consistency 79.3 63.5 70.5Table 8.
Contribution to Chinese triggers identification(incremental)Table 8 shows the contribution of employingcompositional semantics and discourse consistencyto trigger identification on the held-out test set.
Wecan find out that our approach dramaticallyenhances F1-measure by 9.0 units, largely due to adramatic increase of 11.5% in recall, benefitingfrom both compositional semantics and discourseconsistency mechanisms.
We expect that theprecision will also increase since our filteringapproach successfully filters out almost 30% more9 If there are more than one BV in a candidate, we calculatethe average one.1013non-triggers and the number of non-triggermentions is less than that of the baseline.Unfortunately, the resulting set of 444 non-triggermentions (after all filtering) is not a subset oforiginal 629 non-trigger ones.
Our observationshows that our compositional semantics inferenceadds almost 10% new non-triggers into candidateswhich are very hard to distinguish.Table 8 also justifies the impact of the discourseconsistency between trigger mentions in triggeridentification and the effect of the additionaldiscourse-level trigger identifier, with a big gain of5.8% in precision and a small gain of 1.4% inrecall.6.2 Chinese Event ExtractionTable 9 shows the contribution of triggeridentification with compositional semantics anddiscourse consistency to overall event extractionon the held-out test set.
In addition, we also reportthe performance of two human annotators (Thehuman annotator 1 is a first year postgraduatestudent with no background to Chinese eventextraction while the human annotator 2 is a thirdyear postgraduate student working on Chineseevent extraction) on 33 texts (a subset of the held-out test set).
From the results presented in Table 9,we can find that our approach can improve the F1-measure for trigger identification by 9.0 units,trigger type determination by 9.1 units, argumentidentification by 6.0 units and argument roledetermination (i.e.
overall event extraction) by 5.4units, largely due to the dramatic increase in recallof 11.5%, 11.2%, 7.5% and 7.2%.PerformanceSystem/HumanTriggerIdentificationTrigger TypeDeterminationArgumentIdentificationArgument RoleDeterminationP(%) R(%) F P(%) R(%) F P(%) R(%) F P(%) R(%) FOur Baseline 75.2 52.0 61.5 70.3 49.0 57.8 58.4 42.7 49.3 55.2 38.6 45.4+Compositional semantics 73.5 62.1 67.4 70.2 59.1 64.2 58.0 48.9 53.0 54.7 44.5 49.1+Discourse consistency 79.3 63.5 70.5 75.2 60.2 66.9 61.6 50.2 55.3 56.9 45.8 50.8Human annotator1(blind) 63.3 62.9 63.1 61.7 59.5 60.6 64.6 54.1 58.9 60.9 48.2 53.8Human annotator2(familiar) 72.6 74.3 73.4 69.1 70.2 69.6 71.5 65.9 68.6 66.4 54.6 59.9Inter-Annotator Agreement 45.8 42.9 44.3 45.3 42.5 43.8 60.4 49.7 54.5 55.1 45.9 50.1Table 9: Overall contribution to Chinese event extractionIn addition, the results of two annotators showthat Chinese event extraction is really challengingeven for a well-educated human being.
As shownin Table 9, the inter-annotator agreement on triggeridentification and trigger type determination iseven less than 45%.
Although this figure is verylow, it is not surprising: the results on the EnglishACE 2005 corpus show that the inter-annotatoragreement on trigger identification is only about40% (Ji and Grishman, 2008).
Detailed analysisshows that a human annotator tends to make moremistakes in trigger identification for two reasons.The first reason is that a human annotator alwaysmisses some event mentions when a sentencecontains more than one event mention.
The secondreason is that it is hard to identify an event mentiondue to the failure of following specified annotationguidelines, as mentioned in Ji and Grishman(2008).
Table 9 also shows the performance gapsof human annotators between trigger identificationand trigger type determination is very small (2.5%and 3.8% in F1-measure).
It ensures that triggeridentification is the most important step in Chineseevent extraction for a human being.
For humanannotators, it?s much easier to determine the eventtype of a trigger, identify its arguments anddetermine the role of each argument, all with morethan 90% in accuracy, once a trigger is identifiedcorrectly.6.3 DiscussionCompared with English, the word structures inChinese are much more complex and diverse,causing a lot of troubles in Chinese languageprocessing.
We ensure that compositionalsemantics in Chinese words is very useful formany Chinese language processing applications,such as machine translation, semantic parser, etc.For example, many actions (e.g.
???
(hack), ???
(bite), ???
(kick), etc) can combine with ???
(injure) to form words and most of those wordshave similar semantics.
The results in table 8 showits contribution in Chinese event extraction.Although our approach is simple, the result is1014promising enough for further efforts in thisdirection.This paper shows that the compositionalsemantics in the verb structure provides an idealway to expand the coverage of triggers.
As adiscourse-driven language, ellipsis is very commonin Chinese, causing inference from the discourse-level information is a fundamental requirement tounderstand the meaning of a clause, sentence ordiscourse.7 ConclusionIn this paper we propose two novel inferencemechanisms to Chinese trigger identification.
Inparticular, compositional semantics inside Chinesetriggers and discourse consistency betweenChinese trigger mentions are used to resolve twocritical issues in Chinese trigger identification:unknown triggers and word segmentation errors toknown triggers.
We give good reasons why thisshould be done, and present effective methods howthis could be done.
It shows that such novelinference mechanisms for Chinese event extractionare linguistically justified and pragmaticallybeneficial to real world applications.In future work, we will focus on how tointroduce the discourse information into theindividual classifiers to capture those long-distancefeatures and joint learning of subtasks in Chineseevent extraction.AcknowledgmentsThe authors would like to thank three anonymousreviewers for their comments on this paper.
Thisresearch was supported by the National NaturalScience Foundation of China under Grant No.61070123 and No.
90920004, the National 863Project of China under Grant No.
2012AA011102.ReferencesDavid Ahn.
2006.
The Stages of Event Extraction.
InProc.
COLING/ACL 2006 Workshop on Annotatingand Reasoning about Time and Events.
Pages 1-8,Sydney, Australia.Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, andChristopher Manning.
2009.
DiscriminativeReordering with Chinese Grammatical RelationsFeatures.
In Proc.
Third Workshop on Syntax andStructure in Statistical Translation, pages 51-59.Zheng Chen and Heng Ji.
2009a.
Can One LanguageBootstrap the Other: A Case Study on EventExtraction.
In Proc.
NAACL HLT Workshop onSemi-supervised Learning for Natural LanguageProcessing, pages 66-74, Boulder, Colorado.Zheng Chen and Heng Ji.
2009b.
Language SpecificIssue and Feature Exploration in Chinese EventExtraction.
In Proc.
NAACL HLT 2009, pages 209-212, Boulder, CO.Jenny Rose Finkel, Trond Grenager and ChristopherManning.
2005.
Incorporating Non-localInformation into Information Extraction Systems byGibbs Sampling.
In Proc.
ACL 2005, pages 363-370,Ann Arbor, MI.Prashant Gupta and Heng Ji.
2009.
Predicting UnknownTime Arguments based on Cross-Event Propagation.In Proc.
ACL-IJCNLP 2009, pages 369-272, Suntec,Singapore.Ralph Grishman, David Westbrook and Adam Meyers.2005.
NYU?s English ACE 2005 SystemDescription.
In Proc.
ACE 2005 EvaluationWorkshop, Gaithersburg, MD.Hilda Hardy, Vika Kanchakouskaya and TomekStrzalkowski.
2006.
Automatic Event ClassificationUsing Surface Text Features.
In Proc.
AAAI 2006Workshop on Event Extraction and Synthesis, pages36-41, Boston, MA.Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,Guodong Zhou and Qiaoming Zhu.
2011.
UsingCross-Entity Inference to Improve Event Extraction.In Proc.
ACL 2011, pages 1127-1136, Portland, OR.Heng Ji.
2009.
Cross-lingual Predicate ClusterAcquisition to Improve Bilingual Event Extractionby Inductive Learning.
In Proc.
NAACL HLTWorkshop on Unsupervised and MinimallySupervised Learning of Lexical Semantics, pages27-35, Boulder, CO.Heng Ji and Ralph Grishman.
2008.
Refining EventExtraction through Cross-Document Inference.
InProc.
ACL-08: HLT, pages 254-262, Columbus, OH.Young-Joo Kim.
2000.
Subject/object drop in theacquisition of Korean: A Cross-linguisticComparison.
Journal of East Asian Linguistics, 9(4):325-351.Roger Levy and Christopher D. Manning.
2003.
Is itharder to parse Chinese, or the Chinese Treebank?
InProc.
ACL 2003, pages 439-446, Sapporo, Japan.Shasha Liao and Ralph Grishman.
2010.
UsingDocument Level Cross-Event Inference to ImproveEvent Extraction.
In Proc.
ACL 2010, pages 789-797, Uppsala, Sweden.Zhongguo Li.
2011.
Parsing the Internal Structure ofWords: A New Paradigm for Chinese WordSegmentation.
In Proc.
ACL 2011, pages 1405-1414,Portland, OR.Percy Liang, Michael I. Joedan and Dan Klein.
2011.Learning Dependency-Based Compositional1015Semantics.
In Proc.
ACL 2011, pages 590-599,Portland, OR.Gideon Mann.
2007.
Multi-document RelationshipFusion via Constraints on Probabilistic Databases.
InProc.
HLT/NAACL 2007, pages 332-229, Rochester,NY.Mstislav Maslennikov and Tat-Seng Chua.
2007.
AMulti Resolution Framework for InformationExtraction from Free Text.
In Proc.
ACL 2007,pages 592-599, Prague, Czech Republic.Siddharth Patwardhan and Ellen Riloff.
2007.
EffectiveInformation Extraction with Semantic AffinityPatterns and Relevant Regions.
In Proc.EMNLP/CoNLL 2007, pages 717-727, Prague,Czech Republic.Siddharth Patwardhan and Ellen Riloff.
2009.
A UnifiedModel of Phrasal and Sentential Evidence forInformation Extraction.
In Proc.
EMNLP 2009,pages 151-160, Singapore.Hongye Tan, Tiejun Zhao, Jiaheng Zheng.
2008.Identification of Chinese Event and Their ArgumentRoles.
Proc.
of the 2008 IEEE 8th InternationalConference on Computer and InformationTechnology Workshops, pages 14-19, Sydney,Australia.Yuk Wah Wong and Raymond J. Mooney.
2007.Learning Synchronous Grammars for SemanticParsing with Lambda Calculus.
In Proc.
ACL 2007,pages 960-967, Prague, Czech Republic.Roman Yangarber, Clive Best, Peter von Etter, FlavioFuart, David Horby and Ralf Steinberger.
2007.Combining Information about Epidemic Threatsfrom Multiple Sources.
In Proc.
RANLP 2007workshop on Multi-source, Multilingual InformationExtraction and Summarization.
Borovets, pages 41-48, Borovets, Bulgaria.Roman Yangarber and Lauri Jokipii.
2005.Redundancy-based Correction of AutomaticallyExtracted Facts.
In Proc.
EMNLP 2005, pages 57-64,Vancouver, Canada.David Yarowsky.
1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.
InProc.
ACL 1995, pages 189-196, Cambridge, MA.Minglin Yuan.
1998.
Studies on Valency in ModernChinese.
Chinese Commerce and Trade Press,Beijing, China.Luke S. Zettlemoyer and Michael Collins.
2007.
OnlineLearning of Relaxed CCG Grammars for Parsing toLogical Form.
In EMNLP/CoNLL 2007, pages 678-687, Prague, Czech Republic.Dexi Zhu.
1980.
Research on Chinese ModernGrammars.
Chinese Commerce and Trade Press,Beijing, China.1016
