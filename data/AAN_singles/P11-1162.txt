Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1616?1625,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsInsights from Network Structure for Text MiningZornitsa Kozareva and Eduard HovyUSC Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292-6695{kozareva,hovy}@isi.eduAbstractText mining and data harvesting algorithmshave become popular in the computational lin-guistics community.
They employ patternsthat specify the kind of information to be har-vested, and usually bootstrap either the pat-tern learning or the term harvesting process (orboth) in a recursive cycle, using data learnedin one step to generate more seeds for the next.They therefore treat the source text corpus asa network, in which words are the nodes andrelations linking them are the edges.
The re-sults of computational network analysis, espe-cially from the world wide web, are thus ap-plicable.
Surprisingly, these results have notyet been broadly introduced into the computa-tional linguistics community.
In this paper weshow how various results apply to text mining,how they explain some previously observedphenomena, and how they can be helpful forcomputational linguistics applications.1 IntroductionText mining / harvesting algorithms have been ap-plied in recent years for various uses, includinglearning of semantic constraints for verb participants(Lin and Pantel, 2002) related pairs in various rela-tions, such as part-whole (Girju et al, 2003), cause(Pantel and Pennacchiotti, 2006), and other typicalinformation extraction relations, large collectionsof entities (Soderland et al, 1999; Etzioni et al,2005), features of objects (Pasca, 2004) and ontolo-gies (Carlson et al, 2010).
They generally start withone or more seed terms and employ patterns thatspecify the desired information as it relates to theseed(s).
Several approaches have been developedspecifically for learning patterns, including guidedpattern collection with manual filtering (Riloff andShepherd, 1997) automated surface-level pattern in-duction (Agichtein and Gravano, 2000; Ravichan-dran and Hovy, 2002) probabilistic methods for tax-onomy relation learning (Snow et al, 2005) and ker-nel methods for relation learning (Zelenko et al,2003).
Generally, the harvesting procedure is recur-sive, in which data (terms or patterns) gathered inone step of a cycle are used as seeds in the followingstep, to gather more terms or patterns.This method treats the source text as a graph ornetwork, consisting of terms (words) as nodes andinter-term relations as edges.
Each relation type in-duces a different network1.
Text mining is a processof network traversal, and faces the standard prob-lems of handling cycles, ranking search alternatives,estimating yield maxima, etc.The computational properties of large networksand large network traversal have been studied inten-sively (Sabidussi, 1966; Freeman, 1979; Watts andStrogatz, 1998) and especially, over the past years,in the context of the world wide web (Page et al,1999; Broder et al, 2000; Kleinberg and Lawrence,2001; Li et al, 2005; Clauset et al, 2009).
Surpris-ingly, except in (Talukdar and Pereira, 2010), thiswork has not yet been related to text mining researchin the computational linguistics community.The work is, however, relevant in at least twoways.
It sometimes explains why text mining algo-1These networks are generally far larger and more denselyinterconnected than the world wide web?s network of pages andhyperlinks.1616rithms have the limitations and thresholds that areempirically found (or suspected), and it may suggestways to improve text mining algorithms for someapplications.In Section 2, we review some related work.
InSection 3 we describe the general harvesting proce-dure, and follow with an examination of the variousstatistical properties of implicit semantic networksin Section 4, using our implemented harvester toprovide illustrative statistics.
In Section 5 we dis-cuss implications for computational linguistics re-search.2 Related WorkThe Natural Language Processing knowledge har-vesting community has developed a good under-standing of how to harvests various kinds of se-mantic information and use this information to im-prove the performance of tasks such as informationextraction (Riloff, 1993), textual entailment (Zan-zotto et al, 2006), question answering (Katz etal., 2003), and ontology creation (Suchanek et al,2007), among others.
Researchers have focusedon the automated extraction of semantic lexicons(Hearst, 1992; Riloff and Shepherd, 1997; Girju etal., 2003; Pasca, 2004; Etzioni et al, 2005; Kozarevaet al, 2008).
While clustering approaches tend toextract general facts, pattern based approaches haveshown to produce more constrained but accurate listsof semantic terms.
To extract this information, (Linand Pantel, 2002) showed the effect of using differ-ent sizes and genres of corpora such as news andWeb documents.
The latter has been shown to pro-vide broader and more complete information.Researchers outside computational linguisticshave studied complex networks such as the WorldWide Web, the Social Web, the network of scien-tific papers, among others.
They have investigatedthe properties of these text-based networks with theobjective of understanding their structure and ap-plying this knowledge to determine node impor-tance/centrality, connectivity, growth and decay ofinterest, etc.
In particular, the ability to analyze net-works, identify influential nodes, and discover hid-den structures has led to important scientific andtechnological breakthroughs such as the discoveryof communities of like-minded individuals (New-man and Girvan, 2004), the identification of influ-ential people (Kempe et al, 2003), the ranking ofscientists by their citation indexes (Radicchi et al,2009), and the discovery of important scientific pa-pers (Walker et al, 2006; Chen et al, 2007; Sayyadiand Getoor, 2009).
Broder et al (2000) demon-strated that the Web link structure has a ?bow-tie?shape, while (2001) classified Web pages into au-thorities (pages with relevant information) and hubs(pages with useful references).
These findings re-sulted in the development of the PageRank (Page etal., 1999) algorithm which analyzes the structure ofthe hyperlinks of Web documents to find pages withauthoritative information.
PageRank has revolution-ized the whole Internet search society.However, no-one has studied the properties of thetext-based semantic networks induced by semanticrelations between terms with the objective of un-derstanding their structure and applying this knowl-edge to improve concept discovery.
Most relevantto this theme is the work of Steyvers and Tenen-baum (Steyvers and Tenenbaum, 2004), who stud-ied three manually built lexical networks (associa-tion norms, WordNet, and Roget?s Thesaurus (Ro-get, 1911)) and proposed a model of the growth ofthe semantic structure over time.
These networks arelimited to the semantic relations among nouns.In this paper we take a step further to explore thestatistical properties of semantic networks relatingproper names, nouns, verbs, and adjectives.
Under-standing the semantics of nouns, verbs, and adjec-tives has been of great interest to linguists and cog-nitive scientists such as (Gentner, 1981; Levin andSomers, 1993; Gasser and Smith, 1998).
We imple-ment a general harvesting procedure and show its re-sults for these word types.
A fundamental differencewith the work of (Steyvers and Tenenbaum, 2004)is that we study very large semantic networks built?naturally?
by (millions of) users rather than ?artifi-cially?
by a small set of experts.
The large networkscapture the semantic intuitions and knowledge of thecollective mass.
It is conceivable that an analysisof this knowledge can begin to form the basis of alarge-scale theory of semantic meaning and its inter-connections, support observation of the process oflexical development and usage in humans, and evensuggest explanations of how knowledge is organizedin our brains, especially when performed for differ-1617ent languages on the WWW.3 Inducing Semantic Networks in the WebText mining algorithms such as those mentionedabove raise certain questions, such as: Why are someseed terms more powerful (provide a greater yield)than others?, How can one find high-yield terms?,How many steps does one need, typically, to learnall terms for a given relation?, Can one estimate thetotal eventual yield of a given relation?, and so on.On the face of it, one would need to know the struc-ture of the network a priori to be able to provide an-swers.
But research has shown that some surpris-ing regularities hold.
For example, in the text min-ing community, (Kozareva and Hovy, 2010b) haveshown that one can obtain a quite accurate estimateof the eventual yield of a pattern and seed after onlyfive steps of harvesting.
Why is this?
They do notprovide an answer, but research from the networkcommunity does.To illustrate the properties of networks of the kindinduced by semantic relations, and to show the ap-plicability of network research to text harvesting, weimplemented a harvesting algorithm and applied itto a representative set of relations and seeds in twolanguages.Since the goal of this paper is not the developmentof a new text harvesting algorithm, we implementeda version of an existing one: the so-called DAP(doubly-anchored pattern) algorithm (Kozareva etal., 2008), because it (1) is easy to implement, (2)requires minimum input (one pattern and one seedexample), (3) achieves very high precision com-pared to existing methods (Pasca, 2004; Etzioni etal., 2005; Pasca, 2007), (4) enriches existing se-mantic lexical repositories such as WordNet andYago (Suchanek et al, 2007), (5) can be formulatedto learn semantic lexicons and relations for noun,verb and verb+preposition syntactic constructions;(6) functions equally well in different languages.Next we describe the knowledge harvesting proce-dure and the construction of the text-mined semanticnetworks.3.1 Harvesting to Induce Semantic NetworksFor a given semantic class of interest say singers, thealgorithm starts with a seed example of the class, sayMadonna.
The seed term is inserted in the lexico-syntactic pattern ?class such as seed and *?, whichlearns on the position of the ?
new terms of typeclass.
The newly learned terms are then individuallyplaced into the position of the seed in the pattern,and the bootstrapping process is repeated until nonew terms are found.
The output of the algorithmis a set of terms for the semantic class.
The algo-rithm is implemented as a breadth-first search andits mechanism is described as follows:1.
Given:a language L={English, Spanish}a pattern Pi={such as, including, verb prep,noun}a seed term seed for Pi2.
Build a query for Pi using template Ti ?class suchas seed and *?, ?class including seed and *?, ?
*and seed verb prep?, ?
* and seed noun?, ?seedand * noun?3.
Submit Ti to Yahoo!
or other search engine4.
Extract terms occupying the * position5.
Feed terms from 4. into 2.6.
Repeat steps 2?5.
until no new terms are foundThe output of the knowledge harvesting algorithmis a network of semantic terms interconnected bythe semantic relation captured in the pattern.
Wecan represent the traversed (implicit) network as adirected graph G(V,E) with nodes V (|V | = n)and edges E(|E| = m).
A node u in the net-work corresponds to a term discovered during boot-strapping.
An edge (u, v) ?
E represents an ex-isting link between two terms.
The direction of theedge indicates that the term v was generated by theterm u.
For example, given the sentence (wherethe pattern is in italics and the extracted term is un-derlined) ?He loves singers such as Madonna andMichael Jackson?, two nodes Madonna and MichaelJackson with an edge e=(Madonna, Michael Jack-son) would be created in the graph G. Figure 1shows a small example of the singer network.
Thestarting seed term Madonna is shown in red colorand the harvested terms are in blue.3.2 DataWe harvested data from the Web for a representa-tive selection of semantic classes and relations, of1618!"#$%%"&'()$%&*$+%&!,-+".(&*"-/0$%&1.
(,%.&2,$%&'33"& 45,%-.& 6.7$%-.& 8"57&9,+"%%"&:5.##,.&!.5-;57&<(,-,"&8.70&=+"/,5"&2>>& 9,-/.7&!"5?%&=).
@,.&A$%#.5&B,%"&B;5%.5&2$((7&4")$%&Figure 1: Harvesting Procedure.the type used in (Etzioni et al, 2005; Pasca, 2007;Kozareva and Hovy, 2010a):?
semantic classes that can be learned using dif-ferent seeds (e.g., ?singers such as Madonnaand *?
and ?singers such as Placido Domingoand *?);?
semantic classes that are expressed through dif-ferent lexico-syntactic patterns (e.g., ?weaponssuch as bombs and *?
and ?weapons includingbombs and *?);?
verbs and adjectives characterizing the seman-tic class (e.g., ?expensive and * car?, ?dogsrun and *?);?
semantic relations with more complex lexico-syntactic structure (e.g., ?
* and Easyjet fly to?,?
* and Sam live in?);?
semantic classes that are obtained in differ-ent languages, such as English and Spanish(e.g., ?singers such as Madonna and *?
and?cantantes como Madonna y *?
);While most of these variations have been exploredin individual papers, we have found no paper thatcovers them all, and none whatsoever that uses verbsand adjectives as seeds.Using the above procedure to generate the data,each pattern was submitted as a query to Ya-hoo!Boss.
For each query the top 1000 text snippetswere retrieved.
The algorithm ran until exhaustion.In total, we collected 10GB of data which was part-of-speech tagged with Treetagger (Schmid, 1994)and used for the semantic term extraction.
Table 1summarizes the number of nodes and edges learnedfor each semantic network using pattern Pi and theinitial seed shown in italics.Lexico-Syntactic Pattern Nodes EdgesP1=?singers such as Madonna and *?
1115 1942P2=?singers such as Placido Domingo and *?
815 1114P3=?emotions including anger and *?
113 250P4=?emotions such as anger and *?
748 2547P5=?diseases such as malaria and *?
3168 6752P6=?drugs such as ibuprofen and *?
2513 9428P7=?expensive and * cars?
4734 22089P8=?
* and tasty fruits?
1980 7874P9=?whales swim and *?
869 2163P10=?dogs chase and *?
4252 20212P11=?Britney Spears dances and *?
354 540P12=?John reads and *?
3894 18545P13=?
* and Easyjet fly to?
3290 6480P14=?
* and Charlie work for?
2125 3494P15=?
* and Sam live in?
6745 24348P16=?cantantes como Madonna y *?
240 318P17=?gente como Jorge y *?
572 701Table 1: Size of the Semantic Networks.4 Statistical Properties of Text-MinedSemantic NetworksIn this section we apply a range of relevant mea-sures from the network analysis community to thenetworks described above.4.1 CentralityThe first statistical property we explore is centrality.It measures the degree to which the network struc-ture determines the importance of a node in the net-work (Sabidussi, 1966; Freeman, 1979).We explore the effect of two centrality measures:indegree and outdegree.
The indegree of a nodeu denoted as indegree(u)=?
(v, u) considers thesum of all incoming edges to u and captures the abil-ity of a semantic term to be discovered by other se-mantic terms.
The outdegree of a node u denotedas outdegree(u)=?
(u, v) considers the number ofoutgoing edges of the node u and measures the abil-ity of a semantic term to discover new terms.
In-tuitively, the more central the node u is, the moreconfident we are that it is a correct term.Since harvesting algorithms are notorious for ex-tracting erroneous information, we use the two cen-trality measures to rerank the harvested elements.Table 2 shows the accuracy2 of the singer seman-tic terms at different ranks using the in and outdegree measures.
Consistently, outdegree outper-forms indegree and reaches higher accuracy.
This2Accuracy is calculated as the number of correct terms atrank R divided by the total number of terms at rank R.1619shows that for the text-mined semantic networks, theability of a term to discover new terms is more im-portant than the ability to be discovered.
@rank in-degree out-degree10 .92 1.025 .91 1.050 .90 .9775 .90 .96100 .89 .96150 .88 .95Table 2: Accuracy of the Singer Terms.This poses the question ?What are the terms withhigh and low outdegree??.
Table 3 shows the topand bottom 10 terms of the semantic class.Semantic Class top 10 outDegree bottom 10 outDegreeSingers Frank Sinatra Alanis MorisetteElla Fitzgerald Christine AguleraBillie Holiday Buffy Sainte-MarieBritney Spears Cece WinansAretha Franklin Wolfman JackMichael Jackson Billie CelebrationCeline Dion Alejandro SanzBeyonce France GallBessie Smith PeterJoni Mitchell SarahTable 3: Singer Term Ranking with Centrality Measures.The nodes with high outdegree correspond to fa-mous or contemporary singers.
The lower-rankednodes are mostly spelling errors such as AlanisMorisette and Christine Agulera, less known singerssuch as Buffy Sainte-Marie and Cece Winans, non-American singers such as Alejandro Sanz andFrance Gall, extractions due to part-of-speech tag-ging errors such as Billie Celebration, and generalterms such as Peter and Sarah.
Potentially, know-ing which terms have a high outdegree allows one torerank candidate seeds for more effective harvesting.4.2 Power-law Degree DistributionWe next study the degree distributions of the net-works.
Similarly to the Web (Broder et al, 2000)and social networks like Orkut and Flickr, the text-mined semantic networks also exhibit a power-lawdistribution.
This means that while a few terms havea significantly high degree, the majority of the se-mantic terms have small degree.
Figure 2 shows theindegree and outdegree distributions for differentsemantic classes, lexico-syntactic patterns, and lan-guages (English and Spanish).
For each semanticnetwork, we plot the best-fitting power-law function(Clauset et al, 2009) which fits well all degree dis-tributions.
Table 4 shows the power-law exponentvalues for all text-mined semantic networks.Patt.
?in ?out Patt.
?in ?outP1 2.37 1.27 P10 1.65 1.12P2 2.25 1.21 P11 2.42 1.41P3 2.20 1.76 P12 1.60 1.13P4 2.28 1.18 P13 2.26 1.20P5 2.49 1.18 P14 2.43 1.25P6 2.42 1.30 P15 2.51 1.43P7 1.95 1.20 P16 2.74 1.31P8 1.94 1.07 P17 2.90 1.20P9 1.96 1.30Table 4: Power-Law Exponents of Semantic Networks.It is interesting to note that the indegree power-law exponents for all semantic networks fall withinthe same range (?in ?
2.4), and similarly for theoutdegree exponents (?out ?
1.3).
However, thevalues of the indegree and outdegree exponentsdiffer from each other.
This observation is consistentwith Web degree distributions (Broder et al, 2000).The difference in the distributions can be explainedby the link asymmetry of semantic terms: A discov-ering B does not necessarily mean that B will dis-cover A.
In the text-mined semantic networks, thisasymmetry is caused by patterns of language use,such as the fact that people use first adjectives of thesize and then of the color (e.g., big red car), or preferto place male before female proper names.
Harvest-ing patterns should take into account this tendency.4.3 SparsityAnother relevant property of the semantic networksconcerns sparsity.
Following Preiss (Preiss, 1999), agraph is sparse if |E| = O(|V |k) and 1 < k < 2,where |E| is the number of edges and |V | is the num-ber of nodes, otherwise the graph is dense.
For thestudied text-semantic networks, k is ?
1.08.
Spar-sity can be also captured through the density of thesemantic network which is computed as |E|V (V?1) .
Allnetworks have low density which suggests that thenetworks exhibit a sparse connectivity pattern.
Onaverage a node (semantic term) is connected to avery small percentage of other nodes.
Similar be-havior was reported for the WordNet and Roget?s se-mantic networks (Steyvers and Tenenbaum, 2004).16200 50 100 150 200 250 300 350400 450 5000  10  20  30  40  50  60  70  80  90Number of Nodes Indegree 'emotions'power-law exponent=2.28  0 20 40 60 80 100 120  0  20  40  60  80  100  120Number of Nodes Outdegree 'emotions'power-law exponent=1.180 500 1000 1500 200025000  10  20  30  40  50  60Number of Nodes Indegree 'travel_to'power-law exponent=2.26  0 100 200 300 400 500 600 700  0  5  10  15  20  25  30  35Number of Nodes Outdegree 'fly_to'power-law exponent=1.200 50 100 150 200 250 300 350 400450 5001  2  3  4  5  6  7  8Number of Nodes Indegree 'gente'power-law exponent=2.90  0 20 40 60 80 100 120  0  2  4  6  8  10  12  14Number of Nodes Outdegree 'gente'power-law exponent=1.20Figure 2: Degree Distributions of Semantic Networks.4.4 ConnectednessFor every network, we computed the strongly con-nected component (SCC) such that for all nodes (se-mantic terms) in the SCC, there is a path from anynode to another node in the SCC considering the di-rection of the edges between the nodes.
For eachnetwork, we found that there is only one SCC.
Thesize of the component is shown in Table 5.
Un-like WordNet and Roget?s semantic networks wherethe SCC consists 96% of all semantic terms, in thetext-mined semantic networks only 12 to 55% of theterms are in the SCC.
This shows that not all nodescan reach (discover) every other node in the net-work.
This also explains the findings of (Kozarevaet al, 2008; Vyas et al, 2009) why starting with agood seed is important.4.5 Path Lengths and DiameterNext, we describe the properties of the shortest pathsbetween the semantic terms in the SCC.
The dis-tance between two nodes in the SCC is measured asthe length of the shortest path connecting the terms.The direction of the edges between the terms is takeninto consideration.
The average distance is the aver-age value of the shortest path lengths over all pairsof nodes in the SCC.
The diameter of the SCC iscalculated as the maximum distance over all pairs ofnodes (u, v), such that a node v is reachable fromnode u.
Table 5 shows the average distance and thediameter of the semantic networks.Patt.
#nodes in SCC SCC Average Distance SCC DiameterP1 364 (.33) 5.27 16P2 285 (.35) 4.65 13P3 48 (.43) 2.85 6P4 274 (.37) 2.94 7P5 1249 (.38) 5.99 17P6 1471 (.29) 4.82 15P7 2255 (.46 ) 3.51 11P8 1012 (.50) 3.87 11P9 289 (.33) 4.93 13P10 2342 (.55) 4.50 12P11 87 (.24) 5.00 11P12 1967 (.51) 3.20 13P13 1249 (.38) 4.75 13P14 608 (.29) 7.07 23P15 1752 (.26) 5.32 15P16 56 (.23) 4.79 12P17 69 (.12 ) 5.01 13Table 5: SCC, SCC Average Distance and SCC Diameterof the Semantic Networks.The diameter shows the maximum number ofsteps necessary to reach from any node to any other,while the average distance shows the number ofsteps necessary on average.
Overall, all networkshave very short average path lengths and small di-ameters that are consistent with Watt?s finding forsmall-world networks.
Therefore, the yield of har-vesting seeds can be predicted within five steps ex-plaining (Kozareva and Hovy, 2010b; Vyas et al,2009).We also compute for any randomly selected nodein the semantic network on average how many hops(steps) are necessary to reach from one node to an-other.
Figure 3 shows the obtained results for someof the studied semantic networks.4.6 ClusteringThe clustering coefficient (C) is another measureto study the connectivity structure of the networks(Watts and Strogatz, 1998).
This measure capturesthe probability that the two neighbors of a randomlyselected node will be neighbors.
The clustering co-efficient of a node u is calculated as Cu=|eij |ku(ku?1)16210 10 20 30 40 5060 701  2  3  4  5  6  7  8  9  10  11  12  13  14  15Number of Nodes Distance (Hops)Britney Spears (verb harvesting)  0 50 100 150 200 250 300 350 400  1  2  3  4  5  6  7  8  9  10  11Number of Nodes Distance (Hops)fruits (adjective harvesting)0 50 100 150 2002502  4  6  8  10  12  14  16  18  20  22  24Number of Nodes Distance (Hops)work for  0 5 10 15 20 25 30  2  4  6  8  10  12  14  16  18  20Number of Nodes Distance (Hops) genteFigure 3: Hop Plot of the Semantic Networks.
: vi, vj ?
Nu, eij ?
E, where ku is the total degreeof the node u and Nu is the neighborhood of u. Theclustering coefficient C for the whole semantic net-work is the average clustering coefficient of all itsnodes, C= 1n?Ci.
The value of the clustering coef-ficient ranges between [0, 1], where 0 indicates thatthe nodes do not have neighbors which are them-selves connected, while 1 indicates that all nodes areconnected.
Table 6 shows the clustering coefficientfor all text-mined semantic networks together withthe number of closed and open triads3.
The analysissuggests the presence of a strong local cluster, how-ever there are few possibilities to form overlappingneighborhoods of nodes.
The clustering coefficientof WordNet (Steyvers and Tenenbaum, 2004) is sim-ilar to those of the text-mined networks.4.7 Joint Degree DistributionIn social networks, understanding the preferential at-tachment of nodes is important to identify the speedwith which epidemics or gossips spread.
Similarly,we are interested in understanding how the nodes ofthe semantic networks connect to each other.
Forthis purpose, we examine the Joint Degree Distribu-tion (JDD) (Li et al, 2005; Newman, 2003).
JDDis approximated by the degree correlation functionknn which maps the outdegree and the average3A triad is three nodes that are connected by either two (opentriad) or three (closed triad) directed ties.Patt.
C ClosedTriads OpenTriadsP1 .01 14096 (.97) 388 (.03)P2 .01 6487 (.97) 213 (.03)P3 .30 1898 (.94) 129 (.06)P4 .33 60734 (.94) 3944 (.06)P5 .10 79986 (.97) 2321 (.03)P6 .11 78716 (.97) 2336 (.03)P7 .17 910568 (.95) 43412 (.05)P8 .19 21138 (.95) 10728 (.05)P9 .20 27830 (.95) 1354 (.05)P10 .15 712227 (.96) 62101(.04)P11 .09 3407 (.98) 63 (.02)P12 .15 734724 (.96) 32517 (.04)P13 .06 66162 (.99) 858 (.01)P14 .05 28216 (.99) 408 (.01)P15 .09 1336679 (.97) 47110 (.03)P16 .09 1525 (.98) 37 ( .02)P17 .05 2222 (.99) 21 (.01)Table 6: Clustering Coefficient of the Semantic Networks.indegree of all nodes connected to a node withthat outdegree.
High values of knn indicate thathigh-degree nodes tend to connect to other high-degree nodes (forming a ?core?
in the network),while lower values of knn suggest that the high-degree nodes tend to connect to low-degree ones.Figure 4 shows the knn for the singer, whale, livein, cars, cantantes, and gente networks.
The figureplots the outdegree and the average indegree of thesemantic terms in the networks on a log-log scale.We can see that for all networks the high-degreenodes tend to connect to other high-degree ones.This explains why text mining algorithms should fo-cus their effort on high-degree nodes.4.8 AssortivityThe property of the nodes to connect to other nodeswith similar degrees can be captured through the as-sortivity coefficient r (Newman, 2003).
The range ofr is [?1, 1].
A positive assortivity coefficient meansthat the nodes tend to connect to nodes of similardegree, while negative coefficient means that nodesare likely to connect to nodes with degree very dif-ferent from their own.
We find that the assortivi-tiy coefficient of our semantic networks is positive,ranging from 0.07 to 0.20.
In this respect, the se-mantic networks differ from the Web, which has anegative assortivity (Newman, 2003).
This impliesa difference in text mining and web search traver-sal strategies: since starting from a highly-connectedseed term will tend to lead to other highly-connectedterms, text mining algorithms should prefer depth-first traversal, while web search algorithms starting16221 101001  10  100knn Outdegreesinger (seed is Madonna)  1 10 100  1  10  100knn Outdegreewhale (verb harvesting)1 101001  10  100knn Outdegree live in  1 10 100  1  10  100knn Outdegreecars (adjective harvesting)1101  10knn Outdegreecantantes  1 10  1  10knn Outdegree genteFigure 4: Joint Degree Distribution of the Semantic Net-works.from a highly-connected seed page should prefer abreadth-first strategy.5 DiscussionThe above studies show that many of the proper-ties discovered of the network formed by the webhold also for the networks induced by semantic rela-tions in text mining applications, for various seman-tic classes, semantic relations, and languages.
Wecan therefore apply some of the research from net-work analysis to text mining.The small-world phenomenon, for example, holdsthat any node is connected to any other node in atmost six steps.
Since as shown in Section 4.5 the se-mantic networks also exhibit this phenomenon, wecan explain the observation of (Kozareva and Hovy,2010b) that one can quite accurately predict the rel-ative ?goodness?
of a seed term (its eventual totalyield and the number of steps required to obtain that)within five harvesting steps.
We have shown that dueto the strongly connected components in text min-ing networks, not all elements within the harvestedgraph can discover each other.
This implies that har-vesting algorithms have to be started with severalseeds to obtain adequate Recall (Vyas et al, 2009).We have shown that centrality measures can be usedsuccessfully to rank harvested terms to guide the net-work traversal, and to validate the correctness of theharvested terms.In the future, the knowledge and observationsmade in this study can be used to model the lexi-cal usage of people over time and to develop newsemantic search technology.6 ConclusionIn this paper we describe the implicit ?hidden?
se-mantic network graph structure induced over the textof the web and other sources by the semantic rela-tions people use in sentences.
We describe how termharvesting patterns whose seed terms are harvestedand then applied recursively can be used to discoverthese semantic term networks.
Although these net-works differ considerably from the web in relationdensity, type, and network size, we show, some-what surprisingly, that the same power-law, small-world effect, transitivity, and most other character-istics that apply to the web?s hyperlinked networkstructure hold also for the implicit semantic termgraphs?certainly for the semantic relations and lan-guages we have studied, and most probably for al-most all semantic relations and human languages.This rather interesting observation leads us to sur-mise that the hyperlinks people create in the web areof essentially the same type as the semantic relationspeople use in normal sentences, and that they forman extension of normal language that was not neededbefore because people did not have the ability withinthe span of a single sentence to ?embed?
structureslarger than a clause?certainly not a whole otherpage?s worth of information.
The principal excep-tion is the academic citation reference (lexicalizedas ?see?
), which is not used in modern webpages.Rather, the ?lexicalization?
now used is a formattingconvention: the hyperlink is colored and often un-derlined, facilities offered by computer screens butnot available to speech or easy in traditional typeset-ting.1623AcknowledgmentsWe acknowledge the support of DARPA contractnumber FA8750-09-C-3705 and NSF grant IIS-0429360.
We would like to thank Sujith Ravi forhis useful comments and suggestions.ReferencesEugene Agichtein and Luis Gravano.
2000.
Snowball:Extracting relations from large plain-text collections.pages 85?94.Andrei Broder, Ravi Kumar, Farzin Maghoul, PrabhakarRaghavan, Sridhar Rajagopalan, Raymie Stata, An-drew Tomkins, and Janet Wiener.
2000.
Graph struc-ture in the web.
Comput.
Netw., 33(1-6):309?320.Andrew Carlson, Justin Betteridge, Richard C. Wang, Es-tevam R. Hruschka Jr., and Tom M. Mitchell.
2010.Coupled semi-supervised learning for information ex-traction.
pages 101?110.Peng Chen, Huafeng Xie, Sergei Maslov, and Sid Redner.2007.
Finding scientific gems with google?s pagerankalgorithm.
Journal of Informetrics, 1(1):8?15, Jan-uary.Aaron Clauset, Cosma Rohilla Shalizi, and M. E. J. New-man.
2009.
Power-law distributions in empirical data.SIAM Rev., 51(4):661?703.Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland,Daniel S. Weld, and Alexander Yates.
2005.
Unsuper-vised named-entity extraction from the web: an exper-imental study.
Artificial Intelligence, 165(1):91?134,June.Linton Freeman.
1979.
Centrality in social networksconceptual clarification.
Social Networks, 1(3):215?239.Michael Gasser and Linda B. Smith.
1998.
Learningnouns and adjectives: A connectionist account.
InLanguage and Cognitive Processes, pages 269?306.Demdre Gentner.
1981.
Some interesting differences be-tween nouns and verbs.
Cognition and Brain Theory,pages 161?178.Roxana Girju, Adriana Badulescu, and Dan Moldovan.2003.
Learning semantic constraints for the automaticdiscovery of part-whole relations.
In Proceedings ofthe 2003 Conference of the North American Chapter ofthe Association for Computational Linguistics on Hu-man Language Technology, pages 1?8.Marti Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the 14thconference on Computational linguistics, pages 539?545.Boris Katz, Jimmy Lin, Daniel Loreto, Wesley Hilde-brandt, Matthew Bilotti, Sue Felshin, Aaron Fernan-des, Gregory Marton, and Federico Mora.
2003.
In-tegrating web-based and corpus-based techniques forquestion answering.
In Proceedings of the twelfth textretrieval conference (TREC), pages 426?435.David Kempe, Jon Kleinberg, and E?va Tardos.
2003.Maximizing the spread of influence through a socialnetwork.
In KDD ?03: Proceedings of the ninth ACMSIGKDD international conference on Knowledge dis-covery and data mining, pages 137?146.Jon Kleinberg and Steve Lawrence.
2001.
The structureof the web.
Science, 29:1849?1850.Zornitsa Kozareva and Eduard Hovy.
2010a.
Learningarguments and supertypes of semantic relations usingrecursive patterns.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Linguis-tics, ACL 2010, pages 1482?1491, July.Zornitsa Kozareva and Eduard Hovy.
2010b.
Not allseeds are equal: Measuring the quality of text miningseeds.
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages618?626.Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008.Semantic class learning from the web with hyponympattern linkage graphs.
In Proceedings of the 46thAnnual Meeting of the Association for ComputationalLinguistics ACL-08: HLT, pages 1048?1056.Beth Levin and Harold Somers.
1993.
English verbclasses and alternations: A preliminary investigation.Lun Li, David Alderson, Reiko Tanaka, John C. Doyle,and Walter Willinger.
2005.
Towards a Theory ofScale-Free Graphs: Definition, Properties, and Impli-cations (Extended Version).
Internet Mathematica,2(4):431?523.Dekang Lin and Patrick Pantel.
2002.
Concept discoveryfrom text.
In Proc.
of the 19th international confer-ence on Computational linguistics, pages 1?7.Mark E. Newman and Michelle Girvan.
2004.
Find-ing and evaluating community structure in networks.Physical Review, 69(2).Mark Newman.
2003.
Mixing patterns in networks.Physical Review E, 67.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1999.
The pagerank citation ranking:Bringing order to the web.Patrick Pantel and Marco Pennacchiotti.
2006.
Espresso:Leveraging generic patterns for automatically harvest-ing semantic relations.
pages 113?120.Marius Pasca.
2004.
Acquisition of categorized namedentities for web search.
In Proceedings of the thir-teenth ACM international conference on Informationand knowledge management, pages 137?145.1624Marius Pasca.
2007.
Weakly-supervised discovery ofnamed entities using web search queries.
In Proceed-ings of the Sixteenth ACM Conference on Informationand Knowledge Management, CIKM 2007, pages 683?690.Bruno R. Preiss.
1999.
Data structures and algorithmswith object-oriented design patterns in C++.Filippo Radicchi, Santo Fortunato, Benjamin Markines,and Alessandro Vespignani.
2009.
Diffusion of scien-tific credits and the ranking of scientists.
In Phys.
Rev.E 80, 056103.Deepack Ravichandran and Eduard H. Hovy.
2002.Learning surface text patterns for a question answer-ing system.
pages 41?47.Ellen Riloff and Jessica Shepherd.
1997.
A corpus-basedapproach for building semantic lexicons.
In Proceed-ings of the Empirical Methods for Natural LanguageProcessing, pages 117?124.Ellen Riloff.
1993.
Automatically constructing a dictio-nary for information extraction tasks.
pages 811?816.Peter Mark Roget.
1911.
Roget?s thesaurus of EnglishWords and Phrases.
New York Thomas Y. Crowellcompany.Gert Sabidussi.
1966.
The centrality index of a graph.Psychometrika, 31(4):581?603.Hassan Sayyadi and Lise Getoor.
2009.
Future rank:Ranking scientific articles by predicting their futurepagerank.
In 2009 SIAM International Conference onData Mining (SDM09).Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In Proceedings of the In-ternational Conference on New Methods in LanguageProcessing, pages 44?49.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2005.Learning syntactic patterns for automatic hypernymdiscovery.
pages 1297?1304.Stephen Soderland, Claire Cardie, and RaymondMooney.
1999.
Learning information extraction rulesfor semi-structured and free text.
Machine Learning,34(1-3), pages 233?272.Mark Steyvers and Joshua B. Tenenbaum.
2004.
Thelarge-scale structure of semantic networks: Statisticalanalyses and a model of semantic growth.
CognitiveScience, 29:41?78.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: a core of semantic knowledge.In WWW ?07: Proceedings of the 16th internationalconference on World Wide Web, pages 697?706.Partha Pratim Talukdar and Fernando Pereira.
2010.Graph-based weakly-supervised methods for informa-tion extraction and integration.
pages 1473?1481.Vishnu Vyas, Patrick Pantel, and Eric Crestan.
2009.Helping editors choose better seed sets for entity setexpansion.
In Proceedings of the 18th ACM Con-ference on Information and Knowledge Management,CIKM, pages 225?234.Dylan Walker, Huafeng Xie, Koon-Kiu Yan, and SergeiMaslov.
2006.
Ranking scientific publications using asimple model of network traffic.
December.Duncan Watts and Steven Strogatz.
1998.
Collec-tive dynamics of ?small-world?
networks.
Nature,393(6684):440?442.Fabio Massimo Zanzotto, Marco Pennacchiotti, andMaria Teresa Pazienza.
2006.
Discovering asym-metric entailment relations between verbs using selec-tional preferences.
In ACL-44: Proceedings of the 21stInternational Conference on Computational Linguis-tics and the 44th annual meeting of the Association forComputational Linguistics, pages 849?856.Dmitry Zelenko, Chinatsu Aone, Anthony Richardella,Jaz K, Thomas Hofmann, Tomaso Poggio, and JohnShawe-taylor.
2003.
Kernel methods for relation ex-traction.
Journal of Machine Learning Research 3.1625
