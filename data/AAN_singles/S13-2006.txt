Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 34?38, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsSOFTCARDINALITY: Learning to Identify DirectionalCross-Lingual Entailment from Cardinalities and SMTSergio Jimenez, Claudia BecerraUniversidad Nacional de ColombiaCiudad Universitaria,edificio 453, oficina 114Bogot?, Colombiasgjimenezv@unal.edu.cocjbecerrac@unal.edu.coAlexander GelbukhCIC-IPNAv.
Juan Dios B?tiz, Av.
Mendiz?bal,Col.
Nueva Industrial VallejoCP 07738, DF, M?xicogelbukh@gelbukh.comAbstractIn this paper we describe our system submit-ted for evaluation in the CLTE-SemEval-2013task, which achieved the best results in twoof the four data sets, and finished third in av-erage.
This system consists of a SVM clas-sifier with features extracted from texts (andtheir translations SMT) based on a cardinalityfunction.
Such function was the soft cardinal-ity.
Furthermore, this system was simplifiedby providing a single model for the 4 pairsof languages obtaining better (unofficial) re-sults than separate models for each languagepair.
We also evaluated the use of additionalcircular-pivoting translations achieving results6.14% above the best official results.1 IntroductionThe Cross-Lingual Textual Entailment (CLTE) taskconsists in determining the type of directional en-tailment (i.e.
forward, backward, bidirectional orno-entailment) between a pair of texts T1 and T2,each one written in different languages (Negri et al2013).
The texts and reference annotations for thistask were obtained through crowdsourcing appliedto simpler sub-tasks (Negri et al 2011).
CLTE hasas main applications content synchronization andaggregation in different languages (Mehdad et al2012; Duh et al 2013).
We participated in the firstevaluation of this task in 2012 (Negri et al 2012),achieving third place on average among 29 partici-pating systems (Jimenez et al 2012).Since in the CLTE task text pairs are in differentlanguages, in our system, all comparisons made be-tween two texts imply that one of them was writtenby a human and the other is a translation provided bystatistical machine translation (SMT).
Our approachis based on an SVM classifier (Cortes and Vapnik,1995) whose features were cardinalities combinedwith similarity scores.
That system was motivatedby the fact that most text similarity functions aresymmetric, e.g.
Edit Distance (Levenshtein, 1966),longest common sub-sequence (Hirschberg, 1977),Jaro-Winkler similarity (Winkler, 1990), cosine sim-ilarity (Salton et al 1975).
Thus, the use of thesefunctions as only resource seems counter-intuitivesince CLTE task is asymmetric for the forward andbackward entailment classes.Moreover, cardinality is the central component ofthe resemblance coefficients such as Jaccard, Dice,overlap, etc.
For instance, if T1 and T2 are textsrepresented as bag of words, it is only necessary toknow the cardinalities |T1|, |T2| and |T1 ?
T2| to ob-tain a similarity score using a resemblance coeffi-cient such as the Dice?s coefficient (i.e.
2 ?
|T1 ?T2|/(|T1| + |T2|)).
Therefore, the idea is to use theindividual cardinalities to enrich a set of features ex-tracted from texts.Cardinality gives a rough idea of the amount ofinformation in a collection of elements (i.e.
words)providing the number of different elements therein.That is, in a collection of elements whose majorityare repetitions contains less information than a col-lection whose elements are mostly different.
How-ever, the classical sets cardinality is a rigid mea-sure as do not take account the degree of similarityamong the elements.
Unlike the sets cardinality, softcardinality (Jimenez et al 2010) uses the similari-ties among the elements providing a more flexible34measurement of the amount of information in a col-lection.
In the 2012 CLTE evaluation campaign, itwas noted that the soft cardinality overcame classi-cal cardinality in the task at hand.
All the modelsused in our participation and proposed in this paperare based on the soft cardinality.
A brief descrip-tion of the soft cardinality is presented in Section 2,along with a description of the functions used to pro-vide the similarities between words.
Besides, the setof features that are derived from all pairs of texts andtheir cardinalities are presented in Section 3.Section 4 provides a detailed description for eachof the 4 models (one for each language pair) usedto get the predictions submitted for evaluation.
InSection 5 a simplified-multilingual model is testedwith several word-similarity functions and circular-pivoting translations.In sections 6 and 7 a brief discussion of the resultsand conclusions of our participation in this evalua-tion campaign are presented.2 Soft CardinalityThe soft cardinality (Jimenez et al 2010) of a col-lection of words T is calculated with the followingexpression:|T |?
=n?i=1wi?
?n?j=1sim(ti, tj)p??
?1(1)Having T ={t1, t2, .
.
.
, tn}; wi ?
0; p ?
0; 1 >sim(x, y) ?
0, x 6= y; and sim(x, x) = 1.
Theparameter p controls the degree of "softness" of thecardinality (the larger the ?harder?).
The coefficientswi are weights associated with each word (or term)t, which can represent the importance or informativecharacter of each word (e.g.
idf weights).
The func-tion sim is a word-similarity function.
Three suchfunctions are considered in this paper:Q-grams: each word ai is represented as a col-lection of character q-grams (Kukich, 1992).
In-stead of single length q-grams, a combination ofa range of lengths q1 to q2 was used.
Next,a couple of words are compared with the fol-lowing resemblance coefficient: sim(ti, tj) =|ti?tj |+bias?
?max(|ti|,|tj |)+(1??
)?min(|ti|,|tj |).
The parameters ofthis word-similarity function are q1, q2, ?
and bias.Group 1: basic cardinalities#1 |T1|?
#4 |T1 ?
T2|?#2 |T2|?
#5 |T1 ?
T2|?#3 |T1 ?
T2|?
#6 |T2 ?
T1|?Group 2: asymmetrical ratios#7 |T1?T2|?/|T1|?
#8 |T1?T2|?/|T2|?Group 3: similarity and arithmetical* scores#9 |T1?T2|?/|T1?T2|?
#102?|T1?T2|?|T1|?+|T2|?#11 |T1?T2|?/?|T1|??|T2|?
#12|T!?T2|?min[|T1|?,|T2|?
]#13 |T1?T2|?+|T1|?+|T2|?2?|T1|?
?|T2|?#14* |T1|?
?
|T2|?Table 1: Set of features derived from texts T1 and T2Edit-Distance: a similarity score for a pair ofwords can be obtained from their Edit Distance(Levenshtein, 1966) by normalizing and convertingdistance to similarity with the following expression:sim(ti, tj) = 1?EditDistance(ti,tj)max[len(ti),len(tj)].Jaro-Winkler: this measure is based on the Jaro(1989) similarity, which is given by this expressionJaro(ti, tj) = 13(clen(ti)+ clen(tj) +c?mc), where cis the number of characters in common within a slid-ing window of length max[len(ti),len(tj)]2 ?1.
To avoiddivision by 0, when c = 0 then Jaro(ti, tj) = 0.
Thenumber of transpositions m is obtained sorting thecommon characters according to their occurrencein each of the words and counting the number ofnon-matching characters.
Winkler (1990) proposedan extension to this measure taking into accountthe common prefix length l through this expression:sim(ti, tj) = Jaro(ti, tj) + l10 (1?
Jaro(ti, tj)).3 Features from CardinalitiesFor a pair of texts T1 and T2 represented as bagsof words three basic soft cardinalities can be cal-culated: |T1|?, |T2|?
and |T1 ?
T2|?.
The soft car-dinality of their union is calculated using the con-catenation of T1 and T2.
More additional featurescan be derived from these three basic features, e.g.|T1?T2|?
= |T1|?+|T2|??|T1?T2|?
and |T1?T2|?
=|T1|??
|T1 ?
T2|?.
The complete set of features clas-sified into three groups are shown in Table 1.4 Submitted Runs DescriptionThe data for the 2013 CLTE task consists of 4 datasets (spa-eng, ita-eng, fra-eng and deu-eng) each35Data set q1 q2 ?
biasdeu-eng 2 2 0.5 0.0fra-eng 2 3 0.5 0.0ita-eng 2 4 0.6 0.0spa-eng 1 3 0.5 0.1Table 2: Parameters of the q-grams word-similarity func-tion for each language pairwith 1,000 pairs of texts for training and 500 fortesting.
For each pair of texts T1 and T2 writtenin two different languages, two translations are pro-vided using the Google?s translator1.
Thus, T t1 is atranslation of T1 into the language of T2 and T t2 isa translation of T2 into the language of T1.
Usingthese pivoting translations, two pairs of texts can becompared: T1 with T t2 and Tt1 with T2.Then all training and testing texts and their trans-lations were pre-processed with the following se-quence of actions: i) text strings were tokenized,ii) uppercase characters are converted into lower-case equivalents, iii) stop words were removed, iv)punctuation marks were removed, and v) words werestemmed using the Snowball2 multilingual stem-mers provided by the NLTK Toolkit (Loper andBird, 2002).
Then every stemmed word is taggedwith its idf weight (Jones, 2004) calculated with thecomplete collection of texts and translations in thesame language.Five instances of the soft cardinality are providedusing 1, 2, 3, 4 and 5 as values of the parameterp.
Therefore, the total number of features for eachpair of texts is the multiplication of the number offeatures in the feature set (i.e.
14, see Table 1) bythe number of soft cardinality functions (5) and by 2,corresponding to the two pairs of comparable texts.That is, 14?
5?
2 = 140 features.The sim function used was q-grams, whose pa-rameters were adjusted for each language pair.These parameters, which are shown in Table 2, wereobtained by manual exploration using the trainingdata.Four vector data sets for training (one for eachlanguage pair) were built by extracting the 140 fea-tures from the 1,000 training instances and using1https://translate.google.com2http://snowball.tartarus.orgECNUCS-team?s systemspa-eng ita-eng fra-eng deu-eng averagerun4 0.422 0.416 0.436 0.452 0.432run3 0.408 0.426 0.458 0.432 0.431SOFTCARDINALITY-team?s systemspa-eng ita-eng fra-eng deu-eng averagerun1 0.434 0.454 0.416 0.414 0.430run2 0.432 0.448 0.426 0.402 0.427Table 3: Official results for our system and the top per-forming system ECNUCS (accuracies)their gold-standard annotations as class attribute.Predictions for the 500 test cases were obtainedthrough a SVM classifier trained with each data set.For the submitted run1, this SVM classifier used alinear kernel with its complexity parameter set to itsdefault value C = 1.
For the run2, this parameterwas adjusted for each pair of languages with the fol-lowing values: Cspa?eng = 2.0, Cita?eng = 1.5,Cfra?eng = 2.3 and Cdeu?eng = 2.0.
The imple-mentation of the SVM used is that which is availablein WEKA v.3.6.9 (SMO) (Hall et al 2009).
Officialresults for run1, run2 and best accuracies obtainedamong all participant systems are shown in Table 3.5 A Single Multilingual ModelThis section presents the results of our additional ex-periments in search for a simplified model and inturn to respond to the following questions: i) Canone simplified-multilingual model overcome the ap-proach presented in Section 4?
ii) Does using addi-tional circular-pivoting translations improve perfor-mance?
and iii) Do other word-similarity functionswork better than the q-grams measure?First, it is important to note that the approachdescribed in Section 4 used only patterns discov-ered in cardinalities.
This means, that no language-dependent features was used, with the exception ofthe stemmers.
Therefore, we wonder whether thepatterns discovered in a pair of languages can be use-ful in other language pairs.
To answer this question,a single prediction model was built by aggregatinginstances from each of the vector data sets into onedata set with 4,000 training instances.
Afterward,this model was used to provide predictions for the2,000 test cases.36Moreover, customization for each pair of lan-guages in the word-similarity function, which isshow in Table 2, was set on the following unique setof parameters: q1 = 1, q2 = 3, ?
= 0.5, bias = 0.0.Thus, the words are compared using q-grams andthe Dice coefficient.
In addition to the measure ofq-grams, two "off-the-shelf" measures were used asnonparametric alternatives, namely: Edit Distance(Levenshtein, 1966) and the Jaro-Winkler similarity(Winkler, 1990).In another attempt to simplify this model, weevaluated the predictive ability of each of the threegroups of features shown in Table 1.
The combi-nation of groups 2 and 3, consistently obtained bet-ter results when the evaluation with 10 fold cross-validation was used in the training data.
This resultwas consistent with the simple training versus testdata evaluation.
The sum of all previous simplifica-tions significantly reduced the number of parametersand features in comparison with the model describedin Section 4.
That is, only one SVM and 4 parame-ters, namely: ?, bias, q1 and q2.Besides, the additional use of circular-pivotingtranslations was tested.
In the original model, forevery pair of texts (T1, T2) their pivot translations(T t1 , Tt2) were provided allowing the calculation of|T1 ?
T t2| and |Tt1 ?
T2|.
Translations Tt1 and Tt2 canalso be translated back to their original languagesobtaining T tt1 and Ttt2 .
These additional transla-tions in turn allows the calculation of |T tt1 ?
Tt2|and |T t1 ?
Ttt2 |.
This procedure can be repeatedagain to obtain T ttt1 and Tttt2 , which in turn provides|T1 ?
T ttt2 |, |Tttt1 ?
T2|, |Ttt1 ?
Tttt2 | and |Tttt1 ?
Ttt2 |.The original feature set is denoted as t. The extendedfeature sets using double-pivoting translations andtriple-pivot translations are denoted respectively astt and ttt.The results obtained with this simplified modelusing single, double and triple pivot translations areshown in Table 4.
The first column indicates theword-similarity function used by the soft cardinal-ity and the second column indicates the number ofpivoting translations.6 DiscussionIn spite of the customization of the parameter C inthe run2, the run1 obtained better results than run2Soft C. #t spa-e ita-e fra-e deu-e avg.Ed.Dist.
t 0.444 0.450 0.440 0.410 0.436Ed.Dist.
tt 0.452 0.464 0.434 0.432 0.446Ed.Dist.
ttt 0.464 0.468 0.440 0.424 0.449Jaro-W. t 0.422 0.450 0.426 0.406 0.426Jaro-W. tt 0.430 0.456 0.444 0.400 0.433Jaro-W. ttt 0.426 0.458 0.430 0.430 0.436q-grams t 0.428 0.456 0.456 0.432 0.443q-grams tt 0.436 0.478 0.444 0.430 0.447q-grams ttt 0.452 0.474 0.464 0.442 0.458Table 4: Single-multilingual model results (accuracies)(see Table 3).
This result indicates that the simplermodel produced better predictions in unseen data.It is also important to note that two of the threemultilingual systems proposed in Section 5 achievedhigher scores than the best official results (see rowscontaining ?t?
in Table 4).
This indicates that theproposed simplified model is able to discover pat-terns in the cardinalities of a pair of languages andproject them into the other language pairs.Regarding the use of additional circular-pivotingtranslations, Table 4 shows that t was overcome onaverage by tt and tt by ttt in all cases of the threesets of results.
The relative improvement obtainedby comparing t versus ttt for each group was 3.0% inEdit Distance, 2.3% for Jaro-Winkler and 3.4% forthe q-gram measure.
This same trend holds roughlyfor each language pair.7 ConclusionsWe described the SOFTCARDINALITY systemthat participated in the SemEval CLTE evaluationcampaign in 2013, obtaining the best results in datasets spa-eng and ita-eng, and achieving the thirdplace on average.
This result was obtained usingseparate models for each language pair.
It was alsoconcluded that a single-multilingual model outper-forms that approach.
Besides, we found that theuse of additional pivoting translations provide bet-ter results.
Finally, the measure based on q-grams ofcharacters, used within the soft cardinality, resultedto be the best option among other measures of wordsimilarity.
In conclusion, the soft cardinality methodused in combination with SMT and SVM classifiersis a competitive method for the CLTE task.37AcknowledgmentsThis research was funded in part by the Systemsand Industrial Engineering Department, the Officeof Student Welfare of the National University ofColombia, Bogot?, and through a grant from theColombian Department for Science, Technologyand Innovation, Colciencias, proj.
1101-521-28465with funding from ?El Patrimonio Aut?nomo FondoNacional de Financiamiento para la Ciencia, la Tec-nolog?a y la Innovaci?n, Francisco Jos?
de Caldas.
?The third author recognizes the support from Mexi-can Government (SNI, COFAA-IPN, SIP 20131702,CONACYT 50206-H) and CONACYT?DST India(proj.
122030 ?Answer Validation through TextualEntailment?
).ReferencesCorinna Cortes and Vladimir N. Vapnik.
1995.
Support-vector networks.
Machine Learning, 20(3):273?297.Kevin Duh, Ching-Man Au Yeung, Tomoharu Iwata, andMasaaki Nagata.
2013.
Managing information dispar-ity in multilingual document collections.
ACM Trans.Speech Lang.
Process., 10(1):1:1?1:28, March.Mark Hall, Frank Eibe, Geoffrey Holmes, and BernhardPfahringer.
2009.
The WEKA data mining software:An update.
SIGKDD Explorations, 11(1):10?18.Daniel S. Hirschberg.
1977.
Algorithms for the longestcommon subsequence problem.
J. ACM, 24(4):664?675, October.M.A.
Jaro.
1989.
Advances in record-linkage methodol-ogy as applied to matching the 1985 census of tampa,florida.
Journal of the American Statistical Associa-tion, pages 414?420, June.Sergio Jimenez, Fabio Gonzalez, and Alexander Gel-bukh.
2010.
Text comparison using soft cardinality.In Edgar Chavez and Stefano Lonardi, editors, StringProcessing and Information Retrieval, volume 6393 ofLNCS, pages 297?302.
Springer, Berlin, Heidelberg.Sergio Jimenez, Claudia Becerra, and Alexander Gel-bukh.
2012.
Soft cardinality+ ML: learning adaptivesimilarity functions for cross-lingual textual entail-ment.
In Proceedings of the 6th International Work-shop on Semantic Evaluation (SemEval, *SEM 2012),Montreal, Canada.
ACL.Karen Sp?rck Jones.
2004.
A statistical interpretation ofterm specificity and its application in retrieval.
Jour-nal of Documentation, 60(5):493?502, October.Karen Kukich.
1992.
Techniques for automaticallycorrecting words in text.
ACM Computing Surveys,24:377?439, December.Vladimir I. Levenshtein.
1966.
Binary codes capable ofcorrecting deletions, insertions, and reversals.
SovietPhysics Doklady, 10(8):707?710.Edward Loper and Steven Bird.
2002.
NLTK: the natu-ral language toolkit.
In Proceedings of the ACL Work-shop on Effective Tools and Methodologies for Teach-ing Natural Language Processing and ComputationalLinguistics.
Philadelphia.
Association for Computa-tional Linguistics.Yashar Mehdad, Matteo Negri, and Marcello Federico.2012.
Detecting semantic equivalence and informa-tion disparity in cross-lingual documents.
In Proceed-ings of the 50th Annual Meeting of the Association forComputational Linguistics: Short Papers - Volume 2,ACL ?12, page 120?124, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Matteo Negri, Luisa Bentivogli, Yashar Mehdad, DaniloGiampiccolo, and Alessandro Marchetti.
2011.
Di-vide and conquer: crowdsourcing the creation of cross-lingual textual entailment corpora.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, EMNLP ?11, page 670?679,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Matteo Negri, Alessandro Marchetti, Yashar Mehdad,Luisa Bentivogli, and Danilo Giampiccolo.
2012.2012. semeval-2012 task 8: Cross-lingual textual en-tailment for content synchronization.
In Proceedingsof the 6th International Workshop on Semantic Evalu-ation (SemEval 2012), Montreal, Canada.Matteo Negri, Alessandro Marchetti, Yashar Mehdad,and Luisa Bentivogli.
2013.
Semeval-2013 task8: Cross-lingual textual entailment for content syn-chronization.
In Proceedings of the 7th InternationalWorkshop on Semantic Evaluation (SemEval 2013).Gerard Salton, Andrew K. C. Wong, and Chung-ShuYang.
1975.
A vector space model for automatic in-dexing.
Commun.
ACM, 18(11):613?620.William E. Winkler.
1990.
String comparator metricsand enhanced decision rules in the fellegi-sunter modelof record linkage.
In Proceedings of the Section onSurvey Research Methods, pages 354?359.
AmericanStatistical Association.38
