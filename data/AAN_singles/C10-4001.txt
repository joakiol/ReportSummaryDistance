Coling 2008: Paraphrases and Applications?Tutorial notes, pages 1?87,Beijing, August 2010Paraphrases and ApplicationsShiqi ZhaoBaidu, Inc.Haifeng WangBaidu, Inc.Outline?
Part I?
Introduction?Paraphrase Identification?Paraphrase Extraction?
Part II?Paraphrase Generation?Applications of Paraphrases?Evaluation of Paraphrases?Conclusions and Future work1?
Paraphrase?NounDefinition?
Alternative expressions of the same meaning?Verb?
Generate paraphrases for the input expression?
?same meaning??
?Quite subjective?Different degrees of strictness?Depend on applicationsParaphrase (noun): Alternative expressions of the same meaningKorean Kim Yuna won goldwith a world-record score inwomen's figure skating at theVancouver Olympics Thursday.Korean figure skater KimYuna has won the goldmedal of women?s figureskating at the WinterOlympics in VancouverKim Yu-Na (19) is a SouthKorean ice skater who tookthe gold medal at theVancouver Olympics.Kim Yuna, a South Koreanfigure skater has won thegold medal at the on-going Winter Olympics2010.Yuna Kim of South Koreawon the women's figureskating gold medal at theVancouver Olympics inrecord fashion.2Paraphrase (verb): Generate paraphrases for an input S.AutomaticSparaphrasegenerationT1 T2 T3 T4Classification of Paraphrases?
According to granularity?Surface paraphrases?
Lexical level?
Phrase level?
Sentence level?
Discourse level?Structural paraphrases?
Pattern level?
Collocation level3Examples?
Lexical paraphrases (generally synonyms)?
solve and resolve?
Paraphrase phrases?
look after and take care of?
Paraphrase sentences?
The table was set up in the carriage shed.?
The table was laid under the cart-shed.?
Paraphrase patterns[X] considers [Y]??
[X] takes [Y] into consideration?
Paraphrase collocations?
(turn on, OBJ, light)?
(switch on, OBJ, light)?
According to paraphrase style?Trivial changeClassification of Paraphrases?Phrase replacement?Phrase reordering?Sentence split & merge?Complex paraphrases4Examples?
Trivial change?
all the members of and all members of?
Phrase replacement?
He said there will be major cuts in the salaries of high-level civil servants.?
He said there will be major cuts in the salaries of senior officials.?
Phrase reordering?
Last night, I saw Tom in the shopping mall.?
I saw Tom in the shopping mall last night.?
Sentence split & merge?
He bought a computer, which is very expensive.?
(1) He bought a computer.
(2) The computer is very expensive.?
Complex paraphrases?
He said there will be major cuts in the salaries of high-level civil servants.?
He claimed to implement huge salary cut to senior civil servants.Applications of Paraphrases?
Machine Translation (MT)?
Simplify input sentences?
Summarization?
Sentence clustering?
Alleviate data sparseness?
Parameter tuning?
Automatic evaluation?
Question Answering (QA)?
Question reformulation?
Information Extraction (IE)?
IE pattern expansion?
Automatic evaluation?
Natural Language Generation(NLG)?
Sentence rewriting?
Others?
Changing writing style?
Text simplification?
Information Retrieval (IR)?
Query reformulation?
Identifying plagiarism?
Text steganography?
?
?5Research on Paraphrasing?
Paraphrase identification?Identify (sentential) paraphrases?
Paraphrase extraction?Extract paraphrase instances (different granularities)?
Paraphrase generation?Generate (sentential) paraphrases?
P h li tiarap rase app ca ons?Apply paraphrases in other areasTextual Entailment ?
A Similar Direction?
Textual entailment:?A directional relation between two text fragments?
T: the entailing text?
H: the entailed hypothesis?T entails H if, typically, a human reading T would inferthat H is most likely true.
?Compare entailment with paraphrase?
P h i bidi i l ilarap rase s rect ona  enta ment6Text Entailment ?
A Similar Direction?
Recognizing Textual Entailment Track (RTE)?RTE 1 (2004) to RTE 5 (2009)-    -?RTE-6 (2010) is in progress?
Example:?T: A shootout at the Guadalajara airport in May, 1993,killed Cardinal Juan Jesus Posadas Ocampo.
?H: Juan Jesus Posadas Ocampo died in 1993      .Outline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
Part II?Paraphrase Generation?Applications of Paraphrases?Evaluation of Paraphrases?Conclusions and Future work7Paraphrase Identification?
Specially refers to sentential paraphraseidentification?Given any pair of sentences, automatically identifieswhether these two sentences are paraphrases?
Paraphrase identification is not trivialSusan often goes to see movies with her boyfriend.Susan never goes to see movies with her boyfriend.He said there will be major cuts in the salaries of high-level civil servants.He claimed to implement huge salary cut to senior civil servants.Overview?
Classification based methods?Reviewed as a binary classification problem i e     , .
.,input s1 and s2 to a classifier and output 0/1?Compute the similarities between s1 and s2 at differentlevels, which are then used as classification features?
Alignment based methods?Align s1 and s2 first, and score the sentence pairbased on the alignment results?
Alignment based on ITG?
Alignment based on quasi-synchronous dependencygrammars8Classification based Methods?
Brockett and Dolan, 2005?Features:?
String similarity features?Sentence length, word overlap, edit distance, ??
Morphological variants?Word pairs with the same stem?
WordNet lexical mappings?Synonym pairs / word-hypernym pairs from WordNetorbit | orbitaloperation | procedure?
Word association pairs?Automatically learned synonym pairs?Classifier?
SVM classifiervendors | suppliersClassification based Methods (cont?)?
Finch et al, 2005?Using MT evaluation techniques to compute sentencesimilarities, which are then used as classificationfeatures?
WER, PER, BLEU, NIST?
Feature vector vec(s1, s2)?
vec1(s1, s2): s1 as reference, s2 as MT system output;?
vec2(s1, s2): s2 as reference, s1 as MT system output;?
vec(s1, s2): average of vec1(s1, s2) and vec2(s1, s2):?Classifier?
SVM classifier9Classification based Methods (cont?)?
Malakasiotis, 2009?Combining multiple classification features?
String similarity (various levels)?Tokens, stems, POS tags, nouns only, verbs only, ??
Different measures?Edit distance, Jaro-Winkler distance, Manhattan distance??
Synonym similarity?Treat synonyms in two sentences as identical words?
Syntax similarity?Dependency parsing of two sentences and compute theoverlap of dependencies?Classifier?
Maximum Entropy classifierAlignment based Methods?
Wu, 2005?Conduct alignment based on Inversion TransductionGrammars (ITG)?
Sensitive to the differences in sentence structures?
Without using any thesaurus to deal with lexical variation?Performance is comparable to the classificationbased methodsAl f ll i i i t t l t il t?
so per orms we  n recogn z ng ex ua  en a men10Alignment based Methods (cont?)?
Das and Smith, 2009?Conduct alignment based on Quasi-SynchronousDependency Grammar (QG)?
Alignment between two dependency trees?
Assumption: the dependency trees of two paraphrasesentences should be aligned closely?Why does it work?About 120 potential jurors were being asked to complete a lengthy questionnaire .Align words thatare not identical?Performs competitively with classification basedmethodsThe jurors were taken into the courtroom in groups of 40 and asked to fill out a questionnaire .A Summary?
Classification based method is still themainstream method since: ,?Binary classification problem is well defined;?Classification algorithms and tools are readilyavailable;?It can combine various features in a simple way;?It achieves state-of-the-art performance.11References?
Brockett and Dolan.
2005.
Support Vector Machines for ParaphraseIdentification and Corpus Construction.?
Fi h t l 2005 U i M hi T l ti E l ti T h i tnc  e  a .
.
s ng ac ne rans a on va ua on ec n ques oDetermine Sentence-level Semantic Equivalence.?
Wu.
2005.
Recognizing Paraphrases and Textual Entailment usingInversion Transduction Grammars.?
Malakasiotis.
2009.
Paraphrase Recognition Using Machine Learning toCombine Similarity Measures.?
Das and Smith.
2009.
Paraphrase Identification as Probabilistic Quasi-Synchronous Recognition.Outline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
Part II?Paraphrase Generation?Applications of Paraphrases?Evaluation of Paraphrases?Conclusions and Future work12Corpora Assumption AlgorithmThree Elements for ParaphraseExtraction?
thesauri?
monolingual parallelcorpora?
monolingual compar-able corpora?
bilingual parallel?
Different translationversions preservethe meaning of theoriginal source?
Comparable newsarticles may containdistinct descriptions?
co-training?
classification?
logistic regression?
clustering?
word alignment???corpora?
large web corpora?
search engine querylogs?
dictionary glosses??
?of the same facts?
Multiple phrases thatalign with the sameforeign phrase mayhave the same mean-ing?
Distributional hypoth-esis???Outline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
From Thesauri?
From Monolingual Parallel Corpora?
From Monolingual Comparable Corpora?
F Bili l P ll l Crom ngua  ara e  orpora?
From Large Web Corpora?
From Other Resources13Method Overview?
Extract words with specific semantic relations asparaphrases?Most common: synonyms?Other relations: hypernyms, hyponyms??
Widely used thesauri?In English?
WordNet?In other languages?
E.g., HowNet, Tongyici Cilin in ChinesePros and Cons?
Pros?Existing resources?High quality?
Thesauri are hand crafted?
Cons?Language limitation?
Thesauri are not available in many languages?Difficult to update14Outline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
From Thesauri?
From Monolingual Parallel Corpora?
From Monolingual Comparable Corpora?
F Bili l P ll l Crom ngua  ara e  orpora?
From Large Web Corpora?
From Other ResourcesMethod Overview?
Corpus?Multiple translations of the same foreign literary work?
Assumption?Different translation versions preserve the meaning ofthe original source, but may use different expressions15Vingt mille lieues sous les mers(in French)Example20000 Leagues Under the Sea(different English translation versions)?
?Sentence Alignment and Preprocessing?
Barzilay and McKeown, 2001?Collected 11 English translations for 5 foreign novels?
E.g., Madame Bovary, Fairy Tale, Twenty ThousandLeagues under the sea?
?Sentence alignment?
A dynamic programming algorithm?
Produced 44,562 pairs of parallel sentences?
Precision is 94 5%  .
?Other preprocessing?
POS tagging and chunking?
Phrases are the atomic units in paraphrase extraction16Paraphrase Phrase Extraction?
Barzilay and McKeown, 2001 (cont?
)?Extracting paraphrase phrases?
Assumption: phrases in aligned sentences which appear insimilar contexts are paraphrases?
Method: co-training?
Iteratively learn contexts and paraphrasesLeft context right contextparaphrasesMy imagination melted into hazy drowsiness , and I soon fell into an uneasy slumber .My imagination wandered  into vague unconsciousness , and I soon fell into a deep sleep .Pros and Cons?
Pros?Easy to align monolingual parallel sentences?
Cons?Domain limitation?
Limited in literary works?Scale limitation?
Th i f th i l ti l lle s ze o  e corpus s re a ve y sma?Context dependence?
E.g., ?John said?
and ?he said?17Outline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
From Thesauri?
From Monolingual Parallel Corpora?
From Monolingual Comparable Corpora?
F Bili l P ll l Crom ngua  ara e  orpora?
From Large Web Corpora?
From Other ResourcesMethod Overview?
Corpus?News articles that report the same event within a briefperiod of time?
Produced by different news agencies?
Assumption?Comparable news articles may contain distinctdescriptions of the same facts18ExampleComparable documentsd1 d2ProcedureNewscorpusParaphrasephrasesParaphrasepatternsParaphrasegenerationIdentifycomparabledocumentsExtractparaphrasephrasesExtractparaphrasepatternsMT-basedparaphrasegenerationmodelExtractparallelsentencesComparabledocumentsParallelcorpus19Identify Comparable Documents?
Input?News articles from different news agencies?
E.g., CNN, New York Times, Washington Post??
Processing?Method-1: Retrieve documents on a given topic or event?
Needs predefined topics or events?Method-2: Cluster documents?
Content similarity; time interval?
Output?Corpus of comparable documentsExtract Parallel (Paraphrase) Sentences?
Input?Corpus of comparable documents?
Processing?Sentence clustering?
Method-1: based on an assumption: first sentences of anews article usually summarize its content?
Method-2: based on computing the content similarity?
Output?Corpus of parallel (paraphrase) sentences20Extract Paraphrase Patterns?
Using NEs as anchors?
Shinyama et al, 2002?
Basic idea: paraphrase sentences should contain comparable NEsComparable NEsSlots of the same typeparaphrasesExtract Paraphrase Patterns?
Multiple-sequence alignment?
Barzilay and Lee, 2003backbone slot21Pros and Cons?
Pros?Language independent-?
Comparable news can be found in many languages?
Cons?Domain-dependent?
Paraphrases are extracted from specific domains or topics?Sentence clustering?
Either too strict or too looseOutline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
From Thesauri?
From Monolingual Parallel Corpora?
From Monolingual Comparable Corpora?
F Bili l P ll l Crom ngua  ara e  orpora?
From Large Web Corpora?
From Other Resources22Method Overview?
Corpus?A parallel corpus of the source language and aforeign language?
Assumption?Multiple phrases that align with the same foreignphrase may have the same meaning?
The method is also termed as ?pivot approach?Examplesource languageforeign language(pivot language)Alignment?
?different parts?
?different places????????????eiejcmcn?
?various locations???
?ek23A Simple Version?
Takao et al, 2002?Basic idea:?
Generating lexical paraphrases using 2-way dictionaries?
English word e1 can be translated to a Japanese word j withan E-J dic.
D1, and then j can be translated back to anEnglish word e2 with a J-E dictionary D2.
e1 and e2 areextracted as paraphrasesExtracting Paraphrase Phrases?
Bannard and Callison-Burch, 2005?Word alignment and phrase extraction?Basic assumption:?
If two English phrases e1 and e2 can be aligned with thesame foreign phrase f, e1 and e2 are likely to be paraphrases.
?Paraphrase probability:2 12 2 1?
arg max ( | )e ee p e e?= Pivot in a foreign language2 11 2arg max ( | ) ( | )e efp f e p e f?= ?Translation probability24?should take the matter into consideration??????????
?take the matter into considerationBannard & Callison-Burch (2005) ?s results:?must take the matter into account??????????
?The consideration of this matter will????????
?take the matter into accounttake the matter into considerationthe consideration of this matterthe consideration of this mattertake the matter into accountHe?ll take the matter into consideration???????
?We need to consider this matter?????????
?consider this mattertake the matter into considerationAdd Syntactic Constraints?
Callison-Burch, 2008?Basic idea:?
Two paraphrase phrases should have the same syntactictype.
?Paraphrase probability:2 2 1 2 12 2 1 1: ( ) ( )?
arg max ( | , ( ))arg max ( | ( )) ( | ( ))e e e s e s ee p e e s ep f e s e p e f s e?
?
=== ?given the syntactic type?Syntactic constraints are also used when substitutingparaphrases in sentences2 2 1 2 11 1 2 1: ( ) ( ), ,e e e s e s e f?
?
=25?should take the matter into consideration??????????
?take the matter into considerationtake the matter into accountCallison-Burch (2008) ?s results:?must take the matter into account??????????
?The consideration of this matter will????????
?take the matter into considerationthe consideration of this matterthe consideration of this mattertake the matter into accountHe?ll take the matter into consideration???????
?We need to consider this matter?????????
?consider this mattertake the matter into considerationLearning Paraphrases from Graphs?
Kok and Brockett, 2010?Basic idea:?
Convert aligned phrases into a graph, extract paraphrasesbased on random walks and hitting times26?should take the matter into consideration??????????
?take the matter into considerationKok and Brockett (2010) ?s results:?must take the matter into account??????????
?The consideration of this matter will????????
?take the matter into accountconsider this mattertake the matter into accountHe?ll take the matter into consideration???????
?We need to consider this matter?????????
?consider this mattertake the matter into considerationExtracting Paraphrase Patterns?
Zhao et al, 2008?Basic idea:?
Generate paraphrase patterns that include part-of-speechslots.
?Paraphrase probability:2 1 1 21( | ) exp[ ( , , )]Ni ic iscore e e h e e c?==?
?1 1 2 12 1 2 23 1 2 14 1 2 2( , , ) ( | )( , , ) ( | )( , , ) ( | )( , , ) ( | )MLEMLELWLWh e e c score c eh e e c score e ch e e c score c eh e e c score e c====Based on maximumlikelihood estimationBased on lexical weighting27takedemand intotake market   demand into       considerationInducing English patterns Inducing Chinese patternsExamplemarket considerationtake into considerationNN NNtake into considerationNN???
??
?
?take NN into        consideration????
NNconsider NN???
?
NNExtract paraphrase patternstake NN into consideration & consider NN?should take the matter into consideration??????????
?take [NN] into considerationtake [NN] into accountZhao et al(2008) ?s results:?must take the matter into account??????????
?The consideration of this matter will????????
?H ?ll t k th tt i t id titake [NN] into considerationthe consideration of [NN]the consideration of [NN]take [NN] into accounte  a e e ma er n o cons era on???????
?We need to consider this matter?????????
?consider [NN]take [NN] into consideration28Pros and Cons?
Pros?The method proves effective hence it?s widely used   ,?
High precision?
Large scale?
Cons?Language limitation?
Cannot work where the large-scale bilingual parallel corporaare not availableOutline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
From Thesauri?
From Monolingual Parallel Corpora?
From Monolingual Comparable Corpora?
F Bili l P ll l Crom ngua  ara e  orpora?
From Large Web Corpora?
From Other Resources29Method Overview?
Corpus?Large corpus of web documents?Or directly based on web mining?
Assumption?Distributional hypothesis?
If two words / phrases / patterns often occur in similarcontexts, their meanings tend to be similarExampleShakespeareChekhov Merchant of VeniceWar and PeaceX wrote    YMaupassantHugo GorkyTagoreMurakami TolstoyYasunariNotre Dame de ParisRomeo and JulietMadame BovaryMadame Bovarysimilar similarparaphrasesX is the author of    YShakespeareMaupassantHugoGorkyHemingwayBalzacMerchant of VeniceNotre Dame de ParisThe Old Man and SeaRomeo and Juliet30Extracting Lexical Paraphrases (Word Clustering)?
Lin, 1998?Basic idea?
Measure words?
similarity based on the distributional patternof words?Corpus?
A (dependency) parsed corpus?Word similarityMutualinformation1 21 21 2( , ) ( ) ( )1 21 2( , ) ( ) ( , ) ( )( ( , , ) ( , , ))( , )( , , ) ( , , )r rr rr w T w T wr w T w r w T wI w r w I w r wsim w wI w r w I w r w?
??
?+= +??
?Extracting Syntactic Paraphrase Patterns?
Lin and Pantel, 2001?
Basic idea: extended distributional hypothesis?
Corpus: a large corpus of parsed monolingual sentences?
pattern pairsXsolvesYXfindssolutiontoa?
Pattern similarity1 2 1 2 1 2( , ) ( , ) ( , )sim p p sim SlotX SlotX sim SlotY SlotY= ?YSimilarity of the slot fillers31Extracting Surface Paraphrases?
Bhagat and Ravichandran, 2008?Basic idea is the same as the above work?Corpus:?
a large corpus of monolingual sentences without parsing?150GB, 25 billion words?Surface paraphrases?
Pairs of n-gramsE g ?X acquired Y?
and ?X completed the acquisition of Y??
.
.,?Techniques?
Apply locality sensitive hashing (LSH) to speed up thecomputationLearning Unary Paraphrase Patterns?
Szpector and Dagan, 2008?Binary paraphrase patterns (most of the previous work)?
Each pattern has two slots at both ends?E.g., ?X solves Y?
and ?X found a solution to Y?
?Unary paraphrase patterns?
Each pattern has a single slot?E.g., ?X take a nap?
and ?X sleep??Methodsleepkidsinroom?
The same with the above works?Based on distributional hypothesistheX sleep32Extracting Paraphrases based on Web Mining?
Ravichandran and Hovy, 2002?Basic idea?
Learn paraphrase patterns with search engines?Corpus?
The whole internet?Method?
Extract paraphrase patterns for each type, e.g., ?BIRTHDAY??
Provide hand-crafted seeds, e.g., ?Mozart, 1756??
Retrieve sentences containing the seeds from the web with asearch engine?
Extract patterns, e.g.,?born in <ANSWER> , <NAME>?<NAME> was born on <ANSWER> ,??
?Pros and Cons?
Pros?Language independent?
Cons?For methods based on large web corpora?
Computation complexity is high?Needs to process an extremely large corpus?Needs to compute pairwise similarity for all candidates?For methods based on web mining?
Extract paraphrase patterns type by type?
Needs to prepare seeds beforehand33Outline?
Part I?Introduction?Paraphrase Identification?Paraphrase Extraction?
From Thesauri?
From Monolingual Parallel Corpora?
From Monolingual Comparable Corpora?
F Bili l P ll l Crom ngua  ara e  orpora?
From Large Web Corpora?
From Other ResourcesParaphrasing with Search Engine Query Logs?
Zhao et al, 2010?Corpus?
Query logs (queries and titles) of a search engine?Assumption?
If a query q hits a title t, then q and t are likely to beparaphrases?
If queries q1 and q2 hit the same title t, then q1 and q2 arelikely to be paraphrases?
If a query q hits titles t1 and t2, then t1 and t2 are likely to beparaphrases34Example??????????????q1t1??????
?q2Paraphrases:<q1, t1><q1, t2>< 2 t1>query-title??????????
?t2q ,<q1,q2><t1,t2>query-querytitle-titleMethod?
Step-1: extracting <q, t> paraphrases?
Extracting candidate <q, t> pairs from query logs?
Paraphrase validation based on binary classification?
Combining multiple features?
Step-2: extracting <q, q> paraphrases?
Extracting candidate <q, q> from <q, t> paraphrases?
Paraphrase validation based on binary classification?
Step-3: extracting <t, t> paraphrases?
Extracting candidate <t, t> from <q, t> paraphrases?
Paraphrase validation based on binary classification35Pros and Cons?
Pros?No scale limitation?
Query logs keep growing?
A large volume of paraphrases can be extracted?Query logs reflect web users?
real needs?
Cons?Query logs data are only available in IR companies?User queries are noisy?
Spelling mistakes, grammatical errors?Extracting Paraphrases from Dictionary Glosses?
Corpus?Glosses of dictionaries?
Assumption?A word and its definition (gloss) in the dictionary havethe same meaning36Example (Encarta Dictionary)hurricanesevere stormhigh windfast and force person or thingMethod?
Prune and reformulate the definitions?For a verb v extracts the head of the definition (h)   ,and h?s adverb modifier m as v?s paraphrase?
Kaji et al, 2002?Rule based method for extracting the appropriate partfrom the definition?
Higashinaka and Nagao, 2002?
E g w should not be in def; ignore contents in parentheses.
.,in def; avoid double negation?37Pros and Cons?
Pros?Explain unfamiliar words with simpler definitions?
Cons?Transformation of person, number, tensepresident head of companypresidentsheads of companyhead of companiesE.g.,heads of companiesReferences?
From monolingual parallel corpora?
Barzilay and McKeown.
2001.
Extracting Paraphrases from a ParallelCorpus.?
From monolingual comparable corpora?
Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo.
2002.
AutomaticParaphrase Acquisition from News Articles.?
Regina Barzilay and Lillian Lee.
2003.
Learning to Paraphrase: AnUnsupervised Approach Using Multiple-Sequence Alignment.?
Bill Dolan, Chris Quirk, and Chris Brockett.
2004.
UnsupervisedConstruction of Large Paraphrase Corpora: Exploiting MassivelyParallel News Sources.38References (cont?)?
From bilingual parallel corpora?
Takao et al 2002.
Comparing and Extracting Paraphrasing Words with2-Way Bilingual Dictionaries.?
Bannard and Callison-Burch.
2005.
Paraphrasing with Bilingual ParallelCorpora.?
Callison-Burch.
2008.
Syntactic Constraints on Paraphrases Extractedfrom Parallel Corpora.?
Kok and Brockett.
2010.
Hitting the Right Paraphrases in Good Time.?
Zhao et al 2008.
Pivot Approach for Extracting Paraphrase Patternsfrom bilingual corpora  .References (cont?)?
From large web corpora?
Lin.
1998.
Automatic Retrieval and Clustering of Similar Words.?
Lin and Pantel.
2001.
Discovery of Inference Rules for QuestionAnswering.?
Bhagat and Ravichandran.
2008.
Large Scale Acquisition ofParaphrases for Learning Surface Patterns.?
Szpector and Dagan.
2008.
Learning Entailment Rules for UnaryTemplates.?
Ravichandran and Hovy.
2002.
Learning Surface Text Patterns for aQuestion Answering System  .39References (cont?)?
From other resources?
Zhao et al 2010.
Paraphrasing with Search Engine Query Logs.?
Kaji et al 2002.
Verb Paraphrase based on Case Frame Alignment.?
Higashinaka and Nagao.
2002.
Interactive Paraphrasing Based onLinguistic Annotation.C ffee B eak!o r40Outline?
Part 2?Paraphrase Generation?
Rule based Method?
Thesaurus based Method?
NLG based Method?
MT based Method?
Pivot based Method?Applications of Paraphrases?Evaluation of Paraphrases?Conclusions and Future workRule based Method?
Two types:?Based on hand crafted rules  -?
Widely used in early studies of paraphrase generation?
McKeown, 1979; Zong et al, 2001; Tetsuro et al, 2001;Zhang and Yamamoto, 2002??
?Based on automatically extracted rules?
Extract paraphrase patterns from corpora?
Barzilay and Lee 2003 Zhao et al2009  , ,   ., ?
?41Based on Hand-crafted RulesSentence analysis- morphological- syntactic- semantic- ?Rule matching&ParaphrasegenerationS TParaphraserule baseCompileparaphraserules?
Examples of paraphrase rules?
Change the positions of adverbialsBased on Hand-crafted Rules?
He booked a single room in Beijing yesterday.
=>?
Yesterday, he booked a single room in Beijing.?
Split a compound sentence into a group of simple sentences?
He booked a single room in Beijing yesterday =>?
He booked a single room in Beijing.?
He booked a single room yesterday.?
He booked a room.?
Rewrite a sentence using hand-crafted patterns?
Can I have a cup of tea?
=>?
May I have a cup of tea??
I would like a cup of tea, please.?
Give me a cup of tea.42Based on Automatically Extracted Rules?
Studies on paraphrase patterns extraction has beenintroduced above?
Some of them have tried to apply the extractedparaphrase patterns in paraphrase generation?
Complex paraphrase patterns?
Barzilay and Lee, 2003?
E.g.,?
Short and simple paraphrase patterns?
Zhao et al, 2009?
E.g., consider [NN] and take [NN] into considerationPros and Cons?
Methods based on hand-crafted rules?
Pros?
Can design paraphrase rules for specific applications andrequirements?
Cons?
It is time-consuming to construct paraphrase rules?
Problem of rules conflict?
Coverage of paraphrase rules is limited?
Methods based on automatically extracted rulesP?
ros?
Can generate paraphrases with structural changes?
Cons?
Coverage of paraphrase rules is limited43References?
McKeown.
1979.
Paraphrasing Using Given and New Information in aQuestion-Answer System.?
Z t l 2001 A h t S k Chi P h i B dong e  a .
.
pproac  o po en nese arap ras ng ase  onFeature Extraction.?
Tetsuro et al.
2001.
KURA: A Transfer-Based Lexico-StructuralParaphrasing Engine.?
Zhang and Yamamoto.
2002.
Paraphrasing of Chinese Utterances.?
Barzilay and Lee.
2003.
Learning to Paraphrase - An UnsupervisedApproach Using Multiple-Sequence Alignment.?
Zhao et al 2009.
Application-driven Statistic Paraphrase Generation.Outline?
Part 2?Paraphrase Generation?
Rule based Method?
Thesaurus based Method?
NLG based Method?
MT based Method?
Pivot based Method?Applications of Paraphrases?Evaluation of Paraphrases?Conclusions and Future work44Thesaurus based Method?
Also known as lexical substitution?Substitute words in a sentence with their synonymsthat fit in the given context?SemEval-2007: English lexical substitution task?SemEval-2010: Cross-lingual lexical substitution?Example:?
There will be major cuts in the salaries of high level civil        -servants.?
There will be major cuts in the wages of high-level civilservants.Thesaurus based Method?
Include two stages?Stage 1: extract candidate substitutes from-predefined inventories.?
E.g., WordNet?Stage-2: find substitutes that fit in the given context?
Using language model or web data (e.g., Google 5-gram) forevaluating the fitness in the context?
Disambiguation may also be useful45Stage-1: Candidate Extraction?
Various thesauri have been tried?WordNet:?
the most commonly used?Others:?
Encarta, Roget, Oxford American Writer?s Thesaurus??
Extracting different information as candidates?Synsets (all synsets vs. best synset)?Hypernyms, similar-to, also-see?
?Words in glossesExample:WordNetdifferentsynsets46Example:Encartadefinition of the synsetsynsetStage-2: Substitute Selection?
Rank the candidates and select the one fits bestin the given context?
Context constraints?Semantic constraints?
Select substitutes with the correct meaning wrt the givencontext?Syntactic constraints?
The sentence generated after substitution should keepgrammatical47SubFinder: A Lexical Substitution System?
SubFinder?University of North Texas?Performs well in SemEval-2007 English lexicalsubstitution task?
Candidate extraction?WordNet?Encarta?Others?
Prove to be uselessSubFinder: A Lexical Substitution System?
Substitute selection (5 ranking methods R1~R5)?Language model?
Google 1T 5-gram (R1)?
Query search engine (R2)?Latent semantic analysis (LSA) (R3)?
Rank a candidate by its relatedness to the context sentence?Word sense disambiguation (WSD) (R4)?
Disambiguate the target word and select the synset of theright sense?Pivot approach (R5)?
Check whether a candidate substitute can be generated via a2-way translation48SubFinder: A Lexical Substitution System?
Combine R1~R5:?Voting mechanism?Contribution of each ranking method is not analyzed/1( )ii m mm rankings cscore cr?
?= ?Ranks accordingto R1-R5Pros and Cons?
Pros?Based on existing inventories?
Cons?Cannot generate structural paraphrases?Language limitation?
QuestionH t diff t th i??
ow o merge eren  esaur?
Thesauri have different forms of synset clustering49References?
McCarthy and Navigli.
2007.
SemEval-2007 Task 10: English LexicalSubstitution Task.?
H t l 2007 UNT S bFi d C bi i K l d S fassan e  a .
.
: u n er: om n ng now e ge ources orAutomatic Lexical Substitution.?
Yuret.
2007.
KU: Word Sense Disambiguation by Substitution.?
Giuliano et al 2007.
FBK-irst: Lexical Substitution Task Exploiting Domainand Syntagmatic Coherence.?
Martinez et al 2007.
MELB-MKB: Lexical Substitution System based onRelatives in Context.?
Kauchak and Barzilay.
2006.
Paraphrasing for Automatic Evaluation.Outline?
Part 2?Paraphrase Generation?
Rule based Method?
Thesaurus based Method?
NLG based Method?
MT based Method?
Pivot based Method?Applications of Paraphrases?Evaluation of Paraphrases?Conclusions and Future work50Overview?
Two steps?
(1) analysis and (2) generationNLU NLGRs tparaphrasesNLG based Methods?
Kozlowski et al, 2003?Generate single sentence paraphrases -?Input: predicate/argument structure?
Not natural language sentences/?Based on lexico-grammatical resources?
Map elementary semantic structures with syntactic realization51NLG based Methods (cont?)?
Power and Scott, 2005?
Concerning larger-scaleRhetoricalstructure treeparaphrases?
Paraphrases of multiplesentences or even thewhole text?
Paraphrases vary not onlyat lexical and syntacticlevels, but also indocument structure andgeneratorDifferent realizationslayout?
Problem:?
The input is not naturallanguage texts/t1 t2 t3 tnNLG based Methods (cont?)?
Power and Scott, 2005 (cont?
)?Example:reasonNUCLEUS: recommend(doctors, elixir)SATELLITE: conjunction1: quick-results(elixir)2: few-side-effects(elixir)Rhetoricalstructure treeDoctors recommend Elixir since itgives quick results and it has fewside effects.solution1(1) Elixir gives quick results.
(2) Elixir has few side effects.
(3) Therefore, it is recommendedby doctors.solution252NLG based Methods (cont?)?
Fujita et al, 2005?Paraphrase light verb constructions (LVC) in -sentences?
LVC: consists of a light-verb that syntactically governs adeverbal noun?Semantic representation?
LCS: Lexical Conceptual Structure?Procedure?
Semantic analysis?
Semantic transformation?
Surface generationPros and Cons?
Pros?It simulates human being?s behavior when generatingparaphrases:?
Step-1: understand the meaning of a sentence?
Step-2: generate a new sentence expressing the meaning?
Cons?Both deep analysis of sentences and NLG are difficultto realize53References?
Kozlowski et al 2003.
Generation of single-sentence paraphrases frompredicate/argument structure using lexico-grammatical resources.?
P d S tt 2005 A t ti ti f l l hower an  co .
.
u oma c genera on o  arge-sca e parap rases.?
Fujita et al 2005.
Exploiting Lexical Conceptual Structure for ParaphraseGeneration.Outline?
Part 2?Paraphrase Generation?
Rule based Method?
Thesaurus based Method?
NLG based Method?
MT based Method?
Pivot based Method?Applications of Paraphrases?Evaluation of Paraphrases?Conclusions and Future work54Machine Translation vs.
Paraphrase GenerationTranslations tLanguage L1 Language L2ParaphrasingsLanguage L1tFor both machine translation and paraphrase generation:(1) t should preserve the meaning of s(2) t should be a fluent sentenceParaphrase Generation as Machine Translation?
Quirk et al, 2004?First recast paraphrase generation as a monolingualmachine translation taskParaphrasegenerations tA typical MT model(source channel model)PTparaphrase tableFrom comparablenews articles55Paraphrase Generation as Machine Translation(cont?)?
Model?Source channel model* arg max ( | )arg max ( | ) ( )ttt p t sp s t p t==Language model?Translation?
model(based on a phrasalparaphrase table)?
Paraphrase table?Monolingual parallel sentencesParaphrase Generation as Machine Translation(cont?)?
Extracted from comparable news articles?
139K pairs?Word alignment & phrase pair extraction?
With Giza++?
Limitation?Lack of monolingual parallel corpora to train theparaphrase table!!!56?
Zhao et al, 2008?Combine multiple resources to train the paraphraseParaphrase Generation as Machine Translation(cont?
)tableParaphrasegenerations tLog-linear modelPT1Multiple paraphrase tablesPT2 PTn?From various resourcesParaphrase Generation as Machine Translation(cont?)?
Model?Log linear model-_ _1* arg max{ ( , ) ( , )}NTM i TM i LM LMtit h t s h t s?
?== +?N paraphrase tables, each featurecorresponds to a paraphrase tableLanguage model_1( , ) log ( , )iKTM i i k kkh t s score t s== ?57Paraphrase Generation as Machine Translation(cont?)?
Paraphrase tables?
PT1: from word clusters?
Volumes of the PTs:(Lin, 1998)?
PT2: from monolingualparallel corpora?
PT3: from monolingualcomparable corpora?
PT4: from bilingual parallelcorpora?
PT5: from Encartadictionary glosses?
PT6: from clusters ofsimilar user queriesProves most useful!?
Differences between machine translation andparaphrase generation (Zhao et al2009):Paraphrase Generation vs. Machine Translation.,MT has a unique purpose PG has distinct purposes in different applicationsMachine Translation (MT) Paraphrase Generation (PG)In MT, all words in a sentenceh ld b t l t dIn PG, not all words need to beh ds ou  e rans a e parap raseIn MT, the bilingual parallel dataare easy to collectIn PG, multiple resources needto be combinedIn MT, automatic evaluationmetrics (e.g., BLEU) are availableIn PG, automatic evaluationmetrics are not available58Application-driven Statistical ParaphraseGeneration?
Zhao et al, 2009?Propose a statistical model for paraphrase generation?Generate different paraphrases in different applicationsParaphraseplannings tSentencepreprocessingParaphrasegenerationA The given applicationPT1Multiple paraphrase tablesPT2 PTn?Also combinemultiple resourcesSelf-paraphrase PT:allows words tokeep unchanged inparaphrasing?
Paraphrase planning?When an application A is given only the paraphraseApplication-driven Statistical ParaphraseGeneration (cont?
),pairs that can achieve A are keptParaphrase application: sentence compressionThe US government should take the overall situation into consideration and actively promote bilateral high-tech trades.Example:The US governmentThe US administrationThe US government onoverall situationoverall interestoverall pictureoverviewsituation as a wholewhole situation?
?take [NN_1] into considerationconsider [NN_1]take into account [NN_1]take account of [NN_1]take [NN_1] into accounttake into consideration [NN_1]?
?<promote, OBJ, trades><sanction, OBJ, trades><stimulate, OBJ, trades><strengthen, OBJ, trades><support, OBJ, trades><sustain, OBJ, trades>59?
Model:?Log linear modelApplication-driven Statistical ParaphraseGeneration (cont?
)-12 11( | ) ( log ( , ))log ( | )i iiKk k k kk kJlm j j jjp s tp t t t?
??=?
?==+?
?
?t s Paraphrase modelLanguage model1( , )Ium i iis t?
?=+ ?
Usability model(defined for eachapplication)References?
Lin.
1998.
Automatic Retrieval and Clustering of Similar Words.?
Quirk et al 2004.
Monolingual Machine Translation for ParaphraseG tienera on.?
Finch et al 2004.
Paraphrasing as Machine Translation.?
Zhao et al 2008.
Combining Multiple Resources to Improve SMT-basedParaphrasing Model.?
Zhao et al 2009.
Application-driven Statistical Paraphrase Generation.60Outline?
Part 2?Paraphrase Generation?
Rule based Method?
Thesaurus based Method?
NLG based Method?
MT based Method?
Pivot based MethodA li ti f P h?
pp ca ons o  arap rases?Evaluation of Paraphrases?Conclusions and Future workOverview?
Basic idea?We can generate a paraphrase t for a sentence s bytranslating s into  a foreign language, and thentranslating it back into the source language.s t Source languageMT1pMT2Pivot languageMT engines61?
Example:Overview (cont?
)What toxins are most hazardous to expectant mothers?English?
Single-pivotChe tossine sono pi?
pericolose alle donne incinte?ItalianWhat toxins are more dangerous to pregnant women?English?Using a single pivot language?
Multi-pivot?Using multiple pivot languagesPivot based Methods?
Duboue and Chu-Carroll, 2006?Applied in QA systems?
Paraphrase the input questions so as to improve thecoverage in answer extraction?Pivot languages?
11?MT engines?
2: Babelfish (B) and Google MT (G)?
4 combinations: B+B, B+G, G+G, G+B62Pivot based Methods (cont?)?
Duboue and Chu-Carroll, 2006 (cont?
)?Given a list of automatically generated paraphrases      ,we need to select a best one.?
For QA, we need to select the paraphrase that can find theanswer more easily than the original question.Features for paraphrase selection (in a classification framework)SUM IDF The sum of the IDF scores for all terms in the original question and theh ( f h ith i f ti t )parap rase.
pre er parap rases w  more n orma ve ermsLengths Number of query terms for each of the paraphrase and the originalquestion.
(prefer shorter paraphrases)CosineDistanceThe distance between the vectors of both questions, IDF-weighted.
(filter paraphrases that diverge too much from the original)AnswerTypesWhether answer types, as predicted by the question analyzer, are thesame or overlap.
(the answer type should be the same)Pivot based Methods (cont?)?
Max, 2009?Paraphrasing sub sentential fragments -?
Allows the exploitation of context during both source-pivottranslation and pivot-source back-translationcontext constraints contextconstraintsparaphrase63Pivot based Methods (cont?)?
Max, 2009 (cont?)?Application?
Text revision?Pivot language?
English?Paraphrases are acquired for French sub-sentences?MT engine?
S t t SMT (St t l 2007)ource con ex  aware  roppa e  a .,Pivot based Methods (cont?)?
Zhao et al, 20103 MT engines: (1) Googletranslator (GG), (2) Microsofttranslator (MS), (3) Systrantranslator (ST)6 pivot languages: (1)French (F) (2) German (G) ,   ,(3) Spanish (S), (4) Italian (I),(5) Portuguese (P), (6)Chinese (C)54 combinations64Pivot based Methods (cont?)?
Zhao et al, 2010 (cont?
)?Produce a high quality paraphrase using the list of  -candidatesSource he said there will be major cuts in the salaries of high-level civil servants(GG, G, MS) he said there are significant cuts in the salaries of high-level officials(GG, F, GG) he said there will be significant cuts in the salaries of top civil level(GG, P, GG) he said there will be big cuts in salaries of high-level civil(MS, C, MS) he said that there will be a major senior civil service pay cut(MS, S, GG) he said there will be significant cuts in the salaries of senior officials(MS, F, ST) he said there will be great cuts in the wages of the high level civils servant(ST, G, GG) he said that there are major cuts in the salaries of senior government officials??
?
?Good paraphrases Bad paraphrases?
Zhao et al, 2010 (cont?
)?Two techniques for producing high qualityPivot based Methods (cont?
)-paraphrases using the candidates?
Selection-based technique?Select a best paraphrase from the 54 candidates based onMinimum Bayes Risk (MBR)?
Decoding-based technique?Train a MT model using the 54 candidates, and generates ah i h inew parap rase w t  t65References?
Duboue and Chu-Carroll.
2006.
Answering the Question You Wish TheyHad Asked: The Impact of Paraphrasing for Question Answering.?
St t l 2007 E l iti S Si il it f SMT i C t troppa e  a .
.
xp o ng ource m ar y or  us ng on ex -informed Features.?
Max.
2009.
Sub-sentential Paraphrasing by Contextual Pivot Translation.?
Zhao et al 2010.
Leveraging Multiple MT Engines for ParaphraseGeneration.Outline?
Part 2P h G ti?
arap rase enera on?Applications of Paraphrases?
Paraphrasing for MT?
Other Applications?Evaluation of Paraphrases?Conclusions and Future work66Paraphrasing for MT?
Applications:?Translate unknown terms (phrases)?Expand training data?Rewrite input sentences?Improve automatic evaluation?Tune parametersTranslate Unknown Terms (Phrases)?
Basic idea:?In SMT when encountering an unknown source term ,(phrase), we can substitute a paraphrase for it andthen proceed using the translation of that paraphrasef1 -> f1?f2 -> f2?paraphrase tablef1 -> e1f2 -> e2SMT phrase tablenew phrase pair?fi -> fj?fm -> fm?
?fj -> ej?fn -> enunknown phrasefifi -> ej67Translate Unknown Terms (Phrases) (cont?)?
Callison-Burch et al, 2006?Paraphrases are extracted from bilingual parallelcorpora using the pivot approach?New phrase pairs generated through paraphrasingare incorporated into the phrase table?
The paraphrase probability is added as a new featurefunction:paraphrase2 1 11 2( | ) If phrase table entry ( ,  )( , ) is generated from ( ,  )1 Otherwisep f f e fh e f e f?
?= ??
?probabilityTranslate Unknown Terms (Phrases) (cont?)?
Marton et al, 2009?Paraphrases are extracted from monolingual corpora     ,based on distributional hypothesisfUnknown phraseL1__R1L2__R2?contexts paraphrase phrasesf1f2?
?Combine the new phrase pairs in the phrase table1 2 11 2( , ) If phrase table entry ( ,  )( , ) is generated from ( ,  )1 Otherwisef fpsim DP DP e fh e f e f?
?= ???Contextsimilarity68?
Mirkin et al, 2009?Use not only paraphrases but also entailment rulesTranslate Unknown Terms (Phrases) (cont?)?
From WordNet?Paraphrases: synonyms in WordNet?Entailment rules: hypernyms in WordNetparaphrasegenerationparaphraseselectionsgeneratedpara.
list top-k para.SMT ttop-ntran.
translationselectionWordNetsynonymshypernymscontextmodellanguagemodel?
Onishi et al, 2010?Using paraphrase lattices for SMTTranslate Unknown Terms (Phrases) (cont?)?
Step-1: Paraphrase the input sentence, and generate aparaphrase lattice?Paraphrases are extracted from bilingual parallel corpora basedon the pivot approach?
Step-2: Give the paraphrase lattice as the input to the latticedecoder69?
Effectiveness?When the training data of SMT is smallTranslate Unknown Terms (Phrases) (cont?)?
Effective?
?Problem of unknown terms is more serious when the trainingdata is small?When the training data of SMT is large?
Ineffective/?Unknown terms can be covered by adding more training dataExpand Training Data?
Enlarge training data via paraphrasing thesource-side sentences in the parallel corpusOriginal training datae1e2?enf1f2?fnEnglish Foreignexpanded training datae1e2?f1f2?fEnglish Foreigne1?e2??en?paraphrasingene1?e2?
?en?nf1f2?fn70Rewrite Input Sentences?
Paraphrase the sentence to be translated, so asto make it more translatable?Yamamoto, 2002; Zhang and Yamamoto, 2002?
Rule-based Paraphraser for simplifying the source sentences?Shimohata et al, 2004?
Shorten long sentences and sentences with redundantinformation in a speech translation systemImprove Automatic Evaluation?
Automatic evaluation of MT?Based on counting the overlaps between thereferences and machine outputs?
E.g., BLEU, NIST?
?Only computing the surface similarity is limited?
A meaning may be expressed in a way that is not included inthe references?Human references are expensive to produce?Solution: paraphrase the references so as to includeas many correct expressions as possible!71Improve Automatic Evaluation (cont?)?
Kauchak and Barzilay, 2006?Find a paraphrase of the reference that is closer inwording to the system output?
Extract candidates from WordNet synonymsIt is hard to believe that such tremendous changes have taken place for those peopleand lands that I have never stopped missing while living abroad.For someone born here but has been sentimentally attached to a foreign country farCorrect WrongReferenceSystemoutput?Filter the invalid substitution given the context?
Binary classification?Features: context n-grams and local collocationsfrom home, it is difficult to believe this kind of changes.Improve Automatic Evaluation (cont?)?
Zhou et al, 2006?ParaEval: Compute the similarity of reference andsystem output using paraphrases?
Paraphrases are learned from bilingual parallel corpora witha pivot approach?Two-tier matching strategy for SMT evaluation?
First tier: paraphrase match?
Second tier: unigram match for words not matched byparaphrases72Tune Parameters?
Madnani et al 2007?Similar to the studies using paraphrases to improveautomatic evaluation of MT?Parameter tuning in SMT also needs references?
Parameter estimation of SMT:?optimize BLEU on a development set?Expand the references automatically via paraphrasing?
P h tiarap rase genera on?Paraphrase resources are acquired based on a pivot approach?Recast paraphrase generation as a monolingual MT problemand decode with a typical SMT decoderReferences?
Translate unknown terms (phrases)?
Callison-Burch et al 2006.
Improved Statistical Machine TranslationUsing Paraphrases.?
Marton et al 2009.
Improved Statistical Machine Translation UsingMonolingually-Derived Paraphrases.?
Mirkin et al 2009.
Source-Language Entailment Modeling forTranslating Unknown Terms.?
Onishi et al 2010.
Paraphrase Lattice for Statistical MachineTranslation.?
Expand training data?
Nakov.
2008.
Improved Statistical Machine Translation UsingMonolingual Paraphrases.?
Bond et al 2008.
Improving Statistical Machine Translation byParaphrasing the Training Data.73References (cont?)?
Rewrite input sentences?
Yamamoto.
2002.
Machine Translation by Interaction betweenParaphraser and Transfer.?
Zhang and Yamamoto.
2002.
Paraphrasing of Chinese Utterances.?
Shimohata et al 2004.
Building a Paraphrase Corpus for SpeechTranslation.?
Improve automatic evaluation?
Kauchak and Barzilay.
2006.
Paraphrasing for Automatic Evaluation.?
Zhou et al 2006.
Re-evaluating Machine Translation Results withP h S tarap rase uppor .?
Tune parameters?
Madnani et al 2007.
Using Paraphrases for Parameter Tuning inStatistical Machine Translation.Outline?
Part 2P h G ti?
arap rase enera on?Applications of Paraphrases?
Paraphrasing for MT?
Other Applications?Evaluation of Paraphrases?Conclusions and Future work74Paraphrasing for QA?
Goal:?Alleviate the problem of word mismatch betweenquestions and answers?
Two directions:?Paraphrase questions?
Rewrite a question into a group of paraphrases, so as toimprove the coverage in answer extraction?Paraphrase answer extraction patterns?
Generate answer extraction patterns as many as possibleParaphrasing for QA?
Ravichandran and Hovy, 2002.?Mining paraphrase patterns from the web?
Using hand-crafted seeds (e.g., (Mozart, 1756) for BIRTHDAY)?
Mining patterns containing the seedsQuestion taxonomyBIRTHDAY1.00  <NAME> ( <ANSWER> - )0.85  <NAME> was born on <ANSWER>,0.60 <NAME> was born in <ANSWER>scores Paraphrasepatterns0.59  <NAME> was born <ANSWER>0.53  <ANSWER> <NAME> was born0.50  ?
<NAME> ( <ANSWER>0.36  <NAME> ( <ANSWER> -Given seed (Mozart, 1756)75Paraphrasing for Summarization?
Improve automatic evaluation of summaries?Zhou et al2006  .,?Similar to the automatic evaluation of MT?
Measure the similarity between references and systemoutputs using paraphrase match as well as exact match?
Improve sentence clustering?Barzilay et al, 1999?Considering paraphrase match when Computingsentence similarityOther Applications?
Paraphrasing for NLG?Text revision and transformation?
Dras, 1997?Text transformation in order to meet external constraints, suchas length and readability?
Paraphrasing for IR?Query rewriting?
Z k d R k tti 2002u erman an  as u .
.
?Paraphrase user queries with WordNet synonyms76Other Applications (cont?)?
Writing style transformation?Kaji et al2004  .,?
Paraphrasing predicates from written language to spokenlanguage?
Text simplification?Carroll et al 1999?
Simplifying texts for language-impaired readers or non-nativekspea ers?
Identify plagiarism?Uzuner et al 2005?
Using paraphrases to better identify plagiarismReferences?
Paraphrasing for QA?
Ravichandran and Hovy.
2002.
Learning Surface Text Patterns for aQuestion Answering System.?
Duboue and Chu-Carroll.
2006.
Answering the Question You Wish TheyHad Asked: The Impact of Paraphrasing for Question Answering.?
Paraphrasing for summarization?
Barzilay et al 1999.
Information Fusion in the Context of Multi-Document Summarization.?
Zhou et al 2006.
ParaEval: Using Paraphrases to Evaluate SummariesAutomatically.?
Paraphrasing for NLG?
Dras.
1997.
Reluctant Paraphrase: Textual Restructuring under anOptimisation Model.77References (cont?)?
Paraphrasing for IR?
Zukerman and Raskutti.
2002.
Lexical Query Paraphrasing forDocument Retrieval.?
Writing style transformation?
Kaji et al 2004.
Paraphrasing Predicates from Written Language toSpoken Language Using the Web.?
Text simplification?
Carroll et al 1999.
Simplifying Text for Language-Impaired Readers.?
Identify plagiarism?
Uzuner et al 2005.
Using Syntactic Information to Identify Plagiarism.Outline?
Part 2P h G ti?
arap rase enera on?Applications of Paraphrases?
Paraphrasing for MT?
Other Applications?Evaluation of Paraphrases?Conclusions and Future work78Evaluation of Paraphrases?
No widely accepted evaluation criteria/?Problem 1: Researchers define various evaluation-methods in their studies?
Difficult to make a direct comparison among different works?Problem-2: Human evaluation is commonly used?
Human evaluation is rather subjective?
Difficult to replicateEvaluation of Paraphrase Identification?
Human evaluation?
A tomatic e al ationu  v u?Brockett and Dolan, 2005?Alignment Error Rate (AER)?
AER is indicative of how far the corpus is from providing asolution under a standard SMT tool| | | |A P A S?
+ ?| |AERA S= +AutomaticalignmentPOSSIBLE + SUREalignment in the goldstandardSURE alignment inthe gold standard79Evaluation of Lexical Substitution?
Automatic evaluation?McCarthy and Navigli 2007  ,?Construction of gold standard data?
Five annotators, who are native speakers?
For each test word, each annotator provides up to threesubstitutes?Evaluation:?
Precision and RecallEvaluation of Paraphrase Phrases?
Human evaluation?Ask judges:?
Whether paraphrases were approximately conceptualequivalent?
Whether the paraphrases were roughly interchangeablegiven the genre?
Whether the substitutions preserved the meaning andremained grammatical?
??
?The criteria above are vaguely defined and not easyto reproduce80Evaluation of Paraphrase Phrases (cont?)?
Automatic evaluation?Callison Burch et al2008-   .,?Data:?
Parallel sentences, in which paraphrases are annotatedthrough manual alignment (gold standard)?Two fashions of evaluation?
Calculate how well an automatic paraphrasing technique canalign the paraphrases in a sentence pair?
Calculate the lower-bound precision and relative recall ofa paraphrasing technique (which extracts paraphrases fromother resources)Evaluation of ParaphrasePhrases (cont?)?
Alignment precision and recall ?
Lower-bound precision andrelative recallManual alignment1 21 2Pr1 2 1 2,1 2,| ( , , ) ( , , ) || ( , , ) |ece e Ce e CAlignPP e e S PP e e MPP e e S< >?< >?=??
?System alignmentR 1,Pr| ( , ) ( , , ) || ( , ) |MET EFs G C p s METLB ecisionpara p s para p s Gpara p s< >?
??
=??
?Paraphrase acquired witha method METParaphrase in the goldstandard set1 21 2Re1 2 1 2,1 2,| ( , , ) ( , , ) || ( , , ) |calle e Ce e CAlignPP e e S PP e e MPP e e M< >?< >?=???
R 1, 1Re Re| ( , ) ( , , ) || ( , , ) |MET EFs G C p s REFl callpara p s para p s Gpara p s G< >?
??
=??
?81Evaluation of Paraphrase Patterns?
Human evaluation?Paraphrase patterns cannot be evaluated withoutcontext information?
E.g., X acquire Y, X buy Y?Correct or not?
It depends on what fill in slots X and Y?
Common view:?A pair of paraphrase patterns is considered correct if the judgecould think of contexts under which it holds?
Problem:?Different judges may think of totally distinct contexts, thus theagreement among the judges could be lowEvaluation of Paraphrase Patterns (cont?)?
Szpektor et al, 2007?Evaluate paraphrase patterns (and entailment rules)with instances rather than directly evaluate patterns?
Judges are presented not only with a pair of patterns, butalso a sample of sentences that match its left-hand side?
Judges assess whether two patterns are paraphrases undereach specific example?
A pair of paraphrase patterns is considered as correct onlywhen the percentage of correct examples is high enough82Evaluation of Paraphrase Generation?
Human evaluation?Similar to human evaluation of SMT?Criteria (Zhao et al, 2009, 2010)?
Adequacy: If the meaning of the source sentence ispreserved in the paraphrase??
Fluency: if the generated paraphrase is well-formed??
Usability (Zhao et al, 2009): If the paraphrase meets therequirement of the given application??
Paraphrase rate (Zhao et al, 2009): How different theparaphrase is from the source sentence?Evaluation of Paraphrase Generation (cont?)?
Three scales for adequacy, fluency, and usability (Zhaoet al, 2009)Adequacy1 The meaning is evidently changed.2 The meaning is generally preserved.3 The meaning is completely preserved.Fluency1 The paraphrase t is incomprehensible.2 t is comprehensible.3 t is a flawless sentence.1 t is opposite to the application p rpose?
Five scales for adequacy and fluency (Zhao et al, 2010)Usabilityu .2 t does not achieve the application.3 t achieves the application.83Evaluation of Paraphrase Generation (cont?)?
Paraphrase rate (Zhao et al, 2010):?PR 1: based on word overlap rate-?PR-2: based on edit distance( , )1( ) 1( )OL S TPR TL S= ?
Word overlap rateNumber of wordsin the source sen.( , )2( )( )ED S TPR TL S= Edit distanceEvaluation of Paraphrase Generation (cont?)?
Two questions:?Q1: Why not adopt automatic MT methods here e g      , .
.,BLEU, NIST, TER???
Reason-1: It is much more difficult to construct humanreferences in paraphrase generation than MT?
Reason-2: Paraphrases that change less will get largerscores in criteria like BLEU?Q2: How to combine the evaluation of paraphrasequality and paraphrase rate??
They seem to be incompatible84Evaluation within Applications?
Evaluate the role of a paraphrasing module withina certain application system?E.g., in MT, examine whether a paraphrasing modulehelps to alleviate the unknown term problem?E.g., in QA, whether paraphrasing the answer patternscan improve the coverage of answer extraction?
Problems:?Whether the result can hold for a different application?
?How to evaluate the role of the paraphrase moduleindependently (not influenced by other modules)?References?
Brockett and Dolan.
2005.
Support Vector Machines for ParaphraseIdentification.?
S kt t l 2007 I t b d E l ti f E t il t R lzpe or e  a .
.
ns ance- ase  va ua on o  n a men  u eAcquisition.?
McCarthy and Navigli.
2007.
SemEval-2007 Task 10: English LexicalSubstitution Task.?
Callison-Burch et al 2008.
ParaMetric: An Automatic Evaluation Metric forParaphrasing.?
Zhao et al 2009.
Application-driven Statistical Paraphrase Generation.?
Zhao et al 2010.
Leveraging Multiple MT Engines for ParaphraseGeneration.85Outline?
Part 2P h G ti?
arap rase enera on?Applications of Paraphrases?
Paraphrasing for MT?
Other Applications?Evaluation of Paraphrases?Conclusions and Future workConclusions and Future Work?
Conclusions?Paraphrasing is important in various research areas?Many different kinds of corpora and data resourceshave been investigated for paraphrase extraction?Paraphrase generation is a task similar to MT, but notthe same?Paraphrase evaluation is problematic.
Automaticevaluation methods are in need86Conclusions and Future Work (cont?)?
Future work?Paraphrase extraction?
Improve the quality of the extracted paraphrases?Paraphrase generation?
Application-driven paraphrase generation?Paraphrase application?
Apply paraphrasing techniques in commercial NLP systems,rather than merely in labs?Paraphrase evaluation?
Come up with evaluation methods that can be widelyacceptedThanks!QA87
