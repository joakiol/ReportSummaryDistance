Proceedings of the ACL 2010 System Demonstrations, pages 13?18,Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational LinguisticsBEETLE II: a system for tutoring and computational linguisticsexperimentationMyroslava O. Dzikovska and Johanna D. MooreSchool of Informatics, University of Edinburgh, Edinburgh, United Kingdom{m.dzikovska,j.moore}@ed.ac.ukNatalie Steinhauser and Gwendolyn CampbellNaval Air Warfare Center Training Systems Division, Orlando, FL, USA{gwendolyn.campbell,natalie.steihauser}@navy.milElaine FarrowHeriot-Watt UniversityEdinburgh, United Kingdome.farrow@hw.ac.ukCharles B. CallawayUniversity of HaifaMount Carmel, Haifa, Israelccallawa@gmail.comAbstractWe present BEETLE II, a tutorial dia-logue system designed to accept unre-stricted language input and support exper-imentation with different tutorial planningand dialogue strategies.
Our first systemevaluation used two different tutorial poli-cies and demonstrated that the system canbe successfully used to study the impactof different approaches to tutoring.
In thefuture, the system can also be used to ex-periment with a variety of natural languageinterpretation and generation techniques.1 IntroductionOver the last decade there has been a lot of inter-est in developing tutorial dialogue systems that un-derstand student explanations (Jordan et al, 2006;Graesser et al, 1999; Aleven et al, 2001; Buckleyand Wolska, 2007; Nielsen et al, 2008; VanLehnet al, 2007), because high percentages of self-explanation and student contentful talk are knownto be correlated with better learning in human-human tutoring (Chi et al, 1994; Litman et al,2009; Purandare and Litman, 2008; Steinhauser etal., 2007).
However, most existing systems usepre-authored tutor responses for addressing stu-dent errors.
The advantage of this approach is thattutors can devise remediation dialogues that arehighly tailored to specific misconceptions manystudents share, providing step-by-step scaffoldingand potentially suggesting additional problems.The disadvantage is a lack of adaptivity and gen-erality: students often get the same remediationfor the same error regardless of their past perfor-mance or dialogue context, as it is infeasible toauthor a different remediation dialogue for everypossible dialogue state.
It also becomes more dif-ficult to experiment with different tutorial policieswithin the system due to the inherent completixitesin applying tutoring strategies consistently acrossa large number of individual hand-authored reme-diations.The BEETLE II system architecture is designedto overcome these limitations (Callaway et al,2007).
It uses a deep parser and generator, to-gether with a domain reasoner and a diagnoser,to produce detailed analyses of student utterancesand generate feedback automatically.
This allowsthe system to consistently apply the same tutorialpolicy across a range of questions.
To some extent,this comes at the expense of being able to addressindividual student misconceptions.
However, thesystem?s modular setup and extensibility make ita suitable testbed for both computational linguis-tics algorithms and more general questions abouttheories of learning.A distinguishing feature of the system is that itis based on an introductory electricity and elec-tronics course developed by experienced instruc-tional designers.
The course was first created foruse in a human-human tutoring study, without tak-ing into account possible limitations of computertutoring.
The exercises were then transferred intoa computer system with only minor adjustments(e.g., breaking down compound questions into in-dividual questions).
This resulted in a realistic tu-toring setup, which presents interesting challengesto language processing components, involving awide variety of language phenomena.We demonstrate a version of the system thathas undergone a successful user evaluation in132009.
The evaluation results indicate that addi-tional improvements to remediation strategies, andespecially to strategies dealing with interpretationproblems, are necessary for effective tutoring.
Atthe same time, the successful large-scale evalua-tion shows that BEETLE II can be used as a plat-form for future experimentation.The rest of this paper discusses the BEETLE IIsystem architecture (Section 2), system evaluation(Section 3), and the range of computational lin-guistics problems that can be investigated usingBEETLE II (Section 4).2 System ArchitectureThe BEETLE II system delivers basic electricityand electronics tutoring to students with no priorknowledge of the subject.
A screenshot of the sys-tem is shown in Figure 1.
The student interface in-cludes an area to display reading material, a circuitsimulator, and a dialogue history window.
All in-teractions with the system are typed.
Students readpre-authored curriculum slides and carry out exer-cises which involve experimenting with the circuitsimulator and explaining the observed behavior.The system also asks some high-level questions,such as ?What is voltage?
?.The system architecture is shown in Figure 2.The system uses a standard interpretation pipeline,with domain-independent parsing and generationcomponents supported by domain specific reason-ers for decision making.
The architecture is dis-cussed in detail in the rest of this section.2.1 Interpretation ComponentsWe use the TRIPS dialogue parser (Allen et al,2007) to parse the utterances.
The parser providesa domain-independent semantic representation in-cluding high-level word senses and semantic rolelabels.
The contextual interpreter then uses a refer-ence resolution approach similar to Byron (2002),and an ontology mapping mechanism (Dzikovskaet al, 2008a) to produce a domain-specific seman-tic representation of the student?s output.
Utter-ance content is represented as a set of extractedobjects and relations between them.
Negation issupported, together with a heuristic scoping algo-rithm.
The interpreter also performs basic ellipsisresolution.
For example, it can determine that inthe answer to the question ?Which bulbs will beon and which bulbs will be off in this diagram??,?off?
can be taken to mean ?all bulbs in the di-agram will be off.?
The resulting output is thenpassed on to the domain reasoning and diagnosiscomponents.2.2 Domain Reasoning and DiagnosisThe system uses a knowledge base implemented inthe KM representation language (Clark and Porter,1999; Dzikovska et al, 2006) to represent the stateof the world.
At present, the knowledge base rep-resents 14 object types and supports the curricu-lum containing over 200 questions and 40 differ-ent circuits.Student explanations are checked on two levels,verifying factual and explanation correctness.
Forexample, for a question ?Why is bulb A lit?
?, ifthe student says ?it is in a closed path?, the systemchecks two things: a) is the bulb indeed in a closedpath?
and b) is being in a closed path a reason-able explanation for the bulb being lit?
Differentremediation strategies need to be used dependingon whether the student made a factual error (i.e.,they misread the diagram and the bulb is not in aclosed path) or produced an incorrect explanation(i.e., the bulb is indeed in a closed path, but theyfailed to mention that a battery needs to be in thesame closed path for the bulb to light).The knowledge base is used to check the fac-tual correctness of the answers first, and then a di-agnoser checks the explanation correctness.
Thediagnoser, based on Dzikovska et al (2008b), out-puts a diagnosis which consists of lists of correct,contradictory and non-mentioned objects and re-lations from the student?s answer.
At present, thesystem uses a heuristic matching algorithm to clas-sify relations into the appropriate category, thoughin the future we may consider a classifier similarto Nielsen et al (2008).2.3 Tutorial PlannerThe tutorial planner implements a set of generictutoring strategies, as well as a policy to choosean appropriate strategy at each point of the inter-action.
It is designed so that different policies canbe defined for the system.
The currently imple-mented strategies are: acknowledging the correctpart of the answer; suggesting a slide to read withbackground material; prompting for missing partsof the answer; hinting (low- and high- specificity);and giving away the answer.
Two or more strate-gies can be used together if necessary.The hint selection mechanism generates hintsautomatically.
For a low specificity hint it selects14Figure 1: Screenshot of the BEETLE II systemDialogue ManagerParserContextualInterpreterInterpretationCurriculumPlannerKnowledgeBaseContent Planner & GeneratorTutorialPlannerTutoringGUIDiagnoserFigure 2: System architecture diagram15an as-yet unmentioned object and hints at it, forexample, ?Here?s a hint: Your answer should men-tion a battery.?
For high-specificity, it attempts tohint at a two-place relation, for example, ?Here?sa hint: the battery is connected to something.
?The tutorial policy makes a high-level decisionas to which strategy to use (for example, ?ac-knowledge the correct part and give a high speci-ficity hint?)
based on the answer analysis and di-alogue context.
At present, the system takes intoconsideration the number of incorrect answers re-ceived in response to the current question and thenumber of uninterpretable answers.1In addition to a remediation policy, the tuto-rial planner implements an error recovery policy(Dzikovska et al, 2009).
Since the system ac-cepts unrestricted input, interpretation errors areunavoidable.
Our recovery policy is modeled onthe TargetedHelp (Hockey et al, 2003) policy usedin task-oriented dialogue.
If the system cannotfind an interpretation for an utterance, it attemptsto produce a message that describes the problembut without giving away the answer, for example,?I?m sorry, I?m having a problem understanding.
Idon?t know the word power.?
The help message isaccompanied with a hint at the appropriate level,also depending on the number of previous incor-rect and non-interpretable answers.2.4 GenerationThe strategy decision made by the tutorial plan-ner, together with relevant semantic content fromthe student?s answer (e.g., part of the answer toconfirm), is passed to content planning and gen-eration.
The system uses a domain-specific con-tent planner to produce input to the surface realizerbased on the strategy decision, and a FUF/SURGE(Elhadad and Robin, 1992) generation system toproduce the appropriate text.
Templates are usedto generate some stock phrases such as ?When youare ready, go on to the next slide.
?2.5 Dialogue ManagementInteraction between components is coordinated bythe dialogue manager which uses the information-state approach (Larsson and Traum, 2000).
Thedialogue state is represented by a cumulative an-swer analysis which tracks, over multiple turns,the correct, incorrect, and not-yet-mentioned parts1Other factors such as student confidence could be con-sidered as well (Callaway et al, 2007).of the answer.
Once the complete answer has beenaccumulated, the system accepts it and moves on.Tutor hints can contribute parts of the answer tothe cumulative state as well, allowing the systemto jointly construct the solution with the student.3 EvaluationThe first experimental evaluation involving 81 par-ticipants (undergraduates recruited from a South-eastern University in the USA) was completed in2009.
Participants had little or no prior knowledgeof the domain.
Each participant took a pre-test,worked through a lesson with the system, took apost-test, and completed a user satisfaction survey.Each session lasted approximately 4 hours.We implemented two different tutoring policiesin the system for this evaluation.
The baselinepolicy used an ?accept and bottom out?
strategyfor all student answers, regardless of their con-tent.
The students were always given the correctanswer, but the system made no attempt at reme-diation, and never indicated whether the studentwas understood (or correct).
In comparison, thefull adaptive policy attempted to select an appro-priate strategy based on student answer analysisand dialogue context, as described above.
Stu-dents were randomly assigned to a condition.
Onaverage, each student session contained 232 stu-dent language turns in the fully adaptive condition(SD = 25.6) and 156 turns in the baseline condi-tion (SD = 2.02).
Additional time was taken byreading and interacting with the simulation envi-ronment.Out of 81 students, 76 successfully completedthe evaluation (data from 5 participants had to bediscarded due to system crashes).
There was nosignificant difference in learning gain between thetwo conditions (baseline: M = 0.63, SD = 0.26,full: M = 0.57, SD = 0.23, t-test p = 0.32),and students gave higher satisfaction scores to thebaseline condition (baseline: M = 3.32, SD =0.65, full: M = 2.56, SD = 0.65, t-test, p <0.01).
We are currently analyzing the data to in-vestigate the reasons for this outcome.
However,the evaluation demonstrated that the system can besuccessfully deployed in experiments with naiveusers and therefore can be used to study the im-pact of different natural language processing algo-rithms on learning gain and user satisfaction.An example dialogue with the system, takenfrom the evaluation corpus, is shown in Figure 3.16Tutor: Why was bulb A on when switch Ywas open and switch Z was closed?Student: because it had a closed pathTutor: Right.
There is a closed path.
Keepgoing.Student: there was a closed path not effected bythe switchTutor: I?m sorry, I?m having a problem un-derstanding.
I don?t understand theword ?effect?
here.
Here?s a hint.
Youranswer should mention a battery.Student: it has a closed path with the batteryTutor: You?re on the right track.
Here?s theanswer.
Bulb A is still contained in aclosed path with the battery.Figure 3: Example interaction with the systemfrom our corpusIt shows three key system properties: after the stu-dent?s first turn, the system rephrases its under-standing of the correct part of the student answerand prompts the student to supply the missing in-formation.
In the second turn, the student utter-ance could not be interpreted and the system re-sponds with a targeted help message and a hintabout the object that needs to be mentioned.
Fi-nally, in the last turn the system combines the in-formation from the tutor?s hint and the student?sanswers and restates the complete answer since thecurrent answer was completed over multiple turns.4 Conclusions and Future WorkThe BEETLE II system we present was built toserve as a platform for research in computationallinguistics and tutoring, and can be used for task-based evaluation of algorithms developed for otherdomains.
We are currently developing an annota-tion scheme for the data we collected to identifystudent paraphrases of correct answers.
The an-notated data will be used to evaluate the accuracyof existing paraphrasing and textual entailment ap-proaches and to investigate how to combine suchalgorithms with the current deep linguistic analy-sis to improve system robustness.
We also planto annotate the data we collected for evidence ofmisunderstandings, i.e., situations where the sys-tem arrived at an incorrect interpretation of a stu-dent utterance and took action on it.
Such annota-tion can provide useful input for statistical learn-ing algorithms to detect and recover from misun-derstandings.In dialogue management and generation, thekey issue we are planning to investigate is that oflinguistic alignment.
The analysis of the data wehave collected indicates that student satisfactionmay be affected if the system rephrases studentanswers using different words (for example, usingbetter terminology) but doesn?t explicitly explainthe reason why different terminology is needed(Dzikovska et al, 2010).
Results from other sys-tems show that measures of semantic coherencebetween a student and a system were positively as-sociated with higher learning gain (Ward and Lit-man, 2006).
Using a deep generator to automati-cally generate system feedback gives us a level ofcontrol over the output and will allow us to deviseexperiments to study those issues in more detail.From the point of view of tutoring research,we are planning to use the system to answerquestions about the effectiveness of different ap-proaches to tutoring, and the differences betweenhuman-human and human-computer tutoring.
Pre-vious comparisons of human-human and human-computer dialogue were limited to systems thatasked short-answer questions (Litman et al, 2006;Rose?
and Torrey, 2005).
Having a system that al-lows more unrestricted language input will pro-vide a more balanced comparison.
We are alsoplanning experiments that will allow us to eval-uate the effectiveness of individual strategies im-plemented in the system by comparing system ver-sions using different tutoring policies.AcknowledgmentsThis work has been supported in part by US Officeof Naval Research grants N000140810043 andN0001410WX20278.
We thank Katherine Harri-son and Leanne Taylor for their help running theevaluation.ReferencesV.
Aleven, O. Popescu, and K. R. Koedinger.
2001.Towards tutorial dialog to support self-explanation:Adding natural language understanding to a cogni-tive tutor.
In Proceedings of the 10th InternationalConference on Artificial Intelligence in Education(AIED ?01)?.James Allen, Myroslava Dzikovska, Mehdi Manshadi,and Mary Swift.
2007.
Deep linguistic processingfor spoken dialogue systems.
In Proceedings of theACL-07 Workshop on Deep Linguistic Processing.17Mark Buckley and Magdalena Wolska.
2007.
To-wards modelling and using common ground in tu-torial dialogue.
In Proceedings of DECALOG, the2007 Workshop on the Semantics and Pragmatics ofDialogue, pages 41?48.Donna K. Byron.
2002.
Resolving Pronominal Refer-ence to Abstract Entities.
Ph.D. thesis, University ofRochester.Charles B. Callaway, Myroslava Dzikovska, ElaineFarrow, Manuel Marques-Pita, Colin Matheson, andJohanna D. Moore.
2007.
The Beetle and BeeD-iff tutoring systems.
In Proceedings of SLaTE?07(Speech and Language Technology in Education).Michelene T. H. Chi, Nicholas de Leeuw, Mei-HungChiu, and Christian LaVancher.
1994.
Elicitingself-explanations improves understanding.
Cogni-tive Science, 18(3):439?477.Peter Clark and Bruce Porter, 1999.
KM (1.4): UsersManual.
http://www.cs.utexas.edu/users/mfkb/km.Myroslava O. Dzikovska, Charles B. Callaway, andElaine Farrow.
2006.
Interpretation and generationin a knowledge-based tutorial system.
In Proceed-ings of EACL-06 workshop on knowledge and rea-soning for language processing, Trento, Italy, April.Myroslava O. Dzikovska, James F. Allen, and Mary D.Swift.
2008a.
Linking semantic and knowledgerepresentations in a multi-domain dialogue system.Journal of Logic and Computation, 18(3):405?430.Myroslava O. Dzikovska, Gwendolyn E. Campbell,Charles B. Callaway, Natalie B. Steinhauser, ElaineFarrow, Johanna D. Moore, Leslie A. Butler, andColin Matheson.
2008b.
Diagnosing natural lan-guage answers to support adaptive tutoring.
InProceedings 21st International FLAIRS Conference,Coconut Grove, Florida, May.Myroslava O. Dzikovska, Charles B. Callaway, ElaineFarrow, Johanna D. Moore, Natalie B. Steinhauser,and Gwendolyn C. Campbell.
2009.
Dealing withinterpretation errors in tutorial dialogue.
In Pro-ceedings of SIGDIAL-09, London, UK, Sep.Myroslava O. Dzikovska, Johanna D. Moore, NatalieSteinhauser, and Gwendolyn Campbell.
2010.
Theimpact of interpretation problems on tutorial dia-logue.
In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics(ACL-2010).Michael Elhadad and Jacques Robin.
1992.
Control-ling content realization with functional unificationgrammars.
In R. Dale, E. Hovy, D. Ro?sner, andO.
Stock, editors, Proceedings of the Sixth Interna-tional Workshop on Natural Language Generation,pages 89?104, Berlin, April.
Springer-Verlag.A.
C. Graesser, P. Wiemer-Hastings, P. Wiemer-Hastings, and R. Kreuz.
1999.
Autotutor: A simula-tion of a human tutor.
Cognitive Systems Research,1:35?51.Beth Ann Hockey, Oliver Lemon, Ellen Campana,Laura Hiatt, Gregory Aist, James Hieronymus,Alexander Gruenstein, and John Dowding.
2003.Targeted help for spoken dialogue systems: intelli-gent feedback improves naive users?
performance.In Proceedings of the tenth conference on Europeanchapter of the Association for Computational Lin-guistics, pages 147?154, Morristown, NJ, USA.Pamela Jordan, Maxim Makatchev, Umarani Pap-puswamy, Kurt VanLehn, and Patricia Albacete.2006.
A natural language tutorial dialogue systemfor physics.
In Proceedings of the 19th InternationalFLAIRS conference.Staffan Larsson and David Traum.
2000.
Informationstate and dialogue management in the TRINDI Dia-logue Move Engine Toolkit.
Natural Language En-gineering, 6(3-4):323?340.Diane Litman, Carolyn P.
Rose?, Kate Forbes-Riley,Kurt VanLehn, Dumisizwe Bhembe, and Scott Sil-liman.
2006.
Spoken versus typed human and com-puter dialogue tutoring.
International Journal of Ar-tificial Intelligence in Education, 16:145?170.Diane Litman, Johanna Moore, Myroslava Dzikovska,and Elaine Farrow.
2009.
Generalizing tutorial dia-logue results.
In Proceedings of 14th InternationalConference on Artificial Intelligence in Education(AIED), Brighton, UK, July.Rodney D. Nielsen, Wayne Ward, and James H. Mar-tin.
2008.
Learning to assess low-level conceptualunderstanding.
In Proceedings 21st InternationalFLAIRS Conference, Coconut Grove, Florida, May.Amruta Purandare and Diane Litman.
2008.
Content-learning correlations in spoken tutoring dialogs atword, turn and discourse levels.
In Proceedings 21stInternational FLAIRS Conference, Coconut Grove,Florida, May.C.P.
Rose?
and C. Torrey.
2005.
Interactivity versus ex-pectation: Eliciting learning oriented behavior withtutorial dialogue systems.
In Proceedings of Inter-act?05.N.
B. Steinhauser, L. A. Butler, and G. E. Campbell.2007.
Simulated tutors in immersive learning envi-ronments: Empirically-derived design principles.
InProceedings of the 2007 Interservice/Industry Train-ing, Simulation and Education Conference, Orlando,FL.Kurt VanLehn, Pamela Jordan, and Diane Litman.2007.
Developing pedagogically effective tutorialdialogue tactics: Experiments and a testbed.
In Pro-ceedings of SLaTE Workshop on Speech and Lan-guage Technology in Education, Farmington, PA,October.Arthur Ward and Diane Litman.
2006.
Cohesion andlearning in a tutorial spoken dialog system.
In Pro-ceedings of 19th International FLAIRS (Florida Ar-tificial Intelligence Research Society) Conference,Melbourne Beach, FL.18
