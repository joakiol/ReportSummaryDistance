Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 636?641,Dublin, Ireland, August 23-24, 2014.The Impact of Z_score on Twitter Sentiment AnalysisHussam Hamdan*,**,****LSISAix-Marseille Universit?
CNRSAv.
Esc.
Normandie Niemen,13397 Marseille Cedex 20,Francehussam.hamdan@lsis.orgPatrice Bellot*,****OpenEditionAix-Marseille Universit?
CNRS3 pl.
V. Hugo, case n?8613331 Marseille Cedex 3,Francepatrice.bellot@lsis.orgFrederic B?chet******LIFAix-Marseille Universit?
CNRSAvenue de Luminy13288 Marseille Cedex 9,Francefrederic.bechet@lif.univ-mrs.frAbstractTwitter has become more and more an im-portant resource of user-generated data.
Sen-timent Analysis in Twitter is interesting formany applications and objectives.
In this pa-per, we propose to exploit some featureswhich can be useful for this task; the maincontribution is the use of Z-scores as featuresfor sentiment classification in addition topre-polarity and POS tags features.
Our ex-periments have been evaluated using the testdata provided by SemEval 2013 and 2014.The evaluation demonstrates that Z_scoresfeatures can significantly improve the predic-tion performance.1 IntroductionThe interactive Web has changed the relationbetween the users and the web.
Users have be-come an important source of content.
They ex-press their opinion towards different issues.
The-se opinions are important for others who are in-terested in understanding users?
interests such asbuyers, sellers and producers.Twitter is one of the most important platforms inwhich the users express their opinions.
Manyworks have exploited this media for predictingvaluable issues depending on Sentiment Analysis(SA).
The authors in (Asur and Huberman 2010)predicted the box-office revenues of movies inadvance of their releases using the tweets talkingabout them.
In (Bae and Lee 2012) SentimentThis work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbersand proceedings footer are added by the organisers.Licence details:http://creativecommons.org/licenses/by/4.0/Analysis has been used to study the impact of 13twitter accounts of famous persons on their fol-lowers and also for forecasting the interestingtweets which are more probably to be repostedby the followers (Naveed, Gottron et al.
2011).Sentiment Analysis can be done in different lev-els; Document level; Sentence level; Clause levelor Aspect-Based level.
SA in Twitter can be seenas a sentence level task, but some limitationsshould be considered in such sentences.
The sizeof tweets is limited to 140 characters, informallanguage, emotion icons and non-standard ex-pressions are commonly used, and many spellingerrors can be found due to the absence of cor-rectness verification.Three different approaches can be identified inthe literature of Sentiment Analysis in Twitter,the first approach is lexicon based, using specifictypes of lexicons to derive the polarity of a text,this approach suffers from the limited size of lex-icon and requires human expertise to build man-ual lexicon (Joshi, Balamurali et al.
2011), in theother hand the automatic lexicons are not so effi-cient.
The second one is machine learning ap-proach which uses annotated texts with a givenlabels to learn a classification model, an earlywork was done on a movie review dataset (Pang,Lee et al.
2002).
Both lexicon and machine learn-ing approaches can be combined to achieve abetter performance (Khuc, Shivade et al.
2012).These two approaches are used for SA task butthe third one is specific for Twitter or social con-tent, the social approach exploits social networkproperties and data for enhancing the accuracy ofthe classification (Speriosu, Sudan et al.
2011).In this paper, we exploit machine learning al-gorithm with the aid of some features:?
The original Terms: the terms represent-ing the tweet after the tokenization andstemming;636?
Pre-polarity features: the number of neg-ative, positive and neutral words extract-ed from two sentiment lexicons;?
POS tags: the number of adjectives, con-nectors, verbs, nouns, adverbs in thetweet;?
Z-score: The numbers of terms having Z-score value more than three for eachclass positive, negative and neutral.We extended the original terms with these lastfeatures.
We also constructed a dictionary for theabbreviations and the slang words used in Twit-ter in order to overcome the ambiguity of thetweets.
We tested the performance of every pos-sible combination of these features.The rest of this paper is organized as follows.Section 2 outlines previous work that focused onsentiment analysis in Twitter.
Section 3 presentsthe Z_score features and the others which weused for training a classifier.
Our experiments aredescribed in section 4, conclusion and futurework is presented in section 5.2 Related WorksWe can identify three main approaches for sen-timent analysis in Twitter.
The lexicon basedapproaches which depend on sentiment lexiconscontaining positive, negative and neutral wordsor expressions; they calculate the polarity ac-cording to the number of common opinionatedwords between the lexicons and the text.
Manydictionaries have been created manually such asANEW (Affective Norms for English Words) orautomatically such as SentiWordNet(Baccianella, Esuli et al.
2010).
Four lexicon dic-tionaries were used to overcome the lack ofwords in each one (Joshi, Balamurali et al.
2011;Mukherjee, Malu et al.
2012).
Automaticallyconstruction of a Twitter lexicon was imple-mented by (Khuc, Shivade et al.
2012).Machine learning approaches were employedfrom annotated tweets by using Naive Bayes,Maximum Entropy MaxEnt and Support VectorMachines (SVM).
The authors (Go, Bhayani etal.
2009) reported that SVM outperforms otherclassifiers.
They tried a unigram and a bigrammodel in conjunction with parts-of-speech (POS)features; they noted that the unigram model out-performs all other models when using SVM andthat POS features decrease the quality of results.The authors in (Kouloumpis, Wilson et al.
2011)found that N-gram with lexicon features and mi-cro-blogging features are useful but POS featuresare not.
In contrast, in (Pak and Paroubek 2010)they reported that POS and bigrams both help.
In(Barbosa and Feng 2010) the authors proposedthe use of syntax features of tweets like retweet,hashtags, link, punctuation and exclamationmarks in conjunction with features like prior po-larity of words and POS tags, in (Agarwal, Xie etal.
2011) this approach was extended by usingreal valued prior polarity and by combining priorpolarity with POS.
Authors in (Saif, He et al.2012) proposed to use the semantic features,therefore they extracted the named entities in thetweets.
Authors in (Hamdan, B?chet et al.
2013)used the concepts extracted from DBpedia andthe adjectives from WordNet, they reported thatthe DBpedia concepts are useful with Na?ve-Bayes classifier but less useful with SVM.The third main approach takes into accountthe influence of users on their followers and therelation between the users and the tweets theywrote.
It assumes that using the Twitter followergraph might improve the polarity classification.In (Speriosu, Sudan et al.
2011) they demonstrat-ed that using label propagation with Twitter fol-lower graph improves the polarity classification.In  (Tan, Lee et al.
2011) they employed socialrelation for user-level sentiment analysis.
In (Hu,Tang et al.
2013) a Sociological Approach tohandling the Noisy and short Text (SANT) forsupervised sentiment classification is used; theyreported that social theories such as SentimentConsistency and Emotional Contagion could behelpful for sentiment analysis.3 Feature SelectionWe used different types of features in order toimprove the accuracy of sentiment classification.- Bag of words (Terms)The most commonly used features in text analy-sis are the bag of words which represent a text asunordered set of words or terms.
It assumes thatwords are independent from each other and alsodisregards their order of appearance.
Westemmed the words using Porter Stemmer andused them as a baseline features.- Z_score Features (Z)We suggest using a new type of features for Sen-timent Analysis, Z_score can distinguish the im-portance of each term in each class.
We computethe number of terms having Z_score more thanthree for each class over each tweet.
We assumethat the term frequencies follow the multinomialdistribution.
Thus, Z_score can be seen as astandardization of the term.
We compute the637Z_score for each term ti in a class Cj (tij) by cal-culating its term relative frequency tfrij in a par-ticular class Cj, as well as the mean (meani)which is the term probability over the whole cor-pus multiplied by nj the number of terms in theclass Cj, and standard deviation (sdi) of term tiaccording to the underlying corpus (see Eq.(1,2)).Z??????????
=??????????????
Eq.
(1)Z??????????
=??????????(??)?????(??)?(???(??))
Eq.
(2)The term which has salient frequency in a classin compassion to others will have a salientZ_score.
Z_score was exploited for SA by(Zubaryeva and Savoy  2010) , they choose athreshold (>2) for selecting the number of termshaving Z_score more than the threshold, thenthey used a logistic regression for combiningthese scores.
We use Z_scores as added featuresfor classification because the tweet is too short,therefore many tweets does not have any wordswith salient Z_score.
The three following figures1,2,3 show the distribution of Z_score over eachclass, we remark that the majority of terms hasZ_score between -1.5 and 2.5 in each class andthe rest are either vey frequent (>2.5) or very rare(<-1.5).
It should indicate that negative valuemeans that the term is not frequent in this class incomparison with its frequencies in other classes.Table1 demonstrates the first ten terms havingthe highest Z_scores in each class.
We have test-ed to use different values for the threshold, thebest results was obtained when the threshold is 3.positiveZ_scorenegativeZ_scoreNeutralZ_scoreLoveGoodHappyGreatExciteBestThankHopeCantWait14.3114.0112.3011.1010.359.249.218.248.108.05NotFuckDon?tShitBadHateSadSorryCancelstupid13.9912.9710.978.998.408.298.288.117.536.83HttpbitHttpfbHttpbndInternNovHttpdlvrOpenLiveCloudbegin6.444.563.783.583.453.403.303.283.283.17Table1.
The first ten terms having the highest Z_score ineach class-  Sentiment Lexicon Features (POL)We used two sentiment lexicons, MPQA Subjec-tivity Lexicon(Wilson, Wiebe et al.
2005) andBing Liu's Opinion Lexicon which is created by(Hu and Liu 2004) and augmented in many latterworks.
We extract the number of positive, nega-tive and neutral words in tweets according to the-se lexicons.
Bing Liu's lexicon only containsnegative and positive annotation but Subjectivitycontains negative, positive and neutral.- Part Of Speech (POS)We annotate each word in the tweet by its POStag, and then we compute the number of adjec-tives, verbs, nouns, adverbs and connectors ineach tweet.4 Evaluation4.1 Data collectionWe used the data set provided in SemEval 2013and 2014 for subtask B of sentiment analysis inTwitter(Rosenthal, Ritter et al.
2014) (Wilson,Kozareva et al.
2013).
The participants wereprovided with training tweets annotated as posi-tive, negative or neutral.
We downloaded thesetweets using a given script.
Among 9646 tweets,we could only download 8498 of them becauseof protected profiles and deleted tweets.
Then,we used the development set containing 1654tweets for evaluating our methods.
We combinedthe development set with training set and built anew model which predicted the labels of the testset 2013 and 2014.4.2 ExperimentsOfficial ResultsThe results of our system submitted forSemEval evaluation gave 46.38%, 52.02% fortest set 2013 and 2014 respectively.
It shouldmention that these results are not correct becauseof a software bug discovered after the submis-sion deadline, therefore the correct results isdemonstrated as non-official results.
In fact theprevious results are the output of our classifierwhich is trained by all the features in section 3,but because of index shifting error the test setwas represented by all the features except theterms.Non-official ResultsWe have done various experiments using thefeatures presented in Section 3 with MultinomialNa?ve-Bayes model.
We firstly constructed fea-ture vector of tweet terms which gave 49%, 46%for test set 2013, 2014 respectively.
Then, weaugmented this original vector by the Z_score638features which improve the performance by 6.5%and 10.9%, then by pre-polarity features whichalso improve the f-measure by 4%, 6%, but theextending with POS tags decreases the f-measure.
We also test all combinations with the-se previous features, Table2 demonstrates theresults of each combination, we remark that POStags are not useful over all the experiments, thebest result is obtained by combining Z_score andpre-polarity features.
We find that Z_score fea-tures improve significantly the f-measure andthey are better than pre-polarity features.Figure 1 Z_score distribution in positive classFigure 2 Z_score distribution in neutral classFigure 3 Z_score distribution in negative classFeatures F-measure2013 2014Terms 49.42 46.31Terms+Z 55.90 57.28Terms+POS 43.45 41.14Terms+POL 53.53 52.73Terms+Z+POS 52.59 54.43Terms+Z+POL 58.34 59.38Terms+POS+POL 48.42 50.03Terms+Z+POS+POL 55.35 58.58Table 2.
Average f-measures for positive and negative clas-ses of SemEval2013 and 2014 test sets.We repeated all previous experiments after usinga twitter dictionary where we extend the tweet bythe expressions related to each emotion icons orabbreviations in tweets.
The results in Table3demonstrate that using that dictionary improvesthe f-measure over all the experiments, the bestresults obtained also by combining Z_scores andpre-polarity features.Features F-measure2013 2014Terms 50.15 48.56Terms+Z 57.17 58.37Terms+POS 44.07 42.64Terms+POL 54.72 54.53Terms+Z+POS 53.20 56.47Terms+Z+POL 59.66 61.07Terms+POS+POL 48.97 51.90Terms+Z+POS+POL 55.83 60.22Table 3.
Average f-measures for positive and negative clas-ses of SemEval2013 and 2014 test sets after using a twitterdictionary.5 ConclusionIn this paper we tested the impact of usingTwitter Dictionary, Sentiment Lexicons, Z_scorefeatures and POS tags for the sentiment classifi-cation of tweets.
We extended the feature vectorof tweets by all these features; we have proposednew type of features Z_score and demonstratedthat they can improve the performance.We think that Z_score can be used in differentways for improving the Sentiment Analysis, weare going to test it in another type of corpus andusing other methods in order to combine thesefeatures.ReferenceApoorv Agarwal,Boyi Xie,Ilia Vovsha,OwenRambow and Rebecca Passonneau (2011).Sentiment analysis of Twitter data.Proceedings of the Workshop on Languages639in Social Media.
Portland, Oregon,Association for Computational Linguistics:30-38.Sitaram Asur and Bernardo A. Huberman (2010).Predicting the Future with Social Media.Proceedings of the 2010 IEEE/WIC/ACMInternational Conference on WebIntelligence and Intelligent AgentTechnology - Volume 01, IEEE ComputerSociety: 492-499.Stefano Baccianella,Andrea Esuli and FabrizioSebastiani (2010).
SentiWordNet 3.0: AnEnhanced Lexical Resource for SentimentAnalysis and Opinion Mining.
Proceedingsof the Seventh Conference on InternationalLanguage Resources and Evaluation(LREC'10), European Language ResourcesAssociation (ELRA).Younggue Bae and Hongchul Lee (2012).
"Sentimentanalysis of twitter audiences: Measuring thepositive or negative influence of populartwitterers."
J.
Am.
Soc.
Inf.
Sci.
Technol.63(12): 2521-2535.Luciano Barbosa and Junlan Feng (2010).
Robustsentiment detection on Twitter from biasedand noisy data.
Proceedings of the 23rdInternational Conference on ComputationalLinguistics: Posters.
Beijing, China,Association for Computational Linguistics:36-44.Alec Go,Richa Bhayani and Lei Huang TwitterSentiment Classification using DistantSupervision.Hussam Hamdan,Frederic B?chet and Patrice Bellot(2013).
Experiments with DBpedia,WordNet and SentiWordNet as resources forsentiment analysis in micro-blogging.Proceedings of the Seventh InternationalWorkshop on Semantic Evaluation (SemEval2013), Atlanta, Georgia, USA.Minqing Hu and Bing Liu (2004).
Mining andsummarizing customer reviews.
Proceedingsof the tenth ACM SIGKDD internationalconference on Knowledge discovery anddata mining.
Seattle, WA, USA, ACM: 168-177.Xia Hu,Lei Tang,Jiliang Tang and Huan Liu (2013).Exploiting social relations for sentimentanalysis in microblogging.
Proceedings ofthe sixth ACM international conference onWeb search and data mining.
Rome, Italy,ACM: 537-546.Aditya Joshi,A.
R. Balamurali,Pushpak Bhattacharyyaand Rajat Mohanty (2011).
C-Feel-It: asentiment analyzer for micro-blogs.Proceedings of the 49th Annual Meeting ofthe Association for ComputationalLinguistics: Human Language Technologies:Systems Demonstrations.
Portland, Oregon,Association for Computational Linguistics:127-132.Vinh Ngoc Khuc,Chaitanya Shivade,Rajiv Ramnathand Jay Ramanathan (2012).
Towardsbuilding large-scale distributed systems fortwitter sentiment analysis.
Proceedings of the27th Annual ACM Symposium on AppliedComputing.
Trento, Italy, ACM: 459-464.E.
Kouloumpis,T.
Wilson and J. Moore (2011).Twitter Sentiment Analysis: The Good theBad and the OMG!
Fifth International AAAIConference on Weblogs and Social Media.Subhabrata Mukherjee,Akshat Malu,Balamurali A.R.and Pushpak Bhattacharyya (2012).
TwiSent:a multistage system for analyzing sentimentin twitter.
Proceedings of the 21st ACMinternational conference on Information andknowledge management.
Maui, Hawaii,USA, ACM: 2531-2534.Nasir Naveed,Thomas Gottron,J\'Er\^Ome Kunegisand Arifah Che Alhadi (2011).
Bad NewsTravels Fast: A Content-based Analysis ofInterestingness on Twitter.
Proc.
WebScience Conf.Alexander Pak and Patrick Paroubek (2010).
Twitteras a Corpus for Sentiment Analysis andOpinion Mining.
Proceedings of the Seventhconference on International LanguageResources and Evaluation (LREC'10),Valletta, Malta, European LanguageResources Association (ELRA).Bo Pang,Lillian Lee and Shivakumar Vaithyanathan(2002).
Thumbs up?
: sentiment classificationusing machine learning techniques.Proceedings of the ACL-02 conference onEmpirical methods in natural languageprocessing - Volume 10, Association forComputational Linguistics: 79-86.Sara Rosenthal,Alan Ritter,Veselin Stoyanov andPreslav Nakov (2014).
"SemEval-2014 Task9: Sentiment Analysis in Twitter."
InProceedings of the Eighth InternationalWorkshop on Semantic Evaluation(SemEval'14).August 23-24, Dublin, Ireland.Hassan Saif,Yulan He and Harith Alani (2012).Semantic sentiment analysis of twitter.Proceedings of the 11th internationalconference on The Semantic Web - VolumePart I. Boston, MA, Springer-Verlag: 508-524.Michael Speriosu,Nikita Sudan,Sid Upadhyay andJason Baldridge (2011).
Twitter polarityclassification with label propagation overlexical links and the follower graph.Proceedings of the First Workshop onUnsupervised Learning in NLP.
Edinburgh,Scotland, Association for ComputationalLinguistics: 53-63.Chenhao Tan,Lillian Lee,Jie Tang,Long Jiang,MingZhou and Ping Li (2011).
User-level640sentiment analysis incorporating socialnetworks.
Proceedings of the 17th ACMSIGKDD international conference onKnowledge discovery and data mining.
SanDiego, California, USA, ACM: 1397-1405.Theresa Wilson,Zornitsa Kozareva,PreslavNakov,Alan Ritter,Sara Rosenthal andVeselin Stoyanov (2013).
"SemEval-2013Task 2: Sentiment Analysis in Twitter.
"Proceedings of the 7th InternationalWorkshop on Semantic Evaluation.Association for Computational Linguistics.Theresa Wilson,Janyce Wiebe and Paul Hoffmann(2005).
Recognizing contextual polarity inphrase-level sentiment analysis.
Proceedingsof the conference on Human LanguageTechnology and Empirical Methods inNatural Language Processing.
Vancouver,British Columbia, Canada, Association forComputational Linguistics: 347-354.Olena Zubaryeva and Jacques Savoy (2010).
"OpinionDetection by Combining Machine Learning& Linguistic Tools."
In Proceedings of the8th NTCIR, Workshop Meeting onEvaluation of Information AccessTechnologies: InformationRetrieval,Question Answering and Cross-LingualInformation Access.641
