Proceedings of the ACL 2010 Conference Short Papers, pages 263?268,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsUsing Anaphora Resolution to ImproveOpinion Target Identification in Movie ReviewsNiklas JakobTechnische Universita?t DarmstadtHochschulstra?e 10, 64289 DarmstadtIryna GurevychTechnische Universita?t DarmstadtHochschulstra?e 10, 64289 Darmstadthttp://www.ukp.tu-darmstadt.de/peopleAbstractCurrent work on automatic opinion min-ing has ignored opinion targets expressedby anaphorical pronouns, thereby missinga significant number of opinion targets.
Inthis paper we empirically evaluate whetherusing an off-the-shelf anaphora resolutionalgorithm can improve the performance ofa baseline opinion mining system.
Wepresent an analysis based on two differentanaphora resolution systems.
Our exper-iments on a movie review corpus demon-strate, that an unsupervised anaphora reso-lution algorithm significantly improves theopinion target extraction.
We furthermoresuggest domain and task specific exten-sions to an off-the-shelf algorithm whichin turn yield significant improvements.1 IntroductionOver the last years the task of opinion mining(OM) has been the topic of many publications.It has been approached with different goals inmind: Some research strived to perform subjec-tivity analysis at the document or sentence level,without focusing on what the individual opinionsuttered in the document are about.
Other ap-proaches focused on extracting individual opinionwords or phrases and what they are about.
Thisaboutness has been referred to as the opinion tar-get or opinion topic in the literature from the field.In this work our goal is to extract opinion target- opinion word pairs from sentences from moviereviews.
A challenge which is frequently encoun-tered in text mining tasks at this level of gran-ularity is, that entities are being referred to byanaphora.
In the task of OM, it can therefore alsobe necessary to analyze more than the content ofone individual sentence when extracting opiniontargets.
Consider this example sentence: ?Simplyput, it?s unfathomable that this movie cracks theTop 250.
It is absolutely awful.?.
If one wants toextract what the opinion in the second sentence isabout, an algorithm which resolves the anaphoricreference to the opinion target is required.The extraction of such anaphoric opinion targetshas been noted as an open issue multiple timesin the OM context (Zhuang et al, 2006; Hu andLiu, 2004; Nasukawa and Yi, 2003).
It is not amarginal phenomenon, since Kessler and Nicolov(2009) report that in their data, 14% of the opin-ion targets are pronouns.
However, the task of re-solving anaphora to mine opinion targets has notbeen addressed and evaluated yet to the best of ourknowledge.In this work, we investigate whether anaphora res-olution (AR) can be successfully integrated intoan OM algorithm and whether we can achieve animprovement regarding the OM in doing so.
Thispaper is structured as follows: Section 2 discussesthe related work on opinion target identificationand OM on movie reviews.
Section 3 outlines theOM algorithm we employed by us, while in Sec-tion 4 we discuss two different algorithms for ARwhich we experiment with.
Finally, in Section 5we present our experimental work including erroranalysis and discussion, and we conclude in Sec-tion 6.2 Related WorkWe split the description of the related work in twoparts: In Section 2.1 we discuss the related workon OM with a focus on approaches for opiniontarget identification.
In Section 2.2 we elaborateon findings from related OM research which alsoworked with movie reviews as this is our targetdomain in the present paper.2.1 Opinion Target IdentificationThe extraction of opinions and especially opin-ion targets has been performed with quite diverse263approaches.
Initial approaches combined statisti-cal information and basic linguistic features suchas part-of-speech tags.
The goal was to identifythe opinion targets, here in form of products andtheir attributes, without a pre-built knowledge basewhich models the domain.
For the target candidateidentification, simple part-of-speech patterns wereemployed.
The relevance ranking and extractionwas then performed with different statistical mea-sures: Pointwise Mutual Information (Popescuand Etzioni, 2005), the Likelihood Ratio Test (Yiet al, 2003) and Association Mining (Hu and Liu,2004).
A more linguistically motivated approachwas taken by Kim and Hovy (2006) through iden-tifying opinion holders and targets with semanticrole labeling.
This approach was promising, sincetheir goal was to extract opinions from profession-ally edited content i.e.
newswire.Zhuang et al (2006) present an algorithm for theextraction of opinion target - opinion word pairs.The opinion word and target candidates are iden-tified in the annotated corpus and their extractionis then performed by applying possible paths con-necting them in a dependency graph.
These pathsare combined with part-of-speech information andalso learned from the annotated corpus.To the best of our knowledge, there is currentlyonly one system which integrates coreference in-formation in OM.
The algorithm by Stoyanovand Cardie (2008) identifies coreferring targets innewspaper articles.
A candidate selection or ex-traction step for the opinion targets is not required,since they rely on manually annotated targets andfocus solely on the coreference resolution.
How-ever they do not resolve pronominal anaphora inorder to achieve that.2.2 Opinion Mining on Movie ReviewsThere is a huge body of work on OM in movie re-views which was sparked by the dataset from Pangand Lee (2005).
This dataset consists of sen-tences which are annotated as expressing positiveor negative opinions.
An interesting insight wasgained from the document level sentiment analy-sis on movie reviews in comparison to documentsfrom other domains: Turney (2002) observes thatthe movie reviews are hardest to classify since thereview authors tend to give information about thestoryline of the movie which often contain charac-terizations, such as ?bad guy?
or ?violent scene?.These statements however do not reflect any opin-ions of the reviewers regarding the movie.
Zhuanget al (2006) also observe that movie reviews aredifferent from e.g.
customer reviews on Ama-zon.com.
This is reflected in their experiments, inwhich their system outperforms the system by Huand Liu (2004) which attributes an opinion tar-get to the opinion word which is closest regard-ing word distance in a sentence.
The sentences inthe movie reviews tend to be more complex, whichcan also be explained by their origin.
The reviewswere taken from the Internet Movie Database1,on which the users are given a set of guidelineson how to write a review.
Due to these insights,we are confident that the overall textual qualityof the movie reviews is high enough for linguisti-cally more advanced technologies such as parsingor AR to be successfully applied.3 Opinion Target Identification3.1 DatasetCurrently the only freely available dataset anno-tated with opinions including annotated anaphoricopinion targets is a corpus of movie reviewsby Zhuang et al (2006).
Kessler and Nicolov(2009) describe a collection of product reviewsin which anaphoric opinion targets are also an-notated, but it is not available to the public(yet).
Zhuang et al (2006) used a subset of thedataset they published (1829 documents), namely1100 documents, however they do not state whichdocuments comprise this subset used in their eval-uation.
In our experiments, we therefore use thecomplete dataset available, detailed in Table 1.
Asshown, roughly 9.5% of the opinion targets are re-ferred to by pronouns.
Table 2 outlines detailedstatistics on which pronouns occur as opinion tar-gets.Table 1: Dataset Statistics# Documents 1829# Sentences 24918# Tokens 273715# Target + Opinion Pairs 5298# Targets which are Pronouns 504# Pronouns > 110003.2 Baseline Opinion MiningWe reimplemented the algorithm presentedby Zhuang et al (2006) as the baseline for our1http://www.imdb.com (IMDB)264Table 2: Pronouns as Opinion Targetsit 274 he 58 she 22 they 22this 77 his 26 her 10him 15experiments.
Their approach is a supervised one.The annotated dataset is split in five folds, ofwhich four are used as the training data.
In the firststep, opinion target and opinion word candidatesare extracted from the training data.
Frequencycounts of the annotated opinion targets and opin-ion words are extracted from four training folds.The most frequently occurring opinion targets andopinion words are selected as candidates.
Thenthe annotated sentences are parsed and a graphcontaining the words of the sentence is created,which are connected by the dependency relationsbetween them.
For each opinion target - opinionword pair, the shortest path connecting them isextracted from the dependency graph.
A pathconsists of the part-of-speech tags of the nodesand the dependency types of the edges.In order to be able to identify rarely occurringopinion targets which are not in the candidatelist, they expand it by crawling the cast and crewnames of the movies from the IMDB.
How thiscrawling and extraction is done is not explained.4 Algorithms for Anaphora ResolutionAs pointed out by Charniak and Elsner (2009)there are hardly any freely available systemsfor AR.
Although Charniak and Elsner (2009)present a machine-learning based algorithm forAR, they evaluate its performance in comparisonto three non machine-learning based algorithms,since those are the only ones available.
Theyobserve that the best performing baseline algo-rithm (OpenNLP) is hardly documented.
The al-gorithm with the next-to-highest results in (Char-niak and Elsner, 2009) is MARS (Mitkov, 1998)from the GuiTAR (Poesio and Kabadjov, 2004)toolkit.
This algorithm is based on statistical anal-ysis of the antecedent candidates.
Another promis-ing algorithm for AR employs a rule based ap-proach for antecedent identification.
The Cog-NIAC algorithm (Baldwin, 1997) was designedfor high-precision AR.
This approach seems likean adequate strategy for our OM task, since inthe dataset used in our experiments only a smallfraction of the total number of pronouns are ac-tual opinion targets (see Table 1).
We extended theCogNIAC implementation to also resolve ?it?
and?this?
as anaphora candidates, since off-the-shelfit only resolves personal pronouns.
We will referto this extension with [id].
Both algorithms fol-low the common approach that noun phrases areantecedent candidates for the anaphora.
In our ex-periments we employed both the MARS and theCogNIAC algorithm, for which we created threeextensions which are detailed in the following.4.1 Extensions of CogNIACWe identified a few typical sources of errors ina preliminary error analysis.
We therefore sug-gest three extensions to the algorithm which areon the one hand possible in the OM setting andon the other hand represent special features of thetarget discourse type: [1.]
We observed that theStanford Named Entity Recognizer (Finkel et al,2005) is superior to the Person detection of the(MUC6 trained) CogNIAC implementation.
Wetherefore filter out Person antecedent candidateswhich the Stanford NER detects for the imper-sonal and demonstrative pronouns and Location& Organization candidates for the personal pro-nouns.
This way the input to the AR is optimized.[2.]
The second extension exploits the fact that re-views from the IMDB exhibit certain contextualproperties.
They are gathered and to be presentedin the context of one particular entity (=movie).The context or topic under which it occurs is there-fore typically clear to the reader and is thereforenot explicitly introduced in the discourse.
This isequivalent to the situational context we often referto in dialogue.
In the reviews, the authors oftenrefer to the movie or film as a whole by a pro-noun.
We exploit this by an additional rule whichresolves an impersonal or demonstrative pronounto ?movie?
or ?film?
if there is no other (match-ing) antecedent candidate in the previous two sen-tences.
[3.]
The rules by which CogNIAC resolvesanaphora were designed so that anaphora whichhave ambiguous antecedents are left unresolved.This strategy should lead to a high precision AR,but at the same time it can have a negative impacton the recall.
In the OM context, it happens quitefrequently that the authors comment on the entitythey want to criticize in a series of arguments.
Insuch argument chains, we try to solve cases of an-tecedent ambiguity by analyzing the opinions: Ifthere are ambiguous antecedent candidates for a265pronoun, we check whether there is an opinion ut-tered in the previous sentence.
If this is the caseand if the opinion target matches the pronoun re-garding gender and number, we resolve the pro-noun to the antecedent which was the previousopinion target.In the results of our experiments in Section 5, wewill refer to the configurations using these exten-sions with the numbers attributed to them above.5 Experimental WorkTo integrate AR in the OM algorithm, we add theantecedents of the pronouns annotated as opiniontargets to the target candidate list.
Then we ex-tract the dependency paths connecting pronounsand opinion words and add them to the list of validpaths.
When we run the algorithm, we extractanaphora which were resolved, if they occur witha valid dependency path to an opinion word.
Insuch a case, the anaphor is substituted for its an-tecedent and thus extracted as part of an opiniontarget - opinion word pair.To reproduce the system by Zhuang et al (2006),we substitute the cast and crew list employedby them (see Section 3.2), with a NER compo-nent (Finkel et al, 2005).
One aspect regarding theextraction of opinion target - opinion word pairsremains open in Zhuang et al (2006): The de-pendency paths only identify connections betweenpairs of single words.
However, almost 50% ofthe opinion target candidates are multiword ex-pressions.
Zhuang et al (2006) do not explain howthey extract multiword opinion targets with the de-pendency paths.
In our experiments, we require adependency path to be found to each word of amultiword target candidate for it to be extracted.Furthermore, Zhuang et al (2006) do not statewhether in their evaluation annotated multiwordtargets are treated as a single unit which needs tobe extracted, or whether a partial matching is em-ployed in such cases.
We require all individualwords of a multiword expression to be extractedby the algorithm.
As mentioned above, the depen-dency path based approach will only identify con-nections between pairs of single words.
We there-fore employ a merging step, in which we combineadjacent opinion targets to a multiword expres-sion.
We have compiled two result sets: Table 3shows the results of the overall OM in a five-foldcross-validation.
Table 4 gives a detailed overviewof the AR for opinion target identification summedup over all folds.
In Table 4, a true positive refersto an extracted pronoun which was annotated asan opinion target and is resolved to the correctantecedent.
A false positive subsumes two errorclasses: A pronoun which was not annotated as anopinion target but extracted as such, or a pronounwhich is resolved to an incorrect antecedent.As shown in Table 3, the recall of our reimplemen-tation is slightly higher than the recall reportedin Zhuang et al (2006).
However, our precisionand thus f-measure are lower.
This can be at-tributed to the different document sets used in ourexperiments (see Section 3.1), or our substitutionof the list of peoples?
names with the NER compo-nent, or differences regarding the evaluation strat-egy as mentioned above.We observe that the MARS algorithm yields animprovement regarding recall compared to thebaseline system.
However, it also extracts a highnumber of false positives for both the personal andimpersonal / demonstrative pronouns.
This is dueto the fact that the MARS algorithm is designedfor robustness and always resolves a pronoun toan antecedent.CogNIAC in its off-the-shelf configuration alreadyyields significant improvements over the baselineregarding f-measure2.
Our CogNIAC extension[id] improves recall slightly in comparison to theoff-the-shelf system.
As shown in Table 4, thealgorithm extracts impersonal and demonstrativepronouns with lower precision than personal pro-nouns.
Our error analysis shows that this is mostlydue to the Person / Location / Organization clas-sification of the CogNIAC implementation.
Thenames of actors and movies are thus often misclas-sified.
Extension [1] mitigates this problem, sinceit increases precision (Table 3 row 6), while not af-fecting recall.
The overall improvement of our ex-tensions [id] + [1] is however not statistically sig-nificant in comparison to off-the-shelf CogNIAC.Our extensions [2] and [3] in combination with[id] each increase recall at the expense of preci-sion.
The improvement in f-measure of CogNIAC[id] + [3] over the off-the-shelf system is statisti-cally significant.
The best overall results regard-ing f-measure are reached if we combine all ourextensions of the CogNIAC algorithm.
The re-sults of this configuration show that the positiveeffects of extensions [2] and [3] are complemen-2Significance of improvements was tested using a pairedtwo-tailed t-test and p ?
0.05 (?)
and p ?
0.01 (??
)266Table 3: Op.
Target - Op.
Word Pair ExtractionConfiguration Reca.
Prec.
F-Meas.Results in Zhuang et al 0.548 0.654 0.596Our Reimplementation 0.554 0.523 0.538MARS off-the-shelf 0.595 0.467 0.523CogNIAC off-the-shelf 0.586 0.534 0.559?
?CogNIAC+[id] 0.594 0.516 0.552CogNIAC+[id]+[1] 0.594 0.533 0.561CogNIAC+[id]+[2] 0.603 0.501 0.547CogNIAC+[id]+[3] 0.613 0.521 0.563?CogNIAC+[id]+[1]+[2]+[3] 0.614 0.531 0.569?Table 4: Results of AR for Opinion TargetsAlgorithm Pers.1 Imp.
& Dem.1TP2 FP2 TP FPMARS off-the-shelf 102 164 115 623CogNIAC off-the-shelf 117 95 0 0CogNIAC+[id] 117 95 105 180CogNIAC+[id]+[1] 117 41 105 51CogNIAC+[id]+[2] 117 95 153 410CogNIAC+[id]+[3] 131 103 182 206CogNIAC+[id]+[1]+[2]+[3] 124 64 194 1321 personal, impersonal & demonstrative pronouns2 true positives, false positivestary regarding the extraction of impersonal anddemonstrative pronouns.
This configuration yieldsstatistically significant improvements regarding f-measure over the off-the-shelf CogNIAC configu-ration, while also having the overall highest recall.5.1 Error AnalysisWhen extracting opinions from movie reviews, weobserve the same challenge as Turney (2002): Theusers often characterize events in the storyline orroles the characters play.
These characterizationscontain the same words which are also used toexpress opinions.
Hence these combinations arefrequently but falsely extracted as opinion target- opinion word pairs, negatively affecting theprecision.
The algorithm cannot distinguish themfrom opinions expressing the stance of the author.Overall, the recall of the baseline is rather low.This is due to the fact that the algorithm onlylearns a subset of the opinion words and opiniontargets annotated in the training data.
Currently,it cannot discover any new opinion words andtargets.
This could be addressed by integrating acomponent which identifies new opinion targetsby calculating the relevance of a word in thecorpus based on statistical measures.The AR introduces new sources of errors regard-ing the extraction of opinion targets: Errors ingender and number identification can lead to anincorrect selection of antecedent candidates.
Evenif the gender and number identification is correct,the algorithm might select an incorrect antecedentif there is more than one possible candidate.
Anon-robust algorithm as CogNIAC might leavea pronoun which is an actual opinion targetunresolved, due to the ambiguity of its antecedentcandidates.The upper bound for the OM with perfect ARon top of the baseline would be recall: 0.649,precision: 0.562, f-measure: 0.602.
Our bestconfiguration reaches?
50% of the improvementswhich are theoretically possible with perfect AR.6 ConclusionsWe have shown that by extending an OM al-gorithm with AR for opinion target extractionsignificant improvements can be achieved.
Therule based AR algorithm CogNIAC performs wellregarding the extraction of opinion targets whichare personal pronouns.
The algorithm does notyield high precision when resolving impersonaland demonstrative pronouns.
We present a setof extensions which address this challenge andin combination yield significant improvementsover the off-the-shelf configuration.
A robustAR algorithm does not yield any improvementsregarding f-measure in the OM task.
This type ofalgorithm creates many false positives, which arenot filtered out by the dependency paths employedin the algorithm by Zhuang et al (2006).AR could also be employed in other OM algo-rithms which aim at identifying opinion targetsby means of a statistical analysis.
Vicedo andFerra?ndez (2000) successfully modified therelevance ranking of terms in their documents byreplacing anaphora with their antecedents.
Theapproach can be taken for OM algorithms whichselect the opinion target candidates with a rel-evance ranking (Hu and Liu, 2004; Yi et al, 2003).AcknowledgmentsThe project was funded by means of the German FederalMinistry of Economy and Technology under the promotionalreference ?01MQ07012?.
The authors take the responsibilityfor the contents.
This work has been supported by the Volk-swagen Foundation as part of the Lichtenberg-ProfessorshipProgram under grant No.
I/82806.267ReferencesBreck Baldwin.
1997.
Cogniac: High precision coref-erence with limited knowledge and linguistic re-sources.
In Proceedings of a Workshop on Opera-tional Factors in Practical, Robust Anaphora Reso-lution for Unrestricted Texts, pages 38?45, Madrid,Spain, July.Eugene Charniak and Micha Elsner.
2009.
EM worksfor pronoun anaphora resolution.
In Proceedings ofthe 12th Conference of the European Chapter of theACL, pages 148?156, Athens, Greece, March.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informa-tion into information extraction systems by gibbssampling.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguis-tics, pages 363?370, Michigan, USA, June.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the 10thACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, pages 168?177,Seattle, WA, USA, August.Jason Kessler and Nicolas Nicolov.
2009.
Targetingsentiment expressions through supervised rankingof linguistic configurations.
In Proceedings of theThird International AAAI Conference on Weblogsand Social Media, San Jose, CA, USA, May.Soo-Min Kim and Eduard Hovy.
2006.
Extractingopinions, opinion holders, and topics expressed inonline news media text.
In Proceedings of the ACLWorkshop on Sentiment and Subjectivity in Text,pages 1?8, Sydney, Australia, July.Ruslan Mitkov.
1998.
Robust pronoun resolution withlimited knowledge.
In Proceedings of the 36th An-nual Meeting of the Association for ComputationalLinguistics and 17th International Conference onComputational Linguistics, pages 869?875, Mon-treal, Canada, August.Tetsuya Nasukawa and Jeonghee Yi.
2003.
Sentimentanalysis: Capturing favorability using natural lan-guage processing.
In Proceedings of the 2nd Inter-national Conference on Knowledge Capture, pages70?77, Sanibel Island, FL, USA, October.Bo Pang and Lillian Lee.
2005.
Seeing stars: Ex-ploiting class relationships for sentiment categoriza-tion with respect to rating scales.
In Proceedingsof the 43rd Annual Meeting of the Association forComputational Linguistics, pages 115?124, Michi-gan, USA, June.Massimo Poesio and Mijail A. Kabadjov.
2004.
Ageneral-purpose, off-the-shelf anaphora resolutionmodule: Implementation and preliminary evalua-tion.
In Proceedings of the 4th International Confer-ence on Language Resources and Evaluation, pages663?666, Lisboa, Portugal, May.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinions from reviews.
InProceedings of Human Language Technology Con-ference and Conference on Empirical Methods inNatural Language Processing, pages 339?346, Van-couver, Canada, October.Veselin Stoyanov and Claire Cardie.
2008.
Topic iden-tification for fine-grained opinion analysis.
In Pro-ceedings of the 22nd International Conference onComputational Linguistics, pages 817?824, Manch-ester, UK, August.Peter Turney.
2002.
Thumbs up or thumbs down?
se-mantic orientation applied to unsupervised classifi-cation of reviews.
In Proceedings of the 40th An-nual Meeting of the Association for ComputationalLinguistics, pages 417?424, Philadelphia, Pennsyl-vania, USA, July.Jose?
L. Vicedo and Antonio Ferra?ndez.
2000.
Apply-ing anaphora resolution to question answering andinformation retrieval systems.
In Proceedings of theFirst International Conference on Web-Age Informa-tion Management, volume 1846 of Lecture Notes InComputer Science, pages 344?355.
Springer, Shang-hai, China.Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu, andWayne Niblack.
2003.
Sentiment analyzer: Extract-ing sentiments about a given topic using natural lan-guage processing techniques.
In Proceedings of the3rd IEEE International Conference on Data Mining,pages 427?434, Melbourne, FL, USA, December.Li Zhuang, Feng Jing, and Xiao-Yan Zhu.
2006.Movie review mining and summarization.
In Pro-ceedings of the ACM 15th Conference on Informa-tion and Knowledge Management, pages 43?50, Ar-lington, VA, USA, November.268
