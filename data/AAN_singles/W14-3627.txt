Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 196?206,October 25, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsDomain and Dialect Adaptationfor Machine Translation into Egyptian ArabicSerena Jeblee1, Weston Feely1, Houda Bouamor2Alon Lavie1, Nizar Habash3and Kemal Oflazer21Carnegie Mellon University{sjeblee, wfeely, alavie}@cs.cmu.edu2Carnegie Mellon University in Qatarhbouamor@qatar.cmu.edu, ko@cs.cmu.edu3New York University Abu Dhabinizar.habash@nyu.eduAbstractIn this paper, we present a statistical ma-chine translation system for English to Di-alectal Arabic (DA), using Modern Stan-dard Arabic (MSA) as a pivot.
We cre-ate a core system to translate from En-glish to MSA using a large bilingual par-allel corpus.
Then, we design two separatepathways for translation from MSA intoDA: a two-step domain and dialect adap-tation system and a one-step simultane-ous domain and dialect adaptation system.Both variants of the adaptation systems aretrained on a 100k sentence tri-parallel cor-pus of English, MSA, and Egyptian Arabicgenerated by a rule-based transformation.We test our systems on a held-out Egyp-tian Arabic test set from the 100k sen-tence corpus and we achieve our best per-formance using the two-step domain anddialect adaptation system with a BLEUscore of 42.9.1 IntroductionWhile MSA is the shared official language of cul-ture, media and education in the Arab world, it isnot the native language of any speakers of Ara-bic.
Most native speakers are unable to producesustained spontaneous discourse in MSA - theyusually resort to repeated code-switching betweentheir dialect and MSA (Abu-Melhim, 1991).
Ara-bic speakers are quite aware of the contextual fac-tors and the differences between their dialects andMSA, although they may not always be able topinpoint exact linguistic differences.
In the con-text of natural language processing (NLP), someArabic dialects have started receiving increas-ing attention, particularly in the context of ma-chine translation (Zbib et al., 2012; Salloum andHabash, 2013; Salloum et al., 2014; Al-Mannaiet al., 2014) and in terms of data collection (Cot-terell and Callison-Burch, 2014; Bouamor et al.,2014; Salama et al., 2014) and basic enablingtechnologies (Habash et al., 2012; Pasha et al.,2014).
However, the focus is on a small numberof iconic dialects, (e.g., Egyptian).
The Egyptianmedia industry has traditionally played a dominantrole in the Arab world, making the Egyptian di-alect the most widely understood and used dialect.DA is now emerging as the language of informalcommunication online.
DA differs phonologically,lexically, morphologically, and syntactically fromMSA.
And while MSA has an established stan-dard orthography, the dialects do not: people writewords reflecting their phonology and sometimesuse roman script.
Thus, MSA tools cannot ef-fectively model DA; for instance, over one-thirdof Levantine verbs cannot be analyzed using anMSA morphological analyzer (Habash and Ram-bow, 2006).
These differences make the direct useof MSA NLP tools and applications for handlingdialects impractical.In this work, we design an MT system for En-glish to Egyptian Arabic translation by using MSAas an intermediary step.
This includes differentchallenges from those faced when translating intoEnglish.
Because MSA is the formal written va-riety of Arabic, there is an abundance of writtendata, including parallel corpora from sources likethe United Nations and newspapers, as well as var-ious treebanks.
Using these resources, many re-searchers have created fairly reliable MSA trans-lation systems.
However, these systems are notdesigned to deal with the other Arabic variants.Egyptian Arabic is much closer to MSA thanit is to English, so one can get a system bet-196ter performance by translating first into MSA andthen translating from MSA to Egyptian Arabic,which are far more similar.
Our approach consistsof a core MT system trained on a large amountof out-of-domain English-MSA parallel data, fol-lowed by an adaptation system.
We design and im-plement two adaptation systems: a two-step sys-tem first adapts to in-domain MSA and then sep-arately adapts from MSA to Egyptian Arabic, anda one-step system that adapts directly from out-of-domain MSA to in-domain Egyptian Arabic.Our research contributions are summarized asfollows:(a) We build a machine translation system totranslate into, rather than out of, dialectal Ara-bic (from English), using MSA as a pivotpoint.
(b) We apply a domain adaptation technique toimprove the MSA results on our in-domaindataset.
(c) We automatically generate the Egyptian sideof a 100k tri-parallel corpus covering MSA,English and Egyptian.
(d) We use this domain adaptation technique toadapt MSA into dialectal Arabic.The remainder of this paper is structured as fol-lows.
We first review the main previous effortsfor dealing with DA in NLP, in Section 2.
In Sec-tion 3,we give a general description about usingphrase-based MT as an adaptation system.
Sec-tion 4 presents the dataset used in the different ex-periments.
Our approach for translating Englishtext into Egyptian Arabic is explained in Section 5.Section 6 presents our experimental setup and theresults obtained.
Then, we give an analysis of oursystem output in Section 7.
Finally, we concludeand describe our future work in Section 8.2 Related workMachine translation (MT) for dialectal Arabic(DA) is quite challenging given the limited re-sources to build rule-based models or train statis-tical models for MT.
While there has been a con-siderable amount of work in the context of stan-dard Arabic NLP (Habash, 2010), DA is impov-erished in terms of available tools and resourcescompared to MSA, e.g., there are few parallel DA-English corpora (Zbib et al., 2012; Bouamor etal., 2014).
The majority of DA resources are forspeech recognition, although more and more re-sources for machine translation and enabling tech-nologies such as morphological analyzers are be-coming available for specific dialects (Habash etal., 2012; Habash et al., 2013).For Arabic and its dialects, several researchershave explored the idea of exploiting existing MSArich resources to build tools for DA NLP.
Differ-ent research work successfully translated DA toMSA as a bridge to translate to English (Sawaf,2010; Salloum and Habash, 2013), or to enhancethe performance of Arabic-based information re-trieval systems (Shatnawi et al., 2012).
Among theefforts on translation from DA to MSA, Abo Bakret al.
(2008) introduced a hybrid approach to trans-fer a sentence from Egyptian Arabic to MSA.Sajjad et al.
(2013) used a dictionary of Egyp-tian/MSA words to transform Egyptian to MSAand showed improvement in the quality of ma-chine translation.
A similar but rule-based workwas done by Mohamed et al.
(2012).
Boujel-bane et al.
(2013) and Hamdi et al.
(2014) builta bilingual dictionary using explicit knowledgeabout the relation between Tunisian Arabic andMSA.
These works are limited to a dictionary orrules that are not available for all dialects.
Zbibet al.
(2012) used crowdsourcing to translate sen-tences from Egyptian and Levantine into English,and thus built two bilingual corpora.
The dialec-tal sentences were selected from a large corpusof Arabic web text.
Then, they explored severalmethods for dialect/English MT.
Their best Egyp-tian/English system was trained on dialect/Englishparallel data.
They argued that differences in genrebetween MSA and DA make bridging throughMSA of limited value.
For this reason, while piv-oting through MSA, it is important to consider thedomain and add an additional step: domain adap-tation.The majority of previous efforts in DA MT hasbeen focusing on translating from dialectal Arabicinto other languages (mainly MSA or English).
Incontrast, in this work we focus on building a sys-tem to translate from English and MSA into DA.Furthermore, to the best of our knowledge, this isthe first work in which we adapt the domain in ad-dition to the dialect (Egyptian specifically).3 Using Phrase-Based MT as anAdaptation SystemFor commercial use, MT output is usually post-edited by a human translator in order to fix the er-rors generated by the MT system.
This is oftenfaster and cheaper than having a human translate197the document from scratch.
However, we can ap-ply statistical phrase-based MT to create an auto-matic machine post-editor (what we refer to in thispaper as an adaptation system) to improve the out-put of an MT system, and make it more closelyresemble the references.
Simard et al.
(2007) useda phrase-based MT system as an automatic post-editor for the output of a commercial rule-basedMT system, showing that it produced better resultsthan both the rule-based system alone and a sin-gle pass phrase-based MT system.
This techniqueis also useful for adapting to a specific domain ordataset.
Isabelle et al.
(2007) used a statistical MTsystem to automatically post-edit the output of ageneric rule-based MT system, to avoid manuallycustomizing a system dictionary and to reduce theamount of manual post-editing required.For our adaptation systems, we build a corephrase-based MT system with a large amount ofout-of-domain data, which allows us to have bettercoverage of the target language.
For an adaptationsystem, we then build a second phrase-based MTsystem by translating the in-domain train, tune,and test sets through the core translation system,then using that data to build the second system.This system uses only in-domain data: parallelMT output from the core and the references.
Inthis system, instead of learning to translate onelanguage into another, the model learns to trans-late erroneous MT output into more fluent outputof the same language, which more closely resem-bles the references.In this work, we apply this technique fordomain and dialect adaptation, treating Egyp-tian Arabic as the target language, and the MT-generated MSA as the erroneous MT output.
Weuse this approach to adapt to the domain of theMSA data, and also to adapt to the Egyptian di-alect.
What we refer to as the ?one-step?
system isa core system plus one adaptation system, whereasthe ?two-step?
system consists of the core plus twosubsequent adaptation systems.
We describe thesystems in more detail in Section 5.4 DataFor the core English to MSA system, we usethe 5 million parallel sentences of English andMSA from NIST 2012 as the training set.
Thetuning set consists of 1,356 sentences from theNIST 2008 Open Machine Translation Evalua-tion (MT08) data (NIST Multimodal InformationGroup, 2010a), and the test set consists of 1,313sentences from NIST MT09 (NIST MultimodalInformation Group, 2010b).We use a 5-gram MSA language model builtusing the SRILM toolkit (Stolcke, 2002) on 260million words of MSA from the Arabic Gigaword(Parker et al., 2011).
All our MSA parallel dataand monolingual MSA language modeling datawere tokenized with MADA v3.1 (Habash andRambow, 2005) using the ATB (Arabic Treebank)tokenization scheme.For the adaptation systems, we build a 100ktri-parallel corpus Egyptian-MSA-English corpus.The MSA and English parts are extracted fromthe NIST corpus distributed by the Linguistic DataConsortium.
The Egyptian sentences are obtainedautomatically by extending Mohamed et al.
(2012)method for generating Egyptian Arabic from mor-phologically disambiguated MSA sentences.
Thisrule-based method relies on 103 transformationrules covering essentially nouns, verbs and pro-nouns as well as certain lexical items.
For eachMSA sentence, this method provides more thanone possible candidate, in its original version, theEgyptian sentence kept was chosen randomly.
Weextend the selection algorithm by scoring the dif-ferent sentences using a language model.
Forthis, we use SRILM with modified Kneser-Neysmoothing to build a 5-gram language model.
Themodel is trained on a corpus including articles ex-tracted from the Egyptian version of Wikipedia1and the Egyptian side of the AOC corpus (Zaidanand Callison-Burch, 2011).
We chose to includeEgyptian Wikipedia for the formal level of sen-tences in it different from the regular DA writtenin blogs or microblogging websites (e.g., Twitter)and closer to the ones generated by our system.We split this data into train, tune, and test setsof 98,027, 960, and 961 sentences respectively,after removing duplicates across sets.
The MSAcorpus was tokenized using MADA and the Egyp-tian Arabic data was tokenized with MADA-ARZv0.4 (Habash et al., 2013), both using the ATB to-kenization scheme, with alif/ya normalization.5 System DesignFigure 1 shows a diagram of our three English toEgyptian Arabic MT systems: (1) the baseline MTsystem, (2) the one-step adaptation MT system,and (3) the two-step adaptation MT system.
Wedescribe each system below.1http://arz.wikipedia.org/198System DesignEgyptian ArabicEnglishEnglishEnglish Egyptian ArabicEgyptian ArabicMSATranslationTranslationTranslationDomain & Dialect AdaptationDomain Adaptation Dialect AdaptationIn-domain MSAMSA100K sent.100K sent.
100K sent.100K sent.5M sent.5M sent.Baseline MT SystemOne-Step Adaptation MT SystemTwo-Step Adaptation MT SystemFigure 1: An overview of the different system architectures.Baseline SystemOur baseline system is a single phrase-based En-glish to Egyptian Arabic MT system, built usingMoses (Koehn et al., 2007) on the 100k corpus de-scribed in Section 4.
This system does not includeany MSA data, nor does it have an adaptation sys-tem; it is a typical, one-pass MT system that trans-lates English directly into Egyptian Arabic.
Wewill show that using adaptation systems improvesthe results significantly.Core SystemWe base our systems on a core system built us-ing Moses with the NIST data, a large amount ofparallel English-MSA data from different sourcesthan our in-domain data (the 100k dataset).
Ourcore system is also built using Moses.
We usethis core system to translate the English side of our100k train, tune, and test sets into MSA, the outputof which we refer to as MSA?.
This MSA?
data iswhat we use as the source side for the adaptationsystems.One-Step Adaptation SystemTo adapt to the domain and dialect of the 100k cor-pus, we first build a single adaptation system thattranslates the MSA?
output of the core directly intoEgyptian Arabic using the 100k corpus.
The train-ing data consists of parallel MSA?
(the output ofthe core) and the Egyptian Arabic from the 100kdataset.
With this system, we can take an Englishtest set, translate it through the core to get MSA?output, which we can translate through the adap-tation system to get Egyptian Arabic.Two-Step Adaptation SystemWe also build a two-step adaptation system thatconsists of two adaptation steps: one to adapt theMSA output of the core system to the domain ofthe MSA in the 100k corpus, and a second systemto translate the MSA output of the domain adap-tation system into Egyptian Arabic.
We use thefirst adaptation system to translate the MSA?
train,tune, and test sets (the output of the core, which isout-of-domain MSA), into in-domain MSA.
Thissystem is trained on the MSA?
output parallel withthe MSA references from the 100k dataset.
Werefer to the output of this system as MSA?, be-cause it has been translated from English into out-of-domain MSA (MSA?
), and then from out-of-domain MSA to in-domain MSA.The first adaptation system is used to translatethe MSA?
train, tune, and test sets into MSA?.Then we use these MSA?
sets with their parallelEgyptian Arabic from the 100k dataset to build thesecond adaptation system from in-domain MSA toEgyptian Arabic.
We do not use the dialect trans-formation from (Mohamed et al., 2012) because itis designed to work with gold-standard annotationof the MSA text, which we do not have.System VariantsSince MSA and Egyptian are more similar to eachother than they are to English, we tried several dif-ferent reordering window sizes to find the optimalreordering distance for adapting MSA to EgyptianArabic, including the typical reordering windowof length 7, a smaller window of length 4, and noreordering at all.
We found a reordering window199size of 7 to work best for all our systems, exceptfor the one-step adaptation system, where no re-ordering produced the best result.We also tested two different heuristics for sym-metrizing the word alignments: grow-diag andgrow-diag-final-and (Och and Ney, 2003).
Wefound that using grow-diag as our symmetriza-tion heuristic produced slightly better scores onthe 100k datasets.
For the baseline and adaptationsystems we built 5-gram language models withKenLM (Heafield et al., 2013) using the target sideof the training set, and for the core system we usedthe large MSA language model described in sec-tion 4.
We use KenLM because it has been shown(Heafield, 2011) to be faster and use less memorythan SRILM (Stolcke, 2002) and IRSTLM (Fed-erico et al., 2008).6 Evaluation and ResultsFor evaluation we use multeval (Clark et al.,2011) to calculate BLEU (Papineni et al.,2002), METEOR (Denkowski and Lavie, 2011),TER (Snover et al., 2006), and length of the test setfor each system.
We evaluate the core and adap-tation systems on the MSA and Egyptian sides ofthe test set drawn from the 100k corpus, which werefer to as the 100k sets.
The data used for evalua-tion is a genuine Egyptian Arabic generated fromMSA, just like the data the systems were trainedon.
It is not practical to evaluate on naturally-generated Egyptian Arabic in this case because thedomain of our datasets is very formal, since mostof the text comes from news sources, and dialectalArabic is generally used in informal situations.2Below we report BLEU scores from our evalua-tion using tokenized and detokenized system out-put.
We separate our results into the baseline sys-tem results, the results of the core, the results ofthe adaptation systems, and a comparison section.We specify scores of intermediate system output,such as MSA, as BLEU (A), and the scores of fi-nal system output as BLEU (B).
For error analysis,we use METEOR X-ray (Denkowski and Lavie,2011) to visualize the alignments of our systemresults with the references and each other.For all MT systems we used grow-diag as oursymmetrization heuristic.
For each system, we re-port only the BLEU score of the best reorderingwindow variant, which is specified in the caption2It is important to note that the Egyptian Arabic data weuse is more MSA-like than typical Egyptian because it wasgenerated directly from MSA.below each table.
The difference in scores be-tween the different reordering window sizes (7, 4,and 0) we tried for the adaptation systems was notlarge (between 0 and 0.7 BLEU).
In the followingtables we present the best results for each adapta-tion system, which is a reordering window size of7 for all systems, except for the phrase-based one-step domain and dialect adaptation system, whichperforms better with no reordering (0.2 BLEU bet-ter than a window of 7, 0.6 BLEU better than awindow of 4), but these small differences in BLEUscores are within noise.
The greatest differencein scores from the reordering windows was in thetwo-step systems domain adaptation step (MSA toMSA) on top of the phrase-based core, where a re-ordering window of 7 was 0.7 BLEU better than awindow of 0.6.1 Baseline System ResultsBLEU (B)Tokenized Detokenized100k EGY Tune 22.6 22.3100k EGY Test 21.5 21.1Table 1: Baseline results (English ?
EGY) with areordering window size of 7.The baseline system demonstrates the results ofbuilding a basic MT system directly from Englishto Egyptian Arabic.
The goal of the core and adap-tation systems is to achieve better scores than thisinitial approach.6.2 Core System ResultsIn Table 2, we report BLEU scores for our coresystem on its own tuning set, NIST MT08, andNIST MT09 as a held-out MSA test set.
Wealso report scores on the tune and test sets usedto build our adaptation systems, both MSA andEgyptian Arabic.
This is not the final system out-put, but rather these scores are for intermediateoutput only, which becomes the input for our ada-patation systems.We notice that unsurprisingly the core systemperforms much better on the 100k MSA test setthan on the 100k Egyptian Arabic test set, whichis to be expected because the core system is nottrained on any Egyptian Arabic data.
This showsthe impact that the dialectal differences make onMT output.
The results on the Egyptian testset here are the result of evaluating MSA outputagainst Egyptian Arabic references.200BLEU (A)Tokenized DetokenizedNIST MT08 (Tune) 23.6 22.8NIST MT09 (Test) 29.3 28.5100k MSA Tune 39.8 39.3100k MSA Test 39.4 39.0100k EGY Tune 28.1 28.1100k EGY Test 27.7 27.7Table 2: Core system (English ?
MSA) resultsusing a reordering window size of 7.6.3 Adaptation System ResultsThe adaptation systems take as input the MSA out-put of the core and attempt to improve the scoreson the Egyptian test set by adapting to the domainof the 100k dataset, as well as to Egyptian Arabic,in either one or two steps.BLEU (B)Tokenized Detokenized100k EGY Tune 40.8 40.5100k EGY Test 40.3 40.1Table 3: One-Step Adaptation system (MSA?
?Egyptian Arabic) results using a reordering win-dow size of 0.Table 3 shows the results of the single adapta-tion system, which adapts directly from the MSAoutput of the core to Egyptian Arabic.
TheseBLEU scores are already much better than the coresystems performance on the same test sets, im-proving from 28.1 BLEU to 40.5 BLEU on theEgyptian Arabic tuning set (a difference of 12.4BLEU) and improving from 22.7 BLEU to 40.1BLEU on the Egyptian Arabic test set (a differ-ence of 17.4 BLEU).Tables 4 and 5 below illustrate the results of thefirst and second steps of the two-step adaptationsystem: Table 4 contains the results of the first do-main adaptation step from out-of-domain MSA toin-domain MSA and Table 5 contains the results ofthe second dialect adaptation step from in-domainMSA to Egyptian Arabic.An example of our system output for an Englishsentence is given in Table 6.
Its METEOR X-rayalignment is illustrated in Figure 2.6.4 System Comparisons on 100k Test SetsIn Table 7, we compare the results from the coreand the results from the first step of the two-stepBLEU (A)Tokenized Detokenized100k MSA Tune 45.2 44.6100k MSA Test 44.8 44.2100k EGY Tune 32.2 32.2100k EGY Test 32.0 32.0Table 4: Domain Adaptation system (MSA?
?MSA?)
for Two-Step Adaptation System Resultsusing a reordering window size of 7.BLEU (B)Tokenized Detokenized100k EGY Tune 43.3 43.2100k EGY Test 43.1 42.9Table 5: Dialect Adaptation system (MSA?
?Egyptian) for Two-Step Adaptation System Re-sults using a reordering window size of 7.?
?
?????
????????????
??????
??????
??
???????
?????????????
?????
???????
?
????????????
?
????????????
?
?????????
?
?????????????
?????????
?
????
?????
?
??
?????????????
?
?????????????
?
??????????
?
????
?Segment 314P: 0.700 vs 0.900 : 0.200R: 0.700 vs 0.900 : 0.200Frag: 0.214 vs 0.085 : 0.129-Score: 0.550 vs 0.823 : 0.273Figure 2: METEOR X-ray alignment of the sen-tence in table 6.
The left side is the output of theone-step system, the right side is the output of thetwo-step system, and the top is the reference.
Theshaded cells represent matches between the refer-ence and the one-step system, and the dots repre-sent matches between the reference and the two-step system.adaptation system on the MSA test set and wesee that adapting to the domain improves BLEUscores on MSA.Since our goal is to improve the output for1One-Step System: Core + Domain and Dialect Adapta-tion (MSA?
?
EGY)2Two Step Adaptation System (Step 1): Core + DomainAdaptation (MSA?
?
MSA?
)3Two Step Adaptation System (Step 2): Core + DomainAdaptation (MSA??MSA?)
+ Dialect Adaptation (MSA?
?EGY)201English UN closes old office in Liberia in preparation for new missionEgyptian Reference?YKYg.?????
@X @Y?J?@?KQJ.J?
???K.A??
@ A?D.J?????JK.?YjJ??
@ ?
?B@AAlAmm AAlmtHdp btglq mktbhA AAlsAbq fy lybyryp AAstEdAdA lmhmp jdydp1-Step System?YKYg.?????
@X @Y?J?
@ AKQJ.J?
?????Y??
@ I.J?????JK.?YjJ??
@ ?
?B@AAlAmm AAlmtHdp btglq mktb AAlqdymp fy lybyryA AAstEdAdA lmhmp jdydp2-Step System (step2)?YKYg.?????
@X @Y?J?@?KQJ.J?
?????Y??
@ A?D.J?????JK.?YjJ??
@ ?
?B@AAlAmm AAlmtHdp btglq mktbhA AAlqdymp fy lybyryp AAstEdAdA lmhmp jdydpTable 6: An example of system output from the Egyptian test set.BLEU (A)Tokenized DetokenizedCore (English ?
MSA?)
39.4 39.0Core + Domain Adaptation (MSA?
?
MSA?)
44.8 44.2Table 7: Comparison of results on 100k MSA test set.BLEU (A/B)Tokenized DetokenizedBaseline (English ?
EGY) 21.5 (B) 21.1Core (English ?MSA?)
27.7 (A) 27.7One-Step Adaptation System140.3 (B) 40.1Two-Step Adaptation System (Step 1)232.0 (A) 32.0Two-Step Adaptation System (Step 2)343.1 (B) 42.9Table 8: Comparison of results on 100k EGY test data.BLEU (B) METEOR TER LengthBaseline System 21.1 38.5 66.1 102.7One-Step System 40.1 53.4 51.3 100.0Two-Step System: Step 2 (Dialect) 42.9 55.2 50.4 100.1Table 9: Detokenized BLEU, METEOR, TER, and length scores for the best system results.Egyptian Arabic, we examine the improvement ofscores through different steps of the system in Ta-ble 8.
These scores are all based on the sameEgyptian Arabic references, even though some ofthe systems are designed to produce MSA output.It is important to note that although the first stepof the two-step adaptation system (domain adap-tation) is still producing MSA output, it performsbetter on the Egyptian test set than the out-of-domain MSA core.
The domain adaptation sys-tem built on top of the core performs better thanthe core alone on the 100k corpus MSA test set(+5.2 BLEU), as well as the 100k corpus EgyptianArabic test set (+4.3 BLEU).
The best score weachieve on the 100k corpus MSA test set is 44.2BLEU, from the core plus the domain adaptationsystem.Table 9 shows the other detokenized scoresfrom multeval (Clark et al., 2011) from the finaloutput on the EGY test set from each system, andTable 10 shows BLEU-1 through BLEU-4 scoreson the same detokenized results, which shows animprovement at different n-gram levels in unigramcoverage from the baseline system to the adapta-tion systems.Overall, the two-step adaptation system built ontop of the core performs 15.2 BLEU better thanthe core alone on the 100k corpus Egyptian Ara-bic test set and the one-step adaptation system per-forms 12.4 BLEU better than the core on the sametest set.
The best score on the 100k EGY test setis from the two-step adaptation system with 42.9BLEU, which outperforms the one-step adaptationsystem by 2.8 BLEU points.
We consider possiblecauses of these results in section 7.202BLEU-1 BLEU-2 BLEU-3 BLEU-4Baseline System 53.4 26.6 15.3 9.1One-Step System 64.3 43.5 33.5 27.1Two-Step System: Step 2 (Dialect) 65.2 46.0 36.8 30.7Table 10: Detokenized BLEU (B) scores on the 100k EGY test set at different n-gram levels.English US , Indonesia commit to closer trade , investment tiesEgyptian Reference?K?@?KPA?J?@??KPAm.'HA?C?K.@?
?Q?JK.AJ?K?YK @??YjJ??@HAKB??
@AAlwlAyAt AAlmtHdp wAndwnysyA byltzmwA bElAqAt tjAryp wAstvmAryp AAwvqBaseline output?KPA?J?B@??KPAj.J?
@HA?C??@?JK?JK.Y?
?JK.AJ?K?YK @?A?
, AK++nA , fAn AAndwnysyA bt Ehd btwvyq AAlElAqAt AAltjAryp wAlAstvmArypTable 11: An example of a Baseline system output sentence with no word matches.English Pakistan sends envoys to Arab countriesEgyptian Reference?JK.Q??
@ ??Y?
@ ??@?K??J.?
??QK.?AJ??
AK.bAkstAn btrsl mbEwvyn AAly AAldwl AAlErbypOne-Step System?JK.Q??
@ ??Y?
@ ??
@ ?JJ?
??QK.?AJ??
AK.bAkstAn byrsl Envys AAly AAldwl AAlErbypTwo-Step System (Step 2)?JK.Q??
@ ??Y?
@ ??
@ ?JJ?
??QK.?AJ??
AK.bAkstAn btrsl Envys AAly AAldwl AAlErbypTable 12: An example of system output from the Egyptian test set.7 Error AnalysisIn some of the output sentences, there are no exactmatches and the sentence gets a score of 0, such asin the example from the Baseline system output inTable 11.
But there are actually four words in theoutput that are present in the reference, but theyhave different clitics attached to them.
The thirdword in the reference, AJ?K?YK @?/wAndwnysyA?and Indonesia?, is present in the output asjust AJ?K?YK @/AndwnysyA ?Indonesia?.
The sameis true of the fifth, sixth, and seventh wordsin the reference:HA?C?K./bElAqAt ?with re-lationships?
isHA?C??
@/AlElAqAt ?the relation-ships?
in the output,?KPAm.'/tjAryp ?commer-cial?
is?KPAj.J?
@/AltjAryp ?commercial(definite)?,and?KPA?J?
@?/wAstvmAryp ?and investment?
is?KPA?J?B@?/wAlAstvmAryp ?and the investment?.In tokenized output the base words would bematched because the clitics would be separate.This is one of the drawbacks of evaluating on deto-kenized data.Table 12 and Figure 3 show the output for a sen-tence from the Egyptian test set from the two dif-ferent adaptation systems.
In Figure 3, the resultsfrom the one-step and two-step adaptation systemsare almost the same, except that the two-step adap-tation system (which scored 2.8 BLEU higher thanthe one-step system overall) has one more wordcorrect (the second word).
This word is actuallythe same verb, but the two-step adaptation systemhas produced the correct conjugation of the verb(3rd person feminine), while the one-step systemproduced the wrong conjugation (3rd person mas-culine).
In adapting to the domain first, the systemseems to produce better subject-verb agreement.In Table 6 and Figure 2 in Section 6.3, thetransliteration of ?Liberia?
in the output of thetwo-step system matches the reference.
The one-step system produces a different transliterationwhich is also valid, but is not the same one thereference uses.
It also produces the correct objectclitic ( A?D.J?
?/mktbhA ?its office?
vs.
I.J??/mktb?office?).
The output of the two-step system moreconsistently matches the reference in transliter-ation, subject-verb agreement, and clitic attach-ment.In general the output of the two-step adaptationsystem appears to be in the correct order more of-ten than the output of the one-step adaptation sys-203English man stabs nine at moscow synagogueEgyptian Reference@?????
??
?X??E?J?
??
9??
?JK.H.A?$Ab byTEnn 9 fy knys yhwdy fy mwskwAOne-Step System@?????
??
?X??E?J?
??
??????
?g.
@PrAjl TEn tsEh fy knys yhwdy fy mwskwATable 13: Comparison of reference and system output.?
?
??????????????????????
?????
????????????????
?
????????????
?
???????????
?????????
?
????????
?
????????????
?
??????
?Segment 203P: 0.667 vs 0.833 : 0.167R: 0.667 vs 0.833 : 0.167Frag: 0.265 vs 0.194 : 0.071-Score: 0.490 vs 0.672 : 0.182Figure 3: A comparison of the output of theone-step domain and dialect adaptation system(left column) and the two-step domain and dialectadaptation system (right column), both built on topof the phrase-based core.
The top is the referencesentence.tem, perhaps because we used a reordering win-dow of 7 for the two-step system, whereas we useda window of 0 for the one step system.
Addition-ally, the two-step system allows two passes of re-ordering, one in each step.
Each step of the sys-tem produces a decrease in the fragmentation ofthe output: the output of the core on the Egyptiantest set gets a fragmentation penalty of 0.204, theone-step system gets a fragmentation penalty of0.159, and the two step system gets 0.189 for thefirst step (domain) and 0.139 for the second step(dialect).
Since the output of the two-step systemis less fragmented, there are longer sequences ofwords that are in the correct order.Additionally, the one-step system misses morewords, especially at the beginning of a sentence.There are many ways to introduce a sentence inArabic, some of which correspond to the same En-glish phrase.
While the model will generate themost probable one, there may be several accept-able choices, and the reference may have a dif-ferent one.
For instance, in Table 13, the word?man?
is translated as H.A?/$Ab in the reference,and ?g.
@P/rAjl in the output of the one-step adapta-tion system.
This word is penalized for not match-ing the reference, even though both are reason-able translations of ?man?.
This problem couldbe helped by synonym matching in the evaluationmetrics, which is not currently available for Ara-bic.8 Conclusion and Future WorkWe have shown that we can leverage a largeamount of out-of-domain MSA data and a domainadaptation system to achieve better performanceon an in-domain test set.
We apply the same tech-nique to translating Arabic dialects, by adaptingfrom MSA to the Egyptian Arabic dialect as wewould adapt between domains of the same lan-guage.
Our results also show that when adapt-ing to the domain, first by translating to MSAas an intermediary step and then adapting to thedialect, we can improve performance even more.Our results also show the importance of consis-tent and appropriate tokenization of the data.
Thetri-parallel corpus of English, MSA, and Egyptiangave us a unique opportunity to create this kindof system, as parallel data for Arabic dialects ishard to come by.
However, this data is artificialEgyptian, not natural generated dialectal Arabic.In the future we hope to test our domain and di-alect adaptation MT systems on more authenticEgyptian Arabic data sets and to be able to applythis technique to other Arabic dialects.AcknowledgementsThis publication was made possible by grantNPRP-09-1140-1-177 from the Qatar NationalResearch Fund (a member of the Qatar Founda-tion) and by computing resources provided by theNSF-sponsored XSEDE program under grant TG-CCR110017.
The statements made herein aresolely the responsibility of the authors.
We thankthe reviewers for their comments.
Nizar Habashperformed most of his contribution to this pa-per while he was at the Center for ComputationalLearning Systems at Columbia University.204ReferencesHitham Abo Bakr, Khaled Shaalan, and IbrahimZiedan.
2008.
A Hybrid Approach for Convert-ing Written Egyptian Colloquial Dialect into Dia-critized Arabic.
In Proceedings of the 6th Interna-tional Conference on Informatics and Systems (IN-FOS2008).
Cairo University.Abdel-Rahman Abu-Melhim.
1991.
Code-switchingand Linguistic Accommodation in Arabic.
In Per-spectives on Arabic Linguistics III: Papers from theThird Annual Symposium on Arabic Linguistics, vol-ume 80, pages 231?250.
John Benjamins Publish-ing.Kamla Al-Mannai, Hassan Sajjad, Alaa Khader, Fa-had Al Obaidli, Preslav Nakov, and Stephan Vogel.2014.
Unsupervised Word Segmentation ImprovesDialectal Arabic to English Machine Translation.
InProceedings of EMNLP Workshop on Arabic Natu-ral Language Processing, Doha, Qatar.Houda Bouamor, Nizar Habash, and Kemal Oflazer.2014.
A Multidialectal Parallel Corpus of Ara-bic.
In Proceedings of the Ninth InternationalConference on Language Resources and Evaluation(LREC?14), pages 1240?1245, Reykjavik, Iceland.Rahma Boujelbane, Mariem Ellouze Khemekhem, andLamia Hadrich Belguith.
2013.
Mapping Rules forBuilding a Tunisian Dialect Lexicon and GeneratingCorpora.
In Proceedings of the Sixth InternationalJoint Conference on Natural Language Processing,pages 419?428, Nagoya, Japan.Jonathan Clark, Chris Dyer, Alon Lavie, and NoahSmith.
2011.
Better Hypothesis Testing for Sta-tistical Machine Translation: Controlling for Opti-mizer Instability.
In Proceedings of the Associationfor Computational Linguistics (ACL), Portland, Ore-gon.Ryan Cotterell and Chris Callison-Burch.
2014.A Multi-Dialect, Multi-Genre Corpus of InformalWritten Arabic.
In Proceedings of the Ninth In-ternational Conference on Language Resources andEvaluation (LREC?14), pages 241?245, Reykjavik,Iceland.Michael Denkowski and Alon Lavie.
2011.
Meteor1.3: Automatic metric for reliable optimization andevaluation of machine translation systems.
In Pro-ceedings of the EMNLP 2011 Workshop on Statis-tical Machine Translation, pages 1?4, Edinburgh,Scotland.Marcello Federico, Nicola Bertoldi, and Mauro Cet-tolo.
2008.
IRSTLM: an open source toolkit forhandling large scale language models.
In INTER-SPEECH, pages 1618?1621.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-speech Tagging and Morphologi-cal Disambiguation in One Fell Swoop.
In Proceed-ings of the Association for Computational Linguis-tics, Ann Arbor, Michigan.Nizar Habash and Owen Rambow.
2006.
MAGEAD:A Morphological Analyzer and Generator for theArabic Dialects.
In Proceedings of the 21st Interna-tional Conference on Computational Linguistics and44th Annual Meeting of the Association for Compu-tational Linguistics, pages 681?688, Sydney, Aus-tralia.Nizar Habash, Ramy Eskander, and Abdelati Hawwari.2012.
A Morphological Analyzer for Egyptian Ara-bic.
In Proceedings of the Twelfth Meeting of theSpecial Interest Group on Computational Morphol-ogy and Phonology, pages 1?9, Montr?eal, Canada.Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-kander, and Nadi Tomeh.
2013.
MorphologicalAnalysis and Disambiguation for Dialectal Arabic.In Proceedings of the 2013 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 426?432, Atlanta, Georgia.Nizar Habash.
2010.
Introduction to Arabic NaturalLanguage Processing, volume 3.
Morgan & Clay-pool Publishers.Ahmed Hamdi, Nuria Gala, and Alexis Nasr.
2014.Automatically Building a Tunisian Lexicon for De-verbal Nouns.
In Proceedings of the First Workshopon Applying NLP Tools to Similar Languages, Vari-eties and Dialects, pages 95?102, Dublin, Ireland.Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.Clark, and Philipp Koehn.
2013.
Scalable ModfiedKneser-Ney Language Model Estimation.
In In Pro-ceedings of the Association for Computational Lin-guistics, Sofia, Bulgaria.Kenneth Heafield.
2011.
KenLM: Faster and SmallerLanguage Model Queries.
In Proceedings of theEMNLP 2011 Sixth Workshop on Statistical Ma-chine Translation, pages 187?197, Edinburgh, Scot-land, United Kingdom, July.Pierre Isabelle, Cyril Goutte, and Michel Simard.2007.
Domain Adaptation of MT Systems throughAutomatic Post-Editing.
In Proceedings of MTSummit XI, pages 255?261, Copenhagen, Denmark.Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-pher Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Christopher Dyer, Ondrej Bo-jar, Alexandra Constantin, and Evan Herbst.
2007.Moses: Open Source Toolkit for Statistical Ma-chine Translation.
In Proceedings of the 45th An-nual Meeting of the Association for ComputationalLinguistics Companion Volume Proceedings of theDemo and Poster Sessions, pages 177?180, Prague,Czech Republic.Emad Mohamed, Behrang Mohit, and Kemal Oflazer.2012.
Transforming Standard Arabic to ColloquialArabic.
In Proceedings of the 50th Annual Meet-ing of the Association for Computational Linguis-tics (Volume 2: Short Papers), pages 176?180, JejuIsland, Korea.205NIST Multimodal Information Group.
2010a.
NIST2008 Open Machine Translation (OpenMT) Evalua-tion LDC2010T21.
Web Download.NIST Multimodal Information Group.
2010b.
NIST2009 Open Machine Translation (OpenMT) Evalua-tion LDC2010T23.
Web Download.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
In Computational Linguistics, pages 19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
In Proceedingsof the Association for Computational Linguistics,Philadelphia, Pennsylvania.Robert Parker, David Graff, Ke Chen, Junbo Kong, andKazuaki Maeda.
2011.
Arabic Gigaword Fifth Edi-tion LDC2011T11.
Web Download.Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,Ahmed El Kholy, Ramy Eskander, Nizar Habash,Manoj Pooleery, Owen Rambow, and Ryan Roth.2014.
MADAMIRA: A Fast, Comprehensive Toolfor Morphological Analysis and Disambiguation ofArabic.
In Proceedings of the Ninth InternationalConference on Language Resources and Evaluation(LREC?14), pages 1094?1101, Reykjavik, Iceland.Hassan Sajjad, Kareem Darwish, and Yonatan Be-linkov.
2013.
Translating Dialectal Arabic to En-glish.
In Proceedings of the 51st Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 2: Short Papers), pages 1?6, Sofia, Bulgaria.Ahmed Salama, Houda Bouamor, Behrang Mohit, andKemal Oflazer.
2014.
YouDACC: the Youtube Di-alectal Arabic Comment Corpus.
In Proceedingsof the Ninth International Conference on LanguageResources and Evaluation (LREC?14), pages 1246?1251, Reykjavik, Iceland.Wael Salloum and Nizar Habash.
2013.
DialectalArabic to English Machine Translation: Pivotingthrough Modern Standard Arabic.
In Proceedings ofthe 2013 Conference of the North American Chapterof the Association for Computational Linguistics:Human Language Technologies, pages 348?358, At-lanta, Georgia.Wael Salloum, Heba Elfardy, Linda Alamir-Salloum,Nizar Habash, and Mona Diab.
2014.
SentenceLevel Dialect Identification for Machine TranslationSystem Selection.
In Proceedings of the 52nd An-nual Meeting of the Association for ComputationalLinguistics (Volume 2: Short Papers), pages 772?778, Baltimore, Maryland.Hassan Sawaf.
2010.
Arabic Dialect Handling in Hy-brid Machine Translation.
In Proceedings of theNinth Conference of the Association for MachineTranslation in the Americas (AMTA 10), Denver,Colorado.Mohammed Q Shatnawi, Muneer Bani Yassein, andReem Mahafza.
2012.
A Framework for Retriev-ing Arabic Documents Based on Queries Written inArabic Slang Language.
Journal of Information Sci-ence, 38(4):350?365.Michel Simard, Cyril Goutte, and Pierre Isabelle.2007.
Statistical Phrase-Based Post-Editing.
InProceedings of NAACL-HLT-2007 Human Lan-guage Technology: the Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 508?515, Rochester, NY.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Studyof Translation Edit Rate with Targeted Human An-notation.
In Proceedings of Association for Ma-chine Translation in the Americas, Cambridge, Mas-sachusetts.Andreas Stolcke.
2002.
SRILM - An Extensible Lan-guage Modeling Toolkit.
In Proceedings of the In-ternational Conference on Spoken Language Pro-cessing, vol.
2, pages 901?904, Denver, CO, USA.Omar F. Zaidan and Chris Callison-Burch.
2011.
TheArabic Online Commentary Dataset: an AnnotatedDataset of Informal Arabic with High Dialectal Con-tent.
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics:Human Language Technologies, pages 37?41, Port-land, Oregon, USA.Rabih Zbib, Erika Malchiodi, Jacob Devlin, DavidStallard, Spyros Matsoukas, Richard Schwartz, JohnMakhoul, Omar F. Zaidan, and Chris Callison-Burch.
2012.
Machine Translation for Arabic Di-alects.
In Proceedings of North American Chap-ter of the Association for Computational Linguistics,Montreal, Canada.206
