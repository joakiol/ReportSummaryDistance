Using a Probabilistic Translation Model for Cross-LanguageInformation RetrievalJian-Yun Nie, Pierre Isabelle, Pierre Plamondon, George FosterLaboratoire RALI,D~partement d'Inforrnatique et Recherche op6rationnelle, Universit~ de MontrealC.P.
6128, succursale Centre-ville, Montr6al, Qu6bec, H3C 3J7 Canada{nie, isabelle, plamondo, foster} @iro.umontreal.caAbstractThere is an increasing need for documentsearch mechanisms capable of matching anatural language query with documentswritten in a different language.
Recently, weconducted several experiments aimed atcomparing various methods of incorporating across-linguistic capability to existinginformation retrieval (IR) systems.
Our resultsindicate that translating queries with off-the-shelf machine translation systems can result inrelatively good performance.
But the resultsalso indicate that other methods can perfonneven better.
More specifically, we tested aprobabilistic translation model of the kindproposed by Brown & al.
\[2\].
The parametersof that system had been estimatedautomatically on a different, unrelated, corpusof parallel texts.
After we augmented it with asmall bilingual dictionary, this probabilistictranslation model outperformed machinetranslation systems on our cross-language IRtask.1.
IntroductionAdequate text processing systems havebecome widely available for most naturallanguages.
While English remains thedominant language on the Intemet, therelative share of other languages now appearsto be on the rise.
The network has becometruly multilingual.
This situation has createdan acute need for tools capable of performinglanguage-sensitive s arch in multilingualdatabases.
In particular, there is a need fortools capable of performing cross-languageinformation retrieval (CLIR), that is, ofmatching an information query written in oneparticular language with documents hat maybe written in one or several differentlanguages.Given such a need, the solution thatimmediately comes to mind is to translate theinformation query using a machine translation(MT) system, and to feed the resultingtranslation into a classical monolingual IRsystem.However, it should be stressed that MT and IRhave widely divergent concerns.
First, observethat MT systems are expected to producesyntactically correct ranslations and that theytend to spend a lot of effort trying to attainthat rather elusive goal.
On the other hand,current IR systems tend not to care aboutgrammar : for them texts are mostly viewed asvectors of content words.
Second, note thatMT systems are expected to select one of themany translations that words may have.
Forexample, in translating the English word"organic" the MT process will be led to selectbetween the French words "organique"and"biologique".
Generally speaking, thisselection process is very difficult and MTsystems often end up selecting the wrongtarget language quivalent.
Here again whatthe MT system is expected to do turns out tobe unnecessary and maybe undesirable froman IR point of view.
As a case in point,classical IR systems often perform a queryexpansion process by which certain queryterms/words are mapped onto severalequivalent or related index terms.
Notsurprisingly, such a process could well makeprovision for mapping the query word"organique" onto the two index terms"organique" and "biologique" so as to accountfor (partial) synonymy between these words.In other words, MT systems attempt tosystematically eradicate translationalambiguity instead of taking advantage of it tocapture synonymy relations.At the opposite nd of the spectrum, MT isreplaced with a simple bilingual dictionarylookup.
To that end, one can use either anordinary general-purpose dictionary, atechnical terminology database, or both.Because of the fact that in any sizabledictionary most words receive many18translations, the dictionary approach will ineffect subject the query to a rather massiveexpansion process.
The resulting targetlanguage query is likely engender a lot ofnoise (irrelevant documents that getretrieved), mostly due to the fact that in eachdictionary entry some of the translations cancorrespond to different meanings of the sourcelanguage word.
For example, the Englishword "drug" is translated in French as"drogue" (an illegal substance) or as"mgdicament" (a legal medicine) dependingon the context.
There is most often no explicitclue in the query that would allow one tochoose the appropriate meaning.Yet another approach is to determinetranslational equivalence automatically, on thebasis of a corpus of parallel texts (that is, acorpus made up of source texts and theirtranslations).
One way of doing this is to startby establishing translation correspondencesbetween units larger than words, typicallysentences.
There are now well-knownmethods for aligning the sentences of parallelcorpora (Gale & Church \[6\], Simard, Foster 8~Isabelle \[10\]).
Then, the translationalequivalence of a given pair of words can beestimated by their degree of co-occurrence inparallel sentences.
Compared to the previousapproaches, this has the following advantages:- There is no need to acquire or to compile abilingual dictionary or a complete MTsystem.- Word translations are made sensitive to thedomain, as embodied by the training corpus.- As we will see below, it is relatively easy toobtain a suitable degree of query expansionbased on translational mbiguity.In the next section, we describe the structureof a probabilistic translation model that cancalculate pule), the probability of observingwordfj as part of the translation of sentence .Given a query e, we can then select he n best-scoring values offj as the set of index terms inthe target language.
This method will becompared to the other two mentioned above.2.
A Probabilistie Translation ModelAny source language input e can usually betranslated in a great many different ways.Machine translation systems are expected toselect but one particular translation f for eachinput.
In the current state of the art, unaidedMT is generally unable to produce high-quality translations: human translators remainmostly unchallenged.
Moreover, it has beenshown repeatedly that human translatorsseldom find it practical to post-edit MToutput: the machine has just made too manywrong or questionable decisions.If the goal is to help human translators, it isadvisable to stop short of producing a full-blown automatic translation.
There is no pointin having the machine spontaneously proposea detailed target language syntactic structureunless there is at least a reasonably goodchance that the translator will want to use it.Similarly, there is no point in having themachine select arget language quivalents forall source language words unless most ofthese equivalents are likely to be retained bythe translator.In recent years it has been shown that existingMT techniques can produce useful resultswhen they are applied to tasks that amount osomewhat less than translation proper.
Inprevious work, we have shown thatprobabilistic translation models such as thoseof Brown et al \[2\] could be used as the keycomponent of various translation supporttools.
Specifically, our work on the TransTalkproject \[1, 4\] has established that such modelscould become instrumental in improving theprocess of automatically transcribing a spokentranslation.
And our ongoing work on theTransType project \[5\] indicates that models ofthe same kind can drive typing aids fortranslators.A key feature of such applications i that theydo not expect he machine to volunteer a full-fledged translation on its own.
Rather, themachine is only expected to restrict he rangeof possible translations so as to make it easierto guess what the intentions of the humantranslator are.?
For example, in certain incarnations of theTransTalk system, the translation model isused as a means of answering the followingquestion: given a source language sentence ,what is the likelihood of observing the word fin any target language sentence f thatconstitutes a valid translation of e?
If e is anEnglish sentence that contains the word"horses", then the likelihood that "chevaux"(the most direct equivalent for "horses") willappear in a French translation ffof e is much19greater than the a priori likelihood ofobserving "chevaux" in a random Frenchsentence.
In contrast, there is no reason toexpect that the likelihood of observing"cheveux" (an acoustically close word thatmeans "hair") in f will be significantlyaltered:p(chevaux E f I horses ~ e) > p(chevaux ~ f)p(cheveu x ~ f I horses ~ e) =p(cheveux ~ f)TransTalk makes use of this fact to helpresolve the acoustic ambiguity between t\]heFrench words "chevaux'" and "cheveux".From the point of view of translation support,doing somewhat less than full-blown MT islikely to achieve more.In this paper, we want to argue that CLIR isfacing a similar situation in that subjecting thesource language query to a process that stopsshort of producing a full-blown targetlanguage query can result in a good retrievalperformance.
For the purpose of CLIR, ourgoal is to obtain a set of words that are thebest translations of an original query.
Thisgoal may be achieved by using probabilistictranslation models of the kind used in ourTransTalk and TransSearch.By translation model, we mean a mechanismwhich associates to each source languagesentence(or query) e a probability distributionp(fle) on the sentences (or queries) f of thetarget language.
A precise description of afamily of such models can be found in Brown& al.
\[2\].
The model we will be using for theexperiments reported here is basically their"Model 1".
In this model, a source e and !itstranslation f are connected through analignment a, that is a mapping of the words ofe onto those of f. If e = e 1, e r .... e t and f =.f,f2, .... f .
then aj will be used to refer to theparticular position in e that is connected withposition j in f (for example, a2 = 4 expressesthe fact thatf~ is connected with e,) and e, willbe used to refer to the word in e at position a rThe probability p(fle) is decomposed as a sumover all possible alignments:p(fle) = ~a~ Ap(f, ale)The conditional probability of f underalignment a given e can be analysed asfollows:p(f, ale)= p(fla,e)p(ale) =Ke,r p(fla,e)The latter equality stems from the fact that inmodel 1, all alignments are consideredequiprobable (see below).
Consequently p(ale)is a constant Kel equal to 1 over the totalnumber of alignements.The core of the model is tf3~le), the lexicalprobability that some word e~ is translated asword fr The value of p(fla,e) depends mostlyon the product of the lexical probabilities ofeach word pair connected by the alignment:p(fla,e) = Cr~ lq j=l,m t~le , )where Cr, ~ is a constant that accounts forcertain dependencies between the respectivelengths of sentences e and f (mostly irrelevanthere).The probability of observing wordfj in f undera particular alignment a is:p~.la,e) = t~le ?
)And the probability of observing word fj in funder any alignment is:PU le) = ~i=l,l t(~le,)Since all alignments are consideredequiprobable, we can simply sum up thevalues obtained by connecting f~ to each worde e e~ .... e~ of e. In other words, theprobability of observing a particular word in agiven position in f is established as the total ofthe lexical contributions of each word of e.The parameters of our translation model areestimated from a bilingual parallel corpus inwhich each sentence has been aligned with thecorresponding sentence(s) of the otherlanguage.
Such alignments can be producedusing algorithms uch as the one described in\[10\].
Given such alignments we can estimatereasonable values for the parameters t(~le)using the Expectation Maximizationalgorithm, as described in \[2\].
The model usedin the experiments reported here has beentrained using 8 years of the Canadian Hansard(parliamentary debates), that is,approximately 50 million words in eachlanguage.Obviously, a translation model in which allalignments are considered equiprobable, likeModel 1, can only be a very coarse model.The lexical translation probabilities t~le)  areindependent from the positions offj and e i. Asa result, for any j, j ' ,  the model assigns the20same value to p~le) and to pf~.le).
In otherwords, the model is completely blind tosyntax.
This means that it is much too weak togenerate full-blown translations on its own.
Atthe very least, one would need to use it intandem with a language model p(f) capable ofcapturing some constraints on acceptablesequences of words in the target language.Notwithstanding its weaknesses Model 1 doescapture some non trivial aspects of thetranslation relationship as we observe it acrossnatural anguages.
For example, it is indeed aproperty of that model that a relativelyunambiguous source language word (say, theEnglish "chimney") will reinforce itsequivalents in a stronger way than a veryambiguous word.
An ambiguous word like"drug" will reinforce each of its equivalents("mrdicament" and "drogue") according to atranslation probability estimated from thetraining corpus.
While the model onlyoperates at the level of simple word (asopposed to complex terms), it should beobserved that it nonetheless captures somenon-trivial contextual effects.
For example, ifthe training corpus contains many occurrencesof the expression "drug traffic" translated as"trafic de drogue", the presence of the Englishword "traffic" will thereafter tend to reinforcethe French word "drogue" (in this instance,more than the French word "mrdicament").And given the fact that the intendedapplication is not MT but CLIR, the use of a"weak" translation model turns out to be, insome respects, sufficient.
In our IR systemqueries and documents are reperesented asvectors of weighted terms.
Given any query e,our translation model will calculate a valuefor p(t~le), the probability of observing wordfjin the translation of e. It turns out to bestraightforward to reinterpret this probabilitydistribution as a vector of weighted terms.-3.
Cross -Language informationretr ievalAfter a brief description of the principalfunctions of an IR system, we report ourexperiments on CLIR.3.1.
The  tasks of  an IR  systemAn IR system performs three main tasks \[9\] :?
document indexing?
query indexing?
matching the query and the documentsDocument indexing creates an internalrepresentation (for example, a vector) for eachdocument.
Before indexing can beaccomplished.
We proceed the following pre-processing:Morphological analysis: each word istransformed into a canonical, citation form.For example, nouns and (French) adjectivesare transformed into their masculine singularform, and verbs are transformed into theirinfinitive forms.
This neutralization ofirrelevant differences in form often reducesretrieval silence.- Elimination of grammatical words: wordsthat are more or less semantically empty areuseless for IR.
Such words are eliminated inorder to reduce the size of the index and speedup the search process.For the indexing process, each document isrepresented as a set or a vector of weightedterms (words in canonical form).
Term weightis determined by the following two factors:?
( ( te rm frequency): the relative frequency ofthe term in the document; and?
idf(inverse document frequency): a measureof the non uniformity of the distribution ofterm across documents of the collection.The terms that rank best within a document dare those that are at the same time frequentwithin d and distributed unevenly in thecollection of documents.
The tt'*idf weigthingschema combines these two criteria \[3, 9\].
Todetermine the weight wt, of term t i indocument d we used the following variant of0 idf.wt= \[log(f(ti, d)) + 1\] * log (N/n)where f(ti, d) is the frequency of term t i indocument d, N is the total number ofdocuments in the collection, and n is thenumber of documents including ti.The indexing process maps each documentand query onto a vector of weights within thevector space of the indexes of the corpus.
Forexample,Vector space:d---~q--~<t 1, t 2, ..., tn><Wd,, we,..., we><Wq , Wq2, ..., Wq >21where Wd, and Wq, are the weights of t i indocument d and query q.The indexing process for queries is the same:Query matching involves measuring thedegree of similarity sim(d, q) between thequery vector q and each document vector d. Inour case, sim(d, q) is calculated as follows:~i=l,n(Wd, * Wq)sim(d, q)=\[~i=l,n(W d ' 2) ,  ~i=l,n(Wq2)\] 112The IR system then produces a list ofdocuments sorted by order of similarity withthe query.3.2.
Exper imentsOur experiments are conducted on a Frenchcorpus used in TREC-6 (Text RetrievalConference) \[8\].
The corpus contains acollection of articles from a Swiss newspaper- SDA (Schweizerische Depeschen Agentur) -French edition, published between 1988 and1990.
There are 141,656 documents, for atotal size of 87 megabytes.
TREC-6 dataincludes 25 queries, each written in English,French and German versions.
Manualevaluations for 22 of these have been madeavailable by NIST (National Institute ofStandards and Technology).
Our evaluationsare based on this data: the French documentsand the French and English queries.We compared five different approaches:1.
Monolingual French query-Frenchdocuments IR.
This is not CLIR, but is used asa reference point with which CLIRperformance is compared.In the other approaches, the English query istranslated into a French query using varioustools.
The translated queries are then used toretrieve French documents in the same way asin monolingual IR.
We tested the followingtranslation approaches :2.
Using MT systems (two of them: LOGOSand SYSTRAN) ;3.
Using a bilingual dictionary only;4.
Using a probabilistic translation model;5.
Combining 3 and 4.Each approach is now described in detail.Monolingual IRThe classical vector space model described inSection 3.1 is used.
System performance isassessed by a standard IR method: averageprecision over 11 points of recall.
We use theterm IR effectiveness to refer to this particularmeasure.In this monolingual task, our averageprecision for the 22 queries was 37.31%.
Atthe TREC-6 conference, only 13 of the 25queries had been evaluated manually byNIST.
The best performance for monolingualIR was 45.68% for the 13 queries.
For thesame set of queries, we obtain a performanceof 42.93%, slightly below that of the bestsystem.CLIR using MTTwo MT systems - LOGOS and SYSTRANwere used.
The first three test queries arereproduced here:English queries :?
Reasons  for cont roversy  sur round ingWaldhe im's  Wor ld  War  II ac t ions .?
Are  marr iages  increas ing  wor ldwide??
What  measures  are  be ing  taken  tos tem in ternat iona l  d rug  t ra f f i c?LOGOS translations:?
.
Ra isons  pour  les ac t ions  de deux i~meguer re  mond ia le  d' entourer  decont roverse  ?Waldhe im'  s.?
Les mar iages  augmentent - i l s  dans  lemonde ent ie r  ??
Que l les  mesures  sOnt  pr i ses  pourconten i r  la c i rcu la t ion  dem4dicament  in ternat iona le  ?SYSTRAN translations:?
Ra isons  pour  la po l~mique  entourantdes ac t ions  de  la deux i~me guer remond ia le  de Waldhe im.?
Sont des mar iages  augmentant  dans  lemonde ent ie r  ??
Que l les  mesures  sont  p r i ses  aut raf ic  de s tup4f iants  in ternat iona lde t ige  ?LOGOS flags the words missing from itsdictionary with a question mark.
In the case ofthe first query, the missing word Waldheirawill still be considered during indexingbecause there are French documents thathappen to contain it (fortunately, propernames tend to be preserved intact intranslations).
In other cases, words that theMT system did not know will end up beingignored at indexing.
For example, one of ourqueries contained the rare word "reusage"which none of our MT systems knew.As stated earlier, the (sometimesquestionable) quality of translations withrespect o syntactic structure has little effecton IR effectiveness.
What is important is thechoice of correct arget language quivalents.22Both LOGOS and SYSTRAN producedseveral instances of inappropriate choice.
Forexample, one of our queries contained "drugtraffic"; while SYSTRAN correctly translatedthis term as "trafic de drogue", LOGOSincorrectly translated it as "circulation demrdicament".
The same query contained theword stem used as a verb and SYSTRANmistranslated it as the noun "tige" ("treestem").
Such errors lead to retrievingirrelevant documents.Because MT systems choose a uniqueequivalent for each source language term, theresulting query sometimes misses documentscontaining different but related words.
Forexample, the meaning of "drug" in the senseof Query 3 may be expressed as "drogue" or"stuprfiant" in French.
By choosing totranslate "drug" only by "drogue", documentsdescribing "stuprfiant" cannot be retrieved.Despite these problems, the translationsproduced by LOGOS and SYSTRAN scoredrelatively high: an average precision of28.66% with LOGOS and 27.63% withSYSTRAN.
These results appear very good in"comparison with comparable tests conductedin TREC-6 \[6, 7\]: typically, the averageprecision of this method was only about ?
-2/3 as high as monolingual IR.
At the TREC-6conference, the best CLIR system for English-French IR achieved at a performance of24.35% for the 13 evaluated queries.
For thesame queries, we obtained 31.96% and28.90% using LOGOS and SYSTRANrespectively.
These performances aresignificantly better than other systemspresented atTREC6.CLIR using a bilingual dictionaryWe obtained from the Ergane project abilingual dictionary which contains 7898citation forms in English.
Each English wordis translated into one or more French words.For example:drug: remade, mrdicament, drogue,stup4fiant.increase: accro~tre, agrandir,amplifier, augmenter, 4tendre,accroissement, grossir,s'accro?tre, redoubler,accroissement.We tested a very simple approach: each wordof an English query was replaced by all theFrench equivalents listed in the dictionary.For the first 3 queries, this resulted in thefollowing word lists:Query #1cause, motif, raison.polrmique.entourer.
?waldheimmonde.guerre.iiactivitY, action.Query #2mariage.accro~tre, agrandir, amplifier,augmenter, ~tendre, accroissement,grossir, s'acco~tre, redoubler,accroissement.
?worldwideQuery #3quo i .mesure~,mesure, faille.tige, queue, tronc.international.remade, mrdicament, drogue,stup4fiant.circulation, trafic.where ?waldheim and ?worldwide areunknown words.
During indexing, the wordworldwide will be ignored whereaswaldheim will be indexed.From the above examples, we can observe thefollowing facts:In some cases, our dictionary lookup onlyproduces inappropriate translations.
Forexample, the verb "stem" used in the thirdquery is translated as a noun ( t ige ,  queue,t ronc)  .
In many other cases, inappropriatetranslations are given along with some correctones.
Thus, "'drug" receives the correctequivalents drogue and stup4fiane, butalso the inappropriate remade andm4dicaraent.
On one hand, in failing tochoose between distinct meanings of a sourcelanguage word (drogue ~ m4dicaraent) thedictionary method will produce additionalretrieval noise; on the other hand, in refrainingfrom arbitrarily selecting between targetlanguage synonyms (droguestup4fiant) the method performs a naturalquery expansion which will reduce retrievalsilence.We also observe that the dictionary is not welldistributed in the sense that less importantwords (from the IR point of view) may havemore translations than more important ones.For example, in query 2, the word "marriage"23has only one translation, whereas the word"increase" has 10 translations.
As aconsequence, documents containing a wordmeaning "increase" will have a higher chanceto be retrieved than a document about"marriage".
Bilingual dictionaries do not seemto reflect the notion of importance that isrelevant for IR.Our test queries contained few words thatwere missing from our dictionary, despite itslimited size.
No doubt, this is because thequeries were mostly about general topics.Our dictionary-translated queries scored anaverage precision of 18.33%, that is, about50% of our monolingual score.A variant of this approach consists in using abilingual terminology database instead of abilingual dictionary.
In contrast withdictionaries, terminology databases tend tocontain a lot of complex terms.
Moreover, theterms are usually classified into domains.Consequently, one would expect erminologydatabases toprovide a better basis on which tochoose accurate indices for IR queries.We tested this approach using the "Banque deTerminologie du Qurbec" (Terminologydatabase of Quebec - BTQ).
This databasecontains over 500 000 terms in English andFrench, classified into about 160 domains.Most terms are highly specialized.
Thus, thedatabase is very rich in domain-specificinformation.
On the other hand, words andexpressions of everyday language are oftenmissing.
For example, in Query 1 "Reasonsfor controversy surrounding Waldheim'sWorld War II actions", only the followingwords are found in BTQ: sur round,  i f ,ac t ion .
In addition, matched words areassigned very idiosyncratic meanings indifferent specialized omains.
In Query 2 "aremarriages increasing worldwide ?
", none ofthe words is found.
Replacing the originalquery with BTQ matches does not result inanything close to a reasonable translation.
Asa result, our average precision was only about8%, a performance well below our dictionaryapproach.
We conclude that a highlyspecialized terminology database such as BTQis not appropriate for general CLIR.CLIR using a probabilistic translationmodelQuery translation is performed as follows.
AnEnglish query e is submitted to theprobabilistic model as a single sentence so asto calculate p0~le), the probability that word fjwill occur in any translation f of e. Since fjranges over a very large vocabulary (all theFrench words observed in our trainingcorpus), we want to retain only the bestscoring words.
This is because:1) The longer the word list, the longer thetime for the retrieval process.
So a restrictionin length leads to an increase in retrievalspeed.2) As the translation model is not perfect, thelist is sometimes noisy.
This is especially truewhen the source language query containswords whose frequency was low in ourtraining corpus: probability estimations arethen notoriously unreliable.
By limiting theresulting list to an appropriate length, theamount of noise may be reduced.Thus, our "translation" of a query e will besimply made up of the n words f~ for whichp(~le) is highest.
We will experiment withseveral values of n in order to assess how thisparameter affects IR effectiveness.The following lists show the first 20 words inthe translations of the first 3 queries of ourtest corpus and their probabilities.Query #1.=0.117685affaire=O.069960waldheim=O.067383guerre=O.062125,=0.059158raison=O.048319ii=0.047925monde&O.043656controverse=0.038537entourer=0.036864mesure=O.022972mondial=O.O19244prendre=O.O18364second=O.O15948suite=O.Ol3105action=O.OllOl2susciter=O.O06899donner=O.O06639pouvoir=O.O06223cause=0.O05515Query #2mariage=O.172244?=0.152780.=0.088396augmenter=0.056274mondial=0.044127augmentation=0.042161,=0.034191monde=O.030830accro\[tre=O.O1700724hausse=O.O16589entier=O.O16356pouvoir=O.Ol1882union=0.Ol1524marier=O.O07423fait=O.005743international=O.O05516parent4=0.O05454s4paration=0.005454conna\[tre=0.005317apparent~=0.005290Query #3m~dicament=O.l10892?=0.103753mesure=0.091091international=O.086505.=0.067732trafic=O.052353drogue=O.041383,=0.040058d~couler=O.024199circulation=O.O19576pharmaceutique=O.O18728pouvoir=O.O13451prendre=O.O12588ext4rieur=O.Ol1669passer=O.007799demander=O.O07422endiguer=O.006685nouveau=O.O06016stup4fiant=0.005265produit=O.O04789Punctuation symbols are treated as ordinarywords because we did not remove them fromconsideration i our training.
This has littleimpact because they are ignored during queryindexing.
We plan to remove them altogetherin our future experiments.Some interesting facts may be observed inthese lists:I) The word translations obtained reflect thepecularities of our training corpus.
Forexample, the word "drug" is translated by,among others, "m4dicament" et "drogue", anda higher probability is attributed to"mrdicament".
This is because in the Hansardcorpus, the English "drug" refers more oftento the sense "m~dicament'" than to "drogue".2) This dependence on the training corpussometimes leads to odd translations.
Forexample, the word "bille" is considered as aFrench translation of "logging" in the Englishquery "effects of logging on desertification".This translation comes from the fact that inthe Hansard corpus "log" in English is oftentranslated as "bille de bois" in French.3) Some words are rare or even absent in ourtraining corpus, and this leads to unreliabletranslations.
For example, there was only oneoccurrence of "acupuncture" in the trainingcorpus.
Because of that, the model fails toassign a higher probability to the French"acuponcture" than to other semanticallyunrelated words that appeared in the samesentence.4) The model sometimes fail to distinguish thereal translation from noise induced by simplestatistical associations.
For example, the word"prendre" appears in the translations ofqueries 1 and 3.
It is attributed with evenhigher probabilities than the true translationwords of the query such as "second", "action"and "stup4fiant".
Statistics alone may proveinsufficient for tackling this problemcorrectly.Despite these problems, we observe that realtranslations and associated words tend toscore relatively high and appear at the top ofthe list.
When the probabilities areincorporated into the query vector used toretrieve documents, the documents containingthese words will be retrieved in priority.What use should we make of the probabilitiesthat our translation model associates to eachword?
Should we use them directly as theweights appearing in our query vector?Should we rather combine them with otherinformation?Notice that the probabilities assigned by thetranslation model are related to the tf (termfrequency) criterion of IR: our definition ofp(~ le) is such that each individual occurrenceof a word e~ in the query e will reinforce thef~'s that are likely translations for e,.However, our translation model has little tosay about the other criterion that is soimportant in IR: idf (inverse documentfrequency).
One possible way to derive ao~idf-like weighting is to use the followingtransformed weight in the query vector:wq = p(~l e) * log(N/n)where p(fjl e)is the probability obtained by theprobabilistic translation model, and log(N/n)represents the idf criterion as described insection 3.1,In our experiments, we tested ifferent lengthsof the list of translation words, as well as thetwo weighting methods in query vectors.
Thefollowing table shows the IR effectivenessobtained in different cases.25Length of thelist oftranslationwords1020304050100Using the Using theprobability transformedas weight weight23,45% 25,46%24,15 % 26,35%24,28% 26,60%24,33% 26,64%24,38% 26,71%22,51% 25,06%We observe that when the length of thetranslation word list increases from 10 to 50,the retrieval effectiveness increases lightly.However, when the length becomes too high(100), the effectiveness declines.
Thisphenomenon may be explained as follows: themore words we retain in the translation: 1) themore related words get to be included; but 2)the more unrelated words get to be included aswell.
A good compromise is needed.Comparing lists of length 100 with shortenones confirms our intuition that ignoringwords with low probabilities reduces the riskof incorrect word associations, thus the risk ofretrieving irrelevant documents.It is also evident that the transformedweighting which takes into account he idfocrtedon produces better results thantranslation probabilities alone.
This is justanother confirmation of the importance of theidf-cntedon i IR.To compare with the systems participating inthe TREC-6 trial, we evaluated our systemusing transformed weight, at the lengths of 20and 50.
We obtain 29.71% and 29.97% inperformance r spectively.We mentioned above that our probabilistictranslation model is sometimes unable todistinguish true translations from accidentalstatistical associations.
We thought it mighthelp to incorporate additional evidence of atrue translation relationship if any suchevidence was available.
It is often the case inIR that combining different sources ofevidence increases IR effectiveness.
This iswhy we tried combining our probabilistictranslation model with the bilingual dictionarymentioned above.Combining the probabilistic translationmodel with a bilingual dictionaryA problem arises in such a combination due tothe different nature of each element: one isweighted and the other is not.
In other words,the question is the following: if a French wordis a translation of an English word in thebilingual dictionary, how much should weincrease the weight (probability) of thistranslation in the probabilistic model ?
Ourgoal was not to provide a theoretically wellfounded answer to that question but simply tosee if a simple-minded solution would proveuseful in practic e. We tested the followingapproach: when a French translation is storedin the bilingual dictionary, its probability isincreased by a default value, a constantdetermined manually.
The new "probability"is used to obtain the transformed weight forthe query vector as before.
We tested severaldefault values, ranging from 0.005 to 0.05.The following table shows the IReffectiveness obtained in each case.Length of the list of translation wordsDefault 10 20 30 40value0.005 !26,71 27,87 28,12j28,130.01 i27,55 28,73 28,911 28,960.02 128,73 29,59 29,62\[ 29,670.03 128,11 29,06 28,98!
28,970.04 127,51 28,42 28,271 28,260.05 126,87 27,61 27,29!
27,2950 !lO028,29 !26,7129,06 !27,4229,85 i28,2529,04:27,4428,31 126,8327,30 25,78First and foremost, note that in all cases thecombined resources yield better retrievaleffectiveness than either the probabilisticmodel alone or the bilingual dictionary alone.This strongly confirms our intuition thatcombining two sources of information shouldproduce better esults.In many of the tested cases the combinedapproach outperform the MT systems.
In thecase where the default value is 0,02, and 50translation words are retained, we obtainedthe best effectiveness 29,85% (among all thetested cases).
It may be claimed here thatthere are better tools for CLIR than MTsystems.
For the 13 queries used in the TREC-6 tests, we obtain 34.26% and 30.49% for thecases where the default value is set at 0.02,and the lengths at 20 and 50.
Theseperformances are excellent in comparing withthe best systems at the TREC-6 conference(24.35%).Although the improvements in effectivenessof the combined approach over MT systemsobtained so far are still small, we think that26this approach may be further improved by 1)using a better training corpus; 2) using a morecomplete bilingual dictionary; and 3) a bettermethod of combination.
It is also possible tocombine our probabilistic translation modelwith an MT system.
As these two methods arebased on different knowledge sources, theresults could well prove superior too.
We planto examine this combination i the future.4.
ConclusionsMT systems are considered by many asappropriate tools for CLIR.
In this paper, weshowed that there are better tools for CLIRthan MT.
We investigated the possibility ofusing a probabilistic translation model builtautomatically from a parallel corpus.
Incomparison with MT, this approach is moreflexible.
It may be used for any pair oflanguages for which an appropriate parallelcorpus is available.When applied to CLIR, MT systems (LOGOSand SYSTRAN) can give a relatively goodperformance.
Simpler approaches based onlyon bilingual dictionaries or terminologydatabases like BTQ lead to much poorerperformance.
Our probabilistic translationmodel almost rivals the performance of theMT systems, despite the fact that our trainingcorpus is not closely related to the test corpus.In our experiments, we observed differentadvantages and disadvantages for differentapproaches to translate queries from alanguage to another.
They often havecomplementary properties, and may besuccessfully combined.
In this study, wecombined our probabilistic translation modelwith a bilingual dictionary.
This combinationoutperformed the MT systems, leading us tothe conclusion that there are better approachesto CLIR than MT.In all cases, the performance of CLIRremains substantially lower than that ofmonolingual IR.
Thus there is still a lot ofroom for further improvement.
There may notbe any single translation method that will fillthe bill.
We believe that progress is likely tocome from combining various sources oftranslation knowledge and we intend tocontinue testing such methods in our futureresearch.References1.
J. Brousseau, C. Drouin, G. Foster, P.Isabelle, R. Kuhn, Y. Norrnandin, and P.Plamondon., French speech recognition inan automatic dictation system fortranslators: the TransTalk project.Eurospeech 95, Madrid, Spain, 193-196(1995).2.
P. F. Brown, S. A. D. Pietra, V. D. J. Pietra,and R. L. Mercer, The mathematics ofmachine translation: Parameter estimation.Computational Linguistics, vol.
19, pp.
263-312(1993).3.
C. Buckley, Implementation f the SMARTinformation retrieval system.
ComellUniversity, Technical report 85-686, (1985).4.
M. Dymetman, J. Brousseau, G. Foster, P.Isabelle, Y. Normandin, and P. Plamondon,Towards an automatic dictation system fortranslators: the TransTalk project.
ICSLP94, Yokohama, Japan, 691-694 (1994).5.
G. Foster, P. Isabelle, and P. Plamondon,Target-text Mediated Interactive MachineTranslation.
Machine Translation, vol.
12,pp.
175-194 (1997).6.
W.A.
Gale, K.W.
Church, A program foraligning sentences in bilingual corpora,Computational Linguistics, 19:1, 75-102,(1993).7.
G. Grefenstette, Cross-LanguageInformation Retrieval.
: Kluwer AcademicPublisher, (1998).8.
D. K. Harman and E. M. Voorhees, TextREtrieval Conference (TREC-6).Gaithersburg, (1997).9.
G. Salton and M. J. McGill, Introduction toModern Information Retrieval: McGraw-Hill (1983).10.
M. Simard, G. Foster, P. Isabelle,UsingCognates to Align Sentences in ParallelCorpora, Proceedings of the 4 ~ InternationalConference on Theoretical andMethodological Issues in MachineTranslation, Montreal (1992).27
