Listen-Communicate-Show (LCS): Spoken LanguageCommand of Agent-based Remote Information AccessJody J. Daniels and Benjamin BellLockheed Martin Advanced Technology Laboratories1 Federal Street, A&E 3WCamden, NJ 08102{jdaniels, bbell@atl.lmco.com}ABSTRACTListen-Communicate-Show (LCS) is a new paradigm for humaninteraction with data sources.
We integrate a spoken languageunderstanding system with intelligent mobile agents thatmediate between users and information sources.
We have builtand will demonstrate an application of this approach calledLCS-Marine.
Using LCS-Marine, tactical personnel canconverse with their logistics system to place a supply orinformation request.
The request is passed to a mobile,intelligent agent for execution at the appropriate database.Requestors can also instruct the system to notify them whenthe status of a request changes or when a request is complete.We have demonstrated this capability in several field exerciseswith the Marines and are currently developing applications ofthis technology in new domains.KeywordsSpoken language understanding, agents, dialoguemanagement.1.
INTRODUCTIONAn LCS system listens for information requests, communicatesboth with the user and networked information resources, andshows a tailored visualization to the individual user.
TheLCS-Marine system employs a spoken language understandingsystem (SLS) for assisting the user in placing a request andmobile, intelligent agents for information access to implementthe LCS paradigm.
The SLS converses with the user to generatea request or to check status, amend, or cancel an existingrequest.
Once sufficient information is obtained from the user,the SLS launches an agent to accomplish the requested task.The agent accesses the appropriate databases via whatevernetwork services are available (including existing tacticalcommunications networks).
Once the agent's tasks arecomplete, it returns to the SLS, which generates an appropriateresponse to the user.
The response may be visual, verbal, or acombination, depending on the available devices.2.
SYSTEM OVERVIEWThe LCS-Marine system consists of four major components: anSLS, a collection of agents for information access, real-worldoperational databases, and communications networks toconnect the user to the SLS and the agents to the databases.The underlying architecture for the system is the MIT Galaxy IIconversational architecture [3].
It is a distributed, component-based middleware product designed to be ?plug and play?.Specialized servers handle specific tasks, such as translatingaudio data to text.
All Galaxy II-compliant servers com-municate with each other through a central server known as theHub.
The Hub manages flow control, handles traffic amongdistributed servers, and provides state maintenance.In the SLS, speech is sent from the Audio I/O server to theRecognizer.
The top n recognitions are then parsed, priorcontext added, and processed using the Natural Language(NL) servers (Frame Construction and Context Tracking) toverify the new input's validity and context.
The Turn Manager(TM) determines how to proceed with the conversations andgenerates a response.
NL (Language Generation) converts it totext and the Synthesis server generates the verbal response.The audio server then speaks the waveform file to the user.
Wecustomize the various servers to work with domain specificissues and application-specific information and training.Figure 1 shows our LCS architecture.TINAInfo-ServerGENESISText-to-SpeechConversionText-to-SpeechConversionHUBSUMMITSAPIAudioServerAudioServerContextTrackingContextTrackingSpeechRecognitionSpeechRecognitionFrameConstructionFra eConstructionLanguageGenerationLanguageGenerationTurnManagerTurnanagerAgentServerAgentServerFigure 1.
The LCS-Marine architecture.We have integrated an additional server into the architectureto support information access?an Agent server.
The Agentserver manages a collection of agents that can be tasked toaccomplish a variety of missions, including migration todistant machines with possibly different operating systems togather information or to monitor and report events [2].Typically, the Agent server receives its tasking from the TMand supplies the TM with information from the data source(s).For persistent tasks, the Agent server becomes the initiator of adialogue to inform the user of specific events by passing agentreports to the TM.
When a visual display is present, the Agentserver will dispatch an agent to pass the updated informationto the display machine.For the LCS-Marine application our agents had to interactwith a logistics database that could be between one to onehundred miles away.
We later describe how our agents wereable to reach this live database over the tactical communicationlinks available.Users interact with the LCS-Marine system using the voicecapture device appropriate to their organization (telephone,cell phone, tactical radios, computer headsets, etc.).3.
MARINE COMBAT SERVICE SUPPORTPROBLEMMarines work in a dynamic, fluid environment whererequirements and priorities are constantly subject to change.Under current operations, it might take up to 72 hours before aMarine in a Combat Service Support Operations Center(CSSOC) can confirm with a requesting unit that their order i sin the logistics system.
This is due to a lack of resourcesavailable to the tactical units as well as a difficulty in turninglogistics data into information to enable timely analysis anddecision making.
For Marines conducting tactical operations,these restrictions and limited visibility into the supply chainhamper logistics planning, decision, execution, and assess-ment.
Figure 2 shows the various echelons involved in tacticalMarine logistics operations.
It is noteworthy that tacticalunits have no organic means of accessing the logisticaldatabases other than via radio contact with personnel at theCSSOC.The focus of the LCS-Marine project is to provide Marines inthe field with this missing visibility into the supply chain.
Byusing standard radio protocols and a common form, Marinescan now converse with a system that understands their taskand end goal and can assist them in getting both theinformation and supplies they need.
Figure 3 shows a sample ofthe Rapid Request form, used when placing an order.Supporting the LCS-Marine domain required understandingand using proper radio protocols to communicate.
It requiredthe system to understand call signs, military times, gridcoordinates, and special ordinance nomenclature.
Additional-ly, to fully support the dynamic environment, LCS-Marineneeded the ability to understand and translate usages of themilitary phonetic alphabet.
This alphabet is used to spelldifficult or unusual words.
For example, to give the point ofcontact for the request as Sergeant Frew, the user could say: ?
PO C is Sergeant I spell Foxtrot Romeo Echo Whiskey over.
?LCS-Marine would convert the phonetic words to the properletter combination.
This way the vocabulary is potentiallymuch larger than that used for system training.Supporting the dynamic aspects of the Marine environment, thesystem is speaker independent.
This is critical in applicationswhere the user may change and there is no additional time fortraining the system for a new operator.The recognizer is trained on the domain vocabulary, but not onindividual operator voices.
The system also fully supportsnatural, conversational dialogue, i.e., the recognizer expectsutterances at a normal rate of speech and the speaker does notneed to enunciate each syllable.It is important to note that the amount of time spent trainingpersonnel to use the LCS-Marine system is generally less than10 minutes.
After a short introduction, the user is shown asample dialogue for familiarization.
The user is also giveninformation about meta-instructions ?
how to start over or toclear their previous statement ?
before they begin operation.4.
OPERATIONAL EVALUATIONTo measure the effectiveness of the LCS paradigm underoperational conditions?real users placing real requests,accessing a live database, and using existing communicationslinks?we conducted a series of Integrated FeasibilityExperiments (IFE).
The IFEs ranged from a pilot study thatfeatured scripted dialogue, replicated databases, and testing inthe lab with prior military personnel, to field experimentswhere active duty Marines used the system operationally overa series of days as their sole means of interaction with thelogistics system for rapid requests.
We tested the system?ssupport of placing and checking on requests for ammunition(Class V), fuels (Class III), and subsistence (Class I) supplies.More on the experimentation protocols can be found in [1] and[4].RF LANVOICE AND DATARover?sSustainmentandDistributionTeams (SDT)AMMOPEOPLEFSSGCSSOC(MAIN)BSSG/CSSDCSSOC(MEDIUM)VIXIIIIIV VIIIIIBE01567N10234E TKS ON ROADBE01567N10234E TRPS IN OPENBE01567N10234E 4xTEL?S 12 MTI MOV NEBE01567N10234E ADA SITEBE01567N10234E UNK MOV SEBE01567N10234E 4xTEL?SBE01567N10234E 12 MTI MOV NEUNK MOV SEBE01567N10234E TKS ON ROADCISECS NTServer(s)MSSG/MCSSDCSSOC(SMALL)V IIIVIIIIWAN 1-5MBSReplicated DBMSOf CSS Data/StatusCISBE01567N10234E TKS ON ROADBE01567N10234E TRPS IN OPENBE01567N10234E 4xTEL?SBE01567N10234E 12 MTI MOV NEBE01567N10234E ADA SITEBE01567N10234E UNK MOV SEBE01567N10234E 4xTEL?SBE01567N10234E 12 MTI MOV NEUNK MOV SEBE01567N10234E TKS ON ROADECS NTServer(s)Figure 2.
The Marine logistics ordering chain.Figure 3.
Partially Complete Rapid Request Form along with a portion of the database.Over the course of the IFE process we were able to experimentwith differing server configurations as well as varying com-munications linkages between servers.
The most recent IFE(December 2000) used the server layout shown in Figure 4.Win NT/95/98 LinuxAgentServerAgentDockSynthesisAudio-In/Out .wavTextDisplay info*DB request*Turn MgmtRecog NLUser?s PCSPhone/Laptop/HandheldSLS ServerLaptop/Handheld*Compressed toreduce bandwidthHUBAgentDockGPS LCS AppsDisplayDbmsFigure 4.
The physical LCS-Marine server layout.The ideal configuration of the system would have a Marineusing their organic communications system calling in to aremote location and communicating with the SLS there.
Thiswould not add any additional cost or hardware to the existingMarine infrastructure.
This operational layout is depicted inFigure 5.
Unfortunately, the current tactical radio, the SingleChannel Ground and Airborne Radio System (SINCGARS),can create a large amount of channel noise, which alters ordistorts the acoustic signal.
Current recognizers can not yetcompensate for this distortion, although there is activeresearch into solving this problem.We used a second operational layout to test the system and getoperator feedback on using a spoken language understandinginterface.
This layout is depicted in Figure 6.
In this layout, werequired the user to beat the same location as the entire SLSsystem  and  the agents migrated over the SINCGARS data linkUser CSSOCDBDatabase,AgentsVIIIISpoken LanguageSystem, AgentsSINCGARS(voice)User RequestSINCGARS(data)Mobile AgentHMMWVFigure 5.
The ideal LCS-Marine operational layout.CSSOCUser/HMMWVDatabase,AgentsSpoken LanguageSystem, AgentsSINCGARS(data)V IIIIMobile AgentDBFigure 6.
The LCS-Marine actual operational layout.to reach the logistics database.
The recognizer still had tocontend with the issue of a noisy and dynamic background,but the acoustic distortion was eliminated.5.
CONCLUSIONWe have built a system that integrates a spoken languageunderstanding system with a mobile, intelligent agent systemthat allows users in a hostile acoustic environment to placeand access data requests via a conversational interface.
LCS-Marine is speaker independent and requires little training.
Thetime to accomplish a task is significantly lower than themanual input method it seeks to enhance, but it can still beimproved.
Being able to rapidly access, insert, modify, anddelete requests gives the users greater visibility into thesupply system.6.
ACKNOWLEDGMENTSThanks to members of the LCS team: James Denny, Jerry Franke,Ray Hill, Bob Jones, Steve Knott, Dan Miksch, Kathy Stillerand Mike Thomas.
This research was supported by DARPAcontract N66001-98-D-8507 and Naval contract N47406-99-C-7033.7.
REFERENCES[1] Daniels, J.
Integrating a Spoken Language System withAgents for Operational Information Access.
In Proc.. o fInnovative Applications of Artificial Intelligence (IAAI-2000), August, 2000, Austin, TX.
[2] McGrath, S., Chac?n, D., and Whitebread, K. IntelligentMobile Agents in the Military Domain.
In Proc.. OfAutonomous Agents 2000 Workshop on Agents inIndustry.
Barcelona, Spain.
[3] Seneff, S., Lau, R., and Polifroni, J.
1999.
Organization,Communication, and Control in the GALAXY-II Conver-sational System.
In Proc.. of Eurospeech ?98.
Budapest,Hungary.
[4] Stibler, K., and Denny, J.
A Three-tiered Evaluation Ap-proach for Interactive Spoken Dialogue Systems.
In Proc..of the Human Language Technology Conference HLT-2001, Mar, 2001, San Diego, CA.
