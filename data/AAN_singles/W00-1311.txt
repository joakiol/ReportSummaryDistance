Detection of Language (Model) ErrorsK.Y.
Hung, R.W.P.
Luk, D. Yeung, K.F.L.
Chung and W. ShuDepartment ofComputingHong Kong Polytechnic UniversityHong KongE-mail: {cskyhung, csrluk, csdaniel, cskchung, cswshu}@comp.polvu.edu.hkAbstractThe bigram language models are popular, inmuch language processing applications, inboth Indo-European and Asian languages.However, when the language model forChinese is applied in a novel domain, theaccuracy is reduced significantly, from 96% to78% in our evaluation.
We apply patternrecognition techniques (i.e.
Bayesian, decisiontree and neural network classifiers) todiscover language model errors.
We haveexamined 2 general types of features: model-based and language-specific eatures.
In ourevaluation, Bayesian classifiers produce thebest recall performance of 80% but theprecision is low (60%).
Neural networkproduced good recall (75%) and precision(80%) but both Bayesian and Neural networkhave low skip ratio (65%).
The decision treeclassifier produced the best precision (81%)and skip ratio (76%) but its recall is the lowest(73%).IntroductionLanguage models are important post-processingmodules to improve recognition accuracy of awide variety of input, namely speech recognition(Balh et al, 1983), handwritten recognition(Elliman and Lancaster, 1990) and printedcharacter ecognition (Sun, 1991), for manyhuman languages.
They can also be used for textcorrection (Ron et al, 1994) and part-of-speechtagging.For Indo-European languages, the word-bigramlanguage model is used in speech recognition(Jelinek, 1989) and handwriting recognition(Nathan et al, 1995).
Various ways to improvelanguage models were reported.
First, the modelhas been extended with longer dependencies ( .g.trigram) (Jelinek, 1991) and using non-contiguousdependencies, like trigger pairs (Rosenfeid, 1994)or long distance n-gram language models (Huanget al, 1993).
For better probability estimation, themodel was extended to work with (hidden) wordclasses (Brown et al, 1992, Ward and Issar, 1996).A more error-driven approach is the use of hybridlanguage models, in which some detectionmechanism (e.g.
perplexity measures \[Keene andO'Kane, 1996\] or topic detection \[Mahajan et al,1999\]) selects or combines with a moreappropriate language model.For Asian languages (e.g.
Chinese, Japanese andKorean) represented by ideographic haracters,language models are widely used in computerentry because these Asian languages have a largeset of characters (in thousands) that theconventional keyboard is not designed for.
Apartfrom using speech and handwriting recognitionfor computer entry, language models for Asianlanguages can be used for sentence-basedkeyboard input (e.g.
Lochovsky and Chung, 1997),as well as detecting improper writing (e.g.
dialect-specific words or expressions).Unlike Indo-European languages, words in theseAsian languages are not delimited by space andconventional approximate string matchingtechniques (Wagner and Fisher, 1974; Oommenand Zhang, 1974) in handwriting recognition areseldom used in Asian language models.
Instead, awidely used and reported Asian language model isthe character-bigram language model (Jin et al,1995; Xia et al, 1996) because it (1) achievedhigh recognition accuracy (around 90-96%) (2) iseasy to estimate model parameters (3) can beprocessed quickly and (4) is relatively easy toimplement.Improvement of these language models for Indo-European languages can be applied for the Asianlanguages but words need to be identified.
ForAsian languages, the model was integrated withsyntactic rules (Chien, Chen and Lee, 1993).Class based language model (Lee and Tung, 1995)was also examined but the classes are based onsemantically related words.
A-new approach(Yang et al, 1998) is reported using segments87expressed by prefix and suffix trees but thecomparison is based on perplexity measures,which may not correlate well with recognitionimprovement (Iyer et al, 1997).While attempts to improve the; (bigram) languagemodels were (quite) successful, the highrecognition accuracy (about 96%) is not adequatefor professional data entry services, whichtypically require an error rate lower than 1 in1,000.
As part of the quality control exercises,these services estimate their error rate bysampling, and they identify and correct he errorsmanually to achieve the required quality.
Facedwith a large volume of text, the ability toautomatically identify where the errors are isperhaps more important than automaticallycorrecting errors, in post-editing because (1)manual correction is more reliable than automaticcorrection, (2) manual error sampling can becarried out and (3) more manual efforts arerequired in error identification than correction dueto the large volume of text.
For example, if theidentification of errors is 97% and there are noerrors in error correction, then the accuracy of thelanguage model is improved from 96% to 99.9%after error correction.In typical applications, the accuracy of the bigramlanguage model may not be as high as thosereported in the literature because the data may bein a different genre than that of the training data.For evaluation, we tested a bigram languagemodel with text from a novel domain and itsaccuracy dropped significantly from 96% to 78%,which is similar to English (Mahajan et al, 1999).Improvement in the robustness of the bigramlanguage model across different genre isnecessary and several approaches are available,based on detecting errors of the language model.One (adaptive) approach is to automaticallyidentify the errors and manually correcting them.The information about the correction of errors isused to improve the bigram language model.
Forexample, the bigram probabilities of the languagemodel may be estimated and updated with thecorrected ata.
In this way, future occurrences ofthese rrors are reduced.Another (hybrid) approach uses another languagemodel to correct the identified errors.
Thislanguage model can be computationally moreexpensive than the bigram language modelbecause it is applied only to the identified errors.Also, topic detection (Mahajan et al, 1999) andlanguage model selection (Keene and O'Kane,1996) can be applied to those area to find a moreappropriate language model because usuallytopic-dependent words are those causing errors.Another (integrative) approach improves thelanguage model accuracy using moresophisticated recognizers, instead of acomplementary language model.
The moresophisticated recognizer may give a set ofdifferent results that the bigram language modelcan re-apply on or this recognizer simply givesthe recognized character.
This integrates well withthe coarse-fine recognition architecture proposedby Nagy (1988) back in the 1960s.
Coarserecognition provides the candidates for thelanguage model to select.
Fine, expensiverecognition is carried out only where the languagemodels failed.
Finally, it is possible to combine allthe different approaches (i.e.
adaptive, hybrid andintegrative).Given the significance in detecting errors oflanguage models, there is little work in this area.Perhaps, it was considered that these errors wererandom and therefore hard to detect.
However,users can detect errors quickly.
We suspect hatsome of these errors may be systematic due to theproperties of the language model used or due tolanguage specific properties.We adopt a pattern recognition app~'~z, ch todetecting errors of the bigram language rnoaei forthe Chinese language.
Each output is assigned toeither the class of correct output or the class oferrors.
The assignment of a class to an output isbased on a set of features.
We explore a numberof features to detect errors, which are classifiedinto model-based features and language-specificfeatures.The proposed approach can work with Indo-European languages at the word-bigram level.However, language-specific eatures have to bediscovered for the particular language.
In addition,this approach can be adopted for n-gram languagemodels.
In principal, the model-based features canbe found or evaluated similar to the bigramlanguage model.
For example, if the trigramprobability (instead of bigram probability) is low,then the likelihood of a language model error ishigh.This paper is organized as follows.
Section 1discusses various features and some preliminaryevaluation of their suitability for error88identification.
Section 2 describes 3 types ofclassifiers used.
In section 3, our evaluation isreported.
Finally, we conclude.1.
FeaturesWe evaluate individual features for error detectionbecause they are important to the success ofdetection.
Articles from Yazhou Zhoukan (YZZK)magazine (4+ Mbytes)/PH corpus (Guo and Liu,1992) (7+ Mbytes) are used for evaluation.
Weuse the recall and precision measurements forevaluation.
The recall is the number of errorsidentified by a particular feature divided by thetotal number of errors.
The precision is thenumber of errors identified by a particular featuredivided by the total number of times the featureindicate that there are errors.
In the firstsubsection, we describe some model-basedfeatures.
Next, we describe the language-basedfeatures.
In the last subsection, we discuss thecombined use of both types of features.1.1 Model-based featuresThe bigram language model selects the mostlikely path Pm~ out of a set S. The probability of apath s in S is simply the product of the conditionalprobabilities of one character c, after the other c~.lwhere s = Co.C+..c:s:, after making the Markovassumption.
Formally,Pm~ = arg max {p(s)}s~S= arg~ax{p(Co)I~IP(cilC,_l)\[coC,...c,,== s}The set s is generated by the set of candidatecharacters for each recognition output.
Therecognizer may supply the set of candidatecharacters.
Alternatively, a coarse recogniser maysimply identify the best-matched group or class ofcharacters.
Then, members of this class are thecandidate characters.
Formally, we use a functionh(.
), that maps the recognition position to a set ofcandidate characters, i.e.
h(i) = {ciJ.
We can alsodefine the set of sentences in terms of h(.
), i.e.
S ={s I s = cocz...c,, ~ ,  c, ~ h(i)}.1.1.1 Features based on zero probabilities (Fl,t)One feature to detect errors is to count the numberof conditional probabilities p(cilc~.l) that are zero,between 2 consecutive positions.
Zero conditionalprobabilities may be due to insufficient rainingdata or may be because they represent thelanguage properties.
Figure 1 shows the likelihoodof an error occurring against he percentage of theconditional probabilities that are zero.60%50%40% - -30%20%10%0%50% 60% 70% 80% 90% 100% 110%Figure 1: The language model output errors againstpercentages ofzero conditional probabilities.1.1.2 Features based on low probability (Fl,z)When there are insufficient data, the conditionalprobabilities that are small are not reliable.
IfPm~have selected some conditional probabilities thatare low, then probably there are no other choicesfrom the candidate sets.
Hence, the insufficientdata problem may occur in that particular Pm~.In Figure 2, we plot the likelihood of errorsidentified against the different logarithmicconditional probability values.
When the recallincreases, unfortunately, the precision drops.120% \[100%\[ : ~ prec i s ion  .~ ,~ ' -  !80% l : ~  reca l l  .
.
.
.
.
.
.
/ | AccuracyL 6?% \[ , ,  - .
.
.
.t .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
-!
I20% .
.
.
.
- \  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
-I \] I I I  \[0% I~ .
.
.
.
.
.
.
.
.
.
.Figure 2: The precision, recall and accuracy (i.e.
recallx precision) of detecting language model errors byexamining the logarithm conditional probabilities onthe maximum likelihood path.1.2 Language-specific FeaturesThe language-specific features are based onapplying the word segmentation algorithm (Kit etal., 1989) to the maximum likelihood path.
TheROCLING (Chen and Huang, 1993) word listused for segmentation has 78,000+ entries.891.2.1 Features based on word length (F2,OIf the matched word in the maximum likelihoodpath is long, then we expect he likelihood of anerror is low because long words are specific.Figure 3 shows the precision of  detecting thematched word is correct and the recall of errors inmulti-character words.
In general, the longer thematched words, the more likely that they arecorrect and the likelihood of missing undetectedlong words is small.120%lOO%00%60%40%20%o;?
precision ..1 2 3 4 5 6 7 aFigure 3: The precision of correct matched wordsagainst word lengths.1.2.2 Features based on single-charactersequences (F2,z)In word segmentation, when there are no entriesin  the dictionary that can match, the input issegmented into single characters.
Thus, Lin et al(1993) noted that single-character sequences afterword segmentation might indicate segmentationproblems.
Here, we apply the same technique forthe detection of errors.
If we count on the percharacter basis, the recall of error is 80% and theprecision in error identification is 35%.
If wecount multi-character words and a sequence ofsingle-characters a blocks, then the recall oferrors is 79% and the precision in finding one ormore errors in the block is increased to 51%.120% .
.
.
.
.
.
.
.
.
.
.
.20% .
.
.
.
.
.
.
.
:0% .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 2 3 4 5 6 7 8Figure 4: The precision and recall of single-charactersequences of different lengths.Similar to matched words in the maximumlikelihood path, the error detection performance ofsingle-character sequences may depend on theirlength.
Therefore, we plotted the recall andprecision of detecting errors against he length ofthe single-character sequences.
According toFigure 4, as the length of the single-charactersequence is large, the likelihood of an error islarger.
The recall of errors is particularly low forsingle-character sequences that have 2 characters.The other single-character sequences (i.e.
itslength is not equals to 2) have almost 100% recall.One possible reason why 2 single-charactersequences achieved low precision is that there aremany spurious bigrams and therefore false match.1.3 Combined use of  FeaturesWe carried out a preliminary study using thefeatures mentioned in subsection 1.1 and 1.2.
OurBayesian classifier (Section 2.1) achieved 83%recall but 35% precision, which can be achievedusing language specific features only (Fz2).Therefore, we try to combine the use of thesefeatures in a more carefiJl manner.
We divided thedetection into 3 scenarios: (1) single character(feature F2,2); (2) single-character sequence oflength 2 (feature F2,2) and (3) 2 character words(feature Fzl).
Each case is assigned a classifier todetect errors.
Single-character sequences longerthan 2 are considered as having errors (Figure 4).Words of length longer than 2 are consideredcorrect (Figure 3).1.3.1 Single charactersAfter word segmentation, single characters arethose cases when there are no multi-characterwords in the dictionary that can match with it andits following substring.
The single characters havedifferent part-of-speech tags.L~ l .......................................................................................................................................................................... i| i .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
- -~B--tiPa~cfgm:hFigure 5: The single characters and their correspondinglanguage model output accuracy for different part-of-speech tags.Figure 5 shows that the accuracy of the languagemodel for these single characters with part-of-90speech tags related to exclamations are low.
Forerror detection, a feature is assigned to each part-of-speech tag.The language model accuracy for singlecharacters may depend on the availability of theleft and right context to form high probabilitybigrams.
Therefore, we expect that languagemodel accuracy of single characters at thebeginning (70%) and end (70%) of a sentence islower than those in the middle (85%) of thesentence.
The worst case occurs when thesentence has only a single character, where themeasured accuracy is only 8.75% (i.e.
no bigramcontext).1.3.2 Two-single-characters sequenceFigure 6 shows that language model outputaccuracy increases as the bigram probability ofsingle-character sequences of length 2 increases.Hence, the bigram probabilities can be used as afeature for detection.1.2 "~................... .
/<  il.
~ / \ !Figure 6: The bigram (logarithm) probability of thesingle-character s quence of length 2.Similar to single characters, the language modelaccuracy for 2-single-characters sequences at thestart, middle and end of a sentence are 48%, 47%and 30%, respectively.
The accuracy is 33% if thesentence is the 2-single-characters sequence.I~ -  .
.
.
.
.
.
.
.
.
.
.  )
- -Q4 F .
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
/~" - - - - - - *  .
.
.
.
.
.
.ace  ) " ,~ ._~, )_____ , ) .
_~_ .___0)0 1 2 3 4 5 6 7 8nmi:er ofhiddm,,u:rdsFigure 7: Language model accuracy against differentnumber of hidden words (see text).Another feature for 2-single-characters sequencesis to examine whether the characters in the twocandidate sets can form words that match with thedictionary.
These matched words are calledhidden words.
Figure 7 shows that if there arehidden words, the language model accuracydropped from 60% to 25%.
Since there are notmany cases with 6-8 hidden words, the accuracyfor these cases are not reliable.1.3.3 Two-character wordsFor 2 character words, the bigram probability(Figure 8) can be used as a feature similar to thesingle-character sequences.
The position of these2 character words in the sentence does not relateto the language model accuracy.
Our measuredaccuracy is 91%, 89% and 91% for the beginning,the end and the middle of the sentence,respectively.
Even sentences with a single 2-character word achieved 90% accuracy.
Hence,there is no need to assign features for the positionof the 2 character words in a sentence.
Similar to2-single-characters sequences, the language modelaccuracy (Figure 9) decreases as the humber ofhidden words increase in the corresponding 2 setsof candidate characters.1.7 :o.4~- ::, !iO.2 ~ i ~ !~: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ ~+*~,-.+~.~.~.~- : .~.~.~+~..+~.~+,+~*~.~+~Figure 8: The language model accuracy of 2 characterwords against the bigram probability.=1 .
.
.
.
.
.
.
.
.
.
.
.
.o.7 ~ .
.
.
.
.
.
.
.
.
.
.
.
.0.6 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ .
- - -2 .
.
: : - '= -* - - .0,5 .
.
.
.
.
.
.
.
.
.
.
.
.0,40,3 m0 .2 -0,1 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.0 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.1 2 3 4 5 6 7 8 9number of  hidden wordsFigure 9: The language model accuracy againstdifferent number of hidden words.912 ClassifiersOne of the problems witlh using individualfeatures is that the recall and precision are notvery high, except he language-specific features.
Itis also difficult to set the threshold for detectionbecause of the precision-recall trade-off.
Inaddition, there may be some improvement indetection performance if features are combinedfor detection.
Therefore, we adopt a patternrecognition approach to detect errors.Several classifiers are used to decide for erroridentification because we do not know whetherparticular features work well with particularclassifiers, which make different assumptionsabout classification.
Three types of classifers willbe examined: Bayesian, decision tree and neuralnetwork.2.1 Bayesian Classif ierThe Bayesian classifier is simple to implementand is compatible with the model-based features.Given the feature vector x, the Bayesian detectionscheme assigns the correct class wc and the errorclass we, using the following rule:g~(x) > ge(X) assign wc.Otherwise assign wewhere go(.)
and ge(.)
are:gc (x) = -(x -/~c)r y.c-.
(x _/~,)- log l , I +2 log p(w c )g, (x)= - (x - lee)  r Z,-~(x-/~,) - log\] Z~ \] +2log p(w,)Pc and ,ue are the mean vectors of  the class wc andwe, respectively, ~ and ~ are the covariancematrices of the class wc and we, respectively, and1-I is the determinant.2.2 Decision TreeOriginally, we tried to use the support vectormachine (SVM) (Vanpik, 1995) but it could notconverge.
Instead, we used the decision treealgorithm C4.5 by Quinlan (1993).
Decision treesare known to produce good classification ifclusters can be bounded by some hyper-rectilinearregions.
We trained C4.5 with a set of featurevectors, described in Section 1.3.2.3 Neural  NetworkWe use the multi-layer perceptron (MLP) becauseit can perform non-linear classification.
The MLPhas 3 layers of nodes: input, hidden and output.Nodes in the input layer are fully connected withthose in the hidden layer.
Likewise nodes in thehidden layer are fully connected to the outputlayer.
For our application, one input nodecorresponds to a feature in section 1.3.
The valueof the feature is the input value of the node.
Twooutput nodes indicate whether the currentcharacter is correct or erroneous.
The number ofhidden nodes is 2-4, calculated according to(Fujita, 1998).The output of each node in the MLP is theweighted sum of its input, which is transformedby a sigmoidal function.
Initially, the weights areassigned with small random numbers, which areadjusted by the gradient descend method withlearning rate 0.05 and momentum 0.1.3 EvaluationIn the evaluation, the training data is the PHcorpus and the test data is the YZZK magazinearticles (4+ Mbytes), downloaded from theInternet.
In handwritten character recognition, theoptimal size of the number of candidates is 6(Wong and Chan, 1995).
For robustness, eachrecognized character in our evaluation is selectedfrom 10 candidates.We measured the performance in terms of recall,precision and the manual effort reduction inscanning the text for errors.
The recall is thenumber of identified errors over the total numberof errors.
The precision is the number of identifiederrors over the total number of  cases classified aserrors.
The amount of saving in manual scanningfor errors is called the skip ratio, which is thenumber of blocks classified as correct over thetotal number of blocks.
The recall and the skipratio are more important than the precisionbecause post error correction (manual orautomatic) can improve the recognition accuracy.It is possible to combine the recall and precisioninto one, using the F measures (Van Rijsbergen,1979) but the value for rating the relativeimportance is subjective.Table 1 shows the classification performance ofthe Bayesian classifier.
The recall of errors by theBayesian classifier has reduced slightly from 83%using a single classifier to 79% using 3 classifiersbut the precision improved from 51% to 60%.Also, the skip ratio is 65%, which is much higherthan the skip ratio of 0.1% if we did not use theclassifier.
Although the MLP has a higherprecision (80%), its recall is slightly lower than92the Bayesian classifier.
The skip ratio of the bothBayesian and MLP classifiers are about he same.Cases MeasureSingle RecallcharacterPrecision2 single RecallcharactersPrecision2-character RecallwordsPrecisionOverall RecallPrecisionSkip RatioBayes71%40%60%88%60%29%79%60%65%Table 1: The performancesC4.5 MLP56% 28%75% 71%84% 83%82% 80%17% 9%60% 62%73% 75%81% 80%76% : 66%of the 3 types ofclassifiers in detecting language model errors.4 Summary and Future WorkWe have evaluated both model-based andlanguage-specific eatures for detecting languagemodel errors.
Individual model-based features didnot yield good detection accuracy, suffering fromthe precision-recall trade-off.
The language-specific features detect errors better.
In particular,matched multi-character words are usually correct.If the model-based and language-specific featuresare aggregated asa single feature vector, the recalland precision of errors are 83% and 35%,respectively, which are the same if we just uselanguage-specific features.
Hence, instead of asingle classifier, we separated 3 situationsidentified by the language-specific eatures and 3classifiers are used to detect these errorsindividually.
The Bayesian classifier (simpliest)achieved an overall 79% recall, 60% precisionand 65% skip ratio and the MLP achieved anoverall 75% recall, 80% precision and a 66% skipratio.
Similar recall and precision performancesare achieved using decision trees, which arepreferred since their skip ratio is higher (i.e.
76%).Although the precision (so far) is not high (60% -80%), it is not the most important result because(1) this only represents a minor waste of checkingeffort, compared with scanning the entire text, and(2) the identified errors will be checked further orcorrected either manually or automatically.AcknowledgementThis work is supported by the (Hong Kong)University Grants Council under project PolyU5109/97E and the PolyU Central Research GrantG-$603.
We are grateful to Guo and Liu forproviding the PH corpus and ROCLING forproviding their word list.ReferencesBahl, L.R., F. Jelinek and R.L.
Mercer (1983) "Amaximum likelihood approach to continuousspeech recognition", 1EEE Trans.
PAM1, 5:2, pp.179-190.Brown, P.F., V.J.
Della Pietra, P.V.
deSouza ndR.L.
Mercer (1992) "Class-based n-gram modelsof natural anguage", Computational Linguistics,4, pp.467-479.Chen, K.-C. and C.R.
Huang (eds.)
(1993)"Chinese word class analysis", Technical Report93-05, Chinese Knowledge InformationProcessing Group, Institute of InformationScience, Academia Sinica, Taiwan.Chien, L.F., Chen, K.J., Lee, L.S.
(1993) "A best-first language processing model integrating theunification grammar and Markov language modelfor speech recognition applications", 1EEE Trans.Speech and Audio Processing, 1:2, Page(s): 221 -240.Elliman, D.G.
and I.T.
Lancaster (1990) "Areview of segmentation and contextual analysistechniques for text recognition", PatternRecognition, 23:3/4, pp.337-346.Fujita, O.
(1998) "Statistical estimation of thenumber of hidden units for feedforward neuralnetworks", Neural Networks, 11, 851-859.Guo, J. and H.C. Liu, "PH - a Chinese corpus forpinyin-hanzi transcription", 1SS Technical Report,TR93-112-0, Institute of Systems Science,National University of Singapore, 1992.Huang, X., F. Alleva, H. Hon, M. Hwang,, K. Leeand R. Rosenfeld (1993) "The SPHINX-II speechrecognition system: an overview", ComputerSpeech and Lanaguage, 2 137-148.lyer, R., M. Ostendorf and M~-Meteer (1997)"Analyzing and predicting language model93performance", Proc.
IEEE Workshop AutomaticSpeech Recognition and Understanding, pp.
254-261.Jelinek, F. (1989) "Self-organized languagemodeling for speech recognition", in Readings inSpeech Recognition, Morgan Kayfmann.Jelinek, F. (1991) "Up from trigrams", Proc.Eurospeech 91, pp.
181 -184.Jin, Y., Y. Xia and X. Chang (1995) "Usingcontextual information to guide Chinese textrecognition", Proc.
1CCPOL '95, pp.
134-139.Kenne, P.E.
and M. O'Kane (1996) "Hybridlanguage models and spontaneous legaldiscourse", Proc.
ICSLP, Vol.
2, pp.
717-720.Kit, C., Y. Liu and N. Liang (1989) "On methodsof Chinese automatic word segmentation",Journal of Chinese Information Processing, 3:1,13-20.Law, H.H-C. and C. Chan (1996) "N-th orderergodic multigram HMM for modeling oflanguages without marked word boundaries",Proc.
COLING 96, pp.
2043-209.Lee, H-J.
and C-H Tang (1995) "A languagemodel based on semantically clustered words in aChinese character recognition system", Proc.
3 rdlnt Conf.
on Document Analysis and Recognition,Vol.
1., pp.
450-453.Lin, M-Y., T-H. Chiang and K-Y.
Su (1993) "Apreliminary study on unknown word problem inChinese word segmentation", Proc.
ROCLING V1,pp.119-141.Lochovsky, A.F.
and K-H. Chung (1997)"Homonym resolution for Chinese phonetic input",Communications ofCOLIPS, 7:1, 5-15.Mahajan, M., D. Beeferman and X.D.
Huang(1999) "Improving topic-dependent modelingusing information retrieval techniques", Proc.1EEE ICASSP 99, Vol.
1, pp.541-544.Nagy, G. (1988), "Chinese character recognition:twenty-five-year retrospective", in Proc.
9th lnt.Conf.
on Pattern Recognition, Vol.
1, pp.
163-167.Nathan, K.S., H.S.M.
Beigi, J. Subrahmonia, G.J.Clary and H. Maruyama (1995) "Real-time on-line unconstrained handwriting recognition usingstatistical methods",Oommen, B.J.
and K. Zhang (1996) "Thenormalized string editing problem revisited",1EEE Trans.
on PAM1, 18:6, pp.
669-672.Quinlan, J.R. (1993) "C4.5 programs for machinelearning", Morgan Kaufmann, CA.Ron, D., Y.
Singer and N. Tishby (1994) "Thepower of Amnesia: learning probabilisticautomata with variable memory length", toappear in Machine LearningRosenfeld, R. (1994) "Adaptive statisticallanguage modeling" a maximum entropyapproach", Ph.D. Thesis, School of ComputerScience, Carnegie Mellon University, Pittsburgh.Sun, S.W.
(1991), "A Contextual Postprocessingfor Optical Chinese Character Recognition", inProc.lnt.
Sym.
on Circuits and Systems, pp.
2641-2644.Vapnik, V. (1995) The Nature of StatisticalLearning Theory, Springer-Verlag, New York.Van Rijsbergen (1979) Information Retrieval,Butterworths, London.Wagner, R.A. and M.J. Fisher (1974) "The stringto string correction problem", J. ACM, 21:1, pp.168-173.Ward, W. and S. lssar (1996) "A class basedlanguage model for speech recognition", Proc.1EEE 1CASSP 96, Vol.
1, pp.416-418.Wong, P-K. and C. Chan (1999) "Postprocessingstatistical language models for handwrittenChinese character recognizer", IEEE Trans.
SMC,Part B, 29:2, 286-291.Xia, Y., S. Ma, M. Sun, X. Zhu, Y. Jin and X.Chang (1996) "Automatic post-processing of off-line handwritten Chinese text recognition", Proc.ICCC, pp.
413-416.Yang, K-C., T-H. Ho, L-F. Chien and L-S. Lee(1998) "Statistics-based segment pattern lexicon -a new direction for Chinese language modeling",Proc.
1EEE ICASSP 98, Vol.
1., pp.
169-172.94
