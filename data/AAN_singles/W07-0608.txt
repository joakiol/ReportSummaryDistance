Proceedings of the Workshop on Cognitive Aspects of Computational Language Acquisition, pages 57?64,Prague, Czech Republic, June 2007 c?2007 Association for Computational LinguisticsSimulating the acquisition of object namesAlessio Plebe and Vivian De la CruzDept.
Cognitive ScienceUniversity of Messina - Italy{alessio.plebe,vdelacruz}@unime.itMarco MazzoneLab.
Cognitive ScienceUniversity of Catania - Italymazzonem@unict.itAbstractNaming requires recognition.
Recognition requiresthe ability to categorize objects and events.
In-fants under six months of age are capable of makingfine-grained discriminations of object boundaries andthree-dimensional space.
At 8 to 10 months, a child?sobject categories are sufficiently stable and flexible tobe used as the foundation for labeling and referenc-ing actions.
What mechanisms in the brain underliethe unfolding of these capacities?
In this article, wedescribe a neural network model which attempts tosimulate, in a biologically plausible way, the processby which infants learn how to recognize objects andwords through exposure to visual stimuli and vocalsounds.1 IntroductionHumans, come to recognize an infinite variety ofnatural and man-made objects and make use ofsounds to identify and categorize them.
How do hu-man beings arrive at this capacity?
Different expla-nations have been offered to explain the processes,and those behind the learning of first words in par-ticular.Evidence has made clear that object recognitionand categorization in early infancy is much more so-phisticated than was previously thought.
By the timechildren are 8 to 10 months old their object cate-gories are sufficiently stable and flexible to be usedas the foundation for labeling and referencing ac-tions.
Increasing amounts of evidence point to thegrowing capacity of infants at this stage to reliablymap arbitrary sounds onto meanings and this map-ping process is crucial to the acquisition of language.The word-learning mechanisms used at this earlyphase of language learning could very well involve amapping of words onto the most perceptually inter-esting objects in an infant?s environment (Pruden etal., 2006).
There are those that claim that early wordlearning is not purely associative and that it is basedon a sensitivity to social intent (Tomasello, 1999),through joint attention phenomena (Bloom, 2000).Pruden et al have demonstrated that 10-month-oldinfants ?are sensitive to social cues but cannot recruitthem for word learning?
and therefore, at this ageinfants presumably have to learn words on a simpleassociative basis.
It is not by chance, it seems, thatearly vocabulary is made up of the objects infantsmost frequently see (Gershkoff-Stowe and Smith,2004).
Early word-learning and object recognitioncan thus be explained, according to a growing groupof researchers, by associational learning strategiesalone.There are those such as Carey and Spelke thatpostulate that there must necessarily be innate con-straints that have the effect of making salient cer-tain features as opposed to others, so as to narrowthe hypothesis space with respect to the kinds ofobjects to be categorized first (Carey and Spelke,1996).
They reject the idea that object categorizationin infants could emerge spontaneously from the abil-ity to grasp patterns of statistical regularities.
JeanMandler presents evidence that the first similarity di-mensions employed in categorization processes areindeed extremely general (Mandler, 2004); in otherwords, these dimensions single out wide domains ofobjects, with further refinements coming only later.Mandler claims, however, that the early salience of57these extremely general features could have a dif-ferent explanation other than nativism: for example,that salience could emerge from physiological con-straints.Using a connectionist model with backpropaga-tion, Rogers and McClelland have shown that quitegeneral dimensions of similarity can emerge with-out appealing to either physiological or cognitiveconstraints, simply as the result of a coherent co-variation of features, that is, as an effect of mere sta-tistical regularities (Rogers and McClelland, 2006).What Rogers and McClelland say about the mostgeneral features obviously apply also to more spe-cific features which become salient later on.
How-ever, interesting as it is from a computational pointof view, this model is rather unrealistic as a simula-tion of biological categorization processes.Linda Smith, suggests that words can contributeto category formation, in that they behave as featureswhich co-vary with other language-independent fea-tures of objects (Smith, 1999).
In general, her ideais that the relevant features simply emerge from reg-ularities in the input.
Terry Regier, building uponthe proposal offered by Smith, has shown that wordlearning might behave in analogy with what we havesaid about categorization (Regier, 2005): certainfeatures of both objects and words (i.e., phonolog-ical forms) can be made more salient than others,simply as a consequence of regularities in objects,words, and their co-variation.
Regier?s training setshowever, are constituted by wholly ?artificial phono-logical or semantic features?, rather than by ?nat-ural features such as voicing or shape?.
The posi-tions mentioned above conflict with others, such asthat of Lila Gleitman and her colleagues, accordingto which some innate constraints are needed in or-der to learn words.
It should be noted, however,that even in Gleitman?s proposal the need for in-nate constraints on syntax-semantic mapping mainlyconcerns verbs; moreover, the possibility to appre-hend a core set of concrete terms without the con-tribution of any syntactic constraint is considered asa precondition for verb acquisition itself (Gillette etal., 1999).This paper describes a neural network modelwhich attempts to simulate the process by which in-fants learn how to recognize objects and words inthe first year of life through exposure to visual stim-uli and vocal sounds.
The approach here pursued isin line with the view that a coherent covariation offeatures is the major engine leading to object nameacquisition, the attempt made however, is to rely onbiological ways of capturing coherent covariation.The pre-established design of the mature functionsof the organism is avoided, and the emergence ofthe final function of each component of the system isleft to the plastic development of the neural circuits.In the cortex, there is very little differentiation in thecomputational capability that neural circuits will po-tentially perform in the mature stage.
The interac-tion between environmental stimuli and some of thebasic mechanisms of development is what drives dif-ferentiation in computational functions.
This posi-tion has large empirical support (Katz and Callaway,1992; Lo?wel and Singer, 2002), and is compatiblewith current knowledge on neural genetics (Quartz,2003).The model here described, can be considered animplementation of the processes that emerge aroundthe 10 month of age period.
It can also be used toconsider what happens in a hypothesized subsequentperiod, in which the phenomenon of joint attentionprovides the social cueing that leads to the increasedability to focus on certain objects as opposed to oth-ers.2 The proposed modelFirst the mathematics common to the modules willbe described, then the model will be outlined.
De-tails of the visual and the auditory paths will be pro-vided along with a description of the learning proce-dures.2.1 The mathematical abstraction of thecortical mapsAll the modules composing this model are imple-mented as artificial cortical maps, adopting the LIS-SOM (Laterally Interconnected Synergetically Self-Organizing Map) architecture (Sirosh and Miikku-lainen, 1997; Bednar, 2002).
This architecture hasbeen chosen because of its reproduction of neuralplasticity, through the combination of Hebb?s princi-ple and neural homeostasis, and because it is a goodcompromise between a number of realistic featuresand the simplicity necessary for building complex58LGNMGNA1LPC HPCSTS LOCV2V1VOAAMFigure 1: Overall scheme of the model.models.
The LISSOM is a two dimensional arrange-ment of neurons, where each cell is not only con-nected with the afferent input vector, but receives ex-citatory and inhibitory inputs from several neighborneurons on the same map:x(k)i = f(?A1 + ?N~I ?
~vrA,i~arA,i ?
~vrA,i+ ?E~erE,i ?
~x(k?1)rE,i?
?H~hrH,i ?
~x(k?1)rH,i),(1)where x(k)i is the activation of the neuron i at timestep k. All vectors are composed by a circular neigh-borhood of given radius around the neuron i: vectors~x (k?1) are activations of neurons on the same layerat the previous time step.
Vector ~vrA,i comprises allneurons in the underlying layer, in a circular areacentered on the projection of i on this layer, with ra-dius rA.
Vectors ~arA,i, ~erE,i, and ~hrH,i are composedby all connection strengths of, afferent, excitatory orinhibitory neurons respectively, projecting to i, in-side circular areas of radius rA, rE, rH.
Vector ~I isjust a vector of 1?s of the same dimension of ~vrA,i.The scalars ?A, ?E, and ?H, are constants modulat-ing the contribution of afferent, excitatory and in-hibitory connections.
The scalar ?N controls the set-ting of a push-pull effect in the afferent weights, al-lowing inhibitory effect without negative weight val-ues.
Mathematically, it represents dividing the re-sponse from the excitatory weights by the responsefrom a uniform disc of inhibitory weights over thereceptive field of neuron i.
The map is character-ized by the matrices A,E,H, which columns are allvectors ~a, ~e, ~h for every neuron in the map.
Thefunction f is a monotonic non-linear function lim-ited between 0 and 1.
The final activation value ofthe neurons is assessed after settling time K.All connection strengths to neuron i adapt by fol-lowing the rules:?~arA,i =~arA,i + ?Axi~vrA,i?~arA,i + ?Axi~vrA,i??
~arA,i, (2)?~erE,i =~erE,i + ?Exi~xrE,i?~arE,i + ?Exi~xrE,i??
~erE,i, (3)?~hrH,i =~hrH,i + ?Axi~xrH,i??
?~hrH,i + ?Axi~xrH,i????
~hrH,i, (4)where ?
{A,E,H} are the learning rates for afferent, ex-citatory and inhibitory synaptic modifications.
Allrules are based on the Hebbian law, with an ad-ditional competitive factor, here implemented as anormalization, that maintains constant the integra-tion of all connection strengths to the same neu-59layer size rA rE rH ?A ?E ?H ?NLGN Lateral Geniculated Nucleus 120?
120 - - - - - - -MGN Medial Geniculated Nucleus 32?
32 - - - - - - -V1 Primary Visual Cortex 96?
96 8.5 1.5 7.0 1.5 1.0 1.0 0.0V2 Secondary Visual Cortex 30?
30 7.5 8.5 3.5 50.0 3.2 2.5 0.7VO Ventral Occipital 30?
30 24.5 4.0 8.0 1.8 1.0 1.0 0.0A1 Auditory Primary Cortex 24?
24 3.5 2.5 5.5 5.0 5.0 6.7 0.8LOC Lateral Occipital Complex 16?
16 6.5 1.5 3.5 1.2 1.0 1.5 0.0STS Superior Temporal Sulcus 16?
16 3.5 2.5 2.5 2.0 1.6 2.6 0.0Table 1: Legend of all modules, and main parameters of the cortical layers composing the model.ron, and to the same type (afferent, excitatory or in-hibitory).
This is a computational account of the bi-ological phenomena of homeostatic plasticity, thatinduce neurons in the cortex to maintain an aver-age firing rate by correcting their incoming synapticstrengths.2.2 The overall modelAn outline of the modules that make up the modelis shown in Fig.
1.
The component names and theirdimensions are in Tab.
1.
All cortical layers areimplemented by LISSOM maps, where the afferentconnections ~v in (1) are either neurons of lower LIS-SOM maps, or neurons in the thalamic nuclei MGNand LGN.
There are two main paths, one for thevisual process and another for the auditory chan-nel.
Both paths include thalamic modules, which arenot the object of this study and are therefore hard-wired according to what is known about their func-tions.
The two higher cortical maps, LOC and STS,will carry the best representation coded by modelson object visual features and word features.
Thesetwo representations are associated in an abstract typemap, called AAM (Abstract Associative Map).
Thiscomponent is implemented using the SOM (Self Or-ganized Map) (Kohonen, 1995) architecture, knownto provide non linear bidimensional ordering of in-put vectors by unsupervised mechanisms.
It is theonly component of the model that cannot be concep-tually referred to as a precise cortical area.
It is anabstraction of processes that actually involve severalbrain areas in a complex way, and as such departscomputationally from realistic cortical architecture.2.3 The visual pathwayAs shown in Fig.
1, the architecture here used in-cludes hardwired extracortical maps with simple on-center and off-center receptive fields.
There arethree pairs of sheets in the LGN maps: one con-nected to the intensity image plane, and the othertwo connected to the medium and long wavelengthplanes.
In the color channels the internal excita-tory portion of the receptive field is connected to thechannel of one color, and the surrounding inhibitorypart to the opposite color.
The cortical process pro-ceeds along two different streams: the achromaticcomponent is connected to the primary visual mapV1 followed by V2, the two spectral components areprocessed by map VO, the color center, also calledhV4 or V8 (Brewer et al, 2005).
The two streamsrejoin in the cortical map LOC, the area recentlysuggested as being the first involved in object recog-nition in humans (Malach et al, 1995; Kanwisher,2003).
Details of the visual path are in (Plebe andDomenella, 2006).2.4 The auditory pathwayThe hardwired extracortical MGN component isjust a placeholder for the spectrogram represen-tation of the sound pressure waves, which is ex-tracted with tools of the Festival software (Blackand Taylor, 1997).
It is justified by evidenceof the spectro-temporal process performed by thecochlear-thalamic circuits (Escabi and Read, 2003).The auditory primary cortex is simulated by a doublesheet of neurons, taking into account a double popu-lation of cells found in this area (Atzori et al, 2001),where the so-called LPC (Low-Probability Connec-tions) is sensitive to the stationary component ofthe sound signal and the HPC (High-ProbabilityConnections) population responds to transient inputsmainly.
The next map in the auditory path of themodel is STS, because the superior temporal sulcusis believed to be the main brain area responsive to60vocal sounds (Belin et al, 2002).2.5 The Abstract Associative MapThe upper AAM map in the model reflects how thesystem associates certain sound forms with the vi-sual appearance of objects, and has the main pur-pose of showing what has been achieved in the cor-tical part of the model.
It is trained using the outputsof the STS and the LOC maps of the model.
Af-ter training, each neuron x in AAM is labeled, ac-cording to different test conditions X .
The labelingfunction l(?)
associates the neuron x with an entitye, which can be an object o of the COIL set O, whenX ?
{A, B} or a category c of the set C for the testcondition X ?
{C, D}.
The general form of the la-beling function is:l(X)(x) = arg maxe?E{???W(e)x???
}(5)where W(e)x is a set of sensorial stimuli related tothe element e ?
E , such that their processing inthe model activate x as winner in the AMM map.The set E can be O or C depending on X .
Theneuron x elicited in the AAM map as the conse-quence of presenting a visual stimulus vo of an ob-ject o and a sound stimulus sc of a tagory c is givenby the function x = w(vo, sc) with the conventionthat w(v, ) computes the winning neuron in AAMcomparing only the LOC portion of the coding vec-tor, and w(, s) only the STS portion.
The functionb(o) : O ?
C associates an object o to its category.Here four testing conditions are used:?
A object recognition by vision and audio?
B object recognition by vision only?
C category recognition by vision and audio?
D category recognition by audio onlycorresponding to the following W sets in (5):A : {vo : x = w(vo, sc(o))} (6)B : {vo : x = w(vo, )} (7)C : {vo : c = b(o) ?
x = w(, sc)} (8)D : {sc : x = w(, sc)} (9)From the labeling functions the possibility of esti-mating the accuracy of recognition immediately fol-lows, simply by weighing the number of cases wherethe category or the object has been classified as theprevailing one in each neuron of the AAM SOM.2.6 Exposure to stimuliThe visual path in the model develops in two stages.Initially the inputs to the network are synthetic ran-dom blobs, simulating pre-natal waves of sponta-neous activity, known to be essential in the early de-velopment of the visual system (Sengpiel and Kind,2002).
In the second stage, corresponding to the pe-riod after eye opening, natural images are used.
Inorder to address one of the main problems in recog-nition, the identifying of an object under differentviews, the COIL-100 collection has been used (Na-yar and Murase, 1995) where 72 different views areavailable for each of the 100 objects.
Using naturalimages where there is only one main object is clearya simplification in the vision process of this model,but it does not compromise the realism of the con-ditions.
It always could be assumed that the singleobject analysis corresponds to a foval focusing asconsequence of a saccadic move, cued by any atten-tive mechanism.In the auditory path there are different stagesas well.
Initially, the maps are exposed to ran-dom patches in frequency-time domain, withshorter duration for HPC and longer for LPC.Subsequently, all the auditory maps are exposedto the 7200 most common English words (fromhttp://www.bckelk.uklinux.net/menu.html)with lengths between 3 and 10 characters.
All wordsare converted from text to waves using Festival(Black and Taylor, 1997), with cepstral order 64 anda unified time window of 2.3 seconds.
Eventually,the last stage of training simulates events whenan object is viewed and a word corresponding toits basic category is heard simultaneously.
The100 objects have been grouped manually into38 categories.
Some categories, such as cupor medicine count 5 exemplars in the objectcollection, while others, such as telephone, haveonly one exemplar.3 Results3.1 Developed functions in the cortical mapsAt the end of development each map in the modelhas evolved its own function.
Different functions61have emerged from identical computational archi-tectures.
The differences are due to the different po-sitions of a maps in the modules hierarchy, to differ-ent exposure to environmental stimuli, and differentstructural parameters.
The functions obtained in theexperiment are the following.
In the visual path ori-entation selectivity emerged in the model?s V1 mapas demonstrated in (Sirosh and Miikkulainen, 1997)and (Plebe and Domenella, 2006).
Orientation se-lectivity is the main organization in primary visualcortex, where the responsiveness of neurons to ori-ented segments is arranged over repeated patterns ofgradually changing orientations, broken by few dis-continuities (Vanduffel et al, 2002).
Angle selec-tivity emerged in the model?s V2 map.
In the sec-ondary visual cortex the main recently discoveredphenomena is the selectivity to angles (Ito and Ko-matsu, 2004), especially in the range between 60and 150 degrees.
The essential features of colorconstancy are reproduced in the model?s VO map,which is the ability of neurons to respond to specifichues, regardless of intensity.
Color constancy is thetendency of the color of a surface to appear moreconstant that it is in reality.
This property is help-ful in object recognition, and develops sometime be-tween two and four months of age.
(Dannemiller,1989).
One of the main functions shown by the LOClayer in the model is visual invariance, the prop-erty of neurons to respond to peculiar object fea-tures despite changes in the object?s appearance dueto different points of view.
Invariance indeed is oneof the main requirements for an object-recognitionarea, and is found in human LOC (Grill-Spector etal., 2001; Kanwisher, 2003).
Tonotopic mapping isa known feature of the primary auditory cortex thatrepresents the dimensions of frequency and time se-quences in a sound pattern (Verkindt et al, 1995).In the model it is split into a sheet where neuronshave receptive fields that are more elongated alongthe time dimension (LPC) and another where theresulting receptive fields are more elongated alongthe frequency dimension (HPC).
The spectrotempo-ral mapping obtained in STS is a population codingof features, in frequency and time domains, repre-sentative of the sound patterns heard during the de-velopment phase.
It therefore reflects the statisticalphonemic regularities in common spoken English,extracted from the 7200 training samples.category test A test B test C test Dmedicine 0.906 0.803 1.0 1.0fruit 1.0 0.759 1.0 1.0boat 0.604 0.401 1.0 1.0tomato 1.0 0.889 1.0 1.0sauce 1.0 1.0 1.0 1.0car 0.607 0.512 0.992 1.0drink 0.826 0.812 1.0 1.0soap 0.696 0.667 1.0 1.0cup 1.0 0.919 1.0 0.0piece 0.633 0.561 1.0 1.0kitten 1.0 0.806 1.0 1.0bird 1.0 1.0 1.0 1.0truck 0.879 0.556 1.0 1.0dummy 1.0 0.833 1.0 1.0tool 0.722 0.375 1.0 1.0pottery 1.0 1.0 1.0 1.0jam 1.0 1.0 1.0 1.0frog 1.0 0.806 1.0 1.0cheese 0.958 0.949 1.0 1.0bottle 0.856 0.839 1.0 1.0hanger 1.0 0.694 1.0 1.0sweets 1.0 0.701 1.0 1.0tape 1.0 0.861 1.0 1.0mug 0.944 0.889 1.0 1.0spoon 1.0 0.680 1.0 1.0cigarettes 0.972 0.729 0.972 1.0ring 1.0 1.0 1.0 1.0pig 1.0 0.778 1.0 1.0dog 1.0 0.917 1.0 1.0toast 1.0 0.868 1.0 1.0plug 1.0 0.771 1.0 1.0pot 1.0 0.681 1.0 1.0telephone 1.0 0.306 1.0 1.0pepper 1.0 0.951 1.0 1.0chewinggum 0.954 0.509 1.0 1.0chicken 1.0 0.944 1.0 1.0jug 1.0 0.917 1.0 1.0can 1.0 0.903 1.0 1.0Table 2: Accuracy in recognition measured by labeling in theAAM, for objects grouped by category.3.2 Recognition and categorization in AAMThe accuracy of object and category recognition un-der several conditions is shown in Table 2.
All testsclearly prove that the system has learned an efficientcapacity of object recognition and naming, with re-spect to the small world of object and names used inthe experiment.
Tests C and D demonstrate that therecognition of categories by names is almost com-plete, both when hearing a name or when seeing anobject and hearing its name.
In tests A and B, therecognition of individual objects is also very high.In several cases, it can be seen that names also helpin the recognition of individual objects.
One of theclearest cases is the category tool (shown in Fig.
2),62shape test A test B ?h-parallelepiped 0.921 0.712 0.209round 1.0 0.904 0.096composed 0.702 0.565 0.137q-cylindrical 0.884 0.861 0.023q-h-parallelepiped 0.734 0.513 0.221cylindrical 0.926 0.907 0.019cup-shaped 0.975 0.897 0.078q-v-parallelepiped 0.869 0.754 0.115body 1.0 0.869 0.131conic 1.0 1.0 0.0parallelepiped 0.722 0.510 0.212q-parallelepiped 1.0 0.634 0.366Table 3: Accuracy in recognition measured by labeling in theAAM, for objects grouped by their visual shape, ?
is the im-provement gained with naming.where the accuracy for each individual object dou-bles when using names.
It seems to be analogous tothe situation described in (Smith, 1999), where theword contributes to the emergence of patterns of reg-ularity.
The 100% accuracy for the category, in thiscase, is better accounted for as an emergent exampleof synonymy, where coupling with the same word isaccepted, despite the difference in the output of thevisual process.In table 3 accuracy results for individual objectsare listed, grouped by object shape.
In this case cat-egory accuracy cannot be computed, because shapescross category boundaries.
It can be seen that the im-provement ?
is proportional to the salience in shape:it is meaningless for common, obvious shapes, andhigher when object shape is uncommon.
This resultis in agreement with findings in (Gershkoff-Stoweand Smith, 2004).4 ConclusionsThe model here described attempts to simulate lexi-cal acquisition from auditory and visual stimuli froma brain processes point of view.
It models these pro-cesses in a biologically plausible way in that it doesnot begin with a predetermined design of maturefunctions, but instead allows final functions of thecomponents to emerge as a result of the plastic de-velopment of neural circuits.
It grounds this choiceand its design principles in what is known of thecerebral cortex.
In this model, the overall importantresult achieved so far, is the emergence of namingand recognition abilities exclusively through expo-sure of the system to environmental stimuli, in termsof activities similar to pre-natal spontaneous activi-ties, and later to natural images and vocal sounds.This result has interesting theoretical implicationsfor developmental psychologists and may providea useful computational tool for future investigationson phenomena such as the effects of shape on objectrecognition and naming.In conclusion this model represents a first step insimulating the interaction of the visual and the audi-tory cortex in learning object recognition and nam-ing, and being a model of high level complex cog-nitive functions, it necessarily lacks several detailsof the biological cortical circuits.
It lacks biologi-cal plausibility in the auditory path because of thestate of current knowledge of the processes going onthere.
Future developments of the model will fore-see the inclusion of backprojections between mapsin the hierarchy, trials on preliminary categorizationat the level of phonemes and syllables in the auditorypath, as well as exposure to images with multiple ob-jects in the scene.ReferencesMarco Atzori, Saobo Lei, D. Ieuan P. Evans, Patrick O. Kanold,Emily Phillips-Tansey, Orinthal McIntyre, and Chris J.McBain.
2001.
Differential synaptic processing separatesstationary from transient inputs to the auditory cortex.
Neu-ral Networks, 4:1230?1237.James A. Bednar.
2002.
Learning to See: Genetic and Envi-ronmental Influences on Visual Development.
Ph.D. thesis,University of Texas at Austin.
Tech Report AI-TR-02-294.Pascal Belin, Robert J. Zatorre, and Pierre Ahad.
2002.
Humantemporal-lobe response to vocal sounds.
Cognitive BrainResearch, 13:17?26.Alan W. Black and Paul A. Taylor.
1997.
The festival speechsynthesis system: System documentation.
Technical Re-port HCRC/TR-83, Human Communciation Research Cen-tre, University of Edinburgh, Edinburgh, UK.Paul Bloom.
2000.
How children learn the meanings of words.MIT Press, Cambridge (MA).Alyssa A.
Brewer, Junjie Liu, Alex R. Wade, and Brian A. Wan-dell.
2005.
Visual field maps and stimulus selectivity in hu-man ventral occipital cortex.
Nature Neuroscience, 8:1102?1109.Susan Carey and Elizabeth Spelke.
1996.
Science and coreknowledge.
Journal of Philosophy of Science, 63:515?533.James L. Dannemiller.
1989.
A test of color constancy in 9- and20-weeks-old human infants following simulated illuminantchanges.
Developmental Psychology, 25:171?184.63Figure 2: Objects mentioned in the discussion on recognition results.
In the upper row views of the two objects of the categorytool.
In the middle row objects with difficult shapes (q-h-parallelepiped, q-parallelepiped).
In the lower rowobjects with easy shapes (cylindrical, round, and conic).Monty A. Escabi and Heather L. Read.
2003.
Representation ofspectrotemporal sound information in the ascending auditorypathway.
Biological Cybernetics, 89:350?362.Lisa Gershkoff-Stowe and Linda B. Smith.
2004.
Shape andthe first hundred nouns.
Child Development, 75:1098?1114.Jane Gillette, Henry Gleitman, Lila Gleitman, and Anne Led-erer.
1999.
Human simulations of vocabulary learning.Cognition, 73:135?176.Kalanit Grill-Spector, Zoe Kourtzi, and Nancy Kanwisher.2001.
The lateral occipital complex and its role in objectrecognition.
Vision Research, 41:1409?1422.Minami Ito and Hidehiko Komatsu.
2004.
Representationof angles embedded within contour stimuli in area V2 ofmacaque monkeys.
Journal of Neuroscience, 24:3313?3324.Nancy Kanwisher.
2003.
The ventral visual object pathwayin humans: Evidence from fMRI.
In Leo Chalupa and JohnWerner, editors, The Visual Neurosciences.
MIT Press, Cam-bridge (MA).Lawrence C. Katz and Edward M. Callaway.
1992.
Develop-ment of local circuits in mammalian visual cortex.
AnnualReview Neuroscience, 15:31?56.Teuvo Kohonen.
1995.
Self-Organizing Maps.
Springer-Verlag, Berlin.Siegrid Lo?wel and Wolf Singer.
2002.
Experience-dependentplasticity of intracortical connections.
In Manfred Fahle andTomaso Poggio, editors, Perceptual Learning.
MIT Press,Cambridge (MA).R.
Malach, J.
B. Reppas, R. R. Benson, K. K. Kwong, H. Jiang,W.
A. Kennedy, P. J. Ledden, T. J. Brady, B. R. Rosen, andR.
B.H.
Tootell.
1995.
Object-related activity revealed byfunctional magnetic resonance imaging in human occipitalcortex.
Proceedings of the Natural Academy of Science USA,92:8135?8139.Jean Matter Mandler.
2004.
The Foundations of Mind.
OxfordUniversity Press, Oxford (UK).Shree Nayar and Hiroshi Murase.
1995.
Visual learning andrecognition of 3-d object by appearence.
International Jour-nal of Computer Vision, 14:5?24.Alessio Plebe and Rosaria Grazia Domenella.
2006.
Early de-velopment of visual recognition.
BioSystems, 86:63?74.Shannon M. Pruden, Kathy Hirsh-Pasek, Roberta MichnickGolinkoff, and Elizabeth A. Hennon.
2006.
The birthof words: Ten-month-olds learn words through perceptualsalience.
Child Development, 77:266?280.Steven R. Quartz.
2003.
Innateness and the brain.
Biology andPhilosophy, 18:13?40.Terry Regier.
2005.
The emergence of words: Attentionallearning in form and meaning.
Cognitive Science, 29:819?865.Timothy T. Rogers and James L. McClelland.
2006.
Seman-tic Cognition - A Parallel Distributed Processing Approach.MIT Press, Cambridge (MA).Frank Sengpiel and Peter C. Kind.
2002.
The role of activity indevelopment of the visual system.
Current Biology, 12:818?826.Joseph Sirosh and Risto Miikkulainen.
1997.
Topographicreceptive fields and patterned lateral interaction in a self-organizing model of the primary visual cortex.
Neural Com-putation, 9:577?594.Linda B. Smith.
1999.
Children?s noun learning: How generallearning processes make specialized learning mechanisms.In Brian MacWhinney, editor, The Emergence of Language.Lawrence Erlbaum Associates, Mahwah (NJ).
Second Edi-tion.Michael Tomasello.
1999.
The cultural origins of human cog-nition.
Harvard University Press, Cambridge (MA).Wim Vanduffel, Roger B.H.
Tootell, Anick A. Schoups, andGuy A. Orban.
2002.
The organization of orientation selec-tivity throughout the macaque visual cortex.
Cerebral Cor-tex, 12:647?662.Chantal Verkindt, Olivier Bertrand, Frano?is Echallier, andJacques Pernier.
1995.
Tonotopic organization of the hu-man auditory cortex: N100 topography and multiple dipolemodel analysis.
Electroencephalography and Clinical Neu-rophisiology, 96:143?156.64
