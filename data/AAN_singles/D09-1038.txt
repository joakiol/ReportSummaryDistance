Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 362?370,Singapore, 6-7 August 2009. c?2009 ACL and AFNLPBetter Synchronous Binarization for Machine TranslationTong Xiao*, Mu Li+, Dongdong Zhang+, Jingbo Zhu*, Ming Zhou+*Natural Language Processing LabNortheastern UniversityShenyang, China, 110004xiaotong@mail.neu.edu.cnzhujingbo@mail.neu.edu.cn+Microsoft Research AsiaSigma CenterBeijing, China, 100080muli@microsoft.comdozhang@microsoft.commingzhou@microsoft.comAbstractBinarization of Synchronous Context FreeGrammars (SCFG) is essential for achievingpolynomial time complexity of decoding forSCFG parsing based machine translation sys-tems.
In this paper, we first investigate theexcess edge competition issue caused by a left-heavy binary SCFG derived with the methodof Zhang et al (2006).
Then we propose a newbinarization method to mitigate the problemby exploring other alternative equivalent bi-nary SCFGs.
We present an algorithm that ite-ratively improves the resulting binary SCFG,and empirically show that our method can im-prove a string-to-tree statistical machine trans-lations system based on the synchronous bina-rization method in Zhang et al (2006) on theNIST machine translation evaluation tasks.1 IntroductionRecently Statistical Machine Translation (SMT)systems based on Synchronous Context FreeGrammar (SCFG) have been extensively investi-gated (Chiang, 2005; Galley et al, 2004; Galleyet al, 2006) and have achieved state-of-the-artperformance.
In these systems, machine transla-tion decoding is cast as a synchronous parsingtask.
Because general SCFG parsing is an NP-hard problem (Satta and Peserico, 2005), practic-al SMT decoders based on SCFG parsing re-quires an equivalent binary SCFG that is directlylearned from training data to achieve polynomialtime complexity using the CKY algorithm (Ka-sami, 1965; Younger, 1967) borrowed from CFGparsing techniques.
Zhang et al (2006) proposedsynchronous binarization, a principled method tobinarize an SCFG in such a way that both thesource-side and target-side virtual non-terminalshave contiguous spans.
This property of syn-chronous binarization guarantees the polynomialtime complexity of SCFG parsers even when ann-gram language model is integrated, which hasbeen proved to be one of the keys to the successof a string-to-tree syntax-based SMT system.However, as shown by Chiang (2007), SCFG-based decoding with an integrated n-gram lan-guage model still has a time complexity of?
(?3 ?
4(?
?1)), where m is the source sentencelength, and  ?
is the vocabulary size of the lan-guage model.
Although it is not exponential intheory, the actual complexity can still be veryhigh in practice.
Here is an example extractedfrom real data.
Given the following SCFG rule:VP   ?
VB  NP  ?
JJR  ,VB  NP  will be  JJRwe can obtain a set of equivalent binary rulesusing the synchronous binarization method(Zhang et al, 2006)  as follows:VP ?
V1  JJR ,   V1  JJRV1 ?
VB  V2 ,   VB  V2V2 ?
NP ?
,   NP  will beThis binarization is shown with the solid lines asbinarization (a) in Figure 1.
We can see that bi-narization (a) requires that ?NP ??
should bereduced at first.
Data analysis shows that ?NP ?
?is a frequent pattern in the training corpus, andthere are 874 binary rules of which the sourcelanguage sides are ?NP ??.
Consequently thesebinary rules generate a large number of compet-ing edges in the chart when ?NP ??
is matchedin decoding.
To reduce the number of edges pro-362posed in decoding, hypothesis re-combination isused to combine the equivalent edges in terms ofdynamic programming.
Generally, two edges canbe re-combined if they satisfy the following twoconstraints:  1) the LHS (left-hand side) non-terminals are identical and the sub-alignmentsare the same (Zhang et al, 2006); and 2) theboundary words 1  on both sides of the partialtranslations are equal between the two edges(Chiang, 2007).
However, as shown in Figure 2,the decoder still generates 801 edges after thehypothesis re-combination.
As a result, aggres-sive pruning with beam search has to be em-ployed to reduce the search space to make thedecoding practical.
Usually in beam search onlya very small number of edges are kept in thebeam of each chart cell (e.g.
less than 100).These edges have to compete with each other tosurvive from the pruning.
Obviously, more com-peting edges proposed during decoding can leadto a higher risk of making search errors.VB NP ?
JJR(a)(b)V2V1V2'V1'VPVB NP will be JJRFigure 1: Two different binarizations (a) and(b) of the same SCFG rule distinguished by thesolid lines and dashed lines??
??
??
?
??
?
(We hope the situation will be better .)??
??
NP   ?
JJR   ?decodingmatch 874 rules match 62 rulescompeting edges: 801 competing edges: 57Figure 2: Edge competitions caused by differentbinarizationsThe edge competition problem for SMT de-coding is not addressed in previous work (Zhanget al, 2006; Huang, 2007) in which each SCFGrule is binarized in a fixed way.
Actually the re-sults of synchronous binarization may not be theonly solution.
As illustrated in Figure 1, the rule1 For the case of n-gram language model integration,2 ?
(?
?
1) boundary words needs to be examined.can also be binarized as binarization (b) which isshown with the dashed lines.We think that this problem can be alleviatedby choosing better binarizations for SMT decod-ers, since there is generally more than one bina-rization for a SCFG rule.
In our investigation,about 96% rules that need to be binarized havemore than one binarization under the contiguousconstraint.
As shown in binarization (b) (Figure1), ??
JJR?
is reduced first.
In the decoder, thenumber of binary rules with the source-side ??JJR?
is 62, and the corresponding number ofedges is 57 (Figure 2).
The two numbers are bothmuch smaller than those of ?NP ??
in (a).
Thisis an informative clue that the binarization (b)could be better than the binarization (a) based onthe following: the probability of pruning the rulein (a) is higher than that in (b) as the rule in (b)has fewer competitors and has more chances tosurvive during pruning.In this paper we propose a novel binarizationmethod, aiming to find better binarizations toimprove an SCFG-based machine translationsystem.
We formulate the binarization optimiza-tion as a cost reduction process, where the cost isdefined as the number of rules sharing a commonsource-side derivation in an SCFG.
We presentan algorithm, iterative cost reduction algorithm,to obtain better binarization for the SCFG learntautomatically from the training corpus.
It canwork with an efficient CKY-style binarizer tosearch for the lowest-cost binarization.
We applyour method into a state-of-the-art string-to-treeSMT system.
The experimental results show thatour method outperforms the synchronous binari-zation method (Zhang et al, 2006) with over 0.8BLEU scores on both NIST 2005 and NIST 2008Chinese-to-English evaluation data sets.2 Related WorkThe problem of binarization originates from theparsing problem in which several binarizationmethods are studied such as left/right binariza-tion (Charniak et al, 1998; Tsuruoka and Tsujii,2004) and head binarization (Charniak et al,2006).
Generally, the pruning issue in SMT de-coding is unnecessary for the parsing problem,and the accuracy of parsing does not rely on thebinarization method heavily.
Thus, many effortson the binarization in parsing are made for theefficiency improvement instead of the accuracyimprovement (Song et al, 2008).Binarization is also an important topic in theresearch of syntax-based SMT.
A synchronous363binarization method is proposed in (Zhang et al,2006) whose basic idea is to build a left-heavybinary synchronous tree (Shapiro and Stephens,1991) with a left-to-right shift-reduce algorithm.Target-side binarization is another binarizationmethod which is proposed by Huang (2007).
Itworks in a left-to-right way on the target lan-guage side.
Although this method is compara-tively easy to be implemented, it just achievesthe same performance as the synchronous binari-zation method (Zhang et al, 2006) for syntax-based SMT systems.
In addition, it cannot beeasily integrated into the decoding of some syn-tax-based models (Galley et al, 2004; Marcu etal., 2006), because it does not guarantee conti-guous spans on the source language side.3 Synchronous Binarization Optimiza-tion by Cost ReductionAs discussed in Section 1, binarizing an SCFG ina fixed (left-heavy) way (Zhang et al, 2006) maylead to a large number of competing edges andconsequently high risk of making search errors.Fortunately, in most cases a binarizable SCFGcan be binarized in different ways, which pro-vides us with an opportunity to find a better solu-tion than the default left-heavy binarization.
Anideal solution to this problem could be that wedefine an exact edge competition estimationfunction and choose the best binary SCFG basedon it.
However, even for the rules with a com-mon source-side, generally it is difficult to esti-mate the exact number of competing edges in thedynamic SCFG parsing process for machinetranslation, because in order to integrate an n-gram language model, the actual number ofedges not only depends on SCFG rules, but alsodepends on language model states which are spe-cific to input sentences.
Instead, we have to em-ploy certain kinds of approximation of it.
Firstwe will introduce some notations frequently usedin later discussions.3.1 NotationsWe use ?
= {??
?
??
?
??
,??}
to denote anSCFG, where ??
is the ???
rule in ?
; ??
is theLHS (left hand side) non-terminal of ??
; ??
and??
are the source-side and target-side RHS (righthand side) derivations of ??
respectively.
We use?
?
to denote the set of equivalent binarySCFG of ?.
The goal of SCFG binarization is tofind an appropriate binary SCFG ??
?
?
?
.
For??
, ?
??
= {??? }
?
??
?
?
?
is the set ofequivalent binary rules based on ??
, where ???
isthe ???
binary rule in ?
??
.
Figure 3 illustratesthe meanings of these notations with a samplegrammar.VP ?
VB NP ?
JJR  ,   VB NP will be JJRS   ?
NP ?
VP  ,           NP will VPR1 :R2 :GVP ?
V12JJR ,    V12JJR(R1)G?V12?
VB V13,     VB V13V13?
NP ?
,       NP  will bev11:v12:v13:S   ?
V22VP ,      V22VPV22?
NP ?
,      NP willv21:v22:(R2)binarization...v11v12v22S(?VB NP ?
JJR ?, G?)
S(?VB NP ?
?, G?)
S(?NP ?
?, G?
)L(v12)=?VB NP ?
?v13rule bucketFigure 3: Binarization on a sample grammarThe function ?(?)
is defined to map a result-ing binary rule ???
???
to the sub-sequence in ?
?derived from ???
.
For example, as shown in Fig-ure 3, the binary rule ?13 covers the source sub-sequence ?NP ??
in ?1 , so ?
?13 = "NP ?
".Similarly, ?
?12 = "VB NP ?
".The function ?(?)
is used to group the rules in??
with a common right-hand side derivation forsource language.
Given a binary rule ?
?
?
?, wecan put it into a bucket in which all the binaryrules have the same source sub-sequence ?(?
).For example (Figure 3), as ?
?12 = "VB NP ?
",?12 is put into the bucket indexed by ?VB NP ?
?.And ?13  and ?22  are put into the same bucket,since they have the same source sub-sequence?NP ??.
Obviously, ??
can be divided into a setof mutual exclusive rule buckets by ?(?
).In this paper, we use ?(?(?),??)
to denote thebucket for the binary rules having the source sub-sequence ?(?).
For example, ?("??
?",??)
de-notes the bucket for the binary rules having thesource-side ?NP ??.
For simplicity, we also use?(?,??)
to denote ?
?
?
,??
.3.2 Cost Reduction for SCFG BinarizationGiven a binary SCFG ?
?, it can be easily noticedthat if a rule ?
in  the bucket ?(?,??)
can be ap-plied to generate one or more new edges inSCFG parsing, any other rules in this bucket canalso be applied because all of them can be re-duced from the same underlying derivation ?(?
).364Each application of other rules in the bucket?(?,??)
can generate competing edges with theone based on ?
.
Intuitively, the size of bucketcan be used to approximately indicate the actualnumber of competing edges on average, and re-ducing the size of bucket could help reduce theedges generated in a parsing chart by applyingthe rules in the bucket.
Therefore, if we can finda method to greedily reduce the size of eachbucket ?(?,??
), we can reduce the overall ex-pected edge competitions when parsing with ?
?.However, it can be easily proved that thenumbers of binary rules in any ??
?
?
?
aresame, which implies that we cannot reduce thesizes of all buckets at the same time ?
removinga rule from one bucket means adding it to anoth-er.
Allowing for this fact, the excess edge com-petition example shown in Section 1 is essential-ly caused by the uneven distribution of rulesamong different buckets ?
?
.
Accordingly, ouroptimization objective should be a more evendistribution of rules among buckets.In the following, we formally define a metricto model the evenness of rule distribution overbuckets.
Given a binary SCFG ??
and a binarySCFG rule ?
?
??
, ?(?)
is defined as the costfunction that maps ?
to the size of the bucket?
?,??
:?
?
=  ?
?,??
(1)Obviously, all the binary rules in ?
?,??
share acommon cost value  ?
?,??
.
For example (Fig-ure 3), both ?13  and ?22  are put into the samebucket ?
"??
?",??
, so ?
?13 = ?
?22 = 2.The cost of the SCFG ??
is computed bysumming up all the costs of SCFG rules in it:?
??
= ?(?)???
?
(2)Back to our task, we are to find an equivalentbinary SCFG ??
of ?
with the lowest cost interms of the cost function ?(. )
given in Equation(2):??
= argmin????
?
?(??)
(3)Next we will show how ??
is related to theevenness of rule distribution among differentbuckets.
Let ?
??
= {?1,?
, ??}
be the set ofrule buckets containing rules in ?
?, then the valueof ?(??)
can also be written as:?
??
=  ??21????
(4)Assume ??
=  ??
is an empirical distribution of adiscrete random variable ?, then the square devi-ation of the empirical distribution is:?2 =1?
( ??
?
?
)2?
(5)Noticing that ?
??
=  ??
and ?
=  ??
/?, Equ-ation (5) can be written as:?2 =1??
?
?
???
2?
(6)Since both ?
and |?
?| are constants, minimizingthe cost function ?(??)
is equivalent to minimiz-ing the square deviation of the distribution ofrules among different buckets.
A binary SCFGwith the lower cost indicates the rules are moreevenly distributed in terms of derivation patternson the source language side.3.3 Static Cost ReductionBefore moving on discussing the algorithmwhich can optimize Equation (3) based on rulecosts specified in Equation (1), we first presentan algorithm to find the optimal solution to Eq-uation (3) if we have known the cost setting of??
and can use the costs as static values duringbinarization.
Using this simplification, the prob-lem of finding the binary SCFG  ??
with minim-al costs can be reduced to find the optimal bina-rization ??(??)
for each rule ??
in ?.To obtain ??(??)
, we can employ a CKY-style binarization algorithm which builds a com-pact binarization forest for the rule ??
in bottom-up direction.
The algorithm combines two adja-cent spans of ??
each time, in which two spanscan be combined if and only if they observe theBTG constraints?
their translations are eithersequentially or reversely adjacent in ??
, the tar-get-side derivation of ??
.
The key idea of thisalgorithm is that we only use the binarization treewith the lowest cost of each span for later com-bination, which can avoid enumerating all thepossible binarization trees of ??
using dynamicprogramming.Let ??
?be the sub-sequence spanning from pto q on the source-side, ?
[?, ?]
be optimal bina-rization tree spanning ??
?, ??
[?, ?]
be the cost of?
[?, ?
], and ??
[?, ?]
be the cost of any binaryrules whose source-side is ??
?, then the cost ofoptimal binarization tree spanning ??
?can becomputed as:??
[?, ?]
= min??????1(??
[?, ?]
+ ??[?,?]
+ ??[?
+ 1, ?
])365The algorithm is shown as follows:CYK-based binarization algorithmInput: a SCFG rule ??
and the cost function ?(.
).Output: the lowest cost binarization on ?
?1:  Function CKYBINARIZATION(??
, ?
)2:      for l = 2 to n do  ?
Length of span3:        for p = 1 to n ?
l + 1 do ?
Start of span4:               q = p + l  ?
End of span5:             for k = p to q ?
1 do ?
Partition of span6:               if not CONSECUTIVE(?
?, ?
, ?
?
+ 1,?
)then next loop7:                   ??
[?, ?]
?
?(???
)8:                   curCost ?
??
?, ?
+??
?, ?
+??[?
+ 1,?
]9:                 if curCost  <  minCost then10:                   minCost ?
curCost11:                    ?
[?, ?]
?
COMBINE(?
[?, ?
], ?[?
+ 1,?
])12:             ??
?, ?
?
minCost13:    return ?[1,?
]14: Function CONSECUTIVE(( a, b), (c, d))15:    return (b = c ?
1) or (d = a ?
1)where n is the number of tokens (consecutiveterminals are viewed as a single token) on thesource-side of ??
.
COMBINE(?
[?, ?
], ?[?
+ 1,?
])combines the two binary sub-trees into a largersub-tree over ???.
?
?, ?
= (?, ?)
means that thenon-terminals covering ??
?have the consecutiveindices ranging from a to b on the target-side.
Ifthe target non-terminal indices are not consecu-tive, we set ?
?, ?
= (?1,?1).
?
??
?= ?(??
)where ??
is any rule in the bucket ?
???
,??
.In the algorithm, lines 9-11 implement dynam-ic programming, and the function CONSECUTIVEchecks whether the two spans can be combined.VB NP ?V[1,2] V[3,4]VPJJRV[2,3]V[1,3] V[2,4]c=6619 c=874 c=62c=884 c=876 c=64c=6629c=885c=6682c=65VB NP will be JJRlowest costc=0 c=0 c=0 c=0Figure 4: Binarization forest for an SCFG rule?(?)
?(?)
?(?)
?(?
)VB NP 6619 VB NP ?
10NP ?
874 NP ?
JJR 2?
JJR 62 VB NP ?
JJR 1Table 1: Sub-sequences and corresponding costsFigure 4 shows an example of the compactforest the algorithm builds, where the solid linesindicate the optimal binarization of the rule,while other alternatives pruned by dynamic pro-gramming are shown in dashed lines.
The costsfor binarization trees are computed based on thecost table given in Table 1.The time complexity of the CKY-based bina-rization algorithm is ?
(n3), which is higher thanthat of the linear binarization such as the syn-chronous binarization (Zhang et al, 2006).
But itis still efficient enough in practice, as there aregenerally only a few tokens (n < 5) on thesource-sides of SCFG rules.
In our experiments,the linear binarization method is just 2 timesfaster than the CKY-based binarization.3.4 Iterative Cost ReductionHowever, ?(?)
cannot be easily predetermined ina static way as is assumed in Section 3.3 becauseit depends on ??
and should be updated whenevera rule in ?
is binarized differently.
In our workthis problem is solved using the iterative costreduction algorithm, in which the update of ?
?and the cost function ?(?)
are coupled together.Iterative cost reduction algorithmInput: An SCFG ?Output: An equivalent binary SCFG ??
of ?1: Function ITERATIVECOSTREDUCTION(?
)2:   ??
?
?03:   for each ?
?
?0do4:        ?(?)
=  ?
?,?05:   while ?(??)
does not converge do6:        for each ??
?
?
do7:            ?[???]
?
??
?
?(??
)8:            for each ?
?
?(??)
do9:                for each ??
?
?
?,??
do10:                  ?
??
?
?
??
?
111:          ?(??)
?
CKYBINARIZATION(??
, ?
)12:          ??
?
?[???]
?
?(??
)13:          for each ?
?
?(??)
do14:              for each ??
?
?
?,??
do15:                  ?
??
?
?
??
+ 116: return ?
?In the iterative cost reduction algorithm, wefirst obtain an initial binary SCFG ?0 using thesynchronous binarization method proposed in(Zhang et al, 2006).
Then ?0 is assigned to aniterative variable ??.
The cost of each binary rulein ?0 is computed based on ?0 according to Equ-ation (1) (lines 3-4 in the algorithm).After initialization, ??
is updated by iterativelyfinding better binarization for each rule in ?.
Thebasic idea is: for each ??
in ?
, we remove thecurrent binarization result for ??
from ??
(line 7),while the cost function ?(?)
is updated accor-dingly since the removal of binary rule ?
??(??)
results in the reduction of the size of thecorresponding bucket ?
?,??
.
Lines 8-10 im-366plement the cost reduction of each binary rule inthe bucket ?
?,?
?
.Next, we find the lowest cost binarization for??
based on the updated cost function ?(?)
withthe CKY-based binarization algorithm presentedin Section 3.3 (line 11).At last, the new binarization for ??
is addedback to ??
and ?(?)
is re-updated to synchronizewith this change (lines 12-15).
Figure 5 illu-strates the differences between the static costreduction and the iterative cost reduction.RiRi-1Ri+1......the ithruleGbinarizerQ(?
)binarize(a) static cost reductionRiRi-1Ri+1......the ithruleGbinarizerQ(?
)G0(b) iterative cost reductionupdatestaticdynamicbinarizeFigure 5: Comparison between the static costreduction and the iterative cost reductionThe algorithm stops when ?(??)
does not de-crease any more.
Next we will show that ?(??
)is guaranteed not to increase in the iterativeprocess.For any ?(??)
on ??
, we have?
?[???]
?
?
?
?= 2 ?
?
?
??
+  ?
??
+ ?
?[???
]As both  ?
??
and ?
?[???]
are constants withrespect to ?(?
??
), ?
?[???]
?
?
??
is a li-near function of ?(?
??
), and the correspond-ing slope is positive.
Thus ?
?[???]
?
?
?
?reaches the lowest value only when ?(?
??
)reaches the lowest value.
So ?
?[???]
?
?
?
?achieves the lowest cost when we replace thecurrent binarization with the new binarization??(??)
(line 12).
Therefore ?
?[???]
?
?
?
?does not increase in the processing on each ??
(lines 7-15), and ?(??)
will finally converge to alocal minimum when the algorithm stops.4 ExperimentsThe experiments are conducted on Chinese-to-English translation in a state-of-the-art string-to-tree SMT system.
All the results are reported interms of case-insensitive BLEU4(%).4.1 Experimental SetupOur bilingual training corpus consists of about350K bilingual sentences (9M Chinese words +10M English words)2 .
Giza++ is employed toperform word alignment on the bilingual sen-tences.
The parse trees on the English side aregenerated using the Berkeley Parser3.
A 5-gramlanguage model is trained on the English part ofLDC bilingual training data and the Xinhua partof Gigaword corpus.
Our development data setcomes from NIST2003 evaluation data in whichthe sentences of more than 20 words are ex-cluded to speed up the Minimum Error RateTraining (MERT).
The test data sets are theNIST evaluation sets of 2005 and 2008.Our string-to-tree SMT system is built basedon the work of (Galley et al, 2006; Marcu et al,2006), where both the minimal GHKM andSPMT rules are extracted from the training cor-pus, and the composed rules are generated bycombining two or three minimal GHKM andSPMT rules.
Before the rule extraction, we alsobinarize the parse trees on the English side usingWang et al (2007) ?s method to increase thecoverage of GHKM and SPMT rules.
There aretotally 4.26M rules after the low frequency rulesare filtered out.
The pruning strategy is similar tothe cube pruning described in (Chiang, 2007).
Toachieve acceptable translation speed, the beamsize is set to 50 by default.
The baseline systemis based on the synchronous binarization (Zhanget al, 2006).4.2 Binarization SchemesBesides the baseline (Zhang et al, 2006) anditerative cost reduction binarization methods, wealso perform right-heavy and random synchron-ous binarizations for comparison.
In this paper,the random synchronous binarization is obtainedby: 1) performing the CKY binarization to buildthe binarization forest for an SCFG rule; then 2)performing a top-down traversal of the forest.
Inthe traversal, we randomly pick a feasible binari-zation for each span, and then go on the traversalin the two branches of the picked binarization.Table 2 shows the costs of resulting binarySCFGs generated using different binarizationmethods.
The costs of the baseline (left-heavy)2 LDC2003E14, LDC2003E07, LDC2005T06 andLDC2005T103 http://code.google.com/p/berkeleyparser/367and right-heavy binarization are similar, whilethe cost of the random synchronous binarizationis lower than that of the baseline method4.
Asexpected, the iterative cost reduction method ob-tains the lowest cost, which is much lower thanthat of the other three methods.Method cost of binary SCFG ?
?Baseline 4,897MRight-heavy 5,182MRandom 3,479MIterative cost reduction    185MTable 2: Costs of the binary SCFGs generatedusing different binarization methods.4.3 Evaluation of TranslationsTable 3 shows the performance of SMT systemsbased on different binarization methods.
Theiterative cost reduction binarization methodachieves the best performance on the test sets aswell as the development set.
Compared with thebaseline method, it obtains gains of 0.82 and0.84 BLEU scores on NIST05 and NIST08 testsets respectively.
Using the statistical signific-ance test described by Koehn (2004), the im-provements are significant  (p < 0.05).Method Dev NIST05 NIST08Baseline 40.02 37.90 27.53Right-heavy 40.05 37.87 27.40Random 40.10 37.99 27.58Iterative costreduction40.97* 38.72* 28.37*Table 3: Performance (BLUE4(%)) of differentbinarization methods.
* = significantly better thanbaseline (p < 0.05).The baseline method and the right-heavy bina-rization method achieve similar performance,while the random synchronous binarization me-thod performs slightly better than the baselinemethod, which agrees with the fact of the costreduction shown in Table 2.
A possible reasonthat the random synchronous binarization me-thod can outperform the baseline method lies inthat compared with binarizing SCFG in a fixedway, the random synchronous binarization tendsto give a more even distribution of rules amongbuckets, which alleviates the problem of edgecompetition.
However, since the high-frequencysource sub-sequences still have high probabilitiesto be generated in the binarization and lead to the4 We perform random synchronous binarization for 5times and report the average cost.excess competing edges, it just achieves a verysmall improvement.4.4 Translation Accuracy vs.
Cost of BinarySCFGWe also study the impacts of cost reduction ontranslation accuracy over iterations in iterativecost reduction.
Figure 6 and Figure 7 show theresults on NIST05 and NIST08 test sets.
We cansee that the cost of the resulting binary SCFGdrops greatly as the iteration count increases,especially in the first iteration, and the BLEUscores increase as the cost decreases.Figure 6: Cost of binary SCFG vs. BLEU4 (NIST05)Figure 7: Cost of binary SCFG vs. BLEU4 (NIST08)4.5 Impact of Beam SizeIn this section, we study the impacts of beamsizes on translation accuracy as well as compet-ing edges.
To explicitly investigate the issue un-der large beam sizes, we use a subset of NIST05and NIST08 test sets for test, which has 50 Chi-nese sentences of no longer than 10 words.Figure 8 shows that the iterative cost reductionmethod is consistently better than the baselinemethod under various beam settings.
Besides theexperiment on the test set of short sentences, wealso conduct the experiment on NIST05 test set.To achieve acceptable decoding speed, we rangethe beam size from 10 to 70.
As shown in Figure9, the iterative cost reduction method also out-performs the baseline method under variousbeam settings on the large test set.Though enlarging beam size can reduce thesearch errors and improve the system perfor-mance, the decoding speed of string-to-tree SMTdrops dramatically when we enlarge the beamsize.
The problem is more serious when long1.0E+081.0E+091.0E+1037.83838.238.438.638.80 1 2 3 4 5performance(BLEU4) costiterationBLEU4(%) cost of G'1.0E+081.0E+091.0E+1027.427.627.82828.228.40 1 2 3 4 5performance(BLEU4) costBLEU4(%) cost of G'iteration368sentences are translated.
For example, when thebeam size is set to a larger number (e.g.
200), ourdecoder takes nearly one hour to translate a sen-tence whose length is about 20 on a 3GHz CPU.Decoding on the entire NIST05 and NIST08 testsets with large beam sizes is impractical.Figure 8: BLEU4 against beam size (small test set)Figure 9: BLEU4 against beam size (NIST05)Figure 10 compares the baseline method andthe iterative cost reduction method in terms oftranslation accuracy against the number of edgesproposed during decoding.
Actually, the numberof edges proposed during decoding can be re-garded as a measure of the size of search space.We can see that the iterative cost reduction me-thod outperforms the baseline method under var-ious search effort.Figure 10: BLEU4 against competing edgesThe experimental results of this section showthat compared with the baseline method, the iter-ative cost reduction method can lead to muchfewer edges (about 25% reduction) as well as thehigher BLEU scores under various beam settings.4.6 Edge Competition vs.
Cost of BinarySCFGIn this section, we study the impacts of cost re-duction on the edge competition in the chart cellsof our CKY-based decoder.
Two metrics areused to evaluate the degree of edge competition.They are the variance and the mean of the num-ber of competing edges in the chart cells, wherehigh variance means that in some chart cells therules have high risk to be pruned due to the largenumber of competing edges.
The same situationholds for the mean as well.
Both of the two me-trics are calculated on NIST05 test set, varyingwith the span length of chart cell.Figure 11 shows the cost of resulting binarySCFG and the variance of competing edgesagainst iteration count in iterative cost reduction.We can see that both the cost and the variancereduce greatly as the iteration count increases.Figure 12 shows the case for mean, where thereduction of cost also leads to the reduction ofthe mean value.
The results shown in Figure 11and Figure 12 indicate that the cost reduction ishelpful to reduce edge competition in the chartcells.Figure 11: Cost of binary SCFG vs. variance ofcompeting edge number (NIST05)Figure 12: Cost of binary SCFG vs. mean ofcompeting edge number (NIST05)We also perform decoding without pruning(i.e.
beam size = ?)
on a very small set whichhas 20 sentences of no longer than 7 words.
Inthis experiment, the baseline system and our iter-ative cost reduction based system propose14,454M and 10,846M competing edges respec-tively.
These numbers can be seen as the realnumbers of the edges proposed during decodinginstead of an approximate number observed inthe pruned search space.
It suggests that our me-thod can reduce the number of the edges in realsearch space effectively.
A possible reason to32343638404210 50 100 500 1000 5000baselinecost reductionBLEU4(%)beamsize353637383910 20 30 40 50 70baselinecost reductionbeamsizeBLEU4(%)3234363840421E+07 1E+08 1E+09 1E+10baselinecost reductionBLEU4(%)# ofedges1.0E+51.0E+61.0E+71.0E+81.0E+91.0E+101.0E+71.0E+81.0E+91.0E+100 1 2 3 4 5span=2span=3span=5span=7span=10span=20costiterationvariance cost of G'1.0E+61.0E+71.0E+81.0E+91.0E+108.0E+31.0E+50 1 2 3 4 5span=2span=3span=5span=7span=10span=20costiterationmean cost of G'369this result is that the cost reduction based binari-zation could reduce the probability of rule mis-matching caused by binarization, which results inthe reduction of the number of edges proposedduring decoding.5 Conclusion and Future WorkThis paper introduces a new binarization method,aiming at choosing better binarization for SCFG-based SMT systems.
We demonstrate the effec-tiveness of our method on a state-of-the-artstring-to-tree SMT system.
Experimental resultsshow that our method can significantly outper-form the conventional synchronous binarizationmethod, which indicates that better binarizationselection is very beneficial to SCFG-based SMTsystems.In this paper the cost of a binary rule is de-fined based on the competition among the binaryrules that have the same source-sides.
However,some binary rules with different source-sidesmay also have competitions in a chart cell.
Wethink that the cost of a binary rule can be betterestimated by taking the rules with differentsource-sides into account.
We intend to studythis issue in our future work.AcknowledgementsThe authors would like to thank the anonymousreviewers for their pertinent comments, and Xi-nying Song, Nan Duan and Shasha Li for theirvaluable suggestions for improving this paper.ReferencesEugene Charniak,  Mark Johnson, Micha Elsner, Jo-seph Austerweil, David Ellis, Isaac Haxton, Cathe-rine Hill, R. Shrivaths, Jeremy Moore, Michael Po-zar, and Theresa Vu.
2006.
Multilevel Coarse-to-Fine PCFG Parsing.
In Proc.
of HLT-NAACL 2006,New York, USA, 168-175.Eugene Charniak, Sharon Goldwater, and Mark John-son.
1998.
Edge-Based Best-First Chart Parsing.
InProc.
of the Six Workshop on Very Large Corpora,pages: 127-133.David Chiang.
2005.
A Hierarchical Phrase-BasedModel for Statistical Machine Translation.
In Proc.of ACL 2005, Ann Arbor, Michigan, pages: 263-270.David Chiang.
2007.
Hierarchical Phrase-basedTranslation.
Computational Linguistics.
33(2):202-208.Michel Galley, Jonathan Graehl, Kevin Knight, Da-niel Marcu, Steve DeNeefe, Wei Wang, and Igna-cio Thayer.
2006.
Scalable Inference and Trainingof Context-Rich Syntactic Translation Models.
InProc.
of ACL 2006, Sydney, Australia, pages: 961-968.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a translation rule?In Proc.
of HLT-NAACL 2004, Boston, USA, pag-es: 273-280.Liang Huang.
2007.
Binarization, Synchronous Bina-rization, and Target-side binarization.
In Proc.
ofHLT-NAACL 2007 / AMTA workshop on Syntaxand Structure in Statistical Translation, New York,USA, pages: 33-40.Tadao Kasami.
1965.
An Efficient Recognition andSyntax Analysis Algorithm for Context-Free Lan-guages.
Technical Report AFCRL-65-758, AirForce Cambridge Research Laboratory, Bedford,Massachusetts.Philipp Koehn.
2004.
Statistical Significance Tests forMachine Translation Evaluation.
In Proc.
ofEMNLP 2004, Barcelona, Spain , pages: 388?395.Daniel Marcu, Wei Wang, Abdessamad Echihabi, andKevin Knight.
2006.
SPMT: Statistical machinetranslation with syntactified target language phras-es.
In Proc.
of EMNLP 2006, Sydney, Australia,pages: 44-52.Giorgio Satta and Enoch Peserico.
2005.
Some Com-putational Complexity Results for SynchronousContext-Free Grammars.
In Proc.
of HLT-EMNLP2005, Vancouver, pages: 803-810.L.
Shapiro and A.
B. Stephens.
1991.
Bootstrap per-colation, the Sch?
oder numbers, and the n-kingsproblem.
SIAM Journal on Discrete Mathematics,4(2):275-280.Xinying Song, Shilin Ding and Chin-Yew Lin.
2008.Better Binarization for the CKY Parsing.
In Proc.of EMNLP 2008, Hawaii, pages: 167-176.Yoshimasa Tsuruoka and Junichi Tsujii.
2004.
Itera-tive CKY Parsing for Probabilistic Context-FreeGrammars.
In Proc.
of IJCNLP 2004, pages: 52-60.Wei Wang  and  Kevin Knight and Daniel Marcu.2007.
Binarizing Syntax Trees to Improve Syntax-Based Machine Translation Accuracy.
In Proc.
ofEMNLP-CoNLL 2007, Prague, Czech Republic,pages: 746-754.D.
H. Younger.
1967.
Recognition and Parsing ofContext-Free Languages in Time n3.
Informationand Control, 10(2):189-208.Hao Zhang, Liang Huang, Daniel Gildea, and KevinKnight.
2006.
Synchronous Binarization for Ma-chine Translation.
In Proc.
of HLT-NAACL 2006,New York, USA, pages: 256- 263.370
