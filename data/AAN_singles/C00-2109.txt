Backward Beam Search Algorithmfor Dependency Analysis of JapaneseSatoshi  Sek ineComputer Science DepartmentNew York University715 Broadway, 7th floorNew York, NY 10003, USAsekine@cs, nyu.
eduK iyotaka  Uch imoto  H i tosh i  IsaharaCommunications Research Laboratory588-2 Iwaoka, Iwaoka-cho, Nishi-ku,Kobe, Hyogo, 651-2492, Japan\[uchimoto,  i sahara \ ]  @crl.
go.
j pAbst rac tBackward beam search tbr dependency analy-sis of Japanese is proposed.
As dependenciesnormally go fl'om left to right in Japanese, it iseffective to analyze sentences backwards (fromright to left).
The analysis is based on a statisti-cal method and employs a bemn search strategy.Based on experiments varying the bemn searchwidth, we found that the accuracy is not sen-sitivc to the bemn width and even the analysiswith a beam width of 1 gets ahnost he stone de-pendency accuracy as the best accuracy using awider bemn width.
This suggested a determin-istic algorithm for backwards Japanese depen-dency analysis, although still the bemn searchis eitbctive as the N-best sentence accuracy isquite high.
The time of analysis is observed tobe quadratic in the sentence l ngth.1 In t roduct ionDependency analysis is regarded as one of thestandard methods of Japanese syntactic anal-ysis.
The Japanese dependency structure isusually represented by the relationship betweenphrasal units called 'bunsetsu'.
A bunsetsu nsu-ally contains one or more content words, like anoun, verb or adjective, and zero or more func-tion words, like a postposition (case marker)or verb/noun sul~\[ix.
The relation between twobunsetsu has a direction front a dependent toits head.
Figure 1 shows examples of 1)unsetsuand dependencies.
Each bunsetsu is separatedby "I"" The  first segment "KARE-HA" consistsof two words, KARE (He) and HA (subject casemarker).
The  numbers  in the "head" line showthe head ID of the corresponding bunsetsus.Note that the last segment does not have a head,and it is the head bunsetsu of the sentence.
Thetask of the Japanese dependency analysis is tofind the head ID for each bunsetsu.The analysis proposed in this paper has twoconceptual steps.
In the first step, dependencylikelihoods are calculated for all possible pairsof bunsetsus.
In the second step, an optimal de-pendency set for the entire sentence is retrieved.In this paper, we will mainly discuss the secondstep, a method fbr finding an optimal depen-dency set.
In practice, the method proposed inthis paper should be able to be combined withany systems which calculate dependency likeli-hoods.It is said that Japanese dependencies have thetbllowing characteristics1:(1) Dependencies are directed from left to right(2) Dependencies don't cross(3) Each seglnent except he rightmost one hasonly one head(4) In many cases, the left; context is not nec-essary to determine a dependencyThe analysis method proposed in this paper as-sumed these characteristics and is designed toutilize them.
Based on these assumptions, wecan analyze a sentence backwards (from rightto left) in an efficient manner.
There are twomerits to this approach.
Assume that we areanalyzing the M-th segment of a sentence oflength N and analysis has already been donefor the (M + 1)-th to N-th segments (M < N).The first merit is that the head of the depen-dency of the M-th segment is one of the seg-1Of course, there are several exceptions (S.Shirai,1998), but the frequencies of such exceptions are neg-ligible compared to the current precision of the system.We believe those exceptions have to be treated when theproblems we are facing at the moment are solved.
As-sumption (4) has not been discussed very much, but ourinvestigation with humans showed that it is true in moretitan 90?./0 of the cases.754ID i 2 3 4 5 6KARE-HA \[ FUTATABI I PAI-W0 \[ TSUKURI, I KANOJO-NI I 0KUTTA.
(He-subj) (again) (pie-obj) (made ,) (to her) (present)Head 6 4 4 6 6 -Translation: He made a pie again and presented it to her.Figure 1: Exmnt)le a JaI)anese sentence, 1)unsetsus and det)endenciesments between M + 1 and N (because of as-sumption 1), which are already analyzed.
Be-cause of this, we don't have to kce 1) a huge lnlln-1)er of possible analyses, i.e.
we can avoid some-thing like active edges in a chart parser, or mak-ing parallel stacks in GLR parsing, as we canmake a decision at this time.
Also, we can usethe beam search mechanism, 1)y keet)ing only acertain nmnl)er of.analysis candidates at (',achsegment.
The width of the 1)(;am search can 1)c,easily tuned and the memory size of the i)ro-(:ess is l)rot)ortional to the 1)roduct of the inl)utsentence length and tile boron search width.The other merit is that the possit)le headsof tile d(~l)en(lency can t)e narrowed down 1)c-cause of the ~ssuml)tion of non-crossing det)en-(lencies (assumption 2).
For exani1)le , if theK-th seglll(;nl; dCl)ends on the L-tll segnient(A4 < \]~ <~ L), then the \]~J-th segillent (:~l~n'tdepend on any segments between 1~ and L.According to our experilnent, this reduced thenuml)er of heads to consider to less than 50(X~.The te(:hnique of backw~trd analysis of,lal)anese sentences has 1)een used in rule-basedmethods, for example (Fujita, 1988).
How-ever, there are several difficulties with rule-based methods.
First the rules are created byhmnans, so it is difficult to have wide cover-age and keel) consistency of the rules.
Also, itis difficult to incorporate a scoring scheme inrule-1)ased methods.
Many such met;hods usedhem'isties to make deterministic decisions (andbacktracking if it; fails in a sear(:hing) ratherl;han using a scoring scheme.
However, the com-1)ination of the backward analysis and the sta-tistical method has very strong advantages, oneof which is the 1)emn search.2 Stat i s t i c  f rameworkWe.
coin|lined tile backward beam search strat-egy with a statistical dependency analysis.
'riledet~fil of our statistic framework is describedill (Uehimoto et al, 1999).
There have beena lot of prol)OS~fls for statistical analysis, inninny languages, in particular in English andJapanese (Magerman, 1995) (Sekine and Grish-man, 1995) (Collins, 1997) (I/atnal)arkhi, 1997)(K.Shirai et.al, 1998) (Fujio and Matsnlnoto,1998) (Itaruno ct.al, 1997)(Ehara, 1998).
Oneof the most advance(t systems in English is l)ro-posed 1)y I{atnaparkhi.
It, uses the MaximumEntropy (ME) model and both of the accuracyand the speed of the system arc among the bestret)ortcd to date.
Our  system uses the MEmodel, too.
in the ME model, we define a setel!
\]2~,atlll'eS which arc thought to l)e uscflfl indel)ealden(:y analysis, and it: learns the weightsof the R~atures fl'om training data.
Our t~ntttresin(:lude part-of-st)eech, inflections, lexical items,the existence of a contain or bra(:ket 1)etweenthe segments, and the distmme between the seg-ments.
Also, confl)inations of those features areused as additional fe, atures.
The system eal-(:ulates the probabilities of dependencies basedon the model, which is trained using a trainingcorpus.
The probability of an entire sentence isderived from the 1)roduct of tile probal)ilities ofall the dependencies in the sentence.
We choosethe analysis with the highest probafl)ility to bethe analysis of the sentence.
Although the ac-curacy of the analyzer is not the main issue ofthe t)al)er, as any types of models which use de-1)endency 1)rol)al)ilities can be iml)lelnented byour method, the 1)ertbrmance r t)orted in (Uchi-lnoto et al, 1999) is one of the best results re-ported by statistic~flly based systems.7553 A lgor i thmIn this section, the analysis algorithm will be de-scribed.
First the algorithm will be illustratedusing an example, then the algorithm will beformally described.
The main characteristics ofthe algorithm are the backward analysis and thebeam search.The sentence "KARE-HA FUTATABI PAI-W\[ITSUKURI, KANOJ0-NI 0KUTTA.
(He made a pieagain and presented it to her)" is used as an in-put.
We assume the POS tagging and segmen-tation analysis have been done correctly beforestarting the process.
The border of each seg-ment is shown by "1".
In the figures, the head ofthe dependency for each segment is representedby the segment number shown at the top of eachsegment.<Initial>ID 1 2 3 4 5 6RARE-HA \[ FUTATABI \[ PAI-WO \[ TSUKURI, \[ KANOJO-NI I OKUTTA.
(He-subj) (again) (pie-obj) (made ,) (to her) (present).................................................................Algorithm1.
Analyze np to the second segment from theendThe last segment has no dependency, sowedon't have to analyze it.
The second seg-ment fl'om the end always depends on thelast segment.
So the result up to the sec-end segment from the end looks like thefollowing.<Up to the second segment from the end>ID 1 2 3 4 5 6KARE-HA I FUTATABI \[ PAI-WO I TSUKURI, I KANOJO-NI I OKFITA.
(He-subj) (again) (pie-obj) (made ,) (to her) (present)Cand 6..................................................................
The third segment from the endThis segment ("TSUKURI," ) has two depen-dency candidates.
One is the 5th segment("KANOJ0-NI") and the other is the 6th seg-ment ("0KUTTA").
Now, we use the proba-bilities calculated using the ME model inorder to assign probabilities to the two can-didates (Candl and Cand2 in the followingfigure).
Let's assume the probabilities 0.1and 0.9 respectively as an example.
At thetail of each analysis, the total probability(the product of the probabilities of all de-pendencies) is shown.
The candidates aresorted by the total probability..<Up to the third segment from the end>ID 1 2 3 4 5 6KARE-HA I FUTATABI I PAI-WO I TSUKURI, I KANOJO-HI I OKUITA.
(He-subj) (again) (pie-obj) (made ,) (to her) (present)Candl 6 0 - (0.9)Cand2 5 6 - (0.I).................................................................The tburth segment from the endFor each of the two candidates created atthe previous tage, the dependencies of thefburth segment from the end ("PAI-W0")will be analyzed.
For Candl, the segmentcan't have a dependency to the fifth seg-ment ("KANOJ0-1gI"), because of the non-crossing assmnption.
So the probabili-ties of the dependencies only to the fourth(Candi-1) and the sixth (Candi-2) seg-ments are calculated.
In the example, theseprobabilities are assmned to be 0.6 and 0.4.A similar analysis is conducted for Cand2(here probabilities are assumed to be 0.5,0.1 and 0.4) and three candidates are cre-ated (Cand2-1, Cand2-2 and Cand2-3).<Up to the fourth segment from the end>ID 1 2 3 4 5 6RARE-HA I FUTATABI I PAI-WO I TSUKURI, I KANOJO-NI I OKUTTA.
(He-subj) (again) (pie-obj) (made ,) (to her) (present)C~dt - i  4 6 6 - (0.64)Candl-2 6 6 6 - (0.30)Cand2-1 4 5 6 - (0.05)Cand2-2 6 5 6 - (0.04)Caud2-3 5 5 6 - (0.01).................................................................As tile analysis proceeds, a large number(almost L!)
of candidates will he created.However, by linfiting the number of candi-dates at each stage, the total nmnber ofcandidates can be reduced.
This is thebeam search, one of the characteristics ofthe algorithm.
By observing the analysesin the example, we can e~sily imagine thatthis beam search may not cause a seriousproblem in performance, because the candi-dates with low probabilities may be incor-rect anyway.
For instance, when we set thebeam search width = 3, then Canal2-2 andCand2-3 in the figure will be discarded atthis stage, and hence won't be used in thefollowing analyses.
The relationship of thebeam search width and the accuracy oh-served in our experiments will be reportedin the next section.756.
Up to the, first segmentThe analyses are conducted in the, sameway up to the first segment.
For example,the result of tile analysis tbr the entire sell-tence will be shown below.
(Appropriate,probabilities are used.
)4.2 Beam search  w idth  and  accuracyIn this subsection, the relationship between thebeam width and the accuracy is discussed.
Inprinciple, the wider the beam search width, themore analyses can be retained and the betterthe accuracy cml be expected.
However, the re-.................................................................. sultis somewhat different froan tile expectation.<Up to the first segment>ID 1 2 3 4 5 6KARE-IIA \[ FUTATABI \[ PAl-W0 { TSUKURI, \[ KANOJ0-NI \[ 0KUTTA.
(Ile-subj) (again) (pie-obj) (made ,) (to her) (present)Candl 6 4 4 6 0 - (0. ii)Cand2 4 4 6 6 6 - (0 .09)Cand3 6 4 6 5 6 - (0.05).................................................................Now, the formal algorithm is described induc-tiveJy in Figure 3.
The order of the analysis isquadratic ill the length of the sentence.4 Exper imentsIn this section, experiments and evaluations willbe reported.
We use the Kyoto University Cor-pus (version 2) (Kurohashi el.el, 1{)97), a handcreated Japanese corpus with POS-tags, bun-setsu segments and dependency information.The sentences in the articles from January 1,1994 to January 8, 1994 (7,960 sentences) a.reused t'or tim training of the ME model, andthe sente, nccs in the artMes of Janum'y 9, 1994:(1,246 sentences) are used for the ewduation.The seid;ences ill the articles of Ja l luary 10, 1994are kept for future evaluations.4.1 Bas ic  Resu l tThe evahlation result of our systenl is shown illTable 1.
The experiment uses the correctly seg-mente(1 and 1)art-oSsl)eet'h tagger1 sentences ofthe Kyoto University corpus.
The bealn searchwidth is sol; to 1, in other words, the systeln runsdeterministically.
Here, 'dependency accuracy'Table 1: lBvaluationDependency accuracySentence accuracyAverage analysis time87.14% (9814/11263)40.60% 0503/1239)0.03 secis the percentage of correctly analyzed depen-dencies out of all dependencies.
'Sentence accu-racy' is the i)ercentage of the sentences in whichall the dependencies are analyzed correctly.Table 2 shows the dependency accuracy andsentence accuracy for bemn widths 1 through20.
The difference is very small, but the bestTable 2: Relationship between beam width andaccuracyBemn width Dependency SentenceAccuracy Accuracy123456710152087.1487.1687.2087.1.587.1487.1687.2087.2086.2186.2140.6040.7640.7640.6840.6040.6040.6040.6040.6040.60accuracy is obtained when the beain width is 11(fbr the dependency accuracy), and 2 and 3 (tbrthe sentence accuracy).
This proves that thereare cases where the analysis with the highestproduct of probabilities is not correct, but theanalysis decide(1 at each stage is correct.
This isa very interesting result of our experiment, andit is related to assulnption 4 regarding Japanesedependency, lnentioned earlier.This suggests that when we analyze a.Japanese sentence backwards, we can do it de-terministically without great loss of accuracy.Table 3 shows where the mlalysis with bemnwidth 1 appears among the analyses with bealnwidth 200.
It shows that most deterministicanalyses appear as tile best analysis in the non-deterministic analyses.
Also, mnong the deter-aninistic analyses which are correct (503 Sell-tences), 498 sentences (99.0%) have the samemmlysis at the best rank in the 200-beam-widthanalyses.
(Followed by 3 sentences at the see-.end, 1 sentence ach at the third and fifth rank.
)It means that in most of the cases, the mmlysis757<Variable>Length:W:C\[len\]:Length of the input sentence in segmentsThe beam search widthCandidate list; C for each segment keepsthe top W partial analyses from that segmentto the last segment.<Initial Operation>The second segment from the end depends on the last segment.This analysis is stored in C\[Length-l\].<Inductive Operation>Assume the analysis up to the (M+l)-th segment has been finished.For each candidate ~c ' in C\[M+i\], do the following operation.Compute the possible dependencies of the M-th segment compatiblewith 'c'.
For each dependency, create a new candidate Cd~ byadding the dependency to 'c'.
Calculate the probability of 'd'.If C\[M\] has fewer than W entries, add ~d ~ to C\[M\];else if the probability of Cd~ > the probability of the leastprobable entry of C\[M\], replace this entry by 'd';else ignore 'd 'When the operation finishes for all candidates in C\[M+i\],proceed to the analysis of the (M-l)-th segment.Repeat the operation until the first segment is analyzed.The best analysis for the sentence is the best candidate inC\[1\].Figure 2: Formal Algorithlnwith the highest probability at each stage alsohas the highest probability as a whole.
This isrelated to assumption 4.
The best analysis withthe left context and the best analysis withouttile left context are the same 95% of the time ingeneral, and 99% of the time if the analysis iscorrect.
These numbers are much higher thanour human experinmnt mentioned in the ear-lier footnote (note that the number here is thepercentage in terms of sentences, and the num-ber in the footnote is the percentage in terms ofsegnmnts.)
It means that we may get good ac-curacy even without left contexts in analyz ingJapanese dependencies.4.3 N-Best  accuracyAs we can generate N-best results, we measuredN-best sentence accuracy.
Figure 3 shows theN-best accuracy.
N-best accuracy is the per-centage of tile sentences which have the correctanalysis among its top N analyses.
By settinga large beam width, we can observe N-best ac-curacy.
The table shows the N-best accuracywhen the beam width is set, to 20.
When we setN = 20, 78.5% of the sentences have the cor-rect analysis in the top 20 analyses.
If we have758Rank 1\]5"e<luc, n y 1175(%) (.
{},5.8)Rank 11Frequen(:y 1(%)Table 3: The rank of the deterministic analysis2 3 4: 5 6 7 820 11 8 4 2 1 2(1.6) (0.9) (0.6) (0.3) ( I ) .2 ) (0 .1 ) (0 .2 )12 j,5 1(i 17 180 o 1 0 J J(0.1) ({}.1) (0.1) (0.1)9 100 3(02)19 20 and more0 8(0.6)807060504030Sent;once Accuracy.53%#, 40.60%I I I I I I I I I I I - ~ T E0 5 10 11.5 20NFigure 3: N-best sentenc(~ Accuracyan ideal sysl;(ml for finding th(~ COl'lCCi; mmlysisa,lnOllg?
th(;ln~ which maS, 11.%O SCllltl,lll;ic O1" COll-l,(;x{; inforlllt~I;io\]\]~ we can have a v(Ty a(:(;Hr~d;ean alyzer.\~TC Call llltl,l((; two interesting observationstrom the result.
The ac(:uracy of the 1--bestmmlysis is about 40%, which is more tlm.n halfof t, he accura(:y of 20-1)est analysis.
This showsthat although the system is not 1)erfb, ct, thecomputation of the 1)rolml)ilities is t)rol)ablygood in order l;o find the correct mmlysis at thetop rank.The other point is that the accm'aey is sat-urated at m'omM 80%.
Iml)rovemel,t over 80%seelns very dit\[icult even if we use a very largebemn width W. (lf we set; W to the numberof all possible combinations, which means al-most L!
for sentence length L, we (21M gC{; 100(~0N-best accm'aey, lint this is not worth eonsidel'-ing.)
This suggests tlmt wc h~we missed some-thing important.
In part;icular, from our inves-tigation of the result, we believe that (:oordinatestructure is one of the most important factorsto iml)rove the accuracy.
This remains one areaof fllturc work.4.4 Speed of  the  analys isBased on the f'(n'nml algorithm, the analysistinle can be estimated as t)rot)orl;ional to thesquare, of the inl)ut sentence length.
Figure 4:shows the relationshi I) between the analysistime and the sentence length when wc set thebeam width to 1.
We use a Sun Ultra10 ma-chine and the process size is about 8M byte.We can see that the actual analyzing time al-Analysis time (see.
)0.30.2 * / "0 ~ ~  , r , , ,0 10 20 30 40Sentence length\]?igure 4: \]~.elationshi 1) between sentence lengthand mmlyzing timemost follows the quadratic urve.
The ~verageamflysis time is 0.03 second and the ~werage sen-tence lengl:h is 10 segments.
The analysis timefor the longest sentence (41 segments) is 0.29second.
W\; have not ot)l;imized the In'ogram interms of speed aim there is room to shrink /;heprocess ize.7595 Conc lus ionIn this paper, we proposed astatistical Jttpanesedependency analysis method which processes asentence backwards.
As dependencies normallygo from left to right in Japanese, it is eflhctiveto analyze sentences backwards (from right toleft).
In this paper, we proposed a Japanese de-pendency analysis which combines a backwardanalysis and a statistical method.
It can nat-urally incorporate a beam search strategy, aneffective way of limiting the search space in thebackwm'd analysis.
We observed that the bestperfbrmances were achieved when the width isvery small.
Actually, 95% of the analyses ob-tained with bemn width=l  were the stone asthe best analyses with beam width=20.
Theanalysis time was proportional to the square ofthe sentence length (nmnber of segments), aswas predicted from the algorithm.
The averageanalysis time was 0.03 second (average sentencelength was 10.0 bunsetsus) and it took 0.29 sec-end to analyze the longest sentence, which has41 segments.
This method can be ~tpplied tovarious languages which haw~ the stone or simi-lar characteristics of dependencies, for exampleKoran, Turkish etc.ReferencesAdam Berger and Harry Printz.
1998 : "AComparison of Criteria for Maximum En-tropy / Mininmm Divergence Feature Selec-tion".
Proceedings of the EMNLP-98 97-106Michael Collins.
1997 : "Three Generative,Lexicalized Models for Statistical Parsing".Proceedings of the ACL-97 16-23Terumasa Ehara.
1998 : "CMculation ofJapanese dependency likelihood based onMaximmn Entropy model".
Proceedings ofthe ANLP, Japan 382-385Masakazn t51jio and Yuuji Matsumoto.
1998: "Japanese Dependency Structure Analysisbased on Lexicalized Statistics".
Proceedingsof the EMNLP-98 87-96Katsuhiko Fujita.
1988 : "A Trial of determin-istic dependency analysis".
Proceedings of theJapanese Artificial Intelligence Annual meet-in9 399-402Masahiko Haruno and Satoshi Shirai and Yoshi-fumi Ooyama.
1998 : "Using Decision Treesto Construct a Practical Parser".
Proceedingsqf the the COLING/A CL-98 505-511Sadao Kurohashi and Makoto Nagao.
1994 :"KN Parser : ,J~tpanese Dependency/CaseStructure Analyzer".
Proceedings of The In-ternational Workshop on Sharable NaturalLanguage Resources 48-55Sadao Kurohashi and Makoto Nagao.
1997 :"Kyoto University text corpus project".
Pro-ceedings of the ANLP, Japan 115-118David Magerman.
1995 : "Statistical Decision-Tree Models for Parsiug".
Proceedings of theACL-95 276-283Adwait I/,atnaparkhi.
1997 : "A Linear Ob-served Time Statistical Parser Based onMaximum Entropy Models".
Proceedings o.fEMNLP-97Satoshi Sekine and Ralph Grishman.
1995 : "ACorpus-based Probabilistic Grammar withOnly Two Non-terminals".
Proceedings of theIWPT-95 216-223Satoshi Shirai.
1998 : "Heuristics and its lira-itation".
Jowrnal o\[ the ANLP, Japan Vol.5No.l, 1-2Kiyoaki Shirai, Kentaro Inui, Takenobu 'lbku-naga and Hozunli Tanaka.
1998 : "An Em-pirical Evaluation on Statistical Parsing ofJapanese Sentences Using Lexical AssociationStatistics".
P'roceedings ofEMNLP-98 80-86Kiyotaka Uchimoto, Satoshi Sekine, HitoshiIsahara.
1999 : "Jat)anese DependencyStructm'e Analysis Based on Maximum En-tropy Models".
P~vceedings o\[ the EACL-99pp196-203760
