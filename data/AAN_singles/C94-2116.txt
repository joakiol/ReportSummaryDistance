VERBAL CASL FRAME ACQUISITION FROM A BIIAN(?,UAL C()RPUS:GRADUAL KNOWI,EDGE ACQUISITIONltideki Tanaka-tNHK Science and Technical Research Laboratorieshanakah@ strl .nhk.o r.jpAbstractThis paper describes acquisilion of English stillace caseflames from a corpus, based on a gradual knowledge acqui-sition approach.
To acquire and unambiguously accumu-late precise knowledge, the process is divided inln threesteps which are assigned to the most appropriate processor:either a human or a computer.
The data is prepared by hu-man workers and the knowledge is acquired and accumu-lated by a leaning program.
By using this method, inconsis-tent hunmn judgement is minimized.
The acquired caseframes basically duplicate Imman work, but are more pre-cise and intelligible.1 Gradual Knowledge AcquisitionWe have been developing an English-to-Japanese nut-chine translation (MT) system (i~t news reports in l-nglish(Aizawa T., 1990) (Tanaka I I., 1991) and have so far stud-ted the translation selection problem for common Englishverbs (Tanaka I1., 1992).
Recently, we examined the prob-lem of multiple translatkms for COllll/lOl\] English verbs(Tanaka \[1., 1993).
Our MT system uses surface verbal caseflames (simply written its case frames) to selccl a Japanesetranslation for an English verb.
The need to acqtuirc andaccumttlate case frames leads directly to three problems.
(1) How to obtain detailed case frames which are accurateenough to mmslate highly polysemous verbs?
(2) ltow to accumnlate a number o1' case frames in an unam-biguous way.
(3) Manual case frame acquisition tends to yield inconsis-tent results ince human judgements are changeable.
\[Iowcan we maintain cousistency?We need to devise a cleat' methodology lor acquiring suf--ficient case flames and accuumlating them in a way that isunambiguous and consistent.In this paper, we propose agradually building up a knowl-edge base from a bilingual corpus to cope with these threeproblems.
The knowledge base is a collection of casefiames.
Fig.
1 shows an overall view of otn approach.The process is divided into three steps which arc assignedto the most appropriate processor: a hmnan or a computer.Using this method, detailed knowledge is obtained fiom theFig.
1 : Case-Frame Tree Acquisition from aBilingual Corpustarget &)main tents, unstable hmnan judgement is confined,and case IYames are accumtdated unambiguously b  using alemning algorithm.We begin by preparing a tagged bilingual corpus seekingdetailed knowledge in target domain texts.
The annotationdescribed in the corpus is tile syntactic information of tiletexts and tile translaliot~.
They are assigned manually sincehnman translators can do such jobs as syalactic lagging andtranslation with far more cousistency than writing caseframes directly.Next, tile corpus is converted into an intermediate dataform called the primitive case-flame table (PCI'T).
Finallya stalistical learning algorilhm is used to extract he caseframes from the PC\['T and accuuuulate hem in a clear-cutfashion.While this approach let us avoid writing case flames di-rectly using linguistic ontemplation, human activity playsan important role in designing and constructing the corpusand converling it into the PCIq' (Fig.
1).The case frames are represented in a discrimination tcee,which has sev01al attractive features lor word-sense selec-tion (Okunmra M., 1990).
The biggest attraction of thelearning algorithm, we think, is its intelligibility; comparedwith the algorithms for neural networks, for example, itproduces highly intelligible results if the inpul is appmpri-727ate.Knowledge acquisition by machine learning from a cor-pus has recently been getting more attention than ever insome natural anguage processing fields.
Cardie(1992,1993) applied this approach to predict he antecedent ofrelative pronouns and attributes of unknown words.Utsuro(1993) introduced a methodology for autonmticallyacquiring the verbal case frames from bilingual corpora in adifferent way than our methodology.2 Case Frames for Translat ionOre" machine translation system uses case frames for thetranslation of English verbs.
Fig.
2 shows illustrative caseframes for the word take.SN \[man\] take ON \[boy\]~..~ (select)SN \[I\] take ON \[him\] PN\[to\] PNc\[BUILD\]~tL-Cb~ < (escort)SN \[HUMAN\] take ON \[CON\] PN\[to\] PNc\[BUILD\]~ -~ -( L, ~ < (bring)Fig.
2: Example of Case Frames for takeWe write case categories (SN (subject noun) andPN(preposition) here) and specify their restrictions.
The re-striction can be a semantic category like tfUMAN or a wordform itself like boy.
There may be several hundred caseframes for the most common English verbs.The translation selection is performed after the parserproduces a syntactic structure for the input sentence.
Thesystem compares the syntactic structure with the caseframes and selects the translation from the best-matchingcase frame.
Translation selection is performed withoutconsidering the context.
Our new case fiames are designedto follow the same protocol.There are three factors to consider at this point.
(1) How many and what kinds of case categories should beused?
(2) In which order should the system compare the syntacticstructure and the case categories in a case fl'ame?
(3) What kind of restriction should we use?In this paper, we will deal mainly with the first two fac-tors.
Our solution is to use a discrimination tree for thecase-flame representation a d a statistical algorithm forlearning.
The necessary case categories are selected andstacked in a tree form, one by one, according to their contri-bution to the translation selection.
We call the obtained treethe case-flame tree.
Fig.
3a is an example of a case-frametree for take.ONh im/ /O~oxbringescort select.
.
.
.
.
.
,... ................................................................ .
.
, .
.
.
.
,  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Fig.
3a: Example of a Case-Frame "FreeON\[box\] ? "
t,ON\[him\] ~,~ON\[him\] PN\[to\] Z~tLTb,<Fig.
3b: Linear Case Franles for Fig.
3aComparison with the syntactic structure is made fi'om theroot node to the leaf nodes of the case frame-tree and nobacktracking is allowed.
The comp,'u'ison is executed deter-ministical\[y.
If we read the tree fiom the root to the leafs, itcan be expanded into a linear ease fiame, as shown in Fig.3b.
This increases the intelligibility of the case-fiame treeenabling a human lexicographer to evaluate it from a lin-guistic viewpoint.3 Learn ing  f rom the  PCFTA case-fralne tree can be regarded as a decision tree.l)ecision-lree l arning has a long research istory and manyalgorithms have been developed.
Among them, the ID3group (Quinlan J., 1993) of programs and its descendantssatisfy our solution in Sec.
2.
We apply the latest program,C4.5 (Quinlan J., 1993), to our problem.
This algorithmlearns a decision tree from an attribute-value and class table.An exatnple of such a table is shown in Table 1.Tal)le 1: Example nf a Primitive Case Franle TableSN V ON PN PNc translationI take him to theateryou take him to schoolyou take him to parkyou take box to theateryou take box to parkI take box to school1 take him 0 0you take him 0 0~g- (~, '  < (escort)~q~:~Z't,, < (escort)~gZ 'b '  < (escort)~.ff o -C t,~ < (bring)},~ ~ -( t, ~ < (bring)}~o -('t,~/-, (bring)N~,,~ (select)L~,S~ (select)The first row of the table represents he attributes or thecase categories.
The values of the attribntes arc the restric-tions of the case categories.
Word forms are used in this.Since the algorithm produces a case-liame tree fi'om thistable, we term the table a "Primitive Case-fl'ame Table(PCIq').
"728The (;4.5 first puts all translations listed in the PCI:funder a root node then recursively selects one case categoryand pmtitions the translations according to the word formsof the selected category.
For the case category selection, acriteria based on the entropy reduction of translationsgained by the partitioning ix used.
See (Quinlan J., 1993)for more details.
In a word, this algorithm places case cate-gories from the root node to the leaf nodes according to thecategory's ability for translation discrimination.
The case-frame tree in Vig.
3a was produced fl'om Table 1.
It does nothave a node corresponding toa subject.
This simply meansthe subject information is redundant in selecting the transla-tion o1' take in 'fable I.4 Data Preparation4.1 Construction of the Bilingual CorpusAs mentioned in Sec.
l, the data for nmchine learning isprepared in two steps: construction of a bilingual corpusand its conversion into a PCITF.
l"ollowing are the factorsconsklered and the steps taken to put together our corpus.?
SollrceSince we couM not find a readily awfilable bilingual cor-pus from the news domain, we decided to make one our-selves by using the Associated Press (AP) wire service newstext and adding a Japanese translation to it.?
TargetWe selected 15 verbs known to be problematic verbs formaclfine translation: come, get, give, go, make, take, run,call, cut,fi, ll, keep, look, put, stand, and turn.Since case frames correspond to simple sentences, we didnot deal with long sentences.
The maximum sentencelength was set at 15 words.?
Quantity of DataTo estimate the necessary amount of data, we investigatedthe monthly frequency of each verb appearing over sixmonths.
The \[}equency showed a fixed tendency over themeasurement periods, suggesting that the data for onemonth ix a good starting point.
We decided to use twomonths, January 1990 and January 1991, for the Englishsentence xtraction.?
Construction(1) Preparing the English textSentences up to 15 words long which contain one or moreof the 15 target verbs were autonmticatly extracted fi'om Ihetwo-month AP sonrce text.
(2) Identifying the range governed by the verhThe range which the target verb directly governs in theEnglish text was manually identified.
The two lines startingwith FNG in Fig.
4 are an example.
(3) Constructing the English case dataThe a priori-defined category labels for each part of theENG data were manually marked and the head word andfunctional word in each category were identified.
The linesstm'ting with CASF, in Fig.
4 correspond to this data.We had defined 34 category labels beforehand.
Twelveof them (sentence category labels) were assigned to verbs toidentify the sentence category from which the verb was ex-tracted.
Example categories are: V (declarative sentence),PVQ (polm question), IMV (imperative sentence), PASV(passive sentence), and IV (to-infinitive clause).
Twenty-two of the category labels (case category labels) identifythe surface cases or the syntactic ategories of other compo~nents in the sentence, l,~xamples are: SN (subject nounclause), SIN (subject to-infinitive clause), and PN (preposi-tional phrase Imodifying the target verb\]).
(4) Constructing the Japanese dataJapanese translations were assigned to each of the F, nglishhead words and functional words.
When translation was notpossible simply reading the English sentence, its contextwas given to the translators.
The two lines starting with JAPin Fig.
4 show the translations.The complete corpus took about 12 nmn-months of laborto construct.
Table 2 shows the corpus statistics for sevenverbs.
Row (2) shows the percentage of sentences thal re-quired the context for translation.
This figure indicates thelimitations of manual translation without context.
Most ofthese sentences had pronotms like it and the translatorsneeded the context o clarify the referents.19 : " I just know I'm going to take those rubles andbuikl another restaurant, " he said.ENG : I'm going to take those rubles( 'ASE : S N<II\]> AX<\[ he going tel> V<I take 1>()N<those \[ruble\]>JAP : SN<{,~Y',\]{ ~}> AX<IBli GOING Te l>20 : " I take everybody seriously " Graf said.ENG : l take everybody seriouslyCASE: SN<\[I \]> V<\[takel> ON<leverybody\]>DD<I seriously \]>,lAP : SN<I ~/, \[{ ~:~ }> V<\[ '~ l 0 I\[- ~") ~ l><> category label, \[\] head word, { } functional wordFig.
4: Part o fa  Tagged Bilingual Corpus4.2 Conversion into a PCFTThe bilingual corpus must be converted into a PCVF be-729Table 2: Corpus Statistics 1come get give go make(1) 795 867 635 1204 1024(2) 3.4% 5.2% 4.1% 3.7% 6.6%(3) 782 849 637 941 1020(1) Number of English sentences run take(2) Percentage r quiring contextto translate 440 1062(3)Number of obtained quadruplets 6.0% 4.0%303 1067fore a case fiame can be learned.
We can now directly con-trol the information used lbr learning.
We followed theprincipals below.?
Develop one case-fi'ame tree fi'om each sentence categoryThis was intended to observe how the sentence categoryaffects the appearance of case-frame trees.?
Use all case categories in the corpus as attributesThis was to select effective case categories without anybias.?
Use head words and functional words as values for casecategoriesThese words are the primary elements representing eachcase category so it is reasonable to use them as the value.5.
Case-frame Tree Learning ExperimentsSeveral learning experiments were conducted on thePCFT obtained from each sentence category of the targetverbs.
Complete results fiom the experiments are not pre-sented here due to space limitations.
Table 3 shows the sta-tistical results for seven verbs.Tab le  3: Stat ist ics of  Case-Frame Trees( f rom dec larat ive  sentences)(1) come get give go make(2)(3)(4)(5)(6)398 274 292 225 36730 28 31 20 3310 9 9 8 86 5 5 6 ' 6 ....10.1% 5.5% 13.0% 10.2% 6.2%(l)Verbs (2) Number of training data(3)Number of case categories appearingin the PCbT (attribute size)(4) Number of translations (class size)(5) Number of case categoriesappearing in the case-frame tree(6) Error rate when the tree was used tore-classify the training datarun take68 28515 213 103 50.0% 6.0%We are now increasing the corpus for give, make, andtake by 4,000 sets.Translations occun'ing less than ten times were not in-cluded in the PcIq'  for this experiment.
The overall errorrate in Table 3 was quite low.
Part oflhe take tree is shownin Fig.
5.
The figures at the end of each line show the resultof the reclassification of the training PCIq" by the learnedtree: (nnmber o1' data items which fell on this leaf/numberof errors, if any).
As is shown, the case-frame tree is highlyintelligible.D<> = over: {J\[ ,: ~\[g: (" (12.
(I)D<> = up: \]IY,~ (3.0/1.0)D<> = O: need timeON<>=0:  ?
)'73,Z, (5.0/1.0) ~ AON<> = action: ~ 7~ (8.0)ON<> = bronze: ~'{\[~:'~- 7j (9.0)ON<> = hour: 7~,7~, 7~ (11.0/3.0)ON<> = measures: k & (10.0) joinON<> = part: @JJIF~- 7~ (33.0/1.0) - .91 - - -  BON<> = while: J'o'Y0"~ (6.0)ON<> = place:~l: ~ , .
_ ', SN<> = Sergei Shupletsov: ~J~f,J'~ Z~(I.0)', SN<> =attack: ~\] a~)avt.7o (4.0) win ,~?q\ON<> = time: happen "~AX<> = 0: 7~"/0' 70 (4.0/2.0) CAX<> = may: '~,:')~:  -~I ;5 (1.0)AX<> = could: ;0"~~ (1.0)Fig.
5: Part of Case-Frame Tree  for Take?
S imi lar i tyThe number of case categories actually used in the ease-flame tree was drastically smaller than the number used inthe PCFF, ( row (3) vs. row (5) of Table 3).
In the case-fi'ame tree tbr lake, for example, the following case catego-ries were used: AX (adverb equivalents), D (adverbial par-ticles), ON (object noun clause), SIN ( subject o-infinitivechmse), and SN (subject noun clause).
The top node, i.e.
themost important node, became D, the adverbial particle, fol-lowing the description in an ordinary dictionary.
Most ofthese syntactical categories are usually used to describe theverb patterns in ordinary dictionaries.
The case-frame treebasically duplicates the verb patterns found in an ordinmydictionary.?
P rec is ionFrom the line marked A in Fig.
5. the translation becamekakaru (need time) under the condition of (ON=0) thoughlake is usually used as a transitive verb, so the lack of anobject noun looks nnnatural; this part of the tree, however,corresponds to time expressions like "take long" and "takeawhile" which do not have object nouns.
This is reasonablelearning.From the line marked B, the idiomatic expression "take730pm't in" was learned as "take part."
The word in was judgedto be redundant and thus an ineffective lement.
While ourcorpus did reveal one example thal did not have in it stillhad the same translation: "sanka suru."
Ttfis learning ismore precise than the description i  an ordinary dictionary.?
Complementary learningThe lines marked C in Fig.
5 show an exan@e of what wecall complementary learning.
The case-frame tree surpris-ingly distinguished "kakutoku stlrtf' (will) from "okolmwareru" (happen).
The former was learned from "lake ttfirdplace."
The latter corresllonds to an idiomatic expression,"take place".
Tim way tile algorithm learns is tmiquc.
Thekey to discrimination was found in SN, the subject noun,which sounds reasonable.
Discrimination is done in termsof the subject's nature: person vs. actiou notlll, llowever,this could also be distinguished by the existence of themodifier to place, since in the idiomatic sense, no modifica-tion is allowed between take andplace.
In our PCbT, modi-tiers were not iocluded and the system found complemen-tary knowledge to distinguish the translations.
The samephenomenon was fotmd in many paris of the flees.
Thelearning algorithm does its best to sub-categorize the trans-lations within the given case categories.
While this canyiekl linguistically-skewed case frames, tttey are still effec-tive, at least in the corpus.?
Differences among sentence categoriesThe results flom other sentence categories had a mttchdifferent appearance.
Trees for make and take which wereobtained from the PCFT for tile to-infinitive chmse con-tained only one case category, ON (object noun clause).The case categories effective ill the declarative sentence,like the adverbial particle, were not effective for this sen-tence category.
This strongly suggests that translationsshould be selected by using lhe case frames for the sentencetype.6 ConclusionWe proposed the idea ef gradual knowledge acquisitionfrom a bilingual corpus.
The knowledge addressed in thispaper was the surface verbal case frames for the Japanesetranslation of English verbs.
The process consists of threesteps: corpus construction, data conversion, and maclfinelearning.The case-fiame trees we obtained were highly intelli-gible: they can be interpreted from the linguistic viewpoint,They basically matclled linguistic intttition and more pre-cise knowledge was sometimes acquired.
Tree analysisshowed that in some cases comlllementary learning oc-curred even wllen neccssmy knowledge was nol awlilable.The trees successfully distinguislled tile translations ofthe training data.Our approach basically fulfills our primary goal: acquit'-ing detailed knowledge and accunltdating it in a way that isconsistent and unambiguous.There are several areas for future work.
The work in lhispaper used tile word forms as tile restrictions for tile casecategories, resulting ill case-frame trees with limited traus-lation power for open dala.
To increase the lranslationpower, we are generalizing the corllus by using semanliccodes and plan to produce case-frame trees with thenl.AcknowledgementsI would like Io thank Prof. Makoto Nagao oF Kyoto Uni-versity and Prof. lloztuni Tatlaka of tbe Tokyo Institute ofTechnology tor their vahtable suggestions.
I would alsolike to tl/ank my supervisors Dr. Yuichi Ninomiya, 1) r .Teruaki Aizawa, and I)r. Terumasa Ellara, and my col-leagues whose discussions helped clarify this work.
Theallonylnotls reviewers inade very COllStl'uclive COllllnelllSwhich gave us vahlable pointers for ottr future work.ReferencesAizawa, T., Ehara, Uratani and Tanaka (1990).
A MachineTranslation Syslem for l,'oreign News in Satellite Broad-casting, t'roc, o/Coling-90, Vol..5', pp.
308-310.Cardic, C. (1092).
l~eartfing to l)isambiguate Relative Pro-notms.
Pro< o/'AAAI 92, pp.
38-43.Cardie, C. (1993).
A Case-Based Approach to KnowledgeAcquisition for Dotnain-Specil'ic Sentence Analysis.l'roc, of AAAI.93, pp.
798-803.Oktllllura, M, and Tanaka (1990).
Towards htcrementalI)isambiguation with a Generalized Discrimination Net-work.
Proc, o/'AAAI-90, Vol.
2, pp.
990-095.Qttinlan, J, R. (1993).
C4.5 programs for machine learning,Morgan Kau flnalul.Tanaka, 11.
( 1991 ).
The MT User Experience.
Proc.
o/ MTSummit I11, pp.
123-125.Tanaka, I1., Aizawa, Kin/and I latada.
(1992).
A Method ofTranslating English I)elexical Structures into Japanese.l'roc, q/'Coling-92, Vol.
2, pp.
567-573.Tanaka, 11. and Ellara (1993).
Automatic Verbal CaseFrame Acquisition l'rom Bilingual Corpora (in Japanese).lb'oc.
47th Anmml Convention IPS Japan, Vol, 3, pp.
195-196.\[_Jtstlro, T., MalsumoIo and Nagao.(1993).
Verbal Casel:rame Acquisition flom Bilingual Corpora.
l'roc, qf theI, ICAl.93, Vol.
2, pp, 1150-1156.Z31
