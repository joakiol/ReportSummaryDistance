Proceedings of SSST-4, Fourth Workshop on Syntax and Structure in Statistical Translation, pages 83?91,COLING 2010, Beijing, August 2010.Manipuri-English Bidirectional Statistical MachineTranslation Systems using Morphology and Dependency RelationsThoudam Doren SinghDepartment of Computer Science andEngineeringJadavpur Universitythoudam.doren@gmail.comSivaji BandyopadhyayDepartment of Computer Science andEngineeringJadavpur Universitysivaji_cse_ju@yahoo.comAbstractThe present work reports the develop-ment of Manipuri-English bidirectionalstatistical machine translation systems.
Inthe English-Manipuri statistical machinetranslation system, the role of the suffixesand dependency relations on the sourceside and case markers on the target sideare identified as important translationfactors.
A parallel corpus of 10350 sen-tences from news domain is used fortraining and the system is tested with 500sentences.
Using the proposed translationfactors, the output of the translation qual-ity is improved as indicated by baselineBLEU score of 13.045 and factoredBLEU score of 16.873 respectively.
Si-milarly, for the Manipuri English system,the role of case markers and POS tags in-formation at the source side and suffixesand dependency relations at the targetside are identified as useful translationfactors.
The case markers and suffixesare not only responsible to determine theword classes but also to determine thedependency relations.
Using these trans-lation factors, the output of the transla-tion quality is improved as indicated bybaseline BLEU score of 13.452 and fac-tored BLEU score of 17.573 respectively.Further, the subjective evaluation indi-cates the improvement in the fluency andadequacy of both the factored SMT out-puts over the respective baseline systems.1 IntroductionManipuri has little resource for NLP related re-search and development activities.
Manipuri is aless privileged Tibeto-Burman language spokenby approximately three million people mainly inthe state of Manipur in India as well as its neigh-boring states and in the countries of Myanmarand Bangladesh.
Some of the unique features ofthis language are tone, the agglutinative verbmorphology and predominance of aspect thantense, lack of grammatical gender, number andperson.
Other features are verb final word orderin a sentence i.e., Subject Object Verb (SOV)order, extensive suffix with more limited prefixa-tion.
In Manipuri, identification of most of theword classes and sentence types are based on themarkers.
All sentences, except interrogatives endwith one of these mood markers, which may ormay not be followed by an enclitic.
Basic sen-tence types in Manipuri are determined throughillocutionary mood markers, all of which areverbal inflectional suffixes, with the exception ofthe interrogatives that end with an enclitic.
Twoimportant problems in applying statistical ma-chine translation (SMT) techniques to English-Manipuri bidirectional MT systems are: (a) thewide syntactic divergence between the languagepairs, and (b) the richer morphology and casemarking of Manipuri compared to English.
Thefirst problem manifests itself in poor word-orderin the output translations, while the second oneleads to incorrect inflections and case marking.The output Manipuri sentences in case of Eng-lish-Manipuri system suffer badly when mor-phology and case markers are incorrect in thisfree word order and morphologically rich lan-guage.83The parallel corpora used is in news domainwhich have been collected, cleaned and aligned(Singh et al , 2010b) from the Sangai Expressnewspaper website www.thesangaiexpress.comavailable in both Manipuri and English.
A dailybasis collection was done covering the periodfrom May 2008 to November 2008 since there isno repository.2 Related WorksKoehn and Hoang (2007) developed a frame-work for statistical translation models that tightlyintegrates additional morphological, syntactic, orsemantic information.
Statistical Machine Trans-lation with scarce resources using morpho-syntactic information is discussed in (Nie?en andNey, 2004).
It introduces sentence level restruc-turing transformations that aim at the assimila-tion of word order in related sentences andexploitation of the bilingual training data by ex-plicitly taking into account the interdependenciesof related inflected forms thereby improving thetranslation quality.
Popovic and Ney (2006) dis-cussed SMT with a small amount of bilingualtraining data.
Case markers and morphology areused to address the crux of fluency in the Eng-lish-Hindi SMT system (Ramanathan et al,2009).
Work on translating from rich to poormorphology using factored model is reported in(Avramidis and Koehn, 2008).
In this method ofenriching input, the case agreement for nouns,adjectives and articles are mainly defined by thesyntactic role of each phrase.
Resolution of verbconjugation is done by identifying the person ofa verb and using the linguistic information tag.Manipuri to English Example Based MachineTranslation system is reported in (Singh andBandyopadhyay, 2010a) on news domain.
Forthis, POS tagging, morphological analysis, NERand chunking are applied on the parallel corpusfor phrase level alignment.
Chunks are alignedusing a dynamic programming ?edit-distancestyle?
alignment algorithm.
The translationprocess initially looks for an exact match in theparallel example base and returns the retrievedtarget output.
Otherwise, the maximal matchsource sentence is identified.
For word levelmismatch, the unmatched words in the input areeither translated from the lexicon or translite-rated.
Unmatched phrases are looked into thephrase level parallel example base; the targetphrase translations are identified and then re-combined with the retrieved output.
English-Manipuri SMT system using morpho-syntacticand semantic information is reported in (Singhand Bandyopadhyay, 2010c).
In this system, therole of the suffixes and dependency relations onthe source side and case markers on the targetside are identified as important translation fac-tors.3 Syntactic ReorderingThis is a preprocessing step applied to the in-put English sentences for English-Manipuri SMTsystem.
The program for syntactic reorderinguses the parse trees generated by Stanford parser1and applies a handful of reordering rules writtenusing perl module Parse::RecDescent.
By doingthis, the SVO order of English is changed toSOV order for Manipuri, and post modifiers areconverted to pre-modifiers.
The basic differenceof Manipuri phrase order compared to English ishandled by reordering the input sentence follow-ing the rule (Rao et al, 2000):SSmV VmOOmCm  ?
?C'mS'mS'O'mO'V'mV'where,    S: SubjectO: ObjectV : VerbCm: Clause modifierX': Corresponding constituent in Manipuri,where X is S, O, or VXm: modifier of XThere are two reasons why the syntactic reor-dering approach improves over the baselinephrase-based SMT system (Wang et al, 2007).One obvious benefit is that the word order of thetransformed source sentence is much closer tothe target sentence, which reduces the reliance onthe distortion model to perform reordering duringdecoding.
Another potential benefit is that thealignment between the two sides will be of high-er quality because of fewer ?distortions?
betweenthe source and the target, so that the resultingphrase table of the reordered system would bebetter.
However, a counter argument is that thereordering is very error prone, so that the addednoise in the reordered data actually hurts thealignments and hence the phrase tables.1 http://nlp.stanford.edu/software/lex-parser.shtml844 MorphologyThe affixes are the determining factor of theword class in Manipuri.
In this agglutinative lan-guage the number of verbal suffixes is more thanthat of nominal suffixes.
Works on Manipurimorphology are found in (Singh and Bandyo-padhyay, 2006) and (Singh and Bandyopadhyay,2008).
In this language, a verb must minimallyconsist of a verb root and an inflectional suffix.A noun may be optionally affixed by derivationalmorphemes indicating gender, number and quan-tity.
Further, a noun may be prefixed by a pro-nominal prefix which indicates its possessor.Words in Manipuri consist of stems or boundroots with suffixes (from one to ten suffixes),prefixes (only one per word) and/or enclitics.
(a) ??
????-??
?
??-?
?
???
?Ibomcha-na  Ball-du  kao-iIbomcha-nom Ball-distal kickIbomcha kicks the ball.
(b) ?
??-?
?
??
????-??
???
?Ball-du  Ibomcha-na kao-iBall-distal Ibomcha-nom kickIbomcha kicks the ball.The identification of subject and object in boththe sentences are done by the suffixes ??
(na) and?
?
(du) as given by the examples (a) and (b).
Thecase markers convey the right meaning duringtranslation though the most acceptable order ofManipuri sentence is SOV.
In order to produce agood translation output all the morphologicalforms of a word and its translations should beavailable in the training data and every word hasto appear with every possible suffixes.
This willrequire a large training data.
By learning the gen-eral rules of morphology, the amount of trainingdata could be reduced.
Separating lemma andsuffix allows the system to learn more about thedifferent possible word formations.Manipuri  Gloss English Meaning?
?????
Tom-na by Tom?
?????
Tom-dagi from Tom?
???
?
Tom-su Tom also?
????
Tom-gi of Tom?
????
Tom-ga with TomTable 1: Some of the inflected forms of names inManipuri and its corresponding English meaningTable 1 gives some examples of the inflectedforms of a person name and its correspondingEnglish meaning.
The Manipuri stemmer sepa-rates the case markers such as ???
(-na), -???
(-dagi), -?
?
(-su), -??
(-gi), -??
(-ga) etc.
fromsurface forms so that ??
???
(Tom) from Manipu-ri side matches with ?Tom?
at English side help-ing to overcome the data sparseness.
Enclitics inManipuri fall into six categories: determiners,case markers, the copula, mood markers, inclu-sive / exclusive and pragmatic peak markers andattitude markers.
The role of the enclitics usedand its meaning differs based on the context.5  Factored Model of TranslationUsing factored approach, a tighter integration oflinguistic information into the translation modelis done for two reasons2:?
Translation models that operate on moregeneral representations, such as lemma in-stead of surface forms of words, can draw onricher statistics and overcome the datasparseness problem caused by limited train-ing data.?
Many aspects of translation can be best ex-plained at a morphological, syntactic or se-mantic level.
Having such informationavailable to the translation model allows thedirect modeling of these aspects.
For in-stance, reordering at the sentence level ismostly driven by general syntactic principles,local agreement constraints that show up inmorphology, etc.5.1 Combination of Components in Fac-tored ModelFactored translation model is the combination ofseveral components including language model,reordering model, translation steps and genera-tion steps in a log-linear model3:Z is a normalization constant that is ignored inpractice.
To compute the probability of a transla-tion e given an input sentence f, we have to eva-luate each feature function hi.
The feature weight2http://www.statmt.org/moses/?n=Moses.FactoredModels3http://www.statmt.org/moses/?n=Moses.FactoredModels(1 )85?i in the log linear model is determined by usingminimum error rate training method (Och, 2003).For a translation step component, each featurefunction ht is defined over the phrase pairs (f j,ej)given a scoring function ?
:(2)For the generation step component, each fea-ture function hg given a scoring function ?
is de-fined over the output words ek only:(3)5.2 Stanford Dependency ParserThe dependency relations used in the experimentare generated by the Stanford dependency parser(Marie-Catherine de Marneffe and Manning,2008).
This parser uses 55 relations to expressthe dependencies among the various words in asentence.
The dependencies are all binary rela-tions: a grammatical relation holds between agovernor and a dependent.
These relations form ahierarchical structure with the most general rela-tion at the root.Figure 1.
Dependency relation graph of the sen-tence ?Sources said that Tom was shot by police?generated by Stanford ParserThere are various argument relations like sub-ject, object, objects of prepositions and clausalcomplements, modifier relations like adjectival,adverbial, participial, infinitival modifiers andother relations like coordination, conjunct, exple-tive and punctuation.
Let us consider an example?Sources said that Tom was shot by police?.Stanford parser produces the dependency rela-tions, nsubj(said, sources) and agent (shot, po-lice) .
Thus, sources|nsubj and police|agent arethe factors used.
?Tom was shot by police?
formsthe object of the verb ?said?.
The Stanford parserrepresents these dependencies with the help of aclausal complement relation which links ?said?with ?shot?
and uses the complementizer relationto introduce the subordination conjunction.
Fig-ure 1 shows the dependency relation graph of thesentence ?Sources said that Tom was shot by po-lice?.5.3 Factorization approach of English-Manipuri SMT systemManipuri case markers are decided by dependen-cy relation and aspect information of English.Figure 2 shows the translation factors used in thetranslation between English and Manipuri.
(i) Tomba drives the car.?
??????
?????
???
?Tomba-na car-du thou-i(Tomba)  (the car)  (drives)Tomba|empty|nsubj drive|s|empty the|empty|detcar|empty|dobjA subject requires a case marker in a clausewith a perfective form such as ???
(na).
It can berepresented as,suffix+ dependency relation ?
case markers|empty  + empty|dobj ?
??
(na)(ii) Birds are flying.?????????
??????
?ucheksing payri(birds are)  (flying)Bird|s|nsubj are|empty|aux fly|ing|emptyThus, English-Manipuri factorization consists of?
a lemma to lemma translation factor [i.e.,Bird ?
????
(uchek) ]?
a suffix + dependency relation ?
suffix [i.e.,s + nsubj ?
?????
(sing)]?
a lemma + suffix ?
surface form generationfactor[i.e., ????
(uchek) + ?????
(sing) ?
?????????
(ucheksing)]saidsourcesshotthatTom wasPolicensubjccompcomplmnsubjpass auxpassagent86Figure 2.
English to Manipuri translation factors5.4 Factorization approach of Manipuri-English SMT systemManipuri case markers are responsible to identifydependency relation and aspect information ofEnglish.
Figure 3 shows the translation factorsused in the translation between Manipuri andEnglish.
The Manipuri- English factorizationconsists of:?
Translation factor: lemma to lemma[e.g., ????
(uchek) ?
Bird]?
Translation factor: suffix + POS ?
depen-dency relation + POS + suffix[e.g., ?????
(sing) + NN ?
nsubj + NN + s]?
Generation factor: lemma + POS + depen-dency Relation +suffix ?
surface form gen-eration factor[e.g., ????
(uchek) + NN  + nsubj + ?????
(sing)?
?????????
(ucheksing ]Figure 3.
The Manipuri-English translation factors5.5 Syntactically enriched outputHigh-order sequence models (just like n-gramlanguage models over words) are used in order tosupport syntactic coherence of the output (Koehnand Hoang, 2007).Input             Outputword                                word3-gram                       Parts-of-speech7-gramFigure 4.
By generating additional linguistic factorson the output side, high-order sequence models overthese factors support syntactical coherence of the out-put.Adding part-of-speech factor on the outputside and exploiting them with 7-gram sequencemodels (as shown in Figure 4) results in minorimprovements in BLEU score.6 Experimental SetupA number of experiments have been carried outusing factored translation framework and incor-porating linguistic information.
The toolkits usedin the experiment are:?
Stanford Dependency Parser4 was used to (i)generate the dependency relations and (ii)syntactic reordering of the input English sen-tences using Parse::RecDescent module.?
Moses5  toolkit (Koehn, 2007) was used fortraining with GIZA++6, decoding and mini-mum error rate training (Och, 2003) for tun-ing.?
SRILM7 toolkit (Stolcke, 2002) was used tobuild language models with 10350 Manipurisentences for English-Manipuri system andfour and a half million English wordformscollected from the news domain for Manipu-ri-English system.?
English morphological analyzer morpha 8(Minnen et al, 2001) was used and the4 http://nlp.stanford.edu/software/lex-parser.shtml5 http://www.statmt.org/moses/6 http://www.fjoch.com/GIZA++.html7 http://www.speech.sri.com/projects/srilm8ftp://ftp.informatics.susx.ac.uk/pub/users/johnca/morph.tar.gzWordLemmaSuffixDependencyRelationWordLemmaCaseMarkerInput              OutputWordLemmaPOSSuffix/CaseMarkerWordLemmaPOSDependen-cy RelationSuffix87stemmer from Manipuri Morphological ana-lyzer (Singh and Bandyopadhyay, 2006) wasused for the Manipuri side.?
Manipuri POS tagger (Singh et.
al., 2008) isused to tag the POS (Parts of speech) factorsof the input Manipuri sentences.7 Evaluation7.1 English-Manipuri SMT SystemThe evaluation of the machine translation sys-tems developed in the present work is done intwo approaches using automatic scoring withreference translation and subjective evaluation asdiscussed in (Ramanathan et al, 2009).Evaluation Metrics:?
NIST (Doddington, 2002): A high scoremeans a better translation by measuring theprecision of n-gram.?
BLEU (Papineni et al 2002): This metricgives the precision of n-gram with respect tothe reference translation but with a brevitypenalty.No of sentences No of wordsTraining 10350 296728Development 600 16520Test 500 15204Table 2.
Train ing, development and testing corpusstatisticsTable 2 shows the corpus statistics used in theexperiment.
The corpus is annotated with theproposed factors.
The following models are de-veloped for the experiment.Baseline:The model is developed using the default settingvalues in MOSES.Lemma +Suffix:It uses lemma and suffix factors on the sourceside, lemma and suffix on the target side forlemma to lemma and suffix to suffix translationswith generation step of lemma plus suffix to sur-face form.Lemma + Suffix + Dependency Relation:Lemma, suffix and dependency relations are usedon the source side.
The translation steps are (a)lemma to lemma (b) suffix + dependency rela-tion to suffix and generation step is lemma + suf-fix to surface form.
Table 3 shows the BLEU andNIST scores of the system using these factors.Table 4 shows the BLEU and NIST scores ofthe English-Manipuri SMT systems using lexica-lized and syntactic reordering.Model BLEU NISTBaseline (surface) 13.045 4.25Lemma + Suffix 15.237 4.79Lemma + Suffix + De-pendency Relation16.873 5.10Table 3.
Evaluation Scores of English - ManipuriSMT System using various translation factorsModel Reordering BLEU NISTBaseline(surface)13.045 4.25Surface Lexicalized 13.501 4.32Surface Syntactic 14.142 4.47Table 4.
Evaluation Scores of English-Manipuri SMTsystem using Lexicalized and Syntactic ReorderingInput/Output of English-Manipuri SMT:(1a) Input: Going to school is obligatory for stu-dents.???
????
??????????
?
??
???
?
????????
|School chatpa shatra-sing-gi touda yadraba mathouni.Baseline output:  ???
????
????
??
??
?school mathou chatpa oy shatragloss : school duty going is student.Syntactic Reorder output: ???
???
????
?
??
???
?shatra school chatpa touda yadrabagloss: Student school going compulsory.Dependency output: ????????
???
????
???????
?shatrasing schoolda chatpa mathounigloss: Students going to the school is duty.
(1b) Input: Krishna has a flute in his hand.?????
????
?
?????
???
??
|Krishna-gi khut-ta toudri ama lei.Syntactic Reorder output:  ???
??
????
???
?
????
?Krishna lei khut ama toudrigloss : Krishna has a hand fluteDependency output: ?????
??
?
?????
???
???
?krishnagi lei toudri ama  khuttagloss : Krishna has a flute in his hand88One of the main aspects required for the fluen-cy of a sentence is agreement.
Certain wordshave to match in gender, case, number, personetc.
within a sentence.
The rules of agreement arelanguage dependent and are closely linked to themorphological structure of language.
Subjectiveevaluations on 100 sentences have been per-formed for fluency and adequacy by two judges.The fluency measures how well formed the sen-tences are at the output and adequacy measuresthe closeness of the output sentence with the ref-erence translation.
The Table 5 and Table 6 showthe adequacy and fluency scales used for evalua-tion and Table 7 shows the scores of the evalua-tion.Level Interpretation4 Full meaning is conveyed3 Most of the meaning is conveyed2 Poor meaning is conveyed1 No meaning is conveyedTable 5.
Adequacy scaleLevel Interpretation4 Flawless with no grammatical error3 Good output with minor errors2 Disfluent ungrammatical with correctphrase1 IncomprehensibleTable 6.
Fluency scaleSentencelengthFluency AdequacyBaseline <=15words1.95 2.24>15 words 1.49 1.75Reordered <=15words2.58 2.75>15 words 1.82 1.96DependencyRelation<=15words2.83 2.91>15 words 1.94 2.10Table 7.
Scale o f Fluency and Adequacy on sentencelength basis of English-Manipuri SMT system7.2 Manipuri-English SMT SystemThe system uses the corpus statistics shown inTable 2.
The corpus is annotated with the pro-posed factors.
The following models are devel-oped for the experiment.
The baseline andlemma+suffix systems follow same factors asEnglish-Manipuri.Lemma + Suffix + POS:Lemma, suffix and POS are used on the sourceside.
The translation steps are (a) lemma tolemma (b) suffix + POS to POS + suffix + de-pendency relation and generation step is lemma+ suffix + POS + dependency relation to surfaceform.Model BLUE NISTBaseline (surface) 13.452 4.31Lemma + Suffix 16.137 4.89Lemma + Suffix + POS 17.573 5.15Table 8.
Evaluation Scores of Manipuri-English SMTsystem using various translation factorsTable 8 shows the BLEU and NIST scores ofthe Manipuri-English systems using the differentfactors.
Table 9 shows the scores of using lexica-lized reordering and POS language model.Model BLUE NISTBaseline + POS LM 14.341 4.52Baseline + Lexicalized 13.743 4.46Baseline + Lexicalized+POS LM14.843 4.71Table 9.
Evaluation Scores of Manipuri-English SMTsystem using Lexicalized reordering and POS Lan-guage ModelInput/Output of Manipuri-English SMT:(2a) Input: ???
????
??????????
?
??
???
?
????????
|gloss: School chatpa shatra-sing-gi toudayadraba mathouni.Going to school is obligatory for students.Baseline output: school going to the studentsimportantLexicalized Reordered output: school goingimportant to the studentsLemma+Suffix+POS+lexicalized reorderedoutput: School going important to the students(2b) Input: ?????
????
?
?????
???
??
|gloss: Krishna-gi khut-ta toudri ama lei.Krishna has a flute in his hand.Baseline output: Krishna is flute and handLexicalized Reordered output: Krishna flutehas his hand89Lemma+Suffix+POS+lexicalized reorderedoutput: Krishna has flute his handBy considering the lemma along with suffixand POS factors, the fluency and adequacy of theoutput is better addressed as given by the sampleinput and output (2a) and (2b) over the baselinesystem.
Using the Manipuri stemmer, the casemarkers and suffixes are taken into account fordifferent possible word forms thereby helping toovercome the data sparseness problem.
Table 10shows the scores of adequacy and fluency of theevaluation.SentencelengthFluency AdequacyBaseline <=15words1.93 2.31>15 words 1.51 1.76Reordered <=15words2.48 2.85>15 words 1.83 1.97Lemma +Suffix+ POS<=15words2.86 2.92>15 words 2.01 2.11Table 10.
Scale of Fluency and Adequacy on sen-tence length basis of Manipuri-English SMT systemSubjective evaluations on 100 sentences havebeen performed for fluency and adequacy.
In theprocess of subjective evaluation, sentences werejudged on fluency, adequacy and the number oferrors in case marking/morphology.
It is ob-served that poor word-order makes the baselineoutput almost incomprehensible, while lexica-lized reordering solves the problem correctlyalong with parts-of-speech language model (POSLM).
Statistical significant test is performed tojudge if a change in score that comes from achange in the system reflects a change in overalltranslation quality.
It is found that all the differ-ences are significant at the 99% level.8 DiscussionThe factored approach using the proposed factorsshow improved fluency and adequacy at the Ma-nipuri output for English-Manipuri system asshown in the Table 6.
Using the Stanford gener-ated relations shows an improvement in terms offluency and adequacy for shorter sentences thanthe longer ones.Input : Khamba pushed the stone with a lever.??????
????????
???
??
?????????
|Outputs:Syntactic Reordered: ????
???
??????
??
????????
|Khamba nung jamfat adu illigloss:  Khamba stone the lever pushDependency: ??????
???
??
?????????
???????
|Khambana nung adu jamfatna illigloss: Khamba the stone pushed with leverBy the use of semantic relation, ??
(na) is at-tached to ????
(Khamba), which makes the mean-ing ??????
?by Khamba?
instead of  just ????
?Khamba?.Input : Suddenly the woman burst into tears.???
????
???
?????
?????
??????????
|Outputs:Syntactic Reordered: ????
????
?????????
?????
|Nupi thuna pirang-ga kappigloss: woman soon tears cryDependency:  ??
???
?????
?????????
|Athubada nupidu kaplammigloss: suddenly the woman criedHere, in this example, the ????
(nupi) is suf-fixed by the ??
(du), to produce ?????
?
?the wom-an?
instead of just ????
?woman?.The factored approach of Manipuri-EnglishSMT system also shows improved BLEU andNIST scores using the proposed factors as shownin Table 8 not only gain in fluency and adequacyscores as shown in Table 10.9 ConclusionA framework for Manipuri and English bidirec-tional SMT system using factored model is expe-rimented with a goal to improve the translationoutput and reduce the amount of training data.The output of the translation is improved by in-corporating morphological information and se-mantic relations by tighter integration.
Thesystems are evaluated using automatic scoringtechniques BLEU and NIST.
The subjectiveevaluation of the systems is done to find out thefluency and adequacy.
The fluency and adequacyare also addressed better for the shorter sentencesthan the longer ones using semantic relations.The improvement is statistically significant.90ReferencesAvramidis, E. and Koehn, P. 2008.
Enriching mor-phologically poor languages for Statistical MachineTranslation, Proceedings of ACL-08: HLTCallison-Burch, Chris., Osborne, M. and Koehn, P.2006.
Re-evaluating the Role of Bleu in MachineTranslation Research" In Proceedings of EACL-2006Doddington, G. 2002.
Automat ic evaluation of Ma-chine Translation quality using n-gram co-occurrence statistics.
In Proceedings of HLT 2002,San Diego, CA.Koehn.
P., and Hoang, H. 2007.
Factored TranslationModels, In Proceedings of EMNLP-2007Koehn, P., Hieu, H., Alexandra, B., Chris, C., Marcel-lo, F., Nicola, B., Brooke, C., Wade, S., Christine,M., Richard, Z., Chris, D., Ondrej, B., A lexandra,C., Evan, H. 2007.
Moses: Open Source Toolkit  forStatistical Machine Translation, Proceedings of theACL 2007 Demo and Poster Sessions, pages 177?180, Prague.Marie-Catherine de Marneffe and Manning, C. 2008.Stanford Typed Dependency ManualMinnen, G., Carro ll, J., and Pearce, D. 2001.
AppliedMorphological Processing of English, NaturalLanguage Engineering, 7(3), pages 207-223Nie?en, S., and Ney, H. 2004.
Statistical MachineTranslation with Scarce Resources Using Morpho-syntactic Information, Computational Linguistics,30(2), pages 181-204Och, F. 2003.
Minimum error rate train ing in Statis-tical Machine Translation , Proceedings of ACLPapineni, K., Roukos, S., Ward, T., and Zhu, W.2002.
BLEU: a method for automat ic evaluation ofmachine translation.
In Proceedings of 40th  ACL,Philadelphia, PAPopovic, M., and Ney, H. 2006.
Statistical MachineTranslation with a s mall amount of bilingual train-ing data, 5th LREC SALTMIL Workshop on Minor-ity LanguagesRamanathan, A., Choudhury, H., Ghosh, A., andBhattacharyya, P. 2009.
Case markers and Mor-phology: Addressing the crux of the fluency prob-lem in  English-Hindi SMT, Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP: Vo-lume 2, pages: 800-808Rao, D., Mohanraj, K., Hegde, J., Mehta, V. and Ma-hadane, P. 2000.
A practical framework for syntac-tic transfer of compound-complex sentences forEnglish-Hindi Machine Translation, Proceedingsof KBCS 2000, pages 343-354Singh, Thoudam D., and Bandyopadhyay, S. 2006.Word Class and Sentence Type Identification inManipuri Morphological Analyzer, Proceeding ofModeling and Shallow Parsing of Indian Languag-es(MSPIL) 2006, IIT Bombay, pages 11-17, Mum-bai, IndiaSingh, Thoudam D., and Bandyopadhyay, S. 2008.Morphology Driven Manipuri POS Tagger,  In pro-ceedings International Joint Conference on Natu-ral Language Processing (IJCNLP-08) Workshopon Natural Language Processing of Less Privi-leged Languages (NLPLPL) 2008, pages 91-98,Hyderabad, IndiaSingh, Thoudam D., and Bandyopadhyay, S. 2010a.Manipuri-English Example Based Machine Trans-lation System, International Journal of Computa-tional Linguistics and Applications (IJCLA), ISSN0976-0962, pages 147-158Singh, Thoudam D., Singh, Yengkhom R. and Ban-dyopadhyay, S., 2010b.
Manipuri-English SemiAutomatic Parallel Corpora Extraction from Web,In proceedings of 23rd International Conferenceon the Computer Processing of Oriental Languag-es (ICCPOL 2010) - New Generation in Asian In-formation Processing , San Francisco Bay, CA,USA, Pages 45-48Singh, Thoudam D. and Bandyopadhyay, S., 2010c.Statistical Machine Translation of English-Manipuri using Morpho-Syntactic and SemanticInformation, In  the proceedings of Ninth Confe-rence  of the Association for Machine Translationin Americas (AMTA 2010), Denver, Colorado,USA.
(To appear)Stolcke.
A.
2002.
SRILM - An Extensible LanguageModeling Toolkit.
In  Proc.
Intl.
Conf.
Spoken Lan-guage Processing, Denver, Colorado, September.Wang, C., Collin,  M., and Koehn, P. 2007.
Ch inesesyntactic reordering for statistical machine transla-tion, Proceedings of EMNLP-CoNLL91
