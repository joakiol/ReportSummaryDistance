Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 40?48,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsFast, Scalable and Reliable Generation of Controlled Natural LanguageDavid HardcastleFaculty of Maths, Computingand TechnologyThe Open UniversityMilton Keynes, UKd.w.hardcastle@open.ac.ukRichard PowerFaculty of Maths, Computingand TechnologyThe Open UniversityMilton Keynes, UKr.power@open.ac.ukAbstractIn this paper we describe a natural languagegeneration system which takes as its input aset of assertions encoded as a semantic graphand outputs a data structure connecting the se-mantic graph to a text which expresses thoseassertions, encoded as a TAG syntactic tree.The scope of the system is restricted to con-trolled natural language, and this allows thegenerator to work within a tightly restricteddomain of locality.
We can exploit this fea-ture of the system to ensure fast and efficientgeneration, and also to make the generator re-liable by providing a rapid algorithm whichcan exhaustively test at compile time the com-pleteness of the linguistic resources with re-spect to the range of potential meanings.
Thesystem can be exported for deployment witha minimal build of the semantic and linguisticresources that is verified to ensure that no run-time errors will result from missing resources.The framework is targeted at using natural lan-guage generation technology to build semanticweb applications where machine-readable in-formation can be automatically expressed innatural language on demand.1 IntroductionThis paper describes a fast, reliable and scalableframework for developing applications supportingtactical generation ?
by which we mean applicationswhich take as their input some semantic structurethat has already been organised at a high level, andchoose the syntactic structures and words required toexpress it.
The framework takes as input a semanticgraph representing a set of assertions in DescriptionLogic (DL) (Baader et al, 2003) and transforms itinto a tree which encodes the grammar rules, syn-tactic subcategorisations, orderings and lexical an-chors required to construct a textual representationof the input data.
The resulting text is conceptu-ally aligned, by which we mean that each compo-nent of the text structure (such as words, clauses orsentences, for example) is linked back to the medi-ating structure from which the text was generated,and from there back to vertices and edges in thesemantic graph received as input.
The target con-text for the framework is the construction of se-mantic web (Berners-Lee et al, 2001) resources us-ing Natural Language Generation (NLG) technologywhich extends the notion of semantic alignment de-veloped in the WYSIWYM system (Power and Scott,1998; Power et al, 2003).
In this context the text isephemeral and is generated on demand, while thedocument content is fully machine-readable, sup-porting tasks such as automated consistency check-ing, inferencing and semantic search/query.
Sincethe text is fully linked to the underlying semanticrepresentation it supports a rich user interface en-compassing fast and reliable semantic search, inlinesyntax or anaphora highlighting, knowledge editing,and so on.
Finally, the text could be generated inmany different natural languages making the infor-mation content more widely available.
We envisagethe technology supporting a range of different usecases such as information feeds, technical instruc-tions, medical orders or short, factual reports.For such a system to be of practical value in anenterprise system the NLG component must sup-40port standard aspects of software engineering qual-ity such as modularity, reliability, speed and scala-bility.
The design of the framework relies on two keysimplifying assumptions and these limit the range ofinformation which can be represented and the flu-ency of the text used to express it.
Specifically, theinformation is limited by the expressivity of DL ?for example only limited quantification is possible ?and the surface text is restricted to controlled natu-ral language (Hartley and Paris, 2001).
The upsideof this trade-off is that the domain of locality is veryrestricted.
This means that there is minimal searchduring generation and so the algorithm is fast andscalable.
It also enables us to design the generatorso that it is predictable and can therefore be staticallytested for completeness, a notion which we define inSection 3.Our aim in this paper is to show how the simpli-fying assumptions behind the design bring consider-able engineering benefits.
We discuss the theoreti-cal background to our approach (Sections 2 and 3)and then present the implementation details, focus-ing on the features of the design that support speedand scalability (Section 4) and reliability (Section5), followed by an overview of the architectural con-siderations (Section 6).
Finally we present the re-sults of tests evaluating the system?s performance(Section 7).2 Implementation TheoryThe generation algorithm has its roots in the WYSI-WYM system, which was originally developed as away of defining the input for multilingual NLG inDRAFTER (Paris et al, 1995), one of a series ofprojects in the KPML/Penman tradition (Batemanet al, 1989).
The system uses the standard seman-tic representation employed in DL and the SemanticWeb: a Terminology Box, or Tbox, defining the con-cepts and their interrelations and an Assertion Box,or Abox, representing the information content thatforms the input (Baader et al, 2003).
An Abox is aset of assertions defining relations between instancesof the types defined in the Tbox.
It can be depictedby a connected graph (Figure 1) in which verticesrepresent entities and edges represent relations, andis represented in the input to the system by a setof RDF subject-predicate-argument triples (LassilaFigure 1: Sample Aboxand Swick, 1998), with one-place predications as-signing types and two-place predications assertingrelationships.
Assuming that the entities are beingmentioned for the first time, we might express thisAbox fragment in English by the sentence ?a womanlost her bag?1.
This sentence can be aligned with theAbox by associating spans of the text with the enti-ties expressed by the Abox, as follows:Span Entity Contexta woman lost her bag e1 ROOTa woman e2 AGENTher bag e3 PATIENTher e2 OWNERNote that the same entity may be expressed inmultiple contexts (denoted by the incoming arcsin the semantic graph).
The relationships betweenthe entities are represented by syntactic dependen-cies between the spans of the text.
For instance,AGENT(e1,e2) is realised by the clause-subject rela-tion between ?a woman lost her bag?
and its subspan?a woman?.
This direct linking of semantic and syn-tactic dependencies has of course been noted manytimes, for instance in Meaning-Text Theory (Can-dito and Kahane, 1998).The structure of the spans of text can be repre-sented by a reconfiguration of the original Abox asan ordered tree, which we will henceforth call anAtree.
Figure 2 shows an Atree that fits the exam-ple Abox.
Note that since this is a tree, the vertexwith two incoming edges (e2) has to be repeated,and there are two spans referring to the woman.1The system is able to generate a referring expression, ?her?,for the second reference to the woman since it knows that theentity has already been mentioned in the text.
This informa-tion is available because the Atree, see Figure 2, is an orderedstructure.41Figure 2: Sample AtreeThis Atree is constructed using a set of bindingswhich map instances of concepts from the Tbox in agiven context onto a subcategorisation frame, gram-mar rule call and list of lexical anchors.
As each ver-tex of the Atree is constructed it is labelled with thegrammar rule and lexical anchors and linked back tothe vertex of the Abox which it expresses.
Our cur-rent model uses the Tree Adjoining Grammar (TAG)formalism, see Joshi (1987), and the Atree acts as astand-in derivation tree from which the derived syn-tactic tree can be computed.
Each vertex of the de-rived tree is linked back to the vertex of the Atreefrom which it was generated, and so the output fromthe system is a composite data structure compris-ing the Tbox, Abox, Atree and derived tree with achain of references connecting each span of the sur-face text via the Atree to the underlying semanticrepresentation.
A detailed exposition of the processthrough which the Atree and derivation tree are con-structed is presented in a separate Technical Report(Hardcastle and Power, 2008).2.1 Simplifying assumptionsThe design of the generator relies on two simplify-ing assumptions.
The key assumption for this paperis that the text should adhere strictly to a controlledlanguage, so that a given local semantic configura-tion is always realised by the same linguistic pattern.The cost is that the text is likely to be repetitive andmay be awkward at times; however the trade-off isthat the domain of locality is tightly restricted andthis yields important benefits in speed, scalability,reliability and verifiability that make the system suit-able for deployment in an enterprise environment.We also assume that the strategic element of theNLG process, comprising content selection and doc-ument structuring, has occurred prior to our systemreceiving its input.
Our framework is focused specif-ically on tactical generation ?
rendering the semanticrepresentation of the selected content as text.3 CompletenessWe can verify that the generator is complete, in thesense that we can guarantee that it will produce aderivation tree for any Abox valid under the Tbox.We present the details of the verification algorithmbelow, in Section 5.
Note that we assume that thesystem is equipped with the requisite morpholog-ical and orthographic rules to realise the resultingderivation tree.
We also note that we cannot verifythat the generator is consistent, by which we meanthat it should produce different texts for differentAboxes, nor that the syntactic frames and lexical an-chors mapped to the concepts in the Tbox are appro-priate.
Checking the system for consistency remainsan open research question.4 Speed and ScalabilityIn many NLG systems the choice of syntactic struc-ture and lexical arguments depends on a large num-ber of interdependent variables.
This means that theprocess of realizing the semantic input involves ex-ploring a large search space, often with some back-tracking.
In contrast, the algorithm described in thispaper is monotonic and involves minimal search.The system begins at the root of the Abox and usesa set of mappings to construct the Atree one nodeat a time.
Because the same local semantic contextis always expressed in the same way the choice ofsyntactic structure and lexical arguments can alwaysbe made on the basis of a single mapping.
Overthe course of this section we demonstrate this with asimple example using resources that were automati-cally inferred to construct the test harness describedin Section 8, which could be used to construct thefollowing simple sentence:The nurse reminded the doctor that the pa-tient was allergic to aspirin.The Abox representing this sentence is rooted inan instance of a Tbox concept representing an event42in which one person reminds another of a fact.
Fig-ure 3 shows the attributes defined for this Tbox con-cept, 938B, namely an actor, actee and target.
Therange of actor and actee is any concept in the Tboxsubsumed by the person concept, the range of tar-get is any fact.
There will therefore be three out-going arcs from the root Abox node, labelled withattributes actor, actee and target, pointing respec-tively to nodes representing the nurse, doctor andthe fact about the patient?s allergy described in thesample sentence above.
Some of these nodes willthemselves have out-going arcs expressing their ownattributes, such as the subsidiary details of the factabout the allergy.938Bactor(person)actee(person)target(fact)Figure 3: A Sample Tbox NodeTo realize the first node in the Abox the systemsearches for mappings for concept 938B.
The con-trolled language assumption allows the system tosearch with a restricted domain of locality, and sothe only variables affecting the choice of frame willbe: the Tbox concept represented by the Abox nodeto be realized (938B in this case), the syntactic con-text (there is none at this stage since we are process-ing the root node, so the system will default to clausecontext), the incoming arc (there is none at this stageso no constraint is applied), the out-going arcs (thethree attributes specified), and whether or not the in-stance has already been expressed (in this case it hasnot)2.
The search parameters are used to locate a2The last of these variables is used to determine whether ornot a referring expression (an anaphoric reference to an entitywhich has already been mentioned) is required.
Because theAtree is ordered and is constructed in order, the system alwaysknows whether an instance is being mentioned for the first time.We currently render subsequent mentions by pruning all of theout-going arcs from the Abox node, which also allows us tomanage cycles in the semantic graph.
Since the system knowswhich nodes in the semantic graph have already been mentionedit would also be possible to configure an external call to a GREsystem (Dale, 1989) - an application which infers the content ofa referring expression given the current semantic context.mapping such as the one depicted in Figure 4 below.<frame concept=?938B?role=?any?subcat=?CatClause-33?bindings=?SUB,D OB,CL COM?><gr key=?TnxOVnx1s2?><anchor lemma=?remind?
pos=?verb?/></gr></frame>Figure 4: A Sample MappingThis mapping tells the system which subcategori-sation frame to use, which grammar rule to asso-ciate with it, which lexical anchors to pass as argu-ments to the grammar rule and also how to order thesubsidiary arguments of the subcategorisation frame(the bindings attribute in the frame element).
Thesubcategorisation frame itself (shown in Figure 5) ishighly reusable as it only defines a coarse-grainedsyntactic type and a list of arguments, each of whichconsists of a free text label (such as SUB indicat-ing the subject syntactic dependency) and a coarse-grained syntactic constraint such as clause, nomi-nal or modifier.
In this example the first attributeCatClause-33type= CLAUSEargs= SUB/NOMINAL,D OB/NOMINAL,CL COM/CLAUSEFigure 5: Sample Subcategorisation Frameof the 938B node, namely the actor, is mapped tothe SUB (subject) argument, so it will become thefirst child of the Atree node representing the remindevent.
The nominal syntactic constraint will be car-ried forward as the syntactic context for the nursenode of the Abox, constraining the choice of map-ping that the system can make to realise it.
So, eachmapping enforces an ordering on the out-going arcsof the Abox which is used to order the Atree and pro-vides a syntactic context which is used to constrain43the mapping search for each child.
The process oflocating and imposing mappings cascades throughthe Abox from the root with minimal search and nobacktracking.
If multiple mappings are defined fora given context the first one is always chosen.
If nomapping is located then the system fails.While the Atree is constructed, it is annotatedwith the grammar rules and lexical anchors listedin each mapping, allowing it to serve as a stand-inTAG derivation tree from which a derived syntactictree can be constructed by instantiating and connect-ing the elementary trees specified by each grammarrule.
Further details of this process are given in aTechnical Report (Hardcastle and Power, 2008).So while the controlled language assumption thatwe should always express the same local semanticcontext in the same way limits expressivity, it alsolimits algorithmic choice and prevents backtracking,which means that the system can generate rapidlyand scale linearly.
In the following section we showhow we can prove at compile time that no Abox canbe constructed which will result in a local semanticcontext not accounted for in the mappings.5 ReliabilityIn a real-world context the Tbox will evolve as theunderlying domain model is extended and enhanced.As a result, some of the mappings described abovewill become defunct and in some instances a re-quired mapping will not be present.
If the systemencounters an Abox which requires a mapping thatis not present it will not backtrack but will fail, mak-ing the system fragile.
To address this problem weneed to be able to run a static test in a short periodof time to determine if any mappings are unused ormissing.Although the set of possible Abox graphs is aninfinite set, the tight domain of locality means thatthere is a finite set of parameters which could bepassed to the generator for any given Tbox.
As de-scribed in the previous section the choice of map-ping is based only on the following information:the concept being realised, the syntactic context, thenumber of attributes expressed by the concept, theattribute used to select it, and whether or not thisAbox instance is being mentioned for the first time.Given a starting TBox node and syntactic contextthe system can crawl the TBox recursively using thesubcategorisation frames returned from each param-eter set to derive a new list of parameter sets to betested.
Each of these must be tested both as a firstand as a subsequent mention.
The result is an algo-rithm which proves the application?s completeness(as defined in Section 3) with respect to a particulardomain (represented by the Tbox); if the test suc-ceeds then it guarantees that the mappings definedby the system can transform any Abox that is validunder the given domain into an Atree annotated withthe information required to produce a derived syn-tactic tree.As above, the proving algorithm starts with a rootconcept in the Tbox and an initial syntactic contextand uses these as the starting parameter set to findthe first mapping.
Once a mapping is located it ex-plores each of the attributes of the root concept usingthe syntactic context to which the attribute is boundby the mapping.
Since there is no Abox it constructsa list of parameter sets to check using every conceptin the range of the attribute.For example, during the verification process theprover will encounter the mapping shown above inFigure 4 for the remind concept 938B in a clausalcontext.
The concept has three attributes: an actor,an actee and a target.
The first of these has as itsrange all of the subconcepts of person defined in theTbox, and this introduces a new sub-problem.
Thefirst attribute is bound to the SUB argument of thesubcategorisation frame used in the mapping, in Fig-ure 4, by the bindings element, and this argument ofthe subcategorisation frame imposes a nominal con-straint.
So the fact that concept 938B might needto be expressed using this mapping means that anysubconcept of person might need to be expressed ina nominal syntactic context with semantic role ac-tor, and so the prover now checks each subconceptwith these parameters.
If none of the subconcepts ofperson define any attributes and a mapping is foundfor each then no new sub-problems are introducedand so this branch of the search bottoms out.The prover then returns to 938B and processes theactee and target attributes.
The target attribute isbound to the CL COM argument of the subcategori-sation frame, and so the new sub-problem involveschecking that every subconcept of fact can be ex-pressed as a clause with semantic role target.
In44the ontology the subconcepts of fact include events,each of which define a number of attributes, and sothis sub-problem branches out into many new sub-problems before it bottoms out.
One such event willbe the concept 938B, but since the mapping that wehave already encountered (Figure 4) is encoded forany semantic role and the system has already pro-cessed it the prover can break out and does not fallinto an infinite loop.
This checking process contin-ues recursively until the search space is exhausted,with each parameter set tested being cached to re-duce the size of the search space.6 Relaxing the Simplifying ConstraintsThe simplifying assumptions described in Sec-tion 2.1 deliver benefits in terms of performanceand reliability; however, they limit the expressiv-ity of the language and reduce the scope of whatcan be expressed.
We can relax some of the con-straints imposed by the simplifying assumptions andstill have a performant and reliable system, althoughproving completeness becomes more complex andsome localised exponential complexity is introducedinto the generation algorithm.
In this section we ex-plore the ways in which relaxing the constraints toallow quantification or underspecification impact onthe system.The simplest scenario, which adheres to our sim-plifying constraints, is that each node in the Aboxexpresses exactly one of each of the attributes de-fined by the Tbox concept which it instantiates.
So,using the remind example above, every instance ofremind must express an actor, an actee and a fact.In practice the Tbox may allow an attribute not to beexpressed, to be expressed many times or to be ex-pressed but not specified.
We handle the first case byallowing arguments in the subcategorisation framesto be marked as optional; for example, a verb framemay include an optional adverb slot.
These optionalarguments increase the number of tests that must beperformed; if a frame has n optional slots then thesystem will need to perform 2n checks to verify it,and will have to consider 2n mapping combinationsduring generation.
This introduces localised expo-nentiation into both the generation and the verifica-tion algorithm, although it will only lead to tractabil-ity problems if the number of optional slots on anysingle frame is too high, since the exponent is onlyapplied to each frame and not across the wholesearch space.Where an attribute may remain unspecified thesystem can be configured to respond in two differentways.
First, unspecified attributes can be includedin the text using the concept that represents the rootof the range.
For example, if an event occurs at atime which is not specified then the system can usethe concept that represents the root of the range (e.g.timePeriod perhaps) and render it accordingly (?atsome time?).
Alternatively the system can pruneall underspecified instances from the Abox beforethe Atree is generated.
Attributes which may not beexpressed (for either reason) must be flagged in theTBox so that the proving algorithm knows to matchthem to optional arguments in the subcategorisationframes.
This is implemented with a flag on each at-tribute definition indicating whether its presence inthe Abox is optional.Relaxing the constraints also impacts on our abil-ity to verify the grammar rules which are associatedwith each mapping.
If we use TAG, then we caneasily verify that the syntactic type of the root of theelementary tree defined by each mapping matchesthe syntactic type of the subcategorisation frame towhich it is bound.
However, if a mapping can beaccessed via an optional slot in another subcategori-sation frame, then it must be bound to an auxiliarytree, that is to an elementary tree which can be addedto the derived tree through adjunction, since any de-rived tree with open substitution sites will be gram-matically incomplete.
For the system to support thisbehaviour each mapping must declare not just theconcept which it realises but also the role (Tbox at-tribute) which it fulfils, so that both the prover candetermine whether it may be left out, and this in-creases the combinatorial complexity of the algo-rithm.7 ArchitectureThe design of the generator ensures that it can gen-erate rapidly and that it can be verified at compiletime.
A further feature is that it is implementedwith a component-based modular architecture.
ForNLP applications it is particularly important that in-dividual components can be independently verified45and reused, because linguistic resources are time-consuming and expensive to build and curate.
Fur-thermore, because the mappings from concepts tosubcategorisation frames, grammar rules and lexi-cal anchors are defined in a single file, the task ofbuilding and maintaining the mappings is easier tolearn and easier to manage.
It is also easier to boot-strap the mappings through resource mining, as wedid ourselves in the construction of the test data setdiscussed in Section 8.The framework manages the graph and tree struc-tures and the transformations between them, and itdefines the API for the domain and language specificresources that will be required by the application.
Italso defines the API of the linguistic resource man-ager, leaving it to the application layer to providean appropriate implementer using dependency injec-tion (Fowler, 2004).
Rather than define a core ?in-terlingual?
feature structure that attempts to captureall of the lexical features used by the grammar, theframework provides a genericised interface to thelinguistic resource manager.
This means that gram-mars for different natural languages can use differentfeature structures to define the lexical anchors usedby the application and to support tasks that are theresponsibility of the grammar, such as unification ormorphological inflection.
For example, all verbs inFrench should have a flag indicating whether avoiror e?tre is used as a modal auxiliary for the passe?compose?, but this flag need not be present for otherlanguages.
The Tbox, the subcategorisation framesand the mappings between them are all defined asdata sources and can be reused across applicationsas appropriate.
Although they are not defined incode they can still be verified at compile time bythe prover discussed in the previous section, and thisallows the system to be flexible and modular with-out introducing the risk of runtime failures causedby faulty mapping data.7.1 ExportA further feature of the system which arises fromthe proving algorithm is that it supports export be-haviour.
In an enterprise context we want to beable to reuse linguistic resource components, suchas a lexicon, a grammar, a morphological genera-tor and so on, across many different applications.These resources are large and complex and for agiven application much of the data may not be re-quired.
Because the proving algorithm is able tocompile a comprehensive list of the concepts, gram-matical relations, subcategorisation frames and lexi-cal anchors that will be required to realise any Abox,given a starting concept and syntactic context, thesystem can cut the Tbox, lexicon, grammar, subcat-egorisation frame store and related resources to ex-port a build for deployment, while guaranteeing thatthe deployed application will never fail because ofa missing resource.
This is of particular value if wewant to reuse large-scale, generic, curated resourcesfor a small domain and deploy where bandwidth isan issue ?
for example where language generation isrequired in a client-heavy internet-based or mobileapplication.8 Testing and ResultsWe unit-tested the mechanics of the framework,such as the graph and tree managers.
We then built aproof-of-concept application with a small ontologyrepresenting the domain of patient treatment narra-tives and handcrafted the subcategorisation frames,lexical resources and TAG grammars for English,French, Spanish and Italian.
We used this applica-tion to verify the independence of the framework,domain and linguistic resources and verified that wecould develop linguistic resources offline and plugthem into the application effectively.
The applica-tion also served as a test harness to test the adaptibil-ity of the framework to render the same semanticcontext in different syntactic structures dependingon the target natural language.
For example, weincluded the examination of a body part belongingto a person in the domain, and this was expressedthrough a Saxon genitive in English but a preposi-tional phrase (with the subsidiary NPs in the reverseorder) in the other languages.To test our assumptions about efficiency and scal-ability we inferred a larger Tbox, subcategorisationframes and mappings using a pre-existing data setof verb frames for English encoded using the COM-LEX subcategorisation frame inventory (Grishmanet al, 1994).
The linguistic resources for the appli-cation comprised a generative TAG grammar basedon X-TAG (Doran et al, 1994) which we wrote our-46selves, the CUV+ lexicon3, and a pre-existing mor-phological generator for English (Hardcastle, 2007).To test the performance of the generation processwe used a set of randomly-generated Aboxes derivedfrom the Tbox to produce texts of increasing size.For the purposes of testing we defined the size of anAbox as the total number of nodes and edges in thegraph, which is the number of RDF triples requiredto represent it.
Table 1 shows the size of the out-put text in sentences, the time taken to generate it inmilliseconds, averaged over 5 runs, and the ratio ofthe time taken to the size of the output which showslinear scaling4.Size Timing Timing/Size31 2 0.065280 10 0.0362,800 59 0.02128,000 479 0.017Table 1: The time, in milliseconds, taken to generateAboxes of increasing size and the ratio of time taken tothe size of the output.To test the performance of the proving algorithmwe ran the algorithm on a set of Tboxes of differ-ing sizes.
The smallest Tbox in Table 2 is the hand-crafted proof-of-concept Tbox, the largest is the in-ferred Tbox described above, and the intermediateones were pruned from the large, inferred Tbox atrandom cut points.
The size of each Tbox is thetotal number of attribute-concept pairs which it de-fines.
The table shows the time taken to run theprover from the root node of the Tbox with no start-ing syntactic context and the ratio of time taken tosize, which shows linear scaling.We tested the mechanics of the implementationof the prover through unit testing, and we testedthe the design with a test suite of sample data.
Weperformed white box tests by removing individualbindings from a set of mappings which we judgedto be complete for the small handcrafted Tbox, andchecked to ensure that each was highlighted by theprover.
We performed black box tests by using a3A publicly available lexicon for English available from theOxford Text Archive4In fact scaling is slightly sub-linear for this test and thetest of the proving algorithm.
In both cases that is because ofcaching within the framework to improve performance.Size Timing Timing/Size125 10 0.0886,766 432 0.0052,054,020 8,217 0.0049,267,444 21,526 0.002Table 2: The time, in milliseconds, taken to prove relia-bility for Tboxes of increasing size and the ratio of timetaken to size.set of inferred mappings, judged by the prover to becomplete, to generate from a large number of ran-domly structured Aboxes, drawn from our large in-ferred Tbox, and checked that the generation processnever failed.We chose not to undertake a formal evaluationover and above the unit and sampling tests, becausethe accuracy of the prover is a function of the re-stricted domain of locality imposed by the systemand of the recursive algorithm which depends on it.Instead we show that the prover is accurate by de-scribing the parameters that guide search in gener-ation and explaining why they can be exhaustivelytested (see Section 5).9 ConclusionIn this paper we presented a tactical generator whichexploits a simplifying assumption that the outputtext will be restricted to controlled natural languageto enforce a restricted domain of locality on searchin generation.
As a result, the generation process isfast and scales linearly, and furthermore the systemis reliable, since we are able to perform a compile-time check of the data sources which drive the as-signment of syntactic subcategorisations to the ex-pression of each node in the input semantic graph.The generator is most appropriate for applicationswhich need to present small chunks of structureddata as text on demand and in high volume.
For ex-ample, information feeds such as local weather fore-casts, traffic information, and tourist information ortechnical information that must be both machine-readable (for example because it is safety criticaland requires consistency checking) and also human-readable (for example for an operator to make use ofit) such as machine operator instructions, businessprocess/protocol descriptions and medical orders.47ReferencesF.
Baader, D. Calvanese, D. L. Mcguinness, D. Nardi, andP.
F. Patel-Schneider, editors.
2003.
The DescriptionLogic Handbook : Theory, Implementation and Appli-cations.
Cambridge University Press.J.
Bateman, R. Kasper, J. Moore, and R. Whitney.
1989.A general organization of knowledge for natural lan-guage processing: The Penman Upper Model.
Techni-cal report, Information Sciences Institute, Marina delRey, California.T.
Berners-Lee, J. Hendler, and O. Lassila.
2001.
TheSemantic Web.
Scientific American, 284(5):34?43.M.
Candito and S. Kahane.
1998.
Can the TAG deriva-tion tree represent a semantic graph?
An answer inthe light of the Meaning-Text Theory.
In Proceedingsof the Fourth Workshop on Tree-Adjoining Grammarsand Related Frameworks, Philadephia, USA.R.
Dale.
1989.
Cooking up referring expressions.
InProceedings of the 27th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 68 ?
75,Vancouver, Canada.C.
Doran, D. Egedia, B. Hockey, B. Srinivas, andM.
Zaidel.
1994.
XTAG system - a wide coveragegrammar for English.
In Proceedings of the 15th In-ternational Conference on Computational Linguistics,pages 922?928, Kyoto, Japan.M.
Fowler.
2004.
Inversion of control containers and thedependency injection patternhttp://www.martinfowler.com/articles/injection.html.R.
Grishman, C. McLeod, and A. Myers.
1994.
Com-lex Syntax: Building a Computational Lexicon.
InProceedings of the The 15th International Conferenceon Computational Linguistics, pages 268?272, Kyoto,Japan.D.
Hardcastle and R. Power.
2008.
Generating Concep-tually Aligned Texts.
Technical Report 2008/06, TheOpen University, Milton Keynes, UK.D.
Hardcastle.
2007.
Riddle posed by computer (6): TheComputer Generation of Cryptic Crossword Clues.PhD thesis, University of London.A.
Hartley and C. Paris.
2001.
Translation, controlledlanguages, generation.
In E. Steiner and C. Yallop,editors, Exploring Translation and Multilingual Textproduction, pages 307?325.
Mouton de Gruyter.A.
Joshi.
1987.
The relevance of tree adjoining gram-mar to generation.
In G. Kempen, editor, Natural Lan-guage Generation: New Directions in Artificial Intel-ligence, Psychology, and Linguistics.
Kluwer.O.
Lassila and R. Swick.
1998.
Resource Descrip-tion Framework (RDF) model and syntax specifica-tion.
W3C Working Draft WD-rdf-syntax-19981008.C.
Paris, K. Vander Linden, M. Fischer, A. Hartley,L.
Pemberton, R. Power, and D. Scott.
1995.
A sup-port tool for writing multilingual instructions.
In Pro-ceedings of the 14th International Joint Conferenceon Artificial Intelligence, pages 1398?1404, Montreal,Canada.R.
Power and D. Scott.
1998.
Multilingual authoringusing feedback texts.
In Proceedings of the 17th In-ternational Conference on Computational Linguisticsand 36th Annual Meeting of the Association for Com-putational Linguistics, pages 1053?1059, Montreal,Canada.R.
Power, D. Scott, and N. Bouayad-Agha.
2003.Document structure.
Computational Linguistics,29(4):211?260.48
