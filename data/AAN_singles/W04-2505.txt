Intentions, Implicatures and Processing of Complex QuestionsSanda M. Harabagiu and Steven J. Maiorano and Alessandro Moschitti and Cosmin A. BejanUniversity of Texas at DallasHuman Language Technology Research InstituteRichardson, TX 75083-0688, USAAbstractIn this paper we introduce two methods forderiving the intentional structure of complexquestions.
Techniques that enable the deriva-tion of implied information are also presented.We show that both the intentional structureand the implicatures enabled by it are essen-tial components of Q/A systems capable of suc-cessfully processing complex questions.
Theresults of our evaluation support the claim thatthere are multiple interactions between the pro-cess of answer finding and the coercion of in-tentions and implicatures.1 IntroductionThe Problem of Question Intentions.When using a Question Answering system to findinformation, the user cannot separate the intentionsand beliefs from the formulation of the question.
Adirect consequence of this phenomenon is that the userincorporates his or her intentions and beliefs into theinterrogation.
For example, when asking the question:Q1: What kind of assistance has North Korea receivedfrom the USSR/Russia for its missile program?the user associate with the question a number of in-tentions, that maybe expressed a set of intended ques-tions.
Each intended question, in turn generates impliedinformation, that maybe expresses as implied questions.For question Q1, a list of intended questions and impliedquestions is detailed in Table1.Most of the intended questions are similar with thequestions evaluated in TREC1.
For example questions1The Text REtrieval Conferences (TREC) are evaluationworkshops in which Information Retrieval tasks are annuallytested.
Since 1999 the performance of question answering sys-tems are measured in the TREC QA track.Qi1, Qi2 and Qi3 are so-called definition questions, sincethey ask about defining properties of an object.
Howeverunlike the TREC definition questions, these questions ex-press unstated intentions of the questioner and need to beprocessed in the context of the original complex questionQ1.
Questions Qi4 and Qi5 are factoid questions, request-ing information about facts or events.
Qi6 asks about thesource of information that enables the answers of ques-tion Q1.Questions Qi1, Qi2, Qi3, Qi4 and Qi5 result from the in-tentional structure generated when processing questionQ1 or questions similar to it.
When intended questionsare generated, their sequential processing (a) represents adecomposition of the complex question and (b) generatesa scenario for finding information; thus questions like Q1are also known as scenario questions.Intentions and Implicatures.As Table 1 suggests, the implied information takes theform of alternatives that guide the answers to intendedquestions.
For example, question Qm11 lists alternativesfor the answer to Qi1 whereas Qm21 lists components ofthe answer of Qi1.
Implicatures may also involve tem-poral inference, e.g.
the implied questions pertainingto Qi3 and Qi4.
Additionally, the reliability of infor-mation is commonly an implicature in the case of sce-nario questions, since the causal and temporal inferenceis based on the quality and correctness of the availabledata sources.
Neither intentions or implicatures are rec-ognizable at syntactic or semantic level, but they bothplay an important role in the question interpretation.
In-terpretations disregard the implied information or the userintentions determine the extraction of incorrect answers,thus influence the performance of Q/A systems.Our solution.In this paper we present two different mechanisms ofderiving the question implicatures.
Both methods startfrom the syntactic and semantic content of the interro-gation.
The first method considers only the semanticIntended Questions Implied QuestionsQi1 :What is the USSR/Russia?
Qm11 :Is this the Soviet/Russian government?Qm12 :Does it include private firms, state-owned firms, educationalinstitutions, and individuals?Qi2 :What is North Korea?
Qm21 :Is this the North Korean government only?Qm22 :Does it include private firms, state-owned firms, educationalinstitutions, and individuals?Qi3 :What is assistance?
Qm31 :Is it the transfer of complete missile systems, licensing agreements,components, materials, or plans?Qm32 :Is it the training of personnel?Qm33 :What kind of training?Qm34 :Does transfer include data, and, if so, what kind of data?Qm35 :Does transfer include financial assistance, and, if so, what kind offinancial assistance?Qi4 :What are the missiles in the North Qm41 :Are any based upon Soviet/Russian designs?Korean inventory?
Qm42 :If so, which ones?Qm43 :What was the development timeline of the missiles?Qm44 :Did any timeline differ significantly from others?Qm45 :Did North Korea receive assistance from other sources besidesUSSR/Russia to develop these missiles?Qi5 :When did North Korea receive assistance Qm51 :Was any intended assistance halted, stopped or intercepted?from the USSR/Russia?Qi6 :What are the sources of information?
Qm61 :Are the sources reliable?Qm62 :Is some information contradictory?Table 1: Question decomposition associated with question Q1meaning of the words used in the question whereas thesecond method considers the predicate-argument struc-ture of the question and candidate answers as a form ofshallow semantics that enables the inference of the inten-tional structure.
Question implicatures are derived fromlexico-semantic paths retrieved from the WordNet lexico-semantic database.
These paths bring forward new con-cepts, that may be associated with the question implica-tures when testing the paths against the conversationalmaxims introduced by Grice in (Grice, 1975a).
For ex-ample, if the user asks ?Will Prime Minister Mori survivethe crisis?
?, the first method detects the user?s belief thatthe position of the Prime Minister is in jeopardy, sincethe concept DANGER is coerced although none of thequestion words directly imply it.The second method generates the intentional structureof the question, enabling a more structured representa-tion of the pragmatics of question interpretation.
The in-tentional structure is based on a study that we have con-ducted for capturing the motivations of a group of userswhen asking series of questions in several scenarios.
Weshow how the intentional structures that we have gatheredguide the coercion of knowledge that helps to support theacceptance of rejection of computational implicatures.The derivation of intentional structures is made possi-ble by predicate-argument structures that are recognizedboth at the question level and at the candidate answerlevel.
In this paper we show how richer semantic ob-jects can be derived around predicate-argument structuresand how inferential mechanisms can be associated withsuch semantic objects for obtaining correct answers.
Therest of the paper is organized as follows.
In Section 2we describe several forms of complex questions that re-quire the derivation of computational implicatures.
Sec-tion 3 details the models of Question Answering that weconsidered and Section 4 shows our methods of derivingpredicate-argument structures and their usage in identi-fying answers for questions.
Section 5 details the inten-tional structures whereas Section 6 summarizes the con-clusions.2 Question ComplexitySince 1999, the TREC QA evaluations focused on fac-toid questions, such as ?In what year did Joe Di Maggiocompile his 56-game hitting streak??
or ?Name a film inwhich Jude Law acted.?.
The answers to most of thesequestions belong to semantic categories associated witheach question class.
For example, questions asking abouta date or a year can be answered because Named EntityRecognizers identify a temporal expression in a candidatetext span.
Similarly, names of people or organizationsare provided as answers to questions such as ?Who is thefirst Russian astronaut??
or ?What is the largest softwarecompany in the world??.
Most Named Entity Recogniz-ers detect names of PEOPLE, ORGANIZATIONS, LOCA-TIONS, DATES, PRICES and NUMBERS.
For factoid Q/A,the list of name categories needs to be extended, as re-ported in (Harabagiu et al, 2003) for recognizing manyWhat kind od assistance has North Korea received fromComplex Question:What kind of assistance has X received from Y for Z?Question PATTERN:X=North Korea FOCUS=Z=misile programIntended Questions:Definition Questions:What is Y?
"What is USSR/Russia?
"What is assistance?Elaboration of FOCUS:Reliability: "What are the sources of information?
"the USSR/Russia for its missile program?assistance from the USSR/Russia?
"(1) RESULTATIVE(2) TEMPORALNorth Korean inventory?
""When did North Korea receiveY=USSR/RussiaWhat is X?
"What is North Korea?
""What are the missiles in theFigure 1: Decomposition of scenario question into intended questionsmore types of names, e.g.
names of movies, names ofdiseases, names of battles.
Moreover, the semantic cat-egories of the extended set of names need to be incor-porated into an answer type taxonomy that enables therecognition of (a) the expected answer type and (b) thequestion class.
The taxonomy of expected answer typesis useful because the answer is not always a name; it canbe a lexicalized concept or a concept that is expressed bya paraphrase.The TREC evaluations have also considered two moreclasses of questions: (1) list questions and (2) definitionquestions.
The list questions have answers that are typ-ically assembled from different documents.
Such ques-tions are harder to answer than factoid questions be-cause the systems must detect duplications.
Example oflist questions are ?Name singers performing the role ofDonna Elvira in performances of Mozart?s ?Don Gio-vani?.?
or ?What companies manufacture golf clubs?
?.Definition questions require a different form of process-ing that factoid questions because no taxonomy of answertypes needs to be used.
The expected answer type is a def-inition, which cannot be represented by a single concept.Q/A systems assume that definitions are given by follow-ing a set of linguistic patterns that need to be matched forextracting the answer.
Example of definition questionsare ?What is a golden parachute??
or ?What is ETA inSpain?
?.In (Echihabi and Marcu, 2003) a noisy channel modelfor Q/A was introduced.
This model is based on theidea that if a given sentence SA contains an answer sub-string A to a question Q, then SA can be re-written intoQ through a sequence of stochastic operators.
Not only ajustification of the answer is produced, but the conditionalprobability P(Q?SA) re-ranks all candidate answers.A different viewpoint of Q/A was reported in (Itty-cheriah et al, 2000).
Finding the answers A to a ques-tion Q was considered a classification problem that maxi-mizes the conditional probability P(A?Q).
This model isnot tractable currently, because (a) the search space is toolarge for a text collection like the TREC or the AQUAINTcorpora; and (b) the training data is insufficient.
There-fore, Q/A is modeled by the distribution P(C?A,Q)where C measures the ?correctness?
of A to questionQ.
By using a hidden variable E that represents the ex-pected answer type, P(C?A,Q) = ?E p(C,E?Q,A) =?E p(C?E,Q,A) * p(E?Q,A).
Both distributions aremodeled by using the maximum entropy.All three forms of questions are also useful when pro-cessing complex questions, determined by a scenario re-sulting from a problem-solving situation.
As illustratedin Figure 1, a scenario question may be associated with apattern.
One of the pattern variables represents the focusof the question.
The notion of the question focus was firstintroduced by (Lehnert, 1978).
The focus represents themost important concept of the question; a concept deter-mining the domain of question.
In the case of questionQ1, the focus is missile program.
The identification ofthe focus is based on the predicate-structure of the ques-tion pattern and on the order of the arguments.
Figure 3shows both the question pattern associated with Q1 andits predicate-argument structure.
The argument with therole of purpose is ranked highest, and thus it determinesthe question focus.With the exception of the focus, all arguments fromthe predicate-argument structure may be used for gener-ating definition questions.
The focus is elaborated upon.Several forms of elaborations are possible.
One is a tem-poral one, as illustrated in Figure 1.
Other are resultative,causative or manner-based.
For example, the knowledgethat assistance in a missile program results in an inven-When did North Korea receive from USSR/RussiaassistanceWRB VBD NNP NNP NNPVB NNNPBINPPNPBVPNPBSQWHADVPSBARQOBJECTBENEFICIARY SOURCEDATEwhen=DATEStep 2(a): Binary Semantic Dependenciesreceive North Korea USSR/Russia assistanceTypeExpected AnswerStep 2(b): Predicate?Argument StructuresPredicate: receiveArguments: assistance=OBJECTNorth Korea=BENEFICIARYUSSR/Russia=SOURCEWhen=DATE=Expected Answer TypeQuestion: When did North Korea receive assistance from USSR/Russia?Step 1: Syntactic ParseFigure 2: Deriving the Expected Answer TypePredicate?argument structure:Predicate:Arguments:receivePurpose: ZBeneficiary: X Source: YObject: assistanceQuestion Pattern: What kind of assistance has X receivedfrom Y for Z?Figure 3: Predicate-argument structuretory of missiles allows for resultative elaboration.
Furtherknowledge needs to be coerced for generating the impliedquestions as possible follow-ups to intended questions.The relationship between intended questions and im-plied questions is marked by the presence of multiplereferences, e.g.
the pronouns it and this or any andones.
The generation of implied questions is made pos-sible by knowledge that is coerced from the intendedquestions.
For example, when asking Qi1 :?What isthe USSR/Russia??
the coercion process abstracts awayfrom the concept that needs to be defined, i.e.
a coun-try.
The implied question requests confirmation ofthe metonymy resolution involving USSR/Russia.Thisnamed entity may represent a country but most likely itrefers to its government or, as Qm12 suggests, organiza-tions or individuals acting on behalf of the country.
BothQm11 and Qm12 , implied questions derived from the in-tended question Qi1, refer to the metonymy by using thepronouns this and it respectively.
Different forms of coer-cion are used for Qi3 because in this case the knowledgeis associated with the predicate.
The implied questionsassociated with the focus, i.e.
the intended question Qi4,coerce the design and development predicates which areassociated with the missiles as well as the timelines ofpossible additional assistance.3 Models of Question AnsweringThe processing of questions is typically performed as asequence of three processes: (1) Question Processing; (2)Document Processing and (3) Answer Extraction.
In thecase of factoid questions , question processing involvesthe classification of questions with the purpose of pre-dicting what semantic class the answer should belongto.
Thus we may have questions asking about PEOPLE,ORGANIZATIONS, TIME or LOCATIONS.
Since open-domain Q/A systems process questions regardless of thedomain of interest, question processing must be based onan extended ontology of answer types.
The identificationof the expected answer type is based either on binary se-mantic dependencies extracted from the syntactic parse ofthe question (Harabagiu et al, 2001) or on the predicate-argument structure of the question.
In both cases, the re-lation to the question stem (i.e.
what, who, when) enablesthe classification.
Figure 2 illustrates a factoid questiongenerated as an intended question and the derivation ofits expected answer type.However, many times the expected answer type needsto be identified from an ontology that has high lexico-semantic coverage.
Many Q/A systems use the WordNetdatabase for this purpose.
In contrast, definition ques-tions do not require the identification of the expected an-Answer Pattern:Answer:Question Pattern:Question?Point, a Definitionhas killed nearly 800 people sincetaking up arms in 1968for Basque Homeland and Freedom ?ETA, a Basque language acronymWhat is Question?Point in Country?What is in SpainETANNPNPBINPPNNPNPBNPVBZSQWPWHNPSBARQDefinition Question: What is ETA in Spain?Question Parse:Figure 4: Patterns for Processing Definition Questionsswer type, since they always request a definition.
How-ever, definition questions are matched against a set of pat-terns, which enables the extraction of the definition fromthe candidate answers.
Figure 4 illustrates a definitionquestion, the pattern it matched as well as the extractedanswer.Both factoid and definition questions can be answeredonly if candidate passages are available.
The retrieval ofthese passages is made possible by keywords that are se-lected from the question words.
The Documents Process-ing module implements a search engine that returns pas-sages that are likely to contain the expected answer typein the case of factoid questions or the definition patternin the case of definition questions.
The answer extractionmodule optimizes the extraction of the correct answer byunifying the question information with the answer infor-mation.
The unification may be based on pattern match-ing; on machine learning algorithms based on the ques-tion and answer features or on abductive reasoning thatjustifies the answer correctness.Current state-of-the-art QA systems search for the can-didate answer by assuming that the answers are singleconcepts, that can be recognized from a hierarchy or bya Named Entity Recognizer.
This is a serious limitation,but it works well for the factoid, list or definition ques-tions evaluated in TREC.The three modules of current Q/A systems reflect thethree functions that need to be considered by any Q/Amodel: (1) understanding what the question asks; (2)identify candidate text passage that might contain the an-swer; and (3) the extraction of the correct answer.
Cur-rently, the expected answer type represents what ques-tion asks about: a semantic concept, e.g.
the name of aperson, location or organization, kinds of diseases, typesof animals or plants.
Generally these semantic conceptsare lexicalized in a single word or in 2-word collocations.Clearly, this represents a limitation, since often the ques-tions ask for more than a single concept.
As we haveseen in Table1, there is additional intended and impliedinformation that is requested.
Therefore new models ofQuestion/Answering need to incorporate these additionalforms of knowledge.When definition questions are processed in currentQ/A systems, they are matched against a pattern, which isdifferent from the question patterns associated with com-plex questions similar to those illustrated in Figure 1.
Inthe case of a definition question like ?What is ETA inSpain?
?, the pattern identifies the question-point (QP) asETA- the concept that needs to be defined and Spain asits context.
The definition question pattern also containsseveral surface-form patterns that are matched in the can-didate paragraphs.
One such pattern is recognized in anapposition, by [QP, a AP] where AP represents the an-swer phrase.
In the following passage:?ETA, a Basque language acronym for Basque Homelandand Freedom - has killed nearly 800 people since takingup arms in 1968.?the exact answer representing the definition is identifiedin AP: Basque language acronym for Basque Homelandand Freedom.
The fact that Basque country is a region inSpain allows a justification of the question context.In this paper, by considering the intentional informa-tion and the implied information that can be derived whenprocessing questions, we introduce a novel model of Q/A,which has access to rich semantic structures and enablesthe retrieval of more accurate answers as well as inferenceprocesses that explain the validity and contextual cover-age of answers.Figure 5 shows the structure of the novel model of Q/Awe propose.
Both Question Processing and DocumentProcessing have the recognition of predicate-argumentstructures as a crux of their models.
As reported in (Sur-deanu et al, 2003), the recognition of predicate-argumentstructures depends on features made available by full syn-tactic parses and by Named Entity Recognizers.
As weshall show in this paper, the predicate-argument struc-tures enable the recognition of question pattern, the ques-tion focus and the intentional structure associated withQuestionSyntactic Parse Named EntityRecognitionIdentification ofPredicate?Argument StructureStructureRecognition of Answerbased on extendedIndexing & Retrievallexico?semantic knowledgeNamed EntityRecognitionSyntactic ParseIntentional StructureIdentification ofPredicate?ArgumentStructures Question PatternRecognition ofIdentification ofQuestion FocusRecognition of Answer StructureKeyword ExtractionValidation of Implied InformationAnswer StructureRecognition ofRecognition and extentionof intentional structureReference ResolutionQuestion Processing Answer ProcessingDocument ProcessingAnswerFigure 5: Novel Question/Answering Architecture.a question.
When the intentions are known, the answerstructure can be identified and the keywords extracted.For better retrieval of candidate answers, documents areindexed and retrieved based on the predicate-argumentstructures as well as on complex semantic structure asso-ciated with different question patterns.
Similarly, the in-tentional structures are used for indexing/retrieving can-didate passages.
The Answer Processing function in-volves the recognition of the answer structure and inten-tional structure.
Often this requires reference resolution.The implied information coerced from both the questionand the candidate answer is also validated before decid-ing on the answer correctness.4 Predicate-Argument StructuresTo identify predicate-argument structures in questionsand passages, we have: (1) used the Proposition Bank orPropBank as training data; and (2) a mode for predictingargument roles similar to the one employed by (Gildeaand Jurafsky, 2002).PropBank is a one million word corpus annotated withpredicate-argument structures on top of the Penn Tree-bank 2 Wall Street Journal texts.
For any given predicate,the expected arguments are labeled sequentially from Arg0 to Arg 4.
Generally, Arg 0 stands for agent, Arg 1 fordirect object or theme or patient, Arg 2 for indirect objector benefactive or instrument or attribute or end state, Arg3 for start point or benefactive or attribute and Arg4 forend point.
In addition to these core arguments, adjunc-tative arguments are marked up.
They include functionaltags from Treebank, e.g.
ArgM-DIR indicates a direc-tional, ArgM-LOC indicates a locative, and ArgM-TMPstands for a temporal.An example of PropBank markup is:[Arg10 Analysts ] have been [predicate1 expecting ] [Arg11a GM-Jaguar pact ] that would [predicate2 give ] [Arg22 theU.S.
car maker ] [Arg21 an eventual 30% state in the BritishCompany ].The model of identifying the arguments of each pred-icate consists of two tasks: (1) the recognition of theboundaries of each argument in the syntactic parse tree;(2) the identification of the argument role.
Each task canbe cast as a separate classifier.
Next section describesour approach based on Support Vector Machines (SVM)(Vapnik, 1995).4.1 Automatic Predicate-Argument extractionGiven a sentence in natural language, all the predicatesassociated with its verbs have to be identified along withtheir arguments.
This problem can be divided in two sub-tasks: (a) detection of the target argument boundaries,i.e.
all its compounding words, and (b) classification ofthe argument type, e.g.
Arg0 or ArgM.A direct approach to learn both detection and classifi-cation of predicate arguments is summarized by the fol-lowing steps:1.
Given a sentence from the training-set, generate afull syntactic parse-tree;2. let P and A be the set of predicates and the set ofparse-tree nodes (i.e.
the potential arguments), re-spectively;3. for each pair <p, a> ?
P ?A:?
extract the feature representation set, Fp,a;?
if the subtree rooted in a covers exactly thewords of one argument of p, put Fp,a in T+(positive examples), otherwise put it in T?
(negative examples).0.680.710.740.770.80.831 2 3 4 5Polynomial Degree(a)F1Arg0Arg1ArgM0.650.680.710.740.770.81 2 3 4 5Polynomial Degree(b)F1Figure 6: Single classifiers and Multi-classifier performance for argument extraction.The above T+ and T?
sets can be re-organized as pos-itive T+argi and negative T?argi examples for each argu-ment i.
In this way, an individual ONE-vs-ALL SVMclassifier for each argument i can be trained.
We adoptedthis solution as it is simple and effective (Pradhan et al,2003).
In the classification phase, given a sentence of thetest-set, all its Fp,a are generated and classified by eachindividual SVM classifier.
As a final decision, we selectthe argument associated with the maximum value amongthe scores provided by the SVMs2, i.e.
argmaxi?S Ci,where S is the target set of arguments.The discovering of relevant features is a complex task.Nevertheless there is a common consensus on the basicfeatures that should be adopted.
These standard features,first proposed in (Gildea and Jurafsky, 2002), are derivedfrom parse trees as illustrated by Table 2.4.2 Parsing Sentence into Predicate ArgumentStructuresFor the experiments, we used PropBank(www.cis.upenn.edu/?ace) along with Penn-TreeBank3 2 (www.cis.upenn.edu/?treebank)(Echihabi and Marcu, 2003).
This corpus contains about53,700 sentences and a fixed split between training andtesting which has been used in other researches (Gildeaand Jurafsky, 2002; Surdeanu et al, 2003; Hacioglu etal., 2003; Chen and Rambow, 2003; Gildea and Hock-enmaier, 2003; Gildea and Palmer, 2002; Pradhan et al,2003).
In this split, Sections from 02 to 21 are used fortraining, section 23 for testing and sections 1 and 22 asdeveloping set.
We considered all PropBank argumentsfrom Arg0 to Arg9, ArgA and ArgM even if only Arg0from Arg4 and ArgM contain enough training/testing2This is a basic method to pass from binary categorizationinto a multi-class categorization problem; several optimizationhave been proposed, e.g.
(Goh et al, 2001).3We point out that we removed from the Penn TreeBank thespecial tags of noun phrases like Subj and TMP as parsers usu-ally are not able to provide this information.data to affect the global performance.The classifier evaluations were carried out usingthe SVM-light software (Joachims, 1999) available athttp://svmlight.joachims.org/ with the de-fault polynomial kernel according to a degree d ?
{1, 2, 3, 4, 5}.
The performances were evaluated usingthe F1 measure for both single argument classifiers andthe multi-class classifier.- PHRASE TYPE (pt): This feature indicates the syntactictype of the phrase labeled as a predicate argument.- PARSE TREE PATH (path): This feature contains the pathin the parse tree between the predicate phrase and the argu-ment phrase, expressed as a sequence of nonterminal labelslinked by direction (up or down).- POSITION (pos) Indicates if the constituent appears be-fore or after the predicate in the sentence.- VOICE (voice) This feature distinguishes between activeor passive voice for the predicate phrase.- HEAD WORD (hw) This feature contains the head wordof the evaluated phrase.
Case and morphological informa-tion are preserved.- GOVERNING CATEGORY (gov) This feature applies tonoun phrases only, and it indicates if the NP is dominated bya sentence phrase (typical for subject arguments with activevoice predicates), or by a verb phrase (typical for objectarguments).- PREDICATE WORD In our implementation this featureconsists of two components: (1) VERB: the word itselfwith the case and morphological information preserved; and(2) LEMMA which represents the verb normalized to lowercase and infinitive form.Table 2: Standard Features used in Predicate ArgumentExtraction.Figure 6 illustrates the F1 measures for the overall ar-gument extraction task (i.e.
identification and classifica-tion) according to different polynomial degrees.
Figure6(a) illustrates the F1-performance of single classifiersfor the arguments Arg0, Arg1 and ArgM.
Figure 6(b) il-lustrates the performance for all the arguments (i.e.
themulti-classifier).
In general, we were able to recognizepredicate argument structures with an F1-score of 80%.4.3 Using Predicate-Argument Structures inQuestion Answering.Predicate-argument structures are useful for identifyingcandidate answers.
Since they recognize long-distancedependencies between a predicate and one its arguments,they enable (1) the identification of the exact boundariesof an answer; and (2) they unify the predicate-argumentrelation sought by question with those recognized in can-didate passages.Moreover, they are very useful in situations when theexpected answer type of the question could not be recog-nized.
There are two causes when the expected answertype cannot be identified:Case1: the answer class is a name that cannot be correctlyclassified by an available Named Entity Recognizer, be-cause its class name is not encoded.Case2: the answer class cannot be found in the AnswerType hierarchy.
The example from Figure 7 shows an in-stance of case 1.
In this figure, the TREC question Q2054has a predicate that can be unified with PREDICATESfrom the answer passage.
The Arg1 of the predicate isthe expected answer, which is identified as ?the Declara-tion of Independence?.
The Arg0 in the question is But-ton Gwinnett, whereas in the answer, it is underspecified,and should be resolved to who.
This relative pronoun hasButton Gwinnett as one of its antecedents.In Figure 8 the second case is illustrated.
The questionasked about the first argument of the predicate ?measure?,when its Arg2 = ?a theodolite?.
In the answer, Predicate2, with its infinite form, has as Arg 2 the same ?theodo-lite?.
However, the predicates are lexicalized by differentverbs.
In WordNet, the first sense of the verb ?measure?as the verb ?determine?
as a hypernym, therefore Arg1 =?wind speeds?
is the correct answer.5 Intentional StructuresThe correct interpretation of many questions requiresthe inference of implicit information, that is not directlystated in the question, but merely implied.
The mecha-nisms of recognizing the intentions of the questioner arehelpful means of identifying the implied information.
Forexample, in the question QI :?Will Prime Minister Morisurvive the crisis?
?, the user does not literally mean ?WillPrime Minister Mori be still alive when the political cri-sis is over ?
?, but rather (s)he implies her/his belief thatthe current political crisis might cost the Japanese PrimeMinister his job.
It is very unlikely that any expert knowl-edge base covering Japanese politics will encode knowl-edge covering all situations of political crisis and the pos-sible outcomes of the prime minister.
However, this prag-matic knowledge is essential for the correct interpretationof the question.Q2054:Answer: Button Gwinnett, George Walton and Lyman Hall wereGeorgians who could have been hanged as traitors forWhat document did Button Gwinnett sign on the upper lefthand side?signing the Declaration of Independence on July 4, 1776.Predicate?argument structure:PREDICATE1: wereARG1(PREDICATE1): GeorgianswhoPREDICATE2: could have been hangedARG2(PREDICATE2): as traitorsPREDICATE3: signingARG1(PREDICATE3): The Declaration of IndependenceARGM?LOC(PREDICATE3): on July 4, 1776ARG0: Button Gwinnett, George Walton and Lyman HallARGM?LOC: on the upper left hand sideARG0: Button GwinnettPREDICATE: signARG1: What document Question TypePredicate?argument structure:Figure 7: Answer extraction from predicate-argument struc-tures: Case1measurePREDICATE:What does a theodolite measure?Predicate?argument structure:ARG1: WhatARG2: a theodoliteAnswer: The theodolite ?
a 1940s gadget, no longer in production,wind speeds.that uses a helium balloon and trigonometry to determinePredicate?argument structure:a 1940s gadgetthatPREDICATE1: usesPREDICATE2: to determineARG1(PREDICATE2): wind speedsQ2145:ARG1(PREDICATE1): The theodoliteARG2(PREDICATE1): a helium balloon and trigonometryFigure 8: Answer extraction from predicate-argument struc-tures: Case 2The design of advanced Question&Answering systemscapable of grasping the intention of a professional analystwhen (s)he poses a question depends both on the knowl-edge of the domain referred by the question as well as ona variety of rules and conventions that allow the commu-nication of intentions and beliefs in addition to the literarymeaning of the question.
Access to domain knowledge isgranted by a combination of retrieval mechanisms thatbring forward relevant document passages from unstruc-tured collections of documents, specialized knowledgeText Information RetrievalEngineQUERY: Prime & Minister & Mori &DANGER (word)Japanese Factual PoliticsKnowledge BaseText Retrieval"vote of non-confidence againstPrime Minister Mori"political crisissurvive crisisadversity DANGERWordNet 1.6resignationremovalstrikevotevote of non-confidence =DANGER(Position)continue in existenceQuestion: Will Prime Minister Mori survive the political crisis ?DANGER ( Prime Minister Mori continues in Position)Figure 9: Intentional Structure derived from Lexico-Semantic Knowledge.bases and/or database access mechanisms.
The researchproposed in this project focuses on the derivation and us-age of pragmatic knowledge that supports the recognitionof question implications, also known as implicatures (cf.
(Grice, 1975b)).5.1 Intentional structures Derived fromLexico-Semantic KnowledgeThe novel idea of this research is to link computa-tional implicatures, similar to those defined by Grice(Grice, 1975b), to inferences that can be drawn fromgeneral lexico-semantic knowledge bases such as Word-Net of FrameNet.
Incipient work was described in(Sanda Harabagiu and Yukawa, 1996), where a methodof using lexico-semantic path for recognizing textual im-plicatures was presented.
To our knowledge, this is theonly computational model of implicatures that was de-veloped and tested on a large lexico-semantic knowledgebase (e.g.
WordNet), enabling successful recognition ofimplicatures.The model proposed in (Sanda Harabagiu and Yukawa,1996) uncovered a relationship between (a) the coherenceof a text segment; (b) its cohesion expressed by the lexicalpaths and (c) the implicatures that can be drawn, mostlyto account for pragmatic knowledge.
This relationshipcan be extended across documents and across topics, tolearn patterns of textual and Q&A implicatures and themethods of deriving knowledge that enables their recog-nition.The derivation of pragmatic knowledge combines in-formation from three different sources:(1) lexical knowledge bases (e.g.
WordNet),(2) expert knowledge bases that can be rapidly formattedfor many domains (e.g.
Japanese political knowledge);and(3) knowledge supported from the textual informationavailable from documents.
The methodology of combin-ing these three sources of information is novel.For question QI , the starting point is the concept iden-tified as a cue for the expected answer type through meth-ods described in (Harabagiu et al, 2000).
This con-cept is lexicalized by the verb-object pair survive-crisis.Verb survive has four distinct senses in the WordNet 1.6database, whereas noun crisis has two senses.
The poly-semy of the expected answer type increases the difficultyof the derivation of pragmatic knowledge, but it does notpresupposes the word sense disambiguation of the ex-pression.
The information available in the glosses defin-ing the WordNet synsets provides helpful information forexpanding the multi-word term defining the expected an-swer type.
By measuring the similarity between the twosenses of the noun crisis and the words encountered asobjects or prepositional attachments in the glosses of thevarious senses of the verb survive, we distinguish thenoun adversity and the example cancer as expressing theclosest semantic orientation to the first sense of noun cri-sis.
The similarity is measured by counting the numberof common hypernyms and gloss concepts of hypernymsof two synsets.
Figure 9 illustrates the concepts relatedto the question QI , as derived from WordNet lexico-semantic knowledge base.The fact that surviving a political crisis has a dangerouscomponent, indicated by the noun adversity, may also besupported by inferences drawn from an expert knowledgebase, showing that a political crisis may be dangerous forpolitical figures in power.
However, at this point, the ob-ject of the dangerous situation is not specified.
But sev-eral concepts indicating dangerous political situations canbe inferred from the expert knowledge base and used inthe query for text evidence.
Only when text passages in-volving Prime Minister Mori are retrieved, clarificationsof the situation are brought to attention: a vote of non-confidence against the prime minister is considered.
Thisnew information helps inference from the expert knowl-edge base.
The expert knowledge base modeling theIntentional Structure of Questions0* Evidence (     1-possess      (          2-Iraq,      3-biological weapons   ))4* Means of finding (0)a. reportsb.
inspectionsc.
assessments ?
patterns of inspections5* Source (0)a. authorityb.
reliability ?
may, would6* Consequence (0)a. Enablementb.
Hiding/Presenting finding evidenceQuestion: Does Iraq   have biological weapons  ?x                           y: have( Iraq, biological weapons )Predicate-ArgumentStructureQuestionpatternDoes x have y ?possess (x, y)Topic (3)biological  weaponsa.
Types of topicb.
Components- chemical agents- mustard gas, VX, sarinc.
Usage- rockets, artillery shellsa.
discover(1,2,3)b. stockpile(2,3)c. use(2,3)d. 1-possessa.
develop(2,3)b. acquire(2,3)a. inspections( _,2,3)b. ban( _,2,3)Source/      fact/          reliabilityreporter     evidence5.a              0              5.bcoercionStructureFigure 10: Intentional structure derived from predicate-argument structures.Japanese factional politics confirms that this is a danger-ous situation for the Prime Minister and that in fact hisposition is in jeopardy.
Due to this inference from theexpert knowledge base, the concept POSITION replacesnoun existence from the gloss of the second sense of verbsurvive, and the pragmatic knowledge required for the in-terpretation of the implicature is assembled:The interactions between the three information sourcesderives the pragmatic knowledge on which relies the im-plication of the question.
The user had an inherent beliefthat Prime Minister Mori might be replaced, and (s)hequeries the Q&A system not only to find information butalso to find support for his/her belief.
The intentionalstructure is represented as a set of concepts and the re-lations that span them, as illustrated in Figure 9.5.2 Coercion of IntentionsA second method of deriving the intentional structure of aquestion is based on the predicate-argument structure thatis derived from the question and the candidate answers.Figure 10 illustrates the Intentional Structure of onesuch question.
The structure of the intentions is deter-mined by the predicate-argument structure of the ques-tion and by its pattern.
Generally, when asking whetherX posses Y, we want to find (1) evidence of this fact;(2) we explore different means of finding the informa-tion; (3) we are interested in the source of informationand (4) the enablers or inhibitors of finding the informa-tion as well as the consequences of knowing it are of in-terest.
We assign a different index to each object fromthe predicate-argument structure, and do the same foreach element of the intentional structure.
For instance,in Figure 2, source(0) is interpreted as source(index=0)= source(evidence).
Another feature of the intentionalstructure is determined by the coercions that are associ-ated with both forms of indexed objects.
For example,the coercion of evidence shows the most typical waysof finding evidence in the context of the topic of thequestion.
Figure 2 lists such possibilities as (a) discov-ering, (b) stockpiling, (c) using and even (d) possess-ing.
These possibilities are inserted in the context of thetopic, since they make use of the indexes for associat-ing meaning to their representations.
In fact, option (a)discover(1,2,3) reads as discover(index=1, index=2, in-dex=3) =discover(possesses(Iraq, biological weapons)).Whereas option (b) stockpile(2,3) can be similarly inter-preted as stockpile(Iraq, biological weapons).
Note thatone of the indexed objects is the topic.
The structure ofthe topic is define along three semantic dimensions: (1)hyponyms or examples of other types of the same cate-gory as the topic; (2) the meronyms or components; and(3) the functionality or the usage.
The derivation of sucha large set of intentional structures helped us learn howto coerce pragmatic knowledge.
We have developed aprobabilistic approach extending the metonymy work of(Lapata and Lascarides, 2003).Lapata and Lascarides report a model of interpretationof verbal metonymy as the point distribution P (e, o, v) ofthree variables: the metonymy verb v, its object, and thesought after interpretation i.
For example a verb ?
ob-ject relation that needs to be metonymycally interpreted,is enjoy ?
movie.
In this case v = enjoy, o = movieand i ?
{making, watching, directing}.
The variablesof the distribution re ordered as <i, v, o> to help factor-ing P (i, v, o) = P (i) ?
P (v|i) ?
P (o|i, v).
Each of theprobabilities P (i), P (v|i) and P (o|i, v) can be estimatedusing maximum likelihood.
As it is illustrated in Fig-ure 10, we have extended this model to account for: (1)coercion of topic information; (2) coercion of evidenceof a fact; (3) interpretation of predicate and (4) inter-pretation of arguments.
Since the verb ?
object rela-tion translates in one of the predicate-argument relations,we have coerced the predicate interpretations in the sameway as (Lapata and Lascarides, 2003), but we allowedfor any predicate-argument relation.
Argument coercionswere produced by searching the most likely predicatesthat used the same arguments.
The topic model also in-corporated topic signatures, similar to these reported in(E.H. Hovy and Ravichandran, 2002).6 ConclusionsIn this paper we have described the problem of interpret-ing the question intentions and proposed two methods ofgenerating the intentional structure of questions.
The firstmethod is based on lexico-semantic chains between con-cepts that are related to the question.
The second methodgenerates intentional structures by using the predicate-argument structures of questions and the topic represen-tation of questions.
To derive both forms of intentionalstructures, we have relied on information available fromWordNet and on the parsing of questions and answersin predicate-argument structures.
Our experiments showthat the intentional structure may determine a different in-terpretation of the question, and thus different keywordscan be used to retrieve the answers.
Answer extractionalso depends on the semantic relations between the co-erced interpretations of predicates and arguments.
Byselecting a set of 100 questions for test, we have eval-uated the correctness of the extracted answers when (1)no intentional knowledge was coerced; (2) implicatureswere derived from lexico-semantic knowledge and (3)intentional structures were derived based on predicate-argument structures.
An increase of 8structures and oneof 22the impact of each element of the intentional struc-ture on the Q/A processing.ReferencesJohn Chen and Owen Rambow.
2003.
Use of deep lin-guistic features for the recognition and labeling of se-mantic arguments.
In Proceedings of the 2003 Confer-ence on Empirical Methods in Natural Language Pro-cessing.Abdessamad Echihabi and Daniel Marcu.
2003.
Anoisy-channel approach to question answering.
In Pro-ceedings of the 41st Annual Meeting of the ACL, Sap-poro, Japan.Chin-Yew Lin E.H. Hovy, U. Hermjakob and DeepakRavichandran.
2002.
Using knowledge to facilitatepinpointing of factoid answers.
In Proceedings of the19th International Conference on Computational Lin-guistics (COLING 2002).Daniel Gildea and Julia Hockenmaier.
2003.
Identifyingsemantic roles using combinatory categorial grammar.In Proceedings of the 2003 Conference on EmpiricalMethods in Natural Language Processing.Daniel Gildea and Daniel Jurafsky.
2002.
Automatic la-beling of semantic roles.
Computational Linguistic,28(3):254?288.Daniel Gildea and Martha Palmer.
2002.
The neces-sity of parsing for predicate argument recognition.
InProceedings of the 40th Annual Conference of theAssociation for Computational Linguistics (ACL-02),Philadelphia, PA.King-Shy Goh, Edward Chang, and Kwang-Ting Cheng.2001.
SVM binary classifier ensembles for image clas-sification.
In Proceedings of the tenth internationalconference on Information and knowledge manage-ment, pages 395?402.Paul H. Grice.
1975a.
Logic and conversation.
In P. Coleand New York J.L.
Morgan (ed.
), Academic Press, edi-tors, Syntax and Sematics Vol.3:Speech Acts, pages 41?58.Paul J. Grice.
1975b.
Syntax and Semantics Vol.3:SpeechActs.
P. Cole and J. Morgan, editors.Kadri Hacioglu, Sameer Pradhan, Wayne Ward, Jim Mar-tin, and Dan Jurafsky.
2003.
Shallow semantic parsingusing support vector machines.
Technical report.Sanda Harabagiu, Marius Pas?ca, and Steven Maiorano.2000.
Experiments with open-domain textual questionanswering.
In Proceedings of the 18th InternationalConference on Computational Linguistics (COLING-2000), pages 292?298, Saarbrucken, Germany,.Sanda M. Harabagiu, Dan I. Moldovan, Marius Pasca,Rada Mihalcea, Mihai Surdeanu, Razvan C. Bunescu,Roxana Girju, Vasile Rus, and Paul Morarescu.
2001.The role of lexico-semantic feedback in open-domaintextual question-answering.
In Meeting of the ACL,pages 274?281.S.
Harabagiu, D. Moldovan, C. Clark, M. Bodwen,J.
Williams, and J. Bensley.
2003.
Answer mining bycombining extraction techniques with abductive rea-soning.
In Notebook of the Twelveth Text REtrievalConverence (TREC-2003), pages 46?53.A.
Ittycheriah, M. Franz, W. Zhu, and A. Ratnaparkhi.2000.
IBM?s statistical question answering system.In Proceedings of the 9th Text REtrieval Conference,Gaithersburg, MD.T.
Joachims.
1999.
T. Joachims, Making large-ScaleSVM Learning Practical.
In B. Scho?lkopf and C.Burges and A. Smola (ed.
), MIT-Press., editor, Ad-vances in Kernel Methods - Support Vector Learning.Maria Lapata and Alex Lascarides.
2003.
A probabilisticaccount of logical metonymy.
Computational Linguis-tics, 29:2:263?317.Wendy Lehnert.
1978.
The process of question answer-ing.
In Lawrence Erlbaum Assoc., Hillsdale.Sameer Pradhan, Kadri Hacioglu, Wayne Ward, James H.Martin, and Daniel Jurafsky.
2003.
Semantic roleparsing: Adding semantic structure to unstructuredtext.
In Proceedings of the International Conferenceon Data Mining (ICDM-2003).Dan Moldovan Sanda Harabagiu and Takashi Yukawa.1996.
Testing gricean constraints on a wordnet-basedcoherence evaluation system.
In Working Notes of theAAAI-96 Spring Symposium on Computational Impli-cature, Stanford, CA.Mihai Surdeanu, Sanda Harabagiu, John Williams, andPaul Aarseth.
2003.
Using predicate-argument struc-tures for information extraction.
In Proceedings of the41th Annual Conference of the Association for Compu-tational Linguistics (ACL-03), pages 8?15.V.
Vapnik.
1995.
The Nature of Statistical Learning The-ory.
Springer.
