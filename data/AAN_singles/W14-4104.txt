Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 21?31,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsTowards Identifying the Resolvability of Threads in MOOCsDiyi Yang, Miaomiao Wen, Carolyn RoseLanguage Technologies Institute, Carnegie Mellon University5000 Forbes Ave, Pittsburgh, 15213{diyiy,mwen,cprose}@cs.cmu.eduAbstractOne important function of the discussionforums of Massive Open Online Courses(MOOCs) is for students to post problemsthey are unable to resolve and receive helpfrom their peers and instructors.
There area large proportion of threads that are notresolved to the satisfaction of the studentsfor various reasons.
In this paper, weattack this problem by firstly constructinga conceptual model validated using aStructural Equation Modeling technique,which enables us to understand the factorsthat influence whether a problem threadis satisfactorily resolved.
We then demon-strate the robustness of these findings usinga predictive model that illustrates how ac-curately those factors can be used to predictwhether a thread is resolved or unresolved.Experiments conducted on one MOOCshow that thread resolveability connectsclosely to our proposed five dimensions andthat the predictive ensemble model givesbetter performance over several baselines.1 IntroductionMassive Open Online Courses (MOOCs), run byorganizations such as Coursera, have been amongthe most news worthy social media environmentsin the past year.
While usage of social mediaaffordances such as discussion forums in suchcourses is small relative to usage of videos orassignments, participation in the discussion forumsis an important predictor of commitment to thecourse (Yang et al., 2013).
We hypothesize thatsupporting a positive experience in such forumshas the potential to increase retention in suchcourses.
In this paper, we specifically study thebehavior of students in a MOOC course for learningPython programming.
We present empirical workthat elucidates an important problem in existingMOOC discussion forums, propose a practicalsolution, and offer promising results in a corpusbased evaluation.MOOCs for programming skills can be seen asimportant resources for the professional develop-ment of programmers and programmers in training.While MOOCs for learning programming are arecent phenomenon, they are not the first webaccessible resources for development of such skills.In recent years, a plethora of question/answersites for programming have become available thathave grown into thriving communities of practicefor programmers.
In these online communities,programmers can get mentoring from those whoare more expert than them and offer mentoring toprogrammers who are less expert than them.
Forexample, StackOverflow1has become a forum notonly for getting specific questions answered, but fornegotiating the pros and cons of alternative waysof solving technical problems.
The code proposedas part of alternative solutions remains as part ofthe community memory, which is then accessiblefor those who come later with similar concerns.Where StackOverflow falls short is in providingan appropriate environment for the active involve-ment of very novice programmers.
When suchnovices come to a forum like StackOverflow andpresent their naive questions, they are frequentlymet with sarcastic responses if they get a responseat all.MOOCs for learning programming skills fill agap left open by such environments, in that theywelcome the very novice and provide forums wherenaive questions are not shunned.
Nevertheless,discussion forums that only include such noviceprogrammers would be akin to the blind leading theblind were it not for the involvement of a few moreexpert students and the teaching staff.
This does notfully solve the problem, however.
Many threads are1http://stackoverflow.com/21still left without a satisfactory resolution.
Currently,it is challenging for the teaching staff and expertparticipants to know where in the massive amountof communication to look for opportunities wheretheir support is most needed.
This is the problemwe aim to address in this paper, i.e.
automaticallyidentify whether a thread is resolved and providepotential for better allocation of instructor andstudent resources.In the remainder of the paper we first surveyrelated work.
Next we describe the formulationof the problem.
We then present a series oftwo experiments, the later one building on thesuccessful findings and results from the former.The results conducted on one MOOC show thatour proposed model of thread resolveability bettercaptures the difference between resolved andunresolved threads and that the ensemble logisticmodel outperforms several baselines.
We concludethe paper with a discussion of the limitations ofthis work and next steps.2 Related WorkMOOCs have received more and more attentionrecently, with the promise of providing many of thebenefits of traditional classroom learning but notlimited by time, location or finances.
Much priorwork has focused on analysis of such platformsto motivate the design of better student learningexperiences.
In various ways, the issue of studentsneeding support from instructors and students hasbeen addressed (Lieberman, 1995).An important component in the Coursera envi-ronment is the discussion forums, which studentscan use to learn new knowledge from each otherand from the teaching staff when they participate.In support of the importance of the discussionforums in connection with major problems likeattrition, models are proposed to predict studentdropout based both on their video watching be-havior and also discussion forum posting behavior,such as how many posts a student has made (Balakr-ishnan, 2013).
Student behavior in the discussionforum is also focused by other prior works (Yanget al., 2013).
Yang et al.
analyze drop out along theway, demonstrating the predictive power of featuresextracted within time windows of student behaviorwithin the forums.
The results of their work suggestthat interaction with other students is importantfor keeping students motivated, which is furtherconfirmed by many works (Yang et al., 2014; Ros?eet al., 2014).
Besides, linguistic reflections are alsocrucial for students engagement (Wen et al., 2014).Other work highlights the importance of interac-tion in the form of feedback during participation inMOOCs.
For example, some prior work (Piech etal., 2013) has explored peer grading, especiallyin helping grading of open ended assignments,in courses with thousands or tens of thousandsof students.
Other work takes a more holisticapproach to assessment of student behavior.
Forexample, in one such example (Kizilcec et al.,2013), instead of looking at students?
assignments,students were classified based on their patternsof interaction with video lectures and assessmentactivities.
This behavior trace was processed usinga simple and scalable classification method thatcould identify a small number of longitudinalengagement trajectories that potentially providethe impetus for tailored feedback or mentoring.Outside of MOOC discussion forums, there hasalso been work investigating the conditions underwhich questions receive appropriate feedback inmore general Question Answering (QA) sites.
Inparticular, this work has been framed as researchon thread resolveability in QA sites.
It canbe conceived as the human counterpart to fullyautomated question answering systems (Prager etal., 2000; Perera, 2012; Jeon et al., 2006; Agichteinet al., 2008).
Much of this work has emphasized theimportance of having effective features to modelquestion and answer processes.In some of this prior work, the focus has beenon identifying whether a thread is answered givena question and a set of potential answers (Sunget al., 2013; Tian et al., 2013).
The priorwork (Anderson et al., 2012) has focused onunderstanding the dynamics of the surroundingcommunity activity, like the process through whichanswers and voters arrive over time.
Based onunderstanding of such factors, a prediction can bemade about the long term value for the communityof a question being answered.
Similarly, Agichteinand colleagues (Agichtein et al., 2009) presenteda general prediction model of information seekersatisfaction in community question answering,and developed content, structure and communityfocused features for the question answering task.
Acollection of other related work (Liu and Agichtein,2008) has developed personalized models of askersatisfaction to predict whether a particular questionstarter will be satisfied with the answers given22by others.
This is solved by exploring content,structure and interaction features using standardprediction models.Work on automated question answering systemscan also be seen as relevant since questions that canbe answered automatically do not need a humanresponse, and therefore might reduce the loadon available human effort.
Instead of predictingwhether a problem is answered, strategies forpredicting are explored when a question answeringsystem is likely to give an incorrect answer (Brillet al., 2002).
To further understand how a questionis answered, researchers (Yih et al., 2013) havestudied the answer sentence selection problemfor question answering and improves the modelperformance by using lexical semantic resources.That is, they construct semantic matches betweenquestion and answers.
In terms of the extentto which the question is answered, Shah andcolleagues (Shah and Pomerantz, 2010) evaluatedanswer quality by manually rating the qualityof each answer.
Then they extracted variousfeatures to train classifiers to select the best answerfor that question.
Liu et al.
(Liu et al., 2011)proposed to use a mutual reinforcement basedpropagation algorithm to predict question qualitybased.
The model makes its prediction based onthe connection between askers and topics, and howthose connections predict differences in quality.The above question answering work is allabout general discussion forums (Qu et al., 2009;Kabutoya et al., 2010), such as Yahoo!
Answers2.In our work, in addition to taking advantage ofexisting QA work, we also adopt a linguisticperspective (Jansen et al., 2014) and take semanticmatching into account using a latent semanticapproach.
To the best of our knowledge, this isthe first work on thread resolvability analysis in aMOOC context.3 Research Problem IntroductionIn this section, we focus on how to identify theresolveability of threads in the MOOC forums.
Wefirstly introduce the research context and dataset,then we formulate our resolveability problem.3.1 Research Context and DatasetIn programming MOOCs, when students encounterproblems working on the programming assign-ments, or when something is not clear from the2http://answers.yahoo.com/readings or lectures, students have the opportunityto initiate a thread in the course forum, in orderto engage other students in the class as well asthe teaching staff.
For example, if a studentwere confused about the distinction between anargument and a parameter in Python, he/shewould post the question to the variables subforum,marking it unresolved at the same time.
In theideal case, another participant would reply tothis question with some detailed explanation andexample, which would solve that problem.
Whenthe student who initiated the thread receives theresponse, assuming it is adequate, that studentmay mark it as resolved.
Others may join in aswell, and individual posts may be rated throughupvotes and downvotes.
In contrast to existing QAsites, no best answer option is available.
Thus,the resolved/unresolved button provides the closestequivalent groundtruth.The data for this paper was crawled from aPython language course.
Our focus was specificallyto investigate the inner workings of threads relatedto getting answers to questions or help withprogramming difficulty.
In order to avoid includingthreads in our dataset that are off-topic or otherwiseirrelevant, we limited the set of forums to thesubforums that focus strongly on course content,including those indicated to focus on lectures,exercises and assignments as well as the final exam.That is, we discarded posts in the study groups,social discussion, and other discussion areas thatdo not have unresolved buttons.
In the final dataset,there were 2508 threads (1244 resolved threads) intotal, and 2896 users (12 instructors and staffs) whohad at least one post.
Each question is associatedwith a label indicating whether it is resolved or not.3.2 Problem FormulationWork on the related problem of analysis of QAwebsites has grown in popularity in recent years.However, due to differences in how MOOCs workas temporary online communities, it is necessary toconsider how findings from prior work in theseareas may or may not generalize to this newcontext as we formulate our research problem.
Inparticular, MOOCs are different from existing QAwebsites, such as Yahoo!
Q&A, Stack Overflow.The purpose of QA sites is primarily for peopleto get answers.
While people may learn fromtheir interactions on such sites, those sites are notdesigned in particular to support learning.
Thus,230200400600800100012001400CntNumberPost NumberStandby Less Active Active Super Star(a) Question Post02004006008001000120014000 3 6 912151821242731 34 39 4452 6273 88961272131001CntNumberReply NumberStandby Less Active Active Super Star(b) Reply Devotee02004006008001000120014000 1 2 3 4 5 6 7 10 12 28 226CntNumberResolved NumberStandby Less Active Active Super Star(c) Resolved Favor02004006008001000120014000 3 6 912151821242937 404453 79118130212798CntNumberUpVotesStandby Less Active Active Super Star(d) UpVotesFigure 1: Starter Influence Statistics.
Each Figure has two curves; the below one indicates how manyusers have made the associated number of posts/reply.
The above one is the cumulative version of thesame.different characteristics are needed in the MOOCsdiscussion threads.
One implication is that thediscussions in MOOCs may need to be moreinteractive than those found in environments suchas StackOverflow.
Students who post problemscan be expected to be less capable of fullycomprehending an answer even if it is a goodone.
This demands more effort from those with theability to offer helpful responses.
In order for thediscussions to be effective, the threads must includea balance of naive participants and participants withmore knowledge.
A related issue is that it is not yetubiquitous for participants in MOOCs to have theopportunity to earn a reputation score for offeringuseful answers and other instructional support.
Inother QA sites, this is both a valuable motivator aswell as an important predictor of resolved versusunresolved question threads (Anderson et al., 2012).Thus, students who post questions may need tosell their problem in order to attract those whocan offer help.
Taking these interrelated issuesinto account, an important aspect of our modelingwork is in recognizing the different roles thatusers play in the community.
Related to this, wewill describe below how we develop models thatinclude latent variables related to the propensityof users to initiate problem threads that attractuseful responses, and the propensity of others tocontribute useful responses in such contexts.
Werefer to these complementary variables as starterinfluence and expert participation respectively.Secondly, all are welcome to learn in a MOOCand participate actively even if they have noprior knowledge.
In an educational context, itwould not be appropriate to meet a naive questionwith a sarcastic response.
In contrast, in StackOverflow, it would be treated as unremarkable fora naive question to get a sarcastic response.
Whilenaive participants may not enjoy such responses,they learn to expect them.
Since approachingposted problems with patience and friendliness isimportant for avoiding discouraging new learners,we include a variable called friendliness thatrepresents friendly and polite discussion behavior.None of these would ultimately result in threadresolution if the answers that are offered were nottargeted to the problems raised by the studentswho initiated the threads.
This is one place whereour work is very aligned with earlier work on QAsites.
And thus we adopt a similar practice wherewe include in our model an estimate of answerappropriateness in a latent variable we refer to ascontent matching.Now we define important terms used in ourdiscussion.
First, we define roles within discussionthreads that are relevant for our work.
For agiven thread, the user who initialized the threadis called the Starter; the teaching staff includingboth official course instructors and TAs are referredto as Instructors; and any other users whohave replied or commented in the thread arereferred to as Participants.
We count a threadin our dataset as resolved only if the threadstarter personally changes the Unresolved button toResolved.
Otherwise, we count the as unresolved.We are interested in the conditions under whicha thread is marked as resolved or unresolved:Thread Resolveability: Given a thread withits associated question and set of replies, whichmay not have been explicitly marked as resolved,identify whether it should have been marked asresolved or not.4 Latent Variable ModelingWe laid the foundation for a conceptual modelabove to understand the factors associated withresolved versus unresolved threads and introducedfive latent factors we referred to as Starter Influence,Expert Participation, Thread Popularity, Friendli-ness, and Content Matching.
In this section, we24further formalize these latent factors by specifyingassociated sets of observed variables that willultimately enable us to evaluate our conceptualmodel.
All latent and observed variables areenumerated in Table 1.4.1 Starter InfluenceThe person who serves as the Thread starteris responsible for formulating the question thatis addressed, and therefore the focus of thatdiscussion.
Some participants post many questionsand are very adept at formulating their questions inways that engage the attention of people who havethe ability to provide answers.
If the starter posts alot and his/her questions often get resolved, this canbe taken as an indication that this person is popular.Questions contributed by him/her may be morelikely to attract attention and receive replies.
Thissimple indication of popularity, which can be easilycomputed, may in some way compensate for thelack of an established badge system where they arenot in use.
We propose to measure this form of userinfluence by using the following four indicators.
(1) Question Devotee xPst, indicates how manythreads this question starter has proposed in thisforum.
Based on Figure 1(a), we divide users inthis discussion forum into four types to indicate thepropensity to post, i.e.
post number ranges from1-2 as standbys, 3-5 as less active, 6-14 as active,40-489 as superstars.
Similar partition method isadopted for all the following indicators.
(2) ReplyDevotee xRep, means how many times a person actsas a Participant in a thread posted by other studentsas shown in Figure 1(b).
If he/she usually repliesto others, then it is possible that his/her questionwill be paid more attention in return.
(3) ResolvedFavor xRes, means in how many threads the personacts as the Starter in threads that get resolved.
(4)Praised Responder xUvt, indicates the proportionof all the posts this starter makes in the forum thatreceived upvotes, as displayed in Figure 1(d).
Thisconnects to how others recognize this starter and towhat degree.4.2 Expert ParticipationWho participates a discussion is as important aswho initiates the discussion.
Students with someexpertise in the related content can often providequality replies (Anderson et al., 2012).
Since userreputation score information is not available inthis MOOC, it is necessary to for us to identifyobservable indicators.
We define a person as ExpertxExpin our forum as follows.
A person is anExpert if and only if he/she is one of the instructorsor his/her reputation score as we compute it isranked in the top 1% among all students.
Thereputation score of student u is computed basedon his/her question devotee uPst, reply devoteeuRep, resolved favor uRes, and praised recognitionuUvtas we defined in the previous section.
Thecontribution of each factor to reputation score iscontrolled using parameters ?, ?, ?.score(u) =?uPst+ ?uRep+ ?uRes+ (1?
??
?
?
?
)uUvt(1)4.3 Thread PopularityHow much attention is paid to a question may belinked to the attractiveness of the thread basedon how it is presented to the community.
Thusmodeling thread popularity may be valuable foraccounting for variation in level of participationacross threads.
In particular, a reply is givenupvotes when others think it is informative orgood.
Thus upvotes could indicate how othersevaluate the replies in connection with the question.We design three observable factors here thatmay contribute to a model of thread popularity.The Total UpVotes xTvtand Max UpVotes xMvtare used to represent the credit this thread hasreceived and how others recognize the currentdiscussion.
Based on our analysis, people rarelygive a downvote to others?
posts.
The QuestionVotes xSvtindicates whether the starter formulatesa problem that wins recognition from others.
ForTotal Upvotes, we find that in resolved threads, it is6.10 compared to 3.15 in unresolved thread.
Thus,intuitively, thread popularity has the potential togive a useful prediction of thread resolveability.4.4 FriendlinessFriendliness (Danescu-Niculescu-Mizil et al.,2013; Burke and Kraut, 2008) concerns whetherthe current conversation is conducive for othersto discuss ideas.
This has not been consideredin existing question answering work, and wethus discuss our operationalization of politenesshere.
We hypothesize that resolved threads possesmore polite words, such as ?thank?.
For example,a resolved thread might end with gratitude tothank others for providing help, and indeed wesee this.
Thus, we specify a set of observedindicators that may be useful in a latent variablemodel of politeness.
(1) Start with Thanks: xStx,25Var T Description Var T Description Var T DescriptionPae N Please Count Qa1 N 1st Match Score Svt N Question VotesThx N Thanks Count Qa2 N 2nd Match Score Mvt N Max VotesDfe N Deference Qa3 N 3rd Match Score Uvt N User VotesEtx B End with Thx Len N Max Length Rep N Reply NumberStx B Start with Thx Sim N Similarity Res N Resolved CountExp B Expert Join Tvt N Total Votes Pst N Post NumberSin - Starter Influence Epr - Expert Participation Con - Content MatchingPop - Thread Popularity Fen - Friendliness Label B Resolved or notTable 1: Variables used in the Structural Equation Model (SEM).
Var is the factor variable that is used,which also corresponds to Figure 2.
T indicates what type of values a variable can take.
B is short forBinary.
N is short for Numeric.
?-?
means it is a latent unobserved variable.indicates whether this starter shows politenesswhen he/she posted the question.
(2) End withThanks: xEth, stands for whether the starter saysthanks after receiving others?
help.
(3) ThanksCount: xThx, measures overall friendliness in thecurrent discussion.
We evaluate this by countingthe thanking related words.
(4) Deference: xDfe, isa count of positive polite words occurring in the dis-cussion, such as using the words ?Nice?,?Great?, or?Awesome?, as in prior work (Danescu-Niculescu-Mizil et al., 2013).
Such words are used as markersto conduct counting.
(5) Please: xPae, captureswhether friendly question asking words were used,i.e.
how many times words such as ?Please?, ?Will?,occur in current conversation.4.5 Content MatchingMatches between the content of a thread and itsreplies indicate whether replies are relevant toanswering the question instead of some off-topicdiscussion.
In order to estimate this, we buildan Eigenword bipartite graph to capture semanticsimilarities.
Each node in the bipartite graph is thecorresponding Eigenword3of a given word, withthe left side representing the words that occurredin the thread starter, and the right side representingthe words in a given reply.
The edge is a similarityscore computed by using the cosine similaritymetric.
In order to better identify whether a reply isdiscussing the content of the question, a semanticmatch between the thread question and its replies isneeded.
The top 3 matching scores are denoted asxQa1, xQa2, xQa3.
Additionally, TF-IDF similarityxSimis computed (the correlation between xSimand Qa1, Qa2, Qa3 are 0.3280, 0.3572, 0.3569separately) and the maximum answer length xLen3http://www.cis.upenn.edu/ ungar/eigenwords/is used to assist in computing the matching score.5 Experimental InvestigationIn the above section, we described five latent fac-tors we hypothesize are important in distinguishingresolved and unresolved threads along with setsof associated observed variables.
In this section,we conduct two studies on thread resolveability,including validating the influence of each latentfactor on thread resolution using a Structural Equa-tion Model (SEM), and evaluating the generalityof the identification of the resolveability using apredictive model.
Experiments are conducted onthe Python dataset with performance measurementunder different evaluation metrics.5.1 Conceptual SEM ValidationOur conceptual model is implemented as a Struc-tural Equation Model (SEM) and is introduced asan evaluations of the effect of each latent factor onthread resolveability, as shown in Figure 2.5.1.1 Conceptual SEM ModelA Structural Equation Model (Bollen, 1987), isa statistical technique for testing and estimatingcorrelational (and sometimes causal) relations incross sectional datasets.
To explore the influence ofour five latent factors, we take advantage of SEMto formalize the conceptual structure in order tomeasure what contributes to thread resolveability.The designed latent factors are specified as latentvariables within the model, with the associatedobserved variables discussed above.
We define theconceptual structure of how a thread gets resolvedas well as a mathematical expression of each latentvariable in Equation 2.Related variables are explained above and26Figure 2: SEM Model Factor Analysis Result.
Each directed edge indicates the predictive relationship.
Weight on eachdirected edge is the estimated influence strength of one node to another.
Table 1 illustrates the denotation.
Only significant nodeinfluences whose p-value (p < 0.05) are presented.
Circles stand for latent variables while rectangles signify observed variable.summarized in Table 1.
Label refers to thelabel of a unknown thread, taking the value ofResolved or Unresolved.
Label (L) is a linearcombination of each latent factor set.
For eachvariable in a latent factor set, it is associated with aweight parameter ?
in the SEM.
Specifically, thisconceptual structure of how a thread gets resolvedrelates to five aspects, i.e.
(1) whether the threadstarter has enough influence on others, (2) whetherthe relevant experts participated at least once inthe discussion, (3) whether the thread polite andconducive to encouraging others to be willing toprovide help, (4) whether the thread is popular,and (5) whether replies aim at answering questionsinstead of off topic discussion.Con = ?ci3?i=1xQai+ ?c4xSim+ ?c5xLenFen = ?p1xStx+ ?p2xEtx+ ?p3xThx+ ?p4xDfe+ ?p5xPaeSin = ?u1xRep+ ?u2xPst+ ?u3xRes+ ?u4xUvtPop = ?t1xCmt+ ?t2xTvt+ ?t3xMvt+ ?t4xSvtEpr = ?a0xExpLabel = ?1Con+ ?2Fen+ ?3Sin+ ?4Pop+ ?5Epr(2)5.1.2 SEM Result AnalysisIn this section, we discuss what we learn from theSEM about the influence of each factor within themodel.
We adopt the Structural Equation Model inR (Rosseel, 2012) to conduct the validation, andevaluate it by looking at the Comparative Fit Index(CFI), Root Mean Square Error of Approximation(RMSEA) and Standardized Root Mean SquareResidual (SRMR) (Barrett, 2007).
Figure 2 showsthe influence of each observed variable on itscorresponding latent variable, and in turn the latentvariable on the resolved label.
The weights oneach directed edge represent the standard estimatedparameter for measuring the influence.
For themodel fitting, we get a RMSEA of 0.09 and SRMRof 0.06, with a CFI of 0.89.
The fit is not extremelyhigh, but it is moderate, and it is within the rangeone would expect from a good fitting model whena large set of variables is considered.Based on Figure 2, firstly, starter influenceand expert participation contribute a lot to threadresolveability, with a standard estimated parameterof 0.619 and 0.587.
This makes sense that whoposts the question and who gives replies mattera lot in identifying whether a thread is resolved.Next, content matching contributes 0.178 to theresolving of a thread, which means matchingbetween question and replies does differentiatebetween resolved and unresolved threads, but lessso than who participates, perhaps because theobserved variables are very shallow indicatorsof relevance.
Friendliness is not very stronglypredictive of resolvability.
Similarly, Threadpopularity contributes only 0.051 to the prediction,without significant influence compared to the otherfour latent variables, which are all significant.Thus we conclude that starter influence, expertparticipation, and content matching are strongfactors while friendliness and thread popularitycould help us separate resolved and unresolved27threads, but less so than the other two.5.2 Resolveability PredictionThe influences of five latent factors on threadresolveability are demonstrated as above.
In thispart, we build an ensemble logistic regressionmodel to leverage those findings to predict whethera given thread is resolved or not.5.2.1 Ensemble Regression ModelAn ensemble logistic regression model is proposedto deal with the prediction of whether a threadis resolved or not.
That is, given the questionand a set of potential replies, as well as the fivelatent variables and associated observed variables,we want to predict whether a question has beenanswered.
Our ensemble logistic model worksin the following way.
Firstly we train a separatelogistic model for each of the five aspects definedabove, i.e.
five sub logistic model of how eachaspect predicts the resolved property.
Then thosesub-models are included together in an ensemblein order to contribute to a final logistic model,which takes those results as the input features.Similar to generalized boosting (Friedman et al.,1998), this regression model integrates five weakpredictors that capture five different aspects ofthread resolveability, and construct a two layerlogistic ensemble, which is distinct from a linearvoting strategy.
Our ensemble model relaxesthe assumption of linearity and thus offers moreflexibility in finding an effective predictive model.This process is formalized below.
?Rj=11 + e??ki=1?i?
?Rij(3)Here, k refers to the number of latent aspects.
?Rjis the predicted resolved score for thread j; if itis larger than a threshold, the prediction of thatthread question is resolved, otherwise it remainsunresolved.
?Rijis the predicted resolved scoreof latent factor set i on thread j, trained on thecorresponding latent factor set.5.2.2 Prediction ResultsTo demonstrate the predictive abilities of the fivelatent factors, we use our ensemble regressionmodel to predict thread resolution.
10-fold crossvalidation is used, and the prediction results will beevaluated using the metrics Recall, Precision, andAUC (Area under Curve).
For baselines, we beginwith the simplest model EndThx, which simplySingle Model Precision Recall AUCSi 0.697 0.696 0.791Ep 0.602 0.590 0.572Ct 0.626 0.616 0.647Tp 0.594 0.579 0.626Fr 0.639 0.633 0.685Table 2: Prediction Result of Single Latent FactorModel Precision Recall AUCEndThx 0.629 0.612 0.593Si + Ep 0.803 0.802 0.857Si+Ep+Ct 0.819 0.815 0.884Si+Ep+Ct+Fr 0.823 0.823 0.893ALL-Linear 0.826 0.826 0.894ALL-Ensemble 0.831 0.831 0.896Table 3: Prediction Resultbases the prediction on whether the current threadends up with a gratitude sentence.
This makessense because it is natural that students will expresstheir gratitude after receiving others?
help.
Onesimple baseline is the Majority, which predicts thetesting thread as the majority status (unresolved inour dataset), leading to a accuracy of 0.503; Si+Epis a combination of the latent aspect of starterinfluence and expert participation; and Si+Ep+Ctadds the content matching latent set on Si+Ep;Si+Ep+Ct+Fr is defined similarly.
ALL-Linearis adding all five latent factor sets and predicts theresolved or not using a linear logistic regression.Comparably, ALL-Ensemble is trained using thenonlinear ensemble logistic regression model.
Thecombination results as well as a comparison aresummarized in Table 3.
For the influence of eachsingle latent aspect on the same prediction task, wepresent them correspondingly in Table 2, whereSi, Ep, Ct, Tp, and Fr represent Student Influence,Expert Participation, Content Matching, ThreadPopulratiy, and Friendliness respectively.Looking at the five latent aspects, (1) we con-clude that, starter influence has the most powerfulinfluence on thread resolution.
It improves a loton the Precision metric, and 50.25% on AUCcompared to the EndThx.
It makes sense that,if a user posts a lot, and often helps answer others?questions, it is more likely that his/her question willget a lot attention; (2) Thread Popularity, by itselfworks better than the baseline under the metric ofAUC.
The features in this set are not so directly28connected to thread resolution from a conceptualstandpoint compared to whether a thread ends withthanks.
However, it unexpectedly achieves an AUCof 0.626, which is higher than the baseline.
(3) Forcontent matching, the precision is similar to thatof EndThx, but in contrast, this model achievesa good improvement on AUC.
Content matchingdescribes the similarities between a question anda reply, which is a direct indication of whetherthe reply is trying to answer the question.
(4)Friendliness has a significant predictive ability inconnection with thread resolution.
For the AUC, itoffers about a 13% improvement over the baseline.It is reasonable that a resolved thread tends tobe more polite, which means people use ?please?,?thanks?
more than in other unresolved threads.To build the ensemble models, we combine thelatent factor sets in the order of their strengthof estimated influence on resolveability.
Wefirstly integrate the starter influence and expertparticipation, as we can see, it achieves significantimprovement over the simpler baselines, with 28%higher on Precision, 31% on Recall and 45%on AUC.
It even performs better on the threemetrics than any of the single models in Table2.Si+Ep+Ct also gives a substantial increase onthe metrics and when adding semantic contentmatching, Si+Ep+Ct+Fr is about 3% better thanSi+Ep on precision and recall.
This indicates thatfriendliness and content matching are capturingdifferent aspects of the thread resolveability fromstarter influence and expert participation.
Besides,the ALL-Linear performs best among all one layerregression models.
This shows that even thoughthread popularity contributes least to resolved ornot based on the SEM result, it gives a differentperspective of the thread resolveability and is notto be ignored.
When we applied our proposedensemble regression model ALL-Ensemble usingthe five latent factor sets, we find that it outperformsall one layer logistic regressors, especially in Recalland Precision.
This demonstrates that the two-layer ensemble logistic regression model?s addedrepresentational power is needed for this problem.6 Conclusions and Future ResearchIn this paper, we have focused on improving thethread resolveability in MOOC discussion forums.Our investigation is divided into two separatestudies that leverage a common conceptual modelinvolving five latent factors that are associated withthread resolution.
Our first study validates thefive latent variable structures using a SEM model,which helps us to validate our assumptions andhone in on those factors that are most promisingto leverage in subsequent work.
It enables usto assess the relative strength of each factor?sinfluence on thread resolveability, and providesa foundation for the other study.
The secondstudy?s focus is predicting thread resolution basedon the first phase?s findings.
In addition toserving as a test of generality from trained data tounseen data, the predictive model may also have apractical benefit.
In particular, thread resoveabilityidentification could provide the potential to achievea better allocation of valuable human resources towork on unresolved threads, which increases thepotential for students to get their support needsmet in Massive Open Online Courses.
Our workis contenxtualized in the specifics of MOOCsas an online context including the particulars ofinteraction practices within those contexts.
Thus,in addition to building on existing QA work inour feature engineering, we also introduce newdirections, such as the linguistic modeling ofspeaker politeness, and conduct forms of latentsemantic matching that have proven effective indialogue systems.However, we believe there is a need for furthermodeling in order to fully understand threadresolveability.
A limitation of the current work isthat it was conducted in only one course.
Thus,we will be in a stronger position for movingforward if we explicitly address the question ofgeneralizability across courses with further corpusbased investigation.
Besides, how to transferthe prediction models from forums with resolvedbuttons to ones that have no such affordances,which may be challenging because of differencesin the distribution of behaviors.AcknowledgementThis research was funded in part by NSF grantsIIS-1320064 and OMA-0836012 and funding fromGoogle.ReferencesEugene Agichtein, Carlos Castillo, Debora Donato,Aristides Gionis, and Gilad Mishne.
2008.
Findinghigh-quality content in social media.
In Proceedingsof the 2008 International Conference on Web Searchand Data Mining, WSDM ?08, pages 183?194, NewYork, NY, USA.
ACM.29Eugene Agichtein, Yandong Liu, and Jiang Bian.2009.
Modeling information-seeker satisfaction incommunity question answering.
ACM Trans.
Knowl.Discov.
Data, 3(2):10:1?10:27, April.Ashton Anderson, Daniel Huttenlocher, Jon Kleinberg,and Jure Leskovec.
2012.
Discovering value fromcommunity activity on focused question answeringsites: A case study of stack overflow.
In Pro-ceedings of the 18th ACM SIGKDD InternationalConference on Knowledge Discovery and DataMining, KDD ?12, pages 850?858, New York, NY,USA.
ACM.Girish Balakrishnan.
2013.
Predicting student reten-tion in massive open online courses using hiddenmarkov models.
Master?s thesis, EECS Department,University of California, Berkeley, May.Paul Barrett.
2007.
Structural equation modelling:Adjudging model fit.
Personality and IndividualDifferences, 42(5):815?824.Kenneth A Bollen.
1987.
Total, direct, and indirecteffects in structural equation models.
Sociologicalmethodology, 17(1):37?69.Eric Brill, Susan Dumais, and Michele Banko.
2002.An analysis of the askmsr question-answering sys-tem.
In Proceedings of the ACL-02 Conference onEmpirical Methods in Natural Language Processing- Volume 10, EMNLP ?02, pages 257?264, Strouds-burg, PA, USA.
Association for ComputationalLinguistics.Moira Burke and Robert Kraut.
2008.
Mind yourps and qs: The impact of politeness and rudenessin online communities.
In Proceedings of the2008 ACM Conference on Computer SupportedCooperative Work, CSCW ?08, pages 281?284, NewYork, NY, USA.
ACM.Cristian Danescu-Niculescu-Mizil, Moritz Sudhof,Dan Jurafsky, Jure Leskovec, and Christopher Potts.2013.
A computational approach to politeness withapplication to social factors.
In ACL (1), pages 250?259.Jerome Friedman, Trevor Hastie, and Robert Tibshirani.1998.
Additive logistic regression: a statistical viewof boosting.
Annals of Statistics, 28:2000.Peter Jansen, Mihai Surdeanu, and Peter Clark.
2014.Discourse complements lexical semantics for non-factoid answer reranking.
In Proceedings of the52nd Annual Meeting of the Association for Com-putational Linguistics, ACL ?13=4.
Association forComputational Linguistics.Jiwoon Jeon, W. Bruce Croft, Joon Ho Lee, andSoyeon Park.
2006.
A framework to predict thequality of answers with non-textual features.
InProceedings of the 29th Annual International ACMSIGIR Conference on Research and Development inInformation Retrieval, SIGIR ?06, pages 228?235,New York, NY, USA.
ACM.Yutaka Kabutoya, Tomoharu Iwata, Hisako Shiohara,and Ko Fujimura.
2010.
Effective question recom-mendation based on multiple features for questionanswering communities.
In ICWSM.Ren?e F Kizilcec, Chris Piech, and Emily Schneider.2013.
Deconstructing disengagement: analyzinglearner subpopulations in massive open online cours-es.
In Proceedings of the Third InternationalConference on Learning Analytics and Knowledge,pages 170?179.
ACM.Ann Lieberman.
1995.
Practices that supportteacher development: Transforming conceptions ofprofessional learning.
Innovating and EvaluatingScience Education: NSF Evaluation Forums, 1992-94, page 67.Yandong Liu and Eugene Agichtein.
2008.
You?vegot answers: Towards personalized models for pre-dicting success in community question answering.In Proceedings of the 46th Annual Meeting ofthe Association for Computational Linguistics onHuman Language Technologies: Short Papers, HLT-Short ?08, pages 97?100, Stroudsburg, PA, USA.Association for Computational Linguistics.Qiaoling Liu, Eugene Agichtein, Gideon Dror, EvgeniyGabrilovich, Yoelle Maarek, Dan Pelleg, and IdanSzpektor.
2011.
Predicting web searcher satisfac-tion with existing community-based answers.
InProceedings of the 34th International ACM SIGIRConference on Research and Development in Infor-mation Retrieval, SIGIR ?11, pages 415?424, NewYork, NY, USA.
ACM.Rivindu Perera.
2012.
Ipedagogy: Question answeringsystem based on web information clustering.
InTechnology for Education (T4E), 2012 IEEE FourthInternational Conference on, pages 245?246.
IEEE.Chris Piech, Jonathan Huang, Zhenghao Chen, ChuongDo, Andrew Ng, and Daphne Koller.
2013.
Tunedmodels of peer assessment in MOOCs.
In Pro-ceedings of The 6th International Conference onEducational Data Mining (EDM 2013).John Prager, Eric Brown, Anni Coden, and DragomirRadev.
2000.
Question-answering by predictiveannotation.
In Proceedings of the 23rd AnnualInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, SIGIR?00, pages 184?191, New York, NY, USA.
ACM.Mingcheng Qu, Guang Qiu, Xiaofei He, Cheng Zhang,Hao Wu, Jiajun Bu, and Chun Chen.
2009.Probabilistic question recommendation for questionanswering communities.
In Proceedings of the18th International Conference on World Wide Web,WWW ?09, pages 1229?1230, New York, NY, USA.ACM.Carolyn Penstein Ros?e, Ryan Carlson, Diyi Yang,Miaomiao Wen, Lauren Resnick, Pam Goldman,and Jennifer Sherer.
2014.
Social factors that30contribute to attrition in moocs.
In Proceedingsof the first ACM conference on Learning@ scaleconference, pages 197?198.
ACM.Yves Rosseel.
2012. lavaan: An r package forstructural equation modeling.
Journal of StatisticalSoftware, 48(2):1?36, 5.Chirag Shah and Jefferey Pomerantz.
2010.
Evalu-ating and predicting answer quality in communityqa.
In Proceedings of the 33rd International ACMSIGIR Conference on Research and Development inInformation Retrieval, SIGIR ?10, pages 411?418,New York, NY, USA.
ACM.Juyup Sung, Jae-Gil Lee, and Uichin Lee.
2013.Booming up the long tails: Discovering potentiallycontributive users in community-based question an-swering services.
In ICWSM.Qiongjie Tian, Peng Zhang, and Baoxin Li.
2013.Towards predicting the best answers in community-based question-answering services.
In Emre Kici-man, Nicole B. Ellison, Bernie Hogan, Paul Resnick,and Ian Soboroff, editors, ICWSM.
The AAAI Press.Miaomiao Wen, Diyi Yang, and Carolyn Penstein Ros?e.2014.
Linguistic reflections of student engagementin massive open online courses.
In Proceedings ofthe International Conference on Weblogs and SocialMedia.Diyi Yang, Tanmay Sinha, David Adamson, andCarolyn Penstein Rose.
2013. turn on, tunein, drop out: Anticipating student dropouts inmassive open online courses.
In Workshop on DataDriven Education, Advances in Neural InformationProcessing Systems 2013.Diyi Yang, Miaomiao Wen, and Carolyn Rose.
2014.Peer influence on attrition in massive open onlinecourses.
In Proceedings of Educational DataMining.Wen-tau Yih, Ming-Wei Chang, Christopher Meek, andAndrzej Pastusiak.
2013.
Question answering usingenhanced lexical semantic models.
In Proceedingsof the 51st Annual Meeting of the Associationfor Computational Linguistics (Volume 1: LongPapers), pages 1744?1753, Sofia, Bulgaria, August.Association for Computational Linguistics.31
