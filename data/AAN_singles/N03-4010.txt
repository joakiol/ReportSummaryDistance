JAVELIN: A Flexible, Planner-Based Architecture for Question AnsweringEric NybergLanguage Technologies InstituteCarnegie Mellon Universityehn@cs.cmu.eduRobert FrederkingLanguage Technologies InstituteCarnegie Mellon Universityref@cs.cmu.eduAbstractThe JAVELIN system integrates a flexible,planning-based architecture with a variety oflanguage processing modules to provide anopen-domain question answering capability onfree text.
The demonstration will focus on howJAVELIN processes questions and retrieves themost likely answer candidates from the giventext corpus.
The operation of the system will beexplained in depth through browsing the repos-itory of data objects created by the system dur-ing each question answering session.1 IntroductionSimple factoid questions can now be answered reason-ably well using pattern matching.
Some systems (Soub-botin and Soubbotin, 2002) use surface patterns enhancedwith semantic categories and question types in order tomodel the likelihood of answers given the question.
Fur-thermore, Hovy et al (Hovy et al, 2002) have obtainedgood results using only surface patterns pre-extractedfrom the web.
However, pattern-based approaches don?trepresent the meaning of the patterns they use, and it isnot clear whether they can be generalized for more diffi-cult, non-factoid questions.Open domain question answering is a complex, multi-faceted task, where question type, information availabil-ity, user needs, and a combination of text processing tech-niques (statistical, NLP, etc.)
must be combined dynami-cally to determine the optimal answer.
For more complexquestions, a more flexible and powerful control mech-anism is required.
For example, LCC (D. Moldovanand Surdeanu, 2002) has implemented feedback loopswhich ensure that processing constraints are met by re-trieving more documents or expanding question terms.The LCC system includes a passage retrieval loop, alexico-semantic loop and a logic proving loop.
TheIBM PIQUANT system (Carroll et al, 2002) combinesknowledge-based agents using predictive annotation witha statistical approach based on a maximum entropy model(Ittycheriah et al, 2001).exeDomainModelPlannerDataRepositoryJAVELINGUIExecutionManagerprocess historyand dataJAVELIN operator(action) modelsquestionanswerack...dialogresponseexeresultsexeresultsresultsQuestionAnalyzerInformationExtractorAnswerGeneratorRetrievalStrategistAnswerJustificationWebBrowserFigure 1: The JAVELIN architecture.
The Planner con-trols execution of the individual components via the Ex-ecution Manager.Both the LCC and IBM systems represent a depar-ture from the standard pipelined approach to QA archi-tecture, and both work well for straightforward factoidquestions.
Nevertheless, both approaches incorporate apre-determined set of processing steps or strategies, andhave limited ability to reason about new types of ques-tions not previously encountered.
Practically useful ques-tion answering in non-factoid domains (e.g., intelligenceanalysis) requires more sophisticated question decom-position, reasoning, and answer synthesis.
For thesehard questions, QA architectures must define relation-ships among entities, gather information from multiplesources, and reason over the data to produce an effec-tive answer.
As QA functionality becomes more sophis-ticated, the set of decisions made by a system will notbe captured by pipelined architectures or multi-pass con-straint relaxation, but must be modeled as a step-by-stepdecision flow, where the set of processing steps is deter-mined at run time for each question.This demonstration illustrates the JAVELIN QA archi-tecture (Nyberg et al, 2002), which includes a general,modular infrastructure controlled by a step-by-step plan-ning component.
JAVELIN combines analysis modules,information sources, user discourse and answer synthe-sis as required for each question-answering interaction.JAVELIN also incorporates a global memory, or repos-Edmonton, May-June 2003Demonstrations , pp.
19-20Proceedings of HLT-NAACL 2003itory, which maintains a linked set of object dependen-cies for each question answering session.
The repositorycan be used to provide a processing summary or answerjustification for the user.
The repository also provides astraightforward way to compare the results of differentversions of individual processing modules running on thesame question.
The modularity and flexibility of the ar-chitecture provide a good platform for component-based(glass box) evaluation (Nyberg and Mitamura, 2002).2 Demonstration OutlineThe demonstration will be conducted on a laptop con-nected to the Internet.
The demonstration will featurethe JAVELIN graphical user interface (a Java applicationrunning on the laptop) and the JAVELIN Repository (thecentral database of JAVELIN result objects, accessed viaa web browser).
A variety of questions will be asked ofthe system, and the audience will be able to view the sys-tem?s answers along with a detailed trace of the steps thatwere taken to retrieve the answers.Figure 2: An Answer Justification.Figure 2 shows the top-level result returned byJAVELIN.
The preliminary answer justification includesthe selected answer along with a variety of hyperlinksthat can be clicked to provide additional detail regardingthe system?s analysis of the question, the documents re-trieved, the passages extracted, and the full set of answercandidates.
The justification also provides drill-down ac-cess to the steps taken by the Planner module in reason-ing about how to best answer the given question.
Figure 3shows additional detail that is exposed when the ?Docu-ments Returned?
and ?Request Fills?
links are activated.AcknowledgementsThe research described in this paper was supported in partby a grant from ARDA under the AQUAINT ProgramPhase I.
The current version of the JAVELIN system wasconceived, designed and constructed with past and cur-rent members of the JAVELIN team at CMU, including:Figure 3: Partial Answer Detail.Jamie Callan, Jaime Carbonell, Teruko Mitamura, KevynCollins-Thompson, Krzysztof Czuba, Michael Duggan,Laurie Hiyakumoto, Ning Hu, Yifen Huang, Curtis Hut-tenhower, Scott Judy, Jeongwoo Ko, Anna Kups?c?, LucianLita, Stephen Murtagh, Vasco Pedro, David Svoboda, andBenjamin Van Durme.ReferencesJ.
Carroll, J. Prager, C. Welty, K. Czuba, and D. Ferrucci.2002.
A multi-strategy and multi-source approach toquestion answering.S.
Harabagiu D. Moldovan, M. Pasca and M. Surdeanu.2002.E.
Hovy, U. Hermjakob, and D. Ravichandran.
2002.
Aquestion/answer typology with surface text patterns.A.
Ittycheriah, M. Franz, W. Zhu, and A. Ratnaparkhi.2001.
Question answering using maximum-entropycomponents.E.
Nyberg and T. Mitamura.
2002.
Evaluating qa sys-tems on multiple dimensions.E.
Nyberg, T. Mitamura, J. Carbonell, J. Callan,K.
Collins-Thompson, K. Czuba, M. Duggan,L.
Hiyakumoto, N. Hu, Y. Huang, J. Ko, L. Lita,S.
Murtagh, V. Pedro, and D. Svoboda.
2002.
Thejavelin question-answering system at trec 2002.M.
Soubbotin and S. Soubbotin.
2002.
Use of patternsfor detection of likely answer strings: A systematic ap-proach.
