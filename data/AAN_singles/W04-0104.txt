Automatic Acquisition of Feature-Based Phonotactic ResourcesJulie Carson-Berndsen & Robert Kelly & Moritz NeugebauerDepartment of Computer ScienceUniversity College DublinDublin 4, Ireland{julie.berndsen,robert.kelly,moritz.neugebauer}@ucd.ieAbstractAutomata induction and typed feature theory are de-scribed in a unified framework for the automaticacquisition of feature-based phonotactic resources.The viability of this data-driven procedure is il-lustrated with examples taken from a corpus ofsyllable-labelled data.1 IntroductionThis paper combines two hitherto distinct areas ofresearch, namely automata induction and typed fea-ture theory, for the purposes of acquiring phonotac-tic resources for use in speech technology.
In orderto illustrate the methodology a small annotated dataset for Italian has been chosen1; however, given an-notated data, the techniques can be applied to anylanguage thus supporting language documentationat the phonotactic level and eventually building upa catalogue of reusable multilingual phonotactic re-sources.There are numerous ways in which phonotacticinformation has been represented for use in speechtechnology applications ranging from phrase struc-ture rules to n-grams.
In this paper, the feature-based phonotactic automaton of the Time Mapmodel (Carson-Berndsen, 1998) is used as the rep-resentational device.
A phonotactic automaton de-scribes all permissible sound combinations of a lan-guage within the domain of a syllable in terms ofa finite state automaton, describing not only ac-tual lexicalised syllables but also idiosyncratic gapswhich would be considered well-formed by a na-tive speaker of a language.
The advantage of thisrepresentation of phonotactic constraints in the con-text of speech recognition is that it allows out-of-vocabulary items (new words) to be classifiedas well-formed if they adhere to the constraints.Furthermore, since the phonotactic automaton con-strains with respect to the syllable domain, it pro-vides a more flexible and linguistically motivated1We use phonemically annotated data from the EUROM1Multilingual European Speech Database.context than n-grams which restrict their context toa domain of fixed length (the n-1 preceding units).A phonotactic automaton describes language-specific constraints.
Therefore, in order to developmultilingual phonotactic resources, phonotactic au-tomata for different languages must be produced.Phonotactic automata for German and English havealready been constructed for the Time Map modelusing manual techniques (Carson-Berndsen, 1998;Carson-Berndsen and Walsh, 2000).
Since manualconstruction of phonotactic automata is time con-suming and laborious, more recently focus has beenplaced on combining manual and automatic tech-niques in order to reduce the level of required hu-man linguistic expertise.
This will become more im-portant when lesser-studied languages are addressedwhen an expert may not always be available.
Thetechniques presented here are regarded as supporttools for language documentation which allow in-ferences to be made based on generalisations foundin an annotated data set.
The linguist is free to ac-cept or reject the suggestions made by the system.In what follows, a technique is described inwhich phonotactic automata are acquired automat-ically given annotated data for a language.
Whilethis technique describes all forms found in the data,acquired automata cannot be considered completesince the data is likely to be sparse (in this paperwe illustrate this using a small data sample).
How-ever, by combining phonotactic automata with atyped feature classification of sounds encounteredin the data, it is possible to highlight not only dis-tributional similarities, but also phonetic similaritieswhich can be used to predict gaps in the represen-tation.
These can be presented to a user (at least anative speaker of a language) who can accept or re-ject these.
Accepted forms are then integrated intothe phonotactic automaton.2 Automatic Acquisition of PhonotacticAutomataThe approach described in this section is one alter-native to a fully manual construction of phonotac-Barcelona, July 2004Association for Computations LinguisticsACL Special Interest Group on Computational Phonology (SIGPHON)Proceedings of the Workshop of thetic automata whereby they are rapidly acquired au-tomatically and at a low cost.
Given a corpus ofwell-formed syllables for the language in question,it is assumed here that the phonotactics for the lan-guage is implicit in the syllables themselves and canbe automatically extracted by examining each syl-lable structure in turn.
An extracted phonotacticsis assumed to describe at least the syllables in thecorpus and is also assumed to be an approximationof the complete phonotactics for the language fromwhich the data was drawn.
Since the phonotactics inquestion are finite-state structures and the data avail-able for acquiring phonotactics is a corpus of posi-tive examples of well-formed syllable structures, theapproach adopted here is to apply a regular gram-matical inference procedure which can learn frompositive data alone.
The field of grammatical infer-ence has yielded many important learnability resultsfor different language classes.
A full discussion ofthese results is beyond the scope of this paper how-ever see Belz (2000, Chapter 3) for a concise sum-mary and discussion and Angluin and Smith (1983)for a survey style introduction to the field.
Sufficeto say that since the formal language of well-formedsyllables in a given natural language is finite, it ispossible to learn the structure of a regular grammari.e.
the required phonotactic automaton from posi-tive data alone i.e.
the corpus of well-formed sylla-bles.The choice of regular inference algorithm is infact arbitrary.
Many algorithms have been devel-oped which can perform this learning task.
For thepurposes of this paper however the ALERGIA (Car-rasco and Oncina, 1999) regular inference algorithmis used.
This algorithm as applied to the problem ofinferring phonotactic automata is described in detailelsewhere (Kelly, 2004b) .
Here, the workings ofthe algorithm are described by example.
Note thatALERGIA in fact treats any positive data sampleas having been generated by a stochastic process.Thus, learned automata are in fact stochastic au-tomata i.e.
automata in which both states and tran-sitions have associated probabilities, however tradi-tional automata can be obtained by simply ignoringthese probabilities.
Table 1 shows a small subsetof the Italian data set consisting of 14 well-formedItalian syllables each consisting of 3 segments andtranscribed using the SAMPA phonetic alphabet 2.The ALERGIA inference algorithm takes as in-put a sample set of positive strings S (represent-ing well-formed syllables in this case) together witha confidence value ?
and outputs a determinis-tic stochastic automaton A which is minimal for2http://www.phon.ucl.ac.uk/home/sampa//v e n/ /r a n/ /b e n/ /m e n/ /t w a//k a n/ /n o n/ /t o n/ /f j o/ /r a n//d j o/ /s t o/ /s t e/ /t s a/ /p l o/Table 1: Training set of Italian syllables.the language it describes.
ALERGIA proceeds bybuilding a Prefix Tree Automaton (PTA) from thestrings in S. The PTA is a deterministic automa-ton with a single path of state-transitions from itsunique start state for each unique prefix which oc-curs in S. Also, the PTA has a single acceptancepath, i.e.
path of state-transitions from the startstate to some final state, for each unique string inS where an initial subset of the transitions in ac-ceptance paths for strings are shared if those stringshave a common prefix.
Thus, common prefixes areessentially merged giving the PTA its tree shape.The PTA for S accepts exactly the strings in S andeach state of the PTA is associated with a uniqueprefix of S. ALERGIA also assigns each transi-tion in the PTA a frequency count dependent on thenumber of prefixes in S which share that transition.Similarly, each state has an assigned frequency de-pendent on the number of strings from S which areaccepted (or equivalently, generated) at that state.The PTA for the Italian syllables of table 1 is shownin figure 1.
Note that final states are denoted bydouble circles and the single start state is state 0.
Infigure 1 final state 26 has a frequency of 2 since thetwo occurrences of the syllable /r a n/ terminate atthis state.
All other final states have a frequency of1 since exactly one syllable terminates at each finalstate.
All other states have a frequency of 0.
Simi-larly, the transition from state 0 to state 13 has a fre-quency of 3 since three of the syllables in the train-ing set begin with /t/and the transitions from state 0to 17 and from state 17 to 18 have a frequency of2 since two syllables begin with the segment com-bination /s t/.
The frquencies associated with thestates and transitions of the PTA can be used to as-sociate a stochstic language with each state.
Theset of acceptance paths from a given state determinethe set of strings in its associated language and theprobability for a given string in the language is eas-ily derived from the frequencies of the states andtransitions on the acceptance path for that string.ALERGIA uses the PTA as the starting point forconstructing a canonical, i.e.
minimal deterministic,automaton for S. The canonical automaton is iden-tified by performing an ordered search of the au-tomata derivable from the PTA by partitioning andmerging subsets of states of the PTA.
Using the stan-Figure 1: Prefix Tree Automaton for the syllables intable 1.dard order on the prefixes associated with the statesof the PTA, pairs of states are subsequently exam-ined to determine if they generate a similar stochas-tic language within a statistical significance bounddependent on the supplied confidence value ?.
Ifa pair of states are deemed to statistically generatethe same language then they are merged into a sin-gle state and the state-transitions of the automatonare altered to reflect this merge.
The canonical au-tomaton is identified when no more state merges arepossible.
Figure 2 shows the canonical automatonderived from the PTA in figure 1.Since automata are derived from training sets ofsyllables through the use of a language indepen-dent regular inference algorithm, the procedure de-scribed above is generic and language independent.However, the procedure is of course dependent onthe existence of a corpus of training syllables forthe language in question and since it is entirely dataFigure 2: Canonical Automaton for the PTA in fig-ure 1.driven, the quality of the resulting phonotactics willbe dependent on the quality and completeness of thesyllable corpus.
Thus, firstly the corpus must havehigh quality annotations.
Fortunately, the need forhigh quality annotations in corpora is now recog-nised and has become an essential part of speechtechnology research and we assume here that highquality annotations are available.
Secondly, if validsound combinations are not detailed in the train-ing corpus then they may never be represented inthe learned phonotactics.
In order to be completethe learned automaton must model all valid soundcombinations, however.
In this case, generalisationtechniques must be applied in conjunction with theinference algorithm in order to identify and rectifygaps in the training corpus.
This ensures that theacquired phonotactics describes as close an approx-imation as possible to the complete phonotactics forthe language.
One such approach to generalisationwhich operates independently of the chosen regularinference algorithm is described in Kelly (2004a).An alternative technique is discussed in section 3.Finally, note that learned automata represent thefirst stage in the development of multilingual phono-logical resources called Multilingual Time Maps(MTMs) (Carson-Berndsen, 2002).
An MTM ex-tends the single tape model of a phonotactic au-tomaton to a multitape transducer whereby the dif-ferent transition tapes detail linguistic informationof varying levels of granularity and related to theoriginal segment label.
An MTM might have in-dividual tapes detailing the segment, the phonolog-ical features associated with that segment, the av-erage duration of the segment in a particular syl-labic position etc.
In particular, the segment tape ofthe learned phonotactic automata can be augmentedwith additional tapes detailing feature type labelsassociated with the segments.
These additional typelabel tapes are discussed in more detail in the fol-lowing section.3 Phonotactic Automata and TypedFeature StructuresLexical knowledge representation in computationalphonology has already made extensive use of in-heritance hierarchies to model lexical generalisa-tions ranging from higher level prosodic categoriesto the phonological segment.
In contrast to the ap-proach presented in this section, the work describedin (Cahill et al, 2000) is set in an untyped fea-ture system using DATR to define inheritance net-works with path-value equations (Evans and Gaz-dar, 1996).
The merits of applying a type disciplineeven to untyped feature structures is considered inWintner and Sarkar (2002) from a general perspec-tive and in Neugebauer (2003b) with special refer-ence to phonological lexica.Previous proposals to cast phonological structurein a typed feature system can be found in Birdand Klein (1994) and Walther (1999).
However,there are two major differences with regard to ourwork.
First, while types may denote sets of seg-ments, we go beyond the idea of sets as arc labels infinite-state automata (Bird and Ellison, 1994; Eis-ner, 1997; van Noord and Gerdemann, 2001) whichsays that boolean combinations of finitely-valuedfeatures can be stored as a set on just one arc, ratherthan being multiplied out as a disjunctive collectionof arcs.
This choice has no theoretical consequencesbut is merely a convenience for grammar develop-ment (Bird and Ellison, 1994).
The difference inour approach consists in the hierarchical orderingof types (or sets) which relates each arc label toany other type in a given phonological typed featuresystem; such type-augmented automata have beenformally defined in Neugebauer (2003c).
Second,inheritance of type constraints is assumed to gov-ern all subsegmental feature information (Neuge-bauer, 2003b).
Since here the crucial inheritancerelationships are induced automatically, we elabo-rate on work by Walther (1999) where a complexhand-crafted type hierarchy for internal segmentalstructure is mentioned instead of simple appropri-ateness declarations (Bird and Klein, 1994).The interaction of finite-state automata and typedfeature structures is depicted in figure 3.
Transitionsare exhaustively defined over a set of type labelswhich are characterised by a unique position in theunderlying type hierarchy.
This hierarchy is key tothe compilation of well-formed segment definitionswhich are achieved by unification of partial featurestructures.
In the simplest case, only atomic typesappear on the arcs which means that types corre-spond to singleton sets.
This can be achieved fora phonemically annotated corpus (just like the cor-pus in figure 1) by replacing all occurrences of aphoneme with its appropriate atomic type label.Figure 3: Example of the type-augmented automa-ton for [traf].The semantics of the type system assumed hereare extremely simple: the denotation of a parenttype in the directed acyclic graph that constitutes atype hierarchy is defined as the union of the deno-tation of its children, whereas a type node withoutchildren denotes a unique singleton set (A?
?t-Kaci etal., 1989).
Complex type formulae ?
as constructedby logical AND ?
are implicitly supported for thecase of intersections since the greatest lower boundcondition (Carpenter, 1992) is assumed: its the for-mal definition (also known as meet) states that ina bounded complete partial order that is an inheri-tance hierarchy, two types are either incompatible orcompatible.
While in the first case, type constraintsare shared, in the latter case we require them to havea unique highest common descendant.
As suggestedin the LKB system (Copestake, 2002), these typeswill in our approach be generated automatically if atype hierarchy does not conform to this condition.These types ?
such as glbtype2 in figure 3 ?
do nothave their own local constraint description and thusdo not rely on purely linguistic motivation.A useful application of the greatest lower boundcondition seems to be the possibility that we can re-fer to a set of compatible types simply by referenceto their common descendant.
As indicated by thehierarchical structure which is built over type09 infigure 3, atomic types encode maximal informationwhereas non-atomic types characteristically containonly partial information.
Thus, by defining transi-tions over types such as type34 we might elegantlycapture phonotactic generalisations over a subset offricative sounds.
This naturally raises the questionas to how the hierarchies are actually determined;a suitable algorithm is described below, a detailedspecification is provided in Neugebauer (2003a).Given a set of phonological feature bundles, aninheritance hierarchy may be generated in the fol-lowing way.
For each feature which is defined for alinguistic object (here: a phoneme) we compute thecorresponding extent or set description.
The algo-rithm then inserts these set descriptions into a latticeand looks them up at the same time: it asks for thesmallest description that is greater than a singletonset o with respect to the total order ?
used insidethe tree.
Every fully specified feature structure fora given phoneme will deliver such a singleton set,given that no two segments have been defined usingthe identical feature structure.The algorithm can be employed to recursivelycompute all set descriptions of a feature system bystarting from the smallest set description of the lat-tice.
We need the lattice structure to encode theinheritance relationships between sets; in the con-text of lattice computation we will refer to these setsin terms of nodes.
Every set description o has twolists associated with it: the list o?
of its upper nodesand the list o?
of its lower nodes.
One node maybe shared by two different set descriptions as theirupper node.
While the algorithm processes each ofthose two set descriptions, their shared upper nodemust be detected in order to configure the relation-ships correctly.
To this end, all set descriptions arestored in a search tree T .
Every time the algo-rithm finds a node it searches for it in the tree T tofind previously inserted instances of that set descrip-tion.
If the description is found, the existing listsof nodes are updated; otherwise the previously un-known set description is entered into the tree.
Figure4 demonstrates this procedure for the feature bundle{fricative,labiodental,voiceless}.
Once the smallestset description [labiodental] is not able to includeone of segments which are successively added to ita new upper node is created.To make sure that all set descriptions that are in-serted into the tree are also considered for their up-Figure 4: Induction of subsumption hierarchies.per nodes, the total tree order ?
must relate to thepartial lattice order ?
in the following way: o1 < o2implies o1 ?
o2.
This is how recently insertednodes are greater than the actual set description withrespect to ?
and will be considered later.3Once we have computed all set descriptions, wefinally assign types and type constraints to all nodesin the hierarchy.
Therefore, the set of feature struc-tures which constituted the starting point of our al-gorithm has now been computed into a data struc-ture which supersedes the previous level of infor-mation in terms of a type inheritance network.
Thelast step consists of the insertion of greatest lowerbounds thus generating a well-formed lattice.
Fig-ure 5 visualises the final type inheritance hierarchyfor an Italian corpus containing 22 phonemes, eachcorresponding to a unique atomic type (type01, .
.
.
,type22).
While the types numbered 23 to 39 aregenerated by our set-theoretic algorithm, the great-est lower bounds (the glb-types) are required by theformal characteristics of our type system.Any of the non-atomic types may be used to ex-press generalisations over sets of phonological seg-ments since each partial feature structure subsumesall compatible fully specified segment entries.
Ad-ditionally, non-atomic nodes may be associated withconstraints which define appropriateness declara-tions for linguistic signs of a particular type.
Forexample, all segments are at least characterised withrespect to four attributes (phonation, manner, placeand phonetic symbol).
The next section sketchesan application of typed feature structures addressing3Just computing the (ordered) set descriptions turns out tobe more effective since no hierarchy has to be computed.
Com-puting set descriptions as well as their hierarchical structuretakes twice as long for the same input when the algorithm isused.
This is also due to memory usage: while the computationof all set descriptions is only based on a single predecessor, theintegration of a lattice algorithm stores all set descriptions in apersistent search tree.Figure 5: Complete generated type hierarchy.data sparseness in automatically learned phonotac-tic automata.4 ExamplesThe integrated approach utilising both automata in-duction and typed feature theory as presented inthe previous sections requires a phonemically an-notated corpus.
Each phoneme is then mapped to acanonical feature bundle which is based on the pho-netic characteristics specified in the InternationalPhonetic Alphabet (IPA); the features used in Fig-ure 3 serve as an example.
Our set-theoretic algo-rithm operates on these feature structures thus de-riving a type inheritance network for the corpus inquestion.
Note that phonemes and features are notcorpus-specific but rather a subset of a language-independent set of linguistic descriptions that is theIPA.
As a result, we obtain a representation of ourannotation alphabet (phoneme and feature labels)which exclusively refers to (sets of) linguistic ob-jects via their corresponding types.
This is exempli-fied in figure 3 for an individual sound and in figure5 for the full corpus.Once the complete type hierarchy has been gen-erated the inheritance relationships described can beused to construct more compact finite-state struc-tures than the automata learned over the originaldata set.
In addition, the linguistic generalisationsdescribed by the hierarchy can be used to addressdata sparseness in the training corpus.
To illustratethis, the automata are learned over type labels ratherthan segments.
Since all transitions of the learnedautomata will now be labelled with types the infor-mation in the feature hierachy can be used to ex-press generalisations.
To ensure that automata arelearned over types the segments in the training datamust be replaced with type labels that correspond tosingleton sets containing only the original segment.For example, the syllable /r a n/ in table 1 would bereplaced by /type03 type01 type10/.
Note that in thiscase the transitions of the learned automaton will belabelled with type labels rather than segments.In the first case, the type hierarchy allows morecompact automata to be constructed by examiningthe set of transitions emanating from each state ofthe learned automaton.
If each of the transitions em-anating from a given state s1 have the same destina-tion state s2 then the type labels on each transitionare examined to determine if they have a commonancestor node in the hierarchy.
If a common an-cestor exists and if no other type label is the childof that parent other than those appearing on the setof transitions then they can be replaced by a sin-gle transition from s1 to s2 labelled with the parenttype.
The topmost diagram of figure 6 illustrates asmall section of the learned automaton for the fullItalian data set.
In this case there are two transi-tions from state 22 to state 35, one labelled withtype15 and the other labelled with type06.
Refer-ring to the hierarchy in figure 5, a common parent oftype15 and type06 is type30 and the only children oftype30 are type15 and type06.
Therefore these twotransitions can be replaced by the single transitionlabelled with type30.Note that replacements of the kind describedabove serve only to produce more compact au-tomata and do not extend the coverage of the au-tomaton.
However, it is possible to use the typehierarchy to achieve a more complete phonotactics.The middle diagram of figure 6 shows another smallsection of the learned automaton for the full Italiandata set.
Referring again to the hierarchy in figure 5,it can be seen that type29 is a parent of type14 whichlabels the transition from state 0 to state 7 and is alsoa parent of type18 which labels the transition fromstate 0 to state 5.
Similarly, type25 is a common par-ent of type06 and type01 which label the transitionsfrom state 7 to state 17 and state 5 to state 25 respec-tively.
Finally, type35 is a common parent of type10and type14 which label the transitions from state 17to state 35 and state 25 to state 35.
If each type labelis replaced by its common parent then both transi-tions from state 0 are labelled with type29.
Also,the paths emanating from the destination states ofthese transitions (states 5 and 7) are both labelledwith type25.
In this case state 5 and state 7 can bemerged into a single state.
A similar state mergingcan be performed for states 17 and 35 resulting in anew automaton as shown in figure 6.
This processyields a more general phonotactics since type29 ac-tually denotes the segment set {p,m, b} and type25denotes the set {a, i, e, E}.
Thus, the segment p hasbeen effectively introduced as a new onset conso-nant cluster that can precede any vowel in the setdenoted by type25.
Also, as a result of introducingtype25 the additional vowels i and E have been in-troduced as new vowel clusters.
Note however thattype35 denotes exactly the set {m,n} and so no newcoda clusters are introduced.Figure 6: Finite-state diagrams.5 ConclusionAn important pre-requisite for the development ofrobust multilingual speech technology applicationsis the availability of language resources at vary-ing levels of granularity.
This paper has presentedgeneric techniques for acquisition of language-specific phonotactic resources.
The techniques wereexemplified using a small data set for Italian,4 butscale to larger data sets and can be applied to anylanguage.
Although the induction techniques as de-scribed here assume that data is annotated at the syl-lable level, only very few corpora are actually an-notated at this level; a more usual annotation is atthe phonemic level.
As a result, a cyclical learn-ing procedure has been developed which learns assyllable annotation is being performed and uses thephonotactic automaton developed thus far to predictsyllable boundaries for annotation support (Kelly,2004b).
The work presented in this paper repre-sents one specific step towards the provision of fine-grained representations for speech recognition and4Due to space constraints this paper only in-cludes selected examples of the acquired resources.Additional information is publicly available athttp://muster.ucd.ie/sigphon/.
This includesthe complete annotation alphabet (phoneme and feature set),the typed feature system and complete state diagrams for allphonotactic automata.synthesis based on a combination of data-driven anduser-driven techniques.AcknowledgementsThis material is based upon works supported bythe Science Foundation Ireland under Grant No.02/IN1/ I100.
The opinions, findings and conclu-sions or recommendations expressed in this mate-rial are those of the authors and do not necessarilyreflect the views of Science Foundation Ireland.ReferencesA?
?t-Kaci, Hassan, R. Boyer, P. Lincoln, and R. Nasr.1989.
Efficient Implementation of Lattice Oper-ations.
ACM Transactions on Programming Lan-guages and Systems, 11(1):115?146.Dana Angluin and Carl H. Smith.
1983.
Inductiveinference: Theory and methods.
ACM Comput-ing Surveys, 15(3):237?269.Anja Belz.
2000.
Computational Learning ofFinite-State Models for Natural Language Pro-cessing.
Ph.D. thesis, University of Sussex.Steven Bird and T. Mark Ellison.
1994.
One?Level Phonology.
Computational Linguistics,20(1):55?90.Steven Bird and Ewan Klein.
1994.
PhonologicalAnalysis in Typed Feature Systems.
Computa-tional Linguistics, 20:455?491.Lynne Cahill, Julie Carson-Berndsen, and GeraldGazdar.
2000.
Phonology?based Lexical Knowl-edge Representation.
In Lexicon Developmentfor Speech and Language Processing, pages 77?114.
Kluwer Academic Publishers, Dordrecht.Bob Carpenter.
1992.
The Logic of Typed FeatureStructures, volume 32 of Cambridge Tracts inTheoretical Computer Science.
Cambridge Uni-versity Press, Cambridge.Rafael C. Carrasco and Jose Oncina.
1999.
Learn-ing deterministic regular grammars from stochas-tic samples in polynomial time.
ITA, 33(1):1?19.Julie Carson-Berndsen and Michael Walsh.
2000.Interpreting multilinear representations inspeech.
In Proceedings of the 8th AustralianConference on Speech Science and Technology,pages 472?477, Canberra, December.Julie Carson-Berndsen.
1998.
Time Map Phonol-ogy: Finite State Models and Event Logics inSpeech Recognition.
Kluwer Academic Publish-ers, Dordrecht, Holland.Julie Carson-Berndsen.
2002.
Multilingual timemaps: Portable phonotactic models for speechtechnology applications.
In Proceedings of theLREC 2002 Workshop on Portability Issues inHuman Language Technology.Ann Copestake.
2002.
Implementing Typed Fea-ture Structure Grammars, volume 110 of CSLILecture Notes.
CSLI Publications, Center for theStudy of Language and Information.Jason Eisner.
1997.
Efficient generation in primi-tive optimality theory.
In Proceedings of the 35thAnnual Meeting of the Association for Compu-tational Linguistics and the 8th Conference ofthe European Association for Computational Lin-guistics, Madrid.Roger Evans and Gerald Gazdar.
1996.
DATR: Alanguage for Lexical Knowledge Representation.Computational Linguistics, 22(2):176?216.Robert Kelly.
2004a.
Generalisation in the auto-matic acquisition of phonotactic resources.
ToAppear in Proceedings of The University of Cam-bridge Second Postgraduate Conference in Lan-guage Research.Robert Kelly.
2004b.
A language independent ap-proach to acquiring phonotactic resources forspeech recognition.
In Proceedings of the 7thAnnual Colloquium for the UK Special InterestGroup for Computational Linguistics, pages 126?133.
CLUK04.Moritz Neugebauer.
2003a.
Automatic Generationof Constraint Hierarchies.
Poster presented at the14th Meeting of Computational Linguistics in theNetherlands, University of Antwerp.Moritz Neugebauer.
2003b.
ComputationalPhonology and Typed Feature Structures.
InProceedings of the First CamLing PostgraduateConference on Language Research.
Cambridge.University of Cambridge.Moritz Neugebauer.
2003c.
Subsumption inSpeech Recognition and Feature Theory.
In Pro-ceedings of the Twenty-ninth Annual Meeting ofthe Berkeley Linguistics Society, University ofCalifornia at Berkeley.
Berkeley Linguistics So-ciety.Gertjan van Noord and Dale Gerdemann.
2001.
Fi-nite State Transducers with Predicates and Iden-tities.
Grammars, 4(3):263?286.Markus Walther.
1999.
One?Level Prosodic Mor-phology.
In Marburger Arbeiten zur Linguistik,volume 1, Philipps?Universita?t Marburg.Shuly Wintner and Anoop Sarkar.
2002.
A noteon typing feature structures.
Computational Lin-guistics, 28(3):389?397.
