Proceedings of the EACL 2009 Workshop on Language Technology and Resources for Cultural Heritage,Social Sciences, Humanities, and Education ?LaTeCH ?
SHELT&R 2009, pages 60?68,Athens, Greece, 30 March 2009. c?2009 Association for Computational LinguisticsInstance-driven Discovery of Ontological Relation LabelsMarieke van Erp, Antal van den Bosch, Sander Wubben, Steve HuntILK Research GroupTilburg centre for Creative ComputingTilburg UniversityThe Netherlands{M.G.J.vanErp,Antal.vdnBosch,S.Wubben,S.J.Hunt}@uvt.nlAbstractAn approach is presented to the auto-matic discovery of labels of relations be-tween pairs of ontological classes.
Usinga hyperlinked encyclopaedic resource, wegather evidence for likely predicative la-bels by searching for sentences that de-scribe relations between terms.
The termsare instances of the pair of ontologicalclasses under consideration, drawn froma populated knowledge base.
Verbs orverb phrases are automatically extracted,yielding a ranked list of candidate rela-tions.
Human judges rate the extractedrelations.
The extracted relations providea basis for automatic ontology discoveryfrom a non-relational database.
The ap-proach is demonstrated on a database fromthe natural history domain.1 IntroductionThe rapid growth in the digitisation of data hascaused many curators, researchers, and data man-agers of cultural heritage institutions (libraries,archives, museums) to turn to knowledge man-agement systems.
Using these systems typicallycauses them to think about the ontological struc-ture of their domain, involving the identificationof key classes in object data and metadata fea-tures, and importantly, their relations.
The start-ing point of this process is often a more classi-cal ?flat?
database matrix model of size n ?
m,where n is the number of collection items, and mis a fixed number of database columns, typicallydenoting object metadata features, as cultural her-itage institutions are generally well accustomed tousing databases of that type.
An ontology can bebootstrapped from such a database by first assum-ing that the database columns can be mapped ontothe domain?s ontological classes.
The next stepis then to determine which classes are related toeach other, and by which relation.
In this paperwe present a method that partially automates thisprocess.To gather evidence for a relation to exist be-tween two ontological classes, it is not possible tosimply look up the classes in text.
Rather, classesare realised typically as a multitude of terms orphrases.
For example, the natural history class?species?
is realised as many different instances ofspecies names in text.
The automatic discovery ofrelations between ontological classes thus requiresat least a two-step approach: first, the identifica-tion of instances of ontological classes in text andtheir particular relations, and second, the aggrega-tion of these analyses in order to find evidence fora most likely relation.It is common in ontology construction to usepredicative labels for relations.
Although no regu-lations for label names exist, often a verb or verbphrase head is taken, optionally combined with aprepositional head of the subsequent verb-attachedphrase (e. g., ?occurs in?, or ?donated by?).
Inthis study, we make the assumption that good can-didate labels are frequent verbs or verb phrasesfound between instances from a particular pair ofclasses, and that this may sometimes involve averb-attached prepositional phrase containing oneof the two terms.
In this paper we explore thisroute, and present a case study on the discoveryof predicative labels on relations in an ontologyfor animal specimen collections.
The first step,identifying instances of ontological classes, is per-formed by selecting pairs of instances from a flatn ?m specimen database, in which the instances60are organised by the database columns, and thereis a one-to-one relationship between the databasecolumns and the classes in our ontology.Any approach that bases itself on text to dis-cover relations, is dependent on the quality ofthat text.
In this study we opt for Wikipediaas a resource from which to extract relations be-tween terms.
Although the status of Wikipediaas a dependable resource is debated, in part be-cause of its dynamic nature, there is some evi-dence that Wikipedia can be as reliable a sourceas one that is maintained solely by experts (Giles,2005).
Wikipedia is also an attractive resource dueto its size (currently nearly 12 million articles inover 250 languages).
Additionally, Wikipedia?sstrongly hyperlinked structure closely resembles asemantic net, with its untyped (but directed) re-lations between the concepts represented by thearticle topics.
Since the hyperlinks in Wikipediaindicate a relations between two encyclopaedia ar-ticles, we aim at discovering the type of relationsuch a link denotes through the use of syntacticparsing of the text in which the link occurs.The idea of using Wikipedia for relation ex-traction is not new (Auer and Lehmann, 2007;Nakayama et al, 2008; Nguyen et al, 2007;Suchanek et al, 2006; Syed et al, 2008).
How-ever, most studies so far focus on the structuredinformation already explicit in Wikipedia, such asits infoboxes and categories.
The main contribu-tions of our work are that we focus on the in-formation need emerging from a specific domain,and that we test a method of pre-selection of sen-tences to extract relations from.
The selection isbased on the assumption that the strongest andmost reliable lexical relations are those expressedby hyperlinks in Wikipedia pages that relate an ar-ticle topic to another page (Kamps and Koolen,2008).
The selection procedure retains only sen-tences in which the topic of the article, identifiedby matching words in the article title, links to an-other Wikipedia article.
The benefit of the pre-selection of sentences is that it reduces the work-load for the syntactic parser.Since the system is intentionally keptlightweight, the extraction of relations fromWikipedia is sufficiently fast, and we observe thatthe results are sufficient to build a basic ontologyfrom the data.
This paper is organised as follows.In Section 2 we review related work.
In Section 3the data used in this work is described, followedby the system in Section 4 and an explanationof how we evaluated the possible relations oursystem discovered is presented in Section 5.
Wereport on the results of our study in Section 6, andformulate our conclusions and points for furtherresearch in Section 7.2 Related WorkA key property of Wikipedia is that it is for thegreater part unstructured.
On the one hand, ed-itors are encouraged to supply their articles withcategories.
These categories can be subsumed bybroader categories, thus creating a taxonomy-likestructure.
On the other hand, editors can link toany other page in Wikipedia, no matter if it is partof the same category, or any category at all.
Anarticle can be assigned multiple categories, but thenumber of hyperlinks provided in an average arti-cle typically exceeds the number of categories as-signed to it.The free associative hyperlink structure ofWikipedia is intrinsically different from the hier-archical top down architecture as seen in Word-Net, as a hyperlink has a direction, but not atype.
A Wikipedia article can contain any num-ber of links, pointing to any other Wikipedia arti-cle.
Wikipedia guidelines state however that wik-ilinks (hyperlinks referring to another Wikipediapage) should only be added when relevant to thetopic of the article.
Due to the fact that most userstend to adhere to guidelines for editing Wikipediapages and the fact that articles are under constantscrutiny of their viewers, most links in Wikipediaare indeed relevant (Blohm and Cimiano, 2007;Kamps and Koolen, 2008).The structure and breadth of Wikipedia is a po-tentially powerful resource for information extrac-tion which has not gone unnoticed in the natu-ral language processing (NLP) community.
Pre-processing of Wikipedia content in order to ex-tract non-trivial relations has been addressed in anumber of studies.
(Syed et al, 2008) for instanceutilise the category structure in Wikipedia as anupper ontology to predict concepts common to aset of documents.
In (Suchanek et al, 2006) anontology is constructed by combining entities andrelations between these extracted from Wikipediathrough Wikipedia?s category structure and Word-Net.
This results in a large ?is-a?
hierarchy, draw-ing on the basis of WordNet, while further rela-tion enrichments come from Wikipedia?s category61structure.
(Chernov et al, 2006) also exploit theWikipedia category structure to which concepts inthe articles are linked to extract relations.
(Auer and Lehmann, 2007) take a different ap-proach in that they focus on utilising the structurepresent in infoboxes.
Infoboxes are consistentlyformatted tables in articles that provide summaryinformation, such as information about area, pop-ulation and language for countries, and birth datesand places for persons.
Although infoboxes pro-vide rich structured information, their templatesare not yet standardised, and their use has not per-meated throughout the whole of Wikipedia.Although the category and infobox structures inWikipedia already provide a larger coverage at theconcept or term level than for instance WordNet,they do not express all possibly relevant seman-tic relations.
Especially in specific domains, re-lations occur that would make the Wikipedia datastructure unnecessarily dense if added, thus an ap-proach that exploits more of the linguistic contentof Wikipedia is desirable.Such approaches can be found in (Nakayama etal., 2008) and (Nguyen et al, 2007).
In both worksfull sections of Wikipedia articles are parsed, en-tities are identified, and the verb between the enti-ties is taken as the relation.
They also extract re-lations that are not backed by a link in Wikipedia,resulting in common-sense factoids such as ?Bres-cia is a city?.
For a domain specific applicationthis approach lacks precision.
In our approach, wecare more for high precision in finding relationsthan for recall; hence, we carefully pre-select on-tological classes among which relations need to befound, and use these as filters on our search.The usefulness of the link structure inWikipedia has been remarked upon by (Vo?lkel etal., 2006).
They acknowledge that the link struc-ture in Wikipedia denotes a potentially meaning-ful relation between two articles, though the re-lation type is unknown.
They propose an exten-sion to the editing software of Wikipedia to enableusers to define the type of relation when they adda link in Wikipedia.
Potentially this can enrichWikipedia tremendously, but the work involvedwould be tremendous as well.
We believe some ofthe type information is already available throughthe linguistic content of Wikipedia.3 Data Preparation3.1 DataThe data used in this work comes from a manu-ally created, non-relational research database of acollection of reptiles and amphibians at a naturalhistory museum.
The information contained in thecells describes when a specimen entered the col-lection, under what circumstances it was collected,its current location, registration number, etc.
Weargue that the act of retrieving information fromthis flat database could be enhanced by providinga meta-structure that describes relations betweenthe different database columns.
If for instance arelation of the type ?is part of?
can be defined be-tween the database columns province and country,then queries for specimens found at a particularlocation can be expanded accordingly.Even though the main language of the databaseis Dutch, we still chose to use the EnglishWikipedia as the resource for retrieval of rela-tion label candidates.
Explicitly choosing the En-glish Wikipedia has as a consequence that therelation labels we are bound to discover willbe English phrases.
Furthermore, articles inthe English Wikipedia on animal taxonomy havea broader coverage and are far more elaboratethan those contained in the Dutch Wikipedia.Since these database values use a Latin-basednomenclature, using the wider-coverage EnglishWikipedia yields a much higher recall than theDutch Wikipedia.
The values of the other columnsmainly contain proper names, such as personnames and geographic locations and dates, whichare often the same; moreover, English and Dutchare closely related languages.
Different names ex-ist for different countries in each language, buthere the inconsistency of the database aids us, asit in fact contains many database entries partiallyor fully in English, as well as some in German andPortuguese.The database contains 16,870 records in 39columns.
In this work we focus on 20 columns;the rest are discarded as they are either extrinsicfeatures not directly pertaining to the object theydescribe, e.g., a unique database key, or elaboratetextual information that would require a separateprocessing approach.
The columns we focus ondescribe the position of the specimen in the zo-ological taxonomy (6 columns), the geographicallocation in which it was found (4 columns), someof its physical properties (3 columns), its collector62Column Name ValueTaxonomic Class ReptiliaTaxonomic Order CrocodyliaAmphisbaeniaTaxonomic Genus AcanthophisXenobatrachusCountry IndonesiaSurinameLocation city wallsnear Lake MahalonaCollection Date 01.02.188802.01.1995Type holotypeparalectotypeDeterminator A. DuboisM.
S. HoogmoedSpecies defined by (Linnaeus, 1758)(LeSueur, 1827)Table 1: Example classes from test dataand/or determiner, donator and associated date (4columns), and other information (3 columns).
Thevalues in most columns are short, often consist-ing of a single word.
Table 1 lists some exampledatabase values.3.2 PreprocessingAs the database was created manually, it was nec-essary to normalise spelling errors, as well asvariations on diacritics, names and date formats.The database values were also stripped of all non-alphanumeric characters.In order to find meaningful relations betweentwo database columns, query pairs are generatedby combining two values occurring together in arecord.
This approach already limits the numberof queries applied to Wikipedia, as no relations areattempted to be found between values that wouldnot normally occur together.
This approach yieldsa query pair such as Reptilia Crocodylia from thetaxonomic class and order columns, but not Am-phibia Crocodylia.
Because not every databasefield is filled, and some combinations occur moreoften, this procedure results in 186,141 querypairs.For this study we use a database snapshot of theEnglish Wikipedia of July 27, 2008.
This dumpcontains about 2.5 million articles, including a vastamount of domain-specific articles that one wouldtypically not find in general encyclopaedias.
Anindex was built of a subset of the link structurepresent in Wikipedia.
The subset of links includedin the index is constrained to those links occur-ring in sentences from each article in which themain topic of the Wikipedia article (as taken fromthe title name) occurs.
For example, from theWikipedia article on Anura the following sentencewould be included in the experiments1:The frog is an [[amphibian]] in the order Anura(meaning ?tail-less?, from Greek an-, without +oura, tail), formerly referred to as Salientia (Latinsaltare, to jump)whereas we would exclude the sentence:An exception is the [[fire-bellied toad]] (Bombinabombina): while its skin is slightly warty, itprefers a watery habitat.This approach limits the link paths to onlythose between pages that are probably semanti-cally strongly connected to each other.
In thefollowing section the computation of the linkpaths indicating semantic relatedness between twoWikipedia pages is explained.3.3 Computing Semantic RelatednessRelation discovery between terms (instantiationsof different ontological classes) that have a pagein Wikipedia is best performed after establishingif a sufficiently strong relation between the twoterms under consideration actually exists.
To dothis, the semantic relatedness of those two termsor concepts needs to be computed first.
Seman-tic relatedness can denote every possible relationbetween two concepts, unlike semantic similarity,which typically denotes only certain hierarchicalrelations (like hypernymy and synonymy) and isoften computed using hierarchical networks likeWordNet (Budanitsky and Hirst, 2006).A simple and effective way of computing se-mantic relatedness between two concepts c1 and c2is measuring their distance in a semantic network.This results in a semantic distance metric, whichcan be inversed to yield a semantic relatednessmetric.
Computing the path-length between termsc1 and c2 can be done using Formula 1 where P isthe set of paths connecting c1 to c2 and Np is thenumber of nodes in path p.1The double brackets indicate Wikilinks63relpath(c1, c2) = argmaxp?P1Np(1)We search for shortest paths in a semantic net-work that is constructed by mapping the conceptsin Wikipedia to nodes, and the links between theconcepts to edges.
This generates a very largenetwork (millions of nodes and tens of millionsof edges), but due to the fact that Wikipedia isscale-free (Barabasi and Albert, 1999) (its con-nectedness degree distribution follows a power-law), paths stay relatively short.
By indexingboth incoming and outgoing links, a bidirectionalbreadth-first search can be used to find shortestpaths between concepts.
This means that thesearch is divided in two chains: a forward chainfrom c1 and a backward chain to c2.
As soon as thetwo chains are connected, a shortest path is found.4 Extracting Relations from WikipediaEach query pair containing two values from twodatabase columns are sent to the system.
The sys-tem processes each term pair in four steps.
Aschematic overview of the system is given in Fig-ure 1.IndexedWikipediacorpusTerm 1 Term 2Art.1Art.2find path length...<term 1>...<term 2>...<term 1><relation><term 2>extractif path length == 1if pathlength == 2find intermediatevalue in databaseTerm 1Term 2Interm.TermInterm.Termif foundStep 4Step 1Step 3Step 2Figure 1: Schematic overview of the systemStep 1 We look for the most relevant Wikipediapage for each term, by looking up the term in ti-tles of Wikipedia articles.
As Wikipedia format-ting requires the article title to be an informativeand concise description of the article?s main topic,we assume that querying only for article titles willyield reliable results.Step 2 The system finds the shortest link path be-tween the two selected Wikipedia articles.
If thepath distance is 1, this means that the two con-cepts are linked directly to each other via theirWikipedia articles.
This is for instance the casefor Megophrys from the genus column, and Anurafrom the order column.
In the Wikipedia article onMegophrys, a link is found to the Wikipedia arti-cle on Anura.
There is no reverse link from Anurato Megophrys; hierarchical relationships in the zo-ological taxonomy such as this one are often uni-directional in Wikipedia as to not overcrowd theparent article with links to its children.Step 3 The sentence containing both target con-cepts as links is selected from the articles.From the Megophrys article this is for instance?Megophrys is a genus of frogs, order [[Anura]],in the [[Megophryidae]] family.
?Step 4 If the shortest path length between twoWikipedia articles is 2, the two concepts are linkedvia one intermediate article.
In that case the sys-tem checks whether the title of the intermediate ar-ticle occurs as a value in a database column otherthan the two database columns in focus for thequery.
If this is indeed the case, the two addi-tional relations between the first term and the in-termediate article are also investigated, as well asthe second term and that of the intermediate ar-ticle.
Such a bridging relation pair is found forinstance for the query pair Hylidae from the tax-onomic order column, and Brazil from the coun-try column.
Here, the initial path we find is Hyl-idae?
Sphaenorhynchys?
Brazil.
We find thatthe article-in-the-middle value (Sphaenorhynchys)indeed occurs in our database, in the taxonomicgenus column.
We assume this link is evi-dence for co-occurrence.
Thus, the relevant sen-tences from the Wikipedia articles on Hylidaeand Sphaenorhynchys, and between articles onSphaenorhynchys and Brazil are added to the pos-sible relations between ?order?
?
?genus?
and?genus?
?
?country?.Subsequently, the selected sentences are POS-tagged and parsed using the Memory Based Shal-low Parser (Daelemans et al, 1999).
This parserprovides tokenisation, POS-tagging, chunking,and grammatical relations such as subject and di-rect object between verbs and phrases, and isbased on memory-based classification as imple-mented in TiMBL (Daelemans et al, 2004).
Thefive most frequently recurring phrases that occur64between the column pairs, where the subject of thesentence is a value from one of the two columns,are presented to the human annotators.
The cut-offof five was chosen to prevent the annotators fromhaving to evaluate too many relations and to onlypresent those that occur more often, and are henceless likely to be misses.
Misses can for instancebe induced by ambiguous person names that alsoaccidentally match location names (e.g., Dakota).In Section 7 we discuss methods to remedy this infuture work.5 Evaluating Relations from WikipediaFour human judges evaluated the relations be-tween the ontological class pairs that were ex-tracted from Wikipedia.
Evaluating semantic rela-tions automatically is hard, if not impossible, sincethe same relation can be expressed in many ways,and would require a gold standard of some sort,which for this domain (as well as for many cul-tural heritage domains) is not available.The judges were presented with the five highest-ranked candidate labels per column pair, as well alonger snippet of text containing the candidate la-bel, to resolve possible ambiguity.
The items ineach list were scored according to the total recip-rocal rank (TRR) (Radev et al, 2002).
For everycorrect answer 1/n points are given, where n de-notes the position of the answer in the ranked list.If there is more than 1 correct answer the pointswill be added up.
For example, if in a list of five,two correct answers occur on positions 2 and 4, theTRR would be calculated as (1/2 + 1/4) = .75.The TRR scores were normalised for the numberof relation candidates that were retrieved, as forsome column pairs less than five relation candi-dates were retrieved.As an example, for the column pair ?Province?and ?Genus?, the judges were presented with therelations shown in Table 2.
The direction arrowin the first column denotes that the ?Genus?
valueoccurred before the ?Province?
value.The human judges were sufficiently familiarwith the domain to evaluate the relations, and hadthe possibility to gain extra knowledge about theclass pairs through access to the full Wikipediaarticles from which the relations were extracted.Inter-annotator agreement was measured usingFleiss?s Kappa coefficient (Fleiss, 1971).6 Results and EvaluationAs expected, between certain columns there aremore relations than between others.
In total 140relation candidates were retrieved directly, and303 relation label candidates were retrieved via anintermediate Wikipedia article.
We work with theassumption that these columns have a stronger on-tological relation than others.
For some databasecolumns we could not retrieve any relations, suchas the ?collection date?
field.
This is not sur-prising, as even though Wikipedia contains pagesabout dates (?what happened on this day?
), it isunlikely that it would link to such a domain spe-cific event such as an animal specimen collec-tion.
Relations between instances denoting per-sons and other concepts in our domain are also notdiscovered through this approach.
This is due tothe fact that many of the biologists named in thedatabase do not have a Wikipedia page dedicatedto them, indicating the boundaries of Wikipedia?sdomain specific content.
Although not ideal, anamed-entity recognition filter could be applied tothe database after which person names can be re-trieved from other resources.Occasionally we retrieve a Wikipedia article fora value from a person name column, but in mostcases this mistakenly matches with a Wikipediaarticle on a location, as last names in Dutch areoften derived from place names.
Another probleminduced by incorrect data is the incorrect matchof Wikipedia pages on certain values from the?Town?
and ?Province?
columns.
Incorrect rela-tion candidates are retrieved because for instancethe value ?China?
occurs in both the ?Town?
andthe ?Province?
columns.
A data cleaning stepwould solve these two problems.From each column pair the highest rated rela-tion was selected with which we constructed theontology displayed in Figure 2.
As the figureshows, the relations that are discovered are notonly ?is a?-relations one would find in strictly hier-archical resources such as a zoological taxonomyor geographical resource.The numbers in the relation labels in Figure 2denote the average TRR scores given by the fourjudges on all relation label candidates that thejudges were presented with for that column pair.The scores for the relations between the taxo-nomic classes in our domain were particularlyhigh, meaning that in many cases all relation can-didates presented to the judges were assessed as65Direction Label Snippet?
is found in is a genus of venomous pitvipers found in Asia from Pakistan, through India,?
is endemic to Cross Frogs) is a genus of microhylid frogs endemic to Southern Philippine,?
are native to are native to only two countries: the United States and?
is known as is a genus of pond turtles also known as Cooter Turtles, especially in the state ofTable 2: Relation candidates for Province and Genus column paircorrect.
The inter-annotator agreement was ?
=0.63, which is not perfect, but reasonable.
Mostdisagreement is due to vague relation labels suchas ?may refer to?
as found between ?Province?
and?Country?.
If a relation that occurred fewer than 5times was judged incorrect by the majority of thejudges the relation was not included in Figure 2.Manual fine-tuning and post-processing of theresults could filter out synonyms such as thosefound for relations between ?Town?
and otherclasses in the domain.
This would for instance de-fine one particular relation label for the relations?is a town in?
and ?is a municipality in?
that the sys-tem discovered between ?Town?
and ?Province?and ?Town?
and ?Country?, respectively.7 Conclusion and Future WorkIn this work we have shown that it is possibleto extract ontological relation labels for domain-specific data from Wikipedia.
The main contri-bution that makes our work different from otherwork on relation extraction from Wikipedia is thatthe link structure is used as a strong indication ofthe presence of a meaningful relation.
The pres-ence of a link is incorporated in our system by onlyusing sentences from Wikipedia articles that con-tain links to other Wikipedia articles.
Only thosesentences are parsed that contain the two terms weaim to find a relation between, after which the verbphrase and possibly the article or preposition fol-lowing it are selected for evaluation by four humanjudges.The advantage of the pre-selection of contentthat may contain a meaningful relation makes ourapproach fast, as it is not necessary to parse thewhole corpus.
By adding the constraint that atleast one of the query terms should be the sub-ject of a sentence, and by ranking results by fre-quency, our system succeeds in extracting correctand informative relations labels.
However, there isclearly some room for improvement, for instancein the coverage of more general types of infor-mation such as dates and person names.
For thiswe intend to incorporate more domain specific re-sources, such as research papers from the domainthat may mention persons from our database.
Weare also looking into sending queries to the web,whilst keeping the constraint of hyperlink pres-ence.Another factor that may help back up the rela-tions already discovered is more evidence for ev-ery relation.
Currently we only include sentencesin our Wikipedia corpus that contain the literalwords from the title of the article, to ensure wehave content that is actually about the article andnot a related topic.
This causes many sentencesin which the topic is referred to via anaphoric ex-pressions to be missed.
(Nguyen et al, 2007) takethe most frequently used pronoun in the article asreferring to the topic.
This still leaves the prob-lem of cases in which a person is first mentionedby his/her full name and subsequently only by lastname.
Coreference resolution may help to solvethis, although accuracies of current systems for en-cyclopaedic text are often not much higher thanbaselines such as those adopted by (Nguyen et al,2007).Errors in the database lead to some noise inthe selection of the correct Wikipedia article.
Thequeries we used are mostly single-word and two-word terms, which makes disambiguation hard.Fortunately, we have access to the class label (i.e.,the database column name) which may be addedto the query to prevent retrieval of an article abouta country when a value from a person name col-umn is queried.
We would also like to inves-tigate whether querying terms from a particulardatabase column to Wikipedia can identify incon-sistencies in the database and hence perform adatabase cleanup.
Potentially, extraction of re-lation labels from Wikipedia articles can also beused to assign types to links in Wikipedia.AcknowledgmentsThe authors would like to thank the anonymousreviewers for their comments.
This research66TypeLocationon the island of(0.500)GenusOrderis a(1.000)FamilyClassis a(0.750)Countryis in(0.500)Speciesis a(1.000)is a(0.833)Type NameProvinceoccur in(0.333)occur in(0.750)may refer to(0.560)is a(0.854)is found in(0.635)Townis found in(0.566)is a town in(0.794)may refer to(0.482)is found in(0.573)is a municipality in(0.891)is a town in(0.759)is a(1.000)Figure 2: Graph of relations between columns, with TRR scores in parentheseswas funded as part of the Continuous Access toCultural Heritage (CATCH) programme of theNetherlands Organisation for Scientific Research(NWO).ReferencesSo?ren Auer and Jens Lehmann.
2007.
What have inns-bruck and leipzig in common?
extracting seman-tics from wiki content.
In Franconi et al, editor,Proceedings of European Semantic Web Conference(ESWC?07), volume 4519 of Lecture Notes in Com-puter Science, pages 503?517, Innsbruck, Austria,June 3 - 7.
Springer.A.
L. Barabasi and R. Albert.
1999.
Emer-gence of scaling in random networks.
Science,286(5439):509?512, October.Sebastian Blohm and Philipp Cimiano.
2007.
Usingthe web to reduce data sparseness in pattern-basedinformation extraction.
In Proceedings of the 11thEuropean Conference on Principles and Practice ofKnowledge Discovery in Databases (PKDD), War-saw, Poland, September.
Springer.A.
Budanitsky and G. Hirst.
2006.
EvaluatingWordNet-based measures of lexical semantic relat-edness.
Computational Linguistics, 32(1):13?47.Sergey Chernov, Tereza Iofciu, Wolfgang Nejdl, andXuan Zhou.
2006.
Extracting semantic relation-ships between wikipedia categories.
In Proceedingsof the First Workshop on Semantic Wikis - From Wikito Semantics [SemWiki2006] - at ESWC 2006, pages153 ?
163, Karlsruhe, Germany, May 15.Walter Daelemans, Sabine Buchholz, and Jorn Veen-stra.
1999.
Memory-based shallow parsing.
In Pro-ceedings of CoNLL?99, pages 53?60, Bergen, Nor-way, June 12.Walter Daelemans, Jakub Zavrel, Ko Van der Sloot,and Antal Van den Bosch.
2004.
Timbl: Tilburgmemory based learner, version 5.1, reference guide.Technical Report 04-02, ILK/Tilburg University.J.
L. Fleiss.
1971.
Measuring nominal scale agree-ment among many raters.
Psychological Bulletin,76(5):378?382.Jim Giles.
2005.
Internet encyclopaedias go head tohead.
Nature, 438:900?901.Jaap Kamps and Marijn Koolen.
2008.
The impor-tance of link evidence in wikipedia.
In Craig Mac-donald, Iadh Ounis, Vassilis Plachouras, Ian Rutven,and Ryen W. White, editors, Advances in Infor-mation Retrieval: 30th European Conference onIR Research (ECIR 2008), volume 4956 of LectureNotes in Computer Science, pages 270?282, Glas-gow, Scotland, March 30 - April 3.
Springer Verlag.Kotaro Nakayama, Takahiro Hara, and Shojiro Nishio.2008.
Wikipedia link structure and text mining forsemantic relation extraction towards a huge scaleglobal web ontology.
In Proceedings of Sem-Search 2008 CEUR Workshop, pages 59?73, Tener-ife, Spain, June 2.Dat P. T. Nguyen, Yutaka Matsuo, and MitsuruIshizuka.
2007.
Exploiting syntactic and semanticinformation for relation extraction from wikipedia.In Proceedings of Workshop on Text-Mining & Link-Analysis (TextLink 2007) at IJCAI 2007, pages1414?1420, Hyderabad, India, January 7.67Dragomir R. Radev, Hong Q, Harris Wu, and WeiguoFan.
2002.
Evaluating web-based question answer-ing systems.
In Demo section, LREC 2002, Las Pal-mas, Spain, June.F.
M. Suchanek, G. Ifrim, and G. Wiekum.
2006.Leila: Learning to extract information by linguisticanalysis.
In Proceedings of the ACL-06 Workshopon Ontology Learning and Population, pages 18?25,Sydney, Australia, July.Zareen Saba Syed, Tim Finin, and Anupam Joshi.2008.
Wikitology: Using wikipedia as an ontology.Technical report, University of Maryland, BaltimoreCounty.Max Vo?lkel, Markus Kro?tzsch, Denny Vrandecic,Heiko Haller, and Rudi Studer.
2006.
Semanticwikipedia.
In WWW 2006, pages 585?594, Edin-burgh, Scotland.68
