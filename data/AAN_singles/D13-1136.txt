Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366?1371,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsConnecting Language and Knowledge Bases with Embedding Modelsfor Relation ExtractionJason WestonGoogle111 8th avenueNew York, NY, USAjweston@google.comAntoine BordesHeudiasycUT de Compi?gne& CNRSCompi?gne, Francebordesan@utc.frOksana YakhnenkoGoogle111 8th avenueNew York, NY, USAoksana@google.comNicolas UsunierHeudiasycUT de Compi?gne& CNRSCompi?gne, Francenusunier@utc.frAbstractThis paper proposes a novel approach for rela-tion extraction from free text which is trainedto jointly use information from the text andfrom existing knowledge.
Our model is basedon scoring functions that operate by learninglow-dimensional embeddings of words, enti-ties and relationships from a knowledge base.We empirically show on New York Times ar-ticles aligned with Freebase relations that ourapproach is able to efficiently use the extra in-formation provided by a large subset of Free-base data (4M entities, 23k relationships) toimprove over methods that rely on text fea-tures alone.1 IntroductionInformation extraction (IE) aims at generating struc-tured data from free text in order to populate Knowl-edge Bases (KBs).
Hence, one is given an incom-plete KB composed of a set of triples of the form(h, r , t); h is the left-hand side entity (or head), tthe right-hand side entity (or tail) and r the relation-ship linking them.
An example from the FreebaseKB1 is (/m/2d3rf ,<director-of>, /m/3/324), where/m/2d3rf refers to the director ?Alfred Hitchcock"and /m/3/324 to the movie ?The Birds".This paper focuses on the problem of learning toperform relation extraction (RE) under weak super-vision from a KB.
RE is sub-task of IE that consid-ers that entities have already been detected by a dif-ferent process, such as a named-entity recognizer.RE then aims at assigning to a relation mention m1www.freebase.com(i.e.
a sequence of text which states that some rela-tion is true) the corresponding relationship from theKB, given a pair of extracted entities (h, t) as con-text.
For example, given the triple (/m/2d3rf ,?wroteand directed", /m/3/324), a system should predict<director-of>.
The task is said to be weakly super-vised because for each pair of entities (h, t) detectedin the text, all relation mentions m associated withthem are labeled with all the relationships connect-ing h and t in the KB, whether they are actually ex-pressed by m or not.Our key contribution is a novel model that em-ploys not only weakly labeled text mention data, asmost approaches do, but also leverages triples fromthe known KB.
The model thus learns the plausi-bility of new (h, r , t) triples by generalizing fromthe KB, even though this triple is not present.
Aranking-based embedding framework is used to trainour model.
Thereby, relation mentions, entities andrelationships are all embedded into a common low-dimensional vector space, where scores are com-puted.
We show that our method can successfullytake into account information from a large-scale KB(Freebase: 4M entities, 23k relationships) to im-prove over systems that are only using text features.This paper is organized as follows: Section 2presents related work, Section 3 introduces ourmodel and its main influences, and experimental re-sults are displayed in Section 4.2 Previous WorkLearning under weak supervision is common in nat-ural language processing, especially for tasks wherethe annotation costs are significant such as in se-1366mantic parsing (Kate and Mooney, 2007; Liang etal., 2009; Bordes et al 2010; Matuszek et al2012).
This is also naturally used in IE, since itallows to train large-scale systems without requir-ing to label numerous texts.
The idea was intro-duced by (Craven et al 1999), which matched theYeast Protein Database with PubMed abstracts.
Itwas also used to train open extractors based onWikipedia infoboxes and corresponding sentences(Wu and Weld, 2007; Wu and Weld, 2010).
Large-scale open IE projects (e.g.
(Banko et al 2007))also rely on weak supervision, since they learn mod-els from a seed KB in order to extend it.Weak supervision is also a popular option for RE:Mintz et al(2009) used Freebase to train weakly su-pervised relational extractors on Wikipedia, an ap-proach generalized by the multi-instance learningframeworks (Riedel et al 2010; Hoffmann et al2011; Surdeanu et al 2012).
All these works onlyuse textual information to perform extraction.Lao et al(2012) proposed the first work aiming toperform RE employing both KB data and text, usinga rule-based random walk method.
Recently, Riedelet al(2013) proposed another joint approach basedon collaborative filtering for learning entity embed-dings.
This approach connects text with Freebaseby learning shared embeddings of entities throughweak supervision, in contrast to our method whereno joint learning is performed.
We do not compareto these two approaches since they use two differentevaluation protocols that greatly differ from thoseused in all aforementioned previous works.
Never-theless, our method is easier to integrate into exist-ing systems than those, since KB data is used viathe addition of a scoring term, which is trained sepa-rately beforehand (with no shared embeddings).
Be-sides, we demonstrate in our experimental sectionthat our system can handle a large number of rela-tionships, significantly larger than that presented in(Lao et al 2012; Riedel et al 2013).3 Embedding-based FrameworkOur work concerns energy-based methods, whichlearn low-dimensional vector representations (em-beddings) of atomic symbols (words, entities, re-lationships, etc.).
In this framework, we learn twomodels: one for predicting relationships given re-lation mentions and another one to encode the in-teractions among entities and relationships from theKB.
The joint action of both models in predictionallows us to use the connection between the KB andtext to perform relation extraction.
One could alsoshare parameters between models (via shared em-beddings), but this is not implemented in this work.This approach is inspired by previous work designedto connect words and Wordnet (Bordes et al 2012).Both submodels end up learning vector embed-dings of symbols, either for entities or relationshipsin the KB, or for each word/feature of the vocabulary(denoted V).
The set of entities and relationships inthe KB are denoted by E and R, and nv , ne and nrdenote the size of V , E and R respectively.
Givena triple (h, r , t) the embeddings of the entities andthe relationship (vectors in Rk ) are denoted with thesame letter, in boldface characters (i.e.
h, r, t).3.1 Connecting Text and RelationshipsThe first part of the framework concerns the learn-ing of a function Sm2r (m, r), based on embeddings,that is designed to score the similarity of a relationmention m and a relationship r .Our scoring approach is inspired by previouswork for connecting word labels and images (We-ston et al 2010), which we adapted, replacing im-ages by mentions and word labels by relationships.Intuitively, it consists of first projecting words andfeatures into the embedding space and then comput-ing a similarity measure (the dot product in this pa-per) between this projection and a relationship em-bedding.
The scoring function is then:Sm2r (m, r) = f(m)>rwith f a function mapping words and features intoRk , f(m) = W>?(m).
W is the matrix of Rnv?kcontaining all word embeddings w, ?
(m) is the(sparse) binary representation of m (?
Rnv ) indi-cating absence or presence of words/features, andr ?
Rk is the embedding of the relationship r .This approach can be easily applied at test time toscore (mention, relationship) pairs.
Since this typeof learning problem is weakly supervised, Bordes etal.
(2010) showed that a convenient way to train itis by using a ranking loss.
Hence, given a data setD = {(mi , ri ), i = 1, ... , |D|} consisting of (men-tion, relationship) training pairs, one could learn the1367embeddings using constraints of the form:?i , ?r ?
6= ri , f(mi )>ri > 1 + f(mi )>r?
, (1)where 1 is the margin.
That is, we want the re-lation that (weakly) labels a given mention to bescored higher than other relation by a margin of 1.Then, given any mention m one can predict the cor-responding relationship r?
(m) with:r?
(m) = arg maxr ?
?RSm2r (m, r ?)
= arg maxr ??R(f(m)>r?
).Learning Sm2r (?)
under constraints (1) is wellsuited when one is interested in building a per-mention prediction system.
However, performancemetrics of relation extraction are sometimes mea-sured using precision recall curves aggregated forall mentions concerning the same pair of entities,as in (Riedel et al 2010).
In that case the scoresacross predictions for different mentions need to becalibrated so that the most confident ones have thehigher scores.
This can be better encoded with con-straints of the following form:?i , j , ?r ?
6= ri , rj , f(mi )>ri > 1 + f(mj)>r?
.In this setup, scores of pairs observed in the trainingset should be larger than that of any other predictionacross all mentions.
In practice, we use ?soft?
rank-ing constraints (optimizing the hinge loss), i.e.
weminimize:?i , j , ?r ?
6= ri , rj , max(0, 1?f(mi )>ri +f(mj)>r?
).Finally, we also enforce a (hard) constraint on thenorms of the columns of W and r, i.e.
?i , ||Wi ||2 ?1 and ?j , ||rj ||2 ?
1.
Training is carried out byStochastic Gradient Descent (SGD), updating Wand r at each step, following (Weston et al 2010;Bordes et al 2013).
That is, at the start of trainingthe parameters to be learnt (the nv ?
k word/featureembeddings in W and the nr ?
k relation embed-dings r ) are initialized to random weights.
We ini-tialize each k-dimensional embedding vector ran-domly with mean 0, standard deviation 1k .
Then, weiterate the following steps to train them:1.
Select at random a positive training pair(mi , ri ).2.
Select at random a secondary training pair(mj , rj), used to calibrate the scores.3.
Select at random a negative relation r ?
such thatr ?
6= ri and r ?
6= rj .4.
Make a stochastic gradient step to minimizemax(0, 1?
f(mi )>ri + f(mj)>r?).5.
Enforce the constraint that each embeddingvector is normalized, i.e.
if ||Wi ||2 > 1 thenWi ?Wi/||Wi ||2.3.2 Encoding Structured Data of KBsUsing only weakly labeled text mentions for train-ing ignores much of the prior knowledge we canleverage from a large KB such as Freebase.
In or-der to connect this relational data with our model,we propose to encode its information into entity andrelationship embeddings.
This allows us to build amodel which can score the plausibility of new en-tity relationship triples which are missing from Free-base.
Several models have been recently developedfor that purpose (e.g.
in (Nickel et al 2011; Bor-des et al 2011; Bordes et al 2012)): we chose inthis work to follow the approach of (Bordes et al2013), which is simple, flexible and has shown verypromising results on Freebase data.Given a training set S = {(hi , ri , ti ), i =1, ... , |S|} of relations extracted from the KB, thismodel learns vector embeddings of the entities andof the relationships using the idea that the func-tional relation induced by the r -labeled arcs of theKB should correspond to a translation of the em-beddings.
That is, given a k-dimensional embed-ding of the left-hand side (head) entity, adding thek-dimensional embedding of a given relation shouldyield the point (or close to the point) of the k-dimensional embedding of the right-hand side (tail)entity.
Hence, this method enforces that h + r ?
twhen (h, r , t) holds, while h + r should be far awayfrom t otherwise.
The model thus gives the follow-ing score for the plausibility of a relation:Skb(h, r , t) = ?||h + r ?
t||22 .A ranking loss is also used for training Skb.
Theranking objective is designed to assign higher scores1368to existing relations versus any other possibility:?i ,?h?
6= hi , Skb(hi , ri , ti ) ?
1 + Skb(h?, ri , ti ),?i ,?r ?
6= ri , Skb(hi , ri , ti ) ?
1 + Skb(hi , r ?, ti ),?i ,?t ?
6= ti , Skb(hi , ri , ti ) ?
1 + Skb(hi , ri , t ?
).That is, for each known triple (h, r , t), if we re-placed the (i) head, (ii) relation or (iii) tail with someother possibility, the modified triple should have alower score (i.e.
be less plausible) than the originaltriple.
The three sets of constraints defined aboveencode the three types of modification.
As in Sec-tion 3.1 we use soft constraints via the hinge loss,enforce constraints on the norm of embeddings, i.e.
?h,r ,t , ||h||2 ?
1, ||r ||2 ?
1, ||t||2 ?
1, and trainingis performed using SGD, as in (Bordes et al 2013).At test time, one may again need to calibrate thescores Skb across entity pairs.
We propose a sim-ple approach: we convert the scores by ranking allrelationshipsR by Skb and instead output:S?kb(h, r , t)=?
(?r ?
6=r?
(Skb(h, r , t)>Skb(h, r?, t))),i.e.
a function of the rank of r .
We chose the simpli-fied model ?
(x) = 1 if x < ?
and 0 otherwise; ?(?
)is the Kronecker function.3.3 Implementation for Relation ExtractionOur framework can be used for relation extractionin the following way.
First, for each pair of entities(h, t) that appear in the test set, all the correspond-ing mentionsMh,t in the test set are collected and aprediction is performed with:r?h,t = argmaxr?R?m?Mh,tSm2r (m, r) .The predicted relationship can either be a valid re-lationship or NA ?
a marker that means that there isno relation between h and t (NA is added to R dur-ing training and is treated like other relationships).If r?h,t is a relationship, a composite score is defined:Sm2r+kb(h, r?h,t , t)=?m?Mh,tSm2r (m, r?h,t)+S?kb(h, r?h,t , t)That is, only the top scoring non-NA predictions arere-scored.
Hence, our final composite model favorspredictions that agree with both the mentions and theKB.
If r?h,t is NA, the score is unchanged.4 ExperimentsWe use the training and test data, evaluation frame-work and baselines from (Riedel et al 2010; Hoff-mann et al 2011; Surdeanu et al 2012).NYT+FB This dataset, developed by (Riedel etal., 2010), aligns Freebase relations with the NewYork Times corpus.
Entities were found using theStanford named entity tagger (Finkel et al 2005),and were matched to their name in Freebase.
Foreach mention, sentence level features are extractedwhich include part of speech, named entity and de-pendency tree path properties.
Unlike some of theprevious methods, we do not use features that aggre-gate properties across multiple mentions.
We keptthe 100,000 most frequent features.There are 52 pos-sible relationships and 121,034 training mentions ofwhich most are labeled as no relation (labeled ?NA?)?
there are 4700 Freebase relations mentioned in thetraining set, and 1950 in the test set.Freebase Freebase is a large-scale KB that hasaround 80M entities, 23k relationships and 1.2B re-lations.
We used a subset restricted to the top 4Mentities for scalability reasons ?
where top is definedas the ones with the largest number of relations toother entities.
We used all the 23k possible relation-ships in Freebase.
To make a realistic setting, wedid not choose the entity set using the NYT+FB dataset, so it may not overlap completely.
For that rea-son, we needed to keep the set rather large.
Keepingthe top 4M entities gives an overlap of 80% with theentities in the NYT+FB test set.
Most importantly,we then removed all the entity pairs present in theNYT+FB test set from Freebase, i.e.
all relationsthey are involved in independent of the relationship.This ensures that we cannot just memorize the truerelations for an entity pair ?
we have to learn to gen-eralize from other entities and relations.As the NYT+FB dataset was built on an earlierversion of Freebase we also had to translate the dep-recated relationships into their new variants (e.g.
?/p/business/company/place_founded ?
?
?/orga-nization/organization/place_founded?)
to make thetwo datasets link (then, the 52 relationships inNYT+FB are now a subset of the 23k from Free-base).
We then trained the Skb model on the remain-ing triples.1369recallprecision0 0.1 0.200.10.20.30.40.50.60.70.80.9Wsabie M2R+FBMIMLREHoffmannWsabie M2RRiedelMintzrecallprecision0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10.40.50.60.70.80.9 Wsabie M2R+FBMIMLREHoffmannWsabie M2RRiedelMintzFigure 1: Top: Aggregate extraction precision/recallcurves for a variety of methods.
Bottom: thesame plot zoomed to the recall [0-0.1] region.WsabieM2R is our method trained only on mentions,WsabieM2R+FB uses Freebase annotations as well.Modeling Following (Bordes et al 2013) we setthe embedding dimension k to 50.
The learning ratefor SGD was selected using a validation set: we ob-tained 0.001 for Sm2r , and 0.1 for Skb.
For the cal-ibration of S?kb, ?
= 10 (note, here we are rankingall 23k Freebase relationships).
Training Sm2r took5 minutes, whilst training Skb took 2 days due to thelarge scale of the data set.Results Figure 1 displays the aggregate precision/ recall curves of our approach WSABIEM2R+FBwhich uses the combination of Sm2r + Skb, as wellas WSABIEM2R , which only uses Sm2r , and existingstate-of-the-art approaches: HOFFMANN (Hoffmannet al 2011)2, MIMLRE (Surdeanu et al 2012).RIEDEL (Riedel et al 2010) and MINTZ (Mintz etal., 2009).WSABIEM2R is comparable to, but slightly worsethan, the MIMLRE and HOFFMANN methods, possi-bly due to its simplified assumptions (e.g.
predict-ing a single relationship per entity pair).
However,the addition of extra knowledge from other Freebaseentities in WSABIEM2R+FB provides superior per-formance to all other methods, by a wide margin, atleast between 0 and 0.1 recall (see bottom plot).Performance of WSABIEM2R andWSABIEM2R+FB for recall > 0.1 degrades rapidly,faster than that of other methods.
This is alsocaused by the simplifications of WSABIEM2R thatprevent it from reaching high precision when therecall is greater than 0.1.
We recall that Freebasedata is not used to detect relationships i.e.
todiscriminate between NA and the rest, but only toselect the best relationship in case of detection.That is WSABIEM2R+FB only improves precision,not recall, so both versions of Wsabie are similarw.r.t.
recall.
This could be improved by borrowingideas from HOFFMANN (Hoffmann et al 2011) orMIMLRE (Surdeanu et al 2012) for dealing withthe multi-label case.
Our approach, which usesFreebase to increase precision, is general and couldimprove any other method.5 ConclusionIn this paper we described a framework for leverag-ing large scale knowledge bases to improve relationextraction by training not only on (mention, relation-ship) pairs but using all other KB triples as well.
Weempirically showed that it allows to significantly im-prove precision on extracted relations.
Our model-ing approach is general and should apply to othersettings, e.g.
for the task of entity linking.AcknowledgmentsThis work was carried out in the framework ofthe Labex MS2T (ANR-11-IDEX-0004-02), andfunded by the French National Agency for Research(EVEREST-12-JS02-005-01).2There is an error in the plot from (Hoffmann et al 2011),which we have corrected.
The authors acknowledged this issue.1370ReferencesMichele Banko, Michael J Cafarella, Stephen Soderland,Matthew Broadhead, and Oren Etzioni.
2007.
Openinformation extraction from the web.
In IJCAI, vol-ume 7, pages 2670?2676.Antoine Bordes, Nicolas Usunier, and Jason Weston.2010.
Label ranking under ambiguous supervision forlearning semantic correspondences.
In Proceedings ofthe 27th International Conference on Machine Learn-ing (ICML-10), pages 103?110.Antoine Bordes, Jason Weston, Ronan Collobert, andYoshua Bengio.
2011.
Learning structured embed-dings of knowledge bases.
In Proc.
of the 25th Conf.on Artif.
Intel.
(AAAI).Antoine Bordes, Xavier Glorot, Jason Weston, andYoshua Bengio.
2012.
Joint learning of words andmeaning representations for open-text semantic pars-ing.
In Proc.
of the 15th Intern.
Conf.
on Artif.
Intel.and Stat., volume 22, pages 127?135.
JMLR.Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,Jason Weston, and Oksana Yakhnenko.
2013.
Trans-lating embeddings for modeling multi-relational data.In Advances in Neural Information Processing Sys-tems (NIPS 26).Mark Craven, Johan Kumlien, et al1999.
Constructingbiological knowledge bases by extracting informationfrom text sources.
In ISMB, volume 1999, pages 77?86.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In Proceedings of the 43rd Annual Meeting on Associ-ation for Computational Linguistics, pages 363?370.Association for Computational Linguistics.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S Weld.
2011.
Knowledge-based weak supervision for information extraction ofoverlapping relations.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, vol-ume 1, pages 541?550.Rohit J Kate and Raymond J Mooney.
2007.
Learninglanguage semantics from ambiguous supervision.
InAAAI, volume 7, pages 895?900.Ni Lao, Amarnag Subramanya, Fernando Pereira, andWilliam W Cohen.
2012.
Reading the web withlearned syntactic-semantic inference rules.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, pages 1017?1026.
Association for Computational Linguistics.Percy Liang, Michael I Jordan, and Dan Klein.
2009.Learning semantic correspondences with less supervi-sion.
In Proceedings of the Joint Conference of the47th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP: Volume 1-Volume 1, pages 91?99.Association for Computational Linguistics.Cynthia Matuszek, Nicholas FitzGerald, Luke Zettle-moyer, Liefeng Bo, and Dieter Fox.
2012.
A jointmodel of language and perception for grounded at-tribute learning.
In Proceedings of the InternationalConference on Machine Learning.Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 2-Volume 2,pages 1003?1011.
Association for Computational Lin-guistics.Maximilian Nickel, Volker Tresp, and Hans-PeterKriegel.
2011.
A three-way model for collectivelearning on multi-relational data.
In Proceedings ofthe 28th International Conference on Machine Learn-ing (ICML-11), pages 809?816.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions with-out labeled text.
In Machine Learning and KnowledgeDiscovery in Databases, pages 148?163.
Springer.Sebastian Riedel, Limin Yao, Andrew McCallum, andBenjamin M Marlin.
2013.
Relation extraction withmatrix factorization and universal schemas.
In Pro-ceedings of NAACL-HLT, pages 74?84.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, andChristopher D Manning.
2012.
Multi-instance multi-label learning for relation extraction.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 455?465.
Associa-tion for Computational Linguistics.Jason Weston, Samy Bengio, and Nicolas Usunier.
2010.Large scale image annotation: learning to rank withjoint word-image embeddings.
Machine learning,81(1):21?35.Fei Wu and Daniel S Weld.
2007.
Autonomously se-mantifying wikipedia.
In Proceedings of the sixteenthACM conference on Conference on information andknowledge management, pages 41?50.
ACM.Fei Wu and Daniel S Weld.
2010.
Open information ex-traction using wikipedia.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, pages 118?127.
Association for Computa-tional Linguistics.1371
