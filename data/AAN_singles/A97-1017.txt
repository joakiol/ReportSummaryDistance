Probabi l i s t ic  and Ru le -Based  Tagger of an Inf lect iveLanguage-  a Compar i sonJan Haji~ and Barbora  H ladk~iInstitute of Formal and Applied LinguisticsFacu l ty  of  Mathemat ics  and  Phys icsMa los t ransk~ n?m.
25CZ-118 00 Prague  1e -maih  (ha j i c ,h ladka}  ~ufa l .mf f .
cun i .
czAbst rac tWe present results of probabilistic tag-ging of Czech texts in order to show howthese techniques work for one of the highlymorphologically ambiguous inflective lan-guages.
After description of the tag systemused, we show the results of four experi-ments using a simple probabilistic modelto tag Czech texts (unigram, two bigramexperiments, and a trigram one).
For com-parison, we have applied the same code andsettings to tag an English text (anotherfour experiments) using the same size oftraining and test data in the experiments inorder to avoid any doubt concerning the va-lidity of the comparison.
The experimentsuse the source channel model and maxi-mum likelihood training on a Czech hand-tagged corpus and on tagged Wall StreetJournal (WSJ) from the LDC collection.The experiments how (not surprisingly)that the more training data, the better isthe success rate.
The results also indicatethat for inflective languages with 1000+tags we have to develop a more sophisti-cated approach in order to get closer to anacceptable rror rate.
In order to comparetwo different approaches to text tagging - -statistical and rule-based - -  we modifiedEric Brill's rule-based part of speech tag-ger and carried out two more experimentson the Czech data, obtaining similar resultsin terms of the error rate.
We have alsorun three more experiments with greatlyreduced tagset to get another comparisonbased on similar tagset size.1 INTRODUCTIONLanguages with rich inflection like Czech pose aspecial problem for morphological disambiguation(which is usually called tagging1).
For example, theending "-u" is not only highly ambiguous, but at thesame time it carries complex information: it corre-sponds to the genitive, the dative and the locativesingular for inanimate nouns, or the dative singu-lar for animate nouns, or the accusative singular forfeminine nouns, or the first person singular presenttense active participle for certain verbs.
There aretwo different echniques for text tagging: a stochas-tic technique and a rule-based technique.
Each ap-proach has some advantages - - for stochastic tech-niques there exists a good theoretical framework,probabilities provide a straightforward way how todisambiguate tags for each word and probabilitiescan be acquired automatically from the data; forrule-based techniques the set of meaningful rules isautomatically acquired and there exists an easy wayhow to find and implement improvements of the tag-ger.
Small set of rules can be used, in contrast o thelarge statistical tables.
Given the success of statis-tical methods in different areas, including text tag-ging, given the very positive results of English statis-tical taggers and given the fact that there existed nostatistical tagger for any Slavic language we wantedto apply statistical methods even for the Czech lan-guage although it exhibits a rich inflection accom-panied by a high degree of ambiguity.
Originally,we expected that the result would be plain negative,getting no more than about two thirds of the tagscorrect.
However, as we show below, we got bet-ter results than we had expected.
We used the samestatistical approach to tag both the English text andthe Czech text.
For English, we obtained resultscomparable with the results presented in (Merialdo,1992) as well as in (Church, 1992).
For Czech, we ob-tained results which are less satisfactory than thosefor English.
Given the comparabil ity of the accu-racy of the rule-based part-of-speech (POS) tagger(Brill, 1992) with the accuracy of the stochastic tag-IThe development of automatic tagging of Czechis/was supported fully or partially by the fol-lowing grants/projects: Charles University GAUK39/94, Grant Agency of the Czech Republic GACR405/96/K214 and Ministry of Education VS96151.111ger and given the fact that a rule-based POS taggerhas never been used for a Slavic language we havetried to apply rule-based methods even for Czech.2 STAT IST ICAL  EXPERIMENTS2.1 CZECH EXPERIMENTS2.1.1 CZECH TAGSETCzech experiment is based upon ten basic POSclasses and the tags describe the possible combina-tions of morphological categories for each POS class.In most cases, the first letter of the tag denotes thepart-of-speech; the letters and numbers which followit describe combinations of morphological categories(for a detailed description, see Table 2.1 and TableCat.Var.seeTab.2.2)g2.2).Morph.Categ.Poss.
DescriptionVal.gender M masc.
anim.I masc.
inanim.N neuterF femininenumber n S singularP pluraltense t M pastP presentF futuremood m O indicativeR imperativecase c 1 nominative2 genitive3 dative4 accusative5 vocative6 locative7 instrumentalvoice s A active voiceP passive voicepolarity a N negativeA affirmativedeg.
of comp.
d 1 base form2 comparative3 superlativeperson p 1 1st2 2nd3 3rdTable 2.1Note especially, that Czech nouns are dividedinto four classes according to gender (Sgall, 1967)and into seven classes according to ease.POS Classnounsnoun, abbreviationsadjectivesNgncNZAgncdaverbs, infinitives VTaverbs, transgressives VWntsgaverbs, common Vpnstmgapronouns, personal PPpncpronouns, 3rd person PP3gncpronouns, possessive PRgncpgn"svfij" - - "h i s "  referring to PSgncsubjectreflexive particle "se" PEcpronouns, demonstrative PDgncaadverbs Od aconjunctions Snumerals C gncprepositions Rprepositioninterjections Fparticles Ksentence boundaries T_SBpunctuation T_IPunknown tag XTable 2.2Not all possible combinations of morphologicalcategories are meaningful, however.
In addition tothese usual tags we have used special tags for sen-tence boundaries, punctuation and a so called "un-known tag".
In the experiments, we used only thosetags which occurred at least once in the training cor-pus.
To illustrate the form of the tagged text, wepresent here the following examples from our train-ing data, with comments:word Itag #commentsdoIRdo #"to"(prepositions have theirown individuals tags)oddflulNIS2 #"uni t"(noun, masculine inani-mate, singular, genitive)kiRksnfdanilNFS3pou#,ijeIV3SAPOMAprolRpron?s\[PP1P4~:" for"(preposition)~"  breakfast"(noun, feminine, singular,dative)~" uses"(verb, 3rd person, singular,active,present, indicative, masc.animate, affirmative)#"for"(preposition)~" US"(pronoun, personal, 1stperson, plural, accusative)1122.1.2 CZECH TRAIN ING DATAFor training, we used the corpus collected dur-ing the 1960's and 1970's in the Institute for CzechLanguage at the Czechoslovak Academy of Sciences.The corpus was originally hand-tagged, includingthe lemmatization and syntactic tags.
We had todo some cleaning, which means that we have disre-garded the lemmatization i formation and the syn-tactic tag, as we were interested in words and tagsonly.
Tags used in this corpus were different fromour suggested tags: number of morphological cate-gories was higher in the original sample and the no-tation was also different.
Thus we had to carry outconversions of the original data into the format pre-sented above, which resulted in the so-called Czech"modified" corpus, with the following features:tokens 621 015words 72 445tags 1 171average number of tags per token 3.65Table 2.3V~Te used the complete "modified" corpus(621015 tokens) in the experiments No.
1, No.
3,No.
4 and a small part of this corpus in the experi-ment No.
2, as indicated in Table 2.4.tokens 110 874words 22 530tags 882average number of tags per token 2.36Table 2.42.2 ENGL ISH EXPERIMENTS2.2.1 ENGL ISH TAGSETFor the tagging of English texts, we used thePenn Treebank tagset which contains 36 POS tagsand 12 other tags (for punctuation and the currencysymbol).
A detailed description is available in (San-torini, 1990).2.2.2 ENGLISH TRAIN ING DATAFor training in the English experiments, we usedWSJ (Marcus et al, 1993).
We had to change theformat of WSJ to prepare it for our tagging soft-ware.
V~e used a small (100k tokens) part of WSJ inthe experiment No.
6 and the complete corpus (1Mtokens) in the experiments No.
5, No.
7 and No.8.
Table 2.5 contains the basic characteristics of thetraining data.tokenswordstagsaverage numberof tags per tokenExperiment ExperimentsNo.
6 No.
5, No.
7,No.
8110 530 1 287 74913 582 51 43345 451.72 2.34Table 2.52.3 CZECH VS ENGL ISHDifferences between Czech as a morphologically am-biguous inflective language and English as languagewith poor inflection are also reflected in the numberof tag bigrams and tag trigrams.
The figures givenin Table 2.6 and 2.7 were obtained from the trainingfiles.Czech WSJcorpusx<=4 24 064 x<--10 4594<x<=16 5 577 10<x<--100 41116<x<=64 2 706 100<x<=1000 358x>64 1 581 x>1000 225bigrams 33 928 bigrams 1 453Table 2.6 Number of bigrams with frequency xx<----44<x<=16Czechcorpus155 39916 371x<=lO10<x<=100WSJ11 8104 57116<x<=64 4 380 100<x<=1000 1 645x>64 933 x> 1000 231trigrams 177 083 trigrams 18 257Table 2.7 Number of trigrams with frequency xIt is interesting to note the frequencies of themost ambiguous tokens encountered in the whole"modified" corpus and to compare them with theEnglish data.
Table 2.8 and Table 2.9 contain thefirst tokens with the highest number of possible tagsin the complete Czech "modified" corpus and in thecomplete WSJ.Token Frequency #tagsin train, data in train, datajejich 1 087 51jeho 1 087 46jeho~ 163 35jejich~ 150 25vedoucl 193 22Table 2.8In the Czech "modified" corpus, the token "ve-douc/" appeared 193 times and was tagged by twentytwo different tags: 13 tags for adjective and 9 tags113for noun.
The token "vedoucf' means either: "lead-ing" (adjective) or "manager" or "boss" (noun).
Thefollowing columns represent the tags for the token"vedouc/" and their frequencies in the training data;for example "vedoucf' was tagged twice as adjective,feminine, plural, nominative, first degree, affirma-tive.2461114521131222vedouci\[AFPllAvedouci\[AFP41Avedoucl AFSllAvedouci AFS21Avedouci AFS31Avedoue~ AFS41Avedouci AFS71Avedoucl AIPl lAvedoucl A M P 11Avedouc{ AMP41Avedoucl AMSllAvedoucl ANPl lAvedoucl ANS41A10 vedouci1 vedouci1 vedouci1 vedoud2 vedoucl34 vedouci17 vedouci61 vedouc~1 vedouciNFS1NFS2NFS3NFS4NFS7NMP1NMP4NMS1NMS5Token Frequency #tagsin train, data in train, dataa 25 791 7down 1 052 7put 380 6set 362 6that 10 902 6the 56 265 6Table 2.9It is clear from these figures that the two lan-guages in question have quite different propertiesand that nothing can be said without really goingthrough an experiment.2.4 THE ALGORITHMWe have used the basic source channel model (de-scribed e.g.
in (Merialdo, 1992)).
The tagging pro-cedure ?
selects a sequence of tags T for the sentenceW: ?
: PV --+ T .
In this case the optimal taggingprocedure is?
(W) -- argmaxTPr(T \ [W)  =: a rgmaxTPr (T lW)  * P r (W)  == argrnaxTPr(W,T)  =-- a rgmaxTPr (W\[T)  * Pr(T) .Our implementation is based on generating the(W,T) pairs by means of a probabilistic modelusing approximations of probability distributionsPr (WIT)  and Pr(T) .
The Pr (T)  is based on tag bi-grams and trigrams, and Pr (WIT  ) is approximatedas the product of Pr(wi\[tl).
The parameters havebeen estimated by the usual maximum likelihoodtraining method, i.e.
we approximated them as therelative frequencies found in the training data withsmoothing based on estimated unigram probabilityand uniform distributions.2.5 THE RESULTSThe results of the Czech experiments are displayedin Table 2.10.No.
1 No.
2 No.
3 No.
4test data 1 294 1 294 1 294 1 294(tokens)prob.
unigram bigram bigram trigrammodelincorrecttagstaggingaccuracy44465.70%33474.19%23981.53%Table 2.1024481.14%These results show, not surprisingly, of course,that the more data, the better (results experimentsof No.2 vs. No.3), but in order to get better resultsfor a trigram tag prediction model, we would needfar more data.
Clearly, if 88% trigrams occur fourtimes or less, then the statistics is not reliable.
Thefollowing tables show a detailed analysis of the errorsof the trigram experiment.\[ \[\[A IC \[F \]K IN lOA 32 0 0 0 6 3C 0 4 0 0 1 0F 0 0 0 0 0 0K 0 0 0 0 0 0N 4 0 0 0 64 8O 0 0 0 0 1 0P 0 0 0 0 0 3R 0 0 0 0 1 1S 0 0 0 0 0 0V 0 0 0 0 3 8T 0 0 0 0 1 0X 0 0 0 0 0 0Table 2.11aI\] P \[ R I s I V I T I X IA 2 2 2 2 1 0 50C 0 0 0 0 0 0 5F 0 0 0 0 0 0 0K 0 0 1 0 0 1 2N 0 4 2 2 5 4 93O 0 0 0 1 1 0 3P 19 0 0 0 1 2 23R 0 0 0 0 0 2 4S 0 0 0 0 0 2 2V 0 3 8 28 1 2 53T 0 0 0 0 0 0 1X 5 0 1 2 0 0 8Table 2.11bThe letters in the first column and row denotePOS classes, the interpunction (T) and the "un-known tag" (X).
The numbers how how many timesthe tagger assigned an incorrect POS tag to a to-ken in the test file.
The total number of errors was244.
Altogether, fifty times the adjectives (A) were114tagged incorrectly, nouns (N) 93 times, numbers (C)5 times and etc.
(see the last unmarked column inTable 2.11b); to provide a better insight, we shouldadd that in 32 cases, when the adjective was cor-rectly tagged as an adjective, but the mistakes ap-peared in the assignment ofmorphological categories(see Table 2.12), 6 times the adjective was tagged asa noun, twice as a pronoun, 3 times as an adverband so on (see the second row in Table 2.11a).
Adetailed look at Table 2.12 reveals that for 32 cor-rectly marked adjectives the mistakes was 17 timesin gender, once in number, three times in gender andcase simultaneously and so on.\[ A\[\[ g \[ n \[ c I g&~ g&:~ c&:~ g&n~zc\[ g~zc&:d\[1321117\]1161 3 I 2 I 1 I 1 I 1 ITable 2.12Similar tables can be provided for nouns (Table2.13), numerals (Table 2.14), pronouns(Table 2.15)and verbs (Table 2.16a, Table 2.16b).N l\[ g In  t c I g&c \[ n&c I ->NZ \]64 \[\[ 11 \[ 5 \[ 41 \[ 2 \[ 4 \[ 1 \]Table 2.13Cl lg  c4 \[\[1 3Table 2.14P Ilg c g&c lVD->PV19l l8 7 3 I 1Table 2.15V I P t n I s  I n&t I p&t t&a I22\ ]3  6 5151 1 I 1 1 ITable 2.16av II gt~a I pan~t I v ->VT6 II 1 I1  \]4Table 2.16bThe results of our experiments with English aredisplayed in Table 2.17.test data(tokens)INo51 294No.
61 294INo.
71 294No.
81 294prob.
unigram bigram bigram trigrammodel13689.5%incorrecttags4196.83% taggingaccuracy8193.74%3797.14%Table 2.17To illustrate the results of our tagging experi-ments, we present here short examples taken fromthe test data.
Cases of incorrect ag assignment arein boldface.- -  Czechword\[hand tag exp.
exp.
exp.
exp.No.4 No.3 No.2 No.12na\[Rna Rna Rnapfid~\[NFS6 NFS6 NFS6vlasti\[NFS2 NFS2 NFS2rady\[NFS2 NFS2 NFS2~en\[NFP2 NFP2 NFP2Gusta\[NFS1 T_SB T_SBFu~ov?\[NFS1 NFS1 NFS1a\[SS SS SSp~edseda\[NMS1 NMS1 NMS1dv\[NZ NZ NZssm\[NZ NZ NZJuraj\[NMS1 NMS1 NMS1Varhol~\[NMS1 NMS1 NMS1- -  Englishword \[ hand tagRna RnaNFS6 NFS6NFS2 NFS2NFS2 NFS2NFP2 NFP2AFP21A XXNFP2 NFS1SS SSNMS1 NMS1NZ NZNZ NZNMS1 XXNMS1 NMS1exp.
exp.
exp.
exp.No.8 No.7 No.6 No.5With\[IN IN IN IN INstock\[NN NN NN NN NNprices\[NNS NNS NNS NNS NNShovering\[VBG VBG VBG IN VBGnear\[IN IN IN J J  INrecord\[NN NN NN NN NNlevels\[NNS NNS NNS NNS NNS,\[,alDT fiT fiT DT DTnumber\[NN NN NN NN NNof\[IN IN IN IN INcompanieslNNS NNS NNS NNS NNShave\[VBP VBP VBP VBP VBPbeen\[VBN VBN VBN VBN VBNannouncing\[VBG VBG VBG IN VBGstock\[NN NN NN NN NNsplits\]NNS NNS VBZ NN VBZ.\[.2.6 A PROTOTYPE OF  RANK XEROXPOS TAGGER FOR CZECH(Schiller, 1996) describes the general architecture ofthe tool for noun phrase mark-up based on finite-state techniques and statistical part-of-speech dis-ambiguation for seven European languages.
ForCzech, we created a prototype of the first step ofthis process - -  the part-of-speech (POS) tagger - -using Rank Xerox tools (Tapanainen, 1995), (Cut-ting et al, 1992).2.6.1 POS TAGSETThe first step of POS tagging is obviously a def-inition of the POS tags.
We performed three ex-2We used a speciM tag XX for unknown words.115periments.
These experiments differ in the POStagset.
During the first experiment we designedtagset which contains 47 tags.
The POS tagset canbe described as follows:Category Symbol Pos.ValueDescriptioncase c NOM nominativeGEN genitivebAT dativeACC accusativeVOC vocativelocativekindverbLOCINSINVPAPPRIINFIMPTRANminstrumentalinvariantpastpaticiplepresentparticipleinfinitiveimperativetransgressive2.6.2 RESULTSFigures representing the results of all experi-ments are presented in the following table.
We havealso included the results of English tagging using thesame Xerox tools.language tagsCzech 47Czech 43Czech 34English _\[ 76ambiguity ~39%36%14%36%taggingaccuracy91.7%93.0%96.2%97.8%Table 2.20The results how that the more radical reductionof Czech tags (from 1171 to 34) the higher accuracyof the results and the more comparable are the Czechand English results.
However, the difference in theerror rate is still more than visible - -  here we canspeculate that the reason is that Czech is "free" wordorder language, whereas English is not.Table 2.18POS tag DescriptionNOUN_c nouns + caseADJ_c adjectives + casePRON_c pronouns + caseNUM_c numerals + caseVERB_k verbs + kind of verbADV adverbsPROPPREPproper namesprepositionsPSE reflexive particles "se"CLIT cliticsCONJINTJconjunctionsinterjectionsPTCL particlesDATE datesCM commaPUNCT interpunctionSENT sentence bundariesTable 2.19The analysis of the results of the first experimentshowed very high ambiguity between the nominativeand accusative cases of nouns, adjectives, pronounsand numerals.
That is why we replaced the tagsfor nominative and accusative of nouns, adjectives,pronouns and numerals by new tags NOUNANA,ADJANA, PRONANA and NUMANA (meaning nom-inative or accusative, undistinguished).
The rest ofthe tags stayed unchanged.
This led 43 POS tags.In the third experiment we deleted the morphologi-cal information for nouns and adjectives alltogether.This process resulted in the final 34 POS tags.3 A RULE-BASED EXPERIMENTFOR CZECHA simple rule-based part of speech (RBPOS) tag-ger is introduced in (Brill, 1992).
The accuracy ofthis tagger for English is comparable to a stochas-tic English POS tagger.
From our point of view, itis very interesting to compare the results of Czechstochastic POS (SPOS) tagger and a modified RB-POS tagger for Czech.3.1 TRAIN ING DATAWe used the same corpus used in the case of theSPOS tagger for Czech.
RBPOS requires differentinput format; we thus converted the whole corpusinto this format, preserving the original contents.3.2 LEARNINGIt is an obvious fact that the Czech tagset is totallydifferent from the English tagset.
Therefore, we hadto modify the method for the initial guess.
For Czechthe algorithm is: "If the word is W_SB (sentenceboundary) assign the tag T_SB, otherwise assign thetag NNSI.
"3.2.1 LEARNING RULES TO PREDICTTHE MOST L IKELY  TAG FORUNKNOWN WORDSThe first stage of training is learning rules topredict the most likely tag for unknown words.These rules operate on word types; for example, if3The percentage ofambiguous word forms in the testfile.116a word ends by "d37;, it is probably a masculine ad-jective.
To compare the influence of the size of thetraining files on the accuracy of the tagger we per-formed two subexperiments4:TAGGED-CORPUS(tokens)TAGGED-CORPUS(words)TAGGED-CORPUS(tags)No.
1 No.
215 297 5 031738 495UNTAGGED-CORPUS 621 015 621 015(tokens)72 445 72 445 UNTAGGED-CORPUS(words)101 LEXRULEOUTFILE(rules)75Table 3.1We present here an example of rules taken fromLEXRULEOUTFILE from the exp.
No.
1:u hassuf 1 NIS2 # change the tag to NIS2if the suffix is "u"y hassuf 1 NFS2 # change the tag to NFS2if the suffix is "y"ho hassuf 2 AIS21A # change the tag to AIS21Aif the suffix is "ho"?ch hassuf 3 NFP6 # change the tag to NFP6if the suffix is "?ch"nej addpref 3 O2A # change the tag to O2Aif adding the prefix "nej"results in a word3.2 .2  LEARNING CONTEXTUAL CUESThe second stage of training is learning rules toimprove tagging accuracy based on contextual cues.These rules operate on individual word tokens.4We use the same names of files and variables asEric Brill in the rule-based POS tagger's documenta-tion.
TAGGED-CORPUS - -  manually tagged train-ing corpus, UNTAGGED-CORPUS - -  collection ofall untagged texts, LEXRULEOUTFILE - -  the listof transformations to determine the most likely tagfor unknown words, TAGGED-CORPUS-2 - -  manuallytagged training corpus, TAGGED-CORPUS-ENTIRE- -  Czech "modified" corpus (the entire manually taggedcorpus), CONTEXT-RULEFILE - -  the list of transfor-mations to improve accuracy based on contextual cues.No.
1 No.
2TAGGED-CORPUS-2 37 892 9 989(tokens)TAGGED-CORPUS-2 12 676 4 635(words)TAGGED-CORPUS-2 717 479(tags)TAGGED-ENTIRE-CORPUS 621 015 621 015(tokens)TAGGED-ENTIRE-CORPUS 72 445 72 445(words)TAGGED-ENTIRE-CORPUS 1 171 1 171(tags)CONTEXT-RULEFILE 487 61(rules)Table 3.2We present here an example of the rules takenfrom CONTEXT-RULEF ILE  from the exp.
No.
1:AFP21A AIP21A # change the tagAFP21A to AIP21ANEXT1OR2TAG if the following tag isNIP2 NIP2NIS2 NIS6PREV1OR2OR3TAGRv# change the tag NIS2to NIS6if the preceding tag isRvNIS1 NIS4 # change the tag NIS1to NIS4PREVIOR2TAG if the preceding tag isRna Rna3.2.3 RESULTSThe tagger was tested on the same test file asfor the statistical experiments.
We obtained the fol-lowing results:ITEST-FILEerrorstagging accuracyII No.
1 No.
21 294 1 294262 29479.75% 77.28%Table 3.
34 CONCLUSIONThe results, though they might seem negative com-pared to English, are still better than our original ex-pectations.
Before trying some completely differentapproach, we would like to improve the current sim-ple approach by some other simple measures: addinga morphological nalyzer (Hajji, 1994) as a front-end to the tagger (serving as a "supplier" of pos-sible tags, instead of just taking all tags occurringin the training data for a given token), simplifyingthe tagset, adding more data.
However, the desiredpositive effect of some of these measures i not guar-anteed: for example, the average number of tags per117token will increase after a morphological nalyzeris added.
Success should be guaranteed, however,by certain tagset reductions, as the original tagset(even after the reductions mentioned above) is stilltoo detailed.
This is especially true when comparingit to English, where some tags represent, in fact, aset of tags to be discriminated later (if ever).
For ex-ample, the tag VB used in the WSJ corpus actuallymeans "one of the (five different) tags for 1st personsg., 2nd person sg., 1st person pl., etc.".
First, wewill reduce the tagset o correspond to our morpho-logical analyzer which already uses a reduced one.Then, the tagset will be reduced even further, butnevertheless, not as much as we did for the Xerox-tools-based experiment, because that tagset is too"rough" for many applications, even though the re-sults are good.Regarding tagset reduction, we should note thatwe haven't performed a "combined" experiment, i.e.using the full (1100+) tagset for (thus) "interme-diate" tagging, but only the reduced tagset for thefinal results.
However, it can be quite simply derivedfrom the tables 2.10, 2.11a and 2.11b, that the errorrate would not drop much: it will remain high atabout 6.5070 (based on the results of experiment No.4) using the very small tagset of 12 (= number orlines in table 2.11a) tags used for part of speech iden-tification.
This is even much higher than the errorrate reported here for the smallest tagset used in the'pure' experiment (sect.
2.6, table 2.20), which wasat 3.8~0.
This suggests that maybe the pure meth-ods (which are obviously also simple to implement)are in general better than the "combined" methods.Another possibility of an improvement is to addmore data to allow for more reliable trigram esti-mates.
We will also add contemporary newspapertexts to our training data in order to account forrecent language development.
Hedging against fail-ure of all these simple improvements, we are alsoworking on a different model using independent pre-dictions for certain grammatical categories (and thelemma itself), but the final shape of the model hasnot yet been determined.
This would mean to intro-duce constraints on possible combinations of mor-phological categories and take them into accountwhen "assembling" the final tag.ACKNOWLEDGMENTS: The authors wish tothank Eva Hajidovd for her comments and sugges-tions and Eric BriU, Jean-Pierre Chanod and AnneSchiller who made their software tools available.Eric Brill.
1993.
A Corpus Based Approach To Lan-guage Learning.
PhD Dissertation, Departmentof Computer and Information Science, Univer-sity of Pennsylvania.Eric Brill.
1994.
Some Advances in Transformation--Based Part of Speech Tagging.
In: Proceedingsof the Twelfth National Conference on ArtificialIntelligence.Jan Haji~.
1994.
Unification Morphology Gram-mar.
PhD Dissertation, Institute of Formal andApplied Linguistics, Charles University, Prague,Czech Republic.Kenneth W. Church.
1992.
Current Practice In PartOf Speech Tagging And Suggestions For TheFuture.
For Henry Ku~era, Studies in SlavicPhilology and Computational Linguistics, Michi-gan Slavic Publications, Ann Arbor.Doug Cutting, Julian Kupiec, Jan Pedersen andPenelope Sibun 1992.
A Practical Part-of-Speech Tagger.
In: Proceedings of the ThirdConference on Applied Natural Language Pro-cessing , Trento, Italy.Mitchell P. Marcus, Beatrice Santorini, and Mary-Ann Marcinkiewicz 1993.
Building A LargeAnnotated Corpus Of English: The Penn Tree-bank.
Computational Linguistics, 19(2):313--330.Bernard Merialdo.
1992.
Tagging Text With AProbabilistie Model.
Computational Linguis-tics, 20(2):155--171Beatrice Santorini.
1990.
Part Of Speech Tag-ging Guidelines For The Penn Treebank Project.Technical report MS-CIS-90-47, Department ofComputer and Information Science, Universityof Pennsylvania.Anne Schiller.
1996.
Multilingual Finite-State NounPhrase Extraction.
ECAI'96, Budapest, Hun-gary.Petr Sgall.
1967.
The Generative Description of aLanguage and the Czech Declension (In Czech).Studie a prdce lingvistickd, 6.
Prague.Pasi Tapanalnen.
1995.
RXRC Finite-State Com-piler.
Technical Report MLTT-20, Rank XeroxResearch Center, Meylen, France.Re ferencesEric Brill.
1992.
A Simple Rule-Based Part ofSpeech Tagger.
In: Proceedings of the ThirdConference on Applied Natural Language Pro-cessing, Trento, Italy.118
