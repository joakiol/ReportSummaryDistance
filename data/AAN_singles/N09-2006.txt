Proceedings of NAACL HLT 2009: Short Papers, pages 21?24,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsA Simplex Armijo Downhill Algorithm forOptimizing Statistical Machine Translation Decoding ParametersBing ZhaoIBM T.J. Watson Researchzhaob@us.ibm.comShengyuan ChenIBM T.J. Watson Researchsychen@us.ibm.comAbstractWe propose a variation of simplex-downhill algo-rithm specifically customized for optimizing param-eters in statistical machine translation (SMT) de-coder for better end-user automatic evaluation met-ric scores for translations, such as versions of BLEU,TER and mixtures of them.
Traditional simplex-downhill has the advantage of derivative-free com-putations of objective functions, yet still gives satis-factory searching directions in most scenarios.
Thisis suitable for optimizing translation metrics as theyare not differentiable in nature.
On the other hand,Armijo algorithm usually performs line search ef-ficiently given a searching direction.
It is a deephidden fact that an efficient line search methodwill change the iterations of simplex, and hencethe searching trajectories.
We propose to embedthe Armijo inexact line search within the simplex-downhill algorithm.
We show, in our experiments,the proposed algorithm improves over the widely-applied Minimum Error Rate training algorithm foroptimizing machine translation parameters.1 IntroductionA simple log-linear form is used in SMT systems tocombine feature functions designed for identifying goodtranslations, with proper weights.
However, we often ob-serve that tuning the weight associated with each featurefunction is indeed not easy.
Starting from a N-Best listgenerated from a translation decoder, an optimizer, suchas Minimum Error Rate (MER) (Och, 2003) training, pro-poses directions to search for a better weight-vector ?
tocombine feature functions.
With a given ?, the N-Bestlist is re-ranked, and newly selected top-1 hypothesis willbe used to compute the final MT evaluation metric score.Due to limited variations in the N-Best list, the nature ofranking, and more importantly, the non-differentiable ob-jective functions used for MT (such as BLEU (Papineni etal., 2002)), one often found only local optimal solutionsto ?, with no clue to walk out of the riddles.Automatic evaluation metrics of translations known sofar are designed to simulate human judgments of trans-lation qualities especially in the aspects of fluency andadequacy; they are not differentiable in nature.
Simplex-downhill algorithm (Nelder and Mead, 1965) does notrequire the objective function to be differentiable, andthis is well-suited for optimizing such automatic met-rics.
MER searches each dimension independently in agreedy fashion, while simplex algorithms consider themovement of all the dimensions at the same time viathree basic operations: reflection, expansion and contrac-tion, to shrink the simplex iteratively to some local op-timal.
Practically, as also shown in our experiments, weobserve simplex-downhill usually gives better solutionsover MER with random restarts for both, and reachesthe solutions much faster in most of the cases.
How-ever, simplex-downhill algorithm is an unconstrained al-gorithm, which does not leverage any domain knowledgein machine translation.
Indeed, the objective functionused in SMT is shown to be a piece-wise linear prob-lem in (Papineni et al, 1998), and this motivated us toembed an inexact line search with Armijo rules (Armijo,1966) within a simplex to guide the directions for itera-tive expansion, reflection and contraction operations.
Ourproposed modification to the simplex algorithm is an em-bedded backtracking line search, and the algorithm?s con-vergence (McKinnon, 1999) still holds, though it is con-figured specially here for optimizing automatic machinetranslation evaluation metrics.The remainder of the paper is structured as follow: webriefly introduce the optimization problem in section 2;in section 3, our proposed simplex Armijo downhill al-gorithm is explained in details; experiments comparingrelevant algorithms are in section 4; the conclusions anddiscussions are given in section 5.2 NotationsLet {(ei,k, c?i,k, Si,k), k ?
[1,K]} be the K-Best listfor a given input source sentence fi in a developmentdataset containing N sentences.
ei,k is a English hy-pothesis at the rank of k; c?i,k is a cost vector ?
avector of feature function values, with M dimensions:c?i,k = (ci,k,1, ci,k,2 .
.
.
ci,k,M ); Si,k is a sentence-leveltranslation metric general counter (e.g.
ngram hits forBLEU, or specific types of errors counted in TER, etc.
)for the hypothesis.
Let ??
be the weight-vector, so that thecost of ei,k is an inner product: C(ei,k) = ??
?
c?i,k.
Theoptimization process is then defined as below:k?
(wrt i) = argmink??
?
c?i,k (1)???
= argmin??Eval(N?i=1Si,k?
), (2)21where Eval is an evaluation Error metric for MT, presum-ing the smaller the better internal to an optimizer; in ourcase, we decompose BLEU, TER (Snover et al, 2006)and (TER-BLEU)/2.0 into corresponding specific coun-ters for each sentence, cache the intermediate counts inSi,k, and compute final corpus-level scores using the sumof all counters; Eqn.
1 is simply a ranking process, withregard to the source sentence i, to select the top-1 hypoth-esis, indexed by k?
with the lowest cost C(ei,k?)
givencurrent ??
; Eqn.
2 is a scoring process of computing the fi-nal corpus-level MT metrics via the intermediate counterscollected from each top1 hypothesis selected in Eqn.
1.Iteratively, the optimizer picks up an initial guess of ?
?using current K-Best list, and reaches a solution ??
?, andthen updates the event space with new K-Best list gener-ated using a decoder with ???
; it iterates until there is littlechange to final scores (a local optimal ???
is reached).3 Simplex Armijo DownhillWe integrate the Armijo line search into the simplex-downhill algorithm in Algorithm 1.
We take the reflec-tion, expansion and contractions steps1 from the simplex-downhill algorithm to find a ??
to form a direction ??
?
?M+1 as the input to the Armijo algorithm, which inturn updates ??
to ?+ as the input for the next iterationof simplex-downhill algorithm.
The combined algorithmiterates until the simplex shrink sufficiently within a pre-defined threshold.
Via Armijo algorithm, we avoid theexpensive shrink step, and slightly speed up the search-ing process of simplex-downhill algorithm.
Also, thesimplex-downhill algorithm usually provides a descenddirection to start the Armijo algorithm efficiently.
Bothalgorithms are well known to converge.
Moreover, thenew algorithm changes the searching path of the tradi-tional simplex-downhill algorithm, and usually leads tobetter local minimal solutions.To be more specific, Algorithm 1 clearly conducts aniterative search in the while loop from line 3 to line 28until the stopping criteria on line 3 is satisfied.
Withinthe loop, the algorithm can be logically divided into twomajor parts: from line 4 to line 24, it does the simplex-downhill algorithm; the rest does the Armijo search.
Thesimplex-downhill algorithm looks for a lower point bytrying the reflection (line 6), expansion (line 10) and con-traction (line 17) points in the order showed in the al-gorithm, which turned out to be very efficient.
In rarecases, especially for many dimensions (for instance, 10to 30 dimensions, as in typical statistical machine trans-lation decoders) none of these three points are not lowerenough (line 21), we adapt other means to select lowerpoints.
We avoid the traditional expensive shrink pro-1These three basic operations are generally based on heuristics inthe traditional simplex-downhill algorithm.Algorithm 1 Simplex Armijo Downhill Algorithm1: ?
?
1, ?
?
2, ?
?
0.5, ?
= ?
?
0.9, ?
?
1.0 ?10?62: initilize (?1, ?
?
?
, ?M+1)3: while ?M+1i,j=1 ?
?i ?
?j?2 ?
?
do4: sort ?i ascend5: ?o ?
1N?Mi=1 ?i,6: ?r ?
?o + ?
(?o ?
?M+1)7: if S(?1) ?
S(?r) ?
S(?M ) then8: ??
?
?r9: else if S(?r) < S(?1) then10: ?e ?
?o + ?
(?o ?
?M+1)11: if S(?e) < S(?r) then12: ??
?
?e13: else14: ??
?
?r15: end if16: else if S(?r) > S(?M ) then17: ?c ?
?M+1 + ?
(?o ?
?M+1)18: if S(?c) < S(?r) then19: ??
?
?c20: else21: try points on two additional lines for ?
?22: end if23: end if24: d ?
??
?
?M+125: ??
?
maxk=0,1,???
,40{?k|S(?M+1 + ?kd) ?S(?M+1) ?
??
?d?2?k}26: ?+ = ?M+1 + ??
?
d27: replace ?M+1 with ?+28: end whilecedure, which is not favorable for our machine transla-tion problem neither.
Instead we try points on differentsearch lines.
Specifically, we test two additional pointson the line through the highest point and the lowest point,and on the line through the reflection point and the low-est point.
It worth pointing out that there are many vari-ants of simplex-downhill algorithm 2, and the implemen-tation described above showed that the algorithm can suc-cessfully select a lower ??
in many of our translation testcases to enable the simplex move to a better region of lo-cal optimals in the high-dimension space.
Our proposedembedded Armijo algorithm, in the second part of theloop (line 25), continues to refine the search processes.By backtracking on the segment from ??
to ?M+1, theArmijo algorithm does bring even lower points in ourmany test cases.
With the new lower ??
found by theArmijo algorithm, the simplex-downhill algorithm startsover again.
The parameters in line 1 we used are com-2One of such effective tricks for the baseline simplex algorithmscan be found here: http://paula.univ.gda.pl/?dokgrk/simplex.html (linktested to be valid as of 04/03/2009)22Optimizing (1-TER)0.410.4120.4140.4160.4180.420.4220.4240.4260.4280.431 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163Random Seeds(1-TER)MERSimplexSimplex-Arm(a) Optimizing Toward Metric (1-TER)Optimizing IBM BLEU0.3750.3770.3790.3810.3830.3850.3870.3890.3910.3931 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163Random SeedsIBM BLEUMERSIMPLEXSIMPLEX-ARM(b) Optimizing Toward Metric IBM BLEUOptimizing NIST-BLEU0.3880.3930.3980.4030.4080.4131 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163Random SeedsNIST-BLEUMERSimplex-ArmSimplex(c) Optimizing Toward Metric NIST BLEUOptimizing (1-(TER-BLEU))/2.00.40.4020.4040.4060.4080.410.4120.4140.4160.4181 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163Random Seeds(1-(TER-BLEU))/2.0MERSimplex-ArmijoSimplex(d) Optimizing Toward Metric (1-(TER-NISTBLEU))/2Figure 1: On devset, comparing MER, Simplex Downhill, and Simplex Armijo Downhill Algorithms on different TranslationMetrics including TER, IBM BLEU, NIST BLEU, and the combination of TER & NISTBLEU.
Empirically, we found optimizingtoward (TER-NISTBLEU)/2 gave more reliable solutions on unseen test data.
All optimizations are with internal random restarts,and were run from the same 164 random seeds with multiple iterations until convergence.
Simplex Armijo downhill algorithm isoften better than Simplex-downhill algorithm, and is also much better than MER algorithm.mon ones from literatures and can be tuned further.
Wefind that the combination not only accelerates the search-ing process to reach similar solutions to the baseline sim-plex algorithm, but also changes the searching trajectorysignificantly, leading to even better solutions for machinetranslation test cases as shown in our experiments.4 ExperimentsOur experiments were carried out on Chinese-Englishusing our syntax-based decoder (Zhao and Al-Onaizan,2008), a chart-based decoder with tree-to-string 3 gram-mar, in GALE P3/P3.5 evaluations.
There were 10 fea-ture functions computed for each hypothesis, and N-bestlist size is up to 2,000 per sentence.Given a weight-vector ?
?0, our decoder outputs N-Bestunique hypotheses for each input source sentence; theevent space is then built, and the optimizer is called with3Source shallow constituency tree to target-string rules with vari-ables, forming a probabilistic synchronous context free grammar.a number of random restarts.
We used 164 seeds4 witha small perturbation of three random dimensions in ?
?0.The best ?
?1 is selected under a given optimizing metric,and is fed back to the decoder to re-generate a new N-Bestlist.
Event space is enriched by merging the newly gen-erated N-Best list, and the optimization runs again.
Thisprocess is iteratively carried out until there are no moreimprovements observed on a development data set.We select three different metrics: NIST BLEU, IBMBLEU, TER, and a combination of (TER-NISTBLEU)/2as our optimization goal.
On the devset with four refer-ences using MT06-NIST text part data, we carried out theoptimizations as shown in Figure 1.
Over these 164 ran-dom restarts in each of the optimizers over the four con-figurations shown in Figure 1, we found most of the timesimplex algorithms perform better than MER in theseconfigurations.
Simplex algorithm considers to move allthe dimensions at the same time, instead of fixing other4There are 41 servers used in our experiments, four CPUs each.23Table 1: Comparing different optimization algorithms on the held-out speech data, measured on document-average TER, IBMBLEUand (TER-IBMBLEU)/2.0, which were used in GALE P3/3.5 Chinese-English evaluations in Rosetta consortium.Setup Broadcast News & Conversation DataBLEUr4n4 TER (TER-BLEUr4n4)/2MER 37.36 51.12 6.88Simplex-Downhill 37.71 50.10 6.19Simplex Armijo Downhill 38.15 49.92 5.89dimensions and carrying out a greedy search for one di-mension as in MER.
With Armijo line search embeddedin the simplex-downhill algorithm, the algorithm has abetter chance to walk out of the local optimal, via chang-ing the shrinking trajectory of the simplex using a linesearch to identify the best steps to move.
Shown in Fig-ure 1, the solutions from simplex Armijo downhill out-performed the other two under four different optimiza-tion metrics for most of the time.
Empirically, we foundoptimizing toward (TER-NISTBLEU)/2 gives marginallybetter results on final TER and IBM BLEU.On our devset, we also observed that whenever opti-mizing toward TER (or mixture of TER & BLEU), MERdoes not seem to move much, as shown in Figure 1-(a)and Figure 1-(d).
However, on BLEU (NIST or IBM ver-sion), MER does move reasonably with random restarts.Comparing TER with BLEU, we think the ?shift?
counterin TER is a confusing factor to the optimizer, and cannotbe computed accurately in the current TER implementa-tions.
Also, our random perturbations to the seeds usedin restarts might be relatively weaker for MER compar-ing to our simplex algorithms, though they use exactly thesame random seeds.
Another fact we found is optimizingtoward corpus-level (TER-NISTBLEU)/2 seems to givebetter performances on most of our unseen datasets, andwe choose this as optimization goal to illustrate the algo-rithms?
performances on our unseen testset.Our test set is the held-out speech part data5.
Weoptimize toward corpus-level (TER-NISTBLEU)/2 usingdevset, and apply the weight-vector on testset to evalu-ate TER, IBMBLEUr4n4, and a simple combination of(TER-IBMBLEU)/2.0 to compare different algorithms?strengths6.
Shown in Table 1, simplex Armijo downhillperforms the best (though not statistically significant),and the improvements are consistent in multiple runs inour observations.
Also, given limited resources, such asnumber of machines and fixed time schedule, both sim-plex algorithms can run with more random restarts thanMER, and can potentially reach better solutions.5Transcriptions of broadcast news and broadcast conversion inMT06; there are 565 sentences, or 11,691 words after segmentation.6We choose document-average metrics to show here simply becausethey were chosen/required in our GALE P3/P3.5 evaluations for bothArabic-English and Chinese-English individual systems and syscombs.5 Conclusions and DiscussionsWe proposed a simplex Armijo downhill algorithmfor improved optimization solutions over the standardsimplex-downhill and the widely-applied MER.
TheArmijo algorithm changes the trajectories for the simplexto shrink to a local optimal, and empowers the algorithm abetter chance to walk out of the riddled error surface com-puted by automatic MT evaluation metrics.
We showed,empirically, such utilities under several evaluation met-rics including BLEU, TER, and a mixture of them.
In thefuture, we plan to integrate domain specific heuristics viaapproximated derivatives of evaluation metrics or mix-ture of them to guide the optimizers move toward bettersolutions for simplex-downhill algorithms.ReferencesL.
Armijo.
1966.
Minimization of functions having lipschitzcontinuous first partial derivatives.
Pacific Journal of mathe-matics, 6:1?3.K.I.M.
McKinnon.
1999.
Convergence of the nelder-mead sim-plex method to a non-stationary point.
SIAM J Optimization,9:148?158.J.A.
Nelder and R. Mead.
1965.
A simplex method for functionminimization.
The Computer Journal, 7:308?313.Franz J. Och.
2003.
Minimum error rate training for statisticalmachine translation.
In Proc.
of the 41st Annual Meeting ofthe Association for Computational Linguistics, Japan, Sap-poro, July.Kishore Papineni, Salim Roukos, and Todd Ward.
1998.
Maxi-mum likelihood and discriminative training of direct transla-tion models.
In Proceedings of the 1998 IEEE InternationalConference on Acoustics, Speech & Signal Processing, vol-ume 1, pages 189?192, Seattle, May.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
2002.
Bleu: a method for automatic evaluation of ma-chine translation.
In Proc.
of the 40th Annual Conf.
of theAssociation for Computational Linguistics (ACL 02), pages311?318, Philadelphia, PA, July.Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Mic-ciulla, and John Makhoul.
2006.
A study of translation editrate with targeted human annotation.
In AMTA.Bing Zhao and Yaser Al-Onaizan.
2008.
Generalizing localand non-local word-reordering patterns for syntax-based ma-chine translation.
In Conference on Empirical Methods inNatural Language Processing (EMNLP).24
