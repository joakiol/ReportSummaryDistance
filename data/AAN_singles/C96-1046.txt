Pronouncing Text by AnalogyRobert I. Damper and John EG.
EastmondImage, Speech and Intelligent Systems (ISIS) Research Group,Department of Electronics and Computer Science,University of Southampton,Southampton SO17 IBJ,UK.{ridlje}@ecs.
soton, ac.ukAbstractPronunciation-by-analogy (PbA) is an emer-ging technique for text-phoneme conversionbased on a psychological model of read-ing aloud.
This paper explores the impactof certain basic implementational choiceson the performance of various PbA mod-els.
These have been tested on their abil-ity to pronounce sets of short pseudowordspreviously used in similar studies, as well aslexical words temporarily removed from thedictionary.
Best results of 85.7% and 67.9%words correct are obtained lor the pseudo-words and lexical words respectively, cast-ing doubt on certain previous-reported per-formance figures in the literature.1 IntroductionPronunciation-by-analogy (PbA) is an influential psy-chological model of the process of reading aloud.In PbA, most words are pronounced by retrieving theirphonemic form from the readers's lexicon, or diction-ary.
The pronunciation for a 'novel' word not in thelexicon, however, is derived not by the application ofabstract letter-to-sound rules hut is 'assembled' fromthe (known) pronunciations of words that it resembles.PbA has obvious application to text-to-speech onver-sion by machine.Although PbA programs have been presented in theliterature, they are they are few in number.
Ded-ina and Nusbaum (1991) describe PRONOUNCE: arather simple system for English.
Sullivan and Damper(1990; 1992; 1993) describe a considerably morecomplex and developed system, but which apparentlyyields a much poorer perfornmnce.As a psychological theory, PbA is under-specified:offering little meaningfifl guidance on the implement-ation choices which confront the programmer.
Indeed,Sullivan and Damper (1993) show that such choicescan have a profound impact on performance.
In thispaper, we seek to understand how Dedina and Nus-baum's largely unjustified implementational choicesaffected their results and, thereby, to resolve the con-flict between their performance claims and Sullivanand Damper's.2 Psychological BackgroundIn the standard ual-route model of reading aloud(Coltheart, 1978), there is a lexical route for the pro-nunciation of known words and a parallel route util-ising abstract letter-to-sound rules for the pronunci-ation of unknown ('novel') words.
Arguments fordual-route theory cite the ability to pronounce pseudo-words (non-words conforming to the spelling patternsof English), latency difference ffects between regularand exception words, and apparent double dissociationbetween the two routes in dyslexia (see Humphreysand Evett, 1985).
However, all these observations canarguably be explained by a single route.
One pervasiveidea is that pseudowords are pronounced by analogywith lexical words that they resemble (Baron, 1977;Brooks, 1977; Glushko, 1979; 1981; Brown and Be-sner, 1987).
Glushko, for instance, showed that "ex-ception pseudowords" like tave take longer to readthan "regular pseudowords" uch as taze.
Here, tazeis considered as a "regular pseudoword" since all itsorthographic 'neighbours' (raze, gaze, maze etc.)
havethe regular vowel pronunciation/el/.
By contrast, aveis considered tobe an "exception pseudoword" since ithas the exception word (have,/hay/) as an orthographicneighbour.
Thus, according to Glushko (1979), the"assignment ofphonology to non-words i open to lex-ical influence".
This is at variance with the notion oftwo independent routes to pronunciation.
Instead:"it appears that words and pseudowordsare pronounced using similar kinds of or-thographic and phonological knowledge:the pronunciation of words that share or-thographic features with them, and spe-cific spelling-to-sound rules for multiletterspelling patterns.
"268There are two tbrms o1' PbA: explicit mmlogy(Baron, 1977) is a conscious strategy of recalling asimilar word and modifying its pronunciation, whereasin implicit analogy (Brooks, 1977) a pronunciationis derived from generalised phonographic knowledgeabout exisling words.
The latter has obvious com-monalities with most single-route, conncctionist mod-els (e.g.
Seinowski and RosenhErg, 1987) in whichthe generalised knowledge is learned (e.g.
by back-propagation) its it set of weights, and the network hasno holistic notion of the concept 'word'.Until the recent advent of computational PbA mod-els, analogy 'theory' could only be considered seri-ously underspecilied.
Clearly, its operation nmst de-pend critically on some measure of similarity, and"without a metric for similarity and without a specific-ation of how similar is similar enough, the concept ofanalogy by similarity offers little insight" (Glushko,1981, p. 72).
Further, as detailed by Brown and Be-sner (1987), the operation of IExical analogy must beconsmfined by factors such as:?
the size of the segment shared between ovel andlexical word;?
its position in the two strings;?
its tiequency of occurrence in the hmguagc;?
and the frequency of occurrencE of the words con-taining it;none of which had then received serious consideration.Accordingly, they write: "Extant analogy models arenot capable l: predicting the ot|tconte Of assembly op-erations for all possiblc strings.
"In particular, the 'theory' gives no principled wayel' deciding the orthogral~hic neighbours of it novelword which are deemed to intluence its pronunciationwhereas a computational model must (spccilically orotherwise) do so.3 Existing PbA Programs3.1 Dedina and Nusbaum's  SystemTim overall structure el' PRONOUNCf~; is as shownin Fig.
1.
The Icxical datalmsc onsists o1' "approx-imately 20,000 words based on Webster's tbcket Dic-tionary" in which text and phonemes have been auto?matically aligned.
Dedina and Nusbaum acknowledgethe crude natnre of their alignment procedure, sayingit "was carried out by a simple Lisp program that onlyuses knowledge about which phonemes are consonantsand which are w)wels.
"An input string is matched in turn against all ortho-graphic entries in the lexicon.
The process starts withthe input string and the current dictionary entry left-aligned.
Ilfformatinn about matching letter substringsINPUT(spelling pal-tern)LexicalLelter-phoneme k /alignment \]1SubstringmatchingBuildpronunciationlatticeDecisionfunctionOUTPUT(pronunciation)Figure 1: l)cdina and Nusbaum's PRONOUNCE.- and their corresponding phoneme substrings in thedictionary entry under consideration - is entered intoa pronunciation lattice its detailed below.
The shorterof tile two strings is then shifted right by one letter andthe process repeated.
This continues until the two areright-aligned, i.e.
the number of right shifts is equal tothe difference in length between the two strings.
Theprocess is repeated for all words in the dictionary.A node of the lattice represents a matched letter, Li,at some position, i, in the input, as illustrated inFig.
2.
The node is labelled with its position index iand with the phoneme which corresponds to Li in thematched suhstring, Pim say, for the mth matched sub-siring.
An arc is placed from node i to node j if thereis a lnatched substring starting with Li and endingwith L i.
The arc is labelled with the phonemes in-termediate between l'/m and Pj,,, in tim phoneme partof the matched substring.
Note that the empty stringlabels arcs corresponding to bigrams: the two symbolsof the bigram label the nodes at either end.
Addition-ally, arcs are labelled with a "frequency" count whichis incremented by one each time that substring (withthat pronunciation) is matched uring the pass throughthe lexicon.
Finally, there is a Start node at position 0and an End node at position one greater than the lengthof the input string.269S It E----___<_ 0A D/ __  d /\]Figure 2: Partial pronunciation lattice for the pseudoword shead.A possible pronunciation for the input correspondsto a complete path through its lattice from Start to End,with the output string assembled by concatenating inorder the phoneme labels on the nodes/arcs.
The set ofcandidate pronunciations is then passed to the decisionfunction.
Two (prioritised) heuristics are used to rankthe pronunciations, and the top-ranking candidate se-lected as the output.
The first is based on path length.If one candidate corresponds toa unique shortest path(in terms of number of arcs) through the lattice, this isselected as the output.
Otherwise, candidates that tieare ranked on the sum of their arc "frequencies".Dedina and Nusbaum tested PRONOUNCE on 70of Glushko's (1979) pseudowords, which "were fouror five characters long and were derived from mono-syllabic words by changing one letter".
Seven subjectswith phonetics training were asked to read these andgive a transcription for the first pronunciation whichcame to mind.
A 'correct' pronunciation for a givenpseudoword was considered to be one produced by anyof the subjects.
A word error rate of 9% is reported.3.2 Sullivan and Damper's SystemSullivan and Damper employ a more principled align-ment procedure based on the Lawrence and Kaye(1986) algorithm.
By pre-computing mappings andtheir statistics, they implemented a considerably more'implicit' form of PbA: there is no explicit matchingof the input string with lexical entries.
Their pronun-ciation lattice differs, with nodes representing junc-tures between symbols and arcs representing letter-phoneme mappings.
They also examine different waysof numerically ranking candidates, taking into accountprobabilities estimates for the letter-phoneme map-pings used in the assembled pronunciation.Given the improved alignment and candidate-ranking methods, better performance than Dedina andNusbaum might be expected.
On the contrary, Sullivanand Damper's best result on the full set of 131 pseudo-words from Glushko (1979) (plus another 5 words -see section 5.1) is only 70.6% (1993, p. 449).
This isan error rate of ahnost 30%, as compared to Dedinaand Nusbaum's 9% on the smaller test set of size 70.Differences in test-set size and between British andAmerican English, the transcription standards of thephoneticians, and the lexicons employed seem insuffi-cient to explain this.4 Re-Implementing PRONOUNCEOur purpose was to re-implement PRONOUNCE, as-sess its performance, and study the impact of vari-ous implementational choices on this performance.However, the described alignment algorithm is prob-lematic (see pp.
71-73 of Sullivan, 1992) and needsto be replaced.
Rather than re-implement a flawed al-gorithm, we have used manually-aligned data.
Sincemanual alignment generally produces a better resultthan automatic alignment, we ought to produce aneven lower error rate than Dedina and Nusbaum'sclaimed 9%.The performance on lexical words (temporarily re-moved from the lexicon) has not previously been as-sessed but seems worthwhile.
Arguably, 'real' wordsform a much more sensible test set for a PbA systemthan pseudowords, not least because they are multi-syllabic.
Temporary removal from the lexicon meansthat the pronunciation must be assembled by the~ana-logy process rather that merely retrieved in its entirety.Hence, we believe it is sensible and important to testany PbA system in this way.4.1 Lexical DatabasesTo examine any impact hat the specific lexical data-base might have on performance, we have used twoin this work: the 20,009 words of Webster's PocketDictionary and the 16,280 words of the Teacher'sWord Book (TWB) (Thorndike and Lorge, 1944).In both cases, letters and phonemes have previouslybeen hand-aligned for the purposes of training back-propagation networks.
The Webster's database is thatused by Sejnowski and Rosenberg (1987) to train andtest NETtalk.
The TWB database is that used by Mc-Culloch, Bedworth and Bridle (1987) for NETspeak.270The phoneme inventory is of size 52 in both cases,including the null phoneme but excluding stress sym-bols.
We leave the very important problem of stressassignment for later study.4.2 Re-hnplementation DetailsThe re-implementation was programmed in C on aHewlett~Packard 712/80 workstation running HP-UX.A 'direct' version scores candidates using Dedina andNusbaum's method with its two prioritised heurist-ics: we call this model D&N.
Two other methods l'orscoring have also been implemented.
In one, we re-place the second (maximum sum) heuristic with themaximum product of the arc frequencies: we call thismodel PROD.
(It still selects primarily on the basisof shortest path length.)
We have also inlplemented aversion which uses a single heuristic.
This takes theproduct along each possible path from Start to Endof the mapping probabilities for that arc.
These arecomputed using Method 1 (a priori version) of Sulli-van and Damper (1993, pp.
446-447).
For all pathscorresponding to the same pronunciation, these wduesare summed to give an overall score for that pronun-ciation.
We call this the MP model.
The final productscore is not a proper probability for the assembled pro-nunciation, since the scores do not sum to one over allthe candidates.The 'best' pronunciation is found by depth-lirstsearch of the lattice, implemented as a preorder treetraversal.
For the D&N and PROD models, paths werepruned when their length exceeded the shortest \[i)undso far for that input, leading to a uselul reduction in runtimes.
A similarly motivated pruning was carried outfor the MP model.
If any product fell below a thresholdduring traversal, its corresponding path was discarded.The threshold used was e times the maximum productscore found so far, with ~ set by at 10 -3.
While thismay have led to the pruning of a path contributing tothe 'best' pronunciation, its contribution would be verysmall.
Again, this gave a very significant improvementin run times for the testing of lexical words (section 5.2below) but was unnecessary \['or the testing of pseudo-words.5 Results5.1 PseudowordsPronunciations have been obtained lot:?
the 70 pseudowords froln Glushko (1979) used byDedina and Nusbaum to test PRONOUNCE.
The'correct' pronunciation for these strings is takento be that given by Dedina and Nusbaum (1991,pp.
61-62).
We refer to this test set as D&N 70.?
the lull set of 131 pseudowords from Glushkoplus two others (goot, pome) plus two lexicalwords (cat and play) plus the pseudohomophonekwik, as used by Sullivan (1992).
The 'correct'pronunciations are those read aloud by Sullivan's20 non-phonetician subjects, and transcribed byhim as British Received Pronunciation.
We referto this test set as Sul1136.
Our expectation isthat the error rate will be relatively high for thistest set, partly because of its larger size but moreimportantly because the subjects' dialect of Eng-lish is British RP rather that general American,i.e.
there is a very significant inconsistency withthe lexical databases.The output has been scored on words correct and alsoon symbol score (i.e.
phonemes correct) using theLevenshtein (1966) string-edit distance as shown inTable 1.Our best comparison with Dedina and Nusbaum(D&N70 test set, D&N model, Webster's database)gives a figure of 77.1% words correct.
This is enorm-ously poorer than their approximately 91% words cor-rect - yet the implementation, reference pronunci-ations and test set are (as far as we can tell) identical.The only relevant difference is that the Webster's data-base is antomatically-aligned in their work and hand-aligned in ours.
The clear expectation, given the crudenature of their alignment, is that they should have ex-perienced a higher error rate, not a dramatically lowerone.
Overall, this result accords far more closely withSullivan and Damper (1993) whose best word score forautomatic alignment (and using smaller databases buta larger test set) was just over 70%.The re-implementation made 16 errors under theabove conditions.
Dedina and Nusbaum's claim of 9%words correct amounts to just 6 errors, 3 of which arethe same as ours.
The commonest problem is vowelsubstitution.
It is possible to discount a very few errorsas essentially trivial, reducing the error rate marginallyto some 20%.
We conclude, therefore, that Dedina andNusbaum's reported error rate of 9% is unattainable.In our opinion, a major deficiency of the simpleshortest-path length heuristic is that the output can be-come unreasonably sensitive to rare or unique pronun-ciations.
For instance, mone receives the strange pro-nunciation /moni /by analogy with anemone.
Also,the pseudoword shead receives the bizarre, vowel-less pronunciation / f___d/ (where '2 denotes thenull phoneme) when using the D&N model and theTWB database.
As illustrated in Fig.
2 earlier, thisturns out to be a result of matching the unique but longmapping head --+/_ __d/as in forehead --+ Itbr .
.
.
.
d~(arc li'equency 1) in conjunction with the very com-mon mapping sh -+/J '_ /as in she and shed (arc fre-quency 174) which swamps the overall score of 175.The same bizarre pronunciation does not occur withthe PROD model.
In this case, the path through the271Table 1: Results for PbA of pseudowords with both dictionaries.
See text ot further specification.Test set implementationD&N 70 D&NSul1136PRODMPD&NPRODMPWebster's (%) TWB (%)words\[phonemes words\[phonemes77.1 94.3 70.0 92.682.9 95.9 78.6 94.985.7 96.6 80.0 95.375.0 93.6 72.1 93.180.1 95.0 76.5 94.583.8 95.9 81.6 95.7(/e/, 3) node has a product score of 12 x 30 = 360 forthe pronunciation/fed/ which considerably exceedsthe score of 174 for/fd/.Replacing the arc-sum heuristic of the D&N modelby arc-product as in the PROD model leads toa considerable increase in performance, e.g.
from77.
1% words correct o 82.9% for the D&N 70 test setwith Webster's database.
In turn, the MP model per-forms better than PROD in all cases.For the Sull 136 test set, our expectation of poorerperformance (because of the larger test set and incon-sistency between of dialect between the target pro-nunciations and the lexical databases) is borne out forWebster's dictionary.
For TWB, however, the perform-ance difl'erence between test sets is less consistent.5.2 Lexical WordsThe primary ability of a text-to-speech system mustbe to produce correct pronunciations lbr lexical words(rather than pseudowords) which just happen to be ab-sent from the system's dictionary.
Accordingly, wehave tested the PbA implementations by removingeach word in turn from its relevant database, and ob-taining a pronunciation by analogy with the remainder.In these tests, the transcription standard employed bythe compilers of the dictionary becomes its own reference and problems of transcription i consistenciesbetween input strings and lexical entries are avoided.Results for the testing of lexical words are shownin Table 2.
Again there are consistent performancedifferences with the 'standard' D&N model worst andthe mapping probability (MP) mode\[ best.
All modelsperform better with the TWB database than with Web-ster's, probably simply because of its smaller size.For some lexical words, no pronunciation atall wasproduced because there was no complete path fromStart to End in the lattice.
This occurred for 92 ofthe TWB words and 117 of the Webster's words irre-spective of the scoring model.
This is a serious hort-coming: a PbA system should always produce a best-attempt pronunciation, even if it cannot produce thecorrect one.
Sometimes, this failure is a consequenceof the lbrm of pronunciation lattice in which nodes areused to represent the 'end-points' of mappings.
Oneof the inputs for which no pronunciation was foundis anecdote, whose (partial) lattice is shown in Fig.
3.There is in fact no arc in the complete lattice betweennodes (/k/, 4) and (/d/, 5) because there is no cd -+/kd/mapping anywhere in either dictionary.
Nor is therean ecd or cdo trigram - with or without he right end-point phonemes - which could possibly bridge the gap.This problem is entirely avoided with the Sullivan andDamper style of lattice, because the shortest-length arccorresponds to a single-symbol mapping rather thanto a bigram (which may be unique).
Thus, there willalways be a 'default' single-symbol mapping corres-ponding to the commonest pronunciation of the let-ter.
This is not to say that Sullivan and Damper's ys-tem will necessarily produce the correct output here:it ahnost certainly will not because of the rarity of thec -+/k/mapping in the _d context.Another input which thils to produce a pronunci-ation is aardvark.
The problem here is not that thereis no aa bigram in the dictionary (which is found inwords such as bazaar), but that it only appears to-wards the end of other words.
Dedina and Nusbaum'sstrategy ol' performing substring matching only over arestricted range (the number of matching comparisonsis equal to the difference in length between the inputstring and lexical entry) is at the root of this problem.6 Conc lus ions  and Discuss ionWe lind that Dedina and Nusbaum's reported er-ror rate of 9% cannot be reproduced: our figure isabout two or three times that.
Because of the short-comings which emerge in this work, we believe theproblem lies with PRONOUNCE rather than our re-implementation.
Overall, our results are in muchcloser agreement with Sullivan and Damper's word er--ror rates of almost 30% on a similar test set.This work suggests several useful ways in which tileperlk)rmance of PbA systems might be improved.
Ourbest results are obtained with a scoring method basedon a priori mapping probabilities.
According to Sul-272q/rifle 2: Results for PbA of dictionary words.hnplcmentation 1\[ Wcbster's (%) ~ W B  (%)JLw  i w,,ra  i fi  mosMP I ~  ')1.2 6~.9 ~ 93.5A N E C/Ol.
'/'Qff \'~J k i /  k !
/D O T E/ ot:~t /Figure 3: Simplilied prolmnciation lattice lor the lcxical word anecdote which fifils to produce any pronunciation.liwm and Damper (1993), a posteriori mapping prob-abilities may do evcn better.
Also, the type of pronun-ciation lattice used by Sullivan and Damper, in whichnodes correspond to thejuncturcs between symbols, islikely to be superior.
The impacl of different align-ment strategies should repay study.
Finally, we intendto assess the impact of incorl)orating inlormation aboutword frequency in the analogy process.AcknowledgementThis work was funded by the UK Economic and So-cial Research Council via rescarch grant R000235487:"Speech Synthesis by Analogy".ReferencesBaron, J.
(1977).
Mechanisms for pronouncilag printedwords: use and acquisition.
In Basic l'rocesses in Reading:Perception attd (7omprehension (1).
l~aBcrgc and S.
Samuels,eds.
), pp.
175--216. l,awrence l';rlbamu, tlillsdalc, NJ.Brooks, L. (1977).
Non-analytic correspondences and pat-.tern in word pronunciation.
In Attention and Petjbrm-ance VII (J. Rcnquin, ed.
), pp.
163-177.
1 ,awrcnce I';rlbaum,Hillsdalc, NJ.Brown, P. and Besner, I).
(1987).
The asseml)ly of phon-ology in oral reading: a new model.
In Attention and Per-.formatwe Xlh the Psychology oJ'Reading (M. Colthcart, ed.),pp.
471-489.
Lawrence Edbatnn, London.Coltheart, M. (1978).
Lexical access in simple readingtasks.
In Strategies of h!/brmation l'rocessing (G. tJnder-wood, ed.
), pp.
151-.216.
Academic, I xmdon.I)edina, M.J. and Nusbaum, I I.C.
(1991).
I)I,IONOIJNCE:a program for l)ronunciation by analogy.
Compuler Speechand lzmguage, 5, 55--64.Glushko, R.J. (1979).
The organization and actiw~tion of or-thographic knowledge in reading aloud.
,hmrna\] of l'Speri~mental Psychology: ltuman l>erctT)tion t#ld I'e~jbrmance, 5,674-691.Glushko, R.J. (1981).
Principles for pronouncing print: thepsychology of phonography.
In hzteractive Processes inReading (A.M. Lesgold and C.A.
Perlbtti, eds.
), pp.
61-84.Lawrence Erlbaum, ttillsdale, NJ.llumphreys, G.W.
and Evett, I,.J.
(1985).
Are there inde-pendent lexical and nonlexical routes in word processing?An cwlluation of the dual-route theory of reading.
Behavi-oral and lh'ain Sciences, 8, 689-740.\[,awrence, S.G,C.
and Kaye, G. (1986).
Alignment ofphonemes with their corresponding orthography.
ComputerSpeech and Language, 1, 153-165.Levenshtein, V.I.
(1966).
Binary codes capable of corrcctingdeletions, insertions and reversals.
CybetTtetics and ControlTheory, 10, 707-710.McCutloch, N., Bedworth, M. and Bridle, J.S.
(1987).
NET-speak - a re4mplementation of NETtalk.
Computer Speechand lxmguage, 2, 289-301.Sejnowski, T.J. and P, osenberg, C.R.
0987).
Parallel net-works that loam to pronounce English text.
Conwlex Sys-tems, 1, 145-152.Sullivan, K.RH.
(1992).
Synthesis-by-Analogy: a Psycho-logically Motiwtted Approach to Textqo-Speech Convelxion,Phi) rl'hcsis, Department of Electronics and Computer Scioence, University of Southampton, UK.Sullivan, K.P.II.
and l)amper, R.I. (1990).
A psychologic-ally governed approach to novel-word pronunciation withina text-to.-spcech system, l'roceedings oflEl~E InternationalConj~;mnce on Acoustics, Speech and Signal Processing( ICASSt' '90), Vol.
I, Albuquerque, NM, pp.
341--344.Sulliwm, K.RII.
and I)ampcr, R.I. (1992).
Novel-word pro-nunciation within a text-to-speech system.
In rlMking Ma-chines: 7beeries, Models atul Applications (G. Bailly and C.Bcno'fl, cds.
), pp.
183--195.
Elsevier (Northqlolland), Ams-terdanLSullivan, K.P.H.
and Damper, R.I. (1993).
Novel-word pro-.nunciation: across-lallgtlage study.
Speech (;ontmunicatiotz,13, 44l.
452.Thorn,like, E.L. and l,orgc, 1.
(1944).
The Teachetw' WordBook oJ30,O00 Words.
Teachers' College, Columbia Uni-versity, NY.273
