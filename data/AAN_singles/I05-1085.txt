Lexical Choice via Topic Adaptation forParaphrasing Written Language to SpokenLanguageNobuhiro Kaji1 and Sadao Kurohashi21 Institute of Industrial Science, The University of Tokyo,4-6-1 Komaba, Meguro-ku, Tokyo 153-8505, Japankaji@tkl.iis.u-tokyo.ac.jp2 Graduate School of Information Science and Technology,The University of Tokyo, 7-3-1 Hongo,Bunkyo-ku, Tokyo 113-8656, Japankuro@kc.t.u-tokyo.ac.jpAbstract.
Our research aims at developing a system that paraphraseswritten language text to spoken language style.
In such a system, it isimportant to distinguish between appropriate and inappropriate wordsin an input text for spoken language.
We call this task lexical choicefor paraphrasing.
In this paper, we describe a method of lexical choicethat considers the topic.
Basically, our method is based on the wordprobabilities in written and spoken language corpora.
The novelty of ourmethod is topic adaptation.
In our framework, the corpora are classifiedinto topic categories, and the probability is estimated using such corporathat have the same topic as input text.
The result of evaluation showedthe effectiveness of topic adaptation.1 IntroductionWritten language is different from spoken language.
That difference has variousaspects.
For example, spoken language is often ungrammatical, or uses simplifiedwords rather than difficult ones etc.
Among these aspects this paper examinesdifficulty.
Difficult words are characteristic of written language and are not ap-propriate for spoken language.Our research aims at developing a system that paraphrases written languagetext into spoken language style.
It helps text-to-speech generating natural voicewhen the input is in written language.
In order to create such a system, thefollowing procedure is required: (1) the system has to detect inappropriate wordsin the input text for spoken language, (2) generate paraphrases of inappropriatewords, and (3) confirm that the generated paraphrases are appropriate.
Thispaper examines step (1) and (3), which we call lexical choice for paraphrasingwritten language to spoken language.Broadly speaking, lexical choice can be defined as binary classification task:the input is a word and a system outputs whether it is appropriate for spokenR.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
981?992, 2005.c?
Springer-Verlag Berlin Heidelberg 2005982 N. Kaji and S. Kurohashilanguage or not.
This definition is valid if we can assume that the word diffi-culty is independent of such factors as context or listeners.
However, we thinksuch assumption is not always true.
One example is business jargon (or technicalterm).
Generally speaking, business jargon is difficult and inappropriate for spo-ken language.
Notwithstanding, it is often used in business talk.
This exampleimplies that the word difficulty is dependent on the topic of text/talk.In this paper, we define the input of lexical choice as a word and text where itoccurs (= the topic).
Such definition makes it possible for a system to considerthe topic.
We think the topic plays an important role in lexical choice, whendealing with such words that are specific to a certain topic, e.g., business jargon.Hereafter, those words are called topical words, and others are called non-topicalwords.
Of course, in addition to the topic, we have to consider other factors suchas listeners and so on.
But, the study of such factors lies outside the scope ofthis paper.Based on the above discussion, we describe a method of lexical choice thatconsiders the topic.
Basically, our method is based on the word probabilities inwritten and spoken language corpora.
It is reasonable to assume that these twoprobabilities reflect whether the word is appropriate or not.
The novelty of themethod is topic adaptation.
In order to adapt to the topic of the input text,the corpora are classified into topic categories, and the probability is estimatedusing such corpora that have the same topic category as the input text.
Thisprocess enables us to estimate topic-adapted probability.
Our method was evalu-ated by human judges.
Experimental results demonstrated that our method canaccurately deal with topical words.This paper is organized as follows.
Section 2 represents method overview.Section 3 and Section 4 describe the corpora construction.
Section 5 representslearning lexical choice.
Section 6 reports experimental results.
Section 7 describesrelated works.
We conclude this paper in Section 8.2 Method OverviewOur method uses written and spoken language corpora classified into topic cat-egories.
They are automatically constructed from the WWW.
The constructionprocedure consists of the following two processes (Figure 1).1.
Style ClassificationWeb pages are downloaded from the WWW, and are classified into writtenand spoken language style.
Those pages classified as written/spoken languageare referred as written/spoken language corpus.
In this process, we discardedambiguous pages that are difficult to classify.2.
Topic ClassificationThe written and spoken language corpora are classified into 14 topic cate-gories, such as arts, computers and so on.Both classification methods are represented in Section 3 and Section 4.Given an input word and a text where it occurs, it is decided as followswhether the input word is appropriate or inappropriate for spoken language.Lexical Choice via Topic Adaptation for Paraphrasing Written Language 9831.
The topic category of the input text is decided by the same method as theone used to classify Web pages into topic categories.2.
We estimate the probabilities of the input word in the written and spokenlanguage corpora.
We use such corpora that have the same topic as the inputtext.3.
Using the two probabilities, we decide whether the input word is appropriateor not.
Section 5 describes this method.Web PagesSpoken AmbiguousWrittenTopic classificationStyle classification(Section 3)(Section 4)WrittenArts categorySpoken WrittenRecreation categorySpoken.........WrittenScience categorySpokenFig.
1.
Written and spoken language corpora construction3 Style ClassificationIn order to construct written and spoken language corpora classified into topiccategories, first of all, Web pages are classified into written and spoken languagepages (Figure 1).
Note that what is called spoken language here is not realutterance but chat like texts.
Although it is not real spoken language, it worksas a good substitute, as some researchers pointed out [2,11].We follow a method proposed by Kaji et al(2004).
Their method classifiesWeb pages into three types: (1) written language page, (2) spoken language page,and (3) ambiguous page.
Then, Web pages classified into type (1) or (2) areused.
Ambiguous pages are discarded because classification precision decreasesif such pages are used.
This Section summarizes their method.
See [11] for detail.Note that for this method the target language is Japanese, and its procedure isdependent on Japanese characteristics.3.1 Basic IdeaWeb pages are classified based on interpersonal expressions, which imply an at-titude of a speaker toward listeners, such as familiarity, politeness, honor or con-tempt etc.
Interpersonal expressions are often used in spoken language, although984 N. Kaji and S. Kurohashinot frequently used in written language.
For example, when spoken language isused, one of the most basic situations is face-to-face communication.
On theother hand, such situation hardly happens when written language is used.Therefore, Web pages containing many interpersonal expressions are classi-fied as spoken language, and vice versa.
Among interpersonal expressions, suchexpressions that represent familiarity or politeness are used, because:?
Those two kinds of interpersonal expressions frequently appear in spokenlanguage,?
They are represented by postpositional particle in Japanese and, therefore,are easily recognized as such.Hereafter, interpersonal expression that represents familiarity/politeness iscalled familiarity/politeness expression.3.2 Style Classification ProcedureWeb pages are classified into the three types based on the following two ratios:?
Familiarity ratio (F-ratio): ?# of sentences including familiarity expressions?divided by ?# of all the sentences in the page?.?
Politeness ratio (P-ratio): ?# of sentences including politeness expressions?divided by ?# of all the sentences in the page?.The procedure is as follows.
First, Web pages are processed by Japanesemorphological analyzer JUMAN3.
And then, in order to calculate F-ratio and P-ratio, sentences which include familiarity or politeness expressions are recognizedin the following manner.
A sentence is considered to include the familiarityexpression, if it has one of the following six postpositional particles: ne, yo,wa, sa, ze, na.
A sentence is considered to include the politeness expression, ifit has one of the following four postpositional particles: desu, masu, kudasai,gozaimasu.After calculating the two ratios, the page is classified according to the rulesillustrated in Figure 2.
If F-ratio and P-ratio are equal to 0, the page is classifiedas written language page.
If F-ratio is more than 0.2, or if F-ratio is more than0.1 and P-ratio is more than 0.2, the page is classified as spoken language page.The other pages are regarded as ambiguous and are discarded.3.3 The ResultTable 1 shows the number of pages and words (noun, verb, and adjective) in thecorpora constructed from the WWW.
About 8,680k pages were downloaded fromthe WWW, and 994k/1,338k were classified as written/spoken language.
Therest were classified as ambiguous page and they were discarded.
The precision ofthis method was reported by Kaji et al(2004).
According to their experiment,the precision was 94%.3 http://www.kc.t.u-tokyo.ac.jp/nl-resource/juman-e.htmlLexical Choice via Topic Adaptation for Paraphrasing Written Language 98500.2F-ratioP-ratio0.20.1Written languageAmbiguousSpoken languageFig.
2.
Style classification ruleTable 1.
The size of the written and spokenlanguage corpora# of pages # of wordsWritten language 989k 432MSpoken language 1,337k 907MTable 2.
The size of the training and testdataTopic category Training TestArts 2,834 150Business & Economy 5,475 289Computers & Internet 6,156 325Education 2,943 155Entertainment 6,221 328Government 3,131 165Health 1,800 95News 2,888 152Recreation 4,352 230Reference 1,099 58Regional 4,423 233Science 3,868 204Social Science 5,410 285Society & Culture 5,208 2754 Topic ClassificationThe written and spoken language corpora are classified into 14 topic categories(Figure 1).
This task is what is called text categorization.
We used Support Vec-tor Machine because it is reported to achieve high performance in this task.Thetraining data was automatically built from Yahoo!
Japan4.The category provided by Yahoo!
Japan have hierarchy structure.
For exam-ple, there are Arts and Music categories, and Music is one of the subcategoriesof Arts.
We used 14 categories located at the top level of the hierarchy.
Wedownloaded Web pages categorized in one of the 14 categories.
Note that wedid not use Web pages assigned more than one categories.
And then, the Webpages were divided them into 20 segments.
One of them was used as the testdata, and the others were used as the training data (Table 2).
In the Table, the4 http://www.yahoo.co.jp/986 N. Kaji and S. Kurohashi050000100000150000200000250000300000350000400000ArtsBusiness&EconomyComputers&InternetEducationEntertainmentGovernmentHealthNewsRecreationReferenceRegionalScienceSocialScienceSociety&CultureTopic category#ofpagesWritten language page Spoken language pageFig.
3.
The size of written and spoken language corpora in each topic categoryfirst column shows the name of the 14 topic categories.
The second/third columnshows the number of pages in the training/test data.SVM was trained using the training data.
In order to build multi-class clas-sifier, we used One-VS-Rest method.
Features of SVM are probabilities of nounsin a page.
Kernel function was linear.
After the training, it was applied to thetest data.
The macro-averaged accuracy was 86%.The written and spoken language corpora constructed from the WWW wereclassified into 14 categories by SVM.
Figure 3 depicts the number of pages ineach category.5 Learning Lexical ChoiceWe can now construct the written and spoken language corpora classified intotopic categories.
The next step is discrimination between inappropriate and ap-propriate words for spoken language using the probabilities in written and spokenlanguage corpora (Section 2).
This paper proposes two methods: one is basedon Decision Tree (DT), and the other is based on SVM.
This Section first de-scribes the creation of gold standard data, which is used for both training andevaluation.
Then, we describe the features given to DT and SVM.5.1 Creation of Gold Standard DataWe prepared data consisting of pairs of a word and binary tag.
The tag representswhether that word is inappropriate or appropriate for spoken language.
This datais referred as gold standard data.
Note that the gold standard is created for eachtopic category.Gold standard data of topic T is created as follows.1.
Web pages in topic T are downloaded from Yahoo!
Japan, and we sampledwords (verbs, nouns, and adjectives) from those pages at random.2.
Three human judges individually mark each word as INAPPROPRIATE,APPROPRIATE or NEUTRAL.
NEUTRAL tag is used when a judge cannotmark a word as INAPPROPRIATE or APPROPRIATE with certainty.Lexical Choice via Topic Adaptation for Paraphrasing Written Language 9873.
The three annotations are combined, and single gold standard data is cre-ated.
A word is marked as INAPPROPRIATE/APPROPRIATE in the goldstandard, if?
All judges agree that it is INAPPROPRIATE/APPROPRIATE, or?
Two judges agree that it is INAPPROPRIATE/APPROPRIATE andthe other marked it as NEUTRAL.The other words are not used in the gold standard data.5.2 The FeaturesBoth DT and SVM use the same three features: the word probability in writtenlanguage corpus, the word probability in spoken language corpus, and the ratioof the word probability in spoken language corpus to that in written language.Note that when DT and SVM are trained on the gold standard of topic T, theprobability is estimated using the corpus in topic T.6 EvaluationThis Section first reports the gold standard creation.
Then, we show that DT andSVM can successfully classify INAPPROPRIATE and APPROPRIATE wordsin the gold standard.
Finally, the effect of topic adaptation is represented.6.1 The Gold Standard DataThe annotation was performed by three human judges (Judge1, Judge2 andJudge3) on 410 words sampled from Business category, and 445 words sampledfrom Health category.
Then, we created the gold standard data in each category(Table 3).
The average Kappa value [3] between the judges was 0.60, whichcorresponds to substantial agreement.Table 3.
Gold standard dataBusiness HealthINAPPROPRIATE 49 38APPROPRIATE 267 340Total 316 378Table 4.
# of words in Business and Healthcategories corporaBusiness HealthWritten language 29,891k 30,778kSpoken language 9,018k 32,235k6.2 Lexical Choice EvaluationDT and SVM were trained and tested on the gold standard data using Leave-One-Out (LOO) cross validation.
DT and SVM were implemented using C4.55and TinySVM6 packages.
The kernel function of SVM was Gaussian RBF.
Table5 http://www.rulequest.com/Personal/6 http://chasen.org/ taku/software/TinySVM/988 N. Kaji and S. KurohashiTable 5.
The result of LOO cross validationTopic Method Accuracy # of correct answers Precision RecallBusiness DT .915 (289/316) 31 + 258 = 289 .775 .660SVM .889 (281/316) 21 + 260 = 281 .750 .429MCB .845 (267/316) 0 + 267 = 267 ?
.000Health DT .918 (347/378) 21 + 326 = 347 .600 .552SVM .918 (347/378) 13 + 334 = 347 .684 .342MCB .899 (340/378) 0 + 340 = 340 ?
.0004 shows the number of words in Business and Health categories corpora.
Threefeatures described in Section 5 were used.The result is summarized in Table 5.
For example, in Business category, theaccuracy of DT was 91.5%.
289 out of 316 words were classified successfully, andthe 289 consists of 31 INAPPROPRIATE and 258 APPROPRIATE words.
Thelast two columns show the precision and recall of INAPPROPRIATE words.MCB is Majority Class Baseline, which marks every word as APPROPRIATE.Judging from the accuracy in Health category, one may think that ourmethod shows only a little improvement over MCB.
However, considering otherevaluation measures such as recall of INAPPROPRIATE words, it is obviousthat the proposed method overwhelms MCB.
We would like to emphasize thefact that MCB is not at all practical lexical choice method.
If MCB is used, allwords in the input text are regarded as appropriate for spoken language and theinput is never paraphrased.One problem of our method is that the recall of INAPPROPRIATE words islow.
We think that the reason is as follows.
The number of INAPPROPRIATEwords in the gold standard is much smaller than that of APPROPRIATE words.Hence, we think a system that is biased to classify words as APPROPRIATEoften achieves high accuracy.
It is one of future works to improve the recall whilekeeping high accuracy.We examined discrimination rules learned by DT.
Figure 4 depicts the ruleslearned by DT when the whole gold standard data of Business category is usedas a training data.
In the Figure, the horizontal/vertical axis corresponds to theprobability in the written/spoken language corpus.
Words in the gold standardcan be mapped into this two dimension space.
INAPPROPRIATE/ APPROPRI-ATE words are represented by a cross/square.
The line represents discriminationrules.
Words below the line are classified as INAPPROPRIATE, and the othersare classified as APPROPRIATE.6.3 Effect of Topic AdaptationFinally, we investigated the effect of topic adaptation by comparing our methodto a baseline method that does not consider topic.Our method consists of two steps: (1) mapping from a word to features, and(2) applying discrimination rules to the features.
In the step (1), the probabilityis estimated using the written and spoken language corpora in a certain topicLexical Choice via Topic Adaptation for Paraphrasing Written Language 98900.00010 0.0001 0.0002Probability in written languageProbabilityinspokenlanguageFig.
4.
Decision tree rules in Business cat-egorycustomercustomermanagementmanagement00.00020.00040 0.0002 0.0004 0.0006 0.0008Probability in written languageProbabilityinspokenlanguageFig.
5.
Examples in Business categoryT.
In the step (2), discrimination rules are learned by DT using the whole goldstandard data of topic T. We used DT rather than SVM because rules are easyfor humans to understand.
On the other hand, the baseline uses the same dis-crimination rules as our method, but uses the whole written and spoken languagecorpora to map a word to features.
Hereafter, the two methods are referred asProposed and Baseline.
Both methods use the same discrimination rules butmap a word to features in a different way.
Therefore, there are such words thatare classified as INAPPROPRIATE by Proposed and are classified as AP-PROPRIATE by Baseline, and vice versa.
In the evaluation, we compared theclassification results of such words.We evaluated the results of topical words and non-topical words separately.This is because we think Proposed is good at dealing with topical words andhence we can clearly confirm the effectiveness of topic adaptation.
Here, a word isregarded as topical word in topic T, if its probabilities in the written and spokenlanguage corpora assigned topic category T are larger than those in the wholecorpora with statistical significance (the 5% level).
Otherwise it is regarded asnon-topical word in topic T. As a statistical test log-likelihood ratio [4] was used.The evaluation procedure is as follows.1.
Web pages in Business category were downloaded from Yahoo!
Japan, andwords in those pages were classified by the two methods.
If the results of thetwo methods disagree, such words were stocked.2.
From the stocked words, we randomly sampled 50 topical words in Businessand 50 non-topical words.
Note that we did not use such words that arecontained in the gold standard.3.
Using Web pages in Health category, we also sampled 50 topical words inHealth and 50 non-topical words in the same manner.4.
As a result, 100 topical words and 100 non-topical words were prepared.
Foreach word, two judges (Judge-A and Judge-B) individually assessed whichmethod successfully classified the word.
Some classification results were dif-ficult even for human judges to assess.
In such cases, the results of the bothmethods were regarded as correct.990 N. Kaji and S. KurohashiTable 6 represents the classification accuracy of the 100 topical words.
Forexample, according to assessment by Judge-A, 75 out of 100 words were classifiedsuccessfully by Proposed.
Similarly, Table 7 represents the accuracy of the 100non-topical words.
The overall agreement between the two judges according tothe Kappa value was 0.56.
We compared the result of the two methods usingMcNemar?s test [8], and we found statistically significant difference (the 5%level) in the results.
There was no significant difference in the result of non-topical words assessed by the Judge-A.Table 6.
Accuracy of topical words classi-ficationJudge Method AccuracyJudge-A Proposed 75% (75/100)Baseline 52% (52/100)Judge-B Proposed 72% (72/100)Baseline 53% (53/100)Table 7.
Accuracy of non-topical wordsclassificationJudge Method AccuracyJudge-A Proposed 48% (48/100)Baseline 66% (66/100)Judge-B Proposed 38% (38/100)Baseline 78% (78/100)6.4 Discussion and Future WorkProposed outperformed Baseline in topical words classification.
This resultindicates that the difficulty of topical words depends on the topic and we haveto consider the topic.
On the other hand, the result of Proposed was not goodwhen applied to non-topical words.
We think this result is caused by two reasons:(1) the difficulty of non-topical words is independent of the topic, and (2) Base-line uses larger corpora than Proposed (see Table 1 and Table 4).
Therefore,we think this result does not deny the effectiveness of topic adaptation.
Theseresults mean that Proposed and Baseline are complementary to each other,and it is effective to combine the two methods: Proposed/Baseline is appliedto topical/non-topical words.
It is obvious from the experimental results thatsuch combination is effective.We found that Baseline is prone to classify topical words as inappropriateand such bias decreases the accuracy.
Figure 5 depicts typical examples sam-pled from topical words in Business.
Both judges regarded ?management?
and?customer?7 as appropriate for spoken language in Business topic.
The white tri-angle and diamond in the Figure represent their features when the probabilityis estimated using the corpora in Business category.
They are located above theline, which corresponds to discrimination rules, and are successfully classified asappropriate by Proposed.
However, if the probability is estimated using thewhole corpora, the features shift to the black triangle and diamond, and Base-line wrongly classified the two as inappropriate.
In Health category, we couldobserve similar examples such as ?lung cancer?
or ?metastasis?.7 Our target language is Japanese.
Examples illustrated here are translation of theoriginal Japanese words.Lexical Choice via Topic Adaptation for Paraphrasing Written Language 991These examples can be explained in the following way.
Consider topical wordsin Business.
When the probability is estimated using the whole corpora, it isinfluenced by the topic but Business, where topical words in Business are ofteninappropriate for spoken language.
Therefore, we think that Baseline is biasedto classify topical words as inappropriate.Besides the lexical choice method addressed in this paper, we proposed lex-ical paraphrase generation method [10].
Our future direction is to apply thesemethods to written language texts and evaluate the output of text-to-speech.
Sofar, the methods were tested on a small set of reports.Although the main focus of this paper is lexical paraphrases, we think thatit is also important to deal with structural paraphrases.
So far, we implementeda system that paraphrases compound nouns into nominal phrases.
It is ourfuture work to build a system that generates other kinds of structural para-phrases.7 Related WorkLexical choice has been widely discussed in both paraphrasing and natural lan-guage generation (NLG).
However, to the best of our knowledge, no researchesaddress topic adaptation.
Previous approaches are topic-independent or specificto only certain topic.Lexical choice has been one of the central issues in NLG.
However, the mainfocus is mapping from concepts to words, (e.g., [1]).
In NLG, a work by Edmondsand Hirst is related to our research [5].
They proposed a computational modelthat represents the connotation of words.Some paraphrasing researches focus on lexical choice.
Murata and Isaharaaddressed paraphrasing written language to spoken language.
They used onlyprobability in spoken language corpus [12].
Kaji et al also discussed paraphras-ing written language to spoken language, and they used the probabilities inwritten and spoken language corpora [11].
On the other hand, Inkpen et al ex-amined paraphrasing positive and negative text [9].
They used the computationalmodel proposed by Edmonds and Hirst [5].The proposed method is based on the probability, which can be consideredas a simple language model.
In language model works, many researchers havediscussed topic adaptation in order to precisely estimate the probability of topicalwords [6,7,13].
Our work can be regarded as one application of such languagemodel technique.8 ConclusionThis paper proposed lexical choice method that considers the topic.
The methodutilizes written and spoken language corpora classified into topic categories, andestimate the word probability that is adapted to the topic of the input text.From the experimental result we could confirm the effectiveness of topic adap-tation.992 N. Kaji and S. KurohashiReferences1.
Berzilay, R., Lee, L.: Bootstrapping Lexical Choice via Multiple-Sequence Align-ment.
Proceedings of EMNLP.
(2002) 50?572.
Bulyko, I., Ostendorf, M., and Stolcke, A.: Getting More Mileage from Web TextSources for Conversational Speech Language Modeling using Class-Dependent Mix-tures.
Proceedings of HLT-NAACL (2003) 7?93.
Carletta, J.: Assessing Agreement on Classification Tasks: The Kappa Statistic.Computational Linguistics.
22 (2).
(1996) 249?2554.
Dunning, T.: Accurate Methods for the Statistics of Surprise and Coincidence.Computational Linguistics.
19 (1).
(1993) 61?745.
Edmonds, P., Hirst, G.: Near-Synonymy and Lexical Choice.
Computational Lin-guistics.
28 (2).
(2002) 105?1446.
Florian, R., Yarowsky, D.: Dynamic Nonlocal Language Modeling via HierarchicalTopic-Based Adaptation: Proceedings of ACL.
(1999) 167?1747.
Gildea, D., Hofmann, T.; TOPIC-BASED LANGUAGE MODELS USING EM.Proceedings of EUROSPEECH.
(1999) 2167?21708.
Gillick, L., Cox, S.: Some Statistical Issues in the Comparison of Speech Recogni-tion Algorithms.
Proceedings of ICASSP.
(1989) 532?5359.
Inkpen, D., Feiguina, O., and Hirst, G.: Generating more-positive and more-negative text.
Proceedings of AAAI Spring Symposium on Exploring Attitude andAffect in Text.
(2004)10.
Kaji, N., Kawahara, D., Kurohashi, S., and Satoshi, S. : Verb Paraphrase basedon Case Frame Alignment.
Proceedings of ACL.
(2002) 215?22211.
Kaji, N., Okamoto, M., and Kurohasih, S.: Paraphrasing Predicates from WrittenLanguage to Spoken Language Using the Web.
Proceedings of HLT-NAACL.
(2004)241?24812.
Murata, M., Isahara, H.: Automatic Extraction of Differences Between Spoken andWritten Languages, and Automatic Translation from the Written to the SpokenLanguage.
Proceedings of LREC.
(2002)13.
Wu, J., Khudanpur, S.: BUILDING A TOPIC-DEPENDENT MAXIMUM EN-TROPY MODEL FOR VERY LARGE CORPORA.
Proceedings of ICASSP.
(2002) 777?780
