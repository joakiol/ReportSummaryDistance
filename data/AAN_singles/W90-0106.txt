Natural Discourse Hypothesis EngineSusanna CummingDepar tment  o f  L inguist icsCampus  Box  295Univers i ty  o f  Co loradoBoulder ,  Co lorado 80309AbstractAs text generation systems get more sophisticatedand capable of producing a wider syntactic andlexical range, the issue of how to choose amongavailable grammatical options (preferably in ahuman-like way) becomes more pressing.
Thus,devisers of text generation systems are frequentlycalled upon to provide their own analyses of thediscourse function of various kinds of alternations.In this paper, I describe a proposed research toolwhich is designed to help a researcher xplore andanalyze a natural-language "target ext" in order todetermine the contextual factors that predict thechoice of one or another lexical item or grammati-cal feature.
The project described in this paper isstill at the drawing-board stage; I welcome sugges-tions about ways it could be changed or expandedto fulfill particular analytic needs.Theoretical pre l iminar iesWhile some aspects of a natural-language text are deter-mined by the nature of the information a speaker wishes toconvey to a hearer, there are many more aspects that seemto be determined by certain cognitive needs that the hearerhas.
Speakers tailor their output to the informationalresources and deficiencies of the hearer in several ways: byadjusting the amount of information they make explicit, byarranging new information relative to old information in amaximally helpful way, and by giving special marking toinformation that may be difficult for the hearer to accessfor a variety of reasons.
It is these strategies that give riseto the wide variety of syntactic and lexical resources ofany natural language for saying the "same thing" in differ-ent ways.
We can call the relation between lexico-grammatical features and the speaker's communicativegoals in choosing those features the "discourse functions"of the features.For any particular alternation, then, the best predictorof the speaker's choice should be a model of the cognitivestate of the hearer.
Unfortunately, neither human speakersnor computer systems have direct access to the hearer'smind.
But linguists have long realized that we do haveaccess to a fair approximation f an important subset of theinformation the hearer possesses at a given point in a dis-course: namely the text which has been produced up to thatpoint.
(\[Chafe 1987\] and \[Giv6n 1983\] are two con-temporary expressions of that principle.)
And in fact wecan make fairly good predictions of lexico-grammaticalchoices based on inferences that come from the nature ofthe preceding text.
For instance, a referent that has beenreferred to in the previous clause is likely to receiveminimal coding (a pronoun or zero, depending on syntacticconsiderations).
But this principle can be overridden bythe presence of other factors that interfere with the acces-sibility of the referent - -  e.g.
a paragraph break or anothercompeting referent - -  resulting in the use of a full nounphrase.
Or, to give another example, a speaker is likely touse special syntax (such as the "presentative" or "thereis..." construction) to introduce a referent hat will beprominent in the following discourse; so a hearer is likelyto have easier access to a referent introduced in that waythan one that has been introduced "casually", e.g.
in aprepositional phrase.
Therefore, subsequent references toa referent that has been introduced with a presentative aremore likely to be pronouns than noun phrases.These are all factors that can be discerned in thepreceding text and are taken into account by speakers asaffecting the nature of the bearer's expectations.
Thereforeunder these perturbing circumstances the speaker candecide to use a fuller reference, .g.
a proper name or nounphrase.
Figure 1 illustrates the relation between the dis-course produced by the speaker, the hearer's mental state,and the speaker's model of the hearer.
In real face-to-faceinteraction, the hearer can influence the speaker's model ofher or him in more direct ways - -  e.g.
by verbal and non-verbal indications of agreement, understanding, protest, orconfusion.
But this two-way channel is available neitherto human writers nor to computer text generators.39Speaker's eommunieaKve Bearer's mental sure,goa.L~ / including rel~resentatianSpeaker's modet / of speechoj' heater's tate / /Figure 1: A model of communication.The fact that we can draw inferences from precedingtext about the hearer's slate justifies the methodologycommon in functional inguistics whereby the Enguistinvestigates the function of a particular morpho-syntacticalternation by attempting todiscover correlations in naturaltexts between that alternation and various features of thecontext.
This method is also likely to be the one whichwill lead to the best results for text generation specialists,since prior text is one information source any computa-tional system has easy access to as a guide in makingfuture decisions.There are, of course, currently available several large-scale databases of English texts of various kinds, some ofwhich have been provided with various amounts and kindsof coding (from word-class lagging to syntactic analysis).However, for many kinds of discourse work these data-bases have not been useful.
On the one hand, such data-bases are often not available in languages other thanEnglish; on-the other, the coding that is provided assumesan analysis which may not meet the needs of a particularuser.
In fact it is often the case that aspects of the syntacticanalysis depend on a functional analysis having alreadybeen done; so a pre-coded atabase may contain assump-tions about the answers to the same qtfestions it is sup-posed to be helping to solve.
The tool described here isdesigned for the user who is satisfied with a relativelysmall amount of data, but wants to have total control overthe analysis of the corpus.Currently, functional inguists often enter their textdata into commercial relational database tools, such asDBase and Paradox.
However, such tools have beendesigned with other kinds of applications in mind, andtherefore there are many properties of natural anguagetexts which these tools can only capture by awkward orindirect means.
Specifically, natural language texts, unlikee.g.
client or sales lists, are simultaneously linear (ordermatters) and recursively hierarchical.
Thus, the query lan-guages available with such database products are generallygood at extracting the kind of information from textswhich is least useful to linguists, but require considerablead hoc programming to extract he kind of informationmost relevant to our needs.
The tool proposed here, con-versely, should answer most easily the questions a dis-course analyst wants to ask most frequently.These problems in representing certain crucial aspectsof natural anguage texts computationally using off-the-shelf tools have sent many linguists hack to marking upxeroxed texts by hand with colored pencils.
The approachoutlined here is intended to combine the advantages of thecolored-pencil technique (spontaneity, flexibility, anddirect involvement with the whole text) with the advan-tages of computational techniques (quick and painlessidentification, compilation, and comparison of variousfeatures of text units).Descr ip t ion  o f  the  toolThe tool proposed in this paper will aid in the generationof hypotheses concerning the discourse function of alexico-grammatical feature (or combination of features) byallowing the researcher to isolate instances of that featureand view them in relation to various aspects of its dis-course context.
When the researcher has arrived at andstated a working hypothesis about which features of thecontext are most relevant to predicting the targeted feature,the system will be able to test the hypothesis against hedata and provide feedback by displaying both predictedand non-predicted occurrences of the target feature.Further efinements can then be made until the fit betweenthe researcher's hypothesis and the actual text is as good aspossible.
The hypothesis can then be integrated into a textgeneration system with some assurance that the lexico-grammatical choices made by the system will approximatethose made by a human with a similar text-production task.In order for the tool to be able to recognize andcompare various text features - -  including relativelycovert information such as the reference of noun phrasesand the mood of a sentence as well as relatively overt cuessuch as lexical items and structure - -  the user must firstannotate the text, indicating a) its hierarchical structure,and b) a set of features (attribute/value pairs) associatedwith each constituent.
The annotation will be largelymanual (though aspects of it can be automated, as will beexplained), because we want the tool itself to be neutral as40to the theoretical assumptions inherent in any particularanalysis.
Thus, it will be possible to use this tool to testamong other things the comparative predictive usefulnessof various possible analyses of a text.Using the tool will have the following phases:.
Annotation: mark constituents, and for each consti-tuent indicate its category membership and anyother desired features.
The amount and type ofannotation is entirely up to the user; it will never benecessary to include any more detail than is rele-vant for the current analysis.
Constituents may beanything from words to paragraphs or episodes.2.
Hypothesis formation: view the target feature andcontext in various arrangements.. Hypothesis testing: state a hypothesis n terms of apattern in the context that predicts the occurrence ofthe target feature.. Hypothesis refinement: make changes in hypothesis,annotation, or both and retest against he same data;extend analysis by tesdng against different data.l .
Annotat ionAn example text showing segmentation a d sample featurespecification associated with three of the constituents igiven in figure 2.\[\[We\] \[wentl \[from \[Kobell \[to \[Shanghail\],\]\[\[from \[Shanghai\]l \[we\] \[went\] \[to \[Singapore\]l,l\[\[and\] \[there\] \[l\] \[still remember\]calegon/ = np\ [ \ [ \ [and\ ]  \ [ the  \[natives\] \[in \ [ sampans \ ] I \ ]  ] ~ =  plt~r*lI r lf l lctnI = SHIP-FOLK \[would see\] \[it\] \[\[0l \[comiae\].\]\] l e,hn = Oeo,ae:::::::::.
tlm.
role = sub|ec!\ [ \ [0 \ ]  [d ive \ ] .
\ ]  [ \ [and\ ]  i::i\[0\]:i~:: \ [ come up\ ] \ ]  I ( * '~  = v4) .
': "":':':':':'::':': ":':':':':":':+:i +:':':':':':+:'::':'':::'::'':'" " " : :: :': ~ I~lt~lCy' = llpI id = npI5I ~ = p~oI number = plural?
referent = NATIVESi=.-.
j - - - - -  slm, role = ~bied sere.
role = ~ctor" Im~|.
= CtlOI IveVo = V71 class = humanFigure 2: Annotated text.Annotation will have the following steps: segmenta-tion, category specification, further feature specification,and dependency specification.
Furthermore, "pseudo-constituents" may be added and specified at this stage, asexplained below..
Segmentation: Mark off a stretch of text to be con-sidered a unit.
Initially, allowable units must becontinuous and properly contained inside otherunits; but eventually it would be nice to allow twokinds of violations to this principle, namely discon-tinuous constituents and overlapping constituents.. Category specification: Specify the category of theconstituent.
The category will be stored as anattribute-value pair (with the attribute "category")like other features.
At the time of category specifi-cation, the constituent will be assigned a unique ID,also an attribute-value pair (with the attribute "id").. Further feature specification: Specify furtherattribute-value pairs.
In order to ensure consistencythe user will be prompted with a list of a) attributesthat have previously been used with that category,and b) values that have previously ~n associatedwith that at~bute.
The user may select from theselists or enter a new aUribute or value..
Dependency relations: Some kinds of relationsbetween constituents are best treated by specifyingdependency relations between the two items, i.e.
byproviding a labelled pointer linking the two.
Syn-tactic analyses differ from each other in what kindsof relations are treated as constituency relations(e.g.
the relationship of sister nodes in a tree) andwhat kinds are treated as pure dependency rela-tions.. "Pseudo-constituent" i sertion: For some purposes,it may be desirable to allow the insertion of"pseudoconstituents" in the text, i.e.
phonologicallynull "elements" that can be inferred from thesurface text, or boundaries which aren't marked byany explicit linguistic element (such as "episodeboundaries" or possibly the beginning and end ofthe text).
Examples of null elements which can betracked in discourse as if they were overt include"zero pronouns", inferrable propositions, and ele-ments of frames or schemas.
Pseudo-constituentscan be inserted irectly into the text like actual con-stituents, but they should have distinctive markingin their feature specification to indicate theirabstract status; in the examples I have distinguishedthem by the feature "type = pseudo".41Figure 3 illustrates a possible implementation (usingpop-up menus) of the process of feature specification.category = \[\]category values:noun\[ verb| preposition/ adjective/ adverbk._._ complomenlizernoun phraseverb groupprepositional phraseclausesonlanceparagraph~cate~ory = noun phrase~numoer = II |number values: )singular t~legory = noun phrase 1f " noun phrase ath'ibutos: / number/ referent/ status| syn .
role.
._~ sem.
roleFigure 3: Feature specification.QueriesHaving annotated a text to the desired degree, it is thenpossible to start fishing around for an analysis of the distri-butional characteristics of the feature or combination offeatures of interest to the analyst (henceforth "targetpattern").
Experience has shown that the most useful waysto do this is to get an idea of the overall frequency of thephenomenon, and then to "eyeball" the target pattern invarious kinds of context.
Thus, the tool should have thefollowing capabilities:1.
Counting: Count the number of instances of thetarget pattern.2.
Highlighting: Display the whole text, with constitu-ents which match the target pattern highlighted bycolor or a distinctive font..
Extraction: Extract constituents which match thetarget pattern into a file of the same type as the textfile.
It will then be possible to print out the outputfile, or to subset it further by performing additionalhighlighting or extraction queries on it.Basic pattern specification.
These operations require aformat for describing the target pattem.
I propose an inter-face which will allow the user to open a "query window",in which he or she can enter a partial specification of oneor more constituents obe matched against he text, usingthe same entry techniques as are used to enter, edit, andannotate actual text.
This approach as the advantage ofletting the user make use of what he or she already knowsabout the annotation process to specify the target pattern,and furthermore it allows the identification of highlycomplex patterns in an intuitive way.A pattern specification will contain the following kindsof elements:1.
Actual structure (brackets), text, and featurebundles.
~.
Variables which stand for text or features, used toindicate relationships between parts of the pattern,or to specify to parts of the pattern to be acted on(counted, highlighted, extracted).3.
Various kinds of wildcard elements which willmatch unspecified strings of structure or text.4.
Operators (and, or, not) which specify relationsbetween features, text, variables, or whole patterns.It should be possible to save a query in a file for futureediting and re-use.
This avoids repetitive typing of thesame query, while permitting refinement and adjustment ofqueries that don't give the desired results the first time.
Italso allows the creation of a series of related queries bycopying and slightly altering aprototype.Variables (indicated here by strings of alphanumericsstarting with "#") are used to specify text or elements offeature bundles for reference elsewhere, either to bematched or acted upon.
A text variable is interpreted asmatching all the text in the constituent that contains it(including text in embedded constituents).
For instance,the following two queries would match constituents con-taining two elements of the same category conjoined by"and", as in "Jill and Liza" or "sang off-key and danced thewaltz".
The (a) version would highlight he whole con-joined phrase; the (b) version would highlight each of theconjoined phrases, but not "and".
(The dots are wildcards,explained below.
In these and the following examples,feature specifications are indicated in small italics; literaltext is enclosed in quotes.
)( la)  \[ #txt \[..\]cat=#c "and" \[..\]cat=#c \]highl ight #txt(2b) \[ \ [#txt l  ..\]cat=#c "and" \[#txt2 ..\]cat=#c \]highl ight #txt l  and #txt242An analysis of the types of queries I anticipate wantingto make reveals that a fairly diverse set of wildcards isnecessary.
Structure wildcards match elements of struc-ture, i.e.
combinations of brackets.
Text and features areignored by these wildcards (see below).
Two types ofstructure wildcards are provided.
The first, composed ofperiods, stops at the first instance of the pattern in thestring; the second, composed of exclamation marks, findsall instances of the pattern.1st Allmatch matchesDepth: a series of all right or allleft brackets!!
Constituents: a series of matchingleft and right brackets (and theircontents)!!!
Any materialThe following examples illustrate the use of slructure wild-cards:(2) \[ \[ #X \]cat=np .. \]cat=clauseX matches a top-level NP which is the first constituent of aclause.
It matches "Jill" in "Jill ate the peach", but nothingin "On the next day Jill ate the peach" (because the firsttop-level element is a prepositional phrase, not a nounphrase).
(3a) \[.
\[ #X \]cat=np .. \]cat=clause(3b) \[ !
\[ #X \]cat=rip .. \]cat=clauseX matches an NP which is part of the first constituent in aclause, no matter how deeply it is embedded.
In the sen-tence "On the day after the fire Jill ate the peach", both (a)and (b) will match "the day after the fire", and the (b)version will also match "the fire".
(4a) \[ .. \[ #X \]cat=np.. \]cat=clause(4b) \[ !!
\[ #X \]cat=np .. \]cat=clauseX matches the first NP which is a top-level constituent ofthe clause; in (b), it matches all NPs which are top-levelconstituents of the clause.
In the sentence "On the dayafter the fire Jill ate the peach", both versions will match"Jill"; (b) could also match "the peach" if the sentence wasgiven a "flat" structural nalysis (without a verb phrase).
(5a) \[ ... \[ #X \]cat=,~ .. \]cat=clause(5b) \[ !!!
\[ #X \]cat=np .. \]cat=clauseX matches the first noun phrase in a clause (no matterwhere it is); (b) matches every noun phrase in a clause.
In"Much to the surprise of her neighbors, Jill ate the peach",(a) will match "the surprise of her neighbors", while (b)will additionally match "her neighbors", "Jill", and "thepeach".Text/feature wildcards are used both to match actualtext and to match elements of feature bundles (attributesand values).
(nothing) Matches any text/feature or notext/feature@ Matches no text (the absence of text)Matches any text, attribute, or valueThe following examples how how these wildcards couldbe used:(6) \[ #X @ \[ \]cat=clause \]cat=npX matches a noun phrase whose first element is a clause.It would match "that he came" in "that he came surprisedme"; but not in "the fact that he came surprised me".
(7) \[ #X \]ref=*X matches any constituent that has a referent specified.Figure 4 illustrates one way windows and menus couldbe used to simplify the query process.
The query windowis divided into two panes, a "pattern pane" and an "actionpane".
The various kinds of query elements can be eithertyped in or selected from a set of pull-down menus.
Thisquery is designed to extract noun phrases which have theproperty of "referential mbiguity" in the sense of \[Giv6n1983\]: referents which have been referred to in theimmediately previous clause, but where the previousclause also contains another referent of the same semanticclass.
(An example would be "Mary saw Jill, and she ranoff'; she is referentially ambiguous, and in fact we wouldexpect a full noun phrase rather than a pronoun in this kindof context.
)43query window Save query to file~:/:~!~//i::~ii~!~::~ii::!~i::i~i~iii~iiii~!i~:~!!~i~!~!~!!i::~!i~iii::iiiii~iiiiiii~iiii::ii!i~i!ii~!i.~.~ii~::i~.~i~iiii~ii:.i:~?:~iii?.
: :..i.i.
~:: i:.
:  :.Text Wildeards Variables Boolean f...
I I ... 1 ... \ [1  ... l -q .
co, : o,ooso jcat = np col = clauseref JJrefl id = J~X ref = ~refIJand \ [ .
.
.
\ [1 ... \ ] .
,/I )i~iiii  ~:.6 ~ ~iiii~ ~iiiii iiiliiiiil  lil iiiii iiiiiiiiiiiiiii !
iiiii!i  ii !iiiiiiiiiiiiiiiii!i  !
ii i iiiiiiiiiiiiii    iiiii!!!
!i~ ~ iiii!
!iiiiiii~iiii  !~ i: l ~iii::!iiii!
ii::: ~i~i:i ~:: :!
:Count Highlight Extract Variables Booleanexh:oct Jtxtl.
ond Jtxt2to (fi lename): ombig.dotChange quer 7 window Save query 1.o fileText \]fildeards Variables Boolean\[ .-.
\[ \] -- \[ \] ..- \]f~hl~ot--.0 .1Text Wildeards Variables Boolean\[... \ [ \ [ \ ]  .. \ [ \ ] .
.
.
\] \] ( ~ )Figure 4: A query.Using queries to change annotationExtensive xperience with feature-coding of text data hasshown that there is a large number of features which arepredictable from the identity of lexical items and/or com-binations of other features.
In these cases it is very con-venient o be able to partially code a text and to fill in theredundant codes by using queries.
Similarly, it is some-times desirable to use redundant information in anannotated text to change or delete features when youchange your mind about he best coding scheme.
Further-more, if it is possible to insert structure boundaries on thebasis of patterns found in the text, it is even possible toperform some structure insertion automatically, giving theuser in effect he possibility of using queries to automati-cally parse the text where this can be done reliably.he most straightforward way to implement this is to allowthe user to specify two patterns, an "old" pattern and a"new" pattern.
The query illustrated in figure 5 creates averb phrase constituent wherever a verb is followed by anoun phrase which is its object.Figure 5: A change query.Distance queries.
When text is viewed as a window to thecognitive processes of the speaker, it becomes apparentthat the distance between e.g.
two mentions of a referent ortwo clauses referring to the same event can be important.This is because the evidence suggests that the cognitiveaccessibility (to the hearer) of a referent "decays" overtime, so that speakers need to do more work to accomplishreference to something that has not been mentionedrecently (of.
\[Giv6n 1983, Chafe 1987\]; the explanationpresumably has to do with general properties of short ermmemory storage).
For this reason, it is desirable to have away to measure the text distance between two items.There are various ideas "in the air" about what theappropriate units for measuring distance are (e.g.
clauses,intonation units, conversational turns), and differentmeasures are clearly appropriate for different text types; soit is desirable to define distance queries o that the user canspecify the unit to be counted as well as the beginning andending patterns (the two items whose separation is beingmeasured).
The result of a simple distance query is natu-rally an integer; but where the beginning and ending pat-terns are general, the result should be a list of integerswhich can then be averaged.
Finally, in order to make iteasy to reference distance information in future queries, itshould be possible to save the distance result as a value ofa feature with a user-specified attribute.Figure 6 illustrates a query which computes "lookback"(i.e.
the distance between two NPs with the same referent)for pronouns, using the clause as a unit.
It averages the44lookback value, so that average pronoun lookback can becompared with e.g.
average full noun phrase lookback.\[ Distance query window Save query to fileText ffildeards Variables Boolean Text Wildeards Variables Boolean\[,1r cot=riP Itype=prn /.
:!i::;i::~iii~:ip~iii/:ii~i%:.~:iii::~:~: ..: ..i!
:~:: ii!iiiiii::i::iiii~i:iiii!ii!i!ii :.
: ?
.. ::.
:::: ?
:~: :Text Uildeards Variables Boolean\ [ " ' \ [ ~l ist Sum Average Add-as-featureAverageFigure 6: A distance query for "lookback".Another significant use for the distance query is tocompute "mention umber", that is, whether a noun phrasecontains the first, second, third etc.
mention of a referent.This could be accomplished by measuring the distancebetween a noun phrase and the beginning of the text, usingnoun phrases referring to the same entity as the unit of dis-tance.
Such a query is illustrated in figure 7 (whichassumes that text boundaries have been marked withpseudo-constituents).Distance query window Save query to fileiBeginhiti~i!ip~~'t'iiii~panei:::i::ii!:::.
::iiii~i:i::ii:.i:::ii:!i: , i ::!i::Faidfii~::!~t~:: paneText Wildcards Variables Boolean Text lfildcards Variables Boolean\[ \]~-~e'ab*unda,T 1 \[ 1~~.~i~i.Uh.~!i~!i~:.iif~ii!i!J:!i!il;::!:!ili!i!i!:.
:i: ..:i!~:::~~ : iii::i::i?:g!!::;i!i!iii:-!::i:::.::ii!i!i)!~:;i~ii~.:i~:.:i~:~:~:i:i.:;;:.~.~::z:!::~::i!~;~:~:f:.::::i:;:..
: :.Text rddcards Variables Boolean\[ lx(_~i~_ ) =..... ~:~:ii/~:i!ii;ii~:ii!~ii:iiiiii:!i;: ~:!~i~iii;iii;iii~ii~iiiiiii~iii~i~ii~i~i~i~?~Jii~i~i~i~!~:iii~ :::: :.
:Sum Av~rage ARid-u-featureAdd--as-feafum IUFigure 7: A distance query for "mention".Addit ional componentsIn the furore, it would be very desirable to implement thepossibility of adding additional components so that all lin-guistic information eed not be stored directly in the text.For instance, it would be nice to allow a lexicon com-ponent, which would contain partial feature specificationsof lexical items (including e.g.
category, number, tense,semantic lass).
Queries could then search the lexicon aswell as the text for the presnece of features, obviating theneed to manually perform highly predictable annotation.
Itis easy to see how currently available large-scale l xicaldatabases could be adapted to this purpose, obviating alarge amount of hand annotation.
A "slructurecon" couldperform a similar function for larger units.
These addi-tions would be particularly useful for applications involv-ing large amounts of rather similar text; they would be lessuseful for small texts where open-class lexical items andpredictable structures are rarely repeated, or for lexicallyand structurally diverse texts.Hypothesis refinement using queriesI will conclude with an example of the way this tool can beused to generate and test hypotheses about he way linguis-tic choices are made.
Since the tool has not yet beenimplemented, I have chosen an area where previousresearch as given a good indication of what the answersto queries would probably be: the introduction into dis-45course of referents which are new to the hearer (in thesense of "nonidentifiable").
The following discussiondraws largely on the results reported in \[Du Bois 1980\].The category of nonidentifiable r ferent can be approxi-mated by the feature "first mention".
Therefore, the firststep will be to use the method escribed above to automat-ically add the "mention" feature to each noun phrase (thisprocedure will assign the feature "mention = 0" to firstmentions).
Then you can "eyeball" all first mentions incontext by using the following query:(8) \[ #X \]cat=np,~nention=Ohighlight #XLet's say you notice that many, but not all, first mentionshave an indefinite article.
You wonder what proportion ofthe data is accounted for by simply stating "first mentionshave an indefinite article".
You can determine this bymeans of the following series of queries:(9) \[#X "a" or "an" .. \]cat=q, mention=lcount #X'How many first mentions are marked with an indefinitearticle?
'(10) \[#Y not "a" and not "an" .
.
\]cat=np, mention=Ocount #Y'How many first mentions don't have an indefinitearticle?
'(11) \[#Z "a" or "an" .. \]cat=he, mention=not 0count #Z'How many things marked with indefinite articles aren'tfirst mentions?
'Suppose you discover that, although all NPs with indefi-nite ~ticles are first mentions, and most first mentionshave an indefinite article, there is a large number of firstmentions which don't have an indefmite article.
The nextstep might be to highlight hese so you can view them incontext and look for shared characteristics.
For instance,you might notice that plurals don't have indefinite articles.You can then modify the original tests to check for numberas well, e.g.
(12) \[#Y not "a" and not "an" .. \]cat=rip, mention=B, hum=singhighlight and count #Y'How many singular first mentions don't have an indefi-nite article?
Show them to me.
'The response to this query might well reveal anotherlarge class of first mentions which are actually markedwith a definite article.
These are referents which can beinterpreted as "accessible" to the hearer by virtue of beingclosely associated with (e.g.
a part of) something that hasalready been mentioned.
One way to cope with theseinstances i to insert "pseudo-constituents" intothe text atthe point where the associated entity is mentioned, and re-running the mention-number query.
These referenceswould no longer count as first mentions, and a retry ofquery 12 would reveal a much smaller number of excep-tions.This example could be extended, but it is hoped that itwill illustrate the way such a tool could be used for quickand easy exploration of the functional attributes of linguis-tic forms.AcknowledgmentsThis paper was improved by comments from SandyThompson, Randy Sparks, and an anonymous reviewer.They are not responsible for remaining faults.References\[Chafe 1987\] Chafe, Wallace L. Cognitive constraints oninformation flow.
In Russell S. Tomlin (editor),Coherence and grounding in discourse.
(TypologicalStudies in Language 11).
Amsterdam: Benjamins,1987.\[Du Bois 1980\] Du Bois, John W. Beyond definiteness:the trace of identity in discourse.
In Wallace Chafe(editor), The Pear Stories, 203-275.
Norwood: Ablex,1980.\[Giv6n 1983\] Giv6n, Talmy, editor.
Topic continuity indiscourse.
Amsterdam: Benjamins, 1983.46
