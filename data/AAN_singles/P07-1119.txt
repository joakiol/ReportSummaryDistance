Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 944?951,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsSubstring-Based TransliterationTarek Sherif and Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada T6G 2E8{tarek,kondrak}@cs.ualberta.caAbstractTransliteration is the task of converting aword from one alphabetic script to another.We present a novel, substring-based ap-proach to transliteration, inspired by phrase-based models of machine translation.
We in-vestigate two implementations of substring-based transliteration: a dynamic program-ming algorithm, and a finite-state transducer.We show that our substring-based transducernot only outperforms a state-of-the-art letter-based approach by a significant margin, butis also orders of magnitude faster.1 IntroductionA significant proportion of out-of-vocabulary wordsin machine translation models or cross language in-formation retrieval systems are named entities.
Ifthe languages are written in different scripts, thesenames must be transliterated.
Transliteration is thetask of converting a word from one writing script toanother, usually based on the phonetics of the orig-inal word.
If the target language contains all thephonemes used in the source language, the translit-eration is straightforward.
For example, the Arabictransliteration of Amanda is Y 	K A?, which is essen-tially pronounced in the same way.
However, ifsome of the sounds are missing in the target lan-guage, they are generally mapped to the most pho-netically similar letter.
For example, the sound [p]in the name Paul, does not exist in Arabic, and thephonotactic constraints of Arabic disallow the sound[A] in this context, so the word is transliterated as?
?K., pronounced [bul].The information loss inherent in the process oftransliteration makes back-transliteration, which isthe restoration of a previously transliterated word,a particularly difficult task.
Any phonetically rea-sonable forward transliteration is essentially correct,although occasionally there is a standard translitera-tion (e.g.
Omar Sharif ).
In the original script, how-ever, there is usually only a single correct form.
Forexample, both Naguib Mahfouz and Najib Mahfuzare reasonable transliterations of 	??
?
m?
I.Jm.', butTsharlz Dykens is certainly not acceptable if one isreferring to the author of Oliver Twist.In a statistical approach to machine translitera-tion, given a foreign word F , we are interested infinding the English word E?
that maximizes P (E|F ).Using Bayes?
rule, and keeping in mind that F isconstant, we can formulate the task as follows:E?
= arg maxEP (F |E)P (E)P (F )= arg maxEP (F |E)P (E)This is known as the noisy channel approach tomachine transliteration, which splits the task intotwo parts.
The language model provides an esti-mate of the probability P (E) of an English word,while the transliteration model provides an estimateof the probability P (F |E) of a foreign word being atransliteration of an English word.
The probabilitiesassigned by the transliteration and language mod-els counterbalance each other.
For example, sim-ply concatenating the most common mapping foreach letter in the Arabic string ?
?KA?, produces thestring maykl, which is barely pronounceable.
In or-der to generate the correct Michael, a model needs944to know the relatively rare letter relationships ch/?and ae/?, and to balance their unlikelihood againstthe probability of the correct transliteration being anactual English name.The search for the optimal English transliterationE?
for a given foreign name F is referred to as de-coding.
An efficient approach to decoding is dy-namic programming, in which solutions to subprob-lems are maintained in a table and used to build upthe global solution in a bottom-up approach.
Dy-namic programming approaches are optimal as longas the dynamic programming invariant assumptionholds.
This assumption states that if the optimal paththrough a graph happens to go through state q, thenthis optimal path must include the best path up to andincluding q.
Thus, once an optimal path to state q isfound, all other paths to q can be eliminated fromthe search.
The validity of this assumption dependson the state space used to define the model.
Typ-ically, for problems related to word comparison, adynamic programming approach will define states aspositions in the source and target words.
As will beshown later, however, not all models can be repre-sented with such a state space.The phrase-based approach developed for statis-tical machine translation (Koehn et al, 2003) isdesigned to overcome the restrictions on many-to-many mappings in word-based translation models.This approach is based on learning correspondencesbetween phrases, rather than words.
Phrases aregenerated on the basis of a word-to-word alignment,with the constraint that no words within the phrasepair are linked to words outside the phrase pair.In this paper, we propose to apply phrase-basedtranslation methods to the task of machine translit-eration, in an approach we refer to as substring-based transliteration.
We consider two implemen-tations of these models.
The first is an adaptationof the monotone search algorithm outlined in (Zensand Ney, 2004).The second encodes the substring-based transliteration model as a transducer.
The re-sults of experiments on Arabic-to-English transliter-ation show that the substring-based transducer out-performs a state-of-the-art letter-based transducer,while at the same time being orders of magnitudesmaller and faster.The remainder of the paper is organized as fol-lows.
Section 2 discusses previous approachesto machine transliteration.
Section 3 presents theletter-based transducer approach to Arabic-Englishtransliteration proposed in (Al-Onaizan and Knight,2002), which we use as the main point of com-parison for our substring-based models.
Section 4presents our substring-based approaches to translit-eration.
In Section 5, we outline the experimentsused to evaluate the models and present their results.Finally, Section 6 contains our overall impressionsand conclusions.2 Previous WorkArababi et al (1994) propose to model forwardtransliteration through a combination of neural netand expert systems.
Their main task was to vow-elize the Arabic names as a preprocessing step fortransliteration.
Their method is Arabic-specific andrequires that the Arabic names have a regular patternof vowelization.Knight and Graehl (1998) model the translitera-tion of Japanese syllabic katakana script into En-glish with a sequence of finite-state transducers.After performing a conversion of the English andkatakana sequences to their phonetic representa-tions, the correspondences between the English andJapanese phonemes are learned with the expectationmaximization (EM) algorithm.
Stalls and Knight(1998) adapt this approach to Arabic, with the mod-ification that the English phonemes are mapped di-rectly to Arabic letters.
Al-Onaizan and Knight(2002) find that a model mapping directly from En-glish to Arabic letters outperforms the phoneme-to-letter model.AbdulJaleel and Larkey (2003) model forwardtransliteration from Arabic to English by treatingthe words as sentences and using a statistical wordalignment model to align the letters.
They selectcommon English n-grams based on cases when thealignment links an Arabic letter to several Englishletters, and consider these n-grams as single lettersfor the purpose of training.
The English translitera-tions are produced using probabilities, learned fromthe training data, for the mappings between Arabicletters and English letters/n-grams.Li et al (2004) propose a letter-to-letter n-gramtransliteration model for Chinese-English transliter-ation in an attempt to allow for the encoding of more945contextual information.
The model isolates individ-ual mapping operations between training pairs, andthen learns n-gram probabilities for sequences ofthese mapping operations.
Ekbal et al (2006) adaptthis model to the transliteration of names from Ben-gali to English.3 Letter-based TransliterationThe main point of comparison for the evaluationof our substring-based models of transliteration isthe letter-based transducer proposed by (Al-Onaizanand Knight, 2002).
Their model is a compositionof a transliteration transducer and a language trans-ducer.
Mappings in the transliteration transducer aredefined between 1-3 English letters and 0-2 Arabicletters, and their probabilities are learned by EM.The transliteration transducer is split into three statesto allow mapping probabilities to be learned sepa-rately for letters at the beginning, middle and end ofa word.
Unlike the transducers proposed in (Stallsand Knight, 1998) and (Knight and Graehl, 1998)no attempt is made to model the pronunciation ofwords.
Although names are generally transliteratedbased on how they sound, not how they look, theletter-phoneme conversion itself is problematic as itis not a trivial task.
Many transliterated words areproper names, whose pronunciation rules may varydepending on the language of origin (Li et al, 2004).For example, ch is generally pronounced as either[?]
or [k] in English names, but as [S] in Frenchnames.The language model is implemented as a finitestate acceptor using a combination of word unigramand letter trigram probabilities.
Essentially, the wordunigram model acts as a probabilistic lookup table,allowing for words seen in the training data to beproduced with high accuracy, while the letter trigramprobabilities are used model words not seen in thetraining data.4 Substring-based TransliterationOur substring-based transliteration approach is anadaptation of phrase-based models of machine trans-lation to the domain of transliteration.
In particular,our methods are inspired by the monotone searchalgorithm proposed in (Zens and Ney, 2004).
Weintroduce two models of substring-based translitera-tion: the Viterbi substring decoder and the substring-based transducer.
Table 1 presents a comparison ofthe substring-based models to the letter-based modeldiscussed in Section 3.4.1 The Monotone Search AlgorithmZens and Ney (2004) propose a linear-time decodingalgorithm for phrase-based machine translation.
Thealgorithm requires that the translation of phrases besequential, disallowing any phrase reordering in thetranslation.Starting from a word-based alignment for eachpair of sentences, the training for the algorithm ac-cepts all contiguous bilingual phrase pairs (up to apredetermined maximum length) whose words areonly aligned with each other (Koehn et al, 2003).The probabilities P (f?
|e?)
for each foreign phrase f?and English phrase e?
are calculated on the basisof counts gleaned from a bitext.
Since the count-ing process is much simpler than trying to learn thephrases with EM, the maximum phrase length can bemade arbitrarily long with minimal jumps in com-plexity.
This allows the model to actually encodecontextual information into the translation model in-stead of leaving it completely to the language model.There are no null (?)
phrases so the model does nothandle insertions or deletions explicitly.
They can behandled implicitly, however, by including inserted ordeleted words as members of a larger phrase.Decoding in the monotone search algorithm isperformed with a Viterbi dynamic programming ap-proach.
For a foreign sentence of length J and aphrase length maximum of M , a table is filled with arow j for each position in the input foreign sentence,representing a translation sequence ending at thatforeign word, and each column e represents possi-ble final English words for that translation sequence.Each entry in the table Q is filled according to thefollowing recursion:Q(0, $) = 1Q(j, e) = maxe?,e?,f?P (f?
|e?
)P (e?|e?
)Q(j?, e?
)Q(J + 1, $) = maxe?Q(J, e?
)P ($|e?
)where f?
is a foreign phrase beginning at j?
+1, end-ing at j and consisting of up to M words.
The ?$?symbol is the sentence boundary marker.946Letter Transducer Viterbi Substring Substring TransducerModel Type Transducer Dynamic Programming TransducerTransliteration Model Letter Substring SubstringLanguage Model Word/Letter Substring/Letter Word/LetterNull Symbols Yes No NoAlignments All Most Probable Most ProbableTable 1: Comparison of statistical transliteration models.In the above recursion, the language model isrepresented as P (e?|e?
), the probability of the En-glish phrase given the previous English word.
Be-cause of data sparseness issues in the context ofword phrases, the actual implementation approxi-mates this probability using word n-grams.4.2 Viterbi Substring DecoderWe propose to adapt the monotone search algorithmto the domain of transliteration by substituting let-ters and substrings for the words and phrases of theoriginal model.
There are, in fact, strong indica-tions that the monotone search algorithm is bettersuited to transliteration than it is to translation.
Un-like machine translation, where the constraint on re-ordering required by monotone search is frequentlyviolated, transliteration is an inherently sequentialprocess.
Also, the sparsity issue in training the lan-guage model is much less pronounced, allowing usto model P (e?|e?)
directly.In order to train the model, we extract the one-to-one Viterbi alignment of a training pair from astochastic transducer based on the model outlinedin (Ristad and Yianilos, 1998).
Substrings are thengenerated by iteratively appending adjacent links orunlinked letters to the one-to-one links of the align-ment.
For example, assuming a maximum substringlength of 2, the <r, P> link in the alignment pre-sented in Figure 1 would participate in the followingsubstring pairs: <r, P>, <ur, P>, and <ra, P>.The fact that the Viterbi substring decoder em-ploys a dynamic programming search through thesource/target letter state space described in Section 1renders the use of a word unigram language modelimpossible.
This is due to the fact that alternatepaths to a given source/target letter pair are beingeliminated as the search proceeds.
For example,suppose the Viterbi substring decoder were given theFigure 1: A one-to-one alignment of Mourad andXQ?.
For clarity the Arabic name is written left toright.Arabic string ??
'Q?, and there are two valid Englishnames in the language model, Karim (the correcttransliteration of the input) and Kristine (the Arabictransliteration of which would be 	?J?Q?).
The op-timal path up to the second letter might go through<?,k>, <P,r>.
At this point, it is transliterating intothe name Kristine, but as soon as it hits the third let-ter (?
), it is clear that this is the incorrect choice.In order to recover from the error, the search wouldhave to backtrack to the beginning and return to state<P,r> from a different path, but this is an impos-sibility since all other paths to that state have beeneliminated from the search.4.3 Substring-based TransducerThe major advantage the letter-based transducer pre-sented in Section 3 has over the Viterbi substring de-coder is its word unigram language model, whichallows it to reproduce words seen in the trainingdata with high accuracy.
On the other hand, theViterbi substring decoder is able to encode con-textual information in the transliteration model be-cause of its ability to consider larger many-to-manymappings.
In a novel approach presented here, wepropose a substring-based transducer that draws onboth advantages.
The substring transliteration modellearned for the Viterbi substring decoder is encodedas a transducer, thus allowing it to use a word uni-947gram language model.
Our model, which we referto as the substring-based transducer, has several ad-vantages over the previously presented models.?
The substring-based transducer can be com-posed with a word unigram language model, al-lowing it to transliterate names seen in trainingfor the language model with greater accuracy.?
Longer many-to-many mappings enable thetransducer to encode contextual informationinto the transliteration model.
Compared to theletter-based transducer, it allows for the gener-ation of longer well-formed substrings (or po-tentially even entire words).?
The letter-based transducer considers all possi-ble alignments of the training examples, mean-ing that many low-probability mappings are en-coded into the model.
This issue is even morepronounced in cases where the desired translit-eration is not in the word unigram model, andit is guided by the weaker letter trigram model.The substring-based transducer can eliminatemany of these low-probability mappings be-cause of its commitment to a single high-probability one-to-one alignment during train-ing.?
A major computational advantage this modelhas over the letter-based transducer is the factthat null characters (?)
are not encoded explic-itly.
Since the Arabic input to the letter-basedtransducer could contain an arbitrary numberof nulls, the potential number of output stringsfrom the transliteration transducer is infinite.Thus, the composition with the language trans-ducer must be done in such a way that thereis a valid path for all of the strings output bythe transliteration transducer that have a pos-itive probability in the language model.
Thisleads to prohibitively large transducers.
On theother hand, the substring-based transducer han-dles nulls implicitly (e.g.
the mapping ke:?
im-plicitly represents e:?
after a k), so the trans-ducer itself is not required to deal with them.5 ExperimentsIn this section, we describe the evaluation of ourmodels on the task of Arabic-to-English transliter-ation.5.1 DataFor our experiments, we required bilingual namepairs for testing and development data, as well asfor the training of the transliteration models.
To trainthe language models, we simply needed a list of En-glish names.
Bilingual data was extracted from theArabic-English Parallel News part 1 (approx.
2.5Mwords) and the Arabic Treebank Part 1-10k wordEnglish Translation.
Both bitexts contain Arabicnews articles and their English translations.
The En-glish name list for the language model training wasextracted from the English-Arabic Treebank v1.0(approx.
52k words)1.
The language model trainingset consisted of all words labeled as proper namesin this corpus along with all the English names inthe transliteration training set.
Any names in any ofthe data sets that consisted of multiple words (e.g.first name/last name pairs) were split and consid-ered individually.
Training data for the translitera-tion model consisted of 2844 English-Arabic pairs.The language model was trained on a separate setof 10991 (4494 unique) English names.
The finaltest set of 300 English-Arabic transliteration pairscontained no overlap with the set that was used toinduce the transliteration models.5.2 Evaluation MethodologyFor each of the 300 transliteration pairs in the testset, the name written in Arabic served as input to themodels, while its English counterpart was consid-ered a gold standard transliteration for the purposeof evaluation.
Two separate tests were performed onthe test set.
In the first, the 300 English words inthe test set were added to the training data for thelanguage models (the seen test), while in the sec-ond, all English words in the test set were removedfrom the language model?s training data (the unseentest).
Both tests were run on the same set of wordsto ensure that variations in performance for seen andunseen words were solely due to whether or not theyappear in the language model (and not, for exam-ple, their language of origin).
The seen test is sim-ilar to tests run in (Knight and Graehl, 1998) and(Stalls and Knight, 1998) where the models couldnot produce any words not included in the language1All corpora are distributed by the Linguistic Data Consor-tium.
Despite the name, the English-Arabic Treebank v1.0 con-tains only English data.948model training data.
The models were evaluated onthe seen test set in terms of exact matches to the goldstandard.
Because the task of generating transliter-ations for the unseen test set is much more difficult,exact match accuracy will not provide a meaningfulmetric for comparison.
Thus, a softer measure ofperformance was required to indicate how close thegenerated transliterations are to the gold standard.We used Levenshtein distance: the number of inser-tions, deletions and substitutions required to convertone string into another.
We present the results sep-arately for names of Arabic origin and for those ofnon-Arabic origin.We also performed a third test on words that ap-pear in both the transliteration and language modeltraining data.
This test was not indicative of theoverall strength of the models but was meant to givea sense of how much each model depends on its lan-guage model versus its transliteration model.5.3 SetupFive approaches were evaluated on the Arabic-English transliteration task.?
Baseline: As a baseline for our experiments,we used a simple deterministic mapping algo-rithm which maps Arabic letters to the mostlikely letter or sequence of letters in English.?
Letter-based Transducer: Mapping proba-bilities were learned by running the forward-backward algorithm until convergence.
Thelanguage model is a combination of word un-igram and letter trigram models and selects aword unigram or letter trigram modeling of theEnglish word depending on whichever one as-signs the highest probability.
The letter-basedtransducer was implemented in Carmel2.?
Viterbi Substring Decoder: We experimentedwith maximum substring lengths between 3and 10 on the development set, and found thata maximum length of 6 was optimal.?
Substring-based Transducer: The substring-based transducer was also implemented inCarmel.
We found that this model worked bestwith a maximum substring length of 4.2Carmel is a finite-state transducer package written byJonathan Graehl.
It is available at http://www.isi.edu/licensed-sw/carmel/.Method Arabic Non-Arabic AllBaseline 1.9 2.1 2.0Letter trans.
45.9 64.3 54.7Viterbi substring 15.9 30.1 22.7Substring trans.
59.9 81.1 70.0Human 33.1 40.6 36.7Table 2: Exact match accuracy percentage on theseen test set for various methods.Method Arabic Non-Arabic AllBaseline 2.32 2.80 2.55Letter trans.
2.46 2.63 2.54Viterbi substring 1.90 2.13 2.01Substring trans.
1.92 2.41 2.16Human 1.24 1.42 1.33Table 3: Average Levenshtein distance on the un-seen test set for various methods.?
Human: For the purpose of comparison, weallowed an independent human subject (fluentin Arabic, but a native speaker of English) toperform the same task.
The subject was askedto transliterate the Arabic words in the test setwithout any additional context.
No additionalresources or collaboration were allowed.5.4 Results on the Test SetTable 2 presents the word accuracy performance ofeach transliterator when the test set is available to thelanguage models.
Table 3 shows the average Leven-shtein distance results when the test set is unavail-able to the language models.
Exact match perfor-mance by the automated approaches on the unseenset did not exceed 10.3% (achieved by the Viterbisubstring decoder).
Results on the seen test sug-gest that non-Arabic words (back transliterations)are easier to transliterate exactly, while results forthe unseen test suggest that errors on Arabic words(forward transliterations) tend to be closer to thegold standard.Overall, our substring-based transducer clearlyoutperforms the letter-based transducer.
Its per-formance is better in both tests, but its advantageis particularly pronounced on words it has seen inthe training data for the language model (the task949Arabic LBT SBT Correct1 	?A?J?
Uthman Uthman Othman2 	?Q??
 Asharf Asharf Ashraf3 I?
P?
Rafeet Arafat Refaat4 ?
?A? Istamaday Asuma Usama5 	?A?
? Erdman Aliman Iman6 ???
Wortch Watch Watch7 	Q?J?
Mellis Mills Mills8 ?PQ?
February Firari FerrariTable 4: A sample of the errors made by the letter-based (LBT) and segment-based (SBT) transducers.for which the letter-based transducer was originallydesigned).
Since both transducers use exactly thesame language model, the fact that the substring-based transducer outperforms the letter-based trans-ducer indicates that it learns a stronger translitera-tion model.The Viterbi substring decoder seems to strugglewhen it comes to recreating words seen the languagetraining data, as evidenced by its weak performanceon the seen test.
Obviously, its substring/letter bi-gram language model is no match for the word un-igram model used by the transducers on this task.On the other hand, its stronger performance on theunseen test set suggests that its language model isstronger than the letter trigram used by the transduc-ers when it comes to generating completely novelwords.A sample of the errors made by the letter- andsubstring-based transducers is presented in Table 4.In general, when both models err, the substring-based transducer tends toward more phoneticallyreasonable choices.
The most common type of er-ror is simply correct alternate English spellings ofan Arabic name (error 1).
Error 2 is an example ofa learned mapping being misplaced (the deleted a).Error 3 indicates that the letter-based transducer isable to avoid these misplaced mappings at the be-ginning or end of a word because of its three-statetransliteration transducer (i.e.
it learns not to allowvowel deletions at the beginning of a word).
Errors4 and 5 are cases where the letter-based transducerproduced particularly awkward transliterations.
Er-rors 6 and 7 are names that actually appear in theword unigram model but were missed by the letter-based transducer, while error 8 is an example of theMethod Exact match Avg Lev.Letter transducer 81.2 0.46Viterbi substring 83.2 0.24Substring transducer 94.4 0.09Table 5: Results for testing on the transliterationtraining set.letter-based transducer incorrectly choosing a namefrom the word unigram model.
As discussed in Sec-tion 4.3, this is likely due to mappings learned fromlow-probability alignments.5.5 Results on the Training SetThe substring-based approaches encode a great dealof contextual information into the transliterationmodel.
In order to assess how much the perfor-mance of each approach depends on its languagemodel versus its transliteration model, we tested thethree statistical models on the set of 2844 namesseen in both the transliteration and language modeltraining.
The results of this experiment are pre-sented in Table 5.
The Viterbi substring decoder re-ceives the biggest boost, outperforming the letter-based transducer, which indicates that its strengthlies mainly in its transliteration modeling as opposedto its language modeling.
The substring-based trans-ducer, however, still outperforms it by a large mar-gin, achieving near-perfect results.
Most of the re-maining errors can be attributed to names with alter-nate correct spellings in English.The results also suggest that the substring-basedtransducer practically subsumes a naive ?lookup ta-ble?
approach.
Although the accuracy achieved isless than 100%, the substring-based transducer hasthe great advantage of being able to handle noise inthe input.
In other words, if the spelling of an inputword does not match an Arabic word from the train-ing data, a lookup table will generate nothing, whilethe substring-based transducer could still search forthe correct transliteration.5.6 Computational ConsiderationsAnother point of comparison between the modelsis complexity.
The letter-based transducer encodes56144 mappings while the substring-based trans-ducer encodes 13948, but as shown in Table 6, once950Method Size (states/arcs)Letter transducer 86309/547184Substring transducer 759/2131Table 6: Transducer sizes for composition with theword ??
?g (Helmy).Method TimeLetter transducer 5h52minViterbi substring 3 secSubstring transducer 11 secTable 7: Running times for the 300 word test set.the transducers are fully composed, the differencebecomes even more pronounced.
As discussed inSection 4.3, the reason for the size explosion fac-tor in the letter-based transducer is the possibility ofnull characters in the input word.The running times for the statistical approacheson the 300 word test set are presented in Table 7.The huge computational advantage of the substring-based approach makes it a much more attractive op-tion for any real-world application.
Tests were per-formed on an AMD Athlon 64 3500+ machine with2GB of memory running Red Hat Enterprise Linuxrelease 4.6 ConclusionIn this paper, we presented a new substring-basedapproach to modeling transliteration inspired byphrase-based models of machine translation.
Wetested both dynamic programming and finite-statetransducer implementations, the latter of which en-abled us to use a word unigram language model toimprove the accuracy of generated transliterations.The results of evaluation on the task of Arabic-English transliteration indicate that the substring-based approach not only improves performance overa state-of-the-art letter-based model, but also leadsto major gains in efficiency.
Since no language-specific information was encoded directly into themodels, they can also be used for transliteration be-tween other language pairs.In the future, we plan to consider more com-plex language models in order to improve the re-sults on unseen words, which should certainly befeasible for the substring-based transducer becauseof its efficient memory usage.
Another feature of thesubstring-based transducer that we have not yet ex-plored is its ability to easily produce an n-best list oftransliterations.
We plan to investigate whether us-ing methods like discriminative reranking (Och andNey, 2002) on such an n-best list could improve per-formance.AcknowledgmentsWe would like to thank Colin Cherry and the othermembers of the NLP research group at the Univer-sity of Alberta for their helpful comments.
This re-search was supported by the Natural Sciences andEngineering Research Council of Canada.ReferencesN.
AbdulJaleel and L. S. Larkey.
2003.
Statisticaltransliteration for English-Arabic cross language in-formation retrieval.
In CIKM, pages 139?146.Y.
Al-Onaizan and K. Knight.
2002.
Machine translit-eration of names in Arabic text.
In ACL Workshop onComp.
Approaches to Semitic Languages.M.
Arababi, S.M.
Fischthal, V.C.
Cheng, and E. Bart.1994.
Algorithmns for Arabic name transliteration.IBM Journal of Research and Development, 38(2).A.
Ekbal, S.K.
Naskar, and S. Bandyopadhyay.
2006.A modified joint source-channel model for transliter-ation.
In COLING/ACL Poster Sessions, pages 191?198.K.
Knight and J. Graehl.
1998.
Machine transliteration.Computational Linguistics, 24(4):599?612.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In NAACL-HLT, pages 48?54.H.
Li, M. Zhang, and J. Su.
2004.
A joint source-channelmodel for machine transliteration.
In ACL, pages 159?166.F.
J. Och and H. Ney.
2002.
Discriminative trainingand maximum entropy models for statistical machinetranslation.
In ACL, pages 295?302.E.
S. Ristad and P. N. Yianilos.
1998.
Learning string-edit distance.
IEEE Transactions on Pattern Analysisand Machine Intelligence, 20(5):522?532.B.
Stalls and K. Knight.
1998.
Translating names andtechnical terms in Arabic text.
In COLING/ACL Work-shop on Comp.
Approaches to Semitic Languages.R.
Zens and H. Ney.
2004.
Improvements in phrase-based statistical machine translation.
In HLT-NAACL,pages 257?264.951
