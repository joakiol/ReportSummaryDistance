Proceedings of the NAACL HLT 2010: Demonstration Session, pages 21?24,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsA Detailed, Accurate, Extensive, Available English Lexical DatabaseAdam KilgarriffLexical Computing LtdBrighton, UKadam@lexmasterclass.comAbstractWe present an English lexical database whichis fuller, more accurate and more consistentthan any other.
We believe this to be so be-cause the project has been well-planned, witha 12-month intensive planning phase prior tothe lexicography beginning; well-resourced,employing a team of fifteen highly experi-enced lexicographers for a thirty-month mainphase; it has had access to the latest corpusand dictionary-editing technology; it has notbeen constrained to meet any goals other thanan accurate description of the language; andit has been led by a team with singular expe-rience in delivering high-quality and innova-tive resources.
The lexicon will be completein Summer 2010 and will be available for NLPgroups, on terms designed to encourage its re-search use.1 IntroductionMost NLP applications need lexicons.
NLP re-searchers have used databases from dictionary pub-lishers (Boguraev and Briscoe, 1989; Wilks et al,1996), or developed NLP resources (COMLEX(Macleod et al, 1994), XTAG (Doran et al, 1994))or used WordNet,(Fellbaum, 1998) or have switchedto fully corpus-based strategies which need no lex-icons.
However the publishers?
dictionaries werepre-corpus, often inconsistent, and licencing con-straints were in the end fatal.
COMLEX and XTAGaddress only syntax; WordNet, only semantics.
Alsothese resources were not produced by experiencedlexicographers, nor according to a detailed, stringent?style guide?
specifying how to handle all the phe-nomena (in orthography, morphology, syntax, se-mantics and pragmatics, from spelling variation toregister to collocation to sense distinction) that makelexicography complex.
Unsupervised corpus meth-ods are intellectually exciting but do not provide thelexical facts that many applications need.We present DANTE (Database of Analysed Textsof English), an English lexical database.
For thecommonest 50,000 words of English, it gives a de-tailed account of the word?s meaning(s), grammar,phraseology and collocation and any noteworthyfacts about its pragmatics or distribution.In outline this is what dictionaries have been do-ing for many years.
This database is of more interestto NLP than others (for English) because of its:?
quality and consistency?
level of detail?
number of examples?
accountability to the corpus?
purity: it has been created only as an anal-ysis of English, and has not been compro-mised by publishing constraints or other non-lexicographic goals?
availability, on licencing terms that promote itsresearch use and also the re-use of enhancedversions created by NLP groups.2 The ProjectThe overall project is the preparation of a New En-glish Irish Dictionary, and is funded by Foras naGaeilge, the official body for the (Gaelic) Irish lan-guage.1 The project was designed according to a1FnG was set up following the Good Friday Agreement of1998 on Northern Ireland, between the Governments of the Re-21model where the first stage of the production ofa blingual dictionary is a target-language-neutralmonolingual analysis of the source language listingall the phenomena that might possibly have an unex-pected translation.
(The next stages are then trans-lation and ?finishing?.)
The 2.3 MEuro contract forthe analysis of English was won by LexicographyMasterClass Ltd in 2007.2 The lexicographers areworking on the letter ?s?
at time of writing and thedatabase will be complete in Summer 2010.3 LexicographyWriting a dictionary is a large and complex under-taking.
Planning is paramount.In the planning phase, we identified all the as-pects of the behaviour of English words whicha full account of the lexicon should cover.
Wethen found words exemplifying all aspects, and pre-pared a sample of one hundred model entries, wherethe hundred words chosen covered all the prin-cipal phenomena (Atkins and Grundy, 2006).
Adetailed style guide and corresponding DTD werewritten.
We created the New Corpus for Ire-land (NCI) (Kilgarriff, 2006), and set up a corpusquery system (Lexical Computing?s Sketch Engine;http://www.sketchengine.co.uk) and dictionary edit-ing system (IDM?s DPS: http://www.idm.fr) for theproject to use.
50,000 headwords were identifiedand each was classified into one of eighteen cate-gories according to type and complexity.
This sup-ported detailed planning of lexicographers?
work-loads and hence, scheduling, as well as adding to therichness of the data.
Template entries (Atkins andRundell, 2008, pp123-128) were developed for 68lexical sets and for words belonging to these sets, thetemplate was automatically inserted into the draftdictionary, saving lexicographer time and encourag-ing consistency.We identified forty syntactic patterns for verbs,eighteen for nouns and eighteen for adjectives.
Lexi-cographers were required to note all the patterns thatapplied for each word sense.The lexicographers were all known to the man-agement team beforehand for their high-qualitypublic of Ireland and the UK.
FnaG is an institution of the twocountries.2Lexicography MasterClass had also previously undertakenthe planning of the project.work.
They were trained in the dictionary styleat two workshops, and their work was thoroughlychecked throughout the project, with failings re-ported back and progress monitored.A typical short entry is honeymoon (shown herein full but for truncated examples).
Note the levelof detail including senses, subsenses, grammaticalstructures and collocations.
All points are exem-plified by one or usually more corpus example sen-tences.
(The style guide, available online, states theconditions for giving one, two or three examples fora phenomenon.)honeymoon?
n holiday after weddingFollowing the wedding day, Jane and .
.
.Upon your return from honeymoon .
.
.Lee and Zoe left for a honeymoon in .
.
.SUPPORT VERB spendThey now live in Cumbernauld after spending .
.
.Their honeymoon was spent at Sandals .
.
.SUPPORT VERB haveI hope that you have an absolutely fantastic .
.
.The reception was held at the local pub and .
.
.SUPPORT PREP onI have a ring on my left hand which Martha .
.
.The groom whisked the bride off on honeymoon .
.
.This particular portrait was a festive affair, .
.
.STRUCTURE N premoddestination hotel suite holiday night coupleClassic honeymoon destinations like the .
.
.We can help and recommend all types of .
.
.We were staying in the honeymoon suite .
.
.A magical honeymoon holiday in the beautiful .
.
.Our honeymoon packages offer a wide range of .
.
.It is the favourite of our many honeymoon couples.?
v spend one?s honeymoonSTRUCTURE Particle (locative)They?ll be honeymooning in Paris (ooh, la la).Mr and Mrs Maunder will honeymoon in .
.
.The couple spent the early part of their .
.
.A Dave Lister from five years in the future is .
.
.?
n period of graceVARIANT FORM honeymoon periodSince his May 1997 landslide election, Blair has .
.
.The UN and Europe were pan national organisationsCHUNK the honeymoon is overVARIANT the honey moon period is overThe shortest post-election honeymoon is over.Could the honeymoon period be over that quickly?224 Corpus strategy and innovationThe project team combined expertise in corpora,computational linguistics and lexicography, andfrom the outset the project was to be solidly corpus-based.
In the planning phase we had built the NCI:by the time the compilation phase started, in 2007, itwas evident not only that the NCI would no longercapture current English, but also that the field hadmoved on and at 250m words, it was too small.We appended the Irish English data from the NCIto the much larger and newer UKWaC (Ferraresi etal., 2008) and added some contemporary Americannewspaper text to create the project corpus, whichwas then pos-tagged with TreeTagger 3 and loadedinto the Sketch Engine.The distinctive feature of the Sketch Engine is?word sketches?
: one-page, corpus-driven sum-maries of a word?s grammatical and collocationalbehaviour.
The corpus is parsed and a table of col-locations is given for each grammatical relation.
ForDANTE, the set of grammatical relations was de-fined to give an exact match to the grammatical pat-terns that the lexicographers were to record.
Thesame names were used.
The word sketch for theword would, in so far as the POS-tagging, parsing,and statistics worked correctly, identify precisely thegrammatical patterns and collocations that the lexi-cographer needed to note in the dictionary.As is evident, a very large number of corpus sen-tences needed taking from the corpus into the dic-tionary.
This was streamlined with two processes:GDEX, for sorting the examples so that the ?best?
(according to a set of heuristics) are shown to thelexicographer first (Kilgarriff et al, 2008), and ?one-click-copying?
of sentences onto the clipboard (in-cluding highlighting the nodeword).
(In contrast toa finished dictionary, examples were not edited.
)5 XML-based dictionary preparationThe document type definition uses seventy-two el-ements.
It is as restrictive as possible, given thataccuracy and then clarity take priority.
Lexicogra-phers were not permitted to submit work which didnot validate.
Wherever there was a fixed range ofpossible values for an information field, the list was3http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/included in the DTD as possible values for an at-tribute and the lexicographer used menu-selectionrather than text-entry.The database was also used for checking potentialproblems in a number of ways.
For example, thereare some word senses where examples are not re-quired, but it is unusual for both senses of a two-or-more-sense word not to need examples, so we rou-tinely used XML searching to check lexicographers?work for any such cases and scrutinised them priorto approval.6 None of the usual constraintsMost dictionary projects are managed by publisherswho are focused on the final (usually print) product,so constraints such as fitting in limited page-space,or using simplified codes to help naive users, or re-sponding to the marketing department, or tailoringthe analysis according to the specialist interests ofsome likely users, or features of the target language(for a bilingual dictionary) usually play a large rolein the instructions given to lexicographers.
In thisproject, with the separation of the project team fromthe publisher, we were unusually free of such com-promising factors.7 LeadershipMany lexicographic projects take years or decadeslonger than scheduled, and suffer changes of intel-lectual leadership, or are buffeted by political andeconomic constraints, all of which produce grave in-consistencies of style, scale and quality between dif-ferent sections of the data.
A consistent lexicon isimpossible without consistent and rigorous manage-ment.
The credentials of the managers are an indi-cator of the likely quality of the data.Sue Atkins, the project manager, has beenthe driving force behind the Collins-Robert En-glish/French Dictionaries (first two editions), theCOBUILD project (with John Sinclair), The Euro-pean Association for Lexicography (with ReinhartHartmann), the British National Corpus, the Ox-ford Hachette English/French dictionaries (assistedby Valerie Grundy, DANTE Chief Editor) and withCharles Fillmore, FrameNet.
She has co-publishedthe Oxford Guide to Practical Lexicography withMichael Rundell, another of the project management23team, who has been Managing Editor of a large num-ber of dictionaries at Longman and Macmillan.8 LicencingIn the late 1980s it seemed likely that Longman Dic-tionary of Contemporary English (LDOCE) wouldhave a great impact on NLP.
But its star rose, butthen promptly fell.
As a Longman employee withthe task of developing LDOCE use within NLP, thefirst author investigated the reasons long and hard.The problem was that NLP groups could notdo anything with their LDOCE-based work.
Theycould describe the work in papers, but the work it-self was embedded in enhanced versions of LDOCE,or LDOCE-derived resources, and the licence thatallowed them to use LDOCE did not alow them topublish or licence or give away any such resource.So LDOCE research, for academics, was a dead end.A high-quality dictionary represents an invest-ment of millions so one cannot expect its owners togive it away.
The challenge then is to arrive at amodel for a dictionary?s use in which its explorationand enhancement is encouraged, and is not a deadend, and also in which the owner?s interest in a re-turn on investment is respected.DANTE will be made available in a way designedto meet these goals.
It will be licenced for NLP re-search for no fee.
The licence will not allow thelicencee to pass on the resource, but will include anundertaking from the owner to pass on the licencee?senhanced version to other groups on the same terms(provided it passes quality tests).
The owner, or itsagent, will also, where possible, integrate and cross-validate enhancements from different users.
Theowner will retain the right to licence the enhanceddata, for a fee, for commercial use.
The model ispresented fully in (Kilgarriff, 1998).9 DANTE Disambiguation?DANTE disambiguation?
is a program currently inpreparation which takes arbitrary text and, for eachcontent word in the text, identifies the DANTE pat-terns it matches and thereby assigns it to one of theword?s senses in the DANTE database.
It is designedto demonstrate the potential that DANTE has forNLP, and to undertake in a systematic way a pieceof work that many DANTE users would otherwiseneed to do themselves: converting as many DANTEdata fields as possible into methods which either door do not match a particular instance of the word.The program will be freely available alongside thedatabase.AcknowledgmentsThanks to colleagues on the project, particularly themanagement team of Sue Atkins, Michael Rundell,Valerie Grundy, Diana Rawlinson and Cathal Con-very.ReferencesSue Atkins and Valerie Grundy.
2006.
Lexicographicprofiling: an aid to consistency in dictionary entry de-sign.
In Proc.
Euralex, Torino.Sue Atkins and Michael Rundell.
2008.
Oxford Guide toPractical Lexicography.
OUP, Oxford.Bran Boguraev and Ted Briscoe, editors.
1989.
Compu-tational lexicography for natural language processing.Longman, London.Christy Doran, Dania Egedi, Beth Ann Hockey, B. Srini-vas, and Martin Zaidel.
1994.
Xtag system: a widecoverage grammar for english.
In Proc.
COLING,pages 922?928.Christiane Fellbaum, editor.
1998.
WordNet, an elec-tronic lexical database.
MIT Press.Adriano Ferraresi, Eros Zanchetta, Marco Baroni, andSilvia Bernardini.
2008.
Introducing and evaluatingUKWaC, a very large web-derived corpus of English.In Proc ?WAC4, LREC, Marrakesh.Adam Kilgarriff, Milos Husak, Katy McAdam, MichaelRundell, and Pavel Rychly.
2008.
Gdex: Automati-cally finding good dictionary examples in a corpus.
InProc.
Euralex, Barcelona.Adam Kilgarriff.
1998. Business models for dictioanriesand NLP.
Int Jnl Lexicography, 13(2):107?118.Adam Kilgarriff.
2006.
Efficient corpus developmentfor lexicography: building the new corpus for ireland.Language Resources and Evaluation Journal.Catherine Macleod, Ralph Grishman, and Adam Mey-ers.
1994.
The comlex syntax project: the first year.In Proc ?Human Language Technology workshop, pages8?12.Yorick Wilks, Brian Slator, and Louise Guthrie.
1996.Electric words: dictionaries, computers, and mean-ings.
MIT Press, Cambridge, MA, USA.24
