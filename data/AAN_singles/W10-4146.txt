Dependency Parser for Chinese Constituent Parsing ?Xuezhe Ma, Xiaotian Zhang, Hai Zhao, Bao-Liang Lu1Center for Brain-Like Computing and Machine IntelligenceDepartment of Computer Science and Engineering, Shanghai Jiao Tong University2MOE-Microsoft Key Laboratory for Intelligent Computing and Intelligent SystemsShanghai Jiao Tong University, 800 Dong Chuan Rd., Shanghai 200240, China{xuezhe.ma,xtian.zh}@gmail.com, {zhaohai,blu}@cs.sjtu.edu.cnAbstractThis paper presents our work for participationin the 2010 CIPS-ParsEval shared task on Chi-nese syntactic constituent tree parsing.
Weuse dependency parsers for this constituentparsing task based on a formal dependency-constituent transformation method which con-verts dependency to constituent structures us-ing a machine learning approach.
A condi-tional random fields (CRF) tagger is adoptedfor head information recognition.
Our ex-periments shows that acceptable parsing andhead tagging results are obtained on our ap-proaches.1 IntroductionConstituent parsing is a challenging but useful taskaiming at analyzing the constituent structure of a sen-tence.
Recently, it is widely adopted by the popular ap-plications of natural language processing techniques,such as machine translation (Ding and Palmer, 2005),synonym generation (Shinyama et al, 2002), relationextraction (Culotta and Sorensen, 2004) and lexical re-source augmentation (Snow et al, 2004).
A great dealof researches have been conducted on this topic withpromising progress (Magerman, 1995; Collins, 1999;Charniak, 2000; Charniak and Johnson, 2005; Sagaeand Lavie, 2006; Petrov and Klein, 2007; Finkel et al,2008; Huang, 2008).Recently, several effective dependency parsing al-gorithms has been developed and shows excellent per-formance in the responding parsing tasks (McDonald,2006; Nivre and Scholz, 2004).
Since graph struc-tures of dependency and constituent parsing over asentence are strongly related, they should be benefitedfrom each other.
It is true that constituent parsing maybe smoothly altered to fit dependency parsing.
How-ever, due to the inconvenience from dependency toconstituent structure, it is not so easy to adopt the latter?This work is partially supported by the National Natu-ral Science Foundation of China (Grant No.
60903119, GrantNo.
60773090 and Grant No.
90820018), the National Ba-sic Research Program of China (Grant No.
2009CB320901),and the National High-Tech Research Program of China(Grant No.2008AA02Z315).for the former.
This means that most of these popularand effective dependency parsing models can not be di-rectly extended to constituents parsing.
This paper pro-poses an formal method for such a conversion whichadoptively solves the problem of ambiguity.
Based onthe proposed method, a dependency parsing algorithmcan be used to solve tasks of constituent parsing.A part of Tsinghua Chinese Treebank (TCT) (Zhou,2004; Zhou, 2007; Chen et al, 2008) is used asthe training and test data for the 2010 CIPS-ParsEvalshared task.
Being different from the annotationscheme of the Penn Chinese Treebank (CTB), the TCThas another annotation scheme, which combines boththe constituent tree structure and the head informa-tion of each constituent.
Specifically, there can be al-ways multiple heads in a constituent.
For the 2010CIPS-ParsEval shared task, only segmented sentencesare given in test data without part-of-speech (POS)tags, a POS tagger is required for this task.
There-fore, we divide our system into three major cascadestages, namely POS tagging, constituent parsing andhead information recognition, which are connected asa pipeline of processing.
For the POS tagging, weadopt the SVMTool tagger (Gimenez and Marquez,2004); for the constituent parsing, we use the Maxi-mum Spanning Tree (MST) (McDonald, 2006) parsercombined with a dependencies-to-constituents conver-sion; and for the head information recognition, we ap-ply a sequence labeling method to label head informa-tion.Section 2 presents the POS tagger in our approach.The details of our parsing method is presented in sec-tion 3.
The head information recognition is describedin section 4.
The data and experimental results areshown in section 5.
The last section is the conclusionand future work.2 POS TaggingThe SVMTool tagger (Gimenez and Marquez, 2004) isused as our POS tagging tool for the first stage.
It is aPOS tagger based on SVM classifier, written in Perl.
Itcan be trained on standardized collection of hand POS-tagged sentences.
It uses SVM-Light1 toolkit as the1http://www.cs.cornell.edu/People/tj/svm_light/.implementation of SVM classifier and achieves 97.2%accuracy on the Penn English Treebank.
We test theaccuracy of the SVMTool tagger on the developmentset of the TCT (see section 5.1) and achieve accuracyof 94.98%.3 Parsing Constituents UsingDependency Parsing Algorithms3.1 Convert Dependencies to ConstituentsThe conversion from constituent to dependency struc-tures is straightforward with some specific rules basedon linguistic theory.
However, there is not an effectivemethod which can accurately accomplish the oppositetransformation, from the dependency structures backinto constituent ones due to the existence of ambiguityintroduced by the former transformation.Aimed at the above difficulty, our solution is to in-troduce a formal dependency structure and a machinelearning method so that the ambiguity from depen-dency structures to constituent structures can be dealtwith automatically.3.1.1 BinarizationWe first transform constituent trees into the formthat all productions for all subtrees are either unary orbinary, before converting them to dependency struc-tures.
Due to the binarization, the target constituenttrees of the conversion from dependency back to con-stituent structures are binary branching.This binarization is done by the left-factoring ap-proach described in (Charniak et al, 1998; Petrov andKlein, 2008), which converts each production with nchildren, where n > 2, into n?
1 binary productions.Additional non-terminal nodes introduced in this con-version must be clearly marked.
Transforming the bi-nary branching trees into arbitrary branching trees isaccomplished by using the reverse process.3.1.2 Using Binary ClassifierWe train a classifier to decide which dependencyedges should be transformed first at each step of con-version automatically.
After the binarization describedin the previous section, only one dependency edgeshould be transformed at each step.
Therefore theclassifier only need to decide which dependency edgeshould be transformed at each step during the conver-sion.As a result of the projective property of constituentstructures, this problem only happens in the cases thatmodifiers are at both sides of their heads.
And for thesecases that one head has multiple modifiers, only theleftmost or the rightmost dependency edge could betransformed first.
Therefore, a binary classifier is al-ways enough for the disambiguation at each step.1.
Word form of the parent2.
Part-of-speech (POS) tag of the parent3.
Word form of the leftmost child4.
POS tag of the leftmost child5.
Dependency label of the leftmost child6.
Word form of the rightmost child7.
POS tag of the rightmost child8.
Dependency label of the rightmost child9.
Distance between the leftmost child andthe parent10.
Distance between the rightmost childand the parentTable 1: Features used for conversion classifier.Support Vector Machine (SVM) is adopted as thelearning algorithm for the binary classifier and the fea-tures are in Table 1.3.1.3 Convert Constituent LabelsThe rest problem is that we should restore the labelfor each constituent when dependency structure treesare again converted to constituent structures.
The prob-lem is solved by storing constituent labels as labels ofdependency types.
The label for each constituent is justused as the label dependency type for each dependencyedge.The conversion method is tested on the develop-ment, too.
Constituent trees are firstly converted intodependency structures using the head rules describedin (Li and Zhou, 2009).
Then, we transform thosetrees back to constituent structure using our conversionmethod and use the PARSEVAL (Black et al, 1991)measures to evaluate the performance of the conver-sion method.
Our conversion method obtains 99.76%precision and 99.76% recall, which is a great perfor-mance.3.2 Dependency Parser for Constituent ParsingBased on the proposed conversion method, depen-dency parsing algorithms can be used for constituentparsing.
This can be done by firstly transforming train-ing data from constituents into dependencies and ex-tract training instances to train a binary classifier fordependency-constituent conversion, then training a de-pendency parser using the transformed training data.On the test step, parse the test data using the depen-dency parser and convert output dependencies to con-stituents using the binary classifier trained in advance.In addition, since our conversion method needs depen-dency types, labeled dependency parsing algorithmsare always required.1.
Constituent label of the constituent2.
Constituent label of each child ofthe constituent.3.
Wether it is a terminal for eachchild of the constituent4.
The leftmost word in the sentenceof each child of the constituent.5.
The leftmost word in the sentenceof each child of the constituent.Table 2: CRF features for head information recogni-tion.1.
Word form and POS tag of the parent.2.
Word form and POS tag of each child.3.
POS tag of the leftmost child of each child.4.
POS tag of the rightmost child of each child.5.
Dependency label between the parent andits parentTable 3: CRF features for dependency type labeling.4 Head Information RecognitionSince head information of each constituent is alwaysdetermined by the syntactic label of its own and thecategories of the constituents in subtrees, the order andrelations between the productions of each constituentstrongly affects the head information labeling.
It isnatural to apply a sequential labeling strategy to tacklethis problem.
The linear chain CRF model is adoptedfor the head information labeling, and the implemen-tation of CRF model we used is the 0.53 version ofthe CRF++ toolkit2.
We assume that head informationis independent between different constituents, whichcould decrease the length of sequence to be labeled forthe CRF model.We use a binary tag set to determine whether a con-stituent is a head, e.g.
H for a head, O for a non-head,which is the same as (Song and Kit, 2009).
The fea-tures in Table 2 are used for CRF model.To test our CRF tagger, we remove all head informa-tion from the development set, and use the CRF taggerto retrieve the head.
The result strongly proves its ef-fectiveness by showing an accuracy of 99.52%.5 ExperimentsAll experiments reported here were performed on aCore 2 Quad 2.83Ghz CPU with 8GB of RAM.2The CRF++ toolkit is publicly available fromhttp://crfpp.sourceforge.net/.5.1 DataThere are 37,219 short sentences in official releasedtraining data for the first sub-task and 17,744 long sen-tences for the second sub-task (for the second sub-task,one line in the training data set may contain more thanone sentence).
We split one eighth of the data as ourdevelopment set.
On the other hand, there are both1,000 sentences in released test data for the first andsecond sub-tasks.5.2 Constituent ParsingAs mentioned in section 3, constituent parsing isdone by using a dependency parser combined withour conversion method.
We choose the second or-der maximum spanning tree parser with k-best onlinelarge-margin learning algorithm (Crammer and Singer,2003; Crammer et al, 2003).
The MST parser we useis in the form of an open source program implementedin C++3.The features used for MST parser is the same as(McDonald, 2006).
Both the single-stage and two-stage dependency type labeling approaches are appliedin our experiments.
For the two-stage dependency typelabeling, The linear chain CRF model is adopted in-stead of the first-order Markov model used in (McDon-ald, 2006).
The features in Table 3 are used for CRFmodel.
It takes about 7 hours for training the MSTparser, and about 24 hours for training the CRF model.As mentioned in section 3.1.2, SVM is adopted asthe learning algorithm for the binary classifier.
Thereare about 40,000 training instances in the first sub-taskand about 80,000 in the second sub-task.
Develop-ment sets are used for tuning parameter C of SVMand the training time of the SVM classifier for the firstand second sub-task is about 8 and 24 hours, respec-tively.
However, the conversion from dependencies toconstituents is extremely fast.
Converting more than2,000 trees takes less than 1 second.To transform the constituent trees in training set intodependency structures, we use the head rules of (Li andZhou, 2009).5.3 ResultsThe evaluation metrics used in 2010 CIPS-ParsEvalshared task is shown in following:1. syntactic parsingPrecision = number of correct constituents in proposed parsenumber of constituents in proposed parseRecall = number of correct constituents in proposed parsenumber of constituents in standard parseF1 = 2*Precision*RecallPrecision+Recall3The Max-MSTParser is publicly available fromhttp://max-mstparser.sourceforge.net/.without head with headPrecision Recall F1 Precision Recall F1single-stage 77.78 78.13 77.96 75.78 76.13 75.95two-stage 78.61 78.76 78.69 76.61 76.75 76.68Table 4: Official scores of syntactic parsing.
single-stage and two-stage are for single-stage and two-stage depen-dency type labeling approached, respectively.Micro-R Macro-Rsingle-stage 62.74 62.47two-stage 63.14 62.48Table 5: Official scores of event recognitionThe correctness of syntactic constituents is judgedbased on the following two criteria:(a) the boundary, the POS tags of all the wordsin the constituent and the constituent type la-bel should match that of the constituent inthe gold standard data.
(b) the boundary, the POS tags of all the wordsin the constituent, the constituent type la-bel and head child index of the constituentshould match that of the constituent in thegold standard data.
(if the constituent con-tains more than one head child index, at leastone of them should be correct.)2.
event pattern recognitionMicro-R = number of all correct events in proposed parsenumber of all events in standard parseMacro-R = sum of recall of different target verbsnumber of target verbsHere the event pattern of a sentence is defined tobe the sequence of event blocks controlled by thetarget verb in a sentence.
The criteria for judgingthe correctness of event pattern recognition is:?
the event pattern should be completely con-sistent with gold standard data (informationof each event block should completely matchand the order of event blocks should alsoconsistent).There are both two submissions for the first and sec-ond sub-tasks.
One is using the single-stage depen-dency type labeling and the other is two-stage.
Sincethere are some mistakes in our models for the secondsub-task, the results of our submissions are unexpect-edly poor and are not shown in this paper.
All the re-sults in this paper is reported by the official organizerof the 2010 CIPS-ParsEval shared task.The accuracy of POS tagging on the official test datais 92.77%.
The results of syntactic parsing for the firstsub-task is shown in Table 4.
And results of eventrecognition is shown in Table 5.From the Table 4 and 5, we can see that our systemachieves acceptable parsing and head tagging results,and the results of event recognition is also reasonablyhigh.5.4 Comparison with Previous WorksWe comparison our approach with previous works of2009 CIPS-ParsEval shared task.
The data set andevaluation measures of 2009 CIPS-ParsEval sharedtask, which are quite different from that of 2010 CIPS-ParsEval shared task, are used in this experiment forthe comparison purpose.
Table 6 shows the compari-son.We compare our method with several main parserson the official data set of 2009 CIPS-ParsEval sharedtask.
All these results are evaluated with officialevaluation tool by the 2009 CIPS-ParsEval sharedtask.
Bikel?s parser4 (Bikel, 2004) in Table 6 isa implementation of Collins?
head-driven statisticalmodel (Collins, 2003).
The Stanford parser5 is basedon the factored model described in (Klein and Man-ning, 2002).
The Charniak?s parser6 is based on theparsing model described in (Charniak, 2000).
Berke-ley parser7 is based on unlexicalized parsing model de-scribed in (Petrov and Klein, 2007).
According to Ta-ble 6, the performance of our method is better than allthe four parsers described above.
Chen et al (2009)and Jiang et al (2009) both make use of combinationof multiple parsers and achieve considerably high per-formance.4http://www.cis.upenn.edu/?dbikel/software.html5http://nlp.stanford.edu/software/lex-parser.shtml/6ftp://ftp.cs.brown.edu/pub/nlparser/7http://nlp.cs.berkeley.edu/Main.htmlF1Bikel?s parser 81.8Stanford parser 83.3Charniak?s parser 83.9Berkeley parser 85.2this paper 85.6Jiang et al(2009).
87.2Chen et al(2009).
88.8Table 6: Comparison with previous works6 ConclusionThis paper describes our approaches for the parsingtask in CIPS-ParsEval 2010 shared task.
A pipelinesystem is used to solve the POS tagging, constituentparsing and head information recognition.
SVMTooltagger is used for the POS tagging.
For constituentparsing, we proposes a conversion based method,which can use dependency parsers for constituent pars-ing.
MST parser is chosen as our dependency parser.A CRF tagger is used for head information recognition.The official scores indicate that our system obtains ac-ceptable results on constituent parsing and high perfor-mance on head information tagging.One of future work should apply parser combinationand reranking approaches to leverage this in producingmore accurate parsers.ReferencesBikel, Daniel M. 2004.
Intricacies of collins parsingmodel.
Computational Linguistics, 30(4):480?511.Black, Ezra W., Steven P. Abney, Daniel P. Flickinger,Cluadia Gdaniec, Ralph Grishman, Philio Harrison,Donald Hindle, Robert J.P. Inqria, Frederick Jelinek,Judith L. Klavans, Mark Y. Liberman, Mitchell P.Marcus, Salim Roukos, and B Santorini.
1991.
Aprocedure for quantitatively comparing the syntac-tic coverage of english grammars.
In Proceedingsof the February 1991 DARPA Speech and NaturalLanguage Workshop.Charniak, Eugene and Mark Johnson.
2005.
Coarse-to-fine-grained n-best parsing and discriminativereranking.
In Proceedings of the 43rd ACLL, pages132?139.Charniak, Eugene, Sharon Goldwater, and Mark John-son.
1998.
Edge-based best-first chart parsing.
InProceedings of the Sixth Workshop on Very LargeCorpora.Charniak, Eugene.
2000.
A maximum-entropy-inspired parser.
In Proceedings of NAACL, pages132?139, seattle, WA.Chen, Yi, Qiang Zhou, and Hang Yu.
2008.
Anal-ysis of the hierarchical Chinese funcitional chunkbank.
Journal of Chinese Information Processing,22(3):24?31.Chen, Xiao, Changning Huang, Mu Li, and ChunyuKit.
2009.
Better parser combination.
In CIPS-ParsEval-2009 shared task.Collins, Michael.
1999.
Head-Driven Statistical Mod-els for Natural Language Parsing.
Ph.D. thesis,University of Pennsylvania.Collins, Michael.
2003.
Head-driven statistical mod-els for natural language parsing.
ComputationalLinguistics, 29(4):589?637.Crammer, Koby and Yoram Singer.
2003.
Ultracon-servative online algorithms for multiclass problems.Journal of Machine Learining.Crammer, Koby, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
2003.
Onlinepassive aggressive algorithms.
In Proceedings ofNIPS.Culotta, Aron and Jeffrey Sorensen.
2004.
Depen-dency tree kernels for relation extraction.
In Pro-ceedings of ACL.Ding, Yuan and Martha Palmer.
2005.
Machine trans-lation using probabilistic synchronous dependencyinsertion grammars.
In Proceedings of ACL.Finkel, Jenny Rose, Alex Kleeman, and Christopher D.Manning.
2008.
Efficient, feature-based, condi-tional random field parsing.
pages 959?967, TheOhio State University, Columbus, Ohio, USA.Gimenez and Marquez.
2004.
Svmtool: A generalPOS tagger generator based on support vector ma-chines.
In Proceedings of the 4th International Con-ference of Language Resources and Evaluation, Lis-bon, Portugal.Huang, Liang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In Proceedings ofACL/HLT.Jiang, Wenbin, Hao Xiong, and Qun Liu.
2009.
Muti-path shift-reduce parsing with online training.
InCIPS-ParsEval-2009 shared task.Klein, Dan and Christopher Manning.
2002.
Fast ex-act inference with a factored model for natural lan-guage parsing.
In In Advances in NIPS 2002, pages3?10.Li, Junhui and Guodong Zhou.
2009.
Soochow uni-versity report for the 1st china workshop on syntac-tic parsing.
In CIPS-ParsEval-2009 shared task.Magerman, David M. 1995.
Statistical decision-treemodels for parsing.
In Proceedings of ACL, pages276?283, MIT, Cambridge, Massachusetts, USA.McDonald, Ryan.
2006.
Discriminative LearningSpanning Tree Algorithm for Dependency Parsing.Ph.D.
thesis, University of Pennsylvania.Nivre, Joakim and Mario Scholz.
2004.
Determinis-tic dependency parsing of english text.
In Proceed-ings of the 20th international conference on Compu-tational Linguistics (COLING-2004), pages 64?70,Geneva, Switzerland, August 23rd-27th.Petrov, Slav and Dan Klein.
2007.
Improved infer-ence for unlexicalized parsing.
In Proceedings ofHLT/NAACL, pages 404?411, Rochester, New York.Petrov, Slav and Dan Klein.
2008.
Discriminative log-linear grammars with latent variables.
In Proceed-ings of NIPS 20.Sagae, Kenji and Alon Lavie.
2006.
A best-first prob-abilistic shift-reduce parser.
In Proceedings of COL-ING/ACL, pages 689?691, Sydney, Australia.Shinyama, Yusuke, Satoshi Sekine, and Kiyoshi Sudo.2002.
Automatic paraphrase acquisition from newsarticles.
In HLT-2002.Snow, Rion, Daniel Jurafsky, and Andrew Y. Ng.2004.
Learning syntactic patterns for automatic hy-pernym discovery.
In Proceedings of NIPS.Song, Yan and Chunyu Kit.
2009.
PCFG parsing withcrf tagging for head recognition.
In CIPS-ParsEval-2009 shared task.Zhou, Qiang.
2004.
Annotation scheme for Chinesetreebank.
Journal of Chinese Information Process-ing, 18(4):1?8.Zhou, Qiang.
2007.
Base chuck scheme for the Chi-nese language.
Journal of Chinese Information Pro-cessing, 21(3):21?27.
