Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 19?22,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsExtrinsic Parse SelectionDavid Goss-GrubbsUniversity of WashingtonDepartment of LinguisticsBox 354340Seattle, WA 98195-4340, USAdavidgg@u.washington.eduAbstractThis paper reports on one aspect of Locutus, anatural language interface to databases(NLIDB) which uses the output of a high-precision broad-coverage grammar to buildsemantic representations and ultimately SQLqueries.
Rather than selecting just a subset ofthe parses provided by the grammar to use infurther processing, Locutus uses all of them.
Ifthe meaning of a parse does not conform tothe semantic domain of the database, no queryis built for it.
Thus, intended parses are chosenextrinsically.
The parser gives an average of3.01 parses to the sentences in theGEOQUERY250 corpus.
Locutus generates anaverage of 1.02 queries per sentence for thiscorpus, all of them correct.1 IntroductionNatural language sentences are typically more am-biguous than the people who utter them or perceivethem are aware of.
People are very good at usingcontext and world knowledge to unconsciouslydisambiguate them.
High-precision, broad-coverage grammars, however, often assign everylegitimate analysis to a given sentence, even whenonly one of them reflects the sentence?s intendedmeaning.
It is thus important for natural languageprocessing applications that use these analyses tobe able to reliably select the intended parse.
It istypical for such applications to choose the bestparse up front and pass just that one on to furtherprocessing.
For some applications, however, it ispossible, and indeed preferable, to pass all theparses on and let downstream processing decidewhich parses to use.This paper describes such an application.
Locu-tus (Goss-Grubbs to appear), a natural languageinterface to relational databases (NLIDB), createssemantic representations for the parses assigned bya high-precision broad-coverage grammar, andfrom those creates SQL queries.
It does not includea step where one or more ?best?
parses are selectedfor further processing.
Queries are built for allparses for which it is possible to do so.
For a stan-dard corpus of NLIDB training sentences, it is ableto generate the correct query whenever a suitableanalysis is given by the parser.
In the rare casewhere it generates two queries, both queries areequally correct.2 Parse SelectionParse selection for probabilistic grammars involvessimply finding the most probable parse, or top-Nmost probable parses, and can be done using effi-cient algorithms, (e.g.
Klein and Manning, 2003).Things are different for high-precision, hand-coded grammars, such as the LinGO English Re-source Grammar, ERG (Flickinger, 2000), a Head-Driven Phrase Structure Grammar implementationof English; and Xerox?s English grammar (Butt, etal., 2002), a Lexical Functional Grammarimplementation.
These grammars do not define aprobability distribution over parses.
Rather, theyassign to each string all of its grammatically valid19parses.
Techniques for deciding between parsesproduced by these kinds of grammars include us-ing sortal constraints on arguments of semanticrelations (M?ller and Kasper, 2000); andannotating individual grammatical rules withweights (Kiefer, et al, 1999).
More recently, thedevelopment of rich treebanks such as the LinGORedwoods (Oepen, et al, 2004) which stores allanalyses of a sentence, along with an indication ofwhich is the preferred one, makes it possible totrain maximum entropy models for parse selection,(e.g.
Toutanova, et al, 2002).For at least the NLIDB task, however, selectionof the best parse is not an end in itself.
Rather,what is necessary is to generate the intended data-base query.
Indeed, two or more distinct syntacticparses may all lead to the same (intended) query.
Ifthe NLIDB identifies this query correctly, it hasachieved its goal without, strictly speaking, havingselected the best parse.Furthermore, eliminating any grammatically va-lid parse without subjecting it to further processingrisks missing the intended query.
For these rea-sons, Locutus does no intrinsic parse selection.Rather, it tries to build a query for all valid parses.The semantic constraints of the database domainlimit well-formed semantic representations to thosethat make sense in that domain, so that a grammat-ically valid parse may not receive a legitimate se-mantic representation, and thus not receive adatabase query.3 LocutusLocutus is an NLIDB which is designed to be port-able with respect to source language and grammat-ical formalism.
It can take as input the syntacticanalyses produced by any sufficiently sophisticatedgrammar/parser.
The implementation reported onin this paper consumes the f-structures producedby the Xerox English grammar.Locutus is also portable with respect to databasedomain.
The projection of semantic structures fromthe syntactic analyses provided by the parser isguided by a semantic description of the databasedomain together with a set of constraints calledsign templates linking syntactic patterns with se-mantic patterns.High precision (building only correct queries) ismaintained in a number of ways:?
High-precision syntactic grammars are used.?
The projection of semantic structures fromsyntactic structures is resource-sensitive.
Everyelement of the syntactic structure must be refe-renced just once by the sign template that li-censes the corresponding semantic structure.?
The semantic description of the database do-main defines a network of semantic relation-ships and their arguments, along withconstraints regarding which arguments arecompatible with one another.
In this way, se-mantic structures which would otherwise begenerated can be ruled out.3.1 Processing PipelineThe processing of a sentence by Locutus proceedsin the following way.
The string of words is passedto the XLE parser, which returns a contextualizedfeature structure from which individual parses areextracted.
An example parse appears in Figure 1.
[ PRED borderSUBJ [ PRED stateNTYPE [ NSYN common ]SPEC [ DET [ PRED whichNTYPE [ NSYN ?
]PRON-TYPE int ] ]CASE nomNUM plPERS 3 ]OBJ [ PRED delawareNTYPE [ NSYN proper ]CASE oblNUM sgPERS 3 ]PRON-INT [...]FOCUS-INT [...]TNS-ASP [...]CLAUSE-TYPE intPASSIVE -VTYPE main ]Figure 1: parse for ?Which states border delaware?
?Locutus interprets this syntactic analysis into a setof semantic representations called Semantic Mo-bile Structures, an example of which appears in anabbreviated form in Figure 2.x0 DefQuant: [ > [1]]r0 Border:STATE1STATE2: x1 DefQuant: [1]r1 StateName:STATENAME: [delaware]r2 State:STATEFigure 2: SMS for "Which states border delaware?
"20Finally, this representation is translated into anSQL query, as shown in Figure 3, which is sent tothe database, and the answer is shown.select t1.Namefrom border, state t1, state t2where border.State1 = t1.Name andborder.State2 = t2.Name andt2.Name = 'delaware'Figure 3: query for ?Which states border Delaware?
?3.2 EfficiencyThere is a bit of time savings in not having anintrinsic parse-selection step.
These savings arecounterbalanced by the extra time it takes to interp-ret parses that would have otherwise been excludedby such a step.
However, a certain amount of syn-tactic structure is shared among the various parsesof a syntactically ambiguous sentence.
Locutusrecognizes when a piece of syntactic structure hasalready been interpreted, and reuses that interpreta-tion in every parse in which it appears.
In this wayLocutus minimizes the extra time taken to processmultiple parses.
At any rate, processing speed doesnot appear to be a problem at this point in the de-velopment of Locutus.3.3 Further WorkAlthough Locutus has a wide range of functionali-ty, it is still a work in progress.
The format for au-thoring sign templates is rather complex, andcustomizing Locutus for a given database can betime-consuming.
I anticipate an authoring toolwhich makes much of the customization processautomatic, and hides much of the complexity of therest of the process from the author, but such a toolhas yet to be implemented.4 ExperimentTo test the coverage and precision of Locutus, Ihave customized it to answer questions from theGEOQUERY 250 corpus (Mooney, 1996), whichconsists of a database of geographical informationpaired with 250 English sentences requesting in-formation from that database.
25 of these sentencesare held out for the purposes of another study, andI have not examined the behavior of Locutus withrespect to these sentences.
I ran the other 225 sen-tences through Locutus, keeping track of whichsentences Locutus built at least one query for.
Foreach of those sentences, I also tracked the follow-ing:?
How many syntactic parses were generated bythe grammar?
How many queries were produced?
How many of those queries were correctThe XLE Engine includes a facility to do stochas-tic disambiguation (Kaplan, et al 2004), and theEnglish grammar I used comes with a propertyweights file of the kind required by the disambigu-ation process.
I ran the sentences through Locutususing just the single best parse returned by thatprocess, keeping track of how many queries wereproduced.5 Results223 of the 225 sentences (99.1%) are assigned atleast one query.
For the other two sentences, noanalysis returned by the parser reflect the intendedmeaning of the sentence.
The average number ofparses for these sentences is 3.01, with 158 sen-tences given at least two parses, and 84 sentencesgiven at least three.
Some sentences were given asmany as 20 parses.Figure 4 contains the graph of the number ofparses by the average number of queries assignedto sentences with that many parses.
Note that thenumber of queries per sentence is not correlatedwith the number of parses assigned by the gram-mar.
The sentences that were assigned more thanone query were each assigned either one or twoparses.
All the sentences with more syntacticparses were assigned a single query each.Figure 4: Average queries by ambiguity levelOf the 223 sentences that were assigned a query,219 of them were assigned exactly one query.Every query was correct in the sense that it accu-0.980.9911.011.021.031.041 3 5 7 9 11 13 15 17 19AvgQueries# of Parses21rately reflected a reasonable interpretation of thesentence.
Four sentences were each assigned twoqueries.
They are given in (1)-(4).
(1) How many people live in Washington?
(2) How many people live in New York?
(3) What is the length of the Colorado river?
(4) What is the length of the Mississippi river?It is appropriate that each of these sentences getstwo queries.
For (1)-(2), the GEOQUERY 250 data-base contains cities, their populations, states andtheir populations; ?Washington?
and ?New York?are both names of cities and states that appear inthe database.
For (3)-(4), one interpretation is toreturn the length of the river mentioned in the sen-tence.
The other possibility is to return all the riv-ers that are the same lengths as the onesmentioned.
For instance, in the GEOQUERY data-base, the Colorado and Arkansas rivers are both2333 km long.
One valid answer to (3) is the num-ber ?2333?.
The other valid answer is the list ofrivers ?Arkansas?
and ?Colorado?.
To give any ofthese sentences only a single query would be tomiss a reasonable interpretation.Table 1 summarizes the results when only a sin-gle parse for each sentence, chosen stochasticallyusing the property weights file provided with theXLE English grammar, is sent to Locutus.
Theparse is considered correct if it leads to a correctquery.# of sents avg.
parses % correct?
1 parse 223 3.01 54%?
2 parses 158 3.84 35%Table 1Although performance is better than chance, it isclearly less successful than when Locutus is al-lowed to use every parse, in which case a correctquery is always constructed.6 ConclusionFor natural language processing applications thattake the results of a high-precision syntactic parserand pass them along to further processing, select-ing the correct parse is not an end in itself.
It isonly useful insofar as it improves the final result.For applications such as NLIDBs, which areprovided with a precise semantic framework withinwhich sentences may be interpreted, it is better topass along the full set of grammatically validparses than to select beforehand a limited subset ofthose parses.
Using this technique, Locutusachieves 100% correctness on the sentences forwhich it builds a query.ReferencesButt, Miriam, Helge Dyvik, Tracy Holloway King,Hiroshi Masuichi, and Christian Rohrer.
"TheParallel Grammar Project."
Proceedings ofCOLING2002 Workshop on Grammar Engineeringand Evaluation.
2002.Flickinger, Dan.
"On building a more efficientgrammar by exploiting types."
Natural LanguageEngineering 6, no.
1 (2000): 15-28.Goss-Grubbs, David.
"Deep Processing for a PortableNatural Language Interface to Databases.
"dissertation, University of Washington.
to appear.Kaplan, Ron, Stefan Riezler, Trace King, JohnMaxwell, Alexander Vasserman, and RichardCrouch.
"Speed and Accuracy in Shallow and DeepStochastic Parsing."
Proceedings of the HumanLanguage Technology Conference and the 4thAnnual Meeting of the North American Chapter ofthe Association for Computational Linguistics(HLT-NAACL'04).
Boston, MA, 2004.Kiefer, Bernd, Hans-Ulrich Krieger, John Carroll, andRob Malouf.
"A Bag of Useful Techniques forEfficient and Robust Parsing."
Proceedings of the37th Meeting of the Association for ComputationalLinguistics.
College Park, MD, 1999.
473-480.Klein, Dan, and Christopher D. Manning.
"A*Parsing: Fast Exact Viterbi Parse Selection.
"Proceedings of HLT-NAACL 2003.
2003.
40-47.Mooney, Raymond.
Geoquery Data.
1996.http://www.cs.utexas.edu/users/ml/nldata/geoquery.html (accessed February 13, 2010).M?ller, Stefan, and Walter Kasper.
"HPSG Analysisof German."
In Verbmobil.
Foundations of Speech-to-Speech Translation, edited by WolfgangWahlster, 238-253.
Berlin: Springer, 2000.Oepen, Stephan, Dan Flickinger, Kristina Toutanova,and Christopher D. Manning.
"LinGO Redwoods:A Rich and Dynamic Treebank for HPSG.
"Research on Language and Computation (Springer)2 (2004): 575-596.Toutanova, Kristina, Christopher D. Manning, StuartShieber, Dan Flickinger, and Stephan Oepen.
"Parse disambiguation for a rich HPSG grammar.
"Proceedings of the First Workshop on Treebanksand Linguistic Theories.
2002.
253-263.22
