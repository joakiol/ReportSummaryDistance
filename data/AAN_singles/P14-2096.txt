Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 586?591,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsCross-language and Cross-encyclopedia Article Linking UsingMixed-language Topic Model and Hypernym TranslationYu-Chun WangDepartment of CSIENational Taiwan UniversityTaipei, Taiwand97023@csie.ntu.edu.twChun-Kai WuDepartment of CSIENational Tsinghua UniversityHsinchu, Taiwans102065512@m102.nthu.edu.twRichard Tzong-Han Tsai?Department of CSIENational Central UniversityChungli, Taiwanthtsai@csie.ncu.edu.twAbstractCreating cross-language article linksamong different online encyclopedias isnow an important task in the unificationof multilingual knowledge bases.
In thispaper, we propose a cross-language articlelinking method using a mixed-languagetopic model and hypernym translationfeatures based on an SVM model to linkEnglish Wikipedia and Chinese BaiduBaike, the most widely used Wiki-likeencyclopedia in China.
To evaluate ourapproach, we compile a data set from thetop 500 Baidu Baike articles and theircorresponding English Wiki articles.
Theevaluation results show that our approachachieves 80.95% in MRR and 87.46%in recall.
Our method does not heavilydepend on linguistic characteristics andcan be easily extended to generate cross-language article links among differentonline encyclopedias in other languages.1 IntroductionOnline encyclopedias are among the most fre-quently used Internet services today.
One ofthe largest and best known online encyclopediasis Wikipedia.
Wikipedia has many language ver-sions, and articles in one language contain hyper-links to corresponding pages in other languages.However, the coverage of different language ver-sions of Wikipedia is very inconsistent.
Table 1shows the statistics of inter-language link pagesin the English and Chinese editions in February2014.
The total number of Chinese articles isabout one-quarter of English ones, and only 2.3%of English articles have inter-language links totheir Chinese versions.
?corresponding authorArticles Inter-language Links Ratiozh 755,628 zh2en 486,086 64.3%en 4,470,246 en2zh 106,729 2.3%Table 1: Inter-Language Links in WikipediaHowever, there are alternatives to Wikipedia forsome languages.
In China, for example BaiduBaike and Hudong are the largest encyclopediasites, containing more than 6.2 and 7 million Chi-nese articles respectively.
Similarly, in Korea,Naver Knowledge Encyclopedia has a large pres-ence.Since alternative encyclopedias like BaiduBaike are larger (by article count) and growingfaster than the Chinese Wikipedia, it is worth-while to investigate creating cross-language linksamong different online encyclopedias.
Severalworks have focused on creating cross-languagelinks between Wikipedia language versions (Ohet al, 2008; Sorg and Cimiano, 2008) or find-ing a cross-language link for each entity mentionin a Wikipedia article, namely Cross-LanguageLink Discovery (CLLD) (Tang et al, 2013; Mc-Namee et al, 2011).
These works were able toexploit the link structure and metadata commonto all Wikipedia language versions.
However,when linking between different online encyclope-dia platforms this is more difficult as many of thesestructural features are different or not shared.
Todate, little research has been done into linking be-tween encyclopedias on different platforms.Title translation is an effective and widely usedmethod of creating cross-language links betweenencyclopedia articles.
(Wang et al, 2012; Adafreand de Rijke, 2005) However, title translationalone is not always sufficient.
In some cases, forexample, the titles of corresponding articles in dif-ferent languages do not even match.
Other meth-ods must be used along with title translation to cre-ate a more robust linking tool.586In this paper, we propose a method compris-ing title and hypernym translation and mixed-language topic model methods to select and linkrelated articles between the English Wikipedia andBaidu Baike online encyclopedias.
We also com-pile a suitable dataset from the above two ency-clopedias to evaluate the linking accuracy of ourmethod.2 MethodCross-language article linking between differentencyclopedias can be formulated as follows: Foreach encyclopedia K, a collection of human-written articles, can be defined as K = {ai}ni=1,where aiis an article in K and n is the size ofK.
Article linking can then be defined as fol-lows: Given two encyclopedia K1and K2, cross-language article linking is the task of finding thecorresponding equivalent article ajfrom encyclo-pedia K2for each article aifrom encyclopediaK1.
Equivalent articles are articles that describethe same topic in different languages.Our approach to cross-language article linkingcomprises two stages: candidate selection, whichproduces a list of candidate articles, and candidateranking, which ranks that list.2.1 Candidate SelectionSince knowledge bases (KB) may contain millionsof articles, comparison between all possible pairsin two knowledge bases is time-consuming andsometimes impractical.
To avoid brute-force com-parison, we first select plausible candidate articleson which to focus our efforts.
To extract possiblecandidates, two similarity calculation methods arecarried out: title matching and title similarity.2.1.1 Title MatchingIn our title matching method, we formulate can-didate selection as an English-Chinese cross-language information retrieval (CLIR) problem(Sch?onhofen et al, 2008), in which every Englisharticle?s title is treated as a query and all the arti-cles in the Chinese encyclopedia are treated as thedocuments.
We employ the two main CLIR meth-ods: query translation and document translation.In query translation, we translate the title of ev-ery English article into Chinese and then use thesetranslated titles as queries to retrieve articles fromthe Chinese encyclopedia.
In document transla-tion, we translate the contents of the entire Chineseencyclopedia into English and then search themusing the original English titles.
The top 100 re-sults for the query-translation and the top 100 re-sults for document-translation steps are unionized.The resulting list contains our title-matching can-didates.For the query- and document-translation steps,we use the Lucene search engine with similar-ity scores calculated by the Okapi BM25 rankingfunction (Beaulieu et al, 1997).
We separate allwords in the translated and original English articletitles with the ?OR?
operator before submission tothe search engine.
For all E-C and C-E translationtasks, we use Google Translate.2.1.2 Title SimilarityIn the title similarity method, every Chinese arti-cle title is represented as a vector, and each dis-tinct character in all these titles is a dimension ofall vectors.
The title of each English article istranslated into Chinese and represented as a vec-tor.
Then, cosine similarity between this vectorand the vector of each Chinese title is measured astitle similarity.2.2 Candidate RankingThe second stage of our approach is to scoreeach viable candidate using a supervised learningmethod, and then sort all candidates in order ofscore from high to low as final output.Each article xiin KB K1can berepresented by a feature vector xi=(f1(xi), f2(xi), .
.
.
, fn(xi)).
Also, we haveyj= (f1(yj), f2(yj), .
.
.
, fn(yj)) for a candidatearticle yjin KB K2.
Then, individual featurefunctions Fk(xi, yj) are based on the featureproperties of both article aiand aj.
The top pre-dicted corresponding article yjin the knowledgebase K2for an input article xiin K1shouldreceive a higher score than any other entity inK2, am?
K2,m 6= j.
We use the supportvector machine (SVM) approach to determine theprobability of each pair (xi,yj) being equivalent.Our SVM model?s features are described below.Title Matching and Title Similarity Feature(Baseline)We use the results of title matching and title sim-ilarity from the candidate selection stage as twofeatures for the candidate ranking stage.
The sim-ilarity values generated by title matching and titlesimilarity are used directly as real value featuresin the SVM model.587Mixed-language Topic Model Feature (MTM)For a linked English-Chinese article pair, the dis-tribution of words used in each usually showssome convergence.
The two semantically corre-sponding articles often have many related terms,which results in clusters of specific words.
If twoarticles do not describe the same topic, the distri-bution of terms is often scattered.
(Misra et al,2008) Thus, the distribution of terms is good mea-surement of article similarity.Because the number of all possible words is toolarge, we adopt a topic model to gather the wordsinto some latent topics.
For this feature, we usethe Latent Dirichlet Allocation (LDA) (Blei et al,2003).
LDA can be seen as a typical probabilisticapproach to latent topic computation.
Each topicis represented by a distribution of words, and eachword has a probability score used to measure itscontribution to the topic.
To train the LDA model,the pair English and Chinese articles are concate-nated into a single document.
English and Chineseterms are all regarded as terms of the same lan-guage and the LDA topic model, namely mixed-language topic model, generates both English andChinese terms for each latent topic.
Then, for eachEnglish article and Chinese candidate pair in test-ing, the LDA model provides the distribution ofthe latent topics.
Next, we can use entropy to mea-sure the distribution of topics.
The entropy of theestimated topic distribution of a related article isexpected to be lower than that of an unrelated ar-ticle.
We can calculate the entropy of the distribu-tion as a value for SVM.
The entropy is defined asfollows:H = ?T?j=1~?djlog~?djwhere T is the number of latent topics, ?djis thetopic distribution of a given topic j.Hypernym Translation Feature (HT)The first sentence of an encyclopedia article usu-ally contains the title of the article.
It may alsocontain a hypernym that defines the category ofthe article.
For example, the first sentence of the?iPad?
article in the English Wikipedia begins,?iPad is a line of tablet computers designed andmarketed by Apple Inc. .
.?
In this sentence, theterm ?tablet computers?
is the hypernym of iPad.These extracted hypernyms can be treated as arti-cle categories.
Therefore, articles containing thesame hypernym are likely to belong to the samecategory.In this study, we only carry out title hypernymextraction on the first sentences of English articlesdue to the looser syntactic structure of Chinese.
Togenerate dependency parse trees for the sentences,we adopt the Stanford Dependency Parser.
Then,we manually designed seven patterns to extract hy-pernyms from the parse tree structures.
To demon-strate this idea, let us take the English article ?TheHunger Games?
for example.
The first sentence ofthis article is ?The Hunger Games is a 2008 youngadult novel by American writer Suzanne Collins.
?Since article titles may be named entities or com-pound nouns, the dependency parser may mislabelthem and thus output an incorrect parse tree.
Toavoid this problem, we first replace all instances ofan article?s title in the first sentence with pronouns.For example, the previous sentence is rewritten as?It is a 2008 young adult novel by American writerSuzanne Collins.?
Then, the dependency parsergenerates the following parse tree:novelIt is a 2008 young adult collinsnsubj cop det num amod nn prep_bysuzanne writer Americannn nnamodNext, we apply our predefined syntactic patternsto extract the hypernym.
(Hearst, 1992) If any pat-tern matches the structure of the dependency parsetree, the hypernym can be extracted.
In the aboveexample, the following pattern is matched:NNIt is NNnsubj cop nn[target]In this pattern, the rightmost leaf is the hyper-nym target.
Thus, we can extract the hypernym?novel?
from the previous example.
The term?novel?
is the extracted hypernym of the Englisharticle ?The Hunger Games?.After extracting the hypernym of the English ar-ticle, the hypernym is translated into Chinese.
Thevalue of this feature in the SVM model is calcu-lated as follows:Fhypernym(h) = log count(translated(h))where h is the hypernym, translated(h) is theChinese translation of the term h.English Title Occurrence Feature (ETO)In a Baidu Baike article, the first sentence maycontain a parenthetical translation of the main ti-tle.
For example, the first sentence of the Chinese588article on San Francisco is ????
?San Fran-cisco???????????????????
?.We regard the appearance of the English title inthe first sentence of a Baidu Baike article as a bi-nary feature: If the English title appears in the firstsentence, the value of this feature is 1; otherwise,the value is 0.3 Evalutaion3.1 Evaluation DatasetIn order to evaluate the performance of cross-language article linking between English Wikiep-dia and Chinese Baidu Baike, we compilean English-Chinese evaluation dataset fromWikipedia and Baidu Baike online encyclopedias.First, our spider crawls the entire contents of En-glish Wikipedia and Chinese Baidu Baike.
Sincethe two encyclopedias?
article formats differ, wecopy the information in each article (title, content,category, etc.)
into a standardized XML structure.In order to generate the gold standard evalua-tion sets of correct English and Chinese articlepairs, we automatically collect English-Chineseinter-language links from Wikipedia.
For pairsthat have both English and Chinese articles, theChinese article title is regarded as the translationof the English one.
Next, we check if there is aChinese article in Baidu Baike with exactly thesame title as the one in Chinese Wikipedia.
Ifso, the corresponding English Wikipedia articleand the Baidu Baike article are paired in the goldstandard.To evaluate the performance of our method onlinking different types of encyclopedia articles, wecompile a set containing the most popular articles.We select the top 500 English-Chinese article pairswith the highest page view counts in Baidu Baike.This set represents the articles people in China aremost interested in.Because our approach uses an SVM model, thedata set should be split into training and test sets.For statistical generality, each data set is randomlysplit 4:1 (training:test) 30 times.
The final evalua-tion results are calculated as the mean of the aver-age of these 30 evaluation sets.3.2 Evaluation MetricsTo measure the quality of cross-language entitylinking, we use the following three metrics.
Foreach English article queries, ten output BaiduBaike candidates are generated in a ranked list.
Todefine the metrics, we use following notations: Nis the number of English query; ri,jis j-th correctChinese article for i-th English query; ci,kis k-thcandiate the system output for i-th English query.Top-k Accuracy (ACC)ACC measures the correctness of the first candi-date in the candidate list.
ACC = 1 means that alltop candidates are correctly linked (i.e.
they matchone of the references), and ACC = 0 means thatnone of the top candidates is correct.ACC =1NN?i=1{1 if ?ri,j: ri,j= ci,k0 otherwise}Mean Reciprocal Rank (MRR)Traditional MRR measures any correct answerproduced by the system from among the candi-dates.
1/MRR approximates the average rank ofthe correct transliteration.
An MRR closer to 1 im-plies that the correct answer usually appears closeto the top of the n-best lists.RRi={minj1jif ?ri,j, ci,k: ri,j= ci,k0 otherwise}MRR =1N?Ni=1RRiRecallRecall is the fraction of the retrieved articles thatare relevant to the given query.
Recall is used tomeasure the performance of the candidate selec-tion method.
If the candidate selection method canactually select the correct Chinese candidate, therecall will be high.Recall =|relevant articles| ?
|retrieved articles||relevant articles|3.3 Evaluation ResultsThe overall results of our method achieves 80.95%in MRR and 87.46% in recall.
Figure 1 shows thetop-k ACC from the top 1 to 5.
These results showthat our method is very effective in linking articlesin English Wikipedia to those in Baidu Baike.In order to show the benefits of each featureused in the SVM model, we conduct a experimentto test the performance of different feature combi-nations.
Because title similarity of the articles is awidely used method, we choose English and Chi-nese title similarity as the baseline.
Then, anotherfeature is added to each configuration until all thefeatures have been added.
Table 2 shows the finalresults of different feature combinations.5890.76?0.839?0.858?0.869?
0.87?0.7?0.72?0.74?0.76?0.78?0.8?0.82?0.84?0.86?0.88?1?
2?
3?
4?
5?TopK?Figure 1: Top-k AccuracyLevel Configuration MRR0 Baseline (BL) 0.65591BL + MTM?10.6967?BL + HT?20.6975?BL + ETO?30.6981?2BL + MTM + HT 0.7703?BL + MTM + ETO 0.7558?BL + HT + ETO 0.7682?3 BL + MTM + HT + ETO 0.8095?
?1MTM: mix-language topic model?2HT: hypernym translation?3ETO: English title occurrence?This config.
outperforms the best config.
in last level withstatistically significant difference.Table 2: MRRs of Feature CombinationsIn the results, we can observe that mix-languagetopic model, hypernym, and English title oc-curence features all noticeably improve the perfor-mance.
Combining two of these three feature hasmore improvement and the combination of all thefeatures achieves the best.4 DiscussionAlthough our method can effectively generatecross-language links with high accuracy, somecorrect candidates are not ranked number one.
Af-ter examining the results, we can divide errors intoseveral categories:The first kind of error is due to large literal dif-ferences between the English and Chinese titles.For example, for the English article ?Nero?, ourapproach ranks the Chinese candidate ?????
(?King Nero?)
as number one, instead of the cor-rect answer ??????????????????????
(the number two candidate).
The titleof the correct Chinese article is the full name ofthe Roman Emperor Nero (Nero Claudius DrususGermanicus).
The false positive ?????
is a his-torical novel about the life of the Emperor Nero.Because of the large difference in title lengths, thevalue of the title similarity feature between the En-glish article ?Nero?
and the corresponding Chi-nese article is low.
Such length differences maycause the SVM model to rank the correct answerlower when the difference of other features are notso significant because the contents of the Chinesecandidates are similar.The second error type is caused by articles thathave duplicates in Baidu Baike.
For example, forthe English article ?Jensen Ackles?, our approachgenerates a link to the Chinese article ?Jensen?in Baidu Baike.
However, there is another Baiduarticle ????????
(?Jensen Ackles?).
Thesetwo articles both describe the actor Jensen Ackles.In this case, our approach still generates a correctlink, although it is not the one in the gold standard.The third error type is translation errors.
For ex-ample, the English article ?Raccoon?
is linked tothe Baidu article ???
(raccoon dog), though thecorrect one is ????
(raccoon).
The reason is thatGoogle Translate provides the translation ???
in-stead of ???
?.5 ConclusionCross-language article linking is the task of creat-ing links between online encyclopedia articles indifferent languages that describe the same content.We propose a method based on article hypernymand topic model to link English Wikipedia articlesto corresponding Chinese Baidu Baike articles.Our method comprises two stages: candidate se-lection and candidate ranking.
We formulate can-didate selection as a cross-language informationretrieval task based on the title similarity betweenEnglish and Chinese articles.
In candidate rank-ing, we employ several features of the articles inour SVM model.
To evaluate our method, we com-pile a dataset from English Wikipedia and BaiduBaike, containing the 500 most popular Baidu ar-ticles.
Evaluation results of our method show anMRR of up to 80.95% and a recall of 87.46%.
Thisshows that our method is effective in generatingcross-language links between English Wikipediaand Baidu Baike with high accuracy.
Our methoddoes not heavily depend on linguistic characteris-tics and can be easily extended to generate cross-language article links among different encyclope-dias in other languages.590ReferencesSisay Fissaha Adafre and Maarten de Rijke.
2005.Discovering missing links in wikipedia.
In Proceed-ings of the 3rd international workshop on Link dis-covery (LinkKDD ?05).M.
Beaulieu, M. Gatford, X. Huang, S. Robertson,S.
Walker, and P. Williams.
1997.
Okapi at TREC-5.
In Proceedings of the fifth Text REtrieval Confer-ence (TREC-5), pages 143?166.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
Journal of Ma-chine Learning Research, 3(4-5):993?1022.Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 14th conference on Computational linguistics,volume 2.Paul McNamee, James Mayfield, Dawn Lawrie, Dou-glas W Oard, and David S Doermann.
2011.
Cross-language entity linking.
In Proceedings of Interna-tional Joint Con-ference on Natural Language Pro-cessing (IJCNLP), pages 255?263.Hemant Misra, Olivier Cappe, and Franc?ois Yvon.2008.
Using lda to detect semantically incoherentdocuments.
In Proceedings of the Twelfth Confer-ence on Computational Natural Language Learning(CoNLL ?08).Jong-Hoon Oh, Daisuke Kawahara, Kiyotaka Uchi-moto, Jun?ichi Kazama, and Kentaro Torisawa.2008.
Enriching multilingual language re-sources by discovering missing cross-languagelinks in wikipedia.
In Proceedings of the 2008IEEE/WIC/ACM International Conference on WebIntelligence and Intelligent Agent Technology, vol-ume 1, pages 322?328.P`eter Sch?onhofen, Andr`as Bencz`ur, Istv`an B`?r`o, andK`aroly Csalog`any.
2008.
Cross-language retrievalwith wikipedia.
Advances in Multilingual andMultimodal Information Retrieval, Lecture Notes inComputer Science, 5152:72?79.Philipp Sorg and Philipp Cimiano.
2008.
Enrich-ing the crosslingual link structure of wikipedia-aclassification-based approach.
In Proceedings of theAAAI 2008 Workshop on Wikipedia and Artifical In-telligence, pages 49?54.Ling-Xiang Tang, In-Su Kang, Fuminori Kimura, Yi-Hsun Lee, Andrew Trotman, Shlomo Geva, and YueXu.
2013.
Overview of the ntcir-10 cross-linguallink discovery task.
In Proceedings of the Tenth NT-CIR Workshop Meeting.Zhichun Wang, Juanzi Li, Zhigang Wang, and Jie Tang.2012.
Cross-lingual knowledge linking across wikiknowledge bases.
In Proceedings of the 21st in-ternational conference on World Wide Web (WWW?12).591
