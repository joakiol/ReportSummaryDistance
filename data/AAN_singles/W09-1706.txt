Proceedings of the NAACL HLT Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics, pages 45?53,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsCombining Syntactic Co-occurrences and Nearest Neighbours inDistributional Methods to Remedy Data Sparseness.Lonneke van der PlasDepartment of LinguisticsUniversity of GenevaGeneva, SwitzerlandAbstractThe task of automatically acquiring semanti-cally related words have led people to studydistributional similarity.
The distributionalhypothesis states that words that are simi-lar share similar contexts.
In this paper wepresent a technique that aims at improvingthe performance of a syntax-based distribu-tional method by augmenting the original in-put of the system (syntactic co-occurrences)with the output of the system (nearest neigh-bours).
This technique is based on the idea ofthe transitivity of similarity.1 IntroductionThe approach described in this paper builds on theDISTRIBUTIONAL HYPOTHESIS, the idea that se-mantically related words are distributed similarlyover contexts.
Harris (1968) claims that, ?the mean-ing of entities and the meaning of grammatical re-lations among them, is related to the restriction ofcombinations of these entities relative to other enti-ties.?
In other words, you can grasp the meaning ofa word by looking at its context.Context can be defined in many ways.
In this pa-per we look at the syntactic contexts a word is foundin.
For example, the verbs that are in a object rela-tion with a particular noun form a part of its context.In accordance with the Firthian tradition these con-texts can be used to determine the semantic related-ness of words.
For instance, words that occur in aobject relation with the verb drink have somethingin common: they are liquid.
We will refer to wordslinked by a syntactic relation, such as drink -OBJ-beer, as SYNTACTIC CO-OCCURRENCES.
Syntac-tic co-occurrences have often been used in work onlexical acquisition (Lin, 1998b; Dagan et al, 1999;Curran and Moens, 2002; Alfonseca and Manand-har, 2002).Distributional methods for automatic acquisitionof semantically related words suffer from datasparseness.
They generally perform less wellon low-frequency words (Weeds and Weir, 2005;van der Plas, 2008).
This is a pity because the avail-able resources for semantically related words usu-ally cover the frequent words rather well.
It is for thelow-frequency words that automatic methods wouldbe most welcome.This paper tries to find a way to improve the per-formance on the words that are most wanted: themiddle to very-low-frequency words.
At the basis ofthe proposed technique lies the intuition that seman-tic similarity between concepts is transitive: if A islike B and B is like C ?
A is like C. As explainedin the second paragraph of this section, the fact thatboth milk and water are found in object relation withthe verb to drink tells us that they might be similar.However, even if we had never seen lemonade in thesame syntactic contexts as water, we could still in-fer that lemonade and water are similar because wehave found evidence that both water and lemonadeare similar to milk.In an ideal world we would be able to infer thatmilk and water are related from the syntactic co-occurrences alone, however, because of data sparse-ness we might not always encounter this evidencedirectly.
We hope that nearest neighbours are ableto account for the missing information.
Nearestneighbours such as milk and water, and water andlemonade are the output of our system.
We used thenearest neighbours (the output of our system) as in-put to our system that normally takes syntactic co-45occurrences as input.
Thus it uses the output of thesystem as input in a second round to smooth the syn-tactic co-occurrences.Grefenstette (1994) discusses the difference be-tween FIRST- AND SECOND-ORDER AFFINITIES.There exists a first-order affinity between words ifthey often appear in the same context, i.e., if they areoften found in the vicinity of each other.
Words thatco-occur frequently such as orange and squeezedhave a first-order affinity.
There exists a second-order affinity between words if they share many first-order affinities.
These words need not appear to-gether themselves, but their contexts are similar.
Or-ange and lemon appear often in similar contexts suchas being the object of squeezed, or being modified byjuicy.In this paper we will use second-order affinities asinput to the distributional system.
We are thus com-puting THIRD-ORDER AFFINITIES.1 There existsa third-order affinity between words, if they sharemany second-order affinities.
If pear and water-melon are similar and orange and watermelon aresimilar, then pear and orange have a third-orderaffinity.We will refer to traditional approaches that com-pute second-order affinities as second-order tech-niques.
In this paper we will compare a second-order technique with a third-order technique, a tech-nique that computes third-order affinities.
In ad-dition we use a combined technique that combinesboth second-order and third-order techniques.2 Previous workIn Edmonds (1997) the term third-order is used torefer to a different concept.
Firstly, we have tomention that the author is working in a proximity-based framework, that is, he is concerned with co-occurrences of words in text, not relations betweenwords in syntactic dependencies.
Secondly, the no-tion of higher-order co-occurrences refers to con-nectivity paths in networks, i.e.
the network of re-lations between words co-occurring is augmentedby connecting words that are connected by a pathof length 2 (second-order co-occurrences) and paths1Grefenstette (1994) uses the term third-order affinities fora different concept, i.e.
for the subgroupings that can be foundin list of second-order nearest neighbours.of length 3 (third-order co-occurrences) and so on.In the above example water and lemonade wouldbe connected by a second-order relation implied bythe network in which water and lemonade both co-occur with for example to pour.
A third-order rela-tion would be implied between lemonade and drinkif drink should co-occur with water.
We definethird-order affinity as an iterative process of calcu-lating similarity.
The output of the system is fedinto the system again.
There exists a third-orderaffinity between words if they share many nearestneighbours with another word, not if a word sharesa context that in turn shares a context with the otherword.
The same perspective on higher-order co-occurrence, that of connectivity paths in networks,is taken in literature of computational modelling ofthe acquisition of word meaning (Lemaire and Den-hire, 2006).Although Biemann et al (2004) work in the sameproximity-based tradition as the previous authorstheir notion of third-order is closer to our definition.It is defined as an iterative process in which wordsare linked when their co-occurrence score trespassesa certain threshold.
These nth-order co-occurrencesare then used to construct an artificial corpus con-sisting of the co-occurrence sets retrieved from theoriginal corpus.Schu?tze and Walsh (2008) present a graph-theoretic model of lexical-syntactic representation inwhich higher-order syntactic relations, those that re-quire some generalisation, are defined recursively.The problem they are trying to solve, lexical syn-tactic acquisition, is different form ours and sois the evaluation method: discriminating sentencesthat exhibit local coherence from those that do not.Again the method is proximity-based, but since thecontext are defined very locally (left and right neigh-bours) the results are likely to be more compara-ble to a syntax-based method than proximity-basedmethods that use larger contexts.3 Limits of the transitivity of similarityThe validity of the third-order affinities is depen-dent on the transitivity of the similarity between con-cepts.
Unfortunately, it is not always the case thatthe similarity between A and B and B and C impliesthe similarity between A and C.46When two concepts are identical, the transitivityof similarity holds.
If A=B AND B=C ?
A=C.Does the same reasoning hold for similarity of alesser degree?
For (near-)synonyms the transitivityholds and it is symmetric.
If felicity is like gladness,and gladness is like joy?
felicity is like joy.
Also,the near-synonymy relation is symmetric.
We caninfer that gladness is like felicity.Tversky and Gati (1978) give an example of co-hyponymy where transitivity does not hold.
Ja-maica is similar to Cuba (with respect to geograph-ical proximity); Cuba is similar to Russia (with re-spect to their political affinity), but Jamaica and Rus-sia are not similar at all.
Geographical proximity andpolitical affinity are SEPARABLE FEATURES.
Cubaand Jamaica are co-hyponyms if we imagine a hy-pernym Caribbean islands of which both conceptsare daughters.
Cuba and Russia are co-hyponymstoo, but being daughters of another mother, i.e.
theconcept communist countries.
The concept Jamaicathus inherits features from multiple mothers.
Whatcan we say about the transitivity of meaning in thiscase?
The transitivity between two co-hyponymsholds when restricted to single inheritance.When words are ambiguous, we come to a sim-ilar situation.
Widdows (2004) gives the followingexample: Apple is similar to IBM in the domain ofcomputer companies; Apple is similar to pear, whenwe are thinking of fruit.
Pear and IBM are not sim-ilar at all.
Again, there is the problem of multipleinheritance.
Apple is a daughter both of the con-cept computer manufacturers and of fruits.
For co-hyponyms similarity is only transitive in case of sin-gle inheritance.
The same holds for synonyms.
If aword has multiple senses we get into trouble whenapplying the transitivity of meaning.Although we have seen many examples of caseswhere the transitivity of meaning does not hold, wehope to find improvements for finding semanticallyrelated words, when using third-order affinity tech-niques.4 MethodologyWe will now describe the methodology used to com-pute nearest neighbours (subsection 4.1).
In subsec-tion 4.2 we will describe how we have used thesenearest neighbours as input to the third-order andcombined technique.4.1 Syntax-based distributional similarityIn this section we will describe the syntactic con-texts selected, the data we used, and the measuresand weights applied to retrieve nearest neighbours.4.1.1 Syntactic contextMost research has been done using a limited num-ber of syntactic relations (Lee, 1999; Weeds, 2003).We use several syntactic relations: subject, ob-ject, adjective, coordination, apposition, and prepo-sitional complement.
In Figure 1 examples are givenfor these types of syntactic relations.2Subj: De kat eet.
?The cat eats.
?Obj: Ik voer de kat.
?I feed the cat.
?Adj: De langharige kat loopt.
?The long-haired cat walks.
?Coord: Jip and Janneke spelen.
?Jip and Janneke are playing.
?Appo: De clown Bassie lacht.
?The clown Bassie is laughing.
?Prep: Ik begin met mijn werk.
?I start with my work.
?Figure 1: Types of syntactic relations extracted4.1.2 Data collectionBecause we believe that the method will remedydata sparseness we applied the method to a medium-sized corpus.
Approximately 80 million words ofDutch newspaper text.3 All data is parsed automat-ically using the Alpino parser (van Noord, 2006).The result of parsing a sentence is a dependencygraph according to the guidelines of the Corpus ofSpoken Dutch (Moortgat et al, 2000).4.1.3 Syntactic co-occurrencesFor each noun we find its syntactic contexts in thedata.
This results in CO-OCCURRENCE VECTORS,such as the vector given in Table 1 for the headwordkat.
These are used to find distributionally similar2We are working on Dutch and we are thus dealing withDutch data.3This is the so-called CLEF corpus as it was used in theCross Language Evaluation Forum (CLEF).
The corpus is asubset of the TwNC corpus (Ordelman, 2002).47heb OBJ voer OBJ harig ADJ?have OBJ?
?feed OBJ?
?furry?
ADJ?kat ?cat?
50 10 25Table 1: Syntactic co-occurrence vector for katwords.
Every cell in the vector refers to a particularSYNTACTIC CO-OCCURRENCE TYPE, for example,kat ?cat?
in object relation with voer ?feed?.
The val-ues of these cells indicate the number of times theco-occurrence type under consideration is found inthe corpus.
In the example, kat ?cat?
is found inobject relation with voer ?feed?
10 times.
In otherwords, the CELL FREQUENCY for this co-occurrencetype is 10.The first column of this table shows the HEAD-WORD, i.e.
the word for which we determine thecontexts it is found in.
Here, we only find kat ?cat?.The first row shows the contexts that are found, i.e.the syntactic relation plus the accompanying word.These contexts are referred to by the terms FEA-TURES or ATTRIBUTES.Each co-occurrence type has a cell frequency.Likewise each headword has a ROW FREQUENCY.The row frequency of a certain headword is the sumof all its cell frequencies.
In our example the rowfrequency for the word kat ?cat?
is 85.
Cut-offs forcell and row frequency can be applied to discard cer-tain infrequent co-occurrence types or headwords,respectively.
We use cutoffs because we have toolittle confidence in our characterisations of wordswith low frequency.
We have set a row cut-off of10.
So only headwords that appear in 10 or moreco-occurrence tokens in total are taken into account.We have not set a cutoff for the cell frequency.4.1.4 Measures and feature weightsSome syntactic contexts are more informativethan others.
Large frequency counts do not alwaysindicate an important syntactic co-occurrence.
Alarge number of nouns can occur as the subject of theverb hebben ?have?.
The verb hebben is selectionallyweak (Resnik, 1993) or a LIGHT verb.
A verb suchas voer ?feed?
on the other hand occurs much lessfrequently, and only with a restricted set of nounsas direct object.
Intuitively, the fact that two nounsboth occur as subject of hebben tells us less abouttheir semantic similarity than the fact that two nounsboth occur as the direct object of feed.
The resultsof vector-based methods can be improved if we takeinto account the fact that not all combinations ofa word and syntactic relation have the same infor-mation value.
We have used POINTWISE MUTUALINFORMATION (PMI, Church and Hanks (1989)) toaccount for the differences in information value be-tween the several headwords and attributes.The more similar the co-occurrence vectors of anytwo headwords are, the more distributionally similarthe headwords are.
In order to compare the vectorsof any two headwords, we need a similarity measure.In these experiments we have used a variant of Dice:Dice?, proposed by Curran and Moens (2002).
It isdefined as:Dice?
= 2?min(wgt(W1, ?r, ?w?
), wgt(W2, ?r, ?w?
))?wgt(W1, ?r, ?w?)
+ wgt(W2, ?r, ?w?
)We describe the function using an extension of thenotation used by Lin (1998a), adapted by Curran(2003).
Co-occurrence data is described as relationtuples: ?word, relation, word?
?, for example, ?cat,obj, have?.Asterisks indicate a set of values ranging over allexisting values of that component of the relation tu-ple.
For example, (w, ?, ?)
denotes for a given wordw all relations with any other word it has been foundin.
W1 and W2 are the two words we are compar-ing, and wgt is the weight given by PMI.Whereas Dice does not take feature weights intoaccount, Dice?
does.
For each feature two wordsshare, the minimum is taken.
If W1 occurred 15times with relation r and word w?
and W2 occurred10 times with relation r and word w?, it selects 10as the minimum (if weighting is set to 1).
Notethat Dice?
gives the same ranking as the well-knownJaccard measure, i.e.
there is a monotonic trans-formation between their scores.
Dice?
is easier tocompute and therefore the preferred measure (Cur-ran and Moens, 2002).
Choices for measures andweights are based on previous work (van der Plasand Bouma, 2005).4.2 Syntactic co-occurrences and nearestneighboursThe syntactic co-occurrence vectors have co-occurrence frequencies as values.
An example isgiven in Figure 2.48GRACHT ?canal?97 Amsterdams ADJ ?Amsterdam ADJ?26 ben SUBJ ?am SUBJ?12 word SUBJ ?become SUBJ?9 straat CONJ ?street CONJ?9 gedempt ADJ ?closed ADJ?8 Utrechts ADJ Utrecht ADJ5 wal CONJ ?shore CONJ?5 muur CONJ ?wall CONJ?5 moet SUBJ ?has to SUBJ?5 graaf OBJ ?ditch OBJ?Figure 2: Syntactic co-occurrences for the word gracht?canal?To retrieve nearest neighbours, needed for thethird-order technique, we computed for each noun aranked list of most similar words using the method-ology described in the two previous sections, i.e.
bycomparing the weighted feature vector of the head-word with all other words in the corpus.
We col-lected the 3 most similar nouns to all nouns.
Theseare the nearest neighbours that will be input to ourthird-order system.Now, how do we construct a second-order vec-tor from these nearest neighbours?
The cells ofthe second-order vectors that we want to constructshould reflect the similarity between pairs of words.The scores given to the pairs of words by the sys-tem do not usually reflect the similarity very wellacross different headwords and discriminates too lit-tle between different nearest neighbours for a givenheadword.Instead we used the ranks or rather reversed ranksfor a given candidate word.
However, the decreasein similarity between the first candidate and the sec-ond is not linear.
It decreases more rapidly.
After in-specting the average decrease in similarity for near-est neighbours, when going down the ranked list, wedecided to use a scoring method that is in line withZipf?s law (Zipf, 1949).
We decided to attribute sim-ilarity scores that are decreasing very rapidly for thefirst ranks and less as we go down the ranked list ofnearest neighbours.Apart from deciding on the slope of the similar-ity score we needed to set a start value.
We de-cided to choose a start value according to the high-est co-occurrence frequency (in the syntactic co-occurrences) for that headword.
So if a headword?sGRACHT ?canal?97 gracht ?canal?48 laan ?avenue?32 sloot ?ditch?Figure 3: Nearest neighbours for the word gracht ?canal?highest co-occurrence frequency was 100, a simi-larity score of 100 is given to the word at the firstrank (that is itself) and a score of 50 to the candi-date word at the second rank and so on.
The in-tuition between this is that we want to balance theimportance given to nearest neighbours and syntac-tic co-occurrences.
The importance of the nearestneighbours will not tresspass the importance of thesyntactic co-occurrences.The highest score will be given to the second-order affinity between a headword and itself.
Thisseems an unnecessary addition, but it is not, becausewe want canal to be similar to words that have canalas a second-order affinity as well.The second-order similarity score (SOSS) for agiven headword (h) and a given nearest neighbour(nn) is defined as follows:SOSS(h,nn) = max.freq.of.coocc(h)rank(nn)We have given an example of the second-orderfeature vector of the word gracht ?canal?
in Figure 3.As we see the highest score is given to second-orderaffinity between the headword and the headword it-self : gracht-gracht.
This score is taken from thehighest co-occurrence frequency found for the wordgracht as can be seen in Figure 2.
Second-orderfeature vectors such as given in Figure 3 are con-structed for all headwords to be used as input to thethird-order technique.
For the combined techniquewe concatenated both types of data.
So the input tothe combined technique for the word canal would beall its syntactic co-occurrences of which a subset isgiven in Figure 2 plus the three nearest neighboursgiven in Figure 3.5 EvaluationIn the following subsections we will first explainhow we determined the semantic similarity of the re-trieved nearest neighbours (subsection 5.1) and thenwe will describe the test sets used (subsection 5.2).495.1 EWN similarity measure and synonymsLike most researchers in the field of distributionalmethods we have little choice but to evaluate ourwork on the resource that we want to enrich.
Wewant to be able to enrich Dutch EuroWordNet(EWN, Vossen (1998)), but at the same time we useit to evaluate on.
Especially for Dutch there arenot many resources to evaluate semantically relatedwords available.For each word we collected its k nearest neigh-bours according to the system.
For each pair ofwords4 (target word plus one of the nearest neigh-bours) we calculated the semantic similarity accord-ing to EWN.
We used the Wu and Palmer mea-sure (Wu and Palmer, 1994) applied to Dutch EWNfor computing the semantic similarity between twowords.5 The EWN similarity of a set of word pairsis defined as the average of the similarity betweenthe pairs.The Wu and Palmer measure for computing thesemantic similarity between two words (W1 andW2) in a word net, whose most specific commonsubsumer (lowest super-ordinate) is W3, is definedas follows:Sim(W1,W2) = 2(D3)D1 + D2 + 2(D3)We computed, D1 (D2) as the distance from W1(W2) to the lowest common ancestor of W1 and W2,W3.
D3 is the distance of that ancestor to the rootnode.Some words returned by the system as near-est neighbours cannot be found in EWN.
Becausecounting the words not found in EWN as errorswould be too harsh6 we select the next nearest neigh-bour that is found in EWN, when encountering a not-found word.The Wu and Palmer measure gives an indicationof the degree of semantic similarity among the re-4If a word is ambiguous according to EWN, i.e.
is a memberof several synsets, the highest similarity score is used.5This measure correlates well with human judgements (Lin,1998b) without the need for sense-tagged frequency informa-tion, which we believe is not available for Dutch.6Dutch EWN is incomplete.
It is about half the size ofPrinceton WordNet (Fellbaum, 1998).
Nearest neighbours thatare not found in EWN might be valuable additions that we donot want to penalise the system too much for.EWN similarityk=1 k=3 k=5 k=10VLF 2 0.391 0.378 0.364 0.3502-3 0.395 0.392 0.376 0.3593 0.413 0.412 0.411 0.410LF 2 0.433 0.408 0.392 0.3712-3 0.434 0.417 0.401 0.3813 0.437 0.426 0.426 0.428MF 2 0.644 0.605 0.586 0.5552-3 0.646 0.608 0.589 0.5613 0.643 0.608 0.589 0.575HF 2 0.719 0.672 0.645 0.6102-3 0.718 0.674 0.645 0.6123 0.720 0.670 0.639 0.615Table 2: EWN similarity several values of k for the fourtest setstrieved neighbours.
The fact that it combines sev-eral lexical relations, such as synonymy, hyponymy,an co-hyponymy is an advantage on the one hand,but it is coupled with the disadvantage that it is arather opaque measure.
We have therefore decidedto look at one lexical relation in particular: We cal-culated the percentage of synonyms according toEWN.
Note that it is a very strict evaluation and thenumbers will therefore be relatively low.
BecauseDutch EWN is much smaller than Princeton Word-Net many synonyms are missing.5.2 Test setsTo evaluate on EWN, we have used four test sets ofeach 1000 words ranging over four frequency bands:high-frequency, middle frequency, low-frequency,and very-low frequency.
For every noun appearingin EWN we have determined its frequency in the80 million-word corpus of newspaper text.
For thehigh-frequency test set the frequency ranges from258,253 (jaar, ?year?)
to 2,278 (sce`ne, ?scene?).
Themiddle frequency test set has frequencies rangingbetween 541 (celstraf, ?jail sentence?)
and 364 (vre-desverdrag, ?peace treaty?).
The low-frequency testset has frequencies ranging between 28 (ro?ntgenon-derzoek, ?x-ray research?)
and 23 (vriendenprijs,?paltry amount?).
For the very low frequency testset the frequency goes from 9 (slaginstrument ?per-cussion instrument?)
to 8 (cederhout ?cedar wood?
).506 Results and discussionIn Table 2 the results of using second-order (2), com-bined (2+3), and third-order (3) techniques is pre-sented.
The average EWN similarity is shown at sev-eral values of k. At k=1 the average EWN similaritybetween the test word and the nearest neighbour atthe first rank is calculated.
For k=3 we average overthe top-three nearest neighbours returned by the sys-tem and so on.
Results are given for each of the fourtest sets, the very-low-frequency set (VLF), the low-frequency test set (LF), the middle-frequency test set(MF), and high-frequency test set (HF).We can easily compare the scores from thesecond-order technique and the combined tech-nique.
The scores for the third-order technique is alittle more difficult to compare because, since thereis very little data, it is often not possible for alltest words to find the number of nearest neighboursgiven under k. The coverage of the third-order tech-nique is low, especially for the very-low to low-frequency test set.
Already at k=1 the number of testword is about 60% and 70% (resp.)
of the numberof nearest neighbours found when using the second-order technique.
For the middle and high-frequencytest set the number of nearest neighbours found iscomparable, but less for high values of k.Let us compare the second-order and combinedtechniques since coverage of these techniques ismore comparable.7 We see that the combinedmethod outperforms the second-order method foralmost all test sets.
For the high frequency testset there is no difference in performance and forthe middle-frequency testset the differences are verysmall too.
The largest improvements are for thevery-low-frequency and low-frequency test set.
Thisis expected, since the method was introduced to rem-edy data sparseness and for these words data sparse-ness is most severe.
We can conclude that exploitingthe transitivity of meaning by augmenting the inputto the system with nearest neighbours from a previ-ous round results in a higher degree of semantic sim-ilarity among very-low and low-frequency words.The differences in performance are small, but we7In fact, the coverage of the combined method is a bit higher,because it combines two types of data, but the differences arenot as big as between the third-order and the second-order tech-nique.Synonymsk=1 k=3 k=5 k=10HF2 143(14.39) 276(9.26) 357(7.18) 461(4.64)2+3 148(14.89) 275(9.22) 356(7.16) 465(4.68)3 154(15.54) 259(8.84) 315(6.73) 382(5.26)MF2 105(10.56) 194(6.51) 245(4.93) 312(3.14)2+3 109(10.97) 200(6.71) 250(5.03) 318(3.20)3 107(11.38) 173(6.60) 198(5.07) 214(3.95)LF2 33(3.75) 65(2.47) 87(2.00) 108(1.28)2+3 34(3.86) 73(2.77) 88(2.01) 113(1.32)3 25(4.01) 41(3.18) 48(3.10) 54(3.20)VLF2 2(0.54) 4(0.36) 8(0.44) 10(0.30)2+3 2(0.54) 4(0.36) 9(0.49) 10(0.29)3 2(0.91) 2(0.50) 2(0.44) 2(0.42)Table 3: Number of synonyms at several values of k forthe four test setsshould keep in mind that that EWN similarity doesnot go from 0 to 1.
The random baseline reported invan der Plas (2008), i.e.
the score obtained by pick-ing random words from EWN as nearest neighboursof a given target word, is 0.26 at k=5 and a score of1 is impossible unless all words in the testset have ksynonyms.To get a better idea of what is going on we in-spected the nearest neighbours that are the output ofthe system.
There seemed to be many more syn-onyms in the output of the combined method thanin the output of the second-order method.
Becausesynonymy is the lexical relation that is at the far endof semantic similarity, it is important to find manysynonyms.
To quantify our findings we determinedthe number of synonyms among the nearest neigh-bours according to EWN.In Table 3 the number of synonyms as well as thepercentage of synonyms found at several values of kis shown.8Our initial findings proved quantifiable.
Thecombined technique (2+3) results in more syn-onyms.
Most surprising are the results for the high-frequency testset.
Whereas, based on evaluationswith the EWN similarity scores, we believed themethod did not do much good for the high-frequency8At k=n we do not always find n nearest neighbour for allwords in the test set.
That is the reason for showing both countsand percentages in the table.51Second-order Combinedcassette videoband bandje CDi cassettecassette videoband bandje CDi cassettevideoband cassette cassette DCC videobandCDi videofilm videoband CD bandjeFigure 4: Nearest neighbours for videoband ?video tape?,cassette ?cassette?
bandje ?tape?
and CDi ?CDi?method, we now see that the number of synonymsfound is higher when using the combined technique,especially at k=1.
This holds for all but one testset.
Only for the very low frequency test set thereis hardly any difference.We explained before that coverage of the third-order technique is low.
However, we see that thetechnique results in higher numbers of synonymsfound at k=1 for the high-frequency (+11) and themiddle-frequency test set (+2).
At higher values ofk the absolute numbers are smaller for the third-order technique and also for the low and very-low-frequency test set.
This is to be expected becausethe number of nearest neighbours found dramati-cally decreases, when using a third-order techniqueon its own.
But it is surprising that we are able to ex-tract more synonyms, when using only the two near-est neighbours (plus the headword itself) computedby the system before as input.Manual inspection showed that what happens isthat nearest neighbours that have each other as near-est neighbour are promoted.
As can be seen in Fig-ure 4, cassette ?cassette?
has videoband ?video tape?,and CDi as nearest neighbour.
Because CDi has nonearest neighbours in common with cassette, exceptitself, it is demoted in the output of the combinedmethod.
The word bandje ?tape?
has two neighboursin common with cassette.
Bandje is promoted in theoutput of the combined method.This finding bring us to work by Lin (1998a),where the author shows that, when selecting onlyrespective nearest neighbours (words that have eachother as the one most nearest neighbour), the resultsare rather good.
Our technique incorporates that no-tion, but is less restricted, especially in the combinedtechnique.7 Conclusion and future workGuided by the idea of the transitivity of mean-ing we have shown that by augmenting syntacticco-occurrences (that are usually input to distribu-tional methods) with nearest neighbours (the outputof the system from a previous round) we are ableto improve the performance on low- and middle-frequency words with respect to semantic related-ness in general.
This result is encouraging, becausedistributional methods usually perform rather poorlyon low- and middle-frequency words.
In addition,these are the words that are most sought after, be-cause they are the ones that are missing in existingresources.
There is something to be gained for thehigh-frequency to low-frequency words in addition.The percentage of synonyms found is larger whenusing combined techniques.In future work we are planning to implementa more principled way of combining syntactic-co-occurrences and nearest neighbours.
The methodand results presented here sufficed to support our in-tuitions, but we believe that more convincing num-bers could be attained when fully exploiting the prin-ciple.
Since the method uses a combination of la-belled and unlabelled data (although in our casethe labelling is the result of the same unsupervisedmethod and not of manual annotation), we planto consult the literature on co-training (Blum andMitchell, 1998).
Also, instead of expanding thesyntactic co-occurrences of words with their nearestneighbours we could expand them with the syntacticco-occurrences of their nearest neighbours to arriveat more uniform data.
Lastly, the technique allowsfor iteration.
We could measure the performance atseveral iterations.AcknowledgementsThe research leading to these results has receivedfunding from the EU FP7 programme (FP7/2007-2013) under grant agreement nr 216594 (CLASSICproject: www.classic-project.org) and from NWO,the Dutch Organisation for Scientific Research in theframework of the research program for InteractiveMultimedia Information eXtraction, IMIX.52ReferencesE.
Alfonseca and S. Manandhar.
2002.
Extending a lexi-cal ontology by a combination of distributional seman-tics signatures.
In Proceedings of EKAW.C.
Biemann, S. Bordag, and U. Quasthoff.
2004.
Auto-matic acquisition of paradigmatic relations using iter-ated co-occurrences.
In Proceedings of LREC.A.
Blum and T. Mitchell.
1998.
Combining labeled andunlabeled data with co-training.
In Proceedings of the1998 conference on computational learning theory.K.W.
Church and P. Hanks.
1989.
Word associationnorms, mutual information and lexicography.
Pro-ceedings of the Annual Conference of the Associationof Computational Linguistics (ACL).J.R.
Curran and M. Moens.
2002.
Improvements in auto-matic thesaurus extraction.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, EMNLP, pages 222?229.J.R.
Curran.
2003.
From Distributional to Semantic Sim-ilarity.
Ph.D. thesis, University of Edinburgh.I.
Dagan, L. Lee, and F. Pereira.
1999.
Similarity-basedmodels of word cooccurrence probabilities.
MachineLearning, 34(1-3):43?69.P.
Edmonds.
1997.
Choosing the word most typical incontext using a lexical co-occurrence network.
In Pro-ceedings of the European chapter of the Associationfor Computational Linguistics, pages 507?509.C.
Fellbaum.
1998.
WordNet, an electronic lexicaldatabase.
MIT Press.G.
Grefenstette.
1994.
Corpus-derived first-, second-,and third-order word affinities.
In Proceedings of Eu-ralex.Z.S.
Harris.
1968.
Mathematical structures of language.Wiley.L.
Lee.
1999.
Measures of distributional similarity.
In37th Annual Meeting of the Association for Computa-tional Linguistics (ACL).B.
Lemaire and G. Denhire.
2006.
Effects of high-orderco-occurrences on word semantic similarities.
CurrentPsychology Letters - Behaviour, Brain and Cognition,18(1).D.
Lin.
1998a.
Automatic retrieval and clustering of sim-ilar words.
In Proceedings of COLING/ACL.D.
Lin.
1998b.
An information-theoretic definition ofsimilarity.
In Proceedings of the 15th InternationalConference on Machine Learning.M.
Moortgat, I. Schuurman, and T. van der Wouden.2000.
CGN syntactische annotatie.
Internal ProjectReport Corpus Gesproken Nederlands, available fromhttp://lands.let.kun.nl/cgn.R.J.F.
Ordelman.
2002.
Twente nieuws corpus (TwNC).Parlevink Language Techonology Group.
Universityof Twente.P.
Resnik.
1993.
Selection and information.
Unpub-lished doctoral thesis, University of Pennsylvania.H.
Schu?tze and M. Walsh.
2008.
A graph-theoreticmodel of lexical syntactic acquisition.
In Proceedingsof EMNLP.A.
Tversky and I. Gati, 1978.
Cognition and Categorisa-tion, chapter Studies of similarity, pages 81?98.
Erl-baum.L.
van der Plas and G. Bouma.
2005.
Syntactic contextsfor finding semantically similar words.
In Proceed-ings of Computational Linguistics in the Netherlands(CLIN).L.
van der Plas.
2008.
Automatic lexico-semantic acqui-sition for question answering.
Ph.D. thesis, Universityof Groningen.G.
van Noord.
2006.
At last parsing is now operational.In Actes de la 13eme Conference sur le Traitement Au-tomatique des Langues Naturelles.P.
Vossen.
1998.
EuroWordNet a multilingual databasewith lexical semantic networks.J.
Weeds and W. Weir.
2005.
Co-occurrence retrieval: Aflexible framework for lexical distributional similarity.Computational Linguistics, 31(4):439?475.J.
Weeds.
2003.
Measures and Applications of LexicalDistributional Similarity.
Ph.D. thesis, University ofSussex.D.
Widdows.
2004.
Geometry and Meaning.
Center forthe Study of Language and Information/SRI.Z.
Wu and M. Palmer.
1994.
Verb semantics and lexicalselection.
In Proceedings of the Annual Meeting of theAssociation for Computational Linguistics (ACL).G.K.
Zipf.
1949.
Human behavior and the principle ofthe least effort.
Addison-Wesley.53
