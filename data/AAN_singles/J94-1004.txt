An Alternative Conception ofTree-Adjoining DerivationYves Schabes*Mitsubishi Electric Research LaboratoryStuart M. Shieber tHarvard UniversityThe precise formulation of derivation for tree-adjoining grammars has important ramificationsfor a wide variety of uses of the formalism, from syntactic analysis to semantic interpretation a dstatistical language modeling.
We argue that the definition of tree-adjoining derivation must bereformulated in order to manifest the proper linguistic dependencies n derivations.
The particularproposal is both precisely characterizable through adefinition of TAG derivations as equivalenceclasses of ordered erivation trees, and computationally operational, by virtue of a compilationto linear indexed grammars together with an efficient algorithm for recognition and parsingaccording to the compiled grammar.1.
IntroductionIn a context-free grammar, the derivation of a string in the rewriting sense can be cap-tured in a single canonical tree structure that abstracts all possible derivation orders.As it turns out, this derivation tree also corresponds exactly to the hierarchical structurethat the derivation imposes on the string, the derived tree structure of the string.
Theformalism of tree-adjoining grammars (TAG), on the other hand, decouples these twonotions of derivation tree and derived tree.
Intuitively, the derivation tree is a morefinely grained structure than the derived tree, and as such can serve as a substrateon which to pursue further analysis of the string.
This intuitive possibility is mademanifest in several ways.
Fine-grained syntactic analysis can be pursued by imposingon the derivation tree further combinatorial constraints, for instance, selective adjoin-ing constraints or equational constraints over feature structures.
Statistical analysiscan be explored through the specification of derivational probabilities as formalizedin stochastic tree-adjoining grammars.
Semantic analysis can be overlaid through thesynchronous derivations of two TAGs.All of these methods rely on the derivation tree as the source of the importantprimitive relationships among trees.
The decoupling of derivation trees from derivedtrees thus makes possible a more flexible ability to pursue these types of analyses.
Atthe same time, the exact definition of derivation becomes of paramount importance.In this paper, we argue that previous definitions of tree-adjoining derivation have nottaken full advantage of this decoupling, and are not as appropriate as they might befor the kind of further analysis that tree-adjoining analyses could make possible.
Inparticular, the standard efinition of derivation, attributable to Vijay-Shanker (1987),?
Cambridge, MA 02139t Division of Applied Sciences, Cambridge, MA 02138(~) 1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 1requires that auxiliary trees be adjoined at distinct nodes in elementary trees.
However,in certain cases, especially cases characterized as linguistic modification, it is moreappropriate to allow multiple adjunctions at a single node.In this paper we propose a redefinition of TAG derivation along these lines,whereby multiple auxiliary trees of modification can be adjoined at a single node,whereas only a single auxiliary tree of predication can.
The redefinition constitutes anew definition of derivation for TAG that we will refer to as extended derivation.
Forsuch a redefinition to be serviceable, however, it is necessary that it be both preciseand operational.
In service of the former, we provide a formal definition of extendedderivation using a new approach to representing derivations as equivalence classes ofordered derivation trees.
With respect o the latter, we provide a method of compi-lation of TAGs into corresponding linear indexed grammars  (LIG), which makes thederivation structure explicit; and show how the generated LIG can drive a parsingalgorithm that recovers, either implicitly or explicitly, the extended erivations of thestring.The paper is organized as follows.
First we review Vijay-Shanker's standard defi-nition of TAG derivation and introduce the motivation for extended erivations.
Thenwe present he extended notion of derivation and its formal definition.
The originalcompilation of TAGs to LIGs provided by Vijay-Shanker and Weir and our variant forextended erivations are both described.
Finally, we discuss a parsing algorithm forTAG that operates by a variant of Earley parsing on the corresponding LIG.
The setof extended erivations can subsequently be recovered from the set of Earley itemsgenerated by the algorithm.
The resultant algorithm is further modif ied so as to buildan explicit derivation tree incrementally as parsing proceeds; this modification, whichis a novel result in its own right, allows the parsing algorithm to be used by systemsthat require incremental processing with respect o tree-adjoining rammars.2.
The Standard Definition of DerivationTo exemplify the distinction between standard and extended derivations, we exhibitthe TAG of Figure 1.1 This grammar  derives some simple noun phrases such as"roasted red pepper"  and "baked red potato."
The former, for instance, is associatedwith the derived tree in Figure 2(a).
The tree can be viewed as being derived in twoways: 2Dependent: The auxiliary tree,,flro is adjoined at the root node (address C) 3 of fire.The resultant ree is adjoined at the N node (address 1) of initial tree ape.This derivation is depicted as the derivation tree in Figure 3(a).Independent: The auxiliary trees flro and fire are adjoined at the N node (address1) of the initial tree ape.
This derivation is depicted as the derivation treein Figure 3(b).1 Here and elsewhere, we conventionally use the Greek letter c~ and its subscripted and primed variantsfor initial trees, fl and its variants for auxiliary trees, and ~, and its variants for elementary trees ingeneral.
The foot node of an auxiliary tree is marked with an asterisk ('*').2 We ignore here the possibility of another dependent derivation wherein adjunction occurs at the footnode of an auxiliary tree.
Because this introduces yet another systematic ambiguity, it is typicallydisallowed by stipulation in the literature on linguistic analyses using TAGs.3 The address of a node in a tree is taken to be its Gorn number, that sequence of integers pecifyingwhich branches to traverse in order starting from the root of the tree to reach the node.
The address ofthe root of the tree is therefore the empty sequence, notated ?.
See the appendix for a more completediscussion of notation.92Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationNP NPL IN NIpotato pepperN NAdj N* Adj N*I Iroasted redN /NAdj N*Ibaked%0) (%) (fl ro ) (t~re )Figure 1A sample tree-adjoining grammar.NPNAdj Nroasted Adj Nf Ired pepperNPLN /NAdj Nred Adj NIroasted pepper(a) (b)Figure 2Two trees derived by the grammar of Figure 1.o~ pe1 I~rot~ pe J~~ro ge(a) (b)Figure 3Derivation trees for the derived tree of Figure 2(a) according to the grammar of Figure 1.93Computational Linguistics Volume 20, Number 1In the independent derivation, two trees are separately adjoined at one and the samenode in the initial tree.
In the dependent derivation, on the other hand, one auxiliarytree is adjoined to the other, the latter only being adjoined to the initial tree.
We willuse this informal terminology uniformly in the sequel to distinguish the two generaltopologies of derivation trees.The standard efinition of derivation, as codified by Vijay-Shanker, restricts deriva-tions so that two adjunctions cannot occur at the same node in the same elementary tree.
Thedependent otion of derivation (Figure 3(a)) is therefore the only sanctioned derivationfor the desired tree in Figure 2(a); the independent derivation (Figure 3(b)) is disal-lowed.
Vijay-Shanker's definition is appropriate because for any independent deriva-tion, there is a dependent derivation of the same derived tree.
This can be easily seenin that any adjunction of f12 at a node at which an adjunction of fll occurs could insteadbe replaced by an adjunction of f12 at the root of ill.The advantage of this standard efinition of derivation is that a derivation tree inthis normal form unambiguously specifies a derived tree.
The independent derivationtree, on the other hand, is ambiguous as to the derived tree it specifies in that anotion of precedence of the adjunctions at the same node is unspecified, but crucial tothe derived tree specified.
This follows from the fact that the independent derivationtree is symmetric with respect o the roles of the two auxiliary trees (by inspection),whereas the derived tree is not.
By symmetry, therefore, it must be the case that thesame independent derivation tree specifies the alternative derived tree in Figure 2(b).3.
Motivation for an Extended Definition of DerivationIn the absence of some further interpretation f the derivation tree nothing hinges onthe choice of derivation definition, so that the standard efinition disallowing inde-pendent derivations i as reasonable as any other.
However, tree-adjoining grammarsare almost universally extended with augmentations that make the issue apposite.We discuss three such variations here, all of which argue for the use of independentderivations under certain circumstances.
43.1 Adding Adjoining ConstraintsAlready in very early work on tree-adjoining grammars (Joshi, Levy, and Takahashi1975) constraints were allowed to be specified as to whether a particular auxiliarytree may or may not be adjoined at a particular node in a particular tree.
The ideais formulated in its modern variant as selective-adjoining constraints (Vijay-Shanker andJoshi 1985).
As an application of this capability, we consider the traditional grammaticalview that directional djuncts can be used only with certain verbs.
5This would account4 The formulation of derivation for tree-adjoining grammars i also of significance for other grammaticalformalisms based on weaker forms of adjunction such as lexicalized context-free grammar (Schabesand Waters 1993a) and its stochastic extension (Schabes and Waters 1993b), though we do not discussthese arguments here.5 For instance, Quirk, Greenbaum, Leech, and Svartvik (1985, page 517) remark that "direction adjunctsof both goal and source can normally be used only with verbs of motion."
Although the restriction isundoubtedly a semantic one, we will examine the modeling of it in a TAG deriving syntactic trees fortwo reasons.
First, the problematic nature of independent derivation is more easily seen in this way.Second, much of the intuition behind TAG analyses i  based on a tight relationship between syntacticand semantic structure.
Thus, whatever scheme for semantics i to be used with TAGs will requireappropriate derivations to model these data.
For example, an analysis of this phenomenon by adjoiningconstraints on the semantic half of a synchronous TAG would be subject o the identical argument.
SeeSection 3.3.94Yves Schabes and Stuart M. Shieber Tree-Adjoining Derivationfor the felicity distinctions between the following sentences:.
a .b.Brockway walked his Labrador towards the yacht club.# Brockway resembled his Labrador towards the yacht club.This could be modeled by disallowing through selective adjoining constraints headjunction of the elementary tree corresponding to a towards adverbial at the VP nodeof the elementary tree corresponding to the verb resembles.
6 However, the restrictionapplies even with intervening (and otherwise acceptable) adverbials.. a .b.3.
a.b.Brockway walked his Labrador yesterday.Brockway walked his Labrador yesterday towards the yacht club.Brockway resembled his Labrador yesterday.# Brockway resembled his Labrador yesterday towards the yacht club.Under the standard efinition of derivation, there is no direct adjunction in the lattersentence of the towards tree into the resembles tree.
Rather, it is dependently adjoinedat the root of the elementary tree that heads the adverbial yesterday, the latter directlyadjoining into the main verb tree.
To restrict both of the ill-formed sentences, then,a restriction must be placed not only on adjoining the goal adverbial in a resemblescontext, but also in the yesterday adverbial context.
But this constraint is too strong, asit disallows entence (2b) above as well.The problem is that the standard erivation does not correctly reflect the syn-tactic relation between the adverbial modifier and the phrase it modifies when thereare multiple modifications in a single clause.
In such a case, each of the adverbialsindependently modifies the verb, and this should be reflected in their independentadjunction at the same point.
But this is specifically disallowed in a standard eriva-tion.Another example along the same lines follows from the requirement that tenseas manifested in a verb group be consistent with temporal adjuncts.
For instance,consider the following examples:4. a. Brockwayb.
# Brockway5.
a.
# Brockwayb.
Brockwaywalked his Labrador yesterday.will walk his Labrador yesterday.walked his Labrador tomorrow.will walk his Labrador tomorrow.Again, the relationship is independent of other intervening adjuncts.6.
a. Brockwayb.
# Brockway7.
a.
# Brockwayb.
Brockwaywalked his Labrador towards the yacht club yesterday.will walk his Labrador towards the yacht club yesterday.walked his Labrador towards the yacht club tomorrow.will walk his Labrador towards the yacht club tomorrow.It is important to note that these arguments apply specifically to auxiliary trees thatcorrespond to a modification relationship.
Auxiliary trees are used in TAG typically6 Whether the adjunction ccurs at the VP node or the S node is immaterial to the argument.95Computational Linguistics Volume 20, Number 1for predication relations as well, 7 as in the case of raising and sentential complementconstructions, s Consider the following sentences.
(The brackets mark the leaves of thepertinent rees to be combined by adjunction in the assumed analysis.).
a .b.9.
a.b.10.
a.b.11.
a.b.Brockway assumed that Harrison wanted to walk his Labrador.\[Brockway assumed that\] \[Harrison wanted\] \[to walk his Labrador\]Brockway wanted to try to walk his Labrador.\[Brockway wanted\] \[to try\] \[to walk his Labrador\]Harrison wanted Brockway tried to walk his Labrador.\[Harrison wanted\] \[Brockway tried\] \[to walk his Labrador\]Harrison wanted to assume that Brockway walked his Labrador.\[Harrison wanted\] \[to assume that\] \[Brockway walked his Labrador\]Assume (following, for instance, the analysis of Kroch and Joshi \[1985\]) that the treesassociated with the various forms of the verbs try, want,  and assume all take senten-tial complements, certain of which are tensed with overt subjects and others untensedwith empty subjects.
The auxiliary trees for these verbs specify by adjoining constraintswhich type of sentential complement they take: assume requires tensed complements,want  and try untensed.
Under this analysis the auxiliary trees must not be allowed toindependently adjoin at the same node.
For instance, if trees corresponding to "Harri-son wanted" and "Brockway tried" (which both require untensed complements) wereboth adjoined at the root of the tree for "to walk his Labrador," the selective adjoin-ing constraints would be satisfied, yet the generated sentence (10a) is ungrammatical.Conversely, under independent adjunction, sentence (11a) would be deemed ungram-matical, although it is in fact grammatical.
Thus, the case of predicative trees is entirelyunlike that of modifier trees.
Here, the standard notion of derivation is exactly whatis needed as far as interpretation of adjoining constraints i concerned.An alternative would be to modify the way in which adjoining constraints areupdated upon adjunction.
If after adjoining a modifier tree at a node, the adjoiningconstraints of the original node, rather than those of the root and foot of the modifiertree, are manifest in the corresponding nodes in the derived tree, the adjoining con-straints would propagate appropriately to handle the examples above.
This alternativeleads, however, to a formalism for which derivation trees are no longer context-free,with concomitant difficulties in designing parsing algorithms.
Instead, the extendeddefinition of derivation effectively allows use of a Kleene-* in the "grammar" of deriva-tion trees.Adjoining constraints can also be implemented using feature structure quations(Vijay-Shanker and Joshi 1988).
It is possible that judicious use of such techniquesmight prevent he particular problems noted here.
Such an encoding of a solutionrequires consideration of constraints that pass among many trees just to limit the co-occurrence of a pair of trees.
However, it more closely follows the spirit of TAGs tostate such intuitively local limitations locally.7 We use the term 'predication' in its logical sense, that is, for auxiliary trees that serve as logicalpredicates over the trees into which they adjoin, in contrast to the term's linguistic sub-sense in whichthe argument of the predicate is a linguistic subject.8 The distinction between predicative and modifier trees has been proposed previously for purelylinguistic reasons by Kroch (1989), who refers to them as complement and athematic trees, respectively.The arguments presented here can be seen as providing further evidence for differentiating the twokinds of auxiliary trees.
A precursor to this idea can perhaps be seen in the distinction betweenrepeatable and nonrepeatable adjunction in the formalism of string adjunct grammars, a precursor ofTAGs (Joshi, Kosaraju, and Yamada 1972b, pages 253-254).96Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationIn summary, the interpretation of adjoining constraints in TAG is sensitive to theparticular notion of derivation that is used.
Therefore, it can be used as a litmustest for an appropriate definition of derivation.
As such, it argues for a nonstandardindependent otion of derivation for modifier auxiliary trees and a standard ependentnotion for predicative trees.3.2 Adding Statistical ParametersIn a similar vein, the statistical parameters of a stochastic lexicalized TAG (SLTAG)(Resnik 1992; Schabes 1992) specify the probability of adjunction of a given auxiliarytree at a specific node in another tree.
This specification may again be interpretedwith regard to differing derivations, obviously with differing impact on the resultingprobabilities assigned to derivation trees.
(In the extreme case, a constraint prohibitingadjoining corresponds to a zero probability in an SLTAG.
The relation to the argumentin the previous section follows thereby.)
Consider a case in which linguistic modifi-cation of noun phrases by adjectives is modeled by adjunction of a modifying tree.Under the standard definition of derivation, multiple modifications of a single NPwould lead to dependent adjunctions in which a first modifier adjoins at the root ofa second.
As an example, we consider again .the grammar given in Figure 1, whichadmits of derivations for the strings "baked red potato" and "baked red pepper.
"Specifying adjunction probabilities on standard derivations, the distinction betweenthe overall probabilities for these two strings depends olely on the adjunction proba-bilities of fire (the tree for red) into ~po and c~p?
(those for potato and pepper, respectively),as the tree fib for the word baked is adjoined in both cases at the root of fire in bothstandard erivations.
In the extended erivations, on the other hand, both modifyingtrees are adjoined independently into the noun trees.
Thus, the overall probabilitiesare determined as well by the probabilities of adjunction of the trees for baked into thenominal trees.
It seems intuitively plausible that the most important relationships tocharacterize statistically are those between modifier and modified, rather than betweentwo modifiers.
9 In the case at hand, the fact that one typically refers to the processof cooking potatoes as "baking," whereas the appropriate term for the correspondingcooking process applied to peppers is "roasting," would be more determining of theexpected overall probabilities.Note again that the distinction between modifier and predicative trees is important.The standard efinition of derivation is entirely appropriate for adjunction probabili-ties for predicative trees, but not for modifier trees.3.3 Adding SemanticsFinally, the formation of synchronous TAGs has been proposed to allow use of TAGsin semantic interpretation, atural language generation, and machine translation.
Inprevious work (Shieber and Schabes 1990), the definition of synchronous TAG deriva-tion is given in a manner that requires multiple adjunctions at a single node.
The needfor such derivations follows from the fact that synchronous derivations are intendedto model semantic relationships.
In cases of multiple adjunction of modifier trees at9 Intuition is an appropriate guide in the design of the SLTAG framework, as the idea is to set up alinguistically plausible infrastructure on top of which a lexically based statistical model can be built.
Inaddition, suggestive (though certainly not conclusive) evidence along these lines can be gleaned fromcorpora analyses.
For instance, in a simple experiment in which medium frequency triples of exactlythe discussed form "(adjective) (adjective) (noun)" were examined, the mean mutual informationbetween the first adjective and the noun was found to be larger than that between the two adjectives.The statistical assumptions behind this particular experiment do not allow very robust conclusions tobe drawn, and more work is needed along these lines.97Computational Linguistics Volume 20, Number 1a single node, the appropriate semantic relationships comprise separate modificationsrather than cascaded ones, and this is reflected in the definition of synchronous TAGderivation.
1?
Because of this, a parser for synchronous TAGs must recover, at leastimplicitly, the extended erivations of TAG-derived trees.
Shieber (in press) providesa more complete discussion of the relationship between synchronous TAGs and theextended efinition of derivation with special emphasis on the ramifications for formalexpressivity.Note that the independence of the adjunction of modifiers in the syntax does notimply that semantically there is no precedence or scoping relation between them.
Asexemplified in Figure 5, the derived tree generated by multiple independent adjunc-tions at a single node still manifests nesting relationships among the adjoined trees.This fact may be used to advantage in the semantic half of a synchronous tree-adjoininggrammar to specify the semantic distinction between, for example, the following twosentences: u12.
a.b.Brockway ran over his polo mallet wice intentionally.Brockway ran over his polo mallet intentionally twice.We hope to address this issue in greater detail in future work on synchronous tree-adjoining rammars.3.4 Desired Properties of Extended DerivationsWe have presented several arguments hat the standard notion of derivation does notallow for an appropriate specification of dependencies to be captured.
An extendednotion of derivation is needed that1.2.3.4.differentiates predicative and modifier auxiliary trees;requires dependent derivations for predicative trees;allows independent derivations for modifier trees; andunambiguously and nonredundantly specifies a derived tree.Furthermore, following from considerations of the role of modifier trees in a grammaras essentially optional and freely applicable lements, we would like the followingcriterion to hold of extended erivations:.
If a node can be modified at all, it can be modified any number of times,including zero times.Recall that a derivation tree (as traditionally conceived) is a tree with unorderedarcs where each node is labeled by an elementary tree of a TAG and each arc is labeledby a tree address pecifying a node in the parent ree.
In a standard erivation treeno two sibling arcs can be labeled with the same address.
In an extended erivationtree, however, the condition is relaxed: No two sibling arcs to predicative trees can be10 The importance of the distinction between predicative and modifier trees with respect to howderivations are defined was not appreciated in the earlier work; derivations were taken to be of theindependent variety in all cases.
In future work, we plan to remedy this flaw.11 We are indebted to an anonymous reviewer of an earlier version of this paper for raising this issuecrisply through examples similar to those given here.98Yves Schabes and Stuart M. Shieber Tree-Adjoining Derivationlabeled with the same address.
Thus, for any given address there can be at most onepredicative tree and several modifier trees adjoined at that node.
As we have seen, thisrelaxed definition violates the fourth desideratum above; for instance, the derivationtree in Figure 3(b) ambiguously specifies both derived trees in Figure 2.
In the nextsection we provide a formal definition of extended erivations that satisfies all of thecriteria above.4.
Formal Definition of Extended DerivationsIn this section we introduce a new framework for describing TAG derivation trees thatallows for a natural expression of both standard and extended erivations, and makesavailable ven more fine-grained restrictions on derivation trees.
First, we define or-dered derivation trees and show that they unambiguously but redundantly specifyderivations.
12 We characterize the redundant trees as those related by a sibling swap-ping operation.
Derivation trees proper are then taken to be the equivalence classes ofordered erivation trees in which the equivalence r lation is generated by the siblingswapping.
By limiting the underlying set of ordered erivation trees in various ways,Vijay-Shanker's definition of derivation tree, a precise form of the extended efinition,and many other definitions of derivation can be characterized in this way.4.1 Ordered Derivation TreesOrdered derivation trees, like the traditional derivation trees, are trees with" nodeslabeled by elementary trees where each arc is labeled with an address in the tree forthe parent node of the arc.
However, the arcs are taken to be ordered with respect oeach other.An ordered derivation tree is well-formed if for each of its arcs, linking parentnode labeled 3  `to child node labeled 3` ~ and itself labeled with address t, the tree 3"is an auxiliary tree that can be adjoined at the node t in the tree 3'.
(Alternatively, ifsubstitution is allowed, 3"~ may be an initial tree that can be substituted at the node tin 3 .` Later definitions ignore this possibility, but are easily generalized.
)We define the function/~ from ordered erivation trees to the derived trees theyspecify, according to the following recursive definition:/9(D) = {3  ` if D is a trivial tree of one node labeled with the elementary tree 3'3` \ [ /9 (D l ) / t1 ,79(D2) / t2 , .
.
.
,  ~D(Dk) /tk\]if D is a tree with root node labeled with the elementary tree 3  `and with k child subtrees D1,..., Dkwhose arcs are labeled with addresses t l , .
.
.
,  tk.Here 3`\[A1/h,...,Ak/tk\] specifies the simultaneous adjunction of trees A1 through Akat tl through tk, respectively, in 3'.
It is defined as the iterative adjunction of the Ai inorder at their respective addresses, with appropriate updating of the tree addresses ofany later adjunction to reflect he effect of earlier adjunctions that occur at addressesdominating the address of the later adjunction.12 Historical precedent for independent derivation and the associated ordered derivation trees can befound in the derivation trees postulated for string adjunct grammars (Joshi, Kosaraju, and Yamada1972a, 99-100).
In this system, siblings in derivation trees are viewed as totally, not partially, ordered.The systematic ambiguity introduced thereby is eliminated by stipulating that the sibling order beconsistent with an arbitrary ordering on adjunction sites.99Computational Linguistics Volume 20, Number 14.2 Derivation TreesIt is easy to see that the derived tree specified by a given ordered derivation tree isunchanged if adjacent siblings whose arcs are labeled with different tree addresses areswapped.
(This is not true of adjacent siblings whose arcs are labeled with the sameaddress.)
That is, if t ~ t' then 3,\[... ,Aft, B/t',...\] = 7\[..., B/t', Aft,...\].
A graphical"proof" of this intuitive fact is given in Figure 4.
A formal proof, although tedious andunenlightening, is possible as well.
We provide it in an appendix, primarily becausethe definitional aspects of the TAG formulation may be of some interest.This fact about the swapping of adjacent siblings shows that ordered derivationtrees possess an inherent redundancy.
The order of adjacent sibling subtrees labeledwith different tree addresses i immaterial.
Consequently, we can define true derivationtrees to be the equivalence classes of the base set of ordered erivation trees under theequivalence r lation generated by the sibling subtree swapping operation above.
Thisis a well-formed efinition by virtue of the proposition argued informally above.This definition generalizes the traditional definition in not restricting the tree ad-dress labels in any way.
It therefore satisfies criterion (3) of Section 3.4.
Furthermore, byvirtue of the explicit quotient with respect to sibling swapping, a derivation tree underthis definition unambiguously and nonredundantly specifies a derived tree (criterion4).
It does not, however, differentiate predicative from modifier trees (criterion (1)), norcan it therefore mandate dependent derivations for predicative trees (criterion (2)).This general approach can, however, be specialized to correspond to several pre-vious definitions of derivation tree.
For instance, if we further restrict he base setof ordered derivation trees so that no two siblings are labeled with the same treeaddress, then the equivalence r lation over these ordered derivation trees allows forfull reordering of all siblings.
Clearly, these equivalence classes are isomorphic to theunordered trees, and we have reconstructed Vijay-Shanker's standard efinition ofderivation tree.If we instead restrict ordered erivation trees o that no two siblings correspondingto predicative trees are labeled with the same tree address, then we have reconstructeda version of the extended efinition argued for in this paper.
Under this restriction,criteria (1) and (2) are satisfied, while maintaining (3) and (4).By careful selection of other constraints on the base set, other linguistic restrictionsmight be imposed on derivation trees, still using the same definition of derivation treesas equivalence classes over ordered erivation trees.
In the next section, we show thatthe definition of the previous paragraph should be further estricted to disallow thereordering of predicative and modifier trees.
We also describe other potential linguisticapplications of the ability to finely control the notion of derivation through the use ofordered erivation trees.4.3 Further Restrictions on Extended DerivationsThe extended efinition of derivation tree given in the previous section effectivelyspecifies the output derived tree by adding a partial ordering on sibling arcs thatcorrespond to modifier trees adjoined at the same address.
All other arcs are effectivelyunordered (in the sense that all relative orderings of them exist in the equivalenceclass).Assume that in a given tree ~, at a particular address t,the k modifier trees #1,.. .
,  ~kare directly adjoined in that order.
Associated with the subtrees rooted at the k ele-mentary auxiliary trees in this derivation are k derived auxiliary trees (A1,...,Ak,respectively).
The derived tree specified by this derivation tree, according to the def-inition of ~ given above, would have the derived tree A1 directly below A2 and soforth, with Ak at the top.
Now suppose that in addition, a predicative tree 7r is also100Yves Schabes and Stuart M. Shieber Tree-Adjoining Derivation(a)(b)(c)Figure 4A graphical proof of the irrelevance of adjacent sibling swapping.These diagrams how the effect of performing two adjunctions (of auxiliary trees depicted,one as dark-shaded and one light-shaded), presumed to be specified by adjacent siblings in anordered derivation tree.
The adjunctions are to occur at two addresses (referred to in thiscaption as t and t', respectively).
The two addresses must be such that either (a) they aredistinct but neither dominates the other, (b) t dominates t' (or vice versa), or (c) they areidentical.
In case (a) the diagram shows that either order of adjunction yields the samederived tree.
Adjunction at t and then t' corresponds to the upper arrows, adjunction at t' andthen t the lower arrows.
Similarly, in case (b), adjunction at t followed by adjunction at anappropriately updated t' yields the same result as adjunction first at t' and then at t. Clearly,adjunctions occurring before these two or after do not affect the interchangeability.
Thus, iftwo adjacent siblings in a derivation tree specify adjunctions at distinct addresses t and t', theadjunctions can occur in either order.
Diagram (c) demonstrates that this is not the case whent and t' are the same.101Computational Linguistics Volume 20, Number 1Y"'" \]/1 "'" \]'/k 7~ "'" /A~ ~A AA(a) (b) ?/?-..Figure 5Schematic extended erivation tree and associated derived tree.In a derived tree, the predicative tree adjoined at an address t is required to follow allmodifier trees adjoined at the same address, as in (a).
The derived tree therefore appears asdepicted in (b) with the predicative tree outermost.adjoined at address t. It must be ordered with respect o the #i in the derivation tree,and its relative order determines where in the bottom-to-top order in the derived treethe tree A,~ associated with the subderivation rooted at 7r goes.The question that we raise here is whether all k + 1 possible placements of the tree~r relative to the #i are linguistically reasonable.
We might allow all k + 1 orderings(as in the definition of the previous section), or we might restrict hem by requiring,say, that the predicative tree always be adjoined before, or perhaps after, any modifiertrees at a given address.
We emphasize that this is a linguistic question, in the sensethat the definition of extended erivation is well formed whatever decision is madeon this question.Henceforth, we will assume that predicative trees are always adjoined after anymodifier trees at the same address, so that they appear above the modifier trees in thederived tree.
We call this "outermost predication" because a predicative tree appearswrapped around the outside of the modifier trees adjoined at the same address.
(SeeFigure 5.)
If we were to mandate innermost predication, in which a predicative treeis always adjoined before the modifier trees at the same address, the predicative treewould appear within all of the modifier trees, innermost in the derived tree.Linguistically, the outermost method specifies that if both a predicative tree and amodifier tree are adjoined at a single node, then the predicative tree attaches higherthan the modifier tree; in terms of the derived tree, it is as if the predicative treewere adjoined at the root of the modifier tree.
This accords with the semantic intuitionthat in such a case (for English at least), the modifier is modifying the original tree,not the predicative one.
(The alternate "reading," in which the modifier modifies thepredicative tree, is still obtainable under an outermost-predication standard by havingthe modifier auxiliary tree adjoin dependently at the root node of the predicative tree.
)102Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationIn contrast, the innermost-predication method specifies that the modifier tree attacheshigher, as if the modifier tree adjoined at the root of the predicative tree and wastherefore modifying the predicative tree, contra semantic intuitions.For this reason, we specify that outermost predication is mandated.
This is easilydone by further limiting the base set of ordered derivation trees to those in whichpredicative trees are ordered after modifier tree siblings.
(From a technical standpoint, by the way, the outermost-predication method hasthe advantage that it requires no changes to the parsing rules to be presented later,but only a single addition.
The innermost-predication method induces some subtleinteractions between the original parsing rules and the additional one, necessitatinga much more complicated set of modifications to the original algorithm.
In fact, thecomplexities in generating such an algorithm constituted the precipitating factor thatled us to revise our original innermost-predication attempt at redefining tree-adjoiningderivation.
The linguistic argument, although commanding, became clear to us onlylater.
)Another possibility, which we mention but do not pursue here, is to allow forlanguage-particular precedence constraints to restrict he possible orderings of deriva-tion-tree siblings, in a manner similar to the linear precedence constraints of ID/LPformat (Gazdar, Klein, Pullum, and Sag 1985) but at the level of derivation trees.These might be interpreted as hard constraints or soft orderings depending on theapplication.
This more fine-grained approach to the issue of ordering has several ap-plications.
Soft orderings might be used to account for ordering preferences amongmodifiers, such as the default ordering of English adjectives that accounts for the typ-ical preference for "a large red ball" over "?
a red large ball" and the typical orderingof temporal before spatial adverbial phrases in German.Similarly, hard constraints might allow for the handling of an apparent counter-example to the outermost-predication rule.
13 One natural analysis of the sentence13.
At what time did Brockway say Harrison arrived?would involve adjunction of a predicative tree for the phrase "did Brockway say" atthe root of the tree for "Harrison arrived."
A Wh modifier tree "at what time" mustbe adjoined in as well.
The example question is ambiguous, of course, as to whetherit questions the time of the saying or of the arriving.
In the former case, the modifiertree presumably adjoins at the root of the predicative tree for "did Brockway say" thatit modifies.
In the latter case, which is of primary interest here, it must adjoin at theroot of the tree for "Harrison arrived."
Thus, both trees would be adjoined at the sameaddress, and the outermost-predication rule would predict he derived sentence to be"Did Brockway say at what time Harrison arrived."
To get around this problem, wemight specify hard ordering constraints for English that place all Wh modifier treesafter all predicative trees, which in turn come after all non-Wh modifier trees.
Thiswould place the Wh modifier outermost as required.Although we find this extra flexibility to be an attractive aspect of this approach,we stay with the more stringent outermost-predication restriction in the material thatfollows.13 Other solutions are possible that do not require extended erivations or linear precedence constraints.For instance, we might  postulate an elementary tree for the verb arrived that includes a substitutionnode for a fronted adverbial Wh phrase.103Computational Linguistics Volume 20, Number 15.
Compilation of TAGs to Linear Indexed GrammarsIn this section we present a technique for compiling tree-adjoining grammars intolinear indexed grammars uch that the linear indexed grammar makes explicit theextended erivations of the TAG.
This compilation plays two roles.
First, it providesfor a simple proof of the generative quivalence of TAGs under the standard andextended efinitions of derivation, as described at the end of this section.
Second, itcan be used as the basis for a parsing algorithm that recovers the extended erivationsfor strings.
The design of such an algorithm is the topic of Section 6.Linear indexed grammars (LIG) constitute a grammatical framework based, likecontext-free, context-sensitive, and unrestricted rewriting systems, on rewriting stringsof nonterminal nd terminal symbols.
Unlike these systems, linear indexed grammars,like the indexed grammars from which they are restricted, allow stacks of markersymbols, called indices, to be associated with the nonterminal symbols being rewritten.The linear version of the formalism allows the full index information from the parentto be used to specify the index information for only one of the child constituents.Thus, a linear indexed production can be given schematically as:No\[..~o \] --+ Nl\[fll\]..-Ns_l\[fls_l\] Ns\[..~s\] Ns+l\[~s+l\].. "Nk\[flk\]The Ni are nonterminals, the fli.
strings of indices.
The ".." notation stands for theremainder of the stack below the given string of indices.
Note that only one elementon the right-hand side, Ns, inherits the remainder of the stack from the parent.
(Thisschematic rule is intended to be indicative, not definitive.
We ignore issues such asthe optionality of the inherited stack how terminal symbols fit in, and so forth.
Vijay-Shanker and Weir \[1990\] present a complete discussion.
)Vijay-Shanker and Weir (1990) present a way of specifying any TAG as a linearindexed grammar.
The LIG version makes explicit the standard notion of derivationbeing presumed.
Also, the LIG version of a TAG grammar can be used for recognitionand parsing.
Because the LIG formalism is based on augmented rewriting, the parsingalgorithms can be much simpler to understand and easier to modify, and no loss ofgenerality is incurred.
For these reasons, we use the technique in this work.The compilation process that manifests the standard efinition of derivation canbe most easily understood by viewing nodes in a TAG elementary tree as havingboth a top and bottom component, identically marked for nonterminal category, thatdominate (but may not immediately dominate) each other.
(See Figure 6.)
The rewriterules of the corresponding linear indexed grammar capture the immediate dominationbetween a bottom node and its child top nodes directly, and capture the dominationbetween top and bottom parts of the same node by optionally allowing rewriting fromthe top of a node to an appropriate auxiliary tree, and from the foot of the auxiliarytree back to the bottom of the node.
The index stack keeps track of the nodes on whichadjunction has occurred so that the recognition to the left and the right of the footnode will occur under identical assumption of derivation structure.The TAG grammar is encoded as a LIG with two nonterminal symbols t and b cor-responding to the top and bottom components, respectively, of each node.
The stackindices correspond to the individual nodes of the elementary trees of the TAG gram-mar.
Thus, there are as many stack index symbols as there are nodes in the elementarytrees of the grammar, and each such index (i.e., node) corresponds unambiguously toa single address in a single elementary tree.
(In fact, the symbols can be thought of aspairs of an elementary tree identifier and an address within that tree, and our imple-mentation encodes them in just that way.)
The index at the top of the stack corresponds104Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationType 4~ ~-t\[~.
r\]"~i'~ ~  - -~ Type3 / / ~/ Type btnflFigure 6Schematic structure of adjunction with top and bottom of each node separated.7/I 7/2 /7/3Figure 7A stack of indices \[717273\] captures the adjunction history that led to the reaching of the node73 in the parsing process.Parsing of an elementary tree c~ proceeded to node 71 in that tree, at which pointadjunction of the tree containing 72 was pursued by the parser.
When the node 72 wasreached, the tree containing 73 was implicitly adjoined.
Once this latter tree is completelyparsed, the remainder of the tree containing 72 can be parsed from that point, and so on.to the node being rewritten.
Thus, a LIG nonterminal with stack t\[~\] corresponds tothe top component of node 7, and b\[~\]1712~\]3\] corresponds to the bottom component of73- The indices ~h and 7/2 capture the history of adjunctions that are pending comple-tion of the tree in which 73 is a node.
Figure 7 depicts the interpretation of a stack ofindices.In summary, given a tree-adjoining grammar, the following LIG rules are gener-ated:.
Immediate domination dominating foot: For each auxiliary tree node 7 thatdominates the foot node, with children 71,. .
.
,  7s, .
.
.
,  ~n, where 7\]s is thechild that also dominates the foot node, include a productionb\[..,\] --* t\[71\]'"" t\[7s-,\]t\[..71s\]t\[~ls+l\]'" t\[7n\].105Computational Linguistics Volume 20, Number 1..Immediate domination ot including foot: For each elementary tree node ~/that does not dominate a foot node, with children ~/1,..., ~/n, include aproductionb\[,\] --* t \ [ , , \ ] .
.
,  t\[,n\].No adjunction: For each elementary tree node ~/that is not marked forsubstitution or obligatory adjunction, include a productiont\[..,\] b\[..,\]....Start root ofadjunction: For each elementary tree node ~ on which theauxiliary tree fl with root node ~r can be adjoined, include the followingproduction:t\[..,\] --* t\[..,,r\].Start foot ofadjunction: For each elementary tree node ~ on which theauxiliary tree fl with foot node ~//can be adjoined, include the followingproduction:b\[..,,f\] ~ b\[..~/\].Start substitution: For each elementary tree node ~ marked forsubstitution on which the initial tree c~ with root node ?~r can besubstituted, include the productiont\[,\] --* t\[,r\].We will refer to productions generated by Rule i above as Type i productions.
Forexample, Type 3 productions are of the form t\[..~/\] --* b\[..~\].
For further informationconcerning the compilation see Vijay-Shanker and Weir (1990).
For present purposes, itis sufficient o note that the method directly embeds the standard notion of derivationin the rewriting process.
To perform an adjunction, we move (by Rule 4) from thenode adjoined at to the top of the root of the auxiliary tree.
At the root, additionaladjunctions might be performed.
When returning from the foot of the auxiliary treeback to the node where adjunction occurred, rewriting continues at the bottom of thenode (see Rule 5), not the top, so that no more adjunctions can be started at that node.Thus, the dependent nature of predicative adjunction is enforced because only a singleadjunction can occur at any given node.In order to permit extended erivations, we must allow for multiple modifier treeadjunctions at a single node.
There are two natural ways this might be accomplished,as depicted in Figure 8.1.
Modified start foot ofadjunction rule: Allow moving from the bottom of thefoot of a modifier auxiliary tree to the top (rather than the bottom) of thenode at which it adjoined (Figure 8b).2.
Modified start root of adjunction rule: Allow moving from the bottom (ratherthan the top) of a node to the top of the root of a modifier auxiliary tree(Figure 8c).As can be seen from the figures, both of these methods allow recursion at a node,unlike the original method depicted in Figure 8a.
Thus multiple modifier trees areallowed to adjoin at a single node.
Note that since predicative trees fall under theoriginal rules, at most a single predicative tree can be adjoined at a node.
The two106Yves Schabes and Stuart M. Shieber Tree-Adjoining Derivation(a) ~ / ~  predicative /L.S~ eFigure 8Schematic structure of possible predicative and modifier adjunctions with top and bottom ofeach node separated.methods correspond exactly to the innermost- and outermost-predication methodsdiscussed in Section 4.3.
For the reasons described there, the latter is preferred.
TMIn summary, independent derivation structures can be allowed for modifier aux-iliary trees by starting the adjunction process from the bottom, rather than the top ofa node for those trees.
Thus, we split Type 4 LIG productions into two subtypes forpredicative and modifier trees, respectively.4a.4b.Start root of predicative adjunction: For each elementary tree node 7/onwhich the predicative auxiliary tree fl with root node T\]F can be adjoined,include the following production:t\[..,\] ~ t\[..~p?~\].Start root of modifier adjunction: For each elementary tree node ~/on whichthe modifier auxiliary tree fl with root node ~/r can be adjoined, includethe following production:b\[..~/\] ~ t\[.3l~lr \].Once this augmentation has been made, we no longer need to allow for adjunctions atthe root nodes of modifier auxiliary trees, as repeated adjunction is now allowed for14 The more general definition allowing predicative trees to occur anywhere within a sequence ofmodifier adjunctions would be achieved by adding both types of rules.107Computational Linguistics Volume 20, Number 1by the new rule 4b.
Consequently, grammars hould forbid adjunction of a modifiertree fll at the root of a modifier tree f12 except where fll is intended to modify /32directly.This simple modification to the compilation process from TAG to LIG fully spec-ifies the modified notion of derivation.
Note that the extra criterion (5) noted in Sec-tion 3.4 is satisfied by this definition: modifier adjunctions are inherently repeatableand eliminable as the movement through the adjunction "loop" ends up at the samepoint that it begins.
The recognition algorithms for TAG based on this compilation,however, must be adjusted to allow for the new rule types.This compilation makes possible a simple proof of the weak-generative equiva-lence of TAGs under the standard and extended erivations, i  Call the set of languagesgenerable by a TAG under the standard efinition of derivation TALs and under theextended efinition TALe.
Clearly, TALs c TALe since the standard efinition can bemimicked by making all auxiliary trees predicative.
The compilation above providesthe inclusion TALe C LIL, where LIL is the set of linear indexed languages.
The finalinclusion LIL C_ TALs has been shown indirectly by Vijay-Shanker (1987) using em-bedded push-down automata nd modified head grammars as intermediaries.
Fromthese inclusions, we can conclude that TALs = TALe.6.
Recognition and ParsingA recognition algorithm for TAGs can be constructed based on the above translationinto corresponding LIGs as specified by Rules 1 through 6 in the previous ection.
Thealgorithm is not a full recognition algorithm for LIGs, but rather, is tuned for exactlythe types of rules generated as output of this compilation process.
In this section, wepresent the recognition algorithm and modify it to work with the extended erivationcompilation.We will use the following notations in this and later sections.
The symbol P willserve as a variable over the two LIG grammar nonterminals t and b.
The substring ofthe string wl ... Wn being parsed between indices i and j will be notated as wi+t " .
wj,which we take to be the empty string when i is greater than or equal to j.
We will usep, A, and {9 for sequences containing terminals and LIG nonterminals with their stackspecifications.
For instance, F might be t\[rll\]t\[..rl2\]t\[rl3 \].The parsing algorithm can be seen as a tabular parsing method based on deductionof items, as in Earley deduction (Pereira and Warren 1983).
We will so describe it, bypresenting inference rules over items of the form(e\[r/\] --* r ?
A,i , j ,k, l ) .Such items play the role of the items of Earley's algorithm.
Unlike the items of Earley'salgorithm, however, an item of this form does not embed a grammar rule proper; thatis, P\[7/\] --+ pA is not necessarily a rule of the grammar.
Rather, it is what we will calla reduced rule; for reasons described below, the nonterminals in F and A as well asthe nonterminal P\[~/\] record only the top element of each stack of indices.
We will usethe notation P\[~\] --+ pA for the unreduced form of the rule whose reduced form isp\[~/\] --+ pA. For instance, the rule specified by the notation t\[~/1\] --+ t\[712\] might be therule t\[..~l\] --+ t\[..~1~\]2\].
The reader can easily verify that the TAG to LIG compilation issuch that there is a one-to-one correspondence b tween the generated rules and theirreduced form.
Consequently, this notation is well defined.15 We are grateful to K. Vijay-Shanker for bringing this point to our attention.108Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationThe dot in the items is analogous to that found in Earley and LR items as well.
Itserves as a marker for how far recognition has proceeded in identifying the subcon-stituents for this rule.
The indices i, j, k, and l specify the portion of the string Wl .. ?
w~covered by the recognition of the item.
The substring between i and 1 (i.e., wi+ 1 " ' "  Wl )has been recognized, perhaps with a region between j and k where the foot of the treebelow the node ~ has been recognized.
(If the foot node is not dominated by F, wetake the values of j and k to be the dummy value '-'.
)6.1 The Inference RulesIn this section, we specify several inference rules for parsing a LIG generated from aTAG, which we recall in this section.
One explanatory comment is in order, however,before the rules are presented.
The rules of a LIG associate with each constituent anonterminal nd a stack of indices.
It seems natural for a parsing algorithm to maintainthis association by building items that specify for each constituent the full informationof nonterminal nd index stack.
However, this would necessitate storing an unboundedamount of information for each potential constituent, resulting in a parsing algorithmthat is potentially quite inefficient when nondeterminism arises during the parsingprocess, and perhaps noneffective if the grammar is infinitely ambiguous.
Instead, theparse items manipulated by the inference rules that we present do not keep all ofthis information for each constituent.
Rather, the items keep only the single top stackelement for each constituent (in addition to the nonterminal symbol).
This drasticallydecreases the number of possible items and accounts for the polynomial character ofthe resultant algorithm.
16Side conditions make up for some of the loss of information,thereby maintaining correctness.
For instance, the Type 4 Completor ule specifies arelation between ~ and ~/f that takes the place of popping an element off of the stackassociated with ~.
However, the side conditions are strictly weaker than maintainingfull stack information.
Consequently, the algorithm, though correct, does not maintainthe valid prefix property.
See Schabes (1991) for further discussion and alternatives.Scanning and prediction work much as in Earley's original algorithm.?
Scanner:(b\[,\] -* F ?
aA, i,j, k, l>(b\[7/\] -* Fa ?
A, i,j, k, l+  1> a ~- Wl+ 1Note that the only rules that need be considered are those where theparent is a bottom node, as terminal symbols occur on the right-handside only of Type 1 or 2 productions.
Otherwise, the rule is exactly asthat for Earley's algorithm except hat the extra foot indices (j and k) arecarried along.?
Predictor:(P\[~/\] --* F ?
P'\[~\]'\] A, i,j, k, l)(P'\[~/\] -* ?
O, l, - ,  - ,  l) P'\[~'\] ~ @This rule serves to form predictions for any type production in thegrammar, as the variables P and P' range over the values t and b.
In the16 Vijay-Shanker and Weir (1990) first proposed the recording of only the top stack element in order toachieve fficient parsing.
The algorithm they presented is a bottom-up general LIG parsing algorithm.Schabes (1991) sketches a proof of an O(n 6) bound for an Earley-style algorithm for TAG parsing thatis more closely related to the algorithm proposed here.109Computational Linguistics Volume 20, Number 1predicted item, the foot is not dominated by the (empty) recognizedinput, so that the dummy value '-' is used for the foot indices.
Note thatthe predicted item records the reduced form of an unreduced ruleP'\[~/'\] --* (9 of the grammar.Completion of items (moving of the dot from left to right over a nonterminal)breaks up into several cases, depending on which production type is being completed.This is because the addition of the extra indices and the separate interpretations fortop and bottom productions require differing index manipulations to be performed.We will list the various steps, organized by what type of production they participatein the completion of.
.Productions that specify immediate domination (from Rules I and 2) are completedwhenever the top of the child node is fully recognized.?
Type I and 2 Completor:{b\[,1\] --* P?
t \ [ , \ ]A,m, j ' ,k ' , i}  {t\[,\] ~ (9?
,i, j,k,l}(b\[~/1\] --* rt\[,\] ?
A m,j U j', k U k', l}Here, t\[7/\] has been fully recognized as the substring between i and I. Theitem expecting t\[~\] can be completed.
One of the two antecedent i emsmight also dominate the foot node of the tree to which ~/and 71 belong,and would therefore have indices for the foot substring.
The operationsj U j' and k U k' are used to specify whichever of j or j' (and respectivelyfor k or k') contain foot substring indices.
The formal definition of U is asfollows:j i f j '  = -jU j '  = J' i f j  = -j i f j '  = jundefined otherwiseThe remaining rules (3 through 6) are each completed by a particular completioninstance.?
Type 3 Completor:{t\[,\] --* .
b\[~l\], i, - ,  - ,  i} {b\[~/\] --* (9- , i , j ,k , l}{t\[~/\] --* b\[~/\].
,i, j,k,l}This rule is used to complete a prediction that no (predicative)adjunction occurs at node ~/.
Once the part of the string dominated byb\[~/\] has been found, as evidenced by the second antecedent i em, theprediction of no adjunction can be completed.Type 4 Completor:{till --* ?
t\[~/~\], i, --, --, i}{t\[~r\] ~ (9 " ,  i,j, k, l}{b\[~/\] ~ A .
, j,p,q,k}{t\[\] ~ t\[~lr\] " , i,p,q, I}t\[..,\] --* t\[..,~/r\]110Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationHere, an adjunction has been predicted at 7, and the adjoined derivedtree (between t\[~\] and b\[~\]) and the derived material that r\] itselfdominates (below b\[r\]\]) have both been completed.
Thus t\[~\] iscompletely recognized.
Note that the side condition (the unreduced formof the reduced rule in the first antecedent item) is placed merely toguarantee that ~/r is the root node of an adjoinable auxiliary tree.Type 5 Completor:(b\[@ --+ * b\[rl\], i, - ,  - ,  i) (b\[,\] -+ 0 ?
, i , j ,k , l )(b\[*lf\] --+ b\[r\]\] ?
,  i, i, 1,1) b\[..rl~f\] ~ b\[..,\]When adjunction has been performed and recognition up to the footnode ~f has been performed, it is necessary to recognize all the materialunder the foot node.
When that is done, the foot node prediction can becompleted.
Note that it must be possible to have adjoined the auxiliarytree at node r/as specified in the production in the side condition.?
Type 6 Completor:(t\[,\] --~ , t \ [~\ ] , i , - , - , i )  (t\[~r\] --+ O,  , i , - , - , l )(t\[,\] ---+ t \ [ , r \ ] .
, i , - , - , l )  t\[,\] --* t\[rlr\]Completion of the material below the root node ~r of an initial treeallows for the completion of the node at which substitution occurred.The recognition process for a string wl ?
.. Wn starts with some items that serve asaxioms for these inference rules.
For each rule t\[~ls\] --* F where ~s is the root node ofan initial tree whose node is labeled with the start nonterminal, the item (t\[~s\] -~ ?
F,0, -, -, 0) is an axiom.
If from these axioms an item of the form (t\[~s\] --~ P ?
,  0, -, -, n) canbe proved according to the rules of inference above, the string is accepted; otherwiseit is rejected.Alternatively, the axioms can be stated as if there were extra rules S --* t\[r/s\] foreach ~/s a start-nonterminal-labeled root node of an initial tree.
In this case, the axiomsare items of the form (S --~ ?
t\[~s\], 0, - , - ,  0) and the string is accepted upon provingIS --+ t\[~/s\] ?
,  0 , - , - ,  n).
In this case, an extra prediction and completion rule is neededjust for these rules, since the normal rules do not allow S on the left-hand side.
Thispoint is taken up further in Section 6.4.Generation of items can be cached in the standard way for inference-based parsingalgorithms (Shieber 1992); this leads to a tabular or chart-based parsing algorithm.6.2 The Algorithm InvariantThe algorithm maintains an invariant hat holds of all items added to the chart.
Wewill describe the invariant using some additional notational conventions.
Recall thatP\[~\] -+ 1 ~ is the LIG production in the grammar whose reduced form is P\[~\] --+ P. Thenotation F\[7\] where 7 is a sequence of stack symbols (i.e., nodes), specifies the sequenceF with 7 replacing the occurrence of .. in the stack specifications.
For example, if Pis the sequence t\[rll\]t\[..rl2\]t\[~13 \], then F\[3,\] = t\[r\]l\]t\['yrl2\]t\[~3\].
A single LIG derivation stepwill be notated with ~ and its reflexive transitive closure with 3* .11iComputational Linguistics Volume 20, Number 1The invariant specifies that (P\[~\] ~ E ?
A, i,j, k, 1) is in the chart only if 171.
If node ~ dominates the foot node ~f of the tree to which it belongs, thenthere exists a string of stack symbols (i.e., nodes) "y such that(a) P\[~\] --.
PA is a LIG rule in the grammar, where E is theunreduced form of F.(b) F\[Tz/\] o*  ?
Wi+ 1 .
.
w jb \ [v?~f \ ]Wk+I  .
.
.
W l(c) b{Tnr\] o* wj+t...wk2.
If node ~ does not dominate the foot node ~f of the tree to which itbelongs or there is no foot node in the tree, then(a) P\[7/\] --.
PA is a LIG rule in the grammar, where F is theunreduced form of E.(b) F =:k* Wi+I" ' 'W 1(c) j and k are not bound.According to this invariant, for a node ~/s that is the root of an initial tree, the item(t\[z\]s\] --+ P .
,  0,-,- ,  n) is in the chart only if t\[~?s\] ~ E ~* Wl ' ' "  W n. Thus, soundness ofthe algorithm as a recognizer follows.6.3 Modifications for Extended DerivationsExtending the algorithm to allow for the new types of production (specifically, asderived by Rule 4b) requires adding a completion rule for Type 4b productions.
Forthe new type of production, a completion rule of the following form is required:?
Type 4b Completor:?
t\[Zlr\]  i , - , - ,  i)(t\[Zlr \] --* (9 .
,i,j,k l)(b\[, \]  --* A .
,j,p q,k)(b\[z/\] --~ t\[~/~\]., i,p,q, l)b\[..z\]\] --+ t \ [ .
.
,Z l r \ ]In addition to being able to complete Type 4b items, we must also be able tocomplete other items using completed Type 4b items.
This is an issue in particular forcompletor rules that might move their dot over a b\[~\] constituent; in particular, theType 3 and 5 Completors.
However, these rules have been stated so that the antecedentitem with right-hand side b\[~\] already matches Type 4b items.
Furthermore, the generalstatement, including index manipulation is still appropriate in the context of Type 4bproductions.
Thus, no further changes to the recognition inference rules are neededfor this purpose.17 The invariant is not stated as a biconditional because this would require strengthening of theantecedent condition.
The natural strengthening, following the standard for Earley's algorithm, wouldbe to add a requirement that the item be consistent with left context, as(d) 7/s ~*  Wl""  wiP\[7"q\]but this is too strong.
This condition implies that the algorithm possesses the valid prefix property,which it does not.
The exact statement of the invariant condition that would allow for exactspecifications of the item semantics i the topic of ongoing research.
However, the current specificationis sufficient for proving soundness of the algorithm.112Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationHowever, a bit of care must be taken in the interpretation of the Type 1/2 Com-pletor.
Type 4b items that require completion bear a superficial resemblance to Type 1and 2 items, in that both have a constituent of the form t\[_\] after the dot.
In Type 4bitems, the constituent is tier\], in Type 4a items t\[71\].
But it is crucial that the Type 1/2Completor not be used to complete Type 4b items.
A simple distinguishing character-istic is that in Type 1 and 2 items to be completed, the node ~/after the dot is never aroot node (as it is immediately dominated by 71), whereas in Type 4b items, the node~r after the dot is always a root node (of a modifier tree).
Simple side conditions candistinguish the cases.Figure 9 contains the final versions of the inference rules for recognition of LIGscorresponding to extended TAG derivations.6.4 Maintaining Derivation StructuresOne of the intended applications for extended erivation TAG parsing is the parsingof synchronous TAGs.
Especially important in this application is the ability to generatethe derivation trees while parsing proceeds.A synchronous TAG is composed of two base TAGs (which we will call the sourceTAG and the target TAG) whose elementary trees have been paired one-to-one.
A syn-chronous TAG whose source TAG is a grammar for a fragment of English and whosetarget TAG is a grammar for a logical form language may be used to generate logicalforms for each sentence of English that the source grammar admits (Shieber and Sch-abes 1990).
Similarly, with source and target swapped, the synchronized grammar maybe used to generate English sentences corresponding tological forms (Shieber and Sch-abes 1991).
If the source and target grammars pecify fragments of natural anguages,an automatic translation system is specified (Abeill6, Schabes, and Joshi 1990).Abstractly viewed, the processing of a synchronous grammar proceeds by parsingan input string according to the source grammar, thereby generating a derivationtree for the string; mapping the derivation tree into a derivation tree for the targetgrammar; and generating a derived tree (hence, derived string) according to the targetgrammar.One frequent worry about synchronous TAGs as used in their semantic interpreta-tion mode is whether it is possible to perform incremental interpretation.
The abstractview of processing just presented seems to require that a full derivation tree be de-veloped before interpretation i to the logical form language can proceed.
Incrementalinterpretation, on the other hand, would allow partial interpretation results to guidethe parsing process on-line, thereby decreasing the nondeterminism in the parsingprocess.
Whether incremental interpretation is possible depends precisely on the ex-tent to which the three abstract phases of synchronous TAG processing can in fact beinterleaved.
In previous work we left this issue open.
In this section, we allay theseworries by showing how the extended TAG parser just presented can build derivationtrees incrementally as parsing proceeds.
Once this has been demonstrated, it shouldbe obvious that these derivation trees could be transferred to target derivation treesduring the parsing process and immediately generated from.
Thus, incremental inter-pretation is demonstrated to be possible in the synchronous TAG framework.
In fact,the technique presented in this section has allowed for the first implementation f syn-chronous TAG processing, by Onnig Dombalagian.
This implementation was directlybased on the inference-based TAG parser mentioned in Section 6.5 and presented infull elsewhere (Schabes and Shieber 1992).We associate with each item a set of operations that have been implicitly carriedout by the parser in recognizing the substring covered by the item.
An operation canbe characterized by a derivation tree and a tree address at which the derivation tree is113Computational Linguistics Volume 20, Number  1?
Scanner:?
Predictor:(b\[r/\] --+ F ?
aA, i,j, k, I)(b\[z/\] ~ ra .A , i , j , k , l+ l )(P\[r/\] --, P ?
P' \[r/lA, i,j, k, I)(P'\[r/'\]--~ ?
O,/, - ,  - , l )Type 1 and 2 Completor:(b\[rh\] -+ r ?
t\[r/\]A, m,j', k', i) (t\[rl\] -+ 0 ?
,  i,j, k, l)(b\[rh\] -+ Pt\[r/\] ?
A,m, jU j ' , kUk ' , l )?
Type 3 Completor:?
Type 4a Completor:a ~ Wl+lP' \[~/'\] ~ 0(t\[~\] ---+ ?
b \ [~\ ] , i , - , - , i )  (b\[,\] --+ O,  , i , j ,k, l)(t\[~\] ---+b\[,\] ?
, i , j ,k,l)(t\[r/\] --+ ?
t\[,r\], i ,-,-, i)(tier\] --+ 0 ?
,i,j,k,l)(bM --+ A ?
,j,p,q,k)(t\[~\] -+ t\[~r\] ?
,i,p,q,l)?
Type 4b Completor:(b\[~\] -+ ?
t \ [ ,r \] , i , - - , - - , i )(t\[rlr \] --+ 0 ?
, i , j ,k,l)(b\[,\] --+ A ?
, j ,p,q,k)(b\[w\] -+ t\[Wr\] ?
, i ,p,q,l)?
Type 5 Completor:(b\[r/f\] --+ ?
b\[~/\], i, - ,  - ,  i) (b\[~/\] --+ 0 ?
,  i,j, k, I i(bit/f\] --+ b\[r/\] ?
, i, i, l, l)?
Type 6 Completor:(t\[r/\] --+ .
t \ [~ , \ ] , i , - , - , i )  (t\[n,\] --+ o ?
, i , - ,  - , l )(t\[r/\] ---+ t\[,r\] ?
, i , - - , - - , l )Figure 9Inference rules for extended derivation TAG recognition.~/not a root nodet\[..,\] --+ t\[..~lrlr\]b\[..r\]\] --~ t\[..rlrlr\]b\[..~lrlf\] --+ b\[..~\]t\[,\] --+ t\[,r\]to be p laced;  it cor responds  rough ly  to a branch  of a der ivat ion  tree.
Pred ict ion i temshave  the empty  set of operat ions.
Type 4 and  6 complet ion  steps bu i ld  new e lementsof the sets as they  cor respond to actual ly  car ry ing  out  ad junct ion  and  subst i tut ionoperat ions ,  respectively.
Other  complet ion  steps mere ly  poo l  the operat ions  f rom theirconst i tuent  parts.In descr ib ing the bu i ld ing  of der ivat ion  trees, we  wil l  use normal  set notat ion  forthe sets of der ivat ion  trees.
We wil l  assume that  for each node  r/, there are funct ionstree(rl) and addr(rl) that  specify, respectively,  the initial tree that  ~ occurs  in and  itsaddress  in that tree.
Finally, we  wil l  use a const ructor  funct ion  for der ivat ion  trees114Yves Schabes and Stuart M. Shieber Tree-Adjoining Derivationderiv(% S), where "7 specifies an elementary tree and S specifies a set of operations onit.
An operation is built with op(t, D) where t is a tree address and D is a derivationtree to be operated at that address.Figure 10 lists the previously presented recognition rules augmented to buildderivation structures as the final component of each item.
The axioms for this in-ference system are items of the form (S --* ?
t\[~ls\], 0,-,- ,  0, {}), where we assume as inSection 6.1 that there are extra rules S ~ t\[~s\] for each ~s a start-nonterminal-labeledroot node of an initial tree.
We require an extra rule for prediction and completion tohandle this new type of rule.
The predictor ule is the obvious analog:?
Start Rule Predictor:(S ~ r ?
P' \[~'\]A, i , j ,k, l ,S)(P'\[,'\] ?
e,t,-,- ,1, {}) P'\[,'\] eIn fact, the existing predictor ule could have been easily generalized to handle thiscase.The completor for these start rules is the obvious analog to a Type 6 completor,except in the handling of the derivation.
It delivers, instead of a set of derivationoperations, a single derivation tree.?
Start Rule Completor:iS ---+ ?
t\[os\], i , - , - ,  i, {}) (tit/s\] --* O - ,  i , - , - ,  l, S)(S -+ t\[rls\] .
, i , - , - ,  I, deriv(treeO7s), S))The string is accepted upon proving (S-+ t\[r/s\].
, 0,- ,- ,  n, D), where D is thederivation developed uring the parse.6.5 Complexity ConsiderationsThe inference system of Section 6.3 essentially specifies a parsing algorithm with com-plexity of O(n 6) in the length of the string.
Adding explicit derivation structures to theitems, as in the inference system of the previous ection, eliminates the polynomialcharacter of the algorithm in that there may be an unbounded number of derivationscorresponding to any given item of the original sort.
Even for finitely ambiguousgrammars, the number of derivations may be exponential.
Nonetheless, this fact doesnot vitiate the usefulness of the second algorithm, which maintains derivations ex-plicitly.
The point of this augmentation is to allow for incremental interpretation--forinterleaved processing of a post-syntactic sort--so as to guide the parsing process inmaking choices on-line.
By using the extra derivation information, the parser shouldbe able to eliminate certain nondeterministic paths of computation; otherwise, thereis no reason to do the interpretation incrementally.
But this determinization f choicepresumably decreases the complexity.
Thus, the extra information is designed for usein cases where the full search space is not intended to be explored.Of course, a polynomial shared-forest representation f the exponential numberof derivations could have been maintained (by maintaining back pointers among theitems in the standard fashion).
For performing incremental interpretation for the pur-pose of determinization f parsing, however, the non-shared representation is suffi-cient, and preferable on grounds of ease of implementation a d expository conve-nience.115Computat ional  Linguistics Volume 20, Number  1?
Scanner:(b\[~\] --* FoaA, i , j , k , l ,S )(b \ [ , \ ] - - - , Fa .A , i , j , k , l+ l ,S )  a ~ Wl+l?
Predictor:(P\[r/\] --* F ?
P'\[7/'\]A, i,j, k, l, S)(P' \[7/'\] --* ?
O,l, - ,  - , l ,  {}) P,\[~,\] ~ eType I and 2 Completor:(b\[,1\] - - .Pot \ [ , \ ]A ,m, j ' ,k ' , i ,  S1) (t\[,\] --~ (9?
, i , j ,k,l ,  S2)(b\[,1\] --~Ft\[,\] o A, m, ju j ' , kukq ,  l, S1 US21Type 3 Completor:(t\[7/\] --* ?
b\[~/\], i, - ,  - ,  i, {}} (b\[n\] --* O o, i,j, k, l, S)(t\[~/\] --* b\[~?\] ?
, i , j ,k, l ,S)Type 4a Completor:(t\[7/\] --* ?
t\[~/~\], i, - ,  - ,  i, {})(t\[7/r\] --~ O ?
, i , j ,k,l ,S~)(b\[~/\] ~ A .
, j ,p,q,k, $2)(t\[n\] -* t\[nr\] ?
,  i, p, q, 1, {op(addr(n), deriv( tree(nr), S~ ) ) } U $2)Type 4b Completor:(b\[zl\] --* ?
t\[~/r\], i, - ,  - ,  i, {}}(t\[Zlr\] ~ 0 .
, i , j ,k,l ,  S1)(b\[,\] --* A .
, j ,p,q,k, S2)(t\[,\] ---* t\[Zlr\] " , i, p, q, 1, {op(addr(,), deriv(treeO?r), S~) } U $2)Type 5 Completor:(b\[zlf\] ---* .b \ [~ l \ ] , i , - , - , i ,{})  (b\[z/\] --* O .
, i , j ,k, l ,S)(b\[~f\] ---+ b\[~/\]., i, i, I, 1, S)Type 6 Completor:(t\[~/\] ~ ?
tic?r\], i - ,  - ,  i, {}) (t\[rlr\] ~ 0 "~ i~ -~ -~ l, S)(t\[7/\] --* t\[Z\]r\] " ~ i, --, --, I, {op(addr01 ), deriv(treeO?~), S))}}Figure 10Inference rules for extended derivation TAG parsing.Z/ not a root nodet\[..~?\] ~ t\[..,~/r\]b\[..~?\] ~ t\[..~p/r\]b\[..~/r/f\] --~ b\[..r/\]t\[,\] --* t\[~r\]As  a proo f  of concept ,  the pars ing  a lgor i thm just descr ibed  was  imp lemented  inP ro log  on  top  of a s imple ,  genera l -purpose ,  agenda-based  in ference engine.
Encod-ings of  expl ic i t  in ference ru les  are essent ia l ly  in terpreted  by  the in ference engine.
ThePro log  database  is used  as the chart ;  i tems not  a l ready  subsumed by  a prev ious ly  gen-e ra ted  i tem are asser ted  to the database  as the parser  runs.
An  agenda of potent ia l  newi tems is ma inta ined .
I tems are added to the agenda as in ference ru les  are t r iggered  byi tems added to the chart.
Because  the in ference ru les  are s tated  explicit ly,  the re lat ionbetween the abst ract  in ference ru les  descr ibed  in this paper  and  the imp lementat ionis ext remely  t ransparent .
As  a meta - in terpreter ,  the proto type  is not  par t i cu la r ly  effi-116Yves Schabes and Stuart M. Shieber Tree-Adjoining Derivationcient.
(In particular, the implementation does not achieve the theoretical O(n 6) boundon complexity, because of a lack of appropriate indexing.)
Code for the prototypeimplementation is available for distribution electronically from the authors.7.
ConclusionThe precise formulation of derivation for tree-adjoining grammars has important rami-fications for a wide variety of uses of the formalism, from syntactic analysis to semanticinterpretation and statistical language modeling.
We have argued that the definition oftree-adjoining derivation must be reformulated in order to take greatest advantage ofthe decoupling of derivation tree and derived tree by manifesting the proper linguisticdependencies in derivations.
The particular proposal is both precisely characterizablethrough a definition of TAG derivations as equivalence classes of ordered derivationtrees and computationally operational by virtue of a compilation to linear indexedgrammars together with an efficient algorithm for recognition and parsing accordingto the compiled grammar.AcknowledgmentsOrder of authors is not intended as anindication of precedence of authorship.Much of the work reported in this paperwas performed while the first author was atthe Department of Computer andInformation Science, University ofPennsylvania, Philadelphia, PA.
The firstauthor was supported in part by DARPAGrant N0014-90-31863, ARO GrantDAAL03-89-C-0031, and NSF GrantIRI-90-16592.
The second author wassupported in part by Presidential YoungInvestigator award IRI-91-57996 from theNational Science Foundation and amatching rant from Xerox Corporation.The authors wish to thank Aravind Joshi forhis support of the research, and AravindJoshi, Judith Klavans, Anthony Kroch,Shalom Lappin, Kathy McCoy, FernandoPereira, James Pustejovsky, andK.
Vijay-Shanker for their helpfuldiscussions of the issues involved.
We areindebted to David Yarowsky for aid in thedesign of the experiment mentioned infootnote 9 and for its execution.ReferencesAbeill6, Anne; Schabes, Yves; and Joshi,Aravind K. (1990).
"Using lexicalized treeadjoining grammars for machinetranslation."
In Proceedings, 13thInternational Conference on ComputationalLinguistics, Volume 3, 1-6, Helsinki,Finland.Gazdar, Gerald; Klein, Ewan; Pullum,Geoffrey K.; and Sag, Ivan A.
(1985).Generalized Phrase Structure Grammar.Blackwell.Joshi, A. K.; Kosaraju, S. R.; and Yamada,H.M.
(1972a).
"String adjunct grammars:I.
Local and distributed adjunction.
"Information and Control, 21(2), 93-116.Joshi, A. K.; Kosaraju, S. R.; and Yamada,H.
M. (1972b).
"String adjunct grammars:II.
Equational representation, nullsymbols, and linguistic relevance.
"Information and Control, 21 (3), 235-260.Joshi, Aravind K.; Levy, L. S.; andTakahashi, M. (1975).
"Tree adjunctgrammars."
Journal of Computer and SystemSciences, 10(1), 136-163.Kroch, Anthony S. (1989).
"Asymmetries inlong distance xtraction i  a TAGgrammar."
In Alternative Conceptions ofPhrase Structure, edited by M. Baltin andA.
Kroch, 66-98.
University of ChicagoPress.Kroch, Anthony S., and Joshi, Aravind K.(1985).
"The linguistic relevance of treeadjoining grammar."
Technical ReportMS-CIS-85-18, Department of Computerand Information Science, University ofPennsylvania, Philadelphia, PA.Pereira, Fernando C. N., and Warren, DavidH.
D. (1983).
"Parsing as deduction."
InProceedings, 21st Annual Meeting of theAssociation for Computational Linguistics,137-144.
Cambridge, MA.Quirk, Randolph; Greenbaum, Sidney;Leech, Geoffrey; and Svartvik, Jan (1985).A Comprehensive Grammar of the EnglishLanguage.
Longman.Resnik, Philip (1992).
"Probabilistictree-adjoining grammar as a frameworkfor statistical natural anguageprocessing."
In Proceedings, 14thInternational Conference on ComputationalLinguistics, 418-424.
Nantes, France.117Computational Linguistics Volume 20, Number 1Schabes, Yves (1991).
"The valid prefixproperty and left to right parsing oftree-adjoining grammar."
In Proceedings,Second International Workshop on ParsingTechnologies, 21-30.
Cancun, Mexico.Schabes, Yves (1992).
"Stochastic lexicalizedtree-adjoining grammars."
In Proceedings,14th International Conference onComputational Linguistics, 426-432.
Nantes,France.Schabes, Yves, and Shieber, Stuart M.
(1992).
"An alternative conception oftree-adjoining derivation."
TechnicalReport 08-92, Harvard University,Cambridge, MA.Schabes, Yves, and Waters, Richard C.(1993a).
"Lexicalized context-freegrammars."
In Proceedings, 31st AnnualMeeting of the Association for ComputationalLinguistics, 121-129.
Columbus, OH.Schabes, Yves, and Waters, Richard C.(1993b).
"Stochastic lexicalizedcontext-free grammars."
In Proceedings,Third International Workshop on ParsingTechnologies, 257-266.
Tilburg, TheNetherlands and Durbuy, Belgium.Shieber, Stuart M. (1992).
Constraint-BasedGrammar Formalisms.
MIT Press.Shieber, Stuart M. (in press).
"Restricting theweak-generative capacity of synchronoustree-adjoining grammars."
ComputationalIntelligence.Shieber, Stuart M., and Schabes, Yves (1990).
"Synchronous tree-adjoining grammars.
"In Proceedings, 13th International Conferenceon Computational Linguistics, Volume 3,253-258.
Helsinki, Finland.Shieber, Stuart M., and Schabes, Yves (1991).
"Generation and synchronous treeadjoining rammars."
ComputationalIntelligence, 4(7), 220-228.Vijay-Shanker, K. (1987).
A Study of TreeAdjoining Grammars.
Doctoral dissertation,Department of Computer andInformation Science, University ofPennsylvania, Philadelphia, PA.Vijay-Shanker, K., and Joshi, Aravind K.(1985).
"Some computational properties oftree adjoining rammars."
In Proceedings,23rd Annual Meeting of the Association forComputational Linguistics, 82-93.
Chicago,IL.Vijay-Shanker, K., and Joshi, Aravind K.(1988).
"Feature structure based treeadjoining rammars."
In Proceedings, 12thInternational Conference on ComputationalLinguistics, 714--719.
Budapest, Hungary.Vijay-Shanker, K., and Weir, David J.
(1990).
"Polynomial parsing of extensions ofcontext-free grammars."
In Current Issuesin Parsing Technologies, edited by MasaruTomita, 191-206.
Kluwer AcademicPublishers.118Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationAppendix A: Proof of Redundancy of Adjacent Sibling SwappingA.1 PreliminariesA.1.1 Tree Addresses.
We define tree addresses (variables over which are convention-ally notated p~q,...~ t,u~v and their subscripted and primed variants) as the finite,possibly empty, sequences of positive integers (conventionally i~j~ k), with _._ as thesequence concatenation operator.
We uniformly abuse notation by conflating the dis-tinction between singleton sequences and their one element.We use the notation p -~ q to notate that tree address p is a proper prefix of q,and p -~ q for improper prefix.
When p _ q, we write q - p for the (possibly empty)sequence obtained from q by removing p from the front, e.g., 1 - 2 .3 .4  - 1 ?
2 --- 3 .4.A.1.2 Trees.
We will take trees (conventionally A, B, E, T; also ~, r ,  3' in the prior text)to be finite partial functions from tree addresses to symbols, such that the functionsarePrefix closed: For any tree T, if T(p. i) is defined then T(p) is defined.Left closed: For any tree T, if T(p ?
i) is defined and i > 1 then T(p ?
(i - 1)) isdefined.We will refer to the domain of a tree T, the tree addresses for which T is defined,as the nodes of T. A node p of T is a frontier node if T(p. i) is undefined for all i.
A nodeof T is an interior node if it is not a frontier node.
We say that a node p of T is labeledwith a symbol s if T(p) = s.A.2 Tree-Adjoining Grammars and DerivationsA.2.1 Tree-Adjoining Grammars.
In the following definitions, we restrict attention totree-adjoining grammars in which adjunction is the only operation; substitution is notallowed.
The definitions are, however, easily augmented to include substitution.
Wedefine a tree-adjoining grammar to be given by a quintuple/G~ N,/7, ~4~ S) where?
P, is a finite set of terminal symbols.?
N is a finite set of nonterminal symbols disjoint from P,.?
(V = G U N is the vocabulary of the grammar.)?
S is a distinguished nonterminal symbol, the start symbol.?
/7 is a finite set of trees, the initial trees, where-- interior nodes are labeled by nonterminal symbols, andfrontier nodes are labeled by terminal symbols or the specialsymbol c. (We require that e ~g V, as e intuitively specifies theempty string.)?
~4 is a finite set of trees, the auxiliary trees, where-- interior nodes are labeled by nonterminal symbols, and--frontier nodes are labeled by terminal symbols or e, except forone node, called the foot node, which is labeled with anonterminal symbol.?
(g =/7 tO A is the set of elementary trees of the grammar.
)By convention, the address of the foot node of a tree A is notated fa.119Computational Linguistics Volume 20, Number 1A.2.2 Adjunction.
The adjunction of an auxiliary tree A at address t in tree E notatedE\[A/t\] is defined to be the smallest (least defined) tree T such thatE(r) if t 74 r (1)T(r) = A(u)  if r = t. u and fA 74 U (2)E(t .
u) if r = t .
fa .
u (3)These cases ~ire disjoint except at addresses t and t .
fA.
We haveby clause (1), andby clause (2).
Similarly, we haveby clause (2) andT(t) -- E(t)T(t) -- A(t)T(t .
fA) = Aria)T(t "fA) = E(t)by clause (3).
So for an adjunction to be well defined, it must be the case thatE(t) = A(t) = Aria)that is, the node at which adjunction occurs must have the same label as the root andfoot of the auxiliary tree adjoined.
This is, of course, standard in definitions of TAG.Alternatively, this constraint can be added as a stipulation and the definition mod-ified as follows:E(F) if t Z rT(r) = A(u)  if r = t .u  and fA Z UE(t.  u) if r = t .
fA.
UWe will use this latter definition below.A.2.3 Ordered Derivation Trees.
Ordered derivation trees are ordered trees composedof nodes, conventionally notated as ~/, possibly in its subscripted and primed variants.
(For ordered derivation trees, we will be less formal as to their mathematical structure.In particular, the formalization of the previous section need not apply; the definitionsthat follow define all of the structure that we will need.)
The parent of a node ~/in a derivation tree will be written parent(q), and the tree in g that the node marksadjunction of will be notated tree(~l).
The tree tree(q) is to be adjoined into its parenttree(parent(q)) at an address pecified on the arc in the tree linking the two; this addressis notated addrO1 ).
(Of course, the root node has no parent or address; the parent andaddr functions are partial.
)An ordered derivation tree is well formed if for each arc in the derivation treefrom ~ to parent(q) labeled with addr(~), the tree tree(q) is an auxiliary tree that can beadjoined at the node addrO? )
in tree(parent01)).We repeat from Section 4.1 the definition of the funct ion/ )  from derivation treesto the derived trees they specify, in the notation of this appendix:"D(D) = {treeO? )
if D is a trivial tree of one node ~/tree(,)\[~D(D1) /h ,  "D(Da) /t2~ .
.
.
, ~)(Dk) /tk\]if D is a tree with root node ~/and with k child subtrees D1, .
.
.
,  Dkwhose arcs are labeled with addresses t l , .
.
.
,  tk.120Yves Schabes and Stuart M. Shieber Tree-Adjoining DerivationAs in Section 4.1, E\[A1/h, .
.
.
,Ak/tk\ ]  specifies the simultaneous adjunction of treesA1 through Ak at tl through tk, respectively, in E. It is defined as the iterative adjunctionof the Ai in order at their respective addresses, with appropriate updating of the treeaddresses of later adjunctions to reflect the effect of earlier adjunctions.
In particular,the following inductive definition suffices; the base case holds for the adjunction ofzero auxiliary trees.whereEl\] = EE\[A1/ tl , A2/ t2, .
.
.
, Ak/  tk\](E\[A1/tl\]) \[A2/update( t2 ~ A1, t l ) , .
.
.
~ Ak/update( tk , A1, tl )\]update(s, A, t) = { s if t 74 st .
fA ' (S - - t )  i f t -~sIn the following section, we leave out parentheses in specifying sequential ad-junctions such as (E\[A1/tl\]) \[A2/t2\] under a convention of left associativity of the \[_/_\]operator.A.3 Effect of  S ib l ing  SwapsIn this section, we show that the derived tree specified by a given ordered deriva-tion tree is unchanged if adjacent siblings whose arcs are labeled with different reeaddresses are swapped.
This will be shown as the following proposition.Propos i t ionIf t ~ t' then El .
.
.
,  A/t ,  B/t ' , .
.
.
\ ]  = El .
.
.
,  B/if, A/ t , .
.
.
\ ] .We start with a lemma, the case for only two adjunctions.LemmaIf t ~ t' then E\[A/t, B/t'\] = E\[B/t',A/t\].ProofThere are three major cases, depending on the relationship of t and t':Case t -~ t': Let s = t ~ - t. ThenE\[A/t, B/t'\](r) = E\[A/t\]\[B/update(t', A, t)\](r)= E\[A/t\]\[B/t "fa" s\](r)E\[A/t\](r)= B(u)E\[A/t\](t. fA" sE(r) ifa(v)E(t-v)B(u)E(t. s-u)E(r)A(v)E(t. v)B(u)E(t. s. u)if t .
fa .
s  ;~ rif r = t.fA .S.
U andfB ~ u?
u) if r = t'fa'S'fB" Ut .
fA .s  ~ r and t ~ rif t-fA "S :~ r and r = t -vif t .
fa .
s  ~ r and r = t .
fa  'vif r = t .
fa  .s .
u andfB :~ ui f r=t .
fa .
s .
fB .uif t ;~ ri f r=t .vif s ~ v and r = t.fA "vif r=  t .
fa  .
s .u  andfB :~ uif r = t ' fa 'S ' fB"  U121Computational Linguistics Volume 20, Number 1If siblings are swapped,= E\[B/t'\] [A/update(t,= E\[B/t'\]\[A/t\](r)E\[B/t.
s\](r)= A(v)E\[B/t.
s\](t. v)E(r) ifA(v) if= E(t.  v) ifB(u) ifE(t .
s .
u) ifE(r) ifA(v) if= E(t.  v) ifB(u) ifE(t .
s .
u) ifE\[B/tI,A/t\](r)Case t / -~ t: Analogously.Case t 74 t' and t' 74 t:E\[A/tt B/t'\] (r)B t')\](r)i f t  ~rif r = t .v  and fA ~ Vif r=  t ' fA .V:~r=t .v=t ' fA=t ' fA=t ' fA;~r~-t .v:~ v and r = t .
fA .
v= t ' fA  "S" U andfB :~ u=t ' fA 'S ' fB 'U= E\[A/t\] [B/update(Y, A= E\[A/tl\[B/t'\](r)E\[A/t\](r)= B(u)E\[A/t\](t'.
u)E(r) if t'A(v) if t'E(t.  v) if t' :~ rB(u) if r = t'E(t' .
u) if r = t'?
v and t .
s  ~ t .v?
v and t -v  = t .
s .u  andfB :~ u. vandt .v=t .
fB .ut)\](r)if t' ~ ri f r=t ' .uandfB~uif r = t' .
fB " Ur and t :~ rand r = t .v  and fA ;~ Vand r = t .
fA " V?
U andfB ~ U"fB "UNote that this is unchanged (up to var iable renaming)  under  swapp ing  ofA for B and t for t'.
That is E\[A/t, B/t'\](r) = E\[B/t',A/t\](r).
\[\]We now return to the main  proposit ion?Proposi t ionIf t ~ t' then E \ [ .
.
.
,A / t ,B / t ' , .
.
.
\ ]  = E\ [ .
.
.
,B / t ' ,A / t t .
.
.
\ ] .ProofThe effect of the adjunct ions before the two specif ied in the swap is obvious ly  thesame on all fo l lowing adjunctions, so we need only show thatE\[A/t, B/t', C1 / t l , .
.
.
t  Ck/tk\] = E\[B/t', A / t ,  C 1/tlt .
.
.
t Ck/tk\]without  loss of generality.
We examine the effect of the A and B adjunct ions on thetree address  ti for each Ci separately.
In the case of the former  adjunct ion orderE\ [A / t ,B / t ' , .
.
.
,Cdt i t .
.
.
\ ]= E\[A/t\] [B/update(t't A, t ) , .
.
.
,  Ci/update(ti, A, t ) , .
.
.
\ ]= E\[A/t\]\[B/update(t', At t) \] \[ .
.
.
,  Q/update(update(tit A, t), B, update(t', A, t))t.. .
\]= E\[A/t, B/t'\] \[.. .t Ci/update(update(ti, At t), Bt update(Y, A, t)) , .
.
.
\ ]122Yves Schabes and Stuart M. Shieber Tree-Adjoining Derivationand  for the latter ad junct ion  order:E\[B/t', A / t , .
.
.
,  Ci/ti,...\]= E\[B/t'\] \[A/update(t, B, t ' ) , .
.
.
,  Ci/update(ti, B, t ' ) , .
.
.
\ ]= E\[B/t'\] [A/update(t, B, t')\] \ [ .
.
.
,  Ci/update(update(ti, B t'), A, update(t, B, t ' ) ) , .
.
.
\ ]= E\[B/t', A/t\] \[ .
.
.
,  Ci/update(update(ti, B t'), A, update(t, B, t')),...\]= E\[A/t, B/t'\] \[... ,  Ci/update(update(ti, B t'), A, update(t, B, t ' ) ) , .
.
.
\ ]This last step ho lds  by  v i r tue  of  the lemma.Thus,  it suff ices to show thatupdate(update(ti, A, t), B, update(t', A, t) ) = update(update(ti, B t'), A, update(t, B, t'))Again,  we  per fo rm a case analys is  depend ing  on the pref ix re lat ionsh ips  of t, Y,and  ti.
Note  that we  make use of  the fact that  if t -~ t ~ then (Y - t) ?
s = t r ?
s - t.Case t -~ Y:Subcase t ~ -~ ti:update( update( ti, A, t ) , B, update( t', A, t ) )= update(t "fA" (ti -- t), B, t ' fA" (t' -- t))= t ' fA" (t' -- t)"fB" ( t i -  t')= t ' fA" (t' "fB" (ti-- t') -- t)= update(t' "fB" ( t i -  t'),A, t)= update(update(ti, B t'), A, update(t, B, t'))Subcase t ~ 74 ti and t -~ ti:update(update( ti, A, t ), B, update( t', A, t ) )= update(t "fA" ( t i -  t), B, t ' fA" (t'-- t))= t .
fA .
(ti-- t)= update(ti, A, t)= update(update(ti, B t'), A, update(t, B, t'))Subcase t' 74 ti and t 74 ti:update(update( ti, A, t ), B, update( t', A, t ) )= update(ti, B, t ' fA" (t' -- t))-= ti= update(ti, A, t .
fB .
(t' - t))= update(update(ti, B  t'), A, update(t, B, t'))Case t p < t: The  proo f  is as for  the prev ious  case wi th  t for  t r and  vice versa.Case t 74 t ~ and  t ~ 74 t:Subcase t ~ ti: We can conc lude  f rom the assumpt ions  that  Y 74 ti.Thenupdate(update(ti, A t), B, update(t', A, t) )= update(t, fA" (ti -- t), B, t')~- t .
fA .
(ti - t)= update(ti, A, t)= update(update(ti, B t'), A, update(t, B, t'))123Computational Linguistics Volume 20, Number 1Subcase t 74 ti and t ~ -~ ti'- The proof is as for the previous subcasewith t for t ~ and vice versa.Subcase t 74 ti and t' 74 ti:update( update( G A, t ) , Be update( t'~ A, t ) )= update(ti, B, t')= update(G A, t)= update(update(ti, B~ t'), As update(t, B, t'))\[\]124
