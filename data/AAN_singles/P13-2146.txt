Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 843?847,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsMultimodal DBN for Predicting High-Quality Answers in cQA portalsHaifeng Hu, Bingquan Liu, Baoxun Wang, Ming Liu, Xiaolong WangSchool of Computer Science and TechnologyHarbin Institute of Technology, China{hfhu, liubq, bxwang, mliu, wangxl}@insun.hit.edu.cnAbstractIn this paper, we address the problem forpredicting cQA answer quality as a clas-sification task.
We propose a multimodaldeep belief nets based approach that op-erates in two stages: First, the joint rep-resentation is learned by taking both tex-tual and non-textual features into a deeplearning network.
Then, the joint repre-sentation learned by the network is usedas input features for a linear classifier.
Ex-tensive experimental results conducted ontwo cQA datasets demonstrate the effec-tiveness of our proposed approach.1 IntroductionPredicting the quality of answers in communi-ty based Question Answering (cQA) portals is achallenging task.
One straightforward approachis to use textual features as a text classificationtask (Agichtein et al 2008).
However, due tothe word over-sparsity and inherent noise of user-generated content, the classical bag-of-words rep-resentation, is not appropriate to estimate the qual-ity of short texts (Huang et al 2011).
Another typ-ical approach is to leverage non-textual features toautomatically identify high quality answers (Jeonet al 2006; Zhou et al 2012).
However, in thisway, the mining of meaningful textual featuresusually tends to be ignored.Intuitively, combining both textual and non-textual information extracted from answers ishelpful to improve the performance for predict-ing the answer quality.
However, textual and non-textual features usually have different kinds of rep-resentations and the correlations between them arehighly non-linear.
Previous study (Ngiam et al2011) has shown that it is hard for a shallow modelto discover the correlations over multiple sources.To this end, a deep learning approach, calledmultimodal deep belief nets (mDBN), is intro-duced to address the above problems to predict theanswer quality.
The approach includes two stages:feature learning and supervised training.
In theformer stage, a specially designed deep network isgiven to learn the unified representation using bothtextual and non-textual information.
In the latterstage, the outputs of the network are then used asinputs for a linear classifier to make prediction.The rest of this paper is organized as follows:The related work is surveyed in Section 2.
Then,the proposed approach and experimental resultsare presented in Section 3 and Section 4 respec-tively.
Finally, conclusions and future directionsare drawn in Section 5.2 Related WorkThe typical way to predict the answer quality isexploring various features and employing machinelearning methods.
For example, Jeon et al(2006)have proposed a framework to predict the qual-ity of answers by incorporating non-textual fea-tures into a maximum entropy model.
Subsequent-ly, Agichtein et al(2008) and Bian et al(2009)both leverage a larger range of features to find highquality answers.
The deep research on evaluatinganswer quality has been taken by Shah and Pomer-antz (2010) using the logistic regression model.We borrow some of their ideas in this paper.In deep learning field, extensive studies havebeen done by Hinton and his co-workers (Hin-ton et al 2006; Hinton and Salakhutdinov, 2006;Salakhutdinov and Hinton, 2009), who initial-ly propose the deep belief nets (DBN).
Wanget.al (2010; 2011) firstly apply the DBNs to modelsemantic relevance for qa pairs in social communi-ties.
Meanwhile, the feature learning for disparatesources has also been the hot research topic.
Leeet al(2009) demonstrate that the hidden represen-tations computed by a convolutional DBN makeexcellent features for visual recognition.8433 ApproachWe consider the problem of high-quality answerprediction as a classification task.
Figure 1 sum-marizes the framework of our proposed approach.First, textual features and non-textual features ex-TextualFeatures Non-textualFeaturesCQAArchivesClassifierFusion RepresentationFeatureLearning  Supervised TrainingHigh-qualityAnswersFigure 1: Framework of our proposed approach.tracted from cQA portals are used to train two DB-N models to learn the high-level representation-s independently for answers.
The two high-levelrepresentations learned by the deep architecturesare then joined together to train a RBM model.Finally, a linear classifier is trained with the finalshared representation as input to make prediction.In this section, a deep network for the cQA an-swer quality prediction is presented.
Textual andnon-textual features are typically characterized bydistinct statistical properties and the correlationsbetween them are highly non-linear.
It is very dif-ficult for a shallow model to discover these corre-lations and form an informative unified represen-tation.
Our motivation of proposing the mDBN isto tackle these problems using an unified represen-tation to enhance the classification performance.3.1 The Restricted Boltzmann MachinesThe basic building block of our feature leaningcomponent is the Restricted Boltzmann Machine(RBM).
The classical RBM is a two-layer undi-rected graphical model with stochastic visible u-nits v and stochastic hidden units h.The visiblelayer and the hidden layer are fully connected tothe units in the other layer by a symmetric matrixw.
The classical RBM has been used effectively inmodeling distributions over binary-value data.
Asfor real-value inputs, the gaussian RBM (Bengioet al 2007) can be employed.
Different from theformer, the hypothesis for the visible unit in thegaussian RBM is the normal distribution.3.2 Feature LearningThe illustration of the feature learning model isgiven by Figure 2.
Basically, the model consistsof two parts.In the bottom part (i.e., V -H1, H1-H2), eachdata modality is modeled by a two-layer DBN sep-arately.
For clarity, we take the textual modalityas an example to illustrate the construction of themDBN in this part.
Given a textual input vector v,the visible layer generates the hidden vector h, byp(hj = 1|v) = ?
(cj +?iwijvi).Then the conditional distribution of v given h, isp(vi = 1|h) = ?
(bi +?j wijhj).where ?
(x) = (1 + e?x)?1 denotes the logisticfunction.
The parameters are updated by perform-ing gradient ascent using Contrastive Divergence(CD) algorithm (Hinton, 2002).After learning the RBMs in the bottom layer,we treat the activation probabilities of its hiddenunits driven by the inputs, as the training data fortraining a new layer.
The construction proceduresfor the non-textual modality are similar to the tex-tual one, except that we use the gaussian RBM tomodel the real-value inputs in the bottom layer.Finally, we combine the two models by addingan additional layer, H3, on the top of them to formthe mDBN.
The training method is also similar tothe bottom?s, but the input vector is the concatena-tion of the mapped textual vector and the mappednon-textual vector.Figure 2: mDBN for Feature LearningIt should be noted in the network, the bottompart is essential to form the joint representationbecause the correlations between the textual andnon-textual features are highly non-linear.
It ishard for a RBM directly combining the two dis-parate sources to learn their correlations.3.3 Supervised Training and ClassificationAfter the above steps, a deep network for featurelearning between textual and non-textual data isestablished.
Classifiers, either support vector ma-chine (SVM) or logistic regression (LR), can thenbe trained with the unified representation (Ngiam844et al 2011; Srivastava and Salakhutdinov, 2012).Specifically, the LR classifier is used to make thefinal prediction in our experiments since it keepsto deliver the best performance.3.4 Basic FeaturesTextual Features: The textual features ex-tract from 1,500 most frequent words in the train-ing dataset after standard preprocessing steps,namely word segmentation, stopwords removaland stemming1.
As a result, each answer is repre-sented as a vector containing 1,500 distinct termsweighted by binary scheme.Non-textual Features: Referring tothe previous work (Jeon et al 2006; Shah andPomerantz, 2010), we adopt some features usedin theirs and also explore three additional featuresmarked by ?
sign.
The complete list is describedin Table 1.Features TypeLength of question title (description) IntegerLength of answer IntegerNumber of unique words for the answer ?
IntegerRatio of the qa length ?
FloatAnswer?s relative position ?
IntegerNumber of answers for the question IntegerNumber of comments for the question IntegerNumber of questions asked by asker (answerer) IntegerNumber of questions resolved by asker (answerer) IntegerAsker?s (Answerer?s) total points IntegerAsker?s (Answerer?s) level IntegerAsker?s (Answerer?s) total stars IntegerAsker?s (Answerer?s) best answer ratio FloatTable 1: Summary of non-textual features.4 Experiments4.1 Experiment SetupDatasets: We carry out experiments on twodatasets.
One dataset comes from Baidu Zhi-dao2, which contains 33,740 resolved questionscrawled by us from the ?travel?
category.
The oth-er dataset is built by Chen and Nayak (2008) fromYahoo!
Answers3.
We refer to these two dataset-s as ZHIDAO and YAHOO respectively and ran-domly sample 10,000 questions from each to formour experimental datasets.
According to the us-er name, we have crawled all the user profile webpages for non-textual feature collection.
To allevi-ate unnecessary noise, we only select those ques-tions with number of answers no less than 3 (one1The stemming step is only used in English corpus.2http://zhidao.baidu.com3http://answers.yahoo.combest answer among them), and those answers atleast have 10 tokens.
The statistics on the datasetsused for experiments are summarized in Table 2.Statistics Items YAHOO ZHIDAO# of questions 6841 5368# of answers 74485 22435# of answers per question 10.9 4.1# of users 28812 12734Table 2: Statistics on experimental datasets.Baselines and Evaluation Metrics: We com-pare against the following methods as our base-lines.
(1) Logistic Regression (LR): We imple-ment the approach used by Shah and Pomer-antz (2010) with textual features LR-T, non-textual features LR-N and their simple combina-tion LR-C. (2) DBN: Similar to the mDBN, theoutputs of the last hidden layer by the DBN areused as inputs for LR model.
Based on the fea-ture sets, we have DBN-T for textual features andDBN-N for non-textual features.Since we mainly focus on the high quality an-swers, the precision, recall and f1 for positive classand the overall accuracy for both classes are em-ployed as our evaluation metrics.Model Architecture and Training Details: Tocreate the mDBN architecture, we use the classi-cal RBM with 1500 visible units followed by 2hidden layers with 1000 and 800 units respective-ly for the textual branch, and the gaussian RBMwith 20 visible units followed by 2 hidden layerswith 100 and 200 units respectively for the non-textual branch.
On the joint layer of the network,the layer contains 1000 real-value units.Each RBM is trained using 1-step CD algorith-m. During the training stage, a small weight-costof 0.0002 is used, and the learning rate for textu-al data modal is 0.05 while the non-textual data is0.001.
We also adopt a monument of 0.5 for thefirst five epochs and 0.9 for the rest epochs.
Inaddition, all non-textual data vectors are normal-ized to have zero mean and unit standard variance.More details for training the deep architecture canbe found in Hinton (2012).4.2 Results and AnalysisIn the first experiment, we compare the perfor-mance of mDBN with different methods.
To makea fare comparison, we use the liblinear toolkit4 forlogistic regression model with L2 regularizationand randomly select 70% QA pairs as training data4available at http://www.csie.ntu.edu.tw/ cjlin/liblinear845and the rest 30% as testing data.
Table 3 and Ta-ble 4 summarize the average results of the 5 roundexperiments on YAHOO and ZHIDAO respectively.Methods P R F1 Accu.LR-T 0.374 0.558 0.448 0.542LR-N 0.524 0.614 0.566 0.686LR-C 0.493 0.557 0.523 0.662DBN-T 0.496 0.571 0.531 0.663DBN-N 0.505 0.578 0.539 0.670mDBN 0.534 0.631 0.579 0.694Table 3: Comparing results on YAHOOIt is promising to see that the proposed mDBNmethod notably outperforms almost all the othermethods on both datasets over all the metrics asexpected, except for the recall on ZHIDAO.
Themain reason for the improvements is that the jointrepresentation learned by mDBN is able to com-plement each modality perfectly.
In addition, themDBN can extract stronger representation throughmodeling semantic relationship between textualand non-textual information, which can effectivelyhelp distinguish more complicated answers fromhigh quality to low quality.Methods P R F1 Accu.LR-T 0.380 0.540 0.446 0.553LR-N 0.523 0.735 0.611 0.688LR-C 0.537 0.695 0.606 0.698DBN-T 0.527 0.730 0.612 0.692DBN-N 0.539 0.760 0.631 0.703mDBN 0.590 0.755 0.662 0.743Table 4: Comparing results on ZHIDAOThe classification performance of the textu-al features are worse on average compared withnon-textual features, even when the feature learn-ing strategy is employed.
More interestingly, wefind the simple combinations of textual and non-textual features don?t improve the classificationresults compared with using non-textual featuresalone.We conjecture that there are mainly threereasons for the phenomena: First, this is due to thefact that user-generated content is inherently noisywith low word frequency, resulting in the sparsityof employing textual feature.
Second, non-textualfeatures (e.g., answer length) usually own stronglystatistical properties and feature sparsity problemcan be better relieved to some extent.
Finally, s-ince correlations between the textual features andnon-textual features are highly non-linear, con-catenating these features simply sometimes cansubmerge classification performance.
In contrast,mDBN enjoys the advantage of the shared repre-sentation between textual features and non-textualfeatures using the deep learning architecture.We also note that neither the mDBN nor otherapproaches perform very well in predicting answerquality across the two datasets.
The best precisionon ZHIDAO and YAHOO are respectively 59.0%and 53.4%, which means that there are nearly halfof the high quality answers not effectively identi-fied.
One of the possible reason is that the quali-ty of the corpora influences the result significant-ly.
As shown in Table 2, each question on aver-age receives more than 4 answers on ZHIDAO andmore than 10 on YAHOO.
Therefore, it is possi-ble that there are several answers with high quali-ty to the same question.
Selecting only one as thehigh quality answer is relatively difficult for ourhumans, not to mention for the models.100 500 1000 2000 5000# iterations0.500.550.600.650.700.750.80Precision Recall F1 AccuracyFigure 3: Influences of iterations for mDBNIn the second experiment, we intend to exam-ine the performance of mDBN with different num-ber of iterations.
Figure 3 depicts the metrics onZHIDAO when the iteration number is varied from100 to 5000.
From the result, the first observa-tion is that increasing the number of iterations theperformance of mDBN can improve significant-ly, obtaining the best results for iteration of 1000.This clearly shows the representation power of themDBN again.
However, after a large number of it-erations (large than 1000), the mDBN has a detri-mental performance.
This may be explained bywith large number of iterations, the deep learningarchitecture is easier to be overfitting.
The similartrend is also observed on YAHOO.5 Conclusions and Future workIn this paper, we have provided a new perspec-tive to predict the cQA answer quality: learningan informative unified representation between tex-tual and non-textual features instead of concate-nating them simply.
Specifically, we have pro-posed a multimodal deep learning framework to846form the unified representation.
We compare thiswith the basic features both in isolation and incombination.
Experimental results have demon-strated that our proposed approach can capture thecomplementarity between textual and non-textualfeatures, which is helpful to improve the perfor-mance for cQA answer quality prediction.For the future work, we plan to explore more se-mantic analysis to approach the issue for short tex-t quality evaluation.
Additionally, more researchwill be taken to put forward other approaches forlearning multimodal representation.AcknowledgmentsThe authors are grateful to the anonymous re-viewers for their constructive comments.
Spe-cial thanks to Chengjie Sun and Deyuan Zhangfor insightful suggestions.
This work is supportedby National Natural Science Foundation of China(NSFC) via grant 61272383 and 61100094.ReferencesE.
Agichtein, C. Castillo, D. Donato, A. Gionis, andG.
Mishne.
2008.
Finding high-quality content insocial media.
In Proceedings of the internation-al conference on Web search and web data mining,pages 183?194.
ACM.Yoshua Bengio, Pascal Lamblin, Dan Popovici, andHugo Larochelle.
2007.
Greedy layer-wise trainingof deep networks.
In Advances in Neural Informa-tion Processing Systems, pages 153?160.Jiang Bian, Yandong Liu, Ding Zhou, EugeneAgichtein, and Hongyuan Zha.
2009.
Learning torecognize reliable users and content in social mediawith coupled mutual reinforcement.
In Proceedingsof the 18th international conference on World wideweb, pages 51?60.
ACM.L.
Chen and R. Nayak.
2008.
Expertise analysis in aquestion answer portal for author ranking.
In Inter-national Conference on Web Intelligence and Intel-ligent Agent Technology, volume 1, pages 134?140.G.E.
Hinton and R.R.
Salakhutdinov.
2006.
Reduc-ing the dimensionality of data with neural networks.Science, 313(5786):504?507.G.E.
Hinton, S. Osindero, and Y.W.
Teh.
2006.
A fastlearning algorithm for deep belief nets.
Neural com-putation, 18(7):1527?1554.G.E.
Hinton.
2002.
Training products of experts byminimizing contrastive divergence.
Neural compu-tation, 14(8):1771?1800.G.E.
Hinton.
2012.
A practical guide to training re-stricted boltzmann machines.
Lecture Notes in Com-puter Science, pages 599?619.Minlie Huang, Yi Yang, and Xiaoyan Zhu.
2011.Quality-biased ranking of short texts in microblog-ging services.
In Proceedings of the 5th Internation-al Joint Conference on Natural Language Process-ing, pages 373?382.J.
Jeon, W.B.
Croft, J.H.
Lee, and S. Park.
2006.
Aframework to predict the quality of answers withnon-textual features.
In Proceedings of the 29th an-nual international ACM SIGIR conference on Re-search and development in information retrieval,pages 228?235.
ACM.H.
Lee, R. Grosse, R. Ranganath, and A.Y.
Ng.
2009.Convolutional deep belief networks for scalable un-supervised learning of hierarchical representation-s.
In Proceedings of the 26th Annual InternationalConference on Machine Learning, pages 609?616.J.
Ngiam, A. Khosla, M. Kim, J. Nam, H. Lee, and A.Y.Ng.
2011.
Multimodal deep learning.
In Proceed-ings of the 28th International Conference on Ma-chine Learning (ICML), pages 689?696.R.
Salakhutdinov and G.E.
Hinton.
2009.
Deep boltz-mann machines.
In Proceedings of the internation-al conference on artificial intelligence and statistics,volume 5, pages 448?455.C.
Shah and J. Pomerantz.
2010.
Evaluating and pre-dicting answer quality in community qa.
In Pro-ceeding of the 33rd international ACM SIGIR con-ference on Research and development in informationretrieval, pages 411?418.N.
Srivastava and R. Salakhutdinov.
2012.
Multi-modal learning with deep boltzmann machines.
InAdvances in Neural Information Processing System-s, pages 2231?2239.B.
Wang, X. Wang, C. Sun, B. Liu, and L. Sun.
2010.Modeling semantic relevance for question-answerpairs in web social communities.
In Proceedingsof the 48th Annual Meeting of the Association forComputational Linguistics, pages 1230?1238.
ACL.B.
Wang, B. Liu, X. Wang, C. Sun, and D. Zhang.2011.
Deep learning approaches to semantic rele-vance modeling for chinese question-answer pairs.ACM Transactions on Asian Language InformationProcessing, 10(4):21:1?21:16.Z.M.
Zhou, M. Lan, Z.Y.
Niu, and Y. Lu.
2012.
Ex-ploiting user profile information for answer rankingin cqa.
In Proceedings of the 21st international con-ference on World Wide Web, pages 767?774.
ACM.847
