Proceedings of the 12th Conference of the European Chapter of the ACL, pages 808?816,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsDeriving Generalized Knowledge from Corpora using WordNetAbstractionBenjamin Van Durme, Phillip Michalak and Lenhart K. SchubertDepartment of Computer ScienceUniversity of RochesterRochester, NY 14627, USAAbstractExisting work in the extraction of com-monsense knowledge from text has beenprimarily restricted to factoids that serveas statements about what may possibly ob-tain in the world.
We present an ap-proach to deriving stronger, more generalclaims by abstracting over large sets offactoids.
Our goal is to coalesce the ob-served nominals for a given predicate ar-gument into a few predominant types, ob-tained as WordNet synsets.
The results canbe construed as generically quantified sen-tences restricting the semantic type of anargument position of a predicate.1 IntroductionOur interest is ultimately in building systemswith commonsense reasoning and language un-derstanding abilities.
As is widely appreciated,such systems will require large amounts of gen-eral world knowledge.
Large text corpora arean attractive potential source of such knowledge.However, current natural language understand-ing (NLU) methods are not general and reliableenough to enable broad assimilation, in a formal-ized representation, of explicitly stated knowledgein encyclopedias or similar sources.
As well, suchsources typically do not cover the most obviousfacts of the world, such as that ice cream may bedelicious and may be coated with chocolate, orthat children may play in parks.Methods currently exist for extracting simple?factoids?
like those about ice cream and childrenjust mentioned (see in particular (Schubert, 2002;Schubert and Tong, 2003)), but these are quiteweak as general claims, and ?
being unconditional?
are unsuitable for inference chaining.
Considerhowever the fact that when something is said, itis generally said by a person, organization or textsource; this a conditional statement dealing withthe potential agents of saying, and could enableuseful inferences.
For example, in the sentence,?The tires were worn and they said I had to re-place them?, they might be mistakenly identifiedwith the tires, without the knowledge that sayingis something done primarily by persons, organiza-tions or text sources.
Similarly, looking into thefuture one can imagine telling a household robot,?The cat needs to drink something?, with the ex-pectation that the robot will take into account thatif a cat drinks something, it is usually water ormilk (whereas people would often have broaderoptions).The work reported here is aimed at derivinggeneralizations of the latter sort from large sets ofweaker propositions, by examining the hierarchi-cal relations among sets of types that occur in theargument positions of verbal or other predicates.The generalizations we are aiming at are certainlynot the only kinds derivable from text corpora (asthe extensive literature on finding isa-relations,partonomic relations, paraphrase relations, etc.
at-tests), but as just indicated they do seem poten-tially useful.
Also, thanks to their grounding infactoids obtained by open knowledge extractionfrom large corpora, the propositions obtained arevery broad in scope, unlike knowledge extractedin a more targeted way.In the following we first briefly review themethod developed by Schubert and collaboratorsto abstract factoids from text; we then outline ourapproach to obtaining strengthened propositionsfrom such sets of factoids.
We report positive re-sults, while making only limited use of standard808corpus statistics, concluding that future endeav-ors exploring knowledge extraction and WordNetshould go beyond the heuristics employed in re-cent work.2 KNEXTSchubert (2002) presented an approach to ac-quiring general world knowledge from textcorpora based on parsing sentences and mappingsyntactic forms into logical forms (LFs), thengleaning simple propositional factoids from theseLFs through abstraction.
Logical forms werebased on Episodic Logic (Schubert and Hwang,2000), a formalism designed to accommodate ina straightforward way the semantic phenomenaobserved in all languages, such as predication,logical compounding, generalized quantification,modification and reification of predicates andpropositions, and event reference.
An examplefrom Schubert and Tong (2003) of factoidsobtained from a sentence in the Brown corpus bytheir KNEXT system is the following:Rilly or Glendora had entered her room whileshe slept, bringing back her washed clothes.A NAMED-ENTITY MAY ENTER A ROOM.A FEMALE-INDIVIDUAL MAY HAVE A ROOM.A FEMALE-INDIVIDUAL MAY SLEEP.A FEMALE-INDIVIDUAL MAY HAVE CLOTHES.CLOTHES CAN BE WASHED.
((:I (:Q DET NAMED-ENTITY) ENTER[V](:Q THE ROOM[N]))(:I (:Q DET FEMALE-INDIVIDUAL) HAVE[V](:Q DET ROOM[N]))(:I (:Q DET FEMALE-INDIVIDUAL) SLEEP[V])(:I (:Q DET FEMALE-INDIVIDUAL) HAVE[V](:Q DET (:F PLUR CLOTHE[N])))(:I (:Q DET (:F PLUR CLOTHE[N])) WASHED[A]))Here the upper-case sentences are automaticallygenerated verbalizations of the abstracted LFsshown beneath them.1The initial development of KNEXT was basedon the hand-constructed parse trees in the PennTreebank version of the Brown corpus, but sub-sequently Schubert and collaborators refined andextended the system to work with parse trees ob-tained with statistical parsers (e.g., that of Collins(1997) or Charniak (2000)) applied to larger cor-pora, such as the British National Corpus (BNC),a 100 million-word, mixed genre collection, alongwith Web corpora of comparable size (see work ofVan Durme et al (2008) and Van Durme and Schu-bert (2008) for details).
The BNC yielded over 21Keywords like :i, :q, and :f are used to indicate in-fix predication, unscoped quantification, and function appli-cation, but these details need not concern us here.factoids per sentence on average, resulting in a to-tal collection of several million.
Human judging ofthe factoids indicates that about 2 out of 3 factoidsare perceived as reasonable claims.The goal in this work, with respect to the ex-ample given, would be to derive with the use of alarge collection of KNEXT outputs, a general state-ment such as If something may sleep, it is probablyeither an animal or a person.3 Resources3.1 WordNet and SensesWhile the community continues to make gainsin the automatic construction of reliable, generalontologies, the WordNet sense hierarchy (Fell-baum, 1998) continues to be the resource ofchoice for many computational linguists requiringan ontology-like structure.
In the work discussedhere we explore the potential of WordNet as an un-derlying concept hierarchy on which to base gen-eralization decisions.The use of WordNet raises the challenge ofdealing with multiple semantic concepts associ-ated with the same word, i.e., employing Word-Net requires word sense disambiguation in orderto associate terms observed in text with concepts(synsets) within the hierarchy.In their work on determining selectional prefer-ences, both Resnik (1997) and Li and Abe (1998)relied on uniformly distributing observed frequen-cies for a given word across all its senses, an ap-proach later followed by Pantel et al (2007).2 Oth-ers within the knowledge acquisition communityhave favored taking the first, most dominant senseof each word (e.g., see Suchanek et al (2007) andPas?ca (2008)).As will be seen, our algorithm does not selectword senses prior to generalizing them, but ratheras a byproduct of the abstraction process.
More-over, it potentially selects multiple senses of aword deemed equally appropriate in a given con-text, and in that sense provides coarse-grained dis-ambiguation.
This also prevents exaggeration ofthe contribution of a term to the abstraction, as aresult of being lexicalized in a particularly fine-grained way.3.2 Propositional TemplatesWhile the procedure given here is not tied to aparticular formalism in representing semantic con-2Personal communication809text, in our experiments we make use of proposi-tional templates, based on the verbalizations aris-ing from KNEXT logical forms.
Specifically, aproposition F with m argument positions gener-ates m templates, each with one of the argumentsreplaced by an empty slot.
Hence, the statement,A MAN MAY GIVE A SPEECH, gives rise to twotemplates, A MAN MAY GIVE A , and A MAYGIVE A SPEECH.
Such templates match statementswith identical structure except at the template?sslots.
Thus, the factoid A POLITICIAN MAY GIVEA SPEECH would match the second template.
Theslot-fillers from matching factoids (e.g., MAN andPOLITICIAN form the input lemmas to our abstrac-tion algorithm described below.Additional templates are generated by furtherweakening predicate argument restrictions.
Nounsin a template that have not been replaced by a freeslot can be replaced with an wild-card, indicatingthat anything may fill its position.
While slotsaccumulate their arguments, these do not, serv-ing simply as relaxed interpretive constraints onthe original proposition.
For the running exam-ple we would have; A MAY GIVE A ?, and, A ?MAY GIVE A , yielding observation sets pertain-ing to things that may give, and things that may begiven.3We have not restricted our focus to two-argument verbal predicates; examples such as APERSON CAN BE HAPPY WITH A , and, A CANBE MAGICAL, can be seen in Section 5.4 Deriving TypesOur method for type derivation assumes access toa word sense taxonomy, providing:W : set of words, potentially multi-tokenN : set of nodes, e.g., word senses, or synsetsP : N ?
{N ?}
: parent functionS : W?
(N+) : sense functionL : N ?N?Q?0 : path length functionL is a distance function based on P that givesthe length of the shortest path from a node to adominating node, with base case: L(n, n) = 1.When appropriate, we write L(w, n) to stand forthe arithmetic mean over L(n?, n) for all senses n?3It is these most general templates that best correlate withexisting work in verb argument preference selection; how-ever, a given KNEXT logical form may arise from multipledistinct syntactic constructs.function SCORE (n ?
N , ?
?
R+, C ?W ?
W) :C?
?
D(n) \ CreturnPw?C?
L(w,n)|C?|?function DERIVETYPES (W ?
W , m ?
N+, p ?
(0, 1]) :??
1, C ?
{}, R?
{} while too few words coveredwhile |C| < p?
|W | :n??
argminn?N \RSCORE(n, ?,C)R?R ?
{n?
}C?C ?
D(n?
)if |R| > m : cardinality bound exceeded ?
restart??
?+ ?, C ?
{}, R?
{}return RFigure 1: Algorithm for deriving slot type restrictions, with?
representing a fixed step size.of w that are dominated by n.4 In the definition ofS, (N+) stands for an ordered list of nodes.We refer to a given predicate argument positionfor a specified propositional template simply as aslot.
W ?
W will stand for the set of words foundto occupy a given slot (in the corpus employed),and D : N?W ?
is a function mapping a node tothe words it (partially) sense dominates.
That is,for all n ?
N and w ?
W , if w ?
D(n) thenthere is at least one sense n?
?
S(w) such that n isan ancestor of n?
as determined through use of P .For example, we would expect the word bank to bedominated by a node standing for a class such ascompany as well as a separate node standing for,e.g., location.Based on this model we give a greedy search al-gorithm in Figure 1 for deriving slot type restric-tions.
The algorithm attempts to find a set of dom-inating word senses that cover at least one of eachof a majority of the words in the given set of obser-vations.
The idea is to keep the number of nodes inthe dominating set small, while maintaining highcoverage and not abstracting too far upward.For a given slot we start with a set of observedwords W , an upper bound m on the number oftypes allowed in the result R, and a parameter psetting a lower bound on the fraction of items inWthat a valid solution must dominate.
For example,when m = 3 and p = 0.9, this says we require thesolution to consist of no more than 3 nodes, whichtogether must dominate at least 90% of W .The search begins with initializing the cover setC, and the result set R as empty, with the variable4E.g., both senses of female in WN are dominated by thenode for (organism, being), but have different path lengths.810?
set to 1.
Observe that at any point in the exe-cution of DERIVETYPES, C represents the set ofall words from W with at least one sense havingas an ancestor a node in R. While C continues tobe smaller than the percentage required for a so-lution, nodes are added to R based on whicheverelement of N has the smallest score.The SCORE function first computes the modi-fied coverage of n, setting C ?
to be all words in Wthat are dominated by n that haven?t yet been ?spo-ken for?
by a previously selected (and thus lowerscoring) node.
SCORE returns the sum of the pathlengths between the elements of the modified setof dominated nodes and n, divided by that set?ssize, scaled by the exponent ?.
Note when ?
= 1,SCORE simply returns the average path length ofthe words dominated by n.If the size of the result grows beyond the speci-fied threshold,R andC are reset, ?
is incrementedby some step size ?, and the search starts again.As ?
grows, the function increasingly favors thecoverage of a node over the summed path length.Each iteration of DERIVETYPES thus represents afurther relaxation of the desire to have the returnednodes be as specific as possible.
Eventually, ?will be such that the minimum scoring nodes willbe found high enough in the tree to cover enoughof the observations to satisfy the threshold p, atwhich point R is returned.4.1 Non-reliance on FrequencyAs can be observed, our approach makes no use ofthe relative or absolute frequencies of the words inW , even though such frequencies could be addedas, e.g., relative weights on length in SCORE.
Thisis a purposeful decision motivated both by practi-cal and theoretical concerns.Practically, a large portion of the knowledge ob-served in KNEXT output is infrequently expressed,and yet many tend to be reasonable claims aboutthe world (despite their textual rarity).
For ex-ample, a template shown in Section 5, A MAYWEAR A CRASH HELMET, was supported by justtwo sentences in the BNC.
However, based onthose two observations we were able to concludethat usually If something wears a crash helmet, itis probably a male person.Initially our project began as an application ofthe closely related MDL approach of Li and Abe(1998), but was hindered by sparse data.
We ob-served that our absolute frequencies were often toolow to perform meaningful comparisons of rela-tive frequency, and that different examples in de-velopment tended to call for different trade-offsbetween model cost and coverage.
This was dueas much to the sometimes idiosyncratic structureof WordNet as it was to lack of evidence.5Theoretically, our goal is distinct from relatedefforts in acquiring, e.g., verb argument selec-tional preferences.
That work is based on the de-sire to reproduce distributional statistics underly-ing the text, and thus relative differences in fre-quency are the essential characteristic.
In thiswork we aim for general statements about the realworld, which in order to gather we rely on text asa limited proxy view.
E.g., given 40 hypotheticalsentences supporting A MAN MAY EAT A TACO,and just 2 sentences supporting A WOMAN MAYEAT A TACO, we would like to conclude simplythat A PERSON MAY EAT A TACO, remaining ag-nostic as to relative frequency, as we?ve no reasonto view corpus-derived counts as (strongly) tied tothe likelihood of corresponding situations in theworld; they simply tell us what is generally possi-ble and worth mentioning.5 Experiments5.1 Tuning to WordNetOur method as described thus far is not tied to aparticular word sense taxonomy.
Experiments re-ported here relied on the following model adjust-ments in order to make use of WordNet (version3.0).The function P was set to return the union ofa synset?s hypernym and instance hypernym rela-tions.Regarding the function L , WordNet is con-structed such that always picking the first senseof a given nominal tends to be correct more of-ten than not (see discussion by McCarthy et al(2004)).
To exploit this structural bias, we em-ployed a modified version of L that results ina preference for nodes corresponding to the firstsense of words to be covered, especially when thenumber of distinct observations were low (such asearlier, with crash helmet):L(n, n) ={1?
1|W | ?w ?W : S(w) = (n, ...)1 otherwise5For the given example, this method (along with the con-straints of Table 1) led to the overly general type, living thing.811word # glossabstraction 6 a general concept formed by extracting common features from specific examplesattribute 2 an abstraction belonging to or characteristic of an entitymatter 3 that which has mass and occupies spacephysical entity 1 an entity that has physical existencewhole 2 an assemblage of parts that is regarded as a single entityTable 1: ?word, sense #?
pairs in WordNet 3.0 considered overly general for our purposes.Propositional Template Num.A CAN BE WHISKERED 4GOVERNORS MAY HAVE -S 4A CAN BE PREGNANT 28A PERSON MAY BUY A 105A MAY BARK 6A COMPANY MAY HAVE A 713A MAY SMOKE 8A CAN BE TASTY 33A SONG MAY HAVE A 31A CAN BE SUCCESSFUL 664CAN BE AT A ROAD 20A CAN BE MAGICAL 96CAN BE FOR A DICTATOR 5MAY FLOAT 5GUIDELINES CAN BE FOR -S 4A MAY WEAR A CRASH HELMET 2A MAY CRASH 12Table 2: Development templates, paired with the number ofdistinct words observed to appear in the given slot.Note that when |W | = 1, then L returns 0 forthe term?s first sense, resulting in a score of 0 forthat synset.
This will be the unique minimum,leading DERIVETYPES to act as the first-senseheuristic when used with single observations.Parameters were set for our data based on man-ual experimentation using the templates seen inTable 2.
We found acceptable results when us-ing a threshold of p = 70%, and a step size of?
= 0.1.
The cardinality bound m was set to 4when |W | > 4, and otherwise m = 2.In addition, we found it desirable to add a fewhard restrictions on the maximum level of general-ity.
Nodes corresponding to the word sense pairsgiven in Table 1 were not allowed as abstractioncandidates, nor their ancestors, implemented bygiving infinite length to any path that crossed oneof these synsets.5.2 Observations during DevelopmentOur method assumes that if multiple words occur-ring in the same slot can be subsumed under thesame abstract class, then this information shouldbe used to bias sense interpretation of these ob-served words, even when it means not picking thefirst sense.
In general this bias is crucial to our ap-proach, and tends to select correct senses of thewords in an argument set W .
But an examplewhere this strategy errs was observed for the tem-plate A MAY BARK, which yielded the general-ization that If something barks, then it is proba-bly a person.
This was because there were numer-ous textual occurrences of various types of people?barking?
(speaking loudly and aggressively), andso the occurrences of dogs barking, which showedno type variability, were interpreted as involvingthe unusual sense of dog as a slur applied to cer-tain people.The template, A CAN BE WHISKERED, hadobservations including both face and head.
Thisprompted experiments in allowing part holonymrelations (e.g., a face is part of a head) as partof the definition of P , with the final decision be-ing that such relations lead to less intuitive gen-eralizations rather than more, and thus these re-lation types were not included.
The remainingrelation types within WordNet were individuallyexamined via inspection of randomly selected ex-amples from the hierarchy.
As with holonyms wedecided that using any of these additional relationtypes would degrade performance.A shortcoming was noted in WordNet, regard-ing its ability to represent binary valued attributes,based on the template, A CAN BE PREGNANT.While we were able to successfully generalize tofemale person, there were a number of words ob-served which unexpectedly fell outside that asso-ciated synset.
For example, a queen and a duchessmay each be a female aristocrat, a mum may be afemale parent,6 and a fiancee has the exclusive in-terpretation as being synonymous with the genderentailing bride-to-be.6 ExperimentsFrom the entire set of BNC-derived KNEXTpropositional templates, evaluations were per-formed on a set of 21 manually selected examples,6Serving as a good example of distributional preferencing,the primary sense of mum is as a flower.812Propositional Template Num.A MAY HAVE A BROTHER 28A ?
MAY ATTACK A 23A FISH MAY HAVE A 38A CAN BE FAMOUS 665A ?
MAY ENTERTAIN A 8A MAY HAVE A CURRENCY 18A MALE MAY BUILD A 42A CAN BE FAST-GROWING 15A PERSON MAY WRITE A 47A ?
MAY WRITE A 99A PERSON MAY TRY TO GET A 11A ?
MAY TRY TO GET A 17A MAY FALL DOWN 5A PERSON CAN BE HAPPY WITH A 36A ?
MAY OBSERVE A 38A MESSAGE MAY UNDERGO A 14A ?
MAY WASH A 5A PERSON MAY PAINT A 8A MAY FLY TO A ?
9A ?
MAY FLY TO A 4A CAN BE NERVOUS 131Table 3: Templates chosen for evaluation.together representing the sorts of knowledge forwhich we are most interested in deriving strength-ened argument type restrictions.
All modificationof the system ceased prior to the selection of thesetemplates, and the authors had no knowledge ofthe underlying words observed for any particularslot.
Further, some of the templates were purpose-fully chosen as potentially problematic, such as, A?
MAY OBSERVE A , or A PERSON MAY PAINTA .
Without additional context, templates suchas these were expected to allow for exceptionallybroad sorts of arguments.For these 21 templates, 65 types were derived,giving an average of 3.1 types per slot, and allow-ing for statements such as seen in Table 4.One way in which to measure the quality of anargument abstraction is to go back to the under-lying observed words, and evaluate the resultantsense(s) implied by the chosen abstraction.
We saysenses plural, as the majority of KNEXT propo-sitions select senses that are more coarse-grainedthan WordNet synsets.
Thus, we wish to evaluatethese more coarse-grained sense disambiguationresults entailed by our type abstractions.7 We per-formed this evaluation using as comparisons thefirst-sense, and all-senses heuristics.The first-sense heuristic can be thought of asstriving for maximal specificity at the risk of pre-cluding some admissible senses (reduced recall),7Allowing for multiple fine-grained senses to be judgedas appropriate in a given context goes back at least to Sussna(1993); discussed more recently by, e.g., Navigli (2006).while the all-senses heuristic insists on includingall admissible senses (perfect recall) at the risk ofincluding inadmissible ones.Table 5 gives the results of two judges evaluat-ing 314 ?word, sense?
pairs across the 21 selectedtemplates.
These sense pairs correspond to pick-ing one word at random for each abstracted typeselected for each template slot.
Judges were pre-sented with a sampled word, the originating tem-plate, and the glosses for each possible word sense(see Figure 2).
Judges did not know ahead of timethe subset of senses selected by the system (as en-tailed by the derived type abstraction).
Taking thejudges?
annotations as the gold standard, we reportprecision, recall and F-score with a ?
of 0.5 (favor-ing precision over recall, owing to our preferencefor reliable knowledge over more).In all cases our method gives precision resultscomparable or superior to the first-sense heuristic,while at all times giving higher recall.
In partic-ular, for the case of Primary type, correspondingto the derived type that accounted for the largestnumber of observations for the given argumentslot, our method shows strong performance acrossthe board, suggesting that our derived abstractionsare general enough to pick up multiple acceptablesenses for observed words, but not so general as toallow unrelated senses.We designed an additional test of our method?sperformance, aimed at determining whether thedistinction between admissible senses and inad-missible ones entailed by our type abstractionswere in accord with human judgement.
To thisend, we automatically chose for each templatethe observed word that had the greatest num-ber of senses not dominated by a derived typeA MAY HAVE A BROTHER1 WOMAN : an adult female person (as opposed to aman); ?the woman kept house while the man hunted?2 WOMAN : a female person who plays a significantrole (wife or mistress or girlfriend) in the life of a partic-ular man; ?he was faithful to his woman?3 WOMAN : a human female employed to do house-work; ?the char will clean the carpet?
; ?I have a womanwho comes in four hours a day while I write?
*4WOMAN : women as a class; ?it?s an insult to Amer-ican womanhood?
; ?woman is the glory of creation?
;?the fair sex gathered on the veranda?Figure 2: Example of a context and senses provided forevaluation, with the fourth sense being judged as inappropri-ate.813If something is famous, it is probably a person1, an artifact1, or a communication2If ?
writes something, it is probably a communication2If a person is happy with something, it is probably a communication2, a work1, a final result1, or a state of affairs1If a fish has something, it is probably a cognition1, a torso1, an interior2, or a state2If something is fast growing, it is probably a group1 or a business3If a message undergoes something, it is probably a message2, a transmission2, a happening1, or a creation1If a male builds something, it is probably a structure1, a business3, or a group1Table 4: Examples, both good and bad, of resultant statements able to be made post-derivation.
Authors manually selectedone word from each derived synset, with subscripts referring to sense number.
Types are given in order of support, and thus thefirst are examples of ?Primary?
in Table 5.Method?j?j TypePrec Recall F.5 Prec Recall F.5derived 80.2 39.2 66.4 61.5 47.5 58.1Allfirst 81.5 28.5 59.4 63.1 34.7 54.2all 59.2 100.0 64.5 37.6 100.0 42.9derived 90.0 50.0 77.6 73.3 71.0 72.8Primaryfirst 85.7 33.3 65.2 66.7 45.2 60.9all 69.2 100.0 73.8 39.7 100.0 45.2Table 5: Precision, Recall and F-score (?
= 0.5) for coarse grained WSD labels using the methods: derive from corpus data,first-sense heuristic and all-sense heuristic.
Results are calculated against both the unionSj and intersectionTj of manualjudgements, calculated for all derived argument types, as well as Primary derived types exclusively.THE STATEMENT ABOVE IS A REASONABLYCLEAR, ENTIRELY PLAUSIBLE GENERALCLAIM AND SEEMS NEITHER TOO SPECIFICNOR TOO GENERAL OR VAGUE TO BE USEFUL:1.
I agree.2.
I lean towards agreement.3.
I?m not sure.4.
I lean towards disagreement.5.
I disagree.Figure 3: Instructions for evaluating KNEXT propositions.restriction.
For each of these alternative (non-dominated) senses, we selected the ancestor ly-ing at the same distance towards the root from thegiven sense as the average distance from the dom-inated senses to the derived type restriction.
Inthe case where going this far from an alternativesense towards the root would reach a path passingthrough the derived type and one of its subsumedsenses, the distance was cut back until this was nolonger the case.These alternative senses, guaranteed to not bedominated by derived type restrictions, were thenpresented along with the derived type and theoriginal template to two judges, who were giventhe same instructions as used by Van Durme andSchubert (2008), which can be found in Figure 3.Results for this evaluation are found in Table 6,where we see that the automatically derived typerestrictions are strongly favored over alternativejudge 1 judge 2 corrderived 1.76 2.10 0.60alternative 3.63 3.54 0.58Table 6: Average assessed quality for derived and alterna-tive synsets, paired with Pearson correlation values.abstracted types that were possible based on thegiven word.
Achieving even stronger rejection ofalternative types would be difficult, since KNEXTtemplates often provide insufficient context forfull disambiguation of all their constituents, andjudges were allowed to base their assessments onany interpretation of the verbalization that theycould reasonably come up with.7 Related WorkThere is a wealth of existing research focused onlearning probabilistic models for selectional re-strictions on syntactic arguments.
Resnik (1993)used a measure he referred to as selectional pref-erence strength, based on the KL-divergence be-tween the probability of a class and that classgiven a predicate, with variants explored by Ribas(1995).
Li and Abe (1998) used a tree cut modelover WordNet, based on the principle of MinimumDescription Length (MDL).
McCarthy has per-formed extensive work in the areas of selectional814preference and WSD, e.g., (McCarthy, 1997; Mc-Carthy, 2001).
Calling the generalization problema case of engineering in the face of sparse data,Clark and Weir (2002) looked at a number of pre-vious methods, one conclusion being that the ap-proach of Li and Abe appears to over-generalize.Cao et al (2008) gave a distributional methodfor deriving semantic restrictions for FrameNetframes, with the aim of building an ItalianFrameNet.
While our goals are related, their workcan be summarized as taking a pre-existing goldstandard, and extending it via distributional simi-larity measures based on shallow contexts (in thiscase, n-gram contexts up to length 5).
We havepresented results on strengthening type restrictionson arbitrary predicate argument structures deriveddirectly from text.In describing ALICE, a system for lifelonglearning, Banko and Etzioni (2007) gave a sum-mary of a proposition abstraction algorithm devel-oped independently that is in some ways similarto DERIVETYPES.
Beyond differences in nodescoring and their use of the first sense heuristic,the approach taken here differs in that it makes nouse of relative term frequency, nor contextual in-formation outside a particular propositional tem-plate.8 Further, while we are concerned with gen-eral knowledge acquired over diverse texts, AL-ICE was built as an agent meant for construct-ing domain-specific theories, evaluated on a 2.5-million-page collection of Web documents per-taining specifically to nutrition.Minimizing word sense ambiguity by focus-ing on a specific domain was later seen in thework of Liakata and Pulman (2008), who per-formed hierarchical clustering using output fromtheir KNEXT-like system first described in (Li-akata and Pulman, 2002).
Terminal nodes of theresultant structure were used as the basis for in-ferring semantic type restrictions, reminiscent ofthe use of CBC clusters (Pantel and Lin, 2002) byPantel et al (2007), for typing the arguments ofparaphrase rules.Assigning pre-compiled instances to their first-sense reading in WordNet, Pas?ca (2008) then gen-eralized class attributes extracted for these terms,using as a resource Google search engine querylogs.Katrenko and Adriaans (2008) explored a con-8Banko and Etzioni abstracted over subsets of pre-clustered terms, built using corpus-wide distributional fre-quenciesstrained version of the task considered here.
Usingmanually annotated semantic relation data fromSemEval-2007, pre-tagged with correct argumentsenses, the authors chose the least common sub-sumer for each argument of each relation consid-ered.
Our approach keeps with the intuition ofpreferring specific over general concepts in Word-Net, but allows for the handling of relations au-tomatically discovered, whose arguments are notpre-tagged for sense and tend to be more wide-ranging.
We note that the least common sub-sumer for many of our predicate arguments wouldin most cases be far too abstract.8 ConclusionAs the volume of automatically acquired knowl-edge grows, it becomes more feasible to abstractfrom existential statements to stronger, more gen-eral claims on what usually obtains in the realworld.
Using a method motivated by that usedin deriving selectional preferences for verb argu-ments, we?ve shown progress in deriving semantictype restrictions for arbitrary predicate argumentpositions, with no prior knowledge of sense in-formation, and with no training data other than ahandful of examples used to tune a few simple pa-rameters.In this work we have made no use of rela-tive term counts, nor corpus-wide, distributionalfrequencies.
Despite foregoing these often-usedstatistics, our methods outperform abstractionbased on a strict first-sense heuristic, employed inmany related studies.Future work may include a return to the MDLapproach of Li and Abe (1998), but using a fre-quency model that ?corrects?
for the biases in textsrelative to world knowledge ?
for example, cor-recting for the preponderance of people as sub-jects of textual assertions, even for verbs like bark,glow, or fall, which we know to be applicable tonumerous non-human entities.Acknowledgements Our thanks to MatthewPost and Mary Swift for their assistance in eval-uation, and Daniel Gildea for regular advice.
Thisresearch was supported in part by NSF grants IIS-0328849 and IIS-0535105, as well as a Universityof Rochester Provost?s Multidisciplinary Award(2008).815ReferencesMichele Banko and Oren Etzioni.
2007.
Strategies for Life-long Knowledge Extraction from the Web.
In Proceedingsof K-CAP.BNC Consortium.
2001.
The British National Corpus, ver-sion 2 (BNC World).
Distributed by Oxford UniversityComputing Services.Diego De Cao, Danilo Croce, Marco Pennacchiotti, andRoberto Basili.
2008.
Combining Word Sense and Us-age for Modeling Frame Semantics.
In Proceedings ofSemantics in Text Processing (STEP).Eugene Charniak.
2000.
A Maximum-Entropy-InspiredParser.
In Proceedings of NAACL.Stephen Clark and David Weir.
2002.
Class-based probabil-ity estimation using a semantic hierarchy.
ComputationalLinguistics, 28(2).Michael Collins.
1997.
Three Generative, Lexicalised Mod-els for Statistical Parsing.
In Proceedings of ACL.Christiane Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
MIT Press.Sophia Katrenko and Pieter Adriaans.
2008.
SemanticTypes of Some Generic Relation Arguments: Detectionand Evaluation.
In Proceedings of ACL-HLT.Hang Li and Naoki Abe.
1998.
Generalizing case framesusing a thesaurus and the MDL principle.
ComputationalLinguistics, 24(2).Maria Liakata and Stephen Pulman.
2002.
From Trees toPredicate Argument Structures.
In Proceedings of COL-ING.Maria Liakata and Stephen Pulman.
2008.
Automatic Fine-Grained Semantic Classification for Domain Adaption.
InProceedings of Semantics in Text Processing (STEP).Diana McCarthy, Rob Koeling, Julie Weeds, and John Car-roll.
2004.
Using automatically acquired predominantsenses for Word Sense Disambiguation.
In Proceedingsof Senseval-3: Third International Workshop on the Eval-uation of Systems for the Semantic Analysis of Text.Diana McCarthy.
1997.
Estimation of a probability distribu-tion over a hierarchical classification.
In The Tenth WhiteHouse Papers COGS - CSRP 440.Diana McCarthy.
2001.
Lexical Acquisition at the Syntax-Semantics Interface: Diathesis Alternations, Subcatego-rization Frames and Selectional Preferences.
Ph.D. the-sis, University of Sussex.Roberto Navigli.
2006.
Meaningful Clustering of SensesHelps Boost Word Sense Disambiguation Performance.
InProceedings of COLING-ACL.Marius Pas?ca.
2008.
Turning Web Text and Search Queriesinto Factual Knowledge: Hierarchical Class Attribute Ex-traction.
In Proceedings of AAAI.Patrick Pantel and Dekang Lin.
2002.
Discovering WordSenses from Text.
In Proceedings of KDD.Patrick Pantel, Rahul Bhagat, Bonaventura Coppola, TimothyChklovski, and Eduard Hovy.
2007.
ISP: Learning Infer-ential Selectional Preferences.
In Proceedings of NAACL-HLT.Philip Resnik.
1993.
Selection and Information: A Class-Based Approach to Lexical Relationships.
Ph.D. thesis,University of Pennsylvania.Philip Resnik.
1997.
Selectional preference and sense dis-ambiguation.
In Proceedings of the ACL SIGLEX Work-shop on Tagging Text with Lexical Semantics: Why, What,and How?Francesc Ribas.
1995.
On learning more appropriate Selec-tional Restrictions.
In Proceedings of EACL.Lenhart K. Schubert and Chung Hee Hwang.
2000.
EpisodicLogic meets Little Red Riding Hood: A comprehensive,natural representation for language understanding.
InL.
Iwanska and S.C. Shapiro, editors, Natural LanguageProcessing and Knowledge Representation: Languagefor Knowledge and Knowledge for Language.
MIT/AAAIPress.Lenhart K. Schubert and Matthew H. Tong.
2003.
Extractingand evaluating general world knowledge from the browncorpus.
In Proceedings of HLT/NAACL Workshop on TextMeaning, May 31.Lenhart K. Schubert.
2002.
Can we derive general worldknowledge from texts?
In Proceedings of HLT.Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum.2007.
YAGO: A Core of Semantic Knowledge UnifyingWordNet and Wikipedia.
In Proceedings of WWW.Michael Sussna.
1993.
Word sense disambiguation for free-text indexing using a massive semantic network.
In Pro-ceedings of CIKM.Benjamin Van Durme and Lenhart Schubert.
2008.
OpenKnowledge Extraction through Compositional LanguageProcessing.
In Proceedings of Semantics in Text Process-ing (STEP).Benjamin Van Durme, Ting Qian, and Lenhart Schubert.2008.
Class-driven Attribute Extraction.
In Proceedingsof COLING.816
