Deriving Transfer Rules from Dominance-Preserving AlignmentsAdam Meyers ,  Roman Yangarber ,  Ra lph  Gr i shman,Cather ine  Mac leod ,  Anton io  Moreno-Sandova l  tNew York University715 Broadway, 7th Floor, NY, NY 10003, USAtUniversidad Aut6noma de MadridCantoblanco, 28049-Madrid, SPAINmeyers/roman/grishman/macleod?cs, nyu.
edusandoval?lola, lllf.
uam.
es1 In t roduct ionAutomatic acquisition of translation rules fromparallel sentence-aligned text takes a variety offorms.
Some machine translation (MT) systemstreat aligned sentences as unstructured word se-quences.
Other systems, including our own ((Gr-ishman, 1994) and (Meyers et al, 1996)), syn-tactically analyze sentences (parse) before ac-quiring transfer rules (cf.
(Kaji et hi., 1992),(Matsumoto et hi., 1993), and (Kitamura andMatsumoto, 1995)).
This has the advantage ofacquiring structural as well as lexical correspon-dences.
A syntactically analyzed, aligned cor-pus may serve as an example base for a form ofexample-based NIT (cf.
(Sato and Nagao, 1990),(l(aji et al, 1992), and (Furuse and Iida.
1994)).This paper 1 describes: (1) an efficient algo-rithm for aligning a pair of source/target lan-guage parse trees; and (9) a procedure for de-riving transfer ules from this alignment.
Eachtransfer ule consists of a pair of tree fragmentsderived by "cutting up" the source and targettrees.
A set of transfer rules whose left-handsides match a source language parse tree is usedto generate a target language parse tree fromtheir set of right-hand sides, which is a transla-tion of the source tree.
This technique resembleswork on NIT using synchronous Tree-AdjoiningGrammars (cf.
(Abeille et al.
1990)).The Proteus translation system learns transferrules from pairs of aligned source and target reg-ularized parses, Proteus's representation f pred-icate argument structure (cf.
Figure 1).
2 Thenit uses these transfer rules to map source tan-l We thank Cristina Olmeda Moreno for work on pars-ing our Spanish text.
This research was supported byNational Science Fotmdation Grant IRI-9303013.2Regularized parses (henceforth, "parse trees") arelike F-structures of Lexical Ftmction Grammar (LFG),except, hat a dependency structure is used.
"guage regularized parses generated by our sourcelanguage parser into target language regularizedparses.
Finally a generator converts target reg-ularized parses into target language sentences.An alignment f is a 1-to-1 partial mappingfrom source nodes to target nodes.
We con-sider only alignments which preserve the dom-inance relationship: If node a dominates nodeb in the source tree, then f (a)  dominates f(b)in the target ree.
In Figure 1. source nodes .4.B, C and D map to the corresponding targetnodes, marked with a prime, e.g., f (A )  = A'.The alignment may be represented by the set{(d, A'), (B, B'), (C, C'), (D, D')}.
We can as-sign a score to each alignment f,  based on the(weighted) number of pairs in f; finding the bestalignment ranslates into finding the alignmentwith the highest score.
Our algorithms are basedon (Farach et al, 1995) and related work.We needed efficient alignment algorithms be-cause: (1) Corpus-based training requires pro-cessing a lot of text; and (2) An exhaustivesearch of all alignments i  too computationallyexpensive for realistically sized parse trees.Eliminating dominance violations greatly re-duced our search space.
Similar work (e.g.,(Matsumoto et hi., 1993)) considers all possiblematches.
Although.
our system cannot accountfor actual dominance violations in a given bi-text, there are no such violations in our corpusand many hypothetical cases can be avoided byadopting the appropriate grammar.
Cases of ad-juncts aligning with heads and vice versa are notdominance violations if we replace our depen-dency analysis with one in which internal nodeshave category labels and the head constituentsare marked by HEAD arcs and we assume thefollowing Categorial Grammar (CG) style anal-yses.
Suppose that verb (Vi) maps to adverb(A'I) and adverb (A2) maps to verb (V'2), where843SourceTree Target Tree("'D= voiver ~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
"~.
.
.
.
.
iiiiiiii: ......................Excel vuelve a calcular valores en libro de trabajo Excel recalculates values in workbookFigure l: A Pair of Aligned TreesA2 modifies V1 and A' l  modifies V'2.
We as-sume the following structures: \[VP \[VP1 V1 ...\]A2\] and \[VP \[VP2 V '2 .
.
.
\ ]  A'I\].
No dominanceviolation exists because no dominance relationholds between VI and A2 or V'2 and A'L Y.Matsumoto (p.c.)
notes that the subordinateclause of a source sentence may align with themain clause of a target language and vice versa,e.g., X after Y aligns with Y' before X'.
whereX, X', Y and Y' are all clauses.
Assuming a CGstyle analysis, \[S X \[after Y\]\] aligns with \[S Y"\[before X'\]\] with no dominance violations.2 The  Least -Common-AncestorConst ra in tOur earlier tree alignment algorithms (cf.
(Mey-ers et al, 1996)) were designed to produce align-ments which preserve the least common ancestorrelationship: If nodes a and b map into nodesa' = f(a) and b' = f(b), then f (LCA(a,b))  =LCA(f(a) ,  f(b)) = LCA(a', b').
The least com-mon ancestor (LCA) of a and b is the lowest nodein the tree dominating both a and b.
The LCA-preserving approach imposes limitations on thequality of the resulting alignments.
\[n Figure 1,the LCA-preserving algorithm will match nodeE with node D' and report that as the best matchoverall.
The score S(D; D'I would take into ac-count only the match (E, D~), which in turn in-cludes (B, B') and (C, C').
(S(D, D') would bepenalized for collapsing the arc from D to E.)We seek a better alignment scheme, in whichthe score S(D, D') could benefit from S(A, A').We are willing to pay a small penalty to collapsethe path from D to E, and align the resultingstructure.
This leads to new algorithms wherethe LeA-preserving restriction is replaced by theweaker, dominance-preserving constraint.
Therationale behind allowing an edge, say (v, u) tobe collapsed when matching two nodes v and v ~,is that we may find some children of u which cor-respond well to some children of v', while otherchildren of v correspond well to other children ofv'.
(This is not possible if LCA's are preserved.
)The algorithm relies on the assumption that twodifferent children of v will not match well withthe same child of v'.3 The  Dominance-Preserv ingA lgor i thmLet T and T' be the source and the target trees.We use a dynamic programming algorithm tocompute, in a bottom-up fashion, the scores formatching each node in T against each node in T'.There are O(n 2) such scores, n = max(IT\[, IT'\])is number of nodes in the trees.
Let the d(v) bethe degree of a node v. We denote children of uby vi, i = 1,. .
.
,  d(v), and arc (v, v{) by if{.For all pairs of nodes v E T and v' E T', thealgorithm computes the score function S(v, v').S(v, v ~) corresponds to the best match found be-tween the subtrees rooted at v in T and at v ~ inT'.
The values of S are stored in a.
\[T\[ x IT' I ma-trix, also denoted by S. \[nitially, we fill the ma-trix S with undefined values, and invoke the pro-cedure SCOREdom, described below, to com-pute S(root(T), root(T')), the score for matchingthe root nodes of the trees.
During the compu-tation of the score for the roots, the procedurerecursively finds the best-scoring matches for allthe nodes in the trees.
This yields the best align-ment of the entire trees.Table l(a) shows the values of S for the treesin Figure 1.
Whenever we compute a score fox"internal nodes, we also record the best way ofpairing up their children in Table l(b).
3 The3 Children pairings include child/child pairs and par-ent/child pairs: (D.D')'s pairing is {(A, A'), (E, D')}.844alignment, implicit in these children pairings, isused in a later phase (Section 4) to recover thealignment for the entire trees.P rocedure  SCOREdorn: For a pair of nodes,(v, v~), recursively compute the score S(v, v'):Construct an intermediate child-scoring ma-trix M = M(v, v'), for the children of v and v~;the dimensions of M are (d(v) + i) x (d(v') + t).That is, the number of rows in M is one morethan the number of children of v, and the numberof columns is one more than number of childrenof v ?.
V~re label row d(v) + 1 and column d(v ~) + 1with a "*".
Fill the matrix M:1.
Vi, j, where 1 <_ i <_ d(v),t  < j <_ d(?
)compute the corresponding entry in Mij:The function Lex,~od~.
(v,v ~) >_ 0 (used be-low) is the quality of translation, i.e.
themeasure of how closely the label (word) atsource node v corresponds to the label attarget node v ~ in the bilingual dictionary,and Lex~c( ff, ff~) >__ 0 is the correspondingmeasure for arc labels.2.
Fill the last column as follows: Vi, wheret <_ i < d(v) compute the entries:Mi.
= S(vi, v') - Pen(ffi)Pen(ffi) >_ 0 is the penalty for collapsing theedge ffi, which depends on the value of thelabel of that edge.3.
Symmetrically, Vj s.t.
t _< j <_d(v ~) fill the last row with the entries:M.j = S(v, v;) - Pen(~; )4.
The entry M..  is disfavored: ~,'l~.
= -~cFor example, during the calculation of thescores S(D, D') and S(E, D') from Table t; thecorresponding matrices M(D, D ~) and M(E,  D t)are filled in as in Table 2.
The proper values forthe parameter functions used above, such as thepenalty function Pen and the translation inea-sures, are chosen empirically, and constitute thetunable parameters of the procedure.
Normally,we will expect hat the values of Lexr, ode will bemuch larger than the values of Lex~rc and Pen.In the example we used the following settings:1.
Lexnode = 100 for an exact translation, as for(,4, .4'), (B, B t) and (C, C'), and 0 otherwise.2.
all values of Lex~c are set to zero3.
all penalties Pen are set to 1Now, using the values in M, compute the scorefor matching v and ?
:S(v, v') = Lex,~od~(V, v') + max ~ iYI~j (1)PEEP (i,j)EPHere P is a legitimate pairing of v and its chil-dren against v' and its children.
A legitimatepairing P is a set of elements of the matrix M.that conform to the following conditions:1. each row and each column of M may con-tribute at most one element to P, exceptthat the row and the column labeled * maycontribute more than one element o P2.
if P contains an element Mij correspond-ing to the node pair (w. w'), and some childnode u appears in the Children-Pairing for(w, w'), then the row or column of u maynot contribute any elements to P.We use/.7 ) = ?7)(v. v') to denote the set of alllegitimate pairings.
There are O(d!)
such pair-ings, where d is the greater of the degrees of uand v'.
The summation in (l) ranges over allthe pairs (i, j)  that appear in a legitimate pair-ing P E /.7)(v, v').
We evaluate this summationfor all O(d!)
legitimate pairings in/.7), and thenselect the pairing Pbe~t with the maximum score.Pbest is then stored in the Children-Pairing ma-trix entry for (v, v').Table 2 shows how scores are calculated.
Thebest score for S(E, D ~) is 200, the sum of thescores for (B,B')  and (C,C').
S(D.D')  =299 = S(A, A') + S(E,  D') - t, a penalty of tfor collapsing the edge from D to E.We can reduce the computation time of themax term in (1), if we do not consider all O(d!
)pairings of the children of v and v'.
Insteadof exhaustively computing the maximal-scoringpairing Pbest in (t), we can build it in a greedyfashion: successively choos the d highest-scoring,mutually disjoint pairs from the O(d 2) possiblepairs of children of v and v'.1.
Initialize the set of highest scoring pairsPb,=~t e- 02.
Phi.st e- Pbestu{ (i, j) } where Mij is the nextlargest entry in the matrix, which that sat-isfies both conditions 1 and 2 of legitimatepairings845SourceNodesTarget NodesA '  B '  C" D'  A 'A 100 0 0 0 AB 0 100  0 0 BC 0 0 t00 0 Source CD 0 0 0 299 Nodes DE 0 0 0 2OO EF 0 0 0 0 FTarget NodesB '  C '  D'- (d, A')(E, D')- (B,  B ' ) (C ,  C')Table 1: (a) A Final Score Matrix; (b) Children-Pairing MatrixSourceChil-dre nTarget Childrent: A' 2: B' 3: C' *: D't: B 0 100 0 992: C 0 0 100 99*: E 0 99 99 -~The Score S( t = tO0+ tO0 -- 200SourceChil-drenTarget Children1: A' 2: B' 3: C' *: D'1: A 100 0 0 992: E 0 99 99 199*: D 99 98 98 -ocThe Score S(  = t99+ 100 = 299Table 2: Computing Child-Scoring Matrices3.
Repeat the above step until no more pairscan be added to Pbest, at most d times.where d = min(d(v), d(vl)).4.
Compute the result:S(V, Y') -- LeZnode(V. V') -4:- ~(i,j)ePb,.~, :tiiJThe greedy algorithm aligns trees with nnodes and maximal degree d in O(n2d 2) time.4 Acqu i r ing  Trans fer  Ru lesThis section describes the procedure for derivingtransfer ules from aligned parse trees.First, the best-scoring alignment is recoveredfrom the Children-Pairing matrix, (Table t(b)).
4Start by including the root node-pair in thealignment, (here (D, DI)).
Then, for each pair(v, v ~) already in the alignment, repeat the fol-lowing steps, until no more pairs can be added tothe alignment: (t) look up the Children:Pairingfor (v.v') ;  (2) for each pair in the children-pairing, if it does not include either v or v ~, addthe pair to the alignment, (e.g.
(A, At), etc.
).4When sentences in the bitext have multiple parses,we align structure sharing forests of trees.
If one pairof trees has the highest scoring alignment, we acquiretransfer ules from that alignment.
When more than onepair of trees tie for the highest score, we acquire transferrules from the set of pairs of aligned subtrees which areshared by each of these high scoring alignments.In the running example, the final align-ment (FA) is  {(D, D'), (A, A'), (B, S'), (C, C')}.Based on this alignment we can "chop up" thetrees into fragments, or substructures ((Mat-sumoto et hi., 1993)), where each substructureof a tree is a connected group of nodes in thetree, together with their joining arcs.
In Fig-ure i, dashed arrows connect aligned pairs ofsource and target substructures.
These corre-spondences become our transfer ules.For each pair of aligned nodes (v, v') in FA,there is a pair of substructures in Figure t suchthat v and v ~ are the roots of the source and tar-get substructures.
These substructures includeall unaligned source and target nodes v~ and' below v and v', which have no intervening V ualigned nodes y or y' dominating v, or v~u.The transfer rules derived from Figure t maybe written as follows:1.
< root : Exce l  > --+ < root : Exce l  >2.
< root : va lores  > ~ < root : va lues  >3.
< root : libro, de : t raba jo  > -+ < root :workbook  >4.
< root : volver,  sub j  : x l ,a  :< root :calcular,  obj : x2, en : x3 > >< root : reca lcu la te ;sub j  : T r (x l ) ,ob j  :T r (x2) ,  in : T r (x3)  >Each substructure is represented as a list con-846taining a root lexical item, and a set of arc-value pairs.
An arc (role) al with head (value)h is written as al : h, where h is a fixed la-bel (word), a substructure or a variable.
If thesource substructure has n of the leaves labeledwith variables xl, ?
?., x~, the target will haven of the leaves labeled with Tr(xl),..., Tr(x~),where Tr(x) is the texical translation function.This general structure allows us to capture re-lations between multi-word expressions in thesource and target languages.5 T rans la t ionThe described procedure for acquisition of trans-fer rules from corpora is the basis for our trans-lation system.
A large collection of transfer ulesare collected from a training corpus.
When newtext is to be translated, it is first parsed.
Thesource tree is matched against he left hand sidesof the transfer rules which have been collected.If a set of transfer rules whose left-hand sidesmatch the parse tree is found, the correspondingtarget structure is generated from the right handsides of these transfer rules.
Typically, severalsets of transfer rules meet this criterion.
Theyare ranked by their frequency in the training cor-pus.
Once a target tree has been produced, it isconverted to a word sequence by a target lan-guage generator.
We have applied this approachto the translation of Microsoft Help files in En-glish and Spanish.
The sentences are moderatelysimple and quite parallel in structure, which hasmade the corpus suitable for our initial systemdevelopment.
To date, we have been using atraining corpus of about 1,000 sentences, and atest corpus of about 100 sentences.6 Eva luat ionReal evaluation of performance of MT systemsis time consuming and subjective.
Neverthe-less, some evaluation system is needed to insurethat incremental changes are for the better, orat least, are not detrimental.
We measured thesuccess of our translation by how closely we re-produced Microsoft's English (target language)text.
Our evaluation procedure computes theratio between (a) the complement of the inter-section set of words in our translation and theactual Microsoft sentence; and (b) the combinedlengths of these two sentences.
An exact trans-lation gives a score of 0.
If the system generatesthe sentence "A B C D E" and the actual sen-tence is "A B C F", the score is 3/9 (the lengthof D E F divided by the combined lengths ofA B C D E and A B C F.) The dominance-preserving version of the program produced out-put for 88 out of 91 test sentences.
The averagescore for these 88 sentences was 0.29:0.21 dueto incorrect word matches and 0.08 due to failureto translate because insufficient confidence levelswere reached.
The LCA-preserving version pro-duced output for only 83 sentences with an aver-age score of over 0.30: about 0.23 due to incor-rect word matches and about 0.08 due to insuffi-cient confidence levels.
This crude scoring tech-nique suggests that the dominance-preserving al-gorithm improved our results: more sentenceswere translated with higher quality.
One limita-tion of this scoring technique is that paraphrasesare penalized.
An imperfect score (even .20)may signify an adequate translation.Re ferencesA.
Abeille, Y. Schabes.
and A. K. Joshi.
1990.Using Lexicalized Tags for Machine Transla-tion.
In COLING90.M.
Farach, T. M. Przytycka, and M. Thorup.1995.
On the agreement of many trees.
Infor-mation Processing Letters, 55:297-301.O.
Furuse and H. lida.
1994.
ConstituentBoundary Parsing for Example-Based Ma-chine Translation.
In COLING94.R.
Grishman.
1994. lterative Alignment of Syn-tactic Structures for a Bilingual Corpus: InProceedings of the Second Annual Workshopfor Very Large Corpora, Tokyo.H.
Kaji, Y. Kida, and Y. Morimoto.
1992.Learning Translation Templates fi'om Bilin-gual Text.
In COLING92.M.
Kitamura and Y. Matsumoto.
1995.
A Ma-chine Translation System based on Transla-tion Rules Acquired from Parallel Corpora.
InRANLP95.Y.
Matsumoto, H. Ishimoto.
T. Utsuro, andM.
Nagao.
1993.
Structural Matching of Par-allel Texts.
In ACL93.A.
Meyers, R. Yangarber, and R. Grishman.1996.
Alignment of Shared Forests for Bilin-gual Corpora.
In COLING96, pages 460-465.S.
Sato and M. Nagao.
1990.
Toward Memory-based Translation.
In COLING90, volume 3,pages 247-252.847
