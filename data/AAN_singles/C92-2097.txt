Cooperation between Transfer and Analysisin Example-Based FrameworkOsamu FURUSE and Hitoshi  I IDAATR Interpreting Telephony Research Laborator ies2-2, Hikar idai ,  Seika-cho, Soraku-gun, Kyoto 619-02, Japane-mai l :  furuse {iida} %atr- la.atr .co.
jp@uunet.uu.netAbstractTransfer-Driven Machine Translation (TDMT) ispresented as a method which drives the translationprocesses according to the nature of the input.
InTDMT, transfer knowledge is the central knowledge oftranslation, and various kinds aml levels of knowledgeare cooperatively applied to input sentences.
TDMTeffectively utilizes an example-based framework fortransfer and analysis knowledge.
A consistentframework of examples makes the cooperation betweentransfer and analysis effective, and efficient ranslationis achieved.
The TDMT prototype system, whichtranslates Japanese spoken dialogs into English, hasshown great promise.1 In t roduct ionMany applications dealing with spoken-language,such as automatic telephone interpreting system, needefficient and robust processing.
The system must becapable of handling many idiomatic expressions andspoken-language-specific expressions which deviatefrom conventional grammar.Also, spoken-hmguage has both easy and difficultexpressions to translate.
In human translation whentranslating an easy sentence, tile translated result isproduced quickly using only surface-level knowledge.When translating a complex sentence, a more elaborateprocess is performed, using syntactic, semantic, andcontextual knowledge.
Thus, many strategies andvarious levels of knowledge are used to effectivelytranslate spoken-language.This paper proposes a method called Transfer-DrivenMachine Translation (TDMT), which carries outefficient translation processing by driving the necessarytranslation processes according to the nature of theinput sentence.
An example-based framework canachieve quick processing and consistently describeknowledge.
The integration of transfer and analysis inan example-based framework is i)roposed as a methodfor achieving TDMT.
In this method, transfer andanalysis proceed autonomously and cooperatively.
Also,a well-balanced load on each process can be achieved byemploying this integrated processing mechanism.Sectiou 2 explains the idea of TDMT.
Section 3explains distance calculation and transfer in an example-based framework.
Section 4 explains analysis in anexample-based framework.
Section 5 reports on theTDMT prototype system, and Section 6 reports on tileexperimental results.The explanations in the following sections useJapanese-to-English translation.2 Transfer-Driven Machine TranslationTD/vlT performs efficient and robust spoken-languagetranslation using various kinds of strategies to be ableto treat diverse input.
Its characteristics are explained inthe following sub-sections.2.1 Transfer-centered cooperation mechanismTranslation is essentially converting a sourcelanguage xpression i to a target language xpression.In TDMT, transfer knowledge consists of various levelsof bilingual information.
It is the primary knowledgeused to solve translation problems.
The transfer moduleretrieves the necess~u-y transfer knowledge ranging fromglobal unit like sentence structures to local unit likewords.
The retrieval and application of transferknowledge are flexibly controlled epending on theknowledge necessary to translate the input.
Basically,translation isperformed by using transfer knowledge.
Atransfer module util izes analysis knowledge(syntactic/szmantic infonnation) which helps to applytransfer L,~owledge to some part of the input.
Andgeneration and context knowledge are utilized forproducing correct translatiou result.
In other words,TDMT prodaces translation results by utilizing thesedift'cK,~ut kinds of knowledge cooperatively and bycentering on transfer, and achieves efficient ranslationaccording to the nature of the input.ACTES DE COL1NG-92, NAN'rES, 23-28 ^ otrr 1992 6 4 5 l'~oc, oF COLING-92, N^rcrl~s, AU.
23-28, 19922.2 Utilization of example-based frameworkTransfer knowledge is the basic data which is used fortotally controlling the translation process.Most of the transfer knowledge in TDMT is describedby the example-based framework.
An example-basedframework is useful for cortsistenfly describing transferknowledge.
The essence of the example-basedframework is the distance calculation.
This frameworkachieves the best-match based on the distance betweenthe input and provided examples, and selects the mostplausible target expression from many candidates.
Thedistance is calculated quickly because of its simplemechanism.
Through providing examples, variouskinds and levels of knowledge can be described in theexample-based franlework.2.3 Multi- level knowledgeTDMT provides multi-level transfer knowledge,which correspoods to each translation strategy.
In thetransfer knowledge of the TDMT prototype system,there is string-, pattern- and grammar-level knowledge.TDMT achieves efficient ranslation by utilizing multi-level knowledge ffectively according to the nature ofinput.Some conventional machine translation systems alsoprovide multiple levels of transfer knowledge foridioms, syntax, semantics, and so on, and try to applythese levels of that knowledge in a fixed order to coverdiverse input \[Ikehara etal.
87\].
However, this methodproceeds with the analysis lot deciding which level ofknowledge should be applied for any given inputsentence in a fixed order, placing heavy load on theanalysis module.
Also, the knowledge description isratber more complicated than that of the example-basedframework.
Therefore, the lrauslation of a simplesentence is not always quick because the system tries tocover all translation strategies.3 Example -based  Trans ferTDMT utilizes distance calculation to determine themost plausible target expression and structure intransfer.3.1 Word distanceWe adopt he distance calculation method of Example-Based Machine Translation (EBMT) \[Sumita nd lida91\].
The distance between words is defined as thecloseness of semantic attributes in a thesaurus.
Wordshave certain thesaurus codes, which correspond toparticular semantic attributes.
The distance between thesemantic attributes is determined according to therelationship of their positions in the hierarchy of thethesaurus, and varies between 0 and 1 (Fig.
1).
Thedistance between semantic attributes A and B isexpressed as d(A, B).
Provided that the words X and Yhave the semantic attribute A and B, respectively, thedistance between X and Y, d(X, Y), is equal to d(A, B).d ( A , D ~Figure 1 Distance between thesaurus codesThe hierarchy of the thesaurus that we use is inaccordance with the thesaurus of everyday Japanese\[Ohno and Hamanishi 84\], and consists of four layers.when two values can be abstracted in the k-th layerfrom the bottom, the distance k/3 (0 -< k _< 3) isassigned.
The value 0 means that two codes belong toexactly the same category, and 1 means that they areunrelated.
The attributes "writing" and "book" areabstracted by the immediate upper attribute "document"and the distance is given as 1/3.
Thus, the word"ronbun{technical p per}" which has thesaurus code"writing", and "yokoushuu{proceedings}" which hasthe thesaurus code "book", are assigned a distance of1/3.3.2 Description of Transfer KnowledgeTransfer knowledge describes the correspondencebetween source language xpressions (SE) and targetlanguage xpressions (TE) in certain meaningful units,preserving the translational equivalence \[Tsujii andFujila 91\].
The condition under which a TE is chosenas a translation result of an SE is associated with theTE.
Transfer knowledge in an example-basedframework isdescribed as follows:SE => TEl (El l ,  E12,...),TEn (Enl, En2,...)Each TE has several examples as conditions.
Eij meansthe j-th example of TEi.
The input is the SE'senvironment, and the most appropriate TE is selectedaccording to the calculated istance between the inputand the examples.
The input and examples comprise aset of words.Let us suppose that an input I and each example Eijconsist of t elements as follows:Au~s DE COIANG-92, NANTES, 23-28 ^ otn" 1992 6 4 6 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992I : (I1,...,It)Eij = (Eijl,...,Eijt)Then the distance between I and Eij is calculated asfollows:d (I, Eij) = d ((I1,...,It), (Eijl,...,Eijt))t= Z d (Ik, Eijk)*Wkk=lThe attribute weight Wk expresses fire importance ofthe k-th element in the translation 1.
The distancefrom the input is calculated for all examples.
Then theexample whose distance to the input is least, is detectedand the TE which has the example is selected.
When Eijis close,st o I, TEl is selected as file most plausible TE.The enrichment ofexamples increases the accuracy ofdetermining the TE because conditions become moredetailed.
Further, even if there is only one TE, but thereis no example close to the input, the application of thetc, msfer knowledge is rejected.3.3  Wide application of distance calculationDistance calculation is usexl to deternfine which TEhas the example that is clo~st to the input, 'rod can beused in various abstract level expressions tlepending onhow the input words are provided.Various levels of knowledge can be provided by thewide application of distance calculation.
TDMTachieves efficient translation by utilizing multi-levelknowledge effectively.In the transfer knowledge of Ihe TDMT prototypesystem, the string-, pattern- and grammar-levelknowledge, the latter two of which can be describedeasily in an example-based framework, are now adopted.String-level knowledge is the most concrete, whilegrammar-level knowledge is fire most abstract.3.3 .1  String-level transfer knowledgeSince this kind of knowledge has a condition outsidethe SE, the cooperation with such as context module issometimes necessary.In some cases rite conditions can be dcseribed by theexamples of the most closely related word in which theSE is used, as follows:sochira => this ((des'u {be}2)...),you ((okuru {send})..),it ((mira {see})...)1 Wk is given for each lk by TE's distribution that sematicattribute of Ik brings \[Sumita and lida 91\].2 { w l'""Wn } is the list of corresponding English words.Applying this knowledge,"you" is selected as theword correspondiag to the "scehira" in"sochira ni{particle} tsutaeru" because of the smalldistauee between "tsutaeru{convey}" and"okum{send} ".3.3 .2  Pattern-level transfer knowledgePattermlevel transler knowledge has variables.
Thebinding words of the variables are regarded as input.For example, "X o o-negaishimasu" {X particle will-ask-for} has a variable.
Suppose that it is translated intotwo kinds of English expressions in the examplelyclow:X oo-negaishimasu =>may 1 speak to X '3please give me X'((jimukyoku{office}), ...),((hangou(number}),...)In the translation of "X o o-negaishimasu", the TE isdetennined by the calculation below:if Min (d((X), (jimukyoku)),....)< Min (d((X), (bangou)),....)then tile TE is "may I speak to X'else the TE is "pl-ease give me X' "Tire following two sentences have the pattern "X o o-negaishimasu":(1) "jinjika{personnel s ction} o o-negaishimasu.
"(2) "daimei {title} o o-negaishimasu.
"The first sentence select,; "may I speak to X' " because(jinjika) is close to (jimukyoku).
The second sentenceselects "please give me X' " ,because (tlaimei) is closeto (bangou).
Thus, we get the following translations:(1') "may I speak to the l)ersnnuel section.
"(2') "please give me file title,"3 .3 .3  Gramntar- level  t ransfer  knowledgeGrammar-level transfer knowledge is expressed interms of grammatical categories.
The examples consistof sets of words which are concrete instances of eachcategory.
The following transfer knowledge involvessets of three common ouns (CNs):3A' is the transferred expression of AACRES DE COLING-92, NANITS, 23-28 AO~t 1992 6 4 7 t'ROC.
OF COL1NGO2.
NANTES, AU6.23-28, 1992CNI CN2 CN3 =>CN3' of CNI'(("kaigi, kaisai, kikan{confereltce, opening, time} "),...),CN2' CN3' for CNI'(("sanka, moushikomi, youshi{participation, application, form } "),...),This transfer knowledge allows the followingtranslations.kenkyukai kaisai kikan {workshop, opening, time)o> file time of the workshophappyou moshikomi youshi{presentation, application, form}-> the application form for presentationThe above translations select "CN3' of CNI' " and"CN2' CN3' for CNI' " as the most plausible TEs, asthe result of distance calculations.3.4 Disambiguation by total distanceWhen there are several ways to apply transferknowledge to the input sentence, structural mbiguitymay occur.
In such cases, the most appropriate structureis selected on the basis of total distance.
The least otaldistance implies that the chosen structure is the mostsuitable input structure.
For example, when the pattern"X no Y" is applied to the sentence "kaigi no tourokuhi no waribiki {conference, particle, registration, fee,tkar ticle, discount} ", there are two ppssible structures:(1) kaigi no (touroku hi no waribiki)(2) (kaigi no touroku hi) no waribikiThe pattern "X no Y" has various TEs, such as in thefollowingXnoY  => Y'ofX'  (El l ,  E l2, .
.
. )
,Y' for X' (E21, E22, ... ),Y 'atX'  (E3I, E32 .... ),X' Y' (Eel, E42 .... ),The respective TE tree representations constracted fromstructures (1) and (2) are shown in Figs.
2 and 3.The structure of (1) transfers to "Y' of X' " with thedistance value of 0.50 and "Y' of X' " with the distancevalue of 0.17, and generates (1') with a total distancevalue of 0.67.
In structure (2), "Y' of X' " with thedistance value of 0.17 and "Y' for X'" with the distancevalue of 0.17, generates (2') with a total distance valueof 0.34.
The latter esult is selected because it has theleast otal distance va~ue.
(1') "discount of the regiswation fee of the conference"(2') "discount of registration fee for the conference"discount of registration fee of the conference(total distance-0.67)Y' of X' (distanee~0.50)t -X'the conLrence I Y'of X' (distance=0.17)X' Y'I Iregistration fee discountFigure 2 Translation of"kaigi no (touroku hi no waribiki)"discount of registration fee for the conference(total distance-0.34)Y' of X' (distancn=O.
17)X' Y' I discountY' for X' (distance~O.17)W ?
'I Ithe conference registration feeFigure 3 Translation of"(kaigi no touroku hi) no waribiki"4 Example -based  Ana lys i sFor some structurally complex sentences, translationscannot be performed by applying only transferknowledge.
In such cases, analysis knowledge is alsorequired.
The analysis module applies analysisknowledge and supplies the resulting information to thetransfer module, which then applies transfer knowledgeon the basis of that information.
When no analysisknowledge is necessary for translation, the applicationof only transfer knowledge produces the translationresult.
The analysis described in this paper is not theunderstanding of structure and meaning on the basis of aparsing of the input sentence according to grammarrules, but rather the extraction of the informationACq'ES DE COLING-92, NANfES.
23-28 AOfrr 1992 6 4 8 PROC.
OF COLING-92.
N^.,wrEs, AUG. 23-28, 1992required to apply transfer knowledge and to produce thecorrect ranslation from the input sentence.4.1 Description of analysis knowledgeAnalysis knowledge is described by examples in thesame way as transfer knowledge, as follows:SE => RevisedSEl (El l ,  El2 .... ),Revised SEn (Enl, En2 .... )Although the form of knowledge description is virtuallythe same, transfer knowledge descriptions map ontoTEs, whereas analysis knowledge descriptions map ontorevised SEs.4.2 Cooperation mechanismThe transfer and analysis processes operateautonomously but cooperatively to produce thetranslation result shown in Figure 4.Analysisapplication ofanalysiskn0wlegeInputf Transfer \]\[application ofinformation| transfer1.
knowlege1 outputFigure 4 Relation between transfer and analysisAt present, we are providing analysis knowledge fornormalization \[Nagao 84\] and for structuring withTDMT.
In the following sections we will explain thecooperation mechanism between transfer and analysisbased on these two kinds of analysis knowledge.4.2.1 Analysis knowledge for normalizationNormalization is putting together minor colloquialexpressions into standard expressions It leads to robusttranslation and efficient knowledge storage.
Analysisknowledge for normalization is utilized to recover theellipsis of function words such as particles, and tonormalize some variant forms such as sentence-finalforms into normal forms.
Such knowledge helps theapplication of transfer knowledge to the input sentence.The sentence "Watakushi wa Suzuki desu {I, particle,Suzuki, complementizer}" is uanslated into " 1 amSuzuki" by applying transfer knowledge such as thefollowing:XwaYdesu =>X'beY 'However, in spoken Japanese, particles are frequentlyomitted.
The sentence "Watakushi Suzuki desu" isnatural spoken-Japanese.
It is normalized to "Wataknshiwa Suzuki desu", which has the omitted particle "wa"recovered, hy applying the following analysisknowledge:Pronoun Proper-Noun =>Pronoun wa Proper-Noun (a set of examples)The analysis module sends the information about tileapplication of the analysis knowledge to the transfermodule.
The transfer module receives the informationand applies the transfer knowledge to produce theEnglish sentence " I am Suzuki"By examples, tbis kind of analysis knowledge caualso classify the particles to be recovered as shownbelow:CN Verb =>CN o Verb((hotem {hotel}, yoyaku-snra {reserve\]), ,..),CN ni Verb((kaigi{confemnce}, sanka-suru {i)articipate}),...),This analysis knowledge allows the recovery of variousparticles uch as,"hoteru yoyaku-suru" -> "hotern o yoyaku-suru""kaigi sanka-suru"-> "kaigi ni sanka-suru"Analysis knowledge for nomlalization also has theadvantage of making file scale of knowledge moreeconomical nd the translation processing more robust.4.2.2 Analysis knowledge for structur ingStructuring is recognition of structure components ofby insertion of a marker in order to apply transferknowledge to each structure component.
Analysisknowledge for structuring is applied to detect speciallinguistic phenomena such as adnominal expressions,wh-expressions, and di~ontinuities, so as to assign astructure to the SE.Adnominal expressions appear with high frequency inJapanese, corresponding to various English expressionssuch as relative clauses, infinitives, pronouns, gerunds,and subordinate clauses.
They can be detected by meansof inflectional forms.
Three components of adnominalexpressions must be considered in the translationprocess: the modification relationship, the modifier, andAcrEs DE COLING-92, NANTES.
23-28 ho(rr 1992 6 4 9 PROC.
OF COLING-92, NANTes, Ate.
23-28, 1992the modified.
Analysis information for structuring isused to insert a marker at the boundary between themodifier and the modified.
The following analysisknowledge can be constructed.Adnominal-inflection CN =>Adnominal-inflection Adnominal-marker CN(a set of examples)This knowledge identifies adnominal relationships andseparates the modifier from the modified so that ransferknowledge can be applied.
When the transfer modulereceives the information about the application of thisanalysis knowledge, it applies the transfer knowledgeneeded to translate ach component of the expression:the adnominal relationship, the modifier, and themodified.
The scope of the modifier and the modified isdetermined by the total distance of each structure inwhich transfer knowledge isapplied.The following transfer knowledge about theadnominal relation determines the English expressionby distance calculation with examples before and afterthe marker as follows:XAdnominal-mark Y =>Y' that X' ((iku{go} , basu{bas} ), ...),Y' when X' ((deruIaueod} , hi{day} ), ...),For example, analysis knowledge isapplied to "Kyotoeki e iku basu{Kyoto station particle go bus}", and therevised SE "Kyoto eki e iku Adnominal-marker basu" isproduced.
Then, by the application of the above transferknowledge about the adnominal relation and thefollowing transfer knowledge about the modifier andmodified, the translation result "the bus that goes to theKyoto station" is produced.XeY  => Y'toX',Kyoto eki => Kyoto station,iku => go, basu => bus5 TDMT Proto type  SystemA prototype Japanese to English system constructedtoo confirm the feasibility and effectiveness of TDMT isrunning on a Genera 8.1 LISP machine \[Furuse and lida92\].Due to the restriction of the sequential mechanism, amethod for driving the necessary process at the requiredtime has not been completely achieved.
However, thefollowing control mechanism is used to obtain themost efficient processing possible.?
As much as possible, translation is attempted by firstapplying only transfer knowledge; when this fails, thesystem tries to apply analysis knowledge.?
Transfer knowledge is applied at the most concretelevel as possible, that is, in the order of string, pattern,and grammar level.In order to achieve flexible processing whichexchanges necessary translation i formation, a parallelimplementation is under study based on the results fromthe prototype system.The knowledge base has been built from statisticalinvestigation f the bilingual corpus, whose domain isinquiries concerning international conferenceregistration.
The corpus has syntactic orrespondencesbetween Japanese and English.
We have establishedtransfer and analysis knowledge as follows:?
string-level transfer knowledge (about 500 items)?
pattern-level transfer knowledge (about 300 items)?
grammar-level uansfer knowledge (about 20 items)?
analysis knowledge (about 50 items)6 Eva luat ionWe have evaluated the TDMT prototype system, withthe model conversations about conference registrationconsisting of 10 dialogs and 225 sentences.
The modelconversations cover basic expressions.
Table 1 showsthe kinds of knowledge that were required to translatethe model conversations.Table 1 Knowledge Necessary to TranslateModel Conversation( total number of sentences - 225)sentences ratestring only 73 32.4%pattern and string only 90 40.0%grammar-level 21 9.3%transfer knowledge neededanalysis knowledge needed 41 18.2%At present, the prototype system can produce outputquickly by the example-basod framework.200 of the sentences are correct, providing a successrate of 88.9%.
The coverage by string- and paaem-levelknowledge iswider than expected.Table 2 shows the main causes of incorrect sentences.ACT~ DE COLING-92, NANTES, 23-28 AOt~r 1992 6 5 0 PROC.
OF COL1NG-92.
NANTES, AUG. 23-28, 1992Table 2 Causes of Incorrect Sentences(total number of incorrect sentences - 25)oct urrence~(1) inability to get such TEs 9as elided objects(2) selection of incorrect TEs 8(3) error in adverb position 4(4) incorrect declension 1(5) incorrect tense 1(6) etc 2The second factor shows that an elaboration ofdistance calculation and an enrichment of examples areneeded.
The first, third, and fourth factors are caused bythe shortage of generation knowledge.
The fifth factor iscaused by the shortage of analysis knowledge.
Thesefacts show that the cooperative control that flexiblycommunicates various kinds of knowledge includingcontext mid generation knowledge, and various kinds offrameworks uch as a rule-based and a statisticalframework are useful to improve the translationperformance.7 Related ResearchThe example-based approach was advocated by Nagao\[Nagao 84\].
The essence of this approach is (a) retrievalof similar examples from a bilingual database and (b)applying the examples to translate the input.
Otherresearch as emerged following this line, includingEBMT \[Sumita nd Iida 91\], MBT \[Sate and Nagao90\], and ABMT \[Sadler 89\].
EBMT uses phraseexamples and will be integrated with conventional rule-based machine translation.
MBT and ABMT useexample dependency trees of examples and translate thewhole sentence by matching expressions and by a left-to-right search of maximal matching.
TDMT utilizes anexample-based framework for various process as themethod of selecting the most suitable TE, andcombines multi-level transfer knowledge.
On the otherlmnd, MBT and ABMT utilize uni-level knowledge onlyh~r transfer.8 Conc lud ing  RemarksTDMT (Transfer-Driven Machine Translation) hasbeen proposed.
The prototype TDMT system whichtranslates Japanese to English spoken dialogs, has beenconstructed with an example-based framework.
Theconsistent description by example smoothes thecooperation between transfer and analysis, have shownthe high feasibility.
Important future work will includethe achievement of flexible translation which effectivelycontrol the translation process.
Also important is theimplementation f TDMT in distributed cooperativeprocessing by a parallel computer and incorporatingvarious kinds of processing such as rule-based andstatistical framework into the cooperation mechanism.Acknowledgements1 would like to thank the members of the ATRInterpreting Telephony Research Laboratories for theircomments on various parts of this research.
Specialthanks are due to Dr. Kohei Habara, the chairman of theboard of ATR Interpreting Telephony ResearchLaboratories.
Dr. Akira Kurematsu, the president ofATR Interpreting Telephony Research Laboratories, fortheir support of this research.References\[Furuse and lida 92\] Furuse, O., and Iida, H. : AnExample-based Method for Transfer-driven MachineTranslation, Prec.
of the Fourth InternationalConference on Theoretical nd Methodological Issues inMachine Translation, (1992).\[Ikehara et al 87\] lkehara, S., Miyazaki, M., Shirai,S., and Hayashi, Y : Speaker's Recognition and Multi-level-Translating Method Based on It, Trans.IPS JapanVol.28 No.12., IPSJ , pp.1269-1279, (1987), (inJapanese).\[Nagao 84\] Nagao, M. : A framework of a mechanicaltranslation between Japanese and English by analogyprinciple, in Artificial and Human Intelligence, ed.Elithorn, A. and Bmrerji, R.. North-Holland , pp.173-180, (1984).\[Ohno mid ltamanishi 841 Ohno, S. and Hamanishi M.: Ruigo-Shin-Jiten, Kadokawa, (1984), (in Japanese).\[Sadler 89\] Sadler, V. : Working with AnalogicalSemantics, Foris Publications (1989).\[Sato and Nagao 90\] Sato, S. and Nagao M. : TowardMemory-Based Translation, Proc.
of Coling '90,(1990).\[Smnita nd lida 911 Sumita, E., and Iida, 1t.
:Experiments and Prospects of Example-based MachineTranslation, Proc.
of the 291h Annual Meeting of theAssociation for Computational Linguistics, (1991).\[Tsujii and Fujita 91\] Tsujii, J. and Fnjita, K. : l,exicalTransfer based on Bi~Lingual Signs -TowardsInteraction during Transfer, :P roc .
of the 5thConference of the European Chapter of the Associationfor Computational Linguistics, (1991).ACRES DE COL1NG-92, NANTES.
23-28 Ao(rr 1992 6 5 l PROC.
OF COLING-92.
NA~'rEs, AUO.
23-28.
1992
