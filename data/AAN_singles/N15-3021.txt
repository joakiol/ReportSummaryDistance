Proceedings of NAACL-HLT 2015, pages 101?105,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsNatural Language Question Answering and Analytics for Diverse andInterlinked DatasetsDezhao Song Frank Schilder Charese SmileyResearch and Development, Thomson Reuters610 Opperman DriveEagan, MN 55123, USAChris BrewResearch and Development, Thomson Reuters1 Mark SquareLondon, UK{dezhao.song, frank.schilder, charese.smiley, chris.brew}@thomsonreuters.comAbstractPrevious systems for natural language ques-tions over complex linked datasets requirethe user to enter a complete and well-formedquestion, and present the answers as raw listsof entities.
Using a feature-based grammarwith a full formal semantics, we have devel-oped a system that is able to support rich auto-suggest, and to deliver dynamically generatedanalytics for each result that it returns.1 IntroductionIn order to retrieve data from a knowledge base(KB), knowledge workers, such as physicians or fi-nancial analysts, often face the challenge of hav-ing to learn specific query languages (e.g., SQLand SPARQL1).
However, the fast pace of chang-ing query languages to different types of KBs (e.g.,Relational Databases, Triple Stores, NoSQL stores,etc.)
makes it difficult for users to keep up withthe latest developments of such query languages thatallow them to access the data they need for theirwork.
This situation prevents users without exten-sive computer training from effectively utilizing theavailable information in the KB.
Developing user-friendly natural language interfaces will make it eas-ier for non-technical users to access the informationin the KB in an intuitive way.In this paper, we present a Natural Language In-terface that allows users to query the underlying KBswith natural language questions.
Unlike previousapproaches, instead of asking the users to provide1http://www.w3.org/TR/rdf-sparql-query/the entire question on their own, our system makessuggestions to help the users to complete their ques-tions.
Given a complete question, our system parsesit to its First Order Logic (FOL) representation usinga grammar derived from interlinked datasets; differ-ent translators are developed to further translate theFOL of a query into executable queries, includingboth SQL and SPARQL.
Finally, our system gener-ates dynamic analytics for the result sets in order tohelp users to gain a better understanding of the data.2 Related WorkKeyword-based search (Ding et al, 2004; Tum-marello et al, 2007; d?Aquin and Motta, 2011) andfaceted search (Zhang et al, 2013; Zhang et al,2014) have been frequently adopted for retrievinginformation from KBs.
However, users have to fig-ure out the most effective queries in order to retrieverelevant information.
Furthermore, without appro-priate ranking methods, users may be overwhelmedby the information available in the search results.Early Natural Language Interfaces (NLIs) re-quired a handcrafted interface solution for eachdatabase thereby restricting its portability (Green etal., 1961; Hendrix et al, 1978; Woods, 1973).
Re-cent research has focused more on developing opendomain systems (Kwiatkowski et al, 2013; Yao andDurme, 2014; Bordes et al, 2014), but there remainsa need for specialized NLIs (Minock, 2005).
Oneunique feature of our system is to help users to builda complete question by providing suggestions ac-cording to a partial question and a grammar.Much of prior work translates a natural languagequestion into SPARQL and retrieves answers from a101triple store (Lopez et al, 2005; Unger et al, 2012;Lehmann et al, 2012; Yahya et al, 2013; He et al,2014); however, SPARQL queries have been criti-cized to have unsatisfying query response time.
Inthis work, we maintain flexibility by first parsinga question into First Order Logic, which is furthertranslated into both SQL and SPARQL.
This enablesus to easily adapt to new query languages and allowsus to choose the most appropriate query languagetechnology for a given use case.Finally, to the best of our knowledge, none of ex-isting NLIs provide dynamic analytics for the re-sults.
Our system performs descriptive analytics andcomparisons on various dimensions of the data, con-ducts sentiment analysis, and analyzes trends overtime in the data.
Such analytics would enable usersto better conduct further analyses and derive insightsfrom the data.
This feature of our system is a clearadvantage over other NLI systems that only retrievea simple result list of documents/entities.3 Overall ArchitectureFigure 1 shows the overall architecture of our pro-posed NLI system.
Users can input their questionsFigure 1: System Architectureon the Web Interface and our Auto-suggestion com-ponent will guide the users in completing their ques-tions.
A complete question is then sent to the Ques-tion Understanding module again to be parsed intoits first order logic representation with the grammar.As the next step, the FOL of a query is translatedinto an executable query with the Query Translationmodule.
A translated query is then executed againstan underlying knowledge base/graph for retrievinganswers and generating corresponding analytics.Our system currently focuses on the following do-mains: Drugs, Organizations, Patents, People, Fi-nance and News.
The underlying knowledge basecontains about 1 million entities and 12 million rela-tionships.4 Question UnderstandingOur system utilizes a feature-based context-freegrammar (FCFG) that consists of grammar ruleson non-terminal nodes and lexical rules on leafnodes.
Grammatical entries on non-terminal syntac-tic nodes are largely domain-independent, thus en-abling our grammar to be easily adaptable to newdomains.
Each lexical entry to the grammar containsdomain-specific features which are used to constrainthe number of parses computed by the parser prefer-ably to a single, unambiguous parse.The following are two rules in our grammar.1.
N[TYPE=drug, NUM=pl, SEM=<?x.drug(x)>] ?
?drugs?2.
V[TYPE=[org,drug],SEM=?Xx.X(?y.develop org drug(x,y))>,TNS=prog, NUM=?n] ?
?developing?Rule 1 shows a lexical entry for the word drugs, in-dicating that its TYPE is drug, is plural, and has thefollowing semantic: ?x.drug(x).
Rule 2 specifiesthe verb develop, describing its tense (TNS) and indi-cating that it connects an organization and a drug viathe TYPE feature.
By utilizing the type constraints,we can then license the query companies develop-ing drugs while rejecting nonsensical queries likerabbits develop drugs on the basis of the mismatchin semantic type.
Furthermore, our grammar alsocovers wh-questions, e.g., what, which, how many,where, and nominal phrases and imperatives.Disambiguation relies on the presence of featureson non-terminal syntactic nodes.
We mark prepo-sitional phrases (PPs) with features that determinetheir attachment preference.
E.g., the PP for pain inhow many companies develop drugs for pain?
mustattach to an NP rather than a VP; thus, it must attachto drugs rather than develop.
Together with otherfeatures, we filter out many of the logically possiblebut undesired PP-attachments in queries with manymodifiers.
E.g., our approach is able to generate asingle parse for companies headquartered in Ger-many developing drugs for pain or cancer.1025 Auto-suggestionOur NLI provides suggestions to help users to com-plete their questions.
Unlike Google?s query auto-completion that is based on query logs (Cornea andWeininger, 2014), our auto-suggestion utilizes thelinguistic constraints encoded in the grammar.Our auto-suggestion is based on the idea of left-corner parsing.
Given a query segment qs (e.g.,drugs, developed by, etc.
), we find all grammar ruleswhose left corner fe on the right side matches theleft side of the lexical entry of qs.
We then find allleaf nodes in the grammar that can be reached by us-ing the adjacent element of fe.
For all reachable leafnodes (i.e., lexical entries in our grammar), if a lex-ical entry also satisfies all the linguistic constraints,we then treat it as a valid suggestion.Specifically, for the query segment Drugs, ac-cording to our grammar, we could be looking for averb as the next part of the question.
In our lexicon,we may have many verbs, e.g., drive and developedby.
Here, developed by is a valid suggestion becauseits semantic constraints match that of drugs.
We con-tinue our suggestions to the end of the user-enteredquery string, and never try to interpolate material ei-ther before or inside the string.In our current system, the automatically generatedsuggestions are ranked by considering their popular-ity.
We associate each lexical entry with a node ina knowledge graph.
This graph contains nodes forthe entities corresponding to the lexical entries, fur-ther nodes for generic types such as Drug, Companyand Technology, and yet further nodes for predicatessuch as developed by and granted to.The edges ofthe graph represent relations such as developed byand filed by.
For ranking, the degree of a node isas a proxy for its quality.
For example, if the node?Google?
filed 10 patents and is also involved in 20lawsuits, then its popularity will be 30.6 Query Translation and ExecutionThe interpreted FOL (Section 4) of a question is fur-ther analyzed by another parser (implemented withANTLR (Bovet and Parr, 2008)) that parses FOLexpressions.
Figure 3 shows the parse tree of theFOL for the query Drugs developed by Merck.
Wethen traverse this parse tree, and put all the atomiclogical conditions and the logical connectors into aFigure 3: Parse Tree for the First Order Logic Represen-tation of the Query ?Drugs developed by Merck?stack.
When we finish traversing the entire tree, wepop the conditions out of the stack to build the queryconstraints; predicates in the FOL are also mappedto their corresponding attribute names (SQL) or on-tology properties (SPARQL).The following summarizes the translation from anatural language question to a SQL and SPARQLquery via a FOL representation:Natural Language: ?
?Drugs developed by Merck?
?First Order Logic (FOL) Representation: all x.
(drug(x) ?
(develop(id042,x) & type(id042,Company) &label(id042,Merck)))SQL Query: select drug.
*from drugwhere drug.originator company = ?Merck?SPARQL Query (prefixes for RDF and RDFS omitted):PREFIX example: <http://www.example.com#>select ?x ?id123 ?id042where {?id042 rdfs:label ?Merck?.
?id042 rdf:type example:Company .
?x rdf:type example:Drug .
?id042 example:develops ?x .
}We execute the SQL queries using Apache Spark(Zaharia et al, 2010), a distributed computing en-vironment, thus providing us the potential to handlelarge-scale datasets.
We run SPARQL queries withJena (Carroll et al, 2004).
If a question cannot beparsed into FOL or translated to SQL or SPARQL,we then treat it as a keyword query and retrieve theresults from an inverted index built out of our data.7 AnalyticsInstead of only retrieving a list of entities, our sys-tem provides several different types of analytics fordifferent result sets.
In many situations, the resultis a set of records rather than one single entry.
This103Figure 2: System Screenshotprovides us the opportunity to perform and providefurther analyses of the result set for the users.Our system provides several types of analytics.Descriptive analytics summarize the facts in the re-sult set.
For instance, for the question ?show me alldrugs targeting pain?, our system shows the distri-bution of all technologies used for such drugs in theresult set.
We also compare the drugs in the resultset on different dimensions (e.g., diseases).
More-over, we compute trends via exponential smoothingfor entities that have a temporal dimension.By linking entities from our KB to entity men-tions in a large news corpus (14 million articles and147 million sentences), we are able to perform ad-ditional analytics based on named entity recognitionand sentiment analysis techniques.
We adopted theStanford CoreNLP toolkit (Manning et al, 2014)for recognizing person, organization, and locationfrom the news corpus.
Given an entity, we show itsfrequency count and how its sentiment may changeover time.
This information may provide further in-sights to users in order to support their own analysis.8 Demonstration Script OutlineFigure 2 shows the beginning of the sample query:companies developing drugs having an indication of.
.
.
?
While the user is typing, a variety of possibleextensions to the query are offered, and the user se-lects Hypertension (1).
Our system shows a pie chartof each company?s market share for hypertensiondrugs (2); we also show news mentions and senti-ment analysis for the most discussed companies (3).For the demo, we will first motivate the use of nat-ural language question answering for extracting in-formation from complex, interlinked datasets.
Next,we will demonstrate how the user can compose avariety of questions with auto-suggestion.
Finally,we will walk through the generated analytics andvarious visualizations for different natural languagequestions in order to show how it allows the user togain deeper insights into the data.9 Conclusion and Future WorkIn this paper, we presented a Natural Language In-terface for answering complex questions over linkeddata.
Our system parses natural language questionsto an intermediate logical representation based on agrammar derived from multiple interlinked datasets.Different translators are developed to translate aquestion from its FOL representation to SQL andSPARQL queries, which are then executed againstan underlying knowledge graph/base for retrievingthe answers and generating corresponding analytics.In future work, we intend to cover more domainsand provide more complex analytics.
We will alsoperform a thorough evaluation of our system.104ReferencesAntoine Bordes, Sumit Chopra, and Jason Weston.
2014.Question answering with subgraph embeddings.
InProceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing, pages 615?620.Jean Bovet and Terence Parr.
2008.
Antlrworks: anANTLR grammar development environment.
Soft-ware: Practice and Experience, 38(12):1305?1332.Jeremy J. Carroll, Ian Dickinson, Chris Dollin, DaveReynolds, Andy Seaborne, and Kevin Wilkinson.2004.
Jena: implementing the semantic web recom-mendations.
In Proceedings of the 13th internationalconference on World Wide Web - Alternate Track Pa-pers & Posters, pages 74?83.Radu C Cornea and Nicholas B Weininger.
2014.
Pro-viding autocomplete suggestions, February 4.
USPatent 8,645,825.Mathieu d?Aquin and Enrico Motta.
2011.
Watson, morethan a semantic web search engine.
Semantic WebJournal, 2(1):55?63.Li Ding, Timothy W. Finin, Anupam Joshi, Rong Pan,R.
Scott Cost, Yun Peng, Pavan Reddivari, VishalDoshi, and Joel Sachs.
2004.
Swoogle: a search andmetadata engine for the semantic web.
In Proceedingsof the 2004 ACM International Conference on Infor-mation and Knowledge Management, pages 652?659.Bert F. Green, Jr., Alice K. Wolf, Carol Chomsky, andKenneth Laughery.
1961.
Baseball: An automaticquestion-answerer.
In Papers Presented at the WesternJoint IRE-AIEE-ACM Computer Conference, pages219?224.Shizhu He, Kang Liu, Yuanzhe Zhang, Liheng Xu, andJun Zhao.
2014.
Question answering over linked datausing first-order logic.
In Proceedings of the 2014Conference on Empirical Methods in Natural Lan-guage Processing, pages 1092?1103.Gary G. Hendrix, Earl D. Sacerdoti, Daniel Sagalowicz,and Jonathan Slocum.
1978.
Developing a natural lan-guage interface to complex data.
ACM Transactionson Database Systems, 3(2):105?147.Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke S.Zettlemoyer.
2013.
Scaling semantic parsers with on-the-fly ontology matching.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 1545?1556.Jens Lehmann, Tim Furche, Giovanni Grasso, Axel-Cyrille Ngonga Ngomo, Christian Schallhart, An-drew Jon Sellers, Christina Unger, Lorenz B?uhmann,Daniel Gerber, Konrad H?offner, David Liu, and S?orenAuer.
2012.
DEQA: Deep web extraction for ques-tion answering.
In 11th International Semantic WebConference, pages 131?147.Vanessa Lopez, Michele Pasin, and Enrico Motta.
2005.Aqualog: An ontology-portable question answeringsystem for the semantic web.
In The Semantic Web:Research and Applications, Second European Seman-tic Web Conference, pages 546?562.Christopher D. Manning, Mihai Surdeanu, John Bauer,Jenny Rose Finkel, Steven Bethard, and David Mc-Closky.
2014.
The stanford corenlp natural languageprocessing toolkit.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Linguis-tics, pages 55?60.Michael Minock.
2005.
Where are the killer applicationsof restricted domain question answering.
In Proceed-ings of the IJCAI Workshop on Knowledge Reasoningin Question Answering, page 4.Giovanni Tummarello, Renaud Delbru, and Eyal Oren.2007.
Sindice.com: Weaving the open linked data.In The Semantic Web, 6th International Semantic WebConference, 2nd Asian Semantic Web Conference,pages 552?565.Christina Unger, Lorenz B?uhmann, Jens Lehmann, Axel-Cyrille Ngonga Ngomo, Daniel Gerber, and PhilippCimiano.
2012.
Template-based question answeringover RDF data.
In Proceedings of the 21st World WideWeb Conference, pages 639?648.William A.
Woods.
1973.
Progress in natural languageunderstanding: an application to lunar geology.
InAmerican Federation of Information Processing So-cieties: 1973 National Computer Conference, vol-ume 42, pages 441?450.Mohamed Yahya, Klaus Berberich, Shady Elbassuoni,and Gerhard Weikum.
2013.
Robust question answer-ing over the web of linked data.
In 22nd ACM Inter-national Conference on Information and KnowledgeManagement, pages 1107?1116.Xuchen Yao and Benjamin Van Durme.
2014.
Informa-tion extraction over structured data: Question answer-ing with freebase.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Linguis-tics, pages 956?966.Matei Zaharia, Mosharaf Chowdhury, Michael J.Franklin, Scott Shenker, and Ion Stoica.
2010.
Spark:Cluster computing with working sets.
In 2nd USENIXWorkshop on Hot Topics in Cloud Computing, pages1?10.Xingjian Zhang, Dezhao Song, Sambhawa Priya, and JeffHeflin.
2013.
Infrastructure for efficient explorationof large scale linked data via contextual tag clouds.In 12th International Semantic Web Conference, pages687?702.Xingjian Zhang, Dezhao Song, Sambhawa Priya,Zachary Daniels, Kelly Reynolds, and Jeff Heflin.2014.
Exploring linked data with contextual tagclouds.
Journal of Web Semantics, 24:33?39.105
