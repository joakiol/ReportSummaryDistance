Robust Sub-Sentential Alignment of Phrase-Structure TreesDeclan GrovesSchool of ComputingDublin City UniversityDublin 9, Irelanddgroves@computing.dcu.ieMary HearneSchool of ComputingDublin City UniversityDublin 9, Irelandmhearne@computing.dcu.ieAndy WaySchool of ComputingDublin City UniversityDublin 9, Irelandaway@computing.dcu.ieAbstractData-Oriented Translation (DOT), based on Data-Oriented Parsing (DOP), is a language-independentMT engine which exploits parsed, aligned bitextsto produce very high quality translations.
How-ever, data acquisition constitutes a serious bottleneckas DOT requires parsed sentences aligned at bothsentential and sub-structural levels.
Manual sub-structural alignment is time-consuming, error-proneand requires considerable knowledge of both sourceand target languages and how they are related.
Au-tomating this process is essential in order to carry outthe large-scale translation experiments necessary toassess the full potential of DOT.We present a novel algorithm which automatically in-duces sub-structural alignments between context-freephrase structure trees in a fast and consistent fash-ion requiring little or no knowledge of the languagepair.
We present results from a number of experi-ments which indicate that our method provides a se-rious alternative to manual alignment.1 IntroductionApproaches to Machine Translation (MT) usingData-Oriented Parsing (DOP: (Bod, 1998; Bod etal., 2003)) require ?source,target?
tree fragmentsaligned at sentential and sub-sentential levels.
Inprevious approaches to Data-Oriented Translation(DOT: (Poutsma, 2000; Hearne and Way, 2003)),such fragments were produced manually.
This istime-consuming, error-prone, and requires consid-erable expertise of both source and target languagesas well as how they are related.
The obvious solu-tion, therefore, is to automate the process of sub-sentential alignment.
However, while there aremany approaches to sentential alignment e.g.
(Kayand Ro?scheisen, 1993; Gale & Church, 1993), nomethods exist for aligning non-isomorphic phrase-structure (PS) tree fragments at sub-sentential levelfor use in MT.
(Matsumoto et al, 1993) align?source,target?
dependency trees, with a view to re-solve parsing ambiguities, but their approach can-not deal with complex or compound sentences.Other researchers (Imamura, 2001) also use phrase-alignment in parsing but in DOT the translationfragments are already in the form of parse-trees.
(Eisner, 2003) outlines a computationally expensivestructural manipulation tool which he has used forintra-lingual translation but has yet to apply to inter-lingual translation.
(Gildea, 2003) performs tree-to-tree alignment, but treats it as part of a generativestatistical translation model, rather than a seperatetask.
The method of (Ding et al, 2003) can copewith a limited amount of non-isomorphism, but thealgorithm is only suitable for use with dependencytrees.We develop a novel algorithm which automati-cally aligns translationally equivalent tree fragmentsin a fast and consistent fashion, and which requireslittle or no knowledge of the language pair.
Our ap-proach is similar to that of (Menezes and Richard-son, 2003), who use a best-first approach to aligndependency-type tree structures.We conduct a number of experiments on theEnglish-French section of the Xerox HomeCentrecorpus.
Using the manual alignment of (Hearneand Way, 2003) as a ?gold standard?, we show thatour algorithm identifies sub-structural translationalequivalences with 73.7% precision and 67.84% re-call.
Furthermore, we replicate previous DOT ex-periments performed using manually aligned data.However, we use data aligned by our novel al-gorithm and evaluate the output translations.
Wedemonstrate that while coverage decreases by 10%,the translations output are of comparable quality.These results indicate that our automatic alignmentalgorithm provides a serious alternative to manualalignment.The remainder of this paper is organised as fol-lows: in section 2, we discuss related research inmore detail, while in section 3, we provide an over-iew of DOT.
We present our algorithm in section 4,and in section 5 describe the experiments conductedtogether with the results obtained.
Finally, we con-clude and provide avenues for further research.2 Related ResearchSeveral approaches to sub-structural alignment oftree representations have been proposed.
(Matsumoto et al, 1993) and (Imamura, 2001)focus on using alignments to help resolve pars-ing ambiguities.
As we wish to develop an align-ment process for use in MT rather than parsing, thismakes their approaches unsuitable for our use.
(Eisner, 2003) presents a tree-mapping methodfor use on dependency trees which he claims can beadapted for use with PS trees.
He uses dynamic pro-gramming to break tree pairs into pairs of alignedelementary trees, similar to DOT.
However, he aimsto estimate a translation model from unaligned data,whereas we wish to align our data off-line.
Cur-rently, he has used his algorithm to perform intra-lingual translation but has yet to develop and applyreal models to inter-lingual MT.
(Gildea, 2003) outlines an algorithm for use insyntax-based statistical models of MT, applying astatistical TSG with probabilities parameterized togenerate the target tree conditioned on the structureof the source tree.
His approach is unsuitable forDOT as it involves altering the shape of trees in or-der to impose isomorphism and the algorithm doesnot always generate a complete target tree structure.However, unlike (Gildea, 2003), we treat the prob-lem of alignment as a seperate task rather than aspart of a generative translation model.
(Ding et al, 2003) and (Menezes and Richard-son, 2003) also present approaches to the alignmentof tree structures.
Both deal with dependency struc-tures rather than PS trees.
(Ding et al, 2003) out-line an algorithm to extract word-level alignmentsusing structural information taken from parallel de-pendency trees.
They fix the nodes of tree pairsbased on word alignments deduced statistically andthen proceed by partitioning the tree into treeletpairs with the fixed nodes as their roots.
Their al-gorithm relies on the fact that, in dependency trees,subtrees are headed by words rather than syntacticlabels, making it unsuitable for our use.
(Menezes and Richardson, 2003) employ a best-first strategy and use a small alignment grammarto extract transfer mappings from bilingual corporafor use in translation.
They use a bilingual dictio-nary and statistical techniques to supply translationpair candidates and to identify multi-word terms.Lexical correspondences are established using thelexicon of 98,000 translation pairs and a deriva-tional morphology component to match other lexi-cal items.
Nodes are then aligned using these lexicalcorrespondences along with structural information.Our algorithm uses a similar methodology.
How-ever, (Menezes and Richardson, 2003) use logicalforms, which constitute a variation of dependencytrees that normalize both the lexical and syntacticform of examples, whereas we align PS trees.Although the methods outlined above haveachieved promising results, only the approach of(Menezes and Richardson, 2003) seems relevantto our goal, even though they deal with abstractdependency-type structures rather than PS trees.3 Data-Oriented TranslationData-Oriented Translation (DOT) (Poutsma, 2000;Hearne and Way, 2003), which is based on Data-Oriented Parsing (DOP) (Bod, 1998; Bod et al,2003), comprises a context-rich, experience-basedapproach to translation, where new translationsare derived with reference to grammatical analy-ses of previous translations.
DOT exploits bilin-gual treebanks comprising linguistic representationsof previously seen translation pairs, as well as ex-plicit links which map the translational equivalencespresent within these pairs at sub-sentential level ?an example of such a linked translation pair can beseen in Figure 1(a).
Analyses and translations ofthe input are produced simultaneously by combin-ing source and target language fragment pairs de-rived from the treebank trees.3.1 FragmentationThe tree fragment pairs used in Tree-DOT arecalled subtree pairs and are extracted from bilingualaligned treebank trees.
The two decomposition op-erators, which are similar to those used in Tree-DOPbut are refined to take the translational links into ac-count, are as follows:?
the root operator which takes any pair of linkednodes in a tree pair to be the roots of a subtree pairand deletes all nodes except these new roots and allnodes dominated by them;?
the frontier operator which selects a (possiblyempty) set of linked node pairs in the newly cre-ated subtree pairs, excluding the roots, and deletesall subtree pairs dominated by these nodes.Allowing the root operator to select the root nodesof the original treebank tree pair and then the fron-tier operator to select an empty set of node pairsensures that the original treebank tree pair is al-ways included in the fragment base ?
in Figure 1,fragment (a) exactly matches the original treebanktree pair from which fragments (a) ?
(f) were de-rived.
Fragments (b) and (f) were also derived byallowing the frontier operator to select the emptyset; the root operation selected node pairs <A,N>and <NPadj,NPdet> respectively.
Fragments (c),(d) and (e) were derived by selecting all further pos-sible combinations of node pairs by root and fron-tier.
(a) (b)VPvV NPadjclearing A Npaper jamsNPppN PPresolution P NPdetde D NPaples N Nincidents papierApaperNpapier(c) (d)VPvV NPadjclearing A NjamsNPppN PPresolution P NPdetde D NPaples N NincidentsNPadjA NjamsNPdetD NPaples N Nincidents(e) (f)VPvV NPadjclearingNPppN PPresolution P NPdetdeNPadjA Npaper jamsNPdetD NPaples N Nincidents papierFigure 1: DOT fragments generated via root and frontier3.2 TranslationThe DOT composition operator is defined as fol-lows.
The composition of tree pairs <s1,t1> and<s2,t2> (<s1,t1> ?
<s2,t2>) is only possible if?
the leftmost non-terminal frontier node of s1 is ofthe same syntactic category (e.g.
S, NP, VP) as theroot node of s2, and?
the leftmost non-terminal frontier node of s1?slinked counterpart in t1 is of the same syntactic cat-egory as the root node of t2.The resulting tree pair consists of a copy of s1 wheres2 has been inserted at the leftmost frontier node anda copy of t1 where t2 has been inserted at the nodelinked to s1?s leftmost frontier node, as illustrated inFigure 2.The DOT probability of a translation derivation isthe joint probability of choosing each of the subtreepairs involved in that derivation.
The probability ofselecting a subtree pair is its number of occurrencesin the corpus divided by the number of pairs in thecorpus with the same root nodes as it:P (< es, et >) =|<es,et>|?<us,ut>:r(<us,ut>)=r(<es,et>) |<us,ut>|The probability of a derivation in DOT is the prod-uct of the probabilities of the subtree pairs involvedROOTVPv PERIODV N .clickLISTITEMVPverb PERIODV PP .cliquez P Nsur?NSaveNEnregistrer=ROOTVPv PERIODV N .click SaveLISTITEMVPverb PERIODV PP .cliquez P Nsur EnregistrerFigure 2: The DOT composition operationin building that derivation.
Thus, the probability ofderivation <s1,t1> ?
... ?
<sn,tn> is given byP (< s1, t1 > ?...?
< sn, tn >) =?iP (< si, ti >)Again, a translation can be generated by many dif-ferent derivations, so the probability of a transla-tion ws ?
?wt is the sum of the probabilities of itsderivations:P (< ws, wt >) =?<tsi ,tti> yields <ws,wt>P (< tsi , tti >)Selection of the most probable translation via MonteCarlo sampling involves taking a random sample ofderivations and outputting the most frequently oc-curring translation in the sample.4 Our AlgorithmThe operation of a DOT system is dependent on theavailability of bilingual treebanks aligned at senten-tial and sub-sentential level.
Our novel algorithmattempts to fully automate sub-sentential alignmentusing an approach inspired by that of (Menezes andRichardson, 2003).
The algorithm takes as input apair of ?source,target?
PS trees and outputs a map-ping between the nodes of the tree pair.As with the majority of previous approaches, thealgorithm starts by finding lexical correspondencesbetween the source and target trees.
Our lexiconis built automatically using a previously developedword aligner based on the k-vec aligner as outlinedby (Fung & Church, 1994).
This lexical aligner usesa combination of automatically extracted cognateinformation, mutual information and probabilisticmeasures to obtain one-to-one lexical correspon-dences between the source and target strings.
Dur-ing lexical alignment, function words are excludedbecause, as they are the most common words in alanguage, they tend to co-occur frequently with thecontent words they precede.
This can lead to theincorrect alignment of content words with functionwords.The algorithm then proceeds from the alignedlexical terminal nodes in a bottom-up fashion, us-ing a mixture of node label matching and structuralinformation to perform language-independent link-ing between all ?source,target?
node pairs within thetrees.
As with (Menezes and Richardson, 2003),it uses a best-first approach.
After each step, newlinked node pairs are added to the current list oflinked nodes.
The links made between the nodesare fixed, thus restricting the freedom of alignmentfor the remaining unaligned nodes in the tree pair.The methods of the algorithm are applied to eachnew linked node pair in turn until no new node pairscan be added.
The algorithm consists of five mainmethods which are performed on each linked nodepair in the list:Verb + Object Align (Figure 3): We have a linked source-target node pair ?s,t?.
s and t are both verbs, are theleftmost children in their respective trees, both have VPparent nodes and they have the same number of siblingswhich have similar syntactic labels.
We align the corre-sponding siblings of s and t. This aligns the objects ofthe source verb with the equivalent objects of the targetverb.
We also align the parents of s and t.SPRON VPauxyou MODAL VPvcan V NPadjscan A Nentire pagesS[dec]PRON VPverbvous MODAL VPverb[main]pouvez V NPdetnume?riser D NPapdes N Apages entie`resFigure 3: Verb + Object Align: the dashed lines representthe links made by Verb + Object Align when the current linkednode pair is ?MODAL,MODAL?.Parent Align (Figure 4): We have a current linked source-target node pair ?s,t?
with unlinked parents pars and partrespectively.
All the sister nodes of s are aligned withsister nodes of t. We link pars and part.
If s and t eachhave one unlinked sister, but the remaining sisters of s arealigned with sister nodes of t, link the unlinked sisters andlink pars with part.NP/VP Align (Figure 5): We have a linked source-targetnode pair ?s,t?
and s and t are both nouns.
Traverse upthe source tree to find the topmost NP node nps dominat-ing s and traverse up the target tree to find the topmostNmodA NPcolor print headNPapNP Nte?te d?impression couleurFigure 4: Parent Align: The dashed lines are the links madeby Parent Align, when ?color,couleur?
is the current linked nodepair.target NP node npt dominating t. We link nps and npt.We then traverse down from nps and npt to the leftmostleaf nodes ( ls and lt) in the source and target subtreesrooted at nps and npt.
If ls and lt have similar labels,we link them.
This helps to preserve the scope of noun-phrase modifiers.
If s and t are both verbs, we perform asimilar method, this time linking the topmost VP nodesin the source and target trees.NPD NPadja A Npending documentNPdetD NPppun N PPdocument P NPppen N PPattenteP Nde impressionFigure 5: NP Align: the dashed lines represent the links madeby NP Align when the current linked node pair is ?N,N?.Child Align (Figure 6): This method is similar to that of Par-ent Align.
We have a current linked source-target nodepair ?s,t?.
Each node has the same number of childrenand these children have similar node labels.
We link theircorresponding children.SNP VPcopPRON N Vcop NPis PRON NPadjyour imagination your A Nonly limitationSNPdet VPcopD N Vcop NPdetest D NPapvotre imagination votre A Nseule limiteFigure 6: Child Align: the dashed lines represent the linksmade by Child Align when the current linked node pair is ?S,S?.Subtree Align: We have a linked source-target node pair ?s,t?.If the subtrees rooted at s and at t are fully isomorphic, welink the corresponding nodes within the subtrees.
Thisaccounts for the fact that trees may not be completelyisomorphic from their roots but may be isomorphic atsubtree level.11Originally we used a method isomophic which checked forOnce lexical correspondences have been estab-lished, the methods outlined above use structural in-formation to align the ?source,target?
nodes.
Thecomparison of ?source,target?
node labels duringalignment ensures that sub-structures with corre-sponding syntactic categories are aligned.
If thealgorithm fails to find any alignments between thesource and target tree pairs, due to the absenceof initial lexical correspondences, we align the?source,target?
root nodes.5 Experiments and resultsPrevious DOT experiments (Hearne and Way, 2003)were carried out on a subset of the HomeCentrecorpus consisting of 605 English-French sentencepairs from Xerox documentation parsed into LFGc(onstituent)- and f(unctional)-structure representa-tions and aligned at sentence level.
This bilingualtreebank constitutes a linguistically complex frag-ment base containing many ?hard?
translation ex-amples, including cases of nominalisations, pas-sivisation, complex coordination and combinationsthereof.
Accordingly, the corpus would appear topresent a challenge to any MT system.The insertion of the links denoting translationalequivalence for the set of tree pairs used in the pre-vious experiments was performed manually.
Wehave applied our automatic sub-structural alignmentalgorithm to this same set of 605 tree pairs andevaluated performance using two distinct methods.Firstly, we used the manual alignments as a ?goldstandard?
against which we evaluated the output ofthe alignment algorithm in terms of precision, recalland f-score.
The results of this evaluation are pre-sented in Section 5.1.
Secondly, we repeated theDOT experiments described in (Hearne and Way,2003) using the automatically generated alignmentsin place of those determined manually.
We evalu-ated the output translations in terms of IBM Bleuscores, precision, recall and f-score and presentthese results in Section 5.2.5.1 Evaluation of alignment qualityUsing the manually aligned tree pairs as a ?goldstandard?, we evaluated the performance of eachof the five methods which constitute the alignmentalgorithm both individually and in combination.These evaluations are summarised in Figures 7 and8 respectively.The alignment process is always initialised byfinding word correspondences between the sourceisomorphism from the roots downwards, assuming a root-rootcorrespondence.
However, this significantly decreased the per-formance of the aligner.PRECISION RECALL F-SCORELex 0.6800 0.3057 0.4212Par 0.7471 0.4983 0.5978NP/VP 0.7206 0.4879 0.5819Child 0.7045 0.3856 0.4984Verb + Object 0.6843 0.3191 0.4352Figure 7: Individual evaluation of alignment methodsPRECISION RECALL F-SCOREPar + Child 0.7525 0.5588 0.6414Par + NP/VP 0.7373 0.6106 0.6680Par + Child + NP/VP 0.7411 0.6587 0.6974All 0.7430 0.6686 0.7039All + Subtree 0.7370 0.6784 0.7064Figure 8: Evaluation of combined alignment methodsand target trees, meaning that lexical alignment iscarried out regardless of which other method orcombination of methods is included.
The low rate ofrecall achieved by the lexical alignment process of0.3057, shown in Figure 7, can be largely attributedto the fact that it does not align function words.
Weachieve high precision relative to recall ?
as is gen-erally preferred for automatic procedures ?
indicat-ing that the alignments induced are more likely tobe ?partial?
than incorrect.When evaluated individually, the Parent Alignmethod performs best, achieving an f-score of0.5978.
Overall, the highest f-score of 0.7064 isachieved by using all methods, including the addi-tional subtree method, in combination.5.2 Evaluation of translation qualityIn order to evaluate the impact of using automat-ically generated alignments on translation quality,we repeated the DOT experiments described in(Hearne and Way, 2003) using these alignments inplace of manually determined translational equiva-lences.In order to ensure that differences in the resultsachieved could be attributed solely to the differ-ent sub-structural alignments imposed, we used pre-cisely the same 8 training/test set splits as before,where each training set contained 545 parsed sen-tence pairs, each test set 60 sentences, and all wordsoccurring in the source side of the test set alo oc-curred in the source side of the training set (but notnecessarily with the same lexical category).
As be-fore, all translations carried out were from Englishinto French and the number of samples taken duringthe disambiguation process was limited to 5000.Due to constraints on time and memory, data-oriented language processing applications gener-ally limit the size of the fragment base by exclud-Bleu/Auto Bleu/Man F-Score/Aut.
F-Score/ManLD1 0.0605 0.2627 0.3558 0.5506LD2 0.1902 0.3018 0.4867 0.5870LD3 0.1983 0.3235 0.4957 0.6045LD4 0.214 0.3235 0.5042 0.6069Figure 9: Evaluation over all translationsing larger fragments.
In these experiments, we in-creased the size of the fragment base incrementallyby initially allowing only fragments of link depth(LD) 1 and then including those of LD 2, 3 and 4.
2We evaluated the output translations in terms ofIBM Bleu scores using the NIST MT EvaluationToolkit3 and in terms of precision, recall and f-scoreusing the NYU General Text Matcher.4 We sum-marise our results and reproduce and extend thoseof (Hearne and Way, 2003)5 in Figures 9, 10 and11.Results over the full set of output translations,summarised in Figure 9, show that using the man-ually linked fragment base results in significantlybetter overall performance at all link depths (LD1- LD4) than using the automatic alignments.
How-ever, both metrics used assign score 0 in all in-stances where no translation was output by the sys-tem.
The comparatively poor scores achieved us-ing the automatically induced alignments reflect thefact that these alignments give poorer coverage at alldepths than those determined manually (47.71% vs.66.46% at depth 1, 56.39% vs. 67.92% at depths 2- 4).The results in Figure 10 include scores onlywhere a translation was produced.
Here, transla-tions produced using manual alignments score bet-ter only at LD 1; better performance is achieved atLD 2 - 4 using the automatically linked fragmentbase.
Again, this may ?
at least in part ?
be an issueof coverage: many of the sentences for which onlythe manually aligned fragment base produces trans-lations are translationally complex and, therefore,more likely to be only partially correct and achievepoor scores.Finally, we determined the subset of sentencesfor which translations were produced both whenthe manually aligned fragment bases were used and2The link depth of a fragment pair is defined as greatestnumber of steps taken which depart from a linked node to getfrom the root node to any frontier nodes (Hearne and Way,2003).3http://www.nist.gov/speech/tests/mt/mt2001/resource/4http://nlp.cs.nyu.edu/GTM/5The Bleu scores shown here differ from those published in(Hearne and Way, 2003) as a result of recent modifications tothe NIST MT Evaluation Kit.Bleu/Auto Bleu/Man F-Score/Auto F-Score/ManLD1 0.6118 0.6591 0.7900 0.8090LD2 0.7519 0.7144 0.8751 0.8446LD3 0.7790 0.7610 0.8887 0.8688LD4 0.7940 0.7611 0.8930 0.8736Figure 10: Evaluation over translations producedBleu/Auto Bleu/Man F-Score/Auto F-Score/ManLD1 0.5945 0.6363 0.7918 0.7989LD2 0.7293 0.7382 0.8823 0.8629LD3 0.7700 0.7930 0.8938 0.8913LD4 0.7815 0.7940 0.8964 0.8933Figure 11: Evaluation of sentences translated by bothalignment methodswhen the automatically linked ones were used.
Fig-ure 11 summarises the results achieved when eval-uating only these translations.
In terms of Bleuscores, translations produced using manual align-ments score slightly better at all depths.
However,as link depth increases the gap narrows consistentlyand at depth 4 the difference in scores is reducedto just 0.0125.
In terms of f-scores, the translationsproduced using automatic alignments actually scorebetter than those produced using manual alignmentsat depths 2 - 4.5.3 DiscussionOur first evaluation method (Section 5.1) is, per-haps, the obvious one to use when evaluating align-ment performance.
However, the results of thisevaluation, which show best f-scores of 70%, pro-vide no insight into the effect using these align-ments has on translation accuracy.
Evaluating thesealignments in context ?
by using them in the DOTsystem for which they were intended ?
gives us atrue picture of their worth.
Crucially, in Section 5.2we showed that using automatic rather than manualalignments results in translations of extremely highquality, comparable to those produced using manualalignments.In many cases, translations produced using au-tomatic alignments contain fewer errors involvinglocal syntactic phenomena than those produced us-ing manual alignment.
This suggests that, as linksbetween function words are infrequent in the au-tomatic alignments, we achieve better modellingof phenomena such as determiner-noun agreementbecause the determiner fragments do not gener-ally occur without context.
For example, there arerelatively few instances of ?D?the?
aligned with?D?le/la/l?/les?
in the automatic alignment com-pared to the manual alignment.On the other hand, we achieve 10% less coveragewhen translating using the automatic alignments.The automatic alignments are less likely to identifynon-local phenomena such as long-distance depen-dencies.
Consequently, the sentences only trans-lated when using manual alignments are generallylonger and more complex than those translated byboth.
While a degree of trade-off between coverageand accuracy is to be expected, we would like toincrease coverage while maintaining or improvingtranslation quality.
Improvements to lexical align-ment should prove valuable in this regard.
Whilewe expect translation quality to improve as depthincreases, experiments using the automatical align-ment show disproportionately poor performance atdepth 1.
The majority of links in the depth 1 frag-ment base are inserted using the lexical aligner, in-dicating that these are less than satisfactory.
We ex-pect improvements to the lexical aligner to signifi-cantly improve the overall performance of the align-ment algorithm and, consequently, the quality of thetranslations produced.
Lexical alignment is crucialin identifying complex phenomena such as long dis-tance dependencies.
Using machine-readable bilin-gual dictionaries or, alternatively, manually estab-lished word-alignments to intiate the automatic sub-structural alignment algorithm may provide moreaccurate results.6 Conclusions and future workWe have presented an automatic algorithm whichaligns bilingual context-free phrase-structure treesat sub-structural level and applied this algorithm toa subset of the English-French section of the Home-Centre corpus.
We have outlined detailed eval-uations of our algorithm.
They show that whiletranslation coverage was 10% lower using the au-tomatically aligned data, the quality of the trans-lations produced is comparable to the quality ofthose produced using manual alignments.
WhileDOT systems produce very high quality transla-tions in reasonable time, resource acquisition re-mains an issue.
Manual sub-structural alignment istime-consuming, error-prone and requires consider-able linguistic expertise.
Our alignment method, onthe other hand, is efficient, consistent and language-independent, constituting a viable alternative tomanual sub-structural alignment; thus solving thedata acquisition problem.We intend to apply our automatic alignmentmethodology to the full English-French section ofthe HomeCentre corpus, as well as the English-German and French-German sections, and performexperiments to further validate the the language-independent nature of both our alignment algorithmand the data-oriented approach to translation.
Wealso plan to automatically parse existing bitexts,thus creating further resources for use with ourDOT system and, together with our aligner, en-abling much larger-scale DOT-based translation ex-periments than have been performed to date.7 AknowledgementsThe work presented in this paper is partly supportedby an IRCSET 6 PhD Fellowship Award.ReferencesRens Bod.
1998.
Beyond Grammar: An Experience-Based Theory of Language.
CSLI, Stanford, CA.Rens Bod, Remko Scha and Khalil Sima?an.
(eds.)
2003.Data-Oriented Parsing.
CSLI, Stanford CA.Yuan Ding, Dan Gildea and Martha Palmer.
2003.
AnAlgorithm for Word-Level Alignment of Parallel De-pendency Trees.
MT Summit IX.
New Orleans, LO.,pp.95?101.Jason Eisner.
2003.
Learning Non-Isomorphic TreeMappings for Machine Translation.
In Proceedings ofthe 41st COLING, Sapporo, Japan.Pascale Fung & Ken W. Church.
1994.
K-vec: A NewApproach for Aligning Parallel Texts.
In Proceedingsof COLING 94, Kyoto, Japan, pp.1096-1102.William A. Gale & Ken W. Church.
1993.
A programfor aligning sentences in bilingual corpora.
Computa-tional Linguistics 19(1):75?102.Daniel Gildea.
2003.
Loosely Tree-Based Alignment forMachine Translation.
In Proceedings of the 41st ACL.Sapporo, Japan, pp.80?87.Mary Hearne and Andy Way.
2003.
Seeing the Woodfor the Trees: Data-Oriented Translation.
MT SummitIX.
New Orleans, LO., pp.165?172.Kenji Imamura.
2001.
Hierarchical Phrase AlignmentHarmonized With Parsing.
In Proceedings of theSixth Natural Language Processing Pacific Rim Sym-posium.
Tokyo, Japan, pp.377?384.Martin Kay and Martin Ro?scheisen.
1993.
Text-translation alignment.
Computational Linguistics19(1):121?142.Yuji Matsumoto, Ishimoto Hiroyuki and Takehito Ut-suro.
1993.
Structural Matching of Parallel Texts.
InProceedings of the 31st ACL.
Columbus, OH., pp.23?30.Arul Menezes and Stephen D. Richardson.
2003.
ABest-First Alignment Algorithm for Automatic Ex-traction of Transfer Mappings from Bilingual Cor-pora.
In M. Carl & A.
Way (eds.)
Recent Advancesin Example-Based Machine Translation.
KluwerAcademic Publishers, Dordrecht, The Netherlands,pp.421?442.Arjen Poutsma.
2000.
Data-Oriented Translation.
In18th COLING, Saarbru?cken, Germany, pp.635?641.6http://www.ircset.ie
