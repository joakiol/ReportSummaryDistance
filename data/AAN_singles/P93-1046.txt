INTEGRATING WORD BOUNDARY IDENTIF ICAT IONWITH SENTENCE UNDERSTANDINGKok  Wee GanDepartment of Information Systems eJ Computer ScienceNational University of SingaporeKent  R idge  Crescent ,  S ingapore  0511In ternet :  gankw@iscs.nus.sgAbst rac tChinese sentences are written with no special delimiterssuch as space to indicate word boundaries.
Existing Chi-nese NLP systems therefore mploy preprocessors to seg-ment sentences into words.
Contrary to the conventionalwisdom of separating this issue from the task of sentenceunderstanding, we propose an integrated model that per-forms word boundary identification in lockstep with sen-tence understanding.
In this approach, there is no distinc-tion between rules for word boundary identification andrules for sentence understanding.
These two functions arecombined.
Word boundary ambiguities are detected, es-pecially the fallacious ones, when they block the primarytask of discovering the inter-relationships among the var-ious constituents of a sentence, which essentially is theessence of the understanding process.
In this approach,statistical information is also incorporated, providing thesystem a quick and fairly reliable starting ground to carryout the primary task of relationship- building.1 THE PROBLEMChinese sentences are written with no special delimiterssuch as space to indicate word boundaries.
Existing Chi-nese NLP systems therefore mploy preprocessors to seg-ment sentences into words.
Many techniques have been de-veloped for this task, from simple pattern matching meth-ods (e.g., maximum matching, reverse maximum match-ing) (Wang, et al, 1990; Kang & Zheng, 1991), to statis-tical methods (e.g., word association, relaxation) (Sproat& Shih, 1990; Fan & Tsai, 1988), to rule-based approaches(Huang, 1989 ; Yeh & Lee, 1991; He, et al, 1991).However, it is observed that simple pattern matchingmethods and stochastic methods perform poorly in sen-tences uch as (1), (2), and (3), where word boundary am-biguities exist.
1(1) ta benren sheng leShe alone give birth to ASPsan ge haizithree CL childShe alone gives birth to three children.
(2) ta zhi kao duo shi fenH/She only score up to ten markH/She scores only ten marks.1The ambiguous fragments in italics in (1), (2), and (3), ben-ten sheng, shi .fen, and he shang, will be wrongly identified as:ben rensheng, shi.fen, and heshang, respectively, by statisticalapproaches.301(3) zhongguo yi kaifa heChina already develop andshang wei kaifa deyet not develop ASSOCshiyou ziyuan hen duooil resource very manyThere are many developed and not yetdeveloped oil resources in China.This problem can be dealt with in a more systematic andeffective way if syntactic and semantic analyses are also in-corporated.
The frequency in which this problem occursjustifies the additional effort needed.
However, contempo-rary approaches of constructing a standalone, rule-basedword segmentor do not offer the solution, as this wouldmean duplicating the effort of syntactic and semantic anal-yses twice: first in the preprocessing phase, and later inthe understanding phase.
Moreover, separating the issueof word boundary identification from sentence understand-ing often leads to devising word segmentation rules whichare arbitrary and word specific, 2 and hence not useful atall for sentence understanding.
Most importantly, the rulesdevised always face the problem of over-generalization.Contrary to conventional wisdom, we do not view thetask of word boundary identification as separated from thetask of sentence understanding.
Rather, the former is re-garded as one of the tasks an NLP system must handlewithin the understanding phase.
This perspective allowsus to devise a more systematic and natural solution to theproblem, at the same time avoiding the duplication of mor-phological, syntactic, and semantic analyses in two sepa-rate stages: the preprocessing stage and the understandingstage.The basic principle underlying this approach is: ev-ery constituent in a sentence must be meaningfully re-lated (syntactically and/or semantically) to some otherconstituent.
Understanding a sentence is simply a pro-cess to discover this network of relations.
A violation ofthis principle signifies the presence of abnormal groupings(fallacious word boundaries), which must be removed, aFor example, the fallacious grouping rensheng 'life', if itexists in (1), can be detected by observing a violation ofthe syntactic relation between this group and le, which is2 For example, a heuristic rule to resolve the ambiguous frag-ment shi fen in (2): adverb shifen 'very' cannot occur at theend of a sentence.
This rule rules out the grouping shifen toappear in sentence (2).3This principle, in its present form, is too tight for handlingmetonymic usage of language, as well as ill-formed sentences.We will leave this for future work.an aspect marker that cannot be a nominal modifier.
In(2), selectional restrictions on the RANGE of the verb kao,which must either be pedagogical (e.g., kao shuzue 'testMathematics'), resultative (e.g., kao shibai le 'test fail AS-PECT') ,  or time (e.g., kao le yi ge zingqi 'test ASPECTone week'), rules out the grouping shifen 'very', which isa degree marker.
4 Sentence (3) also requires thematicrole interpretation to resolve the ambiguous fragment.
Se-lectional restrictions on the PATIENT of the verb kaifa'develop', which must be either a concrete material (e.g.,kaifa meikuang 'develop coal mine') or a location (e.g.,kaifa sanqu 'develop rural area'), rules out interpreting theambiguous fragment he shang as heshang 'monk'.
5This approach, however, does not totally discard theuse of statistical information.
On the contrary, we usestatistical information s to give our system a quick andfairly reliable initial guess of the likely word boundariesin a sentence.
Based on these suggested word boundaries,the system proceeds to the primary task of determiningthe syntactic and semantic relations that may exist in thesentence (i.e., the understanding process).
Any violationencountered in this process signals the presence of abnor-mal groupings, which must be removed.Our approach will not lead to an exceedingly complexsystem, mainly because we have made use of statisticalinformation to provide us the initial guide.
It does notgenerate all possible word boundary combinations in orderto select the best one.
Rather, alternative paths are ex-plored only when the current one leads to some violation.This feature makes its complexity not more than that of atwo-stage system where syntax and semantics at the laterstage of processing signal to the preprocessor that certainlexemes have been wrongly identified.2 THE PROPOSED MODELThe approach we proposed takes in as input a stream ofcharacters of a sentence rather than a collection of cor-rectly pre-segmented words.
It performs word boundarydisambiguation concurrently with sentence understanding.In our investigation, we focus on sentences with clearlyambiguous word boundaries as they constitute an appro-priate testbed for us to investigate the deeply interwovenrelationships between these two tasks.Since we are proposing an integrated approach to wordboundary identification and sentence understanding, con-ventional sequential-based architectures are not appropri-ate.
A suitable computational model should have at least4Notice the difference between this knowledge and the onementioned in footnote 2.
Both are used to disambiguate hefragment shi .fen.
The former is more ad hoc while ours comesin naturally as part and parcel of thematic role interpretation.awe would like to stress that rules in this approach are notdistinguished into two separate classes, one for resolving wordboundary ambiguities and the other for sentence understand-ing.
Ours combine these two functions together, performingword boundary identification alongside with sentence under-standing.
We will give a detailed escription on the effective-ness of the various kinds of information after we have completedour implementation.6See Section 3 for an example.the following features: (i) linguistic information such asmorphology, syntax, and semantics hould be available si-multaneously so that it can be drawn upon whenever nec-essary; (ii) the architecture should allow competing inter-pretations to coexist and give each one a chance to develop;(iii) partial solutions should be flexible enough that theycan be easily modified and regrouped; (iv) the architec-ture can support localized inferencing which will eventuallyevolve into a global, coherent interpretation of a sentence.We are using the Copycat model (Hofstadter, 1984;Mitchell, 1990), which has been developed and tested inthe domain of analogy-making.
There are four compo-pents in this architecture: the conceptual network (en-codes linguistic concepts), the workspace (the workingarea), the coderack (a pool of codelets waiting to run),and the temperature (controls the rate of understanding).Our model will differ from NLP systems with a similarapproach (Goldman, 1990; Hirst, 1988; Small, 1980) pri-marily through the incorporation of statistical methods,and the nondeterministic control mechanism used.
7 Fora detailed discussion, see (Gan, et al, 1992).
In essence,this model simulates the understanding process as a crys-tallization process, in which high-level linguistic structures(e.g., words; analogous to crystals) are formed and hookedup in a proper way as characters (ions) of a sentence aregradually cooled down.3 AN EXAMPLEWe will use sentence (1) to briefly outline how the modelworks, s(1) ta benren sheng le san ge haizi 9. bottom-up structure buildingThe system starts with bottom-up, character-basedcodelets in the coderack whose task is to evaluate the as-sociative strength between two neighboring characters.10 One of the codelets will be chosen probabilistieally torun.
11 The executing codelet selects an object from theworkspace and tries to build some structures on it.
For7See also footnote 11.SOur description here is oversimplified.
Many importantissues, such as the representation f linguistic knowledge, thetreatment of ambiguous fragments that have multiple equallyplausible word boundaries, are omitted.
The example discussedin this section is a hand-worked test case which is currentlybeing implemented.9The English glosses and translation are omitted here, asthey have been shown in Section 1.1?The association between two characters i measured basedon mutual information (Fano, 1961).
It is derived from thefrequency that the two characters occur together versus thefrequency that they are independent.
Here, we find that statis-tical techniques can be nicely incorporated into the model Wewill derive this information from a corpus of 46,520 words of to-tal usage frequency of 13019,814 given to us by Liang Nanyuanof the Beijing University of Aeronautics and Astronautics.11This is another way statistics is used.
The selection ofwhich codelet o run, and the selection of which object to workon are decided probabilistically depending on the system tem-perature.
This is the nondeterministic control mechanism en-tioned in Section 2.302example, it may select the last two characters hai and ziin (1) and evaluate their associative strength as equal to13.34.
This association is so strong that another codeletwill be called upon to group these two characters into aword-structure, which forms the word haizi 'children'.
* top-down influencesThe formation of the word-structure haizi activates theWORD 12 node in the network of linguistic concepts.This network is a dynamic controller to ensure thatbottom-up rocesses do not proceed independently ofthe system's understanding of the global situation.
Theactivation of the WORD node in turn causes the postingof top-down codelets couting for other would-be word-structures.
Thus, single-character words such as ta 'she',le (aspect marker), san 'three', and ge (a classifier) maybe discovered.?
radical restructuringThe characters ren and sheng will be grouped as a wordrensheng 'life' by bottom-up, character-based codelets,as the associative strength between them is strong(3.75).
This is incorrect in (1).
It will be detected whenan ASPECT-relation builder, spawned after identifyingle as an aspect marker, tries to construct a syntacticrelation between the word-structure rensheng 'life' andthe word-structure l  (ASPECT).
Since this relation canonly be established with a verb, a violation occurs, whichcauses the temperature to be set to its maximal value.The problematic structure rensheng will be dissolved,and the system proceeds in its search for an alternative,recording down in its memory that this structure ren-sheng should not be tried again in future, x34 SUMMARYIn this model, there is an implicit order in which codeletsare executed.
At the initial stage, the system is more con-cerned with identifying words.
After some word-structureshave been built, other types of codelets begin to decipherthe syntactic and semantic relations between these struc-tures.
From then on, the word identification and higher-level analyses proceed hand-in-hand.
In short, the mainideas in our model are: (i) a parallel architecture in whichhierarchical, inguistic structures are built up in a piece-meal fashion by competing and cooperating chains of sim-ple, independently acting codelets; (ii) a notion of fluid re-conformability of structures built up by the system; (iii) aparallel terraced scan (Hofstadter, 1984) of possible coursesof action; (iv) a temperature variable that dynamically ad-justs the amount of randomness in response to how happythe system is with its currently built structures.ACKNOWLEDGMENTSThis paper will not be in its present form without theinvaluable input from Dr. Martha Palmer.
I would liketo express my greatest thanks to her.
I would also like to12This is a node in the conceptual network, which is activatedwhen the system finds that the word concept is relevant o thetask it is currently investigating.13We will skip the implementation details here.thank Guojin, Wu Jianhua, Paul Wu, and Wu Zhibiao fortheir feedback on an earlier draft.REFERENCESFan, C. K. and Tsai, W. H. (1988) Automatic word identi-fication in Chinese sentences by the relaxation technique.Computer Processing of Chinese and Oriental Languages,4(1):33-56.Fano, R. (1961) Transmission of information.
MITPress, Cambridge MA.Goldman, R. (1990) A probabilistic approach to lan-guage understanding.
PhD thesis, Department of Com-puter Science, Brown University.Gan, K. W., Lua, K. T. and Palmer, M. (1992) Model-ing language understanding asa crystallization process: anapplication to ambiguous Chinese word boundaries identi-fication.
Technical Report TR50/92, Department of Infor-mation Systems and Computer Science, National Univer-sity of Singapore.He, K. K, Xu, H. and Sun, B.
(1991) Design principle ofexpert system for automatic words segmentation i  writ-ten Chinese.
Journal of Chinese Information Processing,5(2):1-14 (in Chinese).Hirst, G. (1988) Resolving lexicM ambiguity computa-tionally with spreading activation and polaroid words.
InS.
L. Small, G. W. Cottrell, M. K. Tanenhaus (Eds.
), Lex-icM ambiguity resolution, perspectives from psycholinguis-tics, neuropsychology and artificial intelligence; MorganKaufmann Publishers, San Meteo, California, 73-107.Hofstadter, D. R. (1984) The Copycat project: an ex-periment in non-determinism and creative analogies.
AIMemo No.
755, Massachusetts Institute of Technology,Cambridge, M. A.Huang, X. X.
(1989) A "produce-test" approach to auto-matic segmentation f written Chinese.
Journal of ChineseInformation Processing, 3(4):42-48 (in Chinese).Kang, L. S. and Zheng, J. H. (1991) An algorithm forword segmentation based on mark.
In Proceedings of the10th anniversary of the Chinese Information ProcessingSociety, Beijing, 222-226 (in Chinese).Mitchell, M. (1990) COPYCAT: a computer model ofhigh-level perception and conceptual slippage in analogy-making.
PhD.
Dissertation, University of Michigan.Small, S. L. (1980) Word expert parsing: a theory ofdistributed word-based natural language understanding.PhD.
dissertation, University of Maryland.Sproat, R. and Shih, C. L. (1990) A statistical methodfor finding word boundaries in Chinese text.
ComputerProcessing of Chinese and Oriental Languages, 4(4):336-351.Wang, Y. C., Su, It.
J. and Mo, Y.
(1990) Automaticprocessing Chinese word.
Journal of Chinese InformationProcessing, 4(4):1-11 (in Chinese).Yeh, C. L. and Lee, It.
J.
(1991) Rule-based word iden-tification for Mandarin Chinese sentences - a unificationapproach.
Computer Processing of Chinese and OrientalLanguages, 5(2):97-118.303
