Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 199?206,Sydney, July 2006. c?2006 Association for Computational LinguisticsChinese-English Term Translation Mining Based onSemantic PredictionGaolin Fang, Hao Yu, and Fumihito NishinoFujitsu Research and Development Center, Co., LTD. Beijing 100016, China{glfang, yu, nishino}@cn.fujitsu.comAbstractUsing abundant Web resources to mineChinese term translations can be appliedin many fields such as reading/writing as-sistant, machine translation and cross-language information retrieval.
In miningEnglish translations of Chinese terms,how to obtain effective Web pages andevaluate translation candidates are twochallenging issues.
In this paper, the ap-proach based on semantic prediction isfirst proposed to obtain effective Webpages.
The proposed method predictspossible English meanings according toeach constituent unit of Chinese term, andexpands these English items usingsemantically relevant knowledge forsearching.
The refined related terms areextracted from top retrieved documentsthrough feedback learning to construct anew query expansion for acquiring moreeffective Web pages.
For obtaining a cor-rect translation list, a translationevaluation method in the weighted sum ofmulti-features is presented to rank thesecandidates estimated from effective Webpages.
Experimental results demonstratethat the proposed method has good per-formance in Chinese-English term trans-lation acquisition, and achieves 82.9%accuracy.1 IntroductionThe goal of Web-based Chinese-English (C-E)term translation mining is to acquire translationsof terms or proper nouns which cannot be lookedup in the dictionary from the Web using a statis-tical method, and then construct an applicationsystem for reading/writing assistant (e.g., ???
?The Romance of Three Kingdoms).
Duringtranslating or writing foreign language articles,people usually encounter terms, but they cannotobtain native translations after many lookup ef-forts.
Some skilled users perhaps resort to a Websearch engine, but a large amount of retrievedirrelevant pages and redundant information ham-per them to acquire effective information.
Thus,it is necessary to provide a system to automati-cally mine translation knowledge of terms usingabundant Web information so as to help usersaccurately read or write foreign language articles.The system of Web-based term translationmining has many applications.
1) Read-ing/writing assistant.
2) The construction tool ofbilingual or multilingual dictionary for machinetranslation.
The system can not only providetranslation candidates for compiling a lexicon,but also rescore the candidate list of the diction-ary.
We can also use English as a medium lan-guage to build a lexicon translation bridgebetween two languages with few bilingual anno-tations (e.g., Japanese and Chinese).
3) Providethe translations of unknown queries in cross-language information retrieval (CLIR).
4) As oneof the typical application paradigms of the com-bination of CLIR and Web mining.Automatic acquisition of bilingual translationshas been extensively researched in the literature.The methods of acquiring translations are usuallysummarized as the following six categories.
1)Acquiring translations from parallel corpora.
Toreduce the workload of manual annotations, re-searchers have proposed different methods toautomatically collect parallel corpora of differentlanguage versions from the Web (Kilgarriff,2003).
2) Acquiring translations from non-parallel corpora (Fung, 1997; Rapp, 1999).
It isbased on the clue that the context of source termis very similar to that of target translation in alarge amount of corpora.
3) Acquiring transla-tions from a combination of translations of con-stituent words (Li et al, 2003).
4) Acquiringtranslations using cognate matching (Gey, 2004)199or transliteration (Seo et al, 2004).
This methodis very suitable for the translation between twolanguages with some intrinsic relationships, e.g.,acquiring translations from Japanese to Chineseor from Korean to English.
5) Acquiring transla-tions using anchor text information (Lu et al,2004).
6) Acquiring translations from the Web.When people use Asia language (Chinese, Japa-nese, and Korean) to write, they often annotateassociated English meanings after terms.
Withthe development of Web and the open of accessi-ble electronic documents, digital library, and sci-entific articles, these resources will become moreand more abundant.
Thus, acquiring term transla-tions from the Web is a feasible and effectiveway.
Nagata et al (2001) proposed an empiricalfunction of the byte distance between Japaneseand English terms as an evaluation criterion toextract translations of Japanese words, and theresults could be used as a Japanese-English dic-tionary.Cheng et al (2004) utilized the Web as thecorpus source to translate English unknown que-ries for CLIR.
They proposed context-vector andchi-square methods to determine Chinese transla-tions for unknown query terms via mining of top100 search-result pages from Web search engines.Zhang and Vines (2004) proposed using a Websearch engine to obtain translations of Chineseout-of-vocabulary terms from the Web to im-prove CLIR performance.
The method used Chi-nese as query items, and retrieved previous 100document snippets by Google, and then estimatedpossible translations using co-occurrence infor-mation.From the review above, we know that previousrelated researches didn?t concern the issue how toobtain effective Web pages with bilingualannotations, and they mainly utilized thefrequency feature as the clue to mine thetranslation.
In fact, previous 100 Web resultsseldom contain effective English equivalents.Apart from the frequency information, there aresome other features such as distribution, lengthratio, distance, keywords, key symbols andboundary information which have very importantimpacts on term translation mining.
In this paper,the approach based on semantic prediction isproposed to obtain effective Web pages; foracquiring a correct translation list, the evaluationstrategy in the weighted sum of multi-features isemployed to rank the candidates.The remainder of this paper is organized asfollows.
In Section 2, we give an overview of thesystem.
Section 3 proposes effective Web pagecollection.
In Section 4, we introduce translationcandidate construction and noise solution.
Sec-tion 5 presents candidate evaluation based onmulti-features.
Section 6 shows experimentalresults.
The conclusion is drawn in the last sec-tion.2 System OverviewThe C-E term translation mining system based onsemantic prediction is illustrated in Figure 1.Figure 1.
The Chinese-English term translation min-ing system based on semantic predictionThe system consists of two parts: Web pagehandling and term translation mining.
Web pagehandling includes effective Web page collectionand HTML analysis.
The function of effectiveWeb page collection is to collect these Webpages with bilingual annotations using semanticprediction, and then these pages are inputted intoHTML analysis module, where possible featuresand text information are extracted.
Term transla-tion mining includes candidate unit construction,candidate noise solution, and rank&sort candi-dates.
Translation candidates are formed throughcandidate unit construction module, and then weanalyze their noises and propose the correspond-ing methods to handle them.
At last, the approachusing multi-features is employed to rank thesecandidates.Correctly exploring all kinds of bilingual anno-tation forms on the Web can make a mining sys-tem extract comprehensive translation results.After analyzing a large amount of Web page ex-amples, translation distribution forms is summa-rized as six categories in Figure 2: 1) Directannotation (a).
some have nothing (a1), and somehave symbol marks (a2, a3) between the pair; 2)Separate annotation.
There are English letters (b1)or some Chinese words (b2, b3) between the pair;3) Subset form (c); 4) Table form (d); 5) Listform (e); and 6) Explanation form (f).Query?????WWWFeatures1.
Frequency2.
Distribution3.
Distance4.
Length ratio5.
Key symbolsand boundaryRank & sortcandidatesCandidate unitconstruction Result?Mont Blanc?EffectiveWeb pagecollectionHTMLanalysisCandidate noisesolution200Figure 2.
The examples of translation distributionforms3 Effective Web page collectionFor mining the English translations of Chineseterms and proper names, we must obtain effectiveWeb pages, that is, collecting these Web pagesthat contain not only Chinese characters but alsothe corresponding English equivalents.
However,in a general Web search engine, when you input aChinese technical term, the number of retrievedrelevant Web pages is very large.
It is infeasibleto download all the Web pages because of a hugetime-consuming process.
If only the 100 abstractsof Web pages are used for the translation estima-tion just as in the previous work, effective Eng-lish equivalent words are seldom contained formost Chinese terms in our experiments, for ex-ample: ????
?, ???
?, ????
?, ????.
In this paper, a feasible method based onsemantic prediction is proposed to automaticallyacquire effective Web pages.
In the proposedmethod, possible English meanings of every con-stituent unit of a Chinese term are predicted andfurther expanded by using semantically relevantknowledge, and these expansion units with theoriginal query are inputted to search bilingualWeb pages.
In the retrieved top-20 Web pages,feedback learning is employed to extract moresemantically-relevant terms by frequency andaverage length.
The refined expansion terms, to-gether with the original query, are once more sentto retrieve effective relevant Web pages.3.1 Term expansionTerm expansion is to use predictive semantically-relevant terms of target language as the expan-sion of queries, and therefore resolve the issuethat top retrieved Web pages seldom contain ef-fective English annotations.
Our idea is based onthe assumption that the meanings of Chinesetechnical terms aren?t exactly known just throughtheir constituent characters and words, but theclosely related semantics and vocabulary infor-mation may be inferred and predicted.
For exam-ple, the corresponding unit translations of a term??????
are respectively: three(?
), country,nation(?
), act, practice(?
), and meaning, jus-tice(?).
As seen from these English translations,we have a general impression of ?things aboutthree countries?.
After expanding, the query itemfor the example above becomes "????
"+(three | country | nation | act | practice | meaning |justice).
The whole procedure consists of threesteps: unit segmentation, item translation knowl-edge base construction, and expansion knowl-edge base evaluation.Unit segmentation.
Getting the constituentunits of a technical term is a segmentation proce-dure.
Because most Chinese terms consist of out-of-vocabulary words or meaningless characters,the performance using general word segmenta-tion programs is not very desirable.
In this paper,a segmentation method is employed to handleterm segmentation so that possible meaningfulconstituent units are found.
In the inner structureof proper nouns or terms, the rightmost unit usu-ally contains a headword to reflect the majormeaning of the term.
Sometimes, the modifierstarts from the leftmost point of a term to form amulti-character unit.
As a result, forward maxi-mum matching and backward maximum match-ing are respectively conducted on the term, andall the overlapped segmented units are added tocandidate items.
For example, for the term?abcd?, forward segmented units are ?ab cd?,backward are ?a bcd?, so ?ab cd a bcd?
will beviewed as our segmented items.Item translation knowledge base construc-tion.
Because the segmented units of a technicalterm or proper name often consist of abbreviationitems with shorter length, limited translationsprovided by general dictionaries often cannotsatisfy the demand of translation prediction.
Here,a semantic expansion based method is proposedto construct item translation knowledge base.
Inthis method, we only keep these nouns or adjec-tive items consisting of 1-3 characters in the dic-tionary.
If an item length is greater than twocharacters and contains any item in the knowl-edge base, its translation will be added as transla-tion candidates of this item.
For example, theChinese term ?????
can be segmented intothe units ????
and ??
?, where ???
has onlytwo English meanings ?section, thigh?
in the dic-tionary.
However, we can derive its meaning us-(a1) (a2) (a3)(b1) (b2) (b3)(c) (d) (e) (f)201ing the longer word including this item such as??
?, ???.
Thus, their respective translations?stock, stockholder?
are added into the knowl-edge base list of ???
(see Figure 3).Figure 3.
An expansion example in the dictionaryknowledge baseExpansion knowledge base evaluation.
Toavoid over-expanding of translations for one item,using the retrieved number from the Web as ourscoring criterion is employed to remove irrele-vant expansion items and rank those possiblecandidates.
For example, ???
and its expansiontranslation ?stock?
are combined as a new query??
stock ????.
It is sent to a general searchengine like Google to obtain the count number,where only the co-occurrence of ?
?
?
and?stock?
excluding the word ????
is counted.The retrieved number is about 316000.
If the oc-currence number of an item is lower than a cer-tain threshold (100), the evaluated translationwill not be added to the item in the knowledgebase.
Those expanded candidates for the item inthe dictionary are sorted through their retrievednumber.3.2 Feedback learningThough pseudo-relevance feedback (PRF) hasbeen successfully used in the information re-trieval (IR), whether PRF in single-language IRor pre-translation PRF and post-translation PRFin CLIR, the feedback results are from sourcelanguage to source language or target language totarget language, that is, the language of feedbackunits is same as the retrieval language.
Our novelis that the input language (Chinese) is differentfrom the feedback target language (English), thatis, realizing the feedback from source language totarget language, and this feedback technique isalso first applied to the term mining field.After the expansion of semantic prediction, thepredicted meaning of an item has some devia-tions with its actual sense, so the retrieved docu-ments are perhaps not our expected results.
Inthis paper, a PRF technique is employed to ac-quire more accurate, semantically relevant terms.At first, we collect top-20 documents from searchresults after term expansion, and then selecttarget language units from these documents,get language units from these documents, whichare highly related with the original query insource language.
However, how to effectivelyselect these units is a challenging issue.
In theliterature, researchers have proposed differentmethods such as Rocchio?s method or Robert-son?s probabilistic method to solve this problem.After some experimental comparisons, a simpleevaluation method using term frequency and av-erage length is presented in this paper.
Theevaluation method is defined as follows:1)(1)()(+?+= ttftw , where NtsDtNi i?=?
=1 ),()(  (1)?
(t) represents the average length between thesource word s and the target candidate t. If thegreater that the average length is, the relevancedegree between source terms and candidates willbecome lower.
The purpose of adding ?
(t) to 1is to avoid the divide overflow in the case that theaverage length is equal to zero.
Di(s,t) denotes thebyte distance between source words and targetcandidates, and N represents the total number ofcandidate occurrences in the estimated Webpages.
This evaluation method is very suitable forthe discrimination of these words with lower, butsame term frequencies.
In the ranked candidatesafter PRF feedback, top-5 candidates are selectedas our refined expansion items.
In the previousexample, the refined expansion items are: King-doms, Three, Romance, Chinese, Traditional.These refined expansion terms, together with theoriginal query, "????
"+(Kingdoms | Three |Romance | Chinese | Traditional) are once moresent to retrieve relevant results, which are viewedas effective Web pages used in the process of thefollowing estimation.4 Translation candidate construction andnoise solutionThe goal of translation candidate construction isto construct and mine all kinds of possible trans-lation forms of terms from the Web, and effec-tively estimate their feature information such asfrequency and distribution.
In the transferred text,we locate the position of a query keyword, andthen obtain a 100-byte window with keyword asthe center.
In this window, each English word isbuilt as a beginning index, and then string candi-dates are constructed with the increase of stringin the form of one English word unit.
String can-didates are indexed in the database with hash andbinary search method.
If there exists the sameitem as the inputted candidate, its frequency isincreased by 1, otherwise, this candidate is added???
?
?202to this position of the database.
After handlingone Web page, the distribution information isalso estimated at the same time.
In the program-ming implementation, the table of stop words andsome heuristic rules of the beginning and endwith respect to the keyword position are em-ployed to accelerate the statistics process.The aim of noise solution is to remove these ir-relevant items and redundant information formedin the process of mining.
These noises are de-fined as the following two categories.1) Subset redundancy.
The characteristic isthat this item is a subset of one item, but its fre-quency is lower than that item.
For example, ????
?License plate number (6), License plate(5)?, where the candidate ?License plate?
belongsto subset redundancy.
They should be removed.2) Affix redundancy.
The characteristic is thatthis item is the prefix or suffix of one item, but itsfrequency is greater than that item.
For example,1.
?????
: Three Kingdoms (30), Romanceof the Three Kingdoms (22), The Romance ofThree Kingdoms (7)?, 2.
????
: Blue Chip(35), Blue Chip Economic Indicators (10)?.
InExample 1, the item ?Three Kingdoms?
is suffixredundancy and should be removed.
In Example2, the term ?Blue Chip?
is in accord with thedefinition of prefix redundancy information, butthis term is a correct translation candidate.
Thus,the problem of affix redundancy information isso complex that we need an evaluation method todecide to retain or drop the candidate.To deal with subset redundancy and affixredundancy information, sort-based subsetdeletion and mutual information methods arerespectively proposed.
More details refer to ourprevious paper (Fang et al, 2005).5 Candidate evaluation based on multi-features5.1 Possible features for translation pairsThrough analyzing mass Web pages, we obtainthe following possible features that have impor-tant influences on term translation mining.
Theyinclude: 1) candidate frequency and its distribu-tion in different Web pages, 2) length ratio be-tween source terms and target candidates (S-T), 3)distance between S-T, and 4) keywords, keysymbols and boundary information between S-T.1) Candidate frequency and its distributionTranslation candidate frequency is the mostimportant feature and is the basis of decision-making.
Only the terms whose frequencies aregreater than a certain threshold are further con-sidered as candidates in our system.
Distributionfeature reflects the occurrence information of onecandidate in different Webs.
If the distribution isvery uniform, this candidate will more possiblybecome as the translation equivalent with agreater weight.
This is also in accord with ourintuition.
For example, the translation candidatesof the term ??????
include ?put option?
and?short put?, and their frequencies are both 5.However, their distributions are ?1, 1, 1, 1, 1?and ?2, 2, 1?.
The distribution of ?put option?
ismore uniform, so it will become as a translationcandidate of ??????
with a greater weight.2) Length ratio between S-TThe length ratio between S-T should satisfycertain constraints.
Only the word number of acandidate falls within a certain range, the possi-bility of becoming a translation is great.To estimate the length ratio relation betweenS-T, we conduct the statistics on the databasewith 5800 term translation pairs.
For example,when Chinese term has three characters, i.e.
W=3,the probability of English translations with twowords is largest, about P(E=2 |W =3)= 78%, andthere is nearly no occurrence out of the range of1-4.
Thus, different weights can be impacted ondifferent candidates by using statistical distribu-tion information of length ratio.
The weight con-tributing to the evaluation function is setaccording to these estimated probabilities in theexperiments.3) Distance between S-TIntuitively, if the distance between S-T islonger, the probability of being a translation pairwill become smaller.
Using this knowledge wecan alleviate the effect of some noises throughimpacting different weights when we collect pos-sible correct candidates far from the source term.To estimate the distance between S-T, experi-ments are carried on 5800*200 pages with 5800term pairs, and statistical results are depicted asthe histogram of distances in Figure 4.02000400060008000100001200014000-100 -75 -50 -25 0 25 50 75 100Figure 4.
The histogram of distances between S-T203In the figure, negative value represents thatEnglish translation located in front of the Chineseterm, and positive value represents English trans-lation is behind the Chinese term.
As shown fromthe figure, we know that most candidates are dis-tributed in the range of -60-60 bytes, and fewoccurrences are out of this range.
The numbers oftranslations appearing in front of the term andafter the term are nearly equal.
The curve lookslike Gaussian probability distribution, so Gaus-sian models are proposed to model it.
By thecurve fitting, the parameters of Gaussian modelsare obtained, i.e.
u=1 and sigma=2.
Thus, thecontribution probability of distance to the rankingfunction is formulized as8/)1),(( 2221),( ?
?= jiDD ejip?, where D(i,j) repre-sents the byte distance between the source term iand the candidate j.4) Keywords, key symbols and boundary in-formation between S-TSome Chinese keywords or capital English ab-breviation letters between S-T can provide animportant clue for the acquisition of possible cor-rect translations.
These Chinese keywords in-clude the words such as ???
?, ????,???
?, ????
?, ???
?, ???,??
?, ??
?, ???
?, ???
?, ?????.
The punctuations between S-T can alsoprovide very strong constraints, for example,when the marks ??
?
( ) [ ]?
exist, the probabil-ity of being a translation pair will greatly increase.Thus, correctly judging these cases can not onlymake translation finding results more compre-hensive, but also increase the possibility that thiscandidate is as one of correct translations.Boundary information refers to the fact that thecontext of candidates on the Web has distinctmark information, for example, the position oftransition from continuous Chinese to English,the place with bracket ellipsis and independentunits in the HTML text.5.2 Candidate evaluation methodAfter translation noise handling, we evaluatecandidate translations so that possible candidatesget higher scores.
The method in the weightedsum of multi-features including: candidate fre-quency, distribution, length ratio, distance, key-words, key symbols and boundary informationbetween S-T, is proposed to rank the candidates.The evaluation method is formulized as follows:?
?++==Nij DL wjijiptsptScore11 )),(),(([),()( ??
)]),(),((max2 wjijipDj??
+ , 121 =+ ??
(2)In the equation, Score(t) is proportional to),( tspL , N and ),( jipD .
If the bigger these com-ponent values are, the more they contribute to thewhole evaluation formula, and correspondinglythe candidate has higher score.
The length ratiorelation ),( tspL  reflects the proportion relationbetween S-T as a whole, so its weight will beimpacted on the Score(t) in the macro-view.
Theweights are trained through a large amount oftechnical terms and proper nouns, where eachrelation corresponds to one probability.
N de-notes the total number of Web pages that containcandidates, and partly reflects the distributioninformation of candidates in different Web pages.If the greater N is, the greater Score(t) will be-come.
The distance relation ),( jipD  is defined asthe distance contribution probability of the jthsource-candidate pair on the ith Web pages,which is impacted on every word pair emergedon the Web in the point of micro-view.
Its calcu-lation formula is defined in Section 5.1.
Theweights of 1?
and 2?
represent the proportion ofterm frequency and term distribution, and 1?
de-notes the weight of the total number of one can-didate occurrences, and 2?
represents the weightof counting the nearest distance occurrence foreach Web page.
wji ),(?
is the contribution prob-ability of keywords, key symbols and boundaryinformation.
If there are predefined keywords,key symbols, and boundary information betweenS-T, i.e., 1),( =ji?
, then the evaluation formulawill give a reward w, otherwise, 0),( =ji?
indi-cate that there is no impact on the whole equation.6 ExperimentsOur experimental data consist of two sets: 400 C-E term pairs and 3511 C-E term pairs in the fi-nancial domain.
There is no intersection betweenthe two sets.
Each term often consists of 2-8 Chi-nese characters, and the associated translationcontains 2-5 English words.
In the test set of 400terms, there are more than one English translationfor every Chinese term, and only one Englishtranslation for 3511 term pairs.
In the test sets,Chinese terms are inputted to our system onbatch, and their corresponding translations areviewed as a criterion to evaluate these minedcandidates.
The top n accuracy is defined as the204percentage of terms whose top n translations in-clude correct translations in the term pairs.
A se-ries of experiments are conducted on the two testsets.Experiments on the number of feedbackpages: To obtain the best parameter of feedbackWeb pages that influence the whole system accu-racy, we perform the experiments on the test setof 400 terms.
The number of feedback Webpages is respectively set to 0, 10, 20, 30, and 40.N=1, 3, 5 represent the accuracies of top 1, 3, and5.
From the feedback pages, previous 5 semanti-cally-relevant terms are extracted to construct anew query expansion for retrieving more effec-tive Web pages.
Translation candidates are minedfrom these effective pages, whose accuracycurves are depicted in Figure 5.60657075808590951000 10 20 30 40The number of feedback Web pagesAccuracyN=1N=3N=5Figure 5.
The number of feedback Web pagesAs seen from the figure above, when the num-ber of feedback Web pages is 20, the accuracyreaches the best.
Thus, the feedback parameter inour experiments is set to 20.Experiments on the parameter 1?
: In thecandidate evaluation method using multi-features,the parameter of 1?
need be chosen through theexperiments.
To obtain the best parameter, theexperiments are set as follows.
The accuracy oftop 5 candidates is viewed as a performance cri-terion.
The parameters are respectively set from 0to 1 with the increase of 0.1 step.
The results arelisted in Figure 6.
As seen from the figure,1?
=0.4 is best parameter, and therefore 2?
=0.6.In the following experiments, the parameters areall set to this value.808590951000 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1ParameterAccuracyFigure 6.
The relation between the parameter 1?
andthe accuracyExperiments on the test set of 400 terms us-ing different methods: The methods respec-tively without prediction(NP), with prediction(P),with prediction and feedback(PF) only using termfrequency (TM), and with prediction and feed-back using multi-features(PF+MF) are employedon the test set of 400 terms.
The results are listedin Table 1.
As seen from this table, if there is nosemantic prediction, the obtained translationsfrom Web pages are about 48% in the top 30candidates.
This is because general search en-gines will retrieve more relevant Chinese Webpages rather than those effective pages includingEnglish meanings.
Thus, the semantic predictionmethod is employed.
Experiments demonstratethe method with semantic prediction distinctlyimproves the accuracy, about 36.8%.
To furtherimprove the performance, the feedback learningtechnique is proposed, and it increases the aver-age accuracy of 6.5%.
Though TM is very effec-tive in mining the term translation, the multi-feature method fully utilizes the context of can-didates, and therefore obtains more accurate re-sults, about 92.8% in the top 5 candidates.Table 1.
The term translation results using differentmethodsTop30 Top10 Top5 Top3 Top1NP 48.0 47.5 46.0 44.0 28.0P 84.8 83.3 82.3 79.3 60.8PF+TM 91.3 90.8 90.3 88.3 71.0PF+MF 95.0 94.5 92.8 91.5 78.8Experiments on a large vocabulary: To vali-date our system performance, experiments arecarried on a large vocabulary of 3511 terms usingdifferent methods.
One method is to use termfrequency (TM) as an evaluation criterion, andthe other method is to use multi-features (MF) asan evaluation criterion.
Experimental results areshown as follows.Table 2.
The term translation results on a large vo-cabularyTop30 Top10 Top5 Top3 Top1TM 82.5 81.2 78.3 73.5 49.4MF 89.1 88.4 86.0 82.9 58.2From Table 2, we know the accuracy with top5 candidates is about 86.0%.
The method usingmulti-features is better than that of using termfrequency, and improves an average accuracy of7.94%Some examples of acquiring English transla-tions of Chinese terms are provided in Table 3.1?205Only top 3 English translations are listed for eachChinese term.Table 3.
Some C-E mining examplesChinesetermsThe list of English translations(Top 3)???
?The Three KingdomsThe Romance of the Three KingdomsThe Romance of Three Kingdoms???
?Merit student"Three Goods" studentExcellent League member??
?Blue ChipBlue ChipsBlue chip stocks??
?Mont BlancMont-BlancChamonix Mont-Blanc????
?Burmuda TriangleBermuda TriangleThe Bermuda Triangle??
?License plate numberVehicle plate numberVehicle identification no7 ConclusionsIn this paper, the method based on semanticprediction is first proposed to acquire effectiveWeb pages.
The proposed method predictspossible meanings according to each constituentunit of Chinese term, and expands these items forsearching using semantically relevant knowledge,and then the refined related terms are extractedfrom top retrieved documents through feedbacklearning to construct a new query expansion foracquiring more effective Web pages.
For obtain-ing a correct translation list, the translationevaluation method using multi-features is pre-sented to rank these candidates.
Experimentalresults show that this method has good perform-ance in Chinese-English translation acquisition,about 82.9% accuracy in the top 3 candidates.ReferencesP.J.
Cheng, J.W.
Teng, R.C.
Chen, et al 2004.
Trans-lating unknown queries with web corpora forcross-language information retrieval, Proc.
ACMSIGIR, pp.
146-153.G.L.
Fang, H. Yu, and F. Nishino.
2005.
Web-BasedTerminology Translation Mining, Proc.
IJCNLP,pp.
1004-1016.P.
Fung.
1997.
Finding terminology translations fromnonparallel corpora, Proc.
Fifth Annual Work-shop on Very Large Corpora (WVLC'97), pp.192-202.F.C.
Gey.
2004.
Chinese and Korean topic search ofJapanese news collections, In Working Notes ofthe Fourth NTCIR Workshop Meeting, Cross-Lingual Information Retrieval Task, pp.
214-218.A.
Kilgarriff and G. Grefenstette.
2003.
Introductionto the special issue on the Web as corpus, Com-putational Linguistics, 29(3): 333-348.H.
Li, Y. Cao, and C. Li.
2003.Using bilingual webdata to mine and rank translations, IEEE Intelli-gent Systems, 18(4): 54-59.W.H.
Lu, L.F. Chien, and H.J.
Lee.
2004.
Anchor textmining for translation of Web queries: A transi-tive translation approach, ACM Trans.
Informa-tion System, 22(2): 242-269.M.
Nagata, T. Saito, and K. Suzuki.
2001.
Using theweb as a bilingual dictionary, Proc.
ACL 2001Workshop Data-Driven Methods in MachineTranslation, pp.
95-102.R.
Rapp.
1999.
Automatic identification of wordtranslations from unrelated English and Germancorpora, Proc.
37th Annual Meeting Assoc.
Com-putational Linguistics, pp.
519-526.H.C.
Seo, S.B.
Kim, H.G.
Lim and H.C. Rim.
2004.KUNLP system for NTCIR-4 Korean-Englishcross language information retrieval, In WorkingNotes of the Fourth NTCIR Workshop Meeting,Cross-Lingual Information Retrieval Task, pp.103-109.Y.
Zhang and P. Vines.
2004.
Using the web forautomated translation extraction in cross-language information retrieval, Proc.
ACMSIGIR, pp.
162-169.206
