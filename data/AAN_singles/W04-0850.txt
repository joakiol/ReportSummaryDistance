The Duluth Lexical Sample Systems in SENSEVAL-3Ted PedersenDepartment of Computer ScienceUniversity of MinnesotaDuluth, MN 55812tpederse@d.umn.eduhttp://www.d.umn.edu/?tpederseAbstractTwo systems from the University of Minnesota,Duluth participated in various SENSEVAL-3 lexi-cal sample tasks.
The supervised learning systemis based on lexical features and bagged decisiontrees.
It participated in lexical sample tasks forthe English, Spanish, Catalan, Basque, Romanianand MultiLingual English-Hindi data.
The unsuper-vised system uses measures of semantic relatednessto find the sense of the target word that is most re-lated to the senses of its neighbors.
It participatedin the English lexical sample task.1 IntroductionThe Duluth systems participated in various lexicalsample tasks in SENSEVAL-3, using both super-vised and unsupervised methodologies.The supervised lexical sample system that partic-ipated in SENSEVAL-3 is the Duluth3 (English) orDuluth8 (Spanish) system as used in SENSEVAL-2 (Pedersen, 2001b).
It has been renamed forSENSEVAL-3 as Duluth-xLSS, where x is a one let-ter abbreviation of the language to which it is be-ing applied, and LSS stands for Lexical Sample Su-pervised.
The idea behind this system is to learnthree bagged decision trees, one using unigram fea-tures, another using bigram features, and a thirdusing co?occurrences with the target word as fea-tures.
This system only uses surface lexical fea-tures, so it can be easily applied to a wide rangeof languages.
For SENSEVAL-3 this system partici-pated in the English, Spanish, Basque, Catalan, Ro-manian, and MultiLingual (English-Hindi) tasks.The unsupervised lexical sample system is basedon the SenseRelate algorithm (Patwardhan et al,2003) for word sense disambiguation.
It is knownas Duluth-ELSU, for English Lexical Sample Un-supervised.
This system relies on measures ofsemantic relatedness in order to determine whichsense of a word is most related to the possiblesenses of nearby content words.
This system de-termines relatedness based on information extractedfrom the lexical database WordNet using the Word-Net::Similarity package.
In SENSEVAL-3 this sys-tem was restricted to English text, although in fu-ture it and the WordNet::Similarity package couldbe ported to WordNets in other languages.This paper continues by describing our super-vised learning technique which is based on the useof bagged decision trees, and then introduces thedictionary based unsupervised algorithm.
We dis-cuss our results from SENSEVAL-3, and concludewith some ideas for future work.2 Lexical Sample SupervisedThe Duluth-xLSS system creates an ensemble ofthree bagged decision trees, where each is basedon a different set of features.
A separate ensembleis learned for each word in the lexical sample, andonly the training data that is associated with a par-ticular target word is used in creating the ensemblefor that word.This approach is based on the premise that thesedifferent views of the training examples for a giventarget word will result in classifiers that make com-plementary errors, and that their combined perfor-mance will be better than any of the individual clas-sifiers that make up the ensemble.
A decision treeis learned from each of the three representations ofthe training examples.
Each resulting classifier as-signs probabilities to every possible sense of a testinstance.
The ensemble is created by summing theseprobabilities and assigning the sense with the largestassociated probability.The objective of the Duluth-xLSS system?s par-ticipating in multiple lexical sample tasks is to testthe hypothesis that simple lexical features identifiedusing standard statistical techniques can providereasonably good performance at word sense disam-biguation.
While we doubt that the Duluth-xLSSapproach will result in the top ranked accuracy inSENSEVAL-3, we believe that it should always im-prove upon a simple baseline like the most frequentsense (i.e., majority classifier), and may be compet-itive with other more feature?rich approaches.Association for Computational Linguisticsfor the Semantic Analysis of Text, Barcelona, Spain, July 2004SENSEVAL-3: Third International Workshop on the Evaluation of Systems2.1 Feature SetsThe first feature set is made up of bigrams, whichare consecutive two word sequences that can occuranywhere in the context with the ambiguous word.To be selected as a feature, a bigram must occur twoor more times in the training examples associatedwith the target word, and have a log-likelihood ratio(G2) value ?
6.635, which is associated with a p-value of .01.The second feature set is based on unigrams, i.e.,one word sequences, that occur five or more times inthe training data for the given target word.
Since thenumber of training examples for most words is rel-atively small (100-200 instances in many cases) thenumber of unigram features that are actually identi-fied by this criteria are rather small.The third feature set is made up of co?occurrencefeatures that represent words that occur on the im-mediate left or right of the target word.
In effect,these are bigrams that include the target word.
Tobe selected as features these must occur two or moretimes in the training data and have a log?likelihoodratio (G2) value ?
2.706, which is associated with ap-value of .10.
Note that we are using a more lenientlevel of significance for the co?occurrences than thebigrams (.10 versus .01), which is meant to increasethe number of features that include the target word.The Duluth-xLSS system is identical for each ofthe languages to which it is applied, except thatin the English lexical sample we used a stoplist offunction words, while in the other tasks we did not.The use of a stoplist would likely be helpful, butwe lacked the time to locate and evaluate candi-date stoplists for other languages.
For English, un-igrams in the stop list are not included as features,and bigrams or co?occurrences made up of two stopwords are excluded.
The stop list seems particularlyrelevant for the unigram features, since the bigramand co?occurrence feature selection process tendsto eliminate some features made up of stop wordsvia the log?likelihood ratio score cutoff.In all of the tasks tokenization was based ondefining a word as a white space separated string.There was no stemming or lemmatizing performedfor any of the languages.2.2 Decision TreesDecision trees are among the most widely used ma-chine learning algorithms.They perform a general to specific search of a fea-ture space, adding the most informative features to atree structure as the search proceeds.
The objectiveis to select a minimal set of features that efficientlypartitions the feature space into classes of observa-tions and assemble them into a tree.
In our case, theobservations are manually sense?tagged examplesof an ambiguous word in context and the partitionscorrespond to the different possible senses.Each feature selected during the search process isrepresented by a node in the learned decision tree.Each node represents a choice point between a num-ber of different possible values for a feature.
Learn-ing continues until all the training examples are ac-counted for by the decision tree.
In general, sucha tree will be overly specific to the training dataand not generalize well to new examples.
Thereforelearning is followed by a pruning step where somenodes are eliminated or reorganized to produce atree that can generalize to new circumstances.When a decision tree is bagged (Breiman, 1996),all of the above is still true.
However, what is differ-ent is that the training data is sampled with replace-ment during learning.
This is instead of having thetraining data as a static or fixed set of data.
Thistends to result in a learned decision tree where out-liers or anomalous training instances are smoothedout or eliminated (since it is more likely that theresampling operation will find more typical train-ing examples).
The standard approach in baggingit to learn multiple decision trees from the sametraining data (each based on a different sampling ofthe data), and then create an averaged decision treefrom these trees.In our experiments we learn ten bagged decisiontrees for each feature set, and then take the resultingaveraged decision tree as a member in our ensemble.Thus, to create each ensemble, we learn 30 decisiontrees, ten for each feature set.
The decision treesassociated with each feature set are averaged intoa single tree, leaving us with three decision treesin the ensemble, one which represents the bigramfeatures, another the unigrams, and the third the co?occurrence features.Our experience has been that variations in learn-ing algorithms are far less significant contributorsto disambiguation accuracy than are variations inthe feature set.
In other words, an informative fea-ture set will result in accurate disambiguation whenused with a wide range of learning algorithms, butthere is no learning algorithm that can perform wellgiven an uninformative or misleading set of fea-tures.
Therefore, our interest in these experimentsis more in the effect of the different features setsthan in the variations that would be possible if weused learning algorithms other than decision trees.We are satisfied that decision trees are a reason-able choice of learning algorithm.
They have a longhistory of use in word sense disambiguation, dat-ing back to early work by (Black, 1988), and havefared well in comparative studies such as (Mooney,1996) and (Pedersen and Bruce, 1997).
In the for-mer they were used with unigram features and in thelatter they were used with a small set of features thatincluded the part-of-speech of neighboring words,three collocations, and the morphology of the am-biguous word.
In (Pedersen, 2001a) we introducedthe use of decision trees based strictly on bigramfeatures.While we might squeeze out a few extra pointsof performance by using more complicated meth-ods, we believe that this would obscure our abil-ity to study and understand the effects of differentkinds of features.
Decision trees have the furtheradvantage that a wide range of implementations areavailable, and they are known to be robust and ac-curate across a range of domains.
Most important,their structure is easy to interpret and may provideinsights into the relationships that exist among fea-tures and more general rules of disambiguation.2.3 Software ResourcesThe Duluth-xLSS system is based completely onsoftware that is freely available.
All of the softwarementioned below has been developed at the Univer-sity of Minnesota, Duluth, with the exception of theWeka machine learning system.The Ngram Statistics Package (NSP) (Banerjeeand Pedersen, 2003a) version 0.69 was used to iden-tify the lexical features for all of the different lan-guages.
NSP is written in Perl and is freely availablefor download from the Comprehensive Perl Archive(CPAN) (http://search.cpan.org/dist/Text-NSP) orSourceForge (http://ngram.sourceforge.net).The SenseTools package converts unigram, bi-gram, and co?occurrence features as discov-ered by NSP into the ARFF format requiredby the Weka Machine Learning system (Wittenand Frank, 2000).
It also takes the output ofWeka and builds our ensembles.
We used ver-sion 0.03 of SenseTools, which is available fromhttp://www.d.umn.edu/?tpederse/sensetools.html.Weka is a freely available Java based suite ofmachine learning methods.
We used their J48implementation of the C4.5 decision tree learn-ing algorithm (Quinlan, 1986), which includessupport for bagging.
Weka is available fromhttp://www.cs.waikato.ac.nz/ml/weka/A set of driver scripts known as the DuluthShellintegrates NSP, Weka, and SenseTools, and is avail-able from the same page as SenseTools.
Version 0.3of the DuluthShell was used to create the Duluth-xLSS system.3 Lexical Sample UnsupervisedThe unsupervised Duluth-ELSU system is a dictio-nary based approach.
It uses the content of WordNetto measure the similarity or relatedness between thesenses of a target word and its surrounding words.The general idea behind the SenseRelate algo-rithm is that a target word will tend to have the sensethat is most related to the senses of its neighbors.Here we define neighbor as a content word that oc-curs in close proximity to the target word, but thiscould be extended to include words that may be syn-tactically related without being physically nearby.The objective of the Duluth-ELSU system?s par-ticipation in the English lexical sample task is to testthe hypothesis that disambiguation based on mea-sures of semantic relatedness can perform effec-tively even in very diverse text and possibly noisydata such as is used for SENSEVAL-3.3.1 Algorithm DescriptionIn the SenseRelate algorithm, a window of contextaround the target word is selected, and a set of can-didate senses from WordNet is identified for eachcontent word in the window.
Assume that the win-dow of context consists of 2n + 1 words denotedby wi, ?n ?
i ?
+n, where the target word isw0.
Further let |wi| denote the number of candidatesenses of word wi, and let these senses be denotedby si,j , 1 ?
j ?
|wi|.
In these experiments we useda window size of 3, which means we considered acontent word to the right and left of the target word.Next the algorithm assigns to each possible sensek of the target word a Scorek computed by addingtogether the relatedness scores obtained by compar-ing the sense of the target word in question with ev-ery sense of every non?target word in the window ofcontext using a measure of relatedness.
The Scorefor sense s0,k is computed as follows:Scorek =n?i=?n|wi|?j=1relatedness(s0,k, si,j), i 6= 0That sense with the highest Score is judged to bethe most appropriate sense for the target word.
Ifthere are on average a senses per word and the win-dow of context is N words long, there are a2?
(N?1) pairs of sets of senses to be compared, which in-creases linearly with N .Since the part of speech of the target word isgiven in the lexical sample tasks, this information isused to limit the possible senses of the target word.However, the part of speech of the other words inthe window of context was unknown.
In previousexperiments we have found that the use of a part ofspeech tagger has the potential to considerably re-duce the search space for the algorithm, but does notactually affect the quality of the results to a signifi-cant degree.
This suggests that the measure of relat-edness tends to eventually identify the correct partof speech for the context words, however, it wouldcertainly be more efficient to allow a part of speechtagger to do that apriori.In principle any measure of relatedness can beemployed, but here we use the Extended GlossOverlap measure (Banerjee and Pedersen, 2003b).This assigns a score to a pair of concepts basedon the number of words they share in their Word-Net glosses, as well as the number of words sharedamong the glosses of concepts to which they are di-rectly related according to WordNet.
This particularmeasure (known as lesk in WordNet::Similarity) hasthe virtue that it is able to measure relatedness be-tween mixed parts of speech, that is between nounsand verbs, adjectives and nouns, etc.
Measures ofsimilarity are generally limited to noun?noun andpossibly verb?verb comparisons, thus reducing theirgenerality in a disambiguation system.3.2 Software ResourcesThe unsupervised Duluth-ELSU system is freelyavailable, and is based on version 0.05 ofthe SenseRelate algorithm which was devel-oped at the University of Minnesota, Duluth.SenseRelate is distributed via SourceForge athttp://sourceforge.net/projects/senserelate.
Thispackage uses WordNet::Similarity (version 0.07)to measure the similarity and relatedness amongconcepts.
WordNet::Similarity is available fromthe Comprehensive Perl Archive Network athttp://search.cpan.org/dist/WordNet-Similarity.4 Experimental ResultsTable 1 shows the results as reported for the variousSENSEVAL-3 lexical sample tasks.
In this table werefer to the language and indicate whether the learn-ing was supervised (S) or unsupervised (U).
Thus,Spanish-S refers to the system Duluth-SLSS.
Also,the English and Romanian lexical sample tasks pro-vided both fine and coarse grained scoring, which isindicated by (f) and (c) respectively.
The other tasksonly used fine grained scoring.
We also report theresults from a majority classifier which simply as-signs each instance of a word to its most frequentsense as found in the training data (x-MFS).
Themajority baseline values were either provided by atask organizer, or were computed using an answerkey as provided by a task organizer.Table 1: Duluth-xLSy ResultsSystem (x-y) Prec.
Recall FEnglish-S (f) 61.80 61.80 61.80English-MFS (f) 55.20 55.20 55.20English-U (f) 40.30 38.50 39.38English-S (c) 70.10 70.10 70.10English-MFS (c) 64.50 64.50 64.50English-U (c) 51.00 48.70 49.82Romanian-S (f) 71.40 71.40 71.40Romanian-MFS (f) 55.80 55.80 55.80Romanian-S (c) 75.20 75.20 75.20Romanian-MFS (c) 59.60 59.60 59.60Catalan-S 75.37 76.48 75.92Catalan-MFS 66.36 66.36 66.36Basque-S 60.80 60.80 60.80Basque-MFS 55.80 55.80 55.80Spanish-S 74.29 75.02 74.65Spanish-MFS 67.72 67.72 67.72MultLing-S 58.20 58.20 58.20MultLing-MFS 51.80 51.80 51.804.1 SupervisedThe results of the supervised Duluth-xLSS systemare fairly consistent across languages.
Generallyspeaking it is more accurate than the majority clas-sifier by approximately 5 to 9 percentage points de-pending on the language.
The Romanian results areeven better than this, with Duluth-RLSS attainingaccuracies more than 15 percentage points betterthan the majority sense.We are particularly pleased with our results forBasque, since it is an agglutinating language andyet we did nothing to account for this.
We tok-enized all the languages in the same way, by sim-ply defining a word to be any string separated bywhite spaces.
While this glosses over many dis-tinctions between the languages, in general it stillseemed to result in sufficiently informative featuresto create reliable classifiers.
Thus, our unigrams,bigrams, and co?occurrences are composed of thesewords, and we find it interesting that such simpleand easy to obtain features fare reasonably well.This suggests to use that these techniques mightform a somewhat language independent foundationupon which more language dependent disambigua-tion techniques might be built.4.2 UnsupervisedThe unsupervised system Duluth-ELSU in the En-glish lexical sample task did not perform as well asthe supervised majority classifier method, but thisis not entirely surprising.
The unsupervised methodmade no use of the training data available for thetask, nor did it use any of the first sense informationavailable in WordNet.
We decided not to use theinformation that WordNet provides about the mostfrequent sense of a word, since that is based on thesense?tagged corpus SemCor, and we wanted thissystem to remain purely unsupervised.Also, the window of context used was quite nar-row, and only consisted of one content word to theleft and right of the target word.
It may well be thatexpanding the window, or choosing the words inthe window on criteria other than immediate prox-imity to the target word would result in improvedperformance.
However, larger windows of contextare computationally more complex and we did nothave sufficient time during the evaluation period torun more extensive experiments with different sizedwindows of context.As a final factor in our evaluation, Duluth-ELSUis a WordNet based system.
However, the verbsenses in the English lexical sample task camefrom WordSmyth.
Despite this our system re-lied on WordNet verb senses and glosses to makerelatedness judgments, and then used a mappingfrom WordNet senses to WordSmyth to produce re-portable answers.
There were 178 instances wherethe WordNet sense found by our system was notmapped to WordSmyth.
Rather than attempt to cre-ate our own mapping of WordNet to WordSmyth,we simply threw these instances out of the evalua-tion set, which does lead to somewhat less coveragefor the unsupervised system for the verbs.5 Future WorkThe Duluth-xLSS system was originally inspiredby (Pedersen, 2000), which presents an ensembleof eighty-one Naive Bayesian classifiers based onvarying sized windows of context to the left andright of the target word that define co-occurrencefeatures.
However, the Duluth-ELSS system onlyuses a three member ensemble to explore the ef-ficacy of combinations of different lexical featuresvia simple ensembles.
We plan to carry out a moredetailed analysis of the degree to which unigram, bi-gram, and co?occurrence features are useful sourcesof information for disambiguation.We will also conduct an analysis of the comple-mentary and redundant nature of lexical and syn-tactic features, as we have done in (Mohammad andPedersen, 2004a) for the SENSEVAL-1, SENSEVAL-2, and line, hard, serve, and interest data.
The Syn-taLex system (Mohammad and Pedersen, 2004b)also participated in the English lexical sample taskof SENSEVAL?3 and is a sister system to Duluth-ELSS.
It uses lexical and syntactic features withbagged decision trees and serves as a convenientpoint of comparison.
We are particularly inter-ested to see if there are words that are better dis-ambiguated using syntactic versus lexical features,and in determining how to best combine classifiersbased on different feature sets in order to attain im-proved accuracy.The Duluth-ELSU system is an unsupervised ap-proach that is based on WordNet content, in partic-ular relatedness scores that are computed by mea-suring gloss overlaps of the candidate senses of atarget word with the possible senses of neighbor-ing words.
There are several variations to this ap-proach that can easily be taken, including increas-ing the size of the window of context, and the useof measures of relatedness other than the ExtendedGloss Overlap method.
We are also interested inchoosing words that are included in the window ofcontext more cleverly.
For example, we are study-ing the possibility of letting the window of contextbe defined by words that make up a lexical chainwith the target word.The Duluth-ELSU system could be adapted foruse in the all-words task as well, where all contentwords in a text are assigned a sense.
One importantissue that must be resolved is whether we would at-tempt to disambiguate a sentence globally, that is byassinging the senses that maximize the relatednessof all the words in the sentence at the same time.The alternative would be to simply proceed left toright, fixing the senses that are assigned as we movethrough a sentence.
We are also considering the useof more general discourse level topic restrictions onthe range of possible senses in an all-words task.We also plan to extend our study of comple-mentary and related behavior between systems toinclude an analysis of our supervised and unsu-pervised results, to see if a combination of super-vised and unsupervised systems might prove advan-tageous.
While the level of redundancy betweensupervised systems can be rather high (Moham-mad and Pedersen, 2004a), we are optimistic that acorpus based supervised approach and a dictionarybased unsupervised approach might be highly com-plementary.6 ConclusionsThis paper has described two lexical sample sys-tems from the University of Minnesota, Duluth thatparticipated in the SENSEVAL-3 exercise.
We foundthat our supervised approach, Duluth-xLSS, faredreasonably well in a wide range of lexical sampletasks, thus suggesting that simple lexical featurescan serve as a firm foundation upon which to build adisambiguation system in a range of languages.
Theunsupervised approach of Duluth-ELSU to the En-glish lexical sample task did not fare as well as thesupervised approach, but performed at levels com-parable to that attained by unsupervised systems inSENSEVAL-1 and SENSEVAL-2.7 AcknowledgmentsThis research has been partially supported by aNational Science Foundation Faculty Early CA-REER Development award (#0092784), and by twoGrants?in?Aid of Research, Artistry and Scholar-ship from the Office of the Vice President for Re-search and the Dean of the Graduate School of theUniversity of Minnesota.Satanjeev Banerjee, Jason Michelizzi, Saif Mo-hammad, Siddharth Patwardhan, and Amruta Pu-randare have all made significant contributions tothe development of the various tools that were usedin these experiments.
This includes the NgramStatistics Package, SenseRelate, SenseTools, theDuluthShell, and WordNet::Similarity.
All of thissoftware is freely available at the web sites men-tioned in this paper, and make it possible to easilyreproduce and extend the results described in thispaper.ReferencesS.
Banerjee and T. Pedersen.
2003a.
The design,implementation, and use of the Ngram StatisticsPackage.
In Proceedings of the Fourth Interna-tional Conference on Intelligent Text Processingand Computational Linguistics, pages 370?381,Mexico City, February.S.
Banerjee and T. Pedersen.
2003b.
Extendedgloss overlaps as a measure of semantic related-ness.
In Proceedings of the Eighteenth Interna-tional Joint Conference on Artificial Intelligence,pages 805?810, Acapulco, August.E.
Black.
1988.
An experiment in computa-tional discrimination of English word senses.IBM Journal of Research and Development,32(2):185?194.L.
Breiman.
1996.
The heuristics of instability inmodel selection.
Annals of Statistics, 24:2350?2383.S.
Mohammad and T. Pedersen.
2004a.
Combin-ing lexical and syntactic features for supervisedword sense disambiguation.
In Proceedings ofthe Conference on Computational Natural Lan-guage Learning, pages 25?32, Boston, MA.S.
Mohammad and T. Pedersen.
2004b.
Comple-mentarity of lexical and simple syntactic features:The Syntalex approach to SENSEVAL-3.
In Pro-ceedings of the Third International Workshop onthe Evaluation of Systems for the Semantic Anal-ysis of Text, Barcelona, Spain.R.
Mooney.
1996.
Comparative experiments ondisambiguating word senses: An illustration ofthe role of bias in machine learning.
In Pro-ceedings of the Conference on Empirical Meth-ods in Natural Language Processing, pages 82?91, May.S.
Patwardhan, S. Banerjee, and T. Pedersen.
2003.Using measures of semantic relatedness for wordsense disambiguation.
In Proceedings of theFourth International Conference on IntelligentText Processing and Computational Linguistics,pages 241?257, Mexico City, February.T.
Pedersen and R. Bruce.
1997.
A new supervisedlearning algorithm for word sense disambigua-tion.
In Proceedings of the Fourteenth NationalConference on Artificial Intelligence, pages 604?609, Providence, RI, July.T.
Pedersen.
2000.
A simple approach to buildingensembles of Naive Bayesian classifiers for wordsense disambiguation.
In Proceedings of the FirstAnnual Meeting of the North American Chapterof the Association for Computational Linguistics,pages 63?69, Seattle, WA, May.T.
Pedersen.
2001a.
A decision tree of bigrams isan accurate predictor of word sense.
In Proceed-ings of the Second Annual Meeting of the NorthAmerican Chapter of the Association for Com-putational Linguistics, pages 79?86, Pittsburgh,July.T.
Pedersen.
2001b.
Machine learning with lexicalfeatures: The Duluth approach to senseval-2.
InProceedings of the Senseval-2 Workshop, pages139?142, Toulouse, July.J.
Quinlan.
1986.
Induction of decision trees.
Ma-chine Learning, 1:81?106.I.
Witten and E. Frank.
2000.
Data Mining - Practi-cal Machine Learning Tools and Techniques withJava Implementations.
Morgan?Kaufmann, SanFrancisco, CA.
