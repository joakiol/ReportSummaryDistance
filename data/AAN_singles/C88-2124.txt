P A N E LP~Lra l le l  P~ocess ing  in  Computat iona l  L ingu is  t i csHelmut SchnelleRuhr-Univers i t~t  BochumSprachwissenschaft l iches Inst itutPostfach 102148, D-4630 Bochum 1Pane l i s ts :Garry COTTRELLUnivers i ty  of California, Dept.
ofComputer Science, San Diego,Mail  Code C-O14, La Jolla, CA 92093U.S.A.Paradip DEYThe Univers i ty  of Alabama at BirminghamDept.
of Computer & Information ScienceBirmingham, AL 35294U.S.A.Peter A. REICHDept.
of Linguistics, Univers i ty ofToronto, Toronto, Ontario MBS IAICANADALokendra SHASTRIUnivers i ty  of PennsylvaniaSchool of Engineer ing and Appl iedScience, 200 South 33rd StreetPhi ladelphia, PA 19104-6389U.S.A.Joachim DIEDERICHInternat ional  Computer Science Inst i tute1947 Center Street, Berkeley, CA 94704U.S.A.Akinori  YONEZAWATokyo Inst itute of TechnologyDept.
of Information ScienceOokayama, Meguru-ku, Tokyo 152JAPANIntroduct ionThe topic to be discussed by the panelis new and at present very much under debate.Paralleli~im is developed in a large var ietyof approaches.
The panel wil l  make an attemptto c lar i fy the under ly ing concepts, the dif-ferences <~f approach, the perspect ives andgeneral tt!ndencies, and the di f f icul t ies tobe expected.
Some di f ferences of approachwil l  be iAlustrated with examples from thework of the panelists.The ~ommon context of our approaches isthe fo l lowing:Standard computat ionall inguist ics tries to solve its problems byprogrammiltg a yon Neumann computer.
Theexecut ion of the programs is inherent lysequenti~l.
This is impl ied by the fact thatthere is only one central processing unit(CPU) executing the program.
In contrast tothis, pal~allel process ing def ines the solu-t ion of p~oblems in terms of sets of computa-t ional units which operate concurrent ly  andinteractively, unless sequent ia l ized for si-mulat ion ~urposes.Various approaches to paral le l ism dif ferin the computat ional  power they assume forthe concurrent ly  active units.
The di f feren-ces may be out l ined as follows:Massively paral le l  systems are usual lysystems whose units are, intuit ivelyspeaking, purely reactive units, i.e.
mathe-mat ical ly  def ined by a specif ic function re-lat ing the state and output of a unit  to itsinputs.
They could also be cal led connect io-nist systems in the wide sense; connect ionistsystems in the narrow sense are those whosefunction~ are based on weighted sums of inputactivit ies.In contrast to these systems, the units maybe themselves compl icated systems which com-pute their states and outputs depending onthe messages and control s ignals which theyreceive.
The units cooperate in solving theproblem.
In typical cases, each unit may be acentral processor unit  or even a completecomputer.
Systems with cooperative processors(computing "agents") are usual ly consideredto be non-massively  parallel.These dist inct ions suggest di f ferent meta-phors used in informal talk about the sy-stems: the neural  net metaphor on the onehand and the society of minds (demons) meta~phor on the other.Given this context the panel ists haveanswered the fol lowing questions:I.
How is the dynamics of your systemdef ined?- I.
(A) I.
What is the computat ional  powerof a single unit in your approach- I.
(A) 2.
How is the interact ion or theinterdependency between concurrentunits def ined?- I.
(B} How do you implement your system?- I (C) Which methods are used for ~o-uramminu?II.
What is the representat ional  status ofyour system?- II.
(A) Which parts of grammar or dict ionarydo you model with your system?- II.
(B) Which parts of grammar or dict ionarydo you model by a concurrent unit ofyour system?- II.
(C} Is there a general  method such thata grammar determines uniquely aparal le l  implementat ion or is thisimp3ementat ion an art?The answers given seem to be part icu lar lyappropriate as an introduct ion to the topicand wil l  thus be presented in the subsequentpassages.
{The answers of the di f ferentpanel ists and the organizer are pref ixed bytheir initials)595I.
How is the dynamics of your systemdefined?I.
{A) i.
What is the computat ional  powerof a single unit in your approach (a Booleanfunction, a specif ic  numerical  function, amapping of vectors, a mapping of strings orfiles, a mapping of trees or conf igurat ionsof other types, or the power of a CPU or acomplete computer)?G.C.
:There are no formal l imitat ions on thepower of a unit  in my system; the power is amatter of taste, and is expected to be re-str icted to simple functions.
For example anumerical  approximat ion to Boolean functionsof the inputs, where the inputs are furtherbroken down into functions of input sites.
Myimplemented system has several hundred units.P.D.
:Each unit  has the power of a VAX-11/750.The units share their memories.
I 'mthus current ly working in a shared memorymult iprocess ing environment.
Specif ical ly, myalgorithms run on a 30 processor {=unit} Se-quent Balance 21000 machine.
This is largegrain paral lel ism.
I prefer the environmentof large grained shared memory mult iproces-sots, because they are the most popular gene-ral purpose paral lel  computers avai labletoday.
Earlier, I developed some algorithmsfor a medium grained tree machine, namely theDADO paral lel  machine.J.D.
: Each unit implements a simple numericalfunction, sometimes a simple combinat ion ofseveral funct ions computing input from seve-ral sites of incoming activation.P.A.R.
: Each unit  has the power of a f initestate device {under 32 di f ferent sta-tes).There are 16 di f ferent types of unitswhich di f fer  in their f inite state def ini -tion.
They implement (sometimes onlyslightly} di f ferent logical functions overtheir input activations.
The more impor tantones are: concatenat ion (logical fol lowedby), conjunct ion (logical and), d is junct ion(exclusive or}, precedence dis junct ion {ifboth poss ib i l i t ies  are realizable, one takesprecedence over the other), random dis junc-tion (pick a choice at random}, inter junct ion{inclusive or}, intercatenat ion {inclusiveor; if both: concatenation),  zero (networkdead ends producing nothing), bottom edge(network outputs something), top edge, feed-back barrier.
Units operate independent ly  ofone another and asynchronously.H.S.
: There are two descr ipt ive levels: largegra ined and small grained.
On the former eachunit is a {special purpose) Tur ing machine(not a universal  one}.
On the small grainedlevel, each unit implements either a s impleBoolean funct ion or a simple numerical  {addi-tive, f ixed length} function.
The large grai-ned net is a part i t ion ing of the small grai-ned net; its Tur ing machines are similar tovon Neumann's growing cel lular automata.L.S.
: Each unit  implements a numerical  func-t ion  - the  most compl icated ones have theform: If input aa > 0, then take the productof inputs bt,bs .... b~, else take the productof inputs cl ;cz, .
.
.cm.A.Y.
: Each unit  is a single CPU with memory.My approach involves thousands of units.I.
(A} 2.
How is the interact ion or theinterdependency between concurrent units de-f ined?
Is it str ict ly  connect ionist  and thusalso def ined by a function?
Or is it coopera-tive and thus def ined by the messages sent,encoded and decoded by the units?
Is there ad ist inct ion between data messages and con-trol-s ignal  messages or is it a data-f iow sy-stem?G.C.
: Units pass values in a str ict ly  connec-t ionist way.P.D.
:The system is a shared memory system.All units have in pr inciple access to thesame information.
Actual interact ion is def i -ned by shared variables.
That is, processescommunicate with each other through sharedvariables.J.D.
: The system is str ict ly  connectionist,i.e.
there are no symbol ic messages.
Eachunit  computes the weighted sum of inputs.P.A.R.
:Each unit  is connected to at mostthree other units in the network.
The connec-tions are active or not.
According to theirfunction, three di f ferent signals may be di-st inguished: product ion signal and posit ivefeedback, negative feedback, and antic ipa-tory.H.S.
: On the small grained level the systemis connectionlst,  but not strictly, since notonly weighted sums of inputs are al lowed butalso other simple functions.L.S.
: The system is str ict ly  connectionist.A.Y.
: The interact ion between units involvesmessage passing.
Messages carry either con-trol information or data or both.I.
{B} How do you implement your system?By s imulat ion on a yon Neumann computer or byprogramming on a universal  paral le l  machine(like the connect ion machine} or by designinghardware (e.g.
a specia l -purpose informationprocess ing network}?
If the first, do youplan to implement it eventual ly  by a paral le lsystem?G.C.
: The system is s imulated on a VAX.P.D.
:The system is being implemented on a 30-processor Sequent Balance 21000 machine.
Itis current ly being implemented in paral le l -Crunning under Unix.
When a paral le l  LISP be-comes available, it wil l  be implemented inparal le l  LISP.J.D.
: We use the Rochester  Connsct ionist  Si-mulator  on a SUN-3 with Graphics Interface.Implementat ions on a Sequent (Parallel UnixMachine} are planned.P .A,R.
:S imulat ion on a personal  computerusing standard programming language.H.S.
: The connect ionist  net is def ined on aspread-sheet such as LOTUS 1-2-3.
Some cellsof the spread-sheet are ident i f ied with theunits of the net to be programmed.
In each ofthese cells a formula for a funct ion is ente-red; it determines the react iv i ty of thiscell to the states of those neighbour ingcells whose addresses are arguments of thefunction.
Thus, the addresses of the formulason the spread-sheet implement the connect iv i -ties between the formulas.
We run thespreadsheet in the computat ion-mode: itera-t ive,columnwise, which def ines the sequentialsimulation.
By def in i t ion the di f ferent cel lsof the spread-sheet could operate concur-rent ly in each i terat ive step; their opera-t ion is sequent ia l ized (and thus adapted tothe s imulat ion on PC} only through columnwisecomputation.L .S.
:By s imulat ion on a yon Neumann computer.A.Y.
:By s imulat ion of a yon Neumann computer,and also paral le l  computers596I (C) Which methods are used for pro-~ ?
Paral le l iz ing of exist ing non-par-allel programs or independent programming?Methods of hardware design?GoC.
: A network is constructed from a high-level speci f icat ion such as a grammar.
Thisis g iven to a network construct ion routinethat specif ies the model based on the gram-mar.P.D.
:The computat ional  model is MIMD (multi-ple inst,'uction mult ip le data stream).
Paral-lel programs are developed pr imari ly  by datapartitio,~ing, although function part i t ioningis also itsed.J.D.
: Independent programu~ing.
Networks areconstructed by writ ing a C program and use ofl ibrary funct ion of the simulator.P.A.R.
: The system is programmed by construc-ting the gra~maar in network form.
There is analgorithl4 for represent ing the network interms of algebraic formulas.
Nodes are defi-ned by a series of state transit ion rules.The gran~aar is tested by insert ing init ialinput sionals and running the simulation.H.So: There is a compiler which produces au-tomatical ly for any given CF-grammar a corre-sponding network.
The processes on the net-work cor~:espond to the processes def ined byan Earley chart parser but, in contrast tothe latter, all processes are executed con-current ly whenever this is possible.
In par-ticular, all pars ing paths are fol lowed up inparallel.
Hardware design of networks isplanned~L.S.
: A "compiler" is provided that transla-tes a high level speci f icat ion of a concep-tual structure (semantic network} into aconnect ionist  network.
It is proved, that thenetwork ~enerated by the compiler solves aninterset ing lass of inheritance and reco ngn!~tiol, problems extremely fast - in time pro-port ional  to the depth of the conceptualhierarchy.A.Y.
:We designed an object -or iented concur-rent language cal led ABCL/I  and program par-sers in this language.I.
(D} Is your system fixed or does itlearn ?
If the latter, which learning functi-ons or learning algorithms are used?J.D.
:Lea:cning is the most important topic.Natural  language descr ipt ions of structuredobjects are learned.
These objects are alsopresent in a restr icted visual environment.The interact ion between language and visionin learning is investigated.
Various forms ofweight changes are used: Hebbian learningwith slow weight change, fast weight changefor temporary binding, modi f ied Hebbian lear-ning with restr ict ion on the increase ofweights.P.A.E.
: A substantial  number of learning ru-les have been developed but not yet implemen-ted on computer.
Learning involves "inge-stion" and "digestion".
Ingest ion consists ofco-occurrence rules.
If two signals pre-v iously unconnected co-occur, they areconnected together.
Digest ion makes use ofequivalence relat ionships to s impl i fy thenetwork.
Equivalence re lat ionships include:associat ivity,  commutativity,  distr ibutivity,and a number of other re lat ionships whichhave no name in standard algebra.
Ingest ionand digest ion operate more or less alterna-rely.
First a piece of new information isconnected to the network, then equivalencerelat ions are tried in a search for s impli f i -cation.L.S.
: Structure is f ixed but weights on l inkscan be learned using a Hebbian weight changerule.G.C.
,P.D.
,H.S.
,A.Y.
:  Our systems do not le-arn.If.
What is the representat ional  status ofyour system?II.
(A) Which parts of grammar or dic-t ionary do you model with your system?G.C.
: I  have separate systems designed to worktogether to handle lexical access, case-gram-mar semantics, and f ixed- length context freegrammar .P .D .
:Lex icon ,  g rammar  and  semant ics .
The  le -x icon  has words with their categories, subca-tegories, and lexical meaning.J .D.
:F ixed- length context- free grammar.P.A.R.
: IR theory the entire system from a re--presentat ion of general cognit ive informationthrough language specif ic "deep" or "functio-nal" structure, through a syntax-morphologystructure, and then through a phonologicalstructure.
In actuality, the syntax-morpho-logy and phonology sections have been workedout in greatest detail, and the functionalstructure in bits and pieces.H.S.
:Syntax and phonology as a part of a le-xical  access system.L.S.
: Domain knowledge in terms of a hierar-chy of concepts/ frames - where each conceptis a col lect ion of attr ibute-value (orslot/f i l ler) pairs.
Such information structu-res are var iably referred to as frame-basedlanguages, semantic networks, inheritancehierarchies, etc.A.Y.
:Syntax and some semantics.II.
(B) Which parts of grammar or dic-t ionary do you model by a concurrent unit ofyour system?G.C.
: I use a local ist approach: One unitstands for a word, a meaning, a syntacticclass, and a binding between meanings and ro-les, syntact ic and semantic.P.D.
: Parts of syntax; lexical search is alsoparal lelJ.D.
: Local ist  representation, i.e.
one syn-tactic category - one unitP.A.R.
:Each category (such as noun phrase) isd istr ibut ive ly  represented by many units.H.S.
:(Local ist ;  on small grained level:) Eachoccurrence of a category- in-ru le-context  (adotted rule in Earley's parser definition) isrepresented by a unit.
(On the large grain le-vel:) The set of possible small grain unitsof each category corresponds to a Turing ma-chine, such that one of its units representsthe current state of the "head" of the TM andthe others its "tape".L.S.
:(Local ist:)  A unit may "represent" aconcept, an attribute, a value, a binder bet-ween (concept,attr ibute,value) triples, orcontrol  nodes that mediate and control thespreading of act ivat ion among these units.A.Y.
:(Local ist:} Each grammatical  category isrepresented as a unit, actual ly each occur-fence of each category in a grammar descr ip-tion is a unit.597'%i:.
(C) Is there a genera l  method suchthat a ~ra~,~ar determines  un ique ly  a para l le limp lementat ion  or is this imp lementat ion  anart?G~.Co~Given a ~rammar,  X have an a lgor t ihm togenerate  the network  for that grammar.P,,D.
:Parsing a lgor i thms are deve loped forTree Ad jo in ino  Grammars?J oDo:  Imp lementat ion  is st i l l  an art.PoA,~Ro~ N?o a cer ta in  extent  it is an art, atthis point,  but  the comprehens ion-acqu is i t ionr~les~ if ~ccess fu l ly  implemented,  shou ldp~ov ide  the ~enera l  method~H~So~ ~r i t ing  grammars  as h igh- leve l  spec i f i  --~cat io~s is au art.
F rom there on there is agenera l  method (same answer  as L.S.
)l, oZo:The networks  are  const ructed  f rom ah igh=leve l  spec i f i ca t ion  of the conceptua lk~o~ledoe  to be encoded.
The mapp ing  betweenthe knowledge level  and the network  level  isp rec i se ly  spec i f ied.
Th is  mapp ing  is per fo r -med automat ica l ly  by a network  compi ler .AoYo: G iven  a gra~muar, we have an a lgor i thmto make a network  of units.I I IoA  short  l is t  of papers  re la ted  toyour  research?GoCo: -Cot t re l l ,  Go, Small ,  S.: V iewingPars ing  as a Word  Sense D isc r iminat ion :A Connect ion is t  Approach?
In B.Bara,G ,Gn ida  (eds.
), Computat iona l  Mode ls  ofNatura l  Language Process ing,  Amsterdam~Nor th  Ho l land  1984--Cottrell, Go : A Connect ion is t  Approachto Nord  Sense D isambiguat ion .
(Techn.Repo 154) Rochester :  The Un ivers i ty  ofRochester ,  Dept  of Computer  Sc ience~Rev ised  vers ion  to be p~bl i shed  byP i tman in the Research  Notes  inAr t i f i c ia l  ~nte l l iuence  Ser iesPoDo~-Dey,  P?, Iyengar,  S.S., Byoun, J .S .
:Para l le l  p rocess ing  of Tree Ad jo in ingGrammars .
Dept.
of Computer  Sc ience,Un ivers i ty  of A labama at B i rmingham~Repor t  1987- Joshi~ A.K.,  Levy~ L.S., Takahash i ,  M.:Tree Ad jo in ing  ~rammars .
Journa l  of theComputer  and System Sciences,  Vol.
i0~pp.
136 - 163, March  1975V i jay -Shankar ,  K~, Joshi,  A?K.
: SomeComputat iona l  P roper t ies  of T reeAd jo in ing  Grammars .P roc .23rd  Ann.Meet ing  Ass?CompiL ing .
,  pp.
82-93, 1985,}oDo:~Cottrell ,  G.W?
Para l le l i sm inInher i tance  H ierach ies  w i th  Except ions?XJCAI -85,  194-202,  Los Angeles,  1985o-Fanty,  M. Context -F ree  Pars ing  inConnect ion is t  Networks .
TR 174,Un ivers i ty  of Rochester ,  Depar tment  ofComputer  Sc ience,  November  1985.-Fanty,  M~ Learn ing  in S t ructuredConnect ion is t  Networks?
Ph.D. Thesis~CS Depar tment ,  Univ~ of Rochester ,1988.~Feldman,  J .A.,  Fanty, M.A.,  & Goddard,No Comput ing  w i th  S t ructured  Neura lNetworks~ IEEE Computer  1988; in press?-Shastr i ,  Lo & Feldman,  JoA.
Semant icNetworks  and Neura l  Nets .
TR 131,Un ivers i ty  of Rochester ,  Depar tment  ofComputer  Sc ience~ June 1984.-Shastr i~ L,, Ev ident ia l  reason ing  insemant ic  networks :  a formal  theory  andits para l le l  .
imp lementat ion , ,  P:::~\]:~,,Thes is  and TR 166~ ComD~ ScJi , DG:pL, ~Univ.
of Rochester~ Se~temb~}: ~ 1985oP oAoR.
:L i te ra ture  f rom sys temic  li~E~uistJ.c:~and para l le l  d i s t~ ib~ted  D:~oce~tsin~,HoS.
: -Schne i le~ H~ ~ Element~; Of theo~'eticai!.net - l ingu is t i cs  t Pax't 1:  Syntactica~.and morpho log ica l  nets -- ~euro -l ingu is t i c  in terpretat ions  o 'J~heox'etic.~.Linguistic..so Ber l in:  D'a l te r  ~\[e Gz~u~te:~:& Coo, 8, 1981~ ppo &7-100... Schnel le ,  I~., Job, D~MoZ )9~\].em<~nt~ u ltheoret i ca l  net- l in~l~ist ics ~.
~?a~'t ~Phono log ica l  nets?
~:~h~o~:~tical!
, inuu is t i c~ I0,.
~.9S3~ }?pc 3~79-203o.. Schnel le ,  }~o : Ar ray  ~_o~ic for ~l~ntact:{.<product ion  processors  ~ Xn Mey~ J~ (r:-~,d~) ~.~,an~uaue and D iscourse  : Testand }~rotest (Sgall--Festseh~ift}Amsterdam.
~ John Ben jamins  D~,V...198~, ppo 477-511o-McCle l land,  JoLo~ ~Iman~ JoL.~In teract ive  p~'ocessien speech  pe~ ..ce~)::io::~ The '~AC~ model,  p~.. 5S--:~:~)in: McCle l land~ JoL., R~e lhar t ,  l .~o~and the PDP-oGroup~ Para.ilel Di~t~' : ' ib ' tV tedProcess in~ --- Exp lorat io~ in the l~iic~:'o-,-structux;e of Cogni t ion ,  VOlo 2~ 1986oAho, AoVo~ Ul lman,  J~noz ~z'inciples ofCompi le :  Des ign  ~- Read ing  Mass?~ ~ d o2:4'rile Pars ing  Method  of Er:t@~'z A(\]dison '~Wesley,  1979oL~S.
z-Fahlman, S~.
NETI,: A System foz ?Represent ing  and Us ing  Rea\].-.~k~'IdKnowledge,  '}:he MIT Press, Cm.~b~ide3~MA, 1979.-Hinton,  G.Eo Imp lement ing  Sema~t~:Networks  in Para l le l  Hardware?
InPara l le l  Mode ls  of Assoc ia t ive  Memo~yopp.
161- 187 in: G.~;oHinton and 3gAgAnderson  (EdSo)~o La~rence  ~rlbau~,~Assoc iates ,  H i l l sda le~ N~Jo~ 198~.o~.Derthik, M~ A Conneet ion is t  Arch i  ~tecture  for Represent ing  and Reasoni~.~.iabout  S t ructured  Knowled~eo Pz-oceed ~oings of the n in th  annual  confe~'enceof the Cogn i t ive  Sc ience  Society?Seatt le~ July, 1987o I, awre~ceEr lbaum Assoc ia tes ,  H i l l sda le  ~oJo-Shast r i ,Lo :  A Connect ion is t  Ap~)roach t<~Knowledge Representat ion  and :l.im~tedin ference.
To appeal" in Cogn i t iveScience:  12,3 (1988)-Shastr i ,  Lo: Se~ant ic  Net~: An Ev.~.de:<~--t ia l  Formal i za t ion  and its Connectgo  .mis t  Rea l i za t ion .
Los Altos~ ~o:?
'~asKauf fman~ London:  P i tman P~bl .CompoA.Y .
: -Kaplan R.  : A Mul t i -P rocessor  Approachto Natura l  Language,  PrOCo Nat iona lComputer  Conference,  1973, ppo 435-440.,-Small S., R ieger  C. : Pars ing  and Com-prehend ing  w i th  Word  Experts~ in Stra -~teg ies  for Natura l  Language P~oces~in~(~Ds.
M.D.
R ing le  and Wo Lenher)Lawrence  Er lba~m Assoc iates ,  1988..~Matsumoto  Y. : A Para l le l  Pars in~ S~ste~fo~ Natura l  Langua~e~ Spr in~er  Lect~'~reNotes  in Computer  Science, No~ 225~1986, ppo 396-409.-Yonezawa A, Ohsawa ~o : A New App~oachto Par~l le l  Pars ing  for  Context--FreeGrammars ,  Research  Repor t  on Info:?
'~ o~at ion  Sc iences  C-87, Dew, to of ~nf~ ScJoTokyo  Ins t l tn te  of Techno lo~y~ ~987.
