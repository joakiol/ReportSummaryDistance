Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 321?324,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsHeidelTime: High Quality Rule-based Extraction and Normalization ofTemporal ExpressionsJannik Str?otgenInstitute of Computer ScienceUniversity of HeidelbergHeidelberg, Germanystroetgen@uni-hd.deMichael GertzInstitute of Computer ScienceUniversity of HeidelbergHeidelberg, Germanygertz@uni-hd.deAbstractIn this paper, we describe HeidelTime, asystem for the extraction and normaliza-tion of temporal expressions.
HeidelTimeis a rule-based system mainly using regu-lar expression patterns for the extraction oftemporal expressions and knowledge re-sources as well as linguistic clues for theirnormalization.
In the TempEval-2 chal-lenge, HeidelTime achieved the highest F-Score (86%) for the extraction and the bestresults in assigning the correct value at-tribute, i.e., in understanding the seman-tics of the temporal expressions.1 IntroductionTemporal annotation of documents, i.e., the ex-traction and chronological ordering of events, iscrucial to many NLP applications, e.g., text sum-marization or machine translation.
In this paper,we describe our system HeidelTime for the extrac-tion and normalization of temporal expressions inEnglish documents.
It was the best-performingsystem in Task A for English of the TempEval-2 challenge1.
The purpose of this challenge wasto evaluate different systems for temporal taggingas well as event and temporal relation extractionsince a competitive evaluation helps to drive for-ward research, and temporal annotation is impor-tant for many NLP tasks (Pustejovsky and Verha-gen, 2009).
The annotation scheme for tempo-ral expressions, events, and relations is based onTimeML, the ISO standard for temporal annota-tion2.Before using temporal information in other ap-plications is possible, the first task to solve is to ex-tract and normalize temporal expressions (Task Aof the challenge, annotated as Timex3).
There1http://semeval2.fbk.eu/2http://www.timeml.org/are two types of approaches to address this prob-lem: rule-based and machine learning ones.
Wedecided to develop a rule-based system since nor-malization can then be supervised in a much eas-ier way.
Furthermore, respective systems allow formodular extensions.Although we only participated in Task A, we donot consider the extraction and normalization oftemporal expressions in isolation, but use temporalinformation in combination with other extractedfacts, e.g., for the exploration of spatio-temporalinformation in documents (Str?otgen et al, 2010).One of our primary objectives is therefore to de-velop a system that can be used in other scenar-ios without any adaptations.
Thus, we implementHeidelTime as a UIMA3(Unstructured Informa-tion Management Architecture) component to in-tegrate the system into our existing document pro-cessing pipeline.
Another advantage of our tem-poral tagger is that the user can choose betweena precision- and a recall-optimized rule set.
Inthe TempEval-2 challenge, both rule sets achievedtop scores in the extraction (F-scores of 86%) andthe precision-optimized set achieved the best re-sults for assigning the correct value attributes tothe temporal expressions (85% accuracy).The remainder of the paper is structured as fol-lows: The system architecture is outlined in thenext section.
In Section 3, we present the evalua-tion results of HeidelTime in comparison to othersystems that participated in the challenge.
We con-clude our paper in Section 4.2 System ArchitectureIn this section, the system architecture of Heidel-Time is explained.
First, UIMA and our UIMA-based document processing pipeline are detailed,followed by a description of the extraction andnormalization tasks, the functionality of the rules3http://uima.apache.org/321?
?TempEval?2data?????????rule?design?workflow??????????????
?task?workflowCollection?ReadersTempEval?2?Readerother?heterogeneoussourcesotherCollection?ReadersAnalysis?EnginesSentence?SplitterTokenizerPOS?TaggerHeidelTimeCAS?ConsumersTempEval?2File?Writer TempEval?2Evaluator otherConsumersUIMA?Document?Processing?Pipelineother?Analysis?EnginesFigure 1: UIMA pipeline with two workflows, onefor rule design and one for using HeidelTime.and the post-processing steps.2.1 Document Processing PipelineHeidelTime is developed as a UIMA componentso that we are able to integrate our temporal taggerinto our existing document processing pipeline.
Itis an extension of the temporal tagger we alreadyuse for the extraction and exploration of spatio-temporal information in documents (Str?otgen etal., 2010).
UIMA is widely used for process-ing unstructured content such as audio, images, ortext.
Different components can be combined tocreate a pipeline of modular tools, and all com-ponents use the same data structure, the CommonAnalysis Structure (CAS).
This allows to combinetools that were not originally built to be used to-gether, an advantage we are using for preprocess-ing tasks as well.In general, a UIMA pipeline consists of threetypes of components, a Collection Reader for ac-cessing the documents from a source and initializ-ing a CAS object for each document.
The analy-sis of the documents is performed by Analysis En-gines that add annotations to the CAS objects.
Fi-nally, CAS Consumers are used for final process-ing, e.g., for storing the annotated information ina database or performing an evaluation.In Figure 1, the document processing pipelinefor designing and using our temporal tagger Hei-delTime is depicted.
The design workflow (leftarrows) contains the TempEval-2 Reader, whichreads the TempEval-2 data, initializes a CAS ob-ject for each textual document and adds the anno-tated data to the CAS.
For the test set of the tem-poral expression task, these include the sentenceand token information, and for the training setalso the gold standard Timex3 entities.
Next, theOpenNLP part-of-speech tagger4is used, whichassigns the corresponding part-of-speech (POS)tag to each token.
The information about sen-tences, tokens, and POS tags is then used byour temporal tagger HeidelTime for extracting andnormalizing temporal expressions mentioned inthe documents.
The CAS Consumer TempEval-2 File Writer is used for creating the files neededfor applying the scorer and which had to be sub-mitted for evaluation.
During the rule develop-ment phase of HeidelTime, the CAS ConsumerTempEval-2 Evaluator was used, which comparesthe gold standard Timex3 annotations with theTimex3 annotations extracted by HeidelTime, re-sulting in lists of true positives, false positives,and false negatives.
These lists were then used foradapting existing or creating new rules.On the right-hand side of Figure 1, a workflowfor using HeidelTime in other scenarios is shown.This workflow reflects the fact that temporal tag-ging is just one intermediate component of ourdocument processing pipeline.
Here, the docu-ments have to be split into sentences and tokensusing the two analysis engines Sentence Splitterand Tokenizer.
The POS tagger and HeidelTimeare used in the same way as described for the otherworkflow.
In addition, other Analysis Engines canbe used, e.g., for combining the extracted tempo-ral information with spatial information.
Finally,CAS Consumers are used, e.g., for storing thespatio-temporal information in a database.2.2 Extraction and Normalization TasksEvery temporal expression te can be viewed asa three-tuple tei= ?ei, ti, vi?, where eiis theexpression itself as it occurs in the textual docu-ment, tirepresents the type of the expression, andviis the normalized value.
There are four possi-ble types, namely Date, Time, Duration, and Set.The normalized value represents the temporal se-mantics of an expression as it is specified by themarkup language TimeML, regardless of the ex-pression used in the document.
The goal of Hei-delTime is to extract for every temporal expressionthe expression eiand to correctly assign the typeand value attributes tiand vi, respectively.For this, HeidelTime uses hand-crafted rules,4http://opennlp.sourceforge.net322ExpressionresourcesreMonth = ?(.
.
.
|June|July|.
.
.
)?reSeason = ?(.
.
.
|summer|.
.
.
)?NormalizationfunctionsnormMonth(?June?)
= ?06?normSeason(?summer?)
= ?SU?Table 1: Examples for extraction and normaliza-tion resources for months and seasons.which are grouped into four types, namely the fourpossible types of temporal expressions.
More pre-cisely, every rule is a triple of an expression rule,a normalization function and the type information.The extraction rules mainly consist of regular ex-pression patterns.
However, other features can beused as well, e.g., a constraint what part-of-speechthe previous or next token has to have.
Heidel-Time contains resources for both the extractionand the normalization tasks of the rules.
For in-stance, there are resources for weekdays, months,or seasons, which are realized as regular expres-sions and can be accessed by multiple extractionrules.
In addition, there are knowledge resourcesfor the normalization of such expressions.
Exam-ples are given in Table 1.Algorithm 1 illustrates how rules are used inHeidelTime.
First, the rules are applied to ev-ery sentence of a document, and extracted timexesare added to the CAS object.
Then, two post-processing steps are executed to disambiguate un-derspecified values and to remove invalid tempo-ral expressions from the CAS.
This functionalityis detailed in the next sections with a focus on thelinguistic clues for the normalization task.Algorithm 1 ApplyRules.foreach sentence in documentaddDatesToCAS(date rules, CAS);addTimesToCAS(time rules, CAS);addDurationsToCAS(dur rules, CAS);addSetsToCAS(set rules, CAS);end foreachforeach timex3 in CASdisambiguateValues(CAS);end foreachremoveInvalidsFromCAS(CAS);2.3 Functionality of HeidelTimeThere are many ways to textually describe tem-poral expressions, either explicitly, implicitly orrelatively (Schilder and Habel, 2001).
The extrac-tion for all temporal expressions works in the sameway, but assigning the value attributes has to bedone differently.
Explicit temporal expressions arefully specified, i.e., the value attribute can directlyexplicit temporal expressionsdate r1 = (reMonth)g1(reDay)g2, (reFullY ear)g3norm r1(g1,g2,g3) = g3-normMonth(g1)-normDay(g2)implicit temporal expressionsdate r2 = (reHoliday)g1(reFullY ear)g2norm r2(g1,g2) = g2-normHoliday(g1)Table 2: Extraction parts and normalization partsof two sample rules.be assigned using the corresponding normalizationfunction of the rule.
For example, the explicit ex-pression March 11, 1982 can be extracted with therule date r1 of Table 2 containing the resourcesreMonth, reDay, and reFullY ear (regular ex-pressions for possible month, day and year tokensof a date phrase, respectively).
The matched to-kens can be accessed using the group ids so thatthe normalization function can be called with theextracted tokens resulting in the value 1982-03-11.The value attribute of implicit expressions canbe assigned once the implicit temporal semanticsof such expressions is known.
Holidays, for ex-ample, can be extracted using date r2 with theresource reHoliday and normalized using theknowledge resource for normalization as shown inTable 2.
An example is Independence Day 2010to which the value 2010-07-04 is assigned.The normalization of relative expressions forwhich a reference time is needed is the most chal-lenging task.
Examples are last June, just Junein phrases such as in June, or year-earlier in theyear-earlier results.
To such expressions, Hei-delTime assigns the values in an underspecifiedformat depending on the assumed reference timeand disambiguates them in a post-processing step.The underspecified values for the examples areUNDEF-last-June, UNDEF-June, and UNDEF-REF-last-year, respectively.
For the first two ex-amples, the document creation time (dct) is as-sumed to be the reference time while for the lastexample the previously mentioned date is used forreference.
In news texts (as used in TempEval-2)the dct is meaningful while other documents maynot contain such a reference time.
Then, the previ-ously mentioned date is used for all underspecifiedvalues.
The disambiguation of such expressions isdetailed in the next section.2.4 Post-ProcessingThe first post-processing step is to disambiguateunderspecified value attributes (see Algorithm 1).If the value starts with UNDEF-REF, the pre-323viously mentioned date is used for disambigua-tion, otherwise the document creation time (dct)if meaningful.
The value UNDEF-last-June ofthe previous section is disambiguated by calcu-lating the June before the dct.
More complexare even less underspecified values like UNDEF-June.
Here, linguistic knowledge is used to dis-ambiguate which June is meant: The tense of thesentence is determined by using the part-of-speechinformation of the tokens and checking the seman-tics of the verbs in the sentence.
This method iden-tifies whether a sentence is past, present, or fu-ture tense.
E.g., the tense of the sentence In June,new results will be published will be determinedto be future tense and the new value UNDEF-next-June can be assigned instead of UNDEF-last-Juneif past tense was identified.
Such values are thendisambiguated using the methods described above.If the reference time is assumed to be thepreviously mentioned date all previous extractedTimex3 are checked to be of the type Date.
Thevalue vrefof the closest previously mentioneddate is then used for further disambiguation.
Forexample, UNDEF-REF-last-year is calculated bysubtracting one year from vref.
This can result ina specific day but also in a specific quarter if thelast mentioned timex was a quarter.The last post-processing step is to remove allextracted timex annotations that are invalid.
In-valid are all expressions that are included in otherexpressions.
For instance, having the phrase June11 the whole phrase is found by a rule as well asjust June.
Since June is in June 11, it is removed.3 EvaluationIn this section, we outline the evaluation of Hei-delTime and compare our results with other sys-tems that participated in the TempEval-2 challengeTask A for English.
For this challenge, we devel-oped two rule sets, one precision- and one recall-optimized set, reflecting the user?s choice betweenprecision and recall.
The first set consists of 43rules, 25 for dates, and 6 for times, durations, andsets, respectively.
The recall-optimized rule setcontains two more rules, one for dates and one fordurations.
These rules are very general and thusnegatively influence precision.Our results for the extraction in the two runs areshown in Figure 2 together with the results of theother participating systems.
As one can see, bothour runs achieved the best F-score results (86%)50607080901005060708090100Precision[%]Recall [%]Figure 2: Performance of participating systemswith an F-score contour for reference.
Our runsare shown as full circles.with a precision of 90% (82%) and a recall of 82%(91%) for the two sets.HeidelTime, with the precision-optimized ruleset, was the best system in assigning the value at-tributes (85% values are assigned correctly).
Inaddition, the type attribute was correctly assignedto 96% of the extracted expressions.4 ConclusionsHeidelTime achieves high quality results for theextraction and normalization of temporal expres-sions.
The precision-optimized rule set achievedthe best results for interpreting the semantics ofthe temporal expressions.
In our opinion, this as-pect, i.e., assigning the correct value attribute, iscrucial since the value is used for further analysisof the documents, e.g., when ordering events ordoing a temporal analysis of documents.The rule-based approach makes it possible to in-clude further knowledge easily, e.g., to assign tem-poral information directly to historic events.ReferencesJames Pustejovsky and Marc Verhagen.
2009.SemEval-2010 Task 13: Evaluating Events, TimeExpressions, and Temporal Relations (TempEval-2).In Proceedings of the Workshop on Semantic Evalu-ations (SEW-2009), pages 112?116.
ACL.Frank Schilder and Christopher Habel.
2001.
FromTemporal Expressions to Temporal Information: Se-mantic Tagging of News Messages.
In Proceedingsof the ACL-2001 Workshop on Temporal and SpatialInformation Processing, pages 65?72.
ACL.Jannik Str?otgen, Michael Gertz, and Pavel Popov.2010.
Extraction and Exploration of Spatio-Temporal Information in Documents.
In GIR ?10,pages 1?8.
ACM.324
