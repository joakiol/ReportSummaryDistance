Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 390?396,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsCross-lingual Transfer of Named Entity Recognizerswithout Parallel CorporaAyah Zirikly?Department of Computer ScienceThe George Washington UniversityWashington DC, USAayaz@gwu.eduMasato HagiwaraDuolingo, Inc.Pittsburgh PA, USAmasato@duolingo.comAbstractWe propose an approach to cross-lingualnamed entity recognition model transferwithout the use of parallel corpora.
In ad-dition to global de-lexicalized features, weintroduce multilingual gazetteers that aregenerated using graph propagation, andcross-lingual word representation map-pings without the use of parallel data.
Wetarget the e-commerce domain, which ischallenging due to its unstructured andnoisy nature.
The experiments have shownthat our approaches beat the strong MTbaseline, where the English model is trans-ferred to two languages: Spanish and Chi-nese.1 IntroductionNamed Entity Recognition (NER) is usuallysolved by a supervised learning approach, wheresequential labeling models are trained from a largeamount of manually annotated corpora.
However,such rich annotated data only exist for resource-rich languages such as English, and building NERsystems for the majority of resource-poor lan-guages, or specific domains in any languages, stillposes a great challenge.Annotation projection through parallel text(Yarowsky et al, 2001), (Das and Petrov, 2011),(Wang and Manning, 2014) has been traditionallyused to overcome this issue, where the annotatedtags in the source (resource-rich) language are pro-jected via word-aligned bilingual parallel text (bi-text) and used to train sequential labeling mod-els in the (resource-poor) target language.
How-ever, this could lead to two issues: firstly, word?This work has been performed while the authors wereat Rakuten Institute of Technology, New York.
The authorswould like to thank Prof. Satoshi Sekine at New York Univer-sity and other members of Rakuten Institute of Technologyfor their support during the project.alignment and projected tags are potentially noisy,making the trained models sub-optimal.
Instead ofprojecting noisy labels explicitly, Wang and Man-ning (2014) project posterior marginals expecta-tions as soft constraints.
Das and Petrov (2011)projected POS tags from source language typesto target language trigarms using graph propaga-tion and used the projected label distribution totrain robust POS taggers.
Secondly, the availabil-ity of such bitext is limited especially for resource-poor languages and domains, where it is often thecase that available resources are moderately-sizedmonolingual/comparable corpora and small bilin-gual dictionaries.Instead, we seek a direct transfer approach(Figure 1) to cross-lingual NER (also classifiedas transductive transfer learning (Pan and Yang,2010) and closely related to domain adaptation).Specifically, we only assume the availability ofcomparable corpora and small-sized bilingual dic-tionaries, and use the same sequential taggingmodel trained on the source corpus for taggingthe target corpus.
Direct transfer approaches areextensively studied for cross-lingual dependencyparser transfer.
For example, Zeman et al (2008)built a constituent parser using direct transfer be-tween closely related languages, namely, Danishand Swedish.
McDonald et al (2011) trainedde-lexicalized dependency parsers in English andthen ?re-lexicalized?
the parser.
However, cross-lingual transfer of named entity taggers have notbeen studied enough, and this paper, to the best ofthe authors?
knowledge, is the first to apply directtransfer learning to NER.Transfer of NER taggers poses a difficult chal-lenge that is different from syntax transfer: mostof the past work deals with de-lexicalized parsers,yet one of the most important clues for NER,gazetteers, is inherently lexicalized.
Also, variousfeatures used for dependency parsing (UniversalPOS tags, unsupervised clustering, etc.)
are yet to390Figure 1: System Frameworkbe proven useful for direct transfer of NER.
There-fore, the contributions of this paper is as follows:1.
We show that direct transfer approach formultilingual NER actually works and per-forms better than the strong MT baseline(Shah et al, 2010), where the system?s out-put in the source language is simply machinetranslated into the target language.2.
We explore various non-lexical features,namely, Universal POS tags and Brown clus-ter mapping, which are deemed effectivefor multilingual NER transfer.
Althoughbrown cluster mapping (T?ackstr?om et al,2012), Universal POS Tagset (Petrov et al,2011), and re-lexicalization and self train-ing (T?ackstr?om et al, 2013) are shown tobe effective for direct transfer of dependencyparsers, there have been no studies exploringthese features for NER transfer.3.
We show that gazetteers can actually begenerated only from the source languagegazetteers and a comparable corpus, througha technique which we call gazetteer expan-sion based on semi-supervised graph prop-agation (Zhu et al, 2003).
Gazetteer ex-pansion has been used for various other pur-poses, including POS tagging (Alexandrescuand Kirchhoff, 2007) and dependency parsers(Durrett et al, 2012).2 ApproachIn this paper we propose a direct transfer learningapproach to train NER taggers in a multilingualsetting.
Our goal is to identify named entities in atarget language LT, given solely annotated data inthe source language LS.
Previous approaches relyon parallel data to transfer the knowledge from onelanguage to another.
However, parallel data is veryexpensive to construct and not available for all lan-guage pairs in all domains.
Thus, our approachloosens the constraint and only requires in-domaincomparable corpora.2.1 Monolingual NER in Source LanguageOur framework is based on direct transfer ap-proach, where we extract abstract, language-independent and non lexical features FSand FTin LSand LT. A subset of FTis generated us-ing a mapping scheme discussed in Section 2.2,then, directly apply LSNER model on LTusingFT.
We adopt Conditional Random Field (CRF)sequence labeling (Lafferty et al, 2001) to trainour system and generate the English model.Monolingual Features 1) Token position: In-stead of using token exact position, we use tokenrelative position in addition to position?s binaryfeatures such as token is in: first, second, and lastthird of the sentence.
These features are based onthe observation that certain tokens, such as brandnames in title or description of a product, tend toappear at the beginning of the sentence, while oth-ers toward the end.2) Word Shape: We use a list of binary fea-tures: is-alphanumerical, is-number, is-alpha, is-punctuation, the number length (if is-num is true),pattern-based features (e.g.
regular expressions tocapture certain patterns such as products modelnumbers), latin-only features (first-is-capital, all-capitals, all-small);3913) In-Title: A binary feature that specifieswhether the token is in the product?s title or de-scription.
For instance, brand names mostly ap-pear in the beginning of titles, while this does nothold in descriptions;4) Preceding/Proceeding keywords within win-dow: some NEs are often preceded by certainkeywords.
For instance, often a product size ispreceded by certain keywords such as dimension,height or word?size.?
In our work we use a manu-ally created list of keywords for two classes Colorand Size.
Although the keyword list is domain de-pendent, it is often short and can be easily updated.5) Universal Part of Speech Tags: Part ofSpeech (POS) tags have been widely used in manyNER systems.
However, each language has itsown POS tagset that often has limited overlap withother POS languages?
tagsets.
Thus, we use acoarse-grained layer of POS tags called UniversalPOS, as proposed in (Petrov et al, 2011).6) Token is a unit: A binary feature that is set totrue if it matches an entry in the units dictionary(e.g., ?cm.?
)7) Gazetteers: Building dictionaries for everyLTof interest is expensive; thus, we proposea method, described in Section 3, to generategazetteers in LTgiven ones in LS.8) Brown Clustering (BC): Word representa-tions, especially Brown Clustering (Brown et al,1992), are used in many NLP tasks and are provento improve NER performance (Turian et al, 2010).In this work, we use cluster IDs of variable pre-fix lengths in order to retrieve word similarities ondifferent granularity levels.2.2 Multilingual NER in Target LanguageOur goal is to transfer each feature from LSto LTspace.
The main challenge resides in transferringfeatures 7 and 8 without the use of external re-sources and parallel data for every target language.2.2.1 Brown Clustering MappingGiven i) Vocabulary in the source/target lan-guages VS= {wS1, wS2, ..., wSNS} and VT={wT1, wT2, ..., vTNT}; ii) The output of brown clus-tering on LSand LT: CS= {cS1, ..., cSKS} andCT= {cT1, ..., cTKL}, we aim to find the bestmapping cS?that maximizes the cluster similaritysimCfor each target cluster (Equation 1), and foreach metric discussed in the following.
We cal-culate the cluster similarity simCas the weightedaverage of the word similarity simWof the mem-bers of the two clusters (Equation 2).cS?= arg maxcS?CSsimC(cS, cT) for each cT?
CT(1)simC(ct, cs) =1|cS||cT|?wS?cS,wT?cTsimW(wS, wT)(2)Clusters Similarity Metrics The similaritymetrics used can be summarized in:a) String Similarity (external resources indepen-dent): This metric works only on languages thatshare the same alphabet, as it is based on the in-tuition that most NEs conserve the name?s shapeor present minor changes that can be identified us-ing edit distance in closely related languages (weuse Levenshtein distance (Levenshtein, 1966)).The two variations of string similarity metricsused are: i) Exact match: simW(wi, wj) =1 if wi= wj; ii) Edit distance: simW(wi, wj) =1 if levenshtein-distance(wi, wj) < ?.b) Dictionary-based similarity: We present twosimilarity metrics using BabelNet synsets (Nav-igli and Ponzetto, 2012): i) Binary co-occurence:simbinaryW(wi, wj) = 1 if wj?
synset(wi),where synset(wi) is the set of words in theBabelNet synset of wi; ii) Frequency weighted:Weighted version of the binary similarity thatis based on the observation that less frequentwords tend to be less reliable in brown clustering:simweightedW(wi, wj) = [log f(wi) + log f(wj)]?simbinaryW(wi, wj) where f(w) is the frequencyof word w. Unlike String similarity metrics, thismetric is not limited to similar languages due tothe use of multilingual dictionaries i.e., BabelNet,which covers 271 languages.3 Gazetteer expansionIn our approach, we use graph-based semi-supervised learning to expand the gazetteers inthe source language to the target.
Figure 2 il-lustrates the motivation of our approach.
Sup-pose we have ?New York?
in the GPE gazetteerin LS(English in this case), and we would liketo bootstrap the corresponding GPE gazetteer inLT(Spanish).
Although there is no direct linkbetween ?New York?
and ?Nueva York,?
you caninfer that ?Puerto Rico?
(in English) is similar to?New York?
based on some intra-language seman-tic similarity model, then ?Puerto Rico?
is actually392						 "!			Figure 2: Gazeteer expansionidentical in both languages, then finally ?NuevaYork?
is similar to ?Puerto Rico?
(in Spanish)again based on the Spanish intra-language similar-ity model.
This indirect inference of beliefs fromthe source gazetteers to the target can be modeledby semi-supervised graph propagation (Zhu et al2003), where graph nodes are VS?
VT, positivelabels are entries in the LSgazetteer (e.g., GPE)which we wish to expand to LT, and negative la-bels are entries in other gazetteers (e.g., PERSON)in LS.
The edge weights between same-languagenodes wiand wjare given by exp(?
?||wi?wj||)where wiis the distributed vector representationof wordwicomputed by word2vec (Mikolov et al,2013).
The edge weights between node wi?
VSand vj?
VTare defined 1 if the spelling of thesetwo words are identical and 0 otherwise.
Note thatthis spelling based similarity propagation is stillavailable for language pairs with different writingsystems such as English and Chinese, because ma-jor NEs (e.g., brand names) are often written inRoman alphabets even in Chinese products.
Sincethe analytical solution to this propagation involvesthe computation of n?n (n is the number of unla-beled nodes) matrix, we approximated it by run-ning three propagation steps iteratively, namely,LS?
LS, LS?
LT, and LT?
LT. Afterthe propagation, we used all the nodes with theirpropagated values f(wi) > ?
as entities in the newgazetteer.4 Experiments4.1 DatasetsThe targeted dataset contains a list of products (ti-tles and descriptions).
The titles of products are?
10 words long and poorly structured, addingmore difficulties to our task.
On the other hand,Color Brand Material Model Type SizeEN 358 814 733 203 1238 427ES 207 425 301 172 606 126ZH 416 60 381 24 690 306Table 1: Language-Tags Numbers Statsthe length of product descriptions ranges from12-130 words.
The e-commerce genre poses theneed to introduce new NE tagset as opposed tothe conventional ones, thus we introduce 6 tagtypes: 1) Color; 2) Brand names; 3) Size; 4) Type:e.g.
?camera,?
?shirt?
; 5) Material: e.g.
?plas-tic?, ?cotton?
; 6) Model: the model number of aproduct: e.g., ?A1533.?.
For the rest of the ex-periments, English (EN) is the source language,whereas we experiment with Spanish (ES) andChinese (ZH) as target languages.
The datasetsused are: i) Training data: 1800 annotated Englishproducts from Rakuten.com shopping (Rakuten,2013a); ii) Test data: 300 ES products fromRakuten Spain (Rakuten, 2013b) and 500 prod-ucts from Rakuten Taiwan (Rakuten, 2013c); iii)Brown clustering: English: Rakuten shopping2013 dump (19m unique products with 607m to-kens); Spanish: Rakuten Spain 2013 dump (700Kunique products that contains 41m tokens) in addi-tion to SpanishWikipedia dump (Al-Rfou?, 2013);Chinese: Wikipedia Chinese 2014 dump (147mtokens) plus 16k products crawled from RakutenTaiwan.
Table 1 shows the numbers of tags percategory for each language.4.2 BaselineTo the best of our knowledge, there is no previ-ous work that proposes transfer learning for NERwithout the use of parallel data.
Thus, we ought togenerate a strong baseline to compare our resultsto.
Given the language pair (LS, LT), we use Mi-crosoft Bing Translate API to generate LT?
LStranslation.
Then, we apply LSNER model on thetranslated text and evaluate by mapping the taggedtokens back to LTusing the word alignments gen-erated by Bing Translate.
We choose Bing trans-late as opposed to Google translate due to its free-to-use API that provides word alignment informa-tion on the character level.4.3 Results & DiscussionFor each studied language we use StanfordCoreNLP (Manning et al, 2014) for EN and ZH,and TreeTagger (Schmid, 1994) for ES to produce393Color Brand Material Model Type Size Micro-AvgEN-Mono 68.45 71.91 50.94 59.78 53.73 45.42 61.12ES-Baseline 24.23 3.44 13.08 14.51 12.5 6.61 13.79ES-TL 18.00 9.37 8.05 16.99 18.26 10.64 39.46ES-GT 38.49 13.31 33.5 2.27 36.43 1.16 30.20ZH-Baseline 19.16 2.79 11.96 None 9.35 6.34 12.58ZH-TL 9.36 1.02 1.81 None 17.28 17.74 23.43Table 2: F-score Resultsthe tokens and the POS tags.
However, we ap-ply extra processing steps to the tokenizer due tothe nature of the domain?s data (e.g., avoid tok-enizing models instances), in addition to normaliz-ing URLs, numbers, and elongation.
We also mapPOS tags for all the source and target languages tothe universal POS tagset as explained in 2.1.Based on Table 2, we note that English mono-lingual performance (80:20 train/test split and 5-folds cross variation) is considerably lower thanstate-of-the-art English NER systems, which isdue to the nature of our targeted domain, the newlyproposed NE tagset, and most importantly, theconsiderably small training data (1280 products).These factors also affects the baseline and our pro-posed system performance.Table 2 illustrates the results for the Englishmonolingual NER system (EN-Mono), baselinefor ES and ZH (ES-Baseline and ZH-Baseline,respectively), our proposed transfer learning ap-proach with the gazetteer expansion (ES-TL andZH-TL).
Additionally, we added the results of ourproposed approach where the gazetteers used aremachine translated using Google translate fromthe English gazetteers to Spanish (ES-MT), in or-der to evaluate our gazetteer expansion approachperformance to the translated gazetteers.We note that ES-Baseline and ZH-Baseline areconsiderably low due to the poor word alignmentgenerated by Bing Translator, which results in in-correct tag projection.
The quality of mapping ismainly due to the noisy nature of the domain?sdata, which can be very expensive to fix.Although the performance of our proposed sys-tem is low (39.46% for ES and 23.43% for ZH),but it surpasses the baseline performance in mostof the tag classes and yields an overall improve-ment on the micro-average F-score of ?
23% inES and 11% in ZH.
We note that one of the rea-sons behind ZH Brand low performance is thatuniversal-POS for brands in EN are mostly propernoun as opposed to noun in ZH, additionally theconsiderably low number of brands in ZH testdata (60).
On the other hand, it is intuitive thatModel yields one of the best performance amongthe tags, since it is the most language independenttag (as depicted in ES-TL).
However, this does nothold true in ZH due to the very small number ofModel instances (24).
Type produces the best per-formance in ES and ZH, due to the high cover-age of the new expanded gazetteer over Type in-stances, in addition to the large number of train-ing instances (1238), in comparison to the othertags.
After conducting leave-out experiments onBrown clustering and gazetteers features in ES, wenote that both shows an improvement of?
4% and?
8% respectively.Our system surpasses the MT-based gazetter ex-pansion by ?
9%, when comparing ES-TL to ES-MT.
However, as expected the main improvementis in Model and Size tags as opposed to other tags(e.g.
Brand and Color) where MT provides moreaccurate gazetteers.
In our system output, colorsthat are included in LTexpanded gazetteers (e.g.?azul?
in ES) and have a high similarity score inour proposed BC mapping, are correctly tagged.On the other hand OOV Brand have a very largeprediction error rate due to the small training data.5 Conclusion and Future WorksIn this paper, we propose a cross-lingual NERtransfer learning approach which does not dependon parallel corpora.
Our experiments showed theability to transfer NER model to latin (ES) andnon latin (ZH) languages.
For the future work, wewould like to investigate the generality of our ap-proach in broader languages and domains.394ReferencesRami Al-Rfou?.
2013.
Spanish wikipedia dump.
url =https://sites.google.com/site/rmyeid/projects/polyglot.Andrei Alexandrescu and Katrin Kirchhoff.
2007.Data-driven graph construction for semi-supervisedgraph-based learning in NLP.
In Human LanguageTechnologies 2007: The Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics; Proceedings of the Main Confer-ence, pages 204?211, Rochester, New York, April.Association for Computational Linguistics.Peter F Brown, Peter V Desouza, Robert L Mercer,Vincent J Della Pietra, and Jenifer C Lai.
1992.Class-based n-gram models of natural language.Computational linguistics, 18(4):467?479.Dipanjan Das and Slav Petrov.
2011.
Unsuper-vised part-of-speech tagging with bilingual graph-based projections.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, pages600?609, Portland, Oregon, USA, June.
Associationfor Computational Linguistics.Greg Durrett, Adam Pauls, and Dan Klein.
2012.
Syn-tactic transfer using a bilingual lexicon.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, pages 1?11.Association for Computational Linguistics.John Lafferty, Andrew McCallum, and Fernando CNPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.VI Levenshtein.
1966.
Binary Codes Capable of Cor-recting Deletions, Insertions and Reversals.
SovietPhysics Doklady, 10:707.Christopher D. Manning, Mihai Surdeanu, John Bauer,Jenny Finkel, Steven J. Bethard, and David Mc-Closky.
2014.
The Stanford CoreNLP natural lan-guage processing toolkit.
In Proceedings of 52ndAnnual Meeting of the Association for Computa-tional Linguistics: System Demonstrations, pages55?60.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?11, pages 62?72, Stroudsburg, PA, USA.Association for Computational Linguistics.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013.
Distributed representa-tions of words and phrases and their compositional-ity.
In Advances in Neural Information ProcessingSystems, pages 3111?3119.Roberto Navigli and Simone Paolo Ponzetto.
2012.BabelNet: The automatic construction, evaluationand application of a wide-coverage multilingual se-mantic network.
Artificial Intelligence, 193:217?250.Sinno Jialin Pan and Qiang Yang.
2010.
A survey ontransfer learning.
IEEE Trans.
on Knowl.
and DataEng., 22(10):1345?1359, October.Slav Petrov, Dipanjan Das, and RyanMcDonald.
2011.A universal part-of-speech tagset.
arXiv preprintarXiv:1104.2086.Rakuten.
2013a.
Rakuten shopping.
url =http://www.rakuten.com/.Rakuten.
2013b.
Rakuten spanish.Rakuten.
2013c.
Rakuten taiwanese.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.Rushin Shah, Bo Lin, Anatole Gershman, and RobertFrederking.
2010.
Synergy: A named entity recog-nition system for resource-scarce languages such asswahili using online machine translation.
In Pro-ceedings of the Second Workshop on African Lan-guage Technology (AfLaT 2010), pages 21?26.Oscar T?ackstr?om, Ryan McDonald, and Jakob Uszko-reit.
2012.
Cross-lingual word clusters for directtransfer of linguistic structure.
In Proceedings ofthe 2012 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pages 477?487, Montr?eal, Canada, June.
Association for Com-putational Linguistics.Oscar T?ackstr?om, Ryan McDonald, and Joakim Nivre.2013.
Target language adaptation of discrimina-tive transfer parsers.
In Proceedings of the 2013Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 1061?1071, Atlanta,Georgia, June.
Association for Computational Lin-guistics.Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: A simple and general methodfor semi-supervised learning.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 384?394.
Association forComputational Linguistics.Mengqiu Wang and Christopher D Manning.
2014.Cross-lingual projected expectation regularizationfor weakly supervised learning.David Yarowsky, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing multilingual text analy-sis tools via robust projection across aligned cor-pora.
In Proceedings of the First International Con-ference on Human Language Technology Research,HLT ?01, pages 1?8, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.395Daniel Zeman, Univerzita Karlova, and Philip Resnik.2008.
Cross-language parser adaptation between re-lated languages.
In In IJCNLP-08Workshop on NLPfor Less Privileged Languages, pages 35?42.Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.2003.
Semi-supervised learning using gaussianfields and harmonic functions.
In IN ICML, pages912?919.396
