Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation, pages 60?68,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsOn the complexity of alignment problems in two synchronous grammarformalismsAnders S?gaard?Center for Language TechnologyUniversity of Copenhagensoegaard@hum.ku.dkAbstractThe alignment problem for synchronousgrammars in its unrestricted form, i.e.
whetherfor a grammar and a string pair the grammarinduces an alignment of the two strings, re-duces to the universal recognition problem,but restrictions may be imposed on the align-ment sought, e.g.
alignments may be 1 : 1,island-free or sure-possible sorted.
The com-plexities of 15 restricted alignment problemsin two very different synchronous grammarformalisms of syntax-based machine transla-tion, inversion transduction grammars (ITGs)(Wu, 1997) and a restricted form of rangeconcatenation grammars ((2,2)-BRCGs) (S?-gaard, 2008), are investigated.
The universalrecognition problems, and therefore also theunrestricted alignment problems, of both for-malisms can be solved in time O(n6|G|).
Thecomplexities of the restricted alignment prob-lems differ significantly, however.1 IntroductionThe synchronous grammar formalisms used insyntax-based machine translation typically inducealignments by aligning all words that are recog-nized simultaneously (Wu, 1997; Zhang and Gildea,?This work was done while the first author was a SeniorResearcher at the Dpt.
of Linguistics, University of Potsdam,supported by the German Research Foundation in the EmmyNoether project Ptolemaios on grammar learning from paral-lel corpora; and while he was a Postdoctoral Researcher at theISV Computational Linguistics Group, Copenhagen BusinessSchool, supported by the Danish Research Foundation in theproject Efficient syntax- and semantics-based machine transla-tion.2004).
On a par with weak and strong generative ca-pacity, it is thus possible to talk about the alignmentcapacity of those formalisms.
In this paper, two syn-chronous grammar formalisms are discussed, inver-sion transduction grammars (ITGs) (Wu, 1997) andtwo-variable binary bottom-up non-erasing rangeconcatenation grammars ((2,2)-BRCGs) (S?gaard,2008).
It is known that ITGs do not induce the classof inside-out alignments discussed in Wu (1997).Another class that ITGs do not induce is that ofalignments with discontinuous translation units (S?-gaard, 2008).
S?gaard (2008), on the other hand,shows that the alignments induced by (2,2)-BRCGsare closed under union, i.e.
(2,2)-BRCGs induce allpossible alignments.The universal recognition problems of both ITGsand (2,2)-BRCGs can be solved in time O(n6|G|).This may come as a surprise, as ITGs restrict thealignment search space considerably, while (2,2)-BRCGs do not.
In the context of the NP-hardness ofdecoding in statistical machine translation (Knight,1999; Udupa and Maji, 2006), it is natural to askwhy the universal recognition problem of (2,2)-BRCGs isn?t NP-hard?
How can (2,2)-BRCGs in-duce all possible alignments and still avoid NP-hardness?
This paper bridges the gap betweenthese results and shows that when alignments arerestricted to be 1 : 1, island-free or sure-possiblesorted (see below), or all combinations thereof,the alignment problem of (2,2)-BRCGs is NP-hard.
(2,2)-BRCGs in a sense avoid NP-hardness by giv-ing up control over global properties of alignments,e.g.
any pair of words may be aligned multiple timesin a derivation.60The alignment structures induced by synchronousgrammars in syntax-based machine translation havethe following property: If an alignment structure in-cludes alignments v|v?, v|w?
and w|w?, it also in-cludes the alignment w|v?, where w,w?, v, v?
areword instances.1 This follows from the fact thatonly words that are recognized simultanously, arealigned.
Otherwise alignment structures are just abinary symmetric relation on two strings, a sourceand a target string, such that two words in the source,resp.
target string, cannot be aligned.
Maximallyconnected subgraphs (ignoring precedence edges)are called translation units.The alignment problem can be formulated thisway (with s, s?
source and target sentence, resp.
):INSTANCE: G, ?s, s?
?.QUESTION: Does G induce an alignmenton ?s, s??
?The alignment problem in its unrestricted formreduces to the universal recognition problem (Bar-ton et al, 1987), i.e.
whether for a grammar G anda string pair ?s, s??
it holds that ?s, s??
?
L(G)?Of course the alignment may in this case be emptyor partial.
Both ITGs and (2,2)-BRCGs permit un-aligned nodes.This paper investigates the complexity of re-stricted versions of the alignment problem for ITGsand (2,2)-BRCGs.
A simple example, which canbe solved in linear time for both formalisms, is thealignment problem wrt.
alignments that consist of asingle translation unit including all source and targetwords.
It may be formulated this way:INSTANCE: G, ?s, s?
?.QUESTION: Does G induce an alignment thatconsists of a single translation unitwith no unaligned words on ?s, s??
?This can be solved for ITGs by checking if thereis a production rule that introduces all the words inthe right order such that:21w|w?
is our short hand notation for saying that w, a wordin the source string, and w?, a word in the target string, havebeen aligned.
In the formal definition of alignments below, it issaid that w ?
Vs (w is a word in the source string), w?
?
Vt(w?
is a word in the target string) and (w,w?)
?
A, i.e.
w isaligned to w?, and vice versa.
Alignments are bidirectional inwhat follows.2In fact in normal form ITGs, we can simply check if there?
The LHS nonterminal symbol (possibly suf-fixed by the empty string ?)
can be derived fromthe start symbol.?
The empty string ?
can be derived from all RHSnonterminal symbols.The only difference for (2,2)-BRCGs is that pro-duction rules are typically referred to as clauses inthe range concatenation grammar literature.This paper considers some more complex exam-ples; namely, the alignment problems wrt.
1 : 1-alignments, (source-side and/or target-side) island-free alignments and sure-possible sorted alignments.The formal definitions of the three properties are asfollows:Definition 1.1.
An alignment structure for a stringpair ?w1 .
.
.
wn, v1 .
.
.
vm?
is a graph D = ?V,E?where V = Vs : {w1, .
.
.
, wn} ?
Vt : {v1, .
.
.
, vm}and E = Es : {wi ?
wj | i < j} ?
Et : {vi ?
vj |i < j} ?
A where A ?
Vs ?
Vt.
If (wi, vj) ?
A,also written wi|vj , wi is said to be aligned to vj ,and vice versa.
An alignment structure is said tobe wellformed iff for all wi, wj , vi?
, vj?
it holds thatif wi|vi?
, wi|vj?
and wj|vi?
are aligned then so arewj |vj?
.
An alignment structure is said to be 1 : 1 iffno word occurs in two distinct tuples inA.
An align-ment structure is said to be island-free iff all wordsin V occur in some tuple inA; it is said to be source-side, resp.
target-side, island-free if all words in Vs,resp.
Vt, occur in some tuple in A.
The set of align-ments is divided into sure and possible alignments,i.e.
A = S ?
P (in most cases P = ?).
An align-ment structure is said to be sure-possible sorted iff ifit holds that (wi, vj?)
?
S then for all wj , vi?
neither(wi, vi?)
?
P nor (wj , vj?)
?
P holds; similarly, ifit holds that (wi, vj?)
?
P then for all wj , vi?
neither(wi, vi?)
?
S nor (wj , vj?)
?
S holds.The precedence relations in E are not importantfor any of our definitions, but are important formeaningful interpretation of alignment structures.Note that synchronous grammars are guaranteed toinduce wellformed alignment structures.
Some briefmotivation for the properties singled out:is a production rule with the start symbol in the LHS that in-troduces all the words in the right order, since all productionrules with nonterminal symbols in the RHS are branching andcontain no terminal symbols.61Result 1 : 1 IF(s) IF(t) SP ITGs (2,2)-BRCGs(1) X O(n6|G|) NP-complete(2) X O(n6|G|) NP-complete(3) X O(n6|G|) NP-complete(4) X O(n6|G|) NP-complete(5) X X O(n6|G|) NP-complete(6) X X O(n6|G|) NP-complete(7) X X O(n6|G|) NP-complete(8) X X O(n6|G|) NP-complete(9) X X O(n6|G|) NP-complete(10) X X O(n6|G|) NP-complete(11) X X X O(n6|G|) NP-complete(12) X X X O(n6|G|) NP-complete(13) X X X O(n6|G|) NP-complete(14) X X X O(n6|G|) NP-complete(15) X X X X O(n6|G|) NP-completeFigure 1: The complexity of restricted alignment problems for ITGs and (2,2)-BRCGs.?
1 : 1-alignments have been argued to be ad-equate by Melamed (1999) and elsewhere, andit may therefore be useful to know if a grammarextracted from a parallel corpus produces 1 : 1-alignments for a finite set of sentence pairs.?
Island-free alignments are interesting to the ex-tent that unaligned nodes increase the chance oftranslation errors.
An island threshold may forinstance be used to rule out risky translations.?
The notion of sure-possible sorted alignmentsis more unusual, but can, for instance, be usedto check if the use of possible alignments isconsistently triggered by words that are hard toalign.The results for all cross-classifications of thefour properties ?
1 : 1, source-side island-free(IF(s)), target-side island-free (IF(t)) and sure-possible sorted (SP) ?
are presented in the table inFigure 1.3 Note that all (24 ?
1 = 15) combina-tions of the four properties lead to NP-hard align-ment problems for (2,2)-BRCGs.
Consequently,3One of our reviewers remarks that the Figure 1 is ?artifi-cially blown up?, since all combinations have the same com-plexity.
It cannot really be left out, however.
The numbers inthe figure?s left-most column serves as a reference in the proofsbelow.
Since the 15 results derive from only four proofs, it isconvenient to have a short-hand notation for the decision prob-lems.while the unrestricted alignment problem for (2,2)-BRCGs can be solved in O(n6|G|), the alignmentproblem turns NP-hard as soon as restrictions are puton the alignments sought.
So the extra expressivityof (2,2)-BRCGs in a way comes at the expense ofcontrol over the kind of alignments obtained.On the structure of the paper: Sect.
2 and 3 brieflyintroduce, resp., ITGs and (2,2)-BRCGs.
Sect.
4presents three NP-hardness proofs from which the15 results in Figure 1 can be derived.
The threeproofs are based on reconstructions of the Hamiltoncircuit problem, the 3SAT problem and the vertexcover problem (Garey and Johnson, 1979).2 Inversion transduction grammarsInversion transduction grammars (ITGs) (Wu, 1997)are a notational variant of binary syntax-directedtranslation schemas (Aho and Ullman, 1972) and areusually presented with a normal form:A ?
[BC]A ?
?BC?A ?
e | fA ?
e | ?A ?
?
| fwhere A,B,C ?
N and e, f ?
T .
Thefirst production rule, intuitively, says that the sub-tree [[]B []C ]A in the source language translates into62a subtree [[]B []C ]A, whereas the second produc-tion rule inverts the order in the target language,i.e.
[[]C []B ]A.
The universal recognition problem ofITGs can be solved in time O(n6|G|) by a CYK-style parsing algorithm with two charts.Figure 1 tells us that all the restricted alignmentproblems listed can be solved in time O(n6|G|).The explanation is simple.
It can be read off fromthe syntactic form of the production rules in ITGswhether they introduce 1 : 1-alignments, island-freealignments or sure-possible sorted alignments.
Notethat normal form ITGs only induce 1 : 1-alignments.Consider, for example, the following grammar,not in normal form for brevity:(1) S ?
?ASB?
| ?AB?
(2) A ?
a | a(3) A ?
a | ?
(4) B ?
b | bNote that this grammar recognizes the transla-tion {?anbn, bnam | n ?
m}.
To check if for astring pair ?w1 .
.
.
wn, v1 .
.
.
vm?
this grammar in-duces an island-free alignment, simply remove pro-duction rule (3).
It holds that only strings in the sub-language {?anbn, bnan | n ?
1} induce island-freealignments.
Similarly, to check if the grammar in-duces source-side island-free alignments for stringpairs, no production rules will have to be removed.3 Two-variable binary bottom-upnon-erasing range concatenationgrammars(2,2)-BRCGs are positive RCGs (Boullier, 1998)with binary start predicate names, i.e.
?
(S) = 2.
InRCG, predicates can be negated (for complementa-tion), and the start predicate name is typically unary.The definition is changed only for aesthetic rea-sons; a positive RCG with a binary start predicatename S is turned into a positive RCG with a unarystart predicate name S?
simply by adding a clauseS?
(X1X2) ?
S(X1,X2).A positive RCG is a 5-tuple G = ?N,T, V, P, S?.N is a finite set of predicate names with an arityfunction ?
: N ?
N, T and V are finite sets of, resp.,terminal and variables.
P is a finite set of clauses ofthe form ?0 ?
?1 .
.
.
?m, where each of the ?i, 0 ?i ?
m, is a predicate of the form A(?1, .
.
.
, ??
(A)).Each ?j ?
(T ?V )?, 1 ?
j ?
?
(A), is an argument.S ?
N is the start predicate name with ?
(S) = 2.Note that the order of RHS predicates in a clauseis of no importance.
Three subclasses of RCGs areintroduced for further reference: An RCG G =?N,T, V, P, S?
is simple iff for all c ?
P , it holdsthat no variable X occurs more than once in theLHS of c, and if X occurs in the LHS then it oc-curs exactly once in the RHS, and each argumentin the RHS of c contains exactly one variable.
AnRCGG = ?N,T, V, P, S?
is a k-RCG iff for all A ?N, ?
(A) ?
k. Finally, an RCG G = ?N,T, V, P, S?is said to be bottom-up non-erasing iff for all c ?
Pall variables that occur in the RHS of c also occur inits LHS.A positive RCG is a (2,2)-BRCG iff it is a 2-RCG,if an argument of the LHS predicate contains at mosttwo variables, and if it is bottom-up non-erasing.The language of a (2,2)-BRCG is basedon the notion of range.
For a string pair?w1 .
.
.
wn, vn+2 .
.
.
vn+1+m?
a range is a pairof indices ?i, j?
with 0 ?
i ?
j ?
n orn < i ?
j ?
n + 1 + m, i.e.
a string span,which denotes a substring wi+1 .
.
.
wj in the sourcestring or a substring vi+1 .
.
.
vj in the target string.Only consequtive ranges can be concatenated intonew ranges.
Terminals, variables and argumentsin a clause are bound to ranges by a substitutionmechanism.
An instantiated clause is a clause inwhich variables and arguments are consistentlyreplaced by ranges; its components are instantiatedpredicates.
For example A(?g .
.
.
h?, ?i .
.
.
j?)
?B(?g .
.
.
h?, ?i + 1 .
.
.
j ?
1?)
is an instantiationof the clause A(X1, aY1b) ?
B(X1, Y1) if thetarget string is such that vi+1 = a and vj = b.A derive relation =?
is defined on strings ofinstantiated predicates.
If an instantiated predicateis the LHS of some instantiated clause, it can bereplaced by the RHS of that instantiated clause.
Thelanguage of a (2,2)-BRCG G = ?N,T, V, P, S?
isthe set L(G) = {?w1 .
.
.
wn, vn+2 .
.
.
vn+1+m?
|S(?0, n?, ?n + 1, n + 1 + m?)
?=?
?
}, i.e.
aninput string pair ?w1 .
.
.
wn, vn+2 .
.
.
vn+1+m?
isrecognized iff the empty string can be derived fromS(?0, n?, ?n + 1, n + 1 +m?
).It is not difficult to see that ITGs are also (2,2)-BRCGs.
The left column is ITG production rules;63the right column their translations in simple (2,2)-BRCGs.A?
[BC] A(X1X2, Y1Y2) ?
B(X1, Y1)C(X2, Y2)A?
?BC?
A(X1X2, Y1Y2) ?
B(X1, Y2)C(X2, Y1)A?
e | f A(e, f) ?
?A?
e | ?
A(e, ?)
?
?A?
?
| f A(?, f) ?
?Consequently, (2,2)-BRCGs recognize all trans-lations recognized by ITGs.
In fact the inclusion isstrict, as shown in S?gaard (2008).
The universalrecognition problem of (2,2)-BRCGs can be solvedin time O(n6|G|) by the CYK-style parsing algo-rithm presented in S?gaard (2008).Example 3.1.
Consider the (2,2)-BRCG G =?
{Ss, S0, S?0, S1, S?1, A,B,C,D}, {a, b, c, d}, {X1 ,X2, Y1, Y2}, P, Ss?
with P the following set ofclauses:(1) Ss(X1, Y1) ?
S0(X1, Y1)S?0(X1, Y1)(2) S0(X1X2, Y1) ?
S1(X1, Y1)D(X2)(3) S1(aX1c, abY1) ?
S1(X1, Y1)(4) S1(X1, Y1Y2) ?
B(X1)C(Y1)D(Y2)(5) S?0(X1X2, Y1) ?
S?1(X2, Y1)A(X1)(6) S?1(bX1d, Y1cd) ?
S?1(X1, Y1)(7) S?1(X1, Y1Y2) ?
C(X1)A(Y1)B(Y2)(8) A(aX1) ?
A(X1)(9) A(?)
?
?
(10) B(bX1) ?
B(X1)(11) B(?)
?
?
(12) C(cX1) ?
C(X1)(13) C(?)
?
?
(14) D(dX1) ?
D(X1)(15) D(?)
?
?The string pair ?abbcdd, abcdcd?
is derived:Ss(?0, 6?, ?0, 6?)=?
S0(?0, 6?, ?0, 6?
)S?0(?0, 6?, ?0, 6?)
(1)=?
S1(?0, 4?, ?0, 6?
)D(?4, 6?)
(2)S?0(?0, 6?, ?0, 6?)=?
S1(?0, 4?, ?0, 6?
)S?0(?0, 6?, ?0, 6?)
(14?15)=?
S1(?1, 3?, ?2, 6?
)S?0(?0, 6?, ?0, 6?)
(3)=?
B(?1, 3?
)C(?2, 4?
)D(?4, 6?)
(4)S?0(?0, 6?, ?0, 6?)=?
S?0(?0, 6?, ?0, 6?)
(10?15)=?
S?1(?1, 6?, ?0, 6?
)A(?0, 1?)
(5)=?
S?1(?1, 6?, ?0, 6?)
(8?9)=?
S?1(?2, 5?, ?0, 4?)
(6)=?
S?1(?3, 4?, ?0, 2?)
(6)=?
C(?3, 4?
)A(?0, 1?
)B(?1, 2?)
(7)=?
?
(8?13)Note that L(G) = {?anbmcndm, (ab)n(cd)m?
|m,n ?
0}.4 Results4.1 Checking island-freeness and sure-possiblesortednessOne possible way to check for island-freeness andsure-possible sortedness in the context of (2,2)-BRCGs is to augment the CYK-style algorithm withfeature structures (Boolean vectors); all there isneeded, e.g.
to check sure-possible sortedness, is topair up the nonterminals inserted in the cells of thechart with a flat feature structure of the form:???
?SURE1 val1...SUREn valn???
?where n is the length of the source, resp.
tar-get, string in the source, resp.
target, chart, and1 ?
i ?
n : val i ?
{+,?}.
When a clause ap-plies that induces a sure alignment between a wordwi and some word in the target, resp.
source, string,the attribute SUREi is assigned the value +; if a pos-sible alignment is induced between wi and anotherword, the attribute is assigned the value -.
This canall be done in constant time.
A copying clause nowchecks if the appropriate nonterminals have been in-serted in the cells in question, but also that the as-sociated feature structures unify.
This can be donein linear time.
Feature structures can be used thesame way to record what words have been aligned tocheck island-freeness.
Unfortunately, this techniquedoes not guarantee polynomial runtime.
Note thatthere can be 2n many distinct feature structures foreach nonterminal symbol in a chart.
Consequently,whereas the size of a cell in the standard CYK algo-rithm is bounded by |N |, and in synchronous parsingby |N |?
(2n?
1),4 the cells are now of exponentialsize in the worst case.The following three sections provide three NP-hardness proofs: The first shows that the alignment4The indices used to check that two nonterminals are derivedsimultaneously (S?gaard, 2008) mean that it may be necessarywithin a cell in the source, resp.
target, chart to keep track ofmultiple tuples with the same nonterminals.
In the worst case,there is a nonterminal for each span in the target, resp.
source,chart, i.e.
2n?
1 many.64problem wrt.
1 : 1-alignments is NP-hard for (2,2)-BRCGs and goes by reduction of the Hamilton cir-cuit problem for directed connected graphs.
The sec-ond shows that the alignment problem wrt.
source-or target-side island-free and sure-possible sortedalignments is NP-hard for (2,2)-BRCGs and goesby 3SAT reduction.
The third proof is more generaland goes by reduction of the vertex cover problem.All three formal decision problems are discussed indetail in Garey and Johnson (1979).
All 15 resultsin Figure 1 are derived from modifications of theseproofs.4.2 NP-hardness of the 1 : 1 restriction for(2,2)-BRCGsTheorem 4.1.
The alignment problem wrt.
1 : 1-alignments is NP-hard for (2,2)-BRCGs.Proof.
An instance of the Hamilton circuit problemfor directed connected graphs is simply a directedconnected graph G = ?V,E?
and the problem iswhether there is a path that visits each vertex exactlyonce and returns to its starting point?
Consider, forinstance, the directed connected graph:1 234 5It is easy to see that there is no path in this casethat visits each vertex exactly once and returns to itsstarting point.
The intuition behind our reconstruc-tion of the Hamilton circuit problem for directedconnected graphs is to check this via alignments be-tween a sequence of all the vertices in the graph anditself.
The grammar permits an alignment betweentwo wordsw|v if there is a directed edge between thecorresponding nodes in the graph, e.g.
(w, v) ?
E.The alignment structures below depict the possiblealignments induced by the grammar obtained by thetranslation described below for our example graph:1 2 3 4 51 2 3 4 51 2 3 4 51 2 3 4 51 2 3 4 51 2 3 4 51 2 3 4 51 2 3 4 5Since no alignment above is 1 : 1, there is nosolution to the corresponding circuit problem.
Thetranslation goes as follows:?
Add a rule S(X1, Y1) ?
{Svi(X1, Y1) |?vi.?vj.
(vi, vj) ?
E}.?
For each edge (vi, vj) ?
E adda rule Svi(X1viX2, Y1vjY2) ??(X1)?(X2)?(X3)?(X4).5?
For all vi ?
V add a rule ?
(viX1) ?
?(X1).?
Add a rule ?(?)
?
?.The grammar ensures source-side island-freeness,and therefore if there exists a 1 : 1-alignment of anylinearization of V and itself, by connectivity of theinput graph, there is a solution to the Hamilton cir-cuit problem for directed connected graphs.4.3 NP-hardness of island-freeness andsure-possible sortedness for (2,2)-BRCGsTheorem 4.2.
The alignment problem wrt.
target-side island-free and sure-possible sorted alignmentsis NP-hard for (2,2)-BRCGs.Proof.
An instance of the 3SAT problem is a propo-sitional logic formula ?
that is a conjunction ofclauses of three literals connected by disjunctions,and the problem whether this formula is satisfiable,i.e.
has a model?
Say ?
= p?q?r?p??q??r?.
For ourreconstruction, we use the propositional variablesin ?
as source string, and ?
itself with ?
?s omittedand conjuncts as words as the target string.
One ofthe representations of a solution constructed by thetranslation described below is the following align-ment structure:p q rp ?
q ?
r p?
?
q?
?
r?Solid lines are sure alignments; dotted lines arepossible alignments.
The intuition is to use surealignments to encode true assignments, and possi-ble alignments as false assignments.
The alignment5?
is an arbitrary predicate name chosen to reflect the factthat all possible substrings over the vocabulary are recognizedby the ?
predicates.65above thus corresponds to the model {p, r?
}, whichclearly satisfies ?.For the translation, assume that each 3SAT in-stance, over a set of propositional variables PROP,consists of a set of clauses c1 .
.
.
cm that are sets ofliterals of size 3.
For any literal lj , if lj = p?j thenpos(lj) = pj and lit(lj) = ?
; and if lj = pj thenpos(lj) = pj and lit(lj) = +.
If lj is a literal inci, we write lj ?
ci.
First add the following fourclauses:Ss(X1, Y1) ?
Ss(X1, Y1) | Sp(X1, Y1)Sp(X1, Y1) ?
Ss(X1, Y1) | Sp(X1, Y1)?
If lj ?
ci and lit(lj) = ?, addSp(X1pos(lj)X2, Y1ciY2) ?
?(X1)?(X2)?(Y1)?
(Y2) .?
If lj ?
ci and lit(lj) = +, addSs(X1pos(lj)X2, Y1ciY2) ?
?(X1)?(X2)?(Y1)?
(Y2) .?
For all pj , add ?
(pjX1) ?
?(X1).?
For all ci, add ?
(ciX1) ?
?(X1).?
Add a rule ?(?)
?
?.It is easy to see that the first rule adds at most7m clauses, which for the largest non-redundantformulas equals 7((2|PROP|)3).
The second ruleadds at most 2|PROP| clauses; and the third at mostm ?
(2|PROP|)3 clauses.
It is also easy to see thatthe grammar induces a target-side island-free, sure-possible sorted alignment if and only if the 3SAT in-stance is satisfiable.
Note that the grammar does notguarantee that all induced alignments are target-sideisland-free.
Nothing, in other words, correspondsto conjunctions in our reconstruction.
This is notnecessary as long as there is at least one target-sideisland-free alignment that is induced.Note that the proof also applies in the case whereit is the source side that is required to be island-free.All needed is to make the source string the targetstring, and vice versa.
Note also that the proof canbe modified for the case where both sides are island-free: Just add a dummy symbol to the clause sideand allow (or force) all propositional variables tobe aligned to this dummy symbol.
Consequently, ifthere is a target-side (clause-side) island-free align-ment there is also an island-free alignment.
Re-versely, if there is an island-free alignment there isalso a target-side island-free alignment of the stringpair in question.Note also that a more general proof can be ob-tained by introducing a clause, similar to the clauseintroduced in the first bullet point of the Hamil-ton circuit reduction in the proof of Theorem 4.1:S(X1, Y1) ?
{Sci(X1, Y1) | 1 ?
i ?
m}.
Thefour rules used to change between sure and pos-sible alignments then of course need to be copiedout for all Sci predicates, and the LHS predicates,except ?, of the other clauses must be properlysubscripted.
Now the grammar enforces target-side island-freeness, and sure-possible sortedness isthe only restriction needed on alignments.
Conse-quently, this reduction proves (4) that the alignmentproblem wrt.
sure-possible sortedness is NP-hard for(2,2)-BRCGs.4.4 NP-hardness of island-freeness for(2,2)-BRCGsTheorem 4.3.
The alignment problem wrt.
island-free alignments is NP-hard for (2,2)-BRCGs.Proof.
An instance of the vertex problem is a graphD = ?V,E?
and an integer k, and the prob-lem whether there exists a vertex cover of D ofsize k?
Say D = ?V = {a, b, c, d}, E ={(a, c), (b, c), (b, d), (c, d)}?
and k = 2.
The trans-lation described below constructs a sentence pair??1?2?3?4uu???
?, aaaabbbbccccdddd?for this instance, and a (2,2)-BRCG with theclauses in Figure 2.
Note that there are four kindsof clauses:?
A clause with an S predicate in the LHS.
Ingeneral, there will be one such clause in thegrammar constructed for any instance of thevertex cover problem.?
8 clauses with ?i predicates in the LHS.
In gen-eral, there will be 2|E| many clauses of thisform in the grammars.?
8 clauses withU i predicates in the LHS.
In gen-eral, there will be |V |?
(|V |?k) many clausesof this form in the grammars.66?
16 clauses with ?1 predicates in the LHS.
Ingeneral, there will be (|E| ?
|V | ?
|E| ?
|E| ?
(|V | ?
k)) ?
|V | many clauses of this form inthe grammars.For an instance ?D = ?V,E?, k?, the translationfunction in general constructs the following clauses:S(X1, Y1) ?
{?i(X1, Y1) | 1 ?
i ?
|E|}?
{U |V |?k(X1, Y1)}?
{?|E|?|V |?|E|?|E|?
(|V |?k)(X1, Y1)}and for all 1 ?
i ?
|E| iff ei ?
E = (e, e?
):?i(X1?iX2, Y1eY2) ?
?(X1)?(X2)?(Y1)?
(Y2)?i(X1?iX2, Y1e?Y2) ?
?(X1)?(X2)?(Y1)?
(Y2)For all 2 ?
i ?
|V | ?
k and for all v ?
V :U i(X1UX2, Y1v .
.
.
vY2) ?
U i?1(X1, Y1)?(X2)?
(Y2)where |v .
.
.
v| = |E|.
For the case U1, add theclauses for all v ?
V :U1(X1UX2, Y1v .
.
.
vY2) ?
?(X1)?(Y1)?(X2)?
(Y2)The string pair is constructed this way:?
?1 .
.
.
?|E|U1 .
.
.
U|V |?k?1 .
.
.
?|E|?|V |?|E|?|E|?
(|V |?k), ?
?Finally, for all words w in this string pair, add:?
(wX1) ?
?
(X1)Since this translation is obviously polynomial, itfollows that the alignment problem wrt.
island-freealignments for (2,2)-BRCGs is NP-hard.Note that the proof also applies if only the source,resp.
target, side is required to be island-free, sincethe grammar restricts the alignments in a way suchthat if one side is island-free then so is the other side.This gives us results (2) and (3).It is not difficult to see either that it is possibleto convert the grammar into a grammar that induces1 : 1-alignments.
This gives us results (5), (8) and(11).
Of course by the observation that all the gram-mars only use sure alignments, it follows that thealignment problems in (7), (9?10) and (12?15) arealso NP-hard.5 ConclusionThe universal recognition problems of both ITGsand (2,2)-BRCGs can be solved in time O(n6|G|).This may come as a surprise, as ITGs restrict thealignment space considerably, while (2,2)-BRCGsinduce all possible alignments.
In the context ofthe NP-hardness of decoding in statistical machinetranslation (Knight, 1999; Udupa and Maji, 2006),it is natural to ask why the universal recognitionproblem of (2,2)-BRCGs isn?t NP-hard?
This pa-per bridges the gap between these results and showsthat when alignments are restricted to be 1 : 1,island-free or sure-possible sorted, or all combi-nations thereof, the alignment problem of (2,2)-BRCGs is NP-hard.
Consequently, while the un-restricted alignment problem for (2,2)-BRCGs canbe solved in O(n6|G|), the alignment problem turnsNP-hard as soon as restrictions are put on the align-ments sought.
So the extra expressivity in a waycomes at the expense of control over the kind ofalignments obtained.
Note also that an alignmentof two words may be enforced multiple times in a(2,2)-BRCGs parse, since two derivation trees thatshare leaves on both sides can align the same twowords.Our results are not intended to be qualifications ofthe usefulness of (2,2)-BRCGs (S?gaard, 2008), butrather they are attempts to bridge a gap in our under-standing of the synchronous grammar formalisms athand to us in syntax-based machine translation.67S(X1, Y1) ?
?1(X1, Y1)?2(X1, Y1)?3(X1, Y1)?4(X1, Y1)U2(X1, Y1)?4(X1, Y1)?1(X1?1X2, Y1aY2) ?
?(X1)?(X2)?(Y1)?
(Y2)?1(X1?1X2, Y1cY2) ?
?(X1)?(X2)?(Y1)?(Y2).
.
.U2(X1UX2, aaaaY1) ?
U1(X1, Y1)?
(X2)U1(X1UX2, Y1bbbbY2) ?
?(X1)?(Y1)?(X2)?
(Y2)U2(X1UX2, Y1bbbbY2) ?
U1(X1, Y1)?(X2)?(Y2).
.
.
?4(X1?X2, Y1aY2) ?
?3(X1, Y1)?(X2)?
(Y2)?4(X1?X2, Y1bY2) ?
?3(X1, Y1)?(X2)?(Y2).
.
.Figure 2: A (2,2)-BRCG for the instance of the vertex cover problem ??
{a, b, c, d}, {(a, c), (b, c), (b, d), (c, d)}?, 2?.ReferencesAlfred Aho and Jeffrey Ullman.
1972.
The theoryof parsing, translation and compiling.
Prentice-Hall,London, England.Edward Barton, Robert Berwick, and Erik Ristad.
1987.Computational complexity and natural language.
MITPress, Cambridge, Massachusetts.Pierre Boullier.
1998.
Proposal for a natural languageprocessing syntactic backbone.
Technical report, IN-RIA, Le Chesnay, France.Michael Garey and David Johnson.
1979.
Computersand intractability.
W. H. Freeman & Co., New York,New York.Kevin Knight.
1999.
Decoding complexity in word-replacement translation models.
Computational Lin-guistics, 25(4):607?615.Dan Melamed.
1999.
Bitext maps and alignmentvia pattern recognition.
Computational Linguistics,25(1):107?130.Anders S?gaard.
2008.
Range concatenation gram-mars for translation.
In Proceedings of the 22ndInternational Conference on Computational Linguis-tics, Companion Volume, pages 103?106, Manchester,England.Raghavendra Udupa and Hemanta Maji.
2006.
Compu-tational complexity of statistical machine translation.In Proceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 25?32, Trento, Italy.Dekai Wu.
1997.
Stochastic inversion transductiongrammars and bilingual parsing of parallel corpora.Computational Linguistics, 23(3):377?403.Hao Zhang and Daniel Gildea.
2004.
Syntax-basedalignment: supervised or unsupervised?
In Proceed-ings of the 20th International Conference on Compu-tational Linguistics, pages 418?424, Geneva, Switzer-land.68
