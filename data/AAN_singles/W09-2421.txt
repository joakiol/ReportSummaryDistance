Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 129?137,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsRelation detection between named entities: report of a shared taskCla?udia Freitas, Diana SantosCristina MotaSINTEF ICTclaudiafreitas@puc-rio.brDiana.Santos@sintef.nocmota@ist.utl.ptHugo Gonc?alo OliveiraCISUC, DEI - FCTUChroliv@dei.uc.ptPaula CarvalhoUniv.
Lisbon, FCUL, XLDBpcc@di.fc.ul.ptAbstractIn this paper we describe the first evalu-ation contest (track) for Portuguese whosegoal was to detect and classify relations be-tween named entities in running text, calledReRelEM.
Given a collection annotated withnamed entities belonging to ten different se-mantic categories, we marked all relationshipsbetween them within each document.
We usedthe following fourfold relationship classifi-cation: identity, included-in, located-in, andother (which was later on explicitly detailedinto twenty different relations).
We provide aquantitative description of this evaluation re-source, as well as describe the evaluation ar-chitecture and summarize the results of theparticipating systems in the track.1 MotivationNamed entity recognition can be considered the firststep towards semantic analysis of texts and a crucialsubtask of information extraction systems.
Propernames, besides their high frequency in language, domore than just refer ?
they convey additional infor-mation as instances of general semantic categories.But NE recognition is, as just mentioned, only thefirst step for full language processing.
If we want togo beyond the detection of entities, a natural step isestablishing semantic relations between these enti-ties, and this is what this paper is about.There are two fairly independent communitiesthat focus on the task of detecting relations betweennamed entities: the work on anaphora resolution, il-lustrated by (Mitkov, 2000; Collovini et al, 2007;de Souza et al, 2008) and the work on relation de-tection in information extraction, see e.g.
(Agichteinand Gravano, 2000; Zhao and Grishman, 2005; Cu-lotta and Sorensen, 2004).
Although both commu-nities are doing computational semantics, the twofields are largely non-overlapping, and one of themerits of our work is that we tried to merge the two.Let us briefly describe both traditions: as (Mitkov,2000) explains, anaphora resolution is concernedwith studying the linguistic phenomenon of pointingback to another expression in the text.
The seman-tic relations between the referents of these expres-sions can be of different types, being co-reference aspecial case when the relation is identity.
The focusof anaphora resolution is determining the antecedentchains, although it implicitly also allows to elicit se-mantic relations between referents.
This task has along tradition in natural language processing (NLP)since the early days of artificial intelligence (Web-ber, 1978), and has from the start been considered akey ingredient in text understanding.A different tradition, within information extrac-tion and ontology building, is devoted to fact ex-traction.
The detection of relations involving namedentities is seen as a step towards a more structuredmodel of the meaning of a text.
The main concernshere (see e.g.
(Zhao and Grishman, 2005)) are theextraction of large quantities of facts, generally cou-pled with machine learning approaches.1Although mentions of named entities may ex-1Other authors use the term relation detection in still otherways: for example, (Roth and tau Yih, 2004) use it for the trans-lation of any natural language sentences into ?logical form?, asin kill (x,y).
This task does not concern us here.129Relations WorksorgBased-in, Headquarters, Org-Location, Based-in RY, AG, DI, Sn, CS, ACE07, ACE04, ZGlive-in, Citizen-or-Resident RY, ACE04, ZG, ACE07,CSEmployment, Membership, Subsidiary ZG, CS, ACE04, ACE07located(in), residence, near ACE04, ACE07,CS, ZGwork-for, Affiliate, Founder, Management,Client, Member, Staff CS, ACE04, ACE07, RY, ZGAssociate, Grandparent, Parent, Sibling,Spouse, Other-professional, Other-relative, Other-personal CS, ACE04, ACE07User, Owner,Inventor, Manufacturer ACE04,ACE07, ZG, CSDiseaseOutbreaks AGMetonymy ACE07identity AREsynonym AREgeneralisation AREspecialisation ARETable 1: Relations used in other works or evaluation contests.press semantic relations other than identity or de-pendency, the main focus of the first school hasbeen limited to co-reference.
Yet, relations suchas part-of have been considered under the labelof indirect anaphora, also known as associative orbridging anaphora.Contrarywise, the list of relations of interest forthe second school is defined simply by world knowl-edge (not linguistic clues), and typical are the rela-tions between an event and its location, or an orga-nization and its headquarters.
Obviously, these rela-tions do occur between entities that do not involve(direct or indirect) anaphora in whatever broad un-derstanding of the term.Also, relation detection in the second school doesnot usually cover identity (cf.
ACE?s seven relationtypes): identity or co-reference is often consideredan intermediate step before relation extraction (Cu-lotta and Sorensen, 2004).Table 1 displays a non-exhaustive overview of thedifferent relations found in the literature.2In devising the ReRelEM3 pilot track, our goalwas twofold: to investigate which relations could2There is overlap between ACE 2007 and 2004 types of re-lations.
In order to ease the comparison, we used the names ofsubtypes for ACE relations.3ReRelEM stands for Reconhecimento de Relac?o?es entreEntidades Mencionadas, Portuguese for ?recognition of rela-tions between named entities?, see (Freitas et al, 2008).be found between named entities in Portuguese text,and how could a pilot task be devised that comparedthe performance of different automatic systems sup-posed to identify them.
It should be emphasized thatboth MUC and ACE were key inspiration sources forReRelEM, which stems from Linguateca?s emphasison evaluation.In fact, we were conversant with MUC co-reference track and the way it was scored, as wellas aware of two other related evaluation contests:ACE (Doddington et al, 2004; NIST and ACE,2007), which extended MUC by dropping the re-quirement that entities had to be named, and ARE(Ora?san et al, 2008), which requested the identifi-cation of an anaphoric relation in certain types ofpre-defined relations (identity, synonymy, general-ization and specification), but which ignored indirectanaphora (that may convey meronymy, or inclusion,in a broad sense).ReRelEM, although maintaining (or adding) therestriction to named entitites, is, from our point ofview, an advance in the field of relation detection,since we proposed the detection (and classification)of all (relevant) kinds of relations between NEs in adocument, providing thus both a merge and an ex-tension of the previous evaluation campaigns.130Category/gloss #PESSOA/person 196LOCAL/place 145ORGANIZACAO/org 102TEMPO/time 84OBRA/title 33VALOR/value 33ACONTECIMENTO/event 21ABSTRACCAO/abstraction 17OUTRO/other 6COISA/thing 5Table 2: Category distribution in the golden collection2 Track descriptionThe purpose of ReRelEM is to assess systems thattry to recognize the most relevant relations betweennamed entities, even if those relations do not involvecoreference or anaphora.2.1 ContextIn order for it to be feasible in the short time wehad, the track definition required that both referringexpression and their semantic referent were namedentities.
Pronouns and definite descriptions werehence excluded.
Note also that ReRelEM was de-fined in the context of the second edition of a largerevaluation contest dealing with NE detection andclassification in Portuguese, HAREM (Santos et al,2008) (for a detailed description of HAREM, in Por-tuguese, see also (Santos and Cardoso, 2007; Motaand Santos, 2008)).
HAREM required systems tochoose among ten categories (see Table 2), 43 typesand 21 subtypes, the later concerning the categoriesTEMPO (time) and LOCAL (place).So, it should be emphasized that ReRelEM fo-cuses only on the classification and detection ofthe relations, not limiting in any way the kinds of(named) entities that can be related (as usualy donein other detection tasks).
It only enforces the kindsof relations that must be identified.2.2 Relation inventoryThe establishment of an inventory of the most rele-vant relations between NEs is ultimately subjective,depending on the kind of information that each par-ticipant aims to extract.
We have nevertheless donean exploratory study and annotated exhaustively afew texts to assess the most frequent and less con-troversial (or easier to assign) relations, and cameup with just the following relation types for the taskproposal:?
identity (ident);?
inclusion (inclui (includes) or incluido(included));?
placement (ocorre-em (occurs-in) orsede-de (place-of));?
other (outra)For further description and examples see section 3.However, during the process of buildingReRelEM?s golden collection (a subset of theHAREM collection used as gold standard), humanannotation was felt to be more reliable ?
and alsomore understandable ?
if one specified what ?other?actually meant, and so a further level of detail(twenty new relations) was selected and marked,see Table 3.
(In any case, since this new refinementdid not belong to the initial task description, allwere mapped back to the coarser outra relationfor evaluation purposes.
)2.3 ReRelEM features and HAREMrequirementsThe annotation process began after the annotationof HAREM?s golden collection, that is, the relationsstarted to be annotated after all NE had been taggedand totally revised.
For ReRelEM, we had thereforeno say in that process ?
again, ReRelEM was onlyconcerned with the relations between the classifiedNEs.
However, our detailed consideration of rela-tions helped to uncover ?
and correct some mistakesin the original classification.In order to explain the task(s) at hand, let us de-scribe shortly ReRelEM?s syntax: In ReRelEM?sgolden collection, each NE has a unique ID.
A re-lation between NE is indicated by the additional at-tributes COREL (filled with the ID of the related en-tity) and TIPOREL (filled with the name of the re-lation) present in the NE that corresponds to one ofthe arguments of the relation.
(Actually, there?s nodifference if the relation is marked in the first or inthe second argument.
)131One referring expression can be associated withone or more NEs through several semantic relations.In such cases, all possible relations must be assignedto the referring expression, in the form of a list, asillustrated by UTAD in Figure 1.In this example, the NE with name UTAD (andid ex1-42) corresponds to an acronym of Univer-sidade de Tra?s-os-Montes e Alto Douro (a univer-sity in Portugal), maintaining with this entity anidentity relation (ident).
The TIPOREL field ofex1-42 contains another relation, inclui, whichstands for the relation of inclusion, this time withthe previously mentioned Servic?os Administrativos(ex1-40), a specific department of the university.In order to minimize human labour and also tolet systems mark relations the way it would bettersuit them, we have postulated from the start that, forall purposes, it would be equivalent to annotate ev-erything or just enough relations so that all otherscan be automatically computed.
So, the evaluationprograms, in an obvious extension of what was pro-posed in (Vilain et al, 1995) for identity,1.
add/expand all relations with their inverses(e.g., ?A includes B?
entails ?B is included inA?
), and2.
apply a set of expansion rules (see examples inTable 4) to compute the closureAs a consequence, different systems may tag thesame text in different ways, but encoding the sameknowledge.2.4 What is a relevant relation?An important difference as to what we expect as rel-evant relations should be pointed out: instead of re-quiring explicit (linguistic) clues, as in traditionalresearch on anaphor, we look for all relations thatmay make sense in the specific context of the wholedocument.
Let us provide two arguments supportingthis decision:?
the first one is philosophical: the borders be-tween world knowledge and contextual infer-ence can be unclear in many cases, so it is noteasy to distinguish them, even if we did believein that separation in the first place;?
the second is practical: marking all possible re-lations is a way to also deal with unpredictableinformational needs, for example for text min-ing applications.
Take a sentence like ?When Ilived in Peru, I attended a horse show and wasable to admire breeds I had known only frompictures before, like Falabella and Paso.?.
Fromthis sentence, few people would infer that Pasois a Peruvian breed, but a horse specialist mightat once see the connection.
The question is:should one identify a relation between Peru andPaso in this document?
We took the affirmativedecision, assuming the existence of users inter-ested in the topic: ?relation of breeds to horseshows: are local breeds predominant?
?.However, and since this was the first time such eval-uation contest was run, we took the following mea-sure: we added the attribute INDEP to the caseswhere the relation was not possible to be inferredby the text.
In this way, it is possible to assessthe frequency of these cases in the texts, and onemay even filter them out before scoring the systemruns to check their weight in the ranking of the sys-tems.
Interestingly, there were very few cases (only6) marked INDEP in the annotated collection.3 Qualitative relation descriptionIdentity (or co-reference) does not need to be ex-plained, although we should insist that this is notidentity of expression, but of meaning.
So the samestring does not necessarily imply identity, cf.
:Os adeptos do Porto invadiram a cidadedo Porto em ju?bilo.4Interestingly, even though organization is only thethird most frequent category, Figure 2 shows that wefound more co-reference among organizations thanamong any other category.As to inclusion (see Figure 3), it was defined be-tween NEs of the same sort, as the folowing ex-amples, respectively illustrating LOCAL, PESSOA,OBRA and ORGANIZACAO, show:Centenas de pessoas recepcionaram noAeroporto da Portela num clima deenorme entusiasmo e euforia, a selecc?a?o4The (FC) Porto fans invaded the (city of) Porto, very happy132<EM ID="ex1-39" CATEG="PESSOA" TIPO="INDIVIDUAL"> Miguel Rodrigues</EM>, chefe dos <EM ID="ex1-40" CATEG="ORGANIZACAO" TIPO="INSTITUICAO"COREL="ex1-39" TIPOREL="outra">Servic?os Administrativos</EM> da <EMID="ex1-41" CATEG="ORGANIZACAO" TIPO="INSTITUICAO" COREL="ex1-40"TIPOREL="inclui"> Universidade de Tra?s-os-Montes e Alto Douro</EM> <EMID="ex1-42" CATEG="ORGANIZACAO" TIPO="INSTITUICAO" COREL="ex1-41 ex1-40"TIPOREL="ident inclui">UTAD</EM>Figure 1: Full example of ReRelEM syntax.Figure 2: Distribution of NE categories for identity.portuguesa de ra?guebi.
A boa prestac?a?oglobal da equipa (...) na?o passou desperce-bida em Portugal.5Lewis Hamilton, colega de Alonso naMcLaren6da assinatura do Tratado de Lisboa (...)de ver reconhecido o valor juridicamentevinculativo da Carta um passo ?essencialno quadro de reforma dos Tratados7por participar na cerimo?nia deproclamac?a?o da Carta dos DireitosFundamentais da UE (...) salientouainda o compromisso assumido pelas tre?sinstituic?o?es - PE85Hundreds of people waited with enthusiasm and eupho-ria at the Portela Airport for the Portuguese national rugbyteam.(...)
The team?s good performance did not go unnoticed inPortugal6Lewis Hamilton, Alonso?s team-mate in McLaren ?
Notethat, in HAREM, teams are considered groups of people, there-fore an individual and a team have the same category PESSOA(person), but differ in the type.7the signing of the Lisbon Treaty (...) juridically vincula-tive value of the Charter, a crucial step for the Treaties reformpolicy8to participate in the proclamation ceremony of the CharterFigure 3: NE categories related by inclusion.Placement is clearly skewed towards placement oforganizations (518 cases) as opposed to occurrenceof events (just 98 instances).
However, if we con-sider the relative distribution of organizations andevents (see Table 2), we can state that, relative totheir places, events have 4.8 relations in average andorganizations 5.0, which is a far more interesting re-sult, not favouring any of the NE classes.Examples of this relation are:GP Brasil ?
Na?o faltou emoc?a?o em Inter-lagos no Circuito Jose?
Carlos Pace9As to the refinement of outra, Table 3 presents therelations found in the material.3.1 Vague categoriesIt is important to stress that the basic tenets ofHAREM had to be followed or reckoned with, notonly the classification grid (see Table 2) but par-ticularly the fact that some named entities are con-sidered to be vague among different categories inof Fundamental Rights of the EU (...) stressed the commitmentassumed by the three institutions - EP9GP Brasil ?
There was no lack of excitement in Interlagosat the Jose?
Carlos Pace Circuit.133Relation / gloss Numbervinculo-inst / inst-commitment 936obra-de / work-of 300participante-em / participant-in 202ter-participacao-de / has-participant 202relacao-familiar / family-tie 90residencia-de / home-of 75natural-de / born-in 47relacao-profissional / professional-tie 46povo-de / people-of 30representante-de / representative-of 19residente-de / living-in 15personagem-de / character-of 12periodo-vida / life-period 11propriedade-de / owned-by 10proprietario-de / owner-of 10representado-por / represented-by 7praticado-em / practised-in 7outra-rel/other 6nome-de-ident / name-of 4outra-edicao / other-edition 2Table 3: Frequency of other relations.HAREM.10This last property, namely that named entitiescould belong to more than one category, posed someproblems, since it was not straightforward whetherdifferent relations would involve all or just some (orone) category.
So, in order to specify clearly therelations between vague NEs, we decided to spec-ify separate relations between facets of vague namedentities.
Cf.
the following example, in which vague-ness is conveyed by a slash:(...) a ideia de uma Europa (LO-CAL/PESSOA) unida.
(...) um dia felizpara as cidada?s e os cidada?os da Unia?oEuropeia (LOCAL).
(...) Somos essen-cialmente uma comunidade de valores ?sa?o estes valores comuns que constituemo fundamento da Unia?o Europeia (AB-STRACCAO/ORG/LOCAL).1110This is different from considering metonymy classes, inthat no classifications are considered more basic than others, see(Santos, 2006) for vagueness as an intrinsic property of naturallanguage.11the idea of a united Europe (...) a happy day for the citizensThe several relations between the three bold-facedNEs have been found to be as follows: The LO-CAL facet of the first NE is identical with the LO-CAL facets of the second and third NEs, while theORG(ANIZACAO) facet of the third NE is locatedin the LOCAL facet of the second and first NEs.
(Two kinds of relations are therefore involved here:ident and inclui.
)4 Evaluation: architecture and measuresOur first concern in this pilot track was to make aclear separation between the evaluation of relationsand the evaluation of NE detection, which was thegoal of HAREM.
So, ReRelEM ?s evaluation uses asa starting point the set of alignments that correspondto a mapping of the NE in the golden collection (GC)to a (candidate) NE in the participation.Evaluation has the following stages:?
Maximization: the sets of relations annotated inboth the GC and in the participation are maxi-mized, applying the rules in Table 4;?
Selection: the alignments where the NE in theGC is different from the corresponding one inthe participation are removed, and so are all re-lations held between removed NEs;?
Normalization: The identifiers of the NE in theparticipation are normalized in order to make itpossible to compare the relations in both sides,given that each system uses its own identifiers.?
Translation: The alignments are translated totriples: arg1 relation arg2, where thearguments consist of the identifiers of theNE together with the facet, for example x67LOCAL sede-de ty45 ORGANIZACAO.?
Filtering: removing relations of types not be-ing evaluated (because HAREM, and thereforeReRelEM, allows for partial participation ?
andevaluation ?
scenarios12).?
Individual evaluation: the triples in the GC arecompared to the triples in the participation.of the European Union (...) We are mainly a community ofvalues and these common values constitute the foundation ofthe European Union.12In other words, it is possible to select a subset of the classi-fication hierarchy.134A ident B ?
B ident C ?
A ident CA inclui B ?
B inclui C ?
A inclui CA inclui B ?
B sede de C ?
A sede de CA ident B ?
B any rel C ?
A any rel CTable 4: Maximization rulesSystem NE task RelationsRembr.
all allSeRelEP only identification all but outraSeiGeo only LOCAL detection inclusionTable 5: Participant systems?
Global evaluation: measures (precision, recalland F-measure) are calculated based on thescore of each triple.Each triple is scored as correct, missing or incor-rect.
We only considered as correct triples (and cor-rect relations) those which linked the correct NEsand whose relation was well classified.
So, a systemdoesn?t score if it correctly matches the NEs to be re-lated, but fails to recognize the kind of relation.
Weassign one point to each correct relation and none toincorrect or missing relations, and then we computeprecision, recall and F-measure.ReRelEM?s golden collection includes 12 textswith 4,417 words and 573 NEs (corresponding to642 different facets).
In all we annotated 6,790 re-lations (1436 identity; 1612 inclusion; 1232 place-ment; 2510 other).5 Participation and resultsFor this first edition, only three systems (totallingnine runs) participated, namely REMBRANDT(Cardoso, 2008), SEI-Geo (Chaves, 2008), andSeRelEP (Bruckschen et al, 2008), whose resultsare found in Figure 4.
However, they did not com-pare well: they selected different NER tasks and dif-ferent relation types, as shown in Table 5.
So, giventhe little and diverse participation in ReRelEM, wecannot do a useful state of the art, but we were def-initely able to provide an interesting and importantresource for empirical studies and for training of fu-ture systems, as well as a set of publicly availableprograms to manipulate, evaluate and display thisFigure 4: ReRelEM results: F-measure, all relationskind of semantic data13.6 Discussion and further workAlthough this was just a pilot, a lot of knowledgeabout the task and the problems to be dealt with weregathered for the future, and important resourceswere offered to the community.We intend to annotate further sections of theHAREM golden collection (as well as other kindsof texts and materials) with more relations in orderto have more quantitative empirical data for studyingthe semantic fabric of Portuguese.Although from an organization point of view itmade sense to couple ReRelEM with HAREM, oneshould reflect over the consequences of inheriting alot of decisions taken in HAREM, somehow goingcounter the intuitive and easier task of just annotat-ing relations in a first round.
However, despite initialfears to the contrary, we found out that the consid-erably fine-grained HAREM grid was in fact benefi-cial to the task of specifying relations: it is, after all,much more informative to have a relation of inclu-sion between a COISA-MEMBROCLASSE (concreteinstance of a class of objects) and a COISA-CLASSE(a class of objects), than just a relation of inclusion13http://www.linguateca.pt/HAREM/135tout court.
In fact, in the next sentence, a kind ofspecialization relation can be uncovered.Astro?nomos brasileiros esperam fotogra-far os primeiros planetas fora do SistemaSolar com a ajuda do maior telesco?piodo mundo, o Gemini (...) os telesco?piosGemini te?m capacidade cient?
?fica...14Likewise, an inclusion relation held betweenPESSOA-GRUPOCARGO (a group of roles performedby people) and PESSOA-INDIVIDUAL (an individ-ual person) , as in the following example, is moreinformative than a simple relation of inclusion be-tween NEs, or even inclusion between PESSOA enti-ties without further discrimination.Po?ttering, So?crates e Barroso assinamCarta dos Direitos Fundamentais da UE.Depois de a Carta ser assinada pelosPresidentes das tre?s instituic?o?es, ouviu-seo hino europeu...15Furthermore, this relation is also different froman inclusion relation held between PESSOA-INDIVIDUAL (an individual) and PESSOA-GRUPOMEMBRO (a group of people):Lobos recebidos em apoteose.
(...) ocapita?o Vasco Uva explicou por que houveuma empatia ta?o grande entre... 16Conversely, the specification of relations betweendifferent NEs in a text may help in detecting and jus-tifying different facets of a particular NE, i.e., mul-tiple semantic categories that should be assigned toit.This illustrates the often observed case that it maybe easier for a human annotator to decide and choosea specific issue than a too general one, and that there-fore categories or choices should be more dependenton ease of human interpretation than quantitativefactors (such as few categories or balanced ones).14Brazilian astronomers expect to take the first pictures ofplanets beyond the solar system with the help of the largesttelescope in the world, Gemini (...) Gemini telescopes havea capacity...15Po?ttering, So?crates e Barroso sign the declaration... Afterbeing signed by the Presidents of the three institutions, ...16Lobos received apoteothically.
(...) Captain Vasco Uvaexplained why ...For future work, we obviously intend to increasethe size of the annotated collection (to the wholeHAREM collection and even beyond), and investi-gate a couple of issues that interest us: which strate-gies are used to avoid repetition of proper namesand establish textual cohesion?
How do relationsbetween noun phrases in general compare with re-lations between entities?We would also like to investigate closer rela-tionships between different relations: for exam-ple, is it more appropriate to also develop a hi-erarchy of relations, reconsidering, for example,affiliation (currently one of the other) as akind of inclusion?In order to understand better what this task isabout, we would also like to investigate whetherthere are interesting correlations between NE cate-gories and relations, as well as text genre and thissort of connectivity.
Even though we only studiedand annotated in depth 12 different texts, it was atonce obvious that they had quite different propertiesas far as the number and kinds of relations was con-cerned.From an evaluation point of view, we would liketo improve our inconsistency detection programsand be able to reason about possible contradictions(of the annotation or of the interpretation) as wellas experiment with different weights and evaluationmeasures, taking into account criteria such as pre-dictability of relationships between NEs.In any case, we believe this was an important firststep to understand a number of issues and to reflectabout what computational systems should be doingto harvest semantic knowledge.
We would like toreceive feedback on whether the task design seemssound to the rest of the community, and whether sys-tems which would perform well in such task couldbe put to good use in real world applications.AcknowledgmentsThis work was done in the scope of the Linguatecaproject, jointly funded by the Portuguese Govern-ment and the European Union (FEDER and FSE)under contract ref.
POSC/339/1.3/C/NAC.136ReferencesEugene Agichtein and Luis Gravano.
2000.
Snowball:Extracting Relations from Large Plain-Text Collec-tions.
In Proc.
of the 5th ACM International Con-ference on Digital Libraries (ACM DL), pages 85?94,San Antonio, Texas, USA, June, 2-7.M?
?rian Bruckschen, Jose?
Guilherme Camargo de Souza,Renata Vieira, and Sandro Rigo.
2008.
SistemaSeRELeP para o reconhecimento de relac?o?es entre en-tidades mencionadas.
In Mota and Santos (Mota andSantos, 2008).Nuno Cardoso.
2008.
REMBRANDT - Reconhecimentode Entidades Mencionadas Baseado em Relac?o?es eANa?lise Detalhada do Texto.
In Mota and Santos(Mota and Santos, 2008).Marc?
?rio Chaves.
2008.
Geo-ontologias e padro?es parareconhecimento de locais e de suas relac?o?es em textos:o SEI-Geo no Segundo HAREM.
In Mota and Santos(Mota and Santos, 2008).Sandra Collovini, Thiago Ianez Carbonel, Ju-liana Thiesen Fuchs, Jorge Ce?sar Coelho, LuciaHelena Machado Rino, and Renata Vieira.
2007.Summ-it: Um corpus anotado com informac?o?esdiscursivas visando a` sumarizac?a?o automa?tica.
InAnais do XXVII Congresso da SBC: V Workshop emTecnologia da Informac?a?o e da Linguagem Humana?
TIL, pages 1605?1614, Rio de Janeiro, RJ, Brazil,junho/julho.Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In Proceedings ofthe 42rd Annual Meeting of the Association for Com-putational Linguistics (ACL?04), pages 423?429.
As-sociation for Computational Linguistics, July.Jose?
Guilherme Camargo de Souza, Patr?
?cia NunesGonc?alves, and Renata Vieira.
2008.
Learning coref-erence resolution for portuguese texts.
In Anto?nioTeixeira, Vera Lu?cia Strube de Lima, Lu?
?s Caldasde Oliveira, and Paulo Quaresma, editors, PROPOR,volume 5190 of Lecture Notes in Computer Science,pages 153?162.
Springer.Georde Doddington, Alexis Mitchell, Mark Przybocki,Lance Ramshaw, Stephanie Strassel, and RalphWeischedel.
2004.
The automatic content extraction(ace) programm.
tasks, data and evaluation.
In Pro-ceedings of the Fourth International Conference onLanguage Resources and Evaluation, pages 837?840,Lisbon, Portugal.Cla?udia Freitas, Diana Santos, Hugo Gonc?alo Oliveira,Paula Carvalho, and Cristina Mota.
2008.
Relac?o?essema?nticas do ReRelEM: ale?m das entidades no Se-gundo HAREM.
In Mota and Santos (Mota and San-tos, 2008).Ruslan Mitkov.
2000.
Towards a more consistent andcomprehensive evaluation of anaphora resolution al-gorithms and systems.
In Proceedings of the Dis-course Anaphora and Anaphora Resolution Collo-quium (DAARC-2000), pages 96?107, Lancaster, UK.Cristina Mota and Diana Santos, editors.
2008.
Desafiosno reconhecimento de entidades mencionadas: O Se-gundo HAREM.
Linguateca.NIST and ACE.
2007.
Automatic Content Extrac-tion 2008 Evaluation Plan (ACE08) ?
Assessment ofDetection and Recognition of Entities and Relationswithin and across Documents.
Technical report, NIST.Constantin Ora?san, Dan Cristea, Ruslan Mitkov, and An-tonio Branco.
2008.
Anaphora resolution exercise:An overview.
In Proceedings of the Sixth InternationalLanguage Resources and Evaluation (LREC?08), Mar-rakech, Morocco, May, 28 - 30.Dan Roth and Wen tau Yih.
2004.
A linear programmingformulation for global inference in natural languagetasks.
In Proceedings of CoNLL-2004, pages 1?8.Diana Santos and Nuno Cardoso, editors.
2007.
Re-conhecimento de entidades mencionadas em por-tugue?s: Documentac?a?o e actas do HAREM, a primeiraavaliac?a?o conjunta na a?rea.
Linguateca, Portugal.Diana Santos, Cla?udia Freitas, Hugo Gonc?alo Oliveira,and Paula Carvalho.
2008.
Second HAREM: newchallenges and old wisdom.
In Anto?nio Teixeira, VeraLu?cia Strube de Lima, Lu?
?s Caldas de Oliveira, andPaulo Quaresma, editors, Computational Processingof the Portuguese Language, 8th International Con-ference, Proceedings (PROPOR 2008), volume LNAI5190, pages 212?215.
Springer Verlag.Diana Santos.
2006.
What is natural language?
Dif-ferences compared to artificial languages, and conse-quences for natural language processing, 15 May.
In-vited lecture, SBLP2006 and PROPOR?2006.Marc Vilain, John Burger, John Aberdeen, Dennis Con-nolly, and Lynette Hirschman.
1995.
A model-theoretic coreference scoring scheme.
In Proceed-ings of the Sixth Message Understanding Conference(MUC-6), pages 45?52.
Morgan Kaufmann.Bonnie Lynn Webber.
1978.
A formal approach to dis-course anaphora.
Outstanding dissertations in linguis-tics.
Garland Publishing, New York, NY, USA.Shubin Zhao and Ralph Grishman.
2005.
Extracting re-lations with integrated information using kernel meth-ods.
In Proceedings of the 43rd Annual Meeting on As-sociation for Computational Linguistics (ACL 2005),pages 419?426, Morristown, NJ, USA.
Association forComputational Linguistics.137
