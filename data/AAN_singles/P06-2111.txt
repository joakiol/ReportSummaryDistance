Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 866?873,Sydney, July 2006. c?2006 Association for Computational LinguisticsFinding Synonyms Using Automatic Word Alignment and Measures ofDistributional SimilarityLonneke van der Plas & Jo?rg TiedemannAlfa-InformaticaUniversity of GroningenP.O.
Box 7169700 AS GroningenThe Netherlands{vdplas,tiedeman}@let.rug.nlAbstractThere have been many proposals to ex-tract semantically related words usingmeasures of distributional similarity, butthese typically are not able to distin-guish between synonyms and other typesof semantically related words such asantonyms, (co)hyponyms and hypernyms.We present a method based on automaticword alignment of parallel corpora con-sisting of documents translated into mul-tiple languages and compare our methodwith a monolingual syntax-based method.The approach that uses aligned multilin-gual data to extract synonyms shows muchhigher precision and recall scores for thetask of synonym extraction than the mono-lingual syntax-based approach.1 IntroductionPeople use multiple ways to express the same idea.These alternative ways of conveying the same in-formation in different ways are referred to by theterm paraphrase and in the case of single wordssharing the same meaning we speak of synonyms.Identification of synonyms is critical for manyNLP tasks.
In information retrieval the informa-tion that people ask for with a set of words may befound in in a text snippet that comprises a com-pletely different set of words.
In this paper wereport on our findings trying to automatically ac-quire synonyms for Dutch using two different re-sources, a large monolingual corpus and a multi-lingual parallel corpus including 11 languages.A common approach to the automatic extrac-tion of semantically related words is to use dis-tributional similarity.
The basic idea behind this isthat similar words share similar contexts.
Systemsbased on distributional similarity provide rankedlists of semantically related words according tothe similarity of their contexts.
Synonyms are ex-pected to be among the highest ranks followed by(co)hyponyms and hypernyms, since the highestdegree of semantic relatedness next to identity issynonymy.However, this is not always the case.
Sev-eral researchers (Curran and Moens (2002), Lin(1998), van der Plas and Bouma (2005)) have usedlarge monolingual corpora to extract distribution-ally similar words.
They use grammatical rela-tions1 to determine the context of a target word.We will refer to such systems as monolingualsyntax-based systems.
These systems have provento be quite successful at finding semantically re-lated words.
However, they do not make a cleardistinction between synonyms on the one hand andrelated words such as antonyms, (co)hyponyms,hypernyms etc.
on the other hand.In this paper we have defined context in a mul-tilingual setting.
In particular, translations of aword into other languages found in parallel cor-pora are seen as the (translational) context of thatword.
We assume that words that share transla-tional contexts are semantically related.
Hence,relatedness of words is measured using distribu-tional similarity in the same way as in the mono-lingual case but with a different type of context.Finding translations in parallel data can be approx-1One can define the context of a word in a non-syntacticmonolingual way, that is as the document in which it occursor the n words surrounding it.
From experiments we havedone and also building on the observations made by otherresearchers (Kilgarriff and Yallop, 2000) we can state thatthis approach generates a type of semantic similarity that isof a looser kind, an associative kind,for example doctor anddisease.
These words are typically not good candidates forsynonymy.866imated by automatic word alignment.
We willrefer to this approach as multilingual alignment-based approaches.
We expect that these transla-tions will give us synonyms and less semanticallyrelated words, because translations typically donot expand to hypernyms, nor (co)hyponyms, norantonyms.
The word apple is typically not trans-lated with a word for fruit nor pear, and neither isgood translated with a word for bad.In this paper we use both monolingual syntax-based approaches and multilingual alignment-based approaches and compare their performancewhen using the same similarity measures and eval-uation set.2 Related WorkMonolingual syntax-based distributional similar-ity is used in many proposals to find semanti-cally related words (Curran and Moens (2002),Lin (1998), van der Plas and Bouma (2005)).Several authors have used a monolingual par-allel corpus to find paraphrases (Ibrahim et al(2003), Barzilay and McKeown (2001)).
How-ever, bilingual parallel corpora have mostly beenused for tasks related to word sense disambigua-tion such as target word selection (Dagan et al,1991) and separation of senses (Dyvik, 1998).
Thelatter work derives relations such as synonymy andhyponymy from the separated senses by applyingthe method of semantic mirrors.Turney (2001) reports on an PMI and IR drivenapproach that acquires data by querying a Websearch engine.
He evaluates on the TOEFL test inwhich the system has to select the synonym among4 candidates.Lin et al (2003) try to tackle the problem ofidentifying synonyms among distributionally re-lated words in two ways: Firstly, by looking atthe overlap in translations of semantically similarwords in multiple bilingual dictionaries.
Secondly,by looking at patterns specifically designed to fil-ter out antonyms.
They evaluate on a set of 80synonyms and 80 antonyms from a thesaurus.Wu and Zhou?s (2003) paper is most closely re-lated to our study.
They report an experiment onsynonym extraction using bilingual resources (anEnglish-Chinese dictionary and corpus) as wellas monolingual resources (an English dictionaryand corpus).
Their monolingual corpus-based ap-proach is very similar to our monolingual corpus-based approach.
The bilingual approach is dif-ferent from ours in several aspects.
Firstly, theydo not take the corpus as the starting point to re-trieve word alignments, they use the bilingual dic-tionary to retrieve multiple translations for eachtarget word.
The corpus is only employed to as-sign probabilities to the translations found in thedictionary.
Secondly, the authors use a parallelcorpus that is bilingual whereas we use a multi-lingual corpus containing 11 languages in total.The authors show that the bilingual method out-performs the monolingual methods.
However acombination of different methods leads to the bestperformance.3 Methodology3.1 Measuring Distributional SimilarityAn increasingly popular method for acquiring se-mantically similar words is to extract distribution-ally similar words from large corpora.
The under-lying assumption of this approach is that seman-tically similar words are used in similar contexts.The contexts a given word is found in, be it a syn-tactic context or an alignment context, are used asthe features in the vector for the given word, theso-called context vector.
The vector contains fre-quency counts for each feature, i.e., the multiplecontexts the word is found in.Context vectors are compared with each otherin order to calculate the distributional similaritybetween words.
Several measures have been pro-posed.
Curran and Moens (2002) report on a large-scale evaluation experiment, where they evaluatedthe performance of various commonly used meth-ods.
Van der Plas and Bouma (2005) present asimilar experiment for Dutch, in which they testedmost of the best performing measures accordingto Curran and Moens (2002).
Pointwise MutualInformation (I) and Dice?
performed best in theirexperiments.
Dice is a well-known combinatorialmeasure that computes the ratio between the sizeof the intersection of two feature sets and the sumof the sizes of the individual feature sets.
Dice?is a measure that incorporates weighted frequencycounts.Dice?
=2?f min(I(W1, f), I(W2, f))?f I(W1, f) + I(W2, f),where f is the featureW1 and W2 are the two words that are being compared,and I is a weight assigned to the frequency counts.8673.2 WeightingWe will now explain why we use weighted fre-quencies and which formula we use for weighting.The information value of a cell in a word vec-tor (which lists how often a word occurred in aspecific context) is not equal for all cells.
Wewill explain this using an example from mono-lingual syntax-based distributional similarity.
Alarge number of nouns can occur as the subject ofthe verb have, for instance, whereas only a fewnouns may occur as the object of squeeze.
Intu-itively, the fact that two nouns both occur as sub-ject of have tells us less about their semantic sim-ilarity than the fact that two nouns both occur asobject of squeeze.
To account for this intuition,the frequency of occurrence in a vector can be re-placed by a weighted score.
The weighted scoreis an indication of the amount of information car-ried by that particular combination of a noun andits feature.We believe that this type of weighting is benefi-cial for calculating similarity between word align-ment vectors as well.
Word alignments that areshared by many different words are most probablymismatches.For this experiment we used Pointwise MutualInformation (I) (Church and Hanks, 1989).I(W,f) = log P (W,f)P (W )P (f),where W is the target wordP(W) is the probability of seeing the wordP(f) is the probability of seeing the featureP(W,f) is the probability of seeing the word and the featuretogether.3.3 Word AlignmentThe multilingual approach we are proposing relieson automatic word alignment of parallel corporafrom Dutch to one or more target languages.
Thisalignment is the basic input for the extraction ofthe alignment context as described in section 5.2.2.The alignment context is then used for measuringdistributional similarity as introduced above.For the word alignment, we apply standard tech-niques derived from statistical machine transla-tion using the well-known IBM alignment mod-els (Brown et al, 1993) implemented in the open-source tool GIZA++ (Och, 2003).
These mod-els can be used to find links between words in asource language and a target language given sen-tence aligned parallel corpora.
We applied stan-dard settings of the GIZA++ system without anyoptimisation for our particular input.
We also usedplain text only, i.e.
we did not apply further pre-processing except tokenisation and sentence split-ting.
Additional linguistic processing such as lem-matisation and multi-word unit detection mighthelp to improve the alignment but this is not partof the present study.The alignment models produced are asymmet-ric and several heuristics exist to combine direc-tional word alignments to improve alignment ac-curacy.
We believe, that precision is more cru-cial than recall in our approach and, therefore, weapply a very strict heuristics namely we computethe intersection of word-to-word links retrieved byGIZA++.
As a result we obtain partially word-aligned parallel corpora from which translationalcontext vectors are built (see section 5.2.2).
Note,that the intersection heuristics allows one-to-oneword links only.
This is reasonable for the Dutchpart as we are only interested in single words andtheir synonyms.
However, the distributional con-text of these words defined by their alignments isstrongly influenced by this heuristics.
Problemscaused by this procedure will be discussed in de-tail in section 7 of our experiments.4 Evaluation FrameworkIn the following, we describe the data used andmeasures applied.The evaluation method that is most suitablefor testing with multiple settings is one that usesan available resource for synonyms as a goldstandard.
In our experiments we apply auto-matic evaluation using an existing hand-craftedsynonym database, Dutch EuroWordnet (EWN,Vossen (1998)).In EWN, one synset consists of several syn-onyms which represent a single sense.
Polyse-mous words occur in several synsets.
We havecombined for each target word the EWN synsetsin which it occurs.
Hence, our gold standard con-sists of a list of all nouns found in EWN and theircorresponding synonyms extracted by taking theunion of all synsets for each word.
Precision isthen calculated as the percentage of candidate syn-onyms that are truly synonyms according to ourgold standard.
Recall is the percentage of the syn-onyms according to EWN that are indeed foundby the system.
We have extracted randomly fromall synsets in EWN 1000 words with a frequency868above 4 for which the systems under comparisonproduce output.The drawback of using such a resource is thatcoverage is often a problem.
Not all words thatour system proposes as synonyms can be found inDutch EWN.
Words that are not found in EWNare discarded.2 .
Moreover, EWN?s synsets are notexhaustive.
After looking at the output of our bestperforming system we were under the impressionthat many correct synonyms selected by our sys-tem were classified as incorrect by EWN.
For thisreason we decided to run a human evaluation overa sample of 100 candidate synonyms classified asincorrect by EWN.5 Experimental SetupIn this section we will describe results from thetwo synonym extraction approaches based on dis-tributional similarity: one using syntactic contextand one using translational context based on wordalignment and the combination of both.
For bothapproaches, we used a cutoff n for each row in ourword-by-context matrix.
A word is discarded ifthe row marginal is less than n. This means thateach word should be found in any context at leastn times else it will be discarded.
We refer to thisby the term minimum row frequency.
The cutoff isused to make the feature space manageable and toreduce noise in the data.
35.1 Distributional Similarity Based onSyntactic RelationsThis section contains the description of the syn-onym extraction approach based on distributionalsimilarity and syntactic relations.
Feature vectorsfor this approach are constructed from syntacti-cally parsed monolingual corpora.
Below we de-scribe the data and resources used, the nature ofthe context applied and the results of the synonymextraction task.5.1.1 Data and ResourcesAs our data we used the Dutch CLEF QA cor-pus, which consists of 78 million words of Dutch2Note that we use the part of EWN that contains onlynouns3We have determined the optimum in F-score for thealignment-based method, the syntax-based method and thecombination independently by using a development set of1000 words that has no overlap with the test set used in eval-uation.
The minimum row frequency was set to 2 for allalignment-based methods.
It was set to 46 for the syntax-based method and the combination of the two methods.subject-verb cat eatverb-object feed catadjective-noun black catcoordination cat dogapposition cat Garfieldprep.
complement go+to workTable 1: Types of dependency relations extractedgrammatical relation # pairssubject 507Kobject 240Kadjective 289Kcoordination 400 Kapposition 109Kprep.
complement 84Ktotal 1629KTable 2: Number of word-syntactic-relation pairs(types) per dependency relation with frequency >1.newspaper text (Algemeen Dagblad and NRCHandelsblad 1994/1995).
The corpus was parsedautomatically using the Alpino parser (van derBeek et al, 2002; Malouf and van Noord, 2004).The result of parsing a sentence is a dependencygraph according to the guidelines of the Corpus ofSpoken Dutch (Moortgat et al, 2000).5.1.2 Syntactic ContextWe have used several grammatical relations:subect, object, adjective, coordination, apposi-tion and prepositional complement.
Examples aregiven in table 1.
Details on the extraction can befound in van der Plas and Bouma (2005).
Thenumber of pairs (types) consisting of a word anda syntactic relation found are given in table 2.
Wehave discarded pairs that occur less than 2 times.5.2 Distributional Similarity Based on WordAlignmentThe alignment approach to synonym extraction isbased on automatic word alignment.
Context vec-tors are built from the alignments found in a paral-lel corpus.
Each aligned word type is a feature inthe vector of the target word under consideration.The alignment frequencies are used for weightingthe features and for applying the frequency cutoff.In the following section we describe the data andresources used in our experiments and finally theresults of this approach.8695.2.1 Data and ResourcesMeasures of distributional similarity usually re-quire large amounts of data.
For the alignmentmethod we need a parallel corpus of reasonablesize with Dutch either as source or as target lan-guage.
Furthermore, we would like to experimentwith various languages aligned to Dutch.
Thefreely available Europarl corpus (Koehn, 2003)includes 11 languages in parallel, it is sentencealigned, and it is of reasonable size.
Thus, foracquiring Dutch synonyms we have 10 languagepairs with Dutch as the source language.
TheDutch part includes about 29 million tokens inabout 1.2 million sentences.
The entire corpus issentence aligned (Tiedemann and Nygaard, 2004)which is a requirement for the automatic wordalignment described below.5.2.2 Alignment ContextContext vectors are populated with the links towords in other languages extracted from automaticword alignment.
We applied GIZA++ and the in-tersection heuristics as explained in section .
Fromthe word aligned corpora we extracted word typelinks, pairs of source and target words with theiralignment frequency attached.
Each aligned targetword type is a feature in the (translational) contextof the source word under consideration.Note that we rely entirely on automatic process-ing of our data.
Thus, results from the automaticword alignments include errors and their precisionand recall is very different for the various languagepairs.
However, we did not assess the quality ofthe alignment itself which would be beyond thescope of this paper.As mentioned earlier, we did not include anylinguistic pre-processing prior to the word align-ment.
However, we post-processed the alignmentresults in various ways.
We applied a simple lem-matizer to the list of bilingual word type linksin order to 1) reduce data sparseness, and 2) tofacilitate our evaluation based on comparing ourresults to existing synonym databases.
For thiswe used two resources: CELEX ?
a linguisticallyannotated dictionary of English, Dutch and Ger-man (Baayen et al, 1993), and the Dutch snow-ball stemmer implementing a suffix stripping al-gorithm based on the Porter stemmer.
Note thatlemmatization is only done for Dutch.
Further-more, we removed word type links that includenon-alphabetic characters to focus our investiga-tions on ?real words?.
In order to reduce alignmentnoise, we also applied a frequency threshold to re-move alignments that occur only once.
Finally, werestricted our study to Dutch nouns.
Hence, weextracted word type links for all words tagged asnoun in CELEX.
We also included words whichare not found at all in CELEX assuming that mostof them will be productive noun constructions.From the remaining word type links we popu-lated the context vectors as described earlier.
Ta-ble 3 shows the number of context elements ex-tracted in this manner for each language pair con-sidered from the Europarl corpus4#word-transl.
pairs #word-transl.
pairsDA 104K FR 90KDE 133K IT 96KEL 60K PT 86KEN 119K SV 97KES 119K ALL 994KFI 89KTable 3: Number of word-translation pairs for dif-ferent languages with alignment frequency > 16 Results and DiscussionTable 4 shows the precision recall en F-score forthe different methods.
The first 10 rows referto the results for all language pairs individually.The 11th row corresponds to the setting in whichall alignments for all languages are combined.The penultimate row shows results for the syntax-based method and the last row the combination ofthe syntax-based and alignment-based method.Judging from the precision, recall and F-scorein table 4 Swedish is the best performing lan-guage for Dutch synonym extraction from parallelcorpora.
It seems that languages that are similarto the target language, for example in word or-der, are good candidates for finding synonyms athigh precision rates.
Also the fact that Dutch andSwedish both have one-word compounds avoidsmistakes that are often found with the other lan-guages.
However, judging from recall (and F-score) French is not a bad candidate either.
It ispossible that languages that are lexically differentfrom the target language provide more synonyms.The fact that Finnish and Greek do not gain highscores might be due to the fact that there are onlya limited amount of translational contexts (with afrequency > 1) available for these language (asis shown in table 3).
The reasons are twofold.4abbreviations taken from the ISO-639 2-letter codes870# candidate synonyms1 2 3Prec Rec F-sc Prec Rec F-sc Prec Rec F-scDA 19.8 5.1 8.1 15.5 7.6 10.2 13.3 9.4 11.0DE 21.2 5.4 8.6 16.1 7.9 10.6 13.1 9.3 10.9EL 18.2 4.5 7.2 14.0 6.5 8.9 11.8 7.9 9.4EN 19.5 5.3 8.3 14.7 7.8 10.2 12.4 9.7 10.9ES 18.4 5.0 7.9 14.7 7.8 10.2 12.1 9.4 10.6FI 18.0 3.9 6.5 14.3 5.6 8.1 12.1 6.5 8.5FR 20.3 5.5 8.7 15.8 8.3 10.9 13.0 10.1 11.4IT 18.7 4.9 7.8 14.7 7.5 9.9 12.3 9.2 10.5PT 17.7 4.8 7.6 14.0 7.4 9.7 11.6 8.9 10.1SV 22.3 5.6 9.0 16.4 7.9 10.7 13.3 9.3 10.9ALL 22.5 6.4 10.0 16.6 9.4 12.0 13.7 11.5 12.5SYN 8.8 2.5 3.9 6.9 4.0 5.09 5.9 5.1 5.5COMBI 19.9 5.8 8.9 14.5 8.4 10.6 11.7 10.1 10.9Table 4: Precision, recall and F-score (%) at increasing number of candidate synonymsFirstly, for Greek and Finnish the Europarl corpuscontains less data.
Secondly, the fact that Finnishis a language that has a lot of cases for nouns,might lead to data sparseness and worse accuracyin word alignment.The results in table 4 also show the difference inperformance between the multilingual alignment-method and the syntax-based method.
The mono-lingual alignment-based method outperforms thesyntax-based method by far.
The syntax-basedmethod that does not rely on scarce multilingualresources is more portable and also in this exper-iment it makes use of more data.
However, thelow precision scores of this method are not con-vincing.
Combining both methods does not resultin better performance for finding synonyms.
Thisis in contrast with the results reported by Wu andZhou (2003).
This might well be due to the moresophisticated method they use for combining dif-ferent methods, which is a weighted combination.The precision scores are in line with the scoresreported by Wu and Zhou (2003) in a similar ex-periment discussed under related work.
The re-call we attain however is more than three timeshigher.
These differences can be due to differencesbetween their approach such as starting from abilingual dictionary for acquiring the translationalcontext versus using automatic word alignmentsfrom a large multilingual corpus directly.
Further-more, the different evaluation methods used makecomparison between the two approaches difficult.They use a combination of the English Word-Net (Fellbaum, 1998) and Roget thesaurus (Ro-get, 1911) as a gold standard in their evaluations.It is obvious that a combination of these resourcesleads to larger sets of synonyms.
This could ex-plain the relatively low recall scores.
It does how-ever not explain the similar precision scores.We conducted a human evaluation on a sampleof 100 candidate synonyms proposed by our bestperforming system that were classified as incor-rect by EWN.
Ten evaluators (authors excluded)were asked to classify the pairs of words as syn-onyms or non-synonyms using a web form of theformat yes/no/don?t know.
For 10 out of the 100pairs all ten evaluators agreed that these were syn-onyms.
For 37 of the 100 pairs more than half ofthe evaluators agreed that these were synonyms.We can conclude from this that the scores providedin our evaluations based on EWN (table 4) are toopessimistic.
We believe that the actual precisionscores lie 10 to 37 % higher than the 22.5 % re-ported in table 4.
Over and above, this indicatesthat we are able to extract automatically synonymsthat are not yet covered by available resources.7 Error AnalysisIn table 5 some example output is given for themethod combining word alignments of all 10 for-eign languages as opposed to the monolingualsyntax-based method.
These examples illustratethe general patterns that we discovered by lookinginto the results for the different methods.The first two examples show that the syntax-871ALIGN(ALL) SYNTAXconsensus eensgezindheid evenwichtconsensus consensus equilibriumherfst najaar winterautumn autumn wintereind einde beginend end beginningarmoede armoedebestrijding werkloosheidpoverty poverty reduction unemploymentalcohol alcoholgebruik drankalcohol alcohol consumption liquorbes charme perzikberry charm peachdefinitie definie criteriumdefinition define+incor.stemm.
criterionverlamming lam verstoringparalysis paralysed disturbanceTable 5: Example candidate synonyms at 1st rankand their translations in italicsbased method often finds semantically relatedwords whereas the alignment-based method findssynonyms.
The reasons for this are quite obvious.Synonyms are likely to receive identical transla-tions, words that are only semantically related arenot.
A translator would not often translate auto(car) with vrachtwagen (truck).
However, the twowords are likely to show up in identical syntacticrelations, such as being the object of drive or ap-pearing in coordination with motorcycle.Another observation that we made is that thesyntax-based method often finds antonyms such asbegin (beginning) for the word einde (end).
Expla-nations for this are in line with what we said aboutthe semantically related words: Synonyms arelikely to receive identical translations, antonymsare not but they do appear in similar syntactic con-texts.Compounds pose a problem for the alignment-method.
We have chosen intersection as align-ment method.
It is well-known that this methodcannot cope very well with the alignment of com-pounds because it only allows one-to-one wordlinks.
Dutch uses many one-word compounds thatshould be linked to multi-word counterparts inother languages.
However, using intersection weobtain only partially correct alignments and thiscauses many mistakes in the distributional simi-larity algorithm.
We have given some examples inrows 4 and 5 of table 5.We have used the distributional similarity scoreonly for ranking the candidate synonyms.
In somecases it seems that we should have used it to set athreshold such as in the case of berry and charm.These two words share one translational context :the article el in Spanish.
The distributional sim-ilarity score in such cases is often very low.
Wecould have filtered some of these mistakes by set-ting a threshold.One last observation is that the alignment-basedmethod suffers from incorrect stemming and thelack of sufficient part-of-speech information.
Wehave removed all context vectors that were builtfor a word that was registered in CELEX with aPoS-tag different from ?noun?.
But some wordsare not found in CELEX and although they arenot of the word type ?noun?
their context vec-tors remain in our data.
They are stemmed usingthe snowball stemmer.
The candidate synonymdenie is a corrupted verbform that is not foundin CELEX.
Lam is ambiguous between the nounreading that can be translated in English with lamband the adjective lam which can be translated withparalysed.
This adjective is related to the wordverlamming (paralysis), but would have been re-moved if the word was correctly PoS-tagged.8 ConclusionsParallel corpora are mostly used for tasks relatedto WSD.
This paper shows that multilingual wordalignments can be applied to acquire synonymsautomatically without the need for resources suchas bilingual dictionaries.
A comparison with amonolingual syntax-based method shows that thealignment-based method is able to extract syn-onyms with much greater precision and recall.
Ahuman evaluation shows that the synonyms thealignment-based method finds are often missing inEWN.
This leads us to believe that the precisionscores attained by using EWN as a gold standardare too pessimistic.
Furthermore it is good newsthat we seem to be able to find synonyms that arenot yet covered by existing resources.The precision scores are still not satisfactoryand we see plenty of future directions.
We wouldlike to use linguistic processing such as PoS-tagging for word alignment to increase the accu-racy of the alignment itself, to deal with com-pounds more effectively and to be able to filterout proposed synonyms that are of a different wordclass than the target word.
Furthermore we wouldlike to make use of the distributional similarityscore to set a threshold that will remove a lot oferrors.
The last thing that remains for future workis to find a more adequate way to combine the872syntax-based and the alignment-based methods.AcknowledgementsThis research was carried out in the projectQuestion Answering using Dependency Relations,which is part of the research program for Inter-act ive Multimedia Information Extraction, IMIX,financed by NWO, the Dutch Organisation for Sci-entific Research.ReferencesR.H.
Baayen, R. Piepenbrock, and H. van Rijn.
1993.The CELEX lexical database (CD-ROM).
Lin-guistic Data Consortium, University of Pennsylva-nia,Philadelphia.Regina Barzilay and Kathleen McKeown.
2001.
Ex-tracting paraphrases from a parallel corpus.
In Meet-ing of the Association for Computational Linguis-tics, pages 50?57.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
Themathematics of statistical machine translation: Pa-rameter estimation.
Computational Linguistics,19(2):263?296.K.W.
Church and P. Hanks.
1989.
Word associationnorms, mutual information and lexicography.
Pro-ceedings of the 27th annual conference of the Asso-ciation of Computational Linguistics, pages 76?82.J.R.
Curran and M. Moens.
2002.
Improvements inautomatic thesaurus extraction.
In Proceedings ofthe Workshop on Unsupervised Lexical Acquisition,pages 59?67.Ido Dagan, Alon Itai, and Ulrike Schwall.
1991.
Twolanguages are more informative than one.
In Meet-ing of the Association for Computational Linguis-tics, pages 130?137.Helge Dyvik.
1998.
Translations as semantic mirrors.In Proceedings of Workshop Multilinguality in theLexicon II, ECAI 98, Brighton, UK, pages 24?44.C.
Fellbaum.
1998.
Wordnet, an electronic lexicaldatabase.
MIT Press.A.
Ibrahim, B. Katz, and J. Lin.
2003.
Extract-ing structural paraphrases from aligned monolingualcorpora.A.
Kilgarriff and C. Yallop.
2000.
What?s in a the-saurus?
In Proceedings of the Second Conferenceon Language Resource an Evaluation, pages 1371?1379.Philipp Koehn.
2003.
Europarl: A multilin-gual corpus for evaluation of machine trans-lation.
unpublished draft, available fromhttp://people.csail.mit.edu/koehn/publications/europarl/.Dekang Lin, Shaojun Zhao, Lijuan Qin, and MingZhou.
2003.
Identifying synonyms among distribu-tionally similar words.
In IJCAI, pages 1492?1493.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
In COLING-ACL, pages 768?774.Robert Malouf and Gertjan van Noord.
2004.
Widecoverage parsing with stochastic attribute valuegrammars.
In IJCNLP-04 Workshop Beyond Shal-low Analyses - Formalisms and stati stical modelingfor deep analyses, Hainan.Michael Moortgat, Ineke Schuurman, and Ton van derWouden.
2000.
CGN syntactische annotatie.
In-ternal Project Report Corpus Gesproken Nederlands,see http://lands.
let.kun.nl/cgn.Franz Josef Och.
2003.
GIZA++: Training ofstatistical translation models.
Available fromhttp://www.isi.edu/?och/GIZA++.html.P.
Roget.
1911.
Thesaurus of English words andphrases.Jo?rg Tiedemann and Lars Nygaard.
2004.
The OPUScorpus - parallel & free.
In Proceedings of theFourth International Conference on Language Re-sources and Evaluation (LREC?04), Lisbon, Portu-gal.Peter D. Turney.
2001.
Mining the Web for synonyms:PMI?IR versus LSA on TOEFL.
Lecture Notes inComputer Science, 2167:491?502.Leonoor van der Beek, Gosse Bouma, and Gertjan vanNoord.
2002.
Een brede computationele grammat-ica voor het Nederlands.
Nederlandse Taalkunde,7(4):353?374.Lonneke van der Plas and Gosse Bouma.
2005.Syntactic contexts for finding semantically similarwords.
Proceedings of the Meeting of Computa-tional Linguistics in the Netherlands (CLIN).P.
Vossen.
1998.
Eurowordnet a multilingual databasewith lexical semantic networks.Hua Wu and Ming Zhou.
2003.
Optimizing syn-onym extraction using monolingual and bilingual re-sources.
In Proceedings of the Second InternationalWorkshop on Paraphrasing: Paraphrase Acquisitionand Applications (IWP2003), Sapporo, Japan.873
