Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 412?419,Sydney, July 2006. c?2006 Association for Computational LinguisticsExploiting Non-local Features for Spoken Language UnderstandingMinwoo Jeong and Gary Geunbae LeeDepartment of Computer Science & EngineeringPohang University of Science and Technology,San 31 Hyoja-dong, Nam-guPohang 790-784, Korea{stardust,gblee}@postech.ac.krAbstractIn this paper, we exploit non-local fea-tures as an estimate of long-distance de-pendencies to improve performance on thestatistical spoken language understanding(SLU) problem.
The statistical naturallanguage parsers trained on text performunreliably to encode non-local informa-tion on spoken language.
An alternativemethod we propose is to use trigger pairsthat are automatically extracted by a fea-ture induction algorithm.
We describe alight version of the inducer in which a sim-ple modification is efficient and success-ful.
We evaluate our method on an SLUtask and show an error reduction of up to27% over the base local model.1 IntroductionFor most sequential labeling problems in naturallanguage processing (NLP), a decision is madebased on local information.
However, processingthat relies on the Markovian assumption cannotrepresent higher-order dependencies.
This long-distance dependency problem has been consideredat length in computational linguistics.
It is the keylimitation in bettering sequential models in vari-ous natural language tasks.
Thus, we need newmethods to import non-local information into se-quential models.There are two types of method for using non-local information.
One is to add edges to structureto allow higher-order dependencies and another isto add features (or observable variables) to encodethe non-locality.
An additional consistent edge ofa linear-chain conditional random field (CRF) ex-plicitly models the dependencies between distantoccurrences of similar words (Sutton and McCal-lum, 2004; Finkel et al, 2005).
However, thisapproach requires additional time complexity ininference/learning time and it is only suitable forrepresenting constraints by enforcing label consis-tency.
We wish to identify ambiguous labels withmore general dependency without additional timecost in inference/learning time.Another approach to modeling non-locality isto use observational features which can capturenon-local information.
Traditionally, many sys-tems prefer to use a syntactic parser.
In a languageunderstanding task, the head word dependenciesor parse tree path are successfully applied to learnand predict semantic roles, especially those withambiguous labels (Gildea and Jurafsky, 2002).
Al-though the power of syntactic structure is impres-sive, using the parser-based feature fails to encodecorrect global information because of the low ac-curacy of a modern parser.
Furthermore the inac-curate result of parsing is more serious in a spokenlanguage understanding (SLU) task.
In contrastto written language, spoken language loses muchinformation including grammar, structure or mor-phology and contains some errors in automaticallyrecognized speech.To solve the above problems, we present onemethod to exploit non-local information ?
the trig-ger feature.
In this paper, we incorporate trig-ger pairs into a sequential model, a linear-chainCRF.
Then we describe an efficient algorithm toextract the trigger feature from the training data it-self.
The framework for inducing trigger featuresis based on the Kullback-Leibler divergence cri-terion which measures the improvement of log-likelihood on the current parameters by adding anew feature (Pietra et al, 1997).
To reduce thecost of feature selection, we suggest a modified412version of an inducing algorithm which is quite ef-ficient.
We evaluate our method on an SLU task,and demonstrate the improvements on both tran-scripts and recognition outputs.
On a real-worldproblem, our modified version of a feature selec-tion algorithm is very efficient for both perfor-mance and time complexity.2 Spoken Language Understanding as aSequential Labeling Problem2.1 Spoken Language UnderstandingThe goal of SLU is to extract semantic mean-ings from recognized utterances and to fill thecorrect values into a semantic frame structure.A semantic frame (or template) is a well-formedand machine readable structure of extracted in-formation consisting of slot/value pairs.
An ex-ample of such a reference frame is as follows.<s> i wanna go from denver to new york onnovember eighteenth </s>FROMLOC.CITY NAME = denverTOLOC.CITY NAME = new yorkMONTH NAME = novemberDAY NUMBER = eighteenthThis example from air travel data (CU-Communicator corpus) was automatically gener-ated by a Phoenix parser and manually corrected(Pellom et al, 2000; He and Young, 2005).
In thisexample, the slot labels are two-level hierarchi-cal; such as FROMLOC.CITY NAME.
This hier-archy differentiates the semantic frame extractionproblem from the named entity recognition (NER)problem.Regardless of the fact that there are somedifferences between SLU and NER, we canstill apply well-known techniques used in NERto an SLU problem.
Following (Ramshawand Marcus, 1995), the slot labels are drawnfrom a set of classes constructed by extendingeach label by three additional symbols, Begin-ning/Inside/Outside (B/I/O).
A two-level hierar-chical slot can be considered as an integrated flat-tened slot.
For example, FROMLOC.CITY NAMEand TOLOC.CITY NAME are different on this slotdefinition scheme.Now, we can formalize the SLU prob-lem as a sequential labeling problem, y?
=argmaxy P (y|x).
In this case, input word se-quences x are not only lexical strings, but alsomultiple linguistic features.
To extract semanticframes from utterance inputs, we use a linear-chain CRF model; a model that assigns a jointprobability distribution over labels which is con-ditional on the input sequences, where the distri-bution respects the independent relations encodedin a graph (Lafferty et al, 2001).A linear-chain CRF is defined as follows.
LetG be an undirected model over sets of randomvariables x and y.
The graph G with parameters?
= {?, .
.
.}
defines a conditional probability fora state (or label) sequence y = y1, .
.
.
, yT , givenan input x = x1, .
.
.
, xT , to beP?
(y|x) = 1Zx exp( T?t=1?k?kfk(yt?1, yt,x, t))where Zx is the normalization factor that makesthe probability of all state sequences sum to one.fk(yt?1, yt,x, t) is an arbitrary linguistic featurefunction which is often binary-valued in NLPtasks.
?k is a trained parameter associated withfeature fk.
The feature functions can encode anyaspect of a state transition, yt?1 ?
yt, and theobservation (a set of observable features), x, cen-tered at the current time, t. Large positive val-ues for ?k indicate a preference for such an event,while large negative values make the event un-likely.Parameter estimation of a linear-chain CRF istypically performed by conditional maximum log-likelihood.
To avoid overfitting, the 2-norm reg-ularization is applied to penalize on weight vec-tor whose norm is too large.
We used a limitedmemory version of the quasi-Newton method (L-BFGS) to optimize this objective function.
TheL-BFGS method converges super-linearly to thesolution, so it can be an efficient optimizationtechnique on large-scale NLP problems (Sha andPereira, 2003).A linear-chain CRF has been previously appliedto obtain promising results in various natural lan-guage tasks, but the linear-chain structure is defi-cient in modeling long-distance dependencies be-cause of its limited structure (n-th order Markovchains).2.2 Long-distance Dependency in SpokenLanguage UnderstandingIn most sequential supervised learning prob-lems including SLU, the feature functionfk(yt?1, yt,xt, t) indicates only local information413for practical reasons.
With sufficient local context(e.g.
a sliding window of width 5), inference andlearning are both efficient.However, if we only use local features, thenwe cannot model long-distance dependencies.Thus, we should incorporate non-local infor-mation into the model.
For example, figure1 shows the long-distance dependency problemin an SLU task.
The same two word to-kens ?dec.?
should be classified differently,DEPART.MONTH and RETURN.MONTH.
Thedotted line boxes represent local information at thecurrent decision point (?dec.?
), but they are ex-actly the same in two distinct examples.
More-over, the two states share the same previoussequence (O, O, FROMLOC.CITY NAME-B,O, TOLOC.CITY NAME-B, O).
If we cannotobtain higher-order dependencies such as ?fly?and ?return,?
then the linear-chain CRF cannotclassify the correct labels between the two sametokens.
To solve this problem, we propose an ap-proach to exploit non-local information in the nextsection.3 Incorporating Non-local Information3.1 Using Trigger FeaturesTo exploit non-local information to sequential la-beling for a statistical SLU, we can use two ap-proaches; a syntactic parser-based and a data-driven approach.
Traditionally, information ex-traction and language understanding fields haveusually used a syntactic parser to encode globalinformation (e.g.
parse tree path, governing cat-egory, or head word) over a local model.
In a se-mantic role labeling task, the syntax and semanticsare correlated with each other (Gildea and Juraf-sky, 2002), that is, the global structure of the sen-tence is useful for identifying ambiguous semanticroles.
However the problem is the poor accuracyof the syntactic parser with this type of feature.
Inaddition, recognized utterances are erroneous andthe spoken language has no capital letters, no ad-ditional symbols, and sometimes no grammar, soit is difficult to use a parser in an SLU problem.Another solution is a data-driven method, whichuses statistics to find features that are approxi-mately modeling long-distance dependencies.
Thesimplest way is to use identical words in history orlexical co-occurrence, but we wish to use a moregeneral tool; triggering.
The trigger word pairsare introduced by (Rosenfeld, 1994).
A triggerpair is the basic element for extracting informa-tion from the long-distance document history.
Inlanguage modeling, n-gram based on the Marko-vian assumption cannot represent higher-order de-pendencies, but it can automatically extract triggerword pairs from data.
The pair (A ?
B) meansthat word A and B are significantly correlated, thatis, when A occurs in the document, it triggers B,causing its probability estimate to change.To select reasonable pairs from arbitrary wordpairs, (Rosenfeld, 1994) used averaged mutual in-formation (MI).
In this scheme, the MI score ofone pair is MI(A;B) =P (A,B) log P (B|A)P (B) + P (A, B?)
logP (B?|A)P (B?)
+P (A?, B) log P (B|A?
)P (B?)
+ P (A?, B?)
logP (B?|A?
)P (B?)
.Using the MI criterion, we can select corre-lated word pairs.
For example, the trigger pair(dec.?return) was extracted with score 0.001179in the training data1.
This trigger word pair canrepresent long-distance dependency and provide acue to identify ambiguous classes.
The MI ap-proach, however, considers only lexical colloca-tion without reference labels y, and MI based se-lection tends to excessively select the irrelevanttriggers.
Recall that our goal is to find the signif-icantly correlated trigger pairs which improve themodel.
Therefore, we use a more appropriate se-lection method for sequential supervised learning.3.2 Selecting Trigger FeatureWe present another approach to extract relevanttriggers and exploit them in a linear-chain CRF.Our approach is based on an automatic feature in-duction algorithm, which is a novel method to se-lect a feature in an exponential model (Pietra et al,1997; McCallum, 2003).
We follow McCallum?swork which is an efficient method to induce fea-tures in a linear-chain CRF model.
Following theframework of feature inducing, we start the algo-rithm with an empty set, and iteratively increasethe bundle of features including local features andtrigger features.
Our basic assumption, however,is that the local information should be includedbecause the local features are the basis of the de-cision to identify the classes, and they reduce the1In our experiment, the pair (dec.?fly) cannot be selectedbecause this MI score is too low.
However, the trigger pair isa binary type feature, so the pair (dec.?return) is enough toclassify the two cases in the previous example.4141999dec.onchicagotodenverfromfly... 10th1999dec.onchicagotodenverfrom... 10threturn ......DEPART.MONTHRETURN.MONTHFigure 1: An example of a long-distance dependency problem in spoken language understanding.
Inthis case, a word token ?dec.?
with local feature set (dotted line box) is ambiguous for determining thecorrect label (DEPART.MONTH or RETURN.MONTH).mismatch between training and testing tasks.
Fur-thermore, this assumption leads us to faster train-ing in the inducing procedure because we can onlyconsider additional trigger features.Now, we start the inducing process with localfeatures rather than an empty set.
After trainingthe base model ?
(0), we should calculate the gains,which measure the effect of adding a trigger fea-ture, based on the local model parameter ?(0).
Thegain of the trigger feature is defined as the im-provement in log-likelihood of the current model?
(i) at the i-th iteration according to the followingformula:G??
(i)(g) = max?
G?
(i)(g, ?
)= max?{L?(i)+g,?
?
L?
(i)}where ?
is a parameter of a trigger feature tobe found and g is a corresponding trigger featurefunction.
The optimal value of ?
can be calculatedby Newton?s method.By adding a new candidate trigger, the equationof the linear-chain CRF model is changed to anadditional feature model as P?(i)+g,?
(y|x) =P?
(i)(y|x) exp(?Tt=1 ?g(yt?1, yt,x, t))Zx(?
(i), g, ?
).Note that Zx(?
(i), g, ?)
is the marginal sum overall states of y?.
Following (Pietra et al, 1997; Mc-Callum, 2003), the mean field approximation andagglomerated features allows us to treat the abovecalculation as the independent inference problemrather than sequential inference.
We can evaluatethe probability of state y with an adding triggerpair given observation x separately as follows.P?(i)+g,?
(y|x, t) =P?
(i)(y|x, t) exp (?g(yt,x, t))Zx(?
(i), g, ?
)Here, we introduce a second approximation.
Weuse the individual inference problem over the un-structured maximum entropy (ME) model whosestate variable is independent from other states inhistory.
The background of our approximation isthat the state independent problem of CRF canbe relaxed to ME inference problem without thestate-structured model.
In the result, we calculatethe gain of candidate triggers, and select triggerfeatures over a light ME model instead of a hugecomputational CRF model2.We can efficiently assess many candidate trig-ger features in parallel by assuming that the oldfeatures remain fixed while estimating the gain.The gain of trigger features can be calculated onthe old model that is trained with the local andadded trigger pairs in previous iterations.
Ratherthan summing over all training instances, we onlyneed to use the mislabeled N tokens by the cur-rent parameter ?
(i) (McCallum, 2003).
From mis-classified instances, we generate the candidates oftrigger pairs, that is, all pairs of current words andothers within the sentence.
With the candidate fea-ture set, the gain isG??
(i)(g) = N??E?
[g]?N?j=1log (E?
(i) [exp(?
?g)|xj ])??
?22?2 .Using the estimated gains, we can select a smallportion of all candidates, and retrain the modelwith selected features.
We iteratively perform theselection algorithm with some stop conditions (ex-cess of maximum iteration or no added feature upto the gain threshold).
The outline of the induction2The ME model cannot represent the sequential structureand the resulting model is different from CRF.
Nevertheless,we empirically prove that the effect of additional trigger fea-tures on both ME and approximated CRF (without regardingedge-state) are similar (see the experiment section).415Algorithm InduceLearn(x,y)triggers ?
{?}
and i ?
0while |pairs| > 0 and i < maxiter do?
(i) ?
TrainME(x,y)P (ye|xe) ?
Evaluate(x,y,?
(i))c ?
MakeCandidate(xe)G?
(i) ?
EstimateGain(c, P (ye|xe))pairs ?
SelectTrigger(c, G?
(i))x ?
UpdateObs(x, pairs)triggers ?
triggers ?
pairs and i ?
i+ 1end while?
(i+1) ?
TrainCRF(x,y)return ?
(i+1)Figure 2: Outline of trigger feature induction al-gorithmalgorithms is described in figure 2.
In the next sec-tion, we empirically prove the effectiveness of ouralgorithm.The trigger pairs introduced by (Rosenfeld,1994) are just word pairs.
Here, we can gen-eralize the trigger pairs to any arbitrary pairs offeatures.
For example, the feature pair (of?B-PP) is useful in deciding the correct answerPERIOD OF DAY-I in ?in the middle of the day.
?Without constraints on generating the pairs (e.g.at most 3 distant tokens), the candidates can bearbitrary conjunctions of features3.
Therefore wecan explore any features including local conjunc-tion or non-local singleton features in a uniformframework.4 Experiments4.1 Experimental SetupWe evaluate our method on the CU-Communicatorcorpus.
It consists of 13,983 utterances.
The se-mantic categories correspond to city names, time-related information, airlines and other miscella-neous entities.
The semantic labels are automat-ically generated by a Phoenix parser and manuallycorrected.
In the data set, the semantic categoryhas a two-level hierarchy: 31 first level classesand 7 second level classes, for a total of 62 classcombinations.
The data set is 630k words with29k entities.
Roughly half of the entities are time-related information, a quarter of the entities are3In our experiment, we do not consider the local conjunc-tions because we wish to capture the effect of long-distanceentities.city names, a tenth are state and country names,and a fifth are airline and airport names.
Forthe second level hierarchy, approximately threequarters of the entities are ?NONE?, a tenth are?TOLOC?, a tenth are ?FROMLOC?, and the re-maining are ?RETURN?, ?DEPERT?, ?ARRIVE?,and ?STOPLOC.
?For spoken inputs, we used the open sourcespeech recognizer Sphinx2.
We trained the recog-nizer with only the domain-specific speech corpus.The reported accuracy for Sphinx2 speech recog-nition is about 85%, but the accuracy of our speechrecognizer is 76.27%; we used only a subset of thedata without tuning and the sentences of this sub-set are longer and more complex than those of theremoved ones, most of which are single-word re-sponses.All of our results have averaged over 5-foldcross validation with an 80/20 split of the data.As it is standard, we compute precision and re-call, which are evaluated on a per-entity basis andcombined into a micro-averaged F1 score (F1 =2PR/(P+R)).A final model (a first-order linear chain CRF)is trained for 100 iterations with a Gaussian priorvariance of 20, and 200 or fewer trigger features(down to a gain threshold of 1.0) for each round ofinducing iteration (100 iterations of L-BFGS forthe ME inducer and 10?20 iterations of L-BFGSfor the CRF inducer).
All experiments are imple-mented in C++ and executed on Linux with XEON2.8 GHz dual processors and 2.0 Gbyte of mainmemory.4.2 Empirical ResultsWe list the feature templates used by our experi-ment in figure 3.
For local features, we use theindicators for specific words at location i, or lo-cations within five words of i (?2,?1, 0,+1,+2words on current position i).
We also use the part-of-speech (POS) tags and phrase labels with par-tial parsing.
Like words, the two basic linguis-tic features are located within five tokens.
Forcomparison, we exploit the two groups of non-local syntax parser-based features; we use Collinsparser and extract this type of features from theparse trees.
The first consists of the head wordand POS-tag of the head word.
The second groupincludes governing category and parse tree pathsintroduced by semantic role labeling (Gildea andJurafsky, 2002).
Following the previous studies416Local feature templates-lexical words-part-of-speech (POS) tags-phrase chunk labelsGrammar-based feature templates-head word / POS-tag-parse tree path and governing categoryTrigger feature templates-word pairs (wi ?
wj), |i?
j| > 2-feature pairs between words, POS-tags, andchunk labels (fi ?
fj), |i?
j| > 2-null pairs (?
?
wj)Figure 3: Feature templatesof semantic role labeling, the parse tree path im-proves the classification performance of semanticrole labeling.
Finally, we use the trigger pairs thatare automatically extracted from the training data.Avoiding the overlap of local features, we add theconstraint |i?
j| > 2 for the target word wj .
Notethat null pairs are equivalent to long-distance sin-gleton word features wj .To compute feature performance, we begin withword features and iteratively add them one-by-oneso that we achieve the best performance.
Table 1shows the empirical results of local features, syn-tactic parser-based features, and trigger featuresrespectively.
The two F1 scores for text tran-scripts (Text) and outputs recognized by an au-tomatic speech recognizer (ASR) are listed.
Weachieved F1 scores of 94.79 and 71.79 for Text andASR inputs using only word features.
The perfor-mance is decreased by adding the additional localfeatures (POS-tags and chunk labels) because thepre-processor brings more errors to the system forspoken dialog.The parser-based and trigger features are addedto two baselines: word only and all local features.The result shows that the trigger feature is morerobust to an SLU task than the features generatedfrom the syntactic parser.
The parse tree path andgoverning category show a small improvement ofperformance over local features, but it is rather in-significant (word vs. word+path, McNemar?s test(Gillick and Cox, 1989); p = 0.022).
In contrast,the trigger features significantly improve the per-formance of the system for both Text and ASRinputs.
The differences between the trigger andthe others are statistically significant (McNemar?stest; p < 0.001 for both Text and ASR).Table 1: The result of local features, parser-basedfeatures and trigger featuresFeature set F1 (Text) F1 (ASR)word (w) 94.79 71.79w + POStag (p) 94.57 71.61w + chunk (c) 94.70 71.64local (w+p+c) 94.41 71.60w + head (h) 94.55 71.76w + path (t) 95.07 72.17w + h + t 94.84 72.09local + head (h) 94.17 71.39local + path (t) 94.80 71.89local + h + t 94.51 71.67w + trigger 96.18 72.95local + trigger 96.04 72.72Next, we compared the two trigger selectionmethods; mutual information (MI) and feature in-duction (FI).
Table 2 shows the experimental re-sults of the comparison between MI and FI ap-proaches (with the local feature set; w+p+c).
Forthe MI-based approach, we should calculate an av-eraged MI for each word pair appearing in a sen-tence and cut the unreliable pairs (down to thresh-old of 0.0001) before training the model.
In con-trast, the FI-based approach selects reliable trig-gers which should improve the model in train-ing time.
Our method based on the feature in-duction algorithm outperforms simple MI-basedmethods.
Fewer features are selected by FI, thatis, our method prunes the event pairs which arehighly correlated, but not relevant to models.
Theextended feature trigger (fi ?
fj) and null trig-gers (?
?
wj) improve the performance over wordtrigger pairs (wi ?
wj), but they are not statisti-cally significant (vs. (fi ?
fj); p = 0.749, vs.({?, wi} ?
wj); p = 0.294).
Nevertheless, thenull pairs are effective in reducing the size of trig-ger features.Figure 4 shows a sample of triggers selected byMI and FI approaches.
For example, the trigger?morning ?
return?
is ranked in first of FI but66th of MI.
Moreover, the top 5 pairs of MI arenot meaningful, that is, MI selects many functionalword pairs.
The MI approach considers only lexi-cal collocation without reference labels, so the FImethod is more appropriate to sequential super-vised learning.Finally, we wish to justify that our modified417Table 2: Result of the trigger selection methodsMethod Avg.
# triggers F1 (Text) F1 (ASR) McNemar?s test (vs. MI)MI (wi ?
wj) 1,713 95.20 72.12 -FI (wi ?
wj) 702 96.04 72.72 p < 0.001FI (fi ?
fj) 805 96.04 72.76 p < 0.001FI ({?, wi} ?
wj) 545 96.14 72.80 p < 0.001Mutual Information Feature Induction[1] from?like [1] morning?return[2] on?to [2] morning?on[3] to?i [3] morning?to[4] on?from [4] afternoon?on[5] from?i [5] afternoon?return[41] afternoon?return [6] afternoon?to[66] morning?return [15] morning?leaving[89] morning?leaving [349] december?return[1738] london?fly [608] illinois?airportFigure 4: A sample of triggers extracted by twomethodsversion of an inducing algorithm is efficient andmaintains performance without any drawbacks.We proposed two approximations: starting withlocal features (Approx.
1) and using an unstruc-tured model on the selection stage (Approx.
2),Table 3 shows the results of variant versions ofthe algorithm.
Surprisingly, the selection crite-rion based on ME (the unstructured model) is bet-ter than CRF (the structured model) not only fortime cost but also for the performance on our ex-periment4.
This result shows that local informa-tion provides the fundamental decision clues.
Ourmodification of the algorithm to induce featuresfor CRF is sufficiently fast for practical usage.5 Related Work and DiscussionThe most relevant previous work is (He andYoung, 2005) who describes an generative ap-proach ?
hidden vector state (HVS) model.
Theyused 1,178 test utterances with 18 classes for 1stlevel label, and published the resulting F1 scoreof 88.07.
Using the same test data and classes,we achieved the 92.77 F1-performance, as well4In our analysis, 10?20 iterations for each round of in-ducing procedure are insufficient in optimizing the model inCRF (empty) inducer.
Thus, the resulting parameters areunder-fitted and selected features are infeasible.
We needmore iteration to fit the parameters, but they require too muchlearning time (> 1 day).as 39% of error reduction compared to the previ-ous result.
Our system uses a discriminative ap-proach, which directly models the conditional dis-tribution, and it is sufficient for classification task.To capture long-distance dependency, HVS uses acontext-free model, which increases the complex-ity of models.
In contrast, we use non-local triggerfeatures, which are relatively easy to use withouthaving additional complexity of models.Trigger word pairs are introduced and success-fully applied in a language modeling task.
(Rosen-feld, 1994) demonstrated that the trigger wordpairs improve the perplexity in ME-based lan-guage models.
Our method extends this idea tosequential supervised learning problems.
Our trig-ger selection criterion is based on the automaticfeature inducing algorithm, and it allows us to gen-eralize the arbitrary pairs of features.Our method is based on two works of fea-ture induction on an exponential model, (Pietra etal., 1997) and (McCallum, 2003).
Our inductionalgorithm builds on McCallum?s method whichpresents an efficient procedure to induce featureson CRF.
(McCallum, 2003) suggested using onlythe mislabeled events rather than the whole train-ing events.
This intuitional suggestion has offeredus fast training.
We added two additional approx-imations to reduce the time cost; 1) an inducingprocedure over a conditional non-structured infer-ence problem rather than an approximated sequen-tial inference problem, and 2) training with a localfeature set, which is the basic information to iden-tify the labels.In this paper, our approach describes how toexploit non-local information to a SLU prob-lem.
The trigger features are more robust thangrammar-based features, and are easily extractedfrom the data itself by using an efficient selectionalgorithm.418Table 3: Comparison of variations in the induction algorithm (performed on one of the 5-fold validationsets); columns are induction and total training time (h:m:s), number of trigger and total features, andf-score on test data.Inducer type Approx.
Induction/total time # triggers/features F1 (Text) F1 (ASR)CRF (empty) No approx.
3:55:01 / 5:27:13 682 / 2,693 90.23 67.60CRF (local) Approx.
1 1:25:28 / 2:56:49 750 / 5,241 94.87 71.65ME (empty) Approx.
2 20:57 / 1:54:22 618 / 2,080 94.85 71.46ME (local) Approx.
1+2 6:30 / 1:36:14 608 / 5,099 95.17 71.816 ConclusionWe have presented a method to exploit non-localinformation into a sequential supervised learningtask.
In a real-world problem such as statisticalSLU, our model performs significantly better thanthe traditional models which are based on syntac-tic parser-based features.
In comparing our se-lection criterion, we find that the mutual informa-tion tends to excessively select the triggers whileour feature induction algorithm alleviates this is-sue.
Furthermore, the modified version of the al-gorithm is practically fast enough to maintain itsperformance particularly when the local featuresare offered by the starting position of the algo-rithm.In this paper, we have focused on a sequentialmodel such as a linear-chain CRF.
However, ourmethod can also be naturally applied to arbitrarystructured models, thus the first alternative is tocombine our methods with a skip-chain CRF (Sut-ton and McCallum, 2004).
Applying and extend-ing our approach to other natural language tasks(which are difficult to apply a parser to) such as in-formation extraction from e-mail data or biomed-ical named entity recognition is a topic of futurework.AcknowledgementsWe thank three anonymous reviewers for helpfulcomments.
This research was supported by theMIC (Ministry of Information and Communica-tion), Korea, under the ITRC (Information Tech-nology Research Center) support program super-vised by the IITA (Institute of Information Tech-nology Assessment).
(IITA-2005-C1090-0501-0018)ReferencesJ.
R. Finkel, T. Grenager, and C. Manning.
2005.
In-corporating non-local information into informationextraction systems by gibbs sampling.
In Proceed-ings of ACL?05, pages 363?370.D.
Gildea and D. Jurafsky.
2002.
Automatic label-ing of semantic roles.
Computational Linguistics,28(3):245?288.L.
Gillick and S. Cox.
1989.
Some statistical issues inthe comparison of speech recognition algorithms.
InProceedings of ICASSP, pages 532?535.Y.
He and S. Young.
2005.
Semantic processing usingthe hidden vector state model.
Computer Speech &Language, 19(1):85?106.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In Proceedingsof ICML, pages 282?289.A.
McCallum.
2003.
Efficiently inducing features ofconditional random fields.
In Proceedings of UAI,page 403.B.
L. Pellom, W. Ward, and S. S. Pradhan.
2000.
Thecu communicator: An architecture for dialogue sys-tems.
In Proceedings of ICSLP.S.
Della Pietra, V. J. Della Pietra, and J. Lafferty.
1997.Inducing features of random fields.
IEEE Trans.Pattern Anal.
Mach.
Intell, 19(4):380?393.L.
A. Ramshaw and M. P. Marcus.
1995.
Text chunk-ing using transformation-based learning.
In 3rdWorkshop on Very Large Corpora, pages 82?94.R.
Rosenfeld.
1994.
Adaptive statistical languagemodeling: A maximum entropy approach.
Tech-nical report, School of Computer Science CarnegieMellon University.F.
Sha and F. Pereira.
2003.
Shallow parsingwith conditional random fields.
In Proceedings ofHLT/NAACL?03.C.
Sutton and A. McCallum.
2004.
Collective segmen-tation and labeling of distant entities in informationextraction.
In ICML Workshop on Statistical Rela-tional Learning.419
