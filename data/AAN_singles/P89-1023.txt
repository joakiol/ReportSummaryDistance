COMPUTER AIDED INTERPRETATION OF LEXICAL COOCCURRENCESPaola Velardi (*)Mafia Teresa Pazienza (**)(*)University of Ancona, Istituto di Informatica, via Brecce Bianche, Ancona(**)University of Roma, Dip.
di lnformatica e Sistemistica, via Buonarroti 12, RomaABSTRACTThis paper addresses the problem of developing alarge semantic lexicon for natural languageprocessing.
The increas~g availability of machinereadable documents offers an opportunity to thefield of lexieal semantics, by providing experimentalevidence of word uses (on-line texts) and worddefinitions (on-line dictionaries).The system presented hereafter, PETRARCA,detects word e.occurrences from a large sample ofpress agency releases on finance and economics,and uses these associations to build a ease-basedsemantic lexicon.
Syntactically valid cooccureneesincluding a new word W are detected by ahigh-coverage morphosyntactic analyzer.
Syntacticrelations are interpreted e,g.
replaced by caserelations, using a a catalogue ofpatterns/interpretation pairs, a concept typehierarchy, and a set of selectional restriction ruleson semantic interpretation types.IntroductionSemantic knowledge codification for languageprocessing requires two important issues to beconsidered:1.
Meaning representation.
Each word is a world:how can we conveniently circumscribe thesemantic information associated to a lexic,;dentry?2.
Acquisition.
For a language processor, toimplement a useful application, severalthousands of terms must have an entry in thesemantic lexicon: how do we cope with onesuch a prohibitive task?185The problem of meaning representation is onewhich preoccupied scientists of different disciplinessince the early history of human culture.
We willnot attempt an overall survey of the field ofsemantics, that provided material for manyfascinating books; rather, we will concentrate Onthe computer science perspective, i.e.
how do wego about representing language xpressions on acomputer, in a way that can be useful for naturallanguage processing applications, e.g.
machinetranslation, information retrieval, user-friendlyinterfaces.In the field of computational inguistics, severalapproaches were followed for representing semanticknowledge.
We are not concerned here withsemantic languages, which are relatively welldeveloped; the diversity lies in the meaningrepresentation principles.
We will classify themethods of meaning representations in twocategories: conceptual (or deep) and coilocative (orsurface).
The terms "conceptual" and "collocative"have been introduced in \[81; we decided to adopt anexisting terminology, even though ourinterpretation of the above two categories isbroader than for their inventor.1.
Conceptual Meaning Conceptual meaning is thecognitive content of words; it can be expressedby features or by primitives.
Conceptualmeaning is "deep" in that it expressesphenomena that are deeply embedded inlanguage.2.
Collocatlve meaning.
What is communicatedthrough associations between words or wordclasses.
Coilocative meaning is "superficial" inthat does not seek for "the deep sense" of aword, but rather it "describes" its uses ineveryday language, or in some sub-w, ridlanguage (economy, computers, etc.).
Itprovides more than a simple analysis ofcooccurr~aces, because it attempts anexplanation of word associations in terms ofconceptual relations between a lexical item andother items or classes.Both conceptual and collocative meaningrepresentations are based on some subjective,human-produced set of primitives (features,conceptual dependencies, relations, type hierarchiesetc.)
on which there is no shared agreement at thecurrent state of the art.
As far as conceptualmeaning is concerned, the quality and quantity ofphenomena to be shown in a representation issubjective as well.
On the contrary, surface meaningcan rely on the solid evidence represented by wordassociations; the interpretation of an association issubjective, but valid associations arc an observable,even though vast, phenomenon.
To confu'm this,one can notice that different implementations oflexicons based on surface meaning aresurprisingly similar, whereas conceptual lexicons arcvery dishomogeneous.In principle, the inferential power of collocative, orsurface \[18\] meaning representation is lower thanfor conceptual meaning.
In our previous work onsemantic knowledge representation, however, \[10l\[18\] [12\] we showed that a semantic dictionary inthe style of surface meaning is a useful basis forsemantic interpretation.The knowledge power provided by the semanticlexicon (limited to about I000 manually entereddefmitions) was measured by the capability of thelanguage processor DANTE \[2\] \[18\] [11\] to answera variety of questions concerning previouslyanalyzed sentences (press agency releases on financeand economics).
It was found that, even thoughthe system was unable to perform complexinferences, it could successfully answer more than90% of the questions \[12\]L In other terms, surfacesemantics eems to capture what, at first glance, ahuman reader understands of a piece of text.In\[26\] , the usefulness of this meaningrepresentation method is demonstrated forTRANSALTOR, a system used for machinetranslation in the field of computers.An important advantage of surface meaning is thatmakes it easier the acquisition of the semanticlexicon.
This issue is examined in the next section.Acquisition of Lexical SemanticKnowledge.Acquiring semantic knowledge on a systematicbasis is quite a complex task.
One needs not tolook at metaphors or idioms to fred this; even theinterpretation of apparently simple sentences isriddled with such difficulties that makes it hardeven cutting out a piece of the problem.
A manualcodification of the lexicon is a prohibitive task,regardless of the framework adopted for semanticknowledge representation; even when a large teamof knowledge nters is available, consistency andcompleteness are a major problem.
We believe-that automatic, or semi-automatic acquisition ofthe lexicon is a critical factor in determining howwidespread the use of natural language processorswill be in the next few years.
'Recently a few methods were presented forcomputer aided semantic knowledge acquisition.
Awidely used approach is accessing on-line dictionarydefmitions to solve ambiguity problems \[3\] or toderive type hierarchies and semantic features \[24\].The information presented in a standard ictionaryhas in our view some intrinsic limitation:s definitions are often circular e.g.
the definitionof a term A may refer to a term B that in turnpoints to A;* definitions are not homogeneous as far as thequality and quantity of provided information:they can be very sketchy, or give detailedstructural information, or list examples ofuse-types, or attempt some conceptual meaningdefinition;?
a dictionary is the result of a conceptualizationeffort performed by some human specialist(s);this effort may not be consistent with, orThe test was performed over a 6 month period on about S0 occasional visitors and staff members of theIBM Rome scientific enter, unaware of the system capabilities and structure.
The user would look at 60different releases, previously analyzed by the system (or re-analyzed uring the demo), and freely asksquestions about the content of these texts.
In the last few months, the test was extended to a differentdomain, e.g.
the Italian Constitution, without significant performance changes.
See the referenced papers forexamples of sentences and of (answered and not answered) query types (in general wh-questions).186exl (from \[8\]):boy = + artimate -adult + maleex2.
(from \[251):help =Y carrying out Z, X uses his resources W in order for W to helpY to carry out Z; the use of resources by X and the carrying out of Zby Y are simultaneousex2 (from I161):throw =actor PROPELs and object from a source LOCation to adestination LOCationFigure I.suitable for, the objectives of an application forwhich a language processor is built.Examples of conceptual meaning representation in the literatureA second approach is using corpora rather thanhuman-oriented dictionary entries.
Corpora providean experimental evidence of word uses, wordassociations, and language phenomena asmetaphors, idioms; and metonymies.The problem and at the same time the advantage ofcorpora is that they are raw texts whereasdictionary entries use some formal notation thatfacilitates the task of linguistic data processing.No computer program may ever be able to deriveformatted data from a completely unformattedsource.
Hence the ability of extracting lexicalsemantic information form a corpus depends upona powerful set of mapping rules between phrasalpatterns and human-produced semantic primitivesand relations.
We do not believe that a semanticrepresentation framework is "good" if it mimics ahuman cognitive model; more realistically, webelieve that a set of primitives, relations andmapping rules is "fair', when its coverage over alanguage subworld is suitable for the purpose ofsome useful language processing activity.
Corporarepresent an 'objective" description of thatsubworld, against which it is possible to evaluatethe power of a representation scheme; and they areparticularly suitable for the acquisition of acolloeative meaning based semantic lexicon.Besides our work \[19\], the only knowledgeacquisition system based on corpora (as far as weknow) is described in \[7\].
In this work, when anunknown word is encountered, the system usespre-existing knowledge on the context in which theword occurred to derive its conceptual category.187The context is provided by on line texts in theeconomic domain.
For example, the unknownword merger in "another merger offer" iscategorized as merger-transaction using semanticknowledge on the word offer and on pre-analyzedsentences referring to a previous offer event, assuggested by the word another.
This method isinteresting but reties upon a pre-existing semanticlexicon and contextual knowledge; in our work, theonly pre-existing knowledge is the set of conceptualrelations and primitives.PETRARCA: a method for theacquisition and interpretation ofcooccurrencesPETRARCA detects cooccurrences using apowerful morphologic and syntactic anal~er \[141I11; cooccurences are interpreted by a set ofphrasal-patterns/ emantic-interpretation mappingrules.
The semantic language is Conceptual Graphs\[17\]; the adopted type hierarchy and conceptualrelations are described in \[10l.
The following is asummary description of the algorithm:For any word W,1.
(A) Parse every sentence in the corpus thatuses W.Ex: W = AGREEMENT"Yesterday an agreement was reached amongthe companies".exl (from I181):agreement =is a decision actparticipant pe-rson, organizationtheme transactioncause communication_exchangemanner interesting important effective ..ex2 (from \[26\]):person =/sa creatureagent_of take put fred speech-action mental-actionconsistof hand foot..source_of speech-actiondestination_of speech-actionpower humanspeed slowmass humanFigure 2.
Examples of eollocative meaning representation i  the literature2.
(A) Determine all syntactic attachments of W *(e.g.
syntactically valid cooccurrences) Ex:.NP_PP(AGREEMENT,AMONG,COMPANY).VP_OBJ(TO REACH,AGREEMENT).
(A) Generate a semantic interpretation foreach attachment :step 3 might produce more than oneinterpretation for a single word pattern, due tothe low selectivity of some semantic rule.step 3 might fail to produce an interpretationfor metonymies and idioms, which violatesemantic onstraints.
Strong syntactic evidence(unambiguous syntactic rules) is used to"signal" the user this type of failure.Ex: Knowledge sources used by PETRARCAIAGREEMENT}- ?
(PARTICIPANT)- ?
ICOMPANYi.4.
(A) Generalize the interpretations.Ex: Given the following examples:\[AGREEMENT l- ?
(PARTICIPANT)- > ICOMPANYI.\[AGREEMENT\]- > (PARTICIPANT)- ?
\[COUNTRY.ORGANIZATIONI.\[AGREEMENT}- ?
(PARTICIPANT)- ?
\[PRESIDENT I.derive the most general constraint:\[AGREEMENT\]- ?
(PARTICIPANT)- > IHUMAN.ENTITYI .
Theabove is a new case description added to thedefinition of AGREEMENT5.
(M) Check the newly derived entry.To perform its analysis, PETRARCA uses fiveknowledge sources:I. an on line natural corpus (press agencyreleases) to select a variety of languageexpressions including a new word W;2. a high coverage morphosyntactic analyzer, toderive phrasal patterns centered around W;3. a catalogue of patterns/interpretation pairs,called Syntax-to-Semantic (SS rules);4. a set of rules expressing selectional restrictionon conceptual relation uses (CR rules);5. a hierarchy of conceptual classes and acatalogue associating to words concept ypes.Steps marked (A) are automatic; steps marked (M)axe manual.
The only manual step is the last one:this step is however necessary because of thefollowing:The natural corpus and the parser are used in steps1 and 2 of the above algorithm; SS rules, CR rulesand the word/concept catalogue are used in step 3;the type hierarchy is used in steps 3 and 4188The parser used by PETRARCA is a high coveragemorphosyntactic analyzer developed in the contextof the DANTE system.
The lexical parser is basedon a Context Free grammar, the complete set ofItalian prefixes and suffixes, and a lexicon of 7000elementary lernmata (stems without affixes).
Atpresent, the morphologic omponent has an 100%coverage over the analyzed corpus (100,000 words)1141 131.The syntactic analysis determines syntacticattachment between words by verifying grammarrules and forms agreement; he system is based onan Attribute Grammar, augmented with lookaheadsets I1\]; the coverage is about 80%; when compiled,the parsing time is around 1-2 see.
of CPU time fora sentence with 3-4 prepositional phrases; the CPUis an IBM mainframe.The syntactic relations detected by the parser areassociated to possible semantic interpretations u ingSS rules.
An excerpt of SS rules is given below forthe phrasal pattern:noun..phrase( NP) + prepositional..phrase( PP)(di=o.D.iNP PP('wordl,d|.
"word2) ?
- tel(PO.f~E$S,di?
'word2,*lmrdl).l 'c lne dl Pletro (the do s of Peter)'/NP_PP('wordl,dl,'word2) <.
reI(.SOC RELATION,dl,'word2,'wordl)./ ' l it mtdre rq Elet,o (the mitther of Peter)'/NP PP('wm'dhdi,'word2) < ?
rei(PART1CIPANT,di,*wofdl,'word2)./'riunione dei deleptl (the meeting of the delesliel)'/NP PP('wocdl.di.
'word2) <- rel($UBSET0dt.'wocd2.
'wordl)./ 'due d!
nol (two of us)'/NP_PP('wo~I,di.
'word2) < - mI(PART OF.di.
'wortl2,'wordl)./'p=glne del Itbro (the pitgel of the book)'/NP_PP('wonll.dl.
'word2) ?
.
ml(MATTER.dl,'wordl.
'word2).I 'oglFtto dl legno (itn object of wood)'/NP_PP('wordl,dl, 'word3) <- rel(PRODUeER,di, 'wordl,*word2)./ 'rul~ito del leonl (the rmlr of the lions)'/NP_PP("~mrdl,dl,'wottl '2) <- reI(CHARACTERISTIC.d.I,'word2.
'wordl)./'rintelllgenza delrtlomo (the intelligence of the man)'/Overall, we adopted about 50 conceptual relationsto describe the set of semantic relations commonlyfound in language; see \[10\] for a complete list.
Thecatalogue of SS rules includes about 200 pairs.Given a phrasal pattern produced by the syntacticparser, SS rules select a first set of conceptualrelations that are candidate interpretations for thepattern.Selectional restriction rules on conceptual relationsare used to select a unique interpretation, whenpossible.
Writing CR rules was a very complextask, that required a process of progressiverefinement based on the observation of the results.The following is an example of CR rule for theconceptual relation PARTICIPANT:participant --189has..participant: meeting, agreement, fly, sailis.participant: human_entityExamples of phrasal patterns interpreted by theparticipant relation are:John flies (to New York); the meeting amongparties; the march of the pacifists," a contractbetween Fiat and A lfa; the assembly of theadministrators, etc.An interesting result of the above algorithm is thefollowing: in general, syntax will also acceptsemantically invalid cooccurrences.
In addition, instep 3, ambiguous words can be replaced by the"wrong" concept names.
Despite this, selectionalrestrictions are able to interpret only validassociations and reject the others.
For example,consider the sentence: "The party decided a newstrategy".
The syntax detects the associationSUBJ(DECIDE, PARTY).
Now, the word "party"has two concept names associated with it:POL PARTY, and FEAST, hence in step 3 bothinterpretations are examined.
I lowever, noconceptual relation is found to interpret he pattern"FEAST DECIDE".
This association is hencerejected.Simalirily, in the sentence: "An agreement isreached among the companies, the syntacticanalyzer will submit to the semantic interpreter twoassociations:NP_PP(A GREEMENT, AMONG, COMPA N Y) andVP_PP(REACIt, AMONG,COMPANY) Now,the preposition among in the SS rules, points tosuch conceptual relations as PARTICIPANT,SUBSET (e.g.
"two among all us"), andLOCATION (e.g.
"a pine among the trees'% butnone of the above relates a MOVE ACT with aIIUMAN ORGANIZATION.
The association is mhence rejected.Future experimentation issuesThis section highlights the current limitations andexperimentation issues with PETRARCA.Definition of type hierarchiesPETRARCA gets as input not only the word W,but a list of concept labels CWi, corresponding tothe possible senses of W. For each of these CWi,the supertype in the hierarchy must be provided.Notice .however that the system knows nothingabout conceptual classes; the hierarchy is only anordered set of labels.In order to assign a supertype to a concept, threemethods are currently being investigated.
First, aprogram may "guide" the user towards the choice ofthe appropriate supertype, visiting top down thehierarchy.
This approach is similar to the onedescribed in I261.Alternatively, the user may give a fist ofsynonymous or near synonymous words.
If one ofthese was already included in the hierarchy, thesame supertype is proposed to the user.A third method lets the system propose thesupertype.
The system assumes CW=W andproceeds through steps 1, 2 and 3 of the casedescriptions derivation procedure.
As the supertypeof CW is unknown, CR rules are less effective atdetermining a unique interpretation of syntacticpatterns.
If in some of these patterns the partnerword is already defined in the dictionary, its casedescriptions can be used to restrict the analysis.For example, suppose that the word president isunknown in:The president nominated etc.Pertini was a good president'the knowledge on possible AGENTs forNOMINATE let us inferPRESIDENT < HUMANENTITY; from thesecond sentence, it is possible to further estrict to:PRESIDENT< HUMAN ROLE.
The thirdmmethod is interesting because it is automatic,however it has some drawbacks.
For example, it isslow as compared 1:o methods 1 and 2; a traineduser would rather use his experience to decide asupertype.
Secondly, if the word is found withdifferent meanings in the sample sentences, thesystem might never get to a consistent solution.Finally, if the database includes very few or vagueexamples, the answer may be useless (e.g.
ACT, orTOP).
It should also be considered that the effortrequired to assign a supertype to, say, 10.000 wordsis comparable with the encoding of themorphologic lexicon.
This latter equired about onemonth of data entry by 5-6 part-time researchers,plus about 2-3 months for an extensive testing.The complexity of hierarchically organizingconcepts however, is not circumscribed to the timeconsumed in associating a type label to somethousand words.
All NLP researchersexperimented the difficulty of associating concept190types to words in a consistent way.
Despite theefforts, no commonly accepted hierarchies havebeen proposed so far.
In our view, there is noevidence in humans of primitive conceptualcategories, except for a few categories as animacy,time, etc.
We should perhaps accept the very factthat type hierarchies are a computer method to beused in NLP systems for representing semanticknowledge in a more compact form.
Accordingly,we are starting a research on semi-automatic wordclustering (in some given language subworlddescribed by a natural corpus), based on fuzzy setand conceptual c ustering theories.Interpretation of idiomatic expressionsIn the current version of PETRARCA, in case ofidiomatic expressions the user must provide thecorrect interpretation.
In case o f  metaphors,syntactic evidence is used to detect a metaphor,under the hypothesis that input sentences to thesystem are syntactically and semantically correct.At the current state of implementation, the systemdoes not provide automatic interpretation ofmetaphors.
However, an interesting method wasproposed in 1201.
According to this method, whenfor example a pattern such as "car drinks" isdetected, the system uses knowledge of canonicaldefinitions of the concepts "DRINK" and "CAR"to establish whether ~CAR" is used metaplaoricallyas a HUMANENTITY,  or "DRINK" is usedmetaphorically as 1"O BE FEDBY".
Aninteresting user aided computer program foridiomatic expressions analysis is also described in1231.Generalization of case descriptionsIn PERTRARCA, phrasal patterns are firstmapped into 'low level" case description; in step 4,"similar" patterns are merged into "high level' casedescriptions.
In a first implementation, two orthree low level case descriptions had to be derivedbefore creating a more general semantic rule.
Thisapproach is biased by the availability of examplesentences.
A word often occurs in dozens ofdifferent contexts, and only occasionally twophrasal patterns reflect the same semantic relation.For example, consider the sentences:The company signs a contract for newfimdingThe ACE stipulates a contract o increase its influenceRestricting ourselves to the word "contract', we getthe following semantic interpretations of syntacticpatterns:14SIGNI, > frHBlmtl~ > l ?O l~Cr l2.1COl~t~-~r}.
~ l l~l l~l~- ?
ll~l~llqO-'lMs'rII~JI.&TIBI- > crI-IIBMII).
> l?OlCraAc~rl4.\[CONTRA~WI- > (PIJRPOSli).
?
l l~ l l lIn patterns 1 and 3 "sign" and "stipulate" belong tothe same supertype, i.e.INFORMATIONEXCHANGE; hence a newcase description can be tentatively created forCONTRACT:ICOl,?rr~cl+.l.
?
(TI ' l l IMI~.
> IlI,+F'ORMA'rioI,,I+BXO.IA I~F .
!Indeed, one can tell, talk about, describe etc.
acontract.Conversely, patterns 3 and 4 have no commonsupertype; hence two "low level" case descriptionsare added to the definition of CONTRACT.lCONTRAC'rl.
?
(PURPOSE)- ~ ILmlJNDINGIICOiCTRACI"I- > (PURPOSE)- ?
lll'~'ll, tt.,~IIlEven with a large number of input sentences, thesystem createsmany of these specific patterns; ahuman user must review the results and provide forcase descriptions generalization when he/she feelsthis being reasonable.A second approach is to generalize on the basis ofa single example, and then retract (split) the rule ifa counterexample is found.
Currently, we axe~a'udying different policies and comparing theresults; one interesting issue is the exploitation ofcounterexamples.Conc lud ing remarksEven though PETRARCA is still an experimentand has many unsolved issues, it is, to ourknowledge, the first reported system for extensivesemantic knowledge acquisition.
There is room formany improvements; for example, PETRARCAonly detects, but does not interpret idioms; neitherit knows what to do with errors; if a wronginterpretation of a phrasal pattern is derived, errorcorrection and refinement of the knowledge base isperformed by the programmer.
HoweverPETRARCA is able to process automatically rawlanguage expressions and to perform a first191classification and encoding of these data.
The richlinguistic material produced by PETRARCAprovides a basis for future analysis and refinements.Despite its limitations, we believe this methodbeing a first, useful step towards a more completesystem of language learning.References111 F. Antonacci, P. Velardi, M.T.
Pazienza, AHigh Coverage Grammar for the ItalianLanguage, Journal of the Assoc.
for Literaryand Linguistic Computing, in print 1988.121 F. Antonacci, M.T.
Pazienza, M. Russo,P.Velardi, Representation and ControlStrategies for large Knowledge Domains : anApplication to NLP, Journal of AppliedArtificial Intelligence, inprint 1988.\[31 JL.
Binot and K. Jensen A Semantic ExpertUsing an On-line Standard DictionaryProceedings of the IJCAI Milano, 1987\[41 K. Dahlgren and J. McDoweU Kind Types inKnowledge Reimesentation Proceedings of theColing-86 1986151 Heidorn G.E.
"Augmented Phrase StructureGrammar" in "Theoretical Issues in NaturalLanguage Processing" N ash- Webber andSchank ,eds, ACL 1975161 J. Katz, P. Postal An Integrated Theory ofLinguistic Descriptions Cambridge, M.LT.Press, 1964.171 P. Jacobs, U. Zernik Acquiring LexicalKnowledge from Text: a Ca.~e Study,Proceedings of the AAAI88, St. Paul, August1988\[8\] Geoffrey Leech Semantics: The Study ofMeaning second edition, Penguin Books 1981.191 Michalsky R.S., Carbonell J.C., MitchellT.M.
Machine Learning vol i TiogaPublishing Company Palo Alto, 1983\[101 M.T.
Pazienza and P. Velardi, A StructuredRepresentation f Word Senses for SemanticAnalysis Third Conference of the European\[111\[12lI131\[141\[15\]\[161I1711181Chapter of the ACL, Copenhagen, April 1-31987.M.T.
Pazienza and P. Velardi, IntegratingConceptual Graphs and Logic in a NaturalLanguage Understanding System, in "NaturalLanguage Understanding and LogicProgramming I I ~, V. Dahl and P.Saint-Dizier editors, North-Holland, 1988.M.T.
Pazienza, P. Velardi, Using a SemanticKnowledge Base to Support A NaturalLanguage Interface to a Text Database, 7thInternational Conference onEntity-Relationship Approach, Rome,November 16-18 1988.M.
Russo, A Rule Based System for theMorphologic and Morphosyntactic Analysis ofthe Italian Language, in "Natural LanguageUnderstanding and Logic Programming 11",V. Dahl and P. Saint-Dizier editors,North-Holland, 1988.M.
Russo, A Generative Grammar-Approach ?f o r  the Morphologie and MorphosyntactieAnalysis of Italian, Third Conference of theEuropean Chapter of the ,4CL, Copenhagen,April 1-3 1987.Shank R.C.
Conceptual Dependency: atheory of natural language understanding.Cognitive Psicology, vol 3 1972Shank R.C, Goldman, Rieger, RiesbeckConceptual Information ProcessingN oth-H olland/ american Elsevier 1975J.F.
Sowa, Conceptual Structures:Information Processing in Mind and Machine,,4 ddison.
Wesley, Reading, 1984.P.
Velardi, M.T.
Pazienza and M.DeGiovanetti, Conceptual Graphs for theAnalysis and generation of sentences, IBMJournal of Research and Development, March1988.!191120\]12111221I2311241125112611271P.
Velardi, M.T.
Pazienza, S. MagriniAcquisition of Semantic Patterns from anatural corpus of texts ,4CM-SIG,4RT specialissue on knowledge acquisition i  printE.
Way Dinamic Type Hierachies: AnApproach to Knowledge Representationthrough Metaphor PhD dissertation, Dept.
ofSystem Science, State Univ.
o f  N Y atBinghamton 1987.Y.
Wilks, Preference Semantics Memorandafrom the Artificial Intelligence Laboratory,Stanford University Stanford, 1973Y.
Wilks, Deep and Superficial Parsing, in"Parsing natural Language" M. King editor,Academic Press, 1983.U.
Zemik Strategies in Language Acquisition:Learning Phrases from Examples inContexts.
Phd dissertation, Tech.
Rept.UCL,4-,41-87-1, University of California, Los,4ngeles 1987R.
Byrd, N. Calzolari, M. Chodorow, J.Klavans, M. Neff, O. Rizk Large lexicons forNatural Language Processing: Utilizing thegrammar Coding System of LDOCEComputational Linguistics, special issue of theLexicon D. Walker, ,4.
Zampolli, N. Calzolarieditors July-December 1987 1987.I.
Mel'cuk, A. Polguere A Formal Lexicon inMeaning-Text Theory (or How To Do Lexicawith Words) Computational Linguistics,special issue of the Lexicon D. Walker, 4.Zampoili, N. Calzolari editors July-December1987 1987.S.
Nirenburg, V. Raskin 111e SubworldConcept Lexicon and the LexiconManagement System ComputationalLinguistics, special issue of the Lexicon D.Walker, ,4.
Zampoili, N. Calzolari editorsJuly-December 1987 1987.J.
Pustejovsky Constraints on the Acquisitionof Semantic Knowledge, Journal of IntelligentInformation Systems, vol 3, n. 3, fall 1988192
