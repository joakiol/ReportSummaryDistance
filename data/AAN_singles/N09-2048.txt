Proceedings of NAACL HLT 2009: Short Papers, pages 189?192,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsLexical and Syntactic Priming and Their Impact in Deployed Spoken DialogSystemsSvetlana Stoyanchev and Amanda StentDepartment of Computer ScienceStony Brook UniversityStony Brook, NY 11794-4400, USAsvetastenchikova@gmail.com, amanda.stent@stonybrook.eduAbstractIn this paper, we examine user adaptation tothe system?s lexical and syntactic choices inthe context of the deployed Let?s Go!
dialogsystem.
We show that in deployed dialog sys-tems with real users, as in laboratory experi-ments, users adapt to the system?s lexical andsyntactic choices.
We also show that the sys-tem?s lexical and syntactic choices, and con-sequent user adaptation, can have an impacton recognition of task-related concepts.
Thismeans that system prompt formulation, evenin flexible input dialog systems, can be usedto guide users into producing utterances con-ducive to task success.1 IntroductionNumerous studies have shown that people adapttheir syntactic and lexical choices in conversation tothose of their conversational partners, both human(Brennan, 1996; Pickering et al, 2000; Lockridgeand Brennan, 2002; Reitter et al, 2006) and com-puter (Branigan et al, 2003; Brennan, 1991; Bren-nan, 1996; Gustafson et al, 1997; Ward and Litman,2007).
User adaptation to the system?s lexical andsyntactic choices can be particularly useful in flexi-ble input dialog systems.
Limited input dialog sys-tems, including most commercial systems, requirethe user to respond to each system prompt usingonly the concept and words currently requested bythe system.
Flexible input dialog systems allow theuser to respond to system prompts with conceptsand words in addition to or other than the ones cur-rently requested, and may even allow the user totake task initiative.
Speech recognition (ASR) accu-racy in limited input systems is better than in flexi-ble input systems (Danieli and Gerbino, 1995; Smithand Gordon, 1997).
However, task completion ratesand times are better in flexible input systems (Chu-Carroll and Nickerson, 2000; Smith and Gordon,1997).
With user adaptation, in flexible input dia-log systems prompts can be formulated to maximizeASR accuracy and reduce the number of ASR time-outs (Sheeder and Balogh, 2003).Previous research on user adaptation to dialogsystems was conducted in laboratory settings.
How-ever, the behavior of recruited subjects in a quietlaboratory may differ from that of real users in thenoisy world (Ai et al, 2007).
Here we present thefirst study, to the best of our knowledge, that in-vestigates the adaptive behavior of real users of alive dialog system.
We analyze dialogs from CMU?sLet?s Go!
dialog system (Raux et al, 2005).
Welook at the effects of the system?s lexical and syn-tactic choices on: 1) lexical and syntactic choicesin user responses; and 2) concept identification ratesfor user responses.
We confirm prior results showingthat users adapt to the system?s lexical and syntacticchoices.
We also show that particular choices forsystem prompts can lead to higher concept identifi-cation rates.2 Experimental MethodWe conducted our experiment using the Let?s Go!telephone-based spoken dialog system that providesinformation about bus routes in Pittsburgh (Rauxet al, 2005).
The users are naive callers from thegeneral population seeking information about bus189condition request departure confirm departure request arrival confirm arrivallocation location location location(1) Where are you leav-ing from?Leaving from X, is thiscorrect?Where are you goingto?Going to X, is thiscorrect(2) Where are you leav-ing from?From X, is this cor-rect?Where are you goingto?To X, is this correct(3) What is the place ofyour departureX, is this correct?
What is the place ofyour arrival?X, is this correct(4) Where do you want toleave from?You want to leave fromX, is this correct?Where do you want togo to?You want to go to X,is this correctTable 1: Experimental conditionsSpkr Task type UtteranceSys Open Welcome to the CMU Let?sGo bus information system.What can I do for you?Usr 61A scheduleSys RequestDepartureWhere do you wanna leavefrom?Usr Location From downtownSys ConfirmDepartureLeaving from downtown.
Isthis correct?Usr Location YesSys RequestArrivalWhere are you going to?Usr Location OaklandSys ConfirmArrivalGoing to Waterfront.
Is thiscorrect?Usr Location No, to OaklandFigure 1: Dialog extract from Let?s Go!
dataschedules.
In order to provide the user with routeinformation, Let?s Go!
elicits a departure location,a destination, a departure time, and optionally a busroute number.
Each concept value provided by theuser is explicitly confirmed by the system.
Figure 1shows an example dialog with the system.Let?s Go!
is a flexible input dialog system.
Theuser can respond to a system prompt using a singleword or short phrase, e.g.
Downtown, or a completesentence, e.g.
I am leaving from downtown1.We ran four experimental conditions for twomonths.
The conditions varied in the lexical choiceand syntax of system prompts for two system re-quest location tasks and two system confirm loca-tion tasks (see Table 1).
System prompts differed1The user response can also contain concepts not requestedin the prompt, e.g.
specifying departure location and bus num-ber in one response.by presence of a verb (to leave, to go) or a preposi-tion (to, from), and by the syntactic form of the verb.The request location prompt contained both a verband a preposition in the experimental conditions (1,3, and 4).
The confirm location prompt containedboth a verb and a preposition in conditions 1 and 4,only a preposition in condition 2, and neither verbnor preposition in condition 3.
In conditions 1 and4, both request and confirmation prompts differed inthe verb form (leaving/leave, going/go).2184 dialogs were used for this analysis.
For eachexperimental condition, we counted the percentagesof verbs, verb forms, prepositions, and locations inthe ASR output for user responses to system requestlocation and confirm location prompts.
Althoughthe data contains recognition errors, the only differ-ence in system functionality between the conditionsis the formulation of the system prompt, so any sta-tistically significant difference in user responses be-tween different conditions can be attributed to theformulation of the prompt.3 Syntactic AdaptationWe analyze whether users are more likely to use ac-tion verbs (leave, leaving, go, or going) and prepo-sitions (to, from) in response to system prompts thatuse a verb or a preposition.
This analysis is interest-ing because ASR partially relies on context words,words related to a particular concept type such asplace, time or bus route.
For example, the likelihoodof correctly recognizing the location Oakland in theutterance ?going to Oakland?
is different from thelikelihood of correctly recognizing the single wordutterance ?Oakland?.Table 2 shows the percentages of user responses190Cond.
Sys uses Sys uses % with % withverb prep verb prepResponses to request location prompt(1) yes yes 2.3% ?
5.6%(2) yes yes 1.9% 4.3%(3) no no 0.7% 4.5%(4) yes yes 2.4%?
6.0%Responses to confirm location prompt(1) yes yes 15.7% ?
?
23.4%(2) no yes 3.9% 16.9%(3) no no 6.4% 12.7%(4) yes yes 10.8% 22.0%Table 2: Percentages of user utterances containing verbsand prepositions.
?
indicates a statistically significant dif-ference (p<0.01) from the no action verb condition (3).?
indicates a statistically significant difference from theno action verb in confirmation condition (2).in each experimental condition that contain a verband/or a preposition.
We observe adaptation to thepresence of a verb in user responses to request lo-cation prompts.
The prompts in conditions 1, 2 and4 contain a verb, while those in condition 3 do not.The differences between conditions 1 and 3, and be-tween conditions 4 and 3, are statistically significant(p<0.01)2.
The difference between conditions 2 and3 is not statistically significant, perhaps due to theabsence of a verb in a prior confirm location prompt.A similar adaptation to the presence of a verb inthe system prompt is seen in user responses to con-firm location prompts.
The prompts in conditions1 and 4 contain a verb while those in conditions 2and 3 do not.
The differences between conditions1 and 2, and between conditions 1 and 3, are statis-tically significant (p<.01), while the difference be-tween conditions 4 and 2 exhibits a trend.
We hy-pothesize that the lack of the statistically significantdifferences between conditions 4 and 2, and condi-tions 4 and 3, is caused by the low relative frequencyin our data of dialogs in condition 4.We do not find statistically significant differencesin the use of prepositions.
However, we observe atrend showing higher likelihood of a preposition inuser responses to confirm location in the conditionswhere the system uses a preposition.
Prepositionsare short closed-class context words that are morelikely to be misrecognized (Goldwater et al, 2008).2All analyses in this section are t-tests with Bonferroni ad-justment.Condition/ LEAVING LEAVE totalUser?s verb (progressive) (simple)(1) Progressive 74.5% 25.5% 55(3) Neutral 61.3% 38.7% 31(4) Simple 43% 57% 42Condition/ GOING GO totalUser?s verb (progressive) (simple)(1) Progressive 84.4% 15.6% 45(3) Neutral 66.6% 33.4% 21(4) Simple 46.5% 53.5% 43Table 3: Usage of verb forms in user utterancesHence, more data (or human transcription) may berequired to see a statistically significant effect.4 Lexical AdaptationWe analyze whether system choice of a particularverb form affects user choice of verb form.
Forthis analysis we only consider user utterances inresponse to a request location or confirm locationprompt that contain a concept and at least one of theverb forms leaving, going, leave, or go3.Table 3 shows the total counts and percentagesof each verb form in the progressive form condition(condition 1), and the neutral condition (condition3), and the simple form condition (condition 4)4.We find that the system?s choice of verb form hasa statistically significant impact on the user?s choice(?2 test, p<0.01).
In the neutral condition, usersare more likely to choose the progressive verb form.In the progressive form condition, this preference in-creases by 13.2% for the verb to leave, and by 17.8%for the verb to go.
By contrast, in the simple formcondition, this preference decreases by 18.3% forthe verb to leave and by 20.1% for the verb to go,making users slightly more likely to choose the sim-ple verb form than the progressive verb form.5 Effect of Adaptation on SpeechRecognition PerformanceThe correct identification and recognition of task-related concepts in user utterances is an essentialfunctionality of a dialog system.
Table 4 shows3Such utterances constitute 3% of all user responses to allrequest and confirm place prompts in our data.4We ignore condition 2 where the verb is used only in therequest prompt.191SystempromptArrivalrequestDeparturerequest(1) 72.2% ?
63.8%(2) 77.4% 61.0%(3) 74.5% ?
61.5%(4) 82.0% 66.0%Table 4: Concept identification rates following requestlocation prompts.
?
indicates a statistically significantdifference (p<0.01 with Bonferroni adjustment) fromcondition 4.the percentage of user utterances following a re-quest location prompt that contain an automatically-recognized location concept.
Condition 4, where thesystem prompt uses the verb form to leave, achievesthe highest concept identification rates.
The differ-ences in concept identification rates between condi-tions 1 and 4, and between conditions 3 and 4, arestatistically significant for request arrival location(t-test, p<.01).
Other differences are not statisticallysignificant, perhaps due to lack of data.6 Conclusions and Future WorkIn this paper, we showed that in deployed dialog sys-tems with real users, as in laboratory experiments,users adapt to the lexical and syntactic choices of thesystem.
We also showed that user adaptation to sys-tem prompts can have an impact on recognition oftask-related concepts.
This means that the formula-tion of system prompts, even in flexible input dialogsystems, can be used to guide users into producingutterances conducive to task success.In future work, we plan to confirm these resultsusing transcribed data.
We also plan additional ex-periments on adaptation in Let?s Go!, including ananalysis of the time course of adaptation and furtheranalyses of the impact of adaptation on ASR perfor-mance.7 AcknowledgementsWe would like to thank the Let?s Go!
researchers atCMU for making Let?s Go!
available.
This researchwas supported by the NSF under grant no.
0325188.ReferencesH.
Ai, A. Raux, D. Bohus, M. Eskenazi, and D. Lit-man.
2007.
Comparing spoken dialog corpora col-lected with recruited subjects versus real users.
In Pro-ceedings of SIGDial.H.
Branigan, M. Pickering, J. Pearson, J. McLean, andC.
Nass.
2003.
Syntactic alignment between comput-ers and people: the role of belief about mental states.In Proceedings of CogSci.S.
Brennan.
1991.
Conversation with and through com-puters.
User Modeling and User-Adapted Interaction,1(1):67?86.S.
Brennan.
1996.
Lexical entrainment in spontaneousdialog.
In Proceedings of ISSD.J.
Chu-Carroll and J. Nickerson.
2000.
Evaluating au-tomatic dialogue strategy adaptation for a spoken dia-logue system.
In Proceedings of NAACL.M.
Danieli and E. Gerbino.
1995.
Metrics for evaluat-ing dialogue strategies in a spoken language system.In Proceedings of the AAAI Spring Symposium on Em-pirical Methods in Discourse Interpretation and Gen-eration.S.
Goldwater, D. Jurafsky, and C. Manning.
2008.Which words are hard to recognize?
Lexical, prosodic,and disfluency factors that increase asr error rates.
InProceedings of ACL/HLT.J.
Gustafson, A. Larsson, R. Carlson, and K. Hellman.1997.
How do system questions influence lexicalchoices in user answers?
In Proceedings of Eu-rospeech.C.
Lockridge and S. Brennan.
2002.
Addressees?
needsinfluence speakers?
early syntactic choices.
Psycho-nomics Bulletin and Review.M.
Pickering, H. Branigan, A. Cleland, and A. Stew-art.
2000.
Activation of syntactic priming duringlanguage production.
Journal of Psycholinguistic Re-search, 29(2):205?216.A.
Raux, B. Langner, A.
Black, and M Eskenazi.
2005.Let?s Go public!
taking a spoken dialog system to thereal world.
In Proceedings of Eurospeech.E.
Reitter, J. Moore, and F. Keller.
2006.
Priming of syn-tactic rules in task-oriented dialogue and spontaneousconversation.
In Proceedings of CogSci.T.
Sheeder and J. Balogh.
2003.
Say it like you meanit: priming for structure in caller responses to a spokendialog system.
International Journal of Speech Tech-nology, 6(2):103?111.R.
Smith and S. Gordon.
1997.
Effects of variable initia-tive on linguistic behavior in human-computer spokennatural language dialogue.
Computational Linguistics,23(1):141?168.A.
Ward and D. Litman.
2007.
Automatically measuringlexical and acoustic/prosodic convergence in tutorialdialog corpora.
In Proceedings of the SLaTE Work-shop on Speech and Language Technology in Educa-tion.192
