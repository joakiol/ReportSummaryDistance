TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 61?64,Rochester, April 2007 c?2007 Association for Computational LinguisticsSemi-supervised Algorithm for Human-Computer Dialogue MiningCalkin S. Montero and Kenji ArakiGraduate School of Information Science and TechnologyHokkaido University, Kita 14-jo Nishi 9-chomeKita-ku, Sapporo 060-0814 Japan{calkin,araki}@media.eng.hokudai.ac.jpAbstractThis paper describes the analysis of weaklocal coherence utterances during human-computer conversation through the appli-cation of an emergent data mining tech-nique, data crystallization.
Results revealthat by adding utterances with weak localrelevance the performance of a baselineconversational partner, in terms of usersatisfaction, showed betterment.1 IntroductionData mining can be defined as the process of find-ing new and potentially useful knowledge from data.An enhanced trend of data mining is chance discov-ery, which in spite of being an emergent field of re-search has been applied to different branches of sci-ence.
Recently, data crystallization (Ohsawa, 2005)has been proposed as a chance discovery extensiondevoted to find desired unobservable events withina given data.
This method of data mining has beenintended for revealing events that are significant butare not included in the analyzed data (sparseness).The knowledge database of a conversational part-ner computer program is a good example of datasparseness, making very difficult to realize a human-like conversation between a user and a computer,since the database is missing relevant or coherentanswers for a given user input, e.g., ELIZA sys-tem (Weizenbaum, 1966), corpus-based dialoguesystems (Inui et al, 2003), and so forth.
Herring(1999) noticed the weak sequential coherence dur-ing human-computer interaction that is caused byweak local relevance, pointing out the violation ofthe Gricean maxim of local relevance during the di-alogue.
However, we argue that conversational re-sponses - often of very weak local relevance - gener-ated by a conversational partner computer program(or ?chatbot?)
could successfully simulate human-like coherent dialogue (see example given by (Her-ring, 1999), where topical coherence is stated inspite of violation of local relevance Gricean maxim).Moreover, we argue that weak local relevance utter-ances could be regarded as topic-shifting utterances.These utterances are vital in order to keep the flow ofthe dialogue and its overall coherence.
Determiningthe moment when the topic-shifting utterances areneeded is hence essential to the success of a chatbot.In this paper KeyGraph and data crystallizationtechniques are applied to analyze human-computertrivial dialogue, chat, considering as chances to dis-cover the missing topic-shifting utterances, used toimprove the overall sequential coherence and theflow of the computer dialogue.2 Human-Computer ConversationAnalysis ApproachDuring the process of dialogue mining, in order toanalyze the behavior of human-computer conversa-tional interaction, the interrelationship of utterancesof a dialogue section was obtained.
The following isa fragment of an analyzed dialogue section betweena user and ALICE chatbot (Wallace, 2005):[1] User: hi[2] Chatbot: hello there!
what is your name?
[3] User: Joe[4] Chatbot: Ok, I will call you Joe61[5] User: what should I call you?
[6] Chatbot: my name is Alice[7] User: cool [....](Conversation continues)[17] User: what do you mean by robot?
there are lots of differ-ent robots[18] Chatbot: It is a good question.
Have you tried a websearch?
Would you like to know more?
[19] User: sure[20] Chatbot: Ok let?s do it.
What would you like to know?
[21] User: what Alice thinks a robot means[22] Chatbot: is that a rhetorical question?
I would search for it[23] User: when I hear robot, I think of something that moves[24] Chatbot: you never know what to expect from life.
Why?oh yeah, we are talking about something that moves [....]For the analysis, the application of data crystal-lization is introduced in order to identify the miss-ing topic-shifting utterances.
The interrelationshipof utterances (user-chatbot) is represented in a co-occurrence document created as described below.2.1 The KeyGraphThe KeyGraph has been used as a data-mining toolfor extracting patterns of the appearance of chanceevents (Ohsawa et al(2003)).
The KeyGraph iden-tifies relationships between terms in a documentparticularly focusing on co-occurrence relationshipsof both high-probability and low-probability events.Montero et al (2005) have applied this tool for ana-lyzing the dynamic behavior of human-human chat,identifying criticality.In this paper the KeyGraph is applied in combi-nation with data crystallization in order to visual-ized utterances that do not appear during human-computer chat.
The interrelationship of utterances(user-chatbot) is represented in a co-occurrence doc-ument created by the following algorithm: a) Each ut-terance (from both, the user and the chatbot) was considered asone sentence.
b) Each sentence was segmented into words.
c)High frequency words were eliminated, i.e., I, you, is, follow-ups and the like, as to avoid false co-occurrence.
d) A vectorialrepresentation of each sentence (at word level) was obtained andsentences co-occurrence relationship was determined as1:D= w1:: S1, S2, S4 .../ w2:: S9, S25 .../w3:: S1, S3, S10 .../ ... / wn:: S24, S25, ... Sm1Since follow-ups were eliminated, the number of sentencesin D might be smaller than the actual number of sentences inthe dialogue.where: wk (k = 1, 2, 3, ..., n), represents a word in a sentence.Sl (l = 1, 2, 3, ..., m), represents a sentence.Then it could be said that the obtained D docu-ment contains the co-occurrence relationship of theutterances during the analyzed dialogue section.
Inthe graph, the most frequent items in D are shownas black nodes and the most strongly co-occurringitem-pairs are linked by black lines according to theJaccard coefficient:J(Sx, Sy) = p(Sx ?
Sy)/p(Sx ?
Sy)where p(Sx ?
Sy) is the probability that both el-ements Sx and Sy co-occur in a line in D, andp(Sx ?
Sy) is the probability that either Sx or Syappears in a line.
In the graph, nodes are interpretedas sentences (from D) and clusters of nodes as par-ticular topics (Figure 1).2.2 Data CrystallizationData crystallization (Ohsawa, 2005), is dedicated toexperts working in real domains where discoveriesof events that are important but are not included inthe analyzed data are desired.
The process of datacrystallization involves to insert dummy items inthe given data in order to represent unobservableevents.
In this paper, each dummy item inserted inthe D document (one in each vector of D) is namedXY , where X represents the level of the insertionand Y represents the line where the dummy itemwas inserted.
The KeyGraph is applied to the new Ddocument and all of the dummy nodes that did notappear linking clusters in the graph are eliminatedfrom the data, and then the cycle is iterated to higherlevels.
In the case of the D document of Sec.2.1,after the first level of insertion it becomes:D?= w1:: S1, S2, S4 ...11 / w2:: S9, S25 ...12 /w3:: S1, S3, S10 ...13 / ... / wn:: S24, S25, ... Sm 1nwhere 1 o (o = 1, 2, 3, ..., n), represents each dummy iteminserted in each vector of D.After feeding the KeyGraph with D?, all thedummy items that did not appear linking clusters asbridges in the outputted graph are deleted.
At thispoint new dummy items with higher hierarchy (2x)are inserted in D?, and the cycle iterates.
Unobserv-able events and their relations with other events areto be visualized by the application of KeyGraph iter-atively to the data that is been crystallized (Figure 2).62Figure 1: User-Computer Chat Graph Figure 2: Crystallized Data Graph3 Experiment and Visual ResultsThe performed experiment was carried out in threestages.
In the first stage of the experiment, three dif-ferent dialogue sections (including the one shown inSec.2) between three native English speakers and achatbot (Wallace, 2005) were analyzed in order tofind co-occurrence between the users?
utterance andthe chatbot replies, i.e., D document.
This D docu-ment was then examined by the KeyGraph (unsuper-vised process).
Figure 1 shows the graphical view ofthe dialogue in Sec.2 (48 turns, user - chatbot, in to-tal).
A characteristic of the KeyGraph is the visual-ization of co-occurring events by means of clusters.In Figure 1, the nodes represent sentences from theD document, the clusters represent the relationshipamong those sentences, i.e., a specific topic, and thenodes that link the clusters represent the transitionfrom one topic to the next.
It can be observed thatthe main clusters are not interconnected, leading tothe conclusion that the chatbot in many cases couldnot keep a smooth and natural flow of the dialogue.In the second stage of the experiment, a crystal-lized document of utterance co-occurrence, i.e., D?document, was obtained for the same dialogue sec-tions, following the process described in Sec.2.2.The graphical output of the dialogue in Sec.2, af-ter crystallization, can be observed in Figure 2.
Itcan be seen in this figure how the two main clustersappear to be interconnected by the dummy item 1 3.Although this dummy item was inserted in the thirdline of the D document, it appears in the graph con-necting the two main clusters.
The dummy item 1 3branches from utterance [24].
This interconnectingpoint can be regarded as the system considering itappropriate to insert a topic-shifting utterance at thispoint of the conversation.
In doing so, a well in-terconnected graph is obtained (Figure 2).
This in-formation is valuable for making the chatbot to ask?intelligent questions?
as a mean of conversationalresponses to keep the interest from the user.In the third stage of the experiment, the informa-tion yielded by the previous analysis, i.e., regard-ing the timing where a topic-shifting utterance mightbe needed, was used to feed the chatbot database.Topic-shifting responses were inserted by hand (su-pervised process) as general patterns (around onehundred patterns) for smoothly change the topicwhen there is not a pattern that matches a given ut-terance.
In this way a bridge, represented in Figure2 by the dummy item, is created giving to the di-alogue the desired smoothness.
Seven users (fournative English speakers, three non native speakers)were requested to perform a chat with the plain chat-bot and with the enhanced chatbot (the users didnot know which chatbot was plain or which was en-hanced).
The time set up was maximum 30 minutes-chat with each program, the user was free to stopat any time before the time limit.
The evaluation ofthe chatbots performances was made through a ques-63Turns % V.R.
* Accuracy/relevanceBaseline 74 21.11% fairEnhanced 128 7.37% goodV.R.
* = Vague Reply (This table contains the average of Turns and VR)Table 1: Chatbots Overall Performancetionnaire given to the users.
In the questionnaire thedegree of satisfaction of the user was surveyed basedon the accuracy/relevance of the chatbot responsesand its ability to keep the dialogue flowing.
The ac-curacy/relevance had a ranking scale: 1. excellent, 2.good, 3. average, 4. fair, and 5. poor, while the user satis-faction ranked : 1. very satisfied, 2. satisfied, 3. not sure, 4.dissatisfied, and 5. very dissatisfied.The four native English speaker users globallyagreed ranking enhanced chatbot as having ?good?accurate/relevant responses during the overall dia-logue, giving remarks like ?interesting to talk with?,?better at keeping the conversation going?, ?easierto talk to?, and ?more impression of consciousness?.In the case of the plain chatbot, the native speakersshowed ?dissatisfied?
at its performance, giving re-marks like ?loop responses?, ?slow in keeping theconversation going?, ?no so nice responses?, ?noconstant memory?.
Table 1 shows a resume of theaverage performance of the chatbot for all of theusers.
An example of a vague reply is given in thefollowing fragment:Chatbot: What is like living in Sapporo?User: sweet asChatbot: In the context of living in Sapporo I don?t under-stand ?what is like living in Sapporo??
[vague reply]Two non native English speaker users ranked theenhanced chatbot as having ?fair?
and ?average?accurate/relevant responses while the plain chat-bot was ranked as having ?poor?
and ?fair?
accu-rate/relevant responses.
The third non native En-glish speaker user ranked both chatbots as ?poor?due to ?the chatbots lack of understanding deixis,and anaphor?.As a mean of discussion, in Figure 2 it could beexpected that the dummy item 1 3 would branchfrom utterance [25] {User: no, you asked me who is thebest robot}, which is in the same cluster with utterance[24].
However, under closer examination it becomesclear that utterance [24] has stronger co-occurrencewith utterance [38] {Chatbot: I know you are but what amI} than utterance [25].
Hence, the algorithm suggeststo link the clusters via utterance [24].In other aspect, based on the feedback given bythe seven users of the experiment, the overall per-formance of the enhanced chatbot can be consideredbetter than the plain chatbot.
It is worth noticingthat the evaluation of the non native English speakerusers tended to emphasize the grammatical aspectof the chatbots responses.
On the other hand, theevaluation of the native English speaker users tendedto emphasize the smoothness of the dialogue.
Al-though there is still plenty of room for improve-ment and research a betterment in the chatbot per-formance could be seen through this approach.4 ConclusionIn this paper the application of a novel data miningmethod, data crystallization, for visualizing missingtopic-shifting utterances during human-computerchat has been described.
Based on this informa-tion, during the experiment, the use of weak localrelevance utterances, i.e., topic-shifting responses,despite of violation of Grecian maxim of local rel-evance, showed to meliorate the overall dialogueflow.
Future research will be oriented to the ex-tended implementation of the obtained results forenhancing the chat flow modeling of a conversa-tional partner program.ReferencesSusan Herring.
1999.
Interactional coherence in cmc.
Journalof Computer Mediated Communication, 4(1).Nobuo Inui, Takuya Koiso, Junpei Nakamura, and YoshiyukiKotani.
2003.
Fully corpus-based natural language dia-logue system.
In Natural Language Generation in Spokenand Written Dialogue, AAAI Spring Symposium.Yukio Ohsawa and Peter McBurney, editors.
2003.
ChanceDiscovery.
Springer, Berlin Heidelberg New York.Yukio Ohsawa.
2005.
Data crystallization: Chance discoveryextended for dealing with unobservable events.
New Mathe-matics and Natural Computation, 1(3):373?392.Calkin S Montero and Kenji Araki.
2005.
Human chat and self-organized criticality: A chance discovery application.
NewMathematics and Natural Computation, 1(3):407?420.Richard Wallace.
2005.
A.l.i.c.e.
artificial intelligence founda-tion.
http://www.alicebot.org.Joseph Weizenbaum.
1966.
Eliza a computer program for thestudy of natural language communication between man andmachine.
Commun.
ACM, 9(1):36?45.64
