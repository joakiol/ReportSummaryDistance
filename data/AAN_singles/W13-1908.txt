Proceedings of the 2013 Workshop on Biomedical Natural Language Processing (BioNLP 2013), pages 63?71,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsEvaluating large-scale text mining applicationsbeyond the traditional numeric performance measuresSofie Van Landeghem1,2, Suwisa Kaewphan3,4, Filip Ginter3, Yves Van de Peer1,21.
Dept.
of Plant Systems Biology, VIB, Belgium2.
Dept.
of Plant Biotechnology and Bioinformatics, Ghent University, Belgium3.
Dept.
of Information Technology, University of Turku, Finland4.
Turku Centre for Computer Science (TUCS), Turku, Finlandsolan@psb.ugent.be, sukaew@utu.figinter@cs.utu.fi, yvpee@psb.ugent.beAbstractText mining methods for the biomedicaldomain have matured substantially andare currently being applied on a largescale to support a variety of applica-tions in systems biology, pathway cura-tion, data integration and gene summa-rization.
Community-wide challenges inthe BioNLP research field provide gold-standard datasets and rigorous evaluationcriteria, allowing for a meaningful com-parison between techniques as well asmeasuring progress within the field.
How-ever, such evaluations are typically con-ducted on relatively small training andtest datasets.
On a larger scale, sys-tematic erratic behaviour may occur thatseverely influences hundreds of thousandsof predictions.
In this work, we per-form a critical assessment of a large-scaletext mining resource, identifying system-atic errors and determining their underly-ing causes through semi-automated analy-ses and manual evaluations1.1 IntroductionThe development and adaptation of natural lan-guage processing (NLP) techniques for thebiomedical domain are of crucial importance tomanage the abundance of available literature.
Theinherent ambiguity of gene names and complex-ity of biomolecular interactions present an intrigu-ing challenge both for BioNLP researchers as wellas their targeted audience of biologists, geneticistsand bioinformaticians.
Stimulating such research,various community-wide challenges have been or-ganised and received international participation.1The supplementary data of this study is freely avail-able from http://bioinformatics.psb.ugent.be/supplementary_data/solan/bionlp13/The BioCreative (BC) challenge (Hirschman etal., 2005; Krallinger et al 2008; Leitner et al2010; Arighi et al 2011) touches upon a variety ofextraction targets.
The identification of gene andprotein mentions (?named entity recognition?)
is acentral task and a prerequisite for any follow-upwork in BioNLP.
Linking these mentions to theirrespective gene database identifiers, ?gene normal-ization?, is a crucial step to allow for integrationof textual information with authoritative databasesand experimental results.
Other BC tasks are en-gaged in finding functional and physical relationsbetween gene products, including Gene Ontologyannotations and protein-protein interactions.Focusing more specifically on the molecu-lar interactions between genes and proteins, theBioNLP Shared Task on Event Extraction (Kim etal., 2009; Kim et al 2011b; Nedellec and others,2013) covers a number of detailed molecular eventtypes, including binding and transcription, regula-tory control and post-translational modifications.Additionally, separate tracks involve specific ap-plications of event extraction, including infectiousdiseases, bacterial biotopes and cancer genetics.Performance of the participants in each of thesechallenges is measured using numeric metricssuch as precision, recall, F-measure, slot errorrate, MAP and TAP scores.
While such rig-urous evaluations allow for a meaningful compar-ison between different systems, it is often difficultto translate these numeric values into a measure-ment of practical utility when applied on a largescale.
Additionally, infrequent but consistent er-rors are often not identified through small-scaleevaluations, though they may result in hundreds ofthousands of wrongly predicted interactions on alarger scale.
In this work, we perform an in-depthstudy of an open-source state-of-the-art event ex-traction system which was previously applied tothe whole of PubMed.
Moving beyond the tra-ditional numeric evaluations, we identify a num-63Figure 1: Example event and relation represen-tations, depicted in solid and dotted lines respec-tively.
Picture by Kim et al(2011a).ber of systematic errors in the large-scale data,analyse their underlying causes, and design post-processing rules to resolve these errors.
We be-lieve these findings to be highly relevant for anypractical large-scale implementation of BioNLPtechniques, as the presence of obvious mistakes ina text mining resource might undermine the credi-bility of text mining techniques in general.2 Data and methodsIn this section, we first describe the data and meth-ods used in previous work for the constructionof the large-scale text mining resource that is thetopic of our error analyses (Section 3).2.1 Event extractionEvent extraction has become a widely studiedtopic within the field of BioNLP following thefirst Shared Task (ST) in 2009.
The ST?09 in-troduced the event formalism as a more detailedrepresentation of the common binary relation an-notation (Figure 1).
Each event occurrence con-sists of an event trigger; i.e.
one or more con-secutive tokens that are linked to a specific eventtype.
While the ST?09 included only 9 event types,among which 3 regulatory event types, the ST?11further broadened the coverage of event extractionto post-translational modifications and epigenetics(EPI).To compose a fully correct event, an event trig-ger needs to be connected to its correct arguments.Within the ST, these arguments are selected from aset of gold-standard gene and gene product anno-tations (GGPs).
The ST guidelines determine anunambiguous formalism to which correct eventsmust adhere: most event types only take one themeargument, while Binding events can be connectedto more than one theme.
Regulation events furtherhave an optional cause slot (Figure 1).
Connectingthe correct arguments to the correct trigger wordsis denoted as ?edge detection?.To perform event extraction, we rely on thepublicly available Turku Event Extraction System(TEES) (Bjo?rne et al 2012), which was origi-nally developed for the ST?09.
The TEES mod-ules for trigger and edge detection are based uponsupervised learning principles, employing supportvector machines (SVMs) for multi-label classifi-cation.
TEES has been shown to obtain state-of-the-art performance when measured on the gold-standard datasets of the Shared Tasks of 2009,2011 and 2013.2.2 Large-scale processingPreviously, the whole of PubMed has been anal-ysed using a large-scale event extraction pipelinecomposed of the BANNER named entity rec-ognizer, the McClosky-Charniak parser, and theTurku Event Extraction System (Bjo?rne et al2010).
BANNER identifies gene and protein sym-bols in text through a machine learning approachbased on conditional random fields (Leaman andGonzalez, 2008).
While the resulting large-scaletext mining resource EVEX was focused only onabstracts and ST?09 event types (Van Landeghemet al 2011), it has matured substantially duringthe past few years and now includes ST?11 EPIevent types, full-text processing and gene normal-ization (Van Landeghem et al 2013a).
In thiswork, we use the version of EVEX as publiclyavailable on 16 March 2013, containing 40 millionevent occurrences among 122 thousand gene andprotein symbols in 22 million PubMed abstractsand 460 thousand PubMed Central full-text arti-cles.
Each event occurrence is linked to a normal-ized confidence value, automatically derived fromthe original TEES SVM classification step and thedistance to the hyperplane of each prediction.While this study focuses on the EVEX resourceas primary dataset, the findings are also highly rel-evant for other large-scale text mining resources,especially those based on supervised learning,such as the BioContext (Gerner et al 2012).2.3 Cross-domain evaluationRecently, a plant-specific, application-oriented as-sessment of the EVEX text mining resource hasbeen conducted by manually evaluating 1,800event occurrences (Van Landeghem et al 2013b).In that study, it was established that the generalperformance rates as measured previously on theST, are transferrable also to other domains and or-ganisms.
Specifically, the 58.5% TEES precision64Event type Five most frequent trigger wordsBinding binding interaction associated bind associationGene expression expression expressed production expressing levelsLocalization secretion release localization secreted localizedProtein catabolism degradation degraded cleavage proteolysis degradeTranscription transcription expression levels transcribed detectedAcetylation acetylation acetylated deacetylation hyperacetylation activationGlycosylation glycosylated glycosylation attached N-linked absenceHydroxylation hydroxylation hydroxylated hydroxylate beta-hydroxylation hydroxylationsMethylation radiation methylation methylated diffractometer trimethylationDNA methylation methylation hypermethylation methylated hypermethylated unmethylatedPhosphorylation phosphorylation phosphorylated dephosphorylation phosphorylates phosphorylateUbiquitination ubiquitination ubiquitinated ubiquitylation ubiquitous polyubiquitinationRegulation effect regulation effects regulated controlPositive regulation increased activation increase induced inductionNegative regulation reduced inhibition decreased inhibited inhibitorCatalysis mediated dependent mediates removes inducedTable 1: The top-5 most frequently tagged trigger words per event type in EVEX.
The first 5 rowsrepresent fundamental event types, the next 7 post-translational modifications (PTMs), and the last 4rows are regulatory event types.
In this analysis, the PTMs and their reverse types are pooled together.Trigger words that refer to systematic errors are in italic and are discussed further in the text.rate measured in the ST?09, with the literature dataconcerning human blood cell transcription factors,corresponded with a 58.6% precision rate for theplant-specific evaluation dataset (?PLEV?).
Thisencouraging result supports the general applicabil-ity of large-scale text mining methods trained onrelatively small corpora.
The findings of this pre-vious study and the resulting data are further inter-preted and analysed in more detail in this study.3 ResultsWhile the text mining pipeline underlying theEVEX resource has been shown to produce state-of-the-art results which are transferrable acrossdomains and organisms, it is conceivable that themere scale of the resource allows the accumula-tion of systematic errors.
In this section, we per-form several targeted semi-automated evaluationsto identify, explain and resolve such cases.
It isimportant to note that our main focus is on im-proving the precision rate of the resource, ratherthan the recall, aiming to increase the credibilityof large-scale text mining resources in general.3.1 Most common triggersThe trigger detection algorithm of the TEES soft-ware is based upon SVM classifiers (Section 2.1),and has been shown to outperform dictionary-based approaches (Kim et al 2009; Kim et al2011c).
To investigate its performance in a large-scale application, we first analyse the most fre-quent trigger words of each event type in EVEX(Table 1).
We notice the presence of different in-flections of the same word as well as related verbsand nouns, such as ?inhibition?, ?inhibited?
and?inhibitor?.
The trigger recognition module suc-cessfully uses character bigrams and trigrams inits SVM classification algorithm to allow for theidentification of such related concepts, even whensome of these trigger words were not encounteredin the training phase (Bjo?rne et al 2009).However, occasionally this approach results inconfusion between words with small edit dis-tances, such as the trigger word ?ubiquitous?
forUbiquitination events.
Similarly, the Acetylationtrigger ?activation?
is found within the context ofa correct event structure in most cases, but shouldactually be of the type Positive regulation.
Theimplementation of custom post-processing rulesto automatically detect and resolve these specificcases would ultimately deal with more than 6,000false-positive event predictions.Further, the trigger ?radiation?
seems to occurfrequently for a Methylation event, of which 82%of the instances can be identified in the ?Exper-imental?
subsection of the article.
The majorityof these articles relate to protein crystallography,and that subsection describes the data from the ex-perimental set-up.
Within such sections, phraseslike ?Mo Kalpha radiation?
are wrongly tagged asMethylation events.
Similarly, many false-positiveMethylation predictions refer to the trigger word?diffractometer?.
Removing these instances fromthe resource would result in the deletion of more65Trigger word s Most frequent type t2 Count Frequency Infrequent type t1 Count Frequencyacetylation Acetylation 40,291 0.298383 Binding 1,332 0.000216Phosphorylation 1,050 0.001045Gene expression 969 0.000093Localization 1,045 0.000579secretion Localization 376,976 0.208888 Acetylation 243 0.001800glycosylation Glycosylation 24,226 0.141052 Phosphorylation 389 0.000387Gene expression 214 0.000020phosphorylation Phosphorylation 589,681 0.586772 Binding 454 0.000074DNA methylation 225 0.001297ubiquitylation Ubiquitination 4961 0.055976 Binding 128 0.000021hypermethylation Methylation 19,501 0.112434 Phosphorylation 365 0.000363cleavage Protein catabolism 20,552 0.073728 Gene expression 2,451 0.000234Binding 3,011 0.000489decreased Negative regulation 374,859 0.062372 Positive regulation 1,721 0.000173Binding 855 0.000139Gene expression 2,928 0.000280reduced Negative regulation 442,400 0.073610 Positive regulation 1,091 0.000110reduction Negative regulation 164,736 0.027410 Positive regulation 389 0.000039absence Negative regulation 65,180 0.010845 Positive regulation 226 0.000071Table 2: Examples of trigger words that correspond to the type which has the highest relative frequency(left), but are also found with much lower frequencies in other types (right).
The instances correspondingto the right-most column can thus be interpreted as wrong predictions.
The full list is available as amachine readible translation table in the supplementary data.than 82,000 false-positive event predictions.Finally, we notice that the trigger word ?ab-sence?
for Glycosylation usually refers to a Neg-ative regulation.
Similarly, some words appear asmost frequent for more than one event type, suchas ?levels?
(Gene expression and Transcription).This type of error in trigger type disambiguationis analysed in more detail in the next section.3.2 Event type disambiguationWhile previous work has focused on the disam-biguation of event types on a small, gold-standarddataset (Martinez and Baldwin, 2011), the rich-ness of a large-scale text mining resource providesadditional opportunities to detect plausible errors.To exploit this large-scale information, we anal-yse all EVEX trigger words and their correspond-ing event types, summarizing their raw event oc-currence counts as Occ(t, s) where t denotes thetrigger type and s the trigger string.
As someevent types are more abundantly described in lit-erature, we normalize these counts to frequen-cies (Freq(t, s)) depending on the total numberof event occurrences per type (Tot(t)):Freq(t, s) =Occ(t, s)Tot(t)withTot(t) =n?i=1Occ(t, si)and n the number of different triggers for eventtype t. We then compare all trigger words and theirrelative frequencies across different event types.First, we inspect those cases where a triggerword appears with comparable frequencies for twoevent types t1 and t2:Freq(t1, s) ?
Freq(t2, s) ?
10?
Freq(t1, s)(1)A first broad category of these cases are trig-ger words that refer to both regulatory and non-regulatory events at the same time, such as ?over-expression?
(Gene expression and Positive regula-tion), or ?ubiquitinates?
(Ubiquitination and Catal-ysis).
The majority of these cases are perfectlyvalid and are in fact modeled explicitly by theTEES software (Bjo?rne et al 2009).Further, we find that two broad groups of non-regulatory event types are semantically similar andshare common trigger words: Methylation andDNA methylation (e.g.
?methylation?, ?unmethy-lated?, ?hypomethylation?
), as well as Gene ex-pression and Transcription (?expression?, ?synthe-sis?, ?levels?
), with occasional overlap also withLocalization (?abundance?, ?found?).
Similarly,trigger words are often shared among the fourregulatory event types (?dependent?, ?role?, ?regu-late?
), as the exact type may depend on the broadercontext within the sentence.While the previous findings do not necessar-66Predicted event typeCurated event type Localization Transcription ExpressionLocalization 15 0 3Transcription 0 12 1Expression 0 2 12No event 0 2 3Total 15 16 19Table 3: Targeted evaluation of 50 mixed events of type Localization, Transcription and Gene expression.The curated event type is compared to the original (hidden) predicted type.ily refer to wrong predictions, we also notice theusage of punctuation marks as trigger words forvarious event types.
This option was specificallyprovided in the TEES trigger detection algorithmas the ST?09 training data contains Binding in-stances with ?-?
as trigger word.
However, thesepunctuation triggers are found to be largely falsepositives in the PubMed-scale event dataset.
Re-moving them in an additional post-processing stepwould result in the filtering of more than 130,000event occurrences, of which the largest part is ex-pected to be incorrect predictions.
Similarly, wecan easily remove 25,000 events that are related totrigger words that are numeric values.In a second step, we analyse those cases wherek ?
Freq(t1, s) ?
Freq(t2, s).
(2)When this condition holds, it can be hypothesizedthat trigger predictions of the word s as type t1are false positives and should have instead been oftype t2.
Automatically generating such lists fromthe data, we have experimentally determined anoptimal value of k = 100 that represents a reason-able trade-off between the amount of false posi-tives that can be identified and the manual workneeded for this.From the resulting list, we can easily identify anumber of such cases that are clearly incorrect (Ta-ble 2, right column).
Specifically, a large numberof Positive regulation events actually refer to Neg-ative regulation, providing an explanation of thelower precision rate of Positive regulation predic-tions in the previous PLEV evaluation (Van Lan-deghem et al 2013b).
This semi-automated de-tection procedure can ultimately result in the cor-rection of more than 242,000 events.The remaining cases for which condition (2)holds are more ambiguous and can not be au-tomatically corrected.
However, these cases aremore likely to be incorrect and their confidencevalues could thus be automatically decreased de-pending on the ratio between Freq(t1, s) andFreq(t2, s).
A general exception to this rule isformed by the broad groups of semantically simi-lar events, such as Transcription-Gene expression-Localization, which we analyse in more detail inthe next section.3.3 Gene expression, Transcription andLocalizationTranscription is a sub-process of Gene expression,with both event types relating to protein produc-tion.
However, the distinction between the two intext may not always be straightforward.
Addition-ally, the ST training data for Transcription eventsis significantly smaller than for Gene expressionevents, which may be the reason why not only theTEES performance, but also those of other sys-tems, is considerably lower for Transcription thanfor Gene expression (Kim et al 2011c).
Further,cell-type specific gene expression should be cap-tured by additional site arguments connected to aLocalization event, which represents the presenceor a change in the location of a protein.To gain a deeper insight into the interplay be-tween these three different event types, we haveperformed a manual curation of 50 event occur-rences, sampled at random from the Gene expres-sion, Transcription and Localization events avail-able in EVEX.
For each event, the trigger wordand the corresponding sentence was extracted, butthe predicted event type was hidden.
An expert an-notator subsequently decided on the correct eventtype of the trigger.
Within this evaluation we fol-lowed the ST guidelines to only annotate Gene ex-pression when there is no evidence for the moredetailed Transcription type.Table 3 shows the results.
All 15 predictedLocalization triggers are recorded to be correct.From the 16 predicted Transcription events, twoinvolve incorrect event triggers, and two otherevents refer to the more general Gene expressiontype (75% overall precision).
Likewise, only oneGene expression event should be of the more spe-67Curated event type Error type Instances (%)1 Single-argument Binding No error 5 10%2 Single-argument Binding Edge detection error 0 0%3 Multiple-argument Binding Edge detection error 4 8%4 Single-argument Binding Entity recognition error 1 2%5 Multiple-argument Binding Entity recognition error 19 38%6 Other Trigger detection error 21 42%Table 4: Targeted evaluation of 50 single-argument Binding event triggers.
Row 1: Fully correct event.Row 2: The correct argument was annotated but not linked.
Row 3: At least one correct multiple-argument Binding event could have been extracted using the annotated entities in the sentence.
Row 4:The correct argument was not annotated.
Row 5: No event could be extracted due to missing argumentannotations.
Row 6: The trigger did not refer to a Binding event.Unannotated entity type Entity occurrence count ExamplesGGP 10 SPF30, spinal muscular atrophy geneGeneric GGP 9 primary antibodies, peptides, RNAChemical compound 10 Ca(2+), iron, manganese(II)Table 5: Manual inspection of the textual entity types for those Binding events where a relevant themeargument was not annotated in the entity recognition step.cific Transcription type, three instances should beLocalization, and three more are considered not tobe correct events at all (63% overall precision).
Ingeneral, we remark that the predicted event typelargely corresponds to the curated type (78% ofall predictions and 87% of all otherwise correctevents).3.4 BindingMoving beyond the event type specification asdetermined by the ST guidelines, the previousPLEV analysis (Section 2.3) has established a re-markable difference between single-argument andmultiple-argument Binding.
In contrast to the reg-ular ST evaluations, this work considered single-and multiple-argument Binding as two separateevent types, resulting in a precision rate of 93% formultiple-argument Binding triggers and only 8%precision for single-argument Binding triggers.As the PLEV study only focused on textualnetwork data, single-argument Bindings were notanalysed further.
In this work however, we fur-ther investigate this performance discrepancy andperform an in-depth manual evaluation to try anddetect the main causes of this systematic error.Several hypotheses can be postulated to explainthe low precision rate of single-argument Bindingevents.
Firstly, a false negative instance of theentity recognition module might result in the ab-sence of annotation for a relevant second interac-tion partner.
Another plausible explanation is anerror by the edge detection module of the eventextraction mechanism, which would occasionallydecide to produce one or several single-argumentBinding events rather than one multiple-argumentBinding, even when all involved entities are cor-rectly annotated.
Finally, it is conceivable thatpredicted single-argument triggers simply do notrefer to Binding events, i.e.
they contain false pos-itive predictions of the trigger detection module ofthe event extraction system.In some cases, one trigger leads to many dif-ferent Binding events, such as the trigger ?bind?in the sentence ?Sir3 and Sir4 bind preferentiallyto deacetylated tails of histones H3 and H4?.
Inthese cases, error types may accumulate: someevents could be missed due to unannotated enti-ties, while others may be due to errors in the edgedetection step.
However, multiple events with thesame trigger word are often represented by verysimilar feature vectors in the classification step,and consequently have almost identical final con-fidence values.
For this reason, we summarize theerror as ?Edge detection error?
as soon as one pairof entities was correctly annotated but not linked,and as ?Entity recognition error?
otherwise.Table 4 summarizes the results of a curationeffort of 50 event triggers linked to a single-argument Binding event in EVEX.
We noticethat in fact, 46% should have been multiple-argument Binding events.
The main underlyingreason for the prediction of an incorrect single-argument Binding event, when it should have beena multiple-argument one, is apparently caused by68Curated event type Error type Instances (%)1 Phosphorylation No error 34 68%2 Phosphorylation Edge detection error 4 8%3 Invalid Phosphorylation Edge detection error 2 4%4 Phosphorylation Edge directionality detection error 4 8%5 Invalid Phosphorylation Edge directionality detection error 1 2%6 Phosphorylation Entity recognition error 3 6%7 Other Trigger detection error 2 4%Table 6: Targeted evaluation of 50 Phosphorylation event triggers and their theme arguments.
Row 1:Fully correct event.
Row 2: The correct argument was annotated but not linked.
Row 3: An argumentwas linked but should not have been.
Row 4: A causal argument was wrongly annotated as the themeargument.
Row 5: A causal argument was wrongly annotated as the theme argument.
Row 6: The correctargument was not annotated.
Row 7: The trigger did not refer to a Phosphorylation event.an entity recognition error (19/23 or 83%), whilean edge detection error is much less frequent(17%).
When we examine these entity recogni-tion errors in more detail, we find that 10 rele-vant entities are true GGPs in the sense of theShared Task annotation.
However, 9 entities referto generic GGPs, and 10 instances relate to chemi-cal compounds (Table 5).
As these type of entitiescan not be unambiguously normalized to uniquegene identifiers, they fall out-of-scope of the orig-inal ST challenge.
However, we feel this practiceintroduces an artificial bias on the classifier andthe evaluation.
Additionally, this information canprove to be of value within a large-scale text min-ing resource geared towards practical applicationsand explorative browsing of textual information.Finally, we notice that a remarkable 42% of allpredicted events contain trigger detection errors.Analysing this subclass in more detail, we foundthat 5 cases are invalid event triggers, 6 cases re-fer to other event types such as Localization andGene expression, and 10 more cases were consid-ered to be out-of-scope of the ST challenge, suchas a factor-disease association.3.5 PhosphorylationWithin the PLEV evaluation (Section 2.3), it be-came apparent that Phosphorylation is easy torecognise from the sentence (98%) but the full cor-rect event has a much lower precision rate (65%).As we have seen in the previous section, evenwhen a trigger word is correctly predicted, errorsmay still be generated by the edge detection or en-tity recognition step.
For instance, we might hy-pothesize that the main underlying reason for thereduced final performance is an error by the en-tity recognition step, forcing the edge detectionmechanism to link an incorrect theme due to lackof other options.
Other plausible explanations in-volve genuine errors by the edge detection algo-rithm when the correct argument is annotated, aswell as problems with the identification of causal-ity.
As the TEES version applied in this work wasdeveloped for the Shared Task 2009 and 2011, itdoes not predict causal arguments for a Phospho-rylation event directly, but instead adds Regulationevents on top of the Phosphorylations.
Occasion-ally, we have noticed that the theme of a Phospho-rylation event should in fact have been the causeof the embedding Regulation association, resultingin a wrongly directed causal relationship.To investigate these possibilities, we have man-ually inspected 50 Phosphorylation events pickedat random from the EVEX resource.
Table 6 sum-marizes the results of this effort.
Only two eventsare found not to be Phosphorylation events: oneis in fact a Gene expression mention, the otherinvolves an incorrect trigger.
Additionally, threemore events can semantically be regarded as Phos-phorylations, but do not follow the ST specifica-tions (?Invalid Phosphorylation?
), for instance be-cause they only mention causal arguments (?aninhibition of Ca2+/calmodulin-dependent proteinphosphorylation?).
Among the 45 cases whichcorrectly refer to the Phosphorylation type, 34events are fully correct (68% of the total).
Fourcases are wrongly extracted by misinterpreting thecausal relationship (?Edge directionality detectionerror?)
and four more instances refer to genuinemistakes of the edge detection algorithm.
Onlythree other cases can be attributed to a missing en-tity annotation.
In contrast to the previous find-ings on single-argument Bindings, we thus es-tablish that the incorrect Phosphorylation eventsare mainly caused by errors in the edge detectionmechanism, which either picks the wrong theme69from the set of annotated GGPs, or misinterpretsthe causality direction.4 Discussion and conclusionWe have performed several semi-automated eval-uations and targeted manual curation experiments,identifying and explaining systematic errors in alarge-scale event dataset.
As a first observation,we notice that a few frequent trigger words arealmost always associated to incorrect event pre-dictions, such as the trigger words ?ubiquitous?and ?radiation?, or a punctuation symbol.
Thesecases were identified through a large-scale auto-matic analysis in combination with a limited man-ual evaluation effort.
The results are distributed asa blacklist of event triggers for the implementationor filtering of future large-scale event predictionsefforts.Further, a semi-automated procedure has iden-tified a list of likely incorrect predictions, bycomparing the type-specific frequencies of triggerwords across all event types.
Manual inspection ofthe most frequent cases allowed us to determine anumber of trigger words for which the event typecan automatically be corrected.
These results arealso made publicly available.Additionally, after removal of the most obvi-ous and frequent errors, a fully automated scriptcan automatically reduce the confidence scores ofthose event occurrences where the trigger wordsare found to be much more frequent for anotherevent type.
We have established that this proce-dure should disregard triggers identified within afew specific semantically similar clusters: DNAmethylation/Methylation, Regulation/Positive reg-ulation/Negative regulation/Catalysis and Geneexpression-Transcription/Localization.
An addi-tional targeted evaluation of these last three typesrevealed that, despite their semantic overlap, thelargest fraction of these predictions refers to thecorrect event type (78?
11.5%).Finally, we note that trigger detection (47 ?14.6%) and entity recognition errors (44?14.6%)are the main causes of wrongly predicted Bind-ing events.
The latter causes the event extractionmechanism to artificially produce single-argumentBindings instead of multiple-argument Bindings.We believe this issue can be resolved by broaden-ing the scope of the entity recognition module togeneric GGPs and chemical compounds, and re-applying the TEES algorithm to these entities asif they were normal GGPs as defined in the STformalism.
In contrast, edge detection errors aremuch more frequently the cause of a wrongly pre-dicted Phosphorylation event (statistically signifi-cant difference with p < 0.05), caused by wronglyidentifying the thematic object or the causality ofthe event.
To resolve this issue, we propose fu-ture annotation efforts to specifically annotate theprotein adding the phosphate group to the targetprotein as a separate class than the regulation ofsuch a phosphorylation process by other cellularmachineries and components (Kim et al 2013).In conclusion, we have performed severalstatistical analyses and targeted manual eval-uations on a large-scale event dataset.
As aresult, we were able to identify a set of rulesto automatically delete or correct a numberof false positive predictions (supplementarymaterial at http://bioinformatics.psb.ugent.be/supplementary_data/solan/bionlp13/).
When applying theserules to the winning submission of the recentST?13 (GE subchallenge), which was basedon the TEES classifier (Hakala et al 2013),3 false positive predictions could be identifiedand removed.
Even though this procedure onlymarginally improves the classification results(50.97% to 50.99% F-score), we believe thecleaning procedure to be crucial specifically forthe credibility of any large-scale text miningapplication.
For example, applied on the EVEXresource, it would ultimately result in the removalof 242,000 instances and a corrected event type of230,000 more cases (1.2% of all EVEX events intotal).
These corrections will be implemented aspart of the next big EVEX release.
Additionally,the confidence score of more than 120,000 am-biguous cases could be automatically decreased.Alternatively, these cases could be the target ofa large-scale re-annotation, for instance usingthe brat annotation tool (Stenetorp et al 2012).The resulting dataset could then serve as a newtraining set to enable active learning on top ofexisting event extraction approaches.AcknowledgmentsThe authors thank Cindy Martens and the anony-mous reviewers for a critical reading of themanuscript and constructive feedback.
SVLthanks the Research Foundation Flanders (FWO)for funding her research.70ReferencesCecilia Arighi, Zhiyong Lu, Martin Krallinger, KevinCohen, J. Wilbur, Alfonso Valencia, LynetteHirschman, and Cathy Wu.
2011.
Overview ofthe BioCreative III workshop.
BMC Bioinformatics,12(Suppl 8):S1.Jari Bjo?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2009.
Ex-tracting complex biological events with rich graph-based feature sets.
In Proceedings of the BioNLP2009 Workshop, pages 10?18.Jari Bjo?rne, Filip Ginter, Sampo Pyysalo, Jun?ichi Tsu-jii, and Tapio Salakoski.
2010.
Scaling up biomed-ical event extraction to the entire PubMed.
In Pro-ceedings of the BioNLP 2010 Workshop, pages 28?36.Jari Bjo?rne, Filip Ginter, and Tapio Salakoski.
2012.Generalizing biomedical event extraction.
BMCBioinformatics, 13(suppl.
8):S4.Martin Gerner, Farzaneh Sarafraz, Casey M. Bergman,and Goran Nenadic.
2012.
BioContext: an in-tegrated text mining system for large-scale extrac-tion and contextualization of biomolecular events.Bioinformatics, 28(16):2154?2161.Kai Hakala, Sofie Van Landeghem, Tapio Salakoski,Yves Van de Peer, and Filip Ginter.
2013.
EVEXin ST13: Application of a large-scale text miningresource to event extraction and network construc-tion.
In Proceedings of the BioNLP Shared Task2013 Workshop (in press).Lynette Hirschman, Alexander Yeh, ChristianBlaschke, and Alfonso Valencia.
2005.
Overviewof BioCreAtIvE: critical assessment of informa-tion extraction for biology.
BMC Bioinformatics,6(Suppl 1):S1.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Jun?ichi Tsujii.
2009.
Overviewof BioNLP?09 Shared Task on event extraction.
InProceedings of the BioNLP 2009 Workshop, pages1?9.Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshi-nobu Kano, and Junichi Tsujii.
2011a.
Ex-tracting bio-molecular events from literature - theBioNLP?09 Shared Task.
Computational Intelli-gence, 27(4):513?540.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, Ngan Nguyen, and Jun?ichi Tsujii.
2011b.Overview of BioNLP Shared Task 2011.
In Pro-ceedings of the BioNLP Shared Task 2011 Work-shop, pages 1?6.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-nori Yonezawa.
2011c.
Overview of Genia eventtask in BioNLP Shared Task 2011.
In Proceedingsof the BioNLP Shared Task 2011 Workshop, BioNLPShared Task ?11, pages 7?15.Jin-Dong Kim, Yue Wang, Yamamoto Yasunori,Sabine Bergler, Roser Morante, and Kevin Cohen.2013.
The Genia Event Extraction Shared Task,2013 edition - overview.
In Proceedings of theBioNLP Shared Task 2013 Workshop (in press).Martin Krallinger, Alexander Morgan, Larry Smith,Florian Leitner, Lorraine Tanabe, John Wilbur,Lynette Hirschman, and Alfonso Valencia.
2008.Evaluation of text-mining systems for biology:overview of the second BioCreative communitychallenge.
Genome Biology, 9(Suppl 2):S1.Robert Leaman and Graciela Gonzalez.
2008.
BAN-NER: an executable survey of advances in biomedi-cal named entity recognition.
Pacific Symposium onBiocomputing.
Pacific Symposium on Biocomputing,pages 652?663.F.
Leitner, S.A. Mardis, M. Krallinger, G. Cesareni,L.A.
Hirschman, and A. Valencia.
2010.
Anoverview of BioCreative II.5.
Computational Bi-ology and Bioinformatics, IEEE/ACM Transactionson, 7(3):385?399.David Martinez and Timothy Baldwin.
2011.
Wordsense disambiguation for event trigger word detec-tion in biomedicine.
BMC Bioinformatics, 12(Suppl2):S4.Claire Nedellec et al2013.
Overview of BioNLPShared Task 2013.
In Proceedings of the BioNLPShared Task 2013 Workshop (in press).Pontus Stenetorp, Sampo Pyysalo, Goran Topic?,Tomoko Ohta, Sophia Ananiadou, and Jun?ichi Tsu-jii.
2012. brat: a web-based tool for NLP-assistedtext annotation.
In Proceedings of the Demonstra-tions at the 13th Conference of the European Chap-ter of the Association for Computational Linguistics,pages 102?107.Sofie Van Landeghem, Filip Ginter, Yves Van de Peer,and Tapio Salakoski.
2011.
EVEX: a PubMed-scaleresource for homology-based generalization of textmining predictions.
In Proceedings of the BioNLP2011 Workshop, pages 28?37.Sofie Van Landeghem, Jari Bjo?rne, Chih-Hsuan Wei,Kai Hakala, Sampo Pyysalo, Sophia Ananiadou,Hung-Yu Kao, Zhiyong Lu, Tapio Salakoski, YvesVan de Peer, and Filip Ginter.
2013a.
Large-scale event extraction from literature with multi-level gene normalization.
PLoS ONE, 8(4):e55814.Sofie Van Landeghem, Stefanie De Bodt, Zuzanna J.Drebert, Dirk Inz, and Yves Van de Peer.
2013b.The potential of text mining in data integration andnetwork biology for plant research: A case study onarabidopsis.
The Plant Cell, 25(3):794?807.71
