The Effects of Lexical Specialization onthe Growth Curve of the VocabularyR.
Hara ld  Baayen*Max Planck Institute forPsycholinguisticsThe number of different words expected on the basis of the urn model to appear in, for example,the first half of a text, is known to overestimate he observed number of different words.
Thispaper examines the source of this overestimation bias.
It is shown that this bias does not arisedue to sentence-bound syntactic onstraints, but that it is a direct consequence oftopic cohesionin discourse.
The nonrandom, clustered appearance of lexically specialized words, often the keywords of the text, explains the main trends in the overestimation bias both quantitatively andqualitatively.
The effects of nonrandomness are so strong that they introduce an overestimationbias in distributions of units derived from words, such as syllables and digrams.
Nonrandomword usage also affects the accuracy of the Good-Turing frequency estimates which,for the lowestfrequencies, reveal a strong underestimation bias.
A heuristic adjusted frequency estimate isproposed that, at least for novel-sized texts, is considerably more accurate.1.
IntroductionWhen reading through a text, word token by word token, the number of different wordtypes encountered increases, quickly at first, and ever more slowly as one progressesthrough the text.
The number of different word types encountered after reading Ntokens, the vocabulary size V(N), is a function of N. Analytical expressions for V(N)based on the urn model are available.
A classic problem in word frequency stud-ies is, however, that these analytical expressions tend to overestimate he observedvocabulary size, irrespective of whether these expressions are nonparametric (Good1953; Good and Toulmin 1956; Muller 1979; Brunet 1978) or parametric (Sichel 1986;Khmaladze and Chitashvili 1989; Chitashvili and Baayen 1993) in nature.Although the theoretical or expected vocabulary size E\[V(N)\] generally is of thesame order of magnitude as the observed vocabulary size, the lack of precision oneobserves time and again casts serious doubt on the reliability of a number of mea-sures in word frequency statistics.
For instance, Baayen (1989, 1992) and Baayen andRenouf (1996) exploit the Good-Turing estimate for the probability of sampling un-seen types (Good 1953) to develop measures for the degree of productivity of affixes,Baayen and Sproat (to appear) apply this Good-Turing estimate to obtain enhancedestimates of lexical priors for unseen words, and the Good-Turing estimates also playan important role for estimating population probabilities (Church and Gale 1991).
If asimple random variable such as the vocabulary size reveals consistent and significantdeviation from its expectation, the accuracy of the Good-Turing estimates i also calledinto question.
The aim of this paper is to understand why this deviation between the-* Wundtlaan 1,6525 XD Nijmegen, The Netherlands.
E-mail: baayen@mpi.nl(~) 1996 Association for Computational LinguisticsComputational Linguistics Volume 22, Number 4ory and observation arises in word frequency distributions, and in this light evaluateapplications of the Good-Turing results.The remainder of this paper is structured as follows.
In Section 2, I introduce somebasic notation and the expressions for the growth curve of the vocabulary with whichwe will be concerned throughout, including a model proposed by Hubert and Labbe(1988), which, by introducing a smoothing parameter, leads to much-improved fits.
Un-fortunately, this model is based on a series of unrealistic simplifications, and cannotserve as an explanation for the divergence between the observed and expected vocab-ulary size.
In Section 3, therefore, I consider a number of possible sources for the misfitin greater detail: nonrandomness at the sentence level due to syntactic structure, non-randomness due to the discourse structure of the text as a whole, and nonrandomnessdue to thematic ohesion in restricted sequences of sentences (paragraphs).
Section 4traces the implications of the results obtained for distributions of units derived fromwords, such as syllables and digrams, and examines the accuracy of the Good-Turingfrequency estimates.
A list of symbols is provided at the end of the paper.2.
The Growth Curve of the VocabularyLet N be the size of a text in word tokens, and let V denote the total number of differentword types observed among the N word tokens.
Roughly half of the word types occuronly once, the so-called hapax legomena, others occur with higher frequencies) LetV(N, 1) denote the number of once-occurring types among N tokens, and, similarly,let V(N,f) denote the number of types occurringf times after sampling N tokens.
Theexpected number of different ypes E\[V(M)\] for M < N conditional on the frequencyspectrum {V(N,f)},f -- 1, 2, 3,... can be estimated byF.\[V(M)\] =V- (1- M) s.f(1)A proof for (1) is presented in the appendix.Figure 1 illustrates the problems that arise when (1) is applied to three texts, Alicein Wonderland, by Lewis Carroll (upper panels), Moby Dick by Herman Melville (middlepanels), and Max Havelaar by Multatuli (the pseudonym of Eduard Douwes Dekker,bottom panels).
2All panels show the sample size N on the horizontal axis.
Thus thehorizontal axis can be viewed as displaying the "text time" measured in word tokens.The vertical axis of the left-hand panels shows the number of observed word types(dotted line) and the number of types predicted by the model (solid line) obtainedusing (1).
These panels reveal that the expected vocabulary size overestimates theobserved vocabulary size for almost all of the 40 equidistant measurement points.
Tothe eye, the overestimation seems fairly small.
Nevertheless, in absolute terms theexpectation may be several hundreds of types too high, and may run up to 5% of thetotal vocabulary size.1 The type definition I have used throughout is based on the orthographic word form: house and housesare counted as two different types, houses and houses as two tokens of the same type.
No lemmatizationhas been attempted, first, because the probabilistic aspects of the problem considered here are notaffected by whether or not lemmatization is carried out, and second, because it is of interest toascertain how much information can be extracted from texts with minimal preprocessing.2 These texts were obtained by anonymous ftp from the Project Gutenberg at obi.std.com.
The header ofthe electronic version of Moby Dick requires mention of E.F. Tray at the University of Colorado,Boulder, who prepared the text on the basis of the Hendricks House Edition.456Baayen Lexical SpecializationLewis Carroll0 5000 10000 15000 20000 25000NHerman Melville0 50000 1000O0 150O00 200000NMultatuliAlice in Wonderland0 5000 10OO0 15OOO 20000 25000NMoby Dick>~0 50000 1000C0 150000 2000000 20000 40000 60000 80000 100000N NNMax Havelaaro88 I 0000 ^000" 100000 T 0 20000 40000 6 8UFigure 1The growth curve of the vocabulary.
Observed vocabulary size V(N) (dotted lines) andexpected vocabulary size E\[V(N)\] (solid lines) for three novels (left-hand panels) and thecorresponding overstimation errors E\[V(N)\] - V(N) (dotted lines) and theirsentence-randomized v rsions ("+"-lines, see Section 3.1) (right-hand panels).The right-hand panels of Figure I show the overestimation error functions E\[V(N)\]- V(N) corresponding to the left-hand panels using dotted lines.
For the first 20 mea-surement points, the instances for which E\[V(N)\] diverges significantly from V(N)are shown in bold.
3 Clearly, the divergence is significant for almost all of the first 20measurement points.
This suggests informally that the discrepancy between E\[V(N)\]and V(N) is significant over a wide range of sample sizes.2.1 The Mode l  Proposed by Hubert and LabbeThe problem of the systematic estimation error of E\[V(N)\] has been pointed out byMuller (1979) and Brunet (1978), who hypothesize that lexical specialization is at issue.In any text, there are words the use of which is mainly or even exclusively restrictedto a given subsection of that text.
Such locally concentrated clusters of words are atodds with the randomness assumption underlying the derivation of (1), and may bethe cause of the divergence illustrated in Figure 1.
Following this line of reasoning,Hubert and Labbe (1988) propose a model according to which (1) should be modified3 Since the expression for an estimate of the variance of V(N) figuring in the Z-scores used here requiresknowledge of E\[V(2N)\], the significance ofthe divergence for the second 20 measurement points is notavailable.
For technical details, see Chitashvili and Baayen (1993).457Computational Linguistics Volume 22, Number 4as follows (see the appendix for further details):M (1 p)V-  (1 - p) ~V(N, f )  1 - .
EHL\[V(M)\] = p--~V + - f (2)Hubert and Labbe's model contains one free parameter, the coefficient of vocabu-lary partition p, an estimate of the proportion of specialized words in the vocabulary.Given K different ext sizes for which the observed and expected vocabulary sizes areknown, p can be estimated by minimizing the mean squared error (MSE)K V - ~k=l ( (Mk)  E\[V(Mk)\]) 2K (3)or the chi-square statisticK (V(Mk) - E\[V(Mk)\]) 2~ ~-~-~-~ (4)k=l(conveniently ignoring that the variance of V(M) increases with M, see Chitashviliand Baayen \[1993\]).
For Alice in Wonderland, minimalization of (4) for K = 40 leads top = 0.16, and according to this rough estimate of goodness-of-fit the revised modelfits the data very well i ndeed (X~39) 7- 3.58, p > 0.5).
For Moby Dick, however, the chi-squared statistic suggests a significant difference between the observed and expectedvocabulary sizes (X~39) = 172.93,p < 0.001), even though the value of the p parame-ter (0.12) leads to a fit that is much improved with respect o the unadjusted growthcurve  (X~39) = 730.47).
Closer inspection of the error pattern of the adjusted estimatereveals the source of the misfit: for the first 12 measurement points, the observedvocabulary size is consistently overestimated.
From the 14th observation onwards,the Hubert-Labbe model consistently underestimates the real vocabulary size.
Appar-ently, the development of the vocabulary in Moby Dick can be modeled globally, butlocal fluctuations introducing additional points of inflection into the growth curve areoutside its scope--a more detailed study of the development of lexical specializationin the narrative is required if the appearance of these points of inflection are to beunderstood.In spite of this deficiency, the Hubert-Labbe curve appears to be an optimalsmoother, and this suggests that the value obtained for the coefficient of vocabularypartition p is a fairly reliable estimate of the extent o which a text is characterized bylexical specialization.
In this light, the evaluation by Holmes (1994), who suggests thatp might be a useful discriminant for authorship attribution studies, is understandable.Unfortunately, the assumptions underlying (2) are overly simplistic, and seriously callinto question the reliability of p as a measure of lexical specialization, and the sameholds for the explanatory value of this model for the inaccuracy of E\[V(N)\].2.2 Problems with the Hubert and Labbe ModelOne highly questionable simplification underlying the derivation of (2) spelled out inthe appendix is that specialized words are assumed to occur in a single text slice only.Consider Figure 2, which plots the number of times Ahab appears in 40 successive,equally sized text slices that jointly constitute the full text of Moby Dick.
The dottedline reveals the main developmental pattern (time-series moothing using runningmedians).
Even though Ahab is one of the main characters in Moby Dick, and eventhough his name certainly belongs to the specialized vocabulary of the novel, Ahab is458Baayen Lexical Specializationp-o/...?
/!
?/// !
./i.~.....--, ............ ,/ '/ ./.
// "/?
f?
.
?""";....'...~...'""."""
?text sl icei":/o .6 lb 20 d0 40Figure 2Nonrandom word usage illustrated for Ahab in Moby Dick.
The horizontal axis plots the 40equally sized text slices, the vertical axis the frequency of Ahab in these text slices.
The dottedline represents a time-series moother using running medians (Tukey 1977).not mentioned by name in one text slice only, as the Hubert-Labbe model would have.What we find is that he is not mentioned at all in the first five text slices.
Followingthis we observe a series of text slices in which he appears frequently.
These are in turnsucceeded by slices in which Ahab is hardly mentioned, but he reappears in the lastpart of the book, and as the book draws to its dramatic lose, the frequency of Ahabincreases to its maximum.
This is an illustration of what Indefrey and Baayen (1994)refer to as inter-textual cohesion: the word Ahab enjoys specialized use, but it occursin a series of subtexts within the novel as a whole, contributing to its overall cohesion.Within text slices where Ahab is frequently mentioned, the intra-textual cohesion maysimilarly be strengthened.
For instance, Ahab appears to be a specialized word in textslice 23, but he is mentioned only in passing in text slice 25.
His appearance in the twotext slices strengthens the intertextual cohesion of the whole novel, but it is only theintra-textual cohesion of slice 23 that is raised.
The presence of inter-textual cohesion inaddition to intra-textual cohesion and the concomitant phenomenon of global lexicalspecialization suggest that in order to understand the discrepancy between V(N) andits expectation, a more fine-grained approach is required.A second question concerns how lexical specialization affects the empirical growthcurve of the vocabulary.
Inspection of plots such as those presented in Figure 1 for Al-ice in Wonderland suggests that the effects of lexical specialization appear in the centralsections of the text, as it is there that the largest differences between the expected andthe observed vocabulary are to be observed--differences that are highly penalized bythe MSE and chi-squared techniques used to estimate the proportion of specializedwords in the vocabulary.
Unfortunately, the central sections are not necessarily theones characterized by the highest degree of lexical specialization.
To see this, considerFigure 3, which plots the difference between the expected number of new types using459Computational Linguistics Volume 22, Number 40"~1" "0Qoo6 lb 2'0 do 4'0kFigure 3Error scores for the influx of new types in Alice in Wonderland.
The k -- 1, 2 .
.
.
.
.
40 text slicesare displayed on the horizontal axis, the progressive difference scores D(k) are shown on thevertical axis.
The dashed line represents a nonparametric s atterplot smoother (Cleveland1979), the dotted line a least squares regression line (the negative slope is significant,F(1,38) = 11.07,p < .002).
(1) and the observed number of new types for the successive text slices of Alice in Won-derland.
More precisely, for each text slice k, k = 1 .
.
.
.
.
40, we calculate the progressivedifference error scores D(k), k = 1. .
.
40:D(k)  = {E\[V(Mk)\]  - E \ [V(Mk_ I ) \ ]}  - {V(Mk)  - V (Mk_ , )} .
(5)Note that in addition to positive difference scores, which should be present given thatE\[V(Mk)\] > V(Mk) for most, or, as in Alice in Wonderland, for all values of k, we alsohave negative difference scores.
Text slices containing more types than expected underchance conditions are necessarily present given the existence of text slices k for whichE\[V(Mk)\] - V(Mk) > 0: the total number of types accumulated over the 40 text slices hasto sum up to V(N).
Figure 3 shows that the expected numbers of new word types areoverestimated for the initial part of the novel, that the theoretical estimates are fairlyreliable for the middle section of the novel, while the final chapters how a slightlygreater increase in the number of new types than expected under chance conditions.If lexical specialization affects the influx of new types, its effects appear not in thecentral sections of the novel as suggested by Figure 1, but rather in the beginning andperhaps at the end.
This finding seriously questions the appropriateness of using thegrowth curve of the vocabulary for deriving a measure of lexical specialization.A third question arises with respect o how one's measure of lexical concentrationis affected by the number of text slices K. In Hubert and Labbe's model, the optimalvalue of the p parameter is independent of the number of text slices K for not-too-small K (K > 10).
Since the expected growth curve and the observed growth curveare completely fixed and independent of K--the former is fully determined by the fre-460Baayen Lexical Specializationquency spectrum of the complete text, the latter is determined by the text itself--thechoice of K influences only the number of points at which the divergence betweenthe two curves is measured.
Increasing the number of measurement points increasesthe degrees of freedom along with the deviance, and the optimal value of the p pa-rameter emains virtually unchanged.
But is this a desirable property for a measureof lexical specialization?
Even without aking the effects of inter-textual cohesion intoaccount, and concentrating solely on local specialization and intra-textual cohesion,formulating lexical specialization i terms of concentration at a particular point in thetext is unrealistic: it is absurd to assume that all tokens of a specialized word appear inone chunk without any other intervening words.
A more realistic definition of (local)lexical specialization is the concentration f the tokens of a given word within a par-ticular text slice.
In such an approach, however, the size of the text slice is of crucialimportance.
A word appearing only in the first half of a book enjoys ome specializeduse, but to a far lesser extent han a word with the same frequency that occurs in thefirst half of the first chapter only.
In other words, an approach to lexical specializationin terms of concentration f use is incomplete without a specification of the unit ofconcentration itself.3.
Sources of NonrandomnessTo avoid these problems, I will now sketch a somewhat more fine-grained approach tounderstanding why V(N)  and its expectation diverge, adopting Hubert and Labbe'scentral insight that lexical specialization can be modeled in terms of local concentra-tion.
Consider again the potential sources for violation of the randomness assumptionunderlying the derivation of E\[V(N)\].
At least three possibilities uggest themselves:syntactic onstraints on word usage within sentences, global discourse organization,and local repetition.
I will consider these possibilities in turn.3.1 Syntactic ConstraintsSyntactic onstraints at the level of the sentence introduce many restrictions on theoccurrence ofwords.
For instance, in normal written English, following the determinerthe the appearance ofa second instance of the same determiner (as in this sentence), isextremely unlikely.
According to the urn model, however, such a sequence is likely tooccur once every 278 words (the relative frequency of the in English is approximately0.06), say once every two pages.
This is not what we normally find.
Clearly, syntaximposes evere constraints on the occurrence of words.
Does this imply that the urnmodel is wrong?
For individual sentences, the answer is undoubtedly yes.
But for moreglobal textual properties uch as vocabulary size, a motivated answer is less easy togive.
According to Herdan (1960, 40), reacting to Halle's criticism of the urn model asa realistic model for language, there is no problem, since statistics is concerned withform, not content) Whatever the force of this argument may be, Figure 1 demonstratesclearly that the urn model acks precision for our data.In order to ascertain the potential relevance of syntactic onstraints referred to byHalle, we may proceed as follows: If sentence-level syntax underlies the misfit betweenthe observed and the expected vocabulary size, then this misfit should remain visiblefor randomized versions of the text in which the sentences have been left unchanged,but in which the order of the sentences has been permuted.
If the misfit disappears,4 M. Halle, "In defence ofthe number two," in Studies Presented toJ.
Whatmough, The Hague, 1957, quotedin Herdan, 1960, page 40.461Computational Linguistics Volume 22, Number 4we know that constraints the domain of which are restricted to the sentence can beruled out.The results of this randomization test applied to Alice in Wonderland, Moby Dick,and Max Havelaar are shown in the right-hand panels of Figure 1 by means of "+"symbols.
What we find is that following sentence randomization, all traces of a sig-nificant divergence between the observed and expected vocabulary size disappear.The differences between E\[V(N)\] and V(N) are substantially reduced and may remainslightly negative, as in Alice in Wonderland, or slightly positive, as for Moby Dick, orthey may fluctuate around zero in an unpredictable way, as in Max Havelaar.
Sincewe are left with variation that is probably to be attributed to the particularities of theindividual randomization orders, we may conclude that at the global evel of the textas an (unordered) aggregate of sentences, the randomness assumption remains rea-sonable.
The nonrandomness at the level of sentence structure does not influence theexpected vocabulary size.
As a global text characteristic, t is probably insensitive tothe strictly local constraints imposed by syntax.
Apparently, it is the sequential orderin which sentences actually appear that crucially determines the bias of our theoreticalestimates.
There are at least two domains where this sequential order might be rele-vant: the global domain of the discourse structure of the text as a whole, and the morelocal domain of relatively small sequences of sentences sharing a particular topic.To explore these two potential explanatory domains in detail, we need a methodfor linking topical discourse structure and local topic continuity with word usage.Lexical specialization, informally defined as topic-linked concentrated word usage,and formalized in terms of underdispersion, provides us with the required tool.3.2 Lexical SpecializationRecall that the word Ahab is unevenly distributed in Moby Dick.
Given its high fre-quency (510), one would expect it to occur in all 40 text slices, but it does not.
In fact,there are 11 text slices where Ahab is not mentioned at all.
Technically speaking, Ahabis underdispersed.
If there are many such words, and if these underdispersed wordscluster together, the resulting deviations from randomness may be substantial enoughto become visible as a divergence between the observed and theoretical growth curvesof the vocabulary.In order to explore this intuition, we need a reliable way to ascertain whether aword is underdispersed.
Let the dispersion di of a word ~d i be the number of differenttext slices in which Od i appears.
Analytical expressions for E\[di\] and VAR\[di\] are avail-able (Johnson and Kotz 1977, 113-114), so that In principle Z-scores can be calculated.These Z-scores can then be used to ascertaIn which words are significantly underdis-persed in that they occur in significantly too few text slices given the urn model (cf.Baayen, 1996).
Unfortunately, dispersions deviate substantially from normality, so thatZ-scores remain somewhat impressionistic.
I have therefore used a randomization testto ascertain which words are significantly underdispersed.The randomization test proceeded as follows: The sequence of words of a text wasrandomized 1,000 times.
For each permutation, the dispersion of each word type inthat particular permutation was obtained.
For each word, we calculated the propor-tion of permutations for which the dispersion was lower than or equal to the empiricaldispersion.
For Ahab, all 1,000 permutations revealed full dispersion (d -- 40), whichsuggests that the probability that the low empirical dispersion of Ahab (d = 28) is dueto chance is (much) less than .001.
5The content words singled out as being signifi-5 I am indebted  to an  anonymous  referee for  po in t ing  out  to me that  Z -scores  are  imprec ise .
I am462Baayen Lexical Specializationcantly underdispersed at the 1% level (the significance level I will use throughout thisstudy for determining underdispersion) reveal a strong tendency to be key words.
Forinstance, for Moby Dick, the ten most frequent underdispersed content words are Ahab,boat, captain, said, white, Stubb, whales, men, sperm, and Queequeg.
The five most frequentunderdispersed function words are you, ye, such, her, and any.
6The number of chunks in which an underdispersed word appears, and the fre-quencies with which such a word appears in the various chunks, cannot be predictedon the basis of the urn model.
(Instead of the binomial or Poisson models, the neg-ative binomial has been found to be a good model for such words, see, e.g., Churchand Gale \[1995\]).
Before studying how these words appear in texts and how they af-fect the growth curve of the vocabulary, it is useful to further refine our definition ofunderdispersion.Consider again the distribution of the word Ahab in Figure 2.
In text slice 25,Ahab occurs only once.
Although this single occurrence contributes to the inter-textualcohesion of the novel as a whole, it can hardly be said to be a key word within textslice 25.
In order to eliminate such spurious instances of key words, it is useful to seta frequency threshold.
The threshold used here is that the frequency of the word in agiven text slice should be at least equal to the mean frequency of the word calculatedfor the text slices in which the word appears.
More formally, let~,k be the frequency ofthe i-th word type in the k-th text slice, and define the indicator variable di, k as follows:1 iff ~/ ~ fi,k and a;i underdispersed (6)di'k = 0 otherwise .The number of underdispersed types in text slice k, VU(k), and the correspondingnumber of underdispersed tokens, NU(k), can now be defined asVU(k) : ~_~di,k (7)iNU(k) = Y~di,k'fi,k.
(8)i3.3 Lexical Specialization and Discourse StructureWe are now in a position to investigate where underdispersed words appear andhow they influence the observed growth curve of the vocabulary.
First consider Fig-ure 4, which summarizes a number of diagnostic functions for Alice in Wonderland.The upper panels plot VU(k) (left) and NU(k) (right), the numbers of underdispersedtypes and tokens appearing in the successive text chunks.
Over sampling time, weobserve a slight increase in both the numbers of tokens and the numbers of types.Both trends are significant according to least squares regressions, represented by dot-ted lines (F(1,38) = 6.591,p < .02 for VU(k); F(1,38) = 16.58,p < .001 for NU(k)).
Atime-series smoother using running medians (Tukey 1977), represented by solid lines,similarly indebted to Fiona Tweedie, who suggested the use of the randomization test.
Comparison ofthe results based on Z-scores (see Baayen, to appear) and the results based on the randomization test,however, reveal only minor differences that leave the main patterns in the data unaffected.6 The present method of finding underdispersed words appears to be fairly robust with respect to thenumber of text slices K. For different numbers of text chunks, virtually the same high-frequency wordsappear to be underdispersed.
The number of text chunks exploited in this paper, 40, has been chosen toallow patterns in "sampling time" to become visible without leading to overly small text slices for thesmaller texts.463Computational Linguistics Volume 22, Number 4Alice in Wonder land?
.
.
.
.
.> ?~I : - " - - - ,  "~' , , -  - ~" , I0 10 20 30 40kSeries : VU0 0 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.T , I  " .
, , .V i i  ..... i , .z ~ t .
~ -  " "  " "10 10 20 30 40kSeries : NUI 1- i~  .
.
.
.
.
.
.
.
.
.
.
.
'.
.
.
.
.
.
.
~ .
.
.
.
.
.
'...i .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
: .
.
: _ ' .
.
.
. '
J0 5 10 15 0 5 10 15Lag Lag- ==.
l  - , .~'o~\[ .
.
.
.
_ , ~ .
.
.
.
.
.
, ,  ...... ~ ~1 ?
, , "  ,~- .
/ .
.
.
.
- - - 'M .
- - - - - - I  .~ ._ , .
.
----,- .-,,,.. : : ;~ .
t -~  ....... 1--.- .
- - , .
, , ,  .
-71m i ~ ' 0 1  i ?
?
?
i0 10 20 30 40 a.
0 10 20 30 40k k~ O  ?
? ""
.
?
, ? "
' ?
?
,  .
/0 10 20 30 40 0 10 20 30 40k kFigure 4Diagnostic functions for Alice in Wonderland.
VU(k) and NU(k): numbers of underdispersedtypes and tokens in text slice k; ACF: auto-correlation function; Pr(U, type) and Pr(U, token):proportions of underdispersed types and tokens; D(k) and DU(k): progressive differencescores for the overall vocabulary and the underdispersed words.suggests a slightly oscillating pattern.
At least for a time lag of 1, this finds some sup-port in the autocorrelation functions, shown in the second line of panels of Figure 4.Clearly, key words are not uniformly distributed in Alice in Wonderland.
Not only doesthe use of key words in one text slice appear to influence the intensity with which keywords are used in the immediately neighboring text slices, but as the novel proceedskey words appear with increasing frequency.How does this nonrandom organization of key words in the discourse as a wholeinfluence V(N)?
To answer this question, it is convenient to investigate the nature ofthe new types that arrive with the successive text slices.
LetAV(Mk) = V(Mk) - V(Mk_~) (9)denote the number of new types observed in text slice k, and letaVU(Mk) = VU(Mk)  - -  VU(Mk_,) (10)denote the number of new underdispersed types for text slice k. The proportion of newunderdispersed types in text slice k on the total number of new types, Pr(U, type, k)is given byAVU(k) (11)Pr(U, type, k ) -  AV(k)The plot of Pr(U, types, k) is shown on the third row of Figure 4 (left-hand panel).According to a least squares regression (dotted line), there is a significant increase in464Baayen Lexical Specializationthe proportion of underdispersed new types as k increases (F(1, 38) = 5.804, p < .05).The right-hand side counterpart shows a similar trend for the word tokens that is alsosupported by a least squares regression (F(1, 38) = 5.681, p < .05).
Here, the proportionof new underdispersed tokens on the total number of new tokens is defined asPr(U, token, k) - Y~i nUi,k (12)~-'~i n ,k "withandk-1ni,k = fi,k iff ~m=lfi,m = 0 (13)0 otherwise,I k-1nUi,k = fi,k iff ~m=lfi, m = 0 and di,k = 1 (14)0 otherwise.The increase in the proportions of new underdispersed types and tokens shows thatthe pattern observed for the absolute numbers of types and tokens observed in thetop panels of Figure 4 persists with respect to the new types and tokens.We can now test to what extent he underdispersed types are responsible for thedivergence of E\[V(N)\] and its expectation by comparing the progressive differencescores D(k) defined in (5) with the progressive difference scores for the subset of theunderdispersed words DU(k), defined asDU(k) = E\[VU(k)\] - E\[VU(k - 1)\] - AVU(k).
(15)The two progressive difference score functions are shown in the bottom left panel ofFigure 4, and the residuals D(k) - DU(k) are plotted in the bottom right-hand panel.The residuals do not reveal any significant trend (F(1, 38) < 1), which suggests that theunderdispersed vocabulary is indeed responsible for the main trend in the progressivedifference scores D(k) of the vocabulary and hence for the divergence between E\[V(N)\]and V(N).
In the next section, I will argue that intra-textual cohesion is in large partresponsible for the general downward curvature of DU(k).
In what follows, I will firstpresent an attempt to understand the differences in the error scores E\[V(N)\] - V(N)shown in Figure 1 as a function of differences in the use of key words at the discourselevel.In Alice in Wonderland, key words are relatively rare in the initial text slices.
Asa result, these text slices reveal fewer types than expected under chance conditions.Consequently, V(N) is smaller than E\[V(N)\].
For increasing k, as shown in the up-per right panel of Figure 1, the divergence between V(N) and its expectation firstincreaseswthe initial text slices contain the lowest numbers of underdispersed typesand tokens--and then decreases as more and more underdispersed words appear.Thus the semi-circular shape of the error scores E\[V(N)\] - V(N) shown in Figure 1 isa direct consequence of the topical structure at discourse level of Alice in Wonderland.The error scores E\[V(N)\] - V(N) for Moby Dick and Max Havelaar shown in Fig-ure 1 reveal a different developmental profile.
In these novels, the maximal diver-gence appears early on in the text, after which the divergence decreases until, justbefore the end, V(N) becomes even slightly larger than its expectation.
Is it possibleto understand this qualitatively different pattern in terms of the discourse structureof these novels?
First, consider Moby Dick.
A series of diagnostic plots is shown inFigure 5.
The numbers of underdispersed types and tokens VU(k) and NU(k) revealsome variation, but unlike in Alice in Wonderland, there is only a nonsignificant trend465Computational Linguistics Volume 22, Number 4Moby Dicko 1>?0/  ?
?
, " '~ ' ?
? "
?
Iol ?
?
?
i0 10 20 30 40koZ~'O .
?
?.._...~---~*---6 ---" j''~' ...... vf"'0 10 20 30 40kIo 0 10 20 30 40kE?
I "._~ L"O o e ?.
-.~.
;~-"~'<51 " %" I0- 0 10 20 30 40k- I~ O ?
?
?
?p~-L'KI ?
% ?<o0 10 20 30 40k?1 ~0-  ?
ee  ? "
- ?> o O / r  ?
eo% i~o/  - ,  o I0 10 20 30 40f\[Ahab\]: : :30  .
.a "T, 0 10 " 20 30 40a O  - .
.
.
.
.
.
.
.
.
.
?
.
.
.
.
.
: .
.
.0 10 20 30 40k kFigure 5Diagnostic functions for Moby Dick.
VU(k) and NU(k): numbers of underdispersed types andtokens in text slice k; Pr(U, type) and Pr(U, token): proportions of underdispersed types andtokens; D(k) and DU(k): progressive difference scores for the overall vocabulary and theunderdispersed words; f\[Ahab\](k): frequency of Ahab in text slice k.(F(1,38) -- 2.11,p > .15 for VU(k), F(1,38) = 1.98,p > .15 for NU(k)) for underdisper-sion to occur more often as the novel progresses.
The absence of a trend is supportedby the proportions of underdispersed types and tokens, shown in the second row ofpanels (F < 1 for both types and tokens).
In the last text slices, underdispersed wordsare even underrepresented.
The bottom panels show that the progressive differencescores DU(k) for the underdispersed words capture the main trend in the progressivedifference scores of the total vocabulary D(k) quite well: The residuals D(k) - DU(k)do not reveal a significant rend (F(1, 38) = 1.08, p > .3).Interestingly, the use of underdispersed words in Moby Dick is to some extentcorrelated with the frequency of the word Ahab, with respect o both types and tokens(F(1,38) -- 4.61,p < .04,r 2 = .11 for VU(k); F(1,38) = 10.77,p < .003,r 2 = .22 forNU(k).
The panels on the third row of Figure 5 show the frequencies of Ahab (left)and VU(k) as a function of the frequency of Ahab (right).
A nonparametric time seriessmoother (solid line) supports the least squares regression line (dotted line).
In otherwords, the key figure of Moby Dick induces a somewhat more intensive use of the keywords of the novel.The nonuniform distribution of Ahab sheds some light on the details of the shapeof the difference function E\[V(N)\] - V(N) shown in Figure 1.
The initial sections donot mention Ahab, it is here that D(k) reveals its highest values, and here too we findthe largest discrepancies between E\[V(N)\] and V(N).
By text slice 20, Ahab has beenfirmly established as a principal character in the novel, and the main key words have466Baayen Lexical SpecializationMax Havelaar0 10 20 30 40kSer ies  : VULL 'R.0 0 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
"~ I ' ?
.
, i i , , , , ?
'.0  -zo l  ?- ~ - 'o~"~ - I0 10 20 30 40kSeries : NU<_l  i l .
.
.
.
.
.0 5 10 15 ' 0 5 10 15Lag Lag~.
,  - .
.
.
.
.
- .
, ~o.. o 0 10 20 30 40 o.. 0 10 20 30 40k k~,~i~o ?
~ ' .
.
- .
.'
0 10  20 30 40 0 10  20 30 40k kFigure 6Diagnostic functions for Max Havelaar.
VU(k) and NU(k): numbers of underdispersed typesand tokens in text slice k; ACF: auto-correlation function; Pr(U, type) and Pr(U, token):proportions of underdispersed types and tokens; D(k) and DU(k): progressive differencescores for the overall vocabulary and the underdispersed words.appeared.
The overestimation f the vocabulary is substantially reduced.
As the noveldraws to its dramatic end, the frequency of Ahab increases to its maximum.
The plotson the first row of Figure 5 suggest hat underdispersed types and tokens are alsoused more intensively in the last text slices.
However, the proportions plots on thesecond row show a final dip, suggesting that at the very end of the novel, a morethan average number of normally dispersed new types appears.
Considered together,this may explain why at the very end of the novel the expected vocabulary slightlyunderestimates the observed vocabulary size, as shown in Figure 1.Finally, consider the diagnostic plots for Max Havelaar, shown in Figure 6.
The timeseries smoother (solid line) for the absolute numbers of underdispersed types (VU(k))and tokens (NU(k)) suggests an oscillating use of key words without any increase in theuse of key words over time (the dotted lines represent the least squares regression lines,neither of which are significant: F < 1 in both cases).
This oscillatory structure receivessome support from the autocorrelation functions hown in the second row of panels.Especially in the token analysis, there is some evidence for positive autocorrelationat lag 1, and for a negative polarity at time lags 8 and 9.
No trend emerges fromthe proportions of new underdispersed types and tokens (third row, F < 1 in bothanalyses).
A comparison of the progressive difference scores D(k) and DU(k) (bottomrow) shows that the underdispersed words are again largely responsible for the largevalues of D(k) for small k. No significant rend remains in the residuals D(k) - DU(k)(F(1, 38) ---- 1.848, p > .15).467Computational Linguistics Volume 22, Number 4Figure 1 revealed that E\[V(N)\] - V(N) is largest around text slices 3 to 7, butbecomes negative for roughly the last third of the novel.
This pattern may be dueto the oscillating use of key words in Max Havelaar.
Although there is a fair numberof key words in the first few text chunks, the intensity of key words drops quickly,only to rise again around chunk 20.
Thus, key words are slightly underrepresented inthe first part of the novel, allowing the largest divergence between the expected andobserved vocabulary size to emerge there.3.4 The Paragraph as the Domain of Topic ContinuityThe preceding analyses all revealed violations of the randomness assumption under-lying the urn model that originate in the topical structure of the narrative as a whole.I have argued that a detailed analysis of the distribution of key word tokens andtypes may shed some light on why the theoretical vocabulary size sometimes over-estimates and sometimes underestimates the observed vocabulary size.
We are leftwith the question of to what extent repeated use of words within relatively short se-quences of sentences, henceforth for ease of reference paragraphs, affects the accuracyof E\[V(N)\].
I therefore carried out two additional analyses, one using five issues of theDutch newspaper Trouw, and one using the random samples of the Dutch newspaperDe Telegraaf available in the Uit den Boogaart (1975) corpus.
For both texts, no overalltopical discourse structure is at issue, so that we can obtain a better view of the effectsof intra-textual cohesion by itself.For each newspaper, the available texts were brought together in one large cor-pus, preserving chronological order.
Each corpus was divided into 40 equally large textslices.
The upper left panel of Figure 7 shows that in the consecutive issues of Trouw(March 1994) the expected vocabulary size differs significantly from the observed vo-cabulary size for all of the first 20 measurement points, the domain for which signif-icance can be ascertained (see footnote 3).
The upper right panel reveals that for thechronologically ordered series of samples from De Telegraaf in the Uit den Boogaartcorpus (268 randomly sampled text fragments with on average 75 word tokens) only3 text chunks reveal a significant difference between E\[V(N)\] and V(N).
The bottompanels of Figure 7 show the corresponding plots of the progressive difference scoresfor the complete vocabulary (D(k), ".")
and underdispersed words (DU(k), "+").
Theleast squares regression lines (dotted) for D(k), supported by nonparametric scatter-plot smoothers (solid lines), reveal a significant negative slope (F(1, 38) = 6.89, p < .02for Trouw, F(1, 38) = 10.99, p < .001 for De Telegraaf).
The residuals D(k) - DU(k) donot reveal any significant rends (F < 1 for both newspapers).
Note that for De Tele-graaf DU(k) does not capture the downward curvature of D(k) as well as it shouldfor large k. This may be due to the relatively small number of words that emerge assignificantly underdispersed for this corpus.Figure 7 shows that intra-textual cohesion within paragraphs i sufficient o giverise to substantial deviation between E\[V(N)\] and V(N) in texts with no overall dis-course organization.
Within successive issues of a newspaper, in which a given topic isoften discussed on several pages within the same newspaper, and in which a topic mayreappear in subsequent issues, strands of inter-textual cohesion may still contributesignificantly to the large divergence between the observed and expected vocabularysize.
It is only by randomly sampling short text fragments, as for the data from the Uitden Boogaart corpus, which contains amples evenly spread out over a period of oneyear, that a substantial reduction in overestimation is obtained.
Note, however, thateven for the corpus data we again find that the expectation of V(N) is consistently toohigh.
Within paragraphs, words tend to be reused more often than expected underchange conditions.
This reuse pre-empts the use of other word tokens, among which468Baayen Lexical SpecializationOv OIZ}OTr0uw (full issues)I ?~o/o , ' " "%.
"\ .
.
.
\x , '\ / " '\" , ,"50000 100000 150000 200000 250000NTr0uw (full issues)Ooo=oO e,IoDe Telegraaf (samples)," .
/ \/ \,...\// \  !
\/ I  / "\" , / .\\\\0 5000 10000 15000 20000NOo8 3oo o-I- ??
?
?
-'\[ ...............ooDe Telegraaf (samples).. .
.
.0 10 20 30 40 0 10 20 30 40k kFigure 7Diagnostic plots for two Dutch newspapers.
The difference between the expected andobserved vocabulary size for the Trouw data (five issues from March 1994) and the randomsamples of De Telegraaf in the Uit den Boogaart colpus (upper panels; significant differencesare highlighted for the first 20 measurement points).
The bottom panels how the progressivedifference rror scores for the total vocabulary (D(k)) and for the subset of underdispersedwords (DU(k)).
The dotted line is a least squares regression, the solid line a nonparametricscatterplot smoother.tokens of types that have not been observed among the preceding tokens, and leadsto a decrease in type richness.
Since intra-textual cohesion is also present in the textsof novels, we may conclude that the overestimation bias in novels is determined by acombination of intra-textual nd inter-textual cohesion.4.
ImplicationsWe have seen that intra-textual nd inter-textual cohesion lead to a significant differ-ence between the expected and observed vocabulary size for a wide range of samplesizes.
This section addresses two additional questions.
First, to what extent does thenonrandomness of word occurrences affect distributions of units selected or derivedfrom words?
Second, how does cohesive word usage affect he Good-Turing frequencyestimates?4.1 Word-derived UnitsFirst consider the effect of nonrandomness on the frequency distributions of mor-phological categories.
The upper panels of Figure 8 plot the difference between theexpected and observed vocabulary size for the morphological category of words with469Computational Linguistics Volume 22, Number 4-heid in 'Max Havelaar' -heid in TrouwL,3Z>1.13 z >LU O,/"'"ix.
/\ /'\\/\,'.., ,  .
\\ \ /?
.
.
-" ' .
\ / "?
/\10 20k30 40 5 10 15 20kDigraphs in 'Alice in Wonderland' Syllables in Trouw>8 i o3 z~LU Qo\ , "~\ , , ' .
.o o,1oL o  / ;"",, .
"\ .
,r '\ .
,  .,,"0 10 20 30 40 0 10 20k k30 40Figure 8Diagnostic plots for affixes, syllables, and digraphs?
The difference between the expected andobserved vocabulary size for the morphological category of words with the Dutch suffix -heid'-ness' in Max Havelaar (upper left) and in Trouw (upper ight), for syllables in Trouw (lowerleft), and for digraphs in Alice in Wonderland?
Significant differences are shown in bold for thefirst half of the tokens?the Dutch suffix -heid, which, like -ness in English, is used to coin abstract nouns fromadjectives (e.g., snelheid, 'speed', from snel, 'quick').
The plots are based on samplesconsisting of all and only those words occurring in Max Havelaar (upper left) andTrouw (upper right) that belong to the morphological category of -heid, ignoring allother words, and preserving their order of appearance in the original texts.
The sampleof -heid words in Max Havelaar consisted of 640 tokens representing 260 types, of which146 hapax legomena.
From Trouw, 1145 tokens representing 394 types were extracted,among which 246 hapax legomena.In Max Havelaar, a number of words in -heid, such as waarheid 'truth' and vrijheid'freedom', are underdispersed key words.
Not surprisingly, this affects the growthcurve of -heid itself.
For small values of k, we observe a significant divergence betweenE\[V(N)\] and V(N).
In the newspaper Trouw, where -heid words do not play a centralrole in an overall discourse, no significant divergence merges.
Nevertheless, we againobserve a consistent trend for the expected vocabulary size to overestimate he actualvocabulary size.Figure 8 also plots the development of the vocabulary of syllables in Trouw (bot-tom left), and the development of the vocabulary of digraphs in Alice in Wonderland(bottom right).
The "texts" of syllables and digraphs preserve the linear order of thetexts from which they were derived.
For both digraphs (80,870 tokens representing398 types, of which 30 hapax legomena) and syllables (470,520 tokens, 6,748 types,470Baayen Lexical Specializationand 1,909 hapax legomena), Figure 8 reveals significant deviation in the first half ofboth texts.
This suggests that the nonrandomness observed for words carries over toword-based units such as digraphs and syllables.4.2 Accuracy of Good-Turing EstimatesSamples of words generally contain--often small--subsets of all the different ypesavailable in the population.
The probability mass of the unseen types is generally largeenough to significantly bias population probabilities estimated from sample relativefrequencies.
Good (1953) introduced an adjusted frequency estimate (which he creditsto Turing) to correct this bias.
Instead of estimating the probability of a word withfrequency f by its sample relative frequencyf (16) pi= ,Good suggests the use of the adjusted estimate1 (1: + 1)E\[V(N,f + 1)1 (17)my(N) = E\[V(N,d)\]A closely related statistic is the probability ~P(N) of sampling a new, unseen type afterN word tokens have been sampled:7~(N ) _ E\[V(N, 1)\] (18)NThese estimates are in wide use (see, e.g., Church and Gale \[1991\] for applicationto bigrams, Bod \[1995\] for application to syntax, and Baayen \[1992\] and Baayen andSproat \[1996\] for application to morphology).
Hence, it is useful to consider in somedetail how their accuracy is affected by inter-textual nd intra-textual cohesion.
To thisend, I carried out a short series of experiments of the following kind.Assume that the Trouw data used in the previous ection constitute a populationof N = 265,360 word tokens from which we sample the first N/2 = 132,680 words.
Forthe Trouw data, this is a matter of stipulation, but for texts such as Moby Dick or Alicein Wonderland, an argument can be made that the novel is the true population ratherthan a sample from a population.
For the present purposes, the crucial point is thatwe now have defined a population for which we know exactly what the populationprobabilities--the r lative frequencies in the complete texts--are.First consider how accurately we can estimate the vocabulary size of the popu-lation from the sample.
The expression for E\[V(N)\] given in (1) that we have usedthus far does not allow us to extrapolate to larger sample sizes.
However, analyticalexpressions that allow both interpolation (in the sense of estimating V(N) on the basisof the frequency spectrum for sample sizes M < N) and extrapolation (in the sense ofestimating V(M) for M > N) are available (for a review, see Chitashvili and Baayen\[1993\]).
Here, I will make use of a smoother developed by Sichel (1986).
The threeparameters of this smoother are estimated by requiring that E\[V(N)\] = V(N), thatE\[V(N, 1)\] = V(N, 1), and by minimizing the chi-square statistic for a given span offrequency ranks.The upper left panel of Figure 9 shows that it was possible to select the param-eters of Sichel's model such that the observed frequencies of the first 20 frequencyranks (V(N,f),f = 1 .
.
.
.
,20) do not differ significantly from their model-dependent471Computational Linguistics Volume 22, Number 4Frequency spectrum at N = 1326805 10 15 20fInterpolation and extrapolation from N = 132680F~ ............0 50 100 150 200 250N ('1000)oProbability mass errors (Good-Turing)5 ?oL  - ' ?
?
'~ ' :=="  .
.
.
.
-~- : * -  .
.
.
.
.
.
.
'~ :~-0 10 20 30 40fInterpolation from N = 132680w 0 20 40 60 80 100 120N ( '1000)Estimation errors conditional on N = 132680o o j"?
'?~~,, ?~ ?.....
, .
.
.
.
.
.
.
.
.
.
, .
.
, .Z kO ?'~""7.'
"~"" "".uJ 0 50 100 150 200 250N ('1000)Probability mass errors (unadjusted~r .
, , ?
, , .
, , ?
- - - - '  .
.
.
.
- - - - ?
.
.
.
.
.
.
.
.  '
-t ~s;t ~d c ;L' 0 10 20 30 40fFigure 9Interpolation and extrapolation from sample (the first half of the Trouw data) to population(the complete Trouw data).
E\[V(N,f)\] and V(N,f): expected and observed frequency spectrum;E\[V(N)\] and V(N): expected and observed numbers of types; Mp(f): population probabilitymass of the types with frequency f in the sample; MGT(f): Good-Turing estimate of Mp(f);Ms(f): unadjusted sample stimate of Mp(f).expectations E \[V(N,f)\].
7 The upper right panel shows that interpolation on the basisof Sichel's model (dashed line) is virtually indistinguishable from interpolation using(1) (dotted line).
The observed vocabulary sizes are represented by large dots.
As ex-pected, both (1) and the parametric smoother reveal the characteristic overestimationpattern.The center panels of Figure 9 show that the overestimation characteristic for inter-polation is reversed when extrapolating to larger samples.
For extrapolation, under-estimation is typical.
The dotted line in the left-hand panel represents the observedvocabulary size of the complete Trouw text, the solid line shows the result from in-terpolation and extrapolation from N = 132,680.
The right-hand panel highlights thecorresponding difference scores.
For N = 265,360, the error is large: 5.5% of the actualvocabulary size.Having established that E\[V(N)\] underestimates V(N) when extrapolating, thequestion is how well the Good-Turing estimates perform.
To determine this, I willconsider the probability mass of the frequency classes V(M,f) for f = 1... 40.
Let= v(M, f )  .
p; (M) (19)7 The fit (X2(18) = 9.93, p > .9) was  obta ined  for  the parameter  va lues  c~ = 0.291, 3' = -0 .7 ,  andb = 0.011.472Baayen Lexical Specializationbe the joint Good-Turing probability mass of all types with frequency f in the sampleof M = 132,680 tokens, and let Mp(f) be the joint probability mass of exactly the sameword types, but now in the population (N = 265,360 tokens):Mp(f) -~ Y'~4 I\[f(i,M)=jq .
f ( i, N) (20)Nwith f(i, X) the frequency of the i-th type in a sample of X tokens.
The bottom leftpanel of Figure 9 shows that for the first frequency ranks f, the Good-Turing estimateMeT (f, M) underestimates he probability mass of the frequency class in the population.For the higher-frequency ranks, the estimates are fairly reliable.
The bottom rightpanel of Figure 9 plots the corresponding errors for the unadjusted sample probabilityestimateMs(f,M) = ~d V(M,f), (21)f ,which overestimates the population values.
Surprisingly, the unadjusted estimatesoverestimate he population values to roughly the same extent hat the adjusted esti-mates lead to underestimation.
A heuristic estimate,Mh(f,M) = V(M,f) (f + 1)Es\[V(M,f + 1)\] +fEs\[V(M,f)\]Es\[V(M,f)\] 2M (22)the mean of Ms(f, M) and MCT(f, M), appears to approximate the population relativeclass frequencies Mp(f) reasonably well, as shown in Table 1 for the Trouw data aswell as for Alice in Wonderland, Moby Dick, and Max Havelaar.
For f > 5, as shown inFigure 10, the heuristic estimate remains a reasonable compromise.We have seen that both E\[V(N)\] and the Good-Turing estimates MCT(f,M) (es-pecially for f < 5) lead to underestimation f population values.
Interestingly, ~(M)overestimates the probability mass of unseen types.
For the Trouw data, at M = 132,680we count 11,363 hapax legomena, hence ~'(M) = 0.0856.
However, the probability massof the types that do not appear among the first 132,680 tokens, M(0), is much smaller:0.0609.
Table 1 shows that ~'(M) similarly leads to overestimation for Alice in Wonder-land, Moby Dick, and Max Havelaar.
To judge from Table 1, the Good-Turing estimateMeT(1,M) is an approximate lower bound and the unadjusted estimate Ms(1,M) astrict upper bound for Mp (0).It is easy to see why 7~(N) is an upper bound for coherent text by focusing onits interpretation.
Given the urn model, the probability that the first token sampledrepresents a type that will not be represented by any other token equals V(N, 1)/N.By symmetry, this probability is identical to the probability that the very last tokensampled will represent an unseen type.
This probability approximates the probabilitythat, after N tokens have been sampled, the next token sampled will be a new type.However, this interpretation hinges on the random selection of word tokens, andthis paper presents ample evidence that once a word has been used it is much morelikely to be used again than the urn model predicts.
Hence, the probability that aftersampling N tokens the next token represents an unseen type is less than V(N, 1)/N.Due to intra-textual nd inter-textual cohesion, the V(N) - V(N, 1) types that havealready been observed have a slightly higher probability of appearing than expectedunder chance conditions, and consequently the unseen types have a lower probability.Summing up, the Good-Turing frequency estimates are severely effected by thecohesive use of words in normal text.
In the absence of probabilistic models that takecohesive word usage into account, estimates of (relative) frequencies remain heuristic473Computational Linguistics Volume 22, Number 4Table 1Comparison of probability mass estimates for frequencies f = 1 .
.
.
.
.
5 using the smootherEs\[V(N,f)\] of Sichel (1986).
The probability mass of unseen types, Mp(0), is also tabulated.Notation: MCTOC, M): Good-Turing estimate; Ms(f,M): sample estimate; Mh(f,M): heuristicestimate; Mp(f): population mass.
For Max Havelaar, a sample comprising the first third of thenovel was used, for the other texts, a sample consisting of the first half of the tokens wasselected.f V(N,f) Es\[V(N,f)\]  McT(f,M) Ms(f,M) Mh(f,M) Mp(f)Alice in Wonderland0 0.06301 885 885.00 0.0411 0.0668 0.0540 0.05602 287 272.27 0.0328 0.0434 0.0381 0.03723 147 137.27 0.0277 0.0333 0.0305 0.02934 97 85.52 0.0255 0.0293 0.0274 0.02895 68 59.55 0.0230 0.0257 0.0243 0.0228Moby Dick0 0.03501 5,914 5,914.04 0.0366 0.0553 0.0460 0.04722 2,035 1,958.22 0.0272 0.0381 0.0326 0.03313 990 932.22 0.0218 0.0278 0.0248 0.02514 601 549.44 0.0187 0.0225 0.0206 0.02105 416 366.22 0.0168 0.0195 0.0181 0.0179Max Havelaar0 0.09211 3,513 3,513.01 0.0494 0.1058 0.0776 0.06922 908 821.04 0.0362 0.0547 0.0455 0.04113 346 362.65 0.0240 0.0313 0.0276 0.02464 214 208.95 0.0213 0.0258 0.0235 0.02165 157 137.84 0.0203 0.0236 0.0220 0.0189Trouw0 0.06091 11,363 11,363.05 0.0431 0.0856 0.0644 0.06392 2,941 2,856.65 0.0297 0.0443 0.0370 0.03593 1,338 1,276.07 0.0233 0.0303 0.0268 0.02564 826 737.69 0.0206 0.0249 0.0227 0.02195 532 487.51 0.0172 0.0200 0.0186 0.0190in nature.
For the frequencies of types occurring at least once in the sample, theaverage of the sample and Good-Turing adjusted frequencies i  a useful heuristic.
Forestimates of the probabil ity of unseen types, the sample and Good-Turing estimatesprovide approximate upper  and lower bounds.5.
D iscuss ionWords do not occur randomly in texts.
This simple fact is difficult to take into accountin statistical models of word frequency distributions.
Hence, it is often ignored, inthe hope that violations of the randomness assumption will not seriously affect theaccuracy of quantitative measures and estimates.The goal of this paper has been to explore in detail the consequences of intra-474Baayen Lexical Specialization00O.dr~or~c5Oo 6Figure 1011'0 2'o 30 4'0fFrequency class probability mass estimates for the first 40 frequency ranks in a sample ofM = 132,680 of the Trouw data.
The dots denote the probability mass Mp(f) in the full text(N = 265,360) of the words with frequency f in the sample.
The Good-Turing estimatesMGT(f,M) are represented by "e," the sample stimates Ms(f,M) by "s," and the heuristicestimate Mh(f,M) by "+'.textual and inter-textual cohesion on the accuracy of theoretical estimates of vocab-ulary size, the growth rate of the vocabulary, and Good-Turing adjusted frequencyestimates, in the belief that knowledge of how nonrandomness might affect thesemeasures ultimately leads to a better understanding of the conditions under whichthese measures may, or may not, be reliable.Analyses of three novels, five consecutive issues of the Dutch newspaper Trouw,and the chronologically ordered samples of the Dutch newspaper De Telegraaf inthe Uit den Boogaart corpus, all revealed systematic overestimation for the expectedvocabulary size.
Further analyses of subsets of derived words, syllables, and digramsshowed that the overestimation bias reappears in units derived from words whenthese words occur in normal, cohesive text.The overestimation bias disappears when the order of the sentences i random-ized.
This indicates that the bias should not be attributed to syntactic and semanticconstraints on word usage operating within the sentence.
Instead, the bias arises dueto intra-textual nd inter-textual cohesion.
In sequences of sentences, words are morelikely to be reused than expected under chance conditions.
Coherent discourse requireslocal topic continuity.
This intra-textual cohesion gives rise to a substantial part of theoverestimation bias, a bias that leads to significant deviations even when small textfragments of some 75 words are selected randomly from a newspaper.In addition to intra-textual cohesion, there are words that contribute to the cohe-475Computational Linguistics Volume 22, Number 4sion of the discourse as a whole.
Detailed analyses of how these key words appearover sampling time in the novels reveal marked differences in their distributions.These differences in turn shed light on the details of the differences in the patterns ofestimation errors E\[V(N)\] - V(N) that characterize the texts.
The progressive differencescores of the key words, the deviation scores for the expected and observed numbersof new types appearing in the successive text slices, reveal a pattern that is highlysimilar to the same scores for the vocabulary as a whole, both qualitatively and quan-titatively.
This supports the hypothesis that the key words are primarily responsiblefor the deviation of the expected vocabulary size from its expectation.Nonrandomness in word usage not only introduces a bias with respect o theexpected vocabulary size--overestimation when interpolating and underestimationwhen extrapolating, it also affects the accuracy of the Good-Turing estimates.
To correctfor an overestimation bias, Good (1953) introduced adjusted estimates, building onthe assumption that word usage is to all practical purposes random.
These adjustedestimates, however, appear to overshoot their mark for continuous text in that theyunderestimate he population relative frequencies to roughly the same extent hat theunadjusted probabilities lead to overestimation, especially for the lowest frequencies.Again, the effect of inter-textual nd intra-textual cohesion manifests itself.
Once used,words tend to be used again, and this leads to a somewhat higher relative populationfrequency than expected.
The other side of the same coin is that Good's estimate forthe probability mass of unseen types, 79(N), is an upper bound.
The words that havealready been used have a raised probability of being used again.
Hence, the probabilityfor unseen types to appear is lowered.There are two major ways to deal with the effects of nonrandomness in word usageon the accuracy of statistical estimates.
First, by randomly sampling individual sen-tences instead of sequences of sentences, the effects of intra-textual and inter-textualcohesion will be largely eliminated.
With the increasingly large corpora that are becom-ing available at present, enhanced sampling methods hould pose no serious problem.For literary studies, however, the discourse structure of a text is part and parcel of theobject of study itself.
Here, the use of the heuristically adjusted estimates proposed inSection 4.2 may prove to be useful.Finally, the investigation of the distribution of key words may turn out to be auseful tool for investigating the structure of literary texts, a tool that may lead to animproved understanding of the role of lexical specialization i shaping the quantitativedevelopmental structure of the vocabulary.AppendixEquation (1) can be derived as follows; see Good 1953; Good and Toulmin 1956; Kalinin1965: Let f(i,M) denote the frequency of ~i in a sample of M tokens (M < N), anddefine1 i f f( i ,M) = m (23)Xi -- 0 otherwise.Denoting the probability of wi by pi, the expected total number of word types withfrequency m in a sample of M tokens, E\[V(M, re)I, is given byE\[V(M,m)\] = E\[y~ Xi\]i= ZE\[X,1i476Baayen Lexical Specialization= ~ 1-Pr(Xi = 1) + 0.
Pr(Xi = 0)i:l(24)where we assume that the frequencies f(i,M) are independently and identically bi-nomially (M, pi) distributed.
The expected overall number of different ypes in thesample, irrespective of their frequency, follows immediately:E\[V(M)\] = V(M,m)\]= ~ ~ m Pro(1 - pi)M-m_ i= ~(1--(l--pi)M).i(25)For large M and small p, binomial probabilities can be approximated by Poisson prob-abilities, leading to the simplified expressions(AIM) m e-,X,M E\[V(M,m)\] = ~ m!iEfV(M)\] = ~'~(1 - e-'~'M).
(26)Conditional on a given frequency spectrum {V(N,f),f = 1, 2 .
.
.
.
}, the vocabulary sizeE\[V(M)\] for sample size M < N equalsE\[V(M)\]V(N)= ~--~(l_e-;~i M)i=1V(N)= Z(1  ~e S(-~)M)i=1= V(N)-~-'~V(N,f)e-~ M.f= l(27)In the last step, all V(N,f) types sharing the same frequency f have been groupedtogether.
Note that when the N tokens themselves constitute a sample from a largerpopulation, E\[V(M)\] is in fact an estimate.The derivation of (27) uses an urn model in which words are sampled with re-placement.
A model in which words are sampled without replacement is more precise.For instance, for a randomly reordered text, the likelihood that a hapax-legomenonin the full text that appears in the first M tokens will reappear among the remainingN-  M tokens is greater than zero in a model that assumes constant probabilities, con-trary to fact.
For large N and M, however, the binomial probabilities (sampling withreplacement) are a good approximation of the hypergeometric probabilities (samplingwithout replacement).477Computational Linguistics Volume 22, Number 4Finally note that (27) suggests that, under randomness, and conditional on thewords appearing in the sample of N tokens, f ( i ,M) can alternatively be viewed as abinomially distributed random variable with parameters M/N andf(i, N) forf(i, N) ((M, N (Muller 1977):E\[V(M)\] : V - E V(N,f)e-Myf( ,~ V -  ~-'.
~V(N,f )  1 -f(28)The modification of (28) proposed by Hubert and Labbe (1988) requires the as-sumption that all the tokens of a word type with specialized use occur in a singletext slice.
Let the total number of words in the set S of types with specialized use bepV, and also assume that the text slices in which these specialized words appear arerandomly distributed over the text.
Let1 if wi c S and wi occurs in P1Xi -- 0 otherwise, (29)and let1 if wi ~ S and o;i occurs in P1Yi -- 0 otherwise.
(30)The overall number of types in P1 is ~-,i Xi + Y'~j Yj.
If wi E S, itsfi, tokens ~ ( (M)  willall appear in the same part of the text.
The probability that they will appear in P1 isM_M Hence N"EHL\[V(M)\]-- ~ Pr(Xi = 1) + E Pr(Yj = 1)wiES ~fftS= 1 - 1 -wiCS wj~SM:M:M = pV~+(1-p)V-  E 1 -~j~8+ (1 - p)V-  ~(1 - p)V(N,f) 1 -f+ (1 - p)V - y ; l l  - p)V(N,fle--~<f(31)Note the implicit assumption that the same proportion of the V(N,f)  word types withfrequency f is specialized, irrespective of the value of f.478Baayen Lexical SpecializationList of Symbolsdidi,kD(k)DU(k)AV(k)AVU(k)E\[X\]EHL\[V(M)\]Es\[V(N,f)\]ff(i,M)Y ,kikKmMMpOMcT(f,M)Ms(f,M)MhGM)ni,knUi, kNNU(k)PPfpiPr(U, token, k)Pr(U, type, k)Z'(N)v(N)V(N,f)V(Mk)VU(k)dispersion of word type iindicator variable for underdispersion of type i in chunk kprogressive difference score for text slice kprogressive difference score of underdispersed words at chunk knumber of new types at knumber of new underdispersed types at kexpectation of Xexpectation of V(M) in the Hubert-Labbe modelexpectation of V(N,f) given Sichel's (1986) modeltoken frequency of a wordtoken frequency of i-th word type in sample of size Mtoken frequency of i-th word in the k-th text sliceindex for word types 1 .
.
.
.
.
Vindex for text slices 1 .
.
.
.
, Knumber of text slicestoken frequency of a word in sample of size Msample size in tokens when contrasting two sample sizes (M < N)population probability mass of frequency class fGood-Turing sample estimate of Mp(f) in sample of size Msample estimate of Mp(f)heuristic estimate of Mp(f) (mean of Ms(M,f) and MGT(M,f))indicator variable for type i appearing first in chunk kindicator variable for type i appearing first in chunk k and i beingunderdispersed in knumber of word tokens in the samplenumber of underdispersed tokens in chunk kHubert-Labbe coefficient of vocabulary partitionsample probability (f/N)probability of (d iGood-Turing adjusted probability for sample of size Mproportion of new underdispersed tokens at kproportion of new underdispersed types at kgrowth rate of the vocabulary (E\[V(N, 1)\]/N)number of different word types among N tokensnumber of types with frequency f in a sample of N tokensnumber of types in the first ~- tokensnumber of underdispersed types in chunk kAcknowledgmentsI am indebted to Ken Church, Anne Cutler,James McQueen, Rob Schreuder, RichardSproat, Fiona Tweedie, and five anonymousreviewers for valuable comments anddiscussion.ReferencesBaayen, R. Harald.
1989.
A Corpus-basedApproach to Morphological Productivity.Statistical Analysis and PsycholinguisticInterpretation.
Ph.D. thesis, FreeUniversity, Amsterdam.Baayen, R. Harald.
1992.
Quantitativeaspects of morphological productivity.
InG.
E. Booij and J. van Marie, editors,Yearbook of Morphology 1991.
KluwerAcademic Publishers, Dordrecht, pages109-149.Baayen, R. Harald.
1996.
The randomnessassumption i word frequency statistics.479Computational Linguistics Volume 22, Number 4In G. Perissinotto, editor, Research inHumanities Computing 5.
OxfordUniversity Press, Oxford.Baayen, R. Harald and Antoinette Renouf.1996.
Chronicling the Times: Productivelexical innovations in an Englishnewspaper.
Language, 72:69-96.Baayen, R. Harald and Richard Sproat.
1996.Estimating lexical priors forlow-frequency morphologicallyambiguous forms.
ComputationalLinguistics, 22(2):155-166.Bod, Rens.
1995.
Enriching Linguistics withStatistics: Performance Models of NaturalLanguage.
University of Amsterdam:Institute for logic, language andcomputation, Amsterdam.Brunet, Etienne.
1978.
Le vocabulaire de JeanGiraudoux, volume 1 of TLQ.
Slatkine,Gen~ve.Chitashvili, Revas J and R. Harald Baayen.1993.
Word frequency distributions.
InG.
Altman and L. Hi'eb~ek, editors,Quantitative Text Analysis.Wissenschaftlicher Verlag Trier, Trier,pages 54-135.Church, Kenneth and William Gale.
1991.
Acomparison of the enhanced Good-Turingand deleted estimation methods forestimating probabilities of Englishbigrams.
Computer Speech and Language,5:19-54.Church, Kenneth and William Gale.
1995.Poisson mixtures.
Journal of NaturalLanguage Engineering, 1(2):163-190.Cleveland, W. S. 1979.
Robust locallyweighted regression and smoothingscatterplots.
Journal of the AmericanStatistical Association, 74:829-836.Good, I. J.
1953.
The population frequenciesof species and the estimation ofpopulation parameters.
Biometrika,40:237-264.Good, I. J and G. H. Toulmin.
1956.
Thenumber of new species and the increasein population coverage, when a sample isincreased.
Biometrika, 43:45-63.Herdan, Gustav.
1960.
Type-TokenMathematics.
Mouton, The Hague.Holmes, David.
I.
1994.
Authorshipattribution.
Computers and the Humanities,28(2):87-106.Hubert, Pierre and Dominique Labbe.
1988.A model of vocabulary partition.
Literaryand Linguistic Computing, 3:223-225.Indefrey, Peter and R. Harald Baayen.
1994.Estimating word frequencies fromdispersion data.
Statistica Neerlandica,48:259-270.Johnson, Norman L. and Samuel Kotz.
1977.Urn Models and Their Application.
AnApproach to Modern Discrete ProbabilityTheory.
John Wiley & Sons, New York.Kalinin, V. M. 1965.
Functionals related tothe Poisson distribution and statisticalstructure of a text.
In J. V. Finnik, editor,Articles on Mathematical Statistics and theTheory of Probability, pages 202-220,Providence, Rhode Island.
SteklovInstitute of Mathematics 79, AmericanMathematical Society.Khmaladze, Estate V and Revas J.Chitashvili.
1989.
Statistical analysis oflarge number of rare events and relatedproblems.
Transactions ofthe TbilisiMathematical Institute, 91:196-245.Muller, Charles.
1977.
Principes et mdthodes destatistique l xicale.
Hachette, Paris.Muller, Charles.
1979.
Languefrancaise etlinguistique quantitative.
Slatkine, Gen6ve.Sichel, H. S. 1986.
Word frequencydistributions and type-tokencharacteristics.
Mathematical Scientist,11:45-72.Tukey, John W. 1977.
Exploratory DataAnalysis.
Addison-Wesley, Reading, Mass.Uit den Boogaart, Pieter C., editor.
1975.Woordfrequenties in Gesproken en GeschrevenNederlands.
Oosthoek, Scheltema &Holkema, Utrecht.480
