A Critical Evaluation of Commensurable Abduction Modelsfor Semantic Interpretation *Peter  Norv ig  and Rober t  Wi lenskyUnivers i ty of  Cal i fornia, BerkeleyComputer  Science Division, Evans HallBerkeley, CA 94720, USAIntroductionLanguage interpretation involves mapping from a stringof words to a representation f an interpretation f thosewords.
The problem is to be able to combine videnceI'rom the lexicon, syntax, semantics, ,'rod pragmatics toarrive at the best of the many possible interpretations.Given the well-worn sentence "The box is in the pen,"~;yntax may say that "pen '~ is a noun, while lexical knowl-edge may say that "pen" most often means writing im-plement, less often means a fenced enclosure, and veryrarely means a female swan.
Semantics may say that theobject of "in" is often an enclosure, and pragmatics may::ay lhat the topic is hiding small boxes of illegal drugs imside aquatic birds, Thus there is evidence for.multiple in-tc.rpretations, and one needs ome way to decide betweenthem.In the past few years, some general approaches tointer-pretation have been advanced within an abduction frame-work.
Charniak (1986) and Norvig (1987, 1989) m'e twoexamples.
Abduction is a term coined by Pierce (1955)to describe the (unsound) inference rule that concludes Afrom the observation 13 and the role A ~ B, along withthe fact that there is no "better" rule explaining B.In this paper we critically evaluate three recent alxluc-tire interpretation models, those of Chamiak and Gold-man (1989); Hobbs, Stickel, Martin and Edwards (1988);a~(1 Ng and Mooney (1990).
"Itmse three models add theimportant property of commensurability: all types of ev-idence are represented in a common currency that can becompared and combined.
While commensurability s adesirable property, and there is a clear need for a way tocompare alternate xplanations, it appears that a singlescalar measure is not enough to account for all types ofprocessing.
We present other problems for the abductiveapproach, and some tentative solutions.Cost  Based  Commensurab i l i tyIqobbs et al (1988) view interpreting sentences as "'pro-viding the best explanation of why the sentences would*Sponsored by the Defense Advanced Research ProjectsAgency (DoD), Arpa Order No.
4871, monitorcxl by Space andNaval Warfare Systems Command under Contract N00039-84-CO089.
This paper benefined from discussions wifll MichaelBraverman, Dan .Iurafsky, Nigel Ward, Dekai Wu, and othermembers of the BAIR seminar.225be true."
In this view a given sentence (or an entire text)is translated by an ambiguity-preserving parser into a log-ical form, L. Each conjunct in the logical form is anno-tated by a number indicating the cost, $C, of assuming timconjunct to be true.
Conjuncts corresponding to"new"information have a low cost of assumability, while thosecorresponding to "given" information have a higher cost,since to assume them is to fail to find the proper connec-tion to mutual knowledge.
Each conjunct must be eitherassumed or proved, usinga rule or series of rules from theknowledge base.
Each rule also has cost factors associ-ated with it, and the proper interpretation, I, is the set ofpropositions with minimal cost that entails L.As an example, consider again the sentence "The boxis in the pen."
The cost-,'mnotated logical form (in a sim-plified notation omitting quantifiers) is:L = box(x) $1?
A pen(y) $1?
A in(x, y)$3where psi: means the final interpretation must either as-sume P for $x, or prove P, presumably for less.
Considerthe proof rules:wriling pen( x ) "9 D pen(x)female(x) '3 A swan(x) "6 D pen(x)enclosure(y) '3A inside(x, y).6 D in(x, y)The first rule says that anything that is a writing-penis also a member of the class 'pen'--things that can bedescribed with the word "pen".
The superscripted num-bers are preference information: the first rule says thatpen(z) s~?
can be derived by assuming writing pen(x) s9.Predicates of the form etci(x), as in the second rule, de-note conditions that are stated elsewhere, or, for somenatural kind terms, can not be fully enumerated, but canonly be assumed.
They seem to be related to the ab-normal predicates, ab(x) used in circumscription theory(McCarthy 1986).Below are two interpretations of L. The first just as-sumes the entire logical form for $23, while the secondapplies the rules and shares the enclosure(y) predicatecommon to one of the definitions of pen(y) and the defi-nition of in(x, y) to arrive at a $20.80 solution.box(x)s 0 ^ pen( :)s o ^  y)s3.box(x) sm A enclosure(y) $3 A fenced(y) $3A etcl(y) $3 A enclosure(y) $?
A inside(x, y)$1.8The second enclosure(y) gets a cost of $0 becauseit has already been assumed.
Let me stress that the de-tails here are ours, and the authors may have a differenttreatment of this example.
For example, they do not dis?cuss lexical ambiguity, although we believe we have beenfaithful to the sense of their proposal.
"lThis approach as several problems, as we see it:(1) A single number is being used for two separatemeasures: the cost of the assumptions and the qualityof the explanation.
Hobbs et al hint at this when theydiscuss the "informativeness-correctness radeoff."
Con-sider their example "lube-oil alarm," which gets trans-lated as:lubeoil(o) s5 A alarm(a) s5 A nn(o, a) $~awhere nn means noun-noun compound.
It is given a highcost, $20, because failing tO find the relation means fail-ing to fully understand the referent.
Intuitively this moti-vation is valid.
However, the nn should have a very lowcost of assumption, because there is very strong evidencefor it--the juxtaposition of two nouns in the input--sothere is little doubt hat nn holds.
Thus we see nn shouldhave two numbers associated with it: a low cost of as-sumption, and a low quality of explanation.
It should notbe surprising to see that wo numbers are needed to searchfor an explanation: even in A* search one needs both acost function, 9, and a heuristic function h'.The low quality of explanation is often the sign of aneed to search for a better explanation, but the need de-pends on the task at h,'md.
To diagnose a failure in thecompressor, it is useful to know that a "lube-oil alarm"is an alarm that sounds when the lube-oil pressure is low,and not, .gay, and alarm made out of lube-oil.
However,if the input was "Get me a box of lube-oil alarms fromthe warehouse," then it may not be necessary to filrtherexplain the nn relation) Mayfield (1989)characterizes agood explanation as being applicable to the needs of theexplanation's u er, grounded in what is already known,and completely accounting for the input.To put it another way, consider the situation where amagician pulls a rabbit out of his hat.
One possible x-planation is that the rabbit magically appeared in the hat.This explanation is of very high quality--it perfectly ex-plains the situation--but it has a prohibitive assumptioncost.
An alternate explanation is that the magician some-how used slight of hand to insert the rabbit in the hatwhen the audience was distracted.
This is of fairly lowquality--it fails to completely specify the situation--butit has a much lower assumption cost.
Whether this is asufficient explanation depends on the task.
For a casualobserver it may will do, but for a rival magician trying tosteal the trick, a better explanation is needed.
(2) Translating, say, "the pen" as pen(v) $1?
conflatestwo issues: the final interpretation must find a referent, y,and it must also disambiguatE "pen".
It is true that defi-nite noun phrases are often used to introduce new infor-mation, and thns must be assumed, but an interpretationtTranslating "lube-oil alarm" as (3o)htbeoil(o) is suspect;in the ease of an alarm still in the box, there is not yet any par-ticular oil for which it is file alarm.226that does not disambiguate "pen" is not just making al~assumption--rather it is failing altogether.
One could ac-commodate his problem by writing ttisambiguatio~l ru eswhere tile sum of tile icft-haud.-side compo~w, nts is lessthan 1.
Thus, the system will always prefer to find someinterpretation for"pen", rather titan leaving it ambi~,uous.In the case of vagueness rather than ambiguity, one wouldprobably want the leftohand-side to total greater |hau l.For example, in "He saw her duck", the word "duck" isambiguous between awater fowl and a downward move~meat, and any candidate solution should be force^ to de-cide between the two meanings.
In contrast, "he" is vaguebetween a boy and a man, but it is not necessary lot a validinterpretation to make this choice.
We could model thiswith the rules:ducklowl(~) "9 D duck(x)"9 d  k(x).9 ^maZe(z) "9 A child(z) "2 D he(z)However, this alone is not enough.
Consider the sen-tence "The pen is in the box."
By the rules above (and asosuming a box is defined as an enclosure) we could derivethree interpretations, where either a writing implement,a swan, or a fenced enclosure is inside a box.
All threewould get a cost of $20.8.
To choose among these three,we would have to add knowledge about he likelihood ofthese three things being in boxes, or add knowledge aboutthe relative frequencies of the three senses of "pen".
Forexample, we could change the numbers as follows:writitt.q pen(z) '9 D pen(z)enelosure(:e)'31A fenced(z).sl A etei(z) .3tfe  al (x) "n ^  sw,m(z') 9This has the effect of making the writing implementsense slightly more likely than the fenced enclosuresense, and much more likely than the female swan sense?These rules maintain the desirable property of commenosurability, but the numbers are now even more over-loaded.
Hobbs et al already are giving the numbers re-sponsibility for both "probabilities" and "semantic relat-edness", and now we have shown they must account forword frequency information, and both the cost of assump-tions and the quality of the explanation, the two measuresneeded to control search.
As our previous criticisms haveshown, a single number cannot represent even the costand quality of an explanation, much less these additionalfactors.Also nOtE that to constrain search, it is important toconsider bottom-up clues, as in (Charniak 1986) and(Norvig 1987).
It would be a mistake to use the rulesgiven here in a strictly top-down manner, just becausethey are reminiscent of Prolog rules.
(3) There is no notion of a "good" or "bad" interpre-tation, except as an epiphenomenon f the interpretationrules.
In the "pen" example, the difference between failoing completely to understand "pen" and properly disam-biguating it to fenced-enclosure is less than 10% of thetotal cost.
The numbers in the rules could be changed2to increa,~c this difference, but it would still be a quantio.tative rather than qualitative difference.
The problem isthat her~ are at least hree reasons why we might want tomaintair~ ambiguity: because we are unsure of the causeof an event, because it is so mundane as to not need anexplanation, and because it is so unbelievable that thereis no explanation.
This theory does not distinguish thesecases.
The theory has no provision for saying "I don'tunderstand--the only interpretation I can find is a faultyone," and then looking harder for a better interpretation.
(4) There is no way to entorce apenalty worse than thecost of an assumption.
Consider the sentence "Mary saidshe had killed herself."
"Hie logical form is somethinglike:say,(Ma,'y, re) $3 A z = kill(Mary~ Mary)S3oThus, for $6 we can just assume the logical form, withoutnoticing the inherent contradiction.
Now let's considersome fulton.
We've collapsed most of the interesting parksof these rules into eic predicates, leaving just the partsrelevant m the contradiction:,aive(p) "~ A et,.2(p, ~).9 D s,W(P, ~)-~alive(p) "5A etcs( rn, p).5 ?)
kill(m, p)We've ignored time here, but the intent is that the alivepredicate ~s concerned with the time interval or situationafter the killing, including the time of the saying.
Now,an alternative interpretation f L is:alive(Mary) $'3 A -~alive( M ary) $L5A etc2(Mary, x) $2"7 A e tcs(Mary, Mary) $L5Presumably fllere should be some penalty (finite or in~.finite,) for deriving a contradiction, so this interpretationwill total more than $6.
The problem is there is no way topropagate his contradiction back up to the first interpreta-tion, where we just assmned both clauses.
We would liketo penalize that interpretation, too, so that it costs morethan $6, but there is no way to do so.A solution to this problem is to legislate that rather thanfinding a .~olution to the logical form of a sentence, L  thehearer must find a solution to the larger set of proposi-tions, L', where L ~ is derived from L by some process ofdirect, "obvious" inference.
We do not want the full de-ductive closure from L, of course, but we want to allowfor some amount of automatic forward chaining from theinput.
(5) We would like to be able to go on and find alter~native xplanations, perhaps one where Mary is speakingfrom the afterworld, or she is lying, or the speaker is ly-ing.
One could imagine rules for truthful and untruthfulsaying, and such rules could be applied to Mary's speechact.
However, since the goal of the interpretation processis "providing the best explanation of why the sentenceswould be true," it does not seem that we could use therules to consider the possibility of the speaker being un-tmthflfl.
The truth of the text is assumed by the model,and the speaker is not modeled.P robab i l i ty  Based Commensurab i l i tyCharniak and Goldman (1988) started out with a modelvery similar to Hobbs et al, but became concerned with227the lack of theoretical grounding for Ihe number,?
inrules,much as we we.re.
Chamiak and Goldman (1989a, 1989b)switched to a system based strictly on probabilities inthe world, combined by Bayesian probability theory.
Alothough this solves some problems, other problems reomain, and some new ones are introduced.
For example:(1) The approach in (1989a) is based on "events andobjects in the real world".
As the authors point out, itcannot deal with texts involving modal verbs, nor can itdeal with speech acts by characters, or texts where thespeaker is uncooperative.
Soproblem (4) above remains.
(2) Because the probabilities are based on cvcnL~ in thereal world, the basic system often failed to find stories ascoherent as they should be.
For example, the text:Jack got a rope.
lie killed hhnselfisugge.~ts suicide by hanging when interpreted as a text,but when interpreted &~ a partial report of eveuL~ in theworld, that interpretation is less compelling.
(After all,the killing nmy have taken place years after the getting.
)It is only when the two even|s are taken as a part of acoherent text that we assume they are related, tempo?rally and causally.
In Chmniak and Goldman (1989a),the coherence of stories is explained by a (probabilistic)assumption of spatio~temporal l~ality between evenLsmentioned in adjacent sentences in the text, Thus thestory would be treated roughly as if it were:Jack got a rope.
Soon after, nearby, a male was foundto have killed himself.The Bayesian etworks compute a probability of hangingof.3; this seems about right for the later story, but too lowfor the original version.Perhaps anticipating some of these problems, Chamiakand Goldman (198%) introduce an alternate approach inovolving a parameter, /'7, which denotes the probabilitythat two arbitrary things are the same.
They claim thatin stories this parameter should be set higher than in reallife, and that this will lead, tbr example, to a high prob~ability for the interpretation where the rope that Jack gotis the one he used lbr hanging.
But E does a poor job ofcapturing the notion of coherence.
Consider:John picked an integer from one to ten.
Mary did sotoo.Here the probability that they picked the same numbershould be.
1, regardless of whether we are observing reallife or reading a story, and regardless of the value of E.Chamiak and Goldman (1989b) go on to propose athe-ory of "mention" rather than a theory of coincidence, butthey do not develop this alternative.
(3) It seems that for many inferences, frequency in theworld does not play an important role at all.
Consider thetext:Jack wanted to tie a mattress on top of his car.
lie alsofelt like killing himself, lie got some rope.Now, the probability of getting a rope to hang oneselfgiven suicidal feelings must be quite low, maybe .001,while the probability of getting a rope for tying givena desire to secure a mattress i  much higher, maybe .5.Thus the Charniak-Goldman model would strongly pre-fer the latter interpretation.
With the "mention" theory,it would like both interpretations.
Yet ~ sample of hi-formants mostly found the text confllsing-they reportedfinding both interpretations, and were unable to choosebetween them.
It would be useful to find a better char?acteriz~ation f when frequencies in the world are useful,and when they appear to be ignored in favor of some morediscrete notion of "reasonable connection.
"P rob lems Wi th  Both  Mode lsNeither model is completely explicit on how the final ex-planation is constructed, or on what to do with the fi~nal explanation.
In a sense, Hobbs et al's system islike a justification-based truth-maintenance system thatsearches for a single consistent state, possibly explor-ing other higher-cost states along the way.
Charniakand Goldman's system is like an assumption-based truth-maintenance system (ATMS) that keeps track of all pos-sible worlds in one grand model, hut needs a separate in-terpretation process to extract consistent solutions.
Thus,the system does not really do interpretation to the levelthat could lead to de~cisious.
Rather, it provides evidenceupon which decisions can be based.Both approaches are problematic.
Imagine the situa-tion where a hearer is driving a car, and is about o enteran intersection when a traffic officer says "don't - stop".The hearer derives two possible interpretations, one cor-responding to "Don't stop."
and the other correspond-ing to "Don't.
Stop."
Hobbs et al's system would assigncosts and chose the one with the lower cost, no matter howslight the difference.
A more prudent course of actionmight be to recognize the ambiguity, and seek more infor-mation to decide what was intended.
Charniak and Gold-man's ystem would assign probabilities to each proposi-tion, but would offer no assistance as to what to do.
How-ever, if the model were extended from Bayesian etworksto influence diagrams, then a decision could be made, andit would also be possible to direct search to the importantparts of the network.Deliberate ambiguity is also a problematic area.
In apun, for example, the speaker intends that the hearer e-cover two distinct interpretations.
Such subtlety would belost on the models discussed here.
This issue is discussedin more depth in Norvig (1988).A number of arguments show that strict maximizationof probability (or minimization of cos0 is a bad idea.First, as we have seen, we must sometimes admit thatan input is truly ambiguous (intentionally orunintention-ally).Second, there is the problem of computational com-plexity.
Algorithms that guarantee a maximal solutiontake exponential time for the models discussed here.Thus, a large-scale system will be forced to make somesort of approximation, using a less costly algorithm.
Thisis particularly true because we desire an on-line system--one that computes a partial solution after each word isread, and updates the solution in a bounded period oftime.228Third, communication by language has the propertythat "the sg~..aker is always right".
In chess, if I play opti-mally and my opponent plays sub-optimally, I win.
But inlanguage understanding, if I abduce the "optimal" inter-pretation when the speaker had something else in mind,then we have failed to communicate, and I in effect lose.Put another way, there is a clear "evolutionary" advan-tage tbr optimal chess strategies, but once language ha~gevolved to the point where communication is possible,there is no point for a hearer to try to change his interpre-tation strategy to derive what an optimal speaker wouldhave uttered to an optimal hearer-because there are nosuch optimal speakers.
Indeed, there is an advantage totcommunication strategies that can be computed quickly,allowing the participants o spend time on other ~sks.By the second point above, such a strategy must be sub-optimal.Earlier we said that Charuiak and Goldman (1989b) in~troduced the parameter E to account for the coherence ofstories.
But they also provide a brief sketch of another ac-count, one where, in addition to deriving probabilities ofevents in the world, we also consider the probability thatthe speaker would mention aparticular entity at all.
Sucha theory, if worked out, could account for the difficulty inprocessing speech acts that we have shown both modelssuffer from.Itowever, a theory of "mention" alone is not: enough.We also need theories of representing, intending, believeing, directly implying, predicting, and acting.
The chainof reasoning and acting includes at least he following:H attends to utterance U by speaker SH infers "S said U to H"H infers "L represents U"H infers "L directly implies L'"H infers "S intended tI to believe S believes L"H infers "S intended H to believe L'"H believes aportion of L' compatible with H's beliefsH forms predictions about S's future speech actsH acts accordinglyThis still only covers the case of successful, cooperativecommunication, and it leaves out some steps.
A success-fld model should be able to deal with all these rules, whennecessary.
However, the successful model should also beable to quickly bypass the rules in the default case.
Webelieve that he coherence of stories tems primarily fromthe speaker presenting evidence to the hearer in a fashionthat will lead the hearer to focus his attention on the evi-dence, and thereby derive the inferences intended by thespeaker.
Communication is possible because it consistsprimarily of building a single shared explanation.
It isonly in unusual cases where there are multiple possibili-ties that must be weighed against each other and carriedforth.Both models eem to have difficulty distinguishing am-biguity from multiple xplanations.
This makes a differ-ence in cases like the following:John was wondering about lunch when it started torain.
Ite ran into a restaurant.Here there are two reasons why John would enter the4::cstaurant-lto satisfy hunger and to avoid the a'aiu.
~n~ther word,~ there are two explanations, say, A D R and~3 D 1~, and we would like to combine them to yiektA A B ~ /% As we understand it, Itobbs et al appear~o use "exclusive or" in all c~t~es, so they would not findthis explanation.
Charniak and Goldman allow compet-ing explanations tobe joined by an "or" node, but requirecompeting lexical senses to be joined by "exclusive or"~odes.
So they would find A v B 2) R. In other words,~hey would find both explanations probable, which is notquite the same thing as finding the conjunction probable.Now consider:lie's a real sweetheart.
':(his has a straight and an ironic reading: sweetheart(z)and -~sweethearl(z).
The disjunction is a tautologyand the conjunction is a contradiction, so in this casethe Hobbs approach of keeping the alternatives separate.,;ceres better than allowing their disjunction.
Finally, con-sider:Mary was herding water fowl while dodging hostilegunfire.
John saw her duck.Ilere we do not want to combine the two interpretationsi~ato asingle interpretation.
If we amend amodel to allownmltiple xplanations, we must be carefifl that we don'tgo too far.Coherence  Based  Commensurab i l i tyMuch of the criticism above stems from the lack of amodel of textual coherence.
Intuitively, an explanationthat makes the text cohere (by finding propositions thatrelate pieces of the text to other pieces) will be preferredt(, an equi-probable explanation that is not as coherent.Ng and Mooney (1990) attempt to tormally define a mea-sure of coherence.
In their model the logical form of theinput ext is taken as a set of propositions that hey call ob-servations.
The interpretation is the conjunction of theseobservations with another set of propositions called as-sumptions, where ach assumption is introduced as a nodein the proof graph of the observations.
The most coher-ent interpreuttion is the one that maximizes the numberof nodes that support (directly or indirectly) two observa-tions.
Nodes are counted multiple times if they supportmultiple pairs of observations.
The coherence metric isnormalized to the range 0-1 by dividing the count by thetotal number of possible connections.Ng and Mooney give as an example the text"John washappy.
The exam was easy."
They propose two inter-pretations.
The first relies on the (assumed) rule that op-timists are happy.
Thus, by making the single asst, mp-tion that John is an optimist, one can explain the fact thathe is happy.
This takes one assumption to make one ex-planation, but it gets a coherence score of 0, because nopairs of observations are tied together.
The other inter-pretation makes use of the (assumed) rules that succeed-ing on something makes one happy, and that studyingfor and taking an easy exam leads to succeeding on theexam.
This makes two assumptions ( tudying and takingthe exam) and again explains only one input (that Johnwas happy), so it tares worse ~m the ~'atio~a o~ ~ c?pla~Ja~tions to assumptions.
However, it has a higher coherencescore, because it ties together the exam and the exam beoing easy with John being happy.
Therefore, they concludethat coherence is more important than other metrics con..sidered here.We tend to agree with this conclusion.
While the othermodels may be able to duplicate this particular example,consider "John was happy.
The winning lottery numberwas 174625."
Here, we assert, the best interpretation isthat John has number 174625 and has won the lottery.However, a probability-based model would have to put avery low probability on John having that particular mnnobet, and would prefer some other explanation tot his hap..piness.However, we do not feel that coherence should be usedalone without some notion of relative costs or probabili-ties, nor do we feel that Ng and Mooney have accuratelycaptured the notion of coherence.
There are several prob-lems with their metric.First, recall that if an assumption A supports two ob-servations, it adds to the coherence metric, and that anyfurther assumption that supportsA also adds to the metric.Thus, Ng and Mooney prefer explanations with arbitrar-ily long backward chaining, no matter how improbablethe connection.
They have no way to cut off the explana-tion at an appropriate l vel of detail.Second, they do not attempt to choose between alter-natives.
For example, in the "John was wondering abouthmch when it started to rain.
He ran into a restaurant.
"example, they would accept both explanations.
Since twoexplanations are always more coherent than one, they cannever reject a coherent explanation i favor of a betterone.Third, they have no way to guide the search for coher-ence to the right places.
Suppose the input consists ofthree observations, and that the first two have been tiedtogether.
It would be prudent to try to tie the third ob-servations in with the first two, but the coherence metricgives just as many points for finding another explanationfor the first two as for connecting the third to one of theothers.
To their credit, Ng and Mooney discuss aheuristicsearch mechanism that is guided by coherence.
We feelthis is the right idea, but not with their exact coherencemetric.Finally, while coherence is important, it is not the onlycriteria by which texts are constructed.
Consider "Johnwas 22 years old.
He lives in California."
This is per-fectly acceptable as the setting for a story to come.
Wewould not want to try to explain this passage by assum-ing, for example, that John thought that California was agood place for 22-year-dials to live, and thus he movedthere.Conclus ionsAbduction is a good model for language interpretation,and commensurability is a vital component of an abduc-tion system.
But the models discussed here have seriouslimitations, due to technical problems, and due to a fail~229ure to embrace language as a complex activity, involv-ing actions, goals, beliefs, inferences, predictions, andthe like.
We don't believe that knowledge of probabil-ity in the world, plus a few general principles (such as E)can lead to a viable theory of language use.
This "com-plicated" side of language has been studied in depth forover a decade (a list very similar to our chain of reason-ing and acting appears in Morgan (1978)), so our task isclear: to marry these pre-theoretic "complicated" notionswith the fonnal apparatus of commensurable abductiveinterpretation schemes.ReferencesCharniak, E. A neat heory of marker passing, AAAI-86.Charniak, E. and Goldman, R. (1988) A logic for se-mantic interpretation, Proc.
of the 26th Meeting ofthe ACL.Charniak, E. and Goldman,R.
(1989a) A semantics forprobabilistic quantifier-free first-order languages,with particular application to story understanding,IJCA\[-89.Charniak, E. and Goldman, R. (1989b)Plan recognitionin stories and in life, Uncertainty Workshop, HCAI-89.Hobbs, J. R., Stickel, M., Martin, P. and Edwards, D.(1988) Interpretation asabduction, Proc.
of the 26thMeeting of the ACL.Mayfield, L M. (1989) Goal ~inalysis: Plan recognitionin dialogue systems, Univ.
of Cal.
Berkeley EECSDept.
Report No.
UCB/CSD 89/521.McCarthy, J.
(1986) Applications of circumscription toformalizing common-sense knowledge.
ArtificialIntelligence, 26(3).Morgan, J. L. (1978) Toward a rational model of dis-course comprehension.
Theoretical Issues in Natu-ral Language Processing.Ng, H. T. and Mooney, R. J.
(1990) The role of coher-ence in constructing and evaluating abductive expla-nations.
Proceedings of the AAAI Spring Sympo-sium on Automated Abduction.Norvig, P. (1987) A Unified Theory of Inference for TextUnderstanding.
Univ.
of Cal.
Berkeley EECS Dept.Report No.
UCB/CSD 87/339.Norvig, P. (1988) Multiple simultaneous interpretationsof ambiguous sentences.
Proc.
of the lOth AnnualConference of the Cognitive Science Society.Norvig, E (1989) Marker passing as a Weak Method forText Inferencing.
Cognitive Science, 13, 4, 569-620.Pierce, C. S. (1955) Abduction and Induction.
Dover,NY.230
