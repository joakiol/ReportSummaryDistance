Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 451?459,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Crown in Right of Canada.Discriminative Instance Weighting for Domain Adaptationin Statistical Machine TranslationGeorge Foster and Cyril Goutte and Roland KuhnNational Research Council Canada283 Alexandre-Tache?
BlvdGatineau, QC J8X 3X7first.last@nrc.gc.caAbstractWe describe a new approach to SMT adapta-tion that weights out-of-domain phrase pairsaccording to their relevance to the target do-main, determined by both how similar to itthey appear to be, and whether they belong togeneral language or not.
This extends previ-ous work on discriminative weighting by us-ing a finer granularity, focusing on the prop-erties of instances rather than corpus com-ponents, and using a simpler training proce-dure.
We incorporate instance weighting intoa mixture-model framework, and find that ityields consistent improvements over a widerange of baselines.1 IntroductionDomain adaptation is a common concern when op-timizing empirical NLP applications.
Even whenthere is training data available in the domain of inter-est, there is often additional data from other domainsthat could in principle be used to improve perfor-mance.
Realizing gains in practice can be challeng-ing, however, particularly when the target domain isdistant from the background data.
For developersof Statistical Machine Translation (SMT) systems,an additional complication is the heterogeneous na-ture of SMT components (word-alignment model,language model, translation model, etc.
), which pre-cludes a single universal approach to adaptation.In this paper we study the problem of us-ing a parallel corpus from a background domain(OUT) to improve performance on a target do-main (IN) for which a smaller amount of paralleltraining material?though adequate for reasonableperformance?is also available.
This is a standardadaptation problem for SMT.
It is difficult when INand OUT are dissimilar, as they are in the cases westudy.
For simplicity, we assume that OUT is ho-mogeneous.
The techniques we develop can be ex-tended in a relatively straightforward manner to themore general case when OUT consists of multiplesub-domains.There is a fairly large body of work on SMTadaptation.
We introduce several new ideas.
First,we aim to explicitly characterize examples fromOUT as belonging to general language or not.
Pre-vious approaches have tried to find examples thatare similar to the target domain.
This is less ef-fective in our setting, where IN and OUT are dis-parate.
The idea of distinguishing between generaland domain-specific examples is due to Daume?
andMarcu (2006), who used a maximum-entropy modelwith latent variables to capture the degree of speci-ficity.
Daume?
(2007) applies a related idea in asimpler way, by splitting features into general anddomain-specific versions.
This highly effective ap-proach is not directly applicable to the multinomialmodels used for core SMT components, which haveno natural method for combining split features, sowe rely on an instance-weighting approach (Jiangand Zhai, 2007) to downweight domain-specific ex-amples in OUT.
Within this framework, we use fea-tures intended to capture degree of generality, in-cluding the output from an SVM classifier that usesthe intersection between IN and OUT as positive ex-amples.Our second contribution is to apply instance451weighting at the level of phrase pairs.
Sentencepairs are the natural instances for SMT, but sen-tences often contain a mix of domain-specific andgeneral language.
For instance, the sentence Sim-ilar improvements in haemoglobin levels were re-ported in the scientific literature for other epoetinswould likely be considered domain-specific despitethe presence of general phrases like were reportedin.
Phrase-level granularity distinguishes our workfrom previous work by Matsoukas et al(2009), whoweight sentences according to sub-corpus and genremembership.Finally, we make some improvements to baselineapproaches.
We train linear mixture models for con-ditional phrase pair probabilities over IN and OUTso as to maximize the likelihood of an empiricaljoint phrase-pair distribution extracted from a de-velopment set.
This is a simple and effective alter-native to setting weights discriminatively to maxi-mize a metric such as BLEU.
A similar maximum-likelihood approach was used by Foster and Kuhn(2007), but for language models only.
For compar-ison to information-retrieval inspired baselines, eg(Lu?
et al, 2007), we select sentences from OUTusing language model perplexities from IN.
Thisis a straightforward technique that is arguably bet-ter suited to the adaptation task than the standardmethod of treating representative IN sentences asqueries, then pooling the match results.The paper is structured as follows.
Section 2 de-scribes our baseline techniques for SMT adaptation,and section 3 describes the instance-weighting ap-proach.
Experiments are presented in section 4.
Sec-tion 5 covers relevant previous work on SMT adap-tation, and section 6 concludes.2 Baseline SMT Adaptation TechniquesStandard SMT systems have a hierarchical param-eter structure: top-level log-linear weights are usedto combine a small set of complex features, inter-preted as log probabilities, many of which have theirown internal parameters and objectives.
The top-level weights are trained to maximize a metric suchas BLEU on a small development set of approxi-mately 1000 sentence pairs.
Thus, provided at leastthis amount of IN data is available?as it is in oursetting?adapting these weights is straightforward.We focus here instead on adapting the two most im-portant features: the language model (LM), whichestimates the probability p(w|h) of a target word wfollowing an ngram h; and the translation models(TM) p(s|t) and p(t|s), which give the probabilityof source phrase s translating to target phrase t, andvice versa.
We do not adapt the alignment procedurefor generating the phrase table from which the TMdistributions are derived.2.1 Simple BaselinesThe natural baseline approach is to concatenate datafrom IN and OUT.
Its success depends on the twodomains being relatively close, and on the OUT cor-pus not being so large as to overwhelm the contribu-tion of IN.When OUT is large and distinct, its contributioncan be controlled by training separate IN and OUTmodels, and weighting their combination.
An easyway to achieve this is to put the domain-specificLMs and TMs into the top-level log-linear modeland learn optimal weights with MERT (Och, 2003).This has the potential drawback of increasing thenumber of features, which can make MERT less sta-ble (Foster and Kuhn, 2009).2.2 Linear CombinationsApart fromMERT difficulties, a conceptual problemwith log-linear combination is that it multiplies fea-ture probabilities, essentially forcing different fea-tures to agree on high-scoring candidates.
This isappropriate in cases where it is sanctioned by Bayes?law, such as multiplying LM and TM probabilities,but for adaptation a more suitable framework is of-ten a mixture model in which each event may begenerated from some domain.
This leads to a linearcombination of domain-specific probabilities, withweights in [0, 1], normalized to sum to 1.Linear weights are difficult to incorporate into thestandard MERT procedure because they are ?hid-den?
within a top-level probability that representsthe linear combination.1 Following previous work(Foster and Kuhn, 2007), we circumvent this prob-lem by choosing weights to optimize corpus log-likelihood, which is roughly speaking the trainingcriterion used by the LM and TM themselves.1This precludes the use of exact line-maximization withinPowell?s algorithm (Och, 2003), for instance.452For the LM, adaptive weights are set as follows:??
= argmax??w,hp?
(w, h) log?i?ipi(w|h), (1)where ?
is a weight vector containing an element ?ifor each domain (just IN and OUT in our case), piare the corresponding domain-specific models, andp?
(w, h) is an empirical distribution from a target-language training corpus?we used the IN dev setfor this.It is not immediately obvious how to formulate anequivalent to equation (1) for an adapted TM, be-cause there is no well-defined objective for learningTMs from parallel corpora.
This has led previousworkers to adopt ad hoc linear weighting schemes(Finch and Sumita, 2008; Foster and Kuhn, 2007;Lu?
et al, 2007).
However, we note that the final con-ditional estimates p(s|t) from a given phrase tablemaximize the likelihood of joint empirical phrasepair counts over a word-aligned corpus.
This sug-gests a direct parallel to (1):??
= argmax??s,tp?
(s, t) log?i?ipi(s|t), (2)where p?
(s, t) is a joint empirical distribution ex-tracted from the IN dev set using the standard pro-cedure.2An alternative form of linear combination is amaximum a posteriori (MAP) combination (Bacchi-ani et al, 2004).
For the TM, this is:p(s|t) = cI(s, t) + ?
po(s|t)cI(t) + ?, (3)where cI(s, t) is the count in the IN phrase table ofpair (s, t), po(s|t) is its probability under the OUTTM, and cI(t) =?s?
cI(s?, t).
This is motivated bytaking ?
po(s|t) to be the parameters of a Dirich-let prior on phrase probabilities, then maximizingposterior estimates p(s|t) given the IN corpus.
In-tuitively, it places more weight on OUT when lessevidence from IN is available.
To set ?, we used thesame criterion as for ?, over a dev corpus:??
= argmax??s,tp?
(s, t) log cI(s, t) + ?
po(s|t)cI(t) + ?.2Using non-adapted IBM models trained on all available INand OUT data.TheMAP combination was used for TM probabil-ities only, in part due to a technical difficulty in for-mulating coherent counts when using standard LMsmoothing techniques (Kneser and Ney, 1995).32.3 Sentence SelectionMotivated by information retrieval, a number ofapproaches choose ?relevant?
sentence pairs fromOUT by matching individual source sentences fromIN (Hildebrand et al, 2005; Lu?
et al, 2007), orindividual target hypotheses (Zhao et al, 2004).The matching sentence pairs are then added to theIN corpus, and the system is re-trained.
Althoughmatching is done at the sentence level, this informa-tion is subsequently discarded when all matches arepooled.To approximate these baselines, we implementeda very simple sentence selection algorithm in whichparallel sentence pairs from OUT are ranked by theperplexity of their target half according to the IN lan-guage model.
The number of top-ranked pairs to re-tain is chosen to optimize dev-set BLEU score.3 Instance WeightingThe sentence-selection approach is crude in that itimposes a binary distinction between useful andnon-useful parts of OUT.
Matsoukas et al(2009)generalize it by learning weights on sentence pairsthat are used when estimating relative-frequencyphrase-pair probabilities.
The weight on each sen-tence is a value in [0, 1] computed by a perceptronwith Boolean features that indicate collection andgenre membership.We extend the Matsoukas et alapproach in sev-eral ways.
First, we learn weights on individualphrase pairs rather than sentences.
Intuitively, assuggested by the example in the introduction, thisis the right granularity to capture domain effects.Second, rather than relying on a division of the cor-pus into manually-assigned portions, we use featuresintended to capture the usefulness of each phrasepair.
Finally, we incorporate the instance-weightingmodel into a general linear combination, and learnweights and mixing parameters simultaneously.3Bacchiani et al(2004) solve this problem by reconstitut-ing joint counts from smoothed conditional estimates and un-smoothed marginals, but this seems somewhat unsatisfactory.4533.1 ModelThe overall adapted TM is a combination of theform:p(s|t) = ?t pI(s|t) + (1?
?t) po(s|t), (4)where pI(s|t) is derived from the IN corpus us-ing relative-frequency estimates, and po(s|t) is aninstance-weighted model derived from the OUT cor-pus.
This combination generalizes (2) and (3): weuse either ?t = ?
to obtain a fixed-weight linearcombination, or ?t = cI(t)/(cI(t) + ?)
to obtain aMAP combination.We model po(s|t) using a MAP criterion overweighted phrase-pair counts:po(s|t) =c?
(s, t) + ?u(s|t)?s?
c?
(s?, t) + ?
(5)where c?
(s, t) is a modified count for pair (s, t)in OUT, u(s|t) is a prior distribution, and ?
is aprior weight.
The original OUT counts co(s, t) areweighted by a logistic function w?
(s, t):c?
(s, t) = co(s, t) w?
(s, t) (6)= co(s, t) [1 + exp(?
?i?ifi(s, t))]?1,where each fi(s, t) is a feature intended to charac-terize the usefulness of (s, t), weighted by ?i.The mixing parameters and feature weights (col-lectively ?)
are optimized simultaneously using dev-set maximum likelihood as before:??
= argmax??s,tp?
(s, t) log p(s|t;?).
(7)This is a somewhat less direct objective than usedby Matsoukas et al who make an iterative approxi-mation to expected TER.
However, it is robust, effi-cient, and easy to implement.4To perform the maximization in (7), we usedthe popular L-BFGS algorithm (Liu and Nocedal,1989), which requires gradient information.
Drop-ping the conditioning on ?
for brevity, and let-ting c??
(s, t) = c?
(s, t) + ?u(s|t), and c??
(t) =4Note that the probabilities in (7) need only be evaluatedover the support of p?
(s, t), which is quite small when this dis-tribution is derived from a dev set.
Maximizing (7) is thus muchfaster than a typical MERT run.?s?
c??
(s?, t):?
log p(s|t)?
?t= kt[pI(s|t)p(s|t) ?po(s|t)p(s|t)]?
log p(s|t)?
?= 1?
?tp(s|t)[u(s|t)c??(t)?c??
(s, t)c??(t)2]?
log p(s|t)?
?i= 1?
?tp(s|t)[c?
?i(s, t)c??(t)?c??
(s, t)c??i(t)c??
(t)2]where:kt ={1 fixed weight?cI(t)/(cI(t) + ?
)2 MAPc?
?i(s, t) = fi(s, t)(1?
w?
(s, t))c?
(s, t)and:c?
?i(t) =?s?c?
?i(s?, t).3.2 Interpretation and VariantsTo motivate weighting joint OUT counts as in (6),we begin with the ?ideal?
objective for settingmultinomial phrase probabilities ?
= {p(s|t),?st},which is the likelihood with respect to the true INdistribution pI?
(s, t).
Jiang and Zhai (2007) sug-gest the following derivation, making use of the trueOUT distribution po?
(s, t):??
= argmax??s,tpI?
(s, t) log p?
(s|t) (8)= argmax??s,tpI?
(s, t)po?
(s, t)po?
(s, t) log p?(s|t)?
argmax??s,tpI?
(s, t)po?
(s, t)co(s, t) log p?
(s|t),where co(s, t) are the counts from OUT, as in (6).This has solutions:p??
(s|t) =pI?
(s, t)po?
(s, t)co(s, t)/?s?pI?
(s?, t)po?
(s?, t)co(s?, t),and from the similarity to (5), assuming ?
= 0, wesee that w?
(s, t) can be interpreted as approximat-ing pI?
(s, t)/po?
(s, t).
The logistic function, whoseoutputs are in [0, 1], forces pI?
(s, t) ?
po?
(s, t).
Thisis not unreasonable given the application to phrasepairs fromOUT, but it suggests that an interesting al-ternative might be to use a plain log-linear weighting454function exp(?i ?ifi(s, t)), with outputs in [0,?
].We have not yet tried this.An alternate approximation to (8) would be to letw?
(s, t) directly approximate pI?
(s, t).
With the ad-ditional assumption that (s, t) can be restricted to thesupport of co(s, t), this is equivalent to a ?flat?
alter-native to (6) in which each non-zero co(s, t) is set toone.
This variant is tested in the experiments below.A final alternate approach would be to combineweighted joint frequencies rather than conditionalestimates, ie: cI(s, t) + w?
(s, t)co(, s, t), suitablynormalized.5 Such an approach could be simulatedby a MAP-style combination in which separate ?
(t)values were maintained for each t. This would makethe model more powerful, but at the cost of havingto learn to downweight OUT separately for each t,which we suspect would require more training datafor reliable performance.
We have not explored thisstrategy.3.3 Simple FeaturesWe used 22 features for the logistic weightingmodel, divided into two groups: one intended to re-flect the degree to which a phrase pair belongs togeneral language, and one intended to capture simi-larity to the IN domain.The 14 general-language features embodystraightforward cues: frequency, ?centrality?
asreflected in model scores, and lack of burstiness.They are:?
total number of tokens in the phrase pair (1);?
OUT corpus frequency (1);?
OUT-corpus frequencies of rarest source andtarget words (2);?
perplexities for OUT IBM1 models, in both di-rections (2);?
average and minimum source and target word?document frequencies?
in the OUT corpus,using successive 100-line pseudo-documents6(4); and5We are grateful to an anonymous reviewer for pointing thisout.6One of our experimental settings lacks document bound-aries, and we used this approximation in both settings for con-sistency.?
average and minimum source and target wordvalues from the OUT corpus of the followingstatistic, intended to reflect degree of burstiness(higher values indicate less bursty behaviour):g/(L ?
L/(l + 1) + (), where g is the sumover all sentences containing the word of thedistance (number of sentences) to the nearestsentence that also contains the word, L is thetotal number of sentences, l is the number ofsentences that contain the word, and ( is a smallconstant (4).The 8 similarity-to-IN features are based on wordfrequencies and scores from various models trainedon the IN corpus:?
1gram and 2gram source and target perplexitiesaccording to the IN LM (4);7?
source and target OOV counts with respect toIN (2); and?
perplexities for IN IBM1 models, in both direc-tions (2).To avoid numerical problems, each feature wasnormalized by subtracting its mean and dividing byits standard deviation.3.4 SVM FeatureIn addition to using the simple features directly, wealso trained an SVM classifier with these featuresto distinguish between IN and OUT phrase pairs.Phrase tables were extracted from the IN and OUTtraining corpora (not the dev as was used for instanceweighting models), and phrase pairs in the intersec-tion of the IN and OUT phrase tables were used aspositive examples, with two alternate definitions ofnegative examples:1.
Pairs from OUT that are not in IN, but whosesource phrase is.2.
Pairs from OUT that are not in IN, but whosesource phrase is, and where the intersection ofIN and OUT translations for that source phraseis empty.7In the case of the Chinese experiments below, source LMswere trained using text segmented with the LDC segmenter, aswere the other Chinese models in our system.455The classifier trained using the 2nd definition hadhigher accuracy on a development set.
We used it toscore all phrase pairs in the OUT table, in order toprovide a feature for the instance-weighting model.4 Experiments4.1 Corpora and SystemWe carried out translation experiments in two dif-ferent settings.
The first setting uses the Euro-pean Medicines Agency (EMEA) corpus (Tiede-mann, 2009) as IN, and the Europarl (EP) cor-pus (www.statmt.org/europarl) as OUT,for English/French translation in both directions.The dev and test sets were randomly chosen fromthe EMEA corpus.
Figure 1 shows sample sentencesfrom these domains, which are widely divergent.The second setting uses the news-related sub-corpora for the NIST09 MT Chinese to Englishevaluation8 as IN, and the remaining NIST paral-lel Chinese/English corpora (UN, Hong Kong Laws,and Hong Kong Hansard) as OUT.
The dev cor-pus was taken from the NIST05 evaluation set, aug-mented with some randomly-selected material re-served from the training set.
The NIST06 andNIST08 evaluation sets were used for testing.
(Thusthe domain of the dev and test corpora matches IN.
)Compared to the EMEA/EP setting, the two do-mains in the NIST setting are less homogeneous andmore similar to each other; there is also considerablymore IN text available.The corpora for both settings are summarized intable 1.corpus sentence pairsEuroparl 1,328,360EMEA train 11,770EMEA dev 1,533EMEA test 1,522NIST OUT 6,677,729NIST IN train 2,103,827NIST IN dev 1,894NIST06 test 1,664NIST08 test 1,357Table 1: Corpora8www.itl.nist.gov/iad/mig//tests/mt/2009The reference medicine for Silapo isEPREX/ERYPO, which contains epoetin alfa.Le me?dicament de re?fe?rence de Silapo estEPREX/ERYPO, qui contient de l?e?poe?tine alfa.
?I would also like to point out to commissioner Liika-nen that it is not easy to take a matter to a nationalcourt.Je voudrais pre?ciser, a` l?adresse du commissaireLiikanen, qu?il n?est pas aise?
de recourir aux tri-bunaux nationaux.Figure 1: Sentence pairs from EMEA (top) and Europarltext.We used a standard one-pass phrase-based sys-tem (Koehn et al, 2003), with the following fea-tures: relative-frequency TM probabilities in bothdirections; a 4-gram LM with Kneser-Ney smooth-ing; word-displacement distortion model; and wordcount.
Feature weights were set using Och?s MERTalgorithm (Och, 2003).
The corpus was word-aligned using both HMM and IBM2 models, and thephrase table was the union of phrases extracted fromthese separate alignments, with a length limit of 7.It was filtered to retain the top 30 translations foreach source phrase using the TM part of the currentlog-linear model.4.2 ResultsTable 2 shows results for both settings and all meth-ods described in sections 2 and 3.
The 1st blockcontains the simple baselines from section 2.1.
Thenatural baseline (baseline) outperforms the pure INsystem only for EMEA/EP fren.
Log-linear combi-nation (loglin) improves on this in all cases, and alsobeats the pure IN system.The 2nd block contains the IR system, which wastuned by selecting text in multiples of the size of theEMEA training corpus, according to dev set perfor-mance.
This significantly underperforms log-linearcombination.The 3rd block contains the mixture baselines.
Thelinear LM (lin lm), TM (lin tm) and MAP TM (maptm) used with non-adapted counterparts perform inall cases slightly worse than the log-linear combi-nation, which adapts both LM and TM components.However, when the linear LM is combined with a456method EMEA/EP NISTfren enfr nst06 nst08in 32.77 31.98 27.65 21.65out 20.42 17.41 19.85 15.71baseline 33.61 31.15 26.93 21.01loglin 35.94 32.62 28.09 21.85ir 33.75 31.91 ??
?
?lin lm 35.61 31.55 28.02 21.68lin tm 35.32 32.52 27.16 21.32map tm 35.15 31.99 27.20 21.17lm+lin tm 36.42 33.49 27.83 22.03lm+map tm 36.28 33.31 28.05 22.11iw all 36.55 33.73 28.74 22.28iw all map 37.01 33.90 30.04 23.76iw all flat 36.50 33.42 28.31 22.13iw gen map 36.98 33.75 29.81 23.56iw sim map 36.82 33.68 29.66 23.53iw svm map 36.79 33.67 ??
?
?Table 2: Results, for EMEA/EP translation into English(fren) and French (enfr); and for NIST Chinese to En-glish translation with NIST06 and NIST08 evaluationsets.
Numbers are BLEU scores.linear TM (lm+lin tm) or MAP TM (lm+map TM),the results are much better than a log-linear com-bination for the EMEA setting, and on a par forNIST.
This is consistent with the nature of these twosettings: log-linear combination, which effectivelytakes the intersection of IN and OUT, does relativelybetter on NIST, where the domains are broader andcloser together.
Somewhat surprisingly, there do notappear to be large systematic differences betweenlinear and MAP combinations.The 4th block contains instance-weighting mod-els trained on all features, used within a MAP TMcombination, and with a linear LM mixture.
Theiw all map variant uses a non-0 ?
weight on a uni-form prior in po(s|t), and outperforms a versionwith ?
= 0 (iw all) and the ?flattened?
variant de-scribed in section 3.2.
Clearly, retaining the origi-nal frequencies is important for good performance,and globally smoothing the final weighted frequen-cies is crucial.
This best instance-weighting modelbeats the equivalant model without instance weightsby between 0.6 BLEU and 1.8 BLEU, and beats thelog-linear baseline by a large margin.The final block in table 2 shows models trainedon feature subsets and on the SVM feature describedin 3.4.
The general-language features have a slightadvantage over the similarity features, and both arebetter than the SVM feature.5 Related WorkWe have already mentioned the closely related workby Matsoukas et al(2009) on discriminative cor-pus weighting, and Jiang and Zhai (2007) on (non-discriminative) instance weighting.
It is difficult todirectly compare the Matsoukas et alresults withours, since our out-of-domain corpus is homoge-neous; given heterogeneous training data, however,it would be trivial to include Matsoukas-style iden-tity features in our instance-weighting model.
Al-though these authors report better gains than ours,they are with respect to a non-adapted baseline.
Fi-nally, we note that Jiang?s instance-weighting frame-work is broader than we have presented above, en-compassing among other possibilities the use of un-labelled IN data, which is applicable to SMT settingswhere source-only IN corpora are available.It is also worth pointing out a connection withDaume?
?s (2007) work that splits each feature intodomain-specific and general copies.
At first glance,this seems only peripherally related to our work,since the specific/general distinction is made for fea-tures rather than instances.
However, for multino-mial models like our LMs and TMs, there is a one toone correspondence between instances and features,eg the correspondence between a phrase pair (s, t)and its conditional multinomial probability p(s|t).As mentioned above, it is not obvious how to ap-ply Daume?
?s approach to multinomials, which donot have a mechanism for combining split features.Recent work by Finkel and Manning (2009) whichre-casts Daume?
?s approach in a hierarchical MAPframework may be applicable to this problem.Moving beyond directly related work, majorthemes in SMT adaptation include the IR (Hilde-brand et al, 2005; Lu?
et al, 2007; Zhao et al,2004) and mixture (Finch and Sumita, 2008; Fos-ter and Kuhn, 2007; Koehn and Schroeder, 2007; Lu?et al, 2007) approaches for LMs and TMs describedabove, as well as methods for exploiting monolin-gual in-domain text, typically by translating it auto-matically and then performing self training (Bertoldi457and Federico, 2009; Ueffing et al, 2007; Schwenkand Senellart, 2009).
There has also been somework on adapting the word alignment model prior tophrase extraction (Civera and Juan, 2007; Wu et al,2005), and on dynamically choosing a dev set (Xuet al, 2007).
Other work includes transferring latenttopic distributions from source to target language forLM adaptation, (Tam et al, 2007) and adapting fea-tures at the sentence level to different categories ofsentence (Finch and Sumita, 2008).6 ConclusionIn this paper we have proposed an approach forinstance-weighting phrase pairs in an out-of-domaincorpus in order to improve in-domain performance.Each out-of-domain phrase pair is characterized bya set of simple features intended to reflect how use-ful it will be.
The features are weighted within alogistic model to give an overall weight that is ap-plied to the phrase pair?s frequency prior to makingMAP-smoothed relative-frequency estimates (dif-ferent weights are learned for each conditioningdirection).
These estimates are in turn combinedlinearly with relative-frequency estimates from anin-domain phrase table.
Mixing, smoothing, andinstance-feature weights are learned at the same timeusing an efficient maximum-likelihood procedurethat relies on only a small in-domain developmentcorpus.We obtained positive results using a very sim-ple phrase-based system in two different adaptationsettings: using English/French Europarl to improvea performance on a small, specialized medical do-main; and using non-news portions of the NIST09training material to improve performance on thenews-related corpora.
In both cases, the instance-weighting approach improved over a wide range ofbaselines, giving gains of over 2 BLEU points overthe best non-adapted baseline, and gains of between0.6 and 1.8 over an equivalent mixture model (withan identical training procedure but without instanceweighting).In future work we plan to try this approach withmore competitive SMT systems, and to extend in-stance weighting to other standard SMT componentssuch as the LM, lexical phrase weights, and lexical-ized distortion.
We will also directly compare witha baseline similar to the Matsoukas et alapproach inorder to measure the benefit from weighting phrasepairs (or ngrams) rather than full sentences.
Finally,we intend to explore more sophisticated instance-weighting features for capturing the degree of gen-erality of phrase pairs.ReferencesACL.
2007.
Proceedings of the 45th Annual Meeting ofthe Association for Computational Linguistics (ACL),Prague, Czech Republic, June.Michel Bacchiani, Brian Roark, and Murat Saraclar.2004.
Language model adaptation with MAP esti-mation and the perceptron algorithm.
In NAACL04(NAA, 2004).Nicola Bertoldi and Marcello Federico.
2009.
Do-main adaptation for statistical machine translation withmonolingual resources.
In WMT09 (WMT, 2009).Jorge Civera and Alfons Juan.
2007.
Domain adaptationin Statistical Machine Translation with mixture mod-elling.
In WMT07 (WMT, 2007).Hal Daume?
III and Daniel Marcu.
2006.
Domain Adap-tation for Statistical Classifiers.
Journal of ArtificialIntelligence Research, 26:101?126.Hal Daume?
III.
2007.
Frustratingly Easy Domain Adap-tation.
In ACL-07 (ACL, 2007).Andrew Finch and Eiichiro Sumita.
2008.
Dynamicmodel interpolation for statistical machine translation.In Proceedings of the ACL Workshop on StatisticalMachine Translation, Columbus, June.
WMT.Jenny Rose Finkel and Christopher D. Manning.
2009.Hierarchical Bayesian domain adaptation.
In Proceed-ings of the Human Language Technology Conferenceof the North American Chapter of the Association forComputational Linguistics (NAACL), Boulder, June.NAACL.George Foster and Roland Kuhn.
2007.
Mixture-modeladaptation for SMT.
In WMT07 (WMT, 2007).George Foster and Roland Kuhn.
2009.
Stabilizing min-imum error rate training.
In WMT09 (WMT, 2009).Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,and Alex Waibel.
2005.
Adaptation of the translationmodel for statistical machine translation based on in-formation retrieval.
In Proceedings of the 10th EAMTConference, Budapest, May.Jing Jiang and ChengXiang Zhai.
2007.
InstanceWeighting for Domain Adaptation in NLP.
In ACL-07 (ACL, 2007).Reinhard Kneser and Hermann Ney.
1995.
Improvedbacking-off for m-gram language modeling.
In Pro-ceedings of the International Conference on Acoustics,458Speech, and Signal Processing (ICASSP) 1995, pages181?184, Detroit, Michigan.
IEEE.Philipp Koehn and Josh Schroeder.
2007.
Experimentsin domain adaptation for statistical machine transla-tion.
In Proceedings of the Second Workshop on Sta-tistical Machine Translation, pages 224?227, Prague,Czech Republic, June.
Association for ComputationalLinguistics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of the Human Language Technology Conferenceof the North American Chapter of the Association forComputational Linguistics (NAACL), pages 127?133,Edmonton, May.
NAACL.D.
C. Liu and J. Nocedal.
1989.
On the limited mem-ory method for large scale optimization.
Mathemati-cal Programming B, 45(3):503?528.Yajuan Lu?, Jin Huang, and Qun Liu.
2007.
ImprovingStatistical Machine Translation Performance by Train-ing Data Selection and Optimization.
In Proceedingsof the 2007 Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), Prague, CzechRepublic.Spyros Matsoukas, Antti-Veikko I. Rosti, and BingZhang.
2009.
Discriminative corpus weight estima-tion for machine translation.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), Singapore.NAACL.
2004.
Proceedings of the Human LanguageTechnology Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL), Boston, May.Franz Josef Och.
2003.
Minimum error rate training forstatistical machine translation.
In Proceedings of the41th Annual Meeting of the Association for Computa-tional Linguistics (ACL), Sapporo, July.
ACL.Holger Schwenk and Jean Senellart.
2009.
Translationmodel adaptation for an arabic/french news translationsystem by lightly-supervised training.
In Proceedingsof MT Summit XII, Ottawa, Canada, September.
Inter-national Association for Machine Translation.Yik-Cheung Tam, Ian Lane, and Tanja Schultz.
2007.Bilingual-LSA Based LM Adaptation for Spoken Lan-guage Translation.
In ACL-07 (ACL, 2007).Jorg Tiedemann.
2009.
News from opus - a collectionof multilingual parallel corpora with tools and inter-faces.
In N. Nicolov, K. Bontcheva, G. Angelova,and R. Mitkov, editors, Recent Advances in NaturalLanguage Processing, volume V, pages 237?248.
JohnBenjamins, Amsterdam/Philadelphia.Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar.2007.
Transductive learning for statistical machinetranslation.
In ACL-07 (ACL, 2007).WMT.
2007.
Proceedings of the ACL Workshop on Sta-tistical Machine Translation, Prague, June.WMT.
2009.
Proceedings of the 4th Workshop on Statis-tical Machine Translation, Athens, March.Hua Wu, Haifeng Wang, and Zhanyi Liu.
2005.Alignment model adaptation for domain-specific wordalignment.
In Proceedings of the 43th Annual Meet-ing of the Association for Computational Linguistics(ACL), Ann Arbor, Michigan, July.
ACL.Jia Xu, Yonggang Deng, Yuqing Gao, and Hermann Ney.2007.
Domain dependent statistical machine transla-tion.
In MT Summit XI, Copenhagen, September.Bing Zhao, Matthias Eck, and Stephan Vogel.
2004.Language model adaptation for statistical machinetranslation with structured query models.
In Proceed-ings of the International Conference on ComputationalLinguistics (COLING) 2004, Geneva, August.459
