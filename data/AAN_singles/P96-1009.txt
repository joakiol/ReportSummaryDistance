A Robust System for Natural Spoken DialogueJames F. Allen, Bradford W. Miller, Eric K. Ringger, Teresa SikorskiDept.
o f  Computer  Sc ienceUnivers i ty  of  RochesterRochester ,  NY  14627{james, miller, ringger, s ikorsk i )@cs.rochester .eduhttp : //www.
cs.
rochester, edu/research/tra ins /AbstractThis paper describes a system that leads us tobelieve in the feasibility of constructing naturalspoken dialogue systems in task-oriented domains.
Itspecifically addresses the issue of robust interpre-tation of speech in the presence of recognitionerrors.
Robustness i achieved by a combination ofstatistical error post-correction, syntactically- andsemantically-driven robust parsing, and extensiveuse of the dialogue context.
We present anevaluation of the system using time-to-completionand the quality of the final solution that suggeststhat most native speakers of English can use thesystem successfully with virtually no training.1.
IntroductionWhile there has been much research on natural dialogue,there have been few working systems because of thedifficulties in obtaining robust behavior.
Given overtwenty years of research in this area, if we can'tconstruct a robust system even in a simple domain thenthat bodes ill for progress in the field.
In particular,without some working systems, we are very limited inhow we can evaluate the worth of different models.The prime goal of the work reported here was todemonstrate that it is feasible to construct robustspoken natural dialogue systems.
We were not seekingto develop new theories, but rather to develop tech-niques to enable existing theories to be applied inpractice.
We chose a domain and task that was as simpleas possible yet couldn't be solved without thecollaboration of the human and system.
In addition,there were three fundamental requirements:?
the system must run in near real-time;?
the user should need minimal training and not beconstrained in what can be said; and?
the dialogue should have a concrete result that canbe independently evaluated.The second constraint means we must handle naturaldialogue, namely dialogue as people use it rather than aconstrained form of interaction determined by thesystem (which is often called a dialogue).
We can onlycontrol the complexity of the dialogue by controllingthe complexity of the task.
Increasing the taskcomplexity naturally increases the complexity of thedialogue.
This paper reports on the first stage of thisprocess, working with a highly simplified omain.At the start of this experiment in November 1994, wehad no idea whether it was possible.
While researcherswere reporting good accuracy (upwards of 95%) forspeech systems in simple question-answering tasks, ourdomain was considerably different with a much morespontaneous form of interaction.We also knew that it would not be possible to directlyuse general models of plan recognition to aid in speechact interpretation (as in Alien & Perrault, 1980, Litman& Allen 1987, Carberry 1990), as these models wouldnot lend themselves to real-time processing.
Similarly,it would not be feasible to use general planning modelsfor the system back-end and for planning its responses.We could not, on the other hand, completely abandon theideas underlying the plan-based approach, as we knew ofno other theory that could provide an account for theinteractions.
Our approach was to try to retain theoverall structure of plan-based systems, but to usedomain-specific reasoning techniques to provide real-timeperformance.Dialogue systems are notoriously hard to evaluate asthere is no well-defined "correct answer".
So we cannotgive end-to-end accuracy measures as is typically done tomeasure the performance of speech recognition systemsand parsing systems.
This is especially true whenevaluating dialogue robustness, which results from manydifferent sources: correcting speech recognition errors,using semantic knowledge to interpret fragments, andusing dialogue strategies to keep the dialogue flowingefficiently despite recognition and interpretation errors.The approach we take is to use task-based evaluation.We measure how well the system does at helping theuser solve the problem.
The two most telling measuresare time-to-completion a d the quality of the finalsolution.
In the evaluation described later in this paper,we show that all our subjects were able to use TRAINS-95 to solve problems with only minimal training.
Wealso evaluated the overall effectiveness of our robustprocessing techniques by comparing spoken dialogueswith keyboard dialogues by the same subjects.
Evenwith a 30% word error rate (including insertion errors),speech turned out to be considerably more efficient hankeyboard input in this domain.2.
The  Task and Example SessionThe domain in TRAINS-95 is simple route planning.The user is given a map on a screen showing cities,62connections and the locations of a set of trains (seeFigure 1), and a verbal specification of a set ofdestination cities where trains are needed.
The task is tofind the most efficient set of routes possible.
The routeplanner used by the system is deliberately weak so thatinteraction is needed to find good plans.
Specifically,the planner cannot find routes longer than four hopswithout an intermediate city, and when it can generate aroute, it randomly selects among the possibilities.Typically, the examples in papers on dialogue systemsare carefully hand-constructed and designed to show offspecific system capabilities.
Such examples, however,give little feeling for how robust a system is.
Muchmore revealing is how a system responds to unplannedinteractions with naive users, and how it deals with theinteraction when things start to go wrong.
Thus, wewon't present any examples in which everything wentsmoothly.
Rather, we present a dialogue that stressesthe system's capabilities, better illuminating whatworks and what areas require further improvement.The dialogue below was with a non-computer personwho had used the system a few times before.
In thetranscripts, we show the input as it was produced by thespeech recognizer in ALL CAPS followed by what wasactually said.
If  the recognition was perfect we justshow the speech recognition output.
The dialoguecontains a significant number of errors and has a 29.5%word error rate.
The system display is also shown at keypoints 1.
In this problem, the engines start at Detroit,Montreal and Albany and the goal is to get trains toMilwaukee, Lexington and Washington.S: Ok.
I think I'm ready to start.U" OKAY LET'S SEE CONTAIN FROM DETROIT TO WASHINGTONOkay.
Let's take a train from Detroit to Washington.S: What route would you like to get from Detroit toWashington?U: LET'S GO VIA TOLEDO AND PITTSBURGHS: (displays Figure 2) The terminal at city Scranton isdelaying traffic due to localized heavy winds.
Theterminal at city Baltimore is delaying traffic due tolocalized heavy winds.
An additional five hours willbe needed to travel through them due to decreasedvisibility.U: NOW LET'S TAKE THE TRAIN FROM DETROIT TOWASHINGTON D S_X ANYNo.
Let's take the train from Detroit to Washingtonvia Cincinnati.S: (displays Figure 3) Okay.U: OKAY IT THAT'S OKAY NOWOkay that - that's okay nowS: Pardon Me?U; UP OKAY NOW LET'S TAKE THE TRAIN FROM MONTREAL TOLEXINGTONOkay.
Now let's take the train from Montreal toLexington.'
We apologize for the figures.
The actual system uses colordisplays.
The best way to present examples is by video.
Aquicktime movie can be found inhttp://www.cs.rochester.edu/research/trains/ACL96.Figure 1: The initial scenarioFigure 2: The proposed routeFigure 3: The corrected route63S: I need help choosing a route from Montreal toLexington.U- LET'S GO P_M TO TRYLet's go via DetroitS: (displays a route to Detroit but not on to Lexington)Is this OK?U: YES NOW LET'S GO TO LEXINGTONS: Yep.U: OKAY NOW ADD STATE THE LAST TRAIN AND GO FROMALBANY TO O O'SOkay Now let's take the last train and go fromAlbany to Milwaukee.S: No.
What city are you trying to have the engine atMontreal arrive at, if I caught your drift.
I don'tunderstand where we are sending the engine atAlbany to.U: ME A JET ADD ALBANY NEEDS TO GO TO MILWAUKEEThe engine at Albany needs to go to Milwaukee.S: Tell me a route to use to get from Albany toMilwaukee, please.U" I'D GO VIA BUFFALOUh - Go via Buffalo.S: (displays a route through Toronto and Buffalo) Yes.U: GO B_X SYRACUSE AT BUFFALOGo via Syracuse and Buffalo.S: (displays Figure 4) yeah.U; THAT'S COULD I CANThat's good.
I'm done.S: Hey, itsthe programming.U: I_NEED DONEI'm done.3.
The SystemThe TRAINS-95 system is organized as shown inFigure 5.
At the top are the I/O facilities.
The speechrecognition system is the Sphinx-II system from CMU(Huang et al 1993).
The speech synthesizer is acommercial product: the TRUETALK system fromEntropies.
The rest of the system was built atRochester.
The display supports a communicationlanguage that allows other modules to control thecontent of the display.
It also handles keyboard input.The speech recognition output is passed through thepost-processor described in section 4.
The parser,described in section 5, accepts input either f om thepost-processor (for speech) or the display manager (forkeyboard), and produces a set of speech actinterpretations that are passed to the discourse manager,described in section 6.
The discourse manager breaksinto a range of subcomponents handling reference,speech act interpretation and planning (the verbalreasoner), and the back-end of the system: the problemsolver and domain reasoner.
When a speech act isplanned for output, it is passed to the generator, whichconstructs a sentence and passes this to both the speechsynthesizer and the display.The generator is a simple template-based system.
It usestemplates associated with different speech act forms thatare instantiated with descriptions of the particularobjects involved.
The form of these descriptions idefined for each class of objects in the domain.Figure 4: The final routesI S P ee ~h~eCx?-Iglni t i?
npost  I G eSnPeeea tcih?
n[ / / ~I Prooessor I / I  iisplay [~4~ ~ ] Manager [I Discourse IReference II VerbalReasoner SolverFigure 5 : The TRAINS-95 System ArchitectureIn order to stress the system in our robustnessevaluation, we used the ATIS language model providedfrom CMU.
This system yields an overall word error rateof 30% on TRAINS-95 dialogues, as opposed to a 20%error rate that we can currently obtain by using languagemodels trained on our TRAINS corpus.
While thisaccuracy rate is significantly ower than often reported inthe literature, remember that most speech recognitionresults are reported for read speech, or for constraineddialogue applications uch as ATIS.
Natural dialogueinvolves a more spontaneous form of interaction that ismuch more difficult tointerpret.4.
S ta t i s t i ca l  E r ro r  Pos t -Cor rec t ionThe following are examples of speech recognition (SR)errors that occurred in the sample dialogue.
In each, thewords tagged REF indicate what was actually said, while64those tagged with HYP indicate what the speechrecognition system proposed, and HYP' indicates theoutput of SPEECHPP, our post-processor.
While thecorrected transcriptions are not perfect, they are typicallya better approximation of the actual utterance.
As thefirst example shows, some recognition errors are simpleword-for-word confusions:HYP: GO B_X SYRACUSE AT BUFFALOHYP': GO VIA SYRACUSE VIA BUFFALOREF: GO VIA SYRACUSE AND BUFFALOIn the next example, a single word was replaced bymore than one smaller word:HYP: LET'S GO P_M TO TRYHYP': LET'S GO P_M TO DETROITREF: LET'S GO VIA DETROITThe post-processor yields fewer errors by effectivelyrefining and tuning the vocabulary used by the speechrecognizer.
To achieve this, we adapted some techniquesfrom statistical machine translation (such as Brown etal., 1990) in order to model the errors that Sphinx-IImakes in our domain.
Briefly, the model consists oftwo parts: a channel model, which accounts for errorsmade by the SR, and the language model, whichaccounts for the likelihood of a sequence of words beinguttered in the first place.More precisely, given an observed word sequence ofrom the speech recognizer, SPEECHPP finds the mostlikely original word sequence by finding the sequence sthat maximizes Prob(ols) * Prob(s), where?
Prob(s) is the probability that the user would uttersequence s, and?
Prob(ols) is the probability that the SR producesthe sequence o when s was actually spoken.For efficiency, it is necessary to estimate thesedistributions with relatively simple models by makingindependence assumptions.
For Prob(s), we train aword-bigram "back-offf language model (Katz, 87) fromhand-transcribed dialogues previously collected with theTRAINS-95 system.
For P(ols), we build a channelmodel that assumes independent word-for-wordsubstitutions; i.e.,Prob(o I s) = 1-I i Prob(oi I si)The channel model is trained by automatically aligningthe hand transcriptions with the output of Sphinx-II onthe utterances in the (SPEECHPP) training set and bytabulating the confusions that occurred.
We use aViterbi beam-search to find the s that maximizes theexpression.
This technique is widely known so is notdescribed here (see Forney (1973) and Lowerre (1986)).Having a relatively small number of TRAINS-95dialogues for training, we wanted to investigate howwell the data could be employed in models for both theSR and the SPEECHPP.
We ran several experiments og5 T !
!~PEECHPPj+ Augment&t Sphinx-I!
i~i Aug~cntrxl Sphinx-U Alone i ~--~80 ............................................................. i ,SI~EECl~P..~:.Baselidc.Sphinx:.II~.~..757065 .... ~ .........6O, ,  i !
i0 5()(X) IIX)~X) 15(XX) 2000(I 25000# Trains-95 Words in Training SetFigure 6: Post-processing Evaluationweigh our options.
For a baseline, we built a class-basedback-off language model for Sphinx-II using onlytranscriptions of ATIS spoken utterances.
Using thismodel, the performance ofSphinx-II alone on TRAINS-95 data was 58.7%.
Note that this figure is lower thanour previously mentioned average of 70%, since we wereunable to exactly replicate the ATIS model from CMU.First, we used varying amounts of training dataexclusively for building models for the SPEECHPP;this scenario would be most relevant if the speechrecognizer were a black-box and we did not know how totrain its model(s).
Second, we used varying amounts ofthe training data exclusively for augmenting the ATISdata to build language models for Sphinx-II.
Third, wecombined the methods, using the training data both toextend the language models for Sphinx-II and to thentrain SPEECHPP on the newly trained SR.The results of the first experiment are shown by thebottom curve of Figure 6, which indicates theperformance of the SPEECHPP with the baselineSphinx-II.
The first point comes from using approx.25% of the available training data in the SPEECHPPmodels.
The second and third points come from usingapprox.
50% and 75%, respectively, of the availabletraining data.
The curve clearly indicates that theSPEECHPP does a reasonable job of boosting our wordrecognition rates over baseline Sphinx-II andperformance improves with additional training data.
Wedid not train with all of our available data, since theremainder was used for testing to determine the resultsvia repeated leave-one-out cross-validation.
The error barsin the figure indicate 95% confidence intervals.Similarly, the results of the second experiment areshown by the middle curve.
The points reflect theperformance of Sphinx-II (without SPEECHPP) whenusing 25%, 50%, and 75% of the available training datain its LM.
These results indicate that equivalent amountsof training data can be used with greater impact in thelanguage model of the SR than in the post-processor.Finally, the outcome of the third experiment is reflected65in the uppermost curve.
Each point indicates theperformance of the SPEECHPP using a set of modelstrained on the behavior of Sphinx-II for thecorresponding point from the second experiment.
Theresults from this experiment indicate that even if thelanguage model of the SR can be modified, then thepost-processor trained on the same new data can stillsignificantly improve word recognition accuracy on aseparate test set.
Hence, whether the SR's models aretunable or not, the post-processor is in neither caseredundant.Since these experiments were performed, we haveenhanced the channel model by relaxing the constraintthat replacement errors be aligned on a word-by-wordbasis.
We employ a fertility model (Brown et al 1990)that indicates how likely each word is to map tomultiple words or to a partial word in the SR output.This extension allows us to better handle the secondexample above, replacing TO TRY with DETROIT.
Formore details, see Ringger and Allen (1996).5.
Robust ParsingGiven that speech recognition errors are inevitable,robust parsing techniques are essential.
We use a purebottom-up arser (using the system described in (Allen,1995)) in order to identify the possible constituents atany point in the utterance based on syntactic andsemantic restrictions.
Every constituent in eachgrammar rule specifies both a syntactic ategory and asemantic ategory, plus other features to encode co-occurance restrictions as found in many grammars.
Thesemantic features encode selectional restrictions, mostof which are domain-independent.
For example, there isno general rule for PP attachment in the grammar.Rather there are rules for temporal adverbialmodification (e.g., at eight o'clock), locationalmodification (e.g., in Chicago), and so on.The end result of parsing is a sequence of speech actsrather than a syntactic analysis.
Viewing the output as asequence of speech acts has significant impact on theform and style of the grammar.
It forces an emphasis onencoding semantic and pragmatic features in thegrammar.
There are, for instance, numerous rules thatencode specific conventional speech acts (e.g., That'sg o o d is a CONFIRM,  O k a y is aCONFIRM/ACKNOWLEDGE, Let's go to Chicago isa SUGGEST, and so on).
Simply classifying suchutterances as sentences would miss the point.
Thus theparser computes a set of plausible speech actinterpretation based on the surface form, similar to themodel described in Hinkelman & Allen (1989).We use a hierarchy of speech acts that encode differentlevels of vagueness, including a TELL act that indicatescontent without an identifiable illocutionary force.
Thisallows us to always have an illocutionary force that canbe refined as more of the utterance is processed.
Thefinal interpretation of an utterance is the sequence ofspeech acts that provides the "minimal covering" of theinput - i.e., the shortest sequence that accounts for theinput.
Even if an utterance was completelyuninterpretable, the parser would still produce output - aTELL act with no content.For example, consider an utterance from the sampledialogue that was garbled: OKAY NOW !
TAKE THE LAST TRAININ GO FROM ALBANY TO IS.
The  best sequence of speech actsto cover this input consists of three acts:1. a CONFIRM/ACKNOWLEDGE (OKAY)2. a TELL, with content o take the last train (NOW ITAKE THE LAST TRAIN)3. a REQUEST to go from Albany (Go FROM ALBANY)Note that the to is at the end of the utterance is simplyignored as it is uninterpretable.
While not present in theoutput, the presence of unaccounted words will lower theparser's confidence score that it assigns to theinterpretation.The actual utterance was Okay now let's take the lasttrain and go from Albany to Milwaukee.
Note that whilethe parser is not able to reconstruct he completeintentions of the user, it has extracted enough tocontinue the dialogue in a reasonable fashion byinvoking a clarification subdialogue.
Specifically, it hascorrectly recognized the confirmation of the previousexchange (act 1), and recognized a request to move a trainfrom Albany (act 3).
Act 2 is an incorrect analysis, andresults in the system generating a clarification questionthat the user ends up ignoring.
Thus, as far as furtheringthe dialogue, the system has done reasonably well.6.
Robust Speech Act ProcessingThe dialogue manager is responsible for interpreting thespeech acts in context, formulating responses, andmaintaining the system's idea of the state of thediscourse.
It maintains adiscourse state that consists of agoal stack with similarities to the plan stack of Litman& Allen (1987) and the attentional state of Grosz &Sidner (1986).
Each element of the stack captures1.
the domain or discourse goal motivating the segment2.
the object focus and history list for the segment3.
information on the status of problem solvingactivity (e.g., has the goal been achieved yet or not).A fundamental principle in the design of TRAINS-95was a decision that, when faced with ambiguity it isbetter to choose a specific interpretation and run the riskof making a mistake as opposed to generating aclarification subdialogue.
Of course, the success of thisstrategy depends on the system's ability to recognize andinterpret subsequent corrections if they arise.
Significanteffort was made in the system to detect and handle a widerange of corrections, both in the grammar, the discourseprocessing and the domain reasoning.
In later systems,we plan to specifically evaluate the effectiveness of thisstrategy.66The discourse processing is divided into referenceresolution, verbal reasoning, problem solving anddomain reasoning.Reference resolution, other than having the obvious jobof identifying the referents of noun phrases, also mayreinterpret the parser's assignment of illocutionary forceif it has additional information to draw upon.
One waywe attain robustness i by having overlapping realms ofresponsibility: one module may be able to do a betterjob resolving a problem because it has an alternativeview of it.
On the other hand, it's important torecognize another module's expertise as well.
It could bedisastrous to combine two speech acts that arise from Ireally <garbled> think that's good.
for instance, sincethe garbled part may include don't.
Since speechrecognition may substitute important words one for theother, it's important to keep in mind that speech actsthat have no firm illocutionary force due to grammaticalproblems may have little to do with what the speakeractually said.The verbal reasoner is organized as a set of prioritizedrules that match patterns in the input speech acts andthe discourse state.
These rules allow robust processingin the face of partial or ill-formed input as they match atvarying levels of specificity, including rules thatinterpret fragments that have no identified illocutionaryforce.
For instance, one rule would allow a fragmentsuch as to Avon to be interpreted as a suggestion toextend a route, or an identification of a new goal.
Theprioritized rules are used in turn until an acceptableresult is obtained.The problem solver handles all speech acts that appearto be requests to constrain, extend or change the currentplan.
It is also based on a set of prioritized rules, thistime dealing with plan corrections and extensions.These rules match against he speech act, the problemsolving state, and the current state of the domain.
Iffragmentary information is supplied, the problem solverattempts to incorporate the fragment into what it knowsabout he current state of the plan.As example of the discourse processing, consider howthe system handles the user's first utterance in thedialogue, OKAY LET'S SEND CONTAIN FROM DETROIT TOWASHINGTOn.
From the parser we get three acts:I. a CONFIRM/ACKNOWLEDGE (OKAY)2. a TELL involving mostly uninterpretable words(LET'S SEND CONTAIN)3. a TELL act that mentions a route (FROM DETROIT TOWASHINGTON)The discourse manager sets up its initial conversationstate and passes the act to reference for identification ofparticular objects, and then hands the acts to the verbalreasoner.
Because there is nothing on the discoursestack, the initial confirm has no effect.
(Had there beensomething on the stack, e.g.
a question of a plan, theinitial confirm might have been taken as an answer tothe question, or a confirm of the plan, respectively).
Thefollowing empty TELL act is uninterpretable and henceignored.
While it is possible to claim the "send" couldbe used to indicate the illocutionary force of thefollowing fragment, and that a "container" might even beinvolved, the fact that the parser separated out the speechact indicates there may have been other fragments lost.The last speech act could be a suggestion of a new goalto move from Detroit to Washington.
After checkingthat there is an engine at Detroit, this interpretation isaccepted.
The planner is unable to generate a pathbetween these points (since it is greater than four hops).It returns two items:1. an identification of the speech act as a suggestion ofa goal to take a train from Detroit to Washington2.
a signal that it couldn't find a path to satisfy the goalThe discourse context is updated and the verbal reasonergenerates a response to clarify the route desired, which isrealized in the system's response What route would youlike to get from Detroit o Washington?As another example of robust processing, consider aninteraction later in the dialogue in which the user'sresponse no is misheard as now:Now let's take the trainfrom Detroit to Washington do S_X Albany (instead ofNo let's take the train from Detroit to Washington viaCincinnati).
Since no explicit rejection is identified dueto the recognition error, this utterance looks like aconfirm and continuation of the plan.
Thus the problemsolver is called to extend the path with the currentlyfocused engine (enginel) from Detroit o Washington.The problem solver realizes that enginel isn't currentlyin Detroit, so this can't be a route extension.
In addition,there is no other engine at Detroit, so this is notplausible as a focus shift to a different engine.
Sinceengine l originated in Detroit, it then decides toreinterpret he utterance as a correction.
Since theutterance adds no new constraints, but there are the citiesthat were just mentioned as having delays, it presumesthe user is attempting to avoid them, and invokes thedomain reasoner to plan a new route avoiding thecongested cities.
The new path is returned and presentedto the user.While the response does not address the user's intentionto go through Cincinnati due to the speech recognitionerrors, it is a reasonable r sponse to the problem the useris trying to solve.
In fact, the user decides to accept heproposed route and forget about going throughCincinnati.
In other cases, the user might persevere andcontinue with another correction such as No, throughCincinnati.
Robustness arises in the example becausethe system uses its knowledge of the domain to producea reasonable response.
Note these examples bothillustrate the "strong commitment" model.
We believe itis easier to correct a poor plan, than having to keeptrying to explain a perfect one, particularly in the face of67recognition problems.
For further detail on the problemsolver, see Ferguson et al(1996).7.
Evaluating the SystemWhile examples can be illuminating, they don't addressthe issue of how well the system works overall.
Toexplore how well the system robustly handles spokendialogue, we designed an experiment to contrast speechinput with keyboard input.
The experiment uses thedifferent input media to manipulate the word error rateand the degree of spontaneity.
Task performance wasevaluated in terms of two metrics: the amount of timetaken to arrive at a solution and the quality of thesolution.
Solution quality for our domain is determinedby the amount of time needed to travel the routes.Sixteen subjects for the experiment were recruited fromundergraduate computer science courses.
None of thesubjects had ever used the system before.
The procedurewas as follows:?
The subject viewed an online tutorial lasting 2.4minutes.?
The subject was then allowed a few minutes topractice both speech and keyboard input.?
All subjects were given identical sets of 5 tasks toperform, in the same order.
Half of the subjects wereasked to use speech first, keyboard second, speechthird and keyboard fourth.
The other half usedkeyboard first and then alternated.
All subjects weregiven a choice of whether to use speech or keyboardinput to accomplish the final task.?
After performing the final task, the subjectcompleted a questionnaire.An analysis of the experiment results shows that theplans generated when speech input was used are ofsimilar quality to those generated when keyboard inputwas used.
However, the time needed to develop planswas significantly lower when speech input was used.Overall, problems were solved using speech in 68% ofthe time needed to solve them using the keyboard.Figure 7 shows the task completion time results, andFigure 8 gives the solution quality results, each brokenout by task.Of the 16 subjects, 12 selected speech as the inputmedium for the final task and 4 selected keyboard input.Three of the four selecting keyboard input had actuallyexperienced better or similar performance usingkeyboard input during the first four tasks.
The fourthsubject indicated on his questionnaire that he believed hecould solve the problem more quickly using thekeyboard; however, that subject had solved the twotasks using speech input 19% faster than the two taskshe solved using keyboard input.Figure 7: Time to Completion by Task30 ................................................................................................................ \[ i SpeechKeyboard2010 /11!/!i.I/iiTI T2 T3 T4 Av 1-4 T5 AvFigure 8 : Length of Solution by TaskOf the 80 tasks attempted, there were 7 in which thestated goals were not met.
In each unsuccessful attempt,the subject was using speech input.
There was noparticular task that was troublesome and no particularsubject hat had difficulty.
Seven different subjects had atask where the goals were not met, and each of the fivetasks was left unaccomplished at least once.A review of the transcripts for the unsuccessful attemptsrevealed that in three cases, the subject misinterpreted thesystem's actions, and ended the dialogue believing thegoals were met.
Each of the other four unsuccessfulattempts resulted from a common sequence of events:after the system proposed an inefficient route, wordrecognition errors caused the system to misinterpretrejection of the proposed route as acceptance.
Thesubsequent subdialogues intended to improve the routewere interpreted to be extensions to the route, causingthe route to "overshoot" he intended estination.This suggests that, while our robustness techniques wereeffective on average, the errors do create ahigher variancein the effectiveness of the interaction.
These problemsreveal a need for better handling of corrections, especiallyas resumptions of previous topics.
More details on theevaluation can be found in (Sikorski & Allen,forthcoming).8.
D iscuss ionThere are few systems that attempt to handleunconstrained natural dialogue.
In most current speech68systems, the interaction is driven by a template fillingmechanism (e.g., the ATIS systems (ARPA, 1995),BeRP (Jurafsky et al 1994), Pegasus (Seneff et al1995)).
Some of these systems upport system-initiatedquestions to elicit missing information in the template,but that is the extent of the mixed initiative interaction.Specifically, there is no need for goal managementbecause the goal is fixed throughout the dialogue.
Inaddition, there is little support for clarification andcorrection subdialogues.
The Duke system (Smith andHipp, 1994) uses a more general model based on areasoning system, but allows only a limited vocabularyand grammar and requires extensive training to use.Our approach here is clearly bottom-up.
We haveattempted to build a fully functional system in thesimplest domain possible and focused on the problemsthat most significantly degraded overall performance.This leaves us open to the criticism that we are notusing the most sophisticated models available.
Forinstance, consider our generation strategy.
Template-based generation is clearly inadequate for manygeneration tasks.
In fact, when starting the project wethought generation would be a major problem.However, the problems we expected have not arisen.While we could clearly improve the output of thesystem even in this small domain, the current generatordoes not appear to drag the system's performance down.We approached other problems imilarly.
We tried thesimplest approaches first and then only generalizedthose algorithms whose inadequacies clearly degrade theperformance of the system.Likewise, we view the evaluation as only a verypreliminary first step.
While our evaluation appearssimilar to HCI experiments on whether speech orkeyboard is a more effective interface in general (cf.Oviatt and Cohen, 1991), this comparison was not ourgoal.
Rather, we used the modality switch as a way ofmanipulating the error rate and the degree ofspontaneity.
While keyboard performance is not perfectbecause of typos (we had a 5% word error rate onkeyboard), it is considerably less error prone thanspeech.
All we conclude from this experiment is thatour robust processing techniques are sufficiently goodthat speech is a viable interface in such tasks even withhigh word error rates.
In fact, it appears to be moreefficient in this application than keyboard.
In contrast tothe results of Rudnicky (1993), who found userspreferred speech even when less efficient, our subjectsgenerally preferred the most efficient modality for them(which in a majority of cases was speech).Despite the limitations of the current evaluation, we areencouraged by this first step.
It seems obvious to usthat progress in dialogue systems is intimately tied tofinding suitable evaluation measures.
And task-basedevaluation seems one of the most promising candidates.It measures the impact of proposed techniques directlyrather than indirectly with an abstract accuracy figure.Another area where we are open to criticism is that weused algorithms pecific to the domain in order toproduce ffective intention recognition, disambiguation,and domain planning.
Thus, the success of the systemmay be a result of the domain and say little about theplan-based approach to dialogue.
To be honest, with thecurrent system, it is hard to defend ourselves againstthis.
This is is a first step in what we see as a longongoing process.
To look at it another way: if wecouldn't build a successful system by employingwhatever means available, then there is little hope forfinding more effective general solutions.We are addressing this problem in our current research:we are developing a domain-independent plan reasoning"shell" that manages the plan recognition, evaluation andconstruction around which the dialogue system isstructured.
This shell provides the abstract model ofproblem solving upon which the dialogue manager isbuilt.
It is then instantiated by domain specific reasoningalgorithms to perform the actual searches, constraintchecking and intention recognition for a specificapplication.
The structure of the model remains constantacross domains, but the actual details of constructingplans remain domain specific.Our next iteration of this process, TRAINS-96, involvesadding complexity to the dialogues by increasing thecomplexity of the task.
Specifically, we are addingdistances and travel times between cities, several newmodes of transportation (trucks and planes) withassociated costs, and simple cargoes to be transported andpossibly transferred between different vehicles.
Theexpanded domain will require a much more sophisticatedability to answer questions, to display complexinformation concisely, and will stress our abilities totrack plans and identify focus shifts.While there are clearly many places in which our currentsystem requires further work, it does set a new standardfor spoken dialogue systems.
More importantly, itallows us to address new research issues in a much moresystematic way, supported by empirical evaluation.AcknowledgementsThis work was supported in part by ONR/ARPA grantsN0004-92-J-1512 and N00014-95-1-1088, and NSFgrant IRI-9503312.
Many thanks to Alex Rudnicky,Ronald Rosenfeld and Sunil Issar at CMU for providingthe Sphinx-II system and related tools.
This work wouldnot have been possible without the efforts of GeorgeFerguson on the TRAINS system infrastructure andmodel of problem solving.ReferencesJ.
F. Allen.
1995.
Natural Language Understanding, 2ndEdition, Benjamin-Cummings, Redwood City, CA.J.
F. Allen, G. Ferguson, B. Miller, and E. Ringger.1995.
Spoken dialogue and interactive planning.
InProc.
ARPA SLST Workshop, Morgan Kaufmann69J.
F. Allen and C. R. Perrault.
1980.
Analyzingintention in utterances, Artificial Intelligence15(3):143-178ARPA, 1995.
Proceedings of the Spoken LanguageSystems Technology Workshop, Jan. 1995.Distributed by Morgan Kaufmann.P.
F. Brown, J. Cocke, S. A. Della Pietra, V. J. DellaPietra, F. Jelinek, J. D. Lafferty, R. L. Mercer and P.S.
Roossin.
1990.
A Statistical Approach to MachineTranslation.
Computational Linguistics 16(2):79--85.S.
Carberry.
1990.
Plan Recognition in NaturalLanguage Dialogue, MIT Press, Cambridge, MA.P.
R. Cohen and C. R. Perrault.
1979.
Elements of aplan-based theory of speech acts, Cognitive Science 3G.
M. Ferguson, J. F. Allen and B. W. Miller, 1996.TRAINS-95: Towards a Mixed-Initiative PlanningAssistant, to appear in Proc.
Third Conference onArtificial Intelligent Planning Systems (AIPS-96).G.
E. Forney, Jr. 1973.
The Viterbi Algorithm.
Proc.
ofIEEE 61:266--278.B.
Grosz and C. Sidner.
1986.
Attention, intention andthe structure of discourse.
Computational Linguistics12(3).E.
Hinkelman and J. F. Allen.
1989.Two Constraintson Speech Act Ambiguity, Proc.
ACL.X.
D. Huang, F. Alleva, H. W. Hon, M. Y. Hwang, K.F.
Lee, and R. Rosenfeld.
1993.
The Sphinx-IISpeech Recognition System.
Computer, Speech andLanguageD.
Jurafsky, C. Wooters, G. Tajchman, J. Segal, A.Stolcke, E. Fosler and N. Morgan.
1994.
TheBerkeley Restaurant Project, Proc.
ICSLP-94.S.
M. Katz.
1987.
Estimation of Probabilities fromSparse Data for the Language Model Component of aSpeech Recognizer.
In IEEE Transactions onAcoustics, Speech, and Signal Processing.
IEEE.
pp.400-401.D.
Litman and J. F. Allen.
1987.
A plan recognitionmodel for subdialogues in conversation.
CognitiveScience 11(2): 163-200B, Lowerre and R. Reddy.
1986.
The Harpy SpeechUnderstanding System.
Reprinted in Waibel and Lee,1990: 576-586.S.
L. Oviatt and P.R.
Cohen.
1991.
The contributinginfluence of speech and interaction on humandiscourse patterns.
In J.W.
Sullivan and S.W.
Tyler(eds), Intelligent User Interfaces.
Addison-Wesley,NY, NY.E.
K. Ringger and J. F. Allen.
1996.
A FertilityChannel Model for Post-Correction of ContinuousSpeech Recognition.
To appear in Proc.
1996 ICSLP,IEEE, October, 1996.A.
Rudnicky.
1993.
Mode Preference in a Simple Data-Retrieval Task, Proc.
of ARPA Workshop on HumanLanguage Technology, Dist.
by Morgan Kaufmann.S.
Seneff, V. Zue, J. Polifroni, C. Pao, L.Hetherington, D. Goddeau, and J.
Glass.
1995.
ThePreliminary Development of a DisplaylessPEGASUS System.
Proc.
SLST Workshop, Jan.1995.
Morgan KaufmannR.
Smith and R. D. Hipp.
1994.
Spoken NaturalLanguage Dialog Systems: A Practical Approach,Oxford University Press.A.
Waibel and K. F. Lee, editors.
1990.
Readings inSpeech Recognition.
Morgan Kaufmann, CA.Appendix A: Transcript of post-processor repairs in the dialogue.HYP: OKAY LET'S SEE CONTAIN FROM DETROIT TO WASHINGTONHYP': OKAY LET'S SEND CONTAIN FROM DETROIT TOWASHINGTONREF: OKAY LET'S TAKE THE TRAIN FROM DETROIT TOWASHINGTONHYP: LET'S GO VIA TOLEDO AND PITTSBURGHHYP': LET'S GO VIA TOLEDO AND PITTSBURGHREF: LET'S GO VIA TOLEDO AND PII-rSBURGHHYP: NOW LET'S TAKE THE TRAIN FROM DETROIT TOWASHINGTON D S_X ANYHYP': NOW LET'S TAKE THE TRAIN FROM DETROIT TOWASHINGTON DO S_X ALBANY)REF: NO LET'S TAKE THE TRAIN FROM DETROIT TO WASHINGTONVIA CINCINNATIHYP: OKAY IT THAT'S OKAY NOWHYP': OKAY IT THAT'S OKAY NOWREF: OKAY THAT- THAT'S OKAY NOWHYP: UP OKAY NOW LET'S TAKE THE TRAIN FROM MONTREAL TOLEXINGTONHYP': UP OKAY NOW LET'S TAKE THE TRAIN FROM MONTREAL TOLEXINGTONREF: OKAY NOW LET'S TAKE THE TRAIN FROM MONTREAL TOLEXINGTONHYP: LET'S GO P_M TO TRYHYP': LET'S GO P_M TO DETROITREF: LET'S GO VIA DETROITHYP: YES NOW LET'S GO TO LEXINGTONHYP': YES NOW LET'S GO TO LEXINGTONREF: YES NOW LET'S GO TO LEXINGTONHYP: OKAY NOW ADD STATE THE LAST TRAIN AND GO FROMALBANY TO O_O'SHYP': OKAY NOW I TAKE THE LAST TRAIN IN GO FROM ALBANY TOISREF: OKAY NOW LET'S TAKE THE LAST TRAIN AND GO FROMALBANY TO MILWAUKEEHYP: ME A JET ADD ALBANY NEEDS TO GO TO MILWAUKEEHYP': ME THE JET AT ALBANY INSTEAD TO GO TO MILWAUKEEREF: THE ENGINE AT ALBANY NEEDS TO GO TO MILWAUKEEHYP: I'D GO VIA BUFFALOHYP': UH GO VIA BUFFALOREF: UH GO VIA BUFFALOHYP: GO B X SYRACUSE AT BUFFALOHYP': GO VIA SYRACUSE VIA BUFFALOREF: GO VIA SYRACUSE AND BUFFALOHYP: THAT'S COULD I CANHYP': THAT'S GREAT UH CANREF: THAT'S GOOD I'M DONEHYP: I_NEED DONEHYP': I'M DONEREF: I'M DONE70
