Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 17?24Manchester, August 2008Graph-Based Keyword Extraction for Single-Document SummarizationMarina LitvakDepartment ofInformation System EngineeringBen-Gurion University of the NegevBeer-Sheva 84105, Israellitvakm@bgu.ac.ilMark LastDepartment ofInformation System EngineeringBen-Gurion University of the NegevBeer-Sheva 84105, Israelmlast@bgu.ac.ilAbstractIn this paper, we introduce and comparebetween two novel approaches, supervisedand unsupervised, for identifying the key-words to be used in extractive summa-rization of text documents.
Both our ap-proaches are based on the graph-basedsyntactic representation of text and webdocuments, which enhances the traditionalvector-space model by taking into accountsome structural document features.
In thesupervised approach, we train classifica-tion algorithms on a summarized collec-tion of documents with the purpose ofinducing a keyword identification model.In the unsupervised approach, we run theHITS algorithm on document graphs underthe assumption that the top-ranked nodesshould represent the document keywords.Our experiments on a collection of bench-mark summaries show that given a set ofsummarized training documents, the su-pervised classification provides the highestkeyword identification accuracy, while thehighest F-measure is reached with a sim-ple degree-based ranking.
In addition, it issufficient to perform only the first iterationof HITS rather than running it to its con-vergence.1 IntroductionDocument summarization is aimed at all types ofelectronic documents including HTML files withc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.the purpose of generating the summary - main doc-ument information expressed in ?a few words?.In this paper, we introduce and compare be-tween two approaches: supervised and unsuper-vised, for the cross-lingual keyword extraction tobe used as the first step in extractive summarizationof text documents.
Thus, according to our problemstatement, the keyword is a word presenting in thedocument summary.The supervised learning approach for keywordsextraction was first suggested in (Turney, 2000),where parametrized heuristic rules were combinedwith a genetic algorithm into a system - GenEx -that automatically identified keywords in a docu-ment.For both our approaches, we utilize a graph-based representation for text documents.
Such rep-resentations may vary from very simple, syntacticones like words connected by edges representingco-occurrence relation (Mihalcea and Tarau, 2004)to more complex ones like concepts connected bysemantic relations (Leskovec et al, 2004).
Themain advantage of a syntactic representation is itslanguage independency, while the semantic graphsrepresentation provide new characteristics of textsuch as its captured semantic structure that it-self can serve as a document surrogate and pro-vide means for document navigation.
Authors of(Leskovec et al, 2004) reduce the problem of sum-marization to acquiring machine learning modelsfor mapping between the document graph and thegraph of a summary.
Using deep linguistic anal-ysis, they extract sub-structures (subjectpredica-teobject triples) from document semantic graphs inorder to get a summary.
Contrary to (Leskovec etal., 2004), both our approaches work with a syn-tactic representation that does not require almostany language-specific linguistic processing.
In17this paper, we perform experiments with directedgraphs, where the nodes stand for words/phrasesand the edges represent syntactic relationships be-tween them, meaning?followed by?
(Schenker etal., 2005).Some of the most successful approaches to ex-tractive summarization utilize supervised learn-ing algorithms that are trained on collections of?ground truth?
summaries built for a relativelylarge number of documents (Mani and Maybury,1999).
However, in spite of the reasonable perfor-mance of such algorithms they cannot be adaptedto new languages or domains without trainingon each new type of data.
Our first approachalso utilizes classification algorithms, but, thanksto the language-independent graph representationof documents, it can be applied to various lan-guages and domains without any modifications ofthe graph construction procedure (except for thetechnical upgrade of implementation for multi-lingual processing of text, like reading Unicode orlanguage-specific encodings, etc.)
(Markov et al,2007; Last and Markov, 2005).
Of course, as a su-pervised approach it requires high-quality traininglabeled data.Our second approach uses a technique that doesnot require any training data.
To extract the sum-mary keywords, we apply a ranking algorithmcalled HITS (Kleinberg, 1999) to directed graphsrepresenting source documents.
Authors of (Mi-halcea and Tarau, 2004) applied the PageRank al-gorithm (Brin and Page, 1998) for keyword extrac-tion using a simpler graph representation (undi-rected unweighted graphs), and show that their re-sults compare favorably with results on establishedbenchmarks of manually assigned keywords.
(Mi-halcea and Tarau, 2004) are also using the HITSalgorithm for automatic sentence extraction fromdocuments represented by graphs built from sen-tences connected by similarity relationships.
Sincewe work with directed graphs, HITS is the mostappropriate algorithm for our task as it takes intoaccount both in-degree and out-degree of nodes.We show in our experiments that running HITS tillconvergence is not necessary, and initial weightsthat we get after the first iteration of algorithmare good enough for rank-based extraction of sum-mary keywords.
Another important conclusionthat was infered from our experimental results isthat, given the training data in the form of anno-tated syntactic graphs, supervised classification isthe most accurate option for identifying the salientnodes in a document graph, while a simple degree-based ranking provides the highest F-measure.2 Document representationCurrently, we use the ?simple?
graph representa-tion defined in (Schenker et al, 2005) that holdsunlabeled edges representing order-relationshipbetween the the words represented by nodes.
Thestemming and stopword removal operations of ba-sic text preprocessing are done before graph build-ing.
Only a single vertex for each distinct wordis created even if it appears more than once inthe text.
Thus each vertex label in the graph isunique.
If a word a immediately precedes a wordb in the same sentence somewhere in the docu-ment, then there is a directed edge from the ver-tex corresponding to term a to the vertex corre-sponding to term b.
Sentence terminating punctu-ation marks (periods, question marks, and excla-mation points) are taken by us into account andan edge is not created when these are present be-tween two words.
This definition of graph edgesis slightly different from co-occurrence relationsused in (Mihalcea and Tarau, 2004) for buildingundirected document graphs, where the order ofword occurrence is ignored and the size of the co-occurrence window is varied between 2 and 10.Sections defined for HTML documents are: title,which contains the text related to the document?stitle and any provided keywords (meta-data) andtext, which comprises any of the readable text inthe document.
This simple representation can beextended to many different variations like a se-mantic graph where nodes stand for concepts andedges represent semantic relations between themor a more detailed syntactic graph where edges andnodes are labeled by significant information likefrequency, location, similarity, distance, etc.
Thesyntactic graph-based representations were shownin (Schenker et al, 2005) to outperform the clas-sical vector-space model on several clustering andclassification tasks.
We choose the ?simple?
repre-sentation as a representation that saves processingtime and memory resources as well as gives nearlythe best results for the two above text mining tasks.3 Keywords extractionIn this paper, we deal with the first stage of extrac-tive summarization where the most salient words(?keywords?)
are extracted in order to generate a18summary.
Since each distinct word in a text is rep-resented by a node in the document graph, the key-words extraction problem is reduced to the salientnodes extraction in graphs.3.1 The Supervised approachIn this approach, we try to identify the salientnodes of document graphs by training a classifi-cation algorithm on a repository of summarizeddocuments such as (DUC, 2002) with the purposeof inducing a keyword identification model.
Eachnode of every document graph belongs to one oftwo classes: YES if the corresponding word is in-cluded in the document extractive summary andNO otherwise.
We consider the graph-based fea-tures (e.g., degree) characterizing graph structureas well as statistic-based features (Nobata et al,2001) characterizing text content represented by anode.
The complete list of features, along withtheir formal definitions, is provided below:?
In Degree - number of incoming edges?
Out Degree - number of outcoming edges?
Degree - total number of edges?
Frequency - term frequency of word repre-sented by node1?
Frequent words distribution ?
{0, 1},equals to 1 iff Frequency?threshold2?
Location Score - calculates an average of lo-cation scores between all sentences3contain-ing the word N represented by node (denotethese sentences as S(N)):Score (N) =?Si?S(N)Score (Si)|S (N)|?
Tfidf Score - calculates the tf-idfscore (Salton, 1975) of the word repre-sented by node4.1The term frequency (TF) is the number of times the wordappears in a document divided by the number of total wordsin the document.2In our experiment the threshold is set to 0.053There are many variants for calculating sentence locationscore (Nobata et al, 2001).
In this paper, we calculate it as anreciprocal of the sentence location in text: Score (Si) =1i4There are many different formulas used to calculate tfidf.We use the next formula:tftf+1log2|D|df, where tf - term fre-quency (as defined above), |D| - total number of documents inthe corpus, df - number of documents where the term appears.?
Headline Score ?
{0, 1}, equals to 1 iff doc-ument headline contains word represented bynode.3.2 The Unsupervised approachRanking algorithms, such as Kleinberg?s HITSalgorithm (Kleinberg, 1999) or Google?s PageR-ank (Brin and Page, 1998) have been elaboratedand used in Web-link analysis for the purpose ofoptimizating the search performance on the Web.These algorithms recursively assign a numericalweight to each element of a hyperlinked set of doc-uments, determining how important each page is.A hyperlink to a page counts as a vote of support.A page that is linked to by many important pages(with high rank) receives a high rank itself.
Asimilar idea can be applied to lexical or seman-tic graphs extracted from text documents, in or-der to extract the most significant blocks (words,phrases, sentences, etc.)
for the summary (Mi-halcea and Tarau, 2004; Mihalcea, 2004).
In thispaper, we apply the HITS algorithm to documentgraphs and evaluate its performance on automaticunsupervised text unit extraction in the context ofthe text summarization task.
The HITS algorithmdistinguishes between ?authorities?
(pages with alarge number of incoming links) and ?hubs?
(pageswith a large number of outgoing links).
For eachnode, HITS produces two sets of scores - an ?au-thority?
score, and a ?hub?
score:HITSA(Vi) =?Vj?In(Vi)HITSH(Vj) (1)HITSH(Vi) =?Vj?Out(Vi)HITSA(Vj) (2)For the total rank (H) calculation we used thefollowing four functions:1. rank equals to the authority scoreH (Vi) = HITSA(Vi)2. rank equals to the hub scoreH (Vi) = HITSH(Vi)3. rank equals to the average between two scoresH (Vi) = avg {HITSA(Vi) ,HITSH(Vi)}4. rank equals to the maximum between twoscoresH (Vi) = max {HITSA(Vi) ,HITSH(Vi)}19average merit rank feature0.192 +- 0.005 1 Frequent words distribution0.029 +- 0 2 In Degree0.029 +- 0 3 Out Degree0.025 +- 0 4 Frequency0.025 +- 0 5 Degree0.017 +- 0 6 Headline Score0.015 +- 0 7 Location Score0.015 +- 0.001 8 Tfidf ScoreTable 1: Feature selection results according to GainRatio value0.8240.8260.8280.8300.8320.8340.8360.8380.8400.84287654321size of the feature setaccuracyNBC accuracyMRlower boundMRupperboundFigure 1: Accuracy for Na?
?veBayes classifier (NBC) and Majority Rule (MR)4 Experimental resultsAll experiments have been performed on thecollection of summarized news articles pro-vided by the Document Understanding Conference2002 (DUC, 2002).
This collection contains 566English texts along with 2-3 summaries per doc-ument on average.
The size5of syntactic graphsextracted from these texts is 196 on average, vary-ing from 62 to 876.4.1 Supervised approachWe utilized several classification algorithms im-plemented in Weka?s software (Witten and Frank,2005) : J48 (known as C4.5), SMO (Support Vec-tor Machine) and Na?
?veBayes for building binaryclassification models (a word belongs to summary/ does not belong to the summary).
For the trainingwe built dataset with two classes: YES for nodesbelonging to at least one summary of the docu-5We define the size of a graph as the number of its vertices.ment, and NO for those that do not belong to anysummary.
The accuracy of the default (majority)rule over all nodes is equal to the percentage ofnon-salient nodes (83.17%).
For better classifica-tion results we examined the importance of eachone of the features, described in Section 3.1 usingautomated feature selection.
Table 1 presents theaverage GainRatio6values (?merits?)
and the aver-age rank of the features calculated from the DUC2002 document collection, based on 10-fold crossvalidation.As expected, the results of J48 and SMO (thesealgorithms perform feature selection while build-ing the model) did not vary on different featuresets, while Na?
?veBayes gave the best accuracy onthe reduced set.
Figure 1 demonstrates the accu-racy variations of Na?
?veBayes classifier on the dif-ferent feature sets relative to the confidence inter-6Gain Ratio(A) =Information Gain(A)Intrinsic Info(A), whereIntrinsic Info(A) = ?
?xNxNlog[NxN]2000.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91FalsePositivesT rue P ositiv esFigure 2: Sample ROC curve for one of the DUC?02 documentsRanking function Degree vectors Converged vectorsAuthority 0.625 0.600Hub 0.620 0.601Avg(Authority, Hub) 0.651 0.622Max(Authority, Hub) 0.651 0.624Table 2: Average AUC for each rank calculating functionval for the majority rule accuracy according to thenormal approximation of the binomial distributionwith ?
= 0.05.
Table 3 presents classificationresults for supervised algorithms (for Na?
?veBayesthe results shown on the top 2 features) based on10-fold cross validation as well as results of unsu-pervised learning.4.2 Unsupervised approachWe have studied the following research questions:1.
Is it possible to induce some classificationmodel based on HITS scores?2.
Is it necessary to run HITS until convergence?In order to answer these questions we performedthe following two experiments:1.
In the first one, we run HITS only one it-eration.
Note, that the ranks resulted fromthe first iteration are just in-degree and out-degree scores for each node in graph, andmay be easily computed without even startingHITS7.7Initially, both authority and hub vectors (a and h respec-tively) are set to u = (1, 1, .
.
.
, 1).
At each iteration HITSsets an authority vector to a = ATh, and the hub vector toh = Aa, where A is an adjacency matrix of a graph.
So, afterthe first iteration, a = ATu and h = Au, that are the vec-tors containing in-degree and out-degree scores for nodes in agraph respectively.2.
In the second experiment we run HITS untilconvergence8(different number of steps fordifferent graphs) and compare the results withthe results of the first experiment.After each experiment we sorted the nodes ofeach graph by rank for each function (see the rankcalculating functions described in Section 3.2).After the sorting we built an ROC (Receiver Op-erating Characteristic) curve for each one of thegraphs.
Figure 2 demonstrates a sample ROCcurve for one of the documents from DUC 2002collection.In order to compare between ranking functions(see Section 3.2) we calculated the average of AUC(Area Under Curve) for the 566 ROC curves foreach function.
Table 2 presents the average AUCresults for the four functions.
According to theseresults, functions that take into account both scores(average and maximum between two scores) areoptimal.
We use the average function for compar-ing and reporting the following results.
Also, wecan see that degree vectors give better AUC results8There are many techniques to evaluate the convergenceachievement.
We say that convergence is achieved when forany vertex i in the graph the difference between the scorescomputed at two successive iterations falls below a giventhreshold:|xk+1i?xki|xki< 10?3(Kamvar, 2003; Mihalcea andTarau, 2004)21051015202530351295785113141169197225253281309337365393421449477505533561589number of wordscum ul ativ e A U Cdegree-ranked wordsHITS-rankedwordsFigure 3: Cumulative AUC curves for degree and converged vectorsMethod Accuracy TP FP Precision Recall F-MeasureClassification J48 0.847 0.203 0.022 0.648 0.203 0.309Na?
?veBayes 0.839 0.099 0.011 0.648 0.099 0.172SMO 0.839 0.053 0.002 0.867 0.053 0.100Degree-based N = 10 0.813 0.186 0.031 0.602 0.186 0.282Ranking N = 20 0.799 0.296 0.080 0.480 0.296 0.362N = 30 0.772 0.377 0.138 0.409 0.377 0.388N = 40 0.739 0.440 0.200 0.360 0.440 0.392Table 3: Results for each supervised and unsupervised methodthan converged ones.In order to compare between the degree-basedvectors and the converged ones we calculatedthe precision curves9for each graph in both ex-periments.
Then for each ranking method thecurve representing an average cumulative AUCover the 566 precision curves was calculated.
Fig-ure 3 demonstrates the difference between result-ing curves.
As we can conclude from this chart,the degree-based vectors have a slight advantageover the converged ones.
The ?optimum?
pointwhere the average AUC is maximum for bothmethods is 111 words with the average AUC of28.4 for degree-based words and 33 for HITS-ranked words.
That does not have much signifi-cance because each document has a different ?op-timum?
point.9For each number of top ranked words the percentage ofpositive words (belonging to summary) is shown.Finally, we compared the results of unsuper-vised method against the supervised one.
For thispurpose, we consider unsupervised model basedon extracting top N ranked words for four differ-ent values of N : 10, 20, 30 and 40.
Table 3 rep-resents the values for such commonly used met-rics as: Accuracy, True Positive Rate, False Posi-tive Rate, Precision, Recall and F-Measure respec-tively for each one of the tested methods.
The op-timal values are signed in bold.Despite the relatively poor accuracy perfor-mance of both approaches, the precision and re-call results for the unsupervised methods showthat the classification model, where we choosethe top most ranked words, definitely succeedscompared to the similar keyword extraction meth-ods.
(Leskovec et al, 2004) that is about ?logicaltriples?
extraction rather than single keyword ex-traction, presents results on DUC 2002 data, whichare similar to ours in terms of the F-measure (40%22against 39%) though our method requires muchless linguistic pre-processing and uses a muchsmaller feature set (466 features against 8).
(Mi-halcea and Tarau, 2004) includes a more similartask to ours (single keyword extraction) thoughthe definition of a keyword is different (?keywordsmanually assigned by the indexers?
against the?summary keywords?)
and a different dataset (In-spec) was used for results presentation.5 ConclusionsIn this paper we have proposed and evaluated twograph-based approaches: supervised and unsuper-vised, for the cross-lingual keyword extraction tobe used in extractive summarization of text docu-ments.
The empirical results suggest the follow-ing.
When a large labeled training set of summa-rized documents is available, the supervised classi-fication is the most accurate option for identifyingthe salient keywords in a document graph.
Whenthere is no high-quality training set of significantsize, it is recommended to use the unsupervisedmethod based on the node degree ranking, whichalso provides a higher F-measure than the super-vised approach.
The intuition behind this conclu-sion is very simple: most words that are highly?interconnected?
with other words in text (exceptstop-words) should contribute to the summary.
Ac-cording to our experimental results, we can extractup to 15 words with an average precision above50%.
Running HITS to its convergence is redun-dant, since it does not improve the initial results ofthe degree ranking.6 Future workThe next stage of our extractive summarizationmethodology is generation of larger units from theselected keywords.
At each step, we are goingto reduce document graphs to contain larger units(subgraphs) as nodes and apply some ranking al-gorithms to the reduced graphs.
This algorithm isiterative, where graph reduction steps are repeateduntil maximal subgraph size is exceeded or anotherconstraint is met.
Also, we plan to work on the su-pervised classification of sub-graphs, where manygraph-based features will be extracted and evalu-ated.In the future, we also intend to evaluate ourmethod on additional graph representations of doc-uments, especially on the concept-based represen-tation where the graphs are built from the con-cepts fused from the texts.
Once completed, thegraph-based summarization methodology will becompared to previously developed state-of-the-art summarization methods and tools.
All ex-periments will include collections of English andnon-English documents to demonstrate the cross-linguality of our approach.ReferencesS.
Brin and L. Page.
1998.
The anatomy of a large-scale hypertextual Web search engine.
ComputerNetworks and ISDN Systems, 30:1?7.Document Understanding Documents 2002[http://www-nlpir.nist.gov/projects/duc/index.html]Sepandar D. Kamvar, Taher H. Haveliwala, and GeneH.
Golub.
Adaptive methods for the computation ofpagerank.
Technical report, Stanford University.Kleinberg, J.M.
1999.
Authoritative sources in ahyperlinked environment.
Journal of the ACM,46(5):604-632.Last, M. and Markov A.
2005.
Identification of terror-ist web sites with cross-lingual classiffication tools.In Last, M. and Kandel, A.
(Editors), Fighting Terrorin Cyberspace.
World Scientific, Series in MachinePerception and Artificial Intelligence, 65:117?143.Leskovec, J., Grobelnik, M. and Milic-Frayling, N.2004.
Learning Semantic Graph Mapping forDocument Summarization.
In Proceedings ofECML/PKDD-2004 Workshop on Knowledge Dis-covery and Ontologies.Mani, I. and Maybury, M.T.
1999.
Advances in Auto-matic Text Summarization.
MIT Press, Cambridge,MA.Markov A., Last, M. and Kandel, A.
2007.
FastCategorization of Web Documents Represented byGraphs.
Advances in Web Mining and Web UsageAnalysis - 8th International Workshop on Knowl-edge Discovery on the Web, WEBKDD 2006, Re-vised Papers, O. Nasraoui, et al (Eds).
SpringerLecture Notes in Computer Science 4811:56?71.Mihalcea R. 2004.
Graph-based ranking algorithmsfor sentence extraction, applied to text summariza-tion.
In Proceedings of the 42nd Annual Meetingof the Association for Computational Lingusitics,Barcelona, Spain.Mihalcea and P. Tarau.
2004.
TextRank - bringing or-der into texts.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,Barcelona, Spain.Martin F. Porter.
1980.
An algorithm for suffix strip-ping.
Program, 14(3):130137, July.23Nobata, C., Sekine, S., Murata, M., Uchimoto, K.,Utiyama, M. and Isahara, H. 2001.
Sentence extrac-tion system assembling multiple evidence.
In Pro-ceedings of the Second NTCIR Workshop Meeting,5?213?218.Salton, G., Wong, A. and Yang, C. S. 1975.
A VectorSpace Model for Automatic Indexing Communica-tions of the ACM, 18(11):613-620.Schenker, A., Bunke, H., Last, M., Kandel, A.
2005.Graph-Theoretic Techniques for Web Content Min-ing, volume 62.
World Scientific, Series in MachinePerception and Artificial Intelligence.Peter D. Turney.
2000.
Learning Algorithmsfor Keyphrase Extraction.
Information Retrieval,2(4):303?336.Ian H. Witten and Eibe Frank 2005.
Data Mining:Practical machine learning tools and techniques,2nd Edition, Morgan Kaufmann, San Francisco.24
