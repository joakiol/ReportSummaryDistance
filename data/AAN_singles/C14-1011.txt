Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 99?108, Dublin, Ireland, August 23-29 2014.Multi-Objective Search Results ClusteringSudipta Acharya Sriparna SahaIndian Institute of Technology PatnaKurji, Patna, Bihar, India{sudipta.pcs13,sriparna}@iitp.ac.inJose G. Moreno Ga?el DiasNormandie University - CNRS GREYCCaen, Francefirst.last@unicaen.frAbstractMost web search results clustering (SRC) strategies have predominantly studied the definition ofadapted representation spaces to the detriment of new clustering techniques to improve perfor-mance.
In this paper, we define SRC as a multi-objective optimization (MOO) problem to takeadvantage of most recent works in clustering.
In particular, we define two objective functions(compactness and separability), which are simultaneously optimized using a MOO-based simu-lated annealing technique called AMOSA.
The proposed algorithm is able to automatically detectthe number of clusters for any query and outperforms all state-of-the-art text-based solutions interms of F?-measure and Fb3-measure over two gold standard data sets.1 IntroductionWeb search results clustering (SRC), also known as post-retrieval clustering or ephemeral clustering hasreceived much attention for the past twenty years for easing up user?s effort in web browsing.
The keyidea behind SRC systems is to return some meaningful labeled clusters from a set of web documents (orweb snippets) retrieved from a search engine for a given query.Recently, SRC strategies have been focusing on the introduction of external (exogenous) knowledge tobetter capture semantics between documents (Scaiella et al., 2012; Marco and Navigli, 2013).
Althoughthis research direction has evidenced competitive results, the proposed clustering techniques are basedon a single cluster quality measure, which must reflect alone the goodness of a given partitioning.
Thesetechniques are usually referred to as single objective optimizations (SOO).In this paper, we hypothesize that improved clustering can be achieved by defining different objectivefunctions over well-known data representations.
As such, our study aims to focus on new clusteringissues for SRC instead of defining new representation spaces.Recent studies (Maulik et al., 2011) have shown that clustering can be defined as a multi-objectiveoptimization (MOO) problem.
Within the context of SRC, we propose to define two objective functions(compactness and separability), which are simultaneously optimized using a MOO-based simulated an-nealing technique called AMOSA (Bandyopadhyay et al., 2008).In order to draw conclusive remarks, we present an exhaustive evaluation where our MOO algorithm(MOO-clus) is compared to the most competitive text-based (endogenous) SRC algorithms: STC (Zamirand Etzioni, 1998), LINGO (Osinski and Weiss, 2005), OPTIMSRC (Carpineto and Romano, 2010) andGK-means (Moreno et al., 2013).
Experiments are run over two different gold standard data sets (ODP-239 and MORESQUE) for two clustering evaluation metrics (F?-measure and Fb3-measure).
Resultsshow that MOO-clus outperforms all text-based solutions and approaches performances of knowledgedriven strategies (Scaiella et al., 2012).
In this paper, our main contributions are:?
The first1attempt to solve SRC by defining multiple objective functions,?
A new MOO clustering algorithm for SRC, which automatically determines the number of clusters,This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedingsfooter are added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/.1As far as we know.99?
An exhaustive evaluation of SRC algorithms with recent data sets and evaluation metrics over themost competitive state-of-the-art text-based SRC algorithms.2 Related Work2.1 SRC AlgorithmsOne of the most cited SRC solutions is the Suffix Tree Clustering (STC) algorithm proposed by (Zamirand Etzioni, 1998).
They propose a monothetic clustering technique, which merges base clusters withhigh string overlap based on web snippets represented as compact tries.
Their evaluation shows improve-ments over agglomerative hierarchical clustering, K-Means, Buckshot, Fractionation and Single-Passalgorithms, and is still a hard baseline to beat (Moreno and Dias, 2014).Later, (Osinski and Weiss, 2005) proposed a polythetic solution called LINGO based on the samestring representation as of (Zamir and Etzioni, 1998).
They first extract frequent phrases based on suffix-arrays and match group descriptions with topics obtained with latent semantic analysis.
Documents arethen assigned straightforwardly to their corresponding groups.
Their evaluation does not allow conclu-sive remarks but they propose an open source implementation, which is an important contribution.More recently, (Carpineto and Romano, 2010) showed that the characteristics of the outputs returnedby SRC algorithms suggest the adoption of a meta clustering approach.
The underlying idea is that dif-ferent SOO solutions lead to complementary results that must be combined.
So, they introduce a novelcriterion to measure the concordance of two partitions of objects into different clusters based on the infor-mation content associated to the series of decisions made by the partitions on single pairs of objects.
Theresults of OPTIMSRC demonstrate that meta clustering is superior over individual clustering techniques.The latest work, exclusively based on endogenous information (i.e.
web snippets returned by thesearch engine), is proposed by (Moreno et al., 2013).
They adapt the K-means algorithm to a third-ordersimilarity measure and propose a stopping criterion to automatically determine the ?optimal?
number ofclusters.
Experiments are run over two gold standard data sets, ODP-239 (Carpineto and Romano, 2010)and MORESQUE (Navigli and Crisafulli, 2010), and show improved results over all state-of-the-arttext-based SRC techniques so far.A great deal of works have also proposed to include exogenous information to solve the SRC problem.One important work is proposed by (Scaiella et al., 2012) who use Wikipedia articles to build a bipartitegraph and apply spectral clustering over it to discover relevant clusters.
More recently, (Marco andNavigli, 2013) proposed to include word sense induction based on the Web1T corpus (Brants and Franz,2006) to improve SRC.
In this paper, we exclusively focus on endogenous solutions.2.2 MOO-based ClusteringMany works have been proposed where the problem of clustering is posed as one of multi-objective op-timization (Deb, 2009; Maulik et al., 2011).
One important work is proposed by (Handl and Knowles,2007) who define a multi-objective clustering technique with automatic K-determination called MOCK.Their algorithm outperforms several standard single-objective clustering algorithms (K-means, agglom-erative hierarchical clustering and ensemble clustering) on artificial data sets.In parallel, a multi-objective evolutionary algorithm for fuzzy clustering is proposed by (Bandyopad-hyay et al., 2007) for clustering gene expressions.
Here, two objectives are simultaneously optimized.The first one is the objective function optimized in the fuzzy C-means algorithm (Bezdek, 1981) and theother one is the Xie-Beni index (Xie and Beni, 1991).Later, (Mukhopadhyay and Maulik, 2009) proposed a novel approach that combines the multi-objective fuzzy clustering method of (Bandyopadhyay et al., 2007) with a Support Vector Machines(SVM) classifier.
Performance results are provided for remote sensing data.As far as we know, within text applications, (Morik et al., 2012) is the first work, which formulatestext clustering a multi-objective optimization problem.
In particular, they express desired propertiesof frequent termset clustering in terms of multiple conflicting objective functions.
The optimization issolved by a genetic algorithm and the result is a set of Pareto-optimal solutions.
Note that this effort is100defined for large text colllections with high dimensional data, which is contradictory to the specific taskof SRC (Carpineto et al., 2009)2.2.3 Our MotivationRecent works have focused on the introduction of external (exogenous) knowledge to solve the SRCtask.
However, this research direction higly depends on existing resources, which are not available for agreat deal of languages.
Moreover, (Carpineto and Romano, 2010) has suggested an interesting researchdirection, which has still remained unexplored.
Indeed, (Carpineto and Romano, 2010) showed that metaclustering leads to improved results in the context of text-based (endogenous) SRC.
This suggests thatbetter clustering can be obtained by combining different SOO solutions.
However, their algorithm iscasted to a SOO problem of the concordance between the clustering combination and a meta partition.As a consequence, we hypothesize that improved performances can be obtained by defining the SRCtask as a MOO clustering problem.
For that purpose, we (1) take advantage of the recent advances in thefield of multi-objective clustering (Saha and Bandyopadhyay, 2010), (2) define new objective functionsin a non euclidean space and (3) adapt a MOO-based simulated annealing technique called AMOSA(Bandyopadhyay et al., 2008) to take into account third-order similarity metrics (Moreno et al., 2013).3 Clustering as a MOO Problem3.1 Formal Definition of MOO ClusteringMulti-objective optimization can be formally stated as finding the vector x?= [x?1, x?2, .
.
.
, x?n]Tofdecision variables that simultaneously optimize M objective function values {f1(x), f2(x), .
.
.
, fM(x)}while satisfying user-defined constraints, if any.An important concept in MOO is that of domination.
Within the context of a maximization prob-lem, a solution xiis said to dominate xjif ?k ?
1, 2, .
.
.
,M, fk(xi) ?
fk(xj) and ?k ?1, 2, .
.
.
,M, such that fk(xi) > fk(xj).Among a set of solutions R, the non-dominated set of solutions R?are those that are not dominated byany member of the set R and is called the globally Pareto-optimal set or Pareto front.
In general, a MOOalgorithm outputs a set of solutions not dominated by any solution encountered by it.
These notions canbe illustrated by considering an optimization problem with two objective functions (f1and f2) with sixdifferent solutions, as shown in Figure 1.
Here target is to maximize both objective functions f1and f2.1345Pareto Front26f1(maximize)f2(maximize)Figure 1: Example of dominance and Pareto optimal front.In this example, solutions 3, 4 and 5 dominate all the other three solutions 1, 2 and 6.
Solutions 3, 4and 5 are nondominating to each other.
Because 3 is better than 4 w.r.t.
function f1, but 4 is better than3 w.r.t.
f2.
Similarly 4 is better than 5 w.r.t.
f1but 5 is better than 4 w.r.t.
f2.
The same happens forsolutions 3 and 5.
So, the Pareto front is made of solutions 3, 4 and 5.Within the specific context of clustering, two objective functions are usually defined, which must beoptimized simultaneously.
These functions are based on two intrinsic properties of the data space andare defined as follows.2SRC is usually referred to as text clustering in the ?small?
: i.e.
small list of short text documents.101Compactness: This objective function measures the proximity among the various elements of a givencluster and must be maximized.Separability: This objective function measures the similarity between two cluster centroids and mustbe minimized.3.2 AMOSA Optimization StrategyClustering is viewed as a search problem, where optimal partitions satisfying the given set of objectivefunctions must be discovered.
As such, an optimization strategy must be defined.
Here, we propose touse archived multi-objective simulated annealing (AMOSA) proposed by (Bandyopadhyay et al., 2008).AMOSA incorporates the concept of an archive where the non-dominated solutions seen so far are stored.Two limits are kept on the size of the archive: a hard limit denoted by HL and a soft limit denoted bySL.
Given ?
> 1, the algorithm begins with the initialization of a number (?
?
SL) of solutions each ofwhich representing a state in the search space.
Thereafter, the non-dominated solutions are determinedand stored in the archive.Then, one point is randomly selected from the archive.
This is taken as the current point, or the initialsolution, at temperature T = Tmax.
The current point is perturbed/mutated to generate a new solutionnamed new-pt and its objective functions are computed.
The domination status of the new-pt is checkedw.r.t.
the current point and the solutions in the archive.
Based on domination status, different cases mayarise: (i) accept the new-pt, (ii) accept the current-pt or (iii) accept a solution from the archive.
In caseof overflow of the archive, its size is reduced to HL.The process is repeated iter times for each temperature that is annealed with a cooling rate of ?
(<1)till the minimum temperature Tminis attained.
The process thereafter stops and the archive contains thefinal non-dominated solutions i.e.
the Pareto front.4 SRC as MOO Problem: MOO-clus4.1 Archive InitializationAs we follow an endogenous approach, only the information returned by a search engine is used.
Inparticular, we only deal with web snippets and each one is represented as a word feature vector.
So, oursolution called MOO-clus starts its execution after initializing the archive with some random solutionsas archive members.
Here, a particular solution refers to a complete assignment of web snippets (or datapoints) in several clusters.
So, the first step is to represent a solution compatible with AMOSA, whichrepresents each individual solution as a string.
In order to encode the clustering problem in the form ofa string, a center-based representation is used.
Note that the use of a string representation facilitates thedefinition of individuals and mutation functions (Bandyopadhyay et al., 2008).Let us assume that the archive member i represents the centroids of Kiclusters and the number oftokens in a centroid is p3, then the archive member (or string) has length liwhere li= p?Ki.
To initializethe number of centroids Kiencoded in the string i, a random value between 2 and Kmaxis chosen andeach Kicluster centroid is initialized by randomly generated tokens from the global vocabulary.4.2 Assignment of Web SnippetsAs for any classical clustering algorithms, web snippets (or data points) must be assigned to their respec-tive clusters.
In MOO-clus, this assignment is computed as in (Moreno et al., 2013), to take advantageof recent advances in similarity measures.
For two word feature vectors diand dj, their similarity isevaluated by the similarity of their constituents as defined in Equation 1.S(di, dj) =1?di??dj??di??r=1?dj?
?b=1SCP (wri, wbj), with SCP (w1, w2) =P (w1, w2)2P (w1) ?
P (w2)(1)3A centroid is represented by a p word feature vector (w1k, w2k, w3k, .
.
.
, wpk).102Here, wri(resp.
wbj) corresponds to the token at the rth(resp.
bth) position of the word feature vector di(resp.
dj).
?di?
and ?dj?
respectively denote the total number of tokens in word feature vectors dianddj.
SCP (wri, wbj) is the Symmetric Conditional Probability (da Silva et al., 1999) where P (., .)
is thejoint probability of two tokens (w1and w2) appearing in the same word feature vector and P (.)
is themarginal probability of any token appearing in a word feature vector.Note that each cluster centroid is a word feature vector of varying number of tokens.
Thus, Equation 2is used to assign any data point (web snippet) djto a cluster twhose centroid has the maximum similarityvalue to dj.t = argmaxk=1,...KS(dj,mpik) (2)K denotes the total number of clusters, djis the jthweb snippet, mpikis the centroid of the kthcluster pikand S(dj,mpik) denotes similarity measurement between the point djand cluster centroidmpikdefined in Equation 1.4.3 Definition of Objective FunctionsA string i represents a set of centroids to which web snippets can be assigned as seen in Section 4.2.
As aconsequence, each string i corresponds to a candidate partition of the data space.
Now, in order to verifythe domination of different solutions over other ones, objective functions must be defined.
Compactnessand separability are usually used in MOO clustering solutions.
Here, compactness can be defined as theinformational density of each cluster.
This can be straightforwardly formulated as in Equation 3.Compactness =K?k=1?di?pikS(di,mpik) (3)Note that if tokens in a particular cluster are very similar to the cluster centroid then the correspondingCompactness value would be maximized.
Here our target is to form good clusters whose compactnessin terms of similarity should be maximum.The second objective function is cluster separability, which measures the dissimilarity between twocluster centroids.
Indeed, the purpose of any clustering algorithm is to obtain compact similar typedclusters, which are dissimilar to each other.
Here, we define separability as the minimization of thesummation of similarities between each pair of cluster centroids.
This is defined in Equation 4, wherempikand mpioare the centroids of clusters pikand pio, respectively.Separability =K?k=1K?o=k+1S(mpik,mpio) (4)Finally, for a particular string, the following objectives {Compactness,1Separability} are maximizedusing the search capability of AMOSA.4.4 Search OperatorsIn MOO-clus, AMOSA is used as the optimization strategy.
For that purpose, three different types ofmutation operations have been defined to suit the framework.Mutation 1: This mutation operation is used to update the cluster center representation.
Each token ofcluster centroid is replaced by one token from the global vocabulary according to highest SCP similarity.This is applied individually to all tokens of a particular centroid if it is selected for mutation.Mutation 2: This mutation operation is used to reduce the size of the string by 1.
We randomly select acluster centroid and thereafter all the tokens of this centroid are deleted from the string.Mutation 3: This mutation is for increasing the size of string by 1 i.e.
one new centroid is inserted inthe string.
For that purpose, we randomly choose p number of tokens from the global vocabulary andadd it to the string.103Let be a string < w1w2w3w4w5w6> representing three cluster centroids (w1, w2), (w3, w4) and(w5, w6)4.
For mutation 1, let position 2 be selected randomly.
Each token of the word vector (w3, w4)will be changed by some token from the global vocabulary using SCP.
Then, after change, the stringwill look like < w1w2wnew3wnew4w5w6>.
If mutation 2 is selected, a centroid will be removed fromthe string.
Let centroid 3 be selected for deletion.
The new string will look like < w1w2w3w4>.In case of mutation 3, a new centroid will be added to the string.
A new cluster centroid is generatedchoosing p=2 number of tokens from the global vocabulary.
Let the randomly generated new clus-ter centroid to be added to the string be (w7, w8).
After inclusion of this centroid, the string will be< w1w2w3w4w5w6w7w8>.
In our experiments, we have associated equal probability to each ofthese mutation operations.
Thus, each mutation is applied in 33% cases of the cases.5 Experimental Setup5.1 DatasetsThe main gold standards used for the evaluation of SRC algorithms are ODP-239 and MORESQUE5.In ODP-239 (Carpineto and Romano, 2010), each document is represented by a title and a web snip-pet and the subtopics are chosen from the top levels of DMOZ6.
On the other hand, the subtopics inMORESQUE (Navigli and Crisafulli, 2010) follow a more natural distribution as they are defined basedon the disambiguation pages of Wikipedia.
As such, the subtopics cover most of the query-related senses.However, not all queries are Wikipedia related or ambiguous (e.g.
?Olympic Games?, which Wikipediaentry is not ambiguous, although there are many events related to this topic).
As a consequence, it isclear that different results can be obtained from one data set to another.
A quick summary of both datasets is presented in Table 1.# of # of Subtopics # ofDataset queries Avg / Min / Max SnippetsODP-239 239 10 / 10 / 10 25580MORESQUE 114 6.7 / 2 / 38 11402Table 1: SRC gold standard data sets.5.2 Evaluation MetricsA successful SRC systemmust evidence high quality level clustering.
Each query subtopic should ideallybe represented by a unique cluster containing all the relevant web pages inside.
However, determining aunique and complete metric to evaluate the performance of a clustering algorithm is still an open problem(Amig?o et al., 2013).In this paper, we propose to use the Fb3-measure (Amig?o et al., 2009) to explore the Pareto front.In particular, Fb3has been defined to evaluate cluster homogeneity, completeness, rag-bag and size-vs-quantity constraints.
Fb3is a function of Precisionb3(Pb3) and Recallb3(Rb3).
All metrics are definedin Equation 5Fb3=2 ?
Pb3?Rb3Pb3+ Rb3, Pb3=1NK?i=1?dj?pii1|pii|?dl?piig?
(dj, dl), Rb3=1NK?i=1?dj?pi?i1|pi?i|?dl?pi?ig(dj, dl) (5)where piiis ithcluster, pi?iis the gold standard of the category i, and g?
(., .)
and g(., .)
are defined asfollows:g?
(di, dj) ={1 ?
?l : di?
pi?l?
dj?
pi?l0 otherwiseand g(di, dj) ={1 ?
?l : di?
pil?
dj?
pil0 otherwise.4with p=2.5AMBIENT has received less attention since the creation of ODP-239.6http://www.dmoz.org [Last access: 14/03/2014].104Most SRC studies have also used the F?-measure (F?
), which is defined in Equation 6.F?=(?2+ 1) ?
P ?R?2?
P + R, P =TPTP + FP, R =TPTP + FN(6)whereTP =K?i=1?dj?pi?i?dl?
pi?il 6= jg(di, dj), FP =K?i=1?dj?pii?dl?
piil 6= j(1?
g?
(di, dj)), FN =K?i=1?dj?pi?i?dl?
pi?il 6= j(1?
g(di, dj)).6 Results and DiscussionIn this evaluation, we used the open source framework GATE (Cunningham et al., 2013) without stop-word removal for web snippet tokenization7.
We executed MOO-clus over ODP-239 and MORESQUE.The parameters of MOO-clus are: Tmin= 0.01, Tmax= 100, ?
= 0.85, HL = 10, SL = 20 anditer = 15.
Note that, they have been determined after conducting a thorough sensitivity study.
A firstset of experiments have been conducted for different p values of tokens present in the centroid, namelyin the range 2 to 5 in order to understand the behavior of MOO-clus w.r.t.
centroid size8.
Note that thepartition with maximum Fb3 is choosen for each size of p9.
Overall results are shown in Table 2.MORESQUE ODP-239MOO-clus MOO-clus2 3 4 5 2 3 4 5Fb30.477 0.491 0.497 0.502 0.478 0.481 0.484 0.481F10.661 0.666 0.675 0.658 0.379 0.379 0.384 0.381F20.750 0.768 0.764 0.742 0.534 0.536 0.537 0.535F50.831 0.862 0.846 0.820 0.717 0.720 0.716 0.715Table 2: Evaluation results of MOO-clus over MORESQUE and ODP239 data sets.Results show that for MORESQUE, MOO-clus obtains the highest Fb3 value for p=5.
In particular,performance increases for higher values of p. For ODP-239, best results are reported for p=4, but evi-dence less sensitivity to the number of words in the centroids.
Indeed, a marginal difference is obtainedbetween all runs.
In terms of F?, the same behaviour is obtained for ODP-239.
But, for MORESQUE,best results are provided for smaller values of p, namely p=3.Two important comments must be pointed at.
In the first place, Fb3shows a steady behaviour comparedto F?when the data set changes.
The conclusions drawn in (Amig?o et al., 2009) reporting the superiorityof Fb3over F?seem to be verified for the specific case of SRC.
In the second place, MOO-clus evidencesa marginal sensitivity to different p values.
Indeed, for ODP-239, changing p between 2 and 5 words hasa negligible impact on Fb3 .
The figures show a different behaviour for MORESQUE but this can easilybe explained.
In MORESQUE, less queries are provided for test and the number of reference clustersvaries between 2 and 38, with a majority of queries containing very few clusters (the average cluster sizeis 6.7).
As such, small clustering errors may result in high deviations in the evaluation metrics.
So, pcan be seen as a non influent parameter for clustering purposes.
In fact, increasing the value of p mayexclusively allow a more descriptive power for cluster labeling.We also compared MOO-clus to the current state-of-the-art text-based (endogenous) SRC algorithms:STC (Zamir and Etzioni, 1998), LINGO (Osinski and Weiss, 2005), OPTIMSRC (Carpineto and Ro-mano, 2010), Bisecting Incremental K-means (BIK), GK-means (Moreno et al., 2013) and the combi-nation STC-LINGO (Moreno and Dias, 2014).
The results are illustrated in Table 3 where we providevalues for all the metrics for open source implementations and reported values in the literature for the7Note that keeping stop words is a challenging task as most methodologies withdraw these elements as they are hard tohandle.
This decision is supported by the fact that we aim to produce as much as possible language-independent solutions.8Note that to ease the user effort in searching for information, the cluster label must be small and expressive.
Typicalconfigurations range between 3 to 5 to include multiword expressions.9F?metrics are calculated over the partition with highest Fb3value.105other experiments i.e.
OPTIMSRC, GK-means and STC-LINGO.
In particular, the Min (resp.
Max)column refers to the worst (resp.
best) performance when varying p, the size of the centroid.The results of Table 3 clearly show the performance improvements of our proposed methodology overexisting text-based techniques for both data sets and most evaluation metrics.
For ODP-239, MOO-clusattains the highest values with respect to F1, F2, F5and Fb3metrics against all existing endogenous algo-rithms.
For MORESQUE, our algorithm reaches highest performance over all state-of-the-art algorithmsfor F1and Fb3 metrics but marginally fails for F2and F5against GK-means.MOO-clus SOO SRC Combination of SOO SRCMin Max GK-means STC LINGO BIK OPTIMSRC STC-LINGOMORESQUE F10.658 0.675 0.665 0.455 0.326 0.317 N/A 0.561F20.742 0.768 0.770 0.392 0.260 0.269 N/A N/AF50.820 0.862 0.872 0.370 0.237 0.255 N/A N/AFb30.477 0.502 0.482 0.460 0.399 0.315 N/A 0.498ODP-239 F10.379 0.384 0.366 0.324 0.273 0.200 0.313 0.362F20.534 0.537 0.416 0.319 0.167 0.173 0.341 N/AF50.715 0.720 0.462 0.322 0.153 0.165 0.380 N/AFb30.478 0.484 0.452 0.403 0.346 0.307 N/A 0.425Table 3: Comparative results with respect to F?and Fb3 metrics over the ODP-239 and MORESQUEdatasets obtained by different SRC techniques.It is important to notice that OPTIMSRC and STC-LINGO can be viewed as a combination of differentSRC SOO solutions but still casted to a SOO solution.
These previous results report interesting issuesfor SRC and confort the idea that the combination of different objective functions may lead to enhancedSRC algorithms.
But, MOO-clus is capable to find better partitions than OPTIMSRC and STC-LINGOfor all data sets and all evaluation metrics as reported in Table 3.It is important to notice that the MOO-clus provides a set of partitions with automatic definition ofthe number of clusters.
So, defining one unique solution is an important issue for SRC.
So far, we haveprovided results for the best partition evaluated by Fb3.
However, deeper analysis of all the partitionson the Pareto front must be endeavoured.
Results are reported for Fb3only as all other metrics behavecorrespondingly and are reported in Table 4.MORESQUE ODP-2392 3 4 5 2 3 4 5Min 0.428 0.464 0.464 0.462 0.396 0.401 0.403 0.408Max 0.477 0.491 0.497 0.502 0.478 0.481 0.484 0.481Avg.
0.454 0.479 0.482 0.486 0.443 0.447 0.448 0.449Table 4: Fb3 evaluation results of the Pareto front.Figures show the validity of each individual solution of the Pareto front.
In the worst case, MOO-clusproduces similar results compared to the hard baseline STC.
On average, it reaches the results of GK-means and the highest performance values can be found on the Pareto front.
The correct identificationof the best partition is still an open issue and can be compared to the automatic selection of K clusters,which is a hard task as shown in recent studies (Scaiella et al., 2012; Marco and Navigli, 2013).7 ConclusionsIn this paper, we proposed the first attempt10to define the SRC task as a multi-objective problem.
For thatpurpose, we defined two objective functions, which are simultaneously optimized through the archivedmulti-objective simulated annealing framework called AMOSA.
A correct definition of the task allowedto take advantage of the most recent advances in terms of endogenous SRC algorithms as well as the mostpowerful techniques for multi-objective clustering.
The performance of MOO-clus has been evaluatedover two gold standard data sets, ODP-239 andMORESQUE for different evaluation metrics, F1and Fb3 .10As far as we know.106Results showed that our proposal steadily outperforms all existing state-of-the-art text-based endogenousSRC algorithms and approaches recent knowledge-driven exogenous strategies (Scaiella et al., 2012),which reach F1=0.413 for ODP-23911.As future works, we propose to use MOO clustering in a strict meta learning way, where any labeled-based SOO solution is defined by specific Compactness and Separability functions.
Another researchdirection is the definition of the Dual representation proposed by (Moreno et al., 2014) as a MOO prob-lem.
Finally, new objective functions can be defined to measure the quality of the labels, which mayintegrate meaningful multiword expressions or named entities.AcknowledgementWe would like to thank the CNRS to provide Sriparna Saha with a 6 months internship at the GREYCLaboratory of the Normandie University.ReferencesEnrique Amig?o, Julio Gonzalo, Javier Artiles, and Felisa Verdejo.
2009.
A comparison of extrinsic clusteringevaluation metrics based on formal constraints.
Information Retrieval, 12(4):461?486.Enrique Amig?o, Julio Gonzalo, and Felisa Verdejo.
2013.
A general evaluation measure for document organizationtasks.
In Proceedings of the 36th International ACM SIGIR Conference on Research and Development inInformation Retrieval (SIGIR), pages 643?652.Sanghamitra Bandyopadhyay, Anirban Mukhopadhyay, and Ujjwal Maulik.
2007.
An improved algorithm forclustering gene expression data.
Bioinformatics, 23(21):2859?2865.Sanghamitra Bandyopadhyay, Sriparna Saha, Ujjwal Maulik, and Kalyanmoy Deb.
2008.
A simulated annealing-based multiobjective optimization algorithm: Amosa.
In IEEE transactions on evolutionary computation, pages269?283.James C. Bezdek.
1981.
Pattern Recognition with Fuzzy Objective Function Algorithms.
Plenum, New York.Thorsten Brants and Alex Franz.
2006.
Web 1t 5-gram.Claudio Carpineto and Giovanni Romano.
2010.
Optimal meta search results clustering.
In 33rd InternationalACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 170?177.Claudio Carpineto, Stanislaw Osinski, Giovanni Romano, and Dawid Weiss.
2009.
A survey of web clusteringengines.
ACM Computing Surveys, 41(3):1?38.Hamish Cunningham, Valentin Tablan, Angus Roberts, and Kalina Bontcheva.
2013.
Getting more out ofbiomedical documents with gate?s full lifecycle open source text analytics.
PLoS Computational Biology,9(2):e1002854.Joaquim Ferreira da Silva, Ga?el Dias, Sylvie Guillor?e, and Jos?e Gabriel Pereira Lopes.
1999.
Using localmaxsalgorithm for the extraction of contiguous and non-contiguous multiword lexical units.
In Proceedings of 9thPortuguese Conference in Artificial Intelligence (EPIA), pages 113?132.Kalyanmoy Deb.
2009.
Multi-Objective Optimization Using Evolutionary Algorithms.
Wiley.Julia Handl and Joshua Knowles.
2007.
An evolutionary approach to multiobjective clustering.
IEEE Transactionson Evolutionary Computation, 11:56?76.Antonio D. Marco and Roberto Navigli.
2013.
Clustering and diversifying web search results with graph-basedword sense induction.
Computational Linguistics, 39(4):1?43.Ujjwal Maulik, Sanghamitra Bandyopadhyay, and Anirban Mukhopadhyay.
2011.
Multiobjective Genetic Algo-rithms for Clustering - Applications in Data Mining and Bioinformatics.
Springer.Jos?e G. Moreno and Ga?el Dias.
2014.
Easy web search results clustering: When baselines can reach state-of-the-art algorithms.
In Proceedings of the 14th Conference of the European Chapter of the Association forComputational Linguistics (EACL), pages 1?5.11Note that results of (Marco and Navigli, 2013) are not reported in this paper as the authors do not use the standard versionsof MORESQUE and do not provide experiments for ODP-239.107Jos?e G. Moreno, Ga?el Dias, and Guillaume Cleuziou.
2013.
Post-retrieval clustering using third-order similaritymeasures.
In 51st Annual Meeting of the Association for Computational Linguistics (ACL), pages 153?158.Jos?e G. Moreno, Ga?el Dias, and Guillaume Cleuziou.
2014.
Query log driven web search results clustering.
InProceedings of the 37th Annual ACM SIGIR Conference (SIGIR).Katharina Morik, Andreas Kaspari, Michael Wurst, and Marcin Skirzynsk.
2012.
Multi-objective frequent termsetclustering.
Knowledge Information Systems, 30(3):715?738.Anirban Mukhopadhyay and Ujjwal Maulik.
2009.
Unsupervised pixel classification in satellite imagery usingmultiobjective fuzzy clustering combined with SVM classifier.
IEEE Transactions on Geoscience and RemoteSensing, pages 1132?1138.Roberto Navigli and Giuseppe Crisafulli.
2010.
Inducing word senses to improve web search result clustering.
InProceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages116?126.Stanislaw Osinski and Dawid Weiss.
2005.
A concept-driven algorithm for clustering search results.
IEEEIntelligent Systems, 20(3):48?54.Sriparna Saha and Sanghamitra Bandyopadhyay.
2010.
A symmetry based multiobjective clustering technique forautomatic evolution of clusters.
Pattern Recognition, 43(3):738?751.Ugo Scaiella, Paolo Ferragina, Andrea Marino, and Massimiliano Ciaramita.
2012.
Topical clustering of searchresults.
In 5th ACM International Conference on Web Search and Data Mining (WSDM), pages 223?232.Xuanli L. Xie and Gerardo Beni.
1991.
A validity measure for fuzzy clustering.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 13:841?847.Oren Zamir and Oren Etzioni.
1998.
Web document clustering: A feasibility demonstration.
In 21st AnnualInternational ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages46?54.108
