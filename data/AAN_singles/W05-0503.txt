Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 20?27,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsUsing Morphology and Syntax Togetherin Unsupervised LearningYu Hu and Irina MatveevaDepartment ofComputer ScienceThe University of ChicagoChicago IL 60637yuhu@cs.uchicago.edumatveeva@uchicago.eduJohn GoldsmithDepartments of Linguistics andComputer ScienceThe University of ChicagoChicago IL 60637ja-goldsmith@uchicago.eduColin SpragueDepartment of LinguisticsThe University of ChicagoChicago IL 60637sprague@uchicago.eduAbstractUnsupervised learning of grammar is aproblem that can be important in manyareas ranging from text preprocessingfor information retrieval andclassification to machine translation.We describe an MDL based grammarof a language that contains morphologyand lexical categories.
We use anunsupervised learner of morphology tobootstrap the acquisition of lexicalcategories and use these two learningprocesses iteratively to help andconstrain each other.
To be able to doso, we need to make our existingmorphological analysis less finegrained.
We present an algorithm forcollapsing morphological classes(signatures) by using syntactic context.Our experiments demonstrate that thiscollapse preserves the relation betweenmorphology and lexical categorieswithin new signatures, and therebyminimizes the description length of themodel.1 IntroductionOur long term goal is the development ofmethods which will allow one to produceoptimal analyses from arbitrary natural languagecorpora, where by optimization we understandan MDL (minimum description length;Rissanen, 1989) interpretation of the term: anoptimal analysis is one which finds a grammarwhich simultaneously minimizes grammarlength and data compression length.
Our specificand primary focus is on morphology, and onhow knowledge of morphology can be a usefulstep towards a more complete knowledge of alanguage?s linguistic structure.Our strategy is based on the followingobservation: knowing the rightmost suffix of aword is very useful information in inferring (orguessing) a word?s part of speech (POS), but dueto the ambiguity of many suffixes, it is evenbetter to know both a word?s suffix and therange of other suffixes that the word?s stemappears with elsewhere, i.e., its signature.
As wewill see below, this conjunction of ?better?information is what we call the signaturetransform, and in this paper, we explore howknowledge of signature transform can be mergedwith knowledge of the context vector to drawconclusions about morphology and syntax.In the distant future, we would like to be ableto use the signature transform in a generalprocess of grammar induction, but that day isnot here; we therefore test our experiments byseeing how well we are able to predict POS asassigned by an available tagger (TreeTagger;Schmid 1994).
In particular, we wish to decreasethe uncertainty of a word?s POS through themorphological analysis described here.
Thisdecrease of uncertainty will enter into ourcalculation through an increase in theprobability assigned to our test corpus once thecorpus has been augmented with TreeTaggerassigned POS tags.
But to be clear on our20process: we analyze a completely raw textmorphologically, and use the POS tags fromTreeTagger only to evaluate the signaturetransforms that we generate.We assume without argument here that anyadequate natural language grammar will containa lexicon which includes both lexical stemswhich are specified for morphologicalproperties, such as the specific affixes withwhich they may occur, and affixes associatedwith lexical categories.
We also explicitly notethat many affixes are homophonous: they arepronounced (or written) identically, but havedifferent morphological or syntacticcharacteristics, such as the English plural ?s andthe verbal 3rd person singular present ?s.We focus initially on unsupervised learningof morphology for three reasons: first, becausewe already have a quite successful unsupervisedmorphological learner; second, the final suffix ofa word is typically the strongest single indicatorof its syntactic category; and third, analysis of aword into a stem T plus suffix F allows us(given our knowledge that the suffix F is astronger indicator of category than the stem T)to collapse many distinct stems into a singlecover symbol for purposes of analysis,simplifying our task, as we shall see.1 Weeschew the use of linguistic resources with hand-(i.e., human-)assigned morphological infor-mation in order for this work to contribute,eventually, to a better theoretical understandingof human language acquisition.We present in this paper an algorithm thatmodifies the output of the morphology analyzerby combining redundant signatures.
Since weultimately want to use signatures and signaturetransforms to learn syntactic categories, wedeveloped an algorithm that uses the syntacticcontextual information.
We evaluate the changesto the morphological analysis from thestandpoint of efficient and adequaterepresentation of lexical categories.
This paperpresents a test conducted on English, and thuscan only be considered a preliminary step in the1 See Higgins 2002 for a study similar in some ways;Higgins uses morphology as a bootstrap heuristic in oneexperimental set-up.
This paper is heavily indebted to priorwork on unsupervised learning of position categories suchas Brown et al1992, Sch?tze 1997, Higgins 2002, andothers cited there.eventually development of a language-independent tool for grammar induction basedon morphology.
Nonetheless, the concepts thatmotivate the process are language-independent,and we are optimistic that similar results wouldbe found in tests based on texts from otherlanguages.In section 2 we discuss the notion ofsignature and signature transform, and section 3present a more explicit formulation of thegeneral problem.
In section 4 we present ouralgorithm for signature collapse.
Section 5describes the experiments we ran to test thesignature collapsing algorithm, and section 6presents and discusses our results.2 Signatures and signature transformsWe employ the unsupervised learning ofmorphology developed by Goldsmith(Goldsmith, 2001).
Regrettably, some of thediscussion below depends rather heavily onmaterial presented there, but we attempt tosummarize the major points here.Two critical terms that we employ in thisanalysis are signature and signature transform.A signature found in a given corpus is a pair oflists: a stem-list and a suffix-list (or in theappropriate context, a prefix-list).
By definitionof signature ?, the concatenation of every stemin the stem-list of ?
with every suffix in thesuffix-list of ?
is found in the corpus, and amorphological analysis of a corpus can beviewed as a set of signatures that uniquelyanalyze each word in the corpus.
For example, acorpus of English that includes the words jump,jumps, jumped, jumping, walk, walks, walked,and walking might include the signature ?1whose stem list is { jump, walk } and whosesuffix list is { ?, ed, ing , s }.
For convenience,we label a signature with the concatenation of itssuffixes separated by period ?.?.
On such ananalysis, the word jump is analyzed as belongingto the signature ?.ed.ing.s, and it bears thesuffix ?.
We say, then, that the signaturetransform of jump is ?.ed.ing.s_ ?, just as thesignature transform of jumping is?.ed.ing.s_ing; in general, the signaturetransform of a word W, when W is morpho-logically analyzed as stem T followed by suffixF, associated with signature ?, is defined as ?_F.21In many of the experiments described below,we use a corpus in which all words whosefrequency rank is greater than 200 have beenreplaced by their signature transforms.
Thismove is motivated by the observation that highfrequency words in natural languages tend tohave syntactic distributions poorly predictableby any feature other than their specific identity,whereas the distribution properties of lowerfrequency words (which we take to be wordswhose frequency rank is 200 or below) are betterpredicted by category membership.In many cases, there is a natural connectionbetween a signature transform and a lexicalcategory.
Our ultimate goal is to exploit this inthe larger context of grammar induction.
Forexample, consider the signature ?.er.ly, whichoccurs with stems such as strong and weak; infact, words whose signature transform is?.er.ly_ ?
are adjectives, those whose signaturetransform is ?.er.ly_er are comparativeadjectives, and those whose signature transformis ?.er.ly_ly are adverbs.The connection is not perfect, however.Consider the signature ?.ed.ing.s and its foursignature transforms.
While most words whose?
-transform is ?.ed.ing.s_s are verbs (indeed,3rd person singular present tense verbs, as in hewalks funny), many are in fact plural nouns (e.g.,walks in He permitted four walks in the eighthinning is a plural noun).
We will refer to thisproblem as the signature purity problem?it isessentially the reflex of the ambiguity ofsuffixes.In addition, many 3rd person singular presenttense verbs are associated with other signaturetransforms, such as ?.ing.s_s, ?.ed.s_s, and soforth; we will refer to this as the signature-collapsing problem, because all other thingsbeing equal, we would like to collapse certainsignatures, such as ?.ed.ing.s and ?.ed.ing,since a stem that is associated with the lattersignature could have appeared in the corpus withan -s suffix; removing the ?.ed.ing signature andreassigning its stems to the ?.ed.ing.s signaturewill in general give us a better linguistic analysisof the corpus, one that can be better used in theproblem of lexical category induction.
This isthe reflex of the familiar data sparsity concern.2Since we ultimately want to use signaturesand signature transforms to learn syntacticcategories, we base the similarity measurebetween the signatures on the context.3 A more abstract statement of theproblemA minimum description length (MDL) analysisis especially appropriate for machine learning oflinguistic analysis because simultaneously itputs a premium both on analytical simplicity andon goodness of fit between the model and thedata (Rissanen 1989).We will present first the mathematicalstatement of the MDL model of the morphology,in (1), following the analysis in Goldsmith(2001), followed by a description of the meaningof the terms of the expressions, and then presentthe modified version which includes additionalterms regarding part of speech (POS)information, in (2) and (3).
(1) Morphologya.
Grammar g =[ ])|(log)(minarg gDataprobgLengthGg??b.
=)(gLength?
?=?
<???????
+stemsofsetTt ti itfreqtW||0 ][1log)]([][log ??
?=?
<?+affixesofsetFf fi iffreq||0 ][1log????
???????
+?+ ?
?
?
?f fWf ][][log][][log2 The signature-collapsing problem has another side to it aswell.
An initial morphological analysis of English willtypically give rise to a morphological analysis of wordssuch as move, moves, moved, moving with a signaturewhose stems include mov and whose affixes are e.ed.es.ing.A successful solution to the signature-collapsing problemwill collapse ?.ed.ing.s with e.ed.es.ing, noting that ?
~ e,ed ~ed, es ~ s, and ing ~ ing in an obvious sense.22c.
=)|(log gDataprob?+=?
??????????++?
??
?, ),|(log)|(log)(logftwDataw tfprobtprobprobEquation (1a) states that our goal is to findthe (morphological) grammar thatsimultaneously minimizes the sum of its ownlength and the compressed length of the data itanalyzes, while (1b) specifies the grammarlength (or model length) as the sum of thelengths of the links between the majorcomponents of the morphology: the list of letters(or phonemes) comprising the morphemes, themorphemes (stems and affixes), and thesignatures.
We use square brackets ?[.]?
todenote the token counts in a corpus containing agiven morpheme or word.
The first line of (1b)expresses the notion that each stem consists of apointer to its signature and a list of pointers tothe letters that comprise it; ?
(t) is the signatureassociated with stem t, and we take itsprobability to be][)]([Wt?
, the empirical count ofthe words associated with ?
(t) divided by thetotal count of words in the data.
The second lineexpresses the idea that the morphology containsa list of affixes, each of which contains a list ofpointers to the letters that comprise it.
The thirdline of (1b) expresses the notion that a signatureconsists of a list of pointers to the componentaffixes.
(1c) expresses the compressed length ofeach word in the data.3We now consider extending this model toinclude part of speech labeling, as sketched in(2).
The principal innovation in (2) is theaddition of part of speech tags; each affix isassociated with one or more POS tags.
As we3 We do not sum over all occurrences of a word in thecorpus; we count the compressed length of each word typefound in the corpus.
This decision was made based on theobservation that the (compressed length of the) data termgrows much faster than the length of the grammar as thecorpus gets large, and the loss in ability of the model topredict word frequencies overwhelms any increase inmodel simplicity when we count word tokens in the dataterms.
We recognize the departure from the traditionalunderstanding of MDL here, and assume the responsibilityto explain this in a future publication.have seen, a path from a particular signature ?
toa particular affix f constitutes what we havecalled a particular signature transform ?_f ; andwe condition the probabilities of the POS tags inthe data on the preceding signaturetransformation.
As a result, our final model takesthe form in (3).
(2)t1t2t3tn...Stems Signatures Affixes POSs?1?2?m...f1f2f3fk...?1?2?3?l...(3)a. Grammar g =   [ ])|(log)(minarg gDataprobgLengthGg??b.
=)(gLength?
?=?
<???????
+stemsofsetTt ti itfreqtW||0 ][1log)]([][log ??
?=?
<?+affixesofsetFf fi iffreq||0 ][1log??
???
???
???????????????++?+?
??
?????ffffWf][][log][][log][][logc.
=)|(log gDataprob?+=?
??????????+++?
????
?, ),|(log),|(log)|(log)(logftwDataw fprobtfprobtprobprobThe differences between the models arefound in the added final term in (3b), whichspecifies the information required to predict, orspecify, the part of speech given the signature23transform, and the corresponding term in thecorpus compression expression (3c).The model in (3) implicitly assumes that thetrue POSs are known; in a more completemodel, the POSs play a direct role in assigning ahigher probability to the corpus (and hence asmaller compressed size to the data).
In thecontext of such a model, an MDL-based learningdevice searches for the best assignment of POStags over all possible assignments.
Instead ofdoing that in this paper, we employ theTreeTagger (Schmid, 1994) based tags (seesection 5 below), and make the workingassumption that optimization of descriptionlength over all signature-analyses and POS tagscan be approximated by optimization over allsignature-analyses, given the POS tags providedby TreeTagger.4 The collapsing of signaturesWe describe in this section our proposedalgorithm, using context vectors to collapsesignatures together, composed of a sequence ofoperations, all but the first of which may befamiliar to the reader:Replacement of words by signature-transforms: The input to our algorithm forcollapsing signatures is a modified version ofthe corpus which integrates the (unsupervised)morphological analyses in the following way.First of all, we leave unchanged the 200 mostfrequent words (word types).
Next, we replacewords belonging to the K most reliablesignatures (where K=50 in these experiments)by their associated signature transforms, and wein effect ignore all other words, by replacingthem by a distinguished ?dummy?
symbol.
Inthe following, we refer to our high frequencywords and signature transforms together aselements?so an element is any member of thetransformed corpus other than the ?dummy?.Context vectors based on mutualinformation: By reading through the corpus, wepopulate both left and right context vectors foreach element (=signature-transform and high-frequency word)  by observing the elements thatoccur adjacent to it.
The feature indicating theappearance of a particular word on the left isalways kept distinct from the feature indicatingthe appearance of the same word on the right.The features in a context vector are thusassociated with the members of the elementvocabulary (and indeed, each member of theelement vocabulary occurs as two features: oneon the left, one on the right).
We assign thevalue of each feature y of x?s context vector asthe pointwise mutual information of thecorresponding element pair (x, y), defined as)()(),(logyprxpryxpr .Simplifying context vectors with ?idf?
: Inaddition, because of the high dimensionality ofthe context vector and the fact that some featuresare more representative than others, we trim theoriginal context vector.
For each context vector,we sort features by their values, and then keepthe top N (in general, we set N to 10) by settingthese values to 1, and all others to 0.
However,in this resulting simplified context vector, not allfeatures do equally good jobs of distinguishingsyntactical categories.
As Wicentowski (2002)does in a similar context, we assign a weightifw  to each feature fi in a fashion parallel toinverse document frequency (idf; see SparckJones 1973), orinappearsfeaturethiselementselementsdistincttotal##log .We view these as the diagonal elements of amatrix M (that is, mi,i = ifw ).
We then check thesimilarity between two simplified contextvectors by computing the weighted sum of thedot product of them.
That is, given twosimplified context vectors c and d, theirsimilarity is defined as cTMd.
If this value islarger than a threshold ?
that is set as oneparameter, we deem these two context vectors tobe similar.
Then we determine the similaritybetween elements by checking whether both leftand right simplified context vectors of them aresimilar (i.e., their weighted dot products exceeda threshold ?).
In the experiments we describebelow, we explore four settings ?
for thisthreshold: 0.8 (the most ?liberal?
in allowinggreater signature transform collapse, and hencegreater signature collapse), 1.0, 1.2, and 1.5.Calculate signature similarity: To avoidconsidering many unnecessary pairs ofsignatures, we narrow the candidates intosignature pairs in which the suffixes of oneconstitute a subset of suffixes of the other, andwe set a limit to the permissible difference in the24lengths of the signatures in the collapsed pairs,so that the difference in number of affixescannot exceed 2.
For each such pair, if allcorresponding signature transforms are similarin the sense defined in the preceding paragraph,we deem the two signatures to be similar.Signature graph: Finally, we construct asignature graph, in which each signature isrepresented as a vertex, and an edge is drawnbetween two signatures iff they are similar, asjust defined.
In this graph, we find a number ofcliques, each of which, we believe, indicates acluster of signatures which should be collapsed.If a signature is a member of two or morecliques, then it is assigned to the largest clique(i.e., the one containing the largest number ofsignatures).45 ExperimentsWe obtain the morphological analysis of theBrown corpus (Ku?era and Francis, 1967) usingthe Linguistica software (http://linguistica.uchicago.edu), and we use the TreeTagger toassign a Penn TreeBank-style part-of-speech tagto each token in the corpus.
We then carry outour experiment using the Brown corpusmodified in the way we described above.
Thus,for each token of the Brown corpus that ourmorphology analyzer analyzed, we have thefollowing information: its stem, its signature4 Our parameters are by design restrictive, sothat we declare only few signatures to be similar,and therefore the cliques that we find in thegraph are relatively small.
One way to enlargethe size of collapsed signatures would be toloosen the similarity criterion.
This, however,introduces too many new edges in the signaturesgraph, leading in turn to spurious collapses ofsignatures.
We take a different approach, andapply our algorithms iteratively.
The idea is thatif in the first iteration, two cliques did not haveenough edges between their elements to becomea single new signature, they may be morestrongly connected in the second iteration ifmany of their elements are sufficiently similar.On the other hand, cliques that were dissimilarin the first iteration remain weakly connected inthe second.
(i.e., the signature to which the stem isassigned), the suffix which the stem attains inthis occurrence of the word (hence, thesignature-transform), and the POS tag.
Forexample, the token polymeric is analyzed intothe stem polymer and the suffix ic, the stem isassigned to the signature ?.ic.s, and thus thisparticular token has the signature transform?.ic.s_ic.
Furthermore, it was assigned POS-tagJJ, so that we have the following entry:?polymeric JJ ?.ic.s_ic?.Before performing signature collapsing, wecalculate the description length of themorphology and the compressed length of thewords that our algorithm analyzes and call itbaseline description length (DL0).Now we apply our signature collapsingalgorithm under several different parametersettings for the similarity threshold ?, andcalculate the description length DL?
of theresulting morphological and lexical analysisusing  (3).
We know that the smaller the set ofsignatures, the smaller is the cost of the model.However, a signature collapse that combinessignatures with different distributions over thelexical categories will result in a high cost of thedata term (3c).
The goal was therefore to find amethod of collapsing signatures such that thereduction in the model cost will be higher thanthe increase in the compressed length of the dataso that the total cost will decrease.As noted above, we perform this operationiteratively, and refer to the description length ofthe ith iteration, using a threshold ?, as ?
iiterDL = .We used random collapsing in ourexperiments to ensure the expected relationshipbetween appropriate collapses and descriptionlength.
For each signature collapsing, we createda parallel situation in which the number ofsignatures collapsed is the same, but their choiceis random.
We calculate the description lengthusing this ?random?
analysis as?randomDL .
Wepredict that this random collapsing will notproduce an improvement in the total descriptionlength.256 Results and discussionTable 1 presents the description length, brokeninto its component terms (see (3)), for thebaseline case and the alternative analysesresulting from our algorithm.
The table showsthe total description length of the model, as wellas the individual terms: the signature termDL(?
), the suffix term DL(F), the lexicalcategories term, DL(P), total morphology,DL(M), and the compressed length of the data,DL(D).
We present results for two iterations forfour threshold values (?=0.8,1.0,1.2,1.5) usingour collapsing algorithm.Table 2 presents?randomDL  derived from therandom collapsing, in a fashion parallel to Table1.
We show the results for only one iteration ofrandom collapsing, since the first iterationalready shows a substantial increase indescription length.Figure 1 and Figure 2 present graphically thetotal description length from Tables 1 and 2respectively.
The reader will see that allcollapsing of signatures leads to a shortening ofthe description length of the morphology per se,and an increase in the compressed length of thedata.
This is an inevitable formal consequence ofthe MDL-style model used here.
The empiricalquestion that we care about is whether thecombined description length increases ordecreases, and what we find is that whencollapsing the signatures in the way that wepropose to do, the combined description lengthdecreases, leading us to conclude that this is,overall, a superior linguistic description of thedata.
On the other hand, when signatures arecollapsed randomly, the combined descriptionlength increases.
This makes sense; randomlydecreasing the formal simplicity of thegrammatical description should not improve theoverall analysis.
Only an increase in the formalsimplicity of a grammar that is grammaticallysensible should have this property.
Since ourgoal is to develop an algorithm that iscompletely data-driven and can operate in anCompa rison of DL362,500363,000363,500364,000364,500365,000365,500366,000DL0 DL1 DL2?=0.8 ?=1 ?=1.2 ?=1.5Figure 1 Comparison of DL, 2 iterations and 4threshold valuesCompa rison of ra ndomly c olla psing DL364,000364,500365,000365,500366,000366,500367,000367,500368,000DL0 DrandomDL?=0.8 ?=1 ?=1.2 ?=1.5Figure 2 Comparison of DLs with randomcollapse of signatures (see text)DL0 8.0 1==?iterDL8.02==?iterDL0.11==?iterDL0.12==?iterDL2.11==?iterDL2.12==?iterDL5.11==?iterDL5.12==?iterDL#?
50 41 35 41 34 44 42 46 45DL(?)
47,630 45,343 42,939 45,242 43,046 44,897 44,355 46,172 45,780DL(F) 160 156 156 153 143 158 147 163 164DL(P) 2,246 2,087 1,968 2,084 1,934 2,158 2,094 2,209 2,182DL(M) 50,218 47,768 45,244 47,659 45,304 47,395 46,777 48,724 48,306DL(D) 315,165 316,562 318,687 316,615 318,172 316,971 317,323 315,910 316,251TotalDL365,383 364,330 363,931 364,275 363,476 364,367 364,101 364,635 364,558Table 1.
DL and its individual components for baseline and the resulting cases when collapsingsignatures using our algorithm.26DL0 8.0=?randomDL0.1=?randomDL2.1=?randomDL5.1=?randomDL#?
50 41 41 44 46DL(?)
47,630 44,892 45,126 45,788 46,780DL(F) 160 201 198 187 177DL(P) 2,246 2,193 2,195 2,212 2,223DL(M) 50,218 47,468 47,700 48,369 49,362DL(D) 315,165 320,200 319,551 318,537 316,874Total DL 365,383 367,669 367,252 366,907 366,237Table 2.
DL and its individual components for baseline and theresulting cases when collapsing signatures randomly.unsupervised fashion, we take this evidence assupporting the appropriateness of our algorithm asa means of collapsing signatures in agrammatically and empirically reasonable way.We conclude that the collapsing of signatureson the basis of similarity of context vectors ofsignature transforms (in a space consisting of highfrequency words and signature transforms)provides us with a useful and significant steptowards solving the signature collapsing problem.In the context of the broader project, we will beable to use signature transforms as a more effectivemeans for projecting lexical categories in anunsupervised way.As Table 1 shows, we achieve up to 30%decrease in the number of signatures through ourproposed collapse.
We are currently exploringways to increase this value through powers of theadjacency matrix of the signature graph.In other work in progress, we explore theequally important signature purity problem ingraph theoretic terms: we split ambiguoussignature transforms into separate categories whenwe can determine that the edges connecting left-context features and right-context features can beresolved into two sets (corresponding to thedistinct categories of the transform) whose left-features have no (or little) overlap and whose rightfeatures have no (or little) overlap.
We employ thenotion of minimum cut of a weighted graph todetect this situation.ReferencesBrown, Peter F., Vincent J. Della Pietra, Peter V.deSouza, Jennifer C. Lai, and Robert L. Mercer.1992.
Class-based n-gram models of naturallanguage.
Computational Linguistics, 18(4): 467-479.Goldsmith, John.
2001.
Unsupervised learning of themorphology of a natural language.
ComputationalLinguistics, 27(2): 153-198.Higgins, Derrick.
2002.
A Multi-modular Approach toModel Selection in Statistical NLP.
University ofChicago Ph.D. thesis.Schmid, Helmut.
1994.
Probabilistic part-of-speechtagging using decision trees.. InternationalConference on New Methods in LanguageProcessingKucera, Henry and W. Nelson Francis.
1967.Computational Analysis of Present-day AmericanEnglish.
Brown University Press.Rissanen, Jorma.
1989.
Stochastic Complexity inStatistical Inquiry.
Singapore: World Scientific.Sch?tze, Hinrich.
1997.
Ambiguity Resolution inLanguage Learning.
CSLI Publications.
StanfordCA.Sparck Jones, Karen.
1973.
Index term weighting.Information Storage and Retrieval 9:619-33.Wicentowski, Richard.
2002.
Modeling and LearningMultilingual Inflectional Morphology in a MinimallySupervised Framework.
Johns Hopkins UniversityPh.D.
thesis.27
