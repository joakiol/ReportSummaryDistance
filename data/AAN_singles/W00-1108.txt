A Text Categorization Based on Summarization TechniqueSue J. KerDepartment ofComputer Science,Soochow UniversityTaipei 100, Taiwan,ksj @cis.scu.edu.twJen-Nan ChenDepartment ofManagement,Ming Chuan UniversityTaipei 111, Taiwan,jnchen@mcu.edu.twAbstractWe propose a new approach to textcategorization based upon the ideas ofsummarization.
It combines word-basedfrequency and position method to getcategorization k owledge from the title fieldonly.
Experimental results indicate thatsummarization-based categorization canachieve acceptable performance on Reutersnews corpus.IntroductionWith the current explosive growth of Interactusage, the demand for fast and useful access toonline data is increasing.
An efficientcategorization system should provide accurateinformation quickly.
There are manyapplications for text categorization, includinginformation retrieval, text routing, text filteringand text understanding systems.The text categorization systems usepredefmed categories to label new documents.Many different approaches have been applied tothis task, including nearest neighbor classifiers(Masand, Linoff and Waltz, 1992; Yang, 1994;Lain and Ho, 1998; Yang, 1999), Bayesianindependence lassifiers (Lewis and Ringuette,1994; Baker and McCallum, 1998; McCallumand Nigam, 1998), decision trees (Fuhr et al,1991; Lewis and Ringuette, 1994; Apte et al,1998), induction rule learning (Apte et al, 1994;Cohen and Singer, 1996; Mouilinier et al, 1996),neural networks (Wiener, Pedersen and Weigend,1995; Ng, Gob and Low, 1997), and supportvector machines (Joachims, 1998).
Thesecategorization algorithms have been applied tomany different subject domains, usually newsstories (Apte et al, 1994; Lewis and Ringuette,1994; Wiener, Pedersen and Weigend, 1995;Yang, 1999), but also physics abstracts (Fuhr etal., 1991), and medical texts (Yang and Chute,1994).In this research to resolve the task of textcategorization we apply a method of textsummarization, that is, combining word-basedfrequency and position method to getcategorization knowledge from the title fieldonly.
Experimental results indicate thatsummarization-based categorization can achieveacceptable performance on Reuters news corpus.Additionally, the computation time for the titlefield is very short.
Thus, this system isappropriate for online document classifier.Following is a description of the organizationof this paper.
Section 2 describes the previouswork of summarization.
Summarization-basedalgorithms for text categorization are outlined inSection 3.
The experiments we undertook toassess the performance of these algorithms arethe topic of Section 4.
Quantitativeexperimental results are also summarized.Finally, concluding remarks andrecommendation f r future work is made.1 Text SummarizationThe task of summarization is to identifyinformative vidence from a given document,which are most relevant to its content and createa shorter version of smnmary of the documentfrom this information.
The informativeevidence associated with techniques used insummarization may also provide clues for textcategorization to determine the appropriatecategory of the document.Several techniques for text summarizationhave been reported in the literature, includingmethods based on position (Edmundson, 1969;Hovy and Lin, 1997; Teufel and Moens, 1997),cue phrase (McKeown and Radev, 1995;Mahesh, 1997), word frequency (Teufel andMoens, 1997), and discourse segmentation(Boguraev and Kennedy, 1997).79Of the above approaches, both wordfrequency and position methods are easy toimplement.
In this research we combine thesetwo approaches to investigate the efforts forcategorization..
In regard to the positionmethod, Hovy and Lin (1997) considered thetitle is the most likely to bear topics.
Theyclaim words in titles are positively relevant osummarization.
Teufel and Moens (1997) alsoconfirmed this viewpoint; they mentioned thatwords in the title are good candidates fordocument specific concepts.
They showed21.7% recall and precision, when the titlemethod is used alone, with an increasedperformance of 3%, when combined with othermethods.Furthermore, from observation of the TRECevaluation during recent years, it has beenshown that there is no significant differencebetween short and long query.
It seemsreasonable to acquire informative clues from thetitle, still not degrading the categorizationperformance s verely.2 MethodsThis section describes a series of algorithmsbased on the title summarization technique fortext categorization.2.1 Preprocessing and Feature SelectionWe divide the corpus texts into words, delineateby white space and punctuation.
All charactersare lower-case and stop words are removed.After the words are stemmed, we call themterms.
These terms are then used as features.2.2 Term WeightingWeights are now assigned to the survivingfeatures in each category.
We design severaldifferent formulas for term weighting.
In eachformula, we associate a weight, W~ c), witheach surviving feature, f, in category c, in thesame way weights can be obtained ininformation retrieval when assigning them toindex terms.
In addition, we normalize thevalue of term frequency, q, between categories.The probability of category is also taken intoaccount.
We define W~ c) as equations 1through 3.W(f,  c) = tff,~ x idf/ (Eq.
l-a)Maxcwhere 0~ =T=tiT:Max,=2V~=W(f,c)=p(c)x O's., xidf s (Eq.
l-b)Max,W(f,c)=p(c)xtfI.~xidf: (Eq.
l-c)W(f, c) = ~s.,xidf/ (Eq.
l-d)T idf: = (Eq.
2) df:p(c) = N, (Eq.
3)ZN,?the frequency of the feature fappearing in the category c,the number of categories,the number of categories thatcontain the featureLthe maximum frequency of anyfeature in category c,the document numbers belongingcategory c in training sets.2.3 Category RankingWe now have an index suitable for use in thecategory ranking process.
The index containsfeatures and a weighted value, W(f, c),associated with each feature f in  each category c.Given a document, d, a rank can be associatedwith each category with respect to d. Let Fc isthe set of features,f, in category c. The rankingof category c with respect to document d, R(c, d),is defined as equation 4.R(c,d) = g ~f .axW( f ,c )  (Eq.
4)f~  Fc ~dwhere tf:~ = the frequency of the feature fappearing in the document d,F~= the set of features f in  category c.3 ExperimentsTo assess the proposed method's effectiveness,we apply the algorithms described in theprevious section and conduct a series ofexperiments.
Tests are performed on theReuters corpus.
A general description of thematerials used in these experiments follows.Finally, the success rates are quantitativelyevaluated.3.1 The Reuters CorpusTo make our effectiveness comparable to otherresearchers' results in text categorization, wechose the commonly used Reuters news storycorpus for the data.
This corpus has manydifferent versions.
Yang (1999) points out80there are at least five versions of the Reuterscorpus, depending on how the training/test etsare divided and the scope of categories ordocuments used for evaluation.
In this paper,we select the Reuters version 3 (a formattedversion is currently available at Yang'shomepage http://moscow.mt.cs.cmu.edu:8081/reuters 21450/apte), constructed by Apteet al, as our data set.This version contains 7,789 training and 3,309test documents within 93 categories.
Thedistribution of category number is tabulated inTable 1.
Most of these documents have only asingle category, but some documents aremulticategory.
The average numbers ofcategories per document are 1.23 and 1.24 ontraining and test sets, respectively.
The numberof training documents per category varies widely,from 2 (dr, fishmeal .
.
.
.
.
etc.)
to a maximum of2,877 (earn).
Tables 2 and 3 show the top tenmost frequent categories and ten least frequentcategories on the training sets.
The averagelength of title field and whole document are 7.4and 126.9 words per document, respectively.3.2 Experimental DesignIn this paper, we only use TITLE field as thescope of texts.
In our first experiment, thevariable is variant erm weighting formulas thatare described in Section 3.
We want to see theeffects on categorization performance, whenprobability of  category and normalized processof term frequency are used.
The firstexperiment is summarized in Table 4.A second experiment is to locate the mostpreferred threshold value of minimum termfrequency.
For the number of features in ourexperiment, the values 10, 20, 50, 100, 150, 200,300 and 900 are tested.3.3 Experimental Results andDiscussionWe survey the effectiveness of our algorithmsby using the conventional  1-point averageprecision (Salton and McGill, 1983; Yang1999).We first investigate a suitable term weightedformula by doing a set of initial categorizationfrom Method 1 through 4.
Threshold ofminimum term frequency is fixed at 3.
Theresults are tabulated in Table 5.
It can be seenTable 1 The distribution of category number oncorpus.Category Training sets Test setsNo.
Doe # Percentage Doe # Percentage1 6586 84.6% 2823 85.3%2 878 11.3% 347 10.5%3 188 2.4% 65 2.0%4 61 0.8% 36 1.1%5 39 0.5% 21 0.6%Above 5 37 0.5% 17 0.5%Table 2 The ten most frequent categories in thetraining sets.TopicNameDocument No.money-fxgrainTraining sets Test setsearn 2877 1176acq 1651 776538 207433 168197 388 crudetrade 369 135interest 347 150wheat 212 81198176shipcon l9264Table 3 The ten least frequent categoriestraining sets.TopicNamecomglutenfeedin theDocument No.Test sets Training sets2dr  2 1fishmeal 2 0linseed 2 0naphtha 2 4nzdlr 2 1palladium 2 1palrakemel 2 1rand 2 1woolTable 4 The choice of term-weighting formulasin the first experiment.Method Id.
1 2 3 4Formula Id.
1-a 1-b 1-c 1-dProb.
used v v ?
xMarc used v x v ?that Method 4 appears to perform well in ourmeasure.
The average ll-point evaluation canachieve 82.7% precision for Method 4 (tfxidf).81It seems to point out that" small text size (onlyTITLE field is used) is not bad for textcategorization, when compared with kNN's 93%and LLSF's 92% for full texts (Yang, 1999).The other experimental variable is the numberof chosen features.
Table 5 shows the largefeature sets earn the better result whenprobability isabsent.In the next experiment, with the termweighting formula fixed at Eq.
1-d (Method 4),we vary the minimum number of term frequencyfrom 1 to 3.
Table 6 indicates that here are nosignificant differences among judgements, butshows a little improvement for those smallthreshold values.
The data also shows that theinformation contained in the title field is almostcome together and very little noise.
Thus, itseems to have no effects for the processing ofsparse data.Table 5 The 11-point average precision scoresof the first experiment.
For theminimum term frequency, value 3 wasused.Feature Method Id.No.
1 2 3 410 71.9% 69.2% 70.1% 72.1%20 76 .3% 74.1% 73.8% 77.1%50 78.8% 77.4% 74.3% 80.2%100 80.2% 79.2% 74.5% 81.9%150 180.1% 79.8% 73.8% 82.4%200 80.2% 80.2% 73.3% 82.6%300 80.0% 80.5% 73.0% 82.6%900 79.6% 80.9% 72.2% 82.7%Table 6 The 11-point average precision scoresof Method 4.Feature # Tf>=3 Tf>=2 Tf>=l10 72.1% 72.2% 72.3%20 77.1% 77.2% 77.3%50 80.2% 80.3% 80.5%100 81.9% 82.1% 82.3%150 82.4% 82.7% 82.9%200 82.6% 82.9% 83.1%300 82.6% 82.9% 83.2%900 82.7% 83.0% 83.2%ConclusionIn this paper, we apply the most popularmethods, in text summarization, position andword frequency, to resolve the task of textcategorization.
We use a word-based termweighted technique from the title field, which isinformative but short in length, to processeategofzation.
The results show short titlefield will reduce execution time, and provideacceptable performance.
Thus, this systemwould be appropriate for an online documentclassifier.Previous work shows the hybrid approach forthe text categorization and summarization ismore efficient than a single scheme.
Thus, wewill try to combine several schemes in the future.In addition, in the position method, we could usehybrid structure to consider the title and somespecific position in the document, for instance,the first sentence in the first paragraph or thefirst sentence in the second paragraph.
Whenthere is insufficient information i title field, it ishelpful to proceed to the next position.AcknowledgementsThis research is partially supported by the ROCNSC grants 88-2213-E-031-003 and 89-2213-E-031-004.
We would like to thank the anonymousreferees for their valuable comments.
Any errorsthat remain are solely the responsibility of theauthors.ReferencesWilliam J. Hutchins (1986) Machine Translation :Past, Present, Future.
Ellis Horwood, John Wiley& Sons, Chichester, England, 382 p.Apte C., Damerau F. and Weiss S. (1994) Towardslanguage independent automated learning of textcategorization models.
In 17 ~ Annual InternationalACM SIGIR Conference on Research andDevelopment in Information Retrieval (SIGIR'94),pp.
23-30.Apte C., Darnerau F. and Weiss S. (1998) Textmining with decision roles and decisions trees.
InProceedings of the Conference on AutomatedLearning and discovery, Workshop 6: Learningfrom text and Web.Baker L.D.
and MeCallum A.K.
(1998)Distributional clustering of words for textcategorization.
I  21 a  `Annual International ACMSIGIR Conference on Research and Developmentin Information Retrieval (SIGIR "98), pp.
96.-103.Boguraev B. and Kennedy C. (1997) Salience-based content charaetefisation of text documents.In Proceedings of ACL/EACL'97 Workshop onIntelligent Scalable Text Summarization, pp.
2-9.82Cohen W.W. and Singer Y.
(1996) Context -sensitive learning methods for text categorization.In 19 ~ Annual International ACM SIGIRConference on Research and Development inInformation Retrieval (SIGIR "96), pp.
307-315.Edmundson H.P.
(1969) New methods in automaticextracting.
Journal of ACM, 16(2): 264-285.Fuhr N., Hartmarma S., Lustig G., Sehwantner M.and Tzeras K. (1991) Air/X - a rule-basedmultistage indexing systems for large subject fields.In Proceedings of RIAO'91, pp.
606-623.Hovy E. and Lin C.Y.
(1997) Automated textsummarization i SUMMARIST, In Proceedingsof ACL/EACL '97 Workshop on Intelligent ScalableText Summarization, pp.
18-24.Joaehioms Thorsten (I998) Text categorizationwith support vector machines: Learning with manyrelevant features.
In European Conference onMachine Learning (ECML ).Lain W. and Ho C.Y.
(1998) Using a generalizedinstance set for automatic text categorization.
In21 th Annual International ACM SIGIR Conferenceon Research and Development in InformationRetrieval (SIGIR "98), pp.
81-89.Lewis D.D.
and Ringuette M. (1994) Comparisonof two learning algorithms for text categorization.In proceedings of the 3 '~ Annual Symposium onDocument Analysis and Information Retrieval(SDAIR '94), pp.
81-93.Mahesh K. (1997) Hypertext summary extractionfor fast document browsing.
In Proceedings oJAAAI Spring Symposium: NLP for WWW, pp.
95-104.Masand M., Linoff G. and Waltz D. (1992)Classifying news stories using memory basedreasoning.
In 15 ~ Annual International ACMSIGIR Conference on Research and Developmentin Information Retrieval (SIGIR'92), pp.
59-64.McCallum A. and Nigam K. (1998) A comparisonof event models for Naive Bayes textcategorization.
In AAAI-98 Workshop on Learningfor Text Categorization.McKeown K. and Radev D. (1995) In 18 'h AnnualInternational A CM SIGIR Conference on Researchand Development in Information Retrieval(SIGIR '95), pp.
74-82.Mouilinier I., Raskinis G. and Ganaseia J.
(1996)Text categorization: A symbolic approach.
Inproceedings of the 5 ~ Annual Symposium onDocument Analysis and Information Retrieval(SDAIR "96).Ng, H.T., Goh W.B.
and Low K.L.
(1997) Featureselection, perceptron learning, and a usability casestudy for text categorization.
In 20 ~* AnnualInternational ACM SIGIR Conference on Researchand Development in Information Retrieval(SIGIR "97), pp.
67-73.Salton G. and McGill M.J. (1983) Introduction tomodern information retrieval.
McGraw-HillComputer Science Series.
McGraw-Hill, NewYork.Teufel S. and Moens M. (1997) Sentence xtractionas a classification task, In Proceedings oJACL/EACL'97 Workshop on Intelligent ScalableText Summarization, pp.
58-65.Wiener E., Pedersen J.O.
and Weigend A.S. (1995)A neural network approach to topic spotting.
Inproceedings of the 4 ~ Annual Symposium onDocument Analysis and Information Retrieval(SDAIR '95).Yang Y.
(1994) Expert network: Effective andefficient learning from human decision in textcategorization and retrieval.
In 17 'h AnnualInternational ACM SIGIR Conference on Researchand Development in Information Retrieval(SIGIR'94), pp.
13-22.Yang Y.
(1999) An evaluation of statisticalapproaches to text categorization, InformationRetrieval.
Vol.
1, pp.
69-90.Yang Y. and Chute C.G.
(1994) An application ofexpert network to clinical classification andMEDLINE indexing.
In Proceedings of the 18 ~Annual Symposium on Computer Applications inMedical Care, pp.
157-161.83
