Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 84?91,Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLPPhonological and Logographic Influences on Errors in WrittenChinese WordsChao-Lin Liu1 Kan-Wen Tien2 Min-Hua Lai3 Yi-Hsuan Chuang4 Shih-Hung Wu51-4National Chengchi University, 5Chaoyang University of Technology, Taiwan{1chaolin, 296753027, 395753023, 494703036}@nccu.edu.tw, 5shwu@cyut.edu.twAbstractWe analyze a collection of 3208 reported errorsof Chinese words.
Among these errors, 7.2% in-volved rarely used character, and 98.4% wereassigned common classifications of their causesby human subjects.
In particular, 80% of the er-rors observed in the writings of middle schoolstudents were related to the pronunciations and30% were related to the logographs of the words.We conducted experiments that shed light on us-ing the Web-based statistics to correct the errors,and we designed a software environment for pre-paring test items whose authors intentionally re-place correct characters with wrong ones.
Ex-perimental results show that using Web-basedstatistics can help us correct only about 75% ofthese errors.
In contrast, Web-based statistics areuseful for recommending incorrect characters forcomposing test items for ?incorrect characteridentification?
tests about 93% of the time.1 IntroductionIncorrect writings in Chinese are related to our under-standing of the cognitive process of reading Chinese(e.g., Leck et al, 1995), to our understanding of whypeople produce incorrect characters and our offeringcorresponding remedies (e.g., Law et al, 2005), andto building an environment for assisting the prepara-tion of test items for assessing students?
knowledge ofChinese characters (e.g., Liu and Lin, 2008).Chinese characters are composed of smaller partsthat can carry phonological and/or semantic informa-tion.
A Chinese word is formed by Chinese characters.For example, ???
(Singapore) is a word that con-tains three Chinese characters.
The left (?)
and theright (?)
part of ?, respectively, carry semantic andphonological information.
The semantic information,in turn, is often related to the logographs that form theChinese characters.
Evidences show that productionof incorrect characters are related to phonological,logographic, or the semantic aspect of the characters.Although the logographs of Chinese characters can berelated to the lexical semantics, not all errors that arerelated to semantics were caused by the similarity inlogographs.
Some were due to the context of thewords and/or permissible interpretations of differentwords.In this study, we investigate issues that are relatedto the phonological and logographical influences onthe occurrences of incorrect characters in Chinesewords.
In Section 2, we present the details about thesources of the reported errors.
We have collected er-rors from a published book and from a group of mid-dle school students.
In Section 3, we analyze thecauses of the observed errors.
Native speakers of Chi-nese were asked to label whether the observed errorswere related to the phonological or the logographicreasons.
In Section 4, we explore the effectiveness ofrelying on Web-based statistics to correct the errors.We submitted an incorrect word and a correct wordseparately to Google to find the number of web pagesthat contained these words.
The correct and incorrectwords differed in just the incorrect character.
We ex-amine whether the number of web pages that con-tained the words can help us find the correct way ofwriting.
In Section 5, we employ Web-based statisticsin the process of assisting teachers to prepare testitems for assessing students?
knowledge of Chinesecharacters.
Experimental results showed that ourmethod outperformed the one reported in (Liu and Lin,2008), and captured the incorrect characters betterthan 93% of the time.2 Data SourcesWe obtained data from three major sources.
A list thatcontains 5401 characters that have been believed to besufficient for everyday lives was obtained from theMinistry of Education (MOE) of Taiwan, and we callthe first list the Clist, henceforth.
The 5401 charactersform the core basis for the BIG-5 code, and an officialintroduction of these 5401 characters is available athttp://www.cns11643.gov.tw/AIDB/encodings.do#encode4.We have two lists of words, and each word is ac-companied by an incorrect way to write the word.
Thefirst list is from a book published by MOE (1996).The MOE provided the correct words and specifiedthe incorrect characters which were mistakenly usedto replace the correct characters in the correct words.The second list was collected, in 2008, from the writ-ten essays of students of the seventh and the eighthgrades in a middle school in Taipei.
The incorrectcharacters were entered into computers based on stu-dents?
writings, ignoring those characters that did notactually exist and could not be entered.We will call the first list of word the Elist, and thesecond the Jlist from now on.
Elist and Jlist contain,respectively, 1490 and 1718 entries.
Each of theseentries contains a correct word and the incorrect char-acter.
Hence, we can reconstruct the incorrect words84easily.
Two or more different ways to incorrectlywrite the same words were listed in different entriesand considered as two entries for simplicity of presen-tation.3 Error Analysis of Written WordsTwo human subjects, who are native speakers of Chi-nese and are graduate students in Computer Science,examined Elist and Jlist and categorized the causes oferrors.
They compared the incorrect characters withthe correct characters to determine whether the errorswere pronunciation-related or logographs-related.Referring to an error as being ?semantics-related?
isambiguous.
Two characters might not contain thesame semantic part, but are still semantically related,e.g., misusing ???
(tou1) for ???
(tou2) in ??????.
In this study, we have not considered this factor.For this reason we refer to the errors that are related tothe sharing of logographic parts in characters as com-position-related.Among the 1490 and 1718 words in Elist and Jlist,respectively, the two human subjects had consensusover causes of 1441 and 1583 errors.
It is interestingto learn that native speakers had a high consensusabout the causes for the observed errors, but they didnot always agree.
To have a common standard incomparison, we studied the errors that the two sub-jects had agreed categorizations.The statistics changed when we disregarded errorsthat involved characters not included in Clist.
An er-ror would be ignored if either the correct or the incor-rect character did not belong to the Clist.
It is possiblefor students to write such rarely used characters in anincorrect word just by coincidence.After ignoring the rare characters, there were 1333and 1645 words in Elist and Jlist, respectively.
Thesubjects had consensus over the causes of errors for1285 and 1515 errors in Elist and Jlist, respectively.Table 1 shows the percentages of five categories oferrors: C for the composition-related errors, P for thepronunciation-related errors, C&P for the intersectionof C and P, NE for those errors that belonged to nei-ther C nor P, and D for those errors that the subjectsdisagreed on the error categories.
There were, respec-tively, 505 composition-related and 1314 pronuncia-tion-related errors in Jlist, so we see505/1645=30.70% and 1314/1645=79.88% in thetable.
Notice that C&P represents the intersection ofC and P, so we have to deduct C&P from the sum ofC, P, NE, and D to find the total probability, namely 1.It is worthwhile to discuss the implication of thestatistics in Table 1.
For the Jlist, similarity betweenpronunciations accounted for nearly 80% of the errors,and the ratio for the errors that are related to composi-tions and pronunciations is 1:2.6.
In contrast, for theElist, the corresponding ratio is almost 1:1.
The Jlistand Elist differed significantly in the ratios of the er-ror types.
It was assumed that the dominance of pro-nunciation-related errors in electronic documents wasa result of the popularity of entering Chinese withpronunciation-based methods.
The ratio for the Jlistchallenges this popular belief, and indicates that eventhough the errors occurred during a writing process,rather than typing on computers, students still pro-duced more pronunciation-related errors than compo-sition-related errors.
Distribution over error types isnot as related to input method as one may have be-lieved.
Nevertheless, the observation might still be aresult of students being so used to entering Chinesetext with pronunciation-based method that the organi-zation of their mental lexicons is also pronunciationrelated.
The ratio for the Elist suggests that editors ofthe MOE book may have chosen the examples with aspecial viewpoint in their minds ?
balancing pronun-ciation and composition related errors.4 Reliability of Web-based StatisticsIn this section, we examine the effectiveness of usingWeb-based statistics to differentiate correct and incor-rect characters.
The abundant text material on theInternet gives people to treat the Web as a corpus (e.g.,webascorpus.org).
When we send a query to Google,we will be informed of the number of pages (NOPs)that possibly contain relevant information.
If we putthe query terms in quotation marks, we should findthe web pages that literally contain the query terms.Hence, it is possible for us to compare the NOPs fortwo competing phrases for guessing the correct wayof writing.
At the time of this writing, Google found107000 and 3220 pages, respectively, for ?strong tea?and ?powerful tea?.
(When conducting such advancedsearches with Google, the quotation marks are neededto ensure the adjacency of individual words.)
Hence,?strong?
appears to be a better choice to go with ?tea?.This is an idea similar to the approach that computecollocations based on word frequencies (cf.
Manningand Sch?tze, 1999).
Although the idea may not workvery well for small database, the size of the currentWeb should be considered large enough.Using the quotation marks for the query terms en-forced the influences of the surrounding characters inChinese words, and provides a better clue for judgingcorrect usage of Chinese characters.
For instance,without the context, ???
and ???
might be usedincorrectly to replace each other because they havethe same pronunciation, i.e., Mei3.
It is relativelyunlikely for one to replace ???
with ???
when wewrite ????
(every one), but these two characters canbecome admissible candidates when we write ????
(USA) and ????
(every country).Table 1.
Error analysis for Elist and JlistC P C&P NE DElist 66.09% 67.21% 37.13% 0.23% 3.60%Jlist 30.70% 79.88% 20.91% 2.43% 7.90%854.1 Field TestsWe test this strategy by sending the words in Elist andJlist to Google to find the NOPs.
We can retrieve theNOPs from the documents returned by Google, andcompare the NOPs for the correct and the incorrectwords to evaluate the strategy.
Again, we focused onthose in the 5401 words that the human subjects hadconsensus about their error types.
Recall that we have1285 and 1515 such words in Elist and Jlist, respec-tively.
As the information available on the Webchanges all the time, we also have to note that ourexperiments were conducted during the first half ofMarch 2009.
The queries were submitted at reason-able time intervals to avoid Google?s treating our pro-grams as malicious attackers.Table 2 shows the results of our investigation.
Weconsidered that we had a correct result when we foundthat the NOP for the correct word was larger than theNOP for the incorrect word.
If the NOPs were equal,we recorded an ambiguous result; and when the NOPfor the incorrect word was larger, we recorded an in-correct event.
We use ?C?, ?A?, and ?I?
to denote ?cor-rect?, ?ambiguous?, and ?incorrect?
events in Table 2.The column headings of Table 2 show the settingof the searches with Google and the set of words thatwere used in the experiments.
We asked Google tolook for information from web pages that were en-coded in traditional Chinese (denoted Trad).
Wecould add another restriction on the source of infor-mation by asking Google to inspect web pages frommachines in Taiwan (denoted Twn+Trad).
We werenot sure how Google determined the languages andlocations of the information sources, but chose to trustGoogle.
The headings ?Comp?
and ?Pron?
indicatewhether the words whose error types were composi-tion and pronunciation-related, respectively.Table 2 shows eight distributions, providing ex-perimental results that we observed under differentsettings.
The distribution printed in bold face showedthat, when we gathered information from sources thatwere encoded in traditional Chinese, we found thecorrect words 73.12% of the time for words whoseerror types were related to composition in Elist.
Underthe same experimental setting, we could not judge thecorrect word 4.58% of the time, and would have cho-sen an incorrect word 22.30% of the time.Statistics in Table 2 indicate that web statistics isnot a very reliable factor to judge the correct words.The average of the eight numbers in the ?C?
rows isonly 71.54% and the best sample is 76.59%, suggest-ing that we did not find the correct words frequently.We would made incorrect judgments 24.75% of thetime.
The statistics also show that it is almost equallydifficult to find correct words for errors that are com-position and pronunciation related.
In addition, thestatistics reveal that choosing more features in theadvanced search affected the final results.
Using?Trad?
offered better results in our experiments thanusing ?Twn+Trad?.
This observation may arouse aperhaps controversial argument.
Although Taiwan isthe main area to use traditional Chinese, their webpages might not have used as accurate Chinese as webpages located in other regions.4.2 An Error Analysis for the Field TestsWe have analyzed the reasons for why using Web-based statistics did not always find the correct words.Frequencies might not have been a good factor to de-termine the correctness of Chinese.
However, themyriad amount of data on the Web should have pro-vided a better performance.The most common reason for errors is that some ofthe words are really confusing such that the majorityof the Web pages actually used the incorrect words.Some of errors were so popular that even one of theChinese input methods on Windows XP offeredwrong words as possible choices, e.g., ?????
(thecorrect one) vs.
?????.
It is interesting to note thatpeople may intentionally use incorrect words in someoccasions; for instance, people may choose to writehomophones in advertisements.Another popular reason is that whether a word iscorrect depends on a larger context.
For instance, ????
is more popular than ????
because the formeris a popular nickname.
Unless we had provided morecontextual information about the queried words,checking only the NOPs of ????
and ????
led usto choose ???
?, which happened to be an incorrectword when we meant to find the right way to write????.
Another difficult pair of words to distinguishis ????
and ???
?.Yet another reason for having a large NOP of theincorrect words was due to errors in segmenting Chi-nese character strings.
Consider a correct characterstring ?WXYZ?, where ?WX?
and ?YZ?
are two cor-rect words.
It is possible that ?XY?
happens to be anincorrect way to write a correct word.
This is the casefor having the counts for ??????
to contribute tothe count for ????
which is an incorrect form of???
?.5 Facilitating Test Item AuthoringIncorrect character correction is a very popular type oftest in Taiwan.
There are simple test items for youngchildren, and there are very challenging test items forthe competitions among adults.
Finding an attractiveincorrect character to replace a correct character toform a test item is a key step in authoring test items.Table 2.
Reliability of Web-based statisticsTrad Twn+TradComp Pron Comp PronC 73.12% 73.80% 69.92% 68.72%A 4.58% 3.76% 3.83% 3.76%ElistI 22.30% 22.44% 26.25% 27.52%C 76.59% 74.98% 69.34% 65.87%A 2.26% 3.97% 2.47% 5.01%JlistI 21.15% 21.05% 28.19% 29.12%86We have been trying to build a software environ-ment for assisting the authoring of test items for in-correct character correction (Liu and Lin, 2008, Liu etal., 2009).
It should be easy to find a lexicon that con-tains pronunciation information about Chinese charac-ters.
In contrast, it might not be easy to find visuallysimilar Chinese characters with computational meth-ods.
We expanded the original Cangjie codes (OCC),and employed the expanded Cangjie codes (ECC) tofind visually similar characters (Liu and Lin, 2008).Cangjie encoding (Chu, 2009) is a special systemfor representing the formation of Chinese characterswith a sequence of at most five basic symbols.
Forinstance, ???
and ???
are represented by ??????
and ?????
?, respectively.
It is evident thatthe Cangjie codes are useful for finding visually simi-lar characters.With a lexicon, we can find characters that can bepronounced in a particular way.
However, this is notenough for our goal.
We observed that there weredifferent symptoms when people used incorrect char-acters that are related to their pronunciations.
Theymay use characters that could be pronounced exactlythe same as the correct characters.
They may also usecharacters that have the same pronunciation and dif-ferent tones with the correct character.
Although rela-tively infrequently, people may use characters whosepronunciations are similar to but different from thepronunciation of the correct character.We reported that replacing OCCs with ECCs tofind visually similar characters could increase thechances to find similar characters.
Instead of saving??????
for ???
directly, we divide a Chinesecharacter into subareas systematically, and save theCangjie codes for each of the subareas.
A Chinesecharacter is stored with the information about how itis divided into subareas and the Cangjie sequences foreach of its subareas.
The internal code for how wedivide ???
is 2, and the ECC for ???
has two parts:???
and ?????.
Yet, it was not clear as to whichcomponents of a character should use ECCs (Liu andLin, 2008; Liu et al, 2009).5.1 Formalizing the Extended Cangjie CodesWe analyzed the OCCs for all the characters in Clistto determine the list of basic components, with com-puter programs.
We treated a basic Cangjie symbol asif it was a word, and computed the number of occur-rences of n-grams based on the OCCs of the charac-ters in Clist.
Since the OCC for a character contains atmost five symbols, the longest n-grams are 5-grams.Because the reason to use ECCs was to find commoncomponents in characters, we saved n-grams that re-peated no less than three times in a list.
After obtain-ing this initial list of n-grams, we removed those n-grams that were substrings of longer n-grams in thelist.In addition, the n-grams that appeared no less thanthree times might not represent an actual part in anyChinese characters.
This may happen by chance be-cause we considered only frequencies of n-gramswhen we generated the initial list at the previous step.For instance, the OCC codes for ???
(shai4), ???
(wu4), and ???
(chen2) are ?????
?, ?????
?,and ?????
?, respectively.
Although the substring?????
appears three times, it does represent anactual part of Chinese characters.
Hence, we manuallyexamined all of the n-grams in the initial list, and re-moved such n-grams from the list.In addition to considering the frequencies of n-grams formed by the basic Cangjie codes to determinethe list of components, we also took advantage ofradicals that are used to categorize Chinese charactersin typical printed dictionaries.
Radicals that are stand-alone Chinese words were included in the list of com-ponents.After selecting the list of basic components withthe above procedure, we encoded the words in Elistwith these basic components.
We inherited the 12ways reported in a previous work (Liu and Lin, 2008)to decompose Chinese characters.
There are othermethods for decomposing Chinese characters intocomponents.
Juang et al (2005) and their team at theSinica Academia propose 13 different ways for de-composing characters.At the same time when we annotated individualcharacters with their ECCs, we may revise the list ofbasic components.
If a character that actually con-tained an intuitively ?common?
part and that part hadnot been included in the list of basic component, wewould add this part into the list to make it a basiccomponent and revised the ECC for all charactersaccordingly.
The judgment of being ?common?
issubjective, but we still maintained the rule that suchcommon parts must appear in more than three charac-ters.
When defining the basic components, not alljudgments are completely objectively yet, and this isalso the case of defining the original Cangjie codes.We tried to be as systematic as possible, but intuitionsometimes stepped in.We repeated the procedure described in the preced-ing paragraph five times to make sure that we weresatisfied with the ECCs for all of the 5401 characters.The current list contains 794 components, and we canrevise the list of basic components in our work when-ever necessary.5.2 Recommending Incorrect AlternativesWith the pronunciation of Chinese characters in adictionary and with our ECC encodings for words inthe Elist, we can create lists of candidate charactersfor replacing a specific correct character in a givenword to create a test item for incorrect character cor-rection.There are multiple strategies to create the candidatelists.
We may propose the candidate characters be-cause their pronunciations have the same sound andthe same tone with those of the correct character (de-noted SSST).
Characters that have same sounds and87different tones (SSDT), characters that have similarsounds and same tones (MSST), and characters thathave similar sounds and different tones (MSDT) canbe considered as candidates as well.
It is easy to judgewhether two Chinese characters have the same tone.In contrast, it is not trivial to define ?similar?
sound.We adopted the list of similar sounds that was pro-vided by a psycholinguistic researcher (Dr. Chia-YingLee) at the Sinica Academia.
???
(po) and ???
(bo)and ???
(fan4) and ???
(huan4) are pairs that havesimilar sounds.
It was observed that these are fourpossible reasons that people used incorrect charactersin writing.Because a Chinese character might be pronouncedin multiple ways, character lists generated based onthese strategies may include the same characters.More specifically, the lists SSST and SSDT may over-lap when a character that can be pronounced in multi-ple ways, and these pronunciations share the samesound and have different tones.
The characters ??
?and ???
are such examples.
???
can be pronouncedas ?dai1?
or ?dai4?, and ???
can be pronounced as?hao3?
or ?hao4?.
Hence, characters that can be pro-nounced as ?hao3?
will be listed in both SSST andSSDT for ??
?.In addition, we may propose characters that looksimilar to the correct character.
Two characters maylook similar for many reasons (Liu et al, 2009).
Themost common reason is that they contain the samecomponents, and the other is that they belong to thesame radical category and have the same total numberof strokes (RS), e.g., the pairs ???
and ??
?, ??
?and ??
?, and ???
and ???.
When two characterscontain the same component, the shared componentmight or might not locate at the same position, e.g.,???
and ??
?.In an authoring tool, we could recommend a se-lected number of candidate characters for replacingthe correct character.
We tried two different strategiesto compare and choose the visually similar characters.The similarity is computed based on the number andthe locations of shared Cangjie symbols in the ECCsof the characters.
The first strategy (denoted SC1)gave a higher score to the shared component that lo-cated at the same location in the two characters beingcompared.
The second strategy (SC2) gave the samescore to any shared component even if the componentdid not reside at the same location in the characters.The characters ??
?, ??
?, and ???
share the samecomponent ???.
When computing the similarity be-tween these characters with SC1, the contribution of???
will be the same for any pair.
When computingwith SC2, the contribution of ???
will be larger forthe pair ???
and ???
than for the pair ???
and ??
?.In the former case, ???
appears at the same locationin the characters.When there were more than 20 characters that re-ceive nonzero scores in the SC1 and SC2 categories,we chose to select at most 20 characters that had lead-ing scores as the list of recommended characters.We had to set a bound on the number of candidatecharacters, i.e., 20, for strategies SC1 and SC2.
Thenumber of candidates generated from these twostrategies can be large and artificial, depending on ourscoring functions for determining similarities betweencharacters.
We did not limit the sizes of candidatelists that were generated by other strategies becausethose lists were created based on more objectivemethods.
The rules for determining ?similar?
soundswere given by the domain experts, so we consideredthe rules objective in this research.For the experiments that we reported in the follow-ing subsection, we submitted more than 300 thousandof queries to Google.
As we mentioned in Section 4.1,a frequent continual submission of queries to Googlewill make Google treat our programs as maliciousprocesses.
(We are studying the Google API for amore civilized solution.)
Without the bound, it is pos-sible to offer a very long list of candidates.
On theother hand, it is also possible that our program doesnot find any visually similar characters for some spe-cial characters, and this is considered a possible phe-nomenon.5.3 Evaluating the RecommendationsWe examined the usefulness of these seven categoriesof candidates with errors in Elist and Jlist.
The firstset of evaluation (the inclusion tests) checked whetherthe lists of recommended characters contained theincorrect character in our records.
The second set ofevaluation (the ranking tests) was designed for practi-cal application in computer assisted item generation.Only for those words whose actual incorrect charac-ters were included in the recommended list, we re-placed the correct characters in the words with thecandidate incorrect characters, submitted the incorrectwords to Google, and ordered the candidate charactersbased on their NOPs.
We then recorded the ranks ofthe incorrect characters among all recommendedcharacters.Since the same character may appear simultane-ously in SC1, SC2, and RS, we computed the union ofthese three sets, and checked whether the incorrectcharacters were in the union.
The inclusion rate islisted under Comp, representing the inclusion ratewhen we consider only logographic influences.
Simi-larly, we computed the union for SSST, SSDT, MSST,and MSDT, checked whether the incorrect characterswere in the union, and recorded the inclusion rateunder Pron, representing the inclusion rate when weconsider only phonological influences.
Finally, wecomputed the union of the lists created by the sevenstrategies, and recorded the inclusion rate under Both.The second and the third rows of Table 3 show theresults of the inclusion tests when we recommendedcandidate characters with the methods indicated in thecolumn headings.
The data show the percentage of theincorrect characters being included in the lists that88were recommended by the seven strategies.
Noticethat the percentages were calculated with differentdenominators.
The number of composition-relatederrors was used for SC1, SC2, RS, and Comp (e.g.,505 that we mentioned in Section 3 for Jlist); thenumber of pronunciation-related errors for SSST,SSDT, MSST, MSDT, and Pron (e.g., 1314 mentionedin Section 3 for the Jlist); the number of either ofthese two  types of errors for Both (e.g., 1475 for Jlist).The results recorded in Table 3 show that we wereable to find the incorrect character quite effectively,achieving better than 93% for both Elist and Jlist.
Thestatistics also show that it is easier to find incorrectcharacters that were used for pronunciation-relatedproblems.
Most of the pronunciation-related problemswere misuses of homophones.
Unexpected confusions,e.g., those related to pronunciations in Chinese dia-lects, were the main reason for the failure to capturethe pronunciation-related errors.
(Namely, few pro-nunciation-related errors were not considered in theinformation that the psycholinguist provided.)
SSDTis a crucial complement to SSST.There is still room to improve our methods to findconfusing characters based on their compositions.
Weinspected the list generated by SC1 and SC2, andfound that, although SC2 outperformed SC1 on theinclusion rate, SC1 and SC2 actually generated com-plementary lists in many cases, and should be usedtogether.
The inclusion rate achieved by the RS strat-egy was surprisingly high.
We found that many of theerrors that were captured by the RS strategy were alsocaptured by the SSST strategy.The fourth and the fifth rows of Table 3 show theeffectiveness of relying on Google to rank the candi-date characters for recommending an incorrect charac-ter.
The rows show the average ranks of the includedcases.
The statistics show that, with the help ofGoogle, we were able to put the incorrect character ontop of the recommended list when the incorrect char-acter was included.
This allows us to build an envi-ronment for assisting human teachers to efficientlyprepare test items for incorrect character identification.Note that we did not provide data for all columnsin the fourth and the firth rows.
Unlike that we showthe inclusion rates in the second and the third rows,the fourth and the fifth rows show how the actual in-correct characters were ranked in the recommendedlists.
Hence, we need to have a policy to order thecharacters of different lists to find the ranks of theincorrect characters in the integrated list.However, integrating the lists is not necessary andcan be considered confusing to the teachers.
The se-lection of incorrect characters from different lists isrelated to the goals of the assessment, and it is betterto leave the lists separated for the teachers to choose.The same phenomenon and explanation apply to thesixth and the seventh rows as well.The sixth and the seventh rows show the averagenumbers of candidate characters proposed by differentmethods.
Statistics shown between the second and thefifth rows are related to the recall rates (cf.
Manningand Sch?tz, 1999) achieved by our system.
For thesefour rows, we calculated how well the recommendedlists contained the reported errors and how the actualincorrect characters ranked in the recommended lists.The sixth and the seventh rows showed the costs forthese achievements, measured by the number of rec-ommended characters.
The sum of the sixth and theseventh rows, i.e., 103.59 and 108.75, are, respec-tively, the average numbers of candidate charactersthat our system recommended as possible errors re-corded in Elist and Jlist.
(Note that some of thesecharacters were repeated.
)There are two ways to interpret the statistics shownin the sixth and the seventh rows.
Comparing the cor-responding numbers on the fourth and the sixth rows,e.g., 3.25 and 19.27, show the effectiveness of usingthe NOPs to rank the candidate characters.
The ranksof the actual errors were placed at very high places,considering the number of the originally recom-mended lists.
The other way to use the statistics in thesixth and the seventh rows is to compute the averageprecision.
For instance, we recommended an average19.13 characters in SSST to achieve the 91.64 inclu-sion rate.
The recall rate is very high, but the averagedprecision is very low.
This, however, is not a veryconvincing interpretation of the results.
Having as-sumed that there was only one best candidate as in ourexperiments, it was hard to achieve high precisionrates.
The recall rates are more important than theprecision rates, particularly when we have proved thatthe actual errors were ranked among the top five al-ternatives.When designing a system for assisting the author-ing of test items, it is not really necessary to proposeall of the characters in the categories.
In the reportedexperiments, choosing the top 5 or top 10 candidateswill contain the most of the actual incorrect charactersbased on the statistics shown in the fourth and thefifth rows.
Hence the precision rates can be signifi-cantly increased practically.
We do not have to mergethe candidate characters among different categoriesTable 3.
Incorrect characters were contained and ranked high in the recommended listsSC1 SC2 RS SSST SSDT MSST MSDT Comp Pron BothElist 73.92% 76.08% 4.08% 91.64% 18.39% 3.01% 1.67% 81.97% 99.00% 93.37%Jlist 67.52% 74.65% 6.14% 92.16% 20.24% 4.19% 3.58% 77.62% 99.32% 97.29%Elist 3.25 2.91 1.89 2.30 1.85 2.00 1.58Jlist 2.82 2.64 2.19 3.72 2.24 2.77 1.16Elist 19.27 17.39 11.34 19.13 8.29 19.02 9.15Jlist 17.58 16.24 12.52 22.85 9.75 22.11 7.6889because choosing the categories of incorrect charac-ters depends on the purpose of the assessment.
Reduc-ing the length of the candidate list increases thechances of reducing the recall rates.
Achieving thebest trade off between precision and recall rates relieson a more complete set of experiments that involvehuman subjects.Furthermore, in a more realistic situation, there canbe more than one ?good?
incorrect character, not justone and only gold standard as in the reported experi-ments.
It is therefore more reasonable the compute theprecision rates based the percentage of ?acceptable?incorrect characters.
Hence, the precision rates arelikely to increase and become less disconcerting.We reported experimental results in which weasked 20 human subjects to choose an incorrect char-acter for 20 test items (Liu et al, 2009).
The best so-lutions were provided by a book.
The recommenda-tions provided by our previous system and chosen bythe human subjects achieved comparable qualities.Notice that the numbers do not directly show theactual number of queries that we had to submit toGoogle to receive the NOPs for ranking the characters.Because the lists might contain the same characters,the sum of the rows showed just the maximum num-ber of queries that we submitted.
Nevertheless, theystill served as good estimations, and we actually sub-mitted 103.59?1441(=149273) and 108.75?1583(=172151) queries to Google for Elist and Jlist in ex-periments from which we obtained the data shown inthe fourth and the fifth rows.
These quantities ex-plained why we had to be cautious about how wesubmitted queries to Google.
When we run our pro-gram for just a limited number of characters, the prob-lems caused by intensive queries should not be veryserious.5.4 DiscussionsDividing characters into subareas proved to be crucialin our experiments (Liu and Lin, 2008; Liu et al,2009), but this strategy is not perfect, and could notsolve all of the problems.
The way we divided Chi-nese characters into subareas like (Juang et al, 2005;Liu and Lin, 2008) sometimes contributed to the fail-ure of our current implementation to capture all of theerrors that were related to the composition of thewords.
The most eminent reason is that how we di-vide characters into areas.
Liu and Lin (2008) fol-lowed the division of Cangjie (Chu, 2009), and Juanget al (2005) proposed an addition way to split thecharacters.The best divisions of characters appear to dependon the purpose of the applications.
Recall that eachpart of the character is represented by a string ofCangjie codes in ECCs.
The separation of Cangjiecodes in ECCs was instrumental to find the similarityof ???
and ???
because ???
is a standalone subpartin both ???
and ???.
The Cangjie system has a setof special rules to divide Chinese characters (Chu,2009; Lee, 2008).
Take ???
and ???
for example.The component ???
is recorded as an standalone partin ??
?, but is divided into two parts in ???.
Hence,???
is stored as one string, ????
?, in ???
and astwo strings, ????
and ??
?, in ???.
The differentways of saving ???
in two different words made itharder to find the similarity between ???
and ??
?.An operation of concatenation is in need, but theproblems are that it is not obvious to tell when theconcatenation operations are useful and which of theparts should be rejoined.
Hence, using the currentmethods to divide Chinese characters, it is easy tofind the similar between ???
and ???
but difficult tofind the similar between ???
and ???.
In contrast, ifwe enforce a rule to save ???
as one string of Cang-jie code, it will turn the situations around.
Determin-ing the similarity between ???
and ???
will be moredifficult than finding the similarity between ???
and??
?.Due to this observation, we have come to believethat it is better to save the Chinese characters withmore detailed ECCs.
By saving all detailed informa-tion about a character, our system can offer candidatecharacters based on users?
preferences which can beprovided via a good user interface.
This flexibility canbe very helpful when we are preparing text materialsfor experiments for psycholinguistics or cognitivesciences (e.g., Leck et al 1995; Yeh and Li, 2002).6 SummaryThe analysis of the 1718 errors produced by real stu-dents show that similarity between pronunciations ofcompeting characters contributed most to the ob-served errors.
Evidences show that the Web statisticsare not very reliable for differentiating correct andincorrect characters.
In contrast, the Web statistics aregood for comparing the attractiveness of incorrectcharacters for computer assisted item authoring.AcknowledgmentsThis research was supported in part by the NationalScience Council of Taiwan under grant NSC-97-2221-E-004-007-MY2.
We thank anonymous review-ers for their invaluable comments.ReferencesB.-F. Chu.
2009.
Handbook of the Fifth Generation ofthe Cangjie Input Method, available athttp://www.cbflabs.com/book/ocj5/ocj5/index.html.Last visited on 30 April 2009.D.
Juang, J.-H. Wang, C.-Y.
Lai, C.-C. Hsieh, L.-F.Chien, J.-M. Ho.
2005.
Resolving the unencodedcharacter problem for Chinese digital libraries,Proc.
of the 5th ACM/IEEE Joint Conf.
on DigitalLibraries, 311?319.S.-P. Law, W. Wong, K. M. Y. Chiu.
2005.
Whole-word phonological representations of disyllabic90words in the Chinese lexicon: Data from acquireddyslexia, Behavioural Neurology, 16, 169?177.K.
J. Leck, B. S. Weekes, M. J. Chen.
1995.
Visualand phonological pathways to the lexicon: Evi-dence from Chinese readers, Memory & Cognition,23(4), 468?476.H.
Lee.
2008.
Cangjie Input Methods in 30 Days,http://input.foruto.com/cjdict/Search_1.php, ForutoCompany, Hong Kong.
Last visited on 30 April2009.C.-L. Liu, K.-W. Tien, Y.-H. Chuang, C.-B.
Huang,J.-Y.
Weng.
2009.
Two applications of lexical in-formation to computer-assisted item authoring forelementary Chinese, Proc.
of the 22nd Int?l Conf.on Industrial Engineering & Other Applications ofApplied Intelligent Systems, 470?480.C.-L. Liu, J.-H. Lin.
2008.
Using structural informa-tion for identifying similar Chinese characters,Proc.
of the 46th ACL, short papers, 93?96.C.
D. Manning, H. Sch?tze.
Foundations of StatisticalNatural Language Processing.
The MIT Press.1999.MOE.
1996.
Common Errors in Chinese Writings (??????
), Ministry of Education, Taiwan.S.-L. Yeh, J.-L. Li.
2002.
Role of structure and com-ponent in judgments of visual similarity of Chinesecharacters, Journal of Experimental Psychology:Human Perception and Performance, 28(4), 933?947.91
