Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 267?275,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsFast Query for Large TreebanksSumukh Ghodke?
?Department of Computer Scienceand Software Engineering,University of MelbourneVictoria 3010, AustraliaSteven Bird??
?Linguistic Data Consortium,University of Pennsylvania3600 Market Street, Suite 810Philadelphia PA 19104, USAAbstractA variety of query systems have been devel-oped for interrogating parsed corpora, or tree-banks.
With the arrival of efficient, wide-coverage parsers, it is feasible to create verylarge databases of trees.
However, existing ap-proaches that use in-memory search, or rela-tional or XML database technologies, do notscale up.
We describe a method for storage,indexing, and query of treebanks that uses aninformation retrieval engine.
Several experi-ments with a large treebank demonstrate ex-cellent scaling characteristics for a wide rangeof query types.
This work facilitates the cu-ration of much larger treebanks, and enablesthem to be used effectively in a variety of sci-entific and engineering tasks.1 IntroductionThe problem of representing and querying linguisticannotations has been an active area of research forseveral years.
Much of the work has grown fromefforts to curate large databases of annotated textsuch as treebanks, for use in developing and testinglanguage technologies (Marcus et al, 1993; Abeille?,2003; Hockenmaier and Steedman, 2007).
At leasta dozen linguistic tree query languages have beendeveloped for interrogating treebanks (see ?2).While high quality syntactic parsers are able toefficiently annotate large quantities of English text(Clark and Curran, 2007), existing approaches toquery do not work on the same scale.
Many exist-ing systems load the entire corpus into memory andcheck a user-supplied query against every tree.
Oth-ers avoid the memory limitation, and use relationalor XML database systems.
Although these havebuilt-in support for indexes, they do not scale up ei-ther (Ghodke and Bird, 2008; Zhang et al, 2001)).The ability to interrogate large collections ofparsed text has important practical applications.First, it opens the way to a new kind of informationretrieval (IR) that is sensitive to syntactic informa-tion, permitting users to do more focussed search.At the simplest level, an ambiguous query term likewind or park could be disambiguated with the helpof a POS tag (e.g.
wind/N, park/V).
(Existing IRengines already support query with part-of-speechtags (Chowdhury and McCabe, 1998)).
More com-plex queries could stipulate the syntactic category ofapple is in subject position.A second benefit of large scale tree query is fornatural language processing.
For example, we mightcompute the likelihood that a given noun appears asthe agent or patient of a verb, as a measure of an-imacy.
We can use features derived from syntactictrees in order to support semantic role labeling, lan-guage modeling, and information extraction (Chenand Rambow, 2003; Collins et al, 2005; Hakenberget al, 2009).
A further benefit for natural languageprocessing, though not yet realized, is for a treebankand query engine to provide the underlying storageand retrieval for a variety of linguistic applications.Just as a relational database is present in most busi-ness applications, providing reliable and efficient ac-cess to relational data, such a system would act as arepository of annotated texts, and expose an expres-sive API to client applications.A third benefit of large scale tree query is tosupport syntactic investigations, e.g.
for develop-267ing syntactic theories or preparing materials for lan-guage learners.
Published treebanks will usually notattest particular words in the context of some in-frequent construction, to the detriment of syntacticstudies that make predictions about such combina-tions, and language learners wanting to see instancesof some construction involving words from somespecialized topic.
A much larger treebank allevi-ates these problems.
To improve recall performance,multiple parses for a given sentence could be stored(possibly derived from different parsers).A fourth benefit for large scale tree query is tosupport the curation of treebanks, a major enter-prise in its own right (Abeille?, 2003).
Manual selec-tion and correction of automatically generated parsetrees is a substantial part of the task of preparing atreebank.
At the point of making such decisions, itis often helpful for an annotator to view existing an-notations of a given construction which have alreadybeen manually validated (Hiroshi et al, 2005).
Oc-casionally, an earlier annotation decision may needto be reconsidered in the light of new examples,leading to further queries and to corrections that arespread across the whole corpus (Wallis, 2003; Xueet al, 2005).This paper explores a new methods for scaling uptree query using an IR engine.
In ?2 we describe ex-isting tree query systems, elaborating on the designdecisions, and on key aspects of their implementa-tion and performance.
In ?3 we describe a methodfor indexing trees using an IR engine, and discussthe details of our open source implementation.
In?4 we report results from a variety of experimentsinvolving two data collections.
The first collectioncontains of 5.5 million parsed trees, two orders ofmagnitude larger than those used by existing treequery systems, while the second collection contains26.5 million trees.2 Treebank QueryA tree query system needs to be able to identify treeshaving particular properties.
On the face of it, thisshould be possible to achieve by writing simple pro-grams over treebank files on disk.
The programswould match tree structures using regular expressionpatterns, possibly augmented with syntax for match-ing tree structure.
However, tree query is a morecomplex and interesting task, due to several factorswhich we list below.Structure of the data: There are many varietiesof treebank.
Some extend the nested bracketingsyntax to store morphological information.
Oth-ers store complex attribute-value matrices in treenodes or have tree-valued attributes (Oepen et al,2002), or store dependency structures ( ?Cmejrek etal., 2004), or categorial grammar derivations (Hock-enmaier and Steedman, 2007).
Others store multipleoverlapping trees (Cassidy and Harrington, 2001;Heid et al, 2004; Volk et al, 2007).Form of results: Do we want entire trees, ormatching subtrees, or just a count of the number ofresults?
Do we need some indication of why thequery matched a particular tree, perhaps by show-ing how query terms relate to a hit, cf.
documentsnippets and highlighted words in web search re-sults?
Do we want to see multiple hits when a querymatches a particular tree in more than one place?Do we want to see tree diagrams, or some machine-readable tree representation that can be used in ex-ternal analysis?
Can a query serve to update the tree-bank, cf.
SQL update queries?Number of results: Do we want all results, or thefirst n results in document order, or the ?best?
n re-sults, where our notion of best might be based onrepresentativeness or distinctiveness.Description language: Do we prefer to describetrees by giving examples of tree fragments, replac-ing some nodes replaced with wildcards (Hiroshi etal., 2005; Ichikawa et al, 2006; M?
?rovsky?, 2006)?Or do we prefer a path language (Rohde, 2005; Laiand Bird, 2010)?
Or perhaps we prefer a languageinvolving variables, quantifiers, boolean operators,and negation (Ko?nig and Lezius, 2001; Kepser,2003; Pajas and ?Ste?pa?nek, 2009)?
What built-intree relations are required, beyond the typical par-ent/child, ancestor/descendent, sibling and temporalrelations?
(E.g.
last child, leftmost descendent, par-ent?s following sibling, pronoun?s antecedent.)
Dowe need to describe tree nodes using regular expres-sions, or attributes and values?
Do we need a typesystem, a pattern language, or boolean logic for talk-ing about attribute values?
The expressive require-ments of the query language have been discussed268at length elsewhere (Lai and Bird, 2004; M?
?rovsky?,2008), and we will not consider them further here.Performance: What performance is acceptable,especially as the data size grows?
Do we wantto optimize multiple reformulations of a query, forusers who iteratively refine a query based on queryresults?
Do we want to optimize certain querytypes?
Are queries performed interactively or inbatch mode?
Is the treebank stable, or being activelyrevised, in which case indexes need to be easily up-datable?
Do we expect logically identical queriesto have the same performance, so that users do nothave to rewrite their queries for efficiency?
Key per-formance measures are index size and search times.Architecture: Is the query system standalone, ordoes it exist in a client-server architecture?
Is therea separate user-interface layer that interacts with adata server using a well-defined API, or is it a mono-lithic system?
Should it translate queries into an-other language, such as SQL (Bird et al, 2006;Nakov et al, 2005), or XQuery (Cassidy, 2002;Mayo et al, 2006), or to automata (Maryns andKepser, 2009), in order to benefit from the perfor-mance optimizations they provideIndexing.
The indexing methods used in individ-ual systems are usually not reported.
Many systemsdisplay nearly constant time for querying a database,regardless of the selectivity of a query, a strong in-dicator that no indexes are being used.
For exam-ple, Emu performs all queries in memory with noindexes, and several others are likely to be the same(Cassidy and Harrington, 2001; Ko?nig and Lezius,2001; Heid et al, 2004).
TGrep2 (Rohde, 2005) usesa custom corpus file and processes it sentence bysentence at query execution time.
Other tree querysystems use hashed indexes or other types of in-memory indexes.
However, a common drawback ofthese systems is that they are designed for treebanksthat are at most a few million words in size, and donot scale well to much larger treebanks.There are many positions to be taken on the abovequestions.
Our goal is not to argue for a particu-lar data format or query style, but rather to demon-strate a powerful technique for indexing and query-ing treebanks which should be applicable to most ofthe above scenarios.3 Indexing TreesIn this section we discuss two methods of stor-ing and indexing trees.
The first uses a relationaldatabase and linguistic queries are translated intoSQL, while the second uses an inverted index ap-proach based on an open source IR engine, Lucene.1Relational databases are a mature technology andare known to be efficient at performing joins andaccessing data using indexes.
Information retrievalengines using term vectors, on the other hand, ef-ficiently retrieve documents relevant to a query.
IRengines are known to scale well, but they do not sup-port complex queries.
A common feature of boththe IR and database approaches is the adoption ofso-called ?tree labeling?
schemes.3.1 Tree labeling schemesTree queries specify node labels (?value con-straints?)
and structural relationships between nodesof interest (?structural constraints?).
A simple valueconstraint could look for a wh noun phrase by spec-ifying the WHNP; such queries are efficiently im-plemented using indexes.
Structural relationshipscannot be indexed like node labels.
A term in asentence will have multiple relationships with otherterms in the same sentence.
Indexing all pairs ofterms that exist in a given structural relationship re-sults in an explosion in the index size.
Instead, thestandard approach is to store position informationwith each occurrence of a term, using a table or aterm vector, and then use the position informationto find structural matches.
Many systems use thisapproach, from early object databases such as Lore(McHugh et al, 1997), to relational representationof tree data (Bird et al, 2006) and XISS/R (Hard-ing et al, 2003), and native XML databases such aseXist (Meier, 2003).
Here, the position is encodedvia node labeling schemes, and is designed so it cansupport efficient testing of a variety of structural re-lations.A labeling scheme based on pre-order and post-order labeling of nodes is the foundation for severalextended schemes.
It can be used for efficiently de-tecting that two nodes are in a hierarchical (or inclu-sion) relationship.
Other labeling schemes are basedon the Dewey scheme, in which each node contains1http://lucene.apache.org/269Figure 1: Generating node labelsa hierarchical label in which numbers are separatedby periods (Tatarinov et al, 2002).
A child node getsits label by appending its position relative to its sib-lings to its parent?s label.
This scheme can be usedfor efficiently detecting that two nodes are in a hier-archical or sequential (temporal) relationship.The LPath numbering scheme assigns four integerlabels to each node (Bird et al, 2006).
The genera-tion of these labels is explained with the help of anexample.
Figure 1 is the graphical representation ofa parse tree for a sentence with 7 words, w1 ?
?
?w7.Let A, B, C, D, E, and S represent the annotationtags.
Some nodes at different positions in the treeshare a common name.The first step in labeling is to identify the sequen-tial positions between words, as shown beneath theparse tree in Figure 1.
The left id of a terminal nodeis the sequence position immediately to the left of anode, while its right id is the one to its immediateright.
The left id of a non-terminal node is the leftid of its leftmost descendant, and the right id is theright id of its rightmost descendant.
In most casesthe ancestor-descendant and preceding-following re-lationships between two elements can be evaluatedusing the left and right ids alone.
The sequential idsdo not differentiate between two nodes where one isthe lone child of the other.
The depth id is thereforerequired in such cases and to identify the child node(depth values are shown on the left side of Figure 1).In order to check if two given nodes are siblings,the above three ids will not suffice.
We thereforeassign a common parent id label to siblings.
Thesefour identifiers together enable us to identify rela-tionships between elements without traversing trees.Node Left Right Depth ParentA 2 4 3 2A 1 4 2 6A 5 8 3 8B 3 4 4 4B 4 5 3 8B 7 8 4 10Table 1: Node labelsTable 1 illustrates the node labels assigned to Aand B nodes in Figure 1.
We can see that the parentid of the third A and second B are equal because theyare siblings.Once these numbers are assigned to each node,the nodes can be stored independently without lossof any structural information (in either a relationaldatabase or an inverted index).
At query executiontime, the set of elements on either side of an opera-tor are extracted and only those node numbers thatsatisfy the operator?s specification are selected as theresult.
For example, if the operator is the child rela-tion, and the operands are A and B, then there are twomatches: B{3, 4, 4, 4}, child of A{2, 4, 3, 2} and,B{7, 8, 4, 10}, child of A{5, 8, 3, 8}.2 This processof finding the elements of a document that match op-erators is nothing other than the standard join oper-ation (and it is implemented differently in relationaldatabases and IR engines).3.2 Relational database approachTree nodes can be stored in a relational database us-ing a table structure (Bird et al, 2006).
Each tree-bank would have a single table for all nodes whereeach node?s information is stored in a tuple.
Thenode name is stored along with other position infor-mation and the sentence id.
Every node tuple alsohas a unique primary key.
The parent id columnis a foreign key, referencing the parent node?s id,speeding up parent/child join operations.
In prac-tice, queries are translated from higher level linguis-tic query languages such as LPath into SQL auto-matically, allowing users to use a convenient syntax,rather than query using SQL.Previous research on a similar database structurefor containment queries in XML databases showed2The node labels are represented as an ordered set here forbrevity.
Their positions match the headings in Table 1.270that databases are generally slower than specialisedIR indexes (Zhang et al, 2001).
In that work, theauthors provide results comparing their IR join algo-rithm, the multi-predicate merge join (MPMGJN),with two standard relational join algorithms.
Theyconsider the number of comparisons performed inthe standard merge join and the index nested loopjoin, and contrast these with their IR join algorithm.They show that the IR algorithm performs fewercomparisons than a standard merge join but greaterthan the index nested loop join.The multi-predicate merge join exploits the factthat nodes are encountered in document order (i.e.
anode appears before its descendents).
Search withina document can be aborted as soon as it is clear thatfurther searching will not yield further results.
Im-portantly, this IR join algorithm is faster than bothrelational join algorithms in practice, since it makesmuch better use of the hardware disk cache.
Ourown experiments with a large treebank stored in anOracle database have demonstrated that this short-coming of relational query relative to IR query existsin the linguistic domain (Ghodke and Bird, 2008).3.3 IR engine approachWe transform the task of searching treebanks into aconventional document retrieval task in which eachsentence is treated as a document.
Tree node labelsare stored in inverted indexes just like words in atext index.
We require two types of indexes, for fre-quency and position.
The frequency index for a nodelabel contains a list of sentence ids and, for each one,a count indicating the frequency of the node labelin the sentence.
(Labels with a frequency of zerodo not appear in this index.)
The position index isused to store node numbers for each occurrence ofthe node label.
The numbers at each position areread into memory as objects only when required (atother times, the byte numbers are skipped over forefficiency).
During query processing, the frequencyindexes are first traversed sequentially to find a doc-ument that contains all the required elements in thequery.
Once a document is found, the structural con-straints are checked using the data stored in the po-sition index for that document.
The document itselfdoes not need to be loaded.Using an inverted index for searching structureddata is not new, and several XML databases alreadyuse this method to index XML elements (Meier,2003).
However, linguistic query systems are spe-cial purpose applications where the unit of retrievalis usually a sentence.
A given tree may satisfy aquery in multiple places, but we only identify whichsentences are relevant.
Finding all matches within asentence requires further processing.
3Our approach has been to process each sentenceas a document.
By fixing the unit of retrieval to bethe sentence, we are able to greatly reduce the sizeof intermediate results when performing a series ofjoins.
The task is then to simply check whether asentence satisfies a query or not.
This can be doneusing substantially less resources than is needed forfinding sets of nodes, the unit of retrieval for rela-tional and XML databases.
When processing a se-ries of joins, we use a single buffer to store the nodepositions required to perform the next join in the se-ries.
After computing that join and processing an-other operator in the query, the buffer contents is re-placed with a new set of nodes, discarding the inter-mediate information.4 Experiments with IR Engine4.1 DataWe used two data collections in our experiments.The first collection is a portion of the English Giga-word Corpus, parsed in the Penn Treebank format.We used the TnT tagger and the DBParser trainedon the Wall Street Journal section of the Penn Tree-bank to parse sentences in the corpus.
The total sizeof the corpus is about 5.5 million sentences.
TheTGrep2 corpus file for this corpus is about 1.8 GBand the Lucene index is 4 GB on disk.
The seconddata collection is a portion of English Wikipedia,again tagged and parsed using TnT tagger and DB-Parser, respectively.
This collection contains 26.5million parsed sentences.
The TGrep2 corpus filecorresponding to this collection is about 6.6 GB andthe Lucene index is 14 GB on disk.3Several alternate path joins and improvements to theMPMGJN algorithm have been proposed over the years to over-come the problem of large number of intermediate nodes and toreduce unnecessary joins (Al-Khalifa et al, 2002; Li and Moon,2001).
Bruno et al?s work on twig joins further improved onthose efforts by processing an entire query twig in a holisticfashion (Bruno et al, 2002), and has since been further opti-mized.271Query Selectivity Data Collection 1 (5.5M sentences) Data Collection 2 (26.5M sentences)Full search First 10 Full search First 10(//N1 op N2) N1-op-N2 cold warm hits cold warm cold warm hits cold warmNP/NN L-L-L 7.326 5.533 4,814,540 0.059 0.0003 24.680 20.256 21,906,349 0.260 0.0003VP/DT L-H-L 4.576 3.593 17,328 0.140 0.004 13.865 11.363 91,070 0.301 0.003NP/LST L-L-H 4.454 0.043 6,808 0.083 0.001 16.864 0.077 2.974 0.270 0.003VP/WHPP L-H-H 2.445 0.034 32 1.012 0.014 8.834 0.066 29 3.653 0.015LST\NP H-L-L 4.444 0.043 6,808 0.080 0.001 16.814 0.077 2,974 0.271 0.003WHPP\VP H-H-L 2.461 0.034 32 0.990 0.013 8.726 0.065 29 3.611 0.015LST/LS H-L-H 0.181 0.005 10,432 0.071 0.0001 0.294 0.008 8,977 0.238 0.0002LST/FW H-H-H 0.123 0.009 4 0.103 0.011 0.348 0.012 9 0.408 0.012Table 2: Execution times (in seconds) for queries of varying selectivity4.2 Types of queriesQuery performance depends largely on the nature ofthe individual queries, therefore we present a de-tailed analysis of the query types and their corre-sponding results in this section.Selectivity: A query term that has few correspond-ing hits in the corpus will be considered to have highselectivity.
The selectivity of whole queries dependsnot only on the selectivity of their individual ele-ments, but also on how frequently these terms satisfythe structural constraints specified by the query.Table 2 gives execution times for queries withvarying selectivity, using our system.
We assign aselectivity measure for the operator based on howoften the two operands satisfy the structural condi-tion.
It is clear that when elements are very commonand they frequently satisfy the structural constraintsof the operator, there are bound to be more run-timestructural checks and the performance deteriorates.This is demonstrated by the time taken by the firstquery.
Note the relatively small difference in the ex-ecution time between the second and third queries.The third query contains a high selectivity elementand even returns fewer matches compared to the sec-ond, but takes almost as long.
This may be due to therelative frequency of the tags within each sentence,which we have not controled in this experiment.
Ifthere are several LST tags in the sentences whereit appears, there are likely to be greater number ofsearches within each sentence.
A better join algo-rithm would improve the performance in such cases.A multiple regression analysis of the full search(cold start) times for collection 2 shows that low-selectivity labels contribute 9.5 seconds, and a low-selectivity operator contributes 6.7 seconds, and thatthis accounts for most of the variability in the timingdata (t = ?1.53 + 9.51 ?
N1 + 6.72 ?
op + 9.44 ?N2, R2 = 0.8976).
This demonstrates that the dis-tribution of full search (cold start) times is mostlyaccounted for by the index load time, with the timefor computing a large join being a secondary cost.The full search (warm start) times in Table 2 pay alesser index loading cost.Query length: It is evident that the system mustretrieve and process more term vectors as we in-crease the number of elements in a query.
To findout exactly how the query length affects processing,we ran tests with three sets of queries.
In each set wevaried the number of elements in a dominance rela-tionship with another node of the same name.
Thenumber of terms in the dominance relationship wasvaried from 1 to 6, where the first case is equiva-lent to just finding all terms with that name.
In thefirst set, queries search for nested noun phrases (NP),while the second and third look for adjective phrases(ADJP) and list elements (LST) respectively.These terms have been chosen to simultaneouslystudy the effects of selectivity and query length, withNP being the least selective (or most common), fol-lowed by ADJP, then with LST being the most selec-tive (or least common).
NP is also more frequentlyself-nested than the others.
Figure 2 plots querylength (x-axis) against query execution time (y-axis,log scale) for the three sets, using our system.
With272//NP//ADJP//LSTNumber of elementsTime(seconds)1 2 3 4 5 60.0010.010.1110100Figure 2: Variation of query execution time with query length in data collection 1//NP//ADJP//LSTNumber of elementsTime(seconds)1 2 3 4 5 60.0010.010.1110100Figure 3: Variation of query execution time with query length in data collection 2each step on the x-axis, a query will have an extradescendant node.
For example, at position 3 for ele-ment A, the query would be //A//A//A.The circles on the plot are proportional to the logof the result set size.
The biggest circle is for //NPwhich is of the order of 5.4 million, while there areonly 4 trees in which LST is nested 4 times.
LST isnot nested 5 or more times.
Similarly, ADJP returns0 results for the 6th test query and hence there are nocircles at these locations.
The thick lines on the plotindicate the average cold start run time over threeruns, while the dashed line shows the minimum av-erage run time of 4 sets, with the query executed 5times in each set.
Together, the pairs of unbrokenand dashed lines indicate the variation in run timedepending on the state of the system.
44We can observe from the results that the variation be-4.3 Measurement techniquesThe measurement techniques vary for TGrep andthe IR based approach.
In TGrep the corpus file isloaded each time during query processing, but in theIR approach an index once loaded can operate fasterthan a cold start.In order to understand the variations in the operat-ing speed we plot the variation in times from a coldstart to a repeat query, as shown in Table 3.tween cold start and warm start correlates with query length.The length experiment here use a single term repeated multi-ple times.
However, there is a possibility that the results mayvary when the terms are different, because it would involve ad-ditional time to load the term vectors of distinct elements intomemory.273Query Data collection 1 Data collection 2TGrep2 IR TGrep2 IR//NP 25.28 8.15 89.35 15.53//NP//NP 25.44 10.42 88.36 35.95//NP//NP//NP 25.45 14.96 87.48 52.81//NP.
.
.
//NP (4 times) 25.34 18.38 88.28 66.80//NP.
.
.
//NP (5 times) 25.46 20.94 87.38 70.80//NP.
.
.
//NP (6 times) 25.41 23.23 86.92 75.05//ADJP 25.48 0.69 86.83 1.03//ADJP//ADJP 25.36 0.73 86.42 1.61//ADJP//ADJP//ADJP 25.29 0.84 86.89 1.89//ADJP.
.
.
//ADJP (4 times) 25.45 0.90 87.39 2.11//ADJP.
.
.
//ADJP (5 times) 25.23 1.03 86.50 2.49//ADJP.
.
.
//ADJP (6 times) 25.74 1.11 89.24 2.79//LST 25.29 0.17 87.73 0.26//LST//LST 25.49 0.20 87.09 0.27//LST//LST//LST 25.38 0.20 87.66 0.28//LST.
.
.
//LST (4 times) 25.43 0.19 87.17 0.29//LST.
.
.
//LST (5 times) 25.40 0.19 88.02 0.31//LST.
.
.
//LST (6 times) 25.32 0.19 89.01 0.32//NP/NN 25.66 7.33 87.63 24.68//VP/DT 25.53 4.58 89.85 13.86//NP/LST 25.62 4.45 86.39 16.86//VP/WHPP 25.09 2.97 87.43 8.83//WHPP/IN 25.75 4.44 88.48 16.81//LST/JJ 25.46 2.46 86.57 8.73//LST/LS 25.38 0.18 87.40 0.29//LST/FW 25.51 0.12 87.27 0.35Table 3: Comparison of TGrep2 and IR Engine cold startquery times (seconds)5 ConclusionsWe have shown how an IR engine can be used tobuild a high performance tree query system.
Itoutperforms existing approaches using indexless in-memory search, or custom indexes, or relationaldatabase systems, or XML database systems.
Wereported the results of a variety of experiments todemonstrate the efficiency of query for a variety ofquery types on two treebanks consisting of around5 and 26 million sentences, more than two ordersof magnitude larger than what existing systems sup-port.
The approach is quite general, and not limitedto particular treebank formats or query languages.This work suggests that web-scale tree query maysoon be feasible.
This opens the door to some in-teresting possibilities: augmenting web search withsyntactic constraints, the ability discover rare exam-ples of particular syntactic constructions, and as atechnique for garnering better statistics and moresensitive features for the purpose of constructinglanguage models.AcknowledgmentsWe gratefully acknowledge support from MicrosoftResearch India and the University of Melbourne.ReferencesAnne Abeille?, editor.
2003.
Treebanks: Building andUsing Parsed Corpora.
Text, Speech and LanguageTechnology.
Kluwer.Shurug Al-Khalifa, H.V.
Jagadish, Nick Koudas, Jig-nesh M. Patel, Divesh Srivastava, and Yuqing Wu.2002.
Structural joins: A primitive for efficient XMLquery pattern matching.
In ICDE ?02: Proc.
18th IntlConf on Data Engineering, page 141.
IEEE ComputerSociety.Steven Bird, Yi Chen, Susan B. Davidson, Haejoong Lee,and Yifeng Zheng.
2006.
Designing and evaluatingan XPath dialect for linguistic queries.
In ICDE ?06:Proc.
22nd Intl Conf on Data Engineering, page 52.IEEE Computer Society.Nicolas Bruno, Nick Koudas, and Divesh Srivastava.2002.
Holistic twig joins: optimal XML patternmatching.
In SIGMOD ?02: Proc.
2002 ACM SIG-MOD Intl Conf on Management of Data, pages 310?321.
ACM.Steve Cassidy and Jonathan Harrington.
2001.
Multi-level annotation of speech: an overview of the EmuSpeech Database Management System.
Speech Com-munication, 33:61?77.Steve Cassidy.
2002.
Xquery as an annotation query lan-guage: a use case analysis.
In Proc.
3rd LREC.John Chen and Owen Rambow.
2003.
Use of deep lin-guistic features for the recognition and labeling of se-mantic arguments.
In Empirical Methods in NaturalLanguage Processing, pages 41?48.Abdur Chowdhury and M. Catherine McCabe.
1998.Performance improvements to vector space informa-tion retrieval systems with POS.
U Maryland.Stephen Clark and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with CCG andlog-linear models.
Computational Linguistics,33(4):493?552.Michael Collins, Brian Roark, and Murat Saraclar.2005.
Discriminative syntactic language modeling forspeech recognition.
In Proc.
43rd ACL, pages 507?514.
ACL.Sumukh Ghodke and Steven Bird.
2008.
Querying lin-guistic annotations.
In Proc.
13th Australasian Docu-ment Computing Symposium, pages 69?72.Jo?rg Hakenberg, Illes Solt, Domonkos Tikk, Luis Tari,Astrid Rheinla?nder, Nguyen Quang Long, GracielaGonzalez, and Ulf Leser.
2009.
Molecular eventextraction from Link Grammar parse trees.
In Proc.BioNLP 2009 Workshop, pages 86?94.
ACL.274Philip J Harding, Quanzhong Li, and Bongki Moon.2003.
XISS/R: XML indexing and storage system us-ing RDBMS.
In Proc.
29th Intl Conf on Very LargeData Bases, pages 1073?1076.
Morgan Kaufmann.Ulrich Heid, Holger Voormann, Jan-Torsten Milde, Ul-rike Gut, Katrin Erk, and Sebastian Pado.
2004.Querying both time-aligned and hierarchical corporawith NXT search.
In Proc.
4th LREC.Ichikawa Hiroshi, Noguchi Masaki, Hashimoto Taiichi,Tokunaga Takenobu, and Tanaka Hozumi.
2005.eBonsai: An integrated environment for annotatingtreebanks.
In Proc.
2nd IJCNLP, pages 108?113.Julia Hockenmaier and Mark Steedman.
2007.
CCG-bank: A corpus of CCG derivations and dependencystructures extracted from the Penn Treebank.
Compu-tational Linguistics, 33:355?396.Hiroshi Ichikawa, Keita Hakoda, Taiichi Hashimoto, andTakenobu Tokunaga.
2006.
Efficient sentence re-trieval based on syntactic structure.
In COLING/ACL,pages 399?406.Stephan Kepser.
2003.
Finite Structure Query: A toolfor querying syntactically annotated corpora.
In Proc.10th EACL, pages 179?186.Esther Ko?nig and Wolfgang Lezius.
2001.
The TIGERlanguage: a description language for syntax graphs.part 1: User?s guidelines.
Technical report, Universityof Stuttgart.Catherine Lai and Steven Bird.
2004.
Querying and up-dating treebanks: A critical survey and requirementsanalysis.
In Proc.
Australasian Language TechnologyWorkshop, pages 139?146.Catherine Lai and Steven Bird.
2010.
Querying linguis-tic trees.
Journal of Logic, Language and Information,19:53?73.Quanzhong Li and Bongki Moon.
2001.
Indexing andquerying XML data for regular path expressions.
InVLDB ?01: Proc.
27th Intl Conf on Very Large DataBases, pages 361?370.
Morgan Kaufmann.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: The Penn Treebank.
ComputationalLinguistics, 19(2):313?30.Hendrik Maryns and Stephan Kepser.
2009.Monasearch: Querying linguistic treebanks withmonadic second-order logic.
In The 7th InternationalWorkshop on Treebanks and Linguistic Theories.Neil Mayo, Jonathan Kilgour, and Jean Carletta.
2006.Towards an alternative implementation of nxts querylanguage via xquery.
In Proc.
5th Workshop on NLPand XML: Multi-Dimensional Markup in Natural Lan-guage Processing, pages 27?34.
ACL.J.
McHugh, S. Abiteboul, R. Goldman, D. Quass, andJ.
Widom.
1997.
Lore: A database management sys-tem for semistructured data.
SIGMOD Rec., 26:54?66.Wolfgang Meier.
2003. eXist: An open source nativeXML database.
In Revised Papers from the NODe2002 Web and Database-Related Workshops on Web,Web-Services, and Database Systems, pages 169?183.Springer-Verlag.Jir???
M??rovsky?.
2006.
Netgraph: a tool for searchingin Prague Dependency Treebank 2.0.
In Proc.
5thIntl Conf on Treebanks and Linguistic Theories, pages211?222.Jir???
M??rovsky?.
2008.
PDT 2.0 requirements on a querylanguage.
In Proc.
46th ACL, pages 37?45.
ACL.Preslav Nakov, Ariel Schwartz, Brian Wolf, and MartiHearst.
2005.
Supporting annotation layers for naturallanguage processing.
In Proc.
43rd ACL, pages 65?68.Stephan Oepen, Kristina Toutanova, Stuart Shieber,Christopher Manning, Dan Flickinger, and ThorstenBrants.
2002.
The LinGO Redwoods Treebank: Mo-tivation and preliminary applications.
In Proc.
19thCOLING, pages 1253?57.Petr Pajas and Jan ?Ste?pa?nek.
2009.
System for queryingsyntactically annotated corpora.
In Proc.
47th ACL,pages 33?36.
ACL.Douglas L. T. Rohde, 2005.
TGrep2 User Manual Ver-sion 1.15. http://tedlab.mit.edu/ dr/TGrep2/tgrep2.pdf.Igor Tatarinov, Stratis D. Viglas, Kevin Beyer, JayavelShanmugasundaram, Eugene Shekita, and ChunZhang.
2002.
Storing and querying ordered XMLusing a relational database system.
In SIGMOD ?02:Proc.
2002 ACM SIGMOD Intl Conf on Managementof Data, pages 204?215.
ACM.M.
?Cmejrek, J.
Cur??
?n, and J. Havelka.
2004.
Pragueczech-english dependency treebank: Any hopes for acommon annotation scheme?
In A. Meyers, editor,HLT-NAACL 2004 Workshop: Frontiers in Corpus An-notation, pages 47?54.
ACL.Martin Volk, Joakim Lundborg, and Mae?l Mettler.
2007.A search tool for parallel treebanks.
In Proc.
Linguis-tic Annotation Workshop, pages 85?92.
ACL.Sean Wallis.
2003.
Completing parsed corpora.
InAnne Abeille?, editor, Treebanks: Building and UsingParsed Corpora, Text, Speech and Language Technol-ogy, pages 61?71.
Kluwer.Naiwen Xue, Fei Xia, Fu-Dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese TreeBank: Phrasestructure annotation of a large corpus.
Natural Lan-guage Engineering, 11:207?238.Chun Zhang, Jeffrey Naughton, David DeWitt, QiongLuo, and Guy Lohman.
2001.
On supporting contain-ment queries in relational database management sys-tems.
In SIGMOD ?01: Proc.
ACM SIGMOD inter-national Conference on Management of Data, pages425?436, New York.
ACM.275
