RESEARCH IN CONTINUOUS SPEECHRECOGNITIONPIs: John Makhoul and Richard Schwartzmakhoul@bbn.com, schwartz@bbn.comBBN Systems and Technologies, 10 Moulton St., Cambridge, MA 02138OBJECTIVESThe primary objective of this basic research is todevelop imProved methods and models for acousticrecognition of continuous peech.
The work hasfocussed on developing accurate and detailedmathematical models of phonemes and theircoarticulation for the purpose of large-vocabularycontinuous speech recognition.
Important goals ofthis work are to achieve the highest possible wordrecognition accuracy in continuous peech and todevelop methods for the rapid adaptation ofphonetic models to the voice of a new speaker.ACCOMPLISHMENTS?
Developed context-dependent phonetic modelsbased on the hidden Markov modeling (HMM)formalism to describe the acoustic variabilityof speech due to coarticulation withneighboring phonemes.
The method resultedin a reduction of the word error rate by a factorof two over using context-independent models.Developed and demonstrated the effectivenessof the "time-synchronous" search strategy forfinding the most likely sequence of words,given the input speech.?
Incorporated the various techniques in acomplete continuous speech recognitionsystem, called BYBLOS, and demonstrated itfirst in 1986.
The basic methodology ofBYBLOS has since been adopted by otherDARPA sites.
It was, and continues to be, thehighest-performing continuous recognitionsystem for large vocabularies.
When tested onthe DARPA Resource Management Corpuswith a grammar of perplexity 60, the worderror rate is less than 2% for speaker-dependentrecognition and less than 4% for speaker-independent recognition.Initial experiments with this model on context-independent phonetic units reduced therecognition error by a factor of two comparedto the corresponding context-independentHMM models.
However, the new methodrequires ignificantly more computation.Developed a novel "probabilistic spectralmapping" technique for rapid speakeradaptation whereby the phonetic models of anew speaker are estimated by performing atransformation on the phonetic models of areference speaker, using only a small amountof speech from the new speaker.
Using thistechnique, the recognition accuracy with only 2minutes of training from the new speaker isequal to that usually achieved with 20 minutesof speaker-dependent training or with speaker-independent training (which requires peechfrom over 100 speakers).With multiple reference models, the error ratewith speaker adaptation is cut in half relativeto the single-reference ase.
This constitutesthe first time that speaker adaptation has beensuccessful in improving performance over aspeaker-independent system.A new paradigm for speaker-independenttraining has been developed.
Instead of usingspeech from over 100 speakers, the newmethod uses 30 minutes from each of only adozen speakers.
This new, more practical,paradigm promises to be the key to futuredevelopments in improved speaker-independentrecognition.Developed a new formalism for phoneticmodeling, called "stochastic segmentmodeling", which can model the correlationbetween different parts of a phoneme directly.406
