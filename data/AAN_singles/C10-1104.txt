Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 922?930,Beijing, August 2010An Exploration of Features for Recognizing Word EmotionChangqin QuanFaculty of EngineeringUniversity of Tokushimaquan-c@is.tokushima-u.ac.jpFuji RenFaculty of EngineeringUniversity of Tokushimaren@is.tokushima-u.ac.jpAbstractEmotion words have been well used as themost obvious choice as feature in the taskof textual emotion recognition and auto-matic emotion lexicon construction.
Inthis work, we explore features for rec-ognizing word emotion.
Based on Ren-CECps (an annotated emotion corpus) andMaxEnt (Maximum entropy) model, sev-eral contextual features and their com-bination have been experimented.
ThenPLSA (probabilistic latent semantic anal-ysis) is used to get semantic feature byclustering words and sentences.
The ex-perimental results demonstrate the effec-tiveness of using semantic feature forword emotion recognition.
After that,?word emotion components?
is proposedto describe the combined basic emotionsin a word.
A significant performanceimprovement over contextual and seman-tic features was observed after addingword emotion components as feature.1 IntroductionTextual emotion analysis is becoming increas-ingly important due to augmented communicationvia computer mediated communication (CMC).
Apossible application of textual emotion recogni-tion is online chat system.
An emotion feedbacksystem can recognize users?
emotion and give ap-propriate responses.
Another application exam-ple is weblog emotion recognition and prediction.Blogspace consists of millions of users who main-tain their online diaries, containing frequently-updated views and personal remarks about a rangeof issues.
An emotion recognition and predic-tion system can understand the public?s reaction tosome social issues and predict emotion changes.
Itwould be helpful for solving some psychologicalproblems or giving early warnings, such as suicideor terrorism.Textual emotion analysis also can improvethe accuracy of other nonverbal modalities likespeech or facial emotion recognition, and to im-prove human computer interaction systems.
How-ever, automatic recognition of emotion meaningfrom texts presents a great challenge.
One of thereasons is the manifoldness of expressed emotionsin words.Emotion words have been well used as themost obvious choice as feature in the task of tex-tual emotion recognition and automatic emotionlexicon construction (Virginia and Pablo, 2006;Tokuhisa et al, 2008, etc.).
And there are manylexical resources developed for these tasks, suchas GI (Stone et al, 1966), WordNet-Affect (Strap-parava and Valitutti, 2004), NTU Sentiment Dic-tionary (Ku et al, 2006), Hownet (Dong andDong, 2003), SentiWordnet (Esuli and Sebastiani,2006).
In these sentimental or affective lexicons,the words usually bear direct emotions or opin-ions, such as happy or sad, good or bad.
Al-though they play a role in some applications, sev-eral problems of emotion expression in wordshave been ignored.Firstly, there are a lot of sentences can evokeemotions without direct emotion words.
For ex-ample,(1) SU3?f??p!3?f?%p"(Spring is in children?s eyes, and in theirhearts.
)In sentence (1), we may feel joy, love or expectdelivered by the writer.
But there are no directemotion words can be found from lexicons.
AsOrtony (1987) indicates, besides words directlyreferring to emotion states (e.g., ?fear?, ?cheer-ful?)
and for which an appropriate lexicon wouldhelp, there are words that act only as an indirect922reference to emotions depending on the context.Strapparava et al (2006) also address this issue.The authors believed that all words can potentiallyconvey affective meaning, and they distinguishedbetween words directly referring to emotion states(direct affective words) and those having only anindirect reference that depends on the context (in-direct affective words).The second problem is emotion ambiguity ofwords.
The same word in different contexts mayreflect different emotions.
For example,(2) ??8c??
?U?"(This is cur-rently the only thing I can do.)(3)?????
"(He is my only one.
)In sentence (2), the word ???
(only)?
mayexpress the emotion of anxiety or expect; but insentence (3), the word ???
(only)?
may expressthe emotion of love or expect.
The emotion cat-egories can not be determined without their cer-tain contexts especially for the words with emo-tion ambiguity.In addition, some words can express multipleemotions, such as ?U\ (mingled feelingsof joy and sorrow)?.
Statistics on an annotatedemotion corpus (Ren-CECps 1, Chinese emotioncorpus developed by Ren-lab) showed that 84.9%of all emotion words have one emotion, 15.1%have more than one emotions (Quan and Ren,2010).
Multi-emotion words are indispensable forexpressing complex feelings in use of language.In this work, we explore features for recogniz-ing word emotion in sentences.
Based on Ren-CECps and MaxEnt model, several contextualfeatures and their combination have been exper-imented.
Then PLSA (probabilistic latent seman-tic analysis) is used to get semantic feature byclustering word and sentence.
The experimentalresults demonstrate the effectiveness of using se-mantic feature for word emotion recognition.
Af-ter that, the notion of ?word emotion components?is proposed to describe the combined basic emo-tions in a word.
A significant performance im-provement over only using contextual and seman-tic features was observed after adding word emo-tion components as feature and output in MaxEntbased model.1http://a1-www.is.tokushima-u.ac.jp/member/ren/Ren-CECps1.0/Ren-CECps1.0.htmlThis paper is organized as follows.
In section 2,based on Ren-CECps and MaxEnt, an explorationof using contextual feature for Chinese word emo-tion recognition is described.
In section 3, usingPLSA technique, the performance of adding se-mantic feature is presented.
In section 4, the no-tion of ?word emotion components?
is proposedand the performance of using encoding feature ispresented.
In section 5, the discussions are de-scribed.
Section 6 is conclusions.2 Chinese Word Emotion Recognition2.1 Related WorksThere are many researches concerning comput-ing semantics of words, while the researches oncomputing emotions of words are relatively less.Computing word emotions is a challenge task be-cause the inherent of emotion is ambiguous andnatural language is very rich in emotion termi-nology.
Using the textual emotion information,several methods have been explored for comput-ing lexical emotions.
Wilson et al (2009) pro-posed a two-step approach to classify word po-larity out of context firstly, and then to clas-sify word polarity in context with a wide vari-ety of features.
Strapparava et al (2007) im-plemented a variation of Latent Semantic Anal-ysis (LSA) to measure the similarities between di-rect affective terms and generic terms.
Lee andNarayanan (2005) proposed a method of comput-ing mutual information between a specific wordand emotion category to measure how much in-formation a word provides about a given emo-tion category (emotion salience).
Based on struc-tural similarity, Bhowmick (2008) computed thestructural similarity of words in WordNet to dis-tinguish the emotion words from the non-emotionwords.
Kazemzadeh (2008) measured similar-ity between word and emotion category based oninterval type-2 fuzzy logic method.
Takamura(2005) used a spin model to extract emotion po-larity of words.Different from the above researches, in thiswork, we explore which features are effective forword emotion recognition.
The features includecontextual feature, semantic feature and encodingfeature.9232.2 Ren-CECps and MaxEnt based ChineseWord Emotion RecognitionRen-CECps is constructed based on a relativefine-grained annotation scheme, annotating emo-tion in text at three levels: document, paragraph,and sentence.
The all dataset consisted of 1,487blog articles published at sina blog, sciencenetblog, etc.
There are 11,255 paragraphs, 35,096sentences, and 878,164 Chinese words containedin this corpus (more details can be found in (Quanand Ren, 2010)).In the emotion word annotation scheme of Ren-CECps, direct emotion words and indirect emo-tion words in a sentence are all annotated.
Forexample, in sentence (1) /SU (spring)0and/?f?
(the children)0are labeled.
An emo-tion keyword or phrase is represented as a vec-tor to record its intensities of the eight basic emo-tion classes (expect, joy, love, surprise, anxiety,sorrow, angry and hate).
For instance, the emo-tion vector for the word /SU (spring)0?
?w =(0.1,0.3,0.3,0.0,0.0,0.0,0.0,0.0) indicates theemotions of weak expect, joy and love.
In thiswork, we focus on if a word contains some emo-tion(s) in a certain context.
The analysis on emo-tion intensity of emotion words is included in ourfuture work.As word emotion is subjective entity, a wordin a certain context may evoke multiple emotionsin different people?s mind.
A part of documentsin Ren-CECps have been annotated by three an-notators independently to measure agreement onthe annotation of this corpus, which include 26documents with a total of 805 sentences, 19,738words.
This part of corpus is used as testing cor-pus to evaluate the experimental results.
(Section5.1 shows the analysis on the annotation agree-ment on word emotion.
)MaxEnt modeling provides a framework for in-tegrating information from many heterogeneousinformation sources for classification (Manning,1999).
MaxEnt principle is a well used techniqueprovides probability of belongingness of a tokento a class.
In word emotion recognition, the Max-Ent estimation process produces a model in whicheach feature fi is assigned a weight ?i.
The de-terministic model produces conditional probabil-ity (Berger, 1996), see equation (1) and (2).
Inexperiments, we have used a Java based open-nlpMaxEnt toolkit 2.p(e|context) = 1Z(context) ?i ?fi(context,e)i (1)Z(context) = ??i?
fi(context,e)i (2)2.3 Contextual FeaturesThe contextual features used in MaxEnt for Chi-nese word emotion recognition are described asfollows:Word Feature (WF): Word itself to be recog-nized.N-words Feature (NF): To know the rela-tionship between word emotion and its con-text, the surrounding words of length n for theword (wi) to be recognized are used as feature:(wi?n...wi...wi+n).POS Feature (POSF): The part of speech ofthe current word and surrounding words are usedas feature.
We have used a Chinese segmentationand POS tagger (Ren-CMAS) developed by Ren-lab, which has an accuracy about 97%.
The set ofPOS includes 35 classes.Pre-N-words Emotion Feature (PNEF): Theemotions of the current word may be influencedby the emotions of its previous words.
So theemotions of previous n words are used as feature.The value of this feature for a word (wi) is ob-tained only after the computation of the emotionsfor its previous words.Pre-is-degree-word Feature (PDF), Pre-is-negative-word Feature (PNF), Pre-is-conjunction Feature (PCF): To determine ifthe previous word is a degree word, a negativeword, or a conjunction may be helpful to identifyword emotions.
The degree word list (contains1,039 words), negative word list (contains 645words), and conjunction list (contains 297 words)extracted from Ren-CECps have been used.2.4 The Performance of Using ContextualFeatureWe use the documents in Ren-CECps that havebeen annotated by three annotators independently2http://maxent.sourceforge.net/924as testing corpus.
An output of word emotion(s)will be regarded as a correct result if it is in agree-ment with any one item of word emotion(s) pro-vided by the three annotators.
The numbers oftraining and testing corpus are shown in table 1.The accuracies are measured by F-value.Table 1: Number of training and testing corpusNumber Training TestingDocuments 1,450 26Sentences 33,825 805Words 813,507 19,738Emotion words 99,571 2,271?
(*) At least agreed by two annotators.Table 2 gives the results of F-value for differ-ent contextual features in the MaxEnt based Chi-nese word emotion recognition.
The results of F-value include: (a) recognize emotion and unemo-tion words; (b) recognize the eight basic emotionsfor emotion words (complete matching); (c) rec-ognize the eight basic emotions for emotion words(single emotion matching).As shown in table 2, when we only use WordFeature(WF), the F-value of task (a) achieved ahigh value (96.3).
However, the F-values of task(b) and (c) are relative low, that means the prob-lem of recognizing the eight basic emotions foremotion words is a lot more difficult than theproblem of recognizing emotion and unemotionwords, so we focus on task (b) and (c).When we experiment with Word Feature(WF)and N-words Feature (NF), we have observedthat word feature (wi) and a window of previ-ous and next word (wi?1,wi,wi+1) give the bestresults (a=96.5, b=50.4, c=69.0).
Comparedwith (wi?1,wi,wi+1), a larger window of previousand next two words (wi?2,wi?1,wi,wi+1,wi+2) re-duces the F-value.
This demonstrates that wi andwi?1,wi,wi+1 are effective features for word emo-tion recognition.When POS Feature (POSF) is added, the F-value is increased.
Especially the F-value is in-creased to (a=97.1, b=51.9, c=72.0) when posiand posi?1, posi, posi+1 are added.We also find that Pre-N-words Emotion Fea-ture (PNEF) (pre e0, ..., pre ei?1) increases the F-value, but previous one word emotion can not in-creases the F-value.As can be seen from table 2, when only con-textual features are used, the highest F-valueis (a=97.1, b=53.0, c=72.7) when Pre-is-degree-word Feature (PDF), Pre-is-negative-word Fea-ture (PNF), Pre-is-conjunction Feature (PCF) areadded.3 Semantic FeatureTo know if semantic information is useful foremotion recognition, we have used probabilis-tic latent semantic analysis (PLSA) (Hofmann,1999) to cluster words and sentences.
PLSA clus-ters documents based on the term-document co-occurrence which results in semantic decomposi-tion of the term-document matrix into a lower di-mensional latent space.
PLSA can be defined as:P(s,w) = ?z?ZP(z)P(s|z)P(w|z) (3)where p(s,w) is the probability of word w andsentence s co-occurrence, P(s|z) is the probabilityof a sentence given a semantic class z, and P(w|z)is the probability of a word given a semantic classz.For word clustering, We made the assignmentbased on the maximum p(z|w), if p(z?
|w) = maxp(z|w), then w was assigned to z?
.
Sentence clus-tering is similar to word clustering.
Word clus-tering and sentence clustering are run separately.The word class id and sentence class id are usedas semantic feature (SF), which including sen-tence class feature (SCF) and word class feature(WCF).
PeenAspect implementation of PLSA hasbeen used for our expriments 3.Table 3 gives the results of F-value for com-bined all contextual features and semantic fea-ture in the MaxEnt based Chinese word emotionrecognition.As can be seen from table 3, when SCF is used,the best result is obtained when the cluster num-ber is 100; when WCF is used, the best result isobtained when the cluster number is 100 or 160.The results demonstrate the effectiveness of usingSCF is a little higher than using WCF.3http://www.cis.upenn.edu/datamining/software dist/PennAspect/925Table 2: F-value for different contextual features in the MaxEnt based Chinese word emotion recogni-tion(a) recognize emotion or unemotion words(b) recognize the eight basic emotions for emotion words (complete matching)(c) recognize the eight basic emotions for emotion words (single emotion matching)Feature Features F-valuetype (a) (b) (c)WF f 1 = wi 96.3 45.9 63.0NF f 1 = wi?1,wi,wi+1 94.8 44.8 60.7f 1 = wi?2,wi?1,wi,wi+1,wi+2 92.4 28.4 40.3WF+NF f 1 = wi; f 2 = wi?1,wi,wi+1 96.5 50.4 69.0WF+NF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi 96.8 51.5 71.1+POSF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi?1, posi, posi+1 97.0 51.7 71.6f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posi f 4 = posi?1, posi, posi+1 97.1 51.9 72.0WF+NF+POSFf 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posif 4 = posi?1, posi, posi+1 f 5 = pre ei?1 97.1 51.9 72.0+PNEF f 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posif 4 = posi?1, posi, posi+1 f 5 = pre e0, ..., pre ei?1 97.1 52.4 72.2WF+NF+POSF+PNEF+PDF+PNF+PCFf 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posif 4 = posi?1, posi, posi+1 f 5 = pre e0, ..., pre ei?1f 6 =?
(wi?1 is a degree word)f 7 =?
(wi?1 is a negative word)f 8 =?
(wi?1 is a con junction)97.1 53.0 72.74 Encoding Feature: EmotionComponents of WordResearches on the psychology of concepts showthat categories in the human mind are not sim-ply sets with clearcut boundaries (Murphy, 2002;Hampton, 2007).
Word emotions are certainly re-lated to mental concepts.
As for emotion states,most theorists appear to take a combinatorial view.Plutchik (1962), for example, talks about ?mixedstates?, ?dyads?
and ?triads?
of primary emotions.Similarly, Averill (1975) argues for compoundemotions based on more elementary ones.
Andone model, suggested by Ekman (1982) (emotionblends) and Plutchik (mixed states), is that emo-tions mix (Ortony, 1988).
According to these re-searches, we use an encoding feature: emotioncomponents of word.
?Emotion components of word?
describes thecombined basic emotions in a word, which is rep-resented by eight binary digits, and each digit cor-responding to a basic emotion class respectively.For example, the word ?U?
(like)?, its possi-ble emotion components in a certain context is?01100000?, which expresses the combined emo-tions by joy and love.With the expression of emotion componentsof word, it is possible to distinguish direct emo-tion words and indirect emotion words.
Thosewords always demonstrate similar emotion com-ponents in different contexts can be regarded asdirect emotion words, accordingly, those wordsdemonstrate different emotion components in dif-ferent contexts can be regarded as indirect emo-tion words.
With the expression of emotion com-ponents in word, the problem of expressing emo-tion ambiguity in words can be solved.
The sameword in different contexts may reflect differentemotions, which can be expressed by differentemotion components.
The emotions of words withmultiple emotions also can be expressed by emo-tion components.926Table 3: F-value for combined contextual features(CF) and semantic feature (SF) (including sen-tence class feature (SCF) and word class feature(WCF))Feature Cluster F-valuetype number (a) (b) (c)CF+SCF 20 97.0 53.1 72.840 97.0 53.4 72.760 97.0 53.5 72.880 97.0 52.9 72.5100 97.0 53.6 73.1120 97.0 53.1 72.7150 97.0 53.2 72.9180 97.0 53.4 73.1CF+WCF 40 97.0 53.1 72.8100 97.0 53.4 72.9160 97.0 53.4 72.9220 97.0 53.3 72.9280 97.0 53.2 72.8370 97.0 53.1 72.8The statistics of word emotion components inRen-CECps show that there are a total of 68 emo-tion components in all of 22,095 annotated emo-tion words without repetitions.
Figure 1 shows thegrowth curve of word emotion components num-ber with emotion word number increase.As can be seen from figure 1, the number in-crease of word emotion components shows a veryslow growth rate with the number increase ofemotion words.
We can conclude that the spaceof word emotion components is a relatively smallspace.In the model of MaxEnt based Chinese wordemotion recognition, the Pre-N-words EmotionFeature (PNEF) and emotion output can be en-coded to emotion components.Pre-N-words Emotion Components Feature(PNECF): The emotion components of its previ-ous words for a word (wi).
The value of this fea-ture is obtained only after the computation of theemotion components for its previous words.Table 4 gives the results of F-value for the com-bined contextual features and encoding feature.As can be seen in table 4, when Pre-N-wordsEmotion Feature (PNEF) is replaced by Pre-N-Figure 1: The growth curve of word emotion com-ponentswords Emotion Components Feature (PNECF),and emotion components are output as results, F-value is increased up to (a=97.3, b=57.3, c=73.3).Then based on this result, we firstly trained a wordemotion based model, then the word emotion out-puts of this model are used as Pre-N-words Emo-tion Feature (PNEF) for the word emotion com-ponents based model.
A significant F-value im-provement of task (b) and (c) (b=62.5, c=73.7)over only using contextual and semantic featureswas observed after adding the combined wordemotion and word emotion components as feature.5 Discussion5.1 Word Emotion Agreement on People?sJudgmentsThe final aim of a human-computer interactionrecognition system is to get the result close to peo-ple?s judgments.
As word emotion is inherentlyuncertain and subjective, here we report the anno-tation agreement on word emotion of Ren-CECps,which can be taken as an evaluation criteria for aalgorithm.To measure the annotation agreement of Ren-CECps, three annotators independently annotated26 documents with a total of 805 sentences,19,738 words.
We use the following two metricsto measure agreement on word emotion annota-tion.
(1) Kappa coefficient of agreement (Carletta,1996).
It is a statistic adopted by the computa-927Table 4: F-value for the combined contextual features and encoding featureFeature type Features F-value(a) (b) (c)WF+NF+POSF+PNECF+PDF+PNF+PCFf 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posif 4 = posi?1, posi, posi+1f 5 = pre es0, ..., pre esi?1f 6 =?
(wi?1 is a degree word)f 7 =?
(wi?1 is a negative word)f 8 =?
(wi?1 is a con junction)97.3 57.3 73.3WF+NF+POSF+PNEF+PNECF+PDF+PNF+PCFf 1 = wi f 2 = wi?1,wi,wi+1 f 3 = posif 4 = posi?1, posi, posi+1f 5 = pre e0, ..., pre ei?1f 6 = pre es0, ..., pre esi?1f 7 =?
(wi?1 is a degree word)f 8 =?
(wi?1 is a negative word)f 9 =?
(wi?1 is a con junction)97.3 62.5 73.7tional linguistics community as a standard mea-sure.
(2) Voting agreement.
It is used to mea-sure how much intersection there is betweenthe sets of word emotions identified by theannotators.
It includes majority-voting agree-ment (AgreementMV ) and all-voting agreement(AgreementAV ).
AgreementMV is defined as fol-lows.
Let A, B and C be the sets of word emo-tion components annotated by annotators a, b andc respectively.
The expert coder is the set of ex-pressions that agreed by at least two annotators,see equation (4).AgreementMV = Avg(count(ti = e j)count(ti) ) (4)In which, ti ?
T , e j ?
E, T = A?B?C, E =(A?B)?(A?C)?
(B?C).Accordingly, the expert coder of AgreementAVis the set of expressions that agreed by all annota-tors.The above two metrics are used to measure theagreements on: (a) determine if a word is an emo-tion or unemotion word; (b) determine the eightbasic emotions for emotion words (complete emo-tion matching); (c) determine the eight basic emo-tions for emotion words (single matching).
(b)and (c) are provided that at least two people to be-lieve the word is an emotion word.
Table 5 showsthe agreements measured by the two metrics.As shown in table 5, it is easier for annotators toagree at if a word contains emotion, but it is moredifficult to agree on emotions or emotion compo-nents of a word.
Compared with the agreement onpeople?s judgments, our experiments gave promis-ing results.Table 5: Agreement of word emotion annotationmeasured by Kappa, Majority-voting (MV), andAll-voting (AV)Measure Kappa MV AV(a) 84.3 98.5 95.1(b) 66.7 70.3 26.2(c) 77.5 100 84.95.2 Error AnalysisConducting an error analysis, we find that a lotof errors occur due to the recognition on multi-emotion words and indirect emotion words, espe-cially in short sentences because the features canbe extracted are too few.
So more features shouldbe considered from larger contexts, such as thetopic emotion of paragraph or document.There are some errors occur due to more thanone emotion holders exist in one sentence, for ex-928ample of sentence (4).
(4) ?uy?wX?a,?
"(Ifound that daughter was looking at the toys of herinterest.
)In sentence (4), three annotators all agree thatthe emotion components of the word ?a, (in-terest)?
is ?00000000?
since they believe that thisword is an unemotion word from the view of thewriter.
But our system give a result of ?00100000?because the emotion holder ?
? (daughter)?
ofthe emotion word ?a, (interest)?
has not beenconsidered in our algorithm.
Therefore, the recog-nition of emotion holder is indispensable for anaccurate emotion analysis system.In addition, Chinese segmentation mistakes andphrasing error also cause errors.6 ConclusionsAutomatically perceive the emotions from texthas potentially important applications in CMC(computer-mediated communication) that rangefrom identifying emotions from online blogs toenabling dynamically adaptive interfaces.
Thereinwords play important role in emotion expressionsof text.In this paper we explored features for recogniz-ing word emotions in sentences.
Different fromprevious researches on textual emotion recogni-tion that based on affective lexicons, we believethat besides obvious emotion words referring toemotions, there are words can potentially conveyemotions act only as an indirect reference.
Also,quite often words that bear emotion ambiguity andmultiple emotions are difficult to be recognizeddepending on emotion lexicons.
Emotion of aword should be determined with its context.Based on Ren-CECps (an annotated emotioncorpus) and MaxEnt (Maximum entropy) model,we have experimented several contextual featuresand their combination, then using PLSA (proba-bilistic latent semantic analysis), semantic featureare demonstrated the effectiveness for word emo-tion recognition.
A significant performance im-provement over only using contextual and seman-tic features was observed after adding encodingfeature (word emotion components).
Determiningintensity of word emotion and recognizing emo-tion of sentence or document based on word emo-tion are included in our future work.AcknowledgmentsThis research has been partially supported byMinistry of Education, Science, Sprots and Cul-ture, Grant-in-Aid for Challenging ExploratoryResearch, 21650030.
We also wish to acknowl-edge the anonymous reviewer?s insightful com-ments and suggestions.ReferencesJ.
R. Averill.
1975.
A semantic atlas of emotional con-cepts.
JSAS Catalog of Selected Documents in Psy-chology.Adam Berger, Vincent Della Pietra and Stephen A.Della Pietra.
1996.
A maximum entropy approachto natural language processing.
Computational Lin-guistic 22(1), pages 39?71.Plaban Kumar Bhowmick, Animesh Mukherjee, AritraBanik, Pabitra Mitra, Anupam Basu.
2008.
A com-parative study of the properties of emotional andnon-Emotional words in the Wordnet: A complexnetwork approach.
In Proceedings of Internationalconference on natural language processing (ICON2008).Jean Carletta.
1996.
Assessing agreement on classifica-tion tasks: the Kappa statistic.
Computational Lin-guistics.
22(2): 249-254.Z.
Dong and Q. Dong.
2003.
HowNet)a hybridlanguage and knowledge resource.
In Proceedingsof Int?l Conf.
Natural Language Processing andKnowledge Eng., pages 820?824.Paul Ekman.
1982.
Emotion in the human face.
Cam-bridge University Press.Andrea Esuli and Fabrizio Sebastiani.
2006.
Senti-WordNet: A publicly available lexical resource foropinion mining.
In Proceedings of the Fifth Inter-national Conference on Language Resources andEvaluation (LREC 2006), pages 417-422.James A. Hampton.
2007.
Typicality, gradedmembership, and vagueness.
Cognitive Science31:355?384.Thomas Hofmann.
1999.
Probabilistic latent semanticanalysis.
In Proceedings of the Fifteenth Conferenceon Uncertainty in Artificial Intelligence (UAI?99).Abe Kazemzadeh, Sungbok Lee, and ShrikanthNarayanan.
2008.
An interval type-2 fuzzy logicsystem to translate between emotion-related ocab-ularies.
In Proceedings of Interspeech.929Lun-Wei Ku, Yu-Ting Liang and Hsin-Hsi Chen.
2006.Tagging heterogeneous evaluation corpora for opin-ionated tasks.
In Proceedings of Conference onLanguage Resources and Evaluation (LREC 2006),pages 667-670.Chul Min Lee, Shrikanth S. Narayanan.
2005.
Towarddetecting emotions in spoken dialogs.
Journal ofthe American Society for Information Science.
IEEETrans.
on Speech and Audio Processing 13(2):293-303.Christopher D. Manning and Hinrich Schjtze.
1999.Foundations of statistical natural language process-ing.
Cambridge, MA: MIT Press.Gregory L. Murphy.
2002.
The Big Book of Concepts.Cambridge, MA: MIT Press.Andrew Ortony.
Gerald l. Clore.
Mark A. Foss.
1987.The referential structure of the affective lexicon.Cognitive Science 11:341-364.Andrew Ortony, Gerald L. Clore, Allan Collins.
1988.The Cognitive Structure of Emotions.
CambridgeUniversity Press.Robert Plutchik.
1962.
The emotions: Facts, theories,and a new model.
New York: Random House.Changqin Quan and Fuji Ren.
2010.
A blogemotion corpus for emotional expression analy-sis in Chinese.
Computer Speech & Language,24(4):726?749.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,and Daniel M. Ogilvie.
1966.
The General Inquirer:A computer approach to content analysis.
The MITPress.Carlo Strapparava and Alessandro Valitutti.
2004.Wordnet-affect: an affective extension of word-net.
In Proceedings of the 4th International Con-ference on Language Resources and Evaluation(LREC 2004), pages 1083-1086.Carlo Strapparava, Alessandro Valitutti, and OlivieroStock.
2006.
The affective weight of lexicon.
In Pro-ceedings of the Fifth International Conference onLanguage Resources and Evaluation (LREC 2006),pages 423-426.Carlo Strapparava, Alessandro Valitutti, OlivieroStock.
2007.
Dances with words.
In Proceed-ings of the Twentieth International Joint Confer-ence on Artificial Intelligence (IJCAI 2007), pages1719?1724.Hiroya Takamura, Takashi Inui, and Manabu Oku-mura.
Extracting emotional polarity of words usingspin model.
2005.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL 2005), pages 133?140.Ryoko Tokuhisa, Kentaro Inui, Yuji Matsumoto.
2008.Emotion classification using massive examples ex-tracted from the web.
In Proceedings of the 22nd In-ternational Conference on Computational Linguis-tics (Coling 2008).
pages 881?888.Francisco Virginia and GervSs Pablo.
2006.
Exploringthe compositionality of emotions in text: word emo-tions, sentence emotions and sutomated Tagging.
InProceedings of the AAAI-06 Workshop on Computa-tional Aesthetics: Artificial Intelligence Approachesto Beauty and Happiness, pages 16?20.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2009.
Recognizing Contextual Polarity: an explo-ration of features for phrase-level sentiment analy-sis.
Computational Linguistics 35(3): 1?34.930
