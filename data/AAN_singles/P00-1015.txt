A Unified Statistical Model for the Identification of EnglishBaseNPEndong XunMicrosoft Research ChinaNo.
49 Zhichun Road Haidian District100080, China,i-edxun@microsoft.comMing ZhouMicrosoft Research ChinaNo.
49 Zhichun Road Haidian District100080, China,Mingzhou@microsoft.comChangning HuangMicrosoft Research ChinaNo.
49 Zhichun Road Haidian District100080, China,cnhuang@microsoft.comAbstractThis paper presents a novel statisticalmodel for automatic identification ofEnglish baseNP.
It uses two steps: the N-best Part-Of-Speech (POS) tagging andbaseNP identification given the N-bestPOS-sequences.
Unlike the otherapproaches where the two steps areseparated, we integrate them into a unifiedstatistical framework.
Our model alsointegrates lexical information.
Finally,Viterbi algorithm is applied to makeglobal search in the entire sentence,allowing us to obtain linear complexity forthe entire process.
Compared with othermethods using the same testing set, ourapproach achieves 92.3% in precision and93.2% in recall.
The result is comparablewith or better than the previously reportedresults.1 IntroductionFinding simple and non-recursive base NounPhrase (baseNP) is an important subtask formany natural language processing applications,such as partial parsing, information retrieval andmachine translation.
A baseNP is a simple nounphrase that does not contain other noun phraserecursively, for example, the elements within[...] in the following example are baseNPs,where NNS, IN VBG etc are part-of-speech tags[as defined in M. Marcus 1993].
[Measures/NNS] of/IN [manufacturing/VBGactivity/NN] fell/VBD more/RBR than/IN[the/DT overall/JJ measures/NNS] ./.Figure 1: An example sentence with baseNPbracketsA number of researchers have dealt with theproblem of baseNP identification (Church 1988;Bourigault 1992; Voutilainen 1993; Justeson &Katz 1995).
Recently some researchers havemade experiments with the same test corpusextracted from the 20th section of the PennTreebank Wall Street Journal (Penn Treebank).Ramshaw & Markus (1998) applied transform-based error-driven algorithm (Brill 1995) tolearn a set of transformation rules, and usingthose rules to locally updates the bracketpositions.
Argamon, Dagan & Krymolowski(1998) introduced a memory-based sequenceslearning method, the training examples arestored and generalization is performed atapplication time by comparing subsequence ofthe new text to positive and negative evidence.Cardie & Pierce (1998 1999) devised errordriven pruning approach trained on PennTreebank.
It extracts baseNP rules from thetraining corpus and prune some bad baseNP byincremental training, and then apply the prunedrules to identify baseNP through maximumlength matching (or dynamic programalgorithm).Most of the prior work treats POS tagging andbaseNP identification as two separateprocedures.
However, uncertainty is involved inboth steps.
Using the result of the first step as ifthey are certain will lead to more errors in thesecond step.
A better approach is to consider thetwo steps together such that the final outputtakes the uncertainty in both steps together.
Theapproaches proposed by Ramshaw & Markusand Cardie&Pierce are deterministic and local,while Argamon, Dagan & Krymolowskiconsider the problem globally and assigned ascore to each possible baseNP structures.However, they did not consider any lexicalinformation.This paper presents a novel statistical approachto baseNP identification, which considers bothsteps together within a unified statisticalframework.
It also takes lexical information intoaccount.
In addition, in order to make the bestchoice for the entire sentence, Viterbi algorithmis applied.
Our tests with the Penn Treebankshowed that our integrated approach achieves92.3% in precision and 93.2% in recall.
Theresult is comparable or better that the currentstate of the art.In the following sections, we will describe thedetail for the algorithm, parameter estimationand search algorithms in section 2.
Theexperiment results are given in section 3.
Insection 4 we make further analysis andcomparison.
In the final section we give someconclusions.2 The statistical approachIn this section, we will describe the two-passstatistical model, parameters training and Viterbialgorithm for the search of the best sequences ofPOS tagging and baseNP identification.
Beforedescribing our algorithm, we introduce somenotations we will use2.1 NotationLet us express an input sentence E  as a wordsequence and a sequence of POS respectively asfollows:nn wwwwE 121 ... ?=nn ttttT 121 ... ?=Where n  is the number of words in thesentence, it  is the POS tag of the word iw .Given E, the result of the  baseNP identificationis assumed to be a sequence, in which somewords are grouped into baseNP as follows...]...[... 111 ++?
jjiii wwwwwThe corresponding tag sequence is as follows:(a)mjjiijjiii nnntbttttttB ............]...[... 211,1111 === +?++?In which jib ,  corresponds to the tag sequence ofa baseNP: ]...[ 1 jii ttt + .
jib ,   may also bethought of as a baseNP rule.
Therefore B is asequence of both POS tags and baseNP rules.Thus ???
innm ,1 (POS tag set ?
baseNPrules set), This is the first expression of asentence with baseNP annotated.
Sometime, wealso use the following equivalent form:(b)njjjjiiiiii qqqbmtbmtbmtbmtbmtQ ...)...,(),()...,(),(),...( 21111111 == ++++?
?Where each POS tag it  is associated with itspositional information ibm  with respect tobaseNPs.
The positional information is one of},,,,{ SOEIF .
F, E and I mean respectivelythat the word is the left boundary, rightboundary of a baseNP, or at another positioninside a baseNP.
O means that the word isoutside a baseNP.
S marks a single wordbaseNP.
This second expression is similar to thatused in [Marcus 1995].For example, the two expressions of the examplegiven in Figure 1 are as follows:(a)  B= [NNS] IN [VBG NN] VBD RBR IN [DT JJ NNS](b)  Q=(NNS S) (IN O) (VBG F) (NN E) (VBD O) (RBRO) (IN O) (DT F) (JJ I) (NNS E) (.
O)2.2 An ?integrated?
two-passprocedureThe principle of our approach is as follows.
Themost probable baseNP sequence *B  may beexpressed generally as follows:))|((maxarg* EBpBB=We separate the whole procedure into twopasses, i.e.
:)),|()|((maxarg* ETBPETPBB??
(1)In order to reduce the search space andcomputational complexity, we only consider theN best POS tagging of E, i.e.))|((maxarg)(,...,1ETPbestNTNTTT==?
(2)Therefore, we have:)),|()|((maxarg,...,,*1ETBPETPBNTTTB?
?=(3)Correspondingly, the algorithm is composed oftwo steps: determining the N-best POS taggingusing Equation (2).
And then determining thebest baseNP sequence from those POSsequences using Equation (3).
One can see thatthe two steps are integrated together, rather thatseparated as in the other approaches.
Let us nowexamine the two steps more closely.2.3 Determining the N best POSsequencesThe goal of the algorithm in the 1st pass is tosearch for the N-best POS-sequences within thesearch space (POS lattice).
According to Bayes?Rule, we have)()()|()|(EPTPTEPETP ?=Since )(EP  does not affect the maximizingprocedure of )|( ETP , equation (2) becomes))()|((maxarg))|((maxarg)(,...,,..., 11TPTEPETPbestNTNN TTTTTT?==?==(4)We now assume that the words in E areindependent.
Thus?=?niii twPTEP1)|()|((5)We then use a trigram model as anapproximation of )(TP , i.e.:?=??
?niiii tttPTP112 ),|()(                          (6)Finally we have))|((maxarg)(,...,1ETPbestNTNTTT==?
)),|()|((maxarg 121,...,1?
?==?= ?
iiiniiiTTTtttPtwPN(7)In Viterbi algorithm of N best search, )|( ii twPis called lexical generation (or output)probability, and ),|( 12 ??
iii tttP  is calledtransition probability in Hidden Markov Model.2.3.1 Determining the baseNPsAs mentioned before, the goal of the 2nd pass isto search the best baseNP-sequence given the N-best POS-sequences.Considering E ,T  and B as random variables,according to Bayes?
Rule, we have)|(),|()|(),|(TEPTBEPTBPETBP ?=Since )()()|()|(TPBPBTPTBP ?=  we have,)()|()()|(),|(),|(TPTEPBPBTPTBEPETBP??
?=       (8)Because we search for the best baseNP sequencefor each possible POS-sequence of  the givensentence E, soconstTEPTPTEP =?=?
)()()|( ,Furthermore from the definition of B, duringeach search procedure, we have?===nijiji bttPBTP1,1)|,...,()|( .
Therefore, equation(3) becomes)),|()|((maxarg,...,,*1ETBPETPBNTTTB?==))(),|()|((maxarg,...,, 1BPTBEPETPNTTTB?
?==(9)using the independence assumption, we have?=?niiii bmtwPTBEP1),|(),|((10)With trigram approximation of )(BP , we have:?=??
?miiii nnnPBP112 ),|()(                          (11)Finally, we obtain)),|(),|()|((maxarg,1121,..,*1??=??==?
?=miiiiniiiiTTTBnnnPtbmwPETPBN 12 To summarize, In the first step, Viterbi N-bestsearching algorithm is applied in the POStagging procedure, It determines a pathprobability tf  for each POS sequence calculatedas follows:?=??
?=niiiiiit tttptwpf,112 ),|()|( .In the second step, for each possible POStagging result, Viterbi algorithm is applied againto search for the best baseNP sequence.
EverybaseNP sequence found in this pass is alsoasssociated with a path probability??=?
?=?=miiiiniiiib nnnpbmtwpf,1121),|(),|( .The integrated probability of a baseNP sequenceis determined by bt ff ??
, where?
is anormalization coefficient (?
4.2=  in ourexperiments).
When we determine the bestbaseNP sequence for the given sentence E , wealso determine the best POS sequence of E ,which corresponds to the best baseNP of E .Now let us illustrate the whole process throughan example:  ?stock was down 9.1 pointsyesterday morning.?.
In the first pass, one of theN-best POS tagging result of the sentence is: T =NN VBD RB CD NNS NN NN.
For this POSsequence, the 2nd pass will try to determine thebaseNPs as  shown in Figure 2.
The details ofthe path in the dash line are given in Figure 3, Itsprobability calculated in the second pass is asfollows ( ?
is pseudo variable):),|(),|(),|(),|(),|( BCDNUMBERpORBdownpOVBDwaspSNNstockpETBP ???=).,|(.
),|(),|(),|int( OpENNmorningpBNNyesterdaypENNSspop ????
),|]([)],[|(])[,|(),|]([ RBVBDNNSCDpVBDNNRBpNNVBDpNNp ???????])[],[|(.
])[,|]([ NNNNNNSCDpNNSCDRBNNNNp ?
?Figure 2:  All possible brackets of  "stock was down 9.1 points yesterday morning"Figure 3:  the transformed form of  the path with dash line for the second pass processing2.4 The statistical parametertrainingIn this work, the training and testing data werederived from the 25 sections of Penn Treebank.We divided the whole Penn Treebank data intotwo sections, one for training and the other fortesting.As required in our statistical model, we have tocalculate the following four probabilities:(1) ),|( 12 ??
iii tttP , (2) )|( ii twP ,(3) )|( 12 ??
iii nnnP  and (4) ),|( iii bmtwP .
Thefirst and the third parameters are trigrams of Tand B respectively.
The second and the fourthare lexical generation probabilities.
Probabilities(1) and (2) can be calculated from POS taggeddata with following formulae:?
?????
?=jjiiiiiiii tttcounttttcounttttp )()(),|(121212(13))()()|(iiiii tcountttagwithwcounttwp =  (14)As each sentence in the training set has bothPOS tags and baseNP boundary tags, it can beconverted to the two sequences as B (a) and Q(b) described in the last section.
Using thesesequences, parameters (3) and (4) can becalculated, The calculation formulas are similarwith equations (13) and (14) respectively.Before training trigram model (3), all possiblebaseNP rules should be extracted from thetraining corpus.
For instance, the following threesequences are among the baseNP rules extracted.There are more than 6,000 baseNP rules in thePenn Treebank.
When training trigram model(3), we treat those baseNP rules in two ways.
(1)Each baseNP rule is assigned a unique identifier(UID).
This means that the algorithm considersthe corresponding structure of each baseNP rule.
(2) All of those rules are assigned to the sameidentifier (SID).
In this case, those rules aregrouped into the same class.
Nevertheless, theidentifiers of baseNP rules are still differentfrom the identifiers assigned to POS tags.We used the approach of Katz (Katz.1987) forparameter smoothing, and build a trigram modelto predict the probabilities of parameter (1) and(3).
In the case that unknown words areencountered during baseNP identification, wecalculate parameter  (2) and (4) in the followingway:2)),((max),(),|(ijjiiiii tbmcounttbmcounttbmwp =  (15)2))((max)()|(jjiii tcounttcounttwp =      (16)Here, jbm  indicates all possible baseNP labelsattached to it , and jt  is a POS tag guessed forthe unknown word iw .3 Experiment resultWe designed five experiments as shown in Table1.
?UID?
and ?SID?
mean respectively that anidentifier is assigned to each baseNP rule or thesame identifier is assigned to all the baseNPrules.
?+1?
and ?+4?
denote the number of beatPOS sequences retained in the first step.
And?UID+R?
means the POS tagging result of thegiven sentence is totally correct for the 2nd step.This provides an ideal upper bound for thesystem.
The reason why we choose N=4 for theN-best POS tagging can be explained in Figure4, which shows how the precision of POStagging changes with the number N.96.
9597.
0097.
0597.
1097.
1597.
2097.
2597.
3097.
3597.
4097.
451 2 3 4 5 6Figure 4:  POS tagging precision with respect todifferent number of N-bestIn the experiments, the training and testing setsare derived from the 25 sections of Wall StreetJournal distributed with the Penn Treebank II,and the definition of baseNP is the same asRamshaw?s, Table 1 summarizes the averageperformance on both baseNP tagging and POStagging, each section of the whole PennTreebank was used as the testing data and theother 24 sections as the training data, in this waywe have done the cross validation experiments25 times.Precision( baseNP %)Recall( baseNP %)F-Measure( baseNP %) 2RP +( baseNP %)Precision(POS %)UID+1 92.75 93.30 93.02 93.02 97.06UID+4 92.80 93.33 93.07 93.06 97.02SID+1 86.99 90.14 88.54 88.56 97.06SID+4 86.99 90.16 88.55 88.58 97.13UID+R 93.44 93.95 93.69 93.70 100Table 1  The average performance of the five experiments88.
0088.
5089.
0089.
5090.
0090.
5091.
0091.
5092.
0092.
5093.
001 2 3 4 5 6UI D+1UI D+4UI D+RFigure 5:  Precision under different training setsand different POS tagging results91.
6091.
8092.
0092.
2092.
4092.
6092.
8093.
0093.
2093.
4093.
601 2 3 4 5 6UI D+1UI D+4UI D+RFigure 6:  Recall under different training setsand different POS tagging results96.
8096.
8596.
9096.
9597.
0097.
0597.
1097.
1597.
201 2 3 4 5 6Vi t er biUI D+4SI D+4Figure 7:  POS tagging precision under differenttraining setsFigure 5 -7 summarize the outcomes of ourstatistical model on various size of the trainingdata, x-coordinate denotes the size of thetraining set, where "1" indicates that the trainingset is from section 0-8th of Penn Treebank, "2"corresponds to the corpus that add additionalthree sections 9-11th  into "1" and so on.
In thisway the size of the training data becomes largerand larger.
In those cases the testing data isalways section 20 (which is excluded from thetraining data).From Figure 7, we learned that the POS taggingand baseNP identification are influenced eachother.
We conducted two experiments to studywhether the POS tagging process can make useof baseNP information.
One is UID+4, in whichthe precision of POS tagging dropped slightlywith respect to the standard POS tagging withTrigram Viterbi search.
In the secondexperiment SID+4, the precision of POS tagginghas increase slightly.
This result shows that POStagging can benefit from baseNP information.Whether or not the baseNP information canimprove the precision of POS tagging in ourapproach is determined by the identifierassignment of the baseNP rules when trainingtrigram model of ),|( 12 ??
iii nnnP .
In thefuture, we will further study optimal baseNPrules clustering to further improve theperformances of both baseNP identification andPOS tagging.4 Comparison with otherapproachesTo our knowledge, three other approaches tobaseNP identification have been evaluated usingPenn Treebank-Ramshaw & Marcus?stransformation-based chunker, Argamon et al?sMBSL, and Cardie?s Treebank_lex in Table 2,we give a comparison of our method with otherthese three.
In this experiment, we use thetesting data prepared by Ramshaw (available athttp://www.cs.biu.ac.il/~yuvalk/MBSL), thetraining data is selected from the 24 sections ofPenn Treebank (excluding the section 20).
Wecan see that our method achieves better resultthan the others.Transformation-Based(Training data: 200k)Treebank_Lex MBSL Unified StatisticalPrecision (%) 91.8 89.0 91.6 92.3Recall (%) 92.3 90.9 91.6 93.2F-Measure (%) 92.0 89.9 91.6 92.72RP + 92.1 90.0 91.6 92.8Table 2: The comparison of our statistical method with three other approachesTransforamtion-Based Treebank_Lex MBSL Unified StatisticalUnifying POS &baseNP NO NO NO YESLexical Information YES YES NO YESGlobal Searching NO NO YES YESContext YES NO YES YESTable 3: The comparison of some characteristics of our statistical method with three other approachesTable 3 summarizes some interesting aspects ofour approach and the three other methods.
Ourstatistical model unifies baseNP identificationand POS tagging through tracing N-bestsequences of POS tagging in the pass of baseNPrecognition, while other methods use POStagging as a pre-processing procedure.
FromTable 1, if we reviewed 4 best output of POStagging, rather that only one, the F-measure ofbaseNP identification is improved from 93.02 %to 93.07%.
After considering baseNPinformation, the error ratio of POS tagging isreduced by 2.4% (comparing SID+4 withSID+1).The transformation-based method (R&M 95)identifies baseNP within a local windows ofsentence by matching transformation rules.Similarly to MBSL, the 2nd pass of our algorithmtraces all possible baseNP brackets, and makesglobal decision through Viterbi searching.
Onthe other hand, unlike MSBL we take lexicalinformation into account.
The experiments showthat lexical information is very helpful toimprove both precision and recall of baseNPrecognition.
If we neglect the probability of?=niiii bmtwP1),|(  in the 2nd pass of our model,the precision/recall ratios are reduced to90.0/92.4% from 92.3/93.2%.
Cardie?s approachto Treebank rule pruning may be regarded as thespecial case of our statistical model, since themaximum-matching algorithm of baseNP rulesis only a simplified processing version of ourstatistical model.
Compared with this rulepruning method, all baseNP rules are kept in ourmodel.
Therefore in principle we have lesslikelihood of failing to recognize baseNP typesAs to the complexity of algorithm, our approachis determined by the Viterbi algorithm approach,or )(nO , linear with the length.5 ConclusionsThis paper presented a unified statistical modelto identify baseNP in English text.
Comparedwith other methods, our approach has followingcharacteristics:(1) baseNP identification is implemented in tworelated stages: N-best POS taggings are firstdetermined, then baseNPs are identified giventhe N best POS-sequences.
Unlike otherapproaches that use POS tagging as pre-processing, our approach is not dependant onperfect POS-tagging, Moreover, we can applybaseNP information to further increase theprecision of POS tagging can be improved.These experiments triggered an interestingfuture research challenge: how to cluster certainbaseNP rules into certain identifiers so as toimprove the precision of both baseNP and POStagging.
This is one of our further researchtopics.
(2) Our statistical model makes use of morelexical information than other approaches.
Everyword in the sentence is taken into account duringbaseNP identification.
(3) Viterbi algorithm is applied to make globalsearch at the sentence level.Experiment with the same testing data used bythe other methods showed that the precision is92.3% and the recall is 93.2%.
To ourknowledge, these results are comparable with orbetter than all previously reported results.ReferencesEric Brill and Grace Ngai.
(1999) Man vs. machine:A case study in baseNP learning.
In Proceedings ofthe 18th International Conference on ComputationalLinguistics, pp.65-72.
ACL?99S.
Argamon, I. Dagan, and Y. Krymolowski  (1998)A memory-based approach to learning shallowlanguage patterns.
In Proceedings of the 17thInternational Conference on ComputationalLinguistics, pp.67-73.
COLING-ACL?98Cardie and D. Pierce (1998) Error-driven pruning oftreebank grammas for baseNP identification.
InProceedings of the 36th  International Conferenceon Computational Linguistics, pp.218-224.COLING-ACL?98Lance A. Ramshaw and Michael P. Marcus ( InPress).
Text chunking using transformation-basedlearning.
In Natural Language  Processing UsingVery large Corpora.
Kluwer.
Originally appearedin The second workshop on very large corporaWVLC?95, pp.82-94.Viterbi, A.J.
(1967) Error bounds for convolutioncodes and asymptotically optimum decodingalgorithm.
IEEE Transactions on InformationTheory IT-13(2): pp.260-269, April, 1967S.M.
Katz.
(1987) Estimation of probabilities fromsparse data for the language model component ofspeech recognize.
IEEE Transactions on Acoustics,Speech and Signal Processing.
Volume ASSP-35,pp.400-401, March 1987Church, Kenneth.
(1988) A stochastic parts programand noun phrase parser for unrestricted text.
InProceedings of the Second Conference on AppliedNatural Language Processing, pages 136-143.Association of Computational Linguistics.M.
Marcus, M. Marcinkiewicx, and B. Santorini(1993) Building a large annotated corpus ofEnglish: the Penn Treebank.
ComputationalLinguistics, 19(2): 313-330
