Characterizing and Predicting Correctionsin Spoken Dialogue SystemsDiane Litman?University of PittsburghJulia Hirschberg?Columbia UniversityMarc Swerts?Tilburg UniversityThis article focuses on the analysis and prediction of corrections, defined as turns where auser tries to correct a prior error made by a spoken dialogue system.
We describe our labelingprocedure of various corrections types and statistical analyses of their features in a corpuscollected from a train information spoken dialogue system.
We then present results of machine-learning experiments designed to identify user corrections of speech recognition errors.
Weinvestigate the predictive power of features automatically computable from the prosody of theturn, the speech recognition process, experimental conditions, and the dialogue history.
Ourbest-performing features reduce classification error from baselines of 25.70?28.99% to 15.72%.1.
IntroductionCompared to many other systems, spoken dialogue systems (SDS) tend to have moredifficulties in correctly interpreting user input.
Whereas a car normally goes left if thedriver turns the steering wheel in that direction or a vacuum cleaner starts working ifone pushes the on button, interactions between a user and a spoken dialogue systemare often hampered by mismatches between the action intended by the user and theaction executed by the system.
Such mismatches are mainly due to errors in the Auto-matic Speech Recognition (ASR) and/or the Natural Language Understanding (NLU)component of these systems; they can also be due to wrong default assumptions of thesystem or the fact that a user asks out-of-topic questions for which the system was notdesigned.
To solve these mismatches, users often have to put considerable effort intotrying to make it clear to the system that there was a problem, and trying to correct it byreentering misrecognized or misinterpreted information.
Previous research has alreadybrought to light that it is not always easy for users to determine whether their intendedactions were carried out correctly or not, in particular when the dialogue system doesnot give appropriate feedback about its internal representation at the right moment.In addition, users?
corrections may miss their goal because corrections themselves aremore difficult for the system to recognize and interpret correctly, which may lead toso-called cyclic (or spiral) errors.?
E-mail: litman@cs.pitt.edu.?
E-mail: julia@cs.columbia.edu.?
E-mail: m.g.j.swerts@uvt.nl.Submission received: 12 January 2005; revised submission received: 3 April 2006; accepted for publication:4 May 2006?
2006 Association for Computational LinguisticsComputational Linguistics Volume 32, Number 3Given that current spoken dialogue systems are not sufficiently robust, there isneed for sophisticated error-handling strategies to gracefully solve communicationproblems between the system and the user.
Ideally, apart from strategies to preventerrors, error handling would consist of steps to immediately detect an error whenit occurs and to interact with the user to correct the error in subsequent exchanges.To date, attempts to improve system performance have largely focused on improv-ing ASR accuracy or simplifying the task, either by further constraining the domainand functionality of the system or by further restricting the vocabulary the systemmust recognize.
Such studies include work on improved acoustic and semantic con-fidence scores (Ammicht, Potamianos, and Fosler-Lussier 2001; Andorno, Laface, andGemello 2002; Bouwman, Sturm, and Boves 1999; Falavigna, Gretter, and Riccardi2002; Guillevic, Gandrabur, and Normandin 2002; Moreno, Logan, and Raj 2001; Wangand Lin 2002; Zhang and Rudnicky 2001), on new system architectures for error han-dling (McTear et al 2005; Prodanov and Drygajlo 2005; Torres et al 2005), on newinterfaces that are more user-friendly for error recovery (Bulyko et al 2005; Karsentyand Botherel 2005; Sturm and Boves 2005), and on the use of error-recovery strategiesthat are based on analyses of human?human dialogues (Skantze 2005), including theuse of facial expressions (Barkhuysen, Krahmer, and Swerts 2005).However, as ASR accuracy improves, dialogue systems will be called upon tohandle ever more complex tasks and ever less restricted vocabularies.
So, it seems likelythat spoken dialogue systems will, for the foreseeable future, always require effectiveerror detection and repair strategies.
In previous research (Hirschberg, Litman, andSwerts 1999, 2004), we identified new procedures to detect recognition errors, whichperform well when tested on two different corpora, the TOOT and W99 corpora (traininformation and conference registration dialogues) collected using two different ASRsystems (Sharp et al 1997; Kamm et al 1997).
We found that prosodic features, incombination with information already available to the recognizer, such as acousticconfidence scores, grammar, and recognized string, can distinguish speaker turns thatare misrecognized far better than traditional methods for ASR rejection (the systemdecision that its hypothesis is so weak that it should reprompt for fresh input), whichuse acoustic confidence scores alone.
Related work has been done by Lendvai (2004)and Batliner et al (2003).
In the current study, we turn to the question of how people tryto correct ASR errors in their interactions with machines and the role that prosody mayplay in identifying user corrections and in helping to analyze them.Understanding how users attempt to correct system failures and why their attemptssucceed or fail is important to improve the design of future spoken dialogue systems.For example, knowing whether they are more likely to repeat or rephrase their utter-ances, add new information or shorten their input, and how system behavior influencesthese choices can suggest appropriate on-line modifications to the system?s interactionstrategy or to the recognition procedure it employs.
Determining which speaker behav-iors are more successful in correcting system errors can also lead to improvements in thehelp information such systems provide.
There is growing evidence that there is muchvariance in the way people react to system errors and that the variance can be explainedon the basis of particular properties of the dialogue system or the dialogue context.
Inparticular, dialogue confirmation strategies may hinder users?
ability to correct systemerror.
For instance, if a system wrongly presents information as being correct, as when itverifies information implicitly, users become confused about how to respond (Krahmeret al 2001).
Other studies have shown that speakers tend to switch to a prosodically?marked?
speaking style after communication errors, comparing repetition correctionswith the speech being repeated (Wade, Shriberg, and Price 1992; Oviatt et al 1996;418Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue SystemsLevow 1998; Bell and Gustafson 1999).
Although this speaking style may be effective inproblematic human?human communicative settings, there is evidence that suggests itleads to further errors in human?machine interactions (Levow 1998; Soltau and Waibel2000).
That corrections are difficult for ASR systems is generally explained by the factthat they tend to be hyperarticulated?higher, louder, longer?than other turns (Wade,Shriberg, and Price 1992; Oviatt et al 1996; Levow 1998; Bell and Gustafson 1999;Shimojima, et al 2001; Soltau and Waibel 1998, 2000; Soltau, Metze, and Waibel 2002),where ASR models are not well adapted to handle this special speaking style, althoughrecent studies suggest that ASR systems are becoming less vulnerable to hyperarticula-tion (Bulyko et al 2005).So, repair strategies in human?machine interactions can be more or less effective.Therefore, increased knowledge about the efficiency of different correction strategiescan lead to a number of possible courses of action.
System strategy might be chosen tofavor the type(s) of correction the system can most easily process.
Or, having chosen aparticular interaction strategy, the system repair strategy might be tuned to handle thecorrection types that that strategy is likely to produce.
Alternatively, the system?s dia-logue manager might use the detection of corrections as a signal that it should modify itsinteraction strategy, either locally, by beginning a subdialogue for faster error recovery,or globally, by changing its initiative or confirmation strategies, or even directing theuser to a human operator.
Or, since corrections are often hyperarticulated, detection ofa correction could serve as a signal to the ASR engine to run a recognizer trained onhyperarticulated speech in parallel with its normal processor, to better transcribe thespeech.
All of these possibilities, however, assume that user corrections can be detectedby the system reliably during the dialogue.In this article, we describe an analysis of user corrections of system error collected inthe TOOT spoken dialogue system.
In the next section, we describe the corpus itself andhow it was collected and labeled.
The corpus is suitable to gain insight into the differentcorrection strategies that speakers exploit in different dialogue contexts and interactionstyles.
Then, we characterize the nature of corrections in this corpus in terms of whenthey occur, how well they are handled by the system, what distinguishes their prosodyfrom other utterances, their relationship to the utterances they correct, and how theydiffer according to dialogue strategy.
Then we present results of some machine-learningexperiments designed to automatically distinguish corrections from other user input,using features that we derived as potentially useful from our descriptive analyses.2.
The Data2.1 The TOOT CorpusOur corpus consists of dialogues between human subjects and TOOT, a spoken dialoguesystem that allows access to train information from the Web via telephone.
TOOTwas collected to study variations in dialogue strategy and in user-adapted interac-tion (Litman and Pan 1999).
It is implemented using an interactive voice response(IVR) platform developed at AT&T, combining ASR and text-to-speech with a phoneinterface (Kamm et al 1997).
The system?s speech recognizer is a speaker-independent,hidden Markov model system with context-dependent phone models for telephonespeech and constrained (rule-based) grammars defining vocabulary at any dialoguestate.
Whereas a ?universal?
grammar specifying all legal utterances was used at somepoints in the dialogue, seven smaller grammars were also used at many points in thedialogue (e.g., to recognize city names, days of the week, answers to yes/no questions,419Computational Linguistics Volume 32, Number 3etc.).
Grammars were only written for originally expected answers; in other words,no specific grammar for corrections was built in.1 Confidence scores for recognitionwere available only at the turn level and were based on acoustic likelihoods; thresh-olds for rejecting an utterance based on confidence scores were specified manually bythe system designers and were set differently for different grammars.
The platformsupports barge-in.
Subjects performed four tasks with one of several versions of thesystem that differed in terms of locus of initiative (system, user, or mixed), confirmationstrategy (explicit, implicit, or none), and whether these conditions could be changedby the user during the task (adaptive vs. non-adaptive).
In the adaptive version ofthe system, users were allowed to say change strategy at any point(s) in the dialogue.TOOT would then ask the user to specify new initiative and confirmation strategies,for example, You are using the no confirmation strategy.
Which confirmation strategy doyou want to change to?
No confirmation, implicit confirmation, or explicit confirmation?TOOT?s initiative strategy specifies who has control of the dialogue, whereas TOOT?sconfirmation strategy specifies how and whether TOOT lets the user know what it justunderstood.
The fragments in Figure 1 provide some illustrations of how dialoguesvary with strategy.
For example, in user initiative mode, the system allows the userto specify any number of attributes in a single utterance.
Thus, the system will let theuser ignore specific questions.
In the example in Figure 1, although the system asks forthe day of the week, the user answers with the time, which can be recognized due to theuse of the ?universal grammar.?
In contrast, in both mixed and system initiative mode,when a specific question is asked, one of the restricted grammars is used to recognizethe response.
Finally, in universal and mixed but not system initiative mode, the sys-tem can ask both specific questions and open-ended questions (e.g., How may I helpyou?).
Subjects were 39 students: 20 native speakers and 19 non-native, 16 womenand 23 men.
Dialogues were recorded and system and user behavior were loggedautomatically.
The concept accuracy (CA) of each turn was manually labeled.
If theASR correctly captured all task-related information in the turn (e.g., time, departure,and arrival cities), the turn?s CA score was 1 (semantically correct).
Otherwise, the CAscore reflected the percentage of correctly recognized task information in the turn.
Thedialogues were also transcribed and automatically scored in comparison to the ASRrecognized string (the best hypothesis output by the ASR engine) to produce a worderror rate (WER) for each turn.
For the study described below, we examined 2,328 userturns (all user input between two system inputs) from 152 dialogues.2.2 LabelingTo identify corrections in the corpus two authors independently labeled each turn asto whether or not it constituted a correction of a prior system failure (a rejection or CAerror, which were the only system failure subjects were aware of) and subsequentlydecided upon a consensus label.
Note that many of the discrepancies between labelswere due to tiredness or incidental sloppiness of individual annotators, rather than truedisagreement.
Each turn labeled ?correction?
was further classified as belonging to oneof the following categories: REP (repetition, including repetitions with differences inpronunciation or fluency), PAR (paraphrase), ADD (task-relevant content added), OMIT1 Thus, if the system prompted for a single city, but the user also included a correction of a prior utterance(e.g., No, at 10:30 p.m.
I want to go to New York City), the turn would be out of grammar.
Coding ourcorpus for out of vocabulary turns and examining whether corrections are more likely to be out ofgrammar is an area for future work.420Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue SystemsFigure 1Illustrations of various dialogue strategies in TOOT.
(content omitted), and ADD/OMIT (content both added and omitted).
Repetitionswere further divided into repetitions with pronunciation variation (PRON) (e.g., yescorrecting yeah) and repetitions where the correction was pronounced using the samepronunciation as the original turn, but this distinction was difficult to make and turnedout not to be useful.
User turns that included both corrections and other speech actswere so distinguished by labeling them ?2+.?
For example, the turn I would like to goto Chicago from Baltimore change strategies system contains not only an ADD correction,but also a request to adapt the system?s dialogue strategies, followed by an informof the desired initiative value.
As another example, the turn yes help contains a REPcorrection, followed by a request for help.
For user turns containing a correction plusone or more additional dialogue acts, only the correction is used for purposes of analysisbelow.
We also labeled as ?restarts?
user corrections that followed non-initial system-initial prompts (e.g., How may I help you?
or What city do you want to go to?
); in suchcases, system and user essentially started the dialogue over from the beginning.2 Table 1shows examples of each correction type and additional label for corrections of systemfailures on I want to go to Boston on Sunday.
Note that the utterance on the last line of thisfigure is labeled 2+PAR, given that this turn consists of two speech acts: The goal of theno-part of this turn is to signal a problem, whereas the remainder of this turn serves tocorrect a prior error.Each correction was also indexed with an identifier representing the closest priorturn it was correcting, so that we could investigate ?chains?
of corrections of a singlefailed turn by tracing back through subsequent corrections of that turn.
Figure 2 showsa fragment of a TOOT dialogue with corrections labeled as discussed above.3.
Descriptive AnalysesThis section presents the results of some descriptive analyses of the corrections welabeled in the TOOT corpus.
We provide data on the distribution of different correction2 Restarts occurred when either the user said the phrase I?m done here at any point in the dialogue, oranswered no to the system?s request to perform a database query (e.g., Do you want me to find the trainsfrom Baltimore to Chicago on Tuesday around 8:45 now?
).421Computational Linguistics Volume 32, Number 3Table 1Example corrections of I want to go to Boston on Sunday.Corr Type CorrectionREP I want to go to Boston on SundayPAR To Boston on SundayOMIT I want to go to BostonADD To Boston on Sunday at 8 p.m.ADD/OMIT I want to arrive Sunday at 8 p.m.2+PAR No, to Boston on Sundaytypes, prosodic features of corrections, characteristics of correction chains, and variationin features of corrections as a function of dialogue strategy.3.1 Correction TypesOf the correction types we labeled, the largest numbers were REPs and OMITs, asshown in Table 2, which shows overall distribution of correction types, and distri-butions for each type of system failure corrected, following either a misrecognizedturn (with respect to concept accuracy) (Post-Misrec) or a rejected turn (Post-Rej) orcorrecting an earlier system failure (Non-Immed).
(The last group includes correctionsof earlier utterances that do not immediately follow a rejection or misrecognition.
)Table 2 shows that 39% of TOOT corrections were simple repetitions of a previouslyrejected or misrecognized turn.
Although this strategy is often suboptimal in correctingASR errors (Levow 1998), REPs (45% WER error) and OMITs (52% error) were betterrecognized than ADDs (90% WER error) and PARs (72% WER error).Figure 2Toot dialogue fragment with correction labels.422Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue SystemsTable 2Distribution of correction types.Type ADD ADD/OMIT OMIT PAR REP NTotal 51 8% 14 2% 215 32% 127 19% 265 39% 672Post-Misrec 39 7% 13 3% 203 40% 90 18% 173 32% 518Post-Rej 8 6% 0 0% 9 7% 36 28% 75 59% 128Non-Immed 4 15% 1 4% 3 12% 1 4% 17 65% 26There was no significant difference either in the number of corrections produced(?
= 2.44, p = .12) or in correction type (?2 = 5.07, p = .28) between our native speakersubjects and non-native speakers.
However, what the user was correcting did influencethe type of correction chosen.
Table 2 shows that corrections of misrecognitions (Post-Misrec) were more likely to omit information present in the original turn (OMITs),whereas corrections of rejections (Post-Rej) were more likely to be simple repetitions.The latter finding is not surprising because the rejection message for tasks was alwaysa close paraphrase of Sorry, I can?t understand you.
Can you please repeat your utterance?However, it does suggest the surprising power of system directions and how impor-tant it is to craft prompts to favor the type of correction most easily recognized bythe system.3.2 Prosodic Features of CorrectionsIn part to test the hypothesis that corrections tend to be hyperarticulated (slower andlouder speech that contains wider pitch excursions and more internal silence), weexamined the following features for each user turn: maximum and mean fundamentalfrequency values (f0 Max, f0 Mean); maximum and mean energy values (RMS Max,RMS Mean); total duration; length of pause preceding the turn (Prior Pause); speakingrate (Tempo), calculated in syllables per second (sps); and amount of silence withinthe turn (% Silence).3 f0 and RMS values, representing measures of pitch excursionand loudness, were calculated from the output of Entropic Research Laboratory?s pitchtracker, get f0 (Talkin 1995), with no postcorrection.
Timing variation was representedby four features: Duration of turn and length of pause between turns was hand labeled.Speaking rate was approximated in terms of syllables in the recognized string persecond.
% Silence was defined as the percentage of zero frames in the turn, calculatedfrom the pitch track; this feature approximates the percentage of time within the turnthat the speaker was silent.To ensure that our results were speaker independent, we calculated mean val-ues for each speaker?s corrections and non-corrections for every feature.
Then, foreach feature, we created vectors of speaker means for correction and non-correctionturns and performed paired t tests on the paired vectors.
For example, for the feature?f0 Max,?
we calculated mean maxima for correction turns and for non-correctionsfor each of our thirty-nine speakers.
We then performed a paired t test on these3 Although the features were automatically computed, turn beginnings and endings were hand segmentedin dialogue-level speech files, as the turn-level files created by TOOT were not available.
Because of somesystem/user overlap in the recordings, we were able to calculate prosodic features for only 1,975 userturns.423Computational Linguistics Volume 32, Number 3thirty-nine pairs of means to derive speaker-independent results for differences inf0 maxima between corrections and non-corrections.
Note, however, that there wereoverall differences in the corrections produced by native and non-native speakers,normalized by value of first turn in task: mean f0 was higher for native speakers thanfor non-native speakers (t stat = ?2.72, df = 602, p = .0067), tempo was faster (t stat =?3.18, df = 670, p = .0015), and duration was shorter (t stat = 2.20, df = 670, p = .028).These differences do not occur in non-correction utterances.Our results provide some explanation for why corrections are more poorly re-cognized than non-corrections because they indicate that corrections are indeedcharacterized by prosodic features associated with hyperarticulation.
Table 3 showsthat corrections differ from other turns in that they are longer, louder, higher inpitch excursion, follow longer pauses, and contain less internal silence than non-corrections.
All but the latter difference supports the hypothesis that corrections tendto be hyperarticulated.To confirm this hypothesis, two of the authors labeled each turn in the corpus forevidence of perceptual hyperarticulation, following (Wade, Shriberg, and Price 1992).Fifty-two percent of corrections in the corpus have some perceptual hyperarticulation,compared with only 12% of other turns.
Too, hyperarticulated corrections are morelikely to be misrecognized than other corrections (70% misrecognitions vs. 52%).
How-ever, it is important to note that only 59% of misrecognized corrections in the corpus arealso hyperarticulated, so recognition failure for a considerable portion of correctionsmust be explained in some other way.
There is still a large number of misrecognizedcorrections that show no perceptual evidence of hyperarticulation.In our earlier analysis of prosodic differences between correct and incorrectlyrecognized turns (Hirschberg, Litman, and Swerts 2004), we also found that misrecog-nized turns differed from correctly recognized turns in f0, loudness, duration, andtiming?all features associated with hyperarticulation.
In addition, more misrecogni-tions are hyperarticulated than are correctly recognized turns.
But when we excludedperceptually hyperarticulated turns from our prosodic analysis, we found that mis-recognized turns were still prosodically different from correctly recognized turns, inthe same ways.
We hypothesized there that misrecognitions might exhibit tendenciestoward hyperarticulation that are imperceptible to human listeners, but not to ASRengines.
The same may also be true of non-hyperarticulated, but still prosodicallydistinct corrections.
When we exclude hyperarticulated utterances from our corpusTable 3Corrections versus non-corrections by prosodic feature.Feature t stat Mean corr p- non-corrf0 Max* 3.79 17.76 Hz < .001f0 Mean 0.23 ?4.12 Hz .823RMS Max* 4.88 347.75 < .001RMS Mean* 2.57 63.44 .014Duration* 6.68 1.16 sec < .001Prior pause* 2.17 0.186 sec .036Tempo 1.78 ?0.15 sps .246% Silence* 4.75 ?0.05% < .001*Significant at a 95% confidence level (p ?
.05)424Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue Systemsand reanalyze prosodic features of corrections versus non-corrections, we find signif-icant differences in duration, rms maximum, rms mean, tempo, and amount of turn-internal silence as we did with the corpus as a whole.
So, again, even when correctionsare not perceptibly hyperarticulated, they share some acoustic tendencies with turnsthat are.3.3 Correction ChainsAs noted above, corrections in the TOOT corpus often take the form of chains ofcorrections of a single original error.
Looking back at Figure 2, for example, we seetwo chains of corrections: In the first, which begins with the misrecognition of turn 776(Um, tomorrow), the user repeats the original phrase and then provides a paraphrase(Saturday), which is correctly recognized.
In the second, beginning with turn 780, thetime of departure is misrecognized.
The user omits some information (a.m.) in turn781, but without success; an ADD correction follows, with the previously omittedinformation restored, in turn 783.Distance of a correction from the original misrecognized turn?whether calculatedas position in chain (e.g., Saturday in Figure 2 is the second in the chain correctingturn 776) or further in number of turns from that original error (e.g., Saturday here isalso two turns from the original error)?correlates significantly with prosodic variation.An analysis of the relationship between both distance measures and our prosodicfeatures (using Pearson?s product?moment correlation) shows significant correlationsof distance in chain or from original error with f0 maximum (r = .20, p < .001; r = .21,p < .001) and mean (r = .27, p < .001; r = .29, p < .001), rms maximum (r =?.09, p < .02;r = ?.12, p < .005) and mean (r = ?.12, p < .0025; r = ?.16, p < .001), absolute duration(r = .14, p < 0; r = .16, p < .001) and duration in number of words (r = .11, p < .01; r =.12, p < .005), length of preceding pause (r = .11, p < .005; r = .10, p < .01), and speakingrate (r = ?.05, p < .01; r = ?.10, p < .02).
The more distant a correction is, in short, thehigher it is in pitch, the softer it is, the longer it is, the greater is its preceding pause, andthe more slowly it is spoken.
In addition, more distant corrections are also more likelyto be misrecognized; for distance in turns there is a (negative) significant correlation forconcept accuracy (r = ?.13, p < .001), whereas both word and concept accuracy declinesignificantly by position in chain (r = ?.08, p < .05; r = ?.15, p < .001).
Table 4 showsthe mean concept accuracy of corrections for chain position through 8 (higher numbersare very small) in the corpus.
So, as speakers must try again and again to correct anerror, their attempts appear to become ever less likely to succeed, perhaps because theirprosodic behavior changes in ways that do not help the recognition process.
Curiously,however, our perceptual measure of hyperarticulation is not significantly correlatedwith either of these distance measures.
So, although speakers modify their speech inways generally consistent with hyperarticulation, their corrections do not necessarilybecome more hyperarticulated as their attempts to correct continue.
Another curiousTable 4Mean concept accuracy by correction position in Chain.Position 1 2 3 4 5 6 7 8N 311 143 84 49 25 15 10 4Error .43 .57 .63 .51 .60 .87 .70 1.00425Computational Linguistics Volume 32, Number 3finding is that corrections that are more distant from the turn they immediately correct(e.g., in Figure 2, turn 783 is more distant from the turn it corrects (781) than turn 781 isfrom the turn it corrects, which is 780) tend to be more accurately recognized than turnsthat are closer.
Yet, prosodically, these turns are very like distant turns in a chain or fromthe original error, being higher in f0 maximum and mean, lower in rms maximum andmean, and longer in seconds and number of words.
So, in the one case these prosodicchanges might be thought to lead to recognition error, where in the other they occurwith better recognized corrections.3.4 Variation by Dialogue StrategyDialogue strategy clearly affects the type of correction users make and whether itis successful or not.
For example, users more frequently repeat their misrecognizedutterance in the SystemExplicit (75% of corrections are repetitions) condition than inthe MixedImplicit or UserNoConfirm (both 37% REP); the latter conditions have largerproportions of OMITs and paraphrases.
Perhaps this disparity is partly explained by thelarger proportion of corrections that follow rejections in the SystemExplicit condition(39% vs. 22% and 19%).
Overall, SystemExplicit turns are rejected 6% of the time,whereas the other conditions have about 10% rejections.
Table 5 shows differences inmean length of tasks, number of corrections, number of misrecognitions, and numberof misrecognized corrections by dialogue strategy.
Again, misrecognitions were definedin terms of concept accuracy (turns with CA < 1); misrecognized corrections refer tothe intersection of user terms that were coded as both corrections and misrecognitions.The fewer misrecognitions, corrections, and misrecognized corrections per task in theSystemExplicit condition may well explain user ratings of the various systems (non-adapt) in the original experiments (Litman and Pan 1999): When asked to say whetherthey would be likely to use such a system in the future, on a 1?5 scale, subjects scoredSystemExplicit 3.5, MixedImplicit 2.6, and UserNoConfirm 1.7.
User satisfaction scoreswere similar: Where 40 is the highest score, users gave SystemExplicit 31.25, Mixed-Implicit 24, and UserNoConfirm 22.1.
So, SystemExplicit is preferred by users, eventhough MixedImplicit on average takes fewer turns to accomplish a task, suggestingthat the large number of misrecognitions and consequent need for correction has a largeimpact on user preferences.
This is consistent with performance functions derived fromevaluations of TOOT (Litman and Pan 1999).Perhaps because correction chains often end unsuccessfully, users frequently?restart?
a task within a session.
Most restarts occurred in the MixedImplicit andUserNoConfirm conditions and were rarely successful.
In non-adaptive tasks, 42% ofcorrections in the MixedImplicit condition were restarts and 31% in the UserNoConfirm,Table 5Corrections by system strategy.Means SystemExplicit MixedImplicit UserNoConfirmper task# Turns 13.4 11.7 16.2# Corrs 1.3 4.6 7.1# Misrecs 2.8 6.4 9.4# Misrec?d Corrs 0.3 3.2 4.8426Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue Systemswhereas none occurred in the SystemExplicit condition.
Restarts were misrecognized77% of the time, compared to 65% of first turns in task.
They thus seem to have beena worse strategy than initiating a new task and might prove a useful diagnostic forchanging system strategy?or summoning a human operator.4.
Predicting CorrectionsThe previous section showed that corrections differ significantly from non-correctionsprosodically, being higher in pitch, louder, longer, with longer pauses preceding themand less internal silence.
In addition, they are misrecognized more frequently thannon-corrections?although they are no more likely to be rejected by the system.
Andcorrections more distant from the error they correct tend to exhibit greater prosodicdifferences and are recognized more poorly, suggesting that users are not learning tomodify their own behavior to improve system performance.
So, dealing with correctionsis a particularly difficult task for both users and systems.
We also found that system dia-logue strategy?the amount of initiative users are allowed to exercise in controlling theflow of the dialogue and the type of confirmation strategy the system adopts?affectsusers?
choice of correction type (e.g., directly repeating vs. paraphrasing misrecognizedinformation).
In the following, we turn to the question of identifying user correctionsautomatically, from prosodic features as well as other features that are readily availableto a spoken dialogue system.
In Section 4.1, we describe the features we use for ourmachine-learning experiments.
Section 4.2 presents the results of those experiments.Section 4.3 presents further experiments using additional classifications and features,motivated by our descriptive results.
In the final section, we summarize our conclusionsand describe future research directions.4.1 FeaturesIn this section we describe the features used in the machine-learning experimentsand the motivation behind their selection.
The entire feature set is presented inFigure 3 and includes only features that could be automatically available to a dialoguesystem.4.1.1 Prosodic Features.
Above we showed that corrections were significantly longer,louder, higher in pitch excursion, and followed longer pauses than other turns.
Thus,we expected that these features would be useful in identifying corrections automatically.We examined maximum and mean fundamental frequency values (f0max, f0mn) asindicators of pitch range; maximum and mean energy values (rmsmax, rmsmn) as in-dicators of loudness; total duration of the speaker turn (dur); length of pause precedingthe turn (ppau); speaking rate (tempo); and amount of silence within the turn (zeros).The features were measured as indicated above.
Table 6 shows the overall means andstandard deviations for these features over the corpus.4.1.2 ASR Features.
Since corrections in our corpus were misrecognized more frequentlythan non-corrections (Swerts, Litman, and Hirschberg 2000), we included a set of ASRfeatures that were derived from TOOT?s speech recognition component and its outputs:the grammar used as the ASR language model at each dialogue state (gram), the stringrecognized by the ASR system as its best hypothesis (str), and the turn-level acoustic427Computational Linguistics Volume 32, Number 3Figure 3Feature set for predicting corrections.Table 6Means and standard deviations for prosodic features over all turns.f0max f0mn rmsmax rmsmn dur ppau tempo zeros(Hz) (Hz) (sec) (sec) (sps) (%)Mean 227 163 1612 396 1.92 .71 2.48 44S.D.
77 44 1020 261 2.44 .79 1.37 17confidence score it produced (conf).4 As subcases of the str feature, we included Booleanfeatures representing whether or not the recognized string included the strings yes or no(ynstr), some variant of no, such as nope (nofeat), cancel (canc), or help (help), as theselexical items often occurred during problem resolution.
To estimate durational features,we approximated the length of the user turn in words (wordsstr) and in syllables (syls)from the str feature, and we added a Boolean feature identifying whether or not the turnhad been rejected by the system (rejbool).4.1.3 System Experimental Features.
Our descriptive study showed that differences indialogue strategy affect the type and success of user corrections.
For example, TOOTusers more frequently repeat their misrecognized turns and produce the fewest cor-rections per task when TOOT has the initiative and explicitly confirms all user input.So, we hypothesized that system conditions might prove important in our learningexperiments.
We thus include features representing the system?s current initiativeand confirmation strategies (inittype, conftype), whether users could adapt the sys-tem?s dialogue strategies (adapt), and the combined initiative and confirmation setting(realstrat).4 Confidence scores ranged from ?0.087662 to ?9.884418.428Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue Systems4.1.4 Dialogue Position and History Features.
We also showed that the further a cor-rection is from the original error, the less likely it is to be recognized correctly, and thestronger the correlation with prosodic deviation from the mean values over a speaker?sturns (e.g., more distant corrections are higher in pitch than closer corrections).
As a firstapproximation of this distance feature, we included the feature diadist?distance of thecurrent turn from the beginning of the dialogue.In addition, previous research (Litman, Walker, and Kearns 1999; Walker et al2000) has shown that features of the dialogue as a whole and features of more localcontext can be helpful in predicting ?problematic?
dialogues.
So we looked at a setof features summarizing aspects of the prior dialogue for both the absolute numberof times prior turns exhibited certain characteristics (e.g., contained a key word likecancel?priorcancnum) and the percentage of the prior dialogue containing one of thesefeatures (e.g., priorcancpct).
We also examined means for all our continuous-valuedfeatures over the entire dialogue preceding the turn to be predicted (pmn ), such aspmnsyls, the mean length of prior turns calculated in number of syllables per turn.Finally, we examined more local contexts, including all features of the preceding turn(pre ) and for the turn preceding that (ppre ).It seemed particularly likely that lexical features of the local context?such aswhether a user had asked for help recently, or tried to cancel out of an exchange, orreplied no to a system query?might prove useful in identifying corrections.5 Also,whether a prior turn had been rejected was clearly a useful cue to the identificationof the current turn as a correction, since users generally supplied a correction whenexplicitly asked.4.2 Machine-learning ExperimentsIn this section we investigate whether the features described in Section 4.1 (or inter-esting subsets of them) can in fact be used to accurately predict whether a turn willbe a correction or not.
We describe experiments using the machine-learning programRIPPER (Cohen 1996) to automatically induce such prediction models.
RIPPER takes asinput the classes to be learned, the names and possible values of a set of features, andtraining data specifying the class and feature values for each training example.
For ourexperiments, the features presented in Figure 3 comprise the independent variables forour learning experiments.
The dependent variable to be learned, correction (T) ver-sus non-correction (F), corresponds to the hand-labeled observations described above.Given a vector of values for the independent and dependent variables for each speakerturn, RIPPER outputs a classification model for classifying future examples.
The modelis learned using greedy search guided by an information gain metric and is expressed asan ordered set of if-then rules.
When multiple rules are applicable, RIPPER uses the firstrule it finds.
When no rules are applicable, RIPPER classifies the turn as a non-correction(F) by default.Table 7 shows the performance of the learned classification models for someof the feature sets we examined; all performance figures are estimated using 25-foldcross-validation on the 2,328 turns in our corpus.
The Features column identifies theset of features (as defined in Figure 3) used to learn the model.
The second column,DIA, indicates which type of dialogue history features (PreTurn, PrepreTurn, Prior,5 Recall that these are lexical features from the recognized string, not from the actual user transcript.429Computational Linguistics Volume 32, Number 3Table 7Estimated error, recall, precision, and F?
= 1 for predicting corrections.class = T class = FFeatures DIA Error ?
SE Rec.
Prec.
F?
= 1 Rec.
Prec.
F?
= 1Raw+ASR+SYS+POS PreTurn 15.72 ?
0.80 70.61 74.96 .72 89.95 88.28 .89Raw+ASR+SYS+POS all 16.16 ?
0.58 69.80 74.65 .72 90.12 87.82 .89PROS+ASR+SYS+POS all 16.38 ?
0.61 69.01 74.05 .71 89.60 87.61 .88ASR all 16.41 ?
0.93 69.93 72.39 .70 88.76 87.7 .88ASR+SYS+POS all 17.01 ?
0.78 73.73 73.38 .73 88.68 89.00 .89ASR+SYS+POS none 18.60 ?
0.81 56.48 72.79 .63 91.33 83.76 .87Raw+ASR+SYS+POS none 18.68 ?
0.67 58.45 71.64 .64 90.37 84.17 .87ASR+PROS none 19.29 ?
0.78 54.54 69.97 .61 90.25 82.90 .86POS+PROS none 19.59 ?
0.73 52.96 69.70 .60 90.38 82.47 .86Raw all 19.68 ?
0.78 55.62 70.89 .62 90.64 83.33 .87PROS all 20.33 ?
0.90 56.45 69.23 .61 89.43 83.42 .86ASR+POS none 20.40 ?
0.79 52.20 71.99 .60 91.43 82.41 .87PROS none 20.53 ?
0.81 54.86 71.72 .62 90.78 83.07 .87conf+rejbool all 21.23 ?
0.93 59.70 65.97 .62 87.05 84.05 .85ASR+SYS none 23.46 ?
0.72 51.55 63.40 .56 87.53 81.65 .84ASR none 24.19 ?
0.84 45.93 60.99 .52 87.80 79.90 .84Raw none 25.35 ?
0.93 42.26 59.46 .48 88.29 78.97 .83POS none 29.00 ?
1.02 0.00 ?
?
99.94 70.99 .83SYS none 29.00 ?
1.02 0.00 ?
?
100.00 71.00 .83Prerejbool baseline error = 25.70; majority baseline error = 28.99and/or PMean) were also included in the feature set; these features represent thesame types of information (e.g., f0max) that the Features column denotes, but for oneor more previous turns in the dialogue.
The third column shows the mean error andstandard error (SE) predicted for the model specified by the first two columns.
Whenerror estimates in different rows differ by plus or minus twice the standard error,they are significantly different (Cohen 1995).
The remaining columns show the meanrecall, precision, and F?
= 1 for corrections (focus class = T) and non-corrections (focusclass = F), respectively.6 For comparison purposes, we compare our predictions to twopotential baselines.
The Majority baseline predicts that all turns are non-corrections(the majority class of F), and has a classification error of 28.99%.
The Prerejbool base-line predicts that all turns following rejected turns (prerejbool = T) are corrections?since after rejections, TOOT asks users to repeat their turn7?and all others are non-corrections; this baseline gives a classification error of 25.70%.The first question addressed in our experiments is whether or not corrections can bepredicted significantly better than our baselines.
Table 7 shows that in fact they can.
Ourbest-performing feature set (Raw+ASR+SYS+POS, DIA = PreTurn) cuts the majoritybaseline error almost in half, from 28.99% to 15.72%, and predicts significantly betterthan the rejection-based baseline as well.
This feature set includes raw versions of all ourprosodic features and all of the non-prosodic features, for both the turn being classified6 Recall is the percentage of actual members of a class that are identified, whereas precision is the percentageof predicted class members that are in fact members.
The definition of F?
is(?2+1)PrecisionRecall?2Precicison+Recall; ?
= 1equally weights precision and recall.
These values are computed using our own cross-validationprogram, while error is computed using RIPPER?s cross-validation option.7 Although users are asked to repeat their turn, 29% of the turns after rejections are not in fact corrections(e.g., the user instead asks for help or asks the system to repeat the prompt).430Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue Systemsand the immediately prior turn.
Note that even if all of the available features are usedfor learning (i.e., the normalized versions of prosodic features and all of the varioushistory features (PROS+ASR+SYS+POS, DIA = all, error = 16.38%)), performance isstatistically comparable to this model.8 In addition, the recall, precision and F?
= 1values in Table 7 show that corrections are generally predicted with better precisionthan recall whereas the reverse holds for non-corrections, and that non-corrections (themajority class) are easier to accurately predict than corrections.We next turn to an examination of the contribution of the different types of featureswe used for prediction.
First, we consider the utility of our non-prosodic features.Table 7 shows that, using only non-prosodic features (ASR, SYS, POS), corrections canstill be predicted with an accuracy statistically equivalent to our best results.
That is,using all feature types (PROS+ASR+SYS+POS, DIA = all, error = 16.38%) is equivalentto using only non-prosodic features (ASR+SYS+POS, DIA = all, error = 17.01%).
Simi-larly, restricting our feature set to the ASR-derived subset of our non-prosodic features(ASR, DIA = all, error = 16.41%) or removing all dialogue history (ASR+SYS+POS,DIA = none, error = 18.60%) yields results equivalent to our best-performing classifier.However, when only those ASR features derived from the acoustic confidence score(i.e., conf, preconf, ppreconf, pmnconf, rejbool, prerejbool, pprerejbool, priorrejbool-num, priorrejboolpct) are used for prediction, then performance does significantlydegrade (conf+rejbool, DIA = all, error = 21.23%).
So, it appears that there are numerousways to classify corrections successfully, using various combinations of feature types.This finding is an important one because it suggests that systems that have access torestricted kinds of information can still hope to identify user corrections with someconfidence.
In particular, simply using information available to current ASR systems,such as acoustic confidence score, recognized string, grammar, and features derivedfrom these, produces classification results equivalent to our best-performing classifier.A caveat here is that some of the features in this ASR feature set (e.g., grammar andrecognized string) are less likely to generalize from task to task.Turning now to the role of prosodic features in classifying corrections, Table 7 showsthat use of only non-prosodic features (ASR+SYS+POS, DIA = all, error = 17.01%)9slightly (but not quite significantly) outperforms use of only raw prosodic features (Raw,DIA = all, error = 19.68%).
However, using raw prosodic features alone (error = 19.68%)is comparable to using only ASR features alone (ASR, DIA = all, error = 16.41%).
Andboth significantly outperform the majority class and rejection-based baselines.
Notealso that prediction from raw prosodic features alone (19.68%) is not improved by theinclusion of their normalized versions (PROS, DIA = all, error = 20.33%).
Thus, ASR-derived features and prosodic features seem to provide equally successful classificationsof user corrections.
Since ASR-derived features, in particular, acoustic confidence score,are currently used by spoken dialogue systems to determine when to reject a turn,our results suggest that such features can also be useful for identifying corrections.Although prosodic features are rarely made use of in spoken dialogue systems, theywould, in fact, seem more likely to generalize across tasks and recognizers than theASR features.Now we turn to the issue of how useful features of the dialogue history are inclassifying corrections.
Recall that our best-performing ruleset used only a limited dia-8 Note that removing features sometimes changes performance, which might indicate a weakness inRIPPER?s feature selection process.9 Recall that DIA = all includes only the same type of features as for the current utterance, in this case onlynon-prosodic history features.431Computational Linguistics Volume 32, Number 3Figure 4Best performing ruleset (Raw+ASR+SYS+POS, DIA = PreTurn).logue history?features from the preceding turn (Raw+ASR+SYS+POS, DIA = PreTurn,error = 15.72%).
While adding features of the turn two turns back (PrepreTurn ) andof the dialogue as a whole (Prior and PMean ) does not significantly change theerror (Raw+ASR+SYS+POS, DIA = all, error = 16.16%), removing the features of theimmediately previous turn from the dialogue history does in fact cause a significantincrease in error rate (Raw+ASR+SYS+POS, DIA = none, error = 18.68%).
However,as discussed above, when only non-prosodic features are considered (ASR+SYS+POS),there is no significant difference between DIA = all and DIA = none.
So, it seems thatfeatures of the immediate local context can improve our ability to classify correctionsaccurately when prosodic features are included, but adding a larger local context win-dow and a global context does not improve over these results.
Contextual features seemparticularly important to performance when only raw prosodic features are considered(Raw, DIA = all, error = 19.68%).
When the raw prosodic features of the dialoguehistory are removed, the error rate dramatically increases (Raw, DIA = none, error =25.35%).
However, if the normalized prosodic features (which themselves encode muchof the historical information) are also included, then removing the DIA versions of thesefeatures does not significantly degrade performance (PROS, DIA = all, error = 20.33%vs.
PROS, DIA = none, error = 20.53%).
We might explain the larger role that prosodiccontext plays in classification by returning to the differences we found between prosodicfeatures of corrections and non-corrections, described in Section 3.
In our descriptiveanalyses we found that prosodic features such as pitch, duration, and loudness reliablydistinguish corrections based on relative differences between the two types of turns,not absolute differences.
In prediction also, it seems that some form of normalization bycontext improves the performance of prosodic features.When we examine which class of features performs best in the absence of contextualinformation, we see that the prosodic features (PROS, DIA = none, error = 20.53%)significantly outperform the ASR-derived features (ASR, DIA = none, error = 24.19%),which in turn significantly outperform either of the remaining feature types (POS andSYS).
Table 7 also shows the cases in which the addition of new sources of knowl-edge improves prediction performance.
For DIA = none, the statistically significantimprovements involve adding the feature diadist (distance of the current turn fromthe beginning of the dialogue): For example, ASR+POS (error = 20.4%) outperformsboth ASR (error = 24.19%) and POS (error = 29%), and ASR+SYS+POS (error = 18.6%)outperforms ASR+SYS (error = 23.46%).
Again, these are features that are easily madeavailable to current spoken dialogue systems.The classification model learned from the best-performing feature set in Table 7 isshown in Figure 4.
Rules are presented in order of importance in classifying data.
The432Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue Systemsfirst rule RIPPER finds with this feature set specifies that if the duration of the currentturn is ?
3.89046 seconds, and if the acoustic confidence score of the prior turn is?
?0.645234, and if the percentage of silence in the current turn is ?
53.9474%, thenpredict that the turn is a correction; this rule correctly predicts 153 corrections andincorrectly predicts that 10 non-corrections are corrections.
So, this rule applies whenthe previous turn has a low confidence score and the current turn exhibits some markedprosodic features.
The fourth rule predicts a correction after a previous rejection, butonly when the rejected turn was relatively short with a low confidence score.
Thefifth rule predicts a correction when TOOT uses a particular confirmation strategy forturns that are relatively long and far from the beginning of the dialogue.
The sixthrule predicts a correction when the previous turn is spoken soon after the prompt,and contains the problem indicator help.
Note that this use of the domain-independenthelp is the only reference to a lexical item in this ruleset.
This ruleset includes featuresfrom all of the feature subsets in our inventory (PROS, ASR, SYS, POS, DIA).
For thecurrent turn, the feature types that appear in the rules are PROS (dur, zeros), ASR (conf,gram, syls), SYS (conftype), and POS (diadist).
Of the previous turn?s features, onlytwo feature sets emerge as important: PROS (pref0mn, predur, preppau, pretempo)and ASR (preconf, prestr, prewordstr, prerejbool).
Furthermore, within a feature setsuch as PROS, the useful features of the current and previous turns differ somewhat(e.g., zeros is useful for the current turn, whereas tempo is useful for the prior turn),suggesting important differences in the prosodic characteristics of corrections versusthe turns they follow.When we look at a ruleset produced using only features commonly available tocurrent dialogue systems, such as ASR+SYS+POS (DIA = all), we see that creative useof these features could in fact support correction classification (Figure 5).
For example,the fourth rule predicts that the current turn is a correction when it is not too short, andwhen the pre turn indicates awareness (evidenced by the presence of no) of a problemin the ppre turn (which was recognized with low confidence).
This ruleset uses bothASR (gram, nofeat, syls) and SYS (conftype) features of the current turn; although onlyone rule in fact makes use of SYS features.
For the contextual DIA features, only theASR features occur in the rule-set: PreTurn (preconf, prestr, prenofeat, prerejbool),PrepreTurn (ppreconf, ppreynstr), and Prior and PMean (pmnconf, priorynstrpct,pmnwordsstr, priorrejnum).
Comparing this ruleset to the previous one (Figure 4), wesee that where timing features (dur, predur, zeros, pretempo, preppau) appear oftenwhen prosodic features are available, related features such as syls and wordsstr (fromwhich, e.g., tempo is estimated) may be compensating in this ruleset.
And of course therejection feature (prerejbool) itself is a function of the confidence score of the prior turn.Note also that lexical features of the recognized string (nofeat, prenofeat, ppreynstr,Figure 5Ruleset for non-prosodic features (ASR+SYS+POS, DIA = all).433Computational Linguistics Volume 32, Number 3prestr, priorynstrpct) emerge as quite useful in this ruleset?especially as contextualfeatures.
So, what the system has recognized in prior turns is a good predictor ofwhether the current turn is a correction.
Also note that the overall verbosity of theprevious dialogue (pmnwordsstr) appears in two of the rules.An example of a ruleset learned from only prosodic features (Raw, DIA = all, fromTable 7) is shown in Figure 6.
This ruleset is notably terser than those shown in Figures 4and 5 and includes primarily timing-based features (current turn features dur, zeros,and tempo; local contextual feature pretempo; and dialogue-level features pmndur andpmnppau).
However, all prosodic feature types but f0 appear at least once in the ruleset,and features specific to the current turn differ from those relevant to different types ofdialogue history.
As with our previous descriptive findings discussed in Section 3, thisruleset shows that corrections are longer, louder, follow longer pauses, and contain lessinternal silence than non-corrections, and that these features can be used successfully toidentify them.4.3 Other ExperimentsThe machine-learning experiments described in Section 4.2 were motivated by ourlong-term goal to incorporate a correction predictor into future versions of our spokendialogue system.
As such, the experiments were limited to a binary prediction task(predicting whether a turn was a correction or a non-correction) and only consideredfeatures readily available to our dialogue system.
In this section we present additionalexperiments removing some of these restrictions, with the goal of further investigatingsome of the descriptive findings discussed in Section 3.Recall from Section 3.2 that there were some differences in the prosodic features ofcorrections produced by native versus non-native speakers when such features werenormalized by the first turn in the dialogue.
We thus investigated whether adding anative speaker feature (currently manually labeled) to the prosodic feature set Norm1(DIA = all) would improve prediction accuracy.
Although the error was reduced from24.32% to 22.68%, this difference was not statistically significant.
Furthermore, whenwe added the native speaker feature to both the best-performing ruleset in Table 7(Raw+ASR+SYS+POS, DIA = PreTurn) and the best-performing prosodic feature set(Raw, DIA = all), the error rates actually increased; again, however, the differences werenot statistically significant.Also, in Sections 3.1 and 3.4, we identified differences between different types of cor-rections, which suggests that our features might be more effectively used to predict eachcorrection type differently.
In other words, what would happen if instead of predictingwhether a turn was a correction (T) or not (F) (the binary classification task investigatedabove), we predicted whether a turn was ADD, ADD/OMIT, OMIT, PAR, REP, or F (i.e.,not a correction).
Because, as Table 2 shows, we only have limited amounts of data forFigure 6Ruleset for raw prosodic features (Raw, DIA = all).434Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue Systemsseveral of our classes (e.g., only 2% of our corrections are ADD/OMIT); we performed asimpler version of this experiment, combining our three lowest frequency classes (ADD,ADD/OMIT, and PAR) into the single class MISC.Using the best feature set from Table 7 (Raw+ASR+SYS+POS, DIA = PreTurn),Table 8 shows our results using 25-fold cross-validation.
First, note that our overallestimated error is now 24.13% ?
0.89%.
Although this is a huge increase compared tothe 15.72% error rate of our original binary classifier, it should be noted that consideringcorrection types separately makes our class distribution quite skewed, with the datafor our three correction classes much smaller than the majority class.
Nevertheless,our classifier yields a slight but significant decrease compared to the majority baselineerror, and a nonsignificant decrease compared to the Prerejbool baseline error (bothbaselines remain the same as in Table 7).
With respect to precision and recall, althoughthe absolute numbers for corrections are much lower than in Table 7, we again seethat predicting corrections yields higher precision than recall, whereas predicting non-corrections yields higher recall than precision.
Finally, an examination of the learnedruleset (which contains four rules for predicting MISC, two rules for predicting OMIT,and seven rules for predicting REP) does show that features are used differently acrosscorrection types.
For example, the feature prestr is only used to predict repetition correc-tions (in particular, after a turn containing help).
Our rules also show some overlap withour earlier descriptive findings.
For example, we noted that corrections of rejectionswere more likely to be repetitions, and find the feature prerejbool in two of the rulesfor predicting repetitions.
These findings suggest that if more data were available,predicting corrections by type might prove a useful strategy.5.
ConclusionsIn this article we have presented results of an analysis of corrections in the TOOTspoken dialogue corpus.
We first introduced the TOOT spoken dialogue corpus andour labeling scheme to identify different types of corrections.
The TOOT corpus isrepresentative of many current research and commercial dialog systems in focusing onthe travel domain.
Also, since data were collected using a variety of dialog strategieswith different types of initiative and confirmation, results obtained with this corpusare more likely to have general usefulness for builders of other spoken dialoguesystems.We next presented a statistical description of the corrections we labeled.
In general,it appears that corrections are a serious problem for ASR, being recognized muchmore poorly than non-corrections but not being rejected any more frequently.
Somecorrections types are more difficult to handle for systems than others, with repetitionsTable 8Predicting correction types (error ?
SE = 24.13 ?
0.89)Class Recall Precision F?
= 1FALSE 93.30 82.37 .87REP 33.86 56.00 .41MISC 36.17 48.36 .38OMIT 25.47 50.13 .32435Computational Linguistics Volume 32, Number 3and corrections that omit information from the original turn being much better recog-nized than corrections that add or paraphrase such information.
Confirming previousstudies of repetition corrections, we found that corrections in general differ from non-corrections prosodically: They are higher in f0, softer, longer, follow longer pauses, andcontain less internal silence than non-corrections.
Also, corrections more distant fromthe error they are correcting are louder, higher in pitch, longer, slower, and followlonger pauses than closer corrections.
Both findings suggest a correlation betweencorrections and hyperarticulation; however, most prosodic differences persist evenwhen perceptually hyperarticulated turns are removed from the sample, and perceptualhyperarticulation is not significantly correlated with distance from original error.
Wehypothesize that recognizers may be more sensitive to hyperarticulatory tendenciesthan humans.The second part of this article discusses results of machine-learning experimentsdesigned to evaluate how well we can distinguish user corrections from non-correctionsusing features automatically available to dialogue systems.
Clearly, new techniquesmust be developed to interpret such corrections, but such techniques can only beeffective if corrections can be reliably identified as such for special handling.
Using alarge set of prosodic, ASR-derived, and system-specific features, both for the currentturn and for contextual windows, and using summary features of the prior dialogue, wehave demonstrated that it is possible to classify user corrections significantly better thaneither of two baseline classifiers (15.72% error vs. 25.70?28.99%).
More usefully perhapsfor current spoken dialogue systems, we have found that we can derive classifiersthat perform equivalently well using only features currently available to most speechrecognizers, such as acoustic confidence score, recognized string, grammar, and featureseasily derived from these data.
For example, using only such features, we can classifyuser corrections with an estimated success rate of 16.41%.
So, it does, in fact, seem quitefeasible for current systems to identify user corrections using data they typically do notmake use of.Given that our findings show that corrections can be classified well using quite dis-tinct feature sets, a possible future line of research would be to try classification combi-nation schemes.
For instance, one could envision a form of metalearning or boosting thatcombines classifications using different feature sets (e.g., ASR vs. prosodic vs. context),or that combines the output of different learning algorithms (e.g., Ripper combinedwith memory-based learning; see, e.g., Lendvai 2004).
Kirchhoff (2001) presents someresults of classifier combination schemes, showing some improvements in detection ofcorrections when using cascading, but especially when using boosting.The next steps, developing techniques to interpret these turns more accuratelyand to use correction prediction to drive modifications in dialogue strategy, are bothsubjects of our future research.
Also, whereas our analyses so far have given us overallinformation about the relative contribution of various feature sets for the automaticclassification of corrections, one interesting problem for the future is to get more specificinformation about the cues that characterize corrections, especially for the developmentof on-line error-correction detection.
In this respect, an interesting observation has beenmade by Kirchhoff (2001), who reports that correction classification using only featuresof the first half of a turn performs equally well as a classification using features of theturn as a whole; this could be explained by the fact that speakers tend to put character-istic cue phrases, such as ?no?
or ?help,?
in the beginning of a turn.
Additional researchis needed to find strategies that use the detection of corrections to look back in thedialogue history to identify the utterance being corrected or even the actual problematicwords in these turns.
Finally, it would be worthwhile to investigate speaker-specific436Litman, Hirschberg, and Swerts Corrections in Spoken Dialogue Systemscorrection strategies in more detail, the possible effect on such strategies of the user?sexperience with a system, and his or her linguistic background.AcknowledgmentsMarc Swerts is also affiliated with theUniversity of Antwerp.
His research issponsored by the Netherlands Organisationfor Scientific Research (NWO).
This workwas performed when the authors were atAT&T Labs?Research.ReferencesAmmicht, E., A. Potamianos, andE.
Fosler-Lussier.
2001.
Ambiguityrepresentation and resolution in spokendialogue systems.
In Proceedings ofEUROSPEECH-01, pages 2217?2220,Aalborg.Andorno, M., P. Laface, and R. Gemello.2002.
Experiments in confidence scoringfor word and sentence verification.
InProceedings of International Conference onSpoken Language Processing-02,pages 1377?1381, Denver.Barkhuysen, P., E. Krahmer, and M. Swerts.2005.
Problem detection inhuman?machine interactions based onfacial expressions of users.
SpeechCommunication, 45:343?359.Batliner, A., K. Fischer, R. Huber, J. Spilker,and E. No?th.
2003.
How to find trouble incommunication.
Speech Communication,40:117?143.Bell, L. and J. Gustafson.
1999.
Repetitionand its phonetic realizations: Investigatinga Swedish database of spontaneouscomputer-directed speech.
In Proceedingsof International Congress of PhoneticSciences-99, pages 1221?1224, SanFrancisco.Bouwman, A. G., J. Sturm, and L. Boves.1999.
Incorporating confidencemeasures in the Dutch train timetableinformation system developedin the ARISE project.
In ProceedingsInternational Conference on Acoustics,Speech and Signal Processing, volume 1,pages 493?496, Phoenix.Bulyko, I., K. Kirchhoff, M. Ostendorf, andJ.
Goldberg.
2005.
Error-correctiondetection and response generation in aspoken dialogue system.
SpeechCommunication, 45:271?288.Cohen, P. 1995.
Empirical Methods for ArtificialIntelligence.
MIT Press, Boston.Cohen, W. 1996.
Learning trees and ruleswith set-valued features.
In 14th Conferenceof the American Association of ArtificialIntelligence, AAAI, pages 709?716,Portland.Falavigna, D., R. Gretter, and G. Riccardi.2002.
Acoustic and word lattice basedalgorithms for confidence scores.
InProceedings of International Conferenceon Spoken Language Processing-02,pages 1621?1624, Denver.Guillevic, D., S. Gandrabur, andY.
Normandin.
2002.
Robust semanticconfidence scoring.
In Proceedings ofInternational Conference on Spoken LanguageProcessing-02, pages 853?856, Denver.Hirschberg, J., D. Litman, and M. Swerts.1999.
Prosodic cues to recognition errors.In Proceedings of the Automatic SpeechRecognition and Understanding Workshop(ASRU?99), pages 349?352, Keystone.Hirschberg, J., D. Litman, and M. Swerts.2004.
Prosodic and other cues to speechrecognition failures.
Speech Communication,43:155?175.Kamm, C., S. Narayanan, D. Dutton, andR.
Ritenour.
1997.
Evaluating spokendialog systems for telecommunicationservices.
In Proceedings ofEUROSPEECH-97, pages 2203?2206,Rhodes.Karsenty, L. and V. Botherel.
2005.Transparency strategies to help usershandle system errors.
SpeechCommunication, 45:305?324.Kirchhoff, Katrin.
2001.
A comparisonof classification techniques for theautomatic detection of error correctionsin human?computer dialogues.
InProceedings of the NAACL Workshopon Adaptation in Dialogue Systems,pages 33?40, Pittsburgh, PA.Krahmer, E., M. Swerts, M. Theune, andM.
Weegels.
2001.
Error detection inspoken human?machine interaction.International Journal of Speech Technology,4(1):19?30.Levow, Gina-Anne.
1998.
Characterizingand recognizing spoken corrections inhuman?computer dialogue.
In Proceedingsof the 36th Annual Meeting of the Associationof Computational Linguistics, COLING/ACL98, pages 736?742, Montreal.Lendvai, Piroska.
2004.
Extractinginformation from spoken user input.
Amachine-learning approach.
UnpublishedPh.D.
dissertation, Tilburg University.Litman, D. and S. Pan.
1999.
Empiricallyevaluating an adaptable spoken437Computational Linguistics Volume 32, Number 3dialogue system.
In Proceedings of the7th International Conference on UserModeling (UM), pages 55?64, Banff.Litman, D., M. Walker, and M. Kearns.
1999.Automatic detection of poor speechrecognition at the dialogue level.
InProceedings of the 37th Annual Meeting of theAssociation of Computational Linguistics,ACL99, pages 309?316, College Park.McTear, M., I.
A. O?Neill, P. Hanna, andX.
Liu.
2005.
Handling errors anddetermining confirmation strategies?anobject-based approach.
SpeechCommunication, 45:249?269.Moreno, P. J., B. Logan, and B. Raj.
2001.
Aboosting approach for confidence scoring.In Proceedings of EUROSPEECH-01,pages 2109?2112, Aalborg.Oviatt, S. L., G. Levow, M. MacEarchern, andK.
Kuhn.
1996.
Modeling hyperarticulatespeech during human-computer errorresolution.
In Proceedings of InternationalConference on Spoken LanguageProcessing-96, pages 801?804, Philadelphia.Prodanov, P. and A. Drygajlo.
2005.
Bayesiannetworks based multimodality fusion forerror handling in human?robot dialoguesunder noisy conditions.
SpeechCommunication, 45:231?248.Sharp, R. D., E. Bocchieri, C. Castillo,S.
Parthasarathy, C. Rath, M. Riley,and J. Rowland.
1997.
The Watsonspeech recognition engine.
InProceedings International Conference onAcoustics, Speech and Signal Processing97,pages 4065?4068, Munich.Shimojima, A., Y. Katagiri, H. Koiso, andM.
Swerts.
2001.
An experimental study onthe informational and grounding functionsof prosodic features of Japanese echoicresponses.
Speech Communication,43:155?175.Skantze, G. 2005.
Exploring human errorrecovery strategies: Implications forspoken dialogue systems.
SpeechCommunication, 45:325?341.Soltau, Hagen and Alex Waibel.
1998.
On theinfluence of hyperarticulated speech onrecognition performance.
In Proceedings ofInternational Conference on Spoken LanguageProcessing-98, pages 225?228, Sydney.Soltau, Hagen and Alex Waibel.
2000.Specialized acoustic models forhyperarticulated speech.
In Proceedingsof International Conference on Acoustics,Speech and Signal Processing 2000,pages 1779?1782, Istanbul.Soltau, H., H. Metze, and A. Waibel.
2002.Compensating for hyperarticulation bymodeling articulatory properties.
InProceedings of International Conferenceon Spoken Language Processing-02,pages 83?86, Denver.Sturm, J. and L. Boves.
2005.
Effective errorrecovery strategies for multimodalform-filling applications.
SpeechCommunication, 45:289?303.Swerts, M., D. Litman, and J. Hirschberg.2000.
Corrections in spoken dialoguesystems.
In Proceedings of InternationalConference on Spoken LanguageProcessing-00, pages 615?618, Beijing.Talkin, D. 1995.
A Robust algorithm forpitch tracking (RAPT).
In W. B. Kleinand K. K. Paliwal, editors, SpeechCoding and Synthesis.
Elsevier Science,Athens, pages 495?518.Torres, F., L. Hurtado, F.
Garc?
?a, E. Sanchis,and E. Segarra.
2005.
Error handling in astochastic dialog system throughconfidence measures.
SpeechCommunication, 45:211?229.Wade, E., E. E. Shriberg, and P. J. Price.1992.
User behaviors affectingspeech recognition.
In Proceedings ofInternational Conference on SpokenLanguage Processing-92, volume 2,pages 995?998, Banff.Walker, M., I. Langkilde, J. Wright,A.
Gorin, and D. Litman.
2000.Learning to predict problematicsituations in a spoken dialoguesystem: Experiments with How mayI help you?
In Proceedings of NAACL-00,pages 210?217, Seattle.Wang, H.-M. and Y.-C. Lin.
2002.
Error-tolerant spoken language understandingwith confidence measuring.
In Proceedingsof International Conference on SpokenLanguage Processing-02, pages 1625?1628,Denver.Zhang, R. and A. Rudnicky.
2001.
Wordlevel confidence annotation usingcombinations of features.
In Proceedingsof EUROSPEECH-01, pages 2105?2108,Aalborg.438
