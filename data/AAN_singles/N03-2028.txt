LM Studies on Filled Pauses in Spontaneous Medical DictationJochen PetersPhilips Research Laboratories, Weisshausstrasse 2, D-52066 Aachenjochen.peters@philips.comAbstractWe investigate the optimal LM treatment ofabundant filled pauses (FP) in spontaneousmonologues of a professional dictation task.Questions addressed here are (1) how to dealwith FP in the LM history and (2) to which ex-tent can the LM distinguish between positionswith high and low FP likelihood.
Our resultsdiffer partly from observations reported on di-alogues.
Discarding FP from all LM historiesclearly improves the performance.
Local per-plexities, entropies and word rankings at po-sitions following FP suggest that most FP in-dicate hesitations rather than restarts.
Properprediction of FP allows to distinguish FP fromword positions by a doubled FP probability.Recognition experiments confirm the improve-ments found in our perplexity studies.1 IntroductionSpeech disfluencies are characteristic for spontaneousspeech.
Different disfluency types can be distinguished:Filled pauses (FP) such as ?UH?
or ?UM?, restarts or re-pairs, and repetitions.
It is widely accepted that disflu-encies considerably degrade the performance of speechrecognition due to unexpected word sequences and dueto the acoustic confusability of FP with short functionwords.Most publications investigate different types of disflu-encies in spontaneous dialogues.
This paper, instead, re-ports analyses on spontaneous dictation of medical re-ports, i.e.
on spontaneous monologues.
Our studies focuson FP which are clearly dominant in our data (8% fre-quency) and which appear to be mainly associated withhesitations.
As opposed to dialogues, FP are never usedhere to prevent interruptions by the dialogue partner asthe speaker is searching for some formulation.Central questions for language modeling are the op-timal prediction of FP and its treatment in the LM his-tory.
Discarding FP from the history should be helpful ifthe sentence is continued after the interruption.
For com-plete restarts, however, preceding words may be mislead-ing and a conditioning on FP may be better.
On Switch-board, (Stolcke and Shriberg, 1996) found that wordsfollowing FP are better predicted if FP is not discardedfrom the history.
This was attributed to the tendency ofFP to appear at sentence boundaries where the word con-text from the preceding sentence appears to be harmful.Measurements after sentence-internal FP only, however,showed a local perplexity reduction for FP-cleaned histo-ries by 20?30%.
This was expected since most sentencesare continued after the FP.
These observations were con-firmed by (Siu and Ostendorf, 1996) for sentence-internalFP but the local perplexity reduction due to skipping FPwas much smaller.
Interestingly, there, local trigram per-plexities after FP are about 40% worse than bigram per-plexities, no matter whether FP was discarded from thehistory or not.
For a How May I Help You task, (Rose andRiccardi, 1999) report an improved LM prediction if FPis explicitly used for the conditioning of following words.This paper is organized as follows: Section 2 describesthe dictation task and our corpora.
Section 3 lists threebasic approaches to treat FP in trigram LMs.
Section 4discusses various perplexity comparisons, especially fo-cussing on the question how to treat FP in the LM history.An extra study is concerned with LM uncertainties afterFP.
Finally, we analyze how well our LMs can discrimi-nate FP from word positions.
Section 5 summarizes ourresults and cites related speech recognition experiments.2 CorporaOur experiments are based on about 1.4 Mio.
words ofreal-life dictated medical reports from various US hospi-tals which are partitioned into a Train, Dev, and Eval set(Table 1).
The dictation style is fully spontaneous withrepairs, repetitions, partial words, and ?
most frequent ?filled pauses.
Manual transciptions of these data includethe annotation of FP.
However, tags to distinguish be-tween FP associated with hesitations, repairs, and restartsare missing.
Here, as opposed to Switchboard, most FPare sentence-internal (ca.
70?80%).A large background corpus provides formatted, i.e.non-spontaneous reports which are mapped to the 60 kword list of our recognition system.
To train LMs includ-ing FP this ?Report?
corpus was stochastically enrichedwith FP.
Considering single or sequential FP/s as hid-den events in the reports we randomly inserted them withtheir a-posteriori probabilities in the given word contexts.These probabilities are estimated using a bigram from thespontaneous training data.
A similar approach was men-tioned without details in (Gauvain et al, 1997).
Theyreport increasing error rates if too many FP are insertedby this method into the LM training data.
This might beexplained by the following observation: Adding FP in acontext-dependent fashion diminishes the number of ob-served bi- and trigrams since words typically precedingor following FP ?loose individual contexts?
if many FPare inserted.
For our Report corpus, the number of dis-tinct uni- + bi- + trigrams drops from 107 M (without FP)to 98 M (after FP enrichment).Corpus Spont # words FP rate OOV rateTrain yes 1314 k 8.2 % 0.45 %Dev yes 81 k 6.3 % 0.23 %Eval yes 53 k 7.0 % 0.30 %Report no 1071 M 7.9 % 0.31 %Table 1: Characteristics of text corpora including FP.
(The high OOV rate on Train is due to an extension ofthis data set after fixing our 60 k word list.
)3 Language modelsMapping all filled pauses to a unique symbol FP we com-pare three LM approaches:1.
We treat FP as a regular word which is predicted bythe LM and which conditions following words.2.
We use the LM for both words and FP but discardall FP from the conditioning histories.3.
We use a fixed, context-independent probability forFP of 0.08 (FP unigram).
Here, words are predictedwith a FP-free LM skipping FP in the history (as inapproach 2.).
Normalization is achieved by a scal-ing of word probabilities with (1 ?
pfix(FP)).
Thissimplistic approach relieves us from the need of FP-tagged corpora, but we clearly loose the discrimina-tive prediction of FP.Approaches 1. and 2. use count statistics with FP.
Asdiscussed above, the inclusion of FP ?destroys?
somepossible word transitions.
To exploit the knowledgeabout possible FP-cleaned transitions we successfullytested merged counts.
Here, the sets of observed M-Grams in the corpus with and without FP are joined andcounts of common M-Grams are added.
(Doubled countsuse modified discounting and the reduced FP-rate is com-pensated using marginal adaptation (Kneser et al, 1997).
)All reported results are obtained with linearly interpo-lated models from the spontaneous Train and the non-spontaneous Report corpus.
(For trigrams, perplexitiesof these two component LMs are 95% and 19% abovethe perplexity of the interpolated LM.
)4 Experimental resultsThe three approaches are evaluated in terms of the overallperplexity (PP) and local values: PPFP and PPword aremeasured at FP and word positions only, and PPafter ?are measured immediately thereafter.The results in Table 2 show that discarding FP from thehistory clearly improves the performance (2. versus 1.
).The overall PP is reduced by 4?5%.
Big reductions by30?40% are found at positions immediately following FP.This, and the improvements as we go from bi- to trigrams(which are contrary to (Siu and Ostendorf, 1996)), indi-cates that sentences are ?
on average ?
continued after FP.Using merged counts further improves our LMs.
Gainsare (almost) additive to those from FP-skipping.
Espe-cially, PPafter FP decreases by another 10% for approach2.
which shows that the ?recovered?
FP-free M-Gramsare indeed valuable if we use FP-free histories.A comparison of PPafter FP and PPafter word confirmsthe common knowledge that word prediction after FP ispretty hard.
Even the unigram perplexity is almost 50%higher for words following FP than for words follow-ing fluent contexts.
This supports (Shriberg and Stolcke,1996) where the reduced predictability after FP is partlyattributed to the chosen words in those positions.For trigrams, the discrepancy between PPafter FP andPPafter word is much larger.
Asking ?how unexpected isa word in a given context ??
we evaluated the entropyH(hi) = ?
?w pLM(w | hi) ?
log pLM(w | hi) and therank Ri of wi following hi in the distribution pLM(?
| hi).Both quantities were averaged over histories hi ending onFP or on words.1 Note that eHmean represents a perplex-ity for the case that words following each history are dis-tributed according to pLM(?
| h).
An actually measuredPP above eHmean indicates a bias in the corpus towardswords with low pLM(w | h).
The results from Table 3show almost no such bias after words.
After FP, however,following words are clearly biased to low probabilitieswithin the trigram distributions.
Also, the mean ranks areconsiderably higher after FP than after words.Together, these findings support our impression that FPoften represents a hesitation where the speaker is search-ing for a less common word or formulation.1(Shriberg and Stolcke, 1996) report increasing entropies atFP versus word positions.
Our studies confirm these results.Table 2: Perplexities and error bars (95% confidence) on the Dev set for linearly interpolated LMs.LM range Appr.
CountsPPoverall PPFP PPword PPafter FP PPafter wordsize: 81 k 5 k 76 k 5 k 76 kUnigram1.
= 2. with FP 786.5 ?
14.0 12.4 ?
0.0 1042.2 ?
17.9 1136.8 ?
85.7 767.1 ?
14.03.
FP-free 786.4 ?
14.0 12.5 ?
0.0 1041.7 ?
17.9 1136.3 ?
85.6 767.0 ?
14.01. with FP 115.6 ?
2.4 11.0 ?
0.2 135.7 ?
3.0 957.5 ?
76.0 100.2 ?
2.2Bigram 2. with FP 112.0 ?
2.4 11.1 ?
0.2 131.0 ?
2.9 579.3 ?
50.6 100.2 ?
2.23.
FP-free 110.9 ?
2.3 12.5 ?
0.0 128.6 ?
2.8 503.5 ?
42.6 100.1 ?
2.11. with FP 61.4 ?
1.4 10.4 ?
0.2 69.3 ?
1.6 605.9 ?
49.9 52.6 ?
1.21. merged 60.3 ?
1.3 9.8 ?
0.2 68.2 ?
1.6 646.3 ?
53.2 51.4 ?
1.1Trigram 2. with FP 59.2 ?
1.3 10.9 ?
0.2 66.4 ?
1.5 427.2 ?
39.8 51.8 ?
1.22. merged 57.5 ?
1.2 11.4 ?
0.2 64.2 ?
1.5 383.6 ?
34.5 50.5 ?
1.13.
FP-free 57.9 ?
1.2 12.5 ?
0.0 64.3 ?
1.5 367.0 ?
33.0 51.1 ?
1.1Table 3: Measured PP versus eHmean and mean rank afterhistories ending on FP or on word (using pruned LMs).Range Appr.PPeHmeanafter Rmean afterFP word FP wordUni 1.
= 2.
1.6 1.1 1301 881Tri1.
2.6 1.2 1050 3362.
5.1 1.2 719 335Recall that approach 3. cannot discriminate betweenpositions with an increased or reduced FP probability.
Toevaluate the discrimination for approaches 1. and 2. wecalculated p(FP| h) instead of p(w | h) at each positionin the corpus.
The crucial result is that the mean FP prob-ability is reduced by 48% and 45% (approach 1. and 2.
)at word as compared to FP positions.
This is an importantfeature of these LMs since small FP probabilities reduceconfusions of proper words with FP.5 SummaryConcerning the question how to best predict words nextto FP we get the following results for our spontaneousdictation task: Discarding FP from the LM histories re-duces PPoverall by 4% and PPafter FP by 30%.
(Thelatter reduction is bigger than in (Stolcke and Shriberg,1996).
Note that our measurements include positions af-ter sentence-initial FP which suffer from the FP-removal.
)Count merging with FP-free M-Grams gives an additionalreduction of PPoverall by 3% and of PPafter FP by 10%.Comparisons of local perplexities and studies of en-tropies and word rankings indicate that FP often repre-sents a hesitation as speakers are searching for a less com-mon word or formulation which is hard to predict.At positions following FP, trigrams outperform bi-grams.
This together with gains from discarded FP sug-gests that FP rarely represent sentence breaks or restarts.We presented a new analysis of the LM?s power to dis-criminate between FP and word positions.
Predicting FPwith a trigram allows to lower the FP probability at wordpositions by almost 50%.
This is an important feature toreduce confusions of words with FP.Speech recognition experiments are published in(Schramm et al, 2003).
Using merged counts and dis-carding FP from the LM history reduces the error rate onEval by 2.2% (relative) while PP is reduced by 7%.Acknowledgements: I would like to thank XavierAubert and Hauke Schramm for their contribution ofspeech recognition experiments.ReferencesJ.L.
Gauvain, G. Adda, L. Lamel, M. Adda-Decker.1997.
Transcribing Broadcast News: The LIMSINov96 Hub4 System.
Proc.
DARPA Speech Recog-nition Workshop.R.
Kneser, J. Peters, D. Klakow.
1997.
Languagemodel adaptation using dynamic marginals.
Proc.
EU-ROSPEECH, 4:1971?1974.R.C.
Rose, G. Riccardi.
1999.
Modeling disfluency andbackground events in ASR for a natural language un-derstanding task.
Proc.
ICASSP, 1:341?344.H.
Schramm, X. L. Aubert, C. Meyer, J. Peters.
2003.Filled-pause modeling for medical transcriptions.
Toappear at IEEE Workshop an Spontaneous Speech Pro-cessing and Recognition.E.
Shriberg, A. Stolcke.
1996.
Word predictability af-ter hesitations: a corpus-based study.
Proc.
ICSLP,3:1868 -1871.M.
Siu, M. Ostendorf.
1996.
Modeling disfluencies inconversational speech.
Proc.
ICSLP, 1:386?389.A.
Stolcke, E. Shriberg.
1996.
Statistical language mod-eling for speech disfluencies.
Proc.
ICASSP, 1:405?408.
