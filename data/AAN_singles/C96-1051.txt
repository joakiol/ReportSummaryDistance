Segmentation and Labelling of Slovenian Diphone Inventories*Jerneja Gros, Ivo Ip~i~, Simon Dobri~ek, France Miheli~, Nikola Pavegi~Faculty o f  Electr ical  Engineer ingUnivers i ty  o f  L jubl janaTr~agka cesta 25S I -1000 L jubl janaS loveniajerneja.gros @fe.uni-l j .siAbstractPreparation, recording, segmentation a d pitchlabelling of Slovenian diphone inventories aredescribed.
A special user friendly intert'acepackage was developed in order to facilitatethese operations.
As acquisition of a labelleddiphone inventory or adaptation of a speechsynthesis ystem to synthesise further voicesis manually intensive, an automatic procedureis required.
A speech recogniser, based onHidden Markov Models in forced segmenta-tion mode is used to outline phone boundarieswithin spoken logatoms.
A statistical evalua-tion of manual and automatic segmentation dis-crepancies i performed so as to estinmte thereliability of automatically derived labels.
Fi-nally, diphone boundaries are determined andpitch markers are assigned to voiced sectionsof the speech signal.1 IntroductionFor the Slovenian language, several attempts weremade in the past, where different aspects of a Slove-nian text-to-speech synthesis (TI'S) system were co-vered (Dobnikar95).
Nevertheless, none of them suc-ceeded in building a complete system, providing highquality synthetic speech.
In the Laboratory of Artifi-cial Pemeption, we started on text-to-speech synthesisone year ago (Gros96).
Here we describe the acquisi-tion of an appropriate diphone inventory in a first ver-sion of our Slovenian TTS system, which is supposedto serve as a reference system for future improvements.We start with a brief overview of the different mo-dules el' the Slovenian TTS system, then we go on todescribe how the existing diphone inventory was ob-tained.
The acquisition era labelled iphone inventoryor adaptation of a speech synthesis ystem to synthe-sise new voices is manually intensive and prone to er-rors, therefore automatic procedures are required (Tay-lor91, Sehmidt93, Cosi91, Ottesen93).
In section 4 we*This work was partly funded by the Commission of theEuropean Community under COP-94 contract No 01634(SQEL)explain how we intend to automatically derive addi-tional diphone inventories for building new syntheticvoices.2 Slovenian TTS systemTile different phases of the text-to-speech transforma-tion are performed by separate independent modules,operating sequentially, as shown in Figure 1.
Thus in-put text is gradually transformed into its spoken equi-valent,Graphemc-to-phoneme transcriptionFirst, abbreviations are expanded to t'ornl equiva-lent full words using a special list of lexical en-tries.
A text pre-processor converts further special for-mats, like numbers or dates, into standard graphemicstrings.
Next, word pronunciation is derived, based ona user extensible pronunciation dictionary and letter-to-sound rules.
The dictionary is supposed to cover themost fl'equent words in a given hmguage and a seconddictionary helps with pronouncing proper names.Prosody generationProsody generation assigns the sequence of allo-phones with some of their prosodic parameters (pitchl'requency, duration).
First, words are syllabitied bycounting the nmnber of their vowel clusters and dura-tion of syllables is modelled according to the speaker'snormal articulation rate, depending on the number ofsyllables within a word and on the word's positionwithin a phrase.
Then, segmental prosodic parame-te~w are determined tbr each allophone on the basis ofthe accent position within a word and its type.
Finally,the global intonation contour of a phrase is determined(Sorin87).Diphone ConcatenationOnce the appropriate phonetic symbols and prosodymarkers are determined, the final step is to produceaudible speech by assembling elemental speech units,computing pitch and duration contours, and synthe-sising the speech waveform.
A concatenative TD-PSOLA diphone synthesis technique was used, allow-ing high-quality pitch and duration transformations di-rectly on the waveform (Moulines9(/).298ASCII text ~"'?
":72'""i-  .
.
.
.
.
.
.
.
/ Jpr( ,'ody lu lesn l l c roprosody.
.
.
.
l'tl!es .n lacroprosody?
.
r u l e s  _ _ .dii;h,,,m !,.
!!!veIlt?
!Yspeech OUtlmt ~< " @','))~'}l"igure I: Slovenian text-to-speech xystem architec-tu re.diphone inventory cotnprising 955 pitch-labelled i-phones was created.
In order to guarantee optimalsynthesis quality, a neutral phonetic ontext in whichthe diphones needed to be located, was speeitied.
Un-favourable positions, like inside stressed syllables orin over-a,ticulated contexts, were excluded.
The di-phones were placed in the middle of logatoms, pro-nounced with a steady intonation.
The exception is inthe case where the silence phone is part of the requiredpair: there the diphone was word initial or word final.Speech signals were recorded by a close talking nil-crophone using a sampling rate of 16 kHz and 16 bitlinear AID conversion.3 Slovenian Diphone InventoryIn concatenation systems, both the choice and theproper segmentation of the traits to be concatenatedplay a key role.
Acoustic differences between storedand requested segments, its well as acoustic disconti-nuities at the boundaries belween adjacent segmentshave to be minimised.
Dipt,one units are most corn-.monly adopted as a compromise between the size ofthe unit inventory and tile quality of synthetic speech.A diphonc is, generally speaking, a unit which startsin tim middle o1: one phone, passes through the transi~tion to the next phone and ends in the middle of thisnext phone.
So the transition between two phones isencapsulated and does not ueed to be calculated.Yet it is not clear whether speech segments houldbe extracted from nonsense plurisyllabic words, calledIogatoms, existing isolated words or meaningful sen-teuces.
Even the question of  a bust positioning oI'the units within the spoken corpus is still widely de-bated.
Stressed syllables are longer, thus less submit-ted to coarticulation, which results in easily chainableunits; while unstressed ones are more ntnnerous in nat-ural speech, so that producing them efficiently wouldboth increase segmental qt, ality and reduce lrlcmoryrequirements.
Likewise, coarticulalions are stronglysubject o speaker's lluency, so that imposing a slowspeaking rate results in more intelligible units.
To alarge extent these issues are part of a necessary trade-off between intelligibility and naturalness.One diphone tor every allophone combination pos-sible in a given language is required.
A SlovenianIqgure 2: Wawqbrm (above) and spectral (below) re-presentation of the diphone ac.
Markers 1, and R areset at the pitch periods ~" the left part of the do, honeand of the right part, respectively.After the recording phase, logatoms were hand-segmented and tile center of tile transition betweentile phones was marked, using information from bothtemporal and spectral representation f tile speech s ipnal.
A special user-friendly interface was developedfor this purpose, allowing editing, scaling, viewing, llt-belling and pitch-marking of the speech signal, t,'irstthe approxiumte neighbourhood of a diphone was de-termined, then a fine labelling of its boundaries wasperformed and the center of the phoneme transitionwas marked, l"inally, pitch markers were manually setfor voiced parts of tile corresponding speech signal.t;igure 2 gives an example of the diphone am alongwith its spcctrtuu.
'lb phonetically transcribe the logatom words we299vowelse i~ (I, I , I)" (e, e, e)e (E, ~, E)(3, 3, 3)(o, o, o)(o, o, o)(u, u, u)sonorantsn Nv-2 I WI Lphone\[ modelnonsonorantsp (-, P)t (_, T)k (_, K)b (=,B)d (:, D)g (:, G)f Fh Hs Sz Z2c (_, c, s)(- ,C~)phone I modelsilencesilence \[Table l: List of phones and their corresponding submodels used for Slovenian Iogatom segmentation.
Symbol =represents a voiced closure while symbol _represents an unvoiced closure.used a set of 34 symbols for allophones, whichwe adapted to the SAMPA standard requirements(Fourcin89) t .While concatenating diphones into words it suddenlyturned out that there was a large discrepancy betweenthe duration of allophones, as suggested by the prosodymodule, and the actual corresponding diphone dura-tion stored in the diphone inventory.
This happeneddue to the exaggerated agerness of the speaker try-ing to pronounce the meaningless logatoms in a cor-rect and clear way.
Consequently, the quality of thesynthetic speech was considerably affected and we aretherefore planning to record another diphone inven-tory.
As the transformation range for prosodic speechparameters needed for synthesising naturally soundingspeech is large, the recording should thus be carefullycontrolled to achieve medium pitch and duration va-lues.4 Automat ic  D iphone  Segmentat ionAutomatic speech segmentation procedures are power-fill tools for including new synthetic voices and forupdating and supplementing existing diphone librarieswhereas manual diphone segmentation is a tedious,time consuming task, prone to errors.
Therelbre, in or-der to be able to synthesise speech in a variety of differ-ent voices, we decided to use procedures for automaticsegmentation a d pitch marking of spoken logatoms.The extraction of diphones from the recorded wordsis performed in two stages.
The first stage is thephoneme segmentation of logatoms, yielding a startpoint, transition center and end point for each phone.The second part of the diphone xtraction procedure isto find the concatenation point of each phone.~A list of Slovenian SAMPA symbols together with theiraudio samples is available on the WWW on the address"http:#1uz.fer.uni-lj.si/english/SQEL/sampa-eng.htlnl".Finally, pitch markers are to be determined forvoiced parts of the signal.
We intend to applythe SRPD (Super Resolution Pitch Determination)algorithm as it allows precise pitch determination(Medan91).Hidden Markov Model Phone SegmentationTo solve the segmentation problem, methods forstochastic modelling of speech are used.
HiddenMarkov Models (HMMs) are stochastic finite-state au-tomata that consist of a finite number of states, mo-delling the temporal structure of speech, and a prob-abilistic function for each of the states, modelling theemission and observation of acoustic feature vectors(Rabiner89).To perform logatom segmentation we used theIsadora system, developed at the University Erlangen-Nuremberg (Schukat92).
The Isadora system is a toolused for modelling of one dimensional patterns, likespeech.
It consists of modules for speech signal fea-ture extraction, hard or soft vector quantization andbeam-search driven Viterbi training and recognition.The ls'adora system builds a large network of nodesthat correspond todifferent speech events like phones,phonemes, words or sentences.
The nodes are pro-vided with a dedicated HMM in order to acousticallyrepresent the corresponding speech event.For system training, approximately half an hour ofcontinuous peech recorded from a single speaker isrequired along with its orthographic transcription.
Theacoustical analyser delivers every milisecond a set ofMel fi'equency cepstral coefficients along with theirslopes plus the energy of each frame.
A phone level de-scription is obtained using the orthographic transcrip-tion and a pronunciation dictionary.
In the initiali-sation step the feature vectors are classified into 64classes using a soft vector quantization technique.
Us-ing a phonetically abelled vocabulary a Baum-Welchtraining procedure is applied, and parameters ofmono-300PhonemeABC(:1)Ee314GHIJKI,MNOoPRSTUVZ2_Manual segmentation\[ms\] Ims\]82.00 30.8021.70 7.0675.90 17.6060.80 14.9024.50 11.3067.10 27.8083.80 20.6061.20 16.8088.30 16.1020.80 7.5482.40 41).2062.20 23.3041.40 17.8045.80 22.5047.50 14.9060.90 18.6044.00 18.7065.80 27.8097.80 24.50coniidenceinterval\[ms\]2.081,074.884.691.382.333.514.665.441.69.361.752.053.061.42.431.882.594.34Automatic segmentationx\[ms\](7\[msl30.2018.4025.3019.5016.8026.8025.0018.9032.7010.7056.8027.7024.8025.6019.1024.9018.4027.9028.4024.5044.3077.6076.2031.6065.4054.6058.2063.4038.9043.705.17I1.7027.7022.3013.9022.9010.3015.1011.51)16.0015.900.7 I1.143.576.651.23.11.82.583.841.410.9784.1042.3086.3069.5032.6076.5092.4087.7079.2028.9066.6078.7035.0061.0043.9051.9036.7077.40107.0039.41) 21.7039.40 l 7.1063.20 30.0076.70 29.2036.70 19.8075.30 25.4048.90 19.5049.70 18.3052.40 16.9027.10 I1.1025.90 11.30confidenceinterval\[ms\]2.022.797.026.142.052.254.275.22I1.012.5213.22.082.863.491.793.241.842.615.042.961.673.878.711.723.433.393.115.620.980.69Numberofsamples85217l52412605451365236737467929321043723138344212520940423446510213130136374951040"Iable 2: Average l)honeme duration, cot~fidence interval and xtandard eviation of the population,\[br manual andautomatic segmentation.phone models ark obtained.
By applying the Viterbialignment procedure, the training logatoms are auto-matically labelled using our monophone inventory.Due to the properties ot:the Slovenian language somephones are composed of several phone components,like the stop consonants k,p,b,d,t and the affricates cand & Such phones are described by multiple sub-models.
Table I gives the Slovenian phones and theircorresponding submodels as they are used li)r logatomsegmentation.A preliminary statistical evaluation of mantml andautomatic segmentation discrepancies was performedon a much larger speech database than the logatom in-ventory itself as proposed in (Schmidt93).
150 spokensentences were extracted fi'om the Slovenian speechcorpus GOPOI,IS (l)obrigek96) concerning airflighttimetable inquiries in total duration of 25 minutes.
Av-erage duration, conlidence interwtl and standard evi-ation of the population for both manual and automaticsegmentation are presented in Table 2.The discrepancies between manual and automaticsegmentation are considerable.
Most of the problemsarise when detecting bursts of plosives as tile automaticprocedure tends to shorten their closures considerably.The situation improves when plosives are taken as awhole, closures and bursts together.As a result, a fully automatic seglnentation f speechsegments i hardly conceivable in the context of con-catenation synthesis.
As most phonological units orig-inate via phonological considerations rather than onacoustic grounds, isolating them requires a deep priorknowledge of their specilic features.
Unsupervisedsegmentation, i.e.
segmentation on acoustic princi-ples only, often results in segments and sub-segmentsboundaries being misplaced, or just missing, while un-defined ones appear.
However, it can be used as a seg-mentation outline, the retinement of which has to beperformed by a human expert.301Figure 3: Automatic (above) and manual (center and below) segmentation fthe logatom inacu~.Thus automatic procedures can speed up the segmen-tation process, but they are not likely to suppress man-ual corrections, at least for obtaining highest synthesisquality with a given corpus.Diphone boundaries determinationAs the concatenation point of the diphones corre-sponds to the center of the phone, it is somewhere inthe steady region of the phone.
By studying the dis-tances from the signal to the target values, (Ottesen91)claims that minimal distances tend to be just before themiddle of the phoneme.
We decided to divide eachphoneme duration in a fixed ratio, 40 and 60%.
Plo-sives are exception to this rule: they are divided just infront of the opening burst.
A diphone boundary detec-tion algorithm, minimising spectral discontinuities atconcatenation points (Taylor91) may be investigated.5 ConclusionDiphone inventory acquisition for the Slovenian lan-guage was discussed.
In order to avoid the tedioustime consuming manual segmentation f logatoms, anautomatic procedure, based on HMM models is consi-dered.
Thus diphone sets for new synthetic voices areeasier to produce.
Results of the statistical evaluationof manual and automatic segmentation discrepanciesare given.We expect he whole process of creating anew wficeto be semi-automatic (with manual correction of stop-consonant boundaries), allowing the synthesiser to beretrained on a new voice in less than 3 days.302AcknowledgementThe authors wish to thank 3bma~ Erjavec tbr proof-reading of the text and his usefld comments on the ar-ticle.Re ferencesA.
Dobnikar and J. Bakran.
1995.
A new approachfor Slovene text-to-speech synthesis.
I'roceedingsMipro95.
Opatija, Croatia.
265-268.J.
Gros et al 1996.
A text-to-speech system for theSlovenian language.
Euxipco96.
Trieste, Italy.
Ac-cepted for presentation.P.
A.
%~ylor and S. D. Isard.
199l.
Automaticdiphone segmentation, l'roceedings Eurospeech91.Genova, Italy.
709-711.M.
S. Schmidt and G. S. Watson.
1993.
The eval-uation and optimization of automatic speech segmen-tation.
Proceedings Eumspeech93 Berlin, Germany.701-704.E Cosi et al 1991.
A preliminary statistical evalua-tion of manual and automatic segmentation discrepan-cies.
Proceedings Eurospeech91 Genova, Italy.
693-696.C.
Sorin et al 1987.
A Rhythm-Based ProsodicParser for Text-to-Speech Systems in French.
Pro-ceedings Xlth ICPhS.
Tallin, Estonia.
125-128.E.
Moulines and F. Charpentier.
1990.
Pitch - Syn-chronous Waveform Processing Techniques for Text-to-Speech Synthesis Using Diphones.
Speech Com-munication.
9:453-467.Y.
Medan et al 1991.
Super resolution pitch de-termination of speech signals.
IEITE Transactions onSignal Ptvcessing.
39(l):40-48.E.
G. Schukat-Talamazzini et al 1992.
Acousticmodelling of subword units in the ISADORA speechrecognizer, l'roceedings ICASSP92.
San Francisco,USA.
57'7-580.I~.
Rabiner.
1989.
A Tutorial on Iiidden MarkovModels and SelEcted Applications in Speech Recogni-tion.
Proceedings ~f the IEEE.
77(2):257-289.G.
E. Ottesen.
1991.
An automatic diphone segmen-tation system.
Proceedings Eurospeech93.
Berlin,Germany.
713-716.A.
Fourcin et al 1989.
Speech Input and OutputAs-sessment: Multilingual Methods and Standards.
EllisHorwood Limited, John Wiley & Sons, New York -Chichester - Brisbane - ~Ibronto.303
