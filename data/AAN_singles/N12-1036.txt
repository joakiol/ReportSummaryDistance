2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 352?356,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsTransAhead: A Computer-Assisted Translation and Writing ToolGG*Chung-chi Huang      +Ping-che Yang **Keh-jiann Chen       ++Jason S. Chang*ISA, NTHU, HsinChu, Taiwan, R.O.C.
**IIS, Academia Sinica, Taipei, Taiwan, R.O.C.+III, Taipei, Taiwan, R.O.C.
++CS, NTHU, HsinChu, Taiwan, R.O.C.
{*u901571,+maciaclark,++jason.jschang}@gmail.com; **kchen@iis.sinica.edu.twAbstractWe introduce a method for learning to predicttext completion given a source text and partialtranslation.
In our approach, predictions areoffered aimed at alleviating users?
burden onlexical and grammar choices, and improvingproductivity.
The method involves learningsyntax-based phraseology and translationequivalents.
At run-time, the source and itstranslation prefix are sliced into ngrams togenerate and rank completion candidates,which are then displayed to users.
We presenta prototype writing assistant, TransAhead, thatapplies the method to computer-assistedtranslation and language learning.
Thepreliminary results show that the method hasgreat potentials in CAT and CALL withsignificant improvement in translation qualityacross users.1 IntroductionMore and more language workers and learners usethe MT systems on the Web for informationgathering and language learning.
However, webtranslation systems typically offer top-1translations (which are usually far from perfect)and hardly interact with the user.Text translation could be achieved moreinteractively and effectively if a system consideredtranslation as a collaborative between the machinegenerating suggestions and the user accepting oroverriding on those suggestions, with the systemadapting to the user?s action.Consider the source sentence ??????????????????
(We play an important role inclosing this deal).
The best man-machineinteraction is probably not the one used by typicalexisting MT systems.
A good workingenvironment might be a translation assistant thatoffers suggestions and gives the user direct controlover the target text.We present a system, TransAhead1, that learnsto predict and suggest lexical translations (andtheir grammatical patterns) likely to follow theongoing translation of a source text, and adapts tothe user?s choices.
Example responses ofTransAhead to the source sentence ??????????????????
and two partial translationsare shown in Figure 1.
The responses include textand grammatical patterns (in all-cap labelsrepresenting parts-of-speech).
TransAheaddetermines and displays the probable subsequentgrammatical constructions and partial translationsin the form of parts-of-speech and words (e.g.,?IN[in] VBG[close,?]?
for keywords ?play role?where lexical items in square brackets are lemmasof potential translations) in a pop-up.
TransAheadlearns these constructs and translations duringtraining.At run-time, TransAhead starts with a sourcesentence, and iterates with the user, makingpredictions on the grammar patterns and lexicaltranslations, while adapting to the user?stranslation choices to resolve ambiguities in thesource sentence related to word segmentation andword sense.
In our prototype, TransAheadmediates between users and suggestion modules totranslation quality and  productivity.2 Related WorkComputer Assisted Translation (CAT) has been anarea of active research.
We focus on offeringsuggestions during the  translation process with  an1http://140.114.214.80/theSite/TransAhead/ (Chrome only)352Figure 1.
Example TransAhead responses to a source text under the translation (a) ?we?
and (b) ?we play animportant role?.
Note that the grammar/text predictions of (a) and (b) are not placed directly under the caret (currentinput focus) for space limit.
(c) and (d) depict predominant grammar constructs which follow and (e) summarizesthe confident translations of the source?s character-based ngrams.
The frequency of grammar pattern is shown inround brackets while the history (i.e., keyword) based on the user input is shown in shades.emphasis on language learning.
Specifically, ourgoal is to build a translation assistant to helptranslator (or learner-translator) with inlinegrammar help and translation.
Unlike recentresearch focusing on professional (e.g., Brown andNirenburg, 1990), we target on both professionaland student translators.More recently, interactive MT (IMT) systemshave begun to shift the user?s role from post-editing machine output to collaborating with themachine to produce the target text.
Foster et al(2000) describe TransType, a pioneering systemthat supports next word predictions.
Along thesimilar line, Koehn (2009) develops caitra whichpredicts and displays phrasal translationsuggestions one phrase at a time.
The maindifference between their systems and TransAheadis that we also display grammar patterns to providethe general patterns of predicted translations so astudent translator can learn and become moreproficient.Recent work has been done on using fully-fledged statistical MT systems to produce targethypotheses completing user-validated translationprefix in IMT paradigm.
Barrachina et al (2008)investigate the applicability of different MTkernels within IMT framework.
Nepveu et al(2004) and Ortiz-Martinez et al (2011) furtherexploit user feedbacks for better IMT systems anduser experience.
Instead of triggered by usercorrection, our method is triggered by worddelimiter and assists both translation and learningthe target language.In contrast to the previous CAT research, wepresent a writing assistant that suggests grammarconstructs as well as lexical translations followingusers?
partial translation, aiming to provide userswith choice to ease mental burden and enhanceperformance.3 The TransAhead System3.1 Problem StatementWe focus on predicting a set of grammar patternswith lexical translations likely to follow the currentpartial target translation of a source text.
Thepredictions will be examined by a human userdirectly.
Not to overwhelm the user, our goal is toreturn a reasonable-sized set of predictions thatcontain suitable word choices and grammaticalpatterns to choose and learn from.
Formally,Problem Statement: We are given a target-language reference corpus Ct, a parallel corpus Cst,a source-language text S, and its translation prefixTp.
Our goal is to provide a set of predictions basedon Ct and Cst likely to further translate S in terms ofgrammar and text.
For this, we transform S and Tpinto sets of ngrams such that the predominantgrammar constructs with suitable translationoptions following Tp are likely to be acquired.
(b)Source text: ????????????????
(a)Pop-up predictions/suggestions:we MD VB[play, act, ..]  (41369), ?we VBP[play, act, ..] DT  (13138), ?we VBD[play, act, ..] DT  (8139), ?Pop-up predictions/suggestions:play role IN[in] VBG[close, end, ..] (397), ?important role IN[in] VBG[close, end, ..]  (110), ?role IN[in] VBG[close, end, ..] (854), ?
(c)(d)(e)Patterns for ?we?
:we MD VB (41369), ?,we VBP DT (13138), ?,we VBD DT (8139), ?Patterns for ?we play an important role?
:play role IN[in] DT (599),play role IN[in] VBG (397), ?,important role IN[in] VBG (110), ?,role IN[in] VBG (854), ?Translations for the source text:????
: we, ?
; ????
: close, end, ?
;  ?
; ????
:play, ?
; ????
: critical, ?
; ?
; ???
: act, ?
; ?;???
: heavy, ?
; ???
: will, wish, ?
; ???
: cents, ?;???
: outstanding, ?Input your source text and start to interact with TransAhead!3533.2 Learning to Find Pattern and TranslationIn the training stage, we find and store syntax-based phraseological tendencies and translationpairs.
These patterns and translations are intendedto be used in a real-time system to respond to userinput speedily.First, we part of speech tag sentences in Ct.Using common phrase patterns (e.g., thepossessive noun one?s in ?make up one?s mind?
)seen in grammar books, we resort to parts-of-speech (POS) for syntactic generalization.
Then,we build up inverted files of the words in Ct for thenext stage (i.e., pattern grammar generation).
Apartfrom sentence and position information, a word?slemma and POS are also recorded.Subsequently, we use the procedure in Figure 2to generate grammar patterns following any givensequence of words, either contiguous or skipped.Figure 2.
Automatically generating pattern grammar.The algorithm first identifies the sentencescontaining the given sequence of words, query.Iteratively, Step (3) performs an AND operation onthe inverted file, InvList, of the current word wi andinterInvList, a previous intersected results.After that, we analyze query?s syntax-basedphraseology (Step (5)).
For each element of theform ([wordPosi(w1),?, wordPosi(wn)], sentencenumber) denoting the positions of query?s words inthe sentence, we generate grammar patterninvolving replacing words in the sentence withPOS tags and words in wordPosi(wi) with lemmas,and extracting fixed-window 2  segmentssurrounding query from the transformed sentence.The result is a set of grammatical patterns (i.e.,syntax-based phraseology) for the query.
Theprocedure finally returns top N predominant2Inspired by (Gamon and Leacock, 2010).syntactic patterns of the query.
Such patternscharacterizing the query?s word usages in the spiritof pattern grammar in (Hunston and Francis, 2000)and are collected across the target language.In the fourth and final stage, we exploit Cst forbilingual phrase acquisition, rather than a manualdictionary, to achieve better translation coverageand variety.
We obtain phrase pairs through anumber of steps, namely, leveraging IBM modelsfor bidirectional word alignments, grow-diagonal-final heuristics to extract phrasal equivalences(Koehn et al, 2003).3.3 Run-Time Grammar and Text PredictionOnce translation equivalents and phraseologicaltendencies are learned, they are stored for run-timereference.
TransAhead then predicts/suggests thefollowing grammar and text of a translation prefixgiven the source text using the procedure in Figure3.Figure 3.
Predicting pattern grammar andtranslations at run-time.We first slice the source text S into character-level ngrams, represented by {si}.
We also find theword-level ngrams of the translation prefix Tp.
Butthis time we concentrate on the ngrams, mayskipped, ending with the last word of Tp (i.e.,pivoted on the last word) since these ngrams aremost related to the subsequent grammar patterns.Step (3) and (4) retrieve translations and patternslearned from Section 3.2.
Step (3) acquires thetarget-language active vocabulary that may be usedto translate the source.
To alleviate the wordboundary issue in MT (Ma et al (2007)), the wordboundary in our system is loosely decided.
Initially,TransAhead non-deterministically segments thesource text using character ngrams for translationsand proceeds with collaborations with the user toobtain the segmentation for MT and to completethe translation.
Note that Tp may reflect sometranslated segments, reducing the size of the activevocabulary, and that a user vocabulary ofpreference (due to users?
domain knowledge orprocedure PatternFinding(query,N,Ct) (1)  interInvList=findInvertedFile(w1 of query)for each word wi in query except for w1 (2)     InvList=findInvertedFile(wi) (3a)   newInterInvList= ?
; i=1; j=1(3b)   while i<=length(interInvList) and j<=lengh(InvList)(3c)      if interInvList[i].SentNo==InvList[j].SentNo(3d)         Insert(newInterInvList, interInvList[i],InvList[j])else(3e)         Move i,j accordingly(3f)    interInvList=newInterInvList(4) Usage= ?for each element in interInvList(5)     Usage+={PatternGrammarGeneration(element,Ct)} (6) Sort patterns in Usage in descending order of frequency(7) return the N patterns in Usage with highest frequencyprocedure MakePrediction(S,Tp)(1) Assign sliceNgram(S) to {si} (2) Assign sliceNgramWithPivot(Tp) to {tj} (3) TransOptions=findTranslation({si},Tp) (4) GramOptions=findPattern({tj}) (5) Evaluate translation options in TransOptionsand incorporate them into GramOptions (6) Return GramOptions354errors of the system) may be exploited for bettersystem performance.
In addition, Step (4) extractspatterns preceding with the history ngrams of {tj}.In Step (5), we first evaluate and rank thetranslation candidates using linear combination:( ) ( )( ) ( )1 1 1 2 2   i i pP t s P s t P t T?
??
+ + ?where ?i is combination weight, P1 and P2 aretranslation and language model respectively, and tis one of the translation candidates under S and Tp.Subsequently, we incorporate the lemmatizedtranslation candidates according to their ranks intosuitable grammar constituents in GramOptions.For example, we would include ?close?
in pattern?play role IN[in] VBG?
as ?play role IN[in]VBG[close]?.At last, the algorithm returns the representativegrammar patterns with confident translationsexpected to follow the ongoing translation andfurther translate the source.
This algorithm will betriggered by word delimiter to provide aninteractive CAT and CALL environment.
Figure 1shows example responses of our working prototype.4 Preliminary ResultsIn developing TransAhead, we used BritishNational Corpus and Hong Kong Parallel Text astarget-language reference corpus and paralleltraining corpus respectively, and deployed GENIAtagger for lemma and POS analyses.To evaluate TransAhead in CAT and CALL, weintroduced it to a class of 34 (Chinese) collegefreshmen learning English as foreign language.
Wedesigned TransAhead to be accessible and intuitive,so the user training tutorial took only one minute.After the tutorial, the participants were asked totranslate 15 Chinese texts from (Huang et al, 2011)(half with TransAhead assistance called experi-mental group, and the other without any systemhelp whatsoever called control group).
Theevaluation results show that the experimentalgroup achieved much better translation quality thanthe control group with an average BLEU score(Papineni et al, 2002) of 35.49 vs. 26.46.Admittedly, the MT system Google Translateproduced translations with a higher BLEU score of44.82.Google Translate obviously has much moreparallel training data and bilingual translationknowledge.
No previous work in CAT uses GoogleTranslate for comparison.
Although there is adifference in average translation quality betweenthe experimental TransAhead group and theGoogle Translate, it is not hard for us to notice thesource sentences were better translated bylanguage learners with the help of TransAhead.Take the sentence  ??????????????????
for example.
A total of 90% of the participantsin the experimental group produced moregrammatical and fluent translations (see Figure 4)than that (?We conclude this transaction plays animportant role?)
by Google Translate.Figure 4.
Example translations withTransAhead assistance.Post-experiment surveys indicate that (a) theparticipants found Google Translate lack human-computer interaction while TransAhead is intuitiveto collaborate with in translation/writing; (b) theparticipants found TransAhead grammar andtranslation predictions useful for their immediatetask and for learning; (c) interactivity made thetranslation and language learning a fun process(like image tagging game of (von Ahn and Dabbish,2004)) and the participants found TransAhead veryrecommendable and would like to use it again infuture translation tasks.5 SummaryWe have introduced a method for learning to offergrammar and text predictions expected to assist theuser in translation and writing.
We haveimplemented and evaluated the method.
Thepreliminary results are encouragingly promising.As for the further work, we intend to evaluate andimprove our system further in learner productivityin terms of output quality, typing speed, and theamount of using certain keys such as delete andbackspace.AcknowledgementThis study is conducted under the ?Project DigitalConvergence Service Open Platform?
of theInstitute for Information Industry which issubsidized by the Ministry of Economy Affairs ofthe Republic of China.1.
we play(ed) a critical role in closing this/the deal.2.
we play(ed) a critical role in sealing this/the deal.3.
we play(ed) an important role in ending this/the deal.4.
we play(ed) an important role in closing this/the deal.355ReferencesS.
Barrachina, O. Bender, F. Casacuberta, J. Civera, E.Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Tomas, E.Vidal, and J.-M. Vilar.
2008.
Statistical approachesto computer-assisted translation.
ComputationalLinguistics, 35(1): 3-28.R.
D. Brown and S. Nirenburg.
1990.
Human-computerinteraction for semantic disambiguation.
InProceedings of COLING, pages 42-47.G.
Foster, P. Langlais, E. Macklovitch, and G. Lapalme.2002.
TransType: text prediction for translators.
InProceedings of ACL Demonstrations, pages 93-94.M.
Gamon and C. Leacock.
2010.
Search right and thoushalt find ?
using web queries for learner errordetection.
In Proceedings of the NAACL Workshop.C.-C. Huang, M.-H. Chen, S.-T. Huang, H.-C. Liou, andJ.
S. Chang.
2011.
GRASP: grammar- and syntax-based pattern-finder in CALL.
In Proceedings ofACL Workshop.S.
Hunston and G. Francis.
2000.
Pattern Grammar: ACorpus-Driven Approach to the Lexical Grammar ofEnglish.
Amsterdam: John Benjamins.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proceedings of NAACL.P.
Koehn.
2009.
A web-based interactive computeraided translation tool.
In Proceedings of ACL.Y.
Ma, N. Stroppa, and A.
Way.
2007.
Bootstrappingword alignment via word packing.
In Proceedings ofACL.L.
Nepveu, G. Lapalme, P. Langlais, and G. Foster.2004.
Adaptive language and translation models forinteractive machine translation.
In Proceedings ofEMNLP.D.
Ortiz-Martinez, L. A. Leiva, V. Alabau, I. Garcia-Varea, and F. Casacuberta.
2011.
An interactivemachine translation system with online learning.
InProceedings of ACL System Demonstrations, pages68-73.K.
Papineni, S. Roukos, T. Ward, W.-J.
Zhu.
2002.
Bleu:a method for automatic evaluation of machinetranslation.
In Proceedings of ACL, pages 311-318.L.
von Ahn and L. Dabbish.
2004.
Labeling images witha computer game.
In Proceedings of CHI.356
