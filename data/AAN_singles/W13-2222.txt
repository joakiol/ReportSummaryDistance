Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 177?184,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsShallow Semantically-Informed PBSMT and HPBSMTTsuyoshi OkitaQun LiuJosef van GenabithDublin City UniversityGlasnevin, Dublin 9, Ireland{tokita,qliu,josef}@computing.dcu.ieAbstractThis paper describes shallowsemantically-informed HierarchicalPhrase-based SMT (HPBSMT) andPhrase-Based SMT (PBSMT) systemsdeveloped at Dublin City Universityfor participation in the translation taskbetween EN-ES and ES-EN at the Work-shop on Statistical Machine Translation(WMT 13).
The system uses PBSMTand HPBSMT decoders with multipleLMs, but will run only one decodingpath decided before starting translation.Therefore the paper does not present amulti-engine system combination.
Weinvestigate three types of shallow seman-tics: (i) Quality Estimation (QE) score,(ii) genre ID, and (iii) context ID derivedfrom context-dependent language models.Our results show that the improvement is0.8 points absolute (BLEU) for EN-ESand 0.7 points for ES-EN compared tothe standard PBSMT system (single bestsystem).
It is important to note that wedeveloped this method when the standard(confusion network-based) system com-bination is ineffective such as in the casewhen the input is only two.1 IntroductionThis paper describes shallow semantically-informed Hierarchical Phrase-based SMT(HPBSMT) and Phrase-Based SMT (PBSMT)systems developed at Dublin City Universityfor participation in the translation task betweenEN-ES and ES-EN at WMT 13.
Our objectivesare to incorporate several shallow semantics intoSMT systems.
The first semantics is the QE scorefor a given input sentence which can be used toselect the decoding path either of HPBSMT orPBSMT.
Although we call this a QE score, thisscore is not quite a standard one which does nothave access to translation output information.
Thesecond semantics is genre ID which is intended tocapture domain adaptation.
The third semanticsis context ID: this context ID is used to adjust thecontext for the local words.
Context ID is used ina continuous-space LM (Schwenk, 2007), but isimplicit since the context does not appear in theconstruction of a continuous-space LM.
Note thatour usage of the term semantics refers to meaningconstructed by a sentence or words.
The QEscore works as a sentence level switch to selectHPBSMT or PBSMT, based on the semanticsof a sentence.
The genre ID gives an indicationthat the sentence is to be translated by genre ID-sensitive MT systems, again based on semanticson a sentence level.
The context-dependent LMcan be interpreted as supplying the local contextto a word, capturing semantics on a word level.The architecture presented in this paper is sub-stantially different from multi-engine system com-bination.
Although the system has multiple paths,only one path is chosen at decoding when process-ing unseen data.
Note that standard multi-enginesystem combination using these three semanticshas been presented before (Okita et al 2012b;Okita et al 2012a; Okita, 2012).
This paper alsocompares the two approaches.The remainder of this paper is organized as fol-lows.
Section 2 describes the motivation for ourapproach.
In Section 3, we describe our proposedsystems, while in Section 4 we describe the exper-imental results.
We conclude in Section 5.2 MotivationModel Difference of PBSMT and HPBSMTOur motivation is identical with a system combi-nation strategy which would obtain a better trans-lation if we can access more than two translations.Even though we are limited in the type of MT sys-177tems, i.e.
SMT systems, we can access at leasttwo systems, i.e.
PBSMT and HPBSMT systems.The merit that accrues from accessing these twotranslation is shown in Figure 1.
In this exam-ple between EN-ES, the skirts of the distributionshows that around 20% of the examples obtain thesame BLEU score, 37% are better under PBSMT,and 42% under HPBSMT.
Moreover, around 10%of sentences show difference of 10 BLEU points.Even a selection of outputs would improve the re-sults.
Unfortunately, some pitfall of system com-bination (Rosti et al 2007) impact on the processwhen the number of available translation is onlytwo.
If there are only two inputs, (1) the mismatchof word order and word selection would yield abad combination since system combination relieson monolingual word alignment (or TER-basedalignment) which seeks identical words, and (2)Minimum Bayes Risk (MBR) decoding, which isa first step, will not work effectively since it re-lies on voting.
(In fact, only selecting one of thetranslation outputs is even effective: this methodis called system combination as well (Specia et al2010).)
Hence, although the aim is similar, we donot use a system combination strategy, but we de-velop a semantically-informed SMT system.Figure 1: Figure shows the difference of sentence-based performance between PBSMT and HPB-SMT systems.Relation of Complexity of Source Sentence andPerformance of HPBSMT and PBSMT It isinteresting to note that PBSMT tends to be bet-ter than HPBSMT for European language pairsas the recent WMT workshop shows, while HPB-SMT shows often better performance for distantlanguage pairs such as EN-JP (Okita et al 2010b)and EN-ZH in other workshops.Under the assumption that we use the sametraining corpus for training PBSMT and HPBSMTsystems, our hypothesis is that we may be ableto predict the quality of translation.
Note that al-though this is the analogy of quality estimation,the setting is slightly different in that in test phase,we will not be given a translation output, but onlya source sentence.
Our aim is to predict whetherHPBSMT obtains better translation output thanPBSMT or not.
Hence, our aim does not requirethat the quality prediction here is very accuratecompared to the standard quality estimation task.We use a feature set consisting of various charac-teristics of input sentences.3 Our Methods: Shallow SemanticsOur system accommodates PBSMT and HPBSMTwith multiple of LMs.
A decoder which handlesshallow semantic information is shown in Table3.1.3.1 QE ScoreQuality estimation aims to predict the quality oftranslation outputs for unseen data (e.g.
by build-ing a regressor or a classifier) without access toreferences: the inputs are translation outputs andsource sentences in a test phase, while in a trainingphase the corresponding BLEU or HTER scoresare used.
In this subsection, we try to build a re-gressor with the similar settings but without sup-plying the translation outputs.
That is, we supplyonly the input sentences.
(Since our method is nota quality estimation for a given translation output,quality estimation may not be an entirely appro-priate term.
However, we borrow this term for thispaper.)
If we can build such a regressor for PB-SMT and HPBSMT systems, we would be ableto select a better translation output without actu-ally translating them for a given input sentence.Note that we translate the training set by PBSMTand HPBSMT in a training phase only to supplytheir BLEU scores to a regressor (since a regres-sor is a supervised learning method).
Then, weuse these regressors for a given unseen source sen-tence (which has no translation output attached) topredict their BLEU scores for PBSMT and HPB-SMT.Our motivation came from the comparison ofa sequential learning system and a parser-basedsystem.
The typical decoder of the former is a178Viterbi decoder while that of the latter is a Cocke-Younger-Kasami (CYK) decoder (Younger, 1967).The capability of these two systems providesan intuition about the difference of PBSMT andHPBSMT: the CYK decoder-based system hassome capability to handle syntactic constructionswhile the Viterbi decoder-based system has onlythe capability of learning a sequence.
For ex-Input: Foreign sent f=f1,...,f1f , language model,translation model, rule table.Output: English translation eceScore = predictQEScore(fi)if (ceScore == HPBSMTBetter)for span length l=1 to 1f dofor start=0..1f -1 dogenreID = predictGenreID(fi)end = start + 1forall seq s of entries and words in span[start,end] doforall rules r doif rule r applies to chart seq s thencreate new chart entry cwith LM(genreID)add chart entry c to chartreturn e from best chart entry in span [0,1f ]else:genreID = predictGenreID(fi)place empty hypothesis into stack 0for all stacks 0...n-1 dofor all hypotheses in stack dofor all translation options doif applicable thencreate new hyp with LM(ID)place in stackrecombine with existing hyp ifpossibleprune stack if too bigreturn epredictQEScore()predictGenreID()predictContextID(wordi, wordi?1)Table 1: Decoding algorithm: the main algorithmof PBSMT and HPBSMT are from (Koehn, 2010).The modification is related to predictQEScore(),predictGenreID(), and predictContextID().ample, the (context-free) grammar-based systemhas the capability of handling various difficul-ties caused by inserted clauses, coordination, longMultiword Expressions, and parentheses, whilethe sequential learning system does not (This issince this is what the aim of the context-freegrammar-based system is.)
These difficulties aremanifest in input sentences.0 50 100 150 200 250 300sample ID?1.0?0.50.00.51.0differenceofBLEUpointstrue BLEU difference of PBSMT and HPBSMTpredicted BLEU difference of PBSMT and HPBSMTFigure 2: A blue line shows the true BLEU dif-ference between PBSMT and HPBSMT (y-axis)where x-axis is the sample IDs reordered in de-scending order (blue), while green dots show theBLEU absolute difference (y-axis) of the typicalsamples where x-axis is shared with the above.This example is sampled 300 points from new-stest2013 (ES-EN).
Even if the regressor does notachieve a good performance, the bottom line of theoverall performance is already really high in thistricky problem.
Roughly, even if we plot randomlywe could achieve around 80 - 90% of correctness.Around 50% of samples (middle of the curve) donot care (since the true performance of PBSMTand HPBSMT are even), there is a slope in the leftside of the curve where random plot around thiscurve would achieve 15 - 20% among 25% of cor-rectness (the performance of PBSMT is superior),and there is another slope in the right side of thecurve where random plot would achieve again 15- 20% among 25% (the performance of HPBSMTis superior).
In this case, accuracy is 86%.If we assume that this is one major differencebetween these two systems, the complexity of theinput sentence will correlate with the difference oftranslation quality of these two systems.
In thissubsection, we assume that this is one major dif-ference of these two systems and that the complex-ity of the input sentence will correlate with the dif-ference of translation quality of these two systems.Based on these assumptions, we build a regressor179for each system for a given input sentence where ina training phase we supply the BLEU score mea-sured using the training set.
One remark is that theBLEU score which we predict is only meaning-ful in a relative manner since we actually generatea translation output in preparation phase (there isa dependency to the mean of BLEU score in thetraining set).
Nevertheless, this is still meaningfulas a relative value if we want to talk about theirdifference, which is what we want in our settingsto predict which system, either PBSMT or HPB-SMT, will generate a better output.The main features used for training the regres-sor are as follows: (1) number of / length of in-serted clause / coordination / multiword expres-sions, (2) number of long phrases (connection by?of?
; ordering of words), (3) number of OOVwords (which let it lower the prediction quality),(4) number of / length of parenthesis, etc.
We ob-tained these features using parser (de Marneffe etal., 2006) and multiword extractor (Okita et al2010a).3.2 Genre IDGenre IDs allow us to apply domain adaptationtechnique according to the genre ID of the testset.Among various methods of domain adaptation, weinvestigate unsupervised clustering rather than al-ready specified genres.We used (unsupervised) classification via La-tent Dirichlet Allocation (LDA) (Blei et al 2003)to obtain genre ID.
LDA represents topics asmultinomial distributions over the W uniqueword-types in the corpus and represents docu-ments as a mixture of topics.Let C be the number of unique labels in thecorpus.
Each label c is represented by a W -dimensional multinomial distribution ?c over thevocabulary.
For document d, we observe both thewords in the document w(d) as well as the docu-ment labels c(d).
Given the distribution over top-ics ?d, the generation of words in the document iscaptured by the following generative model.1.
For each label c ?
{1, .
.
.
C}, sample a distri-bution over word-types ?c ?
Dirichlet(?|?)2.
For each document d ?
{1, .
.
.
, D}(a) Sample a distribution over its observedlabels ?d ?
Dirichlet(?|?
)(b) For each word i ?
{1, .
.
.
, NWd }i.
Sample a label z(d)i ?Multinomial(?d)ii.
Sample a word w(d)i ?Multinomial(?c) from the la-bel c = z(d)iUsing topic modeling (or LDA) as describedabove, we perform the in-domain data partitioningas follows, building LMs for each class, and run-ning a decoding process for the development set,which will obtain the best weights for cluster i.1.
Fix the number of clusters C, we explore val-ues from small to big.12.
Do unsupervised document classification (orLDA) on the source side of the training, de-velopment and test sets.3.
Separate each class of training sets and buildLM for each cluster i (1 ?
i ?
C).4.
Separate each class of development set (keepthe original index and new index in the allo-cated separated dataset).5.
(Using the same class of development set):Run the decoder on each class to obtain then-best lists, run a MERT process to obtain thebest weights based on the n-best lists, (Repeatthe decoding / MERT process several itera-tions.
Then, we obtain the best weights for aparticular class.
)For the test phase,1.
Separate each class of the test set (keep theoriginal index and new index in the allocatedseparated dataset).2.
Suppose the test sentence belongs to clusteri, run the decoder of cluster i.3.
Repeat the previous step until all the test sen-tences are decoded.3.3 Context IDContext ID semantics is used through the re-ranking of the n-best list in a MERT process(Schwenk, 2007; Schwenk et al 2012; Le et al2012).
2-layer ngram-HMM LM is a two layerversion of the 1-layer ngram-HMM LM (Blun-som and Cohn, 2011) which is a nonparametric1Currently, we do not have a definite recommendation onthis.
It needs to be studied more deeply.180Bayesian method using hierarchical Pitman-Yorprior.
In the 2-layer LM, the hidden sequence ofthe first layer becomes the input to the higher layerof inputs.
Note that such an architecture comesfrom the Restricted Boltzmann Machine (Smolen-sky, 1986) accumulating in multiple layers in or-der to build deep belief networks (Taylor and Hin-ton, 2009).
Although a 2-layer ngram-HMM LMis inferior in its performance compared with othertwo LMs, the runtime cost is cheaper than these.ht denotes the hidden word for the first layer, h?tdenotes the hidden word for the second layer, widenotes the word in output layer.
The generativemodel for this is shown below.ht|h?t ?
F (?
?st) (1)wt|ht ?
F (?st) (2)wi|w1:i?1 ?
PY(di, ?i, Gi) (3)where ?
is a concentration parameter, ?
is astrength parameter, and Gi is a base measure.Note that these terms belong to the hierarchicalPitman-Yor language model (Teh, 2006).
We useda blocked inference for inference.
The perfor-mance of 2-layer LM is shown in Table 3.4 Experimental SettingsWe used Moses (Koehn et al 2007) for PBSMTand HPBSMT systems in our experiments.
TheGIZA++ implementation (Och and Ney, 2003) ofIBM Model 4 is used as the baseline for wordalignment: Model 4 is incrementally trained byperforming 5 iterations of Model 1, 5 iterationsof HMM, 3 iterations of Model 3, and 3 iter-ations of Model 4.
For phrase extraction thegrow-diag-final heuristics described in (Koehn etal., 2003) is used to derive the refined alignmentfrom bidirectional alignments.
We then performMERT process (Och, 2003) which optimizes theBLEU metric, while a 5-gram language model isderived with Kneser-Ney smoothing (Kneser andNey, 1995) trained with SRILM (Stolcke, 2002).For the HPBSMT system, the chart-based decoderof Moses (Koehn et al 2007) is used.
Most of theprocedures are identical with the PBSMT systemsexcept the rule extraction process (Chiang, 2005).The procedures to handle three kinds of se-mantics are implemented using the already men-tioned algorithm.
We use libSVM (Chang and Lin,2011), and Mallet (McCallum, 2002) for LatentDirichlet Allocation (LDA) (Blei et al 2003).For the corpus, we used all the resources pro-vided for the translation task at WMT13 for lan-output layer2?layer conditional RBM language modelngram language model1st RBM2nd RBMhidden layeroutput layerNprojection layerdiscrete representationNPneural networkprobability estimationcontinuous?space languagemodel [Schwenk, 2007]1st hidden layer2?layer ngram?HMM language model2nd hidden layeroutput layerngram language modelFigure 3: Figure shows the three kinds of context-dependent LM.
The upper-side shows continuous-space language model (Schwenk, 2007).
Thelower-left shows ours, i.e.
the 2-layer ngram-HMM LM.
The lower-right shows the 2-layer con-ditional Restricted Boltzmann Machine LM (Tay-lor and Hinton, 2009).guage model, that is parallel corpora (EuroparlV7 (Koehn, 2005), Common Crawl corpus, UNcorpus, and News Commentary) and monolingualcorpora (Europarl V7, News Commentary, andNews Crawl from 2007 to 2012).Experimental results are shown in Table 2.The left-most column (sem-inform) shows our re-sults.
The sem-inform made a improvement of 0.8BLEU points absolute compared to the PBSMTresults in EN-ES, while the standard system com-bination lost 0.1 BLEU points absolute comparedto the single worst.
For ES-EN, the sem-informmade an improvement of 0.7 BLEU points abso-lute compared to the PBSMT results.
These im-provements over both of PBSMT and HPBSMTare statistically significant by a paired bootstraptest (Koehn, 2004).5 ConclusionThis paper describes shallow semantically-informed HPBSMT and PBSMT systems devel-oped at Dublin City University for participation inthe translation task at the Workshop on StatisticalMachine Translation (WMT 13).
Our system has181EN-ES sem-inform PBSMT HPBSMT syscomb aug-syscombBLEU 30.3 29.5 28.2 28.1 28.5BLEU(11b) 30.3 29.5 28.2 28.1 28.5BLEU-cased 29.0 28.4 27.1 27.0 27.5BLEU-cased(11b) 29.0 28.4 27.1 27.0 27.5NIST 7.91 7.74 7.35 7.35 7.36Meteor 0.580 0.579 0.577 0.577 0.578WER 53.7 55.4 59.3 59.2 58.9PER 41.3 42.4 46.0 45.8 45.5ES-EN sem-inform PBSMT HPBSMT syscomb aug-syscombBLEU 31.1 30.4 23.1?
28.8 29.9BLEU(11b) 31.1 30.4 23.1?
28.8 29.9BLEU-cased 29.7 29.1 22.3?
27.9 28.8BLEU-cased(11b) 29.7 29.1 22.3?
27.9 28.8NIST 7.87 7.79 6.67?
7.40 7.71Meteor 0.615 0.612 0.533?
0.612 0.613WER 54.8 55.4 62.5?
59.3 56.1PER 41.3 41.8 48.3?
45.8 41.9Table 2: Table shows the score where ?sem-inform?
shows our system.
Underlined figure shows theofficial score.
?syscomb?
denotes the confusion-network-based system combination using BLEU, while?aug-syscomb?
uses three shallow semantics described in QE score (Okita et al 2012a), genre ID (Okitaet al 2012b), and context ID (Okita, 2012).
Note that the inputs for syscomb and aug-syscomb are theoutput of HPBSMT and PBSMT.
HPBSMT from ES to EN has marked with ?, which indicates that thisis trained only with Europarl V7.2-layer ngram- SRI-EN HMM LM LMnewstest12 130.4 140.3newstest11 146.2 157.1newstest10 156.4 166.8newstest09 176.3 187.1Table 3: Table shows the perplexity of context-dependent language models, which is 2-layerngram HMM LM, and that of SRILM (Stolcke,2002) in terms of newstest09 to 12.PBSMT and HPBSMT decoders with multipleLMs, but our system will execute only one path,which is different from multi-engine systemcombination.
We consider investigate three typesof shallow semantic information: (i) a QualityEstimate (QE) score, (ii) genre ID, and (iii) acontext ID through context-dependent languagemodels.
Our experimental results show that theimprovement is 0.8 points absolute (BLEU) forEN-ES and 0.7 points for ES-EN compared tothe standard PBSMT system (single best system).We developed this method when the standard(confusion network-based) system combination isineffective such as in the case when the input isonly two.A further avenue would be the investigation ofother semantics such as linguistic semantics, in-cluding co-reference resolution or anaphora reso-lution, hyper-graph decoding, and text understand-ing.
Some of which are investigated in the contextof textual entailment task (Okita, 2013b) and wewould like to extend this to SMT task.
Anotherinvestigation would be the integration of genre IDinto the context-dependent LM.
The preliminarywork shows that such integration would decreasethe overall perplexity (Okita, 2013a).AcknowledgmentsWe thank Antonio Toral and Santiago Corte?sVa?
?lo for providing parts of their processingdata.
This research is supported by the ScienceFoundation Ireland (Grant 07/CE/I1142) as partof the Centre for Next Generation Localisation(http://www.cngl.ie) at Dublin City Uni-versity.182ReferencesDavid Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alcation.
Journal of Ma-chine Learning Research, 3:9931022.Phil Blunsom and Trevor Cohn.
2011.
A hierarchicalpitman-yor process hmm for unsupervised part ofspeech induction.
In Proceedings of Annual Meet-ing of the Association for Computational Linguistics(ACL11), pages 865?874.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A library for support vector machines.
ACMTransactions on Intelligent Systems and Technology,2:27:1?27:27.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the 43th Annual Meeting of the Associa-tion for Computational Linguistics (ACL-05), pages263?270.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of the Sixth International Conferenceon Language Resources and Evaluation (LREC-2006), pages 449?454.Reinhard Kneser and Hermann Ney.
1995.
Im-proved backing-off for n-gram language modeling.In Proceedings of the IEEE International Confer-ence on Acoustics, Speech and Signal Processing,pages 181?184.Philipp Koehn, Franz Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceed-ings of the Human Language Technology Confer-ence of the North American Chapter of the Associ-ation for Computationa Linguistics (HLT / NAACL2003), pages 115?124.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for Statistical Machine Translation.
InProceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics CompanionVolume Proceedings of the Demo and Poster Ses-sions, pages 177?180.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofConference on Empirical Methods in Natural Lan-guage Processing (EMNLP 2004), pages 388?395.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of theMachine Translation Summit, pages 79?86.Philipp Koehn.
2010.
Statistical machine translation.Cambridge University Press.Hai-Son Le, Thomas Lavergne, Alexandre Allauzen,Marianna Apidianaki, Li Gong, Aurelien Max,Artem Sokolov, Guillaume Wisniewski, and Fran-cois Yvon.
2012.
Limsi at wmt12.
In Proceed-ings of the Seventh Workshop on Statistical MachineTranslation, pages 330?337.Andrew Kachites McCallum.
2002.
Mal-let: A machine learning for language toolkit.http://mallet.cs.umass.edu.Franz Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19?51.Franz Och.
2003.
Minimum Error Rate Training inStatistical Machine Translation.
In Proceedings ofthe 41st Annual Meeting of the Association for Com-putational Linguistics, pages 160?167.Tsuyoshi Okita, Alfredo Maldonado Guerra, YvetteGraham, and Andy Way.
2010a.
Multi-Word Ex-pression sensitive word alignment.
In Proceed-ings of the Fourth International Workshop On CrossLingual Information Access (CLIA2010, collocatedwith COLING2010), Beijing, China., pages 1?8.Tsuyoshi Okita, Jie Jiang, Rejwanul Haque, Hala Al-Maghout, Jinhua Du, Sudip Kumar Naskar, andAndy Way.
2010b.
MaTrEx: the DCU MT Systemfor NTCIR-8.
In Proceedings of the MII Test Col-lection for IR Systems-8 Meeting (NTCIR-8), pages377?383.Tsuyoshi Okita, Raphae?l Rubino, and Josef van Gen-abith.
2012a.
Sentence-level quality estima-tion for mt system combination.
In Proceedingsof ML4HMT Workshop (collocated with COLING2012), pages 55?64.Tsuyoshi Okita, Antonio Toral, and Josef van Gen-abith.
2012b.
Topic modeling-based domain adap-tation for system combination.
In Proceedingsof ML4HMT Workshop (collocated with COLING2012), pages 45?54.Tsuyoshi Okita.
2012.
Neural Probabilistic LanguageModel for System Combination.
In Proceedingsof ML4HMT Workshop (collocated with COLING2012), pages 65?76.Tsuyoshi Okita.
2013a.
Joint space neural probabilis-tic language model for statistical machine transla-tion.
Technical Report at arXiv, 1301(3614).Tsuyoshi Okita.
2013b.
Local graph matching withactive learning for recognizing inference in text atntcir-10.
NTCIR 10 Conference, pages 499?506.Antti-Veikko I. Rosti, Spyros Matsoukas, and RichardSchwartz.
2007.
Improved word-level system com-bination for machine translation.
In Proceedings ofthe 45th Annual Meeting of the Association for Com-putational Linguistics, pages 312?319.183Holger Schwenk, Anthony Rousseau, and MohammedAttik.
2012.
Large, pruned or continuous space lan-guage models on a gpu for statistical machine trans-lation.
In NAACL-HLT workshop on the Future ofLanguage Modeling for HLT, pages 11?19.Holger Schwenk.
2007.
Continuous space languagemodels.
Computer Speech and Language, 21:492?518.Paul Smolensky.
1986.
Chapter 6: Information pro-cessing in dynamical systems: Foundations of har-mony theory.
In Rumelhart, David E.; McLel-land, James L. Parallel Distributed Processing:Explorations in the Microstructure of Cognition,1:194281.Lucia Specia, D. Raj, and Marco Turchi.
2010.
Ma-chine translation evaluation versus quality estima-tion.
Machine Translation, Springer, 24(1):39?50.Andreas Stolcke.
2002.
SRILM ?
An extensible lan-guage modeling toolkit.
In Proceedings of the Inter-national Conference on Spoken Language Process-ing, pages 901?904.Graham Taylor and Geoffrey Hinton.
2009.
Factoredconditional restricted boltzmann machines for mod-eling motion style.
In Proceedings of the 26th Inter-national Conference on Machine Learning (ICML),pages 1025?1032.Yee Whye Teh.
2006.
A hierarchical bayesian lan-guage model based on pitman-yor processes.
InProceedings of the 44th Annual Meeting of the As-sociation for Computational Linguistics (ACL-06),Prague, Czech Republic, pages 985?992.Daniel H. Younger.
1967.
Recognition and parsing ofcontext-free languages in time n3.
Information andControl, 10(2):189208.184
