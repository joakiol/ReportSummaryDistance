Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 21?22,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsAutomatic Detection of Tags for Political BlogsKhairun-nisa Hassanali Vasileios HatzivassiloglouHuman Language Technology Institute Human Language Technology InstituteThe University of Texas at Dallas The University of Texas at DallasRichardson, TX 75080, USA Richardson, TX 75080, USAnisa@hlt.utdallas.edu vh@hlt.utdallas.eduAbstractThis paper describes a technique for automati-cally tagging political blog posts using SVM?sand named entity recognition.
We comparethe quality of the tags detected by this ap-proach to earlier approaches in other domains,observing effects from the political domainand benefits from NLP techniques comple-mentary to the core SVM method.1 IntroductionPolitical blogs are a particular type of communica-tion platform that combines analyses provided bythe blog owner or a team of regular contributorswith shorter, but far more numerous, entries byvisitors.
Given the enthusiasm that activities for oragainst a particular politician or party can generate,political blogs are a vibrant part of the blogos-phere: more than 38,500 blogs specifically dedi-cated to politics exist in the US alone according toTechnorati, and some of the more active ones at-tract more than 30 million unique visitors eachmonth (double that number just before major elec-tions).Political blogs provide a wealth of factual in-formation about political events and activities, butalso by their nature are colored by strong opinions.They are therefore a particularly attractive targetfor semantic analysis methods using natural lan-guage processing technology.
In fact, the past twoyears have brought an increased number of colla-borations between NLP researchers and politicalscientists using data from political sources, includ-ing two special issues of leading political sciencejournals on such topics (see (Cardie and Wilker-son, 2008) for an overview).
Our motivation forworking with this kind of data is the constructionof a system that collates information across blogposts, combines evidence to numerically rate atti-tudes of blogs on different topics, and traces theevolution of these attitudes across time and in re-sponse to events.
To enable these tasks, we firstidentify the major topics that each blog post cov-ers.
In the present paper, we describe our recogniz-er of blog post topics.
We show that, perhapsbecause of the richness of political blogs in namedentities, an SVM-based keyword learning approachcan be complemented with named entity recogni-tion and co-reference detection to achieve preci-sion and recall scores higher than those reported byearlier topic recognition systems in other domains.2 Related WorkIn our approach, as in earlier published work, wetake tags assigned by many blogs to individualblog posts as a reference list of the topics coveredby that post.
Tags are single words or short phras-es, most often noun phrases, and are usually cho-sen by each post?s authors without a controlledvocabulary; examples include ?Michigan?,?George Bush?, ?democracy?, and ?health care?.Earlier work in predicting tags includes (Mishne,2006), who adopts a collaborative filtering ap-proach; in contrast, we rely on training classifiersfrom earlier posts in each blog.
Our approach ismore similar to (Sood et al, 2007) and (Wang andDavison, 2008) who use different machine learningtechniques applied to a training set.
We differ fromthe last two approaches in our addition of propernoun and named entity recognition methods to ourcore SVM classifiers, in our exploration of specifi-cally political data, and in our subsequent use of21the predicted tags (for semantic analysis ratherthan tag set compression or query expansion).3 DataWe collected data from two major political blogs,Daily Kos (www.dailykos.com) and Red State(www.redstate.com).
Red State is a conserva-tive political blog whereas Daily Kos is a liberalpolitical blog.
Both these blogs are widely read andtag each of their blog entries.
We collected datafrom both these blogs over a period of two years(January 2008 ?
February 2010).
We collected atotal of 100,000 blog posts from Daily Kos and70,000 blog posts from Red State and a total of787,780 tags across both blogs (an average of 4.63tags per post).4 MethodsWe used SVM Light (Joachims, 2002) to predictthe tags for a given blog post.
We constructed oneclassifier for each of the tags present in the trainingset.
The features used were counts of each wordencountered in the title or the body of a post (twocounts per word), further subdivided by whetherthe word appears in any tags in the training data ornot, and whether it is a synonym of known tagwords.
We extract the top five proposed tags foreach post, corresponding to the five highest scoringSVM classifiers.We also attempt to detect the main entities beingtalked about.
We perform shallow parsing and ex-tract noun phrases and then proper nouns.
Themost frequent proper NPs are probable tags.
Wealso added named entity recognition and co-reference resolution using the OpenNLP toolkit(maxent.sourceforge.net).
We found thatnamed entity recognition proposes additional use-ful tags while the effect of co-reference resolutionis marginal, mostly because of limited success inactually matching co-referent entities.5 Results and EvaluationFor evaluating our methods, we used 2,681 postsfrom Daily Kos and 571 posts from Red State.
Wecompared the tags assigned by our tagger to theoriginal tags of the blog post, using an automatedmethod (Figure 1).
A tag was considered a match ifit exactly matched the original tag or was a wordsuper set ?
for example ?health care system?
isconsidered a match to ?health care?.
We also ma-nually evaluated the relevance of the proposed tagson a small portion of our test set (100 posts).Method Precision Recall F-ScoreSingle word SVM 27.3% 60.3% 37.6%+ Stemming 26.1% 59.5% 36.3%+ Proper Nouns 36.5% 56.8% 44.4%Named Entities 48.4% 49.1% 48.7%All Combined 21.1% 65.0% 31.9%Manual Scoring 67.0% 75.0% 70.8%Single word SVM 19.0% 30.0% 23.3%+ Stemming 22.0% 30.2% 25.5%+ Proper Nouns 46.3% 54.0% 49.9%Named Entities 60.1% 41.5% 49.1%All Combined 20.3% 65.7% 31.0%Manual Scoring 47.0% 62.0% 53.5%Figure 1: Results on Daily Kos (top) and Red State(bottom) data.
Best scores in bold.6 ConclusionWe described and evaluated a tool for automatical-ly tagging political blog posts.
Political blogs differfrom other blogs as they often involve named enti-ties (politicians, organizations, and places).
There-fore, tagging of political blog posts benefits fromusing basic name entity recognition to improve thetagging.
The recall in particular exceeds the scoreobtained by earlier techniques applied to other do-mains (Sood et al (2007) report precision of 13%and recall of 23%; Wang and Davison (2008) re-port precision of 45% and recall of 23%).ReferencesClaire Cardie and John Wilkerson (editors).
?SpecialVolume: Text Annotation for Political Science Re-search?.
Journal of Information Technology andPolitics, 5(1):1-6, 2008.Thorsten Joachims.
SVM-Light.
2002. http://www.svmlight.joachims.org.Gilad Mishne.
?AutoTag: A Collaborative Approach toAutomated Tag Assignment for Weblog Posts?.
InProceedings of WWW, 2006.Sanjay C. Sood, Sara H. Owsley, Kristian J. Hammond,and Larry Birnbaum.
?TagAssist: Automatic TagSuggestion for Blog Posts?.
In Proceedings ofICWSM, 2007.Jian Wang and Brian D. Davison.
?Explorations in TagSuggestion and Query Expansion?.
In Proceedings ofSSM ?08, 2008.22
