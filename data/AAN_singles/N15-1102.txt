Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 995?1000,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsMorphological Modeling for Machine Translation of English-Iraqi ArabicSpoken DialogsKatrin KirchhoffDepartment ofElectrical EngineeringUniversity of WashingtonSeattle, WA, USAkk2@u.washington.eduWilson TamMicrosoft Corporationwilson.yctam@gmail.comColleen Richey, Wen WangSRI InternationalMenlo Park, CA, USAcolleen@speech.sri.comwwang@speech.sri.comAbstractThis paper addresses the problem of mor-phological modeling in statistical speech-to-speech translation for English to Iraqi Ara-bic.
An analysis of user data from a real-timeMT-based dialog system showed that generat-ing correct verbal inflections is a key problemfor this language pair.
We approach this prob-lem by enriching the training data with mor-phological information derived from source-side dependency parses.
We analyze the per-formance of several parsers as well as the ef-fect on different types of translation models.Our method achieves an improvement of morethan a full BLEU point and a significant in-crease in verbal inflection accuracy; at thesame time, it is computationally inexpensiveand does not rely on target-language linguistictools.1 IntroductionSMT from a morphologically poor language like En-glish into a language with richer morphology con-tinues to be a problem, in particular when trainingdata is sparse and/or the SMT system has insufficientmodeling capabilities for morphological variationin the target language.
Most previous approachesto this problem have utilized a translate-and-inflectmethod, where a first-pass SMT system is trainedon lemmatized forms, and the correct inflection forevery word is predicted in a second pass by statis-tical classifiers trained on a combination of sourceand target language features.
This paper looks atmorphological modeling from a different perspec-tive, namely to improve SMT in a real-time speech-to-speech translation system.
Our focus is on resolv-ing those morphological translation errors that aremost likely to cause confusions and misunderstand-ings in machine-translation mediated human-humandialogs.
Due to the constraints imposed by a real-time system, previous approaches that rely on elabo-rate feature sets and multi-pass processing strategiesare unsuitable for this problem.
The language pairof interest in this study is English and Iraqi Arabic(IA).
The latter is a spoken dialect of Arabic withfew existing linguistic resources.
We therefore de-velop a low-resource approach that relies on source-side dependency parses only.
We analyze its perfor-mance in combination with different types of parsersand different translation models.
Results show a sig-nificant improvement in translation performance inboth automatic and manual evaluations.
Moreover,the proposed method is sufficiently fast for a real-time system.2 Prior WorkMuch work in SMT has addressed the issue oftranslating from morphologically-rich languages bypreprocessing the source and/or target data bye.g., stemming and morphological decomposition(Popovic and Ney, 2004; Goldwater and McClosky,2005), compound splitting (Koehn and Knight,2003), or various forms of tokenization (Lee, 2004;Habash and Sadat, 2006).
In (Minkov et al, 2007;Toutanova et al, 2008) morphological generationwas applied as a postprocessing step for translationinto morphologically-rich languages.
A maximum-entropy Markov model was trained to predict thecorrect inflection for every stemmed word in the995machine translation output from a first-pass sys-tem, conditioned on a set of lexical, morphologicaland syntactic features.
More recently, (Chahuneauet al, 2013) applied a similar translate-and-inflectapproach, utilizing unsupervised in addition to su-pervised morphological analyses.
Inflection gen-eration models were also used by (Fraser et al,2012; Weller et al, 2013) for translation into Ger-man, and by (El Kholy and Habash, 2012) for Mod-ern Standard Arabic.
(Sultan, 2011) added bothsyntactic information on the source side that wasused in filtering the phrase table, plus postprocess-ing on the target side for English-Arabic translation.Still other approaches enrich the translation systemwith morphology-aware feature functions or specificagreement models (Koehn and Hoang, 2007; Greenand DeNero, 2012; Williams and Koehn, 2011).In contrast to the above studies, which have con-centrated on text translation, this paper focuseson spoken language translation within a bilingualhuman-human dialog system.
Thus, our main goalis not to predict the correct morphological form ofevery word, but to prevent communication errors re-sulting from the mishandling of morphology.
Theintended use in a real-time dialog system imposesadditional constraints on morphological modeling:any proposed approach should not add a signifi-cant computational burden to the overall system thatmight result in delays in translation or response gen-eration.
Our goal is also complicated by the fact thatour target language is a spoken dialect of Arabic, forwhich few linguistic resources (training data, lexi-cons, morphological analyzers) exist.
Lastly, Arabicwritten forms are morphologically highly ambigu-ous due to the lack of short vowel markers that signalgrammatical categories.3 Dialog System and AnalysisThe first step in the dialog system used for this studyconsists of an automatic speech recognition (ASR)component that produces ASR hypotheses for theuser?s speech input.
Several error detection modulesthen identify likely out-of-vocabulary and misrecog-nized words.
This information is used by a clarifi-cation module that asks the user to rephrase theseerror segments; another module then combines theuser?s answers into a merged, corrected representa-1?LanguageA?ASR?
ASR?Error?Detec?n?
OOV/Name?Detec?n?Dialog?Manager??LanguageB?TTS?LanguageA?TTS?Answer?Merging??
Error?Processing?Clarify?User?A?User?B?Needs?Clarifica-??
?n ??Play?Transla?on?SLU?Sense?Detec?n?
MT?
MT?Error?Detec?n?Parser?Figure 1: Dialog system used in this work.tion before sending it to the translation engine.
Amachine translation error detection module analyzesthe translation to check for errors, such as unknownwords.
If an error is found, another clarification sub-dialog is initiated; otherwise, the translation is sentto a text-to-speech engine to produce the acousticoutput in the other language.
A schematic represen-tation is shown in Figure 1.
More details about thesystem can be found in (et al, 2013).
The systemwas evaluated in live mode with native IA speakersas part of the DARPA BOLT Phase-II benchmarkevaluations.
The predefined scenarios included mil-itary and humanitarian assistance/disaster relief sce-narios as well as general topics.
All system interac-tions were logged and evaluated by bilingual humanassessors.During debriefing sessions with the users, someusers voiced dissatisfaction with the translationquality, and a subsequent detailed error analysis wasconducted on the logs of 30 interactions.
Similarto previous studies (Condon et al, 2010) we foundthat a frequently recurring problem was wrong mor-phological verb forms in the IA output.
Some ex-amples are shown in Table 1.
In Example 1, tomake sure should be translated by a first-person plu-ral verb but it is translated by a second-person pluralform, changing the meaning to (you (pl.)
make sure).The desired verb form would be ntAkd.
Similarly, inExample 2 the translation of transport should agreewith the translations of someone and the preceding9961 you need to tell the locals to evacuate the area so we can secure the area to make sure no one gets hurtlAzm tqwl Alhm AhAly AlmnTqp bAlAxlA?
AlmnTqp HtY nqdr nwmn AlmnTqp Elmwd ttAkdwn Anh mHd ytAY2 do you have someone that can transport you to the nearest american baseEndk wAHd yqdr nqlk lAqrb qAEdp AmrykypTable 1: Examples of mistranslated morphology: English ASR hypotheses and IA translation hypotheses.auxiliary verb can (yqdr).
The correct form wouldbe yqlk (he/she transports you) instead of nqlk (wetransport you).
Such translation errors are confus-ing to users as they affect the understanding of ba-sic semantic roles.
They tend to occur when trans-lating English infinitival constructions (to+verb) orother syntactic constructions where English baseverb forms need to be translated by a finite verb inIA.
In these cases, explicit morphological featureslike person and number are required in Arabic butthey are lacking in the English input.4 ApproachAn analysis of the SMT component showed thatmorphological translation errors primarily occurwhen a head word and its dependent (such as a ver-bal head and its subject noun dependent) are trans-lated as part of different phrases or rules.
In thatcase, insufficient context is available to produce thecorrect translation.
Our approach is to annotate syn-tactic dependencies on the source side using a sta-tistical parser.
Based on the resulting dependencystructures the source-side data is then tagged withexplicit morphological verbal features using deter-ministic rules (e.g., subject nouns assign their per-son/number features to their verbal heads), and anew translation model is trained on this data.
Ourassumption is that words tagged with explicit mor-phological features will be aligned with their cor-rect translations during training and will thus pro-duce correctly inflected forms during testing evenwhen the syntactic context is not available in thesame phrase/rule.
For instance, the input sentencein Example 1 in Table 1 would be annotated as:you need-2sg to tell-2sg the locals to evacuate-3plthe area so we can-1pl secure-1pl the area to make-1pl sure no one gets-3sg hurt.This approach avoids the costly extraction of multi-ple features, subsequent statistical classification, andinflection generation during run time; moreover, itdoes not require target-side annotation tools, an ad-vantage when dealing with under-resourced spokendialects.
There are, however, several potential issueswith this approach.
First, introducing tags fragmentsthe training data: the same word may receive multi-ple different tags, either due to genuine ambiguity orbecause of parser errors.
As a result, word alignmentand phrase extraction may suffer from data spar-sity.
Second, new word-tag combinations in the testdata that were not observed in the training data willnot have an existing translation.
Third, the perfor-mance of the model is highly dependent on the accu-racy of the parser.
Finally, we make the assumptionthat the expression of person and number categoriesare matched across source and target language ?
inpractice, we have indeed seen very few mismatchedcases where e.g., a singular noun phrase in English istranslated by a plural noun phrase in IA (see Section6 below).To address the first point the morph-tagged trans-lation model can be used in a backoff procedurerather than as an alternative model.
In this case thebaseline model is used by default, and the morph-tagged model is only used whenever heads and de-pendents are translated as part of different phrases.Unseen translations for particular word-tag com-binations in the test set could in principle be ad-dressed by using a morphological analyzer to gen-erate novel word forms with the desired inflections.However, this would require identifying the correctstem for the word in question, generating all pos-sible morphological forms, and either selecting oneor providing all options to the SMT system, whichagain increases system load.
We analyzed unseenword-tag combination in the test data but found thattheir percentage was very small (< 1%).
Thus, forthese forms we back off to the untagged counterpartsrather than generating new inflected forms.
To ob-tain better insight into the effect of parsing accuracywe compared the performance of two parsers in our997annotation pipeline: the Stanford parser (de Marn-effe et al, 2006) (version 3.3.1) and the Macaonparser (Nasr et al, 2014).
The latter is an im-plementation of graph-based parsing (McDonald etal., 2005) where a projective dependency tree max-imizing a score function is sought in the graph ofall possible trees using dynamic programming.
Ituses a 1st-order decoder, which is more robust tospeech input as well as out-of-domain training data.The features implemented reflect those of (Bohnet,2010) (based on lexemes and part-of-speech tags).The parser was trained on Penn-Treebank data trans-formed to match speech (lower-cased, no punctu-ation), with one iteration of self-training on theTranstac training set.
We also use the combinationof both parsers, where source words are only taggedif the tags derived independently from each parseragree with each other.5 Data and Baseline SystemsDevelopment experiments were carried out on theTranstac corpus of dialogs in the military and medi-cal domain.
The number of sentence pairs is 762kfor the training set, 6.9k for the dev set, 2.8k foreval set 1, and 1.8k for eval set 2.
Eval set 1 hasone reference per sentence, eval set 2 has four ref-erences.
For the development experiments we useda phrase-based Moses SMT system with a hierarchi-cal reordering model, tested on Eval set 1.
The lan-guage model was a backoff 6-gram model trainedusing Kneser-Ney discounting and interpolation ofhigher- and lower-order n-grams.
In addition to au-tomatic evaluation we performed manual analyses ofthe accuracy of verbal features in the IA translationson a subset of 65 sentences (containing 143 verbforms) from the live evaluations described above.This analysis counts a verb form as correct if its mor-phological features for person and number are cor-rect, although it may have the wrong lemma (e.g.,wrong word sense).
The development experimentswere designed to identify the setup that produces thehighest verbal inflection accuracy.
For final testingwe used a more advanced SMT engine on Eval set2.This system is the one used in the real-time dialogsystem; it contains a hierarchical phrase-based trans-lation model, sparse features, and a neural networkjoint model (NNJM) (Devlin et al, 2014).BLEU Acc (%)Parser std bo std boBaseline 16.8 N/A 37.1 N/AStanford 16.9 17.0 60.1 59.4Macaon 17.0 17.1 67.1 62.9Combined 17.1 17.1 59.4 57.3Table 2: BLEU scores on Transtac eval set 1 and accuracyof verbal morphological features on manual eval set.
std= standard, bo = backed-off system.6 Experiments and ResultsResults in Table 2 show the comparison between thebaseline, different parsers, and the combined sys-tem.
We see that verbal inflection accuracy increasessubstantially from the baseline performance and isbest for the Macaon parser.
Improvements overthe baseline system without morphology are statisti-cally significant; differences between the individualparsers are not (not, however, that the sample sizefor manual evaluation was quite small).BLEU is not affected negatively but even in-creases slightly - thus, data fragmentation does notseem to be a problem overall.
This may be dueto the nature of the task and domain, which is re-sults in fairly short, simple sentence constructionsthat can be adequately translated by a concatena-tion of shorter phrases rather than requiring longerphrases.
Back-off systems (indicated by bo) andthe combined system improve BLEU only triviallywhile decreasing verbal inflection accuracy by vary-ing amounts.
For testing within the dialog systemwe thus choose the Macaon parser and utilize a stan-dard translation model rather than a backoff model.An added benefit is that the Macaon parser is alreadyused in other components in the dialog system.
Us-ing this setup we ran two experiments with dialogsystem?s SMT engine: first, we re-extracted phrasesand rules based on the morph-tagged data and re-optimized the feature weights.
In the second ex-periment, we additionally applied the NNJM to themorph-tagged source text.
To this end we includeall the morphological variants of the original vocab-ulary that was used for the NNJM in the untaggedbaseline system.
Table 3 shows the results.
Themorph-tagged data improves the BLEU score un-der both conditions: in Experiment 1, the improve-998ment is almost a full BLEU point (0.91); in Experi-ment 2 the improvement is even larger (1.13), eventhough the baseline performance is stronger.
Bothresults are statistically significant at p = 0.05, usinga paired bootstrap resampling test.
The combina-tion of morph-tagged data and the more advancedmodeling options (sparse features, NNJM) in thissystem seem to be beneficial.
Improved translationperformance may also be captured by the four ref-erence translations as opposed to one in Eval set1.
In order to assess the added computation costSystem no NNJM with NNJMBaseline 34.38 36.17Morph tags 35.29 37.30Table 3: BLEU on Eval set 2 using dialog system?s SMTengine.of our procedure we computed the decoding speedof the MT component in the dialog system for boththe baseline and the morpho-tag systems.
In thebaseline MT system (with NNJM) without morpho-tags, decoding takes 0.01572 seconds per word or0.15408 seconds per sentence ?
these numbers wereobtained on a Dell Precision M4800 Laptop with aquad-core Intel i7-4930MX Processor and 32GB ofRAM.
Morpho-tagging only adds 0.00031 secondsper word or 0.0024 seconds per sentence.
Thus, ourprocedure is extremely efficient.An analysis of the remaining morphologicaltranslation errors not captured by our approachshowed that in about 34% of all cases these were dueto part-of-speech tagging or parser errors, i.e.
verbswere mistagged as nouns rather than verbs and thusdid not receive any morphological tags, or the parserhypothesized wrong dependency relations.
In 53%of the cases the problem is the lack of more extensivediscourse or contextual knowledge.
This includesconstructions where there is no overt subject for averb in the current utterance, and the appropriate un-derlying subject must be inferred from the precedingdiscourse or from knowledge of the situational con-text.
This is an instance of the more general problemof control (see e.g.,(Landau, 2013) for an overviewof research in this area).
It is exemplified by casessuch as the following:1.
The first step is to make sure that all personnelare in your debrief.Here, the underlying subject of ?to make sure?
couldbe a range of different candidates (I, you, we, etc.
)and must be inferred from context.2.
I can provide up to one platoon to help you guyscordon off the area.In this case the statistical parser identified I as thesubject of help, but platoon is more likely to be thecontroller and was in fact identified as the underly-ing subject by the annotator.
Such cases could po-tentially be resolved during the parsing step by in-tegrating semantic information, e.g.
as in (Bansal etal., 2014).
However, initial investigations with se-mantic features in the Macaon parser resulted in asignificant slow-down of the parser.
In other cases,more sophisticated modeling of the entities and theirrelationships in the situational context will be re-quired.
This clearly is an area for future study.Finally, in 13% of the cases, mistranslations arecaused by a mismatch of number features across lan-guages (e.g.
number features for nouns such as fam-ily or people).7 ConclusionWe have shown that significant gains in BLEU andverbal inflection accuracy in speech-to-speech trans-lation for English-IA can be achieved by incor-porating morphological tags derived from depen-dency parse information in the source language.The proposed method is fast, low-resource, and caneasily be incorporated into a real-time dialog sys-tem.
It adds negligible computational cost and doesnot require any target-language specific annotationtools.
Possible areas for future study include theuse of discourse or and other contextual informationto determine morphological agreement, applicationto other languages pairs/morphological agreementtypes, and learning the annotation rules from data.AcknowledgmentsThis study was funded by the Defense AdvancedResearch Projects Agency (DARPA) under contractHR0011-12-C-0016 - subcontract 19-000234.ReferencesM.
Bansal, K. Gimpel, and K. Livescu.
2014.
Tailoringcontinuous word representations for dependency pars-ing.
In Proc.
of ACL.B.
Bohnet.
2010.
Very high accuracy and fast depen-999dency parsing is not a contradiction.
In Proceedingsof COLING, pages 89?97.V.
Chahuneau, E. Schlinger, N. Smith, and C. Dyer.2013.
Translating into morphologically rich languageswith synthetic phrases.
In Proceedings of EMNLP.S.
Condon, D. Parvaz, J. Aberdeen, C. Doran, A. Free-man, and M. Awad.
2010.
Evaluation of machinetranslation errors in English and Iraqi Arabic.
In Pro-ceedings of LREC.M.-C. de Marneffe, B. MacCartney, and C.D.
Man-ning.
2006.
Generating typed dependency parses fromphrase structure parses.
In Proceedings of LREC.J.
Devlin et al 2014.
Fast and robust neural network jointmodels for statistical machine translation.
In Proceed-ings of ACL, pages 1370?1380.A.
El Kholy and N. Habash.
2012.
Translate, predictor generate: modeling rich morphology in statisticalmachine translation.
In Proceedings of EAMT.N.F.
Ayan et al 2013.
Can you give me another wordfor hyperbaric?
- improving speech translation us-ing targeted clarification questions.
In Proceedings ofICASSP.A.
Fraser, M. Weller, A. Cahill, and F. Cap.
2012.
Mod-eling inflection and word-formation in SMT.
In Pro-ceedings of EACL, pages 664?674.S.
Goldwater and D. McClosky.
2005.
Improving statis-tical MT through morphological analysis.
In Proceed-ings of EMNLP, pages 676?683.S.
Green and J. DeNero.
2012.
A class-based agreementmodel for generating accuractely inflected translation.In Proceedings of ACL, pages 146?155.N.
Habash and F. Sadat.
2006.
Arabic preprocessingschemes for statistical machine translation.
In Pro-ceedings of NAACL.P.
Koehn and H. Hoang.
2007.
Factored translation mod-els.
In Proceedings of EMNLP, pages 868?876.P.
Koehn and K. Knight.
2003.
Empirical methods forcompound splitting.
In Proceedings of EACL.I.
Landau.
2013.
Control in Generative Grammar: AResearch Companion.
Cambridge University Press,Cambridge, UK.Y.S.
Lee.
2004.
Morphological analysis for statisticalmachine translation.
In Proceedings of HLT-NAACL.R.
McDonald, F. Pereira, K. Ribarov, and J. Haji?c.2005.
Non-projective dependency parsing using span-ning tree algorithms.
In Proceedings of HLT/EMNLP,pages 523?530.E.
Minkov, K. Toutanova, and H. Suzuki.
2007.
Gener-ating complex morphology for machine translation.
InProceedings of ACL, pages 128?135.A.
Nasr, F. Bechet, B. Favre, T. Bazillon, J. Deulofeu, andA.
Valli.
2014.
Automatically enriching spoken cor-pora with syntactic information for linguistic studies.In Proceedings of LREC.M.
Popovic and H. Ney.
2004.
Towards the use of wordstems and suffixes for statistical machine translation.In Proceedings of LREC.S.
Sultan.
2011.
Applying Morphology to English-Arabic Statistical Machine Translation.
Ph.D. thesis,Department of Computer Science, ETH Z?urich.K.
Toutanova, H. Suzuki, and A. Ruopp.
2008.
Applyingmorphology generation models to machine translation.In Proceedings of ACL, pages 514?522.M.
Weller, A. Fraser, and S. Schulte im Walde.
2013.
Us-ing subcategorization knowledge to improve case pre-diction for translation to German.
In Proceedings ofACL, pages 593?603.P.
Williams and P. Koehn.
2011.
Agreement constraintsfor statistical machine translation into German.
InProceedings of WMT.1000
