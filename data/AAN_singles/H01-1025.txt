Exploring Speech-Enabled Dialogue with the GalaxyCommunicator InfrastructureSamuel BayerThe MITRE Corporation202 Burlington Rd.Bedford, MA 01730sam@mitre.orgChristine DoranThe MITRE Corporation202 Burlington Rd.Bedford, MA 01730cdoran@mitre.orgBryan GeorgeThe MITRE Corporation11493 Sunset Hills Rd.Reston, VA 20190bgeorge@mitre.orgABSTRACTThis demonstration will motivate some of the significantproperties of the Galaxy Communicator Software Infrastructureand show  how  they support the goals of the DARPACommunicator program.KeywordsSpoken dialogue, speech interfaces1.
INTRODUCTIONThe DARPA Communicator program [1], now in its secondfiscal year, is intended to push the boundaries of speech-enabled dialogue systems by enabling a freer interchangebetween human and machine.
A crucial enabling technologyfor the DARPA Communicator program is the GalaxyCommunicator software infrastructure (GCSI), which providesa common software platform for dialogue system development.This infrastructure was initially designed and constructed byMIT [2], and is now maintained and enhanced by the MITRECorporation.
This demonstration will motivate some of thesignificant properties of this infrastructure and show how theysupport the goals of the DARPA Communicator program.2.
HIGHLIGHTED PROPERTIESThe GCSI is a distributed hub-and-spoke infrastructure whichallows the programmer to develop Communicator-compliantservers in C, C++, Java, Python, or Allegro Common Lisp.
Thissystem is based on message passing rather than CORBA- orRPC-style APIs.
The hub in this infrastructure supportsrouting of messages consisting of key-value pairs, but alsosupports logging and rule-based scripting.
Such aninfrastructure has the following desirable properties:?
The scripting capabilities of the hub allow theprogrammer to weave together servers which may nototherwise have been intended to work together, byrerouting messages and their responses and transformingtheir keys.?
The scripting capabilities of the hub allow theprogrammer to insert simple tools and filters to convertdata among formats.?
The scripting capabilities of the hub make it easy tomodify the message flow of control in real time.?
The scripting capabilities of the hub and the simplicity ofmessage passing make it simple to build up systems bitby bit.?
The standard infrastructure allows the Communicatorprogram to develop platform- and programming-language-independent service standards for recognition,synthesis, and other better-understood resources.?
The standard infrastructure allows members of theCommunicator program to contribute generally usefultools to other program participants.This demonstration will illustrate a number of theseproperties.3.
DEMO CONFIGURATION ANDCONTENTBy way of illustration, this demo will simulate a process ofassembling a Communicator-compliant system, while at thesame time exemplifying some of the more powerful aspects ofthe infrastructure.
The demonstration has three phases,representing three successively more complex configurationsteps.
We use a graphical display of the Communicator hub tomake it easy to see the behavior of this system.As you can see in Figure 1, the hub is connected to eightservers:?
MITRE's Java Desktop Audio Server (JDAS)?
MIT SUMMIT recognizer, using MIT's Mercury traveldomain language model?
CMU Sphinx recognizer, with a Communicator-compliantwrapper written by the University of Colorado Center forSpoken Language Research (CSLR), using CSLR's traveldomain language model?
A string conversion server, for managingincompatibilities between recognizer output andsynthesizer input?
CSLR's concatenative Phrase TTS synthesizer, using theirtravel domain voice?
CMU/Edinburgh Festival synthesizer, with aCommunicator-compliant wrapper written by CSLR, usingCMU's travel domain language model for Festival'sconcatenative voice?
MIT TINA parser, using MIT's Mercury travel domainlanguage model?
MIT Genesis paraphraser, using MIT's Mercury traveldomain language modelFigure 1: Initial demo configurationWe will use the flexibility of the GCSI, and the hub scriptinglanguage in particular, to change the path that messages followamong these servers.3.1 Phase 1In phase 1, we establish audio connectivity.
JDAS is MITRE'scontribution to the problem of reliable access to audioresources.
It is based on JavaSound 1.0 (distributed with JDK1.3), and supports barge-in.
We show the capabilities of JDASby having the system echo the speaker's input; we alsodemonstrate the barge-in capabilities of JDAS bye showingthat the speaker can interrupt the playback with a newutterance/input.
The goal in building JDAS is that anyone whohas a desktop microphone and the Communicatorinfrastructure will be able to use this audio server to establishconnectivity with any Communicator-compliant recognizer orsynthesizer.3.2 Changing the message pathThe hub maintains a number of information states.
TheCommunicator hub script which the developer writes can bothaccess and update these information states, and we can invoke"programs" in the Communicator hub script by sendingmessages to the hub.
This demonstration exploits thiscapability by using messages sent from the graphical displayto change the path that messages follow, as illustrated inFigure 2.
In phase 1, the hub script routed messages from JDASback to JDAS (enabled by the message named "Echo").
In thenext phase, we will change the path of messages from JDASand send them to a speech recognizer.Figure 2: Modifying the hub information state3.3 Phase 2Now that we've established audio connectivity, we can addrecognition and synthesis.
In this configuration, we will routethe output of the preferred recognizer to the preferredsynthesizer.
When we change the path through the hub scriptusing the graphical display, the preferred servers arehighlighted.
Figure 3 shows that the initial configuration ofphase 2 prefers SUMMIT and Festival.Figure 3:  Initial recognition/synthesis configurationThe SUMMIT recognizer and the Festival synthesizer were notintended to work together; in fact, while there is a good deal ofactivity in the area of establishing data standards for variousaspects of dialogue systems (cf.
[3]), there are noprogramming-language-independent service definitions forspeech.
The hub scripting capability, however, allows thesetools to be incorporated into the same configuration and tointeract with each other.
The remaining incompatibilities (forinstance, the differences in markup between the recognizeroutput and the input the synthesizer expects) are addressed bythe string server, which can intervene between the recognizerand synthesizer.
So the GCSI makes it easy both to connect avariety of tools to the hub and make them interoperate, as wellas to insert simple filters and processors to facilitate theinteroperation.In addition to being able to send general messages to the hub,the user can use the graphical display to send messagesassociated with particular servers.
So we can change thepreferred recognizer or synthesizer.
(as shown in Figure 4), orchange the Festival voice (as shown in Figure 5).
All thesemessages are configurable from the hub script.Figure 4: Preferring a recognizerFigure 5: Changing the Festival voice3.4 Phase 3Now that we've established connectivity with recognition andsynthesis, we can add parsing and generation (or, in this case,input paraphrase).
Figure 6 illustrates the final configuration,after changing recognizer and synthesizer preferences.
In thisphase, the output of the recognizer is routed to the parser,which produces a structure which is then paraphrased and thensent to the synthesizer.
So for instance, the user might say "I'dlike to fly to Tacoma", and after parsing and paraphrase, theoutput from the synthesizer might be "A trip to Tacoma".Figure 6: Adding parsing and paraphrase4.
CONCLUSIONThe configuration at the end of phase 3 is obviously not acomplete dialogue system; this configuration is missingcontext management and dialogue control, as well as anapplication backend, as illustrated by the remainingcomponents in white in Figure 7.
However, the purpose of thedemonstration is to illustrate the ease of plug-and-playexperiments within the GCSI, and the role of these capabilitiesto assemble and debug a complex Communicator interface.
TheGCSI is available under an open source license athttp://fofoca.mitre.org/download    .Figure 7: A sample full dialogue system configuration5.
ACKNOWLEDGMENTSThis work was funded by the DARPA Communicator programunder contract number DAAB07-99-C201.
?
2001 The MITRECorporation.
All rights reserved.6.
REFERENCES[1] http://www.darpa.mil/ito/research/com/index.html.
[2] S. Seneff, E. Hurley, R. Lau, C. Pao, P. Schmid, andV.
Zue.
Galaxy-II: A Reference Architecture forConversational System Development.
Proc.
ICSLP98, Sydney, Australia, November 1998.
[3] "'Voice Browser' Activity."
http://www.w3.org/Voice.
