The Rhetorical Parsing of UnrestrictedTexts: A Surface-based ApproachDaniel Marcu*Information Sciences Institute, USCCoherent texts are not just simple sequences ofclauses and sentences, but rather complex artifactsthat have highly elaborate rhetorical structure.
This paper explores the extent to which well-formedrhetorical structures can be automatically derived by means of surface-form-based algorithms.These algorithms identify discourse usages of cue phrases and break sentences into clauses, hy-pothesize rhetorical relations that hold among textual units, and produce valid rhetorical structuretrees for unrestricted natural anguage texts.
The algorithms are empirically grounded in a corpusanalysis of cue phrases and rely on a first-order formalization of rhetorical structure trees.The algorithms are evaluated both intrinsically and extrinsically.
The intrinsic evaluationassesses the resemblance b tween automatically and manually constructed rhetorical structuretrees.
The extrinsic evaluation shows that automatically derived rhetorical structures can besuccessfully exploited in the context of text summarization.1.
Motivat ionConsider the text given in (1), which was taken from Scientific American, November1996.
(1) With its distant orbit--50 percent farther from the sun than Earth--andslim atmospheric blanket, Mars experiences frigid weather conditions.Surface temperatures typically average about -60 degrees Celsius (-76degrees Fahrenheit) at the equator and can dip to -123 degrees C nearthe poles.
Only the midday sun at tropical atitudes is warm enough tothaw ice on occasion, but any liquid water formed in this way wouldevaporate almost instantly because of the low atmospheric pressure.Although the atmosphere holds a small amount of water, andwater-ice clouds sometimes develop, most Martian weather involvesblowing dust or carbon dioxide.
Each winter, for example, a blizzard offrozen carbon dioxide rages over one pole, and a few meters of thisdry-ice snow accumulate as previously frozen carbon dioxide evaporatesfrom the opposite polar cap.
Yet even on the summer pole, where thesun remains in the sky all day long, temperatures never warm enough tomelt frozen water.A rhetorical structure representation (tree) of its first paragraph is shown in Figure 1.In the rhetorical representation, which employs the conventions proposed by Mannand Thompson (1988), each leaf of the tree is associated with a contiguous textual* Information Sciences Institute, University of Southern California, 4676 Admiralty Way, Marina del Rey,CA 90292-6601(~ 2000 Association for Computational LinguisticsComputational Linguistics Volume 26, Number 3EVIDENCEWith its distanl orbit M,u's experiences frigid( - 50 pcrccnt l~nhc~ weather  conditions.from \[hc sun Ihan F:~th -} /o .
,  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
0 .
.
.
.
.
.
.
.
.
2 .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
ON-VOLmON CAUSEblanket typically ~vcragc about  degrees C n~ the at tropical latit udcs If------------.
( ( -70 degrees  Fahrenhe i t  }) po les  is w~m enough to' "on at the equat~ thaw ice on ~ t  .
but ~y l iquid water  bccaus~ o f  thefo r~d in Ihis way would low ntmosph~iccvnporate a~l  inst~t ly  pressure.Figure 1A rhetorical structure representation f the first paragraph in text (1).span.
The internal nodes are labeled with the names of the rhetorical relations thathold between the textual spans that are subsumed by their child nodes.
Each relationbetween two nodes is represented graphically by means of a combination of straightlines and arcs.
The material subsumed by the text span that corresponds tothe startingpoint of an arc is subsidiary to the material subsumed by the text span that correspondsto the end point of an arc.
A relation represented only by straight lines correspondsto cases in which the subsumed text spans are equally important.
Text spans thatsubsume subsidiary information, i.e., text spans that correspond to starting pointsof arcs, are called satellites.
All other text spans are called nuclei.
Text fragmentssurrounded by curly brackets denote parenthetical units: their deletion does not affectthe understanding of the textual unit to which they belong.For example, the textual unit Mars experiences frigid weather conditions is at the endof an arc that originates from the textual unit With its distant orbit--50 percent farther fromthe sun than Earth---and slim atmospheric blanket because the former epresents somethingthat is more essential to the writer's purpose than the latter and because the former canbe understood even if the subsidiary span is deleted, but not vice versa.
The satelliteinformation JUSTIFIES in this case the writer's right to present he information i  thenucleus.
The text spans Only the midday sun at tropical latitudes is warm enough to thaw ice onoccasion, and but any liquid water formed in this way would evaporate almost instantly becauseof the low atmospheric pressure are connected by straight lines because they are equallyimportant with respect o the writer's purpose; they correspond to the elements ofa CONTRAST relation.
The text fragment--50 percent farther from the sun than Earth--issurrounded by curly brackets because it is parenthetical.Traditionally, it has been assumed that rhetorical structures of the kind shown inFigure 1 can be built only if one understands fully the semantics of the text and theintentions of the writer.
To understand, for example, that the information given in thelast two sentences of the first paragraph of text (1) is EVIDENCE to the informationgiven in the first sentence, one needs to understand that the last two sentences mayincrease the reader's belief of the first sentence.
And to understand that it was the lowatmospheric pressure that caused the liquid water to evaporate, one needs to understandthat without he information presented in the satellite, the reader may not know theparticular CAUSE of the situation presented in the nucleus.In spite of the large number of discourse-related theories that have been proposedso far, there have emerged no algorithms capable of deriving the discourse structureof free, unrestricted texts.
On one hand, the theories developed in the traditional,truth-based semantic perspective (Kamp 1981; Lascarides and Asher 1993; Asher 1993;Hobbs et al 1993; Kamp and Reyle 1993; Asher and Lascarides 1994; Kameyama396Marcu Rhetorical Parsing of Unrestricted Texts1994; Polanyi and van den Berg 1996; van den Berg 1996; Gardent 1997; Schilder1997; Cristea and Webber 1997; Webber et al 1999) take the position that discoursestructures can be built only in conjunction with fully specified clause and sentencesyntactic structures.
These theories have a grammar as their backbone and rely onsophisticated logics of belief and default logics in order to intertwine and characterizethe sentence- and discourse-based linguistic phenomena.
Despite their formal elegance,implementations of these theories cannot yet handle naturally occurring texts, suchas that shown in (1).
On the other hand, the theories aimed at characterizing theconstraints that pertain to the structure of unrestricted texts and the computationalmechanisms that would enable the derivation of these structures (van Dijk 1972; Zock1985; Grosz and Sidner 1986; Mann and Thompson 1988; Polanyi 1988, 1996; Hobbs1990) are either too informal or incompletely specified to support a fully automaticapproach to discourse analysis.In this paper, I explore the ground found at the intersection of these two lines ofresearch.
More precisely, I explore the extent o which rhetorical structures of the kindshown in Figure 1 can be built automatically b  relying only on cohesion and connec-tives, i.e., phrases uch as for example, and, although, and however that are used "to linklinguistic units at any level" (Crystal 1991, 74).
1 The results how that although cohe-sion and connectives are ambiguous indicators of rhetorical structure, when used inconjunction with a well-constrained mathematical model of valid rhetorical structures,they enable the implementation f surprisingly accurate rhetorical parsers.2.
FoundationThe hypothesis that underlies this work is that connectives, cohesion, shallow pro-cessing, and a well-constrained mathematical model of valid rhetorical structure trees(RS-trees) can be used to implement algorithms that determine?
the elementary units of a text, i.e., the units that constitute the leaves ofthe RS-tree of that text;?
the rhetorical relations that hold between elementary units and betweenspans of text;?
the relative importance (nucleus or satellite) and the size of the spanssubsumed by these rhetorical relations.In what follows, I examine ach facet of this hypothesis intuitively and explain howit contributes to the derivation of a rhetorical parsing algorithm, i.e., an algorithmthat takes as input free, unrestricted text and that determines its valid RS-trees.
Foreach facet, I consider first the arguments hat support he hypothesis and then discusspotential difficulties.2.1 Determining the Elementary Units Using Connectives and Shallow Processing2.1.1 Pro Arguments.
Recent developments in the linguistics of punctuation (Nun-berg 1990; Briscoe 1996; Pascual and Virbel 1996; Say and Akman 1996; Shiuan andAnn 1996) have emphasized the role that punctuation can have in solving a varietyof natural anguage processing tasks ranging from syntactic parsing to information1 In this paper, I use the terms connective and cue phrase interchangeably.
AndI use the term discoursemarker to refer to a connective that has a discourse function, i.e., a connective that signals arhetoricalrelation that holds between two text spans.397Computational Linguistics Volume 26, Number 3packaging.
For example, if a sentence consists of three arguments eparated by semi-colons, it is likely that one can determine the boundaries of these arguments withoutrelying on sophisticated forms of syntactic analysis.
Shallow processing is sufficientto recognize the occurrences of the semicolons and to break the sentence into threeelementary units.In a corpus study (described in Section 3), I noticed that in most of the cases inwhich a connective such as Although occurred at the beginning of a sentence, it markedthe left boundary of an elementary unit whose right boundary was given by the firstsubsequent occurrence of a comma.
Hence, it is likely that by using only shallowtechniques and knowledge about connectives, one can determine, for example, thatthe elementary units of sentence (2) are those enclosed within square brackets.
(2) \[Although Brooklyn College does not yet have a junior-year-abroadprogram,\] [a good number of students pend summers in Europe.\]2.1.2 Difficulties.
Obviously, by relying only on orthography, connectives, and shallowprocessing it is unlikely that one will be capable of correctly determining all elementaryunits of an RS-tree.
It may very well be the case that knowledge about how Althoughis used in texts can be exploited to determine the elementary units of texts, but notall connectives are used as consistently as Although is.
Just consider, for instance, thehighly ambiguous connective and.
In some cases, and plays a sentential, syntactic role,while in others, it plays a discourse role, i.e., it signals a rhetorical relation that holdsbetween two textual units.
For example, in sentence (3), the first and is sentential, i.e., itmakes a semantic ontribution to the interpretation of the complex noun phrase "Johnand Mary", while the second and has a discourse function, i.e., it signals a rhetoricalrelation of SEQUENCE that holds between the units enclosed within square brackets.
(3) \[John and Mary went to the theatre\] [and saw a nice play.\]If a system is to use connectives to determine lementary unit boundaries, it wouldneed to figure out that a boundary is required before the second occurrence of and (theoccurrence that has a discourse function), but not before the first occurrence.
It seemsclear that shallow processing is insufficient o properly solve this problem.
It remainsan open question, however, to what degree shallow processing and knowledge aboutconnectives can be successfully used to determine the elementary units of texts.
Ourresults how (see Section 4), that using only such lean knowledge resources, elementaryunit boundaries can be determined with approximately 80% accuracy.2.2 Determining Rhetorical Relations Using Connectives2.2.1 Pro Arguments.
The intuition behind this choice relies on the following facts:Linguistic and psycholinguistic research as shown that connectives areconsistently used by humans both as cohesive ties between adjacentclauses and sentences (Halliday and Hasan 1976) and as"macroconnectors" that signal relations that hold between large textualunits.
For example, in stories, connectives such as so, but, and and markboundaries between story parts (Kintsch 1977).
In naturally occurringconversations, somarks the terminal point of a main discourse unit anda potential transition in a participant's turn, whereas and coordinatesidea units and continues a speaker's action (Schiffrin 1987).
In narratives,398Marcu Rhetorical Parsing of Unrestricted Textsconnectives signal structural relations between elements and are crucialfor the understanding of the stories (Segal and Duchan 1997).
In general,cue phrases are used consistently by both speakers and writers tohighlight the most important shifts in their narratives, mark intermediatebreaks, and signal areas of topical continuity (Bestgen and Costermans1997; Schneuwly 1997).
Therefore, it is likely that connectives can beused to determine rhetorical relations that hold both between elementaryunits and between large spans of text.The number of discourse markers in a typical text--approximately onemarker for every two clauses (Redeker 1990)--is sufficiently large toenable the derivation of rich rhetorical structures for texts.
2Moreimportantly, the absence of markers correlates with a preference ofreaders to interpret he unmarked textual units as continuations of thetopics of the units that precede them (Segal, Duchan, and Scott 1991).Hence, when there is no connective between two sentences, for example,it is likely that the second sentence laborates on the first.2.2.2 Difficulties.
The above arguments tell us that connectives are used often andthat they signal relations that hold both between elementary units and large spansof texts.
Hence, previous research tells us only that connectives are potentially usefulin determining the rhetorical structure of texts.
Unfortunately, they cannot be usedstraightforwardly because they are ambiguous.?
In some cases, connectives have a sentential function, while in othercases, they have a discourse function.
Unless we can determine when aconnective has a discourse function, we cannot use connectives tohypothesize rhetorical relations.?
Connectives do not explicitly signal the size of the textual spans thatthey relate.?
Connectives can signal more than one rhetorical relation.
That is, there isno one-to-one mapping between the use of connectives and therhetorical relations that they signal.I address each of these three problems in turn.Sentential and Discourse Uses of Connectives.
Empirical studies on the disambiguation ofcue phrases (Hirschberg and Litman 1993) have shown that just by considering theorthographic environment in which they occur, one can distinguish between sententialand discourse uses in about 80% of cases and that these results can be improvedwith machine learning techniques (Litman 1996) or genetic algorithms (Siegel andMcKeown 1994).
I have taken Hirschberg and Litman's research one step further anddesigned a comprehensive corpus analysis of cue phrases that enabled me to designalgorithms that improved their results and coverage.
The corpus analysis is discussedin Section 3.
The algorithm that determines elementary unit boundaries and identifiesdiscourse uses of cue phrases is discussed in Section 4.2 A corpus of instructional texts that was studied by Moser and Moore (1997) and Di Eugenio, Moore,and Paolucci (1997) reflected approximately the same distribution of cue phrases: 181 of the 406discourse relations that they analyzed were cued relations.399Computational Linguistics Volume 26, Number 3Discourse Markers are Ambiguous with Respect to the Size of the Spans They Connect.
Assume,for example, that a computer is supposed to determine, using only surface-form al-gorithms and knowledge about connectives, the rhetorical relation that is signaled bythe marker In contrast, in text (4).
(4) \[John likes sweets, t \] \[Most of all, John likes ice cream and chocolate.
2\] \[Incontrast, Mary likes fruit.
3\] \[Especially bananas and strawberries.
4\]During the corpus study that I discuss in Section 3, I noticed that in all its occurrencesin a sample of texts, the connective In contrast signaled a CONTRAST relation.
Hence, itis likely that In contrast signals a CONTRAST relation in text (4) as well.
Unfortunately,although we know what relation In contrast signals, we do not know which spansthe CONTRAST relation holds between: does the relation hold between spans \[1,2\] and\[3,4\]; or between unit 2 and span \[3,4\]; or between span \[1,2\] and unit 3; or betweenunits 1 and 3; or between other units and spans?
The best that we can do in this caseis to make an exclusively disjunctive hypothesis, i.e., to hypothesize that one and onlyone of these possible relations holds.
However, it is still unclear what the elements ofsuch an exclusively disjunctive hypothesis hould be.In my previous work (Marcu 1996, 1997a, 1997b, 1999b, 2000), I have argued thatrhetorical relations that hold between large textual spans can be explained in termsof similar relations that hold between their most important elementary units.
Forexample, the rhetorical relation of EVIDENCE that holds between the first sentenceof the first paragraph in text (1) and the last two sentences of the same paragraphcan be explained in terms of a similar relation that holds between the correspondingnuclei: an EVIDENCE relation also holds between the nucleus of the first sentence, Marsexperiences frigid weather conditions and each of the most important nuclei of the lasttwo sentences Surface temperatures typically average about -60 degrees Celsius (-76 degreesFahrenheit) at the equator and \[Surface temperatures\] can dip to -123 degrees C near the poles.Similarly, the CONTRAST relation that holds between the two spans \[1,2\] and \[3,4\] intext (4) can be explained in terms of a CONTRAST relation that holds between units 1and 3, the most important units in spans \[1,2\] and \[3,4\], respectively.The fact that rhetorical relations that hold between large textual spans can beexplained/determined in terms of rhetorical relations that hold between elementarytextual units suggests that rhetorical structure trees can be constructed in a bottom-upfashion, from rhetorical relations that have been determined to hold between ele-mentary textual units.
Hence, to derive the rhetorical structure of text (4) it is suffi-cient to hypothesize with respect o the occurrence of the connective In contrast, theexclusively disjunctive hypothesis rhet_rel(CONTRAST, 1 3) (9 rhet_rel(CONTRAST, 1 4) (9rhet_rel(CONTRAST, 2 3) (grhet_rel(coNTRAST, 2, 4), because this hypothesis subsumes allthe other possible rhetorical relations that may be signaled by the connective.
3 In Sec-tion 2.4, I will explain why exclusive-disjunctive hypotheses of this kind are sufficientfor determining the rhetorical structure of texts.The fact that rhetorical relations that hold between large spans can be explainedin terms of rhetorical relations that hold between elementary units should not leadone to conclude that a computational system should only make rhetorical hypotheseswhose arguments are elementary units.
For example, a text fragment may consist ofthree paragraphs, clearly marked by the connectives First, Second, and Third.
For such3 Throughout this paper, I use the convention that rhetorical relations are represented as sorted,first-order predicates having the form rhet_rel(NAME, SATELLITE, NUCLEUS) in the case of hypotacticrelations and the form rhet_rel(NAME, NUCLEUS, NUCLEUS) in the case of paratactic relations.400Marcu Rhetorical Parsing of Unrestricted Textsa fragment, it is likely that the three paragraphs are in a LIST or SEQUENCE relation.If a computer program exploits the occurrence of these markers, it may be able toderive the high-level rhetorical structure of the text fragment without determining theimportant units and relations that underlie the three paragraphs.
The work presentedin this paper acknowledges the utility of dealing both with simple relations, i.e., rhetor-ical relations that hold between elementary textual units, and with extended rhetoricalrelations, i.e., relations that hold between large segments.
Depending on the circum-stances, a computational system will have to choose the types of relations it shouldhypothesize to determine the rhetorical structure of a text.The observation that rhetorical relations that hold between large textual spanscan be explained in terms of rhetorical relations that hold between elementary textualunits and the need for dealing with extended rhetorical relations amount o providinga composit ional ity criterion for valid rhetorical structures.
This criterion posits thata rhetorical structure tree is valid only if each rhetorical relation that holds betweentwo spans is either an extended rhetorical relation or can be explained in terms of asimple rhetorical relation.Discourse Markers are Ambiguous with Respect to the Rhetorical Relations They Signal.
Dis-course markers are also ambiguous with respect o the rhetorical relations they signaland the importance of the textual spans they relate.
For example, the occurrence ofthe discourse marker But at the beginning of a sentence most often signals either amononuclear relation of ANTITHESIS or CONCESSION between a satellite, a textual spanthat precedes the occurrence of But, and a nucleus, a textual span that starts with But; ora multinuclear relation of CONTRAST between two nuclei: a textual span that precedesthe occurrence of But and a textual span that starts with But.
An exclusive disjunctionis again an adequate way to formalize this hypothesis.
For example, the exclusive dis-junction rhet_rel(ANTITHESIS, 1, 2) ?
rhet_rel(cONCESSION, 1, 2) ?
rhet_rel(CONTRAST, 1, 2)expresses the best hypothesis that one can make on the basis of the occurrence of themarker But in text (5).
As mentioned already, in Section 2.4 it will become apparentwhy such exclusively disjunctive hypotheses are sufficient for deriving the rhetoricalstructure of texts.
(5) \[Bill had no parents, t \] \[But he had seven brothers and sisters.
1\]2.2.3 Discussion.
The more complex the texts one is trying to analyze and the moreambiguous the connectives a text employs, the more likely the rhetorical relationsthat hold between elementary units and spans cannot be hypothesized precisely byautomatic means.
Most often, connectives, tense, pronoun uses, etc.
only suggest hatsome rhetorical relations hold between some textual units; rarely can hypotheses bemade with 100% confidence.When a computer program processes free texts and comes across a connective suchas But, for example, unless it carries out a complete semantic analysis and understandsthe intentions of the writer, it won't  be able to determine unambiguously what relationto use; and it won't  be able to determine what units or spans are involved in therelation.
What is certain, though, is that But, the hypothesis trigger in this example,can signal at most one such relation-- in my empirical work (see Section 3), I have nevercome across a case in which a simple connective signaled more than one rhetoricalrelation.
In general then, if But occurs in unit i of a text, we know that it can signal arhetorical relation that holds between one unit in the interval \[i - k,  i - 1\]  and one unitin the interval \[i, i + k\], where k is a sufficiently large constant; or a relation betweentwo spans \[i - kl, i - 1\] and \[i, i + k2\].
Figure 2 provides a graphical representation f401Computational Linguistics Volume 26, Number 3i - k  i -  I : i i+kFigure 2A graphical representation f the disjunctive hypothesis that is triggered by the occurrence ofthe marker But at the beginning of unit i of a text.the simple rhetorical relations that can be hypothesized on the basis of the connectiveBut in unit i.In this paper, I will focus on dealing only with this sort of exclusively disjunctivehypotheses, i.e., hypotheses whose disjuncts subsume text spans that overlap.
Forexample, in Figure 2, all disjuncts span over the segment \[i - 1, i\].
From a linguisticperspective, only such hypotheses make sense.
Although one can hypothesize on thebasis of the occurrence of a discourse marker in unit i that a rhetorical relation R holdseither between units i - 2 and i - 1 or between units i and i + 1, for example, sucha hypothesis will be ill-formed.
In the discourse analyses I have carried out so far, Ihave never come across an example that would require one to deal with exclusivelydisjunctive hypotheses different from that shown graphically in Figure 2.2.3 Determining Rhetorical Relations Using Cohesion2.3.1 Pro Arguments.
Youmans (1991), Hoey (1991), Morris and Hirst (1991), Saltonet al (1995), Salton and Allan (1995), and Hearst (1997) have shown that word co-occurrences and more sophisticated forms of lexical cohesion can be used to deter-mine segments of topical and thematic ontinuity.
And Morris and Hirst (1991) havealso shown that there is a correlation between cohesion-defined textual segments andhierarchical, intentionally defined segments (Grosz and Sidner 1986).
For example,if the first three paragraphs of a text talk about the moon and the subsequent twoparagraphs talk about the Earth, it is possible that the rhetorical structure of the textis characterized by two spans that subsume these two sets of paragraphs and thata rhetorical relation of JOINT or LIST holds between the two spans.
Also, studies byHarabagiu, Moldovan, and Maiorano (Harabagiu and Maiorano 1996; Harabagiu andMoldovan 1999) show that cohesion can be used to determine rhetorical relations thathold between smaller discourse constituents as well.
For example, if one sentence talksabout vegetables and another sentence talks about carrots and beets, it is possible thata rhetorical relation of ELABORATION holds between the two sentences because carrotsand beets are kinds of vegetables.2.3.2 Difficulties.
For the purpose of this paper, I use a very coarse model of therelation between cohesion and rhetorical relations.
More specifically, I assume that amononuclear rhetorical relation of ELABORATION or BACKGROUND holds between twotextual segments that talk about the same thing, i.e., they share some words, and thata multinuclear relation of JOINT holds between two segments that talk about differentthings.
This assumption is consistent with the approaches discussed in Section 2.3.1,402Marcu Rhetorical Parsing of Unrestricted Textsbut does not follow from them.
Section 5 empirically evaluates the impact that thisassumption has on the problem of rhetorical structure derivation.2.4 Determining Rhetorical Structure Using a Well-Constrained Mathematical ModelIn my previous work (Marcu 1996, 1997b, 2000) I have formalized the constraintsspecific to valid rhetorical structures in the language of first-order logic.
The axiom-atization of valid rhetorical structures that I use throughout this paper relies on thefollowing features and constraints.?
A valid rhetorical structure is a binary tree whose leaves denoteelementary textual units.?
Rhetorical relations hold between textual units and spans of varioussizes.
These relations are paratactic or hypotactic.
Paratactic relations arethose that hold between units (spans) of equal importance.
Hypotacticrelations are those that hold between a unit (span) that is essential forthe writer's purpose, i.e., a nucleus, and a unit (span) that increases theunderstanding of the nucleus but is not essential for the writer'spurpose, i.e., a satellite.?
Each node of a rhetorical structure tree has associated a status (NUCLEUSor  SATELLITE), a type (the rhetorical relation that holds between the textspans that the node spans over), and a set of promotion units.
The set ofpromotion units of a textual span is determined recursively: it is givenby the union of the promotion sets of the immediate subspans when therelation that holds between these subspans is paratactic, or by thepromotion set of the nucleus ubspan when the relation that holdsbetween the immediate subspans is hypotactic.
By convention, the typeof a leaf is LEAF; and the promotion set of a leaf is a set that contains theleaf.?
The status and type associated with each node are unique.
Hence, forexample, a span cannot have both the status of NUCLEUS and the statusof  SATELLITE.?
The rhetorical relations of a valid rhetorical structure hold only betweenadjacent spans.?
There exists a span, which corresponds to the root node of the structure,that spans over the entire text.?
The status, type, and promotion set associated with each node reflect hecompositionality criterion discussed in Section 2.2: if a rhetorical relationholds between two textual spans of the tree structure of a text, either thatrelation is extended or it can be explained in terms of a simple relationthat holds between the promotion units of the constituent subspans.Let us focus our attention again on text (4).
We have seen that a computer programmay be able to hypothesize the first exclusive disjunction in (6) using only knowledgeabout the discourse function of the connective In contrast.
Similarly, a computer maybe able to hypothesize that a rhetorical relation of ELABORATION holds between sen-tences 2 and 1 because both of them talk about John.
A computer may also be ableto hypothesize that a rhetorical relation of ELABORATION holds between sentence 4,403Computational Linguistics Volume 26, Number 3Status = {NUCLEUS, SATELLITE)( '~  Type = (CONTRAST}.~- - -~tatus  = {NUCLEUS) ~ Status = {NUCLEUS)~./- 2~ T~e = {ELABORATION} ~ ?~l) Type = {ELABORATION}(.
~ _ n v = ' A " = " ~  .
.
.
.
.
( 4 ~ Status = {SATELLITE}TyDe = {LEAF}Promotion = J2) Promotion = \[3) Promotion = {4}Figure 3A valid rhetorical structure representation f text (4), which makes explicit he status, type,and promotion units that characterize each node.which starts with the marker Especially, and a sentence that precedes it.
(6)( rhet_rel(CONTRAST, 1, 3) ?
rhet_rel(coNTRAST, 1, 4) ?\] rhet_rel(cONTRAST, 2, 3)?
rhet_rel(CONTRAST, 2, 4)RR = ~ rhet_rel(ELABORATION, 2, 1)I rhet_rel(ELABORATION, 4, 1) ~ rhet_rel(ELABORATION, 4, 2) ?
( rhet_rel(ELABORATION, 4, 3)When these hypotheses are evaluated against he constraints of valid rhetoricalstructure trees, they yield only one valid rhetorical structure representation, which isshown in Figure 3.
This representation makes explicit he status, type, and promotionset of each of the nodes in the tree.
Note, for example, that the CONTRAST relation thatholds between spans \[1,2\] and \[3,4\] is explained/determined by the simple rhetoricalrelation rhet_rel(CONTRAST, 1, 3), which is one of the exclusive disjuncts hown in (6);hence, the rhetorical structure in Figure 3 is consistent with the compositionality cri-terion.
Note also that the hypothesis rhet_rel(ELABORATION, 4, 2), for example, cannotbe used instead of the CONTRAST relation to link spans \[1,2\] and \[3,4\], because the re-lation rhet_FeI(ELABORATION, 4, 3) was used to link units 3 and 4 and because relationsrhet_reI(ELABORATION, 4, 2) and rhet_reI(ELABORATION, 4, 3) are exclusively disjunctive.In fact, even though one could have hypothesized a different relation R to hold,say, between the satellite 4 and the nucleus 2, such a hypothesis would not yield othervalid trees because such trees would violate the compositionality criterion for tworeasons:?
Relation R cannot be used to link spans \[1,2\] and \[3,4\], for example,because units 2 and 4 are not in the promotion sets of spans \[1,2\] and\[3,4\], respectively.?
There is no combination of rhetorical relations that would promote units2 and 4 as salient in spans \[1,2\] and \[3,4\], respectively.Hence, although we were not able to hypothesize precisely the spans and unitsbetween which the CONTRAST relation signaled by In contrast and the ELABORATIONrelation signaled by Especially hold, we were able to derive only one valid structurebecause the mathematical model that underlies our approach is well-constrained.404Marcu Rhetorical Parsing of Unrestricted Texts2.5 DiscussionThroughout Section 2, I have argued that connectives, cohesion, shallow processing,and a well-constrained model of discourse can be used to automatically derive therhetorical structure of free, unrestricted texts.
In order to substantiate his claim, Ineed to solve two problems:..First, I need to show how starting from free, unrestricted text,connectives and cohesion can be used to automatically determine theelementary units of text and hypothesize simple, extended, andexclusively disjunctive rhetorical relations that hold between these unitsand spans of units.
I refer to this problem as the problem of rhetoricalgrounding.Second, I need to show how starting from a sequence of textual unitsU = 1, 2 .
.
.
.
.
n and a set RR of simple, extended, and exclusivelydisjunctive rhetorical relations that hold among these units and amongcontiguous textual spans that are defined over U, the valid rhetoricalstructures of U can be determined, i.e., the rhetorical structures that areconsistent with the constraints given in Section 2.4.
I refer to this as theproblem of rhetorical structure derivation.The keen reader may have noted that in this formulation, the problem of determiningthe rhetorical structure of text is not modeled as an incremental process in whichelementary units are determined and attached to an increasingly complex RS-tree.Rather, it is assumed that all elementary units of a text are determined first; thatknowledge of connectives and cohesion is then used to (over-)hypothesize simple,extended, and exclusively disjunctive rhetorical relatio,ls that hold between units andspans of units; and that these hypotheses and the well-constrained model of valid RS-trees are used to determine the set of valid rhetorical interpretations that are consistentwith both the mathematical model and the hypotheses.In the rest of the paper, I provide solutions to the rhetorical grounding (Sections 3,4.2, 4.3, and 4.4) and rhetorical structure derivation problems (Section 4.5).
The prob-lems are solved in the context of presenting a rhetorical parsing algorithm (see Fig-ure 5), an algorithm that takes as input free text and determines the RS-tree of thattext.3.
A Corpus Analysis of Cue PhrasesWhen I began this research, no empirical data existed which could answer the ques-tion of the extent o which connectives could be used to identify elementary unitsand hypothesize rhetorical relations.
To better understand this problem, I carried outa corpus study.
The corpus study was designed to investigate how cue phrases can beused to identify the elementary units of texts, as well as to determine what rhetoricalrelations hold between units and spans of text, the nuclearity of the units, and thesizes of the related spans.
In this section, I describe the annotation schema that I usedin the study.
In Section 4, I explain how the annotated ata was used to derive algo-rithms that identify connective occurrences (Section 4.2), determine lementary unitsof discourse and determine which connectives have a discourse function (Section 4.3),and hypothesize rhetorical relations that hold between elementary units and spans oftexts (Section 4.4).405Computational Linguistics Volume 26, Number 33.1 MaterialsMany researchers have published lists of potential discourse markers and cue phrases(Halliday and Hasan 1976; Grosz and Sidner 1986; Martin 1992; Hirschberg and Litman1993; Knott 1995; Fraser 1996).
I took the union of their lists and created an initial setof more than 450 potential discourse markers.
For each potential discourse marker, Ithen used an automatic procedure that extracted from the Brown corpus a set of textfragments.
Each text fragment contained a "window" of approximately 300 wordsand an emphasized occurrence of a cue phrase.
My initial goal was to select for eachcue phrase 10 texts in which the phrase was used at the beginning of a sentence and20 texts in which the phrase was used in the middle of a sentence.
(In a prestudy, Ihad noticed that phrases occurring in the middle of sentences were more ambiguousand difficult o handle than those at the beginning of sentences.)
However, since someof the phrases occurred in the corpus very seldom, I ended up with an average of17 text fragments per cue phrase.
Overall, I randomly selected more than 7,600 texts.All the text fragments associated with a cue phrase were paired with a set offields/slots in which I described two types of information.Discourse-related Information.
This information concerned the cue phrase under scrutinyand was described in the following fields:Marker The field Marker encodes the orthographic environment that characterizesthe use of the cue phrase.
This included occurrences of periods, commas,colons, semicolons, etc.
For example, when the cue phrase besides occurredwithin a sentence and was preceded by a comma, the Marker field wasset to ", besides".
When it occurred at the beginning of a paragraph andwas immediately followed by a comma, the Marker field was set to "#Besides, ", where # denotes a paragraph break.Usage The field Usage encodes the functional role of the cue phrase.
The role canbe one or more of the following: SENTENTIAL~ DISCOURSE~ and PRAGMATIC.A cue phrase has a sentential role if it makes a semantic ontribution to theinterpretation of text (Hirschberg and Litman 1993).
A cue phrase has adiscourse role if it signals a rhetorical relation that holds between two textspans.
A cue phrase has a pragmatic role if it signals a relation betweenthe unit to which the cue phrase belongs and the beliefs, plans, intentions,and/or communicative goals of the speaker/hearer (F aser 1996).Position The field Position specifies the position of the marker under scrutiny inthe textual unit to which it belongs.
The possible values for this field are:BEGINNING~ MEDIAL~ and END.Right boundary The Right boundary of the textual unit associated with the mark-er under scrutiny contains the last cue phrase, orthographic marker, orword of that textual unit.Where to link The field Where to link describes whether the textual unit thatcontains the discourse marker under scrutiny is related to a textual unitfound BEFORE or AFTER it.Rhetorical relation The field Rhetorical relation specifies one or more names ofrhetorical relations that are signaled by the cue phrase under scrutiny.
Toencode the information specific to this field, I used a set of 54 rhetoricalrelations (see Section 3.2).406Marcu Rhetorical Parsing of Unrestricted Textsj EXAMPLE2-32 3Figure 4The discourse tree of text (7).Types of textual units The field Types of textual units describes the types of tex-tual units connected through a rhetorical relation that was signaled bythe cue phrase under scrutiny.
It takes values from CLAUSE to MULTI-PLE_PARAGRAPH.
I distinguished between these types of spans because Iintended to use the corpus study to implement a rhetorical parser thathypothesizes both simple and extended rhetorical relations.Statuses The field Statuses pecifies the rhetorical statuses (separated by a semi-colon) of the two textual units involved in the relation.
The status of atextual unit can be NUCLEUS or SATELLITE.Clause distance The field Clause distance contains a count of the clause-like unitsthat separate the units related by the marker.
The count is 0 when therelated units are adjacent.Sentence distance The field Sentence distance contains a count of the sentencesthat are found between the units that are related by the marker.
The countis -1  when the related units belong to the same sentence.Distance to salient unit The field Distance to salient unit contains a count of theclause-like units that separate the textual unit that contains the markerunder scrutiny and the textual unit that is the most salient unit of thespan that is rhetorically related to a unit that is before or after that underscrutiny.
In most cases, this distance is -1 ,  i.e., the unit that contains amarker is directly related to a unit that went before or to a unit thatcomes after.
However, in some cases, this is not so.
Consider, for example,the text given in (7) below, with respect o the cue phrase for example.
(7) \[There are many things I do not like about fast food.
1\] \[Let'sassume, for example, that you want to go out with someone2.\]\[There is no way you can take them to a fast foodrestaurant!
3 \]A rhetorical analysis of text (7) is shown in Figure 4.
It is easy to see thatalthough for example signals a rhetorical relation of EXAMPLE, the relationdoes not hold between units 2 and 1, but rather, between span 2-3 andunit 1.
More precisely, the relation holds between unit 3, which is themost salient unit of span 2-3, and unit 1.
The field Distance to salient unitreflects this state of affairs.
For text (7) and marker for example, its value is 0.When a discourse marker had more than one function or signaled more than onediscourse relation, I enumerated all functions and relations.Algorithmic Information.
In contrast o the discourse-related information, which has ageneral inguistic interpretation, the algorithmic information was specifically tailored407Computational Linguistics Volume 26, Number 3Table 1A corpus analysis of the cue phrase Althoughfrom text (8).Field ContentMarker # UAlthoughUUsage DISCOURSERight boundaryWhere to link1 AFTERTypes of textual units1 CLAUSE;CLAUSEClause distance1 0Sentence distance1 -1Distance to salient unit1 -1Position~ BEGINNINGStatuses~ SATELLITE;NUCLEUSRhetorical relation1 CONCESSIONWhere to link2 BEFORETypes of textual units2 SENTENCE;SENTENCEClause distance2 6Sentence distance2 4Distance to salient unit2 -1Position2 BEGINNINGStatuses2  NUCLEUS;SATELLITERhetorical relation2 ELABORATIONBreak action COMMAto the surface analysis aimed at determining the elementary textual units of a text.
Itconcerned only one field, Break action, which specified the action that a left-to-rightsurface-based lementary unit identifier will need to take to determine the boundariesof elementary textual units found in the vicinity of the cue phrase.
For example, anaction of type NORMAL associated with the occurrence of the connective but encodedthe fact that an elementary unit boundary had to be inserted immediately before theconnective.
Since a discussion of the actions and their semantics i  meaningless inisolation, I will provide it below in Section 4.3.3, in conjunction with the clause-likeunit boundary and discourse marker identification algorithm.One can argue that encoding algorithmic information in a corpus study is notnecessary.
After all, one can use the annotated ata to derive such information auto-matically.
However, during my prestudy of cue phrases, I noticed that there is a finitenumber of ways in which cue phrases can be used to identify the elementary unitsof text.
By encoding algorithmic specific information in the corpus, I only bootstrapthe step that can take one from annotated ata to algorithmic information.
This en-coding does not preclude the employment of more sophisticated methods that derivealgorithmic information automatically.3.2 Methods and ResultsOnce the database had been created, I analyzed its records and updated the fieldsaccording to the requirements described above.
For example, Table 1 shows the in-formation that I associated with the fields when I analyzed the text fragment shownin (8), with respect o the cue phrase Although.
The square brackets in (8) enclose theelementary units of interest.
(8) \[How well do faculty members govern themselves?\] \[There is littleevidence that they are giving any systematic thought o a general theory408Marcu Rhetorical Parsing of Unrestricted Textsof the optimum scope and nature of their part in government.\] \[Theysometimes pay more attention to their rights\] \[than to their own internalproblems of government.\] \[They, too, need to learn to delegate.\] \[Lettingthe administration take details off their hands would give them moretime to inform themselves about education as a whole,\] \[an area thatwould benefit by more faculty attention.\]\[Although faculties insist on governing themselves,\] \[they grant littleprestige to a member who actively participates in college or universitygovernment.\]The information encoded in Table 1 specifies that the marker Although, whichoccurs in the beginning of a paragraph (#UAlthoughU), has a DISCOURSE role and thatthe right boundary of the elementary unit to which it belongs is a comma.
Althoughsignals a relation of CONCESSION between the clause to which it belongs, which has arhetorical status of SATELLITE, and the clause that comes immediately AFTER it, whichhas a rhetorical status of NUCLEUS.
In addition to the discourse relation signaled by amarker such as Although, which introduces expectations (Cristea and Webber 1997), Ialso found it useful to annotate the rhetorical relation that held between the sentence towhich an expectation-based marker belonged and the text span that went before.
Forexample, with respect to the connective Although in text (8), I also represented xplicitlyin the corpus the fact that an ELABORATION relation holds between the sentence thatcontains the connective, which has the status of SATELLITE, and a sentence found sixclauses (four sentences) BEFORE it, which has the status of NUCLEUS.
It turned out thatin most of the cases in which a phrase such as Although was used at the beginningof a sentence/paragraph, it not only signaled a CONCESSION relation between twoclauses, but its use also correlated with an ELABORATION relation that held betweentwo sentences or paragraphs.Overall, I have manually analyzed 2,100 of the text fragments in the corpus.
Iannotated only 2,100 fragments because the task was too time-consuming to complete.Of the 2,100 instances of cue phrases that I considered, 1,197 had a discourse function,773 were sentential, and 244 were pragmatic.
4The taxonomy of relations that I used to label the 1,197 discourse uses in the corpuscontained 54 relations.
Marcu (1997b) lists their names and the number of instancesin which each rhetorical relation was used.
The number of relations is much largerthan 24, which is the size of the taxonomy proposed initially by Mann and Thomp-son (1988), because during the corpus analysis, it often happened that the relationsproposed by Mann and Thompson seemed inadequate to capture the semantics ofthe relationship between the units under consideration.
Because the study describedhere was exploratory, I considered it appropriate to introduce relations that wouldbetter capture the meaning of these relationships.
The rhetorical relation ames werechosen so as to reflect he intended semantics of the relations.
To manage the newrelations, I did not provide for them definitions imilar to those proposed by Mannand Thompson (1988); instead, I kept a list of text examples that I considered to reflectthe meaning of each new rhetorical relation that I introduced.In Section 4, I will explain how the annotated data was used in order to implementalgorithms that solve the problem of rhetorical grounding defined in Section 2.5.4 The three numbers add up to more than 2,100 because ome cue phrases had multiple roles in sometext fragments.409Computational Linguistics Volume 26, Number 33.3 DiscussionThe elementary textual units that I considered, such as those enclosed within squarebrackets in examples (4) and (8) were not necessarily clauses in the traditional, gram-matical sense.
Rather, they were contiguous pans of text that could be smaller than aclause and that could provide grounds for deriving rhetorical inferences.
For example,although the text in italics in the sentence "Only the midday sun at tropical atitudes iswarm enough to thaw ice on occasion, but any liquid water formed in this way wouldevaporate almost instantly because of the low atmospheric pressure."
does not represent afull-fledged clause, I decided to label it as an elementary unit because it provides thegrounds for inferring a causal relation.Hence, in the texts that I analyzed, I did not use an objective definition of elemen-tary unit.
Rather, I relied on a more intuitive one: whenever I found that a rhetoricalrelation held between two spans of text of significant sizes (the relation could be sig-naled or not by a cue phrase, or not), I assigned those spans an elementary unit status,although in some cases they were not full-fledged clauses.
In the rest of the paper Irefer to such elementary units with the term clause-like unit.The main advantage of the empirical work described here is the empirical ground-ing that it provides for a set of algorithms that derive the rhetorical structures of un-restricted texts.
These algorithms are grounded partly in the empirical data derivedfrom the corpus and partly in the intuitions that I developed uring the discourseanalysis of the 2,100 fragments of text.Since I was the only analyst of 2,100 of the 7,600 of the text fragments in the corpusand since I wanted to avoid evaluating the algorithms that I developed against myown subjective standard, I used the corpus analysis only for algorithm development.The testing of the algorithms was done against data that did not occur in the corpusand that was analyzed independently by other judges.4.
The Rhetorical Parsing AlgorithmThe rhetorical parsing algorithm takes as input a free, unrestricted text and determinesits rhetorical structure.
The algorithm presented in this paper assumes that the rhetor-ical structure of a text correlates with the orthographic layout of that text.
That is, itassumes that sentences, paragraphs, and sections correspond to hierarchical spans inthe rhetorical representation f the text that they subsume.Obviously, this assumption is controversial because there is no clear-cut evidencethat the rhetorical structure of a text correlates with its paragraph structure, for ex-ample.
In fact, some psycholinguistic and empirical research of Heurley (1997) andHearst (1997) indicates that paragraph breaks do not always occur at the same loca-tions as the thematic boundaries.
In contrast, experiments of Bruder and Wiebe (1990)and Wiebe (1994) show that paragraph breaks help readers to interpret private-statesentences in narratives, i.e., sentences about psychological states uch as wanting andperceptual states such as seeing.
Hence, paragraph breaks play an important role instory comprehension.
In my own experiments ( ee Section 5), I observed that, in nineout of ten cases, human judges manually built rhetorical structures that correlatedwith the underlying paragraph boundaries.The main reason for assuming that the orthographic layout of text correlates withits rhetorical structure is primarily one of efficiency.
In the same way sentences areambiguous and syntactic parsers can derive thousands of syntactic trees, so texts areambiguous and rhetorical parsers can derive thousands of rhetorical trees.
Assumingthat the rhetorical structure of a text correlates with sentence, paragraph, and section410Marcu Rhetorical Parsing of Unrestricted TextsInput: A text T.Output: The valid rhetorical structures of T.1.
I.
Determine the set D of all cue phrase (potential discourse marker) instances in T.2.
II.
Use information derived from the corpus analysis in order to determine3.
recursively all the sections, paragraphs, entences, and clause-like units of the4.
text and the set Dd E D of cue phrases that have a discourse function.5.
III.
For each of the three highest levels of granularity (sentences, paragraphs,6.
and sections)7.
III.1 Use information derived from the corpus analysis about the8.
discourse markers Dd in order to hypothesize rhetorical relations9.
among the elementary units that correspond to that level.10.
III.2 Use cohesion in order to hypothesize rhetorical relations among11.
the units for which no hypotheses were made in step III.1.12.
III.3 Apply the proof theory discussed in Section 4.5 in order to13.
determine all the valid text trees that correspond to that level.14.
III.4 Assign a weight to each of the text trees and determine the tree15.
with maximal weight.16.
IV.
Merge the best trees that correspond to each level into a discourse tree that17.
spans the whole text and that has clause-like units as its elementary units.Figure 5Outline of the rhetorical parsing algorithm.boundaries ignificantly reduces the search space of possible rhetorical interpretationsand increases the speed of a rhetorical parser.4.1 A Bird's-Eye ViewThe rhetorical parsing algorithm, which was implemented C++, is outlined in Figure 5.The rhetorical parser first determines the set of all instances of cue phrases that occur inthe text; this set includes punctuation marks such as commas, periods, and semicolons.In the second step (lines 2-4 in Figure 5), the rhetorical parser retraverses the inputand by using information derived from the corpus study discussed in Section 3, itdetermines the elementary units and the cue phrases that have a discourse functionin structuring the text.
In the third step, the rhetorical parser builds the valid textstructures for each of the three highest levels of granularity, which are the sentence,paragraph, and section levels (see lines 5-15 in Figure 5).
Tree construction is carriedout in four substeps.III.1III.2III.3First, the rhetorical parser uses the cue phrases that were assigned adiscourse function in step II to hypothesize rhetorical relations betweenclause-like units, sentences, and paragraphs (see lines 7-9).
Most of thediscourse markers yield exclusively disjunctive hypotheses.When the textual units under consideration are characterized by nodiscourse markers, rhetorical relations are hypothesized on the basis of asimple cohesive device, which is similar to that used by Hearst (1997)(see lines 10-11).Once the set of textual units and the set of rhetorical relations that holdamong the units have been determined, the algorithm derives discoursetrees at each of the three levels that are assumed to be in correlation withthe discourse structure: sentence, paragraph, and section levels (see lines12-13).
The derivation is accomplished by a chart-based implementation411Computational Linguistics Volume 26, Number 3III.4of a proof theory that solves the rhetorical structure derivation problem(see Section 4.5).Since the rhetorical parsing process is ambiguous, more than onediscourse tree is usually obtained at each of these levels.
To deal withthis ambiguity, a "best" tree is selected according to a metric to bediscussed in Section 4.6 (see lines 14-15).In the final step, the algorithm assembles the trees built at each level of granularity,thus obtaining a discourse tree that spans over the whole text (lines 16-17 in Figure 5).In the rest of the paper, I discuss in detail the steps that the rhetorical parserfollows when it derives the valid structures of a text and the algorithms that implementthem.
In the cases in which the algorithms rely on data derived from the corpusstudy in Section 3, I also discuss the relationship between the predominantly linguisticinformation that characterizes the corpus and the procedural information that can beexploited at the algorithmic level.
Throughout the discussion, I will use the text in (1)as an example.4.2 Determining the Potential Discourse Markers of a Text4.2.1 From the Corpus Analysis to the Potential Discourse Markers of a Text.
Thecorpus analysis discussed in Section 3 provides information about he orthographic en-vironment of cue phrases and the function they have in the text (sentential, discourse,or pragmatic).
Different orthographic environments often correlate with different dis-course functions and different ways of breaking the surrounding text into elementaryunits.
For example, if the cue phrase Besides occurs at the beginning of a sentence andis not followed by a comma, as in text (9), it usually signals a rhetorical relation thatholds between the clause-like unit that contains it and the following clause(s).
How-ever, if the same cue phrase occurs at the beginning of a sentence and is immediatelyfollowed by a comma, as in text (10), it usually signals a rhetorical relation that holdsbetween the sentence to which Besides belongs and a textual unit that precedes it.
(9)(10)\[Besides the lack of an adequate thical dimension to the Governor'scase,\] \[one can ask seriously whether our lead over the Russians inquality and quantity of nuclear weapons is so slight as to make the testsabsolutely necessary.\]\[For pride's sake, I will not say that the coy and leering vade mecum ofthose verses insinuated itself into my soul.\] \[Besides, that particularmessage does no more than weakly echo the roar in all fresh blood.\]I have taken each cue phrase in the corpus and evaluated its potential contributionin determining the elementary textual units and in hypothesizing the rhetorical rela-tions that hold among the units for each orthographic environment that characterizedits usage.
I used the cue phrases that had a discourse role in most of the text fragmentsand the orthographic environments that characterized them to manually develop a setof regular expressions that can be used to recognize potential discourse markers innaturally occurring texts.
If a cue phrase had different discourse functions in differ-ent orthographic environments and could be used in different ways in identifying theelementary units of the surrounding text, as was the case with Besides, I created oneregular expression for each function.
I ignored both cue phrases that had a sententialrole in a majority of the instances in the corpus and those that were too ambiguous tobe exploited in the context of a surface-based approach.
In general, I preferred to be412Marcu Rhetorical Parsing of Unrestricted TextsTable 2A list of regular expressions that correspond to occurrences ofsomeof the potential discourse markers and punctuation marks.Marker Regular ExpressionAlthoughbecausebutfor examplewhereWithYetCOMMAOPENf~ARENCLOSEX%RENDASHEND_SENTENCEBEGIN_PARAGRAPH\[UXtXn\]Although(U \] \t I \n)\[,\]\[UXtXn\]+because(U \] \t\]\n)\[uXtXn\]+but(U I \t I \n)\[,\]\[UXtXn\]+for\[UXt \nJ+example(u \], I \t I \n),\[UXtXn\]+where(U I \t J \n)\[uXtXn\]With(u I \t \[ \n)\[uNtNn\]Yet(u I \t I \n),(U I \t I \n)\[,\]\[UXtXn\]+()(U I \t I \n)\[,\]\[UXtXn\]+--(U I \t I \n)("-")l("?')l("~")l("."")l("?
"")l("r"'))u*((XnXt\[UXt\]*)l(Xn\[UXtXn\]{2,}))conservative and to consider only potential cue phrases whose discourse role couldbe determined with a relatively high level of confidence.
Table 2 shows a set of reg-ular expressions that correspond to some of the cue phrases in the corpus.
Becauseorthographic markers, such as commas, periods, dashes, paragraph breaks, etc., playan important role in our surface-based approach to discourse processing, I includedthem in the list of potential discourse markers as well.By considering only cue phrases having a discourse function in most of the cases,I deliberately chose to focus more on precision than on recall with respect o thetask of identifying the elementary units of text.
That is, I chose to determine fewerunits than humans do, hoping that, in this way, most of the identified units would becorrect.4.2.2 An Algorithm for Determining the Potential Discourse Markers of a Text.
Oncethe regular expressions that match potential discourse markers were derived, it wastrivial to implement the first step of the rhetorical parser (line I in Figure 5).
A programthat uses the Unix tool lex traverses the text given as input and determines the locationsat which potential discourse markers occur.
For example, when the regular expressionsare matched against ext (1), the algorithm recognizes all punctuation marks and thecue phrases hown in italics in text (11) below.
(11) With its distant orbit--50 percent farther from the sun than Earth--andslim atmospheric blanket, Mars experiences frigid weather conditions.Surface temperatures typically average about -60 degrees Celsius (-76degrees Fahrenheit) at the equator and can dip to -123 degrees C nearthe poles.
Only the midday sun at tropical atitudes is warm enough tothaw ice on occasion, but any liquid water formed in this way wouldevaporate almost instantly because of the low atmospheric pressure.Although the atmosphere holds a small amount of water, andwater-ice clouds sometimes develop, most Martian weather involvesblowing dust or carbon dioxide.
Each winter, for example, a blizzard offrozen carbon dioxide rages over one pole, and a few meters of thisdry-ice snow accumulate as previously frozen carbon dioxide evaporatesfrom the opposite polar cap.
Yet even on the summer pole, where the sun413Computational Linguistics Volume 26, Number 3remains in the sky all day long, temperatures never warm enough tomelt frozen water.4.3 Determining the Elementary Units of a Text4.3.1 From the Corpus Analysis to the Elementary Units of a Text.
As I discussedin Section 3, the corpus study encoded not only linguistic information but also algo-rithmic information, in the field Break action.
During the corpus analysis, I generateda set of 11 actions that constitutes the foundation of an algorithm to automaticallydetermine the elementary units of a text.
The algorithm processes each sentence in thetext given as input in a left-to-right fashion and "executes" the actions that are associ-ated with each potential discourse marker and each punctuation mark that occurs inthat sentence.
Because the algorithm does not use any traditional parsing and taggingtechniques, I call it a shallow analyzer.The names and the intended semantics of the actions used by the shallow analyzerare:?
Action NOTHING instructs the shallow analyzer to treat the cue phraseunder consideration as a simple word.
That is, no textual unit boundaryis normally set when a cue phrase associated with such an action isprocessed.
For example, the action associated with the cue phraseaccordingly is NOTHING.?
Action NORMAL instructs the analyzer to insert a textual boundaryimmediately before the occurrence of the marker.
Textual boundariescorrespond to elementary unit breaks.?
Action COMMA instructs the analyzer to insert a textual boundaryimmediately after the occurrence of the first comma in the input stream.If the first comma is followed by an and or an or, the textual boundary isset after the occurrence of the next comma instead.
If no comma is foundbefore the end of the sentence, a textual boundary is created at the endof the sentence.?
Action NORMAL_THEN_COMMA instructs the analyzer to insert a textualboundary immediately before the occurrence of the marker and to insertanother textual boundary immediately after the occurrence of the firstcomma in the input stream.
As in the case of the action COMMA, if thefirst comma is followed by an and or an or, the textual boundary is setafter the occurrence of the next comma.
If no comma is found before theend of the sentence, a textual boundary is created at the end of thesentence.?
Action END instructs the analyzer to insert a textual boundaryimmediately after the cue phrase.?
Action MATCH_PAREN instructs the analyzer to insert textual boundariesboth before the occurrence of the open parenthesis that is normallycharacterized by such an action, and after the closed parenthesis thatfollows it.?
Action COMMA_PAREN instructs the analyzer to insert textual boundariesboth before the cue phrase and after the occurrence of the next comma inthe input stream.414Marcu Rhetorical Parsing of Unrestricted Texts?
Action MATCH_DASH instructs the analyzer to insert a textual boundarybefore the occurrence of the cue phrase.
The cue phrase is usually adash.
The action also instructs the analyzer to insert a textual boundaryafter the next dash in the text.
If such a dash does not exist, the textualboundary is inserted at the end of the sentence.The preceding three actions, MATCH_PAREN, COMMA_PAREN, andMATCH_DASH, are used for determining the boundaries of parentheticalunits.?
Action SET_AND/SET_OR instructs the analyzer to store the informationthat the input stream contains the lexeme and~or.?
Action DUAL instructs the analyzer to insert a textual boundaryimmediately before the cue phrase under consideration if there is noother cue phrase that immediately precedes it.
If there exists such a cuephrase, the analyzer will behave as in the case of the action COMMA.
Theaction DUAL is usually associated with cue phrases that can introducesome expectations about the discourse (Cristea and Webber 1997).
Forexample, the cue phrase although in text (12) signals a rhetorical relationof CONCESSION between the clause to which it belongs and the previousclause.
However, in text (13), where although is preceded by an and, itsignals a rhetorical relation of CONCESSION between the clause to whichit belongs and the next clause in the text.
(12) \[I went to the theatre\] \[although I had a terrible headache.\](13) \[The trip was fun,\] \[and although we were badly bitten byblackflies,\] \[Ido not regret it.\]In addition to the algorithmic information that is explicitly encoded in the field Breakaction, the shallow analyzer uses information about he position of cue phrases in theelementary textual units to which they belong.
The position information is extracteddirectly from the corpus, from the field Position.
Hence, each regular expression thathas a corresponding instantion in the texts in the corpus that could play a discoursefunction is assigned a structure with two features:the action that the shallow analyzer should perform in order todetermine the boundaries of the textual units found in its vicinity;the relative position of the marker in the textual unit to which it belongs(beginning, middle, or end).Table 3 lists the actions and the positions in the elementary units of the cue phrasesand orthographic markers hown in Table 2.4.3.2 The Section, Paragraph, and Sentence Identification Algorithm.
As discussedin Section 4.1, the rhetorical parser assumes that sentences, paragraphs, and sectionscorrespond to hierarchical spans in the rhetorical representation f the text that theysubsume.The algorithm that determines the section, paragraph, and sentence boundaries ia very simple one, which uses the set of regular expressions that are associated withthe potential discourse markers END_SENTENCE and BEGIN_PARAGRPH found inTable 2 and a list of abbreviations, such as Mr., Mrs., and Inc., that prevent the setting of415Computational Linguistics Volume 26, Number 3Table 3The list of actions that correspond to the potentialdiscourse markers and punctuation marks shownin Table 2; B = beginning, M --- middle, and E =end.Marker Position ActionAlthough B COMMAbecause B DUALbut B NORMALfor example M NOTHINGwhere B COMMA-PARENWi th  B COMMAYet B NOTHINGCOMMA E NOTHINGOPEN_PAREN B MATCH-PARENCLOSEA~AREN E NOTHINGDASH n MATCH-DASHEND_SENTENCE E NOTHINGBEGIN_PARAGRAPH B NOTHINGsentence and paragraph boundaries at places that are inappropriate.
This simple algo-rithm correctly located all of the paragraph boundaries and all but one of the sentenceboundaries found in the texts that I used to evaluate the clause-like unit and discoursemarker identification algorithm that I will present in Section 4.3.3.
Other texts andsemistructured HTML/SGML documents may need more sophisticated algorithms tosolve this segmentation problem, such as those described by Palmer and Hearst (1997).4.3.3 The Clause-Like Unit and Discourse Marker Identification Algorithm.
On thebasis of the information derived from the corpus, I have designed an algorithm thatidentifies elementary textual unit boundaries in sentences and cue phrases that havea discourse function.
Figure 6 shows only its skeleton and focuses on the variablesand steps that are used to determine the elementary units.
The steps that assert thediscourse function of a marker are not shown; however, these steps are mentioned inthe discussion of the algorithm given below.
Marcu (1997b) provides a full descriptionof the algorithm.The algorithm takes as input a sentence S and the array markers\[n\] of cue phrases(potential discourse markers) that occur in that sentence; the array is produced by atrivial algorithm that recognizes regular expressions (see Section 4.2.2).
Each elementin markers\[n\] is characterized by a feature structure with the following entries:?
the action associated with the cue phrase;?
the position in the elementary unit of the cue phrase;?
a flag hasdiscourse~function that is initially set to "no.
"The clause-like unit and discourse marker identification algorithm traverses thearray of cue phrases left-to-right (see the loop between lines 2 and 20) and identifies theelementary textual units in the sentence on the basis of the types of the markers thatit processes.
Crucial to the algorithm is the variable "status," which records the set ofmarkers that have been processed earlier and that may still influence the identificationof clause and parenthetical unit boundaries.416Marcu Rhetorical Parsing of Unrestricted TextsInput:Output:A sentence S.The array of n potential discourse markers markers\[n\] that occur in S.The clause-like units, parenthetical units, and discourse markers of S.1.
status := NIL; ...;2. for i from 1to n3.
if MATCHJPAREN E status V MATCH_DASH E status V COMMA_PAREN E status4.
(deal with parenthetical information)5. if COMMA E status A markerTextEqual(i,",') A6.
NextAdjacentMarkerIsNotAnd0 A NextAdjacentMarkerIsNotOr 07.
(insert extual boundary after comma)8. if (SET_AND E status V SET_OR E status) /~ markerAdjacent(i - 1,i)9.
(deal with adjacent markers)10. switch(getActionType(i)) {11. case DUAL: (deal with DUAL markers)12. case NORMAL: (insert extual boundary before marker)13. case COMMA: status := status U {COMMA};14. case NORMAL_THEN_COMMA: (insert textual boundary before marker)15 status := status U {COMMA};16. case NOTHING: (assign discourse usage)*17. case MATCH_PAREN, GOMMA_PAREN~ MATCHJ)ASH: status := status U{getActionType(i)};18. case SET_AND, SET_OR: status := status U {getActionType(i)};19.
}20. end for21.
finishUpParentheticalsAndClauses0;Figure 6The skeleton of the clause-like unit and discourse marker identification algorithm.The clause-like unit identification algorithm has two main parts: lines 10-20 con-cern actions that are executed when the status variable is NIL.
These actions can inserttextual unit boundaries or modify the value of the status variable, thus influencingthe processing of further markers.
Lines 3-9 concern actions that are executed whenthe status variable is not NIL.
We discuss each of these actions in turn.Lines 3-4 of the algorithm treat parenthetical information.
Once an open paren-thesis, a dash, or a discourse marker whose associated action is COMMA_PAREN hasbeen identified, the algorithm ignores all other potential discourse markers until theelement hat closes the parenthetical unit is processed.
Hence, the algorithm searchesfor the first closed parenthesis, dash, or comma, ignoring all other markers on theway.
Obviously, this implementat ion does not assign a discourse usage to discoursemarkers that are used within a span that is parenthetic.
However,  this choice is consis-tent with the decision, discussed in Section 4.3.1, to assign parenthetical informationno elementary textual unit status.
Because of this, the text shown in italics in text (14),for example, is treated as a single parenthetical unit, which is subordinated to "Yet,even on the summer  pole, temperatures never warm enough to melt frozen water.
"In dealing with parenthetical units, the algorithm avoids setting boundaries in casesin which the first comma that comes after a COMMA..PAREN marker is immediatelyfollowed by an or or an and.
As example (14) shows, taking the first comma as theboundary of the parenthetical unit would be inappropriate.
(14) \[Yet, even on the summer  pole, {where the sun remains in the sky all daylong, and where winds are not as strong as at the Equator,} temperatures neverwarm enough to melt frozen water.\]417Computational Linguistics Volume 26, Number 3Obviously, one can easily find counterexamples to this rule (and to other rulesthat are employed by the algorithm).
For example, the clause-like unit and discoursemarker identification algorithm will produce rroneous results when it processes thesentence shown in (15) below.
(15) \[I gave John a boat,\] \[which e liked, and a duck,\] \[which e didn't.\]Nevertheless, the evaluation results discussed in Section 4.3.4 show that the algorithmproduces correct results in the majority of the cases.If the status variable contains the action COMMA, the occurrence of the first commathat is not adjacent to an and or an or marker determines the identification of a newelementary unit (see lines 5-7 in Figure 6).Usually, the discourse role of the cue phrases and and or is ignored because thesurface-form algorithm that we propose is unable to distinguish accurately enoughbetween their discourse and sentential usages.
However, lines 8-9 of the algorithmconcern cases in which their discourse function can be unambiguously determined.For example, in our corpus, whenever and and or immediately preceded the occurrenceof other discourse markers (function markerAdjacent(i - 1, i) returns "true"), they hada discourse function.
For example, in sentence (16), and acts as an indicator of a JOINTrelation between the first two clauses of the text.
(16) \[Although the weather on Mars is cold\] \[and although it is very unlikelythat water exists,\] [scientists have not dismissed yet the possibility of lifeon the Red Planet.\]If a discourse marker is found that immediately follows the occurrence of an and (oran or) and if the left boundary of the elementary unit under consideration is found tothe left of the and (or the or), a new elementary unit is identified whose right boundaryis just before the and (or the or).
In such a case, the and (or the or) is considered tohave a discourse function as well, so the flag has_discourse_function s set to "yes.
"If any of the complex conditions in lines 3, 5, or 8 in Figure 6 is satisfied, thealgorithm not only inserts textual boundaries as discussed above, but also resets thestatus variable to NIL.Lines 10-19 of the algorithm concern the cases in which the status variable is ML.If the type of the marker is DUAL, the determination f the textual unit boundariesdepends on the marker under scrutiny being adjacent to the marker that precedes it.If it is, the status variable is set such that the algorithm will act as in the case of amarker of type COMMA.
If the marker under scrutiny is not adjacent to the marker thatimmediately preceded it, a textual unit boundary is identified.
This implementationwill modify, for example, the status variable to COMMA when processing the markeralthough in example (17), but only insert a textual unit boundary when processing thesame marker in example (18).
The final textual unit boundaries that are assigned bythe algorithm are shown using square brackets.
(17) \[John is a nice guy,\] \[but although his colleagues do not pick on him,\]\[they do not invite him to go camping with them.\](18) \[John is a nice guy,\] \[although e made a couple of nasty remarks lastnight.\]Line 12 of the algorithm concerns the most frequent marker type.
The type NORMALdetermines the identification ofa new clause-like unit boundary just before the marker418Marcu Rhetorical Parsing of Unrestricted Textsunder scrutiny.
Line 13 concerns the case in which the type of the marker is COMMA.If the marker under scrutiny is adjacent to the previous one, the previous marker isconsidered to have a discourse function as well.
In either case, the status variable isupdated such that a textual unit boundary will be identified at the first occurrence ofa comma.
When a marker of type NORMAL_THEN_COMMA is processed, the algorithmidentifies a new clause-like unit as in the case of a marker of type NORMAL, and thenupdates the status variable such that a textual unit boundary will be identified atthe first occurrence of a comma.
In the case in which a marker of type NOTHING isprocessed, the only action that might be executed is that of assigning that marker adiscourse usage.Lines 17-18 of the algorithm concern the treatment of markers that introduce x-pectations with respect to the occurrence of parenthetical units: the effect of processingsuch markers is that of updating the status variable according to the type of the actionassociated with the marker under scrutiny.
The same effect is observed in the cases inwhich the marker under scrutiny is an and or an or.After processing all the markers, it is possible that some text will remain un-accounted for: this text usually occurs between the last marker and the end of thesentence.
The procedure finishUpParentheticalsAndClauses0 in line 21 of Figure 6puts this text into the last clause-like unit that is under consideration.The clause-like unit boundary and discourse marker identification algorithm hasbeen implemented in C++.
When it processes text (11), it determines that the text has10 elementary units and that six cue phrases have a discourse function.
Text (19) showsthe elementary units within square brackets.
The instances of parenthetical informationare shown within curly brackets.
The cue phrases that are assigned by the algorithmas having a discourse function are shown in italics.
(19) \[With its distant orbit {-- 50 percent farther from the sun than Earth --}and slim atmospheric blanket, i \] \[Mars experiences frigid weatherconditions.
2\] \[Surface temperatures typically average about -60 degreesCelsius {(-76 degrees Fahrenheit)} at the equator and can dip to -123degrees C near the poles.
B\] \[Only the midday sun at tropical atitudes iswarm enough to thaw ice on occasion, 4\] \[but any liquid water formed inthis way would evaporate almost instantly 5\] \[because of the lowatmospheric pressure.
6 \]\[Although the atmosphere holds a small amount of water, andwater-ice clouds sometimes develop, 7\] \[most Martian weather involvesblowing dust or carbon dioxide.
8\] \[Each winter, for example, a blizzard offrozen carbon dioxide rages over one pole, and a few meters of thisdry-ice snow accumulate as previously frozen carbon dioxide evaporatesfrom the opposite polar cap.
9\] \[Yet even on the summer pole, {where thesun remains in the sky all day long,} temperatures never warm enoughto melt frozen water) ?\]4.3.4 Evaluation of the Clause-Like Unit and Discourse Marker Identification Algo-rithm.
The algorithm shown in Figure 6 determines clause-like unit boundaries andidentifies discourse uses of cue phrases using methods based on surface form.
Thealgorithm relies heavily on the corpus study discussed in Section 3.The most important criterion for using a cue phrase in the clause-like unit anddiscourse marker identification algorithm is that the cue phrase (together with itsorthographic neighborhood) functions as a discourse marker in the majority of the ex-amples in the corpus.
On the one hand, the enforcement of this criterion reduces the419Computational Linguistics Volume 26, Number 3recall of the discourse markers that can be detected, but on the other hand, it signif-icantly increases the precision.
I chose to ignore the ambiguous markers deliberatelybecause, during the corpus analysis, I noticed that many of the markers that connectlarge textual units can be identified by a shallow analyzer.
In fact, the discourse markerresponsible for most of the algorithm recall failures is and.
Since a shallow analyzercannot identify with sufficient precision whether an occurrence of and has a discourseor a sentential usage, most of its occurrences are therefore ignored.
It is true that,in this way, the discourse structures that the rhetorical parser eventually builds losesome potentially finer granularity, but fortunately, from a rhetorical analysis perspec-tive, the loss has insignificant global repercussions: the majority of the relations thatthe algorithm misses due to recall failures of and are JOINT and SEQUENCE relationsthat hold between adjacent clause-like units.To evaluate the clause-like unit and discourse marker identification algorithm, Irandomly selected three texts, each belonging to a different genre:1. an expository text of 5,036 words from Scientific American;2. a magazine article of 1,588 words from Time;3. a narration of 583 words from the Brown corpus (segmentP25:1250-1710).No fragment of any of the three texts was used during the corpus analysis.
Threeindependent judges, graduate students in computational linguistics, broke the textsinto elementary units.
The judges were given no detailed instructions about the criteriathat they were to apply in determining the clause-like unit boundaries.
Rather, theywere supposed to rely on their intuition and preferred efinition of clause and to inserta boundary between two clause-like units when they believed that a rhetorical relationheld between those units.
The locations in texts that were labeled as clause-like unitboundaries by at least two of the three judges were considered to be valid elementaryunit boundaries.I used the valid elementary unit boundaries assigned by judges as indicators ofdiscourse usages of cue phrases and I manually determined the cue phrases thatsignaled a discourse relation.
For example, if an and was used in a sentence and if thejudges agreed that a textual unit boundary existed just before the and, I assigned thatand a discourse use.
Otherwise, I assigned it a sentential usage.
I applied this procedureto instances of all 450 cue phrases in the corpus, not only to the subset of phrases thatwere used by the rhetorical parser.
Hence, I manually determined all discourse usagesof cue phrases and all discourse boundaries between elementary units.I then applied the clause-like unit and discourse marker identification algorithm tothe same texts.
The algorithm found 80.8% of the discourse markers with a precision of89.5% (see Table 4), a result that seems to outperform Hirschberg and Litman's (1993)algorithm.
5 The large difference in recall between the first and the third texts is due tothe different ext genres.
In the third text, which is a narration, the discourse markerand occurs frequently.
As discussed above, the clause-like unit and discourse markeridentification algorithm correctly labels only a small percentage of these occurrences.The algorithm correctly identified 81.3% of the clause-like unit boundaries, witha precision of 90.3% (see Table 5).5 Since the algorithm proposed here and Hirschberg and Litman's algorithm were evaluated on differentcorpora, it is impossible to carry out a fair comparison.
Also, the discourse markers in my three textswere not identified using an independent definition, as Hirschberg and Litman were.420Marcu Rhetorical Parsing of Unrestricted TextsTable 4Evaluation of the marker identification procedure.Text Number of Number of Number of Recall PrecisionDiscourse Discourse DiscourseMarkers Markers MarkersIdentified Identified IdentifiedManually by the CorrectlyAlgorithm by theAlgorithm1.
174 169 150 86.2% 88.8%2.
63 55 49 77.8% 89.1%3.
38 24 23 63.2% 95.6%Total 275 248 222 80.8% 89.5%Table 5Evaluation of the clause-like unit boundary identification procedure.Text Number of Number of Number of Number of RecallSentence Clause-like Clause-like Clause-likeBoundaries Unit Unit UnitBoundaries Boundaries BoundariesIdentified Identified IdentifiedManually by the CorrectlyAlgorithm by theAlgorithmPrecision1.
242 428 416 371 86.7% 89.2%2.
80 151 123 113 74.8% 91.8%3.
19 61 37 36 59.0% 97.3%Total 341 640 576 520 81.3% 90.3%4.4 Hypothesiz ing Rhetorical Relations between Textual Units of VariousGranularities4.4.1 From Discourse Markers to Rhetorical Relations.
To hypothesize rhetorical re-lations, I manual ly  associated with each of the regular expressions that can be used torecognize potential discourse markers in naturally occurring texts (see Section 4.2.1) aset of features for each of the discourse roles that a discourse marker can play.
Eachset had six distinct features:?
The feature Statuses pecifies the rhetorical status of the units that arelinked by the discourse marker.
Its value is given by the content of theinstances of the database field Statuses that were consistent with thediscourse usage being considered.
Hence, the accepted values areSATELLITE_NUCLEUS, NUCLEUS_SATELLITE, and NUCLEUS_NUCLEUS.?
The feature Where to link specifies whether the rhetorical relationssignaled by the discourse marker concern a textual unit that goesBEFORE or AFTER the unit that contains the marker.
Its value is given bythe content of the instances of the database field Where to l ink that wereconsistent with the discourse usage being considered.?
The feature Types of textual units specifies the nature of the textual unitsthat are involved in the rhetorical relations.
Its value is given by the421Computational Linguistics Volume 26, Number 3content of the instances of the database field Types of textual units thatwere consistent with the discourse usage being considered.
The acceptedvalues are CLAUSE, SENTENCE~ and PARAGRAPH.?
The feature Rhetorical relation specifies the names of rhetorical relationsthat may be signaled by the cue phrase under consideration.
Its value isgiven by the names listed in the instances of the database field Rhetoricalrelation that were consistent with the discourse usage being considered.?
The feature Maximal distance specifies the maximal number of units ofthe same kind found between the textual units that are involved in therhetorical relation.
Its value is given by the maximal value of thedatabase field Clause distance of the instances that were consistent withthe discourse usage being considered when the related units areclause-like units, and by the maximal value of the field Sentencedistance when the related units are sentences.
The value is 0 when therelated units were adjacent in all the instances in the corpus.?
The feature Distance to salient unit is given by the maximum of thevalues of the database field Distance to salient unit of the instances thatwere consistent with the discourse usage being considered.Table 6 lists the feature sets associated with the cue phrases that were initially listedin Table 2.For example, the cue phrase Although as two sets of features.
The first set,{SATELLITE_NUCLEUS, AFTER, CLAUSE, CONCESSION, 1, -1},  specifies that the markersignals a rhetorical relation of CONCESSION that holds between two clause-like units.The first trait has the status SATELLITE and the second has the status NUCLEUS.
Theclause-like unit to which the textual unit that contains the cue phrase is to be linkedcomes AFTER the one that contains the marker.
The maximum number of clause-likeunits that separated two clauses related by Although in the corpus was one.
And therewere no cases in the corpus in which Although signaled a CONCESSION relation betweena clause that preceded it and one that came after (Distance to salient unit = -1).
Thesecond set, {NUCLEUS_SATELLITE, BEFORE, SENTENCE V PARAGRAPH~ ELABORATION, 5,0} specifies that the occurrence of the marker correlates with an ELABORATION relationholding between two sentences or two paragraphs.
The first sentence or paragraph asthe status NUCLEUS, and the second sentence or paragraph as the status SATELLITE.The sentence or paragraph to which the textual unit that contains the marker is to belinked comes BEFORE the one that contains it.
The maximum number of sentences thatseparated two units related by Although in the corpus was five.
And in at least oneexample in the corpus, Although marked an ELABORATION relation between some unitthat preceded it and a sentence that came immediately after the one that containedthe marker (Distance to salient unit = 0).4.4.2 A Discourse-marker-based Algorithm for Hypothesizing Rhetorical Relations.At the end of step II of the rhetorical parsing algorithm (see Figure 5), the text givenas input has been broken into sections, paragraphs, sentences, and clause-like units;and the cue phrases that have a discourse function have been explicitly marked.
Instep III.1, a set of rhetorical relations that hold between the clause-like units of eachsentence, the sentences of each paragraph, and the paragraphs of each section is hy-pothesized, on the basis of information extracted from the corpus.At each level of granularity (sentence, paragraph, and section levels), a discourse-marker-based hypothesizing algorithm iterates over all textual units of that level and422Marcu Rhetorical Parsing of Unrestricted Textsr...?zo,.- <o 8.~R~<IIO ~m0 ZO~z~z,<r~,.~ Oao0o?
;-.1t~I /z~8e~os Z r.~08Z ~ ZozO~e~zO> ~> r.)m Z co ~ Z Z Z Z Z ZZ Z Z Z Z Z ZZ ZZ Zm m Z Z Z Z Z ZzzD423Computational Linguistics Volume 26, Number 3over all discourse markers that are relevant o them.
For each discourse marker, thealgorithm constructs an exclusively disjunctive hypothesis concerning the rhetoricalrelations that the marker under scrutiny may signal.
Hence, the algorithm assumesthat the rhetorical structure at each level can be derived by hypothesizing rhetoricalrelations that hold between the units at that level.
When it hypothesizes rhetorical re-lations that hold between clause-like units at the sentence l vel, it hypothesizes simplerelations.
When it hypothesizes rhetorical relations that hold between sentences andparagraphs (at the paragraph and section levels), it hypothesizes extended rhetoricalrelations.
In all cases, it overgenerates xclusively disjunctive relations and subse-quently uses the discourse model to determine the combinations of hypotheses thatare consistent with the constraints pecific to well-formed RS-trees.Assume that the algorithm is processing the ith unit of the sequence of n unitsand assume that unit i contains a discourse marker that signals a rhetorical relationNAME that links the unit under scrutiny with one that went before, and whose satellitegoes after the nucleus.
An appropriate disjunctive hypothesis in this case is then theone that corresponds to the graphical representation i  Figure 2.
Such an exclusivelydisjunctive hypothesis enumerates all possible relations that could hold over membersof the Cartesian product {i, i+1 .
.
.
.
.
i+Dist_sal(m) +1} x {/-Max(m),/-Max(m) +1, .
.
.
,i -  1}, where Max(m) is the maximum number of units that separated the satellite andthe nucleus of such a relation in all the examples found in the corpus, and Dist_sal(m)is the maximum distance to the salient unit found in the rightmost position.
Thediscourse-marker-based hypothesizer iterates over all units at the sentence, paragraph,and section levels, and constructs exclusively disjunctive hypotheses such as thosedescribed here.Let us consider, as an example, text (1).
Given the textual units and the discoursemarkers that were identified by the clause-like unit and discourse-marker identifica-tion algorithm (see text (19)), we now examine the relations that are hypothesized bythe discourse-marker-based algorithm at each level of granularity.
Text (19) has threesentences that have more than one elementary unit.
For the sentence shown in (20),the discourse-marker-based algorithm hypothesizes the disjunction shown in (21).
Thishypothesis is consistent with the information given in Table 6, which shows that, inthe corpus, the marker With consistently signaled BACKGROUND and JUSTIFICATIONrelations between a satellite, the unit that contained the marker, and a nucleus, theunit that followed it.
(20)(21)\[With its distant orbit {-- 50 percent farther from the sun than Earth --}and slim atmospheric blanket, 1\] \[Mars experiences frigid weatherconditions, a \]rhet_rel(BACKGROUND, 1, 2) ?
rhet_rel(JuSTIFICATION, 1, 2)For the sentence shown in (22), the discourse-marker-based algorithm hypothe-sizes the two disjunctions hown in (23).
(22)(23)\[Only the midday sun at tropical atitudes is warm enough to thaw iceon occasion, 4\] \[but any liquid water formed in this way would evaporatealmost instantly s\] \[because of the low atmospheric pressure.
6\]rhet_rel(CONTRAST, 4, 5) @ rhet_rel(CONTRAST, 4, 6)rhet_rel(CAUSE, 6, 4) ?
rhet_rel(EvIDENCE, 6, 4) ?rhet_rel(cAusE, 6, 5) @ rhet_rel(EvIDENCE, 6, 5)424Marcu Rhetorical Parsing of Unrestricted TextsThis hypothesis consistent with the information given in Table 6 as well: but signalsa CONTRAST between the clause-like unit that contains the marker and a unit thatwent before; however, it is also possible that this relation involves the clause-like unitthat comes after the one that contains the marker but (the Distance to salient unitfeature has value 0), so rhet_rel(coNTRAST, 4,6) is hypothesized as well.
The seconddisjunct concerns the marker because, which can signal either a CAUSE or an EVIDENCErelation.For sentence (24), which is the first sentence in the second paragraph of text (1),there is only one rhetorical relation that is hypothesized, that shown in (25).
(24)(25)\[Although t e atmosphere holds a small amount of water, and water-iceclouds sometimes develop, 7\] \[most Martian weather involves blowingdust or carbon dioxide.
B\]rhet_rel(cONCESSION, 7, 8)Text (19) has two paragraphs, each of three sentences.
The first paragraph con-tains no discourse markers that could signal relations between sentences.
Hence, thediscourse-marker-based algorithm does not make any hypotheses of rhetorical rela-tions that hold among the sentences of the first paragraph.
In contrast, when thediscourse-marker-based algorithm examines the markers of the second paragraph, ithypothesizes that a rhetorical relation of type EXAMPLE holds either between sen-tences 9 and \[7, 8\] or between sentences 10 and \[7, 8\], because the discourse markerfor example is used in sentence 9.
This is consistent with the information presented inTable 6, which specifies that a rhetorical relation of EXAMPLE holds between a satellite,the sentence that contains the marker, and a nucleus, the sentence that went before.However, the satellite of the relation could also be the sentence that follows the sen-tence that contains the discourse marker (the value of the Distance to salient unitfeature is 0).
Given the marker Yet, the discourse-marker-based algorithm hypothe-sizes that an ANTITHESIS relation holds between a sentence that preceded the one thatcontains the marker, and the sentence that contains it.
The set of disjuncts hown in(26) represents all the hypotheses that are made by the algorithm.
Note that thesehypotheses concern extended rhetorical relations.
(26) rhet_rel(EXAMPLE, 9, \[7, 8\]) ?
rhet_rel(ExAMPLE, 10, \[7, 8\]) rhet_rel(ANTITHESIS, 9, 10) ?
rhet_rel(ANTITHESIS, \[78\], 10)During the corpus analysis, I was not able to make a connection between discoursemarkers that signal sentence-level rhetorical relations and relations that hold betweensequences of sentences, paragraphs, and multiparagraphs.
However, I noticed that adiscourse marker signals a paragraph-level rhetorical relation when the marker underscrutiny is located either at the end of the first paragraph or at the beginning of thesecond paragraph.
The rhetorical parser implements his observation by assuming thatrhetorical relations between paragraphs can be signaled only by markers that occur inthe first sentence of the paragraph, when the marker signals a relation whose other unitprecedes the marker, or in the last sentence of the paragraph, when the marker signalsa relation whose other unit follows the marker.
According to the results derived fromthe corpus analysis, the use of the discourse marker Although at the beginning of asentence or paragraph correlates with a rhetorical relation of ELABORATION that holdsbetween a satellite, the sentence or paragraph that contains the marker, and a nucleus,the sentence or paragraph that precedes it.
The discourse-marker-based algorithm425Computational Linguistics Volume 26, Number 3hypothesizes only one rhetorical relation that holds between the two paragraphs oftext (19), that shown in (27), below.
(27) rhet_rel(ELABORATION, \[7, 10\], \[1, 6\])When a section has more than two paragraphs, the rhetorical parser generatesexclusively disjunctive hypotheses at the paragraph level as well.
The current im-plementation of the rhetorical parser does not hypothesize any relations among thesections of a text.4.4.3 A Word-co-occurrence-based Algorithm for Hypothesizing Rhetorical Rela-tions.
The rhetorical relations hypothesized by the discourse-marker-based algorithmrely entirely on occurrences of discourse markers.
In building the valid rhetorical struc-tures of sentences, the set of rhetorical relations that are hypothesized on the basis ofdiscourse marker occurrences provides ufficient information.
After all, the clause-likeunits of a sentence are determined on the basis of discourse marker occurrences aswell; so every unit of a sentence is related to at least one other unit of the samesentence.
This might not be the case when we consider the paragraph and sectionlevels, however, because discourse markers might not provide sufficient informationfor hypothesizing rhetorical relations among all sentences of a paragraph and amongall paragraphs of a text.
In fact, it is even possible that there are full paragraphs thatuse no discourse markers at all; or that use only markers that link clause-like unitswithin sentences.In step III.2, the rhetorical parser uses cohesion (Halliday and Hasan 1976; Hearst1997; Hoey 1991; Salton et al 1995) to hypothesize rhetorical relations.
The algorithmthat hypothesizes such rhetorical relations assumes that if two sentences or para-graphs talk about the same thing, it is either the case that the sentence or paragraphthat comes later ELABORATES on the topic of the sentence or paragraph that went be-fore; or that the sentence or paragraph that comes before provides the BACKGROUNDfor interpreting the sentence or paragraph that comes later.
If two sentences or para-graphs talk about different hings, it is assumed that a multinuclear JOINT relationholds between the two units.
The decision as to whether two sentences/paragraphstalk about the same thing is made by measuring the similarity between the sen-tences/paragraphs.
If this similarity is above a certain threshold, the textual unitsare considered to be related.
Otherwise, a JOINT relation is assumed to hold betweenthe two units.Once the discourse-marker-based algorithm has hypothesized all relations it could,a word-co-occurrence-based algorithm examines every sentence/paragraph boundaryfor which a marker-based rhetorical relation has not been hypothesized and uses co-hesion to produce such a hypothesis.
As in the case of the discourse-marker-basedalgorithm, each hypothesis i  an exclusive disjunction over the members of the Carte-sian product {i - LD .
.
.
.
.
i} x {i + 1 .
.
.
.
, i + RD},  which contains the units found to theleft and to the right of the boundary between units i and i + 1.
Variables LD and RDrepresent arbitrarily set sizes of the spans that are considered to be relevant from acohesion-based perspective.
The current implementation of the rhetorical parser setsLD to 3 and RD to 2.To assess the similarity between two units l c {i - LD .
.
.
.
.
i} and r c {i + 1 .
.
.
.
.
i +RD},  stopwords such as the, a, and and are initially eliminated from the texts thatcorrespond to these units.
The suffixes of the remaining words are removed as well, sothat words that have the same root can be accounted for by the similarity measurementeven if they are used in different cases, moods, tenses, etc.
If the similarity is above426Marcu Rhetorical Parsing of Unrestricted Textsa certain threshold, an ELABORATION or a BACKGROUND relation is hypothesized tohold between two units; otherwise, a JOINT relation is hypothesized.
The value ofthe threshold is computed for each type of textual unit on the basis of the averagesimilarity of all textual units at that level.As we have already discussed, the first paragraph in text (19) contains no discoursemarkers that could signal relations between sentences.
When the word-co-occurrence-based algorithm examines the boundary between the first two sentences, no stemmedwords are found to co-occur in the first two sentences, but the stem sun is found toco-occur in the first and third sentences.
Therefore, the algorithm hypothesizes the firstdisjunct in (28).
When the boundary between the last two sentences i examined, adisjunct having the same form is hypothesized (the last two sentences of the first para-graph have no words in common).
To distinguish between the two different sourcesthat generated the disjuncts, I assign different subscripts to the rhetorical relationsshown in (28).
(28)rhet_rel(JOINT1, \[1, 2\], 3) ?
rhet_rel(ELABORATION1, \[4, 6\], \[1, 2\])rhet_rel(BACKGROUND1, \[1, 2\], \[4, 6\])rhet_rel(ELABORATION2, \[4, 6\], \[1, 2\]) ?
rhet_reI(BACKGROUND2, \[1, 2\], \[4, 6\]) ?rhet_rel(JOINT2, 3  \[4, 6\])During my corpus study, I noticed that in most of the cases in which the numberof sentences in a paragraph or the number of paragraphs in a section was small and nodiscourse markers were used, the relation that held between the sentences/paragraphswas ELABORATION.
The rhetorical parser implements this empirical observation aswell.
Since the first paragraph in text (1) has only three sentences and no discoursemarker can be used to hypothesize rhetorical relations that hold between these sen-tences, the word-co-occurrence-based algorithm hypothesizes the relations shownin (29).
(29) rhet_reI(ELABORATION, 3, \[1, 2\]) rhet_rel(ELABORATION, \[4, 6\], 3)4.5 A Proof-Theoretic Account of the Problem of Rhetorical Structure DerivationOnce the elementary units of a text have been determined and the rhetorical relationsbetween them have been hypothesized at sentence, paragraph, and section levels, weneed to determine the rhetorical structures that are consistent with these hypothesesand with the constraints specific to valid RS-trees.
That is, we need to solve the problemof rhetorical structure derivation.One way to formalize the problem of rhetorical structure derivation is to assumethat given as input a set of units U = 1, 2 , .
.
.
,  n and a set RR of simple, extended, andexclusively disjunctive hypotheses that hold between these units, we are interested inderiving objects of the form tree(status, type, promotion, left, right), where status can beeither NUCLEUS or SATELLITE; type can be a name of a rhetorical relation; promotioncan be a set of natural numbers from 1 to N; and left and right can be either NULL orrecursively defined objects of type tree.The objects having the form tree(status, type, promotion, left, right) provide a func-tional representation of valid rhetorical structures.
For example, with respect o theelementary units of text (4) and the rhetorical relations that hold between the units ofthis text (see (6)), the subtree in Figure 3 that subsumes units I and 2 can be represented427Computational Linguistics Volume 26, Number 3functionally using an object of type tree as shown in (30).
(30)tree(NUCLEUS, ELABORATION, {1},tree(NUCLEUS, LEAF, {1}, NULL, NULL),tree(SATELLITE, LEAF, {2}, NULL, NULL))Using objects of type tree, I devised a proof theory that can be used to determineall valid rhetorical structures of a text.
The theory consists of a set of axioms andrewriting rules that encode all possible ways in which one can derive the valid RS-trees of a text.
In this paper, I present the proof theory only at the intuitive level.
Theinterested reader can find further detail in Marcu (2000).The proof theory that I outline here assumes that the problem of rhetorical struc-ture derivation can be encoded as a rewriting problem in which valid RS-trees areconstructed bottom-up.
Initially, each elementary unit i in the input is associated withan elementary tree that has either status NUCLEUS or SATELLITE, type LEAF, and pro-motion set {i}.
In the beginning, any of the hypothesized relations RR can be used tojoin these elementary trees into more complex trees.
Once the elementary trees havebeen built, the rhetorical structure is constructed by joining adjacent trees into largertrees and by making sure that at every step, the resulting structure is valid.
The setof rhetorical relations associated with each tree keeps track of the rhetorical relationsthat can still be used to extend that tree.
In the beginning, an elementary tree can beextended using any of the hypothesized relations RR, but as soon as a relation is used,it becomes unavailable for subsequent extensions.We encode the derivation of the elementary trees using axioms (31) and (32).Axiom (31), for example, specifies that if i is an elementary unit in U and if relationsRR have been hypothesized to hold between the units in U, then one can build anelementary tree across text span \[i, i\], having the status NUCLEUS, the type LEAF, andpromotion set {i}; and that this tree can be rewritten into a larger tree by using relationsfrom the set RR.
Hence, the last argument RR enumerates the hypotheses that can beused to expand the tree that characterizes the text span under consideration.
(31)(32)\[unit(i) A hold(RR)\] --, S(i, i, tree(NUCLEUS, LEAF, {i}, NULL, NULL), RR)\[unit(i) A hold(RR)\] --~ S(i, i, tree(SATELLITE, LEAF, {i}, NULL, NULL), RR)A set of 12 axioms (rewriting rules) explains how trees can be assembled into largertrees in a bottom-up fashion.
Let us focus for the moment on the pair of axioms (33)and (34), which are given below.
(33)(34)\[S( I, b, treel ( NUCLEUS, type1, pl, left1, right1), rr l ) AS(b q- 1, h, tree2(SATELLITE, type2, p2, left2, right2), rr2) Arhet_rel(name, s n) Ee rrl A rhet_rel(name, s n) E~ rr2 As ff P2 A n E pl A hypotactic(name)\] --,S (1, h, tree(NUCLEUS, name, Pl, tree1(...), tree2 (.
.
. )
),rrl N rr2 \~ {rhet_rel(name, s,n) } )\[S(I, b, treel ( NUCLEUS, typo, pl, left1, righh ), rrl ) AS(b -}- 1, h, tree2(SATELLITE, type2, p2, left2, right2), rr2) Arhet_rel(name, s n) E~ rrl A rhet_rel(name, s n) Ca rr2 As C P2 A n E pl A hypotactic(name)\] --+S(I, h, tree(SATELLITE, name, p1, tree1(...), tree2(...)),rrl A rr2 \e  {rhet_rel(name, s, n)})428Marcu Rhetorical Parsing of Unrestricted TextsAssume that there exist two spans: one from unit 1 to unit b that is characterized byvalid rhetorical structure tree1 (.
.
.)
and rhetorical relations rrl, and the other from unitb + 1 to unit h that is characterized by valid rhetorical structure tree2(...) and rhetoricalrelations rr2.
Assume also that rhetorical relation rhet_rel(name, s n) holds between aunit s that is in the promotion set of span \[b + 1, h\] and a unit n that is in the promotionset of span \[l, b\], that rhet_rel(name, s n) can be used to extend both spans \[l, b\] and\[b + 1, h\] (rhet_rel(name, s, n) E?
rrl and rhet_rel(name, s n) Ee rr2), and that the relationis hypotactic.
In such a case, one can combine spans \[l, b\] and \[b + 1, h\] into a largerspan \[l, h\] that has a valid structure whose status is either NUCLEUS (see axiom (33)) orSATELLITE (see axiom (34)), type name, promotion set pl, and whose children are givenby the valid structures of the immediate subspans.
The set of rhetorical relations thatcan be used to further extend this structure is given by rrl n rr2 \ {rhet_rel(name, s, n)}.We use operators E~ and \~ instead of E and \ because we treat each exclusivedisjunction as a whole because each exclusive disjunction was hypothesized usingone and only one hypothesis trigger (cue phrase).
That is, we say that a rhetoricalrelation r E~ ri ?
ri+l G ?
.. ?
ri+j if r matches any of the rhetorical relations ri .
.
?
ri+j.We consider that the result of the difference RRi \?
r is a subset of RRi that containsall the members of RRi except he exclusive disjunction that uses relation r. Becauseaxioms (33) and (34) treat each exclusive disjunction as a whole, they ensure that norhetorical relation occurs more than once in a discourse structure.Similarly, we can define rules of inference for the cases in which an extendedrhetorical relation holds across spans \[1,b\] and \[b + 1,hi; for the cases in which thesatellite precedes the nucleus; and for the cases in which the relation under scrutinyis paratactic.
(See Marcu \[2000\] for a complete list of these axioms.)
Rule (35), forexamples, corresponds to the case in which the relation under scrutiny is a simple,paratactic relation.
(35) \[S (I, b, treel ( NUCLEUS, type1, pl, left1, right1), rrl ) AS(b ?
1, h, tree2(NUCLEUS, type2, p2, left2, right2), rr2) Arhet_rel(name, nl, n2) G?
rrl A rhet_rel(name, nl, n2) E?
rr2 Anl E pl A n2 E p2 A paratactic(name)\] --+S ( I, h, tree(NUCLEUS, name, pl U p2, treel ( .
.
.)
,  tree2 (.
.
. )
) ,rrl n rr2 \e  {rhet_rel(name, nl, n2)})Example of a Derivation of a Valid Rhetorical Structure.
If we take any text of N units that ischaracterized by a set RR of rhetorical relations, the proof-theoretic a count provides allthe necessary support for deriving the valid rhetorical structures of that text.
Assume,for example, that we are given text (4), among which rhetorical relations RR givenin (6), hold.
In Figure 7, we sketch the derivation of the theorem that corresponds tothe valid rhetorical structure shown in Figure 3.
The relations RR1 and RR2 that thederivation refers to are shown below.(36)(37)?
rhet_rel(coNTRAST, 1, 3) ?
rhet_rel(coNTRAST, 1, 4) ?rhet_rel(CONTRAST, 2, 3) ?
rhet_rel(CONTRAST, 2, 4)RR1 = rhet_rel(ELABORATION, 4, 1) ?
rhet_reI(ELABORATION, 4, 2) ?rhet_rel(ELABORATION, 4, 3)(rhet_reI(cONTRAST, 1, 3) ?
rhet_rel(coNTRAST, 1, 4) ?RR2 = ~ rhet_rel(CONTRAST, 2,3) G rhet_rel(CONTRAST, 2,4)( rhet_reI(ELABORATION, 2, 1)429Computational Linguistics Volume 26, Number 31. holcl(RR )2. unit(l)3. unit(2)4. unit(3)5. unit(4)6.
S(1,1, tree(NUCLEUS, LEAF, {1}, NULL, NULL), RR)7.
S(2, 2, tree(SATELLITE, LEAF, {2}, NULL, NULL), RR)8.
S(1, 2, tree(NUCLEUS, ELABORATION, {1},tree(NUCLEUS, LEAF, {1}, NULL, NULL),tree(SATELLITE, LEAF, {2}, NULL, NULL),RR1))9.
S(3, 3, tree(NUCLEUS, LEAF, {3}, NULL, NULL), RR)10.
S(4, 4, tree(SATELLITE, LEAF, {4}, NULL, NULL), RR)11.
S(3, 4, tree(NUCLEUS, ELABORATION, {3},tree(NUCLEUS, LEAF, {3}, NULL, NULL),tree(SATELLITE, LEAF, {4}, NULL, NULL),RR2))12.
S(1, 4, tree(NUCLEUS, CONTRAST, {1, 3},tree(NUCLEUS, ELABORATION, {1},InputInputInputInputInput1, 2, Axiom (31), MP1, 3, Axiom (32), MP6, 7, Axiom (33), MP1, 4, Axiom (31), MP1, 5, Axiom (32), MP9, 10, Axiom (33), MP8, 11, Axiom (35), MPtree(NUCLEUS, LEAF, {1}, NULL, NULL),tree(SATELLITE, LEAF, {2}, NULL, NULL)),tree(NUCLEUS, ELABORATION, {3},tree(NUCLEUS, LEAF, {3}, NULL, NULL),tree(SATELLITE, LEAF, {4}, SC null, NULL))),0)Figure 7A derivation of the theorem that corresponds to the valid rhetorical structure shown inFigure 3.The derivation starts with five axioms that are straightforwardly derived fromthe input of the problem.
Using the axioms in lines 1 and 2, axiom (31), and themodus ponens rule, we derive the theorem in line 6.
Using the axioms in lines 1and 3, axiom (32), and modus ponens, we derive the theorem in line 7.
Similarly, wederive the theorems in lines 9 and 10.
These four theorems all correspond to validrhetorical structures that can be built on top of elementary units.
Using the theoremsin lines 6 and 7, axiom (33), and modus ponens, we derive the theorem in line 8.
Itcorresponds to a valid rhetorical structure that can be built across span \[1, 2\].
Sincethis structure uses rhetorical relation rhet_reI(ELABORATION, 2, 1), the set of rhetoricalrelations that can be used to further expand the rhetorical structure will be given bythe set RR1, shown in (36).
Line 11 corresponds to a valid rhetorical structure that canbe built on top of elementary span \[3,4\].
Since this structure uses rhetorical relationrhet_rel(ELABORATION,4,3), the set of rhetorical relations that can be used to furtherexpand the rhetorical structure will be given by the set RR2, shown in (37).
Usingthe theorems derived in lines 8 and 11, axiom (35), and modus ponens gives us thetheorem in line 12 that corresponds to a valid structure for the entire text, the structureshown in Figure 3.As I have shown in Marcu (2000), the proof-theoretic account outlined here isboth sound and complete with respect o the constraints that characterize the validrhetorical structures enumerated in Section 2.4.
That is, all theorems that are derivedusing the disjunctive proof-theoretic account correspond to valid text structures; and430Marcu Rhetorical Parsing of Unrestricted TextsStatus = {NUCLEUS.SATELLITE}~-L  ~} Type = (BACKGROUND}/ / / ~  Promotion = {2}Status = {SATTELITE} 1 /  \ Status = {NUCLEUS}Type = (LEAF} f ~ ~ Type = {LEAF}Promotion = {1} ~.~ ~ Promotion = {2}a)Status = (NUCLEUS,SATELLITE}k~ -L J Type = \[JUSTIRCAT}ON}/ / / ~  Promotion = {2}Status = {SATTELITE} , /  \ Status = (NUCLEUS}Type = {LEAF} f ~ ~ Type = {LEAF}Promotion = {I} ~ ~ Promotion = {2}b)Figure 8All valid rhetorical structures of sentence (20).Status = (NUCLEUS.SATELLITE} ~ Status = {NUCLEUS,SATELLITE}4-6 ) Type = {CAUSE} \[ 4-6 ) Type = {EVIDENCE}~tatus = {N?CLEUS} ~ Status = (SATELLITE} ~ Status = {NUCLEUS} ~ Status = (SATELLITE}~4-5 ) ?pc = {CONTRAST} \[ 6 ) Type = {LEAF} ~4 5 ) Type = {CONTRAST} ~ 6 ) Type = {LEAF}Slatus ( N ~  ~ Stalus = (NUCLEUS} ~ Status {N= UCLEUS} ~ Status = (NUCLEUS}~ 4 ) ~AF} \[ 5 ) Type:}LEAF} ~ a ) Type ={LEAF} {, $ ) Type=}LEAF)I-'romoton=\[4} ~ Prornot~on=(5} ~ PFomotlon=(4} ~ Promotion={5}a) b)Status = {NUCLEUS,SATELLITE}Type = {CONTRAST}= {4.5}( ~  Status = {NUCLEUS( / ~  Status = {NUCLEUS}Type = }LEAF} ~ 5-6 ) Type = {CAUSE}Promotion = ~ =  {5}Slatus = {NUCLEUS} ~ Status = }SATELLITE)~ 5 )Type=(LEAF} \[ 6 )Type={LEAF}P{omolton ={5) ~ Prornotion = {6}c)Status = }NUCLEUS,SATELLITE}~ 4-6 ) Type = {CONTRAST} ~ = 14,51Status = {NUCLEUS( ~ Status = {NUCLEUS}~ 4 ) Type = {LEAF) \[5-6 ) Type=(EVIDENCE}Promotion = ~ =  {5}Status = }NUCLEUS} ~ Status = {SATELLITE}~.
5 ) Type = {LEAF} ~ 6 ) Type = {LEAF}~ Promotion={5) ~ Promotion=(6}d)Figure 9All valid rhetorical structures of sentence (22).any valid rhetorical structure can be derived through the successive application ofmodus ponens and the axioms of the disjunctive proof-theoretic account.Implementing the Proof-Theoretic A count.
There are many ways in which one can imple-ment the proof theory described in this section.
Since all axioms of the theory are Hornclauses, they can be immediately translated into a Prolog program.
Equally trivial is toimplement he proof-theoretic account using traditional parsing techniques that com-bine terminal and nonterminal symbols only when the constraints enumerated in theaxioms of the proof-theoretic account are satisfied.
The rhetorical parser implementsthe proof-theoretic account as a chart-parsing algorithm (see Marcu \[2000\] for details).When a chart-parsing implementation uses as input the rhetorical relations that werehypothesized by the discourse-marker- and word-co-occurrence-based algorithms atthe sentence, paragraph, and section levels of text (19), it derives the valid rhetoricalstructures shown in Figures 8-13.431Computational Linguistics Volume 26, Number 3' ~  Status = {NUCLEUS,SATELLITE}k, " ?
j J  Type = {CONCESSION}/ / / ~  Promotion = {8}Status = {SATTELITE} / ~ Status = \[NUCLEUS}Type = {LEAF} /./- ~-~ f ~,~ Type = {LEAF}Promotion = {7} ~ ~ Promotion = {8}Figure 10The valid rhetorical structure of sentence (24).Status = {NUCLEUS,SATELLITE}1-6 ) Type = {ELABORATION} ~ = {\[1-2\]}_Status = {NUCLEUS} ~ Status = {SATELLITE}1-2 )':,,T pe= {LEAF} \[ 3-6 )Type = {ELABORATION}Promotion = ~ =  {3}_Status = {NUCLEUS} ~ Status = {SATELLITE}\[ 3 ) Type : {LEAF} { 4-6 ) Type = {LEAF}Promotion = {3} ~ Promotion = {\[4-6\]}Figure 11The valid rhetorical structure of the first paragraph of text (19); see the relations in (29).Status : {NUCLEUS.SATELLITE}( 7-10 ) Type = {EXAMPLE} ~ = 117-8\]}Status = {NUCLEUS} ~ Status = {SATELLITE}{~ 7-8 ) Type = {LEAF} {~ 9-10 ) Type = {ANTITHESIS}Promotion = ~ =  {10}Status = {SATELLITE} ~ Status = {NUCLEUS}9 )Type={LEAF} { 10 )Type={LEAF}Promotion = {9} ~ Promotion = {10}Figure 12The valid rhetorical structure of the second paragraph of text (19); see the relations in (26).Status = {NUCLEUS}Type = {LEAF}Promotion = {\[1-6\]}Status = {NUCLEUS,SATELLITE}Type = {ELABORATION}Promotion = {\[1-6\]}Status = {SATELLITE}Type = {LEAF}Promotion = {\[7-10\]}Figure 13The valid rhetorical structure of text (19); see the relation in (27).432Marcu Rhetorical Parsing of Unrestricted Texts4.6 The Ambiguity of Discourse4.6.1 A Weight Function for Rhetorical Structures.
Discourse is ambiguous the sameway sentences are: usually, more than one discourse structure is produced for anygiven text.
For example, we have seen that the rhetorical parser finds four differentvalid rhetorical structures for sentence (22) (see Figure 9).
In my experiments, I no-ticed that the "best" discourse trees are usually those that are skewed to the right.
Ibelieve that the explanation for this observation is that text processing is essentiallya left-to-right process.
Usually, people write texts so that the most important ideasgo first, both at the paragraph and at the text level.
In fact, journalists are trained toconsciously employ this "pyramid" approach to writing (Cumming and McKercher1994).
The more text writers add, the more they elaborate on the text that went be-fore: as a consequence, incremental discourse building consists mostly of expansionof the right branches.
A preference for trees that are skewed to the right is also con-sistent with research in psycholinguistics that shows that readers have a preferencefor interpreting unmarked textual units as continuations of the topics of the unitsthat precede them (Segal, Duchan, and Scott 1991).
At the structural level, this cor-responds to textual units that elaborate on the information that has been presentedbefore.In order to disambiguate he discourse, the rhetorical parser computes a weightfor each valid discourse tree and retains only the trees that are maximal.
The weightfunction w, which is shown in (38), is computed recursively by summing up theweights of the left and right branches of a rhetorical structure and the differencebetween the depth of the right and left branches of the structure.
Hence, the moreskewed to the right a tree is, the greater its weight w is.
(38) l 0 if isLeaf(tree), w( tree) = w( left Of ( tree) + w( right Of ( tree) + otherwise.depth( rightOf ( tree) - depth( leftOf ( tree)For example, when applied to the valid rhetorical structures of sentence (22), theweight function will assign the value -1 to the trees shown in Figures 9(a) and 9(b),and the value +1 to the trees shown in Figures 9(c) and 9(d).4.6.2 The Ambiguity of Discourse--An Implementation Perspective.
There are twoways one can disambiguate discourse.
One way is to consider, during the parsingprocess, all of the valid rhetorical structures of a text.
When the parsing is complete,the structures of maximal weight can be then assigned to the text given as input.
Theother way is to consider, during the parsing process, only the partial structures thatcould lead to a structure of maximal weight.
For example, if a chart parsing algorithmis used, we can keep in the chart only the partial structures that could lead to a finalstructure of maximal weight.In step III.4, the rhetorical parser shown in Figure 5 implements the second ap-proach.
Hence, instead of keeping all the partial structures that characterize sen-tence (22), it will keep only the partial structures of maximal weight, i.e., the structuresshown in Figures 9(c) and 9(d).
In this way, the overall efficiency of the system is in-creased.When the rhetorical parser selects the trees of maximal weight for text (19), at eachof the three levels of abstraction, it selects the trees shown in Figures 8(a), 9(c), 10,11, 12, and 13.
If no weight function were used, the rhetorical parser would generateeight distinct valid rhetorical structures for the whole text.433Computational Linguistics Volume 26, Number 3? "
Surta??
Icmpcramres?
With ils d ist~t or~ill ?
typically a~rag?
aboul, .
~)  p~rcgm t~hcr  ?
\[" .60  Ocgr~.. .
r .
, .
, , , .
,' Irom the sun \[han E~th- ?
M~s expcrlences trigid: } ~d slim atmospl~ric ' ~athc  dmons  (-76 deg~a~p to -' , .'
Example  : ,, .
.
.
.
.
- .
, .
.. .
.
.
.
.
.
gh .
.
.
.
.
.
osph:rc : i mo~M .
.
.
.
.
.
.
.
.  "
~va~cr 'n di~il0e?
~?s  " Ylx'lc\[' wh '~ ; suna ~m~l  amt~pl  nvo  v?
b ow n~ du  : cw ~1?rs  ~ ~is  dry - i ce  ' remains  in ~h?
sky all?
(7 )  .
.
.
.
.
.
: cvap?ra\[?$ Irom th~ , II I ( 10 ) I~ \ [ l~s  ?v?
op.
.
( 8 ?
t f~n c~b~ dtOxld ?
: never w~m cnoug toLsc ol the low atmo~,h?.c  ?Figure 14The discourse tree of maximal weight that is built by the rhetorical parsing algorithm fortext (1).
Nuclei are surrounded by solid boxes and satellites by dotted boxes; links between anode and the subordinate nucleus or nuclei are represented by solid arrows; links between anode and the subordinate satellites by dotted lines.
Occurrences of parenthetical informationare enclosed in the text by curly brackets; the leaves of the discourse structure are numberedfrom 1 to N, where N represents he number of elementary units in the whole text.
Thenumbers associated with each node denote the units that are members of its promotion set.4.7 Deriving the Final Rhetorical StructureIn the last step (lines 16-17 in Figure 5), after the trees of maximal  weight have beenobtained at the sentence, paragraph, and section levels, the rhetorical parser mergesthe valid structures into a structure that spans the whole text of a section.
In this way,the rhetorical parser builds one tree for each of the sections of a given document.
Themerging process is a trivial procedure that assembles the trees obtained at each level ofgranularity.
That is, the trees that correspond to the sentence level are substituted forthe leaves of the structures built at the paragraph level, and the trees that correspond tothe paragraph levels are substituted for the leaves of the structures built at the sectionlevel.
The promotion units associated with each span are recomputed in a bottom-upfashion so that they correspond to elementary units and not to sentence and paragraphlabels.
The rhetorical parser has a back-end process that uses "dot," a preprocessorfor drawing oriented graphs, to automatical ly generate PostScript representations ofthe rhetorical structures of maximal  weight.
When appl ied to text (1), the rhetoricalparser builds the rhetorical structure shown in Figure 14.5.
EvaluationThere are two ways to evaluate the correctness of the discourse trees that an automaticprocess builds.
One is to compare the automatical ly derived trees with trees that havebeen built manually.
The other is to evaluate the impact that they have on the accuracyof other natural language processing tasks, such as anaphora resolution, intentionrecognition, or text summarization.
The rhetorical parser presented here was evaluatedby following both of these avenues.434Marcu Rhetorical Parsing of Unrestricted TextsManually annotated tree1-?4-7 i~/^,,* \[EXAMPLE2 3 E ~ N  6-74 5Automatically nnotated tree1-72-36 7a) b)Figure 15Example of discourse trees: (a) represents a manually built tree; (b) represents anautomatically built tree.5.1 Evaluating the Correctness of the Trees5.1.1 Labeled Recall and Precision Figures.
To evaluate the correctness of the treesbuilt by the rhetorical parser, two analysts have manually built the rhetorical structureof five texts from Scientific American, which ranged in size from 161 to 725 words.
Theanalysts were computational linguists who were familiar with Rhetorical StructureTheory (Mann and Thompson 1988).
They did not agree beforehand on any annotationstyle or protocol and were not given any specific instructions besides being askedto build trees that were consistent with the requirements put forth by Mann andThompson.
The analysts were supposed to use only the set of relations proposed byRST and the relation TEXTUAL to link the subtrees ubsuming the title and body of atext.
Analysts were not asked to build binary structures ( imilar to those derived by therhetorical parser), although we knew that this could negatively affect he performanceof our system.The performance of the rhetorical parser was estimated by applying labeled re-call and precision measures, which are extensively used to study the performance ofsyntactic parsers.
Labeled recall reflects the number of correctly labeled constituentsidentified by the rhetorical parser with respect o the number of labeled constituentsin the corresponding manually built tree.
Labeled precision reflects the number of cor-rectly labeled constituents identified by the rhetorical parser with respect o the totalnumber of labeled constituents identified by the parser.
Labeled recall and precisionfigures were computed with respect o the ability of the rhetorical parser to identifyelementary units, hierarchical text spans, text span nuclei and satellites, and rhetoricalrelations.To understand how these figures were computed, assume for example that ananalyst identified six elementary units in a text and built the discourse structure inFigure 15(a) and that the program identified five elementary units and built the dis-course structure in Figure 15(b).
When we align the two structures, we obtain the labelsin Table 7, which show that the program did not identify the breaks between units 2and 3, and 4 and 5 in the analyst's annotation; and that it considered the unit labeled6-7 in the analyst's annotation to be made of two units.
Table 7 lists all constituentsin the two structures, the associated labels at the elementary unit, span, nuclei, andrhetorical levels, and the corresponding recall and precision figures.
As Table 7 shows,435Computational Linguistics Volume 26, Number 3Table 7Computing the performance of a rhetorical parser (P -- Program;A = Analyst).Constituent Units Spans NuclearityA P A P A P ARelations1-1 * * * * N N SPAN SPAN2-2 * * N JOINT3-3 * * N JOINT4-4 * * N SPAN5-5 * * S ELABORATION6-6 * * N JO INT7-7 * * N JOINT2-3 * * * N S CONTRAST ANTITHESIS4-5 * * * N N SPAN SPAN6-7 * * * S S EXAMPLE EXAMPLE4-7 * * N N CONTRAST SPAN2-7 * * S S ELABORATION ELABORATIONR=1/6 R=6/10 R=5/10 R=4/10P=1/5  P=6/8  P=5/8  P=4/8CON ,ON2 3 1 2a) b) c)Figure 16Discourse trees (b) and (c) represent alternative binary representations of the nonbinarydiscourse tree in (a).the program in this example identified only one of the six elementary units identifiedby the analyst (unit 1), for a recall of 1/6.
Since the program identified a total of fiveunits, the precision is 1/5.
Similarly, recall and precision figures can be computed forspan, nuclearity, and rhetorical relation assignments.This evaluation assumes that rhetorical abels are associated with the childrennodes, and not with the father nodes, as in the formalization.
For example, the EX-AMPLE relation that holds between spans \[4,5\] and \[6,7\] in the tree in Figure 15(a), isnot associated with span \[4,7\], but rather, with the span \[6,7\], which is the satellite ofthe relation; and by convention, the rhetorical relation of the span \[4,5\] is set to SPAN.The rationale for this choice is the fact that the analysts did not construct only binarytrees; some of the nodes in their manually built representations had multiple children.Representing in binary form a tree such as that shown in Figure 16(a), for example,would require an additional hierarchical level on the spans, as shown in Figures 16(b)and 16(c), that was not part of the original analysis.
To avoid introducing in the anno-tation choices that were not part of what the analysts did, I decided for the purposeof evaluation to follow the procedure outlined above.Table 8 shows average recall and precision figures that reflect the performanceof the rhetorical parser on the five Scientific American texts.
In addition to the recall436Marcu Rhetorical Parsing of Unrestricted TextsTable 8Performance ofthe rhetorical parser.Analysts ProgramRecall Precision Recall PrecisionElementary units 87.9 87.9 51.2 95.9Spans 89.6 89.6 63.5 87.7Nuclearity 79.4 88.2 50.6 85.1Relations 83.4 83.4 47.0 78.4and precision figures specific to the program, Table 8 also displays average recall andprecision figures obtained for the trees built only by the analysts.
These figures reflecthow similar the annotations of the two analysts were and provides an upper boundfor the performance of the rhetorical parser: if the recall and precision figures of theparser were the same as the figures for the analysts, the discourse trees built by therhetorical parser would be indistinguishable from those built by a human.As the results in Table 8 show, the rhetorical parser fails to identify a fair num-ber of elementary units (51.2% recall); but the units it identifies tend to be correct(95.9% precision).
As a consequence, performance atall other levels is affected.
Withrespect o identifying hierarchical spans, recall is about 25% lower than the averagehuman performance; with respect to labeling the nuclear status of spans, recall is about30% below human performance; and with respect o labeling the rhetorical relationsthat hold between spans, recall is about 40% below human performance.
In general,the precision of the rhetorical parser comes close to the human performance l vel.However, since the level of granularity at which the rhetorical parser works is muchcoarser than that used by human judges, many sentences are assigned a much simplerstructure than the structure built by humans.
For example, whenever an analyst useda JOINT relation to connect wo clause-like units separated by an and, the rhetoricalparser failed to identify the two units; it often treated them as a single elementaryunit.
As a consequence, the recall figures at all levels were significantly lower thanthose specific to the humans.5.1.2 Confus ion Matrices.
Another way to evaluate the performance of the rhetoricalparser is to build a confusion matrix over the most frequently used relations.
To enablethe reader to distinguish between rhetorical and nuclearity errors, I follow the samestrategy as in the case of computing labeled recall and precision figures.
That is, Iconsider by convention that the nuclei nodes of a rhetorical representation are labeledwith the relation SPAN.Table 9 shows the distributions of rhetorical relation labels used by one of the ana-lysts and the program.
The most frequently used relations were JOINT~ ELABORATION,and CONTRAST.
(Label SPAN denotes the nucleus of any mononuclear relation.)
Over-all, the 15 most frequently used relations account for more than 92% of the relations inthe corpus.
The distribution of relations inferred by the program is somewhat similar,with the most frequently used relations being JOINT~ ELABORATION, and CONTRASTas well.
The program, though, shows a stronger preference for ELABORATION relationsover JOINTS.Table 10 shows a confusion matrix that reflects the ability of the rhetorical parser toderive rhetorical structure trees.
The confusion matrix compares cumulatively, over theentire corpus, the rhetorical relations inferred by the parser with the rhetorical relations437Computational Linguistics Volume 26, Number 3Table 9Distribution of the most frequently used 15relations.Relation Judge (%) Program (%)SPAN 32.62 35.65JOINT 14.53 14.78ELABORATION 12.76 20.43CONTRAST 7.80 7.82TEXTUAL 3.54 3.47CONDITION 3.19 1.73EXAMPLE 2.83 3.04SEQUENCE 2.83 -EVIDENCE 2.12 -OTHERWISE 2.12 0.86PURPOSE 1.77 0.86CONCESSION 1.77 1.73CIRCUMSTANCE 1.77 1.30BACKGROUND 1.77 1.73CAUSE 1.41 2.60Table 10Confusion matrix.Relation (a) (b) (c) (d) (e) (f) (g) (h) (i) (j) (k) (1) (m) (n) (o) (p)SPAN (a) 51 8 9 3JOINT CO) 4 4 5 1 1ELABORATION (C) 2 5 18 1CONTRAST (d) 1 1 14 1TEXTUAL (e) 10CONDITION(f) 5 1EXAMPLE (g) 1 6 1SEQUENCE (h) 3 4 1EVIDENCE (i) 1 1 4OTHERWISE0) 2PURPOSE (k) 2CONCESSION (1) 2 3CIRCUMSTANCE (Ill) 1 1 1BACKGROUND (n) 2 1CAUSE (O) 1 1 5OTHER (p) 2 1 1 1 2NO SPAN (r) 14 8 5 2 1 1 1 2chosen by  one analyst .
For  any  re lat ion a, a co lumn in the confus ion  matr ix  reflectsthe number  of re lat ions of type  R that were  ( in)correct ly ident i f ied by  the rhetor ica lparser  w i th  respect  o the re lat ions ident i f ied by  the analyst .
For example ,  the co lumnlabe led (d) shows  that out  of 18 textual  spans  labe led w i th  the re lat ion CONTRASTby  the parser,  14 were  labe led  as CONTRASTS, one as the satel l i te of an ELABORATIONrelat ion,  and  one as the satel l i te of an OTHER re lat ion by  the analyst .
In add i t ion ,  twoof the 18 spans  had  no cor respond ing  span  in one ana lyst ' s  representat ion.The confus ion matr ix  shows  that the rhetor ica l  parser  does a fair ly good  job atrecogniz ing rhetor ica l  re lat ions that are usua l ly  marked  by  cue phrases,  i.e., CONTRAST~CONDITION~ EXAMPLE, OTHERWISE~ PURPOSE~ CONCESSION~ and CAUSE relat ions.
Theconfus ion matr ix  also shows  that the s imple  mode l  of cohes ion that our  parser  employsis not  adequate  for d i s t ingu ish ing  between rhetor ica l  re lat ions of ELABORATION and438Marcu Rhetorical Parsing of Unrestricted TextsI 2 ka) b)Figure 17A flat (a) and a binary (b) representation f the discourse structure of a text.JOINT; the submatrix that subsumes the labels SPAN~ JOINT, and ELABORATION showsthe highest levels of confusion.
Clearly, semantic similarity is not sufficient if one is todecide whether a rhetorical relation of JOINT, ELABORATION, or BACKGROUND holdsbetween two textual segments.The rhetorical parser is unable to recognize "purely" intentional relations, suchas EVIDENCE, which are seldomly marked.
As the confusion matrix shows, the parserlabels no relation as EVIDENCE; rather, it chooses instead ELABORATION, four times,JOINT, once, and a relation with a different nuclearity, once.
Since the parser drawsno temporal inferences, it labels most of the SEQUENCE relations as JOINTS, which inmany cases is an adequate approximation.The relatively large number of spans that have no correspondence in one analyst'srepresentations can be explained by two factors.
The first factor concerns our repre-sentation choice.
Since the discourse parser builds binary trees, it also derives textspans that cannot be matched against a nonbinary representation.
For example, al-though the tree in Figure 17(b) is a binary reformulation of the tree in Figure 17(a), theintermediate spans \[1,k\], \[2,k\], .
.
.
,  \[k-l,k\] in Figure 17(b) cannot be matched againstany span in the tree in Figure 17(a).
Humans built structures uch as those shown inFigure 17(a); the discourse parser did not.
The second factor concerns the difficulty ofthe task.
Some texts have very sophisticated text structures, which are difficult to inferonly on the basis of cue phrase occurrences and word-based similarity measures.
Wediscuss some of the difficult cases in Section 5.1.3, below.5.1.3 Qualitative Evaluation.
As the quantitative valuation results in the precedingsection show, the rhetorical structures that can be derived by relying only on discoursemarkers and cohesion are adequate in some cases and not in others.
I discuss some ofthese cases below.Good Discourse Structures at the Paragraph Level.
In most of the cases that I inspectedvisually on a variety of texts, the partial structures built above sentences and withinparagraphs appeared to be adequate.
The explanation is simple: Paragraphs that usefew discourse markers tend to express the most important information at their begin-ning, which corresponds to the first sentence being a nucleus and subsequent sentenceselaborating on it.
Such paragraphs usually have discourse structures that are similarto those preferred by the rhetorical parser, which favors structures that are skewed tothe right and which hypothesizes that ELABORATION relations hold between unmarkedsentences.
If a paragraph as a more complex discourse structure, it usually employsdiscourse markers, which are detected and exploited by the rhetorical parser.439Computational Linguistics Volume 26, Number 3Good Discourse Structures at the Text Level, for Short Texts.
The same argument appliesfor short texts as well.
Texts that consist of only a few paragraphs also tend tohave structures that are skewed to the right.
When they do not, these texts usu-ally rely on discourse markers to signal to the reader that the content of a paragraphshould not be interpreted as a simple ELABORATION of the material that was presentedbefore.Good Discourse Structures for Sentences, Paragraphs, and Texts that Use Unambiguous Dis-course Markers.
Discourse markers uch as although, in contrast, and however signal inmost cases CONCESSION~ CONTRAST~ and ANTITHESIS relations, respectively.
Since theuse of these markers is consistent, most of the rhetorical relations that are signaled bysuch markers are correctly identified.
For example, more than 75% of the CONTRASTrelations that hold across clauses, sentences, and paragraphs in our corpus of ScientificAmerican texts were correctly identified.Good Discourse Structures for Sentences that Use Markers Other than And.
The structuresthat the discourse parser derives for sentences that use discourse markers uch as be-cause, if, and when closely match those built by humans.
Although the discourse parseroverhypothesizes r lations, the constrained mathematical model it relies upon consid-erably reduces the space of valid discourse interpretations.
The nuclearity preferencesassociated with the discourse markers eliminate many of the invalid interpretations.As a consequence, the discourse structures built for sentences that have clause-likeunits as leaves are correct in most of these cases.Bad Discourse Structures for Sentences that Use the Discourse Marker And.
Problems fromthis category are readily observed in the trees in Figure 1 and Figure 14.
For example,the rhetorical parser is not able to identify that a discourse boundary should be insertedbefore the occurrence of and in the sentence "\[Surface t mperatures typically averageabout -60 degrees Celsius (-76 degrees Fahrenheit) at the equator\] [and can dip to-123 degrees C near the poles.\]."
As a consequence, the recall figure with respect oidentifying the elementary units of this sentence is 0.
The recall figure with respect toidentifying the hierarchical spans of this sentence is 1/3 (the parser correctly identifiesonly the span that subsumes the entire sentence but not the two subspans that subsumethe elementary units).
The recall figures with respect o identifying the nuclearity ofthe spans and the rhetorical relations that hold between them are also negativelyaffected.
Hence, it seems clear that surface-based methods are not sufficient if we areto approach uman performance l vels at the task of identifying elementary discourseunits.By examining the failures of the elementary unit boundary identification algo-rithm, I have come to believe that some of the problematic cases could be solved byusing part-of-speech tags and other syntactic information.
For example, in many of thesentences in which and is followed by a verb, an elementary unit boundary needs tobe inserted before its occurrence.
Such a rule would be sufficient for breaking into twounits the example sentence considered above.
6It remains to be seen whether a rhetor-ical parser can approach uman performance l vels without building full syntactictrees for the sentences under consideration.6 For research t at uses part-of-speech tags in order to identify elementary unit boundaries, see Marcu(1999a).440Marcu Rhetorical Parsing of Unrestricted TextsIncorrectly Labeled Intentional Relations.
We can see from the trees in Figure 1 and Fig-ure 14 that although the rhetorical parser correctly identified the hierarchical segmentsand the nuclearity statuses in the first paragraph, it was unable to determine that arhetorical relation of EVIDENCE holds between the last two sentences and the firstsentence of the first paragraph.
Instead, the parser used an ELABORATION relation.
Ingeneral, the discourse parser is unable to correctly identify intentional relations, inparticular, relations of EVIDENCE that hold between sentences and paragraphs.
Suchrelations are usually not marked; to derive them one needs to "understand" what atext is about.
For example, our rhetorical parser mislabeled as ELABORATION and JOINTall six EVIDENCE relations that hold between sentences and paragraphs in the texts inour Scientific American corpus.It seems that to build RS-trees as accurately as humans, relying only on cue phrasesand cohesion is not sufficient.
In some cases, a deeper analysis of the relation betweenconnectives and rhetorical relations, such as that proposed by Grote et al (1997) inthe context of natural language generation, may help hypothesize better elations.
Ingeneral, though, it is unclear what forms of reasoning to use to derive, for unrestrictedtexts, relations that are as difficult to infer as the EVIDENCE relation in Figure 1.Bad Discourse Structures for Very Large Texts.
When the discourse parser attempts to de-rive the structure of very large texts, the preference for structures that are skewed tothe right and the modeling of discourse as binary trees do not always work.
For exam-ple, some newspaper articles are written so that k facets of the most important idea arepresented in the first paragraph.
And then, each of these facets is elaborated in turn insubsequent paragraphs.
An adequate discourse structure for such a text is one that hasthe first paragraph as nucleus and k satellites directly linked to it at the same level ofembedding (see Figure 17(a)).
The choice of modeling the discourse structure of textsusing binary representations appears to be infelicitous in such cases because binarytrees induce an unjustified number of additional levels of embedding (see Figure 17(b)).Since the rhetorical parser derives binary trees only, it cannot represent discourse struc-tures that would closely match the structure of newspaper articles of this kind.The preference for discourse trees that are skewed to the right is also problematicwhen handling texts that start by providing some background information or by mo-tivating the reader before presenting the main idea.
For example, the text in italics in(39) should be the satellite of a MOTIVATION relation whose nucleus ubsumes the restof the text.
(39) Running nose.
Raging fever.
Aching joints.
Splitting headache.
Are there any poorsouls suffering from the fiu this winter who haven't longed for a pill to make it allgo away?
Relief may be in sight.
Researchers atGilead Sciences, apharmaceutical company in Foster City, California, reported last week inthe Journal of the American Chemical Society that they have discovereda compound that can stop the influenza virus from spreading in animals.Tests on humans are set for later this year.Unfortunately, cohesion is not enough for determining this relation.
Consequently, thediscourse structure built by the rhetorical parser for this text is erroneous.5.2 Evaluating the Usefulness of the Trees for Text SummarizationFrom a salience perspective, the elementary units in the promotion set of a node of atree structure denote the most important units of the textual span that is dominatedby that node.
For example, according to the rhetorical structure in Figure 14, unit 3441Computational Linguistics Volume 26, Number 3is the most important unit of span \[3,6\], units 4 and 5 are the most important unitsof span \[4,6\], and unit 2 is the most important unit of the whole text.
If we applythe concept of salience over all elementary units in a text, we can use the rhetoricalstructure to induce a partial ordering on the importance of these units.
The intuitionbehind this approach is that the textual units in the promotion sets of the top nodes ofa discourse tree are more important than the units that are salient in the nodes foundat the bottom.
When applied to the rhetorical structure in Figure 14, such an approachinduces the partial ordering in (40), because unit 2 is the only promotion unit of theroot; unit 8 is the only unit found in the promotion set of a node immediately belowthe root (unit 2 has been already accounted for); units 3 and 10 are the only unitsthat belong to promotion sets of nodes that are two levels below the root; and so on.
(See Marcu \[1999b\] for a mathematical formulation of this method that uses rhetoricalstructures for deriving a partial ordering of the important units in texts.
)(40) 2>873,10>1,4 ,5 ,7 ,9>6If we are interested in generating a very short summary of text 19, for example, we canthen produce an extract containing only unit 2, because this is the most important unitgiven by the partial ordering derived from the corresponding rhetorical representation.A longer summary will contain units 2 and 8; a longer one, units 2, 8, 3, and 10; andSO on .Using this idea, I have implemented a rhetorical-based summarization algorithm.The algorithm uses the rhetorical parser described in this paper to determine thediscourse structure of a text given as input, it uses the discourse structure to inducea partial ordering on the elementary units in the text, and then, depending on thedesired compression rate, it selects the p most important units in the text.To evaluate this summarization program, I used two corpora: the five ScientificAmerican texts that I have mentioned above, and a collection of 40 short newspa-per articles from the TREC collection (Jing et al 1998).
Both corpora were labeledfor textual salience by a panel of independent judges: 13 judges labeled clause-likeunits as being important, somewhat important, and nonimportant in the texts of theScientific American corpus; and 5 judges labeled sentences as worthy to be includedin 10% and 20% summaries of the texts in the TREC corpus.
The clauses/sentenceswhich the human judges agreed were important were taken as the gold standard forsummarization.The rhetorical parser derived the RS-tree of each of the 45 texts in the two corpora,and used the RS-tree to induce a partial ordering of the importance of the elementaryunits in the corresponding text.
The rhetorical summarizer then selected the mostimportant k units in a text, where k was chosen so as to match as closely as possible thenumber of units in the gold standard.
The number of units selected for summarizationwas determined similarly for the other summarization programs that I used in theevaluation.To assess the performance of the rhetorical-based summarizer (and of the othersummarizers that I discuss below), I use recall, precision, and F-value figures.
The recallfigure is given by the number of units that were correctly identified by the summarizeras being important, over the total number of important units in the gold standard.The precision figure is given by the number of units that were correctly identified bythe summarizer as being important, over the total number of units identified by thesummarizer.
The F-value is a combined Recall-Precision value, given by the formula2 x Recall x Precision/(Recall + Precision).442Marcu Rhetorical Parsing of Unrestricted TextsTable 11The performance ofthe rhetorical-based summarizer.Corpus Method Recall Precision DvalueScient~'c American(Clause-levelsummarization)Judges 72.66 69.63 71.11Rhetorical-based summarizer with learning 67.57 73.53 70.42Rhetorical-based summarizer 51.35 63.33 56.71Microsoft Office97 summarizer 27.77 25.44 26.55Lead baseline 39.68 39.68 39.68Random baseline 25.70 25.70 25.70TRECSentence-levelsummarization(20% compressionrate)Judges 82.83 64.93 72.80Rhetorical-based summarizer with learning 61.79 60.83 61.31Rhetorical-based summarizer 46.54 49.73 48.08Microsoft Office97 summarizer 39.00 32.00 35.15Lead baseline 70.91 46.96 56.50Random baseline 15.80 15.80 15.80In order to compare the performance of the rhetorical-based summarizer with thatof humans, I have also determined the performance of the human judges, by averagingthe performance of each judge with respect o the gold standard.
As Table 11 shows,the human-level F-value for the task of identifying important clauses in the ScientificAmerican corpus was 71.11%; the human-level F-value for the task of identifying themost important 20% of the sentences in the TREC texts was 72.80%.
To better assess theperformance of the rhetorical-based summarizer, I also determined the performance oftwo baseline summarizers.
The lead-based summarizer assumes that the most impor-tant k units in a text are the first k units in that text.
The random-based summarizerassumes that the most important k units in a text can be selected stochastically.As Table 11 shows, for both corpora, the rhetorical-based summarizer performsbetter than the random baseline summarizer and better than a commercial system,the Microsoft Office97 summarizer.
The rhetorical-based summarizer outperforms thelead-based summarizer only for texts in the Scientific American corpus.
Most of thenewspaper articles in the TREC collection employ the pyramid journalistic style andhave the most important sentences at the beginning of the articles.
As a consequence,the performance of the lead-based summarizer on TREC texts is quite high.
However,an implementation f the rhetorical parser that uses learning techniques to chooserhetorical interpretations that are likely to increase the performance of the rhetorical-based summarizer yields a program that identifies important units at levels of per-formance that are close to human performance for Scientific American texts and thatare about 10% below human performance for TREC newspaper articles and about5% above the lead baseline.
The rhetorical-based summarizer that employs learningtechniques to improve its performance is discussed in detail in Marcu (2000).The data in Table 11 shows that although the rhetorical parser does not produceperfect rhetorical structure trees, it can be used successfully todetermine the importantunits of texts.6.
Re lated WorkWhen this research was carried out, there was no rhetorical parser for English.
How-ever, very recently, Corston-Oliver (1998) has explored a different facet of the workdescribed here and investigated the possibility of using syntactic information to hy-443Computational Linguistics Volume 26, Number 3pothesize relations.
His system uses 13 rhetorical relations and builds discourse treesfor articles in Microsoft's Encarta 96 Encyclopedia.
I believe that the research that comesclosest o that described in this chapter is that of Sumita et al (1992) and Kurohashiand Nagao (1994).Sumita et al (1992) report on a discourse analyzer for Japanese, which differsfrom mine in a number of ways.
Particularly important is the fact that the theoreticalfoundations of Sumita et al's analyzer do not seem to be able to accommodate heambiguity of discourse markers; in their system, discourse markers are consideredunambiguous with respect to the relations that they signal.
In contrast, my rhetoricalparser uses a mathematical model in which this ambiguity is acknowledged and ap-propriately treated.
Furthermore, the discourse trees that the rhetorical parser buildsare more constrained structures (Marcu 2000): as a consequence, the rhetorical parserdoes not overgenerate invalid trees as Sumita et al's does.
Finally, my rhetorical parseruses only surface-form ethods for determining the markers and textual units anduses clause-like units as the minimal units of the discourse trees.
In contrast, Sumita etal.
use deep syntactic and semantic processing techniques for determining the markersand the textual units and use sentences as minimal units in the discourse structuresthat they build.Kurohashi and Nagao (1994) describe a discourse structure generator that buildsdiscourse trees in an incremental fashion.
The algorithm proposed by Kurohashi andNagao starts with an empty discourse tree and then incrementally attaches sentences toits right frontier, in the style of Polanyi (1988).
The node of attachment is determinedon the basis of a ranking score that is computed using three different sources: cuephrases, chains of identical and similar words, and similarities in the syntactic structureof sentences.
As in the case of Sumita's ystem, Kurohashi and Nagao's ystem takesas input a sequence of parse trees; hence, in order to work, it must be preceded by afull syntactic analysis of the text.
The elementary units of the discourse trees built byKurohashi and Nagao are sentences.Since the systems developed by Corston-Oliver (1998), Sumita et al (1992), andKurohashi and Nagao (1994) were not evaluated intrinsically, it is difficult o comparethe performance of their systems to ours.A parallel ine of research as been investigated recently by Strube and Hahn(1999).
They have extended the centering model proposed by Grosz, Joshi, and We-instein (1995) by devising algorithms that build hierarchies of referential discoursesegments.
These hierarchies induce a discourse structure on text, which constrainsthe reachability of potential anaphoric antecedents.
The referential segments are con-structed through an incremental process that compares the centers of each sentencewith those of the structure that has been built up to that point.The referential structures that are built by Hahn and Strube exploit a language facetdifferent from that exploited by the rhetorical parser: their algorithms rely primarilyon cohesion and not on coherence.
Because of this, the referential structures are notas constrained as the discourse structures that the rhetorical parser builds.
In fact,the discourse relations between the referential segments are not even labeled.
Still, Ibelieve that studying the commonalities and differences between the referential andrhetorical segments could provide new insights into the nature of discourse.7.
Discussion and ConclusionAutomatically deriving the discourse structure of texts is not trivial.
This paper dis-cusses extensively the strengths and weaknesses of an approach to discourse parsingthat relies on cue phrases, cohesion, and a formal model of discourse.
Quantitative444Marcu Rhetorical Parsing of Unrestricted Textsand qualitative analyses of the results show that many relations can be identifiedcorrectly within this framework.
However, this approach is not sufficient for identi-fying intentional relations, such as EVIDENCE, or for choosing between ELABORATION,BACKGROUND~ SEQUENCE, and JOINT relations.The brightest side of the story is that the results in this paper show that therhetorical structures derived by my parser can be used successfully in the context oftext summarization.
Hence, although the rhetorical parser does not get the RS-treesperfectly right, it still manages to determine the important units of text at levels ofperformance that are not far from those of humans.
One possible explanation maybe that the rhetorical-based summarizer described here exploits only the differencebetween satellites and nuclei and the hierarchical structure of text to determine textunits that are important.
The reader should not infer from this that correctly identifyingthe rhetorical relations that hold between spans cannot be useful in a summarizationsetting.
It is likely, for instance, that one may want to systematically exclude from anabstract information that is subsumed by the satellite of an EXAMPLE relation; to doso, it is necessary to identify correctly the relation.The rhetorical summarizer is a niche application that shows how an understand-ing of the hierarchical organization of text can make solving difficult natural anguageproblems easier.
Recent research as shown that by exploiting the structure of dis-course, one can decrease storage space in information retrieval applications (Corston-Oliver and Dolan 1999) and address discourse-specific problems in machine translation(Marcu, Carlson, and Watanabe, 2000).
It is possible that discourse structures of thekinds derived by this parser can have a positive impact on other problems as well.
Forexample, Cristea et al (1999) have shown that a hierarchical model of discourse hasa higher potential for improving the performance of a coreference resolution systemthan a linear model of discourse.
And Hirschman et al (1999) have suggested thatcertain types of questions can be better answered if one has access to rhetorical struc-ture representations of the texts that contain the answers to the questions.
How muchof an impact the rhetorical parser presented here can have on solving these problems,of course, remains an empirical question.AcknowledgmentsI am grateful to Graeme Hirst for the helpand advice he gave me during every stageof this work; and to Marilyn Walker forsuggestions that led to significantimprovements, especially in the Evaluationsection of the paper.
I am also grateful tofour anonymous reviewers who providedthoughtful feedback on an earlier draft.Most of this research was conducted while Iwas at the University of Toronto and wassupported by the Natural Sciences andEngineering Research Council of Canada.ReferencesAsher, Nicholas.
1993.
Reference toAbstractObjects in Discourse.
Kluwer AcademicPublishers, Dordrecht.Asher, Nicholas and Alex Lascarides.
1994.Intentions and information i  discourse.In Proceedings ofthe 32nd Annual Meeting,pages 34-41, New Mexico StateUniversity, Las Cruces, NM, June.Association for ComputationalLinguistics.Bestgen, Yves and Jean Costermans.
1997.Temporal markers of narrative structure:Studies in production.
In Jean Costermansand Michel Fayol, editors, ProcessingInterclausal Relationships.
Studies in theProduction and Comprehension f Text.Lawrence Erlbaum Associates, Hillsdale,NJ, pages 201-218.Briscoe, Ted.
1996.
The syntax andsemantics of punctuation and its use ininterpretation.
I  Proceedings oftheAssociation for Computational LinguisticsWorkshop on Punctuation, pages 1-7, SantaCruz, CA, June.Bruder, Gail A. and Janice M. Wiebe.
1990.Psychological test of an algorithm forrecognizing subjectivity in narrative text.In Proceedings ofthe Twelfth AnnualConference on the Cognitive Science Society,pages 947-953, Cambridge, MA, July.445Computational Linguistics Volume 26, Number 3Corston-Oliver, Simon H. 1998.
Beyondstring matching and cue phrases:Improving efficiency and coverage indiscourse analysis.
In Working Notes of theAAAI Spring Symposium on Intelligent TextSummarization, pages 9-15, Stanford,March.Corston-Oliver, Simon H. and William B.Dolan.
1999.
Less is more: Eliminatingindex terms from subordinate clauses.
InProceedings ofthe 37th Annual Meeting,pages 349-356, University of Maryland,June.
Association for ComputationalLinguistics.Cristea, Dan, Nancy Ide, Daniel Marcu, andValentin Tablan.
1999.
Discourse structureand coreference: An empirical study.
InProceedings ofthe ACL'99 Workshop on theRelationship Between Discourse~DialogueStructure and Reference, pages 46-53,University of Maryland, June.Cristea, Dan and Bonnie L. Webber.
1997.Expectations in incremental discourseprocessing.
In Proceedings ofthe 35thAnnual Meeting of the Association forComputational Linguistics (ACL/EACL-97),pages 88-95, Madrid, Spain, July.Crystal, David.
1991.
A Dictionary ofLinguistics and Phonetics.
Third edition.Basil Blackwell, Oxford.Cumming, Carmen and CatherineMcKercher.
1994.
The Canadian Reporter:News Writing and Reporting.
HarcourtBrace.Di Eugenio, Barbara, Johanna D. Moore, andMassimo Paolucci.
1997.
Learning featuresthat predict cue usage.
In Proceedings ofthe35th Annual Meeting of the Association forComputational Linguistics (ACL/EACL-97),pages 80-87, Madrid, Spain, July.Fraser, Bruce.
1996.
Pragmatic markers.Pragmatics, 6(2):167-190.Gardent, Claire.
1997.
Discourse TAG.Technical Report CLAUS-Report Nr.
89,Universit/it des Saarlandes, Saarbr~icken,April.Grosz, Barbara J., Aravind K. Joshi, andScott Weinstein.
1995.
Centering: Aframework for modeling the localcoherence of discourse.
ComputationalLinguistics, 21(2):203-226.Grosz, Barbara J. and Candace L. Sidner.1986.
Attention, intentions, and thestructure of discourse.
ComputationalLinguistics, 12(3):175-204.Grote, Brigitte, Nils Lenke, and ManfredStede.
1997.
Ma(r)king concessions inEnglish and German.
Discourse Processes,24:87-117.Halliday, Michael A. K. and Ruqaiya Hasan.1976.
Cohesion in English.
Longman.Harabagiu, Sanda and Steven Maiorano.1999.
Knowledge-lean coreferenceresolution and its relation to textualcohesion and coreference.
In Proceedings ofthe ACL'99 Workshop on Discourse/DialogueStructure and Reference, pages 29-38,University of Maryland, June.Harabagiu, Sanda M. and Dan I. Moldovan.1996.
Textnet--A text-based intelligentsystem.
In Working Notes of the AAAI FallSymposium on Knowledge RepresentationSystems Based on Natural Language, pages32-43, Cambridge, MA.Hearst, Marti A.
1997.
TextTiling:Segmenting text into multi-paragraphsubtopic passages.
ComputationalLinguistics, 23(1):33-64.Heurley, Laurent.
1997.
Processing units inwritten texts: Paragraphs or informationblocks.
In Jean Costermans and MichelFayol, editors, Processing InterclausalRelationships.
Studies in the Production andComprehension f Text.
Lawrence ErlbaumAssociates, pages 179-200.Hirschberg, Julia and Diane Litman.
1993.Empirical studies on the disambiguationof cue phrases.
Computational Linguistics,19(3):501-530.Hirschman, Lynette, Marc Light, Eric Breck,and John D. Burger.
1999.
Deep read: Areading comprehension system.
InProceedings ofthe 37th Annual Meeting,pages 325-332, University of Maryland,June.
Association for ComputationalLinguistics.Hobbs, Jerry R. 1990.
Literature andCognition.
CSLI Lecture Notes Number 21.Hobbs, Jerry R., Mark Stickel, DouglasAppelt, and Paul Martin.
1993.Interpretation asabduction.
ArtificialIntelligence, 63:69-142.Hoey, Michael.
1991.
Patterns of Lexis in Text.Oxford University Press.Jing, Hongyan, Regina Barzilay, KathleenMcKeown, and Michael Elhadad.
1998.Summarization evaluation methods:Experiments and analysis.
In Proceedingsof the AAAI-98 Spring Symposium onIntelligent Text Summarization, pages 60-68,Stanford, March.Kameyama, Megumi.
1994.
Indefeasiblesemantics and defeasible pragmatics.Technical Note 544, SRI International.
Ashorter version to appear in KanazawaMakoto, Christopher Pinon, and Henriettede Swart, editors, Quantifiers, Deduction,and Context.
CSLI, Stanford.Kamp, Hans.
1981.
A theory of truth andsemantic interpretation.
I  J.
A. G.Groenendijk, T. M. V. Janssen, and M. B. J.Stokhof, editors, Formal Methods in the446Marcu Rhetorical Parsing of Unrestricted TextsStudy of Language, Mathematical CentreTracts 135.
Mathematisch Centrum,Amsterdam, pages 277-322.Kamp, Hans and Uwe Reyle.
1993.
FromDiscourse to Logic: Introduction toModelTheoretic Semantics of NaturalLanguage, Formal Logic and DiscourseRepresentation Theory.
Kluwer AcademicPublishers, London, Boston, Dordrecht.Studies in Linguistics and Philosophy,Volume 42.Kintsch, Walter.
1977.
On comprehendingstories.
In Marcel Just and PatriciaCarpenter, editors, Cognitive Processes inComprehension.
Lawrence ErlbaumAssociates, Hillsdale, NJ.Knott, Alistair.
1995.
A Data-DrivenMethodology for Motivating aSet of CoherenceRelations.
Ph.D. thesis, University ofEdinburgh.Kurohashi, Sadao and Makoto Nagao.
1994.Automatic detection of discoursestructure by checking surface informationin sentences.
In Proceedings ofthe 15thInternational Conference on ComputationalLinguistics (COLING-94), volume 2, pages1,123-1,127, Kyoto, Japan, August.Lascarides, Alex and Nicholas Ashen 1993.Temporal interpretation, discourserelations, and common sense entailment.Linguistics and Philosophy, 16(5):437-493.Litman, Diane J.
1996.
Cue phraseclassification using machine learning.Journal of Artificial Intelligence Research,5:53-94.Mann, William C. and Sandra A.Thompson.
1988.
Rhetorical structuretheory: Toward a functional theory of textorganization.
Text, 8(3):243-281.Marcu, Daniel.
1996.
Building up rhetoricalstructure trees.
In Proceedings oftheThirteenth National Conference on ArtificialIntelligence (AAAI-96), volume 2, pages1,069-1,074, Portland, OR, August.Marcu, Daniel.
1997a.
The rhetorical parsingof natural anguage texts.
In Proceedings ofthe 35th Annual Meeting of the Association forComputational Linguistics (ACL-97), pages96--103, Madrid, Spain, July.Marcu, Daniel.
1997b.
The Rhetorical Parsing,Summarization, and Generation of NaturalLanguage Texts.
Ph.D. thesis, Departmentof Computer Science, University ofToronto, December.Marcu, Daniel.
1999a.
A decision-basedapproach to rhetorical parsing.
InProceedings ofthe 37th Annual Meeting,pages 365-372, University of Maryland,June.
Association for ComputationalLinguistics.Marcu, Daniel.
1999b.
Discourse trees aregood indicators of importance in text.
InInderjeet Mani and Mark Maybury,editors, Advances in Automatic TextSummarization.
MIT Press, Cambridge,MA, pages 123-136.Marcu, Daniel.
2000.
The Theory and Practiceof Discourse Parsing and Summarization.MIT Press, Cambridge, MA.
To appear.Marcu, Daniel, Lynn Carlson, and MakiWatanabe.
2000.
The automatic translationof discourse structures.
In Proceedings ofthe Language Technology Joint ConferenceANLP-NAACL2000, Seattle, WA.Martin, James R. 1992.
English Text.
Systemand Structure.
John Benjamin PublishingCompany, Philadelphia, Amsterdam.Morris, Jane and Graeme Hirst.
1991.Lexical cohesion computed by thesauralrelations as an indicator of the structure oftext.
Computational Linguistics, 17(1):21-48.Moser, Megan and Johanna D. Moore.
1997.On the correlation of cues with discoursestructure: Results from a corpus study.Forthcoming.Nunberg, G. 1990.
The Linguistics ofPunctuation.
CSLI Lecture Notes 18,Stanford.
University of Chicago Press.Palmer, David D. and Marti A. Hearst.
1997.Adaptive multilingual sentence boundarydisambiguation.
Computational Linguistics,23(2):241-269.Pascual, Elsa and Jacques Virbel.
1996.Semantic and layout properties of textpunctuation.
In Proceedings oftheAssociation for Computational LinguisticsWorkshop on Punctuation, pages 41-48,Santa Cruz, CA, June.Polanyi, Livia.
1988.
A formal model of thestructure of discourse.
Journal ofPragmatics, 12:601-638.Polanyi, Livia.
1996.
The linguistic structureof discourse.
Technical ReportCSLI-96-200, Center for the Study ofLanguage and Information.Polanyi, Livia and Martin H. van den Berg.1996.
Discourse structure and discourseinterpretation.
In P. Dekker andM.
Stokhof, editors, Proceedings ofthe TenthAmsterdam Colloquium, pages 113-131.Department of Philosophy, University ofAmsterdam.Redeker, Gisela.
1990.
Ideational andpragmatic markers of discourse structure.Journal of Pragmatics, 14:367-381.Salton, Gerard and James Allan.
1995.Selective text utilization and texttraversal.
International Journal ofHuman-Computer Studies, 43:483-497.Salton, Gerard, Amit Singhal, Chris Buckley,and Mandar Mitra.
1995.
Automatic textdecomposition using text segments and447Computational Linguistics Volume 26, Number 3text themes.
Technical Report TR-95-1555,Department of Computer Science, CornellUniversity.Say, Bilge and Varol Akman.
1996.Information-based aspects of punctuation.In Proceedings ofthe Association forComputational Linguistics Workshop onPunctuation, pages 49-56, Santa Cruz, CA,June.Schiffrin, Deborah.
1987.
Discourse Markers.Cambridge University Press.Schilder, Frank.
1997.
Tree discoursegrammar, or how to get attached adiscourse.
In Proceedings ofthe SecondInternational Workshop on ComputationalSemantics (IWCS-II), pages 261-273,Tilburg, The Netherlands, January.Schneuwly, Bernard.
1997.
Textualorganizers and text types: Ontogeneticaspects in writing.
In Jean Costermansand Michel Fayol, editors, ProcessingInterclausal Relationships.
Studies in theProduction and Comprehension f Text.Lawrence Erlbaum Associates, Hillsdale,NJ, pages 245-263.Segal, Erwin M. and Judith F. Duchan.
1997.Interclausal connectives as indicators ofstructuring in narrative.
In JeanCostermans and Michel Fayol, editors,Processing Interclausal Relationships.
Studiesin the Production and Comprehension f Text.Lawrence Erlbaum Associates, Hillsdale,NJ, pages 95-119.Segal, Erwin M., Judith F. Duchan, andPaula J. Scott.
1991.
The role ofinterclausal connectives in narrativestructuring: Evidence from adults'interpretations of simple stories.
DiscourseProcesses, 14:27-54.Shiuan, Peh Li and Christopher Ting HianAnn.
1996.
A divide-and-conquer st ategyfor parsing.
In Proceedings ofthe Associationfor Computational Linguistics Workshop onPunctuation, pages 57-66, Santa Cruz, CA,June.Siegel, Eric V. and Kathleen R. McKeown.1994.
Emergent linguistic rules frominducing decision trees: Disambiguatingdiscourse clue words.
In Proceedings oftheTwelfth National Conference on ArtificialIntelligence (AAAI-94), volume 1, pages820-826, Seattle, WA.Strube, Michael and Udo Hahn.
1999.Functional centering---Groundingreferential coherence in informationstructure.
Computational Linguistics,25(3):309-344.Sumita, K., K. Ono, T. Chino, T. Ukita, andS.
Amano.
1992.
A discourse structureanalyzer for Japanese text.
In Proceedingsof the International Conference on FifthGeneration Computer Systems, volume 2,pages 1,133-1,140.van den Berg, Martin H. 1996.
Discoursegrammar and dynamic logic.
In P. Dekkerand M. Stokhof, editors, Proceedings oftheTenth Amsterdam Colloquium, pages 93-112.Department of Philosophy, University ofAmsterdam.van Dijk, Teun A.
1972.
Some Aspects of TextGrammars; A Study in Theoretical Linguisticsand Poetics.
Mouton, The Hague.Webber, Bonnie, Alistair Knott, MatthewStone, and Aravind Joshi.
1999.
Discourserelations: A structural andpresuppositional account usinglexicalized TAG.
In Proceedings ofthe 37thAnnual Meeting, pages 41-48, Universityof Maryland, June.
Association forComputational Linguistics.Wiebe, Janice M. 1994.
Tracking point ofview in narrative.
ComputationalLinguistics, 20(2):233-288.Youmans, Gilbert.
1991.
A new tool fordiscourse analysis: Thevocabulary-management profile.Language, 67(4):763-789.Zock, Michael.
1985.
Le fil d'ariane ou lesgrammaires de texte comme guide dansl'organisation etl'expression de la pens~een langue maternelle t/ou 6trang6re.Technical Report, Rapport pour l'Unesco,Juin.448
