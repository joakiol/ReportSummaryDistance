CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 127?134Manchester, August 2008A Nearest-Neighbor Approach to theAutomatic Analysis of Ancient Greek MorphologyJohn LeeSpoken Language SystemsMIT Computer Science and Artificial Intelligence LaboratoryCambridge, MA 02139, USAjsylee@csail.mit.eduAbstractWe propose a data-driven method for au-tomatically analyzing the morphology ofancient Greek.
This method improves onexisting ancient Greek analyzers in twoways.
First, through the use of a nearest-neighbor machine learning framework, theanalyzer requires no hand-crafted rules.Second, it is able to predict novel roots,and to rerank its predictions by exploiting alarge, unlabelled corpus of ancient Greek.1 IntroductionThe civilization of ancient Greece, from which theWestern world has received much of its heritage,has justly received a significant amount of schol-arly attention.
To gain a deeper understanding ofthe civilization, access to the essays, poems, andother Greek documents in the original language isindispensable.Ancient Greek is a highly inflected Indo-European language1.
A verb, for example, is in-flected according to its person, number, voice,tense/aspect and mood.
According to (Crane,1991), ?a single verb could have roughly 1,000forms, and, if we consider that any verb may bepreceded by up to three distinct prefixes, the num-ber of forms explodes to roughly 5,000,000.?
Theinflections are realized by prefixes and suffixes toc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.1All Greek words are transcribed into the Roman alpha-bet in this paper.
The acute, grave and circumflex accentsare represented by diacritics, as in o?, o` and o?, respectively.Smooth breathing marks are omitted; rough breathing marksare signalled by h. Underbars used in e and o represent etaand omega.the stem, and sometimes spelling changes withinthe stem.
These numerous forms can be furthercomplicated by accents, and by additional spellingchanges at morpheme boundaries for phonologicalreasons.
The overall effect can yield an inflectedform in which the root2 is barely recognizable.Indeed, a staple exercise for students of ancientGreek is to identify the root form of an inflectedverb.
This skill is essential; without knowing theroot form, one cannot understand the meaning ofthe word, or even look it up in a dictionary.For Classics scholars, these myriad forms alsopose formidable challenges.
In order to search foroccurrences of a word in a corpus, all of its formsmust be enumerated, since words do not frequentlyappear in their root forms.
This procedure be-comes extremely labor-intensive for small wordsthat overlap with other common words (Crane,1991).Automatic morphological analysis of ancientGreek would be useful for both educational andresearch purposes.
In fact, one of the first analyz-ers was developed as a pedagogical tool (Packard,1973).
Today, a widely used analyzer is embed-ded in the Perseus Digital Library (Crane, 1996),an internet resource utilized by both students andresearchers.This paper presents an analyzer of ancient Greekthat infers the root form of a word.
It intro-duces two innovations.
First, it utilizes a nearest-neighbor framework that requires no hand-craftedrules, and provides analogies to facilitate learning.2The root is also called the ?base?
or ?lexical look-up?form, since it is the form conventionally used in dictionary en-tries.
For verbs in ancient Greek, the root form is the first per-son singular present active indicative form.
(cf.
for English,it is the infinitive.)
For nouns, it is the nominative singularform.
For adjectives, it is the nominative singular masculineform.127Person/Num Form Person/Num Form1st/singular lu?o 1st/plural lu?omen2nd/singular lu?eis 2nd/plural lu?ete3rd/singular lu?ei 3rd/plural lu?ousi(n)Table 1: Paradigm table for the present active in-dicative verb.
It uses as example the verb lu?o (?toloosen?
), showing its inflections according to per-son and number.Second, and perhaps more significantly, it exploitsa large, unlabelled corpus to improve the predic-tion of novel roots.The rest of the paper is organized as follows.
Wefirst motivate these innovations (?2) and summa-rize previous research in morphological analysis(?3).
We then describe the data (?4) and our adap-tations to the nearest-neighbor framework (?5-6),followed by evaluation results (?7).2 Innovations2.1 Use of Analogy and Nearest NeighborTypically, a student of ancient Greek is expectedto memorize a series of ?paradigms?, such as theone shown in Table 1, which can fill several pagesin a grammar book.
Although the paradigm tableshows the inflection of only one particular verb,lu?o (?to loosen?
), the student needs to apply thepatterns to other verbs.
In practice, rather than ab-stracting the patterns, many students simply mem-orize these ?paradigmatic?
verbs, to be used asanalogies for identifying the root form of an un-seen verb.
Suppose the unseen verb is phe?reis(?you carry?
); the reasoning would then be, ?Iknow that lu?eis is the second person singular formof the root lu?o; similarly, phe?reis must be the sec-ond person singular form of phe?ro.
?The use of analogy can be especially usefulwhen dealing with a large number of rules, forexample with the so-called ?contract verbs?.
Thestem of a contract verb ends in a vowel; when avowel-initial suffix is attached to the stem, spellingchanges occur.
For instance, the stem plero- (?tofill?)
combined with the suffix -omen becomespler-ou?-men, due to interaction between two omi-crons at the boundary.
While it is possible to derivethese changes from first principles, or memorizethe rules for all vowel permutations (e.g., ?o?
+ ?o?= ?ou??
), it might be easier to recall the spellingchanges seen in a familiar verb (e.g., plero?o ?plerou?men), and then use analogy to infer the rootof an unseen verb.The nearest-neighbor machine learning frame-work is utilized to provide these analogies.
Givena word in an inflected form (e.g., phe?reis), the algo-rithm searches for the root form (phe?ro) among its?neighbors?, by making substitutions to its prefixand suffix.
Valid substitutions are to be harvestedfrom pairs of inflected and root forms (e.g., ?lu?eis,lu?o?)
in the training set; these pairs, then, can serveas analogies to reinforce learning.Furthermore, these affix substitutions can belearned automatically, reducing the amount of en-gineering efforts.
They also increase the trans-parency of the analyzer, showing explicitly how itderives the root.2.2 Novel RootsAncient Greek, in its many dialects, has beenused from the time of Homer to the MiddleAges, in texts of a wide range of genres.
Eventhe most comprehensive dictionaries do not com-pletely cover its extensive vocabulary.
To the bestof our knowledge, all existing analyzers for ancientGreek require a pre-defined database of stems;thus, they are likely to run into words with un-known or novel roots, which they are not designedto analyze.Rather than expanding an existing database toincrease coverage, we create a mechanism to han-dle all novel roots.
Since words do not often appearin their root forms, inferring a novel root from asurface form is no easy task (Linde?n, 2008).
Wepropose the use of unlabelled data to guide the de-termination of a novel root.3 Previous WorkAfter a brief discussion on morphological analysisin general, we will review existing analyzers forancient Greek in particular.3.1 Morphological AnalysisA fundamental task in morphological analysis isthe segmentation of a word into morphemes, thatis, the smallest meaningful units in the word.
Un-supervised methods have been shown to performwell in this task.
In the recent PASCAL challenge,the best results were achieved by (Keshava andPitler, 2006).
Their algorithm discovers affixesby considering words that appear as substrings ofother words, and by estimating probabilities formorpheme boundaries.
Another successful ap-128proach is the use of Minimum Description Length,which iteratively shortens the length of the mor-phological grammar (Goldsmith, 2001).Spelling changes at morpheme boundaries (e.g.,deny but deni-al) can be captured by orthographicrules such as ?change y- to i- when the suffix is-al?.
Such rules are specified manually in the two-level model of morphology (Koskenniemi, 1983),but they can also be induced (Dasgupta, 2007).
Al-lomorphs (e.g., ?deni?
and ?deny?)
are also auto-matically identified in (Dasgupta, 2007), but thegeneral problem of recognizing highly irregularforms is examined more extensively in (Yarowskyand Wicentowski, 2000).
They attempt to align ev-ery verb to its root form, by exploiting a combina-tion of frequency similarity, context similarity, editdistance and morphological transformation proba-bilities, all estimated from an unannotated corpus.An accuracy of 80.4% was achieved for highly ir-regular words in the test set.3.2 Challenges for Ancient GreekAncient Greek presents a few difficulties that pre-vent a naive application of the minimally super-vised approach in (Yarowsky and Wicentowski,2000).
First, frequency and context analyses aresensitive to data sparseness, which is more pro-nounced in heavily inflected languages, such asGreek, than in English.
Many inflected forms donot appear more than a few times.
Second, manyroot forms do not appear3 in the corpus.
In Finnishand Swahili, also highly inflected languages, only40 to 50% of words appear in root forms (Linde?n,2008).
The same may be expected of ancientGreek.Indeed, for these languages, predicting novelroots is a challenging problem.
This task hasbeen tackled in (Adler et al, 2008) for modernHebrew, and in (Linde?n, 2008) for Finnish.
Inthe former, features such as letter n-grams andword-formation patterns are used to predict themorphology of Hebrew words unknown to an ex-isting analyzer.
In the latter, a probabilistic ap-proach is used for harvesting prefixes and suf-fixes in Finnish words, favoring the longer ones.However, no strategy was proposed for irregularspelling in stems.3The root forms of contract verbs, e.g.
plero?o, are not eveninflected forms.Surface Morphological RootForm Annotation Formka?` (and) Conjunction ka?
?pneu?ma (spirit) Noun 3rd decl pneu?matheou?
(God) Noun 2nd decl theo?sepephe?reto (hover) Verb phe?roTable 2: Sample data from parts of Genesis 1:2(?and the Spirit of God was hovering over ...?).
Theoriginal annotation is more extensive, and only theportion utilized in this research is shown here.3.3 Ancient Greek Morphological AnalysisThe two most well-known analyzers for ancientGreek are both rule-based systems, requiring a pri-ori knowledge of the possible stems and affixes,which are manually compiled.
To give a roughidea, some 40,000 stems and 13,000 inflections areknown by the MORPHEUS system, which will bedescribed below.The algorithm in MORPH (Packard, 1973)searches for possible endings that would result ina stem in its database.
If unsuccessful, it then at-tempts to remove prepositions and prefixes fromthe beginning of the word.
Accents, essential fordisambiguation in some cases, are ignored.
Theanalyzer was applied on Plato?s Apology to studythe distribution of word endings, for the purposeof optimizing the order of grammar topics to becovered in an introductory course.
Evaluation ofthe analyzer stressed this pedagogical perspective,and the accuracy of the analyses is not reported.MORPHEUS (Crane, 1991) augments MORPHwith a generation component which, given a stem,enumerates all possible inflections in different di-alects, including accents.
When accents are con-sidered during analysis, the precision of the ana-lyzer improves by a quarter.
However, the actualprecision and the test set are not specified.In this paper, we have opted for a data-driven ap-proach, to automatically determine the stems andaffixes from training data.4 Data4.1 Morphology DataWe used the Septuagint corpus4 prepared by theCenter for Computer Analysis of Texts at the Uni-versity of Pennsylvania.
The Septuagint, dat-ing from the third to first centuries BCE, is a4http://ccat.sas.upenn.edu/gopher/text/religion/biblical/129Part-of-speech PercentVerbs 68.6%Adjectives 10.4%Nouns (1st declension) 5.6%Nouns (2nd declension masculine) 4.3%Nouns (2nd declension neuter) 2.8%Nouns (3rd declension) 7.6%other 0.7%Table 3: Statistics on the parts-of-speech of thewords in the test set, considering only uniquewords.Greek translation of the Hebrew Bible.
The corpusis morphologically analyzed, and Table 2 showssome sample data.The corpus is split into training and test sets.The training set is made up of the whole Septu-agint except the first five books.
It consists of about470K words, with 37,842 unique words.
The firstfive books, also known as the Torah or Pentateuch,constitute the test set.
It contains about 120Kwords, of which there are 3,437 unique words notseen in the training set, and 7,381 unique wordsseen in training set.
A breakdown of the parts-of-speech of the test set is provided in Table 3.
Propernouns, many of which do not decline, are excludedfrom our evaluation.4.2 Unlabelled DataTo guide the prediction of novel roots, we utilizethe Thesaurus Linguae Graecae (Berkowitz andSquitter, 1986) corpus.
The corpus contains morethan one million unique words, drawn from a widevariety of ancient Greek texts.4.3 EvaluationMany common words in the test set are also seenin the training set.
Rather than artificially boostingthe accuracy rate, we will evaluate performance onunique words rather than all words individually.Some surface forms have more than one possi-ble root form.
For example, the word puro?n maybe inflected from the noun pura?
(?altar?
), or puro?s(?wheat?
), or pu?r (?fire?).
It would be necessary toexamine the context to select the appropriate noun,but morphological disambiguation (Hakkani-Tu?ret al, 2002) is beyond the scope of this paper.
Inthese cases, legitimate root forms proposed by ouranalyzer may be rejected, but we pay this price inreturn for an automatic evaluation procedure.5 Nearest-Neighbor ApproachThe memory-based machine learning frameworkperforms well on a benchmark of language learn-ing tasks (Daelemans, 1999), including morpho-logical segmentation of Dutch (van den Bosch,1999).
In this framework, feature vectors areextracted from the training set and stored in adatabase of instances, called the instance base.
Adistance metric is then defined.
For each test in-stance, its set of nearest neighbors is retrieved fromthe instance base, and the majority label of the setis returned.We now adapt this framework to our task, firstdefining the distance metric (current section), thendescribing the search algorithm for nearest neigh-bors (?6).5.1 Distance MetricEvery word consists of a stem, a (possibly empty)prefix and a (possibly empty) suffix.
If two wordsshare a common stem, one can be transformed tothe other by substituting its prefix and suffix withtheir counterparts in the other word.
We will callthese substitutions the prefix transformation andthe suffix transformation.The ?distance?
between two words is to be de-fined in terms of these transformations.
It wouldbe desirable for words that are inflected from thesame root to be near neighbors.
A distance met-ric can achieve this effect by favoring prefix andsuffix transformations that are frequently observedamong words inflected from the same root.
Wethus provisionally define ?distance?
as the sum ofthe frequency counts of the prefix and suffix trans-formations required to turn one word to the other.5.2 Stems and AffixesDefining ?Stem?
To count the frequencies of pre-fix and suffix transformations, the stem of eachword in the training set must be determined.
Ide-ally, all words inflected from the same root shouldshare the same stem.
Unfortunately, for ancientGreek, it is difficult to insist upon such a commonstem.
In some cases, the stems are completely dif-ferent5; in others, the common stem is obfuscated5Each verb can have up to six different stems, known asthe ?principal parts?.
In extreme cases, a stem may appearcompletely unrelated to the root on the surface.
For example,o?
?so and e?negkon are both stems of the root phe?ro (?to carry?
).A comparable example in English is the inflected verb formwent and its root form go.130Word Prefix Stem Suffix Prefix SuffixTransformation Transformation(root) lu?o - lu?
o (root,1) ?
?
e o?
eto(1) elu?eto e lu?
eto (root,2) ?
?
para o?
sai(2) paralu?sai para lu?
sai (root,3) ?
?
ek o?
the?sontai(3) ekluthe?sontai ek lu the?sontai (1,2) e?
para eto?
sai(1,3) e?
ek eto?
the?sontai(2,3) para?
ek sai?
the?sontaiTable 4: The verb root lu?o (?to loosen?)
and three of its inflected forms are shown.
Each inflected formis compared with the root form, as well as the other inflected forms.
The ?stem?, defined as the longestcommon substring, is determined for each pair.
The prefix and suffix transformations are then extracted.?
represents the empty string.in surface forms due to spelling changes6.We resort to a functional definition of ?stem?
?the longest common substring of a pair of words.Some examples are shown in Table 4.Refinements to Definition Three more refine-ments to the definition of ?stem?
have been foundto be helpful.
First, accents are ignored when de-termining the longest common substring.
Accentson stems often change in the process of inflection.These changes are illustrated in Table 4 by the stemlu, whose letter u has an acute accent, a circumflexaccent, and no accent in the three inflected forms.Second, a minimum length is required for thestem.
On the one hand, some pairs, such as a?go(?to lead?)
and a?xo, do have a stem of length one(?a?).
On the other hand, allowing very shortstems can hurt performance, since many spuriousstems may be misconstrued, such as ?e?
betweenphe?ro and e?negkon.
The minimum stem length isempirically set at two for this paper.Length alone cannot filter out all spurious stems.For example, for the pair pate?o (?to walk?)
and aninflected form katepa?tesan, there are two equallylong candidate stems, *ate and pat.
The latteryields affixes such as ?-e?o?
and ?-esan?, which arerelatively frequent7.
On this basis, the latter stemis chosen.Some further ways to reduce the noise are torequire an affix transformation to occur at leasta minimum number of times in the training set,and to restrict the phonological context in which6For example, the stem oz in the root form o?zo (?to smell?
)is changed to os in exo?sthesan, an aorist passive form.7The frequency of each affix is counted in a preliminaryround, with each affix receiving a half count in cases of tiedstem length.the transformation can be applied8.
While signifi-cantly reducing recall, these additional restrictionsyield only a limited boost in precision.6 AlgorithmIn the training step, a set of prefix and suffix trans-formations, along with their counts, is compiledfor each part-of-speech.
These counts enable us tocompute the distance between any two words, andhence determine the ?nearest neighbor?
of a word.At testing, given an inflected form, its neighboris any word to which it can be transformed usingthe affix transformations.
We first try to find itsnearest neighbor in the training set (?6.1); if noneighbor is found, a novel root is predicted (?6.2).6.1 Finding Known RootsIf the input word itself appears in the training set,we simply look up its morphological analysis.If the input word is not seen in the training set,its root form or another inflected form may still befound.
We try to transform the input word to thenearest such word, i.e., by using the most frequentprefix and suffix transformations, according to thedistance metric (?5.1).Irregular Stem Spelling Typically, if there areno spelling changes in the stem, the input wordcan be transformed directly to the root, e.g., fromphe?reis to phe?ro.
If the spelling of the stem is sub-stantially different, it is likely to be transformedto another inflected form of the root that containsthe same irregular stem.
For example, the wordprosexe?negken bears little resemblance to its rootphe?ro, but it can be mapped to the word e?negken8For example, a certain suffix transformation may be validonly when the stem ends in certain letters.131in the training set, from which we retrieve its rootform phe?ro.Search Order Some affixes are circumfixes; thatis, both the prefix and the suffix must occur to-gether.
For example, the suffix -eto cannot be ap-plied on its own, but must always be used in con-junction with the prefix e-, to form words such aselu?eto, as shown in Table 4.Other affixes, however, can freely mix with oneanother, and not all combinations are attested in thetraining set.
This is particularly common when theprefix contains two or more prepositions.
For ex-ample, the combination dia-kata- occurs only twotimes in the training set, but it can potentially pairwith a large number of different suffixes.Hence, the search for neighbors proceeds in twostages.
In the first stage (denoted CIRCUMFIX), thesearch is restricted to circumfixes, that is, requir-ing that at least one word-pair in the training setcontain both the prefix and suffix transformations.This restriction is prone to data sparseness; if noneighbor is found, the prefix and suffix transfor-mations are then allowed to be applied separatelyin the second stage (denoted PREFIX/SUFFIX).6.2 Proposing Novel RootsA word may be derived from a root of which noinflected form is seen in the training set.
Natu-rally, no neighbor would be found in the previousstep, and a novel root must be proposed.
We ap-ply the prefix and suffix transformations learned in?5.2, using only circumfixes observed between aninflected form and a root form.
For obvious rea-sons, the resulting string is no longer required tobe a neighbor, i.e., a word seen in the training set.Typically, the various transformations producemany candidate roots.
For example, the wordhomometr?
?ou (?born of the same mother?
), a mas-culine genitive adjective, can be transformed to itsroot adjective homome?trios, but it could equallywell be transformed into a hypothetical neuternoun, *homome?trion.
Both are perfectly plausibleroots.The automatically discovered affix transforma-tions inevitably contain some noise.
When dealingwith known roots, much of the noise is suppressedbecause misapplications of these transformationsseldom turn the input word into a real word foundin the training set.
When proposing novel roots,we no longer enjoy this constraint.
Although thedistance metric still helps discriminate againstinvalid candidates, the increased ambiguity leadsto lower accuracy.
We address this issue byexploiting a large, unlabelled corpus.Use of Unlabelled Corpus If a proposed root formis correct, it should be able to generate some in-flected forms attested in a large corpus.
Intuitively,the ?productivity?
of the root form may correlatewith its correctness.To generate inflected forms from a root, we sim-ply take the set of affix transformations observedfrom inflected forms to roots, and reverse the trans-formations.
Continuing with the above example,we generate inflected forms for both candidateroots, the adjective homome?trios, and the hypo-thetical neuter noun *homome?trion.
While a fewinflected forms are generated by both candidates,three are unique to the adjective ?
homome?trios,homome?trioi and homome?trian ?
the nominativemasculine singular and plural, and the accusativefeminine singular, respectively.
None of thesecould have been inflected from a neuter noun.A straightforward notion of ?productivity?
ofa root would be simply the number of inflectedforms attested in the large corpus.
It can be fur-ther refined, however, by considering the preva-lence of the inflected forms.
That is, a form gen-erated with more common affix transformationsshould be given greater weight than one gener-ated with less common ones.
Suppose two candi-date roots, the adjective telespho?ros (?bringing toan end?)
and the hypothetical verb *telesphoro?o,are being considered.
Both can generate the in-flected form telespho?rou, the former as the mascu-line genitive adjective, and the latter as either animperfect indicative or present imperative contractverb.
Since the inflection of the adjective is morefrequent in the training set than that of the rela-tively rare class of contract verbs, the existence oftelespho?rou should lend greater weight to the ad-jective.Hence, the ?productivity?
metric of a novel rootis the number of words in the large corpus that itcan generate with affix transformations, weightedby the frequencies of those transformations.7 ExperimentsSome statistics on the test set are presented in Ta-ble 3.
Of the 7,381 words that are seen in the train-ing set, 98.2% received the correct root form.
The132Transformation Type Proportion AccuracyCIRCUMFIX 77.5% 94.5%PREFIX/SUFFIX 10.8% 61.2%Novel Roots 11.7% 50.0%Overall 100% 85.7%Table 5: After excluding known words, which at-tain an accuracy of 98.2%, the performance onthe remaining 3437 unique words in the test set isshown above.
Please see ?7 for discussions.
Re-sults for novel roots are presented in further detailin Table 6.remaining 1.8% had multiple possible roots; an ex-amination of the context would be needed for dis-ambiguation (see comments in ?4.3).Table 5 presents the accuracy of the predictedroots, after excluding the 7,381 seen words.
Theresult is broken down according to the type oftransformation; for the ?Novel Roots?
type, moredetailed results are presented in Table 6.As discussed in ?6.1, the algorithm firstsearched with CIRCUMFIX.
For 77.5% of thewords, a neighbor was found using this sub-set of affix transformations.
The rest were thenprocessed using the back-up procedure, PRE-FIX/SUFFIX, allowing prefix and suffix transfor-mations culled from different word-pairs.
Thisprocedure found neighbors for 10.8% of the words;novel roots were hypothesized for the remainder.Not surprisingly, known roots were more reli-ably predicted (94.5%) with circumfixes than withseparate prefixes and suffixes (61.2%), but bothcategories still achieved higher accuracy than thechallenging task of proposing novel roots (50.0%).We now take a closer look at the errors for bothknown and novel roots.7.1 Known RootsThere are three main sources of error.
The first isnoise in the affix transformations.
For example, thespurious prefix transformation p?ph was derivedfrom the pair phe?ro and periene?gkasan.
When ap-plied on pasa?to, along with a suffix transformation,it yielded the false root form pha?sko.A second source can be attributed to incorrectaffix boundaries.
For example, ekte?
?nantes wasmisconstrued as having ?e- ?
rather than the prepo-sition ek as prefix.
This prefix is by itself per-fectly viable, but ?e-?
and ?-antes?
cannot occurtogether as a circumfix.
The resulting string hap-Evaluation Method AccuracyBASELINE 45.0%TLG RERANK 50.0%+Ignore accents 55.2%+Oracle POS 65.5%Table 6: Results for predicting novel roots, forthe 402 words for whom no neighbor was found.BASELINE uses the distance metric (?5.1) as be-fore; TLG RERANK exploits the unlabelled The-saurus Linguae Graecae corpus to re-rank the topcandidates (?6.2) proposed by BASELINE.pened to match the root kte?
?no, rather than the trueroot te?
?no.A third source is confusion between parts-of-speech, most commonly noun and verb.
For ex-ample, the nearest neighbor of the genitive nounlupo?n was the verb lupe?sei, yielding the verb rootlupe?o rather than the noun lu?pe.7.2 Novel RootsAs a baseline, the distance metric (?5.1) was usedalone to rank the novel candidate roots.
As seen inTable 6, performance dropped to 45.0%.When the Thesaurus Linguae Graecae corpuswas utilized to rerank the novel candidate rootsproposed by the baseline, an absolute gain9 of 5%was achieved.
A further 5.2% of the mistakeswere due to placing the accent incorrectly, such askteno?trophos rather than ktenotro?phos, mostly onnouns and adjectives.
These mistakes are difficultto rectify, since multiple positions are often possi-ble10.Finally, to measure the extent to which part-of-speech (POS) confusions are responsible, we per-formed an experiment in which the gold-standardPOS of each word was supplied to the analyzer(see ?Oracle POS?
in Table 6).
When derivingnovel roots, only those affix transformations be-longing to the oracle POS were considered.
Withthis constraint, accuracy rose to 65.5%.9The significance level is at p = 0.11, according to Mc-Nemar?s test.
The improvement is not statistically significant,and may be a reflection of the relatively small test set.10The accent in an inflected noun retains its position in theroot, unless that position violates certain phonological rules.In many cases, there is no reliable way to predict the accentposition in the root noun from the position in the inflectedform.1338 ConclusionWe have proposed a nearest-neighbor machinelearning framework for analyzing ancient Greekmorphology.
This framework is data-driven, withautomatic discovery of stems and affixes.
The ana-lyzer is able to predict novel roots.
A significantnovelty is the exploitation of a large, unlabelledcorpus to improve performance.We plan to further improve the derivation ofnovel roots by predicting their parts-of-speechfrom context, and by incorporating distributionalinformation (Yarowsky and Wicentowski, 2000).AcknowledgmentsThe author would like to thank Stephanie Sen-eff, Kalliroi Georgila, Konstantinos Katsiapis andSteven Lulich for their insightful comments.ReferencesMeni Adler, Yoav Goldberg, David Gabay, and MichaelElhadad.
2008.
Unsupervised Lexicon-based Res-olution of Unknown Words for Full MorphologicalAnalysis.
Proc.
ACL.
Columbus, OH.Luci Berkowitz and Karl A. Squitter.
1986.
ThesaurusLinguae Graecae.
Oxford University Press, UK.Antal van den Bosch and Walter Daelemans.
1999.Memory-based Morphological Analysis.
Proc.
ACL.College Park, MD.Gregory Crane.
1991.
Generating and Parsing Clas-sical Greek.
Literary and Linguistic Computing,6(4):243?245.Gregory Crane.
1996.
Perseus 2.0: Interactive Sourcesand Studies on Ancient Greece.
Yale UniversityPress, New Haven, CT.Walter Daelemans, Antal van den Bosch and Jakub Za-vrel.
1999.
Forgetting Exceptions is Harmful inLanguage Learning.
Machine Learning, 34:11?41.Sajib Dasgupta and Vincent Ng.
2007.
High-Performance, Language-Independent MorphologicalSegmentation.
Proc.
HLT-NAACL.
Rochester, NY.John Goldsmith.
2001.
Unsupervised Learning of theMorphology of a Natural Language.
ComputationalLinguistics, 27(2):153?198.Dilek Z. Hakkani-Tu?r, Kemal Oflazer, and Go?khan Tu?r.2002.
Statistical Morphological Disambiguation forAgglutinative Languages.
Computers and the Hu-manities, 36(4):381?410.Samarth Keshava and Emily Pitler.
2006.
A Simpler,Intuitive Approach to Morpheme Induction.
Proc.2nd PASCAL Challenges Workshop.
Venice, Italy.Kimmo Koskenniemi.
1983.
Two-level morphology:a general computation model for word-form recog-nition and production.
Publication No.
11, Depart-ment of General Linguistics, University of Helsinki.Helsinki, Finland.Krister Linde?n.
2008.
A Probabilistic Model forGuessing Base Forms of New Words by Analogy.Proc.
CICLing.
Haifa, Israel.David W. Packard.
1973.
Computer-assisted Morpho-logical Analysis of Ancient Greek.
Proc.
5th Con-ference on Computational Linguistics.
Pisa, Italy.David Yarowsky and Richard Wicentowski.
2000.Minimally Supervised Morphological Analysis byMultimodal Alignment.
Proc.
ACL.
Hong Kong,China.134
