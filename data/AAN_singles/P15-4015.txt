Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 85?90,Beijing, China, July 26-31, 2015.c?2015 ACL and AFNLPLEXenstein: A Framework for Lexical SimplificationGustavo Henrique Paetzold and Lucia SpeciaDepartment of Computer ScienceUniversity of Sheffield, UK{ghpaetzold1,l.specia}@sheffield.ac.ukAbstractLexical Simplification consists in replac-ing complex words in a text with sim-pler alternatives.
We introduce LEXen-stein, the first open source framework forLexical Simplification.
It covers all ma-jor stages of the process and allows foreasy benchmarking of various approaches.We test the tool?s performance and reportcomparisons on different datasets againstthe state of the art approaches.
The re-sults show that combining the novel Sub-stitution Selection and Substitution Rank-ing approaches introduced in LEXensteinis the most effective approach to LexicalSimplification.1 IntroductionThe goal of a Lexical Simplification (LS) ap-proach is to replace complex words and expres-sions in a given text, often a sentence, with sim-pler alternatives of equivalent meaning in context.Although very intuitive, this is a challenging tasksince the substitutions must preserve both the orig-inal meaning and the grammaticality of the sen-tence being simplified.The LS task has been gaining significant atten-tion since the late 1990?s, thanks to the positiveinfluence of the early work presented by (Devlinand Tait, 1998) and (Carroll et al., 1999).
More re-cently, the LS task at SemEval-2012 (Specia et al.,2012) has given LS wider visibility.
Participantshad the opportunity to compare their approachesin the task of ranking candidate substitutions, allof which were already known to fit the context,according to their ?simplicity?.Despite its growth in popularity, the inexistenceof tools to support the process and help researchersto build upon has been hampering progress in thearea.
We were only able to find one tool for LS: aset of scripts designed for the training and testingof ranking models provided by (Jauhar and Spe-cia, 2012)1.
However, they cover only one stepof the process.
In an effort to tackle this issue,we present LEXenstein: a framework for LexicalSimplification development and benchmarking.LEXenstein is an easy-to-use framework thatprovides simplified access to many approachesfor several sub-tasks of the LS pipeline, whichis illustrated in Figure 1.
Its current version in-cludes methods for the three main sub-tasks inthe pipeline: Substitution Generation, SubstitutionSelection and Substitution Ranking.Figure 1: Lexical Simplification PipelineLEXenstein was devised to facilitate per-formance comparisons among various LS ap-proaches, as well as the creation of new strategiesfor LS.
In the following Sections we present LEX-enstein?s components (Section 2) and discuss theresults of several experiments conducted with thetool (Section 3).2 System OverviewLEXenstein is a Python library that provides sev-eral approaches for sub-tasks in LS.
To increaseits flexibility, the library is structured in six mod-ules: Substitution Generation, Substitution Selec-tion, Substitution Ranking, Feature Estimation,Evaluation and Text Adorning.
In the followingSections, we describe them in more detail.1https://github.com/sjauhar/simplex852.1 Substitution GenerationWe define Substitution Generation (SG) as the taskof producing candidate substitutions for complexwords, which is normally done regardless of thecontext of the complex word.
Previous work com-monly addresses this task by querying general do-main thesauri such as WordNet (Fellbaum, 1998),or domain specific ones such as UMLS (Boden-reider, 2004).
Examples of work resorting to thisstrategy are (Devlin and Tait, 1998) and (Carrollet al., 1999).
Recent work focuses on learningsubstitutions from sentence-aligned parallel cor-pora of complex-simple texts (Paetzold and Spe-cia, 2013; Horn et al., 2014).LEXenstein?s SG module offers support for fiveapproaches.
All approaches use LEXenstein?sText Adorning module to create substitutions forall possible inflections of verbs and nouns.
Eachapproach is represented by one of the followingPython classes:KauchakGenerator (Horn et al., 2014) Auto-matically extracts substitutions from parallel cor-pora.
It requires a set of tagged parallel sentencesand the word alignments between them in Pharaohformat (Och and Ney, 2000).
It produces a dictio-nary of complex-to-simple substitutions filtered bythe criteria described in (Horn et al., 2014).BiranGenerator (Biran et al., 2011) Filterssubstitutions based on the Cartesian product be-tween vocabularies of complex and simple words.It requires vocabularies of complex and simplewords, as well as two language models trainedover complex and simple corpora.
It produces adictionary linking words to a set of synonyms andhypernyms filtered by the criteria described in (Bi-ran et al., 2011).YamamotoGenerator (Kajiwara et al., 2013)Extracts substitutions from dictionary definitionsof complex words.
It requires an API key for theMerriam Dictionary2, which can be obtained forfree.
It produces a dictionary linking words in theMerriam Dictionary and WordNet to words withthe same Part-of-Speech (POS) tag in its entries?definitions and examples of usage.MerriamGenerator Extracts a dictionary link-ing words to their synonyms, as listed in the Mer-riam Thesaurus.
It requires an API key.2http://www.dictionaryapi.com/WordnetGenerator Extracts a dictionary link-ing words to their synonyms, as listed in WordNet.2.2 Substitution SelectionSubstitution Selection (SS) is the task of selectingwhich substitutions ?
from a given list ?
can re-place a complex word in a given sentence with-out altering its meaning.
Most work addressesthis task referring to the context of the complexword by employing Word Sense Disambiguation(WSD) approaches (Sedding and Kazakov, 2004;Nunes et al., 2013), or by discarding substitutionswhich do not share the same POS tag of the targetcomplex word (Kajiwara et al., 2013; Paetzold andSpecia, 2013).LEXenstein?s SS module provides access tothree approaches.
All approaches require as inputa dictionary of substitutions generated by a givenapproach and a dataset in the VICTOR format (asin Victor Frankenstein (Shelley, 2007)).
As out-put, they produce a set of selected substitutions foreach entry in the VICTOR dataset.
The VICTORformat is structured as illustrated in Example 1,where Siis the ith sentence in the dataset, wiatarget complex word in the hith position of Si, cjia substitution candidate and rjiits simplicity rank-ing.
Each bracketed component is separated by atabulation marker.????S1?
?w1?
?h1??r11:c11??
?
??rn1:cn1?...?Sm?
?wm?
?hm??r1m:c1m??
?
??rnm:cnm????
(1)LEXenstein includes two resources for train-ing/testing in the VICTOR format: the LexMTurk(Horn et al., 2014) and the SemEval corpus (Spe-cia et al., 2012).
Each approach in the SS mod-ule is represented by one of the following Pythonclasses:WSDSelector Allows for the user to use oneamong various classic WSD approaches in SS.
Itrequires the PyWSD (Tan, 2014) module to be in-stalled, which includes the approaches presentedby (Lesk, 1986) and (Wu and Palmer, 1994), aswell as baselines such as random and first senses.BiranSelector (Biran et al., 2011) Employs astrategy in which a word co-occurrence model isused to determine which substitutions have mean-ing similar to that of a target complex word.
Itrequires a plain text file with each line in the for-mat specified in Example 2, where ?wi?
is a word,86?cji?a co-occurring word and?fji?its frequencyof occurrence.?wi??c0i?:?f0i??
?
?
?cni?
:?fni?
(2)Each component in the format in 2 must beseparated by a tabulation marker.
Given such amodel, the approach filters all substitutions whichare estimated to be more complex than the tar-get word, and also those for which the distancebetween their co-occurrence vector and the targetsentence?s vector is higher than a threshold set bythe user.WordVectorSelector Employs a novel strategy,in which a word vector model is used to deter-mine which substitutions have the closest mean-ing to that of the sentence being simplified.
Itrequires a binary word vector model produced byWord2Vec3, and can be configured in many ways.It retrieves a user-defined percentage of the substi-tutions, which are ranked with respect to the co-sine distance between their word vector and thesum of some or all of the sentences?
words, de-pending on the settings defined by the user.2.3 Substitution RankingSubstitution Ranking (SR) is the task of ranking aset of selected substitutions for a target complexword with respect to their simplicity.
Approachesvary from simple word length and frequency-based measures (Devlin and Tait, 1998; Carroll etal., 1998; Carroll et al., 1999; Biran et al., 2011)to more sophisticated linear combinations of scor-ing functions (Jauhar and Specia, 2012), as well asmachine learning-based approaches (Horn et al.,2014).LEXenstein?s SR module provides access tothree approaches.
All approaches receive as in-put datasets in the VICTOR format, which can beeither training/testing datasets already containingonly valid substitutions in context, or datasets gen-erated with (potentially noisy) substitutions by agiven SS approach.
They also require as input aFeatureEstimator object to calculate feature valuesdescribing the candidate substitutes.
More detailson the FeatureEstimator class are provided in Sec-tion 2.4.
Each approach in the SR module is rep-resented by one of the following Python classes:3https://code.google.com/p/word2vec/MetricRanker Employs a simple ranking strat-egy based on the values of a single feature pro-vided by the user.
By configuring the input Fea-tureEstimator object, the user can calculate valuesof several features for the candidates in a givendataset and easily rank the candidates accordingto each of these features.SVMRanker (Joachims, 2002) Use SupportVector Machines in a setup that minimises a lossfunction with respect to a ranking model.
Thisstrategy is the one employed in the LS experimentsof (Horn et al., 2014), yielding promising results.The user needs to provide a path to their SVM-Rank installation, as well as SVM-related configu-rations, such as the kernel type and parameter val-ues for C, epsilon, etc.BoundaryRanker Employs a novel strategy, inwhich ranking is framed as a binary classificationtask.
During training, this approach assigns the la-bel 1 to all candidates of rank 1 ?
r ?
p, wherep is a range set by the user, and 0 to the remain-ing candidates.
It then trains a stochastic descentlinear classifier based on the features specified inthe FeatureEstimator object.
During testing, can-didate substitutions are ranked based on how farfrom 0 they are.
This ranker allows the user toprovide several parameters during training, suchas loss function and penalty type.2.4 Feature EstimationLEXenstein?s Feature Estimation module allowsthe calculation of several features for LS-relatedtasks.
Its class FeatureEstimator allows the userto select and configure many features commonlyused by LS approaches.The FeatureEstimator object can be used eitherfor the creation of LEXenstein?s rankers, or instand-alone setups.
For the latter, the class pro-vides a function called calculateFeatures, whichproduces a matrix MxN containing M featurevalues for each of the N substitution candidateslisted in the dataset.
Each of the 11 features sup-ported must be configured individually.
They canbe grouped in four categories:Lexicon-oriented: Binary features which re-ceive value 1 if a candidate appears in a given vo-cabulary, and 0 otherwise.Morphological: Features that exploit morpho-logical characteristics of substitutions, such asword length and number of syllables.87Collocational: N-gram probabilities of the formP(Sh?lh?1c Sh+rh+1), where c is a candidate substi-tution in the hth position in sentence S, and Sh?lh?1and Sh+rh+1are n-grams of size l and r, respectively.Sense-oriented: Several features which are re-lated to the meaning of a candidate substitutionsuch as number of senses, lemmas, synonyms, hy-pernyms, hyponyms and maximum and minimumdistances among all of its senses.2.5 EvaluationSince one of the goals of LEXenstein is to facili-tate the benchmarking LS approaches, it is crucialthat it provides evaluation methods.
This moduleincludes functions for the evaluation of all sub-tasks, both individually and in combination.
Itcontains four Python classes:GeneratorEvaluator: Provides evaluation met-rics for SG methods.
It requires a gold-standardin the VICTOR format and a set of generated sub-stitutions.
It returns the Potential, Precision andF-measure, where Potential is the proportion of in-stances for which at least one of the substitutionsgenerated is present in the gold-standard, Preci-sion the proportion of generated instances whichare present in the gold-standard, and F-measuretheir harmonic mean.SelectorEvaluator: Provides evaluation metricsfor SS methods.
It requires a gold-standard inthe VICTOR format and a set of selected substi-tutions.
It returns the Potential, Precision and F-measure of the SS approach, as defined above.RankerEvaluator: Provides evaluation metricsfor SR methods.
It requires a gold-standard in theVICTOR format and a set of ranked substitutions.It returns the TRank-at-1:3 and Recall-at-1:3 met-rics (Specia et al., 2012), where Trank-at-i is theproportion of instances for which a candidate ofgold-rank r ?
i was ranked first, and Recall-at-ithe proportion of candidates of gold-rank r ?
ithat are ranked in positions p ?
i.PipelineEvaluator: Provides evaluation metricsfor the entire LS pipeline.
It requires as inputa gold-standard in the VICTOR format and a setof ranked substitutions which have been gener-ated and selected by a given set of approaches.
Itreturns the approaches?
Precision, Accuracy andChange Proportion, where Precision is the pro-portion of instances for which the highest rankingsubstitution is not the target complex word itselfand is in the gold-standard, Accuracy is the pro-portion of instances for which the highest rankingsubstitution is in the gold-standard, and ChangeProportion is the proportion of instances for whichthe highest ranking substitution is not the targetcomplex word itself.2.6 Text AdorningThis approach provides a Python interface to theMorph Adorner Toolkit (Paetzold, 2015), a setof Java tools that facilitates the access to MorphAdorner?s functionalities.
The class provides easyaccess to word lemmatisation, word stemming,syllable splitting, noun inflection, verb tensing andverb conjugation.2.7 ResourcesLEXenstein also provides a wide array of re-sources for the user to explore in benchmarkingtasks.
Among them are the aforementioned LexM-turk and SemEval corpora in the VICTOR format,lists of stop and basic words, as well as languagemodels and lexica built over Wikipedia and Sim-ple Wikipedia.3 ExperimentsIn this Section, we discuss the results obtained infour benchmarking experiments.3.1 Substitution GenerationIn this experiment we evaluate all SG approachesin LEXenstein.
For the KauchakGenerator, weuse the corpus provided by (Kauchak, 2013), com-posed of 150, 569 complex-to-simple parallel sen-tences, parsed by the Stanford Parser (Klein andManning, 1965).
From the the same corpus, webuild the required vocabularies and language mod-els for the BiranGenerator.
We used the LexMturkdataset as the gold-standard (Horn et al., 2014),which is composed by 500 sentences, each witha single target complex word and 50 substitutionssuggested by turkers.
The results are presented inTable 1.The results in Table 1 show that the method of(Horn et al., 2014) yields the best F-Measure re-sults, although combining the output of all gener-ation methods yields the highest Potential.
Thisshows that using parallel corpora to generate sub-stitution candidates for complex words can be a88Approach Pot.
Prec.
FKauchak 0.830 0.155 0.262Wordnet 0.608 0.109 0.184Biran 0.630 0.102 0.175Merriam 0.540 0.067 0.120Yamamoto 0.504 0.054 0.098All 0.976 0.066 0.124Table 1: SG benchmarking resultsmore efficient strategy than querying dictionariesand databases.
We must, however, keep in mindthat the sentences that compose the LexMturk cor-pus were extracted from Wikipedia, which is thesame corpus from which the KauchakGeneratorlearns substitutions.3.2 Substitution SelectionHere we evaluate of all SS approaches in LEX-enstein.
For the BiranSelector, we trained a co-occurrence model over a corpus of 6+ billionwords extracted from the various sources sug-gested in the Word2Vec documentation4, the samesources over which the word vector model re-quired by the WordVectorSelector was trained.
Inorder to summarise the results, we present thescores obtained only with the best performing con-figurations of each approach.
The LexMturk cor-pus is used as the gold-standard, and the initial setof substitutions is the one produced by all SG ap-proaches combined.
The results are presented inTable 2.Approach Pot.
Prec.
F SizeWord Vec.
0.768 0.219 0.341 3, 042Biran 0.508 0.078 0.136 9, 680First 0.176 0.045 0.072 2, 471Lesk 0.246 0.041 0.070 4, 716Random 0.082 0.023 0.035 2, 046Wu-Pa 0.038 0.013 0.020 1, 749No Sel.
0.976 0.066 0.124 26, 516Table 2: SS benchmarking results?Size?
in Table 2 represents the total number ofsubstitutions selected for all test instances.
Theresults in Table 2 show that our novel word vectorapproach outperforms all others in F-Measure by aconsiderable margin, including the method of notperforming selection at all.
Note that not perform-ing selection allows for Potential to be higher, but4https://code.google.com/p/word2vec/yields very poor Precision.3.3 Substitution RankingIn Table 3 we present the results of the evaluationof several SR approaches.
We trained the SVM-Ranker with features similar to the ones used in(Horn et al., 2014), and the BoundaryRanker witha set of 10 features selected through univariatefeature selection.
We compare these approachesto three baseline Metric Rankers, which use theword?s frequency in Simple Wikipedia, its lengthor its number of senses.
The SemEval corpus isused as the gold-standard so that we can compareour results with the best one obtained at SemEval-2012 (Jauhar and Specia, 2012) (SemEval, in Ta-ble 3).Approach TR-1 Rec-1 Rec-2 Rec-3Boundary 0.655 0.608 0.602 0.663SVM 0.486 0.451 0.502 0.592Freq.
0.226 0.220 0.236 0.300Length 0.180 0.175 0.200 0.261Senses 0.130 0.126 0.161 0.223SemEval 0.602 0.575 0.689 0.769Table 3: SR benchmarking resultsThe novel Boundary ranking approach outper-forms all other approaches in both TRank-at-1and Recall-at-1 by a considerable margin, but itis worse than the best SemEval-2012 approach interms of Recall-at-2 and 3.
This however revealsnot a limitation but a strength of our approach:since the Boundary ranker focuses on placing thebest substitution in the highest rank, it becomesmore effective at doing so as opposed to at pro-ducing a full ranking for all candidates.3.4 Round-Trip EvaluationIn this experiment we evaluate the performance ofdifferent combinations of SS and SR approachesin selecting suitable substitutions for complexwords from the ones produced by all generatorscombined.
Rankers and selectors are configuredin the same way as they were in the experimentsin Sections 3.3 and 3.2.
The gold-standard used isLexMturk, and the performance metric used is thecombination?s Precision: the proportion of timesin which the candidate ranked highest is not thetarget complex word itself and belongs to the gold-standard list.
Results are shown in Table 4.The results show that combining the Word-VectorSelector with the BoundaryRanker yields89No Sel.
Word Vector BiranBoundary 0.342 0.550 0.197SVM 0.108 0.219 0.003Freq.
0.114 0.501 0.096Length 0.120 0.408 0.092Senses 0.214 0.448 0.122Table 4: Round-trip benchmarking resultsthe highest performance in the pipeline evalua-tion.
Interestingly, the SVMRanker, which per-formed very well in the individual evaluation ofSection 3.3, was outperformed by all three base-lines in this experiment.4 Final RemarksWe have presented LEXenstein, a framework forLexical Simplification distributed under the per-missive BSD license.
It provides a wide arrangeof useful resources and tools for the task, suchas feature estimators, text adorners, and variousapproaches for Substitution Generation, Selectionand Ranking.
These include methods from pre-vious work, as well as novel approaches.
LEX-enstein?s modular structure also allows for one toeasily add new approaches to it.We have conducted evaluation experiments in-cluding various LS approaches in the literature.Our results show that the novel approaches intro-duced in this paper outperform those from previ-ous work.
In the future, we intend to incorporate inLEXenstein approaches for Complex Word Iden-tification, as well as more approaches for the re-maining tasks of the usual LS pipeline.The tool can be downloaded from: http://ghpaetzold.github.io/LEXenstein/.ReferencesO.
Biran, S. Brody, and N. Elhadad.
2011.
Putting itSimply: a Context-Aware Approach to Lexical Sim-plification.
The 49th Annual Meeting of the ACL.O.
Bodenreider.
2004.
The unified medical languagesystem (umls): integrating biomedical terminology.Nucleic acids research.J.
Carroll, G. Minnen, Y. Canning, S. Devlin, andJ.
Tait.
1998.
Practical simplification of englishnewspaper text to assist aphasic readers.
In The 15thAAAI.J.
Carroll, G. Minnen, D. Pearce, Y. Canning, S. De-vlin, and J. Tait.
1999.
Simplifying Text for Lan-guage Impaired Readers.
The 9th EACL.S.
Devlin and J. Tait.
1998.
The use of a psy-cholinguistic database in the simplification of textfor aphasic readers.
Linguistic Databases.C.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
Bradford Books.C.
Horn, C. Manduca, and D. Kauchak.
2014.
Learn-ing a Lexical Simplifier Using Wikipedia.
The 52ndAnnual Meeting of the ACL.S.K.
Jauhar and L. Specia.
2012.
UOW-SHEF:SimpLex?lexical simplicity ranking based on con-textual and psycholinguistic features.
The 1st *SEM.T.
Joachims.
2002.
Optimizing search engines usingclickthrough data.
In The 8th ACM.T.
Kajiwara, H. Matsumoto, and K. Yamamoto.
2013.Selecting Proper Lexical Paraphrase for Children.D.
Kauchak.
2013.
Improving Text SimplificationLanguage Modeling Using Unsimplified Text Data.The 51st Annual Meeting of the ACL.D.
Klein and C.D.
Manning.
1965.
Accurate Unlexi-calized Parsing.
In The 41st Annual Meeting of ACL.M.
Lesk.
1986.
Automatic sense disambiguation us-ing machine readable dictionaries: how to tell a pinecone from an ice cream cone.
In The 5th SIGDOC.B.P.
Nunes, R. Kawase, P. Siehndel, M.A.
Casanova,and S. Dietze.
2013.
As Simple as It Gets - A Sen-tence Simplifier for Different Learning Levels andContexts.
IEEE 13th ICALT.F.J.
Och and H. Ney.
2000.
Improved statistical align-ment models.
In The 38th Annual Meeting of theACL.G.H.
Paetzold and L. Specia.
2013.
Text simplificationas tree transduction.
In The 9th STIL.G.H.
Paetzold.
2015.
Morph adornertoolkit: Morph adorner made simple.http://ghpaetzold.github.io/MorphAdornerToolkit/.J.
Sedding and D. Kazakov.
2004.
Wordnet-based textdocument clustering.
In The 3rd ROMAND.M.
Shelley.
2007.
Frankenstein.
Pearson Education.L.
Specia, S.K.
Jauhar, and R. Mihalcea.
2012.Semeval-2012 task 1: English lexical simplification.In The 1st *SEM.L.
Tan.
2014.
Pywsd: Python implementa-tions of word sense disambiguation technologies.https://github.com/alvations/pywsd.Z.
Wu and M. Palmer.
1994.
Verbs semantics and lex-ical selection.
In The 32nd Annual Meeting of ACL.90
