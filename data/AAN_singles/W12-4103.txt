Proceedings of the TextGraphs-7 Workshop at ACL, pages 15?19,Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational LinguisticsUsing Link Analysis to Discover Interesting Messages Spread Across TwitterMin-Chul Yang?
and Jung-Tae Lee?
and Hae-Chang Rim??Dept.
of Computer & Radio Communications Engineering, Korea University, Seoul, Korea?Research Institute of Computer Information & Communication, Korea University, Seoul, Korea{mcyang,jtlee,rim}@nlp.korea.ac.krAbstractTwitter, a popular social networking service,enables its users to not only send messagesbut re-broadcast or retweet a message from an-other Twitter user to their own followers.
Con-sidering the number of times that a message isretweeted across Twitter is a straightforwardway to estimate how interesting it is.
How-ever, a considerable number of messages inTwitter with high retweet counts are actuallymundane posts by celebrities that are of inter-est to themselves and possibly their followers.In this paper, we leverage retweets as implicitrelationships between Twitter users and mes-sages and address the problem of automati-cally finding messages in Twitter that may beof potential interest to a wide audience by us-ing link analysis methods that look at morethan just the sheer number of retweets.
Exper-imental results on real world data demonstratethat the proposed method can achieve betterperformance than several baseline methods.1 IntroductionTwitter (http://twitter.com) is a popular so-cial networking and microblogging service that en-ables its users to share their status updates, news,observations, and findings in real-time by postingtext-based messages of up to 140 characters, calledtweets.
The service rapidly gained worldwide pop-ularity as a communication tool, with millions ofusers generating millions of tweets per day.
Al-though many of those tweets contain valuable in-formation that is of interest to many people, manyothers are mundane tweets, such as ?Thanks guysfor the birthday wishes!!?
that are of interest only tothe authors and users who subscribed to their tweets,known as followers.
Finding tweets that are of po-tential interest to a wide audience from large volumeof tweets being accumulated in real-time is a crucialbut challenging task.
One straightforward way is torely on the numbers of times each tweet has beenpropagated or retweeted by readers of the tweet.Hong et al (2011) propose to regard retweet countas a measure of popularity and present classifiers forpredicting whether and how often new tweets will beretweeted in the future.
However, mundane tweetsby highly popular users, such as celebrities withhuge numbers of followers, can record high retweetcounts.
Alonso et al (2010) use crowdsourcing tocategorize a set of tweets as ?only interesting to au-thor and friends?
and ?possibly interesting to others?and report that the presence of a URL link is a single,highly effective feature for distinguishing interest-ing tweets with more than 80% accuracy.
This sim-ple rule, however, may incorrectly recognize manyinteresting tweets as not interesting, simply becausethey do not contain links.
Lauw et al (2010) suggestseveral features for identifying interesting tweets butdo not experimentally validate them.In this study, we follow the definition of inter-esting tweets provided by Alonso et al (2010) andfocus on automatic methods for finding tweets thatmay be of potential interest to not only the authorsand their followers but a wider audience.
Sinceretweets are intended to spread tweets to new audi-ences, they are often a recommendation or, accord-ing to Boyd et al (2010), productive communica-tion tool.
Thus, we model Twitter as a graph con-15sisting of user and tweet nodes implicitly connectedby retweet links, each of which is formed when oneuser retweets what another user tweeted.
We presenta variant of the popular HITS algorithm (Kleinberg,1999) that exploits the retweet link structure as anindicator of how interesting an individual tweet is.Specifically, we draw attention on the fact that not allretweets are meaningful.
Some users retweet a mes-sage, not because of its content, but only becausethey were asked to, or because they regard retweet-ing as an act of friendship, loyalty, or homage to-wards the person who originally tweeted (Boyd etal., 2010).
The algorithm proposed in this paper isdesigned upon the premise that not all retweet linksare created equal, assuming that some retweets maycarry more importance or weight than others.
Welchet al (2011) and Romero et al (2011) similarly ex-tend link analysis to Twitter, but address essentiallydifferent problems.
We conduct experiments on realworld tweet data and demonstrate that our methodachieves better performance than the simple retweetcount approach and a similar recent work on Twittermessages (Castillo et al, 2011) that uses supervisedlearning with a broad spectrum of features.2 Proposed MethodWe treat the problem of finding interesting tweets asa ranking problem where the goal is to derive a scor-ing function which gives higher scores to interestingtweets than to uninteresting ones in a given set oftweets.
To derive the scoring function, we adopt avariant of HITS, a popular link analysis method thatemphasizes mutual reinforcement between authorityand hub nodes (Kleinberg, 1999).Formally, we model the Twitter structure as di-rected graph G = (N,E) with nodes N and di-rectional edges E. We consider both users U ={u1, .
.
.
, unu} and tweets T = {t1, .
.
.
, tnt} asnodes and the retweet relations between these nodesas directional edges.
For instance, if tweet ta, cre-ated by user ua, retweets tb, written by user ub, wecreate a retweet edge eta,tb from ta to tb and anotherretweet edge eua,ub from ua to ub.1 Strictly speak-ing,G has two subgraphs, one based only on the usernodes and another based on the tweet nodes.
Insteadof running HITS on the tweet subgraph right away,1Note that two user nodes can have multiple edges.we first run it on the user subgraph and let tweets in-herit the scores from their publishers.
Our premiseis that the scores of a user is an important prior in-formation to infer the scores of the tweets that theuser published.User-level procedure: We first run the algorithmon the user subgraph.
?ui, we update the authorityscores A(ui) as:?
?j:euj,ui?E|{uk ?
U : euj ,uk ?
E}||{k : euj ,uk ?
E}|?H(uj) (1)Then, ?ui, we update the hub scores H(ui) to be:?
?j:eui,uj?E|{uk ?
U : euk,uj ?
E}||{k : euk,uj ?
E}|?A(uj) (2)A series of iterations is performed until the scoresare converged.
After each iteration, the author-ity/hub scores are normalized by dividing each ofthem by the square root of the sum of the squaresof all authority/hub values.
When this user-levelstage ends, the algorithm outputs a function SUA :U ?
[0, 1], which represents the user?s final au-thority score, and another function SUH : U ?
[0, 1], which outputs the user?s final hub score.
Notethat, unlike the standard HITS, the authority/hubscores are influenced by edge weights that reflect theretweet behaviors of individual users.
The idea hereis to dampen the influence of users who devote mostof their retweet activities toward a very few otherusers, such as celebrities, and increase the weightof users who retweet many different users?
tweets.To demonstrate the effectiveness of the parameter,we have done some preliminary experiments.
Thecolumn Userfrom in Table 1 shows the retweet be-havior of users who retweeted tweets belonging to?uninteresting?
and ?interesting?
classes observedin our Twitter dataset.
The values are calculatedby the ratio of all other users that a user retweetedto all retweet outlinks from the user; a value closerto 1 means that outlinks are pointed to many dif-ferent users.2 We observe that the value for userswho retweeted interesting tweets is shown to behigher, which means that they tend to retweet mes-sages from many different users, more than userswho retweeted uninteresting ones.2For calculating the ratios, we limit the target to users whoretweeted two or more times in our dataset.16Class Userfrom F = ?
#Not Interesting 0.591 0.252 1985Possibly Interesting 0.711 0.515 1115Both 0.634 0.346 3100Table 1: Dataset analysis.Tweet-level procedure: After the user-levelstage, we start computing the scores of the tweetnodes.
In each iteration, we start out with each tweetnode initially inheriting the scores of its publisher.Let P : T ?
U be a function that returns the pub-lisher of a given tweet.
?ti, we update A(ti) to be:SUA(P (ti)) +?
?j:etj ,ti?EF (etj ,ti)?H(tj) (3)Then, ?ti, we update H(ti) to be:SUH (P (ti)) +?
?j:eti,tj?EF (eti,tj )?A(tj) (4)where F (eta,tb) is a parameter function that returns?
> 1 if P (ta) is not a follower of P (tb) and 1 other-wise.
It is intuitive that if users retweet other users?tweets even if they are not friends, then it is morelikely that those tweets are interesting.
The columnF = ?
in Table 1 shows the ratio of all unfollow-ers who retweeted messages in a particular class toall users who retweeted messages in that class, ob-served in our dataset.
We observe that users retweetinteresting messages more, even when they do notfollow the publishers.
Similar observation has alsobeen made by Recuero et al (2011).
After each it-eration, the authority/hub scores are normalized asdone in the user-level.
After performing several it-erations until convergence, the algorithm finally out-puts a scoring function STA : T ?
[0, 1], which rep-resents the tweet node?s final authority score.
We usethis function to produce the final ranking of tweets.Text pattern rules: We observe that in somecases users retweet messages from their friends, notbecause of the contents, but via retweet requests tosimply evoke attention.
To prevent useless tweetscontaining such requests from receiving high author-ity scores, we collect 20 simple text pattern match-ing rules that frequently appear in those tweets.Specifically, we let the rules make influence whileupdating the scores of tweets by modifying the sum-mations in Eq.
(3) and (4) respectively as:?
?j:etj ,ti?EF (etj ,ti)?R(ti)?H(tj) (5)?
?j:eti,tj?EF (eti,tj )?R(tj)?A(tj) (6)where R(t) is a rule-based function that returns 0 iftweet t contains one of the pre-defined text patternsand 1 otherwise.
Such patterns include ?RT this if?and ?If this tweet gets RT * times I will?.3 Experiment and DiscussionOur Twitter dataset is collected during 31 days ofOctober 2011, containing 64,107,169 tweets and2,824,365 users.
For evaluation, we generated 31immediate Twitter graphs composed of 1.5 millionretweet links in average and 31 initially ranked listsof tweets, each consisting of top 100 tweets createdon a specific date of the month with highest retweetcounts accumulated during the next 7 days.
Two an-notators were instructed to categorize each tweet asinteresting or not, by inspecting its content as donein the work of Alonso et al (2010).
In case of dis-agreement (about 15% of all cases), a final judgmentwas made by consensus between the two annotators.We observe that the ratio of tweets judged to be in-teresting is about 36%; the column ?#?
in Table 1shows the actual counts of each class.
The goal ofthis evaluation is to demonstrate that our method isable to produce better ranked lists of tweets by re-ranking interesting tweets highly.Table 2 reports the ranking performance of vari-ous methods in terms of Precisions @10 and @20,R-Precision, and MAP.
We compare our approachto four baselines.
The first baseline, #RT, is obvi-ously based on retweet counts; tweets with higherretweet counts are ranked higher.
The second base-line, #URL+#RT, favors tweets that contain URLlinks (Alonso et al, 2010).
Since it is less likely fora tweet to contain more than one link, we addition-ally use #RT to break ties in tweet ranking.
Thirdly,HITSoriginal, is the standard HITS algorithm run onboth user and tweet subgraphs that calculates author-ity/hub scores of a node purely by the sum of hubvalues that point to it and the sum of authority val-ues that it points to, respectively, during iterations;17Method P@10 P@20 R-Prec MAP#RT 0.294 0.313 0.311 0.355#URL+#RT 0.245 0.334 0.362 0.361HITSoriginal 0.203 0.387 0.478 0.465MLmessage 0.671 0.645 0.610 0.642MLall 0.819 0.795 0.698 0.763HITSproposed 0.881 0.829 0.744 0.807Table 2: Performance of individual methodsno other influential factors are considered in the cal-culations.
Lastly, we choose one recent work byCastillo et al (2011) that addresses a related prob-lem to ours, which aims at learning to classify tweetsas credible or not credible.
Although interestingnessand credibility are two distinct concepts, the workpresents a wide range of features that may be ap-plied for assessing interestingness of tweets usingmachine learning.
For re-implementation, we traina binary SVM classifier using features proposed byCastillo et al (2011), which include features fromusers?
tweet and retweet behavior, the text of thetweets, and citations to external sources; we usethe probability estimates of the learned classifier forre-ranking.3 We use leave-one-out cross validationin order to evaluate this last approach, denoted asMLall.
MLmessage is a variant that relies only onmessage-based features of tweets.
Our method, with?
empirically set to 7, is denoted as HITSproposed.We observe that #RT alone is not sufficient mea-sure for discovering interesting tweets.
Additionallyleveraging #URL helps, but the improvements areonly marginal.
By manually inspecting tweets withboth high retweet counts and links, it is revealedthat many of them were tweets from celebrities withlinks to their self-portraits photographed in theirdaily lives, which may be of interest to their ownfollowers only.
HITSoriginal performs better thanboth #RT and #URL across most evaluation met-rics but generally does not demonstrate good per-formance.
MLmessage always outperform the firstthree significantly; we observe that tweet lengthsin characters and in words are the two most effec-tive message-based features for finding interestingtweets.
The results of MLall demonstrates that more3We do not use some topic-based features in (Castillo et al,2011) since such information is not available in our case.Method P@10 P@20 R-Prec MAPHITSproposed 0.881 0.829 0.744 0.807w/o User 0.677 0.677 0.559 0.591w/o Tweet 0.861 0.779 0.702 0.772w/o Rule 0.858 0.81 0.733 0.781Table 3: Contributions of individual stages.reasonable performance can be achieved when user-and propagation-based features are combined withmessage-based features.
The proposed method sig-nificantly outperforms all the baselines.
This is asignificant result in that our method is an unsuper-vised approach that relies on a few number of tweetfeatures and does not require complex training.We lastly report the contribution of individualprocedures in our algorithm in Table 3 by ablat-ing each of the stages at a time.
?w/o User?
iswhen tweet nodes do not initially inherit the scoresof their publishers.
?w/o Tweet?
is when tweetsare re-ranked according to the authority scores oftheir publishers.
?w/o Rule?
is when we use Eq.
(3) and (4) instead of Eq.
(5) and (6) for updatingtweet scores.
We observe that the user-level proce-dure plays the most crucial role.
We believe this isbecause of the ability of HITS to distinguish good?hub-users?.
Since authoritative users can post ordi-nary status updates occasionally in Twitter, we can-not always expect them to create interesting contentevery time they tweet.
However, good hub-users4tend to continuously spot and retweet interestingmessages; thus, we can expect the tweets they shareto be interesting steadily.
The role of hubs is not asrevealed on the tweet side of the Twitter graph, sinceeach tweet node can only have at most one retweetoutlink.
The exclusion of text pattern rules does notharm the overall performance much.
We suspect thisis because of the small number of rules and expectmore improvement if we add more effective rules.AcknowledgmentsThis work was supported by the Ministry of Knowl-edge Economy of Korea, under the title ?Develop-ment of social web issue detection-monitoring &prediction technology for big data analytic listeningplatform of web intelligence (10039158)?.4Often referred to as content curators (Bhargava, 2009).18ReferencesOmar Alonso, Chad Carson, David Gerster, Xiang Ji, andShubha U. Nabar.
2010.
Detecting uninteresting con-tent in text streams.
In Proceedings of the SIGIR 2010Workshop on Crowdsourcing for Search Evaluation,CSE ?10, pages 39?42.Rohit Bhargava.
2009.
Manifesto for the content curator:The next big social media job of the future?
http://rohitbhargava.typepad.com/.Danah Boyd, Scott Golder, and Gilad Lotan.
2010.Tweet, tweet, retweet: Conversational aspects ofretweeting on twitter.
In Proceedings of the 2010 43rdHawaii International Conference on System Sciences,HICSS ?10, pages 1?10.Carlos Castillo, Marcelo Mendoza, and Barbara Poblete.2011.
Information credibility on twitter.
In Proceed-ings of the 20th international conference on Worldwide web, WWW ?11, pages 675?684.Liangjie Hong, Ovidiu Dan, and Brian D. Davison.
2011.Predicting popular messages in twitter.
In Proceed-ings of the 20th international conference companionon World wide web, WWW ?11, pages 57?58.Jon M. Kleinberg.
1999.
Authoritative sources in a hy-perlinked environment.
J. ACM, 46(5):604?632.Hady W. Lauw, Alexandros Ntoulas, and KrishnaramKenthapadi.
2010.
Estimating the quality of postingsin the real-time web.
In Proceedings of the WSDM2010 Workshop on Search in Social Media, SSM ?10.Raquel Recuero, Ricardo Araujo, and Gabriela Zago.2011.
How does social capital affect retweets?
In Pro-ceedings of the 5th International AAAI Conference onWeblogs and Social Media, ICWSM ?11, pages 305?312.Daniel M. Romero, Wojciech Galuba, Sitaram Asur, andBernardo A. Huberman.
2011.
Influence and passiv-ity in social media.
In Proceedings of the 2011 Euro-pean Conference on Machine Learning and Principlesand Practice of Knowledge Discovery in Databases,ECML-PKDD ?11, pages 18?33.Michael J. Welch, Uri Schonfeld, Dan He, and JunghooCho.
2011.
Topical semantics of twitter links.
In Pro-ceedings of the 4th International Conference on WebSearch and Web Data Mining, WSDM ?11, pages 327?336.19
