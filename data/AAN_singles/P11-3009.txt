Proceedings of the ACL-HLT 2011 Student Session, pages 46?51,Portland, OR, USA 19-24 June 2011. c?2011 Association for Computational LinguisticsDisambiguating Temporal?Contrastive Discourse Connectives for MachineTranslationThomas MeyerIdiap Research Institute / Martigny, SwitzerlandEPFL - EDEE doctoral school / Lausanne, SwitzerlandThomas.Meyer@idiap.chAbstractTemporal?contrastive discourse connectives(although, while, since, etc.)
signal varioustypes of relations between clauses such as tem-poral, contrast, concession and cause.
Theyare often ambiguous and therefore difficult totranslate from one language to another.
Wediscuss several new and translation-orientedexperiments for the disambiguation of a spe-cific subset of discourse connectives in orderto correct some of the translation errors madeby current statistical machine translation sys-tems.1 IntroductionThe probabilistic phrase-based models used in sta-tistical machine translation (SMT) have been im-proved by integrating linguistic information duringtraining stages.
Recent attempts include, for exam-ple, the reordering of the source language syntax inorder to align it closer to the target language wordorder (Collins et al, 2010) or the tagging of pro-nouns for grammatical gender agreement (Le Na-gard and Koehn, 2010).
On the other hand, inte-grating discourse information, such as discourse re-lations holding between two spans of text or betweensentences, has not yet been applied to SMT.This paper describes several disambiguation andtranslation experiments for a specific subset of dis-course connectives.
Based on examinations in mul-tilingual corpora, we identified the connectives al-though, but, however, meanwhile, since, though,when and while as being particularly problematic formachine translation.
These discourse connectivessignal various types of relations between clauses,such as temporal, contrast, concession, expansion,cause and condition, which are, as we also show,hard to annotate even by humans.
Disambiguatingthese senses and tagging them in large corpora ishypothesized to help in improving SMT systems toavoid translation errors.The paper is organized as follows.
Section 2exemplifies translation and human annotation dif-ficulties.
Resources and the state of the art fordiscourse connective disambiguation and parsingare described in Section 3.
Section 4 summarizesour experiments for disambiguating the senses oftemporal?contrastive connectives.
The impact ofconnective disambiguation on SMT is briefly pre-sented in Section 5.
Section 6 concludes the paperwith an outline of future work.2 Translating ConnectivesDiscourse connectives can signal multiplesenses (Miltsakaki et al, 2005).
For instance,the connective since can have a temporal and causalmeaning.
The disambiguation of these senses iscrucial to the correct translation of texts from onelanguage to another.
Translation can be difficultbecause there may be no direct lexical correspon-dence for the explicit source language connectivein the target language, as shown by the referencetranslation of the first example in Table 1, takenfrom the Europarl corpus (Koehn, 2005).More often, the incorrect rendering of the sense ofa connective can lead to wrong translations, as in thesecond, third and fourth example in Table 1, whichwere translated by the Moses SMT decoder (Koehn46EN So what we want the European Patent Office to dois something on behalf of the European Commission[while] temporal the Office itself is not a Community insti-tution.FR Aussi, ce que nous souhaitons, c?est que l?Office europe?endes brevets agisse au nom de la Commission europe?enne[tout en n?e?tant] temporal pas une institution communau-taire.EN Finally, and in conclusion, Mr President, with the expiry ofthe ECSC Treaty, the regulations will have to be reviewed[since] causal I think that the aid system will have to con-tinue beyond 2002. .
.FR *Enfin, et en conclusion, Monsieur le pre?sident, a`l?expiration du traite?
ceca, la re?glementation devra e?tre revu[depuis que] temporal je pense que le syste`me d?aides de-vront continuer au-dela` de 2002. .
.EN Between 1998 and 1999, loyalists assaulted and shot 123people, [while] contrast republicans assaulted and shot 93people.FR Entre 1998 et 1999, les loyalistes ont attaque?
et abattu 123personnes, [ ] 93 pour les re?publicains.EN He said Akzo is considering alliances with American drugcompanies, [although] contrast he wouldn?t elaborate.DE *Er sagte Akzo erwa?gt Allianzen mit amerikanischen Phar-makonzerne, [obwohl] concession er mo?chte nicht na?hereingehen.Table 1: Translation examples from Europarl and thePDTB.
The discourse connectives, their translations, andtheir senses are indicated in bold.
The first example is areference translation from EN into FR, while the second,third and fourth example are wrong translations gener-ated by MT (EN?FR and EN?DE), hence marked withan asterisk.et al, 2007) trained on the Europarl EN?FR and re-spectively EN?DE subcorpora.
The reference trans-lation for the second example uses the French con-nective car with a correct causal sense, instead ofthe wrong depuis que generated by SMT, which ex-presses a temporal relation.
In the third example,the SMT system failed to translate the English con-nective while to French.
The French translation istherefore not coherent, the contrastive discourse in-formation cannot be established without an explicitconnective.
The last example in Table 1 is a sen-tence from the Penn Discourse Treebank (Prasad etal., 2008), see Section 3.
In its German translation,it would be correct to use the connective auch wenn(for contrast) instead of obwohl (for concession).These examples illustrate the difficulties in trans-lating discourse connectives, even when they arelexically explicit.
Our hypothesis is, that the auto-matic annotation of the senses prior to translationcan help finding more often the correct lexical cor-respondences of a connective (see Section 5 for onewhile (489) Translation EN-FR56% T tout en V-gerund (22%), tant que (22%),tandis que (11%)30% CT tandis que (56%), alors que (40%)14% CO me?me si (100%)although (347) Translation EN-DE76.7% CO obwohl (74%), zwar (9%), auch wenn (9%)23.3% CT obgleich (43%), obwohl (29%)Table 2: The English connectives while and although inthe Europarl corpus (sections numbered 199x, EN-FRand EN-DE) with token frequency, sense distribution andmost frequent translations ordered by the correspondingsenses (T = temporal, CO = concession, CT = contrast).of the methods to achieve this).When examining the frequency and sense distri-bution of these connectives and their translations inthe Europarl corpus, the results confirm that at leastsuch a fine-grained disambiguation as the one be-tween contrast and concession is necessary for a cor-rect translation.
Table 2 shows cases where the dif-ferent senses of the connectives while and althoughlead to different translations.
Disambiguation of thesenses here can help finding the correct lexical cor-respondence of the connective.To confirm that the automatic translation of dis-course connectives is not straightforward, we anno-tated 80 sentences from the Europarl corpus con-taining the connective while with the correspond-ing sense (T, CO or CT) and another 60 sentencescontaining the French connective alors que (T orCT).
We then translated these sentences with the al-ready mentioned EN?FR and FR?EN Moses SMTsystem and compared the output manually to the ref-erence translations from the corpus.
The overall sys-tem performance was 61% of correct translations forsentences with while and 55% of correct translationswith alors que.
As mistakes we either counted miss-ing target connective words (only when the outputsentence became incoherent) or wrong connectivewords because of failure in correct sense rendering.Also, the manual sense annotation task is not triv-ial.
In a manual annotation experiment, the senses ofthe connective while (T, CO and CT) were indicatedin 30 sentences by 4 annotators.
The overall agree-ment on the senses was not higher than a kappa valueof 0.6, which is acceptable but would need improve-ment in order to produce a reliable resource.473 Data and Related WorkOne of the few available discourse annotated cor-pora in English is the Penn Discourse Treebank(PDTB) (Prasad et al, 2008).
For this resource, onehundred types of explicit connectives were manuallyannotated, as well as implicit relations not signaledby a connective.For French, the ANNODIS project for anno-tation of discourse (Pery-Woodley et al, 2009)will provide an original, discourse-annotated cor-pus.
Resources for Czech are also becoming avail-able (Zikanova et al, 2010).
For German, a lexi-con of discourse connectives exists since the 1990s,namely DiMLex for lexicon of discourse markers(Stede and Umbach, 1998).
An equivalent, more re-cent database for French is LexConn for lexicon ofconnectives (Roze et al, 2010) ?
containing a listof 328 explicit connectives.
For each of them, Lex-Conn indicates and exemplifies the possible senses,chosen from a list of 30 labels inspired from Rhetor-ical Structure Theory (Mann and Thompson, 1988).For the first classification experiments in Sec-tion 4, we concentrated on English and the explicitconnectives in the PDTB data.
The sense hierarchyused in the PDTB consists of three levels, reach-ing from four top level senses (Temporal, Contin-gency, Comparison and Expansion) via 16 subsenseson the second level to 23 further subsenses on thethird level.
As the annotators were allowed to as-sign one or two senses for each connective thereare 129 possible simple or complex senses for morethan 18,000 explicit connectives.
The PDTB fur-ther sees connectives as discourse-level predicatesthat have two propositional arguments.
Argument 2is the one containing the explicit connective.
Thesentence from the first example in Table 1 can berepresented as while(So what we...[argument 1], theOffice itself...[argument 2]), which is very helpful toexamine the context of a connective (see Section 4.1on features).The release of the PDTB had quite an impact ondisambiguation experiments.
The state of the art forrecognizing explicit connectives in English is there-fore already high, at a level of 94% for disambiguat-ing the four main senses on the first level of thePDTB sense hierarchy (Pitler and Nenkova, 2009).However, when using all 100 types of connectivesand the whole PDTB training set, it is not so dif-ficult to achieve such a high score, because of thelarge amount of instances and the rather broad dis-tinction of the four main classes only.
As we showin the next section, when building separate classi-fiers for specific connectives with senses from themore detailed second hierarchy level of the PDTB, itis more difficult to reach high accuracies.
Recently,Lin et al (2010) built the first end-to-end PDTB dis-course parser, which is able to parse unrestricted textwith an F1 score of 38.18% on PDTB test data andfor senses on the second hierarchy level.4 Disambiguation ExperimentsFor the experiments described here we used theWEKA machine learning toolkit (Hall et al, 2009)and its implementation of a RandomForest classi-fier (Breiman, 2001).
This method outperformed, inour task, the C4.5 decision tree and NaiveBayes al-gorithms often used in recent research on discourseconnective classification.Our first experiment was aimed at sense disam-biguation down to the third level of the PDTB hi-erarchy.
The training set here consisted of all 100types of explicit connectives annotated in the PDTBtraining set (15,366 instances).
To make the figuresand results of this paper comparable to related work,we use the subdivision of the PDTB recommendedin the annotation manual: sections 02?21 as train-ing set and section 23 as test set.
The only twofeatures were the (capitalized) connective word to-kens from the PDTB and their Part of Speech (POS)tags.
For all 129 possible sense combinations, in-cluding complex senses, results reach 66.51% ac-curacy with 10-fold cross validation on the train-ing set and 74.53% accuracy on the PDTB test set1.This can be seen as a baseline experiment.
For in-stance, Pitler and Nenkova (2009) report an accu-racy of 85.86% for correctly classified connectives(with the 4 main senses), when using the connectivetoken as the only feature.Based on the analysis of translations and frequen-cies from Section 2, we then reduced the list ofsenses to the following six: temporal (T), cause (C),1As far as we know, Versley (2010) is the only referencereporting results down to the third level, reaching an accuracy of79%, using more features, but not stating whether the complexsense annotations were included.48Connective Senses with number of occurrences Best feature subset Accuracy Baseline kappaalthough 134 CO, 133 CT 8, 9, 10 58.4% 48.7% 0.17but 2090 CT, 485 CO, 77 E 5, 8, 9, 10 76.4% 78.8% 0.02however 261 CT, 119 CO 1?10 68.4% 68.7% 0.05meanwhile 77 T, 57 E, 22 CT 1?10 51.9% 49.4% 0.09since 83 C, 67 T 1, 4, 6, 8, 9, 10 75.3% 55.3% 0.49though 136 CO, 125 CT 1, 2, 3, 9, 10 65.1% 52.1% 0.30when 640 T, 135 COND, 17 C, 8 CO, 2 CT 1, 2, 10 79.9% 79.8% 0.05while 342 CT, 159 T, 77 CO, 53 E 3, 5, 7, 8, 9, 10 59.6% 54.1% 0.23all 2975 CT, 959 CO, 943 T, 187 E, 135 COND, 100 C 1?10 72.6% 56.1% 0.50Table 3: Disambiguation of temporal?contrastive connectives.condition (COND), contrast (CT), concession (CO)and expansion (E).
All subsenses from the thirdPDTB hierarchy level were merged under secondlevel ones (C, COND, CT, CO).
Exceptions werethe top level senses T and E, which, so far, needno further disambiguation for translation.
In addi-tion, we extracted separate training sets for each ofthe 8 temporal?contrastive connectives in questionand one training set for all them.
The number of oc-currences and senses in the sets for the single con-nectives is listed in Table 3.
The total number ofinstances in the training set for all 8 connectivesis 5,299 occurrences, with a sense distribution of56.1% CT, 18% CO, 17.8% T, 3.5% E, 2.5% COND,1.9% C.Before summarizing the results, we describe thefeatures implemented and used so far.4.1 FeaturesThe following basic surface features were consid-ered when disambiguating the senses signaled byconnectives.
Their values were extracted from thePDTB manual gold annotation.
Future automateddisambiguation will be applied to unrestricted text,identifying the discourse arguments and syntacticalelements in automatically parsed and POS?taggedsentences.1.
the (capitalized) connective word form2.
its POS tag3.
first word of argument 14. last word of argument 15. first word of argument 26. last word of argument 27.
POS tag of the first word of argument 28. type of first word of argument 29. parent syntactical categories of the connective10.
punctuation patternThe cased word forms (feature 1) were left as is,therefore also indicating whether the connective islocated at the beginning of a sentence or not.
Thevariations from the PDTB (e.g.
when ?
back whenetc.)
were also included, supplemented by their POStags (feature 2).
As shown by Lin et al (2010)and duVerle and Prendinger (2009), the context ofa connective is very important.
The arguments mayinclude other (reinforcing or opposite) connectives,numbers and antonyms (to express contrastive rela-tions).
We extracted the words at the beginning andat the end of argument 1 (features 3, 4) and argu-ment 2 (features 5, 6) which are, as observed, otherconnectives, gerunds, adverbs or determiners (fur-ther generalized by features 7 and 8).
The paths tosyntactical ancestors (feature 9) in which the con-nective word form appears are quite numerous andwere therefore truncated to a maximum of four an-cestors (e.g.
|SBAR?VP?S|, |ADVP?ADJP?VP?S|,etc).
Punctuation patterns (feature 10) are of theform C,A ?
A,CA etc.
where C is the explicit con-nective and A a placeholder for all the other words.Punctuation is important for locating connectives asmany of them are subordinating and coordinatingconjunctions, separated by commas (Haddow, 2005,p.
23).4.2 ResultsIn the disambiguation experiments describedhere, results were generated separately for everytemporal?contrastive connective (supposing onemay try to improve the translation of only certainconnectives), in addition to one result for the wholesubset.
The results in Table 3 above are basedon 10-fold cross validation on the training sets.They were measured using accuracy (percentageof correctly classified instances) and the kappa49value.
The baseline is the majority class, i.e.
theprediction for the most frequent sense annotated forthe corresponding connective.
Feature selection wasperformed in order to find the best feature subset,which also improved the accuracy in a range of1% to 2%.
Marked in bold are the accuracy valuessignificantly above the baseline ones2.
The lastresult for all 8 temporal?contrastive connectivesreports a six-way classification of senses very closeto one another: the accuracy and kappa values arewell above random agreement and prediction of themajority class.Note that experiments for specific subsets of con-nectives have very rarely been tried in research.Miltsakaki et al (2005) describe results for since,while and when, reporting accuracies of 89.5%,71.8% and 61.6%.
The results for the single connec-tives are comparable with ours in the case of sinceand while, where similar senses were used.
For whenthey only distinguished three senses, whereas we re-port a higher accuracy for 5 different senses, see Ta-ble 3.5 SMT ExperimentsWe have started to explore how to constrain an SMTsystem to use labeled connectives resulting from theexperiments above.
There are at least two meth-ods to integrate labeled discourse connectives in theSMT process.
A first method modifies the phrase ta-ble of the Moses SMT decoder (Koehn et al, 2007)in order to encourage it to translate a specific senseof a connective with an acceptable equivalent.
Asecond, more natural method for an SMT systemwould be to apply the discourse information ob-tained from the disambiguation module, adding thesense tags to the discourse connectives in a large par-allel corpus.
This corpus could then be used to traina new SMT system learning and weighting thesetags during the training.So far, we experimented with method one.
Infor-mation about the possible senses of the connectivewhile, labeled as temporal(1), contrast(2) or con-cession(3)) was directly introduced to the Englishsource language phrases when there was an appro-2Paired t-tests were performed at 95% confidence level.
Theother accuracy values are either near to the baseline ones or notsignificantly below them.priate translation of the connective in the Frenchequivalent phrase.
We also increased the lexicalprobability scores for such modified phrases.
Thefollowing example gives an idea of the changes inthe phrase table of the above-mentioned EN?FRMoses SMT system:< original:and the commission , while preserving ||| et la commission tout ende?fendant ||| 1 3.8131e-06 1 5.56907e-06 2.718 ||| ||| 1 1and while many ||| et bien que de nombreuses ||| 1 0.00140575 0.50.000103573 2.718 ||| ||| 1 1> modified:and the commission , while-1 preserving ||| et la commission touten de?fendant ||| 1 1 1 1 2.718 ||| ||| 1 1and while-3 many ||| et bien que de nombreuses ||| 1 1 0.5 1 2.718||| ||| 1 2Experiments with such modifications have al-ready demonstrated a slight increase of BLEUscores (by 0.8% absolute) on a small test corpus(20 hand-labeled sentences).
The analysis of resultshas shown that the system behaves as expected, i.e.labeled connectives are correctly translated.
Thistends to confirm the hypothesis of this paper, thatinformation regarding discourse connectives indeedcan lead to better translations.6 Conclusion and Future WorkThe paper described new translation-oriented ap-proaches to the disambiguation of a subset of ex-plicit discourse connectives with highly ambiguoustemporal?contrastive senses.
Although lexically ex-plicit, their translation by current SMT systems isoften wrong.
Disambiguation results in reasonablyhigh accuracies but also shows that one should findmore accurate and additional features.
We will tryto better model the context of a connective, for in-stance by integrating word similarity distances fromWordNet as features.In addition, the paper showed a first method toforce an existing and trained SMT system to trans-late discourse connectives correctly.
This led tonoticeable improvements on the translations of thetested sentences.
We will continue to train SMT sys-tems on automatically labeled discourse connectivesin large corpora.AcknowledgmentsThis work is funded by the Swiss National Sci-ence Foundation (SNSF) under the Project Sinergia50COMTIS, contract number CRSI22 127510, www.idiap.ch/comtis/.
Many thanks go to Dr. An-drei Popescu-Belis, Dr. Bruno Cartoni and Dr. San-drine Zufferey, for insightful comments and collab-oration.ReferencesLeo Breiman.
2001.
Random Forests.
Machine Learn-ing, 45(1):5?32.Michael Collins, Phillipp Koehn, Ivona Kucerova.
2005.Clause Restructuring for Statistical Machine Transla-tion.
Proceedings of the 43rd Annual Meeting of theACL, 531?540David duVerle, Helmut Prendinger.
2009.
A Novel Dis-course Parser Based on Support Vector Machine Clas-sification.
Proceedings of the 47th Annual Meeting ofthe ACL and the 4th IJCNLP of the AFNLP, 665?673.Barry Haddow.
2005.
Acquiring a DisambiguationModel For Discourse Connectives.
Master Thesis.University of Edinburgh, School of Informatics.Mark Hall, Eibe Frank, Geoffrey Holmes, Bern-hard Pfahringer, Peter Reutemann, Ian H. Witten.2009.
The WEKA Data Mining Software: An Update.SIGKDD Explorations, 11(1).Philipp Koehn.
2005.
Europarl: A Parallel Corpus forStatistical Machine Translation.
Proceedings of MTSummit X, 79?86.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico,Nicola Bertoldi, Brooke Cowan, Wade Shen,Christine Moran, Richard Zens, Chris Dyer, On-drej Bojar, Alexandra Constantin, Evan Herbs.
2007.Moses: Open Source Toolkit for Statistical MachineTranslation.
Proceedings of the 45th Annual Meetingof the ACL, Demonstration session, 177?180.Ronan Le Nagard, Philipp Koehn.
2010.
Aiding PronounTranslation with Co-Reference Resolution.
Proceed-ings of the Joint 5th Workshop on Statistical MachineTranslation and Metrics MATR, 258?267.Ziheng Lin, Hwee Tou Ng, Min-Yen Kan. 2010.
APDTB-Styled End-to-End Discourse Parser.
Techni-cal Report TRB8/10.
School of Computing, NationalUniversity of Singapore, 1?15.William C. Mann, Sandra A. Thompson.
1988.
Rhetori-cal structure theory: towards a functional theory of textorganization.
Text 8(3):243?281.Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, Ar-avind Joshi, Bonnie Webber.
2005.
Experiments onSense Annotations and Sense Disambiguation of Dis-course Connectives.
Proceedings of the Fourth Work-shop on Treebanks and Linguistic Theories (TLT).Marie-Paule Pe?ry-Woodley, Nicholas Asher, Patrice En-jalbert, Farah Benamara, Myriam Bras, Ce?cile Fabre,Ste?phane Ferrari, Lydia-Mai Ho-Dac, Anne LeDraoulec, Yann Mathet, Philippe Muller, Lau-rent Pre?vot, Josette Rebeyrolle, Ludovic Tan-guy, Marianne Vergez-Couret, Laure Vieu, An-toine Widlo?cher.
2009.
ANNODIS: une approche out-ille de l?annotation de structures discursives.
Proceed-ings of TALN.Emily Pitler, Ani Nenkova.
2009.
Using Syntax toDisambiguate Explicit Discourse Connectives in Text.Proceedings of the ACL-IJCNLP 2009 Conference,Short Papers.
13?16.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, Bonnie Webber.2008.
The Penn Discourse Treebank 2.0.
Proceed-ings of the 6th International Conference on LanguageResources and Evaluation (LREC), 29641-2968.Charlotte Roze, Laurence Danlos, Philippe Muller.
2010.LEXCONN: a French Lexicon of Discourse Connec-tives.
Proceedings of Multidisciplinary Approaches toDiscourse (MAD).Manfred Stede, Carla Umbach.
1998.
DiMLex: a lex-icon of discourse markers for text generation and un-derstanding.
Proceedings of the 36th Annual Meetingof the ACL, 1238?1242.Yannick Versley.
2010.
Discovery of Ambiguous andUnambiguous Discourse Connectives via AnnotationProjection.
Proceedings of Workshop on Annotationand Exploitation of Parallel Corpora (AEPC), 83?82Sa?rka Zika?nova?, Lucie Mladova?, Jir???
M?
?rovsky?,Pavlina J??nova?.
2010.
Typical Cases of Annotators?Disagreement in Discourse Annotations in PragueDependency Treebank.
Proceedings of the SeventhInternational Conference on Language Resources andEvaluation (LREC), 2002?2006.51
