Proceedings of the IJCNLP-08 Workshop on NER for South and South East Asian Languages, pages 59?66,Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language ProcessingDomain Focused Named Entity Recognizer for Tamil UsingConditional Random FieldsVijayakrishna RAU-KBC Research CentreMIT Campus, Anna UniversityChennai, Indiavijayakrishna@au-kbc.orgSobha LAU-KBC Research CentreMIT Campus, Anna UniversityChennai, Indiasobha@au-kbc.orgAbstractIn this paper, we present a domain focusedTamil Named Entity Recognizer fortourism domain.
This method takes care ofmorphological inflections of named entities(NE).
It handles nested tagging of namedentities with a hierarchical tagsetcontaining 106 tags.
The tagset is designedwith focus to tourism domain.
We haveexperimented building ConditionalRandom Field (CRF) models by trainingthe noun phrases of the training data and itgives encouraging results.1 IntroductionNamed Entity Recognition (NER) is the task ofidentifying and classifying the entities such asperson names, place names, organization namesetc, in a given document.
Named entities play amajor role in information extraction.
NER has beena defined subtask in Message UnderstandingConference (MUC) since MUC 6.
A wellperforming NER is important for further level ofNLP techniques.In general NER is a hard problem..
Words canhave multiple uses and there is an unboundednumber of possible names.
Many techniques havebeen applied in Indian and European languages forNER.
Some of them are rule based system (Krupkaand Hausman, 1998), which makes use ofdictionary and patterns of named entities, Decisiontrees (Karkaletsis et al, 2000), Hidden MorkovModel (HMM) (Biker, 1997), Maximum EntropyMorkov Model (MEMM) (Borthwick et al, 1998),Conditional Random Fields (CRF) (AndrewMcCallum and Wei Li, 2003) etc.
In short, theapproaches can be classified as rule-basedapproach, machine learning approach or hybridapproach.For Indian languages, many techniques havebeen tried by different people.
MEMM system forHindi NER (Kumar and Pushpak, 2006) gave anaverage F1 measure of 71.9 for a tagset of fournamed entity tags.NER has been done generically and also domainspecific where a finer tagset is needed to describethe named entities in a domain.
Domain specificNER is common and has been in existence for along time in the Bio-domain (Settles 2004) foridentification of protein names, gene names, DNAnames etc.We have developed a domain specifichierarchical tagset consisting of 106 tags fortourism domain.
We have used ConditionalRandom Fields, a machine learning approach tosequence labeling task, which includes NER.Section 2 gives a brief introduction toConditional Random Fields (CRF).
Section 3discusses the nature of named entities in Tamil,followed by section 4 describing the tagset used intourism domain.
Section 5 describes how we havepresented the training data to build CRF modelsand how we have handled nested tagging.
Sections6 and 7 explain the experiments and results.
Thepaper is concluded in section 8.592 Conditional Random Fields (CRF)Conditional Random Fields (CRF) (Lafferty et al,2001) is a machine learning technique.
CRFovercomes the difficulties faced in other machinelearning techniques like Hidden Markov Model(HMM) (Rabiner, 1989) and Maximum EntropyMarkov Model (MEMM) (Berger et al, 1996).HMM does not allow the words in the inputsentence to show dependency among each other.MEMM shows a label bias problem because of itsstochastic state transition nature.
CRF overcomesthese problems and performs better than the othertwo.
HMM, MEMM and CRF are suited forsequence labeling task.
But only MEMM and CRFallows linguistic rules or conditions to beincorporated into machine learning algorithm.Lafferty et al define Conditional Random Fiedsas follows: ?Let G = (V,E) be a graph such that Y= (Yv)v V, so that Y is indexed by the vertices ofG.
Then (X,Y) is a conditional random field incase, when conditioned on X, the random variablesYvobey the Markov property with respect to thegraph: p(Yv|X,Yw,w?v) = p(Yv|X,Yw,w~v), wherew~v means that w and v are neighbors in G?.Here X denotes a sentence and Y denotes thelabel sequence.
The label sequence y whichmaximizes the likelihood probability p?
(y|x) willbe considered as the correct sequence, whiletesting for new sentence x with CRF model ?
.
Thelikelihood probability p?
(y|x) is expressed asfollows.where ?kand ?kare parameters from CRF model ?and fkand gkare the binary feature functions thatwe need to give for training the CRF model.
Thisis how we integrate linguistic features intomachine learning models like CRF.In NER task, the sequence of words whichforms a sentence or a phrase can be considered asthe sequence x and the sequence formed by namedentity label for each word in the sequence x is thelabel sequence y.
Now, the task of finding y thatbest describes x can be found by maximizing thelikelihood probability p?(y|x).
Thus, NER task canbe considered as a sequence labeling task.
HenceCRF can be used for NER task.3 Characteristics of Named Entities inTamilUnlike English, there is no concept of capitalletters in Tamil and hence no capitalizationinformation is available for named entities inTamil.
All named entities are nouns and hence areNoun Phrases.
But not all Noun Phrases areNamed Entities.
Since named entities are nounphrases, they take all morphological inflections.This makes a single named entity to appear asdifferent words in different places.
By applyingMorphological analysis on words, the root wordsof inflected Named Entities can be obtained.
Theseroots will be uninflected Named Entities which iswhat is required in most applications.
Some type ofnamed entities like date, money etc, occur inspecific patterns.Example for inflected named entity:ceVnYnYEkku (?to Chennai?
).Example for pattern in named entity:2006 aktopar 25Am wewi (?25thOctober,2006?
)Pattern: <4 digits> <month> <1-2 digit> [Amwewi]4 Named Entity Tagset usedThe tagset which we use here for NER contains106 tags related to each other hierarchically.
Thistype of tagset is motivated from ?ACE EnglishAnnotation Guidelines for Entities?
developed byLinguistic Data Consortium.
The tagset which weuse is built in-house with focus to tourism domain.4.1 Sample TagsSample tags from the entire tagset is shown belowwith their hierarchy.1.
Enamex1.1.
Person1.1.1.
Individual1.1.1.1.
Family Name1.1.1.2.
Title601.1.2.
Group1.2.
Organization.
.
.
.1.3.
Location.
.
.
.1.4.
Facilities.
.
.
.1.5.
Locomotive.
.
.
.1.6.
Artifact.
.
.
.1.7.
Entertainment.
.
.
.1.8.
Materials.
.
.
.1.9.
Livthings.
.
.
.1.10.
Plants.
.
.
.1.11.
Disease.
.
.
.2.
Numex2.1.
Distance2.2.
Money2.3.
Quantity2.4.
Count3.
Timex3.1.
Time3.2.
Year3.3.
Month3.4.
Date3.5.
Day3.6.
Period3.7.
SdayCertain tags in this tagset are designed withfocus to Tourism and Health Tourism domain,such as place, address, water bodies (rivers, lakesetc.,), religious places, museums, parks,monuments, airport, railway station, bus station,events, treatments for diseases, distance and date.The tags are assigned with numbers 1,2,3 forzerothlevel, the tags with numbers 1.1, 1.11, 2.1,2.4 and 3.1 ,3.7 etc for level-1, the tags withnumbers 1.1.1, 1.1.2, 1.2.1 etc as level-2  and thetags with numbers 1.1.1.1, 1.1.1.2, 1.2.4.1 etc forlevel-3  because they occur in the hierarchy incorresponding levels.
We have 3 tags in zerothlevel, 22 tags in level-1, 50 tags in level-2 and 31tags in level-3.4.2 Sample AnnotationTamil :<person> <city> mawurE </city> <individual>manYi <familyname> Eyar </familyname></individual> </person> <city> ceVnYnYEkku</city> vanwAr.English equivalent :<person> <city> Madhurai </city> <individual>Mani <familyname> Iyer </familyname></individual> </person> came to <city> Chennai</city>.5 NER using CRFWe used CRF++ (Taku Kudo, 2005), an opensource toolkit for linear chain CRF.
This tool whenpresented with the attributes extracted from thetraining data builds a CRF model with the featuretemplate specified by us.
When presented with themodel thus obtained and attributes extracted fromthe test data, CRF tool outputs the test data taggedwith the labels that has been learnt.5.1 Presenting training dataTraining data will contain nested tagging of namedentities as shown in section 4.2.
To handle nestedtagging and to avoid ambiguities, we isolate thetagset into three subsets, each of which willcontain tags from one level in the hierarchy.
Now,the training data itself will be presented to CRF asthree sets of training data.
From this, we will getthree CRF models, one for each level of hierarchy.Example:The sample sentence given in section 4.2 will bepresented to CRF training for each level ofhierarchy as follows:Level-1:<location> mawurE </location> <person>manYi Eyar </person> <location> ceVnYnYEkku</location> vanwAr.Level-2:<place> mawurE </place> <individual> manYiEyar </individual> <place> ceVnYnYEkku</place> vanwAr.Level-3:<city> mawurE </city> manYi <familyname>Eyar </familyname> <city> ceVnYnYEkku</city> vanwAr.Notice that the tags ?location?
and ?place?
arenot specified in the input sentence.
In the61hierarchy, the ?location?
tag is the parent tag of?place?
tag which is a parent tag of ?city?
tag.
Thusfor the word ?mawurE?, level-1 tag is ?location?,level-2 tag is ?place?
and level-3 tag is ?city?.5.2 Attributes and Feature TemplatesAttributes are the dependencies from which thesystem can infer a phrase to be named entity ornot.
Features are the conditions imposed on theseattributes.
Feature templates help CRF engine toform features from the attributes of the trainingdata.
From the characteristics of named entities inTamil, we see that it is only the noun phrases thatare possible candidates for Named Entities.
So weapply Noun Phrase Chunking and consider onlynoun phrases and train on them.
The attributes thatwe arrived at are explained below:1.
Roots of words: This is to ignoreinflections in named entities.
Also to learnthe context in which the named entityoccurs, we consider two words prior andtwo words subsequent to the word underanalysis and take unigram, bigram andtrigram combinations of them as attributes.2.
Their Parts of Speech (POS): This willgive whether a noun is proper noun orcommon noun.
POS of current word isconsidered.3.
Words and POS combined: The presentword combined with the POS tag of theprevious two words and the present wordcombined with POS of the next two wordsare taken as features.4.
Dictionary of Named Entities: A list ofnamed entities is collected for each type ofnamed entities.
Root words are checkedagainst the dictionary and if present in thedictionary, the dictionary feature for thecorresponding type of named entity isconsidered positive.5.
Patterns: Certain types of named entitiessuch as date, time, money etc., showpatterns in their occurrences.
Thesepatterns are listed out.
The current nounphrase is checked against each pattern.
Thefeature is taken as true for those patternswhich are satisfied by the current nounphrase.Example Patterns:Date: <4 digits> <month> <1-2 digit> [Amwewi]Money: rU.
<digits> [Ayiram|latcam|koti](English Equivalent:Rs.
<digits> [thousands|lakhs|crores])6.
Bigram of Named Entity labelA feature considering the bigram occurrences ofthe named entity labels in the corpus is considered.This is the feature that binds the consecutivenamed entity labels of a sequence and thus forminglinear chain CRFs.
Sample noun phrase with level-1 tags:arulYmiku JJ  personcupramaNiya NNPC    personcuvAmi  NNPC    personwirukoyil   NNC locationvayalUr NNP locationEnglish Equivalent:Gracious JJ personSubramaniya NNPC personSwami NNPC personTemple NNC locationVayalore NNP locationAttributes are extracted for each token in thenoun phrase.
For example, the attributes for thirdtoken in the sample noun phrase given are asfollows.1.
Unigram: arulYmiku, cupramaNiya,cuvAmi, wirukoyil, vayalUr.2.
Bigram: cupramaNiya/cuvAmi, cuvAmi/wirukoyil3.
Trigram: cupramaNiya/cuvAmi/wirukoyil4.
POS of current word: NNPC5.
Word and previous 2 POS:  JJ/NNPC/cuvAmi6.
Word and next 2 POS: cuvAmi/NNC/NNP7.
Bigram of NE labels: person/person62The CRF training process described above isillustrated in Figure-1.5.3 Presenting testing dataTest data will also be presented in way similar tohow we presented the training data.
Test data isprocessed for Morph analysis, POS (Arulmozhi etal., 2004) and NP chunking (Sobha and VijaySundar Ram, 2006).
Here also, the same set ofattributes and feature templates are used.
Now, thetest data is tagged with each of the CRF modelsbuilt for three levels of hierarchy.
All the threeoutputs are merged to get a combined output.
TheCRF testing is illustrated in Figure 2.6 ExperimentsA 94k words corpus is collected in Tamil fortourism domain.
Morph Analysis, POS tagging,NP chunking and named entity annotation are donemanually on the corpus.
This corpus contains about20k named entities.
This corpus is split into twosets.
One forms the training data and the otherforms the test data.
They consist of 80% and 20%of the total data respectively.
CRF is trained withtraining data and CRF models for each of thelevels in the hierarchy are obtained.
With thesemodels the test data is tagged and the output isevaluated manually.7 ResultsThe results of the above experiment are as follows.Here, NE means Named Entity, NP means nounphrase.Number of NPs in test data = 7922There are totally 4059 NEs in the test data.
Allof them bear level-1 tags.
Out of 4059 NEs, 3237NEs bear level-2 tags and 727 NEs bear level-3tags.
The result from the system is shown in Table1 and Table 2.The system performs well for domain focusedcorpus.
It identifies inflected named entitiesefficiently by considering the root form of eachword in noun phrases.
The reason for goodFilter NPsCRF TestingFigure 2.
CRF Testing for NERTest DataMorph Analysis, POS Tagging, NPchunkingNPs from test dataLevel-1ModelLevel-2ModelLevel-3ModelMergeAll levels Merged OutputDictionary,PatternsTraining Data (Morph Analyzed, POStagged, NP chunked, NE Tagged)NPs from Training DataRootwords,POS,Level-1tagsRootwords,POS,Level-2tagsRootwords,POS,Level-3tagsCRF TrainingLevel-1CRFmodelLevel-2CRFmodelLevel-3CRFmodelFigure 1.Training CRF for NERFilter NPsDictionary,Patterns63precision is that tagging is done only when the rootword that it is seeing is already learnt from thetraining corpus or the context of the current wordis similar to the context of the named entities that ithas learnt from the training corpus.
However, insome words like ?arccunYAnawi?
(Arjuna River),the Morph Analyzer gives two root words whichare ?arccunYa?
and ?nawi?.
For our case, only thefirst word is considered and the system tags it as?person?
instead of ?waterbodies?.Named EntityLevelLevel-1Level-2Level-3Number of NEsin data4059 3237 727Number of NEsidentified byNER engine3414 2667 606Number of NEsidentifiedcorrectly3056 2473 505Precision % 89.51 92.73 83.33Recall % 75.29 76.40 69.46F1 measure % 81.79 83.77 75.77Table 1.
Evaluation of output from NER engine foreach levelPerformance Measure Value in %Precision 88.52Recall 73.71F1 Measure 80.44Table 2.
Overall result from NER engineWhen there are new named entities which arenot in training corpus, CRF tries to capture thecontext and tags accordingly.
In such casesirrelevant context that it may learn while trainingwill cause problem resulting in wrong tagging.This affects the precision to some extent.
When thenamed entities and their context are new to CRF,then they are most likely not tagged.
This affectsthe recall.From Table 1, we see that the system performsbetter for level-2 tags than for level-1 tags eventhough level-1 tags are less in number than level-2tags and occur more frequently than level-2 tags.This is so because the named entities with level-2tags have relatively more context and are lesser inlength (number of words in the named entity) thanthe named entities in level-1 tags.
Level-3 tagscontain lesser number of tags than level-2 tags andalso occur less frequently.
Because of relativelymore data sparseness, the system is unable toperform well for level-3 tags as it can for otherlevels.8 ConclusionWe see that Conditional Random Fields is wellsuited for Named Entity recognition task in Indianlanguages also, where the inflection of namedentities can be handled by considering their rootforms.
A good precision can be obtained bypresenting only the noun phrases for both testingand training.ReferencesArulmozhi P, Sobha L and Kumara Shanmugam B.2004.
Parts of Speech Tagger for Tamil, Symposiumon Indian Morphology, Phonology & LanguageEngineering, March 19-21, IIT Kharagpur.
:55-57.Berger A, Della Pietra S and Della Pietra V. 1996.
AMaximum Entropy Approach to Natural LanguageProcessing.
Computational Linguistics, 22(1).Bikel D M. 1997.
Nymble: a high-performance learningname-finder.
In Proceedings of the Fifth Conferenceon Applied Natural Language Processing.
:194-201.Borthwick A, Sterling J, Agichtein E and Grishman R.1998.
Description of the MENE named Entity System,In Proceedings of the Seventh MachineUnderstanding Conference (MUC-7).Karkaletsis V, Pailouras G and Spyropoulos C D. 2000.Learning decision trees for named-entity recognitionand classification.
In Proceedings of the ECAIWorkshop on Machine Learning for InformationExtraction.Krupka G R and Hausman K. 1998.
Iso Quest Inc:Description of the NetOwl Text Extraction System asused for MUC-7.
In Proceedings of Seventh MachineUnderstanding Conference (MUC 7).Kumar N, Pushpak Bhattacharyya.
2006.
Named EntityRecognition in Hindi using MEMM.John Lafferty, Andrew McCallum, Fernando Pereira.2001.
Conditional Random Fields: ProbabilisticModels for Segmenting and Labeling Sequence Data.In Proceedings of the Eighteenth International64Conference on Machine Learning (ICML-2001).282-289.Andrew McCallum and Wei Li.
2003.
Early Results forNamed Entity Recognition with Conditional RandomFields, Feature Induction and Web-EnhancedLexicons.
Seventh Conference on Natural LanguageLearning (CoNLL).Lawrence R. Rabiner.
1989.
A Tutorial on HiddenMarkov Models and Selected Applications in SpeechRecognition.
In Proceedings of the IEEE, 77(2):257?286.Settles B.
(2004).
Biomedical Named Entity RecognitionUsing Conditional Random Fields and Rich FeatureSets.
In Proceedings of the International JointWorkshop on Natural Language Processing inBiomedicine and its Applications (NLPBA), Geneva,Switzerland.
pp:104-107.Sobha L, Vijay Sundar Ram R. 2006.
Noun PhraseChunking in Tamil.
In proceedings of the MSPIL-06,IIT Bombay.
pp:194-198.Taku Kudo.
2005.
CRF++, an open source toolkit forCRF, http://crfpp.sourceforge.net .6566
