Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 399?408,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsHow do you pronounce your name?
Improving G2P with transliterationsAditya Bhargava and Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, Alberta, Canada, T6G 2E8{abhargava,kondrak}@cs.ualberta.caAbstractGrapheme-to-phoneme conversion (G2P) ofnames is an important and challenging prob-lem.
The correct pronunciation of a name isoften reflected in its transliterations, which areexpressed within a different phonological in-ventory.
We investigate the problem of us-ing transliterations to correct errors producedby state-of-the-art G2P systems.
We present anovel re-ranking approach that incorporates avariety of score and n-gram features, in orderto leverage transliterations from multiple lan-guages.
Our experiments demonstrate signifi-cant accuracy improvements when re-rankingis applied to n-best lists generated by threedifferent G2P programs.1 IntroductionGrapheme-to-phoneme conversion (G2P), in whichthe aim is to convert the orthography of a word to itspronunciation (phonetic transcription), plays an im-portant role in speech synthesis and understanding.Names, which comprise over 75% of unseen words(Black et al, 1998), present a particular challengeto G2P systems because of their high pronunciationvariability.
Guessing the correct pronunciation of aname is often difficult, especially if they are of for-eign origin; this is attested by the ad hoc transcrip-tions which sometimes accompany new names intro-duced in news articles, especially for internationalstories with many foreign names.Transliterations provide a way of disambiguatingthe pronunciation of names.
They are more abun-dant than phonetic transcriptions, for example whennews items of international or global significance arereported in multiple languages.
In addition, writingscripts such as Arabic, Korean, or Hindi are moreconsistent and easier to identify than various pho-netic transcription schemes.
The process of translit-eration, also called phonetic translation (Li et al,2009b), involves ?sounding out?
a name and thenfinding the closest possible representation of thesounds in another writing script.
Thus, the correctpronunciation of a name is partially encoded in theform of the transliteration.
For example, given theambiguous letter-to-phoneme mapping of the En-glish letter g, the initial phoneme of the name Gersh-win may be predicted by a G2P system to be ei-ther /g/ (as in Gertrude) or /?/ (as in Gerald).
Thetransliterations of the name in other scripts providesupport for the former (correct) alternative.Although it seems evident that transliterationsshould be helpful in determining the correct pronun-ciation of a name, designing a system that takes ad-vantage of this insight is not trivial.
The main sourceof the difficulty stems from the differences betweenthe phonologies of distinct languages.
The mappingsbetween phonemic inventories are often complexand context-dependent.
For example, because Hindihas no /w/ sound, the transliteration of Gershwininstead uses a symbol that represents the phoneme/V/, similar to the /v/ phoneme in English.
In ad-dition, converting transliterations into phonemes isoften non-trivial; although few orthographies are asinconsistent as that of English, this is effectively theG2P task for the particular language in question.In this paper, we demonstrate that leveragingtransliterations can, in fact, improve the grapheme-to-phoneme conversion of names.
We propose anovel system based on discriminative re-ranking thatis capable of incorporating multiple transliterations.We show that simplistic approaches to the problem399fail to achieve the same goal, and that translitera-tions from multiple languages are more helpful thanfrom a single language.
Our approach can be com-bined with any G2P system that produces n-best listsinstead of single outputs.
The experiments that weperform demonstrate significant error reduction forthree very different G2P base systems.2 Improving G2P with transliterations2.1 Problem definitionIn both G2P and machine transliteration, we are in-terested in learning a function that, given an inputsequence x, produces an output sequence y.
In theG2P task, x is composed of graphemes and y iscomposed of phonemes; in transliteration, both se-quences consist of graphemes but they represent dif-ferent writing scripts.
Unlike in machine translation,the monotonicity constraint is enforced; i.e., we as-sume that x and y can be aligned without the align-ment links crossing each other (Jiampojamarn andKondrak, 2010).
We assume that we have available abase G2P system that produces an n-best list of out-puts with a corresponding list of confidence scores.The goal is to improve the base system?s perfor-mance by applying existing transliterations of the in-put x to re-rank the system?s n-best output list.2.2 Similarity-based methodsA simple and intuitive approach to improving G2Pwith transliterations is to select from the n-best listthe output sequence that is most similar to the cor-responding transliteration.
For example, the Hinditransliteration in Figure 1 is arguably closest in per-ceptual terms to the phonetic transcription of thesecond output in the n-best list, as compared tothe other outputs.
One obvious problem with thismethod is that it ignores the relative ordering of then-best lists and their corresponding scores producedby the base system.A better approach is to combine the similarityscore with the output score from the base system, al-lowing it to contribute an estimate of confidence inits output.
For this purpose, we apply a linear combi-nation of the two scores, where a single parameter ?,ranging between zero and one, determines the rela-tive weight of the scores.
The exact value of ?
can beoptimized on a training set.
This approach is similarto the method used by Finch and Sumita (2010) tocombine the scores of two different machine translit-eration systems.2.3 Measuring similarityThe approaches presented in the previous sectioncrucially depend on a method for computing thesimilarity between various symbol sequences thatrepresent the same word.
If we have a methodof converting transliterations to phonetic represen-tations, the similarity between two sequences ofphonemes can be computed with a simple methodsuch as normalized edit distance or the longest com-mon subsequence ratio, which take into account thenumber and position of identical phonemes.
Alter-natively, we could apply a more complex approach,such as ALINE (Kondrak, 2000), which computesthe distance between pairs of phonemes.
However,the implementation of a conversion program wouldrequire ample training data or language-specific ex-pertise.A more general approach is to skip the tran-scription step and compute the similarity betweenphonemes and graphemes directly.
For example, theedit distance function can be learned from a trainingset of transliterations and their phonetic transcrip-tions (Ristad and Yianilos, 1998).
In this paper, weapply M2M-ALIGNER (Jiampojamarn et al, 2007),an unsupervised aligner, which is a many-to-manygeneralization of the learned edit distance algorithm.M2M-ALIGNER was originally designed to aligngraphemes and phonemes, but can be applied to dis-cover the alignment between any sets of symbols(given training data).
The logarithm of the probabil-ity assigned to the optimal alignment can then beinterpreted as a similarity measure between the twosequences.2.4 Discriminative re-rankingThe methods described in Section 2.2, which arebased on the similarity between outputs and translit-erations, are difficult to generalize when multipletransliterations of a single name are available.
A lin-ear combination is still possible but in this case opti-mizing the parameters would no longer be straight-forward.
Also, we are interested in utilizing otherfeatures besides sequence similarity.The SVM re-ranking paradigm offers a solution400Gershwininput/????w?n//d????
?w?n/ /d????
?w?n/n-best outputs??????
???????
??????
?transliterations (/??r??
?n/) (/?a?
?uwi?/) (/?er?vin/)Figure 1: An example name showing the data used for feature construction.
Each arrow links a pair used to generatefeatures, including n-gram and score features.
The score features use similarity scores for transliteration-transcriptionpairs and system output scores for input-output pairs.
One feature vector is constructed for each system output.to the problem.
Our re-ranking system is informedby a large number of features, which are based onscores and n-grams.
The scores are of three types:1.
The scores produced by the base system foreach output in the n-best list.2.
The similarity scores between the outputs andeach available transliteration.3.
The differences between scores in the n-bestlists for both (1) and (2).Our set of binary n-gram features includes thoseused for DIRECTL+ (Jiampojamarn et al, 2010).They can be divided into four types:1.
The context features combine output symbols(phonemes) with n-grams of varying sizes in awindow of size c centred around a correspond-ing position on the input side.2.
The transition features are bigrams on the out-put (phoneme) side.3.
The linear chain features combine the contextfeatures with the bigram transition features.4.
The joint n-gram features are n-grams contain-ing both input and output symbols.We apply the features in a new way: instead of be-ing applied strictly to a given input-output set, weexpand their use across many languages and use allof them simultaneously.
We apply the n-gram fea-tures across all transliteration-transcription pairs inaddition to the usual input-output pairs correspond-ing to the n-best lists.
Figure 1 illustrates the set ofpairs used for feature generation.In this paper, we augment the n-gram features bya set of reverse features.
Unlike a traditional G2Pgenerator, our re-ranker has access to the outputsproduced by the base system.
By swapping the inputand the output side, we can add reverse context andlinear-chain features.
Since the n-gram features arealso applied to transliteration-transcription pairs, thereverse features enable us to include features whichbind a variety of n-grams in the transliteration stringwith a single corresponding phoneme.The construction of n-gram features presupposesa fixed alignment between the input and output se-quences.
If the base G2P system does not provideinput-output alignments, we use M2M-ALIGNERfor this purpose.
The transliteration-transcriptionpairs are also aligned by M2M-ALIGNER, which atthe same time produces the corresponding similarityscores.
(We set a lower limit of -100 on the M2M-ALIGNER scores.)
If M2M-ALIGNER is unable toproduce an alignment, we indicate this with a binaryfeature that is included with the n-gram features.3 ExperimentsWe perform several experiments to evaluate ourtransliteration-informed approaches.
We test simple401similarity-based approaches on single-transliterationdata, and evaluate our SVM re-ranking approachagainst this as well.
We then test our approach us-ing all available transliterations.
Relevant code andscripts required to reproduce our experimental re-sults are available online1.3.1 Data & setupFor pronunciation data, we extracted all names fromthe Combilex corpus (Richmond et al, 2009).
Wediscarded all diacritics, duplicates and multi-wordnames, which yielded 10,084 unique names.
Boththe similarity and SVM methods require transliter-ations for identifying the best candidates in the n-best lists.
They are therefore trained and evaluatedon the subset of the G2P corpus for which transliter-ations available.
Naturally, allowing transliterationsfrom all languages results in a larger corpus than theone obtained by the intersection with transliterationsfrom a single language.For our experiments, we split the data into 10%for testing, 10% for development, and 80% fortraining.
The development set was used for initialtests and experiments, and then for our final resultsthe training and development sets were combinedinto one set for final system training.
For SVM re-ranking, during both development and testing wesplit the training set into 10 folds; this is necessarywhen training the re-ranker as it must have systemoutput scores that are representative of the scores onunseen data.
We ensured that there was never anyoverlap between the training and testing data for alltrained systems.Our transliteration data come from the sharedtasks on transliteration at the 2009 and 2010 NamedEntities Workshops (Li et al, 2009a; Li et al, 2010).We use all of the 2010 English-source data plus theEnglish-to-Russian data from 2009, which makesnine languages in total.
In cases where the dataprovide alternative transliterations for a given in-put, we keep only one; our preliminary experimentsindicated that including alternative transliterationsdid not improve performance.
It should be notedthat these transliteration corpora are noisy: Jiampo-jamarn et al (2009) note a significant increase in1http://www.cs.ualberta.ca/?ab31/g2p-tl-rrLanguage Corpus size OverlapBengali 12,785 1,840Chinese 37,753 4,713Hindi 12,383 2,179Japanese 26,206 4,773Kannada 10,543 1,918Korean 6,761 3,015Russian 6,447 487Tamil 10,646 1,922Thai 27,023 5,436Table 1: The number of unique single-word entries in thetransliteration corpora for each language and the amountof common data (overlap) with the pronunciation data.English-to-Hindi transliteration performance with asimple cleaning of the data.Our tests involving transliterations from multiplelanguages are performed on the set of names forwhich we have both the pronunciation and translit-eration data.
There are 7,423 names in the G2P cor-pus for which at least one transliteration is available.Table 1 lists the total size of the transliteration cor-pora as well as the amount of overlap with the G2Pdata.
Note that the base G2P systems are trained us-ing all 10,084 names in the corpus as opposed toonly the 7,423 names for which there are transliter-ations available.
This ensures that the G2P systemshave more training data to provide the best possiblebase performance.For our single-language experiments, we normal-ize the various scores when tuning the linear com-bination parameter ?
so that we can compare valuesacross different experimental conditions.
For SVMre-ranking, we directly implement the method ofJoachims (2002) to convert the re-ranking probleminto a classification problem, and then use the veryfast LIBLINEAR (Fan et al, 2008) to build the SVMmodels.
Optimal hyperparameter values were deter-mined during development.We evaluate using word accuracy, the percentageof words for which the pronunciations are correctlypredicted.
This measure marks pronunciations thatare even slightly different from the correct one as in-correct, so even a small change in pronunciation thatmight be acceptable or even unnoticeable to humanswould count against the system?s performance.4023.2 Base systemsIt is important to test multiple base systems in orderto ensure that any gain in performance applies to thetask in general and not just to a particular system.We use three G2P systems in our tests:1.
FESTIVAL (FEST), a popular speech synthe-sis package, which implements G2P conver-sion with CARTs (decision trees) (Black et al,1998).2.
SEQUITUR (SEQ), a generative system basedon the joint n-gram approach (Bisani and Ney,2008).3.
DIRECTL+ (DTL), the discriminative systemon which our n-gram features are based (Ji-ampojamarn et al, 2010).All systems are capable of providing n-best outputlists along with scores for each output, although forFESTIVAL they had to be constructed from the listof output probabilities for each input character.We run DIRECTL+ with all of the features de-scribed in (Jiampojamarn et al, 2010) (i.e., contextfeatures, transition features, linear chain features,and joint n-gram features).
System parameters, suchas maximum number of iterations, were determinedduring development.
For SEQUITUR, we keep de-fault options except for the enabling of the 10 bestoutputs and we convert the probabilities assigned tothe outputs to log-probabilities.
We set SEQUITUR?sjoint n-gram order to 6 (this was also determinedduring development).Note that the three base systems differ slightly interms of the alignment information that they pro-vide in their outputs.
FESTIVAL operates letter-by-letter, so we use the single-letter inputs with thephoneme outputs as the aligned units.
DIRECTL+specifies many-to-many alignments in its output.
ForSEQUITUR, however, since it provides no informa-tion regarding the output structure, we use M2M-ALIGNER to induce alignments for n-gram featuregeneration.3.3 Transliterations from a single languageThe goal of the first experiment is to compare sev-eral similarity-based methods, and to determine howthey compare to our re-ranking approach.
In order tofind the similarity between phonetic transcriptions,we use the two different methods described in Sec-tion 2.2: ALINE and M2M-ALIGNER.
We furthertest the use of a linear combination of the similar-ity scores with the base system?s score so that itsconfidence information can be taken into account;the linear combination weight is determined fromthe training set.
These methods are referred to asALINE+BASE and M2M+BASE.
For these experi-ments, our training and testing sets are obtained byintersecting our G2P training and testing sets respec-tively with the Hindi transliteration corpus, yielding1,950 names for training and 229 names for testing.Since the similarity-based methods are designedto incorporate homogeneous same-script translitera-tions, we can only run this experiment on one lan-guage at a time.
Furthermore, ALINE operates onphoneme sequences, so we first need to convert thetransliterations to phonemes.
An alternative wouldbe to train a proper G2P system, but this would re-quire a large set of word-pronunciation pairs.
Forthis experiment, we choose Hindi, for which weconstructed a rule-based G2P converter.
Aside fromsimple one-to-one mapping (romanization) rules,the converter has about ten rules to adjust for con-text.For these experiments, we apply our SVM re-ranking method in two ways:1.
Using only Hindi transliterations (referred to asSVM-HINDI).2.
Using all available languages (referred to asSVM-ALL).In both cases, the test set is restricted to the same229 names, in order to provide a valid comparison.Table 2 presents the results.
Regardless of thechoice of the similarity function, the simplest ap-proaches fail in a spectacular manner, significantlyreducing the accuracy with respect to the base sys-tem.
The linear combination methods give mixed re-sults, improving the accuracy for FESTIVAL but notfor SEQUITUR or DIRECTL+ (although the differ-ences are not statistically significant).
However, theyperform much better than the methods based on sim-ilarity scores alone as they are able to take advan-tage of the base system?s output scores.
If we lookat the values of ?
that provide the best performance403Base systemFEST SEQ DTLBase 58.1 67.3 71.6ALINE 28.0 26.6 27.5M2M 39.3 36.2 36.2ALINE+BASE 58.5 65.9 71.2M2M+BASE 58.5 66.4 70.3SVM-HINDI 63.3 69.0 69.9SVM-ALL 68.6 72.5 75.6Table 2: Word accuracy (in percentages) of various meth-ods when only Hindi transliterations are used.on the training set, we find that they are higher forthe stronger base systems, indicating more relianceon the base system output scores.
For example,for ALINE+BASE the FESTIVAL-based system has?
= 0.58 whereas the DIRECTL+-based system has?
= 0.81.
Counter-intuitively, the ALINE+BASEand M2M+BASE methods are unable to improveupon SEQUITUR or DIRECTL+.
We would expectto achieve at least the base system?s performance,but disparities between the training and testing setsprevent this.The two SVM-based methods achieve much bet-ter results.
SVM-ALL produces impressive accu-racy gains for all three base systems, while SVM-HINDI yields smaller (but still statistically signifi-cant) improvements for FESTIVAL and SEQUITUR.These results suggest that our re-ranking methodprovides a bigger boost to systems built with dif-ferent design principles than to DIRECTL+ whichutilizes a similar set of features.
On the other hand,the results also show that the information obtainedby consulting a single transliteration may be insuf-ficient to improve an already high-performing G2Pconverter.3.4 Transliterations from multiple languagesOur second experiment expands upon the first; weuse all available transliterations instead of being re-stricted to one language.
This rules out the sim-ple similarity-based approaches, but allows us totest our re-ranking approach in a way that fully uti-lizes the available data.
We test three variants of ourtransliteration-informed SVM re-ranking approach,Base systemFEST SEQ DTLBase 55.3 66.5 70.8SVM-SCORE 62.1 68.4 71.0SVM-N-GRAM 66.2 72.5 73.8SVM-ALL 67.2 73.4 74.3Table 3: Word accuracy of the base system versus the re-ranking variants with transliterations from multiple lan-guages.which differ with respect to the set of included fea-tures:1.
SVM-SCORE includes only the three types ofscore features described in Section 2.4.2.
SVM-N-GRAM uses only the n-gram features.3.
SVM-ALL is the full system that combines thescore and n-gram features.The objective is to determine the degree to whicheach of the feature classes contributes to the overallresults.
Because we are using all available transliter-ations, we achieve much greater coverage over ourG2P data than in the previous experiment; in thiscase, our training set consists of 6,660 names whilethe test set has 763 names.Table 3 presents the results.
Note that the base-line accuracies are somewhat lower than in Table 2because of the different test set.
We find that, whenusing all features, the SVM re-ranker can providea very impressive error reduction over FESTIVAL(26.7%) and SEQUITUR (20.7%) and a smaller butstill significant (p < 0.01 with the McNemar test)error reduction over DIRECTL+ (12.1%).When we consider our results using only the scoreand n-gram features, we can see that, interestingly,the n-gram features are most important.
We drawa further conclusion from our results: consider thelarge disparity in improvements over the base sys-tems.
This indicates that FESTIVAL and SEQUITURare benefiting from the DIRECTL+-style featuresused in the re-ranking.
Without the n-gram fea-tures, however, there is still a significant improve-ment over FESTIVAL, demonstrating that the scoresdo provide useful information.
In this case there is404no way for DIRECTL+-style information to makeits way into the re-ranking; the process is basedpurely on the transliterations and their similaritieswith the transcriptions in the output lists, indicat-ing that the system is capable of extracting use-ful information directly from transliterations.
In thecase of DIRECTL+, the transliterations help throughthe n-gram features rather than the score features;this is probably because the crucial feature thatsignals the inability of M2M-ALIGNER to align agiven transliteration-transcription pair belongs to theset of the n-gram features.
Both the n-gram fea-tures and score features are dependent on the align-ments, but they differ in that the n-gram featuresallow weights to be learned for local n-gram pairswhereas the score features are based on global infor-mation, providing only a single feature for a giventransliteration-transcription pair.
The two thereforeoverlap to some degree, although the score fea-tures still provide useful information via probabili-ties learned during the alignment training process.A closer look at the results provides additionalinsight into the operation of our re-ranking system.For example, consider the name Bacchus, which DI-RECTL+ incorrectly converts into /b?k?@s/.
Themost likely reason why our re-ranker selects insteadthe correct pronunciation /b?k@s/ is that M2M-ALIGNER fails to align three of the five availabletransliterations with /b?k?@s/.
Such alignment fail-ures are caused by a lack of evidence for the map-ping of the grapheme representing the sound /k/in the transliteration training data with the phoneme/?/.
In addition, the lack of alignments prevents anyn-gram features from being enabled.Considering the difficulty of the task, the top ac-curacy of almost 75% is quite impressive.
In fact,many instances of human transliterations in our cor-pora are clearly incorrect.
For example, the Hinditransliteration of Bacchus contains the /?/ conso-nant instead of the correct /k/.
Moreover, our strictevaluation based on word accuracy counts all sys-tem outputs that fail to exactly match the dictio-nary data as errors.
The differences are often veryminor and may reflect an alternative pronunciation.The phoneme accuracy2 of our best result is 93.1%,2The phoneme accuracy is calculated from the minimumedit distance between the predicted and correct pronunciations.# TL # Entries Improvement?
1 111 0.9?
2 266 3.0?
3 398 3.8?
4 536 3.2?
5 619 2.8?
6 685 3.4?
7 732 3.7?
8 762 3.5?
9 763 3.5Table 4: Absolute improvement in word accuracy (%)over the base system (DIRECTL+) of the SVM re-rankerfor various numbers of available transliterations.which provides some idea of how similar the pre-dicted pronunciation is to the correct one.3.5 Effect of multiple transliterationsOne motivating factor for the use of SVM re-rankingwas the ability to incorporate multiple transliterationlanguages.
But how important is it to use more thanone language?
To examine this question, we lookparticularly at the sets of names having at most ktransliterations available.
Table 4 shows the resultswith DIRECTL+ as the base system.
Note that thenumber of names with more than five transliterationswas small.
Importantly, we see that the increase inperformance when only one transliteration is avail-able is so small as to be insignificant.
From this, wecan conclude that obtaining improvement on the ba-sis of a single transliteration is difficult in general.This corroborates the results of the experiment de-scribed in Section 3.3, where we used only Hinditransliterations.4 Previous workThere are three lines of research that are relevant toour work: (1) G2P in general; (2) G2P on names; and(3) combining diverse data sources and/or systems.The two leading approaches to G2P are repre-sented by SEQUITUR (Bisani and Ney, 2008) andDIRECTL+ (Jiampojamarn et al, 2010).
Recentcomparisons suggests that the former obtains some-what higher accuracy, especially when it includesjoint n-gram features (Jiampojamarn et al, 2010).Systems based on decision trees are far behind.
Our405results confirm this ranking.Names can present a particular challenge to G2Psystems.
Kienappel and Kneser (2001) reported ahigher error rate for German names than for generalwords, while on the other hand Black et al (1998)report similar accuracy on names as for other typesof English words.
Yang et al (2006) and van denHeuvel et al (2007) post-process the output of ageneral G2P system with name-specific phoneme-to-phoneme (P2P) systems.
They find significant im-provement using this method on data sets consistingof Dutch first names, family names, and geograph-ical names.
However, it is unclear whether such anapproach would be able to improve the performanceof the current state-of-the-art G2P systems.
In addi-tion, the P2P approach works only on single outputs,whereas our re-ranking approach is designed to han-dle n-best output lists.Although our approach is (to the best of ourknowledge) the first to use different tasks (G2P andtransliteration) to inform each other, this is concep-tually similar to model and system combination ap-proaches.
In statistical machine translation (SMT),methods that incorporate translations from other lan-guages (Cohn and Lapata, 2007) have proven effec-tive in low-resource situations: when phrase trans-lations are unavailable for a certain language, onecan look at other languages where the translationis available and then translate from that language.A similar pivoting approach has also been appliedto machine transliteration (Zhang et al, 2010).
No-tably, the focus of these works have been on cases inwhich there are less data available; they also modifythe generation process directly, rather than operatingon existing outputs as we do.
Ultimately, a combina-tion of the two approaches is likely to give the bestresults.Finch and Sumita (2010) combine two very dif-ferent approaches to transliteration using simple lin-ear interpolation: they use SEQUITUR?s n-best out-puts and re-rank them using a linear combinationof the original SEQUITUR score and the score forthat output of a phrased-based SMT system.
The lin-ear weights are hand-tuned.
We similarly use linearcombinations, but with many more scores and otherfeatures, necessitating the use of SVMs to determinethe weights.
Importantly, we combine different datatypes where they combine different systems.5 Conclusions & future workIn this paper, we explored the application of translit-erations to G2P.
We demonstrated that transliter-ations have the potential for helping choose be-tween n-best output lists provided by standard G2Psystems.
Simple approaches based solely on sim-ilarity do not work when tested using a singletransliteration language (Hindi), necessitating theuse of smarter methods that can incorporate mul-tiple transliteration languages.
We apply SVM re-ranking to this task, enabling us to use a varietyof features based not only on similarity scores buton n-grams as well.
Our method shows impressiveerror reductions over the popular FESTIVAL sys-tem and the generative joint n-gram SEQUITUR sys-tem.
We also find significant error reduction usingthe state-of-the-art DIRECTL+ system.
Our analy-sis demonstrated that it is essential to provide there-ranking system with transliterations from multi-ple languages in order to mitigate the differencesbetween phonological inventories and smooth outnoise in the transliterations.In the future, we plan to generalize our approachso that it can be applied to the task of generatingtransliterations, and to combine data from distinctG2P dictionaries.
The latter task is related to the no-tion of domain adaptation.
We would also like to ap-ply our approach to web data; we have shown that itis possible to use noisy transliteration data, so it maybe possible to leverage the noisy ad hoc pronuncia-tion data as well.
Finally, we plan to investigate ear-lier integration of such external information into theG2P process for single systems; while we noted thatre-ranking provides a general approach applicable toany system that can generate n-best lists, there is alimit as to what re-ranking can do, as it relies on thecorrect output existing in the n-best list.
Modifyingexisting systems would provide greater potential forimproving results even though the changes would benecessarily system-specific.AcknowledgementsWe are grateful to Sittichai Jiampojamarn and ShaneBergsma for the very helpful discussions.
This re-search was supported by the Natural Sciences andEngineering Research Council of Canada.406ReferencesMaximilian Bisani and Hermann Ney.
2008.
Joint-sequence models for grapheme-to-phoneme conver-sion.
Speech Communication, 50(5):434?451, May.Alan W. Black, Kevin Lenzo, and Vincent Pagel.
1998.Issues in building general letter to sound rules.
In TheThird ESCA/COCOSDA Workshop (ETRW) on SpeechSynthesis, Jenolan Caves House, Blue Mountains, NewSouth Wales, Australia, November.Trevor Cohn and Mirella Lapata.
2007.
Machine trans-lation by triangulation: Making effective use of multi-parallel corpora.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics, pages 728?735, Prague, Czech Republic, June.Association for Computational Linguistics.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A li-brary for large linear classification.
Journal of Ma-chine Learning Research, 9:1871?1874.Andrew Finch and Eiichiro Sumita.
2010.
Translitera-tion using a phrase-based statistical machine transla-tion system to re-score the output of a joint multigrammodel.
In Proceedings of the 2010 Named EntitiesWorkshop (NEWS 2010), pages 48?52, Uppsala, Swe-den, July.
Association for Computational Linguistics.Sittichai Jiampojamarn and Grzegorz Kondrak.
2010.Letter-phoneme alignment: An exploration.
In Pro-ceedings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics, pages 780?788,Uppsala, Sweden, July.
Association for ComputationalLinguistics.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden Markov models to letter-to-phoneme con-version.
In Human Language Technologies 2007: TheConference of the North American Chapter of the As-sociation for Computational Linguistics; Proceedingsof the Main Conference, pages 372?379, Rochester,New York, USA, April.
Association for ComputationalLinguistics.Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou,Kenneth Dwyer, and Grzegorz Kondrak.
2009.
Di-recTL: a language independent approach to translitera-tion.
In Proceedings of the 2009 Named Entities Work-shop: Shared Task on Transliteration (NEWS 2009),pages 28?31, Suntec, Singapore, August.
Associationfor Computational Linguistics.Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kon-drak.
2010.
Integrating joint n-gram features into adiscriminative training framework.
In Human Lan-guage Technologies: The 2010 Annual Conference ofthe North American Chapter of the Association forComputational Linguistics, pages 697?700, Los An-geles, California, USA, June.
Association for Compu-tational Linguistics.Thorsten Joachims.
2002.
Optimizing search engines us-ing clickthrough data.
In Proceedings of the EighthACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, pages 133?142, Ed-monton, Alberta, Canada.
Association for ComputingMachinery.Anne K. Kienappel and Reinhard Kneser.
2001.
De-signing very compact decision trees for grapheme-to-phoneme transcription.
In EUROSPEECH-2001,pages 1911?1914, Aalborg, Denmark, September.Grzegorz Kondrak.
2000.
A new algorithm for thealignment of phonetic sequences.
In Proceedings ofthe First Meeting of the North American Chapter ofthe Association for Computational Linguistics, pages288?295, Seattle, Washington, USA, April.Haizhou Li, A Kumaran, Vladimir Pervouchine, and MinZhang.
2009a.
Report of NEWS 2009 machinetransliteration shared task.
In Proceedings of the 2009Named Entities Workshop: Shared Task on Transliter-ation (NEWS 2009), pages 1?18, Suntec, Singapore,August.
Association for Computational Linguistics.Haizhou Li, A Kumaran, Min Zhang, and Vladimir Per-vouchine.
2009b.
Whitepaper of NEWS 2009 ma-chine transliteration shared task.
In Proceedingsof the 2009 Named Entities Workshop: Shared Taskon Transliteration (NEWS 2009), pages 19?26, Sun-tec, Singapore, August.
Association for ComputationalLinguistics.Haizhou Li, A Kumaran, Min Zhang, and Vladimir Per-vouchine.
2010.
Report of NEWS 2010 transliterationgeneration shared task.
In Proceedings of the 2010Named Entities Workshop (NEWS 2010), pages 1?11,Uppsala, Sweden, July.
Association for ComputationalLinguistics.Korin Richmond, Robert Clark, and Sue Fitt.
2009.
Ro-bust LTS rules with the Combilex speech technologylexicon.
In Proceedings of Interspeech, pages 1295?1298, Brighton, UK, September.Eric Sven Ristad and Peter N. Yianilos.
1998.
Learn-ing string edit distance.
IEEE Transactions on PatternRecognition and Machine Intelligence, 20(5):522?532, May.Henk van den Heuvel, Jean-Pierre Martens, and NannekeKonings.
2007.
G2P conversion of names.
what canwe do (better)?
In Proceedings of Interspeech, pages1773?1776, Antwerp, Belgium, August.Qian Yang, Jean-Pierre Martens, Nanneke Konings, andHenk van den Heuvel.
2006.
Development of aphoneme-to-phoneme (p2p) converter to improve thegrapheme-to-phoneme (g2p) conversion of names.
In407Proceedings of the 2006 International Conference onLanguage Resources and Evaluation, pages 2570?2573, Genoa, Italy, May.Min Zhang, Xiangyu Duan, Vladimir Pervouchine, andHaizhou Li.
2010.
Machine transliteration: Leverag-ing on third languages.
In Coling 2010: Posters, pages1444?1452, Beijing, China, August.
Coling 2010 Or-ganizing Committee.408
