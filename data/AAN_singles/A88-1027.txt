TIlE EXPERIENCE OF DEVELOPING A LARGE-SCALENATURAL LANGUAGE TEXT PROCFASSING SYSTEM: CRITIQUEStephen D. Richardson and Lisa C. Braden-HarderIBM Thomas J. Watson Research CenterP.O.
Box 704Yorktown Heights, New York 10598AbstractThis paper describes our experience in devel-oping the CRITIQUE system.
It describes threeapplication areas in which the system is beingused and discusses some characteristics ofCRITIQUE which we believe are applicable tolarge-scale natural language systems in general:performance, robustness, flexibility, presentation,and accuracy.IntroductionCRITIQUE is a large-scale natural anguagetext processing system that identifies grammarand style errors in English text.
This advancedprototype, which is currently being developed atIBM Research, is based on a broad-coverage na-tural language parser (Richardson, 1985).
Theparser provides a unique approximate syntacticparse for a large percentage of English text anddiagnoses over 100 grammar and style errors.Earlier writing-aid systems, such as Writer'sWorkbench (Macdonald, et al 1982), containfunctions which identify parts-of-speech ofwords, perform string-level phrase identification,and generate readability statistics.
Similar func-tions are apparent in many systems now com-mercially available, some of which are describedin an issue of The SeyboM Report (1984).
To ourknowledge, however, no other system uses aparser that produces complete structural analysesfor sentences.CRITIQUE is an extension of the EPISTLEproject which began in 1980 (Heidom, et al1982).
The parser and grammar are implementedin PLNLP (the Programming Language for Na-tural language Processing), developed by GeorgeHeidom.
PEG (the PLNLP English Grammar)has been written by Karen Jensen, and the stylerules were written by Yael Ravin.
Today,CRITIQUE is being tested in a variety of appli-cations ranging from office correspondence andtechnical documentation to student essays.
Also,PLNLP and PEG have been incorporated intoseveral other research applications, such as ma-chine translation systems.At the 1986 A('L meeting, Gary Hendrix de-scribed his experience in developing a naturallanguage interface for real users (Hendrix, 1986).In contrast with user interface systems, we con-sider CRITIQUE to be a text processing system.The latter may be distinguished from the formerby its broad coverage of texts that were preparedindependently to communicate ideas and notstrictly to interact with a computer system.
Untilnow, the experience of developing a large-scalenatural language text processing system has notbeen discussed in the literature.This paper first describes the overall process-ing in the CRITIQUE system.
Then it describesthree application areas in which the system isbeing used.
The remaining sections discuss omecharacteristics of CRITIQUE which we believeare applicable to large-scale natural languagesystems in general: performance, robustness,flexibility, presentation, and accuracy.
The dis-cussion draws on our experience in all three ap-plication areas.Processing in CR IT IQUECRITIQUE processes text in six steps.
Thefirst step determines sentence, heading, and par-agraph boundaries.
In the next step, lexicalprocessing identifies unrecognized words andawkward phrases.
The on-line dictionary whichis used includes more than 100,000 entries andprovides information used in syntactic processingas well.
After lexical analysis, text is passed tothe parser, which produces a parse tree, and inso doing checks for grammar errors.
Thenstylistic analysis diagnoses potential style prob-195lems.
CRITIQUE also generates tatistical in-formation about documents based on the lexicaland syntactic analyses.
The final step involveserror summarization and display.CRITIQUE has an interactive processingmode that is fully integrated with a text editor,allowing users to update the text as needed.
Asthe text is modified, new sentences are re-analyzed to ensure that no new errors have beenintroduced.
The system provides three levels ofon-line help: the first level identifies the error, thesecond provides a brief explanation, and the thirdprovides a complete tutorial.
Figure 1 is an il-lustration of the second level of help.
The usercan also specify style preferences in an individualprofde.
Possible errors are filtered through theprofde to determine whether or not they shouldbe displayed.
Ilard-copy output is also available.!
am writing to recommend Susan llayes,who's application you recently received.I Confusion of #who's" and #whose"whoseThe word "who's" (which means"who is') and the word "whose"(which ~ possessive) cannotbe interchanged.Figure 1.
Second level of Help includesname of error, suggestedcorrection, and a brief explanationApplication Areas for CRITIQUEDuring the development of CRrI' IQUE, wehave directed our efforts towards three majorapplication areas: office environments, publica-tions organizations, and educational institutions.Each area has its own particular needs and re-quirements.In the office environment, professionals re-quire quick, succinct feedback on their memosand other documents.
They are less interested inmaintaining a particular style, but want insuranceagainst obvious grammatical and spelling mis-takes.
Our parsing grammar was originally de-veloped using a data base of officecorrespondence.
There has also been an abun-dance of feedback at IBM Research, where thesystem has been made available to hundreds ofusers.
These users submitted over 3,000 pages oftext to CRrI ' IQUE in 1987.Publications organizations usually have strictrequirements for style and consistency which ex-ist in the form of tedious style guides.
The pro-fessional writers in such organizations also wantsuccinct feedback, but are usually willing to waitlonger to receive it, since their documents aretypically longer and more involved.
An IBMtechnical writing group and the US governmenthave been our source of experience and feedbackin this area.Use by educational institutions has proven tobe the most challenging of the three areas.
Thereis a wide range of ill-formed text to deal with,originating from classes in composition, businesswriting, technical writing, and ESI, (English as aSecond language).
The professors in these vari-ous areas also sometimes have differing opinionson grammar and style.
Although there may notbe such a great need for quick processing time(except by those students who procrastinate),processing cost must be minimized to fit mostuniversity budgets.
We currently are doing jointstudies with three universities to help test andrefine CRITIQUE.PerformanceBroad-coverage natural language processingis computationaily expensive.
To do it in realtime is even more so.
Whereas large offices andpublications organizations may be able to affordextensive computing power, such is not the casein many of the environments where a systemsuch as CRITIQUF, would be most useful.Althougla ('RITIQI.IE has been developed ina large IBM-mainframe environment, severalsignificant steps have been taken to improve itsperformance with a view toward running onmuch smaller machines.
In addition, a versionof the PI,NI,P parser on which CRrI ' IQUE isbased was successfully ported to an IBM PC inthe summer of 1986.
Work is continuing on otherversions which would run the complete PLNLPEnglish Grammar (PEG) on intelligent work-stations uch as the IBM RT PC and PS/2.We have used two complimentary approachesto achieve satisfactory performance.
One is todistribute the parts of the system which can run196in parallel over multiple processors (where avail-able), and the other is to optimize the perform-ance of the programs themselves.To distribute the processing involved, wehave used "parsing server" programs which mayoperate either on the same physical computer,or on several computers connected by a network.When CRITIQUE is invoked by a user, eachsentence in the user's document is sent as a sep-arate task to a "manager server" which then dis-tributes uch tasks to as many parsing servers asare available.
After analysis, information about asentence is returned via the manager server to theuser's editing environment.
With this scheme,multiple users can access multiple parsing serversthat may reside on different computers linked bya network.
In this way, several of a user's sen-tences may be processed in parallel and asyn-chronously with respect o other tasks (such asword processing) that the user may be doing.Although this distributed processing systemis currently implemented on a network ofmainframes, the transition to a workstation-based network like those found in small busi-nesses and university environments will not bedifficult.
The distributed architecture is also wellsuited to exploit the power of parallel processormachines currently under development.
Thegranularity of the processing involved, which isnow at the sentence level, may also be madesmaller or larger, depending on resulting effi-ciency and the possible need to consider largersegments of text for a more complete analysis.The parsing servers referred to above consistof the PLNLP parsing engine, the PLNLP Eng-lish Grammar, and a large set of style rules.PLNLP supports the writing of procedures aswell as rules.
Consequently, the parsing engineitself is written as a set of PLNLP procedures.
Inaddition to the run-time nvironment, the trans-lator for the PLNLP language is also written us-ing PLNLP.
When an entire programminglanguage system such as this is written in itself, ahigh degree of portability and language-specificoptimization may be achieved, further enhancingoverall system performance.The PLNLP translator currently turnsPLNLP rules and procedures into LISP or PL.8(a highly-optimized PI,/I variant) code which isthen compiled and executed.
Work has also been197done using C as a base (for the PC version men-tioned earlier), and this work will be extended forportability across computers.
Direct compilationinto machine code is also being considered.In our experience with various programminglanguages and environments, we have found itdesirable to maintain two versions of the system,which share the same PLNLP source code.
Oneis geared toward grammar and style rule devel-opment, being somewhat slower, but very flexi-ble, and containing a set of specially designedtools and development aids.
This version of thesystem now runs in LISP.
The other version,running in PL.8, is optimized for fast executionand is about ten times faster than the develop-ment version.
CRITIQUE uses the PL.8 ver-sion, which can analyze a sentence of about15-20 words in one CPU second on an IBM3081 computer.
This translates into a few sec-onds of elapsed time under an average load.Even as computers become more powerful,there will continue to be a corresponding increasein the complexity and amount of computationinvolved in natural language processing.
Throughuse of a highly-optimized production run-timeenvironment, PLNLP is able to achieve the re-quired performance without sacrificing flexibilityduring development.One last performance issue should be men-tioned: the need for a well-integrated dictionarysystem.
As previously stated, CRITIQUE's dic-tionary is able to recognize well over 100,000words, providing both morphological nd syn-tactic information about those words.
Thetrade-offs between keeping the dictionary on diskor in memory are more significant in a verylarge-scale system.
Disk I/O's, including "hid-den" paging I/O's when the dictionary is in vir-tual memory, must be carefully considered andminimized.
It has been our experience that ex-pensive dynamic morphological processingshould also be kept to a minimum, although thismay not be possible for other languages.RobustnessAny computer system should be robust.
Thisis especially true of natural language systems,and, in particular, those which specialize in han-dling ill-formed input.
Robustness hould beconsidered at every level of processing, both forthe system in general and for the particulars ofdealing with natural anguage inputs.At the system level, the distributed architec-ture which is used by CRITIQUE for perform-ance reasons requires robust task managementmechanisms.
The manager server carefully tracksthe progress of each task (sentence) and theavailability of parser servers on the network.
If aparser loses its network connection, exceeds apredetermined time limit, or otherwise fails whileprocessing a task, that task is sent out again toanother parser.
If a parser fails while processinga task, it automatically restarts itself.
Statisticsconcerning usage and task flow, as well as com-ments recorded by users about the usefulness oraccuracy of critique information, are maintainedby the manager server and automatically distrib-uted to system developers each day.At the natural anguage level, robustness firstcomes into play in handling the various formatsof text inputted to the system.
Text which hasbeen "manually" formatted (using an editor,"WYSIWYG" style), as well as text with imbed-ded formatting commands (IBM's SCRIPT andGML commands are currently supported) isscanned by CRITIQUE to identify "parsable"segments.
This process excludes tables, figures,headings, addresses, etc., and is table driven toaccommodate he varying requirements of usersin the different application areas.
Publicationsorganizations, for example, typically have specialadditional sets of formatting commands thatmust be supported.During parsing, words which are not in thedictionary are assigned efault morphological ndsyntactic information so as to avoid a parsingfailure.
Most such words are generally assumedto be singular nouns, although there are someexceptions.
This is usually adequate to obtain areasonable parse, but can cause problems whenit is a verb that is misspelled.Parsing may take place in one pass or two, ifnecessary.
The fu'st pass applies the rules of thegrammar with all of the constraints in force.
Ifa parse is not obtained, then a second pass ismade, applying the rules with selected constraintsbeing relaxed.
Certain lexical substitution rulesfor easily confused words (e.g., whose/who's,its/it's) are also activated uring the second pass.If a parse is still not obtained after the second198pass, whether because of an unanticipated error,an unrecognized word, or a possible weakness inthe grammar, then the "parse fitting" procedureis invoked (Jensen, et al 1984).
This procedurerelies on the fact that the parsing algorithm isbottom-up in nature, and therefore intermediatewell-formed parse structures are produced forsegments of the sentence.
These structures maybe "fitted" together to form a parse for the sen-tence if no other complete structure is found.Even when a fitted parse is obtained, grammarand style error detection is still active within thesuccessfully parsed segments.If multiple parses are obtained, the systemselects one based on a parse metric which favorstrees in which modifying words and phrases areattached to the closest qualifying constituent(tleidom, 1982).
If the number of parses ob-tained exceeds a certain threshold, CRITIQUEtakes advantage of the situation and informs theuser that the sentence is probably unclear.
If theparser fails for some system reason, the user willreceive a message that the segment of text inquestion was "too difficult to process.
"No one can foresee all the errors that humanscan make.
It is for this reason that we have in-cluded these robust mechanisms, and that wecontinue to enhance the system to catch new er-rors as experience and feedback dictate.FlexibilityBy virtue of the significantly different needsof each application area listed earlier, flexibilityhas been a requirement throughout the develop-ment of CRITIQUE.
For example, the publi-cation organizations we have dealt with haverequired large additions of terminology, the han-dling of special input formats and formattingcommands, and additional style critiques dictatedby organizational style guidelines.
Universities,being pedagogically oriented, have been verymuch concerned with the format and content ofthe critique information presented in the output.We have attempted to handle the need for thisflexibility at the individual, installation, and ap-plication area levels.The basic CRITIQUE system provides pre-determined critiques, intuitively organized intogroups, with default hresholds, if applicable, andgeneral help and tutorial information.
It handlesthe formats of files by default according to certainfile naming conventions.
The vocabulary in thedictionary comes mainly from Webster's 7thCollegiate dictionary, and the grammar and styleerror rules have been developed according to se-veral widely accepted sources.
Every item of in-formation produced by the system is controlledby a switch or threshold contained in a userprofde.
We have found that a good set of de-faults in this profde is indispensable, since mostusers often do not bother to change them.Individuals who use the system are free tochange any of the settings in the profile accordingto their own tastes and needs.
They may alsoadd words to an addendum which is used solelyfor the purpose of checking spelling.Knowledgeable users, or, more commonly,installation administrators, may change the de-fault settings in the system profile or create se-veral profdes for different purposes.
Such wouldbe the case for university classes of different typesor various publications groups, each with its ownparticular style requirements.
This level ofcustomization also includes changing the group-ing of critiques and the associated code (used bythe system to flag the occurrence of an error inthe output), message, help, and tutorial informa-tion, and making large additions of specializedterminology to the system dictionary.
Newclasses of word- and phrase-level rrors may beadded to the dictionary as well.Users at some of our test sites have requestedthe ability to add classes of style errors.
This isnot currently possible, because they would haveto be able to write their own PLNLP rules.
Fornow, further types of customization, for entireapplication areas, for example, are performed bythe system developers, although there is contin-ual re-evaluation of where to draw the line.It is important to point out that the kinds ofsystem customization described above have not,thus far, included tuning the grammar for specialhandling of the texts common in a particular ap-plication area.
Every effort has been made tokeep PEG as broad-coverage as possible.
In fact,there has been a tendency during the develop-ment of CRITIQUE to move certain types oferror detection, where possible, from the gram-mar to the style rule component.
Since style rulesare applied only after a parse has been obtained199by the grammar rules, this lessens the possibilitythat testing for an error will interfere with gram-mar rule processing.PresentationSystems such as CRITIQUE are generallyused to process texts which have been preparedfor a human audience often using word process-ing software.
Therefore it seems natural, perhapseven necessary, that these systems be tightly in-tegrated with a word processing environment.The CRITIQUE system architecture, whichhas been described previously from a distributedprocessing standpoint, may also be viewed as in-corporating a word processing environment as auser interface, with a background natural lan-guage processor.
There is nothing in theCRITIQUE system interface that requires thatwhat the parser servers return be grammaticaland stylistic information.
The "descriptors"produced by the parsers are general in nature andcould be used to send back any kind of informa-tion, possibly including a content characteriza-tion for information retrieval purposes or even atranslation into another language.
In this way,the system may be considered as a general pur-pose natural language processing environment.With respect o the presentation of critiqueinformation in this integrated environment, thediffering needs of the application areas have beenevident once again.
Several lessons in humanfactors have been learned and the results imple-mented.In a prior version of CRITIQUE, problemswere simply underlined on the screen, and userswere required to point to a particular problemand request that a window be opened whichcontained a description of what was wrong.
Asa result of studying the usage statistics gatheredby the manager server at IBM Research, we de-termined that users were not asking for the de-scriptions of errors.
Instead, they seemed to relyon their intuitions, only making use of the factthat CRITIQUE had flagged a particular wordor phrase.
This led us to replace the underliningwith a brief, highlighted code word or phrasewhich indicates what the problem is.
In caseswhere CRITIQUE suggests a corrected form ofa word, that form is now used as the error indi-cator.
This new format for displaying errors isshown in Figure 2.Lets contemplate how a president is selected.
*Let'sIn many cases the best candidate in the eyes of\[MISSING COMMAthe public is the one who has the most exposure.This is no way to chose a president, but*chooseunfortunately it is often true.
The total packageof a candidates political ideas don't really make*doesn'tan impression on the public.
His appearanceIFRAGMEIVTand mannerisms and the amount of exposurethat make him successful.Figure 2.
Example of errors flagged byCRITIQUEFrom this experience and other similar ones,we concluded that professionals usingCRITIQUE in an office environment preferreda quick, interactive review of memos and docu-ments.
The amount of feedback on the screenat any one time should be maximized, and thenumber of keystrokes and overall review timethereby minimized.Publications organizations have proved simi-lar in many respects.
However, due to the lengthand complexity of documents produced in suchorganizations, users may be more willing to waitfor their output, and often make use of overnightbatch runs.One feature of CRITIQUE that has proveduseful in this respect is called "interactive r view.
"It is based on the fact that the system saves allof the information produced about a given fdeon disk at the end of a session or run.
This in-formation is then read the next time the samedocument is processed, thereby eliminating theneed to reprocess sentences that have notchanged.
This means that it is possible for verylarge fdes to be run overnight, and then be re-viewed interactively the following day, therebylessening the impact on prime shift computerusage.Publications groups, through their occasionaluse of sub-contractors that do not have access toon-line information, provided part of the moti-200vation to optionally produce printed outputwhich is almost identical to what is viewed on thescreen.
They also required the flexibility of easilyintegrating the information contained in an or-ganizational style guide with the interactive tuto-rials for each critique.The universities we are working with consid-ered the abbreviated presentation of critique in-formation we developed to be appropriate fortheir advanced students, but inadequate for oth-ers.
They want the ability to lengthen explana-tions where desired and to group critiques bytype, only presenting certain types in the outputat any one time.Our varied experiences in these applicationareas have resulted in highly flexible, table-drivenpresentation modes for both batch and interac-tive output.
We continue to experiment andmake changes based on feedback.AccuracyAccuracy is perhaps the most important as-pect of a natural anguage system's overall per-formance.
It may be evaluated from twoperspectives: the actual "under-the-covers" na-tural language processing involved, and the user'sperception.
Given the state of the art, we mayconsider it a blessing that it is possible for thelatter to be somewhat better than the former.From a processing perspective inCRITIQUE, we reiterate that the PLNLP Eng-lish Grammar produces parses which are ap-proximate.
Without recourse to semantics wecannot hope for much better.
However, we arequite pleased with the coverage and accuracy thatwe have obtained, and fred them to be adequatefor the requirements of a system likeCRITIQUE.
The semantic ambiguities and in-accuracies which remain in the parses have notbeen a stumbling block to the usefulness of thesystem.
This demonstrates that some degree ofinaccuracy at the natural language processinglevel can be acceptable as long as it is not readilyvisible to the user.
We do not pretend to becompletely satisfied with this situation, however,and we are doing research in the area of"dictionary-based" semantic analysis.
This willenable us to improve some of the attachments inthe parse trees produced by PEG (Binot andJensen, 1987).Even being able to deal with a wide range ofill-formed input, it cannot be expected that aparser without a sophisticated semantic ompo-nent can successfully parse "gobbledegook."
Inthe goal to produce a useful and accurate analysisof text, there must also be an assumption in:cluded about the maximum degree of ill-formedness that can be handled.
The sentencegiven below in Figure 3, which was taken froma real student essay, illustrates the kind of ill-formedness which challenges CRITIQUE to itslimits.
The system did point out the commasplice in this sentence, but nothing else.
"lte xtarts to condemn Nora for her mistakeand made as i f  she is like poison that can becontagious, Trovald was ready to take away thekids and kick Nora out as an outcast as how theydid with Mr.
Krogstad.
"Figure 3.
An ill-formed sentence from astudent essayIn discussing the robustness of the parser, itwas pointed out that error detection is still per-formed within the successfully processed seg-ments of a fitted parse.
Our testing to this pointindicates that critiques produced in such situ-ations are about as accurate as those produced innon-fitted parses.
This is another case where theuser's perception may differ from the underlyingperformance of the system.In general, however, we have found users'perceptions and feedback to be most helpful.The facility that CRITIQUE provides for givingfeedback allows users to classify advice providedby the system according to the categoriescorrect, useful, missed, and wrong.
These cate-gories are self-explanatory except, perhaps, forthe useful category.
This refers to the case wherea critique is not exactly correct; but, since theuser's attention is drawn to a particular phraseor sentence, a real problem is noticed.
We tendto include these kinds of critiques with those thatare correct in evaluating the usefulness and accu-racy of the system.The most undesirable critiques are those inthe wrong category, as they tend to destroy userconfidence in the system and are not well toler-ated in educational environments.
We havefound, however, that professionals eem muchmore forgiving of wrong critiques, as long as thetime required to disregard them is minimal.
Thisis similar to using spelling checkers, whichwrongly highlight many proper names, acro-nyms, etc., but are still considered quite useful.In order to analyze CRITIQUE's current ac-curacy in an educational environment, we re-cently processed a number of student essaysprovided by the computer-aided writing programat Colorado State University.
We randomly se-lected 10 essays from each of four groups: fresh-man composition, business writing, ESL (Englishas a Second Language), and professional writing.The diagnoses made by CRITIQUE in these es-says were reviewed and classified according towhether they were correct, useful, or wrong.
Wedid not consider errors that were missed, butsimply concentrated on the correctness of thecritiques actually provided by the system.
Thereason for this orientation was our concern withthe potentially damaging effect of wrong advice.We adjusted the analysis in both directions,in a manner that we believe is fair.
On the onehand, we did not count correct critiques of atrivial or mechanical nature, such as misspelledwords, superficial punctuation checks, or read-ability scores.
On the other hand, we also didnot include a particular class of incorrect commacritiques, the handling of which we need to im-prove.
All other non-trivial critiques generatedby the system were counted.
The results areshown in Table 1.Group Fresh Bus ESL Pro./"# of Essays 10 10 10 I0# of Sentences 108 116 I10 401Avg.
Words per 16 18 21 22Sentence# of Different 20 9 23 32Critiques# of Critiques 36 11 63 158(Total)% Correct 72?/, 73% 54% 39%% Correct and 86% 82?/, 87% al %UsefulTable I.
Summary of accuracy fornon-trivial critiquesThe analysis confmned feedback we have re-ceived from users at IBM Research thatCRITIQUE is most helpful on straightforward201texts before they are significantly revised.
Themore polished and almost literary style of theprofessional essays challenged CRITIQUE'sability to provide generally useful advice.
TheESL texts, written by native Arabic, Chinese, andSpanish speakers, were also difficult, containinga large percentage of very ill-formed sentences.This is indicated by the higher number of usefulcritiques for this group, although it could be ar-gued that these critiques may not be as useful tousers who lack native intuitions about English.For the ESL group, correcting spelling errors firstresulted in significantly better grammar-checkingperformance.
This was not true for the othergroups.
In general, CRITIQUE also appears tobe more accurate on texts with a shorter averagesentence l ngth.ConclusionsBased on real experience in the applicationareas of office environments, publications organ-izations and educational institutions,CRITIQUE has been developed to a level ofapparent usefulness.
Acceptable system per-formance has been achieved through the use ofdistributed and optimized processing.
The sys-tem has achieved a high level of robustness andflexibility in most of its aspects, including pres-entation.
The accuracy of the system is currentlyacceptable for many types of texts and environ-ments, and accuracy continues to improve withexposure in each of the three application areas.CRITIQUE exemplifies a framework for the de-velopment of broad-coverage, large-scale naturallanguage text processing systems.A ckno wledgemen tsWe would like to thank Professor CharlesSmith and his colleagues from Colorado StateUniversity, who provided the student essays usedin the analysis of accuracy, as well as valuablefeedback about CRITIQUE.
We also expresssincere thanks to George Heidorn for his com-ments and guidance in the preparation of thispaper.ReferencesBinot, Jean-Louis and Karen Jensen.
1987.
"A semantic expert using an online standard ic-tionary."
Proceedings oflJCAI-87, Milan, Italy,August 1987.Heidom, George E. 1982.
"Experience withan Easily Computed Metric for Ranking Alter-native Parses."
Proceedings of the 20th AnnualMeeting of the Association for ComputationalLinguistics, Toronto, Canada, June 1982.Heidom, George E., Karen Jensen, LanceMiller, Roy Byrd, and Martin Chodorow.
1982.
"The EPISTLE Text-Critiquing System."
IBMSystems Journal 21, 3, 1982.Hendrix, Gary.
1986.
"Bringing Natural Lan-guage Processing to the Micro-Computer Mar-ket: The Story of Q&A."
Proceedings of the 24thAnnual Meeting of the Association for Computa-tional Linguistics, New York, New York, June1986.Jensen, Karen, George Heidorn, LanceMiller, and Yael Ravin.
1984.
"Parse Fitting andProse Fixing: Getting a Hold on IU-formedness.
"American Journal of Computational Linguistics,9, 3-4, 1984.Macdonald, Nina H., L.T.
Frase, P.Gingfich, and S.A. Keenan.
1982.
"The WRIT-ER'S WORKBENCIt: Computer aids for textanalysis," IEEE Transactions on Communication(Special Issue on Communication i the Auto-mated Office), 30, 1982.Richardson, Stephen D. 1985.
"EnhancedText-Critiquing using a Natural LanguageParser."
Proceedings of the Seventh InternationalConference on Computers and the Humanities,Provo, Utah, June 1985.Seybold Publications, Inc. 1984.
"ComputerAids for Authors and Editors."
The Seybold Re-port on Publishing Systems, 13, 10, 1984.202
